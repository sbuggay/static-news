<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1711789269389" as="style"/><link rel="stylesheet" href="styles.css?v=1711789269389"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://dl.gi.de/server/api/core/bitstreams/7c7a8830-fd81-4e56-8507-cd4809020660/content">Full-scale file system acceleration on GPU [pdf]</a>Â <span class="domain">(<a href="https://dl.gi.de">dl.gi.de</a>)</span></div><div class="subtext"><span>west0n</span> | <span>21 comments</span></div><br/><div><div id="39873023" class="c"><input type="checkbox" id="c-39873023" checked=""/><div class="controls bullet"><span class="by">afr0ck</span><span>|</span><a href="#39871458">next</a><span>|</span><label class="collapse" for="c-39873023">[-]</label><label class="expand" for="c-39873023">[1 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t fully read the paper, but few questions come into mind.<p>1) How does this work differ from Mark Silberstein&#x27;s GPUfs from 2014 [1]?<p>2) Does this work assume the storage device is only accessed by the GPU? Otherwise, how do you guarantee consistency when multiple processes can map, read and write the same files? You mention POSIX. POSIX has MAP_SHARED. How is this situation handled?<p>3) Related to (2), on the device level, how do you sync CPU (on an SMP, multiple cores) and GPU accesses?<p>[1] <a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;2553081" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;2553081</a></div><br/></div></div><div id="39871458" class="c"><input type="checkbox" id="c-39871458" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#39873023">prev</a><span>|</span><a href="#39873066">next</a><span>|</span><label class="collapse" for="c-39871458">[-]</label><label class="expand" for="c-39871458">[2 more]</label></div><br/><div class="children"><div class="content">Given that PCIe allows data to be piped directly from one device to another without going through the host CPU[1][2], I guess it might make sense to just have the GPU read blocks straight from the NVMe (or even NVMe-of[3]) rather than having the CPU do a lot of work.<p>edit: blind as a bat, says so right in the paper of course:<p><i>PMem is mapped directly to the GPU, and NVMe memory is accessed via Peer to Peer-DMA (P2PDMA)</i><p>[1]: <a href="https:&#x2F;&#x2F;nvmexpress.org&#x2F;wp-content&#x2F;uploads&#x2F;Enabling-the-NVMe-CMB-and-PMR-Ecosystem.pdf" rel="nofollow">https:&#x2F;&#x2F;nvmexpress.org&#x2F;wp-content&#x2F;uploads&#x2F;Enabling-the-NVMe-...</a><p>[2]: <a href="https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;767281&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;767281&#x2F;</a><p>[3]: <a href="https:&#x2F;&#x2F;www.nvmexpress.org&#x2F;wp-content&#x2F;uploads&#x2F;NVMe_Over_Fabrics.pdf" rel="nofollow">https:&#x2F;&#x2F;www.nvmexpress.org&#x2F;wp-content&#x2F;uploads&#x2F;NVMe_Over_Fabr...</a></div><br/><div id="39872218" class="c"><input type="checkbox" id="c-39872218" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#39871458">parent</a><span>|</span><a href="#39873066">next</a><span>|</span><label class="collapse" for="c-39872218">[-]</label><label class="expand" for="c-39872218">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure they&#x27;re actually doing NVMe yet; using Optane PMem is a bit of a cheat so that accessing storage is just plain memory reads and writes over PCIe. Implementing an NVMe device driver to set up and interact with command queues would be an extra layer of complexity that I think they left for future work.</div><br/></div></div></div></div><div id="39873066" class="c"><input type="checkbox" id="c-39873066" checked=""/><div class="controls bullet"><span class="by">touisteur</span><span>|</span><a href="#39871458">prev</a><span>|</span><a href="#39870931">next</a><span>|</span><label class="collapse" for="c-39873066">[-]</label><label class="expand" for="c-39873066">[1 more]</label></div><br/><div class="children"><div class="content">Now this is all fun, but has anyone managed to make these mechanisms work with Multicast PCIe ? I really need GPUdirect and StorageDirect to support this, until PCIe catches up to today&#x27;s (or Blackwell&#x27;s) NVLink ... around PCIe 12?</div><br/></div></div><div id="39870931" class="c"><input type="checkbox" id="c-39870931" checked=""/><div class="controls bullet"><span class="by">west0n</span><span>|</span><a href="#39873066">prev</a><span>|</span><a href="#39872562">next</a><span>|</span><label class="collapse" for="c-39870931">[-]</label><label class="expand" for="c-39870931">[6 more]</label></div><br/><div class="children"><div class="content">According to this paper, GPU4FS is a file system that can run on the GPU and be accessed by applications. Since GPUs cannot make system calls, GPU4FS uses shared video memory (VRAM) and a parallel queue implementation. Applications running on the GPU can utilize GPU4FS after modifying their code, eliminating the need for a CPU-side file system when accessing the file system. The experiments are done on Optane memory.<p>It would be interesting to know if this approach could optimize the performance of training and inference for large models.</div><br/><div id="39872810" class="c"><input type="checkbox" id="c-39872810" checked=""/><div class="controls bullet"><span class="by">t-3</span><span>|</span><a href="#39870931">parent</a><span>|</span><a href="#39871500">next</a><span>|</span><label class="collapse" for="c-39872810">[-]</label><label class="expand" for="c-39872810">[1 more]</label></div><br/><div class="children"><div class="content">GPUs seem to have a lot of memory these days - from my limited knowledge, games and other graphics-intensive applications will use too much to make this approach particularly useful but do other applications have a similar level of utilization?</div><br/></div></div><div id="39871500" class="c"><input type="checkbox" id="c-39871500" checked=""/><div class="controls bullet"><span class="by">DemocracyFTW2</span><span>|</span><a href="#39870931">parent</a><span>|</span><a href="#39872810">prev</a><span>|</span><a href="#39872562">next</a><span>|</span><label class="collapse" for="c-39871500">[-]</label><label class="expand" for="c-39871500">[4 more]</label></div><br/><div class="children"><div class="content">&gt; GPU4FS uses shared video memory<p>there will doubtless be a number of folks who understand that as meaning it&#x27;s somewhat like Zoom or Skype, or maybe a collection of VHS tapes</div><br/><div id="39872105" class="c"><input type="checkbox" id="c-39872105" checked=""/><div class="controls bullet"><span class="by">halayli</span><span>|</span><a href="#39870931">root</a><span>|</span><a href="#39871500">parent</a><span>|</span><a href="#39871509">next</a><span>|</span><label class="collapse" for="c-39872105">[-]</label><label class="expand" for="c-39872105">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like projection.</div><br/></div></div><div id="39871509" class="c"><input type="checkbox" id="c-39871509" checked=""/><div class="controls bullet"><span class="by">rrix2</span><span>|</span><a href="#39870931">root</a><span>|</span><a href="#39871500">parent</a><span>|</span><a href="#39872105">prev</a><span>|</span><a href="#39871512">next</a><span>|</span><label class="collapse" for="c-39871509">[-]</label><label class="expand" for="c-39871509">[1 more]</label></div><br/><div class="children"><div class="content">Then this isn&#x27;t for them</div><br/></div></div><div id="39871512" class="c"><input type="checkbox" id="c-39871512" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#39870931">root</a><span>|</span><a href="#39871500">parent</a><span>|</span><a href="#39871509">prev</a><span>|</span><a href="#39872562">next</a><span>|</span><label class="collapse" for="c-39871512">[-]</label><label class="expand" for="c-39871512">[1 more]</label></div><br/><div class="children"><div class="content">Highly unlikely any non-technical folks ever learn about this, much less try to decipher what it does.<p>Or perhaps I&#x27;m misunderstanding your comment? What do you mean exactly?</div><br/></div></div></div></div></div></div><div id="39872562" class="c"><input type="checkbox" id="c-39872562" checked=""/><div class="controls bullet"><span class="by">yeison</span><span>|</span><a href="#39870931">prev</a><span>|</span><a href="#39871909">next</a><span>|</span><label class="collapse" for="c-39872562">[-]</label><label class="expand" for="c-39872562">[1 more]</label></div><br/><div class="children"><div class="content">How to get hired by NVIDIA!  If it does work it&#x27;s a brilliant idea.</div><br/></div></div><div id="39871909" class="c"><input type="checkbox" id="c-39871909" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#39872562">prev</a><span>|</span><a href="#39871651">next</a><span>|</span><label class="collapse" for="c-39871909">[-]</label><label class="expand" for="c-39871909">[5 more]</label></div><br/><div class="children"><div class="content">Like Microsoft DirectStorage?</div><br/><div id="39872181" class="c"><input type="checkbox" id="c-39872181" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#39871909">parent</a><span>|</span><a href="#39871651">next</a><span>|</span><label class="collapse" for="c-39872181">[-]</label><label class="expand" for="c-39872181">[4 more]</label></div><br/><div class="children"><div class="content">Nope. This is an implementation of one of several things that people often imagine Microsoft&#x27;s DirectStorage to be, but the real DirectStorage is a lot more mundane.</div><br/><div id="39872409" class="c"><input type="checkbox" id="c-39872409" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#39871909">root</a><span>|</span><a href="#39872181">parent</a><span>|</span><a href="#39871651">next</a><span>|</span><label class="collapse" for="c-39872409">[-]</label><label class="expand" for="c-39872409">[3 more]</label></div><br/><div class="children"><div class="content">I have no clue, so I&#x27;ve asked, where is the difference?</div><br/><div id="39872659" class="c"><input type="checkbox" id="c-39872659" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#39871909">root</a><span>|</span><a href="#39872409">parent</a><span>|</span><a href="#39871651">next</a><span>|</span><label class="collapse" for="c-39872659">[-]</label><label class="expand" for="c-39872659">[2 more]</label></div><br/><div class="children"><div class="content">DirectStorage is mostly an API for CPU code to asynchronously issue high-level storage requests such as asking for a file to be read from storage and the contents placed in a particular GPU buffer. Behind the scenes, the file contents could in theory be transferred from an SSD to the GPU using P2P DMA, because the OS now has enough of a big-picture view of what&#x27;s going on to set up that kind of transfer when it&#x27;s possible. But everything about parsing the filesystem data structures to locate the requested file data and issue commands to the SSD is still done on the CPU by the OS, and the application originating those high-level requests is a process running on the CPU and making system calls.<p>Making the requests asynchronous and issuing lots of requests in parallel is what makes it possible to get good performance out of flash-based storage; P2P DMA would be a relatively minor optimization on top of that. DirectStorage isn&#x27;t the only way to asynchronously issue batches of storage requests; Windows has long had IOCP and more recently cloned io_uring from Linux.<p>DirectStorage 1.1 introduced an optional feature for GPU decompression, so that data which is stored on disk in a (the) supported compressed format can be streamed to the GPU and decompressed there instead of needing a round-trip through the CPU and its RAM for decompression. This could help make the P2P DMA option more widely usable by reducing the cases which need to fall back to the CPU, but decompressing on the GPU is nothing that applications couldn&#x27;t already implement for themselves; DirectStorage just provides a convenient standardized API for this so that GPU vendors can provide a well-optimized decompression implementation. When P2P DMA isn&#x27;t available, you can still get some computation offloaded from the CPU to the GPU after the compressed data makes a trip through the CPU&#x27;s RAM.<p>(Note: official docs about DirectStorage don&#x27;t really say anything about P2P DMA, but it&#x27;s clearly being designed to allow for it in the future.)<p>The GPU4FS described here is a project to implement the filesystem entirely on the GPU: the code to eg. walk the directory hierarchy and locate what address actually holds the file contents is not on the CPU but on the GPU. This approach means the application running on the GPU needs exclusive ownership of the device holding the filesystem. For now, they&#x27;re using persistent memory as the backing store, but in the future they could implement NVMe and have storage requests originate from the GPU and be delivered directly to the SSD with no CPU or OS involvement.</div><br/><div id="39872773" class="c"><input type="checkbox" id="c-39872773" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#39871909">root</a><span>|</span><a href="#39872659">parent</a><span>|</span><a href="#39871651">next</a><span>|</span><label class="collapse" for="c-39872773">[-]</label><label class="expand" for="c-39872773">[1 more]</label></div><br/><div class="children"><div class="content">Thanks!</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39871651" class="c"><input type="checkbox" id="c-39871651" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#39871909">prev</a><span>|</span><a href="#39872559">next</a><span>|</span><label class="collapse" for="c-39871651">[-]</label><label class="expand" for="c-39871651">[3 more]</label></div><br/><div class="children"><div class="content">Interesting they would discuss system call overhead of opening a file, reading from it and closing it. Seems like in almost all cases the open and close calls would be overwhelmed by the other operations.</div><br/><div id="39872127" class="c"><input type="checkbox" id="c-39872127" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#39871651">parent</a><span>|</span><a href="#39872559">next</a><span>|</span><label class="collapse" for="c-39872127">[-]</label><label class="expand" for="c-39872127">[2 more]</label></div><br/><div class="children"><div class="content">For lots of small files, that might not be the case.<p>(I worked on a FUSE filesystem that had these issues.)</div><br/><div id="39872467" class="c"><input type="checkbox" id="c-39872467" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#39871651">root</a><span>|</span><a href="#39872127">parent</a><span>|</span><a href="#39872559">next</a><span>|</span><label class="collapse" for="c-39872467">[-]</label><label class="expand" for="c-39872467">[1 more]</label></div><br/><div class="children"><div class="content">It seems more straightforward to fix your data-in-files layout than to implement a novel in-GPU filesystem, though.<p>I think the main benefit here is not having to do memory copies through the CPU, which frees up memory bandwidth for other things.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>