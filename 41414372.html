<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1725181262576" as="style"/><link rel="stylesheet" href="styles.css?v=1725181262576"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.theatlantic.com/technology/archive/2024/08/chatbots-false-memories/679660/">Chatbots Are Primed to Warp Reality</a> <span class="domain">(<a href="https://www.theatlantic.com">www.theatlantic.com</a>)</span></div><div class="subtext"><span>peutetre</span> | <span>20 comments</span></div><br/><div><div id="41415190" class="c"><input type="checkbox" id="c-41415190" checked=""/><div class="controls bullet"><span class="by">raesene9</span><span>|</span><a href="#41414698">next</a><span>|</span><label class="collapse" for="c-41415190">[-]</label><label class="expand" for="c-41415190">[2 more]</label></div><br/><div class="children"><div class="content">I can definitely see people becoming overly trusting of LLM output, but I have a feeling it might be a self-correcting problem over time.<p>Initially when working with an LLM if you start with a problem it knows well, it&#x27;s likely to give good results and if some minor hallucination creeps it you may well not notice and accept it based on earlier results being right.<p>However it&#x27;s quite likely you&#x27;ll hit a wildly wrong statement at some point, and that tends to break the illusion, and <i>hopefully</i> people who have that experience will start being more skeptical of what they&#x27;re being told by LLMs.</div><br/><div id="41415259" class="c"><input type="checkbox" id="c-41415259" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#41415190">parent</a><span>|</span><a href="#41414698">next</a><span>|</span><label class="collapse" for="c-41415259">[-]</label><label class="expand" for="c-41415259">[1 more]</label></div><br/><div class="children"><div class="content">People suck at telling the truth. There are whole occupations out there whose primary job it is to make use of that fact and influence people. I&#x27;d say upwards of 50% of the population can&#x27;t even tell when they are being manipulated by other humans with false info. Even when it is against their own interest. How are these people ever gonna stand up to LLMs who are much more suave than your average con artist? These models were literally trained on all the marketing material that is the modern internet.</div><br/></div></div></div></div><div id="41414698" class="c"><input type="checkbox" id="c-41414698" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#41415190">prev</a><span>|</span><a href="#41414529">next</a><span>|</span><label class="collapse" for="c-41414698">[-]</label><label class="expand" for="c-41414698">[3 more]</label></div><br/><div class="children"><div class="content">&gt; <i>suggests that the solicitous, authoritative tone that AI models take—combined with them being legitimately helpful and correct in many cases—could lead people to place too much trust in the technology.</i><p>Haven&#x27;t there been reports lately that people don&#x27;t trust the news? I&#x27;d think that the search engines&#x27; AI models would suffer the same fate given similar levels of accuracy.<p>&gt; <i>No one person, or even government, can tamper with every link displayed by Google or Bing.</i><p>Well, Google or Bing can.</div><br/><div id="41415020" class="c"><input type="checkbox" id="c-41415020" checked=""/><div class="controls bullet"><span class="by">flessner</span><span>|</span><a href="#41414698">parent</a><span>|</span><a href="#41414947">next</a><span>|</span><label class="collapse" for="c-41415020">[-]</label><label class="expand" for="c-41415020">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a difference between reading the news and chatting with an AI - evident because of the verbs.<p>While news are one-sided and usually have no immediate ways of discussing them (besides maybe Reddit and HN). Chatbots on the other hand are a correspondence, which makes them more like a discussion or interview... they seem more approachable (human?)<p>Platforms like c.ai push this to the extreme. While AI relationships seem dystopian right now, I fear they are already creeping up on us - forming beliefs even stronger than news can.<p>... Google and Microsoft are big in AI, so it&#x27;s not even a change in &quot;leadership&quot; anyway.</div><br/></div></div><div id="41414947" class="c"><input type="checkbox" id="c-41414947" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41414698">parent</a><span>|</span><a href="#41415020">prev</a><span>|</span><a href="#41414529">next</a><span>|</span><label class="collapse" for="c-41414947">[-]</label><label class="expand" for="c-41414947">[1 more]</label></div><br/><div class="children"><div class="content">Yeah you&#x27;ll get people ranting about gell-mann amnesia while uncritically ignoring good reporting.</div><br/></div></div></div></div><div id="41414529" class="c"><input type="checkbox" id="c-41414529" checked=""/><div class="controls bullet"><span class="by">sandspar</span><span>|</span><a href="#41414698">prev</a><span>|</span><a href="#41414708">next</a><span>|</span><label class="collapse" for="c-41414529">[-]</label><label class="expand" for="c-41414529">[5 more]</label></div><br/><div class="children"><div class="content">Has The Atlantic written any articles about how Google&#x27;s skewed top results also warps reality?</div><br/><div id="41414568" class="c"><input type="checkbox" id="c-41414568" checked=""/><div class="controls bullet"><span class="by">nox101</span><span>|</span><a href="#41414529">parent</a><span>|</span><a href="#41414953">next</a><span>|</span><label class="collapse" for="c-41414568">[-]</label><label class="expand" for="c-41414568">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve wondered this too. Just typing a single letter or two into Google immediately suggests stuff. I hate it. I don&#x27;t want these random suggestions entering my brain.<p>you can turn them off, if you log in.</div><br/><div id="41414740" class="c"><input type="checkbox" id="c-41414740" checked=""/><div class="controls bullet"><span class="by">hansvm</span><span>|</span><a href="#41414529">root</a><span>|</span><a href="#41414568">parent</a><span>|</span><a href="#41414887">next</a><span>|</span><label class="collapse" for="c-41414740">[-]</label><label class="expand" for="c-41414740">[1 more]</label></div><br/><div class="children"><div class="content">Back in the day I wrote a Google frontend so that I could get search results on a low-bandwidth connection (basically just a fancy proxy server). I bet you could similarly block out the suggestions.<p>Actually, you could probably just DNS block those? I&#x27;ll check later on desktop, but Google has a habit of throwing everything on a new domain.</div><br/></div></div><div id="41414887" class="c"><input type="checkbox" id="c-41414887" checked=""/><div class="controls bullet"><span class="by">anthropodie</span><span>|</span><a href="#41414529">root</a><span>|</span><a href="#41414568">parent</a><span>|</span><a href="#41414740">prev</a><span>|</span><a href="#41414953">next</a><span>|</span><label class="collapse" for="c-41414887">[-]</label><label class="expand" for="c-41414887">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just suggestions. On mobile front page they are showing suggestions of what people are searching without even typing word</div><br/></div></div></div></div><div id="41414953" class="c"><input type="checkbox" id="c-41414953" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41414529">parent</a><span>|</span><a href="#41414568">prev</a><span>|</span><a href="#41414708">next</a><span>|</span><label class="collapse" for="c-41414953">[-]</label><label class="expand" for="c-41414953">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s been a lot of reporting on Google getting worse, particularly in the Verge.</div><br/></div></div></div></div><div id="41414708" class="c"><input type="checkbox" id="c-41414708" checked=""/><div class="controls bullet"><span class="by">kelseyfrog</span><span>|</span><a href="#41414529">prev</a><span>|</span><a href="#41415213">next</a><span>|</span><label class="collapse" for="c-41414708">[-]</label><label class="expand" for="c-41414708">[4 more]</label></div><br/><div class="children"><div class="content">This is the kind of statement that is immediately obvious and vacuously true, or definitionally impossible.<p>If you&#x27;re the kind of person who believes language shapes reality then every utterance or written sentence functions as a reality building device.<p>If you&#x27;re the kind of person who believes reality is real and self-evident then language does nothing to shape our world.</div><br/><div id="41414787" class="c"><input type="checkbox" id="c-41414787" checked=""/><div class="controls bullet"><span class="by">az09mugen</span><span>|</span><a href="#41414708">parent</a><span>|</span><a href="#41415057">next</a><span>|</span><label class="collapse" for="c-41414787">[-]</label><label class="expand" for="c-41414787">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s more subtle than that and the danger relies more on the massive usage of chatbot AIs. Like some people I know, they use it many hours every day and they get trapped in some kind of &quot;echo chamber&quot;. Because they think chatbots have a consciousness like a human and they are social &quot;beings&quot; or entities, they sometimes get tricked into false beliefs. It&#x27;s more easy than you think to induce false memories : <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41598-022-11749-w" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41598-022-11749-w</a></div><br/></div></div><div id="41415057" class="c"><input type="checkbox" id="c-41415057" checked=""/><div class="controls bullet"><span class="by">loa_in_</span><span>|</span><a href="#41414708">parent</a><span>|</span><a href="#41414787">prev</a><span>|</span><a href="#41415116">next</a><span>|</span><label class="collapse" for="c-41415057">[-]</label><label class="expand" for="c-41415057">[1 more]</label></div><br/><div class="children"><div class="content">I think you said it yourself: some (arguably most) people are impressionable.</div><br/></div></div></div></div><div id="41415213" class="c"><input type="checkbox" id="c-41415213" checked=""/><div class="controls bullet"><span class="by">dcreater</span><span>|</span><a href="#41414708">prev</a><span>|</span><a href="#41415064">next</a><span>|</span><label class="collapse" for="c-41415213">[-]</label><label class="expand" for="c-41415213">[1 more]</label></div><br/><div class="children"><div class="content">Paywall. We need a flair for pay walled articles</div><br/></div></div><div id="41415064" class="c"><input type="checkbox" id="c-41415064" checked=""/><div class="controls bullet"><span class="by">julienreszka</span><span>|</span><a href="#41415213">prev</a><span>|</span><a href="#41414691">next</a><span>|</span><label class="collapse" for="c-41415064">[-]</label><label class="expand" for="c-41415064">[1 more]</label></div><br/><div class="children"><div class="content">Motherfucker, the news spit fake news all the time and the author has the nerve to blame chatbots</div><br/></div></div><div id="41414691" class="c"><input type="checkbox" id="c-41414691" checked=""/><div class="controls bullet"><span class="by">honkycat</span><span>|</span><a href="#41415064">prev</a><span>|</span><a href="#41415029">next</a><span>|</span><label class="collapse" for="c-41414691">[-]</label><label class="expand" for="c-41414691">[1 more]</label></div><br/><div class="children"><div class="content">I tried to ask my amazing google AI to send a text message today, and it couldn&#x27;t fucking do it<p>The tech still sucks, and everyone loves to ignore that it is constantly wrong<p>ask an AI to help you with a Makefile to see what I mean lmao</div><br/></div></div><div id="41415029" class="c"><input type="checkbox" id="c-41415029" checked=""/><div class="controls bullet"><span class="by">pdimitar</span><span>|</span><a href="#41414691">prev</a><span>|</span><label class="collapse" for="c-41415029">[-]</label><label class="expand" for="c-41415029">[2 more]</label></div><br/><div class="children"><div class="content">People so strongly wish that AI exists that they will believe anything. Pretty sad from a sociological and, much later, historical point of view.</div><br/></div></div></div></div></div></div></div></body></html>