<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735549258664" as="style"/><link rel="stylesheet" href="styles.css?v=1735549258664"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/OpenSPG/KAG">KAG – Knowledge Graph RAG Framework</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>taikon</span> | <span>17 comments</span></div><br/><div><div id="42547684" class="c"><input type="checkbox" id="c-42547684" checked=""/><div class="controls bullet"><span class="by">mentalgear</span><span>|</span><a href="#42547133">next</a><span>|</span><label class="collapse" for="c-42547684">[-]</label><label class="expand" for="c-42547684">[1 more]</label></div><br/><div class="children"><div class="content">I like their description&#x2F;approach for logical problem solving:<p>2.2.<p>&quot;The engine includes three types of operators: planning, reasoning, and retrieval, which transform natural language problems into problem solving processes that combine language and notation.<p>In this process, each step can use different operators, such as exact match retrieval, text retrieval, numerical calculation or semantic reasoning, so as to realize the integration of four different problem solving processes: Retrieval, Knowledge Graph reasoning, language reasoning and numerical calculation.&quot;</div><br/></div></div><div id="42547133" class="c"><input type="checkbox" id="c-42547133" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#42547684">prev</a><span>|</span><a href="#42547671">next</a><span>|</span><label class="collapse" for="c-42547133">[-]</label><label class="expand" for="c-42547133">[4 more]</label></div><br/><div class="children"><div class="content">Fancy, I think, but again no word on the actual work of turning a few bazillion csv files and pdf&#x27;s into a knowledge graph.<p>I see a lot of these KG tools pop up, but they never solve the first problem I have, which is actually constructing the KG itself.</div><br/><div id="42547488" class="c"><input type="checkbox" id="c-42547488" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#42547133">parent</a><span>|</span><a href="#42547556">next</a><span>|</span><label class="collapse" for="c-42547488">[-]</label><label class="expand" for="c-42547488">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I see a lot of these KG tools pop up, but they never solve the first problem I have, which is actually constructing the KG itself.<p>I have heard good things about Graphrag [1] (but what a stupid name). I did not have the time to try it properly, but it is supposed to build the knowledge graph itself somewhat transparently, using LLMs. This is a big stumbling block. At least vector stores are easy to understand and trivial to build.<p>It <i>looks</i> like KAG can do this from the summary on GitHub, but I could not really find how to do it in the documentation.<p>[1] <a href="https:&#x2F;&#x2F;microsoft.github.io&#x2F;graphrag&#x2F;" rel="nofollow">https:&#x2F;&#x2F;microsoft.github.io&#x2F;graphrag&#x2F;</a></div><br/><div id="42547518" class="c"><input type="checkbox" id="c-42547518" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#42547133">root</a><span>|</span><a href="#42547488">parent</a><span>|</span><a href="#42547556">next</a><span>|</span><label class="collapse" for="c-42547518">[-]</label><label class="expand" for="c-42547518">[1 more]</label></div><br/><div class="children"><div class="content">Indeed they seem to actually know&#x2F;show how the sausage is made... but still, no fire and forget approach for any random dataset. check out what you need to do if the default isnt working for you (scroll down to eg. entity_extraction settings). there is so much complexity there to deal with that i&#x27;d just roll my own extraction pipeline from the start, rather than learning someone elses complex setup (that you have to tweak for each new usecase)<p><a href="https:&#x2F;&#x2F;microsoft.github.io&#x2F;graphrag&#x2F;config&#x2F;yaml&#x2F;" rel="nofollow">https:&#x2F;&#x2F;microsoft.github.io&#x2F;graphrag&#x2F;config&#x2F;yaml&#x2F;</a></div><br/></div></div></div></div><div id="42547556" class="c"><input type="checkbox" id="c-42547556" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#42547133">parent</a><span>|</span><a href="#42547488">prev</a><span>|</span><a href="#42547671">next</a><span>|</span><label class="collapse" for="c-42547556">[-]</label><label class="expand" for="c-42547556">[1 more]</label></div><br/><div class="children"><div class="content">There is some automated named entity extraction and relationship building out of un&#x2F;semi structured data as part of the neo4j onboarding now to go with all these GraphRAG efforts (&amp; maybe honorable mention to WhyHow.ai too)</div><br/></div></div></div></div><div id="42547671" class="c"><input type="checkbox" id="c-42547671" checked=""/><div class="controls bullet"><span class="by">mentalgear</span><span>|</span><a href="#42547133">prev</a><span>|</span><a href="#42547305">next</a><span>|</span><label class="collapse" for="c-42547671">[-]</label><label class="expand" for="c-42547671">[1 more]</label></div><br/><div class="children"><div class="content">It has come to the point that we need benchmarks for (Graph)-Rag systems now, same as we have for pure LLMs. However vendors will certainly then optimize for the popular ones, so we need a good mix of public, private and dynamic eval datasets.</div><br/></div></div><div id="42547305" class="c"><input type="checkbox" id="c-42547305" checked=""/><div class="controls bullet"><span class="by">zbyforgotp</span><span>|</span><a href="#42547671">prev</a><span>|</span><a href="#42546980">next</a><span>|</span><label class="collapse" for="c-42547305">[-]</label><label class="expand" for="c-42547305">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are not that different from humans, in both cases you have some limited working memory and you need to fit the most relevant context into it. This means that if you have a new knowledge base for llms it should be useful for humans too. There should be a lot of cross pollination between these tools.<p>But we need a theory on the differences too. Now it is kind of random how we differentiate the tools. We need ergonomics for llms.</div><br/></div></div><div id="42546980" class="c"><input type="checkbox" id="c-42546980" checked=""/><div class="controls bullet"><span class="by">rastierastie</span><span>|</span><a href="#42547305">prev</a><span>|</span><a href="#42546890">next</a><span>|</span><label class="collapse" for="c-42546980">[-]</label><label class="expand" for="c-42546980">[2 more]</label></div><br/><div class="children"><div class="content">What do other HNers make out of this? Would you use this? Responsible for a legaltech startup here.</div><br/><div id="42547496" class="c"><input type="checkbox" id="c-42547496" checked=""/><div class="controls bullet"><span class="by">leobg</span><span>|</span><a href="#42546980">parent</a><span>|</span><a href="#42546890">next</a><span>|</span><label class="collapse" for="c-42547496">[-]</label><label class="expand" for="c-42547496">[1 more]</label></div><br/><div class="children"><div class="content">Fellow legal tech founder here. The first thing I look at in projects like this are the prompts:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;OpenSPG&#x2F;KAG&#x2F;blob&#x2F;master&#x2F;kag&#x2F;builder&#x2F;prompt&#x2F;semantic_seg_prompt.py">https:&#x2F;&#x2F;github.com&#x2F;OpenSPG&#x2F;KAG&#x2F;blob&#x2F;master&#x2F;kag&#x2F;builder&#x2F;promp...</a><p>All you’re doing here is “front loading” AI: Imstead of running slow and expensive LLMs at query time, you run them at index time.<p>It’s a method for data augmentation or, in database lingo, index building. You use LLMs to add context to chunks that doesn’t exist on either the word level (searchable by BM25) or the semantic level (searchable by embeddings).<p>A simple version of this would be to ask an LLM:<p>“List all questions this chunk is answering.” [0]<p>But you can do the same thing for time frames, objects, styles, emotions — whatever you need a “handle” for to later retrieve via BM25 or semantic similarity.<p>I dreamed of doing that back in 2020, but it would’ve been prohibitively expensive. Because it requires passing your whole corpus through an LLM, possibly multiple times, once for each “angle”.<p>That being said, I recommend running any “Graph RAG” system you see here on HN over some 1% or so of your data. And then look inside the database. Look at all text chunks, original and synthetic, that are now in your index.<p>I’ve done this for a consulting client who absolutely wanted “Graph RAG”. I found the result to be an absolute mess. That is because these systems are built to cover a broad range of applications and are not adapted at all to your problem domain.<p>So I prefer working backwards:<p>What kinds of queries do I need to handle? What does the prompt to my query time LLM need to look like? What context will the LLM need? How can I have this context for each of my chunks, and be able to search by match air similarity? And now how can I make an LLM return exactly that kind of context, with as few hallucinations and as little filler as possible, for each of my chunks?<p>This gives you a very lean, very efficient index that can do everything you want.<p>[0] For a prompt, you’d add context and give the model “space to think”, especially when using a smaller model. Also, you’d instruct it to use a particular format, so you can parse out the part that you need. This “unfancy” approach lets you switch out models easily and compare them against each other without having to care about different APIs for “structured output”.</div><br/></div></div></div></div><div id="42546890" class="c"><input type="checkbox" id="c-42546890" checked=""/><div class="controls bullet"><span class="by">dcreater</span><span>|</span><a href="#42546980">prev</a><span>|</span><a href="#42546617">next</a><span>|</span><label class="collapse" for="c-42546890">[-]</label><label class="expand" for="c-42546890">[5 more]</label></div><br/><div class="children"><div class="content">Yet another RAG&#x2F;knowledge graph implementation.<p>At this point, the onus is on the developer to prove it&#x27;s value through AB comparisons versus traditional RAG. No person&#x2F;team has the bandwidth to try out this (n + 1) solution.</div><br/><div id="42546979" class="c"><input type="checkbox" id="c-42546979" checked=""/><div class="controls bullet"><span class="by">ertdfgcvb</span><span>|</span><a href="#42546890">parent</a><span>|</span><a href="#42546617">next</a><span>|</span><label class="collapse" for="c-42546979">[-]</label><label class="expand" for="c-42546979">[4 more]</label></div><br/><div class="children"><div class="content">I enjoy the explosion of tools. Only time will tell which ones stand the test of time. But this is my day job so I never get tired of new tools but I can see how non-industry folks can find it overwhelming</div><br/><div id="42547052" class="c"><input type="checkbox" id="c-42547052" checked=""/><div class="controls bullet"><span class="by">trees101</span><span>|</span><a href="#42546890">root</a><span>|</span><a href="#42546979">parent</a><span>|</span><a href="#42546617">next</a><span>|</span><label class="collapse" for="c-42547052">[-]</label><label class="expand" for="c-42547052">[3 more]</label></div><br/><div class="children"><div class="content">Can you expand on that?
Where do big enterprise orgs products fit in, eg Microsoft, Google?
What are the leading providers as you see them?
As an outsider it is bewildering. First I hear that llama_index is good, then I hear that its overcomplicating slop. What sources or resources are reliable on this? How can we develop anything that will still stand in 12 months time?</div><br/><div id="42547244" class="c"><input type="checkbox" id="c-42547244" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#42546890">root</a><span>|</span><a href="#42547052">parent</a><span>|</span><a href="#42547418">next</a><span>|</span><label class="collapse" for="c-42547244">[-]</label><label class="expand" for="c-42547244">[1 more]</label></div><br/><div class="children"><div class="content">May help to think of these tools as on the opposite end of the spectrum. As an analogy:<p>1. langchain, llamaindex, etc are the equivalent of jquery or ORMs for calling third-party LLMs. They&#x27;re thin adapter layers with a bit of consistency and common tasks across. Arguably like React, where they are thin composition layers. So complaints of being leaky abstractions is in the sense of an ORM getting in the way vs helping.<p>2. KG&#x2F;graph RAG libraries are the LLM equivalent of, when regex + LIKE sql statements aren&#x27;t enough, graduating to a full-blown lucene&#x2F;solr engine. These are intelligence engines that address index-time, query-time, and likely, both. Thin libraries and those lacking standard benchmarks are a sign of experiments vs production-relevant: unless you&#x27;re just talking to 1 pdf, not likely what you want. IMO, no &#x27;winners&#x27; here yet: llamaindex was part of an early wave of preprocessors that feed PDFs etc to the KG, but not winning the actual &#x27;smart&#x27; KG&#x2F;RAG. In contrast, MSR Graph RAG is popular and benchmarks well, but if you read the github &amp; paper, not intended for use -- ex: it addresses 1 family of infrequent query you&#x27;d do in a RAG system (&quot;n-hop&quot;), but not the primary kinds like mixing semantic+keyword search with query rewriting, and struggles with basics like updates.<p>Most VC infra&#x2F;DB $ goes to a layer below the KG. For example, vector databases -- but vector DBs are relatively dumb blackboxes, you can think of them more like S3 or a DB index, while the LLM KG&#x2F;AI quality work is generally a layer above. (We do train &amp; tune our embedding models, but that&#x27;s a tiny % of the ultimate win, mostly for smarter compression for handling scaling costs, not the bigger smarts.)<p>+ 1 to presentation being confusing! VC $ on agents, vector DB co&#x27;s, etc, and well-meaning LLM enthusiasts are cranking out articles on small uses of LLMs, but in reality, these end up being pretty crappy in quality if you&#x27;d actually ship them. So once quality matters, you get into things like the KG&#x2F;graph RAG work &amp; evals, which is a lot more effort &amp; grinding =&gt; smaller % of the infotainment &amp; marketing going around.<p>(We do this stuff at real-time &amp; data-intensive scales as part of Louie.AI, and are always looking for design partners, esp on graph rag, so happy to chat.)</div><br/></div></div><div id="42547418" class="c"><input type="checkbox" id="c-42547418" checked=""/><div class="controls bullet"><span class="by">ertdfgcvb</span><span>|</span><a href="#42546890">root</a><span>|</span><a href="#42547052">parent</a><span>|</span><a href="#42547244">prev</a><span>|</span><a href="#42546617">next</a><span>|</span><label class="collapse" for="c-42547418">[-]</label><label class="expand" for="c-42547418">[1 more]</label></div><br/><div class="children"><div class="content">&gt;What sources or resources are reliable on this?<p>imo, none. Unfortunately, the landscape is changing too fast. May be things will stabilize, but for now I find experimentation a time-consuming but essential part of maintaining any ML stack.<p>But it&#x27;s okay not to experiment with every new tool (it can be overwhelming to do this). The key is in understanding one&#x27;s own stack and filtering out anything that doesn&#x27;t fit into it.</div><br/></div></div></div></div></div></div></div></div><div id="42546617" class="c"><input type="checkbox" id="c-42546617" checked=""/><div class="controls bullet"><span class="by">slowmovintarget</span><span>|</span><a href="#42546890">prev</a><span>|</span><label class="collapse" for="c-42546617">[-]</label><label class="expand" for="c-42546617">[2 more]</label></div><br/><div class="children"><div class="content">How does this compare to the Model Context Protocol?<p><a href="https:&#x2F;&#x2F;modelcontextprotocol.io&#x2F;introduction" rel="nofollow">https:&#x2F;&#x2F;modelcontextprotocol.io&#x2F;introduction</a></div><br/><div id="42547285" class="c"><input type="checkbox" id="c-42547285" checked=""/><div class="controls bullet"><span class="by">febin</span><span>|</span><a href="#42546617">parent</a><span>|</span><label class="collapse" for="c-42547285">[-]</label><label class="expand" for="c-42547285">[1 more]</label></div><br/><div class="children"><div class="content">MCP is a protocol for tool usage, where as KAG is for knowledge representation and information retrieval.</div><br/></div></div></div></div></div></div></div></div></div></body></html>