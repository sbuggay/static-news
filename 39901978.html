<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712048452241" as="style"/><link rel="stylesheet" href="styles.css?v=1712048452241"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://rbren.substack.com/p/banning-open-weight-models-would">Banning open weight models would be a disaster</a> <span class="domain">(<a href="https://rbren.substack.com">rbren.substack.com</a>)</span></div><div class="subtext"><span>rbren</span> | <span>67 comments</span></div><br/><div><div id="39902606" class="c"><input type="checkbox" id="c-39902606" checked=""/><div class="controls bullet"><span class="by">greenavocado</span><span>|</span><a href="#39902858">next</a><span>|</span><label class="collapse" for="c-39902606">[-]</label><label class="expand" for="c-39902606">[12 more]</label></div><br/><div class="children"><div class="content">Remember when the world freaked out over encryption, thinking every coded message was a digital skeleton key to anarchy? Yeah, the 90s were wild with the whole PGP (Pretty Good Privacy) encryption fight. The government basically treated encryption like it was some kind of wizardry that only &quot;good guys&quot; should have. Fast forward to today, and it&#x27;s like we&#x27;re stuck on repeat with open model weights.<p>Just like code was the battleground back then, open model weights are the new frontier. Think about it—code is just a bunch of instructions, right? Well, model weights are pretty much the same; they&#x27;re the brains behind AI, telling it how to think and learn. Saying &quot;nah, you can&#x27;t share those&quot; is like trying to put a genie back in its bottle after it&#x27;s shown you it can grant wishes.<p>The whole deal with PGP was about privacy, sending messages without worrying about prying eyes. Fast forward, and model weights are about sharing knowledge, making AI smarter and more accessible. Blocking that flow of information? It&#x27;s like telling scientists they can&#x27;t share their research because someone, somewhere, might do something bad with it.<p>Code lets us communicate with machines, model weights let machines learn from us. Both are about building and sharing knowledge. When the government tried to control encryption, it wasn&#x27;t just about keeping secrets; it was about who gets to have a voice and who gets to listen. With open model weights, we&#x27;re talking about who gets to learn and who gets to teach.<p>Banning or restricting access to model weights feels eerily similar to those encryption wars. It&#x27;s a move that says, &quot;We&#x27;re not sure we trust you with this power.&quot; But just like with code, the answer isn&#x27;t locking it away. It&#x27;s about education, responsible use, and embracing the potential for good.<p>Innovation thrives on openness. Whether it&#x27;s the lines of code that secure our digital lives or the model weights that could revolutionize AI, putting up walls only slows us down. We&#x27;ve been down this road before. Let&#x27;s not make the same mistake of thinking we can control innovation by restricting access.</div><br/><div id="39903440" class="c"><input type="checkbox" id="c-39903440" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39902606">parent</a><span>|</span><a href="#39902809">next</a><span>|</span><label class="collapse" for="c-39903440">[-]</label><label class="expand" for="c-39903440">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Just like code was the battleground back then, open model weights are the new frontier. Think about it—code is just a bunch of instructions, right? Well, model weights are pretty much the same; they&#x27;re the brains behind AI, telling it how to think and learn. Saying &quot;nah, you can&#x27;t share those&quot; is like trying to put a genie back in its bottle after it&#x27;s shown you it can grant wishes.<p>I think telling a genie &quot;I wish for no more wishes&quot; is a common enough trope.<p>I&#x27;d agree that making weights available is basically irreversible; however making it illegal to make new sets of weights available is probably fairly achievable… at present.<p>-<p>Some of the issues with &quot;winning&quot; the battle for encryption include:<p>1) We also need it to defend normal people from attackers<p>2) It&#x27;s simple enough to print onto a T-shirt<p>3) The developers recognised the value and wanted to share this<p>The differences with AI include:<p>1) The <i>most capable</i> models don&#x27;t fit on most personal devices at present, let alone T-shirts<p>2) 95% of the advantages can be had from centralised systems without needing to distribute the models directly to everyone<p>3) A huge number of developers have signed an open letter which is basically screaming &quot;please regulate us! We don&#x27;t want to be in an arms race with each other to make this more capable! We don&#x27;t know what we&#x27;re doing or what risks this has!&quot;</div><br/><div id="39903571" class="c"><input type="checkbox" id="c-39903571" checked=""/><div class="controls bullet"><span class="by">SV_BubbleTime</span><span>|</span><a href="#39902606">root</a><span>|</span><a href="#39903440">parent</a><span>|</span><a href="#39902809">next</a><span>|</span><label class="collapse" for="c-39903571">[-]</label><label class="expand" for="c-39903571">[1 more]</label></div><br/><div class="children"><div class="content">As long as everyone admits that number 3 “please regulate us” is really just asking for regulatory capture and is in no way a good faith move, but rather protectionism. Then I’m good to proceed with these conversations.<p>These people have not just suddenly developed consciouses. This is a game move.</div><br/></div></div></div></div><div id="39902809" class="c"><input type="checkbox" id="c-39902809" checked=""/><div class="controls bullet"><span class="by">jj999</span><span>|</span><a href="#39902606">parent</a><span>|</span><a href="#39903440">prev</a><span>|</span><a href="#39902896">next</a><span>|</span><label class="collapse" for="c-39902809">[-]</label><label class="expand" for="c-39902809">[3 more]</label></div><br/><div class="children"><div class="content">The fight against encryption continue to this day and while https is now ubiquitous, large-scale cdns makes it somewhat a moot point and emails are still largely plaintext.</div><br/><div id="39903321" class="c"><input type="checkbox" id="c-39903321" checked=""/><div class="controls bullet"><span class="by">solatic</span><span>|</span><a href="#39902606">root</a><span>|</span><a href="#39902809">parent</a><span>|</span><a href="#39902896">next</a><span>|</span><label class="collapse" for="c-39903321">[-]</label><label class="expand" for="c-39903321">[2 more]</label></div><br/><div class="children"><div class="content">&gt; emails are still largely plaintext<p>But people&#x27;s private digital communications have largely moved to platforms like WhatsApp and Messenger which enjoy end-to-end encryption. Email, at least between major providers, today enjoys TLS over the wire while being sent.<p>I&#x27;m sure there are various flaws and weaknesses and maybe even backdoors, but trying to make it sound like we lost the fight for encryption because emails are in plaintext is rather disingenuous.</div><br/><div id="39903412" class="c"><input type="checkbox" id="c-39903412" checked=""/><div class="controls bullet"><span class="by">oez</span><span>|</span><a href="#39902606">root</a><span>|</span><a href="#39903321">parent</a><span>|</span><a href="#39902896">next</a><span>|</span><label class="collapse" for="c-39903412">[-]</label><label class="expand" for="c-39903412">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure Facebook and a now Facebook owned platform are good examples for private communications. There was an article posted here a week or two ago detailing how Facebook sold access to the contents of users private messages to advertisers.</div><br/></div></div></div></div></div></div><div id="39902896" class="c"><input type="checkbox" id="c-39902896" checked=""/><div class="controls bullet"><span class="by">opdahl</span><span>|</span><a href="#39902606">parent</a><span>|</span><a href="#39902809">prev</a><span>|</span><a href="#39902898">next</a><span>|</span><label class="collapse" for="c-39902896">[-]</label><label class="expand" for="c-39902896">[5 more]</label></div><br/><div class="children"><div class="content">Off-topic but this user seems to be using ChatGPT or something similar for almost every single comment. Does Hacker News have a stance on this or is the thinking that it is allowed as long as the content is good?</div><br/><div id="39903540" class="c"><input type="checkbox" id="c-39903540" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#39902606">root</a><span>|</span><a href="#39902896">parent</a><span>|</span><a href="#39903254">next</a><span>|</span><label class="collapse" for="c-39903540">[-]</label><label class="expand" for="c-39903540">[1 more]</label></div><br/><div class="children"><div class="content">I took a look at their profile and I’m not seeing anything that looks auto generated to me.</div><br/></div></div><div id="39903254" class="c"><input type="checkbox" id="c-39903254" checked=""/><div class="controls bullet"><span class="by">stareatgoats</span><span>|</span><a href="#39902606">root</a><span>|</span><a href="#39902896">parent</a><span>|</span><a href="#39903540">prev</a><span>|</span><a href="#39903089">next</a><span>|</span><label class="collapse" for="c-39903254">[-]</label><label class="expand" for="c-39903254">[1 more]</label></div><br/><div class="children"><div class="content">There is indeed a stance, adding autogenerated comments can get you banned:
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33945628">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33945628</a></div><br/></div></div><div id="39903089" class="c"><input type="checkbox" id="c-39903089" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#39902606">root</a><span>|</span><a href="#39902896">parent</a><span>|</span><a href="#39903254">prev</a><span>|</span><a href="#39902898">next</a><span>|</span><label class="collapse" for="c-39903089">[-]</label><label class="expand" for="c-39903089">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s important not to jump to conclusions about how others are participating in discussions, especially based on the content or style of their comments alone. Many users might have a consistent way of expressing themselves, or they may be leveraging various tools and resources to enhance their contributions.<p>The key focus should always be on the quality and relevance of the content shared.</div><br/><div id="39903591" class="c"><input type="checkbox" id="c-39903591" checked=""/><div class="controls bullet"><span class="by">wruza</span><span>|</span><a href="#39902606">root</a><span>|</span><a href="#39903089">parent</a><span>|</span><a href="#39902898">next</a><span>|</span><label class="collapse" for="c-39903591">[-]</label><label class="expand" for="c-39903591">[1 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t only feel odd, it also is empty prose based on a far-fetched analogy. Apologies to the root commenter if they wrote it themselves, but quality and relevance is lacking here. 99% sure some of their posts are at least heavily augmented.</div><br/></div></div></div></div></div></div><div id="39902898" class="c"><input type="checkbox" id="c-39902898" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#39902606">parent</a><span>|</span><a href="#39902896">prev</a><span>|</span><a href="#39902858">next</a><span>|</span><label class="collapse" for="c-39902898">[-]</label><label class="expand" for="c-39902898">[1 more]</label></div><br/><div class="children"><div class="content">Well, that was a healthy rant<p>Life, all biological life with us as a kind of pinnacle, is about to go through radical change.<p>There is no risk free path. It isn’t guaranteed that a single human will be alive in 100 years - because we failed, or even because technologically we succeeded<p>But a degree of openness is necessary for our best ideas, our most good faith collaborations, to have a chance<p>It is more chaotic to trust each other, en masse. But I also think it is our best bet<p>The dice must be rolled. Best we throw them bold</div><br/></div></div></div></div><div id="39902858" class="c"><input type="checkbox" id="c-39902858" checked=""/><div class="controls bullet"><span class="by">mikkom</span><span>|</span><a href="#39902606">prev</a><span>|</span><a href="#39903632">next</a><span>|</span><label class="collapse" for="c-39902858">[-]</label><label class="expand" for="c-39902858">[3 more]</label></div><br/><div class="children"><div class="content">Wow what a horrible idea. Sounds like monopoly in the making. I would be really interested to hear what &quot;open&quot; AI has commented about this -  I guess they are lobbying for this with all of their billions.<p>If the US government really want to do this correctly, they must also ban any API access to AI models and ban all research related to AI.<p>How could this be even written as law? Universities and companies are probihited to publish their research? How many layer models are forbidden to be published? All neural networks?</div><br/><div id="39903433" class="c"><input type="checkbox" id="c-39903433" checked=""/><div class="controls bullet"><span class="by">DarkNova6</span><span>|</span><a href="#39902858">parent</a><span>|</span><a href="#39903632">next</a><span>|</span><label class="collapse" for="c-39903433">[-]</label><label class="expand" for="c-39903433">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s clear to me that Sam Altman has turned OpanAI into ClosedAI</div><br/><div id="39903576" class="c"><input type="checkbox" id="c-39903576" checked=""/><div class="controls bullet"><span class="by">iLoveOncall</span><span>|</span><a href="#39902858">root</a><span>|</span><a href="#39903433">parent</a><span>|</span><a href="#39903632">next</a><span>|</span><label class="collapse" for="c-39903576">[-]</label><label class="expand" for="c-39903576">[1 more]</label></div><br/><div class="children"><div class="content">Not just &quot;ClosedAI&quot; but &quot;CloseAllAI&quot;. He&#x27;s been actively lobbying congress and others to ensure OpenAI are the only ones, with a few other big actors, that can make AI.</div><br/></div></div></div></div></div></div><div id="39903632" class="c"><input type="checkbox" id="c-39903632" checked=""/><div class="controls bullet"><span class="by">bradley13</span><span>|</span><a href="#39902858">prev</a><span>|</span><a href="#39902935">next</a><span>|</span><label class="collapse" for="c-39903632">[-]</label><label class="expand" for="c-39903632">[1 more]</label></div><br/><div class="children"><div class="content">Government is necessary, in order to organize a complex society, but government is like any other organization: made up of people, many of who are out for their own interests. The most prominent of those interests are power and money.<p>Whenever government proposes banning a technology, one must ask: who benefits? The LLMs, even in their current state of infancy, are powerful tools. Restricting access to those tools keeps power in the hands of wealthy corporations and the government itself. That&#x27;s the power aspect.<p>The money aspect is even simpler: Don&#x27;t doubt that some of those wealthy corporations are making donations to certain officials, in order to gain support for actions like this. Almost no one leaves the Congress (or almost any parliamentary body in any country) as less than a multi-millionaire. Funny, how that works...</div><br/></div></div><div id="39902935" class="c"><input type="checkbox" id="c-39902935" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#39903632">prev</a><span>|</span><a href="#39903330">next</a><span>|</span><label class="collapse" for="c-39902935">[-]</label><label class="expand" for="c-39902935">[1 more]</label></div><br/><div class="children"><div class="content">So AI companies take all the world&#x27;s text and knowledge for free, use openly available research, take massive private funding and generate immense economic value using that, and want to make it illegal for anyone else to do the same?<p>I don&#x27;t get the &#x27;harm can be done by individuals&#x27; argument. Sticks and stones. Every discussion forum on the internet is moderated to some degree, and every human being has the ability to post hurtful or illegal content, yet the system works. Moderation will only get more powerful thanks to AI tools.</div><br/></div></div><div id="39903330" class="c"><input type="checkbox" id="c-39903330" checked=""/><div class="controls bullet"><span class="by">skissane</span><span>|</span><a href="#39902935">prev</a><span>|</span><a href="#39903397">next</a><span>|</span><label class="collapse" for="c-39903330">[-]</label><label class="expand" for="c-39903330">[5 more]</label></div><br/><div class="children"><div class="content">There are almost 200 countries in the world. Even if the US and the EU and a bunch more ban open weight models, I doubt they&#x27;ll succeed in convincing every country to do so. And whichever countries decide not to follow the ban, could thereby give their own AI industries a big boost. As the world becomes ever more globalised, the potential effectiveness of these kinds of policies declines.<p>Sure, they <i>could</i> try to negotiate some kind of UN convention for a coordinated global ban. But, given how fractured global diplomacy has become, I doubt the odds of something like that succeeding are particularly high.</div><br/><div id="39903489" class="c"><input type="checkbox" id="c-39903489" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39903330">parent</a><span>|</span><a href="#39903365">next</a><span>|</span><label class="collapse" for="c-39903489">[-]</label><label class="expand" for="c-39903489">[1 more]</label></div><br/><div class="children"><div class="content">Most of the researchers are specifically in a handful of big labs, most of which in turn are in the USA. As one who has done so, trust me when I say that relocation is harder than it seems on paper.<p>Also note that both California and the EU are economically dominant enough that they tend to influence regulation outside their own borders: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Brussels_effect" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Brussels_effect</a><p>Further note how many people signed the Pause letter: <a href="https:&#x2F;&#x2F;futureoflife.org&#x2F;open-letter&#x2F;pause-giant-ai-experiments&#x2F;" rel="nofollow">https:&#x2F;&#x2F;futureoflife.org&#x2F;open-letter&#x2F;pause-giant-ai-experime...</a><p>In addition, given how much training data current models need, there would be a huge impact just by a handful of governments siding with all the copyright holders suing OpenAI, Midjourney, Stability AI, etc.<p>And all that is without needing Yudkowsky&#x27;s point that a ban isn&#x27;t serious unless you&#x27;re willing to escalate to performing airstrikes on data centres.</div><br/></div></div><div id="39903365" class="c"><input type="checkbox" id="c-39903365" checked=""/><div class="controls bullet"><span class="by">antupis</span><span>|</span><a href="#39903330">parent</a><span>|</span><a href="#39903489">prev</a><span>|</span><a href="#39903397">next</a><span>|</span><label class="collapse" for="c-39903365">[-]</label><label class="expand" for="c-39903365">[3 more]</label></div><br/><div class="children"><div class="content">Money, talent, and institutions still cluster around the US and EU where the best universities are so this would hurt seriously AI development.</div><br/><div id="39903470" class="c"><input type="checkbox" id="c-39903470" checked=""/><div class="controls bullet"><span class="by">perihelions</span><span>|</span><a href="#39903330">root</a><span>|</span><a href="#39903365">parent</a><span>|</span><a href="#39903442">next</a><span>|</span><label class="collapse" for="c-39903470">[-]</label><label class="expand" for="c-39903470">[1 more]</label></div><br/><div class="children"><div class="content">Or it would seriously hurt US and EU universities. Is Western dominance of scientific academics automatic? Did we acquire it for free—no; it&#x27;s the end-product of centuries of incremental cultural development, its openness and freedoms being core to that.<p>Imagine Google-founding era, except it was illegal for 1990&#x27;s Stanford to research CS theory without a license, so they didn&#x27;t. And later someone else founded it anyway, in a different country (which now became the world&#x27;s preeminent tech center).<p>Let&#x27;s put to a halt to these autoimmune attacks on our own civilization. This confusion that labels Western openness as a hazardous external substance.</div><br/></div></div><div id="39903442" class="c"><input type="checkbox" id="c-39903442" checked=""/><div class="controls bullet"><span class="by">skissane</span><span>|</span><a href="#39903330">root</a><span>|</span><a href="#39903365">parent</a><span>|</span><a href="#39903470">prev</a><span>|</span><a href="#39903397">next</a><span>|</span><label class="collapse" for="c-39903442">[-]</label><label class="expand" for="c-39903442">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure it would cause some harm, but exactly how much will depend on the details.<p>For example, suppose the US makes it illegal to publicly distribute open weight models (maybe above a certain size) without a government license. What happens if someone sets up a website to distribute those models outside of US jurisdiction? It may well prosecute Americans it can demonstrate have uploaded models to that website, but will it also ban Americans from downloading from it? If you go back to the encryption export controls, the US banned encryption software from being exported from the US, but (unlike some other countries like France) it never tried to ban encryption software imports. And, it sounds like they are only thinking about banning public&#x2F;&quot;open&quot; distribution, so once an institution downloads a model from outside the US, they may well be able to redistribute it internally without the ban applying.<p>Suppose the US bans distribution of open weight models above size N–how will that apply to fine-tunes? If you have LoRA on top of a model &gt;N, but the LoRA itself is &lt;N, does the ban apply to it? If the answer is &quot;no&quot;, people in the US could still contribute to openly distributing improvements to models that they couldn&#x27;t themselves openly distribute.</div><br/></div></div></div></div></div></div><div id="39903397" class="c"><input type="checkbox" id="c-39903397" checked=""/><div class="controls bullet"><span class="by">entrep</span><span>|</span><a href="#39903330">prev</a><span>|</span><a href="#39903606">next</a><span>|</span><label class="collapse" for="c-39903397">[-]</label><label class="expand" for="c-39903397">[1 more]</label></div><br/><div class="children"><div class="content">The author is a collaborator in OpenDevin [1], an attempt to replicate and improve Cognition Labs&#x27; Devin.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;OpenDevin">https:&#x2F;&#x2F;github.com&#x2F;OpenDevin</a></div><br/></div></div><div id="39903606" class="c"><input type="checkbox" id="c-39903606" checked=""/><div class="controls bullet"><span class="by">fullspectrumdev</span><span>|</span><a href="#39903397">prev</a><span>|</span><a href="#39902966">next</a><span>|</span><label class="collapse" for="c-39903606">[-]</label><label class="expand" for="c-39903606">[1 more]</label></div><br/><div class="children"><div class="content">I’m personally of the view that most AI safety people are delusional and irrationally terrified of progress.<p>I remain open to having my mind changed on this matter, but thus far, I’ve not seen a single good argument for restricting development of AI.</div><br/></div></div><div id="39902966" class="c"><input type="checkbox" id="c-39902966" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#39903606">prev</a><span>|</span><a href="#39902908">next</a><span>|</span><label class="collapse" for="c-39902966">[-]</label><label class="expand" for="c-39902966">[1 more]</label></div><br/><div class="children"><div class="content">Related ongoing thread:<p><i>OpenAI&#x27;s comment to the NTIA on open model weights</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39900197">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39900197</a> - April 2024 (41 comments)</div><br/></div></div><div id="39902908" class="c"><input type="checkbox" id="c-39902908" checked=""/><div class="controls bullet"><span class="by">zzzzzzzzzz10</span><span>|</span><a href="#39902966">prev</a><span>|</span><a href="#39902425">next</a><span>|</span><label class="collapse" for="c-39902908">[-]</label><label class="expand" for="c-39902908">[1 more]</label></div><br/><div class="children"><div class="content">Please ban them, it wont change a thing but drive us underground. I have backups of all relevant models as have many others.</div><br/></div></div><div id="39902425" class="c"><input type="checkbox" id="c-39902425" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#39902908">prev</a><span>|</span><a href="#39902941">next</a><span>|</span><label class="collapse" for="c-39902425">[-]</label><label class="expand" for="c-39902425">[13 more]</label></div><br/><div class="children"><div class="content">Is there any way to comment past the date? This seems like a horrible idea.</div><br/><div id="39902614" class="c"><input type="checkbox" id="c-39902614" checked=""/><div class="controls bullet"><span class="by">greenavocado</span><span>|</span><a href="#39902425">parent</a><span>|</span><a href="#39902504">next</a><span>|</span><label class="collapse" for="c-39902614">[-]</label><label class="expand" for="c-39902614">[10 more]</label></div><br/><div class="children"><div class="content">Open model weight bans will likely be struck down as First Amendment violations because, at their core, model weights are a form of expression. They embody the ideas, research, and innovations of their creators, similar to how code was deemed a form of speech protected under the First Amendment during the encryption debates of the 1990s. Just as the government&#x27;s attempts to control encryption software were challenged and largely curtailed due to free speech concerns, any attempts to ban open model weights will face legal challenges arguing that such bans unjustly restrict the free exchange of ideas and information, a cornerstone of First Amendment protections. The precedent set by cases involving code and free speech strongly suggests that similar principles apply to model weights, making such bans vulnerable to being overturned on constitutional grounds.</div><br/><div id="39903376" class="c"><input type="checkbox" id="c-39903376" checked=""/><div class="controls bullet"><span class="by">skissane</span><span>|</span><a href="#39902425">root</a><span>|</span><a href="#39902614">parent</a><span>|</span><a href="#39902657">next</a><span>|</span><label class="collapse" for="c-39903376">[-]</label><label class="expand" for="c-39903376">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Open model weight bans will likely be struck down as First Amendment violations because, at their core, model weights are a form of expression. They embody the ideas, research, and innovations of their creators, similar to how code was deemed a form of speech protected under the First Amendment during the encryption debates of the 1990s<p>I hope you are right, but I think there are some nuances here you aren&#x27;t considering.<p>Courts have ruled that code is protected under the 1st Amendment because it is something created by human beings, and expresses the ideas and style of its human authors. There is a clear analogy to literary works – which is also supported by the precedent of copyright law protecting computer source code on the grounds that it is a type of literary work – and literary works are a core part of the 1st Amendment&#x27;s scope as traditionally understood (even back to its original framers).<p>Whereas, model weights are just a bunch of numbers produced by an automated process. The legal argument that they should be protected by the 1st Amendment is much less clearcut. I would be happy if they were found to be so protected, but one ought to be careful to distinguish what one would like the law to be, from what it actually is.</div><br/></div></div><div id="39902657" class="c"><input type="checkbox" id="c-39902657" checked=""/><div class="controls bullet"><span class="by">vintermann</span><span>|</span><a href="#39902425">root</a><span>|</span><a href="#39902614">parent</a><span>|</span><a href="#39903376">prev</a><span>|</span><a href="#39902504">next</a><span>|</span><label class="collapse" for="c-39902657">[-]</label><label class="expand" for="c-39902657">[8 more]</label></div><br/><div class="children"><div class="content">That&#x27;s up to the whims of the US Supreme Court. They&#x27;re in the process of legalizing their own corruption right now. I don&#x27;t think you should take for granted that just because you have a solid and obvious argument, your rights will be protected by them.</div><br/><div id="39902680" class="c"><input type="checkbox" id="c-39902680" checked=""/><div class="controls bullet"><span class="by">greenavocado</span><span>|</span><a href="#39902425">root</a><span>|</span><a href="#39902657">parent</a><span>|</span><a href="#39902724">next</a><span>|</span><label class="collapse" for="c-39902680">[-]</label><label class="expand" for="c-39902680">[4 more]</label></div><br/><div class="children"><div class="content">If it makes you feel better the Supreme Court unanimously struck down a North Carolina law that prohibited registered sex offenders from accessing various websites, including social media platforms where children could become members. The Court held that the law imposed an unconstitutional restriction on lawful speech. Justice Kennedy, writing for the majority, noted that the law interfered with the fundamental principle that states may not suppress the freedom of speech on public streets, parks, and in other public spaces just because the expression occurs online. Packingham v. North Carolina (2017)</div><br/><div id="39902712" class="c"><input type="checkbox" id="c-39902712" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#39902425">root</a><span>|</span><a href="#39902680">parent</a><span>|</span><a href="#39902724">next</a><span>|</span><label class="collapse" for="c-39902712">[-]</label><label class="expand" for="c-39902712">[3 more]</label></div><br/><div class="children"><div class="content"><i>&gt; If it makes you feel better</i><p>It doesn&#x27;t. Pedophiles aren&#x27;t high up on the priorities of the Federalist Society or Heritage Foundation or whoever Thomas&#x27; latest sugar daddy is.</div><br/><div id="39902726" class="c"><input type="checkbox" id="c-39902726" checked=""/><div class="controls bullet"><span class="by">greenavocado</span><span>|</span><a href="#39902425">root</a><span>|</span><a href="#39902712">parent</a><span>|</span><a href="#39902724">next</a><span>|</span><label class="collapse" for="c-39902726">[-]</label><label class="expand" for="c-39902726">[2 more]</label></div><br/><div class="children"><div class="content">I know. These are the digital rights the Supreme Court is fighting for.</div><br/><div id="39902741" class="c"><input type="checkbox" id="c-39902741" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#39902425">root</a><span>|</span><a href="#39902726">parent</a><span>|</span><a href="#39902724">next</a><span>|</span><label class="collapse" for="c-39902741">[-]</label><label class="expand" for="c-39902741">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Fighting for&quot;? That&#x27;s laughable.<p>They&#x27;re going to flip the second one of their patrons is involved, regardless of precedent.</div><br/></div></div></div></div></div></div></div></div><div id="39902724" class="c"><input type="checkbox" id="c-39902724" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#39902425">root</a><span>|</span><a href="#39902657">parent</a><span>|</span><a href="#39902680">prev</a><span>|</span><a href="#39902504">next</a><span>|</span><label class="collapse" for="c-39902724">[-]</label><label class="expand" for="c-39902724">[3 more]</label></div><br/><div class="children"><div class="content">&gt; That&#x27;s up to the whims of the US Supreme Court.<p>The supreme court is certainly biased in favor of conservatives.<p>But conservatives these days are generally much more in favor of free speech and libertarian arguments than the people on the left.<p>So, for this specific issue, you should be happy that the supreme court is more conservative and willing to support free speech arguments.</div><br/><div id="39902799" class="c"><input type="checkbox" id="c-39902799" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#39902425">root</a><span>|</span><a href="#39902724">parent</a><span>|</span><a href="#39902504">next</a><span>|</span><label class="collapse" for="c-39902799">[-]</label><label class="expand" for="c-39902799">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Corruption doesn&#x27;t mean &quot;they do bad things&quot;. Instead it means that they are biased.<p>That&#x27;s totally wrong, it sounds almost like downplaying or excusing corruption (which is <i>inherently</i> a &quot;bad thing&quot; on its own) by comparing it to <i>just</i> having a bias.<p>Corruption is not just having a bias (towards &quot;people who give me bribes&quot;, if nothing else) but also acting upon that bias and mixing it up with a job that requires impartiality.<p>In contrast, merely having bias is nowhere near as bad, particularly since someone can be strongly biased and still recuse themselves.<p>When someone talks about &quot;corruption&quot; on the Supreme Court, it&#x27;s probably not hyperbole about bias, but a reference to hundreds of thousands of dollars in alleged bribes.</div><br/><div id="39902841" class="c"><input type="checkbox" id="c-39902841" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#39902425">root</a><span>|</span><a href="#39902799">parent</a><span>|</span><a href="#39902504">next</a><span>|</span><label class="collapse" for="c-39902841">[-]</label><label class="expand" for="c-39902841">[1 more]</label></div><br/><div class="children"><div class="content">Gotcha.  But in reference to the actual topic here, my point still stands, even given your caveat.<p>The people supporting open models are a much larger group than the minority who are trying to ban then.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39902504" class="c"><input type="checkbox" id="c-39902504" checked=""/><div class="controls bullet"><span class="by">thelittleone</span><span>|</span><a href="#39902425">parent</a><span>|</span><a href="#39902614">prev</a><span>|</span><a href="#39902586">next</a><span>|</span><label class="collapse" for="c-39902504">[-]</label><label class="expand" for="c-39902504">[1 more]</label></div><br/><div class="children"><div class="content">Beyond horrible. Beyond even dystopian films. Look at the evil mega corps and governments have shown with regards to privacy and freedoms. They&#x27;ve been eating away at it for years, one bite at a time, not too much to cause a revolt. Are we to depend upon the good intentions of mega corp owners and politicians to wield AGI exclusively and for the benefit of society when that same AGI will render any form of public organized protest impossible.</div><br/></div></div><div id="39902586" class="c"><input type="checkbox" id="c-39902586" checked=""/><div class="controls bullet"><span class="by">supriyo-biswas</span><span>|</span><a href="#39902425">parent</a><span>|</span><a href="#39902504">prev</a><span>|</span><a href="#39902941">next</a><span>|</span><label class="collapse" for="c-39902586">[-]</label><label class="expand" for="c-39902586">[1 more]</label></div><br/><div class="children"><div class="content">You can write to them anyway and also send a copy of the leyter to your representatives.<p>It still sends the message, and if many people send such letters, it will force them to reconsider.</div><br/></div></div></div></div><div id="39902941" class="c"><input type="checkbox" id="c-39902941" checked=""/><div class="controls bullet"><span class="by">injidup</span><span>|</span><a href="#39902425">prev</a><span>|</span><a href="#39902294">next</a><span>|</span><label class="collapse" for="c-39902941">[-]</label><label class="expand" for="c-39902941">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The biggest threats posed by AI come not from individuals, but from corporations and state-level actors.<p>Why is this statement assumed to be true? It is far from clear that advanced weapons in the hands of irresponsible, impulsive and ideological individuals cannot cause large scale chaos.<p>To build an egg requires the effort on the level of states or corporations but to break it requires just an individual motivated to do so.</div><br/><div id="39903126" class="c"><input type="checkbox" id="c-39903126" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#39902941">parent</a><span>|</span><a href="#39902294">next</a><span>|</span><label class="collapse" for="c-39903126">[-]</label><label class="expand" for="c-39903126">[2 more]</label></div><br/><div class="children"><div class="content">It works both ways with open models where _defence_ also advances in hands of majority.<p>With closed models and research only well funded entities participate (state actors and large corps).<p>If you want to draw parallels with advanced weapons, the difference is that weapon is also an antidote to itself.</div><br/><div id="39903325" class="c"><input type="checkbox" id="c-39903325" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39902941">root</a><span>|</span><a href="#39903126">parent</a><span>|</span><a href="#39902294">next</a><span>|</span><label class="collapse" for="c-39903325">[-]</label><label class="expand" for="c-39903325">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think open models offer any defence advantage whatsoever.<p>Compare nukes. You can&#x27;t stop a bad nuke with a good nuke. If I give you a nuke, the probability that you get nuked only goes up.<p>Afaict, nobody has even offered any explanation how open weights do anything to defend you from bad actors with LLMs.</div><br/></div></div></div></div></div></div><div id="39902294" class="c"><input type="checkbox" id="c-39902294" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#39902941">prev</a><span>|</span><a href="#39903041">next</a><span>|</span><label class="collapse" for="c-39902294">[-]</label><label class="expand" for="c-39902294">[5 more]</label></div><br/><div class="children"><div class="content">From the end of the article: &quot;If you agree, please send your comments to the DoC by March 27th, 2024.&quot;<p>Is there a reason why this executive order &#x2F; RFC received no coverage on HN (or anywhere else I&#x27;m aware of) until after the deadline had passed?</div><br/><div id="39902320" class="c"><input type="checkbox" id="c-39902320" checked=""/><div class="controls bullet"><span class="by">mcpherrinm</span><span>|</span><a href="#39902294">parent</a><span>|</span><a href="#39902608">next</a><span>|</span><label class="collapse" for="c-39902320">[-]</label><label class="expand" for="c-39902320">[2 more]</label></div><br/><div class="children"><div class="content">HN discussion was @ <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38067314">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38067314</a></div><br/><div id="39902400" class="c"><input type="checkbox" id="c-39902400" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#39902294">root</a><span>|</span><a href="#39902320">parent</a><span>|</span><a href="#39902608">next</a><span>|</span><label class="collapse" for="c-39902400">[-]</label><label class="expand" for="c-39902400">[1 more]</label></div><br/><div class="children"><div class="content">I remember that discussion about the original order, but I&#x27;m in the same boat as OP—this is the first I&#x27;m hearing about an RFC about open weights. It looks like it was discussed once, about a month ago [0], but I hadn&#x27;t seen any of the public comments show up on HN until today, even though they date back weeks.<p>[0] <i>NTIA Solicits Comments on Open-Weight AI Models</i> (57 points, 11 comments) <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39494760">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39494760</a></div><br/></div></div></div></div><div id="39902608" class="c"><input type="checkbox" id="c-39902608" checked=""/><div class="controls bullet"><span class="by">spiesd</span><span>|</span><a href="#39902294">parent</a><span>|</span><a href="#39902320">prev</a><span>|</span><a href="#39902637">next</a><span>|</span><label class="collapse" for="c-39902608">[-]</label><label class="expand" for="c-39902608">[1 more]</label></div><br/><div class="children"><div class="content">A few come to mind...<p>The executive order (and associated DoC&#x2F;NTIA RFC) was long, and dense with both legal references and political platitudes. Not great reading, (though the EO got a good amount of discussion here). It&#x27;s unfortunate, but less than surprising that it didn&#x27;t make actual news outlets.<p>It seems complicated now, and many would like to see how things play out a little more before committing the time to deciding things. (I think that&#x27;s a bad idea; regardless of the revolutionary tech, it seems wise to begin governmental thought early.)<p>It&#x27;s kinda been buried in an otherwise heavy news cycle since the end of October of last year, AI and otherwise. I assume that wasn&#x27;t intentional, but it seems hard to hide something so big at a better time.<p>And though I hate to say it, I suspect: apathy. Both traditional from the bottom (&quot;too far off, unfixable, can&#x27;t do anything about it&quot;), and from the top (&quot;once we get too big to fuck with, we just won&#x27;t give a damn about any changes they try to make anyway&quot;).</div><br/></div></div><div id="39902637" class="c"><input type="checkbox" id="c-39902637" checked=""/><div class="controls bullet"><span class="by">greenavocado</span><span>|</span><a href="#39902294">parent</a><span>|</span><a href="#39902608">prev</a><span>|</span><a href="#39903041">next</a><span>|</span><label class="collapse" for="c-39902637">[-]</label><label class="expand" for="c-39902637">[1 more]</label></div><br/><div class="children"><div class="content">A careless or reckless president might overly depend on advisers for drafting executive orders, sidelining personal oversight. This delegation risks orders that may not align with the president&#x27;s intent or could lead to adverse outcomes due to unchecked biases or agendas among advisers. Without the president&#x27;s close review, policies might lack comprehensive vetting, inviting legal issues, public disapproval, or impractical implementations. Excessive reliance on advisers could also push more extreme policies under reduced scrutiny. Effective governance requires the president&#x27;s informed engagement to ensure executive orders reflect their vision and serve the nation&#x27;s best interest. Instead we have someone who offers his &quot;concerns&quot; to the public while shipping billions worth of dollars of explosives to the enemies of humanity. Don&#x27;t expect any concerns or input from the public to make any difference.</div><br/></div></div></div></div><div id="39903041" class="c"><input type="checkbox" id="c-39903041" checked=""/><div class="controls bullet"><span class="by">MrYellowP</span><span>|</span><a href="#39902294">prev</a><span>|</span><a href="#39903120">next</a><span>|</span><label class="collapse" for="c-39903041">[-]</label><label class="expand" for="c-39903041">[1 more]</label></div><br/><div class="children"><div class="content">&gt; to prevent abuse.<p>People never grow tired of the ever-repeating excuses to further reduce our freedoms, or to hide criminality, or just insult the already lacking collective IQ.<p>Think of the children! We need to prevent abuse! Someone&#x27;s feelings might be hurt! Someone might get harmed! Seeing real breasts might cause trauma!<p>Or one that&#x27;s not so often used, but still really effective:<p>We&#x27;re just bulldozering this place, because it&#x27;s so horrible. Instead we turn it into a luxury resort for rich people. People who believe that it&#x27;s because we&#x27;re destroy any and all evidence are just conspiracy theorists. (in regards to Epstein&#x27;s Island)</div><br/></div></div><div id="39902888" class="c"><input type="checkbox" id="c-39902888" checked=""/><div class="controls bullet"><span class="by">rgmerk</span><span>|</span><a href="#39903120">prev</a><span>|</span><a href="#39902831">next</a><span>|</span><label class="collapse" for="c-39902888">[-]</label><label class="expand" for="c-39902888">[6 more]</label></div><br/><div class="children"><div class="content">Not saying this ban is a great idea...<p>...but there are plenty of useful things that we ban the general public from having access to.<p>Opium poppies.  Automatic weapons.  Gas centrifuges.<p>In fact, if you start publishing detailed designs for the last one you&#x27;re likely to have people in suits who only go by first names visiting you in pretty short order.</div><br/><div id="39902918" class="c"><input type="checkbox" id="c-39902918" checked=""/><div class="controls bullet"><span class="by">zzzzzzzzzz10</span><span>|</span><a href="#39902888">parent</a><span>|</span><a href="#39903233">next</a><span>|</span><label class="collapse" for="c-39902918">[-]</label><label class="expand" for="c-39902918">[4 more]</label></div><br/><div class="children"><div class="content">In what way are automatic weapons generally useful?</div><br/><div id="39902978" class="c"><input type="checkbox" id="c-39902978" checked=""/><div class="controls bullet"><span class="by">beau_g</span><span>|</span><a href="#39902888">root</a><span>|</span><a href="#39902918">parent</a><span>|</span><a href="#39903188">next</a><span>|</span><label class="collapse" for="c-39902978">[-]</label><label class="expand" for="c-39902978">[1 more]</label></div><br/><div class="children"><div class="content">Mostly suppressive fire, but more generally, providing a steady stream of small projectiles</div><br/></div></div><div id="39903188" class="c"><input type="checkbox" id="c-39903188" checked=""/><div class="controls bullet"><span class="by">rgmerk</span><span>|</span><a href="#39902888">root</a><span>|</span><a href="#39902918">parent</a><span>|</span><a href="#39902978">prev</a><span>|</span><a href="#39903034">next</a><span>|</span><label class="collapse" for="c-39903188">[-]</label><label class="expand" for="c-39903188">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re fighting a war, automatic weapons are a pretty much essential tool for doing so effectively.<p>Yeah, war is bad.  Sometimes the alternatives are worse.</div><br/></div></div><div id="39903034" class="c"><input type="checkbox" id="c-39903034" checked=""/><div class="controls bullet"><span class="by">moomoo11</span><span>|</span><a href="#39902888">root</a><span>|</span><a href="#39902918">parent</a><span>|</span><a href="#39903188">prev</a><span>|</span><a href="#39903233">next</a><span>|</span><label class="collapse" for="c-39903034">[-]</label><label class="expand" for="c-39903034">[1 more]</label></div><br/><div class="children"><div class="content">So you can type this comment with complete safety while being protected by tax dollars</div><br/></div></div></div></div><div id="39903233" class="c"><input type="checkbox" id="c-39903233" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#39902888">parent</a><span>|</span><a href="#39902918">prev</a><span>|</span><a href="#39902831">next</a><span>|</span><label class="collapse" for="c-39903233">[-]</label><label class="expand" for="c-39903233">[1 more]</label></div><br/><div class="children"><div class="content">Equivalent would be to ban not &quot;opium poppies&quot; but &quot;chemistry&quot;, not &quot;automatic weapons&quot; but &quot;automatic machines&quot; etc.<p>It&#x27;s more like trying to ban web or emails in one country because somebody can create harmful website or send harmful emails.<p>Sooner or later we will have to look at information through AI lenses. Before seeing anything it&#x27;ll go through filtering and transformation to weed out spam, misinformation and do fact checks etc.<p>You can&#x27;t build this defense future with crippled law.</div><br/></div></div></div></div><div id="39902831" class="c"><input type="checkbox" id="c-39902831" checked=""/><div class="controls bullet"><span class="by">patcon</span><span>|</span><a href="#39902888">prev</a><span>|</span><a href="#39903559">next</a><span>|</span><label class="collapse" for="c-39902831">[-]</label><label class="expand" for="c-39902831">[10 more]</label></div><br/><div class="children"><div class="content">I&#x27;m open to this. If an attempt to stop frontier models is to hold, banning open weights must be on the table. I&#x27;m excited about AI, but not entirely sure that it doesn&#x27;t call for the same strong regulation as nuclear proliferation did. It&#x27;s about kicking the brakes until culture catches up and absorbs impacts, not stopping<p>I&#x27;m just saying I&#x27;m open to it, and don&#x27;t want them to listen to accelerationists, but rather the ppl doing the deepest work with the edge models. Many of them are humbled and worried. Generalist AI enthusiasts wanting freedom to do any and all things with paradigm-shifting intelligence infra, I&#x27;m not swayed by that so much.</div><br/><div id="39902894" class="c"><input type="checkbox" id="c-39902894" checked=""/><div class="controls bullet"><span class="by">aerhardt</span><span>|</span><a href="#39902831">parent</a><span>|</span><a href="#39902950">next</a><span>|</span><label class="collapse" for="c-39902894">[-]</label><label class="expand" for="c-39902894">[2 more]</label></div><br/><div class="children"><div class="content">If LLMs warrant “the same strong regulation as nuclear proliferation”, but this is all about “kicking the brakes until culture catches up”, should we also now loosen nuclear arms regulations, now that society largely knows what’s up?<p>The more I use LLMs the more I’m convinced they’re harmless… The world’s not going to end because people at the margins are asking LLMs for recipes to manufacture cocaine… or a nuclear bomb.</div><br/><div id="39902964" class="c"><input type="checkbox" id="c-39902964" checked=""/><div class="controls bullet"><span class="by">Ekaros</span><span>|</span><a href="#39902831">root</a><span>|</span><a href="#39902894">parent</a><span>|</span><a href="#39902950">next</a><span>|</span><label class="collapse" for="c-39902964">[-]</label><label class="expand" for="c-39902964">[1 more]</label></div><br/><div class="children"><div class="content">I think LLMs are not a great danger. Ignorance is their use probably is, but that really makes no difference between some random model available that does answer and home trained one. The fault is on user. And nothing can stop people from being ignorant, lazy or just plain stupid.</div><br/></div></div></div></div><div id="39902950" class="c"><input type="checkbox" id="c-39902950" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#39902831">parent</a><span>|</span><a href="#39902894">prev</a><span>|</span><a href="#39903143">next</a><span>|</span><label class="collapse" for="c-39902950">[-]</label><label class="expand" for="c-39902950">[1 more]</label></div><br/><div class="children"><div class="content">There is an argument that banning things for law abiders essentially means giving criminals preferential access.<p>I don’t know that that idea always holds. But it definitely would for AI<p>All you need is ordinary commodity computing power to keep moving Ai forward. So vast numbers of individuals, organizations, and governmental actors will. Visibly or invisibly<p>Any blunt reactionary prohibition will only tilt things in favor of an unconstrained underground</div><br/></div></div><div id="39903143" class="c"><input type="checkbox" id="c-39903143" checked=""/><div class="controls bullet"><span class="by">impossiblefork</span><span>|</span><a href="#39902831">parent</a><span>|</span><a href="#39902950">prev</a><span>|</span><a href="#39903363">next</a><span>|</span><label class="collapse" for="c-39903143">[-]</label><label class="expand" for="c-39903143">[1 more]</label></div><br/><div class="children"><div class="content">But if open weights are banned the companies and the governments still have them and can engage in whatever manipulation etc., that they want.<p>Furthermore, it means that these entities can listen to everything being sent into the models.<p>If the model weights and training data are not published you can&#x27;t even try to determine whether the model is designed to manipulate you, because you don&#x27;t even have a fixed object to look at. If you find something weird about the model and start probing, they can just <i>change the model</i> to be less obvious.<p>This kind of thing: government or commercial manipulation of models is one of the main problems, and the ability to probe, fine-tune and and modify the models are what allows ordinary people to make them do what <i>they</i> want; and this is a free speech issue. LLMs are going to be critical for journalism, to sift through data, to sift through other people&#x27;s news and characterising it objectively, etc., and that requires absolute control of the model, which makes access to the weights absolutely necessary.<p>If there are restrictions on LLMs, then OpenAI, the diverse governments, the CIA, etc. must be subject to as severe restrictions as I am.</div><br/></div></div><div id="39903363" class="c"><input type="checkbox" id="c-39903363" checked=""/><div class="controls bullet"><span class="by">raxxorraxor</span><span>|</span><a href="#39902831">parent</a><span>|</span><a href="#39903143">prev</a><span>|</span><a href="#39903333">next</a><span>|</span><label class="collapse" for="c-39903363">[-]</label><label class="expand" for="c-39903363">[1 more]</label></div><br/><div class="children"><div class="content">I am less open to this. You mean listen to the people that try to implement the pretty well known idea of regulatory capture?<p>The abilities of LLMs are limited and there is reason to believe that this approach will hit a wall at some point where new strategies needs to be considered.<p>That said, luckily I believe it hard to put a lid on open weights again. A lid that would not solve any tangible problem anyway.</div><br/></div></div><div id="39903333" class="c"><input type="checkbox" id="c-39903333" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39902831">parent</a><span>|</span><a href="#39903363">prev</a><span>|</span><a href="#39903076">next</a><span>|</span><label class="collapse" for="c-39903333">[-]</label><label class="expand" for="c-39903333">[1 more]</label></div><br/><div class="children"><div class="content">I like open models, I use them myself. But I think from a safety view, we just need to stop all research advancing the AI frontier. And honestly, banning open weights is a pretty good way to do (at least some part of) that.<p>Yes, it would be a disaster. That&#x27;s the whole point. I think the field should be hit with a disaster, because it&#x27;s broadly harmful for the species.</div><br/></div></div><div id="39903076" class="c"><input type="checkbox" id="c-39903076" checked=""/><div class="controls bullet"><span class="by">ZaoLahma</span><span>|</span><a href="#39902831">parent</a><span>|</span><a href="#39903333">prev</a><span>|</span><a href="#39902970">next</a><span>|</span><label class="collapse" for="c-39903076">[-]</label><label class="expand" for="c-39903076">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s about kicking the brakes until culture catches up and absorbs impacts, not stopping<p>Which impacts are you referring to?</div><br/></div></div><div id="39902970" class="c"><input type="checkbox" id="c-39902970" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#39902831">parent</a><span>|</span><a href="#39903076">prev</a><span>|</span><a href="#39903559">next</a><span>|</span><label class="collapse" for="c-39902970">[-]</label><label class="expand" for="c-39902970">[2 more]</label></div><br/><div class="children"><div class="content">The largest AI models in the world fit on a hard-drive and can be torrented. What makes non-nuclear proliferation realistic is that it&#x27;s still relatively difficult and expensive to build a nuclear bomb. This model banning thing isn&#x27;t even worthy of debate given how trivial it is to distribute them.<p>&gt;Many of them are humbled and worried<p>Yes, because most of them like to imagine themselves as the next Oppenheimer rather than accepting that they&#x27;ve invented a lossy compressed version of Wikipedia. Chatbots aren&#x27;t nuclear bombs or &quot;paradigm shifting intelligence infra&quot;. I wonder how long it&#x27;ll take until the hysteria actually dies off.<p>It reminds me of a conversation with a Palantir guy who at least admitted that he likes it when the press writes a story that makes them look like a Bond villain because every time the stock price goes up. That&#x27;s why AI luminaries are &quot;worried&quot;.</div><br/><div id="39903137" class="c"><input type="checkbox" id="c-39903137" checked=""/><div class="controls bullet"><span class="by">autoexec</span><span>|</span><a href="#39902831">root</a><span>|</span><a href="#39902970">parent</a><span>|</span><a href="#39903559">next</a><span>|</span><label class="collapse" for="c-39903137">[-]</label><label class="expand" for="c-39903137">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Chatbots aren&#x27;t nuclear bombs or &quot;paradigm shifting intelligence infra&quot;. I wonder how long it&#x27;ll take until the hysteria actually dies off.<p>This is one reason why I want AI to be as free and accessible as possible as quickly as possible. People are going to assume that AI is nothing short of magic until they get a chance to play around with it themselves. The sooner people stop panicking about things AI currently isn&#x27;t and likely won&#x27;t be for a very long time (if ever), the better we can focus on preventing it from being used inappropriately.<p>I don&#x27;t think AI is going kill me in my sleep, or make us all unemployable, or brainwash me, but terrible AI could easily screw me over in all kinds of ways as companies and governments increasingly use it without oversight. AI replacing front line customer service&#x2F;support is bad enough but police, doctors, and HR departments will happily use it and mistakes humans would have prevented will be inevitable.</div><br/></div></div></div></div></div></div><div id="39903559" class="c"><input type="checkbox" id="c-39903559" checked=""/><div class="controls bullet"><span class="by">xzzulz</span><span>|</span><a href="#39902831">prev</a><span>|</span><label class="collapse" for="c-39903559">[-]</label><label class="expand" for="c-39903559">[1 more]</label></div><br/><div class="children"><div class="content">This tech is too risky. Could be dangerous.<p>In our current society, full of threats, it should not be open source. That would be crazy, in my opinion.<p>It should be managed, by government authorized organizations only. Kept exclusive in English culture.<p>How-to supervise the correct handling of this tech, is a very, very important topic. Specially for Gov, Universities, Corporations, and Technologists.</div><br/></div></div></div></div></div></div></div></body></html>