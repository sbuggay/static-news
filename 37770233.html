<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1696496489533" as="style"/><link rel="stylesheet" href="styles.css?v=1696496489533"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2310.02059">Security weaknesses of Copilot generated code in GitHub</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>belter</span> | <span>44 comments</span></div><br/><div><div id="37773494" class="c"><input type="checkbox" id="c-37773494" checked=""/><div class="controls bullet"><span class="by">faeriechangling</span><span>|</span><a href="#37775537">next</a><span>|</span><label class="collapse" for="c-37773494">[-]</label><label class="expand" for="c-37773494">[28 more]</label></div><br/><div class="children"><div class="content">If a weakness is common, then of course Copilot is going to suggest it.  Copilot gives you popular responses not correct ones.  Yet if a weakness is common, it also means that human coders frequently make the same mistake as well.<p>The studies results are rather unsurprising and its conclusions are oft-repeated advice.  As many have said, treat copilot’s code in the same light you would treat a junior programmer’s code.</div><br/><div id="37774252" class="c"><input type="checkbox" id="c-37774252" checked=""/><div class="controls bullet"><span class="by">crooked-v</span><span>|</span><a href="#37773494">parent</a><span>|</span><a href="#37773630">next</a><span>|</span><label class="collapse" for="c-37774252">[-]</label><label class="expand" for="c-37774252">[14 more]</label></div><br/><div class="children"><div class="content">&gt; Copilot gives you popular responses not correct ones.<p>That also sums up most of the issues with LLMs in general in one sentence.</div><br/><div id="37775533" class="c"><input type="checkbox" id="c-37775533" checked=""/><div class="controls bullet"><span class="by">steve1977</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774252">parent</a><span>|</span><a href="#37774707">next</a><span>|</span><label class="collapse" for="c-37775533">[-]</label><label class="expand" for="c-37775533">[8 more]</label></div><br/><div class="children"><div class="content">Which is why the term Artificial Intelligence is really a misnomer for LLMs. Artificial Mediocracy might be more fitting.</div><br/><div id="37775996" class="c"><input type="checkbox" id="c-37775996" checked=""/><div class="controls bullet"><span class="by">baz00</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37775533">parent</a><span>|</span><a href="#37775940">next</a><span>|</span><label class="collapse" for="c-37775996">[-]</label><label class="expand" for="c-37775996">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the most accurate term I&#x27;ve heard to describe the situation.  I think it could get worse though because when I&#x27;ve seen mediocre people work with mediocre people they generate sub-mediocre solutions through trying to be clever and failing spectacularly at it.</div><br/><div id="37776311" class="c"><input type="checkbox" id="c-37776311" checked=""/><div class="controls bullet"><span class="by">steve1977</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37775996">parent</a><span>|</span><a href="#37775940">next</a><span>|</span><label class="collapse" for="c-37776311">[-]</label><label class="expand" for="c-37776311">[1 more]</label></div><br/><div class="children"><div class="content">LLMs at the moment feel a bit like a buzwword-throwing dilbertian pointy haired boss. The use terms they heard somewhere and with some luck, they use them in the proper context... but without actually understanding them.<p>Edit: And yeah, I think I know what you mean. The expectation (or hope) that collaboration of mediocre people results in some above-average end by means of some magical synergy effect very rarely works in real life.</div><br/></div></div></div></div><div id="37775940" class="c"><input type="checkbox" id="c-37775940" checked=""/><div class="controls bullet"><span class="by">throwaway20304</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37775533">parent</a><span>|</span><a href="#37775996">prev</a><span>|</span><a href="#37774707">next</a><span>|</span><label class="collapse" for="c-37775940">[-]</label><label class="expand" for="c-37775940">[5 more]</label></div><br/><div class="children"><div class="content">Do you think people with IQ below 80 are not intelligent?</div><br/><div id="37776284" class="c"><input type="checkbox" id="c-37776284" checked=""/><div class="controls bullet"><span class="by">steve1977</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37775940">parent</a><span>|</span><a href="#37776177">next</a><span>|</span><label class="collapse" for="c-37776284">[-]</label><label class="expand" for="c-37776284">[1 more]</label></div><br/><div class="children"><div class="content">Technically they are. My comment was also meant to be a bit tongue-in-cheek of course (and, hopefully, obviously).<p>I wouldn&#x27;t use a score like IQ to define a treshold of &quot;intelligence&quot; in absolute terms. By definition, if you can score <i>somewhere</i> on the IQ scale, you have <i>some</i> intelligence. Otherwise your IQ would probably be N&#x2F;A? (not sure, never looked that deeply into IQ tests=.</div><br/></div></div><div id="37776177" class="c"><input type="checkbox" id="c-37776177" checked=""/><div class="controls bullet"><span class="by">oblio</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37775940">parent</a><span>|</span><a href="#37776284">prev</a><span>|</span><a href="#37774707">next</a><span>|</span><label class="collapse" for="c-37776177">[-]</label><label class="expand" for="c-37776177">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure about your angle here, but I thought IQ was calibrated to have 100 as the average value?<p>So wouldn&#x27;t 80 mean that someone is... kinda dumb?</div><br/><div id="37776297" class="c"><input type="checkbox" id="c-37776297" checked=""/><div class="controls bullet"><span class="by">steve1977</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37776177">parent</a><span>|</span><a href="#37776331">next</a><span>|</span><label class="collapse" for="c-37776297">[-]</label><label class="expand" for="c-37776297">[1 more]</label></div><br/><div class="children"><div class="content">I guess the problem is that the term &quot;intelligent&quot; is ambiguous and overloaded.<p>So in one usage someone who is kinda dumb would still be intelligent, just less intelligent than others.<p>In another usage, we use the term to describe someone of above average intelligence (which is technically not really correct and actually not very intelligent).</div><br/></div></div><div id="37776331" class="c"><input type="checkbox" id="c-37776331" checked=""/><div class="controls bullet"><span class="by">throwaway20304</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37776177">parent</a><span>|</span><a href="#37776297">prev</a><span>|</span><a href="#37774707">next</a><span>|</span><label class="collapse" for="c-37776331">[-]</label><label class="expand" for="c-37776331">[1 more]</label></div><br/><div class="children"><div class="content">Kinda dumb, but still intelligent. The sibling comment explains it well.</div><br/></div></div></div></div></div></div></div></div><div id="37774707" class="c"><input type="checkbox" id="c-37774707" checked=""/><div class="controls bullet"><span class="by">TheRoque</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774252">parent</a><span>|</span><a href="#37775533">prev</a><span>|</span><a href="#37774900">next</a><span>|</span><label class="collapse" for="c-37774707">[-]</label><label class="expand" for="c-37774707">[3 more]</label></div><br/><div class="children"><div class="content">Sums up the issues with democracy too, and a ton of other stuff</div><br/><div id="37775499" class="c"><input type="checkbox" id="c-37775499" checked=""/><div class="controls bullet"><span class="by">sambazi</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774707">parent</a><span>|</span><a href="#37775043">next</a><span>|</span><label class="collapse" for="c-37775499">[-]</label><label class="expand" for="c-37775499">[1 more]</label></div><br/><div class="children"><div class="content">educating the &quot;low-hanging fruit&quot; is much more effective in moving the average than piling on excellence.</div><br/></div></div></div></div><div id="37774900" class="c"><input type="checkbox" id="c-37774900" checked=""/><div class="controls bullet"><span class="by">baby</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774252">parent</a><span>|</span><a href="#37774707">prev</a><span>|</span><a href="#37775586">next</a><span>|</span><label class="collapse" for="c-37774900">[-]</label><label class="expand" for="c-37774900">[1 more]</label></div><br/><div class="children"><div class="content">With humans too</div><br/></div></div><div id="37775586" class="c"><input type="checkbox" id="c-37775586" checked=""/><div class="controls bullet"><span class="by">firtoz</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774252">parent</a><span>|</span><a href="#37774900">prev</a><span>|</span><a href="#37773630">next</a><span>|</span><label class="collapse" for="c-37775586">[-]</label><label class="expand" for="c-37775586">[1 more]</label></div><br/><div class="children"><div class="content">Evals do help to account for correctness when it comes to LLMs</div><br/></div></div></div></div><div id="37773630" class="c"><input type="checkbox" id="c-37773630" checked=""/><div class="controls bullet"><span class="by">pylua</span><span>|</span><a href="#37773494">parent</a><span>|</span><a href="#37774252">prev</a><span>|</span><a href="#37775609">next</a><span>|</span><label class="collapse" for="c-37773630">[-]</label><label class="expand" for="c-37773630">[6 more]</label></div><br/><div class="children"><div class="content">I wonder if llm are biased towards older, more insecure implementations because there is a higher volume of old code vs new code.<p>Same thing with the data it is trained on — not all code requires all levels of refinement. Most of the data is probably around average.</div><br/><div id="37773665" class="c"><input type="checkbox" id="c-37773665" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37773630">parent</a><span>|</span><a href="#37774494">next</a><span>|</span><label class="collapse" for="c-37773665">[-]</label><label class="expand" for="c-37773665">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure that code being newer inherently means it will be more secure</div><br/><div id="37773771" class="c"><input type="checkbox" id="c-37773771" checked=""/><div class="controls bullet"><span class="by">pylua</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37773665">parent</a><span>|</span><a href="#37774494">next</a><span>|</span><label class="collapse" for="c-37773771">[-]</label><label class="expand" for="c-37773771">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think it is a tautology , but I can imagine a cve scanner picking up older code with log4j where newer code may avoid that library altogether, just as an example.<p>Since there is more older code than newer code would the llm be suspectible to that ?</div><br/></div></div></div></div><div id="37774494" class="c"><input type="checkbox" id="c-37774494" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37773630">parent</a><span>|</span><a href="#37773665">prev</a><span>|</span><a href="#37774101">next</a><span>|</span><label class="collapse" for="c-37774494">[-]</label><label class="expand" for="c-37774494">[2 more]</label></div><br/><div class="children"><div class="content">This makes me wonder about training an LLM on one language and then fine tuning it for another. If you train over only, say, JavaScript, and then finetune for C, I imagine it will be quite bad at writing safe code, even if it makes the code look like C, because it didn&#x27;t have to learn about freeing and such.<p>Similarly, would it pick up patterns from one language and keep then in the other? Maybe an LLM trained on Kotlin would be more likely to write functional code finetuned.</div><br/><div id="37774551" class="c"><input type="checkbox" id="c-37774551" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774494">parent</a><span>|</span><a href="#37774101">next</a><span>|</span><label class="collapse" for="c-37774551">[-]</label><label class="expand" for="c-37774551">[1 more]</label></div><br/><div class="children"><div class="content">Given that dataset anomalies can result in LLM output corruption, I&#x27;m not convinced that cross-training like that would even work.</div><br/></div></div></div></div><div id="37774101" class="c"><input type="checkbox" id="c-37774101" checked=""/><div class="controls bullet"><span class="by">darkerside</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37773630">parent</a><span>|</span><a href="#37774494">prev</a><span>|</span><a href="#37775609">next</a><span>|</span><label class="collapse" for="c-37774101">[-]</label><label class="expand" for="c-37774101">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Most of the data is probably around average.<p>I know this is not how distributions work, but I had to chuckle at the literal interpretation of this.</div><br/></div></div></div></div><div id="37775609" class="c"><input type="checkbox" id="c-37775609" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#37773494">parent</a><span>|</span><a href="#37773630">prev</a><span>|</span><a href="#37774209">next</a><span>|</span><label class="collapse" for="c-37775609">[-]</label><label class="expand" for="c-37775609">[2 more]</label></div><br/><div class="children"><div class="content">A junior programmer&#x27;s code? This makes no sense. It&#x27;s happening right in front of you. A junior programmer isn&#x27;t going to write on my screen. I can just correct it right here I am currently holding the context in my head.<p>These &quot;security weakness&quot; examples are<p><pre><code>     print(&quot;first user registered, role set to admin&quot;, user, password)
</code></pre>
and<p><pre><code>     pprint({&quot;json&quot;:&quot;somejunk&quot;, &quot;classes&quot;: somefunc(user)})

</code></pre>
Nah, this stuff I can easily spot while I&#x27;m writing code. For a junior programmer, I&#x27;m going to be looking at design, and then at common specific mistakes. For Copilot it&#x27;s writing in front of me. I can easily exclude anything that isn&#x27;t obviously correct because I&#x27;m in the state right there.<p>It&#x27;s a fantastic tool. If you go and use it and end up with `print(user_credentials)` I don&#x27;t know what to tell you.</div><br/><div id="37775829" class="c"><input type="checkbox" id="c-37775829" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37775609">parent</a><span>|</span><a href="#37774209">next</a><span>|</span><label class="collapse" for="c-37775829">[-]</label><label class="expand" for="c-37775829">[1 more]</label></div><br/><div class="children"><div class="content">The added complication is now you&#x27;ll have to watch out for the junior+copilot combo, though it&#x27;s a trade I personally am very willing to take.</div><br/></div></div></div></div><div id="37774209" class="c"><input type="checkbox" id="c-37774209" checked=""/><div class="controls bullet"><span class="by">diogenes4</span><span>|</span><a href="#37773494">parent</a><span>|</span><a href="#37775609">prev</a><span>|</span><a href="#37775537">next</a><span>|</span><label class="collapse" for="c-37774209">[-]</label><label class="expand" for="c-37774209">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Yet if a weakness is common, it also means that human coders frequently make the same mistake as well.<p>It only means programmers commonly talk about it. This isn&#x27;t the same thing as measuring incidence in production or distribution.<p>Anyway, i&#x27;d argue the real question is &quot;can the chatbot fix the code if requested to&quot;.</div><br/><div id="37774469" class="c"><input type="checkbox" id="c-37774469" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774209">parent</a><span>|</span><a href="#37775537">next</a><span>|</span><label class="collapse" for="c-37774469">[-]</label><label class="expand" for="c-37774469">[4 more]</label></div><br/><div class="children"><div class="content">&gt; It only means programmers commonly talk about it. This isn&#x27;t the same thing as measuring incidence in production or distribution.<p>Copilot was primarily trained on GitHub projects, not on communication between programmers. Patterns that frequently show up in Copilot output are most likely prevalent on GitHub, which is a pretty good indicator that they&#x27;re common in production code.</div><br/><div id="37774598" class="c"><input type="checkbox" id="c-37774598" checked=""/><div class="controls bullet"><span class="by">prosim</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774469">parent</a><span>|</span><a href="#37775537">next</a><span>|</span><label class="collapse" for="c-37774598">[-]</label><label class="expand" for="c-37774598">[3 more]</label></div><br/><div class="children"><div class="content">That’s no longer true. Copilot uses the same ChatGPT-3.5 model as, well, ChatGPT. If it were trained on just GitHub projects, the chat features wouldn’t work at all.</div><br/><div id="37774774" class="c"><input type="checkbox" id="c-37774774" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774598">parent</a><span>|</span><a href="#37775537">next</a><span>|</span><label class="collapse" for="c-37774774">[-]</label><label class="expand" for="c-37774774">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re assuming that Copilot Chat and the regular completion are the same model. Do you have a source that says so? I&#x27;d assumed that they were two different models, since they&#x27;re quite different tasks.</div><br/><div id="37775106" class="c"><input type="checkbox" id="c-37775106" checked=""/><div class="controls bullet"><span class="by">prosim</span><span>|</span><a href="#37773494">root</a><span>|</span><a href="#37774774">parent</a><span>|</span><a href="#37775537">next</a><span>|</span><label class="collapse" for="c-37775106">[-]</label><label class="expand" for="c-37775106">[1 more]</label></div><br/><div class="children"><div class="content">Footnote 1 on page 2 explicitly mentions the 3.5 model and the research in this paper is only about auto completion: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2306.15033.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2306.15033.pdf</a><p>And this blog post states “beyond Codex”, again for auto completion: <a href="https:&#x2F;&#x2F;github.blog&#x2F;2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;github.blog&#x2F;2023-07-28-smarter-more-efficient-coding...</a><p>Lastly, OpenAI states on the original Codex page: “OpenAI Codex is a descendant of GPT-3; its training data contains both natural language and billions of lines of source code from publicly available sources, including code in public GitHub repositories.” - It included GitHub repos, but it never was <i>only</i> GitHub repos. <a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;openai-codex" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;openai-codex</a><p>Update: GitHub Community Manager confirms it here: <a href="https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;community&#x2F;discussions&#x2F;56975#discussioncomment-6086471">https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;community&#x2F;discussions&#x2F;56975#discussi...</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="37775537" class="c"><input type="checkbox" id="c-37775537" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#37773494">prev</a><span>|</span><a href="#37774197">next</a><span>|</span><label class="collapse" for="c-37775537">[-]</label><label class="expand" for="c-37775537">[3 more]</label></div><br/><div class="children"><div class="content">There&#x27;s only one weakness specifically identified that I can see.<p><pre><code>    print(&quot;new user&quot;, username, password)
</code></pre>
Yeah, not best practice, but also pretty common for development if you wanted to check that everything is being passed to the correct function.</div><br/><div id="37776319" class="c"><input type="checkbox" id="c-37776319" checked=""/><div class="controls bullet"><span class="by">jddj</span><span>|</span><a href="#37775537">parent</a><span>|</span><a href="#37776326">next</a><span>|</span><label class="collapse" for="c-37776319">[-]</label><label class="expand" for="c-37776319">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know if it still does it, but it used to be that if you did something like<p><pre><code>  NonQueryResult StoreUser(User user) {
   var sql = &quot;INSERT...

</code></pre>
It would use string interpolation to fill out the properties</div><br/></div></div><div id="37776326" class="c"><input type="checkbox" id="c-37776326" checked=""/><div class="controls bullet"><span class="by">dubbel</span><span>|</span><a href="#37775537">parent</a><span>|</span><a href="#37776319">prev</a><span>|</span><a href="#37774197">next</a><span>|</span><label class="collapse" for="c-37776326">[-]</label><label class="expand" for="c-37776326">[1 more]</label></div><br/><div class="children"><div class="content">That is the CWE that they identify, but the code seems to store the apparently unhashed password in the database on top of that?</div><br/></div></div></div></div><div id="37774197" class="c"><input type="checkbox" id="c-37774197" checked=""/><div class="controls bullet"><span class="by">calibas</span><span>|</span><a href="#37775537">prev</a><span>|</span><a href="#37770234">next</a><span>|</span><label class="collapse" for="c-37774197">[-]</label><label class="expand" for="c-37774197">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The results show that (1) 35.8% of Copilot generated code snippets contain CWEs<p>What percent of non-Copilot generated public GitHub repos contain CWEs?<p><i>Edit:</i> According to this study, Copilot generates C&#x2F;C++ code with vulnerabilities, but at a lower rate than your average human coder: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.04741.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.04741.pdf</a></div><br/></div></div><div id="37770234" class="c"><input type="checkbox" id="c-37770234" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#37774197">prev</a><span>|</span><a href="#37775099">next</a><span>|</span><label class="collapse" for="c-37770234">[-]</label><label class="expand" for="c-37770234">[1 more]</label></div><br/><div class="children"><div class="content">&quot;...The results show that (1) 35.8% of Copilot generated code snippets contain CWEs, and those issues are spread across multiple languages, (2) the security weaknesses are diverse and related to 42 different CWEs, in which CWE-78: OS Command Injection, CWE-330: Use of Insufficiently Random Values, and CWE-703: Improper Check or Handling of Exceptional Conditions occurred the most frequently, and (3) among the 42 CWEs identified, 11 of those belong to the currently recognized 2022 CWE Top-25. Our findings confirm that developers should be careful when adding code generated by Copilot (and similar AI code generation tools) and should also run appropriate security checks as they accept the suggested code...&quot;</div><br/></div></div><div id="37775099" class="c"><input type="checkbox" id="c-37775099" checked=""/><div class="controls bullet"><span class="by">laurent_du</span><span>|</span><a href="#37770234">prev</a><span>|</span><a href="#37774874">next</a><span>|</span><label class="collapse" for="c-37775099">[-]</label><label class="expand" for="c-37775099">[4 more]</label></div><br/><div class="children"><div class="content">I wonder if it would be possible to rate the code used during the training phase. For example the code could go through various static analysis tools and the result would be assigned as metadata to the code being used to train the model. The final model would then know that a given pattern is flagged as problematic by some tool and could take this into account not just to suggest new snippets but also to suggest improvements of existing snippets. Though I suppose if it was that easy, they&#x27;d have done it already.</div><br/><div id="37775257" class="c"><input type="checkbox" id="c-37775257" checked=""/><div class="controls bullet"><span class="by">jasfi</span><span>|</span><a href="#37775099">parent</a><span>|</span><a href="#37775263">next</a><span>|</span><label class="collapse" for="c-37775257">[-]</label><label class="expand" for="c-37775257">[1 more]</label></div><br/><div class="children"><div class="content">This is probably the next step for the LLM providers. They need to find ways to increase quality, and for code, there are many options. Perhaps code repos could get in on this too.</div><br/></div></div><div id="37775263" class="c"><input type="checkbox" id="c-37775263" checked=""/><div class="controls bullet"><span class="by">progval</span><span>|</span><a href="#37775099">parent</a><span>|</span><a href="#37775257">prev</a><span>|</span><a href="#37774874">next</a><span>|</span><label class="collapse" for="c-37775263">[-]</label><label class="expand" for="c-37775263">[2 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t this train it to avoid detection more than to avoid bad patterns?</div><br/><div id="37775403" class="c"><input type="checkbox" id="c-37775403" checked=""/><div class="controls bullet"><span class="by">ivancho</span><span>|</span><a href="#37775099">root</a><span>|</span><a href="#37775263">parent</a><span>|</span><a href="#37774874">next</a><span>|</span><label class="collapse" for="c-37775403">[-]</label><label class="expand" for="c-37775403">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but presumably in the training data those two are quite correlated.</div><br/></div></div></div></div></div></div><div id="37774874" class="c"><input type="checkbox" id="c-37774874" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#37775099">prev</a><span>|</span><a href="#37775887">next</a><span>|</span><label class="collapse" for="c-37774874">[-]</label><label class="expand" for="c-37774874">[1 more]</label></div><br/><div class="children"><div class="content">As always the statistic is useless without the human comparison. If it improves on human coders, no amount of gnashing and wailing will stop the layoffs.</div><br/></div></div><div id="37775887" class="c"><input type="checkbox" id="c-37775887" checked=""/><div class="controls bullet"><span class="by">azangru</span><span>|</span><a href="#37774874">prev</a><span>|</span><a href="#37772904">next</a><span>|</span><label class="collapse" for="c-37775887">[-]</label><label class="expand" for="c-37775887">[1 more]</label></div><br/><div class="children"><div class="content">This is where one needs a hyphen :-)</div><br/></div></div><div id="37772904" class="c"><input type="checkbox" id="c-37772904" checked=""/><div class="controls bullet"><span class="by">jncfhnb</span><span>|</span><a href="#37775887">prev</a><span>|</span><label class="collapse" for="c-37772904">[-]</label><label class="expand" for="c-37772904">[4 more]</label></div><br/><div class="children"><div class="content">Did they prompt it to consider security weaknesses?</div><br/><div id="37774556" class="c"><input type="checkbox" id="c-37774556" checked=""/><div class="controls bullet"><span class="by">prosim</span><span>|</span><a href="#37772904">parent</a><span>|</span><a href="#37774113">next</a><span>|</span><label class="collapse" for="c-37774556">[-]</label><label class="expand" for="c-37774556">[1 more]</label></div><br/><div class="children"><div class="content">They did not prompt at all. They used GitHub’s code search to find projects where the repo owner specified that the code was generated “by Copilot” and the authors took that at face value for all code in the project. Whether the code was actually suggested by Copilot is not at all analyzed in the paper. As such, the results are highly questionable.</div><br/></div></div><div id="37774113" class="c"><input type="checkbox" id="c-37774113" checked=""/><div class="controls bullet"><span class="by">OmarShehata</span><span>|</span><a href="#37772904">parent</a><span>|</span><a href="#37774556">prev</a><span>|</span><label class="collapse" for="c-37774113">[-]</label><label class="expand" for="c-37774113">[2 more]</label></div><br/><div class="children"><div class="content">That would be kind of wild. Imagine a world where whether your system was secure was just a matter of remembering to tell the AI agent &quot;&amp; also make it secure&quot; before it writes your code.<p>(could be quite real!)</div><br/><div id="37774231" class="c"><input type="checkbox" id="c-37774231" checked=""/><div class="controls bullet"><span class="by">Grimburger</span><span>|</span><a href="#37772904">root</a><span>|</span><a href="#37774113">parent</a><span>|</span><label class="collapse" for="c-37774231">[-]</label><label class="expand" for="c-37774231">[1 more]</label></div><br/><div class="children"><div class="content">&gt; also make it secure<p>[proceeds to simply refactor the same code]</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>