<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1734512460715" as="style"/><link rel="stylesheet" href="styles.css?v=1734512460715"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/langfuse/langfuse">Launch HN: Langfuse (YC W23) – OSS Tracing and Workflows to Improve LLM Apps</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>mdeichmann</span> | <span>54 comments</span></div><br/><div><div id="42444382" class="c"><input type="checkbox" id="c-42444382" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#42448860">next</a><span>|</span><label class="collapse" for="c-42444382">[-]</label><label class="expand" for="c-42444382">[2 more]</label></div><br/><div class="children"><div class="content">(unsolicited review) we&#x27;ve been happy adopters of LangFuse at AINews (<a href="https:&#x2F;&#x2F;smol.ai&#x2F;news" rel="nofollow">https:&#x2F;&#x2F;smol.ai&#x2F;news</a>). ive been tracking the llm ops landscape (<a href="https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;braintrust" rel="nofollow">https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;braintrust</a>) for a while and its very nice to have an open source solution that is so comprehensive and intuitive!<p>reflections&#x2F;thoughts on where this field goes next:<p>1. i wonder if there are new ops solutions for the realtime apis popping up<p>2. retries for instructor like structured outputs mess up the traces, i wonder if they can be tracked and collapsible<p>3. chatgpt canvas like &quot;drafting&quot; workflows are on the rise (<a href="https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;inference-fast-and-slow" rel="nofollow">https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;inference-fast-and-slow</a>) and again its noisy to see in a chat flow<p>4. how often do people actually use the feedback tagging and then subsequently finetuning? i always feel guilty that i dont do it yet and wonder when and where i should.</div><br/><div id="42444591" class="c"><input type="checkbox" id="c-42444591" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42444382">parent</a><span>|</span><a href="#42448860">next</a><span>|</span><label class="collapse" for="c-42444591">[-]</label><label class="expand" for="c-42444591">[1 more]</label></div><br/><div class="children"><div class="content">appreciate your constructive feedback!<p>&gt; i wonder if there are new ops solutions for the realtime apis popping up<p>This is something we have spent quite some time on already, both on designs internally and talking to teams using Langfuse with realtime applications. IMO the usage patterns are still developing and the data capturing&#x2F;visualization needs across teams is not aligned. What matters: (1) capture streams, (2) for non-text provide timestamped transcript&#x2F;labels, (3) capture the difference between user-time and api-level-time (e.g. when catching up on a stream after having categorized the input first).<p>We are excited to build support for this, if you or others have ideas or a wishlist, please add them to this thread: <a href="https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;langfuse&#x2F;discussions&#x2F;4757">https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;langfuse&#x2F;discussions&#x2F;4757</a><p>&gt; retries for instructor like structured outputs mess up the traces, i wonder if they can be tracked and collapsible<p>Great feedback. Being able to retroactively downrank llm calls to be `debug` level in order to collapse&#x2F;hide them by default would be interesting. Added thread for this here: <a href="https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;langfuse&#x2F;discussions&#x2F;4758">https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;langfuse&#x2F;discussions&#x2F;4758</a><p>&gt; chatgpt canvas like &quot;drafting&quot; workflows are on the rise (<a href="https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;inference-fast-and-slow" rel="nofollow">https:&#x2F;&#x2F;www.latent.space&#x2F;p&#x2F;inference-fast-and-slow</a>) and again its noisy to see in a chat flow<p>Can you share an example trace for this or open a thread on github? Would love to understand this in more detail as I have seen different trace-representations of it -- the best yet was a _git diff_ on a wrapper span for every iteration.<p>&gt; how often do people actually use the feedback tagging and then subsequently finetuning? i always feel guilty that i dont do it yet and wonder when and where i should.<p>Have not seen finetuning based on user-feedback a lot as the feedback can be noisy and low in frequency (unless there is a very clear feedback loop built into the product). More common workflow that I have seen: identify new problems via user feedback -&gt; review them manually -&gt; create llm-as-a-judge or other automated evals for this problem -&gt; select &quot;good&quot; examples for fine-tuning based on a mix of different evals that currently run on production data -&gt; sanitize the dataset (e.g. remove PII).<p>Finetuning has been more popular for structured output, sql generation (clear feedback loop &#x2F; retries at run-time if the output does not work). More teams fine-tune on all the output that has passed this initial run-time gate for model distillation without further quality controls on the training dataset. They usually then run evals on a test dataset in order to verify whether the fine-tuned hits their quality bar.</div><br/></div></div></div></div><div id="42448860" class="c"><input type="checkbox" id="c-42448860" checked=""/><div class="controls bullet"><span class="by">dcreater</span><span>|</span><a href="#42444382">prev</a><span>|</span><a href="#42443522">next</a><span>|</span><label class="collapse" for="c-42448860">[-]</label><label class="expand" for="c-42448860">[1 more]</label></div><br/><div class="children"><div class="content">Thread is filled with positive reviews.. Little odd</div><br/></div></div><div id="42443522" class="c"><input type="checkbox" id="c-42443522" checked=""/><div class="controls bullet"><span class="by">kappamax</span><span>|</span><a href="#42448860">prev</a><span>|</span><a href="#42445247">next</a><span>|</span><label class="collapse" for="c-42443522">[-]</label><label class="expand" for="c-42443522">[2 more]</label></div><br/><div class="children"><div class="content">Congrats Marc! We&#x27;ve been using Langfuse for about 6-months for our LLMOps tooling. While its SDKs are limited to python and typescript, their openapi specification is pretty easy to implement in any language.<p>The team behind it is amazing, and their product being OSS is one of the reasons we chose it. But it just keeps getting better.<p>We&#x27;re incidentally only using part of the product because we&#x27;ve implemented most of these new features, prompt caching, execution etc in our app. But with the API you can decide what parts are core to your business logic and outsource the parts you don&#x27;t want to deal with to Langfuse.<p>I appreciate that its not an opionated product.</div><br/><div id="42444426" class="c"><input type="checkbox" id="c-42444426" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42443522">parent</a><span>|</span><a href="#42445247">next</a><span>|</span><label class="collapse" for="c-42444426">[-]</label><label class="expand" for="c-42444426">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the feedback.<p>Being unopinionated and API-first has been a core design decision. We want to build the building blocks that everyone needs while acknowledging that most Langfuse users are very sophisticated teams that have a clear idea of what they want to achieve. Over time we will build more abstractions for common workflows to make it easier to get started but new features will always start API-first.<p>More on this here: <a href="https:&#x2F;&#x2F;langfuse.com&#x2F;why">https:&#x2F;&#x2F;langfuse.com&#x2F;why</a></div><br/></div></div></div></div><div id="42445247" class="c"><input type="checkbox" id="c-42445247" checked=""/><div class="controls bullet"><span class="by">lunarcave</span><span>|</span><a href="#42443522">prev</a><span>|</span><a href="#42442595">next</a><span>|</span><label class="collapse" for="c-42445247">[-]</label><label class="expand" for="c-42445247">[2 more]</label></div><br/><div class="children"><div class="content">A happy Langfuse customer here!<p>We&#x27;ve been building an agent platform and some of our customers wanted someway to exfil OTEL traces to their own setup. Initially we tried building our own but then realised Languse does exactly what we needed doing. So we offered it as a first class integration, (and started using it internally).<p>Great product, and hope you guys continue to improve it!</div><br/><div id="42445462" class="c"><input type="checkbox" id="c-42445462" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42445247">parent</a><span>|</span><a href="#42442595">next</a><span>|</span><label class="collapse" for="c-42445462">[-]</label><label class="expand" for="c-42445462">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! Really enjoyed working with you maintainers of other projects to help them offer more native LLM observability and evaluation to their users&#x2F;communities. There is a lot that goes into making the observability&#x2F;eval part scalable&#x2F;useful and requirements change on a weekly basis with new advancements. Same applies to other projects and it makes a lot of sense to integrate.<p>Overview of community integrations: <a href="https:&#x2F;&#x2F;langfuse.com&#x2F;docs&#x2F;integrations&#x2F;overview">https:&#x2F;&#x2F;langfuse.com&#x2F;docs&#x2F;integrations&#x2F;overview</a><p>Packages that depend on Langfuse: <a href="https:&#x2F;&#x2F;langfuse.com&#x2F;faq&#x2F;all&#x2F;packages-depending-on-langfuse">https:&#x2F;&#x2F;langfuse.com&#x2F;faq&#x2F;all&#x2F;packages-depending-on-langfuse</a></div><br/></div></div></div></div><div id="42442595" class="c"><input type="checkbox" id="c-42442595" checked=""/><div class="controls bullet"><span class="by">mfdupuis</span><span>|</span><a href="#42445247">prev</a><span>|</span><a href="#42443293">next</a><span>|</span><label class="collapse" for="c-42442595">[-]</label><label class="expand" for="c-42442595">[15 more]</label></div><br/><div class="children"><div class="content">This is actually one of the more interesting LLM observability platforms I&#x27;ve seen. Beyond addressing scaling issues, where do you see yourself going next?</div><br/><div id="42442702" class="c"><input type="checkbox" id="c-42442702" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42442595">parent</a><span>|</span><a href="#42442658">next</a><span>|</span><label class="collapse" for="c-42442702">[-]</label><label class="expand" for="c-42442702">[1 more]</label></div><br/><div class="children"><div class="content">Positioning&#x2F;roadmap differs between the different project in the space.<p>We summarized what we strongly believe in here: <a href="https:&#x2F;&#x2F;langfuse.com&#x2F;why">https:&#x2F;&#x2F;langfuse.com&#x2F;why</a>
Tldr: open apis, self-hostable, LLM&#x2F;cloud&#x2F;model&#x2F;framework-agnostic, API first, unopinionated building blocks for sophisticated teams, simple yet scalable instrumentation that is incrementally adoptable<p>Regarding roadmap, this is the near-term view: <a href="https:&#x2F;&#x2F;langfuse.com&#x2F;roadmap">https:&#x2F;&#x2F;langfuse.com&#x2F;roadmap</a><p>We work closely with the community, and the roadmap can change frequently based on feedback. GitHub Discussions is very active, so feel free to join the conversation if you want to suggest or contribute a feature: <a href="https:&#x2F;&#x2F;langfuse.com&#x2F;ideas">https:&#x2F;&#x2F;langfuse.com&#x2F;ideas</a></div><br/></div></div><div id="42442658" class="c"><input type="checkbox" id="c-42442658" checked=""/><div class="controls bullet"><span class="by">mathiasn</span><span>|</span><a href="#42442595">parent</a><span>|</span><a href="#42442702">prev</a><span>|</span><a href="#42443293">next</a><span>|</span><label class="collapse" for="c-42442658">[-]</label><label class="expand" for="c-42442658">[13 more]</label></div><br/><div class="children"><div class="content">What are other potential platforms?</div><br/><div id="42442945" class="c"><input type="checkbox" id="c-42442945" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42442658">parent</a><span>|</span><a href="#42443960">next</a><span>|</span><label class="collapse" for="c-42442945">[-]</label><label class="expand" for="c-42442945">[1 more]</label></div><br/><div class="children"><div class="content">This is a good long-list of projects, although it is not narrowly scoped to tracing&#x2F;evals&#x2F;prompt-management: <a href="https:&#x2F;&#x2F;github.com&#x2F;tensorchord&#x2F;Awesome-LLMOps?tab=readme-ov-file#llmops">https:&#x2F;&#x2F;github.com&#x2F;tensorchord&#x2F;Awesome-LLMOps?tab=readme-ov-...</a></div><br/></div></div><div id="42443960" class="c"><input type="checkbox" id="c-42443960" checked=""/><div class="controls bullet"><span class="by">suninsight</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42442658">parent</a><span>|</span><a href="#42442945">prev</a><span>|</span><a href="#42443504">next</a><span>|</span><label class="collapse" for="c-42443960">[-]</label><label class="expand" for="c-42443960">[9 more]</label></div><br/><div class="children"><div class="content">Bunch of them : Langsmith, Lunary, Phoenix Arize, Portkey, Datadog and Helicone.<p>We also picked Langfuse - more details here: <a href="https:&#x2F;&#x2F;www.nonbios.ai&#x2F;post&#x2F;the-nonbios-llm-observability-pick" rel="nofollow">https:&#x2F;&#x2F;www.nonbios.ai&#x2F;post&#x2F;the-nonbios-llm-observability-pi...</a></div><br/><div id="42444237" class="c"><input type="checkbox" id="c-42444237" checked=""/><div class="controls bullet"><span class="by">unnikrishnan_r</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42443960">parent</a><span>|</span><a href="#42444670">next</a><span>|</span><label class="collapse" for="c-42444237">[-]</label><label class="expand" for="c-42444237">[2 more]</label></div><br/><div class="children"><div class="content">Thanks, this post was insightful. I laughed at the reason why you rejected Arize Phoenix, I had similar thoughts while going through their site!=)<p>&gt; &quot;Another notable feature of Langfuse is the use of a model as a judge ... this is not enabled in the free version&#x2F;self-hosted version&quot;<p>I think you can add LLM-as-judge to the self-hosted version of Langfuse by defining your own evaluation pipeline: <a href="https:&#x2F;&#x2F;langfuse.com&#x2F;docs&#x2F;scores&#x2F;external-evaluation-pipelines">https:&#x2F;&#x2F;langfuse.com&#x2F;docs&#x2F;scores&#x2F;external-evaluation-pipelin...</a></div><br/><div id="42448499" class="c"><input type="checkbox" id="c-42448499" checked=""/><div class="controls bullet"><span class="by">suninsight</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42444237">parent</a><span>|</span><a href="#42444670">next</a><span>|</span><label class="collapse" for="c-42448499">[-]</label><label class="expand" for="c-42448499">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the pointer !<p>We are actually toying with building out a prompt evaluation platform and were considering extending langfuse. Maybe just use this instead.</div><br/></div></div></div></div><div id="42444670" class="c"><input type="checkbox" id="c-42444670" checked=""/><div class="controls bullet"><span class="by">barefeg</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42443960">parent</a><span>|</span><a href="#42444237">prev</a><span>|</span><a href="#42445576">next</a><span>|</span><label class="collapse" for="c-42444670">[-]</label><label class="expand" for="c-42444670">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing your blogpost. We had a similar journey. I installed and tried both Langfuse and Phoenix and ended up choosing Langfuse due to some versioning conflicts on the python dependency. I’m curious if your thoughts change after V3? I also liked that it only depended on Postgres but the scalable version requires other dependencies.<p>The thing I liked about Phoenix is that it uses OpenTelemetry. In the end we’re building our Agents SDK in a way that the observability platform can be swapped (<a href="https:&#x2F;&#x2F;github.com&#x2F;zetaalphavector&#x2F;platform&#x2F;tree&#x2F;master&#x2F;agents-sdk">https:&#x2F;&#x2F;github.com&#x2F;zetaalphavector&#x2F;platform&#x2F;tree&#x2F;master&#x2F;agen...</a>) and the abstraction is OpenTelemetry-inspired.</div><br/><div id="42445667" class="c"><input type="checkbox" id="c-42445667" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42444670">parent</a><span>|</span><a href="#42445576">next</a><span>|</span><label class="collapse" for="c-42445667">[-]</label><label class="expand" for="c-42445667">[1 more]</label></div><br/><div class="children"><div class="content">As you mentioned, this was a significant trade-off. We faced two choices:<p>(1) Stick with a single Docker container and Postgres. This option is simple to self-host, operate, and iterate on, but it suffers from poor performance at scale, especially for analytical queries that become crucial as the project grows. Additionally, as more features emerged, we needed a queue and benefited from caching and asynchronous processing, which required splitting into a second container and adding Redis. These features would have been blocked when going for this setup.<p>(2) Switch to a scalable setup with a robust infrastructure that enables us to develop features that interest the majority of our community. We have chosen this path and prioritized templates and Helm charts to simplify self-hosting. Please let us know if you have any questions or feedback as we transition to v3. We aim to make this process as easy as possible.<p>Regarding OTel, we are considering adding a collector to Langfuse as the OTel semantics are currently developing well. The needs of the Langfuse community are evolving rapidly, and starting with our own instrumentation has allowed us to move quickly while the semantic conventions were not developed. We are tracking this here and would greatly appreciate your feedback, upvotes, or any comments you have on this thread: <a href="https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;langfuse&#x2F;discussions&#x2F;2509">https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;langfuse&#x2F;discussions&#x2F;2509</a></div><br/></div></div></div></div><div id="42445576" class="c"><input type="checkbox" id="c-42445576" checked=""/><div class="controls bullet"><span class="by">skull8888888</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42443960">parent</a><span>|</span><a href="#42444670">prev</a><span>|</span><a href="#42443504">next</a><span>|</span><label class="collapse" for="c-42445576">[-]</label><label class="expand" for="c-42445576">[4 more]</label></div><br/><div class="children"><div class="content">We launched Laminar couple of months ago, <a href="https:&#x2F;&#x2F;www.lmnr.ai">https:&#x2F;&#x2F;www.lmnr.ai</a>. Extremely fast, great DX and written in Rust. Definitely worth a look.</div><br/><div id="42445699" class="c"><input type="checkbox" id="c-42445699" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42445576">parent</a><span>|</span><a href="#42443504">next</a><span>|</span><label class="collapse" for="c-42445699">[-]</label><label class="expand" for="c-42445699">[3 more]</label></div><br/><div class="children"><div class="content">Congrats on the Launch!</div><br/><div id="42445890" class="c"><input type="checkbox" id="c-42445890" checked=""/><div class="controls bullet"><span class="by">skull8888888</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42445699">parent</a><span>|</span><a href="#42445875">next</a><span>|</span><label class="collapse" for="c-42445890">[-]</label><label class="expand" for="c-42445890">[1 more]</label></div><br/><div class="children"><div class="content">apologies for hijacking your launch (congrats btw!)</div><br/></div></div><div id="42445875" class="c"><input type="checkbox" id="c-42445875" checked=""/><div class="controls bullet"><span class="by">skull8888888</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42445699">parent</a><span>|</span><a href="#42445890">prev</a><span>|</span><a href="#42443504">next</a><span>|</span><label class="collapse" for="c-42445875">[-]</label><label class="expand" for="c-42445875">[1 more]</label></div><br/><div class="children"><div class="content">thanks Marc :)</div><br/></div></div></div></div></div></div></div></div><div id="42443504" class="c"><input type="checkbox" id="c-42443504" checked=""/><div class="controls bullet"><span class="by">calebkaiser</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42442658">parent</a><span>|</span><a href="#42443960">prev</a><span>|</span><a href="#42445674">next</a><span>|</span><label class="collapse" for="c-42443504">[-]</label><label class="expand" for="c-42443504">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a maintainer of Opik, an open source LLM evaluation and observability platform. We only launched a few months ago, but we&#x27;re growing rapidly: <a href="https:&#x2F;&#x2F;github.com&#x2F;comet-ml&#x2F;opik">https:&#x2F;&#x2F;github.com&#x2F;comet-ml&#x2F;opik</a></div><br/></div></div><div id="42445674" class="c"><input type="checkbox" id="c-42445674" checked=""/><div class="controls bullet"><span class="by">resiros</span><span>|</span><a href="#42442595">root</a><span>|</span><a href="#42442658">parent</a><span>|</span><a href="#42443504">prev</a><span>|</span><a href="#42443293">next</a><span>|</span><label class="collapse" for="c-42445674">[-]</label><label class="expand" for="c-42445674">[1 more]</label></div><br/><div class="children"><div class="content">One missing in the list below is Agenta (<a href="https:&#x2F;&#x2F;github.com&#x2F;agenta-ai&#x2F;agenta">https:&#x2F;&#x2F;github.com&#x2F;agenta-ai&#x2F;agenta</a>).<p>We&#x27;re oss, otel compliant with stronger focus on evals and the enabling collaboration between subject matter experts and devs.</div><br/></div></div></div></div></div></div><div id="42443293" class="c"><input type="checkbox" id="c-42443293" checked=""/><div class="controls bullet"><span class="by">ddtaylor</span><span>|</span><a href="#42442595">prev</a><span>|</span><a href="#42443806">next</a><span>|</span><label class="collapse" for="c-42443293">[-]</label><label class="expand" for="c-42443293">[1 more]</label></div><br/><div class="children"><div class="content">You guys just saved me a lot of trouble. Amazing work everyone wow.</div><br/></div></div><div id="42443806" class="c"><input type="checkbox" id="c-42443806" checked=""/><div class="controls bullet"><span class="by">tmshapland</span><span>|</span><a href="#42443293">prev</a><span>|</span><a href="#42442774">next</a><span>|</span><label class="collapse" for="c-42443806">[-]</label><label class="expand" for="c-42443806">[2 more]</label></div><br/><div class="children"><div class="content">Seems like Langfuse is becoming the standard. Whenever I talk to other builders, they&#x27;re using Langfuse.</div><br/><div id="42444002" class="c"><input type="checkbox" id="c-42444002" checked=""/><div class="controls bullet"><span class="by">mdeichmann</span><span>|</span><a href="#42443806">parent</a><span>|</span><a href="#42442774">next</a><span>|</span><label class="collapse" for="c-42444002">[-]</label><label class="expand" for="c-42444002">[1 more]</label></div><br/><div class="children"><div class="content">Thank you! If these builders have some feedback to share, ask them to reach out to us :)</div><br/></div></div></div></div><div id="42442774" class="c"><input type="checkbox" id="c-42442774" checked=""/><div class="controls bullet"><span class="by">extr</span><span>|</span><a href="#42443806">prev</a><span>|</span><a href="#42445277">next</a><span>|</span><label class="collapse" for="c-42442774">[-]</label><label class="expand" for="c-42442774">[2 more]</label></div><br/><div class="children"><div class="content">Very timely post&#x2F;update, was just checking out your product. IMO it is one of the best solutions I&#x27;ve looked at. Appreciate your dedication to self hosting, for us it&#x27;s not really practical to have traces with potentially sensitive customer data sitting around on some external company&#x27;s server somewhere (no offense).</div><br/><div id="42442887" class="c"><input type="checkbox" id="c-42442887" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42442774">parent</a><span>|</span><a href="#42445277">next</a><span>|</span><label class="collapse" for="c-42442887">[-]</label><label class="expand" for="c-42442887">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for the kind words! Let us know if you have any questions or feedback regarding the self-hosting documentation and experience. We collaborate with many teams that have diverse security needs, including HIPAA, PCI, and on-premises deployments on bare metal without internet access.</div><br/></div></div></div></div><div id="42445277" class="c"><input type="checkbox" id="c-42445277" checked=""/><div class="controls bullet"><span class="by">punkpeye</span><span>|</span><a href="#42442774">prev</a><span>|</span><a href="#42444558">next</a><span>|</span><label class="collapse" for="c-42445277">[-]</label><label class="expand" for="c-42445277">[1 more]</label></div><br/><div class="children"><div class="content">Been using it. Happy customer. It gave me sanity into otherwise very complex LLM infrastructure. We spend 60k+ every month on LLM calls, so having the backbone to debug when things go haywire has helped a lot.</div><br/></div></div><div id="42444558" class="c"><input type="checkbox" id="c-42444558" checked=""/><div class="controls bullet"><span class="by">robrenaud</span><span>|</span><a href="#42445277">prev</a><span>|</span><a href="#42444280">next</a><span>|</span><label class="collapse" for="c-42444558">[-]</label><label class="expand" for="c-42444558">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using self hosted langfuse via litellm in a juptyer notebook for a few weeks for some synthetic data experiments. It&#x27;s been a nice&#x2F;useful tool.<p>I&#x27;ve liked having the traces and scores in a unified browser based UI, it made sanity checking experiments way easier than doing the same thing inside the notebook.<p>The trace&#x2F;generation retrieval API was brutally slow for bulk scanning operations, so I bypassed it and just queried the db directly.  But the is the beauty of open source&#x2F;self hosted code.</div><br/><div id="42444637" class="c"><input type="checkbox" id="c-42444637" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42444558">parent</a><span>|</span><a href="#42444280">next</a><span>|</span><label class="collapse" for="c-42444637">[-]</label><label class="expand" for="c-42444637">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the feedback, glad that you find Langfuse useful!<p>Can you create an issue with more details on the API performance problems? We monitor strict SLOs on the public API for Langfuse Cloud and are not aware of any ongoing issues, would love to learn more.</div><br/></div></div></div></div><div id="42444280" class="c"><input type="checkbox" id="c-42444280" checked=""/><div class="controls bullet"><span class="by">arjunram77</span><span>|</span><a href="#42444558">prev</a><span>|</span><a href="#42444268">next</a><span>|</span><label class="collapse" for="c-42444280">[-]</label><label class="expand" for="c-42444280">[2 more]</label></div><br/><div class="children"><div class="content">Congratulations @Marc. Been using this product for 5ish months, love the iteration and how the team reacts to feedback. The prompt versioning has been immensely valuable!</div><br/><div id="42444405" class="c"><input type="checkbox" id="c-42444405" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42444280">parent</a><span>|</span><a href="#42444268">next</a><span>|</span><label class="collapse" for="c-42444405">[-]</label><label class="expand" for="c-42444405">[1 more]</label></div><br/><div class="children"><div class="content">Thanks AJ, feedback on GitHub&#x2F;Discord (like yours) has been very helpful to evolve prompt management from a quick addition of the core platform to one of the most-used features -- for which we then actually needed to change a lot of infrastructure to make it reliable and fast (see blog post linked in the original post)</div><br/></div></div></div></div><div id="42444268" class="c"><input type="checkbox" id="c-42444268" checked=""/><div class="controls bullet"><span class="by">TripleChecker</span><span>|</span><a href="#42444280">prev</a><span>|</span><a href="#42443362">next</a><span>|</span><label class="collapse" for="c-42444268">[-]</label><label class="expand" for="c-42444268">[1 more]</label></div><br/><div class="children"><div class="content">Looks cool! I’d love to see a simple embedding&#x2F;sharing tool for an LLM playground to share with the non-tech team so they can try it. Is that something Langfuse could do?<p>Also, some typos you want to review on the site: <a href="https:&#x2F;&#x2F;triplechecker.com&#x2F;s&#x2F;655511&#x2F;langfuse.com" rel="nofollow">https:&#x2F;&#x2F;triplechecker.com&#x2F;s&#x2F;655511&#x2F;langfuse.com</a></div><br/></div></div><div id="42443362" class="c"><input type="checkbox" id="c-42443362" checked=""/><div class="controls bullet"><span class="by">lvkleist</span><span>|</span><a href="#42444268">prev</a><span>|</span><a href="#42444159">next</a><span>|</span><label class="collapse" for="c-42443362">[-]</label><label class="expand" for="c-42443362">[2 more]</label></div><br/><div class="children"><div class="content">Have been a very happy Langfuse user since March - dead simple to use and has helped us a lot with LLM observability and debugging - great work guys :))</div><br/><div id="42444659" class="c"><input type="checkbox" id="c-42444659" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42443362">parent</a><span>|</span><a href="#42444159">next</a><span>|</span><label class="collapse" for="c-42444659">[-]</label><label class="expand" for="c-42444659">[1 more]</label></div><br/><div class="children"><div class="content">thank you! if you have any ideas for improvements after having used Langfuse for a while, please contribute them via github discussions: <a href="https:&#x2F;&#x2F;langfuse.com&#x2F;ideas">https:&#x2F;&#x2F;langfuse.com&#x2F;ideas</a></div><br/></div></div></div></div><div id="42444159" class="c"><input type="checkbox" id="c-42444159" checked=""/><div class="controls bullet"><span class="by">david1542</span><span>|</span><a href="#42443362">prev</a><span>|</span><a href="#42442995">next</a><span>|</span><label class="collapse" for="c-42444159">[-]</label><label class="expand" for="c-42444159">[1 more]</label></div><br/><div class="children"><div class="content">Looks awesome! Been using for over a year now and it&#x27;s a great product :) The new improvements seems exciting.</div><br/></div></div><div id="42442995" class="c"><input type="checkbox" id="c-42442995" checked=""/><div class="controls bullet"><span class="by">jondwillis</span><span>|</span><a href="#42444159">prev</a><span>|</span><a href="#42446881">next</a><span>|</span><label class="collapse" for="c-42442995">[-]</label><label class="expand" for="c-42442995">[2 more]</label></div><br/><div class="children"><div class="content">I promise this isn’t astroturfing ;)<p>I happened to have been triaging LLM observability, dataset, and eval solutions yesterday at the day job, and congratulations, Langfuse was the second solution that I tried, and  simple enough to get set up locally with my existing stack for me to stop looking (ye olde time constraints, and I know good-enough when I see it!)<p>Thanks for your and your team’s work.</div><br/><div id="42443076" class="c"><input type="checkbox" id="c-42443076" checked=""/><div class="controls bullet"><span class="by">clemo_ra</span><span>|</span><a href="#42442995">parent</a><span>|</span><a href="#42446881">next</a><span>|</span><label class="collapse" for="c-42443076">[-]</label><label class="expand" for="c-42443076">[1 more]</label></div><br/><div class="children"><div class="content">thank you, that is genuinely nice to hear and motivating for our team.<p>we&#x27;re available if you ever run into any issues (github, email etc.)</div><br/></div></div></div></div><div id="42446881" class="c"><input type="checkbox" id="c-42446881" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#42442995">prev</a><span>|</span><a href="#42444656">next</a><span>|</span><label class="collapse" for="c-42446881">[-]</label><label class="expand" for="c-42446881">[2 more]</label></div><br/><div class="children"><div class="content">Been using Langfuse OSS for almost 15 months from the start. By far the best solution. No dark patterns found in other projects such as Portkey.</div><br/><div id="42446988" class="c"><input type="checkbox" id="c-42446988" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42446881">parent</a><span>|</span><a href="#42444656">next</a><span>|</span><label class="collapse" for="c-42446988">[-]</label><label class="expand" for="c-42446988">[1 more]</label></div><br/><div class="children"><div class="content">All core features are fully open-source and identical to those in Langfuse Cloud, with no limitations on capabilities or scalability (e.g. all v3 infrastructure changes).<p>We also offer some optional commercial add-on features that can help iterate faster or support very large teams using Langfuse. However, these features are entirely optional and we do our best to be transparent about this across our docs.</div><br/></div></div></div></div><div id="42444656" class="c"><input type="checkbox" id="c-42444656" checked=""/><div class="controls bullet"><span class="by">bewestphal</span><span>|</span><a href="#42446881">prev</a><span>|</span><a href="#42447538">next</a><span>|</span><label class="collapse" for="c-42444656">[-]</label><label class="expand" for="c-42444656">[2 more]</label></div><br/><div class="children"><div class="content">Congrats on the launch :) happy users @ Samsara.<p>Key to our LLM customer feedback flywheel and dataset building.</div><br/><div id="42444722" class="c"><input type="checkbox" id="c-42444722" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42444656">parent</a><span>|</span><a href="#42447538">next</a><span>|</span><label class="collapse" for="c-42444722">[-]</label><label class="expand" for="c-42444722">[1 more]</label></div><br/><div class="children"><div class="content">Thank you! Working with your team has been great. I love seeing you ship LLM-powered features and appreciate the feedback you have shared along the way.</div><br/></div></div></div></div><div id="42447538" class="c"><input type="checkbox" id="c-42447538" checked=""/><div class="controls bullet"><span class="by">fiehtle</span><span>|</span><a href="#42444656">prev</a><span>|</span><a href="#42442453">next</a><span>|</span><label class="collapse" for="c-42447538">[-]</label><label class="expand" for="c-42447538">[2 more]</label></div><br/><div class="children"><div class="content">great to see how you guys worked with the community on discord over the last year to build Langfuse</div><br/><div id="42447648" class="c"><input type="checkbox" id="c-42447648" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42447538">parent</a><span>|</span><a href="#42442453">next</a><span>|</span><label class="collapse" for="c-42447648">[-]</label><label class="expand" for="c-42447648">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! IMO, Discord is good, but GitHub Discussions is the better option for building a growing open-source community. It is indexed and makes it easier to revisit conversations weeks later. Currently we use both but have a strong preference for GitHub Discussions.</div><br/></div></div></div></div><div id="42442453" class="c"><input type="checkbox" id="c-42442453" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#42447538">prev</a><span>|</span><a href="#42443982">next</a><span>|</span><label class="collapse" for="c-42442453">[-]</label><label class="expand" for="c-42442453">[4 more]</label></div><br/><div class="children"><div class="content">In this example:<p><pre><code>    from langfuse.openai import openai # OpenAI integration
</code></pre>
Why do I need to import openai from langfuse?</div><br/><div id="42442532" class="c"><input type="checkbox" id="c-42442532" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42442453">parent</a><span>|</span><a href="#42442608">next</a><span>|</span><label class="collapse" for="c-42442532">[-]</label><label class="expand" for="c-42442532">[1 more]</label></div><br/><div class="children"><div class="content">This is an optional instrumentation of the OpenAI SDK which simplifies getting started, tracking token counts, model parameters and streaming latencies.<p>Langfuse is not in the critical path, this just helps with instrumentation.<p>You can use the Langfuse Python SDK &#x2F; Decorator to track any LLM (with some instrumentation code) or use one of the framework integrations.<p>Here is a fully-featured example using the Amazon Bedrock SDK: <a href="https:&#x2F;&#x2F;langfuse.com&#x2F;docs&#x2F;integrations&#x2F;amazon-bedrock">https:&#x2F;&#x2F;langfuse.com&#x2F;docs&#x2F;integrations&#x2F;amazon-bedrock</a></div><br/></div></div><div id="42442608" class="c"><input type="checkbox" id="c-42442608" checked=""/><div class="controls bullet"><span class="by">priompteng</span><span>|</span><a href="#42442453">parent</a><span>|</span><a href="#42442532">prev</a><span>|</span><a href="#42443982">next</a><span>|</span><label class="collapse" for="c-42442608">[-]</label><label class="expand" for="c-42442608">[2 more]</label></div><br/><div class="children"><div class="content">Nice work but, Sorry but I don’t feel comfortable either proxying my llm calls through a 3rd party unless the 3rd party is a llm gateway like litellm or arch or storing my prompts in a SaaS. For tracing, I use OTEL libraries which is more than sufficient for my use case.</div><br/><div id="42442739" class="c"><input type="checkbox" id="c-42442739" checked=""/><div class="controls bullet"><span class="by">marcklingen</span><span>|</span><a href="#42442453">root</a><span>|</span><a href="#42442608">parent</a><span>|</span><a href="#42443982">next</a><span>|</span><label class="collapse" for="c-42442739">[-]</label><label class="expand" for="c-42442739">[1 more]</label></div><br/><div class="children"><div class="content">If you use an OSS Gateway already, some (e.g. LiteLLM) can natively forward logs to Langfuse: <a href="https:&#x2F;&#x2F;docs.litellm.ai&#x2F;docs&#x2F;proxy&#x2F;logging#langfuse" rel="nofollow">https:&#x2F;&#x2F;docs.litellm.ai&#x2F;docs&#x2F;proxy&#x2F;logging#langfuse</a><p>We are looking into adding an Otel Collector as OTel-semantics are maturing around LLMs. For now many features that are key to LLMOPs are difficult to make work with OTel instrumentation as the space is moving quickly. Main thread on this is here: <a href="https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;langfuse&#x2F;discussions&#x2F;2509">https:&#x2F;&#x2F;github.com&#x2F;orgs&#x2F;langfuse&#x2F;discussions&#x2F;2509</a></div><br/></div></div></div></div></div></div><div id="42443982" class="c"><input type="checkbox" id="c-42443982" checked=""/><div class="controls bullet"><span class="by">aantti</span><span>|</span><a href="#42442453">prev</a><span>|</span><a href="#42445115">next</a><span>|</span><label class="collapse" for="c-42443982">[-]</label><label class="expand" for="c-42443982">[1 more]</label></div><br/><div class="children"><div class="content">great product &amp; great team, kudos &amp; congrats! :)</div><br/></div></div><div id="42445115" class="c"><input type="checkbox" id="c-42445115" checked=""/><div class="controls bullet"><span class="by">krb0</span><span>|</span><a href="#42443982">prev</a><span>|</span><a href="#42443869">next</a><span>|</span><label class="collapse" for="c-42445115">[-]</label><label class="expand" for="c-42445115">[1 more]</label></div><br/><div class="children"><div class="content">Great work! Easy to integrate :)</div><br/></div></div><div id="42443869" class="c"><input type="checkbox" id="c-42443869" checked=""/><div class="controls bullet"><span class="by">sebselassie</span><span>|</span><a href="#42445115">prev</a><span>|</span><a href="#42442684">next</a><span>|</span><label class="collapse" for="c-42443869">[-]</label><label class="expand" for="c-42443869">[1 more]</label></div><br/><div class="children"><div class="content">great product, so easy to use. love it.</div><br/></div></div><div id="42442684" class="c"><input type="checkbox" id="c-42442684" checked=""/><div class="controls bullet"><span class="by">matthewolfe</span><span>|</span><a href="#42443869">prev</a><span>|</span><a href="#42442898">next</a><span>|</span><label class="collapse" for="c-42442684">[-]</label><label class="expand" for="c-42442684">[1 more]</label></div><br/><div class="children"><div class="content">Great work, guys!</div><br/></div></div><div id="42442898" class="c"><input type="checkbox" id="c-42442898" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#42442684">prev</a><span>|</span><label class="collapse" for="c-42442898">[-]</label><label class="expand" for="c-42442898">[1 more]</label></div><br/><div class="children"><div class="content">&gt; YC
&gt; OSS<p>Nice try</div><br/></div></div></div></div></div></div></div></body></html>