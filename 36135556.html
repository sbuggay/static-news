<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1685523667010" as="style"/><link rel="stylesheet" href="styles.css?v=1685523667010"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://skiff.com/blog/was-bard-trained-on-gmail-data">Why won’t Google give an answer on whether Bard was trained on Gmail data?</a> <span class="domain">(<a href="https://skiff.com">skiff.com</a>)</span></div><div class="subtext"><span>digitalrealme</span> | <span>24 comments</span></div><br/><div><div id="36135951" class="c"><input type="checkbox" id="c-36135951" checked=""/><div class="controls bullet"><span class="by">delroth</span><span>|</span><a href="#36136013">next</a><span>|</span><label class="collapse" for="c-36135951">[-]</label><label class="expand" for="c-36135951">[10 more]</label></div><br/><div class="children"><div class="content">The article decides to mention that Google made a public statement that clearly and unambiguously answers their question (<a href="https:&#x2F;&#x2F;twitter.com&#x2F;GoogleWorkspace&#x2F;status&#x2F;1638298537195601920" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;GoogleWorkspace&#x2F;status&#x2F;16382985371956019...</a>) and then proceeds to ignore it completely in favor of conspiracy theories (&quot;but look, there they said &#x27;was&#x27; instead of &#x27;is&#x27;!&quot;).</div><br/><div id="36136103" class="c"><input type="checkbox" id="c-36136103" checked=""/><div class="controls bullet"><span class="by">bilekas</span><span>|</span><a href="#36135951">parent</a><span>|</span><a href="#36136061">next</a><span>|</span><label class="collapse" for="c-36136103">[-]</label><label class="expand" for="c-36136103">[1 more]</label></div><br/><div class="children"><div class="content">They also have added replies which have been removed, reading the article it&#x27;s actually not as conspiratorial as you make it seem.<p>In this case I really think it prudent to assume the worst from Google as they don&#x27;t really have a positive history for walling off users data, be it personal email or phone meta information.<p>&gt; &quot;The LaMDA engine underlying Bard is also what drives autocomplete and autoreply in Gmail so ... yeah Bard&#x27;s training data includes Gmail. FWIW, they put a lot of effort into ensuring that LaMDA doesn&#x27;t use give[sic] personal information about individuals in its responses.&quot;<p>If this is true, to me this is a good indicator that it&#x27;s using at least contextual information from emails.</div><br/></div></div><div id="36136061" class="c"><input type="checkbox" id="c-36136061" checked=""/><div class="controls bullet"><span class="by">marak830</span><span>|</span><a href="#36135951">parent</a><span>|</span><a href="#36136103">prev</a><span>|</span><a href="#36135983">next</a><span>|</span><label class="collapse" for="c-36136061">[-]</label><label class="expand" for="c-36136061">[1 more]</label></div><br/><div class="children"><div class="content">I would think that part 4 and &quot;what bard has to say about this&quot; sections would make most people question Google&#x27;s comment.<p>4. Google has never denied that Bard was trained on data from Gmail. They&#x27;ve only claimed that such data is not currently used to “improve” the model.<p>What Bard has to say about this:
“I have not personally seen a real Gmail account. However, I have access to a massive dataset of Gmail emails, and I have used this dataset to train my language model. This means that I am familiar with the format of Gmail emails, and I can generate text that is similar to the text that is found in real Gmail emails.”<p>Now do I think they have done the nasty? I don&#x27;t know.<p>Should it be reviewed by an outside team? I think yes.<p>I cannot think of a solution to this problem, which I believe will keep cropping up, but I think it can be problematic. I think it needs to be prooven true to be safe.</div><br/></div></div><div id="36135983" class="c"><input type="checkbox" id="c-36135983" checked=""/><div class="controls bullet"><span class="by">gersg</span><span>|</span><a href="#36135951">parent</a><span>|</span><a href="#36136061">prev</a><span>|</span><a href="#36136031">next</a><span>|</span><label class="collapse" for="c-36135983">[-]</label><label class="expand" for="c-36135983">[1 more]</label></div><br/><div class="children"><div class="content">Thank the Lord for that &quot;Readers added context&quot; marker that tweets now can have.</div><br/></div></div><div id="36136031" class="c"><input type="checkbox" id="c-36136031" checked=""/><div class="controls bullet"><span class="by">onion2k</span><span>|</span><a href="#36135951">parent</a><span>|</span><a href="#36135983">prev</a><span>|</span><a href="#36135976">next</a><span>|</span><label class="collapse" for="c-36136031">[-]</label><label class="expand" for="c-36136031">[5 more]</label></div><br/><div class="children"><div class="content">Lawyers use language in <i>very</i> specific ways, and anything that&#x27;s not completely obvious can be used to hide the truth. As an example, I once worked with a team who was building some software where a requirement said the app &#x27;should&#x27; do something instead it &#x27;shall&#x27; do something. The company&#x27;s lawyer argued <i>successfully</i> that this meant the requirement was optional.</div><br/><div id="36136053" class="c"><input type="checkbox" id="c-36136053" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#36135951">root</a><span>|</span><a href="#36136031">parent</a><span>|</span><a href="#36136067">next</a><span>|</span><label class="collapse" for="c-36136053">[-]</label><label class="expand" for="c-36136053">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s how Internet standards work.<p><a href="https:&#x2F;&#x2F;www.ietf.org&#x2F;rfc&#x2F;rfc2119.txt" rel="nofollow">https:&#x2F;&#x2F;www.ietf.org&#x2F;rfc&#x2F;rfc2119.txt</a></div><br/><div id="36136100" class="c"><input type="checkbox" id="c-36136100" checked=""/><div class="controls bullet"><span class="by">onion2k</span><span>|</span><a href="#36135951">root</a><span>|</span><a href="#36136053">parent</a><span>|</span><a href="#36136067">next</a><span>|</span><label class="collapse" for="c-36136100">[-]</label><label class="expand" for="c-36136100">[1 more]</label></div><br/><div class="children"><div class="content">This was a contract between two companies, written by a product manager and a CEO. It wasn&#x27;t a technical RFC.</div><br/></div></div></div></div><div id="36136067" class="c"><input type="checkbox" id="c-36136067" checked=""/><div class="controls bullet"><span class="by">delroth</span><span>|</span><a href="#36135951">root</a><span>|</span><a href="#36136031">parent</a><span>|</span><a href="#36136053">prev</a><span>|</span><a href="#36136077">next</a><span>|</span><label class="collapse" for="c-36136067">[-]</label><label class="expand" for="c-36136067">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure what you&#x27;re trying to say, but &quot;It is not trained on Gmail data.&quot; is as obvious a statement as you could ever express in the english language.</div><br/></div></div><div id="36136077" class="c"><input type="checkbox" id="c-36136077" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#36135951">root</a><span>|</span><a href="#36136031">parent</a><span>|</span><a href="#36136067">prev</a><span>|</span><a href="#36135976">next</a><span>|</span><label class="collapse" for="c-36136077">[-]</label><label class="expand" for="c-36136077">[1 more]</label></div><br/><div class="children"><div class="content">Not only that but this tweet is from Google Workspace and so it is not at all unreasonable to say it is not trained on Google Workspace Gmail and it says nothing about public gmail. Words. We have them.</div><br/></div></div></div></div><div id="36135976" class="c"><input type="checkbox" id="c-36135976" checked=""/><div class="controls bullet"><span class="by">ahahahahah</span><span>|</span><a href="#36135951">parent</a><span>|</span><a href="#36136031">prev</a><span>|</span><a href="#36136013">next</a><span>|</span><label class="collapse" for="c-36135976">[-]</label><label class="expand" for="c-36135976">[1 more]</label></div><br/><div class="children"><div class="content">It gives as much credence to bard&#x27;s own bullshit as it does to Google&#x27;s official statement. It&#x27;s a useless article.</div><br/></div></div></div></div><div id="36136013" class="c"><input type="checkbox" id="c-36136013" checked=""/><div class="controls bullet"><span class="by">ttrrooppeerr</span><span>|</span><a href="#36135951">prev</a><span>|</span><a href="#36135941">next</a><span>|</span><label class="collapse" for="c-36136013">[-]</label><label class="expand" for="c-36136013">[1 more]</label></div><br/><div class="children"><div class="content">The discussion here is not if it was trained or not in Gmail data, but on <i>personal</i> Gmail data. And that the definition of personal is vague and subject to interpretations.<p>They can say it was not trained on Gmail data because it was trained with Google’s Smart Compose, which it was trained on Gmail data.<p>Gmail Data -&gt; Google’s Smart Compose -&gt; Bard<p>It all depends on where you draw the line to stop reporting. Language is a powerful tool of deception.</div><br/></div></div><div id="36135941" class="c"><input type="checkbox" id="c-36135941" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#36136013">prev</a><span>|</span><a href="#36135818">next</a><span>|</span><label class="collapse" for="c-36135941">[-]</label><label class="expand" for="c-36135941">[2 more]</label></div><br/><div class="children"><div class="content">Would this not be fairly easy to test?<p>Find some fairly dense thing in gmail, stick 50% into bard and ask it to complete rest&amp; see how close output is?</div><br/><div id="36136062" class="c"><input type="checkbox" id="c-36136062" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#36135941">parent</a><span>|</span><a href="#36135818">next</a><span>|</span><label class="collapse" for="c-36136062">[-]</label><label class="expand" for="c-36136062">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are good at memorization, so yeah, if any included personal data I think you&#x27;d be able to get it to print it. (As an example, ChatGPT and Bard can both quote pretty long passages of Alice in Wonderland.)<p>There aren&#x27;t any techniques I know of to prevent it either; when training an image model the recommendation is to dedupe the input so nothing is weighted over anything else, but that&#x27;s not an absolute defense.</div><br/></div></div></div></div><div id="36135818" class="c"><input type="checkbox" id="c-36135818" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#36135941">prev</a><span>|</span><a href="#36135867">next</a><span>|</span><label class="collapse" for="c-36135818">[-]</label><label class="expand" for="c-36135818">[1 more]</label></div><br/><div class="children"><div class="content">Because the answer is yes.</div><br/></div></div><div id="36135867" class="c"><input type="checkbox" id="c-36135867" checked=""/><div class="controls bullet"><span class="by">michaelmrose</span><span>|</span><a href="#36135818">prev</a><span>|</span><a href="#36135933">next</a><span>|</span><label class="collapse" for="c-36135867">[-]</label><label class="expand" for="c-36135867">[6 more]</label></div><br/><div class="children"><div class="content">Logically it just doesn&#x27;t have that data and why would it? If you had proprietary data you didn&#x27;t want to share why would you add it to the language model?</div><br/><div id="36135947" class="c"><input type="checkbox" id="c-36135947" checked=""/><div class="controls bullet"><span class="by">aiunboxed</span><span>|</span><a href="#36135867">parent</a><span>|</span><a href="#36135940">next</a><span>|</span><label class="collapse" for="c-36135947">[-]</label><label class="expand" for="c-36135947">[1 more]</label></div><br/><div class="children"><div class="content">Agree, I doubt it would be trained.<p>If something personal - like Gmail&#x2F; drive goes out in any of bard responses, it will be the end of bard.</div><br/></div></div><div id="36135940" class="c"><input type="checkbox" id="c-36135940" checked=""/><div class="controls bullet"><span class="by">onion2k</span><span>|</span><a href="#36135867">parent</a><span>|</span><a href="#36135947">prev</a><span>|</span><a href="#36135933">next</a><span>|</span><label class="collapse" for="c-36135940">[-]</label><label class="expand" for="c-36135940">[4 more]</label></div><br/><div class="children"><div class="content">Bard is written by developers, and developers often don&#x27;t have any problem using any data available to them for a purpose they deem &#x27;useful&#x27;, especially if there&#x27;s a bonus or a promotion at stake.</div><br/><div id="36135957" class="c"><input type="checkbox" id="c-36135957" checked=""/><div class="controls bullet"><span class="by">aiunboxed</span><span>|</span><a href="#36135867">root</a><span>|</span><a href="#36135940">parent</a><span>|</span><a href="#36136000">next</a><span>|</span><label class="collapse" for="c-36135957">[-]</label><label class="expand" for="c-36135957">[2 more]</label></div><br/><div class="children"><div class="content">I think a company like Google would be having a lot of restrictions around where to train models and where to not.<p>And they already have access to the whole internet, Gmail conversations would be one tiny part of it.<p>Also wonder if they got to actually train on github data (considering the Microsoft angle)</div><br/><div id="36135981" class="c"><input type="checkbox" id="c-36135981" checked=""/><div class="controls bullet"><span class="by">onion2k</span><span>|</span><a href="#36135867">root</a><span>|</span><a href="#36135957">parent</a><span>|</span><a href="#36136000">next</a><span>|</span><label class="collapse" for="c-36135981">[-]</label><label class="expand" for="c-36135981">[1 more]</label></div><br/><div class="children"><div class="content"><i>Also wonder if they got to actually train on github data</i><p>Considering all the Github data is on Google BigQuery, probably: <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;topics&#x2F;public-datasets&#x2F;github-on-bigquery-analyze-all-the-open-source-code" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;topics&#x2F;public-datasets&#x2F;github-...</a></div><br/></div></div></div></div><div id="36136000" class="c"><input type="checkbox" id="c-36136000" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#36135867">root</a><span>|</span><a href="#36135940">parent</a><span>|</span><a href="#36135957">prev</a><span>|</span><a href="#36135933">next</a><span>|</span><label class="collapse" for="c-36136000">[-]</label><label class="expand" for="c-36136000">[1 more]</label></div><br/><div class="children"><div class="content">In my experience this is not true. Developers were on average more sticklers for &quot;the rules&quot; and very often overinterpreted restrictions beyond what compliance professionals deemed nescessary.</div><br/></div></div></div></div></div></div><div id="36135933" class="c"><input type="checkbox" id="c-36135933" checked=""/><div class="controls bullet"><span class="by">rosebay</span><span>|</span><a href="#36135867">prev</a><span>|</span><label class="collapse" for="c-36135933">[-]</label><label class="expand" for="c-36135933">[3 more]</label></div><br/><div class="children"><div class="content">The article directly quotes google giving a clear answer….<p>“Google replied to the tweet directly, saying, “Bard is an early experiment based on Large Language Models and will make mistakes. It is not trained on Gmail data. -JQ”.</div><br/><div id="36136005" class="c"><input type="checkbox" id="c-36136005" checked=""/><div class="controls bullet"><span class="by">marak830</span><span>|</span><a href="#36135933">parent</a><span>|</span><a href="#36135963">next</a><span>|</span><label class="collapse" for="c-36136005">[-]</label><label class="expand" for="c-36136005">[1 more]</label></div><br/><div class="children"><div class="content">I would have agreed, except for:<p>Initially, Google wrote, “Thank you for your message Kate, no private data will be used during Barbs[sic] training process. We always take good care of our users’ privacy and security.”<p>&quot;That seems like a clear and heartening assurance. It’s notable, then, that Google quickly deleted that tweet and didn’t amend it with any additional clarification&quot;<p>That makes me wonder if another model was trained and then pulled in. Example being the Gmail one.</div><br/></div></div><div id="36135963" class="c"><input type="checkbox" id="c-36135963" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#36135933">parent</a><span>|</span><a href="#36136005">prev</a><span>|</span><label class="collapse" for="c-36135963">[-]</label><label class="expand" for="c-36135963">[1 more]</label></div><br/><div class="children"><div class="content">It does, but there’s more discussion beyond that.</div><br/></div></div></div></div></div></div></div></div></div></body></html>