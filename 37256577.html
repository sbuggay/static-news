<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1692954061573" as="style"/><link rel="stylesheet" href="styles.css?v=1692954061573"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://skventures.substack.com/p/ai-isnt-good-enough">AI isn’t good enough</a> <span class="domain">(<a href="https://skventures.substack.com">skventures.substack.com</a>)</span></div><div class="subtext"><span>MaysonL</span> | <span>141 comments</span></div><br/><div><div id="37258015" class="c"><input type="checkbox" id="c-37258015" checked=""/><div class="controls bullet"><span class="by">ambrozk</span><span>|</span><a href="#37258676">next</a><span>|</span><label class="collapse" for="c-37258015">[-]</label><label class="expand" for="c-37258015">[83 more]</label></div><br/><div class="children"><div class="content">This entire piece is based on one massive, unsupported assertion, which is that LLM progress will cease. Or, as the author puts it, &quot;we are at the tail end of the first wave of large language model-based AI... [it] ends somewhere in the next year or two with the kinds of limits people are running up against.&quot; I want to know only one thing, which is what gives him the confidence necessary to say that. If that one statement is untrue, the thesis of the piece completely fails, and I do not know how any one person alive today can be certain that that statement is true. Has Paul Kedrovsky or Eric Norlin spent $150M training a 2T parameter model that no one&#x27;s heard about? Do they have access to classified OpenAI docs which state that GPT5 exists already, and it&#x27;s no better than GPT4? Without this sort of information, &quot;LLMs are not going to get smart enough for widespread practical use&quot; is an unsubstantiated bet, and nothing more.</div><br/><div id="37259556" class="c"><input type="checkbox" id="c-37259556" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#37258015">parent</a><span>|</span><a href="#37258752">next</a><span>|</span><label class="collapse" for="c-37259556">[-]</label><label class="expand" for="c-37259556">[1 more]</label></div><br/><div class="children"><div class="content">The current crop of LLMs is like Paleozoic megafauna, or like Egyptian Pyramids. It takes a few relatively simple approaches and stretches them wildly, using colossal computing resources.<p>Live systems in nature seem to solve similar problems with way less compute available. There should be better architectures.<p>Also, as somebody said, every exponential growth curve is a lower part of a sigmoid. LLMs will plateau at some level. That level may be impressively high though.</div><br/></div></div><div id="37258752" class="c"><input type="checkbox" id="c-37258752" checked=""/><div class="controls bullet"><span class="by">usrbinbash</span><span>|</span><a href="#37258015">parent</a><span>|</span><a href="#37259556">prev</a><span>|</span><a href="#37259285">next</a><span>|</span><label class="collapse" for="c-37258752">[-]</label><label class="expand" for="c-37258752">[39 more]</label></div><br/><div class="children"><div class="content">&gt; This entire piece is based on one massive, unsupported assertion, which is that LLM progress will cease.<p>Which is countered by...the assertion that it won&#x27;t?<p>LLMs won&#x27;t get intelligent. That&#x27;s a fact based on their MO. They are sequence completion engines. They can be fine tuned to specific tasks, but at their core, they remain stochastic parrots.<p>&gt; I want to know only one thing, which is what gives him the confidence necessary to say that.<p>I want to know only one thing, what gives the confidence to say otherwise?</div><br/><div id="37259248" class="c"><input type="checkbox" id="c-37259248" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37259189">next</a><span>|</span><label class="collapse" for="c-37259248">[-]</label><label class="expand" for="c-37259248">[3 more]</label></div><br/><div class="children"><div class="content">&gt;Which is countered by...the assertion that it won&#x27;t?<p>No it&#x27;s countered by principled restraint in not making an affirmative claim one way or the other.<p>I&#x27;ve heard this referred to as the overconfident pessimism problem. Which is that normal, well founded scientific discipline and evidence-based restraint go out of the window when people declare, without evidence that they know certain advances <i>won&#x27;t</i> happen.<p>Because people get mentally trapped into this framing of either have to declare that it will happen or that it won&#x27;t, seeming to forget that you can just adopt the position of modesty and say the dust hasn&#x27;t yet settled.</div><br/><div id="37259289" class="c"><input type="checkbox" id="c-37259289" checked=""/><div class="controls bullet"><span class="by">tlarkworthy</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259248">parent</a><span>|</span><a href="#37259189">next</a><span>|</span><label class="collapse" for="c-37259289">[-]</label><label class="expand" for="c-37259289">[2 more]</label></div><br/><div class="children"><div class="content">AI has been around the corner since the 1950s, this is the historical evidence for the pessimistic stance against over optimistic predictions.<p>LLMs are a huge stride forward, but AI does not progress like Moore&#x27;s law. LLM have revealed a new wall. Combining multi agents is not working out as hoped.</div><br/><div id="37259544" class="c"><input type="checkbox" id="c-37259544" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259289">parent</a><span>|</span><a href="#37259189">next</a><span>|</span><label class="collapse" for="c-37259544">[-]</label><label class="expand" for="c-37259544">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps without intending to, you&#x27;ve cited a pretty appropriate example of overconfident pessimism. Philosopher Hubert Dreyfus is most responsible for this portrayal of AI research in the &#x27;50s and &#x27;60s. He made a career of insisting that advances in AI would never come to pass, famously predicting that computers couldn&#x27;t become good at chess because it required &quot;insight&quot;, and routinely listing off what he believed were uniquely human qualities that couldn&#x27;t be embodied in computers, always in the form of underdefined terms such as intuition, insight, and other such terms.<p>Many of the things AI does now are exactly the type of things that doomsayers explicitly predicted would never happen, because they extrapolated from limited progress in the short term to absolute declarations over the infinite timeline of the future.<p>There&#x27;s a difference between the outer limits of theoretical possibility on the one hand, and instant results over the span of a couple new cycles, and it&#x27;s unfortunate that these get conflated.</div><br/></div></div></div></div></div></div><div id="37259189" class="c"><input type="checkbox" id="c-37259189" checked=""/><div class="controls bullet"><span class="by">nopinsight</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37259248">prev</a><span>|</span><a href="#37258872">next</a><span>|</span><label class="collapse" for="c-37259189">[-]</label><label class="expand" for="c-37259189">[9 more]</label></div><br/><div class="children"><div class="content">Geoffrey Hinton, Andrew Ng, and quite a few other top AI researchers believe that current LLMs (and incoming waves of multimodal LFMs) learn world models; they are not simply &#x27;stochastic parrots&#x27;.<p>If one feeds GPT-4 a novel problem that does not require multi-step reasoning or very high precision to solve, it can often solve it.</div><br/><div id="37259381" class="c"><input type="checkbox" id="c-37259381" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259189">parent</a><span>|</span><a href="#37259468">next</a><span>|</span><label class="collapse" for="c-37259381">[-]</label><label class="expand" for="c-37259381">[6 more]</label></div><br/><div class="children"><div class="content">Anyone who has worked a bit with a top LLM thinks that they learn world models. Otherwise, what they are doing would be impossible. I&#x27;ve used them for things that are definitely not on the web, because they are brand new research. They are definitely able to apply what they&#x27;ve learnt in novel ways.</div><br/><div id="37259456" class="c"><input type="checkbox" id="c-37259456" checked=""/><div class="controls bullet"><span class="by">RandomLensman</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259381">parent</a><span>|</span><a href="#37259468">next</a><span>|</span><label class="collapse" for="c-37259456">[-]</label><label class="expand" for="c-37259456">[5 more]</label></div><br/><div class="children"><div class="content">If they learn world models, those world models are incredible poor, i.e., there is no consistency of thought in those world models.<p>In my experience, things outside coding quickly devolve into something more like &quot;technobabble&quot; (and in coding there is always a lot of made-up stuff that doesn&#x27;t exists in terms of functions etc.).</div><br/><div id="37259548" class="c"><input type="checkbox" id="c-37259548" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259456">parent</a><span>|</span><a href="#37259520">next</a><span>|</span><label class="collapse" for="c-37259548">[-]</label><label class="expand" for="c-37259548">[2 more]</label></div><br/><div class="children"><div class="content">I see them more as creative artists who have very good intuition, but are poor logicians. Their world model is not a strict database of consistent facts, it is more like a set of various beliefs, and of course those can be highly contradictory.</div><br/><div id="37259568" class="c"><input type="checkbox" id="c-37259568" checked=""/><div class="controls bullet"><span class="by">RandomLensman</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259548">parent</a><span>|</span><a href="#37259520">next</a><span>|</span><label class="collapse" for="c-37259568">[-]</label><label class="expand" for="c-37259568">[1 more]</label></div><br/><div class="children"><div class="content">That maybe sufficient for advertising, marketing, some shallow story telling etc., it is way too dangerous for anything in the physical sciences, legal, medicine, ...</div><br/></div></div></div></div><div id="37259520" class="c"><input type="checkbox" id="c-37259520" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259456">parent</a><span>|</span><a href="#37259548">prev</a><span>|</span><a href="#37259468">next</a><span>|</span><label class="collapse" for="c-37259520">[-]</label><label class="expand" for="c-37259520">[2 more]</label></div><br/><div class="children"><div class="content">&gt;<i>If they learn world models, those world models are incredible poor, i.e., there is no consistency of thought in those world models</i><p>Incredibly poor compared to ours, but thousands of times better than what &quot;AI&quot; we had before.</div><br/><div id="37259559" class="c"><input type="checkbox" id="c-37259559" checked=""/><div class="controls bullet"><span class="by">RandomLensman</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259520">parent</a><span>|</span><a href="#37259468">next</a><span>|</span><label class="collapse" for="c-37259559">[-]</label><label class="expand" for="c-37259559">[1 more]</label></div><br/><div class="children"><div class="content">Not sure that matters much as they are only for low risk stuff without skilled supervision, so back to advertising, marketing, cheap customer support, etc.</div><br/></div></div></div></div></div></div></div></div><div id="37259468" class="c"><input type="checkbox" id="c-37259468" checked=""/><div class="controls bullet"><span class="by">w1nk</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259189">parent</a><span>|</span><a href="#37259381">prev</a><span>|</span><a href="#37259417">next</a><span>|</span><label class="collapse" for="c-37259468">[-]</label><label class="expand" for="c-37259468">[1 more]</label></div><br/><div class="children"><div class="content">Just to further this, it&#x27;s not just &#x27;big names&#x27; that feel this way.  Read this paper from a team at Microsoft Research: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2303.12712" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2303.12712</a> .  These folks spent months studying properties of GPT-4, that paper is ~150 pages of examples probing the boundaries of the model&#x27;s world understanding.  There is obviously some emergent complexity arising from the training procedure.</div><br/></div></div><div id="37259417" class="c"><input type="checkbox" id="c-37259417" checked=""/><div class="controls bullet"><span class="by">Viliam1234</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259189">parent</a><span>|</span><a href="#37259468">prev</a><span>|</span><a href="#37258872">next</a><span>|</span><label class="collapse" for="c-37259417">[-]</label><label class="expand" for="c-37259417">[1 more]</label></div><br/><div class="children"><div class="content">A typical parrot repeats after you said something. A parrot that could <i>predict</i> your words before you said them, and could impersonate you in a phone call, would be quite scary (calling Hollywood, sounds like an interesting move idea). A parrot that could listen to you talking for hours, and then provide you a short summary, would probably also be called intelligent.</div><br/></div></div></div></div><div id="37258872" class="c"><input type="checkbox" id="c-37258872" checked=""/><div class="controls bullet"><span class="by">beefield</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37259189">prev</a><span>|</span><a href="#37258947">next</a><span>|</span><label class="collapse" for="c-37258872">[-]</label><label class="expand" for="c-37258872">[8 more]</label></div><br/><div class="children"><div class="content">&gt; LLMs won&#x27;t get intelligent. That&#x27;s a fact based on their MO.<p>I kind of agree. However, I see a real possibility that in the near future LLM behaviour would be practically indistinguishable from intelligent&#x2F;sentient behavior. And at that point we (or at least I) are facing some really interesting&#x2F;difficult questions, namely how do you know an intelligent looking thing actually is intelligent (or sentient). How do you prove me you&#x2F;LLM are&#x2F;aren&#x27;t a philosophical zombie?<p>How we are supposed to treat very much intelligent&#x2F;sentient looking things when we are not sure if they are sentient&#x2F;intelligent or not? Let&#x27;s face it, lots of people are dumb as rock (too often very much me included). Why we should be able to treat something badly just because we think we know they can&#x27;t be intelligent, even if they walk , look and quack like intelligent duck?<p>I personally have started to think that the behavior of humans should be judged by the behaviour, not the target. If you want to behave like an asshole towards a teddy bear, then you most likely are an asshole.</div><br/><div id="37259532" class="c"><input type="checkbox" id="c-37259532" checked=""/><div class="controls bullet"><span class="by">js8</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258872">parent</a><span>|</span><a href="#37259148">next</a><span>|</span><label class="collapse" for="c-37259532">[-]</label><label class="expand" for="c-37259532">[1 more]</label></div><br/><div class="children"><div class="content">Any sufficiently advanced intelligence is indistinguishable from an LLM?<p>Cute, but practically speaking, I would prefer the former.</div><br/></div></div><div id="37259148" class="c"><input type="checkbox" id="c-37259148" checked=""/><div class="controls bullet"><span class="by">velvetz</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258872">parent</a><span>|</span><a href="#37259532">prev</a><span>|</span><a href="#37259109">next</a><span>|</span><label class="collapse" for="c-37259148">[-]</label><label class="expand" for="c-37259148">[2 more]</label></div><br/><div class="children"><div class="content">Off-topic and might sound strange but I find it intriguing that you wrote behavior and behaviour in these two different forms in the same sentence:)</div><br/><div id="37259536" class="c"><input type="checkbox" id="c-37259536" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259148">parent</a><span>|</span><a href="#37259109">next</a><span>|</span><label class="collapse" for="c-37259536">[-]</label><label class="expand" for="c-37259536">[1 more]</label></div><br/><div class="children"><div class="content">Quite easy to happen if like many of us you were taugh British English, and then you remember that you&#x27;re on a US forum, and everybody around you uses the US spelling for things (and you get to read the US variants all the time in other comments).</div><br/></div></div></div></div><div id="37259109" class="c"><input type="checkbox" id="c-37259109" checked=""/><div class="controls bullet"><span class="by">savolai</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258872">parent</a><span>|</span><a href="#37259148">prev</a><span>|</span><a href="#37258947">next</a><span>|</span><label class="collapse" for="c-37259109">[-]</label><label class="expand" for="c-37259109">[4 more]</label></div><br/><div class="children"><div class="content">It seems to me that the real question here is what is true human intelligence. Ai has made it plain to see, by being able to replicate it so convincingly, that much of what we have considered intelligence has been pattern matching or acting as complex parrots.<p>There is much more to the abilities of human body-mind-emotional-experiential being, but it is only slowly becoming mainstream.<p>(Edit: Of course there are also many analytical skills that AI cannot match at this point. My point is that we shouldn’t overlook any area of human capacity.)<p>One salient question in this is: will we reach a level of intelligence where we become beings capable of actual collaboration that doesn’t waste so much effort in conflicts, or one that is capable of living in harmony within its environment?<p>What capabilities of awareness, trauma work, emotional maturity and self reflection does this require? What resources hidden inside humanity that we have forgotten do we need to wield?<p>Does AI have something to contribute to this process happening?</div><br/><div id="37259564" class="c"><input type="checkbox" id="c-37259564" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259109">parent</a><span>|</span><a href="#37259175">next</a><span>|</span><label class="collapse" for="c-37259564">[-]</label><label class="expand" for="c-37259564">[1 more]</label></div><br/><div class="children"><div class="content">&gt;<i>One salient question in this is: will we reach a level of intelligence where we become beings capable of actual collaboration that doesn’t waste so much effort in conflicts, or one that is capable of living in harmony within its environment?</i><p>That&#x27;s more about ethics and an wish for moral behavior and conflict aversion, than about intelligence.<p>Intelligence (human and AI) could just as well opt for conflict and evil, if this helps it get the upper hand for its own private goals and interests.<p>Simply put, the interests of the collective, are not necessarily the interests of the individual intelligence.<p>(Even assuming there was a single, easy to agree upon, &quot;interest of the collective&quot; for most problems).</div><br/></div></div><div id="37259175" class="c"><input type="checkbox" id="c-37259175" checked=""/><div class="controls bullet"><span class="by">worrycue</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259109">parent</a><span>|</span><a href="#37259564">prev</a><span>|</span><a href="#37259228">next</a><span>|</span><label class="collapse" for="c-37259175">[-]</label><label class="expand" for="c-37259175">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It seems to me that the real question here is what is true human intelligence.<p>IMHO the main weakness with LLMs is they can’t really reason. They can statistically guess their way to an answer - and they do so surprisingly well I will have to admit - but they can’t really “check” themselves to ensure what they are outputting makes any sense like humans do (most of the time) - hence the hallucinations.</div><br/></div></div><div id="37259228" class="c"><input type="checkbox" id="c-37259228" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259109">parent</a><span>|</span><a href="#37259175">prev</a><span>|</span><a href="#37258947">next</a><span>|</span><label class="collapse" for="c-37259228">[-]</label><label class="expand" for="c-37259228">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m getting suspicious that there is a bit of a blind spot in understanding the world and the usefulness of what we call intelligence, as Noval Yuah Harari says, intelligence is overrated. Look at what we&#x27;ve done to the planet and our environment we have fucked it properly, yet we consider ourselves to be intelligent?<p>Could it be that intelligence is overrated and discovery of new ideas &#x2F; thing is underrated? Our egos tell us it&#x27;s intelligence that makes us special and creative and awesome but maybe most of the special stuff is already there for us to find and we conflate discovery with extrapolation. Maybe knowledge and experience are the &quot;important bits&quot; of intellect.<p>Example: Einstein didn&#x27;t really invent anything, he discovered things about the world that blew our mind and changes our lives. Yes he was a great thinker and a courageous soul to go against the grain and he had the balls to be open minded enough to discover new things. We obviously believe Einstein to be intelligent but was he just a great explorer ?<p>I have a similar attitude towards technological progress, yes we&#x27;ve done amazing things but fundamentally the air we breathe, the water we drink and the beauty we are subjected too when looking at a sunset are taken for granted while we stare at our phones.</div><br/></div></div></div></div></div></div><div id="37258947" class="c"><input type="checkbox" id="c-37258947" checked=""/><div class="controls bullet"><span class="by">squeaky-clean</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37258872">prev</a><span>|</span><a href="#37258892">next</a><span>|</span><label class="collapse" for="c-37258947">[-]</label><label class="expand" for="c-37258947">[7 more]</label></div><br/><div class="children"><div class="content">&gt; LLMs won&#x27;t get intelligent.<p>I think this sentence doesn&#x27;t mean much unless we have a strict definition of what intelligence means.<p>Just today ChatGPT helped me solve a DNS issue that I would not have been able to solve on my own in one day, let alone an hour. I&#x27;d consider it already more intelligent than myself when it comes to DNS.</div><br/><div id="37258955" class="c"><input type="checkbox" id="c-37258955" checked=""/><div class="controls bullet"><span class="by">Aperocky</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258947">parent</a><span>|</span><a href="#37259114">next</a><span>|</span><label class="collapse" for="c-37258955">[-]</label><label class="expand" for="c-37258955">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s seen more DNS content than you and anybody else have seen in their entire lives, and are able to regurgitate what it read because it has far faster memory access than you did.<p>A dictionary contain knowledge but no intelligence.</div><br/><div id="37259068" class="c"><input type="checkbox" id="c-37259068" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258955">parent</a><span>|</span><a href="#37259114">next</a><span>|</span><label class="collapse" for="c-37259068">[-]</label><label class="expand" for="c-37259068">[4 more]</label></div><br/><div class="children"><div class="content">And LLMs are the opposite of dictionary, actually. They suck at storing facts. They excel at extracting patterns from noise and learning them. It&#x27;s not obvious to me that this isn&#x27;t intelligence; on the contrary, I feel it&#x27;s very much a core component of it.</div><br/><div id="37259198" class="c"><input type="checkbox" id="c-37259198" checked=""/><div class="controls bullet"><span class="by">worrycue</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259068">parent</a><span>|</span><a href="#37259117">next</a><span>|</span><label class="collapse" for="c-37259198">[-]</label><label class="expand" for="c-37259198">[2 more]</label></div><br/><div class="children"><div class="content">&gt; They excel at extracting patterns from noise and learning them.<p>You can argue those are facts too.</div><br/><div id="37259572" class="c"><input type="checkbox" id="c-37259572" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259198">parent</a><span>|</span><a href="#37259117">next</a><span>|</span><label class="collapse" for="c-37259572">[-]</label><label class="expand" for="c-37259572">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I have noticed that a lot of extreme AI cynics have been arguing that any and every example of reasoning or thinking that an LLM displays is just some variant of memorisation.</div><br/></div></div></div></div><div id="37259117" class="c"><input type="checkbox" id="c-37259117" checked=""/><div class="controls bullet"><span class="by">BartjeD</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259068">parent</a><span>|</span><a href="#37259198">prev</a><span>|</span><a href="#37259114">next</a><span>|</span><label class="collapse" for="c-37259117">[-]</label><label class="expand" for="c-37259117">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that a dictionary of patterns?</div><br/></div></div></div></div></div></div><div id="37259114" class="c"><input type="checkbox" id="c-37259114" checked=""/><div class="controls bullet"><span class="by">PlunderBunny</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258947">parent</a><span>|</span><a href="#37258955">prev</a><span>|</span><a href="#37258892">next</a><span>|</span><label class="collapse" for="c-37259114">[-]</label><label class="expand" for="c-37259114">[1 more]</label></div><br/><div class="children"><div class="content">“… unless we have a strict definition of what intelligence means.”<p>There were some Greek guys working on that exact problem a few (thousand) years ago.</div><br/></div></div></div></div><div id="37258892" class="c"><input type="checkbox" id="c-37258892" checked=""/><div class="controls bullet"><span class="by">albertzeyer</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37258947">prev</a><span>|</span><a href="#37259214">next</a><span>|</span><label class="collapse" for="c-37258892">[-]</label><label class="expand" for="c-37258892">[2 more]</label></div><br/><div class="children"><div class="content">Look at the scaling laws.<p>We found that extrapolating the performance given a few data points with smaller models is actually very accurate. That&#x27;s how they determined hyper parameters, by tuning them on multiple smaller scale models and then extrapolating. So far, all those predictions were quite good.<p>Together with a bigger model, we also need more data to get better performance. If we add video and audio to the text data, we have still a lot more data we can use, so this is also not really a problem.<p>It would be very unexpected that those scaling laws are suddenly not true anymore for the next order of magnitude in model and data size.</div><br/><div id="37258983" class="c"><input type="checkbox" id="c-37258983" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258892">parent</a><span>|</span><a href="#37259214">next</a><span>|</span><label class="collapse" for="c-37258983">[-]</label><label class="expand" for="c-37258983">[1 more]</label></div><br/><div class="children"><div class="content">Scaling laws apply to a single model.  The best single model right now is supposedly a 8x mixture of experts, so not even really a single model in the purist sense.<p>I still expect the final solution will be more along the lines of picking the best model(s) from a sea of possible models, switching them in and out as needed, and then automatically reiterating as needed.</div><br/></div></div></div></div><div id="37259214" class="c"><input type="checkbox" id="c-37259214" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37258892">prev</a><span>|</span><a href="#37258894">next</a><span>|</span><label class="collapse" for="c-37259214">[-]</label><label class="expand" for="c-37259214">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m put in mind of the OpenAI DoTA bot that was winning 99% of its games and some people refused to admit that it knew how to play DoTA based on some esoteric interpretation of the word &quot;play&quot;.<p>We&#x27;re going to see exponential increases in processing power of the best GPU clusters and human brains are a stationary target. And there is precious little evidence that the average human is much more than an LLM. LLMs are already more likely to understand a topic to a high standard than a given human.<p>They&#x27;re going to progress and if they aren&#x27;t intelligent then intelligence is overrated and I&#x27;d rather have whatever they have.</div><br/></div></div><div id="37258894" class="c"><input type="checkbox" id="c-37258894" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37259214">prev</a><span>|</span><a href="#37259469">next</a><span>|</span><label class="collapse" for="c-37258894">[-]</label><label class="expand" for="c-37258894">[1 more]</label></div><br/><div class="children"><div class="content">&gt;LLMs won&#x27;t get intelligent. That&#x27;s a fact based on their MO. They are sequence completion engines. They can be fine tuned to specific tasks, but at their core, they remain stochastic parrots.<p>This is absolutely wrong. There is nothing about their MO that stops them from being intelligent. Suppose I build a human LLM as follows:
A random human expert is picked and he is shown the current context window. He is given 1 week to deliberate and then may choose the next word&#x2F;token&#x2F;character.
Then you hook this human LLM into an auto-GPT style loop.
There is no reason it couldn&#x27;t operate with high intelligence on text data.<p>Not also that LLMs are not really about language at all anymore, the architectures can be used on any sequence data.<p>Right now we are compute limited. If compute was 100x cheaper we could have GPT-6, bring 100x bigger, we could have really large and complex agents using GPT-4 power models, or we could train on tupled text-video data of subtitles videos. Given the world model LLMs manage to learn out of text data, I am 100% certain that a sufficiently large transformer can learn a decent world model from text-video data. Then our agents could also have a good physical understanding.</div><br/></div></div><div id="37259469" class="c"><input type="checkbox" id="c-37259469" checked=""/><div class="controls bullet"><span class="by">nly</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37258894">prev</a><span>|</span><a href="#37259237">next</a><span>|</span><label class="collapse" for="c-37259469">[-]</label><label class="expand" for="c-37259469">[1 more]</label></div><br/><div class="children"><div class="content">Parrots are pretty intelligent. Seems like a an unfair analogy</div><br/></div></div><div id="37259237" class="c"><input type="checkbox" id="c-37259237" checked=""/><div class="controls bullet"><span class="by">alpaca128</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37259469">prev</a><span>|</span><a href="#37259018">next</a><span>|</span><label class="collapse" for="c-37259237">[-]</label><label class="expand" for="c-37259237">[3 more]</label></div><br/><div class="children"><div class="content">&gt; LLMs won&#x27;t get intelligent<p>Even assuming that is true: LLMs aren&#x27;t all that exists in AI research and just like LLMs are amazing in terms of language it&#x27;s possible similar breakthroughs could be made in more abstracted areas that could use LLMs for IO.<p>If you think ChatGPT is nice, wait for ChatGPT as frontend for another AI that doesn&#x27;t have to spend a single CPU cycle on language.</div><br/><div id="37259363" class="c"><input type="checkbox" id="c-37259363" checked=""/><div class="controls bullet"><span class="by">benterix</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259237">parent</a><span>|</span><a href="#37259333">next</a><span>|</span><label class="collapse" for="c-37259363">[-]</label><label class="expand" for="c-37259363">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  LLMs aren&#x27;t all that exists in AI research<p>Frankly, I&#x27;m a bit worried about all the rest now that LLMs proved to be so successful. We might exploit them and arrive to a dead end. In the meantime, other potentially crucial developments in AI might get less attention and funding.</div><br/></div></div><div id="37259333" class="c"><input type="checkbox" id="c-37259333" checked=""/><div class="controls bullet"><span class="by">oceanplexian</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259237">parent</a><span>|</span><a href="#37259363">prev</a><span>|</span><a href="#37259018">next</a><span>|</span><label class="collapse" for="c-37259333">[-]</label><label class="expand" for="c-37259333">[1 more]</label></div><br/><div class="children"><div class="content">The next AI wave hasn&#x27;t even started. Imagine an LLM the size of GPT-4 but it&#x27;s trained on nothing but gene sequence completion.<p>All the models being used in academia are basically toys, none of those guys are running hardware at a scale that can even remotely touch Azure, Meta, etc, and right now there is a massive global shortage of GPU compute that&#x27;s eventually going to clear up. We know models get A LOT better when they are scaled up and are fed more data, so why wouldn&#x27;t the same be true for other problems besides text completion?</div><br/></div></div></div></div><div id="37259018" class="c"><input type="checkbox" id="c-37259018" checked=""/><div class="controls bullet"><span class="by">edf13</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37259237">prev</a><span>|</span><a href="#37258869">next</a><span>|</span><label class="collapse" for="c-37259018">[-]</label><label class="expand" for="c-37259018">[2 more]</label></div><br/><div class="children"><div class="content">&gt; They are sequence completion engines<p>But at the basic level - isn&#x27;t our own brain just a sequence completion engine too?</div><br/><div id="37259196" class="c"><input type="checkbox" id="c-37259196" checked=""/><div class="controls bullet"><span class="by">HPsquared</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37259018">parent</a><span>|</span><a href="#37258869">next</a><span>|</span><label class="collapse" for="c-37259196">[-]</label><label class="expand" for="c-37259196">[1 more]</label></div><br/><div class="children"><div class="content">The brain does seem to do a lot of pattern-matching and prediction.</div><br/></div></div></div></div><div id="37258869" class="c"><input type="checkbox" id="c-37258869" checked=""/><div class="controls bullet"><span class="by">rhn_mk1</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258752">parent</a><span>|</span><a href="#37259018">prev</a><span>|</span><a href="#37259285">next</a><span>|</span><label class="collapse" for="c-37258869">[-]</label><label class="expand" for="c-37258869">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s countered by not making the assertion and not being able to make conclusions. You only need a lack of confidence for that. It&#x27;s orders of magnitude easier to not have knowledge compared to having it.</div><br/></div></div></div></div><div id="37259285" class="c"><input type="checkbox" id="c-37259285" checked=""/><div class="controls bullet"><span class="by">jug</span><span>|</span><a href="#37258015">parent</a><span>|</span><a href="#37258752">prev</a><span>|</span><a href="#37258921">next</a><span>|</span><label class="collapse" for="c-37259285">[-]</label><label class="expand" for="c-37259285">[1 more]</label></div><br/><div class="children"><div class="content">There has actually been research that found that there are strong diminishing returns in terms of at least expanding parameter sizes. While I think there are still breakthroughs to be made in terms of window sizes and workarounds like Mixture of Experts, I&#x27;m not sure how much farther we will get here in the long term in terms of raw performance of the LLM itself. FWIW, Sam Altman agrees and has a surprisingly similar quote as found here &quot;I think we’re at the end of the era where it’s gonna be these giant models, and we’ll make them better in other ways&quot;: <a href="https:&#x2F;&#x2F;techcrunch.com&#x2F;2023&#x2F;04&#x2F;14&#x2F;sam-altman-size-of-llms-wont-matter-as-much-moving-forward" rel="nofollow noreferrer">https:&#x2F;&#x2F;techcrunch.com&#x2F;2023&#x2F;04&#x2F;14&#x2F;sam-altman-size-of-llms-wo...</a></div><br/></div></div><div id="37258921" class="c"><input type="checkbox" id="c-37258921" checked=""/><div class="controls bullet"><span class="by">thrwjud</span><span>|</span><a href="#37258015">parent</a><span>|</span><a href="#37259285">prev</a><span>|</span><a href="#37258382">next</a><span>|</span><label class="collapse" for="c-37258921">[-]</label><label class="expand" for="c-37258921">[1 more]</label></div><br/><div class="children"><div class="content">Every deep learning tech had an exponential growth phase, followed by a slowdown followed by a platou the nothing could break until a fundamentally new architecture came along. People get excited about the first part, project it into the second and start companies by the time we&#x27;re well into the third.</div><br/></div></div><div id="37258382" class="c"><input type="checkbox" id="c-37258382" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#37258015">parent</a><span>|</span><a href="#37258921">prev</a><span>|</span><a href="#37258404">next</a><span>|</span><label class="collapse" for="c-37258382">[-]</label><label class="expand" for="c-37258382">[10 more]</label></div><br/><div class="children"><div class="content">I can take a bet that it haha already failed - the hype cycle has already made a promise that LLMs can’t keep.<p>Hallucinations to the normal person are a bug.<p>The issue is that only humans can hallucinate. We know there is a “reality”.<p>For an LLM, everything it does is a hallucination.<p>That’s why you have more POCs than production goods. Your “hallucination rate” is unknown.<p>Yesterday Ars has an article that described LLMs as a new type of CPU for a new type of architecture.
Others want “LawLLM” or “healthLLM”.<p>These are simply not going to happen.<p>If you even get it to 80% accuracy- it’s a 1&#x2F;5 chance you have a relevant answer.<p>The issue isn’t a technical one.<p>It’s expectations.</div><br/><div id="37258819" class="c"><input type="checkbox" id="c-37258819" checked=""/><div class="controls bullet"><span class="by">Rereereetret</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258382">parent</a><span>|</span><a href="#37259396">next</a><span>|</span><label class="collapse" for="c-37258819">[-]</label><label class="expand" for="c-37258819">[2 more]</label></div><br/><div class="children"><div class="content">And while you mention one article with a negative experience, tons of positive article came out too.<p>GitHub copilot is really good and useful.<p>All demos I saw which use LLMs were spectacular.<p>The ai race started this year for everyone which means we will continuesly see progress.<p>And while you only mention LlM the whole ai space is crazy.<p>There is a high chance that the architecture from LLMs will change.<p>And we haven&#x27;t even touched all possibilities with multi modal LLM models.</div><br/><div id="37259504" class="c"><input type="checkbox" id="c-37259504" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258819">parent</a><span>|</span><a href="#37259396">next</a><span>|</span><label class="collapse" for="c-37259504">[-]</label><label class="expand" for="c-37259504">[1 more]</label></div><br/><div class="children"><div class="content">&gt; All demos I saw which use LLMs were spectacular.<p>Aren&#x27;t demos always spectacular?</div><br/></div></div></div></div><div id="37259396" class="c"><input type="checkbox" id="c-37259396" checked=""/><div class="controls bullet"><span class="by">barrysteve</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258382">parent</a><span>|</span><a href="#37258819">prev</a><span>|</span><a href="#37258508">next</a><span>|</span><label class="collapse" for="c-37259396">[-]</label><label class="expand" for="c-37259396">[1 more]</label></div><br/><div class="children"><div class="content">The bigger problem is that an accurate LLM is such a massive speed up in coding (an order of magnitude, hypothetically at least), that there is zero incentive to share it.<p>All American programming tech has relied on an time-and-knowledge gap to keep big companies in power.<p>Using visual studio and c++ to create programs is trivial or speedy if you have a team of programmers and know what pitfalls to avoid. If you&#x27;re a public pleb&#x2F;peasant who doesn&#x27;t know the pitfalls, you&#x27;re going to waste thousands of hours hitting pointless errors, conceptual problems and scaling issues.<p>Hallucinating LLMs are marketable to the public. Accurate LLMs are a weapon best kept private.<p>I am always intriguied by the people who say LLMs provide a massive benefit to their programming and never ever provide examples............</div><br/></div></div><div id="37258508" class="c"><input type="checkbox" id="c-37258508" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258382">parent</a><span>|</span><a href="#37259396">prev</a><span>|</span><a href="#37258404">next</a><span>|</span><label class="collapse" for="c-37258508">[-]</label><label class="expand" for="c-37258508">[6 more]</label></div><br/><div class="children"><div class="content">Why not &quot;simply&quot; multigen every (important) query and take the statistical average?<p>Hallucinations are random, the truth isn&#x27;t.<p>This is absurdly expensive with GPT4, cheaper with 3, and dirt cheap locally with LLaMA</div><br/><div id="37259071" class="c"><input type="checkbox" id="c-37259071" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258508">parent</a><span>|</span><a href="#37258742">next</a><span>|</span><label class="collapse" for="c-37259071">[-]</label><label class="expand" for="c-37259071">[1 more]</label></div><br/><div class="children"><div class="content">That’s an established technique with papers written on the topic and everything.<p>Anecdotally I tested this by having GPT4 translate Acadian cuneiform — which it can just barely do. I had it do this four times and it returned four gibberish answers. I then prompted it with the source plus the four attempts and asked for a merged result.<p>It did it better than the human archeologists did! More readable and consistent. I compared it with the human version and it matched the meaning.<p>Expensive now… soon to be standard?</div><br/></div></div><div id="37258742" class="c"><input type="checkbox" id="c-37258742" checked=""/><div class="controls bullet"><span class="by">xmprt</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258508">parent</a><span>|</span><a href="#37259071">prev</a><span>|</span><a href="#37258951">next</a><span>|</span><label class="collapse" for="c-37258742">[-]</label><label class="expand" for="c-37258742">[2 more]</label></div><br/><div class="children"><div class="content">That only works if the generated outputs are completely independent and not correlated. I&#x27;d be interested in research that shows whether multigen actually reduces hallucination rates.</div><br/><div id="37258796" class="c"><input type="checkbox" id="c-37258796" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258742">parent</a><span>|</span><a href="#37258951">next</a><span>|</span><label class="collapse" for="c-37258796">[-]</label><label class="expand" for="c-37258796">[1 more]</label></div><br/><div class="children"><div class="content">True, I&#x27;m just throwing multigen out there as a wild ass solution
However you could do multigen across different models, e.g. GPT&#x2F;Claude&#x2F;LLaMA which should not correlate entirely</div><br/></div></div></div></div><div id="37258951" class="c"><input type="checkbox" id="c-37258951" checked=""/><div class="controls bullet"><span class="by">thatjoeoverthr</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258508">parent</a><span>|</span><a href="#37258742">prev</a><span>|</span><a href="#37258404">next</a><span>|</span><label class="collapse" for="c-37258951">[-]</label><label class="expand" for="c-37258951">[2 more]</label></div><br/><div class="children"><div class="content">Just try it!</div><br/><div id="37259037" class="c"><input type="checkbox" id="c-37259037" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258951">parent</a><span>|</span><a href="#37258404">next</a><span>|</span><label class="collapse" for="c-37259037">[-]</label><label class="expand" for="c-37259037">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll give this a shot after work I think.<p>The question I have is what&#x27;s a prompt which reliably hallucinates but still produces the correct answer some of the time?<p>I know it gets some python functions &quot;wrong&quot;, but i think they were actually &quot;right&quot; in the version it was trained on, so software seems out.</div><br/></div></div></div></div></div></div></div></div><div id="37258404" class="c"><input type="checkbox" id="c-37258404" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#37258015">parent</a><span>|</span><a href="#37258382">prev</a><span>|</span><a href="#37258253">next</a><span>|</span><label class="collapse" for="c-37258404">[-]</label><label class="expand" for="c-37258404">[6 more]</label></div><br/><div class="children"><div class="content">&gt;<i>This entire piece is based on one massive, unsupported assertion, which is that LLM progress will cease.</i><p>Sounds like a pretty good guesstimation. Well, not cease, just fizzle out.</div><br/><div id="37258625" class="c"><input type="checkbox" id="c-37258625" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258404">parent</a><span>|</span><a href="#37258253">next</a><span>|</span><label class="collapse" for="c-37258625">[-]</label><label class="expand" for="c-37258625">[5 more]</label></div><br/><div class="children"><div class="content">It hasn&#x27;t even begun to get good, we only got yesterday decent local code generation models, we haven&#x27;t even begun on the fine tuning and tooling for using them.</div><br/><div id="37258765" class="c"><input type="checkbox" id="c-37258765" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258625">parent</a><span>|</span><a href="#37258253">next</a><span>|</span><label class="collapse" for="c-37258765">[-]</label><label class="expand" for="c-37258765">[4 more]</label></div><br/><div class="children"><div class="content">When the &quot;fine tuning&quot; and focus on tooling begins, it usually means the &quot;free&quot; massive improvements have tapered off.</div><br/><div id="37258782" class="c"><input type="checkbox" id="c-37258782" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258765">parent</a><span>|</span><a href="#37258253">next</a><span>|</span><label class="collapse" for="c-37258782">[-]</label><label class="expand" for="c-37258782">[3 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s anything like Stable Diffusion, it&#x27;s actually where it becomes terrifyingly good at a specific thing.<p>Like putting a field of artists out of a job, or copying a style so good that you can complete a persons piece before they do on a livestream.<p>We&#x27;re using a massive mush of the internet model which is taxed at 50% for alignment.  That&#x27;s going to be very dumb in the long run.</div><br/><div id="37258925" class="c"><input type="checkbox" id="c-37258925" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258782">parent</a><span>|</span><a href="#37258253">next</a><span>|</span><label class="collapse" for="c-37258925">[-]</label><label class="expand" for="c-37258925">[2 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Like putting a field of artists out of a job,</i><p>To be frank, between stock art and photos, pre-AI template based tools, and the massive oversupply of graphic design and photography work, the field was already massively redudant and kind of out of a job to begin with...</div><br/><div id="37258963" class="c"><input type="checkbox" id="c-37258963" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258925">parent</a><span>|</span><a href="#37258253">next</a><span>|</span><label class="collapse" for="c-37258963">[-]</label><label class="expand" for="c-37258963">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking of people who... well, take commissions to make lewd images of various themes (e.g. furry stuff) or new specific characters or such... not my cup of tea but i know from researching what is possible that you only need a few images of new season anime girl blue hair edition #9237191 from the Japanese sites to do a lora and be able to make mostly anything you want when it&#x27;s done on the booru models. And you can pose people with controlnet i think. that&#x27;s also how those super cool QR code images are made.<p>Those guys apparently used to make pretty good cash from twitter, usually using pen names so they wouldn&#x27;t&#x27; be associated with their regular work<p>The scary bit here is you can also &quot;clone&quot; a person to make any image you want of them.  Obviously there&#x27;s a lot of problems coming from that in the future, but also neat applications, e.g. some guy made selfie pictures of himself in the past with this for internet dating.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="37258253" class="c"><input type="checkbox" id="c-37258253" checked=""/><div class="controls bullet"><span class="by">user3939382</span><span>|</span><a href="#37258015">parent</a><span>|</span><a href="#37258404">prev</a><span>|</span><a href="#37258676">next</a><span>|</span><label class="collapse" for="c-37258253">[-]</label><label class="expand" for="c-37258253">[24 more]</label></div><br/><div class="children"><div class="content">I asked ChatGPT how to add a JSDoc type to a Vue 2 prop and it gave me a wrong answer. There have been several times where I’ve asked it questions and it sprinkles in well disguised misinformation. These tools are impressive but they definitely have limitations.</div><br/><div id="37258522" class="c"><input type="checkbox" id="c-37258522" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258253">parent</a><span>|</span><a href="#37258439">next</a><span>|</span><label class="collapse" for="c-37258522">[-]</label><label class="expand" for="c-37258522">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re asking a model which is just a big unfocused and highly alignment taxed mush of the entire internet across all language, regardless of if its natural or computer, then (maybe) sliced across 8 experts.<p>It can also simulate a Zizek vs Wittgenstein argument over Russian literature.  the fact that it can usually write executing computer code is nothing short of magic to me.<p>What one would want is something like LLaMA2-Coding-Vue2, maybe with a LoRA for the library or concept.<p>I wrote a big word salad about all the other things you could do but suffice it to say there&#x27;s no reason anyone should be limited to a single pass on a monolithic without automatic context window augmentation nor automatic code checking &amp; regeneration &amp; model escalation (e.g. query out to a 200B coding model or something).</div><br/></div></div><div id="37258439" class="c"><input type="checkbox" id="c-37258439" checked=""/><div class="controls bullet"><span class="by">jstummbillig</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258253">parent</a><span>|</span><a href="#37258522">prev</a><span>|</span><a href="#37258805">next</a><span>|</span><label class="collapse" for="c-37258439">[-]</label><label class="expand" for="c-37258439">[1 more]</label></div><br/><div class="children"><div class="content">Everything has limitations. The linked piece is very much a statement about limited potential, not the current state. In this context, this stance is akin to saying &quot;I asked a 6yo this math question and it gave me a wrong answer, there&#x27;s definitely limitations&quot;. Sure – but who would use that observation to assess where the future potential cap of the kid is?</div><br/></div></div><div id="37258805" class="c"><input type="checkbox" id="c-37258805" checked=""/><div class="controls bullet"><span class="by">GolDDranks</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258253">parent</a><span>|</span><a href="#37258439">prev</a><span>|</span><a href="#37258394">next</a><span>|</span><label class="collapse" for="c-37258805">[-]</label><label class="expand" for="c-37258805">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t encounter a lot of &quot;small&quot;, one-copy-paste-size problems in my daily work that I couldn&#x27;t quickly solve myself, so I haven&#x27;t found a lot of use for ChatGPT while coding, yet. (I reckon this is changing though.)<p>However a few times there have been some mechanical refactoring-style grunt work I&#x27;ve delighted to have been able to let ChatGPT do. However, the rate ChatGPT is giving me subtly wrong results is just high enough that I end up cross-checking everything, and then it takes me a bit more time than it would&#x27;ve otherwise taken. Give it a year or two, maybe?</div><br/><div id="37259149" class="c"><input type="checkbox" id="c-37259149" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258805">parent</a><span>|</span><a href="#37258394">next</a><span>|</span><label class="collapse" for="c-37259149">[-]</label><label class="expand" for="c-37259149">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Give it a year or two, maybe?<p>Maybe? It’s not clear what would bring a qualitative improvement, barring massive amounts of new training data.</div><br/></div></div></div></div><div id="37258394" class="c"><input type="checkbox" id="c-37258394" checked=""/><div class="controls bullet"><span class="by">jasfi</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258253">parent</a><span>|</span><a href="#37258805">prev</a><span>|</span><a href="#37258276">next</a><span>|</span><label class="collapse" for="c-37258394">[-]</label><label class="expand" for="c-37258394">[11 more]</label></div><br/><div class="children"><div class="content">Are you using GPT-4? If not, it&#x27;s understandable.<p>If you don&#x27;t pay for ChatGPT, you get GPT-3.5. You can also get access to GPT-4 if you use the playground.</div><br/><div id="37258891" class="c"><input type="checkbox" id="c-37258891" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258394">parent</a><span>|</span><a href="#37258442">next</a><span>|</span><label class="collapse" for="c-37258891">[-]</label><label class="expand" for="c-37258891">[1 more]</label></div><br/><div class="children"><div class="content">gpt4 gets thing wrong as well, especially as soon as you are out of a well beaten path. I tried writing code with brain off and gpt4 on, and the terraform code was mostly right but didn&#x27;t work, python code for imports of recent libraries (llama-cpp-smth) were a complete fabrication, even if I gave the ai a documentation before hand, and we went in cycles around a problem for which it kept giving me the same solution and resulted in the same error (around python multiprocess, which is very picky aroud nested parallelism and method import)</div><br/></div></div><div id="37258442" class="c"><input type="checkbox" id="c-37258442" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258394">parent</a><span>|</span><a href="#37258891">prev</a><span>|</span><a href="#37258420">next</a><span>|</span><label class="collapse" for="c-37258442">[-]</label><label class="expand" for="c-37258442">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m using GTP-4 and it makes trivial errors all the time.<p>I asked it (actual names changed):<p>&quot;I run the Linux command line program &quot;foo&quot;. When I use the flags -xyz, I get results, but when I use -txyz I get nothing. What could this mean?&quot;<p>And it told me: &quot;The lack of results is because you didn&#x27;t use the -t flag&quot;.<p>Or I ask it some very basic music theory questions and it gets stuff wrong all the time, giving impossible answers.</div><br/><div id="37258627" class="c"><input type="checkbox" id="c-37258627" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258442">parent</a><span>|</span><a href="#37258770">next</a><span>|</span><label class="collapse" for="c-37258627">[-]</label><label class="expand" for="c-37258627">[3 more]</label></div><br/><div class="children"><div class="content">They definitely nerfed the hell out of GPT4 via the webUI at least.<p>Do you have API access?  the old model there still gives me very good results.</div><br/><div id="37258743" class="c"><input type="checkbox" id="c-37258743" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258627">parent</a><span>|</span><a href="#37258770">next</a><span>|</span><label class="collapse" for="c-37258743">[-]</label><label class="expand" for="c-37258743">[2 more]</label></div><br/><div class="children"><div class="content">I also have API access, but this was from the web</div><br/><div id="37258790" class="c"><input type="checkbox" id="c-37258790" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258743">parent</a><span>|</span><a href="#37258770">next</a><span>|</span><label class="collapse" for="c-37258790">[-]</label><label class="expand" for="c-37258790">[1 more]</label></div><br/><div class="children"><div class="content">The web interface seems to be the one they notoriously nerf the most.  Far fewer complaints vs the API - though it is faster and more convenient.<p>I&#x27;d kill to have an easy, wont-get-me-banned-way to submit a query to both the UI and API at the same time and show the results in, say, meld or so.</div><br/></div></div></div></div></div></div><div id="37258770" class="c"><input type="checkbox" id="c-37258770" checked=""/><div class="controls bullet"><span class="by">dustymcp</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258442">parent</a><span>|</span><a href="#37258627">prev</a><span>|</span><a href="#37258420">next</a><span>|</span><label class="collapse" for="c-37258770">[-]</label><label class="expand" for="c-37258770">[1 more]</label></div><br/><div class="children"><div class="content">it really does, it came up with multiple wrong dockerfiles for me yesterday, but it seems to correct it when you tell it</div><br/></div></div></div></div><div id="37258420" class="c"><input type="checkbox" id="c-37258420" checked=""/><div class="controls bullet"><span class="by">andrepd</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258394">parent</a><span>|</span><a href="#37258442">prev</a><span>|</span><a href="#37258276">next</a><span>|</span><label class="collapse" for="c-37258420">[-]</label><label class="expand" for="c-37258420">[4 more]</label></div><br/><div class="children"><div class="content">Why is it always the same reply? Yes, GPT4 is as useless as GPT3.5 on any non trivial task.</div><br/><div id="37259030" class="c"><input type="checkbox" id="c-37259030" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258420">parent</a><span>|</span><a href="#37258768">next</a><span>|</span><label class="collapse" for="c-37259030">[-]</label><label class="expand" for="c-37259030">[1 more]</label></div><br/><div class="children"><div class="content">The WebUI was definitely nerfed but the API still seems ok.</div><br/></div></div><div id="37258768" class="c"><input type="checkbox" id="c-37258768" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258420">parent</a><span>|</span><a href="#37259030">prev</a><span>|</span><a href="#37258708">next</a><span>|</span><label class="collapse" for="c-37258768">[-]</label><label class="expand" for="c-37258768">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why is it always the same reply?<p>When there&#x27;s one definitive answer to something that people keep repeating there&#x27;s a slight chance that it&#x27;s actually true. Shocking, I know.</div><br/></div></div><div id="37258708" class="c"><input type="checkbox" id="c-37258708" checked=""/><div class="controls bullet"><span class="by">input_sh</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258420">parent</a><span>|</span><a href="#37258768">prev</a><span>|</span><a href="#37258276">next</a><span>|</span><label class="collapse" for="c-37258708">[-]</label><label class="expand" for="c-37258708">[1 more]</label></div><br/><div class="children"><div class="content">My guess is people feel the need to self-justify their $20&#x2F;month subscription.</div><br/></div></div></div></div></div></div><div id="37258276" class="c"><input type="checkbox" id="c-37258276" checked=""/><div class="controls bullet"><span class="by">seanthemon</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258253">parent</a><span>|</span><a href="#37258394">prev</a><span>|</span><a href="#37258489">next</a><span>|</span><label class="collapse" for="c-37258276">[-]</label><label class="expand" for="c-37258276">[4 more]</label></div><br/><div class="children"><div class="content">Curious, how does it do when you give it examples &#x2F; use playground.openai?<p>I find that no examples often leads to the same result as a befuddled junior, but with examples often it gains confidence. Also I find playground to give me much better code snippets than chat sometimes</div><br/><div id="37258331" class="c"><input type="checkbox" id="c-37258331" checked=""/><div class="controls bullet"><span class="by">cbozeman</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258276">parent</a><span>|</span><a href="#37258489">next</a><span>|</span><label class="collapse" for="c-37258331">[-]</label><label class="expand" for="c-37258331">[3 more]</label></div><br/><div class="children"><div class="content">You&#x27;ve identified the problem inherent in these models right now, though.<p>There&#x27;s a lot of &quot;extraneous&quot; information and details that <i>appear</i> useless and unrelated, but that long-time developers have tucked away in their brains (or really anyone who has done something at a high level for a long time), that turns out to be incredibly useful; generally these people don&#x27;t require examples - they just <i>know</i> what the right answer is, because they&#x27;ve been exposed to a variety of problems over a long career or lifespan.<p>That&#x27;s where LLMs <i>need to be</i> to be truly &quot;useful&quot;. I think if we get them to that point, we&#x27;ll really have something useful on our hands.</div><br/><div id="37258637" class="c"><input type="checkbox" id="c-37258637" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258331">parent</a><span>|</span><a href="#37258489">next</a><span>|</span><label class="collapse" for="c-37258637">[-]</label><label class="expand" for="c-37258637">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s where good money and societal upheaval will come up, private models for corporations trained on their entire codebase and documentation.<p>Both young and old shall feel the pain then.</div><br/><div id="37259267" class="c"><input type="checkbox" id="c-37259267" checked=""/><div class="controls bullet"><span class="by">HPsquared</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258637">parent</a><span>|</span><a href="#37258489">next</a><span>|</span><label class="collapse" for="c-37259267">[-]</label><label class="expand" for="c-37259267">[1 more]</label></div><br/><div class="children"><div class="content">The codebase and documentation usually don&#x27;t capture the full context of the development process. There is still a lot that isn&#x27;t written down.</div><br/></div></div></div></div></div></div></div></div><div id="37258489" class="c"><input type="checkbox" id="c-37258489" checked=""/><div class="controls bullet"><span class="by">ryoshu</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258253">parent</a><span>|</span><a href="#37258276">prev</a><span>|</span><a href="#37258909">next</a><span>|</span><label class="collapse" for="c-37258489">[-]</label><label class="expand" for="c-37258489">[3 more]</label></div><br/><div class="children"><div class="content">True. I can&#x27;t do a full table scan on an non-indexed column in a RDBMS with billions of rows on a single machine without it grinding to a halt.<p>Tools have limitations.</div><br/><div id="37258523" class="c"><input type="checkbox" id="c-37258523" checked=""/><div class="controls bullet"><span class="by">dclowd9901</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258489">parent</a><span>|</span><a href="#37258909">next</a><span>|</span><label class="collapse" for="c-37258523">[-]</label><label class="expand" for="c-37258523">[2 more]</label></div><br/><div class="children"><div class="content">Disingenuous: given the proper processing, you’d get a 100% deterministic and reliable answer.<p>How do you get that out of an LLM? What tool is any good if it doesn’t work 100% of the time predictably?</div><br/><div id="37258632" class="c"><input type="checkbox" id="c-37258632" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258523">parent</a><span>|</span><a href="#37258909">next</a><span>|</span><label class="collapse" for="c-37258632">[-]</label><label class="expand" for="c-37258632">[1 more]</label></div><br/><div class="children"><div class="content">Right now one generation is expensive on these big mainframe models.<p>Query many times on the right model(s) for the question and the correct answer will be there 99.999% of the time as the other hallucinations will be thrown out.</div><br/></div></div></div></div></div></div><div id="37258909" class="c"><input type="checkbox" id="c-37258909" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#37258015">root</a><span>|</span><a href="#37258253">parent</a><span>|</span><a href="#37258489">prev</a><span>|</span><a href="#37258676">next</a><span>|</span><label class="collapse" for="c-37258909">[-]</label><label class="expand" for="c-37258909">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT (3.5) is not state of the art</div><br/></div></div></div></div></div></div><div id="37258676" class="c"><input type="checkbox" id="c-37258676" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37258015">prev</a><span>|</span><a href="#37257809">next</a><span>|</span><label class="collapse" for="c-37258676">[-]</label><label class="expand" for="c-37258676">[1 more]</label></div><br/><div class="children"><div class="content">I am completely bewildered by the responses here.<p>GPT-3 is so good it could write code, or it could emulate an entire TV show to the point of lawsuit, or simulate an eternal debate between Herzog and Zizek. You could translate Bulgarian to Sindarin for heaven&#x27;s sake. And all of this comes at a 50% tax rate or so because of the alignment tax that OAI opted for. (which doesn&#x27;t even work because anyone who puts effort in can jailbreak it scarily well)<p>The real solution is not these monstrosities of the internet mushed together and taxed like a Belgian billionaire. It&#x27;s models and frameworks specific to what you want in a given query.<p>It was less than 24 hours ago that we finally got a local model that can do code generation well, and we also know that Meta has a far better one that they are holding back.<p>There is no reason that for any query you should be restricted to a single inference run on a single fixed model, and there is no reason that we shouldn&#x27;t perform a bunch of non-LLM processing on the output before the user sees it.<p>Switch between multiple models, fine-tune, or use LoRAs based on the query -- Python plots? Load llama-coding-python-plots. You like Plotly? Add -Plotly. Run the code in a sandbox (with hard kills on resources) and regenerate it if it does not meet standards.<p>You&#x27;re working in linguistics? Switch to a chat model that&#x27;s fine-tuned in the literature and codebase of that field.<p>There are a trillion ways to improve things; we&#x27;re basically at the cavemen-banging-rocks-together point.<p>Hell, I&#x27;m a sleep deprived ESL and i just invoked the monstrosity to fix my grammar and spelling for this post.  What a bloody waste of CO2.<p>If for nothing but to keep the Earth afloat we shouldn&#x27;t be using these huge closed source SaaS things unless we need them.  Repurpose them for SETI@Home or processing human genetics for healthcare, or something else that benefits mankind</div><br/></div></div><div id="37257809" class="c"><input type="checkbox" id="c-37257809" checked=""/><div class="controls bullet"><span class="by">jongjong</span><span>|</span><a href="#37258676">prev</a><span>|</span><a href="#37258321">next</a><span>|</span><label class="collapse" for="c-37257809">[-]</label><label class="expand" for="c-37257809">[4 more]</label></div><br/><div class="children"><div class="content">As impressive as AI is and what it can do. I&#x27;ve felt the same way in my last job. It was almost there; it was almost good enough such that we could almost ship the project but we didn&#x27;t. GPT3.5 was not good enough, GPT4 seemed like it was good enough in terms of accuracy but it was too slow and we were getting throttled like crazy. I lost my job over it. When I was worried about AI taking my job, I didn&#x27;t picture it like this.</div><br/><div id="37257897" class="c"><input type="checkbox" id="c-37257897" checked=""/><div class="controls bullet"><span class="by">jongjong</span><span>|</span><a href="#37257809">parent</a><span>|</span><a href="#37258321">next</a><span>|</span><label class="collapse" for="c-37257897">[-]</label><label class="expand" for="c-37257897">[3 more]</label></div><br/><div class="children"><div class="content">Our use case was that we needed to consider information from thousands of pages of documents to answer customer questions. I let GPT decide where to look based on content tables of the documents (thankfully each section was not more than ~500 words) and only fetched information from the relevant sections to let GPT answer the user&#x27;s question. GPT3.5 was fast enough to be usable but often inaccurate; it would ignore some information or get confused about simple mathematical comparisons in the user&#x27;s questions like &#x27;greater than versus less than&#x27;. GPT4 was good and potentially fast enough but the API throttling was too restrictive and it was not possible to feed it less information and still get a good, nuanced answer every time.<p>Actually the trick to get GPT to find the information based on table of contents worked really well in narrowing down the information for the second-stage summary (to answer the user&#x27;s question) but our use case nevertheless required a lot of information (often from multiple sections) with a lot of grey areas and nuance and the limited amount of throughout provided by GPT4 didn&#x27;t cut it.<p>It was frustrating that, aside from accuracy issues (which depended on the complexity of the question), it often seemed to work very well and fast with GPT3.5 but the exact same code did not meet usability expectations when we switched over to GPT4 due to slow speed (though the accuracy was awesome).<p>I only spent 1 month and a half on this project but management didn&#x27;t have the patience to wait for Open AI to remove GPT4 throttling and because they couldn&#x27;t see it working (at the speed they wanted), they had no reason to believe me that my solution was designed correctly... That&#x27;s startups I guess.<p>Anyway I still think there is a lot of hope for this technology and I&#x27;m confident that the problem can and will be solved. It was just unfortunate timing for me. Being an early adopter isn&#x27;t always a good thing.</div><br/><div id="37257987" class="c"><input type="checkbox" id="c-37257987" checked=""/><div class="controls bullet"><span class="by">ta988</span><span>|</span><a href="#37257809">root</a><span>|</span><a href="#37257897">parent</a><span>|</span><a href="#37258142">next</a><span>|</span><label class="collapse" for="c-37257987">[-]</label><label class="expand" for="c-37257987">[1 more]</label></div><br/><div class="children"><div class="content">Start your own company then, that&#x27;s a product people would use.<p>(I&#x27;m making my own and agree with you, it works)</div><br/></div></div><div id="37258142" class="c"><input type="checkbox" id="c-37258142" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#37257809">root</a><span>|</span><a href="#37257897">parent</a><span>|</span><a href="#37257987">prev</a><span>|</span><a href="#37258321">next</a><span>|</span><label class="collapse" for="c-37258142">[-]</label><label class="expand" for="c-37258142">[1 more]</label></div><br/><div class="children"><div class="content">From what you said your solution wasn&#x27;t designed correctly?<p>You should definitely have been using BM25 and SBERT for something like this, you definitely should have been asking 3.5 for structured output and doing any math yourself.<p>If these were answers from a fixed set of documents there&#x27;s also a ton of pre-processing you should have been doing.<p>-<p>I recently helped a friend with a problem of identifying a certain form of language in EDGAR sourced contracts. He had someone who tried feeding in entire documents into LLMs to find these and the result was some 20 minute search time.<p>I took a few minutes sitting with him to come up with a demo that used synthetic data and SBERT to process documents in less than 30 seconds. 99% of that was stuff you could do 2 years ago, the part the LLM helped with was creating buckets of synthetic data quickly, and even that could be done procedurally if you had more time.</div><br/></div></div></div></div></div></div><div id="37258321" class="c"><input type="checkbox" id="c-37258321" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#37257809">prev</a><span>|</span><a href="#37259219">next</a><span>|</span><label class="collapse" for="c-37258321">[-]</label><label class="expand" for="c-37258321">[3 more]</label></div><br/><div class="children"><div class="content">&quot;we are already at the tail end of the current wave of AI.&quot;<p>Is that really true? Generative AI spending this year just so far is 4x greater than last year, and the results of that spending haven&#x27;t been released yet. How can they conclude this?<p>Most &quot;predictions&quot; about the future I&#x27;ve seen assume that ChatGPT will stay the same and not improve for the next 10 years, or only marginally. Why they make this assumption, I don&#x27;t know, it seems to go against every past trend we&#x27;ve seen with machine learning scaling. There are even people who say LLMs have reached their limit because we&#x27;ve exhausted all the text data that exists, assuming that the only way for LLMs to improve is to blindly feed it more static data and that no other sources of improvements exist.</div><br/><div id="37259553" class="c"><input type="checkbox" id="c-37259553" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#37258321">parent</a><span>|</span><a href="#37258343">next</a><span>|</span><label class="collapse" for="c-37259553">[-]</label><label class="expand" for="c-37259553">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Generative AI spending this year just so far is 4x greater than last year<p>I&#x27;m sure they spent a lot of money looking for gold in the long rushes long before the gold was all gone too.</div><br/></div></div><div id="37258343" class="c"><input type="checkbox" id="c-37258343" checked=""/><div class="controls bullet"><span class="by">sharts</span><span>|</span><a href="#37258321">parent</a><span>|</span><a href="#37259553">prev</a><span>|</span><a href="#37259219">next</a><span>|</span><label class="collapse" for="c-37258343">[-]</label><label class="expand" for="c-37258343">[1 more]</label></div><br/><div class="children"><div class="content">I think they mean tail end of LLM innovation? As in, all the discovery has been done and so all that is left is just computing power and tweaks rather than breakthroughs.<p>I believe the OpenAI folks have already said something to that effect a while ago as well.<p>For end users, the results of tweaks&#x2F;computational power will seem like &quot;breakthrough&quot; to them but it&#x27;s fundamentally not.</div><br/></div></div></div></div><div id="37259219" class="c"><input type="checkbox" id="c-37259219" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#37258321">prev</a><span>|</span><a href="#37259481">next</a><span>|</span><label class="collapse" for="c-37259219">[-]</label><label class="expand" for="c-37259219">[1 more]</label></div><br/><div class="children"><div class="content">By the time AIs stop hallucinating, it will be effectively super human (i.e. much better) because humans hallucinate all the time. And some people are barely coherent. We&#x27;re holding AIs to a much higher standard than ourselves. And we move the goal posts all the time as well.<p>Let&#x27;s deconstruct that title. &quot;AI isn&#x27;t good enough&quot;. Good enough for what? Great example of moving the goal posts. Because anytime it fails to do whatever, it&#x27;s not good enough. But what about all the stuff it is good enough for that people are actually using it for already? It&#x27;s passing tests at a level most humans only manage very briefly after lots of intensive preparation. The knowledge slips away quickly after that.<p>The way I see it, there&#x27;s a long, rapidly growing list of stuff that AIs have nailed already and a list of things where it is clearly struggling. That list is shrinking.<p>Self driving gets cited a lot as something where AIs is failing. It&#x27;s hard to say that in a world where multiple companies are now operating self driving vehicles commercially in several cities across the US, China, and soon Europe. Are they perfect? No. Do they drive better than the average jerk on the road? Definitely; not even close. Most people simply suck at driving. That&#x27;s why traffic deaths are so common. Most of those deaths are caused by somebody with a drivers license proving that they shouldn&#x27;t have received one. Not quite a solved problem but at this point the question of when these things will be on the road in my city is more a matter of when than if. It already works in other cities. I don&#x27;t see what&#x27;s so special in mine that it couldn&#x27;t be replicated here. In other words, I expect the number of cities with autonomous vehicles to start exploding over the next few years. And who knows, Tesla might hit the good enough mark at some point as well. Again, the barrier is very low because humans aren&#x27;t held to the same standards. They&#x27;ll give drivers licenses to just about anyone.</div><br/></div></div><div id="37259481" class="c"><input type="checkbox" id="c-37259481" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#37259219">prev</a><span>|</span><a href="#37257913">next</a><span>|</span><label class="collapse" for="c-37259481">[-]</label><label class="expand" for="c-37259481">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the assertion that we&#x27;ve reached the end of current wave of AI is correct. It hasn&#x27;t even been rolled out to <i>anything</i> yet.<p>Once it is fully integrated into os&#x2F;browser&#x2F;corporate workspace and the MBA&#x27;s have thrown LLMs at every business problem they can think of then perhaps but right now it hasn&#x27;t even left high tech circles</div><br/></div></div><div id="37257913" class="c"><input type="checkbox" id="c-37257913" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#37259481">prev</a><span>|</span><a href="#37257462">next</a><span>|</span><label class="collapse" for="c-37257913">[-]</label><label class="expand" for="c-37257913">[12 more]</label></div><br/><div class="children"><div class="content">Very interesting article. IMHO a key factor in how the world changes in the next  10-20 years will be how far the current wave of AI, based on neural networks can go.<p>If scientists and engineers manage to implement autonomous cars and robots that can do basic human tasks like clean, wait and take care of the sick and elderly we will wake up in a brand new world. It will put a lot of stress on the basics of society, such as democracy and having to work for a salary.</div><br/><div id="37258109" class="c"><input type="checkbox" id="c-37258109" checked=""/><div class="controls bullet"><span class="by">andrewjl</span><span>|</span><a href="#37257913">parent</a><span>|</span><a href="#37258546">next</a><span>|</span><label class="collapse" for="c-37258109">[-]</label><label class="expand" for="c-37258109">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If scientists and engineers manage to implement autonomous cars and robots that can do basic human tasks like clean, wait and take care of the sick and elderly we will wake up in a brand new world. It will put a lot of stress on the basics of society, such as democracy and having to work for a salary.<p>Based on the trends TFA discusses we&#x27;ll be seeing severe social stress if basic tasks <i>don&#x27;t</i> get automated. All due to labor shortages. Focusing on alternative arrangements to salaried work is backwards, unless the goal is boost labor participation.<p>Current demographics are baked in for the next 30 years and only point to a greater shortfall of labor in the future.[1] $1,000 signing bonuses for fast food jobs start to look quaint pretty quickly.<p>[1] <a href="https:&#x2F;&#x2F;www.penguinrandomhouse.com&#x2F;books&#x2F;545397&#x2F;empty-planet-by-darrell-bricker-and-john-ibbitson&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.penguinrandomhouse.com&#x2F;books&#x2F;545397&#x2F;empty-planet...</a></div><br/><div id="37258977" class="c"><input type="checkbox" id="c-37258977" checked=""/><div class="controls bullet"><span class="by">trashtester</span><span>|</span><a href="#37257913">root</a><span>|</span><a href="#37258109">parent</a><span>|</span><a href="#37258546">next</a><span>|</span><label class="collapse" for="c-37258977">[-]</label><label class="expand" for="c-37258977">[1 more]</label></div><br/><div class="children"><div class="content">The only way we will NOT see severe social stress is if AI is able to barely keep up with the decline in labour supply.<p>My gut feeling is that it will either be too little or way too much.<p>Anyway, once they&#x27;re able to fully robot-ify the police force, social upheaval may become easy to deal with for those in power.</div><br/></div></div></div></div><div id="37258546" class="c"><input type="checkbox" id="c-37258546" checked=""/><div class="controls bullet"><span class="by">solumunus</span><span>|</span><a href="#37257913">parent</a><span>|</span><a href="#37258109">prev</a><span>|</span><a href="#37257991">next</a><span>|</span><label class="collapse" for="c-37258546">[-]</label><label class="expand" for="c-37258546">[2 more]</label></div><br/><div class="children"><div class="content">The human-like robot dream is a complete non starter for me, total science fiction. Unless economic reality changes radically it will always be cheaper to simply pay a human to do these jobs. There are already many jobs that could be replaced by robots but by and large they haven’t been because buying, maintaining and powering robots costs more than paying humans minimum wage, and this fact isn’t changing any time soon. The type of robots you’re envisioning are even more complex and expensive… Do you really think a human-like robot with some level of useful general AI is going to be cheaper to build, maintain and run then low skilled workers?</div><br/><div id="37258603" class="c"><input type="checkbox" id="c-37258603" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#37257913">root</a><span>|</span><a href="#37258546">parent</a><span>|</span><a href="#37257991">next</a><span>|</span><label class="collapse" for="c-37258603">[-]</label><label class="expand" for="c-37258603">[1 more]</label></div><br/><div class="children"><div class="content">If not anything else there&#x27;s a shortage of human workers. Yes, it will be easier to manufacture and power robots, than to increase the number of human workers.</div><br/></div></div></div></div><div id="37257991" class="c"><input type="checkbox" id="c-37257991" checked=""/><div class="controls bullet"><span class="by">tuatoru</span><span>|</span><a href="#37257913">parent</a><span>|</span><a href="#37258546">prev</a><span>|</span><a href="#37258325">next</a><span>|</span><label class="collapse" for="c-37257991">[-]</label><label class="expand" for="c-37257991">[6 more]</label></div><br/><div class="children"><div class="content">The real world has many trillions of parameters.<p>Also, doing stuff in the real world is all about sensors. Progress on integrating millions of sensors into a robot has been slow.</div><br/><div id="37259092" class="c"><input type="checkbox" id="c-37259092" checked=""/><div class="controls bullet"><span class="by">trashtester</span><span>|</span><a href="#37257913">root</a><span>|</span><a href="#37257991">parent</a><span>|</span><a href="#37258736">next</a><span>|</span><label class="collapse" for="c-37259092">[-]</label><label class="expand" for="c-37259092">[1 more]</label></div><br/><div class="children"><div class="content">The problem is not integrating millions of sensors of the same type (like individual pixels in a camera), but rather to integrate 2-10 different types of sensors, like microphones, cameras, lidars and tactile&#x2F;temperature sensors.<p>Progress has been slow mosly because it&#x27;s been hand-written, such as the sensor fusion in the F-35.<p>While there are some attempts at using neural networks to do much of the integration (Like Tesla&#x27;s self driving) they&#x27;re mostly quite primitive, and lacks the kind of general understanding of the world that we&#x27;re starting to se in LLM&#x27;s.<p>We have started building multimodal neural networks, though, such as GPT-4&#x27;s ability to handle images, though. he next step is to add video, which is the mode that requires the greatest amount of compute, we will be able to integrate it with lower bandwidth sensors using the same techniques.<p>That would be where general purpose models start to become good enough to be deployed in robots. Let&#x27;s imagine your Tesla has the ability to reason about the world the way GPT-4 can (and with enough fine tuning that halicunations are gone), and that it can do that not only based on text, but also all the sensors of the car, then it might become able to handle situations outside its training set much better than today, possibly better than many humans.<p>Once we&#x27;re able to build multimodal models able to handle realtime video and s</div><br/></div></div><div id="37258736" class="c"><input type="checkbox" id="c-37258736" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37257913">root</a><span>|</span><a href="#37257991">parent</a><span>|</span><a href="#37259092">prev</a><span>|</span><a href="#37258003">next</a><span>|</span><label class="collapse" for="c-37258736">[-]</label><label class="expand" for="c-37258736">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The real world has many trillions of parameters.<p>But at any given time you&#x27;re probably only going to require some millions or double digit billions, unless you&#x27;re a nation state or something like that.</div><br/></div></div><div id="37258003" class="c"><input type="checkbox" id="c-37258003" checked=""/><div class="controls bullet"><span class="by">borissk</span><span>|</span><a href="#37257913">root</a><span>|</span><a href="#37257991">parent</a><span>|</span><a href="#37258736">prev</a><span>|</span><a href="#37258325">next</a><span>|</span><label class="collapse" for="c-37258003">[-]</label><label class="expand" for="c-37258003">[3 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t think a robot needs millions of sensors. 90% of the information that a human uses comes through the eyes - so just 2 sensors. Really in terms of doing most types of work all a robot would need is vision and hearing.</div><br/><div id="37258021" class="c"><input type="checkbox" id="c-37258021" checked=""/><div class="controls bullet"><span class="by">klipt</span><span>|</span><a href="#37257913">root</a><span>|</span><a href="#37258003">parent</a><span>|</span><a href="#37258095">next</a><span>|</span><label class="collapse" for="c-37258021">[-]</label><label class="expand" for="c-37258021">[1 more]</label></div><br/><div class="children"><div class="content">Q: But if the robot has no nose, how will it smell?<p>A: Awful!</div><br/></div></div><div id="37258095" class="c"><input type="checkbox" id="c-37258095" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#37257913">root</a><span>|</span><a href="#37258003">parent</a><span>|</span><a href="#37258021">prev</a><span>|</span><a href="#37258325">next</a><span>|</span><label class="collapse" for="c-37258095">[-]</label><label class="expand" for="c-37258095">[1 more]</label></div><br/><div class="children"><div class="content">Humans have an insane number of sensors all working with each other. The eyes are not just 2 sensors and a blind person can still function fairly well though with limitations.</div><br/></div></div></div></div></div></div></div></div><div id="37257462" class="c"><input type="checkbox" id="c-37257462" checked=""/><div class="controls bullet"><span class="by">ryanklee</span><span>|</span><a href="#37257913">prev</a><span>|</span><a href="#37258499">next</a><span>|</span><label class="collapse" for="c-37257462">[-]</label><label class="expand" for="c-37257462">[8 more]</label></div><br/><div class="children"><div class="content">&quot;We are quickly reaching the limits of current AI&quot;<p>So many words in this piece, but nothing to back up this primary assertion.</div><br/><div id="37258448" class="c"><input type="checkbox" id="c-37258448" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37257462">parent</a><span>|</span><a href="#37258597">next</a><span>|</span><label class="collapse" for="c-37258448">[-]</label><label class="expand" for="c-37258448">[1 more]</label></div><br/><div class="children"><div class="content">This, how absurd.  Do they think the future is always going to be in &quot;just add more parameters&quot;?<p>It&#x27;s obviously going to be smaller, efficient and such.  Even GPT4 itself is supposedly along these lines with MoE</div><br/></div></div><div id="37258597" class="c"><input type="checkbox" id="c-37258597" checked=""/><div class="controls bullet"><span class="by">imadj</span><span>|</span><a href="#37257462">parent</a><span>|</span><a href="#37258448">prev</a><span>|</span><a href="#37258389">next</a><span>|</span><label class="collapse" for="c-37258597">[-]</label><label class="expand" for="c-37258597">[2 more]</label></div><br/><div class="children"><div class="content">&gt; nothing to back up this primary assertion.<p>Well, he&#x27;s making a prediction, a speculation, a claim.<p>If it was as simple as `x-&gt;y` it would no longer be valuable.</div><br/><div id="37259179" class="c"><input type="checkbox" id="c-37259179" checked=""/><div class="controls bullet"><span class="by">Philpax</span><span>|</span><a href="#37257462">root</a><span>|</span><a href="#37258597">parent</a><span>|</span><a href="#37258389">next</a><span>|</span><label class="collapse" for="c-37259179">[-]</label><label class="expand" for="c-37259179">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but even then you&#x27;re expected to back up your speculation. There doesn&#x27;t seem to be anything within the article to support the claim that we&#x27;re at the tail end of development; just assumptions that today&#x27;s limitations will apply tomorrow.</div><br/></div></div></div></div><div id="37258389" class="c"><input type="checkbox" id="c-37258389" checked=""/><div class="controls bullet"><span class="by">system2</span><span>|</span><a href="#37257462">parent</a><span>|</span><a href="#37258597">prev</a><span>|</span><a href="#37257799">next</a><span>|</span><label class="collapse" for="c-37258389">[-]</label><label class="expand" for="c-37258389">[3 more]</label></div><br/><div class="children"><div class="content">For what it&#x27;s worth, I can actually tell the hype around AI died down a little. 8-10 months ago you&#x27;d hear AI from grandmas and their interest in playing with gpt. That&#x27;s gone. From programmer&#x27;s perspective, it is still useless. I can&#x27;t still get chatgpt to give me a useful ffmpeg or a basic php database script. I don&#x27;t know who is really using ai for what, other than crappy chatbots.<p>They are saying JSON works perfectly with chatgpt (gpt4) and still out of 10 queries I get 1 or 2 messed up. I can&#x27;t depend on it yet. Image generation is still terrible and useless, can&#x27;t use for programming, text-to-speech neural still sucks big time, not sure who is doing what with it. Almost feels like crypto-hype.</div><br/><div id="37258451" class="c"><input type="checkbox" id="c-37258451" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#37257462">root</a><span>|</span><a href="#37258389">parent</a><span>|</span><a href="#37259287">next</a><span>|</span><label class="collapse" for="c-37258451">[-]</label><label class="expand" for="c-37258451">[1 more]</label></div><br/><div class="children"><div class="content">Really?  I have a lot of success with bash and ffmpeg scripts.  I don&#x27;t even try to write them myself these days.<p>I don&#x27;t do JSON stuff much but either function calling or grammar based sampling should be able to force correct formatting if the issue is syntax.<p>ImageGen seemed like a solved problem to me with stable diffusion about 6 months ago or so, between LoRAs and the tons of models availble on sites like civitas..<p>SOTA Text to speech&#x2F;voice cloning is <i>scary</i> good, but it&#x27;s only available via SaaS like 11labs (perhaps just them).<p>One interesting weekend they allowed anyone to clone a voice (required only maybe 10-60s of audio) to say anything<p>I made Bob Ross read Neuromancer using 60 seconds of fuzzy audio from youtube, but 4chan made something like 20k fake audio recordings on vocaroo of everything horrible and hilarious you can think of.  Then they shut that off for good reason on Monday.<p>There are some cool applications there.  I watched an hour video about the talkshow wars between Leno and Conan and i couldn&#x27;t figure out what the voice was but it sounded like a smart old guy, apparently it was a weird clone of Biden.  Which means anyone can now make YouTube content with any kind of voice.  Which is bad for impersonation, but good if, say, you don&#x27;t like the sound of your voice and want to go for a different one (maybe an old timey radio broadcaster)<p>What definitely <i>has</i> become shittier is the quality of gpt4.  But that&#x27;s not an AI issue, that&#x27;s OpenAI being OpenAI.</div><br/></div></div><div id="37259287" class="c"><input type="checkbox" id="c-37259287" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#37257462">root</a><span>|</span><a href="#37258389">parent</a><span>|</span><a href="#37258451">prev</a><span>|</span><a href="#37257799">next</a><span>|</span><label class="collapse" for="c-37259287">[-]</label><label class="expand" for="c-37259287">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Image generation is still terrible and useless<p>Image generation is thriving and now an indispensible part of the creative process. The tools are fresh and still evolving, but the impact even in this early stage is ridiculous. You can easily take rough sketches and have it spit out fully fleshed out colored prototypes. Depending on your perspective it&#x27;s either an insane productivity-multiplier or scary as f-ck or both.<p>Look at <a href="https:&#x2F;&#x2F;civitai.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;civitai.com</a> for a taste. Look around. You really believe this is terrible and useless? Most of these images came straight from SD with some minor tweaking, usually upscaling. I think it&#x27;s quite something.<p>It&#x27;s not just MidJourney, it&#x27;s the entire ecosystem surrounding models like SD, ControlNet, etc. Some artists are swinging their fists, others shrug, but all are affected by it whether they like it or not and the damn thing is just getting started. SD came out in 2022. As a young aspiring artist I can imagine it&#x27;s hard to not feel like this whole thing is a massive punch in the gut.<p>Like an experienced and highly-skilled artist, it&#x27;s easy to shrug this off when you&#x27;re an accomplished programmer. It can&#x27;t replace <i>me</i>, right? Well, true. It&#x27;s a gradual thing, but the impact it has on junior programmers is undeniable. What it means for our branch if leagues of young people lose interest in the meticulous acquiring of technical and often arcane knowledge through &quot;manual programming&quot; is anybody&#x27;s guess. Maybe it&#x27;s a good thing, maybe it&#x27;s not.<p>&gt; Text-to-speech neural still sucks big time<p>This is not my experience at all. I am actually practicing French with it and it can pick up my weird accent. It&#x27;s ridiculous how good it has become in such a short time.<p>EDIT: Oh, sorry, I read it wrong. But in that case, the same thing applies. 11labs is insane and getting better. It fools many, many people on Youtube. The Bark project is also scary at times. This is just getting started.<p>&gt; I can&#x27;t still get chatgpt to give me a useful ffmpeg or a basic php database script.<p>I believe these issues are at least for a significant fraction caused by the severely castrated and surprisingly lacking UI efforts from OpenAI. Just free-form &quot;talking&quot; with an LLM might be a good way to get grandma to use it, but as a professional programmer (or professional anything, really) it&#x27;s bordering on stupid.<p>The prompts and settings you use determine 90% of your success. OpenAI&#x27;s interface gives you <i>nothing</i>. They just recently introduced something like &quot;profiles&quot;, but it&#x27;s amateurish at best. It makes me feel like programming without IDE (and Vi&#x2F;Emacs).</div><br/></div></div></div></div></div></div><div id="37258499" class="c"><input type="checkbox" id="c-37258499" checked=""/><div class="controls bullet"><span class="by">nmca</span><span>|</span><a href="#37257462">prev</a><span>|</span><a href="#37258935">next</a><span>|</span><label class="collapse" for="c-37258499">[-]</label><label class="expand" for="c-37258499">[1 more]</label></div><br/><div class="children"><div class="content">This is nuanced and interesting, despite most likely being completely wrong - as others have mentioned, it&#x27;s predicted on LLMs being at the top of the sigmoid and they just ain&#x27;t.<p>Also, this goal-post-moving did crack me up rather:<p>&gt; Sure, it is terrific at using its statistical models to come up with textual passages that read better than the average human’s writing, but that’s not a particularly high hurdle.</div><br/></div></div><div id="37258935" class="c"><input type="checkbox" id="c-37258935" checked=""/><div class="controls bullet"><span class="by">arisAlexis</span><span>|</span><a href="#37258499">prev</a><span>|</span><a href="#37257620">next</a><span>|</span><label class="collapse" for="c-37258935">[-]</label><label class="expand" for="c-37258935">[1 more]</label></div><br/><div class="children"><div class="content">&gt;We are bumping against many of its &gt;limits<p>He keeps saying that as a fact with absolutely no proof and based his whole argument on it.</div><br/></div></div><div id="37257620" class="c"><input type="checkbox" id="c-37257620" checked=""/><div class="controls bullet"><span class="by">petermcneeley</span><span>|</span><a href="#37258935">prev</a><span>|</span><a href="#37257789">next</a><span>|</span><label class="collapse" for="c-37257620">[-]</label><label class="expand" for="c-37257620">[19 more]</label></div><br/><div class="children"><div class="content">&quot;too few people for all the jobs, for the most part&quot;
- Are wages going up?<p>&quot;But almost everywhere else needs people. Badly. Across retail, restaurants, manufacturing, trades, and on and on, companies are struggling to hire. &quot;
- Wow sounds like an exciting star trek future that I cant wait to be part of!<p>&quot;labor became more expensive than capital&quot;
- So wages must be going up right?<p>&quot;In essence, the authors show that for automation to have widespread benefits it must deliver high productivity gains to more than compensate for the high displacement of workers.&quot;
- the reason why this sentence makes no sense is because it is written in two frames at the same time. One of a planned economy and the other of capitalism.<p>&quot;We are in a middle zone, however, with AI able to displace huge numbers of workers quickly, but not provide compensatory and broader productivity benefits.&quot;
- But what about the horses?<p>I tried my best to find the central thesis of this rambling multi-tone work. I think it is difficult because it was written with too many different frames.</div><br/><div id="37259023" class="c"><input type="checkbox" id="c-37259023" checked=""/><div class="controls bullet"><span class="by">csydas</span><span>|</span><a href="#37257620">parent</a><span>|</span><a href="#37257693">next</a><span>|</span><label class="collapse" for="c-37259023">[-]</label><label class="expand" for="c-37259023">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a bit disappointed this part of the conversation is buried under everyone arguing about whether the article is right about AI or not, since the real interesting part of the article is why the author(s) seem to think that the reason McDonalds is doing signing bonuses is because people are just just not working, and the article never seems to really understand why people aren&#x27;t flocking to jobs colloquially known to be absolutely awful and shit jobs.<p>Similarly, I&#x27;m very disappointed that the discussions in the article focus so much on _replacement_ of these workers, but in terms of human replacement, it really seems like AI is better suited to displace management and executives, not the people who perform specialized and physical work.<p>AI should help people and extend their abilities, and right now it&#x27;s very good at that. It can be used to make our lives easier _now_, not replace us, and I think this is the real reason the article is so heavily discussed. I think the article explains how the author released a lot of the conclusions they did, and I agree, the author is jumping around way too fast and in my interpretation, making some very wild assertion in the article without further fleshing out their points.</div><br/></div></div><div id="37257693" class="c"><input type="checkbox" id="c-37257693" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#37257620">parent</a><span>|</span><a href="#37259023">prev</a><span>|</span><a href="#37257909">next</a><span>|</span><label class="collapse" for="c-37257693">[-]</label><label class="expand" for="c-37257693">[12 more]</label></div><br/><div class="children"><div class="content">Capital&#x27;s willingness to ride out labor shortages without increasing wages seems to have become substantially greater in the last couple of decades.<p>TIRED: labor shortage -&gt; wages rise!<p>WIRED: labor shortage -&gt; y&#x27;all work harder for maybe a bit of overtime or maybe not, and we&#x27;ll just absorb the complaints about customer service and product quality. Those damn employees aren&#x27;t getting a penny more!</div><br/><div id="37257886" class="c"><input type="checkbox" id="c-37257886" checked=""/><div class="controls bullet"><span class="by">wilg</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37257693">parent</a><span>|</span><a href="#37259042">next</a><span>|</span><label class="collapse" for="c-37257886">[-]</label><label class="expand" for="c-37257886">[10 more]</label></div><br/><div class="children"><div class="content">Wages are rising: <a href="https:&#x2F;&#x2F;www.axios.com&#x2F;2023&#x2F;07&#x2F;12&#x2F;real-wage-gains-inflation" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.axios.com&#x2F;2023&#x2F;07&#x2F;12&#x2F;real-wage-gains-inflation</a></div><br/><div id="37257997" class="c"><input type="checkbox" id="c-37257997" checked=""/><div class="controls bullet"><span class="by">tuatoru</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37257886">parent</a><span>|</span><a href="#37259042">next</a><span>|</span><label class="collapse" for="c-37257997">[-]</label><label class="expand" for="c-37257997">[9 more]</label></div><br/><div class="children"><div class="content">Just catching up to years of undershooting inflation. In real terms still worse than 1969.</div><br/><div id="37258125" class="c"><input type="checkbox" id="c-37258125" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37257997">parent</a><span>|</span><a href="#37259042">next</a><span>|</span><label class="collapse" for="c-37258125">[-]</label><label class="expand" for="c-37258125">[8 more]</label></div><br/><div class="children"><div class="content">Definitely not. You wouldn&#x27;t like the food, cars and home appliances of 1969, and you really wouldn&#x27;t like the healthcare.</div><br/><div id="37258311" class="c"><input type="checkbox" id="c-37258311" checked=""/><div class="controls bullet"><span class="by">cbozeman</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37258125">parent</a><span>|</span><a href="#37258441">next</a><span>|</span><label class="collapse" for="c-37258311">[-]</label><label class="expand" for="c-37258311">[2 more]</label></div><br/><div class="children"><div class="content">The food of 1969? I&#x27;ve had it. It was my aunt&#x27;s cooking and my uncle&#x27;s butchering - shooting a hog right in the head and then gutting it, draining the blood, and prepping it to go onto a gigantic smoker, and it was delicious. And if you really didn&#x27;t feel like cooking food yourself, McDonald&#x27;s did exist back then, along with things like Kentucky Fried Chicken, Krystal, Burger King, etc.<p>They didn&#x27;t throw sugar into every single product on the market, either.<p>The home appliances? You mean blenders and toasters and refrigerators and mixers that would last 20-30 years before needing to be replaced because they were so well-engineered? Those 1969 home appliances? Like the KitchenAid K45 mixer that was released in 1962 and stayed in production for decades? Like the one my Mom got in 1971 that she still has today, whose motor still works fine, and the only thing that&#x27;s ever been done is 30 minutes of taking it apart and checking the worm drive gears and re-greasing them? Those 1969 appliances??<p>And the cars? Yeah those were kinda shitty compared to what we have now.<p>For the most part though, you&#x27;re not just off-base on the food and appliances, you&#x27;re <i>hilariously</i> off-base.</div><br/><div id="37258422" class="c"><input type="checkbox" id="c-37258422" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37258311">parent</a><span>|</span><a href="#37258441">next</a><span>|</span><label class="collapse" for="c-37258422">[-]</label><label class="expand" for="c-37258422">[1 more]</label></div><br/><div class="children"><div class="content">What % of houses do you remember having heating and indoor plumbing?<p><a href="https:&#x2F;&#x2F;www.aceee.org&#x2F;files&#x2F;proceedings&#x2F;2004&#x2F;data&#x2F;papers&#x2F;SS04_Panel1_Paper17.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.aceee.org&#x2F;files&#x2F;proceedings&#x2F;2004&#x2F;data&#x2F;papers&#x2F;SS0...</a><p>The aspics were pretty good though.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;70s_party" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;70s_party</a><p>Couldn&#x27;t have had eg good Brussels sprouts though, we hadn&#x27;t invented them yet.</div><br/></div></div></div></div><div id="37258441" class="c"><input type="checkbox" id="c-37258441" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37258125">parent</a><span>|</span><a href="#37258311">prev</a><span>|</span><a href="#37258463">next</a><span>|</span><label class="collapse" for="c-37258441">[-]</label><label class="expand" for="c-37258441">[3 more]</label></div><br/><div class="children"><div class="content">Apples and oranges.<p>You would like a home from 1969.<p>You would like the salary saved from 1969.</div><br/><div id="37258635" class="c"><input type="checkbox" id="c-37258635" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37258441">parent</a><span>|</span><a href="#37258888">next</a><span>|</span><label class="collapse" for="c-37258635">[-]</label><label class="expand" for="c-37258635">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You would like a home from 1969.<p>As I live in California, I&#x27;ve seen &#x27;em. They&#x27;re not all Eichlers.<p>&gt; You would like the salary saved from 1969.<p>A tech worker makes more than 5 times the median 2023 personal income and their industry didn&#x27;t exist then, so I mean, I wouldn&#x27;t even if I could afford the house in Palo Alto.<p>And you wouldn&#x27;t want to say this to a racial minority or even someone in Appalachia.</div><br/></div></div><div id="37258888" class="c"><input type="checkbox" id="c-37258888" checked=""/><div class="controls bullet"><span class="by">jcparkyn</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37258441">parent</a><span>|</span><a href="#37258635">prev</a><span>|</span><a href="#37258463">next</a><span>|</span><label class="collapse" for="c-37258888">[-]</label><label class="expand" for="c-37258888">[1 more]</label></div><br/><div class="children"><div class="content">&gt;You would like a home from 1969<p>The average floor area per person (in the US) has roughly doubled since 1969. Not the most reliable source, but from skimming census data it seems to correlate: <a href="https:&#x2F;&#x2F;supplychenmanagement.com&#x2F;2018&#x2F;07&#x2F;15&#x2F;average-house-size&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;supplychenmanagement.com&#x2F;2018&#x2F;07&#x2F;15&#x2F;average-house-si...</a>. I&#x27;m personally not much a fan of large houses, but most people are.</div><br/></div></div></div></div><div id="37258463" class="c"><input type="checkbox" id="c-37258463" checked=""/><div class="controls bullet"><span class="by">Tanjreeve</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37258125">parent</a><span>|</span><a href="#37258441">prev</a><span>|</span><a href="#37259042">next</a><span>|</span><label class="collapse" for="c-37258463">[-]</label><label class="expand" for="c-37258463">[2 more]</label></div><br/><div class="children"><div class="content">Why do you think there is a zero sum choice between real terms purchasing power increases and the technology we have today? (Also worth noting I&#x27;d happily take a lot of goods from a time where they were built to last)</div><br/><div id="37258599" class="c"><input type="checkbox" id="c-37258599" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37258463">parent</a><span>|</span><a href="#37259042">next</a><span>|</span><label class="collapse" for="c-37258599">[-]</label><label class="expand" for="c-37258599">[1 more]</label></div><br/><div class="children"><div class="content">There isn&#x27;t a choice, the original post is incorrect.<p><a href="https:&#x2F;&#x2F;fred.stlouisfed.org&#x2F;series&#x2F;DSPIC96" rel="nofollow noreferrer">https:&#x2F;&#x2F;fred.stlouisfed.org&#x2F;series&#x2F;DSPIC96</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="37259042" class="c"><input type="checkbox" id="c-37259042" checked=""/><div class="controls bullet"><span class="by">KirillPanov</span><span>|</span><a href="#37257620">root</a><span>|</span><a href="#37257693">parent</a><span>|</span><a href="#37257886">prev</a><span>|</span><a href="#37257909">next</a><span>|</span><label class="collapse" for="c-37259042">[-]</label><label class="expand" for="c-37259042">[1 more]</label></div><br/><div class="children"><div class="content">&gt; we&#x27;ll just absorb the complaints about customer service and product quality<p>AKA our economy consists entirely of monopolies.</div><br/></div></div></div></div><div id="37257980" class="c"><input type="checkbox" id="c-37257980" checked=""/><div class="controls bullet"><span class="by">evrydayhustling</span><span>|</span><a href="#37257620">parent</a><span>|</span><a href="#37257909">prev</a><span>|</span><a href="#37259484">next</a><span>|</span><label class="collapse" for="c-37257980">[-]</label><label class="expand" for="c-37257980">[1 more]</label></div><br/><div class="children"><div class="content">I was particularly puzzled by the 2x2.  High productivity is a no brainer, but why should we necessarily seek high displacement as its own goal?  Low displacement would increase employment and GDP, is that not flourishing?<p>And what&#x27;s with using the research scientists who authored Transformers as examples of surplus  middle management?  Google generated  1.4M per employee in 2022, second only to Apple.  Armchair engineers will say they could do as well with a handful of employees, but if this is &quot;low productivity&quot; then sign me up.</div><br/></div></div><div id="37259484" class="c"><input type="checkbox" id="c-37259484" checked=""/><div class="controls bullet"><span class="by">barrysteve</span><span>|</span><a href="#37257620">parent</a><span>|</span><a href="#37257980">prev</a><span>|</span><a href="#37258119">next</a><span>|</span><label class="collapse" for="c-37259484">[-]</label><label class="expand" for="c-37259484">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get it. McDonalds can fully automate their restaurants and chooses not to.<p>There is a crisis in housing and house prices, but we are not automating house production.<p>The electric car revolution is hitting growth barriers, waiting for cities to electrify enough to support a full car fleet.<p>None of the problems are primarily technological, they are a failure of resource discovery and electrical infrastructure.<p>But resource exploitation has got a bad rap and men are not populating materials science, geology, agriculture, ect at university.<p>We don&#x27;t need manufacturing, restaurants and trades that can be automated (or made efficient) with technology.<p>We need more resources and more material wealth, for labour, to labour towards.</div><br/></div></div><div id="37258119" class="c"><input type="checkbox" id="c-37258119" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#37257620">parent</a><span>|</span><a href="#37259484">prev</a><span>|</span><a href="#37258222">next</a><span>|</span><label class="collapse" for="c-37258119">[-]</label><label class="expand" for="c-37258119">[1 more]</label></div><br/><div class="children"><div class="content">Wages are going up and they are going up faster at the low end.</div><br/></div></div><div id="37258222" class="c"><input type="checkbox" id="c-37258222" checked=""/><div class="controls bullet"><span class="by">paulpauper</span><span>|</span><a href="#37257620">parent</a><span>|</span><a href="#37258119">prev</a><span>|</span><a href="#37257789">next</a><span>|</span><label class="collapse" for="c-37258222">[-]</label><label class="expand" for="c-37258222">[1 more]</label></div><br/><div class="children"><div class="content">Employers are always talking out of both sides of their mouths. They signal they want more workers yet are more choosy than ever in terms of pre-employment screening. it&#x27;s like someone who wants to work at McDonald&#x27;s has to go through   a huge gauntlet of background checks , interviews, and tests, yet companies insist thee is a shortage. maybe try lowering the requirements   a bit. And then once you get the job it&#x27;s more requirements and rules.  A lot of low-skilled ppl would rather just not work than deal with t all that crap for a minimum wage job. Part of the problem is maybe the quality of the  pool of workers has declined , so more screening needed.</div><br/></div></div></div></div><div id="37257789" class="c"><input type="checkbox" id="c-37257789" checked=""/><div class="controls bullet"><span class="by">YeBanKo</span><span>|</span><a href="#37257620">prev</a><span>|</span><a href="#37258784">next</a><span>|</span><label class="collapse" for="c-37257789">[-]</label><label class="expand" for="c-37257789">[1 more]</label></div><br/><div class="children"><div class="content">With few prompts I just wrote a small script with a bunch of openssl commands. Saved me an hour. And it works. And it even explained it. There is AGI and then there is “practically agi”. The latter has been achieved with LLMs.</div><br/></div></div><div id="37258784" class="c"><input type="checkbox" id="c-37258784" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#37257789">prev</a><span>|</span><a href="#37257946">next</a><span>|</span><label class="collapse" for="c-37258784">[-]</label><label class="expand" for="c-37258784">[1 more]</label></div><br/><div class="children"><div class="content">Just hook the LLMs to a robot arm and watch another, much larger wave of AI innovation</div><br/></div></div><div id="37257946" class="c"><input type="checkbox" id="c-37257946" checked=""/><div class="controls bullet"><span class="by">michaelmrose</span><span>|</span><a href="#37258784">prev</a><span>|</span><a href="#37258376">next</a><span>|</span><label class="collapse" for="c-37257946">[-]</label><label class="expand" for="c-37257946">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But almost everywhere else needs people. Badly. Across retail, restaurants, manufacturing, trades, and on and on, companies are struggling to hire. And this brings us back to the cross-country trip observation and that “signing bonus” sign in a McDonald’s window.<p>For jobs that pay just enough to not qualify for food stamps or Medicaid but not enough to buy food medicine and rent.<p>Previously it was more possible to earn little enough to qualify for benefits and live if not well but the numbers have become misaligned and don&#x27;t account for differences between expensive and cheaper parts of states.<p>Given present concerns the situation doesn&#x27;t change appreciably unless you go all in on automation implement UBI or both.</div><br/></div></div><div id="37258376" class="c"><input type="checkbox" id="c-37258376" checked=""/><div class="controls bullet"><span class="by">Madmallard</span><span>|</span><a href="#37257946">prev</a><span>|</span><a href="#37258193">next</a><span>|</span><label class="collapse" for="c-37258376">[-]</label><label class="expand" for="c-37258376">[1 more]</label></div><br/><div class="children"><div class="content">GPT4 has been beyond our expectations by a mile. What in the world is this person even on?</div><br/></div></div><div id="37258193" class="c"><input type="checkbox" id="c-37258193" checked=""/><div class="controls bullet"><span class="by">paulpauper</span><span>|</span><a href="#37258376">prev</a><span>|</span><label class="collapse" for="c-37258193">[-]</label><label class="expand" for="c-37258193">[2 more]</label></div><br/><div class="children"><div class="content"><i>The absence of human workers has become a limiting factor on economic growth in the U.S.</i><p>the problem is real GDP growth is flat or negative due to high inflation. having more labor would make this worse, if anything. job creation tends to be inflationary. from 2010-2021 saw strong economic  growth and low inflation, but now things suddenly changed  due to too much inflation, not a lack of growth.</div><br/><div id="37258540" class="c"><input type="checkbox" id="c-37258540" checked=""/><div class="controls bullet"><span class="by">WillPostForFood</span><span>|</span><a href="#37258193">parent</a><span>|</span><label class="collapse" for="c-37258540">[-]</label><label class="expand" for="c-37258540">[1 more]</label></div><br/><div class="children"><div class="content">The jobs are already created, unfilled. The lack of workers causes wages to go up which adds to inflation (e.g., the $1000 McDonalds bonus). But if you add more workers, you increase productivity, and reduce wage inflation.</div><br/></div></div></div></div></div></div></div></div></div></body></html>