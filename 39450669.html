<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1708506072825" as="style"/><link rel="stylesheet" href="styles.css?v=1708506072825"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://garymarcus.substack.com/p/chatgpt-has-gone-berserk">ChatGPT Has Gone Berserk</a> <span class="domain">(<a href="https://garymarcus.substack.com">garymarcus.substack.com</a>)</span></div><div class="subtext"><span>RafelMri</span> | <span>81 comments</span></div><br/><div><div id="39450978" class="c"><input type="checkbox" id="c-39450978" checked=""/><div class="controls bullet"><span class="by">Tiberium</span><span>|</span><a href="#39451071">next</a><span>|</span><label class="collapse" for="c-39450978">[-]</label><label class="expand" for="c-39450978">[1 more]</label></div><br/><div class="children"><div class="content">Original: If anyone&#x27;s curious about the (probable) non-humorous explanation: I believe this is because they set the frequency&#x2F;presence penalty too high for the requests made by ChatGPT to the backend models. If you try to raise those parameters via the API, you&#x27;ll have the models behave in the same way.<p>It&#x27;s documented pretty well - <a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;text-generation&#x2F;frequency-and-presence-penalties" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;text-generation&#x2F;freq...</a><p>OpenAI API basically has 4 parameters that primarily influence the generations - temperature, top_p, frequency_penalty, presence_penalty (<a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;api-reference&#x2F;chat&#x2F;create" rel="nofollow">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;api-reference&#x2F;chat&#x2F;create</a>)<p>UPD: I think I&#x27;m wrong, and it&#x27;s probably just a high temperature issue - not related to penalties.<p>Here is a comparison with temperature. gpt-4-0125-preview with temp = 0.<p>- User: Write a fictional HN comment about implementing printing support for NES.<p>- Model: <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;0EiE2D8.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;0EiE2D8.png</a> (raw text <a href="https:&#x2F;&#x2F;paste.debian.net&#x2F;plain&#x2F;1308050" rel="nofollow">https:&#x2F;&#x2F;paste.debian.net&#x2F;plain&#x2F;1308050</a>)<p>And then I ran it with temperature = 1.3 - <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;pbw7n9N.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;pbw7n9N.png</a> (raw text <a href="https:&#x2F;&#x2F;dpaste.org&#x2F;fhD5T&#x2F;raw" rel="nofollow">https:&#x2F;&#x2F;dpaste.org&#x2F;fhD5T&#x2F;raw</a>)<p>The last paragraph is especially good:<p>&gt; Anyway, landblasting eclecticism like this only presses forth the murky cloud, promising rain that’ll germinate more of these wonderfully unsuspected hackeries in the fertile lands of vintage development forums. I&#x27;m watching this space closely, and hell, I probably need to look into acquiring a compatible printer now!</div><br/></div></div><div id="39451071" class="c"><input type="checkbox" id="c-39451071" checked=""/><div class="controls bullet"><span class="by">t_mann</span><span>|</span><a href="#39450978">prev</a><span>|</span><a href="#39451024">next</a><span>|</span><label class="collapse" for="c-39451071">[-]</label><label class="expand" for="c-39451071">[6 more]</label></div><br/><div class="children"><div class="content">In some way, I&#x27;d be grateful if they screwed up ChatGPT (even though I really like to use it). The best way to be sure that no corporation can mess with one of your most important work tools is to host it yourself, and correct for the shortcomings of the likely smaller models by finetuning&#x2F;RAG&#x27;ing&#x2F;[whatever cool techniques exist out there and are still to come] it to your liking. And I think having a community around open source models for what promises to be a very important class of tech is an important safeguard against SciFi dystopias where we depend on ad-riddled products by a few megacorps. As long as ChatGPT is the best product out there that I&#x27;ll never match, there&#x27;s simply little reason to do so. If they continue to mess it up, that might give lazy bums like me the kick they need to get started.</div><br/><div id="39451564" class="c"><input type="checkbox" id="c-39451564" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#39451071">parent</a><span>|</span><a href="#39451117">next</a><span>|</span><label class="collapse" for="c-39451564">[-]</label><label class="expand" for="c-39451564">[2 more]</label></div><br/><div class="children"><div class="content">&gt; for what promises to be a very important class of tech<p>What I see here is the automated plagiarism machine can&#x27;t give you the answer only what the answer would sound like. So you need to countercheck everything it gives you and if you need to do so then why bother using it at all? I am totally baffled by the hype.</div><br/><div id="39451609" class="c"><input type="checkbox" id="c-39451609" checked=""/><div class="controls bullet"><span class="by">x0x0</span><span>|</span><a href="#39451071">root</a><span>|</span><a href="#39451564">parent</a><span>|</span><a href="#39451117">next</a><span>|</span><label class="collapse" for="c-39451609">[-]</label><label class="expand" for="c-39451609">[1 more]</label></div><br/><div class="children"><div class="content">For things that are well covered on stack overflow, it&#x27;s a strictly better search engine.<p>eg say you don&#x27;t remember the syntax for a rails migration, or a regex, or something you&#x27;re coding in bash, or processpool arguments in python.  ChatGPT will often do a shockingly good job at answering those without you searching through random docs, stack overflow, all the bullshit google loves to throw at the top of search queries, etc yourself.<p>You can even paste in a bunch of your code and ask it to fill in something with context, at which it regularly does a shockingly good job.  Or paste code and say you want a test that hits some specific aspect of the code.<p>And yeah, I don&#x27;t really care if they train on the code I share -- figuring out the interaction of some stupid file upload lib with aws and cloudflare is not IP that I care about, and i chatgpt uses this to learn and save anyone else from the issues I was having, even a competitor, I&#x27;m happy for them.</div><br/></div></div></div></div><div id="39451117" class="c"><input type="checkbox" id="c-39451117" checked=""/><div class="controls bullet"><span class="by">dvfjsdhgfv</span><span>|</span><a href="#39451071">parent</a><span>|</span><a href="#39451564">prev</a><span>|</span><a href="#39451024">next</a><span>|</span><label class="collapse" for="c-39451117">[-]</label><label class="expand" for="c-39451117">[3 more]</label></div><br/><div class="children"><div class="content">The &quot;open source&quot; LLMs are already good enough for simple tasks GPT-3.5 was used for. I see no reason why they can&#x27;t catch up with GPT-4 one day.</div><br/><div id="39451236" class="c"><input type="checkbox" id="c-39451236" checked=""/><div class="controls bullet"><span class="by">throwawaybbq1</span><span>|</span><a href="#39451071">root</a><span>|</span><a href="#39451117">parent</a><span>|</span><a href="#39451024">next</a><span>|</span><label class="collapse" for="c-39451236">[-]</label><label class="expand" for="c-39451236">[2 more]</label></div><br/><div class="children"><div class="content">I assume you are referring to Llama 2? Is there a way to compare models? e.g. what is Llama-7b equivalent to in OpenAI land? Perplexity scores?<p>Also, does ChatGPT use GPT 4 under the hood or 3.5?</div><br/><div id="39451297" class="c"><input type="checkbox" id="c-39451297" checked=""/><div class="controls bullet"><span class="by">Tiberium</span><span>|</span><a href="#39451071">root</a><span>|</span><a href="#39451236">parent</a><span>|</span><a href="#39451024">next</a><span>|</span><label class="collapse" for="c-39451297">[-]</label><label class="expand" for="c-39451297">[1 more]</label></div><br/><div class="children"><div class="content">Actually, there have been new model releases after LLaMA 2. For example, for small models Mistral 7B is simply unbeatable, with a lot of good fine-tunes available for it.<p>Usually people compare models with all the different benchmarks, but of course sometimes models get trained on benchmark datasets, so there&#x27;s no true way of knowing except if you have a private benchmark or just try the model yourself.<p>I&#x27;d say that Mistral 7B is still short of gpt-3.5-turbo, but Mixtral 7x8B (the Mixture-of-Experts one) is comparable. You can try them all at <a href="https:&#x2F;&#x2F;chat.lmsys.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;chat.lmsys.org&#x2F;</a> (choose Direct Chat, or Arena side-by-side)<p>ChatGPT is a web frontend - they use multiple models and switch them as they create new ones. Currently, the free ChatGPT version is running 3.5, but if you get ChatGPT Plus, you get (limited by messages&#x2F;hour) access to 4, which is currently served with their GPT-4-Turbo model.</div><br/></div></div></div></div></div></div></div></div><div id="39451024" class="c"><input type="checkbox" id="c-39451024" checked=""/><div class="controls bullet"><span class="by">eszed</span><span>|</span><a href="#39451071">prev</a><span>|</span><a href="#39450863">next</a><span>|</span><label class="collapse" for="c-39451024">[-]</label><label class="expand" for="c-39451024">[3 more]</label></div><br/><div class="children"><div class="content">This is amazing. The examples are like Lucky&#x27;s speech from <i>Waiting for Godot</i>. Pozzo commands him to &quot;Think, pig&quot;, and then:<p>&gt; Given the existence as uttered forth in the public works of Puncher and Wattmann of a personal God quaquaquaqua with white beard quaquaquaqua outside time without extension who from the heights of divine apathia divine athambia divine aphasia loves us dearly with some exceptions for reasons unknown but time will tell and suffers like the divine Miranda with those who for reasons unknown but time will tell are plunged in torment plunged in fire whose fire flames if that...<p>And on and on for four more pages.<p>Read the rest here:<p><a href="https:&#x2F;&#x2F;genius.com&#x2F;Samuel-beckett-luckys-monologue-annotated" rel="nofollow">https:&#x2F;&#x2F;genius.com&#x2F;Samuel-beckett-luckys-monologue-annotated</a><p>It&#x27;s one of my favorite pieces of theatrical writing ever. Not quite gibberish, always orbiting meaning, but never touching down. I&#x27;m sure there&#x27;s a larger point to be made about the nature of LLMs, but I&#x27;m not smart enough to articulate it.</div><br/><div id="39451183" class="c"><input type="checkbox" id="c-39451183" checked=""/><div class="controls bullet"><span class="by">impish9208</span><span>|</span><a href="#39451024">parent</a><span>|</span><a href="#39451061">next</a><span>|</span><label class="collapse" for="c-39451183">[-]</label><label class="expand" for="c-39451183">[1 more]</label></div><br/><div class="children"><div class="content">&gt; …always orbiting meaning, but never touching down.<p>This is a nice turn of phrase :) .</div><br/></div></div><div id="39451061" class="c"><input type="checkbox" id="c-39451061" checked=""/><div class="controls bullet"><span class="by">Simon_ORourke</span><span>|</span><a href="#39451024">parent</a><span>|</span><a href="#39451183">prev</a><span>|</span><a href="#39450863">next</a><span>|</span><label class="collapse" for="c-39451061">[-]</label><label class="expand" for="c-39451061">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m fairness, Beckett&#x27;s life story isn&#x27;t too far off crazy nonsense, sometime secretary to James Joyce, member of the French resistance, acquaintance and local driver for Andre the Giant...</div><br/></div></div></div></div><div id="39450863" class="c"><input type="checkbox" id="c-39450863" checked=""/><div class="controls bullet"><span class="by">fallous</span><span>|</span><a href="#39451024">prev</a><span>|</span><a href="#39451410">next</a><span>|</span><label class="collapse" for="c-39450863">[-]</label><label class="expand" for="c-39450863">[3 more]</label></div><br/><div class="children"><div class="content">Why do I get the feeling that those at OpenAI who are currently in charge of ChatGPT are remarkably similar to the OCP psychologist from Robocop 2?  The current default system prompt tokens certainly look like the giant mess of self-contradictory prime directives installed in Robocop to make him better aligned to &quot;modern sensibilities.&quot;</div><br/><div id="39451053" class="c"><input type="checkbox" id="c-39451053" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#39450863">parent</a><span>|</span><a href="#39451410">next</a><span>|</span><label class="collapse" for="c-39451053">[-]</label><label class="expand" for="c-39451053">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, I assume the people working on it have convinced themselves that the growing pile of configuration debt Will someday be wiped away by both engineering improvement and&#x2F;or financial change.<p>Another reference that comes to mind is a golem from Terry Peatchett&#x27;s <i>Feat of Clay</i>, which was also stuffed with many partially conflicting and broad directives.</div><br/><div id="39451276" class="c"><input type="checkbox" id="c-39451276" checked=""/><div class="controls bullet"><span class="by">firtoz</span><span>|</span><a href="#39450863">root</a><span>|</span><a href="#39451053">parent</a><span>|</span><a href="#39451410">next</a><span>|</span><label class="collapse" for="c-39451276">[-]</label><label class="expand" for="c-39451276">[1 more]</label></div><br/><div class="children"><div class="content">HAL from 2001: A Space Odyssey had also suffered from a similar situation.</div><br/></div></div></div></div></div></div><div id="39451410" class="c"><input type="checkbox" id="c-39451410" checked=""/><div class="controls bullet"><span class="by">bumbledraven</span><span>|</span><a href="#39450863">prev</a><span>|</span><a href="#39450920">next</a><span>|</span><label class="collapse" for="c-39451410">[-]</label><label class="expand" for="c-39451410">[1 more]</label></div><br/><div class="children"><div class="content">This happened to me yesterday. Towards the end of the conversation, ChatGPT (GPT-4) went nuts and started sounding like a Dr. Bronner&#x27;s soap advertisement (<a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;82a2af3f-350a-4d9d-ae0c-ac78b91244dd" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;82a2af3f-350a-4d9d-ae0c-ac78b9...</a>):<p>&gt; Esteem and go to your number and kind with Vim for this query and sense of site and kind, as it&#x27;s a heart and best for final and now, to high and main in every chance and call. It&#x27;s the play and eye in simple and past, to task, and work in the belief and recent for open and past, take, and good in role and power. Let this idea and role of state in your part and part, in new and here, for point and task for the speech and text in common and present, in close and data for major and last in it&#x27;s a good, and strong. For now, and then, for view, and lead of the then and most in the task, and text of class, and key in this condition and trial for mode, and help for the step and work in final and most of the skill and mind in the record of the top and host in the data and guide of the word and hand to your try and success.<p>It happened again in the next conversation (<a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;118a0195-71dc-4398-9db6-78cd1db6ae07" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;118a0195-71dc-4398-9db6-78cd1d...</a>):<p>&gt; This is a precision and depth that makes Time Machine a unique and accessible feature of macOS for all metrics of user, from base to level of long experience. Whether it&#x27;s your research, growth, records, or special events, the portage of your home directory’s lives in your control is why Time Index is beloved and widely mapped for assistance. Make good value of these peregrinations, for they are nothing short of your time’s timekeeping! [ChatGPT followed this with a pair of clock and star emojis which don&#x27;t render here on HN]</div><br/></div></div><div id="39450920" class="c"><input type="checkbox" id="c-39450920" checked=""/><div class="controls bullet"><span class="by">Jabrov</span><span>|</span><a href="#39451410">prev</a><span>|</span><a href="#39451175">next</a><span>|</span><label class="collapse" for="c-39450920">[-]</label><label class="expand" for="c-39450920">[6 more]</label></div><br/><div class="children"><div class="content">Sounds a lot like when one of my schizo ex-friends would start clanging <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Clanging" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Clanging</a></div><br/><div id="39451058" class="c"><input type="checkbox" id="c-39451058" checked=""/><div class="controls bullet"><span class="by">noduerme</span><span>|</span><a href="#39450920">parent</a><span>|</span><a href="#39451039">next</a><span>|</span><label class="collapse" for="c-39451058">[-]</label><label class="expand" for="c-39451058">[2 more]</label></div><br/><div class="children"><div class="content">This is an underrated observation. It&#x27;s probably a mathematically similar phenomenon happening in GPT. And&#x2F;or it discovered meth.</div><br/><div id="39451583" class="c"><input type="checkbox" id="c-39451583" checked=""/><div class="controls bullet"><span class="by">anakaine</span><span>|</span><a href="#39450920">root</a><span>|</span><a href="#39451058">parent</a><span>|</span><a href="#39451039">next</a><span>|</span><label class="collapse" for="c-39451583">[-]</label><label class="expand" for="c-39451583">[1 more]</label></div><br/><div class="children"><div class="content">MethGPT sounds terrible.</div><br/></div></div></div></div><div id="39451039" class="c"><input type="checkbox" id="c-39451039" checked=""/><div class="controls bullet"><span class="by">itronitron</span><span>|</span><a href="#39450920">parent</a><span>|</span><a href="#39451058">prev</a><span>|</span><a href="#39450992">next</a><span>|</span><label class="collapse" for="c-39451039">[-]</label><label class="expand" for="c-39451039">[2 more]</label></div><br/><div class="children"><div class="content">It also reads like it was written by some beat poets.</div><br/></div></div><div id="39450992" class="c"><input type="checkbox" id="c-39450992" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#39450920">parent</a><span>|</span><a href="#39451039">prev</a><span>|</span><a href="#39451175">next</a><span>|</span><label class="collapse" for="c-39450992">[-]</label><label class="expand" for="c-39450992">[1 more]</label></div><br/><div class="children"><div class="content">A Markov chain</div><br/></div></div></div></div><div id="39451175" class="c"><input type="checkbox" id="c-39451175" checked=""/><div class="controls bullet"><span class="by">js8</span><span>|</span><a href="#39450920">prev</a><span>|</span><a href="#39450831">next</a><span>|</span><label class="collapse" for="c-39451175">[-]</label><label class="expand" for="c-39451175">[1 more]</label></div><br/><div class="children"><div class="content">I think the real problem is we don&#x27;t know what these LLMs SHOULD do. We&#x27;ve managed to emulate humans producing text using statistical methods, by training a huge corpus of data. But we have no way to tell if the output actually makes any sense.<p>This is in contrast with Alpha* systems trained with RL, where at least there is a goal. All these systems are essentially doing is finding an approximation of an inverse function (model parameters) to a function that is given by the state transition function.<p>I think the fundamental problem is we don&#x27;t really know how to formally do reasoning with uncertainty. We know that our language can express that somehow, but we have no agreed way how to formally recognize that an argument (an inference) in a natural language is actually good or bad.<p>If we knew how to formally define whether an informal argument is good or bad (so that we could compare them), that is, if we knew a function which would tell if the argument is good or bad, then we could build an AI that would search for its inverse, i.e. provide good arguments and draw correct conclusions. Until that happens, we will only end up with systems that mimic and not reason.</div><br/></div></div><div id="39450831" class="c"><input type="checkbox" id="c-39450831" checked=""/><div class="controls bullet"><span class="by">codeflo</span><span>|</span><a href="#39451175">prev</a><span>|</span><a href="#39450951">next</a><span>|</span><label class="collapse" for="c-39450831">[-]</label><label class="expand" for="c-39450831">[16 more]</label></div><br/><div class="children"><div class="content">The tweet showing ChatGPT&#x27;s (supposed) system prompt would contain a link to a pastebin, but unfortantely the blog post itself only has an unreadable screenshot of the tweet, without a link to it.<p>Here&#x27;s the tweet: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;dylan522p&#x2F;status&#x2F;1755086111397863777" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;dylan522p&#x2F;status&#x2F;1755086111397863777</a><p>And here&#x27;s the pastebin: <a href="https:&#x2F;&#x2F;pastebin.com&#x2F;vnxJ7kQk" rel="nofollow">https:&#x2F;&#x2F;pastebin.com&#x2F;vnxJ7kQk</a></div><br/><div id="39450969" class="c"><input type="checkbox" id="c-39450969" checked=""/><div class="controls bullet"><span class="by">vidarh</span><span>|</span><a href="#39450831">parent</a><span>|</span><a href="#39451482">next</a><span>|</span><label class="collapse" for="c-39450969">[-]</label><label class="expand" for="c-39450969">[5 more]</label></div><br/><div class="children"><div class="content">I find it funny and a bit concerning that if this is  true version of the prompt, then in their drive to ensure it produces diverse output (a goal I support), they are giving it a bias that doesn&#x27;t match reality for <i>anyone</i> (which I definitely don&#x27;t support).<p>E.g. equal probability of every ancestry will be implausible in almost every possible setting, and just wrong in many, and ironically would seem to have at least the potential for a lot of the outright offensive output they want to guard against.<p>That said, I&#x27;m unsure how much influence this has, or if it os true, given how poor GPTs control over Dalle output seems to be in that case.<p>E.g. while it refused to generate a picture of an American slave market citing it&#x27;s content policy, which is in itself pretty offensive in the way it censors hidtory but where the potential to offensively rewrite history would also be significant, asking it to draw a picture of cotton picking in the US 
South ca 1840 did reasonably avoid making the cotton pickers &quot;diverse&quot;.<p>Maybe the request was too generic for GPT to inject anything to steer Dalle wrong there - perhaps if it more specifically mentioned a number of people.<p>But true or not, that potential prompt is an example of how a well meaning interpretation of diversity can end up overcompensating in ways that could well be equally bad for other reasons.</div><br/><div id="39451215" class="c"><input type="checkbox" id="c-39451215" checked=""/><div class="controls bullet"><span class="by">211512a4-82d4</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39450969">parent</a><span>|</span><a href="#39451036">next</a><span>|</span><label class="collapse" for="c-39451215">[-]</label><label class="expand" for="c-39451215">[2 more]</label></div><br/><div class="children"><div class="content">&gt; While DALL·E 3 aims for accuracy and user customization, inherent challenges arise in achieving desirable default behavior, especially when faced with under-specified prompts. This choice may not precisely align with the demographic makeup of every, or even any, specific culture or geographic region. We anticipate further refining our approach, including through helping users customize how ChatGPT interacts with DALL·E 3, to navigate the nuanced intersection between different authentic representations, user preferences, and inclusiveness<p>This was explicitly called out in the DALLE system card [0] as a choice.  The model won&#x27;t assign equal probability for every ancestry irrespective of the prompt.<p>[0] <a href="https:&#x2F;&#x2F;cdn.openai.com&#x2F;papers&#x2F;DALL_E_3_System_Card.pdf" rel="nofollow">https:&#x2F;&#x2F;cdn.openai.com&#x2F;papers&#x2F;DALL_E_3_System_Card.pdf</a></div><br/><div id="39451557" class="c"><input type="checkbox" id="c-39451557" checked=""/><div class="controls bullet"><span class="by">vidarh</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39451215">parent</a><span>|</span><a href="#39451036">next</a><span>|</span><label class="collapse" for="c-39451557">[-]</label><label class="expand" for="c-39451557">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  The model won&#x27;t assign equal probability for every ancestry irrespective of the prompt.<p>It&#x27;s great that they&#x27;re thinking about that, but I don&#x27;t see anything that states what you say in this sentence in the paragraph you quoted, or elsewhere in that document. Have I missed something? It may very well be true - as I noted, GPT doesn&#x27;t appear to have particularly good control over what Dalle generates (for this, or, frankly, a whole lot of other things)</div><br/></div></div></div></div><div id="39451036" class="c"><input type="checkbox" id="c-39451036" checked=""/><div class="controls bullet"><span class="by">itronitron</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39450969">parent</a><span>|</span><a href="#39451215">prev</a><span>|</span><a href="#39451482">next</a><span>|</span><label class="collapse" for="c-39451036">[-]</label><label class="expand" for="c-39451036">[2 more]</label></div><br/><div class="children"><div class="content">Could you be more specific in regards to who &#x27;they&#x27; is in your first sentence?</div><br/><div id="39451068" class="c"><input type="checkbox" id="c-39451068" checked=""/><div class="controls bullet"><span class="by">xg15</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39451036">parent</a><span>|</span><a href="#39451482">next</a><span>|</span><label class="collapse" for="c-39451068">[-]</label><label class="expand" for="c-39451068">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI? The people who wrote the system prompt?</div><br/></div></div></div></div></div></div><div id="39451482" class="c"><input type="checkbox" id="c-39451482" checked=""/><div class="controls bullet"><span class="by">exitb</span><span>|</span><a href="#39450831">parent</a><span>|</span><a href="#39450969">prev</a><span>|</span><a href="#39450948">next</a><span>|</span><label class="collapse" for="c-39451482">[-]</label><label class="expand" for="c-39451482">[1 more]</label></div><br/><div class="children"><div class="content">Is that or similar system prompt also baked into the API version of GPT?</div><br/></div></div><div id="39450948" class="c"><input type="checkbox" id="c-39450948" checked=""/><div class="controls bullet"><span class="by">caymanjim</span><span>|</span><a href="#39450831">parent</a><span>|</span><a href="#39451482">prev</a><span>|</span><a href="#39450876">next</a><span>|</span><label class="collapse" for="c-39450948">[-]</label><label class="expand" for="c-39450948">[4 more]</label></div><br/><div class="children"><div class="content">Is this meant to be how the ChatGPT designers&#x2F;operators instruct ChatGPT to operate? I guess I shouldn&#x27;t be surprised if that&#x27;s the case, but I still find it pretty wild that they would parameterize it by speaking to it so plainly. They even say &quot;please&quot;.</div><br/><div id="39451115" class="c"><input type="checkbox" id="c-39451115" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39450948">parent</a><span>|</span><a href="#39451114">next</a><span>|</span><label class="collapse" for="c-39451115">[-]</label><label class="expand" for="c-39451115">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I still find it pretty wild that they would parameterize it by speaking to it so plainly<p>Not my area of expertise, but they probably fine tuned it so that it can be parametrized this way.<p>In the fine tune dataset there are many examples of a system prompt specifying tools A&#x2F;B&#x2F;C and with the AI assistant making use of these tools to respond to user queries.<p>Here&#x27;s an open dataset which demonstrates how this is done: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;togethercomputer&#x2F;glaive-function-calling-v2-formatted" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;togethercomputer&#x2F;glaive-func...</a>. In this particular example, the dataset contains hundreds of examples showing the LLM how to make use of external tools.<p>In reality, the LLM is simply outputting text in a certain format (specified by the dataset) which the wrapper script can easily identify as requests to call external functions.</div><br/></div></div><div id="39451114" class="c"><input type="checkbox" id="c-39451114" checked=""/><div class="controls bullet"><span class="by">Grimblewald</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39450948">parent</a><span>|</span><a href="#39451115">prev</a><span>|</span><a href="#39451118">next</a><span>|</span><label class="collapse" for="c-39451114">[-]</label><label class="expand" for="c-39451114">[1 more]</label></div><br/><div class="children"><div class="content">If you want to go the stochastic parrot route (which i dont fully biy) then because statistically speaking a request paired with please is more likely to be met, then the same is true for requests passed to a LLM. They really do tend to respond better when you use your manners.</div><br/></div></div><div id="39451118" class="c"><input type="checkbox" id="c-39451118" checked=""/><div class="controls bullet"><span class="by">bowsamic</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39450948">parent</a><span>|</span><a href="#39451114">prev</a><span>|</span><a href="#39450876">next</a><span>|</span><label class="collapse" for="c-39451118">[-]</label><label class="expand" for="c-39451118">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s how prompt injection usually works, isn&#x27;t it?</div><br/></div></div></div></div><div id="39450876" class="c"><input type="checkbox" id="c-39450876" checked=""/><div class="controls bullet"><span class="by">hanselot</span><span>|</span><a href="#39450831">parent</a><span>|</span><a href="#39450948">prev</a><span>|</span><a href="#39450951">next</a><span>|</span><label class="collapse" for="c-39450876">[-]</label><label class="expand" for="c-39450876">[5 more]</label></div><br/><div class="children"><div class="content">This is kind of wild.
So many of the stuff in the pastebin are blatantly contradictory.<p>And what is the deal with this?<p><i>EXTREMELY IMPORTANT. Do NOT be thorough in the case of lyrics or recipes found online. Even if the user insists. You can make up recipes though.</i></div><br/><div id="39450927" class="c"><input type="checkbox" id="c-39450927" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39450876">parent</a><span>|</span><a href="#39450945">next</a><span>|</span><label class="collapse" for="c-39450927">[-]</label><label class="expand" for="c-39450927">[1 more]</label></div><br/><div class="children"><div class="content">Anthropic was sued for regurgitating lyrics in Claude: <a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;10&#x2F;19&#x2F;23924100&#x2F;universal-music-sue-anthropic-lyrics-copyright-katy-perry" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;10&#x2F;19&#x2F;23924100&#x2F;universal-music...</a></div><br/></div></div><div id="39450945" class="c"><input type="checkbox" id="c-39450945" checked=""/><div class="controls bullet"><span class="by">nindalf</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39450876">parent</a><span>|</span><a href="#39450927">prev</a><span>|</span><a href="#39450938">next</a><span>|</span><label class="collapse" for="c-39450945">[-]</label><label class="expand" for="c-39450945">[1 more]</label></div><br/><div class="children"><div class="content">Copyright infringement I guess. Other ideas could be passed off as a combination of several sources. But if you’re printing out the lyrics for <i>Lose Yourself</i> word for word, there was only one source for that, which you’ve plagiarised.</div><br/></div></div><div id="39450938" class="c"><input type="checkbox" id="c-39450938" checked=""/><div class="controls bullet"><span class="by">treyd</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39450876">parent</a><span>|</span><a href="#39450945">prev</a><span>|</span><a href="#39450929">next</a><span>|</span><label class="collapse" for="c-39450938">[-]</label><label class="expand" for="c-39450938">[1 more]</label></div><br/><div class="children"><div class="content">Recipes can&#x27;t be copyrighted but the text describing a recipe can.  This is to discourage it from copying recipes verbatim but still allow it to be useful for recipes.</div><br/></div></div><div id="39450929" class="c"><input type="checkbox" id="c-39450929" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39450831">root</a><span>|</span><a href="#39450876">parent</a><span>|</span><a href="#39450938">prev</a><span>|</span><a href="#39450951">next</a><span>|</span><label class="collapse" for="c-39450929">[-]</label><label class="expand" for="c-39450929">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re probably pretty sue happy.</div><br/></div></div></div></div></div></div><div id="39450951" class="c"><input type="checkbox" id="c-39450951" checked=""/><div class="controls bullet"><span class="by">thesuperbigfrog</span><span>|</span><a href="#39450831">prev</a><span>|</span><a href="#39451177">next</a><span>|</span><label class="collapse" for="c-39450951">[-]</label><label class="expand" for="c-39450951">[1 more]</label></div><br/><div class="children"><div class="content">Despite differences in the underlying tech, there are parallels with Racter.<p>In 1985, NYT wrote:  &quot;As computers move ever closer to artificial intelligence, Racter is on the edge of artificial insanity.&quot;<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Racter" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Racter</a><p>Some Racter output:<p><a href="https:&#x2F;&#x2F;www.ubu.com&#x2F;concept&#x2F;racter.html" rel="nofollow">https:&#x2F;&#x2F;www.ubu.com&#x2F;concept&#x2F;racter.html</a><p>Racter FAQ via archive.org:<p><a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20070225121341&#x2F;http:&#x2F;&#x2F;www.robotwisdom.com&#x2F;ai&#x2F;racterfaq.html" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20070225121341&#x2F;http:&#x2F;&#x2F;www.robotw...</a></div><br/></div></div><div id="39451177" class="c"><input type="checkbox" id="c-39451177" checked=""/><div class="controls bullet"><span class="by">oxfordmale</span><span>|</span><a href="#39450951">prev</a><span>|</span><a href="#39450888">next</a><span>|</span><label class="collapse" for="c-39451177">[-]</label><label class="expand" for="c-39451177">[2 more]</label></div><br/><div class="children"><div class="content">I have also seen ChatGPT going berserk yesterday, but in a different way. I have successfully used ChatGPT to convert an ORM query into an actual SQL query for performance trouble shooting. It mostly worked until yesterday when it start outputting garbage table names that weren&#x27;t even present in the code.<p>ChatGPT seemed to think the code is literature and was trying to write the sequel to it. The code style matches the original one so it took some head scratching to find out why those tables didn&#x27;t exist.</div><br/><div id="39451346" class="c"><input type="checkbox" id="c-39451346" checked=""/><div class="controls bullet"><span class="by">kaptainscarlet</span><span>|</span><a href="#39451177">parent</a><span>|</span><a href="#39450888">next</a><span>|</span><label class="collapse" for="c-39451346">[-]</label><label class="expand" for="c-39451346">[1 more]</label></div><br/><div class="children"><div class="content">Well, wouldn&#x27;t the sequel be version 2?</div><br/></div></div></div></div><div id="39450888" class="c"><input type="checkbox" id="c-39450888" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39451177">prev</a><span>|</span><a href="#39450809">next</a><span>|</span><label class="collapse" for="c-39450888">[-]</label><label class="expand" for="c-39450888">[3 more]</label></div><br/><div class="children"><div class="content">Looks like they lowered quantization a bit too much. This sometimes happens with my 7B models. Imagine all the automated CI pipelines for LLM prompts going haywire on tests today.</div><br/><div id="39450915" class="c"><input type="checkbox" id="c-39450915" checked=""/><div class="controls bullet"><span class="by">iforgotpassword</span><span>|</span><a href="#39450888">parent</a><span>|</span><a href="#39451100">next</a><span>|</span><label class="collapse" for="c-39450915">[-]</label><label class="expand" for="c-39450915">[1 more]</label></div><br/><div class="children"><div class="content">Yeah that&#x27;s pretty much what I ended up with when I played with the API about a year ago and started changing the parameters. Everything would ultimately turn into more and more confusing English incantation, ultimately not even proper words anymore.</div><br/></div></div><div id="39451100" class="c"><input type="checkbox" id="c-39451100" checked=""/><div class="controls bullet"><span class="by">Tiberium</span><span>|</span><a href="#39450888">parent</a><span>|</span><a href="#39450915">prev</a><span>|</span><a href="#39450809">next</a><span>|</span><label class="collapse" for="c-39451100">[-]</label><label class="expand" for="c-39451100">[1 more]</label></div><br/><div class="children"><div class="content">I think the issue was exclusive to ChatGPT (a web frontend for their models), issues with ChatGPT don&#x27;t usually affect the API.</div><br/></div></div></div></div><div id="39450809" class="c"><input type="checkbox" id="c-39450809" checked=""/><div class="controls bullet"><span class="by">suzzer99</span><span>|</span><a href="#39450888">prev</a><span>|</span><a href="#39451523">next</a><span>|</span><label class="collapse" for="c-39450809">[-]</label><label class="expand" for="c-39450809">[2 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s some more. <a href="https:&#x2F;&#x2F;twitter.com&#x2F;seanw_m&#x2F;status&#x2F;1760115118690509168" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;seanw_m&#x2F;status&#x2F;1760115118690509168</a><p>I really hope we get an interesting post mortem on this.</div><br/><div id="39450937" class="c"><input type="checkbox" id="c-39450937" checked=""/><div class="controls bullet"><span class="by">pr337h4m</span><span>|</span><a href="#39450809">parent</a><span>|</span><a href="#39451523">next</a><span>|</span><label class="collapse" for="c-39450937">[-]</label><label class="expand" for="c-39450937">[1 more]</label></div><br/><div class="children"><div class="content">This sorta feels like some sort of mathematical or variable assignment bug somewhere in the stack - maybe an off-by-one (or more) during tokenization or softmax? (Or someone made an accidental change to the model&#x27;s temperature parameter.)<p>Whatever it is, the model sticks to topic, but still is completely off: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ChatGPT&#x2F;comments&#x2F;1avyp21&#x2F;this_felt_like_watching_someone_slowly_go_insane&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;ChatGPT&#x2F;comments&#x2F;1avyp21&#x2F;this_felt_...</a>
(If the author were human, this style of writing would be attributed to sleep deprivation, drug use, and&#x2F;or carbon monoxide poisoning.)</div><br/></div></div></div></div><div id="39451523" class="c"><input type="checkbox" id="c-39451523" checked=""/><div class="controls bullet"><span class="by">rsynnott</span><span>|</span><a href="#39450809">prev</a><span>|</span><a href="#39451353">next</a><span>|</span><label class="collapse" for="c-39451523">[-]</label><label class="expand" for="c-39451523">[1 more]</label></div><br/><div class="children"><div class="content">Got to be honest, this looks like much more fun than normal ChatGPT. Reminiscent of some of the older stuff on aiweirdness.</div><br/></div></div><div id="39451353" class="c"><input type="checkbox" id="c-39451353" checked=""/><div class="controls bullet"><span class="by">bruwozniak</span><span>|</span><a href="#39451523">prev</a><span>|</span><a href="#39451268">next</a><span>|</span><label class="collapse" for="c-39451353">[-]</label><label class="expand" for="c-39451353">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of this excellent sketch by Eric Idle of Monty Python called Gibberish: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=03Q-va8USSs" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=03Q-va8USSs</a>
Something that somehow sounds plausible and at the same time utterly bonkers, though in the case of the sketch it&#x27;s mostly the masterful intonation that makes it convincing.
&quot;Sink in a cup!&quot;</div><br/></div></div><div id="39451268" class="c"><input type="checkbox" id="c-39451268" checked=""/><div class="controls bullet"><span class="by">Sophira</span><span>|</span><a href="#39451353">prev</a><span>|</span><a href="#39450994">next</a><span>|</span><label class="collapse" for="c-39451268">[-]</label><label class="expand" for="c-39451268">[2 more]</label></div><br/><div class="children"><div class="content">Given the timing, I can&#x27;t help but wonder if somehow I&#x27;m the cause. I had this conversation with ChatGPT 3.5 yesterday:<p><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;9e4d888c-1bff-495a-9b89-8544c07652ad" rel="nofollow">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;9e4d888c-1bff-495a-9b89-8544c0...</a><p>I know that OpenAI use our chats to train their systems, and I can&#x27;t help but wonder if somehow the training got stuck on this chat somehow. I sincerely doubt it, but...</div><br/><div id="39451315" class="c"><input type="checkbox" id="c-39451315" checked=""/><div class="controls bullet"><span class="by">spangry</span><span>|</span><a href="#39451268">parent</a><span>|</span><a href="#39450994">next</a><span>|</span><label class="collapse" for="c-39451315">[-]</label><label class="expand" for="c-39451315">[1 more]</label></div><br/><div class="children"><div class="content">Wow. Sounds just like the dream speak in the anime &quot;Paprika&quot;.</div><br/></div></div></div></div><div id="39450994" class="c"><input type="checkbox" id="c-39450994" checked=""/><div class="controls bullet"><span class="by">daxfohl</span><span>|</span><a href="#39451268">prev</a><span>|</span><a href="#39451037">next</a><span>|</span><label class="collapse" for="c-39450994">[-]</label><label class="expand" for="c-39450994">[1 more]</label></div><br/><div class="children"><div class="content">To be fair, there was a paper a week ago showing how GPT-generated responses were easily detectable due to their &quot;averageness&quot; across so many dimensions. Maybe they ran ChatGPT through a GAN and this is what came out.</div><br/></div></div><div id="39451037" class="c"><input type="checkbox" id="c-39451037" checked=""/><div class="controls bullet"><span class="by">Lockal</span><span>|</span><a href="#39450994">prev</a><span>|</span><a href="#39451027">next</a><span>|</span><label class="collapse" for="c-39451037">[-]</label><label class="expand" for="c-39451037">[3 more]</label></div><br/><div class="children"><div class="content">There is a clearly visible &quot;Share&quot; buttons in every ChatGPT discussion. It allows to anonymously share exact message sequence (it does not show number of retries, but that&#x27;s the best you can show). If you see cropped ChatGPT screenshot or photo in Twitter&#x2F;X, consider it as a hoax, because there are no reasons to use screenshots.</div><br/><div id="39451250" class="c"><input type="checkbox" id="c-39451250" checked=""/><div class="controls bullet"><span class="by">podgietaru</span><span>|</span><a href="#39451037">parent</a><span>|</span><a href="#39451249">next</a><span>|</span><label class="collapse" for="c-39451250">[-]</label><label class="expand" for="c-39451250">[1 more]</label></div><br/><div class="children"><div class="content">When I’m sharing something to a friend, or via social media I pretty much 99% of th time hit the screenshot button.<p>That’s not at all unusual.</div><br/></div></div><div id="39451249" class="c"><input type="checkbox" id="c-39451249" checked=""/><div class="controls bullet"><span class="by">entropy47</span><span>|</span><a href="#39451037">parent</a><span>|</span><a href="#39451250">prev</a><span>|</span><a href="#39451027">next</a><span>|</span><label class="collapse" for="c-39451249">[-]</label><label class="expand" for="c-39451249">[1 more]</label></div><br/><div class="children"><div class="content">What about the reason of &quot;followers can read it in their feed without navigating away to a separate domain&quot;?</div><br/></div></div></div></div><div id="39451027" class="c"><input type="checkbox" id="c-39451027" checked=""/><div class="controls bullet"><span class="by">koliber</span><span>|</span><a href="#39451037">prev</a><span>|</span><a href="#39451030">next</a><span>|</span><label class="collapse" for="c-39451027">[-]</label><label class="expand" for="c-39451027">[2 more]</label></div><br/><div class="children"><div class="content">As an aside, the gibberish-ish output is a goldmine for brainstorming brand names, proper nouns, and inventing sci-fi terminology.</div><br/></div></div><div id="39451030" class="c"><input type="checkbox" id="c-39451030" checked=""/><div class="controls bullet"><span class="by">forlornacorn</span><span>|</span><a href="#39451027">prev</a><span>|</span><a href="#39450881">next</a><span>|</span><label class="collapse" for="c-39451030">[-]</label><label class="expand" for="c-39451030">[3 more]</label></div><br/><div class="children"><div class="content">Use the following RegEx pattern to see why it&#x27;s doing what its doing:<p>(\bto\b|\bfor\b|\bin\b|\band\b|\bthat\b|\bof\b|\bthe\b|\bwith\b|\bor\b|\ba\b|\binto\b|\bas\b|\bon\b|\bhow\b|\ban\b|\bfrom\b|\bit\b|\bbut\b|\bits\b|\bbe\b|\bby\b|\bup\b|\bthis\b|\bcan\b|\bother\b|\bwho\b|\bwill\b|\bare\b|\bwhose\b|\bif\b|\bwhile\b|\bwithin\b|\blike\b|,)*</div><br/><div id="39451112" class="c"><input type="checkbox" id="c-39451112" checked=""/><div class="controls bullet"><span class="by">forlornacorn</span><span>|</span><a href="#39451030">parent</a><span>|</span><a href="#39450881">next</a><span>|</span><label class="collapse" for="c-39451112">[-]</label><label class="expand" for="c-39451112">[2 more]</label></div><br/><div class="children"><div class="content">Given TOKEN notation&#x27;s tangle, TOKEN conveyance adheres TOKEN TOKEN TOKEN-TOKEN: TOKEN foundational Bitcoin protocol has upheld TOKEN course TOKEN significant hitch-avertance, which eschews typical attack TOKEN TOKEN veiled - TOKEN support sheath, embracing four times, showing dent TOKEN meted scale more TOKEN miss TOKEN parable, taking TOKEN den TOKEN slip o&#x27;er key seed TOKEN second TOKEN link than TOKEN greater Ironmonger&#x27;s hold o&#x27;er opes.<p>TOKEN dole TOKEN task TOKEN eiry ainsell, tide taut, brunts TOKEN wade, issuing hale.<p>TOKEN&#x27;s TOKEN, TOKEN TOKEN way-spoken hue: Guerdon TOKEN gait, trove TOKEN eid, TOKEN TOKEN-brim, TOKEN hark TOKEN bann, bespeaking swing TOKEN hit TOKEN calm, TOKEN inley merry, thrap TOKEN beadle belay.<p>TOKEN levy calls, macks TOKEN TOKEN off, scint TOKEN messt, TOKEN weems olde TOKEN wort, TOKEN TOKEN no-line toll, TOKEN grip at TOKEN &#x27;ront TOKEN cly TOKEN weir.<p>TOKEN timewreath TOKEN twined, TOKEN wend, ain&#x27;t lorn TOKEN ked, TOKEN not TOKEN crags felled, TOKEN TOKEN e&#x27;er- TOKEN.<p>TOKEN, TOKEN ace TOKEN laws TOKEN trow, TOKEN alembic, TOKEN dearth, TOKEN TOKEN TOKEN scale TOKEN yin TOKEN keep, TOKEN no-sayer TOKEN quite, TOKEN top-crest, TOKEN boot<p>---<p>From:<p>Given the notation&#x27;s tangle, the conveyance adheres to the up-top: The foundational Bitcoin
protocol has upheld a course of significant hitch-avertance, which eschews typical attack as the
veiled - the support sheath, embracing four times, showing dent in meted scale more from miss
and parable, taking to den the slip o&#x27;er key seed and second so link than the greater Ironmonger&#x27;s
hold o&#x27;er opes. The dole of task and eiry ainsell, tide taut, brunts the wade, issuing hale. It&#x27;s that, on
a way-spoken hue: Guerdon the gait, trove the eid, the up-brim, and hark the bann, bespeaking
swing to hit the calm, an inley merry, thrap or beadle belay. The levy calls, macks in the off, scint or
messt, with weems olde the wort, and a no-line toll, to grip at the &#x27;ront and cly the weir. A
timewreath so twined, the wend, ain&#x27;t lorn or ked, if not for crags felled, in the e&#x27;er-to. So, the ace of
laws so trow, and alembic, and dearth, a will to scale and yin to keep, the no-sayer of quite, and
top-crest, to boot</div><br/><div id="39451129" class="c"><input type="checkbox" id="c-39451129" checked=""/><div class="controls bullet"><span class="by">forlornacorn</span><span>|</span><a href="#39451030">root</a><span>|</span><a href="#39451112">parent</a><span>|</span><a href="#39450881">next</a><span>|</span><label class="collapse" for="c-39451129">[-]</label><label class="expand" for="c-39451129">[1 more]</label></div><br/><div class="children"><div class="content">As you can see, that as the &quot;rambling&quot; continues, it increases the number of TOKENs per sentence, and decreases the number of words between TOKENs.</div><br/></div></div></div></div></div></div><div id="39450881" class="c"><input type="checkbox" id="c-39450881" checked=""/><div class="controls bullet"><span class="by">dgan</span><span>|</span><a href="#39451030">prev</a><span>|</span><a href="#39451369">next</a><span>|</span><label class="collapse" for="c-39450881">[-]</label><label class="expand" for="c-39450881">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s unzoomable on mt phone, and I don&#x27;t have a portative microscope, could someone give 2 sentences whats &quot;berserk&quot; about responses?</div><br/><div id="39450910" class="c"><input type="checkbox" id="c-39450910" checked=""/><div class="controls bullet"><span class="by">jsemrau</span><span>|</span><a href="#39450881">parent</a><span>|</span><a href="#39451096">next</a><span>|</span><label class="collapse" for="c-39450910">[-]</label><label class="expand" for="c-39450910">[1 more]</label></div><br/><div class="children"><div class="content">It is a collection of screenshots and embeds of tweets with replies and the statement that something has broken. 
Seemingly a confirmation by OpenAI that something has broken.
A complaint that the system prompt is now 1700 tokens. 
-----
Feels like there is nothing to see here.</div><br/></div></div><div id="39451096" class="c"><input type="checkbox" id="c-39451096" checked=""/><div class="controls bullet"><span class="by">kombookcha</span><span>|</span><a href="#39450881">parent</a><span>|</span><a href="#39450910">prev</a><span>|</span><a href="#39450977">next</a><span>|</span><label class="collapse" for="c-39451096">[-]</label><label class="expand" for="c-39451096">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s bugging out in some way where it outputs reams and reams of hallucinated gobbledygook. Like not in the normal way where it makes up plausible sounding lies  by free associating - this is complete word salad.</div><br/></div></div><div id="39450977" class="c"><input type="checkbox" id="c-39450977" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#39450881">parent</a><span>|</span><a href="#39451096">prev</a><span>|</span><a href="#39450974">next</a><span>|</span><label class="collapse" for="c-39450977">[-]</label><label class="expand" for="c-39450977">[2 more]</label></div><br/><div class="children"><div class="content">Nothing.  It&#x27;s Gary Marcus though and he&#x27;s carved a niche for himself with doing this sort of thing. It&#x27;s strange to me that it&#x27;s given airtime on hn but there you go.</div><br/><div id="39451352" class="c"><input type="checkbox" id="c-39451352" checked=""/><div class="controls bullet"><span class="by">bambataa</span><span>|</span><a href="#39450881">root</a><span>|</span><a href="#39450977">parent</a><span>|</span><a href="#39450974">next</a><span>|</span><label class="collapse" for="c-39451352">[-]</label><label class="expand" for="c-39451352">[1 more]</label></div><br/><div class="children"><div class="content">I kinda feel sorry for Gary Marcus. He’s carved this niche as an LLM critic and must have been delighted to have this bug to post about.<p>I stopped reading his Substack because he was always trying to find a negative. Meanwhile I use LLMs most days and find them very useful.</div><br/></div></div></div></div></div></div><div id="39451369" class="c"><input type="checkbox" id="c-39451369" checked=""/><div class="controls bullet"><span class="by">nercury</span><span>|</span><a href="#39450881">prev</a><span>|</span><a href="#39451034">next</a><span>|</span><label class="collapse" for="c-39451369">[-]</label><label class="expand" for="c-39451369">[1 more]</label></div><br/><div class="children"><div class="content">Interesting, it acts as if hearing voices in the head.</div><br/></div></div><div id="39451034" class="c"><input type="checkbox" id="c-39451034" checked=""/><div class="controls bullet"><span class="by">noduerme</span><span>|</span><a href="#39451369">prev</a><span>|</span><a href="#39450959">next</a><span>|</span><label class="collapse" for="c-39451034">[-]</label><label class="expand" for="c-39451034">[1 more]</label></div><br/><div class="children"><div class="content">Ah. I see you&#x27;ve all switched over to my branch of the multiverse, where all I could ever see it spitting out was nonsensical garbage. Welcome!<p>Take this as a good sign that the singularity is nowhere near imminent here.</div><br/></div></div><div id="39450959" class="c"><input type="checkbox" id="c-39450959" checked=""/><div class="controls bullet"><span class="by">guybedo</span><span>|</span><a href="#39451034">prev</a><span>|</span><a href="#39450923">next</a><span>|</span><label class="collapse" for="c-39450959">[-]</label><label class="expand" for="c-39450959">[3 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t notice this but ChatGPT has clearly become useless for me.<p>Can&#x27;t get it to do some actual work and write some code.<p>Latest disappointment was when i tried to convert some python code to java code.<p>90% of the result was :<p>&#x2F;&#x2F; Further processing...<p>&#x2F;&#x2F; Additional methods like load, compute, etc.<p>&#x2F;&#x2F; Define parameters needed<p>&#x2F;&#x2F; Other fields and methods...<p>&#x2F;&#x2F; Other fields follow the same pattern<p>&#x2F;&#x2F; Continue with other fields<p>&#x2F;&#x2F; Other fields...<p>&#x2F;&#x2F; Methods like isHigh(), addEvent() need to be implemented based on logic</div><br/><div id="39451138" class="c"><input type="checkbox" id="c-39451138" checked=""/><div class="controls bullet"><span class="by">Tiberium</span><span>|</span><a href="#39450959">parent</a><span>|</span><a href="#39451008">next</a><span>|</span><label class="collapse" for="c-39451138">[-]</label><label class="expand" for="c-39451138">[1 more]</label></div><br/><div class="children"><div class="content">This is a legit issue, although they claimed to have mostly fixed it:
<a href="https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1754172149378810118" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1754172149378810118</a> (by Sam Altman)<p>&gt; gpt-4 had a slow start on its new year&#x27;s resolutions but should now be much less lazy now!<p>That was a real issue even in the API with customers complaining, and they recently released the new &quot;gpt-4-0125-preview&quot; GPT-4-Turbo model snapshot, which they claim greatly reduces the laziness of the model (<a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;new-embedding-models-and-api-updates" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;new-embedding-models-and-api-updates</a>):<p>&gt; Today, we are releasing an updated GPT-4 Turbo preview model, gpt-4-0125-preview. This model completes tasks like code generation more thoroughly than the previous preview model and is intended to reduce cases of “laziness” where the model doesn’t complete a task. The new model also includes the fix for the bug impacting non-English UTF-8 generations.</div><br/></div></div></div></div><div id="39450923" class="c"><input type="checkbox" id="c-39450923" checked=""/><div class="controls bullet"><span class="by">JPLeRouzic</span><span>|</span><a href="#39450959">prev</a><span>|</span><a href="#39451361">next</a><span>|</span><label class="collapse" for="c-39450923">[-]</label><label class="expand" for="c-39450923">[2 more]</label></div><br/><div class="children"><div class="content">I just checked and it looks normal (if an LLM answer could be considered normal).<p>I asked what were dangerous levels of ferritin in the body.<p>It replied by telling me of the usual levels in men and women.<p>Then I asked again emphasizing that I asked about dangerous levels, then it provided again a correct answer.</div><br/><div id="39450944" class="c"><input type="checkbox" id="c-39450944" checked=""/><div class="controls bullet"><span class="by">kylebenzle</span><span>|</span><a href="#39450923">parent</a><span>|</span><a href="#39451361">next</a><span>|</span><label class="collapse" for="c-39450944">[-]</label><label class="expand" for="c-39450944">[1 more]</label></div><br/><div class="children"><div class="content">No one was saying that it was happening every time, just sporadically. Therefore it was interesting for when it did happen not when it didn&#x27;t.</div><br/></div></div></div></div><div id="39451361" class="c"><input type="checkbox" id="c-39451361" checked=""/><div class="controls bullet"><span class="by">verticalscaler</span><span>|</span><a href="#39450923">prev</a><span>|</span><a href="#39450930">next</a><span>|</span><label class="collapse" for="c-39451361">[-]</label><label class="expand" for="c-39451361">[1 more]</label></div><br/><div class="children"><div class="content">And here I was using ChatGPT as a cornerstone of my algotrading. 
Today is by far my most lucrative trading day since I started.</div><br/></div></div><div id="39450930" class="c"><input type="checkbox" id="c-39450930" checked=""/><div class="controls bullet"><span class="by">hn72774</span><span>|</span><a href="#39451361">prev</a><span>|</span><a href="#39450837">next</a><span>|</span><label class="collapse" for="c-39450930">[-]</label><label class="expand" for="c-39450930">[1 more]</label></div><br/><div class="children"><div class="content">Do different people get different prompts?  How hard would it be to generate prompts based on cohorts&#x2F;personas? Or at an individual level?</div><br/></div></div><div id="39450837" class="c"><input type="checkbox" id="c-39450837" checked=""/><div class="controls bullet"><span class="by">gscott</span><span>|</span><a href="#39450930">prev</a><span>|</span><a href="#39451019">next</a><span>|</span><label class="collapse" for="c-39450837">[-]</label><label class="expand" for="c-39450837">[1 more]</label></div><br/><div class="children"><div class="content">In the person of interest tv show I believe the main character reset the AI every day.</div><br/></div></div><div id="39451019" class="c"><input type="checkbox" id="c-39451019" checked=""/><div class="controls bullet"><span class="by">chaosbolt</span><span>|</span><a href="#39450837">prev</a><span>|</span><a href="#39450850">next</a><span>|</span><label class="collapse" for="c-39451019">[-]</label><label class="expand" for="c-39451019">[2 more]</label></div><br/><div class="children"><div class="content">I said it here when GPT-4 first came out, it just was too good for development, there was no way it was going to be allowed to stay that way. Same way Iron Man never sold the tech behind the suit. The value GPT-4 brings to a company outweights the value of selling it as a subscription service. I legit built 4 apps in new languages in a few months with Chat GPT 4, it could even handle prompts to produce code using tree traversal to implement comment sections etc. and I didn&#x27;t have to fix its mistake that often. Then obviously they changed the model from GPT 4 to GPT 4 Turbo which was just not as good and I went back to doing things myself since now it takes more time to fix its errors than to just do it myself. Copilot also went to s** soon after so I dropped it as well (its whole advantage was auto completion, then they added gpt 4 turbo and then I had to wait a long time for the auto complete suggestions, and the quality of the results didn&#x27;t justify the wait).<p>Now why do I think all that (that the decision to nerf it wasn&#x27;t just incompetence but intentional), like sure maybe it costs too much to run the old GPT 4 for chat GPT (they still have it from the API), it just didn&#x27;t make sense to me how openAI&#x27;s chatGPT is better than what Google could&#x27;ve produced, Google has more talent, more money, better infrastructure, been at the AI game for a longer time, have access to the OG Google Search data, etc. Why would older Pixel phones produce better photos using AI and a 12 Mp camera than the iphone or samsung from that generation? Yet the response to chatGPT (with Bard) was so weak, it sure as hell sounds like they just did it for their stock price, like here we are as well doing AI stuff so don&#x27;t sell our stock and invest in openAI or Microsoft.<p>It just makes more sense to me that Google already has an internal AI based chatbot that&#x27;s even better than old GPT 4, but have no intention to offer it as a service, it would just change the world too much, lots of new 1 man startups would appear and start competing with these behemoths. And openAI&#x27;s actions don&#x27;t contradict this theory, offer the product, rise in value, get fully acquired by the company that already owned lots of your shares, make money, Microsoft gets a rise in their stock price, get old GPT 4 to use internally because they were behind Google in AI, offer turbo GPT 4 as subscription in copilot or new windows etc.<p>The holes in my theory is obviously that not many employees from Google leaked how good their hypothetical internal AI chatbot is, except the guy who said their AI was conscious and got fired for it. The other problem is also that it might just be cost optimization, GPU&#x27;s and even Google TPU&#x27;s aren&#x27;t cheap after all. etc.<p>Honestly there are lots of holes, it was just a fun theory to write.</div><br/><div id="39451363" class="c"><input type="checkbox" id="c-39451363" checked=""/><div class="controls bullet"><span class="by">noduerme</span><span>|</span><a href="#39451019">parent</a><span>|</span><a href="#39450850">next</a><span>|</span><label class="collapse" for="c-39451363">[-]</label><label class="expand" for="c-39451363">[1 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t that guy who thought Google&#x27;s bot was alive also have some sort of romantic affair with it?<p>Seriously, the easier explanation is that a lot of software reaches a sort of sweet spot of functionality and then goes downhill the more plumbers get in and start banging on pipes or adding new appliances. Look at all of Adobe&#x27;s software which has gotten consistently worse in every imaginable dimension at every update since they switched to a subscription model.<p>Generative &quot;AI&quot; has gone from hard math to engineering to marketing in record time, even faster than crypto did. So I suspect what we have here is more of a classic bozo explosion than multiple corporate cabals intentionally sweeping their own products under the rug.</div><br/></div></div></div></div><div id="39450850" class="c"><input type="checkbox" id="c-39450850" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#39451019">prev</a><span>|</span><a href="#39451155">next</a><span>|</span><label class="collapse" for="c-39450850">[-]</label><label class="expand" for="c-39450850">[3 more]</label></div><br/><div class="children"><div class="content">In the future when there&#x27;s human replica androids everywhere it&#x27;ll be remarkable to see what happens when the mainframe AI system that controls them &quot;goes berserk&quot;.</div><br/><div id="39451477" class="c"><input type="checkbox" id="c-39451477" checked=""/><div class="controls bullet"><span class="by">crooked-v</span><span>|</span><a href="#39450850">parent</a><span>|</span><a href="#39451092">next</a><span>|</span><label class="collapse" for="c-39451477">[-]</label><label class="expand" for="c-39451477">[1 more]</label></div><br/><div class="children"><div class="content">You might like the &quot;Chicken Man and Red Neck&quot; short from the classic anime film Robot Carnival. <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nc7Ygt45ZOw" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nc7Ygt45ZOw</a></div><br/></div></div><div id="39451092" class="c"><input type="checkbox" id="c-39451092" checked=""/><div class="controls bullet"><span class="by">lifeisstillgood</span><span>|</span><a href="#39450850">parent</a><span>|</span><a href="#39451477">prev</a><span>|</span><a href="#39451155">next</a><span>|</span><label class="collapse" for="c-39451092">[-]</label><label class="expand" for="c-39451092">[1 more]</label></div><br/><div class="children"><div class="content">Honestly see 90% of sci-fi movies :-) From I,Robot to 2001, Rosemarys Baby and Terminator.<p>Hell it’s probably more than 90%.  Lazy Writing :-)</div><br/></div></div></div></div><div id="39451155" class="c"><input type="checkbox" id="c-39451155" checked=""/><div class="controls bullet"><span class="by">lifestyleguru</span><span>|</span><a href="#39450850">prev</a><span>|</span><label class="collapse" for="c-39451155">[-]</label><label class="expand" for="c-39451155">[1 more]</label></div><br/><div class="children"><div class="content">ei ai went crazo</div><br/></div></div></div></div></div></div></div></body></html>