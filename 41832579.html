<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1728896464040" as="style"/><link rel="stylesheet" href="styles.css?v=1728896464040"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://sihyun.me/REPA/">20x faster convergence for diffusion models</a>Â <span class="domain">(<a href="https://sihyun.me">sihyun.me</a>)</span></div><div class="subtext"><span>vsroy</span> | <span>7 comments</span></div><br/><div><div id="41835103" class="c"><input type="checkbox" id="c-41835103" checked=""/><div class="controls bullet"><span class="by">fxtentacle</span><span>|</span><a href="#41834996">next</a><span>|</span><label class="collapse" for="c-41835103">[-]</label><label class="expand" for="c-41835103">[3 more]</label></div><br/><div class="children"><div class="content">The title is not wrong, but it also doesn&#x27;t feel correct either. What they do here is they use a pre-trained model to guide the training of a 2nd model. Of course, that massively speeds up training of the 2nd model. But it&#x27;s not like you can now train a diffusion model from scratch 20x faster. Instead, this is a technique for transplanting an existing model onto a different architecture so that you don&#x27;t have to start training from 0.</div><br/><div id="41835248" class="c"><input type="checkbox" id="c-41835248" checked=""/><div class="controls bullet"><span class="by">byyoung3</span><span>|</span><a href="#41835103">parent</a><span>|</span><a href="#41835174">next</a><span>|</span><label class="collapse" for="c-41835248">[-]</label><label class="expand" for="c-41835248">[1 more]</label></div><br/><div class="children"><div class="content">Yes, now it seems obvious, but before this it wasn&#x27;t clear that that would be something that could speed things up, due to the fact that the pretrained model was trained on a separate objective. It&#x27;s a brilliant idea that works amazingly.</div><br/></div></div><div id="41835174" class="c"><input type="checkbox" id="c-41835174" checked=""/><div class="controls bullet"><span class="by">zaptrem</span><span>|</span><a href="#41835103">parent</a><span>|</span><a href="#41835248">prev</a><span>|</span><a href="#41834996">next</a><span>|</span><label class="collapse" for="c-41835174">[-]</label><label class="expand" for="c-41835174">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I wonder whether this still saves compute if you include the compute used to train DINOV2&#x2F;whatever representation model you&#x27;d like to use?</div><br/></div></div></div></div><div id="41834996" class="c"><input type="checkbox" id="c-41834996" checked=""/><div class="controls bullet"><span class="by">gdiamos</span><span>|</span><a href="#41835103">prev</a><span>|</span><label class="collapse" for="c-41834996">[-]</label><label class="expand" for="c-41834996">[3 more]</label></div><br/><div class="children"><div class="content">Still waiting for a competitive diffusion llm</div><br/><div id="41835254" class="c"><input type="checkbox" id="c-41835254" checked=""/><div class="controls bullet"><span class="by">kleiba</span><span>|</span><a href="#41834996">parent</a><span>|</span><label class="collapse" for="c-41835254">[-]</label><label class="expand" for="c-41835254">[2 more]</label></div><br/><div class="children"><div class="content">Why?</div><br/><div id="41835379" class="c"><input type="checkbox" id="c-41835379" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#41834996">root</a><span>|</span><a href="#41835254">parent</a><span>|</span><label class="collapse" for="c-41835379">[-]</label><label class="expand" for="c-41835379">[1 more]</label></div><br/><div class="children"><div class="content">Diffusion works significantly better for images than sequential pixel generation, there is a good chance it would work better for language as well.<p>This used to be state of the art in 2016 and it&#x27;s basically how current LLMs work:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1601.06759" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1601.06759</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>