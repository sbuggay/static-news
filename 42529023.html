<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735376451365" as="style"/><link rel="stylesheet" href="styles.css?v=1735376451365"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.ams.org/notices/202501/rnoti-p6.pdf">Machine-Assisted Proof by Terence Tao [pdf]</a>Â <span class="domain">(<a href="https://www.ams.org">www.ams.org</a>)</span></div><div class="subtext"><span>jalcazar</span> | <span>5 comments</span></div><br/><div><div id="42529432" class="c"><input type="checkbox" id="c-42529432" checked=""/><div class="controls bullet"><span class="by">vessenes</span><span>|</span><a href="#42529555">next</a><span>|</span><label class="collapse" for="c-42529432">[-]</label><label class="expand" for="c-42529432">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d call this paper a &quot;big deal&quot; in that it is a normalization of, very fair summary of, and indication that there is a future for, LLMs in pure mathematics from one of its leading practitioners.<p>On HN here, we&#x27;ve spent the last few years talking and thinking a lot about LLMs, so the paper might not include much that would be surprising to math-curious HN&#x27;ers. However, there is a large cohort of research mathematicians out there that likely doesn&#x27;t know much about modern AI; Terence is saying there&#x27;s a little utility in last-gen models (GPT-4), and he expects a lot of utility out of combining next-gen models with Lean.<p>Again, not surprising if you read his blog, but I think publishing a full paper in AMS is a pretty important moment.</div><br/><div id="42529583" class="c"><input type="checkbox" id="c-42529583" checked=""/><div class="controls bullet"><span class="by">voxl</span><span>|</span><a href="#42529432">parent</a><span>|</span><a href="#42529555">next</a><span>|</span><label class="collapse" for="c-42529583">[-]</label><label class="expand" for="c-42529583">[1 more]</label></div><br/><div class="children"><div class="content">LLMs as they are I postulate would not work well for this. But, purpose built stochastic auto complete with a type checker to reject the junk? That could be actually useful. Funnily enough it&#x27;s also a domain of application that wouldn&#x27;t make any money at all. It would have to be an offline LLM that is reasonably efficient to execute locally.</div><br/></div></div></div></div><div id="42529555" class="c"><input type="checkbox" id="c-42529555" checked=""/><div class="controls bullet"><span class="by">smellybigbelly</span><span>|</span><a href="#42529432">prev</a><span>|</span><a href="#42529464">next</a><span>|</span><label class="collapse" for="c-42529555">[-]</label><label class="expand" for="c-42529555">[1 more]</label></div><br/><div class="children"><div class="content">One vision in the article that stood out for me, was how formal proof assistants allow for large teams to collaborate on proving theorems. Imagine what we could achieve if we could do mathematics as a hive mind!</div><br/></div></div><div id="42529464" class="c"><input type="checkbox" id="c-42529464" checked=""/><div class="controls bullet"><span class="by">jfmc</span><span>|</span><a href="#42529555">prev</a><span>|</span><label class="collapse" for="c-42529464">[-]</label><label class="expand" for="c-42529464">[1 more]</label></div><br/><div class="children"><div class="content">Actually, most of the paper seems a bit obvious from the computer science side. LLMs scale for really complex tasks, but they are neither correct nor complete. If combined with a tool that is correct (code verifiers, interactive theore provers), then we can get back a correct pipeline.</div><br/></div></div></div></div></div></div></div></body></html>