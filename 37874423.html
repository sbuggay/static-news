<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1697360454267" as="style"/><link rel="stylesheet" href="styles.css?v=1697360454267"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="http://litherum.blogspot.com/2023/10/implementing-gpus-programming-model-on.html">Implementing a GPU&#x27;s programming model on a CPU</a> <span class="domain">(<a href="http://litherum.blogspot.com">litherum.blogspot.com</a>)</span></div><div class="subtext"><span>luu</span> | <span>50 comments</span></div><br/><div><div id="37880832" class="c"><input type="checkbox" id="c-37880832" checked=""/><div class="controls bullet"><span class="by">samsartor</span><span>|</span><a href="#37880725">next</a><span>|</span><label class="collapse" for="c-37880832">[-]</label><label class="expand" for="c-37880832">[2 more]</label></div><br/><div class="children"><div class="content">I helped make a really cursed RISC-V version of this for a class project last year! The idea was to first compile each program to WASM using clang, and lower the WASM back to C but this time with all opcodes implemented in terms of the RISC-V vector intrinsics. That was a hack to be sure, but a surprisingly elegant one since
1. WASM&#x27;s structured control flow maps really well to lane masking
2. Stack and local values easily use &quot;structure of arrays&quot; layout
3. Heap values easily use &quot;array of structures&quot; layout<p>It never went anywhere but the code is still online if anyone wants to stare directly at the madness: <a href="https:&#x2F;&#x2F;gitlab.com&#x2F;samsartor&#x2F;wasm2simt" rel="nofollow noreferrer">https:&#x2F;&#x2F;gitlab.com&#x2F;samsartor&#x2F;wasm2simt</a></div><br/><div id="37887317" class="c"><input type="checkbox" id="c-37887317" checked=""/><div class="controls bullet"><span class="by">vmladenov</span><span>|</span><a href="#37880832">parent</a><span>|</span><a href="#37880725">next</a><span>|</span><label class="collapse" for="c-37887317">[-]</label><label class="expand" for="c-37887317">[1 more]</label></div><br/><div class="children"><div class="content">This is cool! If you wrote a blog post going detail about the insights, I&#x27;d read it</div><br/></div></div></div></div><div id="37880725" class="c"><input type="checkbox" id="c-37880725" checked=""/><div class="controls bullet"><span class="by">raphlinus</span><span>|</span><a href="#37880832">prev</a><span>|</span><a href="#37880669">next</a><span>|</span><label class="collapse" for="c-37880725">[-]</label><label class="expand" for="c-37880725">[3 more]</label></div><br/><div class="children"><div class="content">In addition to ISPC, some of this is also done in software fallback implementations of GPU APIs. In the open source world we have SwiftShader and Lavapipe, and on Windows we have WARP[1].<p>It&#x27;s sad to me that Larrabee didn&#x27;t catch on, as that might have been a path to a good parallel computer, one that has efficient parallel throughput like a GPU, but also agility more like a CPU, so you don&#x27;t need to batch things into huge dispatches and wait RPC-like latencies for them to complete. Apparently the main thing that sunk it was power consumption.<p>[1]: <a href="https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;windows&#x2F;win32&#x2F;direct3darticles&#x2F;directx-warp" rel="nofollow noreferrer">https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;windows&#x2F;win32&#x2F;direct3darti...</a></div><br/><div id="37883333" class="c"><input type="checkbox" id="c-37883333" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#37880725">parent</a><span>|</span><a href="#37880669">next</a><span>|</span><label class="collapse" for="c-37883333">[-]</label><label class="expand" for="c-37883333">[2 more]</label></div><br/><div class="children"><div class="content">The recent &quot;AI chip&quot; proposals (Tenstorrent, Esperanto Technologies etc.) seem to be quite similar to the old Larrabee design, except based on RISC-V as opposed to x86.  So we might see that happen after all.</div><br/><div id="37883490" class="c"><input type="checkbox" id="c-37883490" checked=""/><div class="controls bullet"><span class="by">raphlinus</span><span>|</span><a href="#37880725">root</a><span>|</span><a href="#37883333">parent</a><span>|</span><a href="#37880669">next</a><span>|</span><label class="collapse" for="c-37883490">[-]</label><label class="expand" for="c-37883490">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I&#x27;ve got my eye on those and am hopeful. Do you know of any meaty technical description of the programming model? All I&#x27;ve been able to find so far is fairly high level marketing material. At least for Tenstorrent Jim Keller has promised that the software stack will be open sourced, something I&#x27;m looking forward to.</div><br/></div></div></div></div></div></div><div id="37880669" class="c"><input type="checkbox" id="c-37880669" checked=""/><div class="controls bullet"><span class="by">bcatanzaro</span><span>|</span><a href="#37880725">prev</a><span>|</span><a href="#37880516">next</a><span>|</span><label class="collapse" for="c-37880669">[-]</label><label class="expand" for="c-37880669">[1 more]</label></div><br/><div class="children"><div class="content">Matt Pharr’s series of blogs on ISPC are worth reading:
<a href="https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;blog&#x2F;2018&#x2F;04&#x2F;30&#x2F;ispc-all" rel="nofollow noreferrer">https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;blog&#x2F;2018&#x2F;04&#x2F;30&#x2F;ispc-all</a></div><br/></div></div><div id="37880516" class="c"><input type="checkbox" id="c-37880516" checked=""/><div class="controls bullet"><span class="by">phdelightful</span><span>|</span><a href="#37880669">prev</a><span>|</span><a href="#37879888">next</a><span>|</span><label class="collapse" for="c-37880516">[-]</label><label class="expand" for="c-37880516">[1 more]</label></div><br/><div class="children"><div class="content">One of my colleague&#x27;s Ph.D. thesis was on how to achieve high-performance CPU implementations for bulk-synchronous programming models (&quot;GPU programming&quot;)<p><a href="http:&#x2F;&#x2F;impact.crhc.illinois.edu&#x2F;shared&#x2F;Thesis&#x2F;dissertation-hee-seok_kim.pdf" rel="nofollow noreferrer">http:&#x2F;&#x2F;impact.crhc.illinois.edu&#x2F;shared&#x2F;Thesis&#x2F;dissertation-h...</a></div><br/></div></div><div id="37879888" class="c"><input type="checkbox" id="c-37879888" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#37880516">prev</a><span>|</span><a href="#37880183">next</a><span>|</span><label class="collapse" for="c-37879888">[-]</label><label class="expand" for="c-37879888">[5 more]</label></div><br/><div class="children"><div class="content">See also: <a href="https:&#x2F;&#x2F;ispc.github.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;ispc.github.io&#x2F;</a></div><br/><div id="37880563" class="c"><input type="checkbox" id="c-37880563" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#37879888">parent</a><span>|</span><a href="#37879970">next</a><span>|</span><label class="collapse" for="c-37880563">[-]</label><label class="expand" for="c-37880563">[2 more]</label></div><br/><div class="children"><div class="content">ISPC is great software. It&#x27;s a shame in many ways Intel didn&#x27;t put more resources behind it.</div><br/><div id="37883697" class="c"><input type="checkbox" id="c-37883697" checked=""/><div class="controls bullet"><span class="by">boulos</span><span>|</span><a href="#37879888">root</a><span>|</span><a href="#37880563">parent</a><span>|</span><a href="#37879970">next</a><span>|</span><label class="collapse" for="c-37883697">[-]</label><label class="expand" for="c-37883697">[1 more]</label></div><br/><div class="children"><div class="content">As Bryan mentions in <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37880669">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37880669</a>, I would read Matt&#x27;s post-Intel and post-Google write up of <i>why</i> Intel didn&#x27;t really invest.<p><a href="https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;blog&#x2F;2018&#x2F;04&#x2F;30&#x2F;ispc-all" rel="nofollow noreferrer">https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;blog&#x2F;2018&#x2F;04&#x2F;30&#x2F;ispc-all</a> if you don&#x27;t want to follow the comment link again :).</div><br/></div></div></div></div></div></div><div id="37880183" class="c"><input type="checkbox" id="c-37880183" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#37879888">prev</a><span>|</span><a href="#37882833">next</a><span>|</span><label class="collapse" for="c-37880183">[-]</label><label class="expand" for="c-37880183">[26 more]</label></div><br/><div class="children"><div class="content">This so-called GPU programming model has existed many decades before the appearance of the first GPUs, but at that time the compilers were not so good like the CUDA compilers, so the burden for a programmer was greater.<p>As another poster has already mentioned, there exists a compiler for CPUs which has been inspired by CUDA and which has been available for many years: ISPC (Implicit SPMD Program Compiler), at <a href="https:&#x2F;&#x2F;github.com&#x2F;ispc&#x2F;ispc">https:&#x2F;&#x2F;github.com&#x2F;ispc&#x2F;ispc</a> .<p>NVIDIA has the very annoying habit of using a lot of terms that are different from those that have been previously used in computer science for decades. The worst is that NVIDIA has not invented new words, but they have frequently reused words that have been widely used with other meanings.<p>SIMT (Single-Instruction Multiple Thread) is not the worst term coined by NVIDIA, but there was no need for yet another acronym. For instance they could have used SPMD (Single Program, Multiple Data Stream), which dates from 1988, two decades before CUDA.<p>Moreover, SIMT is the same thing that was called &quot;array of processes&quot; by C.A.R. Hoare in August 1978 (in &quot;Communicating Sequential Processes&quot;), or &quot;replicated parallel&quot; by Occam in 1985 or &quot;PARALLEL DO&quot; by &quot;OpenMP Fortran&quot; in 1997-10 or &quot;parallel for&quot; by &quot;OpenMP C and C++&quot; in 1998-10.<p>Each so-called CUDA kernel is just the body of a &quot;parallel for&quot; (which is multi-dimensional, like in Fortran).<p>The only (but extremely important) innovation brought by CUDA is that the compiler is smart enough so that the programmer does not need to know the structure of the processor, i.e. how many cores it has and how many SIMD lanes each core has. The CUDA compiler distributes automatically the work over the available SIMD lanes and available cores and in most cases the programmer does not care whether two executions of the function that must be executed for each data item are done on two different cores or on two different SIMD lanes of the same core.<p>This distribution of the work over SIMD lanes and over cores is simple when the SIMD operations are maskable, like in GPUs or in AVX-512 a.k.a. AVX10 or in ARM SVE. When masking is not available, like in AVX2 or Armv8-A, the implementation of conditional statements and expressions is more complicated.</div><br/><div id="37881486" class="c"><input type="checkbox" id="c-37881486" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#37880183">parent</a><span>|</span><a href="#37880546">next</a><span>|</span><label class="collapse" for="c-37881486">[-]</label><label class="expand" for="c-37881486">[4 more]</label></div><br/><div class="children"><div class="content">SIMT and SIMD are different things. It&#x27;s fortunate that they have different names.<p>A GPU is a single instruction multiple data machine. That&#x27;s what the predicated vector operations are. 32 floats at a time, each with a disable bit.<p>Cuda is a single instruction multiple thread language. You write code in terms of one float and branching on booleans, as if it was a CPU, with some awkward intrinsics for accessing the vector units in the GPU.<p>That is, the programming model of a GPU ISA and that of Cuda are not the same. The GPU gives you vector instructions. Cuda gives you (mostly) scalar instructions and a compiler that deals with this mismatch, lowering branches to changes in exec mask and so forth.<p>With my numerical library hat on, I hate this. Programming a simd machine through a simt language means trying to get the compiler to transform the control flow into the thing you could easily write using vector instructions.<p>With my compiler implementer hat on, I hate this. It gives you two control flow graphs intertwined and a really bad time in register allocation.<p>It&#x27;s not totally clear to me why simt won out over writing the vector operations. I&#x27;m certainly in the minority opinion here.</div><br/><div id="37888077" class="c"><input type="checkbox" id="c-37888077" checked=""/><div class="controls bullet"><span class="by">alphablended</span><span>|</span><a href="#37880183">root</a><span>|</span><a href="#37881486">parent</a><span>|</span><a href="#37882196">next</a><span>|</span><label class="collapse" for="c-37888077">[-]</label><label class="expand" for="c-37888077">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s not totally clear to me why simt won out over writing the vector operations.<p>From the user side, it is probably simpler to write an algorithm once without vectors, and have a compiler translate it to every vector ISA it supports, rather than to deal with each ISA by hand.<p>Besides, in many situations, having the algorithm executed sequentially or in parallel is irrelevant to the algorithm itself, so why introduce that concern?<p>&gt; I&#x27;m certainly in the minority opinion here.<p>There are definitely more userland programmers than compiler&#x2F;numerical library ones.</div><br/></div></div><div id="37882196" class="c"><input type="checkbox" id="c-37882196" checked=""/><div class="controls bullet"><span class="by">shihab</span><span>|</span><a href="#37880183">root</a><span>|</span><a href="#37881486">parent</a><span>|</span><a href="#37888077">prev</a><span>|</span><a href="#37882102">next</a><span>|</span><label class="collapse" for="c-37882196">[-]</label><label class="expand" for="c-37882196">[1 more]</label></div><br/><div class="children"><div class="content">I think it boils down to which GPGPU camp you are in, AI or HPC.<p>AI has relatively simple workflow, less thread divergence, so the SIMT abstractions add very little value. HPC workflow on the other hand is lot more complex. Writing a good simulation program for example, is going to get inhumanly complex with just SIMD.</div><br/></div></div><div id="37882102" class="c"><input type="checkbox" id="c-37882102" checked=""/><div class="controls bullet"><span class="by">pca006132</span><span>|</span><a href="#37880183">root</a><span>|</span><a href="#37881486">parent</a><span>|</span><a href="#37882196">prev</a><span>|</span><a href="#37880546">next</a><span>|</span><label class="collapse" for="c-37882102">[-]</label><label class="expand" for="c-37882102">[1 more]</label></div><br/><div class="children"><div class="content">I guess that a lot of people are uncomfortable thinking about vector instructions, and dealing with masks manually? And for vector instructions you need to align things properly, pad the arrays such that they are of the right size, that people are not used to I guess.</div><br/></div></div></div></div><div id="37880546" class="c"><input type="checkbox" id="c-37880546" checked=""/><div class="controls bullet"><span class="by">mattpharr</span><span>|</span><a href="#37880183">parent</a><span>|</span><a href="#37881486">prev</a><span>|</span><a href="#37880413">next</a><span>|</span><label class="collapse" for="c-37880546">[-]</label><label class="expand" for="c-37880546">[1 more]</label></div><br/><div class="children"><div class="content">Also related as far as the programming model: C* on Connection Machines and the C dialect used on MasPar systems in the 1980s.<p>There is some discussion in the ispc paper: <a href="https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;assets&#x2F;ispc.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;pharr.org&#x2F;matt&#x2F;assets&#x2F;ispc.pdf</a></div><br/></div></div><div id="37880413" class="c"><input type="checkbox" id="c-37880413" checked=""/><div class="controls bullet"><span class="by">kllrnohj</span><span>|</span><a href="#37880183">parent</a><span>|</span><a href="#37880546">prev</a><span>|</span><a href="#37881657">next</a><span>|</span><label class="collapse" for="c-37880413">[-]</label><label class="expand" for="c-37880413">[2 more]</label></div><br/><div class="children"><div class="content">DirectX 8 added programmable shaders as we mostly know it today in 2000 with directx 9&#x27;s shader model 2.0 really solidifying things in 2002.<p>CUDA didn&#x27;t show up until 2007.</div><br/><div id="37887816" class="c"><input type="checkbox" id="c-37887816" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#37880183">root</a><span>|</span><a href="#37880413">parent</a><span>|</span><a href="#37881657">next</a><span>|</span><label class="collapse" for="c-37887816">[-]</label><label class="expand" for="c-37887816">[1 more]</label></div><br/><div class="children"><div class="content">Except that shaders predate DirectX 8 by several decades.<p>Two major examples,<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;TMS34010" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;TMS34010</a><p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;RenderMan_Shading_Language" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;RenderMan_Shading_Language</a><p>Also in DirectX 8, it wasn&#x27;t as we know them today, because Assembly was the only programming language.<p>Nowadays CUDA does C, C++, Fortran, Python JIT in the box, and has partner collaborations for Haskell, Java, Julia, C#.</div><br/></div></div></div></div><div id="37881657" class="c"><input type="checkbox" id="c-37881657" checked=""/><div class="controls bullet"><span class="by">hasmanean</span><span>|</span><a href="#37880183">parent</a><span>|</span><a href="#37880413">prev</a><span>|</span><a href="#37880695">next</a><span>|</span><label class="collapse" for="c-37881657">[-]</label><label class="expand" for="c-37881657">[3 more]</label></div><br/><div class="children"><div class="content">Subtle difference. A parallel_for can have asynchronous threads. They can all divergen and run independent instructions (due to if statements etc)<p>SIMT means multiple processors all executing the exact same instruction. One instruction decoder, but like 64 execution pipelines.</div><br/><div id="37882399" class="c"><input type="checkbox" id="c-37882399" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#37880183">root</a><span>|</span><a href="#37881657">parent</a><span>|</span><a href="#37880695">next</a><span>|</span><label class="collapse" for="c-37882399">[-]</label><label class="expand" for="c-37882399">[2 more]</label></div><br/><div class="children"><div class="content">The same is true for CUDA&#x2F;OpenCL kernels. They can include conditionals and they can execute independent instructions.<p>The difference is that because the software &quot;kernels&quot; (i.e. software threads) may be mapped by the compiler either on hardware threads or on hardware SIMD lanes, and this mapping is not controlled by the programmer, the divergent instructions will cause inefficient (serial) execution when they happen to be executed on SIMD lanes of the same core, so they must be avoided.<p>This however is only an optimization problem, if the speed would be irrelevant all the kernels could execute divergent instructions.<p>The reason for the existence of CUDA is to mask for the programmer the existence of the SIMD lanes and to allow programming as if the software threads would map only to hardware threads. Nevertheless, for optimum performance the programmer must be aware that this abstraction is not really true, so the programs should be written with awareness of the limitations introduced by SIMD.</div><br/><div id="37882713" class="c"><input type="checkbox" id="c-37882713" checked=""/><div class="controls bullet"><span class="by">my123</span><span>|</span><a href="#37880183">root</a><span>|</span><a href="#37882399">parent</a><span>|</span><a href="#37880695">next</a><span>|</span><label class="collapse" for="c-37882713">[-]</label><label class="expand" for="c-37882713">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Nevertheless, for optimum performance<p>On conventional SIMT implementations (pre-Volta), the programmer also has to be aware of it to not cause deadlocks in the atomics across different lanes in the same warp.<p>On NV Volta onwards, each SIMT lane has its own instruction pointer with opportunistic reconvergence when possible.</div><br/></div></div></div></div></div></div></div></div><div id="37882833" class="c"><input type="checkbox" id="c-37882833" checked=""/><div class="controls bullet"><span class="by">TechnicolorByte</span><span>|</span><a href="#37880183">prev</a><span>|</span><a href="#37885057">next</a><span>|</span><label class="collapse" for="c-37882833">[-]</label><label class="expand" for="c-37882833">[3 more]</label></div><br/><div class="children"><div class="content">&gt; This is in contrast to SIMD, or &quot;single instruction multiple data,&quot; where the programmer explicitly uses vector types and operations in their program. The SIMD approach is suited for when you have a single program that has to process a lot of data, whereas SIMT is suited for when you have many programs and each one operates on its own data<p>This statement is comparing the SIMT model to SIMD. Can anyone explain the last part about SIMT being better for many programs operating on its own data? Are they just saying you can have individual “threads” executing independently (via predication&#x2F;masks and such)?</div><br/><div id="37883291" class="c"><input type="checkbox" id="c-37883291" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#37882833">parent</a><span>|</span><a href="#37885057">next</a><span>|</span><label class="collapse" for="c-37883291">[-]</label><label class="expand" for="c-37883291">[2 more]</label></div><br/><div class="children"><div class="content">SIMT let&#x27;s a scheduler get clever about memory accesses, SIMD can practically only access memory linearly (scatter gather can do better but it&#x27;s still usually quite linear) whereas SIMT can be much smarter in terms of having lots of similar bits of work going on in ways that use the bandwidth maximally and don&#x27;t overlap.</div><br/><div id="37883331" class="c"><input type="checkbox" id="c-37883331" checked=""/><div class="controls bullet"><span class="by">kllrnohj</span><span>|</span><a href="#37882833">root</a><span>|</span><a href="#37883291">parent</a><span>|</span><a href="#37885057">next</a><span>|</span><label class="collapse" for="c-37883331">[-]</label><label class="expand" for="c-37883331">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;how-access-global-memory-efficiently-cuda-c-kernels&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;how-access-global-memory-e...</a><p>SIMT still expects coalesced memory access that&#x27;s close together otherwise performance falls off a cliff</div><br/></div></div></div></div></div></div><div id="37885057" class="c"><input type="checkbox" id="c-37885057" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#37882833">prev</a><span>|</span><a href="#37879846">next</a><span>|</span><label class="collapse" for="c-37885057">[-]</label><label class="expand" for="c-37885057">[2 more]</label></div><br/><div class="children"><div class="content">Hey, AVX-512 again!<p>&quot;Show HN: SimSIMD vs SciPy: How AVX-512 and SVE make SIMD nicer and ML 10x faster&quot; (2023-10) 
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37805810">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37805810</a></div><br/><div id="37887825" class="c"><input type="checkbox" id="c-37887825" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#37885057">parent</a><span>|</span><a href="#37879846">next</a><span>|</span><label class="collapse" for="c-37887825">[-]</label><label class="expand" for="c-37887825">[1 more]</label></div><br/><div class="children"><div class="content">Which is to be expected, given that AVX is what survived from Larrabe.</div><br/></div></div></div></div><div id="37879846" class="c"><input type="checkbox" id="c-37879846" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#37885057">prev</a><span>|</span><a href="#37880500">next</a><span>|</span><label class="collapse" for="c-37879846">[-]</label><label class="expand" for="c-37879846">[2 more]</label></div><br/><div class="children"><div class="content">(Is this available anywhere?)</div><br/></div></div><div id="37880500" class="c"><input type="checkbox" id="c-37880500" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#37879846">prev</a><span>|</span><a href="#37879984">next</a><span>|</span><label class="collapse" for="c-37880500">[-]</label><label class="expand" for="c-37880500">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this already implemented in QEMU?</div><br/><div id="37884871" class="c"><input type="checkbox" id="c-37884871" checked=""/><div class="controls bullet"><span class="by">mikepurvis</span><span>|</span><a href="#37880500">parent</a><span>|</span><a href="#37883213">next</a><span>|</span><label class="collapse" for="c-37884871">[-]</label><label class="expand" for="c-37884871">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think so. I was quite interested in getting emulated GPUs to work for CI workers to be able to test CUDA stuff without needing actual GPU passthrough, but all I could find in this space were abandoned, early stage hobby projects on GitHub.</div><br/></div></div></div></div></div></div></div></div></div></body></html>