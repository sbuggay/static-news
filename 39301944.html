<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1707469260071" as="style"/><link rel="stylesheet" href="styles.css?v=1707469260071"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2402.04494">Grandmaster-Level Chess Without Search</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>jonbaer</span> | <span>93 comments</span></div><br/><div><div id="39307702" class="c"><input type="checkbox" id="c-39307702" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39312397">next</a><span>|</span><label class="collapse" for="c-39307702">[-]</label><label class="expand" for="c-39307702">[23 more]</label></div><br/><div class="children"><div class="content">There is rampant misunderstanding of some parts of this article; allow me to help :)<p>The &quot;no-search&quot; chess engine uses search (Stockfish) in in two ways:<p>1. To score positions in the training data. <i>This is only training data, no search is performed when actually playing.</i><p>2. To play moves when the position has many options with a 99% win rate. <i>This is to prevent pathological behavior in already won positions, and is not &quot;meaningful&quot; in the objective of grandmaster-level play.</i><p>Thus, &quot;without search&quot; is a valid description.</div><br/><div id="39307944" class="c"><input type="checkbox" id="c-39307944" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#39307702">parent</a><span>|</span><a href="#39308100">next</a><span>|</span><label class="collapse" for="c-39307944">[-]</label><label class="expand" for="c-39307944">[2 more]</label></div><br/><div class="children"><div class="content">In one sense, I can understand why they would choose to use Stockfish in mate-in-N positions. The fact that the model can&#x27;t distinguish between mate in 5 and mate in 3 is an implementation detail. Since the vast majority of positions are not known to be wins or draws, it&#x27;s still an interesting finding.<p>However, in reality all positions <i>are</i> actually wins (for black or white) or draws. One reason they gave for why stockfish is needed to finish the game is because their evaluation function is imperfect, which is also an notable result.</div><br/><div id="39311760" class="c"><input type="checkbox" id="c-39311760" checked=""/><div class="controls bullet"><span class="by">GavinB</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39307944">parent</a><span>|</span><a href="#39308100">next</a><span>|</span><label class="collapse" for="c-39311760">[-]</label><label class="expand" for="c-39311760">[1 more]</label></div><br/><div class="children"><div class="content">Is this in comparison to some other evaluation function which is perfect? I agree that all positions should have a certainty of win, draw, or lose with perfect play, but no engine is close to that level of evaluation function.<p>I do suspect that this pathological behavior could be trained out with additional fine tuning, but likely not without slightly diminishing the model&#x27;s overall ability.</div><br/></div></div></div></div><div id="39308100" class="c"><input type="checkbox" id="c-39308100" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#39307702">parent</a><span>|</span><a href="#39307944">prev</a><span>|</span><a href="#39307839">next</a><span>|</span><label class="collapse" for="c-39308100">[-]</label><label class="expand" for="c-39308100">[9 more]</label></div><br/><div class="children"><div class="content">Sort of but it seems a bit of a cheat.<p>Neural networks are universal approximators. Choose a function and get enough data from it and you can approximate it very closely and maybe exactly. If initially creating function F required algorithm Y (&quot;search&quot; or whatever), you can do your approximation to F and then say &quot;Look F without Y&quot; and for all we know, the approximation might be doing things internally that are actually nearly identical to the initial F.</div><br/><div id="39308159" class="c"><input type="checkbox" id="c-39308159" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308100">parent</a><span>|</span><a href="#39308441">next</a><span>|</span><label class="collapse" for="c-39308159">[-]</label><label class="expand" for="c-39308159">[5 more]</label></div><br/><div class="children"><div class="content">A sufficiently large nn can learn an arbitrary function, yes. But stockfish is also theoretically perfect given infinite computational resources.<p>What is interesting is performing well under reasonable computational constraints i.e. doing it faster&#x2F;with fewer flops than stockfish.</div><br/><div id="39308289" class="c"><input type="checkbox" id="c-39308289" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308159">parent</a><span>|</span><a href="#39308441">next</a><span>|</span><label class="collapse" for="c-39308289">[-]</label><label class="expand" for="c-39308289">[4 more]</label></div><br/><div class="children"><div class="content">Is the model more efficient than Stockfish? I think Stockfish runs on regular CPU computer and I&#x27;d guess this &quot; 270M parameter transformer model&quot; requires a GPU but I can&#x27;t find any reference to efficiency in the paper.<p>Also found in the paper: &quot;While our largest model achieves very good performance, it does not completely close the gap to Stockfish 16&quot;. It&#x27;s actually inferior but they still think it&#x27;s an interesting exercise. But that&#x27;s the thing, it&#x27;s primarily an exercise like calculating pi to a billion decimal points or overclocking a gaming laptop.</div><br/><div id="39312313" class="c"><input type="checkbox" id="c-39312313" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308289">parent</a><span>|</span><a href="#39309099">next</a><span>|</span><label class="collapse" for="c-39312313">[-]</label><label class="expand" for="c-39312313">[2 more]</label></div><br/><div class="children"><div class="content">BERT has around that many parameters and it runs on CPU in 200ms</div><br/><div id="39312690" class="c"><input type="checkbox" id="c-39312690" checked=""/><div class="controls bullet"><span class="by">spookie</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39312313">parent</a><span>|</span><a href="#39309099">next</a><span>|</span><label class="collapse" for="c-39312690">[-]</label><label class="expand" for="c-39312690">[1 more]</label></div><br/><div class="children"><div class="content">In that time Stockfish 16 would evaluate about 2 million positions on a mildly powerful consumer CPU</div><br/></div></div></div></div><div id="39309099" class="c"><input type="checkbox" id="c-39309099" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308289">parent</a><span>|</span><a href="#39312313">prev</a><span>|</span><a href="#39308441">next</a><span>|</span><label class="collapse" for="c-39309099">[-]</label><label class="expand" for="c-39309099">[1 more]</label></div><br/><div class="children"><div class="content">Well I think it’s interesting to the extent that it optimizes the solution for a different piece of hardware, the TPU. Their results are also applicable to GPUs. Since the problem is highly parallelizable, we might expect a viable model to quickly approximate a more accurate evaluation, and perhaps even make up for it in volume.</div><br/></div></div></div></div></div></div><div id="39308441" class="c"><input type="checkbox" id="c-39308441" checked=""/><div class="controls bullet"><span class="by">dawnofdusk</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308100">parent</a><span>|</span><a href="#39308159">prev</a><span>|</span><a href="#39308154">next</a><span>|</span><label class="collapse" for="c-39308441">[-]</label><label class="expand" for="c-39308441">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t get the actual optimal Q values computed from Stockfish (presumably this takes infinite compute to calculate), in fact it gets computed estimates from polling Stockfish for only 50ms.<p>So you&#x27;re estimating from data a function which is itself not necessarily optimal. Moreover, the point is more like how far can we get using a really generic transformer architecture that is not tuned to domain-specific details of our problem, which Stockfish is.</div><br/></div></div><div id="39308154" class="c"><input type="checkbox" id="c-39308154" checked=""/><div class="controls bullet"><span class="by">jackblemming</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308100">parent</a><span>|</span><a href="#39308441">prev</a><span>|</span><a href="#39307839">next</a><span>|</span><label class="collapse" for="c-39308154">[-]</label><label class="expand" for="c-39308154">[2 more]</label></div><br/><div class="children"><div class="content">No, arbitrarily wide neural networks are approximators of Borel Measurable functions. Big difference between that and “any function”. RNNs are Turing Complete though.</div><br/><div id="39308296" class="c"><input type="checkbox" id="c-39308296" checked=""/><div class="controls bullet"><span class="by">eldenring</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308154">parent</a><span>|</span><a href="#39307839">next</a><span>|</span><label class="collapse" for="c-39308296">[-]</label><label class="expand" for="c-39308296">[1 more]</label></div><br/><div class="children"><div class="content">You can say the same thing about RNNs. Technically nothing is turing complete without infinite scratch space.</div><br/></div></div></div></div></div></div><div id="39307839" class="c"><input type="checkbox" id="c-39307839" checked=""/><div class="controls bullet"><span class="by">zniturah</span><span>|</span><a href="#39307702">parent</a><span>|</span><a href="#39308100">prev</a><span>|</span><a href="#39308654">next</a><span>|</span><label class="collapse" for="c-39307839">[-]</label><label class="expand" for="c-39307839">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Aready won position&quot; or &quot;99% win rate&quot; is statistics given by Stockfish (or professional chess player). It is weird to assume that the same statement is true for the trained LLM since we are assessing the LLM itself. If it is using during the game then it is searching, thus the title doesn&#x27;t reflect the actual work.</div><br/></div></div><div id="39308654" class="c"><input type="checkbox" id="c-39308654" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#39307702">parent</a><span>|</span><a href="#39307839">prev</a><span>|</span><a href="#39312397">next</a><span>|</span><label class="collapse" for="c-39308654">[-]</label><label class="expand" for="c-39308654">[10 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; 1. To score positions in the training data. This is only training data, no search is performed when actually playing.<p>That&#x27;s like saying you can have eggs without chickens, because when you make an omelette you don&#x27;t add chickens. It&#x27;s completely meaningless and a big fat lie to boot.<p>The truth is that the system created by DeepMind consists of two components: a search-based system used to annotate a dataset of moves and a neural-net based system that generates moves similar to the ones in the dataset. DeepMind arbitrarily draw the boundary of the system around the neural net component and pretend that because the search is external to the neural net, the neural net doesn&#x27;t need the search.<p>And yet, without the search there is no dataset, and without the dataset there is no model. They didn&#x27;t train their system by self-play and they certainly didn&#x27;t hire an army of low-paid workers to annotate moves for them. They generated training moves with a search-based system and learned to reproduce them. They used chickens to make eggs.<p>Their approach depends entirely on there being a powerful chess search engine and they wouldn&#x27;t be able to create their system without it as a main component. Their &quot;without search&quot; claim is just a marketing term.</div><br/><div id="39309458" class="c"><input type="checkbox" id="c-39309458" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308654">parent</a><span>|</span><a href="#39309005">next</a><span>|</span><label class="collapse" for="c-39309458">[-]</label><label class="expand" for="c-39309458">[2 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t matter where the egg came from,  just that it is an egg.<p>It could have luckily coalesced from gas (a Boltzmann egg), or perhaps even more radically, been laid by a duck.<p>you say<p>&gt;They didn&#x27;t train their system by self-play and they certainly didn&#x27;t hire an army of low-paid workers to annotate moves for them.<p>So you are certainly aware that there are avenues to creating the data set. Given that, it is quite reasonable to say that search is unnecessary.</div><br/><div id="39311001" class="c"><input type="checkbox" id="c-39311001" checked=""/><div class="controls bullet"><span class="by">zmgsabst</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39309458">parent</a><span>|</span><a href="#39309005">next</a><span>|</span><label class="collapse" for="c-39311001">[-]</label><label class="expand" for="c-39311001">[1 more]</label></div><br/><div class="children"><div class="content">Neither of those has been shown to produce equivalent training data, no.<p>They should do one of those instead of using search before they claim it’s possible to not use search.<p>Or to borrow your analogy, you’ll need to show me a duck egg to prove you can make omelettes without chickens. Making an omelette from chicken eggs and claiming hypothetically some mystery other animal could have done it is nonsense.</div><br/></div></div></div></div><div id="39309005" class="c"><input type="checkbox" id="c-39309005" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308654">parent</a><span>|</span><a href="#39309458">prev</a><span>|</span><a href="#39310934">next</a><span>|</span><label class="collapse" for="c-39309005">[-]</label><label class="expand" for="c-39309005">[2 more]</label></div><br/><div class="children"><div class="content">Btw, just to be a bit more constructive (not by much) the proper term for what DeepMind did is &quot;neuro-symbolic AI&quot;. But DeepMind shunned the term even for AlphaGO, a system comprised of a couple of neural nets and Monte-Carlo Tree Search.<p>The whole thing is just political: DeepMind use neural nets, GOFAI is dead and that&#x27;s the way to AI. That&#x27;s their story and they&#x27;re sticking with it.</div><br/></div></div><div id="39310934" class="c"><input type="checkbox" id="c-39310934" checked=""/><div class="controls bullet"><span class="by">falcor84</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308654">parent</a><span>|</span><a href="#39309005">prev</a><span>|</span><a href="#39312106">next</a><span>|</span><label class="collapse" for="c-39310934">[-]</label><label class="expand" for="c-39310934">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That&#x27;s like saying you can have eggs without chickens, because when you make an omelette you don&#x27;t add chickens.<p>I just took it in the same way as saying that being a vegetarian is generally better for animal welfare, as you&#x27;re not harming chickens as directly by eating an omelette, as you would by eating their wings.</div><br/></div></div><div id="39312106" class="c"><input type="checkbox" id="c-39312106" checked=""/><div class="controls bullet"><span class="by">rkagerer</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308654">parent</a><span>|</span><a href="#39310934">prev</a><span>|</span><a href="#39309035">next</a><span>|</span><label class="collapse" for="c-39312106">[-]</label><label class="expand" for="c-39312106">[1 more]</label></div><br/><div class="children"><div class="content">Ok maybe it&#x27;s fair to say it&#x27;s Chess with Precompiled Search.</div><br/></div></div><div id="39309035" class="c"><input type="checkbox" id="c-39309035" checked=""/><div class="controls bullet"><span class="by">ogogmad</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39308654">parent</a><span>|</span><a href="#39312106">prev</a><span>|</span><a href="#39312397">next</a><span>|</span><label class="collapse" for="c-39309035">[-]</label><label class="expand" for="c-39309035">[3 more]</label></div><br/><div class="children"><div class="content">The point -- which I don&#x27;t think you got -- is that extremely generic ingredients like high-quality data (which is the point of Stockfish here) and very deep Transformer-type Neural Networks, are enough to nearly match the performance of ad-hoc, non-generalisable techniques like gametree search algorithms.<p>This has two possible applications: 1. There&#x27;s far less need to invent techniques like MCTS in the first place. 2. A single AI might be able to play grandmaster level chess by accident.<p>The catch is you need high quality data in large amounts.</div><br/><div id="39309061" class="c"><input type="checkbox" id="c-39309061" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39309035">parent</a><span>|</span><a href="#39312397">next</a><span>|</span><label class="collapse" for="c-39309061">[-]</label><label class="expand" for="c-39309061">[2 more]</label></div><br/><div class="children"><div class="content">I did get the point and I&#x27;m commenting that the point is missing the point. There is nothing new in learning that a large neural net can approximate the output of a classical system. This has been done many times before. The real point is that DeepMind build a system that is half-search and pretend it&#x27;s no-search. You cannot get the &quot;high-quality data&quot; without a classical system- not in chess.</div><br/><div id="39309169" class="c"><input type="checkbox" id="c-39309169" checked=""/><div class="controls bullet"><span class="by">ogogmad</span><span>|</span><a href="#39307702">root</a><span>|</span><a href="#39309061">parent</a><span>|</span><a href="#39312397">next</a><span>|</span><label class="collapse" for="c-39309169">[-]</label><label class="expand" for="c-39309169">[1 more]</label></div><br/><div class="children"><div class="content">I get your point. Acquiring the data is the hard part, and they cheated to get it. It&#x27;s chicken and egg indeed.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39312397" class="c"><input type="checkbox" id="c-39312397" checked=""/><div class="controls bullet"><span class="by">ad8e</span><span>|</span><a href="#39307702">prev</a><span>|</span><a href="#39311073">next</a><span>|</span><label class="collapse" for="c-39312397">[-]</label><label class="expand" for="c-39312397">[2 more]</label></div><br/><div class="children"><div class="content">A quote from discord: &quot;apparently alpha-zero has been replicated in open source as leela-zero, and then leela-zero got a bunch of improvements so it&#x27;s far ahead of alpha-zero. but leela-zero was barely mentioned at all in the paper; it was only dismissed in the introduction and not compared in the benchmarks. in the stockfish discord they are saying that leela zero can already do everything in this paper including using the transformer architecture.&quot;</div><br/><div id="39312564" class="c"><input type="checkbox" id="c-39312564" checked=""/><div class="controls bullet"><span class="by">shmageggy</span><span>|</span><a href="#39312397">parent</a><span>|</span><a href="#39311073">next</a><span>|</span><label class="collapse" for="c-39312564">[-]</label><label class="expand" for="c-39312564">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, they need to compare against the latest BT2 policy head. It&#x27;s probably about the same performance.</div><br/></div></div></div></div><div id="39311073" class="c"><input type="checkbox" id="c-39311073" checked=""/><div class="controls bullet"><span class="by">verteu</span><span>|</span><a href="#39312397">prev</a><span>|</span><a href="#39307857">next</a><span>|</span><label class="collapse" for="c-39311073">[-]</label><label class="expand" for="c-39311073">[1 more]</label></div><br/><div class="children"><div class="content">How much of this &quot;grandmaster-level&quot; play is an artifact of low time controls? I notice they only achieve GM ELO in Blitz against humans, achieve significantly worse ELO against bots, and do not provide the &quot;Lichess Blitz ELO&quot; of any of their benchmark approaches.</div><br/></div></div><div id="39307857" class="c"><input type="checkbox" id="c-39307857" checked=""/><div class="controls bullet"><span class="by">IIAOPSW</span><span>|</span><a href="#39311073">prev</a><span>|</span><a href="#39302094">next</a><span>|</span><label class="collapse" for="c-39307857">[-]</label><label class="expand" for="c-39307857">[11 more]</label></div><br/><div class="children"><div class="content">Slightly off topic but am I the only one that approaches strategy games by making a &quot;zeroth order approximation&quot;. Eg find the shortest path to victory under the (obviously faulty) assumption that my opponent does nothing and the board is unchanging except for my moves. Now find my opponents shortest path to victory under the same assumption. Then evaluate, if we both just ignore each other and try to bum rush the victory condition, who gets there first?<p>For most games, if you can see a way to an end state within 3-5 steps under these idealized conditions, there&#x27;s only so much that an actual opponent can do to make the board deviate from the initial static board state that you used in your assumption. The optimal strategy will always be just a few minor corrections of edit distance from this dumb no-theory-of-mind strategy. You can always be sure that whoever has the longer path to victory has to do something to interfere with the shorter path of their opponent, and there&#x27;s only ever so many pieces which can interact with that shorter path. Meaning whatever path to victory is currently shortest short circuits the search for potential moves.</div><br/><div id="39307995" class="c"><input type="checkbox" id="c-39307995" checked=""/><div class="controls bullet"><span class="by">dayjaby</span><span>|</span><a href="#39307857">parent</a><span>|</span><a href="#39310207">next</a><span>|</span><label class="collapse" for="c-39307995">[-]</label><label class="expand" for="c-39307995">[3 more]</label></div><br/><div class="children"><div class="content">On beginner level this might work, but if people are more competitive they begin to realize the benefit of not only playing the own game, but reading the enemies plan (e.g. scouting in Starcraft&#x2F;AoE2) to counteract it as much as possible.<p>Chess against humen is different. Usually, there is no path to victory, only to remis. People just follow strategic plans that people told them would be slightly beneficial later on. Along following that strategic plan people mess up and the first one to realize that the opponent messed up usually wins. Like having a piece advantage of 2-3 is usually considered a win already.</div><br/><div id="39308283" class="c"><input type="checkbox" id="c-39308283" checked=""/><div class="controls bullet"><span class="by">jrockway</span><span>|</span><a href="#39307857">root</a><span>|</span><a href="#39307995">parent</a><span>|</span><a href="#39310207">next</a><span>|</span><label class="collapse" for="c-39308283">[-]</label><label class="expand" for="c-39308283">[2 more]</label></div><br/><div class="children"><div class="content">I agree with this.  My default approach to board games is basically to maximize victory points early.  This usually works; when 4 people are playing a new game for the first time, I usually win.  This doesn&#x27;t really work when people know how to play the game specifically, though.<p>I think this algorithm is better than many other algorithms that people come up with, however.<p>(As an aside, when I play a card game I sort my cards with a merge sort instead of an insertion sort.  People said you would never use these algorithms in real life, but you can if you want to!)</div><br/><div id="39309065" class="c"><input type="checkbox" id="c-39309065" checked=""/><div class="controls bullet"><span class="by">entropicdrifter</span><span>|</span><a href="#39307857">root</a><span>|</span><a href="#39308283">parent</a><span>|</span><a href="#39310207">next</a><span>|</span><label class="collapse" for="c-39309065">[-]</label><label class="expand" for="c-39309065">[1 more]</label></div><br/><div class="children"><div class="content">This comment got me thinking about how I sort my cards. I scan the whole hand, then make the biggest changes first (e.g. consolidating suits&#x2F;card types), then sort the subgroups.<p>Huh, guess I&#x27;m doing a sort of human heuristic version of Quicksort</div><br/></div></div></div></div></div></div><div id="39310207" class="c"><input type="checkbox" id="c-39310207" checked=""/><div class="controls bullet"><span class="by">AndrewPGameDev</span><span>|</span><a href="#39307857">parent</a><span>|</span><a href="#39307995">prev</a><span>|</span><a href="#39309748">next</a><span>|</span><label class="collapse" for="c-39310207">[-]</label><label class="expand" for="c-39310207">[1 more]</label></div><br/><div class="children"><div class="content">If you programmed this as a chess strategy, it would probably result in an engine that played the Scholar&#x27;s mate every game. This is actually close to what low Elo players do in chess, but as you get closer to 800-ish ELO the probability of attempted scholar mates drop dramatically (likely due to it being an opening that isn&#x27;t that good).</div><br/></div></div><div id="39309748" class="c"><input type="checkbox" id="c-39309748" checked=""/><div class="controls bullet"><span class="by">themoonisachees</span><span>|</span><a href="#39307857">parent</a><span>|</span><a href="#39310207">prev</a><span>|</span><a href="#39308321">next</a><span>|</span><label class="collapse" for="c-39309748">[-]</label><label class="expand" for="c-39309748">[1 more]</label></div><br/><div class="children"><div class="content">This is one of the canonical ways people learn chess. It&#x27;s not that bad of a way to play because it emphasizes thinking about good moves, and it efficiently finds mates in N (when done by a human)<p>In higher level play it usually loses to opponents that are aware they&#x27;re not playing alone, at least that&#x27;s the case with bots that do in fact stay unaware of their opponent.</div><br/></div></div><div id="39308321" class="c"><input type="checkbox" id="c-39308321" checked=""/><div class="controls bullet"><span class="by">bionsystem</span><span>|</span><a href="#39307857">parent</a><span>|</span><a href="#39309748">prev</a><span>|</span><a href="#39307971">next</a><span>|</span><label class="collapse" for="c-39308321">[-]</label><label class="expand" for="c-39308321">[1 more]</label></div><br/><div class="children"><div class="content">A lot of decision in chess would be like &quot;this square would be nice for that piece, how can I get there ?&quot; and then analyze what your opponent can do to prevent you to do that, or what counterplay that gives him. So what you are doing makes a lot of sense.</div><br/></div></div><div id="39307971" class="c"><input type="checkbox" id="c-39307971" checked=""/><div class="controls bullet"><span class="by">xbpx</span><span>|</span><a href="#39307857">parent</a><span>|</span><a href="#39308321">prev</a><span>|</span><a href="#39309931">next</a><span>|</span><label class="collapse" for="c-39307971">[-]</label><label class="expand" for="c-39307971">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s why white has a higher statistical win rate ya?</div><br/><div id="39309828" class="c"><input type="checkbox" id="c-39309828" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#39307857">root</a><span>|</span><a href="#39307971">parent</a><span>|</span><a href="#39309931">next</a><span>|</span><label class="collapse" for="c-39309828">[-]</label><label class="expand" for="c-39309828">[1 more]</label></div><br/><div class="children"><div class="content">Only if you play on the Tengen point.</div><br/></div></div></div></div><div id="39309931" class="c"><input type="checkbox" id="c-39309931" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#39307857">parent</a><span>|</span><a href="#39307971">prev</a><span>|</span><a href="#39308805">next</a><span>|</span><label class="collapse" for="c-39309931">[-]</label><label class="expand" for="c-39309931">[1 more]</label></div><br/><div class="children"><div class="content">Can&#x27;t you almost always win the game in a few moves if you plan for your opponent to make really stupid responses?</div><br/></div></div><div id="39308805" class="c"><input type="checkbox" id="c-39308805" checked=""/><div class="controls bullet"><span class="by">jncfhnb</span><span>|</span><a href="#39307857">parent</a><span>|</span><a href="#39309931">prev</a><span>|</span><a href="#39302094">next</a><span>|</span><label class="collapse" for="c-39308805">[-]</label><label class="expand" for="c-39308805">[1 more]</label></div><br/><div class="children"><div class="content">Ehh idk. Sounds like it’s prone to the beginner strategy of assuming your opponent will occasionally do something really dumb.</div><br/></div></div></div></div><div id="39302094" class="c"><input type="checkbox" id="c-39302094" checked=""/><div class="controls bullet"><span class="by">fiforpg</span><span>|</span><a href="#39307857">prev</a><span>|</span><a href="#39309105">next</a><span>|</span><label class="collapse" for="c-39302094">[-]</label><label class="expand" for="c-39302094">[7 more]</label></div><br/><div class="children"><div class="content">Given that they used position evaluation from (a search chess engine[1]) Stockfish, how is this &quot;without search&quot;?<p>Edit: looking further than the abstract, this is rather an exploration of scale necessary for a strong engine. Could go without &quot;without search&quot; in the title I guess.<p>[1]: IIRC, it also uses a Leela-inspired NN for evaluation.</div><br/><div id="39302335" class="c"><input type="checkbox" id="c-39302335" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#39302094">parent</a><span>|</span><a href="#39307173">next</a><span>|</span><label class="collapse" for="c-39302335">[-]</label><label class="expand" for="c-39302335">[1 more]</label></div><br/><div class="children"><div class="content">Leela without search supposedly plays around expert level, but I thought the no-search Leela approach ran out of gas around there.  Without search there means evaluating 1 board position per move.  The engine in the paper (per the abstract) use a big LLM instead of a Leela style DCNN.</div><br/></div></div><div id="39307173" class="c"><input type="checkbox" id="c-39307173" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39302094">parent</a><span>|</span><a href="#39302335">prev</a><span>|</span><a href="#39312182">next</a><span>|</span><label class="collapse" for="c-39307173">[-]</label><label class="expand" for="c-39307173">[2 more]</label></div><br/><div class="children"><div class="content">Training uses search, but it plays without search.<p>ChatGPT isn&#x27;t human, but it was trained with humans.</div><br/><div id="39308250" class="c"><input type="checkbox" id="c-39308250" checked=""/><div class="controls bullet"><span class="by">karolist</span><span>|</span><a href="#39302094">root</a><span>|</span><a href="#39307173">parent</a><span>|</span><a href="#39312182">next</a><span>|</span><label class="collapse" for="c-39308250">[-]</label><label class="expand" for="c-39308250">[1 more]</label></div><br/><div class="children"><div class="content">So it&#x27;s a space time trade-off then? Store enough searched and weighted positions into the model and infer them. In this way, inference is replacing Stockfish search, just less accurately, but much faster and with memory required for the model.</div><br/></div></div></div></div><div id="39312182" class="c"><input type="checkbox" id="c-39312182" checked=""/><div class="controls bullet"><span class="by">porphyra</span><span>|</span><a href="#39302094">parent</a><span>|</span><a href="#39307173">prev</a><span>|</span><a href="#39303684">next</a><span>|</span><label class="collapse" for="c-39312182">[-]</label><label class="expand" for="c-39312182">[2 more]</label></div><br/><div class="children"><div class="content">Does Stockfish really use a Leela-inspired NN? I thought the NNUE was independently developed and completely different (it&#x27;s a very tiny network that runs on the CPU).</div><br/><div id="39312534" class="c"><input type="checkbox" id="c-39312534" checked=""/><div class="controls bullet"><span class="by">Oreb</span><span>|</span><a href="#39302094">root</a><span>|</span><a href="#39312182">parent</a><span>|</span><a href="#39303684">next</a><span>|</span><label class="collapse" for="c-39312534">[-]</label><label class="expand" for="c-39312534">[1 more]</label></div><br/><div class="children"><div class="content">This is true, but at least for a while (I’m not sure if it’s still the case), Leela data was used (along with data generated from Stockfish self-play) to train Stockfish’s NN.</div><br/></div></div></div></div></div></div><div id="39309105" class="c"><input type="checkbox" id="c-39309105" checked=""/><div class="controls bullet"><span class="by">tromp</span><span>|</span><a href="#39302094">prev</a><span>|</span><a href="#39307632">next</a><span>|</span><label class="collapse" for="c-39309105">[-]</label><label class="expand" for="c-39309105">[4 more]</label></div><br/><div class="children"><div class="content">While its performance against humans is very impressive indeed, its performance against engines is somewhat less so:<p>&gt; Our agent’s aggressive style is highly successful against human opponents and achieves a grandmasterlevel Lichess Elo of 2895. However, we ran another instance of the bot and allowed other engines to play it. Its estimated Elo was far lower, i.e., 2299. Its aggressive playing style does not work as well against engines that are adept at tactical calculations, particularly when there is a tactical refutation to a suboptimal move.</div><br/><div id="39309140" class="c"><input type="checkbox" id="c-39309140" checked=""/><div class="controls bullet"><span class="by">chongli</span><span>|</span><a href="#39309105">parent</a><span>|</span><a href="#39309926">next</a><span>|</span><label class="collapse" for="c-39309140">[-]</label><label class="expand" for="c-39309140">[2 more]</label></div><br/><div class="children"><div class="content">I like this even more that I’ve read that. That sounds like it makes this agent a much more human-like player than the perfect calculator traditional chess engines. It may end up being more fun for humans to play against if it’s strong but has holes in its play.</div><br/><div id="39309192" class="c"><input type="checkbox" id="c-39309192" checked=""/><div class="controls bullet"><span class="by">dev_tty01</span><span>|</span><a href="#39309105">root</a><span>|</span><a href="#39309140">parent</a><span>|</span><a href="#39309926">next</a><span>|</span><label class="collapse" for="c-39309192">[-]</label><label class="expand" for="c-39309192">[1 more]</label></div><br/><div class="children"><div class="content">I suppose.  I wonder if one can adjust the engine&#x27;s skill level.</div><br/></div></div></div></div><div id="39309926" class="c"><input type="checkbox" id="c-39309926" checked=""/><div class="controls bullet"><span class="by">aexl</span><span>|</span><a href="#39309105">parent</a><span>|</span><a href="#39309140">prev</a><span>|</span><a href="#39307632">next</a><span>|</span><label class="collapse" for="c-39309926">[-]</label><label class="expand" for="c-39309926">[1 more]</label></div><br/><div class="children"><div class="content">This sounds a lot like Mikhail Tal!</div><br/></div></div></div></div><div id="39307632" class="c"><input type="checkbox" id="c-39307632" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#39309105">prev</a><span>|</span><a href="#39308030">next</a><span>|</span><label class="collapse" for="c-39307632">[-]</label><label class="expand" for="c-39307632">[8 more]</label></div><br/><div class="children"><div class="content">Well without <i>explicit</i> search would probably be more accurate.<p>They note that though in the paper:<p>&gt;Since transformers may learn to roll out iterative computation (which arises in search) across layers, deeper networks may hold the potential for deeper unrolls.</div><br/><div id="39308113" class="c"><input type="checkbox" id="c-39308113" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#39307632">parent</a><span>|</span><a href="#39308030">next</a><span>|</span><label class="collapse" for="c-39308113">[-]</label><label class="expand" for="c-39308113">[7 more]</label></div><br/><div class="children"><div class="content">We don’t know if it’s using implicit search either. While it would be interesting if the network was doing some internal search, it’s also possible it has just memorized the evaluations from 10M games and is performing some function of the similarity of the input to those previously seen.</div><br/><div id="39308368" class="c"><input type="checkbox" id="c-39308368" checked=""/><div class="controls bullet"><span class="by">dawnofdusk</span><span>|</span><a href="#39307632">root</a><span>|</span><a href="#39308113">parent</a><span>|</span><a href="#39310800">next</a><span>|</span><label class="collapse" for="c-39308368">[-]</label><label class="expand" for="c-39308368">[1 more]</label></div><br/><div class="children"><div class="content">Even if it&#x27;s &quot;implicit&quot; I&#x27;m not sure if that matters that much. The point is that the model doesn&#x27;t explicitly search anything, it just applies the learned transformation. If the weights of the learned transformation encode a sort of precomputed search and interpolation over the dataset, from an algorithmic perspective this still isn&#x27;t search (it doesn&#x27;t enumerate board states or state-action transitions).<p>&gt;performing some function of the similarity of the input to those previously seen.<p>This is indeed what transformers do. But obviously it learns some sort of interpolation&#x2F;extrapolation which lets it do well on board states&#x2F;games outside the training set.</div><br/></div></div><div id="39310800" class="c"><input type="checkbox" id="c-39310800" checked=""/><div class="controls bullet"><span class="by">gwern</span><span>|</span><a href="#39307632">root</a><span>|</span><a href="#39308113">parent</a><span>|</span><a href="#39308368">prev</a><span>|</span><a href="#39309778">next</a><span>|</span><label class="collapse" for="c-39310800">[-]</label><label class="expand" for="c-39310800">[1 more]</label></div><br/><div class="children"><div class="content">If the Transformer was &#x27;just&#x27; memorizing, you would expect width scaling to work much better than depth scaling (because width enables memorization much more efficiently), and you also wouldn&#x27;t expect depth to run into problems, because it&#x27;s not like memorization is that complex - but it does suggest that it&#x27;s learning some more complicated algorithm which has issues with vanishing gradients &amp; learning multiple serial steps, and the obvious complicated algorithm to be learning in this context would be an implicit search akin to the MuZero RNN (which, incidentally, doesn&#x27;t need any symbolic solver like Stockfish to learn superhuman chess from scratch by self-play).</div><br/></div></div><div id="39309778" class="c"><input type="checkbox" id="c-39309778" checked=""/><div class="controls bullet"><span class="by">devit</span><span>|</span><a href="#39307632">root</a><span>|</span><a href="#39308113">parent</a><span>|</span><a href="#39310800">prev</a><span>|</span><a href="#39308217">next</a><span>|</span><label class="collapse" for="c-39309778">[-]</label><label class="expand" for="c-39309778">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they could test it on &quot;tricky&quot; positions where increasing the search depth on Stockfish dramatically changes the evaluation.</div><br/></div></div><div id="39308217" class="c"><input type="checkbox" id="c-39308217" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#39307632">root</a><span>|</span><a href="#39308113">parent</a><span>|</span><a href="#39309778">prev</a><span>|</span><a href="#39308030">next</a><span>|</span><label class="collapse" for="c-39308217">[-]</label><label class="expand" for="c-39308217">[3 more]</label></div><br/><div class="children"><div class="content">&gt;We don’t know if it’s using implicit search either.<p>Sure<p>&gt;it’s also possible it has just memorized the evaluations from 10M games and is performing some function of the similarity of the input to those previously seen.<p>That&#x27;s not possible. The possible set of moves in chess is incredibly large and it is incredibly easy to play a game that has diverged from training. a model that has just memorized all evaluations would break within ten or so moves tops much less withstand robust evaluations.<p>However this model may work exactly and how much or little it relies on search is unknown but it is no doubt a model of the world of chess. <a href="https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;01&#x2F;03&#x2F;chess-world-models.html" rel="nofollow">https:&#x2F;&#x2F;adamkarvonen.github.io&#x2F;machine_learning&#x2F;2024&#x2F;01&#x2F;03&#x2F;c...</a></div><br/><div id="39308541" class="c"><input type="checkbox" id="c-39308541" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#39307632">root</a><span>|</span><a href="#39308217">parent</a><span>|</span><a href="#39308030">next</a><span>|</span><label class="collapse" for="c-39308541">[-]</label><label class="expand" for="c-39308541">[2 more]</label></div><br/><div class="children"><div class="content">If it could reliably win a mate in N position without inexplicably blundering, I would be more inclined to buy your search hypothesis. But it doesn’t, which is one of the reasons the authors gave for finishing with stockfish. So whatever it’s doing is clearly lossy which an actual search would not be.<p>Neural nets memorize all sorts of things. They memorize ad clicks in high dimensional state spaces. Transformers trained on the whole internet can often reproduce entire texts. It’s lossy, but it’s still memorizing.<p>That seems like the simplest explanation for what’s happening here. There’s some sort of lossy memorization, not a search. The fact that the thing it has memorized is the result of a search doesn’t matter.</div><br/><div id="39308853" class="c"><input type="checkbox" id="c-39308853" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#39307632">root</a><span>|</span><a href="#39308541">parent</a><span>|</span><a href="#39308030">next</a><span>|</span><label class="collapse" for="c-39308853">[-]</label><label class="expand" for="c-39308853">[1 more]</label></div><br/><div class="children"><div class="content">&gt;If it could reliably win a mate in N position without inexplicably blundering, I would be more inclined to buy your search hypothesis.<p>I don&#x27;t have a &quot;search hypothesis&quot;. I don&#x27;t know what strategy the model employs to play. I was simply pointing out that limited search learned by the transformer is not out of the question. Stockfish finishing is not necessary to play chess well above the level a memorization hypothesis makes any sense. This is not the first LLM chess machine.<p>&gt;Neural nets memorize all sorts of things. They memorize ad clicks in high dimensional state spaces. Transformers trained on the whole internet can often reproduce entire texts. It’s lossy, but it’s still memorizing.<p>Intelligent things memorize. Humans memorize a lot. I never said the model hasn&#x27;t memorized a fair few things. Many human chess grandmaster memorize openings. What i&#x27;m saying is that it&#x27;s not playing games via memorization any more than a human is doing the same.<p>&gt;That seems like the simplest explanation for what’s happening here. There’s some sort of lossy memorization, not a search.<p>The options aren&#x27;t only lossy memorization or lossless search.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39308030" class="c"><input type="checkbox" id="c-39308030" checked=""/><div class="controls bullet"><span class="by">iamcreasy</span><span>|</span><a href="#39307632">prev</a><span>|</span><a href="#39307648">next</a><span>|</span><label class="collapse" for="c-39308030">[-]</label><label class="expand" for="c-39308030">[1 more]</label></div><br/><div class="children"><div class="content">I guess this current method is not applicable to have the model explain why a given move was played as it is not planning more than one more ahead. Very cool, nonetheless.</div><br/></div></div><div id="39307648" class="c"><input type="checkbox" id="c-39307648" checked=""/><div class="controls bullet"><span class="by">salamo</span><span>|</span><a href="#39308030">prev</a><span>|</span><a href="#39309867">next</a><span>|</span><label class="collapse" for="c-39307648">[-]</label><label class="expand" for="c-39307648">[4 more]</label></div><br/><div class="children"><div class="content">I think this is an interesting finding from a practical perspective. A function which can reliably approximate stockfish at a certain depth could replace it, basically &quot;compressing&quot; search to a set depth. And unlike NNUE which is optimized for CPU, a neural network is highly parallelizable on GPU meaning you could send all possible future positions (at depth N) through the network and use the results for a primitive tree search.</div><br/><div id="39310219" class="c"><input type="checkbox" id="c-39310219" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#39307648">parent</a><span>|</span><a href="#39309867">next</a><span>|</span><label class="collapse" for="c-39310219">[-]</label><label class="expand" for="c-39310219">[3 more]</label></div><br/><div class="children"><div class="content">The Stockfish installer is ~45 MB. At 16 bits per parameter, the 270B model would be over 500 MB. The 9B model would be smaller than Stockfish, but you could probably find a smaller chess engine that achieves 2000 ELO.</div><br/><div id="39312683" class="c"><input type="checkbox" id="c-39312683" checked=""/><div class="controls bullet"><span class="by">shmageggy</span><span>|</span><a href="#39307648">root</a><span>|</span><a href="#39310219">parent</a><span>|</span><a href="#39311334">next</a><span>|</span><label class="collapse" for="c-39312683">[-]</label><label class="expand" for="c-39312683">[1 more]</label></div><br/><div class="children"><div class="content">Dedicated chess computers were hitting 2000 ELO with an <i>8-bit 6502</i> running at &lt;10MHz in the late 1980s. The Novag Super expert had 96KB of ROM, which also included the opening book, so yeah, quite a bit smaller.<p><a href="https:&#x2F;&#x2F;schach-computer.info&#x2F;wiki&#x2F;index.php?title=Novag_Super_Expert" rel="nofollow">https:&#x2F;&#x2F;schach-computer.info&#x2F;wiki&#x2F;index.php?title=Novag_Supe...</a><p><a href="https:&#x2F;&#x2F;www.schach-computer.info&#x2F;wiki&#x2F;index.php?title=Mephisto_MM_V" rel="nofollow">https:&#x2F;&#x2F;www.schach-computer.info&#x2F;wiki&#x2F;index.php?title=Mephis...</a></div><br/></div></div><div id="39311334" class="c"><input type="checkbox" id="c-39311334" checked=""/><div class="controls bullet"><span class="by">salamo</span><span>|</span><a href="#39307648">root</a><span>|</span><a href="#39310219">parent</a><span>|</span><a href="#39312683">prev</a><span>|</span><a href="#39309867">next</a><span>|</span><label class="collapse" for="c-39311334">[-]</label><label class="expand" for="c-39311334">[1 more]</label></div><br/><div class="children"><div class="content">The advantage of this approach that we can run many simultaneous computations on the GPU&#x2F;TPU. Instead of using maybe a dozen CPU threads, we can approximate the value of a few thousand positions at the same time.</div><br/></div></div></div></div></div></div><div id="39309867" class="c"><input type="checkbox" id="c-39309867" checked=""/><div class="controls bullet"><span class="by">asah</span><span>|</span><a href="#39307648">prev</a><span>|</span><a href="#39307936">next</a><span>|</span><label class="collapse" for="c-39309867">[-]</label><label class="expand" for="c-39309867">[1 more]</label></div><br/><div class="children"><div class="content">imho fascinating experiment, even if it didn&#x27;t produce world class Elo.<p>For one thing, statelessness deprives it of easy solutions to repetition and endgame decisiveness.</div><br/></div></div><div id="39307936" class="c"><input type="checkbox" id="c-39307936" checked=""/><div class="controls bullet"><span class="by">bjourne</span><span>|</span><a href="#39309867">prev</a><span>|</span><a href="#39307535">next</a><span>|</span><label class="collapse" for="c-39307936">[-]</label><label class="expand" for="c-39307936">[1 more]</label></div><br/><div class="children"><div class="content">That must mean they found some similarity metric for high-level chess which is very impressive. In chess one pawn moving one square can be the difference between a won and a lost position. But knowing that usually requires lots of calculation.</div><br/></div></div><div id="39307535" class="c"><input type="checkbox" id="c-39307535" checked=""/><div class="controls bullet"><span class="by">xianshou</span><span>|</span><a href="#39307936">prev</a><span>|</span><a href="#39304034">next</a><span>|</span><label class="collapse" for="c-39307535">[-]</label><label class="expand" for="c-39307535">[6 more]</label></div><br/><div class="children"><div class="content">The path to AGI:<p>0. Have model A.<p>1. Use Monte Carlo with A to get supervised data.<p>2. Train model B with data from A.<p>3. Use Monte Carlo with B to get supervised data.<p>4. Train model C with data from B...</div><br/><div id="39307778" class="c"><input type="checkbox" id="c-39307778" checked=""/><div class="controls bullet"><span class="by">rprenger</span><span>|</span><a href="#39307535">parent</a><span>|</span><a href="#39307812">next</a><span>|</span><label class="collapse" for="c-39307778">[-]</label><label class="expand" for="c-39307778">[1 more]</label></div><br/><div class="children"><div class="content">This is pretty close to how AlphaZero works.<p><a href="https:&#x2F;&#x2F;medium.com&#x2F;applied-data-science&#x2F;alphago-zero-explained-in-one-diagram-365f5abf67e0" rel="nofollow">https:&#x2F;&#x2F;medium.com&#x2F;applied-data-science&#x2F;alphago-zero-explain...</a></div><br/></div></div><div id="39307812" class="c"><input type="checkbox" id="c-39307812" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#39307535">parent</a><span>|</span><a href="#39307778">prev</a><span>|</span><a href="#39307647">next</a><span>|</span><label class="collapse" for="c-39307812">[-]</label><label class="expand" for="c-39307812">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s basically how OpenAI is working.  They use generated training sets from one model to train the next model (plus other stuff with it).<p>But the &quot;other stuff&quot; is pretty important.  That is what pulls it away from just constantly re-amplifying the bias in the initial training data.</div><br/><div id="39307972" class="c"><input type="checkbox" id="c-39307972" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#39307535">root</a><span>|</span><a href="#39307812">parent</a><span>|</span><a href="#39307647">next</a><span>|</span><label class="collapse" for="c-39307972">[-]</label><label class="expand" for="c-39307972">[1 more]</label></div><br/><div class="children"><div class="content">I still want to see some examples of a &quot;mistake&quot; in the training data getting detected or reduced.<p>For example, somewhere in the training data the string &quot;All cats are red&quot; should get detected when lots of other data in the training set contradicts the statement.<p>And obviously it doesn&#x27;t have to be simple logical statements, but also bigger questions like &quot;how come the 2nd world war happened despite X person and Y person being on good speaking terms as evidenced by all these letters in the archives?&quot;<p>When AI can do that, it should be able to turn our body of knowledge into a much bigger&#x2F;more useful one by raising questions that arise from data we already have, but never noticed.</div><br/></div></div></div></div><div id="39307647" class="c"><input type="checkbox" id="c-39307647" checked=""/><div class="controls bullet"><span class="by">spencerchubb</span><span>|</span><a href="#39307535">parent</a><span>|</span><a href="#39307812">prev</a><span>|</span><a href="#39304034">next</a><span>|</span><label class="collapse" for="c-39307647">[-]</label><label class="expand" for="c-39307647">[2 more]</label></div><br/><div class="children"><div class="content">That is an awesome idea. I wish the authors would open source the code and weights so this can be tried.</div><br/><div id="39311693" class="c"><input type="checkbox" id="c-39311693" checked=""/><div class="controls bullet"><span class="by">bigmadshoe</span><span>|</span><a href="#39307535">root</a><span>|</span><a href="#39307647">parent</a><span>|</span><a href="#39304034">next</a><span>|</span><label class="collapse" for="c-39311693">[-]</label><label class="expand" for="c-39311693">[1 more]</label></div><br/><div class="children"><div class="content">They basically just described alphaZero, the difference being that alphaZero uses MCTS during inference too.</div><br/></div></div></div></div></div></div><div id="39304034" class="c"><input type="checkbox" id="c-39304034" checked=""/><div class="controls bullet"><span class="by">zniturah</span><span>|</span><a href="#39307535">prev</a><span>|</span><a href="#39308943">next</a><span>|</span><label class="collapse" for="c-39304034">[-]</label><label class="expand" for="c-39304034">[14 more]</label></div><br/><div class="children"><div class="content">They do use Stockfish for playing thought …<p>“To prevent some of these situations, we check whether the predicted scores for all top five moves lie above a win percentage of 99% and double-check this condition with Stockfish, and if so, use Stockfish’s top move (out of these) to have consistency in strategy across time-steps.”</div><br/><div id="39307400" class="c"><input type="checkbox" id="c-39307400" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#39304034">parent</a><span>|</span><a href="#39307219">next</a><span>|</span><label class="collapse" for="c-39307400">[-]</label><label class="expand" for="c-39307400">[2 more]</label></div><br/><div class="children"><div class="content">The context of that sentence:<p>&gt; <i>Indecisiveness in the face of overwhelming victory</i><p>&gt; <i>If Stockfish detects a mate-in-k (e.g., 3 or 5) it outputs k and not a centipawn score. We map all such outputs to the maximal value bin (i.e., a win percentage of 100%). Similarly, in a very strong position, several actions may end up in the maximum value bin. Thus, across time-steps this can lead to our agent playing somewhat randomly, rather than committing to one plan that finishes the game quickly (the agent has no knowledge of its past moves). This creates the paradoxical situation that our bot, despite being in a position of overwhelming win percentage, fails to take the (virtually) guaranteed win and might draw or even end up losing since small chances of a mistake accumulate with longer games (see Figure 4). To prevent some of these situations, we check whether the predicted scores for all top five moves lie above a win percentage of 99% and double-check this condition with Stockfish, and if so, use Stockfish’s top move (out of these) to have consistency in strategy across time-steps.</i></div><br/><div id="39308337" class="c"><input type="checkbox" id="c-39308337" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307400">parent</a><span>|</span><a href="#39307219">next</a><span>|</span><label class="collapse" for="c-39308337">[-]</label><label class="expand" for="c-39308337">[1 more]</label></div><br/><div class="children"><div class="content">They should try to implement some kind of resolute agent in that case. Might be hard to do if it needs to be &quot;not technically search&quot; though.</div><br/></div></div></div></div><div id="39307219" class="c"><input type="checkbox" id="c-39307219" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39304034">parent</a><span>|</span><a href="#39307400">prev</a><span>|</span><a href="#39308943">next</a><span>|</span><label class="collapse" for="c-39307219">[-]</label><label class="expand" for="c-39307219">[11 more]</label></div><br/><div class="children"><div class="content">But only to complete a winning position.</div><br/><div id="39307980" class="c"><input type="checkbox" id="c-39307980" checked=""/><div class="controls bullet"><span class="by">billforsternz</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307219">parent</a><span>|</span><a href="#39307346">next</a><span>|</span><label class="collapse" for="c-39307980">[-]</label><label class="expand" for="c-39307980">[1 more]</label></div><br/><div class="children"><div class="content">The process of converting a completely winning position (typically one with a large material advantage) is a phase change relative to normal play which is the struggle to achieve such a position. In other words you are doing something different at that point. For example, me as weak FIDE CM (Candidate Master) could not compete with a top grandmaster in a game of chess, but I could finish off a trivial win.<p>Edit: Recently I brought some ancient (1978) chess software back to life <a href="https:&#x2F;&#x2F;github.com&#x2F;billforsternz&#x2F;retro-sargon">https:&#x2F;&#x2F;github.com&#x2F;billforsternz&#x2F;retro-sargon</a>. These two phases of chess, basically two different games, were quite noticeable with that program, which is chess software stripped back to the bone. Sargon 1978 could play decently well, but it absolutely did not have the technique to convert winning positions (because this is different challenge to regular chess). For example, it could not in general mate with rook (or even queen)  and king against bare king. The technique of squeezing the enemy king into a progressively smaller box was unknown to it.</div><br/></div></div><div id="39307346" class="c"><input type="checkbox" id="c-39307346" checked=""/><div class="controls bullet"><span class="by">phoe-krk</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307219">parent</a><span>|</span><a href="#39307980">prev</a><span>|</span><a href="#39307628">next</a><span>|</span><label class="collapse" for="c-39307346">[-]</label><label class="expand" for="c-39307346">[2 more]</label></div><br/><div class="children"><div class="content">From the abstract:<p><i>&gt; We annotate each board in the dataset with action-values provided by the powerful Stockfish 16 engine, leading to roughly 15 billion data points.</i><p>So some of the learning data comes from Stockfish.</div><br/><div id="39307599" class="c"><input type="checkbox" id="c-39307599" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307346">parent</a><span>|</span><a href="#39307628">next</a><span>|</span><label class="collapse" for="c-39307599">[-]</label><label class="expand" for="c-39307599">[1 more]</label></div><br/><div class="children"><div class="content">The original comment was &quot;for playing.&quot;<p>In training, traditional search is absolutely used to score positions.<p>In playing, search is not used. (*Except to finish out an already-won position.)</div><br/></div></div></div></div><div id="39307628" class="c"><input type="checkbox" id="c-39307628" checked=""/><div class="controls bullet"><span class="by">zniturah</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307219">parent</a><span>|</span><a href="#39307346">prev</a><span>|</span><a href="#39308943">next</a><span>|</span><label class="collapse" for="c-39307628">[-]</label><label class="expand" for="c-39307628">[7 more]</label></div><br/><div class="children"><div class="content">That &#x27;only&#x27; usage in the winning position could be a decisive for gaining GM rating.</div><br/><div id="39307655" class="c"><input type="checkbox" id="c-39307655" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307628">parent</a><span>|</span><a href="#39307650">next</a><span>|</span><label class="collapse" for="c-39307655">[-]</label><label class="expand" for="c-39307655">[4 more]</label></div><br/><div class="children"><div class="content">Positions with 99% win percentage are not decisive for GM vs non-GM rating.</div><br/><div id="39307775" class="c"><input type="checkbox" id="c-39307775" checked=""/><div class="controls bullet"><span class="by">zniturah</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307655">parent</a><span>|</span><a href="#39307752">next</a><span>|</span><label class="collapse" for="c-39307775">[-]</label><label class="expand" for="c-39307775">[2 more]</label></div><br/><div class="children"><div class="content">Proof?<p>For winning any game at some point (at the end of the game) there will be a position with &gt;99% winning chances. The move that follows are decisive.</div><br/><div id="39308096" class="c"><input type="checkbox" id="c-39308096" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307775">parent</a><span>|</span><a href="#39307752">next</a><span>|</span><label class="collapse" for="c-39308096">[-]</label><label class="expand" for="c-39308096">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not how chess works. The move that follow aren&#x27;t usually decisive unless you don&#x27;t know how to play the game and make enormous mistakes.<p>Anyone that knows how to play can beat a GM with a big enough advantage at the end of the game (which is what&#x27;s reflected in the win probability).</div><br/></div></div></div></div><div id="39307752" class="c"><input type="checkbox" id="c-39307752" checked=""/><div class="controls bullet"><span class="by">Someone</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307655">parent</a><span>|</span><a href="#39307775">prev</a><span>|</span><a href="#39307650">next</a><span>|</span><label class="collapse" for="c-39307752">[-]</label><label class="expand" for="c-39307752">[1 more]</label></div><br/><div class="children"><div class="content">They are once your opponents know you’re very bad at converting them.</div><br/></div></div></div></div><div id="39307650" class="c"><input type="checkbox" id="c-39307650" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307628">parent</a><span>|</span><a href="#39307655">prev</a><span>|</span><a href="#39308943">next</a><span>|</span><label class="collapse" for="c-39307650">[-]</label><label class="expand" for="c-39307650">[2 more]</label></div><br/><div class="children"><div class="content">Search isn&#x27;t used to play&#x2F;win here. Just for training.</div><br/><div id="39307750" class="c"><input type="checkbox" id="c-39307750" checked=""/><div class="controls bullet"><span class="by">cool_dude85</span><span>|</span><a href="#39304034">root</a><span>|</span><a href="#39307650">parent</a><span>|</span><a href="#39308943">next</a><span>|</span><label class="collapse" for="c-39307750">[-]</label><label class="expand" for="c-39307750">[1 more]</label></div><br/><div class="children"><div class="content">It looks like it does use search here in the sense that Stockfish&#x27;s top move is generated using search.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39308943" class="c"><input type="checkbox" id="c-39308943" checked=""/><div class="controls bullet"><span class="by">penjelly</span><span>|</span><a href="#39304034">prev</a><span>|</span><a href="#39311830">next</a><span>|</span><label class="collapse" for="c-39308943">[-]</label><label class="expand" for="c-39308943">[2 more]</label></div><br/><div class="children"><div class="content">i dont follow... even if its trained anc doesnt use search isnt the act of it deciding the next move a sortof search anyway based off its training? Ive heard people describe LLMs as extremely broad search, basically attempting to build world model and then predicting the next world based on that. Is this fundamentally different from search? Am i wrong in my assumptions here?</div><br/><div id="39309136" class="c"><input type="checkbox" id="c-39309136" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#39308943">parent</a><span>|</span><a href="#39311830">next</a><span>|</span><label class="collapse" for="c-39309136">[-]</label><label class="expand" for="c-39309136">[1 more]</label></div><br/><div class="children"><div class="content">We know the model is approximating the results of a search. We don’t know whether it is actually searching.<p>At the most basic level, the model is just giving probabilities for the next moves, or in the case of value approximation, guessing which bucket the value falls into.</div><br/></div></div></div></div><div id="39311830" class="c"><input type="checkbox" id="c-39311830" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#39308943">prev</a><span>|</span><a href="#39307751">next</a><span>|</span><label class="collapse" for="c-39311830">[-]</label><label class="expand" for="c-39311830">[1 more]</label></div><br/><div class="children"><div class="content">&quot;We annotate each board in the dataset with action-values provided by the powerful Stockfish 16 engine, leading to roughly 15 billion data points [...] without any domain-specific tweaks or explicit search algorithms.&quot;<p>?</div><br/></div></div><div id="39307751" class="c"><input type="checkbox" id="c-39307751" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#39311830">prev</a><span>|</span><a href="#39310935">next</a><span>|</span><label class="collapse" for="c-39307751">[-]</label><label class="expand" for="c-39307751">[3 more]</label></div><br/><div class="children"><div class="content">Now do Go. :)</div><br/><div id="39308076" class="c"><input type="checkbox" id="c-39308076" checked=""/><div class="controls bullet"><span class="by">Kon5ole</span><span>|</span><a href="#39307751">parent</a><span>|</span><a href="#39310935">next</a><span>|</span><label class="collapse" for="c-39308076">[-]</label><label class="expand" for="c-39308076">[2 more]</label></div><br/><div class="children"><div class="content">This used to be a comforting thought whenever computers beat humans in chess, but I think that time has passed. The paper mentions AlphaZero [1], which has beaten AlphaGo, which beat Lee Sedol back in 2016 [2].<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AlphaZero" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AlphaZero</a><p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AlphaGo_versus_Lee_Sedol" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AlphaGo_versus_Lee_Sedol</a></div><br/><div id="39308763" class="c"><input type="checkbox" id="c-39308763" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#39307751">root</a><span>|</span><a href="#39308076">parent</a><span>|</span><a href="#39310935">next</a><span>|</span><label class="collapse" for="c-39308763">[-]</label><label class="expand" for="c-39308763">[1 more]</label></div><br/><div class="children"><div class="content">My pithy comment probably wasn&#x27;t enough to express what I meant. :)<p>I know that computers have already beaten humans at Go.  But what&#x27;s interesting is that in both the chess and Go cases, a lot of real-time compute was necessary to win the games.  Now we have a potential way to build the model ahead of time such that the computer during interactive play is much smaller.<p>This means that we can be much more portable with the solution, and it also means that for online game companies, they can spend a lot less money on gameplay, especially if gameplay is most of their compute.</div><br/></div></div></div></div></div></div><div id="39310935" class="c"><input type="checkbox" id="c-39310935" checked=""/><div class="controls bullet"><span class="by">charcircuit</span><span>|</span><a href="#39307751">prev</a><span>|</span><a href="#39312123">next</a><span>|</span><label class="collapse" for="c-39310935">[-]</label><label class="expand" for="c-39310935">[1 more]</label></div><br/><div class="children"><div class="content">argmax and argmin are searching. Just because it isn&#x27;t a search with a lot of depth that doesn&#x27;t mean it isn&#x27;t searching.</div><br/></div></div><div id="39312123" class="c"><input type="checkbox" id="c-39312123" checked=""/><div class="controls bullet"><span class="by">lettergram</span><span>|</span><a href="#39310935">prev</a><span>|</span><a href="#39307908">next</a><span>|</span><label class="collapse" for="c-39312123">[-]</label><label class="expand" for="c-39312123">[1 more]</label></div><br/><div class="children"><div class="content">I immediately saw this and knew it was BS. It’s a search problem, the human brain even does a search. Model internally is scanning each position and determining the next probably position. That is a predictive  search, you can’t just restructure the problem.<p>Now arguably it’s doing it differently, maybe? But still a search</div><br/></div></div><div id="39307908" class="c"><input type="checkbox" id="c-39307908" checked=""/><div class="controls bullet"><span class="by">ivanjermakov</span><span>|</span><a href="#39312123">prev</a><span>|</span><label class="collapse" for="c-39307908">[-]</label><label class="expand" for="c-39307908">[1 more]</label></div><br/><div class="children"><div class="content">I thought clickbaity titles were discouraged in whitepaper world.</div><br/></div></div></div></div></div></div></div></body></html>