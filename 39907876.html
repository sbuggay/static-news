<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712134865344" as="style"/><link rel="stylesheet" href="styles.css?v=1712134865344"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://dekuliutesla.github.io/citygs/">CityGaussian: Real-time high-quality large-scale scene rendering with Gaussians</a> <span class="domain">(<a href="https://dekuliutesla.github.io">dekuliutesla.github.io</a>)</span></div><div class="subtext"><span>smusamashah</span> | <span>112 comments</span></div><br/><div><div id="39910457" class="c"><input type="checkbox" id="c-39910457" checked=""/><div class="controls bullet"><span class="by">speps</span><span>|</span><a href="#39909110">next</a><span>|</span><label class="collapse" for="c-39910457">[-]</label><label class="expand" for="c-39910457">[16 more]</label></div><br/><div class="children"><div class="content">Note that the dataset from the video is called Matrix city. It&#x27;s highly likely extracted from the Unreal Engine 5 Matrix demo released a few years ago. The views look very similar, so it&#x27;s photorealistic but not from photos.<p>EDIT: here it is, and I was right! <a href="https:&#x2F;&#x2F;city-super.github.io&#x2F;matrixcity&#x2F;" rel="nofollow">https:&#x2F;&#x2F;city-super.github.io&#x2F;matrixcity&#x2F;</a></div><br/><div id="39910679" class="c"><input type="checkbox" id="c-39910679" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#39910457">parent</a><span>|</span><a href="#39913510">next</a><span>|</span><label class="collapse" for="c-39910679">[-]</label><label class="expand" for="c-39910679">[2 more]</label></div><br/><div class="children"><div class="content">Epic acquired the photogrammetry company Quixel a while ago, so it&#x27;s quite likely they used their photo-scanned asset library when building the Matrix city. Funnily that would mean the OP is doing reconstructions of reconstructions of real objects.</div><br/><div id="39911310" class="c"><input type="checkbox" id="c-39911310" checked=""/><div class="controls bullet"><span class="by">reactordev</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39910679">parent</a><span>|</span><a href="#39913510">next</a><span>|</span><label class="collapse" for="c-39911310">[-]</label><label class="expand" for="c-39911310">[1 more]</label></div><br/><div class="children"><div class="content">Or just rendering it mixed with some splats, we don’t know because they didn’t release their source code. I’m highly skeptical of their claims, their dataset, and the fact that it’s trivial to export it into some other viewer to fake it.</div><br/></div></div></div></div><div id="39913510" class="c"><input type="checkbox" id="c-39913510" checked=""/><div class="controls bullet"><span class="by">affgrff2</span><span>|</span><a href="#39910457">parent</a><span>|</span><a href="#39910679">prev</a><span>|</span><a href="#39910532">next</a><span>|</span><label class="collapse" for="c-39913510">[-]</label><label class="expand" for="c-39913510">[3 more]</label></div><br/><div class="children"><div class="content">Just want to add that using data from a game engine gives you perfect camera poses associated to each image. That makes training of nerfs and GS a little easier since there is no error from camera pose optimization. That&#x27;s also the reason early Nerf papers used the famous yellow Lego excavator rendered with blender.</div><br/><div id="39914599" class="c"><input type="checkbox" id="c-39914599" checked=""/><div class="controls bullet"><span class="by">MrSkyNet</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39913510">parent</a><span>|</span><a href="#39910532">next</a><span>|</span><label class="collapse" for="c-39914599">[-]</label><label class="expand" for="c-39914599">[2 more]</label></div><br/><div class="children"><div class="content">How so?<p>Through pixel perfect alignment? Resolution?</div><br/><div id="39914772" class="c"><input type="checkbox" id="c-39914772" checked=""/><div class="controls bullet"><span class="by">arussellsaw</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39914599">parent</a><span>|</span><a href="#39910532">next</a><span>|</span><label class="collapse" for="c-39914772">[-]</label><label class="expand" for="c-39914772">[1 more]</label></div><br/><div class="children"><div class="content">one of the fundamental problems in photogrammetry is determining the position of the camera in 3D space, with a game engine you just have a concrete value for your camera position, removing that entire problem. I don&#x27;t know too much about photogrammetry but i&#x27;d imagine once your camera position is 100% accurate it&#x27;s a lot easier to construct the point cloud accurately.</div><br/></div></div></div></div></div></div><div id="39910532" class="c"><input type="checkbox" id="c-39910532" checked=""/><div class="controls bullet"><span class="by">speps</span><span>|</span><a href="#39910457">parent</a><span>|</span><a href="#39913510">prev</a><span>|</span><a href="#39910788">next</a><span>|</span><label class="collapse" for="c-39910532">[-]</label><label class="expand" for="c-39910532">[9 more]</label></div><br/><div class="children"><div class="content">Replying to myself with a question, as someone could have the answer: Would it be possible to create the splats without the training phase? If we have a fully modelled scene in Unreal Engine for example (like Matrix city), you shouldn&#x27;t need to spend all the time training to recreate the data...</div><br/><div id="39911130" class="c"><input type="checkbox" id="c-39911130" checked=""/><div class="controls bullet"><span class="by">somethingsome</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39910532">parent</a><span>|</span><a href="#39910659">next</a><span>|</span><label class="collapse" for="c-39911130">[-]</label><label class="expand" for="c-39911130">[1 more]</label></div><br/><div class="children"><div class="content">Of course! And this was done many times in the past, probably with better results than current deep learning based gaussian splatting where they use way too many splats to render a scene.<p>Basically the problem with sparse pictures and point clouds in general is their lack of topology and not precise spatial position. But when you already have the topology (eg with a mesh), you can extract (optimally) a set of points and compute the radius of the splats such that there are no holes in the final image (and their color). That is usually done with the curvature and the normal.<p>The &#x27;optimally&#x27; part is difficult, an easier and faster approach is just to do a greedy pass to select good enough splats.</div><br/></div></div><div id="39910659" class="c"><input type="checkbox" id="c-39910659" checked=""/><div class="controls bullet"><span class="by">sorenjan</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39910532">parent</a><span>|</span><a href="#39911130">prev</a><span>|</span><a href="#39910698">next</a><span>|</span><label class="collapse" for="c-39910659">[-]</label><label class="expand" for="c-39910659">[3 more]</label></div><br/><div class="children"><div class="content">Yes, it&#x27;s possible to create gaussian splats from a mesh. See for example step 3 in SuGaR: <a href="https:&#x2F;&#x2F;imagine.enpc.fr&#x2F;~guedona&#x2F;sugar&#x2F;" rel="nofollow">https:&#x2F;&#x2F;imagine.enpc.fr&#x2F;~guedona&#x2F;sugar&#x2F;</a></div><br/><div id="39910734" class="c"><input type="checkbox" id="c-39910734" checked=""/><div class="controls bullet"><span class="by">fudged71</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39910659">parent</a><span>|</span><a href="#39910698">next</a><span>|</span><label class="collapse" for="c-39910734">[-]</label><label class="expand" for="c-39910734">[2 more]</label></div><br/><div class="children"><div class="content">Are you referring to the gaussian splat rasterizer?</div><br/><div id="39911047" class="c"><input type="checkbox" id="c-39911047" checked=""/><div class="controls bullet"><span class="by">sorenjan</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39910734">parent</a><span>|</span><a href="#39910698">next</a><span>|</span><label class="collapse" for="c-39911047">[-]</label><label class="expand" for="c-39911047">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m referring to using the modeled scene to bind gaussian splats to an existing mesh.<p>&gt; Binding New 3D Gaussians to the Mesh<p>&gt; This binding strategy also makes possible the use of traditional mesh-editing tools for editing a Gaussian Splatting representation of a scene</div><br/></div></div></div></div></div></div><div id="39910698" class="c"><input type="checkbox" id="c-39910698" checked=""/><div class="controls bullet"><span class="by">fudged71</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39910532">parent</a><span>|</span><a href="#39910659">prev</a><span>|</span><a href="#39910617">next</a><span>|</span><label class="collapse" for="c-39910698">[-]</label><label class="expand" for="c-39910698">[2 more]</label></div><br/><div class="children"><div class="content">I could be wrong, but being able to remove the step of estimating the camera position would save a large amount of time. You’re still going to need to train on the images to create the splats</div><br/><div id="39912999" class="c"><input type="checkbox" id="c-39912999" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39910698">parent</a><span>|</span><a href="#39910617">next</a><span>|</span><label class="collapse" for="c-39912999">[-]</label><label class="expand" for="c-39912999">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If we have a fully modelled scene in Unreal Engine for example...<p>No images involved, so no training required.</div><br/></div></div></div></div><div id="39910617" class="c"><input type="checkbox" id="c-39910617" checked=""/><div class="controls bullet"><span class="by">kfarr</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39910532">parent</a><span>|</span><a href="#39910698">prev</a><span>|</span><a href="#39910788">next</a><span>|</span><label class="collapse" for="c-39910617">[-]</label><label class="expand" for="c-39910617">[2 more]</label></div><br/><div class="children"><div class="content">Yes, and then it gets interesting to think about procedurally generated splats, such as spawning a randomized distribution of grass splats on a field for example</div><br/><div id="39913035" class="c"><input type="checkbox" id="c-39913035" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#39910457">root</a><span>|</span><a href="#39910617">parent</a><span>|</span><a href="#39910788">next</a><span>|</span><label class="collapse" for="c-39913035">[-]</label><label class="expand" for="c-39913035">[1 more]</label></div><br/><div class="children"><div class="content">To me the big issue is image quality versus generative efficiency. If splats make rending complicated scenes efficient without requiring a lot of data&#x2F;calculation &quot;scaffolding&quot; then you could do almost everything procedurally, maybe using AI models to fill in definitional detail.</div><br/></div></div></div></div></div></div><div id="39910788" class="c"><input type="checkbox" id="c-39910788" checked=""/><div class="controls bullet"><span class="by">ttmb</span><span>|</span><a href="#39910457">parent</a><span>|</span><a href="#39910532">prev</a><span>|</span><a href="#39909110">next</a><span>|</span><label class="collapse" for="c-39910788">[-]</label><label class="expand" for="c-39910788">[1 more]</label></div><br/><div class="children"><div class="content">Not all of the videos are Matrix City, some are real places.</div><br/></div></div></div></div><div id="39909110" class="c"><input type="checkbox" id="c-39909110" checked=""/><div class="controls bullet"><span class="by">kfarr</span><span>|</span><a href="#39910457">prev</a><span>|</span><a href="#39908555">next</a><span>|</span><label class="collapse" for="c-39909110">[-]</label><label class="expand" for="c-39909110">[8 more]</label></div><br/><div class="children"><div class="content">Not quite the same thing, but over the weekend I hacked google maps 3d tiles (mesh) together with a gaussian splat and the effect is pretty similar and effective:<p>Example 1 with code linked: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;kfarr&#x2F;status&#x2F;1773934700878561396" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;kfarr&#x2F;status&#x2F;1773934700878561396</a><p>Example 2 <a href="https:&#x2F;&#x2F;twitter.com&#x2F;3dstreetapp&#x2F;status&#x2F;1775203540442697782" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;3dstreetapp&#x2F;status&#x2F;1775203540442697782</a></div><br/><div id="39909968" class="c"><input type="checkbox" id="c-39909968" checked=""/><div class="controls bullet"><span class="by">cchance</span><span>|</span><a href="#39909110">parent</a><span>|</span><a href="#39914545">next</a><span>|</span><label class="collapse" for="c-39909968">[-]</label><label class="expand" for="c-39909968">[2 more]</label></div><br/><div class="children"><div class="content">Thats really cool is there a github with the code...<p>getting errors on that first link in devtools<p>Uncaught (in promise) Error: Failed to fetch resource <a href="https:&#x2F;&#x2F;tile.googleapis.com&#x2F;v1&#x2F;3dti" rel="nofollow">https:&#x2F;&#x2F;tile.googleapis.com&#x2F;v1&#x2F;3dti</a>...</div><br/><div id="39910234" class="c"><input type="checkbox" id="c-39910234" checked=""/><div class="controls bullet"><span class="by">kfarr</span><span>|</span><a href="#39909110">root</a><span>|</span><a href="#39909968">parent</a><span>|</span><a href="#39914545">next</a><span>|</span><label class="collapse" for="c-39910234">[-]</label><label class="expand" for="c-39910234">[1 more]</label></div><br/><div class="children"><div class="content">Probably rate limited api calls given the hug of Twitter and HN. Capped at 1k per day see <a href="https:&#x2F;&#x2F;github.com&#x2F;3DStreet&#x2F;aframe-loader-3dtiles-component">https:&#x2F;&#x2F;github.com&#x2F;3DStreet&#x2F;aframe-loader-3dtiles-component</a><p>Code is available via glitch url</div><br/></div></div></div></div><div id="39914545" class="c"><input type="checkbox" id="c-39914545" checked=""/><div class="controls bullet"><span class="by">ctrlw</span><span>|</span><a href="#39909110">parent</a><span>|</span><a href="#39909968">prev</a><span>|</span><a href="#39909472">next</a><span>|</span><label class="collapse" for="c-39914545">[-]</label><label class="expand" for="c-39914545">[1 more]</label></div><br/><div class="children"><div class="content">That looks great! I‘ve been playing around with Aframe and OSM building footprints, but this looks so much better. Will have a look at aframe-loader-3dtiles-component.</div><br/></div></div><div id="39909472" class="c"><input type="checkbox" id="c-39909472" checked=""/><div class="controls bullet"><span class="by">sbarre</span><span>|</span><a href="#39909110">parent</a><span>|</span><a href="#39914545">prev</a><span>|</span><a href="#39910254">next</a><span>|</span><label class="collapse" for="c-39909472">[-]</label><label class="expand" for="c-39909472">[1 more]</label></div><br/><div class="children"><div class="content">This is super cool!  Congrats on the PoC ...</div><br/></div></div><div id="39910254" class="c"><input type="checkbox" id="c-39910254" checked=""/><div class="controls bullet"><span class="by">aantix</span><span>|</span><a href="#39909110">parent</a><span>|</span><a href="#39909472">prev</a><span>|</span><a href="#39911673">next</a><span>|</span><label class="collapse" for="c-39910254">[-]</label><label class="expand" for="c-39910254">[1 more]</label></div><br/><div class="children"><div class="content">Wow, amazing work!</div><br/></div></div><div id="39911673" class="c"><input type="checkbox" id="c-39911673" checked=""/><div class="controls bullet"><span class="by">aaroninsf</span><span>|</span><a href="#39909110">parent</a><span>|</span><a href="#39910254">prev</a><span>|</span><a href="#39908555">next</a><span>|</span><label class="collapse" for="c-39911673">[-]</label><label class="expand" for="c-39911673">[2 more]</label></div><br/><div class="children"><div class="content">Are you on Bluesky?<p>Would love to follow. But not, you know, over there.</div><br/><div id="39912154" class="c"><input type="checkbox" id="c-39912154" checked=""/><div class="controls bullet"><span class="by">kfarr</span><span>|</span><a href="#39909110">root</a><span>|</span><a href="#39911673">parent</a><span>|</span><a href="#39908555">next</a><span>|</span><label class="collapse" for="c-39912154">[-]</label><label class="expand" for="c-39912154">[1 more]</label></div><br/><div class="children"><div class="content">Closest I can offer is <a href="https:&#x2F;&#x2F;sfba.social&#x2F;@kfarr&#x2F;112204337465256518" rel="nofollow">https:&#x2F;&#x2F;sfba.social&#x2F;@kfarr&#x2F;112204337465256518</a></div><br/></div></div></div></div></div></div><div id="39908555" class="c"><input type="checkbox" id="c-39908555" checked=""/><div class="controls bullet"><span class="by">chpatrick</span><span>|</span><a href="#39909110">prev</a><span>|</span><a href="#39914672">next</a><span>|</span><label class="collapse" for="c-39908555">[-]</label><label class="expand" for="c-39908555">[32 more]</label></div><br/><div class="children"><div class="content">&quot;The average speed is 36 FPS (tested on A100).&quot;<p>Real-Time if you have $8k I guess.</div><br/><div id="39908954" class="c"><input type="checkbox" id="c-39908954" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39908681">next</a><span>|</span><label class="collapse" for="c-39908954">[-]</label><label class="expand" for="c-39908954">[15 more]</label></div><br/><div class="children"><div class="content">Good ol&#x27; &quot;SIGGRAPH realtime&quot;, when a graphics paper describes itself as achieving realtime speeds you always have to double check that they mean actually realtime and not &quot;640x480 at 20fps on the most expensive hardware money can buy&quot;. Anything can be realtime if you set the bar low enough.</div><br/><div id="39910530" class="c"><input type="checkbox" id="c-39910530" checked=""/><div class="controls bullet"><span class="by">oivey</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39908954">parent</a><span>|</span><a href="#39909470">next</a><span>|</span><label class="collapse" for="c-39910530">[-]</label><label class="expand" for="c-39910530">[7 more]</label></div><br/><div class="children"><div class="content">Depending on what you’re doing, that really isn’t a low bar. Saying you can get decent performance on any hardware is the first step.</div><br/><div id="39910705" class="c"><input type="checkbox" id="c-39910705" checked=""/><div class="controls bullet"><span class="by">PheonixPharts</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39910530">parent</a><span>|</span><a href="#39910605">prev</a><span>|</span><a href="#39909470">next</a><span>|</span><label class="collapse" for="c-39910705">[-]</label><label class="expand" for="c-39910705">[5 more]</label></div><br/><div class="children"><div class="content">&gt; get decent performance<p>The issue is that in Computer Science &quot;real-time&quot; doesn&#x27;t just mean &quot;pretty fast&quot;, it&#x27;s a very specific definition of performance[0]. Doing &quot;real-time&quot; computing is generally considered <i>hard</i> even for problems that are themselves not too challenging, and involves potentially severe consequences for missing a computational deadline.<p>Which leads to both confusion and a bit of frustration when sub-fields of CS throw around the term as if it just means &quot;we don&#x27;t have to wait a long time for it to render&quot; or &quot;you can watch it happen&quot;.<p>[0] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Real-time_computing" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Real-time_computing</a></div><br/><div id="39911724" class="c"><input type="checkbox" id="c-39911724" checked=""/><div class="controls bullet"><span class="by">aleksiy123</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39910705">parent</a><span>|</span><a href="#39911986">next</a><span>|</span><label class="collapse" for="c-39911724">[-]</label><label class="expand" for="c-39911724">[1 more]</label></div><br/><div class="children"><div class="content">That link defines it in terms of simulation as well: &quot;The term &quot;real-time&quot; is also used in simulation to mean that the simulation&#x27;s clock runs at the same speed as a real clock.&quot; and even states that was the original usage of the term.<p>I think that pretty much meets the definition of  &quot;you can watch it happen&quot;.<p>Essentially there is real-time systems and real-time simulation. So it seems that they are using the term correctly in the context of simulation.</div><br/></div></div><div id="39911986" class="c"><input type="checkbox" id="c-39911986" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39910705">parent</a><span>|</span><a href="#39911724">prev</a><span>|</span><a href="#39909470">next</a><span>|</span><label class="collapse" for="c-39911986">[-]</label><label class="expand" for="c-39911986">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s reasonable to expect the larger community to not use &quot;real time&quot; to mean things other than &quot;hard real time as understood by a hardware engineer building a system that needs guaranteed interrupt latencies&quot;.</div><br/><div id="39912911" class="c"><input type="checkbox" id="c-39912911" checked=""/><div class="controls bullet"><span class="by">Mtinie</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39911986">parent</a><span>|</span><a href="#39909470">next</a><span>|</span><label class="collapse" for="c-39912911">[-]</label><label class="expand" for="c-39912911">[2 more]</label></div><br/><div class="children"><div class="content">I think it’s reasonable to assume that it means what you described on this site.</div><br/><div id="39913139" class="c"><input type="checkbox" id="c-39913139" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39912911">parent</a><span>|</span><a href="#39909470">next</a><span>|</span><label class="collapse" for="c-39913139">[-]</label><label class="expand" for="c-39913139">[1 more]</label></div><br/><div class="children"><div class="content">Of course.  I&#x27;m in the &quot;Reality is just 100M lit, shaded, textured polygons per second&quot; kind of guy- realtime is about 65 FPS with no jank.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39909470" class="c"><input type="checkbox" id="c-39909470" checked=""/><div class="controls bullet"><span class="by">phkahler</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39908954">parent</a><span>|</span><a href="#39910530">prev</a><span>|</span><a href="#39911518">next</a><span>|</span><label class="collapse" for="c-39909470">[-]</label><label class="expand" for="c-39909470">[2 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; Anything can be realtime if you set the bar low enough.<p>I was doing &quot;realtime ray tracing&quot; on Pentium class computers in the 1990s. I took my toy ray tracer and made an OLE control and put it inside a small Visual Basic app which handled keypress-navigation. It could run in a tiny little window (size of a large icon) at reasonable frame rates. Might even say it was using Visual Basic! So yeah &quot;realtime&quot; needs some qualifiers ;-)</div><br/><div id="39911255" class="c"><input type="checkbox" id="c-39911255" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39909470">parent</a><span>|</span><a href="#39911518">next</a><span>|</span><label class="collapse" for="c-39911255">[-]</label><label class="expand" for="c-39911255">[1 more]</label></div><br/><div class="children"><div class="content">Fair, but today it could probably run 30FPS full-screen at 2K resolution, without any special effort, on an average consumer-grade machine; better if ported to take advantage of the GPU.<p>Moore&#x27;s law may be dead in general, but computing power still increases (notwithstanding the software bloat that makes it seem otherwise), and it&#x27;s still something to count on wrt. bleeding edge research demos.</div><br/></div></div></div></div><div id="39911518" class="c"><input type="checkbox" id="c-39911518" checked=""/><div class="controls bullet"><span class="by">VelesDude</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39908954">parent</a><span>|</span><a href="#39909470">prev</a><span>|</span><a href="#39910742">next</a><span>|</span><label class="collapse" for="c-39911518">[-]</label><label class="expand" for="c-39911518">[2 more]</label></div><br/><div class="children"><div class="content">Microsoft once set the bar for realtime as 640x480 @ 10fps. But this was just for research purposes. You can make out what it is trying to do and the update rate was JUST acceptable enough to be interactive.</div><br/><div id="39911844" class="c"><input type="checkbox" id="c-39911844" checked=""/><div class="controls bullet"><span class="by">harles</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39911518">parent</a><span>|</span><a href="#39910742">next</a><span>|</span><label class="collapse" for="c-39911844">[-]</label><label class="expand" for="c-39911844">[1 more]</label></div><br/><div class="children"><div class="content">I’d actually call that a good bar. If you’re looking 5-10 years down the line for consumers, it’s reasonable. If you think the results can influence hardware directions sooner than that (for better performance) it’s also reasonable.</div><br/></div></div></div></div><div id="39910742" class="c"><input type="checkbox" id="c-39910742" checked=""/><div class="controls bullet"><span class="by">mateo1</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39908954">parent</a><span>|</span><a href="#39911518">prev</a><span>|</span><a href="#39909976">next</a><span>|</span><label class="collapse" for="c-39910742">[-]</label><label class="expand" for="c-39910742">[1 more]</label></div><br/><div class="children"><div class="content">It can be run real time. Might be 640x480 or 20 fps, but many algorithms out there could never been run on an $10k graphics card or even a computing cluster in real time.</div><br/></div></div><div id="39909976" class="c"><input type="checkbox" id="c-39909976" checked=""/><div class="controls bullet"><span class="by">cchance</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39908954">parent</a><span>|</span><a href="#39910742">prev</a><span>|</span><a href="#39908681">next</a><span>|</span><label class="collapse" for="c-39909976">[-]</label><label class="expand" for="c-39909976">[2 more]</label></div><br/><div class="children"><div class="content">I mean A100&#x27;s were cutting edge a year or so ago now we&#x27;re at what H200 and B200 or is it 300&#x27;s like it may be a year or 2 more but the A100 speed will trickle down to the average consumer as well.</div><br/><div id="39911280" class="c"><input type="checkbox" id="c-39911280" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39909976">parent</a><span>|</span><a href="#39908681">next</a><span>|</span><label class="collapse" for="c-39911280">[-]</label><label class="expand" for="c-39911280">[1 more]</label></div><br/><div class="children"><div class="content">And, from the other end, research demonstrations tend to have a lot of low-hanging fruits wrt. optimization, which will get picked if the result is interesting enough.</div><br/></div></div></div></div></div></div><div id="39908681" class="c"><input type="checkbox" id="c-39908681" checked=""/><div class="controls bullet"><span class="by">rallyforthesun</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39908954">prev</a><span>|</span><a href="#39910468">next</a><span>|</span><label class="collapse" for="c-39908681">[-]</label><label class="expand" for="c-39908681">[1 more]</label></div><br/><div class="children"><div class="content">As it seems the first 3DGS which uses Lods and blocks, there might be place for optimization. 
This might become useful for use cases in Virtual Production, probably not for mobiles.</div><br/></div></div><div id="39910468" class="c"><input type="checkbox" id="c-39910468" checked=""/><div class="controls bullet"><span class="by">m463</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39908681">prev</a><span>|</span><a href="#39910196">next</a><span>|</span><label class="collapse" for="c-39910468">[-]</label><label class="expand" for="c-39910468">[1 more]</label></div><br/><div class="children"><div class="content">otoh I remember those old GPU benchmarks that ran at 10 fps when they came out, then over time...<p><a href="https:&#x2F;&#x2F;www.techpowerup.com&#x2F;forums&#x2F;attachments&#x2F;all-cards-png.325351&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.techpowerup.com&#x2F;forums&#x2F;attachments&#x2F;all-cards-png...</a></div><br/></div></div><div id="39910196" class="c"><input type="checkbox" id="c-39910196" checked=""/><div class="controls bullet"><span class="by">pierotofy</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39910468">prev</a><span>|</span><a href="#39913502">next</a><span>|</span><label class="collapse" for="c-39910196">[-]</label><label class="expand" for="c-39910196">[2 more]</label></div><br/><div class="children"><div class="content">A lot of 3DGS&#x2F;Nerf research is like this unfortunately (ugh).<p>Check <a href="https:&#x2F;&#x2F;github.com&#x2F;pierotofy&#x2F;OpenSplat">https:&#x2F;&#x2F;github.com&#x2F;pierotofy&#x2F;OpenSplat</a> for something you can run on your 10 year old laptop, even without a GPU! (I&#x27;m the author)</div><br/><div id="39911220" class="c"><input type="checkbox" id="c-39911220" checked=""/><div class="controls bullet"><span class="by">somethingsome</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39910196">parent</a><span>|</span><a href="#39913502">next</a><span>|</span><label class="collapse" for="c-39911220">[-]</label><label class="expand" for="c-39911220">[1 more]</label></div><br/><div class="children"><div class="content">I know, I don&#x27;t get the fuzz either, I&#x27;ve coded real-time gaussian splat renderers &gt;7 years ago with LOD and they were able to show any kind of point cloud.<p>They worked with a basic 970 GTX  on a big 3d screen and also on oculus dk2.</div><br/></div></div></div></div><div id="39913502" class="c"><input type="checkbox" id="c-39913502" checked=""/><div class="controls bullet"><span class="by">aurareturn</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39910196">prev</a><span>|</span><a href="#39911676">next</a><span>|</span><label class="collapse" for="c-39913502">[-]</label><label class="expand" for="c-39913502">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m going to guess that the next-gen consumer GPU (5090) will be twice as fast as A100 and will not cost $8k.<p>So I don&#x27;t know see an insurmountable problem.</div><br/></div></div><div id="39911676" class="c"><input type="checkbox" id="c-39911676" checked=""/><div class="controls bullet"><span class="by">datascienced</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39913502">prev</a><span>|</span><a href="#39912719">next</a><span>|</span><label class="collapse" for="c-39911676">[-]</label><label class="expand" for="c-39911676">[1 more]</label></div><br/><div class="children"><div class="content">Just wait 2 years it’ll be on your phone.</div><br/></div></div><div id="39912719" class="c"><input type="checkbox" id="c-39912719" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39911676">prev</a><span>|</span><a href="#39908595">next</a><span>|</span><label class="collapse" for="c-39912719">[-]</label><label class="expand" for="c-39912719">[1 more]</label></div><br/><div class="children"><div class="content">You gotta start somewhere</div><br/></div></div><div id="39908595" class="c"><input type="checkbox" id="c-39908595" checked=""/><div class="controls bullet"><span class="by">RicoElectrico</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39912719">prev</a><span>|</span><a href="#39909089">next</a><span>|</span><label class="collapse" for="c-39908595">[-]</label><label class="expand" for="c-39908595">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Two more papers down the line...&quot; ;)</div><br/><div id="39908810" class="c"><input type="checkbox" id="c-39908810" checked=""/><div class="controls bullet"><span class="by">Fauntleroy</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39908595">parent</a><span>|</span><a href="#39909089">next</a><span>|</span><label class="collapse" for="c-39908810">[-]</label><label class="expand" for="c-39908810">[3 more]</label></div><br/><div class="children"><div class="content">Indeed, this very much looks like what we&#x27;ll likely see from Google Earth within a decade—or perhaps half that.</div><br/><div id="39911216" class="c"><input type="checkbox" id="c-39911216" checked=""/><div class="controls bullet"><span class="by">mortenjorck</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39908810">parent</a><span>|</span><a href="#39913107">next</a><span>|</span><label class="collapse" for="c-39911216">[-]</label><label class="expand" for="c-39911216">[1 more]</label></div><br/><div class="children"><div class="content">I’ve seen very impressive Gaussian splatting demos of more limited urban geographies (a few city blocks) running on consumer hardware, so the reason this requires research-tier Nvidia hardware right now is probably down to LOD streaming. More optimization on that front, and this could plausibly come to Google Earth on current devices.<p>“What a time to be alive” indeed!</div><br/></div></div><div id="39913107" class="c"><input type="checkbox" id="c-39913107" checked=""/><div class="controls bullet"><span class="by">xyproto</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39908810">parent</a><span>|</span><a href="#39911216">prev</a><span>|</span><a href="#39909089">next</a><span>|</span><label class="collapse" for="c-39913107">[-]</label><label class="expand" for="c-39913107">[1 more]</label></div><br/><div class="children"><div class="content">2 years tops, since the technology is there, it would be a considerable improvement to Google Maps, and Google has the required resources.</div><br/></div></div></div></div></div></div><div id="39909089" class="c"><input type="checkbox" id="c-39909089" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39908595">prev</a><span>|</span><a href="#39908997">next</a><span>|</span><label class="collapse" for="c-39909089">[-]</label><label class="expand" for="c-39909089">[3 more]</label></div><br/><div class="children"><div class="content">I chuckled a bit too when I saw it.<p>By the way, what&#x27;s the compute power difference between an A100 and a 4090?</div><br/><div id="39909784" class="c"><input type="checkbox" id="c-39909784" checked=""/><div class="controls bullet"><span class="by">enlyth</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39909089">parent</a><span>|</span><a href="#39909774">next</a><span>|</span><label class="collapse" for="c-39909784">[-]</label><label class="expand" for="c-39909784">[1 more]</label></div><br/><div class="children"><div class="content">I believe the main advantage of the A100 is the memory bandwidth. Computationally the 4090 has a higher clock speed and more CUDA cores, so in that way it is faster.<p>So for this specific application it really depends on where the bottleneck is</div><br/></div></div><div id="39909774" class="c"><input type="checkbox" id="c-39909774" checked=""/><div class="controls bullet"><span class="by">entropicdrifter</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39909089">parent</a><span>|</span><a href="#39909784">prev</a><span>|</span><a href="#39908997">next</a><span>|</span><label class="collapse" for="c-39909774">[-]</label><label class="expand" for="c-39909774">[1 more]</label></div><br/><div class="children"><div class="content">4090 is faster in terms of compute, but the A100 has 40GB of VRAM.</div><br/></div></div></div></div><div id="39908997" class="c"><input type="checkbox" id="c-39908997" checked=""/><div class="controls bullet"><span class="by">mywittyname</span><span>|</span><a href="#39908555">parent</a><span>|</span><a href="#39909089">prev</a><span>|</span><a href="#39914672">next</a><span>|</span><label class="collapse" for="c-39908997">[-]</label><label class="expand" for="c-39908997">[2 more]</label></div><br/><div class="children"><div class="content">Presumably, this is can be used as the first stage in a pipeline.  Take the models and textures generated from source data using this, cached it, and stream that data to clients for local rendering.<p>Consumer GPUs are probably 2-3 generations out from being as capable as an A100.</div><br/><div id="39909184" class="c"><input type="checkbox" id="c-39909184" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#39908555">root</a><span>|</span><a href="#39908997">parent</a><span>|</span><a href="#39914672">next</a><span>|</span><label class="collapse" for="c-39909184">[-]</label><label class="expand" for="c-39909184">[1 more]</label></div><br/><div class="children"><div class="content">There are no models or textures, it&#x27;s just a point cloud of color blobs.<p>You can convert it to a mesh, but in the process you&#x27;d lose the quality and realism that makes it interesting.</div><br/></div></div></div></div></div></div><div id="39914672" class="c"><input type="checkbox" id="c-39914672" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#39908555">prev</a><span>|</span><a href="#39911864">next</a><span>|</span><label class="collapse" for="c-39914672">[-]</label><label class="expand" for="c-39914672">[1 more]</label></div><br/><div class="children"><div class="content">Related <a href="https:&#x2F;&#x2F;city-super.github.io&#x2F;octree-gs&#x2F;" rel="nofollow">https:&#x2F;&#x2F;city-super.github.io&#x2F;octree-gs&#x2F;</a></div><br/></div></div><div id="39911864" class="c"><input type="checkbox" id="c-39911864" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#39914672">prev</a><span>|</span><a href="#39908858">next</a><span>|</span><label class="collapse" for="c-39911864">[-]</label><label class="expand" for="c-39911864">[1 more]</label></div><br/><div class="children"><div class="content">Funny to see just how prolific Gauss was since so many things are named after him and continue to be newly named after him, such as this example of Gaussian splatting, which, while he obviously didn&#x27;t directly invent it, contributed to the mathematics of it significantly.</div><br/></div></div><div id="39908858" class="c"><input type="checkbox" id="c-39908858" checked=""/><div class="controls bullet"><span class="by">999900000999</span><span>|</span><a href="#39911864">prev</a><span>|</span><a href="#39909284">next</a><span>|</span><label class="collapse" for="c-39908858">[-]</label><label class="expand" for="c-39908858">[7 more]</label></div><br/><div class="children"><div class="content">Excited to see what license this is released under. Would love to see some open source games using this.</div><br/><div id="39909093" class="c"><input type="checkbox" id="c-39909093" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#39908858">parent</a><span>|</span><a href="#39909284">next</a><span>|</span><label class="collapse" for="c-39909093">[-]</label><label class="expand" for="c-39909093">[6 more]</label></div><br/><div class="children"><div class="content">Performance aside, someone needs to figure out a generalizable way to make the scenes dynamic before it will really be usable for games. History is littered with alternatives to triangles meshes that looked promising until we realised there&#x27;s no efficient way to animate them.</div><br/><div id="39909180" class="c"><input type="checkbox" id="c-39909180" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#39908858">root</a><span>|</span><a href="#39909093">parent</a><span>|</span><a href="#39909147">next</a><span>|</span><label class="collapse" for="c-39909180">[-]</label><label class="expand" for="c-39909180">[3 more]</label></div><br/><div class="children"><div class="content">Even if this doesn&#x27;t replace triangles everywhere, I&#x27;m guessing it&#x27;s still going to be the easiest way to generate a large volume of static art assets, which means we will see hybrid rendering pipelines.</div><br/><div id="39909415" class="c"><input type="checkbox" id="c-39909415" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#39908858">root</a><span>|</span><a href="#39909180">parent</a><span>|</span><a href="#39909147">next</a><span>|</span><label class="collapse" for="c-39909415">[-]</label><label class="expand" for="c-39909415">[2 more]</label></div><br/><div class="children"><div class="content">AIUI these algorithms currently bake all of the lighting into the surface colors statically, which mostly works if the entire scene is constructed as one giant blob where nothing moves but if you wanted to render an individual NeRF asset inside an otherwise standard triangle-based pipeline then it would need to be more adaptable than that. Even if the asset itself isn&#x27;t animated it would need to adapt to the local lighting at the bare minimum, which I haven&#x27;t seen anyone tackle yet, the focus has been on the rendering-one-giant-static-blob problem.<p>For hybrid pipelines to work the splatting algorithm would probably need to output the standard G-Buffer channels (unlit surface color, normal, roughness, etc) which can then go through the same lighting pass as the triangle-based assets, rather than the splatting algorithm trying to infer lighting by itself and inevitably getting a result that&#x27;s inconsistent with how the triangle-based assets are lit.<p>Think of those old cartoons where you could always tell when part of the scenery was going to move because the animation cel would stick out like a sore thumb against the painted background, that&#x27;s the kind of illusion break you would get if the lighting isn&#x27;t consistent.</div><br/><div id="39911323" class="c"><input type="checkbox" id="c-39911323" checked=""/><div class="controls bullet"><span class="by">somethingsome</span><span>|</span><a href="#39908858">root</a><span>|</span><a href="#39909415">parent</a><span>|</span><a href="#39909147">next</a><span>|</span><label class="collapse" for="c-39911323">[-]</label><label class="expand" for="c-39911323">[1 more]</label></div><br/><div class="children"><div class="content">For NeRF this problems exists. 
However, in the past it was already solved for gaussian splatting. Usually you define a normal field over the (2D) splat, This allows you to have phong shading at least.<p>It is not too difficult to go to a 2D normal field over the 3D gaussians..</div><br/></div></div></div></div></div></div><div id="39909147" class="c"><input type="checkbox" id="c-39909147" checked=""/><div class="controls bullet"><span class="by">999900000999</span><span>|</span><a href="#39908858">root</a><span>|</span><a href="#39909093">parent</a><span>|</span><a href="#39909180">prev</a><span>|</span><a href="#39909284">next</a><span>|</span><label class="collapse" for="c-39909147">[-]</label><label class="expand" for="c-39909147">[2 more]</label></div><br/><div class="children"><div class="content">Can you explain what a dynamic is ?<p>I was more thinking you&#x27;d run this tool, and then have an algorithm convert it( bake the mesh).</div><br/><div id="39909325" class="c"><input type="checkbox" id="c-39909325" checked=""/><div class="controls bullet"><span class="by">lawlessone</span><span>|</span><a href="#39908858">root</a><span>|</span><a href="#39909147">parent</a><span>|</span><a href="#39909284">next</a><span>|</span><label class="collapse" for="c-39909325">[-]</label><label class="expand" for="c-39909325">[1 more]</label></div><br/><div class="children"><div class="content">They probably mean animated, changeable etc. Like movement, or changes in lighting.</div><br/></div></div></div></div></div></div></div></div><div id="39909284" class="c"><input type="checkbox" id="c-39909284" checked=""/><div class="controls bullet"><span class="by">jnsjjdk</span><span>|</span><a href="#39908858">prev</a><span>|</span><a href="#39911738">next</a><span>|</span><label class="collapse" for="c-39909284">[-]</label><label class="expand" for="c-39909284">[5 more]</label></div><br/><div class="children"><div class="content">This does not look significantly better then e.g. cities skylines, especially since they neither zoomed in or out, always showing only a very limited frame<p>Am I missing something?</div><br/><div id="39910720" class="c"><input type="checkbox" id="c-39910720" checked=""/><div class="controls bullet"><span class="by">chankstein38</span><span>|</span><a href="#39909284">parent</a><span>|</span><a href="#39909429">next</a><span>|</span><label class="collapse" for="c-39910720">[-]</label><label class="expand" for="c-39910720">[1 more]</label></div><br/><div class="children"><div class="content">All 3 of the other commenters are replying without having done any actual thought or research.  The paper repeatedly references MatrixCity and another commenter above found this <a href="https:&#x2F;&#x2F;city-super.github.io&#x2F;matrixcity&#x2F;" rel="nofollow">https:&#x2F;&#x2F;city-super.github.io&#x2F;matrixcity&#x2F;</a> which also, I&#x27;d like to add, calls out that it&#x27;s fully Synthetic. And, from what I understand, is extracted from Unreal Engine.</div><br/></div></div><div id="39909429" class="c"><input type="checkbox" id="c-39909429" checked=""/><div class="controls bullet"><span class="by">neuronexmachina</span><span>|</span><a href="#39909284">parent</a><span>|</span><a href="#39910720">prev</a><span>|</span><a href="#39909304">next</a><span>|</span><label class="collapse" for="c-39909429">[-]</label><label class="expand" for="c-39909429">[1 more]</label></div><br/><div class="children"><div class="content">This is a 3D reconstruction, rather than a game rendering.</div><br/></div></div><div id="39909304" class="c"><input type="checkbox" id="c-39909304" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#39909284">parent</a><span>|</span><a href="#39909429">prev</a><span>|</span><a href="#39910015">next</a><span>|</span><label class="collapse" for="c-39909304">[-]</label><label class="expand" for="c-39909304">[1 more]</label></div><br/><div class="children"><div class="content">This was rendered from photographs, I believe</div><br/></div></div><div id="39910015" class="c"><input type="checkbox" id="c-39910015" checked=""/><div class="controls bullet"><span class="by">cchance</span><span>|</span><a href="#39909284">parent</a><span>|</span><a href="#39909304">prev</a><span>|</span><a href="#39911738">next</a><span>|</span><label class="collapse" for="c-39910015">[-]</label><label class="expand" for="c-39910015">[1 more]</label></div><br/><div class="children"><div class="content">LOL this isn&#x27;t a game engine, its real life photos being converted into gausian 3d views.</div><br/></div></div></div></div><div id="39911738" class="c"><input type="checkbox" id="c-39911738" checked=""/><div class="controls bullet"><span class="by">mhuffman</span><span>|</span><a href="#39909284">prev</a><span>|</span><a href="#39908702">next</a><span>|</span><label class="collapse" for="c-39911738">[-]</label><label class="expand" for="c-39911738">[5 more]</label></div><br/><div class="children"><div class="content">Quick question for anyone that may have more technical insight, is Gaussian Splatting the technology that Unreal Engine has been using to have such jaw dropping demos with their new releases?</div><br/><div id="39912166" class="c"><input type="checkbox" id="c-39912166" checked=""/><div class="controls bullet"><span class="by">rmccue</span><span>|</span><a href="#39911738">parent</a><span>|</span><a href="#39914406">next</a><span>|</span><label class="collapse" for="c-39912166">[-]</label><label class="expand" for="c-39912166">[2 more]</label></div><br/><div class="children"><div class="content">Unreal Engine 5 is a combination of a few technologies:<p>* Virtualised geometry (Nanite) allowing very detailed models<p>* Very high quality models and textures from photogrammetry (Megascans)<p>* Real-time global illumination (Lumen)<p>Combining these is what allows the very high fidelity demos, as they’re each step changes from the previous techniques in Unreal. Megascans (and the Quixel library) are a big part of the “photorealness” of these demos, because they’re basically literally photos.</div><br/></div></div><div id="39914406" class="c"><input type="checkbox" id="c-39914406" checked=""/><div class="controls bullet"><span class="by">notachatbot1234</span><span>|</span><a href="#39911738">parent</a><span>|</span><a href="#39912166">prev</a><span>|</span><a href="#39911774">next</a><span>|</span><label class="collapse" for="c-39914406">[-]</label><label class="expand" for="c-39914406">[1 more]</label></div><br/><div class="children"><div class="content">No but here are some nice talks on the Nanite geometry technology of UE:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=NRnj_lnpORU" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=NRnj_lnpORU</a><p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eviSykqSUUw" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eviSykqSUUw</a></div><br/></div></div><div id="39911774" class="c"><input type="checkbox" id="c-39911774" checked=""/><div class="controls bullet"><span class="by">andybak</span><span>|</span><a href="#39911738">parent</a><span>|</span><a href="#39914406">prev</a><span>|</span><a href="#39908702">next</a><span>|</span><label class="collapse" for="c-39911774">[-]</label><label class="expand" for="c-39911774">[1 more]</label></div><br/><div class="children"><div class="content">No. Mostly unrelated.</div><br/></div></div></div></div><div id="39908702" class="c"><input type="checkbox" id="c-39908702" checked=""/><div class="controls bullet"><span class="by">rallyforthesun</span><span>|</span><a href="#39911738">prev</a><span>|</span><a href="#39908955">next</a><span>|</span><label class="collapse" for="c-39908702">[-]</label><label class="expand" for="c-39908702">[1 more]</label></div><br/><div class="children"><div class="content">Really advanced approach to render larger scenes with 3DGaussians, cant wait to test the code :-)</div><br/></div></div><div id="39908955" class="c"><input type="checkbox" id="c-39908955" checked=""/><div class="controls bullet"><span class="by">forrestthewoods</span><span>|</span><a href="#39908702">prev</a><span>|</span><a href="#39913897">next</a><span>|</span><label class="collapse" for="c-39908955">[-]</label><label class="expand" for="c-39908955">[31 more]</label></div><br/><div class="children"><div class="content">Can someone convince me that 3D gaussian splatting isn&#x27;t a dead end? It&#x27;s an order of magnitude too slow to render and order of magnitude too much data. It&#x27;s like raster vs raytrace all over again. Raster will always be faster than raytracing. So even if raytracing gets 10x faster so too will raster.<p>I think generating traditional geometry and materials from gaussian point clouds is maybe interesting. But photogrammetry has already been a thing for quite awhile. Trying to render a giant city in real time via splats doesn&#x27;t feel like &quot;the right thing&quot;.<p>It&#x27;s definitely cool and fun and exciting. I&#x27;m just not sure that it will ever be useful in practice? Maybe! I&#x27;m definitely not an expert so my question is genuine.</div><br/><div id="39909087" class="c"><input type="checkbox" id="c-39909087" checked=""/><div class="controls bullet"><span class="by">kfarr</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39909883">next</a><span>|</span><label class="collapse" for="c-39909087">[-]</label><label class="expand" for="c-39909087">[1 more]</label></div><br/><div class="children"><div class="content">Yes this has tons of potential. It&#x27;s analogous but different to patented techniques used by Unreal engine. Performance is not the focus in most research at the moment. There isn&#x27;t even alignment on unified format with compression yet. The potential for optimization is very clear and straightforward to adapt to many devices, it&#x27;s similar to point cloud LOD, mesh culling, etc. Splat performance could be temporary competitive advantage for viewers, but similar to video decompression and other 3d standards that are made available via open source, it will likely become commonplace in a few years to have high quality high fps splat viewing on most devices as tablestakes. The next question is what are the applications thereof.</div><br/></div></div><div id="39909883" class="c"><input type="checkbox" id="c-39909883" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39909087">prev</a><span>|</span><a href="#39910170">next</a><span>|</span><label class="collapse" for="c-39909883">[-]</label><label class="expand" for="c-39909883">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not an order of magnitude slower. You can easily get 200-400 fps in Unreal or Unity at the moment.<p>100+FPS in browser?
<a href="https:&#x2F;&#x2F;current-exhibition.com&#x2F;laboratorio31&#x2F;" rel="nofollow">https:&#x2F;&#x2F;current-exhibition.com&#x2F;laboratorio31&#x2F;</a><p>900FPS? 
<a href="https:&#x2F;&#x2F;m-niemeyer.github.io&#x2F;radsplat&#x2F;" rel="nofollow">https:&#x2F;&#x2F;m-niemeyer.github.io&#x2F;radsplat&#x2F;</a><p>We have 3 decades worth of R&amp;D in traditional engines, it&#x27;ll take a while for this to catch up in terms of tooling and optimization but when you look where the papers come from (many from Apple and Meta), you see that this is the technology destined to power the MetaVerse&#x2F;Spatial Compute era both companies are pushing towards.<p>The ability to move content at incredibly low production costs (iphone movie) into 3d environments is going to murder a lot of R&amp;D made in traditional methods.</div><br/><div id="39910095" class="c"><input type="checkbox" id="c-39910095" checked=""/><div class="controls bullet"><span class="by">araes</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39909883">parent</a><span>|</span><a href="#39910771">next</a><span>|</span><label class="collapse" for="c-39910095">[-]</label><label class="expand" for="c-39910095">[2 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t know the hardware involved, yet that first link is most definitely not 100 FPS on all hardware.  Slideshow on the current device.</div><br/><div id="39912285" class="c"><input type="checkbox" id="c-39912285" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39910095">parent</a><span>|</span><a href="#39910771">next</a><span>|</span><label class="collapse" for="c-39912285">[-]</label><label class="expand" for="c-39912285">[1 more]</label></div><br/><div class="children"><div class="content">Maybe not, but it&#x27;s relatively smooth on my 3 year old phone, which is crazy impressive<p>Edit: I was in low power mode, it runs quite smoothly</div><br/></div></div></div></div><div id="39910771" class="c"><input type="checkbox" id="c-39910771" checked=""/><div class="controls bullet"><span class="by">101008</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39909883">parent</a><span>|</span><a href="#39910095">prev</a><span>|</span><a href="#39910170">next</a><span>|</span><label class="collapse" for="c-39910771">[-]</label><label class="expand" for="c-39910771">[2 more]</label></div><br/><div class="children"><div class="content">Does anyone know how the first link is made?</div><br/><div id="39914684" class="c"><input type="checkbox" id="c-39914684" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39910771">parent</a><span>|</span><a href="#39910170">next</a><span>|</span><label class="collapse" for="c-39914684">[-]</label><label class="expand" for="c-39914684">[1 more]</label></div><br/><div class="children"><div class="content">You are in luck, the author has been sharing<p><a href="https:&#x2F;&#x2F;medium.com&#x2F;@heyulei&#x2F;capture-images-for-gaussian-splatting-81d081bbc826" rel="nofollow">https:&#x2F;&#x2F;medium.com&#x2F;@heyulei&#x2F;capture-images-for-gaussian-spla...</a></div><br/></div></div></div></div></div></div><div id="39910170" class="c"><input type="checkbox" id="c-39910170" checked=""/><div class="controls bullet"><span class="by">pierotofy</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39909883">prev</a><span>|</span><a href="#39909281">next</a><span>|</span><label class="collapse" for="c-39910170">[-]</label><label class="expand" for="c-39910170">[4 more]</label></div><br/><div class="children"><div class="content">Photogrammetry struggles with certain types of materials (e.g. reflective surfaces). It&#x27;s also very difficult to capture fine details (thin structures, hair). 3DGS is very good at that. And people are working on improving current shortcomings, including methods to extract meshes that we could use in traditional graphics pipelines.</div><br/><div id="39911359" class="c"><input type="checkbox" id="c-39911359" checked=""/><div class="controls bullet"><span class="by">somethingsome</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39910170">parent</a><span>|</span><a href="#39909281">next</a><span>|</span><label class="collapse" for="c-39911359">[-]</label><label class="expand" for="c-39911359">[3 more]</label></div><br/><div class="children"><div class="content">3DGS is absolutely not good with non Lambertian materials..<p>After testing it, if fails in very basic cases. And it is normal that it fails, non Lambertian materials are not reconstructed correctly with SfM methods.</div><br/><div id="39912574" class="c"><input type="checkbox" id="c-39912574" checked=""/><div class="controls bullet"><span class="by">andybak</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39911359">parent</a><span>|</span><a href="#39909281">next</a><span>|</span><label class="collapse" for="c-39912574">[-]</label><label class="expand" for="c-39912574">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand the connection you&#x27;re making between SfM (Structure from Motion) and surface shading.<p>I might be misunderstanding what you&#x27;re trying to say. Could you elaborate?</div><br/><div id="39914097" class="c"><input type="checkbox" id="c-39914097" checked=""/><div class="controls bullet"><span class="by">somethingsome</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39912574">parent</a><span>|</span><a href="#39909281">next</a><span>|</span><label class="collapse" for="c-39914097">[-]</label><label class="expand" for="c-39914097">[1 more]</label></div><br/><div class="children"><div class="content">You use SfM to find the first point cloud. However SfM is based on the hypothesis that the same point &#x27;moves&#x27; linearly in between any two views. This hypothesis is important because it allows you to match a point in two pictures, and given the distance between the two images, you can triangulate the point in space. Therefore find it&#x27;s depth.<p>However, non-Lambertian points move non linearly in viewing space (eg a specular point depends on the viewer pose).<p>So, automatically, their positions in space will be false, and you&#x27;ll have floating points.<p>Gaussian &#x27;splats&#x27; may have the potential to render non-Lambertian stuff using for example the spherical harmonics (even if I don&#x27;t think the viewer use them if I&#x27;m not mistaken). But, capturing non-Lambertian points is very difficult and an open research problem.</div><br/></div></div></div></div></div></div></div></div><div id="39909281" class="c"><input type="checkbox" id="c-39909281" checked=""/><div class="controls bullet"><span class="by">mschuetz</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39910170">prev</a><span>|</span><a href="#39910094">next</a><span>|</span><label class="collapse" for="c-39909281">[-]</label><label class="expand" for="c-39909281">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s currently unparalleled when it comes to realism as in realistic 3D reconstruction from the real world. Photogrammetry only really works for nice surfacic data, whereas gaussian splats work for semi-volumetric data such as fur, vegetation, particles, rough surfaces, and also for glossy&#x2F;specular surfaces and volumes with strong subdivision surface properties, or generally stuff with materials that are strongly view-dependent.</div><br/><div id="39914172" class="c"><input type="checkbox" id="c-39914172" checked=""/><div class="controls bullet"><span class="by">tedd4u</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39909281">parent</a><span>|</span><a href="#39910094">next</a><span>|</span><label class="collapse" for="c-39914172">[-]</label><label class="expand" for="c-39914172">[1 more]</label></div><br/><div class="children"><div class="content">This seems like impressive work. You mention glossy &#x2F; specular. I wonder why nothing in the city (first video) is reflective, not even the glass box skyscrapers. I noticed there is something funky in the third video with the iron railway rails from about :28 to :35 seconds. They look ghostly and appear to come in and out. Overall these three videos are pretty devoid of shiny or reflective things.</div><br/></div></div></div></div><div id="39910094" class="c"><input type="checkbox" id="c-39910094" checked=""/><div class="controls bullet"><span class="by">jerf</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39909281">prev</a><span>|</span><a href="#39909311">next</a><span>|</span><label class="collapse" for="c-39910094">[-]</label><label class="expand" for="c-39910094">[2 more]</label></div><br/><div class="children"><div class="content">You have to ask about what it&#x27;s a dead end for. It seems pretty cool for the moral equivalent of fully 3D photographs. That&#x27;s a completely legitimate use case.<p>For 3D gaming engines? I struggle to see how the fundamental primitive can be made to sing and dance in the way that they demand. People will try, though. But from this perspective, gaussians strike me more as a final render format than a useful intermediate representation. If they are going to use gaussians there&#x27;s going to have to be something else invented to make them practical to use for engines in the meantime, and there&#x27;s still an awful lot of questions there.<p>For other uses? Who knows.<p>But the world is not all 3D gaming and visual special effects.</div><br/><div id="39914703" class="c"><input type="checkbox" id="c-39914703" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39910094">parent</a><span>|</span><a href="#39909311">next</a><span>|</span><label class="collapse" for="c-39914703">[-]</label><label class="expand" for="c-39914703">[1 more]</label></div><br/><div class="children"><div class="content">You are missing where this is coming from.<p>Many of the core papers for this came from Meta&#x27;s VR team (codec avatars), Apple ML (Spatial Compute) and Nvidia - companies deeply invested in VR&#x2F;Spatial compute. It&#x27;s clear that they see it as a key technology to further their interests in the space, and they are getting plenty of free help:<p>After being open sourced in May last year, there were 79 papers overall published on the topic.<p>It&#x27;s more than 150 this year, more than one a day, advancing this &quot;dead end&quot; forward.<p>A small selection:<p><a href="https:&#x2F;&#x2F;animatable-gaussians.github.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;animatable-gaussians.github.io&#x2F;</a>
<a href="https:&#x2F;&#x2F;nvlabs.github.io&#x2F;GAvatar&#x2F;" rel="nofollow">https:&#x2F;&#x2F;nvlabs.github.io&#x2F;GAvatar&#x2F;</a>
<a href="https:&#x2F;&#x2F;research.nvidia.com&#x2F;labs&#x2F;toronto-ai&#x2F;AlignYourGaussians&#x2F;" rel="nofollow">https:&#x2F;&#x2F;research.nvidia.com&#x2F;labs&#x2F;toronto-ai&#x2F;AlignYourGaussia...</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;lkeab&#x2F;gaussian-grouping">https:&#x2F;&#x2F;github.com&#x2F;lkeab&#x2F;gaussian-grouping</a></div><br/></div></div></div></div><div id="39909311" class="c"><input type="checkbox" id="c-39909311" checked=""/><div class="controls bullet"><span class="by">rallyforthesun</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39910094">prev</a><span>|</span><a href="#39910210">next</a><span>|</span><label class="collapse" for="c-39909311">[-]</label><label class="expand" for="c-39909311">[1 more]</label></div><br/><div class="children"><div class="content">In regards of contentproduction for virtual production, it is quicker to capture a scene and process the images into a cloud of 3d-gaussians, but on the other hand it is harder to edit the scene after its shot. Also, the light is already captured and baked into it. 
The tools to edit scenes will probably rely a lot on ai, like delighting and change of settings. right now there are just a few, the process is more like using knife to cut out parts and remove floaters.
You can replay this of course with the unreal engine, but in the long term you could run it in a browser.
So in short, if you want to capture a place as it is with all its tiny details, 3dgaussians are a quicker and cheaper way to afford this than using modelling and texturing.</div><br/></div></div><div id="39910210" class="c"><input type="checkbox" id="c-39910210" checked=""/><div class="controls bullet"><span class="by">peppertree</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39909311">prev</a><span>|</span><a href="#39910817">next</a><span>|</span><label class="collapse" for="c-39910210">[-]</label><label class="expand" for="c-39910210">[4 more]</label></div><br/><div class="children"><div class="content">Mesh based photogrammetry is a dead end. GS or radiance field representation is just getting started. Not just rendering but potentially a highly compact way to store large 3D scenes.</div><br/><div id="39910303" class="c"><input type="checkbox" id="c-39910303" checked=""/><div class="controls bullet"><span class="by">forrestthewoods</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39910210">parent</a><span>|</span><a href="#39910817">next</a><span>|</span><label class="collapse" for="c-39910303">[-]</label><label class="expand" for="c-39910303">[3 more]</label></div><br/><div class="children"><div class="content">&gt; potentially a highly compact way to store large 3D scenes.<p>Is it? So far it seems like the storage size is massive and the detail is unacceptably low up close.<p>Is there a demo that will make me go “holy crap I can’t believe how well this scene compressed”?</div><br/><div id="39911735" class="c"><input type="checkbox" id="c-39911735" checked=""/><div class="controls bullet"><span class="by">peppertree</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39910303">parent</a><span>|</span><a href="#39910817">next</a><span>|</span><label class="collapse" for="c-39911735">[-]</label><label class="expand" for="c-39911735">[2 more]</label></div><br/><div class="children"><div class="content">Here is a paper if you are interested. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2311.13681.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2311.13681.pdf</a><p>The key is not to compress but to leverage the property of neural radiance fields and optimize for entropy. I suspect NERF can yield more compact storage since it&#x27;s volumetric.<p>Not sure what you mean by &quot;unacceptably low up close&quot;. Most GS demos don&#x27;t have LoD lol.</div><br/><div id="39912307" class="c"><input type="checkbox" id="c-39912307" checked=""/><div class="controls bullet"><span class="by">forrestthewoods</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39911735">parent</a><span>|</span><a href="#39910817">next</a><span>|</span><label class="collapse" for="c-39912307">[-]</label><label class="expand" for="c-39912307">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Not sure what you mean by &quot;unacceptably low up close&quot;. Most GS demos don&#x27;t have LoD lol.<p>When the camera gets close the &quot;texture&quot; resolution is extremely low. Like, roughly 1&#x2F;4 what I would expect. Maybe even 1&#x2F;8. Aka it&#x27;s very blurry.</div><br/></div></div></div></div></div></div></div></div><div id="39910817" class="c"><input type="checkbox" id="c-39910817" checked=""/><div class="controls bullet"><span class="by">bodhiandphysics</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39910210">prev</a><span>|</span><a href="#39909426">next</a><span>|</span><label class="collapse" for="c-39910817">[-]</label><label class="expand" for="c-39910817">[1 more]</label></div><br/><div class="children"><div class="content">Try animating a photogrammetric model!  How about one that changes its shape?  You get awful geometry from photogrammetry…<p>In practice the answer to will this be useful is yes! Subdivision surfaces coexist with nurbs for different applications.</div><br/></div></div><div id="39909426" class="c"><input type="checkbox" id="c-39909426" checked=""/><div class="controls bullet"><span class="by">maxglute</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39910817">prev</a><span>|</span><a href="#39909715">next</a><span>|</span><label class="collapse" for="c-39909426">[-]</label><label class="expand" for="c-39909426">[3 more]</label></div><br/><div class="children"><div class="content">Hardware evolves with production in mind. If method saves 10x time&#x2F;labour even using 50x more expensive compute&#x2F;tools then industry will figure out way to optimize&#x2F;amortize compute cost on that task over time and eventually deseminate into consumer hardware.</div><br/><div id="39909674" class="c"><input type="checkbox" id="c-39909674" checked=""/><div class="controls bullet"><span class="by">forrestthewoods</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39909426">parent</a><span>|</span><a href="#39909715">next</a><span>|</span><label class="collapse" for="c-39909674">[-]</label><label class="expand" for="c-39909674">[2 more]</label></div><br/><div class="children"><div class="content">Maybe. That implies that hardware evolution strictly benefits Bar and not Foo. But what has happened so far is that hardware advancements to accelerate NewThing also accelerate OldThing.</div><br/><div id="39912409" class="c"><input type="checkbox" id="c-39912409" checked=""/><div class="controls bullet"><span class="by">maxglute</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39909674">parent</a><span>|</span><a href="#39909715">next</a><span>|</span><label class="collapse" for="c-39912409">[-]</label><label class="expand" for="c-39912409">[1 more]</label></div><br/><div class="children"><div class="content">I think hardware evolution has to benefit Bar and Foo for production continuity anyways, OldThing still has to be supported until it becomes largely obsolete to both industry and consumer. In which case fringe users have to hold on to old hardware to keep processes going.</div><br/></div></div></div></div></div></div><div id="39909715" class="c"><input type="checkbox" id="c-39909715" checked=""/><div class="controls bullet"><span class="by">fngjdflmdflg</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39909426">prev</a><span>|</span><a href="#39910844">next</a><span>|</span><label class="collapse" for="c-39909715">[-]</label><label class="expand" for="c-39909715">[1 more]</label></div><br/><div class="children"><div class="content">&gt;But photogrammetry has already been a thing for quite awhile.<p>Current photogrammetry to my knowledge requires much more data than NeRfs&#x2F;Gaussian splatting. So this could be a way to get more data for the &quot;dumb&quot; photogrammetry algorithms to work with.</div><br/></div></div><div id="39910844" class="c"><input type="checkbox" id="c-39910844" checked=""/><div class="controls bullet"><span class="by">jonas21</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39909715">prev</a><span>|</span><a href="#39910688">next</a><span>|</span><label class="collapse" for="c-39910844">[-]</label><label class="expand" for="c-39910844">[3 more]</label></div><br/><div class="children"><div class="content">How is it too slow? You can easily render scenes at 60fps in a browser or on a mobile phone.<p>Heck, you can even <i>train</i> one from scratch in a minute on an iPhone [1].<p>This technique has been around for less than a year. It&#x27;s only going to get better.<p>[1] <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nk0f4FTcdmM" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nk0f4FTcdmM</a></div><br/><div id="39911377" class="c"><input type="checkbox" id="c-39911377" checked=""/><div class="controls bullet"><span class="by">somethingsome</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39910844">parent</a><span>|</span><a href="#39911201">next</a><span>|</span><label class="collapse" for="c-39911377">[-]</label><label class="expand" for="c-39911377">[1 more]</label></div><br/><div class="children"><div class="content">This technique exists from more than 10 years, and real time renderers exist too from very long.</div><br/></div></div><div id="39911201" class="c"><input type="checkbox" id="c-39911201" checked=""/><div class="controls bullet"><span class="by">mthoms</span><span>|</span><a href="#39908955">root</a><span>|</span><a href="#39910844">parent</a><span>|</span><a href="#39911377">prev</a><span>|</span><a href="#39910688">next</a><span>|</span><label class="collapse" for="c-39911201">[-]</label><label class="expand" for="c-39911201">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s pretty cool. It&#x27;s not clear if it&#x27;s incorporating Lidar data or not though. It&#x27;s very impressive if not.</div><br/></div></div></div></div><div id="39910688" class="c"><input type="checkbox" id="c-39910688" checked=""/><div class="controls bullet"><span class="by">chankstein38</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39910844">prev</a><span>|</span><a href="#39909166">next</a><span>|</span><label class="collapse" for="c-39910688">[-]</label><label class="expand" for="c-39910688">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll be honest, I don&#x27;t have a ton of technical insights into these but anecdotally, I found that using KIRI Engine&#x27;s Gaussian Splatting scans (versus Photogrammetry scans) the GS scans were way more accurate and true to life and required a lot less cleanup!</div><br/></div></div><div id="39909166" class="c"><input type="checkbox" id="c-39909166" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39910688">prev</a><span>|</span><a href="#39911176">next</a><span>|</span><label class="collapse" for="c-39909166">[-]</label><label class="expand" for="c-39909166">[1 more]</label></div><br/><div class="children"><div class="content">Nothing comes close to this for realism, it&#x27;s like looking at a photo.<p>Traditional photogrammetry really struggles with complicated scenes, and reflective or transparent surfaces.</div><br/></div></div><div id="39911176" class="c"><input type="checkbox" id="c-39911176" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39908955">parent</a><span>|</span><a href="#39909166">prev</a><span>|</span><a href="#39913897">next</a><span>|</span><label class="collapse" for="c-39911176">[-]</label><label class="expand" for="c-39911176">[1 more]</label></div><br/><div class="children"><div class="content">&gt;much data. It&#x27;s like raster vs raytrace all over again. Raster will always be faster than raytracing. So even if raytracing gets 10x faster so too will raster.<p>And? It&#x27;s always going to be even faster to not have lighting at all.</div><br/></div></div></div></div><div id="39913897" class="c"><input type="checkbox" id="c-39913897" checked=""/><div class="controls bullet"><span class="by">dukeofdoom</span><span>|</span><a href="#39908955">prev</a><span>|</span><a href="#39909884">next</a><span>|</span><label class="collapse" for="c-39913897">[-]</label><label class="expand" for="c-39913897">[2 more]</label></div><br/><div class="children"><div class="content">Does anyone know how to add motion blur to a game. I&#x27;m learning pygame. Say I&#x27;m making Mario in pygame, and when Mario jumps, I want him to look blurry. I mean I can take an average of 9 pixels, and create a blurry version of Mario. But is that how it&#x27;s that usually done in other games. Since like a lot of games are supper sharp, with no motion blur. I&#x27;m wondering if its even done. It&#x27;s kind of big deal in film, and the need to shoot at 25fps to achieve cinematic motion blur.</div><br/><div id="39914091" class="c"><input type="checkbox" id="c-39914091" checked=""/><div class="controls bullet"><span class="by">jayd16</span><span>|</span><a href="#39913897">parent</a><span>|</span><a href="#39909884">next</a><span>|</span><label class="collapse" for="c-39914091">[-]</label><label class="expand" for="c-39914091">[1 more]</label></div><br/><div class="children"><div class="content">Render the motion vector of objects to another render texture. (ie calculate the velocity of each object and render that as a color)  Use that to define the amplitude and direction of your blur effect in a post pass.<p>And you might want it to be the motion relevant to the camera.  For Mario, probably not, but for an FPS you want to edges of the screen to blur as the camera moves forward.</div><br/></div></div></div></div><div id="39909884" class="c"><input type="checkbox" id="c-39909884" checked=""/><div class="controls bullet"><span class="by">boywitharupee</span><span>|</span><a href="#39913897">prev</a><span>|</span><a href="#39909159">next</a><span>|</span><label class="collapse" for="c-39909884">[-]</label><label class="expand" for="c-39909884">[1 more]</label></div><br/><div class="children"><div class="content">what&#x27;s the memory and compute requirements for this?</div><br/></div></div><div id="39909159" class="c"><input type="checkbox" id="c-39909159" checked=""/><div class="controls bullet"><span class="by">syrusakbary</span><span>|</span><a href="#39909884">prev</a><span>|</span><label class="collapse" for="c-39909159">[-]</label><label class="expand" for="c-39909159">[1 more]</label></div><br/><div class="children"><div class="content">Gaussian splatting is truly amazing for 3d reconstruction.<p>I can&#x27;t wait to see once it&#x27;s applied to the world of driverless vehicles and AI!</div><br/></div></div></div></div></div></div></div></body></html>