<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1685782846825" as="style"/><link rel="stylesheet" href="styles.css?v=1685782846825"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2306.00008">Brainformers: Trading Simplicity for Efficiency</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>PaulHoule</span> | <span>4 comments</span></div><br/><div><div id="36174246" class="c"><input type="checkbox" id="c-36174246" checked=""/><div class="controls bullet"><span class="by">ricklamers</span><span>|</span><a href="#36174718">prev</a><span>|</span><a href="#36173723">next</a><span>|</span><label class="collapse" for="c-36174246">[-]</label><label class="expand" for="c-36174246">[1 more]</label></div><br/><div class="children"><div class="content">I think parsimony is great for human readability but also creates a bias that excludes within reach solutions that overall have meaningfully better properties <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Evolved_antenna" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Evolved_antenna</a></div><br/></div></div><div id="36173723" class="c"><input type="checkbox" id="c-36173723" checked=""/><div class="controls bullet"><span class="by">convexstrictly</span><span>|</span><a href="#36174246">prev</a><span>|</span><label class="collapse" for="c-36173723">[-]</label><label class="expand" for="c-36173723">[1 more]</label></div><br/><div class="children"><div class="content">The Brainformer building block is designed using neural architecture search.<p>&quot;Brainformer consistently outperforms the state-of-the-art dense and sparse Transformers, in terms of both quality and efficiency. A Brainformer model with 8 billion activated parameters per token demonstrates 2× faster training convergence and 5× faster step time compared to its GLaM counterpart.&quot;<p>Note that the 8B model mentioned above has 158B total parameters.  The authors compare the training time to other sparsely activated models, but seemingly not to dense models.</div><br/></div></div></div></div></div></div></div></body></html>