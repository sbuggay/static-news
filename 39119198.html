<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706259658538" as="style"/><link rel="stylesheet" href="styles.css?v=1706259658538"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://softwaredoug.com/blog/2024/01/24/are-we-at-peak-vector-db">Are we at peak vector database?</a>Â <span class="domain">(<a href="https://softwaredoug.com">softwaredoug.com</a>)</span></div><div class="subtext"><span>softwaredoug</span> | <span>62 comments</span></div><br/><div><div id="39140306" class="c"><input type="checkbox" id="c-39140306" checked=""/><div class="controls bullet"><span class="by">physicsguy</span><span>|</span><a href="#39140299">prev</a><span>|</span><a href="#39140037">next</a><span>|</span><label class="collapse" for="c-39140306">[-]</label><label class="expand" for="c-39140306">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In the same way NoSQL forced us to rethink databases.<p>Did it? After using Mongo in my current job (not my choice), I&#x27;d choose Postgres again for my next project.</div><br/></div></div><div id="39140037" class="c"><input type="checkbox" id="c-39140037" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39140306">prev</a><span>|</span><a href="#39139246">next</a><span>|</span><label class="collapse" for="c-39140037">[-]</label><label class="expand" for="c-39140037">[2 more]</label></div><br/><div class="children"><div class="content">Embeddings are good at capturing surface level information but can&#x27;t match implicit&#x2F;deeper&#x2F;conclusion level information. Say you have a collection of 100,000 math problems, and you want to embed them to search problems that give result &quot;0&quot;. Any number of problems can give this result and it is not explicit in the problem statement. But if you solve the problems you can see the data was in there, just not apparent.<p>In general you can see the raw text as a simulation premise that will generate inferences when &quot;executed&quot;. The inferenced part is like the hidden part of the iceberg, you don&#x27;t see it but it is there, implicit in the source text. Not just in math, but in all fields.<p>Embeddings are only good at superficial retrieval. The text needs to be fully analyzed with LLMs before embedding. Thus my conclusion is that we still have a long way to go, we haven&#x27;t peaked.</div><br/><div id="39140316" class="c"><input type="checkbox" id="c-39140316" checked=""/><div class="controls bullet"><span class="by">inertiatic</span><span>|</span><a href="#39140037">parent</a><span>|</span><a href="#39139246">next</a><span>|</span><label class="collapse" for="c-39140316">[-]</label><label class="expand" for="c-39140316">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Embeddings are only good at superficial retrieval. The text needs to be fully analyzed with LLMs before embedding.<p>Embeddings are generated by LLMs, at least what LLM meant before it took on the new meaning of generative model.  Using the same LLM to embed as you are to generate, the embedding for a piece of text is the full intermediate representation of that text that is then used to produced results in the output of the LLM you&#x27;re describing.</div><br/></div></div></div></div><div id="39139246" class="c"><input type="checkbox" id="c-39139246" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#39140037">prev</a><span>|</span><a href="#39138990">next</a><span>|</span><label class="collapse" for="c-39139246">[-]</label><label class="expand" for="c-39139246">[6 more]</label></div><br/><div class="children"><div class="content">IMO we are well past peak cosine-similarity-search as a service. Most people I talk to in the space don&#x27;t bother using specialized vector DBs for that.<p>I think there&#x27;s space for a much more interesting product that is longer-lived (since it&#x27;s harder to implement than just cosine-similarity-search on vectors), which is:<p>1. Fine-tuning OSS embedding models on your real-world query patterns<p>2. Storing and recomputing embeddings for your data as you update the fine-tuned models.<p>MTEB averages are fine, but hardly anyone uses the average result: most use cases are specialized (i.e. classification vs clustering vs retrieval). The best models try to be decent at all of those, but I&#x27;d bet that finetuning on a specific use case would beat a general-purpose model, especially on your own dataset (your retrieval is probably meaningfully different than someone else&#x27;s: code retrieval vs document Q&amp;A, for example). And your queries are usually specialized! People using embeddings for RAG are generally not also trying to use the same embeddings for clustering or classification; and the reverse is true too (your recommendation system is likely different than your search system).<p>And if you&#x27;re fine-tuning new models regularly, you need storage + management, since you&#x27;ll need to recompute the embeddings every time you deploy a new model.<p>I would pay for a service that made (1) and (2) easy.</div><br/><div id="39140169" class="c"><input type="checkbox" id="c-39140169" checked=""/><div class="controls bullet"><span class="by">jn2clark</span><span>|</span><a href="#39139246">parent</a><span>|</span><a href="#39140160">prev</a><span>|</span><a href="#39140004">next</a><span>|</span><label class="collapse" for="c-39140169">[-]</label><label class="expand" for="c-39140169">[1 more]</label></div><br/><div class="children"><div class="content">We (Marqo) are doing a lot on 1 and 2. There is a huge amount to be done on the ML side of vector search and we are investing heavily in it. I think it has not quite sunk in that vector search systems are ML systems and everything that comes with that. I would love to chat about 1 and 2 so feel free to email me (email is in my profile).</div><br/></div></div><div id="39140004" class="c"><input type="checkbox" id="c-39140004" checked=""/><div class="controls bullet"><span class="by">phreeza</span><span>|</span><a href="#39139246">parent</a><span>|</span><a href="#39140169">prev</a><span>|</span><a href="#39139644">next</a><span>|</span><label class="collapse" for="c-39140004">[-]</label><label class="expand" for="c-39140004">[1 more]</label></div><br/><div class="children"><div class="content">Are you aware of any service or OSS solution for this?</div><br/></div></div><div id="39139644" class="c"><input type="checkbox" id="c-39139644" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#39139246">parent</a><span>|</span><a href="#39140004">prev</a><span>|</span><a href="#39138990">next</a><span>|</span><label class="collapse" for="c-39139644">[-]</label><label class="expand" for="c-39139644">[2 more]</label></div><br/><div class="children"><div class="content">Question, does this require specialized hardware at all? GPUs?</div><br/><div id="39140002" class="c"><input type="checkbox" id="c-39140002" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#39139246">root</a><span>|</span><a href="#39139644">parent</a><span>|</span><a href="#39138990">next</a><span>|</span><label class="collapse" for="c-39140002">[-]</label><label class="expand" for="c-39140002">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t require it in theory, but in practice its required bc CPUs are too slow at fine-tuning and computing embeddings.</div><br/></div></div></div></div></div></div><div id="39138990" class="c"><input type="checkbox" id="c-39138990" checked=""/><div class="controls bullet"><span class="by">LispSporks22</span><span>|</span><a href="#39139246">prev</a><span>|</span><a href="#39138832">next</a><span>|</span><label class="collapse" for="c-39138990">[-]</label><label class="expand" for="c-39138990">[3 more]</label></div><br/><div class="children"><div class="content">I believe you&#x27;ve reached peak anything when it&#x27;s been incorporated into PostgreSQL.</div><br/><div id="39139361" class="c"><input type="checkbox" id="c-39139361" checked=""/><div class="controls bullet"><span class="by">spootze</span><span>|</span><a href="#39138990">parent</a><span>|</span><a href="#39138832">next</a><span>|</span><label class="collapse" for="c-39139361">[-]</label><label class="expand" for="c-39139361">[2 more]</label></div><br/><div class="children"><div class="content">pgvector has you covered: <a href="https:&#x2F;&#x2F;github.com&#x2F;pgvector&#x2F;pgvector">https:&#x2F;&#x2F;github.com&#x2F;pgvector&#x2F;pgvector</a></div><br/><div id="39139413" class="c"><input type="checkbox" id="c-39139413" checked=""/><div class="controls bullet"><span class="by">hot_gril</span><span>|</span><a href="#39138990">root</a><span>|</span><a href="#39139361">parent</a><span>|</span><a href="#39138832">next</a><span>|</span><label class="collapse" for="c-39139413">[-]</label><label class="expand" for="c-39139413">[1 more]</label></div><br/><div class="children"><div class="content">Wow. Back in the day, I had to do cosine similarity indexing with pg-cube. It only did euclidean distance, so I had to store a separate column with normalized vectors.</div><br/></div></div></div></div></div></div><div id="39138832" class="c"><input type="checkbox" id="c-39138832" checked=""/><div class="controls bullet"><span class="by">dmezzetti</span><span>|</span><a href="#39138990">prev</a><span>|</span><a href="#39138510">next</a><span>|</span><label class="collapse" for="c-39138832">[-]</label><label class="expand" for="c-39138832">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll add txtai (<a href="https:&#x2F;&#x2F;github.com&#x2F;neuml&#x2F;txtai">https:&#x2F;&#x2F;github.com&#x2F;neuml&#x2F;txtai</a>) to the list.<p>There is still plenty of room for innovation in this space. Just need to focus on the right projects that are innovating and not the ones (re)working on problems solved in 2020&#x2F;2021.</div><br/><div id="39138993" class="c"><input type="checkbox" id="c-39138993" checked=""/><div class="controls bullet"><span class="by">zeroCalories</span><span>|</span><a href="#39138832">parent</a><span>|</span><a href="#39138510">next</a><span>|</span><label class="collapse" for="c-39138993">[-]</label><label class="expand" for="c-39138993">[1 more]</label></div><br/><div class="children"><div class="content">I agree. Honestly even the fundamentals of vector databases aren&#x27;t really &quot;solved&quot; in the way they are for other databases. Vector indexing, embedding generation, horizontal scaling, etc. can probably still improve a lot. And don&#x27;t forget, even if Postgres and MySQL are the only traditional databases in town, every tech company had their own SQL database once. Many of them are still around too. No need to get pissy about these companies.</div><br/></div></div></div></div><div id="39138510" class="c"><input type="checkbox" id="c-39138510" checked=""/><div class="controls bullet"><span class="by">formercoder</span><span>|</span><a href="#39138832">prev</a><span>|</span><a href="#39138724">next</a><span>|</span><label class="collapse" for="c-39138510">[-]</label><label class="expand" for="c-39138510">[17 more]</label></div><br/><div class="children"><div class="content">When I prototype RAG systems I donât use a âvector database.â I just use a pandas dataframe and I do an apply() with a cosine distance function that is one line of code. Iâve done it with up to 1k rows and it still takes less than a second.</div><br/><div id="39140143" class="c"><input type="checkbox" id="c-39140143" checked=""/><div class="controls bullet"><span class="by">marginalia_nu</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39139143">next</a><span>|</span><label class="collapse" for="c-39140143">[-]</label><label class="expand" for="c-39140143">[1 more]</label></div><br/><div class="children"><div class="content">1k rows isn&#x27;t really at a point where you need any form of database.  Vector or BOW, you can just bruteforce the search with such a miniscule amount of data (arguably this should be true into the low millions).<p>The problem is what happens when you have an additional 6 orders of magnitude of data, and the data itself is significantly larger than the system RAM, which is a very realistic case in a search engine.</div><br/></div></div><div id="39139143" class="c"><input type="checkbox" id="c-39139143" checked=""/><div class="controls bullet"><span class="by">omeze</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39140143">prev</a><span>|</span><a href="#39140065">next</a><span>|</span><label class="collapse" for="c-39139143">[-]</label><label class="expand" for="c-39139143">[1 more]</label></div><br/><div class="children"><div class="content">Everyone is piling on you but Id love to see what their companies are doing. Cosine similarity and loading a few thousand rows sounds trivial but most of the enterprise&#x2F;b2b chat&#x2F;copilot apps have a relatively small amount of data whose embeddings can fit in RAM. Combine that with natural sharding by customer ID and it turns out vector DBs are much more niche than an RDBMS. I suspect most people reaching for them havenât done the calculus :&#x2F;</div><br/></div></div><div id="39140065" class="c"><input type="checkbox" id="c-39140065" checked=""/><div class="controls bullet"><span class="by">baldeagle</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39139143">prev</a><span>|</span><a href="#39140062">next</a><span>|</span><label class="collapse" for="c-39140065">[-]</label><label class="expand" for="c-39140065">[1 more]</label></div><br/><div class="children"><div class="content">You may benefit from polars, it can multi-core better than pandas, and has some of the niceties from Arrow (which was the written &#x2F; championed by the power duo of Wes and Hadley, authors of pandas and the R - tidyverse respectively).</div><br/></div></div><div id="39140062" class="c"><input type="checkbox" id="c-39140062" checked=""/><div class="controls bullet"><span class="by">zzleeper</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39140065">prev</a><span>|</span><a href="#39139275">next</a><span>|</span><label class="collapse" for="c-39140062">[-]</label><label class="expand" for="c-39140062">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s kinda why I use LanceDB. It works on all three OSes, doesn&#x27;t require large installs, and is quite easy to use. The files are also just Parquet, so no need to deall with SQL.</div><br/></div></div><div id="39139275" class="c"><input type="checkbox" id="c-39139275" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39140062">prev</a><span>|</span><a href="#39138572">next</a><span>|</span><label class="collapse" for="c-39139275">[-]</label><label class="expand" for="c-39139275">[3 more]</label></div><br/><div class="children"><div class="content">1k is not much. My first RAG had over 40K docs (all short, but still...)<p>The one I&#x27;m working on right now has 115K docs (some quite big - I&#x27;ll likely have to prune the largest 10% just to fit in my RAM).<p>These are all &quot;small&quot; - for personal use on my local machine. I&#x27;m currently RAM limited, otherwise I can think of (personal) use cases that are an order of magnitude larger.<p>Of course, for all I know, your method may still be as fast on those as on a vector DB.</div><br/><div id="39139663" class="c"><input type="checkbox" id="c-39139663" checked=""/><div class="controls bullet"><span class="by">hnfong</span><span>|</span><a href="#39138510">root</a><span>|</span><a href="#39139275">parent</a><span>|</span><a href="#39138572">next</a><span>|</span><label class="collapse" for="c-39139663">[-]</label><label class="expand" for="c-39139663">[2 more]</label></div><br/><div class="children"><div class="content">I must be missing something -- why is the size of the documents a factor? If you embeded a document it would become a vector of ~1k floats, and 115k*1k floats is a couple hundred MB, trivial to fit in modern day RAM.</div><br/><div id="39139932" class="c"><input type="checkbox" id="c-39139932" checked=""/><div class="controls bullet"><span class="by">DougBTX</span><span>|</span><a href="#39138510">root</a><span>|</span><a href="#39139663">parent</a><span>|</span><a href="#39138572">next</a><span>|</span><label class="collapse" for="c-39139932">[-]</label><label class="expand" for="c-39139932">[1 more]</label></div><br/><div class="children"><div class="content">Embeddings are a type of lossy compression, so roughly speaking, using more embedding bytes for a document preserves more information about what it contains. Typically documents are broken down into chunks, then the embedding for each chunk is stored, so longer documents are represented by more embeddings.<p>Going further down the AI == compression path, thereâs: <a href="http:&#x2F;&#x2F;prize.hutter1.net&#x2F;" rel="nofollow">http:&#x2F;&#x2F;prize.hutter1.net&#x2F;</a></div><br/></div></div></div></div></div></div><div id="39138572" class="c"><input type="checkbox" id="c-39138572" checked=""/><div class="controls bullet"><span class="by">ninja3925</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39139275">prev</a><span>|</span><a href="#39139751">next</a><span>|</span><label class="collapse" for="c-39138572">[-]</label><label class="expand" for="c-39138572">[1 more]</label></div><br/><div class="children"><div class="content">True.<p>Also, you are probably doing it wrong by turning a matrix to matrix multiplication into a for loop (over rows). The optimal solution results in better performance<p>sim = np.vstack(df.col) @ vec</div><br/></div></div><div id="39139751" class="c"><input type="checkbox" id="c-39139751" checked=""/><div class="controls bullet"><span class="by">petters</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39138572">prev</a><span>|</span><a href="#39139997">next</a><span>|</span><label class="collapse" for="c-39139751">[-]</label><label class="expand" for="c-39139751">[1 more]</label></div><br/><div class="children"><div class="content">Think about the number of flops needed for each comparison in brute force search.<p>You&#x27;ll realize that it scales well beyond 1k.</div><br/></div></div><div id="39139997" class="c"><input type="checkbox" id="c-39139997" checked=""/><div class="controls bullet"><span class="by">hcks</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39139751">prev</a><span>|</span><a href="#39138634">next</a><span>|</span><label class="collapse" for="c-39139997">[-]</label><label class="expand" for="c-39139997">[1 more]</label></div><br/><div class="children"><div class="content">You could do it by hand at that scale too</div><br/></div></div><div id="39138634" class="c"><input type="checkbox" id="c-39138634" checked=""/><div class="controls bullet"><span class="by">Uncroyable</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39139997">prev</a><span>|</span><a href="#39139153">next</a><span>|</span><label class="collapse" for="c-39138634">[-]</label><label class="expand" for="c-39138634">[2 more]</label></div><br/><div class="children"><div class="content">I mean, you have 1k rows and it is a &quot;prototype&quot;.</div><br/></div></div><div id="39139153" class="c"><input type="checkbox" id="c-39139153" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39138634">prev</a><span>|</span><a href="#39138761">next</a><span>|</span><label class="collapse" for="c-39139153">[-]</label><label class="expand" for="c-39139153">[1 more]</label></div><br/><div class="children"><div class="content">use np.dot, takes 1 line</div><br/></div></div><div id="39138761" class="c"><input type="checkbox" id="c-39138761" checked=""/><div class="controls bullet"><span class="by">jjtheblunt</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39139153">prev</a><span>|</span><a href="#39139046">next</a><span>|</span><label class="collapse" for="c-39138761">[-]</label><label class="expand" for="c-39138761">[1 more]</label></div><br/><div class="children"><div class="content">What RAG systems do you prototype?</div><br/></div></div><div id="39139046" class="c"><input type="checkbox" id="c-39139046" checked=""/><div class="controls bullet"><span class="by">whalesalad</span><span>|</span><a href="#39138510">parent</a><span>|</span><a href="#39138761">prev</a><span>|</span><a href="#39138724">next</a><span>|</span><label class="collapse" for="c-39139046">[-]</label><label class="expand" for="c-39139046">[2 more]</label></div><br/><div class="children"><div class="content">1k rows? Sounds like kindergarten.</div><br/><div id="39139154" class="c"><input type="checkbox" id="c-39139154" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39138510">root</a><span>|</span><a href="#39139046">parent</a><span>|</span><a href="#39138724">next</a><span>|</span><label class="collapse" for="c-39139154">[-]</label><label class="expand" for="c-39139154">[1 more]</label></div><br/><div class="children"><div class="content">up to 100k rows you don&#x27;t get faster by using vector store, just use numpy</div><br/></div></div></div></div></div></div><div id="39138724" class="c"><input type="checkbox" id="c-39138724" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#39138510">prev</a><span>|</span><a href="#39139435">next</a><span>|</span><label class="collapse" for="c-39138724">[-]</label><label class="expand" for="c-39138724">[1 more]</label></div><br/><div class="children"><div class="content">We are past it, it was months ago :) The points are basically right, but a lot of folks realize all this.</div><br/></div></div><div id="39139435" class="c"><input type="checkbox" id="c-39139435" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#39138724">prev</a><span>|</span><a href="#39139233">next</a><span>|</span><label class="collapse" for="c-39139435">[-]</label><label class="expand" for="c-39139435">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re at the peak of blog posts listing vector databases.</div><br/></div></div><div id="39139233" class="c"><input type="checkbox" id="c-39139233" checked=""/><div class="controls bullet"><span class="by">lumost</span><span>|</span><a href="#39139435">prev</a><span>|</span><a href="#39139179">next</a><span>|</span><label class="collapse" for="c-39139233">[-]</label><label class="expand" for="c-39139233">[1 more]</label></div><br/><div class="children"><div class="content">So, there have been gnaw plugins for elastic search for some time. Is there really a need for a new search platform?<p>If there is, what api differentiates it, and why canât this be expressed in either elasticsearch or Postgres?</div><br/></div></div><div id="39139179" class="c"><input type="checkbox" id="c-39139179" checked=""/><div class="controls bullet"><span class="by">feverzsj</span><span>|</span><a href="#39139233">prev</a><span>|</span><a href="#39138789">next</a><span>|</span><label class="collapse" for="c-39139179">[-]</label><label class="expand" for="c-39139179">[1 more]</label></div><br/><div class="children"><div class="content">Investors don&#x27;t really care if it actually creates more value. They only care if the story can attract the public. They just want to profit by taking next investors&#x27; money.</div><br/></div></div><div id="39138789" class="c"><input type="checkbox" id="c-39138789" checked=""/><div class="controls bullet"><span class="by">charcircuit</span><span>|</span><a href="#39139179">prev</a><span>|</span><a href="#39139122">next</a><span>|</span><label class="collapse" for="c-39138789">[-]</label><label class="expand" for="c-39138789">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Real-time recommendations, but driven by vector (and other kinds of) retrieval that looks more like a search engine - not batch computed, nightly jobs common these days.<p>This is already the case. Recommendations are just a fancy search where the query is a vector representing the user. Whether the learning is batched or not doesn&#x27;t change the fact that it will use vector search for at least candidate generation.</div><br/></div></div><div id="39139122" class="c"><input type="checkbox" id="c-39139122" checked=""/><div class="controls bullet"><span class="by">dbCoop3r</span><span>|</span><a href="#39138789">prev</a><span>|</span><a href="#39120393">next</a><span>|</span><label class="collapse" for="c-39139122">[-]</label><label class="expand" for="c-39139122">[1 more]</label></div><br/><div class="children"><div class="content">Why not a &quot;vector filesystem&quot; for Linux?<p>I know it&#x27;s subjective, but databases have started to feel like running a window manager and desktop on a server.<p>I feel like software needs to take a step back and rethink itself after years of putting chimps at typewriters searching for Shakespeare.<p>Why not a Linux kernel with a module(s) to provide the same assurances, SQL operations? Write directly to the filesystem?<p>Why is all the mathematical concept that we derive software from packaged into endless conceptual blobs of black box state?</div><br/></div></div><div id="39120393" class="c"><input type="checkbox" id="c-39120393" checked=""/><div class="controls bullet"><span class="by">flying_lotus</span><span>|</span><a href="#39139122">prev</a><span>|</span><a href="#39138975">next</a><span>|</span><label class="collapse" for="c-39120393">[-]</label><label class="expand" for="c-39120393">[1 more]</label></div><br/><div class="children"><div class="content">To your point, the market for vector db solutions feels very undifferentiated. I am genuinely curious -- what are the types of ANN use-cases that truly require XXms lookup latency, XXX QPS, and capacity for billions of documents?</div><br/></div></div><div id="39138975" class="c"><input type="checkbox" id="c-39138975" checked=""/><div class="controls bullet"><span class="by">monero-xmr</span><span>|</span><a href="#39120393">prev</a><span>|</span><a href="#39138581">next</a><span>|</span><label class="collapse" for="c-39138975">[-]</label><label class="expand" for="c-39138975">[3 more]</label></div><br/><div class="children"><div class="content">Someday enterprises will actually pay someone for LLM tech and infra. Somedayâ¦</div><br/><div id="39139301" class="c"><input type="checkbox" id="c-39139301" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#39138975">parent</a><span>|</span><a href="#39138581">next</a><span>|</span><label class="collapse" for="c-39139301">[-]</label><label class="expand" for="c-39139301">[2 more]</label></div><br/><div class="children"><div class="content">Lots of companies are paying OpenAI, so someday is yesterday?<p><a href="https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;openai-annualized-revenue-tops-16-billion-information-2023-12-30&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;openai-annualized-revenue...</a></div><br/><div id="39139378" class="c"><input type="checkbox" id="c-39139378" checked=""/><div class="controls bullet"><span class="by">monero-xmr</span><span>|</span><a href="#39138975">root</a><span>|</span><a href="#39139301">parent</a><span>|</span><a href="#39138581">next</a><span>|</span><label class="collapse" for="c-39139378">[-]</label><label class="expand" for="c-39139378">[1 more]</label></div><br/><div class="children"><div class="content">Most of that is recycled. They donât break it down because it would make the obvious, obvious. Microsoft pays OpenAI but requires them to use Azure, and OpenAI pays Microsoft the same money back. This is why they continually need billions in investment, because they are far from profitable.<p>The same principle applies to defense. The US gives Israel and Ukraine tens of billions, but thatâs a credit to buy from US defense firms. That money gets recycled right back to US weaponry.</div><br/></div></div></div></div></div></div><div id="39138581" class="c"><input type="checkbox" id="c-39138581" checked=""/><div class="controls bullet"><span class="by">heyitsguay</span><span>|</span><a href="#39138975">prev</a><span>|</span><a href="#39138610">next</a><span>|</span><label class="collapse" for="c-39138581">[-]</label><label class="expand" for="c-39138581">[9 more]</label></div><br/><div class="children"><div class="content">As someone who has been using pgvector for a while and is vaguely curious about alternatives without having the bandwidth to investigate -- is there anything out there that offers truly differentiated advantages over pgvector? I&#x27;m extremely wary of non-OSS solutions in this area, it seems ripe for enshittification and attempts at vendor lock-in.</div><br/><div id="39138780" class="c"><input type="checkbox" id="c-39138780" checked=""/><div class="controls bullet"><span class="by">serjester</span><span>|</span><a href="#39138581">parent</a><span>|</span><a href="#39138985">next</a><span>|</span><label class="collapse" for="c-39138780">[-]</label><label class="expand" for="c-39138780">[6 more]</label></div><br/><div class="children"><div class="content">I use PgVector myself but here&#x27;s the advantages to a true vector db.<p>- Vectors are massive data wise. In our current production database they take up 95% of the memory - should they be stored separately?<p>- Better support for easily re-embedding, hybrid search, certain RAG workflows<p>- Stronger performance once you&#x27;re dealing with millions of vectors.<p>I would still stick with PgVector until you&#x27;re dealing with non trivial scale.</div><br/><div id="39140052" class="c"><input type="checkbox" id="c-39140052" checked=""/><div class="controls bullet"><span class="by">whakim</span><span>|</span><a href="#39138581">root</a><span>|</span><a href="#39138780">parent</a><span>|</span><a href="#39138937">next</a><span>|</span><label class="collapse" for="c-39140052">[-]</label><label class="expand" for="c-39140052">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d also start with pgvector (it&#x27;s easy to switch), but the limitations around hybrid search and filtering + ANN are real and if you&#x27;re doing any kind of RAG-like thing it&#x27;s worth being aware of them upfront. pgvector is also an open-source project with way less manpower behind it than a bunch of venture-backed companies, so while you can expect it to pick up important features, it takes much longer (support for HNSW indices was a good example).</div><br/></div></div><div id="39138937" class="c"><input type="checkbox" id="c-39138937" checked=""/><div class="controls bullet"><span class="by">nikita</span><span>|</span><a href="#39138581">root</a><span>|</span><a href="#39138780">parent</a><span>|</span><a href="#39140052">prev</a><span>|</span><a href="#39138985">next</a><span>|</span><label class="collapse" for="c-39138937">[-]</label><label class="expand" for="c-39138937">[4 more]</label></div><br/><div class="children"><div class="content">What is taking the most time at scale? Is this ingest, index build or lookups ?</div><br/><div id="39139169" class="c"><input type="checkbox" id="c-39139169" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39138581">root</a><span>|</span><a href="#39138937">parent</a><span>|</span><a href="#39138985">next</a><span>|</span><label class="collapse" for="c-39139169">[-]</label><label class="expand" for="c-39139169">[3 more]</label></div><br/><div class="children"><div class="content">ingest and index build can take time</div><br/><div id="39139206" class="c"><input type="checkbox" id="c-39139206" checked=""/><div class="controls bullet"><span class="by">nikita</span><span>|</span><a href="#39138581">root</a><span>|</span><a href="#39139169">parent</a><span>|</span><a href="#39138985">next</a><span>|</span><label class="collapse" for="c-39139206">[-]</label><label class="expand" for="c-39139206">[2 more]</label></div><br/><div class="children"><div class="content">What volumes are we talking about.<p>There are ways to speed things up dramatically. Index build just became multithreaded (see above).<p>We have ideas on what to do with ingest.<p>Also do you interest from S3 ?</div><br/><div id="39139212" class="c"><input type="checkbox" id="c-39139212" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39138581">root</a><span>|</span><a href="#39139206">parent</a><span>|</span><a href="#39138985">next</a><span>|</span><label class="collapse" for="c-39139212">[-]</label><label class="expand" for="c-39139212">[1 more]</label></div><br/><div class="children"><div class="content">np.dot is also multi-threaded, based on BLAS</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39138985" class="c"><input type="checkbox" id="c-39138985" checked=""/><div class="controls bullet"><span class="by">fxtentacle</span><span>|</span><a href="#39138581">parent</a><span>|</span><a href="#39138780">prev</a><span>|</span><a href="#39138726">next</a><span>|</span><label class="collapse" for="c-39138985">[-]</label><label class="expand" for="c-39138985">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re still in the &quot;millions of documents&quot; scale range, then PostgreSQL on a beefy EPYC can probably handle everything fast enough so that it doesn&#x27;t make sense to spend engineering time on using a vector db which would only shave off a few ms in latency.</div><br/></div></div><div id="39138726" class="c"><input type="checkbox" id="c-39138726" checked=""/><div class="controls bullet"><span class="by">MarkMarine</span><span>|</span><a href="#39138581">parent</a><span>|</span><a href="#39138985">prev</a><span>|</span><a href="#39138610">next</a><span>|</span><label class="collapse" for="c-39138726">[-]</label><label class="expand" for="c-39138726">[1 more]</label></div><br/><div class="children"><div class="content">No</div><br/></div></div></div></div><div id="39138610" class="c"><input type="checkbox" id="c-39138610" checked=""/><div class="controls bullet"><span class="by">vishnumohandas</span><span>|</span><a href="#39138581">prev</a><span>|</span><label class="collapse" for="c-39138610">[-]</label><label class="expand" for="c-39138610">[10 more]</label></div><br/><div class="children"><div class="content">There are none that run on the edge, yet. Few more miles to go before we &quot;peak&quot;.</div><br/><div id="39140034" class="c"><input type="checkbox" id="c-39140034" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#39138610">parent</a><span>|</span><a href="#39138768">next</a><span>|</span><label class="collapse" for="c-39140034">[-]</label><label class="expand" for="c-39140034">[1 more]</label></div><br/><div class="children"><div class="content">Incorrect, most of the libraries can run on edge, they&#x27;re just C++.</div><br/></div></div><div id="39138768" class="c"><input type="checkbox" id="c-39138768" checked=""/><div class="controls bullet"><span class="by">0x6c6f6c</span><span>|</span><a href="#39138610">parent</a><span>|</span><a href="#39140034">prev</a><span>|</span><a href="#39140165">next</a><span>|</span><label class="collapse" for="c-39138768">[-]</label><label class="expand" for="c-39138768">[5 more]</label></div><br/><div class="children"><div class="content">Hmmm. Does pgvector count? That&#x27;s supported by NeonDB, serverless compute on PostgreSQL.<p><a href="https:&#x2F;&#x2F;neon.tech&#x2F;docs&#x2F;extensions&#x2F;pgvector" rel="nofollow">https:&#x2F;&#x2F;neon.tech&#x2F;docs&#x2F;extensions&#x2F;pgvector</a></div><br/><div id="39139026" class="c"><input type="checkbox" id="c-39139026" checked=""/><div class="controls bullet"><span class="by">vishnumohandas</span><span>|</span><a href="#39138610">root</a><span>|</span><a href="#39138768">parent</a><span>|</span><a href="#39138808">next</a><span>|</span><label class="collapse" for="c-39139026">[-]</label><label class="expand" for="c-39139026">[1 more]</label></div><br/><div class="children"><div class="content">By &quot;edge&quot;, I was talking about mobile &#x2F; IOT devices.<p>The closest I can see is the VSS extension[1] for Sqlite.<p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;asg017&#x2F;sqlite-vss">https:&#x2F;&#x2F;github.com&#x2F;asg017&#x2F;sqlite-vss</a></div><br/></div></div><div id="39138808" class="c"><input type="checkbox" id="c-39138808" checked=""/><div class="controls bullet"><span class="by">nikita</span><span>|</span><a href="#39138610">root</a><span>|</span><a href="#39138768">parent</a><span>|</span><a href="#39139026">prev</a><span>|</span><a href="#39140165">next</a><span>|</span><label class="collapse" for="c-39138808">[-]</label><label class="expand" for="c-39138808">[3 more]</label></div><br/><div class="children"><div class="content">(Neon CEO)
Itâs about to get a lot better too. Pgvector now supports multi-threaded build<p><a href="https:&#x2F;&#x2F;github.com&#x2F;pgvector&#x2F;pgvector&#x2F;issues&#x2F;409#issuecomment-1905594721">https:&#x2F;&#x2F;github.com&#x2F;pgvector&#x2F;pgvector&#x2F;issues&#x2F;409#issuecomment...</a></div><br/><div id="39138952" class="c"><input type="checkbox" id="c-39138952" checked=""/><div class="controls bullet"><span class="by">boomskats</span><span>|</span><a href="#39138610">root</a><span>|</span><a href="#39138808">parent</a><span>|</span><a href="#39140165">next</a><span>|</span><label class="collapse" for="c-39138952">[-]</label><label class="expand" for="c-39138952">[2 more]</label></div><br/><div class="children"><div class="content">Another very significant contribution to the pg ecosystem. You guys are awesome, thank you for everything you&#x27;re doing.</div><br/><div id="39139196" class="c"><input type="checkbox" id="c-39139196" checked=""/><div class="controls bullet"><span class="by">nikita</span><span>|</span><a href="#39138610">root</a><span>|</span><a href="#39138952">parent</a><span>|</span><a href="#39140165">next</a><span>|</span><label class="collapse" for="c-39139196">[-]</label><label class="expand" for="c-39139196">[1 more]</label></div><br/><div class="children"><div class="content">Lol rare collaboration between neon, AWS, and supabase.<p>But if Postgres wins we all win!</div><br/></div></div></div></div></div></div></div></div><div id="39140165" class="c"><input type="checkbox" id="c-39140165" checked=""/><div class="controls bullet"><span class="by">marginalia_nu</span><span>|</span><a href="#39138610">parent</a><span>|</span><a href="#39138768">prev</a><span>|</span><a href="#39139295">next</a><span>|</span><label class="collapse" for="c-39140165">[-]</label><label class="expand" for="c-39140165">[1 more]</label></div><br/><div class="children"><div class="content">hnswlib?</div><br/></div></div><div id="39139295" class="c"><input type="checkbox" id="c-39139295" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#39138610">parent</a><span>|</span><a href="#39140165">prev</a><span>|</span><label class="collapse" for="c-39139295">[-]</label><label class="expand" for="c-39139295">[2 more]</label></div><br/><div class="children"><div class="content">What is the use case for this?</div><br/><div id="39139441" class="c"><input type="checkbox" id="c-39139441" checked=""/><div class="controls bullet"><span class="by">vishnumohandas</span><span>|</span><a href="#39138610">root</a><span>|</span><a href="#39139295">parent</a><span>|</span><label class="collapse" for="c-39139441">[-]</label><label class="expand" for="c-39139441">[1 more]</label></div><br/><div class="children"><div class="content">Running machine learning on device.<p>Context: I&#x27;m working on an e2ee alternative to Google Photos[1] where we have to cluster embeddings (for face recognition) and run similarity searches (for semantic search[2]) on device.<p>[1]: <a href="https:&#x2F;&#x2F;ente.io" rel="nofollow">https:&#x2F;&#x2F;ente.io</a><p>[2]: <a href="https:&#x2F;&#x2F;openai.com&#x2F;research&#x2F;clip" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;research&#x2F;clip</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>