<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1693558867137" as="style"/><link rel="stylesheet" href="styles.css?v=1693558867137"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://medium.com/dataherald/fine-tuning-gpt-3-5-turbo-for-natural-language-to-sql-4445c1d37f7c">Fine-tuning GPT-3.5-turbo for natural language to SQL</a> <span class="domain">(<a href="https://medium.com">medium.com</a>)</span></div><div class="subtext"><span>saigal</span> | <span>62 comments</span></div><br/><div><div id="37343595" class="c"><input type="checkbox" id="c-37343595" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#37346469">next</a><span>|</span><label class="collapse" for="c-37343595">[-]</label><label class="expand" for="c-37343595">[19 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve been chasing this rabbit since the beginning. It currently seems to be uncatchable for the use cases that would be most valuable to us - writing complex queries we&#x27;ve never seen before. Our use case seems to confound any notion of training or fine-tuning, since the cases we need the most help with are also the ones we have the fewest examples of.<p>Instead of going for generative, few-shot models, I am starting to look at the other end of the spectrum: Binary classification into deterministic query building.<p>With ChatGPT, you cannot realistically explain why you got some output in a way that anyone other than an AI&#x2F;ML expert would find satisfying. With binary classifiers, you can precisely explain how some input resulted in some output in terms that a business person could easily digest - &quot;You mentioned this table so it assumed you wanted to constrain on XYZ. Here&#x27;s the trace from the classifiers...&quot;.<p>I&#x27;ve proposed a few schemes where you define groups of classifiers for each SQL building concern - Which tables are involved, which columns, is a join or aggregate implied, general context of business use, etc. Clearly, there are holes with this scheme, but in our domain we could plausibly fine-tune our <i>humans</i> to be a little bit more verbose in their use of the automagic SQL vending machine. Several hours spent training humans is probably a lot cheaper &amp; easier than getting ChatGPT, et. al. to <i>consistently</i> play by our rules.</div><br/><div id="37343729" class="c"><input type="checkbox" id="c-37343729" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#37343595">parent</a><span>|</span><a href="#37345459">next</a><span>|</span><label class="collapse" for="c-37343729">[-]</label><label class="expand" for="c-37343729">[13 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;ve fallen into the trap of &quot;AIs don&#x27;t generalize, they memorize.&quot; But they do in fact generalize. The reason ChatGPT is so valuable is precisely because it can help out with situations that have never been seen before, not because it merely unlocks old preexisting knowledge. The fella who saved their dog with ChatGPT comes to mind. <a href="https:&#x2F;&#x2F;nypost.com&#x2F;2023&#x2F;03&#x2F;27&#x2F;chatgpt-saved-my-dogs-life-after-vet-couldnt-diagnosis-it&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;nypost.com&#x2F;2023&#x2F;03&#x2F;27&#x2F;chatgpt-saved-my-dogs-life-aft...</a></div><br/><div id="37346021" class="c"><input type="checkbox" id="c-37346021" checked=""/><div class="controls bullet"><span class="by">PheonixPharts</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37343729">parent</a><span>|</span><a href="#37344709">next</a><span>|</span><label class="collapse" for="c-37346021">[-]</label><label class="expand" for="c-37346021">[5 more]</label></div><br/><div class="children"><div class="content">I think you have fallen into the trap of mistaking <i>interpolation</i> for <i>generalization</i>.<p>Working with these models every day, it&#x27;s clear that they can certainly interpolate between points in latent space and generate sensible answers to unseen questions, but it&#x27;s pretty clear that they don&#x27;t <i>generalize</i>. I&#x27;ve seen far to many examples of models failing to display any sense of generalization to believe otherwise.<p>That&#x27;s not to say that interpolation in a rich latent space of text isn&#x27;t very useful. But it&#x27;s not the same level of abstraction that comes from true generalization in this space.</div><br/><div id="37346216" class="c"><input type="checkbox" id="c-37346216" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37346021">parent</a><span>|</span><a href="#37347435">next</a><span>|</span><label class="collapse" for="c-37346216">[-]</label><label class="expand" for="c-37346216">[1 more]</label></div><br/><div class="children"><div class="content">&gt;it&#x27;s pretty clear that they don&#x27;t generalize. I&#x27;ve seen far to many examples of models failing to display any sense of generalization to believe otherwise<p>Failing to generalize on whatever you have in mind is not evidence that the models are incapable of generalization. If you really think so, just be prepared to write off a good chunk of humans as well lol.<p>This is generalization. <a href="https:&#x2F;&#x2F;general-pattern-machines.github.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;general-pattern-machines.github.io&#x2F;</a><p>Just seems to me like you&#x27;ve taken examples of generalization and invented an alternate meaning just so you can&#x27;t admit it generalizes.<p>&quot;Oh but you see this example of answering an unseen question is &quot;insert meaningless distinction&quot; so it doesn&#x27;t really count&quot;</div><br/></div></div><div id="37347435" class="c"><input type="checkbox" id="c-37347435" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37346021">parent</a><span>|</span><a href="#37346216">prev</a><span>|</span><a href="#37346889">next</a><span>|</span><label class="collapse" for="c-37347435">[-]</label><label class="expand" for="c-37347435">[1 more]</label></div><br/><div class="children"><div class="content">Given a multi-dimensional latent space with enough dimensions it&#x27;s hard to imagine cases of generalization that <i>aren&#x27;t</i> interpolation between points in latent space (given enough data).<p>The one possible exception is logical inference, and this problem seems tractable with tool use or programming.</div><br/></div></div><div id="37346889" class="c"><input type="checkbox" id="c-37346889" checked=""/><div class="controls bullet"><span class="by">johndough</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37346021">parent</a><span>|</span><a href="#37347435">prev</a><span>|</span><a href="#37346159">next</a><span>|</span><label class="collapse" for="c-37346889">[-]</label><label class="expand" for="c-37346889">[1 more]</label></div><br/><div class="children"><div class="content">With a sufficiently large dataset, every problem becomes interpolation.</div><br/></div></div><div id="37346159" class="c"><input type="checkbox" id="c-37346159" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37346021">parent</a><span>|</span><a href="#37346889">prev</a><span>|</span><a href="#37344709">next</a><span>|</span><label class="collapse" for="c-37346159">[-]</label><label class="expand" for="c-37346159">[1 more]</label></div><br/><div class="children"><div class="content">I think we’ve all fallen into the trap of mistaking <i>pithiness</i> for <i>evidence</i></div><br/></div></div></div></div><div id="37344709" class="c"><input type="checkbox" id="c-37344709" checked=""/><div class="controls bullet"><span class="by">Zircom</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37343729">parent</a><span>|</span><a href="#37346021">prev</a><span>|</span><a href="#37344160">next</a><span>|</span><label class="collapse" for="c-37344709">[-]</label><label class="expand" for="c-37344709">[6 more]</label></div><br/><div class="children"><div class="content">Did you read the article you posted?<p>-ChatGPT initially gives the same diagnosis the vets did, Babesiosis<p>-It notes that Babesiosis may have either been a misdiagnosis or there may be a secondary condition&#x2F;infection causing the remaining symptoms after the Babesiosis treatment didn&#x27;t resolve all of them<p>-It suggests such a hypothetical secondary condition could be IMHA, which the article notes is an extremely common complication of Babesiosis with this specific dog breed<p>-A quick Google search brings up a fair amount of literature about the association between Babesiosis and IMHA<p>So in fact this is the opposite of a never before seen situation, ChatGPT was just regurgitating common comorbidities of Babesiosis and the vets in question are terrible at their job.</div><br/><div id="37344888" class="c"><input type="checkbox" id="c-37344888" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37344709">parent</a><span>|</span><a href="#37344160">next</a><span>|</span><label class="collapse" for="c-37344888">[-]</label><label class="expand" for="c-37344888">[5 more]</label></div><br/><div class="children"><div class="content">Are you suggesting that it was commonplace for machine learning models to be able to extrapolate medical case reports into an actual diagnosis? Even being able to read and understand a case report is a minor miracle in extrapolation, and it’s interesting how far the goal posts move.</div><br/><div id="37345084" class="c"><input type="checkbox" id="c-37345084" checked=""/><div class="controls bullet"><span class="by">lossolo</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37344888">parent</a><span>|</span><a href="#37344160">next</a><span>|</span><label class="collapse" for="c-37345084">[-]</label><label class="expand" for="c-37345084">[4 more]</label></div><br/><div class="children"><div class="content">I have another example of ChatGPT not generalizing but just being a really good statistical model. I needed a solution to a problem that you can&#x27;t find on Google, and a variation of a problem that also can&#x27;t be found on Google. I attempted to obtain around 15 lines of code from ChatGPT that would solve the problem, but it consistently failed to produce the correct solution. I spent a few hours trying different prompts, indicating its errors and receiving apologies, only for it to generate another incorrect solution while acknowledging its mistake. 
Solving out of distribution problems correctly seems almost impossible for it.</div><br/><div id="37345112" class="c"><input type="checkbox" id="c-37345112" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37345084">parent</a><span>|</span><a href="#37344160">next</a><span>|</span><label class="collapse" for="c-37345112">[-]</label><label class="expand" for="c-37345112">[3 more]</label></div><br/><div class="children"><div class="content">GPT 3.5 or 4? Surprisingly it makes a huge difference. I think a lot of peoples’ impressions are with 3.5, but many startups couldn’t have been built on it, whereas with 4 they can.<p>If it was 4 I’d be curious about the specific problem if you’d be willing to link to the chat.</div><br/><div id="37346857" class="c"><input type="checkbox" id="c-37346857" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37345112">parent</a><span>|</span><a href="#37344160">next</a><span>|</span><label class="collapse" for="c-37346857">[-]</label><label class="expand" for="c-37346857">[2 more]</label></div><br/><div class="children"><div class="content">I had similar issue with gpt4, was looking for a library that given a grammar and a string, would produce a list of next valid symbols.<p>Gpt4 only ever suggested grammar validator to the point I had given up and was going to write a grammar generator, and so I started looking for the equivalent of antlr in python, and in three searches I find out nltk.grammar that actually solves the original problem<p>It&#x27;s not a new library either, so I&#x27;m dumbfounded by why gpt4 couldn&#x27;t make sense of my request.</div><br/><div id="37347978" class="c"><input type="checkbox" id="c-37347978" checked=""/><div class="controls bullet"><span class="by">disgruntledphd2</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37346857">parent</a><span>|</span><a href="#37344160">next</a><span>|</span><label class="collapse" for="c-37347978">[-]</label><label class="expand" for="c-37347978">[1 more]</label></div><br/><div class="children"><div class="content">If it hasn&#x27;t been used much&#x2F;talked about much for this purpose then you wouldn&#x27;t expect it to, right?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="37344160" class="c"><input type="checkbox" id="c-37344160" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37343729">parent</a><span>|</span><a href="#37344709">prev</a><span>|</span><a href="#37345459">next</a><span>|</span><label class="collapse" for="c-37344160">[-]</label><label class="expand" for="c-37344160">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think you&#x27;ve fallen into the trap of &quot;AIs don&#x27;t generalize, they memorize.&quot;<p>Binary classifiers don&#x27;t generalize?<p>Just because my <i>output</i> is not generative does not mean we are cannot learn &#x2F; generalize elsewhere. Think of it as a 2-stage process.</div><br/></div></div></div></div><div id="37345459" class="c"><input type="checkbox" id="c-37345459" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#37343595">parent</a><span>|</span><a href="#37343729">prev</a><span>|</span><a href="#37343865">next</a><span>|</span><label class="collapse" for="c-37345459">[-]</label><label class="expand" for="c-37345459">[1 more]</label></div><br/><div class="children"><div class="content">Yeah louie.ai query generation internals feel more like classic program synthesis, where&#x27;s it&#x27;s more about staged compilation, iterative refinement, etc, and we use gpt3&#x2F;gpt4 for each stage rather than a traditional solver. &quot;Which tables would help this query, which parts should go to text search vs vector search, ...&quot;, and we iteratively rewrite and pass along until we reconstitute.<p>At the same time, we&#x27;re also moving to make a lot more of that process AI controlled, just across LLM calls (e.g., LLM-dictated ones), so it&#x27;s a funny maturity process.</div><br/></div></div><div id="37343865" class="c"><input type="checkbox" id="c-37343865" checked=""/><div class="controls bullet"><span class="by">Nick_Molter</span><span>|</span><a href="#37343595">parent</a><span>|</span><a href="#37345459">prev</a><span>|</span><a href="#37344712">next</a><span>|</span><label class="collapse" for="c-37343865">[-]</label><label class="expand" for="c-37343865">[2 more]</label></div><br/><div class="children"><div class="content">Curious to learn more about your use case. If fine-tuning is only ineffective for your most complex queries (and presumably those are less frequent as well, since you mentioned you have few examples), then couldn&#x27;t you use fine-tuning to handle the simpler queries (presumably the lion&#x27;s share) and thus free up excess man hours to focus on the more complex queries? Is there any benefit to AI being able to answer 90% of queries vs 0%?</div><br/><div id="37344185" class="c"><input type="checkbox" id="c-37344185" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37343865">parent</a><span>|</span><a href="#37344712">next</a><span>|</span><label class="collapse" for="c-37344185">[-]</label><label class="expand" for="c-37344185">[1 more]</label></div><br/><div class="children"><div class="content">These tools are already fantastic at our 80% average case, even without fine tuning. We are seeing <i>some</i> value, but the real pain is in that other 20%.</div><br/></div></div></div></div><div id="37344712" class="c"><input type="checkbox" id="c-37344712" checked=""/><div class="controls bullet"><span class="by">MuffinFlavored</span><span>|</span><a href="#37343595">parent</a><span>|</span><a href="#37343865">prev</a><span>|</span><a href="#37346469">next</a><span>|</span><label class="collapse" for="c-37344712">[-]</label><label class="expand" for="c-37344712">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Binary classification into deterministic query building.<p>I have no clue what this means.</div><br/><div id="37345393" class="c"><input type="checkbox" id="c-37345393" checked=""/><div class="controls bullet"><span class="by">philipodonnell</span><span>|</span><a href="#37343595">root</a><span>|</span><a href="#37344712">parent</a><span>|</span><a href="#37346469">next</a><span>|</span><label class="collapse" for="c-37345393">[-]</label><label class="expand" for="c-37345393">[1 more]</label></div><br/><div class="children"><div class="content">I tried something similar to this so I assume it’s to classify a table as being part of the resulting query or not, and using the schemas of the resulting tables in the prompt for the question. I found it just as useful to give it the full schema and ask it for a list of relevant tables, certainly more cost effective.</div><br/></div></div></div></div></div></div><div id="37346469" class="c"><input type="checkbox" id="c-37346469" checked=""/><div class="controls bullet"><span class="by">TedDallas</span><span>|</span><a href="#37343595">prev</a><span>|</span><a href="#37342560">next</a><span>|</span><label class="collapse" for="c-37346469">[-]</label><label class="expand" for="c-37346469">[2 more]</label></div><br/><div class="children"><div class="content">At a certain level of complexity it is easier to write the damn SQL than it is to explain your query to GPT.</div><br/><div id="37347704" class="c"><input type="checkbox" id="c-37347704" checked=""/><div class="controls bullet"><span class="by">gloosx</span><span>|</span><a href="#37346469">parent</a><span>|</span><a href="#37342560">next</a><span>|</span><label class="collapse" for="c-37347704">[-]</label><label class="expand" for="c-37347704">[1 more]</label></div><br/><div class="children"><div class="content">In the end, the one who possesses knowledge will turn it into value going the most obvious and straightforward way: writing a piece of useful SQL or code hot from the head.<p>GPT is a tool for learners, and they will keep shooting them feet until they learn, just the weapon is different now.<p>Look at the law system, written in natural language. It is misleading and doesn&#x27;t work well, so we have to gather thousands of people around courts doing non-deterministic work in order to process them. Natural language is a tool for learning, not making systems. You have to shrink your vocabulary down to code at some point in order to make systems, and you can do it much faster and better than GPT.</div><br/></div></div></div></div><div id="37342560" class="c"><input type="checkbox" id="c-37342560" checked=""/><div class="controls bullet"><span class="by">philipodonnell</span><span>|</span><a href="#37346469">prev</a><span>|</span><a href="#37344287">next</a><span>|</span><label class="collapse" for="c-37342560">[-]</label><label class="expand" for="c-37342560">[4 more]</label></div><br/><div class="children"><div class="content">Are you planning on submitting this model to be evaluated against the Spider holdout set?<p>Also, wondering if anyone has found research on the inverse of this approach to the problem, i.e., instead of training the model to understand the data, you improve the data to be more understandable to a model? This seems more promising when you are looking at enterprise use cases without much training data. Spider seems like quite a simple dataset compared to the ones I encounter on the job, and LLMs struggle even with those.</div><br/><div id="37342789" class="c"><input type="checkbox" id="c-37342789" checked=""/><div class="controls bullet"><span class="by">aazo11</span><span>|</span><a href="#37342560">parent</a><span>|</span><a href="#37342678">next</a><span>|</span><label class="collapse" for="c-37342789">[-]</label><label class="expand" for="c-37342789">[1 more]</label></div><br/><div class="children"><div class="content">In theory one could create domain specific (or industry specific) templates for data. However coming up with a universal structure might be challenging since data is so varied.<p>Since the issue is often the context, plugging in data dictionaries (and passing those to the LLM) can help</div><br/></div></div><div id="37342678" class="c"><input type="checkbox" id="c-37342678" checked=""/><div class="controls bullet"><span class="by">MrezaPourreza</span><span>|</span><a href="#37342560">parent</a><span>|</span><a href="#37342789">prev</a><span>|</span><a href="#37344287">next</a><span>|</span><label class="collapse" for="c-37342678">[-]</label><label class="expand" for="c-37342678">[2 more]</label></div><br/><div class="children"><div class="content">Yes, we have already submitted the model for evaluation on the Spider holdout test set. While your suggestion is certainly intriguing, implementing a universal solution could be quite challenging, as it would heavily depend on the specifics of the dataset.</div><br/><div id="37343159" class="c"><input type="checkbox" id="c-37343159" checked=""/><div class="controls bullet"><span class="by">philipodonnell</span><span>|</span><a href="#37342560">root</a><span>|</span><a href="#37342678">parent</a><span>|</span><a href="#37344287">next</a><span>|</span><label class="collapse" for="c-37343159">[-]</label><label class="expand" for="c-37343159">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think it’s necessarily about a “universal” solution, just “better”. Make the column names more verbose, changing numeric enums to text ones, disambiguating column names, etc. One of the spider datasets is a stadium table and one of the column names is “average”, which means average capacity, but it’s super ambiguous. If you asked an LLM to “make these table columns more verbose” I bet it would call that “average_capacity” and all of the sudden some NLQ queries that confused the function and the column name would start to work.</div><br/></div></div></div></div></div></div><div id="37344287" class="c"><input type="checkbox" id="c-37344287" checked=""/><div class="controls bullet"><span class="by">codeulike</span><span>|</span><a href="#37342560">prev</a><span>|</span><a href="#37345082">next</a><span>|</span><label class="collapse" for="c-37344287">[-]</label><label class="expand" for="c-37344287">[4 more]</label></div><br/><div class="children"><div class="content">I often do complicated reports in SQL or complicated transformations in SQL for system migrations. To really write a query and &#x27;get it right&#x27; you usually need insider knowledge that you can&#x27;t glean from the column names.<p>I see in their training set they&#x27;ve got comments about columns too. e.g.<p><pre><code>    &quot;Country&quot; TEXT NOT NULL, - country where the singer born
</code></pre>
But thats still not enough.<p>You also need a bunch of information about the real business that the data is describing. And you also need to analyse the whole database - is that field actually used? What are the common values for this picklist? What does that status actually mean in terms of business? If there are two of those rows that match the join but I want to avoid duplicates, which one do I take? - the newest, or the one with a certain status? etc.</div><br/><div id="37347595" class="c"><input type="checkbox" id="c-37347595" checked=""/><div class="controls bullet"><span class="by">codeulike</span><span>|</span><a href="#37344287">parent</a><span>|</span><a href="#37344984">next</a><span>|</span><label class="collapse" for="c-37347595">[-]</label><label class="expand" for="c-37347595">[1 more]</label></div><br/><div class="children"><div class="content">Also, with complicated queries or reports, there&#x27;s quite a big element of &quot;do the results look roughly as I expect?&quot; - e.g does the total income for last month look about right? Then you might do a detailed reconciliation and find out your total is 1% off due to not accounting for refunds and then you go and adjust your query and try again.</div><br/></div></div><div id="37344984" class="c"><input type="checkbox" id="c-37344984" checked=""/><div class="controls bullet"><span class="by">ainesh93</span><span>|</span><a href="#37344287">parent</a><span>|</span><a href="#37347595">prev</a><span>|</span><a href="#37344834">next</a><span>|</span><label class="collapse" for="c-37344984">[-]</label><label class="expand" for="c-37344984">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You also need a bunch of information about the real business that the data is describing.<p>While the article focuses on finetuning GPT-3.5-turbo, how you use the text-to-SQL engine within the architecture of your overall solution is for you to decide. Providing this business context from vectorized context stores in the actual prompt would be a step in the right direction.</div><br/></div></div><div id="37344834" class="c"><input type="checkbox" id="c-37344834" checked=""/><div class="controls bullet"><span class="by">capableweb</span><span>|</span><a href="#37344287">parent</a><span>|</span><a href="#37344984">prev</a><span>|</span><a href="#37345082">next</a><span>|</span><label class="collapse" for="c-37344834">[-]</label><label class="expand" for="c-37344834">[1 more]</label></div><br/><div class="children"><div class="content">Why dont you collect a sample of the data so it knows what to expect then? Include 10 handpicked rows in your prompt and it should be able to pick up the patterns. If you find it doesn&#x27;t handle something, append that row and restart.</div><br/></div></div></div></div><div id="37345082" class="c"><input type="checkbox" id="c-37345082" checked=""/><div class="controls bullet"><span class="by">kristianp</span><span>|</span><a href="#37344287">prev</a><span>|</span><a href="#37346221">next</a><span>|</span><label class="collapse" for="c-37345082">[-]</label><label class="expand" for="c-37345082">[1 more]</label></div><br/><div class="children"><div class="content">So if they&#x27;re doing 50,000,000 tokens to do the fine-tune, @ $0.08&#x2F;1000 tokens and 2 epochs, that&#x27;s about $800 to do the fine-tune.  Not prohibitive from a business standpoint.</div><br/></div></div><div id="37346221" class="c"><input type="checkbox" id="c-37346221" checked=""/><div class="controls bullet"><span class="by">totalhack</span><span>|</span><a href="#37345082">prev</a><span>|</span><a href="#37344151">next</a><span>|</span><label class="collapse" for="c-37346221">[-]</label><label class="expand" for="c-37346221">[2 more]</label></div><br/><div class="children"><div class="content">I think natural language to SQL is a worthwhile goal and will have its use cases, but perhaps fine-tuning a model on a semantic layer and having it talk to a semantic data modeling API will yield a more useful&#x2F;practical result. You may even find the semantic layer makes a natural language approach moot in many cases.<p>In Zillion* I added an experimental feature that uses OpenAI to form a report API call from natural language. Fine tuning (vs prompt tuning) this on the semantic model with gpt-3.5 would probably yield some notable improvement in abilities, as I view it as more of a toy feature at the moment.<p>* <a href="https:&#x2F;&#x2F;github.com&#x2F;totalhack&#x2F;zillion">https:&#x2F;&#x2F;github.com&#x2F;totalhack&#x2F;zillion</a></div><br/><div id="37347625" class="c"><input type="checkbox" id="c-37347625" checked=""/><div class="controls bullet"><span class="by">antupis</span><span>|</span><a href="#37346221">parent</a><span>|</span><a href="#37344151">next</a><span>|</span><label class="collapse" for="c-37347625">[-]</label><label class="expand" for="c-37347625">[1 more]</label></div><br/><div class="children"><div class="content">Yeah it is literally billion dollar question how to do that querying. Is there some good papers or blog posts that go through different approaches?</div><br/></div></div></div></div><div id="37344151" class="c"><input type="checkbox" id="c-37344151" checked=""/><div class="controls bullet"><span class="by">shireboy</span><span>|</span><a href="#37346221">prev</a><span>|</span><a href="#37341671">next</a><span>|</span><label class="collapse" for="c-37344151">[-]</label><label class="expand" for="c-37344151">[2 more]</label></div><br/><div class="children"><div class="content">I think natural language to SQL may not be as great as it sounds in many real-world applications.  You often have permissions, tenants, rules about who-can-see-what.  I love the idea of letting users use natural language to query and possibly even bulk-update data.  But if the app has rules like those, this would just be a SQL injection vulnerability.  You could possibly limit it - just allow query over certain views or something - but the risk of the GPT crafting a dangerous query is still high.<p>What would be more useful IMO is natural language to OData, GraphQL, and OpenAPI&#x2F;Swagger.  Then you could let users do ad-hoc query but only against data they are allowed.  I did a PoC using GPT3 to query OData and it was pretty fun, but did occasionally get the query wrong.  I also ran into the context window issue.  It would get lost when fed larger OData schema.</div><br/><div id="37346034" class="c"><input type="checkbox" id="c-37346034" checked=""/><div class="controls bullet"><span class="by">DevX101</span><span>|</span><a href="#37344151">parent</a><span>|</span><a href="#37341671">next</a><span>|</span><label class="collapse" for="c-37346034">[-]</label><label class="expand" for="c-37346034">[1 more]</label></div><br/><div class="children"><div class="content">You could implement row level security on the database to prevent unauthorized access.</div><br/></div></div></div></div><div id="37341671" class="c"><input type="checkbox" id="c-37341671" checked=""/><div class="controls bullet"><span class="by">saigal</span><span>|</span><a href="#37344151">prev</a><span>|</span><a href="#37343848">next</a><span>|</span><label class="collapse" for="c-37341671">[-]</label><label class="expand" for="c-37341671">[2 more]</label></div><br/><div class="children"><div class="content">A tutorial on how to fine-tune a GPT3.5 model for Natural Language to SQL tasks and a comparison of its performance vs Retrieval Augmented Generation.
Based on the results, fine-tuning can match and outperform RAG (the approach matches the state of the art on accuracy while being far faster and cheaper). The big challenge for fine-tuning tasks like this is building the training datasets. Things should get even more interesting when GPT-4 is opened for fine-tuning.</div><br/></div></div><div id="37343848" class="c"><input type="checkbox" id="c-37343848" checked=""/><div class="controls bullet"><span class="by">tmostak</span><span>|</span><a href="#37341671">prev</a><span>|</span><a href="#37342421">next</a><span>|</span><label class="collapse" for="c-37343848">[-]</label><label class="expand" for="c-37343848">[2 more]</label></div><br/><div class="children"><div class="content">It wasn&#x27;t clear to me what evaluation method was being used, the chart in the blog says Execution Accuracy, but the numbers that seem to be used appear to correlate with &quot;Exact Set Match&quot; (comparing on SQL) instead of the &quot;Execution With Values&quot; (comparing on result set values). For example, DIN-SQL + GPT-4 achieves an 85.3% &quot;Execution With Values&quot; score. Is that what is being used here?<p>See the following for more info:<p><a href="https:&#x2F;&#x2F;yale-lily.github.io&#x2F;spider" rel="nofollow noreferrer">https:&#x2F;&#x2F;yale-lily.github.io&#x2F;spider</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;taoyds&#x2F;spider&#x2F;tree&#x2F;master&#x2F;evaluation_examples">https:&#x2F;&#x2F;github.com&#x2F;taoyds&#x2F;spider&#x2F;tree&#x2F;master&#x2F;evaluation_exam...</a></div><br/><div id="37345630" class="c"><input type="checkbox" id="c-37345630" checked=""/><div class="controls bullet"><span class="by">MrezaPourreza</span><span>|</span><a href="#37343848">parent</a><span>|</span><a href="#37342421">next</a><span>|</span><label class="collapse" for="c-37345630">[-]</label><label class="expand" for="c-37345630">[1 more]</label></div><br/><div class="children"><div class="content">Hello, thank you very much for your meticulous comment. The 85.3% accuracy reported in our paper (I&#x27;m one of the authors of the DIN-SQL paper) pertains to the test set. However, in the blog post, we are reporting the performance on the development set, which stands at 74.2%.</div><br/></div></div></div></div><div id="37342421" class="c"><input type="checkbox" id="c-37342421" checked=""/><div class="controls bullet"><span class="by">MrezaPourreza</span><span>|</span><a href="#37343848">prev</a><span>|</span><a href="#37342967">next</a><span>|</span><label class="collapse" for="c-37342421">[-]</label><label class="expand" for="c-37342421">[1 more]</label></div><br/><div class="children"><div class="content">I believe this article underscores the significance and efficacy of fine-tuning for specific tasks. Looking ahead, I envision the integration of fine-tuned models with RAG agents and models, further enhancing overall performance.</div><br/></div></div><div id="37342967" class="c"><input type="checkbox" id="c-37342967" checked=""/><div class="controls bullet"><span class="by">iandanforth</span><span>|</span><a href="#37342421">prev</a><span>|</span><a href="#37342085">next</a><span>|</span><label class="collapse" for="c-37342967">[-]</label><label class="expand" for="c-37342967">[4 more]</label></div><br/><div class="children"><div class="content">Spider isn&#x27;t anything like the queries that analysts and data scientists write against DBs. I don&#x27;t think it even has many joins. Do you not have access to a more realistic training set?</div><br/><div id="37343856" class="c"><input type="checkbox" id="c-37343856" checked=""/><div class="controls bullet"><span class="by">philipodonnell</span><span>|</span><a href="#37342967">parent</a><span>|</span><a href="#37343713">next</a><span>|</span><label class="collapse" for="c-37343856">[-]</label><label class="expand" for="c-37343856">[1 more]</label></div><br/><div class="children"><div class="content">Agree that it’s not representative of real world queries, but I think it’s more of a “measure progress against a simple but consistent baseline” and SOTA is still struggling so it’s clearly not ready for real queries. Most of the papers on this topic mention a lack of large volumes of high quality training data… Spider is probably the best public one right now.</div><br/></div></div><div id="37343713" class="c"><input type="checkbox" id="c-37343713" checked=""/><div class="controls bullet"><span class="by">tmostak</span><span>|</span><a href="#37342967">parent</a><span>|</span><a href="#37343856">prev</a><span>|</span><a href="#37343493">next</a><span>|</span><label class="collapse" for="c-37343713">[-]</label><label class="expand" for="c-37343713">[1 more]</label></div><br/><div class="children"><div class="content">I agree that Spider queries are not necessarily representative of the SQL you might see in the wild from real users, but looking at some analysis I did of the dataset around 43% of the queries had joins, and a number had 3, 4, or 5-way joins.</div><br/></div></div><div id="37343493" class="c"><input type="checkbox" id="c-37343493" checked=""/><div class="controls bullet"><span class="by">ainesh93</span><span>|</span><a href="#37342967">parent</a><span>|</span><a href="#37343713">prev</a><span>|</span><a href="#37342085">next</a><span>|</span><label class="collapse" for="c-37343493">[-]</label><label class="expand" for="c-37343493">[1 more]</label></div><br/><div class="children"><div class="content">Although Spider is better known in the text-to-SQL world, you&#x27;re right that BiRD may provide a better testing ground. Comparing against the current leaderboard on that standard is on the docket!</div><br/></div></div></div></div><div id="37342085" class="c"><input type="checkbox" id="c-37342085" checked=""/><div class="controls bullet"><span class="by">h1fra</span><span>|</span><a href="#37342967">prev</a><span>|</span><a href="#37345370">next</a><span>|</span><label class="collapse" for="c-37342085">[-]</label><label class="expand" for="c-37342085">[14 more]</label></div><br/><div class="children"><div class="content">The cost per question seems super high. I can&#x27;t even think of an API where a single call would cost $1cent. You better have a good pricing model to follow up on this.</div><br/><div id="37342168" class="c"><input type="checkbox" id="c-37342168" checked=""/><div class="controls bullet"><span class="by">beebmam</span><span>|</span><a href="#37342085">parent</a><span>|</span><a href="#37342226">next</a><span>|</span><label class="collapse" for="c-37342168">[-]</label><label class="expand" for="c-37342168">[3 more]</label></div><br/><div class="children"><div class="content">Really? I sure can. I can even imagine a single API request that triggers a job that costs $100,000. These APIs exist. They&#x27;re not for individuals.</div><br/><div id="37342561" class="c"><input type="checkbox" id="c-37342561" checked=""/><div class="controls bullet"><span class="by">h1fra</span><span>|</span><a href="#37342085">root</a><span>|</span><a href="#37342168">parent</a><span>|</span><a href="#37342226">next</a><span>|</span><label class="collapse" for="c-37342561">[-]</label><label class="expand" for="c-37342561">[2 more]</label></div><br/><div class="children"><div class="content">I mean yes, I have managed BigQuery jobs that cost thousand of dollars per run but the actual call is not the thing that is expensive and I&#x27;m in control of what it costs me. It&#x27;s not exactly the same scenario imo</div><br/><div id="37344482" class="c"><input type="checkbox" id="c-37344482" checked=""/><div class="controls bullet"><span class="by">ainesh93</span><span>|</span><a href="#37342085">root</a><span>|</span><a href="#37342561">parent</a><span>|</span><a href="#37342226">next</a><span>|</span><label class="collapse" for="c-37344482">[-]</label><label class="expand" for="c-37344482">[1 more]</label></div><br/><div class="children"><div class="content">I think the focus here isn&#x27;t necessarily on compute cost. When companies hire data scientists or analysts, they&#x27;re niche-skilled and expensive. If those people spend 50-60% of their time courting ad-hoc questions from various people in the org, the cost of that employee&#x27;s time (and the money spent on them doing menial tasks that are a waste of their skillset) is the biggest factor.</div><br/></div></div></div></div></div></div><div id="37342226" class="c"><input type="checkbox" id="c-37342226" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#37342085">parent</a><span>|</span><a href="#37342168">prev</a><span>|</span><a href="#37345086">next</a><span>|</span><label class="collapse" for="c-37342226">[-]</label><label class="expand" for="c-37342226">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I can&#x27;t even think of an API where a single call would cost $1cent.<p>paying engineer for the same job will be many factors more expensive.</div><br/></div></div><div id="37345086" class="c"><input type="checkbox" id="c-37345086" checked=""/><div class="controls bullet"><span class="by">jug</span><span>|</span><a href="#37342085">parent</a><span>|</span><a href="#37342226">prev</a><span>|</span><a href="#37342469">next</a><span>|</span><label class="collapse" for="c-37345086">[-]</label><label class="expand" for="c-37345086">[1 more]</label></div><br/><div class="children"><div class="content">This is basically what put me off when trying to use GPT-3.5 for this with SQL LangChain. And you can’t go cheaper LLM from OpenAI because then accuracy plummeted. GPT-3.5 is the sweet spot.<p>Sure, some use cases might work but it’s not going to be a thing that Just Works™ for products even accuracy issues aside. There’s just so much data to feed into each and every prompt, schemas and all. Many of them too if you want to enable joins.</div><br/></div></div><div id="37342469" class="c"><input type="checkbox" id="c-37342469" checked=""/><div class="controls bullet"><span class="by">claytonjy</span><span>|</span><a href="#37342085">parent</a><span>|</span><a href="#37345086">prev</a><span>|</span><a href="#37343483">next</a><span>|</span><label class="collapse" for="c-37342469">[-]</label><label class="expand" for="c-37342469">[3 more]</label></div><br/><div class="children"><div class="content">Google Speech-to-Text is one I&#x27;ve dealt with recently; costs over 1¢ to transcribe 1 minute of audio. Almost 8¢&#x2F;minute for the medical version.</div><br/><div id="37342597" class="c"><input type="checkbox" id="c-37342597" checked=""/><div class="controls bullet"><span class="by">h1fra</span><span>|</span><a href="#37342085">root</a><span>|</span><a href="#37342469">parent</a><span>|</span><a href="#37343483">next</a><span>|</span><label class="collapse" for="c-37342597">[-]</label><label class="expand" for="c-37342597">[2 more]</label></div><br/><div class="children"><div class="content">1¢ per 1minute is fair as it would take the best translator much more time than that. 1¢ per sql query seems less fair to me, but we could argue it would also cost more to ask a dev.</div><br/><div id="37342658" class="c"><input type="checkbox" id="c-37342658" checked=""/><div class="controls bullet"><span class="by">eli</span><span>|</span><a href="#37342085">root</a><span>|</span><a href="#37342597">parent</a><span>|</span><a href="#37343483">next</a><span>|</span><label class="collapse" for="c-37342658">[-]</label><label class="expand" for="c-37342658">[1 more]</label></div><br/><div class="children"><div class="content">It would obviously cost much more to pay a person to write SQL for you</div><br/></div></div></div></div></div></div><div id="37343483" class="c"><input type="checkbox" id="c-37343483" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#37342085">parent</a><span>|</span><a href="#37342469">prev</a><span>|</span><a href="#37342200">next</a><span>|</span><label class="collapse" for="c-37343483">[-]</label><label class="expand" for="c-37343483">[1 more]</label></div><br/><div class="children"><div class="content">What? Some of the APIs I use at work cost $100+ per call. (it&#x27;s not really about the call, it&#x27;s about the data it provides)</div><br/></div></div><div id="37342200" class="c"><input type="checkbox" id="c-37342200" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#37342085">parent</a><span>|</span><a href="#37343483">prev</a><span>|</span><a href="#37342383">next</a><span>|</span><label class="collapse" for="c-37342200">[-]</label><label class="expand" for="c-37342200">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s about 0.2 cents right?<p>It&#x27;s hard for something you interact with manually to provide positive value less than 0.2c.</div><br/><div id="37342328" class="c"><input type="checkbox" id="c-37342328" checked=""/><div class="controls bullet"><span class="by">thewataccount</span><span>|</span><a href="#37342085">root</a><span>|</span><a href="#37342200">parent</a><span>|</span><a href="#37342383">next</a><span>|</span><label class="collapse" for="c-37342328">[-]</label><label class="expand" for="c-37342328">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s for the non-finetuned GPT3.5turbo model.<p>Finetuned is 1.2cents&#x2F;1k in and 1.6cents&#x2F;1k out.
So it&#x27;ll likely be closer to 2cents depending on what you&#x27;re doing.<p>I&#x27;m not saying it&#x27;s not useful, at 2c per query you have to be more &quot;purposeful&quot; as they could certainly add up depending on how you use it compared to 0.2c.</div><br/><div id="37343128" class="c"><input type="checkbox" id="c-37343128" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#37342085">root</a><span>|</span><a href="#37342328">parent</a><span>|</span><a href="#37342383">next</a><span>|</span><label class="collapse" for="c-37343128">[-]</label><label class="expand" for="c-37343128">[1 more]</label></div><br/><div class="children"><div class="content">Ah thanks I read that wrong.</div><br/></div></div></div></div></div></div><div id="37342383" class="c"><input type="checkbox" id="c-37342383" checked=""/><div class="controls bullet"><span class="by">Zetobal</span><span>|</span><a href="#37342085">parent</a><span>|</span><a href="#37342200">prev</a><span>|</span><a href="#37345370">next</a><span>|</span><label class="collapse" for="c-37342383">[-]</label><label class="expand" for="c-37342383">[1 more]</label></div><br/><div class="children"><div class="content">If your app is able to function better for the cost of the API calls the value might just be there.</div><br/></div></div></div></div><div id="37345370" class="c"><input type="checkbox" id="c-37345370" checked=""/><div class="controls bullet"><span class="by">philipodonnell</span><span>|</span><a href="#37342085">prev</a><span>|</span><a href="#37342751">next</a><span>|</span><label class="collapse" for="c-37345370">[-]</label><label class="expand" for="c-37345370">[1 more]</label></div><br/><div class="children"><div class="content">Did you provide any db schema information in the prompts after the model was fine tuned?</div><br/></div></div><div id="37342751" class="c"><input type="checkbox" id="c-37342751" checked=""/><div class="controls bullet"><span class="by">sandGorgon</span><span>|</span><a href="#37345370">prev</a><span>|</span><label class="collapse" for="c-37342751">[-]</label><label class="expand" for="c-37342751">[3 more]</label></div><br/><div class="children"><div class="content">do you not use a vector db and embeddings search to get the table structure, etc ?</div><br/><div id="37342803" class="c"><input type="checkbox" id="c-37342803" checked=""/><div class="controls bullet"><span class="by">aazo11</span><span>|</span><a href="#37342751">parent</a><span>|</span><label class="collapse" for="c-37342803">[-]</label><label class="expand" for="c-37342803">[2 more]</label></div><br/><div class="children"><div class="content">Most RAG approaches use a vectorDB and embeddings for schema linking. In this case the fine-tuning is handling schema linking and there is no vectorDB.</div><br/><div id="37347147" class="c"><input type="checkbox" id="c-37347147" checked=""/><div class="controls bullet"><span class="by">sandGorgon</span><span>|</span><a href="#37342751">root</a><span>|</span><a href="#37342803">parent</a><span>|</span><label class="collapse" for="c-37347147">[-]</label><label class="expand" for="c-37347147">[1 more]</label></div><br/><div class="children"><div class="content">that is super interesting. Do you find that schema-linking using finetuning works better ?</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>