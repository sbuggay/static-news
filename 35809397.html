<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1683190851271" as="style"/><link rel="stylesheet" href="styles.css?v=1683190851271"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.npr.org/sections/money/2023/05/02/1172791281/this-company-adopted-ai-heres-what-happened-to-its-human-workers">The first empirical study of the real-world economic effects of new AI systems</a> <span class="domain">(<a href="https://www.npr.org">www.npr.org</a>)</span></div><div class="subtext"><span>SirLJ</span> | <span>29 comments</span></div><br/><div><div id="35812248" class="c"><input type="checkbox" id="c-35812248" checked=""/><div class="controls bullet"><span class="by">spaceman_2020</span><span>|</span><a href="#35812732">next</a><span>|</span><label class="collapse" for="c-35812248">[-]</label><label class="expand" for="c-35812248">[6 more]</label></div><br/><div class="children"><div class="content">It would be interesting to see how a general-purpose AI like GPT-4 trained on internal corporate knowledgebase would perform.<p>Theoretically, such an AI agent would know your internal policies, biases, guidelines. It would also have more knowledge about the company than any individual worker, collating data from across divisions.<p>In large corps, the silofication of knowledge is a real problem. But an AI agent trained across the company&#x27;s functions would not have this issue.</div><br/><div id="35812454" class="c"><input type="checkbox" id="c-35812454" checked=""/><div class="controls bullet"><span class="by">_glass</span><span>|</span><a href="#35812248">parent</a><span>|</span><a href="#35812706">next</a><span>|</span><label class="collapse" for="c-35812454">[-]</label><label class="expand" for="c-35812454">[1 more]</label></div><br/><div class="children"><div class="content">Especially with all of the meetings switching to virtual spaces with transcripts. This would be so powerful. When you can ask (or create documentation) based on all of those meetings. Then enriched by all of the chat messages, the company&#x27;s code. Best thing, it doesn&#x27;t even have to run in the cloud. As it looks like it can be an on-premise inference machine. The future is bright for surveillance.</div><br/></div></div><div id="35812706" class="c"><input type="checkbox" id="c-35812706" checked=""/><div class="controls bullet"><span class="by">bryanrasmussen</span><span>|</span><a href="#35812248">parent</a><span>|</span><a href="#35812454">prev</a><span>|</span><a href="#35812534">next</a><span>|</span><label class="collapse" for="c-35812706">[-]</label><label class="expand" for="c-35812706">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Theoretically, such an AI agent would know your internal... biases,<p>I think it would follow your internal biases, but would not know them. It is an interesting question as to how to train a model to identify your internal biases.</div><br/></div></div><div id="35812534" class="c"><input type="checkbox" id="c-35812534" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#35812248">parent</a><span>|</span><a href="#35812706">prev</a><span>|</span><a href="#35812732">next</a><span>|</span><label class="collapse" for="c-35812534">[-]</label><label class="expand" for="c-35812534">[3 more]</label></div><br/><div class="children"><div class="content">I know this is cynical but it’s honestly quite rare anywhere I work had anything truly important written down that’s current.<p>I know that sounds bad but it’s true, at least I my experience.<p>I think the issue here is, how do you keep this model up to date ? Maybe that’s a trivial thing to do ?</div><br/><div id="35812635" class="c"><input type="checkbox" id="c-35812635" checked=""/><div class="controls bullet"><span class="by">thefounder</span><span>|</span><a href="#35812248">root</a><span>|</span><a href="#35812534">parent</a><span>|</span><a href="#35812730">next</a><span>|</span><label class="collapse" for="c-35812635">[-]</label><label class="expand" for="c-35812635">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; how do you keep this model up to date ?<p>You could place mics everywhere. The machine will hear everything and know everything unless you whisper</div><br/></div></div><div id="35812730" class="c"><input type="checkbox" id="c-35812730" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#35812248">root</a><span>|</span><a href="#35812534">parent</a><span>|</span><a href="#35812635">prev</a><span>|</span><a href="#35812732">next</a><span>|</span><label class="collapse" for="c-35812730">[-]</label><label class="expand" for="c-35812730">[1 more]</label></div><br/><div class="children"><div class="content">Ingest Slack, Gmail, Docs, Jira, Meet, etc. on a constant, always-on basis.<p>Associate a timestamp with documents and use that to decay the importance. Assign higher importance to key policy and onboarding docs, company-wide emails, etc.<p>The PM&#x2F;EM for a team will become responsible for curating a team&#x27;s additional training data.<p>Let the system itself regularly suggest information to prune. Have an internal team analyze this and reach out to the relevant stakeholder(s) to confirm when unclear.<p>If Slack, Microsoft, and Google aren&#x27;t re-shuffling their priorities to build this right now, they&#x27;re crazy.</div><br/></div></div></div></div></div></div><div id="35812732" class="c"><input type="checkbox" id="c-35812732" checked=""/><div class="controls bullet"><span class="by">Bukhmanizer</span><span>|</span><a href="#35812248">prev</a><span>|</span><a href="#35810488">next</a><span>|</span><label class="collapse" for="c-35812732">[-]</label><label class="expand" for="c-35812732">[1 more]</label></div><br/><div class="children"><div class="content">I’ve always thought that in general, societies wants tend to expand to the limits of productivity.<p>The real danger seems to be of leadership using AI as a cudgel to threaten employees into doing what they want.</div><br/></div></div><div id="35810488" class="c"><input type="checkbox" id="c-35810488" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#35812732">prev</a><span>|</span><a href="#35810819">next</a><span>|</span><label class="collapse" for="c-35810488">[-]</label><label class="expand" for="c-35810488">[2 more]</label></div><br/><div class="children"><div class="content">This is an interesting empirical study indeed. Direct link to the study: <a href="https:&#x2F;&#x2F;www.nber.org&#x2F;papers&#x2F;w31161" rel="nofollow">https:&#x2F;&#x2F;www.nber.org&#x2F;papers&#x2F;w31161</a></div><br/></div></div><div id="35810819" class="c"><input type="checkbox" id="c-35810819" checked=""/><div class="controls bullet"><span class="by">JieJie</span><span>|</span><a href="#35810488">prev</a><span>|</span><a href="#35811070">next</a><span>|</span><label class="collapse" for="c-35810819">[-]</label><label class="expand" for="c-35810819">[7 more]</label></div><br/><div class="children"><div class="content">This wasn&#x27;t even GPT-4.<p>Terrific news.<p>It would be super cool if the people who were currently fretting about paperclips could focus a little more on bias, security, data, privacy, openness, and all the stuff we <i>actually</i> are going to have to deal with over the next five years.</div><br/><div id="35812780" class="c"><input type="checkbox" id="c-35812780" checked=""/><div class="controls bullet"><span class="by">gwd</span><span>|</span><a href="#35810819">parent</a><span>|</span><a href="#35811966">next</a><span>|</span><label class="collapse" for="c-35812780">[-]</label><label class="expand" for="c-35812780">[1 more]</label></div><br/><div class="children"><div class="content">I really don&#x27;t understand this antagonism between different branches of the &quot;AI safety&quot; community.  In the 1960&#x27;s, some people were concerned about preventing a nuclear apocalypse, and some people were concerned about lead emissions and CFCs and exploding cars.  But did the nuclear apocalypse people tell the exploding cars people they should stop their work on exploding cars because nuclear apocalypse was more important long-term?  Did the exploding car people tell the nuclear apocalypse people to stop raving about nuclear apocalypse because there were more pressing problems affecting people right now, like exploding cars and lead poisoning and a hole in the ozone layer?<p>I mean, maybe they did; but if they did then I think it was kind of silly.  Both kinds of problems are important, then and now.</div><br/></div></div><div id="35811966" class="c"><input type="checkbox" id="c-35811966" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#35810819">parent</a><span>|</span><a href="#35812780">prev</a><span>|</span><a href="#35811236">next</a><span>|</span><label class="collapse" for="c-35811966">[-]</label><label class="expand" for="c-35811966">[1 more]</label></div><br/><div class="children"><div class="content">While I reckon there&#x27;s <i>at least</i> 5 (and probably 10+) years before it&#x27;s even possible for a sufficiently independent AI to start <i>literally</i> paperclipping us (mostly because of the speed&#x2F;power needs of good image processing AI), the people who are trying to solve that don&#x27;t know if we can actually do so in even double that time frame.<p>But the paperclip scenario was only ever an illustration that the AI doesn&#x27;t need to hate us to destroy us, merely to want to use our atoms for something incompatible with our own desires.<p>For disasters to happen, there are many options which may come sooner, varying from not paying attention to what the AI is doing when it makes mistakes — the default, as we can imagine even today someone putting a Boston Dynamics Spot to work in a virology lab and it walking out with a sample because it doesn&#x27;t know any better — to the malicious, for example one idiot running a more competent version of ChaosGPT: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;g7YJIpkk7KM" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;g7YJIpkk7KM</a><p>Those other, lesser, disasters are sometimes called &quot;fire alarms for AI&quot;.</div><br/></div></div><div id="35811236" class="c"><input type="checkbox" id="c-35811236" checked=""/><div class="controls bullet"><span class="by">UnFleshedOne</span><span>|</span><a href="#35810819">parent</a><span>|</span><a href="#35811966">prev</a><span>|</span><a href="#35811670">next</a><span>|</span><label class="collapse" for="c-35811236">[-]</label><label class="expand" for="c-35811236">[1 more]</label></div><br/><div class="children"><div class="content">Why don&#x27;t you focus on that instead?</div><br/></div></div><div id="35811670" class="c"><input type="checkbox" id="c-35811670" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#35810819">parent</a><span>|</span><a href="#35811236">prev</a><span>|</span><a href="#35811070">next</a><span>|</span><label class="collapse" for="c-35811670">[-]</label><label class="expand" for="c-35811670">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It would be super cool if the people who were currently fretting about paperclips [...]<p>That&#x27;s textbook trivializing of an issue that has been extensively analyzed by experts and found to have civilization-ending consequences with near certainty, unless extensive countermeasures are taken well in advance. Your comment is the equivalent of climate change denial.</div><br/><div id="35811811" class="c"><input type="checkbox" id="c-35811811" checked=""/><div class="controls bullet"><span class="by">EamonnMR</span><span>|</span><a href="#35810819">root</a><span>|</span><a href="#35811670">parent</a><span>|</span><a href="#35811070">next</a><span>|</span><label class="collapse" for="c-35811811">[-]</label><label class="expand" for="c-35811811">[2 more]</label></div><br/><div class="children"><div class="content">Have any countermeasures actually been implemented besides blog posts and podcast appearances? Climate activists regularly disrupt traffic, glue themselves to things, and protest pipelines. By contrast folks who believe AI will end the world have a propensity to start AI companies.</div><br/><div id="35812098" class="c"><input type="checkbox" id="c-35812098" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#35810819">root</a><span>|</span><a href="#35811811">parent</a><span>|</span><a href="#35811070">next</a><span>|</span><label class="collapse" for="c-35812098">[-]</label><label class="expand" for="c-35812098">[1 more]</label></div><br/><div class="children"><div class="content">At the moment, we&#x27;re still trying to turn the question from an easy and obvious natural language form (&quot;give me what I meant to ask for&quot;) into a form that is amenable to being solved in the world of weights and biases.[0]<p>So several of the AI labs are published work on this topic, but it looks like e.g. &quot;interpretable models&quot; or philosophy of ethics etc.<p>So today we&#x27;re doing today with AI alignment research is the equivalent of asking Ada Lovelace how to prevent the Therac-25 deaths and the best response is &quot;Why would you even do that, just don&#x27;t write the wrong commands on the punched cards&quot;.<p>[0] Some, myself included, are optimistic that early AI can help us do that. Yudkowsky appears to be dismissive of all options, but I don&#x27;t see why any near-term AI would care to insert errors into later types of AI, so we&#x27;ve only got out own blind spots to look out for and we had that already…<p>…but all the AI doomers I hang out with seem to  consider me a terrible optimist, so YMMV.</div><br/></div></div></div></div></div></div></div></div><div id="35811070" class="c"><input type="checkbox" id="c-35811070" checked=""/><div class="controls bullet"><span class="by">miksumiksu</span><span>|</span><a href="#35810819">prev</a><span>|</span><a href="#35812703">next</a><span>|</span><label class="collapse" for="c-35811070">[-]</label><label class="expand" for="c-35811070">[9 more]</label></div><br/><div class="children"><div class="content">It will be interesting to see how this company is doing 5 years. It seems that thanks to the AI system novice employees are able to cash out on skilled employees knowledge. But this system might also hinder the novices changes on gaining knowledge and becoming skilled employees. And those skilled emploees are essentialto maintain this system to respond to evolving needs. So the effect on job market might be the opposite than researcher wish: recruits need to be smarter than before and the gap between low-skilled and high-skilled employees will keep widening.<p>So in that case introducing AI to this process would have the exactly same outcome as automation has had in manufacturing.</div><br/><div id="35811900" class="c"><input type="checkbox" id="c-35811900" checked=""/><div class="controls bullet"><span class="by">cosmodisk</span><span>|</span><a href="#35811070">parent</a><span>|</span><a href="#35812144">next</a><span>|</span><label class="collapse" for="c-35811900">[-]</label><label class="expand" for="c-35811900">[3 more]</label></div><br/><div class="children"><div class="content">I do agree with you. My feeling is that there will be a rise of so called super experienced users- those,who didn&#x27;t just get all the answers from the prompt but learned instead and hordes of people who won&#x27;t even know how to do basic stuff without the AI helper. The former group will be small, but extremely well rewarded,while the rest... Well, not so much..</div><br/><div id="35812253" class="c"><input type="checkbox" id="c-35812253" checked=""/><div class="controls bullet"><span class="by">somenameforme</span><span>|</span><a href="#35811070">root</a><span>|</span><a href="#35811900">parent</a><span>|</span><a href="#35812144">next</a><span>|</span><label class="collapse" for="c-35812253">[-]</label><label class="expand" for="c-35812253">[2 more]</label></div><br/><div class="children"><div class="content">It feels somewhat analogous to the calculator, except a million times more impactful because of the breadth of fields it can apply to. The times I go to a minimart type place and cashier laboriously, and slowly, whips out a calculator to determine how much change to give when paid 100 for a 32 cost item. Now imagine that analog generalized to basic knowledge and competence itself.<p>It&#x27;s kind of ironic because each one of these steps forward towards making knowledge egalitarian tends to do the exact opposite. Same thing with the internet which was going to democratize knowledge, information, education and more. And indeed it absolutely has, but 99% of people don&#x27;t take advantage of it - so the 1% just pull that many orders of magnitude further ahead.</div><br/><div id="35812447" class="c"><input type="checkbox" id="c-35812447" checked=""/><div class="controls bullet"><span class="by">shswkna</span><span>|</span><a href="#35811070">root</a><span>|</span><a href="#35812253">parent</a><span>|</span><a href="#35812144">next</a><span>|</span><label class="collapse" for="c-35812447">[-]</label><label class="expand" for="c-35812447">[1 more]</label></div><br/><div class="children"><div class="content">This perspective or line of argumentation does strike an intuitive chord with me.<p>There is a difference between being able to leverage AI to accomplish more than without it, and merely outsourcing intelligence and knowledge to the AI and effectively becoming complacent (which as you say, the 99% will end up doing).<p>My bet is on AI causing equality to worsen, unless there is a major political will to counter this with policy.<p>IMO such policies will need to provide both carrot (equalizing measures) and stick (lessening the options for the 99% to become complacent).<p>EDIT:
There is a third route that could play out. Leveraging AI or “teaming up” could be equivalent to a faustian pact, because of the nonzero possibility of AI to develop their own goals and agency.</div><br/></div></div></div></div></div></div><div id="35812144" class="c"><input type="checkbox" id="c-35812144" checked=""/><div class="controls bullet"><span class="by">euroderf</span><span>|</span><a href="#35811070">parent</a><span>|</span><a href="#35811900">prev</a><span>|</span><a href="#35811415">next</a><span>|</span><label class="collapse" for="c-35812144">[-]</label><label class="expand" for="c-35812144">[3 more]</label></div><br/><div class="children"><div class="content">If your on-the-job experience and your personal efforts for career advancement have been your capital investment in yourself, now these can be replicated for lesser-paid workers, with the surplus going to the business owner. Take a pay cut or advance your career on the front line at McD&#x27;s. Fun times!</div><br/><div id="35812329" class="c"><input type="checkbox" id="c-35812329" checked=""/><div class="controls bullet"><span class="by">spaceman_2020</span><span>|</span><a href="#35811070">root</a><span>|</span><a href="#35812144">parent</a><span>|</span><a href="#35811415">next</a><span>|</span><label class="collapse" for="c-35812329">[-]</label><label class="expand" for="c-35812329">[2 more]</label></div><br/><div class="children"><div class="content">Seems like the first jobs to be impacted will be the ones with narrow, domain specific knowledge. Like a customer support rep for a specific product line or a QA tester.<p>The safer jobs will be the ones where you have to collate knowledge from multiple fields. Like a product creator who needs to know a bit of marketing, code, and design to come up with a new idea.<p>The orchestra conductors, it seems, are safer than the pianists and cellists - for now.</div><br/><div id="35812862" class="c"><input type="checkbox" id="c-35812862" checked=""/><div class="controls bullet"><span class="by">euroderf</span><span>|</span><a href="#35811070">root</a><span>|</span><a href="#35812329">parent</a><span>|</span><a href="#35811415">next</a><span>|</span><label class="collapse" for="c-35812862">[-]</label><label class="expand" for="c-35812862">[1 more]</label></div><br/><div class="children"><div class="content">Revenge of the Generalists..</div><br/></div></div></div></div></div></div><div id="35812065" class="c"><input type="checkbox" id="c-35812065" checked=""/><div class="controls bullet"><span class="by">rlupi</span><span>|</span><a href="#35811070">parent</a><span>|</span><a href="#35811415">prev</a><span>|</span><a href="#35812703">next</a><span>|</span><label class="collapse" for="c-35812065">[-]</label><label class="expand" for="c-35812065">[1 more]</label></div><br/><div class="children"><div class="content">We are the start of a new S-curve. The current skilled employees will use their expertise to bridge the adoption of AI, bring the current use cases. The next wave of AI-native employees will build on their expertise, which we don&#x27;t have widely yet, to develop new ways of doing things that we haven&#x27;t envisioned yet and later to ease the next big paradigm shift.</div><br/></div></div></div></div><div id="35812703" class="c"><input type="checkbox" id="c-35812703" checked=""/><div class="controls bullet"><span class="by">classified</span><span>|</span><a href="#35811070">prev</a><span>|</span><a href="#35811396">next</a><span>|</span><label class="collapse" for="c-35812703">[-]</label><label class="expand" for="c-35812703">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this a bit early, and probably distorted by hype fads?</div><br/></div></div><div id="35811396" class="c"><input type="checkbox" id="c-35811396" checked=""/><div class="controls bullet"><span class="by">trojanalert</span><span>|</span><a href="#35812703">prev</a><span>|</span><label class="collapse" for="c-35811396">[-]</label><label class="expand" for="c-35811396">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be A LOT more interested to see what happens to a whole set of workers who dabble in lower-skilled jobs and are now being rendered redundant with tools such as Chat GPT.</div><br/><div id="35811416" class="c"><input type="checkbox" id="c-35811416" checked=""/><div class="controls bullet"><span class="by">iudqnolq</span><span>|</span><a href="#35811396">parent</a><span>|</span><label class="collapse" for="c-35811416">[-]</label><label class="expand" for="c-35811416">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure what you mean by dabble. Ignoring that that&#x27;s exactly what this study is.<p>They&#x27;re looking at call center employees. The author calls employees who&#x27;ve worked there for more than six months experienced.</div><br/></div></div></div></div></div></div></div></div></div></body></html>