<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1738659674228" as="style"/><link rel="stylesheet" href="styles.css?v=1738659674228"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://simonwillison.net/2025/Feb/3/a-computer-can-never-be-held-accountable/">&quot;A computer can never be held accountable&quot;</a> <span class="domain">(<a href="https://simonwillison.net">simonwillison.net</a>)</span></div><div class="subtext"><span>zdw</span> | <span>120 comments</span></div><br/><div><div id="42929842" class="c"><input type="checkbox" id="c-42929842" checked=""/><div class="controls bullet"><span class="by">_Algernon_</span><span>|</span><a href="#42924083">next</a><span>|</span><label class="collapse" for="c-42929842">[-]</label><label class="expand" for="c-42929842">[1 more]</label></div><br/><div class="children"><div class="content">The other side of this coin is that there is an incentive for decision makers to use computers, precisely to not be held accountable. This is captured pretty well by this quote by Neil Postman in <i>Technopoly</i>:<p>&gt;[B]ureaucrats can be expected to embrace a technology that helps to create the illusion that decisions are not under their control. Because of its seeming intelligence and impartiality, a computer has an almost magical tendency to direct attention away from the people in charge of bureaucratic functions and toward itself, as if the computer were the true source of authority. A bureaucrat armed with a computer is the unacknowledged legislator of our age, and a terrible burden to bear. We cannot dismiss the possibility that, if Adolf Eichmann had been able to say that it was not he but a battery of computers that directed the Jews to the appropriate crematoria, he might never have been asked to answer for his actions.<p>How does one counteract that self-serving incentive? Doesn&#x27;t seem like we&#x27;ve found a good way considering we seem to be spearheading straight into techno-feudalism.</div><br/></div></div><div id="42924083" class="c"><input type="checkbox" id="c-42924083" checked=""/><div class="controls bullet"><span class="by">rzzzt</span><span>|</span><a href="#42929842">prev</a><span>|</span><a href="#42924028">next</a><span>|</span><label class="collapse" for="c-42924083">[-]</label><label class="expand" for="c-42924083">[5 more]</label></div><br/><div class="children"><div class="content">What does the backside say? I can make out the title at the bottom: &quot;THE COMPUTER MANDATE&quot;, but not much else.</div><br/><div id="42924205" class="c"><input type="checkbox" id="c-42924205" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#42924083">parent</a><span>|</span><a href="#42924288">next</a><span>|</span><label class="collapse" for="c-42924205">[-]</label><label class="expand" for="c-42924205">[1 more]</label></div><br/><div class="children"><div class="content">Others have tried to figure out exactly what actual paperwork that particular image might be from (e.g. a memo or presentation flashcards) but AFAIK it&#x27;s still inconclusive.<p>A plausible transcription:<p>&gt; THE COMPUTER MANDATE<p>&gt; AUTHORITY: WHATEVER AUTHORITY IS GRANTED IT BY THE SOCIAL ENVIRONMENT WITHIN WHICH IT OPERATES.<p>&gt; RESPONSIBILITY: TO PERFORM AS PRE-DIRECTED BY THE PROGRAMMER WHENEVER INSTRUCTED TO DO SO<p>&gt; ACCOUNTABILITY: NONE WHATSOEVER.</div><br/></div></div><div id="42924288" class="c"><input type="checkbox" id="c-42924288" checked=""/><div class="controls bullet"><span class="by">shakna</span><span>|</span><a href="#42924083">parent</a><span>|</span><a href="#42924205">prev</a><span>|</span><a href="#42924646">next</a><span>|</span><label class="collapse" for="c-42924288">[-]</label><label class="expand" for="c-42924288">[1 more]</label></div><br/><div class="children"><div class="content">The first word of the paragraph appears to be, &quot;authority&quot;.<p>I can&#x27;t quite make out the first paragraph, contents.<p>But a bit after that comes under another semi-title &quot;responsibility&quot; and part of it reads:<p>&gt; TO PERFORM AS PRE-DIRECTED BY THE PROGRAMMER WHENEVER INSTRUCTED TO DO SO<p>This [0] small link might make it easier to read bits.<p>[0] <a href="https:&#x2F;&#x2F;imgur.com&#x2F;rnW2RJa" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;rnW2RJa</a></div><br/></div></div><div id="42924646" class="c"><input type="checkbox" id="c-42924646" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42924083">parent</a><span>|</span><a href="#42924288">prev</a><span>|</span><a href="#42924028">next</a><span>|</span><label class="collapse" for="c-42924646">[-]</label><label class="expand" for="c-42924646">[2 more]</label></div><br/><div class="children"><div class="content">See: <a href="https:&#x2F;&#x2F;mastodon.social&#x2F;@mhoye&#x2F;112459155499812117" rel="nofollow">https:&#x2F;&#x2F;mastodon.social&#x2F;@mhoye&#x2F;112459155499812117</a><p>Which also links to the earlier: <a href="https:&#x2F;&#x2F;infosec.exchange&#x2F;@realn2s&#x2F;111717179694172705" rel="nofollow">https:&#x2F;&#x2F;infosec.exchange&#x2F;@realn2s&#x2F;111717179694172705</a><p>And that in turn to the somewhat related: <a href="https:&#x2F;&#x2F;www.ibm.com&#x2F;blogs&#x2F;think&#x2F;be-en&#x2F;2013&#x2F;11&#x2F;25&#x2F;the-computer-as-an-advisor-not-a-decision-maker-the-vision-of-ibm-fellow-john-cohn&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.ibm.com&#x2F;blogs&#x2F;think&#x2F;be-en&#x2F;2013&#x2F;11&#x2F;25&#x2F;the-compute...</a></div><br/><div id="42928881" class="c"><input type="checkbox" id="c-42928881" checked=""/><div class="controls bullet"><span class="by">rzzzt</span><span>|</span><a href="#42924083">root</a><span>|</span><a href="#42924646">parent</a><span>|</span><a href="#42924028">next</a><span>|</span><label class="collapse" for="c-42928881">[-]</label><label class="expand" for="c-42928881">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the link. So most of the visible pages were deciphered!</div><br/></div></div></div></div></div></div><div id="42924028" class="c"><input type="checkbox" id="c-42924028" checked=""/><div class="controls bullet"><span class="by">a3w</span><span>|</span><a href="#42924083">prev</a><span>|</span><a href="#42926473">next</a><span>|</span><label class="collapse" for="c-42924028">[-]</label><label class="expand" for="c-42924028">[1 more]</label></div><br/><div class="children"><div class="content">Wisdom from &#x27;79!<p>Could also be wisdom from the fifties, found again.</div><br/></div></div><div id="42926473" class="c"><input type="checkbox" id="c-42926473" checked=""/><div class="controls bullet"><span class="by">1vuio0pswjnm7</span><span>|</span><a href="#42924028">prev</a><span>|</span><a href="#42924173">next</a><span>|</span><label class="collapse" for="c-42926473">[-]</label><label class="expand" for="c-42926473">[1 more]</label></div><br/><div class="children"><div class="content">But a software developer can be held accountable.</div><br/></div></div><div id="42924173" class="c"><input type="checkbox" id="c-42924173" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#42926473">prev</a><span>|</span><a href="#42924566">next</a><span>|</span><label class="collapse" for="c-42924173">[-]</label><label class="expand" for="c-42924173">[8 more]</label></div><br/><div class="children"><div class="content">there&#x27;s the old joke<p><i>&quot;It should be noted that no ethically-trained software engineer would ever consent to write a DestroyBaghdad procedure. Basic professional ethics would instead require him to write a DestroyCity procedure, to which Baghdad could be given as a parameter.&quot;</i><p>Removing yourself to one or more degrees from decision making isn&#x27;t only an accident but is and will more and more be done to intentionally divert accountability. &quot;The algorithm malfunctioned&quot; is already one of the biggest get out of jail free cards and with autonomous systems I&#x27;m pretty pessimistic it&#x27;s only going to get worse. It&#x27;s always been odd to me that people focus so much on what broke and not who deployed it in the first place.</div><br/><div id="42924252" class="c"><input type="checkbox" id="c-42924252" checked=""/><div class="controls bullet"><span class="by">miltonlost</span><span>|</span><a href="#42924173">parent</a><span>|</span><a href="#42924566">next</a><span>|</span><label class="collapse" for="c-42924252">[-]</label><label class="expand" for="c-42924252">[7 more]</label></div><br/><div class="children"><div class="content">It’s why I could never work at Meta, knowing how much I would feel responsible in aiding various genocides around the world. How any engineer there is able to ethically live with themselves is beyond me (but I also don’t make that Meta money)</div><br/><div id="42924583" class="c"><input type="checkbox" id="c-42924583" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#42924173">root</a><span>|</span><a href="#42924252">parent</a><span>|</span><a href="#42924618">next</a><span>|</span><label class="collapse" for="c-42924583">[-]</label><label class="expand" for="c-42924583">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been getting cold-emails from them lately, and I&#x27;ve been toying with the idea of regretfully informing them that I don&#x27;t think I could bring of enough of the &quot;Masculine Energy&quot; their CEO has been talking about.</div><br/></div></div><div id="42924618" class="c"><input type="checkbox" id="c-42924618" checked=""/><div class="controls bullet"><span class="by">DaSHacka</span><span>|</span><a href="#42924173">root</a><span>|</span><a href="#42924252">parent</a><span>|</span><a href="#42924583">prev</a><span>|</span><a href="#42925202">next</a><span>|</span><label class="collapse" for="c-42924618">[-]</label><label class="expand" for="c-42924618">[4 more]</label></div><br/><div class="children"><div class="content">Arguably, depending on your country, paying your taxes is significantly worse...</div><br/><div id="42924741" class="c"><input type="checkbox" id="c-42924741" checked=""/><div class="controls bullet"><span class="by">miltonlost</span><span>|</span><a href="#42924173">root</a><span>|</span><a href="#42924618">parent</a><span>|</span><a href="#42925202">next</a><span>|</span><label class="collapse" for="c-42924741">[-]</label><label class="expand" for="c-42924741">[3 more]</label></div><br/><div class="children"><div class="content">Yes, this thing I MUST DO if I don&#x27;t want to go to jail, is somehow worse than voluntarily working for a private company. Yes, we do live in a society.</div><br/><div id="42924919" class="c"><input type="checkbox" id="c-42924919" checked=""/><div class="controls bullet"><span class="by">DaSHacka</span><span>|</span><a href="#42924173">root</a><span>|</span><a href="#42924741">parent</a><span>|</span><a href="#42925202">next</a><span>|</span><label class="collapse" for="c-42924919">[-]</label><label class="expand" for="c-42924919">[2 more]</label></div><br/><div class="children"><div class="content">Aw shucks, too bad we gotta fund genocide on our dime. Wouldn&#x27;t wanna go to jail, after all.<p>At least we can boycott the company with a CEO that... likes trump and Joe Rogan? That&#x27;ll show &#x27;em!<p>How can those Meta workers live with themselves? Just think of all the AI-slop cat videos the algorithm recommends to their geriatric userbase!<p>That&#x27;s the _real_ genocide, I say.</div><br/><div id="42929722" class="c"><input type="checkbox" id="c-42929722" checked=""/><div class="controls bullet"><span class="by">tempfile</span><span>|</span><a href="#42924173">root</a><span>|</span><a href="#42924919">parent</a><span>|</span><a href="#42925202">next</a><span>|</span><label class="collapse" for="c-42929722">[-]</label><label class="expand" for="c-42929722">[1 more]</label></div><br/><div class="children"><div class="content">Is &quot;likes&quot; the new euphemism for &quot;gives millions of dollars&quot;?<p>You do presumably realise that when they imprison you for refusing to pay your taxes, they take the money anyway? I am wondering whether you thought about this comment at all before posting it.</div><br/></div></div></div></div></div></div></div></div><div id="42925202" class="c"><input type="checkbox" id="c-42925202" checked=""/><div class="controls bullet"><span class="by">wombatpm</span><span>|</span><a href="#42924173">root</a><span>|</span><a href="#42924252">parent</a><span>|</span><a href="#42924618">prev</a><span>|</span><a href="#42924566">next</a><span>|</span><label class="collapse" for="c-42925202">[-]</label><label class="expand" for="c-42925202">[1 more]</label></div><br/><div class="children"><div class="content">RSU’s can be very comforting.</div><br/></div></div></div></div></div></div><div id="42924566" class="c"><input type="checkbox" id="c-42924566" checked=""/><div class="controls bullet"><span class="by">hosh</span><span>|</span><a href="#42924173">prev</a><span>|</span><a href="#42924308">next</a><span>|</span><label class="collapse" for="c-42924566">[-]</label><label class="expand" for="c-42924566">[1 more]</label></div><br/><div class="children"><div class="content">A description of Promise Theory, in an article published in the Linux Journal in 2014:<p>&quot;IT installations grow to massive size in data centers, and the idea of remote command and control, by an external manager, struggles to keep pace, because it is an essentially manual human-centric activity. Thankfully, a simple way out of this dilemma was proposed in 2005 and has acquired a growing band of disciples in computing and networking. This involves the harnessing of autonomous distributed agents.&quot; (<a href="https:&#x2F;&#x2F;www.linuxjournal.com&#x2F;content&#x2F;promise-theory%E2%80%94what-it" rel="nofollow">https:&#x2F;&#x2F;www.linuxjournal.com&#x2F;content&#x2F;promise-theory%E2%80%94...</a>)<p>What are autonomous agents in promise theory?<p>&quot;Agents in promise theory are said to be autonomous, meaning that they are causally independent of one another. This independence implies that they cannot be controlled from without, they originate their own behaviours entirely from within, yet they can rely on one another&#x27;s services through the making of promises to signal cooperation.&quot; (<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Promise_theory#Agents" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Promise_theory#Agents</a>)<p>Note: the wikipedia article is off because it is framing agents in terms of obligations instead of promises. Promises make no guarantee of behavior, and it is up each autonomous agent to decide how much it can rely on the promises of other autonomous agents.<p>So to circle back to this original post with the lens of Promise Theory -- being held accountable comes from a theory of obligations rather than a theory of promises. (There is a promise made by the governing body to hold the bad actor responsible). More crucially, we are treating AIs as _proxies_ for autonomous agents -- humans. Human engineers and potentially, regulatory bodies, are promising certain performances in the AIs, but the AIs have exceeded the engineer&#x27;s capability for bounding behaviors.<p>To make that next leap, we would be basically having AIs make their own promises, and either holding them to them to it, or consider that that specific autonomous agent is not reliable in their promises.</div><br/></div></div><div id="42924308" class="c"><input type="checkbox" id="c-42924308" checked=""/><div class="controls bullet"><span class="by">gwern</span><span>|</span><a href="#42924566">prev</a><span>|</span><a href="#42924071">next</a><span>|</span><label class="collapse" for="c-42924308">[-]</label><label class="expand" for="c-42924308">[3 more]</label></div><br/><div class="children"><div class="content">I would suggest an updated version, more germane to the current fast-developing landscape of AI agents:<p><pre><code>    A COMPUTER CAN NEVER BE HELD ACCOUNTABLE

    THEREFORE WE MUST NEVER DENY THAT

    COMPUTERS CAN MAKE DECISIONS</code></pre></div><br/><div id="42924345" class="c"><input type="checkbox" id="c-42924345" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#42924308">parent</a><span>|</span><a href="#42924071">next</a><span>|</span><label class="collapse" for="c-42924345">[-]</label><label class="expand" for="c-42924345">[2 more]</label></div><br/><div class="children"><div class="content">I disagree, that&#x27;s throwing away the 1979-era qualifier of <i>management</i> decision, as distinct from the decisions made by an hourly employee (or computer) following a pre-made checklist (or program.) It&#x27;s not the same as FizzBuzz &quot;deciding&quot; to print something out.<p>Related qualifiers might be &quot;policy decision&quot; or &quot;design decisions&quot;.</div><br/><div id="42927538" class="c"><input type="checkbox" id="c-42927538" checked=""/><div class="controls bullet"><span class="by">gwern</span><span>|</span><a href="#42924308">root</a><span>|</span><a href="#42924345">parent</a><span>|</span><a href="#42924071">next</a><span>|</span><label class="collapse" for="c-42927538">[-]</label><label class="expand" for="c-42927538">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s precisely the attitude that is the problem. That there&#x27;s some special category of decisions which are the <i>real</i> decisions. Which is why it&#x27;s an uncategorical statement.</div><br/></div></div></div></div></div></div><div id="42924071" class="c"><input type="checkbox" id="c-42924071" checked=""/><div class="controls bullet"><span class="by">etaioinshrdlu</span><span>|</span><a href="#42924308">prev</a><span>|</span><a href="#42924290">next</a><span>|</span><label class="collapse" for="c-42924071">[-]</label><label class="expand" for="c-42924071">[1 more]</label></div><br/><div class="children"><div class="content">I suspect within our lifetimes people will grant AI and robots rights, but with rights come responsibilities, and finally we will be able to hold the computer accountable!</div><br/></div></div><div id="42924290" class="c"><input type="checkbox" id="c-42924290" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924071">prev</a><span>|</span><a href="#42924115">next</a><span>|</span><label class="collapse" for="c-42924290">[-]</label><label class="expand" for="c-42924290">[23 more]</label></div><br/><div class="children"><div class="content">I confess this line always upset me.  It is cute, but it directly points to the idea that the main recourse for a mistake is to take umbridge with an individual that must have obviously been wrong.<p>No.  If a mistake is made and it impacts people, take action to make the impacted people whole and change the system so that a similar mistake won&#x27;t be made again.  If you want, you can argue that the system can be held accountable and changed.<p>Further, if there is evidence of a bad actor that is purposely making choices that hurt people.  Take action on that.  But accountability of actors in the system is almost certainly immune by policy.  And for good reason.</div><br/><div id="42924339" class="c"><input type="checkbox" id="c-42924339" checked=""/><div class="controls bullet"><span class="by">miltonlost</span><span>|</span><a href="#42924290">parent</a><span>|</span><a href="#42924486">next</a><span>|</span><label class="collapse" for="c-42924339">[-]</label><label class="expand" for="c-42924339">[11 more]</label></div><br/><div class="children"><div class="content">A system!!! Held accountable!!!! A system, just like a computer, cannot be held accountable for the reason that a system, as like a computer, is not alive and cannot actual be held accountable in a way that the system or computer cares.<p>But what is a system made of? People who are doing bad decisions and should be held accountable for that. Without accountability of bad actors in systems, you get companies committing crimes because no one at the top rarely sees fines or jail time. The same immunity from responsibility you think is a good thing in a system is what I would say is corporate america’s major sin.<p>You’re upset at the line because you make a fundamental misunderstanding of what it means for someone to be held accountable for something.</div><br/><div id="42924450" class="c"><input type="checkbox" id="c-42924450" checked=""/><div class="controls bullet"><span class="by">coliveira</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924339">parent</a><span>|</span><a href="#42924571">next</a><span>|</span><label class="collapse" for="c-42924450">[-]</label><label class="expand" for="c-42924450">[3 more]</label></div><br/><div class="children"><div class="content">This hits the nail on the head. The issue is that humans are accountable, but systems are not. And smart humans learned how to hide behind systems to avoid accountability. That&#x27;s the whole strategy of using corporations, a social structure that removes individuals from responsibility. A corporation can do pretty much anything, including criminal acts, and the humans benefiting from it are shield from the negative results except for financial losses. What we&#x27;re seeing is just the whole strategy moving into the level of computer systems (and Google has already used this accountability skirting strategy for more than two decades).</div><br/><div id="42924617" class="c"><input type="checkbox" id="c-42924617" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924450">parent</a><span>|</span><a href="#42924571">next</a><span>|</span><label class="collapse" for="c-42924617">[-]</label><label class="expand" for="c-42924617">[2 more]</label></div><br/><div class="children"><div class="content">The problem you will quickly run into is individuals cannot take the load that this line of thinking leads to.  Accidentally typo an extra 0 on a payment process?  Hope you have the funds to take accountability on that mistake.  After all, we have taken the choice that the system cannot be operated to rollback any choice, as that would lower human accountability...</div><br/><div id="42929859" class="c"><input type="checkbox" id="c-42929859" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924617">parent</a><span>|</span><a href="#42924571">next</a><span>|</span><label class="collapse" for="c-42929859">[-]</label><label class="expand" for="c-42929859">[1 more]</label></div><br/><div class="children"><div class="content">Then that person should have the right to refuse or ask for appropriate compensation. It&#x27;s often argued here that the C-suite earns their high compensation by taking on those risks. So let the CFO fatfinger those unchecked transfers if he wishes.<p>But if rollbacks are possible and cheap then we don&#x27;t need accountability. People want accountability when there&#x27;s no rollback possible, e.g. when decisions leads to deaths or life-years wasted.</div><br/></div></div></div></div></div></div><div id="42924571" class="c"><input type="checkbox" id="c-42924571" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924339">parent</a><span>|</span><a href="#42924450">prev</a><span>|</span><a href="#42924486">next</a><span>|</span><label class="collapse" for="c-42924571">[-]</label><label class="expand" for="c-42924571">[7 more]</label></div><br/><div class="children"><div class="content">But your reading presumes that you would hold individuals responsible in a company for something that goes wrong.  Which, without showing intent on individual actors, feels very very unlikely.  Both in actuality, and in desire.<p>Consider, if it is found that salmonella contaminated the spinach of a local farm, I want it recalled and for better systems in place to catch contamination.  I don&#x27;t want to find the farmer that was responsible for the acre of land that introduced the contaminant.<p>I think this idea flows from some thought that people will put more effort into things that they think they could be held accountable for.  In reality, that just isn&#x27;t the case.  People will instead stall and stall on things they think they could be held accountable on if things go south.<p>From my vantage, that style of &quot;accountability&quot; just leads to more and more red tape as you do what you can to line item identify who could have prevented something.  That is not productive.</div><br/><div id="42924998" class="c"><input type="checkbox" id="c-42924998" checked=""/><div class="controls bullet"><span class="by">isityouyesitsme</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924571">parent</a><span>|</span><a href="#42924700">next</a><span>|</span><label class="collapse" for="c-42924998">[-]</label><label class="expand" for="c-42924998">[4 more]</label></div><br/><div class="children"><div class="content">You do not need intent to find fault and have standing. Negligence is a thing.<p>If your farmer chose to ignore industry standard practices and agricultural regulations to prevent and contain such contamination at the source, they are indeed liable. And they can still issue a recall, and indeed must do so as soon as they learn of the problem.<p>Your vantage point is a bit too optimistic for reality. If it was not, we would not need courts.</div><br/><div id="42925056" class="c"><input type="checkbox" id="c-42925056" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924998">parent</a><span>|</span><a href="#42924700">next</a><span>|</span><label class="collapse" for="c-42925056">[-]</label><label class="expand" for="c-42925056">[3 more]</label></div><br/><div class="children"><div class="content">Fair that negligence would be a legally separate thing than &quot;at-fault.&quot;  I&#x27;m using the colloquial use of the terms here, for somewhat obvious reasons.<p>For my example, assume no knowledge of extra risk by anyone on the line.  If you&#x27;d rather, consider the cashier at the local burrito shop that was the final non-consumer hand to touch the contaminated food.</div><br/><div id="42925209" class="c"><input type="checkbox" id="c-42925209" checked=""/><div class="controls bullet"><span class="by">isityouyesitsme</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42925056">parent</a><span>|</span><a href="#42924700">next</a><span>|</span><label class="collapse" for="c-42925209">[-]</label><label class="expand" for="c-42925209">[2 more]</label></div><br/><div class="children"><div class="content">I think I am closer to understanding you, but not quite there.<p>If, for instance, your burrito worker did something egregious, they could be held criminally liable, and depending on the specific situation, the employer could also be held civilly liable.<p>I say &quot;depending on the situation&quot; because it is the duty of the vendor to ensure best practices are followed: sanitary restrooms, soap and running, clean water for cleaning up, etc. And a nontrivial number of places do so because they know an inspector is coming at some point and they will suffer if they do not comply.<p>But it is harder to hold the vendor liable if all reasonable precautions and amenities are availed by the vendor, and all proper education, but the end of line worker decides to ignore all of it one day.</div><br/><div id="42925344" class="c"><input type="checkbox" id="c-42925344" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42925209">parent</a><span>|</span><a href="#42924700">next</a><span>|</span><label class="collapse" for="c-42925344">[-]</label><label class="expand" for="c-42925344">[1 more]</label></div><br/><div class="children"><div class="content">If someone does something specifically with knowledge that it is likely to cause harm, there should almost certainly be recourse there.  Yes.<p>If they did something that was a standard part of their duty, such as assemble a burrito using certified ingredients to the best practices of the organization, then not so much.<p>I&#x27;ll go even further, if the company reacted slowly to recall produce from their shelves after it was discovered that there was contamination, then the company should be held liable for some of the damages that resulted from the delay.<p>That gets obviously complicated to tease out damages that happened from before discovery.  More, to me, I care more about healing the people that were impacted by the contamination as well as possible.  If that means that we have to have a cost of business fund to make sure people can be attended to in the event of a disaster, then we should have such a fund.<p>You can get even more fun, though.  Lets say you have a detection system that can reject produce if a threshold is passed on detected contamination.  Why would the goal not be for this to fail in a &quot;closed&quot; position to minimize risk of contamination?  It could cost more for the company to discard some inventory?  Do we expect to have everything hand inspected and always signed off by a person?  Even if it can easily be shown that is both more expensive for the company, and more risk of accidental contamination?</div><br/></div></div></div></div></div></div></div></div><div id="42924700" class="c"><input type="checkbox" id="c-42924700" checked=""/><div class="controls bullet"><span class="by">miltonlost</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924571">parent</a><span>|</span><a href="#42924998">prev</a><span>|</span><a href="#42924486">next</a><span>|</span><label class="collapse" for="c-42924700">[-]</label><label class="expand" for="c-42924700">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Consider, if it is found that salmonella contaminated the spinach of a local farm, I want it recalled and for better systems in place to catch contamination. I don&#x27;t want to find the farmer that was responsible for the acre of land that introduced the contaminant.<p>Wow a local farm!!!! We must think of the plight of the local farmer! And not the multinational corporations!<p>Consider, if it is found that listeria contaminated the meat of a national Chain, Boar&#x27;s Head, I want it recalled and for better systems in place to catch contamination.  I also want the plant manager and executives who allowed for the massively unsanitary state to continue for years.<p><a href="https:&#x2F;&#x2F;arstechnica.com&#x2F;science&#x2F;2024&#x2F;09&#x2F;10th-person-dead-in-listeria-outbreak-linked-to-boars-head-meats&#x2F;" rel="nofollow">https:&#x2F;&#x2F;arstechnica.com&#x2F;science&#x2F;2024&#x2F;09&#x2F;10th-person-dead-in-...</a><p>The way you&#x27;re talking , we should be going back to pre-Upton Sinclair The Jungle and letting our food run full of contaminants because why make any one person accountable for their willful addition of sawdust to their flour?</div><br/><div id="42924767" class="c"><input type="checkbox" id="c-42924767" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924700">parent</a><span>|</span><a href="#42924486">next</a><span>|</span><label class="collapse" for="c-42924767">[-]</label><label class="expand" for="c-42924767">[1 more]</label></div><br/><div class="children"><div class="content">If there is provable negligence on the plant manager for allowing it, I&#x27;m game for them getting in trouble.  My point was more that there are a TON of individuals that can each be shown to have done something specific to spread the problem.  We don&#x27;t hold them accountable.  By design.<p>Now, I&#x27;m all for more directly holding companies responsible.  Such that I think they probably deserve less protections than they almost certainly have here.  But that is a different thing and, again, is unrelated to &quot;a person taking accountability.&quot;</div><br/></div></div></div></div></div></div></div></div><div id="42924486" class="c"><input type="checkbox" id="c-42924486" checked=""/><div class="controls bullet"><span class="by">landryraccoon</span><span>|</span><a href="#42924290">parent</a><span>|</span><a href="#42924339">prev</a><span>|</span><a href="#42924648">next</a><span>|</span><label class="collapse" for="c-42924486">[-]</label><label class="expand" for="c-42924486">[2 more]</label></div><br/><div class="children"><div class="content">Fwiw I agree with you.<p>I feel that in general people obsess over assigning blame to the detriment of actually correcting the situation.<p>Take the example of punishing crimes. If we don’t punish theft, we’ll get more theft right? But what do you do when you have harsh penalties for crime, but crime keeps happening? Do you accept crime as immutable, or actually begin to address root causes to try to reduce crime systemically?<p>Punishment is only one tool in a toolbox for correcting bad behavior. I am dismayed that people are fearful enough of the loss of this single tool as to want to architect our entire society around making sure it is available.<p>With AI we have a chance to chart a different course. If a machine makes a mistake, the priority can and should be fixing the error in that machine so the same mistake can never happen again. In this way, fixing an AI can be more reliable than trying to punish human beings ever could.</div><br/><div id="42924649" class="c"><input type="checkbox" id="c-42924649" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924486">parent</a><span>|</span><a href="#42924648">next</a><span>|</span><label class="collapse" for="c-42924649">[-]</label><label class="expand" for="c-42924649">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m always hesitant to enter &quot;punishing crimes&quot; discussions on this one.  Those, by definition, establish intent to commit the crime in a majority of cases.  As such, they would almost certainly hit some &quot;accountability&quot; even if they were in a company.  Heck, even qualified immunity for government actors typically falls on that.<p>That said, I do think we are in alignment here.  Punitive actions are but a tool.  I don&#x27;t think it should be tossed out.  But I also suspect it is one of the lesser effective tools we have.</div><br/></div></div></div></div><div id="42924648" class="c"><input type="checkbox" id="c-42924648" checked=""/><div class="controls bullet"><span class="by">michael1999</span><span>|</span><a href="#42924290">parent</a><span>|</span><a href="#42924486">prev</a><span>|</span><a href="#42924406">next</a><span>|</span><label class="collapse" for="c-42924648">[-]</label><label class="expand" for="c-42924648">[4 more]</label></div><br/><div class="children"><div class="content">You have to remember what &quot;calling to account&quot; is.  It is a demand that you explain yourself.  In the case of a business venture, it means to present the books and detail the entries.  A court, congress, or your boss can demand your presence at a meeting to &quot;explain  yourself&quot;.  Accountability doesn&#x27;t mean punishment, it means you are subject to demands to make an &quot;account&quot; of your self.  Punishment is a separate thing from the account.<p>If your account implicates yourself in malfeasance, you might be punished.  But that&#x27;s good!.  But there are other kinds of accountability.  The FAA is very clear that you must make an accounting for yourself.  But the FAA is also very clear that they won&#x27;t punish you for your account.  That doesn&#x27;t mean you aren&#x27;t accountable!<p>Most computer systems can not do this!  They can not describe the inputs to a decision, the criteria used, the history of policy that led to the current configuration, or the reliability of the data.  That&#x27;s why lawsuits always have to have technical witnesses to do these things.  And why the UK Postal scandal was so cruel.<p>Systems that grant actors immunity from accountability as a matter of policy are terrible systems that produce terrible results.  Witness US prosecutorial immunity.</div><br/><div id="42924740" class="c"><input type="checkbox" id="c-42924740" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924648">parent</a><span>|</span><a href="#42924406">next</a><span>|</span><label class="collapse" for="c-42924740">[-]</label><label class="expand" for="c-42924740">[3 more]</label></div><br/><div class="children"><div class="content">But, in that regard, systems can be made such that they can, in fact, be held accountable?  You can design them such that they can list their inputs and why the outputs were set to what they are.<p>With the speed at which systems operate today, it is actually expected for many systems that they can operate before a person does anything, and that they do so.  The world is rife with examples where humans overrode a safety system to their peril.  (I can build a small list, if needed.)  This doesn&#x27;t mean we haven&#x27;t had safety systems mess up.  But nor does it mean that we should not make more safety systems.</div><br/><div id="42924893" class="c"><input type="checkbox" id="c-42924893" checked=""/><div class="controls bullet"><span class="by">michael1999</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924740">parent</a><span>|</span><a href="#42924406">next</a><span>|</span><label class="collapse" for="c-42924893">[-]</label><label class="expand" for="c-42924893">[2 more]</label></div><br/><div class="children"><div class="content">Yes.  Some systems can be made more accountable.  They can provide traceability from their inputs to output, provide reflexive access to source code they run, and provide evidentiary traces for reliability.<p>Safety critical systems that operate faster than human reactions are not accountable.  So that&#x27;s why we never make them responsible.  So who is?  Same as for bridges that fall down -- the engineers.  People forget that civil engineers sign up for accountability that could lead to serious civil or even criminal liability.  Which is exactly the point of this aphorism.<p>Boeing was facing criminal charges, and is currently under a consent decree for exactly this kind of sloppy systems work.</div><br/><div id="42925017" class="c"><input type="checkbox" id="c-42925017" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924893">parent</a><span>|</span><a href="#42924406">next</a><span>|</span><label class="collapse" for="c-42925017">[-]</label><label class="expand" for="c-42925017">[1 more]</label></div><br/><div class="children"><div class="content">I can agree that there is a lot of lifting for &quot;management decision&quot; on the page, but my point is pretty strictly that it is overstated.  I&#x27;m largely used to this getting discussed much more generically.<p>That is, just as I am ok with AES on cars, I am largely ok with the idea that systems can, in fact, be designed in such a way that they could rise to the level of accountability that we would want them to have.<p>I&#x27;m ok with the idea that, at the time of that manual, it was not obvious that systems would grow to have more durable storage than makes sense.  But, I&#x27;d expect that vehicles and anything with automated systems should have a system log that is available and can be called up for evidence.<p>And yes, Boeing was facing criminal charges.  As they should.  I don&#x27;t think it should be a witch hunt for individuals at Boeing for being the last or first on the line to sign something.</div><br/></div></div></div></div></div></div></div></div><div id="42924406" class="c"><input type="checkbox" id="c-42924406" checked=""/><div class="controls bullet"><span class="by">Handprint4469</span><span>|</span><a href="#42924290">parent</a><span>|</span><a href="#42924648">prev</a><span>|</span><a href="#42924440">next</a><span>|</span><label class="collapse" for="c-42924406">[-]</label><label class="expand" for="c-42924406">[2 more]</label></div><br/><div class="children"><div class="content">I disagree. The main point of this line is not about what to do _after_ a mistake (assign blame, punish, etc), but rather about setting up the correct incentives _before_ anything happens so that a mistake is less likely.<p>When you&#x27;re accountable you suddenly have skin in the game, so you&#x27;ll be more careful about whatever you&#x27;re doing.</div><br/><div id="42924680" class="c"><input type="checkbox" id="c-42924680" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924406">parent</a><span>|</span><a href="#42924440">next</a><span>|</span><label class="collapse" for="c-42924680">[-]</label><label class="expand" for="c-42924680">[1 more]</label></div><br/><div class="children"><div class="content">Right, I guessed this is what people had in mind.  I&#x27;ll note that this line of thinking typically doesn&#x27;t get better results.  It largely just gets more &quot;red tape&quot; so that you have to get people to sign off on things.  And the person that shows up to do something will have all of their red tape in order so that they are not responsible for any damages that result from carrying out their job.<p>Agreed that personal responsibility is important and people should strive to it more.  Disagree that accountability is the same thing, or that you can implement it by policy.  Still more strongly disagreed that you should look for a technical solution to what is largely not a technical problem.</div><br/></div></div></div></div><div id="42924440" class="c"><input type="checkbox" id="c-42924440" checked=""/><div class="controls bullet"><span class="by">medhir</span><span>|</span><a href="#42924290">parent</a><span>|</span><a href="#42924406">prev</a><span>|</span><a href="#42924115">next</a><span>|</span><label class="collapse" for="c-42924440">[-]</label><label class="expand" for="c-42924440">[3 more]</label></div><br/><div class="children"><div class="content">so if someone makes a change to the system… there’s a <i>person</i> somewhere holding themselves accountable for the faults of the system, no?</div><br/><div id="42924489" class="c"><input type="checkbox" id="c-42924489" checked=""/><div class="controls bullet"><span class="by">coliveira</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924440">parent</a><span>|</span><a href="#42924115">next</a><span>|</span><label class="collapse" for="c-42924489">[-]</label><label class="expand" for="c-42924489">[2 more]</label></div><br/><div class="children"><div class="content">No, if there are multiple people who in principle are not directly coordinated to make that happen. They can always point the finger at others and say they&#x27;re not responsible for that bad outcome.</div><br/><div id="42924588" class="c"><input type="checkbox" id="c-42924588" checked=""/><div class="controls bullet"><span class="by">taeric</span><span>|</span><a href="#42924290">root</a><span>|</span><a href="#42924489">parent</a><span>|</span><a href="#42924115">next</a><span>|</span><label class="collapse" for="c-42924588">[-]</label><label class="expand" for="c-42924588">[1 more]</label></div><br/><div class="children"><div class="content">Exactly.  And this is a direct consequence of trying to pin things on individuals.</div><br/></div></div></div></div></div></div></div></div><div id="42924115" class="c"><input type="checkbox" id="c-42924115" checked=""/><div class="controls bullet"><span class="by">ysofunny</span><span>|</span><a href="#42924290">prev</a><span>|</span><a href="#42924102">next</a><span>|</span><label class="collapse" for="c-42924115">[-]</label><label class="expand" for="c-42924115">[1 more]</label></div><br/><div class="children"><div class="content">so then, neither can a crowd. not anymore, a crowd will be able to blame a computer now</div><br/></div></div><div id="42924102" class="c"><input type="checkbox" id="c-42924102" checked=""/><div class="controls bullet"><span class="by">canterburry</span><span>|</span><a href="#42924115">prev</a><span>|</span><a href="#42924319">next</a><span>|</span><label class="collapse" for="c-42924102">[-]</label><label class="expand" for="c-42924102">[18 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t accountability simply to prevent repeat bad behavior in the future...or is it meant to be punitive without any other expectations?<p>If meant to prevent repeat bad behavior, then simply reprogramming the computer accomplished the same end goal.<p>Accountability is really just a means to an end which can be similarly accomplished in other ways with machines which isn&#x27;t possible with humans.</div><br/><div id="42924136" class="c"><input type="checkbox" id="c-42924136" checked=""/><div class="controls bullet"><span class="by">brap</span><span>|</span><a href="#42924102">parent</a><span>|</span><a href="#42924148">next</a><span>|</span><label class="collapse" for="c-42924136">[-]</label><label class="expand" for="c-42924136">[1 more]</label></div><br/><div class="children"><div class="content">Right, but as long as you have humans, you will probably need accountability.<p>If a human decided to delegate killing enemy combatants to a machine, and that machine accidentally killed innocent civilians, is it really enough to just reprogram the machine? I think you must also hold the human accountable.<p>(Of course, this is just a simplified example, and in reality there are many humans in the loop who share accountability, some more than others)</div><br/></div></div><div id="42924148" class="c"><input type="checkbox" id="c-42924148" checked=""/><div class="controls bullet"><span class="by">miltonlost</span><span>|</span><a href="#42924102">parent</a><span>|</span><a href="#42924136">prev</a><span>|</span><a href="#42924273">next</a><span>|</span><label class="collapse" for="c-42924148">[-]</label><label class="expand" for="c-42924148">[10 more]</label></div><br/><div class="children"><div class="content">You fundamentally don’t understand either accountability or what people mean by “computers can’t be held accountable”. Who is at fault when a computer makes a mistake? That is accountability.<p>You cannot put a computer in jail. You cannot fine a computer. Please, stop torturing what people mean because you want AI to make decisions to absolve you of guilt.</div><br/><div id="42924266" class="c"><input type="checkbox" id="c-42924266" checked=""/><div class="controls bullet"><span class="by">chgs</span><span>|</span><a href="#42924102">root</a><span>|</span><a href="#42924148">parent</a><span>|</span><a href="#42924183">next</a><span>|</span><label class="collapse" for="c-42924266">[-]</label><label class="expand" for="c-42924266">[6 more]</label></div><br/><div class="children"><div class="content">What is the purpose of putting a person in jail or fining them?<p>Retribution? Reformation? Prevention?</div><br/><div id="42924416" class="c"><input type="checkbox" id="c-42924416" checked=""/><div class="controls bullet"><span class="by">cmgriffing</span><span>|</span><a href="#42924102">root</a><span>|</span><a href="#42924266">parent</a><span>|</span><a href="#42925149">next</a><span>|</span><label class="collapse" for="c-42924416">[-]</label><label class="expand" for="c-42924416">[1 more]</label></div><br/><div class="children"><div class="content">Consider the Volkswagen scandal where code was written that fudged the results when in an emissions testing environment.<p>The only person to see major punishment for that was the software dev that wrote the code, but that decision to write that code involved far more people up the chain. THEY should be held accountable in some way or else nothing prevents them from using some other poor dev as a scapegoat.</div><br/></div></div><div id="42925149" class="c"><input type="checkbox" id="c-42925149" checked=""/><div class="controls bullet"><span class="by">willy_k</span><span>|</span><a href="#42924102">root</a><span>|</span><a href="#42924266">parent</a><span>|</span><a href="#42924416">prev</a><span>|</span><a href="#42924452">next</a><span>|</span><label class="collapse" for="c-42925149">[-]</label><label class="expand" for="c-42925149">[1 more]</label></div><br/><div class="children"><div class="content">All of the above. Whether or not one agrees with it, humans have a need for retribution, or as we prefer to call it to feel better about it, justice. And you cannot get retribution on LLMs.</div><br/></div></div><div id="42924452" class="c"><input type="checkbox" id="c-42924452" checked=""/><div class="controls bullet"><span class="by">echoangle</span><span>|</span><a href="#42924102">root</a><span>|</span><a href="#42924266">parent</a><span>|</span><a href="#42925149">prev</a><span>|</span><a href="#42924405">next</a><span>|</span><label class="collapse" for="c-42924452">[-]</label><label class="expand" for="c-42924452">[1 more]</label></div><br/><div class="children"><div class="content">In this context, prevention. So people see what happens if they screw up in a negligent way and make sure to not do it themselves.</div><br/></div></div><div id="42924405" class="c"><input type="checkbox" id="c-42924405" checked=""/><div class="controls bullet"><span class="by">miltonlost</span><span>|</span><a href="#42924102">root</a><span>|</span><a href="#42924266">parent</a><span>|</span><a href="#42924452">prev</a><span>|</span><a href="#42924183">next</a><span>|</span><label class="collapse" for="c-42924405">[-]</label><label class="expand" for="c-42924405">[2 more]</label></div><br/><div class="children"><div class="content">Mixture of all three, but for the purposes of “accountability”, prevention of the behavior in the first place. But I don’t want to debate prisons when that’s derailing the larger point of “accountability in AI&#x2F;computers”.</div><br/><div id="42924632" class="c"><input type="checkbox" id="c-42924632" checked=""/><div class="controls bullet"><span class="by">dangrape123</span><span>|</span><a href="#42924102">root</a><span>|</span><a href="#42924405">parent</a><span>|</span><a href="#42924183">next</a><span>|</span><label class="collapse" for="c-42924632">[-]</label><label class="expand" for="c-42924632">[1 more]</label></div><br/><div class="children"><div class="content">What are there cowards on this message board that start a conversation, then when asked think, they run away?<p>Why are you a spineless coward?</div><br/></div></div></div></div></div></div><div id="42924327" class="c"><input type="checkbox" id="c-42924327" checked=""/><div class="controls bullet"><span class="by">canterburry</span><span>|</span><a href="#42924102">root</a><span>|</span><a href="#42924148">parent</a><span>|</span><a href="#42924183">prev</a><span>|</span><a href="#42924273">next</a><span>|</span><label class="collapse" for="c-42924327">[-]</label><label class="expand" for="c-42924327">[2 more]</label></div><br/><div class="children"><div class="content">What is the purpose of accountability?</div><br/><div id="42924382" class="c"><input type="checkbox" id="c-42924382" checked=""/><div class="controls bullet"><span class="by">miltonlost</span><span>|</span><a href="#42924102">root</a><span>|</span><a href="#42924327">parent</a><span>|</span><a href="#42924273">next</a><span>|</span><label class="collapse" for="c-42924382">[-]</label><label class="expand" for="c-42924382">[1 more]</label></div><br/><div class="children"><div class="content">To stop people from making illegal decisions ahead of time, and not just to punish them after. If there is no accountability to an AI, then a person making a killer robot would have no reason to not make a killer robot. If they were more to be imprisoned for making a killer robot, then they would be less likely to make a killer robot.<p>In a world without accountability, how do you stop evil people from doing evil things with AI as they want?</div><br/></div></div></div></div></div></div><div id="42924273" class="c"><input type="checkbox" id="c-42924273" checked=""/><div class="controls bullet"><span class="by">Macha</span><span>|</span><a href="#42924102">parent</a><span>|</span><a href="#42924148">prev</a><span>|</span><a href="#42924374">next</a><span>|</span><label class="collapse" for="c-42924273">[-]</label><label class="expand" for="c-42924273">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If meant to prevent repeat bad behavior, then simply reprogramming the computer accomplished the same end goal.<p>Note the bad behaviour you&#x27;re trying to prevent is not just the specific error that the computer made, but delegating authority to the computer to the level that it was able to make that error without proper oversight.</div><br/></div></div><div id="42924374" class="c"><input type="checkbox" id="c-42924374" checked=""/><div class="controls bullet"><span class="by">1shooner</span><span>|</span><a href="#42924102">parent</a><span>|</span><a href="#42924273">prev</a><span>|</span><a href="#42924159">next</a><span>|</span><label class="collapse" for="c-42924374">[-]</label><label class="expand" for="c-42924374">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like a conflation of responsibility with accountability. A machine responsible for emitting a certain amount of radiation on a patient can and should be reprogrammed. The company and&#x2F;or individuals that granted a malfunctioning radiation machine that responsibility need to be held accountable.</div><br/></div></div><div id="42924159" class="c"><input type="checkbox" id="c-42924159" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#42924102">parent</a><span>|</span><a href="#42924374">prev</a><span>|</span><a href="#42924177">next</a><span>|</span><label class="collapse" for="c-42924159">[-]</label><label class="expand" for="c-42924159">[1 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re confusing the tool with the user.<p>Improving the tool&#x27;s safety characteristics is <i>not</i> the same as holding <i>the user</i> accountable because they made stupid choices with unsafe tools. You want them to change their behavior, no matter how idiot-proofed their new toolset is.</div><br/></div></div><div id="42924177" class="c"><input type="checkbox" id="c-42924177" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#42924102">parent</a><span>|</span><a href="#42924159">prev</a><span>|</span><a href="#42924170">next</a><span>|</span><label class="collapse" for="c-42924177">[-]</label><label class="expand" for="c-42924177">[1 more]</label></div><br/><div class="children"><div class="content">In practice they will try to avoid acknowledging errors and will never reprogram the computer. That&#x27;s why a human appeals system is needed.</div><br/></div></div><div id="42924170" class="c"><input type="checkbox" id="c-42924170" checked=""/><div class="controls bullet"><span class="by">maxbond</span><span>|</span><a href="#42924102">parent</a><span>|</span><a href="#42924177">prev</a><span>|</span><a href="#42924356">next</a><span>|</span><label class="collapse" for="c-42924170">[-]</label><label class="expand" for="c-42924170">[1 more]</label></div><br/><div class="children"><div class="content">This makes sense if the computer was programmed that way <i>accidentally</i>. If the computer is a cut out to create plausible deniability, then reprogramming it won&#x27;t actually work. The people responsible will find a way to reintroduce a behavior with a similar outcome.</div><br/></div></div><div id="42924356" class="c"><input type="checkbox" id="c-42924356" checked=""/><div class="controls bullet"><span class="by">chasing</span><span>|</span><a href="#42924102">parent</a><span>|</span><a href="#42924170">prev</a><span>|</span><a href="#42924319">next</a><span>|</span><label class="collapse" for="c-42924356">[-]</label><label class="expand" for="c-42924356">[1 more]</label></div><br/><div class="children"><div class="content">You’ve set up an either-or here that fails to take into account a wide spectrum of thought around accountability and punishment.<p>When it comes to computers, the computer is a tool. It can be improved, but it can’t be held any more accountable than a hammer.<p>At least that’s how it should be. Those with wealth will do whatever they feel they need to do to shun accountability when they create harm. That will no doubt include trying to pin the blame on AI.</div><br/></div></div></div></div><div id="42924319" class="c"><input type="checkbox" id="c-42924319" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#42924102">prev</a><span>|</span><a href="#42924348">next</a><span>|</span><label class="collapse" for="c-42924319">[-]</label><label class="expand" for="c-42924319">[1 more]</label></div><br/><div class="children"><div class="content">... is not a moral subject.  But animals can be moral subjects [1]<p>[1] <a href="https:&#x2F;&#x2F;academic.oup.com&#x2F;book&#x2F;12087" rel="nofollow">https:&#x2F;&#x2F;academic.oup.com&#x2F;book&#x2F;12087</a></div><br/></div></div><div id="42924348" class="c"><input type="checkbox" id="c-42924348" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#42924319">prev</a><span>|</span><a href="#42924594">next</a><span>|</span><label class="collapse" for="c-42924348">[-]</label><label class="expand" for="c-42924348">[1 more]</label></div><br/><div class="children"><div class="content">We let corporations be unaccountable, so why would we treat computers any different.</div><br/></div></div><div id="42924594" class="c"><input type="checkbox" id="c-42924594" checked=""/><div class="controls bullet"><span class="by">xyst</span><span>|</span><a href="#42924348">prev</a><span>|</span><a href="#42924429">next</a><span>|</span><label class="collapse" for="c-42924594">[-]</label><label class="expand" for="c-42924594">[1 more]</label></div><br/><div class="children"><div class="content">yet, we give computers control&#x2F;management over 2 ton vehicles. An ADS controlled vehicle with bad sensors or software update  malfunctions and severely maims or kills multiple pedestrians, what happens here?<p>The computer controlling the vehicle won’t be held accountable. The case will drag on in the court systems. Maybe company is _found_ liable but ultimately allowed to continue pushing their faulty junk on the streets. Just pay a fine, settle out of court with victims and families. Some consultant out there is probably already building in the cost of killing somebody and potential lawsuit into the cost of production.</div><br/></div></div><div id="42924429" class="c"><input type="checkbox" id="c-42924429" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#42924594">prev</a><span>|</span><a href="#42924795">next</a><span>|</span><label class="collapse" for="c-42924429">[-]</label><label class="expand" for="c-42924429">[9 more]</label></div><br/><div class="children"><div class="content">The implication here is that unlike a computer, a person or a corporation <i>can</i> be held accountable.  I&#x27;m not sure that&#x27;s true.<p>Consider all of the shenanigans at OpenAI: <a href="https:&#x2F;&#x2F;www.safetyabandoned.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.safetyabandoned.org&#x2F;</a><p>Dozens of employees have left due to lack of faith in the leadership, and they are in the process of converting from nonprofit to for-profit, all but abandoning their mission to ensure that artificial intelligence benefits all humanity.<p>Will anything stop them?  Can they actually be held accountable?<p>I think social media, paradoxically, might make it <i>harder</i> to hold people and corporations accountable.  There are so many accusations flying around all the time, it can be harder to notice when a situation is truly serious.</div><br/><div id="42924715" class="c"><input type="checkbox" id="c-42924715" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#42924429">parent</a><span>|</span><a href="#42924696">next</a><span>|</span><label class="collapse" for="c-42924715">[-]</label><label class="expand" for="c-42924715">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a big difference between <i>can</i> and <i>will.</i> We absolutely <i>can</i> hold people and corporations accountable, but we often <i>don&#x27;t</i>. We <i>cannot</i> hold a computer responsible for <i>anything.</i> It&#x27;s a computer. No matter how complex or abstracted, its output is entirely based on instructions and data given to it by humans, interpreting and executing it as humans designed it to. It can&#x27;t be discouraged or punished: a computer doesn&#x27;t care if it&#x27;s on or off; if it&#x27;s the most important computer to have ever existed or a DoA Gateway 486 from the early 90s that sat in a dumpster from the day after it was born until the day it was smashed to bits in a garbage compactor in a transfer station. It doesn&#x27;t care because it can&#x27;t care. Anything beyond that is anthropomorphization.</div><br/></div></div><div id="42924696" class="c"><input type="checkbox" id="c-42924696" checked=""/><div class="controls bullet"><span class="by">h0l0cube</span><span>|</span><a href="#42924429">parent</a><span>|</span><a href="#42924715">prev</a><span>|</span><a href="#42924975">next</a><span>|</span><label class="collapse" for="c-42924696">[-]</label><label class="expand" for="c-42924696">[1 more]</label></div><br/><div class="children"><div class="content">&gt; might make it harder to hold people and corporations accountable<p>The problem is that someone (or some organization) chose to employ that system, and if the errant system doesn&#x27;t oblige to have itself replaced with a new one, or be amenable to change, the responsibility rebounds back to whoever controls that system, whether that be at the level of the source code, or the circuit breaker.</div><br/></div></div><div id="42924975" class="c"><input type="checkbox" id="c-42924975" checked=""/><div class="controls bullet"><span class="by">michael1999</span><span>|</span><a href="#42924429">parent</a><span>|</span><a href="#42924696">prev</a><span>|</span><a href="#42924731">next</a><span>|</span><label class="collapse" for="c-42924975">[-]</label><label class="expand" for="c-42924975">[3 more]</label></div><br/><div class="children"><div class="content">Corporations are regularly &quot;held accountable&quot;.  Remember that &quot;accountable&quot; just means &quot;required or expected to justify actions or decisions; responsible.&quot;<p>When you sue a corporation, discovery demands that they share their internal communication.  You can depose key actors and require they describe the events.  These actors can be cross-examined.  A trial continues this.  This is the very definition of &quot;accountable&quot;.<p>The problem at OpenAI is that the employees were credulous children who took magic beans instead of a board seat.  Legally, management is accountable to the board.  In serious cultures that believe in accountability, labour demands seats on the board.  In VC story-land, employees make do with vague promises with no legal force.</div><br/><div id="42925151" class="c"><input type="checkbox" id="c-42925151" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#42924429">root</a><span>|</span><a href="#42924975">parent</a><span>|</span><a href="#42924731">next</a><span>|</span><label class="collapse" for="c-42925151">[-]</label><label class="expand" for="c-42925151">[2 more]</label></div><br/><div class="children"><div class="content">&gt;The problem at OpenAI is that the employees were credulous children who took magic beans instead of a board seat. Legally, management is accountable to the board. In serious cultures that believe in accountability, labour demands seats on the board. In VC story-land, employees make do with vague promises with no legal force.<p>This is not a good description of the incident.  The employees I mention in my comment, who quit due to lack of faith in Sam Altman, were presumably on the board&#x27;s side in the Sam vs board drama.<p>There is still a chance that OpenAI&#x27;s conversion to for-profit will be blocked.  The site I linked is encouraging people to write letters to relevant state AGs: <a href="https:&#x2F;&#x2F;www.safetyabandoned.org&#x2F;#outreach" rel="nofollow">https:&#x2F;&#x2F;www.safetyabandoned.org&#x2F;#outreach</a><p>I think there&#x27;s a decent argument to be made that the conversion to a for-profit is a violation of OpenAI&#x27;s nonprofit charter.</div><br/><div id="42925299" class="c"><input type="checkbox" id="c-42925299" checked=""/><div class="controls bullet"><span class="by">michael1999</span><span>|</span><a href="#42924429">root</a><span>|</span><a href="#42925151">parent</a><span>|</span><a href="#42924731">next</a><span>|</span><label class="collapse" for="c-42925299">[-]</label><label class="expand" for="c-42925299">[1 more]</label></div><br/><div class="children"><div class="content">I hid my point behind the snark.  Apologies.<p>My point is: accountability is NOT an abstract property of a thing.  It is a relationship between two parties.  I am &quot;accountable&quot; to you IF you can demand that I provide an explanation for my behaviour.  I am accountable to my boss.  I am accountable to the law, should I be sued or charged criminally.  I am NOT accountable to random people in the street.<p>Sam Altman is accountable to the board.  The board can demand he explain himself (and did). Management is generally NOT accountable to employees in the USA.  This is because  labor rarely has a legal right to demand an accounting.  In serious labour cultures (e.g. Germany), it is normal for the unions to hold board seats.  These board seats are what makes management accountable to the employees.<p>OpenAI employees took happy words from sama at face value.  That was not a legal relationship that provided accountability.  And here we are.  The decision to change from a not-for-profit is accountable to the board, and maybe the chancellors of Delaware corporate law.</div><br/></div></div></div></div></div></div><div id="42924731" class="c"><input type="checkbox" id="c-42924731" checked=""/><div class="controls bullet"><span class="by">peterldowns</span><span>|</span><a href="#42924429">parent</a><span>|</span><a href="#42924975">prev</a><span>|</span><a href="#42926278">next</a><span>|</span><label class="collapse" for="c-42924731">[-]</label><label class="expand" for="c-42924731">[2 more]</label></div><br/><div class="children"><div class="content">Per Landian-Accelerationist theory, companies are already artificial intelligences. As we&#x27;ve seen, they can be held accountable, and the law (at least in the US) does distinguish in a variety of ways between corporate responsibility and personal responsibility. As you point out, there are lots of failure cases here, and it&#x27;s something I expect to see continue to be litigated over the coming century.</div><br/><div id="42925747" class="c"><input type="checkbox" id="c-42925747" checked=""/><div class="controls bullet"><span class="by">gom_jabbar</span><span>|</span><a href="#42924429">root</a><span>|</span><a href="#42924731">parent</a><span>|</span><a href="#42926278">next</a><span>|</span><label class="collapse" for="c-42925747">[-]</label><label class="expand" for="c-42925747">[1 more]</label></div><br/><div class="children"><div class="content">Correct, for Nick Land &quot;Business ventures are <i>actually existing</i> artificial intelligences&quot;[0] and the failure cases will increase with the ongoing autonomization of capital and eventually the concept of &quot;capital self-ownership&quot;[1] will have to be recognized.<p>[0] Nick Land (2014). <i>Odds and Ends</i> in <i>Collapse Volume VIII: Casino Real.</i> p. 372.<p>[1] <a href="https:&#x2F;&#x2F;retrochronic.com&#x2F;#piketty" rel="nofollow">https:&#x2F;&#x2F;retrochronic.com&#x2F;#piketty</a></div><br/></div></div></div></div><div id="42926278" class="c"><input type="checkbox" id="c-42926278" checked=""/><div class="controls bullet"><span class="by">unparagoned</span><span>|</span><a href="#42924429">parent</a><span>|</span><a href="#42924731">prev</a><span>|</span><a href="#42924795">next</a><span>|</span><label class="collapse" for="c-42926278">[-]</label><label class="expand" for="c-42926278">[1 more]</label></div><br/><div class="children"><div class="content">Also in the justice system, a judge can be racist, and the sentence they give has been show to be related with how hungry they are, etc.<p>Would I rather be at the whims of how hungry somone is, or a model that can be tested and evaluated.</div><br/></div></div></div></div><div id="42924795" class="c"><input type="checkbox" id="c-42924795" checked=""/><div class="controls bullet"><span class="by">michael1999</span><span>|</span><a href="#42924429">prev</a><span>|</span><a href="#42924194">next</a><span>|</span><label class="collapse" for="c-42924795">[-]</label><label class="expand" for="c-42924795">[4 more]</label></div><br/><div class="children"><div class="content">To be &quot;accountable&quot; means you can be called to &quot;explain yourself&quot;.  A dictionary definition is &quot;required or expected to justify actions or decisions;&quot;.<p>Don&#x27;t confuse this with judgement, punishment, firing, etc.  Those are all downstream.  But step one is responding to the demand that you &quot;make an account of the facts&quot;.  That a computer or a company doesn&#x27;t have a body to jail has nothing to do with fundamental accountability.<p>The real problem is that most computer systems can not respond this demand: &quot;explain yourself!&quot;  They can&#x27;t describes the inputs to an output, the criteria and thresholds used, the history of how thresholds have changed, or the reliability of the upstream data.  They just provide a result: computer says no.<p>What&#x27;s interesting is that llms are beginning to form this capacity.  What damns them is not that they can&#x27;t provide an accounting, but that their account is often total confabulation.<p>Careless liars should not be placed in situations of authority; not because they can&#x27;t be held accountable, but because they lie when they are.</div><br/><div id="42924925" class="c"><input type="checkbox" id="c-42924925" checked=""/><div class="controls bullet"><span class="by">nostrademons</span><span>|</span><a href="#42924795">parent</a><span>|</span><a href="#42924194">next</a><span>|</span><label class="collapse" for="c-42924925">[-]</label><label class="expand" for="c-42924925">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The real problem is that most computer systems can not respond this demand: &quot;explain yourself!&quot; They can&#x27;t describes the inputs to an output, the criteria and thresholds used, the history of how thresholds have changed, or the reliability of the upstream data. They just provide a result: computer says no.<p>By this definition, many computer systems <i>can</i>.  The answers are all in the logs and the source code, and the process of debugging is basically the act of holding the software accountable.<p>It&#x27;s true that the average layperson cannot do this, but there are many real-life situations where the average layperson cannot hold other people accountable.  I cannot go up to the CEO of Boeing and ask why the 737-MAX I was on yesterday had a mechanical failure, nor can I go up to Elon Musk and ask why his staff are breaking into the Treasury Department computer systems.  But the board of directors of Boeing or the court system, respectively, can, at least is theory.</div><br/><div id="42925182" class="c"><input type="checkbox" id="c-42925182" checked=""/><div class="controls bullet"><span class="by">michael1999</span><span>|</span><a href="#42924795">root</a><span>|</span><a href="#42924925">parent</a><span>|</span><a href="#42925071">next</a><span>|</span><label class="collapse" for="c-42925182">[-]</label><label class="expand" for="c-42925182">[1 more]</label></div><br/><div class="children"><div class="content">You get it.  To make the concept of accountability operational requires some standard of accounting.  The historical accountability for a business agent meant to literally present oneself and provide an explanation.  That where the term &quot;accounting&quot; comes from.  But different systems have different systems of account.  Firm management is accountable to the board via budgets, reports, presentations, and interviews as described in the incorporation documents.  Publicly-traded firms are accountable via quarterly filings.  Legal disputes require physical presence and verbal interrogation.<p>But your example of a debugging session or logs and register traces are also an accounting!  But not one admissible in traditional forums.  They usually require an expert witness to provided the interpretation and voice I&#x2F;O for the process.<p>The reason you can&#x27;t accost the CEO of Boeing isn&#x27;t because they aren&#x27;t accountable.  It&#x27;s because they aren&#x27;t accountable to you!  Accountability isn&#x27;t a general property of a thing, it is a relationship between two parties.  The CEO of Boeing is accountable to his board.  Your contract was with Delta (or whoever) to provide transport.  You have no contract with Boeing.<p>You are 100% right that the average consumer often zero rights to accountability.  Between mandatory arbitration, rights waivers, web-only interfaces, and 6-hour call-centre wait times, big companies do a pretty good job of reducing their accountability to their customers.  Real accountability is expensive.</div><br/></div></div><div id="42925071" class="c"><input type="checkbox" id="c-42925071" checked=""/><div class="controls bullet"><span class="by">dullcrisp</span><span>|</span><a href="#42924795">root</a><span>|</span><a href="#42924925">parent</a><span>|</span><a href="#42925182">prev</a><span>|</span><a href="#42924194">next</a><span>|</span><label class="collapse" for="c-42925071">[-]</label><label class="expand" for="c-42925071">[1 more]</label></div><br/><div class="children"><div class="content">I don’t know, when asked to explain my actions I don’t typically just provide an MRI scan of my brain. An explanation is something different than just the sum of the inputs that produced something.</div><br/></div></div></div></div></div></div><div id="42924194" class="c"><input type="checkbox" id="c-42924194" checked=""/><div class="controls bullet"><span class="by">hsbauauvhabzb</span><span>|</span><a href="#42924795">prev</a><span>|</span><a href="#42924164">next</a><span>|</span><label class="collapse" for="c-42924194">[-]</label><label class="expand" for="c-42924194">[4 more]</label></div><br/><div class="children"><div class="content">I can defer decision making to a computer but I cannot defer liability.<p>Computers have the final say on anything to do with computers, if I transfer money at my bank, a computer bug could send that money to the wrong account due to a solar ray. The bank has accepted that risk, and on some (significantly less liable but still liable) level, so have I.<p>Interestingly, there are cases where I have not accepted any liability - records (birth certificate, SSN) held about me by my government, for example.</div><br/><div id="42924237" class="c"><input type="checkbox" id="c-42924237" checked=""/><div class="controls bullet"><span class="by">kps</span><span>|</span><a href="#42924194">parent</a><span>|</span><a href="#42924276">next</a><span>|</span><label class="collapse" for="c-42924237">[-]</label><label class="expand" for="c-42924237">[1 more]</label></div><br/><div class="children"><div class="content">&gt; … but I cannot defer liability.<p>For that, you need a corporation.</div><br/></div></div><div id="42924276" class="c"><input type="checkbox" id="c-42924276" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#42924194">parent</a><span>|</span><a href="#42924237">prev</a><span>|</span><a href="#42924277">next</a><span>|</span><label class="collapse" for="c-42924276">[-]</label><label class="expand" for="c-42924276">[1 more]</label></div><br/><div class="children"><div class="content">&gt; a computer bug could send that money to the wrong account due to a solar ray<p>I think the original quote captures that with the qualifier &quot;a <i>management</i> decision&quot;, which given that it was 1979 implies it&#x27;s separate from other kinds of decisions being made by non-manager employees following a checklist, or the machines that were slowly replacing them.<p>So a cosmic-ray bit-flip changing an account number would be analogous to an employee hitting the wrong key on a typewriter.</div><br/></div></div></div></div><div id="42924164" class="c"><input type="checkbox" id="c-42924164" checked=""/><div class="controls bullet"><span class="by">dumbfounder</span><span>|</span><a href="#42924194">prev</a><span>|</span><a href="#42926318">next</a><span>|</span><label class="collapse" for="c-42924164">[-]</label><label class="expand" for="c-42924164">[8 more]</label></div><br/><div class="children"><div class="content">The human that decides to use the AI that makes decisions is the one that should be held accountable.</div><br/><div id="42924357" class="c"><input type="checkbox" id="c-42924357" checked=""/><div class="controls bullet"><span class="by">carlhjerpe</span><span>|</span><a href="#42924164">parent</a><span>|</span><a href="#42924248">next</a><span>|</span><label class="collapse" for="c-42924357">[-]</label><label class="expand" for="c-42924357">[1 more]</label></div><br/><div class="children"><div class="content">While hard&#x2F;impossible in practice, I agree.<p>The Dutch did an AI thing: <a href="https:&#x2F;&#x2F;spectrum.ieee.org&#x2F;artificial-intelligence-in-government" rel="nofollow">https:&#x2F;&#x2F;spectrum.ieee.org&#x2F;artificial-intelligence-in-governm...</a></div><br/></div></div><div id="42924322" class="c"><input type="checkbox" id="c-42924322" checked=""/><div class="controls bullet"><span class="by">nine_zeros</span><span>|</span><a href="#42924164">parent</a><span>|</span><a href="#42924248">prev</a><span>|</span><a href="#42924289">next</a><span>|</span><label class="collapse" for="c-42924322">[-]</label><label class="expand" for="c-42924322">[4 more]</label></div><br/><div class="children"><div class="content">Arrest the executives of companies that allow malicious use of AI?<p>Second degree murder. Much like a car driver can&#x27;t blame their car for the accident, a corporate driver shouldn&#x27;t be allowed blame their software for the decision.</div><br/><div id="42929917" class="c"><input type="checkbox" id="c-42929917" checked=""/><div class="controls bullet"><span class="by">otikik</span><span>|</span><a href="#42924164">root</a><span>|</span><a href="#42924322">parent</a><span>|</span><a href="#42924532">next</a><span>|</span><label class="collapse" for="c-42929917">[-]</label><label class="expand" for="c-42929917">[1 more]</label></div><br/><div class="children"><div class="content">What if an insurance company denies healthcare via an algorithm and then people die as a result?</div><br/></div></div><div id="42924532" class="c"><input type="checkbox" id="c-42924532" checked=""/><div class="controls bullet"><span class="by">echoangle</span><span>|</span><a href="#42924164">root</a><span>|</span><a href="#42924322">parent</a><span>|</span><a href="#42929917">prev</a><span>|</span><a href="#42924289">next</a><span>|</span><label class="collapse" for="c-42924532">[-]</label><label class="expand" for="c-42924532">[2 more]</label></div><br/><div class="children"><div class="content">Interesting that this comes up again after I just discussed this on here yesterday, but you actually can blame your car for accidents.<p>If a mechanical or technical problem was the reason of the accident and you properly took care of your car, you won’t be responsible, because you did everything that’s expected of you.<p>The problem would be defining which level of AI decision making would count as negligent. Sounds like you would like to set it at 0%, but that’s something that’s going to need to be determined.</div><br/><div id="42924916" class="c"><input type="checkbox" id="c-42924916" checked=""/><div class="controls bullet"><span class="by">nine_zeros</span><span>|</span><a href="#42924164">root</a><span>|</span><a href="#42924532">parent</a><span>|</span><a href="#42924289">next</a><span>|</span><label class="collapse" for="c-42924916">[-]</label><label class="expand" for="c-42924916">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If a mechanical or technical problem was the reason of the accident and you properly took care of your car, you won’t be responsible, because you did everything that’s expected of you.<p>Good thing you brought this up because in the US, defective cars must be recalled and are a liability of the manufacturer. Non-effective cars are a liability of the owner.<p>Thus, the owner of a car is responsible by default, and manufacturer is second.<p>In the context of AI, the wielders of AI would be responsible by default, and manufacturers second.<p>The point is that there is a chain of accountability that is humans owning the equipment or manufacturing the equipment.</div><br/></div></div></div></div></div></div></div></div><div id="42926318" class="c"><input type="checkbox" id="c-42926318" checked=""/><div class="controls bullet"><span class="by">from-nibly</span><span>|</span><a href="#42924164">prev</a><span>|</span><a href="#42924251">next</a><span>|</span><label class="collapse" for="c-42926318">[-]</label><label class="expand" for="c-42926318">[1 more]</label></div><br/><div class="children"><div class="content">&gt; a computer must never make a management decision.<p>This a little too weak for my taste.<p>In reality it should read &quot;a computer can&#x27;t make a management decision&quot;. As in the sun can&#x27;t be prevented from rising, or the law of thermo dynamics can&#x27;t be broken.<p>Must implies that you really shoudln&#x27;t but technically it&#x27;s feasible.  Like &quot;you must not murder&quot;.<p>A computer, like dogs, can&#x27;t be held accountable; only their owners can.<p>Edit<p>If anyone tries to do this they are simply laundering their own accountability.</div><br/></div></div><div id="42924251" class="c"><input type="checkbox" id="c-42924251" checked=""/><div class="controls bullet"><span class="by">stevebmark</span><span>|</span><a href="#42926318">prev</a><span>|</span><a href="#42926942">next</a><span>|</span><label class="collapse" for="c-42924251">[-]</label><label class="expand" for="c-42924251">[2 more]</label></div><br/><div class="children"><div class="content">I don’t know if this is being shared intentionally given the timing of “The Gospel” AI target finder, but it is truly horrific that AI is being used this way and as an accountability target</div><br/></div></div><div id="42926942" class="c"><input type="checkbox" id="c-42926942" checked=""/><div class="controls bullet"><span class="by">kylehotchkiss</span><span>|</span><a href="#42924251">prev</a><span>|</span><a href="#42924772">next</a><span>|</span><label class="collapse" for="c-42926942">[-]</label><label class="expand" for="c-42926942">[1 more]</label></div><br/><div class="children"><div class="content">Did you not see Office Space? Any device can be held accountable.</div><br/></div></div><div id="42924772" class="c"><input type="checkbox" id="c-42924772" checked=""/><div class="controls bullet"><span class="by">azlev</span><span>|</span><a href="#42926942">prev</a><span>|</span><a href="#42924435">next</a><span>|</span><label class="collapse" for="c-42924772">[-]</label><label class="expand" for="c-42924772">[1 more]</label></div><br/><div class="children"><div class="content">Relevant example here: <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;1983_Soviet_nuclear_false_alarm_incident" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;1983_Soviet_nuclear_false_al...</a></div><br/></div></div><div id="42924435" class="c"><input type="checkbox" id="c-42924435" checked=""/><div class="controls bullet"><span class="by">dankwizard</span><span>|</span><a href="#42924772">prev</a><span>|</span><a href="#42924218">next</a><span>|</span><label class="collapse" for="c-42924435">[-]</label><label class="expand" for="c-42924435">[6 more]</label></div><br/><div class="children"><div class="content">This feels very &quot;I&#x27;m 12 and this is deep&quot;.<p>If a bridge collapses, are you blaming the cement?</div><br/><div id="42924587" class="c"><input type="checkbox" id="c-42924587" checked=""/><div class="controls bullet"><span class="by">jf</span><span>|</span><a href="#42924435">parent</a><span>|</span><a href="#42924460">next</a><span>|</span><label class="collapse" for="c-42924587">[-]</label><label class="expand" for="c-42924587">[1 more]</label></div><br/><div class="children"><div class="content">It helps to understand the context for when this was written. Before the personal computer revolution, most people didn&#x27;t have access to a computer and only knew about them from depictions in popular culture, which depicted computers as all-known-all-seeing entities (think HAL from Space Odyssey 2001)<p>Because of these misconceptions, some people at the time would think of computers as devices that were (somehow) perfect and infallible.<p>It was very similar to how people view AI today: The way that AI is depicted in popular culture gives people an impression that AI is far more capable than it is. You only really get a good &quot;feel&quot; for what AI can do if you try it yourself. The main difference between AI and pre-personal computers is that basically everyone can use AI now.</div><br/></div></div><div id="42924460" class="c"><input type="checkbox" id="c-42924460" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#42924435">parent</a><span>|</span><a href="#42924587">prev</a><span>|</span><a href="#42924521">next</a><span>|</span><label class="collapse" for="c-42924460">[-]</label><label class="expand" for="c-42924460">[1 more]</label></div><br/><div class="children"><div class="content">Construction companies don’t shrug and blame the concrete. Or at least nowhere near as often as companies that employ software in their customer interactions.</div><br/></div></div><div id="42924521" class="c"><input type="checkbox" id="c-42924521" checked=""/><div class="controls bullet"><span class="by">h0l0cube</span><span>|</span><a href="#42924435">parent</a><span>|</span><a href="#42924460">prev</a><span>|</span><a href="#42924499">next</a><span>|</span><label class="collapse" for="c-42924521">[-]</label><label class="expand" for="c-42924521">[1 more]</label></div><br/><div class="children"><div class="content">I take your point, but the cement mix can absolutely have an impact on the integrity of the bridge structure.  But to further your point, the cement mix was either incorrectly specified, or inadequately provided, and the responsibility for that falls on one of the humans in the loop.</div><br/></div></div><div id="42924499" class="c"><input type="checkbox" id="c-42924499" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#42924435">parent</a><span>|</span><a href="#42924521">prev</a><span>|</span><a href="#42924507">next</a><span>|</span><label class="collapse" for="c-42924499">[-]</label><label class="expand" for="c-42924499">[1 more]</label></div><br/><div class="children"><div class="content">We should keep tapping the sign as long as people are still using &quot;computer says no; nothing can be done&quot; as a serious argument.</div><br/></div></div><div id="42924507" class="c"><input type="checkbox" id="c-42924507" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#42924435">parent</a><span>|</span><a href="#42924499">prev</a><span>|</span><a href="#42924218">next</a><span>|</span><label class="collapse" for="c-42924507">[-]</label><label class="expand" for="c-42924507">[1 more]</label></div><br/><div class="children"><div class="content">In AI crap, I think this crops up as, giant company asks vendor, &quot;Indemnify us against XYZ, but we also want to own everything.&quot; My dude, that&#x27;s what owning the thing entails: taking liability for it.<p>The punchline will be that people will agree to whatever smoke and mirrors leads to sales.</div><br/></div></div></div></div><div id="42924218" class="c"><input type="checkbox" id="c-42924218" checked=""/><div class="controls bullet"><span class="by">nostrademons</span><span>|</span><a href="#42924435">prev</a><span>|</span><a href="#42924064">next</a><span>|</span><label class="collapse" for="c-42924218">[-]</label><label class="expand" for="c-42924218">[5 more]</label></div><br/><div class="children"><div class="content">These days it seems like we can&#x27;t hold humans accountable either.</div><br/><div id="42924963" class="c"><input type="checkbox" id="c-42924963" checked=""/><div class="controls bullet"><span class="by">leptons</span><span>|</span><a href="#42924218">parent</a><span>|</span><a href="#42924627">next</a><span>|</span><label class="collapse" for="c-42924963">[-]</label><label class="expand" for="c-42924963">[3 more]</label></div><br/><div class="children"><div class="content">Not true, there are plenty of poor people being held accountable.</div><br/><div id="42925260" class="c"><input type="checkbox" id="c-42925260" checked=""/><div class="controls bullet"><span class="by">nostrademons</span><span>|</span><a href="#42924218">root</a><span>|</span><a href="#42924963">parent</a><span>|</span><a href="#42924627">next</a><span>|</span><label class="collapse" for="c-42925260">[-]</label><label class="expand" for="c-42925260">[2 more]</label></div><br/><div class="children"><div class="content">Even here, the concept is decaying.  Accountability, as explained elsewhere on the thread, is about being asked to explain and justify your actions.  If a poor person gets arrested and shows up to court, frequently nobody listens to their explanation.  The mere fact that they&#x27;re poor and in court is evidence of guilt.  That&#x27;s not accountability; that&#x27;s just punishment.<p>Accountability requires a common standard of conduct.  People have to agree on what the rules are.  If they can&#x27;t even do that, the concept ceases to have meaning, and you simply have the exercise of power and &quot;might makes right&quot;.</div><br/><div id="42926431" class="c"><input type="checkbox" id="c-42926431" checked=""/><div class="controls bullet"><span class="by">MichaelZuo</span><span>|</span><a href="#42924218">root</a><span>|</span><a href="#42925260">parent</a><span>|</span><a href="#42924627">next</a><span>|</span><label class="collapse" for="c-42926431">[-]</label><label class="expand" for="c-42926431">[1 more]</label></div><br/><div class="children"><div class="content">What is the basis for these opinions?<p>From what I recall of history even the most bloodthirsty warlords somehow got reliable systems of accountability up and running from their princes&#x2F;serfs&#x2F;merchants&#x2F;etc… at least long enough to maintain sizable empires for several generations.<p>It’s not like they were 24&#x2F;7 in a state of rebellion.</div><br/></div></div></div></div></div></div><div id="42924627" class="c"><input type="checkbox" id="c-42924627" checked=""/><div class="controls bullet"><span class="by">bamboozled</span><span>|</span><a href="#42924218">parent</a><span>|</span><a href="#42924963">prev</a><span>|</span><a href="#42924064">next</a><span>|</span><label class="collapse" for="c-42924627">[-]</label><label class="expand" for="c-42924627">[1 more]</label></div><br/><div class="children"><div class="content">I thought the same thing, people do literally whatever they want, evade tax, annex sovereign territory, coups, war crimes, pedophilia, it seems to just be getting worse.<p>I honestly feel like a moron for paying taxes.</div><br/></div></div></div></div><div id="42924064" class="c"><input type="checkbox" id="c-42924064" checked=""/><div class="controls bullet"><span class="by">throwitaway222</span><span>|</span><a href="#42924218">prev</a><span>|</span><a href="#42924215">next</a><span>|</span><label class="collapse" for="c-42924064">[-]</label><label class="expand" for="c-42924064">[9 more]</label></div><br/><div class="children"><div class="content">AI will definitely, without a doubt, make executive decisions. It already makes lower level decisions. The company that runs the AI, can be held accountable. (meaning less likely OpenAI or the foundational LLM, but more likely the company calling LLMs that make decisions on car insurance, etc...)</div><br/><div id="42924536" class="c"><input type="checkbox" id="c-42924536" checked=""/><div class="controls bullet"><span class="by">themanmaran</span><span>|</span><a href="#42924064">parent</a><span>|</span><a href="#42924417">next</a><span>|</span><label class="collapse" for="c-42924536">[-]</label><label class="expand" for="c-42924536">[2 more]</label></div><br/><div class="children"><div class="content">Thing is, the chain of responsibility gets really muddled over time, and blame is hard to dish out. Let&#x27;s think about denying a car insurance claim:<p>The person who clicks the &quot;Approve&quot; &#x2F; &quot;Deny&quot; button is likely an underwriter looking at info on their screen.<p>The info they&#x27;re looking at get&#x27;s aggregated from a lot of sources. They have the insurance contract. Maybe one part is AI summary of the police report. And another part is a repair estimate that gets synced over from the dealership. A list of prior claims this person has. Probably a dozen other sources.<p>Now what happens if this person makes a totally correct decision based on their data, but that data was wrong because the _syncFromMazdaRepairShopSFTP_ service got the quote data wrong? Who is liable? The person denying the claim, the engineer who wrote the code, AWS?<p>In reality, it&#x27;s &quot;the company&quot; in so far as fault can be proven. The underlying service providers they use doesn&#x27;t really factor into that decision. AI is just another tool in that process that (like other tools) can break.</div><br/><div id="42925093" class="c"><input type="checkbox" id="c-42925093" checked=""/><div class="controls bullet"><span class="by">almosthere</span><span>|</span><a href="#42924064">root</a><span>|</span><a href="#42924536">parent</a><span>|</span><a href="#42924417">next</a><span>|</span><label class="collapse" for="c-42925093">[-]</label><label class="expand" for="c-42925093">[1 more]</label></div><br/><div class="children"><div class="content">_syncFromMazdaRepairShopSFTP_ failing is also just as likely to cause a human to deny a claim.<p>Just because an automated decision system exists, does not mean an OOB (out of band) correctional measure should not exist.<p>In other words if AI fixes a time sink for 99% of cases, but fails on 1%, then let 50% of the 1% of angry customers get a second decision because they emailed the staff. That failure system still saves the company millions per year.</div><br/></div></div></div></div><div id="42924417" class="c"><input type="checkbox" id="c-42924417" checked=""/><div class="controls bullet"><span class="by">chasing</span><span>|</span><a href="#42924064">parent</a><span>|</span><a href="#42924536">prev</a><span>|</span><a href="#42924215">next</a><span>|</span><label class="collapse" for="c-42924417">[-]</label><label class="expand" for="c-42924417">[6 more]</label></div><br/><div class="children"><div class="content">Executives have always used decision-making tools. That’s not the point. The point is that the executive can’t point to the computer and say “I just did what it said!” The executive is the responsible party. She or he makes the choice to follow the advice of the decision-making tool or not.</div><br/><div id="42924496" class="c"><input type="checkbox" id="c-42924496" checked=""/><div class="controls bullet"><span class="by">owlbite</span><span>|</span><a href="#42924064">root</a><span>|</span><a href="#42924417">parent</a><span>|</span><a href="#42924215">next</a><span>|</span><label class="collapse" for="c-42924496">[-]</label><label class="expand" for="c-42924496">[5 more]</label></div><br/><div class="children"><div class="content">The scary thing for me is when they&#x27;ve got an 18 year old drone operator making shoot&#x2F;no-shoot decision on the basis of some AI metadata analysis tool (phone A was near phone B, we shot phone B last week...).<p>You end up with &quot;Computer says shoot&quot; and so many cooks involved in the software chain that no one can feasibly be held accountable except maybe the chief of staff or the president.</div><br/><div id="42924567" class="c"><input type="checkbox" id="c-42924567" checked=""/><div class="controls bullet"><span class="by">h0l0cube</span><span>|</span><a href="#42924064">root</a><span>|</span><a href="#42924496">parent</a><span>|</span><a href="#42924559">next</a><span>|</span><label class="collapse" for="c-42924567">[-]</label><label class="expand" for="c-42924567">[1 more]</label></div><br/><div class="children"><div class="content">More than any other organization, the military can literally get away with murder, and they&#x27;re motivated to recruit and protect the best murderers.  It&#x27;s only by political pressure that they may uphold some moral standards.</div><br/></div></div><div id="42924559" class="c"><input type="checkbox" id="c-42924559" checked=""/><div class="controls bullet"><span class="by">freeone3000</span><span>|</span><a href="#42924064">root</a><span>|</span><a href="#42924496">parent</a><span>|</span><a href="#42924567">prev</a><span>|</span><a href="#42924539">next</a><span>|</span><label class="collapse" for="c-42924559">[-]</label><label class="expand" for="c-42924559">[2 more]</label></div><br/><div class="children"><div class="content">There is not a finite amount of blame for a given event. Multiple people can be fully at fault.</div><br/><div id="42924895" class="c"><input type="checkbox" id="c-42924895" checked=""/><div class="controls bullet"><span class="by">PaulKeeble</span><span>|</span><a href="#42924064">root</a><span>|</span><a href="#42924559">parent</a><span>|</span><a href="#42924539">next</a><span>|</span><label class="collapse" for="c-42924895">[-]</label><label class="expand" for="c-42924895">[1 more]</label></div><br/><div class="children"><div class="content">In most cases today if we don&#x27;t attribute a direct crime solely to one person but instead to an organisation everyone avoids criminal prosecutions. Its only the people who didn&#x27;t manage to spread the blame through the rest of the organisation that go down.</div><br/></div></div></div></div><div id="42924539" class="c"><input type="checkbox" id="c-42924539" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#42924064">root</a><span>|</span><a href="#42924496">parent</a><span>|</span><a href="#42924559">prev</a><span>|</span><a href="#42924215">next</a><span>|</span><label class="collapse" for="c-42924539">[-]</label><label class="expand" for="c-42924539">[1 more]</label></div><br/><div class="children"><div class="content">Yeah but it&#x27;s fine because nobody cares if you kill a few thousand brown people extra.</div><br/></div></div></div></div></div></div></div></div><div id="42924215" class="c"><input type="checkbox" id="c-42924215" checked=""/><div class="controls bullet"><span class="by">lrvick</span><span>|</span><a href="#42924064">prev</a><span>|</span><label class="collapse" for="c-42924215">[-]</label><label class="expand" for="c-42924215">[3 more]</label></div><br/><div class="children"><div class="content">Meanwhile I work in reproducible builds and remote attestation. We absolutely can and must hold computers accountable, now that we have elected them into positions of power in our society.</div><br/><div id="42924471" class="c"><input type="checkbox" id="c-42924471" checked=""/><div class="controls bullet"><span class="by">h0l0cube</span><span>|</span><a href="#42924215">parent</a><span>|</span><a href="#42924410">next</a><span>|</span><label class="collapse" for="c-42924471">[-]</label><label class="expand" for="c-42924471">[1 more]</label></div><br/><div class="children"><div class="content">Surely the company that is making profit out of said build systems and providing attestations holds some accountability.  Someone wrote the code.  Someone paid for the code to be written to a particular standard, under particular budget and resourcing constraints.  Someone was responsible for ensuring the code was adequately audited.  Someone claimed it was fit for purpose, and likely insured it as such, <i>because</i> they are ultimately responsible.</div><br/></div></div><div id="42924410" class="c"><input type="checkbox" id="c-42924410" checked=""/><div class="controls bullet"><span class="by">byteknight</span><span>|</span><a href="#42924215">parent</a><span>|</span><a href="#42924471">prev</a><span>|</span><label class="collapse" for="c-42924410">[-]</label><label class="expand" for="c-42924410">[1 more]</label></div><br/><div class="children"><div class="content">You can only hold computers accountable if you can guarantee no outside modification. We still haven&#x27;t ever successfully had a system that&#x27;s not &quot;pop-able&quot; that I am aware of.</div><br/></div></div></div></div></div></div></div></div></div></body></html>