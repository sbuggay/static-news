<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1734253257894" as="style"/><link rel="stylesheet" href="styles.css?v=1734253257894"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://willwhitney.com/computing-inside-ai.html">Computing Inside an AI</a> <span class="domain">(<a href="https://willwhitney.com">willwhitney.com</a>)</span></div><div class="subtext"><span>pongogogo</span> | <span>19 comments</span></div><br/><div><div id="42421966" class="c"><input type="checkbox" id="c-42421966" checked=""/><div class="controls bullet"><span class="by">doug_durham</span><span>|</span><a href="#42421956">next</a><span>|</span><label class="collapse" for="c-42421966">[-]</label><label class="expand" for="c-42421966">[3 more]</label></div><br/><div class="children"><div class="content">I appreciated the thought given in this piece.  However in the age of LLMs these types of &quot;what if we look at problems this way...&quot; seem obsolete.  Instead of asking the question, just use an LLM to help you build the proof of concept and see if it works.<p>Back in the pre-LLM days these types of thought pieces made sense as a call to action because the economics of creating sophisticated proof&#x27;s of concept was beyond the abilities of any one person.  Now you can create implementations and iterate at nearly the speed of thought.  Instead of telling people about your idea, show people your idea.</div><br/><div id="42422167" class="c"><input type="checkbox" id="c-42422167" checked=""/><div class="controls bullet"><span class="by">achierius</span><span>|</span><a href="#42421966">parent</a><span>|</span><a href="#42422000">next</a><span>|</span><label class="collapse" for="c-42422167">[-]</label><label class="expand" for="c-42422167">[1 more]</label></div><br/><div class="children"><div class="content">But LLMs are nowhere near being able to do what you suggest, for anything that one person wouldn&#x27;t have been able to do beforehand.</div><br/></div></div><div id="42422000" class="c"><input type="checkbox" id="c-42422000" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#42421966">parent</a><span>|</span><a href="#42422167">prev</a><span>|</span><a href="#42421956">next</a><span>|</span><label class="collapse" for="c-42422000">[-]</label><label class="expand" for="c-42422000">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m kind of with you in that you could build something kind of like it based on a fast LLM. But what they are actually talking about is a new cutting edge ML model that takes a huge amount of data and compute to train.</div><br/></div></div></div></div><div id="42421956" class="c"><input type="checkbox" id="c-42421956" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#42421966">prev</a><span>|</span><a href="#42422129">next</a><span>|</span><label class="collapse" for="c-42421956">[-]</label><label class="expand" for="c-42421956">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Acting like a computer means producing a graphical interface. In place of the charmingly teletype linear stream of text provided by ChatGPT, a model-as-computer system will generate something which resembles the interface of a modern application: buttons, sliders, tabs, images, plots, and all the rest. This addresses key limitations of the standard model-as-person chat interface:<p>Oh boy I can&#x27;t wait for GPT Electron, so I can wait 60 seconds for the reply to come back and then another 60 seconds for it to render a sad face because I hit some guard rail.</div><br/><div id="42422263" class="c"><input type="checkbox" id="c-42422263" checked=""/><div class="controls bullet"><span class="by">Towaway69</span><span>|</span><a href="#42421956">parent</a><span>|</span><a href="#42422129">next</a><span>|</span><label class="collapse" for="c-42422263">[-]</label><label class="expand" for="c-42422263">[1 more]</label></div><br/><div class="children"><div class="content">Not forgetting the computing power required to generate that single sad face.</div><br/></div></div></div></div><div id="42422129" class="c"><input type="checkbox" id="c-42422129" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#42421956">prev</a><span>|</span><a href="#42421687">next</a><span>|</span><label class="collapse" for="c-42422129">[-]</label><label class="expand" for="c-42422129">[2 more]</label></div><br/><div class="children"><div class="content">Why stop there? Let it figure out how to please us without need for sliders etc. We&#x27;ll just relax. Now that&#x27;s paradigm shift.</div><br/><div id="42422276" class="c"><input type="checkbox" id="c-42422276" checked=""/><div class="controls bullet"><span class="by">Towaway69</span><span>|</span><a href="#42422129">parent</a><span>|</span><a href="#42421687">next</a><span>|</span><label class="collapse" for="c-42422276">[-]</label><label class="expand" for="c-42422276">[1 more]</label></div><br/><div class="children"><div class="content">That was my thought, is model as a computer the best we can do?<p>Isn’t that limiting our perspective of AIs models to being computers and what computers can’t do, so the model can’t do.</div><br/></div></div></div></div><div id="42421687" class="c"><input type="checkbox" id="c-42421687" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#42422129">prev</a><span>|</span><a href="#42421686">next</a><span>|</span><label class="collapse" for="c-42421687">[-]</label><label class="expand" for="c-42421687">[4 more]</label></div><br/><div class="children"><div class="content">I think that Cerebras and Groq would be fun to experiment with using normal LLMs for generating interfaces on the fly, since they are so fast.</div><br/><div id="42421757" class="c"><input type="checkbox" id="c-42421757" checked=""/><div class="controls bullet"><span class="by">FezzikTheGiant</span><span>|</span><a href="#42421687">parent</a><span>|</span><a href="#42421686">next</a><span>|</span><label class="collapse" for="c-42421757">[-]</label><label class="expand" for="c-42421757">[3 more]</label></div><br/><div class="children"><div class="content">what&#x27;s the cost difference between groq&#x2F;cerebras vs using something else for inferencing open source models? I&#x27;m guessing the speed comes at a cost?</div><br/><div id="42421776" class="c"><input type="checkbox" id="c-42421776" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#42421687">root</a><span>|</span><a href="#42421757">parent</a><span>|</span><a href="#42421686">next</a><span>|</span><label class="collapse" for="c-42421776">[-]</label><label class="expand" for="c-42421776">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know off the top of my head, only played with it a little not seriously.</div><br/><div id="42421954" class="c"><input type="checkbox" id="c-42421954" checked=""/><div class="controls bullet"><span class="by">FezzikTheGiant</span><span>|</span><a href="#42421687">root</a><span>|</span><a href="#42421776">parent</a><span>|</span><a href="#42421686">next</a><span>|</span><label class="collapse" for="c-42421954">[-]</label><label class="expand" for="c-42421954">[1 more]</label></div><br/><div class="children"><div class="content">fair enough</div><br/></div></div></div></div></div></div></div></div><div id="42421686" class="c"><input type="checkbox" id="c-42421686" checked=""/><div class="controls bullet"><span class="by">FezzikTheGiant</span><span>|</span><a href="#42421687">prev</a><span>|</span><a href="#42422218">next</a><span>|</span><label class="collapse" for="c-42421686">[-]</label><label class="expand" for="c-42421686">[2 more]</label></div><br/><div class="children"><div class="content">i think lots of apps are going to go in the adaptive&#x2F;generate ui direction - even if it starts a lot simpler than generating the code</div><br/><div id="42422288" class="c"><input type="checkbox" id="c-42422288" checked=""/><div class="controls bullet"><span class="by">Towaway69</span><span>|</span><a href="#42421686">parent</a><span>|</span><a href="#42422218">next</a><span>|</span><label class="collapse" for="c-42422288">[-]</label><label class="expand" for="c-42422288">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps an UI passed on a Salvador Dali painting - perhaps we should also be questioning our UI concepts of slider, button, window and co.</div><br/></div></div></div></div><div id="42422218" class="c"><input type="checkbox" id="c-42422218" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#42421686">prev</a><span>|</span><a href="#42421920">next</a><span>|</span><label class="collapse" for="c-42422218">[-]</label><label class="expand" for="c-42422218">[2 more]</label></div><br/><div class="children"><div class="content">Amateur question: is there a point possible where a llm is using less compute power to calculate a certain formula compared to regular computation?</div><br/><div id="42422352" class="c"><input type="checkbox" id="c-42422352" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#42422218">parent</a><span>|</span><a href="#42421920">next</a><span>|</span><label class="collapse" for="c-42422352">[-]</label><label class="expand" for="c-42422352">[1 more]</label></div><br/><div class="children"><div class="content">When the LLM knows how to simplify&#x2F;solve the formula and the person using it doesn&#x27;t, it could be much more efficient than directly running the brute-force&#x2F;inefficient version provided by the user. A simple example would be summing all numbers from 0 to a billion; if you ask o1 to do this, it uses the O(1) analytical solution, rather than the naive brute-force O(n) approach.</div><br/></div></div></div></div><div id="42421920" class="c"><input type="checkbox" id="c-42421920" checked=""/><div class="controls bullet"><span class="by">deadbabe</span><span>|</span><a href="#42422218">prev</a><span>|</span><a href="#42421544">next</a><span>|</span><label class="collapse" for="c-42421920">[-]</label><label class="expand" for="c-42421920">[2 more]</label></div><br/><div class="children"><div class="content">“Wherever they use AI as a tool they will, in the end, do the same with human beings.”</div><br/><div id="42421940" class="c"><input type="checkbox" id="c-42421940" checked=""/><div class="controls bullet"><span class="by">falcor84</span><span>|</span><a href="#42421920">parent</a><span>|</span><a href="#42421544">next</a><span>|</span><label class="collapse" for="c-42421940">[-]</label><label class="expand" for="c-42421940">[1 more]</label></div><br/><div class="children"><div class="content">Why is that in quote marks? I couldn&#x27;t find any matches in TFA nor elsewhere.<p>And as to the sentence itself,  I&#x27;m unclear on what exactly it&#x27;s saying; people have been using other people at tools from before recorded history. Leaving aside slavery, what is it that you would say that HR departments and capitalism in general do?</div><br/></div></div></div></div><div id="42421544" class="c"><input type="checkbox" id="c-42421544" checked=""/><div class="controls bullet"><span class="by">t0lo</span><span>|</span><a href="#42421920">prev</a><span>|</span><label class="collapse" for="c-42421544">[-]</label><label class="expand" for="c-42421544">[1 more]</label></div><br/><div class="children"><div class="content">Gotten to a point where i have a visceral reaction to any intersection of AI and Psychological thought. As a human it dependably makes me feel sick. We&#x27;re going to see a lot of changes that are good, and not so good.</div><br/></div></div></div></div></div></div></div></body></html>