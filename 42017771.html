<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1730538068481" as="style"/><link rel="stylesheet" href="styles.css?v=1730538068481"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html">Using Large Language Models to Catch Vulnerabilities</a> <span class="domain">(<a href="https://googleprojectzero.blogspot.com">googleprojectzero.blogspot.com</a>)</span></div><div class="subtext"><span>sigmar</span> | <span>18 comments</span></div><br/><div><div id="42019957" class="c"><input type="checkbox" id="c-42019957" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#42023024">next</a><span>|</span><label class="collapse" for="c-42019957">[-]</label><label class="expand" for="c-42019957">[8 more]</label></div><br/><div class="children"><div class="content">The work is impressive, but I wish Google wouldn&#x27;t try so hard to claim to be the world first at everything.  This claim feels extremely unprincipled:<p>&gt; We believe this is the first public example of an AI agent finding a previously unknown exploitable memory-safety issue in widely used real-world software. Earlier this year at the DARPA AIxCC event, Team Atlanta discovered a null-pointer dereference in SQLite, which inspired us to use it for our testing to see if we could find a more serious vulnerability.<p>Every word in &quot;public example of an AI agent finding a previously unknown exploitable memory-safety issue in widely used real-world software&quot; applies to the Team Atlanta finding that they are citing too, and the Team Atlanta finding was against an actual release version of SQLite instead of a prerelease.   If either team has provided the first example of this convoluted sentence, it is Team Atlanta, not Google.<p>It is possible that they&#x27;re arguing that the Team Atlanta finding wasn&#x27;t &quot;exploitable&quot;, but this is very debatable.  We use CVSS to rate vulnerability impact, and CVSS defines Availability (crashing) as an equal member of the [Confidentiality, Integrity, Availability] triad.  Being able to crash a system constitutes an exploitable vulnerability in that system.  This is surely especially true for SQLite, which is one of the most mission-critical production software systems in the entire world.<p>But if we&#x27;re going to act like we&#x27;re being very precise about what &quot;exploitable&quot; means, we should conclude that <i>neither</i> of these are exploitable vulnerabilities.  To exploit them, you have to provide malicious SQL queries to SQLite.  Who does that?  Attackers don&#x27;t provide SQL queries to SQLite systems -- the developers do.  If an attacker could provide arbitrary SQL queries, they can probably <i>already</i> exploit that SQLite system, through something like an arbitrary file content write to an arbitrary local filename into RCE.  I don&#x27;t think either group found an exploitable vulnerability.</div><br/><div id="42020671" class="c"><input type="checkbox" id="c-42020671" checked=""/><div class="controls bullet"><span class="by">jnwatson</span><span>|</span><a href="#42019957">parent</a><span>|</span><a href="#42023762">next</a><span>|</span><label class="collapse" for="c-42020671">[-]</label><label class="expand" for="c-42020671">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Attackers don&#x27;t provide SQL queries to SQLite systems -- the developers do.&quot;<p>Yet SQL injection is still a thing. Any vuln that can promote an SQL injection to an RCE is very bad.</div><br/><div id="42021133" class="c"><input type="checkbox" id="c-42021133" checked=""/><div class="controls bullet"><span class="by">moyix</span><span>|</span><a href="#42019957">root</a><span>|</span><a href="#42020671">parent</a><span>|</span><a href="#42022374">next</a><span>|</span><label class="collapse" for="c-42021133">[-]</label><label class="expand" for="c-42021133">[1 more]</label></div><br/><div class="children"><div class="content">Note that the vulnerable extension is only enabled in the sqlite shell:<p>&gt; However, the generate_series extension is only enabled by default in the shell binary and not the library itself, so the impact of the issue is limited.<p><a href="https:&#x2F;&#x2F;project-zero.issues.chromium.org&#x2F;issues&#x2F;372435124" rel="nofollow">https:&#x2F;&#x2F;project-zero.issues.chromium.org&#x2F;issues&#x2F;372435124</a></div><br/></div></div><div id="42022374" class="c"><input type="checkbox" id="c-42022374" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#42019957">root</a><span>|</span><a href="#42020671">parent</a><span>|</span><a href="#42021133">prev</a><span>|</span><a href="#42023762">next</a><span>|</span><label class="collapse" for="c-42022374">[-]</label><label class="expand" for="c-42022374">[2 more]</label></div><br/><div class="children"><div class="content">(Are you sure that SQLite attempts to protect against RCE from an attacker who can run fully arbitrary queries? I would be surprised.)</div><br/><div id="42024602" class="c"><input type="checkbox" id="c-42024602" checked=""/><div class="controls bullet"><span class="by">StrauXX</span><span>|</span><a href="#42019957">root</a><span>|</span><a href="#42022374">parent</a><span>|</span><a href="#42023762">next</a><span>|</span><label class="collapse" for="c-42024602">[-]</label><label class="expand" for="c-42024602">[1 more]</label></div><br/><div class="children"><div class="content">I sure hope they do. Security doesn&#x27;t end at the gates, so to speak. It starts there. We need layered security to create systems where not every hack has critical impact.</div><br/></div></div></div></div></div></div><div id="42023762" class="c"><input type="checkbox" id="c-42023762" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#42019957">parent</a><span>|</span><a href="#42020671">prev</a><span>|</span><a href="#42021629">next</a><span>|</span><label class="collapse" for="c-42023762">[-]</label><label class="expand" for="c-42023762">[1 more]</label></div><br/><div class="children"><div class="content">Re first AI finding vulnerabilities<p>What came to mind was the DARPA Cyber Grand Challenge. The winner was a product used in the real world, too.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;2016_Cyber_Grand_Challenge#:~:text=in%20prize%20money.-,Final%20results,and%20UVa%2C%20Charlottesville%2C%20Va" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;2016_Cyber_Grand_Challenge#:...</a>.<p><a href="https:&#x2F;&#x2F;www.mayhem.security&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.mayhem.security&#x2F;</a></div><br/></div></div><div id="42021629" class="c"><input type="checkbox" id="c-42021629" checked=""/><div class="controls bullet"><span class="by">rot69</span><span>|</span><a href="#42019957">parent</a><span>|</span><a href="#42023762">prev</a><span>|</span><a href="#42020874">next</a><span>|</span><label class="collapse" for="c-42021629">[-]</label><label class="expand" for="c-42021629">[1 more]</label></div><br/><div class="children"><div class="content">WebSQL?<p><a href="https:&#x2F;&#x2F;blog.exodusintel.com&#x2F;2019&#x2F;01&#x2F;22&#x2F;exploiting-the-magellan-bug-on-64-bit-chrome-desktop&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.exodusintel.com&#x2F;2019&#x2F;01&#x2F;22&#x2F;exploiting-the-magel...</a></div><br/></div></div><div id="42020874" class="c"><input type="checkbox" id="c-42020874" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42019957">parent</a><span>|</span><a href="#42021629">prev</a><span>|</span><a href="#42023024">next</a><span>|</span><label class="collapse" for="c-42020874">[-]</label><label class="expand" for="c-42020874">[1 more]</label></div><br/><div class="children"><div class="content">I couldn&#x27;t believe this, even all the poorly-defined qualifiers, given maximal charity, don&#x27;t really help.<p>The whole thing has the scent of &quot;we were told to get an outcome, eventually got it, and wrote it up!&quot; --- I&#x27;ve never ever read a Project Zero blog post like this,* and I believe they should be ashamed of putting glorified marketing on it.<p>* large # of contributors with unclear contributions (they&#x27;re probably building the agent Google is supposed to sell someday), ~0 explication of the bug, then gives up altogether on writing and splats in selected LLM responses.<p>* disclaimer: ex-Googler, only reason it matters here is I tend to jump to &#x27;and this is a corruption of Google&#x27; because it feels to me like it was a different place when I joined, but either A) it wasn&#x27;t or B) we should all be afraid of drift over time in organizations &gt; 1000 people</div><br/></div></div></div></div><div id="42023024" class="c"><input type="checkbox" id="c-42023024" checked=""/><div class="controls bullet"><span class="by">jumploops</span><span>|</span><a href="#42019957">prev</a><span>|</span><a href="#42021120">next</a><span>|</span><label class="collapse" for="c-42023024">[-]</label><label class="expand" for="c-42023024">[2 more]</label></div><br/><div class="children"><div class="content">We have a “poor man’s” version of this running as a GitHub Action on our PRs[0].<p>It basically just takes the diff from the PR and sends it to GPT-4o for analysis, returning a severity (low&#x2F;medium&#x2F;high) and a description.<p>PRs are auto-blocked for high severity, but can be merged with medium or low.<p>In practice it’s mostly right, but definitely errs on the side of medium too often (which is reasonable without the additional context of the rest of the codebase).<p>With that said, it’s been pretty useful at uncovering simple mistakes before another dev has had a chance to review.<p>[0] <a href="https:&#x2F;&#x2F;magicloops.dev&#x2F;loop&#x2F;3f3781f3-f987-4672-8500-bacbeefca6db&#x2F;view">https:&#x2F;&#x2F;magicloops.dev&#x2F;loop&#x2F;3f3781f3-f987-4672-8500-bacbeefc...</a></div><br/><div id="42024281" class="c"><input type="checkbox" id="c-42024281" checked=""/><div class="controls bullet"><span class="by">ctxc</span><span>|</span><a href="#42023024">parent</a><span>|</span><a href="#42021120">next</a><span>|</span><label class="collapse" for="c-42024281">[-]</label><label class="expand" for="c-42024281">[1 more]</label></div><br/><div class="children"><div class="content">Looks cool!</div><br/></div></div></div></div><div id="42021120" class="c"><input type="checkbox" id="c-42021120" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42023024">prev</a><span>|</span><a href="#42024614">next</a><span>|</span><label class="collapse" for="c-42021120">[-]</label><label class="expand" for="c-42021120">[1 more]</label></div><br/><div class="children"><div class="content">I think the key insight from this is:<p>&gt; We also feel that this variant-analysis task is a better fit for current LLMs than the more general open-ended vulnerability research problem. By providing a starting point – such as the details of a previously fixed vulnerability – we remove a lot of ambiguity from vulnerability research, and start from a concrete, well-founded theory: &quot;This was a previous bug; there is probably another similar one somewhere&quot;.<p>LLMs are great at pattern matching, so it turns out feeding in a pattern describing a prior vulnerability is a great way to identify potential new ones.</div><br/></div></div><div id="42024614" class="c"><input type="checkbox" id="c-42024614" checked=""/><div class="controls bullet"><span class="by">princearthur</span><span>|</span><a href="#42021120">prev</a><span>|</span><a href="#42022133">next</a><span>|</span><label class="collapse" for="c-42024614">[-]</label><label class="expand" for="c-42024614">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m excited at the prospect of LLMs being deployed here. An attacker only needs to find one weak link in the chain. Eliminating weak links is hard, and might be NP-complete.<p>However, throw resources at it and you might just make weak links much rarer. Throw a variety of heterogenous LLMs at it, and you might be looking at a large force multiplier.</div><br/></div></div><div id="42022133" class="c"><input type="checkbox" id="c-42022133" checked=""/><div class="controls bullet"><span class="by">maxtoulouse31</span><span>|</span><a href="#42024614">prev</a><span>|</span><a href="#42018332">next</a><span>|</span><label class="collapse" for="c-42022133">[-]</label><label class="expand" for="c-42022133">[1 more]</label></div><br/><div class="children"><div class="content">Shameless self-plug here, however two years ago I attempted a self study project following a similar intuition:<p><a href="https:&#x2F;&#x2F;maxdunhill.medium.com&#x2F;how-effective-are-transformers-at-detecting-vulnerable-code-f23ed443c017" rel="nofollow">https:&#x2F;&#x2F;maxdunhill.medium.com&#x2F;how-effective-are-transformers...</a><p>And created a Hugging Face repo of known vulnerabilities if anyone else wants to work on a similar project (link in blog post).<p>My project was a lay person’s not especially successful attempt to fine-tune a BERT-based classifier to detect vulnerable code.<p>Having said this, a main takeaway echoes simonw’s comment:<p>“LLMs are great at pattern matching, so it turns out feeding in a pattern describing a prior vulnerability is a great way to identify potential new ones.”<p>Given majority of vulnerabilities stem from memory misallocation, it seems that an LLM would most consistently find misallocated memory. Useful, though not the most complex vulnerabilities to weaponise.<p>It seems the next frontier would be for an LLM to not only identify previously unidentified vulnerabilities, but also describe how to successfully daisy chain them into an effective vulnerability exploitation.<p>Said differently, giving an LLM a goal like jail breaking the iOS sandbox and seeing how it might approach solving the task.</div><br/></div></div><div id="42018332" class="c"><input type="checkbox" id="c-42018332" checked=""/><div class="controls bullet"><span class="by">sigmar</span><span>|</span><a href="#42022133">prev</a><span>|</span><a href="#42021580">next</a><span>|</span><label class="collapse" for="c-42018332">[-]</label><label class="expand" for="c-42018332">[2 more]</label></div><br/><div class="children"><div class="content">TL;DR P0 collaborated with DeepMind to make &quot;Big Sleep,&quot; which is an AI agent (using gemini 1.5 pro) that can look through commits, spot potential issues, and then run testcases to find bugs. The agent found one in SQLite that was recent enough that it hadn&#x27;t made it into an official release yet. They then tried to see if it could have been found with AFL, the fuzzer didn&#x27;t find the issue after 150 cpu-hours.</div><br/><div id="42023720" class="c"><input type="checkbox" id="c-42023720" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#42018332">parent</a><span>|</span><a href="#42021580">next</a><span>|</span><label class="collapse" for="c-42023720">[-]</label><label class="expand" for="c-42023720">[1 more]</label></div><br/><div class="children"><div class="content">Using a fuzzer was a terrible point of comparison. They’re the slowest, heaviest users of resources. They’d be better off comparing to static analyzers which find bugs fast. In this case, Infer might do since it’s designed to catch those errors.<p>My concept was running a bunch of open-source, static analyzers with the LLM’s essentially blocking false positives. They can do it analytically or by generating the test cases to prove the bug. It might also be easier to fine-tune open models for this since the job is narrower.</div><br/></div></div></div></div><div id="42021580" class="c"><input type="checkbox" id="c-42021580" checked=""/><div class="controls bullet"><span class="by">coding123</span><span>|</span><a href="#42018332">prev</a><span>|</span><label class="collapse" for="c-42021580">[-]</label><label class="expand" for="c-42021580">[2 more]</label></div><br/><div class="children"><div class="content">Most code ought to be replaced with llm generated and then reviewed by a number of additional llms</div><br/><div id="42022347" class="c"><input type="checkbox" id="c-42022347" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#42021580">parent</a><span>|</span><label class="collapse" for="c-42022347">[-]</label><label class="expand" for="c-42022347">[1 more]</label></div><br/><div class="children"><div class="content">Is that you Elon?</div><br/></div></div></div></div></div></div></div></div></div></body></html>