<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709370077097" as="style"/><link rel="stylesheet" href="styles.css?v=1709370077097"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://matduggan.com/k8s-service-meshes/">K8s Service Meshes: The Bill Comes Due</a> <span class="domain">(<a href="https://matduggan.com">matduggan.com</a>)</span></div><div class="subtext"><span>zdw</span> | <span>73 comments</span></div><br/><div><div id="39570367" class="c"><input type="checkbox" id="c-39570367" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#39570291">next</a><span>|</span><label class="collapse" for="c-39570367">[-]</label><label class="expand" for="c-39570367">[9 more]</label></div><br/><div class="children"><div class="content">&gt; When you start using Kubernetes one of the first suggestions you&#x27;ll get is to install a service mesh.<p>Who on earth is giving you this advice? Service-messages are squarely in the “you’ll know when you need it, and it’s not day 1” bucket.<p>Is this the experience people are having with K8s? Welcome to Kubernetes, here’s a service mesh gl;hf. If this advice is common, no wonder some people think K8s is over complicated.<p>To anyone not aware: it _does not_ have to be this complicated. Default ingress controller and a normal Deployment will carry you really, really far.</div><br/><div id="39570794" class="c"><input type="checkbox" id="c-39570794" checked=""/><div class="controls bullet"><span class="by">moondev</span><span>|</span><a href="#39570367">parent</a><span>|</span><a href="#39570418">next</a><span>|</span><label class="collapse" for="c-39570794">[-]</label><label class="expand" for="c-39570794">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sad this is the top comment on an incredibly detailed and well researched article.<p>The context of the content is obviously for Kubernetes enterprise platform teams and not deploying your first nginx pod. The author also gives specific examples of why a service mesh is useful and in what scenarios it shines.</div><br/><div id="39571136" class="c"><input type="checkbox" id="c-39571136" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#39570367">root</a><span>|</span><a href="#39570794">parent</a><span>|</span><a href="#39570418">next</a><span>|</span><label class="collapse" for="c-39571136">[-]</label><label class="expand" for="c-39571136">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The author also gives specific examples of why a service mesh is useful and in what scenarios it shines.<p>The author&#x27;s entire point was money which is weird as it is peanuts compared to the DevOps salary of people needed to work with this complex setup. Unless you are in a startup and good in tech, in which case service mesh doesn&#x27;t make a lot of sense. Why do you need encryption or metrics collection above ingress. Nginx does a good enough job for metrics.</div><br/></div></div></div></div><div id="39570418" class="c"><input type="checkbox" id="c-39570418" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#39570367">parent</a><span>|</span><a href="#39570794">prev</a><span>|</span><a href="#39570491">next</a><span>|</span><label class="collapse" for="c-39570418">[-]</label><label class="expand" for="c-39570418">[1 more]</label></div><br/><div class="children"><div class="content">To answer your question, yes this is the majority of the experience and is almost a given decision in the initial setup, in part because of the security association. Especially in enterprises it&#x27;s easier to just say service mesh than have to think the decision through.<p>Regardless of service mesh though, although it&#x27;s a part of it, the complicated reputation is not undeserved and not solely due to meshes.</div><br/></div></div><div id="39570491" class="c"><input type="checkbox" id="c-39570491" checked=""/><div class="controls bullet"><span class="by">vbezhenar</span><span>|</span><a href="#39570367">parent</a><span>|</span><a href="#39570418">prev</a><span>|</span><a href="#39570448">next</a><span>|</span><label class="collapse" for="c-39570491">[-]</label><label class="expand" for="c-39570491">[2 more]</label></div><br/><div class="children"><div class="content">I have small cluster and the only reason I’d want service mesh is to inspect req&#x2F;resp between services for better debug. And I’m not even sure they can do that.<p>Retries for free are good I guess, but not something essential. MTLS is something I don’t want at all.</div><br/><div id="39570594" class="c"><input type="checkbox" id="c-39570594" checked=""/><div class="controls bullet"><span class="by">nullify88</span><span>|</span><a href="#39570367">root</a><span>|</span><a href="#39570491">parent</a><span>|</span><a href="#39570448">next</a><span>|</span><label class="collapse" for="c-39570594">[-]</label><label class="expand" for="c-39570594">[1 more]</label></div><br/><div class="children"><div class="content">Couldn&#x27;t you accomplish that with tracing? You may not even need any changes in your application as eBPF maybe able to automatically instrument the application.
Alternatively, If you use Cilium as a CNI, this functionality can come out the box. <a href="https:&#x2F;&#x2F;docs.cilium.io&#x2F;en&#x2F;latest&#x2F;observability&#x2F;visibility&#x2F;" rel="nofollow">https:&#x2F;&#x2F;docs.cilium.io&#x2F;en&#x2F;latest&#x2F;observability&#x2F;visibility&#x2F;</a></div><br/></div></div></div></div><div id="39570448" class="c"><input type="checkbox" id="c-39570448" checked=""/><div class="controls bullet"><span class="by">sofixa</span><span>|</span><a href="#39570367">parent</a><span>|</span><a href="#39570491">prev</a><span>|</span><a href="#39570823">next</a><span>|</span><label class="collapse" for="c-39570448">[-]</label><label class="expand" for="c-39570448">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If this advice is common, no wonder some people think K8s is over complicated<p>I mean, if even Google who were behind it in the first place, are saying it&#x27;s complicated and have 3 levels of managed Kubernetes services, I&#x27;d say it&#x27;s pretty clear to everyone it is indeed complicated. Some of the complexity is simply due to the complex problems it solves, some is footguns, some is layers upon layers of abstractions to glue around design deficiencies.<p>&gt; To anyone not aware: it _does not_ have to be this complicated. Default ingress controller and a normal Deployment will carry you really, really far<p>You&#x27;re absolutely right. However, Kubernetes is rarely chosen after a careful evaluation of requirements; it&#x27;s more often than not because it&#x27;s considered necessary or for resume driven development. In that case, service mesh is easy to tack on, regardless of need.</div><br/></div></div><div id="39570823" class="c"><input type="checkbox" id="c-39570823" checked=""/><div class="controls bullet"><span class="by">out-of-ideas</span><span>|</span><a href="#39570367">parent</a><span>|</span><a href="#39570448">prev</a><span>|</span><a href="#39570291">next</a><span>|</span><label class="collapse" for="c-39570823">[-]</label><label class="expand" for="c-39570823">[2 more]</label></div><br/><div class="children"><div class="content">its yet another tradeoff, it adds more security for the apps too, now your apps dont need to have tls stuff, you let the sidecar envoy-proxy handle that ect</div><br/><div id="39570882" class="c"><input type="checkbox" id="c-39570882" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#39570367">root</a><span>|</span><a href="#39570823">parent</a><span>|</span><a href="#39570291">next</a><span>|</span><label class="collapse" for="c-39570882">[-]</label><label class="expand" for="c-39570882">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I’m aware of how useful they can be, my comment was about for someone <i>first</i> introduction to K8s, they’re probably overkill.</div><br/></div></div></div></div></div></div><div id="39570291" class="c"><input type="checkbox" id="c-39570291" checked=""/><div class="controls bullet"><span class="by">jmspring</span><span>|</span><a href="#39570367">prev</a><span>|</span><a href="#39570351">next</a><span>|</span><label class="collapse" for="c-39570291">[-]</label><label class="expand" for="c-39570291">[6 more]</label></div><br/><div class="children"><div class="content">The article is about service meshes and the tradeoffs amongst them.  Going back several years, teams at companies ask about feature X - mtls a big one.  The discussion goes to - should we use a service mesh, often the answer was no.<p>K8s is a great platform with many options, but many decision makers have little knowledge (or don’t research) the implication of their choices.</div><br/><div id="39571038" class="c"><input type="checkbox" id="c-39571038" checked=""/><div class="controls bullet"><span class="by">mianos</span><span>|</span><a href="#39570291">parent</a><span>|</span><a href="#39570528">next</a><span>|</span><label class="collapse" for="c-39571038">[-]</label><label class="expand" for="c-39571038">[1 more]</label></div><br/><div class="children"><div class="content">It is worse than that. Many decision makers are making their decisions based on advice from people who fired up k8s and all its gadgets for their pet project or google.</div><br/></div></div><div id="39570528" class="c"><input type="checkbox" id="c-39570528" checked=""/><div class="controls bullet"><span class="by">billfor</span><span>|</span><a href="#39570291">parent</a><span>|</span><a href="#39571038">prev</a><span>|</span><a href="#39570403">next</a><span>|</span><label class="collapse" for="c-39570528">[-]</label><label class="expand" for="c-39570528">[2 more]</label></div><br/><div class="children"><div class="content">I read the article as being about service meshes now being a cost item whereas they were free or low cost. I’m not sure debating the technical merits speaks to that.</div><br/><div id="39570643" class="c"><input type="checkbox" id="c-39570643" checked=""/><div class="controls bullet"><span class="by">jmspring</span><span>|</span><a href="#39570291">root</a><span>|</span><a href="#39570528">parent</a><span>|</span><a href="#39570403">next</a><span>|</span><label class="collapse" for="c-39570643">[-]</label><label class="expand" for="c-39570643">[1 more]</label></div><br/><div class="children"><div class="content">There were technical components mentioned in the article.  Yes, cost comparison was the main thrust.</div><br/></div></div></div></div><div id="39570403" class="c"><input type="checkbox" id="c-39570403" checked=""/><div class="controls bullet"><span class="by">gnarbarian</span><span>|</span><a href="#39570291">parent</a><span>|</span><a href="#39570528">prev</a><span>|</span><a href="#39570351">next</a><span>|</span><label class="collapse" for="c-39570403">[-]</label><label class="expand" for="c-39570403">[2 more]</label></div><br/><div class="children"><div class="content">this is a personal attack</div><br/><div id="39570466" class="c"><input type="checkbox" id="c-39570466" checked=""/><div class="controls bullet"><span class="by">jmspring</span><span>|</span><a href="#39570291">root</a><span>|</span><a href="#39570403">parent</a><span>|</span><a href="#39570351">next</a><span>|</span><label class="collapse" for="c-39570466">[-]</label><label class="expand" for="c-39570466">[1 more]</label></div><br/><div class="children"><div class="content">How so?</div><br/></div></div></div></div></div></div><div id="39570351" class="c"><input type="checkbox" id="c-39570351" checked=""/><div class="controls bullet"><span class="by">n3storm</span><span>|</span><a href="#39570291">prev</a><span>|</span><a href="#39570048">next</a><span>|</span><label class="collapse" for="c-39570351">[-]</label><label class="expand" for="c-39570351">[2 more]</label></div><br/><div class="children"><div class="content">To me every of these sounds like &quot;why don&#x27;t we put 10ys(tm) inside ZFWs(tm) inside Funnylettes(tm) proxy-edge-borderline stuff so stuff is so messhy and uncomprehensible that you need an IA to explain your application deployment&quot;</div><br/><div id="39571063" class="c"><input type="checkbox" id="c-39571063" checked=""/><div class="controls bullet"><span class="by">lpapez</span><span>|</span><a href="#39570351">parent</a><span>|</span><a href="#39570048">next</a><span>|</span><label class="collapse" for="c-39571063">[-]</label><label class="expand" for="c-39571063">[1 more]</label></div><br/><div class="children"><div class="content">Same. I&#x27;ve never worked in infrastructure teams because I simply don&#x27;t care about this stuff, and I always find it funny how the infrastructure details tend to leak out to us application developers.<p>Come on, I just want to deploy my app somewhere. I don&#x27;t want to know about yamls and kubernetes, I just want a button where I deploy my branch.<p>It often feels like people working on infrastructure and platform development do it for it&#x27;s own sake, forgetting that they were supposed to be enablers for other teams building on top of it.</div><br/></div></div></div></div><div id="39570048" class="c"><input type="checkbox" id="c-39570048" checked=""/><div class="controls bullet"><span class="by">phildenhoff</span><span>|</span><a href="#39570351">prev</a><span>|</span><a href="#39570161">next</a><span>|</span><label class="collapse" for="c-39570048">[-]</label><label class="expand" for="c-39570048">[34 more]</label></div><br/><div class="children"><div class="content">good lord is this what modern microservices are like?<p>How is it better have service A request to a proxy, which requests to another proxy, which requests to service B? I get the security benefits of that, but the network architecture is boggling. How many PBs of data are sent each day for what could be a monolithic service?<p>Actually, to the end — companies that embrace microservices, which see the value in them. How do they manage network traffic for these kinds of K8s setups at scale? Surely they’re not using REST and HTTP. Is it as simple as protobufs over HTTP? Quic? Something else?<p>Edit: lots of great discussion below but I really meant how do they manage network TRAFFIC, not microservices in general :)</div><br/><div id="39570443" class="c"><input type="checkbox" id="c-39570443" checked=""/><div class="controls bullet"><span class="by">lukeschlather</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570101">next</a><span>|</span><label class="collapse" for="c-39570443">[-]</label><label class="expand" for="c-39570443">[3 more]</label></div><br/><div class="children"><div class="content">I really hate this pattern in principle, but it isn&#x27;t as bad as you&#x27;re making it out to be. Most of the service meshes operate as sidecars, which is to say that if service A is calling service B through a mesh, there are two proxies in between the services, but proxy A is on the same machine as A, and proxy B is on the same machine as proxy B. So it is kind of offensive to have 3 network hops involved, but actually only one of those is over the wire, and in most cases I don&#x27;t think the proxies are actually causing any measurable latency. (At least, whatever latency it&#x27;s causing is smaller than the latency caused by the TLS encryption, which is necessary and the whole point.)</div><br/><div id="39570614" class="c"><input type="checkbox" id="c-39570614" checked=""/><div class="controls bullet"><span class="by">phildenhoff</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570443">parent</a><span>|</span><a href="#39570531">prev</a><span>|</span><a href="#39570101">next</a><span>|</span><label class="collapse" for="c-39570614">[-]</label><label class="expand" for="c-39570614">[1 more]</label></div><br/><div class="children"><div class="content">That makes sense! I didn&#x27;t realise the proxies were sidecars, but that seems obvious in retrospect.</div><br/></div></div></div></div><div id="39570101" class="c"><input type="checkbox" id="c-39570101" checked=""/><div class="controls bullet"><span class="by">pm90</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570443">prev</a><span>|</span><a href="#39570250">next</a><span>|</span><label class="collapse" for="c-39570101">[-]</label><label class="expand" for="c-39570101">[8 more]</label></div><br/><div class="children"><div class="content">&gt; How is it better have service A request to a proxy, which requests to another proxy, which requests to service B? I get the security benefits of that, but the network architecture is boggling. How many PBs of data are sent each day for what could be a monolithic service?<p>The tradeoff here is to decouple services in order to allow them to be developed somewhat independently of each other. Monoliths remove the overhead of network requests but they present their own challenges. You have a lot of implicit dependencies and feature development becomes complicated with changes having unexpected effects very far from the source.<p>Ultimately engineering organizations need to decide the model that works best for them. Neither is inherently better, they’re solving different problems.</div><br/><div id="39570122" class="c"><input type="checkbox" id="c-39570122" checked=""/><div class="controls bullet"><span class="by">deathanatos</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570101">parent</a><span>|</span><a href="#39570797">next</a><span>|</span><label class="collapse" for="c-39570122">[-]</label><label class="expand" for="c-39570122">[4 more]</label></div><br/><div class="children"><div class="content">&gt; <i>The tradeoff here is to decouple services in order to allow them to be developed somewhat independently of each other.</i><p>You don&#x27;t need a service mesh for that, though? Heck, you don&#x27;t even need an ingress for service to service traffic. ingress-nginx does the job well, without being overly complex, and most importantly to me, logs when something is wrong, which I cannot say the same for Istio which I was fighting earlier this week where it was just happily RST&#x27;ing a connection and saying nothing about <i>why</i> it was deciding to do that.</div><br/><div id="39570204" class="c"><input type="checkbox" id="c-39570204" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570122">parent</a><span>|</span><a href="#39570797">next</a><span>|</span><label class="collapse" for="c-39570204">[-]</label><label class="expand" for="c-39570204">[3 more]</label></div><br/><div class="children"><div class="content">There are a lot of good and bad reasons to adopt a mesh. Some of which might relate to your concerns. The things I like most about them, working in infrastructur:<p>1. I can have a unified set of metrics for all services, regardless of language&#x2F;platform or how diligent the team is at instrumenting their apps.<p>2. I can guarantee zero trust with mTLS, without having to rely on application teams dealing with HTTPs or certificates.<p>3. I can implement automation around canary releases without much lift from dev teams. Other projects leverage these capabilities and do it for you as well.<p>4. I can get the equivalent of tcpdump for a pod pretty easily which I can use to help app teams debug issues.<p>5. I can improve app reliability with automatic retries and timeouts.<p>Probably some other things as well... That said, it can be a big increase in complexity to your system the pains of which aren&#x27;t always distributed to the folks getting the benefits.</div><br/><div id="39570243" class="c"><input type="checkbox" id="c-39570243" checked=""/><div class="controls bullet"><span class="by">deathanatos</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570204">parent</a><span>|</span><a href="#39571103">next</a><span>|</span><label class="collapse" for="c-39570243">[-]</label><label class="expand" for="c-39570243">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>1. I can have a unified set of metrics for all services, regardless of language&#x2F;platform or how diligent the team is at instrumenting their apps.</i><p>But they&#x27;re only going to be coarse metrics, like what requests&#x2F;second. You&#x27;re still going to be needing application-specific metrics.<p>&gt; <i>2. I can guarantee zero trust with mTLS, without having to rely on application teams dealing with HTTPs or certificates.</i><p>I do like the <i>idea</i> of this feature of service meshes. It is a slog to get teams to do this responsibly. But, like I said: fighting Istio to understand why it was RST-ing a connection, for no apparent reason. Not logging errors is worse. Perhaps the idea is sound, but the implementation leaves one desiring more.<p>I should mention the same Istio service mesh above is a SPoF in the cluster it runs in, on account of being a single pod. I can&#x27;t tell if the people who set it up were clueless, or if that&#x27;s the default. I suspect probably the latter.<p>&gt; <i>3., 4., and 5.</i>, as well as actually <i>using</i> mTLS in 2.<p>TBH, these are just benefits I&#x27;ve never been able to realize. I&#x27;m stuck slogging through the swamp of service mesh marketing and the people who want to bring the light of their savior the service mesh but without actually getting their hands dirty doing the work of deploying it.</div><br/></div></div><div id="39571103" class="c"><input type="checkbox" id="c-39571103" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570204">parent</a><span>|</span><a href="#39570243">prev</a><span>|</span><a href="#39570797">next</a><span>|</span><label class="collapse" for="c-39571103">[-]</label><label class="expand" for="c-39571103">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  I can guarantee zero trust with mTLS, without having to rely on application teams dealing with HTTPs or certificates.<p>ok, but what&#x27;s your threat model for this? great you can tie service versions to each other, but they are just proxies.</div><br/></div></div></div></div></div></div><div id="39570797" class="c"><input type="checkbox" id="c-39570797" checked=""/><div class="controls bullet"><span class="by">never_inline</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570101">parent</a><span>|</span><a href="#39570122">prev</a><span>|</span><a href="#39570334">next</a><span>|</span><label class="collapse" for="c-39570797">[-]</label><label class="expand" for="c-39570797">[1 more]</label></div><br/><div class="children"><div class="content">Can someone enlighten me on this: if Authorization policies (which pods can communicate with which services) was built in kube-proxy, wouldn&#x27;t it solve the use case for a large percent of service mesh deployments?</div><br/></div></div><div id="39570334" class="c"><input type="checkbox" id="c-39570334" checked=""/><div class="controls bullet"><span class="by">mdekkers</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570101">parent</a><span>|</span><a href="#39570797">prev</a><span>|</span><a href="#39570250">next</a><span>|</span><label class="collapse" for="c-39570334">[-]</label><label class="expand" for="c-39570334">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The tradeoff here is to decouple services in order to allow them to be developed somewhat independently of each other. Monoliths remove the overhead of network requests but they present their own challenges. You have a lot of implicit dependencies and feature development becomes complicated with changes having unexpected effects very far from the source.<p>I have seen, developed, designed, managed, deployed, operated, fondled, and otherwise been around thousands of large systems that are anything between trivial importance to “must always be running, in the national interest”.  I was around when SOAs were a hot new thing, and SOAP was being rumoured as the thing that was going to save us from everything. A fondly recall an overpaid Compaq consultant talking about “token passing systems” when they were describing message queues.<p>I have seen exactly two systems that really had to be designed and built along a microservice architecture. Both of these had requirements that introduces a scale, scope, and complexity you simply don’t see very often. All other microservice architectures didn’t solve for requirements, they solved for organisational inefficiencies, misalignments, mismanagement, and - in no small part - ego.<p>When discussing this topic, proponents of microservice proponents talk about many of the advantages these architectures bring, and they are often not completely wrong. What is lacking from these discussions is often a sense of perspective. “Is this solving real problems we have?”, “What is the compound lifecycle cost of this approach?”, and, of course, “How much work is involved in displaying the users’ birthday date in the settings page?”[1], and “when will Omega Star get their fucking shit together?!”[2].<p>Don’t start with microservices as the default. I will typically work out the monolithic approach as a point of departure. Want microservices? I’m open to that, just demonstrate how that will be better.<p>[1][2] <a href="https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=y8OnoxKotPQ" rel="nofollow">https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=y8OnoxKotPQ</a></div><br/><div id="39571116" class="c"><input type="checkbox" id="c-39571116" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570334">parent</a><span>|</span><a href="#39570250">next</a><span>|</span><label class="collapse" for="c-39571116">[-]</label><label class="expand" for="c-39571116">[1 more]</label></div><br/><div class="children"><div class="content">&gt; All other microservice architectures didn’t solve for requirements, they solved for organisational inefficiencies, misalignments, mismanagement, and - in no small part - ego.<p>Be developed, maintained, and operated by the real organization that exists and not an ideal organization which doesn&#x27;t is, in fact, usually a practical if not a theoretical requirement, and its usually easier to adapt architecture than to adapt organization.</div><br/></div></div></div></div></div></div><div id="39570250" class="c"><input type="checkbox" id="c-39570250" checked=""/><div class="controls bullet"><span class="by">deathanatos</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570101">prev</a><span>|</span><a href="#39570080">next</a><span>|</span><label class="collapse" for="c-39570250">[-]</label><label class="expand" for="c-39570250">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Edit: lots of great discussion below but I really meant how do they manage network TRAFFIC, not microservices in general :)</i><p>I don&#x27;t really understand the question you&#x27;re asking, but I think maybe the answer is that network pipes are just bigger than the scale most people are operating at? I don&#x27;t think anything I&#x27;ve ever done has really had <i>that</i> many qps, and if it has, it is more likely to raise an eyebrow that says &quot;who&#x27;s spamming requests&quot; more that &quot;I guess we&#x27;ve made it to the big time&quot;.<p>REST &amp; protobufs are orthogonal. Empirically, literally nobody is doing REST, and most things are just ad hoc, poorly to not-at-all defined JSON&#x2F;HTTP with a few HTTP verbs sprinkled in to make everyone feel good. It could be protobuf, too, if you like, but unless you have some truly gargantuan JSON, it really won&#x27;t matter in the end. Compression will make up enough of the difference in size on the network. Some languages don&#x27;t have to allocate the keys a billion times, too, though even in Python, it&#x27;s a while before it starts to hurt.<p>What I see more of is processes just inexplicably using gigabytes upon gigabytes of RAM, burning through whole years of CPU time for no particular reason before just dropping back to nominal levels like nothing happened, and dev teams that can&#x27;t coherently understand the disconnect between just how much power a modern machine has, and what their design doc says their process is supposed to do (hint: something that shouldn&#x27;t take that many resources).<p>I like microservices, but there should be strong areas of responsibility to them. For most companies, I think that&#x27;s ~2–3 services. At my current company, it&#x27;s ~2 services + a database, with the rest being things like cron jobs or <i>really</i> small services that are just various glue or infra tooling.</div><br/></div></div><div id="39570080" class="c"><input type="checkbox" id="c-39570080" checked=""/><div class="controls bullet"><span class="by">spockz</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570250">prev</a><span>|</span><a href="#39570078">next</a><span>|</span><label class="collapse" for="c-39570080">[-]</label><label class="expand" for="c-39570080">[3 more]</label></div><br/><div class="children"><div class="content">The data over the wire is the effect of having micro services and has little to do with service meshes. If anything, a service mesh could help by transparently enabling compression or upgrading to h3 without having to bake that in every app. Also, from a networking perspective, the proxies are hosted next to the instances so there is no difference there.<p>We run 1800 services in our mesh. Most of them rest&#x2F;http, a select few gRPC and graphql. We even have some soap&#x2F;http services in it.</div><br/><div id="39570104" class="c"><input type="checkbox" id="c-39570104" checked=""/><div class="controls bullet"><span class="by">slimsag</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570080">parent</a><span>|</span><a href="#39570078">next</a><span>|</span><label class="collapse" for="c-39570104">[-]</label><label class="expand" for="c-39570104">[2 more]</label></div><br/><div class="children"><div class="content">with 1800 services, do you feel like you are programming&#x2F;architecting code in the same way a complex monolithic codebase might, working across them all?<p>Or are the services just cogs in the machine, managed by individual devs &#x2F; cogs in the machine? I imagine the latter and presume that&#x27;s the main benefit of so many services, but genuinely curious as I&#x27;ve never experience that many services in an architecture</div><br/><div id="39571022" class="c"><input type="checkbox" id="c-39571022" checked=""/><div class="controls bullet"><span class="by">bostik</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570104">parent</a><span>|</span><a href="#39570078">next</a><span>|</span><label class="collapse" for="c-39571022">[-]</label><label class="expand" for="c-39571022">[1 more]</label></div><br/><div class="children"><div class="content">I would say it&#x27;s right about the middle of those two extremes.<p>A well functioning service mesh (or even just a well maintained and discoverable ingress controller) is essentially invisible to the individual dev teams. Just think how modern stacks work from a frontend dev&#x27;s perspective: team wants to use an additional feature, so they find the budgeted credit card, sign up to a random third-party provider, get their access token, and go. From the codebase standpoint, they merely added a new roundtrip to a random service and process the responses in their code.<p>From the dev team&#x27;s point of view, having the same feature available internally, behind &quot;just another URL&quot;, makes no big difference. Maybe less politics around vendor spend and, with luck, easier integration with the remote service auth. Almost certainly less wrangling with compliance and legal.<p>Whether that URL is provided by an ingress with a proper FQDN, or a service mesh entry with otherwise unresolvable name, is (and should be) irrelevant.<p>Modern distributed systems have long since become too large for any single person to fully comprehend them through and through. There is no Grand Design[tm], they are all results of organic changes and evolution. Service discovery and routing can be architected. Individual services within the system can be architected. The complete system where hundreds or even thousands of services interact can not.</div><br/></div></div></div></div></div></div><div id="39570078" class="c"><input type="checkbox" id="c-39570078" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570080">prev</a><span>|</span><a href="#39570342">next</a><span>|</span><label class="collapse" for="c-39570078">[-]</label><label class="expand" for="c-39570078">[4 more]</label></div><br/><div class="children"><div class="content"><i>&gt; How do they manage these kinds of K8s setups at scale?</i><p>Our DevOps team starts off the monthly all hands meeting by leading a ritual during which they ceremoniously sacrifice an animal from the Fish and Wildlife Service&#x27;s Threatened &amp; Endangered Species list while the rest of the company chants:<p><pre><code>    Exorcizamus te, omnis immundus spiritus
    omnis satanica potestas, omnis incursio
    infernalis adversarii, omnis legio,
    omnis congregatio et secta diabolica.</code></pre></div><br/><div id="39570228" class="c"><input type="checkbox" id="c-39570228" checked=""/><div class="controls bullet"><span class="by">vaporary</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570078">parent</a><span>|</span><a href="#39570127">next</a><span>|</span><label class="collapse" for="c-39570228">[-]</label><label class="expand" for="c-39570228">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Getting a SCSI chain working is perfectly simple if you remember that there must be exactly three terminations: one on one end of the cable, one on the far end, and the goat, terminated over the SCSI chain with a silver-handled knife whilst burning *black* candles.&quot;<p>-- Anthony DeBoer<p>&quot;SCSI is *not* magic. There are *fundamental* *technical* *reasons* why you have to sacrifice a young goat to your SCSI chain every now and then.&quot;<p>-- John F. Woods</div><br/></div></div><div id="39570127" class="c"><input type="checkbox" id="c-39570127" checked=""/><div class="controls bullet"><span class="by">jacinda</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570078">parent</a><span>|</span><a href="#39570228">prev</a><span>|</span><a href="#39570273">next</a><span>|</span><label class="collapse" for="c-39570127">[-]</label><label class="expand" for="c-39570127">[1 more]</label></div><br/><div class="children"><div class="content">I needed this laugh so much. Thank you.</div><br/></div></div><div id="39570273" class="c"><input type="checkbox" id="c-39570273" checked=""/><div class="controls bullet"><span class="by">zubairq</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570078">parent</a><span>|</span><a href="#39570127">prev</a><span>|</span><a href="#39570342">next</a><span>|</span><label class="collapse" for="c-39570273">[-]</label><label class="expand" for="c-39570273">[1 more]</label></div><br/><div class="children"><div class="content">haha, IT staff doing mystic chants reminds me of this video I made over a decade ago:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8Sj3_NfDYeU" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8Sj3_NfDYeU</a></div><br/></div></div></div></div><div id="39570342" class="c"><input type="checkbox" id="c-39570342" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570078">prev</a><span>|</span><a href="#39570099">next</a><span>|</span><label class="collapse" for="c-39570342">[-]</label><label class="expand" for="c-39570342">[2 more]</label></div><br/><div class="children"><div class="content">Traffic within a data center is relatively cheap, is it not? Of course, I think managed network proxies tend to be expensive, but I think that mostly comes from the machine costs, not the network itself. You pay a bit of a tax for network serialization, but it&#x27;s unlikely to be the bottleneck in most things ime.<p>Plus, applications built on an external database (e.g., postgres not sqlite) will already have 1 hop. Going from 1 to 2 hops is less dramatic than going from no hops to 1. And I guess implicitly any service sending lots of data to the client already has 1 hop.<p>Imo the only case where a network proxy would be egregious is an in memory database kind of workload where the response size is small relative to the size of the data accessed (maybe something like a custom analytics engine), but that&#x27;s pretty niche.</div><br/><div id="39570365" class="c"><input type="checkbox" id="c-39570365" checked=""/><div class="controls bullet"><span class="by">ozr</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570342">parent</a><span>|</span><a href="#39570099">next</a><span>|</span><label class="collapse" for="c-39570365">[-]</label><label class="expand" for="c-39570365">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Traffic within a data center is relatively cheap, is it not?<p>Complexity is very, very expensive.</div><br/></div></div></div></div><div id="39570099" class="c"><input type="checkbox" id="c-39570099" checked=""/><div class="controls bullet"><span class="by">__turbobrew__</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570342">prev</a><span>|</span><a href="#39570175">next</a><span>|</span><label class="collapse" for="c-39570099">[-]</label><label class="expand" for="c-39570099">[2 more]</label></div><br/><div class="children"><div class="content">&gt; How do they manage these kinds of K8s setups at scale?<p>You check in configs into the monorepo and there is tooling to continuously sync the configs with the actual state of the infrastructure.<p>The advantage of microservices at scale is that team X breaking the build doesn’t affect team Y. This scale is probably not until you have 1000+ engineers however.</div><br/><div id="39570170" class="c"><input type="checkbox" id="c-39570170" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570099">parent</a><span>|</span><a href="#39570175">next</a><span>|</span><label class="collapse" for="c-39570170">[-]</label><label class="expand" for="c-39570170">[1 more]</label></div><br/><div class="children"><div class="content">To be clear, that is the advantage of <i>services</i>. Microservices are a culture of taking that isolation as far as you can.</div><br/></div></div></div></div><div id="39570183" class="c"><input type="checkbox" id="c-39570183" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570175">prev</a><span>|</span><a href="#39570094">next</a><span>|</span><label class="collapse" for="c-39570183">[-]</label><label class="expand" for="c-39570183">[1 more]</label></div><br/><div class="children"><div class="content">&gt; for what could be a monolithic service<p>On larger projects:<p>a) It is sometimes impossible to run the entire application on a laptop. And so having a micro-service means you can quickly iterate and test before embedding it into the wider system.<p>b) You will commonly run into conflicting transitive dependencies which you simply can&#x27;t work around. Classic example being Spark on the JVM which brings in years old Hadoop libraries.<p>c) The inter-relationships between component can become so complex that you really want to be able to use canary or green&#x2F;blue deployment techniques to reduce risk.</div><br/></div></div><div id="39570094" class="c"><input type="checkbox" id="c-39570094" checked=""/><div class="controls bullet"><span class="by">de6u99er</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570183">prev</a><span>|</span><a href="#39570108">next</a><span>|</span><label class="collapse" for="c-39570094">[-]</label><label class="expand" for="c-39570094">[1 more]</label></div><br/><div class="children"><div class="content">The trick is to know which code you want to maintain yourself and which stuff you want to get off the shelf. Going the off the shelf way, also means being stateless and using distributed transactions with all their pitfalls (eventual consistency, fire and forget, ...).<p>Good architects will know how and when to do what  E.g. start with a modulith instead of a monolith, to ease refactoring into micro-services once user count goes through the roof and vertical scaling won&#x27;t do it any more.</div><br/></div></div><div id="39570108" class="c"><input type="checkbox" id="c-39570108" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570094">prev</a><span>|</span><a href="#39570478">next</a><span>|</span><label class="collapse" for="c-39570108">[-]</label><label class="expand" for="c-39570108">[4 more]</label></div><br/><div class="children"><div class="content">&gt; A request to a proxy, which requests to another proxy, which requests to service B?<p>I hesitate to tell you how many layers are between me an HN&#x27;s servers right now.</div><br/><div id="39570124" class="c"><input type="checkbox" id="c-39570124" checked=""/><div class="controls bullet"><span class="by">phildenhoff</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570108">parent</a><span>|</span><a href="#39570478">next</a><span>|</span><label class="collapse" for="c-39570124">[-]</label><label class="expand" for="c-39570124">[3 more]</label></div><br/><div class="children"><div class="content">Right but there are all those layers so that HNs one server can service your request and send a response.<p>How much traffic would be generated if, for every request to HN, six other requests fire? And every time you comment a cascade of requests fire in HNs imaginary K8s cluster?<p>It’s not that there is anything wrong with this, or that the tradeoff isn’t worth it… it’s just so much data flying back and forth over the wire.</div><br/><div id="39570396" class="c"><input type="checkbox" id="c-39570396" checked=""/><div class="controls bullet"><span class="by">aetimmes</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570124">parent</a><span>|</span><a href="#39570786">next</a><span>|</span><label class="collapse" for="c-39570396">[-]</label><label class="expand" for="c-39570396">[1 more]</label></div><br/><div class="children"><div class="content">Ultimately, in the age of massive cloud compute, the constraining resource in an organization is engineering hours, not CPU&#x2F;memory&#x2F;bandwidth. And even then, I&#x27;ve yet to encounter a system (outside of massively parallel MPI-based HPC) where saturating network pipes became the bottleneck for a system before CPU&#x2F;memory utilization.<p>Microservice architecture means there&#x27;s lot of data flying around, but it keeps local resource utilization predictable.</div><br/></div></div><div id="39570786" class="c"><input type="checkbox" id="c-39570786" checked=""/><div class="controls bullet"><span class="by">eptcyka</span><span>|</span><a href="#39570048">root</a><span>|</span><a href="#39570124">parent</a><span>|</span><a href="#39570396">prev</a><span>|</span><a href="#39570478">next</a><span>|</span><label class="collapse" for="c-39570786">[-]</label><label class="expand" for="c-39570786">[1 more]</label></div><br/><div class="children"><div class="content">Most often, the wire is virtual, its just copying bytes between processes.</div><br/></div></div></div></div></div></div><div id="39570478" class="c"><input type="checkbox" id="c-39570478" checked=""/><div class="controls bullet"><span class="by">dilyevsky</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570108">prev</a><span>|</span><a href="#39570163">next</a><span>|</span><label class="collapse" for="c-39570478">[-]</label><label class="expand" for="c-39570478">[1 more]</label></div><br/><div class="children"><div class="content">They manage traffic with “service meshes” which includes anything from relatively” basic” distributed iptables&#x2F;ipvs VIPs (kube-proxy) + dns to full-blown intercepting proxies a la istio&#x2F;linkerd</div><br/></div></div><div id="39570163" class="c"><input type="checkbox" id="c-39570163" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570478">prev</a><span>|</span><a href="#39570126">next</a><span>|</span><label class="collapse" for="c-39570163">[-]</label><label class="expand" for="c-39570163">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re asking some really good questions here<p>I find that microservices and this type of architecture have become a religion - you do it this way because you do it this way. You add another layer of complication because that&#x27;s what you do now. You add this product because that&#x27;s what you do now. Now you do it this way. Now you stop doing this thing and do this thing instead. It&#x27;s all proclamations and a truly insane level of complexity and often a truly stunningly low level of performance achieved from some very powerful hardware because everything is behind at least twenty layers of abstraction and you&#x27;re like, encrypting traffic which is just being passed between VMs which are on the same hardware, but because you can&#x27;t guarantee that they&#x27;re always on the same hardware you have to encrypt and use a proxy and... oh wow<p>Watching it from the outside is a bit exhausting, it just seems to be so much churn and overhead.</div><br/></div></div><div id="39570126" class="c"><input type="checkbox" id="c-39570126" checked=""/><div class="controls bullet"><span class="by">patcon</span><span>|</span><a href="#39570048">parent</a><span>|</span><a href="#39570163">prev</a><span>|</span><a href="#39570161">next</a><span>|</span><label class="collapse" for="c-39570126">[-]</label><label class="expand" for="c-39570126">[1 more]</label></div><br/><div class="children"><div class="content">Heh wait until you hear how the cell signalling and any biological process in your body works :) It&#x27;s an absolute clusterfuck of dependencies and side-effects. It&#x27;s like space bar heating functionality[1] all the way down...!<p>In my thinking, we might as well get used to the levels of indirection and complexity that AIs will be comfortable with. I suspect it will be more akin to what biological computation is &quot;comfortable&quot; with, and less like what our minds happen to prefer<p>But I digress :) yes, microservices strike me as wiiild<p>[1]: <a href="https:&#x2F;&#x2F;xkcd.com&#x2F;1172&#x2F;" rel="nofollow">https:&#x2F;&#x2F;xkcd.com&#x2F;1172&#x2F;</a></div><br/></div></div></div></div><div id="39570117" class="c"><input type="checkbox" id="c-39570117" checked=""/><div class="controls bullet"><span class="by">pm90</span><span>|</span><a href="#39570161">prev</a><span>|</span><a href="#39570180">next</a><span>|</span><label class="collapse" for="c-39570117">[-]</label><label class="expand" for="c-39570117">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Istio has become infamous among k8s infrastructure staff as being the cause of more problems than any other part of the stack<p>True in my opinion. Its very complicated and the docs are confusing af.</div><br/><div id="39570592" class="c"><input type="checkbox" id="c-39570592" checked=""/><div class="controls bullet"><span class="by">throwitaway222</span><span>|</span><a href="#39570117">parent</a><span>|</span><a href="#39570180">next</a><span>|</span><label class="collapse" for="c-39570592">[-]</label><label class="expand" for="c-39570592">[1 more]</label></div><br/><div class="children"><div class="content">At my last company the devops guy was installing istio for 2 years before he gave up. K8s by itself was just fine.</div><br/></div></div></div></div><div id="39570180" class="c"><input type="checkbox" id="c-39570180" checked=""/><div class="controls bullet"><span class="by">parhamn</span><span>|</span><a href="#39570117">prev</a><span>|</span><a href="#39570446">next</a><span>|</span><label class="collapse" for="c-39570180">[-]</label><label class="expand" for="c-39570180">[10 more]</label></div><br/><div class="children"><div class="content">I think people often don&#x27;t realize that depending on the language runtime, micro-services can easily be a must.<p>Most service boundaries at organizations are &quot;I need a different version of a pinned package we can&#x27;t upgrade.&quot;. This is common in languages where there is support for only using one version of a given package, and it&#x27;s worse if there isn&#x27;t a culture of preserving function APIs. E.g. any python company with pandas&#x2F;numpy in the stack will need to split the environments at some point in the future, no ifs ands or buts!</div><br/><div id="39570192" class="c"><input type="checkbox" id="c-39570192" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39570180">parent</a><span>|</span><a href="#39570267">next</a><span>|</span><label class="collapse" for="c-39570192">[-]</label><label class="expand" for="c-39570192">[5 more]</label></div><br/><div class="children"><div class="content">I have heard that the reason Docker (and containers in general) took off was that they solved the problem of Python&#x27;s awful package management. I didn&#x27;t believe it until I saw people put Python in production and have to deal with this. At this point, I would rather have a physical snake in my server racks than any Python code.</div><br/><div id="39570686" class="c"><input type="checkbox" id="c-39570686" checked=""/><div class="controls bullet"><span class="by">noitpmeder</span><span>|</span><a href="#39570180">root</a><span>|</span><a href="#39570192">parent</a><span>|</span><a href="#39570362">next</a><span>|</span><label class="collapse" for="c-39570686">[-]</label><label class="expand" for="c-39570686">[2 more]</label></div><br/><div class="children"><div class="content">Do we live in different worlds? Virtual environments solve 99% of all python packaging and installation use cases.</div><br/><div id="39571162" class="c"><input type="checkbox" id="c-39571162" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#39570180">root</a><span>|</span><a href="#39570686">parent</a><span>|</span><a href="#39570362">next</a><span>|</span><label class="collapse" for="c-39571162">[-]</label><label class="expand" for="c-39571162">[1 more]</label></div><br/><div class="children"><div class="content">I guess so. Virtual environments doesn&#x27;t solve any of the problems as python authors either don&#x27;t specify the version or their dependency author doesn&#x27;t specify it. Try running any of the program which is &gt;3 years old. I remember in one of the programs I needed to pin 10 dependency versions manually to make it run.</div><br/></div></div></div></div><div id="39570362" class="c"><input type="checkbox" id="c-39570362" checked=""/><div class="controls bullet"><span class="by">nurettin</span><span>|</span><a href="#39570180">root</a><span>|</span><a href="#39570192">parent</a><span>|</span><a href="#39570686">prev</a><span>|</span><a href="#39570267">next</a><span>|</span><label class="collapse" for="c-39570362">[-]</label><label class="expand" for="c-39570362">[2 more]</label></div><br/><div class="children"><div class="content">I have used python in production for years, multiple servers, multiple racks, and deployment has always been as simple as<p>.&#x2F;deploy.sh pull sync migrate seed restart<p>pull calls git pull, sync runs pipenv sync, migrate runs django migrate, seed runs django management command seed, restart calls systemctl --user restart</div><br/><div id="39570550" class="c"><input type="checkbox" id="c-39570550" checked=""/><div class="controls bullet"><span class="by">toomuchtodo</span><span>|</span><a href="#39570180">root</a><span>|</span><a href="#39570362">parent</a><span>|</span><a href="#39570267">next</a><span>|</span><label class="collapse" for="c-39570550">[-]</label><label class="expand" for="c-39570550">[1 more]</label></div><br/><div class="children"><div class="content">This was not my experience building infra for a startup heavily leveraging a Python monolith. It was painful AF (both when developing locally and deploying to VMs) and Docker made the deployment story palatable (build, push to hundreds of VMs, run).</div><br/></div></div></div></div></div></div><div id="39570267" class="c"><input type="checkbox" id="c-39570267" checked=""/><div class="controls bullet"><span class="by">jmspring</span><span>|</span><a href="#39570180">parent</a><span>|</span><a href="#39570192">prev</a><span>|</span><a href="#39570195">next</a><span>|</span><label class="collapse" for="c-39570267">[-]</label><label class="expand" for="c-39570267">[2 more]</label></div><br/><div class="children"><div class="content">“Microservices can easily be a must” please explain.<p>Your example talks of packaging issues.</div><br/><div id="39570307" class="c"><input type="checkbox" id="c-39570307" checked=""/><div class="controls bullet"><span class="by">LegibleCrimson</span><span>|</span><a href="#39570180">root</a><span>|</span><a href="#39570267">parent</a><span>|</span><a href="#39570195">next</a><span>|</span><label class="collapse" for="c-39570307">[-]</label><label class="expand" for="c-39570307">[1 more]</label></div><br/><div class="children"><div class="content">Microservices (or really services in general) solve some of these packaging issues.  If I have my application that depends on package A that pulls in dependency C version 1.x, and also on package B that pulls in dependency C version 2.x, this just doesn&#x27;t work in Python, and many other languages.  The only way to make it work is either rectify my dependencies so all my versions match (by running one of your dependencies out of date) or to split them up so my application is composed of one service that pulls in package A and another that pulls in package B, and have them talk over some IPC.</div><br/></div></div></div></div><div id="39570195" class="c"><input type="checkbox" id="c-39570195" checked=""/><div class="controls bullet"><span class="by">eptcyka</span><span>|</span><a href="#39570180">parent</a><span>|</span><a href="#39570267">prev</a><span>|</span><a href="#39570446">next</a><span>|</span><label class="collapse" for="c-39570195">[-]</label><label class="expand" for="c-39570195">[2 more]</label></div><br/><div class="children"><div class="content">Did you read the same article I did? How is this relevant?</div><br/><div id="39570206" class="c"><input type="checkbox" id="c-39570206" checked=""/><div class="controls bullet"><span class="by">parhamn</span><span>|</span><a href="#39570180">root</a><span>|</span><a href="#39570195">parent</a><span>|</span><a href="#39570446">next</a><span>|</span><label class="collapse" for="c-39570206">[-]</label><label class="expand" for="c-39570206">[1 more]</label></div><br/><div class="children"><div class="content">I meant to reply to &quot;good lord is this what modern microservices are like?&quot;.</div><br/></div></div></div></div></div></div><div id="39570446" class="c"><input type="checkbox" id="c-39570446" checked=""/><div class="controls bullet"><span class="by">qazxcvbnm</span><span>|</span><a href="#39570180">prev</a><span>|</span><a href="#39570154">next</a><span>|</span><label class="collapse" for="c-39570446">[-]</label><label class="expand" for="c-39570446">[2 more]</label></div><br/><div class="children"><div class="content">Not having worked with K8s, it seems to me a number of things that service meshes are capable of can be done by SDN (e.g. Tailscale, ZeroTier). As far as I&#x27;m aware, SDN can do encryption and service discovery (via things like custom DNS) just fine. Can someone explain to me the differences and tradeoffs involved?</div><br/><div id="39570462" class="c"><input type="checkbox" id="c-39570462" checked=""/><div class="controls bullet"><span class="by">ibotty</span><span>|</span><a href="#39570446">parent</a><span>|</span><a href="#39570154">next</a><span>|</span><label class="collapse" for="c-39570462">[-]</label><label class="expand" for="c-39570462">[1 more]</label></div><br/><div class="children"><div class="content">Cilium is a service mesh via being a SDN.  That&#x27;s hinted at in the article.</div><br/></div></div></div></div><div id="39570154" class="c"><input type="checkbox" id="c-39570154" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39570446">prev</a><span>|</span><a href="#39570164">next</a><span>|</span><label class="collapse" for="c-39570154">[-]</label><label class="expand" for="c-39570154">[4 more]</label></div><br/><div class="children"><div class="content">I am sort of surprised that the solution to encrypting your traffic isn&#x27;t using HTTPS internally, and people rolled these wild systems of proxies. It makes sense thinking about it now because you have no idea whether you need the encryption or not (two containers may be on the same host), but this seems to be a pyrrhic victory.<p>Once again, the bad implications of a seemingly good idea come to bite us.</div><br/><div id="39570186" class="c"><input type="checkbox" id="c-39570186" checked=""/><div class="controls bullet"><span class="by">sweetjuly</span><span>|</span><a href="#39570154">parent</a><span>|</span><a href="#39570433">next</a><span>|</span><label class="collapse" for="c-39570186">[-]</label><label class="expand" for="c-39570186">[2 more]</label></div><br/><div class="children"><div class="content">It does have some advantages in that you don&#x27;t have key material on every single server. How much this risk actually matters will vary. I suspect most enterprises would actually be relatively safe with their frontend certificates being compromised, though the same cannot be said about the actual compromise of the backend application.</div><br/><div id="39570224" class="c"><input type="checkbox" id="c-39570224" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#39570154">root</a><span>|</span><a href="#39570186">parent</a><span>|</span><a href="#39570433">next</a><span>|</span><label class="collapse" for="c-39570224">[-]</label><label class="expand" for="c-39570224">[1 more]</label></div><br/><div class="children"><div class="content">I assume you would either use self-signed certs or run a private CA to do this. You wouldn&#x27;t get the attestation benefits, but there&#x27;s no material of any value in each container if you do this. The encryption is the only benefit.<p>Reading that comment, I sort of understand why people don&#x27;t do this because it takes some understanding of HTTPS and cryptography to do this properly.</div><br/></div></div></div></div><div id="39570433" class="c"><input type="checkbox" id="c-39570433" checked=""/><div class="controls bullet"><span class="by">cyberax</span><span>|</span><a href="#39570154">parent</a><span>|</span><a href="#39570186">prev</a><span>|</span><a href="#39570164">next</a><span>|</span><label class="collapse" for="c-39570433">[-]</label><label class="expand" for="c-39570433">[1 more]</label></div><br/><div class="children"><div class="content">It boils down to the complexity of running an internal DNS and of issuing certificates. If you don&#x27;t do that, HTTPS is useful only for encryption against passive eavesdroppers.</div><br/></div></div></div></div><div id="39570164" class="c"><input type="checkbox" id="c-39570164" checked=""/><div class="controls bullet"><span class="by">throwawaaarrgh</span><span>|</span><a href="#39570154">prev</a><span>|</span><a href="#39570578">next</a><span>|</span><label class="collapse" for="c-39570164">[-]</label><label class="expand" for="c-39570164">[1 more]</label></div><br/><div class="children"><div class="content">Just like you probably shouldn&#x27;t be using K8s, you probably shouldn&#x27;t be using a service mesh. Only add it when you actually need it. You&#x27;ll know when that happens.</div><br/></div></div><div id="39570578" class="c"><input type="checkbox" id="c-39570578" checked=""/><div class="controls bullet"><span class="by">throwitaway222</span><span>|</span><a href="#39570164">prev</a><span>|</span><label class="collapse" for="c-39570578">[-]</label><label class="expand" for="c-39570578">[1 more]</label></div><br/><div class="children"><div class="content">K8S is quickly turning into BPML</div><br/></div></div></div></div></div></div></div></body></html>