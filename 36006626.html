<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1684573246943" as="style"/><link rel="stylesheet" href="styles.css?v=1684573246943"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://praeclarum.org/2023/05/19/webgpu-torch.html">PyTorch for WebGPU</a> <span class="domain">(<a href="https://praeclarum.org">praeclarum.org</a>)</span></div><div class="subtext"><span>mighdoll</span> | <span>63 comments</span></div><br/><div><div id="36007493" class="c"><input type="checkbox" id="c-36007493" checked=""/><div class="controls bullet"><span class="by">newhouseb</span><span>|</span><a href="#36007476">next</a><span>|</span><label class="collapse" for="c-36007493">[-]</label><label class="expand" for="c-36007493">[20 more]</label></div><br/><div class="children"><div class="content">I&#x27;m excited about this for probably different reasons than most: I think Typescript could be a more ergonomic way to develop ML models than Python because you can automatically infer and check tensor dimensions <i>while you are writing code!</i> Compare this to the mess of comments you usually see writing pytorch telling you that x is of shape [x, y, z].<p><pre><code>  &#x2F;&#x2F; An empty 3x4 matrix
  const tensorA = tensor([3, 4])
  
  &#x2F;&#x2F; An empty 4x5 matrix
  const tensorB = tensor([4, 5])

  const good = multiplyMatrix(tensorA, tensorB);
        ^
        Inferred type is Tensor&lt;readonly [3, 5]&gt;
  
  const bad = multiplyMatrix(tensorB, tensorA);
                             ^^^^^^^
                             Argument of type &#x27;Tensor&lt;readonly [4, 5]&gt;&#x27; is not 
                             assignable to parameter of type &#x27;[never, &quot;Differing 
                             types&quot;, 3 | 5]&#x27;.(2345)
</code></pre>
I prototyped this for PotatoGPT [1] and some kind stranger on the internet wrote up a more extensive take [2]. You can play with an early version on the Typescript playground here [3] (uses a twitter shortlink for brevity)<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;newhouseb&#x2F;potatogpt">https:&#x2F;&#x2F;github.com&#x2F;newhouseb&#x2F;potatogpt</a><p>[2] <a href="https:&#x2F;&#x2F;sebinsua.com&#x2F;type-safe-tensors" rel="nofollow">https:&#x2F;&#x2F;sebinsua.com&#x2F;type-safe-tensors</a><p>[3] <a href="https:&#x2F;&#x2F;t.co&#x2F;gUzzTl4AAN" rel="nofollow">https:&#x2F;&#x2F;t.co&#x2F;gUzzTl4AAN</a></div><br/><div id="36007729" class="c"><input type="checkbox" id="c-36007729" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36009666">next</a><span>|</span><label class="collapse" for="c-36007729">[-]</label><label class="expand" for="c-36007729">[2 more]</label></div><br/><div class="children"><div class="content">That work looks really interesting! I am also excited about type safety when it comes to tensors. My understanding was that this type safe approach to <i>tensor shape</i> had encountered issues because it was difficult&#x2F;impossible (maybe?) to reason about the shape of some common operators at compile time. But perhaps those operators are not really necessary. [0]<p>Some sort of typed &#x27;named tensor&#x27; that could be combined with einsum notation at runtime would be awesome, ie. (don&#x27;t really know TS&#x2F;JS well but pseudocode)<p><pre><code>  import { torch } from &#x27;pytorch&#x27; as t
  import { torch.nn } from &#x27;pytorch&#x27; as nn

  const tensorA: Tensor[Batch, Seq, Emb] = t.randn([10,10,10]) &#x2F;&#x2F; initialize tensor
  const transformLayer = nn.Einsum((Batch, Seq, Emb),(Emb)-&gt;(Batch, Seq))

  const tensorB: Tensor[Emb2] = t.randn([20])

  const transformedOutput = transformLayer(tensorA, tensorB) &#x2F;&#x2F; type error: Emb2 does not match Emb

</code></pre>
[0]: <a href="https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch&#x2F;issues&#x2F;26889">https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch&#x2F;issues&#x2F;26889</a></div><br/><div id="36007905" class="c"><input type="checkbox" id="c-36007905" checked=""/><div class="controls bullet"><span class="by">newhouseb</span><span>|</span><a href="#36007493">root</a><span>|</span><a href="#36007729">parent</a><span>|</span><a href="#36009666">next</a><span>|</span><label class="collapse" for="c-36007905">[-]</label><label class="expand" for="c-36007905">[1 more]</label></div><br/><div class="children"><div class="content">This is a great thread, thanks! Somehow I missed it when looking for prior art.<p>When I initially started implementing this I was hung up on similar concerns. For example in GPT2&#x2F;PotatoGPT the MLP player is 4x the width of the residual stream. I went down a rabbit hole of addition and multiplication in Typescript types (the type system is Turing complete, so it&#x27;s <i>technically</i> possible!) and after crashing my TS language server a bunch I switched tacticts.<p>Where I ended up was to use symbolic equivalence, which turned out to be more ergonomic anyway, i.e.<p><pre><code>  type Multiply&lt;A extends number, B extends number&gt; = 
    number &amp; { label: `${A} * ${B}` }
  const Multiply = &lt;A extends number, B extends number&gt;(a: A, b: B) =&gt; 
    a * b as Multiply&lt;A, B&gt;;
</code></pre>
such that<p><pre><code>  tensor([
    params.EmbeddingDimensions, &#x2F;&#x2F; This is a literal with known size
    Multiply(4, params.EmbeddingDimensions)] as const)
</code></pre>
is inferred as<p><pre><code>  Tensor&lt;readonly [768, Multiply&lt;4, 768&gt;]&gt;
</code></pre>
Notably, switching to a more symbolic approach makes it easier for type checking dimensions that can change at runtime, so something like:<p><pre><code>  tensor([Var(tokens.length, &#x27;Sequence Length&#x27;), 
          Multiply&lt;4, Var(tokens.length, &#x27;Sequence Length&#x27;)&gt;])
</code></pre>
infers as<p><pre><code>  Tensor&lt;readonly [
     Var&lt;&#x27;Sequence Length&#x27;&gt;, 
     Multiply&lt;4, Var&lt;&#x27;Sequence Length&#x27;&gt;&gt;]&gt; 
</code></pre>
And you&#x27;ll get all the same correctness constraints that you would if these were known dimensions.<p>The downside to this approach is that typescript won&#x27;t know that Multiply&lt;4, Var&lt;&#x27;A&#x27;&gt;&gt; is equivalent to Multiply&lt;Var&lt;&#x27;A&#x27;&gt;, 4&gt; but in practice I haven&#x27;t found this to be a problem.<p>Finally, on more complicated operators&#x2F;functions that compose dimensions from different variables Typescript is also very capable, albeit not the most ergonomic. You can check my code for matrix multiplication and Seb&#x27;s writeup for another example of a zip function).</div><br/></div></div></div></div><div id="36009666" class="c"><input type="checkbox" id="c-36009666" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36007729">prev</a><span>|</span><a href="#36008548">next</a><span>|</span><label class="collapse" for="c-36009666">[-]</label><label class="expand" for="c-36009666">[1 more]</label></div><br/><div class="children"><div class="content">That’s a good point, but I think python will be much more feasible because of operator overloading:<p>(x+y)*z&#x2F;3<p>vs<p>x.add(y).mul(z).div(3)<p>And that’s just a really simple example.<p>I’m also hopeful that pythons new variadic generic types make progress here in python.</div><br/></div></div><div id="36008548" class="c"><input type="checkbox" id="c-36008548" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36009666">prev</a><span>|</span><a href="#36007749">next</a><span>|</span><label class="collapse" for="c-36008548">[-]</label><label class="expand" for="c-36008548">[4 more]</label></div><br/><div class="children"><div class="content">Without multidimensional array slicing or operator overloading it seems like Typescript could never be anywhere near as ergonomic as Python for ML, despite its other advantages.</div><br/><div id="36008780" class="c"><input type="checkbox" id="c-36008780" checked=""/><div class="controls bullet"><span class="by">phailhaus</span><span>|</span><a href="#36007493">root</a><span>|</span><a href="#36008548">parent</a><span>|</span><a href="#36008643">next</a><span>|</span><label class="collapse" for="c-36008780">[-]</label><label class="expand" for="c-36008780">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the advantage of those &quot;ergonomics&quot; if you have to memorize all the quirks? With a language like Typescript, all those operations become explicit instead of implicit, letting you take full advantage of your IDE with autocomplete, documentation, and compile-time warnings. Python sacrifices all of those just to save a few keystrokes.</div><br/></div></div><div id="36008643" class="c"><input type="checkbox" id="c-36008643" checked=""/><div class="controls bullet"><span class="by">praeclarum</span><span>|</span><a href="#36007493">root</a><span>|</span><a href="#36008548">parent</a><span>|</span><a href="#36008780">prev</a><span>|</span><a href="#36007749">next</a><span>|</span><label class="collapse" for="c-36008643">[-]</label><label class="expand" for="c-36008643">[2 more]</label></div><br/><div class="children"><div class="content">Those are niceties and can be implemented with some small hacks. Most big nets do very little slicing. Lots of dimension permutations (transpose, reshape, and friends) but less slicing. I personally use a lot of slicing so will do my best to support a clean syntax.</div><br/><div id="36009898" class="c"><input type="checkbox" id="c-36009898" checked=""/><div class="controls bullet"><span class="by">tysam_and</span><span>|</span><a href="#36007493">root</a><span>|</span><a href="#36008643">parent</a><span>|</span><a href="#36007749">next</a><span>|</span><label class="collapse" for="c-36009898">[-]</label><label class="expand" for="c-36009898">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve come to believe over the last few years that slicing is one of the most critical parts of a good ML array framework for a number of things and I&#x27;ve used it heavily. PyTorch, if I understand correctly, still doesn&#x27;t have it right in terms of some forms of slice assignment and the handling of slice objects (please correct me if I&#x27;m wrong) though it is leagues better than tensorflow was.<p>I&#x27;ve written a lot of dataloader and such code over the last number of years, and the slicing was probably the most important (and most hair-pulling) parts for me. I&#x27;ve really debated writing my own wrapper at some point (if it is indeed worth the effort) just to keep my sanity, even if it is as the expense of some speed.</div><br/></div></div></div></div></div></div><div id="36007749" class="c"><input type="checkbox" id="c-36007749" checked=""/><div class="controls bullet"><span class="by">teruakohatu</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36008548">prev</a><span>|</span><a href="#36008361">next</a><span>|</span><label class="collapse" for="c-36007749">[-]</label><label class="expand" for="c-36007749">[1 more]</label></div><br/><div class="children"><div class="content">I think you are absolutely right. It&#x27;s easy to think you are supposed to use a [x y z] tensor when it expects a [z y x] and you don&#x27;t find out until runtime.<p>It would he even better if tensor dims from loaded models could be infered ahead of time in the editor.</div><br/></div></div><div id="36008361" class="c"><input type="checkbox" id="c-36008361" checked=""/><div class="controls bullet"><span class="by">saiojd</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36007749">prev</a><span>|</span><a href="#36007817">next</a><span>|</span><label class="collapse" for="c-36008361">[-]</label><label class="expand" for="c-36008361">[3 more]</label></div><br/><div class="children"><div class="content">Another thing that TS does nicely is object handling in general: dot access for objects attributes, object destructuring, typed objects for function options. In most ML projects I see a bunch of functions that look like:<p><pre><code>    def my_fn(x, **kwargs):
       ...
       return y_1, y_2, y_3
</code></pre>
Which is a pain because kwargs could be anything really + now every call site has to expect 3 return values exactly while knowing their order; there&#x27;s no way of adding an extra return value without changing everyone. In typescript the same function could look like:<p><pre><code>    function myFn(x, options = { someOption: 1 }) {
       ...
       return { y_1, y_2, y_3 };
    }
</code></pre>
Which is so much nicer because everything is typed with all types inferred automatically! And you don&#x27;t burden the call sites with values they don&#x27;t need:<p><pre><code>    const { y_1 } = myFn(x, { someOption: 1 });
</code></pre>
In Python, everyone mostly passes unbundled arguments through every function, and changing anything involves threading these untyped arguments through a bunch of untyped call sites, its not the end of the world but we can do better...</div><br/><div id="36008637" class="c"><input type="checkbox" id="c-36008637" checked=""/><div class="controls bullet"><span class="by">praeclarum</span><span>|</span><a href="#36007493">root</a><span>|</span><a href="#36008361">parent</a><span>|</span><a href="#36007817">next</a><span>|</span><label class="collapse" for="c-36008637">[-]</label><label class="expand" for="c-36008637">[2 more]</label></div><br/><div class="children"><div class="content">I’m of the same opinion. While I think I will keep the standard parameter order from torch, I will include the options overload to give all the benefits you describe.</div><br/><div id="36008855" class="c"><input type="checkbox" id="c-36008855" checked=""/><div class="controls bullet"><span class="by">saiojd</span><span>|</span><a href="#36007493">root</a><span>|</span><a href="#36008637">parent</a><span>|</span><a href="#36007817">next</a><span>|</span><label class="collapse" for="c-36008855">[-]</label><label class="expand" for="c-36008855">[1 more]</label></div><br/><div class="children"><div class="content">Awesome :D Really nice project by the way</div><br/></div></div></div></div></div></div><div id="36007817" class="c"><input type="checkbox" id="c-36007817" checked=""/><div class="controls bullet"><span class="by">a1371</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36008361">prev</a><span>|</span><a href="#36007925">next</a><span>|</span><label class="collapse" for="c-36007817">[-]</label><label class="expand" for="c-36007817">[3 more]</label></div><br/><div class="children"><div class="content">I really hope that takes off because you are correct. Python though has such a fluid syntax that I&#x27;m not sure TS can match. For example when you want to sum two Numpy arrays, you just need the + operator, while that sort of thing is notoriously unpredictable in JS.</div><br/><div id="36008394" class="c"><input type="checkbox" id="c-36008394" checked=""/><div class="controls bullet"><span class="by">saiojd</span><span>|</span><a href="#36007493">root</a><span>|</span><a href="#36007817">parent</a><span>|</span><a href="#36008047">next</a><span>|</span><label class="collapse" for="c-36008394">[-]</label><label class="expand" for="c-36008394">[1 more]</label></div><br/><div class="children"><div class="content">Three.js works just fine with functions like `.add`, it sure is ugly though. It kind of blows the mind that javascript has had so many syntactic additions over the years but still has no operator overloading.</div><br/></div></div><div id="36008047" class="c"><input type="checkbox" id="c-36008047" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#36007493">root</a><span>|</span><a href="#36007817">parent</a><span>|</span><a href="#36008394">prev</a><span>|</span><a href="#36007925">next</a><span>|</span><label class="collapse" for="c-36008047">[-]</label><label class="expand" for="c-36008047">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if you could not do some operator overloading on the TS side to do some rewriting to get things like tensor addition on tensor types.<p>Heck, if you are doing that, maybe convert to webgpu automatically as well.<p>Someone very enterprising might do this in bun using zig.</div><br/></div></div></div></div><div id="36007925" class="c"><input type="checkbox" id="c-36007925" checked=""/><div class="controls bullet"><span class="by">nicoco</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36007817">prev</a><span>|</span><a href="#36009021">next</a><span>|</span><label class="collapse" for="c-36007925">[-]</label><label class="expand" for="c-36007925">[1 more]</label></div><br/><div class="children"><div class="content">I believe there is WIP to get python type annotations for arrays&#x2F;tensors shape, but it&#x27;s not a thing yet, indeed.</div><br/></div></div><div id="36009021" class="c"><input type="checkbox" id="c-36009021" checked=""/><div class="controls bullet"><span class="by">tehsauce</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36007925">prev</a><span>|</span><a href="#36008116">next</a><span>|</span><label class="collapse" for="c-36009021">[-]</label><label class="expand" for="c-36009021">[1 more]</label></div><br/><div class="children"><div class="content">If you want to do this today you can also use the torch c++ api! It’s whats pytorch binds to under the hood.</div><br/></div></div><div id="36008116" class="c"><input type="checkbox" id="c-36008116" checked=""/><div class="controls bullet"><span class="by">tzhenghao</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36009021">prev</a><span>|</span><a href="#36009186">next</a><span>|</span><label class="collapse" for="c-36008116">[-]</label><label class="expand" for="c-36008116">[2 more]</label></div><br/><div class="children"><div class="content">Just a little push back here, I think you strike on the right theme where a programming language could fill this gap. However, I wonder if new domain specific languages will eventually be the more elegant solution. Think Modular&#x27;s Mojo [1] or Meta&#x27;s KNYFE [2] mentioned earlier this week.<p>[1] - <a href="https:&#x2F;&#x2F;www.modular.com&#x2F;mojo" rel="nofollow">https:&#x2F;&#x2F;www.modular.com&#x2F;mojo</a>
[2] - <a href="https:&#x2F;&#x2F;ai.facebook.com&#x2F;blog&#x2F;meta-training-inference-accelerator-AI-MTIA&#x2F;" rel="nofollow">https:&#x2F;&#x2F;ai.facebook.com&#x2F;blog&#x2F;meta-training-inference-acceler...</a></div><br/><div id="36008153" class="c"><input type="checkbox" id="c-36008153" checked=""/><div class="controls bullet"><span class="by">newhouseb</span><span>|</span><a href="#36007493">root</a><span>|</span><a href="#36008116">parent</a><span>|</span><a href="#36009186">next</a><span>|</span><label class="collapse" for="c-36008153">[-]</label><label class="expand" for="c-36008153">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a great question. I don&#x27;t really have a horse in this race as long as whatever wins is maximally ergonomic. I think as long as the DSL is Turing complete such that you could &quot;compute&quot; on tensor shapes then we win. That said, it&#x27;s very easy to build a type system that isn&#x27;t so flexible (see most other languages) so I think it&#x27;d have to likely be a focus of the DSL from the get go.</div><br/></div></div></div></div><div id="36009186" class="c"><input type="checkbox" id="c-36009186" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#36007493">parent</a><span>|</span><a href="#36008116">prev</a><span>|</span><a href="#36007476">next</a><span>|</span><label class="collapse" for="c-36009186">[-]</label><label class="expand" for="c-36009186">[1 more]</label></div><br/><div class="children"><div class="content">Dependant types or it&#x27;s a toy.</div><br/></div></div></div></div><div id="36007476" class="c"><input type="checkbox" id="c-36007476" checked=""/><div class="controls bullet"><span class="by">crubier</span><span>|</span><a href="#36007493">prev</a><span>|</span><a href="#36006928">next</a><span>|</span><label class="collapse" for="c-36007476">[-]</label><label class="expand" for="c-36007476">[9 more]</label></div><br/><div class="children"><div class="content">This is huge! For me the one thing preventing Typescript to replace python is the lack of availability of CV ML libraries. WebGPU and this kind of libraries changes everything</div><br/><div id="36008923" class="c"><input type="checkbox" id="c-36008923" checked=""/><div class="controls bullet"><span class="by">SuboptimalEng</span><span>|</span><a href="#36007476">parent</a><span>|</span><a href="#36008080">next</a><span>|</span><label class="collapse" for="c-36008923">[-]</label><label class="expand" for="c-36008923">[6 more]</label></div><br/><div class="children"><div class="content">And operator overloading. TS code tends to look like this `c.add(b.add(a))` or `add(add(a, b), c)` instead of `a + b + c` as you might write in Python.<p>That was my biggest pain-point with using TS for graphics related projects. If operator overloading existed, then TS would be a no brainer for entry level graphics + AI&#x2F;ML projects.<p>Edit: This gets more complicated when doing operations that force you to manually respect PEMDAS. For example, `add(div(a, b), multiply(c, d))` in TypeScript would simplify to `a &#x2F; b + c * d` in Python. The TS version is unreadable.</div><br/><div id="36009458" class="c"><input type="checkbox" id="c-36009458" checked=""/><div class="controls bullet"><span class="by">crubier</span><span>|</span><a href="#36007476">root</a><span>|</span><a href="#36008923">parent</a><span>|</span><a href="#36009029">next</a><span>|</span><label class="collapse" for="c-36009458">[-]</label><label class="expand" for="c-36009458">[2 more]</label></div><br/><div class="children"><div class="content">I actually think that tagged template strings in JS&#x2F;TS could be a much better version of operator overloading! <a href="https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;JavaScript&#x2F;Reference&#x2F;Template_literals#tagged_templates" rel="nofollow">https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;JavaScript&#x2F;Refe...</a><p>This would give access to any math notation in a more flexible way, implementing a custom DSL in a type safe but expressive way.<p>Imagine writing stuff like<p>const result = math`${a} + ${b} &#x2F; ${c}`</div><br/><div id="36010275" class="c"><input type="checkbox" id="c-36010275" checked=""/><div class="controls bullet"><span class="by">crubier</span><span>|</span><a href="#36007476">root</a><span>|</span><a href="#36009458">parent</a><span>|</span><a href="#36009029">next</a><span>|</span><label class="collapse" for="c-36010275">[-]</label><label class="expand" for="c-36010275">[1 more]</label></div><br/><div class="children"><div class="content">I got nerdsniped and made a small library to test this concept. Might maintain<p><a href="https:&#x2F;&#x2F;github.com&#x2F;crubier&#x2F;opov">https:&#x2F;&#x2F;github.com&#x2F;crubier&#x2F;opov</a></div><br/></div></div></div></div><div id="36009029" class="c"><input type="checkbox" id="c-36009029" checked=""/><div class="controls bullet"><span class="by">killthebuddha</span><span>|</span><a href="#36007476">root</a><span>|</span><a href="#36008923">parent</a><span>|</span><a href="#36009458">prev</a><span>|</span><a href="#36008080">next</a><span>|</span><label class="collapse" for="c-36009029">[-]</label><label class="expand" for="c-36009029">[3 more]</label></div><br/><div class="children"><div class="content">Another option that&#x27;s not quite as good as `a + b + c` but that is possible with TypeScript is a fluent API:<p><pre><code>  const sum = a.add(b).add(c);</code></pre></div><br/><div id="36009409" class="c"><input type="checkbox" id="c-36009409" checked=""/><div class="controls bullet"><span class="by">praeclarum</span><span>|</span><a href="#36007476">root</a><span>|</span><a href="#36009029">parent</a><span>|</span><a href="#36009080">next</a><span>|</span><label class="collapse" for="c-36009409">[-]</label><label class="expand" for="c-36009409">[1 more]</label></div><br/><div class="children"><div class="content">Yes that syntax works right now.</div><br/></div></div><div id="36009080" class="c"><input type="checkbox" id="c-36009080" checked=""/><div class="controls bullet"><span class="by">leeoniya</span><span>|</span><a href="#36007476">root</a><span>|</span><a href="#36009029">parent</a><span>|</span><a href="#36009409">prev</a><span>|</span><a href="#36008080">next</a><span>|</span><label class="collapse" for="c-36009080">[-]</label><label class="expand" for="c-36009080">[1 more]</label></div><br/><div class="children"><div class="content">or add(a,b,c)</div><br/></div></div></div></div></div></div><div id="36008080" class="c"><input type="checkbox" id="c-36008080" checked=""/><div class="controls bullet"><span class="by">tzhenghao</span><span>|</span><a href="#36007476">parent</a><span>|</span><a href="#36008923">prev</a><span>|</span><a href="#36006928">next</a><span>|</span><label class="collapse" for="c-36008080">[-]</label><label class="expand" for="c-36008080">[2 more]</label></div><br/><div class="children"><div class="content">This. Just to riff off an example, a lot of the APIs in common DL frameworks like PyTorch revolve around numpy or pickle formats. These are Python first semantics.</div><br/><div id="36008205" class="c"><input type="checkbox" id="c-36008205" checked=""/><div class="controls bullet"><span class="by">lyu07282</span><span>|</span><a href="#36007476">root</a><span>|</span><a href="#36008080">parent</a><span>|</span><a href="#36006928">next</a><span>|</span><label class="collapse" for="c-36008205">[-]</label><label class="expand" for="c-36008205">[1 more]</label></div><br/><div class="children"><div class="content">There is so much stuff in scipy and opencv alone that it will take forever for another language to catch up to. Unfortunately, because python is suuuuuuuch a mediocre language in comparison. Type annotations were such a lost opportunity in python, it&#x27;s such a horrible implementation.</div><br/></div></div></div></div></div></div><div id="36006928" class="c"><input type="checkbox" id="c-36006928" checked=""/><div class="controls bullet"><span class="by">activatedgeek</span><span>|</span><a href="#36007476">prev</a><span>|</span><a href="#36007544">next</a><span>|</span><label class="collapse" for="c-36006928">[-]</label><label class="expand" for="c-36006928">[13 more]</label></div><br/><div class="children"><div class="content">Amazing!<p>Oddly, two tests fail for me with Brave (Version 1.51.118 &#x2F; Chromium: 113.0.5672.126 (arm64)) on macOS Ventura 13.3.1<p>- pow([0], [0]) gradient, with &quot;Expected «-Infinity» to be close to «0» (diff: &lt; 0.0000005)&quot;<p>- xlogy([0], [0.30000001192092896]) gradient with &quot;Expected «0» to be close to «-1.2039728164672852»&quot;</div><br/><div id="36008674" class="c"><input type="checkbox" id="c-36008674" checked=""/><div class="controls bullet"><span class="by">praeclarum</span><span>|</span><a href="#36006928">parent</a><span>|</span><a href="#36007873">next</a><span>|</span><label class="collapse" for="c-36008674">[-]</label><label class="expand" for="c-36008674">[1 more]</label></div><br/><div class="children"><div class="content">Yeah so the thing is WebGPU doesn’t correctly support IEEE floating point. Particularly, 0 is often substituted for +-Inf and NaN. See section 14.6 of the spec.<p><a href="https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;WGSL&#x2F;#floating-point-evaluation" rel="nofollow">https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;WGSL&#x2F;#floating-point-evaluation</a><p>It’s not such a problem for real nets since you avoid those values like the plague. But the tests catch them and I need to make the tests are tolerant. Thanks for the results!</div><br/></div></div><div id="36007873" class="c"><input type="checkbox" id="c-36007873" checked=""/><div class="controls bullet"><span class="by">MuffinFlavored</span><span>|</span><a href="#36006928">parent</a><span>|</span><a href="#36008674">prev</a><span>|</span><a href="#36007361">next</a><span>|</span><label class="collapse" for="c-36007873">[-]</label><label class="expand" for="c-36007873">[9 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;praeclarum.org&#x2F;webgpu-torch&#x2F;tests&#x2F;" rel="nofollow">https:&#x2F;&#x2F;praeclarum.org&#x2F;webgpu-torch&#x2F;tests&#x2F;</a><p>This is a dumb question but... are GPUs really that much faster than CPUs specifically at the math functions tested on this page?<p>xlogy trunc tan&#x2F;tanh sub square sqrt sin&#x2F;sinc&#x2F;silu&#x2F;sinh sign sigmoid sqrt&#x2F;rsqrt round relu reciprocal rad2deg pow positive neg mul logaddexp&#x2F;logaddexp2 log&#x2F;log1p&#x2F;log10&#x2F;log2 ldexp hypot frac floor expm1 exp2 exp div deg2rad cos&#x2F;cosh copysign ceil atan&#x2F;atan2 asinh&#x2F;asin add acosh&#x2F;acos abs<p>Those are the types of math GPUs are good at? I thought they were better at a different kind of math, like matrices or something?</div><br/><div id="36008583" class="c"><input type="checkbox" id="c-36008583" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#36006928">root</a><span>|</span><a href="#36007873">parent</a><span>|</span><a href="#36007935">next</a><span>|</span><label class="collapse" for="c-36008583">[-]</label><label class="expand" for="c-36008583">[5 more]</label></div><br/><div class="children"><div class="content">GPUs are about 100 times faster than CPUs for <i>any</i> type of single-precision floating point math operation. The catch is that you have to do roughly similar math operations on 10k+ items in parallel before the parallelism and memory bandwidth advantages of the GPU outweigh the latency and single-threaded performance advantages of the CPU. Of course this is achievable in graphics applications with millions of triangles and millions of pixels, and in machine learning applications with millions or billions of neurons.<p>IMO almost any application that is bottlenecked by CPU performance can be recast to use GPUs effectively. But it&#x27;s rarely done because GPUs aren&#x27;t nearly as standardized as CPUs and the developer tools are much worse, so it&#x27;s a lot of effort for a faster but much less portable outcome.</div><br/><div id="36009032" class="c"><input type="checkbox" id="c-36009032" checked=""/><div class="controls bullet"><span class="by">HexDecOctBin</span><span>|</span><a href="#36006928">root</a><span>|</span><a href="#36008583">parent</a><span>|</span><a href="#36009509">next</a><span>|</span><label class="collapse" for="c-36009032">[-]</label><label class="expand" for="c-36009032">[3 more]</label></div><br/><div class="children"><div class="content">Are there any standardised approaches for this? I fail to imagine how one would put branchy CPU code like parsing, etc. on GPUs effectively?</div><br/><div id="36009053" class="c"><input type="checkbox" id="c-36009053" checked=""/><div class="controls bullet"><span class="by">raphlinus</span><span>|</span><a href="#36006928">root</a><span>|</span><a href="#36009032">parent</a><span>|</span><a href="#36009241">next</a><span>|</span><label class="collapse" for="c-36009053">[-]</label><label class="expand" for="c-36009053">[1 more]</label></div><br/><div class="children"><div class="content">It is possible but you have to do things very differently, for example use monoids. There are a few compilers implemented on GPU, including Aaron Hsu&#x27;s co-dfns and Voetter&#x27;s compiler project[1]. The parentheses matching problem itself (the core of parsing) has long known efficient parallel algorithms and those have been ported to compute shaders[2] (disclosure: blatant self-promotion).<p>[1]: <a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;3528416.3530249" rel="nofollow">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;pdf&#x2F;10.1145&#x2F;3528416.3530249</a><p>[2]: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2205.11659.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2205.11659.pdf</a></div><br/></div></div><div id="36009241" class="c"><input type="checkbox" id="c-36009241" checked=""/><div class="controls bullet"><span class="by">kaliqt</span><span>|</span><a href="#36006928">root</a><span>|</span><a href="#36009032">parent</a><span>|</span><a href="#36009053">prev</a><span>|</span><a href="#36009509">next</a><span>|</span><label class="collapse" for="c-36009241">[-]</label><label class="expand" for="c-36009241">[1 more]</label></div><br/><div class="children"><div class="content">WebGPU I think will help change a lot of this. Finally, portable code that is performant and runs virtually anywhere. It&#x27;s the same reason web apps have taken off so much, or just the idea of deploying to and from web platforms, e.g. write in web and deploy to native.<p>I think WebGPU will be that universal language everyone speaks, and I think also that this will help get rid of Nvidia&#x27;s monopoly on GPU compute.</div><br/></div></div></div></div></div></div><div id="36007935" class="c"><input type="checkbox" id="c-36007935" checked=""/><div class="controls bullet"><span class="by">nicoco</span><span>|</span><a href="#36006928">root</a><span>|</span><a href="#36007873">parent</a><span>|</span><a href="#36008583">prev</a><span>|</span><a href="#36007933">next</a><span>|</span><label class="collapse" for="c-36007935">[-]</label><label class="expand" for="c-36007935">[2 more]</label></div><br/><div class="children"><div class="content">GPUs are usually not faster at doing the operation, but excel at doing the operation in parallel on a gazillion elements. Matrix math is mostly additions and multiplications.</div><br/><div id="36008683" class="c"><input type="checkbox" id="c-36008683" checked=""/><div class="controls bullet"><span class="by">praeclarum</span><span>|</span><a href="#36006928">root</a><span>|</span><a href="#36007935">parent</a><span>|</span><a href="#36007933">next</a><span>|</span><label class="collapse" for="c-36008683">[-]</label><label class="expand" for="c-36008683">[1 more]</label></div><br/><div class="children"><div class="content">Yeah this is the trick. You need to maximize the use of workgroup parallelism <i>and also</i> lay things out in memory for those kernels to access efficiently. It’s a bit of a balancing act and I’ll be working on benchmarks to test out different strategies.</div><br/></div></div></div></div><div id="36007933" class="c"><input type="checkbox" id="c-36007933" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#36006928">root</a><span>|</span><a href="#36007873">parent</a><span>|</span><a href="#36007935">prev</a><span>|</span><a href="#36007361">next</a><span>|</span><label class="collapse" for="c-36007933">[-]</label><label class="expand" for="c-36007933">[1 more]</label></div><br/><div class="children"><div class="content">They are relatively tiny but they run on the GPU to avoid lots of copies back and forth.</div><br/></div></div></div></div><div id="36007361" class="c"><input type="checkbox" id="c-36007361" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#36006928">parent</a><span>|</span><a href="#36007873">prev</a><span>|</span><a href="#36007544">next</a><span>|</span><label class="collapse" for="c-36007361">[-]</label><label class="expand" for="c-36007361">[2 more]</label></div><br/><div class="children"><div class="content">Same with Chrome 113.0.5672.92 (arm64) on Ventura 13.2.<p>Safari 16.3 has 4 failures: &quot;webgpu is supported&quot;, &quot;tensor is webgpu&quot;, &quot;xlogy([0], [0]) gradient&quot;, &quot;xlogy([0], [0.30000001192092896]) gradient&quot;</div><br/><div id="36008685" class="c"><input type="checkbox" id="c-36008685" checked=""/><div class="controls bullet"><span class="by">praeclarum</span><span>|</span><a href="#36006928">root</a><span>|</span><a href="#36007361">parent</a><span>|</span><a href="#36007544">next</a><span>|</span><label class="collapse" for="c-36008685">[-]</label><label class="expand" for="c-36008685">[1 more]</label></div><br/><div class="children"><div class="content">Sorry Safari does not support WebGPU yet. Please join me in writing to Apple and requesting it.</div><br/></div></div></div></div></div></div><div id="36007544" class="c"><input type="checkbox" id="c-36007544" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#36006928">prev</a><span>|</span><a href="#36009006">next</a><span>|</span><label class="collapse" for="c-36007544">[-]</label><label class="expand" for="c-36007544">[3 more]</label></div><br/><div class="children"><div class="content">It seems like there&#x27;s a developing competitor to the Python ecosystem in the form of webgpu and js&#x2F;ts. Being able to run anywhere with no native dependencies is a pretty huge advantage, it will be interesting to see if this steals momentum. I wonder how hard it would be to add support for this as an alternate backend to transformers.js.</div><br/><div id="36008576" class="c"><input type="checkbox" id="c-36008576" checked=""/><div class="controls bullet"><span class="by">hot_gril</span><span>|</span><a href="#36007544">parent</a><span>|</span><a href="#36009006">next</a><span>|</span><label class="collapse" for="c-36008576">[-]</label><label class="expand" for="c-36008576">[2 more]</label></div><br/><div class="children"><div class="content">I used to use Python heavily and favor JS now for these reasons. Portability is huge. I think JS is going to eat Python&#x27;s lunch.</div><br/><div id="36009643" class="c"><input type="checkbox" id="c-36009643" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36007544">root</a><span>|</span><a href="#36008576">parent</a><span>|</span><a href="#36009006">next</a><span>|</span><label class="collapse" for="c-36009643">[-]</label><label class="expand" for="c-36009643">[1 more]</label></div><br/><div class="children"><div class="content">Imagine: Isomorphic neural nets that can run server or client side.</div><br/></div></div></div></div></div></div><div id="36009006" class="c"><input type="checkbox" id="c-36009006" checked=""/><div class="controls bullet"><span class="by">infrawhispers</span><span>|</span><a href="#36007544">prev</a><span>|</span><a href="#36007307">next</a><span>|</span><label class="collapse" for="c-36009006">[-]</label><label class="expand" for="c-36009006">[1 more]</label></div><br/><div class="children"><div class="content">This is really nice! I have been working on getting ANN search working in the browser ([1] demo, [2] WIP repo) and would love to switch out onnx for the embedding generation.<p>[1] <a href="https:&#x2F;&#x2F;anansi.pages.dev&#x2F;" rel="nofollow">https:&#x2F;&#x2F;anansi.pages.dev&#x2F;</a>
[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;infrawhispers&#x2F;anansi&#x2F;tree&#x2F;main&#x2F;embedds&#x2F;lib&#x2F;retrieval&#x2F;src">https:&#x2F;&#x2F;github.com&#x2F;infrawhispers&#x2F;anansi&#x2F;tree&#x2F;main&#x2F;embedds&#x2F;li...</a><p>privacy focused semantic search &#x2F; ML at the edge is looking brighter every day.</div><br/></div></div><div id="36007307" class="c"><input type="checkbox" id="c-36007307" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#36009006">prev</a><span>|</span><a href="#36009506">next</a><span>|</span><label class="collapse" for="c-36007307">[-]</label><label class="expand" for="c-36007307">[3 more]</label></div><br/><div class="children"><div class="content">Very impressive work. Would be interesting to do some benchmarks versus PyTorch.<p>On a side-note, I&#x27;m not sure if it is because I&#x27;ve looked at so many autograd engines by now, but it is really cool to see that after the years of different frameworks having been developed, most people seem to agree on some concepts and structure on how to implement something like this. It is pretty easy to dive into this, even without being particularly skilled in JS&#x2F;TS.<p>Wondering how such frameworks will look in a couple years.</div><br/><div id="36009478" class="c"><input type="checkbox" id="c-36009478" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#36007307">parent</a><span>|</span><a href="#36009506">next</a><span>|</span><label class="collapse" for="c-36009478">[-]</label><label class="expand" for="c-36009478">[2 more]</label></div><br/><div class="children"><div class="content">Could there be something like emscripten-forge&#x2F;requests-wasm-polyfill for PyTorch with WebGPU? <a href="https:&#x2F;&#x2F;github.com&#x2F;emscripten-forge&#x2F;requests-wasm-polyfill">https:&#x2F;&#x2F;github.com&#x2F;emscripten-forge&#x2F;requests-wasm-polyfill</a><p>How does the performance of webgpu-torch compare to compiling PyTorch to WASM with emscripten and WebGPU?<p>tfjs benchmarks: Environment &gt; backend &gt; {WASM, WebGL, CPU, WebGPU, tflite}
<a href="https:&#x2F;&#x2F;tensorflow.github.io&#x2F;tfjs&#x2F;e2e&#x2F;benchmarks&#x2F;local-benchmark&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;tensorflow.github.io&#x2F;tfjs&#x2F;e2e&#x2F;benchmarks&#x2F;local-bench...</a> src: <a href="https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tfjs&#x2F;tree&#x2F;master&#x2F;e2e&#x2F;benchmarks">https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tfjs&#x2F;tree&#x2F;master&#x2F;e2e&#x2F;benchmark...</a><p>tensorflow&#x2F;tfjs 
<a href="https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tfjs">https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tfjs</a><p>tfjs-backend-wasm 
<a href="https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tfjs&#x2F;tree&#x2F;master&#x2F;tfjs-backend-wasm">https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tfjs&#x2F;tree&#x2F;master&#x2F;tfjs-backend-...</a><p>tfjs-backend-webgpu 
<a href="https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tfjs&#x2F;tree&#x2F;master&#x2F;tfjs-backend-webgpu">https:&#x2F;&#x2F;github.com&#x2F;tensorflow&#x2F;tfjs&#x2F;tree&#x2F;master&#x2F;tfjs-backend-...</a><p>([...], tflite-support, tflite-micro)<p>From facebookresearch&#x2F;shumai (a JS tensor library) <a href="https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;shumai&#x2F;issues&#x2F;122">https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;shumai&#x2F;issues&#x2F;122</a> :<p>&gt; <i>It doesn&#x27;t make sense to support anything besides WebGPU at this point. WASM + SIMD is around 15-20x slower on my machine[1]. Although WebGL is more widely supported today, it doesn&#x27;t have the compute features needed for efficient modern ML (transformers etc) and will likely be a deprecated backend for other frameworks when WebGPU comes online.</i><p>tensorflow rust has a struct.Tensor:
<a href="https:&#x2F;&#x2F;tensorflow.github.io&#x2F;rust&#x2F;tensorflow&#x2F;struct.Tensor.html" rel="nofollow">https:&#x2F;&#x2F;tensorflow.github.io&#x2F;rust&#x2F;tensorflow&#x2F;struct.Tensor.h...</a><p>&quot;ONNX Runtime merges WebGPU backend&quot; <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;onnxruntime">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;onnxruntime</a>
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35696031" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35696031</a> ... TIL about wonnx: <a href="https:&#x2F;&#x2F;github.com&#x2F;webonnx&#x2F;wonnx#in-the-browser-using-webgpu--webassembly">https:&#x2F;&#x2F;github.com&#x2F;webonnx&#x2F;wonnx#in-the-browser-using-webgpu...</a><p>microsoft&#x2F;onnxruntime: <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;onnxruntime">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;onnxruntime</a><p>Apache&#x2F;arrow has language-portable Tensors for cpp: <a href="https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;cpp&#x2F;api&#x2F;tensor.html" rel="nofollow">https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;cpp&#x2F;api&#x2F;tensor.html</a> and rust: <a href="https:&#x2F;&#x2F;docs.rs&#x2F;arrow&#x2F;latest&#x2F;arrow&#x2F;tensor&#x2F;struct.Tensor.html" rel="nofollow">https:&#x2F;&#x2F;docs.rs&#x2F;arrow&#x2F;latest&#x2F;arrow&#x2F;tensor&#x2F;struct.Tensor.html</a> and Python: <a href="https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;python&#x2F;api&#x2F;tables.html#tensors" rel="nofollow">https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;python&#x2F;api&#x2F;tables.html#tensors</a> <a href="https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;python&#x2F;generated&#x2F;pyarrow.Tensor.html#pyarrow.Tensor" rel="nofollow">https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;python&#x2F;generated&#x2F;pyarrow.Tenso...</a><p>Fwiw it looks like the llama.cpp Tensor is from ggml, for which there are CUDA and OpenCL implementations (but not yet ROCm, or a WebGPU shim for use with emscripten transpilation to WASM): <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;blob&#x2F;master&#x2F;ggml.h">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;blob&#x2F;master&#x2F;ggml.h</a><p>Are the recommendable ways to cast e.g. arrow Tensors to pytorch&#x2F;tensorflow?<p>FWIU, Rust has a better compilation to WASM; and that&#x27;s probably faster than already-compiled-to-JS&#x2F;ES TensorFlow + WebGPU.<p>What&#x27;s a fair benchmark?</div><br/><div id="36009504" class="c"><input type="checkbox" id="c-36009504" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#36007307">root</a><span>|</span><a href="#36009478">parent</a><span>|</span><a href="#36009506">next</a><span>|</span><label class="collapse" for="c-36009504">[-]</label><label class="expand" for="c-36009504">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>What&#x27;s a fair benchmark?</i><p>- &#x2F;? pytorch tensorflow benchmarks webgpu 2023 site:github.com 
<a href="https:&#x2F;&#x2F;www.google.com&#x2F;search?q=pytorch+tensorflow+benchmarks+2023+webgpu+site%253Agithub.com" rel="nofollow">https:&#x2F;&#x2F;www.google.com&#x2F;search?q=pytorch+tensorflow+benchmark...</a><p>- [tfjs benchmarks]<p>- huggingface&#x2F;transformers:src&#x2F;transformers&#x2F;benchmark <a href="https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;transformers&#x2F;tree&#x2F;main&#x2F;src&#x2F;transformers&#x2F;benchmark">https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;transformers&#x2F;tree&#x2F;main&#x2F;src&#x2F;tr...</a></div><br/></div></div></div></div></div></div><div id="36009506" class="c"><input type="checkbox" id="c-36009506" checked=""/><div class="controls bullet"><span class="by">zmmmmm</span><span>|</span><a href="#36007307">prev</a><span>|</span><a href="#36007861">next</a><span>|</span><label class="collapse" for="c-36009506">[-]</label><label class="expand" for="c-36009506">[2 more]</label></div><br/><div class="children"><div class="content">Curious what the potential is for this to then run headless - is the support for this in chrome etc. built into v8 etc such that node and others can simply piggyback on it? Or is it sitting in the browser layer such that you&#x27;d have to end up with a headless browser or similar?</div><br/><div id="36010003" class="c"><input type="checkbox" id="c-36010003" checked=""/><div class="controls bullet"><span class="by">henearkr</span><span>|</span><a href="#36009506">parent</a><span>|</span><a href="#36007861">next</a><span>|</span><label class="collapse" for="c-36010003">[-]</label><label class="expand" for="c-36010003">[1 more]</label></div><br/><div class="children"><div class="content">Node doesn&#x27;t have a GPU backend.<p>Deno has (or had), but you&#x27;d have to use Deno v1.31.3 to get WebGPU support (because if was removed afterwards for startup performance issues).</div><br/></div></div></div></div><div id="36007861" class="c"><input type="checkbox" id="c-36007861" checked=""/><div class="controls bullet"><span class="by">tachim</span><span>|</span><a href="#36009506">prev</a><span>|</span><a href="#36007250">next</a><span>|</span><label class="collapse" for="c-36007861">[-]</label><label class="expand" for="c-36007861">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the reason to run pytorch directly on WebGPU vs using ONNX on WebGPU (e.g. with <a href="https:&#x2F;&#x2F;github.com&#x2F;webonnx&#x2F;wonnx">https:&#x2F;&#x2F;github.com&#x2F;webonnx&#x2F;wonnx</a>)?</div><br/></div></div><div id="36007250" class="c"><input type="checkbox" id="c-36007250" checked=""/><div class="controls bullet"><span class="by">replete</span><span>|</span><a href="#36007861">prev</a><span>|</span><a href="#36007582">next</a><span>|</span><label class="collapse" for="c-36007250">[-]</label><label class="expand" for="c-36007250">[2 more]</label></div><br/><div class="children"><div class="content">Impressive work.<p>A number of test failures for me on chromium 113.0.5672.63 (ungoogled chromium) MacOS Ventura 13.3.1: <a href="https:&#x2F;&#x2F;pastebin.com&#x2F;eM6ZA3j2" rel="nofollow">https:&#x2F;&#x2F;pastebin.com&#x2F;eM6ZA3j2</a><p>I&#x27;ll open a ticket if it helps..</div><br/><div id="36008691" class="c"><input type="checkbox" id="c-36008691" checked=""/><div class="controls bullet"><span class="by">praeclarum</span><span>|</span><a href="#36007250">parent</a><span>|</span><a href="#36007582">next</a><span>|</span><label class="collapse" for="c-36008691">[-]</label><label class="expand" for="c-36008691">[1 more]</label></div><br/><div class="children"><div class="content">Please do. I have a few test machines but cannot match the variety of hardware out there.</div><br/></div></div></div></div><div id="36007582" class="c"><input type="checkbox" id="c-36007582" checked=""/><div class="controls bullet"><span class="by">nwoli</span><span>|</span><a href="#36007250">prev</a><span>|</span><a href="#36007251">next</a><span>|</span><label class="collapse" for="c-36007582">[-]</label><label class="expand" for="c-36007582">[1 more]</label></div><br/><div class="children"><div class="content">I would love to hear what Bram Wasti thinks about this (who has experience in this area and sometimes frequents the HN comments).</div><br/></div></div><div id="36007251" class="c"><input type="checkbox" id="c-36007251" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36007582">prev</a><span>|</span><a href="#36007244">next</a><span>|</span><label class="collapse" for="c-36007251">[-]</label><label class="expand" for="c-36007251">[2 more]</label></div><br/><div class="children"><div class="content">Loads of tests fail for me (chrome, windows). Mainly trigonometric functions which are way less accurate than they are supposed to be.</div><br/><div id="36008699" class="c"><input type="checkbox" id="c-36008699" checked=""/><div class="controls bullet"><span class="by">praeclarum</span><span>|</span><a href="#36007251">parent</a><span>|</span><a href="#36007244">next</a><span>|</span><label class="collapse" for="c-36008699">[-]</label><label class="expand" for="c-36008699">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I think I’ll reduce the accuracy requirement for some transcendental functions since GPUs seem all over the place.</div><br/></div></div></div></div><div id="36007244" class="c"><input type="checkbox" id="c-36007244" checked=""/><div class="controls bullet"><span class="by">garbagecoder</span><span>|</span><a href="#36007251">prev</a><span>|</span><a href="#36007428">next</a><span>|</span><label class="collapse" for="c-36007244">[-]</label><label class="expand" for="c-36007244">[2 more]</label></div><br/><div class="children"><div class="content">There goes my weekend!! Thanks!</div><br/><div id="36009648" class="c"><input type="checkbox" id="c-36009648" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36007244">parent</a><span>|</span><a href="#36007428">next</a><span>|</span><label class="collapse" for="c-36009648">[-]</label><label class="expand" for="c-36009648">[1 more]</label></div><br/><div class="children"><div class="content">Learning as a beginner&#x2F;novice, Feels like I am trying to catch up to a jet at takeoff speed on my kick scooter.</div><br/></div></div></div></div><div id="36007428" class="c"><input type="checkbox" id="c-36007428" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#36007244">prev</a><span>|</span><a href="#36009145">next</a><span>|</span><label class="collapse" for="c-36007428">[-]</label><label class="expand" for="c-36007428">[2 more]</label></div><br/><div class="children"><div class="content">&gt; This is a perfect scenario to take advantage of code generation. I wrote a code generator that takes a template and generates the optimized kernels for each operation. The code generator is written in TypeScript and generates WebGPU compute shader code. This means that the generated code can be heavily optimized for the given scenario and those optimizations can be shared between operations.<p>A clever way to implement an AOT variant of the operator fusion methods in the XLA (JIT) compiler.</div><br/><div id="36008416" class="c"><input type="checkbox" id="c-36008416" checked=""/><div class="controls bullet"><span class="by">SloopJon</span><span>|</span><a href="#36007428">parent</a><span>|</span><a href="#36009145">next</a><span>|</span><label class="collapse" for="c-36008416">[-]</label><label class="expand" for="c-36008416">[1 more]</label></div><br/><div class="children"><div class="content">This is perhaps the most interesting aspect of the project--using a code generator to escape the gravitational pull of CUDA.  I wonder how well it would generalize to other targets.</div><br/></div></div></div></div></div></div></div></div></div></body></html>