<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1725699671405" as="style"/><link rel="stylesheet" href="styles.css?v=1725699671405"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://yorickpeterse.com/articles/asynchronous-io-the-next-billion-dollar-mistake/">Asynchronous IO: the next billion-dollar mistake?</a>Â <span class="domain">(<a href="https://yorickpeterse.com">yorickpeterse.com</a>)</span></div><div class="subtext"><span>signa11</span> | <span>68 comments</span></div><br/><div><div id="41472140" class="c"><input type="checkbox" id="c-41472140" checked=""/><div class="controls bullet"><span class="by">winternewt</span><span>|</span><a href="#41472056">next</a><span>|</span><label class="collapse" for="c-41472140">[-]</label><label class="expand" for="c-41472140">[9 more]</label></div><br/><div class="children"><div class="content">&gt; Now imagine a parallel universe where instead of focusing on making asynchronous IO work, we focused on improving the performance of OS threads such that one can easily use hundreds of thousands of OS threads without negatively impacting performance<p>I actually can&#x27;t imagine how that would ever be accomplished at the OS level. The fact that each thread needs its own stack is an inherent limiter for efficiency, as switching stacks leads to cache misses. Asynchronous I&#x2F;O has an edge because it only stores exactly as much state as it needs for its continuation, and multiple tasks can have their state in the same CPU cache line. The OS doesn&#x27;t know nearly enough about your program to optimize the stack contents to only contain the state you need for the remainder of the thread.<p>But at the programming language level the compiler does have insight into the dependencies of your continuation, so it can build a closure that has only what it needs to have. You still have asynchronous I&#x2F;O at the core but the language creates an abstraction that behaves like a synchronous threaded model, as seen in C#, Kotlin, etc. This doesn&#x27;t come without challenges. For example, in Kotlin the debugger is unable to show contents of variables that are not needed further down in the code because they have already been removed from the underlying closure. But I&#x27;m sure they are solvable.</div><br/><div id="41472187" class="c"><input type="checkbox" id="c-41472187" checked=""/><div class="controls bullet"><span class="by">dist1ll</span><span>|</span><a href="#41472140">parent</a><span>|</span><a href="#41472056">next</a><span>|</span><label class="collapse" for="c-41472187">[-]</label><label class="expand" for="c-41472187">[8 more]</label></div><br/><div class="children"><div class="content">&gt; But at the programming language level the compiler does have insight into the dependencies of your continuation<p>This is really the key point - coupled with the fact that certain I&#x2F;O operations are just inherently asynchronous.<p>The TX&#x2F;RX queues in NICs are an async, message passing interface - regardless of whether you&#x27;re polling descriptors or receiving completion interrupts.<p>So really, async I&#x2F;O is the <i>natural</i> abstraction for networking.</div><br/><div id="41472232" class="c"><input type="checkbox" id="c-41472232" checked=""/><div class="controls bullet"><span class="by">dietr1ch</span><span>|</span><a href="#41472140">root</a><span>|</span><a href="#41472187">parent</a><span>|</span><a href="#41472251">next</a><span>|</span><label class="collapse" for="c-41472232">[-]</label><label class="expand" for="c-41472232">[2 more]</label></div><br/><div class="children"><div class="content">Anything that happens far enough from the CPU is async, and here far probably means 10cm thanks to the speed of light not being fast enough, even in vacuum.<p>So, any computation that spans a machine the size of our hands needs async unless you are willing to drop the clocks to push &quot;far&quot; a bit further away (and bring in power, heat and noise with it).</div><br/><div id="41472412" class="c"><input type="checkbox" id="c-41472412" checked=""/><div class="controls bullet"><span class="by">BenoitP</span><span>|</span><a href="#41472140">root</a><span>|</span><a href="#41472232">parent</a><span>|</span><a href="#41472251">next</a><span>|</span><label class="collapse" for="c-41472412">[-]</label><label class="expand" for="c-41472412">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for putting words into this.<p>Another cut off could be 3 cm away: the RAM. If data needs to go on the heap, be shared, one can consider the truth lives farther away than 3cm and thus has async&#x2F;impure effects.</div><br/></div></div></div></div><div id="41472251" class="c"><input type="checkbox" id="c-41472251" checked=""/><div class="controls bullet"><span class="by">vbezhenar</span><span>|</span><a href="#41472140">root</a><span>|</span><a href="#41472187">parent</a><span>|</span><a href="#41472232">prev</a><span>|</span><a href="#41472249">next</a><span>|</span><label class="collapse" for="c-41472251">[-]</label><label class="expand" for="c-41472251">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So really, async I&#x2F;O is the natural abstraction for networking.<p>Special pointer values are also natural abstraction.</div><br/></div></div><div id="41472249" class="c"><input type="checkbox" id="c-41472249" checked=""/><div class="controls bullet"><span class="by">ffsm8</span><span>|</span><a href="#41472140">root</a><span>|</span><a href="#41472187">parent</a><span>|</span><a href="#41472251">prev</a><span>|</span><a href="#41472056">next</a><span>|</span><label class="collapse" for="c-41472249">[-]</label><label class="expand" for="c-41472249">[4 more]</label></div><br/><div class="children"><div class="content">&gt; certain I&#x2F;O operations are just inherently asynchronous.<p>That&#x27;s technically not true.<p>The fact that its inherently async is an implementation detail. You either have blocking sync or non-blocking async. the implementation could be synchronous if the blocking didn&#x27;t cause overhead and that was the proposed idea here - at least as far as I interpreted it.</div><br/><div id="41472298" class="c"><input type="checkbox" id="c-41472298" checked=""/><div class="controls bullet"><span class="by">Veserv</span><span>|</span><a href="#41472140">root</a><span>|</span><a href="#41472249">parent</a><span>|</span><a href="#41472056">next</a><span>|</span><label class="collapse" for="c-41472298">[-]</label><label class="expand" for="c-41472298">[3 more]</label></div><br/><div class="children"><div class="content">No, the <i>hardware</i> is frequently inherently asynchronous. You write some memory and then the hardware consumes the prepared data  asynchronously, in parallel, until it informs you in some manner that the operation is complete (usually either a asynchronous interrupt, or asynchronous write to a location you are polling). You can do whatever you want after preparing the data without waiting for completion. That is a inherently asynchronous hardware interface.<p>The software interfaces built on top of the inherently asynchronous hardware interface can either preserve or change that nature. <i>That</i> is a implementation detail.</div><br/><div id="41472425" class="c"><input type="checkbox" id="c-41472425" checked=""/><div class="controls bullet"><span class="by">afiori</span><span>|</span><a href="#41472140">root</a><span>|</span><a href="#41472298">parent</a><span>|</span><a href="#41472499">next</a><span>|</span><label class="collapse" for="c-41472425">[-]</label><label class="expand" for="c-41472425">[1 more]</label></div><br/><div class="children"><div class="content">Hardware is even-driven not asynchronous (the event-driven paradigm is an asynchronous paradigm, but I assume here you mean asynchronous as in async&#x2F;await)</div><br/></div></div><div id="41472499" class="c"><input type="checkbox" id="c-41472499" checked=""/><div class="controls bullet"><span class="by">ffsm8</span><span>|</span><a href="#41472140">root</a><span>|</span><a href="#41472298">parent</a><span>|</span><a href="#41472425">prev</a><span>|</span><a href="#41472056">next</a><span>|</span><label class="collapse" for="c-41472499">[-]</label><label class="expand" for="c-41472499">[1 more]</label></div><br/><div class="children"><div class="content">While that is technically true, it&#x27;s also missing the point entirely. That&#x27;s why I said you can have either blocking sync or non-blocking async.<p>The article explicitly talks about the API provided by the OS. As a matter of fact, they&#x27;re even more specific talking about spawning os threads vs async non-blocking file access.<p>At this level, the async is an implementation detail.<p>I guess your comment confirms that you didn&#x27;t read the article, and neither did the people down voting me.<p>As usual on HN. lots of people suffering from the Dunning Kruger complex</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41472056" class="c"><input type="checkbox" id="c-41472056" checked=""/><div class="controls bullet"><span class="by">HippoBaro</span><span>|</span><a href="#41472140">prev</a><span>|</span><a href="#41471936">next</a><span>|</span><label class="collapse" for="c-41472056">[-]</label><label class="expand" for="c-41472056">[2 more]</label></div><br/><div class="children"><div class="content">I am not sure I buy the underlying idea behind this piece, that somehow a lot of money&#x2F;time has been invested into asynchronous IO at the expense of thread performance (creation time, context switch time, scheduler efficiency, etc.).<p>First, significant work has been done in the kernel in that area simply because any gains there massively impact application performance and energy efficiency, two things the big kernel sponsors deeply care about.<p>Second, asynchronous IO in the kernel has actually been underinvested for years. Async disk IO did not exist at all for years until AIO came to be. And even that was a half-backed, awful API no one wanted to use except for some database people who needed it badly enough to be willing to put up with it. It&#x27;s a somewhat recent development that really fast, genuinely async IO has taken center stage through io_uring and the likes of AF_XDP.</div><br/><div id="41472316" class="c"><input type="checkbox" id="c-41472316" checked=""/><div class="controls bullet"><span class="by">mmis1000</span><span>|</span><a href="#41472056">parent</a><span>|</span><a href="#41471936">next</a><span>|</span><label class="collapse" for="c-41472316">[-]</label><label class="expand" for="c-41472316">[1 more]</label></div><br/><div class="children"><div class="content">Make os thread runs more efficient is like `faking async IOs (disk&#x2F;network&#x2F;whatever goes out from the computer shell) into the sync operations in a more efficient way`. But why would you do it at first place if the program can handle async operations at first place? Just let userland program do their business would be a better decision though.</div><br/></div></div></div></div><div id="41471936" class="c"><input type="checkbox" id="c-41471936" checked=""/><div class="controls bullet"><span class="by">haileys</span><span>|</span><a href="#41472056">prev</a><span>|</span><a href="#41472476">next</a><span>|</span><label class="collapse" for="c-41471936">[-]</label><label class="expand" for="c-41471936">[16 more]</label></div><br/><div class="children"><div class="content">Asynchronous IO isn&#x27;t about efficiency.<p>The approach the author takes with their language is just threads, but scheduled in userland. This model allows a decoupling of the performance characteristics of runtime threads from OS threads - which can sometimes be beneficial - but essentially, the programming model is fundamentally still synchronous.<p>Asynchronous programming with async&#x2F;await is about revealing the time dimension of execution as a first class concept. This allows more opportunities for composition.<p>Take cancellation for example: cancelling tasks under the synchronous programming model requires passing a context object through every part of your code that might call down into an IO operation. This context object is checked for cancellation at each point a task might block, and checked when a blocking operation is interrupted.<p>Timeouts are even trickier to do in this model, especially if your underlying IO only allows you to set per-operation timeouts and you&#x27;re trying to expose a deadline-style interface instead.<p>Under the asynchronous model, both timeouts and cancellation simply compose. You take a future representing the work you&#x27;re doing, and spawn a new future that completes after sleeping for some duration, or spawn a new future that waits on a cancel channel. Then you just race these futures. Take whichever completes first and cancel the other.<p>Having done a lot of programming under both paradigms, the synchronous model is so much more clunky and error-prone to work with and involves a lot of tedious manual work, like passing context objects around, that simply disappears under the asynchronous model.</div><br/><div id="41472544" class="c"><input type="checkbox" id="c-41472544" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#41471936">parent</a><span>|</span><a href="#41472096">next</a><span>|</span><label class="collapse" for="c-41472544">[-]</label><label class="expand" for="c-41472544">[1 more]</label></div><br/><div class="children"><div class="content">Cancellation isn&#x27;t possible in general. For example, if you&#x27;ve kicked off expensive work on another thread or passed a pointer to your future to the kernel via io_uring, you must add a layer of indirection that&#x27;s quite similar to a cancelation context. You can&#x27;t just accept that the expensive work you don&#x27;t care about will keep happening or resume a future that has been dropped when the cqe entry bearing a pointer to it arrives. The cancellation facility provided by io_uring that guarantees that you won&#x27;t receive such a thing does so by blocking your thread for a while, which is undesirable.<p>As implemented, async&#x2F;await typically greatly harms composability. For example see here: <a href="https:&#x2F;&#x2F;nullderef.com&#x2F;blog&#x2F;rust-async-sync&#x2F;" rel="nofollow">https:&#x2F;&#x2F;nullderef.com&#x2F;blog&#x2F;rust-async-sync&#x2F;</a><p>In the specific case of Rust, we might begin to be able to write composable libraries a couple decades from now: <a href="https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;keyword-generics-initiative">https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;keyword-generics-initiative</a></div><br/></div></div><div id="41472096" class="c"><input type="checkbox" id="c-41472096" checked=""/><div class="controls bullet"><span class="by">Veserv</span><span>|</span><a href="#41471936">parent</a><span>|</span><a href="#41472544">prev</a><span>|</span><a href="#41472017">next</a><span>|</span><label class="collapse" for="c-41472096">[-]</label><label class="expand" for="c-41472096">[3 more]</label></div><br/><div class="children"><div class="content">One of the other aspects of this is that implementing a synchronous model on top of asynchronous primitives is absolutely trivial. You just wait until the asynchronous operation completes. Any program designed for asynchronous execution can be trivially retrofitted for synchronous execution.<p>In contrast, implementing a asynchronous model on top of synchronous primitives is extremely challenging requiring the current mess of complex implementations such as state machine rewriting and thread pools. Furthermore, retrofitting a program using synchronous execution to use asynchronous execution is a tremendous amount of work as you need to do it bottom up to maintain compatibility during the transition.</div><br/><div id="41472180" class="c"><input type="checkbox" id="c-41472180" checked=""/><div class="controls bullet"><span class="by">Yoric</span><span>|</span><a href="#41471936">root</a><span>|</span><a href="#41472096">parent</a><span>|</span><a href="#41472350">next</a><span>|</span><label class="collapse" for="c-41472180">[-]</label><label class="expand" for="c-41472180">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Furthermore, retrofitting a program using synchronous execution to use asynchronous execution is a tremendous amount of work as you need to do it bottom up to maintain compatibility during the transition.<p>Can attest to that. I was part of the team that rewrote Firefox to be fully async. Took us years and we could not maintain compatibility with XUL add-ons (async was not the only reason for this, but that&#x27;s where the writing on the wall started to become visible).</div><br/></div></div><div id="41472350" class="c"><input type="checkbox" id="c-41472350" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41471936">root</a><span>|</span><a href="#41472096">parent</a><span>|</span><a href="#41472180">prev</a><span>|</span><a href="#41472017">next</a><span>|</span><label class="collapse" for="c-41472350">[-]</label><label class="expand" for="c-41472350">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s also very easy to implement a future&#x2F;promise style API over a blocking IO primitive, as long as you have cheap threads: you spawn a thread that executes the blocking operation (with cancelation and timeout support as needed) and sets the future&#x27;s result once the result is done, or some error state. It&#x27;s really not such a huge problem.<p>I will also note that most async runtimes include much more complex program rewrites and implicit state machines than thread based models. Java style or Go style green threads are much simpler frameworks than C#&#x27;s whole async task machinery, or even than Rust&#x27;s Tokio.<p>And any program written as a series of threads running blocking operations with proper synchronization is also pretty easy to convert to an async model. The difficulty is taking a single-threaded program and making it run in an async model, but that is a completely different discussion.<p>However, I do agree that ultimately you do need the OS to provide async IO primitives to have efficient IO at the application level. Since OS threads can&#x27;t scale to the required level, even the green threads + blocking IO approach is only realistically implementable with async IO from the OS level. This could change if the OS actually implemented a green threads runtime for blocking operations, but that might still have other inefficiencies related to costs of crossing security boundaries.</div><br/></div></div></div></div><div id="41472017" class="c"><input type="checkbox" id="c-41472017" checked=""/><div class="controls bullet"><span class="by">dehrmann</span><span>|</span><a href="#41471936">parent</a><span>|</span><a href="#41472096">prev</a><span>|</span><a href="#41472297">next</a><span>|</span><label class="collapse" for="c-41472017">[-]</label><label class="expand" for="c-41472017">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Asynchronous programming with async&#x2F;await is about revealing the time dimension of execution as a first class concept<p>People are more likely to assume their code is fast enough and not worry about the execution time of synchronous data processing, then spend weeks investigating why the p99 latency is 5 seconds with clusters of spikes.<p>Async IO is almost entirely about efficiency. It&#x27;s telling the OS that you can manage context switches better than it. Usually this means you&#x27;re making a tradeoff for throughput over latency. That tradeoff is for efficiency is fine, but it needs to be conscious, and most of the time, you actually want lower latency.</div><br/><div id="41472133" class="c"><input type="checkbox" id="c-41472133" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#41471936">root</a><span>|</span><a href="#41472017">parent</a><span>|</span><a href="#41472297">next</a><span>|</span><label class="collapse" for="c-41472133">[-]</label><label class="expand" for="c-41472133">[3 more]</label></div><br/><div class="children"><div class="content">Are you sure that the developer is the best at determining these context switches? I mean, for a low-level language like rust, sure. But for higher level programming, e.g. some CRUD backend, should the developer really care about all that <i>added</i> complexity, when the <i>runtime</i> knows just as much, if not more. Like, itâs a DB call? Then just use the async primitive of the OS in the background and schedule another job in its place, until it âreturnsâ. I am not ahead from manually adding points where this could happen.<p>I think the Java virtual thread model is the ideal choice for higher level programming for this reason. Async actually imposes a much stricter order of execution than necessary.</div><br/><div id="41472176" class="c"><input type="checkbox" id="c-41472176" checked=""/><div class="controls bullet"><span class="by">thesnide</span><span>|</span><a href="#41471936">root</a><span>|</span><a href="#41472133">parent</a><span>|</span><a href="#41472297">next</a><span>|</span><label class="collapse" for="c-41472176">[-]</label><label class="expand" for="c-41472176">[2 more]</label></div><br/><div class="children"><div class="content">It is. Until it isn&#x27;t anymore.<p>Same as we used to do asm, but then the generated code is becoming good enough, or even better than hand written asm.<p>I predict the async trend will fade, as hardware and software will improve. And synchronous programming is higher level than using async. And higer level always prevail given enough time, as management always wants to hire the cheapest devs for the task.</div><br/><div id="41472530" class="c"><input type="checkbox" id="c-41472530" checked=""/><div class="controls bullet"><span class="by">aenis</span><span>|</span><a href="#41471936">root</a><span>|</span><a href="#41472176">parent</a><span>|</span><a href="#41472297">next</a><span>|</span><label class="collapse" for="c-41472530">[-]</label><label class="expand" for="c-41472530">[1 more]</label></div><br/><div class="children"><div class="content">Not sure why the downvotes. Async programming is harder than sync, as one needs not only know one&#x27;s code, but also all the dependencies. Since the benefits of async are in many scenarios limited[1] I&#x27;d expect the simpler abstractions to win.<p>I am a CTO at a large company and I routinely experience tech leads who dont understand what happens under the hood of an async event loop and act surprised when weird and hard to debug p99 issues occur in prod (because some obscure dependency of a dependench does sync file access for something trivial).<p>Abstractions win, people are lazy and most new developers lack understanding of lower level concepts such as interrupts or pooling, nor can predict what code may be cpu bound and unsafe in a async codebase. In a few years, explicit aync will be seen as C is seen today - a low level skill.<p>[1] if your service handles, say, 500qps on average the difference between async and threaded sync might be just 1-2 extra nodes. Does not register on the infra spend.</div><br/></div></div></div></div></div></div></div></div><div id="41472297" class="c"><input type="checkbox" id="c-41472297" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41471936">parent</a><span>|</span><a href="#41472017">prev</a><span>|</span><a href="#41472008">next</a><span>|</span><label class="collapse" for="c-41472297">[-]</label><label class="expand" for="c-41472297">[1 more]</label></div><br/><div class="children"><div class="content">With both synchronous and asynchronous flows, if you want to support cancelation from a high level (e.g. the user can click Cancel in the UI), you need to pass some kind of context from there down to each and every operation that needs to be cancellable. Whether that is done by passing around context objects from the UI down to IO operations, or by ensuring all functions called from the UI down return Task&lt;T&gt; objects, the problem is the same. The context object approach even has the advantage that it also allows you to pass other application-specific things, such as passing progress information up from the bottom of the stack to the UI, or logging ids etc, that the generic Task object won&#x27;t have.<p>Also, deadline-style contexts aren&#x27;t as hard as you make them out to be: you keep track of the remaining time, and pass that as a timeout to every blocking operation, then subtract the actual time taken and pass the remaining time to the next blocking task etc. Or, you can do the exact same thing as the async case: you spawn two threads, one handling the blocking operations, the other waiting for a timeout, and both sharing a cancelation context. Whichever finishes first cancels the other.<p>The difficulty of doing cancellations for most real operations is anyway going to be much much higher than these small differences. The real difficulty of cancellations lies in undoing already finished parts of atomic operations that you completed. The effort to do that is going to dominate the effort to get pass down the context object.</div><br/></div></div><div id="41472008" class="c"><input type="checkbox" id="c-41472008" checked=""/><div class="controls bullet"><span class="by">HippoBaro</span><span>|</span><a href="#41471936">parent</a><span>|</span><a href="#41472297">prev</a><span>|</span><a href="#41472266">next</a><span>|</span><label class="collapse" for="c-41472008">[-]</label><label class="expand" for="c-41472008">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Under the asynchronous model, both timeouts and cancellation simply compose. You take a future representing the work you&#x27;re doing, and spawn a new future that completes after sleeping for some duration, or spawn a new future that waits on a cancel channel. Then you just race these futures. Take whichever completes first and cancel the other.<p>That only works when what you&#x27;re trying to do has no side effect. Consider what happens when you need to cancel a write to a file or a stream. Did you write everything? Something? Nothing? What&#x27;s the state of the file&#x2F;stream at this point?<p>Unfortunately, this is intractable: you&#x27;ll need the underlying system to let you know, which means you will have to wait for it to return. Therefore, if these operations should have a deadline, you&#x27;ll need to be able to communicate that to the kernel.</div><br/></div></div><div id="41472266" class="c"><input type="checkbox" id="c-41472266" checked=""/><div class="controls bullet"><span class="by">bjornsing</span><span>|</span><a href="#41471936">parent</a><span>|</span><a href="#41472008">prev</a><span>|</span><a href="#41471963">next</a><span>|</span><label class="collapse" for="c-41472266">[-]</label><label class="expand" for="c-41472266">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Take cancellation for example: cancelling tasks under the synchronous programming model requires passing a context object through every part of your code that might call down into an IO operation.<p>Does it? Wouldnât you just kill the thread in the synchronous model?</div><br/><div id="41472392" class="c"><input type="checkbox" id="c-41472392" checked=""/><div class="controls bullet"><span class="by">meindnoch</span><span>|</span><a href="#41471936">root</a><span>|</span><a href="#41472266">parent</a><span>|</span><a href="#41471963">next</a><span>|</span><label class="collapse" for="c-41472392">[-]</label><label class="expand" for="c-41472392">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a sure way to get leaks and deadlocks.</div><br/></div></div></div></div><div id="41471963" class="c"><input type="checkbox" id="c-41471963" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#41471936">parent</a><span>|</span><a href="#41472266">prev</a><span>|</span><a href="#41472113">next</a><span>|</span><label class="collapse" for="c-41471963">[-]</label><label class="expand" for="c-41471963">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d argue that few usages of async are motivated this way. In Rust land, it&#x27;s efficiency and in JS land it&#x27;s the browser scripting language legacy.<p>&gt; cancelling tasks under the synchronous programming model requires passing a context object through every part of your code that might call down into an IO operation.<p>This is true for some but not all implementations. See eg Erlang or Unix processes (and maybe cancellation in pthreads?).</div><br/><div id="41472209" class="c"><input type="checkbox" id="c-41472209" checked=""/><div class="controls bullet"><span class="by">Yoric</span><span>|</span><a href="#41471936">root</a><span>|</span><a href="#41471963">parent</a><span>|</span><a href="#41472113">next</a><span>|</span><label class="collapse" for="c-41472209">[-]</label><label class="expand" for="c-41472209">[1 more]</label></div><br/><div class="children"><div class="content">To be more precise, in JS land, we introduced async not directly because of scripting but because of backwards compatibility - prior to async&#x2F;Promise, the JS + DOM semantics were specified with a single thread of execution in mind, with complex dependencies in both directions (e.g. some DOM operations can cause sync reflow while handling an event, which is... bad) and run-to-completion.<p>Promise made it easier to:<p>- cut monolithic chunks of code-that-needs-to-be-executed-to-completion-before-updating-the-screen into something that didn&#x27;t cause jank;<p>- introduce background I&#x2F;O.<p>async&#x2F;await made Promise more readable.<p>(yes, that&#x27;s for Promise and async&#x2F;await on the browser, async callbacks have a different history on Node)</div><br/></div></div></div></div><div id="41472113" class="c"><input type="checkbox" id="c-41472113" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#41471936">parent</a><span>|</span><a href="#41471963">prev</a><span>|</span><a href="#41472476">next</a><span>|</span><label class="collapse" for="c-41472113">[-]</label><label class="expand" for="c-41472113">[1 more]</label></div><br/><div class="children"><div class="content">These are just assumptions on your part - the synchronous&#x2F;threading model doesnât have to be that primitive, the Thread itself can take on the semantics of cancellation&#x2F;timeouts just fine. While there are some ergonomic warts in javaâs case, it does show that something like interrupts can work reasonably well (with a sufficiently good error handling system, e.g. exceptions).<p>With âstructured concurrencyâ&#x2F;nurseries it can be much more readable than manually checking interruptions, and you can just do something like fire a bunch of requests with a given timeline, and join them at the end of the âblockâ.</div><br/></div></div></div></div><div id="41472476" class="c"><input type="checkbox" id="c-41472476" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41471936">prev</a><span>|</span><a href="#41472302">next</a><span>|</span><label class="collapse" for="c-41472476">[-]</label><label class="expand" for="c-41472476">[1 more]</label></div><br/><div class="children"><div class="content">To put a different spin on what others are saying, asynchronous IO is a different programming model for concurrency that&#x27;s actually more ergonomic and easier to get right for an average developer (which includes great developers on their not-highly-focused days).<p>Dealing with raciness, deadlocks and starvation is simply hard, especially when you are focused on solving a different but also hard business problem.<p>That&#x27;s also why RDBMSes had and continue to have such a success: they hide this complexity behind a few common patterns and a simple language.<p>Now, I do agree that languages that suffer from the &quot;color of your functions&quot; problems didn&#x27;t get it right (Python, for instance). But ultimately, this is an easier mental model, and it&#x27;s been present since the dawn of purely functional languages (nothing stops a Lisp implementation from doing async IO, and it might only be non-obvious how to do &quot;cancellation&quot; while &quot;gather&quot; is natural too)</div><br/></div></div><div id="41472302" class="c"><input type="checkbox" id="c-41472302" checked=""/><div class="controls bullet"><span class="by">dwaite</span><span>|</span><a href="#41472476">prev</a><span>|</span><a href="#41472410">next</a><span>|</span><label class="collapse" for="c-41472302">[-]</label><label class="expand" for="c-41472302">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t quite agree with this piece, as it is comparing apples and oranges.<p>What you want is patterns for having safety, efficiency and maintainability for concurrent and parallelized processing.<p>One early pattern for doing that was codified as POSIX threads - continue the blocking processing patterns of POSIX so that you can have multiple parallelizable streams of execution with primitives to protect against simultaneous use of shared resources and data.<p>IO_URING is not such a pattern. It is a kernel API. You can try to use it directly, but you can also use it as one component in a userland thread systems, in actor systems, in structured concurrency systems, etc.<p>So the author is seemingly comparing the shipped pattern (threads) vs direct manipulation, and complaining that the direct manipulation isn&#x27;t as safe or maintainable. It wasn&#x27;t meant to be.</div><br/></div></div><div id="41472410" class="c"><input type="checkbox" id="c-41472410" checked=""/><div class="controls bullet"><span class="by">nasretdinov</span><span>|</span><a href="#41472302">prev</a><span>|</span><a href="#41471946">next</a><span>|</span><label class="collapse" for="c-41472410">[-]</label><label class="expand" for="c-41472410">[1 more]</label></div><br/><div class="children"><div class="content">Somewhat controversial take: the current threads implementation is usually already performant enough for most use cases. The actual reason why we don&#x27;t use them to handle more than a few thousand concurrent operations is that, at least in Linux, threads are scheduled and treated very similarly to processes. E.g. if a single process with 3000 threads gets bottlenecked on some syscall, etc, your system load average will become 3000, and it will essentially lead to no other processes being able to run well on the same machine.<p>Another issue with threads performance is that they are visible to most system tools like `ps`, and thus having too mamy threads starts to affect operations _outside_ the kernel, e.g. many monitoring tools, etc.<p>So that&#x27;s the main reason why user-space scheduling became so popular: it hides the &quot;threads&quot; from the system, allowing for processes to be scheduled more fairly (preventing stuff like reaching LA 3000 when writing to 3000 parallel connections), and not affecting performance of the system infrastructure around the kernel.<p>BTW the threads stacks, as well as everything else in Linux are allocated lazily, so if you only use like 4Kb of stack in the thread it wouldn&#x27;t lead to RSS of full 8M. It will contribute to VMEM, but not RSS</div><br/></div></div><div id="41471946" class="c"><input type="checkbox" id="c-41471946" checked=""/><div class="controls bullet"><span class="by">BenoitP</span><span>|</span><a href="#41472410">prev</a><span>|</span><a href="#41471900">next</a><span>|</span><label class="collapse" for="c-41471946">[-]</label><label class="expand" for="c-41471946">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Now imagine a parallel universe where instead of focusing on making asynchronous IO work<p>Funny choice of words. In the JVM world, Ron Pressler&#x27;s first foray into fibers -quasar- was named &quot;parallel universe&quot;. It worked with a java agent manipulating bytecode. Then Ron went to Oracle and now we have Loom, aka a virtual thread unmounted at each async IO request.<p>Java&#x27;s Loom is not even mentioned in the article. I wonder for a cofounder: does the &quot;parallel universe&quot; appear in a other foundational paper, calling for a lightweight thread abstraction?<p><a href="https:&#x2F;&#x2F;docs.paralleluniverse.co&#x2F;quasar&#x2F;" rel="nofollow">https:&#x2F;&#x2F;docs.paralleluniverse.co&#x2F;quasar&#x2F;</a><p>Anyway, yes we need sound abstractions for async IO</div><br/><div id="41472244" class="c"><input type="checkbox" id="c-41472244" checked=""/><div class="controls bullet"><span class="by">junon</span><span>|</span><a href="#41471946">parent</a><span>|</span><a href="#41471900">next</a><span>|</span><label class="collapse" for="c-41472244">[-]</label><label class="expand" for="c-41472244">[1 more]</label></div><br/><div class="children"><div class="content">Quasar was awesome when it came out. Still remember trying to make it work when I was at Uber but it was really finicky.</div><br/></div></div></div></div><div id="41471900" class="c"><input type="checkbox" id="c-41471900" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#41471946">prev</a><span>|</span><a href="#41472207">next</a><span>|</span><label class="collapse" for="c-41471900">[-]</label><label class="expand" for="c-41471900">[1 more]</label></div><br/><div class="children"><div class="content">&gt; More specifically, what if instead of spending 20 years developing various approaches to dealing with asynchronous IO (e.g. async&#x2F;await), we had instead spent that time making OS threads more efficient, such that one wouldn&#x27;t need asynchronous IO in the first place?<p>This is still living in an antiquated world where IO was infrequent and contained enough that one blocking call per thread still made you reasonable forward progress. When youâre making three separate calls and correlating the data between them having the entire thread blocked for each call is still problematic.<p>Linux can handle far more threads than Windows and it still employs io_uring. Why do you suppose that is?<p>One little yellow box about it is not enough to defend the thesis of this article.</div><br/></div></div><div id="41472207" class="c"><input type="checkbox" id="c-41472207" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#41471900">prev</a><span>|</span><a href="#41472269">next</a><span>|</span><label class="collapse" for="c-41472207">[-]</label><label class="expand" for="c-41472207">[1 more]</label></div><br/><div class="children"><div class="content">Asynchronous IO is just simply how the world works. Instead, the idea that changes happen only during CPU computation is the  mistake. Your disk drive&#x2F;network card exists in parallel to your CPU and can process stuff concurrently. Your CPU very likely has a DMA engine that works in parallel without consuming a hardware thread.</div><br/></div></div><div id="41472269" class="c"><input type="checkbox" id="c-41472269" checked=""/><div class="controls bullet"><span class="by">sedatk</span><span>|</span><a href="#41472207">prev</a><span>|</span><a href="#41472552">next</a><span>|</span><label class="collapse" for="c-41472269">[-]</label><label class="expand" for="c-41472269">[1 more]</label></div><br/><div class="children"><div class="content">Many synchronous I&#x2F;O operations under the hood are just async I&#x2F;O + blocking waits, at least that&#x27;s the case with Windows. Why? Because all I&#x2F;O is inherently async. Even polling I&#x2F;O requires timed waits which also makes it async.<p>That said, I like async programming model in general, not just for I&#x2F;O. It makes modeling your software as separetely flowing operations that need to be synchronized occasionally quite easy. Some tasks need to run in parallel? Then, you just wait for them later.<p>I also like the channel concept of Golang and D in the same manner, but I heard it brought up some problems that async&#x2F;await model didn&#x27;t have. Can&#x27;t remember what it was now. Maybe they are more susceptible to race conditions? Not sure.</div><br/></div></div><div id="41472552" class="c"><input type="checkbox" id="c-41472552" checked=""/><div class="controls bullet"><span class="by">dfgdfg34545456</span><span>|</span><a href="#41472269">prev</a><span>|</span><a href="#41472434">next</a><span>|</span><label class="collapse" for="c-41472552">[-]</label><label class="expand" for="c-41472552">[1 more]</label></div><br/><div class="children"><div class="content">The post seems to be assuming that multi threaded code is easy to build and maintain. From my experience it is horrible, every new thread means going from n bugs to n<i>n bugs. As a programmer I </i>prefer* async constructs in languages, and do not want to spin up and manage threads and all the state synchronisation that involves.</div><br/></div></div><div id="41472434" class="c"><input type="checkbox" id="c-41472434" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#41472552">prev</a><span>|</span><a href="#41471973">next</a><span>|</span><label class="collapse" for="c-41472434">[-]</label><label class="expand" for="c-41472434">[2 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;Not only would this offer an easier mental model for developers...&quot;<p>Translation: &quot;I find async i&#x2F;o confusing and all developers are like me&quot;.<p>This argument has been going on for over 20 years at this point. There are some people who think having pools of threads polling is a natural way of thinking about IO. They keep waiting for the day this becomes an efficient way to do IO.</div><br/><div id="41472487" class="c"><input type="checkbox" id="c-41472487" checked=""/><div class="controls bullet"><span class="by">tankenmate</span><span>|</span><a href="#41472434">parent</a><span>|</span><a href="#41471973">next</a><span>|</span><label class="collapse" for="c-41472487">[-]</label><label class="expand" for="c-41472487">[1 more]</label></div><br/><div class="children"><div class="content">I would concur, the author also mentions that file IO isn&#x27;t async; this makes me conclude that the author hasn&#x27;t grasped how much the Linux kernel has moved on since in the mid 2000s.<p>I suspect that the author has an incomplete view of the current kernel &#x2F; userland interface as well as the inner workings of how a kernel actually &quot;does what it does&quot;.</div><br/></div></div></div></div><div id="41471973" class="c"><input type="checkbox" id="c-41471973" checked=""/><div class="controls bullet"><span class="by">p1necone</span><span>|</span><a href="#41472434">prev</a><span>|</span><a href="#41472466">next</a><span>|</span><label class="collapse" for="c-41471973">[-]</label><label class="expand" for="c-41471973">[6 more]</label></div><br/><div class="children"><div class="content">Async&#x2F;await is a language semantics thing. It&#x27;s not really relevant whether there&#x27;s a &quot;real&quot; OS thread under the hood, some language level green thread system, or just the current process blocking on something - the syntax exists because sometimes you <i>don&#x27;t</i> want to block on things that take a long time <i>semantically</i> - I.e. you want the next line of code to run immediately.<p>You could absolutely write a language where the blocking on long running tasks was implicit and instead there was a keyword for when you <i>don&#x27;t</i> want to block, but the programmer doesn&#x27;t really need to care about the underlying threading system.</div><br/><div id="41472165" class="c"><input type="checkbox" id="c-41472165" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41471973">parent</a><span>|</span><a href="#41472415">next</a><span>|</span><label class="collapse" for="c-41472165">[-]</label><label class="expand" for="c-41472165">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s something like what Go does. Goroutines are &quot;green threads&quot; - they can be preempted. There&#x27;s a CPU scheduler in user space. Go tries to provide &quot;async&quot; performance, and goroutines have minimal state. This seems to work well for the web server case.<p>Pure &quot;Async&quot; means your application is now in the CPU dispatching business.  This works well only if 
your application is totally I&#x2F;O bound and has no substantial compute sections. Outside of that use case, it may be a huge mismatch to the problem. Worst case tends to be programs where almost all the time, something is fast, but sometimes it takes a lot of compute. Then all those quick async tasks get stuck behind the compute-bound operation. Web browsers struggle with that class of problems.<p>Async I&#x2F;O tends to be over-used today because Javascript works that way.  Many programmers came up from Javascript land. That&#x27;s the only way they can conceive concurrency. It&#x27;s a simple, clean model - no need for locks.<p>Threading is hard. Especially in languages that don&#x27;t provide much help with locking. Even then, you have lock order problems, deadlocks, starvation, futex congestion...</div><br/><div id="41472218" class="c"><input type="checkbox" id="c-41472218" checked=""/><div class="controls bullet"><span class="by">Yoric</span><span>|</span><a href="#41471973">root</a><span>|</span><a href="#41472165">parent</a><span>|</span><a href="#41472415">next</a><span>|</span><label class="collapse" for="c-41472218">[-]</label><label class="expand" for="c-41472218">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a simple, clean model - no need for locks.<p>Nit: You can very easily have race conditions in async JS. There are all sorts of Mutex-style structures for async.</div><br/><div id="41472288" class="c"><input type="checkbox" id="c-41472288" checked=""/><div class="controls bullet"><span class="by">ayewo</span><span>|</span><a href="#41471973">root</a><span>|</span><a href="#41472218">parent</a><span>|</span><a href="#41472415">next</a><span>|</span><label class="collapse" for="c-41472288">[-]</label><label class="expand" for="c-41472288">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s really interesting. Care to share a link to 1 or 2 real world examples of this that you&#x27;ve seen?<p>Or even better, examples of how one would write such locks in JS that would be effective against these type of race conditions?</div><br/><div id="41472546" class="c"><input type="checkbox" id="c-41472546" checked=""/><div class="controls bullet"><span class="by">mmis1000</span><span>|</span><a href="#41471973">root</a><span>|</span><a href="#41472288">parent</a><span>|</span><a href="#41472415">next</a><span>|</span><label class="collapse" for="c-41472546">[-]</label><label class="expand" for="c-41472546">[1 more]</label></div><br/><div class="children"><div class="content">Having race condition in js is more about having questionable programming practice though.<p>Instead of write result of operations into separate variables and aggregate them later. You write them into the same variable with unspecified order and prey they will work correctly. There won&#x27;t be memory corruption or something. But the results you got won&#x27;t be correct either.<p>This type of problems is probably what rust try to address. (Rust will probably tell you to fxxk off because the write permission shouldn&#x27;t be grant by two place at same time) But unfortunately there isn&#x27;t rust for js. So only thing you can do is take care of it yourself.</div><br/></div></div></div></div></div></div></div></div><div id="41472415" class="c"><input type="checkbox" id="c-41472415" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41471973">parent</a><span>|</span><a href="#41472165">prev</a><span>|</span><a href="#41472466">next</a><span>|</span><label class="collapse" for="c-41472415">[-]</label><label class="expand" for="c-41472415">[1 more]</label></div><br/><div class="children"><div class="content">Async&#x2F;await and threading+blocking are ultimately duals of each other. You can express the same semantics with one model or the other, regardless of the underlying implementation of either. You could in fact implement multi-threading and blocking on top a task-based API if you wanted to - e.g. you could implement a Java style Threads API in JS if you really wanted to (of course, code would still run single threaded, like in old times with single-CPU systems).</div><br/></div></div></div></div><div id="41472466" class="c"><input type="checkbox" id="c-41472466" checked=""/><div class="controls bullet"><span class="by">pyrolistical</span><span>|</span><a href="#41471973">prev</a><span>|</span><a href="#41472186">next</a><span>|</span><label class="collapse" for="c-41472466">[-]</label><label class="expand" for="c-41472466">[1 more]</label></div><br/><div class="children"><div class="content">What if the authorâs proposed solution is the billion dollar mistake?<p>IMO the best programming paradigms are when the abstractions are close to the hardware.<p>Instead of pretending to have unlimited cores, what if as part of the runtime of we are given the exactly one thread per core. As the programmer we are responsible for utilizing all the cores and passing data around.<p>It is then up to the operating system to switch entire sets of cores over different processes.<p>This removes the footgun of a process overloading a computer with too many threads. Programmers need to consider how to best distribute work over a finite number of cores.</div><br/></div></div><div id="41472186" class="c"><input type="checkbox" id="c-41472186" checked=""/><div class="controls bullet"><span class="by">jeffreygoesto</span><span>|</span><a href="#41472466">prev</a><span>|</span><a href="#41472575">next</a><span>|</span><label class="collapse" for="c-41472186">[-]</label><label class="expand" for="c-41472186">[1 more]</label></div><br/><div class="children"><div class="content">Some answer was already posted here:<p><a href="https:&#x2F;&#x2F;utcc.utoronto.ca&#x2F;~cks&#x2F;space&#x2F;blog&#x2F;tech&#x2F;OSThreadsAlwaysExpensive" rel="nofollow">https:&#x2F;&#x2F;utcc.utoronto.ca&#x2F;~cks&#x2F;space&#x2F;blog&#x2F;tech&#x2F;OSThreadsAlway...</a><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41472027">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41472027</a><p>To me the article reads as if the programming language author wants to push a difficult problem out of his language without deeper analysis. As if it would be easier if it was somebody else&#x27;s problem.</div><br/></div></div><div id="41472575" class="c"><input type="checkbox" id="c-41472575" checked=""/><div class="controls bullet"><span class="by">algobro</span><span>|</span><a href="#41472186">prev</a><span>|</span><a href="#41472237">next</a><span>|</span><label class="collapse" for="c-41472575">[-]</label><label class="expand" for="c-41472575">[1 more]</label></div><br/><div class="children"><div class="content">The 1990s called. They want their threads vs events debates back.</div><br/></div></div><div id="41472237" class="c"><input type="checkbox" id="c-41472237" checked=""/><div class="controls bullet"><span class="by">alexgartrell</span><span>|</span><a href="#41472575">prev</a><span>|</span><a href="#41472472">next</a><span>|</span><label class="collapse" for="c-41472237">[-]</label><label class="expand" for="c-41472237">[1 more]</label></div><br/><div class="children"><div class="content">&gt; File IO is perhaps the best example of this (at least on Linux). To handle such cases, languages must provide some sort of alternative strategy such as performing the work in a dedicated pool of OS threads.<p>AIO has existed for a long time. A lot longer than io_uring.<p>I think the thing that the author misses here is that the majority of IO that happens is actually interrupt driven in the first place, so async io is always going to be the more efficient approach.<p>The author also misses that scheduling threads efficiently from a kernel context is really hard. Async io also confers a benefit in terms of âdata scheduling.â This is more relevant for workloads like memcached.</div><br/></div></div><div id="41472472" class="c"><input type="checkbox" id="c-41472472" checked=""/><div class="controls bullet"><span class="by">mmis1000</span><span>|</span><a href="#41472237">prev</a><span>|</span><a href="#41472247">next</a><span>|</span><label class="collapse" for="c-41472472">[-]</label><label class="expand" for="c-41472472">[1 more]</label></div><br/><div class="children"><div class="content">I think compare programing pattern(threads) to kernel async apis is a questionable comparation.<p>The point of kernel async apis is not about letting programmers write system calls directly. It&#x27;s about expose the actual async operations under the hook (it could be disk, be network, be anything outside of the computer case).<p>Those actions are never mean to be interleaved with cpu computation, because they are usually with ms level delay (which could be millions of cpu ticks). The kernel fakes these into sync calls by pause everything. But it isn&#x27;t always the best idea to do these.<p>Let userland program decide what they want to do with the delay will be a way better idea. Even they eventually just invent blocking io calls again. They can still decide what operations are more relevant to itself instead of let the kernel guessing it.</div><br/></div></div><div id="41472247" class="c"><input type="checkbox" id="c-41472247" checked=""/><div class="controls bullet"><span class="by">Someone</span><span>|</span><a href="#41472472">prev</a><span>|</span><a href="#41472233">next</a><span>|</span><label class="collapse" for="c-41472247">[-]</label><label class="expand" for="c-41472247">[1 more]</label></div><br/><div class="children"><div class="content">FTA: <i>âNeed to call a C function that may block the calling thread? Just run it on a separate thread, instead of having to rely on some sort of mechanism provided by the IO runtime&#x2F;language to deal with blocking C function calls.â</i><p>And then? How do you know when your call completed without âsome sort of mechanism provided by the IO runtime&#x2F;languageâ? Yes, you periodically ask the OS whether that thread completed, but that doesnât come for free and is far from elegant.<p>There are solutions. The cheapest, resource-wise, are I&#x2F;O completion callbacks. Thatâs what âSystemâ had on the original Mac in 1984, and there likely were even smaller systems before that had them.<p>Easier for programmers would be something like what we now have with async&#x2F;await.<p>It might not be the best option, but AFAICT, this article doesnât propose a better one. Yes, firing off threads is easy, but getting the parts together the moment theyâre all available isnât.</div><br/></div></div><div id="41472233" class="c"><input type="checkbox" id="c-41472233" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#41472247">prev</a><span>|</span><a href="#41472480">next</a><span>|</span><label class="collapse" for="c-41472233">[-]</label><label class="expand" for="c-41472233">[2 more]</label></div><br/><div class="children"><div class="content">Correct me if I&#x27;m wrong, but Microsoft&#x27;s DirectStorage seems to me something like what the author is writing about. It lets you do eg massively parallel NVME file io ops from the GPU itself of lots of small files. This avoids the delay of the path through the CPU, any extra threads&#x2F;saturation of the CPU, and even lets you do eg decompression of game assets on the GPU itself thereby saving even more CPU. This demo benchmark shows DEFLATE going from 1 GB&#x2F;s on CPU to 7 GBs&#x2F; on GPU <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;DirectStorage&#x2F;tree&#x2F;main&#x2F;Samples&#x2F;GpuDecompressionBenchmark">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;DirectStorage&#x2F;tree&#x2F;main&#x2F;Samples...</a></div><br/><div id="41472488" class="c"><input type="checkbox" id="c-41472488" checked=""/><div class="controls bullet"><span class="by">dudeinjapan</span><span>|</span><a href="#41472233">parent</a><span>|</span><a href="#41472480">next</a><span>|</span><label class="collapse" for="c-41472488">[-]</label><label class="expand" for="c-41472488">[1 more]</label></div><br/><div class="children"><div class="content">I interpreted it as mainly network I&#x2F;O, but the core point in the article is less about the I&#x2F;O itself and more about thread-based async I&#x2F;O handling.</div><br/></div></div></div></div><div id="41472480" class="c"><input type="checkbox" id="c-41472480" checked=""/><div class="controls bullet"><span class="by">ivanjermakov</span><span>|</span><a href="#41472233">prev</a><span>|</span><a href="#41471880">next</a><span>|</span><label class="collapse" for="c-41472480">[-]</label><label class="expand" for="c-41472480">[1 more]</label></div><br/><div class="children"><div class="content">Async IO is not only about creating sockets and spawning threads. Idea of async IO is that the world is not controlled by your CPU. There are network, storage, sound devices that might and will take time to produce the result and the CPU has to wait for it.<p>I feel like there is a big misunderstanding about what async IO is and what problem it solves.</div><br/></div></div><div id="41471880" class="c"><input type="checkbox" id="c-41471880" checked=""/><div class="controls bullet"><span class="by">CJefferson</span><span>|</span><a href="#41472480">prev</a><span>|</span><a href="#41472231">next</a><span>|</span><label class="collapse" for="c-41471880">[-]</label><label class="expand" for="c-41471880">[1 more]</label></div><br/><div class="children"><div class="content">I generally agree with this article.<p>There are programs where async IO is great, but in my experience it stops being useful as your code âdoes more stuffâ.<p>The few large scale async systems Iâve worked with end up with functions taking too long, so you use ability to spin off functions into threadpools, then async wait for their return, at which point you often end up with the worst of both threads and async.</div><br/></div></div><div id="41472231" class="c"><input type="checkbox" id="c-41472231" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#41471880">prev</a><span>|</span><a href="#41472353">next</a><span>|</span><label class="collapse" for="c-41472231">[-]</label><label class="expand" for="c-41472231">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Now imagine a parallel universe where instead of focusing on making asynchronous IO work, we focused on improving the performance of OS threads such that one can easily use hundreds of thousands of OS threads without negatively impacting performance<p>Isn&#x27;t that why async I&#x2F;O was created in the first place?<p>&gt; Just use 100 000 threads and let the OS handle it.<p>How does the OS handle it? How does the OS know whether to give it CPU time or not?<p>I was expecting something from the OP (like a new networking or multi-threading primitive) but I have a feeling he lacks an understanding of how networking and async I&#x2F;O works.</div><br/></div></div><div id="41472353" class="c"><input type="checkbox" id="c-41472353" checked=""/><div class="controls bullet"><span class="by">lima</span><span>|</span><a href="#41472231">prev</a><span>|</span><a href="#41472370">next</a><span>|</span><label class="collapse" for="c-41472353">[-]</label><label class="expand" for="c-41472353">[1 more]</label></div><br/><div class="children"><div class="content">Google&#x27;s SwitchTo kernel patches are similar to what you describe: <a href="https:&#x2F;&#x2F;lore.kernel.org&#x2F;lkml&#x2F;20200722234538.166697-1-posk@posk.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lore.kernel.org&#x2F;lkml&#x2F;20200722234538.166697-1-posk@po...</a><p>Slides: <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20200802205544&#x2F;https:&#x2F;&#x2F;pdxplumbers.osuosl.org&#x2F;2013&#x2F;ocw&#x2F;&#x2F;system&#x2F;presentations&#x2F;1653&#x2F;original&#x2F;LPC%20-%20User%20Threading.pdf" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20200802205544&#x2F;https:&#x2F;&#x2F;pdxplumbe...</a></div><br/></div></div><div id="41472370" class="c"><input type="checkbox" id="c-41472370" checked=""/><div class="controls bullet"><span class="by">weinzierl</span><span>|</span><a href="#41472353">prev</a><span>|</span><a href="#41471902">next</a><span>|</span><label class="collapse" for="c-41472370">[-]</label><label class="expand" for="c-41472370">[2 more]</label></div><br/><div class="children"><div class="content"><i>&quot;Not every IO operation can be performed asynchronously though. File IO is perhaps the best example of this (at least on Linux). To handle such cases, languages must provide some sort of alternative strategy such as performing the work in a dedicated pool of OS threads.&quot;</i><p>Can someone explain, why this would be the case?<p>- Why can&#x27;t every IO op be async?<p>- Why is file IO on Linux not async?<p>- What does iouring have to do with it?</div><br/><div id="41472507" class="c"><input type="checkbox" id="c-41472507" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#41472370">parent</a><span>|</span><a href="#41471902">next</a><span>|</span><label class="collapse" for="c-41472507">[-]</label><label class="expand" for="c-41472507">[1 more]</label></div><br/><div class="children"><div class="content">File IO can absolutely be async on linux[1] and this has been supported since version 2.5 or something provided that the device supports it (which they all have since about 2000). io_uring was the syscall interface that was introduced in 5.1 to improve async file i&#x2F;o performance so it is relevant in that the previous way to do it wasn&#x27;t great.<p>[1] <a href="https:&#x2F;&#x2F;kkourt.io&#x2F;blog&#x2F;2017&#x2F;10-14-linux-aio.html" rel="nofollow">https:&#x2F;&#x2F;kkourt.io&#x2F;blog&#x2F;2017&#x2F;10-14-linux-aio.html</a> &lt;- note the 2017 date.</div><br/></div></div></div></div><div id="41471902" class="c"><input type="checkbox" id="c-41471902" checked=""/><div class="controls bullet"><span class="by">_davide_</span><span>|</span><a href="#41472370">prev</a><span>|</span><a href="#41472384">next</a><span>|</span><label class="collapse" for="c-41471902">[-]</label><label class="expand" for="c-41471902">[2 more]</label></div><br/><div class="children"><div class="content">What about memory? the real price of threads is the stack.<p>Even when perfectly optimized, it wouldn&#x27;t be enough to handle serious workloads.</div><br/><div id="41472146" class="c"><input type="checkbox" id="c-41472146" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#41471902">parent</a><span>|</span><a href="#41472384">next</a><span>|</span><label class="collapse" for="c-41472146">[-]</label><label class="expand" for="c-41472146">[1 more]</label></div><br/><div class="children"><div class="content">Well, the runtime (instead of the OS) knows better and can e.g. allocate part of the call stack on the heap itself, like how Javaâs virtual threads do.</div><br/></div></div></div></div><div id="41472384" class="c"><input type="checkbox" id="c-41472384" checked=""/><div class="controls bullet"><span class="by">praptak</span><span>|</span><a href="#41471902">prev</a><span>|</span><a href="#41472344">next</a><span>|</span><label class="collapse" for="c-41472384">[-]</label><label class="expand" for="c-41472384">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s an effort by Google to address this with userspace threads. I think it has stalled though.<p>HN discussion thereof: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23964633">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23964633</a></div><br/></div></div><div id="41472344" class="c"><input type="checkbox" id="c-41472344" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#41472384">prev</a><span>|</span><a href="#41471893">next</a><span>|</span><label class="collapse" for="c-41472344">[-]</label><label class="expand" for="c-41472344">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not clear that context switches can be made sufficiently cheap on fast CPUs without disabling mitigations for side-channel attacks. So the idea of making OS threads comparably performant to goroutines, rust async, or any implementation of cooperative multithreading seems impractical.</div><br/></div></div><div id="41471893" class="c"><input type="checkbox" id="c-41471893" checked=""/><div class="controls bullet"><span class="by">nullindividual</span><span>|</span><a href="#41472344">prev</a><span>|</span><a href="#41472141">next</a><span>|</span><label class="collapse" for="c-41471893">[-]</label><label class="expand" for="c-41471893">[3 more]</label></div><br/><div class="children"><div class="content">We do live in the universe of high performance threads <i>with</i> asynchronous I&#x2F;O.<p>The author is looking for Windows NT.</div><br/><div id="41472061" class="c"><input type="checkbox" id="c-41472061" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#41471893">parent</a><span>|</span><a href="#41472141">next</a><span>|</span><label class="collapse" for="c-41472061">[-]</label><label class="expand" for="c-41472061">[2 more]</label></div><br/><div class="children"><div class="content">The same Windows NT whose decades-old async IO capabilities are so good they immediately cloned io_uring?</div><br/><div id="41472157" class="c"><input type="checkbox" id="c-41472157" checked=""/><div class="controls bullet"><span class="by">lmz</span><span>|</span><a href="#41471893">root</a><span>|</span><a href="#41472061">parent</a><span>|</span><a href="#41472141">next</a><span>|</span><label class="collapse" for="c-41472157">[-]</label><label class="expand" for="c-41472157">[1 more]</label></div><br/><div class="children"><div class="content">Sorry, which one came first between io_uring and windows RIO? <a href="https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;previous-versions&#x2F;windows&#x2F;it-pro&#x2F;windows-server-2012-r2-and-2012&#x2F;hh997032(v=ws.11)" rel="nofollow">https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;previous-versions&#x2F;windows&#x2F;...</a></div><br/></div></div></div></div></div></div><div id="41472141" class="c"><input type="checkbox" id="c-41472141" checked=""/><div class="controls bullet"><span class="by">josefrichter</span><span>|</span><a href="#41471893">prev</a><span>|</span><label class="collapse" for="c-41472141">[-]</label><label class="expand" for="c-41472141">[2 more]</label></div><br/><div class="children"><div class="content">Isnât that parallel universe actually the Erlang BEAM?</div><br/><div id="41472465" class="c"><input type="checkbox" id="c-41472465" checked=""/><div class="controls bullet"><span class="by">BenoitP</span><span>|</span><a href="#41472141">parent</a><span>|</span><label class="collapse" for="c-41472465">[-]</label><label class="expand" for="c-41472465">[1 more]</label></div><br/><div class="children"><div class="content">Or Go. Or Java&#x27; virtual threads.<p>It must happen at the language level; When it comes to execution context knowledge: what context to compile out (stackless), or what context to serialize to the heap (stackful). Programming language will always know much more about the program than the OS.<p>If I&#x27;m not mistaken in Erlang the programmer will provide the exact context to serialize : the actor.</div><br/></div></div></div></div></div></div></div></div></div></body></html>