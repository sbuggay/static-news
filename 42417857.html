<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1734339678010" as="style"/><link rel="stylesheet" href="styles.css?v=1734339678010"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://andrewkchan.dev/posts/yalm.html">Fast LLM Inference From Scratch (using CUDA)</a> <span class="domain">(<a href="https://andrewkchan.dev">andrewkchan.dev</a>)</span></div><div class="subtext"><span>homarp</span> | <span>13 comments</span></div><br/><div><div id="42425641" class="c"><input type="checkbox" id="c-42425641" checked=""/><div class="controls bullet"><span class="by">shihab</span><span>|</span><a href="#42427189">next</a><span>|</span><label class="collapse" for="c-42425641">[-]</label><label class="expand" for="c-42425641">[2 more]</label></div><br/><div class="children"><div class="content">Excellent, amazing article.<p>To the author, if you&#x27;re lurking here, I have a tangential question- how long did it take you to write this article? From first line of code to the last line of this post?<p>As someone who works in GPGPU space, I can imagine myself writing an article of this sort. But the huge uncertainty around time needed has deterred me so far.</div><br/><div id="42427359" class="c"><input type="checkbox" id="c-42427359" checked=""/><div class="controls bullet"><span class="by">lgas</span><span>|</span><a href="#42425641">parent</a><span>|</span><a href="#42427189">next</a><span>|</span><label class="collapse" for="c-42427359">[-]</label><label class="expand" for="c-42427359">[1 more]</label></div><br/><div class="children"><div class="content">Why not give it a shot and see how it goes?  You should be able to have some idea if you want to proceed within an hour or two.</div><br/></div></div></div></div><div id="42427189" class="c"><input type="checkbox" id="c-42427189" checked=""/><div class="controls bullet"><span class="by">reasonableklout</span><span>|</span><a href="#42425641">prev</a><span>|</span><a href="#42425439">next</a><span>|</span><label class="collapse" for="c-42427189">[-]</label><label class="expand" for="c-42427189">[2 more]</label></div><br/><div class="children"><div class="content">Hi, I&#x27;m the author. Thanks for sharing, was great to wake up to my blog post on the front page! Would love to hear any feedback or if I missed anything.</div><br/><div id="42427973" class="c"><input type="checkbox" id="c-42427973" checked=""/><div class="controls bullet"><span class="by">jmorgan</span><span>|</span><a href="#42427189">parent</a><span>|</span><a href="#42425439">next</a><span>|</span><label class="collapse" for="c-42427973">[-]</label><label class="expand" for="c-42427973">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for writing this!</div><br/></div></div></div></div><div id="42425439" class="c"><input type="checkbox" id="c-42425439" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#42427189">prev</a><span>|</span><a href="#42426500">next</a><span>|</span><label class="collapse" for="c-42425439">[-]</label><label class="expand" for="c-42425439">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this code can make use of the tensor cores, or the wgmma instructions that you typically need to get peak performance out of them.<p>Programming these is a nightmare as you need to have several in flight concurrently for peak performance.<p>Perhaps you don&#x27;t need the extra flops as you end up bandwidth bound?<p>Regardless the good thing about the code in the blog though is it&#x27;ll probably work pretty well for other accelerators, if you port it to HIP or similar. If you use wgmma I&#x27;m not sure it&#x27;ll even be portable across Nvidia generations.</div><br/><div id="42425512" class="c"><input type="checkbox" id="c-42425512" checked=""/><div class="controls bullet"><span class="by">chillee</span><span>|</span><a href="#42425439">parent</a><span>|</span><a href="#42426500">next</a><span>|</span><label class="collapse" for="c-42425512">[-]</label><label class="expand" for="c-42425512">[3 more]</label></div><br/><div class="children"><div class="content">For latency-bound inference (i.e. one request) you don&#x27;t need tensor-cores since all your operations are just matrix vector multiplications.</div><br/><div id="42425732" class="c"><input type="checkbox" id="c-42425732" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#42425439">root</a><span>|</span><a href="#42425512">parent</a><span>|</span><a href="#42426500">next</a><span>|</span><label class="collapse" for="c-42425732">[-]</label><label class="expand" for="c-42425732">[2 more]</label></div><br/><div class="children"><div class="content">Good point yes. That explains why he&#x27;s getting performance similar to the leading frameworks. Those tensor operations are helpful for training or for throughput-optimised batched inference but not really for a batch size of one.</div><br/><div id="42427178" class="c"><input type="checkbox" id="c-42427178" checked=""/><div class="controls bullet"><span class="by">reasonableklout</span><span>|</span><a href="#42425439">root</a><span>|</span><a href="#42425732">parent</a><span>|</span><a href="#42426500">next</a><span>|</span><label class="collapse" for="c-42427178">[-]</label><label class="expand" for="c-42427178">[1 more]</label></div><br/><div class="children"><div class="content">I actually didn&#x27;t know that. I&#x27;m in the space as a hobbyist and I had a vague understanding that tensor cores are essential for reaching peak performance, but can only work for certain operations like dense matrix-matrix multiplication. It was on my list to investigate whether they could be used to further improve single-batch decoding - makes sense that they don&#x27;t help when it&#x27;s all matrix-vector.</div><br/></div></div></div></div></div></div></div></div><div id="42426500" class="c"><input type="checkbox" id="c-42426500" checked=""/><div class="controls bullet"><span class="by">diego898</span><span>|</span><a href="#42425439">prev</a><span>|</span><a href="#42426090">next</a><span>|</span><label class="collapse" for="c-42426500">[-]</label><label class="expand" for="c-42426500">[1 more]</label></div><br/><div class="children"><div class="content">This is great thank you!<p>Does any one know of something similar in python? I want to share with my team something similar to this that goes into  (almost) everything (at least conceptually) needed to efficiently serve an LLM.<p>It doesn’t actually need to be performant mind you (it’s in python) I just need something “conceptually complete” while being more “tutorial style” and concise than vLLM codebase</div><br/></div></div><div id="42426090" class="c"><input type="checkbox" id="c-42426090" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#42426500">prev</a><span>|</span><a href="#42426831">next</a><span>|</span><label class="collapse" for="c-42426090">[-]</label><label class="expand" for="c-42426090">[1 more]</label></div><br/><div class="children"><div class="content">I wonder how does the perf in tokens&#x2F;second compares to my version of Mistral: <a href="https:&#x2F;&#x2F;github.com&#x2F;Const-me&#x2F;Cgml&#x2F;tree&#x2F;master&#x2F;Mistral&#x2F;MistralChat">https:&#x2F;&#x2F;github.com&#x2F;Const-me&#x2F;Cgml&#x2F;tree&#x2F;master&#x2F;Mistral&#x2F;Mistral...</a><p>BTW, see that section of the readme about quantization: <a href="https:&#x2F;&#x2F;github.com&#x2F;Const-me&#x2F;Cgml&#x2F;tree&#x2F;master?tab=readme-ov-file#bcml1-codec">https:&#x2F;&#x2F;github.com&#x2F;Const-me&#x2F;Cgml&#x2F;tree&#x2F;master?tab=readme-ov-f...</a></div><br/></div></div><div id="42426831" class="c"><input type="checkbox" id="c-42426831" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42426090">prev</a><span>|</span><label class="collapse" for="c-42426831">[-]</label><label class="expand" for="c-42426831">[2 more]</label></div><br/><div class="children"><div class="content">Isn’t __shfl_down not recommended these days because of warp synchronization issues?</div><br/><div id="42427234" class="c"><input type="checkbox" id="c-42427234" checked=""/><div class="controls bullet"><span class="by">reasonableklout</span><span>|</span><a href="#42426831">parent</a><span>|</span><label class="collapse" for="c-42427234">[-]</label><label class="expand" for="c-42427234">[1 more]</label></div><br/><div class="children"><div class="content">Oops, you&#x27;re right and it&#x27;s a difference between my blog post and source code. It should be __shfl_down_sync as seen [here](<a href="https:&#x2F;&#x2F;github.com&#x2F;andrewkchan&#x2F;yalm&#x2F;blob&#x2F;8c908f23f5d8cc3f14c941b3ca88b18832e34f2b&#x2F;src&#x2F;infer.cu#L126">https:&#x2F;&#x2F;github.com&#x2F;andrewkchan&#x2F;yalm&#x2F;blob&#x2F;8c908f23f5d8cc3f14c...</a>)</div><br/></div></div></div></div></div></div></div></div></div></body></html>