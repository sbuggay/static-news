<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1721984466086" as="style"/><link rel="stylesheet" href="styles.css?v=1721984466086"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/">AI solves International Math Olympiad problems at silver medal level</a> <span class="domain">(<a href="https://deepmind.google">deepmind.google</a>)</span></div><div class="subtext"><span>ocfnash</span> | <span>308 comments</span></div><br/><div><div id="41070333" class="c"><input type="checkbox" id="c-41070333" checked=""/><div class="controls bullet"><span class="by">Smaug123</span><span>|</span><a href="#41073850">next</a><span>|</span><label class="collapse" for="c-41070333">[-]</label><label class="expand" for="c-41070333">[65 more]</label></div><br/><div class="children"><div class="content">So I am extremely hyped about this, but it&#x27;s not clear to me how much heavy lifting this sentence is doing:<p>&gt; First, the problems were manually translated into formal mathematical language for our systems to understand.<p>The non-geometry problems which were solved were all of the form &quot;Determine all X such that…&quot;, and the resulting theorem statements are all of the form &quot;We show that the set of all X is {foo}&quot;. The downloadable solutions from <a href="https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;DeepMind.com&#x2F;Blog&#x2F;imo-2024-solutions&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;DeepMind.com&#x2F;B...</a> don&#x27;t make it clear whether the set {foo} was decided by a human during this translation step, or whether the computer found it. I <i>want</i> to believe that the computer found it, but I can&#x27;t find anything to confirm. Anyone know?</div><br/><div id="41070372" class="c"><input type="checkbox" id="c-41070372" checked=""/><div class="controls bullet"><span class="by">ocfnash</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41070854">next</a><span>|</span><label class="collapse" for="c-41070372">[-]</label><label class="expand" for="c-41070372">[34 more]</label></div><br/><div class="children"><div class="content">The computer did find the answers itself. I.e., it found &quot;even integers&quot; for P1, &quot;{1,1}&quot; for P2, and &quot;2&quot; for P6. It then also provided provided a Lean proof in each case.</div><br/><div id="41076748" class="c"><input type="checkbox" id="c-41076748" checked=""/><div class="controls bullet"><span class="by">freehorse</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070372">parent</a><span>|</span><a href="#41071245">next</a><span>|</span><label class="collapse" for="c-41076748">[-]</label><label class="expand" for="c-41076748">[1 more]</label></div><br/><div class="children"><div class="content">It would make a lot of sense for the lean-code-formalisation of the problems done by the researchers fed to the AI to be provided. Not assuming bad intent in not providing them, but it would help understand better the results.</div><br/></div></div><div id="41071245" class="c"><input type="checkbox" id="c-41071245" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070372">parent</a><span>|</span><a href="#41076748">prev</a><span>|</span><a href="#41070473">next</a><span>|</span><label class="collapse" for="c-41071245">[-]</label><label class="expand" for="c-41071245">[14 more]</label></div><br/><div class="children"><div class="content">Can you elaborate on how it makes guesses like this? Does it do experiments before? Is it raw LLM? Is it feedback loop based on partial progress?</div><br/><div id="41071536" class="c"><input type="checkbox" id="c-41071536" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071245">parent</a><span>|</span><a href="#41074714">next</a><span>|</span><label class="collapse" for="c-41071536">[-]</label><label class="expand" for="c-41071536">[12 more]</label></div><br/><div class="children"><div class="content">&quot;AlphaProof is a system that trains itself to prove mathematical statements in the formal language Lean. It couples a pre-trained language model with the AlphaZero reinforcement learning algorithm, which previously taught itself how to master the games of chess, shogi and Go.&quot;</div><br/><div id="41074625" class="c"><input type="checkbox" id="c-41074625" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071536">parent</a><span>|</span><a href="#41071796">next</a><span>|</span><label class="collapse" for="c-41074625">[-]</label><label class="expand" for="c-41074625">[1 more]</label></div><br/><div class="children"><div class="content">Huh, so MCTS to find the ‘best’ token using a (relatively) small, quick language model? Sounds like an interesting approach to small model text generation too…</div><br/></div></div><div id="41071796" class="c"><input type="checkbox" id="c-41071796" checked=""/><div class="controls bullet"><span class="by">JKCalhoun</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071536">parent</a><span>|</span><a href="#41074625">prev</a><span>|</span><a href="#41074714">next</a><span>|</span><label class="collapse" for="c-41071796">[-]</label><label class="expand" for="c-41071796">[10 more]</label></div><br/><div class="children"><div class="content">Yeah I am not clear the degree to which this system and LLMs are related. Are they related? Or is AlphaProof a complete tangent to CHatGPT and its ilk?</div><br/><div id="41071991" class="c"><input type="checkbox" id="c-41071991" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071796">parent</a><span>|</span><a href="#41074714">next</a><span>|</span><label class="collapse" for="c-41071991">[-]</label><label class="expand" for="c-41071991">[9 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not an English LLM (Large Language Model).<p>It&#x27;s a math Language Model. Not even sure it&#x27;s a Large Language Model. (Maybe shares a foundational model with an English LLM; I don&#x27;t know)<p>It learns mathematical statements, and generates new mathematical statements, then uses search techniques to continue. Similar to Alpha Go&#x27;s neural network, what makes it new and interesting is how the NN&#x2F;LLM part makes smart guesses that drastically prune the search tree, before the brute-force search part.<p>(This is also what humans do to solve math probrems. But humans are really, really slow at brute-force search, so we really almost entirely on the NN pattern-matching analogy-making part.)</div><br/><div id="41072552" class="c"><input type="checkbox" id="c-41072552" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071991">parent</a><span>|</span><a href="#41073538">next</a><span>|</span><label class="collapse" for="c-41072552">[-]</label><label class="expand" for="c-41072552">[1 more]</label></div><br/><div class="children"><div class="content">My reading of it is that it uses the same architecture as one of the Gemini models but does not share any weights with it. (i.e it&#x27;s not just a finetune)</div><br/></div></div><div id="41073538" class="c"><input type="checkbox" id="c-41073538" checked=""/><div class="controls bullet"><span class="by">nextos</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071991">parent</a><span>|</span><a href="#41072552">prev</a><span>|</span><a href="#41075175">next</a><span>|</span><label class="collapse" for="c-41073538">[-]</label><label class="expand" for="c-41073538">[2 more]</label></div><br/><div class="children"><div class="content">These kind of LLMs are also very interesting for software engineering. It&#x27;s just a matter of replacing Lean with something that is more oriented towards proving software properties.<p>For example, write a formal specification of a function in Dafny on Liquid Haskell and get the LLM to produce code that is formally guaranteed to be correct. Logic-based + probability-based ML.<p>All GOFAI ideas are still very useful.</div><br/><div id="41076307" class="c"><input type="checkbox" id="c-41076307" checked=""/><div class="controls bullet"><span class="by">lucioperca</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41073538">parent</a><span>|</span><a href="#41075175">next</a><span>|</span><label class="collapse" for="c-41076307">[-]</label><label class="expand" for="c-41076307">[1 more]</label></div><br/><div class="children"><div class="content">You can also verify software like compilers in Lean:<p><a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;opensource&#x2F;lean-into-verified-software-development&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;opensource&#x2F;lean-into-verified-s...</a></div><br/></div></div></div></div><div id="41075175" class="c"><input type="checkbox" id="c-41075175" checked=""/><div class="controls bullet"><span class="by">_heimdall</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071991">parent</a><span>|</span><a href="#41073538">prev</a><span>|</span><a href="#41075185">next</a><span>|</span><label class="collapse" for="c-41075175">[-]</label><label class="expand" for="c-41075175">[2 more]</label></div><br/><div class="children"><div class="content">This is really interesting. I would have expected the understanding to be that humans make a guess, test it, and learn from what did or did not work. The lessons learned from the prior tests would impact future guesses.<p>Do you know if a system like the OP is learning from failed tests to guide future tests, or is it a truly a brute force search as if it were trying to mine bitcoin?</div><br/><div id="41075984" class="c"><input type="checkbox" id="c-41075984" checked=""/><div class="controls bullet"><span class="by">Thorrez</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41075175">parent</a><span>|</span><a href="#41075185">next</a><span>|</span><label class="collapse" for="c-41075984">[-]</label><label class="expand" for="c-41075984">[1 more]</label></div><br/><div class="children"><div class="content">This quote from the article sounds like it learns from failed tests:<p>&gt;We trained AlphaProof for the IMO by proving or disproving millions of problems, covering a wide range of difficulties and mathematical topic areas over a period of weeks leading up to the competition. The training loop was also applied during the contest, reinforcing proofs of self-generated variations of the contest problems until a full solution could be found.</div><br/></div></div></div></div><div id="41075185" class="c"><input type="checkbox" id="c-41075185" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071991">parent</a><span>|</span><a href="#41075175">prev</a><span>|</span><a href="#41074714">next</a><span>|</span><label class="collapse" for="c-41075185">[-]</label><label class="expand" for="c-41075185">[3 more]</label></div><br/><div class="children"><div class="content">yeah but it doesn&#x27;t understand the exact syntax on an absolute level, does it...? I understood this to be the same as any language model applied to programming languages (aka Formal Languages). Is that mistaken?</div><br/><div id="41076106" class="c"><input type="checkbox" id="c-41076106" checked=""/><div class="controls bullet"><span class="by">Zondartul</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41075185">parent</a><span>|</span><a href="#41076018">next</a><span>|</span><label class="collapse" for="c-41076106">[-]</label><label class="expand" for="c-41076106">[1 more]</label></div><br/><div class="children"><div class="content">As far as I understand, and I may be wrong here, the system is composed of two networks: Gemini and AlphaZero. Gemini, being an ordinary LLM with some fine-tunes, only does translation from natural to formal language. Then, AlphaZero solves the problem. AlphaZero, unburdened with natural language and only dealing with &quot;playing a game in the proof space&quot;  (where the &quot;moves&quot; are commands to the Lean theorem prover), does not hallucinate in the same way an LLM does because it is nothing like an LLM.</div><br/></div></div><div id="41076018" class="c"><input type="checkbox" id="c-41076018" checked=""/><div class="controls bullet"><span class="by">danielheath</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41075185">parent</a><span>|</span><a href="#41076106">prev</a><span>|</span><a href="#41074714">next</a><span>|</span><label class="collapse" for="c-41076018">[-]</label><label class="expand" for="c-41076018">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but the problem space means that invalid outputs can be quickly identified - whereas general programming isn’t necessarily amenable to rapid checks.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41070473" class="c"><input type="checkbox" id="c-41070473" checked=""/><div class="controls bullet"><span class="by">nnarek</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070372">parent</a><span>|</span><a href="#41071245">prev</a><span>|</span><a href="#41070854">next</a><span>|</span><label class="collapse" for="c-41070473">[-]</label><label class="expand" for="c-41070473">[18 more]</label></div><br/><div class="children"><div class="content">formal definition of first theorem already contain answer of the problem 
&quot;{α : ℝ | ∃ k : ℤ, Even k ∧ α = k}&quot; (which mean set of even real numbers).if they say that they have translated first problem into formal definition then it is very interesting how they initially formalized problem without including answer in it</div><br/><div id="41070695" class="c"><input type="checkbox" id="c-41070695" checked=""/><div class="controls bullet"><span class="by">Smaug123</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070473">parent</a><span>|</span><a href="#41070547">next</a><span>|</span><label class="collapse" for="c-41070695">[-]</label><label class="expand" for="c-41070695">[6 more]</label></div><br/><div class="children"><div class="content">(You&#x27;re talking to one of the people who was part of the project, which is why I took @ocfnash&#x27;s answer as authoritative: they did not cheat.)</div><br/><div id="41072309" class="c"><input type="checkbox" id="c-41072309" checked=""/><div class="controls bullet"><span class="by">Xelynega</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070695">parent</a><span>|</span><a href="#41070547">next</a><span>|</span><label class="collapse" for="c-41072309">[-]</label><label class="expand" for="c-41072309">[5 more]</label></div><br/><div class="children"><div class="content">If they&#x27;re talking to the people who are part of the project I&#x27;d hope the answer would contain detail and not expect to be taken as authoritative.</div><br/><div id="41072679" class="c"><input type="checkbox" id="c-41072679" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41072309">parent</a><span>|</span><a href="#41070547">next</a><span>|</span><label class="collapse" for="c-41072679">[-]</label><label class="expand" for="c-41072679">[4 more]</label></div><br/><div class="children"><div class="content">If they&#x27;re talking to the public I&#x27;d hope that they don&#x27;t face an infinite loop of ever-more stringent requirements for proof they didn&#x27;t give it the answer in the question.</div><br/></div></div></div></div></div></div><div id="41070547" class="c"><input type="checkbox" id="c-41070547" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070473">parent</a><span>|</span><a href="#41070695">prev</a><span>|</span><a href="#41071685">next</a><span>|</span><label class="collapse" for="c-41070547">[-]</label><label class="expand" for="c-41070547">[6 more]</label></div><br/><div class="children"><div class="content">I would expect that in their data which they train AlphaProof on they have some concept of a &quot;vague problem&quot; whoch could just look like<p>{Formal description of the set in question} = ?<p>And then Alphaproof has to find candidate descriptions of this set and prove a theorem that they are equal to the above.<p>I doubt they would claim to solve the problem if they provided half of the answer.</div><br/><div id="41073426" class="c"><input type="checkbox" id="c-41073426" checked=""/><div class="controls bullet"><span class="by">puttycat</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070547">parent</a><span>|</span><a href="#41074512">next</a><span>|</span><label class="collapse" for="c-41073426">[-]</label><label class="expand" for="c-41073426">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I doubt they would claim to solve the problem if they provided half of the answer.<p>Stranger things have happened</div><br/></div></div><div id="41074512" class="c"><input type="checkbox" id="c-41074512" checked=""/><div class="controls bullet"><span class="by">JyB</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070547">parent</a><span>|</span><a href="#41073426">prev</a><span>|</span><a href="#41074506">next</a><span>|</span><label class="collapse" for="c-41074512">[-]</label><label class="expand" for="c-41074512">[2 more]</label></div><br/><div class="children"><div class="content">The deepmind team has a history of being misleading. The great StarCraft 2 strategist bot is still in mind.</div><br/><div id="41074957" class="c"><input type="checkbox" id="c-41074957" checked=""/><div class="controls bullet"><span class="by">totoglazer</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41074512">parent</a><span>|</span><a href="#41074506">next</a><span>|</span><label class="collapse" for="c-41074957">[-]</label><label class="expand" for="c-41074957">[1 more]</label></div><br/><div class="children"><div class="content">What’s the story with that bot? Always thought it was cool. Was that all smoke and mirrors?</div><br/></div></div></div></div><div id="41074506" class="c"><input type="checkbox" id="c-41074506" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070547">parent</a><span>|</span><a href="#41074512">prev</a><span>|</span><a href="#41074669">next</a><span>|</span><label class="collapse" for="c-41074506">[-]</label><label class="expand" for="c-41074506">[1 more]</label></div><br/><div class="children"><div class="content">To be fair, that isn&#x27;t half the answer it&#x27;s like 99% of the answer.<p>They clarified above that it provided the full answer though.</div><br/></div></div><div id="41074669" class="c"><input type="checkbox" id="c-41074669" checked=""/><div class="controls bullet"><span class="by">chx</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070547">parent</a><span>|</span><a href="#41074506">prev</a><span>|</span><a href="#41071685">next</a><span>|</span><label class="collapse" for="c-41074669">[-]</label><label class="expand" for="c-41074669">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I doubt they would claim to solve the problem if they provided half of the answer.<p>This falls under extraordinary claims require extraordinary proof and we have seen nothing of the sort.</div><br/></div></div></div></div><div id="41070562" class="c"><input type="checkbox" id="c-41070562" checked=""/><div class="controls bullet"><span class="by">cygaril</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070473">parent</a><span>|</span><a href="#41071685">prev</a><span>|</span><a href="#41070557">next</a><span>|</span><label class="collapse" for="c-41070562">[-]</label><label class="expand" for="c-41070562">[2 more]</label></div><br/><div class="children"><div class="content">Come up with many possible answers, formalize them all, and then try to prove or disprove each of them.</div><br/><div id="41074058" class="c"><input type="checkbox" id="c-41074058" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070562">parent</a><span>|</span><a href="#41070557">next</a><span>|</span><label class="collapse" for="c-41074058">[-]</label><label class="expand" for="c-41074058">[1 more]</label></div><br/><div class="children"><div class="content">This is probably partially what they did idk why it&#x27;s downvoted lol</div><br/></div></div></div></div><div id="41070557" class="c"><input type="checkbox" id="c-41070557" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070473">parent</a><span>|</span><a href="#41070562">prev</a><span>|</span><a href="#41071055">next</a><span>|</span><label class="collapse" for="c-41070557">[-]</label><label class="expand" for="c-41070557">[1 more]</label></div><br/><div class="children"><div class="content">its not clear if theorem is actual input formal definition, or formal definition was in different form.</div><br/></div></div><div id="41071055" class="c"><input type="checkbox" id="c-41071055" checked=""/><div class="controls bullet"><span class="by">pishpash</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070473">parent</a><span>|</span><a href="#41070557">prev</a><span>|</span><a href="#41070854">next</a><span>|</span><label class="collapse" for="c-41071055">[-]</label><label class="expand" for="c-41071055">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, a problem and its answer are just different ways of describing the same object. Every step of a proof is a transformation&#x2F;translation of the same object. It would be disingenuous to say that <i>some</i> heavy lifting isn&#x27;t done in formalizing a problem but it seems that step is also performed by a machine:<p>&quot;We established a bridge between these two complementary spheres by fine-tuning a Gemini model to automatically translate natural language problem statements into formal statements, creating a large library of formal problems of varying difficulty.&quot;<p>I&#x27;m confused, is the formalization by Gemini or &quot;manually&quot;? Which is it?</div><br/></div></div></div></div></div></div><div id="41070854" class="c"><input type="checkbox" id="c-41070854" checked=""/><div class="controls bullet"><span class="by">summerlight</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41070372">prev</a><span>|</span><a href="#41070467">next</a><span>|</span><label class="collapse" for="c-41070854">[-]</label><label class="expand" for="c-41070854">[11 more]</label></div><br/><div class="children"><div class="content">To speak generally, that translation part is <i>much</i> easier than the proof part. The problem with automated translation is that the translation result might be incorrect. This happens a lot when even people try formal methods by their hands, so I guess the researchers concluded that they&#x27;ll have to audit every single translation regardless of using LLM or whatever tools.</div><br/><div id="41071238" class="c"><input type="checkbox" id="c-41071238" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070854">parent</a><span>|</span><a href="#41071434">next</a><span>|</span><label class="collapse" for="c-41071238">[-]</label><label class="expand" for="c-41071238">[9 more]</label></div><br/><div class="children"><div class="content">You&#x27;d think that, but Timothy Gowers (the famous mathematician they worked with) wrote (<a href="https:&#x2F;&#x2F;x.com&#x2F;wtgowers&#x2F;status&#x2F;1816509817382735986" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;wtgowers&#x2F;status&#x2F;1816509817382735986</a>)<p>&gt; However, LLMs are not able to autoformalize reliably, so they got them to autoformalize each problem many times. Some of the formalizations were correct, but even the incorrect ones were useful as training data, as often they were easier problems.<p>So didn&#x27;t actually solve autoformalization, which is why they still needed humans to translate the input IMO 2024 problems.<p>The reason why formalization is harder than you think is that there is no way to know if you got it right.
You can use Reinforcement Learning with proofs and have a clear signal from the proof checker.
We don&#x27;t have a way to verify formalizations the same way.</div><br/><div id="41071625" class="c"><input type="checkbox" id="c-41071625" checked=""/><div class="controls bullet"><span class="by">thrdbndndn</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071238">parent</a><span>|</span><a href="#41071494">next</a><span>|</span><label class="collapse" for="c-41071625">[-]</label><label class="expand" for="c-41071625">[7 more]</label></div><br/><div class="children"><div class="content">&gt; However, LLMs are not able to autoformalize reliably, so they got them to autoformalize each problem many times. Some of the formalizations were correct, but even the incorrect ones were useful as training data, as often they were easier problems.<p>A small detail wasn&#x27;t clear to me: for these incorrectly formalized problems, how do they get the correct <i>answer</i> as ground truth for training? Have a human to manually solve them?<p>(In contrast to problems actually from &quot;a huge database of IMO-type problems&quot;, they do have answers for these already).</div><br/><div id="41072713" class="c"><input type="checkbox" id="c-41072713" checked=""/><div class="controls bullet"><span class="by">summerlight</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071625">parent</a><span>|</span><a href="#41071717">next</a><span>|</span><label class="collapse" for="c-41072713">[-]</label><label class="expand" for="c-41072713">[3 more]</label></div><br/><div class="children"><div class="content">&gt; A small detail wasn&#x27;t clear to me: for these incorrectly formalized problems, how do they get the correct answer as ground truth for training? Have a human to manually solve them?<p>Formal proofs can be mechanically checked if it&#x27;s correct or not. We just don&#x27;t know what&#x27;s the answer. Think it as an extremely rigorous type system that typically requires really long type annotations, like annotation itself is a complex program. So if AlphaProof happens to generate a proof that passes this checker, we know that it&#x27;s correct.</div><br/><div id="41075465" class="c"><input type="checkbox" id="c-41075465" checked=""/><div class="controls bullet"><span class="by">thrdbndndn</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41072713">parent</a><span>|</span><a href="#41071717">next</a><span>|</span><label class="collapse" for="c-41075465">[-]</label><label class="expand" for="c-41075465">[2 more]</label></div><br/><div class="children"><div class="content">Ah, thanks. That makes a lot of sense now.</div><br/><div id="41076962" class="c"><input type="checkbox" id="c-41076962" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41075465">parent</a><span>|</span><a href="#41071717">next</a><span>|</span><label class="collapse" for="c-41076962">[-]</label><label class="expand" for="c-41076962">[1 more]</label></div><br/><div class="children"><div class="content">One more trick: They look for both proofs and disproofs. So even if they failed the formalization and created a &quot;wrong&quot; theorem, it&#x27;s just another task.</div><br/></div></div></div></div></div></div><div id="41071717" class="c"><input type="checkbox" id="c-41071717" checked=""/><div class="controls bullet"><span class="by">adrianN</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071625">parent</a><span>|</span><a href="#41072713">prev</a><span>|</span><a href="#41072456">next</a><span>|</span><label class="collapse" for="c-41071717">[-]</label><label class="expand" for="c-41071717">[1 more]</label></div><br/><div class="children"><div class="content">You write proofs in a formal language that can be machine checked. If the checker is happy, the proof is correct (unless there is a bug in the checker, but that is unlikely).</div><br/></div></div><div id="41072456" class="c"><input type="checkbox" id="c-41072456" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071625">parent</a><span>|</span><a href="#41071717">prev</a><span>|</span><a href="#41071494">next</a><span>|</span><label class="collapse" for="c-41072456">[-]</label><label class="expand" for="c-41072456">[2 more]</label></div><br/><div class="children"><div class="content">They said the incorrectly formalized ones are usually easier, so I assume they just hire humans to solve them in the old way until the AI is smart enough to solve these easier problems.</div><br/><div id="41076886" class="c"><input type="checkbox" id="c-41076886" checked=""/><div class="controls bullet"><span class="by">czl</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41072456">parent</a><span>|</span><a href="#41071494">next</a><span>|</span><label class="collapse" for="c-41076886">[-]</label><label class="expand" for="c-41076886">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I assume the just hire humans to solve…<p>An incorrectly formalized problem is a different problem and a solution to any formalized problem still useful for AI training because such solutions can be mechanically checked for correctness and this does not require the hire of humans. What requires humans is the initial formalization process since that is more a language translation task which requires nuance and judgment and is difficult to mechanically verify.</div><br/></div></div></div></div></div></div><div id="41071494" class="c"><input type="checkbox" id="c-41071494" checked=""/><div class="controls bullet"><span class="by">llwu</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071238">parent</a><span>|</span><a href="#41071625">prev</a><span>|</span><a href="#41071434">next</a><span>|</span><label class="collapse" for="c-41071494">[-]</label><label class="expand" for="c-41071494">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We don&#x27;t have a way to verify formalizations the same way.<p>While there is no perfect method, it is possible to use the agent to determine if the statement is false, has contradictory hypotheses, or a suspiciously short proof.</div><br/></div></div></div></div><div id="41071434" class="c"><input type="checkbox" id="c-41071434" checked=""/><div class="controls bullet"><span class="by">ajross</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070854">parent</a><span>|</span><a href="#41071238">prev</a><span>|</span><a href="#41070467">next</a><span>|</span><label class="collapse" for="c-41071434">[-]</label><label class="expand" for="c-41071434">[1 more]</label></div><br/><div class="children"><div class="content">&gt; To speak generally, that translation part is much easier than the proof part.<p>To you or me, sure.  But I think the proof that it isn&#x27;t for this AI system is that they didn&#x27;t do it.   Asking a modern LLM to &quot;translate&quot; something is a pretty solved problem, after all.  That argues strongly that what was happening here is not a &quot;translation&quot; but something else, like a semantic distillation.<p>If you ask a AI (or person) to prove the halting problem, they can&#x27;t.  If you &quot;translate&quot; the question into a specific example that does halt, they can run it and find out.<p>I&#x27;m suspicious, basically.</div><br/></div></div></div></div><div id="41070467" class="c"><input type="checkbox" id="c-41070467" checked=""/><div class="controls bullet"><span class="by">dooglius</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41070854">prev</a><span>|</span><a href="#41076565">next</a><span>|</span><label class="collapse" for="c-41070467">[-]</label><label class="expand" for="c-41070467">[11 more]</label></div><br/><div class="children"><div class="content">The linked page says<p>&gt; While the problem statements were formalized into Lean by hand, the answers within the problem statements were generated and formalized by the agent.<p>However, it&#x27;s unclear what initial format was given to the agents that allowed this step</div><br/><div id="41071005" class="c"><input type="checkbox" id="c-41071005" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070467">parent</a><span>|</span><a href="#41070681">next</a><span>|</span><label class="collapse" for="c-41071005">[-]</label><label class="expand" for="c-41071005">[5 more]</label></div><br/><div class="children"><div class="content">So if Lean was used to find the answers, where exactly is the AI?  A thin wrapper around Lean?</div><br/><div id="41071236" class="c"><input type="checkbox" id="c-41071236" checked=""/><div class="controls bullet"><span class="by">dooglius</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071005">parent</a><span>|</span><a href="#41073101">next</a><span>|</span><label class="collapse" for="c-41071236">[-]</label><label class="expand" for="c-41071236">[1 more]</label></div><br/><div class="children"><div class="content">Lean checks that the proof is valid, it didn&#x27;t find the proof.</div><br/></div></div><div id="41073101" class="c"><input type="checkbox" id="c-41073101" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071005">parent</a><span>|</span><a href="#41071236">prev</a><span>|</span><a href="#41071241">next</a><span>|</span><label class="collapse" for="c-41073101">[-]</label><label class="expand" for="c-41073101">[1 more]</label></div><br/><div class="children"><div class="content">Think of problems in NP - you can check the answer efficiently, but finding the answer to check is the hard part... This is basically what we&#x27;re looking at here: The proof checker can quickly evaluate correctness, but we need something to produce the proof, and that&#x27;s the hard part.</div><br/></div></div><div id="41071241" class="c"><input type="checkbox" id="c-41071241" checked=""/><div class="controls bullet"><span class="by">xrisk</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071005">parent</a><span>|</span><a href="#41073101">prev</a><span>|</span><a href="#41071272">next</a><span>|</span><label class="collapse" for="c-41071241">[-]</label><label class="expand" for="c-41071241">[1 more]</label></div><br/><div class="children"><div class="content">Lean is just the language, Presumably to drive the AI towards the program (“the proof”)</div><br/></div></div><div id="41071272" class="c"><input type="checkbox" id="c-41071272" checked=""/><div class="controls bullet"><span class="by">pishpash</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071005">parent</a><span>|</span><a href="#41071241">prev</a><span>|</span><a href="#41070681">next</a><span>|</span><label class="collapse" for="c-41071272">[-]</label><label class="expand" for="c-41071272">[1 more]</label></div><br/><div class="children"><div class="content">The AI is the &quot;solver network&quot;, which is the (directed) search over solutions generated by Lean. The AI is in doing an efficient search, I suppose.<p>I&#x27;m also waiting for my answer on the role of the Gemini formalizer, but reading between the lines, it looks like it was only used during training the &quot;solver network&quot;, but not used in solving the IMO problems. If so then the hyping is greatly premature, as the hybrid formalizer&#x2F;solver is the whole novelty of this, but it&#x27;s not good enough to use end-to-end?<p>You cannot say AlphaProof learned enough to solve problems if formalization made them easier to solve in the first place! You can say that the &quot;solver network&quot; part learned enough to solve formalized problems better than prior training methods.</div><br/></div></div></div></div><div id="41070681" class="c"><input type="checkbox" id="c-41070681" checked=""/><div class="controls bullet"><span class="by">Smaug123</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070467">parent</a><span>|</span><a href="#41071005">prev</a><span>|</span><a href="#41076565">next</a><span>|</span><label class="collapse" for="c-41070681">[-]</label><label class="expand" for="c-41070681">[5 more]</label></div><br/><div class="children"><div class="content">FWIW, GPT-4o transcribed a screenshot of problem 1 perfectly into LaTeX, so I don&#x27;t think &quot;munge the problem into machine-readable form&quot; is per se a difficult part of it these days even if they did somehow take shortcuts (which it sounds like they didn&#x27;t).</div><br/><div id="41071041" class="c"><input type="checkbox" id="c-41071041" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41070681">parent</a><span>|</span><a href="#41076565">next</a><span>|</span><label class="collapse" for="c-41071041">[-]</label><label class="expand" for="c-41071041">[4 more]</label></div><br/><div class="children"><div class="content">Comparing &quot;turn photo into LaTeX&quot; to &quot;translate theorems into Lean&quot; is like comparing a child&#x27;s watercolor drawing to the Mona Lisa.</div><br/><div id="41071228" class="c"><input type="checkbox" id="c-41071228" checked=""/><div class="controls bullet"><span class="by">Smaug123</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071041">parent</a><span>|</span><a href="#41072622">next</a><span>|</span><label class="collapse" for="c-41071228">[-]</label><label class="expand" for="c-41071228">[2 more]</label></div><br/><div class="children"><div class="content">… no? After the LaTeX output, I told stock GPT4o that the answer was &quot;all even integers&quot;, and asked for the statement in Lean. I had to make <i>two changes</i> to its output (both of which were compile-time errors, not misformalisations), and it gave me the formalisation of the difficult direction of the problem.<p>Both changes were trivial: it had one incorrect (but unnecessary) import, and it used the syntax from Lean 3 instead of Lean 4 in one lambda definition. A system that was trained harder on Lean would not make those mistakes.<p>The one <i>actual</i> error it made was in not proposing that the other direction of the &quot;if and only if&quot; is required. Again, I am quite confident that this formalisation failure mode is not hard to solve in a system that is, like, actually trained to do this.<p>Obviously formalising <i>problems that a working mathematicican solves</i> is dramatically harder than formalising IMO problems, and is presumably <i>way</i> ahead of the state of the art.</div><br/><div id="41074307" class="c"><input type="checkbox" id="c-41074307" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071228">parent</a><span>|</span><a href="#41072622">next</a><span>|</span><label class="collapse" for="c-41074307">[-]</label><label class="expand" for="c-41074307">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I am quite confident that this formalisation failure mode is not hard to solve in a system that is, like, actually trained to do this.<p>Why?</div><br/></div></div></div></div><div id="41072622" class="c"><input type="checkbox" id="c-41072622" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41070333">root</a><span>|</span><a href="#41071041">parent</a><span>|</span><a href="#41071228">prev</a><span>|</span><a href="#41076565">next</a><span>|</span><label class="collapse" for="c-41072622">[-]</label><label class="expand" for="c-41072622">[1 more]</label></div><br/><div class="children"><div class="content">I think that&#x27;s exagerating a bit. If you are familiar with both Lean and LaTeX then I think transcribing these problems to Lean only takes about twice as long as transcribing them to LaTeX.</div><br/></div></div></div></div></div></div></div></div><div id="41076565" class="c"><input type="checkbox" id="c-41076565" checked=""/><div class="controls bullet"><span class="by">rldjbpin</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41070467">prev</a><span>|</span><a href="#41070696">next</a><span>|</span><label class="collapse" for="c-41076565">[-]</label><label class="expand" for="c-41076565">[1 more]</label></div><br/><div class="children"><div class="content">as a noob, i feel that formalizing is a major part of solving the problem by yourserlf. my assessment is that once you identify certain patterns, you can solve problems by memorizing some patterns. but people might me can struggle with the first stage and solve the wrong problem.<p>still good progress nonetheless. won&#x27;t call the system sufficient by itself tho.</div><br/></div></div><div id="41070696" class="c"><input type="checkbox" id="c-41070696" checked=""/><div class="controls bullet"><span class="by">zerocrates</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41076565">prev</a><span>|</span><a href="#41072417">next</a><span>|</span><label class="collapse" for="c-41070696">[-]</label><label class="expand" for="c-41070696">[1 more]</label></div><br/><div class="children"><div class="content">Interesting that they have a formalizer (used to create the training data) but didn&#x27;t use it here. Not reliable enough?</div><br/></div></div><div id="41072417" class="c"><input type="checkbox" id="c-41072417" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41070696">prev</a><span>|</span><a href="#41070500">next</a><span>|</span><label class="collapse" for="c-41072417">[-]</label><label class="expand" for="c-41072417">[1 more]</label></div><br/><div class="children"><div class="content">I as someone with a maths degree but who hasn&#x27;t done this kind of thing for half a decade, was able to immediately guess the solution to (1) but actually proving it is much harder.</div><br/></div></div><div id="41070500" class="c"><input type="checkbox" id="c-41070500" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41072417">prev</a><span>|</span><a href="#41070491">next</a><span>|</span><label class="collapse" for="c-41070500">[-]</label><label class="expand" for="c-41070500">[1 more]</label></div><br/><div class="children"><div class="content">&gt; When presented with a problem, AlphaProof generates solution candidates and then proves or disproves them by searching over possible proof steps in Lean.<p>To me, this sounds like Alphaproof receives a &quot;problem&quot;, whatever that is (how do you formalize &quot;determine all X such that...&quot;? One is asked to show that an abstract set is actually some easily understandable set...). Then it generates candidate Theorems, persumably in Lean. I.e. the set is {n: P(n)} for some formula or something. Then it searches for proofs.<p>I think if Alphaproof did not find {foo} but it was given then it would be very outrageous to claim that it solved the problem.<p>I am also very hyped.</div><br/></div></div><div id="41071161" class="c"><input type="checkbox" id="c-41071161" checked=""/><div class="controls bullet"><span class="by">kurthr</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41070491">prev</a><span>|</span><a href="#41072180">next</a><span>|</span><label class="collapse" for="c-41071161">[-]</label><label class="expand" for="c-41071161">[1 more]</label></div><br/><div class="children"><div class="content">As is often the case, creating a well formed problem statement often takes as much knowledge (if not work) as finding the solution.<p>But seriously, if you can&#x27;t ask the LLM to solve the right question, you can&#x27;t really expect it to give you the right answer unless you&#x27;re really lucky. &quot;I&#x27;m sorry, but I think you meant to ask a different question. You might want to check the homework set again to be sure, but here&#x27;s what I think you really want.&quot;</div><br/></div></div><div id="41072180" class="c"><input type="checkbox" id="c-41072180" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41071161">prev</a><span>|</span><a href="#41075374">next</a><span>|</span><label class="collapse" for="c-41072180">[-]</label><label class="expand" for="c-41072180">[1 more]</label></div><br/><div class="children"><div class="content">The article says<p>&gt; AlphaProof solved two algebra problems and one number theory problem by <i>determining the answer</i> and proving it was correct.</div><br/></div></div><div id="41075374" class="c"><input type="checkbox" id="c-41075374" checked=""/><div class="controls bullet"><span class="by">hyfgfh</span><span>|</span><a href="#41070333">parent</a><span>|</span><a href="#41072180">prev</a><span>|</span><a href="#41073850">next</a><span>|</span><label class="collapse" for="c-41075374">[-]</label><label class="expand" for="c-41075374">[1 more]</label></div><br/><div class="children"><div class="content">&gt; First, the problems were manually translated into formal mathematical language for our systems to understand.<p>Some people call this programming</div><br/></div></div></div></div><div id="41073850" class="c"><input type="checkbox" id="c-41073850" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41070333">prev</a><span>|</span><a href="#41070315">next</a><span>|</span><label class="collapse" for="c-41073850">[-]</label><label class="expand" for="c-41073850">[20 more]</label></div><br/><div class="children"><div class="content">This is certainly impressive, but whenever IMO is brought up, a caveat should be put out: medals are awarded to 50% of the participants (high school students), with 1:2:3 ratio between gold, silver and bronze.  That puts all gold and silver medalists among the top 25% of the participants.<p>That means that &quot;AI solves IMO problems better than 75% of the students&quot;, which is probably even more impressive.<p>But, &quot;minutes for one problem and up to 3 days for each remaining problem&quot; means that this is unfortunately not a true representation either.  If these students were given up to 15 days (5 problems at &quot;up to 3 days each&quot;) instead of 9h, there would probably be more of them that match or beat this score too.<p>It really sounds like AI solved only a single problem in the 9h students get, so it certainly would not be even close to the medals.  What&#x27;s the need to taint the impressive result with apples-to-oranges comparison?<p>Why not be more objective and report that it took longer but was able to solve X% of problems (or scored X out of N points)?</div><br/><div id="41075274" class="c"><input type="checkbox" id="c-41075274" checked=""/><div class="controls bullet"><span class="by">NiloCK</span><span>|</span><a href="#41073850">parent</a><span>|</span><a href="#41073929">next</a><span>|</span><label class="collapse" for="c-41075274">[-]</label><label class="expand" for="c-41075274">[1 more]</label></div><br/><div class="children"><div class="content">&gt; medals are awarded to 50% of the participants (high school students)<p>In case this confuses anyone: the high school students in question are not a standard sample of high school students. AFAIK, they are teams of the ~6 strongest competitive problem solving high school students from each country.</div><br/></div></div><div id="41073929" class="c"><input type="checkbox" id="c-41073929" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41073850">parent</a><span>|</span><a href="#41075274">prev</a><span>|</span><a href="#41073903">next</a><span>|</span><label class="collapse" for="c-41073929">[-]</label><label class="expand" for="c-41073929">[12 more]</label></div><br/><div class="children"><div class="content">In my opinion (not Google s) the only reason they didn&#x27;t get gold this year (apart from being unlucky on problem selection) is that they didn&#x27;t want to try for any partial credit in P3 and P5. They are so close to the cut off and usually contestants with a little bit of progress can get 1 point. But i guess they didn&#x27;t want to get a gold on a technicality--it would be bad press. So they settled in a indisputable silver</div><br/><div id="41074579" class="c"><input type="checkbox" id="c-41074579" checked=""/><div class="controls bullet"><span class="by">lozenge</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41073929">parent</a><span>|</span><a href="#41074430">next</a><span>|</span><label class="collapse" for="c-41074579">[-]</label><label class="expand" for="c-41074579">[5 more]</label></div><br/><div class="children"><div class="content">The AI took a day on one of the problems so it must have generated and discarded a lot of proofs that didn&#x27;t work. How could it choose which one to submit as the answer, except the objective fact of the proof passing in Lean.</div><br/><div id="41074912" class="c"><input type="checkbox" id="c-41074912" checked=""/><div class="controls bullet"><span class="by">snewman</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074579">parent</a><span>|</span><a href="#41076313">next</a><span>|</span><label class="collapse" for="c-41074912">[-]</label><label class="expand" for="c-41074912">[2 more]</label></div><br/><div class="children"><div class="content">When tackling IMO problems, the hard part is coming up with a good approach to the proof. Verifying your proof (and rejecting your false attempts) is much easier. You&#x27;ll know which one to submit.<p>(Source: I am a two-time IMO silver medalist.)</div><br/><div id="41076247" class="c"><input type="checkbox" id="c-41076247" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074912">parent</a><span>|</span><a href="#41076313">next</a><span>|</span><label class="collapse" for="c-41076247">[-]</label><label class="expand" for="c-41076247">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see why we should take your word for it, as opposed to just asking AlphaProof to comment instead.</div><br/></div></div></div></div><div id="41076313" class="c"><input type="checkbox" id="c-41076313" checked=""/><div class="controls bullet"><span class="by">Agingcoder</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074579">parent</a><span>|</span><a href="#41074912">prev</a><span>|</span><a href="#41074621">next</a><span>|</span><label class="collapse" for="c-41076313">[-]</label><label class="expand" for="c-41076313">[1 more]</label></div><br/><div class="children"><div class="content">To some extent, what they do is stronger that the other contestants, who I understand don’t formally prove their answers.</div><br/></div></div><div id="41074621" class="c"><input type="checkbox" id="c-41074621" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074579">parent</a><span>|</span><a href="#41076313">prev</a><span>|</span><a href="#41074430">next</a><span>|</span><label class="collapse" for="c-41074621">[-]</label><label class="expand" for="c-41074621">[1 more]</label></div><br/><div class="children"><div class="content">I think it proves lemmas it can submit all the lemmas it proved lol</div><br/></div></div></div></div><div id="41074430" class="c"><input type="checkbox" id="c-41074430" checked=""/><div class="controls bullet"><span class="by">llwu</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41073929">parent</a><span>|</span><a href="#41074579">prev</a><span>|</span><a href="#41074343">next</a><span>|</span><label class="collapse" for="c-41074430">[-]</label><label class="expand" for="c-41074430">[3 more]</label></div><br/><div class="children"><div class="content">Partial credit is quite challenging to earn, per: <a href="https:&#x2F;&#x2F;www.imo-official.org&#x2F;year_statistics.aspx?year=2024" rel="nofollow">https:&#x2F;&#x2F;www.imo-official.org&#x2F;year_statistics.aspx?year=2024</a></div><br/><div id="41074627" class="c"><input type="checkbox" id="c-41074627" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074430">parent</a><span>|</span><a href="#41074343">next</a><span>|</span><label class="collapse" for="c-41074627">[-]</label><label class="expand" for="c-41074627">[2 more]</label></div><br/><div class="children"><div class="content">Link isn&#x27;t working for me can you summarize. What i heard ten years ago was that 1pt is quite common for a significant progress</div><br/><div id="41074789" class="c"><input type="checkbox" id="c-41074789" checked=""/><div class="controls bullet"><span class="by">llwu</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074627">parent</a><span>|</span><a href="#41074343">next</a><span>|</span><label class="collapse" for="c-41074789">[-]</label><label class="expand" for="c-41074789">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the progress has to be quite significant, no points are awarded for trivial observations. Thus scores are usually bimodal around 0 and 7. In the linked stats you can see that 1 point for P3&#x2F;P5 was less common than full score on other problems.</div><br/></div></div></div></div></div></div><div id="41074343" class="c"><input type="checkbox" id="c-41074343" checked=""/><div class="controls bullet"><span class="by">dooglius</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41073929">parent</a><span>|</span><a href="#41074430">prev</a><span>|</span><a href="#41073903">next</a><span>|</span><label class="collapse" for="c-41074343">[-]</label><label class="expand" for="c-41074343">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t believe anything was graded by the IMO, Google is just giving itself 7 for anything proved in Lean (which is reasonable IMO), so they can&#x27;t really try for partial credit so much as choose not to report a higher self-graded number.</div><br/><div id="41074467" class="c"><input type="checkbox" id="c-41074467" checked=""/><div class="controls bullet"><span class="by">utopcell</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074343">parent</a><span>|</span><a href="#41073903">next</a><span>|</span><label class="collapse" for="c-41074467">[-]</label><label class="expand" for="c-41074467">[2 more]</label></div><br/><div class="children"><div class="content">From the article: &quot;Our solutions were scored according to the IMO’s point-awarding rules by prominent mathematicians Prof Sir Timothy Gowers, an IMO gold medalist and Fields Medal winner, and Dr Joseph Myers, a two-time IMO gold medalist and Chair of the IMO 2024 Problem Selection Committee.&quot;</div><br/><div id="41074710" class="c"><input type="checkbox" id="c-41074710" checked=""/><div class="controls bullet"><span class="by">dooglius</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074467">parent</a><span>|</span><a href="#41073903">next</a><span>|</span><label class="collapse" for="c-41074710">[-]</label><label class="expand" for="c-41074710">[1 more]</label></div><br/><div class="children"><div class="content">Fair enough. Although I think the question is whether P3&#x2F;P5 were given zero points vs not evaluated vs evaluated but not published. I don&#x27;t think it is surprising that Lean-verified proofs get a 7.</div><br/></div></div></div></div></div></div></div></div><div id="41073903" class="c"><input type="checkbox" id="c-41073903" checked=""/><div class="controls bullet"><span class="by">muglug</span><span>|</span><a href="#41073850">parent</a><span>|</span><a href="#41073929">prev</a><span>|</span><a href="#41074195">next</a><span>|</span><label class="collapse" for="c-41073903">[-]</label><label class="expand" for="c-41073903">[2 more]</label></div><br/><div class="children"><div class="content">&gt; What&#x27;s the need to taint the impressive result with apples-to-oranges comparison?<p>Most of DeepMind’s research is a cost-centre for the company. These press releases help justify the continued investment both to investors and to the wider public.</div><br/><div id="41074491" class="c"><input type="checkbox" id="c-41074491" checked=""/><div class="controls bullet"><span class="by">utopcell</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41073903">parent</a><span>|</span><a href="#41074195">next</a><span>|</span><label class="collapse" for="c-41074491">[-]</label><label class="expand" for="c-41074491">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Most of DeepMind’s research is a cost-centre for the company.<p>The effect of establishing oneself as the thought leader in a field is enormous.<p>For example, IBM&#x27;s stock went up 15% the month after they beat Kasparov.</div><br/></div></div></div></div><div id="41074195" class="c"><input type="checkbox" id="c-41074195" checked=""/><div class="controls bullet"><span class="by">tardygrade</span><span>|</span><a href="#41073850">parent</a><span>|</span><a href="#41073903">prev</a><span>|</span><a href="#41074275">next</a><span>|</span><label class="collapse" for="c-41074195">[-]</label><label class="expand" for="c-41074195">[1 more]</label></div><br/><div class="children"><div class="content">One key difference between giving humans more time and giving computer programs more time is that historically we have had more success making the latter run faster than the former.</div><br/></div></div><div id="41074275" class="c"><input type="checkbox" id="c-41074275" checked=""/><div class="controls bullet"><span class="by">acchow</span><span>|</span><a href="#41073850">parent</a><span>|</span><a href="#41074195">prev</a><span>|</span><a href="#41070315">next</a><span>|</span><label class="collapse" for="c-41074275">[-]</label><label class="expand" for="c-41074275">[3 more]</label></div><br/><div class="children"><div class="content">But computers get faster each year, so even with zero progress in actual AI, this will reach human-student speeds in a few years (need a 40x speed up)</div><br/><div id="41074477" class="c"><input type="checkbox" id="c-41074477" checked=""/><div class="controls bullet"><span class="by">jimkoen</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074275">parent</a><span>|</span><a href="#41070315">next</a><span>|</span><label class="collapse" for="c-41074477">[-]</label><label class="expand" for="c-41074477">[2 more]</label></div><br/><div class="children"><div class="content">Could you explain where the 40x speedup comes from, given that literally the biggest problem in semi conductors right now is smaller node size?</div><br/><div id="41074636" class="c"><input type="checkbox" id="c-41074636" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#41073850">root</a><span>|</span><a href="#41074477">parent</a><span>|</span><a href="#41070315">next</a><span>|</span><label class="collapse" for="c-41074636">[-]</label><label class="expand" for="c-41074636">[1 more]</label></div><br/><div class="children"><div class="content">Just bigger chip area at lower clock could do it too if there is no threshold on cost anyway and they were limited by power. Google would hit enough accumulated production of AI chip area and cluster build out even if Moore&#x27;s law stopped.  There will likely be big algorithmic improvments too.</div><br/></div></div></div></div></div></div></div></div><div id="41070315" class="c"><input type="checkbox" id="c-41070315" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41073850">prev</a><span>|</span><a href="#41070218">next</a><span>|</span><label class="collapse" for="c-41070315">[-]</label><label class="expand" for="c-41070315">[33 more]</label></div><br/><div class="children"><div class="content">This is the real deal. AlphaGeometry solved a very limited set of problems with a lot of brute force search. This is a much broader method that I believe will have a great impact on the way we do mathematics. They are really implementing a self-feeding pipeling from natural language mathematics to formalized mathematics where they can train both formalization and proving. In principle this pipeline can also learn basic theory building like creating auxilliary definitions and Lemmas. I really think this is the holy grail of proof-assistance and will allow us to formalize most mathematics that we create very naturally. Humans will work podt-rigorously and let the machine asisst with filling in the details.</div><br/><div id="41072771" class="c"><input type="checkbox" id="c-41072771" checked=""/><div class="controls bullet"><span class="by">fmap</span><span>|</span><a href="#41070315">parent</a><span>|</span><a href="#41070908">next</a><span>|</span><label class="collapse" for="c-41072771">[-]</label><label class="expand" for="c-41072771">[6 more]</label></div><br/><div class="children"><div class="content">Agreed, this is a big step forward. Geometry problems are in a different class, since you can translate them into systems of polynomial equations and use well known computer algebra algorithms to solve them.<p>By contrast, this kind of open ended formalization is something where progress used to be extremely slow and incremental. I worked in an adjacent field 5 years ago and I cannot stress enough that these results are simply out of reach for traditional automated reasoning techniques.<p>Real automatic theorem proving is also useful for a lot more than pure mathematics. For example, it&#x27;s simple to write out an axiomatic semantics for a small programming language in lean and pose a question of the form &quot;show that there exists a program which satisfies this specification&quot;.<p>If this approach scales it&#x27;ll be far more important than any other ML application that has come out in the last few years.</div><br/><div id="41073177" class="c"><input type="checkbox" id="c-41073177" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41072771">parent</a><span>|</span><a href="#41070908">next</a><span>|</span><label class="collapse" for="c-41073177">[-]</label><label class="expand" for="c-41073177">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Agreed, this is a big step forward. Geometry problems are in a different class, since you can translate them into systems of polynomial equations and use well known computer algebra algorithms to solve them.<p>The blog post indicates the opposite. The geometry problem in the IMO problem set was solved by AlphaGeometry 2, which is an LLM based on Google&#x27;s Gemini. LLMs are considered relatively general systems. But the other three solved problems were proved by AlphaProof, which is a narrow RL system that is literally based on AlphaZero, the Go and Chess AI. Only its initial (bootstrapping) human training data (proofs) were formalized and augmented by an LLM (Gemini).</div><br/><div id="41076596" class="c"><input type="checkbox" id="c-41076596" checked=""/><div class="controls bullet"><span class="by">dash2</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41073177">parent</a><span>|</span><a href="#41074730">next</a><span>|</span><label class="collapse" for="c-41076596">[-]</label><label class="expand" for="c-41076596">[3 more]</label></div><br/><div class="children"><div class="content">AlphaZero is more general than a Go and Chess AI, right? Isn&#x27;t it a general self-play algorithm?</div><br/><div id="41076947" class="c"><input type="checkbox" id="c-41076947" checked=""/><div class="controls bullet"><span class="by">sapiogram</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41076596">parent</a><span>|</span><a href="#41076726">next</a><span>|</span><label class="collapse" for="c-41076947">[-]</label><label class="expand" for="c-41076947">[1 more]</label></div><br/><div class="children"><div class="content">Only slightly more general. It only works for games that are zero-sum, deterministic, have no hidden information, and discrete game state and moves. Other examples include connect-4.</div><br/></div></div><div id="41076726" class="c"><input type="checkbox" id="c-41076726" checked=""/><div class="controls bullet"><span class="by">redman25</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41076596">parent</a><span>|</span><a href="#41076947">prev</a><span>|</span><a href="#41074730">next</a><span>|</span><label class="collapse" for="c-41076726">[-]</label><label class="expand" for="c-41076726">[1 more]</label></div><br/><div class="children"><div class="content">I think that it can only play “games” for which it has perfect information about the state of the “game”.</div><br/></div></div></div></div><div id="41074730" class="c"><input type="checkbox" id="c-41074730" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41073177">parent</a><span>|</span><a href="#41076596">prev</a><span>|</span><a href="#41070908">next</a><span>|</span><label class="collapse" for="c-41074730">[-]</label><label class="expand" for="c-41074730">[1 more]</label></div><br/><div class="children"><div class="content">AlphaGeometry is not an LLM</div><br/></div></div></div></div></div></div><div id="41070908" class="c"><input type="checkbox" id="c-41070908" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41070315">parent</a><span>|</span><a href="#41072771">prev</a><span>|</span><a href="#41075690">next</a><span>|</span><label class="collapse" for="c-41070908">[-]</label><label class="expand" for="c-41070908">[19 more]</label></div><br/><div class="children"><div class="content">&gt; a lot of brute force search<p>Don&#x27;t dismiss search, it might be brute force but it goes beyond human level in Go and silver at IMO. Search is also what powers evolution which created us, also by a lot of brute forcing, and is at the core of scientific method (re)search.</div><br/><div id="41071336" class="c"><input type="checkbox" id="c-41071336" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41070908">parent</a><span>|</span><a href="#41071025">next</a><span>|</span><label class="collapse" for="c-41071336">[-]</label><label class="expand" for="c-41071336">[5 more]</label></div><br/><div class="children"><div class="content">Also AlphaProof had to search for 60 hours for one of the IMO problems it solved.</div><br/><div id="41073702" class="c"><input type="checkbox" id="c-41073702" checked=""/><div class="controls bullet"><span class="by">randcraw</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41071336">parent</a><span>|</span><a href="#41072834">next</a><span>|</span><label class="collapse" for="c-41073702">[-]</label><label class="expand" for="c-41073702">[2 more]</label></div><br/><div class="children"><div class="content">And I understand the upper time limit for each question was 4.5 hours.  So it solved one question almost immediately, two well over the allotted time (60 hrs), and two not at all.  No medal for you, Grasshopper.</div><br/><div id="41074920" class="c"><input type="checkbox" id="c-41074920" checked=""/><div class="controls bullet"><span class="by">snewman</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41073702">parent</a><span>|</span><a href="#41072834">next</a><span>|</span><label class="collapse" for="c-41074920">[-]</label><label class="expand" for="c-41074920">[1 more]</label></div><br/><div class="children"><div class="content">Contestants get 4.5 hours for each of the two days of competition. They have to solve three problems in that time, so on average you can spend 1.5 hours per problem (if you&#x27;re aiming to finish all three).<p>That said, the gap from &quot;can&#x27;t do it at all&quot; to &quot;can do it in 60 hours&quot; is probably quite a bit larger than the gap from 60 hours to 1.5 hours.</div><br/></div></div></div></div><div id="41072834" class="c"><input type="checkbox" id="c-41072834" checked=""/><div class="controls bullet"><span class="by">renonce</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41071336">parent</a><span>|</span><a href="#41073702">prev</a><span>|</span><a href="#41071025">next</a><span>|</span><label class="collapse" for="c-41072834">[-]</label><label class="expand" for="c-41072834">[2 more]</label></div><br/><div class="children"><div class="content">It’s going to be significantly faster very soon, we have seen how AlphaGo evolved into KataGo which is many magnitudes more compute efficient</div><br/><div id="41076952" class="c"><input type="checkbox" id="c-41076952" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41072834">parent</a><span>|</span><a href="#41071025">next</a><span>|</span><label class="collapse" for="c-41076952">[-]</label><label class="expand" for="c-41076952">[1 more]</label></div><br/><div class="children"><div class="content">The main difficulty to scaling Alpha Proof is finding theorems to train it with. AlphaGo didn&#x27;t have that problem because it could generate it&#x27;s own data.</div><br/></div></div></div></div></div></div><div id="41071025" class="c"><input type="checkbox" id="c-41071025" checked=""/><div class="controls bullet"><span class="by">Eridrus</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41070908">parent</a><span>|</span><a href="#41071336">prev</a><span>|</span><a href="#41071254">next</a><span>|</span><label class="collapse" for="c-41071025">[-]</label><label class="expand" for="c-41071025">[1 more]</label></div><br/><div class="children"><div class="content">Search is great, search works, but there was not a tonne to learn from the AlphaGeometry paper unless you were specifically interested in solving geometry problems.</div><br/></div></div><div id="41071254" class="c"><input type="checkbox" id="c-41071254" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41070908">parent</a><span>|</span><a href="#41071025">prev</a><span>|</span><a href="#41071059">next</a><span>|</span><label class="collapse" for="c-41071254">[-]</label><label class="expand" for="c-41071254">[1 more]</label></div><br/><div class="children"><div class="content">Yes and there&#x27;s a lot of search here too. That&#x27;s a key to the approach</div><br/></div></div><div id="41071059" class="c"><input type="checkbox" id="c-41071059" checked=""/><div class="controls bullet"><span class="by">kypro</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41070908">parent</a><span>|</span><a href="#41071254">prev</a><span>|</span><a href="#41071909">next</a><span>|</span><label class="collapse" for="c-41071059">[-]</label><label class="expand" for="c-41071059">[7 more]</label></div><br/><div class="children"><div class="content">My old AI professor used to say that every problem is a search problem.<p>The issue is that to find solutions for useful problems you&#x27;re often searching through highly complex and often infinite solution spaces.</div><br/><div id="41071181" class="c"><input type="checkbox" id="c-41071181" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41071059">parent</a><span>|</span><a href="#41072695">next</a><span>|</span><label class="collapse" for="c-41071181">[-]</label><label class="expand" for="c-41071181">[1 more]</label></div><br/><div class="children"><div class="content">For some problems validation is expensive. Like the particle collider or space telescope, or testing the COVID vaccine. It&#x27;s actually validation that is the bottleneck in search not ideation.</div><br/></div></div><div id="41072695" class="c"><input type="checkbox" id="c-41072695" checked=""/><div class="controls bullet"><span class="by">shkkmo</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41071059">parent</a><span>|</span><a href="#41071181">prev</a><span>|</span><a href="#41071360">next</a><span>|</span><label class="collapse" for="c-41072695">[-]</label><label class="expand" for="c-41072695">[2 more]</label></div><br/><div class="children"><div class="content">I would argue that no actually searchable solution space is really infinite (if only because infinite turing machines can&#x27;t exist). Finite solution spaces can get more than large enough to be intractable.</div><br/><div id="41072734" class="c"><input type="checkbox" id="c-41072734" checked=""/><div class="controls bullet"><span class="by">smokel</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41072695">parent</a><span>|</span><a href="#41071360">next</a><span>|</span><label class="collapse" for="c-41072734">[-]</label><label class="expand" for="c-41072734">[1 more]</label></div><br/><div class="children"><div class="content">What about ℕ?  Seems pretty infinite to me, unless with &quot;actually&quot; you mean finite in time and space, which would make your argument a tautology.  Or am I missing something?</div><br/></div></div></div></div><div id="41071360" class="c"><input type="checkbox" id="c-41071360" checked=""/><div class="controls bullet"><span class="by">pishpash</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41071059">parent</a><span>|</span><a href="#41072695">prev</a><span>|</span><a href="#41071909">next</a><span>|</span><label class="collapse" for="c-41071360">[-]</label><label class="expand" for="c-41071360">[3 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no problem with search. The goal is to search most efficiently.</div><br/><div id="41071652" class="c"><input type="checkbox" id="c-41071652" checked=""/><div class="controls bullet"><span class="by">deely3</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41071360">parent</a><span>|</span><a href="#41071909">next</a><span>|</span><label class="collapse" for="c-41071652">[-]</label><label class="expand" for="c-41071652">[2 more]</label></div><br/><div class="children"><div class="content">You mean that by improving search we can solve any problem? What if solution field is infinite, even if we make search algo 10x100 more performant, solution field will still be infinite, no?</div><br/><div id="41071816" class="c"><input type="checkbox" id="c-41071816" checked=""/><div class="controls bullet"><span class="by">pishpash</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41071652">parent</a><span>|</span><a href="#41071909">next</a><span>|</span><label class="collapse" for="c-41071816">[-]</label><label class="expand" for="c-41071816">[1 more]</label></div><br/><div class="children"><div class="content">Gradient descent is a search. Where does it say the search space has to be small?</div><br/></div></div></div></div></div></div></div></div><div id="41071909" class="c"><input type="checkbox" id="c-41071909" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41070908">parent</a><span>|</span><a href="#41071059">prev</a><span>|</span><a href="#41075690">next</a><span>|</span><label class="collapse" for="c-41071909">[-]</label><label class="expand" for="c-41071909">[4 more]</label></div><br/><div class="children"><div class="content">What makes solving IMO problems hard is usually the limits of human memory, pattern-matching, and search, not creativity. After all, these are problems that are <i>already</i> solved, and it is expected that many people can solve the problems in about 1 hour&#x27;s time.<p>That makes it, in principle, similar or even easier than a champsionship-level chess move, which often take more than 1 hour for a professional human (with more training than an IMO high school student) to solve.<p>Another interesting concern is that when posing a problem to humans, it&#x27;s fine to pose an &quot;easy&quot; brute-forceable problem, but humans, being slow brute-searchers, need to find  more clever solutions. But if you give such a problem to a computer, it can trivialize it. So to test a computer, you need to pose non- easily-brute-forceable problems, which are harder for the computer than the others, but equally difficult for the humans as the other problems are.</div><br/><div id="41072442" class="c"><input type="checkbox" id="c-41072442" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41071909">parent</a><span>|</span><a href="#41074950">next</a><span>|</span><label class="collapse" for="c-41072442">[-]</label><label class="expand" for="c-41072442">[1 more]</label></div><br/><div class="children"><div class="content">Ok but if you read the actual solutions they aren&#x27;t a bizarre mess of brute force.<p>They look like what a human would write if they were trying to come up with a formal proof (albeit it does some steps in a weird order).</div><br/></div></div><div id="41074950" class="c"><input type="checkbox" id="c-41074950" checked=""/><div class="controls bullet"><span class="by">snewman</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41071909">parent</a><span>|</span><a href="#41072442">prev</a><span>|</span><a href="#41075690">next</a><span>|</span><label class="collapse" for="c-41074950">[-]</label><label class="expand" for="c-41074950">[2 more]</label></div><br/><div class="children"><div class="content">Why do you say these are problems that are already solved? Sure, they&#x27;re often variations on existing themes, but the same is true for chess positions and, honestly, almost everything else in any field of human endeavor.<p>Agreed that the absolute upper tier of chess players have trained longer and harder than most or all IMO contestants. Though I do wonder which (top-tier chess or the IMO) draws on a larger talent pool. To my understanding, a significant fraction of all high school students on Earth take some form of qualifying exam which can channel them into an IMO training program.<p>And as far as the being amenable to brute force (relative difficulty for humans vs. computers): it seems that chess was comparatively easier for computers, IMO problems are comparatively easier for humans, and the game of Go is somewhere in between.</div><br/><div id="41076835" class="c"><input type="checkbox" id="c-41076835" checked=""/><div class="controls bullet"><span class="by">okintheory</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41074950">parent</a><span>|</span><a href="#41075690">next</a><span>|</span><label class="collapse" for="c-41076835">[-]</label><label class="expand" for="c-41076835">[1 more]</label></div><br/><div class="children"><div class="content">These problems are literally already solved? Of course, the IMO problem designers make sure the problems have solutions before the use them. That&#x27;s very different than math research, where it&#x27;s not known in advance what the answer is, or even that there is good answer.</div><br/></div></div></div></div></div></div></div></div><div id="41075690" class="c"><input type="checkbox" id="c-41075690" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#41070315">parent</a><span>|</span><a href="#41070908">prev</a><span>|</span><a href="#41073721">next</a><span>|</span><label class="collapse" for="c-41075690">[-]</label><label class="expand" for="c-41075690">[1 more]</label></div><br/><div class="children"><div class="content">As resident strident AI skeptic, yeah, this is real.<p>But MCTS was <i>always</i> promising when married to large NNs and DeepMind&#x2F;Brain were <i>always</i> in front on it.<p>I don’t know who fucked up on Gemini and it’s concerning for Alphabet shareholders that no one’s head is on a spike. In this context “too big to fail” is probably Pichai.<p>But only very foolish people think that Google is lying down on this. It’s Dean and Hassabis. People should have some respect.</div><br/></div></div><div id="41073721" class="c"><input type="checkbox" id="c-41073721" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#41070315">parent</a><span>|</span><a href="#41075690">prev</a><span>|</span><a href="#41072864">next</a><span>|</span><label class="collapse" for="c-41073721">[-]</label><label class="expand" for="c-41073721">[5 more]</label></div><br/><div class="children"><div class="content">I imagine a system like this to be vastly more useful outside the realm of mathematics research.<p>You don&#x27;t need to be able to prove very hard problems to do useful work. Proving just simple things is often enough. If I ask a language model to complete a task, organize some entries in a certain way, or schedule this or that, write a code that accomplishes X, the result is  typically not trustworthy directly. But if the system is able to translate parts of the problem to logic and find a solution, that might make the system much more reliable.</div><br/><div id="41073798" class="c"><input type="checkbox" id="c-41073798" checked=""/><div class="controls bullet"><span class="by">creata</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41073721">parent</a><span>|</span><a href="#41072864">next</a><span>|</span><label class="collapse" for="c-41073798">[-]</label><label class="expand" for="c-41073798">[4 more]</label></div><br/><div class="children"><div class="content">But for it to be 100% trustworthy, <i>you&#x27;d</i> have to express correctness criteria for those simple tasks as formal statements.</div><br/><div id="41075979" class="c"><input type="checkbox" id="c-41075979" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41073798">parent</a><span>|</span><a href="#41074515">next</a><span>|</span><label class="collapse" for="c-41075979">[-]</label><label class="expand" for="c-41075979">[1 more]</label></div><br/><div class="children"><div class="content">My intuition is that a regular LLM is <i>better</i> att coming up with a correct task description from a fuzzy description than it is at actually solving tasks.</div><br/></div></div><div id="41074515" class="c"><input type="checkbox" id="c-41074515" checked=""/><div class="controls bullet"><span class="by">lanstin</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41073798">parent</a><span>|</span><a href="#41075979">prev</a><span>|</span><a href="#41072864">next</a><span>|</span><label class="collapse" for="c-41074515">[-]</label><label class="expand" for="c-41074515">[2 more]</label></div><br/><div class="children"><div class="content">And most applied maths doesn&#x27;t seem to worry about proofs much. They have techniques that either work pretty well or blow up.</div><br/><div id="41076841" class="c"><input type="checkbox" id="c-41076841" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#41070315">root</a><span>|</span><a href="#41074515">parent</a><span>|</span><a href="#41072864">next</a><span>|</span><label class="collapse" for="c-41076841">[-]</label><label class="expand" for="c-41076841">[1 more]</label></div><br/><div class="children"><div class="content">Bridge collapses are a form of proof validation.</div><br/></div></div></div></div></div></div></div></div><div id="41072864" class="c"><input type="checkbox" id="c-41072864" checked=""/><div class="controls bullet"><span class="by">EugeneOZ</span><span>|</span><a href="#41070315">parent</a><span>|</span><a href="#41073721">prev</a><span>|</span><a href="#41070218">next</a><span>|</span><label class="collapse" for="c-41072864">[-]</label><label class="expand" for="c-41072864">[1 more]</label></div><br/><div class="children"><div class="content">No. It&#x27;s like you are allowed to use search engines to find a solution, nothing more than that.</div><br/></div></div></div></div><div id="41070218" class="c"><input type="checkbox" id="c-41070218" checked=""/><div class="controls bullet"><span class="by">Ericson2314</span><span>|</span><a href="#41070315">prev</a><span>|</span><a href="#41076526">next</a><span>|</span><label class="collapse" for="c-41070218">[-]</label><label class="expand" for="c-41070218">[17 more]</label></div><br/><div class="children"><div class="content">The lede is a bit buried: they&#x27;re using Lean!<p>This is important for more than Math problems. Making ML models wrestle with proof systems is a good way to avoid bullshit in general.<p>Hopefully more humans write types in Lean and similar systems as a much way of writing prompts.</div><br/><div id="41070274" class="c"><input type="checkbox" id="c-41070274" checked=""/><div class="controls bullet"><span class="by">Smaug123</span><span>|</span><a href="#41070218">parent</a><span>|</span><a href="#41072191">next</a><span>|</span><label class="collapse" for="c-41070274">[-]</label><label class="expand" for="c-41070274">[10 more]</label></div><br/><div class="children"><div class="content">And while AlphaProof is clearly <i>extremely</i> impressive, it does give the computer an advantage that a human doesn&#x27;t have in the IMO: nobody&#x27;s going to be constructing Gröbner bases in their head, but `polyrith` is just eight characters away. I saw AlphaProof used `nlinarith`.</div><br/><div id="41071271" class="c"><input type="checkbox" id="c-41071271" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070274">parent</a><span>|</span><a href="#41070851">next</a><span>|</span><label class="collapse" for="c-41071271">[-]</label><label class="expand" for="c-41071271">[1 more]</label></div><br/><div class="children"><div class="content">Good. I want my AI to use all the advantages it has to reinvent the landscape of mathematics</div><br/></div></div><div id="41070851" class="c"><input type="checkbox" id="c-41070851" checked=""/><div class="controls bullet"><span class="by">Ericson2314</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070274">parent</a><span>|</span><a href="#41071271">prev</a><span>|</span><a href="#41071316">next</a><span>|</span><label class="collapse" for="c-41070851">[-]</label><label class="expand" for="c-41070851">[4 more]</label></div><br/><div class="children"><div class="content">Hehe, well, we&#x27;ll need to have a tool-assited international math Olympiad then.</div><br/><div id="41073668" class="c"><input type="checkbox" id="c-41073668" checked=""/><div class="controls bullet"><span class="by">ComplexSystems</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070851">parent</a><span>|</span><a href="#41074526">next</a><span>|</span><label class="collapse" for="c-41073668">[-]</label><label class="expand" for="c-41073668">[2 more]</label></div><br/><div class="children"><div class="content">This is the greatest idea ever. Why doesn&#x27;t this exist?</div><br/><div id="41073919" class="c"><input type="checkbox" id="c-41073919" checked=""/><div class="controls bullet"><span class="by">panagathon</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41073668">parent</a><span>|</span><a href="#41074526">next</a><span>|</span><label class="collapse" for="c-41073919">[-]</label><label class="expand" for="c-41073919">[1 more]</label></div><br/><div class="children"><div class="content">This does sound like a lot of fun. Since this AI only reaches silver level, presumably such a contest could be quite competitive, with it not yet being clear cut whether a human or a tool-assisted human would come out on top, for any particular problem.</div><br/></div></div></div></div><div id="41074526" class="c"><input type="checkbox" id="c-41074526" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070851">parent</a><span>|</span><a href="#41073668">prev</a><span>|</span><a href="#41071316">next</a><span>|</span><label class="collapse" for="c-41074526">[-]</label><label class="expand" for="c-41074526">[1 more]</label></div><br/><div class="children"><div class="content">If the tools are the same as the ones AlphaProof gets (i.e. a lean compiler) then no one would use them.</div><br/></div></div></div></div><div id="41071316" class="c"><input type="checkbox" id="c-41071316" checked=""/><div class="controls bullet"><span class="by">xrisk</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070274">parent</a><span>|</span><a href="#41070851">prev</a><span>|</span><a href="#41072472">next</a><span>|</span><label class="collapse" for="c-41071316">[-]</label><label class="expand" for="c-41071316">[2 more]</label></div><br/><div class="children"><div class="content">Can you give some context on how using Lean benefits?<p>In my understanding, proofs are usually harder to transcribe into Lean which is nobody _writes_ proofs using Lean.<p>What is a nlinarith?</div><br/><div id="41071540" class="c"><input type="checkbox" id="c-41071540" checked=""/><div class="controls bullet"><span class="by">llwu</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41071316">parent</a><span>|</span><a href="#41072472">next</a><span>|</span><label class="collapse" for="c-41071540">[-]</label><label class="expand" for="c-41071540">[1 more]</label></div><br/><div class="children"><div class="content">nlinarith is a proof automation that attempts to finish a proof using the simplex method to find a linear combination of hypotheses and things that have already been proven, as well as some quadratic terms of them.<p>Docs: <a href="https:&#x2F;&#x2F;leanprover-community.github.io&#x2F;mathlib4_docs&#x2F;Mathlib&#x2F;Tactic&#x2F;Linarith&#x2F;Frontend.html#tacticNlinarith!_" rel="nofollow">https:&#x2F;&#x2F;leanprover-community.github.io&#x2F;mathlib4_docs&#x2F;Mathlib...</a></div><br/></div></div></div></div><div id="41072472" class="c"><input type="checkbox" id="c-41072472" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070274">parent</a><span>|</span><a href="#41071316">prev</a><span>|</span><a href="#41071326">next</a><span>|</span><label class="collapse" for="c-41072472">[-]</label><label class="expand" for="c-41072472">[1 more]</label></div><br/><div class="children"><div class="content">The uses of `nlinarith` are very straight forward manipulations of inequalities, they would be one or two steps for a human too.</div><br/></div></div><div id="41071326" class="c"><input type="checkbox" id="c-41071326" checked=""/><div class="controls bullet"><span class="by">empath75</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070274">parent</a><span>|</span><a href="#41072472">prev</a><span>|</span><a href="#41072191">next</a><span>|</span><label class="collapse" for="c-41071326">[-]</label><label class="expand" for="c-41071326">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t think of lean as a tool that the ai is using (ie, cheating), think of lean plus AlphaProof as a single system.  There&#x27;s no reason to draw artificial boundaries around where the AI is and where the tools that the AI is using are.  Lean itself is a traditional symbolic artificial intelligence system.<p>People want always knock generative AIs for not being able to reason, and we&#x27;ve had automated systems that reason perfectly well for decades, but for some reason that doesn&#x27;t count as AI to people.</div><br/></div></div></div></div><div id="41072191" class="c"><input type="checkbox" id="c-41072191" checked=""/><div class="controls bullet"><span class="by">queuebert</span><span>|</span><a href="#41070218">parent</a><span>|</span><a href="#41070274">prev</a><span>|</span><a href="#41070255">next</a><span>|</span><label class="collapse" for="c-41072191">[-]</label><label class="expand" for="c-41072191">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s amazing. I was just about to comment that hooking this up to Lean [1] would be killer. This must be the way forward for higher math, as proofs are getting so complicated that almost no one understands all pieces of major proofs.<p>1. <a href="https:&#x2F;&#x2F;lean-lang.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lean-lang.org&#x2F;</a></div><br/></div></div><div id="41070255" class="c"><input type="checkbox" id="c-41070255" checked=""/><div class="controls bullet"><span class="by">Ericson2314</span><span>|</span><a href="#41070218">parent</a><span>|</span><a href="#41072191">prev</a><span>|</span><a href="#41076526">next</a><span>|</span><label class="collapse" for="c-41070255">[-]</label><label class="expand" for="c-41070255">[5 more]</label></div><br/><div class="children"><div class="content">They&#x27;re def gonna go after the Riemann hypothesis with this, hehe.</div><br/><div id="41070430" class="c"><input type="checkbox" id="c-41070430" checked=""/><div class="controls bullet"><span class="by">nwoli</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070255">parent</a><span>|</span><a href="#41076526">next</a><span>|</span><label class="collapse" for="c-41070430">[-]</label><label class="expand" for="c-41070430">[4 more]</label></div><br/><div class="children"><div class="content">Guessing the context here is that the RH was recently translated into Lean. Would be very cool if they threw their compute on that</div><br/><div id="41070461" class="c"><input type="checkbox" id="c-41070461" checked=""/><div class="controls bullet"><span class="by">Smaug123</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070430">parent</a><span>|</span><a href="#41076526">next</a><span>|</span><label class="collapse" for="c-41070461">[-]</label><label class="expand" for="c-41070461">[3 more]</label></div><br/><div class="children"><div class="content">I think you might be thinking of the recent project to start Fermat&#x27;s Last Theorem? The Riemann hypothesis has been easy to state (given what&#x27;s in Mathlib) for years.</div><br/><div id="41071276" class="c"><input type="checkbox" id="c-41071276" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41070461">parent</a><span>|</span><a href="#41076526">next</a><span>|</span><label class="collapse" for="c-41071276">[-]</label><label class="expand" for="c-41071276">[2 more]</label></div><br/><div class="children"><div class="content">Yeah lol i don&#x27;t think either is hard to formalize in lean</div><br/><div id="41072764" class="c"><input type="checkbox" id="c-41072764" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#41070218">root</a><span>|</span><a href="#41071276">parent</a><span>|</span><a href="#41076526">next</a><span>|</span><label class="collapse" for="c-41072764">[-]</label><label class="expand" for="c-41072764">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re not just formalizing Fermant&#x27;s Last Theorem&#x27;s statement itself. They&#x27;re formalizing the proof.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41076526" class="c"><input type="checkbox" id="c-41076526" checked=""/><div class="controls bullet"><span class="by">signa11</span><span>|</span><a href="#41070218">prev</a><span>|</span><a href="#41076926">next</a><span>|</span><label class="collapse" for="c-41076526">[-]</label><label class="expand" for="c-41076526">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ... but whenever IMO is brought up, a caveat should be put out: medals are awarded to 50% of the participants (high school students), with 1:2:3 ratio between gold, silver and bronze. That puts all gold and silver medalists among the top 25% of the participants.<p>yes, it is true, but getting to the country specific team is itself an arduous journey, and involves brutal winnowing every step of the way f.e. regional math-olympiad, and then national math-olympiad etc.<p>this is then followed by further trainings specifically meant for this elite bunch, and maybe further eliminations etc.<p>suffice it to say, that qualifying to be in a country specific team is imho a <i>big</i> deal. getting a gold&#x2F;silver from amongst them is just plain <i>awesome</i> !</div><br/></div></div><div id="41076926" class="c"><input type="checkbox" id="c-41076926" checked=""/><div class="controls bullet"><span class="by">myspeed</span><span>|</span><a href="#41076526">prev</a><span>|</span><a href="#41071448">next</a><span>|</span><label class="collapse" for="c-41076926">[-]</label><label class="expand" for="c-41076926">[1 more]</label></div><br/><div class="children"><div class="content">This means we may need to remove or replace the Olympiad..It has no practical significance..Winners never contributed to any major scientific breakthroughs.</div><br/></div></div><div id="41071448" class="c"><input type="checkbox" id="c-41071448" checked=""/><div class="controls bullet"><span class="by">michael_nielsen</span><span>|</span><a href="#41076926">prev</a><span>|</span><a href="#41070591">next</a><span>|</span><label class="collapse" for="c-41071448">[-]</label><label class="expand" for="c-41071448">[1 more]</label></div><br/><div class="children"><div class="content">A good brief overview here from Tim Gowers (a Fields Medallist, who participated in the effort), explaining and contextualizing some of the main caveats: <a href="https:&#x2F;&#x2F;x.com&#x2F;wtgowers&#x2F;status&#x2F;1816509803407040909" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;wtgowers&#x2F;status&#x2F;1816509803407040909</a></div><br/></div></div><div id="41070591" class="c"><input type="checkbox" id="c-41070591" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#41071448">prev</a><span>|</span><a href="#41072330">next</a><span>|</span><label class="collapse" for="c-41070591">[-]</label><label class="expand" for="c-41070591">[16 more]</label></div><br/><div class="children"><div class="content">I&#x27;m seriously jealous of the people getting paid to work on this. Sounds great fun and must be incredibly satisfying to move the state of the art forward like that.</div><br/><div id="41076954" class="c"><input type="checkbox" id="c-41076954" checked=""/><div class="controls bullet"><span class="by">lonesword</span><span>|</span><a href="#41070591">parent</a><span>|</span><a href="#41074110">next</a><span>|</span><label class="collapse" for="c-41076954">[-]</label><label class="expand" for="c-41076954">[1 more]</label></div><br/><div class="children"><div class="content">I work in this space (pretraining LLMs). It looks fancier than it really is. It does involve wrangling huge ymls and writing regular expressions at scale (ok I am oversimplifying a bit). I should be excited (and grateful) that I get to work on these things but shoddy tooling takes the joy out of work.</div><br/></div></div><div id="41074110" class="c"><input type="checkbox" id="c-41074110" checked=""/><div class="controls bullet"><span class="by">GuB-42</span><span>|</span><a href="#41070591">parent</a><span>|</span><a href="#41076954">prev</a><span>|</span><a href="#41072693">next</a><span>|</span><label class="collapse" for="c-41074110">[-]</label><label class="expand" for="c-41074110">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know about that. A lot of the work that should have been very satisfying turned out to be boring as hell, if not toxic, while at the same time, some apparently mundane stuff turned out to be really exciting.<p>I found the work environment to be more important than the subject when it comes to work satisfaction. If you are working on a world changing subject with a team of assholes, you are going to have a bad time, some people really have a skill for sucking the fun out of everything, and office politics are everywhere, especially on world changing subjects.<p>On the other hand, you can have a most boring subject, say pushing customer data to a database, and have the time of your life: friendly team, well designed architecture, time for experimentation and sharing of knowledge, etc... I have come to appreciate the beauty of a simple thing that just works. It is so rare, maybe even more rare than scientific breakthroughs.<p>Now, you can also have an awesome work environment <i>and</i> an awesome subject, it is like hitting the jackpot... and a good reason to be envious.</div><br/><div id="41074738" class="c"><input type="checkbox" id="c-41074738" checked=""/><div class="controls bullet"><span class="by">phillypham</span><span>|</span><a href="#41070591">root</a><span>|</span><a href="#41074110">parent</a><span>|</span><a href="#41072693">next</a><span>|</span><label class="collapse" for="c-41074738">[-]</label><label class="expand" for="c-41074738">[2 more]</label></div><br/><div class="children"><div class="content">Awesome work environment for one person can be not ideal for another.<p>Pretty much all the top AI labs are both intensely competitive and collaborative. They consist of many former IMO and IOI medalists. They don&#x27;t believe in remote work, either. Even if you work at Google DeepMind, you really need to be in London for this project.</div><br/><div id="41076885" class="c"><input type="checkbox" id="c-41076885" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#41070591">root</a><span>|</span><a href="#41074738">parent</a><span>|</span><a href="#41072693">next</a><span>|</span><label class="collapse" for="c-41076885">[-]</label><label class="expand" for="c-41076885">[1 more]</label></div><br/><div class="children"><div class="content">The open-source software projects these companies critically depend on are developed by collaborators who have never met in person, and yet these companies still believe you can only do great work in the office.</div><br/></div></div></div></div></div></div><div id="41072693" class="c"><input type="checkbox" id="c-41072693" checked=""/><div class="controls bullet"><span class="by">Mithriil</span><span>|</span><a href="#41070591">parent</a><span>|</span><a href="#41074110">prev</a><span>|</span><a href="#41073337">next</a><span>|</span><label class="collapse" for="c-41072693">[-]</label><label class="expand" for="c-41072693">[1 more]</label></div><br/><div class="children"><div class="content">Best we can do then is keep ourselves up to date and give our support!</div><br/></div></div><div id="41073337" class="c"><input type="checkbox" id="c-41073337" checked=""/><div class="controls bullet"><span class="by">onemoresoop</span><span>|</span><a href="#41070591">parent</a><span>|</span><a href="#41072693">prev</a><span>|</span><a href="#41072928">next</a><span>|</span><label class="collapse" for="c-41073337">[-]</label><label class="expand" for="c-41073337">[7 more]</label></div><br/><div class="children"><div class="content">You probably mean envious not jealous.</div><br/><div id="41073519" class="c"><input type="checkbox" id="c-41073519" checked=""/><div class="controls bullet"><span class="by">yalok</span><span>|</span><a href="#41070591">root</a><span>|</span><a href="#41073337">parent</a><span>|</span><a href="#41072928">next</a><span>|</span><label class="collapse" for="c-41073519">[-]</label><label class="expand" for="c-41073519">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m learning something new today. In some other languages these 2 are usually the same 1 word.</div><br/><div id="41073712" class="c"><input type="checkbox" id="c-41073712" checked=""/><div class="controls bullet"><span class="by">Vinnl</span><span>|</span><a href="#41070591">root</a><span>|</span><a href="#41073519">parent</a><span>|</span><a href="#41075375">next</a><span>|</span><label class="collapse" for="c-41073712">[-]</label><label class="expand" for="c-41073712">[2 more]</label></div><br/><div class="children"><div class="content">Huh. So I tried to look it up just now and I&#x27;m not sure if I understand the difference. (To the extent that there is one - apparently one <i>can</i> mean the other, but I imagine they&#x27;re usually used as follows.)<p>It looks like &quot;jealous&quot; is more being afraid of losing something you have (most commonly e.g. a spouse&#x27;s affection) to someone else, whereas &quot;envious&quot; is wanting what someone else has?</div><br/><div id="41073754" class="c"><input type="checkbox" id="c-41073754" checked=""/><div class="controls bullet"><span class="by">onemoresoop</span><span>|</span><a href="#41070591">root</a><span>|</span><a href="#41073712">parent</a><span>|</span><a href="#41075375">next</a><span>|</span><label class="collapse" for="c-41073754">[-]</label><label class="expand" for="c-41073754">[1 more]</label></div><br/><div class="children"><div class="content">Correct.</div><br/></div></div></div></div><div id="41075375" class="c"><input type="checkbox" id="c-41075375" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#41070591">root</a><span>|</span><a href="#41073519">parent</a><span>|</span><a href="#41073712">prev</a><span>|</span><a href="#41073749">next</a><span>|</span><label class="collapse" for="c-41075375">[-]</label><label class="expand" for="c-41075375">[1 more]</label></div><br/><div class="children"><div class="content">Most English speakers use them interchangeably.  It’s usually only Simpsons fans who know the difference.<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HG8Yn9FX40c" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HG8Yn9FX40c</a></div><br/></div></div><div id="41073749" class="c"><input type="checkbox" id="c-41073749" checked=""/><div class="controls bullet"><span class="by">onemoresoop</span><span>|</span><a href="#41070591">root</a><span>|</span><a href="#41073519">parent</a><span>|</span><a href="#41075375">prev</a><span>|</span><a href="#41076072">next</a><span>|</span><label class="collapse" for="c-41073749">[-]</label><label class="expand" for="c-41073749">[1 more]</label></div><br/><div class="children"><div class="content">No worries. I learned this too a while ago (was also using jealous instead of envious and vice versa myself). From my understanding the use of jealous is when you have something but that is threatened by some external factor, eg a partner, a friend having more fun with somebody else. Envious is when you covet something that you do not have currently but wish to, which is in this case playing with exciting tech.</div><br/></div></div></div></div></div></div><div id="41072928" class="c"><input type="checkbox" id="c-41072928" checked=""/><div class="controls bullet"><span class="by">bearjaws</span><span>|</span><a href="#41070591">parent</a><span>|</span><a href="#41073337">prev</a><span>|</span><a href="#41072330">next</a><span>|</span><label class="collapse" for="c-41072928">[-]</label><label class="expand" for="c-41072928">[3 more]</label></div><br/><div class="children"><div class="content">C&#x27;mon you&#x27;re meant to be re-configuring 3,292,329 line of YML for K8s.<p>(&#x2F;s)</div><br/><div id="41072981" class="c"><input type="checkbox" id="c-41072981" checked=""/><div class="controls bullet"><span class="by">psbp</span><span>|</span><a href="#41070591">root</a><span>|</span><a href="#41072928">parent</a><span>|</span><a href="#41072330">next</a><span>|</span><label class="collapse" for="c-41072981">[-]</label><label class="expand" for="c-41072981">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s funny that if I could describe my entire career, it would probably be something similar to software janitor&#x2F;maintenance worker.<p>I guess I should have pursued a PhD when I was younger.</div><br/><div id="41075561" class="c"><input type="checkbox" id="c-41075561" checked=""/><div class="controls bullet"><span class="by">geodel</span><span>|</span><a href="#41070591">root</a><span>|</span><a href="#41072981">parent</a><span>|</span><a href="#41072330">next</a><span>|</span><label class="collapse" for="c-41075561">[-]</label><label class="expand" for="c-41075561">[1 more]</label></div><br/><div class="children"><div class="content">In another universe, this comment would be &quot;With low pay and few academic jobs going for PhD was the worst decision of my life&quot;</div><br/></div></div></div></div></div></div></div></div><div id="41072330" class="c"><input type="checkbox" id="c-41072330" checked=""/><div class="controls bullet"><span class="by">thrance</span><span>|</span><a href="#41070591">prev</a><span>|</span><a href="#41072338">next</a><span>|</span><label class="collapse" for="c-41072330">[-]</label><label class="expand" for="c-41072330">[12 more]</label></div><br/><div class="children"><div class="content">Theorem proving is a single-player game with an insanely big search space, I always thouht it would be solved long before AGI.<p>IMHO, the largest contributors to AlphaProof were the people behind Lean and Mathlib, who took the daunting task of formalizing the <i>entirety</i> of mathematics to themselves.<p>This lack of formalizing in math papers was what killed any attempt at automation, because AI researcher had to wrestle with the human element of figuring out the author&#x27;s own notations, implicit knowledge, skipped proof steps...</div><br/><div id="41072381" class="c"><input type="checkbox" id="c-41072381" checked=""/><div class="controls bullet"><span class="by">camjw</span><span>|</span><a href="#41072330">parent</a><span>|</span><a href="#41076848">prev</a><span>|</span><a href="#41072696">next</a><span>|</span><label class="collapse" for="c-41072381">[-]</label><label class="expand" for="c-41072381">[9 more]</label></div><br/><div class="children"><div class="content">&gt; Theorem proving is a single-player game with an insanely big search space, I always thouht it would be solved long before AGI.<p>This seems so weird to me - AGI is undefined as a term imo but why would you expect &quot;producing something generally intelligent&quot; (i.e. median human level intelligence) to be significantly harder than &quot;this thing is better than Terrence Tao at maths&quot;?</div><br/><div id="41072454" class="c"><input type="checkbox" id="c-41072454" checked=""/><div class="controls bullet"><span class="by">thrance</span><span>|</span><a href="#41072330">root</a><span>|</span><a href="#41072381">parent</a><span>|</span><a href="#41076324">next</a><span>|</span><label class="collapse" for="c-41072454">[-]</label><label class="expand" for="c-41072454">[4 more]</label></div><br/><div class="children"><div class="content">My intuition tells me we humans are generally very bad at math. Proving a theorem, in an ideal way, mostly involves going from point A to point B in the space of all proofs, using previous results as stepping stones. This isn&#x27;t particularly a &quot;hard&quot; problem for computers which are able to navigate search spaces for various games much more efficiently than us (chess, go...).<p>On the other hand, navigating the real world mostly consists in employing a ton of heuristics we are still kind of clueless about.<p>At the end of the day, we won&#x27;t know before we get there, but I think my reasons are compelling enough to think what I think.</div><br/><div id="41072619" class="c"><input type="checkbox" id="c-41072619" checked=""/><div class="controls bullet"><span class="by">tim-kt</span><span>|</span><a href="#41072330">root</a><span>|</span><a href="#41072454">parent</a><span>|</span><a href="#41072700">next</a><span>|</span><label class="collapse" for="c-41072619">[-]</label><label class="expand" for="c-41072619">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that computers have an advantage because they can navigate search spaces efficiently. The search space for difficult theorems is gigantic. Proving them often relies on a combination of experience with rigorous mathematics and very good intuition [1] as well as many, many steps. One example is the classification of all finite simple groups [2], which took about 200 years and a lot of small steps. I guess maybe brute forcing for 200 years with the technology available today might work. But I&#x27;m sceptical and sort of hope that I won&#x27;t be out of a job in 10 years. I&#x27;m certainly curious about the current development.<p>[1] <a href="https:&#x2F;&#x2F;terrytao.wordpress.com&#x2F;career-advice&#x2F;theres-more-to-mathematics-than-rigour-and-proofs&#x2F;" rel="nofollow">https:&#x2F;&#x2F;terrytao.wordpress.com&#x2F;career-advice&#x2F;theres-more-to-...</a><p>[2] <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Classification_of_finite_simple_groups" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Classification_of_finite_sim...</a></div><br/><div id="41072730" class="c"><input type="checkbox" id="c-41072730" checked=""/><div class="controls bullet"><span class="by">thrance</span><span>|</span><a href="#41072330">root</a><span>|</span><a href="#41072619">parent</a><span>|</span><a href="#41072700">next</a><span>|</span><label class="collapse" for="c-41072730">[-]</label><label class="expand" for="c-41072730">[1 more]</label></div><br/><div class="children"><div class="content">Oh for sure, when I say &quot;soon&quot; it&#x27;s only relative to AGI.<p>What I meant to convey, is that theorem proving at least is a well-defined problem, and computers have had some successes in similar-ish search problems before.<p>Also I don&#x27;t think pure brute-force was ever used to solve any kind of interesting problem.<p>Chess engines make use of alpha-beta pruning plus some empirical heuristics people came up with over the years. Go engines use Monte-Carlo Tree Search with straight deep learning models node evaluation. Theorem proving, when it is solved, will certainly use some kind of neural network.</div><br/></div></div></div></div><div id="41072700" class="c"><input type="checkbox" id="c-41072700" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41072330">root</a><span>|</span><a href="#41072454">parent</a><span>|</span><a href="#41072619">prev</a><span>|</span><a href="#41076324">next</a><span>|</span><label class="collapse" for="c-41072700">[-]</label><label class="expand" for="c-41072700">[1 more]</label></div><br/><div class="children"><div class="content">I also think humans are bad at math. And that we are probably better at IRL but maybe IRL has more data anyway</div><br/></div></div></div></div><div id="41076324" class="c"><input type="checkbox" id="c-41076324" checked=""/><div class="controls bullet"><span class="by">pedrosorio</span><span>|</span><a href="#41072330">root</a><span>|</span><a href="#41072381">parent</a><span>|</span><a href="#41072454">prev</a><span>|</span><a href="#41073752">next</a><span>|</span><label class="collapse" for="c-41076324">[-]</label><label class="expand" for="c-41076324">[1 more]</label></div><br/><div class="children"><div class="content">Replace &quot;this thing is better than Terrence Tao at maths&quot; with &quot;this thing is better than Garry Kasparov at chess&quot; and your statement would sound equally reasonable in the early 90s.</div><br/></div></div><div id="41072565" class="c"><input type="checkbox" id="c-41072565" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#41072330">root</a><span>|</span><a href="#41072381">parent</a><span>|</span><a href="#41073752">prev</a><span>|</span><a href="#41072696">next</a><span>|</span><label class="collapse" for="c-41072565">[-]</label><label class="expand" for="c-41072565">[2 more]</label></div><br/><div class="children"><div class="content">Because &quot;Generally Intelligent&quot; is a very broad and vague term.<p>&quot;Better than Terrence Tao at solving certain formalized problems&quot; (not necessarily equal to &quot;Better that Terrence Tao at maths) isn&#x27;t.</div><br/><div id="41073304" class="c"><input type="checkbox" id="c-41073304" checked=""/><div class="controls bullet"><span class="by">camjw</span><span>|</span><a href="#41072330">root</a><span>|</span><a href="#41072565">parent</a><span>|</span><a href="#41072696">next</a><span>|</span><label class="collapse" for="c-41073304">[-]</label><label class="expand" for="c-41073304">[1 more]</label></div><br/><div class="children"><div class="content">Seems fair - I strongly think that &quot;certain formalized problems&quot; is very very far away from doing actual maths! And that actual maths is sometimes much less about solving known conjectures and much more about developing new theories.</div><br/></div></div></div></div></div></div><div id="41072696" class="c"><input type="checkbox" id="c-41072696" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41072330">parent</a><span>|</span><a href="#41072381">prev</a><span>|</span><a href="#41072338">next</a><span>|</span><label class="collapse" for="c-41072696">[-]</label><label class="expand" for="c-41072696">[1 more]</label></div><br/><div class="children"><div class="content">They didn&#x27;t formalize the entirety of math. Good thing imo doesn&#x27;t need the entirety. But they didn&#x27;t even formalize enough for imo--this is probably why combo wasn&#x27;t solved</div><br/></div></div></div></div><div id="41072338" class="c"><input type="checkbox" id="c-41072338" checked=""/><div class="controls bullet"><span class="by">cynicalpeace</span><span>|</span><a href="#41072330">prev</a><span>|</span><a href="#41073509">next</a><span>|</span><label class="collapse" for="c-41072338">[-]</label><label class="expand" for="c-41072338">[24 more]</label></div><br/><div class="children"><div class="content">Machines have been better than humans at chess for decades.<p>Yet no one cares. Everyone&#x27;s busy watching Magnus Carlsen.<p>We are human. This means we care about what other humans do. We only care about machines insofar as it serves us.<p>This principle is broadly extensible to work and art. Humans will always have a place in these realms as long as humans are around.</div><br/><div id="41073492" class="c"><input type="checkbox" id="c-41073492" checked=""/><div class="controls bullet"><span class="by">ertgbnm</span><span>|</span><a href="#41072338">parent</a><span>|</span><a href="#41072359">next</a><span>|</span><label class="collapse" for="c-41073492">[-]</label><label class="expand" for="c-41073492">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure humans will always enjoy chess and art regardless of how much better AI is at it. In the same way, there will probably always be mathematic hobbyist who study math for fun. But I seriously doubt that in the near future there will be mathematicians who will be publishing new advancements that aren&#x27;t mostly or entirely discovered by AI. A human might get credit for a proof for asking the initial question, but there is pretty much no world where a computer can easily solve a meaningful mathematical problem but we insist on a human solve it more slowly and expensively instead.</div><br/><div id="41073659" class="c"><input type="checkbox" id="c-41073659" checked=""/><div class="controls bullet"><span class="by">cynicalpeace</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41073492">parent</a><span>|</span><a href="#41072359">next</a><span>|</span><label class="collapse" for="c-41073659">[-]</label><label class="expand" for="c-41073659">[1 more]</label></div><br/><div class="children"><div class="content">My point was where does the concept of &quot;meaningful&quot; come from?<p>The proof will only have value if it&#x27;s meaningful to us.</div><br/></div></div></div></div><div id="41072359" class="c"><input type="checkbox" id="c-41072359" checked=""/><div class="controls bullet"><span class="by">camjw</span><span>|</span><a href="#41072338">parent</a><span>|</span><a href="#41073492">prev</a><span>|</span><a href="#41072628">next</a><span>|</span><label class="collapse" for="c-41072359">[-]</label><label class="expand" for="c-41072359">[8 more]</label></div><br/><div class="children"><div class="content">Sure but if an AI can prove e.g the Goldbach conjecture then that is a bfd.</div><br/><div id="41072791" class="c"><input type="checkbox" id="c-41072791" checked=""/><div class="controls bullet"><span class="by">hyperbovine</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41072359">parent</a><span>|</span><a href="#41073436">next</a><span>|</span><label class="collapse" for="c-41072791">[-]</label><label class="expand" for="c-41072791">[6 more]</label></div><br/><div class="children"><div class="content">What if the proof were incomprehensible to humans?</div><br/><div id="41073563" class="c"><input type="checkbox" id="c-41073563" checked=""/><div class="controls bullet"><span class="by">fanatic2pope</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41072791">parent</a><span>|</span><a href="#41073387">next</a><span>|</span><label class="collapse" for="c-41073563">[-]</label><label class="expand" for="c-41073563">[3 more]</label></div><br/><div class="children"><div class="content">If it cannot explain how it was proven, was it actually proven?</div><br/><div id="41073681" class="c"><input type="checkbox" id="c-41073681" checked=""/><div class="controls bullet"><span class="by">cynicalpeace</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41073563">parent</a><span>|</span><a href="#41073387">next</a><span>|</span><label class="collapse" for="c-41073681">[-]</label><label class="expand" for="c-41073681">[2 more]</label></div><br/><div class="children"><div class="content">No. Funny how these discussions too often devolve into semantics lol.</div><br/><div id="41074854" class="c"><input type="checkbox" id="c-41074854" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41073681">parent</a><span>|</span><a href="#41073387">next</a><span>|</span><label class="collapse" for="c-41074854">[-]</label><label class="expand" for="c-41074854">[1 more]</label></div><br/><div class="children"><div class="content">Funny how people don&#x27;t understand basic logic. If it is a proof in a logic, and the machine checked that proof, it is a proof, no matter that no human actually understands it.<p>A human doesn&#x27;t need to understand the proof, they just have to understand why the proof is a proof.</div><br/></div></div></div></div></div></div><div id="41073387" class="c"><input type="checkbox" id="c-41073387" checked=""/><div class="controls bullet"><span class="by">steego</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41072791">parent</a><span>|</span><a href="#41073563">prev</a><span>|</span><a href="#41073288">next</a><span>|</span><label class="collapse" for="c-41073387">[-]</label><label class="expand" for="c-41073387">[1 more]</label></div><br/><div class="children"><div class="content">It shouldn’t count. We need to require it be able to ELI5 the proof to Goldbach’s conjecture to an actual class of <i>graduating</i> kindergartners.</div><br/></div></div><div id="41073288" class="c"><input type="checkbox" id="c-41073288" checked=""/><div class="controls bullet"><span class="by">camjw</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41072791">parent</a><span>|</span><a href="#41073387">prev</a><span>|</span><a href="#41073436">next</a><span>|</span><label class="collapse" for="c-41073288">[-]</label><label class="expand" for="c-41073288">[1 more]</label></div><br/><div class="children"><div class="content">I think that is unlikely to be the case - the classic example of a proof that human&#x27;s &quot;can&#x27;t understand&quot; is the Four Colour Theorem, but thats because the proof is a reduction to like 100000 special cases which are checked by computer.<p>To what extent is the proof of Fermat&#x27;s Last Theorem &quot;incomprehensible to humans&quot; because only like a dozen people on the planet could truly understand it - I don&#x27;t know.<p>The point of new proofs is really to learn new things about mathematics, and I&#x27;m sure we would learn something from a proof of Goldbach&#x27;s conjecture.<p>Finally if it&#x27;s not peer reviewed then its not a real proof eh.</div><br/></div></div></div></div><div id="41073436" class="c"><input type="checkbox" id="c-41073436" checked=""/><div class="controls bullet"><span class="by">cynicalpeace</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41072359">parent</a><span>|</span><a href="#41072791">prev</a><span>|</span><a href="#41072628">next</a><span>|</span><label class="collapse" for="c-41073436">[-]</label><label class="expand" for="c-41073436">[1 more]</label></div><br/><div class="children"><div class="content">How is that a counterpoint?</div><br/></div></div></div></div><div id="41072628" class="c"><input type="checkbox" id="c-41072628" checked=""/><div class="controls bullet"><span class="by">christianqchung</span><span>|</span><a href="#41072338">parent</a><span>|</span><a href="#41072359">prev</a><span>|</span><a href="#41074850">next</a><span>|</span><label class="collapse" for="c-41072628">[-]</label><label class="expand" for="c-41072628">[4 more]</label></div><br/><div class="children"><div class="content">&gt; This principle is broadly extensible to work and art<p>Nah, as a consumer it makes no difference to me if a meat packing factory or Amazon warehouse employs 5000 or 5 people. To art, this principle is totally real, but for work, it only applies to some&#x2F;most of it.</div><br/><div id="41073371" class="c"><input type="checkbox" id="c-41073371" checked=""/><div class="controls bullet"><span class="by">cynicalpeace</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41072628">parent</a><span>|</span><a href="#41074850">next</a><span>|</span><label class="collapse" for="c-41073371">[-]</label><label class="expand" for="c-41073371">[3 more]</label></div><br/><div class="children"><div class="content">Read the next sentence: &quot;We only care about machines insofar as it serves us.&quot;<p>Imagine a machine doing &quot;work&quot; that only serves itself and other machines that does no service to humanity. It would have no economic value. In fact the whole concept of &quot;work&quot; only makes sense if it is assigned economic value by humans.</div><br/><div id="41073667" class="c"><input type="checkbox" id="c-41073667" checked=""/><div class="controls bullet"><span class="by">christianqchung</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41073371">parent</a><span>|</span><a href="#41074850">next</a><span>|</span><label class="collapse" for="c-41073667">[-]</label><label class="expand" for="c-41073667">[2 more]</label></div><br/><div class="children"><div class="content">Then we agree, but your chess example made it sound like if a machine could automatically pack meat with little human intervention, people wouldn&#x27;t want it. That&#x27;s also not the next sentence. How is it broadly applicable to work?</div><br/></div></div></div></div></div></div><div id="41074850" class="c"><input type="checkbox" id="c-41074850" checked=""/><div class="controls bullet"><span class="by">auggierose</span><span>|</span><a href="#41072338">parent</a><span>|</span><a href="#41072628">prev</a><span>|</span><a href="#41072779">next</a><span>|</span><label class="collapse" for="c-41074850">[-]</label><label class="expand" for="c-41074850">[1 more]</label></div><br/><div class="children"><div class="content">There are people that believe that mathematics is actually useful, in ways that chess or art are not. I know, most mathematicians don&#x27;t think so. But let us just entertain this crazy thought for a moment. Then a proof is just a tool that tells us, oh, we have applied this piece of mathematics right. No understanding of the proof is actually required for that, and no one cares if some mathematician somewhere actually fully understands the proof. It will be OK, even expected, that the machine is better than us at finding and checking proofs.</div><br/></div></div><div id="41072779" class="c"><input type="checkbox" id="c-41072779" checked=""/><div class="controls bullet"><span class="by">smokel</span><span>|</span><a href="#41072338">parent</a><span>|</span><a href="#41074850">prev</a><span>|</span><a href="#41073452">next</a><span>|</span><label class="collapse" for="c-41072779">[-]</label><label class="expand" for="c-41072779">[2 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Everyone&#x27;s busy watching Magnus Carlsen.</i><p>Actually, I was looking up Elo ratings of the top <i>computer</i> chess players, and learned that it is not that trivial to compare these, due to differences in hardware requirements and whatnot.</div><br/><div id="41073488" class="c"><input type="checkbox" id="c-41073488" checked=""/><div class="controls bullet"><span class="by">cynicalpeace</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41072779">parent</a><span>|</span><a href="#41073452">next</a><span>|</span><label class="collapse" for="c-41073488">[-]</label><label class="expand" for="c-41073488">[1 more]</label></div><br/><div class="children"><div class="content">Are you arguing computer chess players are as popular as human chess players?</div><br/></div></div></div></div><div id="41073452" class="c"><input type="checkbox" id="c-41073452" checked=""/><div class="controls bullet"><span class="by">zone411</span><span>|</span><a href="#41072338">parent</a><span>|</span><a href="#41072779">prev</a><span>|</span><a href="#41072606">next</a><span>|</span><label class="collapse" for="c-41073452">[-]</label><label class="expand" for="c-41073452">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this principle extends to math proofs. It&#x27;s much, much easier to verify a proof than to create it, and a second proof will just be a footnote. Not many mathematicians will want to work on that. That said, there is a lot of distance between IMO and the frontiers of research math.</div><br/><div id="41073502" class="c"><input type="checkbox" id="c-41073502" checked=""/><div class="controls bullet"><span class="by">cynicalpeace</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41073452">parent</a><span>|</span><a href="#41072606">next</a><span>|</span><label class="collapse" for="c-41073502">[-]</label><label class="expand" for="c-41073502">[1 more]</label></div><br/><div class="children"><div class="content">Why does it not extend to math proofs?</div><br/></div></div></div></div><div id="41072606" class="c"><input type="checkbox" id="c-41072606" checked=""/><div class="controls bullet"><span class="by">awahab92</span><span>|</span><a href="#41072338">parent</a><span>|</span><a href="#41073452">prev</a><span>|</span><a href="#41075797">next</a><span>|</span><label class="collapse" for="c-41072606">[-]</label><label class="expand" for="c-41072606">[3 more]</label></div><br/><div class="children"><div class="content">magnus carlsen basically quit because computers ruined chess. As did kasparov.<p>Fischer was probably the last great player who was unassisted by tools.</div><br/><div id="41072898" class="c"><input type="checkbox" id="c-41072898" checked=""/><div class="controls bullet"><span class="by">karmakurtisaani</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41072606">parent</a><span>|</span><a href="#41072804">next</a><span>|</span><label class="collapse" for="c-41072898">[-]</label><label class="expand" for="c-41072898">[1 more]</label></div><br/><div class="children"><div class="content">Carlsen plays still at the highest level. He just didn&#x27;t want to do the world championship anymore, wasn&#x27;t worth the effort after winning it so many times.</div><br/></div></div><div id="41072804" class="c"><input type="checkbox" id="c-41072804" checked=""/><div class="controls bullet"><span class="by">hyperbovine</span><span>|</span><a href="#41072338">root</a><span>|</span><a href="#41072606">parent</a><span>|</span><a href="#41072898">prev</a><span>|</span><a href="#41075797">next</a><span>|</span><label class="collapse" for="c-41072804">[-]</label><label class="expand" for="c-41072804">[1 more]</label></div><br/><div class="children"><div class="content">?? Carlsen is very much active -- look up the YouTube channel EpicChess for an extremely entertaining recap of what he&#x27;s up to recently.</div><br/></div></div></div></div><div id="41075797" class="c"><input type="checkbox" id="c-41075797" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41072338">parent</a><span>|</span><a href="#41072606">prev</a><span>|</span><a href="#41073509">next</a><span>|</span><label class="collapse" for="c-41075797">[-]</label><label class="expand" for="c-41075797">[1 more]</label></div><br/><div class="children"><div class="content">Eh, people definitely care. AI has completely changed chess. Non viable lines have been proven viable and vice versa. All the pros study and develop new lines with AI.</div><br/></div></div></div></div><div id="41073509" class="c"><input type="checkbox" id="c-41073509" checked=""/><div class="controls bullet"><span class="by">zone411</span><span>|</span><a href="#41072338">prev</a><span>|</span><a href="#41076429">next</a><span>|</span><label class="collapse" for="c-41073509">[-]</label><label class="expand" for="c-41073509">[1 more]</label></div><br/><div class="children"><div class="content">The best discussion is here: <a href="https:&#x2F;&#x2F;leanprover.zulipchat.com&#x2F;#narrow&#x2F;stream&#x2F;219941-Machine-Learning-for-Theorem-Proving" rel="nofollow">https:&#x2F;&#x2F;leanprover.zulipchat.com&#x2F;#narrow&#x2F;stream&#x2F;219941-Machi...</a></div><br/></div></div><div id="41076429" class="c"><input type="checkbox" id="c-41076429" checked=""/><div class="controls bullet"><span class="by">nitrobeast</span><span>|</span><a href="#41073509">prev</a><span>|</span><a href="#41069970">next</a><span>|</span><label class="collapse" for="c-41076429">[-]</label><label class="expand" for="c-41076429">[1 more]</label></div><br/><div class="children"><div class="content">Reading into the details, the system is more impressive than the title. 100% of the algebra and geometry problems were solved. The remaining problems are of combinatorial types, which ironically more closely resembles software engineering work.</div><br/></div></div><div id="41069970" class="c"><input type="checkbox" id="c-41069970" checked=""/><div class="controls bullet"><span class="by">adverbly</span><span>|</span><a href="#41076429">prev</a><span>|</span><a href="#41071135">next</a><span>|</span><label class="collapse" for="c-41069970">[-]</label><label class="expand" for="c-41069970">[58 more]</label></div><br/><div class="children"><div class="content">&gt; First, the problems were manually translated into formal mathematical language for our systems to understand. In the official competition, students submit answers in two sessions of 4.5 hours each. Our systems solved one problem within minutes and took up to three days to solve the others.<p>Three days is interesting... Not technically silver medal performance I guess, but let&#x27;s be real I&#x27;d be okay waiting a month for the cure to cancer.</div><br/><div id="41070126" class="c"><input type="checkbox" id="c-41070126" checked=""/><div class="controls bullet"><span class="by">ZenMikey</span><span>|</span><a href="#41069970">parent</a><span>|</span><a href="#41070708">next</a><span>|</span><label class="collapse" for="c-41070126">[-]</label><label class="expand" for="c-41070126">[10 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t read TFA as I&#x27;m at work, but I would be very interested to know what the system was doing in those three days. Were there failed branches it explored? Was it just fumbling its way around until it guessed correctly? What did the feedback loop look like?</div><br/><div id="41070256" class="c"><input type="checkbox" id="c-41070256" checked=""/><div class="controls bullet"><span class="by">qsort</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070126">parent</a><span>|</span><a href="#41070933">next</a><span>|</span><label class="collapse" for="c-41070256">[-]</label><label class="expand" for="c-41070256">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t find a link to an actual paper, that just seems to be a blog post. But from what I gather the problems were manually translated to Lean 4, and then the program is doing some kind of tree search. I&#x27;m assuming they are leveraging the proof checker to provide feedback to the model.</div><br/></div></div><div id="41070933" class="c"><input type="checkbox" id="c-41070933" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070126">parent</a><span>|</span><a href="#41070256">prev</a><span>|</span><a href="#41071357">next</a><span>|</span><label class="collapse" for="c-41070933">[-]</label><label class="expand" for="c-41070933">[4 more]</label></div><br/><div class="children"><div class="content">&gt; just fumbling its way around until it guessed correctly<p>As opposed to 0.999999% of the human population who can&#x27;t do it even if their life depends on it?</div><br/><div id="41071324" class="c"><input type="checkbox" id="c-41071324" checked=""/><div class="controls bullet"><span class="by">dsign</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070933">parent</a><span>|</span><a href="#41072882">next</a><span>|</span><label class="collapse" for="c-41071324">[-]</label><label class="expand" for="c-41071324">[2 more]</label></div><br/><div class="children"><div class="content">I was going to come here to say that. I remember being a teenager and giving up in frustration at IMO problems. And I was competing at IPhO.</div><br/><div id="41074606" class="c"><input type="checkbox" id="c-41074606" checked=""/><div class="controls bullet"><span class="by">kevinventullo</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41071324">parent</a><span>|</span><a href="#41072882">next</a><span>|</span><label class="collapse" for="c-41074606">[-]</label><label class="expand" for="c-41074606">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, as a former research mathematician, I think “fumbling around blindly” is not an entirely unfair description of the research process.<p>I believe even Wiles in a documentary described his search for the proof of Fermat’s last theorem as groping around in a pitch black room, but once the proof was discovered it was like someone turned the lights on.</div><br/></div></div></div></div><div id="41072882" class="c"><input type="checkbox" id="c-41072882" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070933">parent</a><span>|</span><a href="#41071324">prev</a><span>|</span><a href="#41071357">next</a><span>|</span><label class="collapse" for="c-41072882">[-]</label><label class="expand" for="c-41072882">[1 more]</label></div><br/><div class="children"><div class="content">I guess you mean 99.9999%?</div><br/></div></div></div></div><div id="41071357" class="c"><input type="checkbox" id="c-41071357" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070126">parent</a><span>|</span><a href="#41070933">prev</a><span>|</span><a href="#41070642">next</a><span>|</span><label class="collapse" for="c-41071357">[-]</label><label class="expand" for="c-41071357">[1 more]</label></div><br/><div class="children"><div class="content">They just write &quot;it&#x27;s like alpha zero&quot;. So presumably they used a version of MCTS where each terminal node is scored by LEAN as either correct or incorrect.<p>Then they can train a network to evaluate intermediate positions (score network) and one to suggest things to try next (policy network).</div><br/></div></div><div id="41070642" class="c"><input type="checkbox" id="c-41070642" checked=""/><div class="controls bullet"><span class="by">tsoj</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070126">parent</a><span>|</span><a href="#41071357">prev</a><span>|</span><a href="#41071103">next</a><span>|</span><label class="collapse" for="c-41070642">[-]</label><label class="expand" for="c-41070642">[1 more]</label></div><br/><div class="children"><div class="content">This is NOT the paper, but probably a very similar solution: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2009.03393" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2009.03393</a></div><br/></div></div><div id="41071103" class="c"><input type="checkbox" id="c-41071103" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070126">parent</a><span>|</span><a href="#41070642">prev</a><span>|</span><a href="#41074629">next</a><span>|</span><label class="collapse" for="c-41071103">[-]</label><label class="expand" for="c-41071103">[1 more]</label></div><br/><div class="children"><div class="content"><i>The training loop was also applied during the contest, reinforcing proofs of self-generated variations of the contest problems until a full solution could be found.</i><p>So they had three days to keep training the model, on synthetic variations of each IMO problem.</div><br/></div></div><div id="41074629" class="c"><input type="checkbox" id="c-41074629" checked=""/><div class="controls bullet"><span class="by">utopcell</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070126">parent</a><span>|</span><a href="#41071103">prev</a><span>|</span><a href="#41070708">next</a><span>|</span><label class="collapse" for="c-41074629">[-]</label><label class="expand" for="c-41074629">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m at work and reading this article is the first thing I did this morning. What&#x27;s your point ?</div><br/></div></div></div></div><div id="41070708" class="c"><input type="checkbox" id="c-41070708" checked=""/><div class="controls bullet"><span class="by">10100110</span><span>|</span><a href="#41069970">parent</a><span>|</span><a href="#41070126">prev</a><span>|</span><a href="#41070449">next</a><span>|</span><label class="collapse" for="c-41070708">[-]</label><label class="expand" for="c-41070708">[11 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t confuse interpolation with extrapolation. Curing cancer will require new ideas. IMO requires skill proficiency in tasks where the methods of solving are known.</div><br/><div id="41071030" class="c"><input type="checkbox" id="c-41071030" checked=""/><div class="controls bullet"><span class="by">trotro</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070708">parent</a><span>|</span><a href="#41070922">next</a><span>|</span><label class="collapse" for="c-41071030">[-]</label><label class="expand" for="c-41071030">[3 more]</label></div><br/><div class="children"><div class="content">The methods are know, but the solutions to the IMO problems weren&#x27;t. So the AI did extrapolate a solution.<p>Also, there&#x27;s no reason to affirm that an eventual cure for cancer requires fundamentally new methods. Maybe the current methods are sufficient, it&#x27;s just that nobody has been &quot;smart&quot; enough to put the pieces together. (disclaimer: not an expert at all)</div><br/><div id="41072102" class="c"><input type="checkbox" id="c-41072102" checked=""/><div class="controls bullet"><span class="by">markusde</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41071030">parent</a><span>|</span><a href="#41071383">next</a><span>|</span><label class="collapse" for="c-41072102">[-]</label><label class="expand" for="c-41072102">[1 more]</label></div><br/><div class="children"><div class="content">Unlike curing cancer, the IMO problems were specifically designed to be solvable</div><br/></div></div><div id="41071383" class="c"><input type="checkbox" id="c-41071383" checked=""/><div class="controls bullet"><span class="by">dsign</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41071030">parent</a><span>|</span><a href="#41072102">prev</a><span>|</span><a href="#41070922">next</a><span>|</span><label class="collapse" for="c-41071383">[-]</label><label class="expand" for="c-41071383">[1 more]</label></div><br/><div class="children"><div class="content">I think you are correct though. We don&#x27;t need new physics to cure cancer. But we may need information-handling, reasoning and simulation systems which are orders of magnitude bigger and more complex than anything we have this year. We also need to stop pussy-footing and diddling with ideologies and start working on the root cause of cancer and almost every other disease, which is aging.</div><br/></div></div></div></div><div id="41070922" class="c"><input type="checkbox" id="c-41070922" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070708">parent</a><span>|</span><a href="#41071030">prev</a><span>|</span><a href="#41072636">next</a><span>|</span><label class="collapse" for="c-41070922">[-]</label><label class="expand" for="c-41070922">[1 more]</label></div><br/><div class="children"><div class="content">Mathematicians spend most of their time interpolating between known ideas and it would be extremely helpful to have computer assistance with that.</div><br/></div></div><div id="41072636" class="c"><input type="checkbox" id="c-41072636" checked=""/><div class="controls bullet"><span class="by">xdavidliu</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070708">parent</a><span>|</span><a href="#41070922">prev</a><span>|</span><a href="#41070949">next</a><span>|</span><label class="collapse" for="c-41072636">[-]</label><label class="expand" for="c-41072636">[1 more]</label></div><br/><div class="children"><div class="content">new doesn&#x27;t necessarily mean &quot;an extremal point that&#x27;s not the average of two existing points&quot;. The set of existing knowledge is not necessarily continuous; the midpoint between two known points may be unknown, and thus would be a &quot;new&quot; point that could be obtained by interpolation.</div><br/></div></div><div id="41070949" class="c"><input type="checkbox" id="c-41070949" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070708">parent</a><span>|</span><a href="#41072636">prev</a><span>|</span><a href="#41070825">next</a><span>|</span><label class="collapse" for="c-41070949">[-]</label><label class="expand" for="c-41070949">[3 more]</label></div><br/><div class="children"><div class="content">Search is extrapolation. Learning is interpolation. Search+Learn is the formula used by AZ. Don&#x27;t forget AZ taught us humans a thing or two about a game we had 2000 years head start in, and starting from scratch not from human supervision.</div><br/><div id="41072658" class="c"><input type="checkbox" id="c-41072658" checked=""/><div class="controls bullet"><span class="by">xdavidliu</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070949">parent</a><span>|</span><a href="#41070825">next</a><span>|</span><label class="collapse" for="c-41072658">[-]</label><label class="expand" for="c-41072658">[2 more]</label></div><br/><div class="children"><div class="content">no, search is not extrapolation. Extrapolation means taking some data and projecting out beyond the limits of that data. For example, if my bank account had $10 today and $20 tomorrow, then I can extrapolate and say it might have $30 the day after tomorrow. Interpolation means taking some data and inferring the gaps of that data. For example, if I had $10 today and $30 the day after tomorrow, I can interpolate and say I probably had $20 tomorrow.<p>Search is different from either of those things, it&#x27;s when you have a target and a collection of other things, and are trying to find the target in that collection.</div><br/><div id="41073639" class="c"><input type="checkbox" id="c-41073639" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41072658">parent</a><span>|</span><a href="#41070825">next</a><span>|</span><label class="collapse" for="c-41073639">[-]</label><label class="expand" for="c-41073639">[1 more]</label></div><br/><div class="children"><div class="content">Search can go from a random init model to beating humans at Go. That is not interpolation.<p>- Search allows exploration of the game tree, potentially finding novel strategies.<p>- Learning compresses the insights gained from search into a more efficient policy.<p>- This compressed policy then guides future searches more effectively.<p>Evolution is also a form of search, and it is open-ended. AlphaProof solved IMO problems, those are chosen to be out of distribution, simple imitation can&#x27;t solve them. Scientists do (re)search, they find novel insights nobody else discovered before. What I want to say is that search is on a whole different level than what neural nets do, they can only interpolate their training data, search pushes outside of the known data distribution.<p>It&#x27;s actually a combo of search+learning that is necessary, learning is just the little brother of search, it compresses novel insights into the model. You can think of training a neural net also as search - the best parameters that would fit the training set.</div><br/></div></div></div></div></div></div><div id="41070825" class="c"><input type="checkbox" id="c-41070825" checked=""/><div class="controls bullet"><span class="by">trueismywork</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070708">parent</a><span>|</span><a href="#41070949">prev</a><span>|</span><a href="#41072721">next</a><span>|</span><label class="collapse" for="c-41070825">[-]</label><label class="expand" for="c-41070825">[1 more]</label></div><br/><div class="children"><div class="content">They are the same things</div><br/></div></div><div id="41072721" class="c"><input type="checkbox" id="c-41072721" checked=""/><div class="controls bullet"><span class="by">im3w1l</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070708">parent</a><span>|</span><a href="#41070825">prev</a><span>|</span><a href="#41070449">next</a><span>|</span><label class="collapse" for="c-41072721">[-]</label><label class="expand" for="c-41072721">[1 more]</label></div><br/><div class="children"><div class="content">I think this is kinda false actually on the cancer side. We have reached a point where we have known approaches that work. It&#x27;s &quot;just&quot; a matter of putting them into practice which will of course require solving many little details, which is very important and time-consuming work, but it doesn&#x27;t require super-human genius level of lateral thinking, just a few millions man years of grinding away at it.</div><br/></div></div></div></div><div id="41070449" class="c"><input type="checkbox" id="c-41070449" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#41069970">parent</a><span>|</span><a href="#41070708">prev</a><span>|</span><a href="#41070350">next</a><span>|</span><label class="collapse" for="c-41070449">[-]</label><label class="expand" for="c-41070449">[4 more]</label></div><br/><div class="children"><div class="content">The problem solved &quot;within minutes&quot; is also interesting. I&#x27;d interpret that as somewhere between 2 and 59 minutes. Given the vagueness probably on the higher end, otherwise they&#x27;d celebrate it more. The students had 6 tasks in 9 hours, so on average 1.5h per task. If you add the time a student would take to (correctly!) translate the problems to their input format, their best-case runtime is probably about as fast as a silver-medalist would take to solve the problem on their own.<p>But even if they aren&#x27;t as fast as humans yet this is very valuable. Both as a stepping stone, and because at a certain scale compute is much easier to scale than skilled mathematicians.</div><br/><div id="41070610" class="c"><input type="checkbox" id="c-41070610" checked=""/><div class="controls bullet"><span class="by">gjm11</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070449">parent</a><span>|</span><a href="#41070350">next</a><span>|</span><label class="collapse" for="c-41070610">[-]</label><label class="expand" for="c-41070610">[3 more]</label></div><br/><div class="children"><div class="content">They say &quot;our systems&quot; (presumably meaning AlphaProof <i>and</i> AlphaGeometry 2) solved one problem &quot;within minutes&quot;, and later on the page they say that the geometry question (#4) was solved by AlphaGeometry in 19 seconds.<p>So either (1) &quot;within minutes&quot; was underselling the abilities of the system, or (2) what they actually meant was that the geometry problem was solved in 19 seconds, one of the others &quot;within minutes&quot; (I&#x27;d guess #1 which is definitely easier than the other two they solved), and the others in unspecified times of which the longer was ~3 days.<p>I&#x27;d guess it&#x27;s the first of those.<p>(Euclidean geometry has been a kinda-solved domain for some time; it&#x27;s not super-surprising that they were able to solve that problem quickly.)<p>As for the long solve times, I would guess they&#x27;re related to this fascinating remark:<p>&gt; The training loop was also applied during the contest, reinforcing proofs of self-generated variations of the contest problems until a full solution could be found.</div><br/><div id="41070984" class="c"><input type="checkbox" id="c-41070984" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070610">parent</a><span>|</span><a href="#41070350">next</a><span>|</span><label class="collapse" for="c-41070984">[-]</label><label class="expand" for="c-41070984">[2 more]</label></div><br/><div class="children"><div class="content">Euclidian Geometry still requires constructions to solve, and those are based in intuition.</div><br/><div id="41073355" class="c"><input type="checkbox" id="c-41073355" checked=""/><div class="controls bullet"><span class="by">gjm11</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070984">parent</a><span>|</span><a href="#41070350">next</a><span>|</span><label class="collapse" for="c-41073355">[-]</label><label class="expand" for="c-41073355">[1 more]</label></div><br/><div class="children"><div class="content">There are known algorithms that can solve _all_ problems in euclidean (ruler-and-compasses) geometry, no intuition required. The most effective algorithms of this type are quite inefficient, though, and (at least according to DeepMind) don&#x27;t do as well as AlphaGeometry does at e.g. IMO geometry problems.</div><br/></div></div></div></div></div></div></div></div><div id="41070350" class="c"><input type="checkbox" id="c-41070350" checked=""/><div class="controls bullet"><span class="by">nnarek</span><span>|</span><a href="#41069970">parent</a><span>|</span><a href="#41070449">prev</a><span>|</span><a href="#41070238">next</a><span>|</span><label class="collapse" for="c-41070350">[-]</label><label class="expand" for="c-41070350">[10 more]</label></div><br/><div class="children"><div class="content">&quot;three days&quot; does not say anything about how much computational power is used to solve problems, maybe they have used 10% of all GCP :)</div><br/><div id="41070483" class="c"><input type="checkbox" id="c-41070483" checked=""/><div class="controls bullet"><span class="by">falcor84</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070350">parent</a><span>|</span><a href="#41070453">next</a><span>|</span><label class="collapse" for="c-41070483">[-]</label><label class="expand" for="c-41070483">[3 more]</label></div><br/><div class="children"><div class="content">And say they did use 10% of all GCP? Would it be less impressive? This is a result that was considered by experts to be far beyond the state of the art; it&#x27;s absolutely ok if it&#x27;s not very efficient yet.<p>Also, for what it&#x27;s worth, I&#x27;m pretty sure that I wouldn&#x27;t have been able to solve it myself in three days, even if I had access to all of GCP, Azure and AWS (except if I could mine crypto to then pay actual IMO-level mathematicians to solve it for me).</div><br/><div id="41073684" class="c"><input type="checkbox" id="c-41073684" checked=""/><div class="controls bullet"><span class="by">data_maan</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070483">parent</a><span>|</span><a href="#41070813">next</a><span>|</span><label class="collapse" for="c-41073684">[-]</label><label class="expand" for="c-41073684">[1 more]</label></div><br/><div class="children"><div class="content">Which experts said that?<p>I don&#x27;t think that&#x27;s the case at all. The writing was already on the wall.</div><br/></div></div><div id="41070813" class="c"><input type="checkbox" id="c-41070813" checked=""/><div class="controls bullet"><span class="by">nnarek</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070483">parent</a><span>|</span><a href="#41073684">prev</a><span>|</span><a href="#41070453">next</a><span>|</span><label class="collapse" for="c-41070813">[-]</label><label class="expand" for="c-41070813">[1 more]</label></div><br/><div class="children"><div class="content">yes it is very impressive, especially autoformalization of problems written in natural language and also proof search of theorems</div><br/></div></div></div></div><div id="41070453" class="c"><input type="checkbox" id="c-41070453" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070350">parent</a><span>|</span><a href="#41070483">prev</a><span>|</span><a href="#41070238">next</a><span>|</span><label class="collapse" for="c-41070453">[-]</label><label class="expand" for="c-41070453">[6 more]</label></div><br/><div class="children"><div class="content">The thing is though, once we have a benchmark that we pass, it’s pretty typical to be able to bring down time required in short order through performance improvements and iterating on ideas. So if you knew you had GAI but it took 100% of all GCP for 3 years to give a result, within the next 5 years that would come down significantly (not least of which you’d build HW dedicated to accelerating the slow parts).</div><br/><div id="41070510" class="c"><input type="checkbox" id="c-41070510" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070453">parent</a><span>|</span><a href="#41070238">next</a><span>|</span><label class="collapse" for="c-41070510">[-]</label><label class="expand" for="c-41070510">[5 more]</label></div><br/><div class="children"><div class="content">That&#x27;s patently false for many classes of problems. We know exactly how to solve the traveling salesman problem, and have for decades, but we&#x27;re nowhere close to solving a random 1000 city case (note: there are approximate methods that can find good, but not optimal, results on millions of cities). Edit: I should say 1,000,000 city problem, as there are some solutions for 30-60k cities from the 2000s.<p>And there are good reasons to believe that theorem finding and proof generation are at least NP-hard problems.</div><br/><div id="41070789" class="c"><input type="checkbox" id="c-41070789" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070510">parent</a><span>|</span><a href="#41070581">next</a><span>|</span><label class="collapse" for="c-41070789">[-]</label><label class="expand" for="c-41070789">[3 more]</label></div><br/><div class="children"><div class="content">We&#x27;re not talking about mathematical optimality here, both from the solution found and for the time taken. The point is whether this finds results more cheaply than a human can and right now it&#x27;s better on some problems while others it&#x27;s worse. Clearly if a human can do it, there is a way to solve it in a cheaper amount of time and it would be flawed reasoning to think that improving the amount of time would be asymptotically optimal already.<p>While I agree that not all problems show this kind of acceleration in performance, that&#x27;s typically only true if you&#x27;ve already spent so much time trying to solve it that you&#x27;ve asymptoted to the optimal solution. Right now we&#x27;re nowhere near the asymptote for AI improvements. Additionally, there&#x27;s so many research dollars flowing into AI precisely because the potential upside here is nowhere near realized and there&#x27;s lots of research lines still left to be explored. George Hinton ended the AI winter.</div><br/><div id="41071011" class="c"><input type="checkbox" id="c-41071011" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070789">parent</a><span>|</span><a href="#41070581">next</a><span>|</span><label class="collapse" for="c-41071011">[-]</label><label class="expand" for="c-41071011">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The point is whether this finds results more cheaply than a human can<p>If you need to solve 1000 problems in 3 days you wouldn&#x27;t find the humans that can do it. So it would not be cheaper if it&#x27;s not possible.</div><br/><div id="41072545" class="c"><input type="checkbox" id="c-41072545" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41071011">parent</a><span>|</span><a href="#41070581">next</a><span>|</span><label class="collapse" for="c-41072545">[-]</label><label class="expand" for="c-41072545">[1 more]</label></div><br/><div class="children"><div class="content">Well if it takes 10% of all of Google’s servers 3 days to solve, you may find it difficult to scale out to solving 1000 problems in 3 days as well.<p>As for humans, 100 countries send 6 students to solve these problems. It also doesn’t mean that these problems aren’t solvable by anyone else. These are just the “best 6” where best = can solve and solve most quickly. Given a three day budget, 1000 problems could reasonably be solvable and you know exactly who to tap to try to solve them. Also, while the IMO is difficult and winners tend to win other awards like Field Medals, there’s many professional mathematicians who never even bother because that type of competition isn’t interesting to them. It’s not unreasonable to expect that professional mathematicians are able to solve these problems as well if they wanted to spend 3 days on it.<p>But in terms of energy per solve, humans are definitely cheaper. As you note the harder part is scaling it out but so far the AI isn’t solving problems that are impossible for humans, just that given enough time it managed to perform the same task. That’s a very promising result but supremacy is slightly a ways off for now (this AI can’t win the competition for now)</div><br/></div></div></div></div></div></div><div id="41070581" class="c"><input type="checkbox" id="c-41070581" checked=""/><div class="controls bullet"><span class="by">rowanG077</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070510">parent</a><span>|</span><a href="#41070789">prev</a><span>|</span><a href="#41070238">next</a><span>|</span><label class="collapse" for="c-41070581">[-]</label><label class="expand" for="c-41070581">[1 more]</label></div><br/><div class="children"><div class="content">The person said typical not always the case. Just because there are obviously cases where it didn&#x27;t happen does mean it it&#x27;s still not typically the case.</div><br/></div></div></div></div></div></div></div></div><div id="41070238" class="c"><input type="checkbox" id="c-41070238" checked=""/><div class="controls bullet"><span class="by">ComplexSystems</span><span>|</span><a href="#41069970">parent</a><span>|</span><a href="#41070350">prev</a><span>|</span><a href="#41070496">next</a><span>|</span><label class="collapse" for="c-41070238">[-]</label><label class="expand" for="c-41070238">[6 more]</label></div><br/><div class="children"><div class="content">Or the simultaneous discovery of thousands of cryptographic exploits...</div><br/><div id="41070433" class="c"><input type="checkbox" id="c-41070433" checked=""/><div class="controls bullet"><span class="by">poincaredisk</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070238">parent</a><span>|</span><a href="#41070496">next</a><span>|</span><label class="collapse" for="c-41070433">[-]</label><label class="expand" for="c-41070433">[5 more]</label></div><br/><div class="children"><div class="content">Still waiting for the first one. I&#x27;m not holding my breath - just like fuzzing found a lot of vulnerabilities in low-level software, I expect novel automated analysis approaches will yield some vulnerabilities - but that won&#x27;t be a catastrophic event just like fuzzing wasn&#x27;t.</div><br/><div id="41073398" class="c"><input type="checkbox" id="c-41073398" checked=""/><div class="controls bullet"><span class="by">ComplexSystems</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070433">parent</a><span>|</span><a href="#41071269">next</a><span>|</span><label class="collapse" for="c-41073398">[-]</label><label class="expand" for="c-41073398">[1 more]</label></div><br/><div class="children"><div class="content">Why don&#x27;t you think that AI models will, perhaps rather soon, surpass human capabilities in finding security vulnerabilities? Because an AI that&#x27;s even equally competent would be a fairly catastrophic event.</div><br/></div></div><div id="41071269" class="c"><input type="checkbox" id="c-41071269" checked=""/><div class="controls bullet"><span class="by">criddell</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070433">parent</a><span>|</span><a href="#41073398">prev</a><span>|</span><a href="#41071157">next</a><span>|</span><label class="collapse" for="c-41071269">[-]</label><label class="expand" for="c-41071269">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s rumored that the NSA has 600 mathematicians working for them. If they are the ones finding the exploits you will probably never hear about them until they are independently discovered by someone who can publish.</div><br/></div></div><div id="41071157" class="c"><input type="checkbox" id="c-41071157" checked=""/><div class="controls bullet"><span class="by">throwaway240403</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070433">parent</a><span>|</span><a href="#41071269">prev</a><span>|</span><a href="#41070543">next</a><span>|</span><label class="collapse" for="c-41071157">[-]</label><label class="expand" for="c-41071157">[1 more]</label></div><br/><div class="children"><div class="content">Hope that&#x27;s true.
Really mucks up the world a bit if not.</div><br/></div></div><div id="41070543" class="c"><input type="checkbox" id="c-41070543" checked=""/><div class="controls bullet"><span class="by">sqeaky</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070433">parent</a><span>|</span><a href="#41071157">prev</a><span>|</span><a href="#41070496">next</a><span>|</span><label class="collapse" for="c-41070543">[-]</label><label class="expand" for="c-41070543">[1 more]</label></div><br/><div class="children"><div class="content">I hope it doesn&#x27;t find a new class of bug. Find another thing like Spectre could be problematic.<p>EDIT - I hope if that new class of bug exists that it is found. I hope that new class of bug doesn&#x27;t exist.</div><br/></div></div></div></div></div></div><div id="41070496" class="c"><input type="checkbox" id="c-41070496" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41069970">parent</a><span>|</span><a href="#41070238">prev</a><span>|</span><a href="#41071135">next</a><span>|</span><label class="collapse" for="c-41070496">[-]</label><label class="expand" for="c-41070496">[16 more]</label></div><br/><div class="children"><div class="content">It feels pretty disingenuous to claim silver-medal status when your machine played by significantly different rules. The article is light on details, but it says they wired it up to a theorem prover, presumably with feedback sent back to the AI model for re-evaluation.<p>How many cycles of guess-and-check did it take over the course of three days to get the right answer?<p>If the IMO contestants were allowed to use theorem provers and were given 3 days (even factoring in sleep) would AlphaProof still have gotten silver?<p>&gt; let&#x27;s be real I&#x27;d be okay waiting a month for the cure to cancer.<p>I don&#x27;t think these results suggest that we&#x27;re on the brink of knowledge coming at a substantially faster rate than before. Humans have been using theorem provers to advance our understanding for decades. Now an LLM has been wired up to one too, but it still took 8x as long to solve the problems as our best humans did <i>without any computer assistance</i>.</div><br/><div id="41070612" class="c"><input type="checkbox" id="c-41070612" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070496">parent</a><span>|</span><a href="#41076902">prev</a><span>|</span><a href="#41070966">next</a><span>|</span><label class="collapse" for="c-41070612">[-]</label><label class="expand" for="c-41070612">[8 more]</label></div><br/><div class="children"><div class="content">I believe you are misreading this.<p>First of all, this is not a sport and the point is not to compare AI to humans. The point is to compare AI to IMO-difficulty problems.<p>Secondly, this is now some hacky trick where Brute force and some theorem prover magic are massaged to solve a select few problems and then you&#x27;ll never hear about it again. They are building a general pipeline which turns informal natural lamguage mathematics (of which we have ungodly amounts available) into formalized mathematics, and in addition trains a model to prove such kinds of mathematics. This can also work for theory building. This can become a real mathematical assistant that can help a mathematician test an argument, play with variations of a definition, try 100 combinations of some estimates, apply a classic but lengthy technique etc. etc.</div><br/><div id="41070824" class="c"><input type="checkbox" id="c-41070824" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070612">parent</a><span>|</span><a href="#41070917">next</a><span>|</span><label class="collapse" for="c-41070824">[-]</label><label class="expand" for="c-41070824">[4 more]</label></div><br/><div class="children"><div class="content">&gt; First of all, this is not a sport and the point is not to compare AI to humans. The point is to compare AI to IMO-difficulty problems.<p>If this were the case then the headline would be &quot;AI solves 4&#x2F;6 IMO 2024 problems&quot;, it wouldn&#x27;t be claiming &quot;silver-medal standard&quot;. Medals are generally awarded by comparison to other contestants, not to the challenges overcome.<p>&gt; This can become a real mathematical assistant that can help a mathematician test an argument, play with variations of a definition, try 100 combinations of some estimates, apply a classic but lengthy technique etc. etc.<p>This is great, and I&#x27;m not complaining about what the team is working on, I&#x27;m complaining about how it&#x27;s being sold. Headlines like these from lab press releases will feed the AI hype in counterproductive ways. The NYT literally has a headline right now: &quot;Move Over Mathematicians, Here Comes AlphaProof&quot;.</div><br/><div id="41070880" class="c"><input type="checkbox" id="c-41070880" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070824">parent</a><span>|</span><a href="#41070917">next</a><span>|</span><label class="collapse" for="c-41070880">[-]</label><label class="expand" for="c-41070880">[3 more]</label></div><br/><div class="children"><div class="content">At the IMO &quot;silver medal&quot; afaik is define as some tange of points, which more or less equals some range of problems solved. For me it is fair to say that &quot;silver-medal performance&quot; is IMO langauge for about 4&#x2F;6 problems solved. And what&#x27;s the problem if some clickbait websites totally spin the result? They would&#x27;ve done it anyways even with a different title, and I also don&#x27;t see the harm. Let people be wrong.</div><br/><div id="41071044" class="c"><input type="checkbox" id="c-41071044" checked=""/><div class="controls bullet"><span class="by">mathnmusic</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070880">parent</a><span>|</span><a href="#41070917">next</a><span>|</span><label class="collapse" for="c-41071044">[-]</label><label class="expand" for="c-41071044">[2 more]</label></div><br/><div class="children"><div class="content">No, &quot;silver medal&quot; is defined as a range of points to be earned in the allotted time (4.5 hours for both papers of 3 problems each).</div><br/><div id="41071660" class="c"><input type="checkbox" id="c-41071660" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41071044">parent</a><span>|</span><a href="#41070917">next</a><span>|</span><label class="collapse" for="c-41071660">[-]</label><label class="expand" for="c-41071660">[1 more]</label></div><br/><div class="children"><div class="content">And the cutoffs are chosen <i>after</i> the results are in, not in advance.</div><br/></div></div></div></div></div></div></div></div><div id="41070917" class="c"><input type="checkbox" id="c-41070917" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070612">parent</a><span>|</span><a href="#41070824">prev</a><span>|</span><a href="#41070966">next</a><span>|</span><label class="collapse" for="c-41070917">[-]</label><label class="expand" for="c-41070917">[3 more]</label></div><br/><div class="children"><div class="content">&gt; They are building a general pipeline which turns informal natural lamguage mathematics<p>but this part currently sucks, because they didn&#x27;t trust it and formalized problems manually.</div><br/><div id="41070945" class="c"><input type="checkbox" id="c-41070945" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070917">parent</a><span>|</span><a href="#41070966">next</a><span>|</span><label class="collapse" for="c-41070945">[-]</label><label class="expand" for="c-41070945">[2 more]</label></div><br/><div class="children"><div class="content">Yea that&#x27;s fair, but I don&#x27;t think it will keep sucking forever as formalization is in principle just a translation process.</div><br/><div id="41072195" class="c"><input type="checkbox" id="c-41072195" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070945">parent</a><span>|</span><a href="#41070966">next</a><span>|</span><label class="collapse" for="c-41072195">[-]</label><label class="expand" for="c-41072195">[1 more]</label></div><br/><div class="children"><div class="content">and we don&#x27;t have 100% accuracy in translation in ambiguous texts, because system often need some domain knowledge, context etc. And math has 0% tolerance to mistakes.<p>I also expect that math formalized by machine will be readable by machine and hardly understandable by humans.</div><br/></div></div></div></div></div></div></div></div><div id="41070966" class="c"><input type="checkbox" id="c-41070966" checked=""/><div class="controls bullet"><span class="by">regularfry</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070496">parent</a><span>|</span><a href="#41070612">prev</a><span>|</span><a href="#41070538">next</a><span>|</span><label class="collapse" for="c-41070966">[-]</label><label class="expand" for="c-41070966">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure it matters that it had access to a theorem prover.  The fact that it&#x27;s possible to build a black box that solves hard proofs on its own <i>at all</i> is the fascinating bit.<p>&gt; it still took 8x as long to solve the problems as our best humans did without any computer assistance.<p>Give it a year and that ratio will be reversed.  At least.  But also it matters less how long it takes if doubling the number of things reasoning at a best-human level is pronounced &quot;ctrl-c, ctrl-v&quot;.</div><br/></div></div><div id="41070538" class="c"><input type="checkbox" id="c-41070538" checked=""/><div class="controls bullet"><span class="by">ToucanLoucan</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070496">parent</a><span>|</span><a href="#41070966">prev</a><span>|</span><a href="#41071135">next</a><span>|</span><label class="collapse" for="c-41070538">[-]</label><label class="expand" for="c-41070538">[5 more]</label></div><br/><div class="children"><div class="content">I am so exhausted of the AI hype nonsense. LLMs are not fucking curing cancer. Not now, not in five years, not in a hundred years. That&#x27;s not what they do.<p>LLM&#x2F;ML is fascinating tech that has a lot of legitimate applications, but <i>it is not fucking intelligent, artificial or otherwise,</i> and I am sick to death of people treating it like it is.</div><br/><div id="41070578" class="c"><input type="checkbox" id="c-41070578" checked=""/><div class="controls bullet"><span class="by">apsec112</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070538">parent</a><span>|</span><a href="#41071137">next</a><span>|</span><label class="collapse" for="c-41070578">[-]</label><label class="expand" for="c-41070578">[2 more]</label></div><br/><div class="children"><div class="content">What observation, if you saw it, do you think would falsify that hypothesis?</div><br/><div id="41074139" class="c"><input type="checkbox" id="c-41074139" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070578">parent</a><span>|</span><a href="#41071137">next</a><span>|</span><label class="collapse" for="c-41074139">[-]</label><label class="expand" for="c-41074139">[1 more]</label></div><br/><div class="children"><div class="content">It seems unlikely people will employ <i>only</i> ML models, especially LLM, to achieve great results: they will combine it with human insights (through direction and concrete algorithms).<p>It&#x27;s obvious that&#x27;s happening with LLMs even today to ensure they don&#x27;t spew out too much bullshit or harmful content.  So let&#x27;s get to a point where we can trust AI as-is first, and let&#x27;s talk about what&#x27;s needed to achieve the next milestone after and <i>if</i> we get there.<p>And I love asking every new iteration of ChatGPT&#x2F;Gemini something along the lines of &quot;What day was yesterday if yesterday was a Thursday?&quot; It just makes me giggle.</div><br/></div></div></div></div><div id="41071137" class="c"><input type="checkbox" id="c-41071137" checked=""/><div class="controls bullet"><span class="by">jercos</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070538">parent</a><span>|</span><a href="#41070578">prev</a><span>|</span><a href="#41070724">next</a><span>|</span><label class="collapse" for="c-41071137">[-]</label><label class="expand" for="c-41071137">[1 more]</label></div><br/><div class="children"><div class="content">A significant part of the problem is that a majority of people are unaware of just how simple what they consider &quot;intelligence&quot; really is. You don&#x27;t need actual intelligence to replace the public-facing social role of a politician, or a talking head, or a reactive-only middle manager. You just need words strung together that fit a problem.</div><br/></div></div><div id="41070724" class="c"><input type="checkbox" id="c-41070724" checked=""/><div class="controls bullet"><span class="by">29athrowaway</span><span>|</span><a href="#41069970">root</a><span>|</span><a href="#41070538">parent</a><span>|</span><a href="#41071137">prev</a><span>|</span><a href="#41071135">next</a><span>|</span><label class="collapse" for="c-41070724">[-]</label><label class="expand" for="c-41070724">[1 more]</label></div><br/><div class="children"><div class="content">It is not artificial? so it is natural then?</div><br/></div></div></div></div></div></div></div></div><div id="41071135" class="c"><input type="checkbox" id="c-41071135" checked=""/><div class="controls bullet"><span class="by">Jun8</span><span>|</span><a href="#41069970">prev</a><span>|</span><a href="#41076334">next</a><span>|</span><label class="collapse" for="c-41071135">[-]</label><label class="expand" for="c-41071135">[1 more]</label></div><br/><div class="children"><div class="content">Tangentially: I found it fascinating to follow along the solution to Problem 6: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;7h3gJfWnDoc" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;7h3gJfWnDoc</a> (aquaesulian is a node to ancient name of Bath). There’s no advanced math and each step is quite simple, I’d guess on a medium 8th grader level.<p>Note that the 6th question is generally the hardest (“final boss”) and many top performers couldn’t solve it.<p>I don’t know what Lean is or how see AI’s proofs but an AI system that can explain such a question on par with the YouTuber above would be fantastic!</div><br/></div></div><div id="41076334" class="c"><input type="checkbox" id="c-41076334" checked=""/><div class="controls bullet"><span class="by">amarant</span><span>|</span><a href="#41071135">prev</a><span>|</span><a href="#41075528">next</a><span>|</span><label class="collapse" for="c-41076334">[-]</label><label class="expand" for="c-41076334">[1 more]</label></div><br/><div class="children"><div class="content">This is quite cool! I&#x27;ve found logical reasoning to be one of the biggest weak points of LLMs, nice to see that an alternative approach works better! 
I&#x27;ve tried to enlist gpt to help me play a android game called 4=10, where you solve simple math problems, and gpt was hilariously terrible at it. It would both break the rules I described, and make math mistakes, such as claiming 6*5-5+8=10<p>I wonder if this new model could be integrated with an LLM somehow? I get the feeling that combining those two powers would result in a fairly capable programmer.<p>Also perhaps a LLM could do the translation step that is currently manual?</div><br/></div></div><div id="41075528" class="c"><input type="checkbox" id="c-41075528" checked=""/><div class="controls bullet"><span class="by">_heimdall</span><span>|</span><a href="#41076334">prev</a><span>|</span><a href="#41075929">next</a><span>|</span><label class="collapse" for="c-41075528">[-]</label><label class="expand" for="c-41075528">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m still unclear whether the system used here is actually reasoning through the process of solving the problem, or brute forcing solutions with reasoning coming in during the mathematical proof of each potential proof.<p>Is it clear whether the algorithm is actually learning from <i>why</i> previously attempted solutions failed to prove out, or is it statistically generating potential answers similar to an LLM and then trying to apply reasoning to prove out the potential solution?</div><br/></div></div><div id="41075929" class="c"><input type="checkbox" id="c-41075929" checked=""/><div class="controls bullet"><span class="by">0xd1r</span><span>|</span><a href="#41075528">prev</a><span>|</span><a href="#41070738">next</a><span>|</span><label class="collapse" for="c-41075929">[-]</label><label class="expand" for="c-41075929">[2 more]</label></div><br/><div class="children"><div class="content">&gt; As part of our IMO work, we also experimented with a natural language reasoning system, built upon Gemini and our latest research to enable advanced problem-solving skills. This system doesn’t require the problems to be translated into a formal language and could be combined with other AI systems. We also tested this approach on this year’s IMO problems and the results showed great promise.<p>Wonder what &quot;great promise&quot; entails. Because it&#x27;s hard to imagine Gemini and other transformer-based models solving these problems with reasonable accuracy, as there is no elimination of hallucination. At least in the generally available products.</div><br/><div id="41076300" class="c"><input type="checkbox" id="c-41076300" checked=""/><div class="controls bullet"><span class="by">azeirah</span><span>|</span><a href="#41075929">parent</a><span>|</span><a href="#41070738">next</a><span>|</span><label class="collapse" for="c-41076300">[-]</label><label class="expand" for="c-41076300">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s what they mean.<p>They explicitly stated that to achieve the current results, they had to manually translate the problem statements into formal mathematical statements:<p>&gt; First, the problems were manually translated into formal mathematical language for our systems to understand.<p>How I understand what they&#x27;re saying is that they used gemini to translate the problem statement into formal mathematical language  and let DeepMath do it&#x27;s magic after that initial step.</div><br/></div></div></div></div><div id="41070738" class="c"><input type="checkbox" id="c-41070738" checked=""/><div class="controls bullet"><span class="by">robinhouston</span><span>|</span><a href="#41075929">prev</a><span>|</span><a href="#41070089">next</a><span>|</span><label class="collapse" for="c-41070738">[-]</label><label class="expand" for="c-41070738">[2 more]</label></div><br/><div class="children"><div class="content">Some more context is provided by Tim Gowers on Twitter [1].<p>Since I think you need an account to read threads now, here&#x27;s a transcript:<p>Google DeepMind have produced a program that in a certain sense has achieved a silver-medal peformance at this year&#x27;s International Mathematical Olympiad.<p>It did this by solving four of the six problems completely, which got it 28 points out of a possible total of 42. I&#x27;m not quite sure, but I think that put it ahead of all but around 60 competitors.<p>However, that statement needs a bit of qualifying.<p>The main qualification is that the program needed a lot longer than the human competitors -- for some of the problems over 60 hours -- and of course much faster processing speed than the poor old human brain.<p>If the human competitors had been allowed that sort of time per problem they would undoubtedly have scored higher.<p>Nevertheless, (i) this is well beyond what automatic theorem provers could do before, and (ii) these times are likely to come down as efficiency gains are made.<p>Another qualification is that the problems were manually translated into the proof assistant Lean, and only then did the program get to work. But the essential mathematics was done by the program: just the autoformalization part was done by humans.<p>As with AlphaGo, the program learnt to do what it did by teaching itself. But for that it needed a big collection of problems to work on. They achieved that in an interesting way: they took a huge database of IMO-type problems and got a large language model to formalize them.<p>However, LLMs are not able to autoformalize reliably, so they got them to autoformalize each problem many times. Some of the formalizations were correct, but even the incorrect ones were useful as training data, as often they were easier problems.<p>It&#x27;s not clear what the implications of this are for mathematical research. Since the method used was very general, there would seem to be no obvious obstacle to adapting it to other mathematical domains, apart perhaps from insufficient data.<p>So we might be close to having a program that would enable mathematicians to get answers to a wide range of questions, provided those questions weren&#x27;t <i>too</i> difficult -- the kind of thing one can do in a couple of hours.<p>That would be massively useful as a research tool, even if it wasn&#x27;t itself capable of solving open problems.<p>Are we close to the point where mathematicians are redundant? It&#x27;s hard to say. I would guess that we&#x27;re still a breakthrough or two short of that.<p>It will be interesting to see how the time the program takes scales as the difficulty of the problems it solves increases. If it scales with a similar ratio to that of a human mathematician, then we might have to get worried.<p>But if the function  human time taken --&gt; computer time taken   grows a lot faster than linearly, then more AI work will be needed.<p>The fact that the program takes as long as it does suggests that it hasn&#x27;t &quot;solved mathematics&quot;.<p>However, what it does is way beyond what a pure brute-force search would be capable of, so there is clearly something interesting going on when it operates. We&#x27;ll all have to watch this space.<p>1. <a href="https:&#x2F;&#x2F;x.com&#x2F;wtgowers&#x2F;status&#x2F;1816509803407040909?s=46" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;wtgowers&#x2F;status&#x2F;1816509803407040909?s=46</a></div><br/><div id="41071084" class="c"><input type="checkbox" id="c-41071084" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41070738">parent</a><span>|</span><a href="#41070089">next</a><span>|</span><label class="collapse" for="c-41071084">[-]</label><label class="expand" for="c-41071084">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If the human competitors had been allowed that sort of time per problem they would undoubtedly have scored higher.<p>Or if AlphaProof used more compute they could have slashed that time to 1&#x2F;10 or less. It&#x27;s arbitrary as long as we don&#x27;t define what is the compute the AI should be entitled to use here.</div><br/></div></div></div></div><div id="41070089" class="c"><input type="checkbox" id="c-41070089" checked=""/><div class="controls bullet"><span class="by">petters</span><span>|</span><a href="#41070738">prev</a><span>|</span><a href="#41071091">next</a><span>|</span><label class="collapse" for="c-41070089">[-]</label><label class="expand" for="c-41070089">[21 more]</label></div><br/><div class="children"><div class="content">The problems were first converted into a formal language. So they were partly solved by the AI</div><br/><div id="41070397" class="c"><input type="checkbox" id="c-41070397" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41070089">parent</a><span>|</span><a href="#41070171">next</a><span>|</span><label class="collapse" for="c-41070397">[-]</label><label class="expand" for="c-41070397">[7 more]</label></div><br/><div class="children"><div class="content">Formalization is in principle just a translation process and should be a much simpler problem than the actual IMO problem. Besides, they also trained a Gemini model which formalizes natural language problems, and this is how they generated training data for AlphaProof. I would therefore expect that they could have also formalized the IMO problems with that model and just did it manually because the point is not to demonstrate formalizing but instead proof capabilities.</div><br/><div id="41076010" class="c"><input type="checkbox" id="c-41076010" checked=""/><div class="controls bullet"><span class="by">petters</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41070397">parent</a><span>|</span><a href="#41071415">next</a><span>|</span><label class="collapse" for="c-41076010">[-]</label><label class="expand" for="c-41076010">[1 more]</label></div><br/><div class="children"><div class="content">If they could have solved it, they would have. But I agree that language models will be able to do it.</div><br/></div></div><div id="41071415" class="c"><input type="checkbox" id="c-41071415" checked=""/><div class="controls bullet"><span class="by">pishpash</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41070397">parent</a><span>|</span><a href="#41076010">prev</a><span>|</span><a href="#41070932">next</a><span>|</span><label class="collapse" for="c-41071415">[-]</label><label class="expand" for="c-41071415">[4 more]</label></div><br/><div class="children"><div class="content">Yet the facts at hand are the opposite of what you say. Reliable formalizer was the more difficult problem than solving formalized IMO problems, because they have not produced one.</div><br/><div id="41072819" class="c"><input type="checkbox" id="c-41072819" checked=""/><div class="controls bullet"><span class="by">fngjdflmdflg</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41071415">parent</a><span>|</span><a href="#41070932">next</a><span>|</span><label class="collapse" for="c-41072819">[-]</label><label class="expand" for="c-41072819">[3 more]</label></div><br/><div class="children"><div class="content">That does not necessarily follow from the facts at hand. For example they may have prioritized work on the proof solver itself as they may feel that that is the more important result. Alternatively if their goal is to build a proof solver then building the formalizer would be useless if they could not build the actual proof solver.</div><br/><div id="41073319" class="c"><input type="checkbox" id="c-41073319" checked=""/><div class="controls bullet"><span class="by">pishpash</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41072819">parent</a><span>|</span><a href="#41070932">next</a><span>|</span><label class="collapse" for="c-41073319">[-]</label><label class="expand" for="c-41073319">[2 more]</label></div><br/><div class="children"><div class="content">A proof solver existed. They were improving the proof solver explicitly by making the formalizer a part of the training. Formalizer reliability is the key novelty. It turns out it was only reliable enough for training. So unless they made the problem statement at the outset that &quot;we&#x27;ll only make the formalizer strong enough to train but not use&quot;, I disagree with that assessment.</div><br/><div id="41073503" class="c"><input type="checkbox" id="c-41073503" checked=""/><div class="controls bullet"><span class="by">fngjdflmdflg</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41073319">parent</a><span>|</span><a href="#41070932">next</a><span>|</span><label class="collapse" for="c-41073503">[-]</label><label class="expand" for="c-41073503">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a good point. The formalizer was used to created the training data for the proof solver, so they likely worked on it more than if they just used it as a preprocessing step during inference. It is still possible that they worked on the formalizer until they got good results from it enough to create good training data, and then began training as soon as possible and did not spend too much time trying to improve the formalizer. Depending on how long the training was expected to take, perhaps that is a reasonable assumption. Although I think I agree more with your view now.</div><br/></div></div></div></div></div></div></div></div><div id="41070932" class="c"><input type="checkbox" id="c-41070932" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41070397">parent</a><span>|</span><a href="#41071415">prev</a><span>|</span><a href="#41070171">next</a><span>|</span><label class="collapse" for="c-41070932">[-]</label><label class="expand" for="c-41070932">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Formalization is in principle just a translation process and should be a much simpler problem than the actual IMO problem<p>maybe not, because you need to connect many complicated topics&#x2F;terms&#x2F;definitions together, and you don&#x27;t have a way to reliably verify if formalized statement is correct.<p>They built automatic formalization network in this case, but didn&#x27;t trust it and formalized it manually.</div><br/></div></div></div></div><div id="41070171" class="c"><input type="checkbox" id="c-41070171" checked=""/><div class="controls bullet"><span class="by">jeremyjh</span><span>|</span><a href="#41070089">parent</a><span>|</span><a href="#41070397">prev</a><span>|</span><a href="#41071117">next</a><span>|</span><label class="collapse" for="c-41070171">[-]</label><label class="expand" for="c-41070171">[5 more]</label></div><br/><div class="children"><div class="content">Yes and it is difficult for me to believe that there is not useful human analysis and understanding involved in this translation that the AI is helpless without. But that I suppose is a problem that could be tackled with a different model...</div><br/><div id="41070325" class="c"><input type="checkbox" id="c-41070325" checked=""/><div class="controls bullet"><span class="by">adrianN</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41070171">parent</a><span>|</span><a href="#41073020">next</a><span>|</span><label class="collapse" for="c-41070325">[-]</label><label class="expand" for="c-41070325">[1 more]</label></div><br/><div class="children"><div class="content">Even so, having a human formalize the problems and an AI to find machine checkable proofs could be very useful for mathematicians.</div><br/></div></div><div id="41073020" class="c"><input type="checkbox" id="c-41073020" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41070171">parent</a><span>|</span><a href="#41070325">prev</a><span>|</span><a href="#41071117">next</a><span>|</span><label class="collapse" for="c-41073020">[-]</label><label class="expand" for="c-41073020">[3 more]</label></div><br/><div class="children"><div class="content">It is vastly easier to do the formalization than to actually solve the problem. Any undergraduate with some lean familiarity could do it in minutes.</div><br/><div id="41074015" class="c"><input type="checkbox" id="c-41074015" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41073020">parent</a><span>|</span><a href="#41071117">next</a><span>|</span><label class="collapse" for="c-41074015">[-]</label><label class="expand" for="c-41074015">[2 more]</label></div><br/><div class="children"><div class="content">Disagree! Some problems are much harder than others. If you don&#x27;t believe me please go formalize P5 in this year imo.</div><br/><div id="41074599" class="c"><input type="checkbox" id="c-41074599" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41074015">parent</a><span>|</span><a href="#41071117">next</a><span>|</span><label class="collapse" for="c-41074599">[-]</label><label class="expand" for="c-41074599">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I was just referring to the problems that it actually did.</div><br/></div></div></div></div></div></div></div></div><div id="41071117" class="c"><input type="checkbox" id="c-41071117" checked=""/><div class="controls bullet"><span class="by">trotro</span><span>|</span><a href="#41070089">parent</a><span>|</span><a href="#41070171">prev</a><span>|</span><a href="#41070344">next</a><span>|</span><label class="collapse" for="c-41071117">[-]</label><label class="expand" for="c-41071117">[2 more]</label></div><br/><div class="children"><div class="content">But formalization is the easy part for humans. I&#x27;m sure every mathematician would be be happy if the only thing required to prove a result was to formalize it in Lean and feed it to the AI to find the proof.</div><br/><div id="41074046" class="c"><input type="checkbox" id="c-41074046" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41071117">parent</a><span>|</span><a href="#41070344">next</a><span>|</span><label class="collapse" for="c-41074046">[-]</label><label class="expand" for="c-41074046">[1 more]</label></div><br/><div class="children"><div class="content">Not sure every mathematician would be happy to do this... it sounds much less pleasant than thinking. It&#x27;s like saying mathematicians would rather be programmers lol. It&#x27;s a significant difficult problem which i believe should be left completely to AI. Human formalization should become dead</div><br/></div></div></div></div><div id="41070344" class="c"><input type="checkbox" id="c-41070344" checked=""/><div class="controls bullet"><span class="by">clbrmbr</span><span>|</span><a href="#41070089">parent</a><span>|</span><a href="#41071117">prev</a><span>|</span><a href="#41070276">next</a><span>|</span><label class="collapse" for="c-41070344">[-]</label><label class="expand" for="c-41070344">[3 more]</label></div><br/><div class="children"><div class="content">IIUC, a Gemini-based system could translate the natural language questions into Lean, but in the blog post they don’t really commit to whether this was done just to generate training data or was used in the competition.</div><br/><div id="41076348" class="c"><input type="checkbox" id="c-41076348" checked=""/><div class="controls bullet"><span class="by">cygaril</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41070344">parent</a><span>|</span><a href="#41071052">next</a><span>|</span><label class="collapse" for="c-41076348">[-]</label><label class="expand" for="c-41076348">[1 more]</label></div><br/><div class="children"><div class="content">Formalizations for the competition were done by hand.</div><br/></div></div></div></div><div id="41070276" class="c"><input type="checkbox" id="c-41070276" checked=""/><div class="controls bullet"><span class="by">rpois</span><span>|</span><a href="#41070089">parent</a><span>|</span><a href="#41070344">prev</a><span>|</span><a href="#41071091">next</a><span>|</span><label class="collapse" for="c-41070276">[-]</label><label class="expand" for="c-41070276">[3 more]</label></div><br/><div class="children"><div class="content">Does this formalization process include giving it the answer it should try to prove?</div><br/><div id="41070399" class="c"><input type="checkbox" id="c-41070399" checked=""/><div class="controls bullet"><span class="by">Smaug123</span><span>|</span><a href="#41070089">root</a><span>|</span><a href="#41070276">parent</a><span>|</span><a href="#41070410">next</a><span>|</span><label class="collapse" for="c-41070399">[-]</label><label class="expand" for="c-41070399">[1 more]</label></div><br/><div class="children"><div class="content">Nope, per Oliver Nash who worked on the thing: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41070372">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41070372</a></div><br/></div></div></div></div></div></div><div id="41071091" class="c"><input type="checkbox" id="c-41071091" checked=""/><div class="controls bullet"><span class="by">gallerdude</span><span>|</span><a href="#41070089">prev</a><span>|</span><a href="#41070541">next</a><span>|</span><label class="collapse" for="c-41071091">[-]</label><label class="expand" for="c-41071091">[3 more]</label></div><br/><div class="children"><div class="content">Sometimes I wonder if in 100 years, it&#x27;s going to be surprising to people that computers had a use before AI...</div><br/><div id="41074280" class="c"><input type="checkbox" id="c-41074280" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41071091">parent</a><span>|</span><a href="#41073378">next</a><span>|</span><label class="collapse" for="c-41074280">[-]</label><label class="expand" for="c-41074280">[1 more]</label></div><br/><div class="children"><div class="content">AI is simply another form of what we&#x27;ve been doing since the dawn of computers: expressing real world problems in the form of computations.<p>While there are certainly some huge jumps in compute power, theory of data transformation and availability of data to transform, it would surprise me if computers in a 100 years do not still rely on a combination of well-defined and well-understood algorithms and AI-inspired tools that do the same thing but on a much bigger scale.<p>If not for any other reason, then because there are so many things where you can easily produce a great, always correct result simply by doing very precise, obvious and simple computation.<p>We&#x27;ve had computers and digital devices for a long while now, yet we still rely heavily on mechanical contraptions.  Sure, we improve them with computers (eg. think brushless motors), but I don&#x27;t think anyone would be surprised today about how did anyone design these same devices (hair dryers, lawn mowers, internal combustion engines...) before computers?</div><br/></div></div><div id="41073378" class="c"><input type="checkbox" id="c-41073378" checked=""/><div class="controls bullet"><span class="by">onemoresoop</span><span>|</span><a href="#41071091">parent</a><span>|</span><a href="#41074280">prev</a><span>|</span><a href="#41070541">next</a><span>|</span><label class="collapse" for="c-41073378">[-]</label><label class="expand" for="c-41073378">[1 more]</label></div><br/><div class="children"><div class="content">If AI stays in the computer form though..</div><br/></div></div></div></div><div id="41070541" class="c"><input type="checkbox" id="c-41070541" checked=""/><div class="controls bullet"><span class="by">majikaja</span><span>|</span><a href="#41071091">prev</a><span>|</span><a href="#41075492">next</a><span>|</span><label class="collapse" for="c-41070541">[-]</label><label class="expand" for="c-41070541">[10 more]</label></div><br/><div class="children"><div class="content">It would be nice if on the page they included detailed descriptions of the proofs it came up with, more information about the capabilities of the system and insights into the training process...<p>If the data is synthetic and covers a limited class of problems I would imagine what it&#x27;s doing mostly reduces to some basic search pattern heuristics which would be of more value to understand than just being told it can solve a few problems in three days.</div><br/><div id="41070747" class="c"><input type="checkbox" id="c-41070747" checked=""/><div class="controls bullet"><span class="by">cygaril</span><span>|</span><a href="#41070541">parent</a><span>|</span><a href="#41075492">next</a><span>|</span><label class="collapse" for="c-41070747">[-]</label><label class="expand" for="c-41070747">[9 more]</label></div><br/><div class="children"><div class="content">Proofs are here: <a href="https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;DeepMind.com&#x2F;Blog&#x2F;imo-2024-solutions&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;storage.googleapis.com&#x2F;deepmind-media&#x2F;DeepMind.com&#x2F;B...</a></div><br/><div id="41070956" class="c"><input type="checkbox" id="c-41070956" checked=""/><div class="controls bullet"><span class="by">majikaja</span><span>|</span><a href="#41070541">root</a><span>|</span><a href="#41070747">parent</a><span>|</span><a href="#41075492">next</a><span>|</span><label class="collapse" for="c-41070956">[-]</label><label class="expand" for="c-41070956">[8 more]</label></div><br/><div class="children"><div class="content">I found those, I just would have appreciated if the content of the mathematics wasn&#x27;t sidelined to a separate download as if it&#x27;s not important.
I felt the explanation on the page was shallow, as if they just want people to accept it&#x27;s a black box.<p>All I&#x27;ve learnt from this is that they used an unstated amount of computational resources just to basically brute force what a human already is capable of doing in far less time.</div><br/><div id="41071282" class="c"><input type="checkbox" id="c-41071282" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070541">root</a><span>|</span><a href="#41070956">parent</a><span>|</span><a href="#41075492">next</a><span>|</span><label class="collapse" for="c-41071282">[-]</label><label class="expand" for="c-41071282">[7 more]</label></div><br/><div class="children"><div class="content">Very few humans can after years of training. Please don&#x27;t trivialize.</div><br/><div id="41074315" class="c"><input type="checkbox" id="c-41074315" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41070541">root</a><span>|</span><a href="#41071282">parent</a><span>|</span><a href="#41075154">next</a><span>|</span><label class="collapse" for="c-41074315">[-]</label><label class="expand" for="c-41074315">[4 more]</label></div><br/><div class="children"><div class="content">Very few humans go after this type of the training. In my &quot;math talent&quot; school (most of the Serbian&#x2F;Yugoslavian medal winners came from it), at most a dozen students &quot;trained&quot; for this over 4 high school generations (500 students).<p>Problems are certainly not trivial, but humans are not really putting all their effort into it either, and the few that do train for it, on average medal 50% of the time and get a silver or better 25% of the time (by design) with much less time available to do the problems.</div><br/><div id="41074637" class="c"><input type="checkbox" id="c-41074637" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070541">root</a><span>|</span><a href="#41074315">parent</a><span>|</span><a href="#41075154">next</a><span>|</span><label class="collapse" for="c-41074637">[-]</label><label class="expand" for="c-41074637">[3 more]</label></div><br/><div class="children"><div class="content">This is disingenuous. People who train are already self selected people who are talented in math. And in the people who train not everyone gets to this level. Sadly i speak from personal experience.</div><br/><div id="41074953" class="c"><input type="checkbox" id="c-41074953" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#41070541">root</a><span>|</span><a href="#41074637">parent</a><span>|</span><a href="#41075154">next</a><span>|</span><label class="collapse" for="c-41074953">[-]</label><label class="expand" for="c-41074953">[2 more]</label></div><br/><div class="children"><div class="content">This school is full of people talented at math — you can&#x27;t get in if you don&#x27;t pass a special math exam (looking at the list, out of Serbia&#x27;s 16 gold medals, I can see 14 went to students of this school, and numerous silver and bronzes too — Serbia participates as an independent country since 2006 with a population of roughly 7M, if you want to compare it with other countries on the IMO medal table).  So in general, out of this small pool (10 talented and motivated people out of 4 generations), Serbia could get a gold medal winner on average almost once every year.  I am sure there were other equally talented mathematicians among the 490 students that did not train for the competition (and some have achieved more academic success later on).<p>Most students were simply not interested. And certainly, not everybody is equally talented, but the motivation to achieve competition success is needed too — perhaps you had the latter but not enough of the former. I also believe competitive maths is entirely different from research maths (time pressure, even luck is involved for a good idea to come up quickly, etc). Since you said you were a potential bronze medal winner, it might not even be a talent issue but maybe you just had great competition and someone had the better luck in one or two tests to rank above you (better luck as in the right idea&#x2F;approach came to them quicker, or the type of problem that appeared on the test suited them more). And if you are from a large country like USA, China or Russia (topping the medal table), it&#x27;s going to be freaking hard to get into a team since you&#x27;ll have so many worthy students (and the fact they are not always scoring only golds for their teams out of such large pools tells me that the performance is not deterministic).<p>As a mathematician, I am sure you&#x27;d agree you&#x27;d want to run a lot more than a dozen tests to establish statistical significance for any ranking between two people at competitive maths IMO style, esp if they are close in the first few.  As an anecdote, many at my school participated in national level maths and informatics competitions (they start at school level, go on to county&#x2F;city level to nation level) — other than the few &quot;trained&quot; competitors staying at the top, the rest of the group mostly rotated in the other spots below them regardless of the level (school&#x2F;county&#x2F;nation). We&#x27;ve actually joked amongst ourselves about who had the better intuition &quot;this time around&quot; for a problem or two, while still beating the rest of the country handily (we&#x27;ve obviously had better base level of education + decently high base talent), but not coming close to &quot;competitors&quot;.<p>I, for instance, never enjoyed working through math problems and math competitions (after winning a couple of early age local ones): I&#x27;ve finished the equivalent of math + CS MSc while skipping classes by only learning theory (reading through axioms, theorems and proofs that seemed non-obvious) and using that to solve problems in exams.  I&#x27;ve mostly enjoyed building things with the acquired knowledge (including my own proofs on the spot, but mostly programming), even though I understood that you build up speed with more practice (I was also lazy :)).<p>So, let&#x27;s not trivialize solving IMO-style problems, but let&#x27;s not put them on a pedestal either. Out of a very small pool of people who train for it, many score higher than AI did here, and they don&#x27;t predict future theoretical math performance either. Competition performance mostly predicts competition performance, but even that with large error bars.</div><br/></div></div></div></div></div></div><div id="41075154" class="c"><input type="checkbox" id="c-41075154" checked=""/><div class="controls bullet"><span class="by">majikaja</span><span>|</span><a href="#41070541">root</a><span>|</span><a href="#41071282">parent</a><span>|</span><a href="#41074315">prev</a><span>|</span><a href="#41075492">next</a><span>|</span><label class="collapse" for="c-41075154">[-]</label><label class="expand" for="c-41075154">[2 more]</label></div><br/><div class="children"><div class="content">To mathematicians the problems are basically easy (at least after a few weeks of extra training) and after having seen all the other AI advances lately I don&#x27;t think it&#x27;s surprising that with huge amounts of computing resources one can &#x27;search&#x27; for a solution.</div><br/><div id="41075754" class="c"><input type="checkbox" id="c-41075754" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41070541">root</a><span>|</span><a href="#41075154">parent</a><span>|</span><a href="#41075492">next</a><span>|</span><label class="collapse" for="c-41075754">[-]</label><label class="expand" for="c-41075754">[1 more]</label></div><br/><div class="children"><div class="content">Sorry that&#x27;s wrong. I have a math phd and i trained for Olympiads in high school. These problems are not easy for me at all. Maybe for top mathematicians who used to compete.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41075492" class="c"><input type="checkbox" id="c-41075492" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#41070541">prev</a><span>|</span><a href="#41072611">next</a><span>|</span><label class="collapse" for="c-41075492">[-]</label><label class="expand" for="c-41075492">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The system was allowed unlimited time; for some problems it took up to three days. The students were allotted only 4.5 hours per exam.<p>I know speed is just a matter of engineering, but looks like we still have a ways to go. Hold the gong...</div><br/></div></div><div id="41072611" class="c"><input type="checkbox" id="c-41072611" checked=""/><div class="controls bullet"><span class="by">dan_mctree</span><span>|</span><a href="#41075492">prev</a><span>|</span><a href="#41075911">next</a><span>|</span><label class="collapse" for="c-41072611">[-]</label><label class="expand" for="c-41072611">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious if we&#x27;ll see a world where computers could solve math problems so easily, that we&#x27;ll be overwhelmed by all the results and stop caring. The role of humans might change to asking the computer interesting questions that we care about.</div><br/><div id="41075597" class="c"><input type="checkbox" id="c-41075597" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#41072611">parent</a><span>|</span><a href="#41072710">next</a><span>|</span><label class="collapse" for="c-41075597">[-]</label><label class="expand" for="c-41075597">[1 more]</label></div><br/><div class="children"><div class="content">The next step will be having an AI come up with the problems.</div><br/></div></div><div id="41072710" class="c"><input type="checkbox" id="c-41072710" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#41072611">parent</a><span>|</span><a href="#41075597">prev</a><span>|</span><a href="#41072680">next</a><span>|</span><label class="collapse" for="c-41072710">[-]</label><label class="expand" for="c-41072710">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure what stop caring really means - like stop caring about the result, or the implications?</div><br/></div></div><div id="41072680" class="c"><input type="checkbox" id="c-41072680" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41072611">parent</a><span>|</span><a href="#41072710">prev</a><span>|</span><a href="#41075911">next</a><span>|</span><label class="collapse" for="c-41072680">[-]</label><label class="expand" for="c-41072680">[1 more]</label></div><br/><div class="children"><div class="content">I think mathematicians will still care</div><br/></div></div></div></div><div id="41075911" class="c"><input type="checkbox" id="c-41075911" checked=""/><div class="controls bullet"><span class="by">__0x01</span><span>|</span><a href="#41072611">prev</a><span>|</span><a href="#41072168">next</a><span>|</span><label class="collapse" for="c-41075911">[-]</label><label class="expand" for="c-41075911">[1 more]</label></div><br/><div class="children"><div class="content">Please could someone explain, very simply, what the training data was composed of?</div><br/></div></div><div id="41072168" class="c"><input type="checkbox" id="c-41072168" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#41075911">prev</a><span>|</span><a href="#41070139">next</a><span>|</span><label class="collapse" for="c-41072168">[-]</label><label class="expand" for="c-41072168">[4 more]</label></div><br/><div class="children"><div class="content">To what extent is the training and structure of AlphaProof tailored specifically to IMO-type problems, which typically have short solutions using combinations of a small handful of specific techniques?<p>(It&#x27;s not my main point, but it&#x27;s always worth remembering - even aside from any AI context - that many top mathematicians can&#x27;t do IMO-type problems, and many top IMO medalists turn out to be unable to solve actual problems in research mathematics. IMO problems are generally regarded as somewhat niche.)</div><br/><div id="41072740" class="c"><input type="checkbox" id="c-41072740" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41072168">parent</a><span>|</span><a href="#41070139">next</a><span>|</span><label class="collapse" for="c-41072740">[-]</label><label class="expand" for="c-41072740">[3 more]</label></div><br/><div class="children"><div class="content">The last statement is largely correct (though idk what  the imo medalists that are unable to solve actual problems most mathematicians can&#x27;t solve most open problems). But i kind of disagree with the assessment of imo problems--the search space is huge if it were as you say it would be easy to search.</div><br/><div id="41072904" class="c"><input type="checkbox" id="c-41072904" checked=""/><div class="controls bullet"><span class="by">nybsjytm</span><span>|</span><a href="#41072168">root</a><span>|</span><a href="#41072740">parent</a><span>|</span><a href="#41070139">next</a><span>|</span><label class="collapse" for="c-41072904">[-]</label><label class="expand" for="c-41072904">[2 more]</label></div><br/><div class="children"><div class="content">No, I don&#x27;t mean that the search space is small. I just mean that there are special techniques which are highly relevant for IMO-type problems. It&#x27;d be interesting to know how important that knowledge was for the design and training of AlphaProof.<p>In other words, how does AlphaProof fare on mathematical problems which aren&#x27;t in the IMO style? (As such exceptions comprise most mathematical problems)</div><br/><div id="41073537" class="c"><input type="checkbox" id="c-41073537" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41072168">root</a><span>|</span><a href="#41072904">parent</a><span>|</span><a href="#41070139">next</a><span>|</span><label class="collapse" for="c-41073537">[-]</label><label class="expand" for="c-41073537">[1 more]</label></div><br/><div class="children"><div class="content">Probably less well? They rely heavily on the dataset of existing problems</div><br/></div></div></div></div></div></div></div></div><div id="41070139" class="c"><input type="checkbox" id="c-41070139" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#41072168">prev</a><span>|</span><a href="#41071508">next</a><span>|</span><label class="collapse" for="c-41070139">[-]</label><label class="expand" for="c-41070139">[2 more]</label></div><br/><div class="children"><div class="content">See <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Automated_Mathematician" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Automated_Mathematician</a> for an early system that seems similar in some way.</div><br/><div id="41070440" class="c"><input type="checkbox" id="c-41070440" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#41070139">parent</a><span>|</span><a href="#41071508">next</a><span>|</span><label class="collapse" for="c-41070440">[-]</label><label class="expand" for="c-41070440">[1 more]</label></div><br/><div class="children"><div class="content">This Wikipedia page makes AM kind of comes across as a nonsense project whose outputs no one (besides the author) bothered to decipher.</div><br/></div></div></div></div><div id="41071508" class="c"><input type="checkbox" id="c-41071508" checked=""/><div class="controls bullet"><span class="by">HL33tibCe7</span><span>|</span><a href="#41070139">prev</a><span>|</span><a href="#41069994">next</a><span>|</span><label class="collapse" for="c-41071508">[-]</label><label class="expand" for="c-41071508">[1 more]</label></div><br/><div class="children"><div class="content">This is kind of an ideal use-case for AI, because we can say with absolute certainty whether their solution is correct, completely eliminating the problem of hallucination.</div><br/></div></div><div id="41069994" class="c"><input type="checkbox" id="c-41069994" checked=""/><div class="controls bullet"><span class="by">arnabgho</span><span>|</span><a href="#41071508">prev</a><span>|</span><a href="#41070172">next</a><span>|</span><label class="collapse" for="c-41069994">[-]</label><label class="expand" for="c-41069994">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;x.com&#x2F;GoogleDeepMind&#x2F;status&#x2F;1816498082860667086" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;GoogleDeepMind&#x2F;status&#x2F;1816498082860667086</a></div><br/></div></div><div id="41070172" class="c"><input type="checkbox" id="c-41070172" checked=""/><div class="controls bullet"><span class="by">osti</span><span>|</span><a href="#41069994">prev</a><span>|</span><a href="#41074866">next</a><span>|</span><label class="collapse" for="c-41070172">[-]</label><label class="expand" for="c-41070172">[1 more]</label></div><br/><div class="children"><div class="content">So they weren&#x27;t able to solve the combinatorics problem. I&#x27;m not super well versed in competition math, but combinatorics always seem to be the most interesting problems to me.</div><br/></div></div><div id="41074866" class="c"><input type="checkbox" id="c-41074866" checked=""/><div class="controls bullet"><span class="by">imranhou</span><span>|</span><a href="#41070172">prev</a><span>|</span><label class="collapse" for="c-41074866">[-]</label><label class="expand" for="c-41074866">[1 more]</label></div><br/><div class="children"><div class="content">If the system took 3 days to solve a problem, how different is this approach than a bruteforce attempt at the problem with educated guesses? Thats not reasoning in my mind.</div><br/></div></div></div></div></div></div></div></body></html>