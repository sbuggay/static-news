<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1723971667778" as="style"/><link rel="stylesheet" href="styles.css?v=1723971667778"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://motherduck.com/blog/pg_duckdb-postgresql-extension-for-duckdb-motherduck/">pg_duckdb: Splicing Duck and Elephant DNA</a> <span class="domain">(<a href="https://motherduck.com">motherduck.com</a>)</span></div><div class="subtext"><span>jonbaer</span> | <span>14 comments</span></div><br/><div><div id="41279882" class="c"><input type="checkbox" id="c-41279882" checked=""/><div class="controls bullet"><span class="by">leetrout</span><span>|</span><a href="#41279305">next</a><span>|</span><label class="collapse" for="c-41279882">[-]</label><label class="expand" for="c-41279882">[2 more]</label></div><br/><div class="children"><div class="content">If &#x2F; as we move to analytic workloads it would be awesome to see postgres pickup support for AsOf, time_bucket, etc that duckdb and timescale have.<p>I don&#x27;t and never have enjoyed SQL and I much prefer the ergonomics of time_bucket to date_bin.<p>For example, I would do this in duckdb:<p><pre><code>  SELECT
    count(*) as y
    , time_bucket(interval &#x27;2 weeks&#x27;, at::timestamp) as x
  FROM analytics
  WHERE some_bool AND some_haystack = &#x27;needle&#x27;
  GROUP BY x
  ORDER BY x
</code></pre>
In postgres it looks more like:<p><pre><code>  with counts as (
    SELECT 
        date_bin(&#x27;1 hour&#x27;::interval, at, (now() - interval &#x27;2 weeks&#x27;)::timestamp)
        , count(*) c
    FROM analytics a
    WHERE some_bool AND some_haystack = &#x27;needle&#x27;
    GROUP BY date_bin
  )
  select series as x, coalesce(counts.c, 0) as y
  from generate_series(
    (now() - interval &#x27;2 weeks&#x27;)::timestamp, 
    now()::timestamp,
    interval &#x27;1 hour&#x27;
  ) series
  LEFT JOIN counts
  ON counts.date_bin = series;</code></pre></div><br/><div id="41280597" class="c"><input type="checkbox" id="c-41280597" checked=""/><div class="controls bullet"><span class="by">wuputah</span><span>|</span><a href="#41279882">parent</a><span>|</span><a href="#41279305">next</a><span>|</span><label class="collapse" for="c-41280597">[-]</label><label class="expand" for="c-41280597">[1 more]</label></div><br/><div class="children"><div class="content">I think it will be straightforward to expose time_bucket in pg_duckdb. Feel free to open an issue for the feature.</div><br/></div></div></div></div><div id="41279305" class="c"><input type="checkbox" id="c-41279305" checked=""/><div class="controls bullet"><span class="by">craigkerstiens</span><span>|</span><a href="#41279882">prev</a><span>|</span><a href="#41277796">next</a><span>|</span><label class="collapse" for="c-41279305">[-]</label><label class="expand" for="c-41279305">[4 more]</label></div><br/><div class="children"><div class="content">Very much agreed with this general idea, and believe a lot of this was inspired by the team we hired at Crunchy Data to build it as they were socializing it for a while. Looking forward to pg_duckdb advancing in time for now it still seems pretty early and has some maturing to do. As others have said, it needs to be a bit more stable and production grade. But the opportunity is very much there.<p>We recently submitted our (Crunchy Bridge for Analytics-at most broad level based on same idea) benchmark for clickbench by clickhouse (<a href="https:&#x2F;&#x2F;benchmark.clickhouse.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;benchmark.clickhouse.com&#x2F;</a>) which puts us at #6 overall amongst managed service providers and gives a real viable option for Postgres as an analytics database (at least per clickbench). Also of note there are a number of other Postgres variations such as ParadeDB that are definitely not 1000x slower than Clickhouse or DuckDB.</div><br/><div id="41280317" class="c"><input type="checkbox" id="c-41280317" checked=""/><div class="controls bullet"><span class="by">coatue</span><span>|</span><a href="#41279305">parent</a><span>|</span><a href="#41279620">next</a><span>|</span><label class="collapse" for="c-41280317">[-]</label><label class="expand" for="c-41280317">[1 more]</label></div><br/><div class="children"><div class="content">Hey Craig, for the public record- pg_duckdb was not inspired by the team at Crunchy Data. Our early mvp version, &quot;pg_quack&quot; was made public (apache 2.0) on February 2nd. About 2 months later, Crunchy&#x27;s analytics product shipped on April 30th. If you were working on it around a similar time it was a coincidence. Let&#x27;s call it great minds think alike.</div><br/></div></div><div id="41279620" class="c"><input type="checkbox" id="c-41279620" checked=""/><div class="controls bullet"><span class="by">leetrout</span><span>|</span><a href="#41279305">parent</a><span>|</span><a href="#41280317">prev</a><span>|</span><a href="#41280153">next</a><span>|</span><label class="collapse" for="c-41279620">[-]</label><label class="expand" for="c-41279620">[1 more]</label></div><br/><div class="children"><div class="content">I just did a project for a YC startup and we reverted to postgres from duckdb+sqlite for concerns enterprises might not see the local file combo as mature &#x2F; professional.<p>Really excited about the idea of being able to have everything under the postgres umbrella even with sacrifices.<p>From the engineering side I have nothing but good things to say about duckdb.<p>I opened up the database to the frontend (it&#x27;s an internal reporting tool not unlike grafana and I filtered queries through an allowlist) and it was pure delight to have the metrics queries right next to the graph. Very rapid iterations.</div><br/></div></div><div id="41280153" class="c"><input type="checkbox" id="c-41280153" checked=""/><div class="controls bullet"><span class="by">nikita</span><span>|</span><a href="#41279305">parent</a><span>|</span><a href="#41279620">prev</a><span>|</span><a href="#41277796">next</a><span>|</span><label class="collapse" for="c-41280153">[-]</label><label class="expand" for="c-41280153">[1 more]</label></div><br/><div class="children"><div class="content">Are you guys planning to opensource your work at crunchy?</div><br/></div></div></div></div><div id="41277796" class="c"><input type="checkbox" id="c-41277796" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#41279305">prev</a><span>|</span><a href="#41279557">next</a><span>|</span><label class="collapse" for="c-41277796">[-]</label><label class="expand" for="c-41277796">[1 more]</label></div><br/><div class="children"><div class="content">Would be helpful to list the features. This link has the details:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;duckdb&#x2F;pg_duckdb">https:&#x2F;&#x2F;github.com&#x2F;duckdb&#x2F;pg_duckdb</a><p>Sounds like it would be useful for Postgres users to interact with Parquet and CSV data within a single SQL query and in a performant way (due to DuckDB&#x27;s vectorization).</div><br/></div></div><div id="41279557" class="c"><input type="checkbox" id="c-41279557" checked=""/><div class="controls bullet"><span class="by">netcraft</span><span>|</span><a href="#41277796">prev</a><span>|</span><a href="#41278618">next</a><span>|</span><label class="collapse" for="c-41279557">[-]</label><label class="expand" for="c-41279557">[1 more]</label></div><br/><div class="children"><div class="content">this looks awesome, I cant wait to play with it!
we need to get this into RDS as soon as we can</div><br/></div></div><div id="41278618" class="c"><input type="checkbox" id="c-41278618" checked=""/><div class="controls bullet"><span class="by">nikita</span><span>|</span><a href="#41279557">prev</a><span>|</span><a href="#41279258">next</a><span>|</span><label class="collapse" for="c-41278618">[-]</label><label class="expand" for="c-41278618">[3 more]</label></div><br/><div class="children"><div class="content">Postgres IS missing an analytics engine. benchmark.clickhouse.com puts it at the bottom of the list and ~1000x slower than @duckdb and @ClickHouseDB.<p>Here are the scenarios and how to address them<p>1. Query Parquet and Iceberg from Postgres. When  Parquet files are stored in S3 Postgres should be able to  run analytical queries on them.<p>2. Postgres should allow creation of columnstore tables inside Postgres storage subsystem. Analytical queries on top of these table should be FAST. Top 10 on Clickbench fast. This allows to run analytics without S3 and have super low latencies for analytics.<p>3. Postgres should allow creation of secondary columnstore indexes to speed up analytical queries in mixed workloads. This is super useful for Oracle migrations since Oracle had this feature for a while.<p>So How do we get there? 10 years ago it would be a MASSIVE project, but today we have @duckdb - super fast analytical engine with an open license. The work is still not trivial, but it is much much simpler.<p>First you need to integrate an analytical query processor into Postgres and today @duckdblabs announced github.com&#x2F;duckdb&#x2F;pg_duck…. Yay and congrats!<p>This plugin runs duckdb alongside with Postgres and integrated Postgres syntax with the @duckdb query processor (QP)<p>With that it now can trivially query external files from S3. This addresses scenario 1.<p>With that it now can trivially query external files from S3. This addresses scenario 1.<p>Building columnar table requires either implementing columnar storage from scratch or integrating duckdb storage into the Postgres subsystem. You can of course let duckdb create duckdb files on local disk, but then all the Postgres machinery: replication, backup, recovery won&#x27;t work<p>Duckdb tables have to mapped into 8kb Postgres pages pushed through the Postgres WAL for replication, recovery and transactionality. This will give us scenario 2<p>Scenario 3 is even more work. You need secondary index maintenance and it will require hybrid query execution. We will need to modify Postgres executor so that it can mix and match regular Postgres query operators and &quot;vectorized&quot; query operators from duckdb. Or built vectorized operators into Postgres<p>Scenarios 2 and 3 will take some time, but I&#x27;m excited for this roadmap: this will unlock a huge world for millions of  Postgres users and simplify the lives of many developers dealing with moving data between transactional and analytical systems.</div><br/><div id="41278692" class="c"><input type="checkbox" id="c-41278692" checked=""/><div class="controls bullet"><span class="by">jerrysievert</span><span>|</span><a href="#41278618">parent</a><span>|</span><a href="#41279894">next</a><span>|</span><label class="collapse" for="c-41278692">[-]</label><label class="expand" for="c-41278692">[1 more]</label></div><br/><div class="children"><div class="content">re: columnar - <a href="https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;tree&#x2F;main&#x2F;columnar">https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;tree&#x2F;main&#x2F;columnar</a><p>a much updated fork of citus&#x27; columnar using Postgres tableam.<p>re: duckdb handling storage - <a href="https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;pg_quack&#x2F;tree&#x2F;branch-0.0.1">https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;pg_quack&#x2F;tree&#x2F;branch-0.0.1</a><p>an earlier implementation</div><br/></div></div><div id="41279894" class="c"><input type="checkbox" id="c-41279894" checked=""/><div class="controls bullet"><span class="by">leetrout</span><span>|</span><a href="#41278618">parent</a><span>|</span><a href="#41278692">prev</a><span>|</span><a href="#41279258">next</a><span>|</span><label class="collapse" for="c-41279894">[-]</label><label class="expand" for="c-41279894">[1 more]</label></div><br/><div class="children"><div class="content">I would be all about hive partitioning for postgresified tables, too.<p><a href="https:&#x2F;&#x2F;duckdb.org&#x2F;docs&#x2F;data&#x2F;partitioning&#x2F;hive_partitioning.html" rel="nofollow">https:&#x2F;&#x2F;duckdb.org&#x2F;docs&#x2F;data&#x2F;partitioning&#x2F;hive_partitioning....</a></div><br/></div></div></div></div><div id="41279258" class="c"><input type="checkbox" id="c-41279258" checked=""/><div class="controls bullet"><span class="by">timenova</span><span>|</span><a href="#41278618">prev</a><span>|</span><label class="collapse" for="c-41279258">[-]</label><label class="expand" for="c-41279258">[2 more]</label></div><br/><div class="children"><div class="content">Looking forward to this getting supported on Neon!</div><br/><div id="41279287" class="c"><input type="checkbox" id="c-41279287" checked=""/><div class="controls bullet"><span class="by">nikita</span><span>|</span><a href="#41279258">parent</a><span>|</span><label class="collapse" for="c-41279287">[-]</label><label class="expand" for="c-41279287">[1 more]</label></div><br/><div class="children"><div class="content">Very soon, it needs to get a bit more stable.</div><br/></div></div></div></div></div></div></div></div></div></body></html>