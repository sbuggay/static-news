<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1738400470282" as="style"/><link rel="stylesheet" href="styles.css?v=1738400470282"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blogs.windows.com/windowsdeveloper/2025/01/29/running-distilled-deepseek-r1-models-locally-on-copilot-pcs-powered-by-windows-copilot-runtime/">Running DeepSeek R1 Models Locally on NPU</a>Â <span class="domain">(<a href="https://blogs.windows.com">blogs.windows.com</a>)</span></div><div class="subtext"><span>doomroot13</span> | <span>5 comments</span></div><br/><div><div id="42896624" class="c"><input type="checkbox" id="c-42896624" checked=""/><div class="controls bullet"><span class="by">jokowueu</span><span>|</span><a href="#42896812">next</a><span>|</span><label class="collapse" for="c-42896624">[-]</label><label class="expand" for="c-42896624">[1 more]</label></div><br/><div class="children"><div class="content">How much are NPUs more efficient than GPUs ? What are the limitations , it seems it will have support for deepseek R1 soon</div><br/></div></div><div id="42896812" class="c"><input type="checkbox" id="c-42896812" checked=""/><div class="controls bullet"><span class="by">RandomBK</span><span>|</span><a href="#42896624">prev</a><span>|</span><label class="collapse" for="c-42896812">[-]</label><label class="expand" for="c-42896812">[3 more]</label></div><br/><div class="children"><div class="content">Reminder: DeepSeek distilled models are better thought of as fine-tunes of Qwen&#x2F;Llama using DeepSeek output, and are not the same as actual DeepSeek v3 or R1.<p>This unfortunate naming has sown plenty of confusion around DeepSeek&#x27;s quality and resource requirements. <i>Actual</i> DeepSeek v3&#x2F;R1 continues to require at least ~100GB of VRAM&#x2F;Mem&#x2F;SSD, and this does not change that.</div><br/><div id="42896891" class="c"><input type="checkbox" id="c-42896891" checked=""/><div class="controls bullet"><span class="by">darthrupert</span><span>|</span><a href="#42896812">parent</a><span>|</span><label class="collapse" for="c-42896891">[-]</label><label class="expand" for="c-42896891">[2 more]</label></div><br/><div class="children"><div class="content">Wait, what am I running on my 32GB Macbook then? I thought it was the 32b version of deepseek-r1.</div><br/><div id="42896978" class="c"><input type="checkbox" id="c-42896978" checked=""/><div class="controls bullet"><span class="by">Plankaluel</span><span>|</span><a href="#42896812">root</a><span>|</span><a href="#42896891">parent</a><span>|</span><label class="collapse" for="c-42896978">[-]</label><label class="expand" for="c-42896978">[1 more]</label></div><br/><div class="children"><div class="content">You are running Qwen2.5 32b that has been fine tuned on data that was generated by R1</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>