<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1694077262812" as="style"/><link rel="stylesheet" href="styles.css?v=1694077262812"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/pdtpartners/nix-snapshotter">Show HN: Nix Snapshotter – Native understanding of Nix packages for containerd</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>hinshun</span> | <span>32 comments</span></div><br/><div><div id="37412675" class="c"><input type="checkbox" id="c-37412675" checked=""/><div class="controls bullet"><span class="by">georgyo</span><span>|</span><a href="#37412013">next</a><span>|</span><label class="collapse" for="c-37412675">[-]</label><label class="expand" for="c-37412675">[2 more]</label></div><br/><div class="children"><div class="content">This is one of the most interesting Nix tools I&#x27;ve seen in awhile!<p>Nix is a fantastic tool for building isolated work artifacts, but not the greatest for actually scheduling work across a fleet of machines.<p>This combines both worlds, I hope this succeeds and gains adoption!</div><br/><div id="37412972" class="c"><input type="checkbox" id="c-37412972" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37412675">parent</a><span>|</span><a href="#37412013">next</a><span>|</span><label class="collapse" for="c-37412972">[-]</label><label class="expand" for="c-37412972">[1 more]</label></div><br/><div class="children"><div class="content">Thank you! We appreciate it.</div><br/></div></div></div></div><div id="37412013" class="c"><input type="checkbox" id="c-37412013" checked=""/><div class="controls bullet"><span class="by">flurie</span><span>|</span><a href="#37412675">prev</a><span>|</span><a href="#37415833">next</a><span>|</span><label class="collapse" for="c-37412013">[-]</label><label class="expand" for="c-37412013">[6 more]</label></div><br/><div class="children"><div class="content">This looks a lot like Nixery[1]. Can you explain how they differ?<p>[1] <a href="https:&#x2F;&#x2F;nixery.dev&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;nixery.dev&#x2F;</a></div><br/><div id="37412101" class="c"><input type="checkbox" id="c-37412101" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37412013">parent</a><span>|</span><a href="#37415833">next</a><span>|</span><label class="collapse" for="c-37412101">[-]</label><label class="expand" for="c-37412101">[5 more]</label></div><br/><div class="children"><div class="content">Hi flurie, Nixery exposes an API (in the form of an Docker registry) to dynamically build Nix-based images, but still tar &amp; compresses Nix packages into layer tarballs. Since the image spec has a limit of 128 layers (due to overlayfs), a heuristic is used to put popular packages together. However, in practice there is still a large amount of duplication between images that share the same packages due to this heuristic based strategy. You also may deploy the same packages outside of containers but have to duplicate that same data (in a slightly different format) on a Docker Registry.<p>With `pkgs.nix-snapshotter.buildImage`, containerd natively understands Nix packages, so everything is pulled at package granularity without the layer limit. This means all container content is either already in your host nix store or fetched from your Nix binary cache. Think delta image pulls, which isn&#x27;t possible with regular images since one bit difference will change the layer hash and thus duplicate.<p>That said, nothing stops Nixery from building nix-snapshotter images. Then we&#x27;ll have an Docker Registry that dynamically builds native Nix images.</div><br/><div id="37412277" class="c"><input type="checkbox" id="c-37412277" checked=""/><div class="controls bullet"><span class="by">0x457</span><span>|</span><a href="#37412013">root</a><span>|</span><a href="#37412101">parent</a><span>|</span><a href="#37415833">next</a><span>|</span><label class="collapse" for="c-37412277">[-]</label><label class="expand" for="c-37412277">[4 more]</label></div><br/><div class="children"><div class="content">So if the package isn&#x27;t in cache, then suddenly k8s node is building it from source?</div><br/><div id="37412392" class="c"><input type="checkbox" id="c-37412392" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37412013">root</a><span>|</span><a href="#37412277">parent</a><span>|</span><a href="#37415833">next</a><span>|</span><label class="collapse" for="c-37412392">[-]</label><label class="expand" for="c-37412392">[3 more]</label></div><br/><div class="children"><div class="content">If you are pushing nix-snapshotter images to a Docker Registry, then it can only either use what&#x27;s in your host nix store, or fetch from a binary cache.<p>The same is true if you are using the special image reference like `nix:0&#x2F;nix&#x2F;store&#x2F;f8b1hia3hcqwa5d46anzy3cszi3s6ybk-nix-image-redis.tar`, it just means that instead of fetching the image manifest from a Registry, you are using the Nix protocols.<p>You will only build from source dynamically (and a mix of caching) if you are doing `kubectl apply -f ${podSpec}` as a full deployment Nix expression. See the README&#x27;s asciinema and this file as an example: <a href="https:&#x2F;&#x2F;github.com&#x2F;pdtpartners&#x2F;nix-snapshotter&#x2F;blob&#x2F;v0.1.0&#x2F;examples&#x2F;declarative-k8s.nix#L47-L70">https:&#x2F;&#x2F;github.com&#x2F;pdtpartners&#x2F;nix-snapshotter&#x2F;blob&#x2F;v0.1.0&#x2F;e...</a></div><br/><div id="37415170" class="c"><input type="checkbox" id="c-37415170" checked=""/><div class="controls bullet"><span class="by">alex_hirner</span><span>|</span><a href="#37412013">root</a><span>|</span><a href="#37412392">parent</a><span>|</span><a href="#37415833">next</a><span>|</span><label class="collapse" for="c-37415170">[-]</label><label class="expand" for="c-37415170">[2 more]</label></div><br/><div class="children"><div class="content">I think your usage example will be easier to understand, if it explains where nix:0 is setup as CRI image-service.
Maybe I glanced over it.<p>Awesome project!</div><br/><div id="37416343" class="c"><input type="checkbox" id="c-37416343" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37412013">root</a><span>|</span><a href="#37415170">parent</a><span>|</span><a href="#37415833">next</a><span>|</span><label class="collapse" for="c-37416343">[-]</label><label class="expand" for="c-37416343">[1 more]</label></div><br/><div class="children"><div class="content">Hi Alex, I’ve updated the README with a bit more information.<p>0 is actually an unbindable port, so nix:0 is just an arbitrary string that is unlikely to have conflicts. The Kubelet needs to be configured with —image-service-endpoint to use the nix-snapshotter gRPC socket to handle the “PullImage” RPC. There we can take over resolving the image reference when it’s prefixed with nix:0.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="37415833" class="c"><input type="checkbox" id="c-37415833" checked=""/><div class="controls bullet"><span class="by">IdiranVibe</span><span>|</span><a href="#37412013">prev</a><span>|</span><a href="#37415627">next</a><span>|</span><label class="collapse" for="c-37415833">[-]</label><label class="expand" for="c-37415833">[2 more]</label></div><br/><div class="children"><div class="content">Will you be at NixCon? Seems like good timing to post this!</div><br/><div id="37416210" class="c"><input type="checkbox" id="c-37416210" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37415833">parent</a><span>|</span><a href="#37415627">next</a><span>|</span><label class="collapse" for="c-37416210">[-]</label><label class="expand" for="c-37416210">[1 more]</label></div><br/><div class="children"><div class="content">Yes! Our talk wasn’t accepted but Robbie and I, and a few others from my team will be there. Come say Hi!</div><br/></div></div></div></div><div id="37415627" class="c"><input type="checkbox" id="c-37415627" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#37415833">prev</a><span>|</span><a href="#37413011">next</a><span>|</span><label class="collapse" for="c-37415627">[-]</label><label class="expand" for="c-37415627">[3 more]</label></div><br/><div class="children"><div class="content">Finally, something cool in this space that isn&#x27;t a naked VC grift. Gl Edgar and Robbie.</div><br/><div id="37415743" class="c"><input type="checkbox" id="c-37415743" checked=""/><div class="controls bullet"><span class="by">throwawayqqq11</span><span>|</span><a href="#37415627">parent</a><span>|</span><a href="#37413011">next</a><span>|</span><label class="collapse" for="c-37415743">[-]</label><label class="expand" for="c-37415743">[2 more]</label></div><br/><div class="children"><div class="content">I am still sceptical. What is the difference between &quot;native understanding of nix packages&quot; versus DIY putting your project derivation into dockerTools.buildImage?<p>I dont see a killer selling point, just some middle ware with extra containerization features which also could be pulled into nixpkgs.<p>But i have to admit, in my perception bubble VC gets more desperate and to them, the search metrices for nix must be shining like a christmas tree. I am certainly biased negatively.</div><br/><div id="37415962" class="c"><input type="checkbox" id="c-37415962" checked=""/><div class="controls bullet"><span class="by">rgoulter</span><span>|</span><a href="#37415627">root</a><span>|</span><a href="#37415743">parent</a><span>|</span><a href="#37413011">next</a><span>|</span><label class="collapse" for="c-37415962">[-]</label><label class="expand" for="c-37415962">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What is the difference between &quot;native understanding of nix packages&quot; versus DIY putting your project derivation into dockerTools.buildImage?<p>This is addressed in the readme FAQ.
<a href="https:&#x2F;&#x2F;github.com&#x2F;pdtpartners&#x2F;nix-snapshotter#faq">https:&#x2F;&#x2F;github.com&#x2F;pdtpartners&#x2F;nix-snapshotter#faq</a><p>If you&#x27;re running Nix-based images on Kubernetes, seems like this tool has reduced overhead &#x2F; storage compared to if you build an OCI&#x2F;Docker image.</div><br/></div></div></div></div></div></div><div id="37413011" class="c"><input type="checkbox" id="c-37413011" checked=""/><div class="controls bullet"><span class="by">solatic</span><span>|</span><a href="#37415627">prev</a><span>|</span><a href="#37412621">next</a><span>|</span><label class="collapse" for="c-37413011">[-]</label><label class="expand" for="c-37413011">[7 more]</label></div><br/><div class="children"><div class="content">Super interesting. I can clearly see how this improves the caching story compared to vanilla Kubernetes+containerd, and therefore the potential this has to improve autoscaling performance.<p>Of course, it understandably requires the host VM to be NixOS, which means my Kubernetes cluster needs to be running NixOS, which means I would need to abandon the ease afforded by EKS&#x2F;GKE... which is a tall ask. It would be great if there was a way to more easily add this into popular managed Kubernetes distributions, to play around more with running &quot;Nix images&quot;, simply by adding nodeSelector and&#x2F;or node affinity to the Kubernetes manifests.</div><br/><div id="37413054" class="c"><input type="checkbox" id="c-37413054" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37413011">parent</a><span>|</span><a href="#37413880">next</a><span>|</span><label class="collapse" for="c-37413054">[-]</label><label class="expand" for="c-37413054">[4 more]</label></div><br/><div class="children"><div class="content">We will be running it on a non-NixOS Kubernetes cluster, all you need is a nix daemon running as a systemd service.<p>I have tested with EKS, and you should be able to use nix-snapshotter with GKE too. May be able to put together some docs for that later.<p>In the meantime, see this for running a different snapshotter on EKS: <a href="https:&#x2F;&#x2F;blog.realvarez.com&#x2F;using-estargz-to-reduce-container-startup-time-on-amazon-eks&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.realvarez.com&#x2F;using-estargz-to-reduce-container...</a></div><br/><div id="37414243" class="c"><input type="checkbox" id="c-37414243" checked=""/><div class="controls bullet"><span class="by">mikepurvis</span><span>|</span><a href="#37413011">root</a><span>|</span><a href="#37413054">parent</a><span>|</span><a href="#37413136">next</a><span>|</span><label class="collapse" for="c-37414243">[-]</label><label class="expand" for="c-37414243">[2 more]</label></div><br/><div class="children"><div class="content">I assume that if the nix daemon is being started with each pod, then you&#x27;re downloading a fresh copy of everything every time, so for large closures you give up a lot of the benefit of the cluster being able to cache layers (as in, say, a nix2container- or nixery-style image) and achieve very fast subsequent startups.<p>I&#x27;m a k8s novice, but would there be a way to run the nix daemon&#x2F;cache in a semi-persistent pod on each node, and then &quot;attach&quot; it to the actual worker pods?</div><br/><div id="37414386" class="c"><input type="checkbox" id="c-37414386" checked=""/><div class="controls bullet"><span class="by">rgoulter</span><span>|</span><a href="#37413011">root</a><span>|</span><a href="#37414243">parent</a><span>|</span><a href="#37413136">next</a><span>|</span><label class="collapse" for="c-37414386">[-]</label><label class="expand" for="c-37414386">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I assume that if the nix daemon is being started with each pod, then you&#x27;re downloading a fresh copy of everything every time<p>I got the impression that it uses the node&#x27;s nix daemon.<p>From the project readme&#x27;s FAQ <a href="https:&#x2F;&#x2F;github.com&#x2F;pdtpartners&#x2F;nix-snapshotter#faq">https:&#x2F;&#x2F;github.com&#x2F;pdtpartners&#x2F;nix-snapshotter#faq</a><p>&gt; What&#x27;s the difference between this and a nix-in-docker?<p>&gt; If you run nix inside a container (e.g. nixos&#x2F;nix or nixpkgs&#x2F;nix-flake) then you are indeed fetching packages using the Nix store. However, each container will have its own Nix store instead of de-duplicating at the host level.<p>&gt; nix-snapshotter is intended to live on the host system (sibling to containerd and&#x2F;or kubelet) so that multiple containers running different images can share the underlying packages from the same Nix store.</div><br/></div></div></div></div><div id="37413136" class="c"><input type="checkbox" id="c-37413136" checked=""/><div class="controls bullet"><span class="by">solatic</span><span>|</span><a href="#37413011">root</a><span>|</span><a href="#37413054">parent</a><span>|</span><a href="#37414243">prev</a><span>|</span><a href="#37413880">next</a><span>|</span><label class="collapse" for="c-37413136">[-]</label><label class="expand" for="c-37413136">[1 more]</label></div><br/><div class="children"><div class="content">I would definitely appreciate seeing some docs with quick pointers on setting that up for EKS at least, if not also GKE!</div><br/></div></div></div></div><div id="37413880" class="c"><input type="checkbox" id="c-37413880" checked=""/><div class="controls bullet"><span class="by">adobrawy</span><span>|</span><a href="#37413011">parent</a><span>|</span><a href="#37413054">prev</a><span>|</span><a href="#37413039">next</a><span>|</span><label class="collapse" for="c-37413880">[-]</label><label class="expand" for="c-37413880">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure exactly how the communication of components works there, but in k8s can this be deployed using daemonset rather host service?</div><br/></div></div><div id="37413039" class="c"><input type="checkbox" id="c-37413039" checked=""/><div class="controls bullet"><span class="by">sporeray</span><span>|</span><a href="#37413011">parent</a><span>|</span><a href="#37413880">prev</a><span>|</span><a href="#37412621">next</a><span>|</span><label class="collapse" for="c-37413039">[-]</label><label class="expand" for="c-37413039">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this is true, I think it only requires the host system to have nix installed.</div><br/></div></div></div></div><div id="37412621" class="c"><input type="checkbox" id="c-37412621" checked=""/><div class="controls bullet"><span class="by">yjftsjthsd-h</span><span>|</span><a href="#37413011">prev</a><span>|</span><a href="#37412886">next</a><span>|</span><label class="collapse" for="c-37412621">[-]</label><label class="expand" for="c-37412621">[4 more]</label></div><br/><div class="children"><div class="content">So that means that it needs the host to run nix, right? I suppose that could be useful, but if I&#x27;m running nix-built images as containers it&#x27;s usually because I want to run somewhere that&#x27;s not &quot;nix native&quot;.</div><br/><div id="37412663" class="c"><input type="checkbox" id="c-37412663" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37412621">parent</a><span>|</span><a href="#37414272">next</a><span>|</span><label class="collapse" for="c-37412663">[-]</label><label class="expand" for="c-37412663">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s fair, adding another service is definitely a downside. If you are running nix-built images though, the underlying data still needs to land somewhere on disk. Nix-snapshotter lets you store less data and download less data due to its package granularity.<p>We already have rootless containerd and nix-snapshotter. And I believe there is work underway to run rootless nix (and rootless k3s too). You may be able to run the whole thing unprivileged one day.</div><br/></div></div><div id="37414272" class="c"><input type="checkbox" id="c-37414272" checked=""/><div class="controls bullet"><span class="by">mikepurvis</span><span>|</span><a href="#37412621">parent</a><span>|</span><a href="#37412663">prev</a><span>|</span><a href="#37412637">next</a><span>|</span><label class="collapse" for="c-37414272">[-]</label><label class="expand" for="c-37414272">[1 more]</label></div><br/><div class="children"><div class="content">Even at the cost of the k8s nodes having to be &quot;special&quot;, this is still fabulously useful running Nix-native workloads on stuff like GitLab or Jenkins workers.</div><br/></div></div><div id="37412637" class="c"><input type="checkbox" id="c-37412637" checked=""/><div class="controls bullet"><span class="by">georgyo</span><span>|</span><a href="#37412621">parent</a><span>|</span><a href="#37414272">prev</a><span>|</span><a href="#37412886">next</a><span>|</span><label class="collapse" for="c-37412637">[-]</label><label class="expand" for="c-37412637">[1 more]</label></div><br/><div class="children"><div class="content">If you have a nix environment and want to just kubernetes for orchestration, this is exactly what you want!</div><br/></div></div></div></div><div id="37412886" class="c"><input type="checkbox" id="c-37412886" checked=""/><div class="controls bullet"><span class="by">dlahoda</span><span>|</span><a href="#37412621">prev</a><span>|</span><a href="#37412217">next</a><span>|</span><label class="collapse" for="c-37412886">[-]</label><label class="expand" for="c-37412886">[4 more]</label></div><br/><div class="children"><div class="content">what is performance of image building with this? can it build isolation container without image build <a href="https:&#x2F;&#x2F;iximiuz.com&#x2F;en&#x2F;posts&#x2F;you-dont-need-an-image-to-run-a-container&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;iximiuz.com&#x2F;en&#x2F;posts&#x2F;you-dont-need-an-image-to-run-a...</a>  ?</div><br/><div id="37412969" class="c"><input type="checkbox" id="c-37412969" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37412886">parent</a><span>|</span><a href="#37412217">next</a><span>|</span><label class="collapse" for="c-37412969">[-]</label><label class="expand" for="c-37412969">[3 more]</label></div><br/><div class="children"><div class="content">If you are comparing non-Nix image build performance, Nix is comparable to BuildKit in that it’s able to parallelize a build graph and cache intermediary outputs. Nix doesn’t require a Dockerfile to build, and constructs the layers directly like in the article.<p>In terms of image size, since it’s dependencies are explicit (all the way down to glibc and lower), the Nix image is comparable to a scratch image with a single statically compiled binary.<p>Comparing to the existing Nix built images, we are moving image build performance from O(n) (n is number of Nix packages) to ~O(1) because the build process becomes just constructing a JSON referring to already built Nix packages.</div><br/><div id="37413009" class="c"><input type="checkbox" id="c-37413009" checked=""/><div class="controls bullet"><span class="by">sporeray</span><span>|</span><a href="#37412886">root</a><span>|</span><a href="#37412969">parent</a><span>|</span><a href="#37412217">next</a><span>|</span><label class="collapse" for="c-37413009">[-]</label><label class="expand" for="c-37413009">[2 more]</label></div><br/><div class="children"><div class="content">I’m guessing it also makes building variations of images much quicker because you only need to build the “difference” between the images?</div><br/><div id="37413101" class="c"><input type="checkbox" id="c-37413101" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37412886">root</a><span>|</span><a href="#37413009">parent</a><span>|</span><a href="#37412217">next</a><span>|</span><label class="collapse" for="c-37413101">[-]</label><label class="expand" for="c-37413101">[1 more]</label></div><br/><div class="children"><div class="content">Yup. If you also deploy the Nix packages to bare-metal, then creating containers is at almost zero cost because the container image component is just JSON.</div><br/></div></div></div></div></div></div></div></div><div id="37412217" class="c"><input type="checkbox" id="c-37412217" checked=""/><div class="controls bullet"><span class="by">Y_Y</span><span>|</span><a href="#37412886">prev</a><span>|</span><label class="collapse" for="c-37412217">[-]</label><label class="expand" for="c-37412217">[3 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the advantage over me putting my Nix config in e.g. a Dockerfile?</div><br/><div id="37412394" class="c"><input type="checkbox" id="c-37412394" checked=""/><div class="controls bullet"><span class="by">cstrahan</span><span>|</span><a href="#37412217">parent</a><span>|</span><a href="#37412417">next</a><span>|</span><label class="collapse" for="c-37412394">[-]</label><label class="expand" for="c-37412394">[1 more]</label></div><br/><div class="children"><div class="content">To answer that, I think you’d first need to define what “putting my Nix config in e.g. a Dockerfile” means.<p>Do you mean using a Dockerfile to run a Nix package build, embedding the resulting files (and transitive dependencies) in the image file? If so, this objectively superior in several ways: 1) only one copy of any package exists on disk: the one in the Nix store, instead of multiple images having independent copies. 2) Related to this de-duplication, it will be faster to go from pristine host (virtual machine, dev machine, whatever) to having containers up and running, as you no longer have bulky images to transfer over the network. 3) I haven’t looked at the finer details, but I’m pretty sure this means that the host can build the required packages once, meaning better caching — instead of multiple Dockerfiles rebuilding the same packages, the host builds once and all dependent containers get use the host’s Nix store, again <i>without</i> any copying of files involved.<p>Edit:<p>From hinshun’s comment above, point #3 is incorrect — either the host’s Nix store would need a copy already present, or the package would need to be available in a remote store&#x2F;cache. Even with that correction, you still avoid redundant package builds — either the package is available remotely&#x2F;locally, or the image fetch fails — so things are still only ever built once :)</div><br/></div></div><div id="37412417" class="c"><input type="checkbox" id="c-37412417" checked=""/><div class="controls bullet"><span class="by">hinshun</span><span>|</span><a href="#37412217">parent</a><span>|</span><a href="#37412394">prev</a><span>|</span><label class="collapse" for="c-37412417">[-]</label><label class="expand" for="c-37412417">[1 more]</label></div><br/><div class="children"><div class="content">It can leverage de-duplication in your host nix store (as a sibling service to your container runtime), as opposed to having a containerized nix store each fetching its necessary packages.</div><br/></div></div></div></div></div></div></div></div></div></body></html>