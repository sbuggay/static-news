<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1724576472774" as="style"/><link rel="stylesheet" href="styles.css?v=1724576472774"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://chipsandcheese.com/2024/08/24/amds-radeon-890m-strix-points-bigger-igpu/">AMD&#x27;s Radeon 890M: Strix Point&#x27;s Bigger iGPU</a> <span class="domain">(<a href="https://chipsandcheese.com">chipsandcheese.com</a>)</span></div><div class="subtext"><span>luyu_wu</span> | <span>22 comments</span></div><br/><div><div id="41345239" class="c"><input type="checkbox" id="c-41345239" checked=""/><div class="controls bullet"><span class="by">Luker88</span><span>|</span><a href="#41344270">next</a><span>|</span><label class="collapse" for="c-41345239">[-]</label><label class="expand" for="c-41345239">[1 more]</label></div><br/><div class="children"><div class="content">I basically only buy AMD, but I want to point out how rocm still doesn&#x27;t fully support the 780M.<p>I have a laptop with a 680M and a mini pc with a 780M both beefy enough to play around with small LLM. You basically have to force the gpu detection to an older version, and I get tons of gpu resets on both.<p>AMD your hardware is good please give the software more love.</div><br/></div></div><div id="41344270" class="c"><input type="checkbox" id="c-41344270" checked=""/><div class="controls bullet"><span class="by">rishav_sharan</span><span>|</span><a href="#41345239">prev</a><span>|</span><a href="#41343823">next</a><span>|</span><label class="collapse" for="c-41344270">[-]</label><label class="expand" for="c-41344270">[12 more]</label></div><br/><div class="children"><div class="content">I love how well Intel&#x27;s Arc iGPU and AMDs Strix Point iGPU are doing. I am planning to get an iGPU laptop with 64 Gb RAM. I plan on using local llms and image generators and hopefully with that large of shared RAM that shouldn&#x27;t be too much of a problem. But I am worried that all LLM tools today are pretty much NVidia specific, and I wouldn&#x27;t be able to get my local setup going.</div><br/><div id="41344322" class="c"><input type="checkbox" id="c-41344322" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#41344270">parent</a><span>|</span><a href="#41344589">next</a><span>|</span><label class="collapse" for="c-41344322">[-]</label><label class="expand" for="c-41344322">[7 more]</label></div><br/><div class="children"><div class="content">Can they access the full RAM? Afaik they get capped to a portion of total available RAM.<p>But to your other point, very little of the current popular ML stack does more than CUDA and MPS. Some will do rocm but I don’t know if the AMD iGPUs are guaranteed to support it? There’s not much for Intel GPUs.</div><br/><div id="41344370" class="c"><input type="checkbox" id="c-41344370" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#41344270">root</a><span>|</span><a href="#41344322">parent</a><span>|</span><a href="#41345312">next</a><span>|</span><label class="collapse" for="c-41344370">[-]</label><label class="expand" for="c-41344370">[5 more]</label></div><br/><div class="children"><div class="content">It depends on the API used, whether the data is in the region considered &quot;GPU memory&quot; or whether it&#x27;s shared with the compute API from the app&#x27;s memory space. Support is somewhat in flux and I haven&#x27;t been following closely but if you&#x27;re curious this is my bookmarked jumping of point (a PyTorch ticket about this):<p><a href="https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch&#x2F;issues&#x2F;107605">https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch&#x2F;issues&#x2F;107605</a></div><br/><div id="41344864" class="c"><input type="checkbox" id="c-41344864" checked=""/><div class="controls bullet"><span class="by">slavik81</span><span>|</span><a href="#41344270">root</a><span>|</span><a href="#41344370">parent</a><span>|</span><a href="#41344887">next</a><span>|</span><label class="collapse" for="c-41344864">[-]</label><label class="expand" for="c-41344864">[3 more]</label></div><br/><div class="children"><div class="content">My understanding is that as of Linux 6.10, the driver will now dynamically allocate more memory for the iGPU [1]. The driver team apparently reused a strategy that had been developed for MI300A.<p>I&#x27;m hoping that in combination with the gfx11-generic ISA introduced in LLVM 18, this will make it straightforward to enable compute applications on both Phoenix and Strix (even if they are not officially supported by ROCm).<p>[1]: <a href="https:&#x2F;&#x2F;git.kernel.org&#x2F;pub&#x2F;scm&#x2F;linux&#x2F;kernel&#x2F;git&#x2F;torvalds&#x2F;linux.git&#x2F;commit&#x2F;?h=v6.10-rc4&amp;id=eb853413d02c8d9b27942429b261a9eef228f005" rel="nofollow">https:&#x2F;&#x2F;git.kernel.org&#x2F;pub&#x2F;scm&#x2F;linux&#x2F;kernel&#x2F;git&#x2F;torvalds&#x2F;lin...</a></div><br/><div id="41345303" class="c"><input type="checkbox" id="c-41345303" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#41344270">root</a><span>|</span><a href="#41344864">parent</a><span>|</span><a href="#41344913">next</a><span>|</span><label class="collapse" for="c-41345303">[-]</label><label class="expand" for="c-41345303">[1 more]</label></div><br/><div class="children"><div class="content">One issue is that even if you are using GTT (dynamically allocated memory), this is still limited as a percentage of total RAM. Eg, currently on my 7940HS, I have 64GB of memory, 8GB of dedicated VRAM (GART), and then a limit of 28GB of GTT - there is an amdgpu.gttsize parameter to &quot;Restrict the size of GTT domain in MiB for testing. The default is -1 (It’s VRAM size if 3GB &lt; VRAM &lt; 3&#x2F;4 RAM, otherwise 3&#x2F;4 RAM size)&quot;, but I&#x27;m not sure what the practical&#x2F;effective limits are.</div><br/></div></div><div id="41344913" class="c"><input type="checkbox" id="c-41344913" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#41344270">root</a><span>|</span><a href="#41344864">parent</a><span>|</span><a href="#41345303">prev</a><span>|</span><a href="#41344887">next</a><span>|</span><label class="collapse" for="c-41344913">[-]</label><label class="expand" for="c-41344913">[1 more]</label></div><br/><div class="children"><div class="content">FWIW, It’s one of the patches linked in their linked issue.<p>However the commits do have some caveats called out, as do the techniques they use to achieve the higher allocations.</div><br/></div></div></div></div><div id="41344887" class="c"><input type="checkbox" id="c-41344887" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#41344270">root</a><span>|</span><a href="#41344370">parent</a><span>|</span><a href="#41344864">prev</a><span>|</span><a href="#41345312">next</a><span>|</span><label class="collapse" for="c-41344887">[-]</label><label class="expand" for="c-41344887">[1 more]</label></div><br/><div class="children"><div class="content">I appreciate the link.  The GTT and SDMA tricks mentioned there don’t really increase the shared ram use imho. They just increase the virtual memory the GPU can address, but with several tradeoffs in terms of allocation and copy operations.<p>As an aside, it just feels like a lot of hacks that AMD and Intel should have handled ages ago for their iGPUs instead of letting them languish.</div><br/></div></div></div></div><div id="41345312" class="c"><input type="checkbox" id="c-41345312" checked=""/><div class="controls bullet"><span class="by">guilamu</span><span>|</span><a href="#41344270">root</a><span>|</span><a href="#41344322">parent</a><span>|</span><a href="#41344370">prev</a><span>|</span><a href="#41344589">next</a><span>|</span><label class="collapse" for="c-41345312">[-]</label><label class="expand" for="c-41345312">[1 more]</label></div><br/><div class="children"><div class="content">Be careful, most bios will let you use only 1&#x2F;4 of the total ram for the integrated GPU. Some - really bad - bios are even limiting to 2gb totally ignoring how much ram is available.</div><br/></div></div></div></div><div id="41344589" class="c"><input type="checkbox" id="c-41344589" checked=""/><div class="controls bullet"><span class="by">aappleby</span><span>|</span><a href="#41344270">parent</a><span>|</span><a href="#41344322">prev</a><span>|</span><a href="#41344361">next</a><span>|</span><label class="collapse" for="c-41344589">[-]</label><label class="expand" for="c-41344589">[3 more]</label></div><br/><div class="children"><div class="content">You&#x27;ll be limited by memory bandwidth more than compute.</div><br/><div id="41345183" class="c"><input type="checkbox" id="c-41345183" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#41344270">root</a><span>|</span><a href="#41344589">parent</a><span>|</span><a href="#41344361">next</a><span>|</span><label class="collapse" for="c-41345183">[-]</label><label class="expand" for="c-41345183">[2 more]</label></div><br/><div class="children"><div class="content">Anyone who uses a CPU for inference is severely compute constrained. Nobody cares about tokens per second the moment inference is faster than you can read, but staring down a blank screen for 5 minutes? Yikes.</div><br/><div id="41345400" class="c"><input type="checkbox" id="c-41345400" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#41344270">root</a><span>|</span><a href="#41345183">parent</a><span>|</span><a href="#41344361">next</a><span>|</span><label class="collapse" for="c-41345400">[-]</label><label class="expand" for="c-41345400">[1 more]</label></div><br/><div class="children"><div class="content">Just as a point of reference, this is what a 65W power-limited 7940HS (Radeon 790M) with 64GB of DDR5-5600 looks like w&#x2F; a 7B Q4_K_M model atm w&#x2F; llama.cpp. While it&#x27;s not amazing, at 240 t&#x2F;s prefill, it means that at 4K context, you&#x27;ll wait about 17 seconds before token generation starts, which isn&#x27;t awful. The 890M should have about 20% better compute, so about 300 t&#x2F;s prefill, and with LPDDR5-7500&#x2F;8000, you should get to about 20 t&#x2F;s.<p><pre><code>  .&#x2F;llama-bench -m &#x2F;data&#x2F;ai&#x2F;models&#x2F;llm&#x2F;gguf&#x2F;mistral-7b-instruct-v0.1.Q4_K_M.gguf
  ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
  ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
  ggml_cuda_init: found 1 ROCm devices:
  Device 0: AMD Radeon 780M, compute capability 11.0, VMM: no
  | model                          |       size |     params | backend    | ngl |          test |              t&#x2F;s |
  | ------------------------------ | ---------: | ---------: | ---------- | --: | ------------: | ---------------: |
  | llama 7B Q4_K - Medium         |   4.07 GiB |     7.24 B | ROCm       |  99 |         pp512 |    242.69 ± 0.99 |
  | llama 7B Q4_K - Medium         |   4.07 GiB |     7.24 B | ROCm       |  99 |         tg128 |     15.33 ± 0.03 |

  build: e11bd856 (3620)</code></pre></div><br/></div></div></div></div></div></div><div id="41344361" class="c"><input type="checkbox" id="c-41344361" checked=""/><div class="controls bullet"><span class="by">allen_fisher</span><span>|</span><a href="#41344270">parent</a><span>|</span><a href="#41344589">prev</a><span>|</span><a href="#41343823">next</a><span>|</span><label class="collapse" for="c-41344361">[-]</label><label class="expand" for="c-41344361">[1 more]</label></div><br/><div class="children"><div class="content">I set up both stable diffusion and LLMs on my desktop without Nvidia GPU. Everything goes well. Stable diffusion can run on onnx backend on my AMD GPU, and LLMs run through gguf format through ollama on CPU, model scale and speed are limited though.</div><br/></div></div></div></div><div id="41343823" class="c"><input type="checkbox" id="c-41343823" checked=""/><div class="controls bullet"><span class="by">torrance</span><span>|</span><a href="#41344270">prev</a><span>|</span><a href="#41344441">next</a><span>|</span><label class="collapse" for="c-41343823">[-]</label><label class="expand" for="c-41343823">[5 more]</label></div><br/><div class="children"><div class="content">These results are promising and hopefully carry over to the upcoming Strix Halo which I’m eagerly awaiting. With a rumoured 40 compute cores and performance on par with a low power (&lt;95W) mobile RTX4070, it would make an exciting small form gaming box.</div><br/><div id="41345209" class="c"><input type="checkbox" id="c-41345209" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#41343823">parent</a><span>|</span><a href="#41344014">next</a><span>|</span><label class="collapse" for="c-41345209">[-]</label><label class="expand" for="c-41345209">[1 more]</label></div><br/><div class="children"><div class="content">I hope Strix Halo gets a desktop motherboard (no socket :-( for the memory bandwidth for faster compiles (Go). That or a 9950X3D (like the 7950X3D).</div><br/></div></div><div id="41344014" class="c"><input type="checkbox" id="c-41344014" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#41343823">parent</a><span>|</span><a href="#41345209">prev</a><span>|</span><a href="#41344441">next</a><span>|</span><label class="collapse" for="c-41344014">[-]</label><label class="expand" for="c-41344014">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been super excited for Strix Halo, but I&#x27;m also nervous. Strix Halo is a multi-chip design, and I&#x27;m pretty nervous about whether AMD can pull it off in a mobile form factor, while still being a good mobile chip.<p>Strix Point can be brought down to 15W and still do <i>awesome</i>. And go up to 55W+ and be fine. Nice idles. But it&#x27;s monolithic, and I&#x27;m not sure if AMD &amp; TSMC are really making that power penalty of multichip go down enough.</div><br/><div id="41344025" class="c"><input type="checkbox" id="c-41344025" checked=""/><div class="controls bullet"><span class="by">luyu_wu</span><span>|</span><a href="#41343823">root</a><span>|</span><a href="#41344014">parent</a><span>|</span><a href="#41344891">next</a><span>|</span><label class="collapse" for="c-41344025">[-]</label><label class="expand" for="c-41344025">[1 more]</label></div><br/><div class="children"><div class="content">Very valid concerns! AMD&#x27;s current die-to-die interconnects have some pretty abysmal energy&#x2F;bit. Really hope they can pull off something similar to Intel&#x27;s EMIB maybe?</div><br/></div></div><div id="41344891" class="c"><input type="checkbox" id="c-41344891" checked=""/><div class="controls bullet"><span class="by">asmor</span><span>|</span><a href="#41343823">root</a><span>|</span><a href="#41344014">parent</a><span>|</span><a href="#41344025">prev</a><span>|</span><a href="#41344441">next</a><span>|</span><label class="collapse" for="c-41344891">[-]</label><label class="expand" for="c-41344891">[1 more]</label></div><br/><div class="children"><div class="content">The 7945HX3D needs 55W minimum, if that&#x27;s any indicator.</div><br/></div></div></div></div></div></div><div id="41344441" class="c"><input type="checkbox" id="c-41344441" checked=""/><div class="controls bullet"><span class="by">Shorel</span><span>|</span><a href="#41343823">prev</a><span>|</span><label class="collapse" for="c-41344441">[-]</label><label class="expand" for="c-41344441">[3 more]</label></div><br/><div class="children"><div class="content">Similar performance to Nvidia 1080 dedicated GPU.<p>Would I get it?  Absolutely yes. A full desktop small form factor is a very convenient, nice thing.</div><br/><div id="41344920" class="c"><input type="checkbox" id="c-41344920" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#41344441">parent</a><span>|</span><label class="collapse" for="c-41344920">[-]</label><label class="expand" for="c-41344920">[2 more]</label></div><br/><div class="children"><div class="content">Where do you see a performance comparison for the 1080?<p>The only mention of NVIDIA in the post is of the 1050 which is a considerable step away from a 1080.<p>&gt; It also moves ahead of Nvidia’s Pascal based GTX 1050 3 GB</div><br/><div id="41345541" class="c"><input type="checkbox" id="c-41345541" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#41344441">root</a><span>|</span><a href="#41344920">parent</a><span>|</span><label class="collapse" for="c-41345541">[-]</label><label class="expand" for="c-41345541">[1 more]</label></div><br/><div class="children"><div class="content">From Notebookcheck&#x27;s benchmarks it looks like the Radeon 890M is punching at about a GeForce 1650 Mobile&#x27;s performance: <a href="https:&#x2F;&#x2F;www.notebookcheck.net&#x2F;Computer-Games-on-Laptop-Graphics-Cards.13849.0.html?type=&amp;sort=&amp;gpubenchmarks=1&amp;professional=2&amp;multiplegpus=1&amp;archive=1&amp;perfrating=1&amp;or=0&amp;itemselect_10227=10227&amp;itemselect_9828=9828&amp;itemselect_12524=12524&amp;gameselect%5B%5D=1008&amp;gameselect%5B%5D=1004&amp;gameselect%5B%5D=998&amp;gameselect%5B%5D=990&amp;gameselect%5B%5D=974&amp;gameselect%5B%5D=941&amp;gameselect%5B%5D=919&amp;gameselect%5B%5D=899&amp;gameselect%5B%5D=554&amp;gameselect%5B%5D=532&amp;gameselect%5B%5D=332&amp;gameselect%5B%5D=329&amp;gpu_fullname=1" rel="nofollow">https:&#x2F;&#x2F;www.notebookcheck.net&#x2F;Computer-Games-on-Laptop-Graph...</a><p>Based on <a href="https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;geforce-gtx-1650-mobile.c3367" rel="nofollow">https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;geforce-gtx-1650-mobil...</a> this is about 40% faster than a GTX 1050, but also almost half the speed of a GTX 1080.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>