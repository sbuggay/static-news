<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1736931675383" as="style"/><link rel="stylesheet" href="styles.css?v=1736931675383"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://sakana.ai/transformer-squared/">Transformer^2: Self-Adaptive LLMs</a> <span class="domain">(<a href="https://sakana.ai">sakana.ai</a>)</span></div><div class="subtext"><span>hardmaru</span> | <span>9 comments</span></div><br/><div><div id="42707241" class="c"><input type="checkbox" id="c-42707241" checked=""/><div class="controls bullet"><span class="by">wildermuthn</span><span>|</span><a href="#42707299">next</a><span>|</span><label class="collapse" for="c-42707241">[-]</label><label class="expand" for="c-42707241">[5 more]</label></div><br/><div class="children"><div class="content">Great research here. Contextual real-time weight modification is definitely one of the breakthroughs required for AGI. Why create a LoRA when you can generate one on the fly suited to the task at hand?</div><br/><div id="42707322" class="c"><input type="checkbox" id="c-42707322" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#42707241">parent</a><span>|</span><a href="#42708471">next</a><span>|</span><label class="collapse" for="c-42707322">[-]</label><label class="expand" for="c-42707322">[2 more]</label></div><br/><div class="children"><div class="content">It does not seem like they are doing inference time weight changes, to the tune of running backprop. It sounds more like they are applying a pre-trained vector to the model, and select that vector based on the input, in a two step process</div><br/><div id="42707446" class="c"><input type="checkbox" id="c-42707446" checked=""/><div class="controls bullet"><span class="by">wildermuthn</span><span>|</span><a href="#42707241">root</a><span>|</span><a href="#42707322">parent</a><span>|</span><a href="#42708471">next</a><span>|</span><label class="collapse" for="c-42707446">[-]</label><label class="expand" for="c-42707446">[1 more]</label></div><br/><div class="children"><div class="content">That’s my general understanding as well, but it isn’t a large conceptual leap to go from real-time selection of pretrained “z-vectors” to real-time generation of the same. The larger conceptual breakthrough, with demonstration of its effectiveness, is the big success here.</div><br/></div></div></div></div><div id="42708471" class="c"><input type="checkbox" id="c-42708471" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#42707241">parent</a><span>|</span><a href="#42707322">prev</a><span>|</span><a href="#42708018">next</a><span>|</span><label class="collapse" for="c-42708471">[-]</label><label class="expand" for="c-42708471">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Contextual real-time weight modification is definitely one of the breakthroughs required for AGI.<p>It&#x27;s already been invented: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2202.05780" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2202.05780</a> . That design is just very inefficient to scale up &#x2F; use as a transformer backbone.</div><br/></div></div><div id="42708018" class="c"><input type="checkbox" id="c-42708018" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#42707241">parent</a><span>|</span><a href="#42708471">prev</a><span>|</span><a href="#42707299">next</a><span>|</span><label class="collapse" for="c-42708018">[-]</label><label class="expand" for="c-42708018">[1 more]</label></div><br/><div class="children"><div class="content">See also the work being done by GoodFire AI:<p><a href="https:&#x2F;&#x2F;www.goodfire.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.goodfire.ai&#x2F;</a><p>They now have an API that allows for dynamic exploration and manipulation of the latent space for LLama 8-70B models (think Golden Gate Claude). They also open sourced the sparse auto-encoders that (in part) allow for this:<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;Goodfire&#x2F;Llama-3.3-70B-Instruct-SAE-l50" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;Goodfire&#x2F;Llama-3.3-70B-Instruct-SAE-l...</a></div><br/></div></div></div></div><div id="42707299" class="c"><input type="checkbox" id="c-42707299" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#42707241">prev</a><span>|</span><a href="#42708151">next</a><span>|</span><label class="collapse" for="c-42707299">[-]</label><label class="expand" for="c-42707299">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like MoE and maybe a bit of chain-of-thought. Curious what someone with more domain expertise thinks about this<p>If they can test against Llama 70B and Mistral 7B, they ought to compare against Mistral 8x7b imho</div><br/></div></div><div id="42708151" class="c"><input type="checkbox" id="c-42708151" checked=""/><div class="controls bullet"><span class="by">Vampiero</span><span>|</span><a href="#42707299">prev</a><span>|</span><a href="#42708497">next</a><span>|</span><label class="collapse" for="c-42708151">[-]</label><label class="expand" for="c-42708151">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s all very interesting but those pictures look pretty bad. Clear visible artifacts, awful shapes.</div><br/></div></div><div id="42708497" class="c"><input type="checkbox" id="c-42708497" checked=""/><div class="controls bullet"><span class="by">tzury</span><span>|</span><a href="#42708151">prev</a><span>|</span><label class="collapse" for="c-42708497">[-]</label><label class="expand" for="c-42708497">[1 more]</label></div><br/><div class="children"><div class="content">The ideas in the paper have been implemented and tested. The authors conducted experiments on several tasks (math, coding, reasoning, and visual question answering) and showed that their approach works better than previous methods like LoRA.<p>Key ideas (in simple terms):<p>1. What’s the problem?<p><pre><code>    - Fine-tuning LLMs for every new task is slow, expensive, and often doesn&#x27;t generalize well.
    - Models trained on one task may perform poorly on others, especially unseen ones.
    - Current methods (like LoRA) can add new capabilities but aren&#x27;t efficient enough.</code></pre>
2. The solution:<p><pre><code>    - Transformer² uses a new fine-tuning method called Singular Value Fine-tuning (SVF). This focuses on adjusting only certain parts of the model’s &quot;weight matrices&quot; rather than changing everything.
    - By tweaking specific components (called &quot;singular values&quot;), it trains smaller, efficient &quot;expert&quot; modules that specialize in particular types of tasks.</code></pre>
3. How it works:<p><pre><code>    - Training phase: Train these smaller expert modules offline using reinforcement learning (RL) to specialize in tasks like coding, math, or reasoning.
    - Inference phase: When a new input is given, the system analyzes the task (e.g., “Is this a math or coding problem?”) in the first pass. Based on this, it combines the right expert modules and adapts the model’s behavior in the second pass.</code></pre>
4. Three adaptation strategies:<p><pre><code>    - Prompt-based: Use a cleverly designed text prompt to figure out the task type and pick the right expert module.
    - Classifier-based: Train a separate model to classify tasks and match them to experts.
    - Few-shot adaptation: Look at a small number of examples (few-shot learning) to dynamically combine expert modules for the best results.</code></pre>
5. Efficiency:<p><pre><code>    - The system uses fewer parameters than traditional fine-tuning methods like LoRA.
    - Adaptation works even on small datasets without overfitting or forgetting older tasks.</code></pre></div><br/></div></div></div></div></div></div></div></body></html>