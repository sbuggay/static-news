<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1715763670889" as="style"/><link rel="stylesheet" href="styles.css?v=1715763670889"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="http://nian.llmonpy.ai/">GPT-4o&#x27;s Memory Breakthrough – Needle in a Needlestack</a> <span class="domain">(<a href="http://nian.llmonpy.ai">nian.llmonpy.ai</a>)</span></div><div class="subtext"><span>parrt</span> | <span>141 comments</span></div><br/><div><div id="40362183" class="c"><input type="checkbox" id="c-40362183" checked=""/><div class="controls bullet"><span class="by">bearjaws</span><span>|</span><a href="#40360811">next</a><span>|</span><label class="collapse" for="c-40362183">[-]</label><label class="expand" for="c-40362183">[31 more]</label></div><br/><div class="children"><div class="content">I just used it to compare two smaller legal documents and it completely hallucinated that items were present in one and not the other. It did this on three discrete sections of the agreements.<p>Using ctrl-f I was able to see that they were identical in one another.<p>Obviously this is a single sample but saying 90% seems unlikely. They were around ~80k tokens total.</div><br/><div id="40364640" class="c"><input type="checkbox" id="c-40364640" checked=""/><div class="controls bullet"><span class="by">feverzsj</span><span>|</span><a href="#40362183">parent</a><span>|</span><a href="#40363639">next</a><span>|</span><label class="collapse" for="c-40364640">[-]</label><label class="expand" for="c-40364640">[1 more]</label></div><br/><div class="children"><div class="content">LLM are still toys, no one should treat it seriously. Apparently, the bubble is too massive now.</div><br/></div></div><div id="40363639" class="c"><input type="checkbox" id="c-40363639" checked=""/><div class="controls bullet"><span class="by">sschueller</span><span>|</span><a href="#40362183">parent</a><span>|</span><a href="#40364640">prev</a><span>|</span><a href="#40363203">next</a><span>|</span><label class="collapse" for="c-40363639">[-]</label><label class="expand" for="c-40363639">[21 more]</label></div><br/><div class="children"><div class="content">We are all so majorly f*d.<p>The general public does not know nor understand this limitation. At the same time OpenAI is selling this a a tutor for your kids. Next it will be used to test those same kids.<p>Who is going to prevent this from being used to pick military targets (EU law has an exemption for military of course) or make surgery decisions?</div><br/><div id="40364016" class="c"><input type="checkbox" id="c-40364016" checked=""/><div class="controls bullet"><span class="by">kromokromo</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363639">parent</a><span>|</span><a href="#40363908">next</a><span>|</span><label class="collapse" for="c-40364016">[-]</label><label class="expand" for="c-40364016">[11 more]</label></div><br/><div class="children"><div class="content">This is just doomerism. Even though this model is slightly better than the previous, using an LLM for high risk tasks like healthcare and picking targets in military operations still feels very far away. I work in healthcare tech in a European country and yes we use AI for image recognition on x-rays, retinas etc but these are fundamentally completely different models than a LLM.<p>Using LLMs for picking military targets is just absurd. In the future, someone might use some other variation of AI for this but LLMs are not very effective on this.</div><br/><div id="40364191" class="c"><input type="checkbox" id="c-40364191" checked=""/><div class="controls bullet"><span class="by">dbspin</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364016">parent</a><span>|</span><a href="#40364235">next</a><span>|</span><label class="collapse" for="c-40364191">[-]</label><label class="expand" for="c-40364191">[3 more]</label></div><br/><div class="children"><div class="content">AI is already being used for picking targets in warzones - <a href="https:&#x2F;&#x2F;theconversation.com&#x2F;israel-accused-of-using-ai-to-target-thousands-in-gaza-as-killer-algorithms-outpace-international-law-227453#:~:text=The%20Israeli%20army%20used%20a,by%20Israeli%20and%20Palestinian%20journalists" rel="nofollow">https:&#x2F;&#x2F;theconversation.com&#x2F;israel-accused-of-using-ai-to-ta...</a>.<p>LLM&#x27;s will of course also be used, due to their convenience and superficial &#x27;intelligence&#x27;, and because of the layer of deniability creating a technical substrate between soldier and civilian victim provides - as has happened for two decades with drones.</div><br/><div id="40364553" class="c"><input type="checkbox" id="c-40364553" checked=""/><div class="controls bullet"><span class="by">throwthrowuknow</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364191">parent</a><span>|</span><a href="#40364430">next</a><span>|</span><label class="collapse" for="c-40364553">[-]</label><label class="expand" for="c-40364553">[1 more]</label></div><br/><div class="children"><div class="content">Why? There are many other types of AI or statistical methods that are easier, faster and cheaper to use not to mention better suited and far more accurate. Militaries have been employing statisticians since WWII to pick targets (and for all kinds of other things) this is just current-thing x2 so it’s being used to whip people into a frenzy.</div><br/></div></div><div id="40364430" class="c"><input type="checkbox" id="c-40364430" checked=""/><div class="controls bullet"><span class="by">mike_hearn</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364191">parent</a><span>|</span><a href="#40364553">prev</a><span>|</span><a href="#40364235">next</a><span>|</span><label class="collapse" for="c-40364430">[-]</label><label class="expand" for="c-40364430">[1 more]</label></div><br/><div class="children"><div class="content">Note that the IDF explicitly denied that story:<p><a href="https:&#x2F;&#x2F;www.idf.il&#x2F;en&#x2F;mini-sites&#x2F;hamas-israel-war-24&#x2F;all-articles&#x2F;idf-response-as-sent-to-the-guardian&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.idf.il&#x2F;en&#x2F;mini-sites&#x2F;hamas-israel-war-24&#x2F;all-art...</a><p>Probably this is due to confusion over what the term &quot;AI&quot; means. If you do some queries on a database, and call yourself a &quot;data scientist&quot;, and other people who call themselves data scientists do some AI, does that mean you&#x27;re doing AI? For left wing journalists who want to undermine the Israelis (the story originally appeared in the Guardian) it&#x27;d be easy to hear what you want to hear from your sources and conflate using data with using AI. This is the kind of blurring that happens all the time with apparently technical terms once they leave the tech world and especially once they enter journalism.</div><br/></div></div></div></div><div id="40364235" class="c"><input type="checkbox" id="c-40364235" checked=""/><div class="controls bullet"><span class="by">wolfd</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364016">parent</a><span>|</span><a href="#40364191">prev</a><span>|</span><a href="#40364283">next</a><span>|</span><label class="collapse" for="c-40364235">[-]</label><label class="expand" for="c-40364235">[1 more]</label></div><br/><div class="children"><div class="content">It’s absurd but LLMs for military targets is absolutely something that some companies are trying to sell regardless of the many known failure modes.<p><a href="https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;newsletters&#x2F;2023-07-05&#x2F;the-us-military-is-taking-generative-ai-out-for-a-spin" rel="nofollow">https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;newsletters&#x2F;2023-07-05&#x2F;the-us...</a><p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;XEM5qz__HOU" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;XEM5qz__HOU</a></div><br/></div></div><div id="40364283" class="c"><input type="checkbox" id="c-40364283" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364016">parent</a><span>|</span><a href="#40364235">prev</a><span>|</span><a href="#40364200">next</a><span>|</span><label class="collapse" for="c-40364283">[-]</label><label class="expand" for="c-40364283">[1 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Using LLMs for picking military targets is just absurd</i><p>You&#x27;d be surprised.<p>Not to mention it&#x27;s also used for military and intelligence &quot;analysis&quot;.<p>&gt;<i>using an LLM for high risk tasks like healthcare and picking targets in military operations still feels very far away</i><p>When immaturity and unfitness for purpose has ever stopped companies selling crap?</div><br/></div></div><div id="40364200" class="c"><input type="checkbox" id="c-40364200" checked=""/><div class="controls bullet"><span class="by">lhoff</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364016">parent</a><span>|</span><a href="#40364283">prev</a><span>|</span><a href="#40364187">next</a><span>|</span><label class="collapse" for="c-40364200">[-]</label><label class="expand" for="c-40364200">[3 more]</label></div><br/><div class="children"><div class="content">&gt;Using LLMs for picking military targets is just absurd. In the future<p>I guess the future is now then: 
<a href="https:&#x2F;&#x2F;www.theguardian.com&#x2F;world&#x2F;2023&#x2F;dec&#x2F;01&#x2F;the-gospel-how-israel-uses-ai-to-select-bombing-targets" rel="nofollow">https:&#x2F;&#x2F;www.theguardian.com&#x2F;world&#x2F;2023&#x2F;dec&#x2F;01&#x2F;the-gospel-how...</a><p>Excerpt:<p>&gt;Aviv Kochavi, who served as the head of the IDF until January, has said the target division is “powered by AI capabilities” and includes hundreds of officers and soldiers.<p>&gt;In an interview published before the war, he said it was “a machine that produces vast amounts of data more effectively than any human, and translates it into targets for attack”.<p>&gt;According to Kochavi, “once this machine was activated” in Israel’s 11-day war with Hamas in May 2021 it generated 100 targets a day. “To put that into perspective, in the past we would produce 50 targets in Gaza per year. Now, this machine produces 100 targets a single day, with 50% of them being attacked.”</div><br/><div id="40364367" class="c"><input type="checkbox" id="c-40364367" checked=""/><div class="controls bullet"><span class="by">agos</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364200">parent</a><span>|</span><a href="#40364187">next</a><span>|</span><label class="collapse" for="c-40364367">[-]</label><label class="expand" for="c-40364367">[2 more]</label></div><br/><div class="children"><div class="content">nothing in this says they used an LLM</div><br/><div id="40364508" class="c"><input type="checkbox" id="c-40364508" checked=""/><div class="controls bullet"><span class="by">throwthrowuknow</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364367">parent</a><span>|</span><a href="#40364187">next</a><span>|</span><label class="collapse" for="c-40364508">[-]</label><label class="expand" for="c-40364508">[1 more]</label></div><br/><div class="children"><div class="content">I guess he must have hallucinated that it was about LLMs</div><br/></div></div></div></div></div></div><div id="40364187" class="c"><input type="checkbox" id="c-40364187" checked=""/><div class="controls bullet"><span class="by">ExoticPearTree</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364016">parent</a><span>|</span><a href="#40364200">prev</a><span>|</span><a href="#40364554">next</a><span>|</span><label class="collapse" for="c-40364187">[-]</label><label class="expand" for="c-40364187">[1 more]</label></div><br/><div class="children"><div class="content">I use ChatGPT in particular to narrow down options when I do research, and it is very good at this. It wouldn&#x27;t be far-fetched to feed it a map, traffic patterns and ask it to do some analysis of &quot;what is the most likeliest place to hit&quot;? And then take it from there.</div><br/></div></div><div id="40364554" class="c"><input type="checkbox" id="c-40364554" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40364016">parent</a><span>|</span><a href="#40364187">prev</a><span>|</span><a href="#40363908">next</a><span>|</span><label class="collapse" for="c-40364554">[-]</label><label class="expand" for="c-40364554">[1 more]</label></div><br/><div class="children"><div class="content">&gt; picking targets in military operations<p>I&#x27;m 100% on the side of Israel having the right to defend itself, but as I understand it, they are already using &quot;AI&quot; to pick targets, and they adjust the threshold each day to meet quotas. I have no doubt that some day they&#x27;ll run somebody&#x27;s messages through chat gpt or similar and get the order: kill&#x2F;do not kill.</div><br/></div></div></div></div><div id="40363908" class="c"><input type="checkbox" id="c-40363908" checked=""/><div class="controls bullet"><span class="by">GuardianCaveman</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363639">parent</a><span>|</span><a href="#40364016">prev</a><span>|</span><a href="#40363728">next</a><span>|</span><label class="collapse" for="c-40363908">[-]</label><label class="expand" for="c-40363908">[2 more]</label></div><br/><div class="children"><div class="content">I was in a counter-intelligence unit briefly and there was a mathemtician who spoke to us about the work they were doing to pick targets with the idea that if you can only out one person, who would be the most disruptive. You have all these interconnected but mostly isolated terrorist cells that don&#x27;t know about each other except through a few people who may not be high up in the command but who are critical for the continuing cohesive existence of that terrorist group of cells and logistics etc.<p>So the military already was using math to pick targets, this is just the next logical step, albeit, scary as hell step.</div><br/><div id="40364005" class="c"><input type="checkbox" id="c-40364005" checked=""/><div class="controls bullet"><span class="by">jspank</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363908">parent</a><span>|</span><a href="#40363728">next</a><span>|</span><label class="collapse" for="c-40364005">[-]</label><label class="expand" for="c-40364005">[1 more]</label></div><br/><div class="children"><div class="content">In your scenario there were still individuals accountable for the decisions and their outcomes.<p>How are you supposed to say why a machine learning model produces different outputs from the same input? It&#x27;s just a black box.</div><br/></div></div></div></div><div id="40363728" class="c"><input type="checkbox" id="c-40363728" checked=""/><div class="controls bullet"><span class="by">rolandog</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363639">parent</a><span>|</span><a href="#40363908">prev</a><span>|</span><a href="#40363671">next</a><span>|</span><label class="collapse" for="c-40363728">[-]</label><label class="expand" for="c-40363728">[1 more]</label></div><br/><div class="children"><div class="content">&gt; or make surgery decisions?<p><pre><code>  Analyzing surgical field...
  Identified: open chest cavity, exposed internal organs
  Organs appear gooey, gelatinous, translucent pink
  Comparing to database of aquatic lifeforms...
  93% visual match found:
  Psychrolutes marcidus, common name &quot;blobfish&quot;
  Conclusion: Blobfish discovered inhabiting patient&#x27;s thoracic cavity
  Recommended action: Attempt to safely extract blobfish without damaging organs</code></pre></div><br/></div></div><div id="40363671" class="c"><input type="checkbox" id="c-40363671" checked=""/><div class="controls bullet"><span class="by">Arn_Thor</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363639">parent</a><span>|</span><a href="#40363728">prev</a><span>|</span><a href="#40364224">next</a><span>|</span><label class="collapse" for="c-40363671">[-]</label><label class="expand" for="c-40363671">[2 more]</label></div><br/><div class="children"><div class="content">If any regulator acts it will be the EU. The action, if it comes, will of course be very late, possibly years from now, when the horse has long left the stable.</div><br/><div id="40363696" class="c"><input type="checkbox" id="c-40363696" checked=""/><div class="controls bullet"><span class="by">sschueller</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363671">parent</a><span>|</span><a href="#40364224">next</a><span>|</span><label class="collapse" for="c-40363696">[-]</label><label class="expand" for="c-40363696">[1 more]</label></div><br/><div class="children"><div class="content">My only hope for the EU government is that they put and AI in charge and it accidentally becomes sentient...</div><br/></div></div></div></div><div id="40364224" class="c"><input type="checkbox" id="c-40364224" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363639">parent</a><span>|</span><a href="#40363671">prev</a><span>|</span><a href="#40363906">next</a><span>|</span><label class="collapse" for="c-40364224">[-]</label><label class="expand" for="c-40364224">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI is. Their TOS says don&#x27;t use it for that kind of shit.<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;policies&#x2F;usage-policies&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;policies&#x2F;usage-policies&#x2F;</a></div><br/></div></div><div id="40363906" class="c"><input type="checkbox" id="c-40363906" checked=""/><div class="controls bullet"><span class="by">histories</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363639">parent</a><span>|</span><a href="#40364224">prev</a><span>|</span><a href="#40363746">next</a><span>|</span><label class="collapse" for="c-40363906">[-]</label><label class="expand" for="c-40363906">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  OpenAI is selling this a a tutor for your kids.<p>The Diamond Age.</div><br/><div id="40364100" class="c"><input type="checkbox" id="c-40364100" checked=""/><div class="controls bullet"><span class="by">ipsin</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363906">parent</a><span>|</span><a href="#40363746">next</a><span>|</span><label class="collapse" for="c-40364100">[-]</label><label class="expand" for="c-40364100">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I find most offensive about the use of LLMs in education: it can readily produce something in the <i>shape</i> of a logical argument, without actually being correct.<p>I&#x27;m worried that a generation might learn that that&#x27;s good enough.</div><br/></div></div></div></div><div id="40363746" class="c"><input type="checkbox" id="c-40363746" checked=""/><div class="controls bullet"><span class="by">hehdhdjehehegwv</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363639">parent</a><span>|</span><a href="#40363906">prev</a><span>|</span><a href="#40363203">next</a><span>|</span><label class="collapse" for="c-40363746">[-]</label><label class="expand" for="c-40363746">[1 more]</label></div><br/><div class="children"><div class="content">Right now insurance companies make those decisions based on how your life affects the profit&#x2F;loss statement at the end of the quarter. (In the USA).<p>So it can’t really be worse if there’s just a RNG in a box. It may be better.</div><br/></div></div></div></div><div id="40363039" class="c"><input type="checkbox" id="c-40363039" checked=""/><div class="controls bullet"><span class="by">bckr</span><span>|</span><a href="#40362183">parent</a><span>|</span><a href="#40363203">prev</a><span>|</span><a href="#40363275">next</a><span>|</span><label class="collapse" for="c-40363039">[-]</label><label class="expand" for="c-40363039">[3 more]</label></div><br/><div class="children"><div class="content">Yeah I asked for an estimate of the percentage of the US population that lives in the DMV area (DC, Maryland, Virginia) and it was off by 50% of the actual answer, which I only realized when I realized I shouldn’t trust its estimate for anything important</div><br/><div id="40363805" class="c"><input type="checkbox" id="c-40363805" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363039">parent</a><span>|</span><a href="#40363275">next</a><span>|</span><label class="collapse" for="c-40363805">[-]</label><label class="expand" for="c-40363805">[2 more]</label></div><br/><div class="children"><div class="content">Those models still can&#x27;t reliably do arithmetic, so how could it possibly know that number unless it&#x27;s a commonly repeated fact?<p>Also: would you expect random people to fare any better?</div><br/><div id="40364214" class="c"><input type="checkbox" id="c-40364214" checked=""/><div class="controls bullet"><span class="by">chrischen</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363805">parent</a><span>|</span><a href="#40363275">next</a><span>|</span><label class="collapse" for="c-40364214">[-]</label><label class="expand" for="c-40364214">[1 more]</label></div><br/><div class="children"><div class="content">Arithmetic just happens to be something we can easily and reliably verify, so it becomes painfully obvious when LLMs are just stringing together some words that sound like the right answer.</div><br/></div></div></div></div></div></div><div id="40363275" class="c"><input type="checkbox" id="c-40363275" checked=""/><div class="controls bullet"><span class="by">kylebenzle</span><span>|</span><a href="#40362183">parent</a><span>|</span><a href="#40363039">prev</a><span>|</span><a href="#40360811">next</a><span>|</span><label class="collapse" for="c-40363275">[-]</label><label class="expand" for="c-40363275">[4 more]</label></div><br/><div class="children"><div class="content">What you are asking an llm to do here makes no sense.</div><br/><div id="40363280" class="c"><input type="checkbox" id="c-40363280" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363275">parent</a><span>|</span><a href="#40363364">next</a><span>|</span><label class="collapse" for="c-40363280">[-]</label><label class="expand" for="c-40363280">[1 more]</label></div><br/><div class="children"><div class="content">Why not? It seems like a natural language understanding task</div><br/></div></div><div id="40363364" class="c"><input type="checkbox" id="c-40363364" checked=""/><div class="controls bullet"><span class="by">marshray</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363275">parent</a><span>|</span><a href="#40363280">prev</a><span>|</span><a href="#40364501">next</a><span>|</span><label class="collapse" for="c-40363364">[-]</label><label class="expand" for="c-40363364">[1 more]</label></div><br/><div class="children"><div class="content">You haven&#x27;t seen the promotion of the use of LM AI for handling legal documents?<p>It&#x27;s purported to be a major use case.</div><br/></div></div><div id="40364501" class="c"><input type="checkbox" id="c-40364501" checked=""/><div class="controls bullet"><span class="by">cmrdporcupine</span><span>|</span><a href="#40362183">root</a><span>|</span><a href="#40363275">parent</a><span>|</span><a href="#40363364">prev</a><span>|</span><a href="#40360811">next</a><span>|</span><label class="collapse" for="c-40364501">[-]</label><label class="expand" for="c-40364501">[1 more]</label></div><br/><div class="children"><div class="content">You might be right but I&#x27;ve lost count of the number of startups I&#x27;ve heard of trying to do this for legal documents.</div><br/></div></div></div></div></div></div><div id="40360811" class="c"><input type="checkbox" id="c-40360811" checked=""/><div class="controls bullet"><span class="by">irthomasthomas</span><span>|</span><a href="#40362183">prev</a><span>|</span><a href="#40360697">next</a><span>|</span><label class="collapse" for="c-40360811">[-]</label><label class="expand" for="c-40360811">[15 more]</label></div><br/><div class="children"><div class="content">This is based on a limericks dataset published in 2021. <a href="https:&#x2F;&#x2F;zenodo.org&#x2F;records&#x2F;5722527" rel="nofollow">https:&#x2F;&#x2F;zenodo.org&#x2F;records&#x2F;5722527</a><p>I think it very likely that gpt-4o was trained on this. I mean, why would you not? Innnput, innnput, Johnny five need more tokens.<p>I wonder why the NIAN team don&#x27;t  generate their limericks using different models, and check to make sure they&#x27;re not in the dataset? Then you&#x27;d know the models couldn&#x27;t possibly be trained on them.</div><br/><div id="40364568" class="c"><input type="checkbox" id="c-40364568" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#40360811">parent</a><span>|</span><a href="#40360918">next</a><span>|</span><label class="collapse" for="c-40364568">[-]</label><label class="expand" for="c-40364568">[1 more]</label></div><br/><div class="children"><div class="content">NIAN is a very cool idea, but why not simply translate it into N different languages (you even can mix services, e.g. deepl&#x2F;google translate&#x2F;LLMs themselves) and ask about them that way?</div><br/></div></div><div id="40360918" class="c"><input type="checkbox" id="c-40360918" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360811">parent</a><span>|</span><a href="#40364568">prev</a><span>|</span><a href="#40363575">next</a><span>|</span><label class="collapse" for="c-40360918">[-]</label><label class="expand" for="c-40360918">[12 more]</label></div><br/><div class="children"><div class="content">I tested the LLMs to make sure they could not answer the questions unless the limerick was given to them.  Other than 4o, they do very badly on this benchmark, so I don&#x27;t think the test is invalidated by their training.</div><br/><div id="40364591" class="c"><input type="checkbox" id="c-40364591" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40360918">parent</a><span>|</span><a href="#40361391">next</a><span>|</span><label class="collapse" for="c-40364591">[-]</label><label class="expand" for="c-40364591">[1 more]</label></div><br/><div class="children"><div class="content">It would be interesting to know how it acts if you ask it about one that <i>isn&#x27;t</i> present, or even lie to it (e.g. take a limerick that is present but change some words and ask it to complete it)<p>Maybe some models hallucinate or even ignore your mistake vs others correcting it (depending on the context ignoring or calling out the error might be the more &#x27;correct&#x27; approach)<p>Using limericks is a very nifty idea!</div><br/></div></div><div id="40361391" class="c"><input type="checkbox" id="c-40361391" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40360918">parent</a><span>|</span><a href="#40364591">prev</a><span>|</span><a href="#40363575">next</a><span>|</span><label class="collapse" for="c-40361391">[-]</label><label class="expand" for="c-40361391">[10 more]</label></div><br/><div class="children"><div class="content">Why wouldn&#x27;t it still be invalidated by it if it was indeed trained on it?  The others may do worse and may or may not have been trained on it, but them failing on ititself doesn&#x27;t imply 4o can do this well without the task being present in the corpus.</div><br/><div id="40362516" class="c"><input type="checkbox" id="c-40362516" checked=""/><div class="controls bullet"><span class="by">djsjajah</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40361391">parent</a><span>|</span><a href="#40361419">next</a><span>|</span><label class="collapse" for="c-40362516">[-]</label><label class="expand" for="c-40362516">[1 more]</label></div><br/><div class="children"><div class="content">A better test would be to see if it can still answer the question if you just exclude the limerick for that answer. Having a bunch of limericks in the context window will make it &quot;think&quot; about all of the limericks it &quot;knows&quot;.</div><br/></div></div><div id="40361419" class="c"><input type="checkbox" id="c-40361419" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40361391">parent</a><span>|</span><a href="#40362516">prev</a><span>|</span><a href="#40363575">next</a><span>|</span><label class="collapse" for="c-40361419">[-]</label><label class="expand" for="c-40361419">[8 more]</label></div><br/><div class="children"><div class="content">It can&#x27;t answer the questions without the limericks in the prompt. The benchmark is to establish how well it uses the context window. For example, I just asked it &quot;What is sought by the English top brass?&quot;.  The answer from the limerick is &quot;Cranberry glass&quot; and 4o answers correctly when given the associated limerick once out of 2500+ limericks.<p>However, without the limerick, 4o responded with: &quot;The term &quot;English top brass&quot; typically refers to high-ranking officials or leaders within the British government, military, or other institutions. What they seek can vary widely depending on the context and the specific goals of their roles. Here are some general pursuits that might be sought by such individuals:<p>National Security: Ensuring the safety and security of the United Kingdom from internal and external threats is a primary concern. This involves defense strategies, intelligence operations, and counter-terrorism efforts.<p>Economic Stability: High-ranking officials often focus on policies and initiatives aimed at maintaining and improving the country’s economic health. This includes managing inflation, unemployment, trade relations, and economic growth.<p>Political Influence: Top brass often seek to maintain or expand their influence both domestically and internationally. This can involve diplomacy, forming alliances, and participating in international organizations like the United Nations or NATO.<p>Social Cohesion: Ensuring social stability and addressing issues such as inequality, healthcare, education, and social services are critical. This can involve implementing policies that promote social welfare and cohesion.<p>Public Policy Implementation: Leaders are responsible for developing and implementing policies that reflect the government’s priorities. This includes legislation, regulatory frameworks, and public administration.<p>Technological Advancement: Keeping the nation at the forefront of technological innovation is often a priority. This includes investments in research and development, supporting tech industries, and ensuring cybersecurity.<p>Environmental Sustainability: Addressing climate change and promoting sustainable practices are increasingly important. This includes policies aimed at reducing carbon emissions, protecting natural resources, and transitioning to renewable energy sources.<p>Cultural and Heritage Preservation: Protecting and promoting the country’s cultural heritage and national identity can also be a focus. This includes supporting the arts, preserving historical sites, and promoting cultural initiatives.<p>These pursuits are shaped by the current political climate, global trends, and the specific priorities of the leaders in question. Would you like more detailed information on any of these areas?&quot;</div><br/><div id="40361956" class="c"><input type="checkbox" id="c-40361956" checked=""/><div class="controls bullet"><span class="by">furyofantares</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40361419">parent</a><span>|</span><a href="#40361813">next</a><span>|</span><label class="collapse" for="c-40361956">[-]</label><label class="expand" for="c-40361956">[2 more]</label></div><br/><div class="children"><div class="content">This sounds dumb - but what if you give it all the limericks MINUS the one you want it to answer about?<p>I think it will fail, but this actually seems like the cleanest way to demonstrate it.</div><br/><div id="40363254" class="c"><input type="checkbox" id="c-40363254" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40361956">parent</a><span>|</span><a href="#40361813">next</a><span>|</span><label class="collapse" for="c-40363254">[-]</label><label class="expand" for="c-40363254">[1 more]</label></div><br/><div class="children"><div class="content">Still not enough to rule out training on the data in the task affecting the task.  It may be that it couldn&#x27;t find it without it appearing in the training data, but even with that it also needs it in its context window to bridge enough connections from the training or whatever to do well on the task.</div><br/></div></div></div></div><div id="40361813" class="c"><input type="checkbox" id="c-40361813" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40361419">parent</a><span>|</span><a href="#40361956">prev</a><span>|</span><a href="#40361455">next</a><span>|</span><label class="collapse" for="c-40361813">[-]</label><label class="expand" for="c-40361813">[3 more]</label></div><br/><div class="children"><div class="content">Maybe if you tell it to pull the answer from a limerick instead of generally asking?<p>Edit: Ok no, I tried giving it a whole bunch of hints, and it was just making stuff up that was completely unrelated. Even directly pointing it at the original dataset didn’t help.</div><br/><div id="40362784" class="c"><input type="checkbox" id="c-40362784" checked=""/><div class="controls bullet"><span class="by">causal</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40361813">parent</a><span>|</span><a href="#40362246">next</a><span>|</span><label class="collapse" for="c-40362784">[-]</label><label class="expand" for="c-40362784">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I also tried to get it to complete some limericks from the dataset. Curiously it believed it had heard of the limerick but would then recite a hallucination.<p>So the good news is that the NIAN score might be real, bad news is you can&#x27;t rely on it to know what it knows.</div><br/></div></div><div id="40362246" class="c"><input type="checkbox" id="c-40362246" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40361813">parent</a><span>|</span><a href="#40362784">prev</a><span>|</span><a href="#40361455">next</a><span>|</span><label class="collapse" for="c-40362246">[-]</label><label class="expand" for="c-40362246">[1 more]</label></div><br/><div class="children"><div class="content">Come on guys, it’s already far beyond superhuman if it’s able to do that and so quickly. So if it’s not able to do that, what’s the big deal? If you’re asking for AG.I., then it seems that the model performs beyond it in these areas.</div><br/></div></div></div></div><div id="40363264" class="c"><input type="checkbox" id="c-40363264" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#40360811">root</a><span>|</span><a href="#40361419">parent</a><span>|</span><a href="#40361455">prev</a><span>|</span><a href="#40363575">next</a><span>|</span><label class="collapse" for="c-40363264">[-]</label><label class="expand" for="c-40363264">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It can&#x27;t answer the questions without the limericks in the prompt.<p>Maybe I can&#x27;t solve a bunch of mostly memorized math problems without a visual mnemonic aid.  Someone seeing me fail the problems without the visual aid doesn&#x27;t rule out me having partly memorized solutions.</div><br/></div></div></div></div></div></div></div></div><div id="40363575" class="c"><input type="checkbox" id="c-40363575" checked=""/><div class="controls bullet"><span class="by">internet101010</span><span>|</span><a href="#40360811">parent</a><span>|</span><a href="#40360918">prev</a><span>|</span><a href="#40360697">next</a><span>|</span><label class="collapse" for="c-40363575">[-]</label><label class="expand" for="c-40363575">[1 more]</label></div><br/><div class="children"><div class="content">No disassemble!</div><br/></div></div></div></div><div id="40360697" class="c"><input type="checkbox" id="c-40360697" checked=""/><div class="controls bullet"><span class="by">thorum</span><span>|</span><a href="#40360811">prev</a><span>|</span><a href="#40359937">next</a><span>|</span><label class="collapse" for="c-40360697">[-]</label><label class="expand" for="c-40360697">[3 more]</label></div><br/><div class="children"><div class="content">The needle in the haystack test gives a very limited view of the model’s actual long context capabilities. It’s mostly used because early models were terrible at it and it’s easy to test. In fact, most recent models now do pretty good at this one task, but in practice, their ability to do anything complex drops off hugely after 32K tokens.<p>RULER is a much better test:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;hsiehjackson&#x2F;RULER">https:&#x2F;&#x2F;github.com&#x2F;hsiehjackson&#x2F;RULER</a><p>&gt; Despite achieving nearly perfect performance on the vanilla needle-in-a-haystack (NIAH) test, all models (except for Gemini-1.5-pro) exhibit large degradation on tasks in RULER as sequence length increases.<p>&gt; While all models claim context size of 32k tokens or greater (except for Llama3), only half of them can effectively handle sequence length of 32K by exceeding a qualitative threshold, Llama2-7b performance at 4K (85.6%). The performance exceeding the threshold is underlined.</div><br/><div id="40362887" class="c"><input type="checkbox" id="c-40362887" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360697">parent</a><span>|</span><a href="#40362298">next</a><span>|</span><label class="collapse" for="c-40362887">[-]</label><label class="expand" for="c-40362887">[1 more]</label></div><br/><div class="children"><div class="content">The models benchmarked by RULER do worse in needle in a needlestack.  It will be interested to see how 4o does with RULER.</div><br/></div></div><div id="40362298" class="c"><input type="checkbox" id="c-40362298" checked=""/><div class="controls bullet"><span class="by">WhitneyLand</span><span>|</span><a href="#40360697">parent</a><span>|</span><a href="#40362887">prev</a><span>|</span><a href="#40359937">next</a><span>|</span><label class="collapse" for="c-40362298">[-]</label><label class="expand" for="c-40362298">[1 more]</label></div><br/><div class="children"><div class="content">Maybe, but<p>1. The article is not about NIHS it’s their own variation so it could be more relevant.<p>2. The whole claim of the article is that Gpt4o does better, but the test your pointing to hasn’t benchmarked it.</div><br/></div></div></div></div><div id="40359937" class="c"><input type="checkbox" id="c-40359937" checked=""/><div class="controls bullet"><span class="by">19h</span><span>|</span><a href="#40360697">prev</a><span>|</span><a href="#40364582">next</a><span>|</span><label class="collapse" for="c-40359937">[-]</label><label class="expand" for="c-40359937">[30 more]</label></div><br/><div class="children"><div class="content">I&#x27;d like to see this for Gemini Pro 1.5 -- I threw the entirety of Moby Dick at it last week, and at one point all books Byung Chul-Han has ever published, and it both cases it was able to return the single part of a sentence that mentioned or answered my question verbatim, every single time, without any hallucinations.</div><br/><div id="40360910" class="c"><input type="checkbox" id="c-40360910" checked=""/><div class="controls bullet"><span class="by">nsagent</span><span>|</span><a href="#40359937">parent</a><span>|</span><a href="#40360110">next</a><span>|</span><label class="collapse" for="c-40360910">[-]</label><label class="expand" for="c-40360910">[9 more]</label></div><br/><div class="children"><div class="content">A number of people in my lab do research into long context evaluation of LLMs for works of fiction. The likelihood is very high that Moby Dick is in the training data. Instead the people in my lab have explored recently published books to avoid these issues.<p>See BooookScore (<a href="https:&#x2F;&#x2F;openreview.net&#x2F;forum?id=7Ttk3RzDeu" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;forum?id=7Ttk3RzDeu</a>) which was just presented at ICLR last week and FABLES (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2404.01261" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2404.01261</a>) a recent preprint.</div><br/><div id="40362289" class="c"><input type="checkbox" id="c-40362289" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360910">parent</a><span>|</span><a href="#40361917">next</a><span>|</span><label class="collapse" for="c-40362289">[-]</label><label class="expand" for="c-40362289">[2 more]</label></div><br/><div class="children"><div class="content">I suppose the question then is - if you finetune on your own data (eg internal wiki) does it then retain the near-perfect recall?<p>Could be a simpler setup than RAG for slow-changing documentation, especially for read-heavy cases.</div><br/><div id="40363431" class="c"><input type="checkbox" id="c-40363431" checked=""/><div class="controls bullet"><span class="by">k__</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40362289">parent</a><span>|</span><a href="#40361917">next</a><span>|</span><label class="collapse" for="c-40363431">[-]</label><label class="expand" for="c-40363431">[1 more]</label></div><br/><div class="children"><div class="content"><i>&quot;if you finetune on your own data (eg internal wiki) does it then retain the near-perfect recall&quot;</i><p>No, that&#x27;s one of the primary reasons for RAG.</div><br/></div></div></div></div><div id="40361917" class="c"><input type="checkbox" id="c-40361917" checked=""/><div class="controls bullet"><span class="by">robbiep</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360910">parent</a><span>|</span><a href="#40362289">prev</a><span>|</span><a href="#40361938">next</a><span>|</span><label class="collapse" for="c-40361917">[-]</label><label class="expand" for="c-40361917">[5 more]</label></div><br/><div class="children"><div class="content">I’m not involved in the space, but it seems to me that having a model, in particular a massive model, exposed to a corpus of text like a book in the training data would have very minimal impact. I’m aware that people have been able to return data ‘out of the shadows’ pf the training data but to my mind a model being mildly influenced by the weights between different words in this text hardly constitute hard recall, if anything it now ‘knows’ a little of the linguistic style of the authour.<p>How far off am I?</div><br/><div id="40362405" class="c"><input type="checkbox" id="c-40362405" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40361917">parent</a><span>|</span><a href="#40362821">next</a><span>|</span><label class="collapse" for="c-40362405">[-]</label><label class="expand" for="c-40362405">[3 more]</label></div><br/><div class="children"><div class="content">It depends on how many times it had seen that text during training. For example, GPT-4 can reproduce ayats from the Quran word for word in both Arabic and English. It can also reproduce the Navy SEAL copypasta complete with all the typos.</div><br/><div id="40362669" class="c"><input type="checkbox" id="c-40362669" checked=""/><div class="controls bullet"><span class="by">kaibee</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40362405">parent</a><span>|</span><a href="#40362421">next</a><span>|</span><label class="collapse" for="c-40362669">[-]</label><label class="expand" for="c-40362669">[1 more]</label></div><br/><div class="children"><div class="content">Poe&#x27;s &quot;The Raven&quot; also.</div><br/></div></div><div id="40362421" class="c"><input type="checkbox" id="c-40362421" checked=""/><div class="controls bullet"><span class="by">19h</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40362405">parent</a><span>|</span><a href="#40362669">prev</a><span>|</span><a href="#40362821">next</a><span>|</span><label class="collapse" for="c-40362421">[-]</label><label class="expand" for="c-40362421">[1 more]</label></div><br/><div class="children"><div class="content">Brothers in username.. :-)</div><br/></div></div></div></div><div id="40362821" class="c"><input type="checkbox" id="c-40362821" checked=""/><div class="controls bullet"><span class="by">Salgat</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40361917">parent</a><span>|</span><a href="#40362405">prev</a><span>|</span><a href="#40361938">next</a><span>|</span><label class="collapse" for="c-40362821">[-]</label><label class="expand" for="c-40362821">[1 more]</label></div><br/><div class="children"><div class="content">Remember, it&#x27;s also trained on countless internet discussions and papers on the book.</div><br/></div></div></div></div><div id="40361938" class="c"><input type="checkbox" id="c-40361938" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360910">parent</a><span>|</span><a href="#40361917">prev</a><span>|</span><a href="#40360110">next</a><span>|</span><label class="collapse" for="c-40361938">[-]</label><label class="expand" for="c-40361938">[1 more]</label></div><br/><div class="children"><div class="content">HN post re: FABLES: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39982362">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39982362</a><p>FABLES&#x2F;booklist.md: <a href="https:&#x2F;&#x2F;github.com&#x2F;mungg&#x2F;FABLES&#x2F;blob&#x2F;main&#x2F;booklist.md">https:&#x2F;&#x2F;github.com&#x2F;mungg&#x2F;FABLES&#x2F;blob&#x2F;main&#x2F;booklist.md</a><p>&#x2F;gscholar_related? FABLES: 
<a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?q=related:Y-Hx-kplbEUJ:scholar.google.com&#x2F;&amp;scioq=&amp;hl=en&amp;as_sdt=0,43" rel="nofollow">https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?q=related:Y-Hx-kplbEUJ:sc...</a><p>&#x2F;gscholar_citations? BoookScore: 
<a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?cites=17968620361685249119&amp;as_sdt=5,43&amp;sciodt=0,43&amp;hl=en" rel="nofollow">https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?cites=1796862036168524911...</a><p>...<p>From that one day awhile ago: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38347868#38354679">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38347868#38354679</a> :<p>&gt; <i>&quot;LLMs cannot find reasoning errors, but can correct them&quot; [ <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.08516" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.08516</a> ] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38353285">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38353285</a> </i></div><br/></div></div></div></div><div id="40360110" class="c"><input type="checkbox" id="c-40360110" checked=""/><div class="controls bullet"><span class="by">Fernicia</span><span>|</span><a href="#40359937">parent</a><span>|</span><a href="#40360910">prev</a><span>|</span><a href="#40360687">next</a><span>|</span><label class="collapse" for="c-40360110">[-]</label><label class="expand" for="c-40360110">[10 more]</label></div><br/><div class="children"><div class="content">But this content is presumably in its training set, no? I&#x27;d be interested if you did the same task for a collection of books published more recently than the model&#x27;s last release.</div><br/><div id="40360247" class="c"><input type="checkbox" id="c-40360247" checked=""/><div class="controls bullet"><span class="by">19h</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360110">parent</a><span>|</span><a href="#40360633">next</a><span>|</span><label class="collapse" for="c-40360247">[-]</label><label class="expand" for="c-40360247">[5 more]</label></div><br/><div class="children"><div class="content">To test this hypothesis, I just took the complete book &quot;Advances in Green and Sustainable Nanomaterials&quot; [0] and pasted it into the prompt, asking Gemini: &quot;What absorbs thermal radiations and converts it into electrical signals?&quot;.<p>It replied: &quot;The text indicates that <i>graphene sheets</i> present high optical transparency and are able to absorb thermal radiations with high efficacy. They can then convert these radiations into electrical signals efficiently.&quot;.<p>Screenshot of the PDF with the relevant sentence highlighted: <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;G3FnYEn.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;G3FnYEn.png</a><p>[0] <a href="https:&#x2F;&#x2F;www.routledge.com&#x2F;Advances-in-Green-and-Sustainable-Nanomaterials-Applications-in-Energy-Biomedicine-Agriculture-and-Environmental-Science&#x2F;Goyal-Kulkarni&#x2F;p&#x2F;book&#x2F;9781774911662" rel="nofollow">https:&#x2F;&#x2F;www.routledge.com&#x2F;Advances-in-Green-and-Sustainable-...</a></div><br/><div id="40361039" class="c"><input type="checkbox" id="c-40361039" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360247">parent</a><span>|</span><a href="#40362686">next</a><span>|</span><label class="collapse" for="c-40361039">[-]</label><label class="expand" for="c-40361039">[3 more]</label></div><br/><div class="children"><div class="content">Ask it what material absorbs “infrared light” efficiently.<p>To me, that’s useful intelligence. I can already search text for verbatim matches, I want the AI to <i>understand</i> that “thermal radiations” and “infrared light” are the same thing.</div><br/><div id="40361395" class="c"><input type="checkbox" id="c-40361395" checked=""/><div class="controls bullet"><span class="by">19h</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40361039">parent</a><span>|</span><a href="#40361356">next</a><span>|</span><label class="collapse" for="c-40361395">[-]</label><label class="expand" for="c-40361395">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Answer the following question using verbatim quotes from the text above: &quot;What material absorbs infrared light efficiently?&quot;<p>&gt; &quot;Graphene is a promising material that could change the world, with unlimited potential for wide industrial applications in various fields... It is the thinnest known material with zero bandgaps and is incredibly strong, almost 200 times stronger than steel. Moreover, graphene is a good conductor of heat and electricity with <i>very interesting light absorption properties</i>.&quot;<p>Interestingly, the first sentence of the response actually occures directly after the latter part of the response in the original text.<p>Screenshot from the document: <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;5vsVm5g.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;5vsVm5g.png</a>.<p>Edit: asking it <i>&quot;What absorbs infrared light and converts it into electrical signals?&quot;</i> yields <i>&quot;Graphene sheets are highly transparent presenting high optical transparency, which absorbs thermal radiations with high efficacy and converts it into electrical signals efficiently.&quot;</i> verbatim.</div><br/></div></div><div id="40361356" class="c"><input type="checkbox" id="c-40361356" checked=""/><div class="controls bullet"><span class="by">tristor</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40361039">parent</a><span>|</span><a href="#40361395">prev</a><span>|</span><a href="#40362686">next</a><span>|</span><label class="collapse" for="c-40361356">[-]</label><label class="expand" for="c-40361356">[1 more]</label></div><br/><div class="children"><div class="content">Fair point, but I also think something that&#x27;s &#x2F;really&#x2F; clear is that LLMs don&#x27;t understand (and probably cannot).  It&#x27;s doing highly contextual text retrieval based on natural language processing for the query, it&#x27;s not understanding what the paper means and producing insights.</div><br/></div></div></div></div><div id="40362686" class="c"><input type="checkbox" id="c-40362686" checked=""/><div class="controls bullet"><span class="by">kaibee</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360247">parent</a><span>|</span><a href="#40361039">prev</a><span>|</span><a href="#40360633">next</a><span>|</span><label class="collapse" for="c-40362686">[-]</label><label class="expand" for="c-40362686">[1 more]</label></div><br/><div class="children"><div class="content">Honestly I think testing these on fiction books would be more impressive.  The graphene thing I&#x27;m sure shows up in some research papers.</div><br/></div></div></div></div><div id="40360633" class="c"><input type="checkbox" id="c-40360633" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360110">parent</a><span>|</span><a href="#40360247">prev</a><span>|</span><a href="#40360190">next</a><span>|</span><label class="collapse" for="c-40360633">[-]</label><label class="expand" for="c-40360633">[1 more]</label></div><br/><div class="children"><div class="content">Gemini works with brand new books too; I&#x27;ve seen multiple demonstrations of it. I&#x27;ll try hunting one down. Side note: this experiment is still insightful even using model training material. Just compare its performance <i>with</i> the uploaded book(s) to <i>without.</i></div><br/></div></div><div id="40360190" class="c"><input type="checkbox" id="c-40360190" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360110">parent</a><span>|</span><a href="#40360633">prev</a><span>|</span><a href="#40360687">next</a><span>|</span><label class="collapse" for="c-40360190">[-]</label><label class="expand" for="c-40360190">[3 more]</label></div><br/><div class="children"><div class="content">I would <i>hope</i> that Byung-Chul Han would not be in the training set (at least not without his permission), given he&#x27;s still alive and not only is the legal question still open but it&#x27;s also definitely rude.<p>This doesn&#x27;t mean you&#x27;re wrong, though.</div><br/><div id="40360244" class="c"><input type="checkbox" id="c-40360244" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360190">parent</a><span>|</span><a href="#40360687">next</a><span>|</span><label class="collapse" for="c-40360244">[-]</label><label class="expand" for="c-40360244">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s pretty easy to confirm that copywritten material is in the training data. See the NYT lawsuit against OpenAI for example.</div><br/><div id="40360762" class="c"><input type="checkbox" id="c-40360762" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360244">parent</a><span>|</span><a href="#40360687">next</a><span>|</span><label class="collapse" for="c-40360762">[-]</label><label class="expand" for="c-40360762">[1 more]</label></div><br/><div class="children"><div class="content">Part of that back-and-forth is the claim &quot;this specific text was copied a lot all over the internet making it show up more in the output&quot;, and <i>that</i> means it&#x27;s <i>not</i> a useful guide to things where one copy was added to The Pile and not removed when training the model.<p>(Or worse, that Google already had a copy because of Google Books and didn&#x27;t think &quot;might training on this explode in our face like that thing with the Street View WiFi scanning?&quot;)</div><br/></div></div></div></div></div></div></div></div><div id="40360687" class="c"><input type="checkbox" id="c-40360687" checked=""/><div class="controls bullet"><span class="by">DominikPeters</span><span>|</span><a href="#40359937">parent</a><span>|</span><a href="#40360110">prev</a><span>|</span><a href="#40359960">next</a><span>|</span><label class="collapse" for="c-40360687">[-]</label><label class="expand" for="c-40360687">[2 more]</label></div><br/><div class="children"><div class="content">Just put the 2500 example linked on the article through Gemini 1.5 <i>Flash</i> and it answered correctly (&quot;The tree has diseased leaves and its bark is peeling.&quot;) <a href="https:&#x2F;&#x2F;aistudio.google.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aistudio.google.com&#x2F;</a></div><br/><div id="40360923" class="c"><input type="checkbox" id="c-40360923" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360687">parent</a><span>|</span><a href="#40359960">next</a><span>|</span><label class="collapse" for="c-40360923">[-]</label><label class="expand" for="c-40360923">[1 more]</label></div><br/><div class="children"><div class="content">Interesting!</div><br/></div></div></div></div><div id="40359960" class="c"><input type="checkbox" id="c-40359960" checked=""/><div class="controls bullet"><span class="by">parrt</span><span>|</span><a href="#40359937">parent</a><span>|</span><a href="#40360687">prev</a><span>|</span><a href="#40359992">next</a><span>|</span><label class="collapse" for="c-40359960">[-]</label><label class="expand" for="c-40359960">[3 more]</label></div><br/><div class="children"><div class="content">Wow. Cool. I have access to that model and have also seen some impressive context extraction.  It also gave a really good summary of a large code base that I dumped in.  I saw somebody analyze a huge log file, but we really need something like this needle in a needlestack to help identify when models might be missing something.  At the very least, this could give model developers something to analyze their proposed models.</div><br/><div id="40360092" class="c"><input type="checkbox" id="c-40360092" checked=""/><div class="controls bullet"><span class="by">19h</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40359960">parent</a><span>|</span><a href="#40359992">next</a><span>|</span><label class="collapse" for="c-40360092">[-]</label><label class="expand" for="c-40360092">[2 more]</label></div><br/><div class="children"><div class="content">Funnily enough I ran a 980k token log dump against Gemini Pro 1.5 yesterday to investigate an error scenario and it found a single incident of a 429 error being returned by a third-party API provider while reasoning that &quot;based on the file provided and the information that this log file is aggregated of all instances of the service in question, it seems unlikely that a rate limit would be triggered, and additional investigation may be appropriate&quot;, and it turned out the service had implemented a block against AWS IPs, breaking a system that loads press data from said API provider, leaving the customer who was affected by it without press data -- we didn&#x27;t even notice or investigate that, and Gemini just randomly mentioned it without being prompted for that.</div><br/><div id="40360103" class="c"><input type="checkbox" id="c-40360103" checked=""/><div class="controls bullet"><span class="by">parrt</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360092">parent</a><span>|</span><a href="#40359992">next</a><span>|</span><label class="collapse" for="c-40360103">[-]</label><label class="expand" for="c-40360103">[1 more]</label></div><br/><div class="children"><div class="content">That definitely makes it seem like it&#x27;s noticing a great deal of its context window.  impressive.</div><br/></div></div></div></div></div></div><div id="40359992" class="c"><input type="checkbox" id="c-40359992" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40359937">parent</a><span>|</span><a href="#40359960">prev</a><span>|</span><a href="#40361199">next</a><span>|</span><label class="collapse" for="c-40359992">[-]</label><label class="expand" for="c-40359992">[3 more]</label></div><br/><div class="children"><div class="content">If I had access to Gemini with a reasonable token rate limit, I would be happy to test Gemini.  I have had good results with it in other situations.</div><br/><div id="40360065" class="c"><input type="checkbox" id="c-40360065" checked=""/><div class="controls bullet"><span class="by">cj</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40359992">parent</a><span>|</span><a href="#40361199">next</a><span>|</span><label class="collapse" for="c-40360065">[-]</label><label class="expand" for="c-40360065">[2 more]</label></div><br/><div class="children"><div class="content">What version of Gemini is built into Google Workspace? (I just got the ability <i>today</i> to ask Gemini anything about emails in my work Gmail account, which seems like something that would require a large context window)</div><br/><div id="40360271" class="c"><input type="checkbox" id="c-40360271" checked=""/><div class="controls bullet"><span class="by">underlines</span><span>|</span><a href="#40359937">root</a><span>|</span><a href="#40360065">parent</a><span>|</span><a href="#40361199">next</a><span>|</span><label class="collapse" for="c-40360271">[-]</label><label class="expand" for="c-40360271">[1 more]</label></div><br/><div class="children"><div class="content">Such tasks don&#x27;t need a large context window. Just good RAG.</div><br/></div></div></div></div></div></div><div id="40361199" class="c"><input type="checkbox" id="c-40361199" checked=""/><div class="controls bullet"><span class="by">causality0</span><span>|</span><a href="#40359937">parent</a><span>|</span><a href="#40359992">prev</a><span>|</span><a href="#40360179">next</a><span>|</span><label class="collapse" for="c-40361199">[-]</label><label class="expand" for="c-40361199">[1 more]</label></div><br/><div class="children"><div class="content">Man, we are like 2-5 years away from being able to feed in an ePub and get an accurate graphic novel version in minutes. I am so ready to look at four thousand paintings of Tolkien trees.</div><br/></div></div></div></div><div id="40364582" class="c"><input type="checkbox" id="c-40364582" checked=""/><div class="controls bullet"><span class="by">tartrate</span><span>|</span><a href="#40359937">prev</a><span>|</span><a href="#40360003">next</a><span>|</span><label class="collapse" for="c-40364582">[-]</label><label class="expand" for="c-40364582">[1 more]</label></div><br/><div class="children"><div class="content">Are there any prompts&#x2F;tests about recalling multiple needles (spread out) at once?<p>For example, each needle could be a piece to a logic puzzle.</div><br/></div></div><div id="40360003" class="c"><input type="checkbox" id="c-40360003" checked=""/><div class="controls bullet"><span class="by">youssefabdelm</span><span>|</span><a href="#40364582">prev</a><span>|</span><a href="#40360954">next</a><span>|</span><label class="collapse" for="c-40360003">[-]</label><label class="expand" for="c-40360003">[18 more]</label></div><br/><div class="children"><div class="content">Someone needs to come up with a &quot;synthesis from haystack&quot; test that tests not just retrieval but depth of understanding, connections, abstractions across diverse information.<p>When a person reads a book, they have an &quot;overall intuition&quot; about it. We need some way to quantify this. Needle in haystack tests feel like a simple test that doesn&#x27;t go far enough.</div><br/><div id="40360401" class="c"><input type="checkbox" id="c-40360401" checked=""/><div class="controls bullet"><span class="by">jddj</span><span>|</span><a href="#40360003">parent</a><span>|</span><a href="#40360534">next</a><span>|</span><label class="collapse" for="c-40360401">[-]</label><label class="expand" for="c-40360401">[6 more]</label></div><br/><div class="children"><div class="content">An elaborate Agatha Christie style whodunit, with a series of plot-twists and alibis which can be chopped off the end of the piece to modify who is the most likely suspect</div><br/><div id="40360547" class="c"><input type="checkbox" id="c-40360547" checked=""/><div class="controls bullet"><span class="by">jddj</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360401">parent</a><span>|</span><a href="#40360534">next</a><span>|</span><label class="collapse" for="c-40360547">[-]</label><label class="expand" for="c-40360547">[5 more]</label></div><br/><div class="children"><div class="content">Or a spot the difference.<p>Generate 1000 generic facts about Alice and the same 1000 facts about Eve. Randomise the order and change one minor detail then ask how they differ.</div><br/><div id="40362660" class="c"><input type="checkbox" id="c-40362660" checked=""/><div class="controls bullet"><span class="by">youssefabdelm</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360547">parent</a><span>|</span><a href="#40360924">next</a><span>|</span><label class="collapse" for="c-40362660">[-]</label><label class="expand" for="c-40362660">[1 more]</label></div><br/><div class="children"><div class="content">That seems to go back in the direction of needle in the haystack again</div><br/></div></div><div id="40360924" class="c"><input type="checkbox" id="c-40360924" checked=""/><div class="controls bullet"><span class="by">pushedx</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360547">parent</a><span>|</span><a href="#40362660">prev</a><span>|</span><a href="#40360534">next</a><span>|</span><label class="collapse" for="c-40360924">[-]</label><label class="expand" for="c-40360924">[3 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    sort alice.txt | diff - &lt;(sort eve.txt)
</code></pre>
That&#x27;s not a task for an LLM</div><br/><div id="40361018" class="c"><input type="checkbox" id="c-40361018" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360924">parent</a><span>|</span><a href="#40363577">next</a><span>|</span><label class="collapse" for="c-40361018">[-]</label><label class="expand" for="c-40361018">[1 more]</label></div><br/><div class="children"><div class="content">Asking students to write an essay about Napoleon isn&#x27;t something we do because we need essays about Napoleon - the point is it&#x27;s a <i>test</i> of capabilities.</div><br/></div></div><div id="40363577" class="c"><input type="checkbox" id="c-40363577" checked=""/><div class="controls bullet"><span class="by">semi-extrinsic</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360924">parent</a><span>|</span><a href="#40361018">prev</a><span>|</span><a href="#40360534">next</a><span>|</span><label class="collapse" for="c-40363577">[-]</label><label class="expand" for="c-40363577">[1 more]</label></div><br/><div class="children"><div class="content">I see you are being downvoted, but I agree with you.<p>A useful test would copy all Alice statements to Eve statements, then rewrite all of the Eve statements using synonyms, and then finally change one or two details for Eve.</div><br/></div></div></div></div></div></div></div></div><div id="40360534" class="c"><input type="checkbox" id="c-40360534" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#40360003">parent</a><span>|</span><a href="#40360401">prev</a><span>|</span><a href="#40360028">next</a><span>|</span><label class="collapse" for="c-40360534">[-]</label><label class="expand" for="c-40360534">[2 more]</label></div><br/><div class="children"><div class="content">The needles form a graph and the prompt asks graph based tasks.</div><br/><div id="40360646" class="c"><input type="checkbox" id="c-40360646" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360534">parent</a><span>|</span><a href="#40360028">next</a><span>|</span><label class="collapse" for="c-40360646">[-]</label><label class="expand" for="c-40360646">[1 more]</label></div><br/><div class="children"><div class="content">That is an interesting idea</div><br/></div></div></div></div><div id="40360028" class="c"><input type="checkbox" id="c-40360028" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360003">parent</a><span>|</span><a href="#40360534">prev</a><span>|</span><a href="#40362420">next</a><span>|</span><label class="collapse" for="c-40360028">[-]</label><label class="expand" for="c-40360028">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking about something similar -- to make part of the question be sufficient information that the LLM can find the limerick.  Then the 2nd part would ask something that would require a deeper understanding of the limerick (or other text).</div><br/></div></div><div id="40362420" class="c"><input type="checkbox" id="c-40362420" checked=""/><div class="controls bullet"><span class="by">nebula8804</span><span>|</span><a href="#40360003">parent</a><span>|</span><a href="#40360028">prev</a><span>|</span><a href="#40360155">next</a><span>|</span><label class="collapse" for="c-40362420">[-]</label><label class="expand" for="c-40362420">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if there is some way to have an AI help humans improve their &quot;reading comprehension&quot; aka reasoning across a large body of text. As far as I can tell the only way to do this is to cut out mindless scrolling and force yourself to read a lot of books in the hopes that this skill might be improved.<p>I am many years out of my grade school years where I was required to read a multitude of novels every year and I guess years of mindless reddit scrolling + focusing on nothing but mathematics and the sciences in college have taken their toll: I read long articles or books but completely miss the deeper meaning.<p>As an example: my nerd like obsession with random topics of the decade before I was born (until I get bored) caused me to read numerous articles and all of Wikipedia + sources on the RBMK reactors and Chernobyl nuclear accident as well as the stories of the people involved.<p>But it wasn&#x27;t until I sat down and watched that famous HBO mini seres that I finally connected the dots of how the lies and secretive nature of the soviet system led to the design flaws in the reactor, and the subsequent suicide of Valery Legasov helped finally expose them to the world where they could no longer be hidden.<p>Its like I knew of all these events and people separately but could not connect them together to form a deep realization and when I saw it acted out on screen it all finally hit me like a ton of bricks. How had I not seen it?<p>Hoping one day AI can just scan my existing brain structure and recommend activities to change the neuronal makeup to what I want it to be. Or even better since im a lazy developer, it should just do it for me.</div><br/></div></div><div id="40360155" class="c"><input type="checkbox" id="c-40360155" checked=""/><div class="controls bullet"><span class="by">adamgordonbell</span><span>|</span><a href="#40360003">parent</a><span>|</span><a href="#40362420">prev</a><span>|</span><a href="#40360576">next</a><span>|</span><label class="collapse" for="c-40360155">[-]</label><label class="expand" for="c-40360155">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been thinking about that as well.<p>It&#x27;s hard, but if you have a piece of fiction or non-fiction it hasn&#x27;t seen before, then a deep reading comprehension question can be a good indicator. But you need to be able to separate a true answer from BS.<p>&quot;What does this work says about our culture? Support your answer with direct quotes.&quot;<p>I found both gpt-4 and haiku to do alright at this, but sometimes give answers that imply fixating on certain sections of a 20,000 k context. You could compare it against chunking the text, getting the answer for each chunk and combining them.<p>I suspect if you do that then the chunking would win for things that are found in many chunks, like the work is heavy handed on a theme, but the large context would be better for a sublter message, except sometimes it would miss it altogether and think a Fight Club screenplay was a dark comedy.<p>Interpretation is hard I guess.</div><br/></div></div><div id="40360576" class="c"><input type="checkbox" id="c-40360576" checked=""/><div class="controls bullet"><span class="by">segmondy</span><span>|</span><a href="#40360003">parent</a><span>|</span><a href="#40360155">prev</a><span>|</span><a href="#40360294">next</a><span>|</span><label class="collapse" for="c-40360576">[-]</label><label class="expand" for="c-40360576">[2 more]</label></div><br/><div class="children"><div class="content">Why can&#x27;t you be that someone?</div><br/><div id="40360620" class="c"><input type="checkbox" id="c-40360620" checked=""/><div class="controls bullet"><span class="by">gremlinsinc</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360576">parent</a><span>|</span><a href="#40360294">next</a><span>|</span><label class="collapse" for="c-40360620">[-]</label><label class="expand" for="c-40360620">[1 more]</label></div><br/><div class="children"><div class="content">lol, made me think of the euphemism: be the change you want to see.</div><br/></div></div></div></div><div id="40360294" class="c"><input type="checkbox" id="c-40360294" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#40360003">parent</a><span>|</span><a href="#40360576">prev</a><span>|</span><a href="#40360954">next</a><span>|</span><label class="collapse" for="c-40360294">[-]</label><label class="expand" for="c-40360294">[4 more]</label></div><br/><div class="children"><div class="content">My idea is to buy to a unpublished novel or screenplay with a  detailed, internally consistent world built in to it and a cast of characters that have well crafted motivations and then ask it to continue writing from an arbitrary post-mid-point by creating a new plot line that combines two characters that haven&#x27;t yet met in the story. If it understands the context it should be able to write a new part of the story and will be able to use a reader&#x27;s intuitive sense of the character&#x27;s motivations to move through their arc.<p>This whole thing would have to be kept under lock-and-key in order to be useful, so it would only serve as a kind of personal benchmark. Or it could possibly be a prestige award that is valued for its conclusions and not for its ability to use the methodology to create improvements in the field.</div><br/><div id="40363583" class="c"><input type="checkbox" id="c-40363583" checked=""/><div class="controls bullet"><span class="by">semi-extrinsic</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360294">parent</a><span>|</span><a href="#40360544">next</a><span>|</span><label class="collapse" for="c-40363583">[-]</label><label class="expand" for="c-40363583">[1 more]</label></div><br/><div class="children"><div class="content">Just use memes. People generate new high-quality niche memes so fast it&#x27;s impossible for the LLMs to keep up.</div><br/></div></div><div id="40360544" class="c"><input type="checkbox" id="c-40360544" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360294">parent</a><span>|</span><a href="#40363583">prev</a><span>|</span><a href="#40360954">next</a><span>|</span><label class="collapse" for="c-40360544">[-]</label><label class="expand" for="c-40360544">[2 more]</label></div><br/><div class="children"><div class="content">You can only use it for a short while, they get a copy as well.</div><br/><div id="40360809" class="c"><input type="checkbox" id="c-40360809" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#40360003">root</a><span>|</span><a href="#40360544">parent</a><span>|</span><a href="#40360954">next</a><span>|</span><label class="collapse" for="c-40360809">[-]</label><label class="expand" for="c-40360809">[1 more]</label></div><br/><div class="children"><div class="content">I have been thinking about this for use in evaluating locally run models, so I didn&#x27;t make that connection in this case. I guess it would have limited utility.</div><br/></div></div></div></div></div></div></div></div><div id="40360954" class="c"><input type="checkbox" id="c-40360954" checked=""/><div class="controls bullet"><span class="by">yatz</span><span>|</span><a href="#40360003">prev</a><span>|</span><a href="#40348948">next</a><span>|</span><label class="collapse" for="c-40360954">[-]</label><label class="expand" for="c-40360954">[3 more]</label></div><br/><div class="children"><div class="content">Well, I can now use GPT to transform raw dynamic data into beautiful HTML layouts on the fly for low-traffic pages, such as change&#x2F;audit logs, saving a ton of development time and keeping my HTML updated even when the data structure has changed. My last attempt did not consistently work because GPT4-Turbo sometimes ignored the context and instructions almost entirely.</div><br/><div id="40361031" class="c"><input type="checkbox" id="c-40361031" checked=""/><div class="controls bullet"><span class="by">ijidak</span><span>|</span><a href="#40360954">parent</a><span>|</span><a href="#40348948">next</a><span>|</span><label class="collapse" for="c-40361031">[-]</label><label class="expand" for="c-40361031">[2 more]</label></div><br/><div class="children"><div class="content">Do you have an example of this? I would love to learn more.</div><br/><div id="40361556" class="c"><input type="checkbox" id="c-40361556" checked=""/><div class="controls bullet"><span class="by">balder1991</span><span>|</span><a href="#40360954">root</a><span>|</span><a href="#40361031">parent</a><span>|</span><a href="#40348948">next</a><span>|</span><label class="collapse" for="c-40361556">[-]</label><label class="expand" for="c-40361556">[1 more]</label></div><br/><div class="children"><div class="content">I guess you just need to offer a template in the prompt? Then maybe some validation after.</div><br/></div></div></div></div></div></div><div id="40348948" class="c"><input type="checkbox" id="c-40348948" checked=""/><div class="controls bullet"><span class="by">parrt</span><span>|</span><a href="#40360954">prev</a><span>|</span><a href="#40360903">next</a><span>|</span><label class="collapse" for="c-40348948">[-]</label><label class="expand" for="c-40348948">[2 more]</label></div><br/><div class="children"><div class="content">The article shows how much better GPT-4o is at paying attention across its input window compared to GPT-4 Turbo and Claude-3 Sonnet.<p>We&#x27;ve needed an upgrade to needle in a haystack for a while and this &quot;Needle In A Needlestack&quot; is a good next step! NIAN creates a prompt that includes thousands of limericks and the prompt asks a question about one limerick at a specific location.</div><br/><div id="40363124" class="c"><input type="checkbox" id="c-40363124" checked=""/><div class="controls bullet"><span class="by">mianos</span><span>|</span><a href="#40348948">parent</a><span>|</span><a href="#40360903">next</a><span>|</span><label class="collapse" for="c-40363124">[-]</label><label class="expand" for="c-40363124">[1 more]</label></div><br/><div class="children"><div class="content">I agree, I paid for Claude for a while. Even though they swear the context is huge and having a huge context uses up tokens like crack, it&#x27;s near useless when source code in context just a few pages back. It was so frustrating as everything else was as good as anything and I liked the &#x27;vibe&#x27;.<p>I used 4o last night and it was still perfectly aware of a C++ class I pasted 20 questions ago. I don&#x27;t care about smart, I care about useful and this really contributes to the utility.</div><br/></div></div></div></div><div id="40360903" class="c"><input type="checkbox" id="c-40360903" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40348948">prev</a><span>|</span><a href="#40360008">next</a><span>|</span><label class="collapse" for="c-40360903">[-]</label><label class="expand" for="c-40360903">[2 more]</label></div><br/><div class="children"><div class="content">Increasingly convinced that nobody on the public internet knows how to do actual LLM evaluations.</div><br/><div id="40362269" class="c"><input type="checkbox" id="c-40362269" checked=""/><div class="controls bullet"><span class="by">tedeh</span><span>|</span><a href="#40360903">parent</a><span>|</span><a href="#40360008">next</a><span>|</span><label class="collapse" for="c-40362269">[-]</label><label class="expand" for="c-40362269">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m just glad that we are finally past the &quot;Who was the 29th president of the United States&quot; and &quot;Draw something in the style of Van Gogh&quot; LLM evaluation test everyone did in 2022-2023.</div><br/></div></div></div></div><div id="40360008" class="c"><input type="checkbox" id="c-40360008" checked=""/><div class="controls bullet"><span class="by">petulla</span><span>|</span><a href="#40360903">prev</a><span>|</span><a href="#40360804">next</a><span>|</span><label class="collapse" for="c-40360008">[-]</label><label class="expand" for="c-40360008">[7 more]</label></div><br/><div class="children"><div class="content">You need to know that this test set data wasn&#x27;t included in the training data for this to be meaningful.</div><br/><div id="40360051" class="c"><input type="checkbox" id="c-40360051" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360008">parent</a><span>|</span><a href="#40360658">next</a><span>|</span><label class="collapse" for="c-40360051">[-]</label><label class="expand" for="c-40360051">[2 more]</label></div><br/><div class="children"><div class="content">If you ask the questions without providing the limerick first, it never gets the right answer.  When the LLM gets the wrong answer, it is usually because it reverts to its training data and gives a generic answer that doesn&#x27;t apply to the limerick.</div><br/><div id="40362450" class="c"><input type="checkbox" id="c-40362450" checked=""/><div class="controls bullet"><span class="by">trifurcate</span><span>|</span><a href="#40360008">root</a><span>|</span><a href="#40360051">parent</a><span>|</span><a href="#40360658">next</a><span>|</span><label class="collapse" for="c-40362450">[-]</label><label class="expand" for="c-40362450">[1 more]</label></div><br/><div class="children"><div class="content">Why are you ruling out the possibility that training on the material may confer an advantage when the data is presented, even if the advantage may not be strong enough to pass the test without the data present in the context window?</div><br/></div></div></div></div><div id="40360658" class="c"><input type="checkbox" id="c-40360658" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#40360008">parent</a><span>|</span><a href="#40360051">prev</a><span>|</span><a href="#40360505">next</a><span>|</span><label class="collapse" for="c-40360658">[-]</label><label class="expand" for="c-40360658">[2 more]</label></div><br/><div class="children"><div class="content">No you don&#x27;t. Compare the model&#x27;s performance before and after uploading the material.</div><br/><div id="40361432" class="c"><input type="checkbox" id="c-40361432" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360008">root</a><span>|</span><a href="#40360658">parent</a><span>|</span><a href="#40360505">next</a><span>|</span><label class="collapse" for="c-40361432">[-]</label><label class="expand" for="c-40361432">[1 more]</label></div><br/><div class="children"><div class="content">Previous answer to this question:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40361419s">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40361419s</a></div><br/></div></div></div></div><div id="40360505" class="c"><input type="checkbox" id="c-40360505" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40360008">parent</a><span>|</span><a href="#40360658">prev</a><span>|</span><a href="#40360804">next</a><span>|</span><label class="collapse" for="c-40360505">[-]</label><label class="expand" for="c-40360505">[2 more]</label></div><br/><div class="children"><div class="content">I thought the test limericks were autogenerated?</div><br/><div id="40360660" class="c"><input type="checkbox" id="c-40360660" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360008">root</a><span>|</span><a href="#40360505">parent</a><span>|</span><a href="#40360804">next</a><span>|</span><label class="collapse" for="c-40360660">[-]</label><label class="expand" for="c-40360660">[1 more]</label></div><br/><div class="children"><div class="content">They come from a database of 98k limericks -- <a href="https:&#x2F;&#x2F;zenodo.org&#x2F;records&#x2F;5722527" rel="nofollow">https:&#x2F;&#x2F;zenodo.org&#x2F;records&#x2F;5722527</a></div><br/></div></div></div></div></div></div><div id="40360804" class="c"><input type="checkbox" id="c-40360804" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#40360008">prev</a><span>|</span><a href="#40359975">next</a><span>|</span><label class="collapse" for="c-40360804">[-]</label><label class="expand" for="c-40360804">[2 more]</label></div><br/><div class="children"><div class="content">How Do we know that gpt-4o.has not been trained on this dataset?</div><br/><div id="40360990" class="c"><input type="checkbox" id="c-40360990" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360804">parent</a><span>|</span><a href="#40359975">next</a><span>|</span><label class="collapse" for="c-40360990">[-]</label><label class="expand" for="c-40360990">[1 more]</label></div><br/><div class="children"><div class="content">Previous answer to this question:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40361419">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40361419</a></div><br/></div></div></div></div><div id="40359975" class="c"><input type="checkbox" id="c-40359975" checked=""/><div class="controls bullet"><span class="by">personjerry</span><span>|</span><a href="#40360804">prev</a><span>|</span><a href="#40360858">next</a><span>|</span><label class="collapse" for="c-40359975">[-]</label><label class="expand" for="c-40359975">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s great to hear. My biggest issue with GPT-4.0 was  that as the conversation got longer, the quality diminished (especially relevant for coding projects)<p>I wonder if it&#x27;ll be better now. Will test today.</div><br/><div id="40360698" class="c"><input type="checkbox" id="c-40360698" checked=""/><div class="controls bullet"><span class="by">throwthrowuknow</span><span>|</span><a href="#40359975">parent</a><span>|</span><a href="#40360005">next</a><span>|</span><label class="collapse" for="c-40360698">[-]</label><label class="expand" for="c-40360698">[1 more]</label></div><br/><div class="children"><div class="content">That’s been my experience so far. My current conversations are crazy long compared to any of my gpt4 convos which I had to frequently copy context from and start over in a new chat</div><br/></div></div><div id="40360005" class="c"><input type="checkbox" id="c-40360005" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40359975">parent</a><span>|</span><a href="#40360698">prev</a><span>|</span><a href="#40360858">next</a><span>|</span><label class="collapse" for="c-40360005">[-]</label><label class="expand" for="c-40360005">[1 more]</label></div><br/><div class="children"><div class="content">I had the same experience.  With a 16k prompt, Turbo was nearly flawless. But it wasn&#x27;t very good at 32k and not usable at 100+.  You have to repeat information to get good results with longer prompts</div><br/></div></div></div></div><div id="40360858" class="c"><input type="checkbox" id="c-40360858" checked=""/><div class="controls bullet"><span class="by">ionwake</span><span>|</span><a href="#40359975">prev</a><span>|</span><a href="#40360723">next</a><span>|</span><label class="collapse" for="c-40360858">[-]</label><label class="expand" for="c-40360858">[2 more]</label></div><br/><div class="children"><div class="content">I am in England, do US users have access to memory features? ( Also do you ahve access to voice customisation yet?<p>Thanks</div><br/><div id="40364298" class="c"><input type="checkbox" id="c-40364298" checked=""/><div class="controls bullet"><span class="by">rob137</span><span>|</span><a href="#40360858">parent</a><span>|</span><a href="#40360723">next</a><span>|</span><label class="collapse" for="c-40364298">[-]</label><label class="expand" for="c-40364298">[1 more]</label></div><br/><div class="children"><div class="content">I am in England, on the &#x27;Team Plan&#x27;* and got access to memory this week.<p>* <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;introducing-chatgpt-team&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;introducing-chatgpt-team&#x2F;</a></div><br/></div></div></div></div><div id="40360723" class="c"><input type="checkbox" id="c-40360723" checked=""/><div class="controls bullet"><span class="by">throwthrowuknow</span><span>|</span><a href="#40360858">prev</a><span>|</span><a href="#40360403">next</a><span>|</span><label class="collapse" for="c-40360723">[-]</label><label class="expand" for="c-40360723">[2 more]</label></div><br/><div class="children"><div class="content">This is a very promising development. It would be wise for everyone to go back and revise old experiments that failed now that this capability is unlocked. It should also make RAG even more powerful now that you can load a lot more information into the context and have it be useful.</div><br/><div id="40363888" class="c"><input type="checkbox" id="c-40363888" checked=""/><div class="controls bullet"><span class="by">demilich</span><span>|</span><a href="#40360723">parent</a><span>|</span><a href="#40360403">next</a><span>|</span><label class="collapse" for="c-40363888">[-]</label><label class="expand" for="c-40363888">[1 more]</label></div><br/><div class="children"><div class="content">Agreed</div><br/></div></div></div></div><div id="40360403" class="c"><input type="checkbox" id="c-40360403" checked=""/><div class="controls bullet"><span class="by">cararemixed</span><span>|</span><a href="#40360723">prev</a><span>|</span><a href="#40360055">next</a><span>|</span><label class="collapse" for="c-40360403">[-]</label><label class="expand" for="c-40360403">[4 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the chance that these limericks are now in the training set? As others mention, it&#x27;d be interesting to come up with a way to synthesize something sufficiently interesting so it always evades training fit.</div><br/><div id="40361000" class="c"><input type="checkbox" id="c-40361000" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360403">parent</a><span>|</span><a href="#40360055">next</a><span>|</span><label class="collapse" for="c-40361000">[-]</label><label class="expand" for="c-40361000">[3 more]</label></div><br/><div class="children"><div class="content">Previous answer to this question:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40361419">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40361419</a></div><br/><div id="40362795" class="c"><input type="checkbox" id="c-40362795" checked=""/><div class="controls bullet"><span class="by">causal</span><span>|</span><a href="#40360403">root</a><span>|</span><a href="#40361000">parent</a><span>|</span><a href="#40361404">next</a><span>|</span><label class="collapse" for="c-40362795">[-]</label><label class="expand" for="c-40362795">[1 more]</label></div><br/><div class="children"><div class="content">Your test is a good one but the point still stands that a novel dataset is the next step to being sure.</div><br/></div></div></div></div></div></div><div id="40360055" class="c"><input type="checkbox" id="c-40360055" checked=""/><div class="controls bullet"><span class="by">asadm</span><span>|</span><a href="#40360403">prev</a><span>|</span><a href="#40360774">next</a><span>|</span><label class="collapse" for="c-40360055">[-]</label><label class="expand" for="c-40360055">[1 more]</label></div><br/><div class="children"><div class="content">I have had good experience with Gemini 1M context model with this kind of tasks.</div><br/></div></div><div id="40360774" class="c"><input type="checkbox" id="c-40360774" checked=""/><div class="controls bullet"><span class="by">throw7381</span><span>|</span><a href="#40360055">prev</a><span>|</span><a href="#40349437">next</a><span>|</span><label class="collapse" for="c-40360774">[-]</label><label class="expand" for="c-40360774">[1 more]</label></div><br/><div class="children"><div class="content">Anyone has done any benchmarks for RAG yet?</div><br/></div></div><div id="40349437" class="c"><input type="checkbox" id="c-40349437" checked=""/><div class="controls bullet"><span class="by">dmose2</span><span>|</span><a href="#40360774">prev</a><span>|</span><a href="#40359969">next</a><span>|</span><label class="collapse" for="c-40349437">[-]</label><label class="expand" for="c-40349437">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting (though perhaps not surprising) to see the variance in curve shape across models.</div><br/></div></div><div id="40359969" class="c"><input type="checkbox" id="c-40359969" checked=""/><div class="controls bullet"><span class="by">nickca</span><span>|</span><a href="#40349437">prev</a><span>|</span><a href="#40361190">next</a><span>|</span><label class="collapse" for="c-40359969">[-]</label><label class="expand" for="c-40359969">[1 more]</label></div><br/><div class="children"><div class="content">Would love to see Gemini there too!</div><br/></div></div><div id="40361190" class="c"><input type="checkbox" id="c-40361190" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#40359969">prev</a><span>|</span><a href="#40360087">next</a><span>|</span><label class="collapse" for="c-40361190">[-]</label><label class="expand" for="c-40361190">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Needle in a Needlestack is a new benchmark to measure how well LLMs pay attention to the information in their context window<p>I asked GPT-4o for JavaScript code and got Python, so much for attention.</div><br/><div id="40361205" class="c"><input type="checkbox" id="c-40361205" checked=""/><div class="controls bullet"><span class="by">kolinko</span><span>|</span><a href="#40361190">parent</a><span>|</span><a href="#40360087">next</a><span>|</span><label class="collapse" for="c-40361205">[-]</label><label class="expand" for="c-40361205">[1 more]</label></div><br/><div class="children"><div class="content">What was your query?</div><br/></div></div></div></div><div id="40360087" class="c"><input type="checkbox" id="c-40360087" checked=""/><div class="controls bullet"><span class="by">rguptill</span><span>|</span><a href="#40361190">prev</a><span>|</span><a href="#40361563">next</a><span>|</span><label class="collapse" for="c-40360087">[-]</label><label class="expand" for="c-40360087">[1 more]</label></div><br/><div class="children"><div class="content">We also need a way to determine where a given response fits in the universe of responses - is it an “average” answer or a really good one</div><br/></div></div><div id="40361563" class="c"><input type="checkbox" id="c-40361563" checked=""/><div class="controls bullet"><span class="by">8thcross</span><span>|</span><a href="#40360087">prev</a><span>|</span><a href="#40361182">next</a><span>|</span><label class="collapse" for="c-40361563">[-]</label><label class="expand" for="c-40361563">[1 more]</label></div><br/><div class="children"><div class="content">These benchmarks are becoming like the top 10 lists you find on the internet. I agree that everything has a space, but frankly how many of us need a test that tells you that this is great at limericks?</div><br/></div></div><div id="40361182" class="c"><input type="checkbox" id="c-40361182" checked=""/><div class="controls bullet"><span class="by">causality0</span><span>|</span><a href="#40361563">prev</a><span>|</span><a href="#40360175">next</a><span>|</span><label class="collapse" for="c-40361182">[-]</label><label class="expand" for="c-40361182">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand OpenAI&#x27;s pricing strategy. For free I can talk to GPT 3.5 on an unlimited basis, and a little to GPT 4o. If I pay $20 a month, I can talk to GPT 4o eighty times every three hours, or once every two and a half minutes. That&#x27;s both way more than I need, and way less than I would expect for twenty dollars a month. I wish they had a $5 per month tier that included, say, eighty messages per 24-hours.</div><br/><div id="40363193" class="c"><input type="checkbox" id="c-40363193" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#40361182">parent</a><span>|</span><a href="#40360175">next</a><span>|</span><label class="collapse" for="c-40363193">[-]</label><label class="expand" for="c-40363193">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;ll make more sense when they deploy audio and image capability to paying users only, which they say they&#x27;re going to do in a few weeks</div><br/></div></div></div></div><div id="40360175" class="c"><input type="checkbox" id="c-40360175" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#40361182">prev</a><span>|</span><a href="#40360164">next</a><span>|</span><label class="collapse" for="c-40360175">[-]</label><label class="expand" for="c-40360175">[1 more]</label></div><br/><div class="children"><div class="content">One could have LLM to route it to a text search function and have the function report back to the LLM for secondary processing.</div><br/></div></div><div id="40360164" class="c"><input type="checkbox" id="c-40360164" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#40360175">prev</a><span>|</span><a href="#40362328">next</a><span>|</span><label class="collapse" for="c-40360164">[-]</label><label class="expand" for="c-40360164">[2 more]</label></div><br/><div class="children"><div class="content">I thought google Gemini had almost perfect needle in haystack performance inside 1 million tokens?</div><br/><div id="40360298" class="c"><input type="checkbox" id="c-40360298" checked=""/><div class="controls bullet"><span class="by">sftombu</span><span>|</span><a href="#40360164">parent</a><span>|</span><a href="#40362328">next</a><span>|</span><label class="collapse" for="c-40360298">[-]</label><label class="expand" for="c-40360298">[1 more]</label></div><br/><div class="children"><div class="content">The reason I made Needle in a needlestack is the LLMs are getting to good at needle in a haystack.  Until GPT-4o, no model was good at the NIAN benchmark.</div><br/></div></div></div></div><div id="40362328" class="c"><input type="checkbox" id="c-40362328" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#40360164">prev</a><span>|</span><a href="#40360709">next</a><span>|</span><label class="collapse" for="c-40362328">[-]</label><label class="expand" for="c-40362328">[1 more]</label></div><br/><div class="children"><div class="content">I think large language models can be used to classify people, lying, or saying, rehearsed, things or being disingenuous. Simply train them on a lot of audio of people talking, and they would become better than most polygraph machines. There’s something about how a person says something that quickly reveals that it was rehearsed earlier, or premeditated, and I’m sure when they’re lying there can be things like that too. the LLM can instantly pick up with some probability and classify it<p>I’ve seen claims during open AI demo that is there software can now pick up on extremely subtle emotional clues, how people speak. Then, it shouldn’t take much more to make it read between the lines and understand what people are intending to say, for example, by enumerating all possible interpretations and scoring them based on, many factors, including the current time, location, etc. In fact, by taking into account so much context in factors, the LLM‘s will be better than people the vast majority of the time understanding what a person meant, assuming they were genuinely trying to communicate something.<p>it will become very hard to lie because everyone’s personal LLM will pick up on it fairly quickly, and find tons of inconsistencies, which it will flag for you later. You will no longer be fooled so easily, and if it has the context of everything the person has said publicly, plus if the person gives permission for your LLM to scan everything they’ve said privately because you’re their Business partner or sexual partner, it can easily catch you in many lies and so on.<p>I predict that in the next 5 to 10 years, human society will completely change as people start to prefer machines to other people, because they understand them so well, and taken into account, the context of everything they’ve ever said. They will be thoughtful, remembering details about the person in many different dimensions, and use them to personalize everything. By contrast, the most thoughtful husband or boyfriend will seem like, a jerk seems now. Or a cat.<p>Humor and seductive conversation, will also be at a superhuman standards. People will obviously up their game too, just like when they do when playing the game go after Lee Sedol was totally destroyed by Alpha go, or when people start using Alpha Zarro to train for Chess. However, once the computers understand what triggers people to laugh or have sexual response, they will be able to trigger them a lot more predictively, they simply need more training data.<p>And bullshitting will be done on a completely different level. Just like people no longer walk to destinations but use cars to go thousands of miles a year, similarly people won’t interact with other people so much anymore. The LLM’s, trained to bullshit 1000 times better than any human, Will be undetectable and gradually shift public opinion as open source models will power swarms of accounts.</div><br/></div></div></div></div></div></div></div></body></html>