<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735635663378" as="style"/><link rel="stylesheet" href="styles.css?v=1735635663378"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/lexiforest/curl-impersonate">Curl-Impersonate</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>jakeogh</span> | <span>102 comments</span></div><br/><div><div id="42549111" class="c"><input type="checkbox" id="c-42549111" checked=""/><div class="controls bullet"><span class="by">cle</span><span>|</span><a href="#42549241">next</a><span>|</span><label class="collapse" for="c-42549111">[-]</label><label class="expand" for="c-42549111">[49 more]</label></div><br/><div class="children"><div class="content">The same author also makes a Python binding of this which exposes a requests-like API in Python, very helpful for making HTTP reqs without the overhead of running an entire browser stack: <a href="https:&#x2F;&#x2F;github.com&#x2F;lexiforest&#x2F;curl_cffi">https:&#x2F;&#x2F;github.com&#x2F;lexiforest&#x2F;curl_cffi</a><p>I can&#x27;t help but feel like these are the dying breaths of the open Internet though. All the megacorps (Google, Microsoft, Apple, CloudFlare, et al) are doing their damndest to make sure everyone is only using software approved by them, and to ensure that they can identify you. From multiple angles too (security, bots, DDoS, etc.), and it&#x27;s not just limited to browsers either.<p>End goal seems to be: prove your identity to the megacorps so they can track everything you do and also ensure you are only doing things they approve of. I think the security arguments are just convenient rationalizations in service of this goal.</div><br/><div id="42549247" class="c"><input type="checkbox" id="c-42549247" checked=""/><div class="controls bullet"><span class="by">throwaway99210</span><span>|</span><a href="#42549111">parent</a><span>|</span><a href="#42549386">next</a><span>|</span><label class="collapse" for="c-42549247">[-]</label><label class="expand" for="c-42549247">[38 more]</label></div><br/><div class="children"><div class="content">&gt; I can&#x27;t help but feel like these are the dying breaths of the open Internet though<p>I agree with the over zealous tracking by the megacorps but this is also due to bad actors, I work for a financial company and the amount of API abuse, ATO, DDoS, nefarious bot traffic, etc. we see on a daily basis is absolutely insane</div><br/><div id="42549415" class="c"><input type="checkbox" id="c-42549415" checked=""/><div class="controls bullet"><span class="by">berkes</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549247">parent</a><span>|</span><a href="#42550334">next</a><span>|</span><label class="collapse" for="c-42549415">[-]</label><label class="expand" for="c-42549415">[33 more]</label></div><br/><div class="children"><div class="content">But how much of this &quot;bad actor&quot; interaction is countered with tracking? And how many of these attempts are even close to successfull with even the simplest out of the box security practices set up?<p>And when it does get more dangerous, is over zealous tracking the best counter for this?<p>I&#x27;ve dealt with a lot of these threats as well, and a lot are countered with rather common tools, from simple fail2ban rules to application firewalls and private subnets and whatnot. E.g. a large fai2ban rule to just ban anything that attempts to HTTP GET &#x2F;admin.php or &#x2F;phpmyadmin etc, even just once, gets rid of almost all nefarious bot traffic.<p>So, I think the amount of attacks indeed can be insane. But the amount that need over zealous tracking is to be countered, is, AFAICS, rather small.</div><br/><div id="42549647" class="c"><input type="checkbox" id="c-42549647" checked=""/><div class="controls bullet"><span class="by">Szpadel</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549415">parent</a><span>|</span><a href="#42549483">next</a><span>|</span><label class="collapse" for="c-42549647">[-]</label><label class="expand" for="c-42549647">[18 more]</label></div><br/><div class="children"><div class="content">I can tell you about my experience with blocking traffic from scalpers bots that were very active during pandemic.<p>All requests produced by those bots were valid ones, nothing that could be flagged by tools like fail2ban etc (my assumption is that it would be the same for financial systems).<p>Any blocking or rate limiting by IP is useless, we saw about 2-3 requests per minute per IP, and those actors had access to ridiculous number of large CIDRs, blocking any IP caused it instantly replace it with another.<p>blocking by AS number was also mixed bag, as this list growed up really quickly, most of that were registered to suspicious looking Gmail addresses. (I feel that such activity might own significant percentage of total ipv4 space)<p>This was basically cat and mouse game of finding some specific characteristic in requests that matches all that traffic and filtering it, but the other side would adapt next day or on Sunday.<p>aggregated amount of traffic was in range of 2-20k r&#x2F;s to basically heaviest endpoint in the shop, with was the main reason we needed to block that traffic (it generated 20-40x load of organic traffic)<p>cloudflare was also not really successful with default configuration, we had to basically challenge everyone by default with whitelist of most common regions from where we expected customers.<p>So best solution is to track everyone and calculate long term reputation.</div><br/><div id="42553440" class="c"><input type="checkbox" id="c-42553440" checked=""/><div class="controls bullet"><span class="by">codingminds</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549647">parent</a><span>|</span><a href="#42550297">next</a><span>|</span><label class="collapse" for="c-42553440">[-]</label><label class="expand" for="c-42553440">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve learned that Akamai has a service that deals with this specific problem, maybe this might interest you as well: <a href="https:&#x2F;&#x2F;www.akamai.com&#x2F;products&#x2F;content-protector" rel="nofollow">https:&#x2F;&#x2F;www.akamai.com&#x2F;products&#x2F;content-protector</a></div><br/></div></div><div id="42550297" class="c"><input type="checkbox" id="c-42550297" checked=""/><div class="controls bullet"><span class="by">stareatgoats</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549647">parent</a><span>|</span><a href="#42553440">prev</a><span>|</span><a href="#42550972">next</a><span>|</span><label class="collapse" for="c-42550297">[-]</label><label class="expand" for="c-42550297">[13 more]</label></div><br/><div class="children"><div class="content">Blocking scalper bot traffic by any means, be it by source or certified identification seems a lost cause, i.e. not possible because it can always be circumvented. Why did you not have that filter at point of sale instead? I&#x27;m sure there are reasons, but to have a battery of captchas and a limit on purchases per credit card seems on the surface much more sturdy. And it doesn&#x27;t require that everyone browsing the internet announce their full name and residential address in order to satisfy the requirements of a social score ...</div><br/><div id="42550489" class="c"><input type="checkbox" id="c-42550489" checked=""/><div class="controls bullet"><span class="by">Szpadel</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550297">parent</a><span>|</span><a href="#42550972">next</a><span>|</span><label class="collapse" for="c-42550489">[-]</label><label class="expand" for="c-42550489">[12 more]</label></div><br/><div class="children"><div class="content">The product they tried to buy what not in stock anyways, but their strategy was to constantly try anyways, so in case it would become in stock they would be the first to get it.
It was all for guest checkout, so no address yet to validate nor credit card.
Because they used API endpoints used by the frontend we could not use any captcha at this place because of technical requirements.<p>As stated before the main reason we needed to block it was volume of the traffic, you migh imagine identical scenario for dealing with DDoS attack.</div><br/><div id="42554917" class="c"><input type="checkbox" id="c-42554917" checked=""/><div class="controls bullet"><span class="by">jsdwarf</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550489">parent</a><span>|</span><a href="#42555117">next</a><span>|</span><label class="collapse" for="c-42554917">[-]</label><label class="expand" for="c-42554917">[1 more]</label></div><br/><div class="children"><div class="content">Disabling guest checkout would have been my weapon of choice or at least requiring the user to enter an email address to so that they are notified when the product becomes available.</div><br/></div></div><div id="42555117" class="c"><input type="checkbox" id="c-42555117" checked=""/><div class="controls bullet"><span class="by">dspillett</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550489">parent</a><span>|</span><a href="#42554917">prev</a><span>|</span><a href="#42550657">next</a><span>|</span><label class="collapse" for="c-42555117">[-]</label><label class="expand" for="c-42555117">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Because they used API endpoints used by the frontend we could not use any captcha at this place because of technical requirements</i><p>A time sensitive hash validating each request makes it a bit harder for them without significant extra work on your part. Address sensitive is much more effective but can result in issues for users that switch between networks (using your site on the move and passing between workers networks, for instance).</div><br/></div></div><div id="42550657" class="c"><input type="checkbox" id="c-42550657" checked=""/><div class="controls bullet"><span class="by">bornfreddy</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550489">parent</a><span>|</span><a href="#42555117">prev</a><span>|</span><a href="#42551676">next</a><span>|</span><label class="collapse" for="c-42550657">[-]</label><label class="expand" for="c-42550657">[8 more]</label></div><br/><div class="children"><div class="content">&gt; Because they used API endpoints used by the frontend we could not use any captcha at this place because of technical requirements.<p>That doesn&#x27;t compute... Captcha is almost always used in such setups.<p>It also looks like you could just offer an API endpoint which would return if the article is in stock or not, or even provide a webhook. Why fight them? Just make the resource usage lighter.<p>I&#x27;m curious now though what the articles were, if you are at liberty to share?</div><br/><div id="42552341" class="c"><input type="checkbox" id="c-42552341" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550657">parent</a><span>|</span><a href="#42551107">next</a><span>|</span><label class="collapse" for="c-42552341">[-]</label><label class="expand" for="c-42552341">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Why fight them? Just make the resource usage lighter.<p>Because you presumably want real, returning customers, and that means those customers need to get a chance at buying those products, instead of them being scooped up by a scalper the millisecond they appear on the website.</div><br/><div id="42554841" class="c"><input type="checkbox" id="c-42554841" checked=""/><div class="controls bullet"><span class="by">thatcat</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42552341">parent</a><span>|</span><a href="#42553410">next</a><span>|</span><label class="collapse" for="c-42554841">[-]</label><label class="expand" for="c-42554841">[1 more]</label></div><br/><div class="children"><div class="content">maybe offer the item for preorder ?</div><br/></div></div><div id="42553410" class="c"><input type="checkbox" id="c-42553410" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42552341">parent</a><span>|</span><a href="#42554841">prev</a><span>|</span><a href="#42551107">next</a><span>|</span><label class="collapse" for="c-42553410">[-]</label><label class="expand" for="c-42553410">[2 more]</label></div><br/><div class="children"><div class="content">Sounds like a dream having customers scooping up your products the millisecond the appear on the website. They should increase their prices.</div><br/><div id="42555135" class="c"><input type="checkbox" id="c-42555135" checked=""/><div class="controls bullet"><span class="by">dspillett</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42553410">parent</a><span>|</span><a href="#42551107">next</a><span>|</span><label class="collapse" for="c-42555135">[-]</label><label class="expand" for="c-42555135">[1 more]</label></div><br/><div class="children"><div class="content">No matter what the price, they would still have the &quot;As stated before the main reason we needed to block it was volume of the traffic&quot; problem that was stated above, for a popular item. In fact increasing the base price might attract even more scalpers and such.</div><br/></div></div></div></div></div></div><div id="42551107" class="c"><input type="checkbox" id="c-42551107" checked=""/><div class="controls bullet"><span class="by">Szpadel</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550657">parent</a><span>|</span><a href="#42552341">prev</a><span>|</span><a href="#42551676">next</a><span>|</span><label class="collapse" for="c-42551107">[-]</label><label class="expand" for="c-42551107">[3 more]</label></div><br/><div class="children"><div class="content">We had captcha, but it was at later stage of the checkout process.
This API endpoint needed to work from cached pages, so it could not contain any dynamic state in request.<p>Some bots checked product page where we had info if product is in stock (although they tried heavenly to bypass any caches by putting garbage in URL). This kind of bots also scaled instantly to thousands checkout requests when product become available with gave no time for auto scaling to react (this was another challenge here)<p>This was easy to mitigate so it didn&#x27;t generate almost any load on the system.<p>I believe we had email notification available, but it could be too high latency way for them.<p>I&#x27;m not sure how much I can share about articles here, but I can say that those were fairly expensive (and limited series) wardrobe products.</div><br/><div id="42553988" class="c"><input type="checkbox" id="c-42553988" checked=""/><div class="controls bullet"><span class="by">shaky-carrousel</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42551107">parent</a><span>|</span><a href="#42551676">next</a><span>|</span><label class="collapse" for="c-42553988">[-]</label><label class="expand" for="c-42553988">[2 more]</label></div><br/><div class="children"><div class="content">Hm, is probably too late, but you could have implemented in your API calls some kind of proof of work. Something that&#x27;s not too onerous for a casual user but it is hard for someone trying multiple requests.</div><br/><div id="42555554" class="c"><input type="checkbox" id="c-42555554" checked=""/><div class="controls bullet"><span class="by">Szpadel</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42553988">parent</a><span>|</span><a href="#42551676">next</a><span>|</span><label class="collapse" for="c-42555554">[-]</label><label class="expand" for="c-42555554">[1 more]</label></div><br/><div class="children"><div class="content">This was actually one of my ideas how to solve it, observed behaviour strongly suggested that all those thousands of IP addresses where used by single server. Even small PoW with this volume should heavly influence their capacity.
But we decided that we did not want to affect performance of mobile users.
We later learned that such strategy is also used by cloudflare js check</div><br/></div></div></div></div></div></div></div></div><div id="42551676" class="c"><input type="checkbox" id="c-42551676" checked=""/><div class="controls bullet"><span class="by">sesm</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550489">parent</a><span>|</span><a href="#42550657">prev</a><span>|</span><a href="#42550972">next</a><span>|</span><label class="collapse" for="c-42551676">[-]</label><label class="expand" for="c-42551676">[1 more]</label></div><br/><div class="children"><div class="content">I remember people doing this with PS5 when they were in short supply after release.</div><br/></div></div></div></div></div></div><div id="42550972" class="c"><input type="checkbox" id="c-42550972" checked=""/><div class="controls bullet"><span class="by">shwouchk</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549647">parent</a><span>|</span><a href="#42550297">prev</a><span>|</span><a href="#42556501">next</a><span>|</span><label class="collapse" for="c-42550972">[-]</label><label class="expand" for="c-42550972">[1 more]</label></div><br/><div class="children"><div class="content">Require a verified account to buy high demand items.</div><br/></div></div><div id="42556501" class="c"><input type="checkbox" id="c-42556501" checked=""/><div class="controls bullet"><span class="by">jillyboel</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549647">parent</a><span>|</span><a href="#42550972">prev</a><span>|</span><a href="#42550795">next</a><span>|</span><label class="collapse" for="c-42556501">[-]</label><label class="expand" for="c-42556501">[1 more]</label></div><br/><div class="children"><div class="content">The best solution is to put everyone in a little cage and point and keep a permanent record of everything they do. This doesn&#x27;t mean it&#x27;s a desirable solution.</div><br/></div></div><div id="42550795" class="c"><input type="checkbox" id="c-42550795" checked=""/><div class="controls bullet"><span class="by">cute_boi</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549647">parent</a><span>|</span><a href="#42556501">prev</a><span>|</span><a href="#42549483">next</a><span>|</span><label class="collapse" for="c-42550795">[-]</label><label class="expand" for="c-42550795">[1 more]</label></div><br/><div class="children"><div class="content">why not charge people? This is the only solution I can think of.</div><br/></div></div></div></div><div id="42549483" class="c"><input type="checkbox" id="c-42549483" checked=""/><div class="controls bullet"><span class="by">throwaway99210</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549415">parent</a><span>|</span><a href="#42549647">prev</a><span>|</span><a href="#42550092">next</a><span>|</span><label class="collapse" for="c-42549483">[-]</label><label class="expand" for="c-42549483">[5 more]</label></div><br/><div class="children"><div class="content">&gt; E.g. a large fai2ban rule to just ban anything that attempts to HTTP GET &#x2F;admin.php or &#x2F;phpmyadmin etc, even just once, gets rid of almost all nefarious bot traffic.<p>unfortunately fail2ban wouldn&#x27;t even make a dent in the attack traffic hitting the endpoints in my day-to-day work, these are attackers utilizing residential proxy infrastructure that are increasingly capable of solving JS&#x2F;client-puzzle challenges.. the arms race is always escalating</div><br/><div id="42549898" class="c"><input type="checkbox" id="c-42549898" checked=""/><div class="controls bullet"><span class="by">JohnMakin</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549483">parent</a><span>|</span><a href="#42552523">next</a><span>|</span><label class="collapse" for="c-42549898">[-]</label><label class="expand" for="c-42549898">[1 more]</label></div><br/><div class="children"><div class="content">we see the same thing, also with a financial company, the most successful strategies we’ve seen is making stuff like this extremely expensive for whoever it is if we see it, and they stop or slow down to a point it becomes not worth it and they move on. sometimes that’s really all you can do without harming legit traffic.</div><br/></div></div><div id="42552523" class="c"><input type="checkbox" id="c-42552523" checked=""/><div class="controls bullet"><span class="by">josephcsible</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549483">parent</a><span>|</span><a href="#42549898">prev</a><span>|</span><a href="#42550092">next</a><span>|</span><label class="collapse" for="c-42552523">[-]</label><label class="expand" for="c-42552523">[3 more]</label></div><br/><div class="children"><div class="content">Such a rule is a great way to let malicious users lock out a bunch of your legitimate customers. Imagine if someone makes a forum post and includes this in it:<p><pre><code>  [img]https:&#x2F;&#x2F;example.com&#x2F;phpmyadmin&#x2F;whatever.png[&#x2F;img]</code></pre></div><br/><div id="42556231" class="c"><input type="checkbox" id="c-42556231" checked=""/><div class="controls bullet"><span class="by">RiverCrochet</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42552523">parent</a><span>|</span><a href="#42550092">next</a><span>|</span><label class="collapse" for="c-42556231">[-]</label><label class="expand" for="c-42556231">[2 more]</label></div><br/><div class="children"><div class="content">That would be in the body of the request.  OP is talking about URLs in the actual request, which is part of the header.<p>While I don&#x27;t have experience with a great number of WAFs I&#x27;m sure sophisticated ones let you be quite specific on where you are matching text to identify bad requests.<p>As an aside, another &quot;easy win&quot; is assuming any incoming HTTP request for a dotfile is malicious. I see constant unsolicitied attempts to access `.env`, for example.</div><br/><div id="42556482" class="c"><input type="checkbox" id="c-42556482" checked=""/><div class="controls bullet"><span class="by">josephcsible</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42556231">parent</a><span>|</span><a href="#42550092">next</a><span>|</span><label class="collapse" for="c-42556482">[-]</label><label class="expand" for="c-42556482">[1 more]</label></div><br/><div class="children"><div class="content">When legitimate users viewed that forum post, their browsers would, in the course of loading the image, attempt to HTTP GET &#x2F;phpmyadmin&#x2F;whatever.png, with that being the URL in the actual request in the header.</div><br/></div></div></div></div></div></div></div></div><div id="42550092" class="c"><input type="checkbox" id="c-42550092" checked=""/><div class="controls bullet"><span class="by">mattpallissard</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549415">parent</a><span>|</span><a href="#42549483">prev</a><span>|</span><a href="#42552321">next</a><span>|</span><label class="collapse" for="c-42550092">[-]</label><label class="expand" for="c-42550092">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not the same type of bot net.  Fail 2 ban simply is not going to work when you have a popular unauthenticated endpoint.  You have hundreds of thousands of rps spread across thousands of legitimate networks that.  The requests are always modified to look legitimate in a never ending game of whack-a-mole.<p>You wind up having to use things like tls fingerprinting with other heuristics to identify what to traffic to reject.  These all take engineering hours and require infrastructure.  It is SO MUCH SIMPLER to require auth and reject everything else outright.<p>I know that the BigCo&#x27;s want to track us and you originally mentioned tracking not auth.  But my point is yeah, they have malicious reasons for locking things down, but there are legitimate reasons too.</div><br/><div id="42554289" class="c"><input type="checkbox" id="c-42554289" checked=""/><div class="controls bullet"><span class="by">fijiaarone</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550092">parent</a><span>|</span><a href="#42552573">next</a><span>|</span><label class="collapse" for="c-42554289">[-]</label><label class="expand" for="c-42554289">[2 more]</label></div><br/><div class="children"><div class="content">Easy solution to rate limit. Require initial request to get 1 time token with a 1 second delay  And then require valid requests to include the token. The token returned has a salt with something like timestamp and ip. That way they can only bombard the token generator.<p>get &#x2F;token<p>Returns token with timestamp in salted hash<p>get &#x2F;resource?token=abc123xyz<p>Check for valid token and drop or deny.</div><br/><div id="42555146" class="c"><input type="checkbox" id="c-42555146" checked=""/><div class="controls bullet"><span class="by">int0x29</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42554289">parent</a><span>|</span><a href="#42552573">next</a><span>|</span><label class="collapse" for="c-42555146">[-]</label><label class="expand" for="c-42555146">[1 more]</label></div><br/><div class="children"><div class="content">As at least one person working on this has pointed out in this thread: their adversaries have IP blocks and ASNs.</div><br/></div></div></div></div><div id="42552573" class="c"><input type="checkbox" id="c-42552573" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550092">parent</a><span>|</span><a href="#42554289">prev</a><span>|</span><a href="#42552321">next</a><span>|</span><label class="collapse" for="c-42552573">[-]</label><label class="expand" for="c-42552573">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You wind up having to use things like tls fingerprinting<p>...and we&#x27;ve circled back to the post&#x27;s subject - a version of curl that impersonates browsers TLS handshake behavior to bypass such fingerprinting.</div><br/></div></div></div></div><div id="42552321" class="c"><input type="checkbox" id="c-42552321" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549415">parent</a><span>|</span><a href="#42550092">prev</a><span>|</span><a href="#42550219">next</a><span>|</span><label class="collapse" for="c-42552321">[-]</label><label class="expand" for="c-42552321">[1 more]</label></div><br/><div class="children"><div class="content">This depends on what you&#x27;re fighting.<p>If you&#x27;re fighting adversaries that go for scale, AKA trying to hack as many targets as possible, mostly low-sophistication, using techniques requiring 0 human work and seeing what sticks, yes, blocking those simple techniques works.<p>Those attackers don&#x27;t ever expect to hack Facebook or your bank, that&#x27;s just not the business they&#x27;re in. They&#x27;re fine with posting unsavory ads on your local church&#x27;s website, blackmailing a school principal with the explicit pictures he stores on the school server, or encrypting all the data on that server and demanding a ransom.<p>If your company does something that is specifically valuable to someone, and there are people <i>whose literal job it is to attack your company&#x27;s specific systems</i>, no, those simple techniques won&#x27;t be enough.<p>If you&#x27;re protecting a Church with 150 members, the simple techniques are probably fine, if you&#x27;re working for a major bank or a retailer that sells gaming consoles or concert tickets, they&#x27;re laughably inadequate.</div><br/></div></div><div id="42550219" class="c"><input type="checkbox" id="c-42550219" checked=""/><div class="controls bullet"><span class="by">jsnell</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549415">parent</a><span>|</span><a href="#42552321">prev</a><span>|</span><a href="#42549638">next</a><span>|</span><label class="collapse" for="c-42550219">[-]</label><label class="expand" for="c-42550219">[3 more]</label></div><br/><div class="children"><div class="content">The question is a bit of a non sequitur, since this is not tracking. The TLS fingerprint is not a useful tracking vector, by itself nor as part of some composite fingerprint.</div><br/><div id="42554312" class="c"><input type="checkbox" id="c-42554312" checked=""/><div class="controls bullet"><span class="by">fijiaarone</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550219">parent</a><span>|</span><a href="#42549638">next</a><span>|</span><label class="collapse" for="c-42554312">[-]</label><label class="expand" for="c-42554312">[2 more]</label></div><br/><div class="children"><div class="content">The point is that you have to use an approved client (eg browser, os) with an approved cert authority that goes through approved gatekeepers (eg Cloudflare, Akamai)</div><br/><div id="42556980" class="c"><input type="checkbox" id="c-42556980" checked=""/><div class="controls bullet"><span class="by">jsnell</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42554312">parent</a><span>|</span><a href="#42549638">next</a><span>|</span><label class="collapse" for="c-42556980">[-]</label><label class="expand" for="c-42556980">[1 more]</label></div><br/><div class="children"><div class="content">That seems pretty unlikely to be the original point of <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42549415">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42549415</a>, which mentions none of that, and doesn&#x27;t even have directionally the same concerns.<p>But also, what you wrote is basically nonsense. Clients don&#x27;t need &quot;an approved cert authority&quot;. Nor are there any &quot;approved gatekeepers&quot;, all major browsers are equally happy connecting to your Raspberry Pi as they are connecting to Cloudflare.</div><br/></div></div></div></div></div></div><div id="42549638" class="c"><input type="checkbox" id="c-42549638" checked=""/><div class="controls bullet"><span class="by">tialaramex</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549415">parent</a><span>|</span><a href="#42550219">prev</a><span>|</span><a href="#42550334">next</a><span>|</span><label class="collapse" for="c-42549638">[-]</label><label class="expand" for="c-42549638">[1 more]</label></div><br/><div class="children"><div class="content">A big problem is that where we have a good solution you&#x27;ll lose if you insist on that solution but other people get away with doing something that&#x27;s crap but customers like better. We often have to <i>mandate</i> a poor solution that will be tolerated because if we mandate the better solution it will be rejected, and if we don&#x27;t mandate anything the outcomes are far worse.<p>Today for example I changed energy company†. I made a telephone call, from a number the company has never seen before. I told them my name (truthfully but I could have lied) and address (likewise). I agreed to about five minutes of parameters, conditions, etc. and I made one actual meaningful choice (a specific tariff, they offer two). I then provided 12 digits identifying a bank account (they will eventually check this account exists and ask it to pay them money, which by default will just work) and I&#x27;m done.<p>Notice that <i>anybody</i> could call from a burner and that would work too. They could move Aunt Sarah&#x27;s energy to some random outfit, assign payments to Jim&#x27;s bank account, and cause maybe an hour of stress and confusion for both Sarah and Jim when months or years later they realise the problem.<p>We know how to do this properly, but it would be high friction and that&#x27;s not in the interests of either the &quot;energy companies&quot; or the politicians who created this needlessly complicated &quot;Free Market&quot; for energy. We could abolish that Free Market, but again that&#x27;s not in their interests. So, we&#x27;re stuck with this waste of our time and money, indefinitely.<p>There have been <i>simpler</i> versions of this system, which had even worse outcomes. They&#x27;re clumsier to use, they cause more people to get scammed AND they result in higher cost to consumers, so that&#x27;s not great. And there are <i>better</i> systems we can&#x27;t deploy because in practice too few consumers will use them, so you&#x27;d have 0% failure but lower total engagement and that&#x27;s what matters.<p>† They don&#x27;t actually supply either gas or electricity, that&#x27;s a last mile problem solved by a regulated monopoly, nor do they make electricity or drill for gas - but they do bill me for the gas and electricity I use - they&#x27;re an artefact of Capitalism.</div><br/></div></div></div></div><div id="42550334" class="c"><input type="checkbox" id="c-42550334" checked=""/><div class="controls bullet"><span class="by">code51</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549247">parent</a><span>|</span><a href="#42549415">prev</a><span>|</span><a href="#42549424">next</a><span>|</span><label class="collapse" for="c-42550334">[-]</label><label class="expand" for="c-42550334">[2 more]</label></div><br/><div class="children"><div class="content">Much of this &quot;bad actor&quot; activity is actually customer needs left hanging - for either the customer to automate herself or other companies to fill the gap to create value that&#x27;s not envisioned by the original company.<p>I&#x27;m guessing investors actually like a healthy dose of open access and a healthy dose of defence. We see them (YC, as an example) betting on multiple teams addressing the same problem. The difference is their execution, the angle they attack.<p>If, say, the financial company you work for is capable in both product and technical aspect, I assume it leaves no gap. It&#x27;s the main place to access the service and all the side benefits.</div><br/><div id="42552421" class="c"><input type="checkbox" id="c-42552421" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42550334">parent</a><span>|</span><a href="#42549424">next</a><span>|</span><label class="collapse" for="c-42552421">[-]</label><label class="expand" for="c-42552421">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Much of this &quot;bad actor&quot; activity is actually customer needs left hanging - for either the customer to automate herself or other companies to fill the gap to create value<p>Sometimes the customer you have isn&#x27;t the customer you want.<p>As a bank, you don&#x27;t want the customers that will try to log in to 1000 accounts, and then immediately transfer any money they find to the Seychelles. As a ticketing platform, you don&#x27;t want the customers that buy tickets and then immediately sell them on for 4x the price. As a messaging app, you don&#x27;t want the customers who have 2000 bot accounts and use AI to send hundreds of thousands of spam messages a day. As a social network, you don&#x27;t want the customers who want to use your platform to spread pro-russian misinformation.<p>In a sense, those are &quot;customer needs left changing&quot;, but neither you nor otherr customers want those needs to be automatible.</div><br/></div></div></div></div><div id="42549424" class="c"><input type="checkbox" id="c-42549424" checked=""/><div class="controls bullet"><span class="by">cle</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549247">parent</a><span>|</span><a href="#42550334">prev</a><span>|</span><a href="#42551039">next</a><span>|</span><label class="collapse" for="c-42549424">[-]</label><label class="expand" for="c-42549424">[1 more]</label></div><br/><div class="children"><div class="content">Yep totally agree these are problems. I don&#x27;t have a good alternative proposal either, I&#x27;m just disappointed with what we&#x27;re converging on.</div><br/></div></div></div></div><div id="42549386" class="c"><input type="checkbox" id="c-42549386" checked=""/><div class="controls bullet"><span class="by">octocop</span><span>|</span><a href="#42549111">parent</a><span>|</span><a href="#42549247">prev</a><span>|</span><a href="#42554988">next</a><span>|</span><label class="collapse" for="c-42549386">[-]</label><label class="expand" for="c-42549386">[3 more]</label></div><br/><div class="children"><div class="content">&quot;I have nothing to hide&quot; will eventually spread to everyone. Very unfortunate.</div><br/><div id="42549524" class="c"><input type="checkbox" id="c-42549524" checked=""/><div class="controls bullet"><span class="by">cle</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549386">parent</a><span>|</span><a href="#42552659">next</a><span>|</span><label class="collapse" for="c-42549524">[-]</label><label class="expand" for="c-42549524">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m in a similar boat but it&#x27;s more like &quot;I have nothing I can hide&quot;.<p>These days I just tell friends &amp; family to assume that nothing they do is private.</div><br/></div></div><div id="42552659" class="c"><input type="checkbox" id="c-42552659" checked=""/><div class="controls bullet"><span class="by">Habgdnv</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549386">parent</a><span>|</span><a href="#42549524">prev</a><span>|</span><a href="#42554988">next</a><span>|</span><label class="collapse" for="c-42552659">[-]</label><label class="expand" for="c-42552659">[1 more]</label></div><br/><div class="children"><div class="content">The answer is simple: I have something to hide. I have many things to hide actually. Nothing of these things is illegal currently but I still have many things to hide. And if I have something to hide - I can be worried about many things.</div><br/></div></div></div></div><div id="42554988" class="c"><input type="checkbox" id="c-42554988" checked=""/><div class="controls bullet"><span class="by">jagged-chisel</span><span>|</span><a href="#42549111">parent</a><span>|</span><a href="#42549386">prev</a><span>|</span><a href="#42549359">next</a><span>|</span><label class="collapse" for="c-42554988">[-]</label><label class="expand" for="c-42554988">[1 more]</label></div><br/><div class="children"><div class="content">&gt; … helpful for making HTTP reqs without the overhead of running an entire browser stack<p>For those less informed, add “to impersonate the fingerprints of a browser.”<p>One can, obviously, make requests without a browser stack.</div><br/></div></div><div id="42549359" class="c"><input type="checkbox" id="c-42549359" checked=""/><div class="controls bullet"><span class="by">schnable</span><span>|</span><a href="#42549111">parent</a><span>|</span><a href="#42554988">prev</a><span>|</span><a href="#42554957">next</a><span>|</span><label class="collapse" for="c-42549359">[-]</label><label class="expand" for="c-42549359">[2 more]</label></div><br/><div class="children"><div class="content">A lot of the motivation comes from government regulations too. Right now this is mostly in banking, but social media and porn regs are coming too.</div><br/><div id="42552465" class="c"><input type="checkbox" id="c-42552465" checked=""/><div class="controls bullet"><span class="by">lelandfe</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42549359">parent</a><span>|</span><a href="#42554957">next</a><span>|</span><label class="collapse" for="c-42552465">[-]</label><label class="expand" for="c-42552465">[1 more]</label></div><br/><div class="children"><div class="content">PornHub and all of its affiliate sites now block all residents of Alabama, Arkansas, Idaho, Indiana, Kansas, Kentucky, Mississippi, Montana, Nebraska, North Carolina, Texas, Utah, and Virginia (and Florida on Jan 1): <a href="https:&#x2F;&#x2F;www.pcmag.com&#x2F;news&#x2F;pornhub-blocked-florida-alabama-texas-virginia-nc-age-verification-vpn" rel="nofollow">https:&#x2F;&#x2F;www.pcmag.com&#x2F;news&#x2F;pornhub-blocked-florida-alabama-t...</a><p>Child safety, as always, was the sugar that made the medicine go down in freedom-loving USA. I imagine these states&#x27; approaches will try to move to the federal level after Section 230 dies an ignominious death.<p>Keep an eye out for <i>Free Speech Coalition v. Paxton</i> to hit SCOTUS in January: <a href="https:&#x2F;&#x2F;www.oyez.org&#x2F;cases&#x2F;2024&#x2F;23-1122" rel="nofollow">https:&#x2F;&#x2F;www.oyez.org&#x2F;cases&#x2F;2024&#x2F;23-1122</a></div><br/></div></div></div></div><div id="42554957" class="c"><input type="checkbox" id="c-42554957" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#42549111">parent</a><span>|</span><a href="#42549359">prev</a><span>|</span><a href="#42555670">next</a><span>|</span><label class="collapse" for="c-42554957">[-]</label><label class="expand" for="c-42554957">[2 more]</label></div><br/><div class="children"><div class="content">They&#x27;ve been planning this stuff for a long time...<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Next-Generation_Secure_Computing_Base" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Next-Generation_Secure_Computi...</a><p>...and we&#x27;re seeing the puzzle pieces fall into place. Mandated driver signing, TPMs, and more recently remote attestation. &quot;Security&quot; has always been the excuse --- securing their control over you.</div><br/><div id="42555274" class="c"><input type="checkbox" id="c-42555274" checked=""/><div class="controls bullet"><span class="by">dwattttt</span><span>|</span><a href="#42549111">root</a><span>|</span><a href="#42554957">parent</a><span>|</span><a href="#42555670">next</a><span>|</span><label class="collapse" for="c-42555274">[-]</label><label class="expand" for="c-42555274">[1 more]</label></div><br/><div class="children"><div class="content">Another trending thread right now is Pegasus&#x2F;Predator; as much as it may be a facade, to say MS (or any OS vendor) has no business working on security&#x2F;secure computing is demonstrably false.</div><br/></div></div></div></div><div id="42555670" class="c"><input type="checkbox" id="c-42555670" checked=""/><div class="controls bullet"><span class="by">matheusmoreira</span><span>|</span><a href="#42549111">parent</a><span>|</span><a href="#42554957">prev</a><span>|</span><a href="#42550307">next</a><span>|</span><label class="collapse" for="c-42555670">[-]</label><label class="expand" for="c-42555670">[1 more]</label></div><br/><div class="children"><div class="content">You are on point. There is no open internet without computing freedom.<p>Computers used to be empowering. Cryptography used to be empowering. Then these corporations started using both against us. They own the computers now. Hardware cryptography ensures the computers only run their software now, software that does their the corporation&#x27;s bidding and enforces their controls. And if we somehow gain control of the computer we are denied every service and essentially ostracized. I don&#x27;t think it will be long before we are banned from the internet proper for using &quot;unauthorized&quot; devices.<p>It&#x27;s an incredibly depressing state of affairs. Everything the word &quot;hacker&quot; ever stood for is pretty much dying. It feels like there&#x27;s no way out.</div><br/></div></div><div id="42550307" class="c"><input type="checkbox" id="c-42550307" checked=""/><div class="controls bullet"><span class="by">deadbabe</span><span>|</span><a href="#42549111">parent</a><span>|</span><a href="#42555670">prev</a><span>|</span><a href="#42549241">next</a><span>|</span><label class="collapse" for="c-42550307">[-]</label><label class="expand" for="c-42550307">[1 more]</label></div><br/><div class="children"><div class="content">Even if the internet was wide open it’s of little use these days.<p>AI will replace any search you would want to do to find information, the only reason to scour the internet now is for social purposes: finding comments and forums or content from other users, and you don’t really need to be untracked to do all that.<p>A megacorp’s main motivation for tracking your identity is to sell you shit or sell your data to other people who want to sell you things. But if you’re using AI the amount of ads and SEO spam that you have to sift through will dramatically reduce, rendering most of those efforts pointless.<p>And most people aren’t using the internet like in the old days: stumbling across quaint cozy boutique websites made by hobbyists about some favorite topic. People just jump on social platforms and consume content until satisfied.<p>There is no money to be made anymore in mass web scraping at scale with impersonated clients, it’s all been consumed.</div><br/></div></div></div></div><div id="42549241" class="c"><input type="checkbox" id="c-42549241" checked=""/><div class="controls bullet"><span class="by">oefrha</span><span>|</span><a href="#42549111">prev</a><span>|</span><a href="#42551544">next</a><span>|</span><label class="collapse" for="c-42549241">[-]</label><label class="expand" for="c-42549241">[9 more]</label></div><br/><div class="children"><div class="content">What are some example sites where this is both necessary and sufficient? In my experience sites with serious anti-bot protection basically always have JavaScript-based browser detection, and some are capable of defeating puppeteer-extra-plugin-stealth even in headful mode. I doubt sites without serious anti-bot detection will do TLS fingerprinting. I guess it is useful for the narrower use case of getting a short-lived token&#x2F;cookie with a headless browser on a heavily defended site, then performing requests using said tokens with this lightweight client for a while?</div><br/><div id="42549383" class="c"><input type="checkbox" id="c-42549383" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42549241">parent</a><span>|</span><a href="#42549382">next</a><span>|</span><label class="collapse" for="c-42549383">[-]</label><label class="expand" for="c-42549383">[2 more]</label></div><br/><div class="children"><div class="content">A lot of WAFs make it a simple thing to set up. Since it doesn&#x27;t require any application-level changes, it&#x27;s an easy &quot;first move&quot; in the anti-bot arms race.<p>At the time I wrote this up, r1-api.rabbit.tech required TLS client fingerprints to match an expected value, and not much else: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;DavidBuchanan314&#x2F;aafce6ba7fc49b19206bd2ad357e47fa" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;DavidBuchanan314&#x2F;aafce6ba7fc49b19206...</a><p>(I haven&#x27;t paid attention to what they&#x27;ve done since so it might no longer be the case)</div><br/><div id="42549463" class="c"><input type="checkbox" id="c-42549463" checked=""/><div class="controls bullet"><span class="by">oefrha</span><span>|</span><a href="#42549241">root</a><span>|</span><a href="#42549383">parent</a><span>|</span><a href="#42549382">next</a><span>|</span><label class="collapse" for="c-42549463">[-]</label><label class="expand" for="c-42549463">[1 more]</label></div><br/><div class="children"><div class="content">Makes sense, thanks.</div><br/></div></div></div></div><div id="42549382" class="c"><input type="checkbox" id="c-42549382" checked=""/><div class="controls bullet"><span class="by">jonatron</span><span>|</span><a href="#42549241">parent</a><span>|</span><a href="#42549383">prev</a><span>|</span><a href="#42551531">next</a><span>|</span><label class="collapse" for="c-42549382">[-]</label><label class="expand" for="c-42549382">[2 more]</label></div><br/><div class="children"><div class="content">There are sites that will block curl and python-requests completely, but will allow curl-impersonate. IIRC, Amazon is an example that has some bot protection but it isn&#x27;t &quot;serious&quot;.</div><br/><div id="42550682" class="c"><input type="checkbox" id="c-42550682" checked=""/><div class="controls bullet"><span class="by">ekimekim</span><span>|</span><a href="#42549241">root</a><span>|</span><a href="#42549382">parent</a><span>|</span><a href="#42551531">next</a><span>|</span><label class="collapse" for="c-42550682">[-]</label><label class="expand" for="c-42550682">[1 more]</label></div><br/><div class="children"><div class="content">In most cases this is just based on user agent. It&#x27;s widespread enough that I just habitually tell requests not to set a User Agent at all (these aren&#x27;t blocked, but if the UA contains &quot;python&quot; it is).</div><br/></div></div></div></div><div id="42551531" class="c"><input type="checkbox" id="c-42551531" checked=""/><div class="controls bullet"><span class="by">thrdbndndn</span><span>|</span><a href="#42549241">parent</a><span>|</span><a href="#42549382">prev</a><span>|</span><a href="#42549640">next</a><span>|</span><label class="collapse" for="c-42551531">[-]</label><label class="expand" for="c-42551531">[2 more]</label></div><br/><div class="children"><div class="content">Lots of sites, actually.<p>&gt; I doubt sites without serious anti-bot detection will do TLS fingerprinting<p>They don&#x27;t set it up themselves. CloudFlare offer such thing by default (?).</div><br/><div id="42551972" class="c"><input type="checkbox" id="c-42551972" checked=""/><div class="controls bullet"><span class="by">oefrha</span><span>|</span><a href="#42549241">root</a><span>|</span><a href="#42551531">parent</a><span>|</span><a href="#42549640">next</a><span>|</span><label class="collapse" for="c-42551972">[-]</label><label class="expand" for="c-42551972">[1 more]</label></div><br/><div class="children"><div class="content">Pretty sure it’s not default, and Cloudflare browser check and&#x2F;or captcha is a way bigger problem than TLS fingerprinting, at least was the case the last time I scraped a site behind Cloudflare.</div><br/></div></div></div></div><div id="42549640" class="c"><input type="checkbox" id="c-42549640" checked=""/><div class="controls bullet"><span class="by">Avamander</span><span>|</span><a href="#42549241">parent</a><span>|</span><a href="#42551531">prev</a><span>|</span><a href="#42552287">next</a><span>|</span><label class="collapse" for="c-42549640">[-]</label><label class="expand" for="c-42549640">[1 more]</label></div><br/><div class="children"><div class="content">CloudFlare offers it. Even if it&#x27;s not used for blocking it might be used for analytics or threat calculations, so you might get hit later.</div><br/></div></div><div id="42552287" class="c"><input type="checkbox" id="c-42552287" checked=""/><div class="controls bullet"><span class="by">remram</span><span>|</span><a href="#42549241">parent</a><span>|</span><a href="#42549640">prev</a><span>|</span><a href="#42551544">next</a><span>|</span><label class="collapse" for="c-42552287">[-]</label><label class="expand" for="c-42552287">[1 more]</label></div><br/><div class="children"><div class="content">Those JavaScript scripts often  get data from some API, and it&#x27;s that API that will usually be behind some fingerprinting wall.</div><br/></div></div></div></div><div id="42551544" class="c"><input type="checkbox" id="c-42551544" checked=""/><div class="controls bullet"><span class="by">jandrese</span><span>|</span><a href="#42549241">prev</a><span>|</span><a href="#42548915">next</a><span>|</span><label class="collapse" for="c-42551544">[-]</label><label class="expand" for="c-42551544">[4 more]</label></div><br/><div class="children"><div class="content">The build scripts on this repo seem a bit cursed.  It uses autotools but has you build them in a subdirectory.  The default built target is a help text instead of just building the project.  When you do use the listed build target it doesn&#x27;t have the dependencies set up correctly so you have to run it like 6 times to get to the point where it is building the application.<p>Ultimately I was not able to get it to build because the BoringSSL disto it downloaded failed to build even though I made sure all of the dependencies the INSTALL.md listed are installed.  This might be because the machine I was trying to build it on is an older Ubuntu 20 release.<p>Edit: Tried it on Ubuntu 22, but BoringSSL again failed to build.  The make script did work better however, only requiring a single invocation of make chrome-build before blowing up.<p>Looks like a classic case of &quot;don&#x27;t ship -Werror because compiler warnings are unpredictable&quot;.<p>Died on:<p>&#x2F;extensions.cc:3416:16: error: ‘ext_index’ may be used uninitialized in this function [-Werror=maybe-uninitialized]<p>The good news is that removing -Werror from the CMakeLists.txt in BoringSSL got around that issue.  Bad news is that the dependency list is incomplete.  You will also need libc++-XX-dev and libc++abi-XX-dev where the XX is the major version number of GCC on your machine.  Once you fix that it will successfully build, but the install process is slightly incomplete.  It doesn&#x27;t run ldconfig for you, you have to do it yourself.<p>On a final note, despite the name BoringSSL is huge library that takes a surprisingly long time to build.  I thought it would be like LibreSSL where they trim it down to the core to keep the attack surface samll, but apparently Google went in the opposite direction.</div><br/><div id="42554984" class="c"><input type="checkbox" id="c-42554984" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#42551544">parent</a><span>|</span><a href="#42552328">next</a><span>|</span><label class="collapse" for="c-42554984">[-]</label><label class="expand" for="c-42554984">[1 more]</label></div><br/><div class="children"><div class="content">Look on the bright side: the harder it is to build and use correctly, the harder it is for the enemy to analyse and react.</div><br/></div></div><div id="42552328" class="c"><input type="checkbox" id="c-42552328" checked=""/><div class="controls bullet"><span class="by">at0mic22</span><span>|</span><a href="#42551544">parent</a><span>|</span><a href="#42554984">prev</a><span>|</span><a href="#42553301">next</a><span>|</span><label class="collapse" for="c-42552328">[-]</label><label class="expand" for="c-42552328">[1 more]</label></div><br/><div class="children"><div class="content">Played this game and switched to prebuilt libraries. Think builder docker images have also been broken for a while.</div><br/></div></div><div id="42553301" class="c"><input type="checkbox" id="c-42553301" checked=""/><div class="controls bullet"><span class="by">38</span><span>|</span><a href="#42551544">parent</a><span>|</span><a href="#42552328">prev</a><span>|</span><a href="#42548915">next</a><span>|</span><label class="collapse" for="c-42553301">[-]</label><label class="expand" for="c-42553301">[1 more]</label></div><br/><div class="children"><div class="content">that&#x27;s exactly why I stopped using C&#x2F;C++. building is many times a nightmare, and the language teams seems to have no interest in improving the situation</div><br/></div></div></div></div><div id="42548915" class="c"><input type="checkbox" id="c-42548915" checked=""/><div class="controls bullet"><span class="by">zlagen</span><span>|</span><a href="#42551544">prev</a><span>|</span><a href="#42557438">next</a><span>|</span><label class="collapse" for="c-42548915">[-]</label><label class="expand" for="c-42548915">[5 more]</label></div><br/><div class="children"><div class="content">In case anyone is interested, I created something similar but for python(using chromium&#x27;s network stack) <a href="https:&#x2F;&#x2F;github.com&#x2F;lagenar&#x2F;python-cronet">https:&#x2F;&#x2F;github.com&#x2F;lagenar&#x2F;python-cronet</a>
I&#x27;m looking for help to create the build for windows.</div><br/><div id="42550867" class="c"><input type="checkbox" id="c-42550867" checked=""/><div class="controls bullet"><span class="by">Klonoar</span><span>|</span><a href="#42548915">parent</a><span>|</span><a href="#42549733">next</a><span>|</span><label class="collapse" for="c-42550867">[-]</label><label class="expand" for="c-42550867">[1 more]</label></div><br/><div class="children"><div class="content">Similar projects exist for C# (<a href="https:&#x2F;&#x2F;github.com&#x2F;sleeyax&#x2F;CronetSharp">https:&#x2F;&#x2F;github.com&#x2F;sleeyax&#x2F;CronetSharp</a>), Go (<a href="https:&#x2F;&#x2F;github.com&#x2F;sleeyax&#x2F;cronet-go">https:&#x2F;&#x2F;github.com&#x2F;sleeyax&#x2F;cronet-go</a>) and Rust (<a href="https:&#x2F;&#x2F;github.com&#x2F;sleeyax&#x2F;cronet-rs">https:&#x2F;&#x2F;github.com&#x2F;sleeyax&#x2F;cronet-rs</a>).<p>These <i>can</i> work well in some cases but it&#x27;s always a tradeoff.</div><br/></div></div><div id="42549733" class="c"><input type="checkbox" id="c-42549733" checked=""/><div class="controls bullet"><span class="by">hk__2</span><span>|</span><a href="#42548915">parent</a><span>|</span><a href="#42550867">prev</a><span>|</span><a href="#42551569">next</a><span>|</span><label class="collapse" for="c-42549733">[-]</label><label class="expand" for="c-42549733">[2 more]</label></div><br/><div class="children"><div class="content">Any reason you didn’t use <a href="https:&#x2F;&#x2F;github.com&#x2F;lexiforest&#x2F;curl_cffi">https:&#x2F;&#x2F;github.com&#x2F;lexiforest&#x2F;curl_cffi</a>?</div><br/><div id="42550472" class="c"><input type="checkbox" id="c-42550472" checked=""/><div class="controls bullet"><span class="by">zlagen</span><span>|</span><a href="#42548915">root</a><span>|</span><a href="#42549733">parent</a><span>|</span><a href="#42551569">next</a><span>|</span><label class="collapse" for="c-42550472">[-]</label><label class="expand" for="c-42550472">[1 more]</label></div><br/><div class="children"><div class="content">I wanted to try a diffent approach which is to use chromium&#x27;s network stack directly instead of patching curl to impersonate it. In this case you&#x27;re using the real thing so it&#x27;s a bit easier to maintain when there are changes in the fingerprint.</div><br/></div></div></div></div><div id="42551569" class="c"><input type="checkbox" id="c-42551569" checked=""/><div class="controls bullet"><span class="by">thrdbndndn</span><span>|</span><a href="#42548915">parent</a><span>|</span><a href="#42549733">prev</a><span>|</span><a href="#42557438">next</a><span>|</span><label class="collapse" for="c-42551569">[-]</label><label class="expand" for="c-42551569">[1 more]</label></div><br/><div class="children"><div class="content">Any plan to offer a sync API?</div><br/></div></div></div></div><div id="42557438" class="c"><input type="checkbox" id="c-42557438" checked=""/><div class="controls bullet"><span class="by">jakeogh</span><span>|</span><a href="#42548915">prev</a><span>|</span><a href="#42550125">next</a><span>|</span><label class="collapse" for="c-42557438">[-]</label><label class="expand" for="c-42557438">[1 more]</label></div><br/><div class="children"><div class="content">(very rough) ebuild: <a href="https:&#x2F;&#x2F;github.com&#x2F;jakeogh&#x2F;jakeogh&#x2F;blob&#x2F;master&#x2F;net-misc&#x2F;curl-impersonate&#x2F;curl-impersonate-9999.ebuild">https:&#x2F;&#x2F;github.com&#x2F;jakeogh&#x2F;jakeogh&#x2F;blob&#x2F;master&#x2F;net-misc&#x2F;curl...</a></div><br/></div></div><div id="42550125" class="c"><input type="checkbox" id="c-42550125" checked=""/><div class="controls bullet"><span class="by">Sytten</span><span>|</span><a href="#42557438">prev</a><span>|</span><a href="#42548952">next</a><span>|</span><label class="collapse" for="c-42550125">[-]</label><label class="expand" for="c-42550125">[1 more]</label></div><br/><div class="children"><div class="content">Thankfully only a small fraction of website does JA3&#x2F;JA4 fingerprinting. Some do more advanced stuff like correlating headers to the fingerprint. We have been able to get away without doing much in Caido for a long time but I am working on an OSS rust based equivalent. Neat trick, you can use the fingerprint of our competitor (Burp Suite) since it is whitelisted for the security folks to do their job. Only time you will not hear me complain about checkbox security.</div><br/></div></div><div id="42548952" class="c"><input type="checkbox" id="c-42548952" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42550125">prev</a><span>|</span><a href="#42548784">next</a><span>|</span><label class="collapse" for="c-42548952">[-]</label><label class="expand" for="c-42548952">[1 more]</label></div><br/><div class="children"><div class="content">I recently used ja3proxy, which uses utls for the impersonation. It exposes an HTTP proxy that you can use with any regular HTTP client (unmodified curl, python, etc.) and wraps it in a TLS client fingerprint of your choice. Although I don&#x27;t think it does anything special for http&#x2F;2, which curl-impersonate does advertise support for.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;LyleMi&#x2F;ja3proxy">https:&#x2F;&#x2F;github.com&#x2F;LyleMi&#x2F;ja3proxy</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;refraction-networking&#x2F;utls">https:&#x2F;&#x2F;github.com&#x2F;refraction-networking&#x2F;utls</a></div><br/></div></div><div id="42548784" class="c"><input type="checkbox" id="c-42548784" checked=""/><div class="controls bullet"><span class="by">peetistaken</span><span>|</span><a href="#42548952">prev</a><span>|</span><a href="#42552714">next</a><span>|</span><label class="collapse" for="c-42548784">[-]</label><label class="expand" for="c-42548784">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;bogdanfinn&#x2F;tls-client">https:&#x2F;&#x2F;github.com&#x2F;bogdanfinn&#x2F;tls-client</a> is the go-to package for the go world, it does the same thing</div><br/></div></div><div id="42552714" class="c"><input type="checkbox" id="c-42552714" checked=""/><div class="controls bullet"><span class="by">kerblang</span><span>|</span><a href="#42548784">prev</a><span>|</span><a href="#42549026">next</a><span>|</span><label class="collapse" for="c-42552714">[-]</label><label class="expand" for="c-42552714">[1 more]</label></div><br/><div class="children"><div class="content">Interesting in light of another much-discussed story about AI scraper farms swamping&#x2F;DDOSing sites <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42549624">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42549624</a></div><br/></div></div><div id="42549026" class="c"><input type="checkbox" id="c-42549026" checked=""/><div class="controls bullet"><span class="by">TekMol</span><span>|</span><a href="#42552714">prev</a><span>|</span><a href="#42549055">next</a><span>|</span><label class="collapse" for="c-42549026">[-]</label><label class="expand" for="c-42549026">[10 more]</label></div><br/><div class="children"><div class="content">What is the use case? If you have to read data from one specific website which uses handshake info to avoid being read by software?<p>When I have to do HTTP requests these days, I default to a headless browser right away, because that seems to be the best bet. Even then, some website are not readable because they use captchas and whatnot.</div><br/><div id="42549290" class="c"><input type="checkbox" id="c-42549290" checked=""/><div class="controls bullet"><span class="by">adastral</span><span>|</span><a href="#42549026">parent</a><span>|</span><a href="#42549058">next</a><span>|</span><label class="collapse" for="c-42549290">[-]</label><label class="expand" for="c-42549290">[8 more]</label></div><br/><div class="children"><div class="content">&gt; I default to a headless browser<p>Headless browsers consume orders of magnitude more resources, and execute far more requests (e.g. fetching images) than a common webscraping job would require. Having run webscraping at scale myself, the cost of operating headless browsers made us only use them as a last resort.</div><br/><div id="42552305" class="c"><input type="checkbox" id="c-42552305" checked=""/><div class="controls bullet"><span class="by">at0mic22</span><span>|</span><a href="#42549026">root</a><span>|</span><a href="#42549290">parent</a><span>|</span><a href="#42550015">next</a><span>|</span><label class="collapse" for="c-42552305">[-]</label><label class="expand" for="c-42552305">[6 more]</label></div><br/><div class="children"><div class="content">Blocking all image&#x2F;video&#x2F;CSS requests is the rule of thumb when working with headless browsers via CDP</div><br/><div id="42552706" class="c"><input type="checkbox" id="c-42552706" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#42549026">root</a><span>|</span><a href="#42552305">parent</a><span>|</span><a href="#42550015">next</a><span>|</span><label class="collapse" for="c-42552706">[-]</label><label class="expand" for="c-42552706">[5 more]</label></div><br/><div class="children"><div class="content">Speaking as a person who has played on both offense and defense: this is a heuristic that&#x27;s not used frequently enough by defenders. Clients that load a single HTML&#x2F;JSON endpoint without loading css or image resources associated with the endpoints are likely bots (or user agents with a fully loaded cache, but defenders control what gets cached by legit clients and how). Bot data thriftiness is a huge signal.</div><br/><div id="42553076" class="c"><input type="checkbox" id="c-42553076" checked=""/><div class="controls bullet"><span class="by">at0mic22</span><span>|</span><a href="#42549026">root</a><span>|</span><a href="#42552706">parent</a><span>|</span><a href="#42553632">next</a><span>|</span><label class="collapse" for="c-42553076">[-]</label><label class="expand" for="c-42553076">[2 more]</label></div><br/><div class="children"><div class="content">As a high load system engineer you&#x27;d want to offload asset serving to CDN which makes detection slightly more complicated.
The easy way is to attach an image onload handler with client js, but that would give a high yield of false positives.
I personally have never seen such approach and doubt its useful for many concerns.</div><br/><div id="42553747" class="c"><input type="checkbox" id="c-42553747" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#42549026">root</a><span>|</span><a href="#42553076">parent</a><span>|</span><a href="#42553632">next</a><span>|</span><label class="collapse" for="c-42553747">[-]</label><label class="expand" for="c-42553747">[1 more]</label></div><br/><div class="children"><div class="content">Unless organization policy forces you to, you do not have to put <i>all</i> resources behind a CDN. As a matter of fact, getting this heuristic to work requires a non-optimal caching strategy of one or more real or decoy resources - CDN or not. &quot;Easy&quot; is not an option for the bot&#x2F;anti-bot arms race, all the low hanging fruit is now gone when fighting a determined adversary on either end.<p>&gt; I personally have never seen such approach and doubt its useful for many concerns.<p>It&#x27;s an arms race and defenders are not keen on sharing their secret sauce, though I can&#x27;t be the only one who thought of this rather basic bot characteristic, multiple abuse trams probably realized this decades ago. It works pretty well against the low-resource scrapers with fakes UA strings and all the right TLS handshakes. It won&#x27;t work against the headless browsers that costs scrapers more in resources and bandwidth, and there are specific countermeasures for headless browsers [1], and counter-countermeasures. It&#x27;s a cat and mouse game.<p>1. e.g. Mouse movement, as made famous as ine signal evaluated by Google&#x27;s reCAPTCHA v2, monitor resolution &amp; window size and position, and Canvas rendering, all if which have been gradually degraded by browser anti-fingerprinting efforts. The bot war is fought on the long tail.</div><br/></div></div></div></div><div id="42553632" class="c"><input type="checkbox" id="c-42553632" checked=""/><div class="controls bullet"><span class="by">zzo38computer</span><span>|</span><a href="#42549026">root</a><span>|</span><a href="#42552706">parent</a><span>|</span><a href="#42553076">prev</a><span>|</span><a href="#42550015">next</a><span>|</span><label class="collapse" for="c-42553632">[-]</label><label class="expand" for="c-42553632">[2 more]</label></div><br/><div class="children"><div class="content">Even legitimate users might want to disable CSS and pictures and whatever, and I often do when I just want to read the document.<p>Blind users also might have no use for the pictures, and another possibility is if the document is longer than the screen so the picture is out of view then the user might program the client software to use lazy loading, etc.</div><br/><div id="42556062" class="c"><input type="checkbox" id="c-42556062" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#42549026">root</a><span>|</span><a href="#42553632">parent</a><span>|</span><a href="#42550015">next</a><span>|</span><label class="collapse" for="c-42556062">[-]</label><label class="expand" for="c-42556062">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, that&#x27;s why it&#x27;s one heuristic&#x2F;signal among many others</div><br/></div></div></div></div></div></div></div></div><div id="42550015" class="c"><input type="checkbox" id="c-42550015" checked=""/><div class="controls bullet"><span class="by">TekMol</span><span>|</span><a href="#42549026">root</a><span>|</span><a href="#42549290">parent</a><span>|</span><a href="#42552305">prev</a><span>|</span><a href="#42549058">next</a><span>|</span><label class="collapse" for="c-42550015">[-]</label><label class="expand" for="c-42550015">[1 more]</label></div><br/><div class="children"><div class="content">So you maintain a table of domains and how to access them?<p>How do you build that table and keep it up to date? Manually?</div><br/></div></div></div></div><div id="42549058" class="c"><input type="checkbox" id="c-42549058" checked=""/><div class="controls bullet"><span class="by">mschuster91</span><span>|</span><a href="#42549026">parent</a><span>|</span><a href="#42549290">prev</a><span>|</span><a href="#42549055">next</a><span>|</span><label class="collapse" for="c-42549058">[-]</label><label class="expand" for="c-42549058">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What is the use case? If you have to read data from one specific website which uses handshake info to avoid being read by software?<p>Evade captchas. curl user agent &#x2F; heuristics are blocked by many sites these days - I&#x27;d guess many popular CDNs have pre-defined &quot;block bots&quot; stuff that blocks everything automated that is not a well-known search engine indexer.</div><br/></div></div></div></div><div id="42549055" class="c"><input type="checkbox" id="c-42549055" checked=""/><div class="controls bullet"><span class="by">jollyllama</span><span>|</span><a href="#42549026">prev</a><span>|</span><a href="#42554901">next</a><span>|</span><label class="collapse" for="c-42549055">[-]</label><label class="expand" for="c-42549055">[4 more]</label></div><br/><div class="children"><div class="content">&gt;The Client Hello message that most HTTP clients and libraries produce differs drastically from that of a real browser.<p>Why is this?</div><br/><div id="42549106" class="c"><input type="checkbox" id="c-42549106" checked=""/><div class="controls bullet"><span class="by">throwaway99210</span><span>|</span><a href="#42549055">parent</a><span>|</span><a href="#42549124">next</a><span>|</span><label class="collapse" for="c-42549106">[-]</label><label class="expand" for="c-42549106">[1 more]</label></div><br/><div class="children"><div class="content">Based on what I&#x27;ve seen, most command-line clients and basic HTTP libraries typically ship with leaner, more static configurations (e.g., no GREASE extensions in the Client Hello, limited protocols in the ALPN extension header, smaller number of Signature Algorithms). Mirroring real browser TLS fingerprints is also more difficult due to the randomization of the Client Hello parameters (e.g., current versions of Chrome)</div><br/></div></div><div id="42549124" class="c"><input type="checkbox" id="c-42549124" checked=""/><div class="controls bullet"><span class="by">zlagen</span><span>|</span><a href="#42549055">parent</a><span>|</span><a href="#42549106">prev</a><span>|</span><a href="#42549110">next</a><span>|</span><label class="collapse" for="c-42549124">[-]</label><label class="expand" for="c-42549124">[1 more]</label></div><br/><div class="children"><div class="content">They use different SSL libraries&#x2F;configuration. Chrome uses BoringSSL and other libraries may use OpenSSL or some other library.
Besides that the SSL library may be configured with different cipher suites and extensions. The solution these impersonators provide is to use the same SSL library and configuration as a real browser.</div><br/></div></div><div id="42549110" class="c"><input type="checkbox" id="c-42549110" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42549055">parent</a><span>|</span><a href="#42549124">prev</a><span>|</span><a href="#42554901">next</a><span>|</span><label class="collapse" for="c-42549110">[-]</label><label class="expand" for="c-42549110">[1 more]</label></div><br/><div class="children"><div class="content">The protocols are flexible and most browsers bring their own HTTP+TLS clients</div><br/></div></div></div></div><div id="42554901" class="c"><input type="checkbox" id="c-42554901" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#42549055">prev</a><span>|</span><a href="#42549569">next</a><span>|</span><label class="collapse" for="c-42554901">[-]</label><label class="expand" for="c-42554901">[2 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t help but think that projects like these shouldn&#x27;t be posted here, since the enemy is among us. Prodding the bear even more might lead to an acceleration towards the dystopia that others here have already prophesised.<p><i>The following browsers can be impersonated.</i><p>...unfortunately no Firefox to be seen.<p>I&#x27;ve had to fight this too, since I use a filtering proxy. User-agent discrimination should be illegal. One may think the EU could have some power to change things, but then again, they&#x27;re also hugely into the whole &quot;digital identity&quot; thing.</div><br/><div id="42555202" class="c"><input type="checkbox" id="c-42555202" checked=""/><div class="controls bullet"><span class="by">crtasm</span><span>|</span><a href="#42554901">parent</a><span>|</span><a href="#42549569">next</a><span>|</span><label class="collapse" for="c-42555202">[-]</label><label class="expand" for="c-42555202">[1 more]</label></div><br/><div class="children"><div class="content">It says &quot;Firefox(In progress)&quot;, and the original project this was forked from has it: <a href="https:&#x2F;&#x2F;github.com&#x2F;lwthiker&#x2F;curl-impersonate">https:&#x2F;&#x2F;github.com&#x2F;lwthiker&#x2F;curl-impersonate</a></div><br/></div></div></div></div><div id="42549569" class="c"><input type="checkbox" id="c-42549569" checked=""/><div class="controls bullet"><span class="by">aninteger</span><span>|</span><a href="#42554901">prev</a><span>|</span><a href="#42548743">next</a><span>|</span><label class="collapse" for="c-42549569">[-]</label><label class="expand" for="c-42549569">[3 more]</label></div><br/><div class="children"><div class="content">I think we should list the sites where this fingerprinting is done. I have a suspicion that Microsoft does it for conditional access policies but I am not sure of other services.</div><br/><div id="42549643" class="c"><input type="checkbox" id="c-42549643" checked=""/><div class="controls bullet"><span class="by">Galanwe</span><span>|</span><a href="#42549569">parent</a><span>|</span><a href="#42552151">next</a><span>|</span><label class="collapse" for="c-42549643">[-]</label><label class="expand" for="c-42549643">[1 more]</label></div><br/><div class="children"><div class="content">We cannot really list them, as 90% of the time, it&#x27;s not the websites themselves, it&#x27;s their WAF. And there is a trend toward most company websites to be behind a WAF nowadays to avoid 1) annoying regulations (US companies putting geoloc on their websites to avoid EU cookie regulations) and 2) DDoS.<p>It&#x27;s now pretty common to have cloudflare, AWS, etc WAFs as main endpoints, and these do anti bots (TLS fingerprinting, header fingerprinting, Javascript checks, capt has, etc).</div><br/></div></div><div id="42552151" class="c"><input type="checkbox" id="c-42552151" checked=""/><div class="controls bullet"><span class="by">pixelesque</span><span>|</span><a href="#42549569">parent</a><span>|</span><a href="#42549643">prev</a><span>|</span><a href="#42548743">next</a><span>|</span><label class="collapse" for="c-42552151">[-]</label><label class="expand" for="c-42552151">[1 more]</label></div><br/><div class="children"><div class="content">Cloudflare (which seems to be fronting half the web these days based off the number of cf-ray cookies that I see being sent back) does this with bot protection on, and Akamai has something similar I think.</div><br/></div></div></div></div><div id="42548743" class="c"><input type="checkbox" id="c-42548743" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#42549569">prev</a><span>|</span><a href="#42549303">next</a><span>|</span><label class="collapse" for="c-42548743">[-]</label><label class="expand" for="c-42548743">[7 more]</label></div><br/><div class="children"><div class="content">&gt; The resulting curl looks, from a network perspective, identical to a real browser.<p>How close is it?     If I ran wireshark, would the bytes be exactly the same in the exact same packets?</div><br/><div id="42548837" class="c"><input type="checkbox" id="c-42548837" checked=""/><div class="controls bullet"><span class="by">jsnell</span><span>|</span><a href="#42548743">parent</a><span>|</span><a href="#42549540">next</a><span>|</span><label class="collapse" for="c-42548837">[-]</label><label class="expand" for="c-42548837">[1 more]</label></div><br/><div class="children"><div class="content">The packets from Chrome wouldn&#x27;t be exactly the same as packets sent by Chrome at a different time either. &quot;The exact same packets&quot; is not a viable benchmark, since both the client and the server randomize the payloads in various ways. (E.g. key exchange, GREASE).</div><br/></div></div><div id="42549540" class="c"><input type="checkbox" id="c-42549540" checked=""/><div class="controls bullet"><span class="by">peetistaken</span><span>|</span><a href="#42548743">parent</a><span>|</span><a href="#42548837">prev</a><span>|</span><a href="#42548796">next</a><span>|</span><label class="collapse" for="c-42549540">[-]</label><label class="expand" for="c-42549540">[1 more]</label></div><br/><div class="children"><div class="content">You can check your fingerprint on <a href="https:&#x2F;&#x2F;tls.peet.ws" rel="nofollow">https:&#x2F;&#x2F;tls.peet.ws</a></div><br/></div></div><div id="42548796" class="c"><input type="checkbox" id="c-42548796" checked=""/><div class="controls bullet"><span class="by">dchest</span><span>|</span><a href="#42548743">parent</a><span>|</span><a href="#42549540">prev</a><span>|</span><a href="#42549303">next</a><span>|</span><label class="collapse" for="c-42548796">[-]</label><label class="expand" for="c-42548796">[4 more]</label></div><br/><div class="children"><div class="content">What else could &quot;identical&quot; mean?</div><br/><div id="42548832" class="c"><input type="checkbox" id="c-42548832" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#42548743">root</a><span>|</span><a href="#42548796">parent</a><span>|</span><a href="#42549303">next</a><span>|</span><label class="collapse" for="c-42548832">[-]</label><label class="expand" for="c-42548832">[3 more]</label></div><br/><div class="children"><div class="content">It could be that the TCP streams are the same, but packetiation is different.<p>It could mean that the packets are the same, but timing is off by a few milliseconds.<p>It could mean a single HTTP request exactly matches, but when doing two requests the real browser uses a connection pool but curl doesn&#x27;t.  Or uses HTTP&#x2F;3&#x27;s fast-open abilities, etc.<p>etc.</div><br/><div id="42548982" class="c"><input type="checkbox" id="c-42548982" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42548743">root</a><span>|</span><a href="#42548832">parent</a><span>|</span><a href="#42548933">next</a><span>|</span><label class="collapse" for="c-42548982">[-]</label><label class="expand" for="c-42548982">[1 more]</label></div><br/><div class="children"><div class="content">Two TLS streams are never byte-identical, due to randomness inherent to the protocol.<p>Identical here means having the same fingerprint - i.e. you could not write a function to reliably distinguish traffic from one or the other implementation (and if you can then that&#x27;s a bug).</div><br/></div></div><div id="42548933" class="c"><input type="checkbox" id="c-42548933" checked=""/><div class="controls bullet"><span class="by">zlagen</span><span>|</span><a href="#42548743">root</a><span>|</span><a href="#42548832">parent</a><span>|</span><a href="#42548982">prev</a><span>|</span><a href="#42549303">next</a><span>|</span><label class="collapse" for="c-42548933">[-]</label><label class="expand" for="c-42548933">[1 more]</label></div><br/><div class="children"><div class="content">It replicates the browser at the HTTP&#x2F;SSL level, not TCP. From what I know this is good enough to bypass cloudflare&#x27;s bot detection.</div><br/></div></div></div></div></div></div></div></div><div id="42549303" class="c"><input type="checkbox" id="c-42549303" checked=""/><div class="controls bullet"><span class="by">ape4</span><span>|</span><a href="#42548743">prev</a><span>|</span><a href="#42552411">next</a><span>|</span><label class="collapse" for="c-42549303">[-]</label><label class="expand" for="c-42549303">[2 more]</label></div><br/><div class="children"><div class="content">I like this project!<p>Is there a way to request impersonization of the current version of Chrome (or whatever)?</div><br/><div id="42557472" class="c"><input type="checkbox" id="c-42557472" checked=""/><div class="controls bullet"><span class="by">jakeogh</span><span>|</span><a href="#42549303">parent</a><span>|</span><a href="#42552411">next</a><span>|</span><label class="collapse" for="c-42557472">[-]</label><label class="expand" for="c-42557472">[1 more]</label></div><br/><div class="children"><div class="content">The current version is always a moving new target, but you get the following programs which emulate each browser (these are wrapper scripts that pass the appropriate arguments to mirror each browser):<p><pre><code>  $ curl_chrome &lt;TAB&gt;&lt;TAB&gt;
  curl_chrome100
  curl_chrome104
  curl_chrome110
  curl_chrome119
  curl_chrome123
  curl_chrome131
  curl_chrome99           
  curl_chrome101
  curl_chrome107
  curl_chrome116
  curl_chrome120
  curl_chrome124
  curl_chrome131_android
  curl_chrome99_android</code></pre></div><br/></div></div></div></div></div></div></div></div></div></body></html>