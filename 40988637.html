<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1721638876449" as="style"/><link rel="stylesheet" href="styles.css?v=1721638876449"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Ask HN: What&#x27;s your preferred logging stack in Kubernetes</a> </div><div class="subtext"><span>ryanisnan</span> | <span>28 comments</span></div><br/><div><div id="41032036" class="c"><input type="checkbox" id="c-41032036" checked=""/><div class="controls bullet"><span class="by">vbezhenar</span><span>|</span><a href="#41031668">next</a><span>|</span><label class="collapse" for="c-41032036">[-]</label><label class="expand" for="c-41032036">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m using loki with S3 storage (not AWS, OpenStack Swift that my hoster sells). Can&#x27;t say I&#x27;m amazed, logcli is not pleasant to use, Grafana integration is very bare-bones and I spent more than I&#x27;d like to make it work smoothly, but in the end it works, so no big issues either. Log retention is configured in loki and storage costs are low, it compresses things well.</div><br/></div></div><div id="41031668" class="c"><input type="checkbox" id="c-41031668" checked=""/><div class="controls bullet"><span class="by">wczekalski</span><span>|</span><a href="#41032036">prev</a><span>|</span><a href="#41031892">next</a><span>|</span><label class="collapse" for="c-41031668">[-]</label><label class="expand" for="c-41031668">[2 more]</label></div><br/><div class="children"><div class="content">Loki is not bad but PSA, don&#x27;t use it with anything else than real AWS S3. The performance with Minio is awful (and can&#x27;t be good, because of how minio works). Might be a bit better with Seaweedfs.</div><br/><div id="41031711" class="c"><input type="checkbox" id="c-41031711" checked=""/><div class="controls bullet"><span class="by">teeheelol</span><span>|</span><a href="#41031668">parent</a><span>|</span><a href="#41031892">next</a><span>|</span><label class="collapse" for="c-41031711">[-]</label><label class="expand" for="c-41031711">[1 more]</label></div><br/><div class="children"><div class="content">Yeah this. Make sure you provision lots of memcache chunk caches as well because S3 is slow as shit.</div><br/></div></div></div></div><div id="41031892" class="c"><input type="checkbox" id="c-41031892" checked=""/><div class="controls bullet"><span class="by">relistan</span><span>|</span><a href="#41031668">prev</a><span>|</span><a href="#41031518">next</a><span>|</span><label class="collapse" for="c-41031892">[-]</label><label class="expand" for="c-41031892">[1 more]</label></div><br/><div class="children"><div class="content">Since 2017, at two different companies, I’ve sent logs via UDP to Sumo Logic, via their  collector hosted in our cluster. Sumo Logic is reasonably priced, super powerful, easy to use, and really flexible. Can’t recommend it enough.<p>We do log collection and per service log rate limiting via <a href="https:&#x2F;&#x2F;github.com&#x2F;NinesStack&#x2F;logtailer">https:&#x2F;&#x2F;github.com&#x2F;NinesStack&#x2F;logtailer</a> to make sure we don’t blow out the budget because someone deployed with debug logging enabled. Fluentbit doesn’t support that per service. Logs are primarily for debugging and we send metrics separately. Rate limiting logs encourages good logging practices as well, because people want to be sure they have the valuable logs when they need them. We dashboard which services are hitting the rate limit. This usually indicates something more deeply wrong that otherwise didn’t get caught.<p>This logging setup gives us everything we’ve needed in seven years of production on two stacks.</div><br/></div></div><div id="41031518" class="c"><input type="checkbox" id="c-41031518" checked=""/><div class="controls bullet"><span class="by">jpgvm</span><span>|</span><a href="#41031892">prev</a><span>|</span><a href="#41031809">next</a><span>|</span><label class="collapse" for="c-41031518">[-]</label><label class="expand" for="c-41031518">[1 more]</label></div><br/><div class="children"><div class="content">They all sort of suck to be honest. The least suck has actually been hosted Google Cloud Logging of late, it&#x27;s just &quot;not bad enough&quot; to get the job done.<p>When I worked at Postmates we had a proprietary log search built on Clickhouse which was excelent. The same idea was also implemented concurrently at Uber (yay multiple discovery) and is documented at a relatively high level here: <a href="https:&#x2F;&#x2F;www.uber.com&#x2F;blog&#x2F;logging&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.uber.com&#x2F;blog&#x2F;logging&#x2F;</a><p>If gun was placed to head I would rebuild that over running the existing logging solutions.<p>I also worked for several months on building my own purpose built logging storage and indexing engine based trigram bitmap indices for accelerated regex searches ala CodeSearch but I ran out of motivation to finish it and commercialisation seemed very difficult, too much competition even if that competition is bad.
Really really should get around to finishing it enough that it can be OSSed at least.</div><br/></div></div><div id="41031809" class="c"><input type="checkbox" id="c-41031809" checked=""/><div class="controls bullet"><span class="by">pradeepchhetri</span><span>|</span><a href="#41031518">prev</a><span>|</span><a href="#41031244">next</a><span>|</span><label class="collapse" for="c-41031809">[-]</label><label class="expand" for="c-41031809">[1 more]</label></div><br/><div class="children"><div class="content">I would recommend using ClickHouse which provides very efficient compression and thus reduces the size of data drastically.<p>Apart from that, it provides various other feature:<p>- Dynamic datatype [0] which are very useful for semi-structured fields which generally logs contains very often.<p>- You can configure column&#x27;s &amp; table&#x27;s TTL [1] which provides efficient way to configure retention.<p>At my previous job (Cloudflare), we migrated from Elasticsearch to ClickHouse and saved nearly 10x reduction in data size and got 5x perf improvement. You can read more about it [2] and watch the recording here [3]<p>Recently, ClickHouse engineers published a wondering detailed blog about their logging pipeline [4]<p>[0] <a href="https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;sql-reference&#x2F;data-types&#x2F;dynamic" rel="nofollow">https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;sql-reference&#x2F;data-types&#x2F;dyna...</a><p>[1] <a href="https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;engines&#x2F;table-engines&#x2F;mergetree-family&#x2F;mergetree#table_engine-mergetree-ttl" rel="nofollow">https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;engines&#x2F;table-engines&#x2F;mergetr...</a><p>[2] <a href="https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;log-analytics-using-clickhouse" rel="nofollow">https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;log-analytics-using-clickhouse</a><p>[3] <a href="https:&#x2F;&#x2F;vimeo.com&#x2F;730379928" rel="nofollow">https:&#x2F;&#x2F;vimeo.com&#x2F;730379928</a><p>[4] <a href="https:&#x2F;&#x2F;clickhouse.com&#x2F;blog&#x2F;building-a-logging-platform-with-clickhouse-and-saving-millions-over-datadog" rel="nofollow">https:&#x2F;&#x2F;clickhouse.com&#x2F;blog&#x2F;building-a-logging-platform-with...</a></div><br/></div></div><div id="41031244" class="c"><input type="checkbox" id="c-41031244" checked=""/><div class="controls bullet"><span class="by">nullify88</span><span>|</span><a href="#41031809">prev</a><span>|</span><a href="#41031844">next</a><span>|</span><label class="collapse" for="c-41031244">[-]</label><label class="expand" for="c-41031244">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m currently migrating from Elasticsearch to Loki, and it&#x27;s much simpler to run and still meet our requirements.<p>I think Elasticsearch had its day when it&#x27;s used to derive metrics from logs and performing aggregate searches. But now as logging is often paired with metrics from Prometheus or similar tdb, we don&#x27;t run such complex log queries anymore, and so we find ourselves questioning whether it&#x27;s worth running such a intensive and complex Elasticsearch installation.</div><br/></div></div><div id="41031844" class="c"><input type="checkbox" id="c-41031844" checked=""/><div class="controls bullet"><span class="by">nikolay_sivko</span><span>|</span><a href="#41031244">prev</a><span>|</span><a href="#41031654">next</a><span>|</span><label class="collapse" for="c-41031844">[-]</label><label class="expand" for="c-41031844">[1 more]</label></div><br/><div class="children"><div class="content">Take a look at Coroot [0], which stores logs in ClickHouse with configurable TTL. Its agent can discover container logs and extract repeated patterns from logs [1].<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;coroot&#x2F;coroot">https:&#x2F;&#x2F;github.com&#x2F;coroot&#x2F;coroot</a><p>[1] demo: <a href="https:&#x2F;&#x2F;community-demo.coroot.com&#x2F;p&#x2F;qcih204s&#x2F;app&#x2F;default:Deployment:recommendations&#x2F;Logs?query=%7B%22source%22%3A%22agent%22,%22view%22%3A%22patterns%22%7D" rel="nofollow">https:&#x2F;&#x2F;community-demo.coroot.com&#x2F;p&#x2F;qcih204s&#x2F;app&#x2F;default:Dep...</a></div><br/></div></div><div id="41031654" class="c"><input type="checkbox" id="c-41031654" checked=""/><div class="controls bullet"><span class="by">loosescrews</span><span>|</span><a href="#41031844">prev</a><span>|</span><a href="#40988692">next</a><span>|</span><label class="collapse" for="c-41031654">[-]</label><label class="expand" for="c-41031654">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not entirely sold on it yet, but Quickwit seems to be the current trendy solution.</div><br/></div></div><div id="40988692" class="c"><input type="checkbox" id="c-40988692" checked=""/><div class="controls bullet"><span class="by">Atreiden</span><span>|</span><a href="#41031654">prev</a><span>|</span><a href="#41031278">next</a><span>|</span><label class="collapse" for="c-40988692">[-]</label><label class="expand" for="c-40988692">[6 more]</label></div><br/><div class="children"><div class="content">Loki backed by S3 and queried via Grafana is a good, mostly FOSS solution. Installs pretty easily via helm and S3 gives a reasonable balance between cost, ease, and durability if you&#x27;re in AWS already.</div><br/><div id="40989335" class="c"><input type="checkbox" id="c-40989335" checked=""/><div class="controls bullet"><span class="by">ryanisnan</span><span>|</span><a href="#40988692">parent</a><span>|</span><a href="#41031278">next</a><span>|</span><label class="collapse" for="c-40989335">[-]</label><label class="expand" for="c-40989335">[5 more]</label></div><br/><div class="children"><div class="content">That&#x27;s kind of what we were thinking about as a next stack to experiment with.<p>How difficult have you found scaling Loki?<p>One concern I have with our current setup is the frequency that we need to step in and manually intervene.</div><br/><div id="41031118" class="c"><input type="checkbox" id="c-41031118" checked=""/><div class="controls bullet"><span class="by">rootsu</span><span>|</span><a href="#40988692">root</a><span>|</span><a href="#40989335">parent</a><span>|</span><a href="#41031278">next</a><span>|</span><label class="collapse" for="c-41031118">[-]</label><label class="expand" for="c-41031118">[4 more]</label></div><br/><div class="children"><div class="content">What kind of issues that you see where you have to step in and intervene? We have been running Loki for a long time, and it barely requires any manual intervention apart from version upgrades.</div><br/><div id="41031212" class="c"><input type="checkbox" id="c-41031212" checked=""/><div class="controls bullet"><span class="by">sureglymop</span><span>|</span><a href="#40988692">root</a><span>|</span><a href="#41031118">parent</a><span>|</span><a href="#41031137">next</a><span>|</span><label class="collapse" for="c-41031212">[-]</label><label class="expand" for="c-41031212">[2 more]</label></div><br/><div class="children"><div class="content">One thing that I find hard is configuring the retention time. The docs are unclear and there are about 3 configuration parameters involved. It scares me as a non expert because I don&#x27;t want to fill up all disk space but also don&#x27;t want to keep too little logs.</div><br/><div id="41031452" class="c"><input type="checkbox" id="c-41031452" checked=""/><div class="controls bullet"><span class="by">raffraffraff</span><span>|</span><a href="#40988692">root</a><span>|</span><a href="#41031212">parent</a><span>|</span><a href="#41031137">next</a><span>|</span><label class="collapse" for="c-41031452">[-]</label><label class="expand" for="c-41031452">[1 more]</label></div><br/><div class="children"><div class="content">You can log straight to s3 and use policies there to clean up old logs</div><br/></div></div></div></div><div id="41031137" class="c"><input type="checkbox" id="c-41031137" checked=""/><div class="controls bullet"><span class="by">theBaus</span><span>|</span><a href="#40988692">root</a><span>|</span><a href="#41031118">parent</a><span>|</span><a href="#41031212">prev</a><span>|</span><a href="#41031278">next</a><span>|</span><label class="collapse" for="c-41031137">[-]</label><label class="expand" for="c-41031137">[1 more]</label></div><br/><div class="children"><div class="content">Yes I agree with rootsu, we have been running Loki in production for over two years and rarely have to step in and fix things. It&#x27;s very stable and performant.</div><br/></div></div></div></div></div></div></div></div><div id="41031278" class="c"><input type="checkbox" id="c-41031278" checked=""/><div class="controls bullet"><span class="by">YZF</span><span>|</span><a href="#40988692">prev</a><span>|</span><a href="#41031544">next</a><span>|</span><label class="collapse" for="c-41031278">[-]</label><label class="expand" for="c-41031278">[1 more]</label></div><br/><div class="children"><div class="content">Filebeat + ELK stack is pretty good. You can easily run filebeat as a daemonset and have it detect all your pods and logs. This is what I&#x27;m using right now.<p>Otherwise Loki. Also seen used and I think it&#x27;s fine. That&#x27;s more &quot;pure&quot; logging where ELK has more advanced searching&#x2F;indexing&#x2F;dashboards etc.</div><br/></div></div><div id="41031544" class="c"><input type="checkbox" id="c-41031544" checked=""/><div class="controls bullet"><span class="by">wanderingmind</span><span>|</span><a href="#41031278">prev</a><span>|</span><a href="#41031150">next</a><span>|</span><label class="collapse" for="c-41031544">[-]</label><label class="expand" for="c-41031544">[3 more]</label></div><br/><div class="children"><div class="content">Can some one ELI5  why logging with loki is better than using a database like sqlite or postgresql.</div><br/><div id="41031571" class="c"><input type="checkbox" id="c-41031571" checked=""/><div class="controls bullet"><span class="by">fire_lake</span><span>|</span><a href="#41031544">parent</a><span>|</span><a href="#41031721">next</a><span>|</span><label class="collapse" for="c-41031571">[-]</label><label class="expand" for="c-41031571">[1 more]</label></div><br/><div class="children"><div class="content">Log data is often massive so you don’t want to be paying for a gigantic Postgres instance for storage. Logs also do not get updated, so the transactionality of Postgres is wasted.</div><br/></div></div><div id="41031721" class="c"><input type="checkbox" id="c-41031721" checked=""/><div class="controls bullet"><span class="by">hckr1292</span><span>|</span><a href="#41031544">parent</a><span>|</span><a href="#41031571">prev</a><span>|</span><a href="#41031150">next</a><span>|</span><label class="collapse" for="c-41031721">[-]</label><label class="expand" for="c-41031721">[1 more]</label></div><br/><div class="children"><div class="content">Scalability and cost -- Loki stores the the actual log data on S3 and only keeps an index of a few fields. Log queries that can then efficiently target the (hopefully small) set of files containing the data and loki can re-parse those specific files from S3 to display the log results.</div><br/></div></div></div></div><div id="41031150" class="c"><input type="checkbox" id="c-41031150" checked=""/><div class="controls bullet"><span class="by">cyberpunk</span><span>|</span><a href="#41031544">prev</a><span>|</span><a href="#41031098">next</a><span>|</span><label class="collapse" for="c-41031150">[-]</label><label class="expand" for="c-41031150">[5 more]</label></div><br/><div class="children"><div class="content">EFK. Loki just sucks if you’re used to kibana searches.</div><br/><div id="41031217" class="c"><input type="checkbox" id="c-41031217" checked=""/><div class="controls bullet"><span class="by">imp0cat</span><span>|</span><a href="#41031150">parent</a><span>|</span><a href="#41031098">next</a><span>|</span><label class="collapse" for="c-41031217">[-]</label><label class="expand" for="c-41031217">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s quite sufficient for logs that you&#x27;d just cat&#x2F;grep anyways.</div><br/><div id="41031432" class="c"><input type="checkbox" id="c-41031432" checked=""/><div class="controls bullet"><span class="by">cyberpunk</span><span>|</span><a href="#41031150">root</a><span>|</span><a href="#41031217">parent</a><span>|</span><a href="#41031423">next</a><span>|</span><label class="collapse" for="c-41031432">[-]</label><label class="expand" for="c-41031432">[2 more]</label></div><br/><div class="children"><div class="content">Except there is no grep? You can’t just type a search into the box on an unindexed field can you? It’s a bit more like Prometheus in that stuff has to be labelled and you just get all of it? Or am I using it wrong?</div><br/><div id="41031622" class="c"><input type="checkbox" id="c-41031622" checked=""/><div class="controls bullet"><span class="by">theblazehen</span><span>|</span><a href="#41031150">root</a><span>|</span><a href="#41031432">parent</a><span>|</span><a href="#41031423">next</a><span>|</span><label class="collapse" for="c-41031622">[-]</label><label class="expand" for="c-41031622">[1 more]</label></div><br/><div class="children"><div class="content">You can, try using 
|= &quot;your text string&quot;
appended to your logql query</div><br/></div></div></div></div><div id="41031423" class="c"><input type="checkbox" id="c-41031423" checked=""/><div class="controls bullet"><span class="by">raffraffraff</span><span>|</span><a href="#41031150">root</a><span>|</span><a href="#41031217">parent</a><span>|</span><a href="#41031432">prev</a><span>|</span><a href="#41031098">next</a><span>|</span><label class="collapse" for="c-41031423">[-]</label><label class="expand" for="c-41031423">[1 more]</label></div><br/><div class="children"><div class="content">...but it&#x27;s superpower is that Grafana can put metric panels right beside error log panels. If a graphs show you a spike in errors, you zoom in on the spike and the error logs panel zooms to the same period. So it&#x27;s like cat&#x2F;grep with a visual cue.</div><br/></div></div></div></div></div></div><div id="41031098" class="c"><input type="checkbox" id="c-41031098" checked=""/><div class="controls bullet"><span class="by">rootsu</span><span>|</span><a href="#41031150">prev</a><span>|</span><a href="#41031258">next</a><span>|</span><label class="collapse" for="c-41031098">[-]</label><label class="expand" for="c-41031098">[1 more]</label></div><br/><div class="children"><div class="content">Self-hosted Loki + Traces using Tempo + Grafana.</div><br/></div></div><div id="41031258" class="c"><input type="checkbox" id="c-41031258" checked=""/><div class="controls bullet"><span class="by">GauntletWizard</span><span>|</span><a href="#41031098">prev</a><span>|</span><a href="#41031103">next</a><span>|</span><label class="collapse" for="c-41031258">[-]</label><label class="expand" for="c-41031258">[1 more]</label></div><br/><div class="children"><div class="content">Stop using logging. You&#x27;re using logging wrong and there is no using it right. Logging (unqualified) is for temporary debugging data. It shouldn&#x27;t go anywhere or be aggregated unless you need to be debugging, and then it should go to the developer doing the debugging&#x27;s machine.<p>Request logging should be done in a structured form. You don&#x27;t need an indexing solution for this kind of request logging - It&#x27;s vaguely timestamp ordered, and that&#x27;s about it. If you need to search it, it gets loaded into a structured data query engine - Spark, or Bigquery&#x2F;Athena.<p>Audit logging belongs in a durable database and it requires being written and committed before the request is finished serving - Logging frameworks that dump to disk or stdout obviously fail his requirement.</div><br/></div></div><div id="41031103" class="c"><input type="checkbox" id="c-41031103" checked=""/><div class="controls bullet"><span class="by">endre</span><span>|</span><a href="#41031258">prev</a><span>|</span><label class="collapse" for="c-41031103">[-]</label><label class="expand" for="c-41031103">[1 more]</label></div><br/><div class="children"><div class="content">one word: axoflow</div><br/></div></div></div></div></div></div></div></body></html>