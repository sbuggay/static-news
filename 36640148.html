<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1688806856383" as="style"/><link rel="stylesheet" href="styles.css?v=1688806856383"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2307.01415">Matrix Multiplication Using Only Addition</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>daniel-cussen</span> | <span>67 comments</span></div><br/><div><div id="36641420" class="c"><input type="checkbox" id="c-36641420" checked=""/><div class="controls bullet"><span class="by">Drunk_Engineer</span><span>|</span><a href="#36640754">next</a><span>|</span><label class="collapse" for="c-36641420">[-]</label><label class="expand" for="c-36641420">[4 more]</label></div><br/><div class="children"><div class="content">As a chip designer, I&#x27;m dubious of this claim:<p>&quot;The advantage of performing matrix multiplication using only addition for arithmetic is that it then becomes feasible to build special- purpose chips with no multiplier circuits. Such chips will take up less space per on-chip processor.&quot;<p>Perhaps that is true in a toy design, but in real-world chips the multiplier uses only a very tiny fraction of chip real-estate. And even if the matrix-multiply can be eliminated, there are other uses for multiply operations.<p>I once attended a chip design conference where NVidia discussed its latest GPU. In one of the slides showing block layout, the designers pointed out how barely any silicon was being used for actual floating operations -- the vast majority was for pipelining and moving bits around.</div><br/><div id="36642341" class="c"><input type="checkbox" id="c-36642341" checked=""/><div class="controls bullet"><span class="by">brigade</span><span>|</span><a href="#36641420">parent</a><span>|</span><a href="#36641558">next</a><span>|</span><label class="collapse" for="c-36642341">[-]</label><label class="expand" for="c-36642341">[1 more]</label></div><br/><div class="children"><div class="content">That’s because CPUs and GPUs are useful for more than just matrix multiplication. TPUs aren’t; they assume highly regular data movement in and out of the ALUs.</div><br/></div></div><div id="36641558" class="c"><input type="checkbox" id="c-36641558" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#36641420">parent</a><span>|</span><a href="#36642341">prev</a><span>|</span><a href="#36640754">next</a><span>|</span><label class="collapse" for="c-36641558">[-]</label><label class="expand" for="c-36641558">[2 more]</label></div><br/><div class="children"><div class="content">It of course depends on workload but I know more than a little about this specific problem space and reducing the space+energy cost of the multipliers is useful. If the idea proposed worked well enough it might be a useful block in a camera ISP chip, audio interface for wake word and speech preprocessing, and similar applications where the models are small and energy is precious.</div><br/><div id="36641573" class="c"><input type="checkbox" id="c-36641573" checked=""/><div class="controls bullet"><span class="by">creato</span><span>|</span><a href="#36641420">root</a><span>|</span><a href="#36641558">parent</a><span>|</span><a href="#36640754">next</a><span>|</span><label class="collapse" for="c-36641573">[-]</label><label class="expand" for="c-36641573">[1 more]</label></div><br/><div class="children"><div class="content">I don’t know, sorting requires a lot of moving data around, which is expensive for energy too. Maybe this will be used for vectors of small fixed&#x2F;bounded size, but then you don’t get to amortize the cost of the logs as much either.</div><br/></div></div></div></div></div></div><div id="36640754" class="c"><input type="checkbox" id="c-36640754" checked=""/><div class="controls bullet"><span class="by">pkoird</span><span>|</span><a href="#36641420">prev</a><span>|</span><a href="#36642313">next</a><span>|</span><label class="collapse" for="c-36640754">[-]</label><label class="expand" for="c-36640754">[19 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t look too deep into the paper but can I just say that I LOVE this style of academic writing? Accessible, full of examples, and in a conversing tone. Most of the math papers I come across jump right into the &quot;Let $X \in F be ring of S^1$ and etc. I secretly believe that people heap abstractions after abstractions to purposefully shield the fact that the meat of what they&#x27;ve written is actually quite simple. Either that, or I&#x27;ve failed to understand that some ideas can&#x27;t just be explained without invoking arcane symbols.</div><br/><div id="36642259" class="c"><input type="checkbox" id="c-36642259" checked=""/><div class="controls bullet"><span class="by">throw_pm23</span><span>|</span><a href="#36640754">parent</a><span>|</span><a href="#36641117">next</a><span>|</span><label class="collapse" for="c-36642259">[-]</label><label class="expand" for="c-36642259">[2 more]</label></div><br/><div class="children"><div class="content">Believe it or not, the &quot;Let $X \in F$...&quot; style is typically easier and more straightforward to write for mathematicians and theoretical computer scientists and closer to how they have the solution in their head (or on scraps of paper) anyway. The problem is, unless the result is super important, that style will get your paper rejected as it doesn&#x27;t engage the reviewers who are not already familiar with the problem. So authors go instead for the conversational tone and try to find a good story, which is more often what actually shields that the work is quite simple or less important.</div><br/><div id="36642444" class="c"><input type="checkbox" id="c-36642444" checked=""/><div class="controls bullet"><span class="by">yakubin</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36642259">parent</a><span>|</span><a href="#36641117">next</a><span>|</span><label class="collapse" for="c-36642444">[-]</label><label class="expand" for="c-36642444">[1 more]</label></div><br/><div class="children"><div class="content">It’s also easier to spot errors in that style than in prose.</div><br/></div></div></div></div><div id="36641117" class="c"><input type="checkbox" id="c-36641117" checked=""/><div class="controls bullet"><span class="by">celrod</span><span>|</span><a href="#36640754">parent</a><span>|</span><a href="#36642259">prev</a><span>|</span><a href="#36640855">next</a><span>|</span><label class="collapse" for="c-36641117">[-]</label><label class="expand" for="c-36641117">[8 more]</label></div><br/><div class="children"><div class="content">As a grad student, one of my more cynical professors said that to write a paper, you take a simple idea and then obfuscate it until it sounds complicated, and therefore seems impressive.
He also said the hardest part of reading papers is understanding the notation (thanks to that obfuscation).</div><br/><div id="36641319" class="c"><input type="checkbox" id="c-36641319" checked=""/><div class="controls bullet"><span class="by">inopinatus</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36641117">parent</a><span>|</span><a href="#36641647">next</a><span>|</span><label class="collapse" for="c-36641319">[-]</label><label class="expand" for="c-36641319">[3 more]</label></div><br/><div class="children"><div class="content">If the whole academic career doesn&#x27;t work out, patent drafting offers an even more baroque application of obfuscated writing skills.</div><br/><div id="36641557" class="c"><input type="checkbox" id="c-36641557" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36641319">parent</a><span>|</span><a href="#36641647">next</a><span>|</span><label class="collapse" for="c-36641557">[-]</label><label class="expand" for="c-36641557">[2 more]</label></div><br/><div class="children"><div class="content">Now the whole journey of Einstein from patent examiner to physics superstar makes sense to me.</div><br/><div id="36642454" class="c"><input type="checkbox" id="c-36642454" checked=""/><div class="controls bullet"><span class="by">bl0rg</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36641557">parent</a><span>|</span><a href="#36641647">next</a><span>|</span><label class="collapse" for="c-36642454">[-]</label><label class="expand" for="c-36642454">[1 more]</label></div><br/><div class="children"><div class="content">He simply did not have the intellectual aptitude required for the patent business.   Suddenly I don&#x27;t feel so bad about becoming a math professor after failing accounting school.</div><br/></div></div></div></div></div></div><div id="36641647" class="c"><input type="checkbox" id="c-36641647" checked=""/><div class="controls bullet"><span class="by">WinLychee</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36641117">parent</a><span>|</span><a href="#36641319">prev</a><span>|</span><a href="#36641861">next</a><span>|</span><label class="collapse" for="c-36641647">[-]</label><label class="expand" for="c-36641647">[1 more]</label></div><br/><div class="children"><div class="content">I have often found that to be true. From what I&#x27;ve heard, it is sometimes against the author&#x27;s wishes, that they have to toss in equations to &quot;make it look good&quot; to get past review. At least in CS, you can read the source code if it&#x27;s been published, and often it&#x27;s a basic technique with a slight new twist that _maybe_ works but is super hard to reproduce. Also much of the papers are fluff lol, just random equations thrown in that are just copied from the textbook.</div><br/></div></div><div id="36641861" class="c"><input type="checkbox" id="c-36641861" checked=""/><div class="controls bullet"><span class="by">_nalply</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36641117">parent</a><span>|</span><a href="#36641647">prev</a><span>|</span><a href="#36640855">next</a><span>|</span><label class="collapse" for="c-36641861">[-]</label><label class="expand" for="c-36641861">[3 more]</label></div><br/><div class="children"><div class="content">The incentives are misaligned.<p>The general public wants something simple and useful.<p>The writers want recognition.<p>I learnt that when I wrote my own thesis. I tried to be simple and useful but I discovered something else when thinking about the subject: I wanted to make sure that my thesis gets good grades.</div><br/><div id="36641945" class="c"><input type="checkbox" id="c-36641945" checked=""/><div class="controls bullet"><span class="by">tgv</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36641861">parent</a><span>|</span><a href="#36640855">next</a><span>|</span><label class="collapse" for="c-36641945">[-]</label><label class="expand" for="c-36641945">[2 more]</label></div><br/><div class="children"><div class="content">Two days ago, a friend of mine sent a link to a site with audio versions of scientific articles. He sarcastically added: &quot;as if anyone actually still reads articles.&quot; In many discplines, articles are write only. It&#x27;s publish-or-perish, not read-or-perish.</div><br/><div id="36642235" class="c"><input type="checkbox" id="c-36642235" checked=""/><div class="controls bullet"><span class="by">kingkongjaffa</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36641945">parent</a><span>|</span><a href="#36640855">next</a><span>|</span><label class="collapse" for="c-36642235">[-]</label><label class="expand" for="c-36642235">[1 more]</label></div><br/><div class="children"><div class="content">That’s nuts to me. I read aerodynamics for my masters and would have been lost without skimming 100’s of papers and fully reading about 100 papers.<p>Now I’m currently doing research on a niche statistics topic and I would be lost without papers.<p>How does one figure out “this is what we currently understand about x” without research papers and plundering scihub?</div><br/></div></div></div></div></div></div></div></div><div id="36640855" class="c"><input type="checkbox" id="c-36640855" checked=""/><div class="controls bullet"><span class="by">sublinear</span><span>|</span><a href="#36640754">parent</a><span>|</span><a href="#36641117">prev</a><span>|</span><a href="#36640856">next</a><span>|</span><label class="collapse" for="c-36640855">[-]</label><label class="expand" for="c-36640855">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I secretly believe that people heap abstractions after abstractions to purposefully shield the fact that the meat of what they&#x27;ve written is actually quite simple.<p>It usually is pretty simple, but what they&#x27;re going for is rigor and concision. Maybe a few papers are overconstrained and could drop a few unnecessary details, but I don&#x27;t think that&#x27;s all that common after enough review.</div><br/><div id="36642280" class="c"><input type="checkbox" id="c-36642280" checked=""/><div class="controls bullet"><span class="by">cinntaile</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36640855">parent</a><span>|</span><a href="#36640856">next</a><span>|</span><label class="collapse" for="c-36642280">[-]</label><label class="expand" for="c-36642280">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes people just want their work to sound more impressive than it actually is. Using in-words is a pretty standard technique, their peers don&#x27;t mind because they speak the same language. To outsiders it sounds difficult. Quite common in academia.</div><br/></div></div></div></div><div id="36640856" class="c"><input type="checkbox" id="c-36640856" checked=""/><div class="controls bullet"><span class="by">l33t233372</span><span>|</span><a href="#36640754">parent</a><span>|</span><a href="#36640855">prev</a><span>|</span><a href="#36641567">next</a><span>|</span><label class="collapse" for="c-36640856">[-]</label><label class="expand" for="c-36640856">[2 more]</label></div><br/><div class="children"><div class="content">I think it’s just that what’s being talked about is so precise and so deep in the weeds of nested definitions that you generally need to talk like that, or at least you have to be a truly gifted communicator to write a math paper without it.</div><br/><div id="36641175" class="c"><input type="checkbox" id="c-36641175" checked=""/><div class="controls bullet"><span class="by">mathisfun123</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36640856">parent</a><span>|</span><a href="#36641567">next</a><span>|</span><label class="collapse" for="c-36641175">[-]</label><label class="expand" for="c-36641175">[1 more]</label></div><br/><div class="children"><div class="content">&gt;or at least you have to be a truly gifted communicator to write a math paper without it.<p>i know a lot of math (hence the name) - basically lots of stuff scattered around analysis, geometry, and complexity theory, at varying levels between senior undergrad and research level (MIP and SAT and SMT). this basically tracks my academic progression (from math undergrad to cs phd student).<p>the stuff that i can explain the best is the research level stuff. why? because i can explain it in the same relatable terms that i learned it through, since i learned it when i <i>needed</i> it - through relatable examples that clearly motivate the ideas. i&#x27;ve done it many times - often a junior phd student will ask me what i work on and i start telling a story that starts with some really common thing that gives a foothold (&quot;how would you figure out which variables in a for loop are reused&quot;) and then step by step you &quot;follow your nose&quot; to the ideas behind the proofs and techniques and etc.<p>what&#x27;s my point? lots of academic math is useless frippery that couldn&#x27;t be motivated in this way and so it can&#x27;t be articulated except formally.</div><br/></div></div></div></div><div id="36641567" class="c"><input type="checkbox" id="c-36641567" checked=""/><div class="controls bullet"><span class="by">akasakahakada</span><span>|</span><a href="#36640754">parent</a><span>|</span><a href="#36640856">prev</a><span>|</span><a href="#36641268">next</a><span>|</span><label class="collapse" for="c-36641567">[-]</label><label class="expand" for="c-36641567">[2 more]</label></div><br/><div class="children"><div class="content">Read a paper with few hundreds of cites. They proposed a new algorithm to solve eigenvalue problem. I look at it, decrypt the equations, and then notice that it is just basically a bunch of if-then condition like this:<p>count = 0<p>for x in list:<p><pre><code>  if x == 1:

    count +=1
</code></pre>
if count != 0:<p><pre><code>  return 3
</code></pre>
else:<p><pre><code>  return 1
</code></pre>
Everything is simple, they try too hard to make things look mathematically rigorous but turn out stupid.<p>if you want to see how cryptic it is:
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2103.07510" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2103.07510</a></div><br/><div id="36642304" class="c"><input type="checkbox" id="c-36642304" checked=""/><div class="controls bullet"><span class="by">elcritch</span><span>|</span><a href="#36640754">root</a><span>|</span><a href="#36641567">parent</a><span>|</span><a href="#36641268">next</a><span>|</span><label class="collapse" for="c-36642304">[-]</label><label class="expand" for="c-36642304">[1 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t look to try to solve the eigenvalue problem.</div><br/></div></div></div></div><div id="36642332" class="c"><input type="checkbox" id="c-36642332" checked=""/><div class="controls bullet"><span class="by">nabla9</span><span>|</span><a href="#36640754">parent</a><span>|</span><a href="#36641268">prev</a><span>|</span><a href="#36642313">next</a><span>|</span><label class="collapse" for="c-36642332">[-]</label><label class="expand" for="c-36642332">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s because the second author is Jeffrey Ullman  (Turing Award, Neumann medal)<p>Ullman is of the authors of several legendary computer science books Dragon Book (Compilers: Principles, Techniques, and Tools) the Cinderella Book (Introduction to Automata Theory, Languages, and Computation), Green Dragon Book (Principles of Compiler Design)<p>If you want to learn deep stuff with clarity,  those old books are still the way to go.</div><br/></div></div></div></div><div id="36642313" class="c"><input type="checkbox" id="c-36642313" checked=""/><div class="controls bullet"><span class="by">hamilyon2</span><span>|</span><a href="#36640754">prev</a><span>|</span><a href="#36642311">next</a><span>|</span><label class="collapse" for="c-36642313">[-]</label><label class="expand" for="c-36642313">[1 more]</label></div><br/><div class="children"><div class="content">I rarely let myself a negative comment, but core of article is authors realising that n-bit multiplication is n additions. So, absolutely nothing interesting or new</div><br/></div></div><div id="36642311" class="c"><input type="checkbox" id="c-36642311" checked=""/><div class="controls bullet"><span class="by">inglor</span><span>|</span><a href="#36642313">prev</a><span>|</span><a href="#36640779">next</a><span>|</span><label class="collapse" for="c-36642311">[-]</label><label class="expand" for="c-36642311">[1 more]</label></div><br/><div class="children"><div class="content">Did the comments here actually read the paper? It just does &quot;russian peasant&quot; multiplication simulating multiplication with addition.<p>There is no new math discovered as far as I understand. It&#x27;s basically &quot;we know how to do multiplication with a lot of additions&quot;.<p>If this was effective rather than just &quot;simulate multiplication with a lot of additions&quot; it would have been super interesting for parallelization of multiplications and communication bounds.</div><br/></div></div><div id="36640779" class="c"><input type="checkbox" id="c-36640779" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36642311">prev</a><span>|</span><a href="#36640466">next</a><span>|</span><label class="collapse" for="c-36640779">[-]</label><label class="expand" for="c-36640779">[8 more]</label></div><br/><div class="children"><div class="content">One thing I highly recommend is trying it for yourself, just with pen and paper.  Think of ten two-digit numbers under 40 for it to work nicely.  Just numbers under 40, 1-100 would require like 20 numbers for it to work as well as it does in realistic examples.  Write them in one line, then write them sorted on the next line, with lines connecting them to where they were before.  Then underneath each number write down the difference between that number n the one before it, this is called taking the first differences.  Repeat the sorting followed by taking first differences until you have only two numbers, two being an arbitrary limit.  You may then pretend the row and column are the same, so expand with the same vector using the lines drawn, and prefix sum where first difference was performed.<p>So:<p>11 39 23 28 31 19 32 05 01 09<p>sort<p>01 05 09 11 19 23 28 31 32 39<p>first differences<p>1  4  4  2  8  4  5  3  1  7<p>sort and remove duplicates<p>1 2 3 4 5 7 8<p>first differences<p>1 1 1 1 1 2 1<p>sort and remove duplicates<p>1 2<p>reduction complete</div><br/><div id="36641158" class="c"><input type="checkbox" id="c-36641158" checked=""/><div class="controls bullet"><span class="by">smlacy</span><span>|</span><a href="#36640779">parent</a><span>|</span><a href="#36641748">next</a><span>|</span><label class="collapse" for="c-36641158">[-]</label><label class="expand" for="c-36641158">[3 more]</label></div><br/><div class="children"><div class="content">Writing &#x27;n&#x27; instead of &#x27;and&#x27; when discussing mathematics is generally a very bad idea. Your example is a good one, but your use of abbreviations in your writing is horrid.</div><br/><div id="36641247" class="c"><input type="checkbox" id="c-36641247" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36640779">root</a><span>|</span><a href="#36641158">parent</a><span>|</span><a href="#36641748">next</a><span>|</span><label class="collapse" for="c-36641247">[-]</label><label class="expand" for="c-36641247">[2 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re right in this case.  Alright I&#x27;ll edit if I still can.  I don&#x27;t use any variables anyway in my post.<p>EDIT:  alright I fixed all the single letter abbreviations.</div><br/><div id="36641316" class="c"><input type="checkbox" id="c-36641316" checked=""/><div class="controls bullet"><span class="by">svnt</span><span>|</span><a href="#36640779">root</a><span>|</span><a href="#36641247">parent</a><span>|</span><a href="#36641748">next</a><span>|</span><label class="collapse" for="c-36641316">[-]</label><label class="expand" for="c-36641316">[1 more]</label></div><br/><div class="children"><div class="content">almost:<p>&gt; Then underneath each number write down the difference between that number n the one before it</div><br/></div></div></div></div></div></div><div id="36641748" class="c"><input type="checkbox" id="c-36641748" checked=""/><div class="controls bullet"><span class="by">casey2</span><span>|</span><a href="#36640779">parent</a><span>|</span><a href="#36641158">prev</a><span>|</span><a href="#36641209">next</a><span>|</span><label class="collapse" for="c-36641748">[-]</label><label class="expand" for="c-36641748">[1 more]</label></div><br/><div class="children"><div class="content">Rather than pen and paper I recommend using a computer if you have access to one.<p><pre><code>   (-⟜»∘⍷∧)⍟(1+↕3) 11‿39‿23‿28‿31‿19‿32‿5‿1‿9</code></pre>
⟨ ⟨ 1 4 4 2 8 4 5 3 1 7 ⟩ ⟨ 1 1 1 1 1 2 1 ⟩ ⟨ 1 1 ⟩ ⟩<p><pre><code>   -⟜»∘⍷∧ vec</code></pre>
⟨ 7 2 4 1 3 2 2 4 10 12 3 10 1 6 1 5 17 2 8 ⟩<p><pre><code>   +´-⟜»∘⍷∧ vec</code></pre>
100<p><pre><code>   ⍷∧ vec</code></pre>
⟨ 7 9 13 14 17 19 21 25 35 47 50 60 61 67 68 73 90 92 100 ⟩<p><pre><code>   +`-⟜»∘⍷∧ vec</code></pre>
⟨ 7 9 13 14 17 19 21 25 35 47 50 60 61 67 68 73 90 92 100 ⟩</div><br/></div></div><div id="36641209" class="c"><input type="checkbox" id="c-36641209" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#36640779">parent</a><span>|</span><a href="#36641748">prev</a><span>|</span><a href="#36640466">next</a><span>|</span><label class="collapse" for="c-36641209">[-]</label><label class="expand" for="c-36641209">[3 more]</label></div><br/><div class="children"><div class="content">i feel like this sometimes runs into problems<p>like, if after 7 iterations, we have<p>1 2 3 7 9 12 18 23 27 57 72 95 129 680 718 994 2631 10770 18047 785265<p>that gets down to four items after 14 iterations<p>1 54 2814 716356<p>but because that&#x27;s roughly exponential it takes a beastly number of iterations to get down to 2 items<p>i guess i should read the paper</div><br/><div id="36641277" class="c"><input type="checkbox" id="c-36641277" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36640779">root</a><span>|</span><a href="#36641209">parent</a><span>|</span><a href="#36640466">next</a><span>|</span><label class="collapse" for="c-36641277">[-]</label><label class="expand" for="c-36641277">[2 more]</label></div><br/><div class="children"><div class="content">Yeah i address that, that&#x27;s a gotcha and if the numbers are exponentially distributed the algorithm does not work.  It is not universal.  It depends in part on the exponent for which the numbers are exponentially distributed, n the other optimizations you use.  This is the purpose of ongoing experiments.  The Fibonacci series is an interesting case, since you get rid of the two largest numbers in each pass.<p>Yeah hey the paper will not be that painful to read if you can already perform the reduction steps.  I&#x27;ll answer further questions.<p>Yeah so for floating point an exponential distribution is bounded in how many elements it can contain for a given exponent, so it works out quite nicely.  It does not work on bignums.<p>Nice to see someone use lower-case i like i do!</div><br/><div id="36641368" class="c"><input type="checkbox" id="c-36641368" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#36640779">root</a><span>|</span><a href="#36641277">parent</a><span>|</span><a href="#36640466">next</a><span>|</span><label class="collapse" for="c-36641368">[-]</label><label class="expand" for="c-36641368">[1 more]</label></div><br/><div class="children"><div class="content">the paper is not painful at all<p>unless i fucked it up, it looks like you can insert a separate renormalization step before the sorting where you shift each number to the left by a variable amount, like a floating-point unit always does with the mantissa (except subnormals), and that seems to solve the exponential distribution problem; it always seems to get down to a single item from 10000 34-bit items in about 15 steps<p>no wait, it doesn&#x27;t really solve it, because a vector of the first 1000 fibonacci numbers still takes 485 iterations.  but the last number in that vector is a 694-bit number.  it does seem to improve it enormously<p>i thought this might make it work much worse (because in a sense it&#x27;s adding bits to the numbers: what used to be a 1-bit number might now have <i>n</i>-bit-wide differences with the numbers before and after it) but at least in random tests it seems to make a huge improvement<p>just to clarify, what i&#x27;m doing (with unsigned integers) is<p><pre><code>    def normalize(v):
        for vi in v:
            while vi &lt; 2**34:
                vi *= 2
            yield vi

    def nreductions(v):
        while True:
            v = list(sortu(normalize(v)))
            yield v
            v = list(diffs(v))
</code></pre>
with 256-bit numbers and a 2**256 normalization target it seems to typically be about 30 or 40 reduction steps, not sure if those qualify as bignums to you<p>the shifts of course have to be undone in the other direction, just like the permutations, but i don&#x27;t think that&#x27;s a problem?<p>(oh, now i see that in §3.1 &#x27;alignment&#x27; you are already doing something like this, except that you&#x27;re shifting right to reduce the number of duplicates and eliminate one extra bit of differencing per iteration, not left to reduce the dynamic range of the data.  for smallish numbers that seems to be roughly as effective, but left-shift normalizing works a lot better than right-shift aligning for 256-bit numbers)<p>i haven&#x27;t tried doing any actual vector multiplies with this algorithm yet so if i did fuck it up i wouldn&#x27;t have noticed<p>this is a pretty exciting algorithm, thanks for sharing</div><br/></div></div></div></div></div></div></div></div><div id="36640466" class="c"><input type="checkbox" id="c-36640466" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#36640779">prev</a><span>|</span><a href="#36641410">next</a><span>|</span><label class="collapse" for="c-36640466">[-]</label><label class="expand" for="c-36640466">[8 more]</label></div><br/><div class="children"><div class="content">This is a fascinating idea. Any real acedemic critique is over my head (and I hope others chime in), but some random thoughts:<p>- &quot;logarithm LUT then add&quot; seems delightfully simple, especially at low precision. I am going to have to read that paper too...<p>- The concerns about GPU style parallelism <i>may</i> not be as bad in &quot;alternative&quot; architectures. For instance, Centaur came up with a single, serial, but hilariously wide 32,768-bit SIMD core for inference: <a href="https:&#x2F;&#x2F;fuse.wikichip.org&#x2F;news&#x2F;3256&#x2F;centaur-new-x86-server-processor-packs-an-ai-punch&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;fuse.wikichip.org&#x2F;news&#x2F;3256&#x2F;centaur-new-x86-server-p...</a><p>- The silicon simplification also seems relevant to Samsung&#x27;s in memory computing effort: <a href="https:&#x2F;&#x2F;www.servethehome.com&#x2F;samsung-hbm2-pim-and-aquabolt-xl-at-hot-chips-33&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.servethehome.com&#x2F;samsung-hbm2-pim-and-aquabolt-x...</a><p>- I wonder if this would be relevant to llama.cpp&#x27;s CPU inference?</div><br/><div id="36640595" class="c"><input type="checkbox" id="c-36640595" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36640466">parent</a><span>|</span><a href="#36641410">next</a><span>|</span><label class="collapse" for="c-36640595">[-]</label><label class="expand" for="c-36640595">[7 more]</label></div><br/><div class="children"><div class="content">Well so one issue w both GPUs n CPUs which make them bad platforms for this algorithm is that, in both, FLOPS are such an important metric for sales that multiplication is highly subsidized in both those chip types.  So huge amounts of area is dedicated to floating point multiplication, meaning the advantage of fgemm (the name of the algorithm is the same as the name of the company) is purely one of energy.<p>Which is great because if it were software it would be impossible to protect the IP.  USPTO is very clear in that sense, i believe in both in re Bilski and in the Alice Corp. case which reached SCOTUS, that algorithms need to be implemented physically, typically meaning in a chip, to be patentable.  So because it needs a chip to work, it is good business, if it did not it would be bad business.  A chip provides every form of IP protection, all four forms, trade secret, copyright, patent, n even trademark.  No other medium has that to my knowledge.<p>So if you have a CPU or a GPU n want it to do more work in the same amount of time, this paper promises nothing, n it keeps that promise.  Nonetheless i&#x27;m advancing rapidly to the point of creating the hardware that can cut off 70% of the cost of GEMM.  I considered 50% off, same thing at half the price, but it wouldn&#x27;t be fair to the consumer w my economics.  You see 50% discounts all the time, who cares?  70% off, you don&#x27;t see that all the time.  On something you actually want?  Especially on a commodity, n it&#x27;s still good business for me as the lowest-cost producer.</div><br/><div id="36641164" class="c"><input type="checkbox" id="c-36641164" checked=""/><div class="controls bullet"><span class="by">david-gpu</span><span>|</span><a href="#36640466">root</a><span>|</span><a href="#36640595">parent</a><span>|</span><a href="#36641137">next</a><span>|</span><label class="collapse" for="c-36641164">[-]</label><label class="expand" for="c-36641164">[3 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Well so one issue w both GPUs n CPUs which make them bad platforms for this algorithm is that, in both, FLOPS are such an important metric for sales that multiplication is highly subsidized in both those chip types. So huge amounts of area is dedicated to floating point multiplication, meaning the advantage of fgemm (the name of the algorithm is the same as the name of the company) is purely one of energy.</i><p>I&#x27;m having trouble understanding this. Are you saying that GPUs invest area on floating-point multipliers because FLOPS are an important marketing metric? The only thing that mattered to us was: how can we make these operations faster within the area and power constraints we have? Reducing energy consumption was thus a major goal.<p>I wish you luck. If I were in your shoes, I would approach NVidia or Google -- and expect to be hammered with tough questions.</div><br/><div id="36641389" class="c"><input type="checkbox" id="c-36641389" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36640466">root</a><span>|</span><a href="#36641164">parent</a><span>|</span><a href="#36641313">next</a><span>|</span><label class="collapse" for="c-36641389">[-]</label><label class="expand" for="c-36641389">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Are you saying that GPUs invest area on floating-point multipliers because FLOPS are an important marketing metric?<p>Yes.  That is precisely what i&#x27;m saying.  If i&#x27;m mistaken in saying that that&#x27;s one thing, but as far as it being what i&#x27;m saying, it very much is.  It&#x27;s been an important guiding principle for some time now in the project, that recent chips--including FPGA&#x27;s--tend to have hard IP for floating point multiplication.<p>Now spending a lot of chip area on getting more FLOPS is not necessarily a bad decision if there is no <i>alternative</i> for achieving fast matrix multiplication.  Almost any method is sensible if there was no better alternative available when the decision to use that method was made.  In addition, fgemm only really makes sense when matrices contain over 1000 elements per row or column, not sure how much more than 1000 per vector but more than that.  Small and in particular small and dense matrices are still best multiplied exactly the way GPUs multiply them, with many floating-point multiplier circuits in parallel.  It&#x27;s not stupid in the least.<p>Yeah so NVidia n Google have the same business model i&#x27;m going for, Google having TPUs in its datacenters that do work that cannot be reverse engineered.  Google does not sell TPUs.  You can use them by sending Google the work, and you&#x27;ll benefit from much lower cost and faster speed.  NVidia has a similar offering, just not as well-known.  That&#x27;s the correct business model in my analysis, and what fgemm will sell.  Sell the work.</div><br/></div></div><div id="36641313" class="c"><input type="checkbox" id="c-36641313" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#36640466">root</a><span>|</span><a href="#36641164">parent</a><span>|</span><a href="#36641389">prev</a><span>|</span><a href="#36641137">next</a><span>|</span><label class="collapse" for="c-36641313">[-]</label><label class="expand" for="c-36641313">[1 more]</label></div><br/><div class="children"><div class="content">this is an interesting idea; in some sense rotating a point in space is only multiplying a 3-item or 4-item vector (where this idea wouldn&#x27;t be useful), but rotating <i>n</i> points is multiplying a 3×<i>n</i> or 4×<i>n</i> matrix by the transformation vector, so if the algorithm pans out, you should be able to do that kind of stuff too; <i>n</i> can be pretty large</div><br/></div></div></div></div><div id="36641137" class="c"><input type="checkbox" id="c-36641137" checked=""/><div class="controls bullet"><span class="by">kopecs</span><span>|</span><a href="#36640466">root</a><span>|</span><a href="#36640595">parent</a><span>|</span><a href="#36641164">prev</a><span>|</span><a href="#36640973">next</a><span>|</span><label class="collapse" for="c-36641137">[-]</label><label class="expand" for="c-36641137">[2 more]</label></div><br/><div class="children"><div class="content">&gt; A chip provides every form of IP protection, all four forms, trade secret, copyright, patent, n even trademark. No other medium has that to my knowledge.<p>IANAL, but I do not believe semiconductor masks are copyrightable under US law (my limited understanding is that there is essentially due to the fact that the mask is inherently functional and&#x2F;or aspects of the merger doctrine). There is a separate sui generis mask work protection via 17 U.S.C. §§ 901-914.<p>Edit: Moreover, I&#x27;m unsure how you figure a chip itself is protected by trade secret, since reverse engineering an IC is not terribly difficult.</div><br/><div id="36641242" class="c"><input type="checkbox" id="c-36641242" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36640466">root</a><span>|</span><a href="#36641137">parent</a><span>|</span><a href="#36640973">next</a><span>|</span><label class="collapse" for="c-36641242">[-]</label><label class="expand" for="c-36641242">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know why trade secret applies, but i remember reading it does.  Perhaps in the rationale, or the preimage.  It doesn&#x27;t make all that much sense, come to think.  I think Intel tried it?  Intel for sure used copyright to protect chips.  Hey thanks, i did not know about 17 U.S.C. §§ 901-914.</div><br/></div></div></div></div><div id="36640973" class="c"><input type="checkbox" id="c-36640973" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#36640466">root</a><span>|</span><a href="#36640595">parent</a><span>|</span><a href="#36641137">prev</a><span>|</span><a href="#36641410">next</a><span>|</span><label class="collapse" for="c-36640973">[-]</label><label class="expand" for="c-36640973">[1 more]</label></div><br/><div class="children"><div class="content">mask works</div><br/></div></div></div></div></div></div><div id="36641410" class="c"><input type="checkbox" id="c-36641410" checked=""/><div class="controls bullet"><span class="by">KETpXDDzR</span><span>|</span><a href="#36640466">prev</a><span>|</span><a href="#36642122">next</a><span>|</span><label class="collapse" for="c-36641410">[-]</label><label class="expand" for="c-36641410">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m unsure if this yields any computational benefits over classic multiplication.<p>&quot;In real arithmetic, multiplication may be faster for the following reason:
When two real numbers are multiplied, the mantissae are multiplied together and the exponents are added, and these operations can be carried out in parallel.
When two real numbers are added, first the mantissa of the smaller number must be shifted so that the exponents match (a process termed normalisation). Then the mantissae must be added. The result of the addition may overflow the original word length by 1 bit, or it may generate any number of leading zeros. Therefore the result must be normalised again. There are therefore 3 steps and they must be done in series.&quot; - <a href="https:&#x2F;&#x2F;www.researchgate.net&#x2F;post&#x2F;Is-multiplication-slower-than-addition-on-modern-CPUs" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.researchgate.net&#x2F;post&#x2F;Is-multiplication-slower-t...</a></div><br/><div id="36641463" class="c"><input type="checkbox" id="c-36641463" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36641410">parent</a><span>|</span><a href="#36642122">next</a><span>|</span><label class="collapse" for="c-36641463">[-]</label><label class="expand" for="c-36641463">[1 more]</label></div><br/><div class="children"><div class="content">One addition and one move replacing one multiplication?  Absolutely makes things much cheaper.</div><br/></div></div></div></div><div id="36642122" class="c"><input type="checkbox" id="c-36642122" checked=""/><div class="controls bullet"><span class="by">Roark66</span><span>|</span><a href="#36641410">prev</a><span>|</span><a href="#36641606">next</a><span>|</span><label class="collapse" for="c-36642122">[-]</label><label class="expand" for="c-36642122">[2 more]</label></div><br/><div class="children"><div class="content">I learned (assembly)programming on a chip that had no multiplication instruction. It was 6510 (a version of popular 6502) and I fail to see the benefit. Back then every multiplication had to be done via addition in loop and division with subtract&#x2F;compare(except certain numbers like powers of 2 where one could bit shift). You can imagine how slow it was. I was envious of my friends with Amigas (68k cpu) who had chips that were capable of multiplication in hardware. It seems obvious that a properly tuned hardware implementation is always going to be faster than doing the same thing in software. Taken to the extreme this is the crux of the old RISC vs CISC debate.</div><br/></div></div><div id="36641606" class="c"><input type="checkbox" id="c-36641606" checked=""/><div class="controls bullet"><span class="by">sabhiram</span><span>|</span><a href="#36642122">prev</a><span>|</span><a href="#36642104">next</a><span>|</span><label class="collapse" for="c-36641606">[-]</label><label class="expand" for="c-36641606">[3 more]</label></div><br/><div class="children"><div class="content">Fascinating paper.<p>We design an inference accelerator which more or less accomplishes this by quantizing input tensors into logarithmic space. This allows the multiplication (in convolution especially), to be optimized into very simple adders. This (and a few other tricks) has a very dramatic impact on how much compute density we achieve while keeping power very low. We keep the tensors in our quantized space throughout the layers of the network and convert the outputs as required on the way out of the ASIC.<p>We achieve impressive task level performance, but this requires some specialized training and model optimizations.<p>Very cool to see ideas like this propagate more into the mainstream.</div><br/><div id="36641615" class="c"><input type="checkbox" id="c-36641615" checked=""/><div class="controls bullet"><span class="by">KRAKRISMOTT</span><span>|</span><a href="#36641606">parent</a><span>|</span><a href="#36642104">next</a><span>|</span><label class="collapse" for="c-36641615">[-]</label><label class="expand" for="c-36641615">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t matrix multiplication already a convolution? You are rotating the right hand side matrix anti clockwise 90 degrees and then convolving it upon the LHS matrix from top to bottom.</div><br/><div id="36641825" class="c"><input type="checkbox" id="c-36641825" checked=""/><div class="controls bullet"><span class="by">sabhiram</span><span>|</span><a href="#36641606">root</a><span>|</span><a href="#36641615">parent</a><span>|</span><a href="#36642104">next</a><span>|</span><label class="collapse" for="c-36641825">[-]</label><label class="expand" for="c-36641825">[1 more]</label></div><br/><div class="children"><div class="content">The point above regarding convolution had to do specifically with accelerating 3x3 and above convolutional operations, as the product and the accumulation can be done in a few clock cycles if setup with care and love.</div><br/></div></div></div></div></div></div><div id="36642104" class="c"><input type="checkbox" id="c-36642104" checked=""/><div class="controls bullet"><span class="by">Vasniktel</span><span>|</span><a href="#36641606">prev</a><span>|</span><a href="#36640960">next</a><span>|</span><label class="collapse" for="c-36642104">[-]</label><label class="expand" for="c-36642104">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the paper Daniel. Very easy to read and understand.<p>I believe I might have found a minor typo that made me scratch my head for a second. On page 3 in the part where you describe the &quot;follow pointers&quot; part of the algorithm you wrote vi=sj and then cpi=csj whereas I believe you meant cvi=csj and that we can now replace vi with csj to make it cvi. Let me know if I&#x27;m misunderstanding something here.</div><br/></div></div><div id="36640960" class="c"><input type="checkbox" id="c-36640960" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#36642104">prev</a><span>|</span><a href="#36641445">next</a><span>|</span><label class="collapse" for="c-36640960">[-]</label><label class="expand" for="c-36640960">[3 more]</label></div><br/><div class="children"><div class="content">apparently the fgemm future of artificial intelligence is... a versatrig slide rule?<p>wait, this actually doesn&#x27;t use logarithms at all, it&#x27;s more of a difference engine really</div><br/><div id="36641526" class="c"><input type="checkbox" id="c-36641526" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36640960">parent</a><span>|</span><a href="#36641445">next</a><span>|</span><label class="collapse" for="c-36641526">[-]</label><label class="expand" for="c-36641526">[2 more]</label></div><br/><div class="children"><div class="content">Yeh, it bears many resemblances to Babbage&#x27;s difference engine.</div><br/><div id="36641605" class="c"><input type="checkbox" id="c-36641605" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#36640960">root</a><span>|</span><a href="#36641526">parent</a><span>|</span><a href="#36641445">next</a><span>|</span><label class="collapse" for="c-36641605">[-]</label><label class="expand" for="c-36641605">[1 more]</label></div><br/><div class="children"><div class="content">yeah, sorry for making the slide rule joke before even reading the abstract</div><br/></div></div></div></div></div></div><div id="36641445" class="c"><input type="checkbox" id="c-36641445" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#36640960">prev</a><span>|</span><a href="#36641955">next</a><span>|</span><label class="collapse" for="c-36641445">[-]</label><label class="expand" for="c-36641445">[2 more]</label></div><br/><div class="children"><div class="content">Instead of sorting, just count the occurrences of the distinct values. For 8-bit values, this requires only 256 registers, each with a relatively small number of bits. E.g.: if the maximum matrix size is 16K*16K, then only 14 bits per accumulator is required.<p>This is just Radix sort and is very easy to implement in digital circuits. It can even reuse the same adder circuits.</div><br/><div id="36641523" class="c"><input type="checkbox" id="c-36641523" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36641445">parent</a><span>|</span><a href="#36641955">next</a><span>|</span><label class="collapse" for="c-36641523">[-]</label><label class="expand" for="c-36641523">[1 more]</label></div><br/><div class="children"><div class="content">Sorting is very fast since i designed a sorting algorithm tailor-made for this problem, which is about as fast as your approach.  Difference being the numbers are 32-bit, so iterating through the entire array of all possible 24-bit mantissas (i know they&#x27;re 23 bit, but the implicit initial 1 of normal (vs denormal) values is explicit here) would be way too slow.  Otherwise you&#x27;d be right, 8-bit values you can just use counting-sort, no problem.  Or 14 bits, same deal.  Now also notice there&#x27;s a difference between the matrix size and the mantissa size, we care about the mantissa size, so it&#x27;s 24 bits.</div><br/></div></div></div></div><div id="36641955" class="c"><input type="checkbox" id="c-36641955" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36641445">prev</a><span>|</span><a href="#36642326">next</a><span>|</span><label class="collapse" for="c-36641955">[-]</label><label class="expand" for="c-36641955">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately i cannot answer questions as unlike i chip i must now sleep.  It&#x27;s 2:42 AM here.<p>First thing in the morning i&#x27;ll be on it.</div><br/></div></div><div id="36642326" class="c"><input type="checkbox" id="c-36642326" checked=""/><div class="controls bullet"><span class="by">nabla9</span><span>|</span><a href="#36641955">prev</a><span>|</span><a href="#36641388">next</a><span>|</span><label class="collapse" for="c-36642326">[-]</label><label class="expand" for="c-36642326">[1 more]</label></div><br/><div class="children"><div class="content">Wow. Jeffrey Ullman? Turing Award, Neumann medal etc.  He is now 80 years old.<p>Ullman is  of the authors of several legendary computer science books Dragon Book (Compilers: Principles, Techniques, and Tools) the Cinderella Book (Introduction to Automata Theory, Languages, and Computation), Green Dragon Book (Principles of Compiler Design)<p>He was the thesis advisor for Sergey Brin, Ravi Sethi,  Surajit Chaudhuri</div><br/></div></div><div id="36641388" class="c"><input type="checkbox" id="c-36641388" checked=""/><div class="controls bullet"><span class="by">hdhsjsbv</span><span>|</span><a href="#36642326">prev</a><span>|</span><a href="#36640191">next</a><span>|</span><label class="collapse" for="c-36641388">[-]</label><label class="expand" for="c-36641388">[1 more]</label></div><br/><div class="children"><div class="content">What is the algorithmic complexity (Big O) of this?<p>And thank you for great submission. I skimmed it and I enjoyed it. But didn’t read the cost function section with much attention.</div><br/></div></div><div id="36640191" class="c"><input type="checkbox" id="c-36640191" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36641388">prev</a><span>|</span><label class="collapse" for="c-36640191">[-]</label><label class="expand" for="c-36640191">[9 more]</label></div><br/><div class="children"><div class="content">Hi HN, this paper is my first proper academic publication, it&#x27;s on arxiv only for now--this is a pre-print--but is being considered for publication by peer-reviewed journals concurrently.  Open-access journals, of course.<p>I&#x27;m totally disinterested in tenure or academic recognition.  For my goals being a Stanford dropout is better than any other amount of academic recognition.  So i don&#x27;t care about journals uh prestige numbers the impact factors i know that term but anything paywalled is bad for what i do care about, which is my business, fgemm.  Means Fast&#x2F;Faster&#x2F;Fastest GEneral Matrix-Matrix multiplication.  gemm is an acronym already used in BLAS libraries, Basic Linear Algebra Subprograms, which is what most of the time n money spent on ML goes to.<p>I&#x27;m going to be available to answer questions insofar as i can.</div><br/><div id="36641234" class="c"><input type="checkbox" id="c-36641234" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36640191">parent</a><span>|</span><a href="#36641545">next</a><span>|</span><label class="collapse" for="c-36641234">[-]</label><label class="expand" for="c-36641234">[5 more]</label></div><br/><div class="children"><div class="content">Hi Daniel. Thanks for the inspiration. Something I have thought about too is sticking some papers out there without needing to
go through expensive gates (PhD etc.).</div><br/><div id="36641305" class="c"><input type="checkbox" id="c-36641305" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36640191">root</a><span>|</span><a href="#36641234">parent</a><span>|</span><a href="#36642094">next</a><span>|</span><label class="collapse" for="c-36641305">[-]</label><label class="expand" for="c-36641305">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s brutally hard.  I had an easier time buying skylinesort.com n posting the skylinesort algorithm there, than publishing through professors n academia.  Typically not feasible for undergraduates, least of all anybody not paying tuition.  Same way professors are expected to have an undergraduate degree at the very least (4 profs at Stanford have just an undergraduate degree), a Master&#x27;s degree (a handful have that and no more), but typically a PhD is required (literally all the other professors have PhD&#x27;s).  Is required.  Who requires it?  Who says, &quot;I require a PhD.&quot;?  Is expected?  Who expects it?  Who says, &quot;I expect a PhD.&quot;?  Passive voice is typical in academia.  Very rare to get around the gatekeeping, frankly.  I couldn&#x27;t publish on arxiv for years because of lack of academic affiliation alone.<p>Took years to get to this point in terms of the effort I dedicate to getting recognition for my work.</div><br/><div id="36641438" class="c"><input type="checkbox" id="c-36641438" checked=""/><div class="controls bullet"><span class="by">Vasniktel</span><span>|</span><a href="#36640191">root</a><span>|</span><a href="#36641305">parent</a><span>|</span><a href="#36642094">next</a><span>|</span><label class="collapse" for="c-36641438">[-]</label><label class="expand" for="c-36641438">[2 more]</label></div><br/><div class="children"><div class="content">Thanks Daniel. Could you expand on this comment? What did you have to do to be able to publish a paper on arxiv?</div><br/><div id="36641563" class="c"><input type="checkbox" id="c-36641563" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36640191">root</a><span>|</span><a href="#36641438">parent</a><span>|</span><a href="#36642094">next</a><span>|</span><label class="collapse" for="c-36641563">[-]</label><label class="expand" for="c-36641563">[1 more]</label></div><br/><div class="children"><div class="content">At the time, i needed academic affiliation, meaning be in college or more likely have a professor vouch for me.  What i ended up doing was return to Stanford undergrad n take classes related to algorithms, show my algorithm portfolio in office hours, then get referred to other profs, one of them being Jeffrey Ullman, in 2019.  N then after emails back n forth we met in person in the Gates building, it went from there.<p>Very happy to have met Professor Jeffrey Ullman.</div><br/></div></div></div></div></div></div><div id="36642094" class="c"><input type="checkbox" id="c-36642094" checked=""/><div class="controls bullet"><span class="by">jmhimara</span><span>|</span><a href="#36640191">root</a><span>|</span><a href="#36641234">parent</a><span>|</span><a href="#36641305">prev</a><span>|</span><a href="#36641545">next</a><span>|</span><label class="collapse" for="c-36642094">[-]</label><label class="expand" for="c-36642094">[1 more]</label></div><br/><div class="children"><div class="content">Not sure if this is what you&#x27;re talking about, but you don&#x27;t typically pay to get a PhD (in fact you get paid in the US).</div><br/></div></div></div></div><div id="36641545" class="c"><input type="checkbox" id="c-36641545" checked=""/><div class="controls bullet"><span class="by">blast</span><span>|</span><a href="#36640191">parent</a><span>|</span><a href="#36641234">prev</a><span>|</span><a href="#36640714">next</a><span>|</span><label class="collapse" for="c-36641545">[-]</label><label class="expand" for="c-36641545">[1 more]</label></div><br/><div class="children"><div class="content">This is cool! How did you end up working with Ullman? I guess &quot;being a Stanford dropout&quot; explains how you met him, but there must be an interesting story here. Can you share how that happened and what the process was?</div><br/></div></div><div id="36640714" class="c"><input type="checkbox" id="c-36640714" checked=""/><div class="controls bullet"><span class="by">unlikelymordant</span><span>|</span><a href="#36640191">parent</a><span>|</span><a href="#36641545">prev</a><span>|</span><label class="collapse" for="c-36640714">[-]</label><label class="expand" for="c-36640714">[2 more]</label></div><br/><div class="children"><div class="content">Could you adapt this to finding fast inverses?</div><br/><div id="36640800" class="c"><input type="checkbox" id="c-36640800" checked=""/><div class="controls bullet"><span class="by">daniel-cussen</span><span>|</span><a href="#36640191">root</a><span>|</span><a href="#36640714">parent</a><span>|</span><label class="collapse" for="c-36640800">[-]</label><label class="expand" for="c-36640800">[1 more]</label></div><br/><div class="children"><div class="content">I looked at that, i concluded yes because the bottleneck of inverting a matrix is matrix multiplication.  Spesh since fgemm targets 32-bit floating-point format, n has high accuracy (not saying how high but much better than Strassen, at least as good as naive matrix multiplication).</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>