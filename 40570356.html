<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1717491672767" as="style"/><link rel="stylesheet" href="styles.css?v=1717491672767"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.anandtech.com/show/21425/intel-lunar-lake-architecture-deep-dive-lion-cove-xe2-and-npu4">Intel Unveils Lunar Lake Architecture</a> <span class="domain">(<a href="https://www.anandtech.com">www.anandtech.com</a>)</span></div><div class="subtext"><span>zdw</span> | <span>82 comments</span></div><br/><div><div id="40570729" class="c"><input type="checkbox" id="c-40570729" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#40571193">next</a><span>|</span><label class="collapse" for="c-40570729">[-]</label><label class="expand" for="c-40570729">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Another striking advance is the migration in the P-core database from a &#x27;sea of fubs&#x27; to a &#x27;sea of cells&#x27;. This process of updating the organization of the P-cores substructure moves from tiny, latch-dominated partitions to more extensive and ever larger flop-dominated partitions that are very agnostic as things go.<p>I like to pretend I know a thing about CPU design, but I have to admit, I have no idea what&#x27;s going on here.</div><br/><div id="40570863" class="c"><input type="checkbox" id="c-40570863" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#40570729">parent</a><span>|</span><a href="#40571193">next</a><span>|</span><label class="collapse" for="c-40570863">[-]</label><label class="expand" for="c-40570863">[2 more]</label></div><br/><div class="children"><div class="content">FUB: Functional Unit Block.<p>It seems that they are moving from higher level (larger) building blocks to lower level (smaller) building blocks to increase efficiency.</div><br/><div id="40571321" class="c"><input type="checkbox" id="c-40571321" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40570729">root</a><span>|</span><a href="#40570863">parent</a><span>|</span><a href="#40571193">next</a><span>|</span><label class="collapse" for="c-40571321">[-]</label><label class="expand" for="c-40571321">[1 more]</label></div><br/><div class="children"><div class="content">The second part of the quote says they&#x27;re moving from &quot;tiny&quot; to &quot;more extensive&quot; partitions though; it feels confusingly contradictory.</div><br/></div></div></div></div></div></div><div id="40571193" class="c"><input type="checkbox" id="c-40571193" checked=""/><div class="controls bullet"><span class="by">acje</span><span>|</span><a href="#40570729">prev</a><span>|</span><a href="#40572023">next</a><span>|</span><label class="collapse" for="c-40571193">[-]</label><label class="expand" for="c-40571193">[6 more]</label></div><br/><div class="children"><div class="content">I look forward to the decline in interest in generative ML. There is a screaming need for secure online services to enable democracies to face off the threat from authoritarian regimes. To do this we need hardware that enables actors as in actor model with truly private state, not sandboxed where there is an external entity that can observe its state. Today pretty much all designs has a perverse von Neumann architecture where state is shared across different compute devices like network controllers and management engines. And the software stack is more of the same sandboxing. Apple includes a Secure Enclave on its SoC where you may only communicate with it by sending messages like a proper actor, but why aren’t servers made entirely of secure enclaves? If the memory of each enclave was private by design in hardware it shouldn’t be necessary to encrypt it.</div><br/><div id="40571272" class="c"><input type="checkbox" id="c-40571272" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40571193">parent</a><span>|</span><a href="#40571281">next</a><span>|</span><label class="collapse" for="c-40571272">[-]</label><label class="expand" for="c-40571272">[2 more]</label></div><br/><div class="children"><div class="content">How would that empower democracies more than authoritative regimes? The technologies you mention are means of control, and are used as such. Secure computing doesn&#x27;t help you when the regime owns the keys (or can coerce them out of the vendor).<p>I may very much be wrong about it, but intuition and experience tells me that means of control usually empower authoritarian parties first and foremost, unless fully owned and operated by individuals - which, in computing, is very much counter the trend and the zeitgeist.</div><br/><div id="40571361" class="c"><input type="checkbox" id="c-40571361" checked=""/><div class="controls bullet"><span class="by">acje</span><span>|</span><a href="#40571193">root</a><span>|</span><a href="#40571272">parent</a><span>|</span><a href="#40571281">next</a><span>|</span><label class="collapse" for="c-40571361">[-]</label><label class="expand" for="c-40571361">[1 more]</label></div><br/><div class="children"><div class="content">Good question and I don’t have a good answer. My intuition is that democracies are more dependent on transparency and that lower complexity and higher security would enable more distribution in control.</div><br/></div></div></div></div><div id="40571281" class="c"><input type="checkbox" id="c-40571281" checked=""/><div class="controls bullet"><span class="by">chucke1992</span><span>|</span><a href="#40571193">parent</a><span>|</span><a href="#40571272">prev</a><span>|</span><a href="#40572023">next</a><span>|</span><label class="collapse" for="c-40571281">[-]</label><label class="expand" for="c-40571281">[3 more]</label></div><br/><div class="children"><div class="content">I am pretty sure that democracies are happily pivot to authoritarian regimes because a lot of people just like to have a single choice they prefer.</div><br/><div id="40571510" class="c"><input type="checkbox" id="c-40571510" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#40571193">root</a><span>|</span><a href="#40571281">parent</a><span>|</span><a href="#40572023">next</a><span>|</span><label class="collapse" for="c-40571510">[-]</label><label class="expand" for="c-40571510">[2 more]</label></div><br/><div class="children"><div class="content">To be clear: It&#x27;s not that the electorates like authoritarianism, they hate &quot;democracy&quot; which doesn&#x27;t listen to them nor work for their interests and benefit.</div><br/><div id="40572004" class="c"><input type="checkbox" id="c-40572004" checked=""/><div class="controls bullet"><span class="by">chucke1992</span><span>|</span><a href="#40571193">root</a><span>|</span><a href="#40571510">parent</a><span>|</span><a href="#40572023">next</a><span>|</span><label class="collapse" for="c-40572004">[-]</label><label class="expand" for="c-40572004">[1 more]</label></div><br/><div class="children"><div class="content">but that&#x27;s the whole point - the democracy has to consider interests of various group and - ironically - it only somehow works when you have a single unified group. When you have diverse groups - there interests do not align and it becomes a clownshow</div><br/></div></div></div></div></div></div></div></div><div id="40572023" class="c"><input type="checkbox" id="c-40572023" checked=""/><div class="controls bullet"><span class="by">fariszr</span><span>|</span><a href="#40571193">prev</a><span>|</span><a href="#40570583">next</a><span>|</span><label class="collapse" for="c-40572023">[-]</label><label class="expand" for="c-40572023">[2 more]</label></div><br/><div class="children"><div class="content">A lot of the efficiency improvments depend on the new thread scheduler in Windows 11.<p>I doubt these chips are going to be great or at least, as efficient in Linux as they are in Windows 11.
AMD going for Zen5 and Zen5 is exactly to avoid this issue and the need for complex scheduling algorithms.</div><br/><div id="40572072" class="c"><input type="checkbox" id="c-40572072" checked=""/><div class="controls bullet"><span class="by">eigenspace</span><span>|</span><a href="#40572023">parent</a><span>|</span><a href="#40570583">next</a><span>|</span><label class="collapse" for="c-40572072">[-]</label><label class="expand" for="c-40572072">[1 more]</label></div><br/><div class="children"><div class="content">I’m sure support for heterogeneous CPU scheduling will continue to improve on Linux too. Intel’s server chips have little cores too, and those servers are overwhelmingly running Linux, so they have a clear reason to continue to help support scheduling improvements in Linux as well.</div><br/></div></div></div></div><div id="40570583" class="c"><input type="checkbox" id="c-40570583" checked=""/><div class="controls bullet"><span class="by">mahkeiro</span><span>|</span><a href="#40572023">prev</a><span>|</span><a href="#40571756">next</a><span>|</span><label class="collapse" for="c-40570583">[-]</label><label class="expand" for="c-40570583">[2 more]</label></div><br/><div class="children"><div class="content">Intel fully using TSMC for this generation is quite something!</div><br/><div id="40571900" class="c"><input type="checkbox" id="c-40571900" checked=""/><div class="controls bullet"><span class="by">automatic6131</span><span>|</span><a href="#40570583">parent</a><span>|</span><a href="#40571756">next</a><span>|</span><label class="collapse" for="c-40571900">[-]</label><label class="expand" for="c-40571900">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re making the interconnect themselves. But that very much sounds like I&#x27;m coping on their behalf. TSMC for all the logic and IO though.</div><br/></div></div></div></div><div id="40571756" class="c"><input type="checkbox" id="c-40571756" checked=""/><div class="controls bullet"><span class="by">ThePhysicist</span><span>|</span><a href="#40570583">prev</a><span>|</span><a href="#40571366">next</a><span>|</span><label class="collapse" for="c-40571756">[-]</label><label class="expand" for="c-40571756">[2 more]</label></div><br/><div class="children"><div class="content">Anyone got an estimate for when we might see new Thinkpads with these chips? End of this year? I&#x27;m not unhappy with my current gen 3 T14 but if I could have a device that&#x27;s closer to my Macbook Pro M1 in performance and efficiency I&#x27;d be willing to upgrade, as I still like Linux much more than MacOS.</div><br/><div id="40571947" class="c"><input type="checkbox" id="c-40571947" checked=""/><div class="controls bullet"><span class="by">MaKey</span><span>|</span><a href="#40571756">parent</a><span>|</span><a href="#40571366">next</a><span>|</span><label class="collapse" for="c-40571947">[-]</label><label class="expand" for="c-40571947">[1 more]</label></div><br/><div class="children"><div class="content">Why Intel instead of AMD? Just curious.</div><br/></div></div></div></div><div id="40571366" class="c"><input type="checkbox" id="c-40571366" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40571756">prev</a><span>|</span><a href="#40571023">next</a><span>|</span><label class="collapse" for="c-40571366">[-]</label><label class="expand" for="c-40571366">[1 more]</label></div><br/><div class="children"><div class="content">Based on the instruction set extensions supported, the design of Lunar Lake has been started later that the designs of Arrow Lake and Arrow Lake S.<p>When first announced, Lunar Lake was supposed to be manufactured by an Intel CMOS process that will be available only in 2025 (18A).<p>At some point, Intel has decided to retarget Lunar Lake for the TSMC &quot;3 nm&quot; process, and it appears that this decision has allowed them to be ready for product launch much earlier, so it might be launched before Arrow Lake and Arrow Lake S (the latter of these 2 is a desktop CPU that will also be made in the TSMC &quot;3 nm&quot; process, according to rumors).<p>At Hot Chips 2024, Intel is scheduled to make a more detailed presentation of Lunar Lake.</div><br/></div></div><div id="40571023" class="c"><input type="checkbox" id="c-40571023" checked=""/><div class="controls bullet"><span class="by">diavolodeejay</span><span>|</span><a href="#40571366">prev</a><span>|</span><a href="#40570662">next</a><span>|</span><label class="collapse" for="c-40571023">[-]</label><label class="expand" for="c-40571023">[3 more]</label></div><br/><div class="children"><div class="content">TIL that ram affects wifi performance by creating interferences</div><br/><div id="40571247" class="c"><input type="checkbox" id="c-40571247" checked=""/><div class="controls bullet"><span class="by">bjoli</span><span>|</span><a href="#40571023">parent</a><span>|</span><a href="#40572153">next</a><span>|</span><label class="collapse" for="c-40571247">[-]</label><label class="expand" for="c-40571247">[1 more]</label></div><br/><div class="children"><div class="content">If you have external antennas you can (or at least could) actually try this. Having the RAM just behind the antennas (by holding them in an open case) with a clear line of sight to the router produced significantly worse results than moving the antenna 30cm in either direction.<p>I can&#x27;t remember which WiFi generation I was testing this with but I remember seeing something like a 40% reduction, worst case.</div><br/></div></div><div id="40572153" class="c"><input type="checkbox" id="c-40572153" checked=""/><div class="controls bullet"><span class="by">mschuster91</span><span>|</span><a href="#40571023">parent</a><span>|</span><a href="#40571247">prev</a><span>|</span><a href="#40570662">next</a><span>|</span><label class="collapse" for="c-40572153">[-]</label><label class="expand" for="c-40572153">[1 more]</label></div><br/><div class="children"><div class="content">Anything RF is deep wizarding lore, a world filled with wonders unexplainable to laypeople.<p>The effect is well known, and the reason why if you open up your average phone, there will always be a ton of shielding around components. All the high speed buses can and do create lots of side emissions... so in order to allow a phone to function with its extremely tiny bunch of antennae in direct proximity to the chips, all components get shielded from each other.<p>In desktops and even most laptops however, the high-speed (and thus high-frequency) chips and their clock traces are very far away from the wifi&#x2F;bt antennae, so for a long time manufacturers could get away with not shielding anything, just taking care about ground planes, trace length and impedance matching and spacing. Nowadays, with buses getting ever faster and faster (to the point where <i>analog</i> design criteria take over priority), I think we&#x27;ll start seeing shielding rather sooner than later, and we&#x27;re already seeing CAMM modules getting implemented in devices for the same purpose.<p>Side note: that&#x27;s also why you&#x27;re not supposed to operate a computer&#x27;s parts without a case at all or with a partially open cases. The case itself acts like a faraday cage.</div><br/></div></div></div></div><div id="40570662" class="c"><input type="checkbox" id="c-40570662" checked=""/><div class="controls bullet"><span class="by">mlboss</span><span>|</span><a href="#40571023">prev</a><span>|</span><a href="#40570854">next</a><span>|</span><label class="collapse" for="c-40570662">[-]</label><label class="expand" for="c-40570662">[6 more]</label></div><br/><div class="children"><div class="content">&gt; the Lunar Lake SoC platform also includes up to 32 GB of LPDDR5X memory on the chip package itself<p>Is this similar to Macbook M series chip with shared memory ? Will this allow intel chips to run local llms efficiently ?</div><br/><div id="40571758" class="c"><input type="checkbox" id="c-40571758" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#40570662">parent</a><span>|</span><a href="#40570851">next</a><span>|</span><label class="collapse" for="c-40571758">[-]</label><label class="expand" for="c-40571758">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>the Lunar Lake SoC platform also includes up to 32 GB of LPDDR5X memory on the chip package itself. This is arranged as a pair of 64-bit memory chips, offering a total 128-bit memory interface. As with other vendors using on-package memory, this change means that users can&#x27;t just upgrade DRAM at-will, and the memory configurations for Lunar Lake will ultimately be determined by what SKUs Intel opts to ship.</i><p>In other words, even though it&#x27;s on-package, the width of the memory interface is the same as previous generations. They also exclude upgradability unnecessarily, because even with on-package memory you can still support adding memory through slots. For example, the Xeons with on-package HBM allow this.<p>This decision by Intel seems specifically designed to screw the customer by forcing them to buy a new CPU (or computer) in order to upgrade the memory, without even providing the countervailing benefit that Apple gets from doing it that way. (Note that Apple too unnecessarily prevents adding memory at the traditional level of performance. Cache hierarchies are a thing, if you&#x27;re not trying to screw the customer.)</div><br/></div></div><div id="40570851" class="c"><input type="checkbox" id="c-40570851" checked=""/><div class="controls bullet"><span class="by">DeepYogurt</span><span>|</span><a href="#40570662">parent</a><span>|</span><a href="#40571758">prev</a><span>|</span><a href="#40570712">next</a><span>|</span><label class="collapse" for="c-40570851">[-]</label><label class="expand" for="c-40570851">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Will this allow intel chips to run local llms efficiently ?<p>32GB might not be enough for everything</div><br/><div id="40571056" class="c"><input type="checkbox" id="c-40571056" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#40570662">root</a><span>|</span><a href="#40570851">parent</a><span>|</span><a href="#40570712">next</a><span>|</span><label class="collapse" for="c-40571056">[-]</label><label class="expand" for="c-40571056">[2 more]</label></div><br/><div class="children"><div class="content">Microsoft&#x27;s local copilot requirements are 16GB of memory so it&#x27;s plenty for that.</div><br/></div></div></div></div><div id="40570712" class="c"><input type="checkbox" id="c-40570712" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#40570662">parent</a><span>|</span><a href="#40570851">prev</a><span>|</span><a href="#40570854">next</a><span>|</span><label class="collapse" for="c-40570712">[-]</label><label class="expand" for="c-40570712">[1 more]</label></div><br/><div class="children"><div class="content">In theory, that’s how Intel already is but the memory accessible to the GPU is capped at conservative values .<p>The other issue is that traditionally the integrated GPU has been quite anaemic.</div><br/></div></div></div></div><div id="40570854" class="c"><input type="checkbox" id="c-40570854" checked=""/><div class="controls bullet"><span class="by">shrubble</span><span>|</span><a href="#40570662">prev</a><span>|</span><a href="#40570690">next</a><span>|</span><label class="collapse" for="c-40570854">[-]</label><label class="expand" for="c-40570854">[5 more]</label></div><br/><div class="children"><div class="content">My thinking is that we may be seeing MSFT working to commoditize CPUs and in the process end up strengthening their position while weakening ARM, AMD, and Intel&#x27;s positions.<p>In the past MSFT was always wedded to x86 but now with other ISAs coming, that presumably Windows 11 can be ported to...</div><br/><div id="40570955" class="c"><input type="checkbox" id="c-40570955" checked=""/><div class="controls bullet"><span class="by">jayb_oz</span><span>|</span><a href="#40570854">parent</a><span>|</span><a href="#40571294">next</a><span>|</span><label class="collapse" for="c-40570955">[-]</label><label class="expand" for="c-40570955">[3 more]</label></div><br/><div class="children"><div class="content">&gt; In the past MSFT was always wedded to x86<p>??<p>WindowsNT shipped on x86, Alpha, and MIPS. Then got ported to X64, PowerPC and Itanium.<p>For the NT line, historically Microsoft was very supportive of other ISAs. The market wasn&#x27;t.<p>(I worked on applications supporting a number of those. x86&#x2F;x64 won the price&#x2F;performance war).</div><br/><div id="40571049" class="c"><input type="checkbox" id="c-40571049" checked=""/><div class="controls bullet"><span class="by">shrubble</span><span>|</span><a href="#40570854">root</a><span>|</span><a href="#40570955">parent</a><span>|</span><a href="#40571294">next</a><span>|</span><label class="collapse" for="c-40571049">[-]</label><label class="expand" for="c-40571049">[2 more]</label></div><br/><div class="children"><div class="content">No one bought it on those alternative ISAs, however.  The Alphas and MIPS vendors had a port but what percentage of those systems ended up running a Unix?  This time it is different since DOS and 16bit Windows is out of the picture.<p>This time you have multiple vendors&#x2F;OEMs actually shipping e.g. Snapdragon-based Windows systems.  Lenovo might make money selling such laptops, but over time MSFT will be the largest beneficiary of the &quot;CPU wars&quot;.</div><br/><div id="40572182" class="c"><input type="checkbox" id="c-40572182" checked=""/><div class="controls bullet"><span class="by">The_Colonel</span><span>|</span><a href="#40570854">root</a><span>|</span><a href="#40571049">parent</a><span>|</span><a href="#40571294">next</a><span>|</span><label class="collapse" for="c-40572182">[-]</label><label class="expand" for="c-40572182">[1 more]</label></div><br/><div class="children"><div class="content">There was already Windows on ARM in not so distant past, but it failed. I&#x27;m not convinced this time it will be different.</div><br/></div></div></div></div></div></div><div id="40571294" class="c"><input type="checkbox" id="c-40571294" checked=""/><div class="controls bullet"><span class="by">chucke1992</span><span>|</span><a href="#40570854">parent</a><span>|</span><a href="#40570955">prev</a><span>|</span><a href="#40570690">next</a><span>|</span><label class="collapse" for="c-40571294">[-]</label><label class="expand" for="c-40571294">[1 more]</label></div><br/><div class="children"><div class="content">Rather than MSFT it is just becoming a natural progression - we used to have a lot of various CPU makes in the past too at one point. With ARM now everybody can ship their processors.<p>Intel, AMD, Nvidia, Qualcomm + big tech giants like Apple are already producing them, MSFT is also planning to do that. I recall either Google or Facebook wanted too and so on.</div><br/></div></div></div></div><div id="40570690" class="c"><input type="checkbox" id="c-40570690" checked=""/><div class="controls bullet"><span class="by">simple_quest_9</span><span>|</span><a href="#40570854">prev</a><span>|</span><a href="#40571067">next</a><span>|</span><label class="collapse" for="c-40570690">[-]</label><label class="expand" for="c-40570690">[18 more]</label></div><br/><div class="children"><div class="content">I&#x27;m trying to learn about ISAs.<p>And, after taking a class and watching a whole bunch of RISC vs CISC videos, I still don&#x27;t know &#x27;why&#x27; Apple Silicon is faster at a lower power consumption than Intel&#x27;s chips.<p>Can someone tell me?</div><br/><div id="40572165" class="c"><input type="checkbox" id="c-40572165" checked=""/><div class="controls bullet"><span class="by">mmaniac</span><span>|</span><a href="#40570690">parent</a><span>|</span><a href="#40570772">next</a><span>|</span><label class="collapse" for="c-40572165">[-]</label><label class="expand" for="c-40572165">[1 more]</label></div><br/><div class="children"><div class="content">Lots of reasons, but RISC vs CISC has little to do with it.<p>Apple have access to the newest and best fabbing processes from TSMC. That alone can put a chip a generation in terms of efficiency.<p>Increasing clock speed is the easiest way to increase performance, but power increases quadratically with clock speed so it&#x27;s very inefficient. Apple clock their processors pretty low and instead focused on increasing instructions-per-clock, which is generally more efficient but requires more die area. As an example, a lot of noise was made about the M1&#x27;s 8-wide decoder, twice as wide as contemporary x86 chips, which is an important bottleneck for IPC.<p>Increasing instructions-per-clock requires much bigger CPU cores, and the dies Apple use for their SoCs are famously enormous. While other chip manufacturers are very conscious of performance&#x2F;$, Apple&#x27;s vertical integration gives them wider margins and their customers are much less sensitive to value. So Apple can afford to spend a lot more on bigger chips that are on par in performance but have much greater efficiency.</div><br/></div></div><div id="40570772" class="c"><input type="checkbox" id="c-40570772" checked=""/><div class="controls bullet"><span class="by">supertrope</span><span>|</span><a href="#40570690">parent</a><span>|</span><a href="#40572165">prev</a><span>|</span><a href="#40570862">next</a><span>|</span><label class="collapse" for="c-40570772">[-]</label><label class="expand" for="c-40570772">[2 more]</label></div><br/><div class="children"><div class="content">Power Performance Area. Area is how much wafer area each chip and the features within a chip use. Apple optimizes for the first two and sacrifices the third. Because they mark up their products a lot, are vertically integrated, and they move millions of devices they can sink a lot of $ into bigger chips made on bleeding edge lithography. More area means bigger caches, higher instruction level parallelism. Hiring lots of top chip designers gets better results too.</div><br/><div id="40571026" class="c"><input type="checkbox" id="c-40571026" checked=""/><div class="controls bullet"><span class="by">brigade</span><span>|</span><a href="#40570690">root</a><span>|</span><a href="#40570772">parent</a><span>|</span><a href="#40570862">next</a><span>|</span><label class="collapse" for="c-40571026">[-]</label><label class="expand" for="c-40571026">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re only large compared to other ARM cores, and Cortex-X4 is pretty close nowadays. AMD and especially Intel have a significantly larger per-core area budget; they have to in order to clock past 5 GHz.</div><br/></div></div></div></div><div id="40570862" class="c"><input type="checkbox" id="c-40570862" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#40570690">parent</a><span>|</span><a href="#40570772">prev</a><span>|</span><a href="#40570703">next</a><span>|</span><label class="collapse" for="c-40570862">[-]</label><label class="expand" for="c-40570862">[5 more]</label></div><br/><div class="children"><div class="content">No (less) legacy (smaller chip die area, faster and easier decoder). Paying prime prices for TSMCs newest nodes, one node ahead of everyone else. Bigger (more expensive) caches. Faster memory interface.<p>Nothing magic.<p>But the deep integration with better margins and higher end product prices allows Apple to have more expensive CPUs than the competition.</div><br/><div id="40571057" class="c"><input type="checkbox" id="c-40571057" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40570690">root</a><span>|</span><a href="#40570862">parent</a><span>|</span><a href="#40570703">next</a><span>|</span><label class="collapse" for="c-40571057">[-]</label><label class="expand" for="c-40571057">[4 more]</label></div><br/><div class="children"><div class="content">&gt;No (less) legacy (smaller chip die area, faster and easier decoder)<p>What do you consider legacy? Can you point out how much it does affect die area and the instruction decoder?<p>If I&#x27;d take a guess it&#x27;s not more than maybe 2 or 3%.</div><br/><div id="40571140" class="c"><input type="checkbox" id="c-40571140" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#40570690">root</a><span>|</span><a href="#40571057">parent</a><span>|</span><a href="#40571341">prev</a><span>|</span><a href="#40570703">next</a><span>|</span><label class="collapse" for="c-40571140">[-]</label><label class="expand" for="c-40571140">[2 more]</label></div><br/><div class="children"><div class="content">3% is 3% - IPC gains for Ryzen would not be 15% but 18%.<p>But I do think the benefits are in a faster and easier decoder, and easier memory interfaces etc.<p>Not a hardware engineer, from a software engineer dropping legacy code makes development of new features easier and more cost efficient, so I can concentrate on other things. But as I&#x27;ve said, I&#x27;m no hardware engineer.</div><br/><div id="40572232" class="c"><input type="checkbox" id="c-40572232" checked=""/><div class="controls bullet"><span class="by">mkl</span><span>|</span><a href="#40570690">root</a><span>|</span><a href="#40571140">parent</a><span>|</span><a href="#40570703">next</a><span>|</span><label class="collapse" for="c-40572232">[-]</label><label class="expand" for="c-40572232">[1 more]</label></div><br/><div class="children"><div class="content">3% of die area is not the same as 3% of IPC.</div><br/></div></div></div></div></div></div></div></div><div id="40570703" class="c"><input type="checkbox" id="c-40570703" checked=""/><div class="controls bullet"><span class="by">lights0123</span><span>|</span><a href="#40570690">parent</a><span>|</span><a href="#40570862">prev</a><span>|</span><a href="#40571040">next</a><span>|</span><label class="collapse" for="c-40570703">[-]</label><label class="expand" for="c-40570703">[5 more]</label></div><br/><div class="children"><div class="content">A big factor is that Apple buys out all of TSMC&#x27;s capacity for new process nodes, so they get the smallest transistors that run at lower power and higher speeds.</div><br/><div id="40570776" class="c"><input type="checkbox" id="c-40570776" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40570690">root</a><span>|</span><a href="#40570703">parent</a><span>|</span><a href="#40570726">next</a><span>|</span><label class="collapse" for="c-40570776">[-]</label><label class="expand" for="c-40570776">[2 more]</label></div><br/><div class="children"><div class="content">Notably, Lunar Lake and Apple M4 are made on the same TSMC N3E process and have similar specs so we can perform an apples to apples comparison (sorry not sorry).</div><br/><div id="40571065" class="c"><input type="checkbox" id="c-40571065" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40570690">root</a><span>|</span><a href="#40570776">parent</a><span>|</span><a href="#40570726">next</a><span>|</span><label class="collapse" for="c-40571065">[-]</label><label class="expand" for="c-40571065">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Notably, Lunar Lake and Apple M4 are made on the same TSMC N3E<p>Lunar Lake will be on N3B process.</div><br/></div></div></div></div><div id="40570726" class="c"><input type="checkbox" id="c-40570726" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#40570690">root</a><span>|</span><a href="#40570703">parent</a><span>|</span><a href="#40570776">prev</a><span>|</span><a href="#40571040">next</a><span>|</span><label class="collapse" for="c-40570726">[-]</label><label class="expand" for="c-40570726">[2 more]</label></div><br/><div class="children"><div class="content">People say this, but it’s a trite trivialization of the architectural choices made beyond just the ISA.<p>When AMD&#x2F;intel have moved  to the same or comparable nodes, they’re not catching up for perf&#x2F;watt. Lunar Lake will be on the same N3E as M4, so we’ll have to see how it compares.</div><br/><div id="40572238" class="c"><input type="checkbox" id="c-40572238" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#40570690">root</a><span>|</span><a href="#40570726">parent</a><span>|</span><a href="#40571040">next</a><span>|</span><label class="collapse" for="c-40572238">[-]</label><label class="expand" for="c-40572238">[1 more]</label></div><br/><div class="children"><div class="content">&gt; When AMD&#x2F;intel have moved to the same or comparable nodes, they’re not catching up for perf&#x2F;watt.<p>They are though? If you compare the Apple and AMD processors that are both on e.g. TSMC 5nm, the AMD ones have if anything better performance per watt. Compare the 7945HX3D to any Apple CPU on the same 5nm process with a similar TDP and the 7945HX3D will generally be faster.<p>But people keep doing comparisons right after Apple is the first to release a CPU on a new TSMC process, and naturally if you don&#x27;t compare like with like, the newer process is more efficient.</div><br/></div></div></div></div></div></div><div id="40571040" class="c"><input type="checkbox" id="c-40571040" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40570690">parent</a><span>|</span><a href="#40570703">prev</a><span>|</span><a href="#40571437">next</a><span>|</span><label class="collapse" for="c-40571040">[-]</label><label class="expand" for="c-40571040">[1 more]</label></div><br/><div class="children"><div class="content">Apple optimizes for IPC and power, that means wide architecture and large die area. The rest optimize for throughput and cost. That means small dies and higher power consumption.<p>AMD and Intel can do what Apple does and Apple can do what AMD and Intel do, but each company chooses the path they believe it makes more sense for them.</div><br/></div></div><div id="40571437" class="c"><input type="checkbox" id="c-40571437" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40570690">parent</a><span>|</span><a href="#40571040">prev</a><span>|</span><a href="#40570785">next</a><span>|</span><label class="collapse" for="c-40571437">[-]</label><label class="expand" for="c-40571437">[1 more]</label></div><br/><div class="children"><div class="content">When first launched, the Apple CPUs did about 50% more work per clock cycle (i.e. more instructions executed simultaneously) than the best Intel and AMD CPUs, enabling a 3.2 GHz Apple CPU to have the same single-thread speed as a 4.8 GHz Intel or AMD CPU.<p>Because the power consumption grows at least quadratically with the clock frequency, having the same speed at a lower clock frequency provides better energy efficiency.<p>Meanwhile, the difference in IPC (instructions per clock cycle) between Apple and the others has been reduced, but Apple still has a healthy advantage.<p>The different microarchitecture explains the energy efficiency advantage for single-threaded tasks.<p>On the other hand, for multi-threaded tasks, the power consumption per chip area is limited by cooling and the energy required to do a quantity of useful work (which is done by switching a certain number of logic gates) is mainly determined by the parameters of the CMOS process used to make the CPU die (assuming that the CPU designers are not incompetent).<p>So for multi-threaded tasks the better energy efficiency of the Apple CPUs has been determined mostly by the fact that they have been the only company able to use the latest and greatest TSMC CMOS process.</div><br/></div></div><div id="40570785" class="c"><input type="checkbox" id="c-40570785" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40570690">parent</a><span>|</span><a href="#40571437">prev</a><span>|</span><a href="#40571067">next</a><span>|</span><label class="collapse" for="c-40570785">[-]</label><label class="expand" for="c-40570785">[2 more]</label></div><br/><div class="children"><div class="content">Apple is just better at designing CPUs but nobody wants to hear that. CPU design requires sweating thousands of details. There&#x27;s no one cool trick.</div><br/><div id="40570884" class="c"><input type="checkbox" id="c-40570884" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#40570690">root</a><span>|</span><a href="#40570785">parent</a><span>|</span><a href="#40571067">next</a><span>|</span><label class="collapse" for="c-40570884">[-]</label><label class="expand" for="c-40570884">[1 more]</label></div><br/><div class="children"><div class="content">In which way are they better?<p>Jim Keller (and others) worked on Apple CPUs and on AMDs Ryzen.<p>So when leaving Apple, he (they) became stupid?</div><br/></div></div></div></div></div></div><div id="40571067" class="c"><input type="checkbox" id="c-40571067" checked=""/><div class="controls bullet"><span class="by">SunlitCat</span><span>|</span><a href="#40570690">prev</a><span>|</span><a href="#40571000">next</a><span>|</span><label class="collapse" for="c-40571067">[-]</label><label class="expand" for="c-40571067">[4 more]</label></div><br/><div class="children"><div class="content">Although memory bandwidth is still a limiting factor, I still hope those improvements at the integrated gpu ship over to their desktop counterpart. AMD seems to get at it already.<p>(Yes Yes, I know I know. But I am still dreaming to fit a system capable to play at least a few games into a mini itx case without needing to add a dgpu. One can dream, eh? :)</div><br/><div id="40572133" class="c"><input type="checkbox" id="c-40572133" checked=""/><div class="controls bullet"><span class="by">eigenspace</span><span>|</span><a href="#40571067">parent</a><span>|</span><a href="#40571212">next</a><span>|</span><label class="collapse" for="c-40572133">[-]</label><label class="expand" for="c-40572133">[1 more]</label></div><br/><div class="children"><div class="content">It’s sounding like AMDs high-end mobile processors will probably do what you want mid-to-late next year. Look up “Strix Halo” (not Strix Point, that’s this year).<p>They’re reportedly going for a 256 bit memory interface, and a way bigger GPU than what’s normal for integrated graphics.</div><br/></div></div><div id="40571212" class="c"><input type="checkbox" id="c-40571212" checked=""/><div class="controls bullet"><span class="by">kohlerm</span><span>|</span><a href="#40571067">parent</a><span>|</span><a href="#40572133">prev</a><span>|</span><a href="#40571000">next</a><span>|</span><label class="collapse" for="c-40571212">[-]</label><label class="expand" for="c-40571212">[2 more]</label></div><br/><div class="children"><div class="content">What is the memory bandwidth? I could not find any numbers ..</div><br/><div id="40571426" class="c"><input type="checkbox" id="c-40571426" checked=""/><div class="controls bullet"><span class="by">SunlitCat</span><span>|</span><a href="#40571067">root</a><span>|</span><a href="#40571212">parent</a><span>|</span><a href="#40571000">next</a><span>|</span><label class="collapse" for="c-40571426">[-]</label><label class="expand" for="c-40571426">[1 more]</label></div><br/><div class="children"><div class="content">Sorry, I worded my comment not correctly!<p>I meant in general like in for gaming uses, integrated gpus are limited by the memory bandwidth of the DDR memory bus compared to the high bandwidth memory on dgpus.</div><br/></div></div></div></div></div></div><div id="40571000" class="c"><input type="checkbox" id="c-40571000" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40571067">prev</a><span>|</span><a href="#40570598">next</a><span>|</span><label class="collapse" for="c-40571000">[-]</label><label class="expand" for="c-40571000">[3 more]</label></div><br/><div class="children"><div class="content">&gt;Intel Core product, the Lunar Lake SoC platform also includes up to 32 GB of LPDDR5X memory on the chip package itself<p>What if you need 64 GB of RAM?</div><br/><div id="40571089" class="c"><input type="checkbox" id="c-40571089" checked=""/><div class="controls bullet"><span class="by">ac29</span><span>|</span><a href="#40571000">parent</a><span>|</span><a href="#40571011">next</a><span>|</span><label class="collapse" for="c-40571089">[-]</label><label class="expand" for="c-40571089">[1 more]</label></div><br/><div class="children"><div class="content">Buy something else? Meteor Lake supports up to 96GB, and I assume AMD has something that supports 64GB+ as well.<p>Lunar Lake is specifically targeted towards power efficient laptops, there are no desktop chips, or desktop-class mobile chips. Its being positioned for Macbook Air competitors, a device which maxes out at 24GB RAM.</div><br/></div></div><div id="40571011" class="c"><input type="checkbox" id="c-40571011" checked=""/><div class="controls bullet"><span class="by">kalleboo</span><span>|</span><a href="#40571000">parent</a><span>|</span><a href="#40571089">prev</a><span>|</span><a href="#40570598">next</a><span>|</span><label class="collapse" for="c-40571011">[-]</label><label class="expand" for="c-40571011">[1 more]</label></div><br/><div class="children"><div class="content">Then you don&#x27;t buy a &quot;Low Power Mobile SoC&quot; but a more powerful chipset</div><br/></div></div></div></div><div id="40570598" class="c"><input type="checkbox" id="c-40570598" checked=""/><div class="controls bullet"><span class="by">nubinetwork</span><span>|</span><a href="#40571000">prev</a><span>|</span><a href="#40571448">next</a><span>|</span><label class="collapse" for="c-40570598">[-]</label><label class="expand" for="c-40570598">[20 more]</label></div><br/><div class="children"><div class="content">4P4E and no HT?  Hard pass.</div><br/><div id="40570660" class="c"><input type="checkbox" id="c-40570660" checked=""/><div class="controls bullet"><span class="by">TrainedMonkey</span><span>|</span><a href="#40570598">parent</a><span>|</span><a href="#40571833">next</a><span>|</span><label class="collapse" for="c-40570660">[-]</label><label class="expand" for="c-40570660">[1 more]</label></div><br/><div class="children"><div class="content">It is an offering for low power segment with integrated graphics and an AI unit. I doubt intel is breaking into phones any time soon so I have no idea where this will be used.<p>The really big deal there is that this is an Intel processor built at TMSC.</div><br/></div></div><div id="40571833" class="c"><input type="checkbox" id="c-40571833" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#40570598">parent</a><span>|</span><a href="#40570660">prev</a><span>|</span><a href="#40570634">next</a><span>|</span><label class="collapse" for="c-40571833">[-]</label><label class="expand" for="c-40571833">[1 more]</label></div><br/><div class="children"><div class="content">Hyperthreading is a dead technology, something from the days it was too expensive to have real cores.</div><br/></div></div><div id="40570634" class="c"><input type="checkbox" id="c-40570634" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#40570598">parent</a><span>|</span><a href="#40571833">prev</a><span>|</span><a href="#40571226">next</a><span>|</span><label class="collapse" for="c-40570634">[-]</label><label class="expand" for="c-40570634">[16 more]</label></div><br/><div class="children"><div class="content">What workloads benefit enough from HT to justify it in a laptop?</div><br/><div id="40570666" class="c"><input type="checkbox" id="c-40570666" checked=""/><div class="controls bullet"><span class="by">adgjlsfhk1</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570634">parent</a><span>|</span><a href="#40571001">next</a><span>|</span><label class="collapse" for="c-40570666">[-]</label><label class="expand" for="c-40570666">[13 more]</label></div><br/><div class="children"><div class="content">Most things (other than highly optimized HPC) benefits a ton from hyper threading. Code that&#x27;s unoptimized (e.g. everything web&#x2F;interpreted languages like python&#x2F;JS) spends all its time chasing pointers which means that your cores are doing a whole lot of nothing. Hyperthreading means that you can run twice as many applications per core which means that while one thread is waiting for data from RAM, the other thread can utilize the execution units. This also helps power consumption since if you can consolidate all the tasks onto fewer cores, you can put the other cores to sleep and save power.</div><br/><div id="40570891" class="c"><input type="checkbox" id="c-40570891" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570666">parent</a><span>|</span><a href="#40570702">next</a><span>|</span><label class="collapse" for="c-40570891">[-]</label><label class="expand" for="c-40570891">[4 more]</label></div><br/><div class="children"><div class="content">Likely true in some cases but are these the bottlenecks on a laptop? I&#x27;ve never experienced HT on a multicore CPU being more than maybe a 40% increase in throughput and no real help on latency or efficiency. Implementing HT isn&#x27;t free and doubling the number of active processes halves the per-process cache while doubling the concurrency in the memory controller (or more because less cache). Then there&#x27;s the scheduler complexity... On the other hand there&#x27;s the dual efficiency win of adding more E cores with shorter&#x2F;simpler pipeline and lower clock speeds.<p>Back in the P4 days HT made desktop interactivity much smoother, these days with 8+ core laptops the win is less clear and at least some of the top design teams think it&#x27;s not worth it.</div><br/><div id="40571509" class="c"><input type="checkbox" id="c-40571509" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570891">parent</a><span>|</span><a href="#40570702">next</a><span>|</span><label class="collapse" for="c-40571509">[-]</label><label class="expand" for="c-40571509">[3 more]</label></div><br/><div class="children"><div class="content">As a software developer, by far the most imortant advantage of SMT is the reduction in compilation time for big software projects.<p>I have not encountered any other application that benefits so much from SMT as a compilation that uses all available threads.<p>On older CPUs, such as Skylake derivatives, a 25% compilation speed improvement from SMT was frequent. On newer CPUs, e.g. Zen 3 (presumably also on Zen 4, which has a very similar microarchitecture), the benefits of SMT are smaller (due to improved out-of-order execution), but a 20% compilation speed improvement is still frequent.<p>However, doing compilation on a device with Lunar Lake, a CPU with only 4+4 cores, would be a waste of time, so it clearly does not need SMT.<p>On the other hand, doing compilation on a bigger laptop, with an AMD Strix Point 12-core&#x2F;24-thread CPU or with whatever Arrow Lake CPU will be launched by Intel to compete with it (presumably having much more smaller Skymont cores than Lunar Lake, to compensate for the lack of SMT) would certainly be useful.</div><br/><div id="40571662" class="c"><input type="checkbox" id="c-40571662" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40571509">parent</a><span>|</span><a href="#40570702">next</a><span>|</span><label class="collapse" for="c-40571662">[-]</label><label class="expand" for="c-40571662">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve moved to almost entirely remote dev workflow for similar reasons. Out of curiosity how much RAM do you need per build thread?</div><br/><div id="40571806" class="c"><input type="checkbox" id="c-40571806" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40571662">parent</a><span>|</span><a href="#40570702">next</a><span>|</span><label class="collapse" for="c-40571806">[-]</label><label class="expand" for="c-40571806">[1 more]</label></div><br/><div class="children"><div class="content">When compiling an entire Linux distribution, there are a few outliers, all of which are derivatives of the Google Chrome code base, which may fail when less than 2 GB is available per build thread (e.g. for a 16C&#x2F;32T CPU with make -j32, 64 GB of DRAM are required).<p>For most other software projects 1 GB per build thread is enough.</div><br/></div></div></div></div></div></div></div></div><div id="40570702" class="c"><input type="checkbox" id="c-40570702" checked=""/><div class="controls bullet"><span class="by">dumbo-octopus</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570666">parent</a><span>|</span><a href="#40570891">prev</a><span>|</span><a href="#40571186">next</a><span>|</span><label class="collapse" for="c-40570702">[-]</label><label class="expand" for="c-40570702">[1 more]</label></div><br/><div class="children"><div class="content">This isn’t really true. In JS, the JIT can optimize many routines to be much more CPU bound than “just pointer chasing” would have you believe. And of course in Python the bulk of your time <i>should</i> be spent in native code. Whether it actually is is a different question.</div><br/></div></div><div id="40571186" class="c"><input type="checkbox" id="c-40571186" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570666">parent</a><span>|</span><a href="#40570702">prev</a><span>|</span><a href="#40570826">next</a><span>|</span><label class="collapse" for="c-40571186">[-]</label><label class="expand" for="c-40571186">[1 more]</label></div><br/><div class="children"><div class="content">How often do you have more than 4&#x2F;8 processes being CPU&#x2F;memory bound at the same time?<p>As far as power, using simpler cores helps a significant amount too.</div><br/></div></div><div id="40570826" class="c"><input type="checkbox" id="c-40570826" checked=""/><div class="controls bullet"><span class="by">YZF</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570666">parent</a><span>|</span><a href="#40571186">prev</a><span>|</span><a href="#40571001">next</a><span>|</span><label class="collapse" for="c-40570826">[-]</label><label class="expand" for="c-40570826">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve always thought of HyperThreading as marketing with no substance. I&#x27;ve seen applications run slower with HT turned on (admittedly a long time ago). Does this combination of running two threads that are &quot;poorly&quot; written (i.e. they can&#x27;t make use of all the execution units) really exist? If you&#x27;re multitasking applications you very rarely have multiple application simultaneously require a lot of CPU cycles (e.g. you might be switching from a spreadsheet to a browser but not doing heavy work on both simultaneously). If you are running some specific heavy computational workload then likely it&#x27;s already optimized to fully utilize the cores it is getting and HT can actually get in the way of that.</div><br/><div id="40571084" class="c"><input type="checkbox" id="c-40571084" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570826">parent</a><span>|</span><a href="#40570931">next</a><span>|</span><label class="collapse" for="c-40571084">[-]</label><label class="expand" for="c-40571084">[2 more]</label></div><br/><div class="children"><div class="content">&gt;If you are running some specific heavy computational workload then likely it&#x27;s already optimized to fully utilize the cores it is getting and HT can actually get in the way of that.<p>You can test that by running Cinebench with and without hyperthreading. In most of the cases hyperthreading does help.</div><br/><div id="40571492" class="c"><input type="checkbox" id="c-40571492" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40571084">parent</a><span>|</span><a href="#40570931">next</a><span>|</span><label class="collapse" for="c-40571492">[-]</label><label class="expand" for="c-40571492">[1 more]</label></div><br/><div class="children"><div class="content">A lot of rendering benefits from having SMT&#x2F;HT disabled. Almost every film studio will do so.<p>Having accurate hardware thread counts matter in those scenarios because the renderers will basically peg each core completely , and the risk of having an SMT&#x2F;HT context switch between them is detrimental. It was often up to a 30% speed decrease when HT was enabled for us in production scenes.<p>Similarly , many games run better without HT.<p>HT primarily benefits scenarios with many smaller jobs without latency sensitivity.<p>Today though, E-cores have largely replaced the need for HT. It’s much easier to send them to an E core and have them done without the extra overhead of HT scheduling and support.</div><br/></div></div></div></div><div id="40570931" class="c"><input type="checkbox" id="c-40570931" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570826">parent</a><span>|</span><a href="#40571084">prev</a><span>|</span><a href="#40571204">next</a><span>|</span><label class="collapse" for="c-40570931">[-]</label><label class="expand" for="c-40570931">[1 more]</label></div><br/><div class="children"><div class="content">There are server workloads like maybe high concurrency web apps that might benefit. Back in the days of single core CPUs HT made desktops feel a lot better not just because of throughput but (my speculation) because it reduced typical scheduling latency. Antivirus or whatever else was happening in the background was less likely to cause UI jank.</div><br/></div></div><div id="40571204" class="c"><input type="checkbox" id="c-40571204" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570826">parent</a><span>|</span><a href="#40570931">prev</a><span>|</span><a href="#40570861">next</a><span>|</span><label class="collapse" for="c-40571204">[-]</label><label class="expand" for="c-40571204">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve always thought of HyperThreading as marketing with no substance.<p>It could make a big difference when you only had one or two cores.</div><br/></div></div><div id="40570861" class="c"><input type="checkbox" id="c-40570861" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570826">parent</a><span>|</span><a href="#40571204">prev</a><span>|</span><a href="#40571001">next</a><span>|</span><label class="collapse" for="c-40570861">[-]</label><label class="expand" for="c-40570861">[1 more]</label></div><br/><div class="children"><div class="content">HT is good for shitty code that chooses core count for threading. When it should really be multiples the core count given time spent mostly in IO.</div><br/></div></div></div></div></div></div><div id="40571001" class="c"><input type="checkbox" id="c-40571001" checked=""/><div class="controls bullet"><span class="by">sregister</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570634">parent</a><span>|</span><a href="#40570666">prev</a><span>|</span><a href="#40571289">next</a><span>|</span><label class="collapse" for="c-40571001">[-]</label><label class="expand" for="c-40571001">[1 more]</label></div><br/><div class="children"><div class="content">I dont think apple silicon supports SMT? Isn&#x27;t that enough evidence to show at least for mobile parts 4P4E at least has a chance to be interesting? Also some of the graphs appear to show the new Skymont uarch has high perf&#x2F;w than raptor cove (the previous P core) which is rather impressive in my opinion.</div><br/></div></div><div id="40571289" class="c"><input type="checkbox" id="c-40571289" checked=""/><div class="controls bullet"><span class="by">usrusr</span><span>|</span><a href="#40570598">root</a><span>|</span><a href="#40570634">parent</a><span>|</span><a href="#40571001">prev</a><span>|</span><a href="#40571226">next</a><span>|</span><label class="collapse" for="c-40571289">[-]</label><label class="expand" for="c-40571289">[1 more]</label></div><br/><div class="children"><div class="content">Nothing. When you want more throughput, pick a setup with more cores. HT was good (not <i>that</i> good but still good) when the goal was performance per die area, but now we live in the area of performance per watt. Doubly so when looking at laptops, but also in all other areas except perhaps gaming PCs (but even there, throughput at high wattage will eventually lead to throttling).</div><br/></div></div></div></div></div></div><div id="40571448" class="c"><input type="checkbox" id="c-40571448" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#40570598">prev</a><span>|</span><label class="collapse" for="c-40571448">[-]</label><label class="expand" for="c-40571448">[6 more]</label></div><br/><div class="children"><div class="content">Integrated ram, limited to 32 Gb.<p>I wonder if they&#x27;ll make 4 Gb SKUs to outdo Apple at their own game...<p>Also, will the spying coprocessor, sorry, &quot;AI&quot; coprocessor, have a hardware off switch that will cut the power to that part of the CPU?</div><br/><div id="40571702" class="c"><input type="checkbox" id="c-40571702" checked=""/><div class="controls bullet"><span class="by">fomine3</span><span>|</span><a href="#40571448">parent</a><span>|</span><a href="#40571503">next</a><span>|</span><label class="collapse" for="c-40571702">[-]</label><label class="expand" for="c-40571702">[2 more]</label></div><br/><div class="children"><div class="content">Apple M3 supports up to 24GB of RAM so it&#x27;s not so bad.</div><br/><div id="40571735" class="c"><input type="checkbox" id="c-40571735" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#40571448">root</a><span>|</span><a href="#40571702">parent</a><span>|</span><a href="#40571503">next</a><span>|</span><label class="collapse" for="c-40571735">[-]</label><label class="expand" for="c-40571735">[1 more]</label></div><br/><div class="children"><div class="content">Apple supports up to 96 or 128 gb in laptops though. Why do you compare just with the entry level SoC?<p>That doesn’t make them any less assholes (cough ram pricing). I’m predicting that Intel will try to outcompete them at assholery though.</div><br/></div></div></div></div><div id="40571503" class="c"><input type="checkbox" id="c-40571503" checked=""/><div class="controls bullet"><span class="by">Sakos</span><span>|</span><a href="#40571448">parent</a><span>|</span><a href="#40571702">prev</a><span>|</span><label class="collapse" for="c-40571503">[-]</label><label class="expand" for="c-40571503">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m so tired of soldered components. The performance and power benefits are simply not good enough to justify producing millions of landfill-destined devices and high costs for consumers.</div><br/><div id="40572040" class="c"><input type="checkbox" id="c-40572040" checked=""/><div class="controls bullet"><span class="by">johnny22</span><span>|</span><a href="#40571448">root</a><span>|</span><a href="#40571503">parent</a><span>|</span><label class="collapse" for="c-40572040">[-]</label><label class="expand" for="c-40572040">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think soldered components would have been a big deal were the amounts enough. 32gb soldered on say 7 years ago would last you a long time. If they&#x27;re gonna solder, they need to stop skimping.</div><br/><div id="40572222" class="c"><input type="checkbox" id="c-40572222" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#40571448">root</a><span>|</span><a href="#40572040">parent</a><span>|</span><label class="collapse" for="c-40572222">[-]</label><label class="expand" for="c-40572222">[1 more]</label></div><br/><div class="children"><div class="content">One other major problem with soldering is only the most common SKUs are in stock, at least if you&#x27;re in a smaller market. I mean, I hope the US is different, not sure if that&#x27;s true.<p>If you want to future proof and max out the ram you have to wait. And if you need an emergency hardware replacement, you&#x27;re screwed.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>