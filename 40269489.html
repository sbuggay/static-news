<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1714986073264" as="style"/><link rel="stylesheet" href="styles.css?v=1714986073264"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/alessiodm/drl-zh">Deep Reinforcement Learning: Zero to Hero</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>alessiodm</span> | <span>29 comments</span></div><br/><div><div id="40269490" class="c"><input type="checkbox" id="c-40269490" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270005">next</a><span>|</span><label class="collapse" for="c-40269490">[-]</label><label class="expand" for="c-40269490">[4 more]</label></div><br/><div class="children"><div class="content">While trying to learn the latest in Deep Reinforcement Learning, I was able to take advantage of many excellent resources (see credits [1]), but I couldn&#x27;t find one that provided the right balance between theory and practice for my personal experience. So I decided to create something myself, and open-source it for the community, in case it might be useful to someone else.<p>None of that would have been possible without all the resources listed in [1], but I rewrote all algorithms in this series of Python notebooks from scratch, with a &quot;pedagogical approach&quot; in mind. It is a hands-on step-by-step tutorial about Deep Reinforcement Learning techniques (up ~2018&#x2F;2019 SoTA) guiding through theory and coding exercises on the most utilized algorithms (QLearning, DQN, SAC, PPO, etc.)<p>I shamelessly stole the title from a hero of mine, Andrej Karpathy, and his &quot;Neural Network: Zero To Hero&quot; [2] work. I also meant to work on a series of YouTube videos, but didn&#x27;t have the time yet. If this posts gets any type of interest, I might go back to it. Thank you.<p>P.S.: A friend of mine suggested me to post here, so I followed their advice: this is my first post, I hope it properly abides with the rules of the community.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;alessiodm&#x2F;drl-zh&#x2F;blob&#x2F;main&#x2F;00_Intro.ipynb">https:&#x2F;&#x2F;github.com&#x2F;alessiodm&#x2F;drl-zh&#x2F;blob&#x2F;main&#x2F;00_Intro.ipynb</a>
[2] <a href="https:&#x2F;&#x2F;karpathy.ai&#x2F;zero-to-hero.html" rel="nofollow">https:&#x2F;&#x2F;karpathy.ai&#x2F;zero-to-hero.html</a></div><br/><div id="40271917" class="c"><input type="checkbox" id="c-40271917" checked=""/><div class="controls bullet"><span class="by">tunnuz</span><span>|</span><a href="#40269490">parent</a><span>|</span><a href="#40269583">next</a><span>|</span><label class="collapse" for="c-40271917">[-]</label><label class="expand" for="c-40271917">[1 more]</label></div><br/><div class="children"><div class="content">Does it rely heavily on python, or could someone use a different language to go through the material?</div><br/></div></div><div id="40269583" class="c"><input type="checkbox" id="c-40269583" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40269490">parent</a><span>|</span><a href="#40271917">prev</a><span>|</span><a href="#40270005">next</a><span>|</span><label class="collapse" for="c-40269583">[-]</label><label class="expand" for="c-40269583">[2 more]</label></div><br/><div class="children"><div class="content">very cool, thanks for putting this together<p>It would be great to see a page dedicated to SoTA techniques &amp; results</div><br/><div id="40269707" class="c"><input type="checkbox" id="c-40269707" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40269490">root</a><span>|</span><a href="#40269583">parent</a><span>|</span><a href="#40270005">next</a><span>|</span><label class="collapse" for="c-40269707">[-]</label><label class="expand" for="c-40269707">[1 more]</label></div><br/><div class="children"><div class="content">Thank you so much! And very good advice: I have an extremely brief and not-descriptive list in the &quot;Next&quot; notebook, initially intended for that. But it definitely falls short.<p>I may actually expand it in a second &quot;more advanced&quot; series of notebooks, to explore model-based RL, curiosity, and other recent topics: even if not comprehensive, some hands on basic coding exercise on those topics might be of interest nonetheless.</div><br/></div></div></div></div></div></div><div id="40270005" class="c"><input type="checkbox" id="c-40270005" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#40269490">prev</a><span>|</span><a href="#40270264">next</a><span>|</span><label class="collapse" for="c-40270005">[-]</label><label class="expand" for="c-40270005">[4 more]</label></div><br/><div class="children"><div class="content">In case you want to expand to more chapters one day: there&#x27;s lots of tutorials of doing the simple things that has been verified to work, but if I&#x27;m struggling it&#x27;s normally with something people barely ever mention - what to do when things go wrong. For example your actions just consistently get stuck at maximum. Or the exploration doesn&#x27;t kick in, regardless how noisy you make the off-policy training. Or ...<p>I wish there were more practical resources for when you&#x27;ve got the basics usually working, but suddenly get issues nobody really talks about. (beyond &quot;just tweak some stuff until it works&quot; anyway)</div><br/><div id="40270119" class="c"><input type="checkbox" id="c-40270119" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270005">parent</a><span>|</span><a href="#40270264">next</a><span>|</span><label class="collapse" for="c-40270119">[-]</label><label class="expand" for="c-40270119">[3 more]</label></div><br/><div class="children"><div class="content">Thanks a lot, and another great suggestion for improvement. I also found that the common advice is &quot;tweak hyperparameters until you find the right combination&quot;. That can definitely help. But usually issues hide in different &quot;corners&quot;, both of the problem space and its formulation, the algorithm itself (e.g., just different random seeds have big variance in performance), and more.<p>As you mentioned, in real applications of DRL things tend to go wrong more often than right: &quot;it doesn&#x27;t work just yet&quot; [1]. And my short tutorial definitely lacks in the area of troubleshooting, tuning, and &quot;productionisation&quot;. If I carve time for expansion, this will likely make top of list. Thanks again.<p>[1] <a href="https:&#x2F;&#x2F;www.alexirpan.com&#x2F;2018&#x2F;02&#x2F;14&#x2F;rl-hard.html" rel="nofollow">https:&#x2F;&#x2F;www.alexirpan.com&#x2F;2018&#x2F;02&#x2F;14&#x2F;rl-hard.html</a></div><br/><div id="40270681" class="c"><input type="checkbox" id="c-40270681" checked=""/><div class="controls bullet"><span class="by">ubj</span><span>|</span><a href="#40270005">root</a><span>|</span><a href="#40270119">parent</a><span>|</span><a href="#40270264">next</a><span>|</span><label class="collapse" for="c-40270681">[-]</label><label class="expand" for="c-40270681">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing [1], that was a great read. I&#x27;d be curious to see an updated version of that article, since it&#x27;s about 6 years old now. For example, Boston Dynamics has transitioned from MPC to RL for controlling its Spot robots [2]. Davide Scaramuzza, whose team created autonomous FPV drones that beat expert human pilots, has also discussed how his team had to transition from MPC to RL [3].<p>[2]: <a href="https:&#x2F;&#x2F;bostondynamics.com&#x2F;blog&#x2F;starting-on-the-right-foot-with-reinforcement-learning&#x2F;" rel="nofollow">https:&#x2F;&#x2F;bostondynamics.com&#x2F;blog&#x2F;starting-on-the-right-foot-w...</a><p>[3]: <a href="https:&#x2F;&#x2F;www.incontrolpodcast.com&#x2F;1632769&#x2F;13775734-ep15-davide-scaramuzza-vision-based-navigation-agile-drone-racing-perception-aware-control-and-event-cameras" rel="nofollow">https:&#x2F;&#x2F;www.incontrolpodcast.com&#x2F;1632769&#x2F;13775734-ep15-david...</a></div><br/><div id="40271016" class="c"><input type="checkbox" id="c-40271016" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270005">root</a><span>|</span><a href="#40270681">parent</a><span>|</span><a href="#40270264">next</a><span>|</span><label class="collapse" for="c-40271016">[-]</label><label class="expand" for="c-40271016">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for the amazing links as well! You are right that the article [1] is 6 years old now, and indeed the field has evolved. But the algorithms and techniques I share in the GitHub repo are the &quot;classic&quot; ones (dating back then too), for which that post is still relevant - at least from an historical perspective.<p>You bring up a very good point though: more recent advancements and assessments should be linked and&#x2F;or mentioned in the repo (e.g., in the resources and&#x2F;or an appendix). I will try to do that sometime.</div><br/></div></div></div></div></div></div></div></div><div id="40270264" class="c"><input type="checkbox" id="c-40270264" checked=""/><div class="controls bullet"><span class="by">zaptrem</span><span>|</span><a href="#40270005">prev</a><span>|</span><a href="#40271218">next</a><span>|</span><label class="collapse" for="c-40270264">[-]</label><label class="expand" for="c-40270264">[3 more]</label></div><br/><div class="children"><div class="content">I spent three semesters in college learning RL only to be massively disappointed in the end after discovering that the latest and greatest RL techniques canât even beat a simple heuristic in Tetris.</div><br/><div id="40270449" class="c"><input type="checkbox" id="c-40270449" checked=""/><div class="controls bullet"><span class="by">jmward01</span><span>|</span><a href="#40270264">parent</a><span>|</span><a href="#40270333">next</a><span>|</span><label class="collapse" for="c-40270449">[-]</label><label class="expand" for="c-40270449">[1 more]</label></div><br/><div class="children"><div class="content">I modeled part of my company&#x27;s business problem as a MAB problem and saved my company 10% off their biggest cost and, just as important, showcased an automated truth signal that helped us understand what was, and wasn&#x27;t, working in several of our features. Like all tools, finding the right place to use RL concepts is a big deal. I think one thing that is often missed in a classroom setting is pushing more real world examples of where powerful ideas can be used. Talking about optimal policies is great, but if you don&#x27;t help people understand where those ideas can be applied then it is just a bunch of fun math. (which is often a good enough reason on its own :)</div><br/></div></div><div id="40270333" class="c"><input type="checkbox" id="c-40270333" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270264">parent</a><span>|</span><a href="#40270449">prev</a><span>|</span><a href="#40271218">next</a><span>|</span><label class="collapse" for="c-40270333">[-]</label><label class="expand" for="c-40270333">[1 more]</label></div><br/><div class="children"><div class="content">RL can be massively disappointing, indeed. And I agree with you (and with the amazing post I already referenced [1]) that it is hard to get it to work at all. Sorry to hear you have been disappointed so much!<p>Nonetheless, I would personally recommend even just learning the basics and fundamentals of RL. Beyond supervised, unsupervised, and the most-recent and well-deservedly hyped semi-supervised learning (generative AI, LLMs, and so on), reinforcement learning indeed models the learning problem in a very elegant way: an agent interacting with an environment and getting feedback. Which is, arguably, a very intuitive and natural way of modeling it. You could consider backward error correction &#x2F; propagation as an implicit reward signal, but that would be a very limited view.<p>On a positive note, RL has very practical sucessful applications today - even if in niche fields. For example, LLM fine-tuning techniques like RLHF successfully apply RL to modern AI systems, companies like Covariant are working on large robotics models which definitely use RL, and generally as a research field I believe (but I may be proven wrong!) there is so much more to explore. For example, check Nvidia Eureka that combines LLM to RL [2]: pretty cool stuff IMHO!<p>Far from attempting to convince you on the strength and capabilities of DRL, just recommending folks to not discard it right away and at least give it a chance to learn the basics, even just for an intellectual exercise :) Thanks again!<p>[1] <a href="https:&#x2F;&#x2F;www.alexirpan.com&#x2F;2018&#x2F;02&#x2F;14&#x2F;rl-hard.html" rel="nofollow">https:&#x2F;&#x2F;www.alexirpan.com&#x2F;2018&#x2F;02&#x2F;14&#x2F;rl-hard.html</a><p>[2] <a href="https:&#x2F;&#x2F;blogs.nvidia.com&#x2F;blog&#x2F;eureka-robotics-research&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blogs.nvidia.com&#x2F;blog&#x2F;eureka-robotics-research&#x2F;</a></div><br/></div></div></div></div><div id="40271218" class="c"><input type="checkbox" id="c-40271218" checked=""/><div class="controls bullet"><span class="by">chaosprint</span><span>|</span><a href="#40270264">prev</a><span>|</span><a href="#40270177">next</a><span>|</span><label class="collapse" for="c-40271218">[-]</label><label class="expand" for="c-40271218">[1 more]</label></div><br/><div class="children"><div class="content">Great resources! Thank you for making this.<p>I&#x27;m attaching here a DRL framework I made for music generation, similar to OpenAI Gym. If anyone wants to test the algorithms OP includes, you are welcome to use it. Issues and PRs are also welcome.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;chaosprint&#x2F;RaveForce">https:&#x2F;&#x2F;github.com&#x2F;chaosprint&#x2F;RaveForce</a></div><br/></div></div><div id="40270177" class="c"><input type="checkbox" id="c-40270177" checked=""/><div class="controls bullet"><span class="by">achandra03</span><span>|</span><a href="#40271218">prev</a><span>|</span><a href="#40272218">next</a><span>|</span><label class="collapse" for="c-40270177">[-]</label><label class="expand" for="c-40270177">[2 more]</label></div><br/><div class="children"><div class="content">This looks really interesting! I tried exploring deep RL myself some time ago but could never get my agents to make any meaningful progress, and as someone with very little stats&#x2F;ML background it was difficult to debug what was going wrong. Will try following this and seeing what happens!</div><br/><div id="40270202" class="c"><input type="checkbox" id="c-40270202" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270177">parent</a><span>|</span><a href="#40272218">next</a><span>|</span><label class="collapse" for="c-40270202">[-]</label><label class="expand" for="c-40270202">[1 more]</label></div><br/><div class="children"><div class="content">Thank you very much! I&#x27;d be really interested to know if your agents will eventually make progress, and if these notebooks help - even if a tiny bit!<p>If you just want to see if these algorithm can even work at all, feel free to jump on the `solution` folder and pick any algorithm you think could work and just try it out there. If it does, then you can have all the fun rewriting it from scratch :) Thanks again!</div><br/></div></div></div></div><div id="40272218" class="c"><input type="checkbox" id="c-40272218" checked=""/><div class="controls bullet"><span class="by">malomalsky</span><span>|</span><a href="#40270177">prev</a><span>|</span><a href="#40271015">next</a><span>|</span><label class="collapse" for="c-40272218">[-]</label><label class="expand" for="c-40272218">[1 more]</label></div><br/><div class="children"><div class="content">If there anything like that, but for NLP?</div><br/></div></div><div id="40271015" class="c"><input type="checkbox" id="c-40271015" checked=""/><div class="controls bullet"><span class="by">levocardia</span><span>|</span><a href="#40272218">prev</a><span>|</span><a href="#40270421">next</a><span>|</span><label class="collapse" for="c-40271015">[-]</label><label class="expand" for="c-40271015">[2 more]</label></div><br/><div class="children"><div class="content">This looks great - maybe add a link to the youtube videos in the README?</div><br/><div id="40271033" class="c"><input type="checkbox" id="c-40271033" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40271015">parent</a><span>|</span><a href="#40270421">next</a><span>|</span><label class="collapse" for="c-40271033">[-]</label><label class="expand" for="c-40271033">[1 more]</label></div><br/><div class="children"><div class="content">Thank you so much!  Unfortunately, that is a mistake in the README that I just noticed (thank you for pointing it out!) :(  As I mentioned in the first post, I didn&#x27;t get to make the YouTube videos yet. But it seems the community would be indeed interested.<p>I will try to get to them (and in the meantime fix the README, sorry about that!)</div><br/></div></div></div></div><div id="40270421" class="c"><input type="checkbox" id="c-40270421" checked=""/><div class="controls bullet"><span class="by">bluishgreen</span><span>|</span><a href="#40271015">prev</a><span>|</span><label class="collapse" for="c-40270421">[-]</label><label class="expand" for="c-40270421">[11 more]</label></div><br/><div class="children"><div class="content">&quot;Shamelessly stole the title from a hero of mine&quot;. Your Shamelessness is all fine. But at first I thought this is a post from Andrej Karpathy. He has one of the best personal brands out there on the internet, while personal brands can&#x27;t be enforced, this confused me at first.</div><br/><div id="40270475" class="c"><input type="checkbox" id="c-40270475" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270421">parent</a><span>|</span><label class="collapse" for="c-40270475">[-]</label><label class="expand" for="c-40270475">[10 more]</label></div><br/><div class="children"><div class="content">TL;DR: If more folks feel this way, please upvote this comment: I&#x27;ll be happy to take down this post, change the title, and either re-post it or just don&#x27;t - the GitHub repo is out there - that that should be more than enough. Sorry again for the confusion (I just upvoted it).<p>I am deeply sorry about the confusion. And the last thing I intended was to grab any attention away from Andrej, and &#x2F; or being confused with him.<p>I tried to find a way to edit the post title, but I couldn&#x27;t find one. Is there just a limited time window to do that? If you know how to do it, I&#x27;d be happy to edit it right away in case.<p>I didn&#x27;t even think this post would get any attention at all - it is my first post indeed here, and I really did it just b&#x2F;c if anybody could use this project to learn RL I was happy to share.</div><br/><div id="40270600" class="c"><input type="checkbox" id="c-40270600" checked=""/><div class="controls bullet"><span class="by">ultra_nick</span><span>|</span><a href="#40270421">root</a><span>|</span><a href="#40270475">parent</a><span>|</span><a href="#40270591">next</a><span>|</span><label class="collapse" for="c-40270600">[-]</label><label class="expand" for="c-40270600">[2 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t &quot;Zero to Hero&quot; come from Disney&#x27;s Hercules movie before Karparthy used it?</div><br/><div id="40270609" class="c"><input type="checkbox" id="c-40270609" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270421">root</a><span>|</span><a href="#40270600">parent</a><span>|</span><a href="#40270591">next</a><span>|</span><label class="collapse" for="c-40270609">[-]</label><label class="expand" for="c-40270609">[1 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t know that, but now I have an excuse to go watch a movie :D</div><br/></div></div></div></div><div id="40270591" class="c"><input type="checkbox" id="c-40270591" checked=""/><div class="controls bullet"><span class="by">gradascent</span><span>|</span><a href="#40270421">root</a><span>|</span><a href="#40270475">parent</a><span>|</span><a href="#40270600">prev</a><span>|</span><a href="#40270510">next</a><span>|</span><label class="collapse" for="c-40270591">[-]</label><label class="expand" for="c-40270591">[2 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t find it confusing at all. I think it&#x27;s totally ok to re-use phrasing made famous by someone else - this is how language evolves after all.</div><br/><div id="40270606" class="c"><input type="checkbox" id="c-40270606" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270421">root</a><span>|</span><a href="#40270591">parent</a><span>|</span><a href="#40270510">next</a><span>|</span><label class="collapse" for="c-40270606">[-]</label><label class="expand" for="c-40270606">[1 more]</label></div><br/><div class="children"><div class="content">Thank you, I appreciate it.</div><br/></div></div></div></div><div id="40270510" class="c"><input type="checkbox" id="c-40270510" checked=""/><div class="controls bullet"><span class="by">khiner</span><span>|</span><a href="#40270421">root</a><span>|</span><a href="#40270475">parent</a><span>|</span><a href="#40270591">prev</a><span>|</span><a href="#40270791">next</a><span>|</span><label class="collapse" for="c-40270510">[-]</label><label class="expand" for="c-40270510">[2 more]</label></div><br/><div class="children"><div class="content">Throwing in my vote - I wasnât confused, saw your GH link and a âZero to Heroâ course name on RL, seems clear to me and âZero to Heroâ is a classic title for a first course, nice that you gave props to Andrea too! Multiple people can and should make ML guides and reference each other. Thanks for putting in the time to share your learnings and make a fantastic resource out of it!</div><br/><div id="40270533" class="c"><input type="checkbox" id="c-40270533" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270421">root</a><span>|</span><a href="#40270510">parent</a><span>|</span><a href="#40270791">next</a><span>|</span><label class="collapse" for="c-40270533">[-]</label><label class="expand" for="c-40270533">[1 more]</label></div><br/><div class="children"><div class="content">Thanks a lot. It makes me feel better to hear that the post is not completely confusing and appropriating - I really didn&#x27;t mean that, or to use it as a trick for attention.</div><br/></div></div></div></div><div id="40270572" class="c"><input type="checkbox" id="c-40270572" checked=""/><div class="controls bullet"><span class="by">FezzikTheGiant</span><span>|</span><a href="#40270421">root</a><span>|</span><a href="#40270475">parent</a><span>|</span><a href="#40270791">prev</a><span>|</span><label class="collapse" for="c-40270572">[-]</label><label class="expand" for="c-40270572">[2 more]</label></div><br/><div class="children"><div class="content">this is a great resource nonetheless. Even if you did use the name to get attention how does it matter? I still see it as a net positive. Thanks for sharing this</div><br/><div id="40270581" class="c"><input type="checkbox" id="c-40270581" checked=""/><div class="controls bullet"><span class="by">alessiodm</span><span>|</span><a href="#40270421">root</a><span>|</span><a href="#40270572">parent</a><span>|</span><label class="collapse" for="c-40270581">[-]</label><label class="expand" for="c-40270581">[1 more]</label></div><br/><div class="children"><div class="content">Thank you!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>