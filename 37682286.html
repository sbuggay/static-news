<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1695891663104" as="style"/><link rel="stylesheet" href="styles.css?v=1695891663104"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://carton.run">Show HN: Carton – Run any ML model from any programming language</a> <span class="domain">(<a href="https://carton.run">carton.run</a>)</span></div><div class="subtext"><span>vpanyam</span> | <span>28 comments</span></div><br/><div><div id="37686229" class="c"><input type="checkbox" id="c-37686229" checked=""/><div class="controls bullet"><span class="by">otabdeveloper4</span><span>|</span><a href="#37686976">next</a><span>|</span><label class="collapse" for="c-37686229">[-]</label><label class="expand" for="c-37686229">[1 more]</label></div><br/><div class="children"><div class="content">&gt; From any [*] programming language.<p>[*] If &quot;any programming language&quot; is Python or Javascript.</div><br/></div></div><div id="37686976" class="c"><input type="checkbox" id="c-37686976" checked=""/><div class="controls bullet"><span class="by">softg</span><span>|</span><a href="#37686229">prev</a><span>|</span><a href="#37685196">next</a><span>|</span><label class="collapse" for="c-37686976">[-]</label><label class="expand" for="c-37686976">[1 more]</label></div><br/><div class="children"><div class="content">Slightly related dumb question, I saw on GitHub that TensorFlow has Java support. Does anyone actually use TensorFlow with Java?</div><br/></div></div><div id="37685196" class="c"><input type="checkbox" id="c-37685196" checked=""/><div class="controls bullet"><span class="by">Areibman</span><span>|</span><a href="#37686976">prev</a><span>|</span><a href="#37686666">next</a><span>|</span><label class="collapse" for="c-37685196">[-]</label><label class="expand" for="c-37685196">[3 more]</label></div><br/><div class="children"><div class="content">Maybe I&#x27;m missing something here, isn&#x27;t this largely achieved by ONNX already?<p>[0] <a href="https:&#x2F;&#x2F;onnx.ai" rel="nofollow noreferrer">https:&#x2F;&#x2F;onnx.ai</a></div><br/><div id="37685408" class="c"><input type="checkbox" id="c-37685408" checked=""/><div class="controls bullet"><span class="by">vpanyam</span><span>|</span><a href="#37685196">parent</a><span>|</span><a href="#37686666">next</a><span>|</span><label class="collapse" for="c-37685408">[-]</label><label class="expand" for="c-37685408">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a good question! There&#x27;s an FAQ entry on the homepage that touches on this, but let me know if I can improve it:<p>&gt; ONNX <i>converts</i> models while Carton <i>wraps</i> them. Carton uses the underlying framework (e.g. PyTorch) to actually execute a model under the hood. This is important because it makes it easy to use custom ops, TensorRT, etc without changes. For some sophisticated models, &quot;conversion&quot; steps (e.g. to ONNX) can be problematic and require additional validation. By removing these conversion steps, Carton enables faster experimentation, deployment, and iteration.<p>&gt; With that said, we plan to support ONNX models within Carton. This lets you use ONNX if you choose and it enables some interesting use cases (like running models in-browser with WASM).<p>More broadly, Carton can compose with other interesting technologies in ways ONNX isn&#x27;t able to because ONNX is an inference engine while Carton is an abstraction layer.</div><br/><div id="37686878" class="c"><input type="checkbox" id="c-37686878" checked=""/><div class="controls bullet"><span class="by">Dayshine</span><span>|</span><a href="#37685196">root</a><span>|</span><a href="#37685408">parent</a><span>|</span><a href="#37686666">next</a><span>|</span><label class="collapse" for="c-37686878">[-]</label><label class="expand" for="c-37686878">[1 more]</label></div><br/><div class="children"><div class="content">ONNX runtime doesn&#x27;t convert models, it runs them, and it has bindings in several languages. And most importantly it&#x27;s tiny compared to the whole python package mess you get with TF or pytorch.<p>If carton took a TF&#x2F;pytorch model and just dealt with the conversion into a real runtime, somehow using custom ops for the bits that don&#x27;t convert, that would be amazing though.</div><br/></div></div></div></div></div></div><div id="37686666" class="c"><input type="checkbox" id="c-37686666" checked=""/><div class="controls bullet"><span class="by">astronautas</span><span>|</span><a href="#37685196">prev</a><span>|</span><a href="#37684767">next</a><span>|</span><label class="collapse" for="c-37686666">[-]</label><label class="expand" for="c-37686666">[3 more]</label></div><br/><div class="children"><div class="content">Make it for Go, and I am sold. Running ML models in Go services is still an unsolved problem.</div><br/><div id="37686807" class="c"><input type="checkbox" id="c-37686807" checked=""/><div class="controls bullet"><span class="by">r0l1</span><span>|</span><a href="#37686666">parent</a><span>|</span><a href="#37684767">next</a><span>|</span><label class="collapse" for="c-37686807">[-]</label><label class="expand" for="c-37686807">[2 more]</label></div><br/><div class="children"><div class="content">We have a similar high performance AI stack written in Go capable to load many different models from different frameworks. This is work of several years. Just saw your comment and thought about our company internal talk to release everything under an open source license. Thanks for reminding me :)
What are your use-cases?</div><br/><div id="37686859" class="c"><input type="checkbox" id="c-37686859" checked=""/><div class="controls bullet"><span class="by">astronautas</span><span>|</span><a href="#37686666">root</a><span>|</span><a href="#37686807">parent</a><span>|</span><a href="#37684767">next</a><span>|</span><label class="collapse" for="c-37686859">[-]</label><label class="expand" for="c-37686859">[1 more]</label></div><br/><div class="children"><div class="content">Wow, make it open source quickly!!! :hype:. It&#x27;s a classic Python REST API for model serving. But we have very low latency constraints. As such, rewriting in more high performant backend languages e.g. Go or Rust would substantially reduce resource usage (by reducing horizontal scaling need). Pre-baked model serving frameworks e.g. Nvidia&#x27;s Triton aren&#x27;t an option, since we have to query a feature store, and do some input feature tracking in between. Go seemed like an efficient, developer friendly choice, but there aren&#x27;t any well maintained model inference libraries in  Go up to this day...</div><br/></div></div></div></div></div></div><div id="37684767" class="c"><input type="checkbox" id="c-37684767" checked=""/><div class="controls bullet"><span class="by">jcrash</span><span>|</span><a href="#37686666">prev</a><span>|</span><a href="#37686689">next</a><span>|</span><label class="collapse" for="c-37684767">[-]</label><label class="expand" for="c-37684767">[5 more]</label></div><br/><div class="children"><div class="content">So this means if I want to use a ML model I made in python, but don&#x27;t want to code the rest of the application in python I can do that?</div><br/><div id="37684890" class="c"><input type="checkbox" id="c-37684890" checked=""/><div class="controls bullet"><span class="by">vpanyam</span><span>|</span><a href="#37684767">parent</a><span>|</span><a href="#37686689">next</a><span>|</span><label class="collapse" for="c-37684890">[-]</label><label class="expand" for="c-37684890">[4 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s a use case Carton supports.<p>For exmaple, if your model contains arbitrary Python code, you&#x27;d pack it using [1] and then you could load it from another language using [2]. In this case, Carton transparently spins up an isolated Python interpreter under the hood to run your model (even if the rest of your application is in another language).<p>You can take it one step further if you&#x27;re using certain DL frameworks. For example, you can create a TorchScript model in Python [3] and then use it from any programming language Carton supports <i>without requiring python at runtime</i> (i.e. your model runs completely in native code).<p>[1] <a href="https:&#x2F;&#x2F;carton.run&#x2F;docs&#x2F;packing&#x2F;python" rel="nofollow noreferrer">https:&#x2F;&#x2F;carton.run&#x2F;docs&#x2F;packing&#x2F;python</a><p>[2] <a href="https:&#x2F;&#x2F;carton.run&#x2F;docs&#x2F;loading" rel="nofollow noreferrer">https:&#x2F;&#x2F;carton.run&#x2F;docs&#x2F;loading</a><p>[3] <a href="https:&#x2F;&#x2F;carton.run&#x2F;docs&#x2F;packing&#x2F;torchscript" rel="nofollow noreferrer">https:&#x2F;&#x2F;carton.run&#x2F;docs&#x2F;packing&#x2F;torchscript</a></div><br/><div id="37685147" class="c"><input type="checkbox" id="c-37685147" checked=""/><div class="controls bullet"><span class="by">ZeroCool2u</span><span>|</span><a href="#37684767">root</a><span>|</span><a href="#37684890">parent</a><span>|</span><a href="#37685128">next</a><span>|</span><label class="collapse" for="c-37685147">[-]</label><label class="expand" for="c-37685147">[2 more]</label></div><br/><div class="children"><div class="content">Seems almost too good to be true, but I really hope it&#x27;s not. How does it handle things like CUDA dependencies? Can it somehow make those portable too? Or is GPU acceleration not quite there yet?</div><br/><div id="37685207" class="c"><input type="checkbox" id="c-37685207" checked=""/><div class="controls bullet"><span class="by">vpanyam</span><span>|</span><a href="#37684767">root</a><span>|</span><a href="#37685147">parent</a><span>|</span><a href="#37685128">next</a><span>|</span><label class="collapse" for="c-37685207">[-]</label><label class="expand" for="c-37685207">[1 more]</label></div><br/><div class="children"><div class="content">Thanks :)<p>It uses the NVIDIA drivers on your system, but it should be possible to make the rest of CUDA somewhat portable. I have a few thoughts on how to do this, but haven&#x27;t gotten around to it yet.<p>The current GPU enabled torch runners use a version of libtorch that&#x27;s statically linked against the CUDA runtime libraries. So in theory, they just depend on your GPU drivers and not your CUDA installation. I haven&#x27;t yet tested on a machine that has just the GPU drivers installed (i.e without CUDA), but if it doesn&#x27;t already work, it should be very possible to make it work.</div><br/></div></div></div></div><div id="37685128" class="c"><input type="checkbox" id="c-37685128" checked=""/><div class="controls bullet"><span class="by">jcrash</span><span>|</span><a href="#37684767">root</a><span>|</span><a href="#37684890">parent</a><span>|</span><a href="#37685147">prev</a><span>|</span><a href="#37686689">next</a><span>|</span><label class="collapse" for="c-37685128">[-]</label><label class="expand" for="c-37685128">[1 more]</label></div><br/><div class="children"><div class="content">That’s awesome! Thanks for making this</div><br/></div></div></div></div></div></div><div id="37686689" class="c"><input type="checkbox" id="c-37686689" checked=""/><div class="controls bullet"><span class="by">astronautas</span><span>|</span><a href="#37684767">prev</a><span>|</span><a href="#37685620">next</a><span>|</span><label class="collapse" for="c-37686689">[-]</label><label class="expand" for="c-37686689">[1 more]</label></div><br/><div class="children"><div class="content">Is this the same as Nvidia&#x27;s Triton?</div><br/></div></div><div id="37685620" class="c"><input type="checkbox" id="c-37685620" checked=""/><div class="controls bullet"><span class="by">Nischalj10</span><span>|</span><a href="#37686689">prev</a><span>|</span><a href="#37686129">next</a><span>|</span><label class="collapse" for="c-37685620">[-]</label><label class="expand" for="c-37685620">[2 more]</label></div><br/><div class="children"><div class="content">is this ancillary to what [these guys](<a href="https:&#x2F;&#x2F;github.com&#x2F;unifyai&#x2F;ivy">https:&#x2F;&#x2F;github.com&#x2F;unifyai&#x2F;ivy</a>) are trying to do?</div><br/><div id="37686127" class="c"><input type="checkbox" id="c-37686127" checked=""/><div class="controls bullet"><span class="by">carbocation</span><span>|</span><a href="#37685620">parent</a><span>|</span><a href="#37686129">next</a><span>|</span><label class="collapse" for="c-37686127">[-]</label><label class="expand" for="c-37686127">[1 more]</label></div><br/><div class="children"><div class="content">That seems different to me. OP is talking about using ML models outside of python (well, in python, too). That link seems to be talking about using ML models across frameworks (pytorch, tensorflow, jax, etc) in python.</div><br/></div></div></div></div><div id="37686129" class="c"><input type="checkbox" id="c-37686129" checked=""/><div class="controls bullet"><span class="by">carbocation</span><span>|</span><a href="#37685620">prev</a><span>|</span><a href="#37685195">next</a><span>|</span><label class="collapse" for="c-37686129">[-]</label><label class="expand" for="c-37686129">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to see this for golang (even without GPU support).</div><br/></div></div><div id="37685195" class="c"><input type="checkbox" id="c-37685195" checked=""/><div class="controls bullet"><span class="by">conradev</span><span>|</span><a href="#37686129">prev</a><span>|</span><a href="#37685406">next</a><span>|</span><label class="collapse" for="c-37685195">[-]</label><label class="expand" for="c-37685195">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Carton wraps your model with some metadata and puts it in a zip file<p>Why a zip file?</div><br/><div id="37685365" class="c"><input type="checkbox" id="c-37685365" checked=""/><div class="controls bullet"><span class="by">vpanyam</span><span>|</span><a href="#37685195">parent</a><span>|</span><a href="#37685277">next</a><span>|</span><label class="collapse" for="c-37685365">[-]</label><label class="expand" for="c-37685365">[1 more]</label></div><br/><div class="children"><div class="content">In addition to the benefits mentioned in the sibling comment, zip files let you seek to and access individual files in the archive without extracting all files (vs tar files for example).<p>This lets us do things like fetch model metadata [1] for a large remote model, by only fetching a few tiny byte ranges instead of the whole model archive.<p>It also means you can include sample data (images, etc) with your model and they&#x27;re only fetched when necessary (for example with stable diffusion: <a href="https:&#x2F;&#x2F;carton.pub&#x2F;stabilityai&#x2F;sdxl" rel="nofollow noreferrer">https:&#x2F;&#x2F;carton.pub&#x2F;stabilityai&#x2F;sdxl</a>)<p>[1] <a href="https:&#x2F;&#x2F;carton.run&#x2F;docs&#x2F;metadata" rel="nofollow noreferrer">https:&#x2F;&#x2F;carton.run&#x2F;docs&#x2F;metadata</a></div><br/></div></div><div id="37685277" class="c"><input type="checkbox" id="c-37685277" checked=""/><div class="controls bullet"><span class="by">shoo</span><span>|</span><a href="#37685195">parent</a><span>|</span><a href="#37685365">prev</a><span>|</span><a href="#37685406">next</a><span>|</span><label class="collapse" for="c-37685277">[-]</label><label class="expand" for="c-37685277">[2 more]</label></div><br/><div class="children"><div class="content">zip-file-as-a-container-format seems pragmatic: it&#x27;s a way to bundle multiple files into one file (easier to manage than scattering multiple files), it avoids introducing a new proprietary format, it can optionally be compressed, support for reading and writing the container format is already widespread.<p>To give two examples of prior art, it worked for Quake 3 data files (.pk3) &amp; geospatial data files (.kmz)<p>Maybe it&#x27;s not the best choice but it doesn&#x27;t seem like a bad one.</div><br/><div id="37686319" class="c"><input type="checkbox" id="c-37686319" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#37685195">root</a><span>|</span><a href="#37685277">parent</a><span>|</span><a href="#37685406">next</a><span>|</span><label class="collapse" for="c-37686319">[-]</label><label class="expand" for="c-37686319">[1 more]</label></div><br/><div class="children"><div class="content">Also docx as well I believe.</div><br/></div></div></div></div></div></div><div id="37685406" class="c"><input type="checkbox" id="c-37685406" checked=""/><div class="controls bullet"><span class="by">civilitty</span><span>|</span><a href="#37685195">prev</a><span>|</span><a href="#37685543">next</a><span>|</span><label class="collapse" for="c-37685406">[-]</label><label class="expand" for="c-37685406">[2 more]</label></div><br/><div class="children"><div class="content">Any plans to support Windows? That would make Carton the ultimate library to embed LLMs into desktop applications</div><br/><div id="37685478" class="c"><input type="checkbox" id="c-37685478" checked=""/><div class="controls bullet"><span class="by">vpanyam</span><span>|</span><a href="#37685406">parent</a><span>|</span><a href="#37685543">next</a><span>|</span><label class="collapse" for="c-37685478">[-]</label><label class="expand" for="c-37685478">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m definitely open to it if there&#x27;s interest (or if someone wants to help), but I don&#x27;t have plans to implement Windows support myself at the moment.<p>The currently supported platforms [1] were mostly driven by environments I&#x27;ve seen at various tech companies.<p>I do have active plans to support inference from WASM&#x2F;WebGPU so maybe that could be a good entrypoint to Windows support.<p>--<p>[1] Currently, the supported platforms are:<p>* `x86_64` Linux and macOS<p>* `aarch64` Linux (e.g. Linux on AWS Graviton)<p>* `aarch64` macOS (e.g. M1 and M2 Apple Silicon chips)<p>* WebAssembly (metadata access only for now, but WebGPU runners are coming soon)</div><br/></div></div></div></div><div id="37685543" class="c"><input type="checkbox" id="c-37685543" checked=""/><div class="controls bullet"><span class="by">otteromkram</span><span>|</span><a href="#37685406">prev</a><span>|</span><label class="collapse" for="c-37685543">[-]</label><label class="expand" for="c-37685543">[4 more]</label></div><br/><div class="children"><div class="content">&quot;...run any machine learning model from any programming language*.&quot;<p>*As long as that language is python or rust.<p>What I think is that this is nothing more than a resume-bolstering effort that doesn&#x27;t really need to exist and probably won&#x27;t once OP lands a role at whatever FAANG company they&#x27;re trying to impress.</div><br/><div id="37685839" class="c"><input type="checkbox" id="c-37685839" checked=""/><div class="controls bullet"><span class="by">smokel</span><span>|</span><a href="#37685543">parent</a><span>|</span><label class="collapse" for="c-37685839">[-]</label><label class="expand" for="c-37685839">[3 more]</label></div><br/><div class="children"><div class="content">Replying to this to explain the downvotes.<p>We all think this.  My initial thought was that this is probably a startup selling PyTorch-as-a-Service, and I did not bother to read the article.  It turns out that I was wrong, and this might even be useful -- if not for the implementation, then perhaps for the idea.<p>However, it turns out to make Hacker News a nicer space if we follow these guidelines:<p><i>&gt; Please don&#x27;t post shallow dismissals, especially of other people&#x27;s work. A good critical comment teaches us something.</i></div><br/><div id="37686272" class="c"><input type="checkbox" id="c-37686272" checked=""/><div class="controls bullet"><span class="by">otabdeveloper4</span><span>|</span><a href="#37685543">root</a><span>|</span><a href="#37685839">parent</a><span>|</span><label class="collapse" for="c-37686272">[-]</label><label class="expand" for="c-37686272">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not a shallow dismissal.<p>The selling point of this thing is cross-language interoperability, and while they advertise it, they don&#x27;t deliver.<p>Sorry, but if your &quot;any language&quot; is &quot;Python or Javascript&quot; your project hasn&#x27;t even reached the proof of concept stage, it&#x27;s just a vague idea at this point.<p>Supporting C++ and C will be 90% of the work and the real challenge.</div><br/><div id="37686835" class="c"><input type="checkbox" id="c-37686835" checked=""/><div class="controls bullet"><span class="by">smokel</span><span>|</span><a href="#37685543">root</a><span>|</span><a href="#37686272">parent</a><span>|</span><label class="collapse" for="c-37686835">[-]</label><label class="expand" for="c-37686835">[1 more]</label></div><br/><div class="children"><div class="content">The shallow dismissal that I was referring to is:<p>&gt; What I think is that this is nothing more than a resume-bolstering effort that doesn&#x27;t really need to exist and probably won&#x27;t once OP lands a role at whatever FAANG company they&#x27;re trying to impress.<p>The title of the post might be click-bait, but there is an obvious asterisk on the homepage of Carton, and even at a quick glance it is obvious that only very few languages are supported.  The claim is so obviously false, that I don&#x27;t mind.  I would not expect support for INTERCAL or Awk.<p>Yes, it does not deliver, but that does not warrant the personal attack.  The author of Carton actually already had internships at Google and Facebook, and currently works at Uber.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>