<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701248458725" as="style"/><link rel="stylesheet" href="styles.css?v=1701248458725"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://nihalsid.github.io/mesh-gpt/">MeshGPT: Generating triangle meshes with decoder-only transformers</a> <span class="domain">(<a href="https://nihalsid.github.io">nihalsid.github.io</a>)</span></div><div class="subtext"><span>jackcook</span> | <span>136 comments</span></div><br/><div><div id="38457126" class="c"><input type="checkbox" id="c-38457126" checked=""/><div class="controls bullet"><span class="by">Mizza</span><span>|</span><a href="#38449170">next</a><span>|</span><label class="collapse" for="c-38457126">[-]</label><label class="expand" for="c-38457126">[1 more]</label></div><br/><div class="children"><div class="content">Great work. But I don&#x27;t get from the demo how it knows what object to autocomplete the mesh with - if you give it four posts as an input, how does it know to autocomplete as a table and not a dog?<p>So maybe the next step is something like CLIP, but for meshes?</div><br/></div></div><div id="38449170" class="c"><input type="checkbox" id="c-38449170" checked=""/><div class="controls bullet"><span class="by">shaileshm</span><span>|</span><a href="#38457126">prev</a><span>|</span><a href="#38450435">next</a><span>|</span><label class="collapse" for="c-38449170">[-]</label><label class="expand" for="c-38449170">[11 more]</label></div><br/><div class="children"><div class="content">This is what a truly revolutionary idea looks like. There are so many details in the paper. Also, we know that transformers can scale. Pretty sure this idea will be used by a lot of companies to train the general 3D asset creation pipeline. This is just too great.<p>&quot;We first learn a vocabulary of latent quantized embeddings, using graph convolutions, which inform these embeddings of the local mesh geometry and topology. These embeddings are sequenced and decoded into triangles by a decoder, ensuring that they can effectively reconstruct the mesh.&quot;<p>This idea is simply beautiful and so obvious in hindsight.<p>&quot;To define the tokens to generate, we consider a practical approach to represent a mesh M for autoregressive generation: a sequence of triangles.&quot;<p>More from paper. Just so cool!</div><br/><div id="38455375" class="c"><input type="checkbox" id="c-38455375" checked=""/><div class="controls bullet"><span class="by">legel</span><span>|</span><a href="#38449170">parent</a><span>|</span><a href="#38450380">next</a><span>|</span><label class="collapse" for="c-38455375">[-]</label><label class="expand" for="c-38455375">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s cool, it&#x27;s also par for the field of 3D reconstruction today.  I wouldn&#x27;t describe this paper as particularly innovative or exceptional.<p>What do I think is really compelling in this field (given that it&#x27;s my profession)?<p>This has me star-struck lately -- 3D meshing from a single image, a very large 3D reconstruction model trained on millions of all kinds of 3D models... <a href="https:&#x2F;&#x2F;yiconghong.me&#x2F;LRM&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;yiconghong.me&#x2F;LRM&#x2F;</a></div><br/></div></div><div id="38450380" class="c"><input type="checkbox" id="c-38450380" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#38449170">parent</a><span>|</span><a href="#38455375">prev</a><span>|</span><a href="#38450192">next</a><span>|</span><label class="collapse" for="c-38450380">[-]</label><label class="expand" for="c-38450380">[1 more]</label></div><br/><div class="children"><div class="content">Another thing to note here is this looks to be around seven total days of training on at most 4 A100s. Not all really cutting edge work requires a data center sized cluster.</div><br/></div></div><div id="38450192" class="c"><input type="checkbox" id="c-38450192" checked=""/><div class="controls bullet"><span class="by">tomcam</span><span>|</span><a href="#38449170">parent</a><span>|</span><a href="#38450380">prev</a><span>|</span><a href="#38454215">next</a><span>|</span><label class="collapse" for="c-38450192">[-]</label><label class="expand" for="c-38450192">[5 more]</label></div><br/><div class="children"><div class="content">Can someone explain quantized embeddings to me?</div><br/><div id="38450317" class="c"><input type="checkbox" id="c-38450317" checked=""/><div class="controls bullet"><span class="by">_hark</span><span>|</span><a href="#38449170">root</a><span>|</span><a href="#38450192">parent</a><span>|</span><a href="#38454215">next</a><span>|</span><label class="collapse" for="c-38450317">[-]</label><label class="expand" for="c-38450317">[4 more]</label></div><br/><div class="children"><div class="content">NNs are typically continuous&#x2F;differentiable so you can do gradient-based learning on them. We often want to use some of the structure the NN has learned to represent data efficiently. E.g., we might take a pre-trained GPT-type model, and put a passage of text through it, and instead of getting the next-token prediction probability (which GPT was trained on), we just get a snapshot of some of the activations at some intermediate layer of the network. The idea is that these activations will encode semantically useful information about the input text. Then we might e.g. store a bunch of these activations and use them to do semantic search&#x2F;lookup to find similar passages of text, or whatever.<p>Quantized embeddings are just that, but you introduce some discrete structure into the NN, such that the representations there are not continuous. A typical way to do this these days is to learn a codebook VQ-VAE style. Basically, we take some intermediate continuous representation learned in the normal way, and replace it in the forward pass with the nearest &quot;quantized&quot; code from our codebook. It biases the learning since we can&#x27;t differentiate through it, and we just pretend like we didn&#x27;t take the quantization step, but it seems to work well. There&#x27;s a lot more that can be said about why one might want to do this, the value of discrete vs continuous representations, efficiency, modularity, etc...</div><br/><div id="38450683" class="c"><input type="checkbox" id="c-38450683" checked=""/><div class="controls bullet"><span class="by">enjeyw</span><span>|</span><a href="#38449170">root</a><span>|</span><a href="#38450317">parent</a><span>|</span><a href="#38454215">next</a><span>|</span><label class="collapse" for="c-38450683">[-]</label><label class="expand" for="c-38450683">[3 more]</label></div><br/><div class="children"><div class="content">If you’re willing, I’d love your insight on the “why one might want to do this”.<p>Conceptually I understand embedding quantization, and I have some hint of why it works for things like WAV2VEC - human phonemes are (somewhat) finite so forcing the representation to be finite makes sense - but I feel like there’s a level of detail that I’m missing regarding whats really going on and when quantisation helps&#x2F;harms that I haven’t been able to gleam from papers.</div><br/><div id="38453654" class="c"><input type="checkbox" id="c-38453654" checked=""/><div class="controls bullet"><span class="by">topwalktown</span><span>|</span><a href="#38449170">root</a><span>|</span><a href="#38450683">parent</a><span>|</span><a href="#38451106">next</a><span>|</span><label class="collapse" for="c-38453654">[-]</label><label class="expand" for="c-38453654">[1 more]</label></div><br/><div class="children"><div class="content">Quantization also works as regularization; it stops the neural network from being able to use arbitrarily complex internal rules.<p>But really it&#x27;s only really useful if you absolutely need to have a discrete embedding space for some sort of downstream usage. VQVAEs can be difficult to get to converge, they have problems stemming from the approximation of the gradient like codebook collapse</div><br/></div></div><div id="38451106" class="c"><input type="checkbox" id="c-38451106" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38449170">root</a><span>|</span><a href="#38450683">parent</a><span>|</span><a href="#38453654">prev</a><span>|</span><a href="#38454215">next</a><span>|</span><label class="collapse" for="c-38451106">[-]</label><label class="expand" for="c-38451106">[1 more]</label></div><br/><div class="children"><div class="content">Maybe it helps to point out that the first version of Dall-E (of &#x27;baby daikon radish in a tutu walking a dog&#x27; fame) used the same trick, but they quantized the image patches.</div><br/></div></div></div></div></div></div></div></div><div id="38454215" class="c"><input type="checkbox" id="c-38454215" checked=""/><div class="controls bullet"><span class="by">donpark</span><span>|</span><a href="#38449170">parent</a><span>|</span><a href="#38450192">prev</a><span>|</span><a href="#38453078">next</a><span>|</span><label class="collapse" for="c-38454215">[-]</label><label class="expand" for="c-38454215">[1 more]</label></div><br/><div class="children"><div class="content">How does this differ from similar techniques previously applied to DNA and RNA sequences?</div><br/></div></div><div id="38453078" class="c"><input type="checkbox" id="c-38453078" checked=""/><div class="controls bullet"><span class="by">ganzuul</span><span>|</span><a href="#38449170">parent</a><span>|</span><a href="#38454215">prev</a><span>|</span><a href="#38450435">next</a><span>|</span><label class="collapse" for="c-38453078">[-]</label><label class="expand" for="c-38453078">[2 more]</label></div><br/><div class="children"><div class="content">...Is graph convolution matrix factorization by another name?</div><br/><div id="38456082" class="c"><input type="checkbox" id="c-38456082" checked=""/><div class="controls bullet"><span class="by">fjkdlsjflkds</span><span>|</span><a href="#38449170">root</a><span>|</span><a href="#38453078">parent</a><span>|</span><a href="#38450435">next</a><span>|</span><label class="collapse" for="c-38456082">[-]</label><label class="expand" for="c-38456082">[1 more]</label></div><br/><div class="children"><div class="content">No... a graph convolution is just a convolution (over a graph, like all convolutions).<p>The difference from a &quot;normal&quot; convolution is that you can consider arbitrary connectivity of the graph (rather than the usual connectivity induced by a regular Euclidian grid), but the underlying idea is the same: to calculate the result of the operation at any single place (i.e., node), you need to perform a linear operation over that place (i.e., node) and its neighbourhood (i.e., connected nodes), the same way that (e.g.) in a convolutional neural network, you calculate the value of a pixel by considering its value and that of its neighbours, when performing a convolution.</div><br/></div></div></div></div></div></div><div id="38450435" class="c"><input type="checkbox" id="c-38450435" checked=""/><div class="controls bullet"><span class="by">LarsDu88</span><span>|</span><a href="#38449170">prev</a><span>|</span><a href="#38457122">next</a><span>|</span><label class="collapse" for="c-38450435">[-]</label><label class="expand" for="c-38450435">[36 more]</label></div><br/><div class="children"><div class="content">As a machine learning engineer who dabbles with Blender and hobby gamedev, this is pretty impressive, but not quite to the point of being useful in any practical manner (as far as the limited furniture examples are concerned.<p>A competent modeler can make these types of meshes in under 5 minutes, and you still need to seed the generation with polys.<p>I imagine the next step will be to have the seed generation controlled by an LLM, and to start adding image models to the autoregressive parts of the architecture.<p>Then we might see truly mobile game-ready assets!</div><br/><div id="38451941" class="c"><input type="checkbox" id="c-38451941" checked=""/><div class="controls bullet"><span class="by">empath-nirvana</span><span>|</span><a href="#38450435">parent</a><span>|</span><a href="#38453726">next</a><span>|</span><label class="collapse" for="c-38451941">[-]</label><label class="expand" for="c-38451941">[20 more]</label></div><br/><div class="children"><div class="content">&gt; A competent modeler can make these types of meshes in under 5 minutes.<p>I don&#x27;t think this general complaint about AI workflows is that useful.  Most people are not a competent &lt;insert job here&gt;.  Most people don&#x27;t know a competent &lt;insert job here&gt; or can&#x27;t afford to hire one.   Even something that takes longer than a professional do at worse quality for many things is better than _nothing_ which is the realistic alternative for most people who would use something like this.</div><br/><div id="38452509" class="c"><input type="checkbox" id="c-38452509" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38451941">parent</a><span>|</span><a href="#38452264">next</a><span>|</span><label class="collapse" for="c-38452509">[-]</label><label class="expand" for="c-38452509">[4 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t think this general complaint about AI workflows is that useful<p>Maybe not to you, but it&#x27;s useful if you&#x27;re in these fields professionally, though. The difference between a neat hobbyist toolkit and a professional toolkit has gigantic financial implications, even if the difference is minimal to &quot;most people.&quot;</div><br/><div id="38452824" class="c"><input type="checkbox" id="c-38452824" checked=""/><div class="controls bullet"><span class="by">ajuc</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38452509">parent</a><span>|</span><a href="#38452264">next</a><span>|</span><label class="collapse" for="c-38452824">[-]</label><label class="expand" for="c-38452824">[3 more]</label></div><br/><div class="children"><div class="content">Linux vs Unix. Wikipedia vs Britannica. GCC vs Intel compiler.  Good enough free hobby toy beats expansive professional tools given enough hobbysts.</div><br/><div id="38453839" class="c"><input type="checkbox" id="c-38453839" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38452824">parent</a><span>|</span><a href="#38453280">next</a><span>|</span><label class="collapse" for="c-38453839">[-]</label><label class="expand" for="c-38453839">[1 more]</label></div><br/><div class="children"><div class="content">First, we&#x27;re talking about the state of the technology and what it can produce, not the fundamental worthiness of the approach. Right now, it&#x27;s not up to the task. In the earliest phases of those technologies, they also weren&#x27;t good enough for for professional use cases.<p>Secondly, the number of hobbyists only matters if you&#x27;re talking about hobbyists that develop the technology-- not hobbyists that <i>use</i> the technology. Until those tools are good enough, you could have every hobbyist on the planet collectively attempting to make a Disney-quality character model with tools that aren&#x27;t capable of doing so and it wouldn&#x27;t get much closer to the requisite result than a single hobbyist doing the same.</div><br/></div></div><div id="38453280" class="c"><input type="checkbox" id="c-38453280" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38452824">parent</a><span>|</span><a href="#38453839">prev</a><span>|</span><a href="#38452264">next</a><span>|</span><label class="collapse" for="c-38453280">[-]</label><label class="expand" for="c-38453280">[1 more]</label></div><br/><div class="children"><div class="content">1. they don&#x27;t beat them outight. It&#x27;s simply more accessible.<p>2. those &quot;hobbyists&quot; in all examples are in fact professionals now. That&#x27;s why they could scale up.</div><br/></div></div></div></div></div></div><div id="38452264" class="c"><input type="checkbox" id="c-38452264" checked=""/><div class="controls bullet"><span class="by">cannonpalms</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38451941">parent</a><span>|</span><a href="#38452509">prev</a><span>|</span><a href="#38453260">next</a><span>|</span><label class="collapse" for="c-38452264">[-]</label><label class="expand" for="c-38452264">[6 more]</label></div><br/><div class="children"><div class="content">Is the target market really &quot;most people,&quot; though? I would say not. The general goal of all of this economic investment is to improve the productivity of labor--that means first and foremost that things need to be useful and practical for those trained to make determinations such as &quot;useful&quot; and &quot;practical.&quot;</div><br/><div id="38452388" class="c"><input type="checkbox" id="c-38452388" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38452264">parent</a><span>|</span><a href="#38453260">next</a><span>|</span><label class="collapse" for="c-38452388">[-]</label><label class="expand" for="c-38452388">[5 more]</label></div><br/><div class="children"><div class="content">Millions of people generating millions of images (some of them even useful!) using Dall-E and Stable Diffusion would say otherwise. A skilled digital artist could create most of these images in an hour or two, I’d guess… but ‘most people’ certainly could not, and it turns out that these people really want to.</div><br/><div id="38454069" class="c"><input type="checkbox" id="c-38454069" checked=""/><div class="controls bullet"><span class="by">reubenmorais</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38452388">parent</a><span>|</span><a href="#38453260">next</a><span>|</span><label class="collapse" for="c-38454069">[-]</label><label class="expand" for="c-38454069">[4 more]</label></div><br/><div class="children"><div class="content">Are those millions of people actually creating something of lasting value, or just playing around with a new toy?</div><br/><div id="38455517" class="c"><input type="checkbox" id="c-38455517" checked=""/><div class="controls bullet"><span class="by">willy_k</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38454069">parent</a><span>|</span><a href="#38454183">next</a><span>|</span><label class="collapse" for="c-38455517">[-]</label><label class="expand" for="c-38455517">[1 more]</label></div><br/><div class="children"><div class="content">A lot, but how many people will start with the latter but find themselves (capable of) doing the former?</div><br/></div></div><div id="38454183" class="c"><input type="checkbox" id="c-38454183" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38454069">parent</a><span>|</span><a href="#38455517">prev</a><span>|</span><a href="#38453260">next</a><span>|</span><label class="collapse" for="c-38454183">[-]</label><label class="expand" for="c-38454183">[2 more]</label></div><br/><div class="children"><div class="content">Is there a problem with the latter?</div><br/></div></div></div></div></div></div></div></div><div id="38453260" class="c"><input type="checkbox" id="c-38453260" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38451941">parent</a><span>|</span><a href="#38452264">prev</a><span>|</span><a href="#38453726">next</a><span>|</span><label class="collapse" for="c-38453260">[-]</label><label class="expand" for="c-38453260">[9 more]</label></div><br/><div class="children"><div class="content">&gt;Most people don&#x27;t know a competent &lt;insert job here&gt; or can&#x27;t afford to hire one<p>May be relevant in the long run, but it&#x27;ll probably be 5+ years before this is commercially available. And it won&#x27;t be cheap either, so out of the range of said people who can&#x27;t hire a competent &lt;insert job here&gt;<p>That&#x27;s why a lot of this stuff is pitched to companies with competent people instead of offered as a general product to download.</div><br/><div id="38453931" class="c"><input type="checkbox" id="c-38453931" checked=""/><div class="controls bullet"><span class="by">jamilton</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38453260">parent</a><span>|</span><a href="#38453717">next</a><span>|</span><label class="collapse" for="c-38453931">[-]</label><label class="expand" for="c-38453931">[3 more]</label></div><br/><div class="children"><div class="content">Is there a reason to expect it&#x27;d be significantly more expensive than current-gen LLM? Reading the &quot;Implementation Details&quot; section, this was done with GPT2-medium, and assuming running it is about as intensive as the original GPT2, it can be run (slowly) on a regular computer, without a graphics card. Seems reasonable to assume future versions will be around GPT-3&#x2F;4&#x27;s price.</div><br/><div id="38454227" class="c"><input type="checkbox" id="c-38454227" checked=""/><div class="controls bullet"><span class="by">22c</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38453931">parent</a><span>|</span><a href="#38455856">next</a><span>|</span><label class="collapse" for="c-38454227">[-]</label><label class="expand" for="c-38454227">[1 more]</label></div><br/><div class="children"><div class="content">Agreed! There&#x27;s also no way this is 5 years away from being viable.<p>I just checked the timestamps on my Dall-E Mini generated images. They&#x27;re dated June 2022<p>This is what people were doing on commodity hardware back then:<p><a href="https:&#x2F;&#x2F;cdn-uploads.huggingface.co&#x2F;production&#x2F;uploads&#x2F;1655372600588-62a38c9086968c944929cedb.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;cdn-uploads.huggingface.co&#x2F;production&#x2F;uploads&#x2F;165537...</a><p>This is what people are doing on commodity hardware now:<p><a href="https:&#x2F;&#x2F;civitai.com&#x2F;images&#x2F;3853761" rel="nofollow noreferrer">https:&#x2F;&#x2F;civitai.com&#x2F;images&#x2F;3853761</a><p>I&#x27;m not even going to try to predict what we&#x27;ll be able to do in 2 years time; even when accounting for the current GenAI hype&#x2F;bubble!</div><br/></div></div><div id="38455856" class="c"><input type="checkbox" id="c-38455856" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38453931">parent</a><span>|</span><a href="#38454227">prev</a><span>|</span><a href="#38453717">next</a><span>|</span><label class="collapse" for="c-38455856">[-]</label><label class="expand" for="c-38455856">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps not, but it begs the question of if GPT is affordable for a dev to begin with. I don&#x27;t know how they would monetize this sort of work so it&#x27;s hard to say. But making game models probably requires a lot more processing power than generating text or static images.</div><br/></div></div></div></div><div id="38453717" class="c"><input type="checkbox" id="c-38453717" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38453260">parent</a><span>|</span><a href="#38453931">prev</a><span>|</span><a href="#38453726">next</a><span>|</span><label class="collapse" for="c-38453717">[-]</label><label class="expand" for="c-38453717">[5 more]</label></div><br/><div class="children"><div class="content">&gt; but it&#x27;ll probably be 5+ years before this is commercially available<p>I think you should look at the progress of image, text, and video generation over the past 12 months and re-asses your timeline prediction.</div><br/><div id="38456225" class="c"><input type="checkbox" id="c-38456225" checked=""/><div class="controls bullet"><span class="by">LarsDu88</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38453717">parent</a><span>|</span><a href="#38453901">next</a><span>|</span><label class="collapse" for="c-38456225">[-]</label><label class="expand" for="c-38456225">[1 more]</label></div><br/><div class="children"><div class="content">I have no doubt that 3d modeling will become commodified in the same way that art has with the dawn of AI art generation over the past year.<p>I honestly think we&#x27;ll get there within 18 months.<p>My skepticism is whether the technique described here will be the basis of what people will be using in ~2 years to replace their low level static 3d asset generation.<p>There are several techniques out there, leveraging different sources of data right now. This looks like a step in the right direction, but who knows.</div><br/></div></div><div id="38453901" class="c"><input type="checkbox" id="c-38453901" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38453717">parent</a><span>|</span><a href="#38456225">prev</a><span>|</span><a href="#38453726">next</a><span>|</span><label class="collapse" for="c-38453901">[-]</label><label class="expand" for="c-38453901">[3 more]</label></div><br/><div class="children"><div class="content">Availability =&#x2F;= viability. I&#x27;m sure as we speak some large studios are already leveraging this work or are close to leveraging it.<p>But this stuff trickles down to the public very slowly. Because indies aren&#x27;t a good audience to sell what is likely an expensive tech that is focused on mid-large scale production.</div><br/><div id="38455701" class="c"><input type="checkbox" id="c-38455701" checked=""/><div class="controls bullet"><span class="by">willy_k</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38453901">parent</a><span>|</span><a href="#38453726">next</a><span>|</span><label class="collapse" for="c-38455701">[-]</label><label class="expand" for="c-38455701">[2 more]</label></div><br/><div class="children"><div class="content">Yes but no, none of that really describes current development.</div><br/><div id="38455843" class="c"><input type="checkbox" id="c-38455843" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38455701">parent</a><span>|</span><a href="#38453726">next</a><span>|</span><label class="collapse" for="c-38455843">[-]</label><label class="expand" for="c-38455843">[1 more]</label></div><br/><div class="children"><div class="content">perhaps, but I was responding to<p>&gt;Most people are not a competent &lt;insert job here&gt;. Most people don&#x27;t know a competent &lt;insert job here&gt; or <i>can&#x27;t afford to hire one.</i><p>emphasis mine. Affordability doesn&#x27;t have much to do with capabilities, but it is a strong factor to consider for an indie dev. Devs in fields (games, VFX) that don&#x27;t traditionally pay well to begin with.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38453726" class="c"><input type="checkbox" id="c-38453726" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#38450435">parent</a><span>|</span><a href="#38451941">prev</a><span>|</span><a href="#38454621">next</a><span>|</span><label class="collapse" for="c-38453726">[-]</label><label class="expand" for="c-38453726">[3 more]</label></div><br/><div class="children"><div class="content">&gt; A competent modeler can make these types of meshes in under 5 minutes<p>Sweet. Can you point me to these modelers who work on-demand and bill for their time in 5 minute increments? I’d love to be able to just pay $1-2 per model and get custom &lt;whatever&gt; dropped into my game when I need it.</div><br/><div id="38454949" class="c"><input type="checkbox" id="c-38454949" checked=""/><div class="controls bullet"><span class="by">dvngnt_</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38453726">parent</a><span>|</span><a href="#38454621">next</a><span>|</span><label class="collapse" for="c-38454949">[-]</label><label class="expand" for="c-38454949">[2 more]</label></div><br/><div class="children"><div class="content">they said competent though no cheap</div><br/><div id="38456016" class="c"><input type="checkbox" id="c-38456016" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38454949">parent</a><span>|</span><a href="#38454621">next</a><span>|</span><label class="collapse" for="c-38456016">[-]</label><label class="expand" for="c-38456016">[1 more]</label></div><br/><div class="children"><div class="content">but the AI will be cheap. $1 per model would be the OpenAI wrapper’s price. Let alone the wholesale price.</div><br/></div></div></div></div></div></div><div id="38454621" class="c"><input type="checkbox" id="c-38454621" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#38450435">parent</a><span>|</span><a href="#38453726">prev</a><span>|</span><a href="#38454411">next</a><span>|</span><label class="collapse" for="c-38454621">[-]</label><label class="expand" for="c-38454621">[2 more]</label></div><br/><div class="children"><div class="content">&gt; A competent modeler can make these types of meshes in under 5 minutes<p>It&#x27;s not about competent modellers, any more than SD is for expert artists.<p>It&#x27;s about giving tools to the non-experts. And also about freeing up those competent modellers to work on more interesting things than the 10,000 chair variants needed for future AAA games. They can work on making unique and interesting characters instead, or novel futuristic models that aren&#x27;t in the training set and require real imagination combined with their expertise.</div><br/><div id="38454839" class="c"><input type="checkbox" id="c-38454839" checked=""/><div class="controls bullet"><span class="by">adventured</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38454621">parent</a><span>|</span><a href="#38454411">next</a><span>|</span><label class="collapse" for="c-38454839">[-]</label><label class="expand" for="c-38454839">[1 more]</label></div><br/><div class="children"><div class="content">Like most of the generative AI space, it&#x27;ll eliminate something like the bottom half of modelers, and turn them into lower paid prompt wizards. The top half will become combo modelers &#x2F; prompt wizards, using both skillsets as needed.<p>Prompt wizard hands work off to the finisher&#x2F;detailer.<p>It&#x27;ll boost productivity and lead to higher quality finished content. And you&#x27;ll be able to spot when a production - whether video game or movie - lacks a finisher (relying just on generation by prompt). The objects won&#x27;t have that higher tier level of realism or originality.</div><br/></div></div></div></div><div id="38454411" class="c"><input type="checkbox" id="c-38454411" checked=""/><div class="controls bullet"><span class="by">Art9681</span><span>|</span><a href="#38450435">parent</a><span>|</span><a href="#38454621">prev</a><span>|</span><a href="#38452253">next</a><span>|</span><label class="collapse" for="c-38454411">[-]</label><label class="expand" for="c-38454411">[2 more]</label></div><br/><div class="children"><div class="content">Just like a competent developer can use LLMs to bootstrap workflows, a competent model will soon have tools like this as part of their normal workflow. A casual user would be able to do things that they otherwise wouldnt have been able to. But an expert in the ML model&#x27;s knowledge domain can really make it shine.<p>I really believe that the more experienced you are in a particular use case, the more use you can get out of an ML model.<p>Unfortunately, it&#x27;s those very same people that seem to be the most resistant to adopting this without really giving it the practice required to get somewhere useful with it. I suppose part of the problem is we expect it to be a magic wand. But it&#x27;s really just the new PhotoShop, or Blender, or Microsoft Word, or PowerPoint ...<p>Most people open those apps, click mindleslly for a bit, promptly leave never to return. And so it is with &quot;AI&quot;.</div><br/><div id="38455215" class="c"><input type="checkbox" id="c-38455215" checked=""/><div class="controls bullet"><span class="by">eropple</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38454411">parent</a><span>|</span><a href="#38452253">next</a><span>|</span><label class="collapse" for="c-38455215">[-]</label><label class="expand" for="c-38455215">[1 more]</label></div><br/><div class="children"><div class="content">I think eventually it may settle into what you describe. I don&#x27;t think it&#x27;s guaranteed, and I fear that there will be a pretty huge amount of damage done before that by the hype freaks whose real interest isn&#x27;t in making artists more productive, but in rendering them (and other members of the actually-can-do-a-thing creative class) <i>unemployed</i>.<p>The pipeline problem also exists: if you need to still have the skillsets you build up through learning the craft, you still need to have avenues to learn the craft--and the people who already have will get old eventually.<p>There&#x27;s a golden path towards a better future for everybody out of this, but a lot of swamps to drive into instead without careful forethought.</div><br/></div></div></div></div><div id="38452253" class="c"><input type="checkbox" id="c-38452253" checked=""/><div class="controls bullet"><span class="by">Kaijo</span><span>|</span><a href="#38450435">parent</a><span>|</span><a href="#38454411">prev</a><span>|</span><a href="#38453670">next</a><span>|</span><label class="collapse" for="c-38452253">[-]</label><label class="expand" for="c-38452253">[2 more]</label></div><br/><div class="children"><div class="content">The mesh topology here would see these rejected as assets for in basically any professional context. A competent modeler could make much higher quality models, more suited to texturing and deformation, in under five minutes. A speed modeler could make the same in under a minute. And a procedural system in something like Blender geonodes can already spit out an endless variety of such models. But the pace of progress is staggering.</div><br/><div id="38453303" class="c"><input type="checkbox" id="c-38453303" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38452253">parent</a><span>|</span><a href="#38453670">next</a><span>|</span><label class="collapse" for="c-38453303">[-]</label><label class="expand" for="c-38453303">[1 more]</label></div><br/><div class="children"><div class="content">I see it as a black triangle[0] more than anything else. Sounds like a really good first step that will scale to stuff that would take even a good modeler days to produce. That&#x27;s where the real value will start to be seen.<p>[0]: <a href="https:&#x2F;&#x2F;rampantgames.com&#x2F;blog&#x2F;?p=7745" rel="nofollow noreferrer">https:&#x2F;&#x2F;rampantgames.com&#x2F;blog&#x2F;?p=7745</a></div><br/></div></div></div></div><div id="38454577" class="c"><input type="checkbox" id="c-38454577" checked=""/><div class="controls bullet"><span class="by">WhitneyLand</span><span>|</span><a href="#38450435">parent</a><span>|</span><a href="#38453670">prev</a><span>|</span><a href="#38453326">next</a><span>|</span><label class="collapse" for="c-38454577">[-]</label><label class="expand" for="c-38454577">[1 more]</label></div><br/><div class="children"><div class="content">As I understand it their claim is more about efficiency and quality.<p>Being able to model something - is way different from being able to do it in the least amount of triangles and&#x2F;or without losing details.</div><br/></div></div><div id="38453326" class="c"><input type="checkbox" id="c-38453326" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#38450435">parent</a><span>|</span><a href="#38454577">prev</a><span>|</span><a href="#38450621">next</a><span>|</span><label class="collapse" for="c-38453326">[-]</label><label class="expand" for="c-38453326">[1 more]</label></div><br/><div class="children"><div class="content">A simple next step would be to simply scale the model, make it bigger, and train it on millions of images in the wild.</div><br/></div></div><div id="38450621" class="c"><input type="checkbox" id="c-38450621" checked=""/><div class="controls bullet"><span class="by">th0ma5</span><span>|</span><a href="#38450435">parent</a><span>|</span><a href="#38453326">prev</a><span>|</span><a href="#38457122">next</a><span>|</span><label class="collapse" for="c-38450621">[-]</label><label class="expand" for="c-38450621">[3 more]</label></div><br/><div class="children"><div class="content">This is a very underrated comment... As with any tech demo, I&#x27;d they don&#x27;t show it, it can&#x27;t do it. It is very very easy to imagine a generalization of these things to other purposes, which, if it could do it, would be a different presentation.</div><br/><div id="38452056" class="c"><input type="checkbox" id="c-38452056" checked=""/><div class="controls bullet"><span class="by">rawrawrawrr</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38450621">parent</a><span>|</span><a href="#38457122">next</a><span>|</span><label class="collapse" for="c-38452056">[-]</label><label class="expand" for="c-38452056">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s research, not meant for commercialization. The main point is in the process, not necessarily the output.</div><br/><div id="38456618" class="c"><input type="checkbox" id="c-38456618" checked=""/><div class="controls bullet"><span class="by">th0ma5</span><span>|</span><a href="#38450435">root</a><span>|</span><a href="#38452056">parent</a><span>|</span><a href="#38457122">next</a><span>|</span><label class="collapse" for="c-38456618">[-]</label><label class="expand" for="c-38456618">[1 more]</label></div><br/><div class="children"><div class="content">What? If the research doesn&#x27;t show it, it can&#x27;t do it, is my point, or else they would&#x27;ve put it in their research.</div><br/></div></div></div></div></div></div></div></div><div id="38457122" class="c"><input type="checkbox" id="c-38457122" checked=""/><div class="controls bullet"><span class="by">wolfgang805</span><span>|</span><a href="#38450435">prev</a><span>|</span><a href="#38449242">next</a><span>|</span><label class="collapse" for="c-38457122">[-]</label><label class="expand" for="c-38457122">[1 more]</label></div><br/><div class="children"><div class="content">It would be nice to be see work and be part of a field that did work that humans could not do, instead of creating work that just replaces what humans already know how to do.</div><br/></div></div><div id="38449242" class="c"><input type="checkbox" id="c-38449242" checked=""/><div class="controls bullet"><span class="by">kranke155</span><span>|</span><a href="#38457122">prev</a><span>|</span><a href="#38449196">next</a><span>|</span><label class="collapse" for="c-38449242">[-]</label><label class="expand" for="c-38449242">[19 more]</label></div><br/><div class="children"><div class="content">My chosen profession (3D &#x2F; filmmaking) feels like being in some kind of combat trench at the moment. Both fascinating and scary</div><br/><div id="38450219" class="c"><input type="checkbox" id="c-38450219" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#38449242">parent</a><span>|</span><a href="#38451286">next</a><span>|</span><label class="collapse" for="c-38450219">[-]</label><label class="expand" for="c-38450219">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps one way to look at this could be auto-scaffolding. The typical modelling and CAD tools might include this feature to get you up and running faster.<p>Another massive benefit is composability. If the model can generate a cup and a table, it also knows how to generate a cup on a table.<p>Think of all the complex gears and machine parts this could generate in the blink of an eye, while being relevant to the project - rotated and positioned exact where you want it. Very similar to how GitHub Copilot works.</div><br/></div></div><div id="38451286" class="c"><input type="checkbox" id="c-38451286" checked=""/><div class="controls bullet"><span class="by">worldsayshi</span><span>|</span><a href="#38449242">parent</a><span>|</span><a href="#38450219">prev</a><span>|</span><a href="#38452957">next</a><span>|</span><label class="collapse" for="c-38451286">[-]</label><label class="expand" for="c-38451286">[7 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see that LLM&#x27;s have come that much further in 3D animation than programming in this regard: It can spit out bits and pieces that looks okay in isolation but a human need to solve the puzzle. And often solving the puzzle means rewriting&#x2F;redoing most of the pieces.<p>We&#x27;re safe for now but we should learn how to leverage the new tech.</div><br/><div id="38452104" class="c"><input type="checkbox" id="c-38452104" checked=""/><div class="controls bullet"><span class="by">andkenneth</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38451286">parent</a><span>|</span><a href="#38455003">next</a><span>|</span><label class="collapse" for="c-38452104">[-]</label><label class="expand" for="c-38452104">[3 more]</label></div><br/><div class="children"><div class="content">This is the &quot;your job won&#x27;t be taken away by AI, it will be taken away by someone who knows how to leverage AI better than you&quot;</div><br/><div id="38453328" class="c"><input type="checkbox" id="c-38453328" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38452104">parent</a><span>|</span><a href="#38453207">next</a><span>|</span><label class="collapse" for="c-38453328">[-]</label><label class="expand" for="c-38453328">[1 more]</label></div><br/><div class="children"><div class="content">Probably, but isn&#x27;t that how most if the technical fields go? Software in particular moves blazing fast and you need to adapt to the market quickly to be marketable.</div><br/></div></div><div id="38453207" class="c"><input type="checkbox" id="c-38453207" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38452104">parent</a><span>|</span><a href="#38453328">prev</a><span>|</span><a href="#38455003">next</a><span>|</span><label class="collapse" for="c-38453207">[-]</label><label class="expand" for="c-38453207">[1 more]</label></div><br/><div class="children"><div class="content">Don’t worry , the price of goods will be exponentially cheaper, so you won’t need a job &#x2F;s</div><br/></div></div></div></div><div id="38455003" class="c"><input type="checkbox" id="c-38455003" checked=""/><div class="controls bullet"><span class="by">kranke155</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38451286">parent</a><span>|</span><a href="#38452104">prev</a><span>|</span><a href="#38454879">next</a><span>|</span><label class="collapse" for="c-38455003">[-]</label><label class="expand" for="c-38455003">[1 more]</label></div><br/><div class="children"><div class="content">The reason AI generative tools are faster to become useful in artistic areas is that in the arts you can take “errors” as style.<p>Doesn’t apply too much to mesh generation but was certainly the case in image gen. Mistakes that wouldn’t fly for a human artist (hands) were just accepted as part of AIgen.<p>So these areas are much less strict about precision than coding. Making these tools much more capable are replacing artists in some tasks than CoPilot is for coders atm.</div><br/></div></div><div id="38454879" class="c"><input type="checkbox" id="c-38454879" checked=""/><div class="controls bullet"><span class="by">adventured</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38451286">parent</a><span>|</span><a href="#38455003">prev</a><span>|</span><a href="#38452957">next</a><span>|</span><label class="collapse" for="c-38454879">[-]</label><label class="expand" for="c-38454879">[2 more]</label></div><br/><div class="children"><div class="content">&gt; We&#x27;re safe for now<p>Some are safe for several years (3-5), that&#x27;s it. During that time it&#x27;s going to wreck the bottom tiers of employees and progressively move up the ladder.<p>GPT and the equivalent will be extraordinary at programming five years out. It will end up being a trivially easy task for AI in hindsight (15-20 years out), not a difficult task.<p>Have you seen how far things like MidJourney, Dalle, Stable Diffusion have come in just a year or two? It&#x27;s moving extremely fast. They&#x27;ve gone from generating stick figures to realistic photographs in two years.</div><br/><div id="38456394" class="c"><input type="checkbox" id="c-38456394" checked=""/><div class="controls bullet"><span class="by">user432678</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38454879">parent</a><span>|</span><a href="#38452957">next</a><span>|</span><label class="collapse" for="c-38456394">[-]</label><label class="expand" for="c-38456394">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I’d better buy more wedding cakes in advance.<p><a href="https:&#x2F;&#x2F;xkcd.com&#x2F;605" rel="nofollow noreferrer">https:&#x2F;&#x2F;xkcd.com&#x2F;605</a></div><br/></div></div></div></div></div></div><div id="38452957" class="c"><input type="checkbox" id="c-38452957" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#38449242">parent</a><span>|</span><a href="#38451286">prev</a><span>|</span><a href="#38449535">next</a><span>|</span><label class="collapse" for="c-38452957">[-]</label><label class="expand" for="c-38452957">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know, 3D CGI has already been moving at the breakneck speed for the last three decades without any AI. Today&#x27;s tools are qualitatively different (sculpting, simulation, auto-rigging etc etc etc).</div><br/><div id="38454965" class="c"><input type="checkbox" id="c-38454965" checked=""/><div class="controls bullet"><span class="by">kranke155</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38452957">parent</a><span>|</span><a href="#38449535">next</a><span>|</span><label class="collapse" for="c-38454965">[-]</label><label class="expand" for="c-38454965">[2 more]</label></div><br/><div class="children"><div class="content">3D CGI has gotten faster, but I haven’t seen any qualitative jump for quite some time.<p>IMO the last time a major tech advance was visible was Davy Jones on the Pirates films. That was a fully photorealistic animated character that was plausible as a hero character in a major feature. That was a breakthrough. After that a lot of refinement and speeding up.<p>This is different. I have some positivity about it, but it’s getting hard to keep track of everything that’s going on tbh. Every week it’s a new application and every few months it’s some quantum leap.<p>Like others said, Midjourney and DallE are essentially photorealistic.<p>It seems to me that the next step is generative AI creating better and better assets.<p>And then of course you have video generation which is happening as well…</div><br/><div id="38455322" class="c"><input type="checkbox" id="c-38455322" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38454965">parent</a><span>|</span><a href="#38449535">next</a><span>|</span><label class="collapse" for="c-38455322">[-]</label><label class="expand" for="c-38455322">[1 more]</label></div><br/><div class="children"><div class="content">Both DE3 and MJ are essentially toys for single random pictures, unusable in a professional setting. DALL-E in particular has really bad issues with quality, and while it follows the prompt well it also rewrites it so it&#x27;s barely controllable. Midjourney is RLHF&#x27;d to death.<p>What you want for asset creation is not photorealism, but style and concept transfer, multimodal controllability (text alone is terrible at expressing artistic intent), and tooling. And tooling isn&#x27;t something that is developed quickly (although there were several rapid breakthroughs in the past, for example ZBrush).<p>Most of the fancy demos you hear about sound good on paper, but don&#x27;t really go anywhere. Academia is throwing shit at the wall to see what sticks, this is its purpose, especially when practice is running ahead of theory. It&#x27;s similar to building airplanes before figuring out aerodynamics (which happened long ago): watching a heavier-than-air thing fly is amazing, until you realize it&#x27;s not very practical in the current form, or might even kill its brave inventor who tried to fly it.<p>If you look at the field closely, most of the progress in visual generative tooling happens in the open source community; people are trying to figure out what works in real use and what doesn&#x27;t. Little is being done in big houses, at least publicly and for now, as they&#x27;re more interested in a DC-3 than a Caproni Ca.60. The change is really incremental and gradual, similarly to the current mature state of 3D. Paradigms are different but they are both highly technical and depend on academic progress. Once it matures, it&#x27;s going to become another skill-demanding field.</div><br/></div></div></div></div></div></div><div id="38449535" class="c"><input type="checkbox" id="c-38449535" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#38449242">parent</a><span>|</span><a href="#38452957">prev</a><span>|</span><a href="#38449845">next</a><span>|</span><label class="collapse" for="c-38449535">[-]</label><label class="expand" for="c-38449535">[5 more]</label></div><br/><div class="children"><div class="content">What do you ascertain the use case of this in your field? Does it seem high quality? (I have no context)</div><br/><div id="38450250" class="c"><input type="checkbox" id="c-38450250" checked=""/><div class="controls bullet"><span class="by">zavertnik</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38449535">parent</a><span>|</span><a href="#38452844">next</a><span>|</span><label class="collapse" for="c-38450250">[-]</label><label class="expand" for="c-38450250">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not a professional in VFX, but I work in television and do a lot of VFX&#x2F;3D work on the side. The quality isn&#x27;t amazing, but it looks like this could be the start of a Midjourney-tier VFX&#x2F;3D LLM, which would be awesome. For me, this would help bridge the gap between having to use&#x2F;find premade assets and building what I want.<p>For context, building from scratch in a 3D pipeline requires you to wear a lot of different hats (modeling, materials, lighting, framing, animating, ect). It costs a lot of time to get to not only learn these hats but also use them together. The individual complexity of those skill sets makes it difficult to experiment and play around, which is how people learn with software.<p>The shortcut is using premade assets or addons. For instance, being able to use the Source game assets in Source Filmmaker combined with SFM using a familiar game engine makes it easy to build an intuition with the workflow. This makes Source Filmmaker accessible and its why theres so much content out there made with it. So if you have gaps in your skillset or need to save time, you&#x27;ll buy&#x2F;use premade assets. This comes at a cost of control, but that&#x27;s always been the tradeoff between building what you want and building with what you have.<p>Just like GPT and DALL-E built a bridge between building what you want and building with what you have, a high fidelity GPT for the 3D pipeline would make that world so much more accessible and would bring the kind of attention NLE video editing got in the post-Youtube world. If I could describe in text and&#x2F;or generate an image of a scene I want and have a GPT create the objects, model them, generate textures, and place them in the scene, I could suddenly just open blender, describe a scene, and just experimenting with shooting in it, as if I was playing in a sandbox FPS game.<p>I&#x27;m not sure if MeshGPT is the ChatGPT of the 3D pipeline, but I do think this is kind of content generation is the conduit for the DALL-E of video that so many people are terrified and&#x2F;or excited for.</div><br/><div id="38451840" class="c"><input type="checkbox" id="c-38451840" checked=""/><div class="controls bullet"><span class="by">gavinray</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38450250">parent</a><span>|</span><a href="#38452844">next</a><span>|</span><label class="collapse" for="c-38451840">[-]</label><label class="expand" for="c-38451840">[2 more]</label></div><br/><div class="children"><div class="content">On an unrelated note, could I ask your opinion?<p>My wife is passionate about film&#x2F;TV production and VFX.<p>She&#x27;s currently in school for this but is concerned about the difficulty of landing a job afterwards.<p>Do you have any recommendations on breaking into the industry without work experience?</div><br/><div id="38454920" class="c"><input type="checkbox" id="c-38454920" checked=""/><div class="controls bullet"><span class="by">kranke155</span><span>|</span><a href="#38449242">root</a><span>|</span><a href="#38451840">parent</a><span>|</span><a href="#38452844">next</a><span>|</span><label class="collapse" for="c-38454920">[-]</label><label class="expand" for="c-38454920">[1 more]</label></div><br/><div class="children"><div class="content">As a producer? Huh. That’s such a great question.<p>I think producer roles are a little bit less ultra competitive &#x2F; scarce as they are actually jobs jobs where you have to use excel and planning and budgeting.<p>Being a producer means being on the phone all the time, negotiating, haggling, finding solutions where they don’t seem to exist.<p>Be it in TV, advertising or somewhere in the media space, the common rule is that producers are mostly actually terrible at their jobs, that’s my experience in London. So if she’s really good and really dedicated and learns the job of everyone on set, I’d say she has a shot.<p>The real secret to being good in filmmaking is learning everyone else’s job. Toyota Production System says if you want to run a production line you have to know how it works.<p>If she wants to do VFX production she could start doing her own test scenes, learning basics in nuke and Blender, even understanding the role of Houdini and how that works.<p>If she does that - any company will be lucky to have her.</div><br/></div></div></div></div></div></div></div></div><div id="38449845" class="c"><input type="checkbox" id="c-38449845" checked=""/><div class="controls bullet"><span class="by">bsenftner</span><span>|</span><a href="#38449242">parent</a><span>|</span><a href="#38449535">prev</a><span>|</span><a href="#38455272">next</a><span>|</span><label class="collapse" for="c-38449845">[-]</label><label class="expand" for="c-38449845">[1 more]</label></div><br/><div class="children"><div class="content">So you&#x27;re probably familiar with the role of a Bidding Producer; imagine the difficulty they are facing: on one side they have filmmakers saying they just read so and so is now created by AI, while that is news to the bidding producer and their VFX&#x2F;animation studio clients scrambling as everything they do is new again.</div><br/></div></div></div></div><div id="38449196" class="c"><input type="checkbox" id="c-38449196" checked=""/><div class="controls bullet"><span class="by">sram1337</span><span>|</span><a href="#38449242">prev</a><span>|</span><a href="#38449347">next</a><span>|</span><label class="collapse" for="c-38449196">[-]</label><label class="expand" for="c-38449196">[12 more]</label></div><br/><div class="children"><div class="content">What is the input? Is it converting a text query like &quot;chair&quot; to a mesh?<p>edit: Seems like mesh completion is the main input-output method, not just a neat feature.</div><br/><div id="38449405" class="c"><input type="checkbox" id="c-38449405" checked=""/><div class="controls bullet"><span class="by">anentropic</span><span>|</span><a href="#38449196">parent</a><span>|</span><a href="#38449369">next</a><span>|</span><label class="collapse" for="c-38449405">[-]</label><label class="expand" for="c-38449405">[1 more]</label></div><br/><div class="children"><div class="content">Yeah it&#x27;s hard to tell.<p>It looks like the input is itself a 3D mesh? So the model is doing &quot;shape completion&quot; (e.g. they show generating a chair from just some legs)... or possibly generating &quot;variations&quot; when the input shape is more complete?<p>But I guess it&#x27;s a starting point... maybe you could use another model that does worse quality text-to-mesh as the input and get something more crisp and coherent from this one.</div><br/></div></div><div id="38449369" class="c"><input type="checkbox" id="c-38449369" checked=""/><div class="controls bullet"><span class="by">all2</span><span>|</span><a href="#38449196">parent</a><span>|</span><a href="#38449405">prev</a><span>|</span><a href="#38449276">next</a><span>|</span><label class="collapse" for="c-38449369">[-]</label><label class="expand" for="c-38449369">[5 more]</label></div><br/><div class="children"><div class="content">You prompt this LLM using 3D meshes for it to complete, in the same manner you use language to prompt language specific LLMs.</div><br/><div id="38449467" class="c"><input type="checkbox" id="c-38449467" checked=""/><div class="controls bullet"><span class="by">owenpalmer</span><span>|</span><a href="#38449196">root</a><span>|</span><a href="#38449369">parent</a><span>|</span><a href="#38449276">next</a><span>|</span><label class="collapse" for="c-38449467">[-]</label><label class="expand" for="c-38449467">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what it seems like. Although this is not an LLM.<p>&gt; Inspired by recent advances in powerful large language models, we adopt a sequence-based approach to autoregressively generate triangle meshes as sequences of triangles.<p>It&#x27;s only inspired by LLMs</div><br/><div id="38450262" class="c"><input type="checkbox" id="c-38450262" checked=""/><div class="controls bullet"><span class="by">adw</span><span>|</span><a href="#38449196">root</a><span>|</span><a href="#38449467">parent</a><span>|</span><a href="#38451750">next</a><span>|</span><label class="collapse" for="c-38450262">[-]</label><label class="expand" for="c-38450262">[1 more]</label></div><br/><div class="children"><div class="content">This is sort of a distinction without a difference. It&#x27;s an autoregressive sequence model; the distinction is how you&#x27;re encoding data into (and out of) a sequence of tokens.<p>LLMs are autoregressive sequence models where the &quot;role&quot; of the graph convolutional encoder here is filled by a BPE tokenizer (also a learned model, just a much simpler one than the model used here). That this works implies that you can probably port this idea to other domains by designing clever codecs which map their feature space into discrete token sequences, similarly.<p>(Everything is feature engineering if you squint hard enough.)</div><br/></div></div><div id="38451750" class="c"><input type="checkbox" id="c-38451750" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38449196">root</a><span>|</span><a href="#38449467">parent</a><span>|</span><a href="#38450262">prev</a><span>|</span><a href="#38449783">next</a><span>|</span><label class="collapse" for="c-38451750">[-]</label><label class="expand" for="c-38451750">[1 more]</label></div><br/><div class="children"><div class="content">The only difference is the label, really. The underlying transformer architecture and the approach of using a codebook is identical to a large language model. The same approach was also used originally for image generation in DALL-E 1.</div><br/></div></div></div></div></div></div><div id="38449325" class="c"><input type="checkbox" id="c-38449325" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#38449196">parent</a><span>|</span><a href="#38449276">prev</a><span>|</span><a href="#38449347">next</a><span>|</span><label class="collapse" for="c-38449325">[-]</label><label class="expand" for="c-38449325">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I was wondering.  From the diagram it looks like the input is other chair meshes, which makes it somewhat less interesting.</div><br/><div id="38449544" class="c"><input type="checkbox" id="c-38449544" checked=""/><div class="controls bullet"><span class="by">treyd</span><span>|</span><a href="#38449196">root</a><span>|</span><a href="#38449325">parent</a><span>|</span><a href="#38449501">next</a><span>|</span><label class="collapse" for="c-38449544">[-]</label><label class="expand" for="c-38449544">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also examples of tables, lamps, couches, etc in the video.</div><br/></div></div><div id="38449501" class="c"><input type="checkbox" id="c-38449501" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#38449196">root</a><span>|</span><a href="#38449325">parent</a><span>|</span><a href="#38449544">prev</a><span>|</span><a href="#38449347">next</a><span>|</span><label class="collapse" for="c-38449501">[-]</label><label class="expand" for="c-38449501">[2 more]</label></div><br/><div class="children"><div class="content">Really the hardest thing with art is details and usually seperates good from bad. So if you can sketch what you want roughly without skill and have the details generated, that&#x27;s extremely useful. And image to image with the existing diffusion models is useful and popular.</div><br/><div id="38449822" class="c"><input type="checkbox" id="c-38449822" checked=""/><div class="controls bullet"><span class="by">nullptr_deref</span><span>|</span><a href="#38449196">root</a><span>|</span><a href="#38449501">parent</a><span>|</span><a href="#38449347">next</a><span>|</span><label class="collapse" for="c-38449822">[-]</label><label class="expand" for="c-38449822">[1 more]</label></div><br/><div class="children"><div class="content">I have no idea about your background when I am commenting here. But these are my two cents.<p>NO. Details are mostly like icing on top of the cake. Sure, good details make good art but it is not always the case. True and beautiful art requires form + shape. What you are saying is something visually appealing. So, the reason why diffusion models feel so bland is because they are good with details but do not have precise forms and shape. Nowadays they are getting better, however, it still remains an issue.<p>Form + shape &gt; details is something they teach in Art 101.</div><br/></div></div></div></div></div></div></div></div><div id="38449347" class="c"><input type="checkbox" id="c-38449347" checked=""/><div class="controls bullet"><span class="by">alexose</span><span>|</span><a href="#38449196">prev</a><span>|</span><a href="#38449762">next</a><span>|</span><label class="collapse" for="c-38449347">[-]</label><label class="expand" for="c-38449347">[1 more]</label></div><br/><div class="children"><div class="content">It sure feels like every remaining hard problem (i.e., the ones where we haven&#x27;t made much progress since the 90s) is in line to be solved by transformers in some fashion.  What a time to be alive.</div><br/></div></div><div id="38449762" class="c"><input type="checkbox" id="c-38449762" checked=""/><div class="controls bullet"><span class="by">mlsu</span><span>|</span><a href="#38449347">prev</a><span>|</span><a href="#38449711">next</a><span>|</span><label class="collapse" for="c-38449762">[-]</label><label class="expand" for="c-38449762">[2 more]</label></div><br/><div class="children"><div class="content">The next breakthrough will be the UX to create 3d scenes in front of a model like this, in VR. This would basically let you _generate_ a permanent, arbitrary 3D environment, for any environment for which we have training data.<p>Diffusion models could be used to generate textures.<p>Mark is right and so so early.</div><br/><div id="38452889" class="c"><input type="checkbox" id="c-38452889" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38449762">parent</a><span>|</span><a href="#38449711">next</a><span>|</span><label class="collapse" for="c-38452889">[-]</label><label class="expand" for="c-38452889">[1 more]</label></div><br/><div class="children"><div class="content">Mark?<p>edit: Oh, _that_ Mark? lol okay<p>edit edit: Maybe credit Lecun or something? Mark going all in on the metaverse was definitely not because he somehow predicted deep learning would take off. Even the people who trained the earliest models weren&#x27;t sure how well it would work.</div><br/></div></div></div></div><div id="38449711" class="c"><input type="checkbox" id="c-38449711" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#38449762">prev</a><span>|</span><a href="#38456210">next</a><span>|</span><label class="collapse" for="c-38449711">[-]</label><label class="expand" for="c-38449711">[5 more]</label></div><br/><div class="children"><div class="content">Even if this is “only” mesh autocomplete, it is still massively useful for 3D artists. There’s a disconnect right now between how characters are sculpted and how characters are animated. You’d typically need a time consuming step to retopologize your model. Transformer based retopology that takes a rough mesh and gives you clean topology would be a big time saver.<p>Another application: take the output of your gaussian splatter or diffusion model and run it through MeshGPT. Instant usable assets with clean topology from text.</div><br/><div id="38449764" class="c"><input type="checkbox" id="c-38449764" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#38449711">parent</a><span>|</span><a href="#38455556">next</a><span>|</span><label class="collapse" for="c-38449764">[-]</label><label class="expand" for="c-38449764">[1 more]</label></div><br/><div class="children"><div class="content">What you have to understand is that these methods are very sensitive to what is in distribution and out of distribution. If you just plug in user data, it will likely not work.</div><br/></div></div><div id="38455556" class="c"><input type="checkbox" id="c-38455556" checked=""/><div class="controls bullet"><span class="by">bradleyishungry</span><span>|</span><a href="#38449711">parent</a><span>|</span><a href="#38449764">prev</a><span>|</span><a href="#38453749">next</a><span>|</span><label class="collapse" for="c-38455556">[-]</label><label class="expand" for="c-38455556">[2 more]</label></div><br/><div class="children"><div class="content">sorry to tell you, but there’s no way anything will be generating clean topology for characters for a long long time.</div><br/><div id="38456384" class="c"><input type="checkbox" id="c-38456384" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#38449711">root</a><span>|</span><a href="#38455556">parent</a><span>|</span><a href="#38453749">next</a><span>|</span><label class="collapse" for="c-38456384">[-]</label><label class="expand" for="c-38456384">[1 more]</label></div><br/><div class="children"><div class="content">There’s no shortage of 3D mesh data to train on. Who to say scaling up the parameter count won’t allow for increasingly intricate topology the same way scaling language models improved reading comprehension.</div><br/></div></div></div></div><div id="38453749" class="c"><input type="checkbox" id="c-38453749" checked=""/><div class="controls bullet"><span class="by">mattigames</span><span>|</span><a href="#38449711">parent</a><span>|</span><a href="#38455556">prev</a><span>|</span><a href="#38456210">next</a><span>|</span><label class="collapse" for="c-38453749">[-]</label><label class="expand" for="c-38453749">[1 more]</label></div><br/><div class="children"><div class="content">Lol for 3D artists, this will be used 99% by people who have have never created a mesh by hand in their lifes; to replace their need to hire a 3D artist: programmers who don&#x27;t want (or can&#x27;t) pay a designer, architects who never learned nothing other than CAD, fiver &quot;jobs&quot;, et al<p>I don&#x27;t think people here realize how are we inching to automating the automation itself, and the programmers who will be able to make a living out of this will be a tiny fraction of those who can make a living out of it today.</div><br/></div></div></div></div><div id="38456210" class="c"><input type="checkbox" id="c-38456210" checked=""/><div class="controls bullet"><span class="by">BrokrnAlgorithm</span><span>|</span><a href="#38449711">prev</a><span>|</span><a href="#38449513">next</a><span>|</span><label class="collapse" for="c-38456210">[-]</label><label class="expand" for="c-38456210">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not a 3D artist, but why are we still, for lack of a better word, &quot;stuck&quot; with having &#x2F; wanting to use simple meshes? I appreciate the simplicity, but isn&#x27;t this an unnecessary limitation of mesh generation? It feels like an approach that imitates the constraints of having both limited hardware and artist resources. Shouldn&#x27;t AI models help us break these boundaries?</div><br/><div id="38456217" class="c"><input type="checkbox" id="c-38456217" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#38456210">parent</a><span>|</span><a href="#38449513">next</a><span>|</span><label class="collapse" for="c-38456217">[-]</label><label class="expand" for="c-38456217">[4 more]</label></div><br/><div class="children"><div class="content">We&#x27;re not stuck on meshes. Check out neural radiance fields as an alternative.</div><br/><div id="38456380" class="c"><input type="checkbox" id="c-38456380" checked=""/><div class="controls bullet"><span class="by">BrokrnAlgorithm</span><span>|</span><a href="#38456210">root</a><span>|</span><a href="#38456217">parent</a><span>|</span><a href="#38456279">next</a><span>|</span><label class="collapse" for="c-38456380">[-]</label><label class="expand" for="c-38456380">[1 more]</label></div><br/><div class="children"><div class="content">I was referring to being stuck with having to create simple &#x2F; low tri polygonal meshes as opposed to using complex poly meshes such as photogrammetry would provide. The paper specifically addresses clean low poly meshes as opposed to what they call complex iso surfaces created by photogrammetry and other methods</div><br/></div></div><div id="38456279" class="c"><input type="checkbox" id="c-38456279" checked=""/><div class="controls bullet"><span class="by">fireant</span><span>|</span><a href="#38456210">root</a><span>|</span><a href="#38456217">parent</a><span>|</span><a href="#38456380">prev</a><span>|</span><a href="#38449513">next</a><span>|</span><label class="collapse" for="c-38456279">[-]</label><label class="expand" for="c-38456279">[2 more]</label></div><br/><div class="children"><div class="content">My understanding is that it&#x27;s quite hard to make convex objects with radiance fields, right? For example the furniture in OP would be quite problematic.<p>We can create radiance fields with photogrammetry, but IMO we need much better algorithms for transforming these into high quality triangle meshes that are usable in lower triangle budget media like games.</div><br/><div id="38456360" class="c"><input type="checkbox" id="c-38456360" checked=""/><div class="controls bullet"><span class="by">BrokrnAlgorithm</span><span>|</span><a href="#38456210">root</a><span>|</span><a href="#38456279">parent</a><span>|</span><a href="#38449513">next</a><span>|</span><label class="collapse" for="c-38456360">[-]</label><label class="expand" for="c-38456360">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Lower triangle budget media&quot; is what I wonder if its still a valid problem. Modern game engines coupled with modern hardware can already render insane number of triangles. It feels like the problem is rather in engines not handling LOD correctly (see city skylines 2), although stuff like UE5 nanite seems to have taken the right path here.<p>I suppose though there is a case for AI models for example doing what nanite does entirely algorithmically and research like this paper may come in handy there.</div><br/></div></div></div></div></div></div></div></div><div id="38449513" class="c"><input type="checkbox" id="c-38449513" checked=""/><div class="controls bullet"><span class="by">j7ake</span><span>|</span><a href="#38456210">prev</a><span>|</span><a href="#38449972">next</a><span>|</span><label class="collapse" for="c-38449513">[-]</label><label class="expand" for="c-38449513">[1 more]</label></div><br/><div class="children"><div class="content">I love this field. Paper include a nice website, examples, and videos.<p>So much more refreshing than the dense abstract, intro, results paper style.</div><br/></div></div><div id="38449972" class="c"><input type="checkbox" id="c-38449972" checked=""/><div class="controls bullet"><span class="by">catapart</span><span>|</span><a href="#38449513">prev</a><span>|</span><a href="#38449072">next</a><span>|</span><label class="collapse" for="c-38449972">[-]</label><label class="expand" for="c-38449972">[3 more]</label></div><br/><div class="children"><div class="content">Dang, this is getting so good! Still got a ways to go, with the weird edges, but at this point, that feels like &#x27;iteration details&#x27; rather than an algorithmic or otherwise complex problem.<p>It&#x27;s really going to speed up my pipeline to not have to pipe all of my meshes into a procgen library with a million little mesh modifiers hooked up to drivers. Instead, I can just pop all of my meshes into a folder, train the network on them, and then start asking it for other stuff in that style, knowing that I won&#x27;t have to re-topo or otherwise screw with the stuff it makes, unless I&#x27;m looking for more creative influence.<p>Of course, until it&#x27;s all the way to that point, I&#x27;m still better served by the procgen; but I&#x27;m very excited by how quickly this is coming together! Hopefully by next year&#x27;s Unreal showcase, they&#x27;ll be talking about their new &quot;Asset Generator&quot; feature.</div><br/><div id="38450059" class="c"><input type="checkbox" id="c-38450059" checked=""/><div class="controls bullet"><span class="by">truckerbill</span><span>|</span><a href="#38449972">parent</a><span>|</span><a href="#38449072">next</a><span>|</span><label class="collapse" for="c-38450059">[-]</label><label class="expand" for="c-38450059">[2 more]</label></div><br/><div class="children"><div class="content">Do you have a recommended procgen lib?</div><br/><div id="38450579" class="c"><input type="checkbox" id="c-38450579" checked=""/><div class="controls bullet"><span class="by">catapart</span><span>|</span><a href="#38449972">root</a><span>|</span><a href="#38450059">parent</a><span>|</span><a href="#38449072">next</a><span>|</span><label class="collapse" for="c-38450579">[-]</label><label class="expand" for="c-38450579">[1 more]</label></div><br/><div class="children"><div class="content">Oh man, sorry, I wish! I&#x27;ve been using cobbled together bits of python plugins that handle Blender&#x27;s geometry nodes, and the geometry scripts tools in Unreal. I haven&#x27;t even ported over to their new proc-gen tools, which I suspect can be pretty useful.</div><br/></div></div></div></div></div></div><div id="38449072" class="c"><input type="checkbox" id="c-38449072" checked=""/><div class="controls bullet"><span class="by">chongli</span><span>|</span><a href="#38449972">prev</a><span>|</span><a href="#38456486">next</a><span>|</span><label class="collapse" for="c-38449072">[-]</label><label class="expand" for="c-38449072">[16 more]</label></div><br/><div class="children"><div class="content">This looks really cool! Seems like it would be an incredible boon for an indie game developer to generate a large pool of assets!</div><br/><div id="38449262" class="c"><input type="checkbox" id="c-38449262" checked=""/><div class="controls bullet"><span class="by">stuckinhell</span><span>|</span><a href="#38449072">parent</a><span>|</span><a href="#38456486">next</a><span>|</span><label class="collapse" for="c-38449262">[-]</label><label class="expand" for="c-38449262">[15 more]</label></div><br/><div class="children"><div class="content">I think indie game development is dead with these techniques.
Instead big companies will create &quot;make your own game&quot; games.<p>Indie games already seems pretty derivative these days.
I think this tech will kill them in mid-term as big companies use them.</div><br/><div id="38449479" class="c"><input type="checkbox" id="c-38449479" checked=""/><div class="controls bullet"><span class="by">chongli</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449262">parent</a><span>|</span><a href="#38450887">next</a><span>|</span><label class="collapse" for="c-38449479">[-]</label><label class="expand" for="c-38449479">[4 more]</label></div><br/><div class="children"><div class="content">“Make your own game” games will never replace regular games. They target totally different interests. People who play games (vast majority) just want to play an experience created by someone else. People who like “make your own game” games are creative types who just use that as a jumping off point to becoming a game designer.<p>It’s no different than saying “these home kitchen appliances are really gonna kill off the restaurant industry.”</div><br/><div id="38456050" class="c"><input type="checkbox" id="c-38456050" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449479">parent</a><span>|</span><a href="#38451059">next</a><span>|</span><label class="collapse" for="c-38456050">[-]</label><label class="expand" for="c-38456050">[1 more]</label></div><br/><div class="children"><div class="content">But the make your own game games are saleable games. Or at least they will be with enough AI. The Roblox minecraft
for example is super realistic.</div><br/></div></div><div id="38451059" class="c"><input type="checkbox" id="c-38451059" checked=""/><div class="controls bullet"><span class="by">stuckinhell</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449479">parent</a><span>|</span><a href="#38456050">prev</a><span>|</span><a href="#38450887">next</a><span>|</span><label class="collapse" for="c-38451059">[-]</label><label class="expand" for="c-38451059">[2 more]</label></div><br/><div class="children"><div class="content">Hmm I think it will destroy the market in a couple ways.<p>AI creating video games would drastically increase the volume of games available in the market. This surge in supply could make it harder for indie games to stand out, especially if AI-generated games are of high quality or novelty. It could also lead to even more indie saturation( the average indie makes less than 1000 dollars).<p>As the market expectations shift, I think most indie development dies unless you are already rich or basically have patronage from rich clients.</div><br/><div id="38454251" class="c"><input type="checkbox" id="c-38454251" checked=""/><div class="controls bullet"><span class="by">crq-yml</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38451059">parent</a><span>|</span><a href="#38450887">next</a><span>|</span><label class="collapse" for="c-38454251">[-]</label><label class="expand" for="c-38454251">[1 more]</label></div><br/><div class="children"><div class="content">The likes of itch.io, Roblox, and the App Store already exist, each with more games than anyone can reasonably curate.<p>The games market has been in the same place as the rest of the arts for some time now: if you want to be noticed, you have to mount a bit of a production around it, add layers of design effort, and find a marketing funnel for that particular audience. The days of just making a Pong clone passed in the 1970&#x27;s.<p>What technology has done to the arts, historically, is add either more precision or more repeatability. The relationship to production and arts as a business maps to what kinds of capital-and-labor-intensive endeavors leverage the tech.<p>Photographs didn&#x27;t end painting, they ended painting as the ideal of precisely representational art. In the classical era, just before the tech was good enough to switch, painting was a process of carefully staging a scene with actors and sketching it using a camera obscura to trace details, then transferring the result to your canvas. Afterwards, the exact scene could be generated precisely in a photo, and so a more candid, informal method became possible both through using photographs directly and using them as reference. As well, exact copies of photographs could be manufactured. What changed was that you had a repeatable way of getting a precise result, and so getting the precision or the product itself became uninteresting. But what happened next was that movies and comics were invented, and they brought us back to a place of needing production: staged scenes, large quantities of film or illustration, etc.<p>With generative AI, you are getting a clip art tool - a highly repeatable way of getting a generic result. If you want the design to be specific, you still have to stage it with a photograph, model it as a scene, or draw it yourself using illustration techniques.<p>And so the next step in the marketplace is simply in finding the approach to a production that will be differentiating with AI - the equivalent of movies to photography. This collapses not the indie space - because they never could afford productions to begin with - but existing modes of mobile gaming, because they were leveraging the old production framework. Nobody has need of microtransaction cosmetics if they can generate the look they want.</div><br/></div></div></div></div></div></div><div id="38450887" class="c"><input type="checkbox" id="c-38450887" checked=""/><div class="controls bullet"><span class="by">angra_mainyu</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449262">parent</a><span>|</span><a href="#38449479">prev</a><span>|</span><a href="#38449403">next</a><span>|</span><label class="collapse" for="c-38450887">[-]</label><label class="expand" for="c-38450887">[2 more]</label></div><br/><div class="children"><div class="content">I couldn&#x27;t disagree more. RPGMaker didn&#x27;t kill RPGs, Unity&#x2F;Godot&#x2F;Unreal didn&#x27;t kill games, Minecraft didn&#x27;t kill games, and Renpy didn&#x27;t kill VNs.<p>Far more people prefer playing games than making them.<p>We&#x27;ll probably see a new boom of indie games instead. Don&#x27;t forget, a large part of what makes the gaming experience unique is the narrative elements, gameplay, and aesthetics - none of which are easily replaceable.<p>This empowers indie studios to hit a faster pace on one of the most painful areas of indie game dev: asset generation (or at least for me as a solo dev hobbyist).</div><br/><div id="38450957" class="c"><input type="checkbox" id="c-38450957" checked=""/><div class="controls bullet"><span class="by">stuckinhell</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38450887">parent</a><span>|</span><a href="#38449403">next</a><span>|</span><label class="collapse" for="c-38450957">[-]</label><label class="expand" for="c-38450957">[1 more]</label></div><br/><div class="children"><div class="content">Sorry I guess I wasn&#x27;t clear. None of those things made games automatically.
The future is buying a game making game, and saying I want a zelda clone but funnier.<p>The ai game framework handles the full game creation pipeline.</div><br/></div></div></div></div><div id="38449403" class="c"><input type="checkbox" id="c-38449403" checked=""/><div class="controls bullet"><span class="by">owenpalmer</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449262">parent</a><span>|</span><a href="#38450887">prev</a><span>|</span><a href="#38452107">next</a><span>|</span><label class="collapse" for="c-38449403">[-]</label><label class="expand" for="c-38449403">[4 more]</label></div><br/><div class="children"><div class="content">People who use &quot;make your own game&quot; games aren&#x27;t good at making games. They might enjoy a simplified process to feel the accomplishment of seeing quick results, but I find it unlikely they&#x27;ll be competing with indie developers.</div><br/><div id="38449868" class="c"><input type="checkbox" id="c-38449868" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449403">parent</a><span>|</span><a href="#38450476">next</a><span>|</span><label class="collapse" for="c-38449868">[-]</label><label class="expand" for="c-38449868">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, and if there was going to be such a tool, people who invest more time in it would be better than those casually using it. In other words, professionals.</div><br/><div id="38453794" class="c"><input type="checkbox" id="c-38453794" checked=""/><div class="controls bullet"><span class="by">mattigames</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449868">parent</a><span>|</span><a href="#38450476">next</a><span>|</span><label class="collapse" for="c-38453794">[-]</label><label class="expand" for="c-38453794">[1 more]</label></div><br/><div class="children"><div class="content">Not really, &quot;I&quot; can make 2D pictures that look like masterpieces using stable diffusion and didn&#x27;t invest more than 6 hours playing with it, the learning curve is not that high, and people already have a hard time telling apart AI art than those from real 2D masters who have a lifetime learning it, the same thing will happen with making videogames and 3D art.(Yeah nothing of this looks exiting to me, actually it looks completely bleak)</div><br/></div></div></div></div><div id="38450476" class="c"><input type="checkbox" id="c-38450476" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449403">parent</a><span>|</span><a href="#38449868">prev</a><span>|</span><a href="#38452107">next</a><span>|</span><label class="collapse" for="c-38450476">[-]</label><label class="expand" for="c-38450476">[1 more]</label></div><br/><div class="children"><div class="content">Careful with that generalization.  Game-changing FPS mods like Counterstrike were basically &quot;make your own game&quot; projects, built with the highest-level toolkits imaginable (editors for existing commercial games.)</div><br/></div></div></div></div><div id="38452107" class="c"><input type="checkbox" id="c-38452107" checked=""/><div class="controls bullet"><span class="by">Vegenoid</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449262">parent</a><span>|</span><a href="#38449403">prev</a><span>|</span><a href="#38449580">next</a><span>|</span><label class="collapse" for="c-38452107">[-]</label><label class="expand" for="c-38452107">[1 more]</label></div><br/><div class="children"><div class="content">There are more amazing, innovative and interesting indie games being created now than ever before. There&#x27;s just also way more indie games that aren&#x27;t those things.</div><br/></div></div><div id="38449580" class="c"><input type="checkbox" id="c-38449580" checked=""/><div class="controls bullet"><span class="by">dexwiz</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449262">parent</a><span>|</span><a href="#38452107">prev</a><span>|</span><a href="#38449355">next</a><span>|</span><label class="collapse" for="c-38449580">[-]</label><label class="expand" for="c-38449580">[1 more]</label></div><br/><div class="children"><div class="content">The platform layer of the &quot;make your own game&quot; game is always too heavy and too limited to compete with a dedicated engine in the long run. Also the monetization strategy is bad for professionals.</div><br/></div></div><div id="38449355" class="c"><input type="checkbox" id="c-38449355" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449262">parent</a><span>|</span><a href="#38449580">prev</a><span>|</span><a href="#38456486">next</a><span>|</span><label class="collapse" for="c-38449355">[-]</label><label class="expand" for="c-38449355">[2 more]</label></div><br/><div class="children"><div class="content">For values of &quot;dead&quot; equal to &quot;Now people who aren&#x27;t 3D artists and can&#x27;t afford to hire them will be able to make games,&quot; maybe.<p>User name checks out.</div><br/><div id="38451264" class="c"><input type="checkbox" id="c-38451264" checked=""/><div class="controls bullet"><span class="by">stuckinhell</span><span>|</span><a href="#38449072">root</a><span>|</span><a href="#38449355">parent</a><span>|</span><a href="#38456486">next</a><span>|</span><label class="collapse" for="c-38451264">[-]</label><label class="expand" for="c-38451264">[1 more]</label></div><br/><div class="children"><div class="content">AI is already taking video game illustrators’ jobs in China
<a href="https:&#x2F;&#x2F;restofworld.org&#x2F;2023&#x2F;ai-image-china-video-game-layoffs&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;restofworld.org&#x2F;2023&#x2F;ai-image-china-video-game-layof...</a><p>It feels like a countdown until every creative in the videogame industry is automated.</div><br/></div></div></div></div></div></div></div></div><div id="38456486" class="c"><input type="checkbox" id="c-38456486" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#38449072">prev</a><span>|</span><a href="#38454669">next</a><span>|</span><label class="collapse" for="c-38456486">[-]</label><label class="expand" for="c-38456486">[1 more]</label></div><br/><div class="children"><div class="content">So maybe in a few years we can ask AI to generate a level or entire game.</div><br/></div></div><div id="38454669" class="c"><input type="checkbox" id="c-38454669" checked=""/><div class="controls bullet"><span class="by">Stevvo</span><span>|</span><a href="#38456486">prev</a><span>|</span><a href="#38454444">next</a><span>|</span><label class="collapse" for="c-38454669">[-]</label><label class="expand" for="c-38454669">[1 more]</label></div><br/><div class="children"><div class="content">Fantastic, but still useless from a professional perspective. i.e. A mesh that represents a cube as 12 triangles is a better prestation of the form than previous efforts, but  barely more usable.<p>Whilst it might not be the solution I&#x27;m waiting for, I can now see it as possible. If an AI model can handle traingles, it might handle edge loops and NURBS curves.</div><br/></div></div><div id="38454444" class="c"><input type="checkbox" id="c-38454444" checked=""/><div class="controls bullet"><span class="by">btbuildem</span><span>|</span><a href="#38454669">prev</a><span>|</span><a href="#38453879">next</a><span>|</span><label class="collapse" for="c-38454444">[-]</label><label class="expand" for="c-38454444">[1 more]</label></div><br/><div class="children"><div class="content">This is fantastic! You can broad-strokes sketch the key strokes of the shape you want, and this will generate some &quot;best&quot; matches around that.<p>What I really appreciate about this is that they took the concept (transformers) and applied it in a quite different-from-usual domain. Thinking outside of the (triangulated) box!</div><br/></div></div><div id="38453879" class="c"><input type="checkbox" id="c-38453879" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#38454444">prev</a><span>|</span><a href="#38453792">next</a><span>|</span><label class="collapse" for="c-38453879">[-]</label><label class="expand" for="c-38453879">[1 more]</label></div><br/><div class="children"><div class="content">So you train it with vector sequences that represent furnitures and it predicts the next token(triangles), so how is this different from it ChatGPT was trained with the same sequences and can output all the 3d locations and trangle size&#x2F;lengths in sequence and have a 3d program piece it together?</div><br/></div></div><div id="38453792" class="c"><input type="checkbox" id="c-38453792" checked=""/><div class="controls bullet"><span class="by">KyleLewis</span><span>|</span><a href="#38453879">prev</a><span>|</span><a href="#38449499">next</a><span>|</span><label class="collapse" for="c-38453792">[-]</label><label class="expand" for="c-38453792">[1 more]</label></div><br/><div class="children"><div class="content">Cant wait for the &quot;multimodal&quot; version that can take a written description and generate meshes</div><br/></div></div><div id="38449499" class="c"><input type="checkbox" id="c-38449499" checked=""/><div class="controls bullet"><span class="by">mclanett</span><span>|</span><a href="#38453792">prev</a><span>|</span><a href="#38449218">next</a><span>|</span><label class="collapse" for="c-38449499">[-]</label><label class="expand" for="c-38449499">[2 more]</label></div><br/><div class="children"><div class="content">This is very cool. You can start with an image, generate a mesh for it, render it, and then compare the render to the image. Fully automated training.</div><br/><div id="38452979" class="c"><input type="checkbox" id="c-38452979" checked=""/><div class="controls bullet"><span class="by">de6u99er</span><span>|</span><a href="#38449499">parent</a><span>|</span><a href="#38449218">next</a><span>|</span><label class="collapse" for="c-38452979">[-]</label><label class="expand" for="c-38452979">[1 more]</label></div><br/><div class="children"><div class="content">continous training</div><br/></div></div></div></div><div id="38449218" class="c"><input type="checkbox" id="c-38449218" checked=""/><div class="controls bullet"><span class="by">carbocation</span><span>|</span><a href="#38449499">prev</a><span>|</span><a href="#38449266">next</a><span>|</span><label class="collapse" for="c-38449218">[-]</label><label class="expand" for="c-38449218">[1 more]</label></div><br/><div class="children"><div class="content">On my phone so I’ve only read this promo page - could this approach be modified for surface reconstruction from a 3D point cloud?</div><br/></div></div><div id="38449266" class="c"><input type="checkbox" id="c-38449266" checked=""/><div class="controls bullet"><span class="by">trostaft</span><span>|</span><a href="#38449218">prev</a><span>|</span><a href="#38449850">next</a><span>|</span><label class="collapse" for="c-38449266">[-]</label><label class="expand" for="c-38449266">[1 more]</label></div><br/><div class="children"><div class="content">Seems like the bibtex on the page is broken? Or might just be an extension of mine.</div><br/></div></div><div id="38449850" class="c"><input type="checkbox" id="c-38449850" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#38449266">prev</a><span>|</span><a href="#38450488">next</a><span>|</span><label class="collapse" for="c-38449850">[-]</label><label class="expand" for="c-38449850">[1 more]</label></div><br/><div class="children"><div class="content">Is this limited to shapes that have mostly flat faces?</div><br/></div></div><div id="38450488" class="c"><input type="checkbox" id="c-38450488" checked=""/><div class="controls bullet"><span class="by">frozencell</span><span>|</span><a href="#38449850">prev</a><span>|</span><a href="#38450064">next</a><span>|</span><label class="collapse" for="c-38450488">[-]</label><label class="expand" for="c-38450488">[1 more]</label></div><br/><div class="children"><div class="content">Not reproducible with code = Not research.</div><br/></div></div><div id="38450064" class="c"><input type="checkbox" id="c-38450064" checked=""/><div class="controls bullet"><span class="by">circuit10</span><span>|</span><a href="#38450488">prev</a><span>|</span><a href="#38449092">next</a><span>|</span><label class="collapse" for="c-38450064">[-]</label><label class="expand" for="c-38450064">[1 more]</label></div><br/><div class="children"><div class="content">Can this handle more organic shapes?</div><br/></div></div><div id="38449092" class="c"><input type="checkbox" id="c-38449092" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#38450064">prev</a><span>|</span><a href="#38452996">next</a><span>|</span><label class="collapse" for="c-38449092">[-]</label><label class="expand" for="c-38449092">[1 more]</label></div><br/><div class="children"><div class="content">This is revolutionary</div><br/></div></div><div id="38452996" class="c"><input type="checkbox" id="c-38452996" checked=""/><div class="controls bullet"><span class="by">beebeepka</span><span>|</span><a href="#38449092">prev</a><span>|</span><a href="#38451906">next</a><span>|</span><label class="collapse" for="c-38452996">[-]</label><label class="expand" for="c-38452996">[1 more]</label></div><br/><div class="children"><div class="content">Games and pretty much any other experience being generated by AI is obvious to anyone paying attention at this point. But how would it work. Are current ai generated images and videos using rasterisation? Will they use rasterisation, path tracing or any other traditional rendering technique, or is will it be an entirely different thing.</div><br/></div></div><div id="38449736" class="c"><input type="checkbox" id="c-38449736" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#38449473">prev</a><span>|</span><label class="collapse" for="c-38449736">[-]</label><label class="expand" for="c-38449736">[6 more]</label></div><br/><div class="children"><div class="content">This was done years ago, with transformers. It was then dubbed Polygen.</div><br/><div id="38449789" class="c"><input type="checkbox" id="c-38449789" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#38449736">parent</a><span>|</span><a href="#38453699">next</a><span>|</span><label class="collapse" for="c-38449789">[-]</label><label class="expand" for="c-38449789">[4 more]</label></div><br/><div class="children"><div class="content">You might want to RTFA. Polygen and other prior art are mentioned. This approach is superior.</div><br/><div id="38449848" class="c"><input type="checkbox" id="c-38449848" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#38449736">root</a><span>|</span><a href="#38449789">parent</a><span>|</span><a href="#38453699">next</a><span>|</span><label class="collapse" for="c-38449848">[-]</label><label class="expand" for="c-38449848">[3 more]</label></div><br/><div class="children"><div class="content">I read the article. It has exactly the same limitations as Polygen from what I can tell.</div><br/><div id="38449975" class="c"><input type="checkbox" id="c-38449975" checked=""/><div class="controls bullet"><span class="by">dymk</span><span>|</span><a href="#38449736">root</a><span>|</span><a href="#38449848">parent</a><span>|</span><a href="#38453699">next</a><span>|</span><label class="collapse" for="c-38449975">[-]</label><label class="expand" for="c-38449975">[2 more]</label></div><br/><div class="children"><div class="content">Their comparison against PolyGen looks like it&#x27;s a big improvement. What are the limitations that this has in common with PolyGen that make it still not useful?</div><br/><div id="38451489" class="c"><input type="checkbox" id="c-38451489" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#38449736">root</a><span>|</span><a href="#38449975">parent</a><span>|</span><a href="#38453699">next</a><span>|</span><label class="collapse" for="c-38451489">[-]</label><label class="expand" for="c-38451489">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think it’s as widely applicable as they try to make it seem. I have worked specifically with PolyGen, and the main problem is “out of distribution” data. Basically anything you want to do will likely be outside the training distribution.  This surfaces as sequencing. How do you determine which triangle or vertex to place first? Why would a user do it that way? What if I want to draw a table with the legs last? Cannot be done. The model is autoregressive.</div><br/></div></div></div></div></div></div></div></div><div id="38453699" class="c"><input type="checkbox" id="c-38453699" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#38449736">parent</a><span>|</span><a href="#38449789">prev</a><span>|</span><label class="collapse" for="c-38453699">[-]</label><label class="expand" for="c-38453699">[1 more]</label></div><br/><div class="children"><div class="content">First, you use the word &quot;transformers&quot; to mean &quot;autoregressive models&quot;, they are not synonymous, second, this model beats Polygen on every metric, it&#x27;s not even close.</div><br/></div></div></div></div></div></div></div></div></div></body></html>