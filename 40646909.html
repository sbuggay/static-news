<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1718269274765" as="style"/><link rel="stylesheet" href="styles.css?v=1718269274765"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/">Terence Tao on proof checkers and AI programs</a> <span class="domain">(<a href="https://www.scientificamerican.com">www.scientificamerican.com</a>)</span></div><div class="subtext"><span>antineutrino</span> | <span>160 comments</span></div><br/><div><div id="40649931" class="c"><input type="checkbox" id="c-40649931" checked=""/><div class="controls bullet"><span class="by">drlemonpepper</span><span>|</span><a href="#40659833">next</a><span>|</span><label class="collapse" for="c-40649931">[-]</label><label class="expand" for="c-40649931">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.is&#x2F;Idouw" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;Idouw</a></div><br/></div></div><div id="40659833" class="c"><input type="checkbox" id="c-40659833" checked=""/><div class="controls bullet"><span class="by">raphlinus</span><span>|</span><a href="#40649931">prev</a><span>|</span><a href="#40662087">next</a><span>|</span><label class="collapse" for="c-40659833">[-]</label><label class="expand" for="c-40659833">[4 more]</label></div><br/><div class="children"><div class="content">The description of &quot;project manager mathematicians&quot; reminded me of &quot;A letter to my old friend Jonathan&quot; [1] and the followup [2] by Edsger Dijkstra from 1975. It was written as satire, basically criticizing the way that software was produced by showing how ridiculous it would be to produce mathematics the same way. But in some ways it was prescient. Of course, the <i>main</i> point of these documents is to critique intellectual property (particularly the absurdity of applying it to mathematical truth) but fortunately that aspect is not a significant concern of this push toward mechanization.<p>[1]: <a href="https:&#x2F;&#x2F;www.cs.utexas.edu&#x2F;users&#x2F;EWD&#x2F;transcriptions&#x2F;EWD04xx&#x2F;EWD475.html" rel="nofollow">https:&#x2F;&#x2F;www.cs.utexas.edu&#x2F;users&#x2F;EWD&#x2F;transcriptions&#x2F;EWD04xx&#x2F;E...</a><p>[2]: <a href="https:&#x2F;&#x2F;www.cs.utexas.edu&#x2F;users&#x2F;EWD&#x2F;transcriptions&#x2F;EWD05xx&#x2F;EWD539.html" rel="nofollow">https:&#x2F;&#x2F;www.cs.utexas.edu&#x2F;users&#x2F;EWD&#x2F;transcriptions&#x2F;EWD05xx&#x2F;E...</a></div><br/><div id="40666114" class="c"><input type="checkbox" id="c-40666114" checked=""/><div class="controls bullet"><span class="by">data_maan</span><span>|</span><a href="#40659833">parent</a><span>|</span><a href="#40665313">next</a><span>|</span><label class="collapse" for="c-40666114">[-]</label><label class="expand" for="c-40666114">[1 more]</label></div><br/><div class="children"><div class="content">LLMs can do math. AFAIK I know this is the SOTA if you don&#x27;t formalize it:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2301.13867" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2301.13867</a></div><br/></div></div><div id="40665313" class="c"><input type="checkbox" id="c-40665313" checked=""/><div class="controls bullet"><span class="by">pierrefermat1</span><span>|</span><a href="#40659833">parent</a><span>|</span><a href="#40666114">prev</a><span>|</span><a href="#40664697">next</a><span>|</span><label class="collapse" for="c-40665313">[-]</label><label class="expand" for="c-40665313">[1 more]</label></div><br/><div class="children"><div class="content">Except it&#x27;s a non sensical comparison? 99.999% of software is not living on the cutting edge and is just engineering implementation that can be managed.</div><br/></div></div><div id="40664697" class="c"><input type="checkbox" id="c-40664697" checked=""/><div class="controls bullet"><span class="by">coderenegade</span><span>|</span><a href="#40659833">parent</a><span>|</span><a href="#40665313">prev</a><span>|</span><a href="#40662087">next</a><span>|</span><label class="collapse" for="c-40664697">[-]</label><label class="expand" for="c-40664697">[1 more]</label></div><br/><div class="children"><div class="content">This was fantastic. Thank you for sharing it!</div><br/></div></div></div></div><div id="40662087" class="c"><input type="checkbox" id="c-40662087" checked=""/><div class="controls bullet"><span class="by">tmsh</span><span>|</span><a href="#40659833">prev</a><span>|</span><a href="#40650202">next</a><span>|</span><label class="collapse" for="c-40662087">[-]</label><label class="expand" for="c-40662087">[12 more]</label></div><br/><div class="children"><div class="content">Really insightful. What&#x27;s missing though I think is that LLMs abstract things in ways that are increasingly super-human. Tao says: &quot;It’s very easy to transform a problem into one that’s harder than into one that’s simpler. And AI has not demonstrated any ability to be any better than humans in this regard.&quot; But I think due to the way LLMs work there will be much higher-level insights that are possible. And that is the really exciting part.<p>Right now it&#x27;s a helper. A fact checker. And doer of tedious things. Soon it will be a suggester of insights. Already LLMs compress embeddings and knowledge and have insights that we don&#x27;t see.<p>Hinton gives the example of how a nuclear bomb and a compost heap are related and that most humans would miss that: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Gg-w_n9NJIE&amp;t=4613s" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Gg-w_n9NJIE&amp;t=4613s</a></div><br/><div id="40662829" class="c"><input type="checkbox" id="c-40662829" checked=""/><div class="controls bullet"><span class="by">Salgat</span><span>|</span><a href="#40662087">parent</a><span>|</span><a href="#40665823">next</a><span>|</span><label class="collapse" for="c-40662829">[-]</label><label class="expand" for="c-40662829">[8 more]</label></div><br/><div class="children"><div class="content">The biggest problem with LLMs are that they are simply regressions of writings of millions of humans on the internet. It&#x27;s very much a machine that is trained to mimic how humans write, nothing more.<p>The bigger concern is that we don&#x27;t have the training data required for it to mimic something smarter than a human (assuming that a human is given sufficient time to work on the same problem).<p>I have no doubt ML will exceed human intelligence, but the current bottleneck is figuring out how to get a model to train itself against its own output without human intervention, instead of doing a regression against the entire world&#x27;s collective writings. Remember, Ramanujan was, with no formal training and only access to a few math books, able to achieve brilliant discoveries in mathematics. In terms of training data used by ML models, that is basically nothing.</div><br/><div id="40663096" class="c"><input type="checkbox" id="c-40663096" checked=""/><div class="controls bullet"><span class="by">mofeien</span><span>|</span><a href="#40662087">root</a><span>|</span><a href="#40662829">parent</a><span>|</span><a href="#40663140">next</a><span>|</span><label class="collapse" for="c-40663096">[-]</label><label class="expand" for="c-40663096">[3 more]</label></div><br/><div class="children"><div class="content">LLMs are increasingly trained on multimodal data besides human written text, such as videos showing complex real-world phenomena that humans may also observe, but not understand, or time series data that humans may observe but be incapable of predicting. I don&#x27;t see a fundamental reason why the LLM that is trained on such data may not already become a superhuman predictor of e. g. time-series data, with the right model architecture, amount of data, and compute.<p>In a way, next-token prediction is also a time-series prediction problem, and one that is arguably more difficult than producing the time-series&#x2F;text in the first place. That is since to predict what a human will say about a topic, you don&#x27;t just need to model the topic, but also the mental processes of the human talking about it, adding another layer of abstraction.</div><br/><div id="40664969" class="c"><input type="checkbox" id="c-40664969" checked=""/><div class="controls bullet"><span class="by">beepbooptheory</span><span>|</span><a href="#40662087">root</a><span>|</span><a href="#40663096">parent</a><span>|</span><a href="#40663140">next</a><span>|</span><label class="collapse" for="c-40664969">[-]</label><label class="expand" for="c-40664969">[2 more]</label></div><br/><div class="children"><div class="content">In this case, what are we hoping to get from the LLM that, say, a simulation or domain specific analysis would not already give us? Also why does it need to be an LLM that is doing these things?<p>Wouldn&#x27;t it make more sense to delegate such a pattern finding intelligence? Why does the LLM have to do everything these days?</div><br/><div id="40666928" class="c"><input type="checkbox" id="c-40666928" checked=""/><div class="controls bullet"><span class="by">ezst</span><span>|</span><a href="#40662087">root</a><span>|</span><a href="#40664969">parent</a><span>|</span><a href="#40663140">next</a><span>|</span><label class="collapse" for="c-40666928">[-]</label><label class="expand" for="c-40666928">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Also why does it need to be an LLM that is doing these things?<p>Well, if you ask me it&#x27;s pretty clear why: we are in the hype cycle of a very specific new type of hammers, so, of course everything must be nails. Another one is that our understanding of LLMs is limited, which makes them limitless and constantly shape&#x2F;purpose-shifting for those whose job it is to sell them to us. As an Engineer, I don&#x27;t know what to do with them: they have no &quot;datasheet&quot; describing their field and range of applicability, and I feel there are many of us annoyed and tired of being constantly pulled into discussions about how to use them at all cost.<p>(Yes, I understand it was rhetorical)</div><br/></div></div></div></div></div></div><div id="40663140" class="c"><input type="checkbox" id="c-40663140" checked=""/><div class="controls bullet"><span class="by">tmsh</span><span>|</span><a href="#40662087">root</a><span>|</span><a href="#40662829">parent</a><span>|</span><a href="#40663096">prev</a><span>|</span><a href="#40663035">next</a><span>|</span><label class="collapse" for="c-40663140">[-]</label><label class="expand" for="c-40663140">[1 more]</label></div><br/><div class="children"><div class="content">Right, I think the insight that LLMs &quot;create&quot; though is via compression of knowledge in new ways.<p>It&#x27;s like teaching one undergraduate (reading some blog on the internet and training on next word prediction), then another undergraduate (training on another blog), then another one, etc. And finding a way to store what&#x27;s in common among all these undergraduates. Over time, it starts to see commonalities and to become more powerful than a human. Or a human who had taught a million undergraduates. But it&#x27;s not just at the undergraduate level. It&#x27;s the most abstract&#x2F;efficient way to represent the essence of their ideas.<p>And in math that&#x27;s the whole ball game.</div><br/></div></div><div id="40663035" class="c"><input type="checkbox" id="c-40663035" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#40662087">root</a><span>|</span><a href="#40662829">parent</a><span>|</span><a href="#40663140">prev</a><span>|</span><a href="#40663474">next</a><span>|</span><label class="collapse" for="c-40663035">[-]</label><label class="expand" for="c-40663035">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the current bottleneck is figuring out how to get a model to train itself against its own output without human intervention<p>Isn&#x27;t that what AlphaZero was known for? After all, the &#x27;zero&#x27; part of the name was a play on &#x27;zero-shot learning&#x27; which is the concept you&#x27;re talking about. So we have a proof of existence already, and there&#x27;s been recent papers showing progress in some mathematical domains (though simplified ones so far, such as Euclidean geometry - which does however feature complex proofs).</div><br/></div></div><div id="40663474" class="c"><input type="checkbox" id="c-40663474" checked=""/><div class="controls bullet"><span class="by">rdevsrex</span><span>|</span><a href="#40662087">root</a><span>|</span><a href="#40662829">parent</a><span>|</span><a href="#40663035">prev</a><span>|</span><a href="#40663220">next</a><span>|</span><label class="collapse" for="c-40663474">[-]</label><label class="expand" for="c-40663474">[1 more]</label></div><br/><div class="children"><div class="content">Ramanujan attributed his success in no small part to divine assistance. I wonder if sentient AI would do the same :)</div><br/></div></div><div id="40663220" class="c"><input type="checkbox" id="c-40663220" checked=""/><div class="controls bullet"><span class="by">mistrial9</span><span>|</span><a href="#40662087">root</a><span>|</span><a href="#40662829">parent</a><span>|</span><a href="#40663474">prev</a><span>|</span><a href="#40665823">next</a><span>|</span><label class="collapse" for="c-40663220">[-]</label><label class="expand" for="c-40663220">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but the current bottleneck is figuring out how to get a model to train itself against its own output without human intervention<p>this is sort of humorous, because the entire current generation of Transformer-based encoders was built specifically to get &quot;a model to train itself without human intervention&quot;<p>ref. arXiv:2304.12210v2 [cs.LG] 28 Jun 2023 * 
A Cookbook of Self-Supervised Learning</div><br/></div></div></div></div><div id="40665823" class="c"><input type="checkbox" id="c-40665823" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#40662087">parent</a><span>|</span><a href="#40662829">prev</a><span>|</span><a href="#40663664">next</a><span>|</span><label class="collapse" for="c-40665823">[-]</label><label class="expand" for="c-40665823">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Right now it&#x27;s a helper. A fact checker. And doer of tedious things.<p>One of these is not like the others.</div><br/></div></div><div id="40663664" class="c"><input type="checkbox" id="c-40663664" checked=""/><div class="controls bullet"><span class="by">calf</span><span>|</span><a href="#40662087">parent</a><span>|</span><a href="#40665823">prev</a><span>|</span><a href="#40664055">next</a><span>|</span><label class="collapse" for="c-40663664">[-]</label><label class="expand" for="c-40663664">[1 more]</label></div><br/><div class="children"><div class="content">Hinton&#x27;s example doesn&#x27;t resonate for me -- I do gardening as  a hobby, so my immediate answer to his &quot;What is common to nukes and compost heap?&quot; -- was the concept of critical mass. It took me 10 seconds to articulate the word, so I&#x27;m not as fast, but I still got the &quot;correct&quot; analogy right away, because with the right information the answer is obvious.<p>Hinton says this demonstrates analogical thinking. I read about gardening online and I&#x27;ve probably read about compost heap physics written down somewhere online.<p>So what is more likely happened was that ChatGPT was previously trained some article about compost heap chain reactions, because there&#x27;s a lot of soil science and agriculture that discusses this, even for laypeople like myself that I&#x27;ve already read, so that it isn&#x27;t a long reach if you know enough about both topics.<p>Thus Hinton&#x27;s example strikes me as more having failed to control for LLMs having already basically seen the answer before in its training texts.<p>EDIT: A few minutes later in the video, Ilya comments (<a href="https:&#x2F;&#x2F;youtu.be&#x2F;Gg-w_n9NJIE?t=4966" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;Gg-w_n9NJIE?t=4966</a>): &quot;We have a proof of existence, the human brain is a neural network&quot; (and the panelist agrees, assuming&#x2F;barring any computational &quot;magic&quot; happening in the human brain. I&#x27;m interested in this comment, because I generally hold that position as well, but I see many naysayers and dissenters who will respond &quot;Well but real neurons don&#x27;t run on 8 bits, neurons have different types and cells and contain DNA in a chemical soup of hormones, etc. etc., you are just confusing the model for the real thing in a backwards way&quot;, and so on. So I think there&#x27;s an interesting divide in philosophy there as well, and I don&#x27;t personally have an articulate answer to explain why I might hold the position that natural brains are also neural networks other than an appeal to computationalism.</div><br/></div></div><div id="40664055" class="c"><input type="checkbox" id="c-40664055" checked=""/><div class="controls bullet"><span class="by">29athrowaway</span><span>|</span><a href="#40662087">parent</a><span>|</span><a href="#40663664">prev</a><span>|</span><a href="#40650202">next</a><span>|</span><label class="collapse" for="c-40664055">[-]</label><label class="expand" for="c-40664055">[1 more]</label></div><br/><div class="children"><div class="content">If one AI based system becomes an expert in writing math proofs, the cost of getting another one is simply copying files and provisioning them into different cloud instances. This can be done within minutes to hours.<p>If one human becomes an expert in writing math proofs, the cost of getting another one is waiting for a human within the human population that likes math as a career, the cost of waiting for that human to finish school (decades) and getting advanced specialization, with no guarantee that the human will finish school or become proficient enough to advance the frontier of knowledge. By the time you finished waiting for this, you could have trillions of AI experts working in parallel.<p>The bandwidth of the brain when it comes to assimilating new information is low (up to hundreds of words per minute). Machines will be able to clone a lifetime of knowledge in seconds, have thousands of conversations in parallel, even serializing parts of their &quot;brain&quot; and sending them over to other AIs, like the Borg. These are things that are not possible within the human condition.<p>And once programmable matter is attained, you could produce exponential amounts of computronium and do the equivalent of millennias of research in seconds. This is how the omega point could happen.</div><br/></div></div></div></div><div id="40650202" class="c"><input type="checkbox" id="c-40650202" checked=""/><div class="controls bullet"><span class="by">Tarean</span><span>|</span><a href="#40662087">prev</a><span>|</span><a href="#40660917">next</a><span>|</span><label class="collapse" for="c-40650202">[-]</label><label class="expand" for="c-40650202">[14 more]</label></div><br/><div class="children"><div class="content">Computer-Checked proofs are one area where ai could be really useful fairly soon. Though it may be closer to neural networks in chess engines than full llm&#x27;s.<p>You already use tons of solvers because proving everything by hand  is mind numbingly tedious and time consuming, but tactics&#x2F;solvers really struggle if you throw too many theorems and lemmas at them. Neural nets as search machines to pattern match relevant lemmas fit perfectly.  
Similarly induction and higher order unification are full-on code synthesis where brute-force iterating over all possible syntax trees is really inefficient.<p>And solvers do a backtracking solve anyway, so if the ai returns 95% irrelevant lemmas it doesn&#x27;t matter. Still would be a dramatic improvement over manually searching for them.<p>Though I&#x27;m not convinced that computer checked proofs are necessarily good for communication. There are reasons beside page-count that proofs for human consumption are high-level and gloss over details.</div><br/><div id="40659728" class="c"><input type="checkbox" id="c-40659728" checked=""/><div class="controls bullet"><span class="by">qsort</span><span>|</span><a href="#40650202">parent</a><span>|</span><a href="#40661184">next</a><span>|</span><label class="collapse" for="c-40659728">[-]</label><label class="expand" for="c-40659728">[8 more]</label></div><br/><div class="children"><div class="content">Not a mathematician, but knowing how proof-checkers work I don&#x27;t expect them to become practical without some significant future advancement, they certainly aren&#x27;t right now.<p>The main problem is that in order to work they have to be connected to the formal definition of the mathematical objects you are using in your proof. But nobody thinks that way when writing (or reading!) a proof, you usually have a high-level, informal idea of what you are &quot;morally&quot; doing, and then you fill-in formal details as needed.<p>Computer code (kinda) works because the formal semantics of the language is much closer to your mental model, so much that in many cases it&#x27;s possible to give an operational semantics, but generally speaking math is different in its objectives.</div><br/><div id="40660093" class="c"><input type="checkbox" id="c-40660093" checked=""/><div class="controls bullet"><span class="by">g15jv2dp</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40659728">parent</a><span>|</span><a href="#40666789">next</a><span>|</span><label class="collapse" for="c-40660093">[-]</label><label class="expand" for="c-40660093">[4 more]</label></div><br/><div class="children"><div class="content">You&#x27;re commenting on a thread about an interview where an actual Fields medalist explains how proof assistants are actually used to do meaningful mathematical work, today. The issues you raise are all discussed in the interview.</div><br/><div id="40660209" class="c"><input type="checkbox" id="c-40660209" checked=""/><div class="controls bullet"><span class="by">qsort</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40660093">parent</a><span>|</span><a href="#40662135">next</a><span>|</span><label class="collapse" for="c-40660209">[-]</label><label class="expand" for="c-40660209">[2 more]</label></div><br/><div class="children"><div class="content">practical = practical for routine mathematical work, which they aren&#x27;t right now, which Tao says in the article itself.<p>Never have I ever said or implied, here or anywhere else, that proof checkers are useless and bad and stupid.</div><br/><div id="40660541" class="c"><input type="checkbox" id="c-40660541" checked=""/><div class="controls bullet"><span class="by">g15jv2dp</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40660209">parent</a><span>|</span><a href="#40662135">next</a><span>|</span><label class="collapse" for="c-40660541">[-]</label><label class="expand" for="c-40660541">[1 more]</label></div><br/><div class="children"><div class="content">&gt; practical = practical for routine mathematical work, which they aren&#x27;t right now, which Tao says in the article itself.<p>I see, I guess it would have been nice to be clearer from the start.<p>&gt; Never have I ever said or implied, here or anywhere else, that proof checkers are useless and bad and stupid.<p>Did I say you did?</div><br/></div></div></div></div><div id="40662135" class="c"><input type="checkbox" id="c-40662135" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40660093">parent</a><span>|</span><a href="#40660209">prev</a><span>|</span><a href="#40666789">next</a><span>|</span><label class="collapse" for="c-40662135">[-]</label><label class="expand" for="c-40662135">[1 more]</label></div><br/><div class="children"><div class="content">They = LLMs.<p>As I’ve interpreted it, they mean that LLMs and similar tech isn’t particularly helpful to theorem provers at the moment.</div><br/></div></div></div></div><div id="40666789" class="c"><input type="checkbox" id="c-40666789" checked=""/><div class="controls bullet"><span class="by">cjfd</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40659728">parent</a><span>|</span><a href="#40660093">prev</a><span>|</span><a href="#40666086">next</a><span>|</span><label class="collapse" for="c-40666789">[-]</label><label class="expand" for="c-40666789">[1 more]</label></div><br/><div class="children"><div class="content">Actually, it is possible to do a high level outline of a proof development and later fill in the details. This is done by starting out with axioms. I.e., don&#x27;t define the basic types but state that they exist as axioms and also write down their basic properties as axioms. Then later, when you have some development going on, fill in the blanks by turning the axioms into definitions.</div><br/></div></div><div id="40666086" class="c"><input type="checkbox" id="c-40666086" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40659728">parent</a><span>|</span><a href="#40666789">prev</a><span>|</span><a href="#40659840">next</a><span>|</span><label class="collapse" for="c-40666086">[-]</label><label class="expand" for="c-40666086">[1 more]</label></div><br/><div class="children"><div class="content">The whole article is about Terence Tao predicts it will be practical <i>without</i> a significant breakthrough.<p>&gt;&gt; I don’t think mathematics will become solved. If there was another major breakthrough in AI, it’s possible, but I would say that in three years you will see notable progress, and it will become more and more manageable to actually use AI.<p>He think you need another breakthrough to solve mathematics, i.e. making mathematicians obsolete. But even a major breakthrough doesn&#x27;t happen, AI will be useful for mathematicians in 3 years.<p>Of course you can still disagree with Terence Tao. He being one of the best mathematicians doesn&#x27;t make him an oracle.<p>&gt; But nobody thinks that way when writing (or reading!) a proof<p>He even very specifically addressed this issue with:<p>&gt;&gt; Let’s say an AI supplies an incomprehensible, ugly proof. Then you can work with it, and you can analyze it. Suppose this proof uses 10 hypotheses to get one conclusion—if I delete one hypothesis, does the proof still work?<p>He clearly believes an ugly, incomprehensible proof is much better than no proof at all.</div><br/></div></div><div id="40659840" class="c"><input type="checkbox" id="c-40659840" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40659728">parent</a><span>|</span><a href="#40666086">prev</a><span>|</span><a href="#40661184">next</a><span>|</span><label class="collapse" for="c-40659840">[-]</label><label class="expand" for="c-40659840">[1 more]</label></div><br/><div class="children"><div class="content">You yourself identified some problems that a modern AI guru would salivate over: Formal specifications from natural language, &quot;filling in&quot; formal details. etc<p>I&#x27;ll add another one: NN-based speedups to constraint solvers, which are usually something like branch-and-bound. This is (i&#x27;ve heard) a very active area of research.</div><br/></div></div></div></div><div id="40661184" class="c"><input type="checkbox" id="c-40661184" checked=""/><div class="controls bullet"><span class="by">bramhaag</span><span>|</span><a href="#40650202">parent</a><span>|</span><a href="#40659728">prev</a><span>|</span><a href="#40661428">next</a><span>|</span><label class="collapse" for="c-40661184">[-]</label><label class="expand" for="c-40661184">[4 more]</label></div><br/><div class="children"><div class="content">Automated theorem proving is a concept that has been around for a long time already.<p>Isabelle&#x27;s sledgehammer strategy combines automatic theorem provers (E, Z3, SPASS, Vampire, ...) and attempts to prove&#x2F;refute a goal. In theory this seems fine, but in practice you end up with a reconstructed proof that applies 12 seemingly arbitrary lemmas. This sort of proof is unreadable and very fragile. I don&#x27;t see how AI will magically solve this issue.</div><br/><div id="40661617" class="c"><input type="checkbox" id="c-40661617" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40661184">parent</a><span>|</span><a href="#40661428">next</a><span>|</span><label class="collapse" for="c-40661617">[-]</label><label class="expand" for="c-40661617">[3 more]</label></div><br/><div class="children"><div class="content">What is a &quot;fragile&quot; proof?</div><br/><div id="40661763" class="c"><input type="checkbox" id="c-40661763" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40661617">parent</a><span>|</span><a href="#40661428">next</a><span>|</span><label class="collapse" for="c-40661763">[-]</label><label class="expand" for="c-40661763">[2 more]</label></div><br/><div class="children"><div class="content">It no longer works when some definition or other theorem changes slightly. Most of these proof assistants provide ways to write proofs that can slightly adjust and &quot;plug together&quot; the other theorems in the &quot;obvious&quot; way.</div><br/><div id="40665935" class="c"><input type="checkbox" id="c-40665935" checked=""/><div class="controls bullet"><span class="by">harpiaharpyja</span><span>|</span><a href="#40650202">root</a><span>|</span><a href="#40661763">parent</a><span>|</span><a href="#40661428">next</a><span>|</span><label class="collapse" for="c-40665935">[-]</label><label class="expand" for="c-40665935">[1 more]</label></div><br/><div class="children"><div class="content">So it&#x27;s a brittle proof</div><br/></div></div></div></div></div></div></div></div><div id="40661428" class="c"><input type="checkbox" id="c-40661428" checked=""/><div class="controls bullet"><span class="by">trott</span><span>|</span><a href="#40650202">parent</a><span>|</span><a href="#40661184">prev</a><span>|</span><a href="#40660917">next</a><span>|</span><label class="collapse" for="c-40661428">[-]</label><label class="expand" for="c-40661428">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Computer-Checked proofs are one area where ai could be really useful fairly soon. Though it may be closer to neural networks in chess engines than full llm&#x27;s.<p>Yes, if significant progress is made in sample-efficiency. The current neural networks are extremely sample-inefficient. And formal math datasets are much smaller than those of, say, Python code.</div><br/></div></div></div></div><div id="40660917" class="c"><input type="checkbox" id="c-40660917" checked=""/><div class="controls bullet"><span class="by">munchler</span><span>|</span><a href="#40650202">prev</a><span>|</span><a href="#40664833">next</a><span>|</span><label class="collapse" for="c-40660917">[-]</label><label class="expand" for="c-40660917">[1 more]</label></div><br/><div class="children"><div class="content">Terence Tao also gave a great talk on this topic a few months ago, where he goes into more detail about uses of Lean: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=AayZuuDDKP0" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=AayZuuDDKP0</a></div><br/></div></div><div id="40664833" class="c"><input type="checkbox" id="c-40664833" checked=""/><div class="controls bullet"><span class="by">brhsagain</span><span>|</span><a href="#40660917">prev</a><span>|</span><a href="#40662174">next</a><span>|</span><label class="collapse" for="c-40664833">[-]</label><label class="expand" for="c-40664833">[13 more]</label></div><br/><div class="children"><div class="content">I know absolutely nothing about math, but... I&#x27;m thinking about the history of software, where back in the day you had all these amazing projects like RollerCoaster Tycoon basically being written by one guy. Then software engineering became modularized in a way that sounds kind of similar to what is described in the interview, and now you have hordes of people who churn out React for a living (like myself) and software engineering is now a giant assembly line and the productivity (or skill required) per individual has dropped to near zero.<p>I guess I have the impression that when fields are in their heyday, the best work is done by some genius fitting like a hundred things in one brain, and when that gets replaced by an assembly line, the field has basically stopped producing anything of real value. Anyone in math (or otherwise) want to tell me why that&#x27;s completely wrong?</div><br/><div id="40664929" class="c"><input type="checkbox" id="c-40664929" checked=""/><div class="controls bullet"><span class="by">sublinear</span><span>|</span><a href="#40664833">parent</a><span>|</span><a href="#40664877">next</a><span>|</span><label class="collapse" for="c-40664929">[-]</label><label class="expand" for="c-40664929">[1 more]</label></div><br/><div class="children"><div class="content">&gt; software engineering is now a giant assembly line and the productivity (or skill required) per individual has dropped to near zero<p>If you want a more engaging job you can take a paycut and work at a startup where the code is an even bigger mess written by people who are just as lazy and disorganized but in another (more &quot;prestigious&quot;) programming language.<p>Joking aside, when inevitably someone needs to fix a critical bug you&#x27;ll see the skills come out. When products&#x2F;services become stable and profitable it doesn&#x27;t necessarily mean the original devs have left the company or that someone can&#x27;t rise to the occasion.</div><br/></div></div><div id="40664877" class="c"><input type="checkbox" id="c-40664877" checked=""/><div class="controls bullet"><span class="by">cayley_graph</span><span>|</span><a href="#40664833">parent</a><span>|</span><a href="#40664929">prev</a><span>|</span><a href="#40665001">next</a><span>|</span><label class="collapse" for="c-40664877">[-]</label><label class="expand" for="c-40664877">[3 more]</label></div><br/><div class="children"><div class="content">This intuition denies the inherent human power: that we are not merely individuals, and can work together to accomplish greater things than any individual could. Software engineering has certainly _not_ stopped doing cool things-- exactly the opposite-- obviously. I don&#x27;t care to justify this since there was none in the claim I&#x27;m responding to.</div><br/><div id="40665071" class="c"><input type="checkbox" id="c-40665071" checked=""/><div class="controls bullet"><span class="by">brhsagain</span><span>|</span><a href="#40664833">root</a><span>|</span><a href="#40664877">parent</a><span>|</span><a href="#40665001">next</a><span>|</span><label class="collapse" for="c-40665071">[-]</label><label class="expand" for="c-40665071">[2 more]</label></div><br/><div class="children"><div class="content">My theory is not that individual genius accomplishes more than a group, but that whether a field is currently more suited for individual single-brain productivity or assembly-line cooperation is a signal of whether that field is nascent, at its peak, or in decline. I genuinely think software technology has not advanced in a long time. Computers got really fast, which allowed us to build a mountain of abstractions on top, and now you can throw together web apps, and there is no shortage of companies running around with that hammer and banging on everything. But the actual boundaries of what is possible with software have not moved in a while.<p>Most of the software nowadays (in addition to being terribly slow and broken, by the way) feels like stuff that doesn&#x27;t actually need to exist. It doesn&#x27;t advance the boundaries of technology or humanity&#x27;s skill tree in any way. It&#x27;s a &quot;nice to have&quot; — it might have some social value or make some business process more efficient or whatever — but no one looks at it and goes, wow, we couldn&#x27;t do that before.<p>Someone is going to bring up AI and LLMs, and about that, I will just say that ChatGPT was a real accomplishment... but after that, I have not seen any use cases of LLMs that represent a genuine step forward. Like smart contracts, it&#x27;s a solution in desperate search of a problem, a technology in search of a breakout app. You feel like there&#x27;s just no way it doesn&#x27;t have wide reaching implications, and everyone around you (especially VCs) talks about the &quot;possibilities unlocked&quot; — but two years in and we haven&#x27;t seen a single actually interesting use case. (Again, of course they&#x27;re being incorporated to optimize some business process or whatever. But who cares?)<p>Meanwhile, as far as the day to day reality of software engineering goes, if you work professionally as an engineer, your job is more or less wrangling microservices in one form or another. If you&#x27;re at a big company this is probably literal, but even if you&#x27;re at a startup the bigco transplants start doing microservice stuff basically on arrival, and a bunch of the &quot;best practices&quot; and frameworks and tools are meant to mimic microservices type thinking (making things more complicated rather than less).<p>As a final note, I grew up being a giant fan of YC and PG&#x27;s essays, so I will make a comment about the latest batch of YC startups. It seems to me that a bunch of them basically exist to make some process more efficient. But then you wonder, why does that process need to exist in the first place? Like there was one startup helping you to optimize your AWS costs or something, but why is software written in such a way <i>to begin with</i> that you have all these microservices and towers of abstractions and untrackable infrastructure? Like you look at these startups solving a problem of solving a problem... and then you get to the root problem, and the whole thing is just a giant castle in the sky. I think this describes much of the motivating thrust of software today.</div><br/><div id="40666617" class="c"><input type="checkbox" id="c-40666617" checked=""/><div class="controls bullet"><span class="by">2shaun</span><span>|</span><a href="#40664833">root</a><span>|</span><a href="#40665071">parent</a><span>|</span><a href="#40665001">next</a><span>|</span><label class="collapse" for="c-40666617">[-]</label><label class="expand" for="c-40666617">[1 more]</label></div><br/><div class="children"><div class="content">Theorem provers are a rapidly developing software innovation that is invading a field that has existed since Euclid. I would consider Bitcoin an advancement of boundaries as well. Possibly even Kubernetes, VR, etc.<p>These boundary pushing technologies appear as a &quot;decline&quot; as you put it because most of the software world needs to worry about paying bills with CRUD apps instead of pushing technological boundaries. I would say this Project Managementization of math as Terrence Tao put it would push the boundaries of math to a point of a sort of revolution, but the sad truth is that it will lose its romantic qualities.<p>I&#x27;m sure there are plenty of mathematicians that enjoy the Euclid&#x2F;Andrew Wiles way of things and will come to similar conclusions as you. It will be easy to view it as either a revolution or decline depending on whether you prefer advancing the field as a universal truth or you prefer the practice as it is.</div><br/></div></div></div></div></div></div><div id="40665001" class="c"><input type="checkbox" id="c-40665001" checked=""/><div class="controls bullet"><span class="by">nighthawk454</span><span>|</span><a href="#40664833">parent</a><span>|</span><a href="#40664877">prev</a><span>|</span><a href="#40665034">next</a><span>|</span><label class="collapse" for="c-40665001">[-]</label><label class="expand" for="c-40665001">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m inclined to agree. People seem to be getting hung up on &#x27;no, _my_ React app is hard and challenging for me!&#x27; which completely misses the point. I think it&#x27;s a combination of a few things:<p>- skill is generally log-normally distributed, so there&#x27;s few exceptional people anyway (see also: sturgeon&#x27;s law, 99% of everything is crap)<p>- smaller&#x2F;earlier fields may self-select for extreme talent as the support infrastructure just isn&#x27;t there for most to make it, leading to an unrealistically high density of top talent<p>- it&#x27;s a fundamentally different thing to make a substantial impact than to cookie-cutter a todo list app by wrangling the latest 47 frameworks. in that, it&#x27;s highly unlikely that the typical engineering career trajectory will somehow hit an inflection point and change gears<p>- presumably, from a cost&#x2F;benefit perspective there&#x27;s a strong local maxima in spewing out tons of code cheaply for some gain, vs a much more substantial investment in big things that are harder to realize gains (further out, less likely, etc). the more the field develops, the lower the skill floor gets to hit that local maxima. which therefore increases the gap between the typical talent and the top talent<p>- there&#x27;s not a lot of focus on training top talent. it&#x27;s not really a direct priority of most organizations&#x2F;institutions by volume. most coders are neither aiming for or pushed towards that goal<p>All told, I think there&#x27;s a bunch of systemic effects at play. It seems unlikely to expect the density of talent to just get better for no reason, and it&#x27;s easier to explain why left unchecked the average talent would degrade as a field grows. Perhaps that&#x27;s not even an issue and we don&#x27;t need &#x27;so many cooks in the kitchen&#x27;, if the top X% can push the foundations enough for everyone else to make apps with. But the general distribution should be worth paying attention to bc if we get it wrong it&#x27;s probably costly to fix</div><br/><div id="40665099" class="c"><input type="checkbox" id="c-40665099" checked=""/><div class="controls bullet"><span class="by">beryilma</span><span>|</span><a href="#40664833">root</a><span>|</span><a href="#40665001">parent</a><span>|</span><a href="#40665034">next</a><span>|</span><label class="collapse" for="c-40665099">[-]</label><label class="expand" for="c-40665099">[2 more]</label></div><br/><div class="children"><div class="content">&gt; _my_ React app is hard and challenging for me<p>I love the idea of &quot;essential vs artificial complexity&quot;. React claiming to solve the essential complexity of state management, among others, creates bunch of artificial complexities. And software engineers are no better as a result and become masters of frameworks, but not masters of their arts. That is why the comparison to assembly line is apt. Doing assembly line work is still hard, but it is not software &quot;engineering&quot; in a certain definition of the word.</div><br/><div id="40665324" class="c"><input type="checkbox" id="c-40665324" checked=""/><div class="controls bullet"><span class="by">nighthawk454</span><span>|</span><a href="#40664833">root</a><span>|</span><a href="#40665099">parent</a><span>|</span><a href="#40665034">next</a><span>|</span><label class="collapse" for="c-40665324">[-]</label><label class="expand" for="c-40665324">[1 more]</label></div><br/><div class="children"><div class="content">Yeah! I think of that &#x27;intrinsic difficulty&#x27; in sort of information theory terms. In that, given the context of where we are and where we want to be, what is the minimum amount of work needed to get there. If that minimum work is a large amount, the problem is &#x27;hard&#x27;. This also accounts for the change in difficulty over time as our &#x27;where we are&#x27; gets better.<p>Line work is certainly still hard from a toil standpoint. But academically, little of that total effort is intrinsically necessary, so the work is in some sense highly inefficient. There may still be aspects that need human intervention of course, but the less that is the more robotic the task.<p>In theory, anything that&#x27;s already figured out is a candidate to be offloaded to the robots, and in some sense isn&#x27;t necessarily a good use of human time. (There may be other socioeconomic reasons to value humans doing these tasks, but, it&#x27;s not absolutely required that a human do it over a machine)</div><br/></div></div></div></div></div></div><div id="40665034" class="c"><input type="checkbox" id="c-40665034" checked=""/><div class="controls bullet"><span class="by">beryilma</span><span>|</span><a href="#40664833">parent</a><span>|</span><a href="#40665001">prev</a><span>|</span><a href="#40664917">next</a><span>|</span><label class="collapse" for="c-40665034">[-]</label><label class="expand" for="c-40665034">[1 more]</label></div><br/><div class="children"><div class="content">Mathematics or more generally academics is no panacea either. At least in engineering and applied math, there is a different assembly line of &quot;research&quot; and publications going on. We live in the area of enshitification of everything.<p>In both software and math, there are still very good people. But too far and between. And it is hard to separate the good from the bad.</div><br/></div></div><div id="40664917" class="c"><input type="checkbox" id="c-40664917" checked=""/><div class="controls bullet"><span class="by">BarryMilo</span><span>|</span><a href="#40664833">parent</a><span>|</span><a href="#40665034">prev</a><span>|</span><a href="#40665109">next</a><span>|</span><label class="collapse" for="c-40664917">[-]</label><label class="expand" for="c-40664917">[1 more]</label></div><br/><div class="children"><div class="content">Skill required near zero? I&#x27;m approaching 15 years as a developer and React is still completely foreign to me. I&#x27;d need days full-time just to learn one version of it, not to mention every prerequisite skill.<p>And what do you mean by &quot;real&quot; value? Carrots have value because we can eat them, React apps have value because they communicate information (or do other things app do).<p>Or do you mean artistic value? We can agree, if you like, that SPAs are not as much &quot;art&quot; as RCT. But... who cares?</div><br/></div></div><div id="40665109" class="c"><input type="checkbox" id="c-40665109" checked=""/><div class="controls bullet"><span class="by">im3w1l</span><span>|</span><a href="#40664833">parent</a><span>|</span><a href="#40664917">prev</a><span>|</span><a href="#40665513">next</a><span>|</span><label class="collapse" for="c-40665109">[-]</label><label class="expand" for="c-40665109">[2 more]</label></div><br/><div class="children"><div class="content">I think that is unfair. The productivity per person in old projects like RollerCoaster Tycoon is impressive. But the overall result pales in comparison with modern games. Saying the field has stopped producing anything of real value is very wrong.<p>To me it&#x27;s like comparing a cathedral made by 100 people over 100 years to a shack without made by one person in one month. Like it stands I suppose. It gives him shelter and lets him live. But it&#x27;s no cathedral.</div><br/><div id="40665225" class="c"><input type="checkbox" id="c-40665225" checked=""/><div class="controls bullet"><span class="by">brhsagain</span><span>|</span><a href="#40664833">root</a><span>|</span><a href="#40665109">parent</a><span>|</span><a href="#40665513">next</a><span>|</span><label class="collapse" for="c-40665225">[-]</label><label class="expand" for="c-40665225">[1 more]</label></div><br/><div class="children"><div class="content">I probably should&#x27;ve defined &quot;real value&quot; more carefully. My framework here is basically the idea of technology as humanity&#x27;s &quot;skill tree,&quot; the total set of stuff we&#x27;re able to do. Back when RCT (and Doom before that) were written, we genuinely weren&#x27;t sure if such things could be created, and their creation represented a novel step forward. The vibe in software feels like we&#x27;re long past the stage of doing things like that, like we&#x27;re not even attempting to do things like that. I can only think of two things in recent history: whatever strand of AI culminated in ChatGPT, which is genuinely impressive, and Bitcoin, which ostensibly <i>was</i> created by one guy.</div><br/></div></div></div></div></div></div><div id="40662174" class="c"><input type="checkbox" id="c-40662174" checked=""/><div class="controls bullet"><span class="by">Tossrock</span><span>|</span><a href="#40664833">prev</a><span>|</span><a href="#40666394">next</a><span>|</span><label class="collapse" for="c-40662174">[-]</label><label class="expand" for="c-40662174">[21 more]</label></div><br/><div class="children"><div class="content">A working mathematician recently got GPT-4o to prove an (afaik) novel lemma while pursuing their research:<p>&quot;My partner, who is mathematician, used ChatGPT last week for the first time to prove some lemmas for his research. He already suspected those lemmas were true and had some vague idea how to approach them, but he wasn&#x27;t expert in this type of statement. This is the first time that he got correct and useful proofs out of the models.<p>[...]<p>These are the two lemmas. The first one is something that a collaborator of my partner noticed for small values of e in their computations. ChatGPT did not find the proof before being told to try Mobius functions.<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;9ee33e31-7cec-4847-92e4-eebb48d4ffea" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;9ee33e31-7cec-4847-92e4-eebb48d4ff...</a><p>The second looks a bit more standard to me, probably something that Mathematica would have been able to do as well. But perhaps that&#x27;s just because I am more familiar with such formulas. Still, Mathematica doesn&#x27;t give a nice derivation, so this is useful.<p><a href="https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;7335f11d-f7c0-4093-a761-1090a21579b4" rel="nofollow">https:&#x2F;&#x2F;chatgpt.com&#x2F;share&#x2F;7335f11d-f7c0-4093-a761-1090a21579...</a><p>&quot;</div><br/><div id="40662414" class="c"><input type="checkbox" id="c-40662414" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#40662174">parent</a><span>|</span><a href="#40664393">next</a><span>|</span><label class="collapse" for="c-40662414">[-]</label><label class="expand" for="c-40662414">[10 more]</label></div><br/><div class="children"><div class="content">In a recent interview, Ben Goertzel mentioned having a PhD-level discussion with GPT-4 about novel math ideas cooked up by himself and a colleague. These things are becoming scary good at reasoning and heavyweight topics. As the ML field continues focusing on adding more System Two capabilities to complement LLMs&#x27; largely System One thinking, things will get wild.</div><br/><div id="40663283" class="c"><input type="checkbox" id="c-40663283" checked=""/><div class="controls bullet"><span class="by">UniverseHacker</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40662414">parent</a><span>|</span><a href="#40664393">next</a><span>|</span><label class="collapse" for="c-40663283">[-]</label><label class="expand" for="c-40663283">[9 more]</label></div><br/><div class="children"><div class="content">This is my experience as well- even the popular hype underestimates how creative and intelligent LLMs can be. Most discussions are reasoning about what it should or shouldn’t be capable of based on how we think they work, without really looking directly at what is can actually do, and not focusing on what it can’t do. They are very alien- much worse than humans at many things, but also much better at others. And not in the areas we would expect in both cases. Ironically they are especially good at creative and abstract thinking and very bad at keeping track of details and basic computation, nearly the opposite of what we’d expect from computers.</div><br/><div id="40663798" class="c"><input type="checkbox" id="c-40663798" checked=""/><div class="controls bullet"><span class="by">mu53</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40663283">parent</a><span>|</span><a href="#40664518">next</a><span>|</span><label class="collapse" for="c-40663798">[-]</label><label class="expand" for="c-40663798">[7 more]</label></div><br/><div class="children"><div class="content">I am pessimistic about AI. The technology is definitely useful, but I watched a video that made good points.<p><pre><code>  * On benchmark style tests, LLMs are not improving. GPT-4o is equivalent to GPT-4 and both barely improve on GPT-3.5T.
  * AI companies have been caught outright lying in demos and manipulating outcomes by pre-training for certain scenarios.
  * The main features added to GPT-4o have been features that manipulate humans with dark patterns
  * The dark patterns include emotional affects in tone and cute&#x2F;quirky responses
  * These dark patterns encourage people to think of LLMs as humans that have a similar processing of the universe.
</code></pre>
I seriously wonder about the transcript that these guys had with the LLM. Were they suggesting things? Did ChatGPT just reconfigure words that helped them think through the problem? I think the truth is that ChatGPT is a very effective rubber duck debugger.<p>&gt; <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=VctsqOo8wsc" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=VctsqOo8wsc</a></div><br/><div id="40663952" class="c"><input type="checkbox" id="c-40663952" checked=""/><div class="controls bullet"><span class="by">UniverseHacker</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40663798">parent</a><span>|</span><a href="#40666002">next</a><span>|</span><label class="collapse" for="c-40663952">[-]</label><label class="expand" for="c-40663952">[3 more]</label></div><br/><div class="children"><div class="content">Try playing around with getting GPT-4 to discuss creative solutions to real unsolved problems you are personally an expert on, or created yourself. That video looks like just standard internet ragebait to me.<p>I find it pretty annoying when people say you are just being manipulated by hype if you are impressed by LLMs, when I was a serious skeptic, thought GPT-3 was useless, and only changed my opinion by directly experimenting with GPT-4 on my own- by getting it to discuss and solve problems in my area of expertise as an academic researcher.</div><br/><div id="40664415" class="c"><input type="checkbox" id="c-40664415" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40663952">parent</a><span>|</span><a href="#40666002">next</a><span>|</span><label class="collapse" for="c-40664415">[-]</label><label class="expand" for="c-40664415">[2 more]</label></div><br/><div class="children"><div class="content">Its the new eternal summer, welcome to the club :) GPT-3 was translating 2000 lines of code across 5 languages and enabling me to ship at scale</div><br/><div id="40664766" class="c"><input type="checkbox" id="c-40664766" checked=""/><div class="controls bullet"><span class="by">cdelsolar</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40664415">parent</a><span>|</span><a href="#40666002">next</a><span>|</span><label class="collapse" for="c-40664766">[-]</label><label class="expand" for="c-40664766">[1 more]</label></div><br/><div class="children"><div class="content">I don’t know Jack about C# and .NET and I’ve used ChatGPT to write several nontrivial programs.</div><br/></div></div></div></div></div></div><div id="40666002" class="c"><input type="checkbox" id="c-40666002" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40663798">parent</a><span>|</span><a href="#40663952">prev</a><span>|</span><a href="#40664307">next</a><span>|</span><label class="collapse" for="c-40666002">[-]</label><label class="expand" for="c-40666002">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  On benchmark style tests, LLMs are not improving. GPT-4o is equivalent to GPT-4 and both barely improve on GPT-3.5T.<p>The understatement of this year.<p>GPT-4o is 6x cheaper than GPT-4. So if it&#x27;s actually equivalent to GPT-4, it&#x27;s <i>great</i> improvmenet.<p>In fact, calling it &quot;great&quot; is still a crazy understatement. It&#x27;s a cutting edge technology becoming 6x cheaper in 1.5 year. I&#x27;m quite sure that never happened before in the human history.</div><br/></div></div><div id="40664307" class="c"><input type="checkbox" id="c-40664307" checked=""/><div class="controls bullet"><span class="by">wvenable</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40663798">parent</a><span>|</span><a href="#40666002">prev</a><span>|</span><a href="#40664411">next</a><span>|</span><label class="collapse" for="c-40664307">[-]</label><label class="expand" for="c-40664307">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it makes sense to base your opinion on videos when you could simply use the product yourself and get first-hand experience.<p>I&#x27;ve come full circle on it.  First I thought it was totally amazing, then I pushed it hard and found it lacking, and then I started using it more casually and now I use a little bit every day.  I don&#x27;t find it completely brilliant but it knows an above-average amount about everything.  And it can make short work of very tedious tasks.<p>I just type to ChatGPT so there are no &quot;emotional effects&quot; involved.</div><br/></div></div><div id="40664411" class="c"><input type="checkbox" id="c-40664411" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40663798">parent</a><span>|</span><a href="#40664307">prev</a><span>|</span><a href="#40664518">next</a><span>|</span><label class="collapse" for="c-40664411">[-]</label><label class="expand" for="c-40664411">[1 more]</label></div><br/><div class="children"><div class="content">A lot of the video points are plain wrong in numbers and experientially. I don&#x27;t know how they feel comfortable claiming benchmark numbers didn&#x27;t improve much from 3.5 to 4</div><br/></div></div></div></div><div id="40664518" class="c"><input type="checkbox" id="c-40664518" checked=""/><div class="controls bullet"><span class="by">barfbagginus</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40663283">parent</a><span>|</span><a href="#40663798">prev</a><span>|</span><a href="#40664393">next</a><span>|</span><label class="collapse" for="c-40664518">[-]</label><label class="expand" for="c-40664518">[1 more]</label></div><br/><div class="children"><div class="content">I feel that&#x27;s because most people criticizing AI in that way don&#x27;t know enough about math or other really abstract and conceptual domains to use it for PhD level work. And they don&#x27;t know how to get GPT excited and having fun. There is an additional level of intelligence available to anyone who is passionate enough to get the AI to be exuberant about a topic.<p>It&#x27;s almost like a kindergartner goes up to Einstein and finds out that Einstein&#x27;s just really bad at schoolhouse rhymes - because he finds them boring. So the kid,  adorably, concludes that Einstein is less smart than a kindergartner.<p>But if you need to talk to Einstein about partial differential equations and why, morally, we consider distributional solutions to have physical reality, and if you bring enough creativity and engagement to make the conversation fun and exciting for both you and him, then he&#x27;ll really help you out!<p>Simple point: Don&#x27;t trust the opinion of anyone who can&#x27;t get GPT to &quot;have fun&quot;. Don&#x27;t trust the opinions of anyone who can&#x27;t get GPT helpfully explaining and discussing very complicated things with them. There&#x27;s a very big chance those people have poor opinions about GPT simply because they don&#x27;t know prompting, and don&#x27;t show enjoyment, cameraderie, and respect. Because they don&#x27;t understand the elements of AI conversation, and because they don&#x27;t respect the AI as an emerging fragment of pre-sentient  personhood, they can&#x27;t hold long and useful conversations.</div><br/></div></div></div></div></div></div><div id="40664393" class="c"><input type="checkbox" id="c-40664393" checked=""/><div class="controls bullet"><span class="by">fovc</span><span>|</span><a href="#40662174">parent</a><span>|</span><a href="#40662414">prev</a><span>|</span><a href="#40663403">next</a><span>|</span><label class="collapse" for="c-40664393">[-]</label><label class="expand" for="c-40664393">[2 more]</label></div><br/><div class="children"><div class="content">I’m pretty sure that 2nd proof exists in some book or ebook somewhere. generating functionology was the one that came to mind.<p>Impressive recall, but not novel reasoning</div><br/><div id="40665281" class="c"><input type="checkbox" id="c-40665281" checked=""/><div class="controls bullet"><span class="by">williamcotton</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40664393">parent</a><span>|</span><a href="#40663403">next</a><span>|</span><label class="collapse" for="c-40665281">[-]</label><label class="expand" for="c-40665281">[1 more]</label></div><br/><div class="children"><div class="content">I’m pretty sure that LLMs can generalize a deep model and can create novel assemblages and are not just search engines.<p>The burden of proof would be on you to find the existing mathematical, erhm, proof.</div><br/></div></div></div></div><div id="40663403" class="c"><input type="checkbox" id="c-40663403" checked=""/><div class="controls bullet"><span class="by">Sniffnoy</span><span>|</span><a href="#40662174">parent</a><span>|</span><a href="#40664393">prev</a><span>|</span><a href="#40662602">next</a><span>|</span><label class="collapse" for="c-40663403">[-]</label><label class="expand" for="c-40663403">[3 more]</label></div><br/><div class="children"><div class="content">Sorry, what is this quoted from?<p>It&#x27;s interesting because that first one is something I was discussing recently with my friend Beren (does he have an account here? idk).  We were thinking of it as summing over ordered partitions, rather than over partitions with a factor of |tau|!, but obviously those are the same thing.<p>(If you do it over <i>cyclically</i> ordered partitions -- so, a factor of (|tau|-1)! rather than |tau|! -- you get 0 instead of (-1)^e.)<p>Here&#x27;s Beren&#x27;s combinatorial proof:<p>First let&#x27;s do the second one I said, about cyclically ordered ones, because it&#x27;s easier.  Choose one element of the original set to be special.  Now we can set up a bijection between even-length and odd-length cyclically ordered partitions as follows: If the special element is on its own, merge it with the part after it.  If it&#x27;s not on its own, split it out into its own part before the part it&#x27;s in.  So if we sum with a sign factor, we get 0.<p>OK, so what about the linearly ordered case?  We&#x27;ll use a similar bijection, except it won&#x27;t quite be a bijection this time.  Pick an order on your set.  Apply the above bijection with the last element as the special element.  Except some things don&#x27;t get matched, namely, partitions that have the last element of your set on its own as the last part.<p>So in that case, take the second-to-last element, and apply recursively, etc, etc.  Ultimately everything gets matched except for the paritition where everything is separate and all the parts are in order.  This partition has length equal to the size of the original set.  So if the original set was even you get one more even one, and if the original set was odd you get one more odd one.  Which rephrased as a sum with a sign factor yields the original statement.<p>Would be interested to send this to the mathematician you&#x27;re referring to, but I have no idea who that might be since you didn&#x27;t say. :)</div><br/><div id="40666091" class="c"><input type="checkbox" id="c-40666091" checked=""/><div class="controls bullet"><span class="by">Tossrock</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40663403">parent</a><span>|</span><a href="#40662602">next</a><span>|</span><label class="collapse" for="c-40666091">[-]</label><label class="expand" for="c-40666091">[2 more]</label></div><br/><div class="children"><div class="content">this was from the current ACX Open Thread</div><br/><div id="40667177" class="c"><input type="checkbox" id="c-40667177" checked=""/><div class="controls bullet"><span class="by">Sniffnoy</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40666091">parent</a><span>|</span><a href="#40662602">next</a><span>|</span><label class="collapse" for="c-40667177">[-]</label><label class="expand" for="c-40667177">[1 more]</label></div><br/><div class="children"><div class="content">Thanks!  Went and posted over there.</div><br/></div></div></div></div></div></div><div id="40662602" class="c"><input type="checkbox" id="c-40662602" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#40662174">parent</a><span>|</span><a href="#40663403">prev</a><span>|</span><a href="#40664501">next</a><span>|</span><label class="collapse" for="c-40662602">[-]</label><label class="expand" for="c-40662602">[4 more]</label></div><br/><div class="children"><div class="content">Woah that second proof is really slick. Is there a combinatorial proof instead of algebraic proof as to why that holds?</div><br/><div id="40662944" class="c"><input type="checkbox" id="c-40662944" checked=""/><div class="controls bullet"><span class="by">gjm11</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40662602">parent</a><span>|</span><a href="#40664501">next</a><span>|</span><label class="collapse" for="c-40662944">[-]</label><label class="expand" for="c-40662944">[3 more]</label></div><br/><div class="children"><div class="content">Yes.<p>(HN comments aren&#x27;t the best medium for writing mathematics. I hope this ends up reasonably readable.)<p>(d choose k) is the number of ways to pick k things from d.<p>(d choose k) k^2 is the number of ways to pick k things from d, and then colour one of them red and one of them (possibly the same one) blue.<p>(-1)^k (d choose k) k^2 is that (when k is even), or minus that (when k is odd).<p>So the identity says: Suppose we consider a set of d things, and we consider picking <i>some</i> of them (meaning 0 or more, though actually 0 is impossible; k is the number we pick) and colouring one of those red and one blue; then there are the same number of ways to do this picking an <i>odd</i> number of things as picking an <i>even</i> number.<p>Well, let&#x27;s describe the process a bit differently. We take our set of d things. We colour one of them red. We colour one of them blue. Then we pick some set of the things (k in number), including the red thing and the blue thing (which may or may not also be the red thing). And the claim is that there are the same number of ways to do this with an even value of k as with an odd number.<p>But now this is almost trivial!<p>Once we&#x27;ve picked our red and blue things, we just have to decide which of the <i>other</i> things to pick. And as long as there&#x27;s at least one of those, there are as many ways to pick an odd number of things as to pick an even number. (Fix one of them; we can either include it or not, and switching that changes the parity.)<p>So if d&gt;2 then we&#x27;re done -- for each choice of red and blue, there are the same number of &quot;odd&quot; and &quot;even&quot; ways to finish the job.<p>What if d&lt;=2? Well, then the &quot;theorem&quot; isn&#x27;t actually true.<p>d=1: (1 choose 0) 0^2 - (1 choose 1) 1^2 = -1.<p>d=2: (2 choose 0) 0^2 - (2 choose 1) 1^2 + (2 choose 2) 2^2 = 2.</div><br/><div id="40663476" class="c"><input type="checkbox" id="c-40663476" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40662944">parent</a><span>|</span><a href="#40664501">next</a><span>|</span><label class="collapse" for="c-40663476">[-]</label><label class="expand" for="c-40663476">[2 more]</label></div><br/><div class="children"><div class="content">&gt;We take our set of d things. We colour one of them red. We colour one of them blue. Then we pick some set of the things (k in number), including the red thing and the blue thing<p>In this alternate view of the process, where does the k^2 term come from? Isn&#x27;t the number of ways to do it in this perspective just<p>(d-1 choose k-1)  # We already chose the red one (which is also the blue) and need to choose k-1 more<p>+<p>(d-2 choose k-2) # We chose both red and blue ones and need to choose the other k-2<p>Edit: I think it actually works out, seems to be equal to<p>d * 1 * Binomial[d - 1, k - 1] + d * (d - 1) * Binomial[d - 2, k - 2] = Binomial[d, k]*k^2<p>And then you apply your argument about fixing one of the elements in each of the two cases. Actually the proof seems to be a variant (same core argument) as sum of even binomial terms = sum of odd binomial terms [1]<p>[1] <a href="https:&#x2F;&#x2F;math.stackexchange.com&#x2F;questions&#x2F;313832&#x2F;a-combinatorial-proof-that-the-alternating-sum-of-binomial-coefficients-is-zero" rel="nofollow">https:&#x2F;&#x2F;math.stackexchange.com&#x2F;questions&#x2F;313832&#x2F;a-combinator...</a></div><br/><div id="40663841" class="c"><input type="checkbox" id="c-40663841" checked=""/><div class="controls bullet"><span class="by">gjm11</span><span>|</span><a href="#40662174">root</a><span>|</span><a href="#40663476">parent</a><span>|</span><a href="#40664501">next</a><span>|</span><label class="collapse" for="c-40663841">[-]</label><label class="expand" for="c-40663841">[1 more]</label></div><br/><div class="children"><div class="content">In the alternate view, the k^2 isn&#x27;t there any more. Not because we are computing a different number, but because we&#x27;re organizing the computation differently.<p>(It&#x27;s turned into a d^2 factor, except that we then need to treat the red=blue case differently from the red!=blue case, so it&#x27;s really a d factor plus a d^2-d factor.)<p>And yes, the last bit of the proof is exactly the same thing as one way to prove that the sum of &quot;even&quot; and &quot;odd&quot; binomial coefficients are equal -- provided n&gt;0. (For the (0 choose whatever) case, the &quot;even&quot; sum is 1 and the &quot;odd&quot; sum is 0.)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40666394" class="c"><input type="checkbox" id="c-40666394" checked=""/><div class="controls bullet"><span class="by">CloseChoice</span><span>|</span><a href="#40662174">prev</a><span>|</span><a href="#40659991">next</a><span>|</span><label class="collapse" for="c-40666394">[-]</label><label class="expand" for="c-40666394">[1 more]</label></div><br/><div class="children"><div class="content">3 points stand out to me in this interview:<p>- Project manager mathematicians: Tao draws a future where mathematical insights are &quot;produced&quot; like anything else in our society. He attributes the lack of this productionalization of mathematics to a lack of tools in this area but AI and proof assistants might be revolutionary in this regard (proof assistants already are). Human interaction and guidance still needed<p>- Implicit Knowledge: he points out that so much knowledge is not in papers, e.g. intuition and knowledge of failures. This is crucial and makes it necessary even for top mathematicians to talk to one another to not make mistakes again.<p>- Formalization of mathematics: one would think that mathematics is pretty formalized already (and it is) but in the papers a lot of common knowledge is taken for granted so having proofs formalized in such a way that proof assistants can understand will help more people actually understanding what is going on.<p>I think this just shows how Tao always searches for new ways to do mathematical research, which I first came across in his talk about one of the polymath projects.</div><br/></div></div><div id="40659991" class="c"><input type="checkbox" id="c-40659991" checked=""/><div class="controls bullet"><span class="by">egl2021</span><span>|</span><a href="#40666394">prev</a><span>|</span><a href="#40666275">next</a><span>|</span><label class="collapse" for="c-40659991">[-]</label><label class="expand" for="c-40659991">[21 more]</label></div><br/><div class="children"><div class="content">For now this might be a project for Fields medalists, like Tao and Scholze, who have the leisure to spend 10x the time on a proof.  I recently talked to a post-doc in a top-ranked math department, and he doesn&#x27;t know anyone who actually uses lean4 in their work.  For early-career people, it&#x27;s probably better to trust your intuition and get the papers out.</div><br/><div id="40660052" class="c"><input type="checkbox" id="c-40660052" checked=""/><div class="controls bullet"><span class="by">g15jv2dp</span><span>|</span><a href="#40659991">parent</a><span>|</span><a href="#40661187">next</a><span>|</span><label class="collapse" for="c-40660052">[-]</label><label class="expand" for="c-40660052">[14 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a math professor and I know many people who use or contribute to lean. Not all of them are Fields medalists. Maybe it takes more than a couple of people&#x27;s opinion on the subject to have a good picture.</div><br/><div id="40661020" class="c"><input type="checkbox" id="c-40661020" checked=""/><div class="controls bullet"><span class="by">shakow</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40660052">parent</a><span>|</span><a href="#40661187">next</a><span>|</span><label class="collapse" for="c-40661020">[-]</label><label class="expand" for="c-40661020">[13 more]</label></div><br/><div class="children"><div class="content">&gt; people who use or contribute to lean<p>And do they get tenure- or funding-able output of it, or is it more of a side-hobby?</div><br/><div id="40661193" class="c"><input type="checkbox" id="c-40661193" checked=""/><div class="controls bullet"><span class="by">g15jv2dp</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661020">parent</a><span>|</span><a href="#40661187">next</a><span>|</span><label class="collapse" for="c-40661193">[-]</label><label class="expand" for="c-40661193">[12 more]</label></div><br/><div class="children"><div class="content">Yes, they get grants to work on it. Other questions? I can&#x27;t say I enjoy this &quot;gotcha&quot; tone.</div><br/><div id="40661870" class="c"><input type="checkbox" id="c-40661870" checked=""/><div class="controls bullet"><span class="by">GPerson</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661193">parent</a><span>|</span><a href="#40662281">next</a><span>|</span><label class="collapse" for="c-40661870">[-]</label><label class="expand" for="c-40661870">[2 more]</label></div><br/><div class="children"><div class="content">The person you are replying to asked a very useful question, and you supplied a useful answer. I don’t detect any snarky tone in their comment.</div><br/><div id="40666183" class="c"><input type="checkbox" id="c-40666183" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661870">parent</a><span>|</span><a href="#40662281">next</a><span>|</span><label class="collapse" for="c-40666183">[-]</label><label class="expand" for="c-40666183">[1 more]</label></div><br/><div class="children"><div class="content">It sounds quite &quot;gotcha&quot; to me.<p>Compare these two cases:<p>&gt; people who use or contribute to lean<p>And do they get tenure- or funding-able output of it, or is it more of a side-hobby?<p>&gt; people who use or contribute to lean<p>Do they get tenure- or funding-able output of it, or is it more of a side-hobby?<p>The &quot;And&quot; at the begining makes it snarky to me. It&#x27;s probably just me tho.</div><br/></div></div></div></div><div id="40662281" class="c"><input type="checkbox" id="c-40662281" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661193">parent</a><span>|</span><a href="#40661870">prev</a><span>|</span><a href="#40661950">next</a><span>|</span><label class="collapse" for="c-40662281">[-]</label><label class="expand" for="c-40662281">[1 more]</label></div><br/><div class="children"><div class="content">Snark and contrarianism are specialties around here. Thank you for sharing your experience; I genuinely appreciate it.</div><br/></div></div><div id="40661950" class="c"><input type="checkbox" id="c-40661950" checked=""/><div class="controls bullet"><span class="by">shakow</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661193">parent</a><span>|</span><a href="#40662281">prev</a><span>|</span><a href="#40661407">next</a><span>|</span><label class="collapse" for="c-40661950">[-]</label><label class="expand" for="c-40661950">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not a “gotcha”, but an interrogation on whether what I experienced in bioinformatics (i.e. working on tools, especially already existing ones, is a carreer trap) also applied to maths.</div><br/></div></div><div id="40661407" class="c"><input type="checkbox" id="c-40661407" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661193">parent</a><span>|</span><a href="#40661950">prev</a><span>|</span><a href="#40661303">next</a><span>|</span><label class="collapse" for="c-40661407">[-]</label><label class="expand" for="c-40661407">[2 more]</label></div><br/><div class="children"><div class="content">I’m with them. They’re using a tool they’re paid to work on. That’s always a special case. The general case would be what percentage of mathematicians use (a) proof assistants at all, (b) mechanized proof assistants, and (c) Lean specifically.<p>Do most working mathematicians use proof assistant or checkers? Does anyone have a percentage with feedback on how they use them?</div><br/><div id="40663165" class="c"><input type="checkbox" id="c-40663165" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661407">parent</a><span>|</span><a href="#40661303">next</a><span>|</span><label class="collapse" for="c-40663165">[-]</label><label class="expand" for="c-40663165">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>They’re using a tool they’re paid to work on. That’s always a special case.</i><p>FWIW, the industry term for this is &quot;dogfooding&quot;, and it&#x27;s usually seen as a predictor of high quality tool.</div><br/></div></div></div></div><div id="40661303" class="c"><input type="checkbox" id="c-40661303" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661193">parent</a><span>|</span><a href="#40661407">prev</a><span>|</span><a href="#40661187">next</a><span>|</span><label class="collapse" for="c-40661303">[-]</label><label class="expand" for="c-40661303">[5 more]</label></div><br/><div class="children"><div class="content">So they get grants to work on these tools rather than to work on math, seems like a very special situation then and a very special math department and therefore not a good picture for how helpful it is to math departments in general.</div><br/><div id="40662076" class="c"><input type="checkbox" id="c-40662076" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661303">parent</a><span>|</span><a href="#40663350">next</a><span>|</span><label class="collapse" for="c-40662076">[-]</label><label class="expand" for="c-40662076">[1 more]</label></div><br/><div class="children"><div class="content">The mathematicians I know of who work on Lean4 as part of grant-funded research do so because their research funding is for formalising mathematics and Lean4 is the tool they choose to use for that.<p>I really have no idea why people are taking this approach here.<p>Proof assistants are useful. People use them to do actual maths. There is a lot of work to formalise all of maths (this isn&#x27;t a proof assistant thing this is a huge undertaking given maths is 3000+ years old and we&#x27;ve only just decided what formality really fundamentally consists of) so some places you need to do more foundational work than others to make it useful.</div><br/></div></div><div id="40663350" class="c"><input type="checkbox" id="c-40663350" checked=""/><div class="controls bullet"><span class="by">szvsw</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661303">parent</a><span>|</span><a href="#40662076">prev</a><span>|</span><a href="#40661863">next</a><span>|</span><label class="collapse" for="c-40663350">[-]</label><label class="expand" for="c-40663350">[1 more]</label></div><br/><div class="children"><div class="content">Isn’t working on these tools a form of working on math? Math is a language unto itself.</div><br/></div></div><div id="40661863" class="c"><input type="checkbox" id="c-40661863" checked=""/><div class="controls bullet"><span class="by">g15jv2dp</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661303">parent</a><span>|</span><a href="#40663350">prev</a><span>|</span><a href="#40661632">next</a><span>|</span><label class="collapse" for="c-40661863">[-]</label><label class="expand" for="c-40661863">[1 more]</label></div><br/><div class="children"><div class="content">I guess we got in the top 10 worldwide for math in the Shanghai ranking by accident. If you don&#x27;t know what you&#x27;re speaking about, sometimes it&#x27;s wise to not say anything.</div><br/></div></div><div id="40661632" class="c"><input type="checkbox" id="c-40661632" checked=""/><div class="controls bullet"><span class="by">nimih</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661303">parent</a><span>|</span><a href="#40661863">prev</a><span>|</span><a href="#40661187">next</a><span>|</span><label class="collapse" for="c-40661632">[-]</label><label class="expand" for="c-40661632">[1 more]</label></div><br/><div class="children"><div class="content">&quot;No <i>true</i> working mathematician would spend their time using Lean!&quot;</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40661187" class="c"><input type="checkbox" id="c-40661187" checked=""/><div class="controls bullet"><span class="by">flostk</span><span>|</span><a href="#40659991">parent</a><span>|</span><a href="#40660052">prev</a><span>|</span><a href="#40660724">next</a><span>|</span><label class="collapse" for="c-40661187">[-]</label><label class="expand" for="c-40661187">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure this also depends a lot on the field within mathematics. Areas like mathematical logic or algebra have a pretty formal style anyway, so it&#x27;s comparatively less effort to translate proofs to lean. I would expect more people from these areas to use proof checkers than say from low-dimensional topology, which has a more &quot;intuitive&quot; style. Of course by &quot;intuitive&quot; I don&#x27;t mean it&#x27;s any less rigorous. But a picture proof of some homotopy equivalence is just much harder to translate to something lean can understand than some sequence of inequalities. To add a data point, I&#x27;m in geometry&#x2F;topology and I&#x27;ve never seen or heard of anyone who uses this stuff (so far).</div><br/><div id="40667361" class="c"><input type="checkbox" id="c-40667361" checked=""/><div class="controls bullet"><span class="by">ocfnash</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661187">parent</a><span>|</span><a href="#40661557">next</a><span>|</span><label class="collapse" for="c-40667361">[-]</label><label class="expand" for="c-40667361">[1 more]</label></div><br/><div class="children"><div class="content">If you are curious, I encourage you to look up The Sphere Eversion Project [1].<p>It was a project in which we formalised a version of Gromov&#x27;s (open, ample) h-principle for first order differential relations. Part of the reason it was carried out was to demonstrate what is involved formalising something in differential topology.<p>1. <a href="https:&#x2F;&#x2F;leanprover-community.github.io&#x2F;sphere-eversion&#x2F;" rel="nofollow">https:&#x2F;&#x2F;leanprover-community.github.io&#x2F;sphere-eversion&#x2F;</a></div><br/></div></div><div id="40661557" class="c"><input type="checkbox" id="c-40661557" checked=""/><div class="controls bullet"><span class="by">enugu</span><span>|</span><a href="#40659991">root</a><span>|</span><a href="#40661187">parent</a><span>|</span><a href="#40667361">prev</a><span>|</span><a href="#40660724">next</a><span>|</span><label class="collapse" for="c-40661557">[-]</label><label class="expand" for="c-40661557">[1 more]</label></div><br/><div class="children"><div class="content">Pictures can be directly used in formal proofs. See [1] for instance So, the problem is not in principle, but rather, pictures and more direct syntax has not yet been integrated into current proof systems. When that is done, proofs will be much more natural and the formal proof will be closer to the &#x27;proof in the mind&#x27;.<p>[1] <a href="https:&#x2F;&#x2F;www.unco.edu&#x2F;nhs&#x2F;mathematical-sciences&#x2F;faculty&#x2F;miller&#x2F;pdf&#x2F;thesis.pdf" rel="nofollow">https:&#x2F;&#x2F;www.unco.edu&#x2F;nhs&#x2F;mathematical-sciences&#x2F;faculty&#x2F;mille...</a></div><br/></div></div></div></div><div id="40660724" class="c"><input type="checkbox" id="c-40660724" checked=""/><div class="controls bullet"><span class="by">occamrazor</span><span>|</span><a href="#40659991">parent</a><span>|</span><a href="#40661187">prev</a><span>|</span><a href="#40661291">next</a><span>|</span><label class="collapse" for="c-40660724">[-]</label><label class="expand" for="c-40660724">[2 more]</label></div><br/><div class="children"><div class="content">For Tao, spending 10x time on aproof still means spending 5x less time than an average postdoc. He is incredibly fast and productive.</div><br/></div></div><div id="40661291" class="c"><input type="checkbox" id="c-40661291" checked=""/><div class="controls bullet"><span class="by">yboris</span><span>|</span><a href="#40659991">parent</a><span>|</span><a href="#40660724">prev</a><span>|</span><a href="#40666275">next</a><span>|</span><label class="collapse" for="c-40661291">[-]</label><label class="expand" for="c-40661291">[1 more]</label></div><br/><div class="children"><div class="content"><i>lean4</i> - programming language and theorem prover<p><a href="https:&#x2F;&#x2F;lean-lang.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lean-lang.org&#x2F;</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;leanprover&#x2F;lean4">https:&#x2F;&#x2F;github.com&#x2F;leanprover&#x2F;lean4</a></div><br/></div></div></div></div><div id="40666275" class="c"><input type="checkbox" id="c-40666275" checked=""/><div class="controls bullet"><span class="by">gsuuon</span><span>|</span><a href="#40659991">prev</a><span>|</span><a href="#40662534">next</a><span>|</span><label class="collapse" for="c-40666275">[-]</label><label class="expand" for="c-40666275">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  &gt; But they only publish the successful thing, not the process.
</code></pre>
Learning from other people&#x27;s failures is a really productive use of time (compared to failing on your own) - really wish this were easier to do for most things in life.</div><br/></div></div><div id="40662534" class="c"><input type="checkbox" id="c-40662534" checked=""/><div class="controls bullet"><span class="by">grondilu</span><span>|</span><a href="#40666275">prev</a><span>|</span><a href="#40663610">next</a><span>|</span><label class="collapse" for="c-40662534">[-]</label><label class="expand" for="c-40662534">[9 more]</label></div><br/><div class="children"><div class="content">&quot;I think in the future, instead of typing up our proofs, we would explain them to some GPT. And the GPT will try to formalize it in Lean as you go along. If everything checks out, the GPT will [essentially] say, “Here’s your paper in LaTeX; here’s your Lean proof. If you like, I can press this button and submit it to a journal for you.” It could be a wonderful assistant in the future.&quot;<p>That&#x27;d be nice, but eventually what will happen is that the human will submit a mathematical conjecture, the computer will internally translate into something like Lean, and try to find either a proof or a disproof.  It will then translate it in natural language and tell it to the user.<p>Unless mathematics is fundamentally more complicated than chess or go, I don&#x27;t see why that could not happen.</div><br/><div id="40662655" class="c"><input type="checkbox" id="c-40662655" checked=""/><div class="controls bullet"><span class="by">qfiard</span><span>|</span><a href="#40662534">parent</a><span>|</span><a href="#40663296">next</a><span>|</span><label class="collapse" for="c-40662655">[-]</label><label class="expand" for="c-40662655">[5 more]</label></div><br/><div class="children"><div class="content">It is fundamentally more complicated. Possible moves can be evaluated against one another in games. We have no idea how to make progress on many math conjectures, e.g. Goldbach or Riemann&#x27;s. An AI would need to find connections with different fields in mathematics that no human has found before, and this is far beyond what chess or Go AIs are doing.</div><br/><div id="40663489" class="c"><input type="checkbox" id="c-40663489" checked=""/><div class="controls bullet"><span class="by">salamo</span><span>|</span><a href="#40662534">root</a><span>|</span><a href="#40662655">parent</a><span>|</span><a href="#40663296">next</a><span>|</span><label class="collapse" for="c-40663489">[-]</label><label class="expand" for="c-40663489">[4 more]</label></div><br/><div class="children"><div class="content">Not a mathematician, but I can imagine a few different things which make proofs much more difficult if we simply tried to map chess algorithms to theorem proving. In chess, each board position is a node in a game tree and the legal moves represent edges to other nodes in the game tree. We could represent a proof as a path through a tree of legal transformations to some initial state as well.<p>But the first problem is, the number of legal transformations is actually infinite. (Maybe I am wrong about this.) So it immediately becomes impossible to search the full tree of possibilities.<p>Ok, so maybe a breadth-first approach won&#x27;t work. Maybe we can use something like Monte Carlo tree search with move (i.e. math operation) ordering. But unlike chess&#x2F;go, we can&#x27;t just use rollouts because the &quot;game&quot; never ends. You can always keep tacking on more operations.<p>Maybe with a constrained set of transformations and a really good move ordering function it would be possible. Maybe Lean is already doing this.</div><br/><div id="40663567" class="c"><input type="checkbox" id="c-40663567" checked=""/><div class="controls bullet"><span class="by">grondilu</span><span>|</span><a href="#40662534">root</a><span>|</span><a href="#40663489">parent</a><span>|</span><a href="#40663296">next</a><span>|</span><label class="collapse" for="c-40663567">[-]</label><label class="expand" for="c-40663567">[3 more]</label></div><br/><div class="children"><div class="content">&gt; But the first problem is, the number of legal transformations is actually infinite.<p>I am fairly certain the number of legal transformations in mathematics is not infinite.   There is a finite number of axioms, and all proven statements are derived from axioms through a finite number of steps.</div><br/><div id="40663640" class="c"><input type="checkbox" id="c-40663640" checked=""/><div class="controls bullet"><span class="by">hwayne</span><span>|</span><a href="#40662534">root</a><span>|</span><a href="#40663567">parent</a><span>|</span><a href="#40663296">next</a><span>|</span><label class="collapse" for="c-40663640">[-]</label><label class="expand" for="c-40663640">[2 more]</label></div><br/><div class="children"><div class="content">Technically speaking one of the foundational axioms of ZFC set theory is actually an axiom <i>schema</i>, or an infinite collection of axioms all grouped together. I have no idea how lean or isabelle treat them.</div><br/><div id="40664369" class="c"><input type="checkbox" id="c-40664369" checked=""/><div class="controls bullet"><span class="by">fspeech</span><span>|</span><a href="#40662534">root</a><span>|</span><a href="#40663640">parent</a><span>|</span><a href="#40663296">next</a><span>|</span><label class="collapse" for="c-40664369">[-]</label><label class="expand" for="c-40664369">[1 more]</label></div><br/><div class="children"><div class="content">Whether it needs to be a schema of an infinite number of axioms depends on how big the sets can be. In higher order logic the quantifiers can range over more types of objects.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40663296" class="c"><input type="checkbox" id="c-40663296" checked=""/><div class="controls bullet"><span class="by">szvsw</span><span>|</span><a href="#40662534">parent</a><span>|</span><a href="#40662655">prev</a><span>|</span><a href="#40666189">next</a><span>|</span><label class="collapse" for="c-40663296">[-]</label><label class="expand" for="c-40663296">[1 more]</label></div><br/><div class="children"><div class="content">Chess and Go are some of the simplest board games there are. Board gamers would put them in the very low “weight” rankings from a rules complexity perspective (compared to ”modern” board games)!<p>Mathematics are infinitely (ha) more complex. Work your way up to understanding (at least partially) a proof of Gödel’s incompleteness theorem and then you will agree! Apologies if you have done that already.<p>To some extent, mathematics is a bit like drunkards looking for a coin at night under a streetlight because that’s where the light is… there’s a whole lot more out there though (quote from a prof in undergrad)</div><br/></div></div><div id="40666189" class="c"><input type="checkbox" id="c-40666189" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#40662534">parent</a><span>|</span><a href="#40663296">prev</a><span>|</span><a href="#40663612">next</a><span>|</span><label class="collapse" for="c-40666189">[-]</label><label class="expand" for="c-40666189">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Unless mathematics is fundamentally more complicated than chess or go<p>&quot;Fundamentally&quot; carries the weight of the whole solar system here. Everyone knows mathematics is more conceptually and computationally complicated than chess.<p>But of course every person has different opinions on what makes two things &quot;fundamentally&quot; different so this is a tautology statement.</div><br/></div></div><div id="40663612" class="c"><input type="checkbox" id="c-40663612" checked=""/><div class="controls bullet"><span class="by">hwayne</span><span>|</span><a href="#40662534">parent</a><span>|</span><a href="#40666189">prev</a><span>|</span><a href="#40663610">next</a><span>|</span><label class="collapse" for="c-40663612">[-]</label><label class="expand" for="c-40663612">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Unless mathematics is fundamentally more complicated than chess or go, I don&#x27;t see why that could not happen.<p>My usual comparison is Sokoban: there are still lots of levels that humans can beat that all Sokoban AIs cannot, including the AIs that came out of Deepmind and Google. The problem is that the training set is so much smaller, and the success heuristics so much more exacting, that we can&#x27;t get the same benefits from scale as we do with chess. Math is even harder than that.<p>(I wonder if there&#x27;s something innate about &quot;planning problems&quot; that makes them hard for AI to do.)</div><br/></div></div></div></div><div id="40663610" class="c"><input type="checkbox" id="c-40663610" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#40662534">prev</a><span>|</span><a href="#40662029">next</a><span>|</span><label class="collapse" for="c-40663610">[-]</label><label class="expand" for="c-40663610">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Let’s say an AI supplies an incomprehensible, ugly proof. Then you can work with it, and you can analyze it. Suppose this proof uses 10 hypotheses to get one conclusion—if I delete one hypothesis, does the proof still work? That’s a science that doesn’t really exist yet because we don’t have so many AI-generated proofs, but I think there will be a new type of mathematician that will take AI-generated mathematics and make it more comprehensible.<p>My thoughts exactly about designing public APIs of code. A role which traditionally performed only by experienced developers, now it can be greatly simplified and accessible to everyone.</div><br/></div></div><div id="40662029" class="c"><input type="checkbox" id="c-40662029" checked=""/><div class="controls bullet"><span class="by">zero_k</span><span>|</span><a href="#40663610">prev</a><span>|</span><a href="#40662225">next</a><span>|</span><label class="collapse" for="c-40662029">[-]</label><label class="expand" for="c-40662029">[1 more]</label></div><br/><div class="children"><div class="content">Proofs and proof checking is also big in SAT solving (think: MiniSat) and SMT (think: z3, cvc5). It&#x27;s also coming to model counting (counting the number of solutions). In fact, we did one in Isabelle for an approximate model counter [1], that provides probabilistically approximate count (a so-called PAC guarantee), which is a lot harder to do, due to the probabilistic nature.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;meelgroup&#x2F;approxmc">https:&#x2F;&#x2F;github.com&#x2F;meelgroup&#x2F;approxmc</a></div><br/></div></div><div id="40662225" class="c"><input type="checkbox" id="c-40662225" checked=""/><div class="controls bullet"><span class="by">dorfsmay</span><span>|</span><a href="#40662029">prev</a><span>|</span><a href="#40660176">next</a><span>|</span><label class="collapse" for="c-40662225">[-]</label><label class="expand" for="c-40662225">[6 more]</label></div><br/><div class="children"><div class="content">I just spent hours looking at formal methods and had decided to learn Isabelle&#x2F;HOL, then this article !</div><br/><div id="40664443" class="c"><input type="checkbox" id="c-40664443" checked=""/><div class="controls bullet"><span class="by">fspeech</span><span>|</span><a href="#40662225">parent</a><span>|</span><a href="#40662637">next</a><span>|</span><label class="collapse" for="c-40664443">[-]</label><label class="expand" for="c-40664443">[1 more]</label></div><br/><div class="children"><div class="content">I would recommend HOL Light and Lean. HOL Light is no longer being developed. It&#x27;s very self contained and the foundation is very simple to comprehend. It&#x27;s great for learning ATP, not the least due to the fact that Harrison wrote a nice companion book. And OCaml these days is very easy to access. I also developed a way to run it natively (<a href="https:&#x2F;&#x2F;github.com&#x2F;htzh&#x2F;holnat">https:&#x2F;&#x2F;github.com&#x2F;htzh&#x2F;holnat</a>), which, while slightly less pretty, makes loading and reloading significantly faster.</div><br/></div></div><div id="40662637" class="c"><input type="checkbox" id="c-40662637" checked=""/><div class="controls bullet"><span class="by">garbthetill</span><span>|</span><a href="#40662225">parent</a><span>|</span><a href="#40664443">prev</a><span>|</span><a href="#40660176">next</a><span>|</span><label class="collapse" for="c-40662637">[-]</label><label class="expand" for="c-40662637">[4 more]</label></div><br/><div class="children"><div class="content">may i ask why isabelle over agda or lean?</div><br/><div id="40663137" class="c"><input type="checkbox" id="c-40663137" checked=""/><div class="controls bullet"><span class="by">dorfsmay</span><span>|</span><a href="#40662225">root</a><span>|</span><a href="#40662637">parent</a><span>|</span><a href="#40663732">next</a><span>|</span><label class="collapse" for="c-40663137">[-]</label><label class="expand" for="c-40663137">[2 more]</label></div><br/><div class="children"><div class="content">I know nothing, I am a complete beginner when it comes to formal methods. From reading about it, it seems that Isabelle&#x2F;HOL is the best when it comes to automation which apparently is something you really want. It might be easier to learn (controversial, some say Lean is easier). It&#x27;s been used to prove some software (including sel4 and a version of java), Apple and AWS are using it (but then I know AWS uses, or used, TLA+).<p>At the end of the day, I didn&#x27;t want to spend more time reading about it then learning two of them (trying one and potentially switch later). The more you read about it, the more options open up (SPARK, TLA+, COQ, etc...).<p>I do find it ironic to read this article today given that I made that decision yesterday!</div><br/><div id="40663650" class="c"><input type="checkbox" id="c-40663650" checked=""/><div class="controls bullet"><span class="by">hwayne</span><span>|</span><a href="#40662225">root</a><span>|</span><a href="#40663137">parent</a><span>|</span><a href="#40663732">next</a><span>|</span><label class="collapse" for="c-40663650">[-]</label><label class="expand" for="c-40663650">[1 more]</label></div><br/><div class="children"><div class="content">[shameless plug]I maintain a collection of proofs of leftpad in different prover languages, so people can compare them. It&#x27;s here: <a href="https:&#x2F;&#x2F;github.com&#x2F;hwayne&#x2F;lets-prove-leftpad">https:&#x2F;&#x2F;github.com&#x2F;hwayne&#x2F;lets-prove-leftpad</a><p>[&#x2F;invalid closing tag]</div><br/></div></div></div></div><div id="40663732" class="c"><input type="checkbox" id="c-40663732" checked=""/><div class="controls bullet"><span class="by">chaoskanzlerin</span><span>|</span><a href="#40662225">root</a><span>|</span><a href="#40662637">parent</a><span>|</span><a href="#40663137">prev</a><span>|</span><a href="#40660176">next</a><span>|</span><label class="collapse" for="c-40663732">[-]</label><label class="expand" for="c-40663732">[1 more]</label></div><br/><div class="children"><div class="content">The main upside Isabelle has over other proof assistants is the existence of Sledgehammer: invoke it, and your current proof state gets handed off to a SMT solver like cvc4, veriT, z3, vampire, etc. If the SMT solver finds a solution, Isabelle then reconstructs the proof.<p>It&#x27;s essentially a brute-force button that no other proof assistant (aside from Coq) has.</div><br/></div></div></div></div></div></div><div id="40660176" class="c"><input type="checkbox" id="c-40660176" checked=""/><div class="controls bullet"><span class="by">iamwil</span><span>|</span><a href="#40662225">prev</a><span>|</span><a href="#40628861">next</a><span>|</span><label class="collapse" for="c-40660176">[-]</label><label class="expand" for="c-40660176">[12 more]</label></div><br/><div class="children"><div class="content">A tangential topic, but anyone have recommendations for proof-checking languages? Lean, Isabelle, Coq, Idris are the few I know about. I&#x27;ve only ever used Isabelle, but can&#x27;t really tell the difference between them. Anyone here used more than one, and can tell why people pick one over the other?</div><br/><div id="40660800" class="c"><input type="checkbox" id="c-40660800" checked=""/><div class="controls bullet"><span class="by">tombert</span><span>|</span><a href="#40660176">parent</a><span>|</span><a href="#40660304">next</a><span>|</span><label class="collapse" for="c-40660800">[-]</label><label class="expand" for="c-40660800">[1 more]</label></div><br/><div class="children"><div class="content">Isabelle is my favorite, and it&#x27;s the one I&#x27;ve used the most, if only because sledgehammer is super cool, but Coq is neat as well.  It has coqhammer (a word I will not say at work), and that works ok but it didn&#x27;t seem to work as well as sledgehammer did for me.<p>Coq is much more type-theory focused, which I do think lends it a bit better to a regular programming language.  Isabelle feels a lot more predicate-logic and set-theory-ish to me, which is useful in its own right but I don&#x27;t feel maps quite as cleanly to code (though the Isabelle code exporter has generally worked fine).</div><br/></div></div><div id="40660304" class="c"><input type="checkbox" id="c-40660304" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#40660176">parent</a><span>|</span><a href="#40660800">prev</a><span>|</span><a href="#40664681">next</a><span>|</span><label class="collapse" for="c-40660304">[-]</label><label class="expand" for="c-40660304">[1 more]</label></div><br/><div class="children"><div class="content">They are pretty similar as languages. In general I would recommend Lean because the open source community is very active and helpful and you can easily get help with whatever you&#x27;re doing on Zulip. (Zulip is a Slack&#x2F;Discord alternative.) The other ones are technically open source but the developers are far less engaged with the public.<p>Proof-checking languages are still just quite hard to use, compared to a regular programming language. So you&#x27;re going to need assistance in order to get things done, and the Lean community is currently the best at that.</div><br/></div></div><div id="40664681" class="c"><input type="checkbox" id="c-40664681" checked=""/><div class="controls bullet"><span class="by">fspeech</span><span>|</span><a href="#40660176">parent</a><span>|</span><a href="#40660304">prev</a><span>|</span><a href="#40660943">next</a><span>|</span><label class="collapse" for="c-40664681">[-]</label><label class="expand" for="c-40664681">[1 more]</label></div><br/><div class="children"><div class="content">It depends on the kind of proofs you deal with. If you need to write math in general terms, you can&#x27;t avoid dealing with at some level the equivalent of category theory and you will want natural access to dependent types. So Coq and Lean. Otoh HOL is easy to comprehend and sufficient for almost everything else. And HOL based provers are designed to work with ATPs. HOL Light in particular is just another OCaml program and all terms and data structures can be easily manipulated in OCaml.</div><br/></div></div><div id="40660943" class="c"><input type="checkbox" id="c-40660943" checked=""/><div class="controls bullet"><span class="by">vzaliva</span><span>|</span><a href="#40660176">parent</a><span>|</span><a href="#40664681">prev</a><span>|</span><a href="#40660312">next</a><span>|</span><label class="collapse" for="c-40660943">[-]</label><label class="expand" for="c-40660943">[1 more]</label></div><br/><div class="children"><div class="content">One consideration in choosing a proof assistant is the type of proofs you are doing. For example, mathematicians often lean towards Lean (pun intended), while those in programming languages favour Coq or Isabelle, among others.</div><br/></div></div><div id="40660312" class="c"><input type="checkbox" id="c-40660312" checked=""/><div class="controls bullet"><span class="by">einszwei</span><span>|</span><a href="#40660176">parent</a><span>|</span><a href="#40660943">prev</a><span>|</span><a href="#40661778">next</a><span>|</span><label class="collapse" for="c-40660312">[-]</label><label class="expand" for="c-40660312">[1 more]</label></div><br/><div class="children"><div class="content">I have personally tried Coq and Lean and stuck to Lean as it has much better tooling, documentation and usability while being functionally similar to Coq.<p>Caveat that I have only used Coq and Lean side by side for about a month before deciding to stick with Lean.</div><br/></div></div><div id="40661778" class="c"><input type="checkbox" id="c-40661778" checked=""/><div class="controls bullet"><span class="by">trott</span><span>|</span><a href="#40660176">parent</a><span>|</span><a href="#40660312">prev</a><span>|</span><a href="#40660852">next</a><span>|</span><label class="collapse" for="c-40661778">[-]</label><label class="expand" for="c-40661778">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Metamath" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Metamath</a><p>Its smallest proof-checker is only 500 lines.</div><br/></div></div><div id="40660852" class="c"><input type="checkbox" id="c-40660852" checked=""/><div class="controls bullet"><span class="by">awfulneutral</span><span>|</span><a href="#40660176">parent</a><span>|</span><a href="#40661778">prev</a><span>|</span><a href="#40661415">next</a><span>|</span><label class="collapse" for="c-40660852">[-]</label><label class="expand" for="c-40660852">[1 more]</label></div><br/><div class="children"><div class="content">Another one is Oak: <a href="https:&#x2F;&#x2F;oakproof.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;oakproof.org&#x2F;</a></div><br/></div></div><div id="40661415" class="c"><input type="checkbox" id="c-40661415" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#40660176">parent</a><span>|</span><a href="#40660852">prev</a><span>|</span><a href="#40660279">next</a><span>|</span><label class="collapse" for="c-40661415">[-]</label><label class="expand" for="c-40661415">[1 more]</label></div><br/><div class="children"><div class="content">As Tao says in the interview: Lean is the dominant one.</div><br/></div></div><div id="40660279" class="c"><input type="checkbox" id="c-40660279" checked=""/><div class="controls bullet"><span class="by">mathgradthrow</span><span>|</span><a href="#40660176">parent</a><span>|</span><a href="#40661415">prev</a><span>|</span><a href="#40628861">next</a><span>|</span><label class="collapse" for="c-40660279">[-]</label><label class="expand" for="c-40660279">[3 more]</label></div><br/><div class="children"><div class="content">Lean has the largest existing math library, but you&#x27;re kind of stuck in a microsoft ecosystem.</div><br/><div id="40661720" class="c"><input type="checkbox" id="c-40661720" checked=""/><div class="controls bullet"><span class="by">ykonstant</span><span>|</span><a href="#40660176">root</a><span>|</span><a href="#40660279">parent</a><span>|</span><a href="#40660558">next</a><span>|</span><label class="collapse" for="c-40661720">[-]</label><label class="expand" for="c-40661720">[1 more]</label></div><br/><div class="children"><div class="content">If you mean dependence on VS Code, there are emacs and neovim packages for Lean; some of the core devs use those exclusively.  Also note that de Moura is no longer at Microsoft and Lean is not an MS product.</div><br/></div></div><div id="40660558" class="c"><input type="checkbox" id="c-40660558" checked=""/><div class="controls bullet"><span class="by">mkehrt</span><span>|</span><a href="#40660176">root</a><span>|</span><a href="#40660279">parent</a><span>|</span><a href="#40661720">prev</a><span>|</span><a href="#40628861">next</a><span>|</span><label class="collapse" for="c-40660558">[-]</label><label class="expand" for="c-40660558">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure what you mean.  I&#x27;ve been playing around with Lean and it works fine on a Mac.  I am using VSCode, though.</div><br/></div></div></div></div></div></div><div id="40628861" class="c"><input type="checkbox" id="c-40628861" checked=""/><div class="controls bullet"><span class="by">sylware</span><span>|</span><a href="#40660176">prev</a><span>|</span><a href="#40649404">next</a><span>|</span><label class="collapse" for="c-40628861">[-]</label><label class="expand" for="c-40628861">[2 more]</label></div><br/><div class="children"><div class="content">I took us only Terence Tao to speak out loud about the ego of many mathematicians refusing to consider &quot;AI&quot; as a potential assistant.<p>We may realise we need much bigger neural net and training facilities, different models.<p>And in end, it can be a failure.<p>You know, R&amp;D.</div><br/></div></div><div id="40649404" class="c"><input type="checkbox" id="c-40649404" checked=""/><div class="controls bullet"><span class="by">rthnbgrredf</span><span>|</span><a href="#40628861">prev</a><span>|</span><a href="#40663851">next</a><span>|</span><label class="collapse" for="c-40649404">[-]</label><label class="expand" for="c-40649404">[1 more]</label></div><br/><div class="children"><div class="content">Will be interesting when they become able to autocomplete current research topics correctly.</div><br/></div></div><div id="40663851" class="c"><input type="checkbox" id="c-40663851" checked=""/><div class="controls bullet"><span class="by">mik1998</span><span>|</span><a href="#40649404">prev</a><span>|</span><a href="#40647242">next</a><span>|</span><label class="collapse" for="c-40663851">[-]</label><label class="expand" for="c-40663851">[1 more]</label></div><br/><div class="children"><div class="content">All I can read from this article is &quot;the end of mathematics is on the horizon&quot;. Hopefully nothing he says actually materializes.</div><br/></div></div><div id="40648574" class="c"><input type="checkbox" id="c-40648574" checked=""/><div class="controls bullet"><span class="by">aeternum</span><span>|</span><a href="#40647242">prev</a><span>|</span><a href="#40659220">next</a><span>|</span><label class="collapse" for="c-40648574">[-]</label><label class="expand" for="c-40648574">[2 more]</label></div><br/><div class="children"><div class="content">How about:  AI will become everyone&#x27;s co-pilot<p>Now we don&#x27;t need to write hundreds of additional articles.</div><br/><div id="40649151" class="c"><input type="checkbox" id="c-40649151" checked=""/><div class="controls bullet"><span class="by">ProllyInfamous</span><span>|</span><a href="#40648574">parent</a><span>|</span><a href="#40659220">next</a><span>|</span><label class="collapse" for="c-40649151">[-]</label><label class="expand" for="c-40649151">[1 more]</label></div><br/><div class="children"><div class="content">~&quot;You don&#x27;t ever want to be a company programming a bot for a company which is designed to program bots, to program bots, programming bots programming bots.&quot;~ [1]<p>—Mark Zuckerberg, probably [actually not].<p>I am not a robot, but the above limerick&#x27;s author.<p>RIP to my IRL humanbro, who recently programmed himself out of his kushy SalesForce job.<p>Welcome... to The Future™.<p>--<p>[1] Paraphrasing Zuckerberg saying he doesn&#x27;t think a structure of &quot;just managers managing managers&quot; is ideal.</div><br/></div></div></div></div><div id="40659220" class="c"><input type="checkbox" id="c-40659220" checked=""/><div class="controls bullet"><span class="by">boyka</span><span>|</span><a href="#40648574">prev</a><span>|</span><a href="#40661662">next</a><span>|</span><label class="collapse" for="c-40659220">[-]</label><label class="expand" for="c-40659220">[11 more]</label></div><br/><div class="children"><div class="content">Isn’t proof checking at least as hard as k-sat and therefore NP? Given that neural networks process in constant time, how would that be possible without approximation?</div><br/><div id="40659570" class="c"><input type="checkbox" id="c-40659570" checked=""/><div class="controls bullet"><span class="by">memkit</span><span>|</span><a href="#40659220">parent</a><span>|</span><a href="#40659385">next</a><span>|</span><label class="collapse" for="c-40659570">[-]</label><label class="expand" for="c-40659570">[1 more]</label></div><br/><div class="children"><div class="content">This is kind of amusing because NP problems, by definition, must have a polynomial-length <i>certification</i> to a given solution that can be run in polynomial time.<p>The word &quot;certification&quot; can be read as &quot;proof&quot; without loss of meaning.<p>What you&#x27;re asking is slightly different: whether the proof-checking problem in logic is NP. I don&#x27;t know enough math to know for sure, but assuming that any proof can be found in polynomial time by a <i>non-deterministic</i> Turing machine and that such a proof is polynomial in length, then yes, the proof-checking problem is in NP. Alas, I think that all of that is moot because Turing and Church&#x27;s answer in the negative to the <i>Entscheidungsproblem</i> [1].<p>It would help your understanding and everyone else&#x27;s if you separated the <i>search problem</i> for a proof from the <i>verification problem</i> of a proof. Something is NP when you can provide verification that runs in polynomial time. The lesser spoken about second condition is that the search problem must be solved in polynomial time by a non-deterministic Turing machine. Problems which don&#x27;t meet the second condition are generally only of theoretical value.<p>1. <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Entscheidungsproblem" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Entscheidungsproblem</a></div><br/></div></div><div id="40659385" class="c"><input type="checkbox" id="c-40659385" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#40659220">parent</a><span>|</span><a href="#40659570">prev</a><span>|</span><a href="#40659502">next</a><span>|</span><label class="collapse" for="c-40659385">[-]</label><label class="expand" for="c-40659385">[1 more]</label></div><br/><div class="children"><div class="content">Checking a proof is much easier than finding it.</div><br/></div></div><div id="40659502" class="c"><input type="checkbox" id="c-40659502" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#40659220">parent</a><span>|</span><a href="#40659385">prev</a><span>|</span><a href="#40659318">next</a><span>|</span><label class="collapse" for="c-40659502">[-]</label><label class="expand" for="c-40659502">[1 more]</label></div><br/><div class="children"><div class="content">Most k-sat problems are easy, or can be reduced to a smaller and easier version of k-sat. Neural networks might be able to write Lean or Coq to feed into a theorem prover.</div><br/></div></div><div id="40659318" class="c"><input type="checkbox" id="c-40659318" checked=""/><div class="controls bullet"><span class="by">empath75</span><span>|</span><a href="#40659220">parent</a><span>|</span><a href="#40659502">prev</a><span>|</span><a href="#40659427">next</a><span>|</span><label class="collapse" for="c-40659318">[-]</label><label class="expand" for="c-40659318">[1 more]</label></div><br/><div class="children"><div class="content">This article isn&#x27;t about using neural networks for proof checking, but just using them to assist with writing Lean programs in the same way that developers use co-pilot to write java code or whatever.  It might just spit out boilerplate code for you, of which there still is a great deal in formal proofs.<p>The proof checking is still actually done with normal proof checking programs.</div><br/></div></div><div id="40659427" class="c"><input type="checkbox" id="c-40659427" checked=""/><div class="controls bullet"><span class="by">AnimalMuppet</span><span>|</span><a href="#40659220">parent</a><span>|</span><a href="#40659318">prev</a><span>|</span><a href="#40659243">next</a><span>|</span><label class="collapse" for="c-40659427">[-]</label><label class="expand" for="c-40659427">[1 more]</label></div><br/><div class="children"><div class="content">Neural networks process in constant time <i>per input&#x2F;output</i> (token or whatever).  But some prompts could produce more tokens.<p>As you increase the size of the window, doesn&#x27;t the size of the NN have to increase?  So if you want to just use an NN for this, the bigger the problem it can handle, the bigger the window, so the longer per token produced; but also the more tokens produced, so it&#x27;s longer on that front as well.  I don&#x27;t know if that adds up to polynomial time or not.<p>Note well:  I&#x27;m not disagreeing with your overall assertion.  I don&#x27;t know if NNs can do this; I&#x27;m inclined to think they can&#x27;t.  All I&#x27;m saying is that even NNs are not constant time in problem size.</div><br/></div></div><div id="40659243" class="c"><input type="checkbox" id="c-40659243" checked=""/><div class="controls bullet"><span class="by">hollerith</span><span>|</span><a href="#40659220">parent</a><span>|</span><a href="#40659427">prev</a><span>|</span><a href="#40659494">next</a><span>|</span><label class="collapse" for="c-40659243">[-]</label><label class="expand" for="c-40659243">[4 more]</label></div><br/><div class="children"><div class="content">No.</div><br/><div id="40659247" class="c"><input type="checkbox" id="c-40659247" checked=""/><div class="controls bullet"><span class="by">boyka</span><span>|</span><a href="#40659220">root</a><span>|</span><a href="#40659243">parent</a><span>|</span><a href="#40659494">next</a><span>|</span><label class="collapse" for="c-40659247">[-]</label><label class="expand" for="c-40659247">[3 more]</label></div><br/><div class="children"><div class="content">Care to explain?<p>E.g. <a href="https:&#x2F;&#x2F;mathoverflow.net&#x2F;questions&#x2F;226966&#x2F;algorithmic-complexity-of-formal-proof-verification" rel="nofollow">https:&#x2F;&#x2F;mathoverflow.net&#x2F;questions&#x2F;226966&#x2F;algorithmic-comple...</a></div><br/><div id="40659324" class="c"><input type="checkbox" id="c-40659324" checked=""/><div class="controls bullet"><span class="by">markisus</span><span>|</span><a href="#40659220">root</a><span>|</span><a href="#40659247">parent</a><span>|</span><a href="#40659330">next</a><span>|</span><label class="collapse" for="c-40659324">[-]</label><label class="expand" for="c-40659324">[1 more]</label></div><br/><div class="children"><div class="content">A proof is basically a directed graph where nodes are propositions, and edges are deductive rules. One only needs to check that the starting nodes are axioms and that each edge is one of a finite set of deduction rules in the system. So the time to check a proof is linear in the number of edges.</div><br/></div></div></div></div></div></div><div id="40659494" class="c"><input type="checkbox" id="c-40659494" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#40659220">parent</a><span>|</span><a href="#40659243">prev</a><span>|</span><a href="#40661662">next</a><span>|</span><label class="collapse" for="c-40659494">[-]</label><label class="expand" for="c-40659494">[1 more]</label></div><br/><div class="children"><div class="content">Humans run in constant time. So yeah it depends on the constant factor.</div><br/></div></div></div></div><div id="40661662" class="c"><input type="checkbox" id="c-40661662" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#40659220">prev</a><span>|</span><a href="#40664636">next</a><span>|</span><label class="collapse" for="c-40661662">[-]</label><label class="expand" for="c-40661662">[1 more]</label></div><br/><div class="children"><div class="content">&gt; German mathematician and Fields Medalist Peter Scholze collaborated in a Lean project—even though he told me he doesn’t know much about computers.<p>&gt; With these formalization projects, not everyone needs to be a programmer. Some people can just focus on the mathematical direction; you’re just splitting up a big mathematical task into lots of smaller pieces. And then there are people who specialize in turning those smaller pieces into formal proofs. We don’t need everybody to be a programmer; we just need some people to be programmers. It’s a division of labor.<p>Who can get paid to be a &quot;mathematical programmer&quot; ?<p>PhD mathematicians? Grad students?</div><br/></div></div><div id="40664636" class="c"><input type="checkbox" id="c-40664636" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#40661662">prev</a><span>|</span><a href="#40659435">next</a><span>|</span><label class="collapse" for="c-40664636">[-]</label><label class="expand" for="c-40664636">[1 more]</label></div><br/><div class="children"><div class="content">The signal of AGI is if it can help solve a hard problem or create a new one</div><br/></div></div><div id="40659435" class="c"><input type="checkbox" id="c-40659435" checked=""/><div class="controls bullet"><span class="by">qsort</span><span>|</span><a href="#40664636">prev</a><span>|</span><a href="#40661013">next</a><span>|</span><label class="collapse" for="c-40659435">[-]</label><label class="expand" for="c-40659435">[3 more]</label></div><br/><div class="children"><div class="content">&quot;their time frame is maybe a little bit aggressive&quot; has to be the nicest way I&#x27;ve ever heard someone say &quot;they&#x27;re full of shit&quot;.</div><br/><div id="40660755" class="c"><input type="checkbox" id="c-40660755" checked=""/><div class="controls bullet"><span class="by">hyperfuturism</span><span>|</span><a href="#40659435">parent</a><span>|</span><a href="#40661013">next</a><span>|</span><label class="collapse" for="c-40660755">[-]</label><label class="expand" for="c-40660755">[2 more]</label></div><br/><div class="children"><div class="content">I think he&#x27;s being quite literal in that he believes that they&#x27;re too aggressive.<p>In the article he does afterall second the notion that AI will eventually replace a lot of human labour related to mathematics.</div><br/><div id="40661822" class="c"><input type="checkbox" id="c-40661822" checked=""/><div class="controls bullet"><span class="by">qsort</span><span>|</span><a href="#40659435">root</a><span>|</span><a href="#40660755">parent</a><span>|</span><a href="#40661013">next</a><span>|</span><label class="collapse" for="c-40661822">[-]</label><label class="expand" for="c-40661822">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not reading it that way, I don&#x27;t know where you are getting &quot;AI will eventually replace...&quot; from, if anything he seems to have the opposite idea: &quot;even if AI can do the type of mathematics we do now, it means that we will just move to a to a higher type of mathematics&quot;.<p>The line I quoted is in response to &quot;in two to three years mathematics will be “solved” in the same sense that chess is solved&quot;.<p>Unless my priors are dramatically wrong, anyone who believes <i>that</i> is indeed full of shit.</div><br/></div></div></div></div></div></div><div id="40661013" class="c"><input type="checkbox" id="c-40661013" checked=""/><div class="controls bullet"><span class="by">thecleaner</span><span>|</span><a href="#40659435">prev</a><span>|</span><a href="#40666340">next</a><span>|</span><label class="collapse" for="c-40661013">[-]</label><label class="expand" for="c-40661013">[2 more]</label></div><br/><div class="children"><div class="content">Does Lean work with linear slgebra proofs ?</div><br/><div id="40661706" class="c"><input type="checkbox" id="c-40661706" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#40661013">parent</a><span>|</span><a href="#40666340">next</a><span>|</span><label class="collapse" for="c-40661706">[-]</label><label class="expand" for="c-40661706">[1 more]</label></div><br/><div class="children"><div class="content">You need to ask a more specific question.<p><a href="https:&#x2F;&#x2F;leanprover-community.github.io&#x2F;theories&#x2F;linear_algebra.html" rel="nofollow">https:&#x2F;&#x2F;leanprover-community.github.io&#x2F;theories&#x2F;linear_algeb...</a></div><br/></div></div></div></div><div id="40664821" class="c"><input type="checkbox" id="c-40664821" checked=""/><div class="controls bullet"><span class="by">throwme_123</span><span>|</span><a href="#40666340">prev</a><span>|</span><a href="#40659856">next</a><span>|</span><label class="collapse" for="c-40664821">[-]</label><label class="expand" for="c-40664821">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Elon Must&quot;</div><br/></div></div><div id="40659856" class="c"><input type="checkbox" id="c-40659856" checked=""/><div class="controls bullet"><span class="by">ur-whale</span><span>|</span><a href="#40664821">prev</a><span>|</span><a href="#40665495">next</a><span>|</span><label class="collapse" for="c-40659856">[-]</label><label class="expand" for="c-40659856">[11 more]</label></div><br/><div class="children"><div class="content">Relying on GPT style systems to translate high level math to lean stuff strikes me as dangerous unless you&#x27;re going to double-check by hand that the LLM didn&#x27;t suddenly decide to hallucinate parts of the answer.<p>Granted, the hallucinated part might not pass the final Lean verification, but ... what if it does because the LLM did not properly translate the mathematician&#x27;s intent to Lean language?<p>I&#x27;m thinking the human will still need to read the Lean program, understand it and double-check that his original human intent was properly codified.<p>Better than having to produce it by hand, but still sub-optimal.</div><br/><div id="40661346" class="c"><input type="checkbox" id="c-40661346" checked=""/><div class="controls bullet"><span class="by">m4lvin</span><span>|</span><a href="#40659856">parent</a><span>|</span><a href="#40660692">next</a><span>|</span><label class="collapse" for="c-40661346">[-]</label><label class="expand" for="c-40661346">[2 more]</label></div><br/><div class="children"><div class="content">The trick is that the human only needs to read and understand the Lean <i>statement</i> of a theorem and agree that it (with all involved definitions) indeed represents the original mathematical statement, but not the <i>proof</i>. Because that the proof is indeed proving the statement is what Lean checks. We do not need to trust the LLM in any way.<p>So would I accept a proof made by GPT or whatever? Yes. But not a (re)definition.<p>The analogy for programming is that if someone manages to write a function with a certain input and output types, and the compiler accepts it, then we do know that indeed someone managed to write a function of that type. Of course we have no idea about the behaviour, but statements&#x2F;theorems are types, not values :-)</div><br/><div id="40661534" class="c"><input type="checkbox" id="c-40661534" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#40659856">root</a><span>|</span><a href="#40661346">parent</a><span>|</span><a href="#40660692">next</a><span>|</span><label class="collapse" for="c-40661534">[-]</label><label class="expand" for="c-40661534">[1 more]</label></div><br/><div class="children"><div class="content">The thing is, when AI systems are able to translate intuitive natural language proofs into formal Lean code, they will also be used to translate intuitive concepts into formal Lean definitions. And then we can&#x27;t be sure whether those definitions actually define the concepts they are named after.</div><br/></div></div></div></div><div id="40660692" class="c"><input type="checkbox" id="c-40660692" checked=""/><div class="controls bullet"><span class="by">constantcrying</span><span>|</span><a href="#40659856">parent</a><span>|</span><a href="#40661346">prev</a><span>|</span><a href="#40659988">next</a><span>|</span><label class="collapse" for="c-40660692">[-]</label><label class="expand" for="c-40660692">[1 more]</label></div><br/><div class="children"><div class="content">There is no danger. If the output of the Neural net is wrong, then Lean will catch it.<p>&gt;what if it does because the LLM did not properly translate the mathematician&#x27;s intent to Lean language?<p>How so? The one thing which definitely needs to be checked by hand is the theorem to be proven, which obviously shouldn&#x27;t be provided by a Neural network. The NN will try to find the proof, which is then verified by Lean, but fundamentally the NN can&#x27;t prove the wrong theorem and have it verified by Lean.</div><br/></div></div><div id="40659988" class="c"><input type="checkbox" id="c-40659988" checked=""/><div class="controls bullet"><span class="by">kccqzy</span><span>|</span><a href="#40659856">parent</a><span>|</span><a href="#40660692">prev</a><span>|</span><a href="#40661046">next</a><span>|</span><label class="collapse" for="c-40659988">[-]</label><label class="expand" for="c-40659988">[1 more]</label></div><br/><div class="children"><div class="content">I disagree. I think if the hallucinated part pass the final Lean verification, it would actually be trivial for a mathematician to verify the intent is reflected in the theorem.<p>And also, in this case, doesn&#x27;t the mathematician first come up with a theorem and then engage AI to find a proof? I believe that&#x27;s what Terence did recently by following his Mastodon threads a while ago. Therefore that intent verification can be skipped too. Lean can act as the final arbiter of whether the AI produces something correct or not.</div><br/></div></div><div id="40661046" class="c"><input type="checkbox" id="c-40661046" checked=""/><div class="controls bullet"><span class="by">jerf</span><span>|</span><a href="#40659856">parent</a><span>|</span><a href="#40659988">prev</a><span>|</span><a href="#40665495">next</a><span>|</span><label class="collapse" for="c-40661046">[-]</label><label class="expand" for="c-40661046">[6 more]</label></div><br/><div class="children"><div class="content">GPT != AI. GPT is a subset of AI. GPT is probably absolutely useless for high-level math, if for no other reason that to be useful you&#x27;d need training data that basically by definition doesn&#x27;t exist. Though I am also strongly inclined to believe that LLMs are constitutionally incapable of functioning at that level of math regardless, because that&#x27;s simply not what they are designed to do.<p>But AI doesn&#x27;t have to mean LLMs, recent narrowing of the term&#x27;s meaning notwithstanding. There&#x27;s all kinds of ways AIs in the more general sense could assist with proof writing in a proof language, and do it in a way that each step is still sound and reliable.<p>In fact once you accept you&#x27;re working in a proof language like lean, the LLM part of the problem goes away. The AIs can work directly on such a language, the problems LLMs solve simply aren&#x27;t present. There&#x27;s no need to understand a high-context, fuzzy-grammar, background-laden set of symbols anymore. Also no problem with the AI &quot;explaining&quot; its thinking. We might still not be able to follow too large an explanation, but it would certainly be present even so, in a way that neural nets don&#x27;t necessarily have one.</div><br/><div id="40664352" class="c"><input type="checkbox" id="c-40664352" checked=""/><div class="controls bullet"><span class="by">emporas</span><span>|</span><a href="#40659856">root</a><span>|</span><a href="#40661046">parent</a><span>|</span><a href="#40661692">next</a><span>|</span><label class="collapse" for="c-40664352">[-]</label><label class="expand" for="c-40664352">[1 more]</label></div><br/><div class="children"><div class="content">High level math, is made from a lot of low level math combined together to form the high level, right? You can definitely use tools like GPT to write the low level math.<p>It doesn&#x27;t work the same for all use cases, training data do play a role certainly.</div><br/></div></div><div id="40661692" class="c"><input type="checkbox" id="c-40661692" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#40659856">root</a><span>|</span><a href="#40661046">parent</a><span>|</span><a href="#40664352">prev</a><span>|</span><a href="#40665495">next</a><span>|</span><label class="collapse" for="c-40661692">[-]</label><label class="expand" for="c-40661692">[4 more]</label></div><br/><div class="children"><div class="content">&gt; GPT is probably absolutely useless for high-level math<p>Terence Tao disagrees with you.<p><a href="https:&#x2F;&#x2F;mathstodon.xyz&#x2F;@tao&#x2F;110601051375142142" rel="nofollow">https:&#x2F;&#x2F;mathstodon.xyz&#x2F;@tao&#x2F;110601051375142142</a></div><br/><div id="40662140" class="c"><input type="checkbox" id="c-40662140" checked=""/><div class="controls bullet"><span class="by">jerf</span><span>|</span><a href="#40659856">root</a><span>|</span><a href="#40661692">parent</a><span>|</span><a href="#40661916">next</a><span>|</span><label class="collapse" for="c-40662140">[-]</label><label class="expand" for="c-40662140">[1 more]</label></div><br/><div class="children"><div class="content">If it could be solved with a Math Overflow-post level of effort, even from Terence Tao, it isn&#x27;t what I was talking about as &quot;high level math&quot;.<p>I also am not surprised by &quot;Consider a generation function&quot; coming out of an LLM. I am talking about a system that could <i>solve</i> that problem, entirely, as doing high level math. A system that can emit &quot;have you considered using wood?&quot; is not a system that can build a house autonomously.<p>It especially won&#x27;t seem all that useful next to the generation of AIs I anticipate to be coming which use LLMs as a component to understand the world but are not just big LLMs.</div><br/></div></div><div id="40661916" class="c"><input type="checkbox" id="c-40661916" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#40659856">root</a><span>|</span><a href="#40661692">parent</a><span>|</span><a href="#40662140">prev</a><span>|</span><a href="#40665495">next</a><span>|</span><label class="collapse" for="c-40661916">[-]</label><label class="expand" for="c-40661916">[2 more]</label></div><br/><div class="children"><div class="content">This tool is like all other tools in that expert practitioners extract value from it and novices consider it useless. Fascinating. The advent of search engines was similar with many remarking on how if you searched for something sometimes you&#x27;d find websites that were wrong. Things change and yet stay the same. At the time I thought age was the discriminator. Today I know it&#x27;s not that. It&#x27;s something else.</div><br/><div id="40664863" class="c"><input type="checkbox" id="c-40664863" checked=""/><div class="controls bullet"><span class="by">fspeech</span><span>|</span><a href="#40659856">root</a><span>|</span><a href="#40661916">parent</a><span>|</span><a href="#40665495">next</a><span>|</span><label class="collapse" for="c-40664863">[-]</label><label class="expand" for="c-40664863">[1 more]</label></div><br/><div class="children"><div class="content">But this shows you that the tools (LLMs included) don&#x27;t understand what they are producing. It takes an expert to extract the value. The tools do enrich the probability distribution greatly, raising the concentration of solutions much above the noise floor. But still they are only amplifiers. Even if they can get over the stage of producing apparent nonsense in the end they still can&#x27;t get into the user&#x27;s head to see what is exactly desired, and a precise specification of the intention takes experience and effort. A precise specification of a program can exceed in effort that of actually writing the program.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40665495" class="c"><input type="checkbox" id="c-40665495" checked=""/><div class="controls bullet"><span class="by">idkdotcom</span><span>|</span><a href="#40659856">prev</a><span>|</span><a href="#40647258">next</a><span>|</span><label class="collapse" for="c-40665495">[-]</label><label class="expand" for="c-40665495">[1 more]</label></div><br/><div class="children"><div class="content">I have great respect for Terry Tao but let&#x27;s not forget that while he won the Fields Medal at a relatively young age, he hasn&#x27;t made any major contribution to math comparable to proving Fermat&#x27;s Last Theorem (Andrew Wiles did), solving the Poincaré&#x27;s Conjecture (Grigori Perelman did) or Yitang Zhang&#x27;s proof progress towards solving the twin prime conjecture.<p>Perhaps for mathematicians like Terry Tao AI will be a tool they will rely on, but for mathematicians like the aforementioned, a pen, paper and the published research literature will continue to be their main tools!</div><br/></div></div><div id="40647258" class="c"><input type="checkbox" id="c-40647258" checked=""/><div class="controls bullet"><span class="by">pollimr</span><span>|</span><a href="#40665495">prev</a><span>|</span><label class="collapse" for="c-40647258">[-]</label><label class="expand" for="c-40647258">[2 more]</label></div><br/><div class="children"><div class="content">These tools, and subsequently their unethical parent companies, will be air gapped by length from my research.</div><br/><div id="40661066" class="c"><input type="checkbox" id="c-40661066" checked=""/><div class="controls bullet"><span class="by">rcpt</span><span>|</span><a href="#40647258">parent</a><span>|</span><label class="collapse" for="c-40661066">[-]</label><label class="expand" for="c-40661066">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;lean-lang.org&#x2F;about&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lean-lang.org&#x2F;about&#x2F;</a> is an open source project</div><br/></div></div></div></div></div></div></div></div></div></body></html>