<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1722330064774" as="style"/><link rel="stylesheet" href="styles.css?v=1722330064774"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://augmend.com/blog/TreeSeg">TreeSeg: Hierarchical Topic Segmentation of Large Transcripts</a> <span class="domain">(<a href="https://augmend.com">augmend.com</a>)</span></div><div class="subtext"><span>gklezd</span> | <span>8 comments</span></div><br/><div><div id="41106018" class="c"><input type="checkbox" id="c-41106018" checked=""/><div class="controls bullet"><span class="by">blackkettle</span><span>|</span><a href="#41103483">next</a><span>|</span><label class="collapse" for="c-41106018">[-]</label><label class="expand" for="c-41106018">[2 more]</label></div><br/><div class="children"><div class="content">This is quite interesting, but I have to ask, have you experimented much with larger LLMs as a mechanism to basically automate the entire process?<p>I&#x27;m doing something pretty similar right now for internal meetings and I use a process like: transcribe meeting with utterance timestamps, extract keyframes from video along with timestamps, request segmented summary from LLM along with rough timestamps for transitions, add keyframe analysis (mainly for slides).<p>gpt-4o, claude sonnet 3.5, llama 3.1 405b instruct, llama 3.1 70b instruct all do a pretty stunning job of this IMO.  Each department still reviews and edits the final result before sending it out, but I&#x27;m so far quite impressed with what we get from the default output even for 1-2hr conversations.<p>I&#x27;d argue the key feature for us is also still providing a simple, intuitive UI for non technical users to manage the final result, edit, polish and send it out.</div><br/><div id="41106226" class="c"><input type="checkbox" id="c-41106226" checked=""/><div class="controls bullet"><span class="by">gklezd</span><span>|</span><a href="#41106018">parent</a><span>|</span><a href="#41103483">next</a><span>|</span><label class="collapse" for="c-41106226">[-]</label><label class="expand" for="c-41106226">[1 more]</label></div><br/><div class="children"><div class="content">That is a great point! I can certainly think of cases where you might want to go with an LLM instead and
we have definitely experimented with that approach. Here are some reasons why we think TreeSeg is more
suitable for us:<p>1. A more algorithmic approach allows us to bake certain contraints into the model. As an example you can add
a regularizer to incentivize TreeSeg to split more eagerly when there are large pauses. You can also strictly
enforce minimum and maximum sizes on segments.<p>2. If you are interested in reproducing a segmentation with slight variations you might not have good results
with an LLM. Our experience has been that there is significant stochasticity in the answers we get from an LLM.
Even if you try to obtain a more deterministic answer (i.e. set temp to zero), you will need an exact copy of
the model to get the same result in the future. Depending on what LLM you are using this might not be possible
(e.g. OpenAI adjusts models frequently). With TreeSeg you only need your block-utterance embeddings, which you
probably have already stored (presumably in a vector db).<p>3. TreeSeg outputs a binary tree of segments and their sub-segments and so forth... This structure is important
to us for many reasons, some of which are subjects of future posts. One such reason is access to a continuum
between local (i.e. chapters) and global (i.e. full session) context. Obtaining such a hierarchy via an LLM
might not be that straightforward.<p>4. There is something attractive about not relying on an LLM for everything!<p>Hope this is useful to you!</div><br/></div></div></div></div><div id="41103483" class="c"><input type="checkbox" id="c-41103483" checked=""/><div class="controls bullet"><span class="by">gklezd</span><span>|</span><a href="#41106018">prev</a><span>|</span><a href="#41105425">next</a><span>|</span><label class="collapse" for="c-41103483">[-]</label><label class="expand" for="c-41103483">[3 more]</label></div><br/><div class="children"><div class="content">Here is a link to the preprint for more details: <a href="https:&#x2F;&#x2F;www.arxiv.org&#x2F;abs&#x2F;2407.12028" rel="nofollow">https:&#x2F;&#x2F;www.arxiv.org&#x2F;abs&#x2F;2407.12028</a></div><br/><div id="41106051" class="c"><input type="checkbox" id="c-41106051" checked=""/><div class="controls bullet"><span class="by">itronitron</span><span>|</span><a href="#41103483">parent</a><span>|</span><a href="#41105425">next</a><span>|</span><label class="collapse" for="c-41106051">[-]</label><label class="expand" for="c-41106051">[2 more]</label></div><br/><div class="children"><div class="content">The Visualization research community has historically had some papers that might be of interest to you, for example...<p>TOPIC ISLANDS — A Wavelet-Based Text Visualization System, <a href="https:&#x2F;&#x2F;www.computer.org&#x2F;csdl&#x2F;proceedings-article&#x2F;ieee-vis&#x2F;1998&#x2F;91760189&#x2F;12OmNvqEvKm" rel="nofollow">https:&#x2F;&#x2F;www.computer.org&#x2F;csdl&#x2F;proceedings-article&#x2F;ieee-vis&#x2F;1...</a></div><br/><div id="41106220" class="c"><input type="checkbox" id="c-41106220" checked=""/><div class="controls bullet"><span class="by">gklezd</span><span>|</span><a href="#41103483">root</a><span>|</span><a href="#41106051">parent</a><span>|</span><a href="#41105425">next</a><span>|</span><label class="collapse" for="c-41106220">[-]</label><label class="expand" for="c-41106220">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting indeed!</div><br/></div></div></div></div></div></div><div id="41105425" class="c"><input type="checkbox" id="c-41105425" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#41103483">prev</a><span>|</span><label class="collapse" for="c-41105425">[-]</label><label class="expand" for="c-41105425">[2 more]</label></div><br/><div class="children"><div class="content">Reminds me of this site VideoGist. They do a similar thing, breaking down transcripts into chapters and providing summaries for each chapter.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38555629">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38555629</a></div><br/><div id="41105741" class="c"><input type="checkbox" id="c-41105741" checked=""/><div class="controls bullet"><span class="by">gklezd</span><span>|</span><a href="#41105425">parent</a><span>|</span><label class="collapse" for="c-41105741">[-]</label><label class="expand" for="c-41105741">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the reference!<p>Note that we have open-sourced TreeSeg. You can find the repo here:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;AugmendTech&#x2F;treeseg">https:&#x2F;&#x2F;github.com&#x2F;AugmendTech&#x2F;treeseg</a><p>You can see its inner workings and use it directly or adapt it to your case.
Excited to see what folks can do with it!<p>P.S. I am the corresponding author on the paper.</div><br/></div></div></div></div></div></div></div></div></div></body></html>