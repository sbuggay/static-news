<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701853256376" as="style"/><link rel="stylesheet" href="styles.css?v=1701853256376"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2312.02120">Magicoder: Source Code Is All You Need</a>Â <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>tosh</span> | <span>64 comments</span></div><br/><div><div id="38541736" class="c"><input type="checkbox" id="c-38541736" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#38540020">next</a><span>|</span><label class="collapse" for="c-38541736">[-]</label><label class="expand" for="c-38541736">[1 more]</label></div><br/><div class="children"><div class="content">A couple of tests I&#x27;ve done in their live demo.<p>- Implement the quicksort algorithm in python. I like this test because usually LLMs do the first time using list comprehensions, then I ask to avoid allocations.<p>- Write the game &quot;snake&quot; in python, and then in JS&#x2F;HTML.<p>It succeeded on the simple quicksort implementation with list comprehensions, but failed when I asked for the in-place implementation. With the snake game tests, it didn&#x27;t get even close.<p>In my experience these results are worse than non-code top 7B LLMs such as OpenChat&#x2F;NeuralHermes, and significantly worse than plain Deepseek-coder-instruct 6.7B (which is the only small model I&#x27;ve tested that gets the &quot;snake&quot; game to work). When I ran these tests locally I used Q6 quantization (GGUF), and I assume their live demo is not quantized.<p>I find the benchmark results surprising, to the point I wonder if the benchmarks didn&#x27;t leak into the training set.</div><br/></div></div><div id="38540020" class="c"><input type="checkbox" id="c-38540020" checked=""/><div class="controls bullet"><span class="by">eyegor</span><span>|</span><a href="#38541736">prev</a><span>|</span><a href="#38538881">next</a><span>|</span><label class="collapse" for="c-38540020">[-]</label><label class="expand" for="c-38540020">[3 more]</label></div><br/><div class="children"><div class="content">For anyone looking to try this out on consumer grade hardware here&#x27;s a q4 version [0]. From initial testing it&#x27;s subjectively a bit behind deepseek-coder-instruct [1] at the same size and quantization. Deepseeks model is near magic when it behaves (1-2 tries), spitting out nicely formatted code fence blocks in markdown that I can naively render in real time to get a local chatgpt like experience. Magicoder can do this too, but it usually takes 3-4 tries and it tends to &quot;opt out&quot; and ask for more info pretty frequently. Of course if you have a ton of vram, use the 33b-instruct variant instead.<p>After more testing, I think it&#x27;s a toss up on most coding tasks but Magicoder tends to give subjectively better responses to &quot;bad prompts&quot;. That is, prompts where you don&#x27;t put effort into writing clear instructions. For example, one of my &quot;bad prompt&quot; tests is<p>&gt; how to enable shared gpu memory in wsl2 docker container<p>A good response to this would discuss the nvidia container toolkit, maybe something about port forwarding, etc. But this isn&#x27;t a prompt most models can give good responses to. Both of these models can handle it, even at 7b, but Magicoder gives more information.<p>[0] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;LoneStriker&#x2F;Magicoder-S-DS-6.7B-4.0bpw-h6-exl2" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;LoneStriker&#x2F;Magicoder-S-DS-6.7B-4.0bp...</a><p>[1] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;bartowski&#x2F;deepseek-coder-6.7b-instruct-exl2&#x2F;tree&#x2F;4_0" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;bartowski&#x2F;deepseek-coder-6.7b-instruc...</a></div><br/><div id="38541504" class="c"><input type="checkbox" id="c-38541504" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#38540020">parent</a><span>|</span><a href="#38541116">next</a><span>|</span><label class="collapse" for="c-38541504">[-]</label><label class="expand" for="c-38541504">[1 more]</label></div><br/><div class="children"><div class="content">&gt; spitting out nicely formatted code fence blocks in markdown that I can naively render in real time to get a local chatgpt like experience.<p>Not sure if understood, but in my experience almost every 7B instruct model does this if you add something like &quot;respond with markdown&quot; to the system prompt.<p>Chatbot-UI (A ChatGPT UI clone) handles markdown nicely and does code rendering in real time.</div><br/></div></div><div id="38541116" class="c"><input type="checkbox" id="c-38541116" checked=""/><div class="controls bullet"><span class="by">Hedepig</span><span>|</span><a href="#38540020">parent</a><span>|</span><a href="#38541504">prev</a><span>|</span><a href="#38538881">next</a><span>|</span><label class="collapse" for="c-38541116">[-]</label><label class="expand" for="c-38541116">[1 more]</label></div><br/><div class="children"><div class="content">&gt; tends to give subjectively better responses to &quot;bad prompts&quot;.<p>I wonder if a first pass with another model to expand these so called bad prompts into better prompts would work.</div><br/></div></div></div></div><div id="38538881" class="c"><input type="checkbox" id="c-38538881" checked=""/><div class="controls bullet"><span class="by">micimize</span><span>|</span><a href="#38540020">prev</a><span>|</span><a href="#38538408">next</a><span>|</span><label class="collapse" for="c-38538881">[-]</label><label class="expand" for="c-38538881">[5 more]</label></div><br/><div class="children"><div class="content">Any time I see humaneval comparisons I feel the need to point out that humaneval is only 164 questions. 66.5 vs. 65.9% is a difference between 109 and 108 solutions, a single question. Still interesting work though</div><br/><div id="38539490" class="c"><input type="checkbox" id="c-38539490" checked=""/><div class="controls bullet"><span class="by">moyix</span><span>|</span><a href="#38538881">parent</a><span>|</span><a href="#38539362">next</a><span>|</span><label class="collapse" for="c-38539490">[-]</label><label class="expand" for="c-38539490">[1 more]</label></div><br/><div class="children"><div class="content">At least they used HumanEval+, which adds a bunch more test cases and fixes some errors in the original benchmark!</div><br/></div></div></div></div><div id="38538408" class="c"><input type="checkbox" id="c-38538408" checked=""/><div class="controls bullet"><span class="by">gsuuon</span><span>|</span><a href="#38538881">prev</a><span>|</span><a href="#38538201">next</a><span>|</span><label class="collapse" for="c-38538408">[-]</label><label class="expand" for="c-38538408">[2 more]</label></div><br/><div class="children"><div class="content">I think these smaller models really struggle with the reasoning aspect of writing decent code, I&#x27;m getting pretty nonsensical things out when asking it to fix fizzbuzz (though it made the right fix), like:<p><pre><code>  - Replaced &quot;i % 2 === 0&quot; with &quot;i % 3 === 0&quot;, because a number is divisible by 2 only if it&#x27;s divisible by 3.</code></pre></div><br/><div id="38541560" class="c"><input type="checkbox" id="c-38541560" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#38538408">parent</a><span>|</span><a href="#38538201">next</a><span>|</span><label class="collapse" for="c-38541560">[-]</label><label class="expand" for="c-38541560">[1 more]</label></div><br/><div class="children"><div class="content">The model might have been trained with code that contained this exact comment</div><br/></div></div></div></div><div id="38538201" class="c"><input type="checkbox" id="c-38538201" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38538408">prev</a><span>|</span><a href="#38537583">next</a><span>|</span><label class="collapse" for="c-38538201">[-]</label><label class="expand" for="c-38538201">[1 more]</label></div><br/><div class="children"><div class="content">Sentiment analysis of movie reviews is <i>not</i> what i would call an inspired or high-quality programming problem.  This seems like too common examples from the training data being made manifest.<p>There&#x27;s so many more interesting things you could be doing  --  Even if you stick with the &quot;use tf-idf on review data&quot; how about sentiment analysis of vacation destination reviews segmented by season posted?  Things like that lead directly into other ideas and possible metrics.<p>Creativity is really a sore spot with these.  I suspect more elaborate prompts can suppress the commonalities but gpt-3.5 with a bog standard prompt gives bog standard ideas.</div><br/></div></div><div id="38537583" class="c"><input type="checkbox" id="c-38537583" checked=""/><div class="controls bullet"><span class="by">yawnxyz</span><span>|</span><a href="#38538201">prev</a><span>|</span><a href="#38538630">next</a><span>|</span><label class="collapse" for="c-38537583">[-]</label><label class="expand" for="c-38537583">[1 more]</label></div><br/><div class="children"><div class="content">Github: <a href="https:&#x2F;&#x2F;github.com&#x2F;ise-uiuc&#x2F;magicoder">https:&#x2F;&#x2F;github.com&#x2F;ise-uiuc&#x2F;magicoder</a></div><br/></div></div><div id="38538630" class="c"><input type="checkbox" id="c-38538630" checked=""/><div class="controls bullet"><span class="by">abrookewood</span><span>|</span><a href="#38537583">prev</a><span>|</span><a href="#38539800">next</a><span>|</span><label class="collapse" for="c-38538630">[-]</label><label class="expand" for="c-38538630">[9 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the Open Source claim is accurate. From their repo &quot;Magicoder models are trained on the synthetic data generated by gpt-3.5-turbo-1106 developed by OpenAI. Please pay attention to OpenAI&#x27;s terms of use when using the models and the datasets.&quot;</div><br/><div id="38539098" class="c"><input type="checkbox" id="c-38539098" checked=""/><div class="controls bullet"><span class="by">PostOnce</span><span>|</span><a href="#38538630">parent</a><span>|</span><a href="#38540765">next</a><span>|</span><label class="collapse" for="c-38539098">[-]</label><label class="expand" for="c-38539098">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI behaves as though everyone else&#x27;s outputs are fair game for training LLMs, including GPT, but doesn&#x27;t want others using GPT&#x27;s output?<p>So, when OpenAI does it, it&#x27;s transformative, but when we do it, it&#x27;s not?<p>That&#x27;s not right, and I don&#x27;t think the courts will rule in their favor.</div><br/><div id="38541548" class="c"><input type="checkbox" id="c-38541548" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#38538630">root</a><span>|</span><a href="#38539098">parent</a><span>|</span><a href="#38540765">next</a><span>|</span><label class="collapse" for="c-38541548">[-]</label><label class="expand" for="c-38541548">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That&#x27;s not right, and I don&#x27;t think the courts will rule in their favor.<p>Especially if you consider that all of OpenAI code training data comes from open Github repositories.</div><br/></div></div></div></div><div id="38540765" class="c"><input type="checkbox" id="c-38540765" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#38538630">parent</a><span>|</span><a href="#38539098">prev</a><span>|</span><a href="#38539355">next</a><span>|</span><label class="collapse" for="c-38540765">[-]</label><label class="expand" for="c-38540765">[1 more]</label></div><br/><div class="children"><div class="content">All model outputs (text, image, video) are considered public domain in the US, so they can be used for whatever.</div><br/></div></div><div id="38539355" class="c"><input type="checkbox" id="c-38539355" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#38538630">parent</a><span>|</span><a href="#38540765">prev</a><span>|</span><a href="#38539129">next</a><span>|</span><label class="collapse" for="c-38539355">[-]</label><label class="expand" for="c-38539355">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Please pay attention to OpenAI&#x27;s terms<p>Just because people at a company tell you how to behave doesn&#x27;t mean you need to comply</div><br/><div id="38539500" class="c"><input type="checkbox" id="c-38539500" checked=""/><div class="controls bullet"><span class="by">startupsfail</span><span>|</span><a href="#38538630">root</a><span>|</span><a href="#38539355">parent</a><span>|</span><a href="#38539129">next</a><span>|</span><label class="collapse" for="c-38539500">[-]</label><label class="expand" for="c-38539500">[3 more]</label></div><br/><div class="children"><div class="content">Or you can do the right thing and avoid distilling that stinky model, like theyâve asked.</div><br/><div id="38539782" class="c"><input type="checkbox" id="c-38539782" checked=""/><div class="controls bullet"><span class="by">vore</span><span>|</span><a href="#38538630">root</a><span>|</span><a href="#38539500">parent</a><span>|</span><a href="#38539578">next</a><span>|</span><label class="collapse" for="c-38539782">[-]</label><label class="expand" for="c-38539782">[1 more]</label></div><br/><div class="children"><div class="content">Does the fact someone asks you not to do something inherently make it the right thing? Especially when what they&#x27;ve asked is hypocritical?</div><br/></div></div><div id="38539578" class="c"><input type="checkbox" id="c-38539578" checked=""/><div class="controls bullet"><span class="by">graphe</span><span>|</span><a href="#38538630">root</a><span>|</span><a href="#38539500">parent</a><span>|</span><a href="#38539782">prev</a><span>|</span><a href="#38539129">next</a><span>|</span><label class="collapse" for="c-38539578">[-]</label><label class="expand" for="c-38539578">[1 more]</label></div><br/><div class="children"><div class="content">What makes it the &quot;right thing&quot; and who decided it was right?</div><br/></div></div></div></div></div></div></div></div><div id="38539800" class="c"><input type="checkbox" id="c-38539800" checked=""/><div class="controls bullet"><span class="by">sagarpatil</span><span>|</span><a href="#38538630">prev</a><span>|</span><a href="#38537812">next</a><span>|</span><label class="collapse" for="c-38539800">[-]</label><label class="expand" for="c-38539800">[1 more]</label></div><br/><div class="children"><div class="content">Asked it to write code for two python programs (one of them tricky) and it got both of them right in the first pass. Looks promising.</div><br/></div></div><div id="38537812" class="c"><input type="checkbox" id="c-38537812" checked=""/><div class="controls bullet"><span class="by">Reubend</span><span>|</span><a href="#38539800">prev</a><span>|</span><a href="#38540837">next</a><span>|</span><label class="collapse" for="c-38537812">[-]</label><label class="expand" for="c-38537812">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m guessing this model was made to be small simply to keep costs low and make sure that they could feasibly train the model with the amount of time&#x2F;effort they had. But to some extent I&#x27;m left wondering whether this technique would continue to be fruitful when scaled up to a huge model and with a bigger initial training set.</div><br/><div id="38539755" class="c"><input type="checkbox" id="c-38539755" checked=""/><div class="controls bullet"><span class="by">genidoi</span><span>|</span><a href="#38537812">parent</a><span>|</span><a href="#38539185">next</a><span>|</span><label class="collapse" for="c-38539755">[-]</label><label class="expand" for="c-38539755">[1 more]</label></div><br/><div class="children"><div class="content">It was made to be small out of necessity. The US government put extensive export controls on many inter-GPU connectivity products last year and expanded those controls recently to include anything above an A100.<p>Page 9 of this recently published paper[1] is a strong indicator of how far non-US firms go to formally analyze and factor in these bandwidth constraints in building large models.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2311.15786v2.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2311.15786v2.pdf</a></div><br/></div></div></div></div><div id="38540837" class="c"><input type="checkbox" id="c-38540837" checked=""/><div class="controls bullet"><span class="by">yieldcrv</span><span>|</span><a href="#38537812">prev</a><span>|</span><a href="#38538565">next</a><span>|</span><label class="collapse" for="c-38540837">[-]</label><label class="expand" for="c-38540837">[2 more]</label></div><br/><div class="children"><div class="content">could have been a blog post<p>this phase reminds me of when crypto projects all had pseudo academic âwhite papersâ in order to be taken âseriouslyâ</div><br/><div id="38541047" class="c"><input type="checkbox" id="c-38541047" checked=""/><div class="controls bullet"><span class="by">colinsane</span><span>|</span><a href="#38540837">parent</a><span>|</span><a href="#38538565">next</a><span>|</span><label class="collapse" for="c-38541047">[-]</label><label class="expand" for="c-38541047">[1 more]</label></div><br/><div class="children"><div class="content">nice username for that comment.<p>i was toying around quite a bit with the ecosystem a couple years ago. particularly, comparing all the different sidechains and &quot;layer 2&quot; networks: those white papers were a godsend, because i could actually understand the _specific_ guarantees and assumptions each one made (and it made spotting the BS ones trivial). it&#x27;s like `man` for the internet, and i quite like that.<p>i don&#x27;t see the parallel between this PDF and cryptocurrency whitepapers.</div><br/></div></div></div></div><div id="38538565" class="c"><input type="checkbox" id="c-38538565" checked=""/><div class="controls bullet"><span class="by">staflow</span><span>|</span><a href="#38540837">prev</a><span>|</span><a href="#38538308">next</a><span>|</span><label class="collapse" for="c-38538565">[-]</label><label class="expand" for="c-38538565">[6 more]</label></div><br/><div class="children"><div class="content">Somebody should make a coomer meme but with AI âall you needâ papers</div><br/><div id="38538765" class="c"><input type="checkbox" id="c-38538765" checked=""/><div class="controls bullet"><span class="by">triyambakam</span><span>|</span><a href="#38538565">parent</a><span>|</span><a href="#38539370">next</a><span>|</span><label class="collapse" for="c-38538765">[-]</label><label class="expand" for="c-38538765">[3 more]</label></div><br/><div class="children"><div class="content">Seriously! It was clever in the beginning but it&#x27;s wearing on me seeing it everywhere now.</div><br/><div id="38540611" class="c"><input type="checkbox" id="c-38540611" checked=""/><div class="controls bullet"><span class="by">mrtesthah</span><span>|</span><a href="#38538565">root</a><span>|</span><a href="#38538765">parent</a><span>|</span><a href="#38539370">next</a><span>|</span><label class="collapse" for="c-38540611">[-]</label><label class="expand" for="c-38540611">[2 more]</label></div><br/><div class="children"><div class="content">All you need considered harmful.</div><br/><div id="38540647" class="c"><input type="checkbox" id="c-38540647" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#38538565">root</a><span>|</span><a href="#38540611">parent</a><span>|</span><a href="#38539370">next</a><span>|</span><label class="collapse" for="c-38540647">[-]</label><label class="expand" for="c-38540647">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;ll take it full circle.</div><br/></div></div></div></div></div></div><div id="38539370" class="c"><input type="checkbox" id="c-38539370" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#38538565">parent</a><span>|</span><a href="#38538765">prev</a><span>|</span><a href="#38539138">next</a><span>|</span><label class="collapse" for="c-38539370">[-]</label><label class="expand" for="c-38539370">[1 more]</label></div><br/><div class="children"><div class="content">All you need is all you need</div><br/></div></div></div></div><div id="38538308" class="c"><input type="checkbox" id="c-38538308" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#38538565">prev</a><span>|</span><a href="#38537897">next</a><span>|</span><label class="collapse" for="c-38538308">[-]</label><label class="expand" for="c-38538308">[3 more]</label></div><br/><div class="children"><div class="content">Just make one which is capable of creating the perfect React &#x2F; Vue &#x2F; Angular framework including upgrade paths and while at it using it for us so that we don&#x27;t have to bother with reinventing the wheel every 3 years.</div><br/><div id="38541089" class="c"><input type="checkbox" id="c-38541089" checked=""/><div class="controls bullet"><span class="by">colinsane</span><span>|</span><a href="#38538308">parent</a><span>|</span><a href="#38539385">next</a><span>|</span><label class="collapse" for="c-38541089">[-]</label><label class="expand" for="c-38541089">[1 more]</label></div><br/><div class="children"><div class="content">&quot;the solution to runaway complexity is more complexity&quot;<p>okay, more nuanced than that. but from the perspective of someone who spends far more time reading code (and patching it or packaging it) than writing it, i worry about that mindset.</div><br/></div></div></div></div><div id="38538038" class="c"><input type="checkbox" id="c-38538038" checked=""/><div class="controls bullet"><span class="by">fizx</span><span>|</span><a href="#38537941">prev</a><span>|</span><label class="collapse" for="c-38538038">[-]</label><label class="expand" for="c-38538038">[2 more]</label></div><br/><div class="children"><div class="content">This looks like a llama2 finetune, so the dataset (inclusive of llama2) isn&#x27;t fully open as claimed, and I&#x27;d still have to accept the Facebook and possibly OpenAI licenses.<p>Let alone that clearly the base model was built on non-source-code, so their premise doesn&#x27;t hold.<p>Disappointing.</div><br/><div id="38538172" class="c"><input type="checkbox" id="c-38538172" checked=""/><div class="controls bullet"><span class="by">KRAKRISMOTT</span><span>|</span><a href="#38538038">parent</a><span>|</span><label class="collapse" for="c-38538172">[-]</label><label class="expand" for="c-38538172">[1 more]</label></div><br/><div class="children"><div class="content">The number of entities that are possibly constrained by the llama 2 license can be counted on two hands and <i>all</i> of them have the ability to train models that can match Llama 2&#x27;s performance.</div><br/></div></div></div></div></div></div></div></div></div></body></html>