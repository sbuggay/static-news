<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706173267814" as="style"/><link rel="stylesheet" href="styles.css?v=1706173267814"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/flame/blis">BLIS: A BLAS-like framework for basic linear algebra routines</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>ogogmad</span> | <span>33 comments</span></div><br/><div><div id="39123014" class="c"><input type="checkbox" id="c-39123014" checked=""/><div class="controls bullet"><span class="by">quanto</span><span>|</span><a href="#39124661">next</a><span>|</span><label class="collapse" for="c-39123014">[-]</label><label class="expand" for="c-39123014">[19 more]</label></div><br/><div class="children"><div class="content">The real money shot is here:
<a href="https:&#x2F;&#x2F;github.com&#x2F;flame&#x2F;blis&#x2F;blob&#x2F;master&#x2F;docs&#x2F;Performance.md">https:&#x2F;&#x2F;github.com&#x2F;flame&#x2F;blis&#x2F;blob&#x2F;master&#x2F;docs&#x2F;Performance.m...</a><p>It seems that the selling point is that BLIS does multi-core quite well.  I am especially impressed that it does as well as the highly optimized Intel MKL on Intel CPUs.<p>I do not see the selling point of BLIS-specific APIs, though.  The whole point of having an open BLAS API standard is that numerical libraries should be drop-in replaceable, so when a new library (such as BLIS here) comes along, one could just re-link the library and reap the performance gain immediately.<p>What is interesting is that numerical algebra work, by nature, is mostly embarrassingly parallel, so it should not be too difficult to write multi-core implementations.  And yet, BLIS here performs so much better than some other industry-leading implementations on multi-core configurations.  So the question is not why BLIS does so well; the question is why some other implementations do so poorly.</div><br/><div id="39125353" class="c"><input type="checkbox" id="c-39125353" checked=""/><div class="controls bullet"><span class="by">vatican_banker</span><span>|</span><a href="#39123014">parent</a><span>|</span><a href="#39127189">next</a><span>|</span><label class="collapse" for="c-39125353">[-]</label><label class="expand" for="c-39125353">[5 more]</label></div><br/><div class="children"><div class="content">&gt; numerical algebra work [...] is mostly embarrassingly parallel<p>It&#x27;s the exact opposite, most numerical linear algebra is _not_ embarrassingly parallel and requires quite an effort to code properly.<p>That is why BLAS&#x2F;LAPACK is popular and there are few competing implementations.</div><br/><div id="39125392" class="c"><input type="checkbox" id="c-39125392" checked=""/><div class="controls bullet"><span class="by">quanto</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39125353">parent</a><span>|</span><a href="#39127189">next</a><span>|</span><label class="collapse" for="c-39125392">[-]</label><label class="expand" for="c-39125392">[4 more]</label></div><br/><div class="children"><div class="content">I would love to be corrected:  do you have some specific examples or some underlying principles?<p>My professional and academic background is in numerical analysis and scientific computing (including BLAS&#x2F;LAPACK level implementations), but I admit I haven&#x27;t done deep numerical implementations in years.</div><br/><div id="39126961" class="c"><input type="checkbox" id="c-39126961" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39125392">parent</a><span>|</span><a href="#39125473">next</a><span>|</span><label class="collapse" for="c-39126961">[-]</label><label class="expand" for="c-39126961">[1 more]</label></div><br/><div class="children"><div class="content">Even for the algorithms that look easy on paper (nothing easier than a matrix multiplication, right?), the real issues are memory accesses. A huge amount of work went into making these libraries cache-friendly. Not so much effort was put in making them NUMA-friendly and multi core was often added after the fact, probably not as efficiently as it could have been.<p>And then, there are many parts of the algorithms deep in things like the various matrix decompositions that are difficult to parallelise because of non-trivial data dependencies. It’s easy to write some code to pivot a matrix; it’s very hard to do it in an efficient and scalable way. And because all the higher-level routines depend on them, so they have a large effect on overall performance.</div><br/></div></div><div id="39125473" class="c"><input type="checkbox" id="c-39125473" checked=""/><div class="controls bullet"><span class="by">sfpotter</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39125392">parent</a><span>|</span><a href="#39126961">prev</a><span>|</span><a href="#39125535">next</a><span>|</span><label class="collapse" for="c-39125473">[-]</label><label class="expand" for="c-39125473">[1 more]</label></div><br/><div class="children"><div class="content">Anything involving pivoting for stability isn’t trivial to parallelize. Plain old Gaussian elimination on huge sparse matrices doesn’t scale in parallel very well.<p>At the other end of the spectrum, getting a matrix-matrix multiply to run fast isn’t easy either. It’s what necessitated the kind of approach the authors of BLIS adopted. On paper it’s easy, but actually getting it to run fast on a computer isn’t.</div><br/></div></div><div id="39125535" class="c"><input type="checkbox" id="c-39125535" checked=""/><div class="controls bullet"><span class="by">vatican_banker</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39125392">parent</a><span>|</span><a href="#39125473">prev</a><span>|</span><a href="#39127189">next</a><span>|</span><label class="collapse" for="c-39125535">[-]</label><label class="expand" for="c-39125535">[1 more]</label></div><br/><div class="children"><div class="content">Embarrassingly parallel means &quot;singe task multiple data&quot; or &quot;multiple task single data&quot;. Canonical example: monte carlo simulations.<p>With that out of the way, basic linear algebra operations that require sophisticated algorithms and are not &quot;embarrassingly parallel&quot;: matrix multiplication, matrix inversion, matrix decomposition (SVM, QR, etc). Some of these algos fall into BLAS and others in LAPACK.</div><br/></div></div></div></div></div></div><div id="39127189" class="c"><input type="checkbox" id="c-39127189" checked=""/><div class="controls bullet"><span class="by">mratsim</span><span>|</span><a href="#39123014">parent</a><span>|</span><a href="#39125353">prev</a><span>|</span><a href="#39124648">next</a><span>|</span><label class="collapse" for="c-39127189">[-]</label><label class="expand" for="c-39127189">[1 more]</label></div><br/><div class="children"><div class="content">The batch match-mul API would be very useful for convolutions. It&#x27;s also used on Nvidia GPUs.<p>Often you get tensors that are sliced views on one or more dimensions, with BLAS-api you need to allocate them in a contiguous buffer. BLIS does not need that, there is a repacking algorithm to overcome memory bandwidth bounds in matrix multiplication (search the &quot;roofline model&quot;), the slicing&#x2F;realloc can be fused with repacking with BLIS API.</div><br/></div></div><div id="39124648" class="c"><input type="checkbox" id="c-39124648" checked=""/><div class="controls bullet"><span class="by">eigenman</span><span>|</span><a href="#39123014">parent</a><span>|</span><a href="#39127189">prev</a><span>|</span><a href="#39123938">next</a><span>|</span><label class="collapse" for="c-39124648">[-]</label><label class="expand" for="c-39124648">[2 more]</label></div><br/><div class="children"><div class="content">Many of the algorithms in BLAS are not easily parallelized. For example, a QR factorization an inherently sequential algorithm. Optimizing BLAS performance comes mainly from rewriting the sequential algorithm into larger blocks so as to efficiently access memory. As Jim Demmel is fond of saying, floating point optimizations are cheap, memory movement is expensive.</div><br/><div id="39125214" class="c"><input type="checkbox" id="c-39125214" checked=""/><div class="controls bullet"><span class="by">CreRecombinase</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39124648">parent</a><span>|</span><a href="#39123938">next</a><span>|</span><label class="collapse" for="c-39125214">[-]</label><label class="expand" for="c-39125214">[1 more]</label></div><br/><div class="children"><div class="content">QR decomposition isn’t in BLAS, you’re probably thinking of LAPACK.</div><br/></div></div></div></div><div id="39123938" class="c"><input type="checkbox" id="c-39123938" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#39123014">parent</a><span>|</span><a href="#39124648">prev</a><span>|</span><a href="#39126893">next</a><span>|</span><label class="collapse" for="c-39123938">[-]</label><label class="expand" for="c-39123938">[3 more]</label></div><br/><div class="children"><div class="content">BLIS mixed precision interfaces seem quite interesting and might be a good reason to expand on the BLAS api.<p>If I recall correctly, MKL also has interfaces that allow different array orders (row order or column order).</div><br/><div id="39125397" class="c"><input type="checkbox" id="c-39125397" checked=""/><div class="controls bullet"><span class="by">quanto</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39123938">parent</a><span>|</span><a href="#39126893">next</a><span>|</span><label class="collapse" for="c-39125397">[-]</label><label class="expand" for="c-39125397">[2 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t comment on BLIS-specific interfaces as I do not know, but BLAS standards (including MKL API) covers both different precision levels and matrix representations.</div><br/><div id="39126468" class="c"><input type="checkbox" id="c-39126468" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39125397">parent</a><span>|</span><a href="#39126893">next</a><span>|</span><label class="collapse" for="c-39126468">[-]</label><label class="expand" for="c-39126468">[1 more]</label></div><br/><div class="children"><div class="content">By mixed precision, I mean something like AB+C where A and B are single and C is double. That way you don’t have to make a double precision copy of A and B.</div><br/></div></div></div></div></div></div><div id="39126893" class="c"><input type="checkbox" id="c-39126893" checked=""/><div class="controls bullet"><span class="by">eyegor</span><span>|</span><a href="#39123014">parent</a><span>|</span><a href="#39123938">prev</a><span>|</span><a href="#39123493">next</a><span>|</span><label class="collapse" for="c-39126893">[-]</label><label class="expand" for="c-39126893">[2 more]</label></div><br/><div class="children"><div class="content">Holy cow, my main takeaway is that mkl is complete garbage on amd parts and that isn&#x27;t on accident. This makes me think I need to go back and relink some programs against blis or openblas for amd systems... Even though we primarily switched cluster hardware to amd it never occurred to us that mkl would run at half the throughput of open implementations.</div><br/><div id="39127052" class="c"><input type="checkbox" id="c-39127052" checked=""/><div class="controls bullet"><span class="by">danieldk</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39126893">parent</a><span>|</span><a href="#39123493">next</a><span>|</span><label class="collapse" for="c-39127052">[-]</label><label class="expand" for="c-39127052">[1 more]</label></div><br/><div class="children"><div class="content">You can override the detection function and get the faster Intel AVX kernels:<p><a href="https:&#x2F;&#x2F;danieldk.eu&#x2F;Posts&#x2F;2020-08-31-MKL-Zen" rel="nofollow">https:&#x2F;&#x2F;danieldk.eu&#x2F;Posts&#x2F;2020-08-31-MKL-Zen</a><p>Some back history: they used to use (slow) SSE kernels when a non-Intel CPU is detected. Over time, they started adding kernels for Zen, but last time I tested the Zen kernels were still slower than the AVX kernels. So it still pays off override the Intel CPU detection.<p>It looks like these benchmarks use MKL 2020 update 3. If I recall correctly, this version did not have the Zen sgemm kernels yet. A newer MKL version would perform much better and if you disable Intel detection, MKL would be competitive on Zen.</div><br/></div></div></div></div><div id="39123493" class="c"><input type="checkbox" id="c-39123493" checked=""/><div class="controls bullet"><span class="by">celrod</span><span>|</span><a href="#39123014">parent</a><span>|</span><a href="#39126893">prev</a><span>|</span><a href="#39123631">next</a><span>|</span><label class="collapse" for="c-39123493">[-]</label><label class="expand" for="c-39123493">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think these are realistic. It does far worse than MKL in practice on Intel CPUs in my tests, especially if arrays are not huge.</div><br/><div id="39127169" class="c"><input type="checkbox" id="c-39127169" checked=""/><div class="controls bullet"><span class="by">mratsim</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39123493">parent</a><span>|</span><a href="#39123631">next</a><span>|</span><label class="collapse" for="c-39127169">[-]</label><label class="expand" for="c-39127169">[1 more]</label></div><br/><div class="children"><div class="content">MKL has a JIT similar to libxsmm for small sizes.</div><br/></div></div></div></div><div id="39123631" class="c"><input type="checkbox" id="c-39123631" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#39123014">parent</a><span>|</span><a href="#39123493">prev</a><span>|</span><a href="#39124119">next</a><span>|</span><label class="collapse" for="c-39123631">[-]</label><label class="expand" for="c-39123631">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not that difficult to be faster than MKL when you write the benchmarks.<p>MKL is a general-purpose library, it does compromises to be good for most sizes. If you care about the performance of specific sizes, you can write code to beat it on that very specific benchmark.<p>Interestingly, BLIS does poorly at small sizes, which is the area where it is easiest to beat MKL at.</div><br/><div id="39127178" class="c"><input type="checkbox" id="c-39127178" checked=""/><div class="controls bullet"><span class="by">mratsim</span><span>|</span><a href="#39123014">root</a><span>|</span><a href="#39123631">parent</a><span>|</span><a href="#39124119">next</a><span>|</span><label class="collapse" for="c-39127178">[-]</label><label class="expand" for="c-39127178">[1 more]</label></div><br/><div class="children"><div class="content">MKL is very fast, on Intel. Due to how they do CPU detection.<p>It is a specialized library and they JIT their kernel.<p>Usually BLIS is slower.</div><br/></div></div></div></div><div id="39124119" class="c"><input type="checkbox" id="c-39124119" checked=""/><div class="controls bullet"><span class="by">klysm</span><span>|</span><a href="#39123014">parent</a><span>|</span><a href="#39123631">prev</a><span>|</span><a href="#39124661">next</a><span>|</span><label class="collapse" for="c-39124119">[-]</label><label class="expand" for="c-39124119">[1 more]</label></div><br/><div class="children"><div class="content">I think it has different goals than the BLAS API - it seems like they want to be a higher level generator of BLAS-ish APIs.</div><br/></div></div></div></div><div id="39124661" class="c"><input type="checkbox" id="c-39124661" checked=""/><div class="controls bullet"><span class="by">ngmc</span><span>|</span><a href="#39123014">prev</a><span>|</span><a href="#39127010">next</a><span>|</span><label class="collapse" for="c-39124661">[-]</label><label class="expand" for="c-39124661">[2 more]</label></div><br/><div class="children"><div class="content">I took one of the group&#x27;s courses, Linear Algebra: Foundations to Frontiers, for fun at the beginning of COVID lockdown and loved it. Here&#x27;s the course that teaches their basic approach to creating BLIS:<p><a href="https:&#x2F;&#x2F;www.edx.org&#x2F;learn&#x2F;computer-programming&#x2F;the-university-of-texas-at-austin-laff-on-programming-for-high-performance" rel="nofollow">https:&#x2F;&#x2F;www.edx.org&#x2F;learn&#x2F;computer-programming&#x2F;the-universit...</a><p>Neat stuff. The instructors are great, so I&#x27;ll try to make room in my schedule for this later in the year.</div><br/><div id="39127047" class="c"><input type="checkbox" id="c-39127047" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#39124661">parent</a><span>|</span><a href="#39127010">next</a><span>|</span><label class="collapse" for="c-39127047">[-]</label><label class="expand" for="c-39127047">[1 more]</label></div><br/><div class="children"><div class="content">Looks very interesting, thanks for the pointer.</div><br/></div></div></div></div><div id="39127010" class="c"><input type="checkbox" id="c-39127010" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#39124661">prev</a><span>|</span><a href="#39122790">next</a><span>|</span><label class="collapse" for="c-39127010">[-]</label><label class="expand" for="c-39127010">[1 more]</label></div><br/><div class="children"><div class="content">It’s interesting, it does very well in multicore and with complex numbers. The issue is that there’s no way we’ll rewrite all our code littered with calls to BLAS and LAPACK to use a different API. It looks like they have a BLAS compatibility layer though; I hope it’s good.<p>It even has a nice, friendly licence.</div><br/></div></div><div id="39122790" class="c"><input type="checkbox" id="c-39122790" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#39127010">prev</a><span>|</span><a href="#39122989">next</a><span>|</span><label class="collapse" for="c-39122790">[-]</label><label class="expand" for="c-39122790">[1 more]</label></div><br/><div class="children"><div class="content">Discussed just a little in the past:<p><i>BLIS:  BLAS-Like Library Instantiation Software Framework</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11369541">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11369541</a> - March 2016 (2 comments)</div><br/></div></div><div id="39122989" class="c"><input type="checkbox" id="c-39122989" checked=""/><div class="controls bullet"><span class="by">boegel</span><span>|</span><a href="#39122790">prev</a><span>|</span><a href="#39123480">next</a><span>|</span><label class="collapse" for="c-39122989">[-]</label><label class="expand" for="c-39122989">[1 more]</label></div><br/><div class="children"><div class="content">For people new to BLIS, I can recommend this talk from the EasyBuild User Meeting (2021): <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eb3dXivyTzE" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eb3dXivyTzE</a></div><br/></div></div><div id="39123480" class="c"><input type="checkbox" id="c-39123480" checked=""/><div class="controls bullet"><span class="by">pletnes</span><span>|</span><a href="#39122989">prev</a><span>|</span><a href="#39122685">next</a><span>|</span><label class="collapse" for="c-39123480">[-]</label><label class="expand" for="c-39123480">[3 more]</label></div><br/><div class="children"><div class="content">Is this approach similar to or inspired by ATLAS? Sounds like it to me at first glance.</div><br/><div id="39123789" class="c"><input type="checkbox" id="c-39123789" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#39123480">parent</a><span>|</span><a href="#39122685">next</a><span>|</span><label class="collapse" for="c-39123789">[-]</label><label class="expand" for="c-39123789">[2 more]</label></div><br/><div class="children"><div class="content">They are solving the same problem (tuning a BLAS).<p>ATLAS tries to automate it away.<p>For BLIS, instead they isolated the part that requires hand-tuning so you only have to write a couple kernels, then they can use them for the whole library.<p>BLIS is quite a bit newer and I’d be surprised if ATLAS kept up.</div><br/><div id="39127203" class="c"><input type="checkbox" id="c-39127203" checked=""/><div class="controls bullet"><span class="by">pletnes</span><span>|</span><a href="#39123480">root</a><span>|</span><a href="#39123789">parent</a><span>|</span><a href="#39122685">next</a><span>|</span><label class="collapse" for="c-39127203">[-]</label><label class="expand" for="c-39127203">[1 more]</label></div><br/><div class="children"><div class="content">Right, I guess DGEMM (or parts of it) is all you need for surprisingly many operations.</div><br/></div></div></div></div></div></div><div id="39122685" class="c"><input type="checkbox" id="c-39122685" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#39123480">prev</a><span>|</span><a href="#39126511">next</a><span>|</span><label class="collapse" for="c-39122685">[-]</label><label class="expand" for="c-39122685">[4 more]</label></div><br/><div class="children"><div class="content">New? Isn&#x27;t this AMD&#x27;s reference BLAS implementation?</div><br/><div id="39122988" class="c"><input type="checkbox" id="c-39122988" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#39122685">parent</a><span>|</span><a href="#39122857">next</a><span>|</span><label class="collapse" for="c-39122988">[-]</label><label class="expand" for="c-39122988">[1 more]</label></div><br/><div class="children"><div class="content">BLIS is a framework to instantiate (among other things) a BLAS. The exciting bit is that they distilled it down to a couple compute kernels. You provide stuff like the inner loops for a matrix multiplication, it turns it into a numerical library.<p>AMD did use it to create their BLAS library though.<p>Also, side note, when I’ve heard “reference BLAS,” it has been used in the opposite way. Netlib BLAS is the reference BLAS, it has basically bad performance but it defines the functionality. AMD used BLIS to create a tuned vendor BLAS.</div><br/></div></div><div id="39122857" class="c"><input type="checkbox" id="c-39122857" checked=""/><div class="controls bullet"><span class="by">lloda</span><span>|</span><a href="#39122685">parent</a><span>|</span><a href="#39122988">prev</a><span>|</span><a href="#39122793">next</a><span>|</span><label class="collapse" for="c-39122857">[-]</label><label class="expand" for="c-39122857">[1 more]</label></div><br/><div class="children"><div class="content">BLIS is a different library from BLAS, with a better API. For example when you pass an array, you can pass independent strides for all axes, and you can give independent transpose&#x2F;conjugate flags. It does have a BLAS compatibility interface.<p>The interface isn&#x27;t perfect though. For example they didn&#x27;t commit to supporting zero strides. That used to work anyway, but it&#x27;s broken now for some archs.</div><br/></div></div><div id="39122793" class="c"><input type="checkbox" id="c-39122793" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#39122685">parent</a><span>|</span><a href="#39122857">prev</a><span>|</span><a href="#39126511">next</a><span>|</span><label class="collapse" for="c-39122793">[-]</label><label class="expand" for="c-39122793">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve taken the word &#x27;new&#x27; out of the title. Thanks!</div><br/></div></div></div></div></div></div></div></div></div></body></html>