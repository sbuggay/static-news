<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701334879169" as="style"/><link rel="stylesheet" href="styles.css?v=1701334879169"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://martinfowler.com/articles/exploring-gen-ai.html#memo-08">How to tackle unreliability of coding assistants</a> <span class="domain">(<a href="https://martinfowler.com">martinfowler.com</a>)</span></div><div class="subtext"><span>ingve</span> | <span>130 comments</span></div><br/><div><div id="38464556" class="c"><input type="checkbox" id="c-38464556" checked=""/><div class="controls bullet"><span class="by">abeppu</span><span>|</span><a href="#38466688">next</a><span>|</span><label class="collapse" for="c-38464556">[-]</label><label class="expand" for="c-38464556">[57 more]</label></div><br/><div class="children"><div class="content">I think this is &quot;how to think about coding assistants and your task&quot; but none of this is &quot;tackling&quot; their unreliability.<p>While coding assistants seem to do well in a range of situations, I continue to believe that for coding specifically, merely training on next-token-prediction is leaving too much on the table. Yes, source code is represented as text, but computer programs are an area where there&#x27;s available information which is _so much richer_. We can know not only the text of the program but the type of every expression, which variables are in scope at any point, what is the signature of a method we&#x27;re trying to call, etc. These assistants should be able to make predictions about program _traces_, not just program source text. A step further would be to guess potential loop invariants, pre&#x2F;post conditions, etc, confirm which are upheld by existing tests, and down-weight recommending changes which introduce violations to those inferred conditions.<p>ChatGPT and tab-completion assistants have both given me things that are not even valid programs (e.g. will not compile, use a variable that isn&#x27;t actually in scope, etc). ChatGPT even told me that an example it generated wasn&#x27;t compiling for me b&#x2F;c I wasn&#x27;t using a new enough version of the language, and then referenced a language version which does not yet exist. All of this is possible in part b&#x2F;c these tools are engaging only at the level of text, and are structurally isolated from the rich information available inside an interpreter or debugger. &quot;Tackling&quot; unreliability should start with reframing tasks in a way which lets tools better see the causes of their failures.</div><br/><div id="38464589" class="c"><input type="checkbox" id="c-38464589" checked=""/><div class="controls bullet"><span class="by">jkaptur</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38464722">next</a><span>|</span><label class="collapse" for="c-38464589">[-]</label><label class="expand" for="c-38464589">[11 more]</label></div><br/><div class="children"><div class="content">I absolutely agree, but I find the situation incredibly funny. There are three characters here: me, the LLM, and the compiler. Two of them are robots, but they refuse to talk to each other - it&#x27;s up to me to tell the LLM the bad news from the compiler.</div><br/><div id="38465312" class="c"><input type="checkbox" id="c-38465312" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464589">parent</a><span>|</span><a href="#38470566">next</a><span>|</span><label class="collapse" for="c-38465312">[-]</label><label class="expand" for="c-38465312">[5 more]</label></div><br/><div class="children"><div class="content">that&#x27;s a frontend issue though. If you use the python interpreter in ChatGPT, you can tell it to run the code until it works, at which point it&#x27;ll do a couple of iterations before giving you code.</div><br/><div id="38467664" class="c"><input type="checkbox" id="c-38467664" checked=""/><div class="controls bullet"><span class="by">jgalt212</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465312">parent</a><span>|</span><a href="#38465985">next</a><span>|</span><label class="collapse" for="c-38467664">[-]</label><label class="expand" for="c-38467664">[3 more]</label></div><br/><div class="children"><div class="content">How many people are putting service credentials into a ChatGPT Python interpreter to see if their generated code &quot;works&quot;?</div><br/><div id="38469328" class="c"><input type="checkbox" id="c-38469328" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38467664">parent</a><span>|</span><a href="#38467848">next</a><span>|</span><label class="collapse" for="c-38469328">[-]</label><label class="expand" for="c-38469328">[1 more]</label></div><br/><div class="children"><div class="content">You can just use your own.... There is still the risk GPT-4 gives you ~ &quot;delete all the things&quot; and you blindly run it on your infra, but.. it&#x27;s better than what. you describe.</div><br/></div></div><div id="38467848" class="c"><input type="checkbox" id="c-38467848" checked=""/><div class="controls bullet"><span class="by">notjoemama</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38467664">parent</a><span>|</span><a href="#38469328">prev</a><span>|</span><a href="#38465985">next</a><span>|</span><label class="collapse" for="c-38467848">[-]</label><label class="expand" for="c-38467848">[1 more]</label></div><br/><div class="children"><div class="content">One of our very large customers was hit with ransomware recently. So…best practice is don’t do things like that.</div><br/></div></div></div></div></div></div><div id="38470566" class="c"><input type="checkbox" id="c-38470566" checked=""/><div class="controls bullet"><span class="by">pjerem</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464589">parent</a><span>|</span><a href="#38465312">prev</a><span>|</span><a href="#38465237">next</a><span>|</span><label class="collapse" for="c-38470566">[-]</label><label class="expand" for="c-38470566">[1 more]</label></div><br/><div class="children"><div class="content">It will come.<p>In fact, GPT is really good at correcting its code given the compiler output. We just need to automate that.<p>I think that this is not done yet because LLMs costs are O(n+1) so you really don’t want it to be stuck in some loop.</div><br/></div></div><div id="38465237" class="c"><input type="checkbox" id="c-38465237" checked=""/><div class="controls bullet"><span class="by">sa-code</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464589">parent</a><span>|</span><a href="#38470566">prev</a><span>|</span><a href="#38465356">next</a><span>|</span><label class="collapse" for="c-38465237">[-]</label><label class="expand" for="c-38465237">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like the worst game of telephone</div><br/></div></div><div id="38465356" class="c"><input type="checkbox" id="c-38465356" checked=""/><div class="controls bullet"><span class="by">convolvatron</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464589">parent</a><span>|</span><a href="#38465237">prev</a><span>|</span><a href="#38464722">next</a><span>|</span><label class="collapse" for="c-38465356">[-]</label><label class="expand" for="c-38465356">[3 more]</label></div><br/><div class="children"><div class="content">dont you already cut and paste your error message to google like everyone else?</div><br/><div id="38468307" class="c"><input type="checkbox" id="c-38468307" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465356">parent</a><span>|</span><a href="#38464722">next</a><span>|</span><label class="collapse" for="c-38468307">[-]</label><label class="expand" for="c-38468307">[2 more]</label></div><br/><div class="children"><div class="content">I decided to cut out the middleman:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;skorokithakis&#x2F;sysaidmin&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;skorokithakis&#x2F;sysaidmin&#x2F;</a></div><br/><div id="38470913" class="c"><input type="checkbox" id="c-38470913" checked=""/><div class="controls bullet"><span class="by">kosolam</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38468307">parent</a><span>|</span><a href="#38464722">next</a><span>|</span><label class="collapse" for="c-38470913">[-]</label><label class="expand" for="c-38470913">[1 more]</label></div><br/><div class="children"><div class="content">This is really nice. Thumb up</div><br/></div></div></div></div></div></div></div></div><div id="38464722" class="c"><input type="checkbox" id="c-38464722" checked=""/><div class="controls bullet"><span class="by">swatcoder</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38464589">prev</a><span>|</span><a href="#38467417">next</a><span>|</span><label class="collapse" for="c-38464722">[-]</label><label class="expand" for="c-38464722">[14 more]</label></div><br/><div class="children"><div class="content">Indeed. These are basically tech demos at this point. A marvel to see, and sometimes useful, but still extremely crude.<p>There&#x27;s a lot of headroom for sophistication as a few more research insights are made and an experienced tooling team commits a few years to making rich multimodal&#x2F;ensemble code assistants that can perform smart analyses, transformations, boilerplating, etc on your <i>project</i> instead of just adding some text to your file.<p>But it&#x27;ll take a years of insight and labor to build that system up, adapt it to different industries&#x2F;uses, and prove it out as engineering-ready.<p>People get caught up in the novelty of Copilot and ChatGPT and then imagine that the revolution arrives when some new paper comes out tomorrow (or that none will arrive because of today&#x27;s limitations), but the far more likely reality is that the revolution paces as something more like the internet&#x27;s -- real and profound, but unfolding gradually over the span of decades as people work hard to make new things with it.</div><br/><div id="38470249" class="c"><input type="checkbox" id="c-38470249" checked=""/><div class="controls bullet"><span class="by">moring</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464722">parent</a><span>|</span><a href="#38465503">next</a><span>|</span><label class="collapse" for="c-38470249">[-]</label><label class="expand" for="c-38470249">[1 more]</label></div><br/><div class="children"><div class="content">&gt; These are basically tech demos at this point.<p>I disagree with this conclusion. Crude as it is, Copilot _does_ make me faster in practice, even though I have to proofread its output. I think this also agrees with your second statement, that progress will come in small but useful improvements. If you treat Copilot like improved auto-completion, then it is very useful today.<p>Actually, while using syntax trees as the underlying model is a very interesting approach, there is still a lot of low-hanging fruit to make Copilot much more useful than it is today, just in terms of performance (waiting 1-2 seconds to see if there is a completion, and if it makes sense, interrupts my typing flow) as well as low-level features (e.g. mark and insert part of a suggestion, instead of inserting the whole and then removing the wrong parts).</div><br/></div></div><div id="38465503" class="c"><input type="checkbox" id="c-38465503" checked=""/><div class="controls bullet"><span class="by">TerrifiedMouse</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464722">parent</a><span>|</span><a href="#38470249">prev</a><span>|</span><a href="#38470961">next</a><span>|</span><label class="collapse" for="c-38465503">[-]</label><label class="expand" for="c-38465503">[9 more]</label></div><br/><div class="children"><div class="content">Frankly, we may be barking up the wrong tree with LLMs. Sure they deliver novel and very marketable results, hence the insane funding, but I can’t help but feel it’s really just a parlor trick and there is a yet undiscovered algorithm that can actually deliver the AGI that we seek - AGI that reliable and precise like fictional AIs.</div><br/><div id="38466033" class="c"><input type="checkbox" id="c-38466033" checked=""/><div class="controls bullet"><span class="by">jrockway</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465503">parent</a><span>|</span><a href="#38467520">next</a><span>|</span><label class="collapse" for="c-38466033">[-]</label><label class="expand" for="c-38466033">[7 more]</label></div><br/><div class="children"><div class="content">I think a lot of progress in the field of AI comes from random breakthroughs rather than evolution of existing ideas.  For that reason, I think AGI will probably be another random breakthrough, and not just an LLM with more parameters.  Good if you&#x27;re NVidia, bad if you&#x27;re OpenAI.  The random breakthrough could happen at Google, or it could happen in some professor&#x27;s basement.  There is no way to know, and no way to throw money at the problem and guarantee a return.</div><br/><div id="38469086" class="c"><input type="checkbox" id="c-38469086" checked=""/><div class="controls bullet"><span class="by">TerrifiedMouse</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38466033">parent</a><span>|</span><a href="#38467747">next</a><span>|</span><label class="collapse" for="c-38469086">[-]</label><label class="expand" for="c-38469086">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Good if you&#x27;re NVidia, bad if you&#x27;re OpenAI<p>Not necessarily good for Nvidia. If the new algorithm is branch heavy, don’t parallelize well, … etc. and operate better on CPUs rather than GPUs, it will be Intel, AMD, and ARM that enjoy the windfall.</div><br/><div id="38470133" class="c"><input type="checkbox" id="c-38470133" checked=""/><div class="controls bullet"><span class="by">jrockway</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38469086">parent</a><span>|</span><a href="#38467747">next</a><span>|</span><label class="collapse" for="c-38470133">[-]</label><label class="expand" for="c-38470133">[1 more]</label></div><br/><div class="children"><div class="content">Good point!</div><br/></div></div></div></div><div id="38467747" class="c"><input type="checkbox" id="c-38467747" checked=""/><div class="controls bullet"><span class="by">TillE</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38466033">parent</a><span>|</span><a href="#38469086">prev</a><span>|</span><a href="#38470222">next</a><span>|</span><label class="collapse" for="c-38467747">[-]</label><label class="expand" for="c-38467747">[3 more]</label></div><br/><div class="children"><div class="content">&gt; bad if you&#x27;re OpenAI<p>Just a few days ago there was a (somewhat cryptic) report about OpenAI developing a model that could do simple math. I&#x27;m certain they&#x27;re pursuing quite a lot of research that&#x27;s not directly related to LLMs.<p>I don&#x27;t think we&#x27;re heading towards AGI any time soon, but I can imagine a complex system in the next couple years which uses an LLM for text generation, but offloads its serious &quot;thinking&quot; on to predictable, specialized subsystems. It&#x27;s easy to imagine a lot of possibilities for code in particular.</div><br/><div id="38468826" class="c"><input type="checkbox" id="c-38468826" checked=""/><div class="controls bullet"><span class="by">jrockway</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38467747">parent</a><span>|</span><a href="#38470222">next</a><span>|</span><label class="collapse" for="c-38468826">[-]</label><label class="expand" for="c-38468826">[2 more]</label></div><br/><div class="children"><div class="content">I look at it like finding a lost treasure or something like that.  The government expedition with a 1 trillion dollar budget might find it first... or it might be in some guy&#x27;s attic and his kid came over and happened to notice it.  Spending infinite money on research increases your chances, but it&#x27;s still a chance.</div><br/><div id="38471002" class="c"><input type="checkbox" id="c-38471002" checked=""/><div class="controls bullet"><span class="by">Belomolo</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38468826">parent</a><span>|</span><a href="#38470222">next</a><span>|</span><label class="collapse" for="c-38471002">[-]</label><label class="expand" for="c-38471002">[1 more]</label></div><br/><div class="children"><div class="content">The protein folding project was basically solved due to money and ml.<p>Alpha fold.<p>The leap that area took thanks to it was a leap.<p>It&#x27;s more than just something potentially better</div><br/></div></div></div></div></div></div><div id="38470222" class="c"><input type="checkbox" id="c-38470222" checked=""/><div class="controls bullet"><span class="by">ImHereToVote</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38466033">parent</a><span>|</span><a href="#38467747">prev</a><span>|</span><a href="#38467520">next</a><span>|</span><label class="collapse" for="c-38470222">[-]</label><label class="expand" for="c-38470222">[1 more]</label></div><br/><div class="children"><div class="content">It would be a very poor AGI if it didn&#x27;t create a company that does AGI ASICs in the first few days. Minutes?</div><br/></div></div></div></div></div></div><div id="38470961" class="c"><input type="checkbox" id="c-38470961" checked=""/><div class="controls bullet"><span class="by">Belomolo</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464722">parent</a><span>|</span><a href="#38465503">prev</a><span>|</span><a href="#38466470">next</a><span>|</span><label class="collapse" for="c-38470961">[-]</label><label class="expand" for="c-38470961">[1 more]</label></div><br/><div class="children"><div class="content">Internet was hard limited on getting access in a physical world.<p>The first tech giving me internet reliable was DSL or 60kbytes&#x2F;sec.<p>This tech could only be replaced with replacing or adding cables.<p>Nvidia is making a ton more petaflops per month than last year and a lot of money and people have moved&#x2F;shifted in a very short period of time.<p>Even my company saw the writing and the only&#x2F;primarily thing we talk about is ml.<p>I also don&#x27;t have to wait for services like a bank or anyone else supporting emails or internet services.<p>We have everything already in place for a much faster speed than at any other tech before.</div><br/></div></div><div id="38466470" class="c"><input type="checkbox" id="c-38466470" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464722">parent</a><span>|</span><a href="#38470961">prev</a><span>|</span><a href="#38464896">next</a><span>|</span><label class="collapse" for="c-38466470">[-]</label><label class="expand" for="c-38466470">[1 more]</label></div><br/><div class="children"><div class="content">I think the ultimate jump in capability would be achieved by making a dedicated language to be used by an LLM and training it in parallel on mainly that. The problem is that to make this actually useful you need to establish a new programming language. And making a useful programming language that is actually used by people is even more expensive and takes more time than training a state-of-the-art LLM...</div><br/></div></div><div id="38464896" class="c"><input type="checkbox" id="c-38464896" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464722">parent</a><span>|</span><a href="#38466470">prev</a><span>|</span><a href="#38467417">next</a><span>|</span><label class="collapse" for="c-38464896">[-]</label><label class="expand" for="c-38464896">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Any sufficiently advanced technology is indistinguishable from magic.&quot;<p>-Arthur C. Clarke</div><br/></div></div></div></div><div id="38467417" class="c"><input type="checkbox" id="c-38467417" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38464722">prev</a><span>|</span><a href="#38470921">next</a><span>|</span><label class="collapse" for="c-38467417">[-]</label><label class="expand" for="c-38467417">[1 more]</label></div><br/><div class="children"><div class="content">Good point about program traces.<p>Another area I wish Copilot understood: where my cursor will go next. Right now it can only feed me new lines, but I bet the underlying LLM is already powerful enough that with little fine-tuning, it could guess that after I edit a call to foobar() to add an argument the next thing I&#x27;ll do is probably edit the definition of foobar.<p>It feels like there&#x27;s a trove of UX improvements in there; we&#x27;ve barely scratched the surface.</div><br/></div></div><div id="38470921" class="c"><input type="checkbox" id="c-38470921" checked=""/><div class="controls bullet"><span class="by">Belomolo</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38467417">prev</a><span>|</span><a href="#38467785">next</a><span>|</span><label class="collapse" for="c-38470921">[-]</label><label class="expand" for="c-38470921">[1 more]</label></div><br/><div class="children"><div class="content">At least chatgpt can already use a python interpreter and can also write unit tests for it.<p>Alone with copilot the amount of money flowing into this area is much more now than just a year ago.<p>And based on a Google research blog article, they use it internally with over 50% of suggestions being accepted.<p>The race is on and no one can afford not to play the game.</div><br/></div></div><div id="38467785" class="c"><input type="checkbox" id="c-38467785" checked=""/><div class="controls bullet"><span class="by">disconcision</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38470921">prev</a><span>|</span><a href="#38464783">next</a><span>|</span><label class="collapse" for="c-38467785">[-]</label><label class="expand" for="c-38467785">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been working on some basics in this direction... taking the expected type at the cursor and using this to inform exactly what type &amp; function definitions to splice into the prompt: <a href="https:&#x2F;&#x2F;andrewblinn.com&#x2F;papers&#x2F;2023-MWPLS-Type-directed-Prompt-Construction-for-LLM-powered-Programming-Assistants.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;andrewblinn.com&#x2F;papers&#x2F;2023-MWPLS-Type-directed-Prom...</a><p>We&#x27;re currently working on two forks off this... one, using the expected type information in conjunction with existing grammar constrained generation to enforce per-token type-correct generations, and two, using some program synthesis unevaluation techniques to also provided runtime trace data relevant to the current program hole we&#x27;re trying to generate a completion for.<p>But yeah in general there is so much existing work on static and dynamic program analysis which can be applied here... I think a lot of the interesting challenges are going to be UI&#x2F;UX ones... interactive processes to help more precisely specify intent and iteratively valid generations as more and more code is written autonomously.</div><br/><div id="38468437" class="c"><input type="checkbox" id="c-38468437" checked=""/><div class="controls bullet"><span class="by">pedrovhb</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38467785">parent</a><span>|</span><a href="#38464783">next</a><span>|</span><label class="collapse" for="c-38468437">[-]</label><label class="expand" for="c-38468437">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s interesting. In my experience, although synctatic errors do happen, they&#x27;re not nearly as common as, say, hallucinating methods or tripping over the exact API of a library.<p>One thought I&#x27;ve had but haven&#x27;t experimented with yet is that we could leverage a lot of the existing tooling that was made for humans - e.g. tab-complete providers like Jedi, which do some type inference behind the scenes. It&#x27;s able to provide suggestions of valid members for a given cursor position, and so logits could be warped to prefer tokens which match the suggestions (so if the output at a given time is `math.sq`, `math.sqrt` would be much preferred over `math.square_root` which doesn&#x27;t exist). You&#x27;d have to be a bit smart around this though because in since situations such as when using an identifier for the first time it&#x27;s not yet in scope and you don&#x27;t want the LLM to never create variables. Maybe some beam search shenanigans and heuristics could be enough to get useful output, but at that point it no longer seems like a quick thing to just try out :)</div><br/></div></div></div></div><div id="38464783" class="c"><input type="checkbox" id="c-38464783" checked=""/><div class="controls bullet"><span class="by">Night_Thastus</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38467785">prev</a><span>|</span><a href="#38465091">next</a><span>|</span><label class="collapse" for="c-38464783">[-]</label><label class="expand" for="c-38464783">[14 more]</label></div><br/><div class="children"><div class="content">In order to really solve this, you couldn&#x27;t use an LLM, at least not one in any shape that we have now.<p>You&#x27;d need something that actually <i>understands</i> the language. What is a lifetime, what is scope, what are types, functions, variables, etc. Something that can contextually look at correct, incomplete, or broken programs and reason about what they&#x27;re doing by knowing the rules that the language operates on and following them to a conclusion. It would also need to understand high-level design patterns and structure to not just know what&#x27;s happening in the literal sense &quot;this variable is being incremented&quot; but also in a more abstract sense &quot;this variable keeps track of references because this is mixed C&#x2F;Python code that needs that to handle deallocation&quot;. Something that recognizes patterns both within and outside of the code, with appropriately fuzzy matching where needed.<p>And I think importantly you&#x27;d need to be able to query it at a variety of levels. What&#x27;s happening on a line-by-line basis and what&#x27;s happening at the high level at a given point of code. One OR the other isn&#x27;t sufficient.<p>That is not a simple ask. We&#x27;re a long way away from something that smart existing.</div><br/><div id="38465336" class="c"><input type="checkbox" id="c-38465336" checked=""/><div class="controls bullet"><span class="by">abeppu</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464783">parent</a><span>|</span><a href="#38465137">next</a><span>|</span><label class="collapse" for="c-38465336">[-]</label><label class="expand" for="c-38465336">[2 more]</label></div><br/><div class="children"><div class="content">Absolutely it&#x27;s not a simple ask. But research in program synthesis was making interesting progress before LLMs came along. I think it would be better to ask how ML can improve or speed up those efforts, rather than trying to make a general ML model &quot;solve&quot; such a complex problem as a special case.<p>A step in this direction, which I&#x27;ve been trying to figure out as a side project, and which I would love someone to scoop me on and build a real thing, is to stitch an ML model into into a (mini)kanren. Minikanren folk have built relational interpreters for small languages but not for a &quot;real&quot; industrial language (so far as I&#x27;m aware). These small relational interpreters can generate programs given a set of relational statements about them (e.g. &quot;find f so that f(x1) == y1, f(x2) == y2, ...&quot;). Because they&#x27;re actually examining the full universe of programs in their small language, they will eventually find all programs that satisfy the constraints. But their search is in an order that&#x27;s given by the structure&#x2F;definition of the interpreter, and so for complex sets of requirements, finding the _first_ satisfying example can be unacceptably slow. But what if the search were based on the softmaxed outputs of an ML model, and you do a least cost search? Then (roughly) in the case that beam-search generation from the ML model would have produced a valid answer, you still find it in roughly the same time, but you _know_ it&#x27;s valid. In the case where a valid answer requires that in a small number of key places, we have to take a choice that the model assigns low probability, then we&#x27;ll find it but it takes longer. And in the case that all the choices needed to construct a valid answer are low-probability under the model, then we&#x27;re basically in the same place that the vanilla minikanren search was.</div><br/><div id="38466652" class="c"><input type="checkbox" id="c-38466652" checked=""/><div class="controls bullet"><span class="by">aeonik</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465336">parent</a><span>|</span><a href="#38465137">next</a><span>|</span><label class="collapse" for="c-38466652">[-]</label><label class="expand" for="c-38466652">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve thought a lot about this as well, and I&#x27;m convinced it&#x27;s a really great way forward assuming the model can have some inference of the search space of the queries that it&#x27;s going to run.<p>It&#x27;s too easy to fall into infinite loops for something with only a naïve understanding of the questions.</div><br/></div></div></div></div><div id="38465137" class="c"><input type="checkbox" id="c-38465137" checked=""/><div class="controls bullet"><span class="by">LeifCarrotson</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464783">parent</a><span>|</span><a href="#38465336">prev</a><span>|</span><a href="#38467509">next</a><span>|</span><label class="collapse" for="c-38465137">[-]</label><label class="expand" for="c-38465137">[7 more]</label></div><br/><div class="children"><div class="content">What LLM text generation has shown is that you don&#x27;t actually have to understand English to generate pretty decent English. You just have to have enough examples.<p>This is where the massive corpus of source code available on the Internet can help generate a &quot;LSM&quot; (large software model) if you can expose the tokens as the lexer understands them in the training set.<p>If your LSM sees a trillion examples of correct usage of lifetime and scope and types and so on, then in the same way that an LLM trained on English grammar will emit text with correct grammar as if it <i>understands</i> English, your LSM will generate software with correct syntax as if it <i>understands</i> the software. Whatever the definition of &quot;understands&quot; is in the context of an LLM.</div><br/><div id="38465483" class="c"><input type="checkbox" id="c-38465483" checked=""/><div class="controls bullet"><span class="by">abeppu</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465137">parent</a><span>|</span><a href="#38465925">next</a><span>|</span><label class="collapse" for="c-38465483">[-]</label><label class="expand" for="c-38465483">[1 more]</label></div><br/><div class="children"><div class="content">But:<p>- natural language is flexible, computer languages are less so.<p>- &quot;pretty decent English&quot; still includes hallucinations. I&#x27;ve seen companies whose product demo for generating marketing copy just makes up a plausible review. Hallucinating methods, variables, other packages&#x2F;modules yields broken code.<p>- the human thought behind natural language is not feasible to directly provide to a model. An IR corresponding to the source of the program is feasible to provide. A trace of the program executing is feasible to provide. Grounding an LLM in the rich exterior world that humans talk about is hard; grounding an LSM in the rich internal representations accessible to an IDE or a debugger is achievable.</div><br/></div></div><div id="38465925" class="c"><input type="checkbox" id="c-38465925" checked=""/><div class="controls bullet"><span class="by">majormajor</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465137">parent</a><span>|</span><a href="#38465483">prev</a><span>|</span><a href="#38466420">next</a><span>|</span><label class="collapse" for="c-38465925">[-]</label><label class="expand" for="c-38465925">[1 more]</label></div><br/><div class="children"><div class="content">&quot;pretty decent english&quot; is a pretty fuzzy bar.<p>Indeed, Chat GPT 4 and Copilot can generate &quot;pretty decent code&quot; that will look fine to the average human coder <i>even when it&#x27;s incorrect</i> (making up methods or getting params wrong or slighly missing requirements or similar).<p>The level of precision required for &quot;pretty decent non-trivial code&quot; is much higher than prose that looks like it was written by an educated human, so I share the idea that if it was augmented - even in really <i>stupid</i> ways like asking the IDE if it would even compile, in the case of Copilot, before suggesting it to the user - it would work <i>much</i> better at a much lower effort than increasing it&#x27;s understanding implicitly by orders of magnitude.</div><br/></div></div><div id="38466420" class="c"><input type="checkbox" id="c-38466420" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465137">parent</a><span>|</span><a href="#38465925">prev</a><span>|</span><a href="#38465341">next</a><span>|</span><label class="collapse" for="c-38466420">[-]</label><label class="expand" for="c-38466420">[3 more]</label></div><br/><div class="children"><div class="content">&gt; you don&#x27;t actually have to understand English to generate pretty decent English. You just have to have enough examples.<p>I would have thought babies have been showing this beyond a doubt since time immemorial.</div><br/><div id="38469162" class="c"><input type="checkbox" id="c-38469162" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38466420">parent</a><span>|</span><a href="#38468833">prev</a><span>|</span><a href="#38465341">next</a><span>|</span><label class="collapse" for="c-38469162">[-]</label><label class="expand" for="c-38469162">[1 more]</label></div><br/><div class="children"><div class="content">No, because we can&#x27;t look into their skulls, to figure out whether they &#x27;understand&#x27;, whatever that means.</div><br/></div></div></div></div><div id="38465341" class="c"><input type="checkbox" id="c-38465341" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465137">parent</a><span>|</span><a href="#38466420">prev</a><span>|</span><a href="#38467509">next</a><span>|</span><label class="collapse" for="c-38465341">[-]</label><label class="expand" for="c-38465341">[1 more]</label></div><br/><div class="children"><div class="content">right. we&#x27;re already abstracting from English words and characters into tokens, piping code through half a compiler so the LSM is given the AST to train on doesn&#x27;t seem all that far fetched.</div><br/></div></div></div></div><div id="38467509" class="c"><input type="checkbox" id="c-38467509" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464783">parent</a><span>|</span><a href="#38465137">prev</a><span>|</span><a href="#38469143">next</a><span>|</span><label class="collapse" for="c-38467509">[-]</label><label class="expand" for="c-38467509">[1 more]</label></div><br/><div class="children"><div class="content">I keep seeing these takes and I still think OthelloGPT disproves them.<p>So far it really looks like a sufficiently large LLM with a sufficiently large &#x2F; high-quality dataset can learn basically anything (given a slightly generous interpretation of the word &quot;sufficiently&quot;).<p>In case of code completion, I think just training on program output in addition to source code would already unlock huge capability boosts.</div><br/></div></div><div id="38469143" class="c"><input type="checkbox" id="c-38469143" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464783">parent</a><span>|</span><a href="#38467509">prev</a><span>|</span><a href="#38465852">next</a><span>|</span><label class="collapse" for="c-38469143">[-]</label><label class="expand" for="c-38469143">[2 more]</label></div><br/><div class="children"><div class="content">&gt; You&#x27;d need something that actually understands the language. What is a lifetime, what is scope, what are types, functions, variables, etc.<p>Why is that more important for programming languages than for human natural languages?</div><br/><div id="38469853" class="c"><input type="checkbox" id="c-38469853" checked=""/><div class="controls bullet"><span class="by">Night_Thastus</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38469143">parent</a><span>|</span><a href="#38465852">next</a><span>|</span><label class="collapse" for="c-38469853">[-]</label><label class="expand" for="c-38469853">[1 more]</label></div><br/><div class="children"><div class="content">Because if you use a somewhat odd phrasing, uncommon terms, weird sentence structure, etc - human beings are <i>very</i> good at figuring out what is meant. We can interpolate, we can extrapolate, we can estimate and understand context. Very incomplete language can still be understood with the right context.<p>A compiler cannot do these things. The code must follow the rules of the language perfectly, or the code won&#x27;t compile. And further, it doesn&#x27;t understand intention like a human can. It doesn&#x27;t know that you <i>intended</i> to loop over all items in a collection - if you have an off-by-one error it&#x27;ll happily compile that regardless.</div><br/></div></div></div></div><div id="38465852" class="c"><input type="checkbox" id="c-38465852" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38464783">parent</a><span>|</span><a href="#38469143">prev</a><span>|</span><a href="#38465091">next</a><span>|</span><label class="collapse" for="c-38465852">[-]</label><label class="expand" for="c-38465852">[1 more]</label></div><br/><div class="children"><div class="content">An interface layer is 70% of the value for 10% of the work.</div><br/></div></div></div></div><div id="38465091" class="c"><input type="checkbox" id="c-38465091" checked=""/><div class="controls bullet"><span class="by">dxbydt</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38464783">prev</a><span>|</span><a href="#38465843">next</a><span>|</span><label class="collapse" for="c-38465091">[-]</label><label class="expand" for="c-38465091">[3 more]</label></div><br/><div class="children"><div class="content">Generating invalid code is a big hassle. I have used ChatGPT for generating R code &amp; sometimes it refers to functions that don&#x27;t exist. The standard deviation of [1,2,1] is 0.577, given by  sd(c(1,2,1)). Sometimes I get stdev(c(1,2,3)) - there is no stdev in R. Why not have a slower mode where you run the code thru the R interpreter first, &amp; only emit valid code that passes that step ?</div><br/><div id="38465379" class="c"><input type="checkbox" id="c-38465379" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465091">parent</a><span>|</span><a href="#38465843">next</a><span>|</span><label class="collapse" for="c-38465379">[-]</label><label class="expand" for="c-38465379">[2 more]</label></div><br/><div class="children"><div class="content">The Python one that currently exists can use Pandas, but then you&#x27;re using Python and not R. Other language support must be on their roadmap, only question is how far down the list it is.</div><br/><div id="38467338" class="c"><input type="checkbox" id="c-38467338" checked=""/><div class="controls bullet"><span class="by">blharr</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465379">parent</a><span>|</span><a href="#38465843">next</a><span>|</span><label class="collapse" for="c-38467338">[-]</label><label class="expand" for="c-38467338">[1 more]</label></div><br/><div class="children"><div class="content">This can be done pretty easily with their api if you are willing to spend some time on it</div><br/></div></div></div></div></div></div><div id="38465843" class="c"><input type="checkbox" id="c-38465843" checked=""/><div class="controls bullet"><span class="by">delta_p_delta_x</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38465091">prev</a><span>|</span><a href="#38469129">next</a><span>|</span><label class="collapse" for="c-38465843">[-]</label><label class="expand" for="c-38465843">[3 more]</label></div><br/><div class="children"><div class="content">&gt; these tools are engaging only at the level of text<p>Couldn&#x27;t we say the same thing about almost all UNIX&#x2F;Linux coreutils? There&#x27;s no way to get a strongly-typed array&#x2F;tree of folders, files, and metadata from `ls`; it has to be awk-ed and sed-ed into compliance. There&#x27;s no way to get a strongly-typed dictionary of command-line options and what they do for pretty much every coreutil; you have to invoke `something --help` and then awk&#x2F;sed <i>that</i> output again.<p>These coreutils are at their core, only stringly-typed, which makes life more difficult than it strictly needs to be.<p>Everything is a bag of bytes, or a stream to be manipulated. This philosophy simply leaked into LLMs.</div><br/><div id="38467474" class="c"><input type="checkbox" id="c-38467474" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465843">parent</a><span>|</span><a href="#38467532">next</a><span>|</span><label class="collapse" for="c-38467474">[-]</label><label class="expand" for="c-38467474">[1 more]</label></div><br/><div class="children"><div class="content">I think GP&#x27;s point is we could get much better results if we fed the LLMs with more than the <i>input</i> text.<p>It could still be text, or at least bytestreams: program traces, OpenTelemetry logs, objdump of the compiled binaries, LLVM IR dumps, compiler errors, syntax highlighting markers, etc.</div><br/></div></div><div id="38467532" class="c"><input type="checkbox" id="c-38467532" checked=""/><div class="controls bullet"><span class="by">sanderjd</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465843">parent</a><span>|</span><a href="#38467474">prev</a><span>|</span><a href="#38469129">next</a><span>|</span><label class="collapse" for="c-38467532">[-]</label><label class="expand" for="c-38467532">[1 more]</label></div><br/><div class="children"><div class="content">This is, indeed, also a weakness of those tools.</div><br/></div></div></div></div><div id="38469129" class="c"><input type="checkbox" id="c-38469129" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38465843">prev</a><span>|</span><a href="#38467484">next</a><span>|</span><label class="collapse" for="c-38469129">[-]</label><label class="expand" for="c-38469129">[1 more]</label></div><br/><div class="children"><div class="content">&gt; These assistants should be able to make predictions about program _traces_, not just program source text.<p>Are you sure &#x27;traces&#x27; is the right word?  Not something more like ASTs?<p>Btw, the predict-next-token approach has the benefit of also being able to deal with broken code.<p>You might also want to compare <a href="http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html" rel="nofollow noreferrer">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a> and <a href="https:&#x2F;&#x2F;gwern.net&#x2F;scaling-hypothesis" rel="nofollow noreferrer">https:&#x2F;&#x2F;gwern.net&#x2F;scaling-hypothesis</a> with your idea of adding more domain specific knowledge.</div><br/></div></div><div id="38467484" class="c"><input type="checkbox" id="c-38467484" checked=""/><div class="controls bullet"><span class="by">sanderjd</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38469129">prev</a><span>|</span><a href="#38465271">next</a><span>|</span><label class="collapse" for="c-38467484">[-]</label><label class="expand" for="c-38467484">[1 more]</label></div><br/><div class="children"><div class="content">Very well put. The current generation of these tools are <i>incredibly</i> useful but clearly leaving a huge amount on the table.<p>Just makes me more excited for future iterations!</div><br/></div></div><div id="38465271" class="c"><input type="checkbox" id="c-38465271" checked=""/><div class="controls bullet"><span class="by">walt_grata</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38467484">prev</a><span>|</span><a href="#38465457">next</a><span>|</span><label class="collapse" for="c-38465271">[-]</label><label class="expand" for="c-38465271">[1 more]</label></div><br/><div class="children"><div class="content">You know I&#x27;ve been thinking about this for a while, I honestly don&#x27;t think LLMs will ever be the right choice for a coding assistant.  Where I&#x27;ve had a strange idea they could help, although it&#x27;s completely unproven yet, is replacing what we traditionally think of as a developer and code.  I&#x27;m envisioning, for simple application, a completely non-technical person have a conversation with a coding assistant and it something directly executable, think the tokens it outputs are JVM bytecode or something similar.  I&#x27;m sure there&#x27;s innumerable flaws with my thinking&#x2F;approach but so far, it&#x27;s been fun to think and code around.</div><br/></div></div><div id="38465457" class="c"><input type="checkbox" id="c-38465457" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38465271">prev</a><span>|</span><a href="#38468110">next</a><span>|</span><label class="collapse" for="c-38465457">[-]</label><label class="expand" for="c-38465457">[3 more]</label></div><br/><div class="children"><div class="content">Would be interesting to see them trained on actual syntax trees from text.<p>Then maybe have a separate model trained on going from syntax tree to source code.</div><br/><div id="38466261" class="c"><input type="checkbox" id="c-38466261" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38465457">parent</a><span>|</span><a href="#38468110">next</a><span>|</span><label class="collapse" for="c-38466261">[-]</label><label class="expand" for="c-38466261">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Then maybe have a separate model trained on going from syntax tree to source code.<p>I don&#x27;t see why you need a model for this. But yes, this is a very cool idea.</div><br/><div id="38466673" class="c"><input type="checkbox" id="c-38466673" checked=""/><div class="controls bullet"><span class="by">tonyedgecombe</span><span>|</span><a href="#38464556">root</a><span>|</span><a href="#38466261">parent</a><span>|</span><a href="#38468110">next</a><span>|</span><label class="collapse" for="c-38466673">[-]</label><label class="expand" for="c-38466673">[1 more]</label></div><br/><div class="children"><div class="content">Presumably so you don’t need to write a code generator for every language you support.</div><br/></div></div></div></div></div></div><div id="38468110" class="c"><input type="checkbox" id="c-38468110" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#38464556">parent</a><span>|</span><a href="#38465457">prev</a><span>|</span><a href="#38466688">next</a><span>|</span><label class="collapse" for="c-38468110">[-]</label><label class="expand" for="c-38468110">[1 more]</label></div><br/><div class="children"><div class="content">&gt; then referenced a language version which does not yet exist<p>It must have gaming forums in its training data.  Gamers know that the solution to all problems is to upgrade (game&#x2F;drivers&#x2F;OS) to the latest version.</div><br/></div></div></div></div><div id="38466688" class="c"><input type="checkbox" id="c-38466688" checked=""/><div class="controls bullet"><span class="by">irrational</span><span>|</span><a href="#38464556">prev</a><span>|</span><a href="#38469849">next</a><span>|</span><label class="collapse" for="c-38466688">[-]</label><label class="expand" for="c-38466688">[3 more]</label></div><br/><div class="children"><div class="content">I just started using copilot last week. I was blown away. I would barely start typing and it would show me anywhere from a single line to 15 lines of exactly what I had been intending to write. It was mind blowing. In one instance, it found reference to data in a totally different part of the page and correctly used it in the code it was creating. I still can&#x27;t figure out how it did that. I was beyond impressed. Sometimes it was 100% spot on, other times it was 90% of the way there, but it was crazy how much time it saved. Though, I have been programming for many decades, so I was able to tell pretty easily if what it was creating was good or not. I think this could lead a new coder astray.</div><br/><div id="38467808" class="c"><input type="checkbox" id="c-38467808" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#38466688">parent</a><span>|</span><a href="#38469849">next</a><span>|</span><label class="collapse" for="c-38467808">[-]</label><label class="expand" for="c-38467808">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, you really need to experience it first hand to get to that &quot;wow&quot; moment. For me, that moment was when I was writing some code in my over-engineered codebase, with some prematurely generalized abstractions that even I can barely understand. I&#x27;d pause for a second to think &quot;wtf am I doing again?&quot; and Copilot would suggest a whole block of code that aligned perfectly with my intent. This happened repeatedly and it felt like I was being guided to a solution. The incredible thing was that I hadn&#x27;t even thought about it yet. It&#x27;s like Copilot was thinking a step ahead of me.<p>I found this effect to be most pronounced when writing tests. I think Copilot shines in codebases with static typing, clear interfaces, doctstrings and unit tests. That&#x27;s really about the densest, most richly annotated context you could give to an LLM. And that&#x27;s before adding capabilities for more well-defined reasoning about static languages, types, etc. - there is potential for it to get even better at this.</div><br/><div id="38469791" class="c"><input type="checkbox" id="c-38469791" checked=""/><div class="controls bullet"><span class="by">redhale</span><span>|</span><a href="#38466688">root</a><span>|</span><a href="#38467808">parent</a><span>|</span><a href="#38469849">next</a><span>|</span><label class="collapse" for="c-38469791">[-]</label><label class="expand" for="c-38469791">[1 more]</label></div><br/><div class="children"><div class="content">Writing unit tests is the most effective use of copilot hands-down.<p>For pure functions, it is 100% correct and complete essentially 100% of the time, allowing me to write descriptive test names and nothing more. Even when mocks or spies have to come into the picture, it is usually 95% accurate. The key is that you should always have the file you are testing open in an editor tab, as well as another test class that demonstrates the testing style you want it to emulate.<p>Forget everything else about Copilot, it&#x27;s worth the cost for this alone. Time writing tests reduced ~80%. They could remove all other functionality and rebrand it as Test Copilot, and they would still get my money.</div><br/></div></div></div></div></div></div><div id="38469849" class="c"><input type="checkbox" id="c-38469849" checked=""/><div class="controls bullet"><span class="by">calamari4065</span><span>|</span><a href="#38466688">prev</a><span>|</span><a href="#38466403">next</a><span>|</span><label class="collapse" for="c-38469849">[-]</label><label class="expand" for="c-38469849">[1 more]</label></div><br/><div class="children"><div class="content">I view these LLM tools as just another code generator. I have no idea how many bespoke single-use code generators I&#x27;ve written, but I know that I&#x27;ve spent a nontrivial amount of time writing code that writes code. If an LLM can do it with a natural language interface, it&#x27;ll save me a lot of time.<p>But also, I would never trust a script I threw together in 15 minutes to actually produce real code and solve the problem. All it does is generate the text I tell it to. It can&#x27;t understand the system or how it works, it just procedurally spits out text.<p>In the same way that a dozen lines of Python cannot understand your program, an LLM is also fundamentally incapable of understanding it. That&#x27;s the crucial part of programming. An LLM will give you text all day, but it can&#x27;t write your program.<p>Sure an LLM can produce trivial scripts, but in my experience so far, it can only reliably generate trivial programs that I could write blindfolded in the same amount of time.<p>If we just treat these tools like the <i>text</i> generators they are instead of insisting they&#x27;re <i>code</i> generators, we&#x27;ll all be better off.</div><br/></div></div><div id="38466403" class="c"><input type="checkbox" id="c-38466403" checked=""/><div class="controls bullet"><span class="by">vishnumenon</span><span>|</span><a href="#38469849">prev</a><span>|</span><a href="#38464637">next</a><span>|</span><label class="collapse" for="c-38466403">[-]</label><label class="expand" for="c-38466403">[3 more]</label></div><br/><div class="children"><div class="content">My current hypothesis here is that the way to make coding assistants as reliable as possible is to shift the balance towards making their output rely on context provided in-prompt rather than information stored in LLM weights. As all the major providers shift towards larger context-windows, it seems increasingly viable to give the LLM the necessary docs for whatever libraries are being used in the current file. I&#x27;ve been working on an experiment in this space[0], and while it&#x27;s obviously bottle-necked by the size of the documentation index, even a couple-hundred documentation sources seems to help a ton when working with less-used languages&#x2F;libraries.<p>[0]: <a href="https:&#x2F;&#x2F;indexical.dev&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;indexical.dev&#x2F;</a></div><br/><div id="38468410" class="c"><input type="checkbox" id="c-38468410" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#38466403">parent</a><span>|</span><a href="#38464637">next</a><span>|</span><label class="collapse" for="c-38468410">[-]</label><label class="expand" for="c-38468410">[2 more]</label></div><br/><div class="children"><div class="content">I like that your solution is basically telling the LLM to RTFM.</div><br/><div id="38468726" class="c"><input type="checkbox" id="c-38468726" checked=""/><div class="controls bullet"><span class="by">vishnumenon</span><span>|</span><a href="#38466403">root</a><span>|</span><a href="#38468410">parent</a><span>|</span><a href="#38464637">next</a><span>|</span><label class="collapse" for="c-38468726">[-]</label><label class="expand" for="c-38468726">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I&#x27;ve been using it with prompts that ask it to cite sources as well, honestly I think the best results are when I&#x27;m still interacting w&#x2F; the docs directly in addition to having the LLM look at em - still can&#x27;t quite replace needing to RTFM!</div><br/></div></div></div></div></div></div><div id="38464637" class="c"><input type="checkbox" id="c-38464637" checked=""/><div class="controls bullet"><span class="by">wrs</span><span>|</span><a href="#38466403">prev</a><span>|</span><a href="#38468974">next</a><span>|</span><label class="collapse" for="c-38464637">[-]</label><label class="expand" for="c-38464637">[7 more]</label></div><br/><div class="children"><div class="content">Several times when I’ve asked ChatGPT for an approach to something, it has spit out code that uses an API that looks perfect for my use case, but doesn’t actually exist.<p>So I’m thinking someone should be building an automated product manager!</div><br/><div id="38466058" class="c"><input type="checkbox" id="c-38466058" checked=""/><div class="controls bullet"><span class="by">gnulinux</span><span>|</span><a href="#38464637">parent</a><span>|</span><a href="#38464717">next</a><span>|</span><label class="collapse" for="c-38466058">[-]</label><label class="expand" for="c-38466058">[4 more]</label></div><br/><div class="children"><div class="content">This is what ChatGPT does to me whenever I ask anything non-trivial. I find it funny people think it&#x27;ll take over our jobs, it simply can&#x27;t even do the most basic things beyond the beaten path.</div><br/><div id="38467180" class="c"><input type="checkbox" id="c-38467180" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#38464637">root</a><span>|</span><a href="#38466058">parent</a><span>|</span><a href="#38469813">next</a><span>|</span><label class="collapse" for="c-38467180">[-]</label><label class="expand" for="c-38467180">[2 more]</label></div><br/><div class="children"><div class="content">are you using GPT-4? because it&#x27;s been incredibly helpful to me. major refactoring gets done in a matter of seconds, and when it doesn&#x27;t work, I can just paste whatever compiler error I&#x27;m getting and it usually fixes the problem</div><br/><div id="38470722" class="c"><input type="checkbox" id="c-38470722" checked=""/><div class="controls bullet"><span class="by">ozim</span><span>|</span><a href="#38464637">root</a><span>|</span><a href="#38467180">parent</a><span>|</span><a href="#38469813">next</a><span>|</span><label class="collapse" for="c-38470722">[-]</label><label class="expand" for="c-38470722">[1 more]</label></div><br/><div class="children"><div class="content">Can you give an example of what you consider “major refactoring”?</div><br/></div></div></div></div></div></div><div id="38464717" class="c"><input type="checkbox" id="c-38464717" checked=""/><div class="controls bullet"><span class="by">jwells89</span><span>|</span><a href="#38464637">parent</a><span>|</span><a href="#38466058">prev</a><span>|</span><a href="#38469174">next</a><span>|</span><label class="collapse" for="c-38464717">[-]</label><label class="expand" for="c-38464717">[1 more]</label></div><br/><div class="children"><div class="content">Have had the same experience several times. “Yes ChatGPT, it makes perfect sense for that to exist and would be wonderful if it did, but unfortunately it does not.”</div><br/></div></div><div id="38469174" class="c"><input type="checkbox" id="c-38469174" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#38464637">parent</a><span>|</span><a href="#38464717">prev</a><span>|</span><a href="#38468974">next</a><span>|</span><label class="collapse" for="c-38469174">[-]</label><label class="expand" for="c-38469174">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps that means you should implement that API.</div><br/></div></div></div></div><div id="38468974" class="c"><input type="checkbox" id="c-38468974" checked=""/><div class="controls bullet"><span class="by">eetus</span><span>|</span><a href="#38464637">prev</a><span>|</span><a href="#38464955">next</a><span>|</span><label class="collapse" for="c-38468974">[-]</label><label class="expand" for="c-38468974">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s confusing that you had to scroll up to realize the article isn&#x27;t by Martin Fowler.</div><br/></div></div><div id="38464955" class="c"><input type="checkbox" id="c-38464955" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#38468974">prev</a><span>|</span><a href="#38469900">next</a><span>|</span><label class="collapse" for="c-38464955">[-]</label><label class="expand" for="c-38464955">[5 more]</label></div><br/><div class="children"><div class="content">In practice I find a bigger problem is perversity - AI assistant doing OK with incremental prompting, but sometimes decides to just remove all comments from the code, or if asked to focus its effort on one section, deletes all other code. Code assistants need to be much integrated with IDEs and I think you probably need 2 or 3 running in parallel, maybe more.</div><br/><div id="38466487" class="c"><input type="checkbox" id="c-38466487" checked=""/><div class="controls bullet"><span class="by">sevagh</span><span>|</span><a href="#38464955">parent</a><span>|</span><a href="#38469900">next</a><span>|</span><label class="collapse" for="c-38466487">[-]</label><label class="expand" for="c-38466487">[4 more]</label></div><br/><div class="children"><div class="content">Yes, this really irritates me.<p>Me: &lt;prompt 1: modify this function&gt;<p>AI assistant (either ChatGPT or Copilot-X): &lt;attempt 1&gt;<p>Me: &lt;feedback&gt;<p>AI assistant: &lt;attempt 2&gt;, fixed with feedback, but deleted something crucial from attempt 1, for no reason at all</div><br/><div id="38466947" class="c"><input type="checkbox" id="c-38466947" checked=""/><div class="controls bullet"><span class="by">all2</span><span>|</span><a href="#38464955">root</a><span>|</span><a href="#38466487">parent</a><span>|</span><a href="#38469900">next</a><span>|</span><label class="collapse" for="c-38466947">[-]</label><label class="expand" for="c-38466947">[3 more]</label></div><br/><div class="children"><div class="content">To avoid stuff like this I&#x27;ve tried to prompt for only the necessary changes. I haven&#x27;t found a good prompt that does this repeatably. It might be worth some experimentation.</div><br/><div id="38468156" class="c"><input type="checkbox" id="c-38468156" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#38464955">root</a><span>|</span><a href="#38466947">parent</a><span>|</span><a href="#38469334">next</a><span>|</span><label class="collapse" for="c-38468156">[-]</label><label class="expand" for="c-38468156">[1 more]</label></div><br/><div class="children"><div class="content">One can usually get around it by modifying the prompt, but one really shouldn&#x27;t have to include things like &#x27;do not remove comments&#x27; over and over. My IDE  (shoutout to Jetbrains) lets me make custom prompts, but the real problems  here are the transformer model&#x27;s inability to maintain context or ask questions of its own, more readily, and a lack of visual grammar for &#x27;what are we both talking about, and how&#x27;. Pair programming has gone some way toward improving that in recent years, but realistically transformers are getting to where they can spit out code faster than most people can compose or type it (not <i>you</i> of course).  Looking at live diffs is not ideal, especially late in a coding session when fatigue is setting in. Some sort of shared context map for functions and variables might be a better approach. As things are I find myself using a clumsy mix of save-as and commits and often throwing away hours of work when an assistant is unable to backtrack.</div><br/></div></div><div id="38469334" class="c"><input type="checkbox" id="c-38469334" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#38464955">root</a><span>|</span><a href="#38466947">parent</a><span>|</span><a href="#38468156">prev</a><span>|</span><a href="#38469900">next</a><span>|</span><label class="collapse" for="c-38469334">[-]</label><label class="expand" for="c-38469334">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve used Aider &lt;<a href="https:&#x2F;&#x2F;aider.chat" rel="nofollow noreferrer">https:&#x2F;&#x2F;aider.chat</a>&gt; a fair amount, and I have read about Paul&#x27;s experiments with different &quot;diff producing&quot; methods. I think a good avenue to experiment is two-pass. First, ask the LLM to output only the changed code, then (in a separate conversion) as the LLM just to update the relevant lines with the change the first LLM provided. I suspect this would clear up a lot of the &quot;LLM failed to transcribe old code&quot; and &quot;diff isn&#x27;t well-formed&quot; errors that this tool has.</div><br/></div></div></div></div></div></div></div></div><div id="38469900" class="c"><input type="checkbox" id="c-38469900" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#38464955">prev</a><span>|</span><a href="#38468536">next</a><span>|</span><label class="collapse" for="c-38469900">[-]</label><label class="expand" for="c-38469900">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using chat gpt plus quite a bit for supporting me in programming tasks. It&#x27;s too flaky to trust blindly and you need to narrowly scope what it does. It can also be a bit hand wavy with some things and I&#x27;ve had issues getting it to generate working code for some more complicated things. But where it really shines is in documenting things, explaining things, and suggesting problem areas in code and possible solutions.<p>And you can do fun things like point it at an openapi schema and asking it some questions about that API. I&#x27;ve given it screenshots of websites and asked it to criticize the design or document what is visible. It&#x27;s amazingly good at supporting localization work.<p>I was working with some geospatial code for an algorithm that generates UTM coordinates from GPS coordinates a few weeks ago. I needed a Kotlin implementation that I could use on multiple of its platforms (js and jvm, i.e. no java dependencies allowed).<p>It was kind of useless writing the code for me for this (that&#x27;s the first thing I tried obviously) but it unblocked me a couple of times and helped me figure out some details.<p>I ultimately found several old Java implementations that contained a lot of undocumented magical numbers and I just asked it the meaning of those numbers (about a dozen) and it came back with good explanations (basically things like wgs84 ellipsoid parameters, radius of the earth, etc.). The code wasn&#x27;t quite working (it failed a test I wrote) so I asked it to identify possible causes for that and it came up with some uncovered edge cases that I was able to cross confirm with other implementations. In the end I was able to piece together a working implementation by combining different elements from several implementations. Each of them individually had issues. A lot of this code is ancient and there is apparently a lot of copy paste reuse in this space.</div><br/></div></div><div id="38468536" class="c"><input type="checkbox" id="c-38468536" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38469900">prev</a><span>|</span><a href="#38464360">next</a><span>|</span><label class="collapse" for="c-38468536">[-]</label><label class="expand" for="c-38468536">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re going to be productive with LLM coding assistants, the skill you most need to develop is a strong QA process. You need to be really good at running code, trying edge-cases and quickly getting to a point where you have proven to yourself that the code works. Having good habits around automated testing helps with this a lot.<p>If you&#x27;re already good at this stuff, you&#x27;ll find the risk of coding assistants getting things wrong is pretty minimal for you.<p>If you have bad habits where you frequently write and commit code without first executing it and trying to poke holes in it, you&#x27;ll find AI assisted coding full of traps.</div><br/></div></div><div id="38464360" class="c"><input type="checkbox" id="c-38464360" checked=""/><div class="controls bullet"><span class="by">meindnoch</span><span>|</span><a href="#38468536">prev</a><span>|</span><a href="#38465395">next</a><span>|</span><label class="collapse" for="c-38464360">[-]</label><label class="expand" for="c-38464360">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m happy that more and more people embrace these tools for more and more critical software.<p>It keeps me employed, and even increases my rate quite a bit.</div><br/><div id="38464944" class="c"><input type="checkbox" id="c-38464944" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#38464360">parent</a><span>|</span><a href="#38465395">next</a><span>|</span><label class="collapse" for="c-38464944">[-]</label><label class="expand" for="c-38464944">[1 more]</label></div><br/><div class="children"><div class="content">Are you an EMT?</div><br/></div></div></div></div><div id="38465395" class="c"><input type="checkbox" id="c-38465395" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#38464360">prev</a><span>|</span><a href="#38464250">next</a><span>|</span><label class="collapse" for="c-38465395">[-]</label><label class="expand" for="c-38465395">[1 more]</label></div><br/><div class="children"><div class="content">I feel like the work on using CFGs with LLMs should be low-hanging fruit for improving code assistants, but perhaps someone more knowledgeable could chime in[1], [2], [3].<p>At lot of the confabulations we see today - non-existent variables, imports and APIs, out-of-scope variables, etc - would seem (to me) to be meaningfully addressable with these techniques.<p>Relatedly, I have gotten surprisingly great mileage out of treating confabulations, in the first instance, as a user (ie, my own) failure to adequately contextualise, rather than error.<p>In a sense, CFGs give you sharper tools to do that contextualisation. I wonder how far the “sharper tools” approach will carry us. It seems, to this interested layman, consistent with Shannon’s work in statistical language modelling.[4]<p>The term “prompt engineering” implies, to me, a focus on the instructive aspects of prompting, which is a bit unfortunate but also wholly consistent with the way I see colleagues and friends trying to interact with LLMs. Perhaps we should instead call it “context composition” or something, to emphasise the constructive nature.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;outlines-dev&#x2F;outlines">https:&#x2F;&#x2F;github.com&#x2F;outlines-dev&#x2F;outlines</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773</a><p>[3] <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;156gu8c&#x2F;d_constraining_llama_models_with_context_free&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;156gu8c&#x2F;d_const...</a><p>[4] <a href="https:&#x2F;&#x2F;hedgehogreview.com&#x2F;issues&#x2F;markets-and-the-good&#x2F;articles&#x2F;language-machinery" rel="nofollow noreferrer">https:&#x2F;&#x2F;hedgehogreview.com&#x2F;issues&#x2F;markets-and-the-good&#x2F;artic...</a></div><br/></div></div><div id="38464250" class="c"><input type="checkbox" id="c-38464250" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#38465395">prev</a><span>|</span><a href="#38470008">next</a><span>|</span><label class="collapse" for="c-38464250">[-]</label><label class="expand" for="c-38464250">[5 more]</label></div><br/><div class="children"><div class="content">Are there tools yet that put the compiler in the loop? Maybe even a check-compile-test loop that bails on the first failure and then tries to refine it in the background based on what failed?</div><br/><div id="38468561" class="c"><input type="checkbox" id="c-38468561" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38464250">parent</a><span>|</span><a href="#38464933">next</a><span>|</span><label class="collapse" for="c-38468561">[-]</label><label class="expand" for="c-38468561">[1 more]</label></div><br/><div class="children"><div class="content">Yes. ChatGPT Code Interpreter mode does exactly this - it writes code, runs it through a Python interpreter, then if there are any errors it rewrites the code and runs it until it works.<p>... and you can use it to run a C compiler too, if you know what you are doing! <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Oct&#x2F;17&#x2F;open-questions&#x2F;#open-questions.037.jpeg" rel="nofollow noreferrer">https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Oct&#x2F;17&#x2F;open-questions&#x2F;#open-q...</a></div><br/></div></div><div id="38464933" class="c"><input type="checkbox" id="c-38464933" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#38464250">parent</a><span>|</span><a href="#38468561">prev</a><span>|</span><a href="#38470008">next</a><span>|</span><label class="collapse" for="c-38464933">[-]</label><label class="expand" for="c-38464933">[3 more]</label></div><br/><div class="children"><div class="content">Then maybe the model could be fine-tuned on that loop, haha. Could be a fun thing to try at least.</div><br/><div id="38465885" class="c"><input type="checkbox" id="c-38465885" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#38464250">root</a><span>|</span><a href="#38464933">parent</a><span>|</span><a href="#38470008">next</a><span>|</span><label class="collapse" for="c-38465885">[-]</label><label class="expand" for="c-38465885">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a bit of fools-errand because they train on information which is no longer valid and will get stuck if you don&#x27;t inform them.  For instance GPT cannot write a connection to an openai endpoint because the API was upgraded to 1.0 and broke compatibility with all the code it learned from</div><br/><div id="38467857" class="c"><input type="checkbox" id="c-38467857" checked=""/><div class="controls bullet"><span class="by">bloopernova</span><span>|</span><a href="#38464250">root</a><span>|</span><a href="#38465885">parent</a><span>|</span><a href="#38470008">next</a><span>|</span><label class="collapse" for="c-38467857">[-]</label><label class="expand" for="c-38467857">[1 more]</label></div><br/><div class="children"><div class="content">Is it possible for an LLM to have knowledge&#x2F;input marked as &quot;deprecated&#x2F;obsolete&quot;? Either by a user or some sort of &quot;retraining&quot; process?</div><br/></div></div></div></div></div></div></div></div><div id="38470008" class="c"><input type="checkbox" id="c-38470008" checked=""/><div class="controls bullet"><span class="by">russfink</span><span>|</span><a href="#38464250">prev</a><span>|</span><a href="#38464220">next</a><span>|</span><label class="collapse" for="c-38470008">[-]</label><label class="expand" for="c-38470008">[1 more]</label></div><br/><div class="children"><div class="content">I use it like a man page on steroids. “Write an example bash program that implements a set data structure, and demonstrate it with examples.”</div><br/></div></div><div id="38464220" class="c"><input type="checkbox" id="c-38464220" checked=""/><div class="controls bullet"><span class="by">cleandreams</span><span>|</span><a href="#38470008">prev</a><span>|</span><a href="#38464275">next</a><span>|</span><label class="collapse" for="c-38464220">[-]</label><label class="expand" for="c-38464220">[5 more]</label></div><br/><div class="children"><div class="content">I have several issues with coding assistants.<p>Over time, will less skilled programmers produce more critical code? I think so. At some point a jet will fall out of the sky because the coding assistant wasn&#x27;t correct and the whole profession will have a black eye.<p>The programmers will be less skilled because the (up until recently) lack of coding assistants provides a more rigorous and thorough training environment. With coding assistants the profession will be less intellectually selective because a wider range of people can do it. I don&#x27;t think this is good given how critical some code is.<p>There is another related issue. Studies have shown that use of google maps has resulted in a deterioration of people&#x27;s ability to navigate. Human mapping and navigation ability needs training which it doesn&#x27;t get when google maps are used. This sort of thing will be an issue with coding.</div><br/><div id="38465211" class="c"><input type="checkbox" id="c-38465211" checked=""/><div class="controls bullet"><span class="by">BurningFrog</span><span>|</span><a href="#38464220">parent</a><span>|</span><a href="#38464735">next</a><span>|</span><label class="collapse" for="c-38465211">[-]</label><label class="expand" for="c-38465211">[1 more]</label></div><br/><div class="children"><div class="content">I spent 10 years pair programming. It&#x27;s a similar situation in some ways.<p>Like, I can&#x27;t know if the code my pair writes has flaws, just like an AI coding assistant.<p>I&#x27;ve never learned so much about programming as when pairing. Having someone else to ask or suggest improvements is just invaluable. It&#x27;s very rarely I learn something new from myself, but another human will always know things I don&#x27;t, just like an AI.<p>Of course, you don&#x27;t blindly accept the code your pair&#x2F;assistant writes. You have to understand it, ask questions, and most of all write tests that confirms it actually works.</div><br/></div></div><div id="38464735" class="c"><input type="checkbox" id="c-38464735" checked=""/><div class="controls bullet"><span class="by">SoftTalker</span><span>|</span><a href="#38464220">parent</a><span>|</span><a href="#38465211">prev</a><span>|</span><a href="#38464821">next</a><span>|</span><label class="collapse" for="c-38464735">[-]</label><label class="expand" for="c-38464735">[2 more]</label></div><br/><div class="children"><div class="content">This will be an issue with all knowledge work. The machines will have the knowledge and more and more we will just trust them because we don&#x27;t know ourselves. Google Maps is a great example.</div><br/><div id="38465632" class="c"><input type="checkbox" id="c-38465632" checked=""/><div class="controls bullet"><span class="by">hamburga</span><span>|</span><a href="#38464220">root</a><span>|</span><a href="#38464735">parent</a><span>|</span><a href="#38464821">next</a><span>|</span><label class="collapse" for="c-38465632">[-]</label><label class="expand" for="c-38465632">[1 more]</label></div><br/><div class="children"><div class="content">I want to build a &quot;Google Maps that doesn&#x27;t make you dumber.&quot;<p>For local navigation, first and foremost. The goal is to teach you how to navigate your locale, so you use it less and less. You still will want to ask it for traffic updates, but you talk to it like you would between locals who know all the roads.<p>As a model for how to do AI in a way that enhances your thinking rather than softens&#x2F;replaces it.</div><br/></div></div></div></div><div id="38464821" class="c"><input type="checkbox" id="c-38464821" checked=""/><div class="controls bullet"><span class="by">bena</span><span>|</span><a href="#38464220">parent</a><span>|</span><a href="#38464735">prev</a><span>|</span><a href="#38464275">next</a><span>|</span><label class="collapse" for="c-38464821">[-]</label><label class="expand" for="c-38464821">[1 more]</label></div><br/><div class="children"><div class="content">A wide range of people can build things. We trust only a few to build jets and skyscrapers, etc.<p>I think much the same will happen with regards to programming. Sure, most people will be able to bust out a simple script to do X. But if you want to do a &quot;serious task&quot;, you&#x27;re going to get a professional.</div><br/></div></div></div></div><div id="38464275" class="c"><input type="checkbox" id="c-38464275" checked=""/><div class="controls bullet"><span class="by">righthand</span><span>|</span><a href="#38464220">prev</a><span>|</span><a href="#38466753">next</a><span>|</span><label class="collapse" for="c-38464275">[-]</label><label class="expand" for="c-38464275">[1 more]</label></div><br/><div class="children"><div class="content">Honestly I’d rather just RTFM and code it myself than invent a game to deal with these issues.</div><br/></div></div><div id="38466753" class="c"><input type="checkbox" id="c-38466753" checked=""/><div class="controls bullet"><span class="by">PH95VuimJjqBqy</span><span>|</span><a href="#38464275">prev</a><span>|</span><a href="#38464111">next</a><span>|</span><label class="collapse" for="c-38466753">[-]</label><label class="expand" for="c-38466753">[1 more]</label></div><br/><div class="children"><div class="content">I basically refuse to use any sort of AI assisted autocomplete for this very reason.  I want consistency more than accuracy.  consistency enables power and reliability, if it changes every 3rd time on the same input it slows me down.</div><br/></div></div><div id="38464111" class="c"><input type="checkbox" id="c-38464111" checked=""/><div class="controls bullet"><span class="by">kazinator</span><span>|</span><a href="#38466753">prev</a><span>|</span><a href="#38466485">next</a><span>|</span><label class="collapse" for="c-38464111">[-]</label><label class="expand" for="c-38464111">[4 more]</label></div><br/><div class="children"><div class="content">The way you tackle the unreliability of coding assistants is to know what you&#x27;re doing so that you don&#x27;t need a coding assistant, so that you&#x27;re only using it to save time and effort.<p>Roughly speaking, if you stick to using AI for writing code you could have written yourself, you&#x27;re okay.</div><br/><div id="38464672" class="c"><input type="checkbox" id="c-38464672" checked=""/><div class="controls bullet"><span class="by">digging</span><span>|</span><a href="#38464111">parent</a><span>|</span><a href="#38464280">next</a><span>|</span><label class="collapse" for="c-38464672">[-]</label><label class="expand" for="c-38464672">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve only used a very small amount of AI assistance (mostly Anthropic&#x27;s Claude), and always to learn, not to do. That is, I will ask it what&#x27;s happening, why are things breaking, etc. It doesn&#x27;t have to have the right answers, it just needs to unblock me.<p>I hear it is also quite useful for <i>doing</i> things which you know extremely well but are tedious to do. Anything in between is certainly a danger zone.</div><br/></div></div><div id="38464280" class="c"><input type="checkbox" id="c-38464280" checked=""/><div class="controls bullet"><span class="by">NateEag</span><span>|</span><a href="#38464111">parent</a><span>|</span><a href="#38464672">prev</a><span>|</span><a href="#38466485">next</a><span>|</span><label class="collapse" for="c-38464280">[-]</label><label class="expand" for="c-38464280">[2 more]</label></div><br/><div class="children"><div class="content">Though regular use of the assistant will degrade your ability to program without it.</div><br/><div id="38464650" class="c"><input type="checkbox" id="c-38464650" checked=""/><div class="controls bullet"><span class="by">majormajor</span><span>|</span><a href="#38464111">root</a><span>|</span><a href="#38464280">parent</a><span>|</span><a href="#38466485">next</a><span>|</span><label class="collapse" for="c-38464650">[-]</label><label class="expand" for="c-38464650">[1 more]</label></div><br/><div class="children"><div class="content">I think in the same way that autocomplete does - I may not have typed out `.length` or whatever it happens to be in the language I used last year enough to remember a year later if it&#x27;s len or length or size and if it&#x27;s a property or a method after a year goes by without me touching that language... but then it&#x27;s a simple search away to refresh my memory, and overall the autocomplete saves a LOT of time that makes up for this.<p>Yeah, if you never knew what the code that got generated did in the first place, that&#x27;s not gonna apply, but if you&#x27;re using it as basically just a code expander for things you could do the pseudocode for in your sleep, you&#x27;re probably gonna be ok.</div><br/></div></div></div></div></div></div><div id="38466485" class="c"><input type="checkbox" id="c-38466485" checked=""/><div class="controls bullet"><span class="by">tomjakubowski</span><span>|</span><a href="#38464111">prev</a><span>|</span><a href="#38464028">next</a><span>|</span><label class="collapse" for="c-38466485">[-]</label><label class="expand" for="c-38466485">[1 more]</label></div><br/><div class="children"><div class="content">fairly off-topic, sorry: Midjourney gets the cartoon donkey&#x27;s snout wrong, so wrong. It looks more like a cartoon dog. For some reason I&#x27;m really bothered by it.</div><br/></div></div><div id="38464028" class="c"><input type="checkbox" id="c-38464028" checked=""/><div class="controls bullet"><span class="by">DonaldPShimoda</span><span>|</span><a href="#38466485">prev</a><span>|</span><a href="#38466053">next</a><span>|</span><label class="collapse" for="c-38464028">[-]</label><label class="expand" for="c-38464028">[23 more]</label></div><br/><div class="children"><div class="content">I&#x27;m just waiting for people to catch on that using an inherently unreliable tool that cannot gauge its own reliability to generate code or answer fact-based queries is a fool&#x27;s errand. But I expect we&#x27;ll spend a <i>lot</i> of effort on &quot;verifying&quot; the results before we just give up entirely.</div><br/><div id="38464145" class="c"><input type="checkbox" id="c-38464145" checked=""/><div class="controls bullet"><span class="by">kazinator</span><span>|</span><a href="#38464028">parent</a><span>|</span><a href="#38465905">next</a><span>|</span><label class="collapse" for="c-38464145">[-]</label><label class="expand" for="c-38464145">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve written a few pieces of code with the help of AI. The trick is that I don&#x27;t need the help. I could see where the bugs are.<p>The AI could do certain things much faster than I would be able to by hand. For instance, in a certain hash table containing structures, it turned out that the deletion algorithm which moves elements couldn&#x27;t be used because other code retains (reference counted) pointers to the structures, so the addresses of the object have to be stable.  AI easily and correctly rewrote the code from &quot;array of struct&quot; to &quot;array of pointer to struct&quot; representation: the declaration of the thing and all the code working on it was correctly adjusted. I can do that myself, but not in two seconds.</div><br/></div></div><div id="38465905" class="c"><input type="checkbox" id="c-38465905" checked=""/><div class="controls bullet"><span class="by">willsmith72</span><span>|</span><a href="#38464028">parent</a><span>|</span><a href="#38464145">prev</a><span>|</span><a href="#38464367">next</a><span>|</span><label class="collapse" for="c-38465905">[-]</label><label class="expand" for="c-38465905">[5 more]</label></div><br/><div class="children"><div class="content">I could not disagree more. Having something generate code which is 90-100% correct is extremely valuable.<p>E.g. creating a new page in an app.<p>Feed an LLM the design, the language&#x2F;framework&#x2F;component library you&#x27;re using, and get a page which is 90% of the way there. Some tweaks and you&#x27;re good.<p>Far, far quicker than going by hand, and often better quality code than a junior developer.<p>Now I would never deploy that code without reading it, understanding it, and testing it, but I would always do that anyway. GPT4 is close enough to a good software engineer, that to resist is it to disadvantage your business.<p>Now if you&#x27;re coding for pleasure and the fun of creation and creativity, then ditch the LLMs, they take some of that fun away for sure. But most of the time, I&#x27;m focused on achieving business outcomes quickly. That&#x27;s way more productive with a modern LLM</div><br/><div id="38466216" class="c"><input type="checkbox" id="c-38466216" checked=""/><div class="controls bullet"><span class="by">bigstrat2003</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38465905">parent</a><span>|</span><a href="#38464367">next</a><span>|</span><label class="collapse" for="c-38466216">[-]</label><label class="expand" for="c-38466216">[4 more]</label></div><br/><div class="children"><div class="content">I strongly disagree. Having something which is 90% reliable doesn&#x27;t save me any effort over just doing it myself. If I have to spend the time to check everything the tool generates (which I do, because LLMs are unreliable) then I may as well have written it myself to start with.<p>I firmly believe that the worst kind of help is unreliable help. If your help never does its job, then you know you have to do everything yourself. If your help always does its job, you know you can trust it. If your help only sometimes does its job, you get the worst deal of all because you never know what you&#x27;ll get and have to check every single time.</div><br/><div id="38468579" class="c"><input type="checkbox" id="c-38468579" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38466216">parent</a><span>|</span><a href="#38466278">next</a><span>|</span><label class="collapse" for="c-38468579">[-]</label><label class="expand" for="c-38468579">[1 more]</label></div><br/><div class="children"><div class="content">I have nearly 12 months of personal experience now that having LLMs produce code for me - even when I only use ~20% of the code they generate - is still a huge personal productivity boost.<p>Unreliable help is still useful if you know that it&#x27;s unreliable - you learn to keep a critical eye on what it&#x27;s doing and correct when necessary. Still saves a ton of time, and I&#x27;m not guessing that, I&#x27;m saying that from my own experience.</div><br/></div></div><div id="38466278" class="c"><input type="checkbox" id="c-38466278" checked=""/><div class="controls bullet"><span class="by">willsmith72</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38466216">parent</a><span>|</span><a href="#38468579">prev</a><span>|</span><a href="#38464367">next</a><span>|</span><label class="collapse" for="c-38466278">[-]</label><label class="expand" for="c-38466278">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If I have to spend the time to check everything the tool generates (which I do, because LLMs are unreliable) then I may as well have written it myself to start with.<p>Do you feel the same way about a PR from a coworker?</div><br/><div id="38468611" class="c"><input type="checkbox" id="c-38468611" checked=""/><div class="controls bullet"><span class="by">diputsmonro</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38466278">parent</a><span>|</span><a href="#38464367">next</a><span>|</span><label class="collapse" for="c-38468611">[-]</label><label class="expand" for="c-38468611">[1 more]</label></div><br/><div class="children"><div class="content">Depends on the coworker.  I would say that I trust ChatGPT code much less than the average coworker, because coworkers usually don&#x27;t do something like use imaginary variables or check-in code that doesn&#x27;t compile.</div><br/></div></div></div></div></div></div></div></div><div id="38464367" class="c"><input type="checkbox" id="c-38464367" checked=""/><div class="controls bullet"><span class="by">throwuwu</span><span>|</span><a href="#38464028">parent</a><span>|</span><a href="#38465905">prev</a><span>|</span><a href="#38465070">next</a><span>|</span><label class="collapse" for="c-38464367">[-]</label><label class="expand" for="c-38464367">[2 more]</label></div><br/><div class="children"><div class="content">Just wait a few months. Verifiability is the technique du jour and will make its way into a variety of models soon enough.</div><br/><div id="38465160" class="c"><input type="checkbox" id="c-38465160" checked=""/><div class="controls bullet"><span class="by">westoncb</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38464367">parent</a><span>|</span><a href="#38465070">next</a><span>|</span><label class="collapse" for="c-38465160">[-]</label><label class="expand" for="c-38465160">[1 more]</label></div><br/><div class="children"><div class="content">Seems like there are certain fundamental limits to what can be done here though. Much of the advantage to using these models is being able to come up with a vague&#x2F;informal spec and most of the time have it get what you mean and come up with something serviceable with very little effort. If the spec you have in mind to begin with is fuzzy and informal, what do you use to perform verification?<p>After all, whether a result is correct or not depends on whether it matches the user&#x27;s desire, so verification criteria must come from that source too.<p>Sure there are certain types of relatively objective correctness that most of the time will line up with a user&#x27;s desires, but this kind of verification can never be complete afaict.</div><br/></div></div></div></div><div id="38465070" class="c"><input type="checkbox" id="c-38465070" checked=""/><div class="controls bullet"><span class="by">coffeecantcode</span><span>|</span><a href="#38464028">parent</a><span>|</span><a href="#38464367">prev</a><span>|</span><a href="#38464062">next</a><span>|</span><label class="collapse" for="c-38465070">[-]</label><label class="expand" for="c-38465070">[3 more]</label></div><br/><div class="children"><div class="content">.</div><br/><div id="38465420" class="c"><input type="checkbox" id="c-38465420" checked=""/><div class="controls bullet"><span class="by">agentdrek</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38465070">parent</a><span>|</span><a href="#38464062">next</a><span>|</span><label class="collapse" for="c-38465420">[-]</label><label class="expand" for="c-38465420">[2 more]</label></div><br/><div class="children"><div class="content">is that a vi repeat? lol</div><br/><div id="38467118" class="c"><input type="checkbox" id="c-38467118" checked=""/><div class="controls bullet"><span class="by">kevindamm</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38465420">parent</a><span>|</span><a href="#38464062">next</a><span>|</span><label class="collapse" for="c-38467118">[-]</label><label class="expand" for="c-38467118">[1 more]</label></div><br/><div class="children"><div class="content">yyp</div><br/></div></div></div></div></div></div><div id="38464062" class="c"><input type="checkbox" id="c-38464062" checked=""/><div class="controls bullet"><span class="by">onethought</span><span>|</span><a href="#38464028">parent</a><span>|</span><a href="#38465070">prev</a><span>|</span><a href="#38466053">next</a><span>|</span><label class="collapse" for="c-38464062">[-]</label><label class="expand" for="c-38464062">[11 more]</label></div><br/><div class="children"><div class="content">Don’t humans fit that definition? We’ve managed okay for 1000s of years under those conditions.</div><br/><div id="38464954" class="c"><input type="checkbox" id="c-38464954" checked=""/><div class="controls bullet"><span class="by">abeppu</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38464062">parent</a><span>|</span><a href="#38464319">next</a><span>|</span><label class="collapse" for="c-38464954">[-]</label><label class="expand" for="c-38464954">[1 more]</label></div><br/><div class="children"><div class="content">Humans are unreliable, but we are also under normal circumstances thoroughly and continually grounded in an external world whose mechanics we interact with, make predictions about, and correct our beliefs about.<p>The specific way we&#x27;re training coding assistants for next-token-prediction would also be an incredibly difficult context for humans to produce code.<p>Suppose you were dropped off in an society of aliens whose perceptual, cultural and cognitive universe is meaningfully different from our own; you don&#x27;t have a grounding in concepts of what they&#x27;re trying to _do_ with their programs. You receive a giant dump of reams and reams of source code, in their unfamiliar script, where none of the names initially mean anything to you. In the pile of training material handed to you, you might find some documentation about their programming language, but it&#x27;s written in their (foreign, weird to you) natural language, and is mixed with everythign else. You never get a teacher who can answer questions, never get access to a IDE&#x2F;repl&#x2F;interpreter&#x2F;debugger&#x2F;compiler, never get to _run_ a program on different inputs to see its outputs, never get to add a log line to peek at the program&#x27;s internal state, etc. After a _lot_ of training, you can often predict the next symbol in a program text. But shouldn&#x27;t we _expect_ you to be &quot;unreliable&quot;? You don&#x27;t have the ability to run checks against the code you produce! You don&#x27;t get a warning if you use a variable that doesn&#x27;t exist! You just produce _tokens_, and get no feedback.<p>To the degree humans are reliable at coding, it&#x27;s because we can simulate what program execution will do, with a level of abstraction which we vary in a task dependent way. You can mentally step through every line in a program carefully if you need to. But you can also mentally choose to trust some abstraction and skip steps which you infer cannot be related to some attribute or condition of interest if that abstraction is upheld. The most important parts of your attention are on _what the program does_. This is fully hidden in the next-token-prediction scenario, which is totally focused on _what tokens are used to write the program_.</div><br/></div></div><div id="38464319" class="c"><input type="checkbox" id="c-38464319" checked=""/><div class="controls bullet"><span class="by">trefoiled</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38464062">parent</a><span>|</span><a href="#38464954">prev</a><span>|</span><a href="#38464256">next</a><span>|</span><label class="collapse" for="c-38464319">[-]</label><label class="expand" for="c-38464319">[1 more]</label></div><br/><div class="children"><div class="content">I hear this argument applied often when people bring up the deficiencies of AI, and I don&#x27;t find it convincing. Compare an AI coding assistant to reaching out to another engineer on my team as an example. If I know this engineer, I will likely have an idea of their relative skill level, their familiarity with the problem at hand, their propensity to suggest one type of solution over another, etc. People are pretty good at developing this kind of sense because we work with other people constantly. The AI assistant, on the other hand, is very much not like a human. I have a limited capacity to understand its &quot;thought process,&quot; and I consider myself far more technical than the average person. This makes a verification step troublesome, because I don&#x27;t know what to expect.<p>This difference is even more stark when it comes to driving assistants. Video compilations of Teslas with FSD behaving erratically and most importantly, unpredictably, are all over the place. Experienced Tesla drivers seem to have some limited ability to predict the weaknesses of the FSD package, but the issue is that the driving assistant is so unlike a human. I&#x27;ve seen multiple examples of people saying &quot;well, humans cause car crashes too,&quot; but the key difference is that I have to sit behind the wheel and deal with the fact that my driving assistant may or may not suddenly swerve into oncoming traffic. The reasons for it doing so are likely obscure to me, and this is a real problem.</div><br/></div></div><div id="38464256" class="c"><input type="checkbox" id="c-38464256" checked=""/><div class="controls bullet"><span class="by">ryanklee</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38464062">parent</a><span>|</span><a href="#38464319">prev</a><span>|</span><a href="#38464189">next</a><span>|</span><label class="collapse" for="c-38464256">[-]</label><label class="expand" for="c-38464256">[1 more]</label></div><br/><div class="children"><div class="content">They do fit this definition. One result of the rise of generative AI is exposing just how severely and commonly people misperceive their own capabilities and the functioning of their cognitive powers.</div><br/></div></div><div id="38464189" class="c"><input type="checkbox" id="c-38464189" checked=""/><div class="controls bullet"><span class="by">bena</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38464062">parent</a><span>|</span><a href="#38464256">prev</a><span>|</span><a href="#38466053">next</a><span>|</span><label class="collapse" for="c-38464189">[-]</label><label class="expand" for="c-38464189">[7 more]</label></div><br/><div class="children"><div class="content">They do not. A human can verify its own reliability.</div><br/><div id="38464221" class="c"><input type="checkbox" id="c-38464221" checked=""/><div class="controls bullet"><span class="by">ryanklee</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38464189">parent</a><span>|</span><a href="#38464766">next</a><span>|</span><label class="collapse" for="c-38464221">[-]</label><label class="expand" for="c-38464221">[5 more]</label></div><br/><div class="children"><div class="content">A human cannot do this self-sufficiently. This is why we work so hard to implement risk mitigation measures and checks and balances on changes.</div><br/><div id="38464773" class="c"><input type="checkbox" id="c-38464773" checked=""/><div class="controls bullet"><span class="by">bena</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38464221">parent</a><span>|</span><a href="#38464766">next</a><span>|</span><label class="collapse" for="c-38464773">[-]</label><label class="expand" for="c-38464773">[4 more]</label></div><br/><div class="children"><div class="content">Yes, not all humans at all tasks all the time. And some things are important enough to implement checks regardless.<p>However, there&#x27;s a lot we can just throw humans at and trust that the thing will get complete and be correct. And even with the checks and balances, we can have the human perform those checks and balances. A human is a pretty autonomous unit on average.<p>So far, AI can&#x27;t really say &quot;let me double check that for you&quot; for instance. You ask it a thing, it does a thing, and that&#x27;s it. If it&#x27;s wrong, you have to tell it to do the thing again, but differently.<p>In all the rush to paint these LLMs as &quot;pretty much human&quot;, we&#x27;ve instead taken to severely downplaying just how adaptable and clever most sentient beings can be.</div><br/><div id="38465146" class="c"><input type="checkbox" id="c-38465146" checked=""/><div class="controls bullet"><span class="by">ryanklee</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38464773">parent</a><span>|</span><a href="#38464766">next</a><span>|</span><label class="collapse" for="c-38465146">[-]</label><label class="expand" for="c-38465146">[3 more]</label></div><br/><div class="children"><div class="content">AIs can double check. Agent to agent confirmation and validation is a thing.<p>In any case, the point is that we have learned techniques to compensate for human fallibility. We will learn techniques to compensate for gen AI fallibility, as well. The objection that AIs can be wrong is far less a barrier to the rise of their utility than is often supposed.</div><br/><div id="38465738" class="c"><input type="checkbox" id="c-38465738" checked=""/><div class="controls bullet"><span class="by">bena</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38465146">parent</a><span>|</span><a href="#38464766">next</a><span>|</span><label class="collapse" for="c-38465738">[-]</label><label class="expand" for="c-38465738">[2 more]</label></div><br/><div class="children"><div class="content">You see how that&#x27;s worse, right?<p>The original argument put forth was that &quot;an inherently unreliable tool cannot gauge its own reliability&quot;.<p>Someone responded that humans fit that description as well.<p>I said we don&#x27;t. We can and do verify our own reliability. We can essentially test our assumptions against the real world and fix them.<p>You then claimed we couldn&#x27;t do that &quot;self-sufficiently&quot;.<p>I responded that while that is true for some tasks, for a lot of tasks, we can. That an AI can&#x27;t check itself and won&#x27;t even try.<p>And now you&#x27;re telling me that they can check against each other.<p>But if you can&#x27;t trust the originals, asking them if they trust each other is kind of pointless. You&#x27;re not really doing anything more than adding another layer.<p>For example: If I put my pants on backwards, I correct that myself. Without the need to check and&#x2F;or balance against any other person. I am self-correcting to a large degree. The AI would not even know to check its pants until someone told it it was wrong.<p>The objection isn&#x27;t that &quot;AIs can be wrong&quot;, the objection is that AIs can&#x27;t really tell the difference between correct and incorrect. So everything has to be checked, often with as much effort as it would take to do the thing in the first place.</div><br/><div id="38467628" class="c"><input type="checkbox" id="c-38467628" checked=""/><div class="controls bullet"><span class="by">ryanklee</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38465738">parent</a><span>|</span><a href="#38464766">next</a><span>|</span><label class="collapse" for="c-38467628">[-]</label><label class="expand" for="c-38467628">[1 more]</label></div><br/><div class="children"><div class="content">This is a very narrow view of how LLMs can interact to improve inference accuracy. Different LLMs have different capabilities. They can be used in coordination to improve results.<p>Your objections seem to rely on a restricted view that says &quot;we can&#x27;t do better&quot; but with no evidence. Whereas we have plenty of evidence of massive, continual improvement in the very areas you are holding up as problematic.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38464766" class="c"><input type="checkbox" id="c-38464766" checked=""/><div class="controls bullet"><span class="by">cornel_io</span><span>|</span><a href="#38464028">root</a><span>|</span><a href="#38464189">parent</a><span>|</span><a href="#38464221">prev</a><span>|</span><a href="#38466053">next</a><span>|</span><label class="collapse" for="c-38464766">[-]</label><label class="expand" for="c-38464766">[1 more]</label></div><br/><div class="children"><div class="content">If that was even close to true then I would have had to fire far fewer people over the years.</div><br/></div></div></div></div></div></div></div></div><div id="38466053" class="c"><input type="checkbox" id="c-38466053" checked=""/><div class="controls bullet"><span class="by">slalomskiing</span><span>|</span><a href="#38464028">prev</a><span>|</span><a href="#38468723">next</a><span>|</span><label class="collapse" for="c-38466053">[-]</label><label class="expand" for="c-38466053">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like an exercise in frustration</div><br/></div></div><div id="38468723" class="c"><input type="checkbox" id="c-38468723" checked=""/><div class="controls bullet"><span class="by">Obscurity4340</span><span>|</span><a href="#38466053">prev</a><span>|</span><a href="#38467374">next</a><span>|</span><label class="collapse" for="c-38468723">[-]</label><label class="expand" for="c-38468723">[2 more]</label></div><br/><div class="children"><div class="content">[]</div><br/><div id="38469187" class="c"><input type="checkbox" id="c-38469187" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#38468723">parent</a><span>|</span><a href="#38467374">next</a><span>|</span><label class="collapse" for="c-38469187">[-]</label><label class="expand" for="c-38469187">[1 more]</label></div><br/><div class="children"><div class="content">Why?  And why allow autocomplete?  Why not ban anything including compilers, especially optimizing compilers?  How do you draw the line?</div><br/></div></div></div></div><div id="38467374" class="c"><input type="checkbox" id="c-38467374" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#38468723">prev</a><span>|</span><a href="#38465568">next</a><span>|</span><label class="collapse" for="c-38467374">[-]</label><label class="expand" for="c-38467374">[1 more]</label></div><br/><div class="children"><div class="content">Not use them?</div><br/></div></div><div id="38465568" class="c"><input type="checkbox" id="c-38465568" checked=""/><div class="controls bullet"><span class="by">firebot</span><span>|</span><a href="#38467374">prev</a><span>|</span><label class="collapse" for="c-38465568">[-]</label><label class="expand" for="c-38465568">[2 more]</label></div><br/><div class="children"><div class="content">Maybe learn to code?</div><br/><div id="38466102" class="c"><input type="checkbox" id="c-38466102" checked=""/><div class="controls bullet"><span class="by">sciolist</span><span>|</span><a href="#38465568">parent</a><span>|</span><label class="collapse" for="c-38466102">[-]</label><label class="expand" for="c-38466102">[1 more]</label></div><br/><div class="children"><div class="content">My good-faith interpretation of your comment is: &quot;Maybe learn to code (without external resources or tools)?&quot; LLMs are another tool and resource, just like StackOverflow, linters, autocomplete, Google, etc. None of these tools are infallible, but they provide value. Just like all other tools, you don&#x27;t need to use LLMs because of their issues - but we want them to be as useful as possible - what the author is trying to do.</div><br/></div></div></div></div></div></div></div></div></div></body></html>