<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687165250065" as="style"/><link rel="stylesheet" href="styles.css?v=1687165250065"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://enccs.github.io/gpu-programming/">GPU Programming: When, Why and How?</a> <span class="domain">(<a href="https://enccs.github.io">enccs.github.io</a>)</span></div><div class="subtext"><span>transpute</span> | <span>13 comments</span></div><br/><div><div id="36388140" class="c"><input type="checkbox" id="c-36388140" checked=""/><div class="controls bullet"><span class="by">Munksgaard</span><span>|</span><a href="#36388000">next</a><span>|</span><label class="collapse" for="c-36388140">[-]</label><label class="expand" for="c-36388140">[1 more]</label></div><br/><div class="children"><div class="content">Shameless plug for Futhark[0], which you can use to write your computational kernels.  The idea is to use functional constructs like map and reduce to express parallel code and let the compiler handle the generation of low-level OpenCL or CUDA.<p>Disclaimer: I&#x27;ve recently finished a PhD focused on memory optimizations in Futhark.<p>[0]: <a href="https:&#x2F;&#x2F;futhark-lang.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;futhark-lang.org&#x2F;</a><p>Edit: They do actually mention stuff like Julia and NumPy.</div><br/></div></div><div id="36388000" class="c"><input type="checkbox" id="c-36388000" checked=""/><div class="controls bullet"><span class="by">hutzlibu</span><span>|</span><a href="#36388140">prev</a><span>|</span><a href="#36388085">next</a><span>|</span><label class="collapse" for="c-36388000">[-]</label><label class="expand" for="c-36388000">[3 more]</label></div><br/><div class="children"><div class="content">Interesting, but very heavy read. And this is about the low level access towards it via system libaries.<p>A more simple way to get into GPU programming, would be WebGPU.<p>I can recommend this tutorial as an introduction:<p><a href="https:&#x2F;&#x2F;surma.dev&#x2F;things&#x2F;webgpu&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;surma.dev&#x2F;things&#x2F;webgpu&#x2F;</a><p>GPU programming is really a different way of programming, even though the code looks mostly familiar. And if you are used to single threaded, it will give you a massive headache thinking about, how to do everything in parallel, so that everything is not blocking everything.<p>The raw power is tempting, so much that I evaluate now how to do allmost everything on the GPU, but many things simply are not suitable to do there.<p>Basically, you want to avoid conditions and loops. Cannot do recursion. Debugging is a pain and non obvious things can make everything very slow, until you roughly understand, what is going on inside.</div><br/><div id="36388075" class="c"><input type="checkbox" id="c-36388075" checked=""/><div class="controls bullet"><span class="by">onion2k</span><span>|</span><a href="#36388000">parent</a><span>|</span><a href="#36388085">next</a><span>|</span><label class="collapse" for="c-36388075">[-]</label><label class="expand" for="c-36388075">[2 more]</label></div><br/><div class="children"><div class="content"><i>how to do everything in parallel</i><p>I found it was worse than that when I started playing with shaders, because my idea of parallelism came from threads, workers, and async functions eg doing several separate tasks at the same time. Parallel on a GPU is more like running lots of <i>the same function</i> each with different parameters at the same time eg running a function to calculate the color of a pixel using its x and y coordinates (and maybe some other uniforms) for every pixel on the screen.</div><br/><div id="36388584" class="c"><input type="checkbox" id="c-36388584" checked=""/><div class="controls bullet"><span class="by">delta_p_delta_x</span><span>|</span><a href="#36388000">root</a><span>|</span><a href="#36388075">parent</a><span>|</span><a href="#36388085">next</a><span>|</span><label class="collapse" for="c-36388584">[-]</label><label class="expand" for="c-36388584">[1 more]</label></div><br/><div class="children"><div class="content">I like to put it like this: a GPU is a really, <i>really</i> fast Map-Reduce hardware processor.<p>You give it a bunch of data with elements which are all independent of each other, apply the same transformations to to each element, and output a single data structure (a colour attachment or render target, or some compute buffer).<p>This explains a lot of the shortcomings and design decisions of GPUs. They prioritise throughput over latency; they have a lot of memory but much slower than the cores themselves (~500 – 700 cycle latency compared to ~20 – 40 cycle latency on the CPU); they run &#x27;threads&#x27; in synchronised lock-step, called warps; branching on a GPU is particularly expensive—if one shader for one fragment needs to branch, then the <i>entire warp</i> that it&#x27;s on will have to wait for it, or worse still, calculate that branch, too;<p>Their 3D graphics legacy still endures: despite the advent of GPGPU, they still have plenty of dedicated hardware for the graphics pipeline, including rasterisers, texture-mapping units, render output processors, etc.<p>Once people get this idea, then GPU programming is easier to reason about. One execution of a shader deals with one fragment (actually four, but at a high level of abstraction, this is sufficient).<p>Oddly enough, I did GPU parallelisation first, and then came to CPU parallelisation. I find CPU-level parallelism and concurrency problems like OS inter-process synchronisation, async-await, etc. much harder to reason about, because they generally cannot be reduced to such a simplistic &#x27;one thread for one pixel&#x27;. It&#x27;s also why I like embarrassingly parallel problems, because they&#x27;re the most easily GPU-able.</div><br/></div></div></div></div></div></div><div id="36388085" class="c"><input type="checkbox" id="c-36388085" checked=""/><div class="controls bullet"><span class="by">wiz21c</span><span>|</span><a href="#36388000">prev</a><span>|</span><a href="#36387119">next</a><span>|</span><label class="collapse" for="c-36388085">[-]</label><label class="expand" for="c-36388085">[5 more]</label></div><br/><div class="children"><div class="content">I still don&#x27;t get the &quot;no good for branching code&quot; point... Since most of the work is split in millions of &quot;threads&quot; which all run in parallel, then why is branching an issue  ? Some threads will take a bit longer than the others. Maybe groups of threads will go as slow as the slowest but still, prallelism should make up the bulk of the acceleration. No ?</div><br/><div id="36388118" class="c"><input type="checkbox" id="c-36388118" checked=""/><div class="controls bullet"><span class="by">seanmcdirmid</span><span>|</span><a href="#36388085">parent</a><span>|</span><a href="#36388110">next</a><span>|</span><label class="collapse" for="c-36388118">[-]</label><label class="expand" for="c-36388118">[1 more]</label></div><br/><div class="children"><div class="content">The threads share control units. So if threads sharing the same control unit branch differently, they have to do both branches for all the threads (well, it depends on the GPU architecture). The threads will never finish before the others (again, if they are sharing the same control units). It works out for graphics and well engineered GGPU code because adjacent pixels and vertexes usually are similar enough to have a high chance of having the same branching behavior.</div><br/></div></div><div id="36388110" class="c"><input type="checkbox" id="c-36388110" checked=""/><div class="controls bullet"><span class="by">maeln</span><span>|</span><a href="#36388085">parent</a><span>|</span><a href="#36388118">prev</a><span>|</span><a href="#36387119">next</a><span>|</span><label class="collapse" for="c-36388110">[-]</label><label class="expand" for="c-36388110">[3 more]</label></div><br/><div class="children"><div class="content">Most GPU&#x27;s only have so much compute cores. Even if you have a million threads, you might only have a few hundreds cores to execute them. 
If you have heavy branching you might slow down the whole lane (which size can vary from 8 to 64 execution most of the time). Which at this scale still do make a big difference. Although for small branching, masking help avoid too much slowdown.</div><br/><div id="36388139" class="c"><input type="checkbox" id="c-36388139" checked=""/><div class="controls bullet"><span class="by">WJW</span><span>|</span><a href="#36388085">root</a><span>|</span><a href="#36388110">parent</a><span>|</span><a href="#36387119">next</a><span>|</span><label class="collapse" for="c-36388139">[-]</label><label class="expand" for="c-36388139">[2 more]</label></div><br/><div class="children"><div class="content">To expand on this, even the latest Nvidia 4090 card &quot;only&quot; has about 16k cores. That&#x27;s a lot, but it&#x27;s hardly &quot;millions&quot; either.</div><br/><div id="36388429" class="c"><input type="checkbox" id="c-36388429" checked=""/><div class="controls bullet"><span class="by">ben-schaaf</span><span>|</span><a href="#36388085">root</a><span>|</span><a href="#36388139">parent</a><span>|</span><a href="#36387119">next</a><span>|</span><label class="collapse" for="c-36388429">[-]</label><label class="expand" for="c-36388429">[1 more]</label></div><br/><div class="children"><div class="content">To expand further the 16k cores aren&#x27;t real cores. What people would normally consider a core is what Nvidia calls a &quot;streaming multiprocessor&quot; (SM), of which the 4090 has 128. These cores each have 128 &quot;cuda cores&quot;, analogous to a SIMD lane - although not quite since &quot;cuda cores&quot; are themselves SIMD.<p>To simplify: Each 128 SMs can run a different program and each of their 128 &quot;cuda cores&quot; can do ~single-cycle (small) matrix operations.</div><br/></div></div></div></div></div></div></div></div><div id="36387119" class="c"><input type="checkbox" id="c-36387119" checked=""/><div class="controls bullet"><span class="by">kaycey2022</span><span>|</span><a href="#36388085">prev</a><span>|</span><a href="#36387754">next</a><span>|</span><label class="collapse" for="c-36387119">[-]</label><label class="expand" for="c-36387119">[1 more]</label></div><br/><div class="children"><div class="content">No local setup it seems :(</div><br/></div></div><div id="36387754" class="c"><input type="checkbox" id="c-36387754" checked=""/><div class="controls bullet"><span class="by">whatever1</span><span>|</span><a href="#36387119">prev</a><span>|</span><label class="collapse" for="c-36387754">[-]</label><label class="expand" for="c-36387754">[2 more]</label></div><br/><div class="children"><div class="content">Hard No for sequential &#x2F; dynamic programming code and sparse matrices.</div><br/><div id="36387960" class="c"><input type="checkbox" id="c-36387960" checked=""/><div class="controls bullet"><span class="by">patagurbon</span><span>|</span><a href="#36387754">parent</a><span>|</span><label class="collapse" for="c-36387960">[-]</label><label class="expand" for="c-36387960">[1 more]</label></div><br/><div class="children"><div class="content">Sparse matrix codes can be and often are much faster than their CPU counterparts. At least for the most common kernels</div><br/></div></div></div></div></div></div></div></div></div></body></html>