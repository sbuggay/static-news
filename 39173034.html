<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706691660760" as="style"/><link rel="stylesheet" href="styles.css?v=1706691660760"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2401.14953">Learning Universal Predictors</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>jandrewrogers</span> | <span>14 comments</span></div><br/><div><div id="39200545" class="c"><input type="checkbox" id="c-39200545" checked=""/><div class="controls bullet"><span class="by">Xcelerate</span><span>|</span><a href="#39197951">next</a><span>|</span><label class="collapse" for="c-39200545">[-]</label><label class="expand" for="c-39200545">[1 more]</label></div><br/><div class="children"><div class="content">Really exciting article from Hutter et al. I feel like I’m beating a dead horse with how much I comment about Solomonoff induction on here, but I am constantly both amazed and perplexed that we don’t have thousands of research labs going about AGI via a top-down, theory-first approach—i.e., starting with the upper bound of what is possible and working down to the nearest resource-constrained physical approximation to it.<p>Can we bootstrap our way to basic AGI by tinkering with neural network architectures and scaling up the hardware? Maybe. After all, the human brain sort of echos that approach. But at some point, in order to sustain continued improvement toward <i>optimal</i> AGI, there will have be a strong algorithmic component to sequence prediction that is based upon a very deep understanding of what is computable (assuming the physical Church-Turing thesis). I don’t really see a way around that, because the foundational principles of algorithmic and computational complexity ultimately determine the upper limit of our ability to predict the future, which is kind of mind-blowing to me (and even more so considering that much of the theory was developed over half a century ago).<p>But wait! What about the halting problem, NP hardness, the NFL theorem, Gödel’s incompleteness theorems, Blum’s speedup theorem, ..., [insert your favorite pessimistic no-go theorem]? Yeah, so what? Most of these nonstarters apply to “almost all” valid problems, which ironically happen to overlap with “almost none” of the problems we care about, because the distribution of real world problems does not coincide with the distribution of problems randomly sampled from a formal language. If that were the case, then nothing would be predictable at all because prediction-making beings could not exist in such an environment (in other words, real world problems tend to exhibit Kolmogorov-compressibility in the form of mathematical substructure that leads to heuristic solvers that are particularly effective beyond what average-case complexity would imply).</div><br/></div></div><div id="39197951" class="c"><input type="checkbox" id="c-39197951" checked=""/><div class="controls bullet"><span class="by">tripplyons</span><span>|</span><a href="#39200545">prev</a><span>|</span><a href="#39200909">next</a><span>|</span><label class="collapse" for="c-39197951">[-]</label><label class="expand" for="c-39197951">[1 more]</label></div><br/><div class="children"><div class="content">This sentence was fun to read:<p>&quot;For our BrainPhoque language (that we use in our experiments later) it increases the yield of ‘interesting’ programs by a factor of 137&quot;</div><br/></div></div><div id="39200909" class="c"><input type="checkbox" id="c-39200909" checked=""/><div class="controls bullet"><span class="by">drdeca</span><span>|</span><a href="#39197951">prev</a><span>|</span><a href="#39197242">next</a><span>|</span><label class="collapse" for="c-39200909">[-]</label><label class="expand" for="c-39200909">[2 more]</label></div><br/><div class="children"><div class="content">So, how good are these results? Are these impressive?</div><br/><div id="39201021" class="c"><input type="checkbox" id="c-39201021" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#39200909">parent</a><span>|</span><a href="#39197242">next</a><span>|</span><label class="collapse" for="c-39201021">[-]</label><label class="expand" for="c-39201021">[1 more]</label></div><br/><div class="children"><div class="content">I actually don&#x27;t know. They say in the paper they can&#x27;t figure out a better way to approximate Solomonoff induction in the UTM (universal Turing machine) section, so they just guess some reasonable value (based on knowledge of the program that generates the sequence).</div><br/></div></div></div></div><div id="39197242" class="c"><input type="checkbox" id="c-39197242" checked=""/><div class="controls bullet"><span class="by">QuadmasterXLII</span><span>|</span><a href="#39200909">prev</a><span>|</span><a href="#39197555">next</a><span>|</span><label class="collapse" for="c-39197242">[-]</label><label class="expand" for="c-39197242">[3 more]</label></div><br/><div class="children"><div class="content">Everybody gangster until Deepmind starts saying mid-2010s LessWrong words</div><br/><div id="39197334" class="c"><input type="checkbox" id="c-39197334" checked=""/><div class="controls bullet"><span class="by">shmageggy</span><span>|</span><a href="#39197242">parent</a><span>|</span><a href="#39197354">next</a><span>|</span><label class="collapse" for="c-39197334">[-]</label><label class="expand" for="c-39197334">[1 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;ve got it backwards: LessWrong was saying these author&#x27;s words. Hutter has been publishing about this topic for almost 25 years.</div><br/></div></div><div id="39197354" class="c"><input type="checkbox" id="c-39197354" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#39197242">parent</a><span>|</span><a href="#39197334">prev</a><span>|</span><a href="#39197555">next</a><span>|</span><label class="collapse" for="c-39197354">[-]</label><label class="expand" for="c-39197354">[1 more]</label></div><br/><div class="children"><div class="content">Marcus Hutter invented AIXI (Hutter 2000), the theoretically optimal AI system. It&#x27;s not computable though, and the computable version is hilariously inefficient. Yes it uses Solomonoff induction.</div><br/></div></div></div></div><div id="39197555" class="c"><input type="checkbox" id="c-39197555" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#39197242">prev</a><span>|</span><a href="#39197527">next</a><span>|</span><label class="collapse" for="c-39197555">[-]</label><label class="expand" for="c-39197555">[4 more]</label></div><br/><div class="children"><div class="content">I see your universal predictor and raise you one non-halting program (in a language of your choice).</div><br/><div id="39200579" class="c"><input type="checkbox" id="c-39200579" checked=""/><div class="controls bullet"><span class="by">Xcelerate</span><span>|</span><a href="#39197555">parent</a><span>|</span><a href="#39197604">next</a><span>|</span><label class="collapse" for="c-39200579">[-]</label><label class="expand" for="c-39200579">[1 more]</label></div><br/><div class="children"><div class="content">I see your pathological proof of existence and raise you an asymptotic probability of one:<p>“The halting problem for Turing machines is perhaps the canonical undecidable set. Nevertheless, we prove that there is an algorithm deciding almost all instances of it.”<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;math&#x2F;0504351.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;math&#x2F;0504351.pdf</a></div><br/></div></div><div id="39197604" class="c"><input type="checkbox" id="c-39197604" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#39197555">parent</a><span>|</span><a href="#39200579">prev</a><span>|</span><a href="#39199816">next</a><span>|</span><label class="collapse" for="c-39197604">[-]</label><label class="expand" for="c-39197604">[1 more]</label></div><br/><div class="children"><div class="content">Yes that&#x27;s why it would be something like a Gödel machine[0]. Ignore everything it can&#x27;t prove is not malicious (won&#x27;t halt, runs too long, takes too many resources, etc.).<p>[0]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;G%C3%B6del_machine" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;G%C3%B6del_machine</a></div><br/></div></div><div id="39199816" class="c"><input type="checkbox" id="c-39199816" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#39197555">parent</a><span>|</span><a href="#39197604">prev</a><span>|</span><a href="#39197527">next</a><span>|</span><label class="collapse" for="c-39199816">[-]</label><label class="expand" for="c-39199816">[1 more]</label></div><br/><div class="children"><div class="content">is halting program something can happen in infinite space?<p>If space is finite, you can just memorize all processed internal states of the program, there are two options:<p>- program gets into infinite loop, which will be detected by checking that internal program state was observed in the past already<p>- program will actually halt</div><br/></div></div></div></div><div id="39197527" class="c"><input type="checkbox" id="c-39197527" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#39197555">prev</a><span>|</span><label class="collapse" for="c-39197527">[-]</label><label class="expand" for="c-39197527">[2 more]</label></div><br/><div class="children"><div class="content">Interesting that they combine assumptions from highly idealized abstractions (universal Turing machines, Solomonoff induction) with realistic neural network architectures.</div><br/><div id="39199101" class="c"><input type="checkbox" id="c-39199101" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#39197527">parent</a><span>|</span><label class="collapse" for="c-39199101">[-]</label><label class="expand" for="c-39199101">[1 more]</label></div><br/><div class="children"><div class="content">They have been doing this forever. Here is a paper by some of the same authors: A Monte Carlo AIXI Approximation (2009). <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;0909.0801" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;0909.0801</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>