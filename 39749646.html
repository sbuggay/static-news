<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710838876782" as="style"/><link rel="stylesheet" href="styles.css?v=1710838876782"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.cnbc.com/2024/03/18/nvidia-announces-gb200-blackwell-ai-chip-launching-later-this-year.html">Nvidia CEO Jensen Huang announces new AI chips: ‘We need bigger GPUs’</a> <span class="domain">(<a href="https://www.cnbc.com">www.cnbc.com</a>)</span></div><div class="subtext"><span>tiahura</span> | <span>253 comments</span></div><br/><div><div id="39753297" class="c"><input type="checkbox" id="c-39753297" checked=""/><div class="controls bullet"><span class="by">__mharrison__</span><span>|</span><a href="#39752617">next</a><span>|</span><label class="collapse" for="c-39753297">[-]</label><label class="expand" for="c-39753297">[5 more]</label></div><br/><div class="children"><div class="content">My take from being at the keynote and the content I&#x27;ve seen so far at the conference is that Nvidia&#x27;s is moving up the stack (like all good hardware vendors are prone to do).<p>Obviously they are going to keep doing bigger. But the takeaway for me is that they are building &quot;docker for llms&quot; - NIM. They are building a container system where you can download&#x2F;buy(?) NIMs and easily deploy them on their hardware. Going to be fun to watch what this does to all the AI startups...</div><br/><div id="39753493" class="c"><input type="checkbox" id="c-39753493" checked=""/><div class="controls bullet"><span class="by">flessner</span><span>|</span><a href="#39753297">parent</a><span>|</span><a href="#39753849">next</a><span>|</span><label class="collapse" for="c-39753493">[-]</label><label class="expand" for="c-39753493">[1 more]</label></div><br/><div class="children"><div class="content">Won&#x27;t do anything to most consumer facing AI, the UI &amp; convenience is already a major selling point. A bigger threat is that the feature the business is built around makes it into mainline software... there is no demand for (paid) background removal anymore as every iPhone can do it nowadays.<p>Generally if whatever AI product you have can easily just be a feature in whatever application businesses already use, then you are running a business on borrowed time.</div><br/></div></div><div id="39753849" class="c"><input type="checkbox" id="c-39753849" checked=""/><div class="controls bullet"><span class="by">ixaxaar</span><span>|</span><a href="#39753297">parent</a><span>|</span><a href="#39753493">prev</a><span>|</span><a href="#39753369">next</a><span>|</span><label class="collapse" for="c-39753849">[-]</label><label class="expand" for="c-39753849">[1 more]</label></div><br/><div class="children"><div class="content">There are also open source equivalents btw - <a href="https:&#x2F;&#x2F;github.com&#x2F;geniusrise">https:&#x2F;&#x2F;github.com&#x2F;geniusrise</a></div><br/></div></div><div id="39753491" class="c"><input type="checkbox" id="c-39753491" checked=""/><div class="controls bullet"><span class="by">djtango</span><span>|</span><a href="#39753297">parent</a><span>|</span><a href="#39753369">prev</a><span>|</span><a href="#39752617">next</a><span>|</span><label class="collapse" for="c-39753491">[-]</label><label class="expand" for="c-39753491">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not that abreast of all the developments in the AI space.<p>What specific class of AI startups do you have in mind here? AI-aaS startups who provide the &quot;infra&quot;?</div><br/></div></div></div></div><div id="39752617" class="c"><input type="checkbox" id="c-39752617" checked=""/><div class="controls bullet"><span class="by">cebert</span><span>|</span><a href="#39753297">prev</a><span>|</span><a href="#39750658">next</a><span>|</span><label class="collapse" for="c-39752617">[-]</label><label class="expand" for="c-39752617">[28 more]</label></div><br/><div class="children"><div class="content">&gt; “Nvidia … is becoming less of a mercenary chip provider and more of a platform provider, like Microsoft or Apple, on which other companies can build software.<p>I can understand from a growth perspective why it’s more profitable for Nvidia if it can become more of a platform service for AI. However, that’s difficult to balance that and partnerships the company already has with AWS and Microsoft. I’d expect to see some acquisitions or competing custom solutions in the future. Fortunately for Nvidia, a lot of AI is still dependent on CUDA. I’m interested to see how this plays out.</div><br/><div id="39752686" class="c"><input type="checkbox" id="c-39752686" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39752617">parent</a><span>|</span><a href="#39752652">next</a><span>|</span><label class="collapse" for="c-39752686">[-]</label><label class="expand" for="c-39752686">[7 more]</label></div><br/><div class="children"><div class="content">I think they&#x27;re planning for a world where half their customers (hyperscalers) just use GPUs and CUDA while the other half (the long tail) use more profitable, higher-level parts of the platform. They don&#x27;t have the leverage to force customers one way or the other. It would be easier to just sell GPUs, but they know that sophisticated customers can switch to other chips while the platform provides lock-in for smaller customers.</div><br/><div id="39753899" class="c"><input type="checkbox" id="c-39753899" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752686">parent</a><span>|</span><a href="#39753225">next</a><span>|</span><label class="collapse" for="c-39753899">[-]</label><label class="expand" for="c-39753899">[1 more]</label></div><br/><div class="children"><div class="content">There are already platforms and projects which provide resources for long tail of science. EU is supporting projects which brings together resource providers with researchers and private companies in some cases.<p>NVIDIA is not entering an empty marketplace here. Also there&#x27;s already enough know-how to make things run on cloud, OpenStack, HPC, etc.<p>Unless they make things very difficult for independent platforms, they can&#x27;t force their way in that much, from my perspective.</div><br/></div></div><div id="39753225" class="c"><input type="checkbox" id="c-39753225" checked=""/><div class="controls bullet"><span class="by">neverokay</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752686">parent</a><span>|</span><a href="#39753899">prev</a><span>|</span><a href="#39752652">next</a><span>|</span><label class="collapse" for="c-39753225">[-]</label><label class="expand" for="c-39753225">[5 more]</label></div><br/><div class="children"><div class="content">Doesn’t matter how good your in-house tech team was, your company still outsourced it to cloud infra.<p>That’s what Nvidia faces. Doesn’t matter how good the current in-house teams are using direct hardware, the trend in corporate is shift to a vendor (Google&#x2F;AWS).<p>Nvidia can watch this inevitable shift or get ready to offer itself as a platform too.</div><br/><div id="39753306" class="c"><input type="checkbox" id="c-39753306" checked=""/><div class="controls bullet"><span class="by">joshellington</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753225">parent</a><span>|</span><a href="#39752652">next</a><span>|</span><label class="collapse" for="c-39753306">[-]</label><label class="expand" for="c-39753306">[4 more]</label></div><br/><div class="children"><div class="content">I get it, the service model always shines the brightest in the eye of the revenue calculator. But I have immediate skepticism they’ll be able to execute at a competitive level. Their core competency has always been manufacture and production, not service-based things. It’s a big rock to push up a tall hill.</div><br/><div id="39753861" class="c"><input type="checkbox" id="c-39753861" checked=""/><div class="controls bullet"><span class="by">bboygravity</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753306">parent</a><span>|</span><a href="#39753712">next</a><span>|</span><label class="collapse" for="c-39753861">[-]</label><label class="expand" for="c-39753861">[1 more]</label></div><br/><div class="children"><div class="content">Genuine question (I don&#x27;t know much about cloud stuff): how is providing a cloud service&#x2F;platform (at scale) even remotely as hard as designing, manufacturing and selling GPU&#x27;s (including drivers and firmware) at massive scale?<p>It feels like reading that setting up something like Facebook would be extremely challenging for a company like SpaceX.</div><br/></div></div><div id="39753712" class="c"><input type="checkbox" id="c-39753712" checked=""/><div class="controls bullet"><span class="by">omnimus</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753306">parent</a><span>|</span><a href="#39753861">prev</a><span>|</span><a href="#39753528">next</a><span>|</span><label class="collapse" for="c-39753712">[-]</label><label class="expand" for="c-39753712">[1 more]</label></div><br/><div class="children"><div class="content">This doesnt seem to be true. They have been running Geforce  Now for a long time and its one of the best gaming streaming services. It seems they are doing it in partnership with other regional companies but nobody says they cant use same partners. Running games with small latency seems more complicated than llms on cuda.</div><br/></div></div><div id="39753528" class="c"><input type="checkbox" id="c-39753528" checked=""/><div class="controls bullet"><span class="by">neverokay</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753306">parent</a><span>|</span><a href="#39753712">prev</a><span>|</span><a href="#39752652">next</a><span>|</span><label class="collapse" for="c-39753528">[-]</label><label class="expand" for="c-39753528">[1 more]</label></div><br/><div class="children"><div class="content">Hey, if it doesn’t work out they can always return back to what they are, a consumer first company but now with world class hardware&#x2F;software.<p>AI graphics service that renders games in the cloud (photorealistic), concluding its epic journey of being an amazing graphics card company.<p>Kinda cool when you think about it.</div><br/></div></div></div></div></div></div></div></div><div id="39752652" class="c"><input type="checkbox" id="c-39752652" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#39752617">parent</a><span>|</span><a href="#39752686">prev</a><span>|</span><a href="#39750658">next</a><span>|</span><label class="collapse" for="c-39752652">[-]</label><label class="expand" for="c-39752652">[20 more]</label></div><br/><div class="children"><div class="content">My prediction is eventually there will be anti-trust ligitation, they will be required to open the CUDA standard, after which AMD will become a competitor.<p>NVIDIA could voluntarily open the standard to avoid this ligitation if they wanted to, though, and IMO it would be the smart thing to do, but almost every corporation in history has chosen the ligitation instead.</div><br/><div id="39752919" class="c"><input type="checkbox" id="c-39752919" checked=""/><div class="controls bullet"><span class="by">nemothekid</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752652">parent</a><span>|</span><a href="#39752825">next</a><span>|</span><label class="collapse" for="c-39752919">[-]</label><label class="expand" for="c-39752919">[13 more]</label></div><br/><div class="children"><div class="content">&gt;<i>My prediction is eventually there will be anti-trust ligitation, they will be required to open the CUDA standard, after which AMD will become a competitor.</i><p>If AMD isn&#x27;t a competitor before government intervention, I don&#x27;t the government forcing nvidia to open up CUDA changes much. CUDA&#x27;s moat isn&#x27;t due to some secret sauce - nvidia put in the developer hours; and if AMDs CUDA implementation is still broken, people will continue to buy nvidia.<p>There has been a lot of trying to get AMD to work - Hotz has been trying for a while now[1] and has been uncovering a ton of bugs in AMD drivers. To AMD&#x27;s credit, they have been fixed, but it does give you a sense of how far behind they are in regards to their own software. Now imagine them trying to implement a competitor&#x27;s spec?<p>[1] <a href="https:&#x2F;&#x2F;twitter.com&#x2F;__tinygrad__&#x2F;status&#x2F;1765085827946942923" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;__tinygrad__&#x2F;status&#x2F;1765085827946942923</a></div><br/><div id="39753024" class="c"><input type="checkbox" id="c-39753024" checked=""/><div class="controls bullet"><span class="by">AYBABTME</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752919">parent</a><span>|</span><a href="#39753775">next</a><span>|</span><label class="collapse" for="c-39753024">[-]</label><label class="expand" for="c-39753024">[11 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand AMD in this. Isn&#x27;t it insanity that they&#x27;re not throwing all they&#x27;ve got at their software stack?</div><br/><div id="39753362" class="c"><input type="checkbox" id="c-39753362" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753024">parent</a><span>|</span><a href="#39753133">next</a><span>|</span><label class="collapse" for="c-39753362">[-]</label><label class="expand" for="c-39753362">[3 more]</label></div><br/><div class="children"><div class="content">You know what happens to companies that panic and throw all their resources into knee-jerk software projects? I don&#x27;t, but I&#x27;d predict it is ugly. Adding more people to a bad project generally makes it worse.<p>The issue that AMD has is they had a long period where they clearly had no idea what they were doing. You could tell just from looking at websites, CUDA pretty much immediately gets to &quot;here is a library for FFT&quot;, &quot;here is a library for sparse matricies&quot;. AMD would explain that ROCM is an abbreviation of the ROCm Software platform or something unspeakably stupid. And that your graphics card wasn&#x27;t supported.<p>That changed a few months ago; so it looks like they have put some competent PMs in the chair now or something. But it&#x27;ll take months for the flow on effects to reach the market. They have to figure out what the problems are which takes months to do properly; then fix the software (1-3 months more minimum); then get it into the open and the foundational libraries like PyTorch pick it up (might take another year). You can speed that up, but more cooks in the kitchen is not the way. Bandwidth use needs to be optimised.<p>It isn&#x27;t like ROCm seems lacks key features; it can technically do inference and training. My card crashes regularly though (might be a VRAM issue) so it is useless in practice. AMD can check boxes but the software doesn&#x27;t really work and grappling with that organisationally is hard. Unless you have the right people in the right places, which AMD didn&#x27;t have up to at least mid 2023.</div><br/><div id="39753917" class="c"><input type="checkbox" id="c-39753917" checked=""/><div class="controls bullet"><span class="by">Certhas</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753362">parent</a><span>|</span><a href="#39753792">next</a><span>|</span><label class="collapse" for="c-39753917">[-]</label><label class="expand" for="c-39753917">[1 more]</label></div><br/><div class="children"><div class="content">Look at AMDs vs Intel. They have now surpassed Intel in terms of CPUs sold and market cap. That was unthinkable even six, seven years ago.<p>It makes perfect sense that, organisationally, they were focused on that battle. If you remember the Athlon days, AMD beat Intel before, but briefly. It didn&#x27;t last. This time it looks like they beat Intel and have had the focus to stay. Intel will come back and beat them some cycles, but there is no collapse on the horizon.<p>So it makes sense that they started looking at nVidia in the last year or so. Of course nVidia has amassed an obscene war chest in the meantime...</div><br/></div></div><div id="39753792" class="c"><input type="checkbox" id="c-39753792" checked=""/><div class="controls bullet"><span class="by">elcomet</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753362">parent</a><span>|</span><a href="#39753917">prev</a><span>|</span><a href="#39753133">next</a><span>|</span><label class="collapse" for="c-39753792">[-]</label><label class="expand" for="c-39753792">[1 more]</label></div><br/><div class="children"><div class="content">Pytorch has been supporting rocm for all last 2 years</div><br/></div></div></div></div><div id="39753094" class="c"><input type="checkbox" id="c-39753094" checked=""/><div class="controls bullet"><span class="by">tempaccount420</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753024">parent</a><span>|</span><a href="#39753133">prev</a><span>|</span><a href="#39753778">next</a><span>|</span><label class="collapse" for="c-39753094">[-]</label><label class="expand" for="c-39753094">[5 more]</label></div><br/><div class="children"><div class="content">Hardware people don&#x27;t get along very well with software people.</div><br/><div id="39753341" class="c"><input type="checkbox" id="c-39753341" checked=""/><div class="controls bullet"><span class="by">elbear</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753094">parent</a><span>|</span><a href="#39753778">next</a><span>|</span><label class="collapse" for="c-39753341">[-]</label><label class="expand" for="c-39753341">[4 more]</label></div><br/><div class="children"><div class="content">Why&#x27;s that?</div><br/><div id="39753516" class="c"><input type="checkbox" id="c-39753516" checked=""/><div class="controls bullet"><span class="by">rapsey</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753341">parent</a><span>|</span><a href="#39753777">next</a><span>|</span><label class="collapse" for="c-39753516">[-]</label><label class="expand" for="c-39753516">[1 more]</label></div><br/><div class="children"><div class="content">Because it is a different type of engineering. If you manage software development like you manage hardware development your software is going to be bad. That has always been AMD&#x27;s problem and it is not likely to get fixed.</div><br/></div></div><div id="39753771" class="c"><input type="checkbox" id="c-39753771" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753341">parent</a><span>|</span><a href="#39753777">prev</a><span>|</span><a href="#39753778">next</a><span>|</span><label class="collapse" for="c-39753771">[-]</label><label class="expand" for="c-39753771">[1 more]</label></div><br/><div class="children"><div class="content">Because they didn&#x27;t go to uni when hardware-software-codesign was being taught.</div><br/></div></div></div></div></div></div><div id="39753778" class="c"><input type="checkbox" id="c-39753778" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753024">parent</a><span>|</span><a href="#39753094">prev</a><span>|</span><a href="#39753775">next</a><span>|</span><label class="collapse" for="c-39753778">[-]</label><label class="expand" for="c-39753778">[1 more]</label></div><br/><div class="children"><div class="content">You have to remember that this only applies to cheap consumer GPUs, they tend to support their datacenter GPUs better. When you consider that Ryzen AI already eats the AI inference lunch, having better GPUs with better software only threatens to cannibalize their data center GPU offering. Given enough time nobody will care about using AMD GPUs for AI.</div><br/></div></div></div></div><div id="39753775" class="c"><input type="checkbox" id="c-39753775" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752919">parent</a><span>|</span><a href="#39753024">prev</a><span>|</span><a href="#39752825">next</a><span>|</span><label class="collapse" for="c-39753775">[-]</label><label class="expand" for="c-39753775">[1 more]</label></div><br/><div class="children"><div class="content">Getting this working <i>might</i> be worth a trillion $ to AMD - they should be doing more than just waiting for a bootstrapped startup to debug their drivers for them.</div><br/></div></div></div></div><div id="39752825" class="c"><input type="checkbox" id="c-39752825" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752652">parent</a><span>|</span><a href="#39752919">prev</a><span>|</span><a href="#39752724">next</a><span>|</span><label class="collapse" for="c-39752825">[-]</label><label class="expand" for="c-39752825">[3 more]</label></div><br/><div class="children"><div class="content">The cuda api is essentially open... Hip is basically a copy.<p>CUDA is such a misnomer. Amd doesn&#x27;t have tensorRT, cuDNN, cutlass, etc. Forcing Nvidia to make these work on AMD is like forcing Microsoft to make windows work on apple hardware... Not going to happen.</div><br/><div id="39752987" class="c"><input type="checkbox" id="c-39752987" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752825">parent</a><span>|</span><a href="#39752724">next</a><span>|</span><label class="collapse" for="c-39752987">[-]</label><label class="expand" for="c-39752987">[2 more]</label></div><br/><div class="children"><div class="content">They did force Microsoft to make Office work on Mac though... (Office for Mac already existed but I think MS agreed to not cancel it.)</div><br/><div id="39753708" class="c"><input type="checkbox" id="c-39753708" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752987">parent</a><span>|</span><a href="#39752724">next</a><span>|</span><label class="collapse" for="c-39753708">[-]</label><label class="expand" for="c-39753708">[1 more]</label></div><br/><div class="children"><div class="content">It was more like Microsoft had the anti-trust stuff going on, and Apple was on the verge of going bankrupt.</div><br/></div></div></div></div></div></div><div id="39752724" class="c"><input type="checkbox" id="c-39752724" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752652">parent</a><span>|</span><a href="#39752825">prev</a><span>|</span><a href="#39750658">next</a><span>|</span><label class="collapse" for="c-39752724">[-]</label><label class="expand" for="c-39752724">[3 more]</label></div><br/><div class="children"><div class="content">It would be kind of genius for Nvidia to &quot;open&quot; the CUDA APIs (which have already been unofficially reverse engineered anyway) but not the code. Maybe they&#x27;d also officially support HIP and SYCL. Maybe they could open SXM after all competitors have already committed to OAM. They&#x27;d create the appearance of opening up while giving up very little.</div><br/><div id="39753309" class="c"><input type="checkbox" id="c-39753309" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39752724">parent</a><span>|</span><a href="#39750658">next</a><span>|</span><label class="collapse" for="c-39753309">[-]</label><label class="expand" for="c-39753309">[2 more]</label></div><br/><div class="children"><div class="content">By &quot;Opening Up&quot; they cement their leadership position. AI frameworks are already targeting CL, SPIR-V, etc. The low level details will fade and so will Nvidias api dominance.<p>The MI300 smokes the H100 yet here we are.</div><br/><div id="39753911" class="c"><input type="checkbox" id="c-39753911" checked=""/><div class="controls bullet"><span class="by">incrudible</span><span>|</span><a href="#39752617">root</a><span>|</span><a href="#39753309">parent</a><span>|</span><a href="#39750658">next</a><span>|</span><label class="collapse" for="c-39753911">[-]</label><label class="expand" for="c-39753911">[1 more]</label></div><br/><div class="children"><div class="content">Just because they are a target doesn’t mean things just work. Historically, AMD hardware for GPGPU becomes obsolete well before the software landscape catches up. I am not going to risk my time and money finding out whether history repeats itself, just for a few potential FLOPS per dollar.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39750658" class="c"><input type="checkbox" id="c-39750658" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#39752617">prev</a><span>|</span><a href="#39750119">next</a><span>|</span><label class="collapse" for="c-39750658">[-]</label><label class="expand" for="c-39750658">[28 more]</label></div><br/><div class="children"><div class="content">What is FP4, 4 bit floating point? If so, the comparison graph [0] with 30x above Hopper was a bit misleading.<p>[0] <a href="https:&#x2F;&#x2F;youtu.be&#x2F;Y2F8yisiS6E?t=4698" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;Y2F8yisiS6E?t=4698</a></div><br/><div id="39751594" class="c"><input type="checkbox" id="c-39751594" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#39750658">parent</a><span>|</span><a href="#39751275">next</a><span>|</span><label class="collapse" for="c-39751594">[-]</label><label class="expand" for="c-39751594">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s 4 bit floating point, at twice the speed of 8 bit floating point. There&#x27;s also FP6, doesn&#x27;t offer faster compute than FP8 but manages to take advantage of the better memory bandwith and cache use of the 6 bit format.<p>Apparently some people are drawing connections to this paper [1] on 4 bit LLMs, which has one NVIDIA employee among its contributors<p>1: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.16836.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.16836.pdf</a></div><br/></div></div><div id="39751275" class="c"><input type="checkbox" id="c-39751275" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#39750658">parent</a><span>|</span><a href="#39751594">prev</a><span>|</span><a href="#39752158">next</a><span>|</span><label class="collapse" for="c-39751275">[-]</label><label class="expand" for="c-39751275">[5 more]</label></div><br/><div class="children"><div class="content">&gt;bit misleading.<p>Only partially, because in LLMs FP4 isn&#x27;t half as useful as FP8. So if you have gear that crushes at FP4 then that&#x27;s what you use and you benefit from that increased speed (at minimal accuracy loss).<p>Definitely some marketing creativity in there, but its not entirely wrong as a measure of real world usage</div><br/><div id="39752642" class="c"><input type="checkbox" id="c-39752642" checked=""/><div class="controls bullet"><span class="by">jxy</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751275">parent</a><span>|</span><a href="#39752158">next</a><span>|</span><label class="collapse" for="c-39752642">[-]</label><label class="expand" for="c-39752642">[4 more]</label></div><br/><div class="children"><div class="content">curiously, what real world usage actually uses FP4? AFICT, most of the LLMs still use BF16, and even the quantizations down to 4bits and 2bits end up back to 16bit or INT8 for actual computations.</div><br/><div id="39753531" class="c"><input type="checkbox" id="c-39753531" checked=""/><div class="controls bullet"><span class="by">creshal</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39752642">parent</a><span>|</span><a href="#39753012">next</a><span>|</span><label class="collapse" for="c-39753531">[-]</label><label class="expand" for="c-39753531">[2 more]</label></div><br/><div class="children"><div class="content">Half the reason why they move back up to 8&#x2F;16 bit is that current hardware doesn&#x27;t properly support 4 bit floats, and you get better performance from the conversion. I think once this hardware hits, most of the computation will shift to native 4 bit just for efficency&#x27;s sake.<p>...assuming the recent 1.58b paper doesn&#x27;t render the entire float quantization approach obsolete by then.</div><br/><div id="39753785" class="c"><input type="checkbox" id="c-39753785" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39753531">parent</a><span>|</span><a href="#39753012">next</a><span>|</span><label class="collapse" for="c-39753785">[-]</label><label class="expand" for="c-39753785">[1 more]</label></div><br/><div class="children"><div class="content">The 1.58b approach is good for everyone including for quantization. It means that current quantization schemes have room for improvement.</div><br/></div></div></div></div><div id="39753012" class="c"><input type="checkbox" id="c-39753012" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39752642">parent</a><span>|</span><a href="#39753531">prev</a><span>|</span><a href="#39752158">next</a><span>|</span><label class="collapse" for="c-39753012">[-]</label><label class="expand" for="c-39753012">[1 more]</label></div><br/><div class="children"><div class="content">Llama.cpp and many others support 4 bit weights and lower</div><br/></div></div></div></div></div></div><div id="39752158" class="c"><input type="checkbox" id="c-39752158" checked=""/><div class="controls bullet"><span class="by">opcode84</span><span>|</span><a href="#39750658">parent</a><span>|</span><a href="#39751275">prev</a><span>|</span><a href="#39751281">next</a><span>|</span><label class="collapse" for="c-39752158">[-]</label><label class="expand" for="c-39752158">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.10537.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.10537.pdf</a><p>Discussed in a previous post
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37930663">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37930663</a></div><br/><div id="39753007" class="c"><input type="checkbox" id="c-39753007" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39752158">parent</a><span>|</span><a href="#39751281">next</a><span>|</span><label class="collapse" for="c-39753007">[-]</label><label class="expand" for="c-39753007">[1 more]</label></div><br/><div class="children"><div class="content">Yes this is it!</div><br/></div></div></div></div><div id="39751281" class="c"><input type="checkbox" id="c-39751281" checked=""/><div class="controls bullet"><span class="by">s_m_t</span><span>|</span><a href="#39750658">parent</a><span>|</span><a href="#39752158">prev</a><span>|</span><a href="#39751020">next</a><span>|</span><label class="collapse" for="c-39751281">[-]</label><label class="expand" for="c-39751281">[16 more]</label></div><br/><div class="children"><div class="content">How can 4 bits possibly be enough? Are intermediate calculations done at a higher width and then converted down back to FP4?</div><br/><div id="39751659" class="c"><input type="checkbox" id="c-39751659" checked=""/><div class="controls bullet"><span class="by">WhitneyLand</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751281">parent</a><span>|</span><a href="#39752570">next</a><span>|</span><label class="collapse" for="c-39751659">[-]</label><label class="expand" for="c-39751659">[5 more]</label></div><br/><div class="children"><div class="content">- Training isn’t done at 4-bits, to date this small size has only been for inference.<p>- Research for a while now has been finding that smaller weights are surprisingly effective.  It’s kind of a counterintuitive result, but one way to think about it is there are billions of weights working together. So taken as a whole you still have a large amount of information.</div><br/><div id="39753938" class="c"><input type="checkbox" id="c-39753938" checked=""/><div class="controls bullet"><span class="by">tmalsburg2</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751659">parent</a><span>|</span><a href="#39751842">next</a><span>|</span><label class="collapse" for="c-39753938">[-]</label><label class="expand" for="c-39753938">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  - Training isn’t done at 4-bits, to date this small size has only been for inference.<p>Wasn&#x27;t there a paper from Microsoft two weeks ago or so where they trained on log₂(3) bits?<p>Edit: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.17764.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.17764.pdf</a></div><br/></div></div><div id="39751842" class="c"><input type="checkbox" id="c-39751842" checked=""/><div class="controls bullet"><span class="by">acchow</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751659">parent</a><span>|</span><a href="#39753938">prev</a><span>|</span><a href="#39752212">next</a><span>|</span><label class="collapse" for="c-39751842">[-]</label><label class="expand" for="c-39751842">[2 more]</label></div><br/><div class="children"><div class="content">Intuitively, there is a ton of redundancy and we still have a long way we can still compress things.</div><br/><div id="39753788" class="c"><input type="checkbox" id="c-39753788" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751842">parent</a><span>|</span><a href="#39752212">next</a><span>|</span><label class="collapse" for="c-39753788">[-]</label><label class="expand" for="c-39753788">[1 more]</label></div><br/><div class="children"><div class="content">Each token is represented by a vector of 4096 floats. Of course there is redundancy.</div><br/></div></div></div></div><div id="39752212" class="c"><input type="checkbox" id="c-39752212" checked=""/><div class="controls bullet"><span class="by">coffeebeqn</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751659">parent</a><span>|</span><a href="#39751842">prev</a><span>|</span><a href="#39752570">next</a><span>|</span><label class="collapse" for="c-39752212">[-]</label><label class="expand" for="c-39752212">[1 more]</label></div><br/><div class="children"><div class="content">Maybe the rounding errors are noise that is somewhat useful in a big enough neutral net. Image generators also generate noise to work on</div><br/></div></div></div></div><div id="39752570" class="c"><input type="checkbox" id="c-39752570" checked=""/><div class="controls bullet"><span class="by">yalok</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751281">parent</a><span>|</span><a href="#39751659">prev</a><span>|</span><a href="#39752658">next</a><span>|</span><label class="collapse" for="c-39752570">[-]</label><label class="expand" for="c-39752570">[4 more]</label></div><br/><div class="children"><div class="content">There are research papers where even 1 bit (not floating point) was enough, with some quality loss.<p>4 bits is effectively 16 different float point numbers - 8 positive, 8 negative, no zero and no NaN&#x2F;inf. 1 bit for sign and 3 bits for exponent, 0 bits for mantissa, mantissa is implied to be 4. It’s logarithmic - representing numbers in the range from -4^3 to 4^3, smallest numbers are 4^-3.</div><br/><div id="39753941" class="c"><input type="checkbox" id="c-39753941" checked=""/><div class="controls bullet"><span class="by">phh</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39752570">parent</a><span>|</span><a href="#39753824">next</a><span>|</span><label class="collapse" for="c-39753941">[-]</label><label class="expand" for="c-39753941">[1 more]</label></div><br/><div class="children"><div class="content">Thanks. First source i see for what fp4 is. Gotta say I&#x27;m surprised: I would have chosen to lose one value, but have a zero. (though I have no doubt those people are much more clever and knowledgeable than I am)</div><br/></div></div><div id="39753824" class="c"><input type="checkbox" id="c-39753824" checked=""/><div class="controls bullet"><span class="by">carlmr</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39752570">parent</a><span>|</span><a href="#39753941">prev</a><span>|</span><a href="#39752748">next</a><span>|</span><label class="collapse" for="c-39753824">[-]</label><label class="expand" for="c-39753824">[1 more]</label></div><br/><div class="children"><div class="content">&gt;1 bit (not floating point)<p>I like how you specified that it&#x27;s not floating point.</div><br/></div></div><div id="39752748" class="c"><input type="checkbox" id="c-39752748" checked=""/><div class="controls bullet"><span class="by">s_m_t</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39752570">parent</a><span>|</span><a href="#39753824">prev</a><span>|</span><a href="#39752658">next</a><span>|</span><label class="collapse" for="c-39752748">[-]</label><label class="expand" for="c-39752748">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, I was thinking that zero, negative zero, inf, negative inf, and the NaN&#x27;s were included like in IEEE 754</div><br/></div></div></div></div><div id="39752658" class="c"><input type="checkbox" id="c-39752658" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751281">parent</a><span>|</span><a href="#39752570">prev</a><span>|</span><a href="#39751645">next</a><span>|</span><label class="collapse" for="c-39752658">[-]</label><label class="expand" for="c-39752658">[3 more]</label></div><br/><div class="children"><div class="content">The fundamental &#x27;unit&#x27; of NN computation is not an individual vector element but rather an entire vector. One of the first results you often learn about in linear algebra is that some axes are more important than others (principal components, singular value decomposition). Thus, it totally stands to reason that the underlying field of the vector is inconsequential but rather the entire vector machinery. All you have to do is make sure that there are enough elements in the vector to get the job done for whatever bit size of element.</div><br/><div id="39752754" class="c"><input type="checkbox" id="c-39752754" checked=""/><div class="controls bullet"><span class="by">s_m_t</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39752658">parent</a><span>|</span><a href="#39751645">next</a><span>|</span><label class="collapse" for="c-39752754">[-]</label><label class="expand" for="c-39752754">[2 more]</label></div><br/><div class="children"><div class="content">I see, so the idea is that enough of the quantization errors are sort of averaged out across the dimensions of the vector space to still be useful?</div><br/><div id="39753345" class="c"><input type="checkbox" id="c-39753345" checked=""/><div class="controls bullet"><span class="by">singularity2001</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39752754">parent</a><span>|</span><a href="#39751645">next</a><span>|</span><label class="collapse" for="c-39753345">[-]</label><label class="expand" for="c-39753345">[1 more]</label></div><br/><div class="children"><div class="content">The way I think about it is finally it will end in a binary feature vector similar to 20Questions (male or female, alive or dead ...) just with 100s of dimensions</div><br/></div></div></div></div></div></div><div id="39751645" class="c"><input type="checkbox" id="c-39751645" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751281">parent</a><span>|</span><a href="#39752658">prev</a><span>|</span><a href="#39752534">next</a><span>|</span><label class="collapse" for="c-39751645">[-]</label><label class="expand" for="c-39751645">[1 more]</label></div><br/><div class="children"><div class="content">For training FP4 sounds pretty niche, but for inference it might be very useful.</div><br/></div></div><div id="39752534" class="c"><input type="checkbox" id="c-39752534" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#39750658">root</a><span>|</span><a href="#39751281">parent</a><span>|</span><a href="#39751645">prev</a><span>|</span><a href="#39751467">next</a><span>|</span><label class="collapse" for="c-39752534">[-]</label><label class="expand" for="c-39752534">[1 more]</label></div><br/><div class="children"><div class="content">The various sigmoid activation functions have the effect of keeping bit growth under control, by virtue of clamping to the +&#x2F;- 1 range.</div><br/></div></div></div></div><div id="39751020" class="c"><input type="checkbox" id="c-39751020" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#39750658">parent</a><span>|</span><a href="#39751281">prev</a><span>|</span><a href="#39750698">next</a><span>|</span><label class="collapse" for="c-39751020">[-]</label><label class="expand" for="c-39751020">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s right.There was mention of a precision aware transformer engine which might make it easier to use fp4, but it&#x27;s not 30x faster in a like for like way. This shouldn&#x27;t be surprising since it&#x27;s more or less two hoppers next to one another on a slightly improved process node. 2.5x seems more likely in cases where you don&#x27;t exploit a new feature like that or the increased memory.</div><br/></div></div><div id="39750662" class="c"><input type="checkbox" id="c-39750662" checked=""/><div class="controls bullet"><span class="by">sipjca</span><span>|</span><a href="#39750658">parent</a><span>|</span><a href="#39750698">prev</a><span>|</span><a href="#39750119">next</a><span>|</span><label class="collapse" for="c-39750662">[-]</label><label class="expand" for="c-39750662">[1 more]</label></div><br/><div class="children"><div class="content">yes</div><br/></div></div></div></div><div id="39750119" class="c"><input type="checkbox" id="c-39750119" checked=""/><div class="controls bullet"><span class="by">bluedino</span><span>|</span><a href="#39750658">prev</a><span>|</span><a href="#39750805">next</a><span>|</span><label class="collapse" for="c-39750119">[-]</label><label class="expand" for="c-39750119">[25 more]</label></div><br/><div class="children"><div class="content">They acquired Bright Cluster Manager a few years ago, who would be next on their list to acquire? It seems like they want to provide customers with the whole stack.</div><br/><div id="39753919" class="c"><input type="checkbox" id="c-39753919" checked=""/><div class="controls bullet"><span class="by">az226</span><span>|</span><a href="#39750119">parent</a><span>|</span><a href="#39750542">next</a><span>|</span><label class="collapse" for="c-39753919">[-]</label><label class="expand" for="c-39753919">[1 more]</label></div><br/><div class="children"><div class="content">Anthropic or Mistral and build AGI&#x2F;ASI.</div><br/></div></div><div id="39750542" class="c"><input type="checkbox" id="c-39750542" checked=""/><div class="controls bullet"><span class="by">shiftpgdn</span><span>|</span><a href="#39750119">parent</a><span>|</span><a href="#39753919">prev</a><span>|</span><a href="#39750942">next</a><span>|</span><label class="collapse" for="c-39750542">[-]</label><label class="expand" for="c-39750542">[21 more]</label></div><br/><div class="children"><div class="content">Canonical is a ripe target.  Canonical has been trying to grow Ubuntu and other tools in the enterprise world for the last few years without significant success, and much of the Nvidia devkit stuff is built around Ubuntu.</div><br/><div id="39751355" class="c"><input type="checkbox" id="c-39751355" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750542">parent</a><span>|</span><a href="#39753721">next</a><span>|</span><label class="collapse" for="c-39751355">[-]</label><label class="expand" for="c-39751355">[3 more]</label></div><br/><div class="children"><div class="content">Canonical’s culture [1] is the antithesis of what nvidia wants.<p>[1] <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;recruitinghell&#x2F;comments&#x2F;1bec2zk&#x2F;literally_the_most_insane_candidate_screening_for&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;recruitinghell&#x2F;comments&#x2F;1bec2zk&#x2F;lit...</a></div><br/><div id="39751399" class="c"><input type="checkbox" id="c-39751399" checked=""/><div class="controls bullet"><span class="by">riffic</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39751355">parent</a><span>|</span><a href="#39753721">next</a><span>|</span><label class="collapse" for="c-39751399">[-]</label><label class="expand" for="c-39751399">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not <i>culture</i>, that&#x27;s Shuttleworth.</div><br/><div id="39752455" class="c"><input type="checkbox" id="c-39752455" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39751399">parent</a><span>|</span><a href="#39753721">next</a><span>|</span><label class="collapse" for="c-39752455">[-]</label><label class="expand" for="c-39752455">[1 more]</label></div><br/><div class="children"><div class="content">&quot;We hire only the best who can fully recall the intimate nuances of their high school experience?&quot;</div><br/></div></div></div></div></div></div><div id="39753721" class="c"><input type="checkbox" id="c-39753721" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750542">parent</a><span>|</span><a href="#39751355">prev</a><span>|</span><a href="#39750623">next</a><span>|</span><label class="collapse" for="c-39753721">[-]</label><label class="expand" for="c-39753721">[1 more]</label></div><br/><div class="children"><div class="content">I would rather bet Microsoft doing that, given their cozy relationship for .NET and main WSL distribution.<p>At least I would finally get to buy MS Ubuntu PCs at the shopping mall.</div><br/></div></div><div id="39750623" class="c"><input type="checkbox" id="c-39750623" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750542">parent</a><span>|</span><a href="#39753721">prev</a><span>|</span><a href="#39750942">next</a><span>|</span><label class="collapse" for="c-39750623">[-]</label><label class="expand" for="c-39750623">[16 more]</label></div><br/><div class="children"><div class="content">Please do not give them this idea.<p>Ubuntu is actually a pretty great daily driver desktop Linux, and I&#x27;d hate for that to lose priority and disappear.<p>I&#x27;m not a fan of what happened to the Red Hat ecosystem for exactly the same reasons.</div><br/><div id="39750827" class="c"><input type="checkbox" id="c-39750827" checked=""/><div class="controls bullet"><span class="by">xmprt</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750623">parent</a><span>|</span><a href="#39752933">next</a><span>|</span><label class="collapse" for="c-39750827">[-]</label><label class="expand" for="c-39750827">[11 more]</label></div><br/><div class="children"><div class="content">As someone who has used Ubuntu in the past and has now moved onto greener pastures, I appreciate everything Canonical and Ubuntu have done for the Linux community but there are many better options today and Canonical is already far from the company it once used to be.</div><br/><div id="39751224" class="c"><input type="checkbox" id="c-39751224" checked=""/><div class="controls bullet"><span class="by">hnlmorg</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750827">parent</a><span>|</span><a href="#39753305">next</a><span>|</span><label class="collapse" for="c-39751224">[-]</label><label class="expand" for="c-39751224">[1 more]</label></div><br/><div class="children"><div class="content">There have always been better distributions than Ubuntu. That isn’t something new. What Canonical did better than anyone else was mass market appeal. Or at least appeal to a wider market than Linux traditionally had. But as someone who’s used Linux since the 90s, I was always underwhelmed by Ubuntu as a distribution.<p>That all said, I have to work with a lot of CentOS and Rocky workstations for VFX and I enjoy those for desktop Linux even less than Ubuntu.</div><br/></div></div><div id="39753305" class="c"><input type="checkbox" id="c-39753305" checked=""/><div class="controls bullet"><span class="by">solumunus</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750827">parent</a><span>|</span><a href="#39751224">prev</a><span>|</span><a href="#39750900">next</a><span>|</span><label class="collapse" for="c-39753305">[-]</label><label class="expand" for="c-39753305">[3 more]</label></div><br/><div class="children"><div class="content">I hate it when people say stuff like this and then don’t express their opinions on the better alternatives.</div><br/><div id="39753319" class="c"><input type="checkbox" id="c-39753319" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39753305">parent</a><span>|</span><a href="#39753796">next</a><span>|</span><label class="collapse" for="c-39753319">[-]</label><label class="expand" for="c-39753319">[1 more]</label></div><br/><div class="children"><div class="content">They mean Nix and Arch.</div><br/></div></div></div></div><div id="39750900" class="c"><input type="checkbox" id="c-39750900" checked=""/><div class="controls bullet"><span class="by">dgfitz</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750827">parent</a><span>|</span><a href="#39753305">prev</a><span>|</span><a href="#39752902">next</a><span>|</span><label class="collapse" for="c-39750900">[-]</label><label class="expand" for="c-39750900">[3 more]</label></div><br/><div class="children"><div class="content">Whenever I see an open job req for canonical I run for the hills.</div><br/><div id="39751726" class="c"><input type="checkbox" id="c-39751726" checked=""/><div class="controls bullet"><span class="by">mianos</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750900">parent</a><span>|</span><a href="#39752902">next</a><span>|</span><label class="collapse" for="c-39751726">[-]</label><label class="expand" for="c-39751726">[2 more]</label></div><br/><div class="children"><div class="content">They must have a fast revolving door. I have know so many people who worked there in the last few years but seem to have moved in.<p>Probably depends on the team and the worst ones have a lot of churn.</div><br/><div id="39752194" class="c"><input type="checkbox" id="c-39752194" checked=""/><div class="controls bullet"><span class="by">margorczynski</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39751726">parent</a><span>|</span><a href="#39752902">next</a><span>|</span><label class="collapse" for="c-39752194">[-]</label><label class="expand" for="c-39752194">[1 more]</label></div><br/><div class="children"><div class="content">From what I see on Glassdoor they have bad, toxic management so that would explain a lot.</div><br/></div></div></div></div></div></div><div id="39752902" class="c"><input type="checkbox" id="c-39752902" checked=""/><div class="controls bullet"><span class="by">xarope</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750827">parent</a><span>|</span><a href="#39750900">prev</a><span>|</span><a href="#39752933">next</a><span>|</span><label class="collapse" for="c-39752902">[-]</label><label class="expand" for="c-39752902">[3 more]</label></div><br/><div class="children"><div class="content">what would your top suggestions be for server or desktop, instead of ubuntu?  Arch (too unstable for server?), Silverblue?</div><br/><div id="39753333" class="c"><input type="checkbox" id="c-39753333" checked=""/><div class="controls bullet"><span class="by">rompledorph</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39752902">parent</a><span>|</span><a href="#39753631">next</a><span>|</span><label class="collapse" for="c-39753333">[-]</label><label class="expand" for="c-39753333">[1 more]</label></div><br/><div class="children"><div class="content">Recently installed PopOS on my desktop. That is currently my top suggestion as an Ubuntu alternative</div><br/></div></div><div id="39753631" class="c"><input type="checkbox" id="c-39753631" checked=""/><div class="controls bullet"><span class="by">unmole</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39752902">parent</a><span>|</span><a href="#39753333">prev</a><span>|</span><a href="#39752933">next</a><span>|</span><label class="collapse" for="c-39753631">[-]</label><label class="expand" for="c-39753631">[1 more]</label></div><br/><div class="children"><div class="content">Debian for server, Fedora or openSUSE Tumbleweed for desktop.</div><br/></div></div></div></div></div></div><div id="39752933" class="c"><input type="checkbox" id="c-39752933" checked=""/><div class="controls bullet"><span class="by">pm90</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750623">parent</a><span>|</span><a href="#39750827">prev</a><span>|</span><a href="#39751403">next</a><span>|</span><label class="collapse" for="c-39752933">[-]</label><label class="expand" for="c-39752933">[1 more]</label></div><br/><div class="children"><div class="content">What happened to Red Hat? As far as I see they’re continuing to invest in linux. Im glad they are keeping CoreOs around as FCOS.</div><br/></div></div><div id="39751403" class="c"><input type="checkbox" id="c-39751403" checked=""/><div class="controls bullet"><span class="by">riffic</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750623">parent</a><span>|</span><a href="#39752933">prev</a><span>|</span><a href="#39751058">next</a><span>|</span><label class="collapse" for="c-39751403">[-]</label><label class="expand" for="c-39751403">[1 more]</label></div><br/><div class="children"><div class="content">the desktop Linux ecosystem can survive w&#x2F;o Ubuntu. Silverblue &#x2F; Universal Blue for instance is quite compelling.</div><br/></div></div><div id="39751058" class="c"><input type="checkbox" id="c-39751058" checked=""/><div class="controls bullet"><span class="by">greggsy</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39750623">parent</a><span>|</span><a href="#39751403">prev</a><span>|</span><a href="#39750942">next</a><span>|</span><label class="collapse" for="c-39751058">[-]</label><label class="expand" for="c-39751058">[2 more]</label></div><br/><div class="children"><div class="content">Tbh, Ubuntu’s only pull is the support and breadth of users. As a desktop, it’s let down by Unity, which IMHO is basically a port of Windows 8 tablet UI.<p>If they defaulted back to a menu and taskbar-based WM, it might actually be more approachable to users who are more familiar with macOS and Windows.</div><br/><div id="39751125" class="c"><input type="checkbox" id="c-39751125" checked=""/><div class="controls bullet"><span class="by">kcb</span><span>|</span><a href="#39750119">root</a><span>|</span><a href="#39751058">parent</a><span>|</span><a href="#39750942">next</a><span>|</span><label class="collapse" for="c-39751125">[-]</label><label class="expand" for="c-39751125">[1 more]</label></div><br/><div class="children"><div class="content">Main Ubuntu hasn&#x27;t shipped with Unity for like 7 years.</div><br/></div></div></div></div></div></div></div></div><div id="39750942" class="c"><input type="checkbox" id="c-39750942" checked=""/><div class="controls bullet"><span class="by">kflansburg</span><span>|</span><a href="#39750119">parent</a><span>|</span><a href="#39750542">prev</a><span>|</span><a href="#39750934">next</a><span>|</span><label class="collapse" for="c-39750942">[-]</label><label class="expand" for="c-39750942">[1 more]</label></div><br/><div class="children"><div class="content">Run:AI <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39738342">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39738342</a></div><br/></div></div></div></div><div id="39750805" class="c"><input type="checkbox" id="c-39750805" checked=""/><div class="controls bullet"><span class="by">herecomethefuzz</span><span>|</span><a href="#39750119">prev</a><span>|</span><a href="#39752532">next</a><span>|</span><label class="collapse" for="c-39750805">[-]</label><label class="expand" for="c-39750805">[9 more]</label></div><br/><div class="children"><div class="content">&quot;Platform company&quot; means multi-chip in this case?<p>Seems logical since it&#x27;s becoming impractical to cram so many transistors on a single die.</div><br/><div id="39751163" class="c"><input type="checkbox" id="c-39751163" checked=""/><div class="controls bullet"><span class="by">dweekly</span><span>|</span><a href="#39750805">parent</a><span>|</span><a href="#39751154">next</a><span>|</span><label class="collapse" for="c-39751163">[-]</label><label class="expand" for="c-39751163">[1 more]</label></div><br/><div class="children"><div class="content">It means all the main chips required for a large-scale datacenter. And many of the layers of software on top of it.<p>Hardware:
* The GPU
* The GPU-GPU Fabric (NVLINK)
* The CPU
* The NIC
* The Network Fabric (infiniband)
* The Switch<p>And that&#x27;s not even starting to get into the many layers of the software stack (CUDA, Riva, Megatron, Omniverse) that they&#x27;re contributing and working to get folks to build on.</div><br/></div></div><div id="39751154" class="c"><input type="checkbox" id="c-39751154" checked=""/><div class="controls bullet"><span class="by">0xcde4c3db</span><span>|</span><a href="#39750805">parent</a><span>|</span><a href="#39751163">prev</a><span>|</span><a href="#39750980">next</a><span>|</span><label class="collapse" for="c-39751154">[-]</label><label class="expand" for="c-39751154">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really understand the bird&#x27;s-eye view of the product line, but judging by some of the raw physical numbers and configurations Jensen was bragging about, it means that they want to basically play the mainframe game of locking high-end applications into proprietary middleware running on proprietary chassis with proprietary cluster interconnect (hello, Mellanox acquisiton).</div><br/><div id="39751379" class="c"><input type="checkbox" id="c-39751379" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#39750805">root</a><span>|</span><a href="#39751154">parent</a><span>|</span><a href="#39752831">next</a><span>|</span><label class="collapse" for="c-39751379">[-]</label><label class="expand" for="c-39751379">[1 more]</label></div><br/><div class="children"><div class="content">The lock-in is more of a bonus for them. The underlying problem is that it&#x27;s impossible to build a chip big enough, or even a collection of chiplets big enough. Training LLMs requires more silicon than can fit on one PCB, so they need an interconnect that is as fast as possible. With interconnect bandwidth as a critical bottleneck, they&#x27;re not going to wait around for the industry to standardize on a suitable interconnect when they can build what they need to be ready to ship alongside the chips they need to connect.</div><br/></div></div><div id="39752831" class="c"><input type="checkbox" id="c-39752831" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#39750805">root</a><span>|</span><a href="#39751154">parent</a><span>|</span><a href="#39751379">prev</a><span>|</span><a href="#39750980">next</a><span>|</span><label class="collapse" for="c-39752831">[-]</label><label class="expand" for="c-39752831">[1 more]</label></div><br/><div class="children"><div class="content">In this case the interconnects are also doing compute.</div><br/></div></div></div></div><div id="39750980" class="c"><input type="checkbox" id="c-39750980" checked=""/><div class="controls bullet"><span class="by">1oooqooq</span><span>|</span><a href="#39750805">parent</a><span>|</span><a href="#39751154">prev</a><span>|</span><a href="#39752532">next</a><span>|</span><label class="collapse" for="c-39750980">[-]</label><label class="expand" for="c-39750980">[4 more]</label></div><br/><div class="children"><div class="content">no it means rent seeking.<p>imagine aws if they also sold all computers in the world, now you can only rent from them</div><br/><div id="39752610" class="c"><input type="checkbox" id="c-39752610" checked=""/><div class="controls bullet"><span class="by">maximus-decimus</span><span>|</span><a href="#39750805">root</a><span>|</span><a href="#39750980">parent</a><span>|</span><a href="#39751165">next</a><span>|</span><label class="collapse" for="c-39752610">[-]</label><label class="expand" for="c-39752610">[2 more]</label></div><br/><div class="children"><div class="content">&quot;For only 100$ a month, you&#x27;ll be able to turn on the gpu you already paid for&quot;<p>--Nvidia, pretty soon</div><br/><div id="39753449" class="c"><input type="checkbox" id="c-39753449" checked=""/><div class="controls bullet"><span class="by">bpye</span><span>|</span><a href="#39750805">root</a><span>|</span><a href="#39752610">parent</a><span>|</span><a href="#39751165">next</a><span>|</span><label class="collapse" for="c-39753449">[-]</label><label class="expand" for="c-39753449">[1 more]</label></div><br/><div class="children"><div class="content">This is sort of already a reality. Their vGPU functionality (partitioning a single physical GPU into multiple virtual GPUs) is already separately licensed - <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;buy-grid&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;buy-grid&#x2F;</a><p>And that&#x27;s once you&#x27;ve bought an expensive Tesla&#x2F;Quadro GPU too.</div><br/></div></div></div></div><div id="39751165" class="c"><input type="checkbox" id="c-39751165" checked=""/><div class="controls bullet"><span class="by">throwaway11460</span><span>|</span><a href="#39750805">root</a><span>|</span><a href="#39750980">parent</a><span>|</span><a href="#39752610">prev</a><span>|</span><a href="#39752532">next</a><span>|</span><label class="collapse" for="c-39751165">[-]</label><label class="expand" for="c-39751165">[1 more]</label></div><br/><div class="children"><div class="content">So like IBM at the beginning of computers</div><br/></div></div></div></div></div></div><div id="39752532" class="c"><input type="checkbox" id="c-39752532" checked=""/><div class="controls bullet"><span class="by">jakobov</span><span>|</span><a href="#39750805">prev</a><span>|</span><a href="#39751158">next</a><span>|</span><label class="collapse" for="c-39752532">[-]</label><label class="expand" for="c-39752532">[4 more]</label></div><br/><div class="children"><div class="content">They are claiming a 25x reduction in power consumption. That can&#x27;t be right. Anyone understand where this number is coming from?</div><br/><div id="39752645" class="c"><input type="checkbox" id="c-39752645" checked=""/><div class="controls bullet"><span class="by">LTL_FTC</span><span>|</span><a href="#39752532">parent</a><span>|</span><a href="#39751158">next</a><span>|</span><label class="collapse" for="c-39752645">[-]</label><label class="expand" for="c-39752645">[3 more]</label></div><br/><div class="children"><div class="content">Did you read that in the linked article? I couldn’t find it. But maybe due to the better efficiency with regard to the performance boost (5x) and the ability to now use 27 trillion parameters versus 1.7 Trillion, one can presumably finish the same amount of work in 1&#x2F;25th of the time and bam, reduction in power consumption. As you say, I’m skeptical the max power draw itself is 25x lower.</div><br/><div id="39752769" class="c"><input type="checkbox" id="c-39752769" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39752532">root</a><span>|</span><a href="#39752645">parent</a><span>|</span><a href="#39751158">next</a><span>|</span><label class="collapse" for="c-39752769">[-]</label><label class="expand" for="c-39752769">[2 more]</label></div><br/><div class="children"><div class="content">I think Jensen said something like needing 25x fewer GPUs (vs. A100) to get the same performance, which amounts to essentially the same thing.</div><br/><div id="39753540" class="c"><input type="checkbox" id="c-39753540" checked=""/><div class="controls bullet"><span class="by">creshal</span><span>|</span><a href="#39752532">root</a><span>|</span><a href="#39752769">parent</a><span>|</span><a href="#39751158">next</a><span>|</span><label class="collapse" for="c-39753540">[-]</label><label class="expand" for="c-39753540">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t imply a full 25x reduction in power consumption though, that might &quot;only&quot; go down by 10x.</div><br/></div></div></div></div></div></div></div></div><div id="39751158" class="c"><input type="checkbox" id="c-39751158" checked=""/><div class="controls bullet"><span class="by">Deasiomlo</span><span>|</span><a href="#39752532">prev</a><span>|</span><a href="#39751144">next</a><span>|</span><label class="collapse" for="c-39751158">[-]</label><label class="expand" for="c-39751158">[4 more]</label></div><br/><div class="children"><div class="content">Double digit peta flop mass produced.<p>&quot;The computing power needed to replicate the human brain’s relevant activities has been estimated by various authors, with answers ranging from 10^12 to 10^28 FLOPS.&quot;<p>Petaflop is 10^15<p>Crazy times.</div><br/><div id="39751235" class="c"><input type="checkbox" id="c-39751235" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#39751158">parent</a><span>|</span><a href="#39751144">next</a><span>|</span><label class="collapse" for="c-39751235">[-]</label><label class="expand" for="c-39751235">[3 more]</label></div><br/><div class="children"><div class="content">I’ll be happy with this if we use it to design viable fusion power plants. And I’ll be severely disappointed if it’s mostly used for ad targeting.</div><br/><div id="39753356" class="c"><input type="checkbox" id="c-39753356" checked=""/><div class="controls bullet"><span class="by">sbstp</span><span>|</span><a href="#39751158">root</a><span>|</span><a href="#39751235">parent</a><span>|</span><a href="#39751307">next</a><span>|</span><label class="collapse" for="c-39753356">[-]</label><label class="expand" for="c-39753356">[1 more]</label></div><br/><div class="children"><div class="content">You are about to be severely disappointed.</div><br/></div></div><div id="39751307" class="c"><input type="checkbox" id="c-39751307" checked=""/><div class="controls bullet"><span class="by">steelframe</span><span>|</span><a href="#39751158">root</a><span>|</span><a href="#39751235">parent</a><span>|</span><a href="#39753356">prev</a><span>|</span><a href="#39751144">next</a><span>|</span><label class="collapse" for="c-39751307">[-]</label><label class="expand" for="c-39751307">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I’ll be severely disappointed if it’s mostly used for ad targeting<p>Obligatory Rick and Morty: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=xerLPWdyX-M" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=xerLPWdyX-M</a></div><br/></div></div></div></div></div></div><div id="39751144" class="c"><input type="checkbox" id="c-39751144" checked=""/><div class="controls bullet"><span class="by">tzm</span><span>|</span><a href="#39751158">prev</a><span>|</span><a href="#39749917">next</a><span>|</span><label class="collapse" for="c-39751144">[-]</label><label class="expand" for="c-39751144">[3 more]</label></div><br/><div class="children"><div class="content">Platform co seems fitting, considering Nvidia&#x27;s data center revenue in the fourth quarter of 2023 was a record $18.4 billion, which is 27% higher than the previous quarter and 409% higher than the previous year.<p>Seems revenue from inference is growing at a significant clip.</div><br/><div id="39751723" class="c"><input type="checkbox" id="c-39751723" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#39751144">parent</a><span>|</span><a href="#39751561">next</a><span>|</span><label class="collapse" for="c-39751723">[-]</label><label class="expand" for="c-39751723">[1 more]</label></div><br/><div class="children"><div class="content">Data center revenue includes sales to companies like Meta that run their chips in their own data centers.</div><br/></div></div></div></div><div id="39749917" class="c"><input type="checkbox" id="c-39749917" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#39751144">prev</a><span>|</span><a href="#39752810">next</a><span>|</span><label class="collapse" for="c-39749917">[-]</label><label class="expand" for="c-39749917">[28 more]</label></div><br/><div class="children"><div class="content">FP8 being 2.5x Hopper is kind of disappointing after such a long time.  Since its 2 fused chips, that means it’s 25% effective delta.<p>though it seems most of the progress has been on memory throughput and power use which is still very impressive.<p>I wonder how this will trickle down to the consumer segment.</div><br/><div id="39750066" class="c"><input type="checkbox" id="c-39750066" checked=""/><div class="controls bullet"><span class="by">azeirah</span><span>|</span><a href="#39749917">parent</a><span>|</span><a href="#39750592">next</a><span>|</span><label class="collapse" for="c-39750066">[-]</label><label class="expand" for="c-39750066">[18 more]</label></div><br/><div class="children"><div class="content">Jensen revealed later that the LLM inference is 30x due to architectural improvements, it&#x27;s massive. I don&#x27;t know if it&#x27;s latency or just 2-3x performance boost with 30x more customers served in the same chip. Either way, 30x is massive.</div><br/><div id="39751147" class="c"><input type="checkbox" id="c-39751147" checked=""/><div class="controls bullet"><span class="by">kkielhofner</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750066">parent</a><span>|</span><a href="#39750490">next</a><span>|</span><label class="collapse" for="c-39751147">[-]</label><label class="expand" for="c-39751147">[1 more]</label></div><br/><div class="children"><div class="content">The other big announcement here is NIM - Nvidia Inference Microservice.<p>It&#x27;s basically TensorRT-LLM + Triton Inference Server + pre-build of models to TensorRT-LLM engines + packaging + what appears to be an OpenAI compatible API router in front of all of it + other &quot;enterprise&quot; management and deployment tools.<p>This software stack is extremely performant and very flexible, I&#x27;ve noted here before it&#x27;s what many large-scale hosted inference providers are already using (Amazon, Cloudflare, Mistral, etc).<p>From the article:<p>&#x27;Nvidia will work with AI companies like Microsoft or Hugging Face to ensure their AI models are tuned to run on all compatible Nvidia chips. Then, using a NIM, developers can efficiently run the model on their own servers or cloud-based Nvidia servers without a lengthy configuration process.<p>“In my code, where I was calling into OpenAI, I will replace one line of code to point it to this NIM that I got from Nvidia instead,” Das said.&#x27;<p>The dead giveaway is &quot;I changed one line of code in my OpenAI code&quot; which means &quot;I pointed the OpenAI API base URL to an OpenAI compatible API proxy that likely interfaces with Triton on the backend via its gRPC protocol&quot;.<p>I have a lot of experience with TensorRT-LLM + Triton and have been working on a highly performant rust-based open source project for the OpenAI compatible API and routing portion[0].<p>On this hardware (FP4) with this software package 30x compared to other solutions (who knows what - base transformers?) on Hopper seems possible. TensorRT-LLM and Triton can already do FP8 on Hopper and as noted the performance is impressive.<p>[0] - <a href="https:&#x2F;&#x2F;github.com&#x2F;toverainc&#x2F;ai-router">https:&#x2F;&#x2F;github.com&#x2F;toverainc&#x2F;ai-router</a></div><br/></div></div><div id="39750490" class="c"><input type="checkbox" id="c-39750490" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750066">parent</a><span>|</span><a href="#39751147">prev</a><span>|</span><a href="#39750114">next</a><span>|</span><label class="collapse" for="c-39750490">[-]</label><label class="expand" for="c-39750490">[4 more]</label></div><br/><div class="children"><div class="content">He always does that. They stack up a bunch of special case features like sparsity that most people don&#x27;t use in practice to get these unrealistic numbers. It&#x27;ll be faster, certainly, but 30x will only be achievable in very special cases I&#x27;m sure.</div><br/><div id="39750655" class="c"><input type="checkbox" id="c-39750655" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750490">parent</a><span>|</span><a href="#39750114">next</a><span>|</span><label class="collapse" for="c-39750655">[-]</label><label class="expand" for="c-39750655">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t sparsity almost always a win at this point?  Making everything fully connected is a major waste.</div><br/><div id="39750943" class="c"><input type="checkbox" id="c-39750943" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750655">parent</a><span>|</span><a href="#39750114">next</a><span>|</span><label class="collapse" for="c-39750943">[-]</label><label class="expand" for="c-39750943">[2 more]</label></div><br/><div class="children"><div class="content">The kind of sparsity that the hardware supports is not fully general. I&#x27;m not aware of any large models trained using it. Maybe they are all leaving 2x perf on the table for no reason, but maybe not. I don&#x27;t think sparsity is really proven to be &quot;almost always a win&quot; for training.</div><br/><div id="39752476" class="c"><input type="checkbox" id="c-39752476" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750943">parent</a><span>|</span><a href="#39750114">next</a><span>|</span><label class="collapse" for="c-39752476">[-]</label><label class="expand" for="c-39752476">[1 more]</label></div><br/><div class="children"><div class="content">To train well with it I think you still need to store all the optimizer state (derivatives and momentum or whatever) if not all the weights (for RigL), so maybe not nearly as much memory bandwidth advantage as you get in inference?</div><br/></div></div></div></div></div></div></div></div><div id="39750114" class="c"><input type="checkbox" id="c-39750114" checked=""/><div class="controls bullet"><span class="by">ephemeral-life</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750066">parent</a><span>|</span><a href="#39750490">prev</a><span>|</span><a href="#39752726">next</a><span>|</span><label class="collapse" for="c-39750114">[-]</label><label class="expand" for="c-39750114">[6 more]</label></div><br/><div class="children"><div class="content">30x is the type of number that when you see it in a generational improvement, you should ignore it as marketing fluff.</div><br/><div id="39750208" class="c"><input type="checkbox" id="c-39750208" checked=""/><div class="controls bullet"><span class="by">azeirah</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750114">parent</a><span>|</span><a href="#39752726">next</a><span>|</span><label class="collapse" for="c-39750208">[-]</label><label class="expand" for="c-39750208">[5 more]</label></div><br/><div class="children"><div class="content">From how I understood it, it means they optimised the entire stack from CUDA to the networking interconnects specifically for data centers, meaning you get 30x more inference per dollar for a datacenter. This is probably not fluff, but it&#x27;s only relevant for a very very specific use-case, ie enterprises with the money to buy a stack to serve thousands of users with LLMs.<p>It doesn&#x27;t matter for anyone who&#x27;s not microsoft, aws or openai or similar.</div><br/><div id="39751383" class="c"><input type="checkbox" id="c-39751383" checked=""/><div class="controls bullet"><span class="by">misterdabb</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750208">parent</a><span>|</span><a href="#39750672">next</a><span>|</span><label class="collapse" for="c-39751383">[-]</label><label class="expand" for="c-39751383">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a weird graph... It&#x27;s specifically tokens per GPU but the x-axis is &quot;interactivity per second&quot;, so the y-axis is including Blackwell being twice the size and also the increase from fp8 -&gt; fp4, note it will needs to be counted multiple time as half as much data is needed to be going through the networks as well.</div><br/></div></div><div id="39750672" class="c"><input type="checkbox" id="c-39750672" checked=""/><div class="controls bullet"><span class="by">acchow</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750208">parent</a><span>|</span><a href="#39751383">prev</a><span>|</span><a href="#39752726">next</a><span>|</span><label class="collapse" for="c-39750672">[-]</label><label class="expand" for="c-39750672">[3 more]</label></div><br/><div class="children"><div class="content">They showed 30x was for FP4. Who is using FP4 in practice?</div><br/><div id="39750768" class="c"><input type="checkbox" id="c-39750768" checked=""/><div class="controls bullet"><span class="by">KaoruAoiShiho</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750672">parent</a><span>|</span><a href="#39752726">next</a><span>|</span><label class="collapse" for="c-39750768">[-]</label><label class="expand" for="c-39750768">[2 more]</label></div><br/><div class="children"><div class="content">But maybe you should. Once the software stack is ready for it there&#x27;ll be more people since the performance gains are so massive.</div><br/><div id="39752509" class="c"><input type="checkbox" id="c-39752509" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750768">parent</a><span>|</span><a href="#39752726">next</a><span>|</span><label class="collapse" for="c-39752509">[-]</label><label class="expand" for="c-39752509">[1 more]</label></div><br/><div class="children"><div class="content">It would depend highly on the model though. Some stuff will generalize better to FP4 than others.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39752726" class="c"><input type="checkbox" id="c-39752726" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750066">parent</a><span>|</span><a href="#39750114">prev</a><span>|</span><a href="#39750184">next</a><span>|</span><label class="collapse" for="c-39752726">[-]</label><label class="expand" for="c-39752726">[1 more]</label></div><br/><div class="children"><div class="content">This is also the only place Nvidia are getting competitive pressure - from the likes of Groq (and likely but less published from Cerebras) with higher inferance T&#x2F;s and concurrency utilization&#x2F;batching [1]  so if this proves to be the true then the case for big chip systems (on todays specs) will be harder.<p>[1]<a href="https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1760065636410274162?t=rpbcr8hbwnG7QBxZgVAbFQ&amp;s=19" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;swyx&#x2F;status&#x2F;1760065636410274162?t=rpbcr8...</a></div><br/></div></div><div id="39750184" class="c"><input type="checkbox" id="c-39750184" checked=""/><div class="controls bullet"><span class="by">my123</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750066">parent</a><span>|</span><a href="#39752726">prev</a><span>|</span><a href="#39750229">next</a><span>|</span><label class="collapse" for="c-39750184">[-]</label><label class="expand" for="c-39750184">[3 more]</label></div><br/><div class="children"><div class="content">The 30x number is for a really narrow scenario tbh. Running a GPT 1.8T parameters (w&#x2F; MOE) on one GB200</div><br/><div id="39750321" class="c"><input type="checkbox" id="c-39750321" checked=""/><div class="controls bullet"><span class="by">huac</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750184">parent</a><span>|</span><a href="#39750307">next</a><span>|</span><label class="collapse" for="c-39750321">[-]</label><label class="expand" for="c-39750321">[1 more]</label></div><br/><div class="children"><div class="content">&#x27;narrow scenario,&#x27; perhaps, but one that also happens to closely match rumors for GPT4&#x27;s size</div><br/></div></div></div></div><div id="39750229" class="c"><input type="checkbox" id="c-39750229" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750066">parent</a><span>|</span><a href="#39750184">prev</a><span>|</span><a href="#39750729">next</a><span>|</span><label class="collapse" for="c-39750229">[-]</label><label class="expand" for="c-39750229">[1 more]</label></div><br/><div class="children"><div class="content">Yeah and the 30x is largely due to the increase in factors like packaging and throughput. It&#x27;s not indicative of general purpose performance which is what I was talking about.<p>Again, I do think the throughput and energy efficiency gains are impressive, but the raw performance gain is lower than I&#x27;d have expected for the massive leap in node size etc</div><br/></div></div><div id="39750729" class="c"><input type="checkbox" id="c-39750729" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750066">parent</a><span>|</span><a href="#39750229">prev</a><span>|</span><a href="#39750592">next</a><span>|</span><label class="collapse" for="c-39750729">[-]</label><label class="expand" for="c-39750729">[1 more]</label></div><br/><div class="children"><div class="content">But Blackwell in the graph is FP4 whereas Hopper is FP8.</div><br/></div></div></div></div><div id="39750592" class="c"><input type="checkbox" id="c-39750592" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#39749917">parent</a><span>|</span><a href="#39750066">prev</a><span>|</span><a href="#39752810">next</a><span>|</span><label class="collapse" for="c-39750592">[-]</label><label class="expand" for="c-39750592">[9 more]</label></div><br/><div class="children"><div class="content">How is 2.5x disappointing in one generation?</div><br/><div id="39751169" class="c"><input type="checkbox" id="c-39751169" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750592">parent</a><span>|</span><a href="#39750638">next</a><span>|</span><label class="collapse" for="c-39751169">[-]</label><label class="expand" for="c-39751169">[6 more]</label></div><br/><div class="children"><div class="content">Did you skip the sentence immediately after that one?<p>It’s two fused chips. So 1.25x per chip. 25% uplift. Not 2.5x uplift. The 2.5x is for the whole package.</div><br/><div id="39752179" class="c"><input type="checkbox" id="c-39752179" checked=""/><div class="controls bullet"><span class="by">downvotetruth</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39751169">parent</a><span>|</span><a href="#39752126">next</a><span>|</span><label class="collapse" for="c-39752179">[-]</label><label class="expand" for="c-39752179">[2 more]</label></div><br/><div class="children"><div class="content">&gt; two fused chips<p>Jensen&#x27;s comment about being first was such a dig to Emerald Rapids.</div><br/><div id="39752489" class="c"><input type="checkbox" id="c-39752489" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39752179">parent</a><span>|</span><a href="#39752126">next</a><span>|</span><label class="collapse" for="c-39752489">[-]</label><label class="expand" for="c-39752489">[1 more]</label></div><br/><div class="children"><div class="content">Is it the first? The Apple Ultra series chips are two Max’s fused with an interconnect. In which case it’s both CPU and GPU.<p>I believe this is just the first for a GPU only product.</div><br/></div></div></div></div><div id="39752126" class="c"><input type="checkbox" id="c-39752126" checked=""/><div class="controls bullet"><span class="by">throwaway11460</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39751169">parent</a><span>|</span><a href="#39752179">prev</a><span>|</span><a href="#39750638">next</a><span>|</span><label class="collapse" for="c-39752126">[-]</label><label class="expand" for="c-39752126">[3 more]</label></div><br/><div class="children"><div class="content">Is that how it works? Why don&#x27;t we just put many chips in one computer?</div><br/><div id="39752498" class="c"><input type="checkbox" id="c-39752498" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39752126">parent</a><span>|</span><a href="#39750638">next</a><span>|</span><label class="collapse" for="c-39752498">[-]</label><label class="expand" for="c-39752498">[2 more]</label></div><br/><div class="children"><div class="content">the massive blackwell SoC he showed is two Blackwell dies with an interconnect. It’s very similar to what Apple does with their Ultra series.<p>Then the B200 package is 2 of these plus a CPU. So a total of 4 GPU dies in each unit.</div><br/><div id="39752579" class="c"><input type="checkbox" id="c-39752579" checked=""/><div class="controls bullet"><span class="by">abhinavk</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39752498">parent</a><span>|</span><a href="#39750638">next</a><span>|</span><label class="collapse" for="c-39752579">[-]</label><label class="expand" for="c-39752579">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Then the B200 package is 2 of these plus a CPU.<p>That&#x27;s GB200.</div><br/></div></div></div></div></div></div></div></div><div id="39750638" class="c"><input type="checkbox" id="c-39750638" checked=""/><div class="controls bullet"><span class="by">chimney</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750592">parent</a><span>|</span><a href="#39751169">prev</a><span>|</span><a href="#39752810">next</a><span>|</span><label class="collapse" for="c-39750638">[-]</label><label class="expand" for="c-39750638">[2 more]</label></div><br/><div class="children"><div class="content">Compare to the 10x that was Hopper uplift.</div><br/><div id="39750770" class="c"><input type="checkbox" id="c-39750770" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#39749917">root</a><span>|</span><a href="#39750638">parent</a><span>|</span><a href="#39752810">next</a><span>|</span><label class="collapse" for="c-39750770">[-]</label><label class="expand" for="c-39750770">[1 more]</label></div><br/><div class="children"><div class="content">Because it involved scaling in chip area needed for FP8. AI community realized that FP8 training is possible few years back so the transistors given for FP8 was scaled. Overall I think transistors grow just by ~50% per generation so most of the gains comes from removing FP32&#x2F;FP64 share which were dominant 10 years back, but there is only some point it could go to.</div><br/></div></div></div></div></div></div></div></div><div id="39752810" class="c"><input type="checkbox" id="c-39752810" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39749917">prev</a><span>|</span><a href="#39749849">next</a><span>|</span><label class="collapse" for="c-39752810">[-]</label><label class="expand" for="c-39752810">[1 more]</label></div><br/><div class="children"><div class="content">More technical details: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39752500">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39752500</a></div><br/></div></div><div id="39749849" class="c"><input type="checkbox" id="c-39749849" checked=""/><div class="controls bullet"><span class="by">paulpauper</span><span>|</span><a href="#39752810">prev</a><span>|</span><a href="#39750664">next</a><span>|</span><label class="collapse" for="c-39749849">[-]</label><label class="expand" for="c-39749849">[60 more]</label></div><br/><div class="children"><div class="content">Stock unchanged in afterhours. A lot of people were hoping for a big pop on some big development.</div><br/><div id="39750151" class="c"><input type="checkbox" id="c-39750151" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#39749849">parent</a><span>|</span><a href="#39750337">next</a><span>|</span><label class="collapse" for="c-39750151">[-]</label><label class="expand" for="c-39750151">[46 more]</label></div><br/><div class="children"><div class="content">Well, stock price is not a good short term indicator about Nvidia developments, nor any company for that matter. Nvidia is doing a very good job.<p>That being said, their stock is absolutely and hilariously overvalued.</div><br/><div id="39751207" class="c"><input type="checkbox" id="c-39751207" checked=""/><div class="controls bullet"><span class="by">Blammar</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750151">parent</a><span>|</span><a href="#39750258">next</a><span>|</span><label class="collapse" for="c-39751207">[-]</label><label class="expand" for="c-39751207">[9 more]</label></div><br/><div class="children"><div class="content">NVDA&#x27;s forward PE is ~37, about what it has been for the past ~5 years I&#x27;ve been tracking that. So it&#x27;s not overpriced based on that metric.<p>If you&#x27;re convinced the stock is that overvalued, go short some or, if you like to live dangerously, buy some long-term put options (don&#x27;t be an idiot and buy short-term options.)<p>I have no idea if NVDA is like Cisco Systems in 2000, or if it&#x27;s something unique. What I am aware of is that there&#x27;s around 5-7 trillion that were moved from stocks to t-bills since the Fed raised rates in March 2022. If and when they drop their rates back to the historical ~2.5%, it&#x27;s reasonable to predict these funds will go back into stocks, which will presumably drive up prices.</div><br/><div id="39751354" class="c"><input type="checkbox" id="c-39751354" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39751207">parent</a><span>|</span><a href="#39752507">next</a><span>|</span><label class="collapse" for="c-39751354">[-]</label><label class="expand" for="c-39751354">[7 more]</label></div><br/><div class="children"><div class="content">That&#x27;s exactly what I&#x27;m saying below - PE is still very high, hence projecting the past growth into the future. But the scale changed a bit. A 37 PE ratio is extremely high by historical standards - this was reserved for very promising, small startups. Not for 2T companies. I know this got distorted in the past 15 years by abnormally low interest rates, but sooner or later it will come back to something that makes sense.<p>Buying long-term put options on Nvidia now is extremely expensive - the stock was so volatile that the price you pay for those options almost annihilate any gains you could expect, even if the stock losses 50% in 12 months.<p>You got me curious about those 5-7 trillions. Where these numbers come from ?</div><br/><div id="39752275" class="c"><input type="checkbox" id="c-39752275" checked=""/><div class="controls bullet"><span class="by">rytill</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39751354">parent</a><span>|</span><a href="#39753336">next</a><span>|</span><label class="collapse" for="c-39752275">[-]</label><label class="expand" for="c-39752275">[3 more]</label></div><br/><div class="children"><div class="content">Then be the options seller. You can sell cash secured puts, or a put credit spread, or a call credit spread. Calls are even more expensive than puts right now.</div><br/><div id="39752479" class="c"><input type="checkbox" id="c-39752479" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39752275">parent</a><span>|</span><a href="#39753336">next</a><span>|</span><label class="collapse" for="c-39752479">[-]</label><label class="expand" for="c-39752479">[2 more]</label></div><br/><div class="children"><div class="content">Selling options is an even worse idea.<p>Frankly, I don&#x27;t understand why we made it possible for individuals to gamble by selling options. As Charlie Munger used to say, Wall Street will sell shit as long as shit can be sold.</div><br/><div id="39753723" class="c"><input type="checkbox" id="c-39753723" checked=""/><div class="controls bullet"><span class="by">rytill</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39752479">parent</a><span>|</span><a href="#39753336">next</a><span>|</span><label class="collapse" for="c-39753723">[-]</label><label class="expand" for="c-39753723">[1 more]</label></div><br/><div class="children"><div class="content">You would be right about selling naked options. But call&#x2F;put credit spreads have bounded downside, just like buying options.<p>Selling cash secured puts or selling covered calls would be less risky than just holding stock.</div><br/></div></div></div></div></div></div><div id="39753336" class="c"><input type="checkbox" id="c-39753336" checked=""/><div class="controls bullet"><span class="by">solumunus</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39751354">parent</a><span>|</span><a href="#39752275">prev</a><span>|</span><a href="#39752507">next</a><span>|</span><label class="collapse" for="c-39753336">[-]</label><label class="expand" for="c-39753336">[3 more]</label></div><br/><div class="children"><div class="content">People need to stop focusing on “historical standards”. For better or worse, retail entering the market en masse (often with options trading) has created a new standard. The market over the last 10 years is the new normal, the smart people have worked this out and are making huge returns. TSLA at its peak had a WAY higher PE than NVDA does now, and NVDA is just as popular, with even stronger fundamentals.</div><br/><div id="39753811" class="c"><input type="checkbox" id="c-39753811" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39753336">parent</a><span>|</span><a href="#39752507">next</a><span>|</span><label class="collapse" for="c-39753811">[-]</label><label class="expand" for="c-39753811">[2 more]</label></div><br/><div class="children"><div class="content">For better or worse, human psychology doesn&#x27;t change that much - those historical standards very much apply today.<p>For us, older folks, we&#x27;ve seen this &#x27;new normal&#x27; several times already - it will end up as usual. There are no free lunches and as it appears to me that have not entered any permanently high plateau.<p>It&#x27;s even quite funny that ~100 years ago, we&#x27;ve had the previous big pandemic, and the biggest stock market crash. Epidemic of this century is done, now waiting for the second part !</div><br/><div id="39753815" class="c"><input type="checkbox" id="c-39753815" checked=""/><div class="controls bullet"><span class="by">solumunus</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39753811">parent</a><span>|</span><a href="#39752507">next</a><span>|</span><label class="collapse" for="c-39753815">[-]</label><label class="expand" for="c-39753815">[1 more]</label></div><br/><div class="children"><div class="content">No, that’s objectively wrong. You simply haven’t seen retail involvement in the market on this level before, not even close. It’s a new precedent, the market has changed.<p>To clarify, I’m not saying NVDA won’t crash from here or bear markets no longer exist. I’m simply saying that historic PE valuations are a poor metric for assessing the potential of a stock in todays market conditions.</div><br/></div></div></div></div></div></div></div></div><div id="39752507" class="c"><input type="checkbox" id="c-39752507" checked=""/><div class="controls bullet"><span class="by">dkrich</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39751207">parent</a><span>|</span><a href="#39751354">prev</a><span>|</span><a href="#39750258">next</a><span>|</span><label class="collapse" for="c-39752507">[-]</label><label class="expand" for="c-39752507">[1 more]</label></div><br/><div class="children"><div class="content">We are at a very unique time. The stock market has basically been in a bull market for 15 years with some very short-lived sell-offs along the way. During that time we&#x27;ve had some incredible innovations such as the iPhone, FANG stock dominance and unprecedented profitability for years.<p>You&#x27;ve also had three or four bona fide bubbles in that span, starting around 2017. First was Bitcoin along with the stock market as a whole (with Nvidia being one of the leading stocks of that bull market advance).<p>Then you had Tesla go parabolic and lots of people become rich. Then you had the whole post-COVID speculative mania.<p>The result of this has been extreme credulity by the average person. Today&#x27;s keynote is the perfect summation of this phenomenon. I saw multiple people who almost certainly couldn&#x27;t explain in any level of detail how Nvidia GPUs are used for training and inference, but rather rely on the secondhand talking points like CUDA that they&#x27;ve learned by watching Jim Cramer, watching this keynote with excitement and anticipating how much it would pump their shares or call options.<p>Contrast this with Steve Jobs keynotes from 15 years ago when Apple&#x27;s best days were well ahead of them. Most keynotes were questioned, in some cases even mocked. When Tesla stock broke out, many people couldn&#x27;t make sense of it. Ditto for cryptocurrencies. But now, taking their cues from those cycles, the average person wants to ride the next bubble to riches and is trying to catch the wave and so now believes every story attached to a rising asset price.<p>CEO&#x27;s aren&#x27;t blind to this and are using every opportunity to create favorable storylines. The leadup to a keynote like this carries with it an enormous amount of pressure to deliver. Hence a company like Nvidia leaning into generative artwork and straight up made up storylines like robot development.<p>At the end of the day, I&#x27;m afraid that there likely isn&#x27;t all that much substance and the evidence is beginning to pile up that the megacap tech stocks have run out of ideas which is why they are laying off people en masse and appealing to the AI hype cycle to carry their stocks higher.<p>Consider that Nvidia has gone up 8x- 800%!- in just over a year. The cycles are moving faster and faster. I remember just a year ago when lots of people said Nvidia at $250 was insane. Now here we are with the stock at more than three times that level and most people are calling it cheap. The stock market seems to have in certain areas like semis, completely disconnected from the fundamentals and taken flight. Yes, Nvidia earnings have grown. But understand that this is all part of a positive feedback loop where tech CEO&#x27;s are pressured by their competitors and shareholders to show that they are investing in AI. Thus they all talk about it on their earnings calls and spend massively. All of their stocks rise in unison as you have a market that increasingly looks like its chasing momentum stock trends up. Nvidia&#x27;s moves of late have almost nothing to do with any fundamental developments in the company. It has been routinely trading upwards of $45 billion a day. The Friday before last that number was over $100 billion. These are absolutely insane figures. Compare that to Microsoft, the largest company by market cap in the world, which trades on average around $8 billion per day.<p>I think this is generally how bull markets end and I think we may be actually forming the top of the great bull market for the megacaps that began around 2010 but really hit its stride starting in 2017.</div><br/></div></div></div></div><div id="39750258" class="c"><input type="checkbox" id="c-39750258" checked=""/><div class="controls bullet"><span class="by">costcofries</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750151">parent</a><span>|</span><a href="#39751207">prev</a><span>|</span><a href="#39750337">next</a><span>|</span><label class="collapse" for="c-39750258">[-]</label><label class="expand" for="c-39750258">[36 more]</label></div><br/><div class="children"><div class="content">Tell me more about why you believe their stock is hilariously overvalued.</div><br/><div id="39750436" class="c"><input type="checkbox" id="c-39750436" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750258">parent</a><span>|</span><a href="#39750344">next</a><span>|</span><label class="collapse" for="c-39750436">[-]</label><label class="expand" for="c-39750436">[2 more]</label></div><br/><div class="children"><div class="content">Their market cap is 2.2T $.<p>In the past year, they had a revenue of 60B $ and net income of 30B $. Absolutely amazing numbers, I agree. The year before they had a revenue of 30B $ and a net income of 4.5B $ - and it was a rather good year. What happens next of course depend of how you judge the situation - was it a peak hype demand ? Will it stabilize now ? Grow at current extraordinary rates ?<p>Scenario 1 - margins get back to normal due to hype going down, competition improving etc - in this case the company is worth at best ~200B $ - or 1&#x2F;10 of what it is now.<p>Scenario 2 - they maintain current revenue and the exceptional margins - the company would be worth ~1T - or 1&#x2F;2 of what it is now.<p>Scenario 3 - they current growth rate (based on past 12 months) continue for ~5 years. This is the case the company is worth ~2T $.<p>But they are in a business where most money come from a handful of customers, all of which are working on similar chips - and given the sums in play now, the incentives are *very* strong.<p>My opinion, is that the company is already priced for perfection - basically the current price reflects the perfect scenario. I struggle to see any upside, unless we have AGI in the next 5 years and it decides it can only run on Nvidia chips.<p>All of this is akin to Tesla in the past years. They grew from a small startup to a medium car maker - the % growth rate was huge of course - an amazing achievement in itself. But people projected that the % growth rate would continue - and the stock was priced accordingly. Reality is catching up on Tesla, even if some projections are still absolutely crazy.</div><br/><div id="39752561" class="c"><input type="checkbox" id="c-39752561" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750436">parent</a><span>|</span><a href="#39750344">next</a><span>|</span><label class="collapse" for="c-39752561">[-]</label><label class="expand" for="c-39752561">[1 more]</label></div><br/><div class="children"><div class="content">It does no good to design similar or even superior chips if you can&#x27;t get them fabbed.  How much of the world&#x27;s fab capacity has Nvidia already reserved?</div><br/></div></div></div></div><div id="39750344" class="c"><input type="checkbox" id="c-39750344" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750258">parent</a><span>|</span><a href="#39750436">prev</a><span>|</span><a href="#39750373">next</a><span>|</span><label class="collapse" for="c-39750344">[-]</label><label class="expand" for="c-39750344">[14 more]</label></div><br/><div class="children"><div class="content">They are priced as if they are the only ones who are capable of creating chips that can crunch LLM algos. But AMD, Google, Intel, and even Apple are also capable.<p>Apple is in talks with Google to bring Gemini to the iPhone, and it will obviously also be on android phones. So almost every phone on earth is poised to be using Gemini in the near future, and Gemini runs entirely on Google&#x27;s own custom hardware (which is at parity or better than nVidia&#x27;s offerings anyway).</div><br/><div id="39750444" class="c"><input type="checkbox" id="c-39750444" checked=""/><div class="controls bullet"><span class="by">jerf</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750344">parent</a><span>|</span><a href="#39750621">next</a><span>|</span><label class="collapse" for="c-39750444">[-]</label><label class="expand" for="c-39750444">[10 more]</label></div><br/><div class="children"><div class="content">This seems as good a place as any to be Corrected by the Internet, so... correct me if I&#x27;m wrong.<p>Making a graphics chip that is as good as Nvidia: Very difficult. Huge moat, huge effort, lots of barriers, lots of APIs, lot of experience, lots of decades of experience to overcome.<p>Making something that can run a NN: Much, much easier. I&#x27;d guess, start-up level feasible. The math is much simpler. There&#x27;s a lot of it, but my biggest concern would be less about pulling it off and more around whether my custom hardware is still the correct custom hardware by the time it is released. You&#x27;d think you could even eke out a bit of a performance advantage in not having all the other graphics stuff around. LLMs in their current state are characterized by vast swathes of input data and unbelievably repetitive number crunching, not complicated silicon architectures and decades-refined algorithms. (I mean, the algorithms are decades refined, but they&#x27;re still simple as programs go.)<p>I understand nVidia&#x27;s graphics moat. I do not understand the moat implied by their stock valuation, that as you say, they are the only people who will ever be able to build AI hardware. That doesn&#x27;t seem remotely true.<p>So... correct me Internet. Explain why nVidia has persistent advantages in the specific field of neural nets that can not be overcome. I&#x27;m seriously listening, because I&#x27;m curious; this is a deliberate Cunningham&#x27;s Law invocation, not me speaking from authority.</div><br/><div id="39750543" class="c"><input type="checkbox" id="c-39750543" checked=""/><div class="controls bullet"><span class="by">smallmancontrov</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750444">parent</a><span>|</span><a href="#39751210">next</a><span>|</span><label class="collapse" for="c-39750543">[-]</label><label class="expand" for="c-39750543">[2 more]</label></div><br/><div class="children"><div class="content">I agree with you, but let me devil&#x27;s advocate.<p>After 10 years of pretending to care about compute, AMD has filled the industry with burned-once experts who, when weighing nvidia against competitors, instinctively include &quot;likely boondoggle&quot; against every competitor&#x27;s quote because they&#x27;ve seen it happen, possibly several times. Combine this with nvidia&#x27;s deep experience and and huge rich-get-richer R&amp;D budget keeping them always one or two architecture and software steps ahead, like it did in graphics, and their rich-get-richer TSMC budget buying them a step ahead in hardware, and you have a scenario where it continues makes sense to pay the green tax for the next generation or three. Red&#x2F;blue&#x2F;other rebels get zinged and join team &quot;just pay the green tax.&quot; NV continues to dominate. Competitors go green with envy, as was fortold.</div><br/><div id="39750693" class="c"><input type="checkbox" id="c-39750693" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750543">parent</a><span>|</span><a href="#39751210">next</a><span>|</span><label class="collapse" for="c-39750693">[-]</label><label class="expand" for="c-39750693">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  burned-once experts<p>More like burned 2x &#x2F; 3x &#x2F; 4x of this time it&#x27;s different people.<p>Looking at you Intel</div><br/></div></div></div></div><div id="39751210" class="c"><input type="checkbox" id="c-39751210" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750444">parent</a><span>|</span><a href="#39750543">prev</a><span>|</span><a href="#39750690">next</a><span>|</span><label class="collapse" for="c-39751210">[-]</label><label class="expand" for="c-39751210">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So... correct me Internet. Explain why nVidia has persistent advantages in the specific field of neural nets that can not be overcome. I&#x27;m seriously listening, because I&#x27;m curious; this is a deliberate Cunningham&#x27;s Law invocation, not me speaking from authority.<p>To become a person who writes driver infrastructure for this sort of thing, you need to be a smart person who commits, probably, several of their most productive years to becoming an expert in a particular niche skillset. This only makes sense if you get a job somewhere that has a proven commitment of taking driver work seriously and rewarding it over multiple years.<p>NVidia is the only company in history that has ever written non-awful drivers, and therefore it&#x27;s not so implausible to believe that it might be the only company that can ever hire people who write non-awful drivers, and will continue to be the only company that can write non-awful drivers.</div><br/></div></div><div id="39750690" class="c"><input type="checkbox" id="c-39750690" checked=""/><div class="controls bullet"><span class="by">bgnn</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750444">parent</a><span>|</span><a href="#39751210">prev</a><span>|</span><a href="#39753351">next</a><span>|</span><label class="collapse" for="c-39750690">[-]</label><label class="expand" for="c-39750690">[1 more]</label></div><br/><div class="children"><div class="content">CUDA is&#x2F;was their biggest advantage to be honest, not the HW. They saw the demand to super high-end GPUs driven by Bitcoin mining craze thanks to CUDA, and it transitioned gracefully to AI&#x2F;ML workloads. Google was much more ahead to see the need and develop TPUs for example.<p>I don&#x27;t think they have a crazy advantage HW wise. Couple of start-ups are able to achieve this. If SW infrastracture end is standardized, we will have a more level playground.</div><br/></div></div><div id="39753351" class="c"><input type="checkbox" id="c-39753351" checked=""/><div class="controls bullet"><span class="by">__mharrison__</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750444">parent</a><span>|</span><a href="#39750690">prev</a><span>|</span><a href="#39750785">next</a><span>|</span><label class="collapse" for="c-39753351">[-]</label><label class="expand" for="c-39753351">[1 more]</label></div><br/><div class="children"><div class="content">Anecdata... one of the folks sitting in front of me at a session at GTC claimed the be an AMD employee who also claimed to previously work on cuda. He seemed skeptical that AMD would pull this off. This is the sort of fun stuff that you hear at a conference and aren&#x27;t sure how much of it is just technical bragging&#x2F;oneupmanship.</div><br/></div></div><div id="39750785" class="c"><input type="checkbox" id="c-39750785" checked=""/><div class="controls bullet"><span class="by">elorant</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750444">parent</a><span>|</span><a href="#39753351">prev</a><span>|</span><a href="#39753814">next</a><span>|</span><label class="collapse" for="c-39750785">[-]</label><label class="expand" for="c-39750785">[3 more]</label></div><br/><div class="children"><div class="content">CUDA is a big reason for their moat. And that&#x27;s not something you can build in a couple of years no matter how money you can throw on it.<p>Without CUDA you have a chip that runs on premise without anyone having a clue how good that is which is supposedly what Google does. Your only offering is cloud services. As big as this is, corporations would want to build their own datacenters.</div><br/><div id="39751027" class="c"><input type="checkbox" id="c-39751027" checked=""/><div class="controls bullet"><span class="by">sottol</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750785">parent</a><span>|</span><a href="#39751822">next</a><span>|</span><label class="collapse" for="c-39751027">[-]</label><label class="expand" for="c-39751027">[1 more]</label></div><br/><div class="children"><div class="content">Sure, CUDA has a lot of highly optimized utilities baked-in (CUDNN and the likes) and maybe more importantly, implementors have a lot of experience with it but afaict everyone is working on their own HAL&#x2F;compiler and not using CUDA directly to implement the actual models. It&#x27;s part of the HAL&#x2F;framework. You can probably port any of these frameworks to a new hardware platform with a few man-years worth of work imo if you can spare the manpower.<p>I think nobody had the time to port any of these architectures away from CUDA because:
* the leaders want to maintain their lead and everyone needs to catch up asap so no time to waste,
* and progress was _super_ fast so doubly no time to waste,
* there was&#x2F;is plenty of money that buys some perceived value in maintaining the lead or catching up.<p>But imo:
1. progress has slowed a bit, maybe there&#x27;s time to explore alternatives,
2. nvidia GPUs are pretty hard to come by, switching vendors may actually be a competitive advantage (if performance&#x2F;price pans out and you can actually buy the hardware now as opposed to later).<p>In terms of ML &quot;compilers&quot;&#x2F;frameworks, afaik there&#x27;s:<p>* Google JAX&#x2F;Tensorflow XLA&#x2F;MLIR,
* OpenAI Triton,
* Meta Glow,
* Apple PyTorch+Metal fork.</div><br/></div></div><div id="39751822" class="c"><input type="checkbox" id="c-39751822" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750785">parent</a><span>|</span><a href="#39751027">prev</a><span>|</span><a href="#39753814">next</a><span>|</span><label class="collapse" for="c-39751822">[-]</label><label class="expand" for="c-39751822">[1 more]</label></div><br/><div class="children"><div class="content">&gt; CUDA is a big reason for their moat.<p>Zen 1 showed that absolute performance is not the end-all metric ( Zen lost on single-core performance vs Intel). A <i>lot</i> of people care for bang-for-buck metric. If AMD can squeak out good-enough drivers for cards with good-enough performance for a TCO[1]  significantly lower than NVidia, they break Nvidia&#x27;s current positive feedback cycle.<p>1. Initial cost and cooling - I imagine for AI data center usage, opex exceeds capex.</div><br/></div></div></div></div><div id="39753814" class="c"><input type="checkbox" id="c-39753814" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750444">parent</a><span>|</span><a href="#39750785">prev</a><span>|</span><a href="#39750621">next</a><span>|</span><label class="collapse" for="c-39753814">[-]</label><label class="expand" for="c-39753814">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t. If NVIDIA doesn&#x27;t work with SK Hynix to integrate PIM GDDR into their products they are going to die, because processing in memory is already a thing and it is faster and more scalable than GPU based inference.</div><br/></div></div></div></div><div id="39750621" class="c"><input type="checkbox" id="c-39750621" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750344">parent</a><span>|</span><a href="#39750444">prev</a><span>|</span><a href="#39750373">next</a><span>|</span><label class="collapse" for="c-39750621">[-]</label><label class="expand" for="c-39750621">[3 more]</label></div><br/><div class="children"><div class="content">Good luck with that. Gemini Advanced is simply unusable right now....It&#x27;s so bad its hard to believe nobody picked up on that yet.</div><br/><div id="39751179" class="c"><input type="checkbox" id="c-39751179" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750621">parent</a><span>|</span><a href="#39750373">next</a><span>|</span><label class="collapse" for="c-39751179">[-]</label><label class="expand" for="c-39751179">[2 more]</label></div><br/><div class="children"><div class="content">Go to Gemini Advanced and try a common programming task in Parallel with Claude and ChatGPT4. Within 2 prompts Claude and ChatGPT4 will give nice working code you can use as a basis while Gemini Advanced will ignore your prompts, provide partial code and quickly tell you it can do more, until you tell it exactly what you want. It will go from looking usable to stuck on &quot;I can do A or I can do B you tell me what you prefer hell&quot; in less than  2 or 3 prompts...Unusable. And I say that as paying customer that will soon cancel the service.</div><br/><div id="39751258" class="c"><input type="checkbox" id="c-39751258" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39751179">parent</a><span>|</span><a href="#39750373">next</a><span>|</span><label class="collapse" for="c-39751258">[-]</label><label class="expand" for="c-39751258">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re not wrong, but it wouldn&#x27;t be surprising if Google irons things out with a few more updates. The point is that it would be foolish to write off Gemini right now, and Gemini is totally independent of Nvidia&#x27;s dominance.</div><br/></div></div></div></div></div></div></div></div><div id="39750373" class="c"><input type="checkbox" id="c-39750373" checked=""/><div class="controls bullet"><span class="by">swalsh</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750258">parent</a><span>|</span><a href="#39750344">prev</a><span>|</span><a href="#39750433">next</a><span>|</span><label class="collapse" for="c-39750373">[-]</label><label class="expand" for="c-39750373">[2 more]</label></div><br/><div class="children"><div class="content">72 P&#x2F;E ratio while they have a mere monopoly on one the most valuable resource in the world.<p>Competition WILL come.  Maybe it&#x27;s Groq, maybe AMD, maybe Cerebras.  Maybe there&#x27;s a stealth startup out there.  Point is, they&#x27;re going to be challenged soon.</div><br/><div id="39750697" class="c"><input type="checkbox" id="c-39750697" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750373">parent</a><span>|</span><a href="#39750433">next</a><span>|</span><label class="collapse" for="c-39750697">[-]</label><label class="expand" for="c-39750697">[1 more]</label></div><br/><div class="children"><div class="content">You and what fab?<p>It&#x27;s almost impossible to manufacture at scale with good yields and leading edge fabs are almost all bought out.</div><br/></div></div></div></div><div id="39750433" class="c"><input type="checkbox" id="c-39750433" checked=""/><div class="controls bullet"><span class="by">smallmancontrov</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750258">parent</a><span>|</span><a href="#39750373">prev</a><span>|</span><a href="#39750357">next</a><span>|</span><label class="collapse" for="c-39750433">[-]</label><label class="expand" for="c-39750433">[7 more]</label></div><br/><div class="children"><div class="content">No moat.<p>Yes, CUDA, but CUDA is maaaaaybe a few tens of billion USD deep and a few (more) years wide. When the rest of the industry saw compute as a vanity market, that was sufficient. Now, it&#x27;s a matter of time before margins go to, uhhh, less than 90%.<p>Does that make shorting a good idea? I wouldn&#x27;t count on it. The market can always remain irrational longer than you can remain solvent.</div><br/><div id="39751843" class="c"><input type="checkbox" id="c-39751843" checked=""/><div class="controls bullet"><span class="by">yen223</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750433">parent</a><span>|</span><a href="#39750752">next</a><span>|</span><label class="collapse" for="c-39751843">[-]</label><label class="expand" for="c-39751843">[1 more]</label></div><br/><div class="children"><div class="content">I used to think that CUDA was something that would get commoditised real fast. How hard could building it be?<p>However, given that the nearest competitor AMD has basically given up on building a CUDA alternative, despite the fact that this could grow the company by literal trillions of dollars, I suspect the CUDA moat is much bigger than I give it credit for.</div><br/></div></div><div id="39750752" class="c"><input type="checkbox" id="c-39750752" checked=""/><div class="controls bullet"><span class="by">tiahura</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750433">parent</a><span>|</span><a href="#39751843">prev</a><span>|</span><a href="#39750742">next</a><span>|</span><label class="collapse" for="c-39750752">[-]</label><label class="expand" for="c-39750752">[4 more]</label></div><br/><div class="children"><div class="content">And MS and everyone else have plenty of interest in helping AMD commodify CUDA compatibility.</div><br/><div id="39751368" class="c"><input type="checkbox" id="c-39751368" checked=""/><div class="controls bullet"><span class="by">stefan_</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750752">parent</a><span>|</span><a href="#39750742">next</a><span>|</span><label class="collapse" for="c-39751368">[-]</label><label class="expand" for="c-39751368">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s so weird it&#x27;s taking them so long, because as far as anyone can tell AMD is mostly competent enough to make GPUs within some percentage points of Nvidia, the &quot;breadth of complexity&quot; in what these things do at the end of the day is ... rather underwhelming, the software stack may appear to be changing all the time but is also distinctly JavaScript-frotend-esque... is  there an insider that knows what the holdup is? Is AMD just averse to making a ton of money?<p>At this point AMD investors should be rebelling, it&#x27;s pissing money out there but they are not getting wet, and management might have doubled the stock price but that&#x27;s little consolation if &quot;order of magnitude&quot; is what could have been.</div><br/><div id="39752088" class="c"><input type="checkbox" id="c-39752088" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39751368">parent</a><span>|</span><a href="#39752481">next</a><span>|</span><label class="collapse" for="c-39752088">[-]</label><label class="expand" for="c-39752088">[1 more]</label></div><br/><div class="children"><div class="content">&gt; At this point AMD investors should be rebelling<p>Looking at the chart for $AMD over the past 5 years gives plenty od reasons to be happy, and no reason to rebel. A rational AMD investor should not be Jonesing Nvidia&#x27;s catching lightning in a bottle via crypto + AI. The Transformers paper was published a few months <i>before</i> AMD released Zen 1 chips - they did not have a lot of money for GPU R&amp;D then.<p>The timing of the LLM-craze was very fortuitous for Nvidia.</div><br/></div></div><div id="39752481" class="c"><input type="checkbox" id="c-39752481" checked=""/><div class="controls bullet"><span class="by">wkat4242</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39751368">parent</a><span>|</span><a href="#39752088">prev</a><span>|</span><a href="#39750742">next</a><span>|</span><label class="collapse" for="c-39752481">[-]</label><label class="expand" for="c-39752481">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s kinda great for those of us wanting GPUs though. Nvidia might eventually decide it&#x27;s not worth their time to bother with.</div><br/></div></div></div></div></div></div><div id="39750742" class="c"><input type="checkbox" id="c-39750742" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750433">parent</a><span>|</span><a href="#39750752">prev</a><span>|</span><a href="#39750357">next</a><span>|</span><label class="collapse" for="c-39750742">[-]</label><label class="expand" for="c-39750742">[1 more]</label></div><br/><div class="children"><div class="content">They also bought infiniband which has played a big role in being the best at clustering, though Google&#x27;s TPU reconfigurable topology stuff seems really cool too.<p>Tesla went after them with Dojo and has still ended up splurging on big H100 clusters.</div><br/></div></div></div></div><div id="39750357" class="c"><input type="checkbox" id="c-39750357" checked=""/><div class="controls bullet"><span class="by">xyst</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750258">parent</a><span>|</span><a href="#39750433">prev</a><span>|</span><a href="#39750305">next</a><span>|</span><label class="collapse" for="c-39750357">[-]</label><label class="expand" for="c-39750357">[9 more]</label></div><br/><div class="children"><div class="content">Because their stock value is highly coupled with crypto mining and AI craze.<p>The move from PoW to PoS for most crypto networks in combination with bust of ‘22. NVDA slid down in value.<p>OpenAI debuts ChatGPT in late 2022 and now it’s suddenly bumping in price as the hype and rush for GPUs from companies of all types buys up their stock of GPUs. Demand is far outpacing the supply. Nvda can’t keep up.<p>Thus, share price is brittle. Competition in the GPU market is dominantly owned by Nvidia. That can change, but so far openai loves using nvidia for some reason.</div><br/><div id="39750511" class="c"><input type="checkbox" id="c-39750511" checked=""/><div class="controls bullet"><span class="by">ryandrake</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750357">parent</a><span>|</span><a href="#39750305">next</a><span>|</span><label class="collapse" for="c-39750511">[-]</label><label class="expand" for="c-39750511">[8 more]</label></div><br/><div class="children"><div class="content">If you are a true believer that AI is not a craze, then the stock can only go up from here. If you think there is a chance that everyone gets bored of AI and moves on to some other fad that is not in Nvidia’s wheelhouse, then it’s probably down from here. I’m staying out of this bet: don’t have the stomach for it.</div><br/><div id="39751613" class="c"><input type="checkbox" id="c-39751613" checked=""/><div class="controls bullet"><span class="by">throw0101b</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750511">parent</a><span>|</span><a href="#39750790">next</a><span>|</span><label class="collapse" for="c-39751613">[-]</label><label class="expand" for="c-39751613">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>If you think there is a chance that everyone gets bored of AI and moves on to some other fad that is not in Nvidia’s wheelhouse, then it’s probably down from here.</i><p>You may wish to look at history to see how things can work out: Cisco had a P&#x2F;E ratio of 148 in 1999:<p>* <a href="https:&#x2F;&#x2F;www.dividendgrowthinvestor.com&#x2F;2022&#x2F;09&#x2F;cisco-systems-csco-lessons-from-dot-com.html" rel="nofollow">https:&#x2F;&#x2F;www.dividendgrowthinvestor.com&#x2F;2022&#x2F;09&#x2F;cisco-systems...</a><p>The share price tanked, but that does not mean that people got bored of the Internet and the need for routers and switches. QCOM had a P&#x2F;E of 166: did people decide that mobile communications was a fad?<p>The connection between technological revolutions and financial bubbles dates back to (at least) Canal Mania:<p>* <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Canal_Mania" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Canal_Mania</a><p>* <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Technological_Revolutions_and_Financial_Capital" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Technological_Revolutions_and_...</a><p>It is possible for <i>both</i> AI to be a big thing <i>and</i> for NVDA to drop.</div><br/><div id="39753026" class="c"><input type="checkbox" id="c-39753026" checked=""/><div class="controls bullet"><span class="by">oblio</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39751613">parent</a><span>|</span><a href="#39750790">next</a><span>|</span><label class="collapse" for="c-39753026">[-]</label><label class="expand" for="c-39753026">[1 more]</label></div><br/><div class="children"><div class="content">Regarding bubbles:<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;South_Sea_Company" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;South_Sea_Company</a><p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Tulip_mania" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Tulip_mania</a></div><br/></div></div></div></div><div id="39750790" class="c"><input type="checkbox" id="c-39750790" checked=""/><div class="controls bullet"><span class="by">AlexandrB</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750511">parent</a><span>|</span><a href="#39751613">prev</a><span>|</span><a href="#39750791">next</a><span>|</span><label class="collapse" for="c-39750790">[-]</label><label class="expand" for="c-39750790">[4 more]</label></div><br/><div class="children"><div class="content">There&#x27;s another case for pessimism as well: cost. It&#x27;s possible that many AI applications aren&#x27;t worth the money required for the extra compute. AI-enhanced search comes to mind here: how is Microsoft going to monetize users of Copilot in Bing to justify the extra cost? Right now a lot of this stuff is heavily subsidized by VCs or the MSFTs of the world, but when it comes time to make a profit we&#x27;ll see what actually sticks around.</div><br/><div id="39752391" class="c"><input type="checkbox" id="c-39752391" checked=""/><div class="controls bullet"><span class="by">_factor</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750790">parent</a><span>|</span><a href="#39751088">next</a><span>|</span><label class="collapse" for="c-39752391">[-]</label><label class="expand" for="c-39752391">[2 more]</label></div><br/><div class="children"><div class="content">Better question: why does a simple search for “What color is a labrador retriever” require any compute time when the answer can be cached?  This is a simple example, but 90% of my searches don’t require an llm to process a simple question.</div><br/><div id="39753739" class="c"><input type="checkbox" id="c-39753739" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39752391">parent</a><span>|</span><a href="#39751088">next</a><span>|</span><label class="collapse" for="c-39753739">[-]</label><label class="expand" for="c-39753739">[1 more]</label></div><br/><div class="children"><div class="content">One time I came across a git repo that let me download a gigabyte of prime numbers and I thought to myself, is that more or less efficient than me running a program locally to generate a gigabyte of prime numbers?<p>The compute for a direct answer like that is fractions of a penny, it might be better to create answers on the fly than store an index of every question anyone has asked (well, that&#x27;s essentially what the weights are after all)</div><br/></div></div></div></div><div id="39751088" class="c"><input type="checkbox" id="c-39751088" checked=""/><div class="controls bullet"><span class="by">jacobr1</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750790">parent</a><span>|</span><a href="#39752391">prev</a><span>|</span><a href="#39750791">next</a><span>|</span><label class="collapse" for="c-39751088">[-]</label><label class="expand" for="c-39751088">[1 more]</label></div><br/><div class="children"><div class="content">This seems true as far as incentives go. But how much of that cost driver will be due to efficiencies driven by companies like NVIDIA? They seem well poised to benefit from a lot of the increased (non-hype) use of AI. Seems like we spent a decade or more of stalled CPU performance gains chasing better energy efficiency in the data center, same story could play out here.</div><br/></div></div></div></div><div id="39750791" class="c"><input type="checkbox" id="c-39750791" checked=""/><div class="controls bullet"><span class="by">partiallypro</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750511">parent</a><span>|</span><a href="#39750790">prev</a><span>|</span><a href="#39750305">next</a><span>|</span><label class="collapse" for="c-39750791">[-]</label><label class="expand" for="c-39750791">[1 more]</label></div><br/><div class="children"><div class="content">AI is obviously the future, though current iterations will probably die at some point. but the dot com bubble ended up with the internet being more pervasive than may have even been thought of at the time, but regardless even the likes of Amazon&#x27;s stock went bust before it recollected itself. Not a perfect comparison given Nvidia has really good revenue growth, but the point still stands.</div><br/></div></div></div></div></div></div><div id="39750305" class="c"><input type="checkbox" id="c-39750305" checked=""/><div class="controls bullet"><span class="by">Takennickname</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750258">parent</a><span>|</span><a href="#39750357">prev</a><span>|</span><a href="#39750337">next</a><span>|</span><label class="collapse" for="c-39750305">[-]</label><label class="expand" for="c-39750305">[1 more]</label></div><br/><div class="children"><div class="content">Because he missed the train. My guess.</div><br/></div></div></div></div></div></div><div id="39750337" class="c"><input type="checkbox" id="c-39750337" checked=""/><div class="controls bullet"><span class="by">swalsh</span><span>|</span><a href="#39749849">parent</a><span>|</span><a href="#39750151">prev</a><span>|</span><a href="#39752364">next</a><span>|</span><label class="collapse" for="c-39750337">[-]</label><label class="expand" for="c-39750337">[1 more]</label></div><br/><div class="children"><div class="content">At 2 trillion, it&#x27;s all baked in already</div><br/></div></div><div id="39752364" class="c"><input type="checkbox" id="c-39752364" checked=""/><div class="controls bullet"><span class="by">_factor</span><span>|</span><a href="#39749849">parent</a><span>|</span><a href="#39750337">prev</a><span>|</span><a href="#39749898">next</a><span>|</span><label class="collapse" for="c-39752364">[-]</label><label class="expand" for="c-39752364">[1 more]</label></div><br/><div class="children"><div class="content">Nvidia is no secret.  Whatever hidden value is in the stock, is likely already represented.</div><br/></div></div><div id="39749891" class="c"><input type="checkbox" id="c-39749891" checked=""/><div class="controls bullet"><span class="by">synergy20</span><span>|</span><a href="#39749849">parent</a><span>|</span><a href="#39749898">prev</a><span>|</span><a href="#39750169">next</a><span>|</span><label class="collapse" for="c-39749891">[-]</label><label class="expand" for="c-39749891">[1 more]</label></div><br/><div class="children"><div class="content">not only that, it lost steam during the day, maybe it was overheated too much and no more news can pump it up any further.</div><br/></div></div><div id="39750169" class="c"><input type="checkbox" id="c-39750169" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#39749849">parent</a><span>|</span><a href="#39749891">prev</a><span>|</span><a href="#39752173">next</a><span>|</span><label class="collapse" for="c-39750169">[-]</label><label class="expand" for="c-39750169">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A lot of people were hoping for a big pop on some big development<p>They are waiting for earnings projections for such a pop since right now it is extremely overbought and struggling to move past &gt;$1,000 per share.<p>For now, Microsoft and OpenAI will use these chips, but in the long term they are just looking at this and plotting to build their own chips and reducing their dependence on Nvidia and will be ready to switch once their contracts have run out.</div><br/></div></div><div id="39749901" class="c"><input type="checkbox" id="c-39749901" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#39749849">parent</a><span>|</span><a href="#39752173">prev</a><span>|</span><a href="#39750096">next</a><span>|</span><label class="collapse" for="c-39749901">[-]</label><label class="expand" for="c-39749901">[1 more]</label></div><br/><div class="children"><div class="content">I imagine it’ll pop in the morning</div><br/></div></div><div id="39750096" class="c"><input type="checkbox" id="c-39750096" checked=""/><div class="controls bullet"><span class="by">dxbydt</span><span>|</span><a href="#39749849">parent</a><span>|</span><a href="#39749901">prev</a><span>|</span><a href="#39750664">next</a><span>|</span><label class="collapse" for="c-39750096">[-]</label><label class="expand" for="c-39750096">[6 more]</label></div><br/><div class="children"><div class="content">guy is messing it up bigtime and in real-time as well. sheesh. none of his jokes are landing. “we had 2 customers. we have more now”. long pause. screen behind him covered with logos of all his customers. pause. pause. finally applause.
ok on to the next tidbit.<p>whole conference has been proceeding like this now. look if you invite cramer and the wall street crowd, you should throw in some dollar figures. like - who is paying for all this. how much. and why. talk is entirely about token generation bandwidth, exaflops and petaflops, data parallel vs tensor parallel vs pipeline parallel - do you honestly think cramer knows the difference between an ml pipeline and an oil pipeline ?<p>i am watching this conf with my kid - proper GenZ member - who got up after 5 mins and said man who is this comedian, his jokes are so bad, and left :(</div><br/><div id="39750273" class="c"><input type="checkbox" id="c-39750273" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750096">parent</a><span>|</span><a href="#39750371">next</a><span>|</span><label class="collapse" for="c-39750273">[-]</label><label class="expand" for="c-39750273">[1 more]</label></div><br/><div class="children"><div class="content">Nah, wallstreet doesn’t understand what it’s looking at.<p>That’s fine, it’s a developer conference for a founder lead company that hasn’t reached the “stock price is the product” state.  He’s not trying to optimize the next 5 days of stock.<p>There’s a full ecosystem grab with Nim there, a new GPU that forces every major datacenter to adopt (or their competitors will massively increase their compute density)</div><br/></div></div><div id="39750371" class="c"><input type="checkbox" id="c-39750371" checked=""/><div class="controls bullet"><span class="by">smallmancontrov</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750096">parent</a><span>|</span><a href="#39750273">prev</a><span>|</span><a href="#39751102">next</a><span>|</span><label class="collapse" for="c-39750371">[-]</label><label class="expand" for="c-39750371">[1 more]</label></div><br/><div class="children"><div class="content">You might not like it, but this is what peak performance looks like.</div><br/></div></div><div id="39751102" class="c"><input type="checkbox" id="c-39751102" checked=""/><div class="controls bullet"><span class="by">Deasiomlo</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750096">parent</a><span>|</span><a href="#39750371">prev</a><span>|</span><a href="#39750274">next</a><span>|</span><label class="collapse" for="c-39751102">[-]</label><label class="expand" for="c-39751102">[1 more]</label></div><br/><div class="children"><div class="content">Why would a Gen z kid care about this conference?<p>It&#x27;s not a hipster event.<p>And the pauses are clearly his style of presenting. Having a artificial pause to tell the audience it would be a good time to react.<p>You clearly don&#x27;t like it, I don&#x27;t mind it.<p>But just to be clear: we see peak human ingenuity. This right now will be history on how we as humans build AGI, full human robots etc (in case we don&#x27;t nuke ourselves).<p>You can read the conference results easily at any it news portal.<p>There is no requirement from Nvidia entertaining you or your kid.</div><br/></div></div><div id="39750274" class="c"><input type="checkbox" id="c-39750274" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750096">parent</a><span>|</span><a href="#39751102">prev</a><span>|</span><a href="#39750352">next</a><span>|</span><label class="collapse" for="c-39750274">[-]</label><label class="expand" for="c-39750274">[1 more]</label></div><br/><div class="children"><div class="content">This is a developer&#x27;s conference, not a financial one.</div><br/></div></div><div id="39750352" class="c"><input type="checkbox" id="c-39750352" checked=""/><div class="controls bullet"><span class="by">Takennickname</span><span>|</span><a href="#39749849">root</a><span>|</span><a href="#39750096">parent</a><span>|</span><a href="#39750274">prev</a><span>|</span><a href="#39750664">next</a><span>|</span><label class="collapse" for="c-39750352">[-]</label><label class="expand" for="c-39750352">[1 more]</label></div><br/><div class="children"><div class="content">Cramer is an entertainer. Not a developer or an investor.</div><br/></div></div></div></div></div></div><div id="39750664" class="c"><input type="checkbox" id="c-39750664" checked=""/><div class="controls bullet"><span class="by">tamimio</span><span>|</span><a href="#39749849">prev</a><span>|</span><a href="#39752595">next</a><span>|</span><label class="collapse" for="c-39750664">[-]</label><label class="expand" for="c-39750664">[14 more]</label></div><br/><div class="children"><div class="content">I think at this point, they should stop making it video “cards” but rather video “stations”, a full tower station with power supply and one giant “card” inside with proper cooling, etc., might also justify the crazy prices anyway.</div><br/><div id="39750858" class="c"><input type="checkbox" id="c-39750858" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#39750664">parent</a><span>|</span><a href="#39750760">next</a><span>|</span><label class="collapse" for="c-39750858">[-]</label><label class="expand" for="c-39750858">[4 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;lambdalabs.com&#x2F;gpu-workstations&#x2F;vector" rel="nofollow">https:&#x2F;&#x2F;lambdalabs.com&#x2F;gpu-workstations&#x2F;vector</a></div><br/><div id="39751709" class="c"><input type="checkbox" id="c-39751709" checked=""/><div class="controls bullet"><span class="by">justinclift</span><span>|</span><a href="#39750664">root</a><span>|</span><a href="#39750858">parent</a><span>|</span><a href="#39753745">next</a><span>|</span><label class="collapse" for="c-39751709">[-]</label><label class="expand" for="c-39751709">[2 more]</label></div><br/><div class="children"><div class="content">Heh Heh Heh<p>&quot;Ultimate AI Workstation&quot;.  Pricing starts at US$83,549:<p><a href="https:&#x2F;&#x2F;shop.lambdalabs.com&#x2F;gpu-workstations&#x2F;vector&#x2F;customize" rel="nofollow">https:&#x2F;&#x2F;shop.lambdalabs.com&#x2F;gpu-workstations&#x2F;vector&#x2F;customiz...</a><p>Adding every option only adds $2,100 to the price too (totalling $85,649).  They should probably just include everything as standard. ;)</div><br/></div></div><div id="39753745" class="c"><input type="checkbox" id="c-39753745" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#39750664">root</a><span>|</span><a href="#39750858">parent</a><span>|</span><a href="#39751709">prev</a><span>|</span><a href="#39750760">next</a><span>|</span><label class="collapse" for="c-39753745">[-]</label><label class="expand" for="c-39753745">[1 more]</label></div><br/><div class="children"><div class="content">I love that &quot;we installed a working python environment for you&quot; is a front-page value-add</div><br/></div></div></div></div><div id="39750760" class="c"><input type="checkbox" id="c-39750760" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39750664">parent</a><span>|</span><a href="#39750858">prev</a><span>|</span><a href="#39751166">next</a><span>|</span><label class="collapse" for="c-39750760">[-]</label><label class="expand" for="c-39750760">[5 more]</label></div><br/><div class="children"><div class="content">Probably better to stick to the GPUs. Integration is a low margin game.</div><br/><div id="39750873" class="c"><input type="checkbox" id="c-39750873" checked=""/><div class="controls bullet"><span class="by">georgyo</span><span>|</span><a href="#39750664">root</a><span>|</span><a href="#39750760">parent</a><span>|</span><a href="#39750789">next</a><span>|</span><label class="collapse" for="c-39750873">[-]</label><label class="expand" for="c-39750873">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d prefer they stick to GPUs, but I think you&#x27;re over simplifying.<p>Dell proves that selling complete units is very profitable.<p>Apple shows that owning the entire stack is immensely profitable.<p>Nvidia already has significant hardware and software investment. They very well could fully integrate and grab larger slices of the pie.<p>In fact, Nvidia already has complete appliance like fully integrated machines. But enterprises like to install their own OS and run their own software stack. These appliances have not caught on, at least not yet.</div><br/><div id="39751680" class="c"><input type="checkbox" id="c-39751680" checked=""/><div class="controls bullet"><span class="by">zer00eyz</span><span>|</span><a href="#39750664">root</a><span>|</span><a href="#39750873">parent</a><span>|</span><a href="#39750789">next</a><span>|</span><label class="collapse" for="c-39751680">[-]</label><label class="expand" for="c-39751680">[2 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; Apple shows that owning the entire stack is immensely profitable.<p>Apple shows no such thing. Apple, sells pretty, reliable and safe. A car is a car, but apple is a sports car, or a saloon. Vertical integration is the way they chose to deliver that, and pretty and reliable are all normal people care about.<p>Nvidia is gonna have to think long and hard about the &quot;whole stack&quot;. 20 years ago they might have been able to pull a next, but right now anything that isnt LINUX is a rounding error, and they dont want to turn into SUN (no one at nividia is smart enough to make them the next sun).<p>Nvidia architecture + Nvidia os is not something that I see them pulling off for the datacenter.</div><br/><div id="39753377" class="c"><input type="checkbox" id="c-39753377" checked=""/><div class="controls bullet"><span class="by">__mharrison__</span><span>|</span><a href="#39750664">root</a><span>|</span><a href="#39751680">parent</a><span>|</span><a href="#39750789">next</a><span>|</span><label class="collapse" for="c-39753377">[-]</label><label class="expand" for="c-39753377">[1 more]</label></div><br/><div class="children"><div class="content">Nvidia is moving up the stack. They announced NIMs today. I liken it to Docker for AI.</div><br/></div></div></div></div></div></div><div id="39750789" class="c"><input type="checkbox" id="c-39750789" checked=""/><div class="controls bullet"><span class="by">caycep</span><span>|</span><a href="#39750664">root</a><span>|</span><a href="#39750760">parent</a><span>|</span><a href="#39750873">prev</a><span>|</span><a href="#39751166">next</a><span>|</span><label class="collapse" for="c-39750789">[-]</label><label class="expand" for="c-39750789">[1 more]</label></div><br/><div class="children"><div class="content">granted, at this point we plug the computer into the GPU, so it might not make a difference...</div><br/></div></div></div></div><div id="39751166" class="c"><input type="checkbox" id="c-39751166" checked=""/><div class="controls bullet"><span class="by">acchow</span><span>|</span><a href="#39750664">parent</a><span>|</span><a href="#39750760">prev</a><span>|</span><a href="#39751123">next</a><span>|</span><label class="collapse" for="c-39751166">[-]</label><label class="expand" for="c-39751166">[1 more]</label></div><br/><div class="children"><div class="content">That’s the DGX GB200 they announced today, with liquid cooling.</div><br/></div></div><div id="39751123" class="c"><input type="checkbox" id="c-39751123" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39750664">parent</a><span>|</span><a href="#39751166">prev</a><span>|</span><a href="#39750947">next</a><span>|</span><label class="collapse" for="c-39751123">[-]</label><label class="expand" for="c-39751123">[1 more]</label></div><br/><div class="children"><div class="content">SXM for desktop would be great but it won&#x27;t happen. The PC industry can&#x27;t even adopt things like 12VO.</div><br/></div></div><div id="39750947" class="c"><input type="checkbox" id="c-39750947" checked=""/><div class="controls bullet"><span class="by">ribosometronome</span><span>|</span><a href="#39750664">parent</a><span>|</span><a href="#39751123">prev</a><span>|</span><a href="#39750705">next</a><span>|</span><label class="collapse" for="c-39750947">[-]</label><label class="expand" for="c-39750947">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that just a computer? Or an eGPU, if it doesn&#x27;t contain the rest of the computer?</div><br/></div></div></div></div><div id="39752595" class="c"><input type="checkbox" id="c-39752595" checked=""/><div class="controls bullet"><span class="by">adamnemecek</span><span>|</span><a href="#39750664">prev</a><span>|</span><a href="#39749973">next</a><span>|</span><label class="collapse" for="c-39752595">[-]</label><label class="expand" for="c-39752595">[2 more]</label></div><br/><div class="children"><div class="content">Which Blackwell is it named after?</div><br/><div id="39752780" class="c"><input type="checkbox" id="c-39752780" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39752595">parent</a><span>|</span><a href="#39749973">next</a><span>|</span><label class="collapse" for="c-39752780">[-]</label><label class="expand" for="c-39752780">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;David_Blackwell" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;David_Blackwell</a></div><br/></div></div></div></div><div id="39749973" class="c"><input type="checkbox" id="c-39749973" checked=""/><div class="controls bullet"><span class="by">jairuhme</span><span>|</span><a href="#39752595">prev</a><span>|</span><a href="#39751507">next</a><span>|</span><label class="collapse" for="c-39749973">[-]</label><label class="expand" for="c-39749973">[17 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t listened to Jensen speak before, but am I the only one who thought the presentation wasn&#x27;t very polished?  Not a knock on anything he has accomplished, just an observation that sorta surprised me</div><br/><div id="39750085" class="c"><input type="checkbox" id="c-39750085" checked=""/><div class="controls bullet"><span class="by">azeirah</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750421">next</a><span>|</span><label class="collapse" for="c-39750085">[-]</label><label class="expand" for="c-39750085">[1 more]</label></div><br/><div class="children"><div class="content">He said he didn&#x27;t rehearse well. I think it makes him come across very genuinely, not some dumb hyperpolished corporate blabla</div><br/></div></div><div id="39750421" class="c"><input type="checkbox" id="c-39750421" checked=""/><div class="controls bullet"><span class="by">swalsh</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750085">prev</a><span>|</span><a href="#39750656">next</a><span>|</span><label class="collapse" for="c-39750421">[-]</label><label class="expand" for="c-39750421">[1 more]</label></div><br/><div class="children"><div class="content">He&#x27;s selling water in a desert, kind of doesn&#x27;t matter how polished his presentation is.</div><br/></div></div><div id="39750656" class="c"><input type="checkbox" id="c-39750656" checked=""/><div class="controls bullet"><span class="by">erupt7893</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750421">prev</a><span>|</span><a href="#39751760">next</a><span>|</span><label class="collapse" for="c-39750656">[-]</label><label class="expand" for="c-39750656">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been watching his keynotes for as long as I can remember, this is how it&#x27;s always been</div><br/></div></div><div id="39751760" class="c"><input type="checkbox" id="c-39751760" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750656">prev</a><span>|</span><a href="#39750450">next</a><span>|</span><label class="collapse" for="c-39751760">[-]</label><label class="expand" for="c-39751760">[1 more]</label></div><br/><div class="children"><div class="content">Previous ones have been similar. Awkward “you may clap now” pauses etc.<p>Don’t think anyone cares as long as the company keeps getting the bets right</div><br/></div></div><div id="39750450" class="c"><input type="checkbox" id="c-39750450" checked=""/><div class="controls bullet"><span class="by">cableshaft</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39751760">prev</a><span>|</span><a href="#39750076">next</a><span>|</span><label class="collapse" for="c-39750450">[-]</label><label class="expand" for="c-39750450">[1 more]</label></div><br/><div class="children"><div class="content">The beginning in particular seemed pretty rough, but he seemed to mostly get into a groove about halfway into it. At least he started talking a lot smoother around then.</div><br/></div></div><div id="39750076" class="c"><input type="checkbox" id="c-39750076" checked=""/><div class="controls bullet"><span class="by">jefozabuss</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750450">prev</a><span>|</span><a href="#39750817">next</a><span>|</span><label class="collapse" for="c-39750076">[-]</label><label class="expand" for="c-39750076">[1 more]</label></div><br/><div class="children"><div class="content">When he had that slide up with generating everything I was kind of expecting that he&#x27;d say this whole keynote is generated including him. That&#x27;d have been crazy.</div><br/></div></div><div id="39750817" class="c"><input type="checkbox" id="c-39750817" checked=""/><div class="controls bullet"><span class="by">caycep</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750076">prev</a><span>|</span><a href="#39750074">next</a><span>|</span><label class="collapse" for="c-39750817">[-]</label><label class="expand" for="c-39750817">[1 more]</label></div><br/><div class="children"><div class="content">I remember his opening line at NEURIPS 2017, to an audience of grad students and postdocs,  &quot;only Nvidia would unveil their most expensive product to an audience who&#x27;s completely broke&quot;<p>Then he went into a comedic monologue about GANS.  But hey, at least that meant that the CEO was reading the actual conference proceedings...</div><br/></div></div><div id="39750074" class="c"><input type="checkbox" id="c-39750074" checked=""/><div class="controls bullet"><span class="by">acchow</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750817">prev</a><span>|</span><a href="#39750507">next</a><span>|</span><label class="collapse" for="c-39750074">[-]</label><label class="expand" for="c-39750074">[2 more]</label></div><br/><div class="children"><div class="content">He has more important things to do than perfecting a presentation. He likes his employees to message him freely with things they think he can help with.</div><br/><div id="39753507" class="c"><input type="checkbox" id="c-39753507" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#39749973">root</a><span>|</span><a href="#39750074">parent</a><span>|</span><a href="#39750507">next</a><span>|</span><label class="collapse" for="c-39753507">[-]</label><label class="expand" for="c-39753507">[1 more]</label></div><br/><div class="children"><div class="content">I read about this around and tbh I respect it a lot. Somehow Jensen has managed to scale the company and still keep it focused on the product with high eng practices.</div><br/></div></div></div></div><div id="39750507" class="c"><input type="checkbox" id="c-39750507" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750074">prev</a><span>|</span><a href="#39750207">next</a><span>|</span><label class="collapse" for="c-39750507">[-]</label><label class="expand" for="c-39750507">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s typical. He isn&#x27;t a great public speaker IMO. Not terrible but not great.</div><br/></div></div><div id="39750207" class="c"><input type="checkbox" id="c-39750207" checked=""/><div class="controls bullet"><span class="by">angm128</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750507">prev</a><span>|</span><a href="#39750454">next</a><span>|</span><label class="collapse" for="c-39750207">[-]</label><label class="expand" for="c-39750207">[1 more]</label></div><br/><div class="children"><div class="content">The products, animations and slides are doing some heavy lifting. Most jokes don&#x27;t land and his presentation is somewhat confusing at times (e.g. star trek intro token count)</div><br/></div></div><div id="39750454" class="c"><input type="checkbox" id="c-39750454" checked=""/><div class="controls bullet"><span class="by">sct202</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750207">prev</a><span>|</span><a href="#39750180">next</a><span>|</span><label class="collapse" for="c-39750454">[-]</label><label class="expand" for="c-39750454">[2 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s a good reminder that objectively great CEO&#x27;s and leaders can be kind of cringe when presenting. A lot of times people like that get passed up in promotions in favor of smooth talkers.</div><br/><div id="39751138" class="c"><input type="checkbox" id="c-39751138" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39749973">root</a><span>|</span><a href="#39750454">parent</a><span>|</span><a href="#39750180">next</a><span>|</span><label class="collapse" for="c-39751138">[-]</label><label class="expand" for="c-39751138">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s been said that founders are people who can&#x27;t get hired.</div><br/></div></div></div></div><div id="39750180" class="c"><input type="checkbox" id="c-39750180" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750454">prev</a><span>|</span><a href="#39752276">next</a><span>|</span><label class="collapse" for="c-39750180">[-]</label><label class="expand" for="c-39750180">[1 more]</label></div><br/><div class="children"><div class="content">Yeah he said he didn&#x27;t rehearse and it really shows.</div><br/></div></div><div id="39752276" class="c"><input type="checkbox" id="c-39752276" checked=""/><div class="controls bullet"><span class="by">CoachRufus87</span><span>|</span><a href="#39749973">parent</a><span>|</span><a href="#39750180">prev</a><span>|</span><a href="#39750034">next</a><span>|</span><label class="collapse" for="c-39752276">[-]</label><label class="expand" for="c-39752276">[1 more]</label></div><br/><div class="children"><div class="content">Its refreshing. Another tech keynote that I regularly watch (Apple) is far too polished these days.</div><br/></div></div></div></div><div id="39751507" class="c"><input type="checkbox" id="c-39751507" checked=""/><div class="controls bullet"><span class="by">geor9e</span><span>|</span><a href="#39749973">prev</a><span>|</span><a href="#39750515">next</a><span>|</span><label class="collapse" for="c-39751507">[-]</label><label class="expand" for="c-39751507">[5 more]</label></div><br/><div class="children"><div class="content">Like a lot of the commenters here, I have a problem with this headline. They don&#x27;t &quot;seek to become a platform company&quot;, as in making their own cloud platform where they rent GPU time, meaning they stop selling GPUs to other cloud platforms. That easy misinterpretation makes good clickbait, but no, that&#x27;s not what the article says - the article has Huang bragging that CUDA already is a parallel computing platform, for a decade or more, and Blackwell Architecture is so integrated and customizable with CUDA (with all its user-extendable kernels and community) that it&#x27;s thought of as a platform rather than just chip architecture.</div><br/><div id="39751795" class="c"><input type="checkbox" id="c-39751795" checked=""/><div class="controls bullet"><span class="by">basiccalendar74</span><span>|</span><a href="#39751507">parent</a><span>|</span><a href="#39751734">next</a><span>|</span><label class="collapse" for="c-39751795">[-]</label><label class="expand" for="c-39751795">[1 more]</label></div><br/><div class="children"><div class="content">they announced a cloud service NIM that hosts LLMs using Nvidia software stack.<p><a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale&#x2F;" rel="nofollow">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;nvidia-nim-offers-optimize...</a><p>so there is a push towards a platform company, but probably not well explained in this article.</div><br/></div></div><div id="39751734" class="c"><input type="checkbox" id="c-39751734" checked=""/><div class="controls bullet"><span class="by">baobabKoodaa</span><span>|</span><a href="#39751507">parent</a><span>|</span><a href="#39751795">prev</a><span>|</span><a href="#39751551">next</a><span>|</span><label class="collapse" for="c-39751734">[-]</label><label class="expand" for="c-39751734">[2 more]</label></div><br/><div class="children"><div class="content">Someone please &quot;chip in&quot; and confirm or deny if this interpretation is correct?</div><br/><div id="39752139" class="c"><input type="checkbox" id="c-39752139" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#39751507">root</a><span>|</span><a href="#39751734">parent</a><span>|</span><a href="#39751551">next</a><span>|</span><label class="collapse" for="c-39752139">[-]</label><label class="expand" for="c-39752139">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Platform&quot; can have several different meanings and some people in this thread are picking the most evil meaning as an excuse to shit on Nvidia. It&#x27;s true that Nvidia is providing the GPU, the CPU, the server, the rack, the network, the drivers, and the orchestration software to run AI training&#x2F;inference. (If you want that stuff. You could just buy GPUs if you want.) It&#x27;s fair to call that a platform.<p>Nvidia is not becoming a cloud provider (beyond a small eval environment perhaps).</div><br/></div></div></div></div></div></div><div id="39750515" class="c"><input type="checkbox" id="c-39750515" checked=""/><div class="controls bullet"><span class="by">lvl102</span><span>|</span><a href="#39751507">prev</a><span>|</span><a href="#39750407">next</a><span>|</span><label class="collapse" for="c-39750515">[-]</label><label class="expand" for="c-39750515">[3 more]</label></div><br/><div class="children"><div class="content">Seems Nvidia is going for maximum margin as they see competition ahead.</div><br/><div id="39750681" class="c"><input type="checkbox" id="c-39750681" checked=""/><div class="controls bullet"><span class="by">theGnuMe</span><span>|</span><a href="#39750515">parent</a><span>|</span><a href="#39750643">prev</a><span>|</span><a href="#39750407">next</a><span>|</span><label class="collapse" for="c-39750681">[-]</label><label class="expand" for="c-39750681">[1 more]</label></div><br/><div class="children"><div class="content">And they can build a big moat with cuda.</div><br/></div></div></div></div><div id="39750407" class="c"><input type="checkbox" id="c-39750407" checked=""/><div class="controls bullet"><span class="by">stevethomas</span><span>|</span><a href="#39750515">prev</a><span>|</span><a href="#39751110">next</a><span>|</span><label class="collapse" for="c-39750407">[-]</label><label class="expand" for="c-39750407">[10 more]</label></div><br/><div class="children"><div class="content">Time to sell. When they start becoming a platform, it means they have nothing more concrete in the near future. Sell now and buy again later once the price corrects.</div><br/><div id="39750478" class="c"><input type="checkbox" id="c-39750478" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#39750407">parent</a><span>|</span><a href="#39753628">next</a><span>|</span><label class="collapse" for="c-39750478">[-]</label><label class="expand" for="c-39750478">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t bet against a CEO who knows what is talking about, has 80% market share and an arm tattoo of his own company logo.... :-)<p>So far the short sellers, learned that bitter lesson.</div><br/></div></div><div id="39753628" class="c"><input type="checkbox" id="c-39753628" checked=""/><div class="controls bullet"><span class="by">hsuz</span><span>|</span><a href="#39750407">parent</a><span>|</span><a href="#39750478">prev</a><span>|</span><a href="#39750521">next</a><span>|</span><label class="collapse" for="c-39753628">[-]</label><label class="expand" for="c-39753628">[1 more]</label></div><br/><div class="children"><div class="content">Selling is a bit exaggerated. Scaling up is almost always non-detrimental. But I do feel that NVDA is slowly falling to a stall because there are no exciting new modes of business coming out.</div><br/></div></div><div id="39750521" class="c"><input type="checkbox" id="c-39750521" checked=""/><div class="controls bullet"><span class="by">pvg</span><span>|</span><a href="#39750407">parent</a><span>|</span><a href="#39753628">prev</a><span>|</span><a href="#39751035">next</a><span>|</span><label class="collapse" for="c-39750521">[-]</label><label class="expand" for="c-39750521">[1 more]</label></div><br/><div class="children"><div class="content">If you held and then sold Nvidia stock when they announced CUDA or GeForce Live, you&#x27;d now be now a big pile of negative money richer.</div><br/></div></div><div id="39751035" class="c"><input type="checkbox" id="c-39751035" checked=""/><div class="controls bullet"><span class="by">Keyframe</span><span>|</span><a href="#39750407">parent</a><span>|</span><a href="#39750521">prev</a><span>|</span><a href="#39750494">next</a><span>|</span><label class="collapse" for="c-39751035">[-]</label><label class="expand" for="c-39751035">[1 more]</label></div><br/><div class="children"><div class="content">They still have to announce you can send an email through their platform.</div><br/></div></div><div id="39750494" class="c"><input type="checkbox" id="c-39750494" checked=""/><div class="controls bullet"><span class="by">golergka</span><span>|</span><a href="#39750407">parent</a><span>|</span><a href="#39751035">prev</a><span>|</span><a href="#39752122">next</a><span>|</span><label class="collapse" for="c-39750494">[-]</label><label class="expand" for="c-39750494">[3 more]</label></div><br/><div class="children"><div class="content">Does a company like Nvidia has to have anything more concrete than newer, bigger and faster chips?</div><br/></div></div><div id="39752122" class="c"><input type="checkbox" id="c-39752122" checked=""/><div class="controls bullet"><span class="by">mark336</span><span>|</span><a href="#39750407">parent</a><span>|</span><a href="#39750494">prev</a><span>|</span><a href="#39750501">next</a><span>|</span><label class="collapse" for="c-39752122">[-]</label><label class="expand" for="c-39752122">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t be 100% against them, but it is disappointing that they don&#x27;t have any better ideas.</div><br/></div></div></div></div><div id="39751110" class="c"><input type="checkbox" id="c-39751110" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39750407">prev</a><span>|</span><a href="#39750593">next</a><span>|</span><label class="collapse" for="c-39751110">[-]</label><label class="expand" for="c-39751110">[3 more]</label></div><br/><div class="children"><div class="content">&quot;platform co.&quot;<p>Platform company, as in they&#x27;re allowing developers on their AI platform and opening an app store?</div><br/><div id="39751150" class="c"><input type="checkbox" id="c-39751150" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#39751110">parent</a><span>|</span><a href="#39751558">next</a><span>|</span><label class="collapse" for="c-39751150">[-]</label><label class="expand" for="c-39751150">[1 more]</label></div><br/><div class="children"><div class="content">The headline is editorialized by the submitter, the actual headline is “Nvidia CEO Jensen Huang announces new AI chips: ‘We need bigger GPUs’” which is arguably worse.<p>The article doesn’t discuss becoming a platform co but instead discussed ways their existing platform subscription model is evolving to add backwards compatibility testing.</div><br/></div></div></div></div></div></div></div></div></div></body></html>