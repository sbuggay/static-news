<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1698138085960" as="style"/><link rel="stylesheet" href="styles.css?v=1698138085960"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.datature.io/blog/how-to-build-your-own-ai-generated-image-with-controlnet-and-stable-diffusion">How to Build Your Own AI-Generated Images with ControlNet and Stable Diffusion</a> <span class="domain">(<a href="https://www.datature.io">www.datature.io</a>)</span></div><div class="subtext"><span>gkeechin</span> | <span>39 comments</span></div><br/><div><div id="37994207" class="c"><input type="checkbox" id="c-37994207" checked=""/><div class="controls bullet"><span class="by">drschwabe</span><span>|</span><a href="#37996036">next</a><span>|</span><label class="collapse" for="c-37994207">[-]</label><label class="expand" for="c-37994207">[3 more]</label></div><br/><div class="children"><div class="content">ControlNet model specifically the scribble ControlNet (and ComfyUI) was major gamechanger for me.<p>Was getting good results with just SD and occassional masking but it would take hours and hours to hone in and composite a complex scene with specific requirements &amp; shapes (with most of the work spent currating the best outputs and then blending them into a scene with Gimp&#x2F;Inkscape).<p>Masking is unintuitive compared to the scribble which gets similar effect; no need to paint masks (which is disruptive to the natural process of &#x27;drawing&#x27; IMO) instead just make a general black and white outline of your scene.  Simply dial up&#x2F;down the conditioning strength to have it more tightly or fuzzily follow that outline.<p>You can also use Gimp&#x27;s Threshold or Inkscape Trace Bitmap tool to get a decent black &amp; white outline from an existing bitmap to expedite the scribble procedure.</div><br/><div id="37996410" class="c"><input type="checkbox" id="c-37996410" checked=""/><div class="controls bullet"><span class="by">fsloth</span><span>|</span><a href="#37994207">parent</a><span>|</span><a href="#37994779">next</a><span>|</span><label class="collapse" for="c-37996410">[-]</label><label class="expand" for="c-37996410">[1 more]</label></div><br/><div class="children"><div class="content">Comfy ui is really nice. The fact that the node graph is saved as png metadata actually makes node based workflows super fluent and reproducible since all you need to do to get the graph for your image is to drag and drop the result png to the gui. This feels like a huge quality-of-life improvement compared to any other lightweight node tools I’ve used.</div><br/></div></div><div id="37994779" class="c"><input type="checkbox" id="c-37994779" checked=""/><div class="controls bullet"><span class="by">gkeechin</span><span>|</span><a href="#37994207">parent</a><span>|</span><a href="#37996410">prev</a><span>|</span><a href="#37996036">next</a><span>|</span><label class="collapse" for="c-37994779">[-]</label><label class="expand" for="c-37994779">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s for sure - I think we have seen other kind of edge detector or filter work better for differing use cases, especially around foreground images where you want to retain more information (i.e. images with small nitty-gritty details)<p>In this post, we just seek to showcase the fastest way to do it - and how augmentation may potentially help vary the position!</div><br/></div></div></div></div><div id="37996036" class="c"><input type="checkbox" id="c-37996036" checked=""/><div class="controls bullet"><span class="by">imranhou</span><span>|</span><a href="#37994207">prev</a><span>|</span><a href="#37994672">next</a><span>|</span><label class="collapse" for="c-37996036">[-]</label><label class="expand" for="c-37996036">[2 more]</label></div><br/><div class="children"><div class="content">The versatility of Stable Diffusion, especially when combined with tools like ControlNet, highlights the advantages of a more controlled image generation process. While DALL-E and others provide ease and speed, the depth of customization and local processing capabilities of SD models cater to those seeking deeper creative control and independence.</div><br/><div id="37996313" class="c"><input type="checkbox" id="c-37996313" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#37996036">parent</a><span>|</span><a href="#37994672">next</a><span>|</span><label class="collapse" for="c-37996313">[-]</label><label class="expand" for="c-37996313">[1 more]</label></div><br/><div class="children"><div class="content">It is interesting isn&#x27;t it? Because we have &quot;AI&quot; generating the image, but we still seem to want to &quot;paint&quot; or have control over the creative process.<p>Prompts seem to be a new type of camera, lens or paintbrush.</div><br/></div></div></div></div><div id="37994672" class="c"><input type="checkbox" id="c-37994672" checked=""/><div class="controls bullet"><span class="by">rvion</span><span>|</span><a href="#37996036">prev</a><span>|</span><a href="#37994310">next</a><span>|</span><label class="collapse" for="c-37994672">[-]</label><label class="expand" for="c-37994672">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m building CushyStudio <a href="https:&#x2F;&#x2F;github.com&#x2F;rvion&#x2F;cushystudio#readme">https:&#x2F;&#x2F;github.com&#x2F;rvion&#x2F;cushystudio#readme</a> to make Stable Diffusion practical and fun to play with.<p>It&#x27;s still a bit rough around the corners, and I haven&#x27;t properly launched it yet, but if you want to play with ControlNets, pre-processors, IP adapters, and all those various SD technologies, it&#x27;s a pretty fun tool ! I personally use for real-time scribble to image, things like this :)<p>(will post that properly on HN in a few days &#x2F; week I think, when early feedback will have been properly addressed)</div><br/></div></div><div id="37994310" class="c"><input type="checkbox" id="c-37994310" checked=""/><div class="controls bullet"><span class="by">Magi604</span><span>|</span><a href="#37994672">prev</a><span>|</span><a href="#37994948">next</a><span>|</span><label class="collapse" for="c-37994310">[-]</label><label class="expand" for="c-37994310">[24 more]</label></div><br/><div class="children"><div class="content">SD outputs have an &quot;uncanny valley&quot; type of quality to them. You just KNOW when an image is from SD. And I have looked at getting started with SD, but the requirements and setup and +-prompting &quot;language&quot; just kind of turned me off the whole thing.<p>Whereas with DALL E you can get some hyper-realistic images from it with very little effort using plain human language.<p>I guess my point is to ask whether SD is worth bothering with at this time when DALL E and Imagen and possibly others are just on the brink of becoming mainstream and just going to get better and better. Clunking together something with SD seems unnecessary when you can generate more results, better results, in a faster way, with less requirements, and without the steep learning curve, by using other methods.</div><br/><div id="37996453" class="c"><input type="checkbox" id="c-37996453" checked=""/><div class="controls bullet"><span class="by">fsloth</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37994495">next</a><span>|</span><label class="collapse" for="c-37996453">[-]</label><label class="expand" for="c-37996453">[1 more]</label></div><br/><div class="children"><div class="content">[delayed]</div><br/></div></div><div id="37994495" class="c"><input type="checkbox" id="c-37994495" checked=""/><div class="controls bullet"><span class="by">jyap</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37996453">prev</a><span>|</span><a href="#37995542">next</a><span>|</span><label class="collapse" for="c-37994495">[-]</label><label class="expand" for="c-37994495">[6 more]</label></div><br/><div class="children"><div class="content">One major benefit and the reason why I use the StableDiffusion tools and models is because I can run them at home on my relatively old NVIDIA 2080 GPU with 8GB of VRAM. Costs me nothing (besides electricity).<p>Depends if you value this kind of freedom in life.<p>You can do some things such as colorizing black and white images with the Recolor model.<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;stabilityai&#x2F;control-lora" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;stabilityai&#x2F;control-lora</a></div><br/><div id="37994782" class="c"><input type="checkbox" id="c-37994782" checked=""/><div class="controls bullet"><span class="by">gkeechin</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37994495">parent</a><span>|</span><a href="#37994519">next</a><span>|</span><label class="collapse" for="c-37994782">[-]</label><label class="expand" for="c-37994782">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting - thank you for sharing this. Would love to explore this as a team and perhaps put out a blog on helping others get started with control-lora</div><br/></div></div><div id="37994519" class="c"><input type="checkbox" id="c-37994519" checked=""/><div class="controls bullet"><span class="by">NBJack</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37994495">parent</a><span>|</span><a href="#37994782">prev</a><span>|</span><a href="#37994543">next</a><span>|</span><label class="collapse" for="c-37994519">[-]</label><label class="expand" for="c-37994519">[1 more]</label></div><br/><div class="children"><div class="content">I have to agree at how convenient and (long term) inexpensive this can be. I may not always get the greatest results right away, but it is fun to come up with some ideas, put them into a prompt iterator (or matrix), and run it overnight. I can tweak it to my heart&#x27;s content.</div><br/></div></div><div id="37994543" class="c"><input type="checkbox" id="c-37994543" checked=""/><div class="controls bullet"><span class="by">Magi604</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37994495">parent</a><span>|</span><a href="#37994519">prev</a><span>|</span><a href="#37995542">next</a><span>|</span><label class="collapse" for="c-37994543">[-]</label><label class="expand" for="c-37994543">[3 more]</label></div><br/><div class="children"><div class="content">I mean, I&#x27;m running DALLE 3 on a browser from an old laptop and I&#x27;ve generated probably over 15k images in 2 weeks, spanning the gamut from memes to art to lewds (with jailbreaks). The ability to completely scrap what you&#x27;re building and start totally fresh at the drop of a hat with a new line of ideas and get instant results seems pretty freeing to me.</div><br/><div id="37995263" class="c"><input type="checkbox" id="c-37995263" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37994543">parent</a><span>|</span><a href="#37995559">next</a><span>|</span><label class="collapse" for="c-37995263">[-]</label><label class="expand" for="c-37995263">[1 more]</label></div><br/><div class="children"><div class="content">That’s fine, but it’s like asking: “Why would anyone want to have a personal website when you can just write stuff on Facebook and Twitter and it’s so much easier?”<p>Stable Diffusion is an open model that you can run locally on your own computer without anyone’s permission. Dall-E is a closed model that runs on OpenAI’s very expensive server farm, and they can change how it works and what it costs whenever they please.<p>Right now AI is in the Uber-style expansion phase where the service is practically given away to conquer market share. Once the hypergrowth is over, OpenAI will start raising their prices just like Uber did.</div><br/></div></div><div id="37995559" class="c"><input type="checkbox" id="c-37995559" checked=""/><div class="controls bullet"><span class="by">Karuma</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37994543">parent</a><span>|</span><a href="#37995263">prev</a><span>|</span><a href="#37995542">next</a><span>|</span><label class="collapse" for="c-37995559">[-]</label><label class="expand" for="c-37995559">[1 more]</label></div><br/><div class="children"><div class="content">With SD I can generate at least 15k images daily on my old laptop, I can train it with new styles, characters, real people, etc.; download thousands of new styles, characters, real people, etc. from Civitai, and best of all, never worry about ever losing access to it, being censored, having to jailbreak it, being snooped on, etc.<p>Plus a million other tools that the community has made for it, like ControlNet or things like AnimateDiff to create videos. I can also easily create all kinds of scripts and workflows.</div><br/></div></div></div></div></div></div><div id="37995542" class="c"><input type="checkbox" id="c-37995542" checked=""/><div class="controls bullet"><span class="by">smcleod</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37994495">prev</a><span>|</span><a href="#37994355">next</a><span>|</span><label class="collapse" for="c-37995542">[-]</label><label class="expand" for="c-37995542">[5 more]</label></div><br/><div class="children"><div class="content">I’m assuming you haven’t used SDXL?<p>Give it a go with invokeAI - you can create images that I guarantee you wouldn’t know were generated. Like anything (photography included) it’s a skill.<p>Examples:<p><pre><code>  - https:&#x2F;&#x2F;civitai.com&#x2F;images&#x2F;2862100
  - https:&#x2F;&#x2F;civitai.com&#x2F;images&#x2F;2339666
  - https:&#x2F;&#x2F;civitai.com&#x2F;images&#x2F;2846876</code></pre></div><br/><div id="37996015" class="c"><input type="checkbox" id="c-37996015" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37995542">parent</a><span>|</span><a href="#37995622">next</a><span>|</span><label class="collapse" for="c-37996015">[-]</label><label class="expand" for="c-37996015">[2 more]</label></div><br/><div class="children"><div class="content">I can see at least three finger issues with the couple in the cinema.<p>More than that though: I use SDXL quite a bit for fun, and while I like it and it can be very good, it&#x27;s still prone to getting stuck in a David Cronenberg mode for reasons I can&#x27;t solve.</div><br/><div id="37996308" class="c"><input type="checkbox" id="c-37996308" checked=""/><div class="controls bullet"><span class="by">smcleod</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37996015">parent</a><span>|</span><a href="#37995622">next</a><span>|</span><label class="collapse" for="c-37996308">[-]</label><label class="expand" for="c-37996308">[1 more]</label></div><br/><div class="children"><div class="content">Oh yeah it’s not one-shot perfect but it gets you 90% of the way there for a lot of things. I’m super impressed with it.</div><br/></div></div></div></div><div id="37995622" class="c"><input type="checkbox" id="c-37995622" checked=""/><div class="controls bullet"><span class="by">moritonal</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37995542">parent</a><span>|</span><a href="#37996015">prev</a><span>|</span><a href="#37994355">next</a><span>|</span><label class="collapse" for="c-37995622">[-]</label><label class="expand" for="c-37995622">[2 more]</label></div><br/><div class="children"><div class="content">At glance I get uncanny valley from two. After looking closer it&#x27;s likely because with the photo of the couple at the cinema, the woman&#x27;s arm around him is wearing the wrong clothes. Then photo of the guy with a hat, his neck piece is asymmetric.</div><br/><div id="37995976" class="c"><input type="checkbox" id="c-37995976" checked=""/><div class="controls bullet"><span class="by">pmx</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37995622">parent</a><span>|</span><a href="#37994355">next</a><span>|</span><label class="collapse" for="c-37995976">[-]</label><label class="expand" for="c-37995976">[1 more]</label></div><br/><div class="children"><div class="content">The eyes are messed up in the second one too which instantly gives it away</div><br/></div></div></div></div></div></div><div id="37994355" class="c"><input type="checkbox" id="c-37994355" checked=""/><div class="controls bullet"><span class="by">NBJack</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37995542">prev</a><span>|</span><a href="#37996219">next</a><span>|</span><label class="collapse" for="c-37994355">[-]</label><label class="expand" for="c-37994355">[1 more]</label></div><br/><div class="children"><div class="content">Try SDXL. Find a good negative prompt, then just put a short sentence (starting with the kind of image, such as photograph, render, etc.) describing what you want in the positive prompt. It is much simpler and has fantastic results. Tweak to your hearts desire from there.<p>If you see a part of the scene that looks weird (and you know what it should be) add it to your prompt. For example, if you want &quot;photo of a jungle in South America&quot;, and the foliage looks weird, add something like &quot;with lush trees and ferns&quot;.</div><br/></div></div><div id="37996219" class="c"><input type="checkbox" id="c-37996219" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37994355">prev</a><span>|</span><a href="#37995472">next</a><span>|</span><label class="collapse" for="c-37996219">[-]</label><label class="expand" for="c-37996219">[1 more]</label></div><br/><div class="children"><div class="content">Dall-E has the same problems as other models. Try generating a clockwork mechanism with it, for example.<p>SD is worth bothering with because it&#x27;s open, you can run and extend it yourself.</div><br/></div></div><div id="37995472" class="c"><input type="checkbox" id="c-37995472" checked=""/><div class="controls bullet"><span class="by">orbital-decay</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37996219">prev</a><span>|</span><a href="#37994514">next</a><span>|</span><label class="collapse" for="c-37995472">[-]</label><label class="expand" for="c-37995472">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s funny to hear because DALL-E 3 mainly improves prompt understanding, it hallucinates like mad with faces and hands, and doesn&#x27;t seem to do anything to improve them like Midjourney for example.<p><i>&gt;Whereas with DALL E you can get some hyper-realistic images from it with very little effort using plain human language.</i><p>Hyper-realistic, but is it <i>what you want</i> from it? Are you able to guide it into doing exactly what you want? If you have such requirements that just a natural language prompt is enough and is somehow faster than sketching and providing references, of course use it. I&#x27;m not so lucky, I don&#x27;t get what I want from it, and no amount of prompt understanding will make it easier. Although SD&#x2F;SDXL doesn&#x27;t pass the quality bar either, not because it&#x27;s not &quot;detailed&quot; or &quot;hyper-realistic&quot; enough, but because it doesn&#x27;t pay attention to the things that should be prioritized, like linework or lighting. Neither does any other model. Controlnets and LoRAs alone aren&#x27;t sufficient for controllability either, mostly because it&#x27;s too small to understand high-level concepts. So I don&#x27;t use anything.</div><br/></div></div><div id="37994514" class="c"><input type="checkbox" id="c-37994514" checked=""/><div class="controls bullet"><span class="by">fassssst</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37995472">prev</a><span>|</span><a href="#37995483">next</a><span>|</span><label class="collapse" for="c-37994514">[-]</label><label class="expand" for="c-37994514">[2 more]</label></div><br/><div class="children"><div class="content">DALL-E within ChatGPT uses GPT-4 to rewrite what you ask for into a good text-to-image prompt. You could probably do something similar with Stable Diffusion with just a little upfront effort tuning that system prompt.</div><br/><div id="37995988" class="c"><input type="checkbox" id="c-37995988" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37994514">parent</a><span>|</span><a href="#37995483">next</a><span>|</span><label class="collapse" for="c-37995988">[-]</label><label class="expand" for="c-37995988">[1 more]</label></div><br/><div class="children"><div class="content">Somewhat, but dalle3 is hugely better at understanding a description and relationships.</div><br/></div></div></div></div><div id="37995483" class="c"><input type="checkbox" id="c-37995483" checked=""/><div class="controls bullet"><span class="by">DrSiemer</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37994514">prev</a><span>|</span><a href="#37994856">next</a><span>|</span><label class="collapse" for="c-37995483">[-]</label><label class="expand" for="c-37995483">[1 more]</label></div><br/><div class="children"><div class="content"><i>You just KNOW when an image is from SD</i><p>No, you know when a beginner generated an image in Stable Diffusion. With enough skill and attention, you will not.<p>Sure, there is a learning curve and it takes more time to get to a good result. But in turn, it gives you control far beyond what the competition can offer.</div><br/></div></div><div id="37994856" class="c"><input type="checkbox" id="c-37994856" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37995483">prev</a><span>|</span><a href="#37995487">next</a><span>|</span><label class="collapse" for="c-37994856">[-]</label><label class="expand" for="c-37994856">[3 more]</label></div><br/><div class="children"><div class="content">Try: <a href="https:&#x2F;&#x2F;github.com&#x2F;lllyasviel&#x2F;Fooocus">https:&#x2F;&#x2F;github.com&#x2F;lllyasviel&#x2F;Fooocus</a><p>I also recommend a good photorealistic base model, like RealVis XL.<p>In my experience its like DALL E but straight up better, more customizable, and local. And thats before you start trying finetunes and LORAs.<p>Other UIs will do SDXL, but every one I tried is terrible without all those default fooocus augmentations.</div><br/><div id="37995175" class="c"><input type="checkbox" id="c-37995175" checked=""/><div class="controls bullet"><span class="by">AuryGlenz</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37994856">parent</a><span>|</span><a href="#37995487">next</a><span>|</span><label class="collapse" for="c-37995175">[-]</label><label class="expand" for="c-37995175">[2 more]</label></div><br/><div class="children"><div class="content">SDXL is great but it&#x27;s in no way better than DALL E as far as straight text-to-image goes apart from the lack of censorship.<p>It has plenty of other advantages, but you can&#x27;t tell it &quot;make me a cute illustration of a 2 year old girl with Blaze from Blaze and the Monster Machines on a birthday cake with a large 2 candle on it.&quot;<p>DALL E will nail that, more or less.  SDXL very much won&#x27;t.</div><br/><div id="37996375" class="c"><input type="checkbox" id="c-37996375" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#37994310">root</a><span>|</span><a href="#37995175">parent</a><span>|</span><a href="#37995487">next</a><span>|</span><label class="collapse" for="c-37996375">[-]</label><label class="expand" for="c-37996375">[1 more]</label></div><br/><div class="children"><div class="content">SD XL understands prompts much better than 1.5. So the next version of SD might be comparable to Dall-E without censorship.</div><br/></div></div></div></div></div></div><div id="37995487" class="c"><input type="checkbox" id="c-37995487" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37994856">prev</a><span>|</span><a href="#37995791">next</a><span>|</span><label class="collapse" for="c-37995487">[-]</label><label class="expand" for="c-37995487">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You just KNOW when an image is from SD.<p>You don&#x27;t. People think they do, but they don&#x27;t.</div><br/></div></div><div id="37995791" class="c"><input type="checkbox" id="c-37995791" checked=""/><div class="controls bullet"><span class="by">vidarh</span><span>|</span><a href="#37994310">parent</a><span>|</span><a href="#37995487">prev</a><span>|</span><a href="#37994948">next</a><span>|</span><label class="collapse" for="c-37995791">[-]</label><label class="expand" for="c-37995791">[1 more]</label></div><br/><div class="children"><div class="content">You know when they&#x27;re bad enough that you know.</div><br/></div></div></div></div><div id="37994948" class="c"><input type="checkbox" id="c-37994948" checked=""/><div class="controls bullet"><span class="by">jaggs</span><span>|</span><a href="#37994310">prev</a><span>|</span><a href="#37995013">next</a><span>|</span><label class="collapse" for="c-37994948">[-]</label><label class="expand" for="c-37994948">[1 more]</label></div><br/><div class="children"><div class="content">Artroom.ai is a great option. Free image generation feature, plus a ton of editing features like layers, zoom out etc.</div><br/></div></div><div id="37995013" class="c"><input type="checkbox" id="c-37995013" checked=""/><div class="controls bullet"><span class="by">ComputerGuru</span><span>|</span><a href="#37994948">prev</a><span>|</span><a href="#37994412">next</a><span>|</span><label class="collapse" for="c-37995013">[-]</label><label class="expand" for="c-37995013">[2 more]</label></div><br/><div class="children"><div class="content">The word ControlNet doesn’t appear even once in the article?</div><br/><div id="37995520" class="c"><input type="checkbox" id="c-37995520" checked=""/><div class="controls bullet"><span class="by">DarthNebo</span><span>|</span><a href="#37995013">parent</a><span>|</span><a href="#37994412">next</a><span>|</span><label class="collapse" for="c-37995520">[-]</label><label class="expand" for="c-37995520">[1 more]</label></div><br/><div class="children"><div class="content">They did use the Canny ControlNet Pipeline</div><br/></div></div></div></div><div id="37994412" class="c"><input type="checkbox" id="c-37994412" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#37995013">prev</a><span>|</span><a href="#37996189">next</a><span>|</span><label class="collapse" for="c-37994412">[-]</label><label class="expand" for="c-37994412">[4 more]</label></div><br/><div class="children"><div class="content">With the luggage example it seems to only generate backgrounds where the lighting makes sense? That&#x27;s kind of interesting. I was wondering how it would handle the highlight on the right.</div><br/><div id="37995661" class="c"><input type="checkbox" id="c-37995661" checked=""/><div class="controls bullet"><span class="by">zamalek</span><span>|</span><a href="#37994412">parent</a><span>|</span><a href="#37994762">next</a><span>|</span><label class="collapse" for="c-37995661">[-]</label><label class="expand" for="c-37995661">[1 more]</label></div><br/><div class="children"><div class="content">In ComfyUI you could run the image through a style-to-style (sdxl refinement might even pull it off) model to change the lighting without changing the content. Or use another ControlNet. Your workflow can get arbitrarily complex.</div><br/></div></div><div id="37994762" class="c"><input type="checkbox" id="c-37994762" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#37994412">parent</a><span>|</span><a href="#37995661">prev</a><span>|</span><a href="#37996189">next</a><span>|</span><label class="collapse" for="c-37994762">[-]</label><label class="expand" for="c-37994762">[2 more]</label></div><br/><div class="children"><div class="content">Giving Stable Diffusion constraints forces it to get creative.<p>It’s the best argument against “AI generated images are just collages”.</div><br/><div id="37994934" class="c"><input type="checkbox" id="c-37994934" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#37994412">root</a><span>|</span><a href="#37994762">parent</a><span>|</span><a href="#37996189">next</a><span>|</span><label class="collapse" for="c-37994934">[-]</label><label class="expand" for="c-37994934">[1 more]</label></div><br/><div class="children"><div class="content">This is a general result. For example, ChatGPT struggles hard with following lexical, syntactic, or phonetic constraints in prompts due to the tokenization scheme - see <a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;most-language-models-can-be-poets-too-an-ai-1" rel="nofollow noreferrer">https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;most-language-models-can-be...</a><p>LLMs + Diffusors are super charged when using techniques like constraints, controlnet, regional prompting, and related techniques.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>