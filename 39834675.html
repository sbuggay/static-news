<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1711530068056" as="style"/><link rel="stylesheet" href="styles.css?v=1711530068056"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://hothardware.com/news/mit-dmd-image-diffusion">MIT Unveils Gen AI Tool That Generates High Res Images 30 Times Faster</a> <span class="domain">(<a href="https://hothardware.com">hothardware.com</a>)</span></div><div class="subtext"><span>mikhael</span> | <span>37 comments</span></div><br/><div><div id="39835668" class="c"><input type="checkbox" id="c-39835668" checked=""/><div class="controls bullet"><span class="by">ChrisArchitect</span><span>|</span><a href="#39835245">next</a><span>|</span><label class="collapse" for="c-39835668">[-]</label><label class="expand" for="c-39835668">[2 more]</label></div><br/><div class="children"><div class="content">Official news release rather than whatever this site is:<p><a href="https:&#x2F;&#x2F;news.mit.edu&#x2F;2024&#x2F;ai-generates-high-quality-images-30-times-faster-single-step-0321" rel="nofollow">https:&#x2F;&#x2F;news.mit.edu&#x2F;2024&#x2F;ai-generates-high-quality-images-3...</a></div><br/></div></div><div id="39835245" class="c"><input type="checkbox" id="c-39835245" checked=""/><div class="controls bullet"><span class="by">fngjdflmdflg</span><span>|</span><a href="#39835668">prev</a><span>|</span><a href="#39835506">next</a><span>|</span><label class="collapse" for="c-39835245">[-]</label><label class="expand" for="c-39835245">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Our method is similar to GANs in that a critic is jointly trained with the generator to minimize a divergence between the real and fake distributions, but differs in that our training does not play an adversarial game that may cause training instability, and our critic can fully leverage the weights of a pretrained diffusion model.<p>Very glad to see GANs (or GAN-likes) coming back! Also I don&#x27;t know if the examples were cherrypicked but a lot of the images look more realistic than SD. For example the dog in the snow[0] is severely oversaturated in the SD version giving it that distinct AI look (sometimes referred to as AIslop). Also the landscape scene[1] has a random lens flare in the SD version which makes it look oversaturated as well. The MIT images are much better in this regard.<p>[0] <a href="https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;images&#x2F;teaser&#x2F;teaser2_Page_1_Image_0009.png" rel="nofollow">https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;images&#x2F;teaser&#x2F;teaser2_Page_1_...</a> vs <a href="https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;images&#x2F;teaser&#x2F;teaser2_Page_1_Image_0008.png" rel="nofollow">https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;images&#x2F;teaser&#x2F;teaser2_Page_1_...</a><p>[1] <a href="https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;images&#x2F;teaser&#x2F;teaser2_Page_1_Image_0001.png" rel="nofollow">https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;images&#x2F;teaser&#x2F;teaser2_Page_1_...</a> vs <a href="https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;images&#x2F;teaser&#x2F;teaser2_Page_1_Image_0005.png" rel="nofollow">https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;images&#x2F;teaser&#x2F;teaser2_Page_1_...</a></div><br/><div id="39836744" class="c"><input type="checkbox" id="c-39836744" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39835245">parent</a><span>|</span><a href="#39835506">next</a><span>|</span><label class="collapse" for="c-39836744">[-]</label><label class="expand" for="c-39836744">[1 more]</label></div><br/><div class="children"><div class="content">Can GANs prevent the &quot;&gt;10 fingers&quot; problem?</div><br/></div></div></div></div><div id="39835506" class="c"><input type="checkbox" id="c-39835506" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#39835245">prev</a><span>|</span><a href="#39836508">next</a><span>|</span><label class="collapse" for="c-39835506">[-]</label><label class="expand" for="c-39835506">[4 more]</label></div><br/><div class="children"><div class="content">Is the text prompt input the only common thing between SD and MIT models when comparing outputs?<p>If so I am surprised at how SIMILAR the outputs of both models look in the general layout &#x2F; framing &#x2F; composition of the image.<p>How can for example both fox astronaut images have near identical backdrop of earth and earth alone on the same side of image at same apparent size. Virtually the same shade of deep blue for deep space.<p>&quot;Lightshow at the Dolomities&quot; output is virtually identical. So similar that they almost look like iPhone versus Samsung Galaxy camera comparison shots of same scene (I am exaggerating of course but almost there).<p>What results in such a close similarity in outputs? Same training data set?<p>It is almost like they have the same DNA!</div><br/><div id="39835553" class="c"><input type="checkbox" id="c-39835553" checked=""/><div class="controls bullet"><span class="by">mattnewton</span><span>|</span><a href="#39835506">parent</a><span>|</span><a href="#39835582">next</a><span>|</span><label class="collapse" for="c-39835553">[-]</label><label class="expand" for="c-39835553">[1 more]</label></div><br/><div class="children"><div class="content">I believe this is similar to the Latent Consistency Modeling approach, where it’s a replacement for the “diffusion” process, not the underlying weights. Basically, they have a more efficient process for pulling images out of the weights, not necessarily a set of new weights.</div><br/></div></div><div id="39835582" class="c"><input type="checkbox" id="c-39835582" checked=""/><div class="controls bullet"><span class="by">gr0m</span><span>|</span><a href="#39835506">parent</a><span>|</span><a href="#39835553">prev</a><span>|</span><a href="#39836211">next</a><span>|</span><label class="collapse" for="c-39835582">[-]</label><label class="expand" for="c-39835582">[1 more]</label></div><br/><div class="children"><div class="content">MIT is somewhat distillation model, maybe it was distilled from SD?
Edit: it was, section 3.1</div><br/></div></div><div id="39836211" class="c"><input type="checkbox" id="c-39836211" checked=""/><div class="controls bullet"><span class="by">jzbontar</span><span>|</span><a href="#39835506">parent</a><span>|</span><a href="#39835582">prev</a><span>|</span><a href="#39836508">next</a><span>|</span><label class="collapse" for="c-39836211">[-]</label><label class="expand" for="c-39836211">[1 more]</label></div><br/><div class="children"><div class="content">I assume those images were generated using the same text prompt as well as the same initial random noise.</div><br/></div></div></div></div><div id="39836508" class="c"><input type="checkbox" id="c-39836508" checked=""/><div class="controls bullet"><span class="by">neya</span><span>|</span><a href="#39835506">prev</a><span>|</span><a href="#39836650">next</a><span>|</span><label class="collapse" for="c-39836508">[-]</label><label class="expand" for="c-39836508">[1 more]</label></div><br/><div class="children"><div class="content">This is just an ad dumpster borderline malware link.<p>Here is the link to the actual tool.<p><a href="https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;" rel="nofollow">https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;</a></div><br/></div></div><div id="39836650" class="c"><input type="checkbox" id="c-39836650" checked=""/><div class="controls bullet"><span class="by">mosselman</span><span>|</span><a href="#39836508">prev</a><span>|</span><a href="#39835386">next</a><span>|</span><label class="collapse" for="c-39836650">[-]</label><label class="expand" for="c-39836650">[1 more]</label></div><br/><div class="children"><div class="content">Is the tool available to use somewhere? I&#x27;ve been looking around, but I am not familiar with the research paper format of these types of tools so maybe I am overlooking some obvious link to a repository or something?</div><br/></div></div><div id="39835386" class="c"><input type="checkbox" id="c-39835386" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#39836650">prev</a><span>|</span><a href="#39836654">next</a><span>|</span><label class="collapse" for="c-39835386">[-]</label><label class="expand" for="c-39835386">[1 more]</label></div><br/><div class="children"><div class="content">This is 30 times faster than SD (on its own, as opposed to LCM methods) right?<p>Noting the &quot;50&quot; steps they referenced- whereas I&#x27;ve been using LCMs with 3-8 steps for months.<p>Just trying to understand context of the paper &#x2F; comparisons etc.<p>90ms is fast, but like 2-3x speedup (over what I&#x27;ve been seeing) which is still huge, but not 30x<p>Can someone with more context explain?</div><br/></div></div><div id="39836654" class="c"><input type="checkbox" id="c-39836654" checked=""/><div class="controls bullet"><span class="by">angiosperm</span><span>|</span><a href="#39835386">prev</a><span>|</span><a href="#39835335">next</a><span>|</span><label class="collapse" for="c-39836654">[-]</label><label class="expand" for="c-39836654">[1 more]</label></div><br/><div class="children"><div class="content">The word &quot;confabulate&quot; is underused in AI image generation circles.</div><br/></div></div><div id="39835335" class="c"><input type="checkbox" id="c-39835335" checked=""/><div class="controls bullet"><span class="by">robertclaus</span><span>|</span><a href="#39836654">prev</a><span>|</span><a href="#39834885">next</a><span>|</span><label class="collapse" for="c-39835335">[-]</label><label class="expand" for="c-39835335">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m glad to see another project tackling the challenge of speeding up image generation. After seeing the bang-for-buck jump from sdxl to sdxl-turbo, I assume there&#x27;s tons more room for improvement on the speed side of things.</div><br/></div></div><div id="39834885" class="c"><input type="checkbox" id="c-39834885" checked=""/><div class="controls bullet"><span class="by">maytc</span><span>|</span><a href="#39835335">prev</a><span>|</span><a href="#39835913">next</a><span>|</span><label class="collapse" for="c-39834885">[-]</label><label class="expand" for="c-39834885">[1 more]</label></div><br/><div class="children"><div class="content">Link to the paper: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.18828" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.18828</a></div><br/></div></div><div id="39835913" class="c"><input type="checkbox" id="c-39835913" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#39834885">prev</a><span>|</span><a href="#39835578">next</a><span>|</span><label class="collapse" for="c-39835913">[-]</label><label class="expand" for="c-39835913">[1 more]</label></div><br/><div class="children"><div class="content">30 times faster <i>than SD1.5</i>.<p>Which is in the same broad neighborhood as existing Stable Diffusion 1.5 LCM (and similar to the speedup, compared to SDXL, for the SDXL LCM, Turbo, and Lightning models.)</div><br/></div></div><div id="39835578" class="c"><input type="checkbox" id="c-39835578" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#39835913">prev</a><span>|</span><a href="#39835130">next</a><span>|</span><label class="collapse" for="c-39835578">[-]</label><label class="expand" for="c-39835578">[1 more]</label></div><br/><div class="children"><div class="content">Article is only talking about 1 step generation. It doesn&#x27;t anything if 2 steps improve the image at all. The images look good enough but not as good as 30-50 step generation by SD. The cat in water is much clear example of that.</div><br/></div></div><div id="39835130" class="c"><input type="checkbox" id="c-39835130" checked=""/><div class="controls bullet"><span class="by">bl0b</span><span>|</span><a href="#39835578">prev</a><span>|</span><a href="#39836148">next</a><span>|</span><label class="collapse" for="c-39835130">[-]</label><label class="expand" for="c-39835130">[3 more]</label></div><br/><div class="children"><div class="content">Am I missing it or is the source code not available?</div><br/><div id="39835487" class="c"><input type="checkbox" id="c-39835487" checked=""/><div class="controls bullet"><span class="by">geor9e</span><span>|</span><a href="#39835130">parent</a><span>|</span><a href="#39836148">next</a><span>|</span><label class="collapse" for="c-39835487">[-]</label><label class="expand" for="c-39835487">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think they open sourced it. Thinking back, most AI breakthrough papers I&#x27;ve read don&#x27;t include source code unfortunately. Researchers want their names out there explaining what they did and that they did it first, but MIT might want to license the implementation IP or Adobe (sounds like their interns discovered this during a summer) lawyers might be hanging onto it for a business edge.</div><br/><div id="39835567" class="c"><input type="checkbox" id="c-39835567" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#39835130">root</a><span>|</span><a href="#39835487">parent</a><span>|</span><a href="#39836148">next</a><span>|</span><label class="collapse" for="c-39835567">[-]</label><label class="expand" for="c-39835567">[1 more]</label></div><br/><div class="children"><div class="content">Pretty ironic given this comment at the end of the page<p>&gt; While image generators like DALL-E and Meta AI&#x27;s Imagine can produce extremely impressive results, these groups are highly protective of their technology and jealously guard it from curious public eyes. Meanwhile, you can go read about MIT&#x27;s findings at this link.[0]<p>[0] <a href="https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;" rel="nofollow">https:&#x2F;&#x2F;tianweiy.github.io&#x2F;dmd&#x2F;</a></div><br/></div></div></div></div></div></div><div id="39836148" class="c"><input type="checkbox" id="c-39836148" checked=""/><div class="controls bullet"><span class="by">aussieguy1234</span><span>|</span><a href="#39835130">prev</a><span>|</span><a href="#39835523">next</a><span>|</span><label class="collapse" for="c-39836148">[-]</label><label class="expand" for="c-39836148">[1 more]</label></div><br/><div class="children"><div class="content">Given the speed increase, how much work would be needed to create videos?</div><br/></div></div><div id="39835523" class="c"><input type="checkbox" id="c-39835523" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#39836148">prev</a><span>|</span><a href="#39836583">next</a><span>|</span><label class="collapse" for="c-39835523">[-]</label><label class="expand" for="c-39835523">[1 more]</label></div><br/><div class="children"><div class="content">There are so many similar diffusion model distillation techniques these days that it&#x27;s become hard to tell the difference between them, this is probably the fourth example I&#x27;ve seen that uses adversarial loss to distill the model, the others being UFOgen, some other work by StabilityAI on SDXL-turbo and similar, SDXL-Lightning by ByteDance. I found this blog page that explains some of the differences: <a href="https:&#x2F;&#x2F;sander.ai&#x2F;2024&#x2F;02&#x2F;28&#x2F;paradox.html" rel="nofollow">https:&#x2F;&#x2F;sander.ai&#x2F;2024&#x2F;02&#x2F;28&#x2F;paradox.html</a></div><br/></div></div><div id="39836583" class="c"><input type="checkbox" id="c-39836583" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#39835523">prev</a><span>|</span><a href="#39835183">next</a><span>|</span><label class="collapse" for="c-39836583">[-]</label><label class="expand" for="c-39836583">[1 more]</label></div><br/><div class="children"><div class="content">I am waiting for the day i can hook up my webcam and do some live video to video :)</div><br/></div></div><div id="39835183" class="c"><input type="checkbox" id="c-39835183" checked=""/><div class="controls bullet"><span class="by">FrustratedMonky</span><span>|</span><a href="#39836583">prev</a><span>|</span><a href="#39835575">next</a><span>|</span><label class="collapse" for="c-39835183">[-]</label><label class="expand" for="c-39835183">[11 more]</label></div><br/><div class="children"><div class="content">Makes me wonder that on any given day someone could find way to improve something, and OpenAI value will evaporate quickly.<p>Seems like these startups with high valuations, are more tenuous even than the startups of years past.</div><br/><div id="39835324" class="c"><input type="checkbox" id="c-39835324" checked=""/><div class="controls bullet"><span class="by">BadHumans</span><span>|</span><a href="#39835183">parent</a><span>|</span><a href="#39835233">next</a><span>|</span><label class="collapse" for="c-39835324">[-]</label><label class="expand" for="c-39835324">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI&#x27;s value doesn&#x27;t just come from their tech. Copyright Shield is a deal closer from business types I have spoken to. Telling a company, &quot;if anyone we took data from has a problem they have to deal with our lawyers and not you&quot; is music because what companies want most is stability and reliance. It&#x27;s the entire reason SLAs are such a big deal in B2B.</div><br/></div></div><div id="39835233" class="c"><input type="checkbox" id="c-39835233" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#39835183">parent</a><span>|</span><a href="#39835324">prev</a><span>|</span><a href="#39835552">next</a><span>|</span><label class="collapse" for="c-39835233">[-]</label><label class="expand" for="c-39835233">[5 more]</label></div><br/><div class="children"><div class="content">There&#x27;s more to startup value that whether or not they&#x27;ve implemented the latest nifty trick into their models. Their moat is architecture, research, distribution, design, and scale. Have all the local LLM hacks based off Llama 2 and the like done anything to diminish OpenAI&#x27;s value?</div><br/><div id="39835274" class="c"><input type="checkbox" id="c-39835274" checked=""/><div class="controls bullet"><span class="by">aurareturn</span><span>|</span><a href="#39835183">root</a><span>|</span><a href="#39835233">parent</a><span>|</span><a href="#39835552">next</a><span>|</span><label class="collapse" for="c-39835274">[-]</label><label class="expand" for="c-39835274">[4 more]</label></div><br/><div class="children"><div class="content">I would say it has. If no one could demonstrate even GPT3.5 capabilities, then OpenAI could be worth a few hundred billion more in private valuations.<p>But multiple vendors have already demonstrated viable alternatives.</div><br/><div id="39835776" class="c"><input type="checkbox" id="c-39835776" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#39835183">root</a><span>|</span><a href="#39835274">parent</a><span>|</span><a href="#39835552">next</a><span>|</span><label class="collapse" for="c-39835776">[-]</label><label class="expand" for="c-39835776">[3 more]</label></div><br/><div class="children"><div class="content">Their valuation tripled to 80 billion in 10 months. I&#x27;m pretty sure they&#x27;re not losing much to open source</div><br/><div id="39835838" class="c"><input type="checkbox" id="c-39835838" checked=""/><div class="controls bullet"><span class="by">aurareturn</span><span>|</span><a href="#39835183">root</a><span>|</span><a href="#39835776">parent</a><span>|</span><a href="#39835552">next</a><span>|</span><label class="collapse" for="c-39835838">[-]</label><label class="expand" for="c-39835838">[2 more]</label></div><br/><div class="children"><div class="content">It gives an idea in investors&#x27; minds that OpenAI&#x27;s models can be matched or be &quot;good enough&quot; by open source models.</div><br/><div id="39835985" class="c"><input type="checkbox" id="c-39835985" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#39835183">root</a><span>|</span><a href="#39835838">parent</a><span>|</span><a href="#39835552">next</a><span>|</span><label class="collapse" for="c-39835985">[-]</label><label class="expand" for="c-39835985">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI has been at least one year ahead of everyone else in everything they have released do far. And there’s no sign they are stopping any time soon (e.g. GPT5 is expected this year).</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39835552" class="c"><input type="checkbox" id="c-39835552" checked=""/><div class="controls bullet"><span class="by">error9348</span><span>|</span><a href="#39835183">parent</a><span>|</span><a href="#39835233">prev</a><span>|</span><a href="#39835234">next</a><span>|</span><label class="collapse" for="c-39835552">[-]</label><label class="expand" for="c-39835552">[1 more]</label></div><br/><div class="children"><div class="content">Could be. Could also be that LLM is to OpenAI what information retrieval is to Google. A lot is publicly known in the information retrieval space, but google still dominates.</div><br/></div></div><div id="39835234" class="c"><input type="checkbox" id="c-39835234" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39835183">parent</a><span>|</span><a href="#39835552">prev</a><span>|</span><a href="#39835423">next</a><span>|</span><label class="collapse" for="c-39835234">[-]</label><label class="expand" for="c-39835234">[2 more]</label></div><br/><div class="children"><div class="content">Also Meta can spend billions building their own models and release it for free to kill your business.</div><br/><div id="39836144" class="c"><input type="checkbox" id="c-39836144" checked=""/><div class="controls bullet"><span class="by">aussieguy1234</span><span>|</span><a href="#39835183">root</a><span>|</span><a href="#39835234">parent</a><span>|</span><a href="#39835423">next</a><span>|</span><label class="collapse" for="c-39836144">[-]</label><label class="expand" for="c-39836144">[1 more]</label></div><br/><div class="children"><div class="content">And people will for sure use them to start new startups</div><br/></div></div></div></div><div id="39835423" class="c"><input type="checkbox" id="c-39835423" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#39835183">parent</a><span>|</span><a href="#39835234">prev</a><span>|</span><a href="#39835575">next</a><span>|</span><label class="collapse" for="c-39835423">[-]</label><label class="expand" for="c-39835423">[1 more]</label></div><br/><div class="children"><div class="content">Safe to say that FedEx has had to add another flight or two to carry documents from OpenAI to the USPTO.</div><br/></div></div></div></div><div id="39835644" class="c"><input type="checkbox" id="c-39835644" checked=""/><div class="controls bullet"><span class="by">th0ma5</span><span>|</span><a href="#39835575">prev</a><span>|</span><a href="#39835275">next</a><span>|</span><label class="collapse" for="c-39835644">[-]</label><label class="expand" for="c-39835644">[1 more]</label></div><br/><div class="children"><div class="content">I think it is wild that &quot;good&quot; outputs are always some of the most uncanny imagery. Sure it is better than older versions, but &quot;photorealistic&quot; only makes sense if you are describing a photo to someone who can&#x27;t see. I know it&#x27;s &quot;early&quot; but they don&#x27;t deserve this praise. It is cool they can assemble things but it really is a very low bar compared to reality. I know non creative people don&#x27;t care but audiences care.</div><br/></div></div><div id="39835275" class="c"><input type="checkbox" id="c-39835275" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#39835644">prev</a><span>|</span><label class="collapse" for="c-39835275">[-]</label><label class="expand" for="c-39835275">[1 more]</label></div><br/><div class="children"><div class="content">Diffusion models are exceptionally rich troves of statistical information. You just have to find it. The model will take any random noise and denoise of a bit. By guiding the denoising process, you can speed it up or improve the output tremendously.</div><br/></div></div></div></div></div></div></div></body></html>