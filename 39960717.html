<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712566861305" as="style"/><link rel="stylesheet" href="styles.css?v=1712566861305"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2404.02258">Mixture-of-Depths: Dynamically allocating compute in transformers</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>milliondreams</span> | <span>65 comments</span></div><br/><div><div id="39961814" class="c"><input type="checkbox" id="c-39961814" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39966339">next</a><span>|</span><label class="collapse" for="c-39961814">[-]</label><label class="expand" for="c-39961814">[35 more]</label></div><br/><div class="children"><div class="content">I think more complicated routing is absolutely going to become more common.<p>Specifically, I think at some point we are going to move to recursive routing, ie. pass back through a set of experts again. In the future, &#x27;chain-of-thought&#x27; will happen internal to the model recursively</div><br/><div id="39962245" class="c"><input type="checkbox" id="c-39962245" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#39961814">parent</a><span>|</span><a href="#39962719">next</a><span>|</span><label class="collapse" for="c-39962245">[-]</label><label class="expand" for="c-39962245">[15 more]</label></div><br/><div class="children"><div class="content">We can name these hypothetical objects Recursive Neural Networks.</div><br/><div id="39962437" class="c"><input type="checkbox" id="c-39962437" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39962245">parent</a><span>|</span><a href="#39963938">next</a><span>|</span><label class="collapse" for="c-39962437">[-]</label><label class="expand" for="c-39962437">[12 more]</label></div><br/><div class="children"><div class="content">i know you&#x27;re jesting but RNNs are recursive along the sequence length where I am describing recursion along the depth.</div><br/><div id="39966277" class="c"><input type="checkbox" id="c-39966277" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39962437">parent</a><span>|</span><a href="#39963905">next</a><span>|</span><label class="collapse" for="c-39966277">[-]</label><label class="expand" for="c-39966277">[1 more]</label></div><br/><div class="children"><div class="content">Depthwise RNN?</div><br/></div></div><div id="39963905" class="c"><input type="checkbox" id="c-39963905" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39962437">parent</a><span>|</span><a href="#39966277">prev</a><span>|</span><a href="#39963938">next</a><span>|</span><label class="collapse" for="c-39963905">[-]</label><label class="expand" for="c-39963905">[10 more]</label></div><br/><div class="children"><div class="content">Like decode the next token, then adjust what you&#x27;re paying attention to, then decode it again?</div><br/><div id="39964701" class="c"><input type="checkbox" id="c-39964701" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963905">parent</a><span>|</span><a href="#39964017">next</a><span>|</span><label class="collapse" for="c-39964701">[-]</label><label class="expand" for="c-39964701">[8 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t it the only way to, say,understand a pun?</div><br/><div id="39964782" class="c"><input type="checkbox" id="c-39964782" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39964701">parent</a><span>|</span><a href="#39964017">next</a><span>|</span><label class="collapse" for="c-39964782">[-]</label><label class="expand" for="c-39964782">[7 more]</label></div><br/><div class="children"><div class="content">That is exactly how LLM inference is performed, so I&#x27;m being cheeky (I&#x27;m 99% sure anyone proposing anything in this thread is someone handwaving based on limited understanding)</div><br/><div id="39965078" class="c"><input type="checkbox" id="c-39965078" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39964782">parent</a><span>|</span><a href="#39964017">next</a><span>|</span><label class="collapse" for="c-39965078">[-]</label><label class="expand" for="c-39965078">[6 more]</label></div><br/><div class="children"><div class="content">You would be wrong, but that is fine. Been working with attention since 2018.<p>Why assume I know little and leave snarky comments (and basically a repetition of the prior joke at that, subbing RNN for transformer)?</div><br/><div id="39965234" class="c"><input type="checkbox" id="c-39965234" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39965078">parent</a><span>|</span><a href="#39964017">next</a><span>|</span><label class="collapse" for="c-39965234">[-]</label><label class="expand" for="c-39965234">[5 more]</label></div><br/><div class="children"><div class="content">To playfully invite for you to participate in conversation further, so that I may humbly learn from you. &quot;I don&#x27;t know what you&#x27;re talking about&quot; seemed too spartan and austere and aggressive, and you reciprocated politely, if again sparsely, when the other person playfully invited you to elaborate.</div><br/><div id="39965585" class="c"><input type="checkbox" id="c-39965585" checked=""/><div class="controls bullet"><span class="by">webmaven</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39965234">parent</a><span>|</span><a href="#39964017">next</a><span>|</span><label class="collapse" for="c-39965585">[-]</label><label class="expand" for="c-39965585">[4 more]</label></div><br/><div class="children"><div class="content">Well, you&#x27;ve now made your original intent specific, but in case you didn&#x27;t draw the requisite lesson I&#x27;ll make that explicit.<p>Because text has less bandwidth than almost any other medium, certain forms of humor are much more likely to be understood (in this case, your &quot;gentle playfulness&quot; was taken to be snark, sarcasm, and point scoring).<p>If you insist on using this and similar forms of humor that, ordinarily, depend quite strongly on intonation to convey intent, you&#x27;ll have to be <i>much</i> more explicit to avoid being misunderstood. You are going to have actually state your intent explicitly as part of your communication. This need not entirely destroy the humor, for example, you might try something like this:<p>And so I say to you (playfully, sir, playfully): etc.<p>Or this:<p>Yadda yadda yadda. (I kid, I kid!)<p>The Internet-native forms of this are the humble ;-) or the newer j&#x2F;k, but I find that it is all too easy to overlook a 3-character sequence, particularly if the passage being so marked is even as long as a single paragraph, but they can serve their purpose when used for the commonplace one-liner.</div><br/><div id="39966324" class="c"><input type="checkbox" id="c-39966324" checked=""/><div class="controls bullet"><span class="by">anamax</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39965585">parent</a><span>|</span><a href="#39966361">next</a><span>|</span><label class="collapse" for="c-39966324">[-]</label><label class="expand" for="c-39966324">[1 more]</label></div><br/><div class="children"><div class="content">&quot;blah, blah, blah&quot; can be an expression of scornful boredom or the utterance of a vampire.</div><br/></div></div><div id="39966361" class="c"><input type="checkbox" id="c-39966361" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39965585">parent</a><span>|</span><a href="#39966324">prev</a><span>|</span><a href="#39966267">next</a><span>|</span><label class="collapse" for="c-39966361">[-]</label><label class="expand" for="c-39966361">[1 more]</label></div><br/><div class="children"><div class="content">You are painfully boring</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39963938" class="c"><input type="checkbox" id="c-39963938" checked=""/><div class="controls bullet"><span class="by">conradev</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39962245">parent</a><span>|</span><a href="#39962437">prev</a><span>|</span><a href="#39966123">next</a><span>|</span><label class="collapse" for="c-39963938">[-]</label><label class="expand" for="c-39963938">[1 more]</label></div><br/><div class="children"><div class="content">Yep: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.13048" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.13048</a></div><br/></div></div><div id="39966123" class="c"><input type="checkbox" id="c-39966123" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39962245">parent</a><span>|</span><a href="#39963938">prev</a><span>|</span><a href="#39962719">next</a><span>|</span><label class="collapse" for="c-39966123">[-]</label><label class="expand" for="c-39966123">[1 more]</label></div><br/><div class="children"><div class="content">We did: <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Recursive_neural_network" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Recursive_neural_network</a></div><br/></div></div></div></div><div id="39962719" class="c"><input type="checkbox" id="c-39962719" checked=""/><div class="controls bullet"><span class="by">miven</span><span>|</span><a href="#39961814">parent</a><span>|</span><a href="#39962245">prev</a><span>|</span><a href="#39965452">next</a><span>|</span><label class="collapse" for="c-39962719">[-]</label><label class="expand" for="c-39962719">[1 more]</label></div><br/><div class="children"><div class="content">What you describe here sounds a little like the line of work centered around Universal Transformers, which basically process the input embeddings through a single transformer block multiple times with a separate module deciding when the embeddings have been cooked enough and can be pulled out of the oven so to speak.<p>Even more in line with the idea of &quot;experts&quot; there&#x27;s a paper from last year on Sparse Universal Transformers in which they combine a universal transformer with sparse mixture of experts, so it&#x27;s up to the gating mechanism to decide which transformer blocks and in which order are to be used in shaping the embeddings.<p>This really isn&#x27;t my specialty but from what I gathered these are tricky to train properly, and require more overall compute during inference to reach comparable results to their vanilla transformer counterparts. It&#x27;s an interesting direction nonetheless, having an upper bound on the number of computation steps per token is, in my opinion, one of the major downsides of the classical transformer architecture.</div><br/></div></div><div id="39965452" class="c"><input type="checkbox" id="c-39965452" checked=""/><div class="controls bullet"><span class="by">rfdearborn</span><span>|</span><a href="#39961814">parent</a><span>|</span><a href="#39962719">prev</a><span>|</span><a href="#39963347">next</a><span>|</span><label class="collapse" for="c-39965452">[-]</label><label class="expand" for="c-39965452">[1 more]</label></div><br/><div class="children"><div class="content">The trendline is definitely toward increasing dynamic routing, but I suspect it&#x27;s more so that MoE&#x2F;MoD&#x2F;MoDE enable models to embed additional facts with less superposition within their weights than enable deeper reasoning. Instead I expect deeper reasoning will come through token-wise dynamism rather than layer-wise -- e.g., this recent Quiet-STaR paper in which the model outputs throwaway rationale tokens: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.09629" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.09629</a></div><br/></div></div><div id="39963347" class="c"><input type="checkbox" id="c-39963347" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#39961814">parent</a><span>|</span><a href="#39965452">prev</a><span>|</span><a href="#39963304">next</a><span>|</span><label class="collapse" for="c-39963347">[-]</label><label class="expand" for="c-39963347">[6 more]</label></div><br/><div class="children"><div class="content">I think the reason this hasn&#x27;t been done is you have no way to decide how many recursions are necessary at train time.<p>And if you pick a random number&#x2F;try many different levels of recursion, you &#x27;blur&#x27; the output.   Ie. the output of a layer doesn&#x27;t know if it should be outputting info important for the final result, or the output that is the best possible input to another round of recursion.</div><br/><div id="39967485" class="c"><input type="checkbox" id="c-39967485" checked=""/><div class="controls bullet"><span class="by">Nesco</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963347">parent</a><span>|</span><a href="#39963442">next</a><span>|</span><label class="collapse" for="c-39967485">[-]</label><label class="expand" for="c-39967485">[1 more]</label></div><br/><div class="children"><div class="content">I have been thinking about this topic for some time. It might be done using the energy of the token. If it&#x27;s still higher than an energy limit, then process it again, and increase the energy limit. 
The energy could be computed using log-sum-exp: <a href="https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=Hkxzx0NtDB" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=Hkxzx0NtDB</a></div><br/></div></div><div id="39963442" class="c"><input type="checkbox" id="c-39963442" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963347">parent</a><span>|</span><a href="#39967485">prev</a><span>|</span><a href="#39963753">next</a><span>|</span><label class="collapse" for="c-39963442">[-]</label><label class="expand" for="c-39963442">[2 more]</label></div><br/><div class="children"><div class="content">Yes, I think training this model would be hard. Perhaps something akin to how MoEs are trained where you impose some sort of loss distribution to encourage equitable routing, but for recursion.</div><br/><div id="39967004" class="c"><input type="checkbox" id="c-39967004" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963442">parent</a><span>|</span><a href="#39963753">next</a><span>|</span><label class="collapse" for="c-39967004">[-]</label><label class="expand" for="c-39967004">[1 more]</label></div><br/><div class="children"><div class="content">Look at the human brain for useful analogies?<p>The default mode network does recursive&#x2F;looping processing in the absence of external stimuli and world interaction. Multiple separate modules outside of the network are responsible for stopping and regulating this activity.</div><br/></div></div></div></div><div id="39963753" class="c"><input type="checkbox" id="c-39963753" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963347">parent</a><span>|</span><a href="#39963442">prev</a><span>|</span><a href="#39964270">next</a><span>|</span><label class="collapse" for="c-39963753">[-]</label><label class="expand" for="c-39963753">[1 more]</label></div><br/><div class="children"><div class="content">You could just learn the right estimated number of recursions, also passing &#x27;backtracking&#x27;&#x2F;&#x27;state&#x27; information at the next nested level. Kind of like how state space models encode extractible information via a basis function representation, you could encode extractible recursion state information into the embedding. See also transformers that can learn to recognize n-deep balanced parentheses (Dyck-n languages)</div><br/></div></div><div id="39964270" class="c"><input type="checkbox" id="c-39964270" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963347">parent</a><span>|</span><a href="#39963753">prev</a><span>|</span><a href="#39963304">next</a><span>|</span><label class="collapse" for="c-39964270">[-]</label><label class="expand" for="c-39964270">[1 more]</label></div><br/><div class="children"><div class="content">This is actually how EfficientNet trains, using random truncation of the network during training. It does just fine... The game is that each layer needs to get as close as it can to good output, improving in the previous activation quality.</div><br/></div></div></div></div><div id="39963304" class="c"><input type="checkbox" id="c-39963304" checked=""/><div class="controls bullet"><span class="by">imranq</span><span>|</span><a href="#39961814">parent</a><span>|</span><a href="#39963347">prev</a><span>|</span><a href="#39965975">next</a><span>|</span><label class="collapse" for="c-39963304">[-]</label><label class="expand" for="c-39963304">[6 more]</label></div><br/><div class="children"><div class="content">Attention is basically routing, these other routing schemes put a less fine-grained choice for the model, which potentially makes it easier to train</div><br/><div id="39963315" class="c"><input type="checkbox" id="c-39963315" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963304">parent</a><span>|</span><a href="#39965975">next</a><span>|</span><label class="collapse" for="c-39963315">[-]</label><label class="expand" for="c-39963315">[5 more]</label></div><br/><div class="children"><div class="content">How is attention basically routing?</div><br/><div id="39963746" class="c"><input type="checkbox" id="c-39963746" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963315">parent</a><span>|</span><a href="#39964653">next</a><span>|</span><label class="collapse" for="c-39963746">[-]</label><label class="expand" for="c-39963746">[2 more]</label></div><br/><div class="children"><div class="content">It routes values based on linear combinations taken from the attention map.</div><br/><div id="39964028" class="c"><input type="checkbox" id="c-39964028" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963746">parent</a><span>|</span><a href="#39964653">next</a><span>|</span><label class="collapse" for="c-39964028">[-]</label><label class="expand" for="c-39964028">[1 more]</label></div><br/><div class="children"><div class="content">But all of those values are created using an MLP with the same parameters, so there is no routing to different parameters.</div><br/></div></div></div></div><div id="39964653" class="c"><input type="checkbox" id="c-39964653" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39963315">parent</a><span>|</span><a href="#39963746">prev</a><span>|</span><a href="#39965975">next</a><span>|</span><label class="collapse" for="c-39964653">[-]</label><label class="expand" for="c-39964653">[2 more]</label></div><br/><div class="children"><div class="content">Think of it like an edge flow matrix</div><br/><div id="39964737" class="c"><input type="checkbox" id="c-39964737" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39964653">parent</a><span>|</span><a href="#39965975">next</a><span>|</span><label class="collapse" for="c-39964737">[-]</label><label class="expand" for="c-39964737">[1 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t clarify it for me. The same parameters are being used for every layer for every token. Yes, there is this differentiable lookup in attention like in MoE - but routing is about more than just differentiable lookup, it is about selecting on <i>parameters</i> not state.</div><br/></div></div></div></div></div></div></div></div><div id="39965975" class="c"><input type="checkbox" id="c-39965975" checked=""/><div class="controls bullet"><span class="by">mountainriver</span><span>|</span><a href="#39961814">parent</a><span>|</span><a href="#39963304">prev</a><span>|</span><a href="#39962345">next</a><span>|</span><label class="collapse" for="c-39965975">[-]</label><label class="expand" for="c-39965975">[2 more]</label></div><br/><div class="children"><div class="content">Most of the original MoE implementations around LLMs were in fact recursive</div><br/><div id="39965994" class="c"><input type="checkbox" id="c-39965994" checked=""/><div class="controls bullet"><span class="by">rajnathani</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39965975">parent</a><span>|</span><a href="#39962345">next</a><span>|</span><label class="collapse" for="c-39965994">[-]</label><label class="expand" for="c-39965994">[1 more]</label></div><br/><div class="children"><div class="content">Could you please elaborate?</div><br/></div></div></div></div><div id="39962345" class="c"><input type="checkbox" id="c-39962345" checked=""/><div class="controls bullet"><span class="by">digdugdirk</span><span>|</span><a href="#39961814">parent</a><span>|</span><a href="#39965975">prev</a><span>|</span><a href="#39966339">next</a><span>|</span><label class="collapse" for="c-39962345">[-]</label><label class="expand" for="c-39962345">[3 more]</label></div><br/><div class="children"><div class="content">See, this is where my understanding of LLMs breaks down. I can understand one token going through the model, but I can&#x27;t understand a model that has different &quot;experts&quot; internally.<p>Do you have any resources or links to help explain that concept?</div><br/><div id="39965304" class="c"><input type="checkbox" id="c-39965304" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39962345">parent</a><span>|</span><a href="#39962429">next</a><span>|</span><label class="collapse" for="c-39965304">[-]</label><label class="expand" for="c-39965304">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;mixture of experts&quot; goal is to add more parameters to the model to make it more powerful, without requiring any more compute. The way this is done is by having sections of the model (&quot;experts&quot;) that are in parallel with each other, and each token only going through one of them. Think of it like a multi-lane highway with a toll booth on each lane - each car only drives on one lane rather than using them all, so only pays one toll.<p>The name &quot;experts&quot; is a bit misleading, since each expert (&quot;highway lane&quot;) is not really specialized in any obviously meaningful way. There is a routing&#x2F;gating component in front of the experts that chooses on a token by token basis (not sentence by sentence!) which &quot;expert&quot; to route the token to, with the goal of roughly load balancing between the experts so that they all see the same number of tokens, and the parameters in each expert are therefore all equally utilized.<p>The fact that the tokens in a sentence will be somewhat arbitrarily sent through different &quot;experts&quot; makes it an odd kind of expertise - not directly related to the sentence as a whole! There has been experimentation with a whole bunch of routing (expert selection) schemes.</div><br/></div></div><div id="39962429" class="c"><input type="checkbox" id="c-39962429" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#39961814">root</a><span>|</span><a href="#39962345">parent</a><span>|</span><a href="#39965304">prev</a><span>|</span><a href="#39966339">next</a><span>|</span><label class="collapse" for="c-39962429">[-]</label><label class="expand" for="c-39962429">[1 more]</label></div><br/><div class="children"><div class="content">It is still just one token going through the model.<p>I actually think mixture-of-expert is a bit of a misnomer, the &#x27;experts&#x27; do not really necessarily have super distinct expertise. Think of it more as how neurons activate in the brain - your entire brain doesn&#x27;t light up for every query, now in neural networks the same thing happens (it doesn&#x27;t fully light up for every query).<p>Don&#x27;t really know a resource besides the seminal Noam Shazeer paper, sorry - I&#x27;m sure others have higher-level.</div><br/></div></div></div></div></div></div><div id="39966339" class="c"><input type="checkbox" id="c-39966339" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#39961814">prev</a><span>|</span><a href="#39967356">next</a><span>|</span><label class="collapse" for="c-39966339">[-]</label><label class="expand" for="c-39966339">[2 more]</label></div><br/><div class="children"><div class="content">Most important paper of 2024.<p>The idea that we want models not to have to use the same amount of compute for every token has been around for a while. This is the first compelling mechanism I&#x27;ve seen for doing it.<p>&gt; Equipped with these new methods, we can sample autoregressively by choosing to route tokens to or around a block based on the router’s output, which does not depend on any information from future tokens. We provide empirical evidence that this is a relatively easy auxiliary task that quickly achieves 99% accuracy.<p>Does anyone else find this is a bit surprising?</div><br/><div id="39967266" class="c"><input type="checkbox" id="c-39967266" checked=""/><div class="controls bullet"><span class="by">namibj</span><span>|</span><a href="#39966339">parent</a><span>|</span><a href="#39967356">next</a><span>|</span><label class="collapse" for="c-39967266">[-]</label><label class="expand" for="c-39967266">[1 more]</label></div><br/><div class="children"><div class="content">Sparse Universal Transformer is older and already did routing-based early termination...</div><br/></div></div></div></div><div id="39967356" class="c"><input type="checkbox" id="c-39967356" checked=""/><div class="controls bullet"><span class="by">macrolime</span><span>|</span><a href="#39966339">prev</a><span>|</span><a href="#39964780">next</a><span>|</span><label class="collapse" for="c-39967356">[-]</label><label class="expand" for="c-39967356">[1 more]</label></div><br/><div class="children"><div class="content">&quot;This is more computationally efficient than performing a full content-based lookup across an entire memory buffer for each step in the future, and could be one step towards drastically increasing the context-length available for making a prediction.&quot;<p>Is this how they get a context window of 10 million tokens? Or are they refering to even longer context windows in the future?</div><br/></div></div><div id="39964780" class="c"><input type="checkbox" id="c-39964780" checked=""/><div class="controls bullet"><span class="by">panqueca</span><span>|</span><a href="#39967356">prev</a><span>|</span><a href="#39967033">next</a><span>|</span><label class="collapse" for="c-39964780">[-]</label><label class="expand" for="c-39964780">[4 more]</label></div><br/><div class="children"><div class="content">Simplified Intro Version:<p>Imagine you have a smart assistant that can understand and process the words you say to it. Usually, this assistant pays equal attention to every word you say, no matter how important or unimportant each word is to the overall meaning of your message.<p>Now, imagine that we found a way to teach the assistant to be smarter about how it uses its &quot;brain power.&quot; Instead of giving equal attention to every word, the assistant learns to focus more on the words that are most important for understanding what you mean. It can even adjust this focus on the fly, paying more attention to different words depending on the context of your message.<p>To make sure the assistant doesn&#x27;t get overwhelmed, we also set a limit on how much total &quot;brain power&quot; it can use at any given time. It&#x27;s like giving the assistant a budget and saying, &quot;You can only spend your brain power on a certain number of words at a time.&quot; The assistant then has to decide which words are most important to focus on.<p>Even with this limit, the assistant is still flexible in how it uses its brain power. It might spend more on certain words and less on others, depending on what you&#x27;re saying. This means that while we always know the total amount of brain power the assistant is using, it can adapt to different situations and prioritize what&#x27;s most important.<p>When we teach the assistant using this method, it not only learns to focus its attention intelligently but also does so very efficiently. It can understand you just as well as an assistant that pays equal attention to every word, but it uses less brain power overall. This makes the assistant much faster at responding to you and processing new information.</div><br/><div id="39966330" class="c"><input type="checkbox" id="c-39966330" checked=""/><div class="controls bullet"><span class="by">dannyw</span><span>|</span><a href="#39964780">parent</a><span>|</span><a href="#39965323">next</a><span>|</span><label class="collapse" for="c-39966330">[-]</label><label class="expand" for="c-39966330">[2 more]</label></div><br/><div class="children"><div class="content">I understand this is ELI5, but doesn’t attention already do this, in the way you described? It pays specific focus to the most contextual words in the prior sequence.</div><br/><div id="39966524" class="c"><input type="checkbox" id="c-39966524" checked=""/><div class="controls bullet"><span class="by">xcv123</span><span>|</span><a href="#39964780">root</a><span>|</span><a href="#39966330">parent</a><span>|</span><a href="#39965323">next</a><span>|</span><label class="collapse" for="c-39966524">[-]</label><label class="expand" for="c-39966524">[1 more]</label></div><br/><div class="children"><div class="content">The way I understood it is that for each token, the attention mechanism itself consumes a fixed amount of processor time.<p>The innovation here is to prioritize tokens so that some tokens have more or less processor time.</div><br/></div></div></div></div></div></div><div id="39967033" class="c"><input type="checkbox" id="c-39967033" checked=""/><div class="controls bullet"><span class="by">yair99dd</span><span>|</span><a href="#39964780">prev</a><span>|</span><a href="#39962766">next</a><span>|</span><label class="collapse" for="c-39967033">[-]</label><label class="expand" for="c-39967033">[1 more]</label></div><br/><div class="children"><div class="content">hu-po does in-depth live-stream reviews of AI papers.<p>highly recommended, here is his take on the mixture-of-depths paper discussed. 
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Teru_qIdB8Y" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Teru_qIdB8Y</a></div><br/></div></div><div id="39962766" class="c"><input type="checkbox" id="c-39962766" checked=""/><div class="controls bullet"><span class="by">mattmcdonagh</span><span>|</span><a href="#39967033">prev</a><span>|</span><a href="#39961518">next</a><span>|</span><label class="collapse" for="c-39962766">[-]</label><label class="expand" for="c-39962766">[2 more]</label></div><br/><div class="children"><div class="content">I wrote up a bit about it here, from what I could piece together:<p><a href="https:&#x2F;&#x2F;lifeinthesingularity.com&#x2F;p&#x2F;googles-breakthroughs-in-ai-design" rel="nofollow">https:&#x2F;&#x2F;lifeinthesingularity.com&#x2F;p&#x2F;googles-breakthroughs-in-...</a></div><br/><div id="39965487" class="c"><input type="checkbox" id="c-39965487" checked=""/><div class="controls bullet"><span class="by">datascienced</span><span>|</span><a href="#39962766">parent</a><span>|</span><a href="#39961518">next</a><span>|</span><label class="collapse" for="c-39965487">[-]</label><label class="expand" for="c-39965487">[1 more]</label></div><br/><div class="children"><div class="content">Nice writing. Reminds me of New Scientist style. (I like NS so that is a compliment). I think the “explain as you go along but be brief style”. Which is nice for getting a feel for the space.</div><br/></div></div></div></div><div id="39961518" class="c"><input type="checkbox" id="c-39961518" checked=""/><div class="controls bullet"><span class="by">rughouse</span><span>|</span><a href="#39962766">prev</a><span>|</span><a href="#39961764">next</a><span>|</span><label class="collapse" for="c-39961518">[-]</label><label class="expand" for="c-39961518">[3 more]</label></div><br/><div class="children"><div class="content">It’s very similar to Mixture of Experts. But instead of routing tokens to multiple experts, you &quot;deploy to a single expert which can be dynamically skipped&quot;</div><br/><div id="39962256" class="c"><input type="checkbox" id="c-39962256" checked=""/><div class="controls bullet"><span class="by">erikaww</span><span>|</span><a href="#39961518">parent</a><span>|</span><a href="#39961764">next</a><span>|</span><label class="collapse" for="c-39962256">[-]</label><label class="expand" for="c-39962256">[2 more]</label></div><br/><div class="children"><div class="content">Mixing these would be pretty cool. Further reduced compute for MoE while keeping the performance.</div><br/><div id="39962305" class="c"><input type="checkbox" id="c-39962305" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#39961518">root</a><span>|</span><a href="#39962256">parent</a><span>|</span><a href="#39961764">next</a><span>|</span><label class="collapse" for="c-39962305">[-]</label><label class="expand" for="c-39962305">[1 more]</label></div><br/><div class="children"><div class="content">In the paper they already show a mixing of these two with Mixture-of-Depths-and-Experts (MoDE).</div><br/></div></div></div></div></div></div><div id="39965211" class="c"><input type="checkbox" id="c-39965211" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#39961764">prev</a><span>|</span><a href="#39964794">next</a><span>|</span><label class="collapse" for="c-39965211">[-]</label><label class="expand" for="c-39965211">[2 more]</label></div><br/><div class="children"><div class="content">Essentially the second law of thermodynamics for neural networks.<p>Neat!</div><br/><div id="39965367" class="c"><input type="checkbox" id="c-39965367" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#39965211">parent</a><span>|</span><a href="#39964794">next</a><span>|</span><label class="collapse" for="c-39965367">[-]</label><label class="expand" for="c-39965367">[1 more]</label></div><br/><div class="children"><div class="content">Can you elaborate on this analogy?</div><br/></div></div></div></div><div id="39964794" class="c"><input type="checkbox" id="c-39964794" checked=""/><div class="controls bullet"><span class="by">maxrumpf</span><span>|</span><a href="#39965211">prev</a><span>|</span><a href="#39965740">next</a><span>|</span><label class="collapse" for="c-39964794">[-]</label><label class="expand" for="c-39964794">[3 more]</label></div><br/><div class="children"><div class="content">The abstract and the rest of the paper don&#x27;t really match imo. It&#x27;s not really allocating more to some sequences, but just introducing ~dropout. Might be different sides to the same coin, but was still a weird read.</div><br/><div id="39964908" class="c"><input type="checkbox" id="c-39964908" checked=""/><div class="controls bullet"><span class="by">adamsantoro</span><span>|</span><a href="#39964794">parent</a><span>|</span><a href="#39965734">next</a><span>|</span><label class="collapse" for="c-39964908">[-]</label><label class="expand" for="c-39964908">[1 more]</label></div><br/><div class="children"><div class="content">We spent a fair bit of effort ensuring we were accurate with the language and claims, so we&#x27;re happy to take any feedback and make updates in subsequent versions. However, I don&#x27;t see where we claim that MoD allocates more to some sequences and not others (specifically, the abstract says &quot;transformers can instead learn to dynamically allocate FLOPs (or compute) to <i>specific positions</i> in a sequence&quot;.<p>That said, it&#x27;s a pretty simple change to make the approach work in the way you describe (allocating more to some sequences and not others) by changing the group across which the top-k works. In the paper we use the time (sequence) dimension, but one could also use the batch * time dimension, which would result in asymmetric allocation across sequences</div><br/></div></div><div id="39965734" class="c"><input type="checkbox" id="c-39965734" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39964794">parent</a><span>|</span><a href="#39964908">prev</a><span>|</span><a href="#39965740">next</a><span>|</span><label class="collapse" for="c-39965734">[-]</label><label class="expand" for="c-39965734">[1 more]</label></div><br/><div class="children"><div class="content">Dropout is at train time this is at inference time. Dropout is random this is determined. Can&#x27;t compare them.</div><br/></div></div></div></div><div id="39965740" class="c"><input type="checkbox" id="c-39965740" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#39964794">prev</a><span>|</span><a href="#39963751">next</a><span>|</span><label class="collapse" for="c-39965740">[-]</label><label class="expand" for="c-39965740">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a start but it&#x27;s disappointing that half the layers still have to process every token. It seems like we ought to be able to get to 90% or even 99% savings when these models currently allocate the same compute for outputting &quot;the&quot; as they do for outputting the first digit of the answer of a complicated math problem.</div><br/><div id="39965771" class="c"><input type="checkbox" id="c-39965771" checked=""/><div class="controls bullet"><span class="by">aiddun</span><span>|</span><a href="#39965740">parent</a><span>|</span><a href="#39963751">next</a><span>|</span><label class="collapse" for="c-39965771">[-]</label><label class="expand" for="c-39965771">[2 more]</label></div><br/><div class="children"><div class="content">Speculative decoding does this to an extent - using a smaller model to generate its own predictions and putting them in the batch of the bigger model until they diverge<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;whisper-speculative-decoding" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;whisper-speculative-decoding</a></div><br/><div id="39965901" class="c"><input type="checkbox" id="c-39965901" checked=""/><div class="controls bullet"><span class="by">brrrrrm</span><span>|</span><a href="#39965740">root</a><span>|</span><a href="#39965771">parent</a><span>|</span><a href="#39963751">next</a><span>|</span><label class="collapse" for="c-39965901">[-]</label><label class="expand" for="c-39965901">[1 more]</label></div><br/><div class="children"><div class="content">It doesn’t. It simply trades compute efficiency by transposing matrix multiplications into “the future.”  It doesn’t actually save FLOPs (uses more) and doesn’t work at large batch size</div><br/></div></div></div></div></div></div><div id="39962682" class="c"><input type="checkbox" id="c-39962682" checked=""/><div class="controls bullet"><span class="by">barrenko</span><span>|</span><a href="#39963751">prev</a><span>|</span><label class="collapse" for="c-39962682">[-]</label><label class="expand" for="c-39962682">[6 more]</label></div><br/><div class="children"><div class="content">Are we going to hit bullseye?</div><br/><div id="39962842" class="c"><input type="checkbox" id="c-39962842" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#39962682">parent</a><span>|</span><label class="collapse" for="c-39962842">[-]</label><label class="expand" for="c-39962842">[5 more]</label></div><br/><div class="children"><div class="content">This only cuts compute by “up to” 50% and only during inference. Quadratic dependence on context size remains, as do the enormous memory requirements. For something to be considered a bulls eye in this space it has to offer nonlinear improvements on both of these axes, and&#x2F;or be much faster to train. Until that happens, people, including Google will continue to train bog standard MoE and dense transformers. Radical experimentation at scale is too expensive even for megacorps at this point.</div><br/><div id="39963926" class="c"><input type="checkbox" id="c-39963926" checked=""/><div class="controls bullet"><span class="by">mdale</span><span>|</span><a href="#39962682">root</a><span>|</span><a href="#39962842">parent</a><span>|</span><a href="#39963788">next</a><span>|</span><label class="collapse" for="c-39963926">[-]</label><label class="expand" for="c-39963926">[2 more]</label></div><br/><div class="children"><div class="content">Makes opportunities for smaller companies to innovative&#x2F;experiment to offer solutions &#x2F; acquisition targets where tighter inference compute requirements makes or breaks the experience but larger training cost is less of a concern (such as embedded or local runtime use cases)</div><br/><div id="39964002" class="c"><input type="checkbox" id="c-39964002" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#39962682">root</a><span>|</span><a href="#39963926">parent</a><span>|</span><a href="#39963788">next</a><span>|</span><label class="collapse" for="c-39964002">[-]</label><label class="expand" for="c-39964002">[1 more]</label></div><br/><div class="children"><div class="content">Before those opportunities are available to you, someone would need to spend a few million dollars and train a competitive model with this, and then release it under a license that allows commercial use. This is out of reach for the vast majority of smaller companies. These models only excel at large parameter counts, even for narrow problems. This is especially true in the case of MoE, which is a way to push the overall parameter count even larger without lighting up the whole thing for every token.</div><br/></div></div></div></div><div id="39963788" class="c"><input type="checkbox" id="c-39963788" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39962682">root</a><span>|</span><a href="#39962842">parent</a><span>|</span><a href="#39963926">prev</a><span>|</span><label class="collapse" for="c-39963788">[-]</label><label class="expand" for="c-39963788">[2 more]</label></div><br/><div class="children"><div class="content">Yeah all attempts at reducing complexity from quadratic to linear failed, only Mamba still has a chance, but it&#x27;s not tested on large models and only provides a speedup at for 2000+ tokens. That was to be expected as small sequences have very small memory requirements for transformers, but recursive architectures use the same hidden size. So when recurrent hidden size &gt; sequence length, the old transformer is faster.</div><br/><div id="39963955" class="c"><input type="checkbox" id="c-39963955" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#39962682">root</a><span>|</span><a href="#39963788">parent</a><span>|</span><label class="collapse" for="c-39963955">[-]</label><label class="expand" for="c-39963955">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s more subtle than that IMO. They haven&#x27;t necessarily &quot;failed&quot; - they just don&#x27;t have the &quot;superpowers&quot; that the metrics used to evaluate such systems are aimed at. E.g. no such linear method devised so far (that I know of, at least) is able to do very high recall point retrieval in long context _and_ effective in-context learning simultaneously. You get one or the other, but not both. But as far as the metrics go, high recall retrieval in long context is easier to for the researcher to demonstrate and for the observer to comprehend - a typical needle&#x2F;haystack setting is trivial to put together. It is also something that (unlike in-context learning) humans are usually very bad at, so it&#x27;s perceived as a &quot;superpower&quot; or &quot;magic&quot;. In this case e.g. Mamba being more human like due to its selective forgetfulness is currently playing against it. But whether it&#x27;s &quot;better&quot; per se will depend on the task. It&#x27;s just that we do not know how to evaluate most of the tasks yet, so people keep trying to find the proverbial keys under the lamp post, and measure what they can to make progress, and thereby keep their efforts lavishly funded.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>