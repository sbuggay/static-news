<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1734944451746" as="style"/><link rel="stylesheet" href="styles.css?v=1734944451746"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://rachelbythebay.com/w/2024/12/17/packets/">Feed readers which don&#x27;t take &quot;no&quot; for an answer</a> <span class="domain">(<a href="https://rachelbythebay.com">rachelbythebay.com</a>)</span></div><div class="subtext"><span>kencausey</span> | <span>176 comments</span></div><br/><div><div id="42486481" class="c"><input type="checkbox" id="c-42486481" checked=""/><div class="controls bullet"><span class="by">strogonoff</span><span>|</span><a href="#42486357">next</a><span>|</span><label class="collapse" for="c-42486481">[-]</label><label class="expand" for="c-42486481">[24 more]</label></div><br/><div class="children"><div class="content">A friend of mine co-runs a semi-popular semi-niche news site (for now more than a decade), and complains that recently traffic rose with bots masquerading as humans.<p>How would they know? Well, because Google, in its omniscience, started to downrank them for faking views with bots (which they do not do): it shows bot percentage in traffic stats, and it skyrocketed relative to non-bot traffic (which is now less than 50%) as they started to fall from the front page (feeding the vicious circle). Presumably, Google does not know or care it is a bot when it serves ads, but correlates it later with the metrics it has from other sites that use GA or ads.<p>Or, perhaps, Google spots the same anomalies that my friend (an old school sysadmin who pays attention to logs) did, such as the increase of traffic along with never seen before popularity among iPhone users (who are so tech savvy that they apparently do not require CSS), or users from Dallas who famously love their QQBrowser. I’m not going to list all telltale signs as the crowd here is too hype on LLMs (which is our going theory so far, it is very timely), but my friend hopes Google learns them quickly.<p>These newcomers usually fake UA, use inconspicuous Western IPs (requests from Baidu&#x2F;Tencent data center ranges do sign themselves as bots in UA), ignore robots.txt and load many pages very quickly.<p>I would assume bot traffic increase would apply to feeds, since they are of as much use for LLM training purposes.<p>My friend does not actually engage in stringent filtering like Rachel does, but I wonder how soon it becomes actually infeasible to operate a website <i>with actual original content</i> (which my friend co-writes) without either that or resorting to Cloudflare or the like for protection because of the domination of these creepy-crawlies.<p>Edit: Google already downranked them, not threatened to downrank. Also, traffic rose but did not skyrocket, but relative amount of bot traffic skyrocketed. (Presumably without downranking the traffic would actually skyrocket.)</div><br/><div id="42487167" class="c"><input type="checkbox" id="c-42487167" checked=""/><div class="controls bullet"><span class="by">afandian</span><span>|</span><a href="#42486481">parent</a><span>|</span><a href="#42487986">next</a><span>|</span><label class="collapse" for="c-42487167">[-]</label><label class="expand" for="c-42487167">[4 more]</label></div><br/><div class="children"><div class="content">Are you saying that Google down-ranked them in search engine rankings for user behaviour in AdWords? Isn&#x27;t that an abuse of monopoly? It still surprises me a little bit.</div><br/><div id="42490480" class="c"><input type="checkbox" id="c-42490480" checked=""/><div class="controls bullet"><span class="by">malfist</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42487167">parent</a><span>|</span><a href="#42491195">next</a><span>|</span><label class="collapse" for="c-42490480">[-]</label><label class="expand" for="c-42490480">[1 more]</label></div><br/><div class="children"><div class="content">Who&#x27;s going to call them on it if it is?</div><br/></div></div><div id="42491195" class="c"><input type="checkbox" id="c-42491195" checked=""/><div class="controls bullet"><span class="by">EdwardDiego</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42487167">parent</a><span>|</span><a href="#42490480">prev</a><span>|</span><a href="#42487986">next</a><span>|</span><label class="collapse" for="c-42491195">[-]</label><label class="expand" for="c-42491195">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, but then who is going to stop them acting monopolistic?<p>New administration is going to be monopoly friendly.<p>I was honestly pleased that Gaetz was nominated for AG solely because he&#x27;s big on antitrust. Or has been.</div><br/><div id="42492380" class="c"><input type="checkbox" id="c-42492380" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42491195">parent</a><span>|</span><a href="#42487986">next</a><span>|</span><label class="collapse" for="c-42492380">[-]</label><label class="expand" for="c-42492380">[1 more]</label></div><br/><div class="children"><div class="content">if you believe their words (and I can&#x27;t blame anyone who doesn&#x27;t) apparently they want to lighten regulations on everything <i>except</i> big tech. So there may be a chance all those Google&#x2F;Amazon cases will keep going on into the Trump administration.</div><br/></div></div></div></div></div></div><div id="42487986" class="c"><input type="checkbox" id="c-42487986" checked=""/><div class="controls bullet"><span class="by">m3047</span><span>|</span><a href="#42486481">parent</a><span>|</span><a href="#42487167">prev</a><span>|</span><a href="#42486947">next</a><span>|</span><label class="collapse" for="c-42487986">[-]</label><label class="expand" for="c-42487986">[7 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not that hard to dominate bots. I do it for fun, I do it for profit. Block datacenters. Run bot motels. Poison them. Lie to them. Make them have really really bad luck. Change the cost equation so that it costs them more than it costs you.<p>You&#x27;re thinking of it wrong, the seeds of the thinking error are here: &quot;I wonder how soon it becomes actually infeasible to operate a website with actual original content&quot;.<p>Bots want original content, no? So what&#x27;s the problem with giving it to them? But that&#x27;s the issue, isn&#x27;t it? Clearly, contextually, what you should be saying is &quot;I wonder how soon it becomes actually infeasible to operate a website for actual organic users&quot; or something like that. But phrased that way, I&#x27;m not sure a CDN helps (I&#x27;m not sure they don&#x27;t suffer false positives which interfere with organic traffic when they intermediate, more security theater because hangings and executions look good, look at the numbers of enemy dead).<p>Take measures that any damn fool (or at least your desired audience) can recognize.<p>Reading for comprehension, I think Rachel understands this.</div><br/><div id="42488077" class="c"><input type="checkbox" id="c-42488077" checked=""/><div class="controls bullet"><span class="by">throaway89</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42487986">parent</a><span>|</span><a href="#42486947">next</a><span>|</span><label class="collapse" for="c-42488077">[-]</label><label class="expand" for="c-42488077">[6 more]</label></div><br/><div class="children"><div class="content">what is a bot motel and how do you run one?</div><br/><div id="42488090" class="c"><input type="checkbox" id="c-42488090" checked=""/><div class="controls bullet"><span class="by">m3047</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42488077">parent</a><span>|</span><a href="#42489003">next</a><span>|</span><label class="collapse" for="c-42488090">[-]</label><label class="expand" for="c-42488090">[4 more]</label></div><br/><div class="children"><div class="content">Easy way is to implement e.g. a 4xx handler which serves content with links which generate further 4xx errors and rewrite the status code to something like 200 when sent to the requester. Load the garbage pages up with... garbage.</div><br/><div id="42488281" class="c"><input type="checkbox" id="c-42488281" checked=""/><div class="controls bullet"><span class="by">throaway89</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42488090">parent</a><span>|</span><a href="#42489003">next</a><span>|</span><label class="collapse" for="c-42488281">[-]</label><label class="expand" for="c-42488281">[3 more]</label></div><br/><div class="children"><div class="content">Thanks, and you can make money with this? Sorry I&#x27;m a total noob in this area.</div><br/><div id="42490977" class="c"><input type="checkbox" id="c-42490977" checked=""/><div class="controls bullet"><span class="by">shadowgovt</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42488281">parent</a><span>|</span><a href="#42489003">next</a><span>|</span><label class="collapse" for="c-42490977">[-]</label><label class="expand" for="c-42490977">[2 more]</label></div><br/><div class="children"><div class="content">Not really... You cost the bots money.<p>Many are trying to index the web for whatever reason. By feeding them a Library of Babel, you can clog up their storage with noise.</div><br/><div id="42491939" class="c"><input type="checkbox" id="c-42491939" checked=""/><div class="controls bullet"><span class="by">m3047</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42490977">parent</a><span>|</span><a href="#42489003">next</a><span>|</span><label class="collapse" for="c-42491939">[-]</label><label class="expand" for="c-42491939">[1 more]</label></div><br/><div class="children"><div class="content">Once in a while people pay you to do something you enjoy doing, like making people cry and wish they had a jobs flipping burgers instead. But I do it on my own systems for fun, honestly.</div><br/></div></div></div></div></div></div></div></div><div id="42489003" class="c"><input type="checkbox" id="c-42489003" checked=""/><div class="controls bullet"><span class="by">yesco</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42488077">parent</a><span>|</span><a href="#42488090">prev</a><span>|</span><a href="#42486947">next</a><span>|</span><label class="collapse" for="c-42489003">[-]</label><label class="expand" for="c-42489003">[1 more]</label></div><br/><div class="children"><div class="content">The idea is that bots are inflexible to deviations from accepted norms and can&#x27;t actually &quot;see&quot; rendered browser content. So if your generic 404, 403 error pages return a 200 status instead, with invisible links to other non accessible pages. The bots will follow the links but real users will not, trapping them in a kind of isolated labyrinth of recursive links (the urls should be slightly different though). It&#x27;s basically how a lobster trap works if you want a visual metaphor.<p>The important part here is to do this chaotically. The worst sites to scrape are buggy ones. You are, in essence, deliberately following bad practices in a way real users wouldn&#x27;t notice but would still influence bots.</div><br/></div></div></div></div></div></div><div id="42486947" class="c"><input type="checkbox" id="c-42486947" checked=""/><div class="controls bullet"><span class="by">blfr</span><span>|</span><a href="#42486481">parent</a><span>|</span><a href="#42487986">prev</a><span>|</span><a href="#42487410">next</a><span>|</span><label class="collapse" for="c-42486947">[-]</label><label class="expand" for="c-42486947">[4 more]</label></div><br/><div class="children"><div class="content">QQBrowser users from Dallas are more likely to be Chinese using a VPN than bots, I would guess.</div><br/><div id="42488001" class="c"><input type="checkbox" id="c-42488001" checked=""/><div class="controls bullet"><span class="by">m3047</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42486947">parent</a><span>|</span><a href="#42487019">next</a><span>|</span><label class="collapse" for="c-42488001">[-]</label><label class="expand" for="c-42488001">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m seeing some address ranges in the US clearly serving what must be VPN traffic from Asia, and I&#x27;m also seeing an uptick in TOR traffic looking for feeds as well as WP infra.</div><br/></div></div><div id="42487019" class="c"><input type="checkbox" id="c-42487019" checked=""/><div class="controls bullet"><span class="by">strogonoff</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42486947">parent</a><span>|</span><a href="#42488001">prev</a><span>|</span><a href="#42487410">next</a><span>|</span><label class="collapse" for="c-42487019">[-]</label><label class="expand" for="c-42487019">[2 more]</label></div><br/><div class="children"><div class="content">That much is clear, yeah. The VPN they use may not be a service advertised to public and featured in lists, however.<p>Some of the new traffic did come directly from Tencent data center IP ranges and reportedly those bots signed themselves in UA. I can’t say whether they respect robots.txt because I am told their ranges were banned along with robots.txt tightening. However, US IP bots that remain unblocked and fake UA naturally ignore robot rules.</div><br/><div id="42487961" class="c"><input type="checkbox" id="c-42487961" checked=""/><div class="controls bullet"><span class="by">thaumasiotes</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42487019">parent</a><span>|</span><a href="#42487410">next</a><span>|</span><label class="collapse" for="c-42487961">[-]</label><label class="expand" for="c-42487961">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The VPN they use may not be a service advertised to public and featured in lists, however.<p>Well, of course not, since the service is illegal.</div><br/></div></div></div></div></div></div><div id="42487410" class="c"><input type="checkbox" id="c-42487410" checked=""/><div class="controls bullet"><span class="by">BadHumans</span><span>|</span><a href="#42486481">parent</a><span>|</span><a href="#42486947">prev</a><span>|</span><a href="#42489924">next</a><span>|</span><label class="collapse" for="c-42487410">[-]</label><label class="expand" for="c-42487410">[1 more]</label></div><br/><div class="children"><div class="content">At my company we have seen a massive increase in bot traffic since LLMs have become mainstream. Blocking known OpenAI and Anthropic crawlers has decreased traffic somewhat so I agree with your theory.</div><br/></div></div><div id="42489924" class="c"><input type="checkbox" id="c-42489924" checked=""/><div class="controls bullet"><span class="by">wiseowise</span><span>|</span><a href="#42486481">parent</a><span>|</span><a href="#42487410">prev</a><span>|</span><a href="#42490900">next</a><span>|</span><label class="collapse" for="c-42489924">[-]</label><label class="expand" for="c-42489924">[1 more]</label></div><br/><div class="children"><div class="content">&gt; who are so tech savvy that they apparently do not require CSS<p>Lmao!</div><br/></div></div><div id="42490900" class="c"><input type="checkbox" id="c-42490900" checked=""/><div class="controls bullet"><span class="by">m3047</span><span>|</span><a href="#42486481">parent</a><span>|</span><a href="#42489924">prev</a><span>|</span><a href="#42486357">next</a><span>|</span><label class="collapse" for="c-42490900">[-]</label><label class="expand" for="c-42490900">[6 more]</label></div><br/><div class="children"><div class="content">Heres Crime^H^H^H^H^(ahem)Cloudflare requesting assets from one of my servers. I don&#x27;t use Cloudflare, they have no business doing this.<p><pre><code>  104.28.42.8 - - [21&#x2F;Dec&#x2F;2024:13:58:35 -0800] consulting.m3047.net &quot;GET &#x2F;apple-touch-icon-precomposed.png HTTP&#x2F;1.1&quot; 404 980 &quot;-&quot; &quot;NetworkingExtension&#x2F;8620.1.16.10.11 Network&#x2F;4277.60.255 iOS&#x2F;18.2&quot;
  104.28.42.8 - - [21&#x2F;Dec&#x2F;2024:13:58:35 -0800] consulting.m3047.net &quot;GET &#x2F;favicon.ico HTTP&#x2F;1.1&quot; 200 302 &quot;-&quot; &quot;NetworkingExtension&#x2F;8620.1.16.10.11 Network&#x2F;4277.60.255 iOS&#x2F;18.2&quot;
  104.28.42.8 - - [21&#x2F;Dec&#x2F;2024:13:58:35 -0800] consulting.m3047.net &quot;GET &#x2F;dubai-letters&#x2F;balkanized-internet.html HTTP&#x2F;1.1&quot; 200 16370 &quot;-&quot; &quot;Mozilla&#x2F;5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit&#x2F;601.2.4 (KHTML, like Gecko) Version&#x2F;9.0.1 Safari&#x2F;601.2.4 facebookexternalhit&#x2F;1.1 Facebot Twitterbot&#x2F;1.0&quot;
  104.28.42.8 - - [21&#x2F;Dec&#x2F;2024:13:58:35 -0800] consulting.m3047.net &quot;GET &#x2F;apple-touch-icon.png HTTP&#x2F;1.1&quot; 404 980 &quot;-&quot; &quot;NetworkingExtension&#x2F;8620.1.16.10.11 Network&#x2F;4277.60.255 iOS&#x2F;18.2&quot;

  # dig -x 104.28.42.8

  ; &lt;&lt;&gt;&gt; DiG 9.12.3-P1 &lt;&lt;&gt;&gt; -x 104.28.42.8
  ;; global options: +cmd
  ;; Got answer:
  ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NXDOMAIN, id: 35228
  ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1

  ;; OPT PSEUDOSECTION:
  ; EDNS: version: 0, flags:; udp: 1280
  ; COOKIE: 6b82e88bcaf538fc7ab9d44467685e82becd47ff4492b1be (good)
  ;; QUESTION SECTION:
  ;8.42.28.104.in-addr.arpa.      IN      PTR

  ;; AUTHORITY SECTION:
  28.104.in-addr.arpa.    3600    IN      SOA     cruz.ns.cloudflare.com. dns.cloudflare.com. 2288625504 10000 2400 604800 3600

  ;; Query time: 212 msec
  ;; SERVER: 127.0.0.1#53(127.0.0.1)
  ;; WHEN: Sun Dec 22 10:46:26 PST 2024
  ;; MSG SIZE  rcvd: 176
</code></pre>
Further osint left as an exercise for the reader.</div><br/><div id="42491412" class="c"><input type="checkbox" id="c-42491412" checked=""/><div class="controls bullet"><span class="by">Crosseye_Jack</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42490900">parent</a><span>|</span><a href="#42490966">next</a><span>|</span><label class="collapse" for="c-42491412">[-]</label><label class="expand" for="c-42491412">[1 more]</label></div><br/><div class="children"><div class="content">104.28.42.0&#x2F;25 Is one of the ip ranges used by Apples Private Relay (via Cloudflare)<p><a href="https:&#x2F;&#x2F;github.com&#x2F;hroost&#x2F;icloud-private-relay-iplist&#x2F;blob&#x2F;main&#x2F;ip-ranges.txt">https:&#x2F;&#x2F;github.com&#x2F;hroost&#x2F;icloud-private-relay-iplist&#x2F;blob&#x2F;m...</a><p>(There is also a list of ranges on apples site, but I forget where…)<p>Edit: found it <a href="https:&#x2F;&#x2F;mask-api.icloud.com&#x2F;egress-ip-ranges.csv" rel="nofollow">https:&#x2F;&#x2F;mask-api.icloud.com&#x2F;egress-ip-ranges.csv</a></div><br/></div></div><div id="42490966" class="c"><input type="checkbox" id="c-42490966" checked=""/><div class="controls bullet"><span class="by">shadowgovt</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42490900">parent</a><span>|</span><a href="#42491412">prev</a><span>|</span><a href="#42486357">next</a><span>|</span><label class="collapse" for="c-42490966">[-]</label><label class="expand" for="c-42490966">[4 more]</label></div><br/><div class="children"><div class="content">What is the issue with this request?</div><br/><div id="42491880" class="c"><input type="checkbox" id="c-42491880" checked=""/><div class="controls bullet"><span class="by">m3047</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42490966">parent</a><span>|</span><a href="#42491347">next</a><span>|</span><label class="collapse" for="c-42491880">[-]</label><label class="expand" for="c-42491880">[2 more]</label></div><br/><div class="children"><div class="content">&gt; What is the issue with this request?<p>I didn&#x27;t realize this was an Apple thing, but that&#x27;s fine. It changes the color of the horse and the name of the river, but the same road leads to the same destination.<p>1) There is a notion that Cloudflare is a content distribution network. The risk profile for a content distribution network is different from a VPN service. Now I know it&#x27;s a VPN service (or is it?). Changes it from &quot;seems weird and inappropriate&quot; to &quot;do I care about people relying on this? no, probably not&quot;. Cloudflare can&#x27;t be arsed to provide reverse DNS for something which is clearly not part of their CDN, or is it?<p>1.5) Is it layer 2 or application? Cloudflare runs a CDN. Correct me if I&#x27;m wrong, but the CDN is a reverse proxy is it not? Is Cloudflare caching my website&#x27;s content? Can they observe it? (It&#x27;s surprisingly hard to find a solid explanation, but they talk about &quot;proxies&quot; and &quot;decrypts the name of the website you requested&quot; and none of that adds clarity, it makes it sound more like believe what we want you want to believe.)<p>2) I don&#x27;t block incoming SYNs from Cloudflare (yet) the way I do with Amazon, and this traffic per se isn&#x27;t going to trip any mitigations here. But not all of the traffic is as benign (and it&#x27;s impressive that they&#x27;re so technically savvy they don&#x27;t need the CSS as noted elsewhere). Presumably those exit points are shared by multiple customers. Did I mention I block all incoming SYNs from Amazon?</div><br/><div id="42492162" class="c"><input type="checkbox" id="c-42492162" checked=""/><div class="controls bullet"><span class="by">Crosseye_Jack</span><span>|</span><a href="#42486481">root</a><span>|</span><a href="#42491880">parent</a><span>|</span><a href="#42491347">next</a><span>|</span><label class="collapse" for="c-42492162">[-]</label><label class="expand" for="c-42492162">[1 more]</label></div><br/><div class="children"><div class="content">&gt; and it&#x27;s impressive that they&#x27;re so technically savvy they don&#x27;t need the CSS as noted elsewhere<p>With the logs you provided, they appear to be coming from within iMessage.<p>So when someone posts a link in iMessage it will fetch the favicon(s) and the html  in order to generate a “preview” of the page with the title of the page and use one of the favicons. It doesn’t need to fetch any css files to do this.<p>Not saying bad actors don’t fetch css either, but the lack of it being fetched doesn’t mean that it’s a bad actor.<p>As for why CF don’t reverse DNS their IPs stating it’s iCloud private relay, well CF are not Apples only 3rd party egress provider (Akamai are also one that springs to mind). So if the number of providers can change at any time, the best source of information about valid egress providers is from Apple themselves.<p>But Apple do also publish these changes to geo-location databases for you to query, for example: <a href="https:&#x2F;&#x2F;www.ip2location.com&#x2F;demo&#x2F;104.28.42.8" rel="nofollow">https:&#x2F;&#x2F;www.ip2location.com&#x2F;demo&#x2F;104.28.42.8</a> lists it as iCloud Private Relay.<p>As for “are CloudFlare caching my site when ran through private relay?”, not 100% sure, I’ll have to check my own logs and cba’ed right now, but I don’t think so (it’s been a while since I ran tests on it to see how it behaved to be 100% sure right this minute.<p>But I think it would be silly of them if they did as they may not be aware of the what to cache and for who. Let’s say they cached &#x2F;profile without knowing what the server is using to determine who the logged in user is, they may false cache-hit and leak data from a previous request. When they act as your sites CDN you explicitly tell them what to cache on, but when acting as a relay (either for apple or their own warp product) for a site they are not a CDN for they are missing this info, sure they could guess, but why risk being wrong?)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42486357" class="c"><input type="checkbox" id="c-42486357" checked=""/><div class="controls bullet"><span class="by">Apreche</span><span>|</span><a href="#42486481">prev</a><span>|</span><a href="#42490135">next</a><span>|</span><label class="collapse" for="c-42486357">[-]</label><label class="expand" for="c-42486357">[9 more]</label></div><br/><div class="children"><div class="content">Feed readers should be sending the If-Modified-Since header and web sites should properly recognize it and send the 304 Unmodified response. This isn’t new tech.</div><br/><div id="42486380" class="c"><input type="checkbox" id="c-42486380" checked=""/><div class="controls bullet"><span class="by">graemep</span><span>|</span><a href="#42486357">parent</a><span>|</span><a href="#42486367">next</a><span>|</span><label class="collapse" for="c-42486380">[-]</label><label class="expand" for="c-42486380">[6 more]</label></div><br/><div class="children"><div class="content">That is exactly what the article says.</div><br/><div id="42486806" class="c"><input type="checkbox" id="c-42486806" checked=""/><div class="controls bullet"><span class="by">smallerize</span><span>|</span><a href="#42486357">root</a><span>|</span><a href="#42486380">parent</a><span>|</span><a href="#42489603">next</a><span>|</span><label class="collapse" for="c-42486806">[-]</label><label class="expand" for="c-42486806">[4 more]</label></div><br/><div class="children"><div class="content">The article implies this but doesn&#x27;t actually say it. It&#x27;s nice to have the extra detail.</div><br/><div id="42490400" class="c"><input type="checkbox" id="c-42490400" checked=""/><div class="controls bullet"><span class="by">rtpg</span><span>|</span><a href="#42486357">root</a><span>|</span><a href="#42486806">parent</a><span>|</span><a href="#42487009">next</a><span>|</span><label class="collapse" for="c-42490400">[-]</label><label class="expand" for="c-42490400">[1 more]</label></div><br/><div class="children"><div class="content">Rachel has been writing about feed readers a lot on their blog the past year (<a href="https:&#x2F;&#x2F;rachelbythebay.com&#x2F;w&#x2F;" rel="nofollow">https:&#x2F;&#x2F;rachelbythebay.com&#x2F;w&#x2F;</a> shows 21 results for &quot;feed reader&quot;), so this is part of a whole narrative.<p>If you&#x27;re interested in it, I highly recommend just reading from start to end. It&#x27;s all quite interesting (including building out a whole test service for feed readers to get scored on their behavior)</div><br/></div></div><div id="42487009" class="c"><input type="checkbox" id="c-42487009" checked=""/><div class="controls bullet"><span class="by">avg_dev</span><span>|</span><a href="#42486357">root</a><span>|</span><a href="#42486806">parent</a><span>|</span><a href="#42490400">prev</a><span>|</span><a href="#42489603">next</a><span>|</span><label class="collapse" for="c-42487009">[-]</label><label class="expand" for="c-42487009">[2 more]</label></div><br/><div class="children"><div class="content">While it might be nice if the article spelled out the header, I do believe that there is more than implication present.<p>&gt; 00:04:51 GET &#x2F;w&#x2F;atom.xml, unconditional.<p>&gt; Fulfilled with 200, 502 KB.<p>&gt; [...]<p>&gt; A 20 minute retry rate with unconditional requests is wasteful. [...]<p>And If-Modified-Since makes a request conditional. <a href="https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;HTTP&#x2F;Conditional_requests#conditional_headers" rel="nofollow">https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;HTTP&#x2F;Conditiona...</a></div><br/><div id="42487122" class="c"><input type="checkbox" id="c-42487122" checked=""/><div class="controls bullet"><span class="by">JadeNB</span><span>|</span><a href="#42486357">root</a><span>|</span><a href="#42487009">parent</a><span>|</span><a href="#42489603">next</a><span>|</span><label class="collapse" for="c-42487122">[-]</label><label class="expand" for="c-42487122">[1 more]</label></div><br/><div class="children"><div class="content">You left out a further explicit mention of conditional requests:<p>&gt;  Advised (via Retry-After header) to come back in one day since they are unwilling or unable to do conditional requests.<p>But I think it&#x27;s still unarguable that the post doesn&#x27;t <i>explicitly</i> mention If-Modified-Since, which it&#x27;s not obliged to do, but the mention of it here could be helpful to someone.  So why fuss?</div><br/></div></div></div></div></div></div><div id="42489603" class="c"><input type="checkbox" id="c-42489603" checked=""/><div class="controls bullet"><span class="by">shkkmo</span><span>|</span><a href="#42486357">root</a><span>|</span><a href="#42486380">parent</a><span>|</span><a href="#42486806">prev</a><span>|</span><a href="#42486367">next</a><span>|</span><label class="collapse" for="c-42489603">[-]</label><label class="expand" for="c-42489603">[1 more]</label></div><br/><div class="children"><div class="content">The people who already know that a &quot;conditional request&quot; means a request with an If-Modified-After header aren&#x27;t the ones who need to learn this information.</div><br/></div></div></div></div><div id="42486367" class="c"><input type="checkbox" id="c-42486367" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42486357">parent</a><span>|</span><a href="#42486380">prev</a><span>|</span><a href="#42491592">next</a><span>|</span><label class="collapse" for="c-42486367">[-]</label><label class="expand" for="c-42486367">[1 more]</label></div><br/><div class="children"><div class="content">If only people know of the standards</div><br/></div></div><div id="42491592" class="c"><input type="checkbox" id="c-42491592" checked=""/><div class="controls bullet"><span class="by">righthand</span><span>|</span><a href="#42486357">parent</a><span>|</span><a href="#42486367">prev</a><span>|</span><a href="#42490135">next</a><span>|</span><label class="collapse" for="c-42491592">[-]</label><label class="expand" for="c-42491592">[1 more]</label></div><br/><div class="children"><div class="content">Yeah but my LLM won’t generate that code.</div><br/></div></div></div></div><div id="42490135" class="c"><input type="checkbox" id="c-42490135" checked=""/><div class="controls bullet"><span class="by">shepherdjerred</span><span>|</span><a href="#42486357">prev</a><span>|</span><a href="#42486677">next</a><span>|</span><label class="collapse" for="c-42490135">[-]</label><label class="expand" for="c-42490135">[3 more]</label></div><br/><div class="children"><div class="content">I like Rachel&#x27;s writing, but I don&#x27;t understand this recent crusade against RSS readers. Sure, they should work properly and optimizations can be made to reduce bandwidth and processing power.<p>But... why not throw a CDN in front of your site and focus your energy somewhere else? I guess every problem has to be solved by someone, but this just seems like a very strange hill to die on.</div><br/><div id="42491237" class="c"><input type="checkbox" id="c-42491237" checked=""/><div class="controls bullet"><span class="by">EdwardDiego</span><span>|</span><a href="#42490135">parent</a><span>|</span><a href="#42492607">next</a><span>|</span><label class="collapse" for="c-42491237">[-]</label><label class="expand" for="c-42491237">[1 more]</label></div><br/><div class="children"><div class="content">Because she&#x27;s old school sysadmin mate, likes running her own stuff her own way, fair enough.<p>And she posts on it lots because she has a bunch of RSS clients pointed at her writing, because she&#x27;s rather popular.<p>And she&#x27;d rather people writing this stuff just learn HTTP properly, at least out of professionalism, if not courtesy.<p>Hey, you might not, I might not, but we all choose our hills to die on.<p>My personal hill is &quot;It&#x27;s lollies and biscuits, not candy and cookies&quot;.</div><br/></div></div><div id="42492607" class="c"><input type="checkbox" id="c-42492607" checked=""/><div class="controls bullet"><span class="by">est</span><span>|</span><a href="#42490135">parent</a><span>|</span><a href="#42491237">prev</a><span>|</span><a href="#42486677">next</a><span>|</span><label class="collapse" for="c-42492607">[-]</label><label class="expand" for="c-42492607">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But... why not throw a CDN in front of your site and focus your energy somewhere else?<p>Yes it&#x27;s been invented before, known as Feedburner, which was acquired &amp; abandoned by Google.</div><br/></div></div></div></div><div id="42486677" class="c"><input type="checkbox" id="c-42486677" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#42490135">prev</a><span>|</span><a href="#42486149">next</a><span>|</span><label class="collapse" for="c-42486677">[-]</label><label class="expand" for="c-42486677">[53 more]</label></div><br/><div class="children"><div class="content">Blocked for 2 hits in 20 minutes on a light protocol like rss?<p>That seems hilariously aggressive to me, but her server her rules I guess.</div><br/><div id="42486882" class="c"><input type="checkbox" id="c-42486882" checked=""/><div class="controls bullet"><span class="by">II2II</span><span>|</span><a href="#42486677">parent</a><span>|</span><a href="#42486799">next</a><span>|</span><label class="collapse" for="c-42486882">[-]</label><label class="expand" for="c-42486882">[8 more]</label></div><br/><div class="children"><div class="content">If your feed reader is refreshing every 20 minutes for a blog that is updated daily, nearly 99% of the data sent is identical. It looks like Rachel&#x27;s blog is updated (roughly) weekly, so that jumps to 99.8%. It&#x27;s not the least efficient thing in the world of computers, but it is definitely incurring unnecessary costs.</div><br/><div id="42486936" class="c"><input type="checkbox" id="c-42486936" checked=""/><div class="controls bullet"><span class="by">elashri</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486882">parent</a><span>|</span><a href="#42488793">next</a><span>|</span><label class="collapse" for="c-42486936">[-]</label><label class="expand" for="c-42486936">[6 more]</label></div><br/><div class="children"><div class="content">I opened the xml file she provides in the blog and it seems very long but okay. Then I decided it is a good blog to subscribe so I went and tried to add to my freshrss selfhosted instance (same ip obviously) and I couldn&#x27;t because I got blocked&#x2F;rate limited. So yes it is aggressive for different reasons.</div><br/><div id="42491623" class="c"><input type="checkbox" id="c-42491623" checked=""/><div class="controls bullet"><span class="by">lilyball</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486936">parent</a><span>|</span><a href="#42488530">next</a><span>|</span><label class="collapse" for="c-42491623">[-]</label><label class="expand" for="c-42491623">[2 more]</label></div><br/><div class="children"><div class="content">I know she&#x27;s mentioned this particular problem before on her blog, I don&#x27;t remember where to find it offhand now but my vague recollection is that because browsers have largely removed the ability to directly view RSS feeds she doesn&#x27;t consider this a significant issue anymore.<p>Why did you view the XML file directly?</div><br/><div id="42492072" class="c"><input type="checkbox" id="c-42492072" checked=""/><div class="controls bullet"><span class="by">elashri</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42491623">parent</a><span>|</span><a href="#42488530">next</a><span>|</span><label class="collapse" for="c-42492072">[-]</label><label class="expand" for="c-42492072">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why did you view the XML file directly?<p>There are many reasons why I do personally this.<p>1- Check that the link actually loads and works!<p>2- See how much content and does it contain last n or all feed history by default<p>3- To see if the feed gives summary or full content of posts<p>4- Just for curiosity like in this case I wanted to see what is this feed that prompted a blog post that reached HN front page.<p>It is usually a superposition state of those reasons. But this is why it is aggressive limit and I know it her server her rulee but this wasn&#x27;t pleasant experience for me as an end user. I was just sharing my experience.</div><br/></div></div></div></div><div id="42488530" class="c"><input type="checkbox" id="c-42488530" checked=""/><div class="controls bullet"><span class="by">KomoD</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486936">parent</a><span>|</span><a href="#42491623">prev</a><span>|</span><a href="#42488078">next</a><span>|</span><label class="collapse" for="c-42488530">[-]</label><label class="expand" for="c-42488530">[1 more]</label></div><br/><div class="children"><div class="content">Same, I made 3 requests in total and got blocked.</div><br/></div></div><div id="42488078" class="c"><input type="checkbox" id="c-42488078" checked=""/><div class="controls bullet"><span class="by">mubou</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486936">parent</a><span>|</span><a href="#42488530">prev</a><span>|</span><a href="#42488102">next</a><span>|</span><label class="collapse" for="c-42488078">[-]</label><label class="expand" for="c-42488078">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that&#x27;s insane. Pretty much telling me not to subscribe to your blog at that point. Like sites that have an rss feed yet put Cloudflare protection in front of it...<p>The correct thing to do here is put a caching layer in front so that every feed reader isn&#x27;t simultaneously hitting the origin for the same content. IP banning is the wrong approach. (Even if it&#x27;s only a temporary block, that&#x27;s going to cause my reader to show an error and is entirely unnecessary.)</div><br/></div></div><div id="42488102" class="c"><input type="checkbox" id="c-42488102" checked=""/><div class="controls bullet"><span class="by">radicality</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486936">parent</a><span>|</span><a href="#42488078">prev</a><span>|</span><a href="#42488793">next</a><span>|</span><label class="collapse" for="c-42488102">[-]</label><label class="expand" for="c-42488102">[1 more]</label></div><br/><div class="children"><div class="content">Weird. Those should have had different user-agents, and I would guess it cannot be purely based on up.</div><br/></div></div></div></div><div id="42488793" class="c"><input type="checkbox" id="c-42488793" checked=""/><div class="controls bullet"><span class="by">wakawaka28</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486882">parent</a><span>|</span><a href="#42486936">prev</a><span>|</span><a href="#42486799">next</a><span>|</span><label class="collapse" for="c-42488793">[-]</label><label class="expand" for="c-42488793">[1 more]</label></div><br/><div class="children"><div class="content">It should be a timeboxed block if anything. Most RSS users are actual readers and expecting them to spend lots of time figuring out why clicking &quot;refresh&quot; twice on their RSS app got them blocked is totally unreasonable. I&#x27;ve got my feeds set up to refresh every hour. Considering the small number of people still using RSS and how lightweight it is, it&#x27;s not bad enough to freak out over. At some point all Rachel&#x27;s complaining and investigating will be more work than her simply interacting directly with the makers of the various readers that cause the most traffic.</div><br/></div></div></div></div><div id="42486799" class="c"><input type="checkbox" id="c-42486799" checked=""/><div class="controls bullet"><span class="by">sccxy</span><span>|</span><a href="#42486677">parent</a><span>|</span><a href="#42486882">prev</a><span>|</span><a href="#42486876">next</a><span>|</span><label class="collapse" for="c-42486799">[-]</label><label class="expand" for="c-42486799">[9 more]</label></div><br/><div class="children"><div class="content">Her rss feed is last 100 posts with full content.<p>So it means 30 months of blog posts content in single request.<p>Sending 0.5MB in single rss request is more crime than those 2 hits in 20 minutes.</div><br/><div id="42486881" class="c"><input type="checkbox" id="c-42486881" checked=""/><div class="controls bullet"><span class="by">horsawlarway</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486799">parent</a><span>|</span><a href="#42492450">next</a><span>|</span><label class="collapse" for="c-42486881">[-]</label><label class="expand" for="c-42486881">[5 more]</label></div><br/><div class="children"><div class="content">I generally agree here.<p>There are a lot of very valid use cases where defaulting to deny for an entire 24 hour cycle after a single request is incredible frustrating for your downstream users (shared IP at my university means I will never get a non-429 response... And God help me if I&#x27;m testing new RSS readers...)<p>It&#x27;s her server, so do as you please, I guess.  But it&#x27;s a hilariously hostile response compared to just returning less data.</div><br/><div id="42486900" class="c"><input type="checkbox" id="c-42486900" checked=""/><div class="controls bullet"><span class="by">mrweasel</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486881">parent</a><span>|</span><a href="#42492450">next</a><span>|</span><label class="collapse" for="c-42486900">[-]</label><label class="expand" for="c-42486900">[4 more]</label></div><br/><div class="children"><div class="content">&gt; But it&#x27;s a hilariously hostile response compared to just returning less data.<p>So provide a poor service to everyone, because some people doesn&#x27;t know how to behave. That sees like an even worse response.</div><br/><div id="42486933" class="c"><input type="checkbox" id="c-42486933" checked=""/><div class="controls bullet"><span class="by">sccxy</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486900">parent</a><span>|</span><a href="#42488822">next</a><span>|</span><label class="collapse" for="c-42486933">[-]</label><label class="expand" for="c-42486933">[1 more]</label></div><br/><div class="children"><div class="content">Send only one year&#x27;s recent posts and you&#x27;ve reduced bandwidth by 50%.</div><br/></div></div><div id="42488822" class="c"><input type="checkbox" id="c-42488822" checked=""/><div class="controls bullet"><span class="by">wakawaka28</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486900">parent</a><span>|</span><a href="#42486933">prev</a><span>|</span><a href="#42492450">next</a><span>|</span><label class="collapse" for="c-42488822">[-]</label><label class="expand" for="c-42488822">[2 more]</label></div><br/><div class="children"><div class="content">People don&#x27;t want to have to customize refresh rates on a per-feed basis. Perhaps the RSS or Atom standards need to support importing the recommended refresh rate automatically.</div><br/><div id="42492663" class="c"><input type="checkbox" id="c-42492663" checked=""/><div class="controls bullet"><span class="by">ncallaway</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42488822">parent</a><span>|</span><a href="#42492450">next</a><span>|</span><label class="collapse" for="c-42492663">[-]</label><label class="expand" for="c-42492663">[1 more]</label></div><br/><div class="children"><div class="content">They don&#x27;t need to change the refresh rate, though. They need to make conditional requests with an etag or a last-modified date, so the server can respond with a 304 not modified if no changes have been made.<p>No standards need to be updated. The client software needs to be a better HTTP citizen.</div><br/></div></div></div></div></div></div></div></div><div id="42492450" class="c"><input type="checkbox" id="c-42492450" checked=""/><div class="controls bullet"><span class="by">BonoboIO</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486799">parent</a><span>|</span><a href="#42486881">prev</a><span>|</span><a href="#42490660">next</a><span>|</span><label class="collapse" for="c-42492450">[-]</label><label class="expand" for="c-42492450">[1 more]</label></div><br/><div class="children"><div class="content">Complains about traffic, sends 0.5mb of everything.<p>That’s my kind of humor.</div><br/></div></div><div id="42490660" class="c"><input type="checkbox" id="c-42490660" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486799">parent</a><span>|</span><a href="#42492450">prev</a><span>|</span><a href="#42488812">next</a><span>|</span><label class="collapse" for="c-42490660">[-]</label><label class="expand" for="c-42490660">[1 more]</label></div><br/><div class="children"><div class="content">If there were a widely supported standard for pagination in RSS, then it would make sense to limit the number of posts.  As there isn&#x27;t, sending 500kB seems eminently reasonable, and RSS readers that send conditional requests are fine.</div><br/></div></div><div id="42488812" class="c"><input type="checkbox" id="c-42488812" checked=""/><div class="controls bullet"><span class="by">wakawaka28</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486799">parent</a><span>|</span><a href="#42490660">prev</a><span>|</span><a href="#42486876">next</a><span>|</span><label class="collapse" for="c-42488812">[-]</label><label class="expand" for="c-42488812">[1 more]</label></div><br/><div class="children"><div class="content">Yes that&#x27;s right. Most blogs that are popular enough to have this problem send you the last 10 post titles and links or something. THAT is why people refresh every hour, so they don&#x27;t miss out.</div><br/></div></div></div></div><div id="42486876" class="c"><input type="checkbox" id="c-42486876" checked=""/><div class="controls bullet"><span class="by">cesarb</span><span>|</span><a href="#42486677">parent</a><span>|</span><a href="#42486799">prev</a><span>|</span><a href="#42486784">next</a><span>|</span><label class="collapse" for="c-42486876">[-]</label><label class="expand" for="c-42486876">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Blocked for 2 hits in 20 minutes on a light protocol like rss?<p>I might be getting old, but 500KB in a single response doesn&#x27;t feel &quot;light&quot; to me.</div><br/><div id="42486915" class="c"><input type="checkbox" id="c-42486915" checked=""/><div class="controls bullet"><span class="by">sccxy</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486876">parent</a><span>|</span><a href="#42486784">next</a><span>|</span><label class="collapse" for="c-42486915">[-]</label><label class="expand" for="c-42486915">[5 more]</label></div><br/><div class="children"><div class="content">Yes, this is a very poorly designed RSS feed.<p>500KB is horrible for RSS.</div><br/><div id="42488163" class="c"><input type="checkbox" id="c-42488163" checked=""/><div class="controls bullet"><span class="by">Symbiote</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486915">parent</a><span>|</span><a href="#42486784">next</a><span>|</span><label class="collapse" for="c-42488163">[-]</label><label class="expand" for="c-42488163">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s reasonable to have whole articles in RSS, of you aren&#x27;t trying to show ads or similar.</div><br/><div id="42488225" class="c"><input type="checkbox" id="c-42488225" checked=""/><div class="controls bullet"><span class="by">sccxy</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42488163">parent</a><span>|</span><a href="#42486784">next</a><span>|</span><label class="collapse" for="c-42488225">[-]</label><label class="expand" for="c-42488225">[3 more]</label></div><br/><div class="children"><div class="content">Whole articles are reasonable.<p>100 articles are not reasonable.<p>100 articles where most of them are 1+ year old is madness.<p>RSS is not an archive of the entire website.</div><br/><div id="42492585" class="c"><input type="checkbox" id="c-42492585" checked=""/><div class="controls bullet"><span class="by">Sweepi</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42488225">parent</a><span>|</span><a href="#42489696">next</a><span>|</span><label class="collapse" for="c-42492585">[-]</label><label class="expand" for="c-42492585">[1 more]</label></div><br/><div class="children"><div class="content">Well, its note the entire website, and i find the &quot;last 100 articles&quot; rule way better than &quot;last 3&quot; or &quot;last 90 days&quot; (which some times is 0 or 1).<p>The host is fine with sending 0.5 MiB once (the client should be aswell from both a bandwidth and storage point of view).<p>The host is not fine with sending 0.5 MiB every 20 minutes, which could be easily avoided if the client would use the mentioned &quot;If-Modified-Since header&quot;.</div><br/></div></div><div id="42489696" class="c"><input type="checkbox" id="c-42489696" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42488225">parent</a><span>|</span><a href="#42492585">prev</a><span>|</span><a href="#42486784">next</a><span>|</span><label class="collapse" for="c-42489696">[-]</label><label class="expand" for="c-42489696">[1 more]</label></div><br/><div class="children"><div class="content">&gt; RSS is not an archive of the entire website<p>Whole-article feeds end up become exactly that - a local archive of a blog.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42486784" class="c"><input type="checkbox" id="c-42486784" checked=""/><div class="controls bullet"><span class="by">garfij</span><span>|</span><a href="#42486677">parent</a><span>|</span><a href="#42486876">prev</a><span>|</span><a href="#42486878">next</a><span>|</span><label class="collapse" for="c-42486784">[-]</label><label class="expand" for="c-42486784">[21 more]</label></div><br/><div class="children"><div class="content">I believe if you read carefully, it&#x27;s not blocked, it&#x27;s rate limited to once daily, with very clear remediation steps included in the response.</div><br/><div id="42486849" class="c"><input type="checkbox" id="c-42486849" checked=""/><div class="controls bullet"><span class="by">that_guy_iain</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486784">parent</a><span>|</span><a href="#42486878">next</a><span>|</span><label class="collapse" for="c-42486849">[-]</label><label class="expand" for="c-42486849">[20 more]</label></div><br/><div class="children"><div class="content">If you understand what rate limiting is, you block them for a period of time. Let&#x27;s stop being pedantic here.<p>72 requests per day is nothing and acting like it&#x27;s mayhem is a bit silly. And for a lot of people would result in them getting possible news slower. Sure OP won&#x27;t publish that often but their rate limiting is an edge case and should be treated as such. If they&#x27;re blocked until the next day and nothing gets updated then the only person harmed is OP for being overly bothered by their HTTP logs.<p>Sure it&#x27;s their server and they can do whatever they want. But all this does is hurts the people trying to reach their blog.</div><br/><div id="42486988" class="c"><input type="checkbox" id="c-42486988" checked=""/><div class="controls bullet"><span class="by">HomeDeLaPot</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486849">parent</a><span>|</span><a href="#42487010">next</a><span>|</span><label class="collapse" for="c-42486988">[-]</label><label class="expand" for="c-42486988">[5 more]</label></div><br/><div class="children"><div class="content">72 requests per day _per user with a naive feed reader_. This is a small personal blog with no ads that OP is self-hosting on her own hardware, so blocking all this junk traffic is probably saving her money. Plus she&#x27;s calling attention to how feed readers can be improved!</div><br/><div id="42488031" class="c"><input type="checkbox" id="c-42488031" checked=""/><div class="controls bullet"><span class="by">m3047</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486988">parent</a><span>|</span><a href="#42487488">next</a><span>|</span><label class="collapse" for="c-42488031">[-]</label><label class="expand" for="c-42488031">[1 more]</label></div><br/><div class="children"><div class="content">My reason for smacking stuff down is that I don&#x27;t want to see it in my logs. That simple.</div><br/></div></div><div id="42487488" class="c"><input type="checkbox" id="c-42487488" checked=""/><div class="controls bullet"><span class="by">that_guy_iain</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486988">parent</a><span>|</span><a href="#42488031">prev</a><span>|</span><a href="#42487010">next</a><span>|</span><label class="collapse" for="c-42487488">[-]</label><label class="expand" for="c-42487488">[3 more]</label></div><br/><div class="children"><div class="content">Even if they had 1000 feed readers which would be a massive amount for a blog, if you can&#x27;t scale that cheaply, that&#x27;s on you.<p>As I pointed out, her blog and rate limiting are an extreme edge case, it would be silly for anyone to put effort into changing their feed reader for a single small blog. It&#x27;s bad product management.</div><br/><div id="42487528" class="c"><input type="checkbox" id="c-42487528" checked=""/><div class="controls bullet"><span class="by">tecleandor</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487488">parent</a><span>|</span><a href="#42487010">next</a><span>|</span><label class="collapse" for="c-42487528">[-]</label><label class="expand" for="c-42487528">[2 more]</label></div><br/><div class="children"><div class="content">Of course she can. It&#x27;s static. She doesn&#x27;t want and I understand. She&#x27;s signaling their clients an standard call to say &quot;I think you already have read this, at lest ask me first when this changed the last time&quot;.</div><br/><div id="42489940" class="c"><input type="checkbox" id="c-42489940" checked=""/><div class="controls bullet"><span class="by">that_guy_iain</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487528">parent</a><span>|</span><a href="#42487010">next</a><span>|</span><label class="collapse" for="c-42489940">[-]</label><label class="expand" for="c-42489940">[1 more]</label></div><br/><div class="children"><div class="content">If you choose to run a poorly implemented rss feed and not scale it cheaply you lose any sympathy from me.</div><br/></div></div></div></div></div></div></div></div><div id="42487010" class="c"><input type="checkbox" id="c-42487010" checked=""/><div class="controls bullet"><span class="by">throw0101b</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486849">parent</a><span>|</span><a href="#42486988">prev</a><span>|</span><a href="#42487125">next</a><span>|</span><label class="collapse" for="c-42487010">[-]</label><label class="expand" for="c-42487010">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>72 requests per day is nothing and acting like it&#x27;s mayhem is a bit silly.</i><p>72 requests per day per IP over <i>how many IPs</i>? When you start multiplying numbers together they can get big.</div><br/></div></div><div id="42487125" class="c"><input type="checkbox" id="c-42487125" checked=""/><div class="controls bullet"><span class="by">quest88</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486849">parent</a><span>|</span><a href="#42487010">prev</a><span>|</span><a href="#42486878">next</a><span>|</span><label class="collapse" for="c-42487125">[-]</label><label class="expand" for="c-42487125">[13 more]</label></div><br/><div class="children"><div class="content">I invite you to run your own popular blog on your own hardware and pay for the costs. It sounds like you don&#x27;t know what the true costs are.</div><br/><div id="42487165" class="c"><input type="checkbox" id="c-42487165" checked=""/><div class="controls bullet"><span class="by">donatj</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487125">parent</a><span>|</span><a href="#42492680">next</a><span>|</span><label class="collapse" for="c-42487165">[-]</label><label class="expand" for="c-42487165">[6 more]</label></div><br/><div class="children"><div class="content">I do run a popular blog, and a $5 a month Digital Ocean droplet handles millions of requests per month without breaking a sweat.</div><br/><div id="42487230" class="c"><input type="checkbox" id="c-42487230" checked=""/><div class="controls bullet"><span class="by">devjab</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487165">parent</a><span>|</span><a href="#42492680">next</a><span>|</span><label class="collapse" for="c-42487230">[-]</label><label class="expand" for="c-42487230">[5 more]</label></div><br/><div class="children"><div class="content">If every user is collecting 36mb a day like in the story here, your droplet wouldn’t even be capable of serving 500 users a month without hitting your bandwidth limit. With their current rates, your one million requests would cost you around 10 million USD.</div><br/><div id="42487370" class="c"><input type="checkbox" id="c-42487370" checked=""/><div class="controls bullet"><span class="by">donatj</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487230">parent</a><span>|</span><a href="#42487288">next</a><span>|</span><label class="collapse" for="c-42487370">[-]</label><label class="expand" for="c-42487370">[2 more]</label></div><br/><div class="children"><div class="content">30 * 500 * 36mb = 560gb and I have 1tb a month on my apparently $6 droplet<p>Correction - from my billing page it&#x27;s $4.50 a month, from the resize page it is $6 so I&#x27;m guessing I am grandfathered in to some older pricing</div><br/><div id="42487542" class="c"><input type="checkbox" id="c-42487542" checked=""/><div class="controls bullet"><span class="by">tecleandor</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487370">parent</a><span>|</span><a href="#42487288">next</a><span>|</span><label class="collapse" for="c-42487542">[-]</label><label class="expand" for="c-42487542">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s ridiculously big quantity of data to serve a seldomly updated blog just because the client doesn&#x27;t want (or know how, or think about) to implement an easy and old http method.<p>Imagine the petabytes of data transferred through the internet saved if a couple RSS clients added that method.</div><br/></div></div></div></div><div id="42487288" class="c"><input type="checkbox" id="c-42487288" checked=""/><div class="controls bullet"><span class="by">sccxy</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487230">parent</a><span>|</span><a href="#42487370">prev</a><span>|</span><a href="#42492680">next</a><span>|</span><label class="collapse" for="c-42487288">[-]</label><label class="expand" for="c-42487288">[2 more]</label></div><br/><div class="children"><div class="content">If OP enabled gzip then this 36mb would be 13mb.<p>If OP reduced 30 months of posts in rss to 12 months then this 13mb would be 5mb a day.<p>Using Cloudflare free plan and this static content is cached without any problem.</div><br/><div id="42491562" class="c"><input type="checkbox" id="c-42491562" checked=""/><div class="controls bullet"><span class="by">notpushkin</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487288">parent</a><span>|</span><a href="#42492680">next</a><span>|</span><label class="collapse" for="c-42491562">[-]</label><label class="expand" for="c-42491562">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but also... if RSS readers behaved correctly, it would be 512 kb. (170 kb with gzip, if she didn&#x27;t enable it like you imply – I&#x27;m too lazy to check, but I assumed it was on.)<p>I think making clients behave correctly is much more sustainable solution, although we could do better than doing so at the cost of the end users.</div><br/></div></div></div></div></div></div></div></div><div id="42492680" class="c"><input type="checkbox" id="c-42492680" checked=""/><div class="controls bullet"><span class="by">omgtehlion</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487125">parent</a><span>|</span><a href="#42487165">prev</a><span>|</span><a href="#42487265">next</a><span>|</span><label class="collapse" for="c-42492680">[-]</label><label class="expand" for="c-42492680">[1 more]</label></div><br/><div class="children"><div class="content">I serve 30tb&#x2F;month for $30&#x2F;mo on my own colocated hw</div><br/></div></div><div id="42487265" class="c"><input type="checkbox" id="c-42487265" checked=""/><div class="controls bullet"><span class="by">Twirrim</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487125">parent</a><span>|</span><a href="#42492680">prev</a><span>|</span><a href="#42487154">next</a><span>|</span><label class="collapse" for="c-42487265">[-]</label><label class="expand" for="c-42487265">[3 more]</label></div><br/><div class="children"><div class="content">OP has <i>never</i> said that this is about financial aspects of things.</div><br/><div id="42487891" class="c"><input type="checkbox" id="c-42487891" checked=""/><div class="controls bullet"><span class="by">Joker_vD</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487265">parent</a><span>|</span><a href="#42487154">next</a><span>|</span><label class="collapse" for="c-42487891">[-]</label><label class="expand" for="c-42487891">[2 more]</label></div><br/><div class="children"><div class="content">Yews, it&#x27;s about enforcing their preference on how others should interact with OP&#x27;s published site feed, on principle. Which is always an uphill battle.</div><br/><div id="42492406" class="c"><input type="checkbox" id="c-42492406" checked=""/><div class="controls bullet"><span class="by">Twirrim</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487891">parent</a><span>|</span><a href="#42487154">next</a><span>|</span><label class="collapse" for="c-42492406">[-]</label><label class="expand" for="c-42492406">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s about enforcing that people follow standards.  Which is still an uphill battle, but at least it&#x27;s based in something sane.  Their work on this has resulted in improvements to a whole slew of popular feed readers that should make life easier for a chunk of the internet, not just OP&#x27;s own site.</div><br/></div></div></div></div></div></div><div id="42487154" class="c"><input type="checkbox" id="c-42487154" checked=""/><div class="controls bullet"><span class="by">that_guy_iain</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487125">parent</a><span>|</span><a href="#42487265">prev</a><span>|</span><a href="#42487169">next</a><span>|</span><label class="collapse" for="c-42487154">[-]</label><label class="expand" for="c-42487154">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like you don&#x27;t know how to scale for cheap.<p>And since I&#x27;ve ran integrations that connected over 500 companies. I know what a rouge client actually looks like and 72 requests per day and I wouldn&#x27;t even notice.</div><br/></div></div><div id="42487169" class="c"><input type="checkbox" id="c-42487169" checked=""/><div class="controls bullet"><span class="by">sccxy</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487125">parent</a><span>|</span><a href="#42487154">prev</a><span>|</span><a href="#42486878">next</a><span>|</span><label class="collapse" for="c-42487169">[-]</label><label class="expand" for="c-42487169">[1 more]</label></div><br/><div class="children"><div class="content">More like a skill issue or just decision to make your life more difficult.<p>It is free and easy to scale this kind of text based blog.</div><br/></div></div></div></div></div></div></div></div><div id="42486878" class="c"><input type="checkbox" id="c-42486878" checked=""/><div class="controls bullet"><span class="by">mrweasel</span><span>|</span><a href="#42486677">parent</a><span>|</span><a href="#42486784">prev</a><span>|</span><a href="#42486807">next</a><span>|</span><label class="collapse" for="c-42486878">[-]</label><label class="expand" for="c-42486878">[1 more]</label></div><br/><div class="children"><div class="content">But it&#x27;s not a &quot;light&quot; protocol when you&#x27;re serving 36MB per day, when 500KB would suffice. RSS&#x2F;Atom is light weight, if clients play by the rules. This could also have been a news website, imagine how much traffic would be dedicated to pointless transfers of unchanged data. Traffic isn&#x27;t free.<p>A similar problem arise from the increase in AI scraper activities. Talking to other SREs the problem seems pretty wide spread. AI companies will just hoover up data, but revisit so frequently and aggressively that it&#x27;s starting to affect the transit feeds for popular websites. Frequently user-agents wouldn&#x27;t be set to something unique, or deliberately hidden, and traffic originates from AWS, making it hard to target individual bad actors. Fair enough that you&#x27;re scraping websites, that&#x27;s part of the game when your online, but when your industry starts to affect transit feeds, then we need to talk compensation.</div><br/></div></div><div id="42486807" class="c"><input type="checkbox" id="c-42486807" checked=""/><div class="controls bullet"><span class="by">yladiz</span><span>|</span><a href="#42486677">parent</a><span>|</span><a href="#42486878">prev</a><span>|</span><a href="#42486149">next</a><span>|</span><label class="collapse" for="c-42486807">[-]</label><label class="expand" for="c-42486807">[7 more]</label></div><br/><div class="children"><div class="content">That’s a bit disingenuous. 429s aren’t “blocking”, they’re telling the requester that they’re done too many requests and to try again later (with a value in the header). I assume the author configured this because they know how often the site is going to change typically. That the web server eventually stops responding if the client ignores requests isn’t that surprising, but I doubt it was configured directly too.</div><br/><div id="42486891" class="c"><input type="checkbox" id="c-42486891" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486807">parent</a><span>|</span><a href="#42486868">next</a><span>|</span><label class="collapse" for="c-42486891">[-]</label><label class="expand" for="c-42486891">[1 more]</label></div><br/><div class="children"><div class="content">Semantics. 429 is an error code. Rate limiting...blocking...too many requests...ignoring...call it whatever you like but it amounts to the same, namingly server isn&#x27;t serving the requested content.</div><br/></div></div><div id="42486868" class="c"><input type="checkbox" id="c-42486868" checked=""/><div class="controls bullet"><span class="by">luckylion</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486807">parent</a><span>|</span><a href="#42486891">prev</a><span>|</span><a href="#42486861">next</a><span>|</span><label class="collapse" for="c-42486868">[-]</label><label class="expand" for="c-42486868">[2 more]</label></div><br/><div class="children"><div class="content">&gt; 429s aren’t “blocking”<p>Like how &quot;unlimited traffic, but will slow down to 1bps if you use more than 100gb in a month&quot; is technically &quot;unlimited traffic&quot;.<p>But for all intents and purposes, it&#x27;s limited. And 429 are blocking. They include a hint towards the reason why you are blocked and when the block might expire (retry-after doesn&#x27;t promise that you&#x27;ll be successful if you wait), but besides that, what&#x27;s the different compared to 403?</div><br/><div id="42487413" class="c"><input type="checkbox" id="c-42487413" checked=""/><div class="controls bullet"><span class="by">yladiz</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486868">parent</a><span>|</span><a href="#42486861">next</a><span>|</span><label class="collapse" for="c-42487413">[-]</label><label class="expand" for="c-42487413">[1 more]</label></div><br/><div class="children"><div class="content">I would disagree. Blocking typically implies permanence (without more action by the blockee), and since 429 isn’t usually a permanent error code I wouldn’t call it blocking. Same applies with 403, it’s only permanent if the requester doesn’t authorize correctly.</div><br/></div></div></div></div><div id="42486861" class="c"><input type="checkbox" id="c-42486861" checked=""/><div class="controls bullet"><span class="by">that_guy_iain</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486807">parent</a><span>|</span><a href="#42486868">prev</a><span>|</span><a href="#42486149">next</a><span>|</span><label class="collapse" for="c-42486861">[-]</label><label class="expand" for="c-42486861">[3 more]</label></div><br/><div class="children"><div class="content">I would say it&#x27;s disingenuous to claim sending HTTP status and body that is not expected for a period of time is not blocking them for that period of time. You can be pedantic and claim &quot;but they can still access the server&quot; but in reality that client is blocked for a period of time.</div><br/><div id="42487371" class="c"><input type="checkbox" id="c-42487371" checked=""/><div class="controls bullet"><span class="by">kstrauser</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42486861">parent</a><span>|</span><a href="#42486149">next</a><span>|</span><label class="collapse" for="c-42487371">[-]</label><label class="expand" for="c-42487371">[2 more]</label></div><br/><div class="children"><div class="content">In that case, I should be irate that the AWS API blocks me many times per day. Run `aws cli service some-paginated-thing` and see how many retries you get during normal, routine operation.<p>But I’m not, because they’re not blocking me. They’re asking my client to slow down. Neither AWS nor Rachel’s blog owes me unlimited requests per unit time, and neither have “blocked” me when I violate they policies.</div><br/><div id="42487554" class="c"><input type="checkbox" id="c-42487554" checked=""/><div class="controls bullet"><span class="by">that_guy_iain</span><span>|</span><a href="#42486677">root</a><span>|</span><a href="#42487371">parent</a><span>|</span><a href="#42486149">next</a><span>|</span><label class="collapse" for="c-42487554">[-]</label><label class="expand" for="c-42487554">[1 more]</label></div><br/><div class="children"><div class="content">They literally do block you for a period of time until you are out of the rate limit. That is how rate limits work. That&#x27;s why you don&#x27;t get to access the resource you requested, because their system literally blocked you from doing so.<p>See when you&#x27;re trying to be pedantic and all about semantics, you should make sure you&#x27;ve crossed your Ts and dotted your Is.<p>&gt; Block – AWS WAF blocks the request and applies any custom blocking behavior that you&#x27;ve defined.<p>from <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;waf&#x2F;latest&#x2F;developerguide&#x2F;waf-rule-statement-type-rate-based-request-limiting.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;waf&#x2F;latest&#x2F;developerguide&#x2F;waf-ru...</a><p>And my favourite<p>&gt; Rate limiting blocks users, bots, or applications that are over-using or abusing a web property. Rate limiting can stop certain kinds of bot attacks.<p>From CloudFlare&#x27;s explainer <a href="https:&#x2F;&#x2F;www.cloudflare.com&#x2F;learning&#x2F;bots&#x2F;what-is-rate-limiting&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.cloudflare.com&#x2F;learning&#x2F;bots&#x2F;what-is-rate-limiti...</a><p>Every documentation on rate limit will include the word block. Because that&#x27;s what you do, you allow access for a specific amount of requests and then block those that go over.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42486149" class="c"><input type="checkbox" id="c-42486149" checked=""/><div class="controls bullet"><span class="by">jannes</span><span>|</span><a href="#42486677">prev</a><span>|</span><a href="#42486266">next</a><span>|</span><label class="collapse" for="c-42486149">[-]</label><label class="expand" for="c-42486149">[18 more]</label></div><br/><div class="children"><div class="content">The HTTP protocol is a lost art. These days people don&#x27;t even look at the status code and expect some mumbo jumbo JSON payload explaining the error.</div><br/><div id="42486341" class="c"><input type="checkbox" id="c-42486341" checked=""/><div class="controls bullet"><span class="by">klntsky</span><span>|</span><a href="#42486149">parent</a><span>|</span><a href="#42486626">next</a><span>|</span><label class="collapse" for="c-42486341">[-]</label><label class="expand" for="c-42486341">[4 more]</label></div><br/><div class="children"><div class="content">I would argue that HTTP statuses are a bad design decision, because they are intended to be consumed by apps, but are not app-specific. They are effectively a part of every API automatically without considerations whether they are needed.<p>People often implement error handling using constructs like regexp matching on status codes, while with domain-specified errors it would be obvious what exactly is the range of possible errors.<p>Moreover, when people do implement domain errors, they just have to write more code to handle two nested levels of branching.</div><br/><div id="42492588" class="c"><input type="checkbox" id="c-42492588" checked=""/><div class="controls bullet"><span class="by">est</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42486341">parent</a><span>|</span><a href="#42487040">next</a><span>|</span><label class="collapse" for="c-42492588">[-]</label><label class="expand" for="c-42492588">[1 more]</label></div><br/><div class="children"><div class="content">&gt; error handling using constructs like regexp matching on status codes<p>Oh the horror. I would assume the practice is encourage by &quot;RESTful&quot; people?</div><br/></div></div><div id="42487040" class="c"><input type="checkbox" id="c-42487040" checked=""/><div class="controls bullet"><span class="by">throw0101b</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42486341">parent</a><span>|</span><a href="#42492588">prev</a><span>|</span><a href="#42486999">next</a><span>|</span><label class="collapse" for="c-42487040">[-]</label><label class="expand" for="c-42487040">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>I would argue that HTTP statuses are a bad design decision, because they are intended to be consumed by apps, but are not app-specific.</i><p>Perhaps put the app-specific part in the body of the reply. In the RFC they give a human specific reply to (presumably) be displayed in the browser:<p><pre><code>   HTTP&#x2F;1.1 429 Too Many Requests
   Content-Type: text&#x2F;html
   Retry-After: 3600

   &lt;html&gt;
      &lt;head&gt;
         &lt;title&gt;Too Many Requests&lt;&#x2F;title&gt;
      &lt;&#x2F;head&gt;
      &lt;body&gt;
         &lt;h1&gt;Too Many Requests&lt;&#x2F;h1&gt;
         &lt;p&gt;I only allow 50 requests per hour to this Web site per
            logged in user.  Try again soon.&lt;&#x2F;p&gt;
      &lt;&#x2F;body&gt;
   &lt;&#x2F;html&gt;
</code></pre>
* <a href="https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc6585#section-4" rel="nofollow">https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc6585#section-4</a><p>* <a href="https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;HTTP&#x2F;Status&#x2F;429" rel="nofollow">https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;HTTP&#x2F;Status&#x2F;429</a><p>But if the URL is specific to an API, you can document that you will&#x2F;may give further debugging details (in text, JSON, XML, whatever).</div><br/></div></div><div id="42486999" class="c"><input type="checkbox" id="c-42486999" checked=""/><div class="controls bullet"><span class="by">marcosdumay</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42486341">parent</a><span>|</span><a href="#42487040">prev</a><span>|</span><a href="#42486626">next</a><span>|</span><label class="collapse" for="c-42486999">[-]</label><label class="expand" for="c-42486999">[1 more]</label></div><br/><div class="children"><div class="content">&gt; because they are intended to be consumed by apps, but are not app-specific<p>Well, good luck designing any standard app-independent protocol that works and doesn&#x27;t do that.<p>And yes, you must handle two nested levels of branching. That&#x27;s how it works.<p>The only improvement possible to make it clearer is having codes for API specific errors... what 400 and 500 aren&#x27;t exactly. But then, that doesn&#x27;t gain you much.</div><br/></div></div></div></div><div id="42486626" class="c"><input type="checkbox" id="c-42486626" checked=""/><div class="controls bullet"><span class="by">KomoD</span><span>|</span><a href="#42486149">parent</a><span>|</span><a href="#42486341">prev</a><span>|</span><a href="#42486563">next</a><span>|</span><label class="collapse" for="c-42486626">[-]</label><label class="expand" for="c-42486626">[10 more]</label></div><br/><div class="children"><div class="content">That&#x27;s because a lot of people refuse to use status codes properly, like just using 200 everywhere.</div><br/><div id="42487392" class="c"><input type="checkbox" id="c-42487392" checked=""/><div class="controls bullet"><span class="by">kstrauser</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42486626">parent</a><span>|</span><a href="#42486563">next</a><span>|</span><label class="collapse" for="c-42487392">[-]</label><label class="expand" for="c-42487392">[9 more]</label></div><br/><div class="children"><div class="content">A colleague who should’ve known better argued that a 404 response to an API call was confusing because we were, in fact, successfully returning a response to the client. We had a long talk about that afterward.</div><br/><div id="42487909" class="c"><input type="checkbox" id="c-42487909" checked=""/><div class="controls bullet"><span class="by">Joker_vD</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42487392">parent</a><span>|</span><a href="#42486563">next</a><span>|</span><label class="collapse" for="c-42487909">[-]</label><label class="expand" for="c-42487909">[8 more]</label></div><br/><div class="children"><div class="content">No, it is pretty confusing: the difference between 404 from hitting an endpoint that the server doesn&#x27;t serve (because you forgot to expose this endpoint, oops!) and a 404 that means &quot;we&#x27;ve successfully performed the search in our DB for the business entity you&#x27;ve requested and guarantee you that it does not exist&quot; is rather difficult to tell programmatically.</div><br/><div id="42491786" class="c"><input type="checkbox" id="c-42491786" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42487909">parent</a><span>|</span><a href="#42489087">next</a><span>|</span><label class="collapse" for="c-42491786">[-]</label><label class="expand" for="c-42491786">[1 more]</label></div><br/><div class="children"><div class="content">422 unprocessable content (webdav)<p>The request couldn&#x27;t be processed due to semantic errors... perhaps such as not being mapped to a handler :-&gt;<p>I suppose from the right point of view that could also be likened to a reverse proxy not being able to send the request on (502 bad gateway), but sane people would probably find that even more confusing.<p>There were also attempts to use 204 no content for &quot;I successfully confirmed that what you asked for doesn&#x27;t exist&quot;, but I think I managed to shoot those down.</div><br/></div></div><div id="42489087" class="c"><input type="checkbox" id="c-42489087" checked=""/><div class="controls bullet"><span class="by">yjftsjthsd-h</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42487909">parent</a><span>|</span><a href="#42491786">prev</a><span>|</span><a href="#42489710">next</a><span>|</span><label class="collapse" for="c-42489087">[-]</label><label class="expand" for="c-42489087">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m open to arguing about <i>which</i> error to return in each case, but surely we can agree that neither of those warrant a 200?</div><br/><div id="42489732" class="c"><input type="checkbox" id="c-42489732" checked=""/><div class="controls bullet"><span class="by">echoangle</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42489087">parent</a><span>|</span><a href="#42489710">next</a><span>|</span><label class="collapse" for="c-42489732">[-]</label><label class="expand" for="c-42489732">[3 more]</label></div><br/><div class="children"><div class="content">Why not? I wouldn’t say „I performed the search and there’s 0 results“ is an error condition. It’s just the result of a search, and everything went fine.</div><br/><div id="42489966" class="c"><input type="checkbox" id="c-42489966" checked=""/><div class="controls bullet"><span class="by">yjftsjthsd-h</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42489732">parent</a><span>|</span><a href="#42489710">next</a><span>|</span><label class="collapse" for="c-42489966">[-]</label><label class="expand" for="c-42489966">[2 more]</label></div><br/><div class="children"><div class="content">Hm, maybe? I guess it depends on what we mean by search; if myapp.com&#x2F;search?someproduct finds that there are 0 matches then yeah that&#x27;s probably a 200, but if myapp.com&#x2F;products&#x2F;123456 fails because no product has id 123456 then that&#x27;s a textbook 404.</div><br/><div id="42490993" class="c"><input type="checkbox" id="c-42490993" checked=""/><div class="controls bullet"><span class="by">wruza</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42489966">parent</a><span>|</span><a href="#42489710">next</a><span>|</span><label class="collapse" for="c-42490993">[-]</label><label class="expand" for="c-42490993">[1 more]</label></div><br/><div class="children"><div class="content">It’s both nonsense, cause what you see here is a double conversion from an arbitrary problem domain into http domain and back again. Using a specific http code <i>together</i> with an app-domain code could make sense iff you wanted an intermediate host (a proxy etc) to perform some additional operation based on that status. Otherwise http status doesn’t speak the call language and can be just OK. (400&#x2F;500 should still be handled by a client).<p>Back-and-forth conversion is a very poor idea. It works for what was “internet resources” initially (basically files and folders), but later people stretched that on application data models and that creates constant issues because people naturally can’t understand the mapping, cause there’s none. This is not a good idea. Talk to http hosts with http and talk to your client with a language you designed specifically for talking to it. 200 vs non-200 is http level and orthogonal to in-service statuses.</div><br/></div></div></div></div></div></div></div></div><div id="42489710" class="c"><input type="checkbox" id="c-42489710" checked=""/><div class="controls bullet"><span class="by">wiml</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42487909">parent</a><span>|</span><a href="#42489087">prev</a><span>|</span><a href="#42486563">next</a><span>|</span><label class="collapse" for="c-42489710">[-]</label><label class="expand" for="c-42489710">[2 more]</label></div><br/><div class="children"><div class="content">If the URL identifies a <i>resource</i> (REST-style) and that database entry doesn&#x27;t exist, then yes, 404 is less confusing response. If the URL identifies an <i>API endpoint</i> (RPC-style) then, sure, tunnel the error inside a &quot;I successfully failed to handle that request&quot; response if you like.</div><br/><div id="42489892" class="c"><input type="checkbox" id="c-42489892" checked=""/><div class="controls bullet"><span class="by">reshlo</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42489710">parent</a><span>|</span><a href="#42486563">next</a><span>|</span><label class="collapse" for="c-42489892">[-]</label><label class="expand" for="c-42489892">[1 more]</label></div><br/><div class="children"><div class="content">All URLs used when interacting with an API obviously identify API endpoints. There is no such thing as a URL which is part of an API but which is not an API endpoint.<p>There is a difference between &#x2F;api&#x2F;entity&#x2F;123 and &#x2F;api&#x2F;search with a payload of 123, though.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42486563" class="c"><input type="checkbox" id="c-42486563" checked=""/><div class="controls bullet"><span class="by">AznHisoka</span><span>|</span><a href="#42486149">parent</a><span>|</span><a href="#42486626">prev</a><span>|</span><a href="#42486804">next</a><span>|</span><label class="collapse" for="c-42486563">[-]</label><label class="expand" for="c-42486563">[2 more]</label></div><br/><div class="children"><div class="content">I dont look at the code because its wrong sometimes. Some pages return a 200 yet display an error in the page</div><br/><div id="42487651" class="c"><input type="checkbox" id="c-42487651" checked=""/><div class="controls bullet"><span class="by">DaSHacka</span><span>|</span><a href="#42486149">root</a><span>|</span><a href="#42486563">parent</a><span>|</span><a href="#42486804">next</a><span>|</span><label class="collapse" for="c-42487651">[-]</label><label class="expand" for="c-42487651">[1 more]</label></div><br/><div class="children"><div class="content">Nothing more annoying than a 200 response when the server &#x27;successfully&#x27; serves a 404 page</div><br/></div></div></div></div></div></div><div id="42486266" class="c"><input type="checkbox" id="c-42486266" checked=""/><div class="controls bullet"><span class="by">generationP</span><span>|</span><a href="#42486149">prev</a><span>|</span><a href="#42486581">next</a><span>|</span><label class="collapse" for="c-42486266">[-]</label><label class="expand" for="c-42486266">[9 more]</label></div><br/><div class="children"><div class="content">Rejecting every unconditional GET after the first? That sounds a bit excessive. What if the reader crashed after the first and lost the data?</div><br/><div id="42486604" class="c"><input type="checkbox" id="c-42486604" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#42486266">parent</a><span>|</span><a href="#42488814">next</a><span>|</span><label class="collapse" for="c-42486604">[-]</label><label class="expand" for="c-42486604">[7 more]</label></div><br/><div class="children"><div class="content">It’s a RSS feed. In that case, wait until the specified time and try again and any missed article will appear then. If it is constantly crashing so articles never get loaded, fix that.</div><br/><div id="42487341" class="c"><input type="checkbox" id="c-42487341" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#42486266">root</a><span>|</span><a href="#42486604">parent</a><span>|</span><a href="#42488814">next</a><span>|</span><label class="collapse" for="c-42487341">[-]</label><label class="expand" for="c-42487341">[6 more]</label></div><br/><div class="children"><div class="content">&gt; If it is constantly crashing so articles never get loaded, fix that.<p>This often requires to do lots of tests against the endpoint, which the server prohibits.</div><br/><div id="42487908" class="c"><input type="checkbox" id="c-42487908" checked=""/><div class="controls bullet"><span class="by">im3w1l</span><span>|</span><a href="#42486266">root</a><span>|</span><a href="#42487341">parent</a><span>|</span><a href="#42488814">next</a><span>|</span><label class="collapse" for="c-42487908">[-]</label><label class="expand" for="c-42487908">[5 more]</label></div><br/><div class="children"><div class="content">If you are an rss-reader dev then you can set up a caching layer of your own.</div><br/><div id="42488045" class="c"><input type="checkbox" id="c-42488045" checked=""/><div class="controls bullet"><span class="by">aleph_minus_one</span><span>|</span><a href="#42486266">root</a><span>|</span><a href="#42487908">parent</a><span>|</span><a href="#42490123">next</a><span>|</span><label class="collapse" for="c-42488045">[-]</label><label class="expand" for="c-42488045">[3 more]</label></div><br/><div class="children"><div class="content">&gt; If you are an rss-reader dev then you can set up a caching layer of your own.<p>But are RSS reader devs <i>willing</i> to jump through such hoops?<p>I would claim that writing a (simple) RSS reader (using a programming language that provides suitable libraries) is something that would be rather easy for me, but setting up a caching layer would (because I have less knowledge about the latter topic) take a lot more research from my side concerning how to do it.</div><br/><div id="42492713" class="c"><input type="checkbox" id="c-42492713" checked=""/><div class="controls bullet"><span class="by">ncallaway</span><span>|</span><a href="#42486266">root</a><span>|</span><a href="#42488045">parent</a><span>|</span><a href="#42488933">next</a><span>|</span><label class="collapse" for="c-42492713">[-]</label><label class="expand" for="c-42492713">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but setting up a caching layer would (because I have less knowledge about the latter topic) take a lot more research from my side concerning how to do it.<p>If I was doing local development on an RSS reader, I&#x27;d just download any atom.xml file that seemed relevant, then serve it locally using php -S or some other local HTTP file-system server.<p>That way I can hit that file a million times without bothering any remote server. Plus, then you&#x27;ve made your local development environment stable even in the face of internet outages.<p>And if you automate the local HTTP server setup a little bit, then you can even run local integration tests.<p>I dunno, it seems like if &quot;write an RSS feed reader&quot; is an easy problem, I&#x27;d expect &quot;serve a file from my hard drive over HTTP on localhost&quot; should also be an easy problem.</div><br/></div></div><div id="42488933" class="c"><input type="checkbox" id="c-42488933" checked=""/><div class="controls bullet"><span class="by">im3w1l</span><span>|</span><a href="#42486266">root</a><span>|</span><a href="#42488045">parent</a><span>|</span><a href="#42492713">prev</a><span>|</span><a href="#42490123">next</a><span>|</span><label class="collapse" for="c-42488933">[-]</label><label class="expand" for="c-42488933">[1 more]</label></div><br/><div class="children"><div class="content">Sure, I have done such a thing myself and it was very simple. Let&#x27;s say you do http_get(rss_address). Create a function http_cached_get, that looks for a recent cached response, and if none exists delegates to http_get and saves the response. In python this is like 10 lines.</div><br/></div></div></div></div><div id="42490123" class="c"><input type="checkbox" id="c-42490123" checked=""/><div class="controls bullet"><span class="by">shepherdjerred</span><span>|</span><a href="#42486266">root</a><span>|</span><a href="#42487908">parent</a><span>|</span><a href="#42488045">prev</a><span>|</span><a href="#42488814">next</a><span>|</span><label class="collapse" for="c-42490123">[-]</label><label class="expand" for="c-42490123">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a bit insane</div><br/></div></div></div></div></div></div></div></div><div id="42488814" class="c"><input type="checkbox" id="c-42488814" checked=""/><div class="controls bullet"><span class="by">XCabbage</span><span>|</span><a href="#42486266">parent</a><span>|</span><a href="#42486604">prev</a><span>|</span><a href="#42486581">next</a><span>|</span><label class="collapse" for="c-42488814">[-]</label><label class="expand" for="c-42488814">[1 more]</label></div><br/><div class="children"><div class="content">For that matter, what if it&#x27;s a different device (or entire different human being) on the same IP address?</div><br/></div></div></div></div><div id="42486581" class="c"><input type="checkbox" id="c-42486581" checked=""/><div class="controls bullet"><span class="by">bombcar</span><span>|</span><a href="#42486266">prev</a><span>|</span><a href="#42487439">next</a><span>|</span><label class="collapse" for="c-42486581">[-]</label><label class="expand" for="c-42486581">[2 more]</label></div><br/><div class="children"><div class="content">At some point instead of 429 it should return a feed with this post as always newest.</div><br/><div id="42491334" class="c"><input type="checkbox" id="c-42491334" checked=""/><div class="controls bullet"><span class="by">cpeterso</span><span>|</span><a href="#42486581">parent</a><span>|</span><a href="#42487439">next</a><span>|</span><label class="collapse" for="c-42491334">[-]</label><label class="expand" for="c-42491334">[1 more]</label></div><br/><div class="children"><div class="content">That’s a great point: the client software isn’t listening to the server, so the server software should break the loop by escalating to the human reader. The message response should probably be even more direct with a call to action about their feed reader (naming it, if possible) causing server problems.</div><br/></div></div></div></div><div id="42487439" class="c"><input type="checkbox" id="c-42487439" checked=""/><div class="controls bullet"><span class="by">wheybags</span><span>|</span><a href="#42486581">prev</a><span>|</span><a href="#42487096">next</a><span>|</span><label class="collapse" for="c-42487439">[-]</label><label class="expand" for="c-42487439">[3 more]</label></div><br/><div class="children"><div class="content">Rss is pretty light. Even if you say it&#x27;s too much to be re-sending, you could remove the content from the rss feed (so they need to click through to read it), which would shrink the feed size massively. Alternatively, remove old posts. Or do both.<p>Hopefully you don&#x27;t have some expensive code generating the feed on the fly, so processing overhead is negligible. But if it&#x27;s not, cache the result and reset the cache every time you post.<p>Surely this is easier than spending the effort and emotional bandwidth to care about this issue?<p>I might be wrong here, but this feels more emotionally driven (&quot;someone is wrong on the internet&quot;) than practical.</div><br/><div id="42487553" class="c"><input type="checkbox" id="c-42487553" checked=""/><div class="controls bullet"><span class="by">gavinsyancey</span><span>|</span><a href="#42487439">parent</a><span>|</span><a href="#42487096">next</a><span>|</span><label class="collapse" for="c-42487553">[-]</label><label class="expand" for="c-42487553">[2 more]</label></div><br/><div class="children"><div class="content">As a user of the RSS feed, please don&#x27;t remove content from it so I have to click through. This makes it much less useful and more annoying to use.</div><br/><div id="42488089" class="c"><input type="checkbox" id="c-42488089" checked=""/><div class="controls bullet"><span class="by">wheybags</span><span>|</span><a href="#42487439">root</a><span>|</span><a href="#42487553">parent</a><span>|</span><a href="#42487096">next</a><span>|</span><label class="collapse" for="c-42488089">[-]</label><label class="expand" for="c-42488089">[1 more]</label></div><br/><div class="children"><div class="content">I always click through regardless, because the rss text is probably missing formatting and images. I&#x27;ll never be sure I&#x27;m getting a proper copy of the article unless I click through anyway.</div><br/></div></div></div></div></div></div><div id="42487096" class="c"><input type="checkbox" id="c-42487096" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#42487439">prev</a><span>|</span><a href="#42486133">next</a><span>|</span><label class="collapse" for="c-42487096">[-]</label><label class="expand" for="c-42487096">[2 more]</label></div><br/><div class="children"><div class="content">This is why RSS for the birds.<p>My RSS reader YOShInOn subscribes to 110 RSS feeds through Superfeedr which absolves me of the responsibility of being on the other side of Rachel&#x27;s problem.<p>With RSS you are always polling too fast or too slow;  if you are polling too slow you might even miss items.<p>When a blog gets posted Superfeedr hits an AWS lambda function that stores the entry in SQS so my RSS reader can update itself at its own pace.  The only trouble is Superfeedr costs 10 cents a feed per month which is a good deal for an active feed such as comments from Hacker News or article from <i>The Guardian</i> but is not affordable for subscribing to 2000+ indy blogs which YOShInOn could handle just fine.<p>I might yet write my own RSS head end,  but there is something to say for protocols like ActivityPub and AT Protocol.</div><br/><div id="42489649" class="c"><input type="checkbox" id="c-42489649" checked=""/><div class="controls bullet"><span class="by">rakoo</span><span>|</span><a href="#42487096">parent</a><span>|</span><a href="#42486133">next</a><span>|</span><label class="collapse" for="c-42489649">[-]</label><label class="expand" for="c-42489649">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s why websub (formerly pubsubhubbub) was created and should be the proper solution, not a proprietary middleware</div><br/></div></div></div></div><div id="42486133" class="c"><input type="checkbox" id="c-42486133" checked=""/><div class="controls bullet"><span class="by">RA2lover</span><span>|</span><a href="#42487096">prev</a><span>|</span><a href="#42487298">next</a><span>|</span><label class="collapse" for="c-42486133">[-]</label><label class="expand" for="c-42486133">[1 more]</label></div><br/><div class="children"><div class="content">Related: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42470035">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42470035</a></div><br/></div></div><div id="42487298" class="c"><input type="checkbox" id="c-42487298" checked=""/><div class="controls bullet"><span class="by">donatj</span><span>|</span><a href="#42486133">prev</a><span>|</span><a href="#42486729">next</a><span>|</span><label class="collapse" for="c-42487298">[-]</label><label class="expand" for="c-42487298">[2 more]</label></div><br/><div class="children"><div class="content">On the flip side, what percent of RSS feed <i>generators</i> actually support conditional requests? I&#x27;ve written many over the last twenty years and I can tell you plainly, none of the ones I wrote have.<p>I never even considered the option or necessity. It&#x27;s easy and cheap just to send everything.<p>I guess static generators with a apache style web server probably do, but I can&#x27;t imagine any dynamic generators bother to try to save the small handful of bytes.</div><br/><div id="42489809" class="c"><input type="checkbox" id="c-42489809" checked=""/><div class="controls bullet"><span class="by">aendruk</span><span>|</span><a href="#42487298">parent</a><span>|</span><a href="#42486729">next</a><span>|</span><label class="collapse" for="c-42489809">[-]</label><label class="expand" for="c-42489809">[1 more]</label></div><br/><div class="children"><div class="content">For another perspective, I can offer the data point that the one dynamic feed generator I’ve written supports both If-Modified-Since and If-None-Match, and that I considered that to be an obvious requirement from the beginning.</div><br/></div></div></div></div><div id="42486729" class="c"><input type="checkbox" id="c-42486729" checked=""/><div class="controls bullet"><span class="by">nilslindemann</span><span>|</span><a href="#42487298">prev</a><span>|</span><a href="#42487761">next</a><span>|</span><label class="collapse" for="c-42486729">[-]</label><label class="expand" for="c-42486729">[4 more]</label></div><br/><div class="children"><div class="content">I am stupid, why not just return an HTML document explaining the issue, when there is such an incorrect second request in 20 minutes, then blocking that IP for 24 hours? The feed reader software author has to react, otherwise its users will complain to him, no?</div><br/><div id="42487137" class="c"><input type="checkbox" id="c-42487137" checked=""/><div class="controls bullet"><span class="by">ruszki</span><span>|</span><a href="#42486729">parent</a><span>|</span><a href="#42487030">next</a><span>|</span><label class="collapse" for="c-42487137">[-]</label><label class="expand" for="c-42487137">[2 more]</label></div><br/><div class="children"><div class="content">That’s what 429 return is for, which is mentioned in the article.</div><br/><div id="42492299" class="c"><input type="checkbox" id="c-42492299" checked=""/><div class="controls bullet"><span class="by">Too</span><span>|</span><a href="#42486729">root</a><span>|</span><a href="#42487137">parent</a><span>|</span><a href="#42487030">next</a><span>|</span><label class="collapse" for="c-42492299">[-]</label><label class="expand" for="c-42492299">[1 more]</label></div><br/><div class="children"><div class="content">Most readers presumably keep showing the last valid response when they get an error, so that the user doesn’t notice. Returning a fake ok response, explaining that the reader is dumb, will lift attention to the user. Not that I would advocate for this solution, except for desperate moments.</div><br/></div></div></div></div><div id="42487030" class="c"><input type="checkbox" id="c-42487030" checked=""/><div class="controls bullet"><span class="by">ImPostingOnHN</span><span>|</span><a href="#42486729">parent</a><span>|</span><a href="#42487137">prev</a><span>|</span><a href="#42487761">next</a><span>|</span><label class="collapse" for="c-42487030">[-]</label><label class="expand" for="c-42487030">[1 more]</label></div><br/><div class="children"><div class="content">It might be clever to return an rss feed containing 1 item: the html document you mention.</div><br/></div></div></div></div><div id="42487761" class="c"><input type="checkbox" id="c-42487761" checked=""/><div class="controls bullet"><span class="by">ruuda</span><span>|</span><a href="#42486729">prev</a><span>|</span><a href="#42486645">next</a><span>|</span><label class="collapse" for="c-42487761">[-]</label><label class="expand" for="c-42487761">[1 more]</label></div><br/><div class="children"><div class="content">I have a blog where I post a few posts per year. [1] &#x2F;feed.xml is served with an Expires header of 24 hours. I wrote a tool that allows me to query the webserver logs using SQLite [2]. Over the past 90 days, these are the top 10 requesters grouped by ip address (remote_addr column redacted here):<p><pre><code>    requests_per_day  user_agent
    283               Reeder&#x2F;5050001 CFNetwork&#x2F;1568.300.101 Darwin&#x2F;24.2.0
    274               CommaFeed&#x2F;4.4.0 (https:&#x2F;&#x2F;github.com&#x2F;Athou&#x2F;commafeed)
    127               Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;131.0.0.0 Safari&#x2F;537.36
    52                NetNewsWire (RSS Reader; https:&#x2F;&#x2F;netnewswire.com&#x2F;)
    47                Tiny Tiny RSS&#x2F;23.04-0578bf80 (https:&#x2F;&#x2F;tt-rss.org&#x2F;)
    47                Refeed Reader&#x2F;v1 (+https:&#x2F;&#x2F;www.refeed.dev&#x2F;)
    46                Selfoss&#x2F;2.18 (SimplePie&#x2F;1.5.1; +https:&#x2F;&#x2F;selfoss.aditu.de)
    41                Reeder&#x2F;5040601 CFNetwork&#x2F;1568.100.1.1.1 Darwin&#x2F;24.0.0
    39                Tiny Tiny RSS&#x2F;23.04 (Unsupported) (https:&#x2F;&#x2F;tt-rss.org&#x2F;)
    34                FreshRSS&#x2F;1.24.3 (Linux; https:&#x2F;&#x2F;freshrss.org)
</code></pre>
Reeder is loading the feed every 5 minutes, and in the vast majority of cases it’s getting a 301 response because it tries to access the http version that redirects to https. At least it has state and it gets 304 Not Modified in the remaining cases.<p>If I order by body bytes served rather than number of requests (and group by remote_addr again), these are the worst consumers:<p><pre><code>    body_megabytes_per_year  user_agent
    149.75943975             Refeed Reader&#x2F;v1 (+https:&#x2F;&#x2F;www.refeed.dev&#x2F;)
    95.90771025              Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;131.0.0.0 Safari&#x2F;537.36
    75.00080025              rss-parser
    73.023702                Tiny Tiny RSS&#x2F;24.09-0163884ef (Unsupported) (https:&#x2F;&#x2F;tt-rss.org&#x2F;)
    38.402385                Tiny Tiny RSS&#x2F;24.11-42ebdb02 (https:&#x2F;&#x2F;tt-rss.org&#x2F;)
    37.984539                Selfoss&#x2F;2.20-cf74581 (+https:&#x2F;&#x2F;selfoss.aditu.de)
    30.3982965               NetNewsWire (RSS Reader; https:&#x2F;&#x2F;netnewswire.com&#x2F;)
    28.18013325              Tiny Tiny RSS&#x2F;23.04-0578bf80 (https:&#x2F;&#x2F;tt-rss.org&#x2F;)
    26.330142                Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;84.0.4147.105 Safari&#x2F;537.36
    24.838461                Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;84.0.4147.105 Safari&#x2F;537.36
</code></pre>
The top consumer, Refeed, is responsible for about 2.25% of all egress of my webserver. (Counting only body bytes, not http overhead.)<p>[1]: <a href="https:&#x2F;&#x2F;ruudvanasseldonk.com&#x2F;writing" rel="nofollow">https:&#x2F;&#x2F;ruudvanasseldonk.com&#x2F;writing</a>
[2]: <a href="https:&#x2F;&#x2F;github.com&#x2F;ruuda&#x2F;sqlog&#x2F;blob&#x2F;d129db35da9bbf95d8c2e97d575b4d5beb3bb40c&#x2F;queries&#x2F;feed_readers.sql">https:&#x2F;&#x2F;github.com&#x2F;ruuda&#x2F;sqlog&#x2F;blob&#x2F;d129db35da9bbf95d8c2e97d...</a></div><br/></div></div><div id="42486645" class="c"><input type="checkbox" id="c-42486645" checked=""/><div class="controls bullet"><span class="by">internet2000</span><span>|</span><a href="#42487761">prev</a><span>|</span><a href="#42486552">next</a><span>|</span><label class="collapse" for="c-42486645">[-]</label><label class="expand" for="c-42486645">[2 more]</label></div><br/><div class="children"><div class="content">Does anyone know if FreshRSS behaves properly here?</div><br/><div id="42486717" class="c"><input type="checkbox" id="c-42486717" checked=""/><div class="controls bullet"><span class="by">reocha</span><span>|</span><a href="#42486645">parent</a><span>|</span><a href="#42486552">next</a><span>|</span><label class="collapse" for="c-42486717">[-]</label><label class="expand" for="c-42486717">[1 more]</label></div><br/><div class="children"><div class="content">Earlier article with some info on freshrss: <a href="https:&#x2F;&#x2F;rachelbythebay.com&#x2F;w&#x2F;2024&#x2F;10&#x2F;25&#x2F;fs&#x2F;" rel="nofollow">https:&#x2F;&#x2F;rachelbythebay.com&#x2F;w&#x2F;2024&#x2F;10&#x2F;25&#x2F;fs&#x2F;</a></div><br/></div></div></div></div><div id="42486552" class="c"><input type="checkbox" id="c-42486552" checked=""/><div class="controls bullet"><span class="by">Forge36</span><span>|</span><a href="#42486645">prev</a><span>|</span><a href="#42486551">next</a><span>|</span><label class="collapse" for="c-42486552">[-]</label><label class="expand" for="c-42486552">[1 more]</label></div><br/><div class="children"><div class="content">I couldn&#x27;t find the tester. Thankfully the client i was tested... And it behaves poorly. Thankfully emacs has a client I can switch to!</div><br/></div></div><div id="42486551" class="c"><input type="checkbox" id="c-42486551" checked=""/><div class="controls bullet"><span class="by">6510</span><span>|</span><a href="#42486552">prev</a><span>|</span><a href="#42487830">next</a><span>|</span><label class="collapse" for="c-42486551">[-]</label><label class="expand" for="c-42486551">[1 more]</label></div><br/><div class="children"><div class="content">I ban the feed for 24 hours if it doesnt work.<p>I also design 2 new formats that no one (including myself) has ever implemented.<p><a href="https:&#x2F;&#x2F;go-here.nl&#x2F;ess-and-nno" rel="nofollow">https:&#x2F;&#x2F;go-here.nl&#x2F;ess-and-nno</a><p>enjoy</div><br/></div></div><div id="42487830" class="c"><input type="checkbox" id="c-42487830" checked=""/><div class="controls bullet"><span class="by">mixmastamyk</span><span>|</span><a href="#42486551">prev</a><span>|</span><a href="#42491308">next</a><span>|</span><label class="collapse" for="c-42487830">[-]</label><label class="expand" for="c-42487830">[1 more]</label></div><br/><div class="children"><div class="content">I have a few feeds configured into Thunderbird but wasn’t reading them very often, so I “disabled” them to load manually.  Despite this it tries to contact the sites often and, when not able to (firewall) goes into a frenzy of trying to contact them.  All this despite being disabled.<p>Disappointing combined with the various update sites it tries to contact every startup, which is completely unnecessary as well.  Couple of times a week should be the maximum rate.</div><br/></div></div><div id="42487945" class="c"><input type="checkbox" id="c-42487945" checked=""/><div class="controls bullet"><span class="by">euroderf</span><span>|</span><a href="#42486282">prev</a><span>|</span><a href="#42486193">next</a><span>|</span><label class="collapse" for="c-42487945">[-]</label><label class="expand" for="c-42487945">[6 more]</label></div><br/><div class="children"><div class="content">which =&gt; that</div><br/><div id="42487993" class="c"><input type="checkbox" id="c-42487993" checked=""/><div class="controls bullet"><span class="by">thaumasiotes</span><span>|</span><a href="#42487945">parent</a><span>|</span><a href="#42486193">next</a><span>|</span><label class="collapse" for="c-42487993">[-]</label><label class="expand" for="c-42487993">[5 more]</label></div><br/><div class="children"><div class="content">They&#x27;re exactly equivalent. What are you hoping to correct?</div><br/><div id="42488361" class="c"><input type="checkbox" id="c-42488361" checked=""/><div class="controls bullet"><span class="by">euroderf</span><span>|</span><a href="#42487945">root</a><span>|</span><a href="#42487993">parent</a><span>|</span><a href="#42486193">next</a><span>|</span><label class="collapse" for="c-42488361">[-]</label><label class="expand" for="c-42488361">[4 more]</label></div><br/><div class="children"><div class="content">They&#x27;re obviously not.<p>It&#x27;s a Britticism (AFAICT) making inroads.</div><br/><div id="42489795" class="c"><input type="checkbox" id="c-42489795" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#42487945">root</a><span>|</span><a href="#42488361">parent</a><span>|</span><a href="#42490655">next</a><span>|</span><label class="collapse" for="c-42489795">[-]</label><label class="expand" for="c-42489795">[1 more]</label></div><br/><div class="children"><div class="content">Oh no, not the British influencing the English language! I can&#x27;t be arsed* about which vs. that when &quot;on accident&quot; has become semi-accepted (as the opposite of &quot;on purpose&quot;). Yuck.</div><br/></div></div><div id="42490655" class="c"><input type="checkbox" id="c-42490655" checked=""/><div class="controls bullet"><span class="by">thaumasiotes</span><span>|</span><a href="#42487945">root</a><span>|</span><a href="#42488361">parent</a><span>|</span><a href="#42489795">prev</a><span>|</span><a href="#42489644">next</a><span>|</span><label class="collapse" for="c-42490655">[-]</label><label class="expand" for="c-42490655">[1 more]</label></div><br/><div class="children"><div class="content">What do you hope to accomplish by making random false statements?</div><br/></div></div></div></div></div></div></div></div><div id="42486193" class="c"><input type="checkbox" id="c-42486193" checked=""/><div class="controls bullet"><span class="by">kelsey98765431</span><span>|</span><a href="#42487945">prev</a><span>|</span><a href="#42486850">next</a><span>|</span><label class="collapse" for="c-42486193">[-]</label><label class="expand" for="c-42486193">[12 more]</label></div><br/><div class="children"><div class="content">if you have to 429 people for an rss feed the problem is you</div><br/><div id="42486284" class="c"><input type="checkbox" id="c-42486284" checked=""/><div class="controls bullet"><span class="by">quectophoton</span><span>|</span><a href="#42486193">parent</a><span>|</span><a href="#42486311">next</a><span>|</span><label class="collapse" for="c-42486284">[-]</label><label class="expand" for="c-42486284">[3 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s an acceptable response. Not only there&#x27;s no SLA, but people are free to not provide a service to misbehaving user agents. It&#x27;s like rejecting connections from Tor.<p>If anything, a 429 is a nice heads up. It could have been worse; she could have redirected those requests to a separate URL with an... unpleasant content, like a certain domain that redirects to I-don&#x27;t-know-what whenever they detect the Referer header is from HN.</div><br/><div id="42487000" class="c"><input type="checkbox" id="c-42487000" checked=""/><div class="controls bullet"><span class="by">redleader55</span><span>|</span><a href="#42486193">root</a><span>|</span><a href="#42486284">parent</a><span>|</span><a href="#42486311">next</a><span>|</span><label class="collapse" for="c-42487000">[-]</label><label class="expand" for="c-42487000">[2 more]</label></div><br/><div class="children"><div class="content">As interesting as that site is, and as much as I sympathise with the author&#x27;s plight, that site&#x27;s behavior is so anti-me that I&#x27;m going to ignore it whenever&#x2F;wherever it pops up. I&#x27;m not trolling the author, I&#x27;m not calling them names or anything, I was just interested in the technical stuff. I wish them good luck.</div><br/><div id="42489951" class="c"><input type="checkbox" id="c-42489951" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#42486193">root</a><span>|</span><a href="#42487000">parent</a><span>|</span><a href="#42486311">next</a><span>|</span><label class="collapse" for="c-42489951">[-]</label><label class="expand" for="c-42489951">[1 more]</label></div><br/><div class="children"><div class="content">I think that&#x27;s the whole point - <i>that</i> author won&#x27;t begrudge you for not visiting their site. They detest HN ideologically, so losing HNer traffic won&#x27;t ruin their day.</div><br/></div></div></div></div></div></div><div id="42486311" class="c"><input type="checkbox" id="c-42486311" checked=""/><div class="controls bullet"><span class="by">noident</span><span>|</span><a href="#42486193">parent</a><span>|</span><a href="#42486284">prev</a><span>|</span><a href="#42486265">next</a><span>|</span><label class="collapse" for="c-42486311">[-]</label><label class="expand" for="c-42486311">[4 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a particular type of person that scours their HTTP logs and makes up rules that block 90% of feed readers using the default poll interval. If I stick your RSS feed into Miniflux and I get 429&#x27;d, I just stop reading your blog. Learn2cache. I&#x27;m talking to you, Cheapskate&#x27;s Guide.</div><br/><div id="42492743" class="c"><input type="checkbox" id="c-42492743" checked=""/><div class="controls bullet"><span class="by">ncallaway</span><span>|</span><a href="#42486193">root</a><span>|</span><a href="#42486311">parent</a><span>|</span><a href="#42486860">next</a><span>|</span><label class="collapse" for="c-42492743">[-]</label><label class="expand" for="c-42492743">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Learn2cache<p>I find this a particularly amusing comment, given that the main complaint is about feed reader&#x27;s not sending conditional requests.<p>Learn2cache indeed, feed reader authors.</div><br/></div></div><div id="42486860" class="c"><input type="checkbox" id="c-42486860" checked=""/><div class="controls bullet"><span class="by">Kudos</span><span>|</span><a href="#42486193">root</a><span>|</span><a href="#42486311">parent</a><span>|</span><a href="#42492743">prev</a><span>|</span><a href="#42486265">next</a><span>|</span><label class="collapse" for="c-42486860">[-]</label><label class="expand" for="c-42486860">[2 more]</label></div><br/><div class="children"><div class="content">This site would not 429 current Miniflux, since it makes conditional requests. She has a previous post outlining cache respecting behaviour of many common feed readers.</div><br/><div id="42486952" class="c"><input type="checkbox" id="c-42486952" checked=""/><div class="controls bullet"><span class="by">Kwpolska</span><span>|</span><a href="#42486193">root</a><span>|</span><a href="#42486860">parent</a><span>|</span><a href="#42486265">next</a><span>|</span><label class="collapse" for="c-42486952">[-]</label><label class="expand" for="c-42486952">[1 more]</label></div><br/><div class="children"><div class="content">It could 429 it for conditional requests as well:<p>&gt; Unconditional requests: at most once per 24 hour period.<p>&gt; Conditional requests: at most once per 60 minute period.<p>(Source: calling `curl hxxps:&#x2F;&#x2F;rachelbythebay[.]com&#x2F;w&#x2F;atom.xml` twice)</div><br/></div></div></div></div></div></div><div id="42486265" class="c"><input type="checkbox" id="c-42486265" checked=""/><div class="controls bullet"><span class="by">dxdm</span><span>|</span><a href="#42486193">parent</a><span>|</span><a href="#42486311">prev</a><span>|</span><a href="#42486592">next</a><span>|</span><label class="collapse" for="c-42486265">[-]</label><label class="expand" for="c-42486265">[2 more]</label></div><br/><div class="children"><div class="content">Nobody owes these people and their feed readers a 200 whenever they want one.</div><br/></div></div><div id="42486592" class="c"><input type="checkbox" id="c-42486592" checked=""/><div class="controls bullet"><span class="by">silvestrov</span><span>|</span><a href="#42486193">parent</a><span>|</span><a href="#42486265">prev</a><span>|</span><a href="#42486242">next</a><span>|</span><label class="collapse" for="c-42486592">[-]</label><label class="expand" for="c-42486592">[1 more]</label></div><br/><div class="children"><div class="content">not when the client sends <i>unconditional requests</i> i.e. missing If-Modified-Since and If-None-Match headers.<p>All feed readers&#x2F;clients should cache responses when sending multiple requests the same day.</div><br/></div></div><div id="42486242" class="c"><input type="checkbox" id="c-42486242" checked=""/><div class="controls bullet"><span class="by">ramses0</span><span>|</span><a href="#42486193">parent</a><span>|</span><a href="#42486592">prev</a><span>|</span><a href="#42486850">next</a><span>|</span><label class="collapse" for="c-42486242">[-]</label><label class="expand" for="c-42486242">[1 more]</label></div><br/><div class="children"><div class="content">If you don&#x27;t stop at red lights, the problem is other people. &#x2F;s</div><br/></div></div></div></div></div></div></div></div></div></body></html>