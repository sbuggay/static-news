<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709283672982" as="style"/><link rel="stylesheet" href="styles.css?v=1709283672982"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://vickiboykis.com/2024/02/28/gguf-the-long-way-around/">GGUF, the Long Way Around</a>Â <span class="domain">(<a href="https://vickiboykis.com">vickiboykis.com</a>)</span></div><div class="subtext"><span>Tomte</span> | <span>27 comments</span></div><br/><div><div id="39555528" class="c"><input type="checkbox" id="c-39555528" checked=""/><div class="controls bullet"><span class="by">tbalsam</span><span>|</span><a href="#39556156">next</a><span>|</span><label class="collapse" for="c-39555528">[-]</label><label class="expand" for="c-39555528">[12 more]</label></div><br/><div class="children"><div class="content">Llama.cpp I think has a ton of clone-and-own boilerplate, presumably from having grown so quickly (I think one of their .cu files is over 10k lines or so, roughly, ATM).<p>While I haven&#x27;t seen the model storage and distribution format, the rewrite to GGUF for file storage seems to have been a big boon&#x2F;boost to the project. Thanks Phil! Cool stuff. Also, he&#x27;s a really nice guy to boot. Please say hi from Fern to him if you ever run into him. I mean it literally, make his life a hellish barrage of nonstop greetings from Fern.</div><br/><div id="39557515" class="c"><input type="checkbox" id="c-39557515" checked=""/><div class="controls bullet"><span class="by">qrios</span><span>|</span><a href="#39555528">parent</a><span>|</span><a href="#39555554">next</a><span>|</span><label class="collapse" for="c-39557515">[-]</label><label class="expand" for="c-39557515">[2 more]</label></div><br/><div class="children"><div class="content">Thank you for the reference to the CUDA file [1]. It&#x27;s always nice to see how complex data structures are handled in GPUs. Does anyone have any idea what the bit patterns are for (starting at line 1529)?<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;blob&#x2F;master&#x2F;ggml-cuda.cu">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;blob&#x2F;master&#x2F;ggml-cuda...</a></div><br/><div id="39558158" class="c"><input type="checkbox" id="c-39558158" checked=""/><div class="controls bullet"><span class="by">thrtythreeforty</span><span>|</span><a href="#39555528">root</a><span>|</span><a href="#39557515">parent</a><span>|</span><a href="#39555554">next</a><span>|</span><label class="collapse" for="c-39558158">[-]</label><label class="expand" for="c-39558158">[1 more]</label></div><br/><div class="children"><div class="content">Those have to do with dequantization. It involves table lookups and some adjusting math.</div><br/></div></div></div></div><div id="39555554" class="c"><input type="checkbox" id="c-39555554" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#39555528">parent</a><span>|</span><a href="#39557515">prev</a><span>|</span><a href="#39556156">next</a><span>|</span><label class="collapse" for="c-39555554">[-]</label><label class="expand" for="c-39555554">[9 more]</label></div><br/><div class="children"><div class="content">I honestly think have a way to just use json (a.k.a. safetensors) &#x2F; msgpack or some lightweight metadata serializer is a better route than coming up with a new file format. That&#x27;s also why I just use SQLite to serialize the metadata (and tensor weights, this part is an oversight).</div><br/><div id="39555770" class="c"><input type="checkbox" id="c-39555770" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#39555528">root</a><span>|</span><a href="#39555554">parent</a><span>|</span><a href="#39557030">next</a><span>|</span><label class="collapse" for="c-39555770">[-]</label><label class="expand" for="c-39555770">[7 more]</label></div><br/><div class="children"><div class="content">Gguf is cleaner to read in languages that don&#x27;t have a json parsing library, and works with memory mapping in C. It&#x27;s very appealing for minimal inference frameworks vs other options.</div><br/><div id="39555825" class="c"><input type="checkbox" id="c-39555825" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#39555528">root</a><span>|</span><a href="#39555770">parent</a><span>|</span><a href="#39556542">next</a><span>|</span><label class="collapse" for="c-39555825">[-]</label><label class="expand" for="c-39555825">[3 more]</label></div><br/><div class="children"><div class="content">safetensors can mmap too because the tensor data are just offsets and you are free to align to whatever you want.<p>It is hard to keep metadata minimal, and before long, you will start to have many different &quot;atom&quot;s and end-up with things that mov supports but mp4 doesn&#x27;t etc etc. (mov format is generally well-defined and easy-to-parse, but being a binary format, you have to write your parser etc is not a pleasant experience).<p>If you just want minimal dependency, flatbuffers, capnproto, json are all well-supported on many platforms.</div><br/><div id="39556218" class="c"><input type="checkbox" id="c-39556218" checked=""/><div class="controls bullet"><span class="by">jart</span><span>|</span><a href="#39555528">root</a><span>|</span><a href="#39555825">parent</a><span>|</span><a href="#39556542">next</a><span>|</span><label class="collapse" for="c-39556218">[-]</label><label class="expand" for="c-39556218">[2 more]</label></div><br/><div class="children"><div class="content">mmap() requires that you map at page aligned intervals which must be congruent with the file offset. You can&#x27;t just round down because some gpus like metal require that the data pointers themselves be page aligned too.</div><br/><div id="39556317" class="c"><input type="checkbox" id="c-39556317" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#39555528">root</a><span>|</span><a href="#39556218">parent</a><span>|</span><a href="#39556542">next</a><span>|</span><label class="collapse" for="c-39556317">[-]</label><label class="expand" for="c-39556317">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, safetensors separates metadata and tensor data. The metadata is an offset reference to the tensor data that you are free to define yourselves. In that way, you can create files in safetensors format but the tensor data itself is paged aligned offsets.</div><br/></div></div></div></div></div></div><div id="39556542" class="c"><input type="checkbox" id="c-39556542" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39555528">root</a><span>|</span><a href="#39555770">parent</a><span>|</span><a href="#39555825">prev</a><span>|</span><a href="#39557030">next</a><span>|</span><label class="collapse" for="c-39556542">[-]</label><label class="expand" for="c-39556542">[3 more]</label></div><br/><div class="children"><div class="content">But usually AWQ get recommended for GPU inference over GGUF</div><br/><div id="39557008" class="c"><input type="checkbox" id="c-39557008" checked=""/><div class="controls bullet"><span class="by">Mathnerd314</span><span>|</span><a href="#39555528">root</a><span>|</span><a href="#39556542">parent</a><span>|</span><a href="#39557756">next</a><span>|</span><label class="collapse" for="c-39557008">[-]</label><label class="expand" for="c-39557008">[1 more]</label></div><br/><div class="children"><div class="content">By who? Only comparison I have seen is that it sucks vs. EXL2 <a href="https:&#x2F;&#x2F;oobabooga.github.io&#x2F;blog&#x2F;posts&#x2F;gptq-awq-exl2-llamacpp&#x2F;" rel="nofollow">https:&#x2F;&#x2F;oobabooga.github.io&#x2F;blog&#x2F;posts&#x2F;gptq-awq-exl2-llamacp...</a></div><br/></div></div><div id="39557756" class="c"><input type="checkbox" id="c-39557756" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#39555528">root</a><span>|</span><a href="#39556542">parent</a><span>|</span><a href="#39557008">prev</a><span>|</span><a href="#39557030">next</a><span>|</span><label class="collapse" for="c-39557756">[-]</label><label class="expand" for="c-39557756">[1 more]</label></div><br/><div class="children"><div class="content">Haven&#x27;t heard this. Was this a few months ago? A lot happens in this space over that time span.</div><br/></div></div></div></div></div></div><div id="39557030" class="c"><input type="checkbox" id="c-39557030" checked=""/><div class="controls bullet"><span class="by">fzzzy</span><span>|</span><a href="#39555528">root</a><span>|</span><a href="#39555554">parent</a><span>|</span><a href="#39555770">prev</a><span>|</span><a href="#39556156">next</a><span>|</span><label class="collapse" for="c-39557030">[-]</label><label class="expand" for="c-39557030">[1 more]</label></div><br/><div class="children"><div class="content">I think a binary format is obviously the right answer here.</div><br/></div></div></div></div></div></div><div id="39556156" class="c"><input type="checkbox" id="c-39556156" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#39555528">prev</a><span>|</span><a href="#39557615">next</a><span>|</span><label class="collapse" for="c-39556156">[-]</label><label class="expand" for="c-39556156">[2 more]</label></div><br/><div class="children"><div class="content">&gt; GPT-Generated Unified Format<p>GG is Georgi Gerganov</div><br/><div id="39558711" class="c"><input type="checkbox" id="c-39558711" checked=""/><div class="controls bullet"><span class="by">kristjansson</span><span>|</span><a href="#39556156">parent</a><span>|</span><a href="#39557615">next</a><span>|</span><label class="collapse" for="c-39558711">[-]</label><label class="expand" for="c-39558711">[1 more]</label></div><br/><div class="children"><div class="content">Nothing like a good backronym</div><br/></div></div></div></div><div id="39557615" class="c"><input type="checkbox" id="c-39557615" checked=""/><div class="controls bullet"><span class="by">null_point</span><span>|</span><a href="#39556156">prev</a><span>|</span><a href="#39557357">next</a><span>|</span><label class="collapse" for="c-39557615">[-]</label><label class="expand" for="c-39557615">[1 more]</label></div><br/><div class="children"><div class="content">Cool. I was just learning about GGUF by creating my own parser for it based on the spec <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;ggml&#x2F;blob&#x2F;master&#x2F;docs&#x2F;gguf.md">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;ggml&#x2F;blob&#x2F;master&#x2F;docs&#x2F;gguf.md</a> (for educational purposes)</div><br/></div></div><div id="39557357" class="c"><input type="checkbox" id="c-39557357" checked=""/><div class="controls bullet"><span class="by">SOLAR_FIELDS</span><span>|</span><a href="#39557615">prev</a><span>|</span><a href="#39555463">next</a><span>|</span><label class="collapse" for="c-39557357">[-]</label><label class="expand" for="c-39557357">[1 more]</label></div><br/><div class="children"><div class="content">âno yappingâ gave me a bit of a chuckle. Quick way to ask the response to be brief I guess.</div><br/></div></div><div id="39555463" class="c"><input type="checkbox" id="c-39555463" checked=""/><div class="controls bullet"><span class="by">RicoElectrico</span><span>|</span><a href="#39557357">prev</a><span>|</span><a href="#39555422">next</a><span>|</span><label class="collapse" for="c-39555463">[-]</label><label class="expand" for="c-39555463">[6 more]</label></div><br/><div class="children"><div class="content">As LLMs have quite minor changes between architectures, would it make sense to just embed the model compiled to some sort of simple bytecode right in the GGUF file? Then, only implement specific new operations when researchers come up with a new model that gains enough traction to be of interest.</div><br/><div id="39555520" class="c"><input type="checkbox" id="c-39555520" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#39555463">parent</a><span>|</span><a href="#39555494">next</a><span>|</span><label class="collapse" for="c-39555520">[-]</label><label class="expand" for="c-39555520">[1 more]</label></div><br/><div class="children"><div class="content">Not really. We&#x27;ve been on that road before. Embedding computation graph into the file makes changes to the computation graph harder (you need to make sure it is backward compatible). This is OK in general (as we have onnx already), but then if you have dynamic shape and the fact that different optimizations we implemented are actually tied to the computation graph, this is simply not optimal. (BTW, this is why PyTorch just embed the code into the pth file, much easier and backward compatible than a static computation graph).</div><br/></div></div><div id="39555494" class="c"><input type="checkbox" id="c-39555494" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#39555463">parent</a><span>|</span><a href="#39555520">prev</a><span>|</span><a href="#39555533">next</a><span>|</span><label class="collapse" for="c-39555494">[-]</label><label class="expand" for="c-39555494">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, but you want to avoid remote code execution:<p><a href="https:&#x2F;&#x2F;www.bleepingcomputer.com&#x2F;news&#x2F;security&#x2F;malicious-ai-models-on-hugging-face-backdoor-users-machines&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.bleepingcomputer.com&#x2F;news&#x2F;security&#x2F;malicious-ai-...</a></div><br/><div id="39555518" class="c"><input type="checkbox" id="c-39555518" checked=""/><div class="controls bullet"><span class="by">RicoElectrico</span><span>|</span><a href="#39555463">root</a><span>|</span><a href="#39555494">parent</a><span>|</span><a href="#39555533">next</a><span>|</span><label class="collapse" for="c-39555518">[-]</label><label class="expand" for="c-39555518">[2 more]</label></div><br/><div class="children"><div class="content">The bytecode would not even need to be Turing-complete. Or maybe it could take inspiration from eBPF which gives some guarantees. What you posted is related to the design oversight of Python&#x27;s pickle format.</div><br/><div id="39555721" class="c"><input type="checkbox" id="c-39555721" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#39555463">root</a><span>|</span><a href="#39555518">parent</a><span>|</span><a href="#39555533">next</a><span>|</span><label class="collapse" for="c-39555721">[-]</label><label class="expand" for="c-39555721">[1 more]</label></div><br/><div class="children"><div class="content">I think ONNX does what you say.</div><br/></div></div></div></div></div></div><div id="39555533" class="c"><input type="checkbox" id="c-39555533" checked=""/><div class="controls bullet"><span class="by">rahimnathwani</span><span>|</span><a href="#39555463">parent</a><span>|</span><a href="#39555494">prev</a><span>|</span><a href="#39555422">next</a><span>|</span><label class="collapse" for="c-39555533">[-]</label><label class="expand" for="c-39555533">[1 more]</label></div><br/><div class="children"><div class="content">It seems like a lot of innovation is around training, no? GGML (the library that reads GGUF format) supports these values for the 
required &#x27;general.architecture&#x27;:<p><pre><code>  llama
  mpt
  gptneox
  gptj
  gpt2
  bloom
  falcon
  rwkv</code></pre></div><br/></div></div></div></div><div id="39555422" class="c"><input type="checkbox" id="c-39555422" checked=""/><div class="controls bullet"><span class="by">cooper_ganglia</span><span>|</span><a href="#39555463">prev</a><span>|</span><a href="#39555314">next</a><span>|</span><label class="collapse" for="c-39555422">[-]</label><label class="expand" for="c-39555422">[1 more]</label></div><br/><div class="children"><div class="content">Iâve been looking for a good resource on GGUF for the past week or so, the timing on this is awesome! Thanks!</div><br/></div></div><div id="39554858" class="c"><input type="checkbox" id="c-39554858" checked=""/><div class="controls bullet"><span class="by">skadamat</span><span>|</span><a href="#39555314">prev</a><span>|</span><a href="#39555755">next</a><span>|</span><label class="collapse" for="c-39554858">[-]</label><label class="expand" for="c-39554858">[1 more]</label></div><br/><div class="children"><div class="content">This is an excellent deep dive! Love the depth here Vicki</div><br/></div></div></div></div></div></div></div></body></html>