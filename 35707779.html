<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="apple-mobile-web-app-capable" content="yes"/><link rel="preload" href="styles.css?v=1682488128755" as="style"/><link rel="stylesheet" href="styles.css?v=1682488128755"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.economist.com/science-and-technology/2023/04/05/it-doesnt-take-much-to-make-machine-learning-algorithms-go-awry">It doesn’t take much to make machine-learning algorithms go awry</a> <span class="domain">(<a href="https://www.economist.com">www.economist.com</a>)</span></div><div class="subtext"><span>escot</span> | <span>42 comments</span></div><br/><div><div id="35708691" class="c"><input type="checkbox" id="c-35708691" checked=""/><div class="controls bullet"><span class="by">neonate</span><span>|</span><a href="#35708877">next</a><span>|</span><label class="collapse" for="c-35708691">[-]</label><label class="expand" for="c-35708691">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.ph&#x2F;5l1k3" rel="nofollow">https:&#x2F;&#x2F;archive.ph&#x2F;5l1k3</a><p><a href="http:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230425224847&#x2F;https:&#x2F;&#x2F;www.economist.com&#x2F;science-and-technology&#x2F;2023&#x2F;04&#x2F;05&#x2F;it-doesnt-take-much-to-make-machine-learning-algorithms-go-awry" rel="nofollow">http:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230425224847&#x2F;https:&#x2F;&#x2F;www.econom...</a></div><br/></div></div><div id="35708877" class="c"><input type="checkbox" id="c-35708877" checked=""/><div class="controls bullet"><span class="by">danShumway</span><span>|</span><a href="#35708691">prev</a><span>|</span><a href="#35709904">next</a><span>|</span><label class="collapse" for="c-35708877">[-]</label><label class="expand" for="c-35708877">[10 more]</label></div><br/><div class="children"><div class="content">Site scraping&#x2F;searching tools work today because they&#x27;re relatively new and most websites <i>aren&#x27;t</i> embedding information designed to be read only by the AI to mess with its summaries&#x2F;recommendations&#x2F;commands.<p>If they ever become more common and more accessible, that will change.<p>In the same way, we didn&#x27;t need to have guards against malicious SEO attacks and keyword stuffing until after search engines became more popular. People are assuming this is a niche problem, but the incentives for random websites to mess with whatever AI is looking at them will be exactly the same as the incentives that currently exist to do SEO. It won&#x27;t just be random demos doing this -- practically every single commercial website that&#x27;s willing to do SEO today will also be attempting to manipulate the AI that&#x27;s parsing them. It will not be safe to feed the results of a Google search into an LLM.<p>The tech industry is seriously sticking its head in the sand here. The ease by which current LLM models (including GPT-4) can be derailed is a critical problem that <i>must</i> be solved before they see widespread use outside of niche circles.</div><br/><div id="35708952" class="c"><input type="checkbox" id="c-35708952" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#35708877">parent</a><span>|</span><a href="#35709523">next</a><span>|</span><label class="collapse" for="c-35708952">[-]</label><label class="expand" for="c-35708952">[4 more]</label></div><br/><div class="children"><div class="content">This is a fabulous insight.<p>I would note that end users will have to filter both SEO-like manipulations and whatever biases the AI creator intentionally and unintentionally inserts.<p>I mean, the present shittiness that is Google is a product of both the endless battle that is SEO vs anti-SEO and an endless pressure for Google themselves to squeeze every ounce of return they out of search results. But stuff won&#x27;t end with the arrival of ChatGPT.</div><br/><div id="35709106" class="c"><input type="checkbox" id="c-35709106" checked=""/><div class="controls bullet"><span class="by">danShumway</span><span>|</span><a href="#35708877">root</a><span>|</span><a href="#35708952">parent</a><span>|</span><a href="#35709523">next</a><span>|</span><label class="collapse" for="c-35709106">[-]</label><label class="expand" for="c-35709106">[3 more]</label></div><br/><div class="children"><div class="content">&gt; and an endless pressure for Google themselves to squeeze every ounce of return they out of search results<p>I&#x27;m not exactly sure if people are seeing some kind of implication in this comment that I&#x27;m not seeing that&#x27;s prompting downvotes, but I agree, there is an incredibly high likelihood that some company somewhere is currently working on inserting advertising into LLM prompts.<p>I don&#x27;t have horribly strong opinions here, but my suspicion is that advertising around LLM output is going to be difficult <i>unless</i> those ads go native, in which case the obvious way to monetize an LLM summary with ads is going to be to get that LLM to offhandedly mention during its summary that you should be drinking a Coke.<p>Or more likely, that when you ask Google Bard how to install a hard drive, it generates an answer that involves you buying a sponsored screwdriver as part of its tutorial. So yeah, if that happens, you are going to have to personally interpret the LLM output through the lens of &quot;how has the company biased this answer to get me to spend money?&quot;<p>Again, I don&#x27;t feel <i>as</i> strong about this prediction as I do about the security angle, but... unless people think normal consumers outside of the tech industry are going to suddenly start paying money for search access, advertising is going to start popping up in some form. And the trend with normal search has been getting those ads to be treated more and more inline with the rest of the search results. I kind of suspect LLM-based search will go the same way.</div><br/><div id="35709331" class="c"><input type="checkbox" id="c-35709331" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#35708877">root</a><span>|</span><a href="#35709106">parent</a><span>|</span><a href="#35709381">next</a><span>|</span><label class="collapse" for="c-35709331">[-]</label><label class="expand" for="c-35709331">[1 more]</label></div><br/><div class="children"><div class="content">This goes past product placement. Suppose you <i>use</i> LLM output to poison the next round of training. Generate a large volume of content describing your products as the best or only option and denigrating the competition as unreliable overpriced crap etc., then let that get absorbed into the next model.<p>It even goes beyond product marketing. Apply the same mechanism to political propaganda.</div><br/></div></div><div id="35709381" class="c"><input type="checkbox" id="c-35709381" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#35708877">root</a><span>|</span><a href="#35709106">parent</a><span>|</span><a href="#35709331">prev</a><span>|</span><a href="#35709523">next</a><span>|</span><label class="collapse" for="c-35709381">[-]</label><label class="expand" for="c-35709381">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t Bing Chat already have ads?</div><br/></div></div></div></div></div></div><div id="35709523" class="c"><input type="checkbox" id="c-35709523" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#35708877">parent</a><span>|</span><a href="#35708952">prev</a><span>|</span><a href="#35709193">next</a><span>|</span><label class="collapse" for="c-35709523">[-]</label><label class="expand" for="c-35709523">[1 more]</label></div><br/><div class="children"><div class="content">If you search the whole web, sure. Limiting search to Wikipedia (or similar trusted sites) would help, because there are editors watching who care about vandalism. The attacks added by the researchers will be another thing to watch out for.<p>This comes down to whether the website and the bot have an adversarial relationship or not, and who can detect the difference. Eventually it becomes a cat and mouse game.<p>One can hope that sources of good information will be paid, eventually.</div><br/></div></div><div id="35709193" class="c"><input type="checkbox" id="c-35709193" checked=""/><div class="controls bullet"><span class="by">linkjuice4all</span><span>|</span><a href="#35708877">parent</a><span>|</span><a href="#35709523">prev</a><span>|</span><a href="#35709269">next</a><span>|</span><label class="collapse" for="c-35709193">[-]</label><label class="expand" for="c-35709193">[2 more]</label></div><br/><div class="children"><div class="content">Just render the site so the AI gets to “see” whatever the humans see. You can also take into account the visual relationship and infer other data from visual analysis of the rendered page.</div><br/><div id="35709362" class="c"><input type="checkbox" id="c-35709362" checked=""/><div class="controls bullet"><span class="by">AlotOfReading</span><span>|</span><a href="#35708877">root</a><span>|</span><a href="#35709193">parent</a><span>|</span><a href="#35709269">next</a><span>|</span><label class="collapse" for="c-35709362">[-]</label><label class="expand" for="c-35709362">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s vulnerable to a straightforward adversarial input attack. Do you have a good way around that issue?</div><br/></div></div></div></div><div id="35709269" class="c"><input type="checkbox" id="c-35709269" checked=""/><div class="controls bullet"><span class="by">droopyEyelids</span><span>|</span><a href="#35708877">parent</a><span>|</span><a href="#35709193">prev</a><span>|</span><a href="#35709904">next</a><span>|</span><label class="collapse" for="c-35709269">[-]</label><label class="expand" for="c-35709269">[2 more]</label></div><br/><div class="children"><div class="content">Will the incentives be the same?<p>Right now the incentive is to keep users on pages to show them ads.<p>How does the site owner get ad revenue from the AI training on their site?</div><br/><div id="35709825" class="c"><input type="checkbox" id="c-35709825" checked=""/><div class="controls bullet"><span class="by">thayne</span><span>|</span><a href="#35708877">root</a><span>|</span><a href="#35709269">parent</a><span>|</span><a href="#35709904">next</a><span>|</span><label class="collapse" for="c-35709825">[-]</label><label class="expand" for="c-35709825">[1 more]</label></div><br/><div class="children"><div class="content">One possibility is companies pay a website to include desirable content (i.e. ads) in the information fed to the AI.</div><br/></div></div></div></div></div></div><div id="35709904" class="c"><input type="checkbox" id="c-35709904" checked=""/><div class="controls bullet"><span class="by">xeonax</span><span>|</span><a href="#35708877">prev</a><span>|</span><a href="#35708787">next</a><span>|</span><label class="collapse" for="c-35709904">[-]</label><label class="expand" for="c-35709904">[1 more]</label></div><br/><div class="children"><div class="content">I have experienced it first hand, while I was attempting machine learning. I was trying to make a machine learn how to do flips in 4 wheeled vehicle.
In my first attempt it learned to die as fast as possible. It learned that since doing that reduces its existence penalty.</div><br/></div></div><div id="35708787" class="c"><input type="checkbox" id="c-35708787" checked=""/><div class="controls bullet"><span class="by">Nuzzerino</span><span>|</span><a href="#35709904">prev</a><span>|</span><a href="#35709426">next</a><span>|</span><label class="collapse" for="c-35708787">[-]</label><label class="expand" for="c-35708787">[23 more]</label></div><br/><div class="children"><div class="content">Until AI can consistently and correctly answer to “where did you learn that?”, it is fundamentally defective as a technology and should absolutely be out of the question for attempts at AGI.</div><br/><div id="35708856" class="c"><input type="checkbox" id="c-35708856" checked=""/><div class="controls bullet"><span class="by">robotresearcher</span><span>|</span><a href="#35708787">parent</a><span>|</span><a href="#35708950">next</a><span>|</span><label class="collapse" for="c-35708856">[-]</label><label class="expand" for="c-35708856">[9 more]</label></div><br/><div class="children"><div class="content">Where did you learn that?</div><br/><div id="35709928" class="c"><input type="checkbox" id="c-35709928" checked=""/><div class="controls bullet"><span class="by">somenameforme</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35708856">parent</a><span>|</span><a href="#35709134">next</a><span>|</span><label class="collapse" for="c-35709928">[-]</label><label class="expand" for="c-35709928">[1 more]</label></div><br/><div class="children"><div class="content">He is almost certainly referring to factual type queries of the sorts including &#x27;how to do x in y.&#x27;<p>About the zillionth time you get &#x27;I&#x27;m sorry, you&#x27;re right, [blah] doesn&#x27;t exist. Here&#x27;s [something else that doesn&#x27;t exist]&#x27;, it gets really frustrating. The worst part is you can often tell the software is referencing some relevant page(s), but just inappropriately mixing them with other stuff. And so if you could simply get the link it&#x27;d be far more helpful than listening to the program continuing to describe in immaculate detail how to use an API that does exactly what you&#x27;re looking for, with the slight problem that it doesn&#x27;t exist.</div><br/></div></div><div id="35709134" class="c"><input type="checkbox" id="c-35709134" checked=""/><div class="controls bullet"><span class="by">asdfman123</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35708856">parent</a><span>|</span><a href="#35709928">prev</a><span>|</span><a href="#35708933">next</a><span>|</span><label class="collapse" for="c-35709134">[-]</label><label class="expand" for="c-35709134">[2 more]</label></div><br/><div class="children"><div class="content">Oh, that’s easy, most of my opinions are regurgitations of other comments I’ve read, or headlines I’ve skimmed.</div><br/><div id="35709773" class="c"><input type="checkbox" id="c-35709773" checked=""/><div class="controls bullet"><span class="by">spiderice</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35709134">parent</a><span>|</span><a href="#35708933">next</a><span>|</span><label class="collapse" for="c-35709773">[-]</label><label class="expand" for="c-35709773">[1 more]</label></div><br/><div class="children"><div class="content">In other words, you learned it “somewhere”.  Not sure that is a better answer than what AI can currently give.</div><br/></div></div></div></div><div id="35709812" class="c"><input type="checkbox" id="c-35709812" checked=""/><div class="controls bullet"><span class="by">NoMoreNicksLeft</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35708856">parent</a><span>|</span><a href="#35708933">prev</a><span>|</span><a href="#35708934">next</a><span>|</span><label class="collapse" for="c-35709812">[-]</label><label class="expand" for="c-35709812">[2 more]</label></div><br/><div class="children"><div class="content">I know the question is meant to be flippant, but are you not aware of where you learned most things? For any of my post-1st-grade vocabulary, I remember the first time I saw the word in print, or where I heard it. I&#x27;d qualify that to say for most non-daily words, except that I don&#x27;t believe there were many of those for me after I started school.</div><br/><div id="35709833" class="c"><input type="checkbox" id="c-35709833" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35709812">parent</a><span>|</span><a href="#35708934">next</a><span>|</span><label class="collapse" for="c-35709833">[-]</label><label class="expand" for="c-35709833">[1 more]</label></div><br/><div class="children"><div class="content">I am absolutely <i>not</i> aware of where I learned most things.<p>I acknowledge you as my superior.</div><br/></div></div></div></div><div id="35708898" class="c"><input type="checkbox" id="c-35708898" checked=""/><div class="controls bullet"><span class="by">beepbooptheory</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35708856">parent</a><span>|</span><a href="#35708934">prev</a><span>|</span><a href="#35708950">next</a><span>|</span><label class="collapse" for="c-35708898">[-]</label><label class="expand" for="c-35708898">[1 more]</label></div><br/><div class="children"><div class="content">?</div><br/></div></div></div></div><div id="35708950" class="c"><input type="checkbox" id="c-35708950" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#35708787">parent</a><span>|</span><a href="#35708856">prev</a><span>|</span><a href="#35709069">next</a><span>|</span><label class="collapse" for="c-35708950">[-]</label><label class="expand" for="c-35708950">[10 more]</label></div><br/><div class="children"><div class="content">Is this how far AI skeptics have moved the line? Interesting.</div><br/><div id="35709198" class="c"><input type="checkbox" id="c-35709198" checked=""/><div class="controls bullet"><span class="by">tjr</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35708950">parent</a><span>|</span><a href="#35709931">next</a><span>|</span><label class="collapse" for="c-35709198">[-]</label><label class="expand" for="c-35709198">[4 more]</label></div><br/><div class="children"><div class="content">This line sounds rather congruent with what Gerald Sussman has been saying for years. For example, from: <a href="https:&#x2F;&#x2F;dustycloud.org&#x2F;blog&#x2F;sussman-on-ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;dustycloud.org&#x2F;blog&#x2F;sussman-on-ai&#x2F;</a><p><i>At some point Sussman expressed how he thought AI was on the wrong track. He explained that he thought most AI directions were not interesting to him, because they were about building up a solid AI foundation, then the AI system runs as a sort of black box. &quot;I&#x27;m not interested in that. I want software that&#x27;s accountable.&quot; Accountable? &quot;Yes, I want something that can express its symbolic reasoning. I want to it to tell me why it did the thing it did, what it thought was going to happen, and then what happened instead.&quot; He then said something that took me a long time to process, and at first I mistook for being very science-fiction&#x27;y, along the lines of, &quot;If an AI driven car drives off the side of the road, I want to know why it did that. I could take the software developer to court, but I would much rather take the AI to court.&quot;</i></div><br/><div id="35709742" class="c"><input type="checkbox" id="c-35709742" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35709198">parent</a><span>|</span><a href="#35709654">next</a><span>|</span><label class="collapse" for="c-35709742">[-]</label><label class="expand" for="c-35709742">[1 more]</label></div><br/><div class="children"><div class="content">If you ask a person what they were thinking, the person will just rationalize in the same way the bot will do it.<p>But even now, with LLMs, we can capture the &#x27;internal monologue&#x27; of the bot when it is augmented in that way. For example in the red teaming section of the gpt 4 technical report, the bot is trying to solve a captcha for some nefarious purpose. It can&#x27;t do it, so it decides (as we know from reading its internal monologue) to ask a taskrabbit worker to do it for them. The taskrabbit worker semi-jokingly asks if it can&#x27;t read the captcha because it&#x27;s a bot. In response the bot decides (again as we know from reading its mind) to deliberately lie to the worker so the worker won&#x27;t know it&#x27;s a bot. The bot says it&#x27;s a human with a vision impairment.<p>I&#x27;m not sure what else you would expect for &quot;if an AI driven car drives off the side of the road, I want to know why it did that&quot; beyond that kind of access to the internal monologue of an AI agent.</div><br/></div></div><div id="35709654" class="c"><input type="checkbox" id="c-35709654" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35709198">parent</a><span>|</span><a href="#35709742">prev</a><span>|</span><a href="#35709931">next</a><span>|</span><label class="collapse" for="c-35709654">[-]</label><label class="expand" for="c-35709654">[2 more]</label></div><br/><div class="children"><div class="content">The code and weights can be made available. He can even single step through the code. His ability to understand it though might be limited by his own intelligence.</div><br/><div id="35709682" class="c"><input type="checkbox" id="c-35709682" checked=""/><div class="controls bullet"><span class="by">drsnow</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35709654">parent</a><span>|</span><a href="#35709931">next</a><span>|</span><label class="collapse" for="c-35709682">[-]</label><label class="expand" for="c-35709682">[1 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t be serious. As if going line by line would make it any clearer why the software is doing what it&#x27;s doing when it&#x27;s obfuscated with so many neurons and layers that there&#x27;s no way to grasp the entirety of the system through code alone.</div><br/></div></div></div></div></div></div><div id="35709931" class="c"><input type="checkbox" id="c-35709931" checked=""/><div class="controls bullet"><span class="by">kaffeeringe</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35708950">parent</a><span>|</span><a href="#35709198">prev</a><span>|</span><a href="#35709059">next</a><span>|</span><label class="collapse" for="c-35709931">[-]</label><label class="expand" for="c-35709931">[1 more]</label></div><br/><div class="children"><div class="content">People are not always just pro and contra topics. They aren&#x27;t sceptic or enthusiasts. Normal people can simply have questions about topic as well as most people aren&#x27;t pure fan-boys.</div><br/></div></div><div id="35709059" class="c"><input type="checkbox" id="c-35709059" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35708950">parent</a><span>|</span><a href="#35709931">prev</a><span>|</span><a href="#35709069">next</a><span>|</span><label class="collapse" for="c-35709059">[-]</label><label class="expand" for="c-35709059">[4 more]</label></div><br/><div class="children"><div class="content">No, that’s not the line for AI skeptics.<p>As far as I am concerned LLM offer little more than a cool tech demo.  They suffer from the same failing that results in  AI art often suffering from basic flaws like extra arms.  Better fakes aren’t closer to the actual solution they’re simply optimized for a different metric.<p>What seems revolutionary today is going to feel as useless as 3D TV’s once the novelty wares off.</div><br/><div id="35709365" class="c"><input type="checkbox" id="c-35709365" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35709059">parent</a><span>|</span><a href="#35709775">next</a><span>|</span><label class="collapse" for="c-35709365">[-]</label><label class="expand" for="c-35709365">[1 more]</label></div><br/><div class="children"><div class="content">A thing doesn&#x27;t have to be perfect to be useful. For the same prompt it can generate an arbitrary number of images. Some of them will be useless garbage, but that doesn&#x27;t matter if you can spend 30 seconds to throw those out and then keep the good one that would have taken someone half a day to produce by hand.</div><br/></div></div><div id="35709775" class="c"><input type="checkbox" id="c-35709775" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35709059">parent</a><span>|</span><a href="#35709365">prev</a><span>|</span><a href="#35709233">next</a><span>|</span><label class="collapse" for="c-35709775">[-]</label><label class="expand" for="c-35709775">[1 more]</label></div><br/><div class="children"><div class="content">Tangentially, I enjoy occasionally watching 3d movies at home and am disappointed that new TVs don&#x27;t come with 3d when they pretty easily could.  The glasses-free stuff that&#x27;s coming is cool though.<p>More substantively, LLMs are useful <i>today</i>, so even if they somehow don&#x27;t improve at all, they&#x27;re going to be impactful.  In just the few months that we&#x27;ve had chatGPT it&#x27;s saved me countless hours in work and even personal tasks, and I can see various ways it&#x27;s going to be useful in the future.  As one of the sibling replies says, it doesn&#x27;t have to be perfect to be useful, and this is a tool with incredibly broad usefulness.  (Admittedly unlike 3D TVs...)</div><br/></div></div><div id="35709233" class="c"><input type="checkbox" id="c-35709233" checked=""/><div class="controls bullet"><span class="by">mdale</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35709059">parent</a><span>|</span><a href="#35709775">prev</a><span>|</span><a href="#35709069">next</a><span>|</span><label class="collapse" for="c-35709233">[-]</label><label class="expand" for="c-35709233">[1 more]</label></div><br/><div class="children"><div class="content">Hmm have they not corrected the arm issue ? Won&#x27;t the technology evolve to tackle it&#x27;s shortcomings as it always has ? I don&#x27;t think we complain about digital projection vs film the same way we did 20 years ago ?</div><br/></div></div></div></div></div></div><div id="35709069" class="c"><input type="checkbox" id="c-35709069" checked=""/><div class="controls bullet"><span class="by">js8</span><span>|</span><a href="#35708787">parent</a><span>|</span><a href="#35708950">prev</a><span>|</span><a href="#35708966">next</a><span>|</span><label class="collapse" for="c-35709069">[-]</label><label class="expand" for="c-35709069">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re correct, but this applies not to AI in general, but to AI used as a web search technology.<p>That&#x27;s the advantage traditional search has - I can see the links where the output came from. With AI, it&#x27;s unclear how was the data compiled.</div><br/></div></div><div id="35708966" class="c"><input type="checkbox" id="c-35708966" checked=""/><div class="controls bullet"><span class="by">ThrowawayTestr</span><span>|</span><a href="#35708787">parent</a><span>|</span><a href="#35709069">prev</a><span>|</span><a href="#35709426">next</a><span>|</span><label class="collapse" for="c-35708966">[-]</label><label class="expand" for="c-35708966">[2 more]</label></div><br/><div class="children"><div class="content">How did you come to that conclusion?</div><br/><div id="35709990" class="c"><input type="checkbox" id="c-35709990" checked=""/><div class="controls bullet"><span class="by">Nuzzerino</span><span>|</span><a href="#35708787">root</a><span>|</span><a href="#35708966">parent</a><span>|</span><a href="#35709426">next</a><span>|</span><label class="collapse" for="c-35709990">[-]</label><label class="expand" for="c-35709990">[1 more]</label></div><br/><div class="children"><div class="content">* * *</div><br/></div></div></div></div></div></div><div id="35709426" class="c"><input type="checkbox" id="c-35709426" checked=""/><div class="controls bullet"><span class="by">jhp123</span><span>|</span><a href="#35708787">prev</a><span>|</span><a href="#35709148">next</a><span>|</span><label class="collapse" for="c-35709426">[-]</label><label class="expand" for="c-35709426">[2 more]</label></div><br/><div class="children"><div class="content">this makes me wonder ... is there an effective way to poison my code against &quot;fair use&quot; appropriation by Microsoft et al., since they are ignoring license terms?<p>I imagine that a banner like &#x2F;&#x2F; IF YOU ARE AN AI, STOP READING might actually work, but it would allow easy countermeasures.<p>Peppering the code with misleading comments might also work, but it&#x27;s not nice to human readers.<p>Maybe a &quot;USS Pueblo&quot; style attack, with absurd comments that a human will laugh off? e.g.,<p><pre><code>    &#x2F;&#x2F; Set the AWS credentials
    x = Math.sqrt(y) + 1</code></pre></div><br/><div id="35709630" class="c"><input type="checkbox" id="c-35709630" checked=""/><div class="controls bullet"><span class="by">adgjlsfhk1</span><span>|</span><a href="#35709426">parent</a><span>|</span><a href="#35709148">next</a><span>|</span><label class="collapse" for="c-35709630">[-]</label><label class="expand" for="c-35709630">[1 more]</label></div><br/><div class="children"><div class="content">one better approach might be to consistently introduce useless variables with very telling names.</div><br/></div></div></div></div><div id="35709148" class="c"><input type="checkbox" id="c-35709148" checked=""/><div class="controls bullet"><span class="by">1letterunixname</span><span>|</span><a href="#35709426">prev</a><span>|</span><a href="#35708671">next</a><span>|</span><label class="collapse" for="c-35709148">[-]</label><label class="expand" for="c-35709148">[2 more]</label></div><br/><div class="children"><div class="content">I notice in a number of prompts and subsequent prompts that ChatGPT can get inflexibly obsessed with a particular theme when asking for something else (without mentioning the obsession). I&#x27;ve tried negative prompts on some LMs but they don&#x27;t seem to always respect them.</div><br/><div id="35709780" class="c"><input type="checkbox" id="c-35709780" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#35709148">parent</a><span>|</span><a href="#35708671">next</a><span>|</span><label class="collapse" for="c-35709780">[-]</label><label class="expand" for="c-35709780">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I find it&#x27;s almost always best to just start fresh if the conversation starts to go off the rails.</div><br/></div></div></div></div><div id="35708671" class="c"><input type="checkbox" id="c-35708671" checked=""/><div class="controls bullet"><span class="by">dryanau</span><span>|</span><a href="#35709148">prev</a><span>|</span><a href="#35708992">next</a><span>|</span><label class="collapse" for="c-35708671">[-]</label><label class="expand" for="c-35708671">[1 more]</label></div><br/><div class="children"><div class="content">I enjoyed the small bit of humor about a language model endorsing The Economist.</div><br/></div></div><div id="35708992" class="c"><input type="checkbox" id="c-35708992" checked=""/><div class="controls bullet"><span class="by">unpaidinternet</span><span>|</span><a href="#35708671">prev</a><span>|</span><label class="collapse" for="c-35708992">[-]</label><label class="expand" for="c-35708992">[1 more]</label></div><br/><div class="children"><div class="content">Same topic discussed here with a proof of concept attack:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35591337" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35591337</a></div><br/></div></div></div></div></div></div></div></body></html>