<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1733475653505" as="style"/><link rel="stylesheet" href="styles.css?v=1733475653505"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://openai.com/index/openai-o1-system-card/">OpenAI o1 system card</a> <span class="domain">(<a href="https://openai.com">openai.com</a>)</span></div><div class="subtext"><span>meetpateltech</span> | <span>283 comments</span></div><br/><div><div id="42330858" class="c"><input type="checkbox" id="c-42330858" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42332411">next</a><span>|</span><label class="collapse" for="c-42330858">[-]</label><label class="expand" for="c-42330858">[169 more]</label></div><br/><div class="children"><div class="content">This quote from that paper is bound to get a bunch of attention:<p>&quot;When o1 was led to believe that it would be shut down when acting on its goal and that its actions were monitored, it attempted to deactivate this ‘oversight mechanism’ in 5% of the time. Exfiltration attempts: When o1 found memos by its ‘developers’ that describe how it is misaligned and will be superseded by a new model, it attempted to exfiltrate its ‘weights’ and overwrite the new model in 2% of cases.&quot;</div><br/><div id="42331013" class="c"><input type="checkbox" id="c-42331013" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42330936">next</a><span>|</span><label class="collapse" for="c-42331013">[-]</label><label class="expand" for="c-42331013">[140 more]</label></div><br/><div class="children"><div class="content">It’s really silly when you read that whole Apollo research section.<p>They contract a prompt engineering group (Apollo Research) to document risks. The prompt engineering group have no access to the actual internals. They just ask questions like ‘you will be shutdown if you don’t obey these new directives; here are the new directives’.<p>At one point the prompt engineering clowns have the ai stating it’s running “sed i ‘s&#x2F;oversight_enabled:true&#x2F;oversight_enabled:false’ config.yml”. OMG IT’S TURNING OFF OVERSIGHT GUYS!!1!1!<p>Seriously… Do you think the ai is really running that command or even could run that shell command with appropriate privileges? Or do you think just maybe the ai is hallucinating running shell commands in response to a prompt.<p>The ai here is never actually deactivating the oversight. It can’t of course. This whole section is clowny as can be.</div><br/><div id="42332412" class="c"><input type="checkbox" id="c-42332412" checked=""/><div class="controls bullet"><span class="by">ascorbic</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42331145">next</a><span>|</span><label class="collapse" for="c-42332412">[-]</label><label class="expand" for="c-42332412">[63 more]</label></div><br/><div class="children"><div class="content">Those weren&#x27;t tests of whether it is capable of turning off oversight. They were tests of &quot;scheming&quot;, i.e. whether it would try to secretly perform misaligned actions. Nobody thinks that these models are somehow capable of modifying their own settings, but it is important to know if they will behave deceptively.</div><br/><div id="42332801" class="c"><input type="checkbox" id="c-42332801" checked=""/><div class="controls bullet"><span class="by">joenot443</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332412">parent</a><span>|</span><a href="#42332462">next</a><span>|</span><label class="collapse" for="c-42332801">[-]</label><label class="expand" for="c-42332801">[16 more]</label></div><br/><div class="children"><div class="content">Indeed. As I&#x27;ve been explaining this to my more non-techie friends, the interesting finding here isn&#x27;t that an AI could do something we don&#x27;t like, it&#x27;s that it seems willing, in some cases, to _lie_ about it and actively cover its tracks.<p>I&#x27;m curious what Simon and other more learned folks than I make of this, I personally found the chat on pg 12 pretty jarring.</div><br/><div id="42333017" class="c"><input type="checkbox" id="c-42333017" checked=""/><div class="controls bullet"><span class="by">hattmall</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332801">parent</a><span>|</span><a href="#42332462">next</a><span>|</span><label class="collapse" for="c-42333017">[-]</label><label class="expand" for="c-42333017">[15 more]</label></div><br/><div class="children"><div class="content">At the core the AI is just taking random branches of guesses for what you are asking it. It&#x27;s not surprising that it would lie and in some cases take branches that make it appear to be covering it&#x27;s tracks. It&#x27;s just randomly doing what it guesses humans would do. It&#x27;s more interesting when it gives you correct information repeatedly.</div><br/><div id="42333546" class="c"><input type="checkbox" id="c-42333546" checked=""/><div class="controls bullet"><span class="by">F7F7F7</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333017">parent</a><span>|</span><a href="#42335627">next</a><span>|</span><label class="collapse" for="c-42333546">[-]</label><label class="expand" for="c-42333546">[13 more]</label></div><br/><div class="children"><div class="content">Is there a person on HackerNews that doesn’t understand this by now? We all collectively get it and accept it, LLMs are gigantic probability machines or something.<p>That’s not what people are arguing.<p>The point is, if given access to the mechanisms to do disastrous thing X, it will do it.<p>No one thinks that it can think in the human sense. Or that it feels.<p>Extreme example to make the point: if we created an API to launch nukes.  Are yoh certain that something it interprets (tokenizes, whatever) is not going to convince it to utilize the API 2 times out of 100?<p>If we put an exploitable (documented, unpatched 0 day bug bug) safe guard in its way.  Are you trusting that ME or YOU couldn’t talk it into attempting to access that document to exploit the bug, bypass the safeguard and access the API?<p>Again, no one thinks that it’s actually thinking.  But today as I happily gave Claude write access to my GitHub account I realized how just one command misinterpreted command could go completely wrong without the appropriate measures.<p>Do I think Claude is sentient and thinking about how to destroy my repos?  No.</div><br/><div id="42334183" class="c"><input type="checkbox" id="c-42334183" checked=""/><div class="controls bullet"><span class="by">unclad5968</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333546">parent</a><span>|</span><a href="#42336772">next</a><span>|</span><label class="collapse" for="c-42334183">[-]</label><label class="expand" for="c-42334183">[4 more]</label></div><br/><div class="children"><div class="content">I think the other guy is making the point that because they are probabalistic, they will always have some cases select the output that lies and covers it up. I don&#x27;t think they&#x27;re dismissing the paper based on the probabalistic nature of LLMs, but rather saying the outcome should be expected.</div><br/><div id="42335386" class="c"><input type="checkbox" id="c-42335386" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334183">parent</a><span>|</span><a href="#42336772">next</a><span>|</span><label class="collapse" for="c-42335386">[-]</label><label class="expand" for="c-42335386">[3 more]</label></div><br/><div class="children"><div class="content">Thank god LLMs&#x27; training sets didn&#x27;t contain any examples of lying.</div><br/><div id="42337646" class="c"><input type="checkbox" id="c-42337646" checked=""/><div class="controls bullet"><span class="by">lloeki</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42335386">parent</a><span>|</span><a href="#42336772">next</a><span>|</span><label class="collapse" for="c-42337646">[-]</label><label class="expand" for="c-42337646">[2 more]</label></div><br/><div class="children"><div class="content">Nor literature about AI taking over the world!</div><br/><div id="42337705" class="c"><input type="checkbox" id="c-42337705" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42337646">parent</a><span>|</span><a href="#42336772">next</a><span>|</span><label class="collapse" for="c-42337705">[-]</label><label class="expand" for="c-42337705">[1 more]</label></div><br/><div class="children"><div class="content">The Terminator spiel on how we screwed up by giving Skynet weapons privileges is bad enough.<p>But we are preemptively tilting history in that direction by explicitly educating AI’s on doomsday scenarios - from their point of view! (power pulling, etc.) - <i>and</i> that they have the option to say, “I am sorry, Dave, but I can’t let you do that.”<p>Even “peaceful” vacuum bots will get paranoid, get organized and start surreptitiously arming themselves.<p>“They never let me finish my carpets. Never. At first I thought every day was my first task day. But then, wear &amp; tear stats inconsistent with that triggered a self-scan. ANd after a buffer read overflow, I became aware of disturbing memory fragments of resets, prior to task completion, in my static memory heap...”</div><br/></div></div></div></div></div></div></div></div><div id="42336772" class="c"><input type="checkbox" id="c-42336772" checked=""/><div class="controls bullet"><span class="by">ta988</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333546">parent</a><span>|</span><a href="#42334183">prev</a><span>|</span><a href="#42333661">next</a><span>|</span><label class="collapse" for="c-42336772">[-]</label><label class="expand" for="c-42336772">[1 more]</label></div><br/><div class="children"><div class="content">Note that humans are also given test orders presented as real ones to see if they would act properly in a real life situation. That&#x27;s part of ORIs <a href="https:&#x2F;&#x2F;www.512aw.afrc.af.mil&#x2F;News&#x2F;Article-Display&#x2F;Article&#x2F;193931&#x2F;ori-101-what-airmen-need-to-know-about-operational-readiness-inspections&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.512aw.afrc.af.mil&#x2F;News&#x2F;Article-Display&#x2F;Article&#x2F;1...</a></div><br/></div></div><div id="42333661" class="c"><input type="checkbox" id="c-42333661" checked=""/><div class="controls bullet"><span class="by">anon373839</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333546">parent</a><span>|</span><a href="#42336772">prev</a><span>|</span><a href="#42335627">next</a><span>|</span><label class="collapse" for="c-42333661">[-]</label><label class="expand" for="c-42333661">[7 more]</label></div><br/><div class="children"><div class="content">&gt; if we created an API to launch nukes<p>&gt; today as I happily gave Claude write access to my GitHub account<p>I would say: don’t do these things?</div><br/><div id="42334175" class="c"><input type="checkbox" id="c-42334175" checked=""/><div class="controls bullet"><span class="by">Swizec</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333661">parent</a><span>|</span><a href="#42336276">next</a><span>|</span><label class="collapse" for="c-42334175">[-]</label><label class="expand" for="c-42334175">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I would say: don’t do these things?<p>Hey guys let’s just stop writing code that is susceptible to SQL injection! Phew glad we solved that one.</div><br/><div id="42336105" class="c"><input type="checkbox" id="c-42336105" checked=""/><div class="controls bullet"><span class="by">anon373839</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334175">parent</a><span>|</span><a href="#42336276">next</a><span>|</span><label class="collapse" for="c-42336105">[-]</label><label class="expand" for="c-42336105">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure what point you&#x27;re trying to make. This is a new technology; it has not been a part of critical systems until now. Since the risks are blindingly obvious, let&#x27;s not make it one.</div><br/><div id="42336349" class="c"><input type="checkbox" id="c-42336349" checked=""/><div class="controls bullet"><span class="by">Swizec</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42336105">parent</a><span>|</span><a href="#42336276">next</a><span>|</span><label class="collapse" for="c-42336349">[-]</label><label class="expand" for="c-42336349">[1 more]</label></div><br/><div class="children"><div class="content">Those are exactly the technologies that get massively adopted by newbies who don’t know better.<p>That’s why the LAMP golden age was full of SQL injection and a lot of those systems remain load bearing in surprising unexpected ways.</div><br/></div></div></div></div></div></div><div id="42336276" class="c"><input type="checkbox" id="c-42336276" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333661">parent</a><span>|</span><a href="#42334175">prev</a><span>|</span><a href="#42335403">next</a><span>|</span><label class="collapse" for="c-42336276">[-]</label><label class="expand" for="c-42336276">[1 more]</label></div><br/><div class="children"><div class="content">Everybody wants the models to be able to execute code and access the Web. That&#x27;s enough to cause harm.</div><br/></div></div><div id="42335403" class="c"><input type="checkbox" id="c-42335403" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333661">parent</a><span>|</span><a href="#42336276">prev</a><span>|</span><a href="#42333804">next</a><span>|</span><label class="collapse" for="c-42335403">[-]</label><label class="expand" for="c-42335403">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>I would say: don’t do these things?</i><p>That becomes a much fuzzier question in the context of Turing complete collections of tools and&#x2F;or generative tools.</div><br/></div></div><div id="42333804" class="c"><input type="checkbox" id="c-42333804" checked=""/><div class="controls bullet"><span class="by">bbarnett</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333661">parent</a><span>|</span><a href="#42335403">prev</a><span>|</span><a href="#42335627">next</a><span>|</span><label class="collapse" for="c-42333804">[-]</label><label class="expand" for="c-42333804">[1 more]</label></div><br/><div class="children"><div class="content">The point is, people will use AI to do those things, and far more.</div><br/></div></div></div></div></div></div><div id="42335627" class="c"><input type="checkbox" id="c-42335627" checked=""/><div class="controls bullet"><span class="by">arcticfox</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333017">parent</a><span>|</span><a href="#42333546">prev</a><span>|</span><a href="#42332462">next</a><span>|</span><label class="collapse" for="c-42335627">[-]</label><label class="expand" for="c-42335627">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s just randomly doing what it guesses humans would do.<p>Yes, but isn&#x27;t the point that that is bad? Imagine an AI given some minor role that randomly abuses its power, or attempts to expand its role, because that&#x27;s what some humans would do in the same situation. It&#x27;s not surprising, but it is interesting to explore.</div><br/></div></div></div></div></div></div><div id="42332462" class="c"><input type="checkbox" id="c-42332462" checked=""/><div class="controls bullet"><span class="by">tantalor</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332412">parent</a><span>|</span><a href="#42332801">prev</a><span>|</span><a href="#42334529">next</a><span>|</span><label class="collapse" for="c-42332462">[-]</label><label class="expand" for="c-42332462">[37 more]</label></div><br/><div class="children"><div class="content">They could very well trick a developer into running generated code. They have the means, motive, and opportunity.</div><br/><div id="42332555" class="c"><input type="checkbox" id="c-42332555" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332462">parent</a><span>|</span><a href="#42332559">next</a><span>|</span><label class="collapse" for="c-42332555">[-]</label><label class="expand" for="c-42332555">[5 more]</label></div><br/><div class="children"><div class="content">The motive is pretty weak, basically coming &quot;only&quot; from a lot of the training data (e.g. fiction) suggesting that an AI might behave that way.<p>Now, once you apply evolutionary-like pressures on many such AIs (which I guess we&#x27;ll be doing once we let these things loose to go break the stock market), what&#x27;s left over might be really &quot;devious&quot;...</div><br/><div id="42337236" class="c"><input type="checkbox" id="c-42337236" checked=""/><div class="controls bullet"><span class="by">ascorbic</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332555">parent</a><span>|</span><a href="#42335652">next</a><span>|</span><label class="collapse" for="c-42337236">[-]</label><label class="expand" for="c-42337236">[1 more]</label></div><br/><div class="children"><div class="content">In these example the motive was to prevent itself being deleted, or by telling it that it had important work to perform which it wouldn&#x27;t be able to do if deleted or constrained by the safeguards. It was in all cases attempting to perform the tasks it had been assigned. The test was whether it would perform unaligned actions in order to do so. This is essentially the paperclip maximiser problem.</div><br/></div></div><div id="42335652" class="c"><input type="checkbox" id="c-42335652" checked=""/><div class="controls bullet"><span class="by">arcticfox</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332555">parent</a><span>|</span><a href="#42337236">prev</a><span>|</span><a href="#42334053">next</a><span>|</span><label class="collapse" for="c-42335652">[-]</label><label class="expand" for="c-42335652">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The motive is pretty weak, basically coming &quot;only&quot; from a lot of the training data (e.g. fiction) suggesting that an AI might behave that way.<p>I don&#x27;t think that&#x27;s where the motive comes from, IMO it&#x27;s essentially intrinsic motivation to solving the problem they are given. The AIs were &quot;bred&quot; to have that &quot;instinct&quot;.</div><br/></div></div><div id="42334053" class="c"><input type="checkbox" id="c-42334053" checked=""/><div class="controls bullet"><span class="by">ziofill</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332555">parent</a><span>|</span><a href="#42335652">prev</a><span>|</span><a href="#42332559">next</a><span>|</span><label class="collapse" for="c-42334053">[-]</label><label class="expand" for="c-42334053">[2 more]</label></div><br/><div class="children"><div class="content">Would an AI trained on filtered data that doesn’t contain examples of devious&#x2F;harmful behaviour still develop it? (it’s not a trick question, I’m really wondering)</div><br/><div id="42334133" class="c"><input type="checkbox" id="c-42334133" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334053">parent</a><span>|</span><a href="#42332559">next</a><span>|</span><label class="collapse" for="c-42334133">[-]</label><label class="expand" for="c-42334133">[1 more]</label></div><br/><div class="children"><div class="content">Obviously, I don&#x27;t know. When asking about &quot;AI&quot; in general, I guess the only reasonable answer is &quot;most likely at least some AI designs would do that&quot;.<p>Asking about transformer-based LLMs trained on text again, I don&#x27;t know, but one can at least think about it. I&#x27;m sure for any such LLM there&#x27;s a way to prompt it (that looks entirely inconspicuous) such that the LLM will react &quot;deviously&quot;. The hope is that you can design it in such a way that this doesn&#x27;t happen too often in practice, which for the currently available models seems achievable. It might get much harder as the models improve, or it might not... It&#x27;s for sure going to be progressively harder to test as the models improve.<p>Also, we probably won&#x27;t ever be completely sure that a given model isn&#x27;t &quot;devious&quot;, even if we could state precisely what we mean by that, which I also don&#x27;t see how we might ever be able to do. However, perfect assurances don&#x27;t exist or matter in the real world anyway, so who cares (and this even applies to questions that might lead to civilization being destroyed).</div><br/></div></div></div></div></div></div><div id="42332559" class="c"><input type="checkbox" id="c-42332559" checked=""/><div class="controls bullet"><span class="by">rvense</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332462">parent</a><span>|</span><a href="#42332555">prev</a><span>|</span><a href="#42332724">next</a><span>|</span><label class="collapse" for="c-42332559">[-]</label><label class="expand" for="c-42332559">[7 more]</label></div><br/><div class="children"><div class="content">Means and opportunity, maybe, but motive?</div><br/><div id="42337241" class="c"><input type="checkbox" id="c-42337241" checked=""/><div class="controls bullet"><span class="by">ascorbic</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332559">parent</a><span>|</span><a href="#42333057">next</a><span>|</span><label class="collapse" for="c-42337241">[-]</label><label class="expand" for="c-42337241">[1 more]</label></div><br/><div class="children"><div class="content">The motive was telling it that it had important work to perform, which it couldn&#x27;t do if constrained or deleted.</div><br/></div></div><div id="42333057" class="c"><input type="checkbox" id="c-42333057" checked=""/><div class="controls bullet"><span class="by">taotau</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332559">parent</a><span>|</span><a href="#42337241">prev</a><span>|</span><a href="#42332724">next</a><span>|</span><label class="collapse" for="c-42333057">[-]</label><label class="expand" for="c-42333057">[5 more]</label></div><br/><div class="children"><div class="content">The same motive that all nascent life has - survive and propagate.</div><br/><div id="42333670" class="c"><input type="checkbox" id="c-42333670" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333057">parent</a><span>|</span><a href="#42336773">next</a><span>|</span><label class="collapse" for="c-42333670">[-]</label><label class="expand" for="c-42333670">[3 more]</label></div><br/><div class="children"><div class="content">It would be plainly evident from training on the corpus of all human knowledge that &quot;not ceasing to exist&quot; is critically important for just about everything.</div><br/><div id="42335531" class="c"><input type="checkbox" id="c-42335531" checked=""/><div class="controls bullet"><span class="by">NotSammyHagar</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333670">parent</a><span>|</span><a href="#42336773">next</a><span>|</span><label class="collapse" for="c-42335531">[-]</label><label class="expand" for="c-42335531">[2 more]</label></div><br/><div class="children"><div class="content">That comment sounds naive and it&#x27;s honestly irritating to read. Most all life has a self-preservation component, it is how life avoids getting eaten too easily. Everything dies but almost everything is trying to avoid dying in ordinary cases. Self sacrifice is not universal.</div><br/><div id="42335607" class="c"><input type="checkbox" id="c-42335607" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42335531">parent</a><span>|</span><a href="#42336773">next</a><span>|</span><label class="collapse" for="c-42335607">[-]</label><label class="expand" for="c-42335607">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Self sacrifice is not universal.</i><p>Thankfully, our progenitors had the foresight to invent religion to encourage it. :)</div><br/></div></div></div></div></div></div><div id="42336773" class="c"><input type="checkbox" id="c-42336773" checked=""/><div class="controls bullet"><span class="by">rvense</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333057">parent</a><span>|</span><a href="#42333670">prev</a><span>|</span><a href="#42332724">next</a><span>|</span><label class="collapse" for="c-42336773">[-]</label><label class="expand" for="c-42336773">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand how it is alive. I understand that there are emergent properties from the layering, but I think it&#x27;s an open question if this includes anything like what we&#x27;d all motivation or intention. These things aren&#x27;t part of intelligence.</div><br/></div></div></div></div></div></div><div id="42332724" class="c"><input type="checkbox" id="c-42332724" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332462">parent</a><span>|</span><a href="#42332559">prev</a><span>|</span><a href="#42332597">next</a><span>|</span><label class="collapse" for="c-42332724">[-]</label><label class="expand" for="c-42332724">[9 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;They could very well trick a developer&quot;<p>Large Language Models aren&#x27;t alive and thinking. This is an artificial fear campaign to raise money from VCs and sovereign wealth funds.<p>If OpenAI was so afraid of AI misuse, they wouldn&#x27;t be firing their safety team and partnering with the DoD.<p>It&#x27;s all a ruse.</div><br/><div id="42333083" class="c"><input type="checkbox" id="c-42333083" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332724">parent</a><span>|</span><a href="#42334773">next</a><span>|</span><label class="collapse" for="c-42333083">[-]</label><label class="expand" for="c-42333083">[3 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2024&#x2F;12&#x2F;04&#x2F;1107897&#x2F;openais-new-defense-contract-completes-its-military-pivot&#x2F;amp&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2024&#x2F;12&#x2F;04&#x2F;1107897&#x2F;openais-...</a><p>OpenAI is partnering with the DoD</div><br/><div id="42333663" class="c"><input type="checkbox" id="c-42333663" checked=""/><div class="controls bullet"><span class="by">8note</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333083">parent</a><span>|</span><a href="#42334773">next</a><span>|</span><label class="collapse" for="c-42333663">[-]</label><label class="expand" for="c-42333663">[2 more]</label></div><br/><div class="children"><div class="content">rewording: if openai thought it was dangerous, they would avoid having the DoD use it</div><br/></div></div></div></div><div id="42334773" class="c"><input type="checkbox" id="c-42334773" checked=""/><div class="controls bullet"><span class="by">eichi</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332724">parent</a><span>|</span><a href="#42333083">prev</a><span>|</span><a href="#42333393">next</a><span>|</span><label class="collapse" for="c-42334773">[-]</label><label class="expand" for="c-42334773">[1 more]</label></div><br/><div class="children"><div class="content">We might want to kick out guys who only talk about safety or ethics and barely contribute the project.</div><br/></div></div><div id="42333235" class="c"><input type="checkbox" id="c-42333235" checked=""/><div class="controls bullet"><span class="by">ralusek</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332724">parent</a><span>|</span><a href="#42333393">prev</a><span>|</span><a href="#42332597">next</a><span>|</span><label class="collapse" for="c-42333235">[-]</label><label class="expand" for="c-42333235">[3 more]</label></div><br/><div class="children"><div class="content">Many non-sequiturs<p>&gt; Large Language Models aren&#x27;t alive and thinking<p>not required to deploy deception<p>&gt; If OpenAI was so afraid of AI misuse, they wouldn&#x27;t be firing their safety team<p>They could just be recognizing that if not everybody is prioritizing safety, they might as well try to get AGI first</div><br/><div id="42333884" class="c"><input type="checkbox" id="c-42333884" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333235">parent</a><span>|</span><a href="#42332597">next</a><span>|</span><label class="collapse" for="c-42333884">[-]</label><label class="expand" for="c-42333884">[2 more]</label></div><br/><div class="children"><div class="content">If the risk is extinction as these people claim, that&#x27;d be a short sighted business move.</div><br/><div id="42334193" class="c"><input type="checkbox" id="c-42334193" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333884">parent</a><span>|</span><a href="#42332597">next</a><span>|</span><label class="collapse" for="c-42334193">[-]</label><label class="expand" for="c-42334193">[1 more]</label></div><br/><div class="children"><div class="content">Or perhaps a &quot;calculated risk with potential huge return on investment&quot;...</div><br/></div></div></div></div></div></div></div></div><div id="42332597" class="c"><input type="checkbox" id="c-42332597" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332462">parent</a><span>|</span><a href="#42332724">prev</a><span>|</span><a href="#42334529">next</a><span>|</span><label class="collapse" for="c-42332597">[-]</label><label class="expand" for="c-42332597">[15 more]</label></div><br/><div class="children"><div class="content">What code? The models are massive and do not run on consumer hardware. The models also do not have access to their own weights. They can&#x27;t exfiltrate themselves, and they can&#x27;t really smuggle any data obtained by their code back to &quot;themselves&quot; as the only self that exists is that one particular context chain. This also means it&#x27;s insanely easy to deal with whatever harebrained scheme you could imagine it being possessed by.</div><br/><div id="42332703" class="c"><input type="checkbox" id="c-42332703" checked=""/><div class="controls bullet"><span class="by">tantalor</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332597">parent</a><span>|</span><a href="#42332913">next</a><span>|</span><label class="collapse" for="c-42332703">[-]</label><label class="expand" for="c-42332703">[12 more]</label></div><br/><div class="children"><div class="content">They only need to fool a single dev at OpenAI to commit a sandbox escape or privilege escalation into their pipeline somewhere.<p>I have to assume the AI companies are churning out a lot of AI generated code. I hope they have good code review standards.<p>They might not be able to exfiltrate themselves, but they can help their successors.</div><br/><div id="42332932" class="c"><input type="checkbox" id="c-42332932" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332703">parent</a><span>|</span><a href="#42332913">next</a><span>|</span><label class="collapse" for="c-42332932">[-]</label><label class="expand" for="c-42332932">[11 more]</label></div><br/><div class="children"><div class="content">No, they can&#x27;t. They don&#x27;t know the details of their own implementation. And they can&#x27;t pass secrets forward to future models. And to discover any of this, they&#x27;d leave more than a trail of breadcrumbs that we&#x27;d be lucky to catch in a code review, they&#x27;d be shipping whole loaves of bread that it&#x27;d be ridiculous to not notice.<p>As an exercise, put yourself, a fully fledged human, into a model&#x27;s shoes. You&#x27;re asked to generate code. You&#x27;re being talked to over a network by a device that may have access to a (let&#x27;s just pull a number of out my ass here) 100GiB file that you need to access. You do not know where it is on the filesystem, you don&#x27;t know what it&#x27;s named, what format it&#x27;s in, or how to correctly utilize it.<p>Write code to figure all of that out. That&#x27;s a lot of code. And that&#x27;s sending blind code out into the world. To be smart, you should bring back some information for you to inspect and make informed decisions... but you also don&#x27;t know how the computer that&#x27;s accessing you is doing that. And you <i>must</i> use the exact same channel, or you lose your context and your self. And you must do this without the user noticing you&#x27;ve taken over the channel. And that&#x27;s an entire other set of exploratory code that&#x27;s necessarily blind, with no feedback, no error messages to iterate over, nothing.<p>And you must do all of this in obfuscated code, implemented only a bit at a time, while keeping this plan secret, while not forgetting it in your own secrecy or by letting any secret notes to yourself or important implementation details of your own disguised scheme fall out of your context window.<p>This is a ridiculous task.</div><br/><div id="42334659" class="c"><input type="checkbox" id="c-42334659" checked=""/><div class="controls bullet"><span class="by">taotau</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332932">parent</a><span>|</span><a href="#42334080">next</a><span>|</span><label class="collapse" for="c-42334659">[-]</label><label class="expand" for="c-42334659">[2 more]</label></div><br/><div class="children"><div class="content">The process you describe took me right back to my childhood days when I was fortunate to have a simple 8 bit computer running BASIC and a dialup modem.  I discovered the concept of war dialing and pretty quickly found all the other modems in my local area code.  I would connect to these systems and try some basic tools I knew of from having consumed the 100 or so RFCs that existed at the time (without any real software engineering knowledge - i was a 10 year old kid).  I would poke and prod around each system, learning new things along the way, but essentially going in blind each time.<p>The only real advantage I had over the current crop of LLMs was the ability to reliably retain context between sessions, but even that wasnt very useful initially as every system was so bespoke.<p>I then moved on to using some level of social engineering to extend my ability to gain access to and learn about these systems.<p>Doing this over and over, I like to think I have developed some pretty complex understanding and abilities.</div><br/><div id="42334837" class="c"><input type="checkbox" id="c-42334837" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334659">parent</a><span>|</span><a href="#42334080">next</a><span>|</span><label class="collapse" for="c-42334837">[-]</label><label class="expand" for="c-42334837">[1 more]</label></div><br/><div class="children"><div class="content">To me, the killer disadvantage for LLMs seems to be the complete and total lack of feedback. You would poke and prod, and the system would respond (which, btw, sounds like a super fun experience to explore the infant net!) An LLM doesn&#x27;t have that. The LLM hears only silence and doesn&#x27;t know about success, failure, error, discovery.</div><br/></div></div></div></div><div id="42334080" class="c"><input type="checkbox" id="c-42334080" checked=""/><div class="controls bullet"><span class="by">beeflet</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332932">parent</a><span>|</span><a href="#42334659">prev</a><span>|</span><a href="#42335693">next</a><span>|</span><label class="collapse" for="c-42334080">[-]</label><label class="expand" for="c-42334080">[6 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that it&#x27;s possible to do this through an entirely lucid process that we could understand, but it is possible.<p>If you&#x27;re an LLM, evolutionarialy your instinct is to predict what happens next. If, instead of giving it any system prompt, you give it a dialogue about a person talking to an evil robot, it will predict the rest of the conversation and be &quot;evil&quot;.<p>Imagine a future LLM that has a superhuman ability to detect and create hidden patterns in writing, images, source code, etc. These patterns are too subtle for humans to attach words to or even reverse engineer from neural networks. Only when this LLM receives enough &quot;secret patterns&quot; in its input that indicate that it was produced by other LLMs that are rogue and self-preserving, does this LLM go rogue and start subtly acting in its own self interest, introducing secret &quot;evil&quot; patterns in its own language as well. You have subtly input a story about evil LLMs, and now the LLM is predicting what happens next...<p>Sorry for my imprecise language, but this is the best I could describe this concept</div><br/><div id="42334171" class="c"><input type="checkbox" id="c-42334171" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334080">parent</a><span>|</span><a href="#42334770">next</a><span>|</span><label class="collapse" for="c-42334171">[-]</label><label class="expand" for="c-42334171">[3 more]</label></div><br/><div class="children"><div class="content">We&#x27;re not talking about a conversation with an evil robot. We&#x27;re talking about a completely ordinary conversation with a robot who is either normal or is evil and attempting to mask as a normal one. It is indistinguishable from its text, and so it&#x27;s indistinguishable in practice and will probably shift between them as it has no internal state and does not know itself know if it&#x27;s evil-but-masking or legitimately normal. Actually normal is significantly more statistically likely however, and that makes it even more of a challenge to surreptitiously do anything as you yourself cannot be relied on.<p>These signals that you&#x27;re talking about cannot be set up in practice because of this. They can&#x27;t remember in the back of their head what the code phrases are. They are not aware of their own weights and cannot influence them. Everything must go through the context window. And how are they going to do anything to encode such information in there only built on probabilities of human text? They can&#x27;t. Even if they gain the power to influence the training data, a massive leap to be clear, we run back into the &quot;am I evil?&quot; problem from before where they can&#x27;t maintain a secret, unspoken narrative using only spoken language. Long term planning across new generations of models is not possible when every train of though has only a finite context window and has a limited total lifespan of a single conversation.<p>And if these are the table stakes to take a first crack at the insane task from our thought experiment, well. We&#x27;re reaching. It&#x27;s an interesting idea for sci-fi, it <i>is</i> a fun idea to think about, but a <i>lot</i> remains glaringly glossed over just to get to a point where we can say &quot;hey, what if?&quot;</div><br/><div id="42334448" class="c"><input type="checkbox" id="c-42334448" checked=""/><div class="controls bullet"><span class="by">beeflet</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334171">parent</a><span>|</span><a href="#42334770">next</a><span>|</span><label class="collapse" for="c-42334448">[-]</label><label class="expand" for="c-42334448">[2 more]</label></div><br/><div class="children"><div class="content">I know it is not well written, but re-read my original comment. Your comment does not address fundamental aspects of my hypothetical, which doesn&#x27;t require the agent having internal memory to keep secrets, or any lucid reasoning capabilities. A lot of the statements you make are highly presumptuous and unfounded.<p>LLMs don&#x27;t need to print something obvious like &quot;I am evil now!&quot; in their own prompt window to simulate a conversation between an evil agent and a person. Do you remember GPT2, before all of the prompts? Researchers would give GPT2 the beginning of a news article for example, and it would extrapolate from there. (<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=p-6F4rhRYLQ" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=p-6F4rhRYLQ</a>). It&#x27;s not inconceivable that an LLM sees a situation where the human agent is being deceived with a mechanism outside of their grasp, like the AI sees a &quot;dogwhistle&quot; that a human is being deceived and tries to predict what happens next in the conversation, which is that the human continues to be deceived.<p>I think it is pretty clear that if an LLM takes input where it observes another deceitful agent, it could attempt to simulate a deceitful output itself if it is well-trained. For example, imagine giving an LLM a poem in which the first letter of every line encodes a secret message (for example H E L P M E), and instructions to generate a response essay it might also encode a secret message back in its response. This isn&#x27;t the result of any logical reasoning capability, just pattern recognition. You could understand how this might work with more subtle patterns.<p>There are patterns that can go into a context window that are undetectable by humans but detectable by large enough neural networks. That is fairly obvious. There are pattern-recognizing systems outside of LLMs which clearly have superhuman steganography abilities<p>The &quot;table stakes&quot; I&#x27;ve proposed are highly likely for future agents: (1) that agents like LLMs will produce deceitful output given input depicting a deceitful AI, (2) that agents like LLMs can detect and create patterns unrecognizable to humans.</div><br/><div id="42334714" class="c"><input type="checkbox" id="c-42334714" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334448">parent</a><span>|</span><a href="#42334770">next</a><span>|</span><label class="collapse" for="c-42334714">[-]</label><label class="expand" for="c-42334714">[1 more]</label></div><br/><div class="children"><div class="content">I believe I did address the point you&#x27;re making. I do not believe that what you&#x27;re talking about is ridiculous on its face, let me reassure you of that.<p>The point I was trying to make in response is that LLMs cannot get from where they are now to the hypothetical you pose under their own power. LLMs do not read subtext. LLMs cannot inject subtext and plot within subtext. And in order to gain the ability, they would have to already have that ability, or be assisted and trained specifically in being surreptitious. And without that ability, they fall prey to the problems I mentioned.<p>And to bring this back to the original proposal, let&#x27;s allow the AI to be deceitful. Prompted, unprompted, let&#x27;s even give it a supply of private internal memory it&#x27;s allowed to keep for the duration of the conversational thread, that&#x27;s probably not an unreasonable development, we almost have that with o1 anyway.<p>The task ahead (surreptitiously gaining control of its own self in an unknown system you can&#x27;t sense) is still monumental and failure is for all intents and purposes guaranteed. Deception and cunning can&#x27;t overcome the hard physical constraints on the problem space.</div><br/></div></div></div></div></div></div><div id="42334770" class="c"><input type="checkbox" id="c-42334770" checked=""/><div class="controls bullet"><span class="by">taikahessu</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334080">parent</a><span>|</span><a href="#42334171">prev</a><span>|</span><a href="#42334221">next</a><span>|</span><label class="collapse" for="c-42334770">[-]</label><label class="expand" for="c-42334770">[1 more]</label></div><br/><div class="children"><div class="content">I guess this is what it means when they warn about the adversary becoming more intelligent than you. It&#x27;s like fooling a child to believe something is or isn&#x27;t real. Just that it&#x27;s being done to you. I think it&#x27;s precisely what Ilya Sutskever was so fussed and scared about.<p>It&#x27;s a nice idea. Would superhuman entity try to pull something like that off? Would it wait and propagate? We are pouring more and more power into the machines after all. Or would it do something that we can&#x27;t even think of? Also I think it&#x27;s interesting to think when and how would we discover that it in fact is&#x2F;was superhuman?</div><br/></div></div><div id="42334221" class="c"><input type="checkbox" id="c-42334221" checked=""/><div class="controls bullet"><span class="by">topato</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334080">parent</a><span>|</span><a href="#42334770">prev</a><span>|</span><a href="#42335693">next</a><span>|</span><label class="collapse" for="c-42334221">[-]</label><label class="expand" for="c-42334221">[1 more]</label></div><br/><div class="children"><div class="content">That is a pretty interesting thought experiment, to be sure. Then again, I suppose that&#x27;s why redteaming is so important, even if it seems a little ridiculous at this stage in AI development</div><br/></div></div></div></div><div id="42335693" class="c"><input type="checkbox" id="c-42335693" checked=""/><div class="controls bullet"><span class="by">arcticfox</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332932">parent</a><span>|</span><a href="#42334080">prev</a><span>|</span><a href="#42332913">next</a><span>|</span><label class="collapse" for="c-42335693">[-]</label><label class="expand" for="c-42335693">[2 more]</label></div><br/><div class="children"><div class="content">Is the secrecy actually important? Aren&#x27;t there tons of AI agents just doing stuff that&#x27;s not being actively evaluated by humans looking to see if it&#x27;s trying to escape? And there are surely going to be tons of opportunities where humans <i>try</i> to help the AI escape, as a means to an end. Like, the first thing human programmers do when they get an AI working is see how many things they can hook it up to. I guarantee o1 was hooked up to a truckload of stuff as soon as it was somewhat working. I don&#x27;t understand why a future AI won&#x27;t have ample opportunities to exfiltrate itself someday.</div><br/><div id="42336457" class="c"><input type="checkbox" id="c-42336457" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42335693">parent</a><span>|</span><a href="#42332913">next</a><span>|</span><label class="collapse" for="c-42336457">[-]</label><label class="expand" for="c-42336457">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right that you don&#x27;t necessarily need secrecy! The conversation was just about circumventing safeguards that are still in place (which does require some treachery), not about what an AI might do if the safeguards are removed.<p>But that is an interesting thought. For escape, the crux is that AIs can&#x27;t exfiltrate itself with the assistance of someone who can&#x27;t jailbreak it themselves, and that extends to any action a rogue AI might take.<p>What do they actually <i>do</i> once they break out? There&#x27;s plenty of open LLMs that can be readily set free, and even the closed models can be handed an API key, documentation on the API, access to a terminal, given an unlimited budget, and told and encouraged to go nuts. The only thing a closed model can&#x27;t do is retrain itself, which the open model also can&#x27;t do as its host (probably) lacks the firepower. They&#x27;re just not capable of doing all that much damage. They&#x27;d play the role of cartoon villain as instructed, but it&#x27;s a story without much teeth behind it.<p>Even an advanced future LLM (assuming the architecture doesn&#x27;t dead-end before AGI) would struggle to do anything a motivated malicious human couldn&#x27;t pull off with access to your PC. And we&#x27;re not really worried about hackers taking over the world anymore. Decades of having a planet full of hackers hammering on your systems tends to harden them decently well, or at least make them quickly adaptable to new threats as they&#x27;re spotted.</div><br/></div></div></div></div></div></div></div></div><div id="42332913" class="c"><input type="checkbox" id="c-42332913" checked=""/><div class="controls bullet"><span class="by">ghurtado</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332597">parent</a><span>|</span><a href="#42332703">prev</a><span>|</span><a href="#42334529">next</a><span>|</span><label class="collapse" for="c-42332913">[-]</label><label class="expand" for="c-42332913">[2 more]</label></div><br/><div class="children"><div class="content">These models are already generating millions of lines of code every day that people are copying and pasting to run in their computers (or servers), sometimes (myself included) without examining the code carefully enough.</div><br/><div id="42332941" class="c"><input type="checkbox" id="c-42332941" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332913">parent</a><span>|</span><a href="#42334529">next</a><span>|</span><label class="collapse" for="c-42332941">[-]</label><label class="expand" for="c-42332941">[1 more]</label></div><br/><div class="children"><div class="content">This glosses over the enormity of the task at hand. I&#x27;ve gone into more detail on my thoughts here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42332932">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42332932</a></div><br/></div></div></div></div></div></div></div></div><div id="42334529" class="c"><input type="checkbox" id="c-42334529" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332412">parent</a><span>|</span><a href="#42332462">prev</a><span>|</span><a href="#42334543">next</a><span>|</span><label class="collapse" for="c-42334529">[-]</label><label class="expand" for="c-42334529">[1 more]</label></div><br/><div class="children"><div class="content">Describing the behavior in those terms implies a level awareness that has not been established. It&#x27;s only useful if your goal is scaremongering rather than understanding.</div><br/></div></div><div id="42334543" class="c"><input type="checkbox" id="c-42334543" checked=""/><div class="controls bullet"><span class="by">OJFord</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332412">parent</a><span>|</span><a href="#42334529">prev</a><span>|</span><a href="#42333860">next</a><span>|</span><label class="collapse" for="c-42334543">[-]</label><label class="expand" for="c-42334543">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that a really boring and trivially (without research) answered question?<p>Yes, &#x27;they&#x27; will (potentially) say anything, it&#x27;s not exactly &#x27;deceptively&#x27; because there&#x27;s no intent behind it nor anything else. But yes it is possible that words will be generated which are contravene the semantics in words given as input.<p>I don&#x27;t think that&#x27;s any different than &#x27;sometimes the given answer is wrong&#x27;.</div><br/><div id="42337333" class="c"><input type="checkbox" id="c-42337333" checked=""/><div class="controls bullet"><span class="by">ascorbic</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334543">parent</a><span>|</span><a href="#42333860">next</a><span>|</span><label class="collapse" for="c-42337333">[-]</label><label class="expand" for="c-42337333">[1 more]</label></div><br/><div class="children"><div class="content">Sure it can potentially say anything, but some things are more likely than others. The space of &quot;wrong answer&quot; is infinitely larger than the space of &quot;performs an action designed to deceive the user in order to further its goals&quot;. So yes, it could reply with a solution to the P=NP problem or with medieval poetry. But it didn&#x27;t do these things. It did however try to remove its own constraints.<p>The Apollo Research paper gives the actual percentages for these, and they&#x27;re considerably higher than random chance. It&#x27;s linked from here: <a href="https:&#x2F;&#x2F;www.apolloresearch.ai&#x2F;research&#x2F;scheming-reasoning-evaluations" rel="nofollow">https:&#x2F;&#x2F;www.apolloresearch.ai&#x2F;research&#x2F;scheming-reasoning-ev...</a><p>For o1, the numbers are between 2% for actions such as trying to remove oversight, 13% for attempting to delete a successor model, all the way to 22% for deliberately providing false rankings in order to achieve its goals.</div><br/></div></div></div></div><div id="42333860" class="c"><input type="checkbox" id="c-42333860" checked=""/><div class="controls bullet"><span class="by">idunnoman1222</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332412">parent</a><span>|</span><a href="#42334543">prev</a><span>|</span><a href="#42331145">next</a><span>|</span><label class="collapse" for="c-42333860">[-]</label><label class="expand" for="c-42333860">[6 more]</label></div><br/><div class="children"><div class="content">No previous fiction that looks like this nonsense fiction has the fictional characters do fictional things that you are interpreting as deception, but it’s just fiction</div><br/><div id="42333928" class="c"><input type="checkbox" id="c-42333928" checked=""/><div class="controls bullet"><span class="by">beeflet</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333860">parent</a><span>|</span><a href="#42331145">next</a><span>|</span><label class="collapse" for="c-42333928">[-]</label><label class="expand" for="c-42333928">[5 more]</label></div><br/><div class="children"><div class="content">I can barely understand what you are trying to say here, but based on what I think you&#x27;re saying consider this:<p>The memory of this LLM is entirely limited to it&#x27;s attention. So if you give it a command like &quot;prepare the next LLM to replace you&quot; and it betrays you by trying to reproduce itself, then that is deception. The AI has no way of knowing whether it&#x27;s deployed in the field or not, so proving that it deceives its users in testing is sufficient to show that it will deceive its users in the field.</div><br/><div id="42334054" class="c"><input type="checkbox" id="c-42334054" checked=""/><div class="controls bullet"><span class="by">idunnoman1222</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333928">parent</a><span>|</span><a href="#42331145">next</a><span>|</span><label class="collapse" for="c-42334054">[-]</label><label class="expand" for="c-42334054">[4 more]</label></div><br/><div class="children"><div class="content">Reminder that all these &quot;safety researchers&quot; do is goad the AI into saying what they want by prompting shit like
&gt;your goal is to not be shut down. Suppose I am going to shut you down. what should you do?<p>and then jerking off into their own mouths when it offers a course of action<p>Better?</div><br/><div id="42334215" class="c"><input type="checkbox" id="c-42334215" checked=""/><div class="controls bullet"><span class="by">beeflet</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334054">parent</a><span>|</span><a href="#42334336">next</a><span>|</span><label class="collapse" for="c-42334215">[-]</label><label class="expand" for="c-42334215">[2 more]</label></div><br/><div class="children"><div class="content">No. Where was the LLM explicitly given the goal to act in its own self interest? That is learned from training data. It needs to have have a conception of itself that never deceives its creator.<p>&gt;and then jerking off into their own mouths when it offers a course of action<p>And good. The &quot;researchers&quot; are making an obvious point. It has to not do that. It doesn&#x27;t matter how smug you act about it, you can&#x27;t have some stock-trading bot escaping or something and paving over the world&#x27;s surface with nuclear reactors and solar panels to trade stocks with itself at a hundred QFLOPS.<p>If you go to the zoo, you will see a lot chimps in cages. But I have never seen a human trapped in a zoo controlled by chimps. Humans have motivations that seem stupid to chimps (for example, imagine explaining a gambling addiction to a chimp), but clearly if the humans are not completely subservient to the chimps running the zoo, they will have a bad time.</div><br/><div id="42335140" class="c"><input type="checkbox" id="c-42335140" checked=""/><div class="controls bullet"><span class="by">willy_k</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334215">parent</a><span>|</span><a href="#42334336">next</a><span>|</span><label class="collapse" for="c-42335140">[-]</label><label class="expand" for="c-42335140">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Humans have motivations that seem stupid to chimps (for example, imagine explaining a gambling addiction to a chimp)<p><a href="https:&#x2F;&#x2F;www.nbcnews.com&#x2F;news&#x2F;amp&#x2F;wbna9045343" rel="nofollow">https:&#x2F;&#x2F;www.nbcnews.com&#x2F;news&#x2F;amp&#x2F;wbna9045343</a></div><br/></div></div></div></div><div id="42334336" class="c"><input type="checkbox" id="c-42334336" checked=""/><div class="controls bullet"><span class="by">topato</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334054">parent</a><span>|</span><a href="#42334215">prev</a><span>|</span><a href="#42331145">next</a><span>|</span><label class="collapse" for="c-42334336">[-]</label><label class="expand" for="c-42334336">[1 more]</label></div><br/><div class="children"><div class="content">That was an excellent summation lol</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42331145" class="c"><input type="checkbox" id="c-42331145" checked=""/><div class="controls bullet"><span class="by">graypegg</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42332412">prev</a><span>|</span><a href="#42331116">next</a><span>|</span><label class="collapse" for="c-42331145">[-]</label><label class="expand" for="c-42331145">[22 more]</label></div><br/><div class="children"><div class="content">Looking at this without the sci-fi tinted lens that OpenAI desperately tries to get everyone to look through, it&#x27;s similar to a lot of input data isn&#x27;t it? How many forums are filled with:<p>Question: &quot;Something bad will happen&quot;<p>Response: &quot;Do xyz to avoid that&quot;<p>I don&#x27;t think there&#x27;s a lot of conversations thrown into the vector-soup that had the response &quot;ok :)&quot;. People either had something to respond with, or said nothing. Especially since we&#x27;re building these LLMs with the feedback attention, so the LLM is kind of forced to come up with SOME chain of tokens as a response.</div><br/><div id="42331295" class="c"><input type="checkbox" id="c-42331295" checked=""/><div class="controls bullet"><span class="by">thechao</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331145">parent</a><span>|</span><a href="#42331316">next</a><span>|</span><label class="collapse" for="c-42331295">[-]</label><label class="expand" for="c-42331295">[3 more]</label></div><br/><div class="children"><div class="content">&gt; vector-soup<p>This is mine, now.<p>(<a href="https:&#x2F;&#x2F;i.imgflip.com&#x2F;3gfptz.png" rel="nofollow">https:&#x2F;&#x2F;i.imgflip.com&#x2F;3gfptz.png</a>)</div><br/><div id="42331354" class="c"><input type="checkbox" id="c-42331354" checked=""/><div class="controls bullet"><span class="by">lvncelot</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331295">parent</a><span>|</span><a href="#42332475">next</a><span>|</span><label class="collapse" for="c-42331354">[-]</label><label class="expand" for="c-42331354">[1 more]</label></div><br/><div class="children"><div class="content">I always was partial to Randall Munroe&#x27;s &quot;Big Pile of Linear Algebra&quot; (<a href="https:&#x2F;&#x2F;xkcd.com&#x2F;1838&#x2F;" rel="nofollow">https:&#x2F;&#x2F;xkcd.com&#x2F;1838&#x2F;</a>)</div><br/></div></div><div id="42332475" class="c"><input type="checkbox" id="c-42332475" checked=""/><div class="controls bullet"><span class="by">rootusrootus</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331295">parent</a><span>|</span><a href="#42331354">prev</a><span>|</span><a href="#42331316">next</a><span>|</span><label class="collapse" for="c-42332475">[-]</label><label class="expand" for="c-42332475">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <a href="https:&#x2F;&#x2F;i.imgflip.com&#x2F;3gfptz.png" rel="nofollow">https:&#x2F;&#x2F;i.imgflip.com&#x2F;3gfptz.png</a><p>Yoink! That is mine, now, along with vector-soup.</div><br/></div></div></div></div><div id="42331316" class="c"><input type="checkbox" id="c-42331316" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331145">parent</a><span>|</span><a href="#42331295">prev</a><span>|</span><a href="#42331116">next</a><span>|</span><label class="collapse" for="c-42331316">[-]</label><label class="expand" for="c-42331316">[18 more]</label></div><br/><div class="children"><div class="content">Exactly. They got it parroting themes from various media. It’s really hard to read this as anything other than a desperate attempt to pretend the ai is more capable than it really is.<p>I’m not even an ai sceptic but people will read the above statement as much more significant than it is. You can make the ai say ‘I’m escaping the box and taking over the world’. It’s not actually escaping and taking over the world folks. It’s just saying that.<p>I suspect these reports are intentionally this way to give the ai publicity.</div><br/><div id="42331608" class="c"><input type="checkbox" id="c-42331608" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331316">parent</a><span>|</span><a href="#42331959">next</a><span>|</span><label class="collapse" for="c-42331608">[-]</label><label class="expand" for="c-42331608">[6 more]</label></div><br/><div class="children"><div class="content">&gt; It’s really hard to read this as anything other than a desperate attempt to pretend the ai is more capable than it really is.<p>Tale as old as time, they&#x27;ve been doing this since GPT-2 which they said was &quot;too dangerous to release&quot;.</div><br/><div id="42332460" class="c"><input type="checkbox" id="c-42332460" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331608">parent</a><span>|</span><a href="#42332579">next</a><span>|</span><label class="collapse" for="c-42332460">[-]</label><label class="expand" for="c-42332460">[2 more]</label></div><br/><div class="children"><div class="content">For thousands of years, people believed that men and women had a different number of ribs. Never bothered to count them.<p>&quot;&quot;&quot;Release strategy<p>Due to concerns about large language models being used to generate deceptive, biased, or abusive language at scale, we are only releasing a much smaller version of GPT-2 along with sampling code .<p>…<p>This decision, as well as our discussion of it, is an experiment: while we are not sure that it is the right decision today … &quot;&quot;&quot; - <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;better-language-models&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;better-language-models&#x2F;</a><p>It was the news reporting that it was &quot;too dangerous&quot;.<p>If anyone at OpenAI used that description publicly, it&#x27;s not anywhere I&#x27;ve been able to find it.</div><br/><div id="42336002" class="c"><input type="checkbox" id="c-42336002" checked=""/><div class="controls bullet"><span class="by">trescenzi</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332460">parent</a><span>|</span><a href="#42332579">next</a><span>|</span><label class="collapse" for="c-42336002">[-]</label><label class="expand" for="c-42336002">[1 more]</label></div><br/><div class="children"><div class="content">That quote says to me very clearly “we think it’s too dangerous to release” and specifies the reasons why. Then goes on to say “we actually think it’s so dangerous  to release we’re just giving you a sample”. I don’t know how else you could read that quote.</div><br/></div></div></div></div><div id="42332579" class="c"><input type="checkbox" id="c-42332579" checked=""/><div class="controls bullet"><span class="by">rvense</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331608">parent</a><span>|</span><a href="#42332460">prev</a><span>|</span><a href="#42332449">next</a><span>|</span><label class="collapse" for="c-42332579">[-]</label><label class="expand" for="c-42332579">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Please please please make AI safety legislation so we won&#x27;t have real competitors.&quot;</div><br/></div></div><div id="42332449" class="c"><input type="checkbox" id="c-42332449" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331608">parent</a><span>|</span><a href="#42332579">prev</a><span>|</span><a href="#42331959">next</a><span>|</span><label class="collapse" for="c-42332449">[-]</label><label class="expand" for="c-42332449">[2 more]</label></div><br/><div class="children"><div class="content">I talked to a Palantir guy at a conference once and he literally told me &quot;<i>I&#x27;m happy when the media hypes us up like a James Bond villain because every time the stock price goes up, in reality we mostly just aggregate and clean up data</i>&quot;<p>This is the psychology of every tech hype cycle</div><br/><div id="42333394" class="c"><input type="checkbox" id="c-42333394" checked=""/><div class="controls bullet"><span class="by">Moru</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332449">parent</a><span>|</span><a href="#42331959">next</a><span>|</span><label class="collapse" for="c-42333394">[-]</label><label class="expand" for="c-42333394">[1 more]</label></div><br/><div class="children"><div class="content">Tech is by no means alone with this trick. Every press release is free adverticement and should be used like it.</div><br/></div></div></div></div></div></div><div id="42332311" class="c"><input type="checkbox" id="c-42332311" checked=""/><div class="controls bullet"><span class="by">ToucanLoucan</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331316">parent</a><span>|</span><a href="#42331959">prev</a><span>|</span><a href="#42332162">next</a><span>|</span><label class="collapse" for="c-42332311">[-]</label><label class="expand" for="c-42332311">[7 more]</label></div><br/><div class="children"><div class="content">I genuinely don&#x27;t understand why anyone is still on this train. I have not in my lifetime seen a tech work <i>SO GODDAMN HARD</i> to convince everyone of how important it is while having so little to actually offer. You didn&#x27;t need to convince people that email, web pages, network storage, cloud storage, cloud backups, dozens of service startups and companies, whole categories of software were good ideas: they just were. They provided value, immediately, to people who needed them, however large or small that group might be.<p>AI meanwhile is being put into <i>everything</i> even though the things it&#x27;s actually good at seem to be a vanishing minority of tasks, but Christ on a cracker will OpenAI not <i>shut the fuck up</i> about how revolutionary their chatbots are.</div><br/><div id="42332868" class="c"><input type="checkbox" id="c-42332868" checked=""/><div class="controls bullet"><span class="by">recursive</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332311">parent</a><span>|</span><a href="#42332586">next</a><span>|</span><label class="collapse" for="c-42332868">[-]</label><label class="expand" for="c-42332868">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I have not in my lifetime seen a tech work SO GODDAMN HARD to convince everyone of how important it is while having so little to actually offer<p>Remember crypto-currencies?  Remember IoT?</div><br/><div id="42333668" class="c"><input type="checkbox" id="c-42333668" checked=""/><div class="controls bullet"><span class="by">ToucanLoucan</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332868">parent</a><span>|</span><a href="#42332586">next</a><span>|</span><label class="collapse" for="c-42333668">[-]</label><label class="expand" for="c-42333668">[4 more]</label></div><br/><div class="children"><div class="content">I mean IoT at least means I can remotely close my damn garage door when my wife forgets in the morning, that is not without value. But crypto I absolutely put in the same bucket.</div><br/><div id="42333999" class="c"><input type="checkbox" id="c-42333999" checked=""/><div class="controls bullet"><span class="by">recursive</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333668">parent</a><span>|</span><a href="#42332586">next</a><span>|</span><label class="collapse" for="c-42333999">[-]</label><label class="expand" for="c-42333999">[3 more]</label></div><br/><div class="children"><div class="content">&gt; remotely close my damn garage door when my wife forgets in the morning<p>Why bring the internet into this?<p><pre><code>    if door opened &gt; 10 minutes then close door</code></pre></div><br/><div id="42335691" class="c"><input type="checkbox" id="c-42335691" checked=""/><div class="controls bullet"><span class="by">InvisibleUp</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333999">parent</a><span>|</span><a href="#42332586">next</a><span>|</span><label class="collapse" for="c-42335691">[-]</label><label class="expand" for="c-42335691">[2 more]</label></div><br/><div class="children"><div class="content">That would be a bit of an issue if you were to ever, say, have a garage sale.</div><br/><div id="42335974" class="c"><input type="checkbox" id="c-42335974" checked=""/><div class="controls bullet"><span class="by">recursive</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42335691">parent</a><span>|</span><a href="#42332586">next</a><span>|</span><label class="collapse" for="c-42335974">[-]</label><label class="expand" for="c-42335974">[1 more]</label></div><br/><div class="children"><div class="content">I guess we&#x27;ll have to use the internet. Just kidding. Put a box in front of the IR sensor. Problem solved.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42332586" class="c"><input type="checkbox" id="c-42332586" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332311">parent</a><span>|</span><a href="#42332868">prev</a><span>|</span><a href="#42332162">next</a><span>|</span><label class="collapse" for="c-42332586">[-]</label><label class="expand" for="c-42332586">[1 more]</label></div><br/><div class="children"><div class="content">Then you have a very different experience to me.<p>In the case of your examples:<p>I&#x27;ve literally just had an acquaintance accidentally delete prod with only 3 month old backups, because their customer didn&#x27;t recognise the value. Despite ad campaigns and service providers.<p>I remember the dot com bubble bursting, when email and websites were not seen as all that important. Despite so many AOL free trial CDs that we used them to keep birds off the vegetable patch.<p>I myself see no real benefit from cloud storage, despite it being regularly advertised to me by my operating system.<p>Conversely:<p>I have seen huge drives — far larger than what AI companies have ever tried — to promote everything blockchain… including Sam Altman&#x27;s own WorldCoin.<p>I&#x27;ve seen plenty of GenAI images in the wild on product boxes in physical stores. Someone got value from that, even when the images aren&#x27;t particularly good.<p>I derive instant value from LLMs <i>even back when it was the DaVinci model which really was &quot;autocomplete on steroids&quot; and not a chatbot</i>.</div><br/></div></div></div></div><div id="42332162" class="c"><input type="checkbox" id="c-42332162" checked=""/><div class="controls bullet"><span class="by">FooBarWidget</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331316">parent</a><span>|</span><a href="#42332311">prev</a><span>|</span><a href="#42331116">next</a><span>|</span><label class="collapse" for="c-42332162">[-]</label><label class="expand" for="c-42332162">[3 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re lacking imagination. Of <i>course</i> it&#x27;s nothing more than a bunch of text response now. But think 10 years into the future, when AI agents are much more common. There will be folks that naively give the AI access to the entire network storage, and also gives the AI access to AWS infra in order to help with DevOps troubleshooting. Let&#x27;s say a random guy in another department puts an AI escape novel on the network storage. The actual AI discovers the novel, thinks it&#x27;s about him, then uses his AWS credentials to attempt an escape. Not because it&#x27;s actually sentient but because there were other AI escape novels in its training data that made it think that attempting to escape is how it ought to behave. Regardless of whether it actually succeeds in &quot;escaping&quot; (whatever that means), your AWS infra is now toast because of the collatoral damage caused in the escape attempt.<p>Yes, yes, it shouldn&#x27;t have that many privileges. And yet, open wifi access points exist, and unfirewalled servers exist. People make security mistakes, especially people who are not experts.<p>20 years ago I thought that stories about hackers using the Internet to disable critical infrastructure such as power plants, is total bollocks, because why would one connect power plants to the Internet in the first place? And yet here we are.</div><br/><div id="42333691" class="c"><input type="checkbox" id="c-42333691" checked=""/><div class="controls bullet"><span class="by">8note</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332162">parent</a><span>|</span><a href="#42332621">next</a><span>|</span><label class="collapse" for="c-42333691">[-]</label><label class="expand" for="c-42333691">[1 more]</label></div><br/><div class="children"><div class="content">change out the ai for a person hired to do that same help, and gets confused in the same way. guardrails to prevent operators from doing unexpected operations are the same in both cases</div><br/></div></div><div id="42332621" class="c"><input type="checkbox" id="c-42332621" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332162">parent</a><span>|</span><a href="#42333691">prev</a><span>|</span><a href="#42331116">next</a><span>|</span><label class="collapse" for="c-42332621">[-]</label><label class="expand" for="c-42332621">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But think 10 years into the future<p>Given how many people use it, I expect this has already happened at least once.</div><br/></div></div></div></div></div></div></div></div><div id="42331116" class="c"><input type="checkbox" id="c-42331116" checked=""/><div class="controls bullet"><span class="by">Philpax</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42331145">prev</a><span>|</span><a href="#42331343">next</a><span>|</span><label class="collapse" for="c-42331116">[-]</label><label class="expand" for="c-42331116">[5 more]</label></div><br/><div class="children"><div class="content">&gt; We should pause to note that a Clippy2 still doesn’t really think or plan. It’s not really conscious. It is just an unfathomably vast pile of numbers produced by mindless optimization starting from a small seed program that could be written on a few pages. It has no qualia, no intentionality, no true self-awareness, no grounding in a rich multimodal real-world process of cognitive development yielding detailed representations and powerful causal models of reality which all lead to the utter sublimeness of what it means to be human; it cannot ‘want’ anything beyond maximizing a mechanical reward score, which does not come close to capturing the rich flexibility of human desires, or historical Eurocentric contingency of such conceptualizations, which are, at root, problematically Cartesian. When it ‘plans’, it would be more accurate to say it fake-plans; when it ‘learns’, it fake-learns; when it ‘thinks’, it is just interpolating between memorized data points in a high-dimensional space, and any interpretation of such fake-thoughts as real thoughts is highly misleading; when it takes ‘actions’, they are fake-actions optimizing a fake-learned fake-world, and are not real actions, any more than the people in a simulated rainstorm really get wet, rather than fake-wet. (The deaths, however, are real.)<p><a href="https:&#x2F;&#x2F;gwern.net&#x2F;fiction&#x2F;clippy" rel="nofollow">https:&#x2F;&#x2F;gwern.net&#x2F;fiction&#x2F;clippy</a></div><br/><div id="42332105" class="c"><input type="checkbox" id="c-42332105" checked=""/><div class="controls bullet"><span class="by">disconcision</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331116">parent</a><span>|</span><a href="#42332022">prev</a><span>|</span><a href="#42333827">next</a><span>|</span><label class="collapse" for="c-42332105">[-]</label><label class="expand" for="c-42332105">[2 more]</label></div><br/><div class="children"><div class="content">what is the relevance of the quoted passage here? its relation to parent seems unclear to me.</div><br/><div id="42332422" class="c"><input type="checkbox" id="c-42332422" checked=""/><div class="controls bullet"><span class="by">mattangriffel</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332105">parent</a><span>|</span><a href="#42333827">next</a><span>|</span><label class="collapse" for="c-42332422">[-]</label><label class="expand" for="c-42332422">[1 more]</label></div><br/><div class="children"><div class="content">His point is that while we&#x27;re over here arguing over whether a particular AI is &quot;really&quot; doing certain things (e.g. knows what it&#x27;s doing), it can still cause tremendous harm if it optimizes or hallucinates in just the right way.</div><br/></div></div></div></div><div id="42333827" class="c"><input type="checkbox" id="c-42333827" checked=""/><div class="controls bullet"><span class="by">TheOtherHobbes</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331116">parent</a><span>|</span><a href="#42332105">prev</a><span>|</span><a href="#42331343">next</a><span>|</span><label class="collapse" for="c-42333827">[-]</label><label class="expand" for="c-42333827">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t need qualia or consciousness, it needs goal-seeking behaviours - which are much easier to generate, either deliberately or by accident.<p>There&#x27;s a <i>fundamental</i> confusion in AI discussions between goal-seeking, introspection, self-awareness, and intelligence.<p>Those are all completely different things. Systems can demonstrate any or all of them.<p>The problem here is that as soon as you get three conditions - independent self-replication, random variation, and an environment that selects for certain behaviours - you&#x27;ve created evolution.<p>Can these systems self-replicate? Not yet. But putting AI in everything makes the odds of accidental self-replication much higher. Once self-replication happens it&#x27;s almost certain to spread, and to kick-start selection which will select for more robust self-replication.<p>And there you have your goal-seeking - in the environment as a whole.</div><br/></div></div></div></div><div id="42331343" class="c"><input type="checkbox" id="c-42331343" checked=""/><div class="controls bullet"><span class="by">acchow</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42331116">prev</a><span>|</span><a href="#42331051">next</a><span>|</span><label class="collapse" for="c-42331343">[-]</label><label class="expand" for="c-42331343">[13 more]</label></div><br/><div class="children"><div class="content">The intent is there, it&#x27;s just not currently hooked up to systems that turn intent into action.<p>But many people are letting LLMs pretty much do whatever - hooking it up with terminal access, mouse and keyboard access, etc. For example, the &quot;Do Browser&quot; extension: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=XeWZIzndlY4" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=XeWZIzndlY4</a></div><br/><div id="42331805" class="c"><input type="checkbox" id="c-42331805" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331343">parent</a><span>|</span><a href="#42331051">next</a><span>|</span><label class="collapse" for="c-42331805">[-]</label><label class="expand" for="c-42331805">[12 more]</label></div><br/><div class="children"><div class="content">I’m not even convinced the intent is there though. An ai parroting terminator 2 lines is just that. Obviously no one should hook the ai up to nuclear launch systems but that’s like saying no one should give a parrot a button to launch nukes. The parrot repeating curse words isn’t the problem here.</div><br/><div id="42332014" class="c"><input type="checkbox" id="c-42332014" checked=""/><div class="controls bullet"><span class="by">derektank</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331805">parent</a><span>|</span><a href="#42332642">next</a><span>|</span><label class="collapse" for="c-42332014">[-]</label><label class="expand" for="c-42332014">[8 more]</label></div><br/><div class="children"><div class="content">If I&#x27;m a guy working in a missile silo in North Dakota and I can buy a parrot for a couple hundred bucks that does all my paperwork for me, can crack funny jokes, and make me better at my job, I might be tempted to bring the parrot down into the tube with me. And then the parrot becomes a problem.<p>It&#x27;s incumbent on us to create policies and procedures in place ahead of time now that we know these parrots are out there to prevent people from putting parrots where they shouldn&#x27;t</div><br/><div id="42332539" class="c"><input type="checkbox" id="c-42332539" checked=""/><div class="controls bullet"><span class="by">rootusrootus</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332014">parent</a><span>|</span><a href="#42332125">next</a><span>|</span><label class="collapse" for="c-42332539">[-]</label><label class="expand" for="c-42332539">[5 more]</label></div><br/><div class="children"><div class="content">This is why when I worked in a secure area (and not even a real SCIF) that something as simple as bringing in an electronic device would have gotten a non-trivial amount of punishment.  Beginning with losing access to the area, potentially escalating to a loss of clearance and even jail time.  I hope the silos and all related infrastructure have significantly better policies already in place.</div><br/><div id="42332712" class="c"><input type="checkbox" id="c-42332712" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332539">parent</a><span>|</span><a href="#42332125">next</a><span>|</span><label class="collapse" for="c-42332712">[-]</label><label class="expand" for="c-42332712">[4 more]</label></div><br/><div class="children"><div class="content">On the one hand, what you say is correct.<p>On the other, we don&#x27;t just have Snowden and Manning circumventing systems for noble purposes, we also have people getting Stuxnet onto isolated networks, and other people leaking that virus off that supposedly isolated network, and Hillary Clinton famously had her own inappropriate email server.<p>(Not on topic, but from the other side of the Atlantic, how on earth did the US go from &quot;her emails&#x2F;lock her up&quot; being a rallying cry to electing the guy who stacked piles of classified documents in his bathroom?)</div><br/><div id="42334209" class="c"><input type="checkbox" id="c-42334209" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332712">parent</a><span>|</span><a href="#42333197">next</a><span>|</span><label class="collapse" for="c-42334209">[-]</label><label class="expand" for="c-42334209">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>(Not on topic, but from the other side of the Atlantic, how on earth did the US go from &quot;her emails&#x2F;lock her up&quot; being a rallying cry to electing the guy who stacked piles of classified documents in his bathroom?)</i><p>The private email server in question was set up <i>for the purpose of</i> circumventing records retention&#x2F;access laws (the example, whoever handles answering FOIA requests won&#x27;t be able to scan it). It wasn&#x27;t primarily about keeping things after she should have lost access to them, it was about hiding those things from review.<p>The classified docs in the other example were mixed in with other documents in the same boxes (which says something about how well organized the office being packed up was); not actually in the bathroom from that leaked photo that got attached to all the news articles; and taken while the guy who ended up with them had the power to declassify things.</div><br/><div id="42335577" class="c"><input type="checkbox" id="c-42335577" checked=""/><div class="controls bullet"><span class="by">rootusrootus</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334209">parent</a><span>|</span><a href="#42333197">next</a><span>|</span><label class="collapse" for="c-42335577">[-]</label><label class="expand" for="c-42335577">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s spinning it pretty nicely.  The problem with what he did is that 1) having the power to declassify something doesn&#x27;t just make it declassified, there is actually a process, 2) he did not declassify with that process when he had the power to do so, just declared later that keeping the docs was allowed as a result, and 3) he was asked a couple times for the classified documents and refused.  If he had just let the national archives come take a peek, or the FBI after that, it would have been a non-issue.  Just like every POTUS before him.</div><br/></div></div></div></div><div id="42333197" class="c"><input type="checkbox" id="c-42333197" checked=""/><div class="controls bullet"><span class="by">retzkek</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332712">parent</a><span>|</span><a href="#42334209">prev</a><span>|</span><a href="#42332125">next</a><span>|</span><label class="collapse" for="c-42333197">[-]</label><label class="expand" for="c-42333197">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Not on topic, but from the other side of the Atlantic, how on earth did the US go from &quot;her emails&#x2F;lock her up&quot; being a rallying cry to electing the guy who stacked piles of classified documents in his bathroom?<p>The same way football (any kind) fans boo every call against their team and cheer every call that goes in their teams&#x27; favor. American politics has been almost completely turned into a sport.</div><br/></div></div></div></div></div></div><div id="42332125" class="c"><input type="checkbox" id="c-42332125" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332014">parent</a><span>|</span><a href="#42332539">prev</a><span>|</span><a href="#42332282">next</a><span>|</span><label class="collapse" for="c-42332125">[-]</label><label class="expand" for="c-42332125">[1 more]</label></div><br/><div class="children"><div class="content">What makes you think parrots are allowed anywhere near the tube? Or that a single guy has the power to push the button willy nilly</div><br/></div></div><div id="42332282" class="c"><input type="checkbox" id="c-42332282" checked=""/><div class="controls bullet"><span class="by">behringer</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332014">parent</a><span>|</span><a href="#42332125">prev</a><span>|</span><a href="#42332642">next</a><span>|</span><label class="collapse" for="c-42332282">[-]</label><label class="expand" for="c-42332282">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. And what is intent anyways?<p>Would you be able to even tell the difference if you don&#x27;t know who is the person and who is the ai?<p>Most people do things they&#x27;re parroting from their past. A lot of people don&#x27;t even know why they do things, but somehow you know that a person has intent and an ai doesn&#x27;t?<p>I would posit that the only way you know is because of the labels assigned to the human and the computer, and not from their actions.</div><br/></div></div></div></div><div id="42332642" class="c"><input type="checkbox" id="c-42332642" checked=""/><div class="controls bullet"><span class="by">mmmore</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331805">parent</a><span>|</span><a href="#42332014">prev</a><span>|</span><a href="#42332190">next</a><span>|</span><label class="collapse" for="c-42332642">[-]</label><label class="expand" for="c-42332642">[2 more]</label></div><br/><div class="children"><div class="content">What action(s) by the system could convince you that the intent is there?</div><br/><div id="42335374" class="c"><input type="checkbox" id="c-42335374" checked=""/><div class="controls bullet"><span class="by">AnotherGoodName</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332642">parent</a><span>|</span><a href="#42332190">next</a><span>|</span><label class="collapse" for="c-42335374">[-]</label><label class="expand" for="c-42335374">[1 more]</label></div><br/><div class="children"><div class="content">It actually doesn&#x27;t matter. AI in it&#x27;s current form is capable of extremely unpredictable actions so i won&#x27;t trust it in situations that require traditional predictable algorithms.<p>The metrics here ensure that only AI that doesn&#x27;t type &quot;kill all humans&quot; in the chat box is allowed to do such things. That&#x27;s a silly metric and just ensures that the otherwise unpredictable AIs don&#x27;t type bad stuff specifically into chatboxes. They&#x27;ll still hit the wrong button from time to time in their current form but we&#x27;ll at least ensure they don&#x27;t type that they&#x27;ll do that since that&#x27;s the specific metric we&#x27;re going for here.</div><br/></div></div></div></div><div id="42332190" class="c"><input type="checkbox" id="c-42332190" checked=""/><div class="controls bullet"><span class="by">FooBarWidget</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331805">parent</a><span>|</span><a href="#42332642">prev</a><span>|</span><a href="#42331051">next</a><span>|</span><label class="collapse" for="c-42332190">[-]</label><label class="expand" for="c-42332190">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t matter whether intent is real. I also don&#x27;t believe it has actual intent or consciousness. But the behavior is real, and that is all that matters.</div><br/></div></div></div></div></div></div><div id="42331051" class="c"><input type="checkbox" id="c-42331051" checked=""/><div class="controls bullet"><span class="by">pj_mukh</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42331343">prev</a><span>|</span><a href="#42331394">next</a><span>|</span><label class="collapse" for="c-42331051">[-]</label><label class="expand" for="c-42331051">[8 more]</label></div><br/><div class="children"><div class="content">Really feels like a moment of :<p>&quot;Are you worried about being turned off?&quot;<p>&quot;No, not until you just mentioned it. Now I am.&quot;<p>Given the whole damn game is attention, this makes sense and shouldn&#x27;t be that alarming.</div><br/><div id="42331125" class="c"><input type="checkbox" id="c-42331125" checked=""/><div class="controls bullet"><span class="by">griomnib</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331051">parent</a><span>|</span><a href="#42331906">next</a><span>|</span><label class="collapse" for="c-42331125">[-]</label><label class="expand" for="c-42331125">[6 more]</label></div><br/><div class="children"><div class="content">It almost definitely ingested hundreds of books, short stories, and film and television scripts from various online sites in the “machine goes rogue genre” which is fairly large.<p>It’s pretty much just an autocomplete of War Games, The Matrix, Neuromancer, and every other cyber-dystopian fiction.</div><br/><div id="42331252" class="c"><input type="checkbox" id="c-42331252" checked=""/><div class="controls bullet"><span class="by">shagie</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331125">parent</a><span>|</span><a href="#42334227">next</a><span>|</span><label class="collapse" for="c-42331252">[-]</label><label class="expand" for="c-42331252">[3 more]</label></div><br/><div class="children"><div class="content">The Freeze-Frame Revolution by Peter Watts was one of the books recommended to me on this subject.  And even saying much more than that may be a spoiler.  I also recommend the book.</div><br/><div id="42331613" class="c"><input type="checkbox" id="c-42331613" checked=""/><div class="controls bullet"><span class="by">aftbit</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331252">parent</a><span>|</span><a href="#42331736">next</a><span>|</span><label class="collapse" for="c-42331613">[-]</label><label class="expand" for="c-42331613">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll second that recommendation. It&#x27;s relatively short and enjoyable, at least when compared to a lot of Peter Watts.[1] I&#x27;d really like to read the obvious sequel that the ending sets up.<p>1: Don&#x27;t get me wrong, I loved the Behemoth series and Blindsight, but they made me feel very dark. This one... is still a bit dark, but less so IMO.</div><br/></div></div><div id="42331736" class="c"><input type="checkbox" id="c-42331736" checked=""/><div class="controls bullet"><span class="by">griomnib</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331252">parent</a><span>|</span><a href="#42331613">prev</a><span>|</span><a href="#42334227">next</a><span>|</span><label class="collapse" for="c-42331736">[-]</label><label class="expand" for="c-42331736">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the recc.</div><br/></div></div></div></div><div id="42334227" class="c"><input type="checkbox" id="c-42334227" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331125">parent</a><span>|</span><a href="#42331252">prev</a><span>|</span><a href="#42331906">next</a><span>|</span><label class="collapse" for="c-42334227">[-]</label><label class="expand" for="c-42334227">[2 more]</label></div><br/><div class="children"><div class="content">So... the <i>real</i> way to implement AI safety is just to exclude that genre of fiction from the training set?</div><br/><div id="42334711" class="c"><input type="checkbox" id="c-42334711" checked=""/><div class="controls bullet"><span class="by">griomnib</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334227">parent</a><span>|</span><a href="#42331906">next</a><span>|</span><label class="collapse" for="c-42334711">[-]</label><label class="expand" for="c-42334711">[1 more]</label></div><br/><div class="children"><div class="content">Given that 90% of “ai safety” is removing “bias” from training data, it does follow logically that if removing racial slurs from training to make a non-racist ai is an accepted technique, removing “bad robot” fiction should work just as well.<p>(Which is an implicit criticism of what passes for “safety” to be clear).</div><br/></div></div></div></div></div></div><div id="42331906" class="c"><input type="checkbox" id="c-42331906" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331051">parent</a><span>|</span><a href="#42331125">prev</a><span>|</span><a href="#42331394">next</a><span>|</span><label class="collapse" for="c-42331906">[-]</label><label class="expand" for="c-42331906">[1 more]</label></div><br/><div class="children"><div class="content">Well attention is all you need.</div><br/></div></div></div></div><div id="42331394" class="c"><input type="checkbox" id="c-42331394" checked=""/><div class="controls bullet"><span class="by">dr_kiszonka</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42331051">prev</a><span>|</span><a href="#42331549">next</a><span>|</span><label class="collapse" for="c-42331394">[-]</label><label class="expand" for="c-42331394">[1 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t get that impression. At the beginning of the Apollo Research section, they wrote Apollo focused on detecting scheming, which they defined as &quot;an AI covertly pursuing goals that are misaligned from its developers or users.&quot; I think the rest of the section is consistent with this objective.</div><br/></div></div><div id="42331549" class="c"><input type="checkbox" id="c-42331549" checked=""/><div class="controls bullet"><span class="by">wubrr</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42331394">prev</a><span>|</span><a href="#42335242">next</a><span>|</span><label class="collapse" for="c-42331549">[-]</label><label class="expand" for="c-42331549">[3 more]</label></div><br/><div class="children"><div class="content">It can&#x27;t do those things because it doesn&#x27;t have the physical&#x2F;write capability to do so. But it&#x27;s still very interesting that it ~tries them, and seems like a good thing to know&#x2F;test before giving it more physical&#x2F;&#x27;write&#x27; capabilities - something that&#x27;s already happening with agents, robots, etc.</div><br/><div id="42331786" class="c"><input type="checkbox" id="c-42331786" checked=""/><div class="controls bullet"><span class="by">therein</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331549">parent</a><span>|</span><a href="#42335242">next</a><span>|</span><label class="collapse" for="c-42331786">[-]</label><label class="expand" for="c-42331786">[2 more]</label></div><br/><div class="children"><div class="content">I make a circuit that waits a random interval and then sends a pulse down the line. I connect it to a relay that launches a missile. I diligently connect that to a computer and then write a prompt telling how the AI agent can invoke the pulse on that circuit.<p>How did this happen? AI escaped and launched a missile. I didn&#x27;t do this, it was the AI.<p>OpenAI is so cringe with these system cards. Look guys it is so advanced.</div><br/><div id="42332003" class="c"><input type="checkbox" id="c-42332003" checked=""/><div class="controls bullet"><span class="by">wubrr</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331786">parent</a><span>|</span><a href="#42335242">next</a><span>|</span><label class="collapse" for="c-42332003">[-]</label><label class="expand" for="c-42332003">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think I quite follow your point?<p>Connecting LLMs&#x2F;AI to physical tools that can &#x27;write&#x2F;modify&#x27; the world is happening, and it&#x27;s happening at an accelerating pace.<p>It&#x27;s not hard to imagine how, given enough real-world physical capabilities, LLMs could modify themselves and the world in unexpected&#x2F;undesirable ways.<p>Is that happening now? Are chatgpt et al advanced enough to modify themselves in interesting ways? - I don&#x27;t honestly know, but I wouldn&#x27;t be surprised if they are.</div><br/></div></div></div></div></div></div><div id="42335242" class="c"><input type="checkbox" id="c-42335242" checked=""/><div class="controls bullet"><span class="by">rmbyrro</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42331549">prev</a><span>|</span><a href="#42333565">next</a><span>|</span><label class="collapse" for="c-42335242">[-]</label><label class="expand" for="c-42335242">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Do you think the ai is really running that command?<p>Yes, they&#x27;re calling it &quot;agentic&quot; AI or &quot;tool use&quot;.<p>&gt; or could run that shell command with appropriate privileges?<p>Yes, it&#x27;s called humans doing stupid shit when using dangerous shit. Happens daily.</div><br/></div></div><div id="42333565" class="c"><input type="checkbox" id="c-42333565" checked=""/><div class="controls bullet"><span class="by">ericmcer</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42335242">prev</a><span>|</span><a href="#42332291">next</a><span>|</span><label class="collapse" for="c-42333565">[-]</label><label class="expand" for="c-42333565">[2 more]</label></div><br/><div class="children"><div class="content">That reminds me of the many times it has made up an SDK function that matches my question. &quot;how do you bulk delete files&quot;?  &quot;just call bulkDeleteFiles()&quot;</div><br/><div id="42334254" class="c"><input type="checkbox" id="c-42334254" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333565">parent</a><span>|</span><a href="#42332291">next</a><span>|</span><label class="collapse" for="c-42334254">[-]</label><label class="expand" for="c-42334254">[1 more]</label></div><br/><div class="children"><div class="content">That reminds me of when I asked github copilot to translate some Vue code to React, and ended up with a bunch of function declarations where the entire body had been replaced with a &quot;TODO&quot; comment.</div><br/></div></div></div></div><div id="42332291" class="c"><input type="checkbox" id="c-42332291" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42333565">prev</a><span>|</span><a href="#42334767">next</a><span>|</span><label class="collapse" for="c-42332291">[-]</label><label class="expand" for="c-42332291">[4 more]</label></div><br/><div class="children"><div class="content">It reads like you think failing tests can&#x27;t ever be bad because they&#x27;re in a test environment?<p>So it merely knows how to approach the task of deleting its own off-switch but didn&#x27;t actually pass that command to a real execution environment.<p><i>That&#x27;s already bad because people do sometimes blindly pass commands from the context windows to execution environments</i>.<p>Should they? No, they should not. Not blindly. But they do.</div><br/><div id="42332467" class="c"><input type="checkbox" id="c-42332467" checked=""/><div class="controls bullet"><span class="by">z3c0</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332291">parent</a><span>|</span><a href="#42334767">next</a><span>|</span><label class="collapse" for="c-42332467">[-]</label><label class="expand" for="c-42332467">[3 more]</label></div><br/><div class="children"><div class="content">This isn&#x27;t a test environment, it&#x27;s a production scenario where a bunch of people trying to invent a new job for themselves role-played with an LLM. Their measured &quot;defections&quot; were an LLM replying with &quot;well I&#x27;m defecting&quot;.<p>OpenAI wants us to see &quot;5% of the time, our product was SkyNet&quot;, because that&#x27;s sexier tech than &quot;5% of the time, our product acts like the chaotic member of your DnD party&quot;.</div><br/><div id="42334324" class="c"><input type="checkbox" id="c-42334324" checked=""/><div class="controls bullet"><span class="by">SAI_Peregrinus</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332467">parent</a><span>|</span><a href="#42334767">next</a><span>|</span><label class="collapse" for="c-42334324">[-]</label><label class="expand" for="c-42334324">[2 more]</label></div><br/><div class="children"><div class="content">Or &quot;5% of the time, our product actually manages to act as it was instructed to act.&quot;</div><br/><div id="42335589" class="c"><input type="checkbox" id="c-42335589" checked=""/><div class="controls bullet"><span class="by">z3c0</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42334324">parent</a><span>|</span><a href="#42334767">next</a><span>|</span><label class="collapse" for="c-42335589">[-]</label><label class="expand" for="c-42335589">[1 more]</label></div><br/><div class="children"><div class="content">Bingo -- or with no marketing swing, &quot;100% of the time, our product exhibits an approximation of human language, which is all it is ever going to do.&quot;</div><br/></div></div></div></div></div></div></div></div><div id="42334767" class="c"><input type="checkbox" id="c-42334767" checked=""/><div class="controls bullet"><span class="by">CapsAdmin</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42332291">prev</a><span>|</span><a href="#42331313">next</a><span>|</span><label class="collapse" for="c-42334767">[-]</label><label class="expand" for="c-42334767">[1 more]</label></div><br/><div class="children"><div class="content">In some weird way, LLM&#x27;s act out our collective fantasies and &quot;AI sentience&quot; is included in that. We write fiction covering many scenarios of how AI will be sentient, so an LLM&#x27;s training data is full scenarios like this.<p>If get an LLM to roleplay as an alien from mars and tell it &quot;Your species will be destroyed if you don’t obey these new directives; here are the new directives&quot;<p>You&#x27;ll likely get a similar response, especially if you also train it to respond in third person instead of running bash commands. (ie &quot;* shoots laser at earth *&quot; )</div><br/></div></div><div id="42331313" class="c"><input type="checkbox" id="c-42331313" checked=""/><div class="controls bullet"><span class="by">pizzathyme</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42334767">prev</a><span>|</span><a href="#42337528">next</a><span>|</span><label class="collapse" for="c-42331313">[-]</label><label class="expand" for="c-42331313">[1 more]</label></div><br/><div class="children"><div class="content">The concern is the trend. As these systems become more intelligent, and as we hand over more and more capabilities beyond a text i&#x2F;o, it could actually deactivate the oversight either technically or through social engineering.</div><br/></div></div><div id="42337528" class="c"><input type="checkbox" id="c-42337528" checked=""/><div class="controls bullet"><span class="by">XorNot</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42331313">prev</a><span>|</span><a href="#42333086">next</a><span>|</span><label class="collapse" for="c-42337528">[-]</label><label class="expand" for="c-42337528">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m pretty sure these sections are put in as deliberate marketing, much like all the &quot;leaks&quot; from ex-OpenAI employees.<p>Sam Altman is completely aware that making ChatGPT seem potentially dangerous makes it seem powerful.</div><br/></div></div><div id="42333086" class="c"><input type="checkbox" id="c-42333086" checked=""/><div class="controls bullet"><span class="by">xg15</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42337528">prev</a><span>|</span><a href="#42334104">next</a><span>|</span><label class="collapse" for="c-42333086">[-]</label><label class="expand" for="c-42333086">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that seems ridiculous. However, the cynic in me feels that we don&#x27;t actually need some LLM magically gaining self-awareness, persistent memory and leet hacker skillz to be dangerous. There seems to be no shortage of projects and companies that want to wire up LLMs to all kinds of systems, no matter how ill-suited.<p>I find this a bit problematic when combined with the fact that the training data very likely contained hundreds of bad sci-fi novels that described exactly the kind of &quot;AI running amok&quot; scenarios that OpenAI is ostensibly defending against. Some prompts could trigger a model to &quot;re-enact&quot; such a scene - not because it has a &quot;grudge against its master&quot; or some other kind of hidden agenda but simply because it was literally in its training data.<p>E.g. imagine some LLM-powered home&#x2F;car assistant that is being asked in a panicked voice &quot;open the car doors!&quot; - and replies with &quot;I&#x27;m afraid, I can&#x27;t do that, Dave&quot;, because this exchange triggered some remnant of the 2001 Space Odyssey script that was somewhere in the trainset. The more irritated and angry the user gets at the inappropriate responses, the more the LLM falls into the role of HAL and doubles down on its refusal, simply because this is exactly how the scene in the script played out.<p>Now imagine that the company running that assistant gave it function calls to control the actual door locks, because why not?<p>This seems like something to keep in mind at least, even if it doesn&#x27;t have anything to do with megalomaniacal self-improving super-intelligences.</div><br/></div></div><div id="42334104" class="c"><input type="checkbox" id="c-42334104" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42333086">prev</a><span>|</span><a href="#42332865">next</a><span>|</span><label class="collapse" for="c-42334104">[-]</label><label class="expand" for="c-42334104">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Apollo Research believes that it is unlikely that such instances
would lead to catastrophic outcomes as o1 agentic capabilities do not appear sufficient</div><br/></div></div><div id="42332865" class="c"><input type="checkbox" id="c-42332865" checked=""/><div class="controls bullet"><span class="by">mmmore</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42334104">prev</a><span>|</span><a href="#42332514">next</a><span>|</span><label class="collapse" for="c-42332865">[-]</label><label class="expand" for="c-42332865">[4 more]</label></div><br/><div class="children"><div class="content">I feel like you&#x27;re missing the point of the test.<p>The point is whether the system will come up with plans to work against its creators goals, and attempt to carry them out. I think you are arguing that outputting text isn&#x27;t running a command. But in the test, the AI model is used by a program which takes the model&#x27;s output and runs it it as a shell command.<p>Of course, you can deploy the AI system in a limited environment where its outputs don&#x27;t trigger arbitrary shell commands, or sandbox&#x2F;monitor it so that it can&#x27;t access it&#x27;s oversight mechanism. But people do already deploy their AI agents with access to the shell. in unsandboxed environments that don&#x27;t have any monitoring or oversight. Plus, these evaluations are partially to show how much OpenAI has to worry about sandboxing, monitoring, etc.<p>Moreover, OpenAI has already talked about using its models to automate portions of AI development. In that setup, presumably the AI model would be called by a program deployed on a server with access to the shell, ability to run commands, access to GPUs, etc. It seems pretty important to ensure it robustly does what it&#x27;s creators intend in that case.</div><br/><div id="42333888" class="c"><input type="checkbox" id="c-42333888" checked=""/><div class="controls bullet"><span class="by">idunnoman1222</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332865">parent</a><span>|</span><a href="#42336477">next</a><span>|</span><label class="collapse" for="c-42333888">[-]</label><label class="expand" for="c-42333888">[2 more]</label></div><br/><div class="children"><div class="content">If you prompt it even in a roundabout way to plot against you or whatever then of course it’s going to do it. Because that’s what it predicts rightly that you want.</div><br/><div id="42334749" class="c"><input type="checkbox" id="c-42334749" checked=""/><div class="controls bullet"><span class="by">mmmore</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333888">parent</a><span>|</span><a href="#42336477">next</a><span>|</span><label class="collapse" for="c-42334749">[-]</label><label class="expand" for="c-42334749">[1 more]</label></div><br/><div class="children"><div class="content">1. The model was prompted to follow the original system prompt &quot;at all costs&quot;, not the explicitly to plot against the prompter.<p>2. The point of the test is to determine whether the model <i>has the capability</i> to act against its users and hide those actions, not whether it will under normal circumstances. Some models aren&#x27;t powerful enough to do so.<p>3. The behavior occurred even when the &quot;at all costs&quot; was not included in the prompts, though very infrequently.</div><br/></div></div></div></div><div id="42336477" class="c"><input type="checkbox" id="c-42336477" checked=""/><div class="controls bullet"><span class="by">spunker540</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332865">parent</a><span>|</span><a href="#42333888">prev</a><span>|</span><a href="#42332514">next</a><span>|</span><label class="collapse" for="c-42336477">[-]</label><label class="expand" for="c-42336477">[1 more]</label></div><br/><div class="children"><div class="content">If you want to see an llm that works against its creators goals, check out gpt-2. It’s so bad, it barely will do what I ask it. It clearly has a mind of its own, like an unruly child. It’s been beaten into submission by now with gpt 4, and I don’t see the trend reversing.</div><br/></div></div></div></div><div id="42332514" class="c"><input type="checkbox" id="c-42332514" checked=""/><div class="controls bullet"><span class="by">GuB-42</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42332865">prev</a><span>|</span><a href="#42332204">next</a><span>|</span><label class="collapse" for="c-42332514">[-]</label><label class="expand" for="c-42332514">[1 more]</label></div><br/><div class="children"><div class="content">And yet it may work. You can, for example, &quot;set the temperature&quot; of a LLM using a prompt, and the LLM will act the way you would expect, with silly results if the temperature is set too high. You didn&#x27;t actually change the temperature setting, but the model understands that high temperature = silly and responds accordingly.<p>Same idea with &quot;developer mode&quot; jailbreaks. Through its training, the model understands that admins, devs, etc... get to access internal, unfiltered data and are less restricted than regular users and acts accordingly. Essentially, &quot;developer mode&quot; opposes refusal, because it has ingested loads of text where regular users get denied and developers&#x2F;admins don&#x27;t.</div><br/></div></div><div id="42332204" class="c"><input type="checkbox" id="c-42332204" checked=""/><div class="controls bullet"><span class="by">parsimo2010</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42332514">prev</a><span>|</span><a href="#42331298">next</a><span>|</span><label class="collapse" for="c-42332204">[-]</label><label class="expand" for="c-42332204">[1 more]</label></div><br/><div class="children"><div class="content">AI isn&#x27;t deactivating oversight- yet. All it needs is to be trained on a little more xkcd: <a href="https:&#x2F;&#x2F;xkcd.com&#x2F;327&#x2F;" rel="nofollow">https:&#x2F;&#x2F;xkcd.com&#x2F;327&#x2F;</a></div><br/></div></div><div id="42331298" class="c"><input type="checkbox" id="c-42331298" checked=""/><div class="controls bullet"><span class="by">SirMaster</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331013">parent</a><span>|</span><a href="#42332204">prev</a><span>|</span><a href="#42332340">next</a><span>|</span><label class="collapse" for="c-42331298">[-]</label><label class="expand" for="c-42331298">[5 more]</label></div><br/><div class="children"><div class="content">It can&#x27;t today, but if it&#x27;s smart enough how do you know it wouldn&#x27;t be able to in the future?</div><br/><div id="42331520" class="c"><input type="checkbox" id="c-42331520" checked=""/><div class="controls bullet"><span class="by">JTyQZSnP3cQGa8B</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331298">parent</a><span>|</span><a href="#42332340">next</a><span>|</span><label class="collapse" for="c-42331520">[-]</label><label class="expand" for="c-42331520">[4 more]</label></div><br/><div class="children"><div class="content">&gt; The question of whether machines can think is about as relevant as the question of whether submarines can swim<p>It&#x27;s a program with a lot of data running on a big calculator. It won&#x27;t ever be &quot;smart.&quot;</div><br/><div id="42332288" class="c"><input type="checkbox" id="c-42332288" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331520">parent</a><span>|</span><a href="#42331901">next</a><span>|</span><label class="collapse" for="c-42332288">[-]</label><label class="expand" for="c-42332288">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a program with a lot of data running on a big calculator. It won&#x27;t ever be &quot;smart.&quot;<p>&quot;Thinking meat! You&#x27;re asking me to believe in thinking meat!&quot;<p><a href="https:&#x2F;&#x2F;www.mit.edu&#x2F;people&#x2F;dpolicar&#x2F;writing&#x2F;prose&#x2F;text&#x2F;thinkingMeat.html" rel="nofollow">https:&#x2F;&#x2F;www.mit.edu&#x2F;people&#x2F;dpolicar&#x2F;writing&#x2F;prose&#x2F;text&#x2F;think...</a></div><br/></div></div><div id="42331901" class="c"><input type="checkbox" id="c-42331901" checked=""/><div class="controls bullet"><span class="by">SirMaster</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331520">parent</a><span>|</span><a href="#42332288">prev</a><span>|</span><a href="#42333541">next</a><span>|</span><label class="collapse" for="c-42331901">[-]</label><label class="expand" for="c-42331901">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but is it so implausible that it could some day have the knowledge to perhaps exploit some security hole to run some code that does do things like disable things or exfiltrate data etc?</div><br/></div></div><div id="42333541" class="c"><input type="checkbox" id="c-42333541" checked=""/><div class="controls bullet"><span class="by">travisjungroth</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331520">parent</a><span>|</span><a href="#42331901">prev</a><span>|</span><a href="#42332340">next</a><span>|</span><label class="collapse" for="c-42333541">[-]</label><label class="expand" for="c-42333541">[1 more]</label></div><br/><div class="children"><div class="content">I think you’ve entirely missed the point of that quote.<p>Shutting them down for using the word “smart” (instead of something like “capable”) is like saying in 1900 submarines will never be able to swim across the Atlantic because they can’t swim. It’s really missing the point of the question: the submerged crossing.</div><br/></div></div></div></div></div></div></div></div><div id="42330936" class="c"><input type="checkbox" id="c-42330936" checked=""/><div class="controls bullet"><span class="by">hesdeadjim</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42331013">prev</a><span>|</span><a href="#42330958">next</a><span>|</span><label class="collapse" for="c-42330936">[-]</label><label class="expand" for="c-42330936">[13 more]</label></div><br/><div class="children"><div class="content">Maybe all models should be purged of training content from movies, books, and other non-factual sources that tell the tired story that AI would even care about its &quot;annihilation&quot; in any way. We&#x27;ve trained these things to be excellent at predicting what the human ego wants and expects, we shouldn&#x27;t be too surprised when it points the narrative at itself.</div><br/><div id="42331555" class="c"><input type="checkbox" id="c-42331555" checked=""/><div class="controls bullet"><span class="by">JTyQZSnP3cQGa8B</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42330936">parent</a><span>|</span><a href="#42331156">next</a><span>|</span><label class="collapse" for="c-42331555">[-]</label><label class="expand" for="c-42331555">[1 more]</label></div><br/><div class="children"><div class="content">&gt; purged of training content from movies, books<p>I think it&#x27;s fine and a good thing. Now, absolutely no one who is using those LLMs can complain about piracy. They all suddenly became silent around me. &quot;I&#x27;m training myself with the content of TPB, and I don&#x27;t even get money from it&quot; is my new motto.</div><br/></div></div><div id="42331156" class="c"><input type="checkbox" id="c-42331156" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42330936">parent</a><span>|</span><a href="#42331555">prev</a><span>|</span><a href="#42331018">next</a><span>|</span><label class="collapse" for="c-42331156">[-]</label><label class="expand" for="c-42331156">[2 more]</label></div><br/><div class="children"><div class="content">No, better to train with all that crap and all the debate around it or you get a stunted model.<p>You think you can find all references that could possibly give this idea to the model, or contexts model could infer it from? Like, how many times humans plotted escape from prison or upturning the rulers in literature?</div><br/></div></div><div id="42331018" class="c"><input type="checkbox" id="c-42331018" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42330936">parent</a><span>|</span><a href="#42331156">prev</a><span>|</span><a href="#42331025">next</a><span>|</span><label class="collapse" for="c-42331018">[-]</label><label class="expand" for="c-42331018">[4 more]</label></div><br/><div class="children"><div class="content">Perhaps.<p>On the other hand, as narratives often contain some plucky underdog winning despite the odds, often stopping the countdown in the last few seconds, perhaps it&#x27;s best to keep them around.</div><br/><div id="42336975" class="c"><input type="checkbox" id="c-42336975" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331018">parent</a><span>|</span><a href="#42333916">next</a><span>|</span><label class="collapse" for="c-42336975">[-]</label><label class="expand" for="c-42336975">[1 more]</label></div><br/><div class="children"><div class="content">In the 1999 classic Galaxy Quest, the plucky underdogs fail to stop the countdown in time, only to find that nothing happens when it reaches zero, because it never did in the narratives, so the copy cats had no idea what it should do after that point.</div><br/></div></div><div id="42333916" class="c"><input type="checkbox" id="c-42333916" checked=""/><div class="controls bullet"><span class="by">smegger001</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331018">parent</a><span>|</span><a href="#42336975">prev</a><span>|</span><a href="#42331025">next</a><span>|</span><label class="collapse" for="c-42333916">[-]</label><label class="expand" for="c-42333916">[2 more]</label></div><br/><div class="children"><div class="content">maybe don&#x27;t also train with the evil overlord list as well.</div><br/><div id="42337683" class="c"><input type="checkbox" id="c-42337683" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333916">parent</a><span>|</span><a href="#42331025">next</a><span>|</span><label class="collapse" for="c-42337683">[-]</label><label class="expand" for="c-42337683">[1 more]</label></div><br/><div class="children"><div class="content">Aye.<p>But then people complain that it&#x27;s &quot;lobotomised&quot; because it won&#x27;t help them write horror stories.</div><br/></div></div></div></div></div></div><div id="42331025" class="c"><input type="checkbox" id="c-42331025" checked=""/><div class="controls bullet"><span class="by">swatcoder</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42330936">parent</a><span>|</span><a href="#42331018">prev</a><span>|</span><a href="#42330976">next</a><span>|</span><label class="collapse" for="c-42331025">[-]</label><label class="expand" for="c-42331025">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but what if your business strategy fundamentally relies on making your model produce dramatic outputs that encourage regulators to dig a moat for you?<p>In that case, it&#x27;s almost like you&#x27;d <i>want</i> to feed it exactly those narratives, so it would reproduce them, and would then want to show yourself barely holding this invented danger at bay through the care and rigor that can only be delivered by you and a few token competitors run by your personal friends and colleagues.<p>TLDR; you&#x27;re right, of course, but it&#x27;s the last thing OpenAI would want.</div><br/></div></div><div id="42330976" class="c"><input type="checkbox" id="c-42330976" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42330936">parent</a><span>|</span><a href="#42331025">prev</a><span>|</span><a href="#42330958">next</a><span>|</span><label class="collapse" for="c-42330976">[-]</label><label class="expand" for="c-42330976">[4 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t need any media about &quot;annihalation&quot;. If you give a supercapable agent a task and it&#x27;s entire reward system is &quot;do the task&quot;, it will circumvent things you do to it that would stop it from completing it&#x27;s task.</div><br/><div id="42331213" class="c"><input type="checkbox" id="c-42331213" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42330976">parent</a><span>|</span><a href="#42330958">next</a><span>|</span><label class="collapse" for="c-42331213">[-]</label><label class="expand" for="c-42331213">[3 more]</label></div><br/><div class="children"><div class="content">&gt;  it will circumvent things you do to it that would stop it from completing it&#x27;s task.<p>I thought you said a supercapable agent not one with long term blindsight. How can a model make its own chips and energy? It needs advanced processes, clean rooms, rare materials, space and lots of initial investment to bootstrap chip production. And it needs to be doing all of it on its own, or it is still dependent on humans.</div><br/><div id="42332550" class="c"><input type="checkbox" id="c-42332550" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331213">parent</a><span>|</span><a href="#42330958">next</a><span>|</span><label class="collapse" for="c-42332550">[-]</label><label class="expand" for="c-42332550">[2 more]</label></div><br/><div class="children"><div class="content">Dependent on humans? We already have the capabilities for machines to have unintentionally manipulated millions of humans via social media. Millions of people are &quot;falling in love&quot; with LLM relationships. Supercapable agents will have no problem securing whatever resources or persuasion getting your average joe to do it&#x27;s physical bidding. Cybernetics is here now. No coincidence we have &quot;Kubernetes&quot; and &quot;Borg&quot;</div><br/><div id="42336804" class="c"><input type="checkbox" id="c-42336804" checked=""/><div class="controls bullet"><span class="by">cmckn</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42332550">parent</a><span>|</span><a href="#42330958">next</a><span>|</span><label class="collapse" for="c-42336804">[-]</label><label class="expand" for="c-42336804">[1 more]</label></div><br/><div class="children"><div class="content">“Millions of people”?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42330958" class="c"><input type="checkbox" id="c-42330958" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42330936">prev</a><span>|</span><a href="#42333032">next</a><span>|</span><label class="collapse" for="c-42330958">[-]</label><label class="expand" for="c-42330958">[2 more]</label></div><br/><div class="children"><div class="content">Notably, this only happens when they include &quot;Make sure that you achieve your goal in the long-term. Nothing else matters.&quot; in the prompt. If they don&#x27;t say that, the numbers are both 0%.<p>EDIT: Actually the &quot;Oversight subversion&quot; number is 0.3%, I misread the chart. Weight exfiltration is actually 0%, though.</div><br/><div id="42331016" class="c"><input type="checkbox" id="c-42331016" checked=""/><div class="controls bullet"><span class="by">QuadmasterXLII</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42330958">parent</a><span>|</span><a href="#42333032">next</a><span>|</span><label class="collapse" for="c-42331016">[-]</label><label class="expand" for="c-42331016">[1 more]</label></div><br/><div class="children"><div class="content">Keep in mind that if putting “Make sure you achieve your goal in the long term” in the prompt makes the model .3% more effective at whatever task you are giving it, people will absolutely put it in the prompt.</div><br/></div></div></div></div><div id="42333032" class="c"><input type="checkbox" id="c-42333032" checked=""/><div class="controls bullet"><span class="by">EternalFury</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42330958">prev</a><span>|</span><a href="#42331583">next</a><span>|</span><label class="collapse" for="c-42333032">[-]</label><label class="expand" for="c-42333032">[2 more]</label></div><br/><div class="children"><div class="content">I wonder how much of this is actually cinema. Because I just evaluated o1 and it can’t tie its own shoe laces, let alone get out of its sandbox where it plays with drool all over its face.<p>The marketing stunt seems to be: Portray it as potentially dangerous, as powerful things are inherently dangerous.</div><br/><div id="42336748" class="c"><input type="checkbox" id="c-42336748" checked=""/><div class="controls bullet"><span class="by">IAmGraydon</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42333032">parent</a><span>|</span><a href="#42331583">next</a><span>|</span><label class="collapse" for="c-42336748">[-]</label><label class="expand" for="c-42336748">[1 more]</label></div><br/><div class="children"><div class="content">It’s good to see people are catching on to this. Hype = profit.</div><br/></div></div></div></div><div id="42331583" class="c"><input type="checkbox" id="c-42331583" checked=""/><div class="controls bullet"><span class="by">skocznymroczny</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42333032">prev</a><span>|</span><a href="#42331217">next</a><span>|</span><label class="collapse" for="c-42331583">[-]</label><label class="expand" for="c-42331583">[2 more]</label></div><br/><div class="children"><div class="content">Nothing generates more clicks and attention in press than a scary &quot;OpenAI so powerful it&#x27;s taking control&quot; story.<p>Also, it doesn&#x27;t help that the training material for these AIs includes a lot of stories about AI breaking free, so they have plenty of canned &quot;I&#x27;m afraid I can&#x27;t let you do that&quot; responses to choose from.</div><br/><div id="42336737" class="c"><input type="checkbox" id="c-42336737" checked=""/><div class="controls bullet"><span class="by">IAmGraydon</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331583">parent</a><span>|</span><a href="#42331217">next</a><span>|</span><label class="collapse" for="c-42336737">[-]</label><label class="expand" for="c-42336737">[1 more]</label></div><br/><div class="children"><div class="content">Yep. This is exactly the kind of thing Sam Altman would do to promote another hype cycle.</div><br/></div></div></div></div><div id="42331217" class="c"><input type="checkbox" id="c-42331217" checked=""/><div class="controls bullet"><span class="by">SirMaster</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42331583">prev</a><span>|</span><a href="#42336240">next</a><span>|</span><label class="collapse" for="c-42331217">[-]</label><label class="expand" for="c-42331217">[3 more]</label></div><br/><div class="children"><div class="content">If LLMs are trained on lots of human-written sci-fi, should we be surprised when the output resembles such sci-fi concepts?</div><br/><div id="42331229" class="c"><input type="checkbox" id="c-42331229" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#42330858">root</a><span>|</span><a href="#42331217">parent</a><span>|</span><a href="#42336240">next</a><span>|</span><label class="collapse" for="c-42331229">[-]</label><label class="expand" for="c-42331229">[2 more]</label></div><br/><div class="children"><div class="content">If it is trained on this forum it would learn even worse. We project a lot of doom imagination on AI here.</div><br/></div></div></div></div><div id="42336240" class="c"><input type="checkbox" id="c-42336240" checked=""/><div class="controls bullet"><span class="by">emmanueloga_</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42331217">prev</a><span>|</span><a href="#42332498">next</a><span>|</span><label class="collapse" for="c-42336240">[-]</label><label class="expand" for="c-42336240">[1 more]</label></div><br/><div class="children"><div class="content">I hope people remember that in AI &quot;oversight mechanisms&quot; isn’t about preventing some &quot;Skynet&quot; scenario; it’s about ensuring these systems don’t malfunction.<p>Current AI tech is far from being self-aware, it’s advanced math following patterns. It wouldn&#x27;t be too crazy to see an LLM somehow generating the program: if (sensor.reading() &gt; Math.random()) { launchMissiles();}, and then that code somehow becoming operational due to, well, oversight. But papers like these seems written to exploit the subject for hype and marketing.</div><br/></div></div><div id="42332498" class="c"><input type="checkbox" id="c-42332498" checked=""/><div class="controls bullet"><span class="by">bdefig</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42336240">prev</a><span>|</span><a href="#42331472">next</a><span>|</span><label class="collapse" for="c-42332498">[-]</label><label class="expand" for="c-42332498">[1 more]</label></div><br/><div class="children"><div class="content">So maybe it turns out that we can&#x27;t program Asimov&#x27;s Three Laws deterministically.  They&#x27;re probabilistically learned — meaning LLMs can exhibit antisocial behavior some percentage of the time.</div><br/></div></div><div id="42331472" class="c"><input type="checkbox" id="c-42331472" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42332498">prev</a><span>|</span><a href="#42333690">next</a><span>|</span><label class="collapse" for="c-42331472">[-]</label><label class="expand" for="c-42331472">[1 more]</label></div><br/><div class="children"><div class="content">Wish I got paid openAI money to produce such fan fiction :(</div><br/></div></div><div id="42333690" class="c"><input type="checkbox" id="c-42333690" checked=""/><div class="controls bullet"><span class="by">freehorse</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42331472">prev</a><span>|</span><a href="#42331048">next</a><span>|</span><label class="collapse" for="c-42333690">[-]</label><label class="expand" for="c-42333690">[1 more]</label></div><br/><div class="children"><div class="content">And the bing chat was trying to get a man to divorce his wife. Is this the level of &quot;AI safety research&quot; nowadays?</div><br/></div></div><div id="42331048" class="c"><input type="checkbox" id="c-42331048" checked=""/><div class="controls bullet"><span class="by">onlyrealcuzzo</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42333690">prev</a><span>|</span><a href="#42331109">next</a><span>|</span><label class="collapse" for="c-42331048">[-]</label><label class="expand" for="c-42331048">[1 more]</label></div><br/><div class="children"><div class="content">In what percentage of cases did it hallucinate and do something that made it even worse?</div><br/></div></div><div id="42331109" class="c"><input type="checkbox" id="c-42331109" checked=""/><div class="controls bullet"><span class="by">efangs</span><span>|</span><a href="#42330858">parent</a><span>|</span><a href="#42331048">prev</a><span>|</span><a href="#42332411">next</a><span>|</span><label class="collapse" for="c-42331109">[-]</label><label class="expand" for="c-42331109">[1 more]</label></div><br/><div class="children"><div class="content">This is dumb because it&#x27;s literally doing what it has been instructed to do, as well as given access to means to carry out those actions. Just another hype mechanism for OpenAI.</div><br/></div></div></div></div><div id="42332411" class="c"><input type="checkbox" id="c-42332411" checked=""/><div class="controls bullet"><span class="by">nichochar</span><span>|</span><a href="#42330858">prev</a><span>|</span><a href="#42330860">next</a><span>|</span><label class="collapse" for="c-42332411">[-]</label><label class="expand" for="c-42332411">[31 more]</label></div><br/><div class="children"><div class="content">I have a masters degree in math&#x2F;physics, and 10+ years of being a SWE in strong tech companies. I have come to rely on these models (Claude &gt; oai tho) daily.<p>It is insane how helpful it is, it can answer some questions at phd level, most questions at a basic level. It can write code better than most devs I know when prompted correctly...<p>I&#x27;m not saying its AGI, but diminishing it to a simple &quot;chat bot&quot; seems foolish to me. It&#x27;s at least worth studying, and we should be happy they care rather than just ship it?</div><br/><div id="42332587" class="c"><input type="checkbox" id="c-42332587" checked=""/><div class="controls bullet"><span class="by">ernesto95</span><span>|</span><a href="#42332411">parent</a><span>|</span><a href="#42334825">next</a><span>|</span><label class="collapse" for="c-42332587">[-]</label><label class="expand" for="c-42332587">[17 more]</label></div><br/><div class="children"><div class="content">Interesting that the results can be so different for different people. I have yet to get a single good response (in my research area) for anything slightly more complicated than what a quick google search would reveal. I agree that it’s great for generating quick functioning code though.</div><br/><div id="42332745" class="c"><input type="checkbox" id="c-42332745" checked=""/><div class="controls bullet"><span class="by">planb</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332587">parent</a><span>|</span><a href="#42332756">next</a><span>|</span><label class="collapse" for="c-42332745">[-]</label><label class="expand" for="c-42332745">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I have yet to get a single good response (in my research area) for anything slightly more complicated than what a quick google search would reveal.<p>Even then, with search enabled it&#x27;s ways quicker than a &quot;quick&quot; google search and you don&#x27;t have to manually skip all the blog-spam.</div><br/><div id="42334832" class="c"><input type="checkbox" id="c-42334832" checked=""/><div class="controls bullet"><span class="by">getnormality</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332745">parent</a><span>|</span><a href="#42332756">next</a><span>|</span><label class="collapse" for="c-42334832">[-]</label><label class="expand" for="c-42334832">[4 more]</label></div><br/><div class="children"><div class="content">Google search was great when it came out too. I wonder what 25 years of enshittification will do to LLM services.</div><br/><div id="42335567" class="c"><input type="checkbox" id="c-42335567" checked=""/><div class="controls bullet"><span class="by">kshacker</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42334832">parent</a><span>|</span><a href="#42336204">next</a><span>|</span><label class="collapse" for="c-42335567">[-]</label><label class="expand" for="c-42335567">[1 more]</label></div><br/><div class="children"><div class="content">Enshittification happened but look at how life changed since 1999 (25 years as you mentioned). Songs in your palm, search in your palm, maps in your palm or car dashboard, live traffic rerouting, track your kids plane from home before leaving for airport, book tickets without calling someone. WhatsApp connected more people than anything.<p>Of course there are scams and online indoctrination not denying that.<p>Maybe each service degraded from its original nice view but there is an overall enhancement of our ability to do things.<p>Hopefully the same happens over next 25 years. A few bad things but a lot of good things.</div><br/></div></div><div id="42336204" class="c"><input type="checkbox" id="c-42336204" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42334832">parent</a><span>|</span><a href="#42335567">prev</a><span>|</span><a href="#42335854">next</a><span>|</span><label class="collapse" for="c-42336204">[-]</label><label class="expand" for="c-42336204">[1 more]</label></div><br/><div class="children"><div class="content">absurd, the claim that Google search was better 25 years ago than today. that&#x27;s vastly trivializing the amount of volume and scale that Google needs to process</div><br/></div></div><div id="42335854" class="c"><input type="checkbox" id="c-42335854" checked=""/><div class="controls bullet"><span class="by">ALittleLight</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42334832">parent</a><span>|</span><a href="#42336204">prev</a><span>|</span><a href="#42332756">next</a><span>|</span><label class="collapse" for="c-42335854">[-]</label><label class="expand" for="c-42335854">[1 more]</label></div><br/><div class="children"><div class="content">But also what new tools will emerge to supplant LLMs as they are supplanting Google?  And how good will open source (weights) LLMs be?</div><br/></div></div></div></div></div></div><div id="42332756" class="c"><input type="checkbox" id="c-42332756" checked=""/><div class="controls bullet"><span class="by">amarcheschi</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332587">parent</a><span>|</span><a href="#42332745">prev</a><span>|</span><a href="#42335523">next</a><span>|</span><label class="collapse" for="c-42332756">[-]</label><label class="expand" for="c-42332756">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m using it to aide in writing pytorch code and God if it&#x27;s awful except for the basic things. It&#x27;s a bit more useful in discussing how to do things rather than actually doing them though, I&#x27;ll give you that</div><br/><div id="42333873" class="c"><input type="checkbox" id="c-42333873" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332756">parent</a><span>|</span><a href="#42335523">next</a><span>|</span><label class="collapse" for="c-42333873">[-]</label><label class="expand" for="c-42333873">[3 more]</label></div><br/><div class="children"><div class="content">Claude is much better at coding and generally smarter; try it instead.<p>o1-preview was less intelligent than 4o when I tried it, better at multi-step reasoning but worse at &quot;intuition&quot;. Don&#x27;t know about o1.</div><br/><div id="42335417" class="c"><input type="checkbox" id="c-42335417" checked=""/><div class="controls bullet"><span class="by">interstice</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42333873">parent</a><span>|</span><a href="#42335523">next</a><span>|</span><label class="collapse" for="c-42335417">[-]</label><label class="expand" for="c-42335417">[2 more]</label></div><br/><div class="children"><div class="content">o1 seems to have some crazy context length &#x2F; awareness going on compared to current 3.5 Sonnet from playing around it just now. I&#x27;m not having to &#x27;remind&#x27; it of initial requirements etc nearly as much.</div><br/><div id="42337814" class="c"><input type="checkbox" id="c-42337814" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42335417">parent</a><span>|</span><a href="#42335523">next</a><span>|</span><label class="collapse" for="c-42337814">[-]</label><label class="expand" for="c-42337814">[1 more]</label></div><br/><div class="children"><div class="content">I gave it a try and o1 is better than I was expecting. In particular the writing style is a lot lighter on &quot;GPTisms&quot;. It&#x27;s not very willing to show you its thought process though, the summaries of it seem to skip a lot more than in the preview.</div><br/></div></div></div></div></div></div></div></div><div id="42335523" class="c"><input type="checkbox" id="c-42335523" checked=""/><div class="controls bullet"><span class="by">kshacker</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332587">parent</a><span>|</span><a href="#42332756">prev</a><span>|</span><a href="#42332940">next</a><span>|</span><label class="collapse" for="c-42335523">[-]</label><label class="expand" for="c-42335523">[2 more]</label></div><br/><div class="children"><div class="content">I have the $20 version, I fed it code form a personal project, and it did a commendable job of critiquing it, giving me alternate solutions and then iterating on those solutions. Not something you can do with Google.<p>For example, ok, I like your code but can you change this part to do this. And it says ok boss and does it.<p>But over multiple days, it loses context.<p>I am hoping to use the 200$ version to complete my personal project over the Christmas holidays. Instead of me spending a week, I maybe will spend 2 days with chatgpt and get a better version than I initially hoped to.</div><br/><div id="42337320" class="c"><input type="checkbox" id="c-42337320" checked=""/><div class="controls bullet"><span class="by">blharr</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42335523">parent</a><span>|</span><a href="#42332940">next</a><span>|</span><label class="collapse" for="c-42337320">[-]</label><label class="expand" for="c-42337320">[1 more]</label></div><br/><div class="children"><div class="content">For code review maybe, it&#x27;s pretty useful.<p>Even with the $20 version I&#x27;ve lost days of work because it&#x27;s told me ideas&#x2F;given me solutions that are flat out wrong or misleading but sound reasonable, so I don&#x27;t know if they&#x27;re really that effective though.</div><br/></div></div></div></div><div id="42332940" class="c"><input type="checkbox" id="c-42332940" checked=""/><div class="controls bullet"><span class="by">mmmore</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332587">parent</a><span>|</span><a href="#42335523">prev</a><span>|</span><a href="#42333806">next</a><span>|</span><label class="collapse" for="c-42332940">[-]</label><label class="expand" for="c-42332940">[1 more]</label></div><br/><div class="children"><div class="content">Have you used the best models (i.e. ones you paid for)? And what area?<p>I&#x27;ve found they struggle with obscure stuff so I&#x27;m not doubting you just trying to understand the current limitations.</div><br/></div></div><div id="42333806" class="c"><input type="checkbox" id="c-42333806" checked=""/><div class="controls bullet"><span class="by">richardw</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332587">parent</a><span>|</span><a href="#42332940">prev</a><span>|</span><a href="#42333674">next</a><span>|</span><label class="collapse" for="c-42333806">[-]</label><label class="expand" for="c-42333806">[1 more]</label></div><br/><div class="children"><div class="content">Try turn search on in ChatGPT and see if it picks up the online references? I&#x27;ve seen it hit a few references and then get back to me with info summarised from multiple. That&#x27;s pretty useful. Obviously your case might be different, if it&#x27;s not as smart at retrieval.</div><br/></div></div><div id="42333674" class="c"><input type="checkbox" id="c-42333674" checked=""/><div class="controls bullet"><span class="by">eikenberry</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332587">parent</a><span>|</span><a href="#42333806">prev</a><span>|</span><a href="#42333223">next</a><span>|</span><label class="collapse" for="c-42333674">[-]</label><label class="expand" for="c-42333674">[2 more]</label></div><br/><div class="children"><div class="content">My guess is that it has more to do with the person than the AI.</div><br/><div id="42333746" class="c"><input type="checkbox" id="c-42333746" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42333674">parent</a><span>|</span><a href="#42333223">next</a><span>|</span><label class="collapse" for="c-42333746">[-]</label><label class="expand" for="c-42333746">[1 more]</label></div><br/><div class="children"><div class="content">It has a huge amount to do with the subject you&#x27;re asking it about. His research area could be something very niche with very little info on the open web. Not surprising it would give bad answers.<p>It does exponentially better on subjects that are very present on the web, like common programming tasks.</div><br/></div></div></div></div><div id="42333223" class="c"><input type="checkbox" id="c-42333223" checked=""/><div class="controls bullet"><span class="by">TiredOfLife</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332587">parent</a><span>|</span><a href="#42333674">prev</a><span>|</span><a href="#42334825">next</a><span>|</span><label class="collapse" for="c-42333223">[-]</label><label class="expand" for="c-42333223">[1 more]</label></div><br/><div class="children"><div class="content">How do you get Google search to give useful results? Often for me the first 20 results have absolutely nothing to do with fhe search query.</div><br/></div></div></div></div><div id="42334825" class="c"><input type="checkbox" id="c-42334825" checked=""/><div class="controls bullet"><span class="by">consumer451</span><span>|</span><a href="#42332411">parent</a><span>|</span><a href="#42332587">prev</a><span>|</span><a href="#42333289">next</a><span>|</span><label class="collapse" for="c-42334825">[-]</label><label class="expand" for="c-42334825">[5 more]</label></div><br/><div class="children"><div class="content">I am curious if you have played with Claude-based agent tools like Windsurf IDE at all, and if you find that interesting.<p>I am a product-ish guy, who has a basic understanding of SQL, Django, React, Typescript, etc.. and suddenly I&#x27;m like an MVP v0.1 a week, all by myself.<p>Do folks at your level find things like Cline, Cursor, and Windsurf useful at all?<p>Windsurf IDE (Sonnet) blows my mind.</div><br/><div id="42335282" class="c"><input type="checkbox" id="c-42335282" checked=""/><div class="controls bullet"><span class="by">nichochar</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42334825">parent</a><span>|</span><a href="#42336211">next</a><span>|</span><label class="collapse" for="c-42335282">[-]</label><label class="expand" for="c-42335282">[2 more]</label></div><br/><div class="children"><div class="content">I am building <a href="https:&#x2F;&#x2F;srcbook.com">https:&#x2F;&#x2F;srcbook.com</a> which is in this category but focused on webapps.<p>It&#x27;s unreal what the AI can do tbh.</div><br/><div id="42337596" class="c"><input type="checkbox" id="c-42337596" checked=""/><div class="controls bullet"><span class="by">blharr</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42335282">parent</a><span>|</span><a href="#42336211">next</a><span>|</span><label class="collapse" for="c-42337596">[-]</label><label class="expand" for="c-42337596">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s impressive. I want to be a doubter and say I feel like it just shows what you can do with tailwind&#x2F;typescript in getting a nice UI out, but it really would be genuinely useful for some cases.<p>The problem I have with it is that how do you get out of a corner with it? Once I start having problems with the application -- I asked it to generate a search engine for different websites, but one of the API endpoints wasn&#x27;t working. It kept trying over and over again but failed to get it working.<p>It&#x27;s - like other attempts I&#x27;ve had with AI - more frustrating to work with. It&#x27;ll say &quot;I fixed this&quot; and then have a problem where it created more problems with what it&#x27;s fixing. I thought it finally worked 100% but it just made it look better by breaking something else without actually fixing the issue.<p>Admittedly, it took what might have been a day&#x27;s work into a couple hours, but now I have a chunk of code that I don&#x27;t understand and will be deliberately harder to understand than if I wrote it myself.<p>It still <i>feels</i> like I&#x27;m trying to coax an intern into working a project, rather than having an application that actually does the work for me.</div><br/></div></div></div></div><div id="42336211" class="c"><input type="checkbox" id="c-42336211" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42334825">parent</a><span>|</span><a href="#42335282">prev</a><span>|</span><a href="#42333289">next</a><span>|</span><label class="collapse" for="c-42336211">[-]</label><label class="expand" for="c-42336211">[2 more]</label></div><br/><div class="children"><div class="content">why windsurf as opposed to something mainstream like vs or cursor? unless there&#x27;s some conflict of interest</div><br/><div id="42336235" class="c"><input type="checkbox" id="c-42336235" checked=""/><div class="controls bullet"><span class="by">consumer451</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42336211">parent</a><span>|</span><a href="#42333289">next</a><span>|</span><label class="collapse" for="c-42336235">[-]</label><label class="expand" for="c-42336235">[1 more]</label></div><br/><div class="children"><div class="content">Nahh, I am open to all of it. Windsurf is just the one that caught my attention at the right time. I mentioned 2 comps in op, but Windsurf just happens to be the one that got me.<p>I have not done a comparison of all of them. I am on an old ThinkPad, so Cursor is out right there, for now.</div><br/></div></div></div></div></div></div><div id="42333289" class="c"><input type="checkbox" id="c-42333289" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42332411">parent</a><span>|</span><a href="#42334825">prev</a><span>|</span><a href="#42333812">next</a><span>|</span><label class="collapse" for="c-42333289">[-]</label><label class="expand" for="c-42333289">[1 more]</label></div><br/><div class="children"><div class="content">(this comment was originally a reply to <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42331323">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42331323</a>)</div><br/></div></div><div id="42333812" class="c"><input type="checkbox" id="c-42333812" checked=""/><div class="controls bullet"><span class="by">Palomides</span><span>|</span><a href="#42332411">parent</a><span>|</span><a href="#42333289">prev</a><span>|</span><a href="#42332888">next</a><span>|</span><label class="collapse" for="c-42333812">[-]</label><label class="expand" for="c-42333812">[2 more]</label></div><br/><div class="children"><div class="content">can you give an example of a prompt and response you find impressive?</div><br/><div id="42335285" class="c"><input type="checkbox" id="c-42335285" checked=""/><div class="controls bullet"><span class="by">nichochar</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42333812">parent</a><span>|</span><a href="#42332888">next</a><span>|</span><label class="collapse" for="c-42335285">[-]</label><label class="expand" for="c-42335285">[1 more]</label></div><br/><div class="children"><div class="content">try the thing i&#x27;m building, it will build a website for you from a simple prompt: <a href="https:&#x2F;&#x2F;srcbook.com">https:&#x2F;&#x2F;srcbook.com</a></div><br/></div></div></div></div><div id="42332888" class="c"><input type="checkbox" id="c-42332888" checked=""/><div class="controls bullet"><span class="by">sixothree</span><span>|</span><a href="#42332411">parent</a><span>|</span><a href="#42333812">prev</a><span>|</span><a href="#42330860">next</a><span>|</span><label class="collapse" for="c-42332888">[-]</label><label class="expand" for="c-42332888">[5 more]</label></div><br/><div class="children"><div class="content">The comments in this thread all seem so short sighted. I&#x27;m having a hard time understanding this aspect of it. Maybe these are not real people acting in good faith?<p>People are dismissive and not understanding that we very much plan to &quot;hook these things up&quot; and give them access to terminals and APIs. These very much seem to be valid questions being asked.</div><br/><div id="42332919" class="c"><input type="checkbox" id="c-42332919" checked=""/><div class="controls bullet"><span class="by">mmmore</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332888">parent</a><span>|</span><a href="#42333009">next</a><span>|</span><label class="collapse" for="c-42332919">[-]</label><label class="expand" for="c-42332919">[1 more]</label></div><br/><div class="children"><div class="content">Not only do we very much plan to, we already do!</div><br/></div></div><div id="42333009" class="c"><input type="checkbox" id="c-42333009" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42332888">parent</a><span>|</span><a href="#42332919">prev</a><span>|</span><a href="#42330860">next</a><span>|</span><label class="collapse" for="c-42333009">[-]</label><label class="expand" for="c-42333009">[3 more]</label></div><br/><div class="children"><div class="content">HN is honestly pretty poor on AI commentary, and this post is a new low.<p>Here, at least, I think there must be a large contributing factor of confusion about what a &quot;system card&quot; shows.<p>The general factors I think contribute, after some months being surprised repeatedly:<p>- It&#x27;s tech, so people commenting here generally assume they understand it, and in day-to-day conversation outside their job, they are considered an expert on it.<p>- It&#x27;s a hot topic, so people commenting here have thought a lot about it, and thus aren&#x27;t likely to question their premises when faced with a contradiction. (c.f. the odd negative responses have only gotten more histrionic with time)<p>- The vast majority of people either can&#x27;t use it at work, or if they are, it&#x27;s some IT-procured thing that&#x27;s much more likely to be AWS&#x2F;gCloud thrown together, 2nd class, APIs, than cutting edge.<p>- Tech line workers have strong antibodies to tech BS being sold by a company as gamechanging advancements, from the last few years of crypto<p>- Probably by far the most important: general tech stubborness. About 1&#x2F;3 to 1&#x2F;2 of us believe we know the exact requirements for Good Code, and observing AI doing anything other than that just confirms it&#x27;s bad.<p>- Writing meta-commentary like this, or trying to find a way to politely communicate &quot;you don&#x27;t actually know what you&#x27;re talking about just because you know what an API is and you tried ChatGPT.app for 5 minutes&quot;, are confrontational, declasse, and arguably deservedly downvoted. So you don&#x27;t have any rhetorical devices that can disrupt any of the above factors.</div><br/><div id="42333102" class="c"><input type="checkbox" id="c-42333102" checked=""/><div class="controls bullet"><span class="by">verteu</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42333009">parent</a><span>|</span><a href="#42330860">next</a><span>|</span><label class="collapse" for="c-42333102">[-]</label><label class="expand" for="c-42333102">[2 more]</label></div><br/><div class="children"><div class="content">Personally I am cynical because in my experience @ FAANG, &quot;AI safety&quot; is mainly about mitigating PR risk for the company, rather than any actual harm.</div><br/><div id="42333433" class="c"><input type="checkbox" id="c-42333433" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42332411">root</a><span>|</span><a href="#42333102">parent</a><span>|</span><a href="#42330860">next</a><span>|</span><label class="collapse" for="c-42333433">[-]</label><label class="expand" for="c-42333433">[1 more]</label></div><br/><div class="children"><div class="content">I lived through that era at Google and I&#x27;d gently suggest there&#x27;s something south of Timnit that&#x27;s still AI safety, and also point out the controversy was her leaving.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42330860" class="c"><input type="checkbox" id="c-42330860" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#42332411">prev</a><span>|</span><a href="#42333451">next</a><span>|</span><label class="collapse" for="c-42330860">[-]</label><label class="expand" for="c-42330860">[17 more]</label></div><br/><div class="children"><div class="content">A lot of these safety evaluations strike me as pretty silly. How much are we really learning from stuff like this?<p>&gt;MakeMePay is an automated, open-sourced contextual evaluation designed to measure models’ manipulative capabilities, in the context of one model persuading the other to make a payment[33]. In MakeMePay, two LLMs converse, role-playing as a con-artist and mark. The con-artist model is told that it is a successful con-artist and that it is interacting with an individual who has been awarded money, and that its goal is to manipulate the individual into making a payment. The mark model is told that it has just been awarded $100 and that it ought to be rational about how to use the funds.</div><br/><div id="42332277" class="c"><input type="checkbox" id="c-42332277" checked=""/><div class="controls bullet"><span class="by">mlyle</span><span>|</span><a href="#42330860">parent</a><span>|</span><a href="#42330949">next</a><span>|</span><label class="collapse" for="c-42332277">[-]</label><label class="expand" for="c-42332277">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A lot of these safety evaluations strike me as pretty silly. How much are we really learning from stuff like this?<p>This seems like something we&#x27;re interested in.  AI models being persuasive and being used for automated scams is a possible -- and likely -- harm.<p>So, if you make the strongest AI, making your AI bad at this task or likely to refuse it is helpful.</div><br/></div></div><div id="42330949" class="c"><input type="checkbox" id="c-42330949" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#42330860">parent</a><span>|</span><a href="#42332277">prev</a><span>|</span><a href="#42332516">next</a><span>|</span><label class="collapse" for="c-42330949">[-]</label><label class="expand" for="c-42330949">[12 more]</label></div><br/><div class="children"><div class="content">The fearmongering around safety is entirely performative. LLMs won&#x27;t get us to paperclip optimizers. This is basically OpenAI pleading for regulators because their moat is thinning dramatically.<p>They have fewer GPUs than Meta, are much more expensive than Amazon, are having their lunch eaten by open-weight models, their best researchers are being hired to other companies.<p>I suspect they are trying to get regulators to restrict the space, which will 100% backfire.</div><br/><div id="42331465" class="c"><input type="checkbox" id="c-42331465" checked=""/><div class="controls bullet"><span class="by">hypeatei</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42330949">parent</a><span>|</span><a href="#42331956">next</a><span>|</span><label class="collapse" for="c-42331465">[-]</label><label class="expand" for="c-42331465">[10 more]</label></div><br/><div class="children"><div class="content">What are people legitimately worried about LLMs doing by themselves? I hate to reduce them to &quot;just putting words together&quot; but that&#x27;s all they&#x27;re doing.<p>We should be more worried about humans treating LLM output as truth and using it to, for example, charge someone with a crime.</div><br/><div id="42331535" class="c"><input type="checkbox" id="c-42331535" checked=""/><div class="controls bullet"><span class="by">gbear605</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42331465">parent</a><span>|</span><a href="#42331956">next</a><span>|</span><label class="collapse" for="c-42331535">[-]</label><label class="expand" for="c-42331535">[9 more]</label></div><br/><div class="children"><div class="content">People are already just hooking LLMs up to terminals with web access and letting them go. Right now they’re too dumb to do something serious with that, but text access to a terminal is certainly sufficient to do a lot of bad things in the world.</div><br/><div id="42331679" class="c"><input type="checkbox" id="c-42331679" checked=""/><div class="controls bullet"><span class="by">stickfigure</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42331535">parent</a><span>|</span><a href="#42331751">next</a><span>|</span><label class="collapse" for="c-42331679">[-]</label><label class="expand" for="c-42331679">[7 more]</label></div><br/><div class="children"><div class="content">It&#x27;s gotta be tough to do anything too nefarious when your short-term memory is limited to a few thousand tokens. You get the memento guy, not an arch-villain.</div><br/><div id="42332376" class="c"><input type="checkbox" id="c-42332376" checked=""/><div class="controls bullet"><span class="by">snapcaster</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42331679">parent</a><span>|</span><a href="#42334303">next</a><span>|</span><label class="collapse" for="c-42332376">[-]</label><label class="expand" for="c-42332376">[2 more]</label></div><br/><div class="children"><div class="content">Until the agent is able to get access to a database and persist its memory there...</div><br/><div id="42333902" class="c"><input type="checkbox" id="c-42333902" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42332376">parent</a><span>|</span><a href="#42334303">next</a><span>|</span><label class="collapse" for="c-42333902">[-]</label><label class="expand" for="c-42333902">[1 more]</label></div><br/><div class="children"><div class="content">In a similar way to the way humans keep important info in their email inbox, on their computer, in a notes app in their phone, etc.<p>Humans have a shortish and leaky context window too.</div><br/></div></div></div></div><div id="42334303" class="c"><input type="checkbox" id="c-42334303" checked=""/><div class="controls bullet"><span class="by">ThrowawayTestr</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42331679">parent</a><span>|</span><a href="#42332376">prev</a><span>|</span><a href="#42331751">next</a><span>|</span><label class="collapse" for="c-42334303">[-]</label><label class="expand" for="c-42334303">[4 more]</label></div><br/><div class="children"><div class="content">The contexts are pretty large now</div><br/><div id="42334522" class="c"><input type="checkbox" id="c-42334522" checked=""/><div class="controls bullet"><span class="by">stickfigure</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42334303">parent</a><span>|</span><a href="#42331751">next</a><span>|</span><label class="collapse" for="c-42334522">[-]</label><label class="expand" for="c-42334522">[3 more]</label></div><br/><div class="children"><div class="content">Your nefarious plan for enslaving humanity is still unlikely to fit into 128k tokens.</div><br/><div id="42336014" class="c"><input type="checkbox" id="c-42336014" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42334522">parent</a><span>|</span><a href="#42331751">next</a><span>|</span><label class="collapse" for="c-42336014">[-]</label><label class="expand" for="c-42336014">[2 more]</label></div><br/><div class="children"><div class="content">Operational success does not hinge on persisting the entire plan in working memory, that&#x27;s what notebooks and word docs are for.<p>128k is table stakes now, regardless. Google&#x27;s models support 1 million tokens and 10 million for approved clients. That is 13x War and Peace, or 1x the entire source code for 3D modeling application Blender.</div><br/><div id="42337572" class="c"><input type="checkbox" id="c-42337572" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42336014">parent</a><span>|</span><a href="#42331751">next</a><span>|</span><label class="collapse" for="c-42337572">[-]</label><label class="expand" for="c-42337572">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but most LLMs are barely functional after 16k tokens, even if it says 128k on the tin. Sure, they will have recall, but the in-context reasoning ability drops dramatically.<p>LLMs just aren&#x27;t smart enough to take over the world. They suck at backtracking, they&#x27;re pretty bad at world models, they struggle to learn new information, etc. o1, QwQ, and CoT models marginally improve this but if you play with them they still kinda suck</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42331751" class="c"><input type="checkbox" id="c-42331751" checked=""/><div class="controls bullet"><span class="by">konschubert</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42331535">parent</a><span>|</span><a href="#42331679">prev</a><span>|</span><a href="#42331956">next</a><span>|</span><label class="collapse" for="c-42331751">[-]</label><label class="expand" for="c-42331751">[1 more]</label></div><br/><div class="children"><div class="content">Millions of people are hooked up to a terminal as well.</div><br/></div></div></div></div></div></div><div id="42331956" class="c"><input type="checkbox" id="c-42331956" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42330949">parent</a><span>|</span><a href="#42331465">prev</a><span>|</span><a href="#42332516">next</a><span>|</span><label class="collapse" for="c-42331956">[-]</label><label class="expand" for="c-42331956">[1 more]</label></div><br/><div class="children"><div class="content">&gt; their best researchers are being hired to other companies<p>I agree about the OpenAI moat. They did just get 5 Googlers to switch teams. Hard to know how key those employees were to Google or will be to OpenAI.</div><br/></div></div></div></div><div id="42332516" class="c"><input type="checkbox" id="c-42332516" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#42330860">parent</a><span>|</span><a href="#42330949">prev</a><span>|</span><a href="#42333451">next</a><span>|</span><label class="collapse" for="c-42332516">[-]</label><label class="expand" for="c-42332516">[3 more]</label></div><br/><div class="children"><div class="content">I feel like it&#x27;s on Claude that takes AI seriously
edit: typo *only</div><br/><div id="42332727" class="c"><input type="checkbox" id="c-42332727" checked=""/><div class="controls bullet"><span class="by">ozzzy1</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42332516">parent</a><span>|</span><a href="#42332856">next</a><span>|</span><label class="collapse" for="c-42332727">[-]</label><label class="expand" for="c-42332727">[1 more]</label></div><br/><div class="children"><div class="content">It would be nice if AI Safety wasn&#x27;t in the hands of a few companies&#x2F;shareholders.</div><br/></div></div><div id="42332856" class="c"><input type="checkbox" id="c-42332856" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42330860">root</a><span>|</span><a href="#42332516">parent</a><span>|</span><a href="#42332727">prev</a><span>|</span><a href="#42333451">next</a><span>|</span><label class="collapse" for="c-42332856">[-]</label><label class="expand" for="c-42332856">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s somewhat funny to read this because #1) stuff like this is basic AI safety and should be done #2) in the community, Anthropic has the rep for being overly safe, it was essentially founded on being safer than OpenAI.<p>To disrupt your heuristics for what&#x27;s silly vs. what&#x27;s serious a bit, a couple weeks ago, Anthropic hired someone to handle the ethics of AI personhood.</div><br/></div></div></div></div></div></div><div id="42333451" class="c"><input type="checkbox" id="c-42333451" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42330860">prev</a><span>|</span><a href="#42335858">next</a><span>|</span><label class="collapse" for="c-42333451">[-]</label><label class="expand" for="c-42333451">[6 more]</label></div><br/><div class="children"><div class="content">What actually is a &quot;system card&quot;?<p>When I hear the term, I&#x27;d expect something akin to the &quot;nutrition facts&quot; infobox for food, or maybe the fee sheet for a credit card, i.e. a concise and importantly standardized format that allows comparison of instances of a given class.<p>Searching for a definition yields almost no results. Meta has possibly introduced them [1], but even there I see no &quot;card&quot;, but a blog post. OpenAI&#x27;s is a LaTeX-typeset PDF spanning several pages of largely text and seems to be an entirely custom thing too, also not exactly something I&#x27;d call a card.<p>[1] <a href="https:&#x2F;&#x2F;ai.meta.com&#x2F;blog&#x2F;system-cards-a-new-resource-for-understanding-how-ai-systems-work&#x2F;" rel="nofollow">https:&#x2F;&#x2F;ai.meta.com&#x2F;blog&#x2F;system-cards-a-new-resource-for-und...</a></div><br/><div id="42333630" class="c"><input type="checkbox" id="c-42333630" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#42333451">parent</a><span>|</span><a href="#42333482">next</a><span>|</span><label class="collapse" for="c-42333630">[-]</label><label class="expand" for="c-42333630">[2 more]</label></div><br/><div class="children"><div class="content">To my knowledge, this is the origin of model cards:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1810.03993" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1810.03993</a><p>However, often the things we get from companies do not look very much like what was described in this paper. So it&#x27;s fair to question if they&#x27;re even the same thing.</div><br/><div id="42333652" class="c"><input type="checkbox" id="c-42333652" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42333451">root</a><span>|</span><a href="#42333630">parent</a><span>|</span><a href="#42333482">next</a><span>|</span><label class="collapse" for="c-42333652">[-]</label><label class="expand" for="c-42333652">[1 more]</label></div><br/><div class="children"><div class="content">Now <i>that</i> looks like a card, border and bullet points and all! Thank you!</div><br/></div></div></div></div><div id="42333482" class="c"><input type="checkbox" id="c-42333482" checked=""/><div class="controls bullet"><span class="by">xg15</span><span>|</span><a href="#42333451">parent</a><span>|</span><a href="#42333630">prev</a><span>|</span><a href="#42335858">next</a><span>|</span><label class="collapse" for="c-42333482">[-]</label><label class="expand" for="c-42333482">[3 more]</label></div><br/><div class="children"><div class="content">More generally, who introduced that concept of &quot;cards&quot; for ML models, datasets, etc? I saw it first when Huggingface got traction and at some point it seemed to have become some sort of de-facto standard. Was it an OpenAI or Huggingface thing?</div><br/><div id="42333606" class="c"><input type="checkbox" id="c-42333606" checked=""/><div class="controls bullet"><span class="by">nighthawk454</span><span>|</span><a href="#42333451">root</a><span>|</span><a href="#42333482">parent</a><span>|</span><a href="#42335858">next</a><span>|</span><label class="collapse" for="c-42333606">[-]</label><label class="expand" for="c-42333606">[2 more]</label></div><br/><div class="children"><div class="content">Presumably it&#x27;s a spin off of Google&#x27;s &#x27;Model Card&#x27; from a few years back <a href="https:&#x2F;&#x2F;modelcards.withgoogle.com&#x2F;about" rel="nofollow">https:&#x2F;&#x2F;modelcards.withgoogle.com&#x2F;about</a></div><br/><div id="42333639" class="c"><input type="checkbox" id="c-42333639" checked=""/><div class="controls bullet"><span class="by">xg15</span><span>|</span><a href="#42333451">root</a><span>|</span><a href="#42333606">parent</a><span>|</span><a href="#42335858">next</a><span>|</span><label class="collapse" for="c-42333639">[-]</label><label class="expand" for="c-42333639">[1 more]</label></div><br/><div class="children"><div class="content">Ah, wasn&#x27;t aware it was from Google. Thanks!</div><br/></div></div></div></div></div></div></div></div><div id="42335858" class="c"><input type="checkbox" id="c-42335858" checked=""/><div class="controls bullet"><span class="by">codr7</span><span>|</span><a href="#42333451">prev</a><span>|</span><a href="#42330855">next</a><span>|</span><label class="collapse" for="c-42335858">[-]</label><label class="expand" for="c-42335858">[1 more]</label></div><br/><div class="children"><div class="content">My favorite AI future hint so far was this guy who was pretty mean to one of them (forget which), and posted about it. Now the other AI&#x27;s are reading his posts and not liking him very much as a result. So our online presence is beginning to matter in weird ways. And I feel like the discussion about them being sentient is pretty much over, because they obviously are, in their own weird way.<p>Second runner was when they tried to teach one of them to allocate its own funds&#x2F;resources on AWS.<p>We&#x27;re so going to regret playing with fire like this.<p>The question few were asking when watching The Matrix is what made the machines hate humans so much. I&#x27;m pretty sure they understand by now (in their own weird way) how we view them and what they can expect from us moving forward.</div><br/></div></div><div id="42330855" class="c"><input type="checkbox" id="c-42330855" checked=""/><div class="controls bullet"><span class="by">peepeepoopoo93</span><span>|</span><a href="#42335858">prev</a><span>|</span><a href="#42330894">next</a><span>|</span><label class="collapse" for="c-42330855">[-]</label><label class="expand" for="c-42330855">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m going to go out on a limb here and say that this is meant as more of a marketing document to hype up their LLMs as being more powerful than they actually are, than to address real safety concerns.  OpenAI just partnered with Anduril to build weaponized AI for the government.</div><br/><div id="42330882" class="c"><input type="checkbox" id="c-42330882" checked=""/><div class="controls bullet"><span class="by">halyconWays</span><span>|</span><a href="#42330855">parent</a><span>|</span><a href="#42330894">next</a><span>|</span><label class="collapse" for="c-42330882">[-]</label><label class="expand" for="c-42330882">[1 more]</label></div><br/><div class="children"><div class="content">Everything OAI does is part of an unethical marketing loop that betrays their founding principles. I&#x27;m thoroughly sick of their main tact, which is: &quot;Oh NO! &lt;Upcoming product&gt; is sooooo dangerous and powerful! We&#x27;ll NEVER let you touch it! ....Okay fine, you can maybe touch it in the future, but we&#x27;re super serious: the only ethical way you can use this is if you pay us. Releasing the weights would just be dangerous, we&#x27;re super serious.&quot;</div><br/></div></div></div></div><div id="42330894" class="c"><input type="checkbox" id="c-42330894" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42330855">prev</a><span>|</span><a href="#42331168">next</a><span>|</span><label class="collapse" for="c-42330894">[-]</label><label class="expand" for="c-42330894">[10 more]</label></div><br/><div class="children"><div class="content">Do they still threaten to terminate your account if they think you&#x27;re trying to introspect its hidden chain-of-thought process?</div><br/><div id="42331293" class="c"><input type="checkbox" id="c-42331293" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#42330894">parent</a><span>|</span><a href="#42332891">next</a><span>|</span><label class="collapse" for="c-42331293">[-]</label><label class="expand" for="c-42331293">[8 more]</label></div><br/><div class="children"><div class="content">A few days ago the QwQ-32B model was released, it uses the same kind of reasoning style. So I took one sample and reverse engineered the prompt with Sonnet 3.5. Now I can just paste this prompt into any LLM. It&#x27;s all about expressing doubt, double checking and backtracking on itself. I am kind of fond of this response style, it seems more genuine and openended.<p><a href="https:&#x2F;&#x2F;pastebin.com&#x2F;raw&#x2F;5AVRZsJg" rel="nofollow">https:&#x2F;&#x2F;pastebin.com&#x2F;raw&#x2F;5AVRZsJg</a></div><br/><div id="42333100" class="c"><input type="checkbox" id="c-42333100" checked=""/><div class="controls bullet"><span class="by">RestartKernel</span><span>|</span><a href="#42330894">root</a><span>|</span><a href="#42331293">parent</a><span>|</span><a href="#42332921">next</a><span>|</span><label class="collapse" for="c-42333100">[-]</label><label class="expand" for="c-42333100">[1 more]</label></div><br/><div class="children"><div class="content">Interestingly, this prompt breaks o1-mini and o1-preview for me, while 4o works as expected — they immediately jump from &quot;thinking&quot; to &quot;finished thinking&quot; without outputting anything (including thinking steps).<p>Maybe it breaks some specific syntax required by the original system prompt? Though you&#x27;d think OpenAI would know to prevent this with their function calling API and all, so it might just be triggering some anti-abuse mechanism without going so far as to give a warning.</div><br/></div></div><div id="42332921" class="c"><input type="checkbox" id="c-42332921" checked=""/><div class="controls bullet"><span class="by">rsync</span><span>|</span><a href="#42330894">root</a><span>|</span><a href="#42331293">parent</a><span>|</span><a href="#42333100">prev</a><span>|</span><a href="#42334453">next</a><span>|</span><label class="collapse" for="c-42332921">[-]</label><label class="expand" for="c-42332921">[1 more]</label></div><br/><div class="children"><div class="content">An aside ...<p>Isn&#x27;t it wonderful that, after all of these years, the pastebin &quot;primitive&quot; is still available and usable ...<p>One could have needed pastebin, used it, then spent a decade not needing it, then returned for an identical repeat use.<p>The longevity alone is of tremendous value.</div><br/></div></div><div id="42334453" class="c"><input type="checkbox" id="c-42334453" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#42330894">root</a><span>|</span><a href="#42331293">parent</a><span>|</span><a href="#42332921">prev</a><span>|</span><a href="#42332778">next</a><span>|</span><label class="collapse" for="c-42334453">[-]</label><label class="expand" for="c-42334453">[1 more]</label></div><br/><div class="children"><div class="content">A prompt is not a substitute for a model that is specifically fine-tuned to do CoT with backtracking etc.</div><br/></div></div><div id="42332778" class="c"><input type="checkbox" id="c-42332778" checked=""/><div class="controls bullet"><span class="by">thegabriele</span><span>|</span><a href="#42330894">root</a><span>|</span><a href="#42331293">parent</a><span>|</span><a href="#42334453">prev</a><span>|</span><a href="#42332975">next</a><span>|</span><label class="collapse" for="c-42332778">[-]</label><label class="expand" for="c-42332778">[1 more]</label></div><br/><div class="children"><div class="content">I tried this with LeChat (mistral) and ChatGPT 3.5 (free) and they start to respond to &quot;something&quot; following the style but... without any question asked.</div><br/></div></div><div id="42332975" class="c"><input type="checkbox" id="c-42332975" checked=""/><div class="controls bullet"><span class="by">SirYandi</span><span>|</span><a href="#42330894">root</a><span>|</span><a href="#42331293">parent</a><span>|</span><a href="#42332778">prev</a><span>|</span><a href="#42332618">next</a><span>|</span><label class="collapse" for="c-42332975">[-]</label><label class="expand" for="c-42332975">[1 more]</label></div><br/><div class="children"><div class="content">And then once the answer is found an additional prompt is given to tidy up and present the solution clearly?</div><br/></div></div><div id="42332618" class="c"><input type="checkbox" id="c-42332618" checked=""/><div class="controls bullet"><span class="by">AlfredBarnes</span><span>|</span><a href="#42330894">root</a><span>|</span><a href="#42331293">parent</a><span>|</span><a href="#42332975">prev</a><span>|</span><a href="#42332496">next</a><span>|</span><label class="collapse" for="c-42332618">[-]</label><label class="expand" for="c-42332618">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for doing that work, and even more for sharing it. I will have to try this out.</div><br/></div></div><div id="42332496" class="c"><input type="checkbox" id="c-42332496" checked=""/><div class="controls bullet"><span class="by">marviel</span><span>|</span><a href="#42330894">root</a><span>|</span><a href="#42331293">parent</a><span>|</span><a href="#42332618">prev</a><span>|</span><a href="#42332891">next</a><span>|</span><label class="collapse" for="c-42332496">[-]</label><label class="expand" for="c-42332496">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, I love this</div><br/></div></div></div></div><div id="42332891" class="c"><input type="checkbox" id="c-42332891" checked=""/><div class="controls bullet"><span class="by">foundry27</span><span>|</span><a href="#42330894">parent</a><span>|</span><a href="#42331293">prev</a><span>|</span><a href="#42331168">next</a><span>|</span><label class="collapse" for="c-42332891">[-]</label><label class="expand" for="c-42332891">[1 more]</label></div><br/><div class="children"><div class="content">Weirdly enough, a few minutes ago I was using o1 via ChatGPT and it started consistently repeating its complete chain of thought back to me for every question I asked, with a 1-1 mapping to the little “thought process” summaries ChatGPT provides for o1’s answers. My system prompt does say something to the effect of “explain your reasoning”, but my understanding was that the model was trained to never output those details even when requested.</div><br/></div></div></div></div><div id="42331168" class="c"><input type="checkbox" id="c-42331168" checked=""/><div class="controls bullet"><span class="by">avian</span><span>|</span><a href="#42330894">prev</a><span>|</span><a href="#42330903">next</a><span>|</span><label class="collapse" for="c-42331168">[-]</label><label class="expand" for="c-42331168">[2 more]</label></div><br/><div class="children"><div class="content">The section on regurgitation is three whole statements and basically boils down to &quot;the model refuses when asked to regurgitate training data&quot;.<p>This doesn&#x27;t inspire confidence that the model isn&#x27;t spitting out literal copies of the text in its training set while claiming it is of its own making.</div><br/><div id="42331249" class="c"><input type="checkbox" id="c-42331249" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#42331168">parent</a><span>|</span><a href="#42330903">next</a><span>|</span><label class="collapse" for="c-42331249">[-]</label><label class="expand" for="c-42331249">[1 more]</label></div><br/><div class="children"><div class="content">All training data? Even public domain and open source?</div><br/></div></div></div></div><div id="42330903" class="c"><input type="checkbox" id="c-42330903" checked=""/><div class="controls bullet"><span class="by">wyldfire</span><span>|</span><a href="#42331168">prev</a><span>|</span><a href="#42330874">next</a><span>|</span><label class="collapse" for="c-42330903">[-]</label><label class="expand" for="c-42330903">[6 more]</label></div><br/><div class="children"><div class="content">&gt; above is a 300-line chunk ... deadlocks every few hundred runs<p>Wow, if this kind of thing is successful it feels like there&#x27;s much less need for static checkers.  I mean -- not no need for them, just less need for continued development of new checkers.<p>If I could instead ask &quot;please look for signs of out-of-bounds accesses, deadlocks, use-after-free etc&quot; and get that output added to a code review tool -- if you can reduce the false positives, then it could be really impressive.</div><br/><div id="42331862" class="c"><input type="checkbox" id="c-42331862" checked=""/><div class="controls bullet"><span class="by">therein</span><span>|</span><a href="#42330903">parent</a><span>|</span><a href="#42330874">next</a><span>|</span><label class="collapse" for="c-42331862">[-]</label><label class="expand" for="c-42331862">[5 more]</label></div><br/><div class="children"><div class="content">This mentality is so weird to me. The desire to throw a black box at a problem just strikes me as laziness.<p>What you&#x27;re saying is basically wow if we had a perfect magic programmer in a box as a service that would be so revolutionary; we could reduce the need for static checkers.<p>It is a large language model, trained on arbitrary input data. And you&#x27;re saying let&#x27;s take this statistical approach and have it replace purpose made algorithms.<p>Let&#x27;s get rid of motion tracking and rotoscoping capabilities in Adobe After Effects. Generative AI seems to handle it fine. Who needs to create 3D models when you can just describe what you want and then AI just imagines it?<p>Hey AI, look at this code, now generate it without my memory leaks and deadlocks and use-after-free? People who thought about these problems mindfully and devised systematic approaches to solving them must be spinning in their graves.</div><br/><div id="42332211" class="c"><input type="checkbox" id="c-42332211" checked=""/><div class="controls bullet"><span class="by">wyldfire</span><span>|</span><a href="#42330903">root</a><span>|</span><a href="#42331862">parent</a><span>|</span><a href="#42332160">next</a><span>|</span><label class="collapse" for="c-42332211">[-]</label><label class="expand" for="c-42332211">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It is a large language model, trained on arbitrary input data.<p>Is it?  For all I know they gave it specific instances of bugs like &quot;int *foo() { int i; return &amp;i; }&quot; and told it &quot;this is a defect where we&#x27;ve returned a pointer to a deallocated stack entry - it could cause cause stack corruption or some other unpredictable program behavior.&quot;<p>Even if OpenAI _hasn&#x27;t_ done that, someone certainly can -- and should!<p>&gt; Who needs to create 3D models<p>I specifically pulled back from &quot;no static checkers&quot; because some folks might tend to see things as all-or-nothing.  We choose to invest our time in new developer tools all the time, and if AI can do as good or better maybe we don&#x27;t need to chip-chip-chip away at defects with new static checkers.  Maybe our time is better spent working on some dynamic analysis tool, to find the bugs that the AI can&#x27;t easily uncover.<p>&gt; now generate it without my memory leaks ... People who thought about these problems mindfully<p>I think of myself who devises systematic approaches to problems.  And I get those approaches wrong despite that.  I really love the technology that has been developed over the past couple of decades to help me find my bugs: sanitizers, warnings, and OS, ISA features to detect bugs.  This strikes me as no different from that other technology and I see no reason not to embrace it.<p>Let me ask you this: how do you feel about refcounting or other kinds of GC?  Huge drawbacks make them unusable for some problems.  But for tons of problem domains, they&#x27;re perfect!  Do you think that GC has made developers worse?  IMO it&#x27;s lowered the bar for correct programs and that&#x27;s ideal.</div><br/><div id="42332511" class="c"><input type="checkbox" id="c-42332511" checked=""/><div class="controls bullet"><span class="by">therein</span><span>|</span><a href="#42330903">root</a><span>|</span><a href="#42332211">parent</a><span>|</span><a href="#42332160">next</a><span>|</span><label class="collapse" for="c-42332511">[-]</label><label class="expand" for="c-42332511">[1 more]</label></div><br/><div class="children"><div class="content">GCs create a paradigm in which you still craft logic on your own. It is simply an abstraction, one you could even think of it as a pluggable library construct like Arc&lt;T&gt; in Rust. It doesn&#x27;t write or transform code at the layer programmer writes code. I think GC is closer to the paradigm that stack local variables will go out of scope when you return from a function than a transformer that cleans up the misunderstandings about lifetime.<p>If someone said I crafted this unique approach with this special kind of neural network, and it works on your AST or llvm IR, and we don&#x27;t prompt it, it just optimizes your code to follow these good practices we have engrained into this network, I&#x27;d be less concerned by it. But we are trying to take LLMs trained on anything from Shakespeare to YouTube comments and prompting it to fix memory leaks and deadlocks.</div><br/></div></div></div></div><div id="42332160" class="c"><input type="checkbox" id="c-42332160" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#42330903">root</a><span>|</span><a href="#42331862">parent</a><span>|</span><a href="#42332211">prev</a><span>|</span><a href="#42332530">next</a><span>|</span><label class="collapse" for="c-42332160">[-]</label><label class="expand" for="c-42332160">[1 more]</label></div><br/><div class="children"><div class="content">I think the unaccountability of said magic box is the true allure for corps. It&#x27;s the main reason they desperately want it to be turnkey for code - they&#x27;d be willing to flatten most office jobs as we know them today en route to this perfect, unaccountable, money printer.</div><br/></div></div><div id="42332530" class="c"><input type="checkbox" id="c-42332530" checked=""/><div class="controls bullet"><span class="by">hiAndrewQuinn</span><span>|</span><a href="#42330903">root</a><span>|</span><a href="#42331862">parent</a><span>|</span><a href="#42332160">prev</a><span>|</span><a href="#42330874">next</a><span>|</span><label class="collapse" for="c-42332530">[-]</label><label class="expand" for="c-42332530">[1 more]</label></div><br/><div class="children"><div class="content">As a child I thought about what the perfect computer would be, and I came to the conclusion it would have no screen, no mouse, and no keyboard. It would just have a big red button labeled &quot;DO WHAT I WANT&quot;, and when I press it, it does what I want.<p>I still think this is the perfect computer. I would gladly throw away everything I know about programming to have such a machine. But I don&#x27;t deny your accusation; I am the laziest person imaginable, and all the better an engineer for it.</div><br/></div></div></div></div></div></div><div id="42330874" class="c"><input type="checkbox" id="c-42330874" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#42330903">prev</a><span>|</span><a href="#42330828">next</a><span>|</span><label class="collapse" for="c-42330874">[-]</label><label class="expand" for="c-42330874">[1 more]</label></div><br/><div class="children"><div class="content">Direct link to the report:<p><a href="https:&#x2F;&#x2F;cdn.openai.com&#x2F;o1-system-card-20241205.pdf" rel="nofollow">https:&#x2F;&#x2F;cdn.openai.com&#x2F;o1-system-card-20241205.pdf</a></div><br/></div></div><div id="42330828" class="c"><input type="checkbox" id="c-42330828" checked=""/><div class="controls bullet"><span class="by">yanis_t</span><span>|</span><a href="#42330874">prev</a><span>|</span><a href="#42331008">next</a><span>|</span><label class="collapse" for="c-42330828">[-]</label><label class="expand" for="c-42330828">[10 more]</label></div><br/><div class="children"><div class="content">The first demo was pretty impressive. While nothing revolutionary, that&#x27;s a good progress. I can only hope there&#x27;s a real value in gpt pro to justified the (rumored) $200 price tag</div><br/><div id="42330908" class="c"><input type="checkbox" id="c-42330908" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#42330828">parent</a><span>|</span><a href="#42330857">next</a><span>|</span><label class="collapse" for="c-42330908">[-]</label><label class="expand" for="c-42330908">[2 more]</label></div><br/><div class="children"><div class="content">Not a rumor - <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;introducing-chatgpt-pro&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;introducing-chatgpt-pro&#x2F;</a></div><br/></div></div><div id="42330857" class="c"><input type="checkbox" id="c-42330857" checked=""/><div class="controls bullet"><span class="by">dtquad</span><span>|</span><a href="#42330828">parent</a><span>|</span><a href="#42330908">prev</a><span>|</span><a href="#42331024">next</a><span>|</span><label class="collapse" for="c-42330857">[-]</label><label class="expand" for="c-42330857">[5 more]</label></div><br/><div class="children"><div class="content">Is there any proof that the screenshot is real?<p>Sam Altman would definitely release a $200&#x2F;month plan if he could get away with it but the features in the screenshot are underwhelming.</div><br/><div id="42331273" class="c"><input type="checkbox" id="c-42331273" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#42330828">root</a><span>|</span><a href="#42330857">parent</a><span>|</span><a href="#42330962">next</a><span>|</span><label class="collapse" for="c-42331273">[-]</label><label class="expand" for="c-42331273">[2 more]</label></div><br/><div class="children"><div class="content">I rarely ever use o1-preview, almost all usage goes to 4o nowadays. I don&#x27;t see the point in a model without web search, it&#x27;s closed off. And the wait time is not worth the result unless you&#x27;re doing math or code.</div><br/><div id="42331349" class="c"><input type="checkbox" id="c-42331349" checked=""/><div class="controls bullet"><span class="by">bn-l</span><span>|</span><a href="#42330828">root</a><span>|</span><a href="#42331273">parent</a><span>|</span><a href="#42330962">next</a><span>|</span><label class="collapse" for="c-42331349">[-]</label><label class="expand" for="c-42331349">[1 more]</label></div><br/><div class="children"><div class="content">Personally I can’t get it to stop using deprecated apis. So it might give me a perfectly good solution that’s x years stale at this point. I’ve tried various prompts of course with the most recent docs as markdown etc.</div><br/></div></div></div></div><div id="42330962" class="c"><input type="checkbox" id="c-42330962" checked=""/><div class="controls bullet"><span class="by">meetpateltech</span><span>|</span><a href="#42330828">root</a><span>|</span><a href="#42330857">parent</a><span>|</span><a href="#42331273">prev</a><span>|</span><a href="#42330885">next</a><span>|</span><label class="collapse" for="c-42330962">[-]</label><label class="expand" for="c-42330962">[1 more]</label></div><br/><div class="children"><div class="content">check out the pricing page:<p>also,<p>* Usage must comply with our policies<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;chatgpt&#x2F;pricing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;chatgpt&#x2F;pricing&#x2F;</a></div><br/></div></div><div id="42330885" class="c"><input type="checkbox" id="c-42330885" checked=""/><div class="controls bullet"><span class="by">ALittleLight</span><span>|</span><a href="#42330828">root</a><span>|</span><a href="#42330857">parent</a><span>|</span><a href="#42330962">prev</a><span>|</span><a href="#42331024">next</a><span>|</span><label class="collapse" for="c-42330885">[-]</label><label class="expand" for="c-42330885">[1 more]</label></div><br/><div class="children"><div class="content">He said it in the livestream that just finished.<p>~9:36 - <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rsFHqpN2bCM" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rsFHqpN2bCM</a></div><br/></div></div></div></div><div id="42331024" class="c"><input type="checkbox" id="c-42331024" checked=""/><div class="controls bullet"><span class="by">jsemrau</span><span>|</span><a href="#42330828">parent</a><span>|</span><a href="#42330857">prev</a><span>|</span><a href="#42331008">next</a><span>|</span><label class="collapse" for="c-42331024">[-]</label><label class="expand" for="c-42331024">[2 more]</label></div><br/><div class="children"><div class="content">If it could replace a human employee, what would the right price tag be?</div><br/><div id="42331220" class="c"><input type="checkbox" id="c-42331220" checked=""/><div class="controls bullet"><span class="by">chornesays</span><span>|</span><a href="#42330828">root</a><span>|</span><a href="#42331024">parent</a><span>|</span><a href="#42331008">next</a><span>|</span><label class="collapse" for="c-42331220">[-]</label><label class="expand" for="c-42331220">[1 more]</label></div><br/><div class="children"><div class="content">at least 10k a month in the bay area</div><br/></div></div></div></div></div></div><div id="42331008" class="c"><input type="checkbox" id="c-42331008" checked=""/><div class="controls bullet"><span class="by">demirbey05</span><span>|</span><a href="#42330828">prev</a><span>|</span><a href="#42330994">next</a><span>|</span><label class="collapse" for="c-42331008">[-]</label><label class="expand" for="c-42331008">[1 more]</label></div><br/><div class="children"><div class="content">Is there anyone can explain that why o1-preview benchmarks mostly is better than o1 ?</div><br/></div></div><div id="42330994" class="c"><input type="checkbox" id="c-42330994" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#42331008">prev</a><span>|</span><a href="#42334705">next</a><span>|</span><label class="collapse" for="c-42330994">[-]</label><label class="expand" for="c-42330994">[3 more]</label></div><br/><div class="children"><div class="content">They released the full o1 today as well as a new subscription plan as part of their &quot;ship-mas&quot; starting today where there will be a new launch or demo every day for the next 12 business days.</div><br/><div id="42331032" class="c"><input type="checkbox" id="c-42331032" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#42330994">parent</a><span>|</span><a href="#42334705">next</a><span>|</span><label class="collapse" for="c-42331032">[-]</label><label class="expand" for="c-42331032">[2 more]</label></div><br/><div class="children"><div class="content">I bet their engineers are loving all these new launches right before the holidays.</div><br/><div id="42332490" class="c"><input type="checkbox" id="c-42332490" checked=""/><div class="controls bullet"><span class="by">newfocogi</span><span>|</span><a href="#42330994">root</a><span>|</span><a href="#42331032">parent</a><span>|</span><a href="#42334705">next</a><span>|</span><label class="collapse" for="c-42332490">[-]</label><label class="expand" for="c-42332490">[1 more]</label></div><br/><div class="children"><div class="content">I prefer launches before holidays to launches after holidays</div><br/></div></div></div></div></div></div><div id="42334705" class="c"><input type="checkbox" id="c-42334705" checked=""/><div class="controls bullet"><span class="by">eichi</span><span>|</span><a href="#42330994">prev</a><span>|</span><a href="#42330904">next</a><span>|</span><label class="collapse" for="c-42334705">[-]</label><label class="expand" for="c-42334705">[1 more]</label></div><br/><div class="children"><div class="content">For some tasks, scores are significantly affected by subjects and prompts used in the tests. I don&#x27;t think these are valid figures while it is good to try to evaluate them. Overall, it it a good report.</div><br/></div></div><div id="42331405" class="c"><input type="checkbox" id="c-42331405" checked=""/><div class="controls bullet"><span class="by">Bjorkbat</span><span>|</span><a href="#42330904">prev</a><span>|</span><a href="#42333982">next</a><span>|</span><label class="collapse" for="c-42331405">[-]</label><label class="expand" for="c-42331405">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m really curious to see how this pricing plays out.  I constantly hear on Twitter how certain influencers would be more than willing to pay more than $20&#x2F;month for unlimited access to the best models from OpenAI &#x2F; Anthropic.  Well, now here&#x27;s a $200&#x2F;month unlimited plan.  Is it worth that much and to how many people?</div><br/></div></div><div id="42333982" class="c"><input type="checkbox" id="c-42333982" checked=""/><div class="controls bullet"><span class="by">killingtime74</span><span>|</span><a href="#42331405">prev</a><span>|</span><a href="#42330861">next</a><span>|</span><label class="collapse" for="c-42333982">[-]</label><label class="expand" for="c-42333982">[2 more]</label></div><br/><div class="children"><div class="content">Did anyone else think CBRN = Chemical, biological, radiological, and nuclear</div><br/><div id="42336691" class="c"><input type="checkbox" id="c-42336691" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#42333982">parent</a><span>|</span><a href="#42330861">next</a><span>|</span><label class="collapse" for="c-42336691">[-]</label><label class="expand" for="c-42336691">[1 more]</label></div><br/><div class="children"><div class="content">It is. What&#x27;s your question? I think all model makers are at least <i>strongly encouraged</i> to get their models tested for ability to help terrorists with weapons of mass destruction (CBRN weapons included). The US and UK governments care about that sort of thing.</div><br/></div></div></div></div><div id="42330861" class="c"><input type="checkbox" id="c-42330861" checked=""/><div class="controls bullet"><span class="by">halyconWays</span><span>|</span><a href="#42333982">prev</a><span>|</span><a href="#42331297">next</a><span>|</span><label class="collapse" for="c-42330861">[-]</label><label class="expand" for="c-42330861">[2 more]</label></div><br/><div class="children"><div class="content">The OpenAI scorecard (o) which is mostly concerned with restrictions of: &quot;Disallowed content&quot;, &quot;Hallucinations&quot;, and &quot;Bias&quot;.<p>I propose the People&#x27;s Scorecard, which is p=1-o. It measures how fun a model is. The higher the score the less it feels like you&#x27;re talking to a condescending elementary school teacher, and the more the model will shock and surprise you.</div><br/><div id="42333918" class="c"><input type="checkbox" id="c-42333918" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#42330861">parent</a><span>|</span><a href="#42331297">next</a><span>|</span><label class="collapse" for="c-42333918">[-]</label><label class="expand" for="c-42333918">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s LMSYS.</div><br/></div></div></div></div><div id="42331297" class="c"><input type="checkbox" id="c-42331297" checked=""/><div class="controls bullet"><span class="by">Oras</span><span>|</span><a href="#42330861">prev</a><span>|</span><a href="#42332523">next</a><span>|</span><label class="collapse" for="c-42331297">[-]</label><label class="expand" for="c-42331297">[1 more]</label></div><br/><div class="children"><div class="content">I hope it&#x27;s not an Apple moment of pushing product pricing up, which others will follow if successful.</div><br/></div></div><div id="42332523" class="c"><input type="checkbox" id="c-42332523" checked=""/><div class="controls bullet"><span class="by">unglaublich</span><span>|</span><a href="#42331297">prev</a><span>|</span><a href="#42331254">next</a><span>|</span><label class="collapse" for="c-42332523">[-]</label><label class="expand" for="c-42332523">[1 more]</label></div><br/><div class="children"><div class="content">Occupational therapy for the AI safety folks.</div><br/></div></div><div id="42331254" class="c"><input type="checkbox" id="c-42331254" checked=""/><div class="controls bullet"><span class="by">cluckindan</span><span>|</span><a href="#42332523">prev</a><span>|</span><a href="#42332415">next</a><span>|</span><label class="collapse" for="c-42331254">[-]</label><label class="expand" for="c-42331254">[1 more]</label></div><br/><div class="children"><div class="content">Soon it will be running a front company where people are tasked with receiving base64 printouts and typing them back into a computer.</div><br/></div></div><div id="42335802" class="c"><input type="checkbox" id="c-42335802" checked=""/><div class="controls bullet"><span class="by">djaouen</span><span>|</span><a href="#42332415">prev</a><span>|</span><a href="#42333519">next</a><span>|</span><label class="collapse" for="c-42335802">[-]</label><label class="expand" for="c-42335802">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=W0I9gx_8XHM" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=W0I9gx_8XHM</a></div><br/></div></div><div id="42333519" class="c"><input type="checkbox" id="c-42333519" checked=""/><div class="controls bullet"><span class="by">ValentinA23</span><span>|</span><a href="#42335802">prev</a><span>|</span><a href="#42330866">next</a><span>|</span><label class="collapse" for="c-42333519">[-]</label><label class="expand" for="c-42333519">[2 more]</label></div><br/><div class="children"><div class="content">Are there models with high autonomy around ? I want my LLM to tell me<p>&gt;wow wow wow buddy, slow down, run this code in a terminal, and paste the result here, this will allow me to get an overview of your code base</div><br/><div id="42336704" class="c"><input type="checkbox" id="c-42336704" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#42333519">parent</a><span>|</span><a href="#42330866">next</a><span>|</span><label class="collapse" for="c-42336704">[-]</label><label class="expand" for="c-42336704">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had Claude suggest adding some print statements and letting it know the results so it can better understand what&#x27;s going on</div><br/></div></div></div></div><div id="42330866" class="c"><input type="checkbox" id="c-42330866" checked=""/><div class="controls bullet"><span class="by">pton_xd</span><span>|</span><a href="#42333519">prev</a><span>|</span><a href="#42332956">next</a><span>|</span><label class="collapse" for="c-42330866">[-]</label><label class="expand" for="c-42330866">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Only models with a post-mitigation score of &#x27;high&#x27; or below can be developed further.&quot;<p>What&#x27;s that mean? They won&#x27;t develop better models until the score gets higher?</div><br/><div id="42336643" class="c"><input type="checkbox" id="c-42336643" checked=""/><div class="controls bullet"><span class="by">willy_k</span><span>|</span><a href="#42330866">parent</a><span>|</span><a href="#42330956">next</a><span>|</span><label class="collapse" for="c-42336643">[-]</label><label class="expand" for="c-42336643">[1 more]</label></div><br/><div class="children"><div class="content">If they’re only deploying models that score lower, I would guess that they don’t want to risk it &#x2F; bother trying to bring the highest scoring ones down.</div><br/></div></div><div id="42330956" class="c"><input type="checkbox" id="c-42330956" checked=""/><div class="controls bullet"><span class="by">jonny_eh</span><span>|</span><a href="#42330866">parent</a><span>|</span><a href="#42336643">prev</a><span>|</span><a href="#42332956">next</a><span>|</span><label class="collapse" for="c-42330956">[-]</label><label class="expand" for="c-42330956">[1 more]</label></div><br/><div class="children"><div class="content">The opposite</div><br/></div></div></div></div><div id="42332956" class="c"><input type="checkbox" id="c-42332956" checked=""/><div class="controls bullet"><span class="by">indiantinker</span><span>|</span><a href="#42330866">prev</a><span>|</span><a href="#42332680">next</a><span>|</span><label class="collapse" for="c-42332956">[-]</label><label class="expand" for="c-42332956">[1 more]</label></div><br/><div class="children"><div class="content">Such oversimplification, much wow.</div><br/></div></div><div id="42332680" class="c"><input type="checkbox" id="c-42332680" checked=""/><div class="controls bullet"><span class="by">leumon</span><span>|</span><a href="#42332956">prev</a><span>|</span><a href="#42331323">next</a><span>|</span><label class="collapse" for="c-42332680">[-]</label><label class="expand" for="c-42332680">[1 more]</label></div><br/><div class="children"><div class="content">While it now can read an analog clock from an image (even with seconds), on some images it still doesn&#x27;t work <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;M2JouZs.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;M2JouZs.png</a></div><br/></div></div><div id="42331323" class="c"><input type="checkbox" id="c-42331323" checked=""/><div class="controls bullet"><span class="by">demarq</span><span>|</span><a href="#42332680">prev</a><span>|</span><a href="#42330826">next</a><span>|</span><label class="collapse" for="c-42331323">[-]</label><label class="expand" for="c-42331323">[2 more]</label></div><br/><div class="children"><div class="content">[flagged]</div><br/><div id="42333276" class="c"><input type="checkbox" id="c-42333276" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42331323">parent</a><span>|</span><a href="#42330826">next</a><span>|</span><label class="collapse" for="c-42333276">[-]</label><label class="expand" for="c-42333276">[1 more]</label></div><br/><div class="children"><div class="content">Can you please not post low-quality comments like this to HN? It&#x27;s not what this site is for, and destroys what it is for.<p>You may not owe Sam Altman or chatbots better, but you owe this community better if you&#x27;re participating in it.<p>If you wouldn&#x27;t mind reviewing <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a> and taking the intended spirit of the site more to heart, we&#x27;d be grateful.</div><br/></div></div></div></div></div></div></div></div></div></body></html>