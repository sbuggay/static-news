<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1710320462169" as="style"/><link rel="stylesheet" href="styles.css?v=1710320462169"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2401.09334">Large Language Models Are Neurosymbolic Reasoners</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>optimalsolver</span> | <span>59 comments</span></div><br/><div><div id="39688684" class="c"><input type="checkbox" id="c-39688684" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#39688599">next</a><span>|</span><label class="collapse" for="c-39688684">[-]</label><label class="expand" for="c-39688684">[3 more]</label></div><br/><div class="children"><div class="content">The authors get LLMs to perform pretty well in a variety of IF-style text based games. Which is pretty cool, these kinds of games are played and read in natural language, which makes them pretty hard to write AIs for normally.<p>Something I&#x27;d love to see one day is modern AI applied to other kinds of text based games like nethack. Last I checked nobody had managed to solve the problem of nethack AI without using hard coded heuristics and goals!</div><br/><div id="39689214" class="c"><input type="checkbox" id="c-39689214" checked=""/><div class="controls bullet"><span class="by">still_grokking</span><span>|</span><a href="#39688684">parent</a><span>|</span><a href="#39688853">next</a><span>|</span><label class="collapse" for="c-39689214">[-]</label><label class="expand" for="c-39689214">[1 more]</label></div><br/><div class="children"><div class="content">Is it actually possible to beat Nethack without reading up some &quot;spoilers&quot; upfront? I&#x27;ve <i>never</i> heard of anybody who managed to do that.<p>Even when you read up all kinds of info about the game before you attempt a run it&#x27;s extremely hard to reach higher levels, yet beat the game. (I myself never reached any later levels despite I know some tricks by now. Tricks impossible to infer from just playing the game; you need to read them up…)<p>Imho there is no winning strategy for Nethack. It&#x27;s some random stuff &quot;you need to know&quot; to progress even a little bit paired with complete rule of the dice while encountering maximally nonsensical &quot;puzzles&quot;.<p>But OK, maybe I&#x27;m just too dumb for this game and don&#x27;t see the &quot;logic&quot; behind the things the game presents.</div><br/></div></div><div id="39688853" class="c"><input type="checkbox" id="c-39688853" checked=""/><div class="controls bullet"><span class="by">wiz21c</span><span>|</span><a href="#39688684">parent</a><span>|</span><a href="#39689214">prev</a><span>|</span><a href="#39688599">next</a><span>|</span><label class="collapse" for="c-39688853">[-]</label><label class="expand" for="c-39688853">[1 more]</label></div><br/><div class="children"><div class="content">Yes IF-style for sure but that&#x27;s not Zork either. Cool work though, but having those solving Zork or Mystery House or whatever would be sooo cool !</div><br/></div></div></div></div><div id="39688599" class="c"><input type="checkbox" id="c-39688599" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688684">prev</a><span>|</span><a href="#39689043">next</a><span>|</span><label class="collapse" for="c-39688599">[-]</label><label class="expand" for="c-39688599">[48 more]</label></div><br/><div class="children"><div class="content">I was recently thinking how every neural network is equivalent to a lookup table where the input is all numbers up to what can be expressed within the context window and the output is the result of the arithmetic operations applied to that number. So every neural network is equivalent to T = {(i, f(i)) : i &lt; K} where K is the constant which determines the context window and f is the numerical function implemented by the network. Can someone ask a neural network if my reasoning is valid and correct?<p>The main practical issue is the size of the table but I don&#x27;t see any theoretical reasons why this is incorrect. The neural network is simply a compressed representation of the uncompressed lookup table. Given that the two representations are theoretically equivalent and a lookup table does not perform any reasoning we can conclude that no neural network is actually doing any thinking other than uncompressing the table and looking up the value corresponding to the input number.<p>Modern neural networks have some randomness but that doesn&#x27;t change the table in any meaningful way because instead of the output being a number it becomes a distribution over some finite range which can again be turned into a table with some tuples.</div><br/><div id="39688952" class="c"><input type="checkbox" id="c-39688952" checked=""/><div class="controls bullet"><span class="by">edflsafoiewq</span><span>|</span><a href="#39688599">parent</a><span>|</span><a href="#39688724">next</a><span>|</span><label class="collapse" for="c-39688952">[-]</label><label class="expand" for="c-39688952">[2 more]</label></div><br/><div class="children"><div class="content">This reminds me of the classic problem in computation, where the simplest form of computation, the lookup table, input -&gt; output, is limited to a finite domain. Turing modified the computation to have a finite internal state and infinite external environment (tape), so it becomes a transition function (state, stimulus) -&gt; (new state, response), applied recursively in a feedback loop, allowing it to operate on infinite domains.<p>Famously a simple lookup table for the transition function then suffices to compute any computable function.</div><br/><div id="39688960" class="c"><input type="checkbox" id="c-39688960" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688952">parent</a><span>|</span><a href="#39688724">next</a><span>|</span><label class="collapse" for="c-39688960">[-]</label><label class="expand" for="c-39688960">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a good point.</div><br/></div></div></div></div><div id="39688724" class="c"><input type="checkbox" id="c-39688724" checked=""/><div class="controls bullet"><span class="by">Centigonal</span><span>|</span><a href="#39688599">parent</a><span>|</span><a href="#39688952">prev</a><span>|</span><a href="#39689049">next</a><span>|</span><label class="collapse" for="c-39688724">[-]</label><label class="expand" for="c-39688724">[13 more]</label></div><br/><div class="children"><div class="content">It sounds like you&#x27;re asking whether the output of a neural network is a deterministic function of its input. For many LLMs, you can make that answer yes with the right combination of parameters (temperature  = 0) and underlying compute (variance in floating point calculations can still introduce randomness in model outputs even when the model should theoretically return the same answer every time).<p>There are some ways to introduce stochasticity:<p>1. Add randomness. The temperature or &quot;creativity&quot; hyperparameter in most LLMs does this, as do some decoders. The hardware these models run can also add randomness.<p>2. Add some concept of state. RNNs do this, some of the approaches which give the LLM a scratch pad or external memory do this, and continuous pre-training sort of does this.<p>How this affects people&#x27;s perception of LLMs as thinking machines, I don&#x27;t know. What if someone took every response I ever gave to every question that was ever asked of me in my life and made a Chinese Room[1] version of me? A lookup table that is functionally identical to my entire existence. In what contexts is the difference meaningful?<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chinese_room" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chinese_room</a></div><br/><div id="39688828" class="c"><input type="checkbox" id="c-39688828" checked=""/><div class="controls bullet"><span class="by">cryptoxchange</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688724">parent</a><span>|</span><a href="#39688764">next</a><span>|</span><label class="collapse" for="c-39688828">[-]</label><label class="expand" for="c-39688828">[1 more]</label></div><br/><div class="children"><div class="content">To your last point, <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Problem_of_induction" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Problem_of_induction</a><p>A LUT version of you is inductive. Every observed input&#x2F;output pair does not uniquely identify your current state. Much like a puddle left by a melted ice cube indicates its volume, but little to nothing of its shape.<p>Post LUT-you genesis, applying property based fuzz testing would quickly reveal that the LUT-you is one of an infinite number of LUT-yous that melts into the puddle of historical data, but not the LUT-you that is the original ice cube.<p><a href="https:&#x2F;&#x2F;fsharpforfunandprofit.com&#x2F;posts&#x2F;property-based-testing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;fsharpforfunandprofit.com&#x2F;posts&#x2F;property-based-testi...</a></div><br/></div></div><div id="39688764" class="c"><input type="checkbox" id="c-39688764" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688724">parent</a><span>|</span><a href="#39688828">prev</a><span>|</span><a href="#39689049">next</a><span>|</span><label class="collapse" for="c-39688764">[-]</label><label class="expand" for="c-39688764">[11 more]</label></div><br/><div class="children"><div class="content">People can not be reduced to lookup tables even in theory. No one even knows how a single cell does what it does let alone an entire organism like a person.<p>I&#x27;m not making an abstract claim about neural networks because all numerical algorithms like neural networks can be reduced to a lookup table given a large enough hard drive. This is not practical because the space required would exceed the number of atoms in the known universe but the argument is sound. The same isn&#x27;t true for people unless a person is idealized and abstracted into a sequence of numbers. I&#x27;m not saying no one is allowed to think of people as some sequence of numbers but this is clearly an abstraction of what it means to be a person and in the case of the neural network there is no abstraction, it really is a numerical function which can be expanded into a large table which represents its graph.</div><br/><div id="39688829" class="c"><input type="checkbox" id="c-39688829" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688764">parent</a><span>|</span><a href="#39688806">next</a><span>|</span><label class="collapse" for="c-39688829">[-]</label><label class="expand" for="c-39688829">[8 more]</label></div><br/><div class="children"><div class="content">&gt;People can not be reduced to lookup tables even in theory<p>Sure you can. Simply enumerate all of the physical states that the atoms in your body could be in. Any finite-sized object has a finite number of possible states, and so can be represented by a finite lookup table.<p>Your argument is so broad as to be meaningless.</div><br/><div id="39688851" class="c"><input type="checkbox" id="c-39688851" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688829">parent</a><span>|</span><a href="#39689104">next</a><span>|</span><label class="collapse" for="c-39688851">[-]</label><label class="expand" for="c-39688851">[6 more]</label></div><br/><div class="children"><div class="content">Then give some concrete numbers for the states of the atoms. My argument is not abstract, it is very concrete. Give me a neural network and I can generate the graph and prove the equivalence between the network and its graph representation as a table of tuples.</div><br/><div id="39688918" class="c"><input type="checkbox" id="c-39688918" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688851">parent</a><span>|</span><a href="#39689245">next</a><span>|</span><label class="collapse" for="c-39688918">[-]</label><label class="expand" for="c-39688918">[4 more]</label></div><br/><div class="children"><div class="content">You said &quot;even in theory&quot; which is obviously wrong, since the (local) universe is finite and deterministic, hence it is itself a giant lookup table.</div><br/><div id="39689230" class="c"><input type="checkbox" id="c-39689230" checked=""/><div class="controls bullet"><span class="by">aruss</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688918">parent</a><span>|</span><a href="#39689245">next</a><span>|</span><label class="collapse" for="c-39689230">[-]</label><label class="expand" for="c-39689230">[3 more]</label></div><br/><div class="children"><div class="content">Where are you going to get all that time and space to build a lookup table? Are you sure you&#x27;re able to measure all state at enough precision to make an accurate table?</div><br/><div id="39689255" class="c"><input type="checkbox" id="c-39689255" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39689230">parent</a><span>|</span><a href="#39689245">next</a><span>|</span><label class="collapse" for="c-39689255">[-]</label><label class="expand" for="c-39689255">[2 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t matter given the original statement spawning this subthread was:<p>&gt; People can not be reduced to lookup tables even in theory</div><br/><div id="39689341" class="c"><input type="checkbox" id="c-39689341" checked=""/><div class="controls bullet"><span class="by">mistermann</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39689255">parent</a><span>|</span><a href="#39689245">next</a><span>|</span><label class="collapse" for="c-39689341">[-]</label><label class="expand" for="c-39689341">[1 more]</label></div><br/><div class="children"><div class="content">[delayed]</div><br/></div></div></div></div></div></div></div></div><div id="39689245" class="c"><input type="checkbox" id="c-39689245" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688851">parent</a><span>|</span><a href="#39688918">prev</a><span>|</span><a href="#39689104">next</a><span>|</span><label class="collapse" for="c-39689245">[-]</label><label class="expand" for="c-39689245">[1 more]</label></div><br/><div class="children"><div class="content">&quot;&quot;&quot;the number of bits required to perfectly recreate the natural matter of the average-sized U.S. adult male human brain down to the quantum level on a computer is about 2.6×10^42 bits of information (see Bekenstein bound for the basis for this calculation).&quot;&quot;&quot; - <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Orders_of_magnitude_(data)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Orders_of_magnitude_(data)</a><p>(That said, I think quantum physics makes it &quot;all a Markov chain&quot; rather than &quot;all a lookup table&quot;).</div><br/></div></div></div></div><div id="39689104" class="c"><input type="checkbox" id="c-39689104" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688829">parent</a><span>|</span><a href="#39688851">prev</a><span>|</span><a href="#39688806">next</a><span>|</span><label class="collapse" for="c-39689104">[-]</label><label class="expand" for="c-39689104">[1 more]</label></div><br/><div class="children"><div class="content">You are making the assumption that your body consists of a static set of atoms, but your body is a living thing. Your lookup table would end up containing the entire universe to account for extremely remote possibilities.</div><br/></div></div></div></div><div id="39688806" class="c"><input type="checkbox" id="c-39688806" checked=""/><div class="controls bullet"><span class="by">Centigonal</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688764">parent</a><span>|</span><a href="#39688829">prev</a><span>|</span><a href="#39689049">next</a><span>|</span><label class="collapse" for="c-39688806">[-]</label><label class="expand" for="c-39688806">[2 more]</label></div><br/><div class="children"><div class="content">My &quot;what if someone made a lookup table of everything I ever said in response to something else&quot; hypothetical is pretty flimsy - I realized that right after writing it.<p>The point I wanted to make is that concepts of sentience, consciousness, reasoning, intelligence, etc. are very philosophically loaded ideas.<p>Responding to your comment, I don&#x27;t think anyone credible is arguing that a human being is somehow the same as a neural network. I think the question at play here is &quot;what constitutes reasoning?&quot; - and more specifically &quot;can a deterministic process reason?&quot;<p>This is not a new debate at all - an abacus can tell us truths about the world, but we don&#x27;t consider the abacus intelligent. Is GPT-4 somehow different, or is it a very large abacus?</div><br/><div id="39688840" class="c"><input type="checkbox" id="c-39688840" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688806">parent</a><span>|</span><a href="#39689049">next</a><span>|</span><label class="collapse" for="c-39688840">[-]</label><label class="expand" for="c-39688840">[1 more]</label></div><br/><div class="children"><div class="content">As a numerical function it can be implemented on an abacus so I don&#x27;t think it&#x27;s any different from a large enough abacus. It&#x27;s practically not feasible but theoretically there is no idealization or abstraction happening when numerical calculations on a computer are transferred to an abacus.</div><br/></div></div></div></div></div></div></div></div><div id="39689049" class="c"><input type="checkbox" id="c-39689049" checked=""/><div class="controls bullet"><span class="by">radarsat1</span><span>|</span><a href="#39688599">parent</a><span>|</span><a href="#39688724">prev</a><span>|</span><a href="#39688914">next</a><span>|</span><label class="collapse" for="c-39689049">[-]</label><label class="expand" for="c-39689049">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this is one view of machine learning, the idea that you are training some function to map input to output, similar to &quot;looking up&quot; what output is addressed by some input.<p>And that&#x27;s why the concept of generalization is so important on machine learning, and as a consequence, why the internal representation of that &quot;lookup&quot; <i>matters</i>.<p>By definition a lookup table can only store data it is given. However, the idea of ML systems is actually to predict values of inputs that are similar to but <i>not</i> given in their training data.<p>Interpolation and extrapolation, key components to applying ML systems to new data and therefore critical for actual usage, are enabled by internal representations that allow for modeling the space between and around data points.  It so happens that multilayer neural networks accomplish this by general and smoothed (due to regularization tricks and inductive biases) iterative warpings of the representation (embedding) space.<p>Due to the manifold hypothesis, we can interpret this as determining underlying and semantically meaningful subspaces, and unfolding them to perform generalized operations such as logical manipulations and drawing classification boundaries in some relatively smooth semantic space, then refolding things to drive some output representation (pixels, classes, etc.)<p>Another view on this is that these manipulations allow a kind of compression by optimizing the representation to make manipulations easier, in other words they re-express the data in a form that allows algorithmic evaluation of some input program. This gives the chance of modeling intrinsic relationships such as infinite sequences as vector programs. (Here I mean things like mathematical recursions, etc.) When this is accomplished, and it happens due to the pressure to optimally compress data, you could say that &quot;understanding&quot; emerges, and the result is a program that extrapolates to unseen values of such sequences.  At this point you could say that while the input-output relationship is like a lookup table, functionally it is not the same thing because the need to compress these input-output relationships has led to some representation which allows for extrapolation, aka &quot;intelligence&quot; by some definitions.<p>The fact that these systems are still very dumb sometimes is simply due to not developing these representations as well as we would like them to, for a variety of reasons. But theoretically this is the idea behind why emergence might occur in an NN but not in a lookup table.</div><br/></div></div><div id="39688914" class="c"><input type="checkbox" id="c-39688914" checked=""/><div class="controls bullet"><span class="by">danieldk</span><span>|</span><a href="#39688599">parent</a><span>|</span><a href="#39689049">prev</a><span>|</span><a href="#39689099">next</a><span>|</span><label class="collapse" for="c-39688914">[-]</label><label class="expand" for="c-39688914">[6 more]</label></div><br/><div class="children"><div class="content">Suppose that we used embeddings as the input of the model rather than piece identifiers plus an embedding lookup table. This is possible with every transformer model and some libraries provide an API to do this. Moreover, we convert the parameters and ops to use arbitrary precision types. Then the network cannot be represented as a lookup table. Given that there is an infinite number of inputs, there is also an infinite number of outputs. But the arbitrary-precision network does not operate fundamentally different from the original network. It has the same parameters, ops, etc., yet you cannot store it as a (finite) lookup table.</div><br/><div id="39688947" class="c"><input type="checkbox" id="c-39688947" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688914">parent</a><span>|</span><a href="#39689099">next</a><span>|</span><label class="collapse" for="c-39688947">[-]</label><label class="expand" for="c-39688947">[5 more]</label></div><br/><div class="children"><div class="content">Even if you increase the precision I can still generate a table T(P) for each fixed precision P. So the table is parametrized by P but it&#x27;s still a table. The entire table T = colim T(P) is the colimit over all precision values but for every finite precision it is still a table.</div><br/><div id="39688997" class="c"><input type="checkbox" id="c-39688997" checked=""/><div class="controls bullet"><span class="by">danieldk</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688947">parent</a><span>|</span><a href="#39689099">next</a><span>|</span><label class="collapse" for="c-39688997">[-]</label><label class="expand" for="c-39688997">[4 more]</label></div><br/><div class="children"><div class="content">I did not say fixed precision. I said arbitrary precision, so P is infinite.<p>The only counter-argument is that even arbitrary precision is fixed-precision because computer memory is finite. But that&#x27;s kind of a silly argument, because then you are arguing that computers can never reason, because they have finite memory, and moreover humans cannot reason either, because there is a finite number of brain cells.</div><br/><div id="39689007" class="c"><input type="checkbox" id="c-39689007" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688997">parent</a><span>|</span><a href="#39689099">next</a><span>|</span><label class="collapse" for="c-39689007">[-]</label><label class="expand" for="c-39689007">[3 more]</label></div><br/><div class="children"><div class="content">P obviously can&#x27;t be infinite, even in theory, if you want the computation to terminate.</div><br/><div id="39689018" class="c"><input type="checkbox" id="c-39689018" checked=""/><div class="controls bullet"><span class="by">danieldk</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39689007">parent</a><span>|</span><a href="#39689099">next</a><span>|</span><label class="collapse" for="c-39689018">[-]</label><label class="expand" for="c-39689018">[2 more]</label></div><br/><div class="children"><div class="content">Right, but then as others said, then you are also arguing that humans cannot reason, since the universe is a system with a finite number of particles. Or if we exclude external factors, because humans have a finite number of brain cells.<p>In the end it all depends on what your definition of <i>reasoning</i> is, which you did not provide.</div><br/><div id="39689045" class="c"><input type="checkbox" id="c-39689045" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39689018">parent</a><span>|</span><a href="#39689099">next</a><span>|</span><label class="collapse" for="c-39689045">[-]</label><label class="expand" for="c-39689045">[1 more]</label></div><br/><div class="children"><div class="content">The bit precision of computation is always finite for halting computations and any finite computation can be turned into a lookup table which does no thinking or reasoning other than comparing two numbers and then extracting the value corresponding to the input key.<p>My argument carries through for any piece of software so if you think software can think and reason then you can remain unconvinced by my argument.<p>In any case, I have to drop out of this thread.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39689099" class="c"><input type="checkbox" id="c-39689099" checked=""/><div class="controls bullet"><span class="by">cesaref</span><span>|</span><a href="#39688599">parent</a><span>|</span><a href="#39688914">prev</a><span>|</span><a href="#39688699">next</a><span>|</span><label class="collapse" for="c-39689099">[-]</label><label class="expand" for="c-39689099">[2 more]</label></div><br/><div class="children"><div class="content">Just like to point out that RNNs have internal state which isn&#x27;t captured in this view, so yes, lots of NNs can be considered this way, but not all. It&#x27;s the DSP equivalent of FIRs vs IIRs.</div><br/></div></div><div id="39688699" class="c"><input type="checkbox" id="c-39688699" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#39688599">parent</a><span>|</span><a href="#39689099">prev</a><span>|</span><a href="#39688998">next</a><span>|</span><label class="collapse" for="c-39688699">[-]</label><label class="expand" for="c-39688699">[18 more]</label></div><br/><div class="children"><div class="content">This is an old argument against determinism - I think a serious challenge is that:<p>1. Modern physics suggests you can implement such a lookup table for any subset of our universe.<p>2. We are a subset of the universe.<p>3. Therefore we are representable by lookup tables too.<p>...so your argument appears to prove too much, namely that humans aren&#x27;t thinking beings either. Which is fine, but personally I don&#x27;t think that&#x27;s a useful definition of &quot;thinking&quot;.</div><br/><div id="39688739" class="c"><input type="checkbox" id="c-39688739" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688699">parent</a><span>|</span><a href="#39688718">next</a><span>|</span><label class="collapse" for="c-39688739">[-]</label><label class="expand" for="c-39688739">[5 more]</label></div><br/><div class="children"><div class="content">We&#x27;re not a lookup table <i>of</i> the things we&#x27;re, eg., saying, or doing etc. Nor are we looking up, in this sense, when we act.<p>ie., when you compress text into an NN and use it to generate text, the generated text is just a synthesis of the compressed <i>text</i>.<p>Whereas when I type, I am not synthesising <i>text</i>. Rather I have the skill of typing, I have an interior subjectivity of thoughts, I have memories which arent text, and so on.<p>When my fingers move across the keyboard it isn&#x27;t <i>because</i> they are looking up text.<p>Our causal properties (experiencing, thinking, seeing, feeling, remembering, moving, speaking, growing, digesting ...) are not each, &quot;index on the total history of prior experience&quot;, &quot;index on the total history of prior seeing&quot;. The world directly causes, eg., us to see -- seeing isnt a lookup table of prior seeings.<p>( Also, the whole of physics is formulated in terms that cannot be made into a lookup table; and there is no evidence, only insistence, of the converse. )</div><br/><div id="39689020" class="c"><input type="checkbox" id="c-39689020" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688739">parent</a><span>|</span><a href="#39688836">next</a><span>|</span><label class="collapse" for="c-39689020">[-]</label><label class="expand" for="c-39689020">[3 more]</label></div><br/><div class="children"><div class="content">I strongly disagree with your last statement - physics explicitly _is_ formulated in terms that can be made into a lookup table (see phase spaces in classical mechanics, for instance).<p>My point is that there&#x27;s a finite light cone of possible causal influences over you at any moment in time, and in principle you can break those down into state variables finely enough to predict future states of a person. This is isomorphic to a lookup table, albeit one we aren&#x27;t able to construct right now.<p>Im not suggesting it&#x27;s enough to consider just the person in this scenario - the causal factors are part of the lookup.</div><br/><div id="39689127" class="c"><input type="checkbox" id="c-39689127" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39689020">parent</a><span>|</span><a href="#39688836">next</a><span>|</span><label class="collapse" for="c-39689127">[-]</label><label class="expand" for="c-39689127">[2 more]</label></div><br/><div class="children"><div class="content">How do you lookup quantum mechanics? Please tell the physicists about your breakthroughs.</div><br/><div id="39689159" class="c"><input type="checkbox" id="c-39689159" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39689127">parent</a><span>|</span><a href="#39688836">next</a><span>|</span><label class="collapse" for="c-39689159">[-]</label><label class="expand" for="c-39689159">[1 more]</label></div><br/><div class="children"><div class="content">No need, physicists already do this all the time - any computer simulation of quantum mechanical systems has to come to terms with the same problems (namely quantising the state space and representing the dynamics deterministically).</div><br/></div></div></div></div></div></div><div id="39688836" class="c"><input type="checkbox" id="c-39688836" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688739">parent</a><span>|</span><a href="#39689020">prev</a><span>|</span><a href="#39688718">next</a><span>|</span><label class="collapse" for="c-39688836">[-]</label><label class="expand" for="c-39688836">[1 more]</label></div><br/><div class="children"><div class="content">Typing is just a medium, it is irrelevant. Seeing and all the other senses that you mentioned are input within a context window.</div><br/></div></div></div></div><div id="39688718" class="c"><input type="checkbox" id="c-39688718" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688699">parent</a><span>|</span><a href="#39688739">prev</a><span>|</span><a href="#39688998">next</a><span>|</span><label class="collapse" for="c-39688718">[-]</label><label class="expand" for="c-39688718">[12 more]</label></div><br/><div class="children"><div class="content">How are people lookup tables? In the case of neural networks the representation of the table is obvious, it&#x27;s just numbers. What would be the equivalent table for the liver?<p>My argument isn&#x27;t abstract. Neural networks really are just numerical functions which can be expanded into their equivalent graph representations.</div><br/><div id="39689047" class="c"><input type="checkbox" id="c-39689047" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688718">parent</a><span>|</span><a href="#39688760">next</a><span>|</span><label class="collapse" for="c-39689047">[-]</label><label class="expand" for="c-39689047">[1 more]</label></div><br/><div class="children"><div class="content">People really are just stacks of molecules that can be broken down into their causal properties - moreover, we know those causal properties to a high degree of accuracy these days.<p>I&#x27;m suggesting that for any given human&#x2F;environment pair, there is a lookup table that produces that person&#x27;s actual behaviour in that situation. Modern physics lets us approximate this lookup table, and presumably better physics would give us a better lookup table.<p>Since human behaviour can in principle be described with a lookup table, I see this as a bad reason to rule out a system as &quot;thinking&quot;.<p>Perhaps there is another way to describe neural nets, one that does not use the language of lookup tables, that makes it feel more like thinking and less like lookups.<p>One such approach I&#x27;ve seen is looking for embedded world models in neural nets.</div><br/></div></div><div id="39688760" class="c"><input type="checkbox" id="c-39688760" checked=""/><div class="controls bullet"><span class="by">josh-stylo</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688718">parent</a><span>|</span><a href="#39689047">prev</a><span>|</span><a href="#39688998">next</a><span>|</span><label class="collapse" for="c-39688760">[-]</label><label class="expand" for="c-39688760">[10 more]</label></div><br/><div class="children"><div class="content">Not sure what he&#x27;s referring to in terms of modern physics saying we&#x27;re just a lookup table but at the very least, you could say the same thing about the conversation that we&#x27;re having now. You read words, those words map to meaning representation in our heads, we then generate a response.</div><br/><div id="39688785" class="c"><input type="checkbox" id="c-39688785" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688760">parent</a><span>|</span><a href="#39688998">next</a><span>|</span><label class="collapse" for="c-39688785">[-]</label><label class="expand" for="c-39688785">[9 more]</label></div><br/><div class="children"><div class="content">Obviously if we are interacting over a digital medium then the responses will be encoded as numbers but there is no way to reduce an entire person to a lookup table. Measured output of human behavior can be expressed as lists of numbers but thinking is not the same as the list of numbers, unlike in the case of neural networks where the graph and the network are actually equivalent.</div><br/><div id="39688848" class="c"><input type="checkbox" id="c-39688848" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688785">parent</a><span>|</span><a href="#39688998">next</a><span>|</span><label class="collapse" for="c-39688848">[-]</label><label class="expand" for="c-39688848">[8 more]</label></div><br/><div class="children"><div class="content">You could represent all the input on different levels as numbers, e.g. all EM waves hitting our eyes, then all the physical output from our body also as numbers, and everything that causes this output from input within is what you would consider to be a lookup table.</div><br/><div id="39688874" class="c"><input type="checkbox" id="c-39688874" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688848">parent</a><span>|</span><a href="#39688998">next</a><span>|</span><label class="collapse" for="c-39688874">[-]</label><label class="expand" for="c-39688874">[7 more]</label></div><br/><div class="children"><div class="content">What are the dimension of the input and output spaces involved in this idealization? In the case of a neural network there is no idealization. The network is software, it&#x27;s a number. It&#x27;s inputs and outputs are all bounded and can be expressed as a table of bounded tuples.</div><br/><div id="39688964" class="c"><input type="checkbox" id="c-39688964" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688874">parent</a><span>|</span><a href="#39688948">next</a><span>|</span><label class="collapse" for="c-39688964">[-]</label><label class="expand" for="c-39688964">[2 more]</label></div><br/><div class="children"><div class="content">You could pick a very large number depending on a reasonable processing capability a human has, which represents all the significant physical interactions on a human body over a certain amount of time. Then take the output over a certain amount of time, being all movements of the body.<p>If you wanted to focus on thoughts alone, you might want to skip few layers&#x2F;systems, to give input directly to whatever causes thoughts to happen.<p>All particles and their interactions could also be represented as numbers. But it just depends on what level we do this, and at what level what kind of complex logic is required.</div><br/><div id="39689013" class="c"><input type="checkbox" id="c-39689013" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688964">parent</a><span>|</span><a href="#39688948">next</a><span>|</span><label class="collapse" for="c-39689013">[-]</label><label class="expand" for="c-39689013">[1 more]</label></div><br/><div class="children"><div class="content">Ok so give me some concrete number.</div><br/></div></div></div></div><div id="39688948" class="c"><input type="checkbox" id="c-39688948" checked=""/><div class="controls bullet"><span class="by">ccozan</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688874">parent</a><span>|</span><a href="#39688964">prev</a><span>|</span><a href="#39688998">next</a><span>|</span><label class="collapse" for="c-39688948">[-]</label><label class="expand" for="c-39688948">[4 more]</label></div><br/><div class="children"><div class="content">I think the OP is right. All the input to a human brain can be expressed as numbers, at any given time a specific radiation, vibration, or chemical reaction is hitting our &quot;sensors&quot; and by the law of physics this is just numbers ( in terms of differentiation, brain does not know absolute values ).<p>Our output ( mechanical and vibrations ) is also fully quantifiable, thus numbers.<p>One giant lookup table.</div><br/><div id="39688995" class="c"><input type="checkbox" id="c-39688995" checked=""/><div class="controls bullet"><span class="by">clooper</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688948">parent</a><span>|</span><a href="#39688998">next</a><span>|</span><label class="collapse" for="c-39688995">[-]</label><label class="expand" for="c-39688995">[3 more]</label></div><br/><div class="children"><div class="content">Provide some concrete numbers for solar radiation then as a lookup table. You guys are confusing abstraction and idealization with what it means to be a thinking person. There is no such abstraction and idealization happening with software. The software is really just a number, there is no idealization or abstraction happening when I claim that GPT is a sequence of bits representing a numerical function.</div><br/><div id="39689103" class="c"><input type="checkbox" id="c-39689103" checked=""/><div class="controls bullet"><span class="by">danieldk</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688995">parent</a><span>|</span><a href="#39689093">next</a><span>|</span><label class="collapse" for="c-39689103">[-]</label><label class="expand" for="c-39689103">[1 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t really have it both ways, being reductionist when it comes to computers (it&#x27;s just a finite set of numbers, so there is no reasoning), but not permitting to use the same line of argumentation with humans (it&#x27;s just a finite set of particles).<p>At any rate, this is an ages-old discussion in philosophy, so most likely we are not going to settle this in a Hacker News thread.</div><br/></div></div><div id="39689093" class="c"><input type="checkbox" id="c-39689093" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688995">parent</a><span>|</span><a href="#39689103">prev</a><span>|</span><a href="#39688998">next</a><span>|</span><label class="collapse" for="c-39689093">[-]</label><label class="expand" for="c-39689093">[1 more]</label></div><br/><div class="children"><div class="content">Abstraction is a property of a description of a thing, not the thing itself. In reality, what we call &quot;GPT&quot; is the highly organised behaviour of many electrons, probably distributed across many computers, each with extremely complex hardware of various kinds, etc etc. Calling it a sequence of bits representing a numerical function is a choice of description - an abstraction, even!<p>In this case it&#x27;s a good description, because it correlates with the GPT in reality quite well. But they are not the same thing.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39688998" class="c"><input type="checkbox" id="c-39688998" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#39688599">parent</a><span>|</span><a href="#39688699">prev</a><span>|</span><a href="#39689043">next</a><span>|</span><label class="collapse" for="c-39688998">[-]</label><label class="expand" for="c-39688998">[5 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a counterexample. Suppose I create a simple neural network that computes f(x) = x^2 + c (where x and c are  complex numbers) and then I run it as an RNN. This RNN will compute the mandelbrot set, which can&#x27;t be represented by a lookup table.<p>You can&#x27;t even know if the RNN will halt for a given input. Neural networks are stronger than lookup tables, they are <i>programs.</i></div><br/><div id="39689037" class="c"><input type="checkbox" id="c-39689037" checked=""/><div class="controls bullet"><span class="by">cjfd</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39688998">parent</a><span>|</span><a href="#39689043">next</a><span>|</span><label class="collapse" for="c-39689037">[-]</label><label class="expand" for="c-39689037">[4 more]</label></div><br/><div class="children"><div class="content">I am sorry to be this blunt but this is really utter and complete nonsense. The phrase that the mandelbrot set can&#x27;t be represented in a lookup table is as such true but that is because nothing that you do with finite precision numbers can represent the mandelbrot set because it essentially is an inifinte object. The function f(x) = x^2 + c as an RNN can also not compute the mandelbrot set if the numbers it uses are of finite precision. That is exactly the same limitation that the lookup table also faces so there is no fundamental difference between the two.</div><br/><div id="39689177" class="c"><input type="checkbox" id="c-39689177" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39689037">parent</a><span>|</span><a href="#39689112">next</a><span>|</span><label class="collapse" for="c-39689177">[-]</label><label class="expand" for="c-39689177">[2 more]</label></div><br/><div class="children"><div class="content">We can give them both infinite precision, you still can&#x27;t build a lookup table of the mandelbrot set.<p>The mandelbrot set is essentially a map of the halting behavior of a specific program. You can&#x27;t know whether or not the program will halt for a given input, and so cannot build the lookup table. Programs are stronger than input-output mappings.</div><br/><div id="39689306" class="c"><input type="checkbox" id="c-39689306" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39689177">parent</a><span>|</span><a href="#39689112">next</a><span>|</span><label class="collapse" for="c-39689306">[-]</label><label class="expand" for="c-39689306">[1 more]</label></div><br/><div class="children"><div class="content">Infinity is really hard to reason about, are you sure about that?<p>(For all I know you&#x27;re a PhD in transfinites, your profile says nothing).</div><br/></div></div></div></div><div id="39689112" class="c"><input type="checkbox" id="c-39689112" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39688599">root</a><span>|</span><a href="#39689037">parent</a><span>|</span><a href="#39689177">prev</a><span>|</span><a href="#39689043">next</a><span>|</span><label class="collapse" for="c-39689112">[-]</label><label class="expand" for="c-39689112">[1 more]</label></div><br/><div class="children"><div class="content">I see you are a fan of flying disembodied brains, but this time without a universe surrounding the brain.</div><br/></div></div></div></div></div></div></div></div><div id="39689043" class="c"><input type="checkbox" id="c-39689043" checked=""/><div class="controls bullet"><span class="by">lkrubner</span><span>|</span><a href="#39688599">prev</a><span>|</span><a href="#39688441">next</a><span>|</span><label class="collapse" for="c-39689043">[-]</label><label class="expand" for="c-39689043">[2 more]</label></div><br/><div class="children"><div class="content">Possibly off-topic, but does anyone know where I can read up on LLMs? I&#x27;ve posted an &quot;Ask HN&quot; here, in the hopes some people can inform me about how I can keep up on what&#x27;s new:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39688911">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39688911</a></div><br/><div id="39689168" class="c"><input type="checkbox" id="c-39689168" checked=""/><div class="controls bullet"><span class="by">thinkingemote</span><span>|</span><a href="#39689043">parent</a><span>|</span><a href="#39688441">next</a><span>|</span><label class="collapse" for="c-39689168">[-]</label><label class="expand" for="c-39689168">[1 more]</label></div><br/><div class="children"><div class="content">Search box in the bottom can help look for introduction tutorials recommendations etc</div><br/></div></div></div></div><div id="39688441" class="c"><input type="checkbox" id="c-39688441" checked=""/><div class="controls bullet"><span class="by">sharts</span><span>|</span><a href="#39689043">prev</a><span>|</span><a href="#39687920">next</a><span>|</span><label class="collapse" for="c-39688441">[-]</label><label class="expand" for="c-39688441">[1 more]</label></div><br/><div class="children"><div class="content">Not really</div><br/></div></div><div id="39687920" class="c"><input type="checkbox" id="c-39687920" checked=""/><div class="controls bullet"><span class="by">egberts1</span><span>|</span><a href="#39688441">prev</a><span>|</span><a href="#39688731">next</a><span>|</span><label class="collapse" for="c-39687920">[-]</label><label class="expand" for="c-39687920">[1 more]</label></div><br/><div class="children"><div class="content">Yep, just along as it is fed biased data, it can still reason based on faulty info.</div><br/></div></div><div id="39688161" class="c"><input type="checkbox" id="c-39688161" checked=""/><div class="controls bullet"><span class="by">zer00eyz</span><span>|</span><a href="#39688731">prev</a><span>|</span><a href="#39689121">next</a><span>|</span><label class="collapse" for="c-39688161">[-]</label><label class="expand" for="c-39688161">[1 more]</label></div><br/><div class="children"><div class="content">I...<p>&quot;It is a tale Told by an idiot, full of sound and fury Signifying nothing.&quot;<p>This is sort of water is wet kind of research. Im glad they did it but it&#x27;s not exactly moving the ball down the field.</div><br/></div></div></div></div></div></div></div></body></html>