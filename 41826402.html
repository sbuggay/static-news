<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1728896464040" as="style"/><link rel="stylesheet" href="styles.css?v=1728896464040"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://diamond-wm.github.io/">Diffusion for World Modeling</a> <span class="domain">(<a href="https://diamond-wm.github.io">diamond-wm.github.io</a>)</span></div><div class="subtext"><span>francoisfleuret</span> | <span>208 comments</span></div><br/><div><div id="41827243" class="c"><input type="checkbox" id="c-41827243" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#41826706">next</a><span>|</span><label class="collapse" for="c-41827243">[-]</label><label class="expand" for="c-41827243">[24 more]</label></div><br/><div class="children"><div class="content">This video <a href="https:&#x2F;&#x2F;x.com&#x2F;Sentdex&#x2F;status&#x2F;1845146540555243615" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;Sentdex&#x2F;status&#x2F;1845146540555243615</a> looks way too much like my dreams. This is almost exactly that happens when I sometimes try to jump high, it transforms me to a different place just like that. Things keep changing <i>just like that</i>. It&#x27;s amazing to see how close it is to a real dream experience.</div><br/><div id="41835415" class="c"><input type="checkbox" id="c-41835415" checked=""/><div class="controls bullet"><span class="by">voidUpdate</span><span>|</span><a href="#41827243">parent</a><span>|</span><a href="#41828113">next</a><span>|</span><label class="collapse" for="c-41835415">[-]</label><label class="expand" for="c-41835415">[1 more]</label></div><br/><div class="children"><div class="content">Its interesting how much dreams differ from person to person. Mine tend to be completely coherant visually, to the point that I have used google maps in my dreams, and while the geography was inaccurate, it was consistent. However, I have never been lucid within a dream, maybe that makes a difference</div><br/></div></div><div id="41828113" class="c"><input type="checkbox" id="c-41828113" checked=""/><div class="controls bullet"><span class="by">kleene_op</span><span>|</span><a href="#41827243">parent</a><span>|</span><a href="#41835415">prev</a><span>|</span><a href="#41830723">next</a><span>|</span><label class="collapse" for="c-41828113">[-]</label><label class="expand" for="c-41828113">[9 more]</label></div><br/><div class="children"><div class="content">I noticed that all text looked garbled up when I had some lucid dreams. When diffusion models started to gain attention, I made the connection that text generated in generated images also looked garbled up.<p>Maybe all of those are clues that parts of the human subconscious mind operate pretty close to the principles behind diffusion models.</div><br/><div id="41828902" class="c"><input type="checkbox" id="c-41828902" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828113">parent</a><span>|</span><a href="#41829735">next</a><span>|</span><label class="collapse" for="c-41828902">[-]</label><label class="expand" for="c-41828902">[2 more]</label></div><br/><div class="children"><div class="content">I also lucid dream occasionally. Very rarely things are very detailed, most often the colors and details are just as bleak and blurry and keep changing as these videos. I walk down a street, take a turn (or not), its almost guaranteed I can&#x27;t go back to where I came from. I usually appreciate when I can track back the same path.</div><br/><div id="41834732" class="c"><input type="checkbox" id="c-41834732" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828902">parent</a><span>|</span><a href="#41829735">next</a><span>|</span><label class="collapse" for="c-41834732">[-]</label><label class="expand" for="c-41834732">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve watched entire movies while lucid dreaming. I&#x27;ve listened to entire concerts play out, eaten entire meals with all 5 senses.<p>One of the more annoying parts of growing older was that I stopped lucid dreaming.</div><br/></div></div></div></div><div id="41829735" class="c"><input type="checkbox" id="c-41829735" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828113">parent</a><span>|</span><a href="#41828902">prev</a><span>|</span><a href="#41828283">next</a><span>|</span><label class="collapse" for="c-41829735">[-]</label><label class="expand" for="c-41829735">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think lucid dreaming is a requirement for this. Whenever I dream my environment morphs into another one, scene by scene, things I try to get details from, like the content of a text, refuse to show clearly enough to extract any meaningful information from it, no matter what I try.</div><br/></div></div><div id="41828283" class="c"><input type="checkbox" id="c-41828283" checked=""/><div class="controls bullet"><span class="by">sci_prog</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828113">parent</a><span>|</span><a href="#41829735">prev</a><span>|</span><a href="#41830723">next</a><span>|</span><label class="collapse" for="c-41828283">[-]</label><label class="expand" for="c-41828283">[5 more]</label></div><br/><div class="children"><div class="content">Also the AI generated images that can&#x27;t get the fingers right. Have you ever tried to look at your hands while lucid dreaming and try counting fingers? There are some really interesting parallels between the dreams and diffusion models.</div><br/><div id="41828605" class="c"><input type="checkbox" id="c-41828605" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828283">parent</a><span>|</span><a href="#41830723">next</a><span>|</span><label class="collapse" for="c-41828605">[-]</label><label class="expand" for="c-41828605">[4 more]</label></div><br/><div class="children"><div class="content">Of course, due to the very nature of dreams, your awareness of diffusion models and their output flavors how you perceive even past dreams.<p>Our brains love retroactively altering fuzzy memories.</div><br/><div id="41829485" class="c"><input type="checkbox" id="c-41829485" checked=""/><div class="controls bullet"><span class="by">hombre_fatal</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828605">parent</a><span>|</span><a href="#41829567">next</a><span>|</span><label class="collapse" for="c-41829485">[-]</label><label class="expand" for="c-41829485">[1 more]</label></div><br/><div class="children"><div class="content">On the other hand, psychedelics give you perceptions similar to even early deepdream genai images.<p>On LSD, I was swimming in my friend’s pool (for six hours…) amazed at all the patterns on his pool tiles underwater. I couldn’t get enough. Every tile had a different sophisticated pattern.<p>The next day I went back to his place (sober) and commented on how cool his pool tiles were. He had nfi what I was talking about.<p>I walk out to the pool and sure enough it’s just a grid of small featureless white tiles. Upon closer inspection they have a slight grain to them. I guess my brain was connecting the dots on the grain and creating patterns.<p>It was quite a trip to be so wrong about reality.<p>Not really related to your claim I guess but I haven’t thought of this story in 10 years and don’t want to delete it.</div><br/></div></div><div id="41829567" class="c"><input type="checkbox" id="c-41829567" checked=""/><div class="controls bullet"><span class="by">Jackson__</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828605">parent</a><span>|</span><a href="#41829485">prev</a><span>|</span><a href="#41830723">next</a><span>|</span><label class="collapse" for="c-41829567">[-]</label><label class="expand" for="c-41829567">[2 more]</label></div><br/><div class="children"><div class="content">This may be a joke, but counting your fingers to lucid dream has been a thing for a lot longer than diffusion models.<p>That being said, your reality will influence your dreams if you&#x27;re exposed to some things enough. I used to play minecraft on a really bad PC back in the day, and in my lucid dreams I used to encounter the same slow chunk loading as I saw in the game.</div><br/><div id="41833770" class="c"><input type="checkbox" id="c-41833770" checked=""/><div class="controls bullet"><span class="by">timschmidt</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41829567">parent</a><span>|</span><a href="#41830723">next</a><span>|</span><label class="collapse" for="c-41833770">[-]</label><label class="expand" for="c-41833770">[1 more]</label></div><br/><div class="children"><div class="content">Playing Population One in VR did this to me.  Whenever I hopped into a new game, I&#x27;d ask the other participants if they&#x27;d had particularly vivid dreams since getting VR, and more than half of folks said they had.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41830723" class="c"><input type="checkbox" id="c-41830723" checked=""/><div class="controls bullet"><span class="by">siavosh</span><span>|</span><a href="#41827243">parent</a><span>|</span><a href="#41828113">prev</a><span>|</span><a href="#41830435">next</a><span>|</span><label class="collapse" for="c-41830723">[-]</label><label class="expand" for="c-41830723">[4 more]</label></div><br/><div class="children"><div class="content">What’s amazing is that if you really start paying attention it seems like the mind is often doing the same thing when you’re awake, less noticeable with your visual field but more noticeable with attention and thoughts themselves.</div><br/><div id="41831202" class="c"><input type="checkbox" id="c-41831202" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41830723">parent</a><span>|</span><a href="#41830435">next</a><span>|</span><label class="collapse" for="c-41831202">[-]</label><label class="expand" for="c-41831202">[3 more]</label></div><br/><div class="children"><div class="content">This is a very interesting thought. I never thought of mind doing anything like that in wake state. I know I will now be thinking about this idea every time I recall those dreams.</div><br/><div id="41831690" class="c"><input type="checkbox" id="c-41831690" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41831202">parent</a><span>|</span><a href="#41830435">next</a><span>|</span><label class="collapse" for="c-41831690">[-]</label><label class="expand" for="c-41831690">[2 more]</label></div><br/><div class="children"><div class="content">Yeah I also hadn’t but it makes sense. Just like all output from an LLM is a “hallucination” but we have a tendency to only call it a hallucination when something looks wrong about the result, we forget that our conscious lived experience is a hallucination based on a bunch of abstract sensory data that our brain fuses in to a world state experience. It’s obvious when we are asleep that dreams are hallucinations, but it is less obvious that the conscious experience is too.</div><br/><div id="41834261" class="c"><input type="checkbox" id="c-41834261" checked=""/><div class="controls bullet"><span class="by">siavosh</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41831690">parent</a><span>|</span><a href="#41830435">next</a><span>|</span><label class="collapse" for="c-41834261">[-]</label><label class="expand" for="c-41834261">[1 more]</label></div><br/><div class="children"><div class="content">Agree that the whole senate field is a type of hallucination. But when it comes to thoughts appearing in our minds their transitions are much more classically hallucination like. I became aware of this during meditation. It has a strange intoxicating quality where you have to figuratively pinch yourself to notice how bizarrely one thought transitions to a thought in the periphery of your attention.</div><br/></div></div></div></div></div></div></div></div><div id="41830435" class="c"><input type="checkbox" id="c-41830435" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#41827243">parent</a><span>|</span><a href="#41830723">prev</a><span>|</span><a href="#41828835">next</a><span>|</span><label class="collapse" for="c-41830435">[-]</label><label class="expand" for="c-41830435">[1 more]</label></div><br/><div class="children"><div class="content">This is why I&#x27;m excited in a limited way. Clearly something is disconnected in a dream state that has an analogous disconnect here.<p>I think these models lack a world model, something with strong spatial reasoning and continuity expectations that animals have.<p>Of course that&#x27;s probably learned too.</div><br/></div></div><div id="41828835" class="c"><input type="checkbox" id="c-41828835" checked=""/><div class="controls bullet"><span class="by">earnesti</span><span>|</span><a href="#41827243">parent</a><span>|</span><a href="#41830435">prev</a><span>|</span><a href="#41828652">next</a><span>|</span><label class="collapse" for="c-41828835">[-]</label><label class="expand" for="c-41828835">[3 more]</label></div><br/><div class="children"><div class="content">That looks way too much to the one time I did DMT-5</div><br/><div id="41829248" class="c"><input type="checkbox" id="c-41829248" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828835">parent</a><span>|</span><a href="#41828652">next</a><span>|</span><label class="collapse" for="c-41829248">[-]</label><label class="expand" for="c-41829248">[2 more]</label></div><br/><div class="children"><div class="content">Machine Elves</div><br/><div id="41833258" class="c"><input type="checkbox" id="c-41833258" checked=""/><div class="controls bullet"><span class="by">loxias</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41829248">parent</a><span>|</span><a href="#41828652">next</a><span>|</span><label class="collapse" for="c-41833258">[-]</label><label class="expand" for="c-41833258">[1 more]</label></div><br/><div class="children"><div class="content">IYKYK</div><br/></div></div></div></div></div></div><div id="41828652" class="c"><input type="checkbox" id="c-41828652" checked=""/><div class="controls bullet"><span class="by">thegabriele</span><span>|</span><a href="#41827243">parent</a><span>|</span><a href="#41828835">prev</a><span>|</span><a href="#41833635">next</a><span>|</span><label class="collapse" for="c-41828652">[-]</label><label class="expand" for="c-41828652">[4 more]</label></div><br/><div class="children"><div class="content">We are unconsciously (pun intended) implementing how brains work both in dream and wake states.
Can&#x27;t wait until we add some kind of (lossless) memory to this models.</div><br/><div id="41828678" class="c"><input type="checkbox" id="c-41828678" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828652">parent</a><span>|</span><a href="#41828828">next</a><span>|</span><label class="collapse" for="c-41828678">[-]</label><label class="expand" for="c-41828678">[2 more]</label></div><br/><div class="children"><div class="content">Any evidence to back this lofty claim?</div><br/><div id="41830777" class="c"><input type="checkbox" id="c-41830777" checked=""/><div class="controls bullet"><span class="by">sweeter</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828678">parent</a><span>|</span><a href="#41828828">next</a><span>|</span><label class="collapse" for="c-41830777">[-]</label><label class="expand" for="c-41830777">[1 more]</label></div><br/><div class="children"><div class="content">vibes</div><br/></div></div></div></div><div id="41828828" class="c"><input type="checkbox" id="c-41828828" checked=""/><div class="controls bullet"><span class="by">soraki_soladead</span><span>|</span><a href="#41827243">root</a><span>|</span><a href="#41828652">parent</a><span>|</span><a href="#41828678">prev</a><span>|</span><a href="#41833635">next</a><span>|</span><label class="collapse" for="c-41828828">[-]</label><label class="expand" for="c-41828828">[1 more]</label></div><br/><div class="children"><div class="content">We have lossless memory for models today. That&#x27;s the training data. You could consider this the offline version of a replay buffer which is also typically lossless.<p>The online, continuous and lossy version of this problem is more like how our memory works and still largely unsolved.</div><br/></div></div></div></div><div id="41833635" class="c"><input type="checkbox" id="c-41833635" checked=""/><div class="controls bullet"><span class="by">soheil</span><span>|</span><a href="#41827243">parent</a><span>|</span><a href="#41828652">prev</a><span>|</span><a href="#41826706">next</a><span>|</span><label class="collapse" for="c-41833635">[-]</label><label class="expand" for="c-41833635">[1 more]</label></div><br/><div class="children"><div class="content">How are you so sure this is like your dreams? If it was easy to accurately remember dreams why would they be all so smooshy and such a jumbled mess like in this video?</div><br/></div></div></div></div><div id="41826706" class="c"><input type="checkbox" id="c-41826706" checked=""/><div class="controls bullet"><span class="by">francoisfleuret</span><span>|</span><a href="#41827243">prev</a><span>|</span><a href="#41827196">next</a><span>|</span><label class="collapse" for="c-41826706">[-]</label><label class="expand" for="c-41826706">[19 more]</label></div><br/><div class="children"><div class="content">This is 300M parameters model (1&#x2F;1300th of the big llama-3) trained with 5M frames with 12 days of a GTX4090.<p>This is what a big tech company was doing in 2015.<p>The same stuff at industrial scale à la large LLMs would be absolutely mind blowing.</div><br/><div id="41827672" class="c"><input type="checkbox" id="c-41827672" checked=""/><div class="controls bullet"><span class="by">gjulianm</span><span>|</span><a href="#41826706">parent</a><span>|</span><a href="#41826880">next</a><span>|</span><label class="collapse" for="c-41827672">[-]</label><label class="expand" for="c-41827672">[13 more]</label></div><br/><div class="children"><div class="content">What exactly would be the benefit of that? We already have Counter Strike working far more smooth than this, without wasting tons of compute.</div><br/><div id="41827893" class="c"><input type="checkbox" id="c-41827893" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41827672">parent</a><span>|</span><a href="#41829623">next</a><span>|</span><label class="collapse" for="c-41827893">[-]</label><label class="expand" for="c-41827893">[5 more]</label></div><br/><div class="children"><div class="content">As with diffusion models in general, the point isn&#x27;t the specific example but that it&#x27;s generalisable.<p>5 million frames of video data with corresponding accelerometer data, and you get this for genuine photorealism.</div><br/><div id="41829697" class="c"><input type="checkbox" id="c-41829697" checked=""/><div class="controls bullet"><span class="by">gjulianm</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41827893">parent</a><span>|</span><a href="#41829623">next</a><span>|</span><label class="collapse" for="c-41829697">[-]</label><label class="expand" for="c-41829697">[4 more]</label></div><br/><div class="children"><div class="content">Generalisable how? The model completely hallucinates invalid input, it&#x27;s not even high quality and required CSGO to work. What&#x27;s the output you expect from this and what alternatives are there?</div><br/><div id="41832597" class="c"><input type="checkbox" id="c-41832597" checked=""/><div class="controls bullet"><span class="by">Art9681</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41829697">parent</a><span>|</span><a href="#41830531">next</a><span>|</span><label class="collapse" for="c-41832597">[-]</label><label class="expand" for="c-41832597">[1 more]</label></div><br/><div class="children"><div class="content">None of those questions are relevant are they? I get the impression you&#x27;ve already decided this isnt good enough, which is basically agreeing with everyone else. No one is talking about what it&#x27;s capable of today. Read the thread again. We&#x27;re imagining the great probability a few permutations later this thing will basically be The Matrix.</div><br/></div></div><div id="41830531" class="c"><input type="checkbox" id="c-41830531" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41829697">parent</a><span>|</span><a href="#41832597">prev</a><span>|</span><a href="#41831640">next</a><span>|</span><label class="collapse" for="c-41830531">[-]</label><label class="expand" for="c-41830531">[1 more]</label></div><br/><div class="children"><div class="content">It did not <i>require</i> CSGO, that  was simply one of their examples. The very first video in the link shows a bunch of classic Arati games, and even the video which is showing CSGO is captioned &quot;DIAMOND&#x27;s diffusion world model can also be trained to simulate 3D environments, such as CounterStrike: Global Offensive (CSGO)&quot; — I draw your attention to &quot;such as&quot; being used rather than &quot;only&quot;.<p>And I thought I was fairly explicit about video data, but just in case that&#x27;s ambiguous: the stuff you record with your phone camera set to video mode, synchronised with the accelerometer data instead of player keyboard inputs.<p>As for output, with the model as it currently stands, I&#x27;d expect a 24h training video at 60fps to be &quot;photorealisic and with similar weird hallucinations&quot;. Which is still interesting, even without combining this with a control net like Stable Diffusion can do.</div><br/></div></div><div id="41831640" class="c"><input type="checkbox" id="c-41831640" checked=""/><div class="controls bullet"><span class="by">empath75</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41829697">parent</a><span>|</span><a href="#41830531">prev</a><span>|</span><a href="#41829623">next</a><span>|</span><label class="collapse" for="c-41831640">[-]</label><label class="expand" for="c-41831640">[1 more]</label></div><br/><div class="children"><div class="content">You do the same thing at a larger scale, and instead of video game footage you use a few million hours of remote controlled drone input in the real world.</div><br/></div></div></div></div></div></div><div id="41829623" class="c"><input type="checkbox" id="c-41829623" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41827672">parent</a><span>|</span><a href="#41827893">prev</a><span>|</span><a href="#41828218">next</a><span>|</span><label class="collapse" for="c-41829623">[-]</label><label class="expand" for="c-41829623">[5 more]</label></div><br/><div class="children"><div class="content">To answer your question directly, the benefit is that we could make something different from counter strike.<p>You see, there are these things called &quot;proof of concept&quot;s that are meant to not be a product, but instead show off capabilities.<p>Counterstrike is an example, meant to show off complex capabilities. It is not meant to show how the useful thing of these models is to literally recreate counterstrike.</div><br/><div id="41829733" class="c"><input type="checkbox" id="c-41829733" checked=""/><div class="controls bullet"><span class="by">gjulianm</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41829623">parent</a><span>|</span><a href="#41828218">next</a><span>|</span><label class="collapse" for="c-41829733">[-]</label><label class="expand" for="c-41829733">[4 more]</label></div><br/><div class="children"><div class="content">Which capabilities are being shown off here? The ability to take an already existing world-model and take lots of compute to have a worse, less correct model?</div><br/><div id="41830731" class="c"><input type="checkbox" id="c-41830731" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41829733">parent</a><span>|</span><a href="#41832058">prev</a><span>|</span><a href="#41828218">next</a><span>|</span><label class="collapse" for="c-41830731">[-]</label><label class="expand" for="c-41830731">[2 more]</label></div><br/><div class="children"><div class="content">The capability to have mostly working, real time generation of images that represent a world model.<p>If that capability is possible, then it could be possible to take 100 examples of seperate world models that exist, and then combine those world models together in interesting ways.<p>Combining together world models is an obvious next step (IE, not showed off in this proof of concept.  But it is a logical&#x2F;plausible future capability).<p>Having multiple world models combined together in new and interesting ways, is almost like creating an entirely new world model, even though thats not exactly the same.</div><br/><div id="41834927" class="c"><input type="checkbox" id="c-41834927" checked=""/><div class="controls bullet"><span class="by">6r17</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41830731">parent</a><span>|</span><a href="#41828218">next</a><span>|</span><label class="collapse" for="c-41834927">[-]</label><label class="expand" for="c-41834927">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;d have to have the rights to do the training wouldn&#x27;t you ? Or does that mean I should close off all of my creations legally just so you can&#x27;t use them ?<p>I don&#x27;t have a problem with you using this with a Camera and the real world or your creations ; but I do have a problem when people are able to use someone&#x27;s work and use these blend and call them original.<p>It&#x27;s just as I would have taken a 3d model static mesh, apply some blend on it and call it my own.<p>No it&#x27;s f* not.</div><br/></div></div></div></div></div></div></div></div><div id="41828218" class="c"><input type="checkbox" id="c-41828218" checked=""/><div class="controls bullet"><span class="by">nuz</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41827672">parent</a><span>|</span><a href="#41829623">prev</a><span>|</span><a href="#41827875">next</a><span>|</span><label class="collapse" for="c-41828218">[-]</label><label class="expand" for="c-41828218">[1 more]</label></div><br/><div class="children"><div class="content">&quot;What would be the point of creating a shooter set in the middle east? We already have pong and donkey kong&quot;</div><br/></div></div><div id="41827875" class="c"><input type="checkbox" id="c-41827875" checked=""/><div class="controls bullet"><span class="by">eproxus</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41827672">parent</a><span>|</span><a href="#41828218">prev</a><span>|</span><a href="#41826880">next</a><span>|</span><label class="collapse" for="c-41827875">[-]</label><label class="expand" for="c-41827875">[1 more]</label></div><br/><div class="children"><div class="content">But please, think of the shareholders!</div><br/></div></div></div></div><div id="41826880" class="c"><input type="checkbox" id="c-41826880" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41826706">parent</a><span>|</span><a href="#41827672">prev</a><span>|</span><a href="#41829829">next</a><span>|</span><label class="collapse" for="c-41826880">[-]</label><label class="expand" for="c-41826880">[2 more]</label></div><br/><div class="children"><div class="content">If 12 days with an RTX4090 is all you need, some random people on the Internet will soon start training their own.</div><br/></div></div><div id="41829829" class="c"><input type="checkbox" id="c-41829829" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#41826706">parent</a><span>|</span><a href="#41826880">prev</a><span>|</span><a href="#41827267">next</a><span>|</span><label class="collapse" for="c-41829829">[-]</label><label class="expand" for="c-41829829">[1 more]</label></div><br/><div class="children"><div class="content">Came here to say pretty much the same thing, and saw your comment.<p>The rate of progress has been mind-blowing indeed.<p>We sure live in interesting times!</div><br/></div></div><div id="41827267" class="c"><input type="checkbox" id="c-41827267" checked=""/><div class="controls bullet"><span class="by">Sardtok</span><span>|</span><a href="#41826706">parent</a><span>|</span><a href="#41829829">prev</a><span>|</span><a href="#41827196">next</a><span>|</span><label class="collapse" for="c-41827267">[-]</label><label class="expand" for="c-41827267">[2 more]</label></div><br/><div class="children"><div class="content">Two 4090s, but yeah.</div><br/><div id="41827311" class="c"><input type="checkbox" id="c-41827311" checked=""/><div class="controls bullet"><span class="by">Sardtok</span><span>|</span><a href="#41826706">root</a><span>|</span><a href="#41827267">parent</a><span>|</span><a href="#41827196">next</a><span>|</span><label class="collapse" for="c-41827311">[-]</label><label class="expand" for="c-41827311">[1 more]</label></div><br/><div class="children"><div class="content">Never mind, the repo on Github says 12 days on a 4090, so I&#x27;m unsure why the title here says two.</div><br/></div></div></div></div></div></div><div id="41827196" class="c"><input type="checkbox" id="c-41827196" checked=""/><div class="controls bullet"><span class="by">marcyb5st</span><span>|</span><a href="#41826706">prev</a><span>|</span><a href="#41826630">next</a><span>|</span><label class="collapse" for="c-41827196">[-]</label><label class="expand" for="c-41827196">[32 more]</label></div><br/><div class="children"><div class="content">So, this is pretty exciting.<p>I can how this can already be used to generate realistic physics approximations in a game engine. You create a bunch of snippets of gameplay using a much heavier and realistic physics engine (perhaps even CGI). The model learn to approximate the physics and boom, now you have a lightweight physics engine. Perhaps you can even have several that are specialized (e.g. one for smoke dynamics, one for explosions, ...). Even if it allucinates, wouldn&#x27;t be worse than the physics bugs that are so common in games.</div><br/><div id="41827252" class="c"><input type="checkbox" id="c-41827252" checked=""/><div class="controls bullet"><span class="by">monsieurbanana</span><span>|</span><a href="#41827196">parent</a><span>|</span><a href="#41829480">next</a><span>|</span><label class="collapse" for="c-41827252">[-]</label><label class="expand" for="c-41827252">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Even if it allucinates, wouldn&#x27;t be worse than the physics bugs that are so common in games.<p>I don&#x27;t know about that. Physic bugs are common, but you can prioritize and fix the worst (gamebreaking) ones. If you have a blackbox model, it becomes much harder to do that.</div><br/></div></div><div id="41829480" class="c"><input type="checkbox" id="c-41829480" checked=""/><div class="controls bullet"><span class="by">bobsomers</span><span>|</span><a href="#41827196">parent</a><span>|</span><a href="#41827252">prev</a><span>|</span><a href="#41827839">next</a><span>|</span><label class="collapse" for="c-41829480">[-]</label><label class="expand" for="c-41829480">[2 more]</label></div><br/><div class="children"><div class="content">What makes you think the network inference is less expensive? Newtonian physics is already extremely well known and pretty computationally efficient to compute.<p>How would a &quot;function approximation&quot; of Newtonian physics, with billions of parameters, be cheaper to compute?<p>It seems like this would both be more expensive and less correct than a proper physics simulation.</div><br/><div id="41833104" class="c"><input type="checkbox" id="c-41833104" checked=""/><div class="controls bullet"><span class="by">crackalamoo</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41829480">parent</a><span>|</span><a href="#41827839">next</a><span>|</span><label class="collapse" for="c-41833104">[-]</label><label class="expand" for="c-41833104">[1 more]</label></div><br/><div class="children"><div class="content">Basic Newtonian physics is pretty efficient to compute, but afaik some more complex physics like fluids is faster with network inference. There are probably a lot of cases where network inference physics is faster.</div><br/></div></div></div></div><div id="41827839" class="c"><input type="checkbox" id="c-41827839" checked=""/><div class="controls bullet"><span class="by">twic</span><span>|</span><a href="#41827196">parent</a><span>|</span><a href="#41829480">prev</a><span>|</span><a href="#41827724">next</a><span>|</span><label class="collapse" for="c-41827839">[-]</label><label class="expand" for="c-41827839">[5 more]</label></div><br/><div class="children"><div class="content">Do you think that inference on a thirteen million parameter neural network is more lightweight than running a conventional physics engine?</div><br/><div id="41828529" class="c"><input type="checkbox" id="c-41828529" checked=""/><div class="controls bullet"><span class="by">procgen</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827839">parent</a><span>|</span><a href="#41829335">next</a><span>|</span><label class="collapse" for="c-41828529">[-]</label><label class="expand" for="c-41828529">[1 more]</label></div><br/><div class="children"><div class="content">Convincing liquid physics (e.g. surf interacting with a beach, rocks, the player character) might be a good candidate.</div><br/></div></div><div id="41829335" class="c"><input type="checkbox" id="c-41829335" checked=""/><div class="controls bullet"><span class="by">tiagod</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827839">parent</a><span>|</span><a href="#41828529">prev</a><span>|</span><a href="#41827901">next</a><span>|</span><label class="collapse" for="c-41829335">[-]</label><label class="expand" for="c-41829335">[1 more]</label></div><br/><div class="children"><div class="content">In some cases, the model will be lighter. There is no need for 14M parameters for physics simulations, and there&#x27;s a lot of promising work in that area.</div><br/></div></div><div id="41827901" class="c"><input type="checkbox" id="c-41827901" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827839">parent</a><span>|</span><a href="#41829335">prev</a><span>|</span><a href="#41827724">next</a><span>|</span><label class="collapse" for="c-41827901">[-]</label><label class="expand" for="c-41827901">[2 more]</label></div><br/><div class="children"><div class="content">Every software that can be implemented in a JavaScript, ehm, LLM, will eventually be implemented in an LLM.</div><br/><div id="41828682" class="c"><input type="checkbox" id="c-41828682" checked=""/><div class="controls bullet"><span class="by">kendalf89</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827901">parent</a><span>|</span><a href="#41827724">next</a><span>|</span><label class="collapse" for="c-41828682">[-]</label><label class="expand" for="c-41828682">[1 more]</label></div><br/><div class="children"><div class="content">Are you predicting node.llm right now?</div><br/></div></div></div></div></div></div><div id="41827724" class="c"><input type="checkbox" id="c-41827724" checked=""/><div class="controls bullet"><span class="by">Thorrez</span><span>|</span><a href="#41827196">parent</a><span>|</span><a href="#41827839">prev</a><span>|</span><a href="#41829621">next</a><span>|</span><label class="collapse" for="c-41827724">[-]</label><label class="expand" for="c-41827724">[2 more]</label></div><br/><div class="children"><div class="content">Would that work for multiplayer? If it&#x27;s a visual effect only, I guess it would be ok. But if it affects gameplay, wouldn&#x27;t different players get different results?</div><br/><div id="41827820" class="c"><input type="checkbox" id="c-41827820" checked=""/><div class="controls bullet"><span class="by">killerstorm</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827724">parent</a><span>|</span><a href="#41829621">next</a><span>|</span><label class="collapse" for="c-41827820">[-]</label><label class="expand" for="c-41827820">[1 more]</label></div><br/><div class="children"><div class="content">Well, it doesn&#x27;t make sense to use this exact model - this is just demonstration that it can learn world model from pixels.<p>An obvious next step towards a more playable game is to add state vector to the inputs of the model: it is easier to learn to render the world from pixels + state vectors than from pixels alone.<p>Then it depends what we want to do. If we want normal Counter Strike gameplay but with new graphics, we can keep existing CS game server and train only the rendering part.<p>If you want to make Dream-Counter-Strike where rules are more bendable then you might want to train state update model...</div><br/></div></div></div></div><div id="41829621" class="c"><input type="checkbox" id="c-41829621" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41827196">parent</a><span>|</span><a href="#41827724">prev</a><span>|</span><a href="#41828941">next</a><span>|</span><label class="collapse" for="c-41829621">[-]</label><label class="expand" for="c-41829621">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, I definitely wouldn&#x27;t trust it to replace basic physics of running, jumping, bullets, objects shattering, etc.<p>But it seems extremely promising for fiery explosions, smoke, and <i>especially</i> water. Anything with dynamics that are essentially complex.<p>Also for lighting -- both to get things like skin right with subsurface scattering, as well as global ray-traced lighting.<p>You can train specific lightweight models for these things, and they important thing is that their output is correct at the macro level. E.g., a tree should be casting a shadow that looks like the right shadow at the right angle for that type of tree and its types of leaves and general shape. Nobody cares if each individual leaf shadow corresponds to an individual leaf 10 feet above or is just hallucinated.</div><br/><div id="41833667" class="c"><input type="checkbox" id="c-41833667" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41829621">parent</a><span>|</span><a href="#41828941">next</a><span>|</span><label class="collapse" for="c-41833667">[-]</label><label class="expand" for="c-41833667">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking it would be especially effective for situations where one needed to predict the behavior of a chaotic system, not so much accurately but convincingly. Turbulence flow would be an irreducible system right?</div><br/></div></div></div></div><div id="41828941" class="c"><input type="checkbox" id="c-41828941" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#41827196">parent</a><span>|</span><a href="#41829621">prev</a><span>|</span><a href="#41833112">next</a><span>|</span><label class="collapse" for="c-41828941">[-]</label><label class="expand" for="c-41828941">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  boom, now you have a lightweight physics engine<p>lightweight, but producing several hundred watts of heat.</div><br/></div></div><div id="41833112" class="c"><input type="checkbox" id="c-41833112" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#41827196">parent</a><span>|</span><a href="#41828941">prev</a><span>|</span><a href="#41827216">next</a><span>|</span><label class="collapse" for="c-41833112">[-]</label><label class="expand" for="c-41833112">[1 more]</label></div><br/><div class="children"><div class="content">Define &quot;lightweight&quot;.</div><br/></div></div><div id="41827216" class="c"><input type="checkbox" id="c-41827216" checked=""/><div class="controls bullet"><span class="by">hobs</span><span>|</span><a href="#41827196">parent</a><span>|</span><a href="#41833112">prev</a><span>|</span><a href="#41826630">next</a><span>|</span><label class="collapse" for="c-41827216">[-]</label><label class="expand" for="c-41827216">[17 more]</label></div><br/><div class="children"><div class="content">A physics bug would be a consistent problem you can fix. 
There&#x27;s no such guarantee about an ML model. 
This would likely only be ok in the context of a game specifically made to be janky.</div><br/><div id="41827270" class="c"><input type="checkbox" id="c-41827270" checked=""/><div class="controls bullet"><span class="by">fullstackwife</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827216">parent</a><span>|</span><a href="#41827261">next</a><span>|</span><label class="collapse" for="c-41827270">[-]</label><label class="expand" for="c-41827270">[6 more]</label></div><br/><div class="children"><div class="content">This is one of the fallacies of current AI research space: they don&#x27;t focus on the end-user too much. In this case the end-user would be the gamer, and while playing games you expect a valid gameplay, so those kind of hallucinations are not acceptable, while I&#x27;m pretty sure they give the AI research authors a strong dopamine trigger. We have a hammer and now we are looking for a nail, while you should ask a question first: what is the problem we are trying to solve here?<p>Real world usage will be probably different, and maybe even unexpected by the authors of this research.</div><br/><div id="41827310" class="c"><input type="checkbox" id="c-41827310" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827270">parent</a><span>|</span><a href="#41829591">next</a><span>|</span><label class="collapse" for="c-41827310">[-]</label><label class="expand" for="c-41827310">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is one of the fallacies of current AI research space: they don&#x27;t focus on the end-user too much. In this case the end-user would be the gamer<p>Or from another angle the end-user is a game developer trying to actually work with this kind of technology, which is just a nightmarish prospect. Nobody in the industry is asking for a game engine that runs entirely on vibes and dream logic, gamedev is already chaotic enough when everything is laid out in explicit code and data.</div><br/></div></div><div id="41829591" class="c"><input type="checkbox" id="c-41829591" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827270">parent</a><span>|</span><a href="#41827310">prev</a><span>|</span><a href="#41827651">next</a><span>|</span><label class="collapse" for="c-41829591">[-]</label><label class="expand" for="c-41829591">[1 more]</label></div><br/><div class="children"><div class="content">&gt; they don&#x27;t focus on the end-user too much.<p>Of course they don&#x27;t. Stuff like this is a proof of concept.<p>If they had a product that worked, they wouldn&#x27;t be in academia. Instead, they would leave the world of research and create a multi billion dollar company.<p>Almost by definition, anything in academia isn&#x27;t going to be productized, because if it was, then the researchers would just stop researching and make a bunch of money selling the product to consumers.<p>Such research is still useful for society, though, as it means that someone else can spend the millions and millions of dollars making a better version and then selling that.</div><br/></div></div><div id="41827651" class="c"><input type="checkbox" id="c-41827651" checked=""/><div class="controls bullet"><span class="by">badpun</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827270">parent</a><span>|</span><a href="#41829591">prev</a><span>|</span><a href="#41827261">next</a><span>|</span><label class="collapse" for="c-41827651">[-]</label><label class="expand" for="c-41827651">[3 more]</label></div><br/><div class="children"><div class="content">The whole purpose of academia is literally to nerd out on cool, impractical things, which will ocasionally turn out to have some real-life relevance years or decades later. This (hallucinated CS) is still more relevant to real world than 99% of what happens in academic research.</div><br/><div id="41828624" class="c"><input type="checkbox" id="c-41828624" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827651">parent</a><span>|</span><a href="#41827261">next</a><span>|</span><label class="collapse" for="c-41828624">[-]</label><label class="expand" for="c-41828624">[2 more]</label></div><br/><div class="children"><div class="content">Yes to the first part, no to the random “99% useless” number you made up.<p>I’m no fan of academia, but it undeniably produces useful and meaningful knowledge regularly.</div><br/><div id="41834771" class="c"><input type="checkbox" id="c-41834771" checked=""/><div class="controls bullet"><span class="by">badpun</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41828624">parent</a><span>|</span><a href="#41827261">next</a><span>|</span><label class="collapse" for="c-41834771">[-]</label><label class="expand" for="c-41834771">[1 more]</label></div><br/><div class="children"><div class="content">You made up the &quot;99% useless&quot; straw man, I never used the word useless in my post. I merely said that the AI research is more relevant than 99% of research, which includes things like gender studies, studies of Rennaisance German theatre, discussions of which exact villages were pillaged and in what order during the march of some army 300 years ago etc. etc.</div><br/></div></div></div></div></div></div></div></div><div id="41827261" class="c"><input type="checkbox" id="c-41827261" checked=""/><div class="controls bullet"><span class="by">kqr</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827216">parent</a><span>|</span><a href="#41827270">prev</a><span>|</span><a href="#41826630">next</a><span>|</span><label class="collapse" for="c-41827261">[-]</label><label class="expand" for="c-41827261">[10 more]</label></div><br/><div class="children"><div class="content">This obsession people have with determinism! I&#x27;d much rather take a low rate of weird bugs than common consistent ones. I don&#x27;t believe reproducibility of bugs makes for better gameplay generally.</div><br/><div id="41827637" class="c"><input type="checkbox" id="c-41827637" checked=""/><div class="controls bullet"><span class="by">paulryanrogers</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827261">parent</a><span>|</span><a href="#41827787">next</a><span>|</span><label class="collapse" for="c-41827637">[-]</label><label class="expand" for="c-41827637">[2 more]</label></div><br/><div class="children"><div class="content">Reproducibility does make bugs more likely to be fixed, or at least fixable.<p>Also, games introduce randomness in a controlled way so users don&#x27;t get frustrated by it appearing in unexpected places. I don&#x27;t want characters to randomly appear and disappear. It&#x27;s fine if bullet trajectory varies more randomly as they get further away.</div><br/><div id="41828499" class="c"><input type="checkbox" id="c-41828499" checked=""/><div class="controls bullet"><span class="by">skydhash</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827637">parent</a><span>|</span><a href="#41827787">next</a><span>|</span><label class="collapse" for="c-41828499">[-]</label><label class="expand" for="c-41828499">[1 more]</label></div><br/><div class="children"><div class="content">Also most engines have been worked on for years. So more often than not, core elements like audio, physics, input,... are very stable and the remaining bugs are either &quot;can&#x27;t fix&quot; or &quot;won&#x27;t fix&quot;.</div><br/></div></div></div></div><div id="41827787" class="c"><input type="checkbox" id="c-41827787" checked=""/><div class="controls bullet"><span class="by">NotMichaelBay</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827261">parent</a><span>|</span><a href="#41827637">prev</a><span>|</span><a href="#41827974">next</a><span>|</span><label class="collapse" for="c-41827787">[-]</label><label class="expand" for="c-41827787">[3 more]</label></div><br/><div class="children"><div class="content">It might be fine for casual players, but it would prevent serious and pro players from getting into the game. In Counter-Strike, for example, pro players (and other serious players) practice specific grenade throws so they can use them reliably in matches.</div><br/><div id="41827818" class="c"><input type="checkbox" id="c-41827818" checked=""/><div class="controls bullet"><span class="by">kqr</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827787">parent</a><span>|</span><a href="#41827974">next</a><span>|</span><label class="collapse" for="c-41827818">[-]</label><label class="expand" for="c-41827818">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not saying one can make specifically Counter-Strike on a non-deterministic engine -- that seems like strawmanning my argument.<p>People play and enjoy many games with varying levels of randomness as a fundamental component, some even professionally (poker, stock market). This could be made such a game.</div><br/><div id="41828183" class="c"><input type="checkbox" id="c-41828183" checked=""/><div class="controls bullet"><span class="by">monsieurbanana</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827818">parent</a><span>|</span><a href="#41827974">next</a><span>|</span><label class="collapse" for="c-41828183">[-]</label><label class="expand" for="c-41828183">[1 more]</label></div><br/><div class="children"><div class="content">Either the physics engine matter, in which case you want a deterministic engine as you said, or it doesn&#x27;t like in a poker game and you don&#x27;t want to spend much resources (manpower, computer cycles) into it.<p>Which also means an off-the-shelf deterministic engine.</div><br/></div></div></div></div></div></div><div id="41827974" class="c"><input type="checkbox" id="c-41827974" checked=""/><div class="controls bullet"><span class="by">mrob</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827261">parent</a><span>|</span><a href="#41827787">prev</a><span>|</span><a href="#41828639">next</a><span>|</span><label class="collapse" for="c-41827974">[-]</label><label class="expand" for="c-41827974">[1 more]</label></div><br/><div class="children"><div class="content">The whole hobby of speedrunning relies heavily on exploiting deterministic game bugs.</div><br/></div></div><div id="41828639" class="c"><input type="checkbox" id="c-41828639" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827261">parent</a><span>|</span><a href="#41827974">prev</a><span>|</span><a href="#41828586">next</a><span>|</span><label class="collapse" for="c-41828639">[-]</label><label class="expand" for="c-41828639">[1 more]</label></div><br/><div class="children"><div class="content">You don’t play a lot of games, huh?<p>Consistent bugs you can anticipate and play&#x2F;work around, random ones you can’t. Just look at pretty much any speed running community for games before 1995.<p>Say goodbye to any real competitive scene with random unfixable potentially one off bugs.</div><br/></div></div><div id="41828586" class="c"><input type="checkbox" id="c-41828586" checked=""/><div class="controls bullet"><span class="by">hobs</span><span>|</span><a href="#41827196">root</a><span>|</span><a href="#41827261">parent</a><span>|</span><a href="#41828639">prev</a><span>|</span><a href="#41830030">next</a><span>|</span><label class="collapse" for="c-41828586">[-]</label><label class="expand" for="c-41828586">[1 more]</label></div><br/><div class="children"><div class="content">Make a fun game with this as a premise and I will try it, but it sounds just an annoying concept.</div><br/></div></div></div></div></div></div></div></div><div id="41826630" class="c"><input type="checkbox" id="c-41826630" checked=""/><div class="controls bullet"><span class="by">croo</span><span>|</span><a href="#41827196">prev</a><span>|</span><a href="#41826976">next</a><span>|</span><label class="collapse" for="c-41826630">[-]</label><label class="expand" for="c-41826630">[12 more]</label></div><br/><div class="children"><div class="content">For anyone who actually tried it :<p>Does it respects&#x2F;builds some kind of game map in the process or is it just a bizarre psychedelic dream walk experience where you cannot go back the same place twice and space dimensions are just funny? Is a game map finite?</div><br/><div id="41827104" class="c"><input type="checkbox" id="c-41827104" checked=""/><div class="controls bullet"><span class="by">InsideOutSanta</span><span>|</span><a href="#41826630">parent</a><span>|</span><a href="#41826756">next</a><span>|</span><label class="collapse" for="c-41827104">[-]</label><label class="expand" for="c-41827104">[2 more]</label></div><br/><div class="children"><div class="content">Just looking at the first video, there&#x27;s a section where structures just suddenly appear in front of the player, so this does not appear to build any kind of map, or have any kind of meaningful awareness of something resembling a game state.<p>This is similar to LLM-based RPGs I&#x27;ve played, where you can pick up a sword and put it in your empty bag, and then pull out a loaf of bread and eat it.</div><br/><div id="41827119" class="c"><input type="checkbox" id="c-41827119" checked=""/><div class="controls bullet"><span class="by">anal_reactor</span><span>|</span><a href="#41826630">root</a><span>|</span><a href="#41827104">parent</a><span>|</span><a href="#41826756">next</a><span>|</span><label class="collapse" for="c-41827119">[-]</label><label class="expand" for="c-41827119">[1 more]</label></div><br/><div class="children"><div class="content">&gt; you can pick up a sword and put it in your empty bag, and then pull out a loaf of bread and eat it<p>Mondays</div><br/></div></div></div></div><div id="41826756" class="c"><input type="checkbox" id="c-41826756" checked=""/><div class="controls bullet"><span class="by">aidos</span><span>|</span><a href="#41826630">parent</a><span>|</span><a href="#41827104">prev</a><span>|</span><a href="#41826754">next</a><span>|</span><label class="collapse" for="c-41826756">[-]</label><label class="expand" for="c-41826756">[4 more]</label></div><br/><div class="children"><div class="content">Just skimmed the article but my guess is that it’s a dream type experience where if you turned around 180 and walked the other direction it wouldn’t correspond to where you just came from. More like an infinite map.</div><br/><div id="41827367" class="c"><input type="checkbox" id="c-41827367" checked=""/><div class="controls bullet"><span class="by">lopuhin</span><span>|</span><a href="#41826630">root</a><span>|</span><a href="#41826756">parent</a><span>|</span><a href="#41826754">next</a><span>|</span><label class="collapse" for="c-41827367">[-]</label><label class="expand" for="c-41827367">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think so, what they show on CS video is exactly the Dust2 map, not just something similar&#x2F;inspired by it.</div><br/><div id="41827765" class="c"><input type="checkbox" id="c-41827765" checked=""/><div class="controls bullet"><span class="by">twic</span><span>|</span><a href="#41826630">root</a><span>|</span><a href="#41827367">parent</a><span>|</span><a href="#41828310">next</a><span>|</span><label class="collapse" for="c-41827765">[-]</label><label class="expand" for="c-41827765">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s trained on moving around dust2, so as long as the previous frame was a view of dust2, the next frame is very likely to be a plausible subsequent view of dust2. In some sense, this encodes a map; but it&#x27;s not what most people think of when they think about maps.<p>I&#x27;d be interested to see what happens if you look down at your feet for a while, then back up. If the ground looks the same everywhere, do you come up in a random place?</div><br/></div></div><div id="41828310" class="c"><input type="checkbox" id="c-41828310" checked=""/><div class="controls bullet"><span class="by">arendtio</span><span>|</span><a href="#41826630">root</a><span>|</span><a href="#41827367">parent</a><span>|</span><a href="#41827765">prev</a><span>|</span><a href="#41826754">next</a><span>|</span><label class="collapse" for="c-41828310">[-]</label><label class="expand" for="c-41828310">[1 more]</label></div><br/><div class="children"><div class="content">It probably depends on what you see. As long as you have a broad view over a part of the map, you should stay in that region, but I guess that if you look at a mono-color wall, you probably find yourself in a very different part of the map when you look around yourself again.<p>But I am just guessing, and I haven&#x27;t tried it yet.</div><br/></div></div></div></div></div></div><div id="41826754" class="c"><input type="checkbox" id="c-41826754" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#41826630">parent</a><span>|</span><a href="#41826756">prev</a><span>|</span><a href="#41826976">next</a><span>|</span><label class="collapse" for="c-41826754">[-]</label><label class="expand" for="c-41826754">[5 more]</label></div><br/><div class="children"><div class="content">Just tried it out, and no. It doesn&#x27;t have any sort of &quot;map&quot; awareness. It&#x27;s very much in the &quot;recall&#x2F;replay&quot; category of &quot;AI&quot; where it seems to accurately recall stuff that is part of the training dataset, but as soon as you do something not in there (like walk into a wall), it completely freaks out and spits out gibberish. Plausible gibberish, but gibberish none the less.</div><br/><div id="41826805" class="c"><input type="checkbox" id="c-41826805" checked=""/><div class="controls bullet"><span class="by">neongreen</span><span>|</span><a href="#41826630">root</a><span>|</span><a href="#41826754">parent</a><span>|</span><a href="#41827273">next</a><span>|</span><label class="collapse" for="c-41826805">[-]</label><label class="expand" for="c-41826805">[1 more]</label></div><br/><div class="children"><div class="content">Can you upload a screen recording? I don’t think I can run the model locally but it’d be super interesting to see what happens if you run into a wall</div><br/></div></div><div id="41827273" class="c"><input type="checkbox" id="c-41827273" checked=""/><div class="controls bullet"><span class="by">kqr</span><span>|</span><a href="#41826630">root</a><span>|</span><a href="#41826754">parent</a><span>|</span><a href="#41826805">prev</a><span>|</span><a href="#41826976">next</a><span>|</span><label class="collapse" for="c-41827273">[-]</label><label class="expand" for="c-41827273">[3 more]</label></div><br/><div class="children"><div class="content">This should mainly be a matter of giving it more training though, right? It sounds like to amount of training it&#x27;s gotten is relatively sparse.</div><br/><div id="41827928" class="c"><input type="checkbox" id="c-41827928" checked=""/><div class="controls bullet"><span class="by">treyd</span><span>|</span><a href="#41826630">root</a><span>|</span><a href="#41827273">parent</a><span>|</span><a href="#41829876">next</a><span>|</span><label class="collapse" for="c-41827928">[-]</label><label class="expand" for="c-41827928">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t have any ability to reason about what you did more than a couple of seconds ago.  Its memory is what&#x27;s currently on the screen and what the user&#x27;s last few inputs were.</div><br/></div></div><div id="41829876" class="c"><input type="checkbox" id="c-41829876" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#41826630">root</a><span>|</span><a href="#41827273">parent</a><span>|</span><a href="#41827928">prev</a><span>|</span><a href="#41826976">next</a><span>|</span><label class="collapse" for="c-41829876">[-]</label><label class="expand" for="c-41829876">[1 more]</label></div><br/><div class="children"><div class="content">Theoretically. In practice, that&#x27;s not clear. As you add more training data you have to ask yourself what the point is. we already have a pretty good simulation of Counter Strike.</div><br/></div></div></div></div></div></div></div></div><div id="41826976" class="c"><input type="checkbox" id="c-41826976" checked=""/><div class="controls bullet"><span class="by">jmchambers</span><span>|</span><a href="#41826630">prev</a><span>|</span><a href="#41826654">next</a><span>|</span><label class="collapse" for="c-41826976">[-]</label><label class="expand" for="c-41826976">[14 more]</label></div><br/><div class="children"><div class="content">I _think_ I understand the basic premise behind stable diffusion, i.e., reverse the denoising process to generate realistic images but, as far as I know, this is always done at the pixel level. Is there any research attempting to do this at the 3D asset level, i.e., subbing in game engine assets (with position and orientation) until a plausible scene is recreated? If it were possible to do it that way, couldn&#x27;t it &quot;dream&quot; up real maps, with real physics, and so avoid the somewhat noisy output these types of demo generate?</div><br/><div id="41827006" class="c"><input type="checkbox" id="c-41827006" checked=""/><div class="controls bullet"><span class="by">desdenova</span><span>|</span><a href="#41826976">parent</a><span>|</span><a href="#41830578">next</a><span>|</span><label class="collapse" for="c-41827006">[-]</label><label class="expand" for="c-41827006">[6 more]</label></div><br/><div class="children"><div class="content">I think the closest we have right now is 3D gaussian splatting.<p>So far it&#x27;s only been used to train a scene from photographs from multiple angles and rebuild it volumetrically by adjusting densities in a point-cloud.<p>But it might be possible to train a model on multiple different scenes, and perform diffusion on a random point cloud to generate new scenes.<p>Rendering a point cloud in real time is also very efficient, so it could be used to create insanely realistic game worlds instead of polygonal geometry.<p>It seems someone already thought of that: <a href="https:&#x2F;&#x2F;ar5iv.labs.arxiv.org&#x2F;html&#x2F;2311.11221" rel="nofollow">https:&#x2F;&#x2F;ar5iv.labs.arxiv.org&#x2F;html&#x2F;2311.11221</a></div><br/><div id="41827125" class="c"><input type="checkbox" id="c-41827125" checked=""/><div class="controls bullet"><span class="by">jmchambers</span><span>|</span><a href="#41826976">root</a><span>|</span><a href="#41827006">parent</a><span>|</span><a href="#41828491">next</a><span>|</span><label class="collapse" for="c-41827125">[-]</label><label class="expand" for="c-41827125">[2 more]</label></div><br/><div class="children"><div class="content">Interesting, I guess that takes things even further and removes the need for hand-crafted 3D assets altogether, which is probably how things will end up going in gaming, long-term.<p>I was suggesting a more modest approach, I guess, one where the reverse-denoising process involves picking and placing existing 3D assets, e.g., those in GTA 5, so that the process is actually building a plausible map, using those 3D assets, but on the fly...<p>Turn your car right and a plausible street decorated with buildings, trees and people is dreamt up by the algorithm. All the lighting and physics would still be done in-engine, with stable diffusion acting as a dynamic map creator, with an inherent knowledge of how to decorate a street with a plausible mix of assets.<p>I suppose it could form the basis of a procedurally generated game world where, given the same random seed, it could generate whole cities or landscapes that would be the same on each player&#x27;s machine. Just an idea...</div><br/><div id="41828540" class="c"><input type="checkbox" id="c-41828540" checked=""/><div class="controls bullet"><span class="by">skydhash</span><span>|</span><a href="#41826976">root</a><span>|</span><a href="#41827125">parent</a><span>|</span><a href="#41828491">next</a><span>|</span><label class="collapse" for="c-41828540">[-]</label><label class="expand" for="c-41828540">[1 more]</label></div><br/><div class="children"><div class="content">The thing is that, there are generators that can do exactly this, no need to have an LLM as the middle man. Things like terrain generation, city generation, crowd control, character generation, can be done quite easily with far less compute and energy.</div><br/></div></div></div></div><div id="41828491" class="c"><input type="checkbox" id="c-41828491" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#41826976">root</a><span>|</span><a href="#41827006">parent</a><span>|</span><a href="#41827125">prev</a><span>|</span><a href="#41830578">next</a><span>|</span><label class="collapse" for="c-41828491">[-]</label><label class="expand" for="c-41828491">[3 more]</label></div><br/><div class="children"><div class="content">Technically I guess one could do a stable diffusion-like model except on voxels, where instead of pixel intensity values it producing a scalar field which you could turn into geometry using marching cubes or something similar.<p>Not sure how efficient that would be though, and would only work for assets like teapots and whatnot, not whole game maps say.</div><br/><div id="41832809" class="c"><input type="checkbox" id="c-41832809" checked=""/><div class="controls bullet"><span class="by">desdenova</span><span>|</span><a href="#41826976">root</a><span>|</span><a href="#41828491">parent</a><span>|</span><a href="#41830578">next</a><span>|</span><label class="collapse" for="c-41832809">[-]</label><label class="expand" for="c-41832809">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a simplified version of what a point cloud stores, but only works with cubes then.<p>A point cloud is basically a 3D texture of colors and densities, so a raymarching algorithm can traverse it adding densities it collides with to find the final fragment color. That&#x27;s how realistic fog and clouds are rendered in games nowadays, and it&#x27;s very fast, except they use a noise function instead of a scene model.</div><br/><div id="41835608" class="c"><input type="checkbox" id="c-41835608" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#41826976">root</a><span>|</span><a href="#41832809">parent</a><span>|</span><a href="#41830578">next</a><span>|</span><label class="collapse" for="c-41835608">[-]</label><label class="expand" for="c-41835608">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A point cloud is basically a 3D texture of colors and densities<p>That&#x27;s not how I&#x27;m familiar with it. As I know it[1], a point cloud is literally that, a collection of individual points, that represents an object scene.<p>While what you describe is like the scalar field[2] I mentioned, each position in space has some value.<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Point_cloud" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Point_cloud</a><p>[2]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Scalar_field" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Scalar_field</a></div><br/></div></div></div></div></div></div></div></div><div id="41830578" class="c"><input type="checkbox" id="c-41830578" checked=""/><div class="controls bullet"><span class="by">furyofantares</span><span>|</span><a href="#41826976">parent</a><span>|</span><a href="#41827006">prev</a><span>|</span><a href="#41827565">next</a><span>|</span><label class="collapse" for="c-41830578">[-]</label><label class="expand" for="c-41830578">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but, as far as I know, this is always done at the pixel level<p>Image models are NOT denoised at the pixel level - diffusion happens in latent space. This was one of the big breakthroughs that made all of this work well.<p>There&#x27;s a model for encoding&#x2F;decoding between pixels and latent space. Latent space is able to encode whatever concepts it needs in whichever of its dimensions it needs, and is generally lower dimensional than pixel space. So we get a noisy latent space, denoise it using the diffusion model, then use the other model (variational autoencoder) to decode into pixel space.</div><br/></div></div><div id="41827565" class="c"><input type="checkbox" id="c-41827565" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#41826976">parent</a><span>|</span><a href="#41830578">prev</a><span>|</span><a href="#41827520">next</a><span>|</span><label class="collapse" for="c-41827565">[-]</label><label class="expand" for="c-41827565">[1 more]</label></div><br/><div class="children"><div class="content">Not exactly 3D assets, but diffusion modems are used to generate e.g. traffic (vehicle trajectories) for evaluating autonomous vehicle algorithms. These vehicles tend to crash quite a lot.<p>For example <a href="https:&#x2F;&#x2F;github.com&#x2F;NVlabs&#x2F;CTG">https:&#x2F;&#x2F;github.com&#x2F;NVlabs&#x2F;CTG</a><p>Edit: fixed link</div><br/></div></div><div id="41827520" class="c"><input type="checkbox" id="c-41827520" checked=""/><div class="controls bullet"><span class="by">tiborsaas</span><span>|</span><a href="#41826976">parent</a><span>|</span><a href="#41827565">prev</a><span>|</span><a href="#41827069">next</a><span>|</span><label class="collapse" for="c-41827520">[-]</label><label class="expand" for="c-41827520">[1 more]</label></div><br/><div class="children"><div class="content">Generating this at pixel level <i>is</i> the next level thing. The reverse engineering method your described is probably appealing because it&#x27;s easier to understand.<p>Focusing on pixel level generation is the right approach I think. The somewhat noisy output will be improved upon probably in a short timeframe. Now that they proved with Doom (<a href="https:&#x2F;&#x2F;gamengen.github.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;gamengen.github.io&#x2F;</a>) and this that it&#x27;s possible, probably more research is happening currently to nail the correct architecture to scale this to HD and minimal hallucination. It happened with videos alredy so we should see a similar level breakthrough soon.</div><br/></div></div><div id="41827069" class="c"><input type="checkbox" id="c-41827069" checked=""/><div class="controls bullet"><span class="by">gliptic</span><span>|</span><a href="#41826976">parent</a><span>|</span><a href="#41827520">prev</a><span>|</span><a href="#41833122">next</a><span>|</span><label class="collapse" for="c-41827069">[-]</label><label class="expand" for="c-41827069">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I _think_ I understand the basic premise behind stable diffusion, i.e., reverse the denoising process to generate realistic images but, as far as I know, this is always done at the pixel level.<p>It&#x27;s typically not done at the pixel level, but at the &quot;latent space&quot; level of e.g. a VAE. The image generation is done in this space, which has fewer outputs than the pixels of the final image, and then converted to the pixels using the VAE.</div><br/><div id="41827206" class="c"><input type="checkbox" id="c-41827206" checked=""/><div class="controls bullet"><span class="by">jmchambers</span><span>|</span><a href="#41826976">root</a><span>|</span><a href="#41827069">parent</a><span>|</span><a href="#41833122">next</a><span>|</span><label class="collapse" for="c-41827206">[-]</label><label class="expand" for="c-41827206">[2 more]</label></div><br/><div class="children"><div class="content">Frantically Googles VAE...<p>Ah, okay, so the work is done at a different level of abstraction, didn&#x27;t know that. But I guess it&#x27;s still a pixel-related abstraction, and it is converted back to pixels to generate the final image?<p>I suppose in my proposed (and probably implausible) algorithm, that different level of abstraction might be loosely analogous to collections of related game engine assets that are often used together, so that the denoising algorithm might be effectively saying things like &quot;we&#x27;ll put some building-related assets here-ish, and some park-related flora assets over here...&quot;, and then that gets crystallised in to actual placement of individual assets in the post-processing step.</div><br/><div id="41827978" class="c"><input type="checkbox" id="c-41827978" checked=""/><div class="controls bullet"><span class="by">StevenWaterman</span><span>|</span><a href="#41826976">root</a><span>|</span><a href="#41827206">parent</a><span>|</span><a href="#41833122">next</a><span>|</span><label class="collapse" for="c-41827978">[-]</label><label class="expand" for="c-41827978">[1 more]</label></div><br/><div class="children"><div class="content">(High level, specifics are definitely wrong here)<p>The VAE isn&#x27;t really pixel-level, it&#x27;s semantic-level. The most significant bits in the encoding are like &quot;how light or dark is the image&quot; and then towards the other end bits represent more niche things like &quot;if it&#x27;s an image of a person, make them wear glasses&quot;. This is way more efficient than using raw pixels because it&#x27;s so heavily compressed, there&#x27;s less data. This was one of the big breakthroughs of stable diffusion compared to previous efforts like disco diffusion that work on the pixel level.<p>The VAE encodes and decodes images automatically. It&#x27;s not something that&#x27;s written, it&#x27;s trained to understand the semantics of the images in the same way other neural nets are.</div><br/></div></div></div></div></div></div><div id="41833122" class="c"><input type="checkbox" id="c-41833122" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#41826976">parent</a><span>|</span><a href="#41827069">prev</a><span>|</span><a href="#41826654">next</a><span>|</span><label class="collapse" for="c-41833122">[-]</label><label class="expand" for="c-41833122">[1 more]</label></div><br/><div class="children"><div class="content">Stable diffusion is in latent space, not by pixel.</div><br/></div></div></div></div><div id="41826654" class="c"><input type="checkbox" id="c-41826654" checked=""/><div class="controls bullet"><span class="by">cousin_it</span><span>|</span><a href="#41826976">prev</a><span>|</span><a href="#41826922">next</a><span>|</span><label class="collapse" for="c-41826654">[-]</label><label class="expand" for="c-41826654">[6 more]</label></div><br/><div class="children"><div class="content">I continue to be puzzled by people who don&#x27;t notice the &quot;noise of hell&quot; in NN pictures and videos. To me it&#x27;s always recognizable and terrifying, has been from the start.</div><br/><div id="41826950" class="c"><input type="checkbox" id="c-41826950" checked=""/><div class="controls bullet"><span class="by">npteljes</span><span>|</span><a href="#41826654">parent</a><span>|</span><a href="#41827029">next</a><span>|</span><label class="collapse" for="c-41826950">[-]</label><label class="expand" for="c-41826950">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean by noise of hell in particular? I do notice that the images are almost always uncanny in a way, but maybe we&#x27;re not meaning the same thing. Could you elaborate on what you experience?</div><br/></div></div><div id="41827029" class="c"><input type="checkbox" id="c-41827029" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#41826654">parent</a><span>|</span><a href="#41826950">prev</a><span>|</span><a href="#41826816">next</a><span>|</span><label class="collapse" for="c-41827029">[-]</label><label class="expand" for="c-41827029">[3 more]</label></div><br/><div class="children"><div class="content">Like a subtle but unsettling babble&#x2F;hubbub&#x2F;cacophony? If so then I think I kind of know what you mean.</div><br/><div id="41829311" class="c"><input type="checkbox" id="c-41829311" checked=""/><div class="controls bullet"><span class="by">TechDebtDevin</span><span>|</span><a href="#41826654">root</a><span>|</span><a href="#41827029">parent</a><span>|</span><a href="#41829844">next</a><span>|</span><label class="collapse" for="c-41829311">[-]</label><label class="expand" for="c-41829311">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s definately a bit of an uncanny valley in the land of top tier diffusion models. A generative video of someone smiling is way more likely to illicit this response for me than a generative image or single frame. It definately has something to do with the movement.</div><br/></div></div><div id="41829844" class="c"><input type="checkbox" id="c-41829844" checked=""/><div class="controls bullet"><span class="by">cousin_it</span><span>|</span><a href="#41826654">root</a><span>|</span><a href="#41827029">parent</a><span>|</span><a href="#41829311">prev</a><span>|</span><a href="#41826816">next</a><span>|</span><label class="collapse" for="c-41829844">[-]</label><label class="expand" for="c-41829844">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s exactly it.</div><br/></div></div></div></div><div id="41826816" class="c"><input type="checkbox" id="c-41826816" checked=""/><div class="controls bullet"><span class="by">HKH2</span><span>|</span><a href="#41826654">parent</a><span>|</span><a href="#41827029">prev</a><span>|</span><a href="#41826922">next</a><span>|</span><label class="collapse" for="c-41826816">[-]</label><label class="expand" for="c-41826816">[1 more]</label></div><br/><div class="children"><div class="content">Eyes have a lot of noise too.</div><br/></div></div></div></div><div id="41826922" class="c"><input type="checkbox" id="c-41826922" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#41826654">prev</a><span>|</span><a href="#41826804">next</a><span>|</span><label class="collapse" for="c-41826922">[-]</label><label class="expand" for="c-41826922">[4 more]</label></div><br/><div class="children"><div class="content">This was Schmidhuber&#x27;s group is 2018:<p><a href="https:&#x2F;&#x2F;worldmodels.github.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;worldmodels.github.io&#x2F;</a><p>Just want to point that out.</div><br/><div id="41832316" class="c"><input type="checkbox" id="c-41832316" checked=""/><div class="controls bullet"><span class="by">hervature</span><span>|</span><a href="#41826922">parent</a><span>|</span><a href="#41827759">next</a><span>|</span><label class="collapse" for="c-41832316">[-]</label><label class="expand" for="c-41832316">[2 more]</label></div><br/><div class="children"><div class="content">I assume you are pointing this out because it is the first reference in the paper and getting the recognition it deserves and you are simply providing this link for convenience to those who do not go to the references.</div><br/><div id="41832911" class="c"><input type="checkbox" id="c-41832911" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#41826922">root</a><span>|</span><a href="#41832316">parent</a><span>|</span><a href="#41827759">next</a><span>|</span><label class="collapse" for="c-41832911">[-]</label><label class="expand" for="c-41832911">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it was very nice to see it was the first citation in the paper (and cited several times throughout).<p>The World Models paper is still one of the most amazing papers I&#x27;ve ever read.  And I just really keep wanting to show that, in case people really don&#x27;t see that, many in-the-know... knew.</div><br/></div></div></div></div><div id="41827759" class="c"><input type="checkbox" id="c-41827759" checked=""/><div class="controls bullet"><span class="by">afh1</span><span>|</span><a href="#41826922">parent</a><span>|</span><a href="#41832316">prev</a><span>|</span><a href="#41826804">next</a><span>|</span><label class="collapse" for="c-41827759">[-]</label><label class="expand" for="c-41827759">[1 more]</label></div><br/><div class="children"><div class="content">Ahead of its time for sure. Dream is an accurate term here, that driving scene does resemble driving in dreams.</div><br/></div></div></div></div><div id="41826804" class="c"><input type="checkbox" id="c-41826804" checked=""/><div class="controls bullet"><span class="by">DrSiemer</span><span>|</span><a href="#41826922">prev</a><span>|</span><a href="#41828077">next</a><span>|</span><label class="collapse" for="c-41826804">[-]</label><label class="expand" for="c-41826804">[13 more]</label></div><br/><div class="children"><div class="content">Where it gets really interesting is if we can train a model on the latest GTA, plus maybe related real life footage, and then use it to live upgrade the visuals of an old game like Vice City.<p>The lack of temporal consistency will still make it feel pretty dreamlike, but it won&#x27;t matter that much, because the base is consistent and it will look amazing.</div><br/><div id="41827129" class="c"><input type="checkbox" id="c-41827129" checked=""/><div class="controls bullet"><span class="by">InsideOutSanta</span><span>|</span><a href="#41826804">parent</a><span>|</span><a href="#41826855">next</a><span>|</span><label class="collapse" for="c-41827129">[-]</label><label class="expand" for="c-41827129">[1 more]</label></div><br/><div class="children"><div class="content">Just redrawing images drawn by an existing game engine works, and generates amazing results, although like you point out, temporal consistency is not great. It might interpret the low-res green pixels on a far-away mountain as fruit trees in one frame, and as pines in the next.<p>Here&#x27;s a demo from 2021 doing something like that:
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3rYosbwXm1w" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3rYosbwXm1w</a></div><br/></div></div><div id="41826855" class="c"><input type="checkbox" id="c-41826855" checked=""/><div class="controls bullet"><span class="by">davedx</span><span>|</span><a href="#41826804">parent</a><span>|</span><a href="#41827129">prev</a><span>|</span><a href="#41827328">next</a><span>|</span><label class="collapse" for="c-41826855">[-]</label><label class="expand" for="c-41826855">[2 more]</label></div><br/><div class="children"><div class="content">A game like GTA has way too much functionality and complex branching for this to work I think (beyond eg doing aimless drives around the city — which would be very cool though)</div><br/><div id="41829649" class="c"><input type="checkbox" id="c-41829649" checked=""/><div class="controls bullet"><span class="by">DrSiemer</span><span>|</span><a href="#41826804">root</a><span>|</span><a href="#41826855">parent</a><span>|</span><a href="#41827328">next</a><span>|</span><label class="collapse" for="c-41829649">[-]</label><label class="expand" for="c-41829649">[1 more]</label></div><br/><div class="children"><div class="content">Gta 5 has everything Vice City has and more. In the Doom AI dream it&#x27;s possible to shoot people. Maybe in this CS model as well?<p>I think the model does not have to know anything about the functionality. It can just dream up what is most probable to happen based on the training data.</div><br/></div></div></div></div><div id="41827328" class="c"><input type="checkbox" id="c-41827328" checked=""/><div class="controls bullet"><span class="by">sorenjan</span><span>|</span><a href="#41826804">parent</a><span>|</span><a href="#41826855">prev</a><span>|</span><a href="#41828554">next</a><span>|</span><label class="collapse" for="c-41827328">[-]</label><label class="expand" for="c-41827328">[3 more]</label></div><br/><div class="children"><div class="content">In addition to the sibling comment&#x27;s older example there&#x27;s new work done with GTA too.<p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;aivideo&#x2F;comments&#x2F;1fx6zdr&#x2F;gta_iv_with_a_photorealistic_filter_with_runway&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;aivideo&#x2F;comments&#x2F;1fx6zdr&#x2F;gta_iv_wit...</a></div><br/><div id="41829608" class="c"><input type="checkbox" id="c-41829608" checked=""/><div class="controls bullet"><span class="by">DrSiemer</span><span>|</span><a href="#41826804">root</a><span>|</span><a href="#41827328">parent</a><span>|</span><a href="#41828554">next</a><span>|</span><label class="collapse" for="c-41829608">[-]</label><label class="expand" for="c-41829608">[2 more]</label></div><br/><div class="children"><div class="content">Cool! Looks fairly consistent as well.<p>I wonder if this type of AI upscaling could eventually also fix things like slightly janky animations, but I guess that would be pretty hard without predetermined input and some form of look ahead.<p>Limiting character motion to only allow correct, natural movement would introduce a strange kind of input lag.</div><br/><div id="41830364" class="c"><input type="checkbox" id="c-41830364" checked=""/><div class="controls bullet"><span class="by">sorenjan</span><span>|</span><a href="#41826804">root</a><span>|</span><a href="#41829608">parent</a><span>|</span><a href="#41828554">next</a><span>|</span><label class="collapse" for="c-41830364">[-]</label><label class="expand" for="c-41830364">[1 more]</label></div><br/><div class="children"><div class="content">Nvidia has done work in AI driven character animation too.<p><a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;on-demand&#x2F;session&#x2F;gtcspring22-d4107&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;on-demand&#x2F;session&#x2F;gtcspring22-d...</a></div><br/></div></div></div></div></div></div><div id="41828554" class="c"><input type="checkbox" id="c-41828554" checked=""/><div class="controls bullet"><span class="by">skydhash</span><span>|</span><a href="#41826804">parent</a><span>|</span><a href="#41827328">prev</a><span>|</span><a href="#41831662">next</a><span>|</span><label class="collapse" for="c-41828554">[-]</label><label class="expand" for="c-41828554">[3 more]</label></div><br/><div class="children"><div class="content">Why not just creating the assets with higher resolution?</div><br/><div id="41829575" class="c"><input type="checkbox" id="c-41829575" checked=""/><div class="controls bullet"><span class="by">DrSiemer</span><span>|</span><a href="#41826804">root</a><span>|</span><a href="#41828554">parent</a><span>|</span><a href="#41831662">next</a><span>|</span><label class="collapse" for="c-41829575">[-]</label><label class="expand" for="c-41829575">[2 more]</label></div><br/><div class="children"><div class="content">Because that is a lot more work, will only work for a single game, potentially requires more resources to run and will not get you the same level of realism.</div><br/><div id="41833783" class="c"><input type="checkbox" id="c-41833783" checked=""/><div class="controls bullet"><span class="by">skydhash</span><span>|</span><a href="#41826804">root</a><span>|</span><a href="#41829575">parent</a><span>|</span><a href="#41831662">next</a><span>|</span><label class="collapse" for="c-41833783">[-]</label><label class="expand" for="c-41833783">[1 more]</label></div><br/><div class="children"><div class="content">Based on what I know about 3D games, I can not imagine that being more efficient than current methods. Especially if you take the 3D world data into account.</div><br/></div></div></div></div></div></div><div id="41831662" class="c"><input type="checkbox" id="c-41831662" checked=""/><div class="controls bullet"><span class="by">empath75</span><span>|</span><a href="#41826804">parent</a><span>|</span><a href="#41828554">prev</a><span>|</span><a href="#41831395">next</a><span>|</span><label class="collapse" for="c-41831662">[-]</label><label class="expand" for="c-41831662">[2 more]</label></div><br/><div class="children"><div class="content">People focusing on the use of this in video games baffles me.  The point isn&#x27;t that it can regenerate a videogame world, the point is that it can simulate the _real world_.  They&#x27;re using video game footage to train it because it&#x27;s cheap and easy to synthesize the data they need.  This system doesn&#x27;t know it&#x27;s simulating a game.  You can give it thousands or millions of hours of real world footage and agent input and get a simulation of the real world.</div><br/><div id="41833858" class="c"><input type="checkbox" id="c-41833858" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#41826804">root</a><span>|</span><a href="#41831662">parent</a><span>|</span><a href="#41831395">next</a><span>|</span><label class="collapse" for="c-41833858">[-]</label><label class="expand" for="c-41833858">[1 more]</label></div><br/><div class="children"><div class="content">Reading this thread has been extremely frustrating because so many commenters seem to be stuck on &quot;why do this when we already have a CS:GO simulation at home?&quot;.<p>You hit the nail on the head.</div><br/></div></div></div></div><div id="41831395" class="c"><input type="checkbox" id="c-41831395" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#41826804">parent</a><span>|</span><a href="#41831662">prev</a><span>|</span><a href="#41828077">next</a><span>|</span><label class="collapse" for="c-41831395">[-]</label><label class="expand" for="c-41831395">[1 more]</label></div><br/><div class="children"><div class="content">Using it as a visual upgrade is pretty close to what DLSS does so that sounds plausible.</div><br/></div></div></div></div><div id="41828077" class="c"><input type="checkbox" id="c-41828077" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#41826804">prev</a><span>|</span><a href="#41826596">next</a><span>|</span><label class="collapse" for="c-41828077">[-]</label><label class="expand" for="c-41828077">[3 more]</label></div><br/><div class="children"><div class="content">I wonder if there is some way to combine this with a language model, or somehow have the language model in the same latent space or something.<p>Is that was vision-language models already do? Somehow all of the language should be grounded in the world model. For models like Gemini that can answer questions about video, it must have some level of this grounding already.<p>I don&#x27;t understand how this stuff works, but compressing everything to one dimension as in a language model for processing seems inefficient. The reason our language is serial is because we can only make one sound at a time.<p>But suppose the &quot;game&quot; trained on was a structural engineering tool. The user asks about some scenario for a structure and somehow that language is converted to an input visualization of the &quot;game state&quot;. Maybe some constraints to be solved for are encoded also somehow as part of that initial state.<p>Then when it&#x27;s solved (by an agent trained through reinforcement learning that uses each dreamed game state as input?), the result &quot;game state&quot; is converted somehow back into language and combined with the original user query to provide an answer.<p>But if I understand properly, the biggest utility of this is that there is a network that understands how the world works, and that part of the network can be utilized for predicting useful actions or maybe answering questions etc. ?</div><br/><div id="41828814" class="c"><input type="checkbox" id="c-41828814" checked=""/><div class="controls bullet"><span class="by">LarsDu88</span><span>|</span><a href="#41828077">parent</a><span>|</span><a href="#41831679">next</a><span>|</span><label class="collapse" for="c-41828814">[-]</label><label class="expand" for="c-41828814">[1 more]</label></div><br/><div class="children"><div class="content">To combine with a language model simply replace the action vector with a language model latent.<p>Alternative as of last year there are now purely diffusion based text decoder models</div><br/></div></div><div id="41831679" class="c"><input type="checkbox" id="c-41831679" checked=""/><div class="controls bullet"><span class="by">empath75</span><span>|</span><a href="#41828077">parent</a><span>|</span><a href="#41828814">prev</a><span>|</span><a href="#41826596">next</a><span>|</span><label class="collapse" for="c-41831679">[-]</label><label class="expand" for="c-41831679">[1 more]</label></div><br/><div class="children"><div class="content">Not everything needs to be a single giant neural network.  You could have a bunch of weakly coupled specialized networks sending data back and forth over a normal api.</div><br/></div></div></div></div><div id="41826596" class="c"><input type="checkbox" id="c-41826596" checked=""/><div class="controls bullet"><span class="by">mungoman2</span><span>|</span><a href="#41828077">prev</a><span>|</span><a href="#41826656">next</a><span>|</span><label class="collapse" for="c-41826596">[-]</label><label class="expand" for="c-41826596">[2 more]</label></div><br/><div class="children"><div class="content">This is getting ridiculous!<p>Curious, since this is a strong loop  old frame + input -&gt; new frame, What happens if a non-CS image is used to start it off? Or a map the model has never seen. Will the model play ball, or will it drift back to known CS maps?</div><br/><div id="41826650" class="c"><input type="checkbox" id="c-41826650" checked=""/><div class="controls bullet"><span class="by">Arch-TK</span><span>|</span><a href="#41826596">parent</a><span>|</span><a href="#41826656">next</a><span>|</span><label class="collapse" for="c-41826650">[-]</label><label class="expand" for="c-41826650">[1 more]</label></div><br/><div class="children"><div class="content">Looks like it only knows Dust 2 since every single &quot;dream&quot; (I&#x27;m going to call them that since looking at this stuff feels like dreaming about Dust 2) is of that map only.</div><br/></div></div></div></div><div id="41826656" class="c"><input type="checkbox" id="c-41826656" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#41826596">prev</a><span>|</span><a href="#41828805">next</a><span>|</span><label class="collapse" for="c-41826656">[-]</label><label class="expand" for="c-41826656">[3 more]</label></div><br/><div class="children"><div class="content">Strangely the paper doesn&#x27;t seem to give much detail on the cs-go example. Actually the paper explicitly mentions it&#x27;s limited to discrete control environments. Unless I&#x27;m missing something the mouse input for counterstrike isn&#x27;t discrete and wouldn&#x27;t work.<p>I&#x27;m not sure why the title says it was trained on 2x4090 either as I can&#x27;t see this on either the linked page or the paper. The paper mentions a GPU year of 4090 compute was used to train the Atari model.</div><br/><div id="41826703" class="c"><input type="checkbox" id="c-41826703" checked=""/><div class="controls bullet"><span class="by">c1b</span><span>|</span><a href="#41826656">parent</a><span>|</span><a href="#41828805">next</a><span>|</span><label class="collapse" for="c-41826703">[-]</label><label class="expand" for="c-41826703">[2 more]</label></div><br/><div class="children"><div class="content">CSGO model is only 1.5 gb &amp; training took 12 days on a 4090<p><a href="https:&#x2F;&#x2F;github.com&#x2F;eloialonso&#x2F;diamond&#x2F;tree&#x2F;csgo?tab=readme-ov-file">https:&#x2F;&#x2F;github.com&#x2F;eloialonso&#x2F;diamond&#x2F;tree&#x2F;csgo?tab=readme-o...</a></div><br/><div id="41826783" class="c"><input type="checkbox" id="c-41826783" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#41826656">root</a><span>|</span><a href="#41826703">parent</a><span>|</span><a href="#41828805">next</a><span>|</span><label class="collapse" for="c-41826783">[-]</label><label class="expand" for="c-41826783">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, that&#x27;s the detail I was looking for on the training. It&#x27;s amazing results like this can be achieved at such a low costs! I thought this kind of work was out of reach for the GPU poor.<p>The part about the continuous control still seems weird to me though. If anyone understands that then very interested to hear more.</div><br/></div></div></div></div></div></div><div id="41828805" class="c"><input type="checkbox" id="c-41828805" checked=""/><div class="controls bullet"><span class="by">LarsDu88</span><span>|</span><a href="#41826656">prev</a><span>|</span><a href="#41826731">next</a><span>|</span><label class="collapse" for="c-41828805">[-]</label><label class="expand" for="c-41828805">[1 more]</label></div><br/><div class="children"><div class="content">Iterative denoising diffusion is such a hurdle for getting this sort of thing running at reasonable fps</div><br/></div></div><div id="41826731" class="c"><input type="checkbox" id="c-41826731" checked=""/><div class="controls bullet"><span class="by">ThouYS</span><span>|</span><a href="#41828805">prev</a><span>|</span><a href="#41827299">next</a><span>|</span><label class="collapse" for="c-41826731">[-]</label><label class="expand" for="c-41826731">[10 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really understand the intuition on why this helps RL. The original game has a lot more detail, why can&#x27;t it be used directly?</div><br/><div id="41826766" class="c"><input type="checkbox" id="c-41826766" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#41826731">parent</a><span>|</span><a href="#41827080">next</a><span>|</span><label class="collapse" for="c-41826766">[-]</label><label class="expand" for="c-41826766">[2 more]</label></div><br/><div class="children"><div class="content">It is used as a predictive model of the environment for model-based RL. I.e. agents can predict consequences of their actions.</div><br/><div id="41826797" class="c"><input type="checkbox" id="c-41826797" checked=""/><div class="controls bullet"><span class="by">ThouYS</span><span>|</span><a href="#41826731">root</a><span>|</span><a href="#41826766">parent</a><span>|</span><a href="#41827080">next</a><span>|</span><label class="collapse" for="c-41826797">[-]</label><label class="expand" for="c-41826797">[1 more]</label></div><br/><div class="children"><div class="content">Oh, I see. I was somehow under the impression that the simulation was the game the RL agent learns to play (which kinda seemed nonsensical).</div><br/></div></div></div></div><div id="41827080" class="c"><input type="checkbox" id="c-41827080" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41826731">parent</a><span>|</span><a href="#41826766">prev</a><span>|</span><a href="#41826740">next</a><span>|</span><label class="collapse" for="c-41827080">[-]</label><label class="expand" for="c-41827080">[1 more]</label></div><br/><div class="children"><div class="content">It can use the game directly but if you try this with real life robots, then it is better to do neural simulation before performing an action that could result in injury or damage. We don&#x27;t need to fall with our cars off the road many times to learn to drive on the road because we can imagine the consequences. Same thing here.</div><br/></div></div><div id="41826740" class="c"><input type="checkbox" id="c-41826740" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#41826731">parent</a><span>|</span><a href="#41827080">prev</a><span>|</span><a href="#41827299">next</a><span>|</span><label class="collapse" for="c-41826740">[-]</label><label class="expand" for="c-41826740">[6 more]</label></div><br/><div class="children"><div class="content">In the real world, you can&#x27;t just boot up a copy of reality to play out strategies. You need an internal model.</div><br/><div id="41826776" class="c"><input type="checkbox" id="c-41826776" checked=""/><div class="controls bullet"><span class="by">tourmalinetaco</span><span>|</span><a href="#41826731">root</a><span>|</span><a href="#41826740">parent</a><span>|</span><a href="#41827299">next</a><span>|</span><label class="collapse" for="c-41826776">[-]</label><label class="expand" for="c-41826776">[5 more]</label></div><br/><div class="children"><div class="content">So, effectively, these video game models are proof-of-concepts to say “we can make models with extremely accurate predictions using minimal resources”?</div><br/><div id="41827498" class="c"><input type="checkbox" id="c-41827498" checked=""/><div class="controls bullet"><span class="by">usrusr</span><span>|</span><a href="#41826731">root</a><span>|</span><a href="#41826776">parent</a><span>|</span><a href="#41827338">next</a><span>|</span><label class="collapse" for="c-41827498">[-]</label><label class="expand" for="c-41827498">[1 more]</label></div><br/><div class="children"><div class="content">Not sure where you see the &quot;minimal resources&quot; here? But I&#x27;d just counter all questions about &quot;why&quot; with the blanket response of &quot;for understanding natural intelligence&quot;: the way biology innovates is that it throws everything against the wall and not pick the one thing that sticks as the winner and focus on that mechanism, it keeps the sticky bits and also everything else as long as their cost isn&#x27;t prohibitive. Symbolic modeling (&quot;this is an object that can fall down&quot;), prediction chains based on visual similarity patterns (this), hardwired reflexes (we tend to not trust anything that looks and moves like a spider or snake) and who knows what else, it&#x27;s all there, it all runs in parallel, invited or not, and they all influence each other in subtle and less subtle ways. The interaction is not engineered, it&#x27;s more like crosstalk that&#x27;s allowed to happen and has more upside than downside, or else evolution would have preferred variations of the setup that have less of the kind of crosstalk in question. But in our quest to understand us, it&#x27;s super exciting to see candidates for processes that perhaps play some role in our minds, in isolation, no matter if that role is big or small.</div><br/></div></div><div id="41827338" class="c"><input type="checkbox" id="c-41827338" checked=""/><div class="controls bullet"><span class="by">vbezhenar</span><span>|</span><a href="#41826731">root</a><span>|</span><a href="#41826776">parent</a><span>|</span><a href="#41827498">prev</a><span>|</span><a href="#41831689">next</a><span>|</span><label class="collapse" for="c-41827338">[-]</label><label class="expand" for="c-41827338">[2 more]</label></div><br/><div class="children"><div class="content">May be I&#x27;m wrong but my understanding is that you can film some area using, say, dashcams and then generate this kind of neuro model. Then you can train robot to walk in this area with this neuro-model. It can perform billions of training sessions without touching physical world. Alternatively you can somehow perform 3D scan of area, recreate its 3D model and use, say, game engine to simulate, but that probably requires more effort and not necessarily better.</div><br/><div id="41827528" class="c"><input type="checkbox" id="c-41827528" checked=""/><div class="controls bullet"><span class="by">usrusr</span><span>|</span><a href="#41826731">root</a><span>|</span><a href="#41827338">parent</a><span>|</span><a href="#41831689">next</a><span>|</span><label class="collapse" for="c-41827528">[-]</label><label class="expand" for="c-41827528">[1 more]</label></div><br/><div class="children"><div class="content">And the leg motions we sometimes see in sleeping dogs suggest that this is very much a way how having dreams is useful!</div><br/></div></div></div></div><div id="41831689" class="c"><input type="checkbox" id="c-41831689" checked=""/><div class="controls bullet"><span class="by">empath75</span><span>|</span><a href="#41826731">root</a><span>|</span><a href="#41826776">parent</a><span>|</span><a href="#41827338">prev</a><span>|</span><a href="#41827299">next</a><span>|</span><label class="collapse" for="c-41831689">[-]</label><label class="expand" for="c-41831689">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this is exactly right.  What they need is a giant dataset of agent data and audio and video from real world locomotion.</div><br/></div></div></div></div></div></div></div></div><div id="41827299" class="c"><input type="checkbox" id="c-41827299" checked=""/><div class="controls bullet"><span class="by">shahzaibmushtaq</span><span>|</span><a href="#41826731">prev</a><span>|</span><a href="#41827544">next</a><span>|</span><label class="collapse" for="c-41827299">[-]</label><label class="expand" for="c-41827299">[3 more]</label></div><br/><div class="children"><div class="content">As I used to play CS 1.6 and CS: GO in my free time before the pandemic, this playable CS diffusion world map has been trained by a noob player for research purposes.<p>After reading the comments I can assume that if you play outside of the scope it was trained on, the game loses its functionality.<p>Nevertheless, R&amp;D for a good cause is something we all admire.</div><br/><div id="41827356" class="c"><input type="checkbox" id="c-41827356" checked=""/><div class="controls bullet"><span class="by">crossroadsguy</span><span>|</span><a href="#41827299">parent</a><span>|</span><a href="#41827544">next</a><span>|</span><label class="collapse" for="c-41827356">[-]</label><label class="expand" for="c-41827356">[2 more]</label></div><br/><div class="children"><div class="content">How is the last version CS 2.0 (I think)? It’s been free to play like GO I guess. Is it like GO where physics felt too dramatised (could just be my opinion)? Or realistic in a snappy way like 1.6?</div><br/><div id="41828410" class="c"><input type="checkbox" id="c-41828410" checked=""/><div class="controls bullet"><span class="by">shahzaibmushtaq</span><span>|</span><a href="#41827299">root</a><span>|</span><a href="#41827356">parent</a><span>|</span><a href="#41827544">next</a><span>|</span><label class="collapse" for="c-41828410">[-]</label><label class="expand" for="c-41828410">[1 more]</label></div><br/><div class="children"><div class="content">Honestly, I heard about CS 2.0 from you. And you are right what you just said about GO.</div><br/></div></div></div></div></div></div><div id="41827544" class="c"><input type="checkbox" id="c-41827544" checked=""/><div class="controls bullet"><span class="by">Zealotux</span><span>|</span><a href="#41827299">prev</a><span>|</span><a href="#41826798">next</a><span>|</span><label class="collapse" for="c-41827544">[-]</label><label class="expand" for="c-41827544">[1 more]</label></div><br/><div class="children"><div class="content">Could we imagine parts of game elements to become &quot;targets&quot; for models? For example hair and fur physics have been notoriously difficult to nail, but it should be easier to use AI to simulate some fake physics on top of the rendered frame, right? Is anyone working on that?</div><br/></div></div><div id="41826798" class="c"><input type="checkbox" id="c-41826798" checked=""/><div class="controls bullet"><span class="by">thenthenthen</span><span>|</span><a href="#41827544">prev</a><span>|</span><a href="#41826604">next</a><span>|</span><label class="collapse" for="c-41826798">[-]</label><label class="expand" for="c-41826798">[1 more]</label></div><br/><div class="children"><div class="content">When my game starts to look like this, I know it is time to quit hahha, maybe a helpful tool in gaming addiction therapy? The morphing of the gun&#x2F;skins and the environment (the sandbags) wow. Would like to play this and see what happens when you walk backwards, turn around quick, use ‘noclip’ :D</div><br/></div></div><div id="41826604" class="c"><input type="checkbox" id="c-41826604" checked=""/><div class="controls bullet"><span class="by">advael</span><span>|</span><a href="#41826798">prev</a><span>|</span><a href="#41826777">next</a><span>|</span><label class="collapse" for="c-41826604">[-]</label><label class="expand" for="c-41826604">[1 more]</label></div><br/><div class="children"><div class="content">Dang this is the first paper I&#x27;ve seen in a while that makes me think I need new GPUs</div><br/></div></div><div id="41826777" class="c"><input type="checkbox" id="c-41826777" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#41826604">prev</a><span>|</span><a href="#41826403">next</a><span>|</span><label class="collapse" for="c-41826777">[-]</label><label class="expand" for="c-41826777">[1 more]</label></div><br/><div class="children"><div class="content">I just checked it out right quick. It works perfectly well on an AMD card with ROCM pytorch.<p>It seems decent in short bursts. As it goes on it quite quickly loses detail and the weapon has a tendency to devolve into colorful garbage. I would also like to point out that none of the videos show what happens when you walk into a wall. It doesn&#x27;t handle it very gracefully.</div><br/></div></div><div id="41827579" class="c"><input type="checkbox" id="c-41827579" checked=""/><div class="controls bullet"><span class="by">gadders</span><span>|</span><a href="#41826403">prev</a><span>|</span><a href="#41827794">next</a><span>|</span><label class="collapse" for="c-41827579">[-]</label><label class="expand" for="c-41827579">[2 more]</label></div><br/><div class="children"><div class="content">Cool achievement, but I want AI to give me smarter NPCs, not simulate the map.</div><br/><div id="41827749" class="c"><input type="checkbox" id="c-41827749" checked=""/><div class="controls bullet"><span class="by">thelastparadise</span><span>|</span><a href="#41827579">parent</a><span>|</span><a href="#41827794">next</a><span>|</span><label class="collapse" for="c-41827749">[-]</label><label class="expand" for="c-41827749">[1 more]</label></div><br/><div class="children"><div class="content">The NPCs need a model of the world in their brain in order to act normal.</div><br/></div></div></div></div><div id="41827794" class="c"><input type="checkbox" id="c-41827794" checked=""/><div class="controls bullet"><span class="by">styfle</span><span>|</span><a href="#41827579">prev</a><span>|</span><a href="#41830837">next</a><span>|</span><label class="collapse" for="c-41827794">[-]</label><label class="expand" for="c-41827794">[1 more]</label></div><br/><div class="children"><div class="content">But does it work on macOS?<p>(The latest CS removed support for macOS)</div><br/></div></div><div id="41830837" class="c"><input type="checkbox" id="c-41830837" checked=""/><div class="controls bullet"><span class="by">akomtu</span><span>|</span><a href="#41827794">prev</a><span>|</span><a href="#41827262">next</a><span>|</span><label class="collapse" for="c-41830837">[-]</label><label class="expand" for="c-41830837">[1 more]</label></div><br/><div class="children"><div class="content">The current batch of ML models looks a lot like filling in holes in the wall of text, drawings or movies: you erase a part of the wall and tell it to fix it. And it fills in the hole using colors from the nearby walls in the kitchen and similar walls and we watch this in awe thinking it must&#x27;ve figured out the design rules of the kitchen. However what it&#x27;s really done is it interpolated the gaps with some sort of basic functions, trigonometric polynomials for example, and it used thousands of those. This solution wouldn&#x27;t occur to us because our limited memory isn&#x27;t enough for thousands of polynomials: we have to find a compact set of rules or give up entirely. So when these ML models predict the motion of planets, they approximate the Newton&#x27;s law with a long series of basic functions.</div><br/></div></div><div id="41827262" class="c"><input type="checkbox" id="c-41827262" checked=""/><div class="controls bullet"><span class="by">iwontberude</span><span>|</span><a href="#41830837">prev</a><span>|</span><a href="#41826918">next</a><span>|</span><label class="collapse" for="c-41827262">[-]</label><label class="expand" for="c-41827262">[1 more]</label></div><br/><div class="children"><div class="content">This is crazy looking, I know it’s basically useless but it’s cool anyways.</div><br/></div></div><div id="41826918" class="c"><input type="checkbox" id="c-41826918" checked=""/><div class="controls bullet"><span class="by">mixtureoftakes</span><span>|</span><a href="#41827262">prev</a><span>|</span><a href="#41826620">next</a><span>|</span><label class="collapse" for="c-41826918">[-]</label><label class="expand" for="c-41826918">[1 more]</label></div><br/><div class="children"><div class="content">this is crazy<p>when trying to run on a mac it only plays in a very small window, how could this be configured?</div><br/></div></div><div id="41826620" class="c"><input type="checkbox" id="c-41826620" checked=""/><div class="controls bullet"><span class="by">6510</span><span>|</span><a href="#41826918">prev</a><span>|</span><a href="#41826595">next</a><span>|</span><label class="collapse" for="c-41826620">[-]</label><label class="expand" for="c-41826620">[1 more]</label></div><br/><div class="children"><div class="content">Can it use a seed that makes the same map every time?</div><br/></div></div><div id="41826595" class="c"><input type="checkbox" id="c-41826595" checked=""/><div class="controls bullet"><span class="by">madaxe_again</span><span>|</span><a href="#41826620">prev</a><span>|</span><a href="#41826767">next</a><span>|</span><label class="collapse" for="c-41826595">[-]</label><label class="expand" for="c-41826595">[38 more]</label></div><br/><div class="children"><div class="content">I earnestly think this is where all gaming will go in the next five years - it’s going to be so compelling that stuff already under development will likely see a shift to using diffusion models. As this is demonstrating, a sufficiently honed model can produce realtime graphics - and some of the demos floating around where people are running GTA San Andreas through non-realtime models hint as to where this will go.<p>I give it the same five years before there are games entirely indistinguishable from reality, and I don’t just mean graphical fidelity - there’s no reason that the same or another model couldn’t provide limitless physics - bust a hole through that wall, set fire to this refrigerator, whatever.</div><br/><div id="41826698" class="c"><input type="checkbox" id="c-41826698" checked=""/><div class="controls bullet"><span class="by">qayxc</span><span>|</span><a href="#41826595">parent</a><span>|</span><a href="#41826633">next</a><span>|</span><label class="collapse" for="c-41826698">[-]</label><label class="expand" for="c-41826698">[8 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re missing the most important point: these models need to be trained on something and that something is a fully developed, working game.<p>You&#x27;re basically saying that game development would need to do the work twice: step 1: develop a fully functional game, step 2: spend ridiculous effort (in terms of time and compute) on training a model to emulate the game in a half-baked fashion.<p>It&#x27;s a solution looking for a problem.</div><br/><div id="41826722" class="c"><input type="checkbox" id="c-41826722" checked=""/><div class="controls bullet"><span class="by">manmal</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826698">parent</a><span>|</span><a href="#41826757">next</a><span>|</span><label class="collapse" for="c-41826722">[-]</label><label class="expand" for="c-41826722">[3 more]</label></div><br/><div class="children"><div class="content">The world model can still be rendered in very low res, and then the diffusion skin&#x2F;remaster is applied.<p>And this would also be an exciting route to go at remastering old games. I‘d pay a lot to play NFS Porsche again, with photorealism. Or imagine Command &amp; Conquer Red Alert, „rendered“ with such a model.</div><br/><div id="41826762" class="c"><input type="checkbox" id="c-41826762" checked=""/><div class="controls bullet"><span class="by">qayxc</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826722">parent</a><span>|</span><a href="#41826757">next</a><span>|</span><label class="collapse" for="c-41826762">[-]</label><label class="expand" for="c-41826762">[2 more]</label></div><br/><div class="children"><div class="content">NVIDIA&#x27;s RTX Remix [1] suite of tools already does that. It doesn&#x27;t require any model training or dozens of hours of pre-recorded gameplay either.<p>You can drop in low-res textures and have AI tools upscale them. Models can be replaced, as well as lighting and the best part: it&#x27;s all under your control. You&#x27;re not at the merci of obscure training material that might or might not result in a consistent look-and-feel. More knobs, more control, less compute required.<p>[1] <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;geforce&#x2F;rtx-remix&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;geforce&#x2F;rtx-remix&#x2F;</a></div><br/><div id="41826942" class="c"><input type="checkbox" id="c-41826942" checked=""/><div class="controls bullet"><span class="by">manmal</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826762">parent</a><span>|</span><a href="#41826757">next</a><span>|</span><label class="collapse" for="c-41826942">[-]</label><label class="expand" for="c-41826942">[1 more]</label></div><br/><div class="children"><div class="content">TIL, thanks for posting. The workflow I was sketching out is simpler though: Render a legacy game or low fidelity modern game as-is, and run it through a diffusion model in real time.</div><br/></div></div></div></div></div></div><div id="41826757" class="c"><input type="checkbox" id="c-41826757" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826698">parent</a><span>|</span><a href="#41826722">prev</a><span>|</span><a href="#41831701">next</a><span>|</span><label class="collapse" for="c-41826757">[-]</label><label class="expand" for="c-41826757">[3 more]</label></div><br/><div class="children"><div class="content">You can crosstrain on reality.</div><br/><div id="41826794" class="c"><input type="checkbox" id="c-41826794" checked=""/><div class="controls bullet"><span class="by">qayxc</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826757">parent</a><span>|</span><a href="#41827230">next</a><span>|</span><label class="collapse" for="c-41826794">[-]</label><label class="expand" for="c-41826794">[1 more]</label></div><br/><div class="children"><div class="content">Sure - and that&#x27;ll work great on titles like Ratchet &amp; Clank [1] or Tiny Tina&#x27;s Wonderland [2] because art and style are dead and everything must be a mirror-like reflection of reality in order to be a fun game...<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ratchet_%26_Clank" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ratchet_%26_Clank</a><p>[2]<a href="https:&#x2F;&#x2F;playwonderlands.2k.com" rel="nofollow">https:&#x2F;&#x2F;playwonderlands.2k.com</a></div><br/></div></div></div></div><div id="41831701" class="c"><input type="checkbox" id="c-41831701" checked=""/><div class="controls bullet"><span class="by">empath75</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826698">parent</a><span>|</span><a href="#41826757">prev</a><span>|</span><a href="#41826633">next</a><span>|</span><label class="collapse" for="c-41831701">[-]</label><label class="expand" for="c-41831701">[1 more]</label></div><br/><div class="children"><div class="content">No, you use it to simulate things that we don&#x27;t have efficient perfect models of -- like the actual world.  Everyone is correct that using this to simulate counterstrike is pointless.  This is not video game technology, this is autonomous agent technology -- training robots to predict and navigate the real world.</div><br/></div></div></div></div><div id="41826633" class="c"><input type="checkbox" id="c-41826633" checked=""/><div class="controls bullet"><span class="by">casenmgreen</span><span>|</span><a href="#41826595">parent</a><span>|</span><a href="#41826698">prev</a><span>|</span><a href="#41826659">next</a><span>|</span><label class="collapse" for="c-41826633">[-]</label><label class="expand" for="c-41826633">[24 more]</label></div><br/><div class="children"><div class="content">Not a chance.<p>There are fundamental limitations with what are in the end all essentially neural nets; there is no understanding, only prediction.  Prediction alone is not enough to emulate reality, which is why for example genuinely self-driving cars have not, and will not, emerge.  A fundamental advance in AI technology will be required for that, something which leads to genuine intelligence, and we are no closer to that than ever we were.</div><br/><div id="41826679" class="c"><input type="checkbox" id="c-41826679" checked=""/><div class="controls bullet"><span class="by">fancyfredbot</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826633">parent</a><span>|</span><a href="#41833798">next</a><span>|</span><label class="collapse" for="c-41826679">[-]</label><label class="expand" for="c-41826679">[1 more]</label></div><br/><div class="children"><div class="content">Looking at the examples of 2600 games in the paper I&#x27;m not sure you can tell that they are just predictions.<p>Have you considered how you&#x27;d tell the difference between a prediction and understanding in practice?</div><br/></div></div><div id="41833798" class="c"><input type="checkbox" id="c-41833798" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826633">parent</a><span>|</span><a href="#41826679">prev</a><span>|</span><a href="#41826717">next</a><span>|</span><label class="collapse" for="c-41833798">[-]</label><label class="expand" for="c-41833798">[1 more]</label></div><br/><div class="children"><div class="content">Ilya Sutskever, among others, believe that better prediction is achieved through understanding, and that models can be learn to understand. As we have. We are not born understanding everything.</div><br/></div></div><div id="41826717" class="c"><input type="checkbox" id="c-41826717" checked=""/><div class="controls bullet"><span class="by">francoisfleuret</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826633">parent</a><span>|</span><a href="#41833798">prev</a><span>|</span><a href="#41826854">next</a><span>|</span><label class="collapse" for="c-41826717">[-]</label><label class="expand" for="c-41826717">[10 more]</label></div><br/><div class="children"><div class="content">&quot;there is no understanding, only prediction&quot;<p>I have no idea what this means.</div><br/><div id="41826917" class="c"><input type="checkbox" id="c-41826917" checked=""/><div class="controls bullet"><span class="by">nonrandomstring</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826717">parent</a><span>|</span><a href="#41826803">next</a><span>|</span><label class="collapse" for="c-41826917">[-]</label><label class="expand" for="c-41826917">[5 more]</label></div><br/><div class="children"><div class="content">&gt; &gt; &quot;there is no understanding, only prediction&quot;<p>&gt; I have no idea what this  means.<p>You can throw a ball up in the air and predict that it will fall again
and bounce. You have no understanding of mass, gravity, acceleration,
momentum, impulse, elasticity...<p>You can press a button that makes an Uber car appear in reality and
take you home. You have no understanding of apps, operating systems,
radio, internet, roads, wheels, internal combustion engines, driving,
GPS, maps...<p>This confusion of understanding and prediction affects a lot of people
who use technology in a &quot;machine-like&quot; way, purely instrumental and
utilitarian... &quot;how does this get me what I want immediately?&quot;<p>You can take any complex reality and deflate it, abstract it, reduce
it down to a mere set of predictions that preserve all the utility for
a narrow task (in this case visual facsimile) but strip away all depth
of meaning. The models, of both the system and the internal working
model of the user are flattened. In this sense &quot;AI&quot; is probably the
greatest assault on actual knowledge since the book burning under
totalitarian regimes of the mid 20th century.</div><br/><div id="41826968" class="c"><input type="checkbox" id="c-41826968" checked=""/><div class="controls bullet"><span class="by">binary132</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826917">parent</a><span>|</span><a href="#41826937">next</a><span>|</span><label class="collapse" for="c-41826968">[-]</label><label class="expand" for="c-41826968">[1 more]</label></div><br/><div class="children"><div class="content">I think GP is saying that understanding is measured by predictive capability of the theory<p>and in case you hadn’t noticed, that kind of uncomprehending slopthink has been going on for a lot longer than the AI fad</div><br/></div></div><div id="41826937" class="c"><input type="checkbox" id="c-41826937" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826917">parent</a><span>|</span><a href="#41826968">prev</a><span>|</span><a href="#41826803">next</a><span>|</span><label class="collapse" for="c-41826937">[-]</label><label class="expand" for="c-41826937">[3 more]</label></div><br/><div class="children"><div class="content">What if the model actually understands that the ball will fall and bounce because of mass, gravity, acceleration, momentum, impulse, elasticity? I mean you can just ask ChatGPT and Claude, I guess you would answer that in this case it&#x27;s just prediction, but if they were human then it would be understanding.</div><br/><div id="41826990" class="c"><input type="checkbox" id="c-41826990" checked=""/><div class="controls bullet"><span class="by">nonrandomstring</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826937">parent</a><span>|</span><a href="#41826803">next</a><span>|</span><label class="collapse" for="c-41826990">[-]</label><label class="expand" for="c-41826990">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I guess you would answer that in this case it&#x27;s just prediction,<p>No I would answer that it is indeed understanding, to upend your
&quot;guess&quot; (prediction) and so prove that while you think you can
&quot;predict&quot; the next answer you lack understanding of what the argument
is really about :)</div><br/><div id="41827265" class="c"><input type="checkbox" id="c-41827265" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826990">parent</a><span>|</span><a href="#41826803">next</a><span>|</span><label class="collapse" for="c-41827265">[-]</label><label class="expand" for="c-41827265">[1 more]</label></div><br/><div class="children"><div class="content">I think I understand the topic quite well, since you deliberately deviate from answering the question. You made a practical example that doesn&#x27;t really work in practice.</div><br/></div></div></div></div></div></div></div></div><div id="41826803" class="c"><input type="checkbox" id="c-41826803" checked=""/><div class="controls bullet"><span class="by">tourmalinetaco</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826717">parent</a><span>|</span><a href="#41826917">prev</a><span>|</span><a href="#41826851">next</a><span>|</span><label class="collapse" for="c-41826803">[-]</label><label class="expand" for="c-41826803">[1 more]</label></div><br/><div class="children"><div class="content">The MLM has no idea what it’s making, where you are in the map, what you left behind, and what you picked up. It can accurately predict what comes next, but if you pick up an item and do a 360° turn the item will be back and you can repeat the process.</div><br/></div></div><div id="41826851" class="c"><input type="checkbox" id="c-41826851" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826717">parent</a><span>|</span><a href="#41826803">prev</a><span>|</span><a href="#41826854">next</a><span>|</span><label class="collapse" for="c-41826851">[-]</label><label class="expand" for="c-41826851">[3 more]</label></div><br/><div class="children"><div class="content">When a human does it, it&#x27;s understanding, when an AI does it, it&#x27;s prediction, I thinks it&#x27;s very clear &#x2F;s</div><br/><div id="41827024" class="c"><input type="checkbox" id="c-41827024" checked=""/><div class="controls bullet"><span class="by">therouwboat</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826851">parent</a><span>|</span><a href="#41826854">next</a><span>|</span><label class="collapse" for="c-41827024">[-]</label><label class="expand" for="c-41827024">[2 more]</label></div><br/><div class="children"><div class="content">Does what? In normal game world things tend to stay where they are without player having to do anything.</div><br/><div id="41827354" class="c"><input type="checkbox" id="c-41827354" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41827024">parent</a><span>|</span><a href="#41826854">next</a><span>|</span><label class="collapse" for="c-41827354">[-]</label><label class="expand" for="c-41827354">[1 more]</label></div><br/><div class="children"><div class="content">We are talking about neural networks in general, not this one or that one, if you train a bad model or the model is untrained it would not indeed understand much or anything.</div><br/></div></div></div></div></div></div></div></div><div id="41826854" class="c"><input type="checkbox" id="c-41826854" checked=""/><div class="controls bullet"><span class="by">killerstorm</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826633">parent</a><span>|</span><a href="#41826717">prev</a><span>|</span><a href="#41827217">next</a><span>|</span><label class="collapse" for="c-41826854">[-]</label><label class="expand" for="c-41826854">[9 more]</label></div><br/><div class="children"><div class="content">That&#x27;s bs. You have no understanding of understanding.<p>Hooke&#x27;s law was pure curve-fitting. Hooke definitely did not understand the &quot;why&quot;. And yet we don&#x27;t consider that bad physics.<p>Newton&#x27;s laws can be derived from curve fitting. How is that different from &quot;understanding&quot;?</div><br/><div id="41827078" class="c"><input type="checkbox" id="c-41827078" checked=""/><div class="controls bullet"><span class="by">madaxe_again</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826854">parent</a><span>|</span><a href="#41827217">next</a><span>|</span><label class="collapse" for="c-41827078">[-]</label><label class="expand" for="c-41827078">[8 more]</label></div><br/><div class="children"><div class="content">Einstein couldn’t even explain <i>why</i> general relativity occurred. Sure, spacetime is curved by mass, but <i>why</i>? What a loser.</div><br/><div id="41827644" class="c"><input type="checkbox" id="c-41827644" checked=""/><div class="controls bullet"><span class="by">killerstorm</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41827078">parent</a><span>|</span><a href="#41827217">next</a><span>|</span><label class="collapse" for="c-41827644">[-]</label><label class="expand" for="c-41827644">[7 more]</label></div><br/><div class="children"><div class="content">It&#x27;s very illustrative to look into the history of discovery of laws of motion, as it&#x27;s quite well documented.<p>People have an intuitive understanding of motion - we see it literally every day, we throw objects, etc.<p>And yet it took literally thousands of years since discovery of mathematics (geometry, etc.) to formulate a concept of force, momentum, etc.<p>Ancient Greek mathematicians could do integration, so they were not lacking mathematical sophistication. And yet their understanding of motion was so primitive:<p>Aristotle, an extremely smart man, was muttering something about &quot;violent&quot; and &quot;natural&quot; motion: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Newton%27s_laws_of_motion#Antiquity_and_medieval_background" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Newton%27s_laws_of_motion#Anti...</a><p>People started to understand the conservation of quantity of motion only in 17th century.<p>So we have two possibilities:<p>* everyone until 17th century was dumb af (despite being able to do quite impressive calculations)<p>* scientific discovery is really a heuristic-driven search process where people try various things until they find a good fit<p>I.e. millions of people were somehow failing to understand motion for literally thousands of years until they collected enough assertions about motion that they were able to formulate the rule of conservation, test it, and confirm it fits. And only then it became understanding.<p>You can literally see conservation of momentum on a billiard table: you &quot;violently&quot; hit one ball, it hits other balls and they start to move, but slower, etc. So you really transfer something from one ball to the rest. And yet people could not see it for thousands of years.<p>What this shows is that there&#x27;s nothing fundamental about understanding: it&#x27;s just a sense of familiarity, it is a sense that your model fits well. Under the hood it&#x27;s all prediction and curve fitting.<p>We literally have prediction hardware in our brains: cerebellum has specialized cells which can predict, e.g. motion. So people with damaged cerebellum have impaired movement: they still can move, but their movement are not precise. When do you think we find specialized understanding cells in the human brain?</div><br/><div id="41827964" class="c"><input type="checkbox" id="c-41827964" checked=""/><div class="controls bullet"><span class="by">mrob</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41827644">parent</a><span>|</span><a href="#41827217">next</a><span>|</span><label class="collapse" for="c-41827964">[-]</label><label class="expand" for="c-41827964">[6 more]</label></div><br/><div class="children"><div class="content">It seems to me that your evidence supports the exact opposite of your conclusion. Familiarity was only enough to find ad-hoc heuristics for specific situations. It let us discover intuitive methods to throw stones, drive carts, play ball games, etc. but never discovered the general principle behind them. A skilled archer does not automatically know that the same rules can be used to aim a mortar.<p>Ad-hoc heuristics are not the same thing as understanding. It took formal reasoning for humans to actually understand motion, of a type that modern AI does not use. There is something fundamental about understanding that no amount of familiarity can substitute for. Modern AI can gain enormous amounts of familiarity but still fail to understand, e.g. this Counter-Strike simulator not knowing what happens when the player walks into a wall.</div><br/><div id="41828634" class="c"><input type="checkbox" id="c-41828634" checked=""/><div class="controls bullet"><span class="by">killerstorm</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41827964">parent</a><span>|</span><a href="#41827217">next</a><span>|</span><label class="collapse" for="c-41828634">[-]</label><label class="expand" for="c-41828634">[5 more]</label></div><br/><div class="children"><div class="content">People found that `m * v` is the quantity which is conserved.<p>There&#x27;s no understanding. It&#x27;s just a formula which matches the observations. It also matches our intuition (a heavier object is hard to move, etc), and you feel this connection as understanding.<p>Centuries later people found that conservation laws are linked to symmetries. But again, it&#x27;s not some fundamental truth, it&#x27;s just a link between two concepts.<p>LLM can link two concepts too. So why do you believe that LLM cannot understand?<p>I middle school I did extremely well in physics classes - I could solve complex problems which my classmates couldn&#x27;t because I could visualize the physical process (e.g. motion of an object) and link that to formulas. This means I understood it, right?<p>Years later I thought &quot;But what *is* motion, fundamentally?&quot;. I grabbed Landau-Lifshitz mechanics textbook. How do they define motion? Apparently, bodies move in a way to minimize some integral. They can derive the rest from it. But it doesn&#x27;t explain what a motion is. Some of the best physicists in the world cannot define it.<p>So I don&#x27;t think there&#x27;s anything to understanding except feeling of connection between different things. &quot;X is like Y except for Z&quot;.</div><br/><div id="41828757" class="c"><input type="checkbox" id="c-41828757" checked=""/><div class="controls bullet"><span class="by">mrob</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41828634">parent</a><span>|</span><a href="#41827217">next</a><span>|</span><label class="collapse" for="c-41828757">[-]</label><label class="expand" for="c-41828757">[4 more]</label></div><br/><div class="children"><div class="content">Understanding is finding the simplest general solution. Newton&#x27;s laws are understanding. Catching the ball is not. LLMs take billions of parameters to do anything and don&#x27;t even generalize well. That&#x27;s obviously not understanding.</div><br/><div id="41829050" class="c"><input type="checkbox" id="c-41829050" checked=""/><div class="controls bullet"><span class="by">killerstorm</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41828757">parent</a><span>|</span><a href="#41828965">next</a><span>|</span><label class="collapse" for="c-41829050">[-]</label><label class="expand" for="c-41829050">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re confusing two meanings of world &quot;understanding&quot;:<p>1. Finding a comprehensive explanation<p>2. Having a comprehensive explanation which is usable<p>99.999% people on Earth do not discover any new laws, so I don&#x27;t think you use #1 as a fundamental deficiency of LLMs.<p>And nobody is saying that just training a LLM produces understanding of new phenomena. That&#x27;s a strawman.<p>The thesis is that a more powerful LLM together with more software, more models, etc, can potentially discover something new. That&#x27;s not observed yet. But I&#x27;d say it would be weird if LLM can match capabilities of average folk but never match Newton. It&#x27;s not like Newton&#x27;s brain is fundamentally different.<p>Also worth noting that formulas can be discovered by enumeration. E.g. `m * v` should not be particularly hard to discover. And the fact that it took people centuries implies that that&#x27;s what happened: people tried different formulas until they found one which works. It doesn&#x27;t have to be some fancy Newton magic.</div><br/><div id="41829209" class="c"><input type="checkbox" id="c-41829209" checked=""/><div class="controls bullet"><span class="by">mrob</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41829050">parent</a><span>|</span><a href="#41828965">next</a><span>|</span><label class="collapse" for="c-41829209">[-]</label><label class="expand" for="c-41829209">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m certain that people did not spend centuries trying different formulas for the laws of motion before finding one that worked. The crucial insight was applying any formula at all. Once you have that then the rest is relatively easy. I don&#x27;t see LLMs making that kind of discovery.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="41827217" class="c"><input type="checkbox" id="c-41827217" checked=""/><div class="controls bullet"><span class="by">madaxe_again</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826633">parent</a><span>|</span><a href="#41826854">prev</a><span>|</span><a href="#41826671">next</a><span>|</span><label class="collapse" for="c-41827217">[-]</label><label class="expand" for="c-41827217">[1 more]</label></div><br/><div class="children"><div class="content">Yet <i>we</i> have no understanding, only prediction. We can describe a great many things in detail, how they interact - and we can claim to understand things, yet if you recursively ask “why?” everybody, and I mean <i>everybody</i>, will reach a point where they say “I don’t know” or “god”.<p>An incomplete understanding is no understanding at all, and I would argue that we can only predict, and we can certainly emulate reality, otherwise we would not be able to function within it. A toddler can emulate reality, anticipate causality - and they certainly can’t be said to be in possession of a robust grand unified theory.</div><br/></div></div><div id="41826671" class="c"><input type="checkbox" id="c-41826671" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826633">parent</a><span>|</span><a href="#41827217">prev</a><span>|</span><a href="#41826659">next</a><span>|</span><label class="collapse" for="c-41826671">[-]</label><label class="expand" for="c-41826671">[1 more]</label></div><br/><div class="children"><div class="content">For simulations like games, it&#x27;s a trivial matter to feed the neural game engine pixel-perfect metadata.<p>Instead of rendering the final shaded and textured pixels, the engine would output just the material IDs, motion vectors, and similar &quot;meta&quot; data that would normally be the inputs into a real-time shader.<p>The AI can use this as inputs to render a photorealistic output. It can be trained using offline-rendered &quot;ground-truth&quot; raytraced scenes. Potentially, video labelled in a similar way could be used to give it a flair of realism.<p>This is already what NVIDIA DLSS and similar AI upscaling tech uses. The obvious next step is not just to upscale rendered scenes, but to do the rendering itself.</div><br/></div></div></div></div><div id="41826659" class="c"><input type="checkbox" id="c-41826659" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41826595">parent</a><span>|</span><a href="#41826633">prev</a><span>|</span><a href="#41826705">next</a><span>|</span><label class="collapse" for="c-41826659">[-]</label><label class="expand" for="c-41826659">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not <i>that</i> great yet.<p>Given a model which can generate the game view in ~real time and a model which can generate the models and textures, why would you ever use the first option, apart from a cool tech demo? I&#x27;m sure there&#x27;s space for new dreamy games where invisible space behind you transforms when you turn around, but for other genres... why? Destructible environment has been possible for quite a while, but once you allow that everywhere, you can get games into unplayable state. They need to be designed around that mechanic to work well: Noita, Worms, Teardown, etc. I don&#x27;t believe the &quot;limitless physics&quot; would matter after a few minutes.</div><br/></div></div><div id="41826705" class="c"><input type="checkbox" id="c-41826705" checked=""/><div class="controls bullet"><span class="by">Arch485</span><span>|</span><a href="#41826595">parent</a><span>|</span><a href="#41826659">prev</a><span>|</span><a href="#41826615">next</a><span>|</span><label class="collapse" for="c-41826705">[-]</label><label class="expand" for="c-41826705">[2 more]</label></div><br/><div class="children"><div class="content">It seems extremely unlikely to me that ML models will ever run entire games. Nobody wants a game that&#x27;s &quot;entirely indistinguishable from reality&quot; anyways. If they did, they would go outside.<p>I think it&#x27;s possible specific engine components could be ML-driven in the future, like graphics or NPC interactions. This is already happening to a certain degree.<p>Now, I don&#x27;t think it&#x27;s impossible for an ML model to run an entire game. I just don&#x27;t think making + running your game in a predictive ML model will ever be more effective than making a game the normal way.</div><br/><div id="41826724" class="c"><input type="checkbox" id="c-41826724" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#41826595">root</a><span>|</span><a href="#41826705">parent</a><span>|</span><a href="#41826615">next</a><span>|</span><label class="collapse" for="c-41826724">[-]</label><label class="expand" for="c-41826724">[1 more]</label></div><br/><div class="children"><div class="content">Yep, the fuzziness and opaqueness of ML models makes developing an entire game state inside one a non-starter in my opinion. You need precise rules, and you need to be able to iterate on those rules quickly, neither of which are feasible with our current understanding of ML models. Nobody wants a version of CS:GO where fundamental constants like weapon damage run on dream logic.<p>If ML has any place in games it&#x27;s for specific subsystems which don&#x27;t need absolute precision, NPC behaviour, character animation, refining the output of a renderer, that kind of thing.</div><br/></div></div></div></div><div id="41826615" class="c"><input type="checkbox" id="c-41826615" checked=""/><div class="controls bullet"><span class="by">advael</span><span>|</span><a href="#41826595">parent</a><span>|</span><a href="#41826705">prev</a><span>|</span><a href="#41826653">next</a><span>|</span><label class="collapse" for="c-41826615">[-]</label><label class="expand" for="c-41826615">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure that&#x27;s a warranted assumption based on this result, exciting as it is, we are still seeing replication of an extant testable world model, rather than extrapolation that can produce novel mechanics without them being in the training data. I&#x27;m not saying this isn&#x27;t a stepping stone to that, I just think your prediction&#x27;s a little optimistic based on the scope of that problem</div><br/></div></div><div id="41826653" class="c"><input type="checkbox" id="c-41826653" checked=""/><div class="controls bullet"><span class="by">TinkersW</span><span>|</span><a href="#41826595">parent</a><span>|</span><a href="#41826615">prev</a><span>|</span><a href="#41826767">next</a><span>|</span><label class="collapse" for="c-41826653">[-]</label><label class="expand" for="c-41826653">[1 more]</label></div><br/><div class="children"><div class="content">It requires a monster GPU to run 10 fps at what looks like sub 720p... I think it may be abit more than 5 years..</div><br/></div></div></div></div><div id="41826767" class="c"><input type="checkbox" id="c-41826767" checked=""/><div class="controls bullet"><span class="by">snickerer</span><span>|</span><a href="#41826595">prev</a><span>|</span><a href="#41826657">next</a><span>|</span><label class="collapse" for="c-41826767">[-]</label><label class="expand" for="c-41826767">[6 more]</label></div><br/><div class="children"><div class="content">I see where this is going.<p>The next step to create training data is a real human with a bodycam. There is only the need to connect the real body movement (step forward, turning left, etc) to typical keyboard and mouse game control events, to feed them into the model, too.<p>I think that is what the devs here are dreaming about.</div><br/><div id="41826901" class="c"><input type="checkbox" id="c-41826901" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#41826767">parent</a><span>|</span><a href="#41826785">next</a><span>|</span><label class="collapse" for="c-41826901">[-]</label><label class="expand" for="c-41826901">[1 more]</label></div><br/><div class="children"><div class="content">Or a cockpit cam for the world&#x27;s most realistic flight simulator. &#x2F;lighthearted</div><br/></div></div><div id="41826785" class="c"><input type="checkbox" id="c-41826785" checked=""/><div class="controls bullet"><span class="by">devttyeu</span><span>|</span><a href="#41826767">parent</a><span>|</span><a href="#41826901">prev</a><span>|</span><a href="#41826871">next</a><span>|</span><label class="collapse" for="c-41826785">[-]</label><label class="expand" for="c-41826785">[3 more]</label></div><br/><div class="children"><div class="content">The &quot;We live in a simulation&quot; argument just started looking a lot more conceivable.</div><br/><div id="41827657" class="c"><input type="checkbox" id="c-41827657" checked=""/><div class="controls bullet"><span class="by">tiborsaas</span><span>|</span><a href="#41826767">root</a><span>|</span><a href="#41826785">parent</a><span>|</span><a href="#41827271">next</a><span>|</span><label class="collapse" for="c-41827657">[-]</label><label class="expand" for="c-41827657">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m already very suspicious, we just got the same room number in the third hotel in a row. Someone got lazy with the details :)</div><br/></div></div><div id="41827271" class="c"><input type="checkbox" id="c-41827271" checked=""/><div class="controls bullet"><span class="by">iwontberude</span><span>|</span><a href="#41826767">root</a><span>|</span><a href="#41826785">parent</a><span>|</span><a href="#41827657">prev</a><span>|</span><a href="#41826871">next</a><span>|</span><label class="collapse" for="c-41827271">[-]</label><label class="expand" for="c-41827271">[1 more]</label></div><br/><div class="children"><div class="content">Not really because is it simulators all the way down? Simulation theory explains nothing and only adds more unexplainable phenomenon.</div><br/></div></div></div></div><div id="41826871" class="c"><input type="checkbox" id="c-41826871" checked=""/><div class="controls bullet"><span class="by">devttyeu</span><span>|</span><a href="#41826767">parent</a><span>|</span><a href="#41826785">prev</a><span>|</span><a href="#41826657">next</a><span>|</span><label class="collapse" for="c-41826871">[-]</label><label class="expand" for="c-41826871">[1 more]</label></div><br/><div class="children"><div class="content">Could probably make a decent dataset from VR headset tracking cameras + motion sensors + passthrough output + decoded hand movements</div><br/></div></div></div></div><div id="41826657" class="c"><input type="checkbox" id="c-41826657" checked=""/><div class="controls bullet"><span class="by">TealMyEal</span><span>|</span><a href="#41826767">prev</a><span>|</span><a href="#41829708">next</a><span>|</span><label class="collapse" for="c-41826657">[-]</label><label class="expand" for="c-41826657">[3 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the end goal here? personalised games for everyone. ultra-graphics. i dont really see how this is going to be better than our engine based systems.<p>I love being a horse in the 1900s that automobilewill never take off &#x2F;s</div><br/><div id="41827097" class="c"><input type="checkbox" id="c-41827097" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#41826657">parent</a><span>|</span><a href="#41826726">next</a><span>|</span><label class="collapse" for="c-41827097">[-]</label><label class="expand" for="c-41827097">[1 more]</label></div><br/><div class="children"><div class="content">The goal is to train agents that can imagine consequences before acting. But it could also become a cheap way to create experiences and user interfaces on the fly, imagine if you can have any app UI dreamed up like that, not just games. Generative visual interfaces could be a big leap over text mode.</div><br/></div></div><div id="41826726" class="c"><input type="checkbox" id="c-41826726" checked=""/><div class="controls bullet"><span class="by">qayxc</span><span>|</span><a href="#41826657">parent</a><span>|</span><a href="#41827097">prev</a><span>|</span><a href="#41829708">next</a><span>|</span><label class="collapse" for="c-41826726">[-]</label><label class="expand" for="c-41826726">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a research paper. Not everything that comes out of research has an immediate  real-world application in mind.<p>Games are just an accessible and easy to replicate context to work in, they&#x27;re not an end goal or target application.<p>The research is about AI agents interacting with and creating world models. Such world models could just as well be alien environments - i.e. the kind of stuff an interstellar and even interplanetary probe would need to be able to do, as two-way communication over large distances is impractical.</div><br/></div></div></div></div></div></div></div></div></div></body></html>