<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1688461260284" as="style"/><link rel="stylesheet" href="styles.css?v=1688461260284"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.brendangregg.com/blog/2017-05-09/cpu-utilization-is-wrong.html">CPU Utilization Is Wrong (2017)</a>Â <span class="domain">(<a href="https://www.brendangregg.com">www.brendangregg.com</a>)</span></div><div class="subtext"><span>xk3</span> | <span>29 comments</span></div><br/><div><div id="36582379" class="c"><input type="checkbox" id="c-36582379" checked=""/><div class="controls bullet"><span class="by">YZF</span><span>|</span><a href="#36583442">next</a><span>|</span><label class="collapse" for="c-36582379">[-]</label><label class="expand" for="c-36582379">[5 more]</label></div><br/><div class="children"><div class="content">I love Brendan&#x27;s article about load averages but I feel like this is missing the mark.<p>A core, or an execution unit stalling within a core, still count as busy.  I.e. the CPU can&#x27;t process something else.  The utilization metric is correct.  The question of whether a CPU be used more efficiently is in the domain of optimization.  It might be executing NOPs and not stalling.  It could be using an O(N^3) algorithm instead of O(N).</div><br/><div id="36582529" class="c"><input type="checkbox" id="c-36582529" checked=""/><div class="controls bullet"><span class="by">Leszek</span><span>|</span><a href="#36582379">parent</a><span>|</span><a href="#36583442">next</a><span>|</span><label class="collapse" for="c-36582529">[-]</label><label class="expand" for="c-36582529">[4 more]</label></div><br/><div class="children"><div class="content">With out of order execution, speculation, and SMT, it&#x27;s hard to say if an instruction stalling means that the CPU can&#x27;t process something else; CPUs are complex parallel streams of processing and trying to think of them in linear terms necessarily misses some complexity.</div><br/><div id="36583397" class="c"><input type="checkbox" id="c-36583397" checked=""/><div class="controls bullet"><span class="by">bpye</span><span>|</span><a href="#36582379">root</a><span>|</span><a href="#36582529">parent</a><span>|</span><a href="#36582923">next</a><span>|</span><label class="collapse" for="c-36583397">[-]</label><label class="expand" for="c-36583397">[1 more]</label></div><br/><div class="children"><div class="content">Another factor (also mentioned in the article) is dynamic frequency scaling. Is a core at 100% when it&#x27;s running at it&#x27;s running &#x27;flat-out&#x27; at its nominal frequency or when it has boosted? The boost clock generally depends on thermals, silicon quality and maybe time - so in that case what do you make 100%? If you go for nominal being 100% then sometimes you&#x27;re going to be at say 120%.</div><br/></div></div><div id="36582923" class="c"><input type="checkbox" id="c-36582923" checked=""/><div class="controls bullet"><span class="by">M95D</span><span>|</span><a href="#36582379">root</a><span>|</span><a href="#36582529">parent</a><span>|</span><a href="#36583397">prev</a><span>|</span><a href="#36583442">next</a><span>|</span><label class="collapse" for="c-36582923">[-]</label><label class="expand" for="c-36582923">[2 more]</label></div><br/><div class="children"><div class="content">If it could process something else, it would. If it doesn&#x27;t, it means it can&#x27;t. So, what are you trying to say?</div><br/><div id="36583900" class="c"><input type="checkbox" id="c-36583900" checked=""/><div class="controls bullet"><span class="by">FartyMcFarter</span><span>|</span><a href="#36582379">root</a><span>|</span><a href="#36582923">parent</a><span>|</span><a href="#36583442">next</a><span>|</span><label class="collapse" for="c-36583900">[-]</label><label class="expand" for="c-36583900">[1 more]</label></div><br/><div class="children"><div class="content">In the case of SMT (aka hyperthreading) you&#x27;d only know if the CPU can process something else by profiling a different thread that&#x27;s running on the same core.</div><br/></div></div></div></div></div></div></div></div><div id="36583442" class="c"><input type="checkbox" id="c-36583442" checked=""/><div class="controls bullet"><span class="by">kazinator</span><span>|</span><a href="#36582379">prev</a><span>|</span><a href="#36582145">next</a><span>|</span><label class="collapse" for="c-36583442">[-]</label><label class="expand" for="c-36583442">[2 more]</label></div><br/><div class="children"><div class="content">Umm, no.<p>While the memory stalled information could be valuable in optimizing a program, it is correct to count it as part of the CPU busy.<p>Busy means the CPU was occupied with a task (other than the operating system&#x27;s idle task), <i>and thus not available for another task</i>, regardless of how well or poorly it is making any sort of useful progress.<p>Just like you&#x27;re busy at work even when you&#x27;re wiping your monitor instead of coding.<p>Since &quot;waiting for memory&quot; isn&#x27;t something handled by the scheduler (is not a scheduling wait), it just looks like any other non-scheduler-related busy.<p>A program can keep a CPU busy in multiple of ways such that there is no &quot;utility&quot; even in the absence of memory stalls. It might have a bug which causes it to loop infinitely. Or it could be a service application which is wrongly blowing through what should be a wait at the top of its loop.<p>In the days of multi-user systems at universities, administrations looked upon the running of game programs as a no-utility activity.</div><br/><div id="36583772" class="c"><input type="checkbox" id="c-36583772" checked=""/><div class="controls bullet"><span class="by">blueflow</span><span>|</span><a href="#36583442">parent</a><span>|</span><a href="#36582145">next</a><span>|</span><label class="collapse" for="c-36583772">[-]</label><label class="expand" for="c-36583772">[1 more]</label></div><br/><div class="children"><div class="content">Memory stall means re-fetching an evicted or not-yet-faulted-in page from disk, so its disk I&#x2F;O, which is done asynchronously and leaves the CPU available for another task.</div><br/></div></div></div></div><div id="36582145" class="c"><input type="checkbox" id="c-36582145" checked=""/><div class="controls bullet"><span class="by">sweetjuly</span><span>|</span><a href="#36583442">prev</a><span>|</span><a href="#36582396">next</a><span>|</span><label class="collapse" for="c-36582145">[-]</label><label class="expand" for="c-36582145">[2 more]</label></div><br/><div class="children"><div class="content">Hmm, I feel like this is a bit too big of a generalization to be useful. It&#x27;s a cool observation but I don&#x27;t think you can interpet IPC so directly as to conclude that IPC &lt; 1 indicates &quot;you are likely memory stalled&quot;. There are a million reasons why you&#x27;d have an IPC &lt; 1, many of them which are not memory. Maybe you just have a lot of hard to predict branches which take a long time to resolve (all that mispeculated work is wasted cycles!), maybe you use a lot of long latency FP operations, maybe you just have really long dependency chains. If your core doesn&#x27;t have full speculative wakeups for variable latency instructions (meaning things like loads but often things like division and multiplication have early exits), you can very easily end up with plenty of cycles where you don&#x27;t complete an instruction. And, yes, of course, it could be that you&#x27;re having a lot of cache misses. Memory is a good guess but it&#x27;s not really actionable advice for performance analysis, you really need to pull out some proper tools to understand why you&#x27;re getting that number.<p>I think this is a cool article in that, yes, Task Manager&#x2F;top&#x2F;Activity Monitor aren&#x27;t telling you the full story when it comes to what &quot;CPU %&quot; means. In the end though, there really isn&#x27;t an easy way to come up with a better metric for utilization that can be summarized in one number, so realistically &quot;how much time did the scheduler put this process on a core for&quot; is plenty good enough for most purposes.</div><br/><div id="36582273" class="c"><input type="checkbox" id="c-36582273" checked=""/><div class="controls bullet"><span class="by">failuser</span><span>|</span><a href="#36582145">parent</a><span>|</span><a href="#36582396">next</a><span>|</span><label class="collapse" for="c-36582273">[-]</label><label class="expand" for="c-36582273">[1 more]</label></div><br/><div class="children"><div class="content">Memory is just the most common. Most software does not involve complicated calculations to get to the other reasons.</div><br/></div></div></div></div><div id="36582396" class="c"><input type="checkbox" id="c-36582396" checked=""/><div class="controls bullet"><span class="by">failuser</span><span>|</span><a href="#36582145">prev</a><span>|</span><a href="#36583715">next</a><span>|</span><label class="collapse" for="c-36582396">[-]</label><label class="expand" for="c-36582396">[3 more]</label></div><br/><div class="children"><div class="content">Did anyone had the impression that utilization reflects the actual computations the CPU does? It only reflects the fraction the of wall clock time spent in the context, nothing more.</div><br/><div id="36582857" class="c"><input type="checkbox" id="c-36582857" checked=""/><div class="controls bullet"><span class="by">JBiserkov</span><span>|</span><a href="#36582396">parent</a><span>|</span><a href="#36583715">next</a><span>|</span><label class="collapse" for="c-36582857">[-]</label><label class="expand" for="c-36582857">[2 more]</label></div><br/><div class="children"><div class="content">Reminds me of the old saying<p>&quot;A computer is a device that moves data around and <i>occasionally</i> does computations with it.&quot;<p>think network&#x2F;disk -&gt; RAM -&gt; L3 -&gt; L2 -&gt; L1 -&gt; registers</div><br/><div id="36583371" class="c"><input type="checkbox" id="c-36583371" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36582396">root</a><span>|</span><a href="#36582857">parent</a><span>|</span><a href="#36583715">next</a><span>|</span><label class="collapse" for="c-36583371">[-]</label><label class="expand" for="c-36583371">[1 more]</label></div><br/><div class="children"><div class="content">CPUs can broadly be considered to have three major components:<p>- Memory subsystem<p>- Frontend<p>- Backend<p>That is:<p>- Get the data to work on<p>- Figure out what work to do on it<p>- Actually do the work.<p>These are in order of decreasing importance.  The von neumann bottleneck is real.</div><br/></div></div></div></div></div></div><div id="36583715" class="c"><input type="checkbox" id="c-36583715" checked=""/><div class="controls bullet"><span class="by">bullen</span><span>|</span><a href="#36582396">prev</a><span>|</span><a href="#36580262">next</a><span>|</span><label class="collapse" for="c-36583715">[-]</label><label class="expand" for="c-36583715">[1 more]</label></div><br/><div class="children"><div class="content">So is IPC another measurement of cache-misses?<p>Tried running tiptop on Raspberry 4, it fails with no workaround on the internet.<p><i>shrugs</i> and goes back to write poor software.<p>Last week I tried to get RDMA bypassing the kernel.<p>Also did not work.<p>Nothing works. Like NOTHING!</div><br/></div></div><div id="36580262" class="c"><input type="checkbox" id="c-36580262" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#36583715">prev</a><span>|</span><a href="#36582961">next</a><span>|</span><label class="collapse" for="c-36580262">[-]</label><label class="expand" for="c-36580262">[4 more]</label></div><br/><div class="children"><div class="content">SMT is pitched as a good way to &quot;hide&quot; low IPC loads by giving the core something else to do while waiting for memory. Hence IBM and (very briefly) Marvell both shipped 4-way SMT cores for database-heavy workloads.<p>AFAIK this further complicates the IPC metric. What looks like a stalled core might actually be working on another thread. And at the other extreme, two very high IPC threads on one core would lower the observed IPC of each thread.</div><br/><div id="36581158" class="c"><input type="checkbox" id="c-36581158" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#36580262">parent</a><span>|</span><a href="#36582961">next</a><span>|</span><label class="collapse" for="c-36581158">[-]</label><label class="expand" for="c-36581158">[3 more]</label></div><br/><div class="children"><div class="content">I was always curious why they didn&#x27;t just make pairs of CPUs that shared a few logic units in common. Like I don&#x27;t know what the instruction mix is these days and just how long the pipeline is, but say most code can do 2-3 ALU instructions per clock, why not 2 cores with 1-2 ALUs each and 2 shared?<p>As things are, there is very little guarantee that the hyperthread will make any substantial progress.</div><br/><div id="36581837" class="c"><input type="checkbox" id="c-36581837" checked=""/><div class="controls bullet"><span class="by">csherratt</span><span>|</span><a href="#36580262">root</a><span>|</span><a href="#36581158">parent</a><span>|</span><a href="#36582961">next</a><span>|</span><label class="collapse" for="c-36581837">[-]</label><label class="expand" for="c-36581837">[2 more]</label></div><br/><div class="children"><div class="content">AMD Bulldozer did something like this. Ultraspac T1 had a shared FPU too. There is are a savings there, but neither of these solutions ended up being practically fast. The amount of die space spent on an ALU is relatively low compared to the rest of the CPU, hence why they shared FPUs instread.<p>We might see it again now that the server world is having an ARM CPU renaissance. But I doubt AMD or Intel will make anything that exotic.</div><br/><div id="36582077" class="c"><input type="checkbox" id="c-36582077" checked=""/><div class="controls bullet"><span class="by">sweetjuly</span><span>|</span><a href="#36580262">root</a><span>|</span><a href="#36581837">parent</a><span>|</span><a href="#36582961">next</a><span>|</span><label class="collapse" for="c-36582077">[-]</label><label class="expand" for="c-36582077">[1 more]</label></div><br/><div class="children"><div class="content">I sort of hope we don&#x27;t see SMT ARM cores. SMT was&#x2F;is a huge pain for side channels and all the ARM chip houses dodged that one by nature of just never implementing it. I would hope that the concern of cloud vendors over isolation would be enough to discourage bringing <i>more</i> SMT uarchs in to this world.</div><br/></div></div></div></div></div></div></div></div><div id="36582961" class="c"><input type="checkbox" id="c-36582961" checked=""/><div class="controls bullet"><span class="by">M95D</span><span>|</span><a href="#36580262">prev</a><span>|</span><a href="#36581821">next</a><span>|</span><label class="collapse" for="c-36582961">[-]</label><label class="expand" for="c-36582961">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not familiar with modern CPUs, but I remember that most instructions take more than one cycle to execute, without counting memory or cache delays. So, expecting to see 1:1 IPC is ... a fantasy?</div><br/><div id="36583130" class="c"><input type="checkbox" id="c-36583130" checked=""/><div class="controls bullet"><span class="by">kryptiskt</span><span>|</span><a href="#36582961">parent</a><span>|</span><a href="#36583183">next</a><span>|</span><label class="collapse" for="c-36583130">[-]</label><label class="expand" for="c-36583130">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s true, instructions generally take more than one cycle to execute, although the most common ones are fast. But processors these days can execute more than one instruction at a time (this has nothing to do with multiple cores, this is on a single core) and aren&#x27;t bound to the order the instructions appear in the code, it will make sure that instructions that are dependent on each other will be executed in the right order, otherwise it can opportunistically execute whatever it has room for. Modern processors even speculatively executes code from branches it doesn&#x27;t yet know will be taken, which caused the whole Meltdown&#x2F;Spectre security headache.</div><br/></div></div><div id="36583183" class="c"><input type="checkbox" id="c-36583183" checked=""/><div class="controls bullet"><span class="by">somat</span><span>|</span><a href="#36582961">parent</a><span>|</span><a href="#36583130">prev</a><span>|</span><a href="#36583355">next</a><span>|</span><label class="collapse" for="c-36583183">[-]</label><label class="expand" for="c-36583183">[1 more]</label></div><br/><div class="children"><div class="content">Many processing units can offset this via superscaler methods, that is tricks to have more than one instruction processing at the same time. pipelining, speculative execution, smt, etc.<p>The article does not go into great depth about it, but does say that the 1 ipc ratio number is based off more gut feel than anything else. I assume the idea is that the superscaler bits(greater than 1 ipc ratio) help compensate for the slow bits(less than 1 ipc ratio) normalizing out at around a 1 ipc ratio when your code is good.</div><br/></div></div><div id="36583355" class="c"><input type="checkbox" id="c-36583355" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#36582961">parent</a><span>|</span><a href="#36583183">prev</a><span>|</span><a href="#36583132">next</a><span>|</span><label class="collapse" for="c-36583355">[-]</label><label class="expand" for="c-36583355">[1 more]</label></div><br/><div class="children"><div class="content">They do take more than cycle (how many depend on how you count), but they are fully pipelined so they can start executing an ( independent) instruction before a previous one has finished.<p>They are also superscalar so they have multiple (pipelined) units that can start executing instructions at the same time.</div><br/></div></div><div id="36583132" class="c"><input type="checkbox" id="c-36583132" checked=""/><div class="controls bullet"><span class="by">anurag6892</span><span>|</span><a href="#36582961">parent</a><span>|</span><a href="#36583355">prev</a><span>|</span><a href="#36581821">next</a><span>|</span><label class="collapse" for="c-36583132">[-]</label><label class="expand" for="c-36583132">[1 more]</label></div><br/><div class="children"><div class="content">yes, most instructions are multicycle. but multiple instructions can execute in parallel in the CPU pipeline.<p>Moreover, while latency is multiple cycles, most ALU units in CPU can start a new operation every cycle i.e. throughput is 1 operation per cycle.</div><br/></div></div></div></div><div id="36581821" class="c"><input type="checkbox" id="c-36581821" checked=""/><div class="controls bullet"><span class="by">nubinetwork</span><span>|</span><a href="#36582961">prev</a><span>|</span><a href="#36581187">next</a><span>|</span><label class="collapse" for="c-36581821">[-]</label><label class="expand" for="c-36581821">[3 more]</label></div><br/><div class="children"><div class="content">Why use top when you can use htop?  It breaks down CPU usage into various parts like IO wait and vm guest time...  they even integrated functionality from iotop so you eventually won&#x27;t need that program either.</div><br/><div id="36582686" class="c"><input type="checkbox" id="c-36582686" checked=""/><div class="controls bullet"><span class="by">pavon</span><span>|</span><a href="#36581821">parent</a><span>|</span><a href="#36581187">next</a><span>|</span><label class="collapse" for="c-36582686">[-]</label><label class="expand" for="c-36582686">[2 more]</label></div><br/><div class="children"><div class="content">The &quot;Detailed CPU time&quot; setting in htop doesn&#x27;t show the time the CPU is waiting on memory, it is just traditional I&#x2F;O (disk, network, etc).</div><br/><div id="36583075" class="c"><input type="checkbox" id="c-36583075" checked=""/><div class="controls bullet"><span class="by">oriettaxx</span><span>|</span><a href="#36581821">root</a><span>|</span><a href="#36582686">parent</a><span>|</span><a href="#36581187">next</a><span>|</span><label class="collapse" for="c-36583075">[-]</label><label class="expand" for="c-36583075">[1 more]</label></div><br/><div class="children"><div class="content">he is suggesting the use of `tiptop`</div><br/></div></div></div></div></div></div><div id="36581187" class="c"><input type="checkbox" id="c-36581187" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#36581821">prev</a><span>|</span><a href="#36581741">next</a><span>|</span><label class="collapse" for="c-36581187">[-]</label><label class="expand" for="c-36581187">[2 more]</label></div><br/><div class="children"><div class="content">How long has it been the case that a CPU would basically catch on fire if it could run without pipeline stalls slowing down the thermal dissipation?</div><br/><div id="36582028" class="c"><input type="checkbox" id="c-36582028" checked=""/><div class="controls bullet"><span class="by">sweetjuly</span><span>|</span><a href="#36581187">parent</a><span>|</span><a href="#36581741">next</a><span>|</span><label class="collapse" for="c-36582028">[-]</label><label class="expand" for="c-36582028">[1 more]</label></div><br/><div class="children"><div class="content">Stalls are not necessary for thermal regulation, DVFS [1] is the tool we actually use for handling thermal limits (generally referred to as &quot;thermal throttling&quot;). In a modern CPU, you really don&#x27;t expect (or, rather, want) to be fully stalled ever, that&#x27;s the point of very deep reorder buffers. You can try this yourself, make a long loop with a ton of unrelated int and fp operations (unrelated so as not to cause dependency chains) and you&#x27;ll get 100% occupancy without the core catching on fire.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dynamic_frequency_scaling" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dynamic_frequency_scaling</a></div><br/></div></div></div></div><div id="36581741" class="c"><input type="checkbox" id="c-36581741" checked=""/><div class="controls bullet"><span class="by">kaelinl</span><span>|</span><a href="#36581187">prev</a><span>|</span><label class="collapse" for="c-36581741">[-]</label><label class="expand" for="c-36581741">[1 more]</label></div><br/><div class="children"><div class="content">(2017)</div><br/></div></div></div></div></div></div></div></body></html>