<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1689152467644" as="style"/><link rel="stylesheet" href="styles.css?v=1689152467644"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2101.00027">The Pile: An 800GB dataset of diverse text for language modeling (2020)</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>charlysl</span> | <span>58 comments</span></div><br/><div><div id="36686476" class="c"><input type="checkbox" id="c-36686476" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36691132">next</a><span>|</span><label class="collapse" for="c-36686476">[-]</label><label class="expand" for="c-36686476">[41 more]</label></div><br/><div class="children"><div class="content">Author here. And by author I mean I created books3 (the books component of The Pile) while everyone else did the hard work of actually writing the paper, ha. Stella and Leo Gao in particular did so much wonderful work on the paper, though it couldn’t have happened without everyone’s contributions.<p>As far as I know, this was the first academic contribution from a discord collaboration to ML. Back then discord was barely used for ML at all, though nowadays of course the largest discord in the world is midjourney.<p>There were a bunch of interesting stories from those days. We almost didn’t release at all (or at least the books component) because of fear of copyright backlash. Turns out no one cared, and then suddenly today the world cares a great deal.<p>As a side note, I’ll be participating in a legal action against Meta for the purpose of making ML models uncopyrightable: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;theshawwn&#x2F;status&#x2F;1641804013791215619?s=61&amp;t=jQbmCk1JqL7depzFWJNuPA" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;theshawwn&#x2F;status&#x2F;1641804013791215619?s=6...</a>. They DMCA’ed one of my repos distributing LLaMA, so we fought back and challenged the idea that weights can be copyrighted at all. This seems like the best outcome for hackers and individual researchers, for a few reasons. It’s also one of the most ethical outcomes; since ~no one trains on data that they own, they shouldn’t own the resulting model.<p>One last thing. The Pile would’ve been far less relevant without the wonderful assistance of The Eye, a group of people who archive all kinds of things. They’ve hosted the datasets for years now. And although it seems strange to say that dataset hosting could make or break The Pile, back then there was nobody else willing to host us. <a href="https:&#x2F;&#x2F;the-eye.eu&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;the-eye.eu&#x2F;</a></div><br/><div id="36688435" class="c"><input type="checkbox" id="c-36688435" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#36686476">parent</a><span>|</span><a href="#36687102">next</a><span>|</span><label class="collapse" for="c-36688435">[-]</label><label class="expand" for="c-36688435">[14 more]</label></div><br/><div class="children"><div class="content">Hi Shawn, re your side note, I disagree with you that we&#x27;d be better off if weights couldn&#x27;t be copyrighted - basically because copyright gives options like GPL that can keep models open, otherwise we&#x27;re just going to see everything good disappear behind trade secret. That said I fully support your &quot;civil disobedience&quot; in sharing the weights. I don&#x27;t expect you to agree, but take a look at something I just wrote about this yesterday: <a href="http:&#x2F;&#x2F;marble.onl&#x2F;posts&#x2F;model_weight_copyrights.html" rel="nofollow noreferrer">http:&#x2F;&#x2F;marble.onl&#x2F;posts&#x2F;model_weight_copyrights.html</a> . I&#x27;m happy to chat about it if you&#x27;re interested.</div><br/><div id="36688730" class="c"><input type="checkbox" id="c-36688730" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688435">parent</a><span>|</span><a href="#36691820">next</a><span>|</span><label class="collapse" for="c-36688730">[-]</label><label class="expand" for="c-36688730">[2 more]</label></div><br/><div class="children"><div class="content">It might seem like I’m entrenched in my position, but it’s quite the opposite — the only reason I’m doing this is because I really believe it’s the best outcome for devs in the long run. I’m open to changing my mind and pulling the plug in everything.<p>I’ll read over your essay and give it some thought. There are a bunch of subtle aspects to consider; I’ve been thinking it over for about four months now and still haven’t covered all the territory yet.<p>It feels like this may be one of the most important decisions going forward — both from an intellectual property point of view, and an individual rights perspective. E.g. you mention that it’s civil disobedience to share the weights, but it feels like if someone is claiming to do open science (LLaMA), sharing the research materials is the minimum requirement. Plus look how it’s benefited them; they’ve captured most of the open source LLM mindshare. So it seems likely that this will lead to more open source work in the long run, not less.<p>Feel free to chat! You can DM me on Twitter or email me. I’ve been in the hospital with my wife for 7 weeks, with two to go, so I’ve been a bit less responsive than I usually am.</div><br/><div id="36688948" class="c"><input type="checkbox" id="c-36688948" checked=""/><div class="controls bullet"><span class="by">scoot</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688730">parent</a><span>|</span><a href="#36691820">next</a><span>|</span><label class="collapse" for="c-36688948">[-]</label><label class="expand" for="c-36688948">[1 more]</label></div><br/><div class="children"><div class="content">~I’ll read over your essay~<p>I&#x27;l get an LLM to summarise your essay...</div><br/></div></div></div></div><div id="36691820" class="c"><input type="checkbox" id="c-36691820" checked=""/><div class="controls bullet"><span class="by">zarzavat</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688435">parent</a><span>|</span><a href="#36688730">prev</a><span>|</span><a href="#36691719">next</a><span>|</span><label class="collapse" for="c-36691820">[-]</label><label class="expand" for="c-36691820">[1 more]</label></div><br/><div class="children"><div class="content">There’s no use living a lie. Training a model is not an act of creative expression and cannot give you authorship of the weights. Enforcing GPL if you don’t have IP no better than any other copyright troll…</div><br/></div></div><div id="36691719" class="c"><input type="checkbox" id="c-36691719" checked=""/><div class="controls bullet"><span class="by">amoss</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688435">parent</a><span>|</span><a href="#36691820">prev</a><span>|</span><a href="#36690374">next</a><span>|</span><label class="collapse" for="c-36691719">[-]</label><label class="expand" for="c-36691719">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If you’re sceptical, go look at one of the forums where people are building derivatives of Stable Diffusion (possibly NSFW, I’m not providing any links).<p>Does anybody have a link to a relevant discussion here? I would like to read about the creative process that goes into defining model weights, and how it differs from the mechanical output of running the training algorithm.</div><br/></div></div><div id="36690374" class="c"><input type="checkbox" id="c-36690374" checked=""/><div class="controls bullet"><span class="by">js8</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688435">parent</a><span>|</span><a href="#36691719">prev</a><span>|</span><a href="#36691409">next</a><span>|</span><label class="collapse" for="c-36690374">[-]</label><label class="expand" for="c-36690374">[3 more]</label></div><br/><div class="children"><div class="content">&gt; otherwise we&#x27;re just going to see everything good disappear behind trade secret<p>We will see that anyway. All the code I work on commercially is copyrighted and yet a trade secret. Existence of copyright (with the exception of copyleft, but that&#x27;s subversion) didn&#x27;t help software to be open sourced.<p>IMHO allowing models to be copyrighted is basically 18th century enclosures again.</div><br/><div id="36690566" class="c"><input type="checkbox" id="c-36690566" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36690374">parent</a><span>|</span><a href="#36691409">next</a><span>|</span><label class="collapse" for="c-36690566">[-]</label><label class="expand" for="c-36690566">[2 more]</label></div><br/><div class="children"><div class="content">&gt; All the code I work on commercially is copyrighted<p>What do you mean by that? Do you continuously copyright the changes?</div><br/><div id="36690682" class="c"><input type="checkbox" id="c-36690682" checked=""/><div class="controls bullet"><span class="by">js8</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36690566">parent</a><span>|</span><a href="#36691409">next</a><span>|</span><label class="collapse" for="c-36690682">[-]</label><label class="expand" for="c-36690682">[1 more]</label></div><br/><div class="children"><div class="content">Yes, more or less. I am not really sure why we legally do that, I believe it&#x27;s just another protection in case someone actually copies the code.</div><br/></div></div></div></div></div></div><div id="36691409" class="c"><input type="checkbox" id="c-36691409" checked=""/><div class="controls bullet"><span class="by">vr46</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688435">parent</a><span>|</span><a href="#36690374">prev</a><span>|</span><a href="#36691050">next</a><span>|</span><label class="collapse" for="c-36691409">[-]</label><label class="expand" for="c-36691409">[5 more]</label></div><br/><div class="children"><div class="content">Reading these discussions with interest as I am in the process of making and training my own personal model using my 31+ archive of photography, pictures taken and owned by be, which goes against this idea that models are not trained on data owned by the companies doing the training. While this is all for my own personal interest and use, how would the idea that the weights cannot be copyrighted affect my rights on the model if I were to release the whole thing for use?</div><br/><div id="36691447" class="c"><input type="checkbox" id="c-36691447" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36691409">parent</a><span>|</span><a href="#36691606">next</a><span>|</span><label class="collapse" for="c-36691447">[-]</label><label class="expand" for="c-36691447">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d be interested to know how your  model performs if it is trained <i>only</i> on your own work.<p>Assuming you haven&#x27;t taken a photo a second for your entire life, then I suspect you&#x27;ll struggle to make something even close to what&#x27;s available publically, due to lack of training data.</div><br/><div id="36691752" class="c"><input type="checkbox" id="c-36691752" checked=""/><div class="controls bullet"><span class="by">vr46</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36691447">parent</a><span>|</span><a href="#36691606">next</a><span>|</span><label class="collapse" for="c-36691752">[-]</label><label class="expand" for="c-36691752">[1 more]</label></div><br/><div class="children"><div class="content">Obviously not, but the point isn&#x27;t to make a public model, but to make something out of my own - my question was how does ownership work? At some point, somebody is going to be making something out of their own massive archive.</div><br/></div></div></div></div><div id="36691606" class="c"><input type="checkbox" id="c-36691606" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36691409">parent</a><span>|</span><a href="#36691447">prev</a><span>|</span><a href="#36691050">next</a><span>|</span><label class="collapse" for="c-36691606">[-]</label><label class="expand" for="c-36691606">[2 more]</label></div><br/><div class="children"><div class="content">How big is the archive? These models are typically trained on at least 100M images.</div><br/><div id="36691739" class="c"><input type="checkbox" id="c-36691739" checked=""/><div class="controls bullet"><span class="by">vr46</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36691606">parent</a><span>|</span><a href="#36691050">next</a><span>|</span><label class="collapse" for="c-36691739">[-]</label><label class="expand" for="c-36691739">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s around 1M images in there, I was wondering whether the labelling and object detection would be more important than the quantity.</div><br/></div></div></div></div></div></div><div id="36691050" class="c"><input type="checkbox" id="c-36691050" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688435">parent</a><span>|</span><a href="#36691409">prev</a><span>|</span><a href="#36687102">next</a><span>|</span><label class="collapse" for="c-36691050">[-]</label><label class="expand" for="c-36691050">[1 more]</label></div><br/><div class="children"><div class="content">Even RMS himself prefers the abolition of copyright over the existence of the GPL.<p>Besides, it&#x27;s already pretty unambiguous that weights are not copyrightable: they&#x27;re a result of a mechanical process.  The only original creative input that goes in to the weights is the unfathomable amounts of content scraped from other sources that aren&#x27;t the authorship of the models.  The objective of the gradient descent is simply minimizing loss on the training data.<p>Facebook doesn&#x27;t own the llama model weights any more than the Bridgeman Art Library practically owns the paintings of European masters because they made quality scans of them. ( <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bridgeman_Art_Library_v._Corel_Corp" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bridgeman_Art_Library_v._Corel...</a>. ), or any more than Rural Telephone owns the phone directory ( <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Feist_Publications,_Inc.,_v._Rural_Telephone_Service_Co" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Feist_Publications,_Inc.,_v._R...</a>. ).<p>Trying to <i>make</i> model weights copyrightable is going uphill, and I don&#x27;t see how you get there without first establishing that the these LLM are unlawful derivatives of a countless number of copyrighted works along the way.  Doing so would probably create a immediate monopoly for legally created LLMs for the hand full of corporations with quasi-monopoly content hosting services (facebook, google, etc) that can (and&#x2F;or already have) stuffed licensing into their terms of use.<p>Do you want a cyberpunk dystopia?  I think creating an AI monopoly is how you get a cyberpunk dystopia -- and the two ways we end up with one is either outright restrictions on private development of AI like some have been lobbying for and the other is the extension of copyright so that only a few entities can get access to enough of other people&#x27;s data at a low enough cost to train them.</div><br/></div></div></div></div><div id="36687102" class="c"><input type="checkbox" id="c-36687102" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#36686476">parent</a><span>|</span><a href="#36688435">prev</a><span>|</span><a href="#36686779">next</a><span>|</span><label class="collapse" for="c-36687102">[-]</label><label class="expand" for="c-36687102">[7 more]</label></div><br/><div class="children"><div class="content">I understand that LLMs to date have mostly been trained on a wide variety of copyright-encumbered data but in other domains (computer vision for example) the tradeoffs are different and in practice many models are trained on private &#x2F; unencumbered data. If those weights are not protected by copyright then my concern is it will be hard to sufficiently protect them via license agreement and it will become yet another factor favoring the SaaSification of everything in tech.</div><br/><div id="36688154" class="c"><input type="checkbox" id="c-36688154" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36687102">parent</a><span>|</span><a href="#36687325">next</a><span>|</span><label class="collapse" for="c-36688154">[-]</label><label class="expand" for="c-36688154">[4 more]</label></div><br/><div class="children"><div class="content">This is true, and it&#x27;s why I hesitated to file legal action. My goal was to benefit hackers. If the outcome causes problems for people who are just trying to share their work, I&#x27;d be upset.<p>Ultimately what convinced me to proceed is that there are immense forces pressuring ML models to become SaaS companies. It&#x27;s very difficult to offer an ML model for extended periods <i>without</i> being a company. E.g. <a href="https:&#x2F;&#x2F;6b.eleuther.ai&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;6b.eleuther.ai&#x2F;</a> is down. Eleuther failing illustrates just how hard it is –– we were all working as hard as we could to design something that would last a long time, and a long time turned out to be two short years. Contrast that with other kinds of hacking (e.g. webdev, gamedev, hardware...) where the end result lasts basically forever.<p>So if ML models aren&#x27;t copyrightable, I think it&#x27;ll hurt companies a lot more than individuals. In fact the goal is the other way around: to protect individuals. All I did was publish Facebook&#x27;s own GPL download script to github, and it got DMCA&#x27;d. If we don&#x27;t push back on that kind of behavior now, companies will get used to the idea that they control &quot;their&quot; model –– even when their model is anything but theirs.</div><br/><div id="36689440" class="c"><input type="checkbox" id="c-36689440" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688154">parent</a><span>|</span><a href="#36688895">next</a><span>|</span><label class="collapse" for="c-36689440">[-]</label><label class="expand" for="c-36689440">[2 more]</label></div><br/><div class="children"><div class="content">If an individual trains a model on their own data to embody their own skills and behaviour, so that they can then sell&#x2F;rent that model out to work on their behalf, well in that scenario not being able to treat the weights as intellectual property (copyright or otherwise controllable by a license), would be a huge violation and detrimental to that individual.<p>I think it would be a shame to try to build legislation around the notion of the sass melting pot application of machine learning and in the process destroy all sorts of other use cases.</div><br/><div id="36690445" class="c"><input type="checkbox" id="c-36690445" checked=""/><div class="controls bullet"><span class="by">js8</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36689440">parent</a><span>|</span><a href="#36688895">next</a><span>|</span><label class="collapse" for="c-36690445">[-]</label><label class="expand" for="c-36690445">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If an individual trains a model on their own data to embody their own skills and behaviour, so that they can then sell&#x2F;rent that model out to work on their behalf<p>No, because we already do not treat all work as copyrightable. A plumber doesn&#x27;t get copyright on his piping job. It has to be original enough. So while your own skill might be original enough to warrant copyright, distilling it into a model might not.</div><br/></div></div></div></div><div id="36688895" class="c"><input type="checkbox" id="c-36688895" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688154">parent</a><span>|</span><a href="#36689440">prev</a><span>|</span><a href="#36687325">next</a><span>|</span><label class="collapse" for="c-36688895">[-]</label><label class="expand" for="c-36688895">[1 more]</label></div><br/><div class="children"><div class="content">I think the DMCA being a massive overreach is a separate issue from whether weights should be eligible for copyright. This is a complicated legal area and I&#x27;m very much not a lawyer so let me just stick to some examples that guide my thinking:<p>- Grammarly. Clear value prop, if weights can&#x27;t be adequately protected then that&#x27;s a significant headwind against doing processing on the client.<p>- Adobe Firefly. Could run locally, they understand the technical challenges well, same headwind.<p>- GitHub Copilot. Same.<p>Copyright protection is probably not a single deciding issue in their product strategy but all of those are use cases that would for most users be better run locally as hardware can support that and are not going to because it&#x27;s too much of a risk. Better to limit distribution and protect as trade secret.<p>The most powerful force for openness I see has nothing to do with copyright eligibility and everything to do with companies wanting to showcase their research arms to build brand and support recruiting. That leads me to believe it&#x27;s probably better for models to be eligible for copyright and considered derivatives of all of the constituent training data. In some ways the better parallel is sampling in the music industry. It&#x27;ll be interesting to see how this plays out.</div><br/></div></div></div></div><div id="36687325" class="c"><input type="checkbox" id="c-36687325" checked=""/><div class="controls bullet"><span class="by">idiotsecant</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36687102">parent</a><span>|</span><a href="#36688154">prev</a><span>|</span><a href="#36686779">next</a><span>|</span><label class="collapse" for="c-36687325">[-]</label><label class="expand" for="c-36687325">[2 more]</label></div><br/><div class="children"><div class="content">Is it useful to protect weights with copyright? What if I download your weights and retrain them for 5 seconds, changing each weight .0000001%? How much change is a new product? What if I change a single weight?</div><br/><div id="36687403" class="c"><input type="checkbox" id="c-36687403" checked=""/><div class="controls bullet"><span class="by">hedgehog</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36687325">parent</a><span>|</span><a href="#36686779">next</a><span>|</span><label class="collapse" for="c-36687403">[-]</label><label class="expand" for="c-36687403">[1 more]</label></div><br/><div class="children"><div class="content">Like the parallel scenarios of taking a book and changing a few words, slapping a new logo on someone else&#x27;s app, or stylizing a photo with a filter, those are questions that will be answered in court if people can&#x27;t come to an agreement on their own.</div><br/></div></div></div></div></div></div><div id="36686779" class="c"><input type="checkbox" id="c-36686779" checked=""/><div class="controls bullet"><span class="by">sfriedr</span><span>|</span><a href="#36686476">parent</a><span>|</span><a href="#36687102">prev</a><span>|</span><a href="#36691504">next</a><span>|</span><label class="collapse" for="c-36686779">[-]</label><label class="expand" for="c-36686779">[6 more]</label></div><br/><div class="children"><div class="content">Could you share more about copyright? For example, aren&#x27;t you worried that now, with all kinds of lawsuits happening [1] and copyright issues that were found in existing datasets [2], that you might get threatening letters from a lawyer some day?<p>I&#x27;m the author of [3] where we introduced one of the first natural-language datasets that test graduate mathematics for LLMs, but some of the prompts we took from a copyrighted book and therefore thought about excluding them. Having them in the public dataset would be really nice though, hence I&#x27;m keen about your experience.<p>I&#x27;d also be keen to hear how your challenge against the DMCA on sharing LLaMA&#x27;s weights goes?<p>[1] <a href="https:&#x2F;&#x2F;www.theguardian.com&#x2F;books&#x2F;2023&#x2F;jul&#x2F;05&#x2F;authors-file-a-lawsuit-against-openai-for-unlawfully-ingesting-their-books" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.theguardian.com&#x2F;books&#x2F;2023&#x2F;jul&#x2F;05&#x2F;authors-file-a...</a>
[2] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2105.05241" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2105.05241</a>
[3] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2301.13867" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2301.13867</a></div><br/><div id="36688039" class="c"><input type="checkbox" id="c-36688039" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36686779">parent</a><span>|</span><a href="#36686818">next</a><span>|</span><label class="collapse" for="c-36688039">[-]</label><label class="expand" for="c-36688039">[4 more]</label></div><br/><div class="children"><div class="content">I think a lot of hackers shy away from doing impactful work because of fear. Sometimes those fears are justified, but it&#x27;s remarkable how often things that seem like a big deal turn out not to matter. My advice for ambitious devs would be to do what seems interesting, and don&#x27;t worry too much about threatening letters. Usually the worst thing that happens is that you agree to stop doing whatever generated the threat.<p>Personally, I&#x27;m not worried. It would be a damn shame if academics come under fire merely for trying to operate on the cutting edge of science. None of us were trying to make money; we just wanted to make something interesting.<p>&gt; I&#x27;d also be keen to hear how your challenge against the DMCA on sharing LLaMA&#x27;s weights goes?<p>Thanks! I think we might be putting up a website for it soon, if only to explain ourselves. In the meantime – I hate this phrase, since I don&#x27;t want followers – the only way to keep informed is to follow my Twitter, and perhaps keep an eye on my HN comments.<p>You&#x27;ll probably hear about it either way though, since it&#x27;s a groundbreaking case. No one has tested the copyrightability of ML models before.</div><br/><div id="36688508" class="c"><input type="checkbox" id="c-36688508" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688039">parent</a><span>|</span><a href="#36686818">next</a><span>|</span><label class="collapse" for="c-36688508">[-]</label><label class="expand" for="c-36688508">[3 more]</label></div><br/><div class="children"><div class="content">What exactly is it that you claim copyright over? Are you sure that you have standing to bring that suit?</div><br/><div id="36688742" class="c"><input type="checkbox" id="c-36688742" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688508">parent</a><span>|</span><a href="#36686818">next</a><span>|</span><label class="collapse" for="c-36688742">[-]</label><label class="expand" for="c-36688742">[2 more]</label></div><br/><div class="children"><div class="content">It’s the other way around — Meta DMCA’d llama-dl, my github repo, claiming they control copyright of llama. Our assertion is that ML weights are uncopyrightable, much like a phone book - training a model on the same dataset in the same way usually gives more or less the same model, even if the weights are completely different each time.<p>I can send you the draft we’ve prepared if you’re interested — drop me an email. But I’ll probably set up a site for this, if only to clear up our motives and expected outcomes.</div><br/><div id="36691789" class="c"><input type="checkbox" id="c-36691789" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688742">parent</a><span>|</span><a href="#36686818">next</a><span>|</span><label class="collapse" for="c-36691789">[-]</label><label class="expand" for="c-36691789">[1 more]</label></div><br/><div class="children"><div class="content">Ah, I mis-interpreted &#x27;I’ll be participating in a legal action against Meta&#x27; as you guys bringing a counter suit of some sort. Thanks for clearing that up.<p>Copyright lawsuits are usually a case of who has the biggest stamina and hence who has the biggest wallet. Your funding will be a very important part of the outcome, regardless of the legal merits of your defense. You may want to get out of any kind of control of GH because they are strongly connected to OpenAI through Microsoft and hence has a stake in getting rid of any reasonably competent open source LLM.<p>Make sure you know what you are in for, lawsuits with large counterparties are a rodeo and even if you win they can make your life miserable with endless appeals. You will have to be prepared to spend years on this. Much good luck and if you set up a site do post the link.</div><br/></div></div></div></div></div></div></div></div><div id="36686818" class="c"><input type="checkbox" id="c-36686818" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36686779">parent</a><span>|</span><a href="#36688039">prev</a><span>|</span><a href="#36691504">next</a><span>|</span><label class="collapse" for="c-36686818">[-]</label><label class="expand" for="c-36686818">[1 more]</label></div><br/><div class="children"><div class="content">Getting sued is straight up a good thing for most peoples careers in tech. Haven&#x27;t you watched silicon valley?</div><br/></div></div></div></div><div id="36691504" class="c"><input type="checkbox" id="c-36691504" checked=""/><div class="controls bullet"><span class="by">koheripbal</span><span>|</span><a href="#36686476">parent</a><span>|</span><a href="#36686779">prev</a><span>|</span><a href="#36691829">next</a><span>|</span><label class="collapse" for="c-36691504">[-]</label><label class="expand" for="c-36691504">[1 more]</label></div><br/><div class="children"><div class="content">What ever happened with The Pile V2?  I spent a couple hours searching for it, but the Eye is impossible to navigate and people on the discord generally invite noobs like myself.</div><br/></div></div><div id="36691829" class="c"><input type="checkbox" id="c-36691829" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#36686476">parent</a><span>|</span><a href="#36691504">prev</a><span>|</span><a href="#36687293">next</a><span>|</span><label class="collapse" for="c-36691829">[-]</label><label class="expand" for="c-36691829">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They DMCA’ed one of my repos distributing LLaMA<p>Boy they&#x27;ll be mad once they learn about Huggingface distributing thousands of LLama fine tunes with full weights.</div><br/></div></div><div id="36687293" class="c"><input type="checkbox" id="c-36687293" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#36686476">parent</a><span>|</span><a href="#36691829">prev</a><span>|</span><a href="#36688063">next</a><span>|</span><label class="collapse" for="c-36687293">[-]</label><label class="expand" for="c-36687293">[6 more]</label></div><br/><div class="children"><div class="content">&gt;  It’s also one of the most ethical outcomes; since ~no one trains on data that they own, they shouldn’t own the resulting model.<p>In my opinion the most ethical outcome would be that they are on the hook for the cumulative cost of the copyright they violated. That way authors would come out ahead instead of having their rights trashed &#x27;because it&#x27;s too late anyway&#x27;.</div><br/><div id="36688890" class="c"><input type="checkbox" id="c-36688890" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36687293">parent</a><span>|</span><a href="#36688212">next</a><span>|</span><label class="collapse" for="c-36688890">[-]</label><label class="expand" for="c-36688890">[1 more]</label></div><br/><div class="children"><div class="content">Learning from something has never been copyright violation before, even when a computer was learning (eg, building a search index from copyrighted data is fair use; cite: Google cases).</div><br/></div></div><div id="36688212" class="c"><input type="checkbox" id="c-36688212" checked=""/><div class="controls bullet"><span class="by">rpdillon</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36687293">parent</a><span>|</span><a href="#36688890">prev</a><span>|</span><a href="#36687654">next</a><span>|</span><label class="collapse" for="c-36688212">[-]</label><label class="expand" for="c-36688212">[2 more]</label></div><br/><div class="children"><div class="content">&gt; on the hook for the cumulative cost of the copyright they violated.<p>I think there&#x27;s a strong argument for a Fair Use defense, given the size of the models versus the size of the training sets, as well as the gulf in intended use: an AI model doesn&#x27;t compete with e.g. a book. Obviously we&#x27;ll have to see if play out in court to find out.</div><br/><div id="36688295" class="c"><input type="checkbox" id="c-36688295" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688212">parent</a><span>|</span><a href="#36687654">next</a><span>|</span><label class="collapse" for="c-36688295">[-]</label><label class="expand" for="c-36688295">[1 more]</label></div><br/><div class="children"><div class="content">Current AI models don&#x27;t compete with a book, from what I&#x27;ve seen; I wouldn&#x27;t want to bet how long it takes before they can compete with not just one but all books.</div><br/></div></div></div></div><div id="36687654" class="c"><input type="checkbox" id="c-36687654" checked=""/><div class="controls bullet"><span class="by">cornel_io</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36687293">parent</a><span>|</span><a href="#36688212">prev</a><span>|</span><a href="#36688063">next</a><span>|</span><label class="collapse" for="c-36687654">[-]</label><label class="expand" for="c-36687654">[2 more]</label></div><br/><div class="children"><div class="content">Whether or not training on publicly available data counts as a copyright violation is still completely up in the air legally, and clearly a lot of lawyers at all of the top tech companies think they&#x27;re going to end up in the clear under fair use.<p>At some point this stuff will have to get tested by making its way up the appeals stack in the US, and IMO there is only a minuscule chance that will result in Google, MS, and Meta getting slapped with anything more than a token fine (my bet is it won&#x27;t even be that), let alone paying every person who ever wrote anything that was used in these datasets for copyright violations, which would basically be everyone.</div><br/><div id="36688458" class="c"><input type="checkbox" id="c-36688458" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36687654">parent</a><span>|</span><a href="#36688063">next</a><span>|</span><label class="collapse" for="c-36688458">[-]</label><label class="expand" for="c-36688458">[1 more]</label></div><br/><div class="children"><div class="content">There are more courts than just the US ones.</div><br/></div></div></div></div></div></div><div id="36688063" class="c"><input type="checkbox" id="c-36688063" checked=""/><div class="controls bullet"><span class="by">archivist0</span><span>|</span><a href="#36686476">parent</a><span>|</span><a href="#36687293">prev</a><span>|</span><a href="#36689613">next</a><span>|</span><label class="collapse" for="c-36688063">[-]</label><label class="expand" for="c-36688063">[3 more]</label></div><br/><div class="children"><div class="content">&gt; One last thing. The Pile would’ve been far less relevant without the wonderful assistance of The Eye, a group of people who archive all kinds of things. They’ve hosted the datasets for years now. And although it seems strange to say that dataset hosting could make or break The Pile, back then there was nobody else willing to host us. <a href="https:&#x2F;&#x2F;the-eye.eu&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;the-eye.eu&#x2F;</a><p>I&#x27;m afraid to say... the-eye no longer hosts the pile as of today due to legal threats above the likes of DMCA.<p>Though I believe it&#x27;s still available via its original torrent and on at.<p>&gt; <a href="https:&#x2F;&#x2F;academictorrents.com&#x2F;details&#x2F;0d366035664fdf51cfbe9f733953ba325776e667" rel="nofollow noreferrer">https:&#x2F;&#x2F;academictorrents.com&#x2F;details&#x2F;0d366035664fdf51cfbe9f7...</a></div><br/><div id="36691259" class="c"><input type="checkbox" id="c-36691259" checked=""/><div class="controls bullet"><span class="by">sfriedr</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688063">parent</a><span>|</span><a href="#36691521">next</a><span>|</span><label class="collapse" for="c-36691259">[-]</label><label class="expand" for="c-36691259">[1 more]</label></div><br/><div class="children"><div class="content">Of this is true, it would be something close of an insane situation: One of the largest datasets, that the largest companies are using to train their models (probably; many of the best LLMs have technical reports that raise more questions rather than answer them) being forced to live an obscure existance on torrents.<p>From a scientific point of view this is very problematic because few safeguards exist that guarantee that the dataset is not tampered with (as is the case if you&#x27;d upload it to Zenodo, which providea some guarantee of immutability).<p>How about trying to upload the Pile to Zenodo?
Only half-joking :D</div><br/></div></div><div id="36691521" class="c"><input type="checkbox" id="c-36691521" checked=""/><div class="controls bullet"><span class="by">koheripbal</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36688063">parent</a><span>|</span><a href="#36691259">prev</a><span>|</span><a href="#36689613">next</a><span>|</span><label class="collapse" for="c-36691521">[-]</label><label class="expand" for="c-36691521">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m more interested in The Pile V2 which seems to have gone underground...</div><br/></div></div></div></div><div id="36689613" class="c"><input type="checkbox" id="c-36689613" checked=""/><div class="controls bullet"><span class="by">lukemerrick</span><span>|</span><a href="#36686476">parent</a><span>|</span><a href="#36688063">prev</a><span>|</span><a href="#36691132">next</a><span>|</span><label class="collapse" for="c-36689613">[-]</label><label class="expand" for="c-36689613">[2 more]</label></div><br/><div class="children"><div class="content">Related to the idea of &quot;no one trains on data they own, they shouldn&#x27;t own the resulting model&quot;: since big public datasets like The Pile have CC-SA items in them, is anyone considering bringing the argument that model weights are derivative work that must be &quot;shared alike&quot;?</div><br/><div id="36691572" class="c"><input type="checkbox" id="c-36691572" checked=""/><div class="controls bullet"><span class="by">koheripbal</span><span>|</span><a href="#36686476">root</a><span>|</span><a href="#36689613">parent</a><span>|</span><a href="#36691132">next</a><span>|</span><label class="collapse" for="c-36691572">[-]</label><label class="expand" for="c-36691572">[1 more]</label></div><br/><div class="children"><div class="content">By that token, my brain is a derivative work of all the copyrighted works I&#x27;ve consumed</div><br/></div></div></div></div></div></div><div id="36691132" class="c"><input type="checkbox" id="c-36691132" checked=""/><div class="controls bullet"><span class="by">Roark66</span><span>|</span><a href="#36686476">prev</a><span>|</span><a href="#36686978">next</a><span>|</span><label class="collapse" for="c-36691132">[-]</label><label class="expand" for="c-36691132">[2 more]</label></div><br/><div class="children"><div class="content">Great stuff, I skimmed the article searching for some table showing a breakdown of content by language, but I haven&#x27;t found one.<p>I hope there is a lot of text in languages other than English. As for example in my language (Polish) current SOTA models are very deffiecient. I have wondered why is that considering companies like (not at all)OpenAI claim to train on large datasets including in my language of interest. It turns out (and I learned this just yesterday) they used LLM translated English content that that used as other language training data. They used Azure translator which itself is a transformer model to generate content for gpt-3.5 for example. Also, I bet there is a lot of poorly machine translated content in their supposedly &quot;original&quot; data.<p>The result? You can use chatgpt to write you an email of any kind in English and you can copy&#x2F;paste&#x2F;send immediately. Try doing that in Polish... It will make sense, but the language used will use bad tone (too familiar in a business setting), bad words(words that exist, but no real person would use) and sentence layout that just plainly feels weird. I suspect this is even worse in many other languages.</div><br/><div id="36691747" class="c"><input type="checkbox" id="c-36691747" checked=""/><div class="controls bullet"><span class="by">koheripbal</span><span>|</span><a href="#36691132">parent</a><span>|</span><a href="#36686978">next</a><span>|</span><label class="collapse" for="c-36691747">[-]</label><label class="expand" for="c-36691747">[1 more]</label></div><br/><div class="children"><div class="content">While having multiple languages makes a model more versatile and appeal to a wider audience, it actually significantly increases the memory required to run the model and thus limits other aspects of the model.<p>Optimally, a Polish audience should try to create a Polish trained model.<p>As it stands now, most advanced models, like gpt are multilingual, but are noticeably less capable in non-English languages.</div><br/></div></div></div></div><div id="36686978" class="c"><input type="checkbox" id="c-36686978" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#36691132">prev</a><span>|</span><a href="#36686750">next</a><span>|</span><label class="collapse" for="c-36686978">[-]</label><label class="expand" for="c-36686978">[1 more]</label></div><br/><div class="children"><div class="content">Related:<p><i>The Pile: An 800GB Dataset of Diverse Text for Language Modeling</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36272365">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36272365</a> - June 2023 (5 comments)<p><i>The Pile: An 800GB Dataset of Diverse Text for Language Modeling</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25607809">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25607809</a> - Jan 2021 (60 comments)</div><br/></div></div><div id="36686750" class="c"><input type="checkbox" id="c-36686750" checked=""/><div class="controls bullet"><span class="by">cschmidt</span><span>|</span><a href="#36686978">prev</a><span>|</span><a href="#36687639">next</a><span>|</span><label class="collapse" for="c-36686750">[-]</label><label class="expand" for="c-36686750">[2 more]</label></div><br/><div class="children"><div class="content">If you’re looking at The Pile, you also might consider the Red Pajama dataset. A new cleaned version was released recently <a href="https:&#x2F;&#x2F;www.cerebras.net&#x2F;blog&#x2F;slimpajama-a-627b-token-cleaned-and-deduplicated-version-of-redpajama" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.cerebras.net&#x2F;blog&#x2F;slimpajama-a-627b-token-cleane...</a></div><br/><div id="36689997" class="c"><input type="checkbox" id="c-36689997" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#36686750">parent</a><span>|</span><a href="#36687639">next</a><span>|</span><label class="collapse" for="c-36689997">[-]</label><label class="expand" for="c-36689997">[1 more]</label></div><br/><div class="children"><div class="content">Is there a straightforward way to download that dataset, the way there was for the original RedPajama data?  SlimPajama appears to have been released as 60,000 small files, which is ridiculous.</div><br/></div></div></div></div><div id="36687639" class="c"><input type="checkbox" id="c-36687639" checked=""/><div class="controls bullet"><span class="by">charlysl</span><span>|</span><a href="#36686750">prev</a><span>|</span><a href="#36688446">next</a><span>|</span><label class="collapse" for="c-36687639">[-]</label><label class="expand" for="c-36687639">[2 more]</label></div><br/><div class="children"><div class="content">OP here. I learned about this while reading Stanford&#x27;s LLM course&#x27;s &quot;Data&quot; lecture [1]. Very interesting how it assesses the datasets used for GPT 2 and 3, etc, and how The Pile addresses their issues. A very interesting course!<p>[1] <a href="https:&#x2F;&#x2F;stanford-cs324.github.io&#x2F;winter2022&#x2F;lectures&#x2F;data&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;stanford-cs324.github.io&#x2F;winter2022&#x2F;lectures&#x2F;data&#x2F;</a></div><br/><div id="36687920" class="c"><input type="checkbox" id="c-36687920" checked=""/><div class="controls bullet"><span class="by">pjot</span><span>|</span><a href="#36687639">parent</a><span>|</span><a href="#36688446">next</a><span>|</span><label class="collapse" for="c-36687920">[-]</label><label class="expand" for="c-36687920">[1 more]</label></div><br/><div class="children"><div class="content">The Pile was also referenced in a post today of some guys tweets about “leaked” gpt4 details<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36675934">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36675934</a></div><br/></div></div></div></div><div id="36688446" class="c"><input type="checkbox" id="c-36688446" checked=""/><div class="controls bullet"><span class="by">robertheadley</span><span>|</span><a href="#36687639">prev</a><span>|</span><a href="#36691360">next</a><span>|</span><label class="collapse" for="c-36688446">[-]</label><label class="expand" for="c-36688446">[4 more]</label></div><br/><div class="children"><div class="content">As long as LLMs and generative AI uses copywritten works for training, then they are going to be the enemy of creative people.</div><br/><div id="36691311" class="c"><input type="checkbox" id="c-36691311" checked=""/><div class="controls bullet"><span class="by">mattkevan</span><span>|</span><a href="#36688446">parent</a><span>|</span><a href="#36689058">next</a><span>|</span><label class="collapse" for="c-36691311">[-]</label><label class="expand" for="c-36691311">[1 more]</label></div><br/><div class="children"><div class="content">Creative people will be using LLMs and other models as new and exciting creative tools.<p>Their real enemies will be the people who make money off the creative people’s work, e.g. the entire history of recorded music or the current writers strike.</div><br/></div></div><div id="36689058" class="c"><input type="checkbox" id="c-36689058" checked=""/><div class="controls bullet"><span class="by">splatzone</span><span>|</span><a href="#36688446">parent</a><span>|</span><a href="#36691311">prev</a><span>|</span><a href="#36691360">next</a><span>|</span><label class="collapse" for="c-36689058">[-]</label><label class="expand" for="c-36689058">[2 more]</label></div><br/><div class="children"><div class="content">Unless the financial benefit could be shared with the original authors somehow, with some kind of royalties system?</div><br/><div id="36691142" class="c"><input type="checkbox" id="c-36691142" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#36688446">root</a><span>|</span><a href="#36689058">parent</a><span>|</span><a href="#36691360">next</a><span>|</span><label class="collapse" for="c-36691142">[-]</label><label class="expand" for="c-36691142">[1 more]</label></div><br/><div class="children"><div class="content">I love how &quot;creatives&quot; enjoy the freedom of the free internet but never try to shame their peers as to whether they use GPL or MIT license for their art.</div><br/></div></div></div></div></div></div><div id="36691360" class="c"><input type="checkbox" id="c-36691360" checked=""/><div class="controls bullet"><span class="by">ryoshiro</span><span>|</span><a href="#36688446">prev</a><span>|</span><a href="#36686438">next</a><span>|</span><label class="collapse" for="c-36691360">[-]</label><label class="expand" for="c-36691360">[1 more]</label></div><br/><div class="children"><div class="content">Side Topic: In the leaked OpenAI GPT-training details, there are speculations that OpenAI trained on Libgen dataset. Is there a link to the dataset of Libgen, if so how big is it?</div><br/></div></div><div id="36686438" class="c"><input type="checkbox" id="c-36686438" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#36691360">prev</a><span>|</span><label class="collapse" for="c-36686438">[-]</label><label class="expand" for="c-36686438">[4 more]</label></div><br/><div class="children"><div class="content">I came so close to getting my dataset DebateSum (<a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;Hellisotherpeople&#x2F;DebateSum" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;Hellisotherpeople&#x2F;DebateSum</a>) into the pile, but they decided at the last minute not to add it: <a href="https:&#x2F;&#x2F;github.com&#x2F;EleutherAI&#x2F;the-pile&#x2F;issues&#x2F;56">https:&#x2F;&#x2F;github.com&#x2F;EleutherAI&#x2F;the-pile&#x2F;issues&#x2F;56</a><p>I&#x27;m still a tiny bit salty about that, but the pile is a wonderful dataset regardless.</div><br/><div id="36687135" class="c"><input type="checkbox" id="c-36687135" checked=""/><div class="controls bullet"><span class="by">orange_fritter</span><span>|</span><a href="#36686438">parent</a><span>|</span><label class="collapse" for="c-36687135">[-]</label><label class="expand" for="c-36687135">[3 more]</label></div><br/><div class="children"><div class="content">That dataset looks cool.  Good work either way, I&#x27;m sure it&#x27;ll go somewhere</div><br/><div id="36687705" class="c"><input type="checkbox" id="c-36687705" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#36686438">root</a><span>|</span><a href="#36687135">parent</a><span>|</span><label class="collapse" for="c-36687705">[-]</label><label class="expand" for="c-36687705">[2 more]</label></div><br/><div class="children"><div class="content">Stay tuned! I&#x27;ve got a paper I&#x27;m writing about a new followup which is a 40x improvement in size (basically every open source debate card... Ever) and a 40x improvement in metadata and duplication detection. The work is all done since late april and I&#x27;ve just been lazy&#x2F;writer-blocked (ironic in a world of high end LLMs) and haven&#x27;t gotten the paper finished.<p>Kinda of sad to have missed NeurIPS dataset track deadline and ACL, but I know that anything close to this in scope is a slam-dunk accept at the argument mining workshop</div><br/><div id="36690439" class="c"><input type="checkbox" id="c-36690439" checked=""/><div class="controls bullet"><span class="by">robmsmt</span><span>|</span><a href="#36686438">root</a><span>|</span><a href="#36687705">parent</a><span>|</span><label class="collapse" for="c-36690439">[-]</label><label class="expand" for="c-36690439">[1 more]</label></div><br/><div class="children"><div class="content">Would love to see an early version of it!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>