<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1693299664915" as="style"/><link rel="stylesheet" href="styles.css?v=1693299664915"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://superfastpython.com/numpy-share-array-processes/">How to share a NumPy array between processes</a> <span class="domain">(<a href="https://superfastpython.com">superfastpython.com</a>)</span></div><div class="subtext"><span>jasonb05</span> | <span>10 comments</span></div><br/><div><div id="37304205" class="c"><input type="checkbox" id="c-37304205" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#37304078">next</a><span>|</span><label class="collapse" for="c-37304205">[-]</label><label class="expand" for="c-37304205">[2 more]</label></div><br/><div class="children"><div class="content">Though deprecated probably in favor of more of a database&#x2F;DBMS like DuckDB, the arrow plasma store holds handles to objects as a separate process:<p><pre><code>  $ plasma_store -m 1000000000 -s &#x2F;tmp&#x2F;plasma
</code></pre>
Arrow arrays are like NumPy arrays but they&#x27;re made for zero copy e.g. IPC Interprocess Communication. There&#x27;s a dtype_backend kwarg to the Pandas DataFrame constructor and read_ methods:<p>df = pandas.Dataframe(dtype_backend=&quot;arrow&quot;)<p>The Plasma In-Memory Object Store &gt; Using Arrow and Pandas with Plasma &gt; Storing Arrow Objects in Plasma 
<a href="https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;dev&#x2F;python&#x2F;plasma.html#storing-arrow-objects-in-plasma" rel="nofollow noreferrer">https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;dev&#x2F;python&#x2F;plasma.html#storing...</a><p>Streaming, Serialization, and IPC &gt; 
<a href="https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;python&#x2F;ipc.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;python&#x2F;ipc.html</a><p>&quot;DuckDB quacks Arrow: A zero-copy data integration between Apache Arrow and DuckDB&quot; (2021) 
<a href="https:&#x2F;&#x2F;duckdb.org&#x2F;2021&#x2F;12&#x2F;03&#x2F;duck-arrow.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;duckdb.org&#x2F;2021&#x2F;12&#x2F;03&#x2F;duck-arrow.html</a></div><br/><div id="37304260" class="c"><input type="checkbox" id="c-37304260" checked=""/><div class="controls bullet"><span class="by">Simon_O_Rourke</span><span>|</span><a href="#37304205">parent</a><span>|</span><a href="#37304078">next</a><span>|</span><label class="collapse" for="c-37304260">[-]</label><label class="expand" for="c-37304260">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the latency delta of reading from a local database instance versus reading from memory - is there much additional overhead to slow things down?</div><br/></div></div></div></div><div id="37304078" class="c"><input type="checkbox" id="c-37304078" checked=""/><div class="controls bullet"><span class="by">arjvik</span><span>|</span><a href="#37304205">prev</a><span>|</span><a href="#37303859">next</a><span>|</span><label class="collapse" for="c-37304078">[-]</label><label class="expand" for="c-37304078">[3 more]</label></div><br/><div class="children"><div class="content">Good content, but over SEO optimized. Would be nice to hear about the actual efficiency of using these methods.<p>For instance, does fork() copy the page of memory containing the array? I believe it&#x27;s Copy-on-Write semantics, right? What happens when the parent process changes the array?<p>Then, how do Pipe and Queue send the array across processes? Do they also pickle and unpickle it? Use shared memory?</div><br/><div id="37304884" class="c"><input type="checkbox" id="c-37304884" checked=""/><div class="controls bullet"><span class="by">ahoka</span><span>|</span><a href="#37304078">parent</a><span>|</span><a href="#37304354">next</a><span>|</span><label class="collapse" for="c-37304884">[-]</label><label class="expand" for="c-37304884">[1 more]</label></div><br/><div class="children"><div class="content">“I believe it&#x27;s Copy-on-Write semantics, right? What happens when the parent process changes the array?”<p>Yes and you just answered your question.</div><br/></div></div><div id="37304354" class="c"><input type="checkbox" id="c-37304354" checked=""/><div class="controls bullet"><span class="by">ikhatri</span><span>|</span><a href="#37304078">parent</a><span>|</span><a href="#37304884">prev</a><span>|</span><a href="#37303859">next</a><span>|</span><label class="collapse" for="c-37304354">[-]</label><label class="expand" for="c-37304354">[1 more]</label></div><br/><div class="children"><div class="content">This is a super common occurrence in training loops for ML models because PyTorch uses multiprocessing for its dataloader workers. If you want to read more, see the discussion in this issue: <a href="https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch&#x2F;issues&#x2F;13246#issuecomment-905703662">https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch&#x2F;issues&#x2F;13246#issuecomment...</a><p>As you’ve pointed out fork() isn’t ideal for a number of reasons and in general it’s preferred to use torch tensors directly instead of numpy arrays so that you are not forced into using fork()<p>There’s also this write up which I found to be quite useful for details: <a href="https:&#x2F;&#x2F;ppwwyyxx.com&#x2F;blog&#x2F;2022&#x2F;Demystify-RAM-Usage-in-Multiprocess-DataLoader&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;ppwwyyxx.com&#x2F;blog&#x2F;2022&#x2F;Demystify-RAM-Usage-in-Multip...</a></div><br/></div></div></div></div><div id="37303859" class="c"><input type="checkbox" id="c-37303859" checked=""/><div class="controls bullet"><span class="by">pplonski86</span><span>|</span><a href="#37304078">prev</a><span>|</span><a href="#37304098">next</a><span>|</span><label class="collapse" for="c-37303859">[-]</label><label class="expand" for="c-37303859">[1 more]</label></div><br/><div class="children"><div class="content">I was searching for similar article. Im working on AutoML python package where I use different packages to train ML models on tabular data. Very often the memory is not properly released by external packages so the only way to manage memeory is to execute training in separate processes.</div><br/></div></div><div id="37304098" class="c"><input type="checkbox" id="c-37304098" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#37303859">prev</a><span>|</span><a href="#37304183">next</a><span>|</span><label class="collapse" for="c-37304098">[-]</label><label class="expand" for="c-37304098">[2 more]</label></div><br/><div class="children"><div class="content">Actually ran into this problem this week, toyed around with multiprocessing.shared_memory (which seems to also rely on mmaped-files, right?) and decided to just embrace the GIL.<p>Multiprocessing is not needed when all of your handful subprocesses are just calling Numpy-code and release their gil anyways.<p>Also some&#x2F;most Numpy functions are multithreaded (depending on the BLAS implementation, linked against), take advantage of that and schedule huge operations and just let the interpreter sit idle waiting for that result.</div><br/><div id="37304918" class="c"><input type="checkbox" id="c-37304918" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#37304098">parent</a><span>|</span><a href="#37304183">next</a><span>|</span><label class="collapse" for="c-37304918">[-]</label><label class="expand" for="c-37304918">[1 more]</label></div><br/><div class="children"><div class="content">I have seen this movie before, it always ends the same way.<p>Look to go parallel for speed increase, burn a bunch of time and decide its way too hard and just wait the extra few minutes instead.</div><br/></div></div></div></div><div id="37304183" class="c"><input type="checkbox" id="c-37304183" checked=""/><div class="controls bullet"><span class="by">schoetbi</span><span>|</span><a href="#37304098">prev</a><span>|</span><label class="collapse" for="c-37304183">[-]</label><label class="expand" for="c-37304183">[1 more]</label></div><br/><div class="children"><div class="content">There is also Apache Arrow that uses a similar use case. Maybe this is worth considering: <a href="https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;python&#x2F;memory.html#on-disk-and-memory-mapped-files" rel="nofollow noreferrer">https:&#x2F;&#x2F;arrow.apache.org&#x2F;docs&#x2F;python&#x2F;memory.html#on-disk-and...</a></div><br/></div></div></div></div></div></div></div></body></html>