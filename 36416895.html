<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687424459210" as="style"/><link rel="stylesheet" href="styles.css?v=1687424459210"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://gwern.net/tank">The Neural Net Tank Urban Legend</a> <span class="domain">(<a href="https://gwern.net">gwern.net</a>)</span></div><div class="subtext"><span>belter</span> | <span>41 comments</span></div><br/><div><div id="36425683" class="c"><input type="checkbox" id="c-36425683" checked=""/><div class="controls bullet"><span class="by">jumploops</span><span>|</span><a href="#36429188">next</a><span>|</span><label class="collapse" for="c-36425683">[-]</label><label class="expand" for="c-36425683">[6 more]</label></div><br/><div class="children"><div class="content">My friend once asked me to help him with an autonomous RC car race, where we’d go to a warehouse and train the car around the track.<p>After a few weekends of iterating and improving the model&#x2F;training set, we were convinced we’d win the next race… only to lose almost immediately by crossing the lines on the track.<p>We did some inverse model explanation work which quickly showed that our car was paying attention to the overhead skylights more than the actual tracks. Unlike the other weekends, it was a foggy day!<p>A quick hack to cut out the top 50% of each training image brought our car back to its prior reliability.</div><br/><div id="36426073" class="c"><input type="checkbox" id="c-36426073" checked=""/><div class="controls bullet"><span class="by">sobellian</span><span>|</span><a href="#36425683">parent</a><span>|</span><a href="#36426574">next</a><span>|</span><label class="collapse" for="c-36426073">[-]</label><label class="expand" for="c-36426073">[3 more]</label></div><br/><div class="children"><div class="content">In college, I had to make a line follower car that could drive over a line drawn with segments of black tape. While most folks just used a micro-controller to write their control loop, I made a set of op-amp circuits to compute the power to each wheel in analog.<p>It took a while to get good resistor values, but the night before the project was due I managed to get it working really well. So that was cool, and I got to catch up on sleep. Well the funny thing was that the next day we tested our line followers in this big lecture hall and the courses were not directly under the lights. So my beautiful analog line follower started following its own shadow!<p>Of course, the more diligent students had already tested their cars under these conditions and found the need to put a little hood over the photoresistors so that they only saw the light reflected from the car&#x27;s own LED.</div><br/><div id="36426242" class="c"><input type="checkbox" id="c-36426242" checked=""/><div class="controls bullet"><span class="by">Waterluvian</span><span>|</span><a href="#36425683">root</a><span>|</span><a href="#36426073">parent</a><span>|</span><a href="#36428758">next</a><span>|</span><label class="collapse" for="c-36426242">[-]</label><label class="expand" for="c-36426242">[1 more]</label></div><br/><div class="children"><div class="content">I’m going to bet that well-experienced lesson has positively affected future endeavours. Did it ever come to mind when you were working on something and the memory guided you towards searching for additional edge cases or taking “what ifs” more seriously?</div><br/></div></div><div id="36428758" class="c"><input type="checkbox" id="c-36428758" checked=""/><div class="controls bullet"><span class="by">Doxin</span><span>|</span><a href="#36425683">root</a><span>|</span><a href="#36426073">parent</a><span>|</span><a href="#36426242">prev</a><span>|</span><a href="#36426574">next</a><span>|</span><label class="collapse" for="c-36428758">[-]</label><label class="expand" for="c-36428758">[1 more]</label></div><br/><div class="children"><div class="content">Another good trick here is to do two measurements. Once with a light on your bot aimed at the line <i>on</i>, and once with it <i>off</i>. Taking the difference between these measurements will fairly reliably reject ambient lighting.<p>Of course getting that to work with all-analog hardware is left as an exercise to the reader.</div><br/></div></div></div></div><div id="36426574" class="c"><input type="checkbox" id="c-36426574" checked=""/><div class="controls bullet"><span class="by">bhickey</span><span>|</span><a href="#36425683">parent</a><span>|</span><a href="#36426073">prev</a><span>|</span><a href="#36429188">next</a><span>|</span><label class="collapse" for="c-36426574">[-]</label><label class="expand" for="c-36426574">[2 more]</label></div><br/><div class="children"><div class="content">&gt; We did some inverse model explanation work which quickly showed that our car was paying attention to the overhead skylights more than the actual tracks.<p>It must&#x27;ve been posted here before: this is exactly the strategy Andy Sloane used to localize his car.<p><a href="https:&#x2F;&#x2F;www.a1k0n.net&#x2F;2021&#x2F;01&#x2F;22&#x2F;indoor-localization.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.a1k0n.net&#x2F;2021&#x2F;01&#x2F;22&#x2F;indoor-localization.html</a></div><br/><div id="36426687" class="c"><input type="checkbox" id="c-36426687" checked=""/><div class="controls bullet"><span class="by">jumploops</span><span>|</span><a href="#36425683">root</a><span>|</span><a href="#36426574">parent</a><span>|</span><a href="#36429188">next</a><span>|</span><label class="collapse" for="c-36426687">[-]</label><label class="expand" for="c-36426687">[1 more]</label></div><br/><div class="children"><div class="content">Ah very cool! Thanks for sharing.<p>We did this back in 2017(?) using an Nvidia Jetson TX2, allowing us to train the model on the car itself, avoiding a round-trip to our laptop!</div><br/></div></div></div></div></div></div><div id="36429188" class="c"><input type="checkbox" id="c-36429188" checked=""/><div class="controls bullet"><span class="by">Jaxkr</span><span>|</span><a href="#36425683">prev</a><span>|</span><a href="#36425676">next</a><span>|</span><label class="collapse" for="c-36429188">[-]</label><label class="expand" for="c-36429188">[1 more]</label></div><br/><div class="children"><div class="content">I’m shocked that nobody has mentioned this yet: AI intended to recognize skin cancer instead learned to identify doctors’ markings and  rulers.<p><a href="https:&#x2F;&#x2F;jamanetwork.com&#x2F;journals&#x2F;jamadermatology&#x2F;fullarticle&#x2F;2740808" rel="nofollow noreferrer">https:&#x2F;&#x2F;jamanetwork.com&#x2F;journals&#x2F;jamadermatology&#x2F;fullarticle...</a><p><a href="https:&#x2F;&#x2F;venturebeat.com&#x2F;business&#x2F;when-ai-flags-the-ruler-not-the-tumor-and-other-arguments-for-abolishing-the-black-box-vb-live&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;venturebeat.com&#x2F;business&#x2F;when-ai-flags-the-ruler-not...</a></div><br/></div></div><div id="36425676" class="c"><input type="checkbox" id="c-36425676" checked=""/><div class="controls bullet"><span class="by">teraflop</span><span>|</span><a href="#36429188">prev</a><span>|</span><a href="#36428069">next</a><span>|</span><label class="collapse" for="c-36425676">[-]</label><label class="expand" for="c-36425676">[3 more]</label></div><br/><div class="children"><div class="content">A fictional variant of this story also shows up in Peter Watts&#x27; novel <i>Starfish</i>.<p>In that version, the neural net is trained to manage the ventilation system of an underground train station, based on data about passenger movements. Unfortunately, it ends up simply paying attention to the display of a clock that happens to be visible through one of its cameras. And when the clock breaks, a bunch of people asphyxiate. A bit implausible, but memorable.</div><br/><div id="36426282" class="c"><input type="checkbox" id="c-36426282" checked=""/><div class="controls bullet"><span class="by">pacaro</span><span>|</span><a href="#36425676">parent</a><span>|</span><a href="#36427903">next</a><span>|</span><label class="collapse" for="c-36426282">[-]</label><label class="expand" for="c-36426282">[1 more]</label></div><br/><div class="children"><div class="content">Some time in the mid 90s I spoke with someone who had worked on this kind of problem (and others) on the London Underground. There had been a desire to know platform occupancy, and that this could be achieved by using a NN. The story as relayed to me was that the NN was never much more reliable that simply measuring the brightness of the platform — or rather the reflection of lights from the platform surface — which could be fairly easily calibrated<p>I took it less as a cautionary tale about NN and more about looking for simple solutions</div><br/></div></div><div id="36427903" class="c"><input type="checkbox" id="c-36427903" checked=""/><div class="controls bullet"><span class="by">dmbche</span><span>|</span><a href="#36425676">parent</a><span>|</span><a href="#36426282">prev</a><span>|</span><a href="#36428069">next</a><span>|</span><label class="collapse" for="c-36427903">[-]</label><label class="expand" for="c-36427903">[1 more]</label></div><br/><div class="children"><div class="content">Just going throught the trilogy - it&#x27;s good! It&#x27;s also free to download - go read it!</div><br/></div></div></div></div><div id="36428069" class="c"><input type="checkbox" id="c-36428069" checked=""/><div class="controls bullet"><span class="by">AussieWog93</span><span>|</span><a href="#36425676">prev</a><span>|</span><a href="#36426125">next</a><span>|</span><label class="collapse" for="c-36428069">[-]</label><label class="expand" for="c-36428069">[2 more]</label></div><br/><div class="children"><div class="content">Disagree wholeheartedly with the conclusion here.  Even though the story is untrue, sharing it is a fantastic way for students to grapple with a new concept and come to grips with the real problem of biased datasets.  They&#x27;ll remember it for their whole careers and share the wisdom with others too.<p>The death of mythology in the age of science has really done a disservice to mankind.</div><br/><div id="36428455" class="c"><input type="checkbox" id="c-36428455" checked=""/><div class="controls bullet"><span class="by">finitemonkey</span><span>|</span><a href="#36428069">parent</a><span>|</span><a href="#36426125">next</a><span>|</span><label class="collapse" for="c-36428455">[-]</label><label class="expand" for="c-36428455">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t worry, the post-truth age is coming will full speed toward us.</div><br/></div></div></div></div><div id="36426125" class="c"><input type="checkbox" id="c-36426125" checked=""/><div class="controls bullet"><span class="by">bemusedthrow75</span><span>|</span><a href="#36428069">prev</a><span>|</span><a href="#36426568">next</a><span>|</span><label class="collapse" for="c-36426125">[-]</label><label class="expand" for="c-36426125">[7 more]</label></div><br/><div class="children"><div class="content">Heh. I heard this in a cybernetics lecture in late ‘92 or early ‘93. I have never been able to track down the original either.<p>It&#x27;s not the funniest tech urban legend story I&#x27;ve heard in a lecture -- that award would go to the kangaroos-with-grenade-launchers story -- but it is good.</div><br/><div id="36426444" class="c"><input type="checkbox" id="c-36426444" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#36426125">parent</a><span>|</span><a href="#36426403">next</a><span>|</span><label class="collapse" for="c-36426444">[-]</label><label class="expand" for="c-36426444">[5 more]</label></div><br/><div class="children"><div class="content">Could you elaborate on that story or give a link?</div><br/><div id="36426516" class="c"><input type="checkbox" id="c-36426516" checked=""/><div class="controls bullet"><span class="by">bemusedthrow75</span><span>|</span><a href="#36426125">root</a><span>|</span><a href="#36426444">parent</a><span>|</span><a href="#36426403">next</a><span>|</span><label class="collapse" for="c-36426516">[-]</label><label class="expand" for="c-36426516">[4 more]</label></div><br/><div class="children"><div class="content">Not a neural net story.<p>I only remember it hazily but it was just very funny in the moment; the lecturer was one of the most naturally funny people. It concerned as I recall it a combat flight (helicopter I think) simulator that had been unsuccessful and was being hastily tweaked as a demo for a civilian contract.<p>The story went that elements of the simulator were closely tied to ground attack scenarios, and that there was not time to remove all the code concerning enemy soldiers, so the models of the soldiers were replaced with models of kangaroos (same sort of height, walk on two legs).<p>On the day of the demo, there was some impromptu change to the script — they flew lower and too close to the ground or something — and the kangaroos fired at them with rocket propelled grenades.<p>I don’t believe the story is really true, but as a cautionary tale about reskinning demos it has always stuck with me.</div><br/><div id="36427177" class="c"><input type="checkbox" id="c-36427177" checked=""/><div class="controls bullet"><span class="by">svieira</span><span>|</span><a href="#36426125">root</a><span>|</span><a href="#36426516">parent</a><span>|</span><a href="#36426403">next</a><span>|</span><label class="collapse" for="c-36427177">[-]</label><label class="expand" for="c-36427177">[3 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.snopes.com&#x2F;fact-check&#x2F;shoot-me-kangaroo-down-sport&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.snopes.com&#x2F;fact-check&#x2F;shoot-me-kangaroo-down-spo...</a></div><br/><div id="36428339" class="c"><input type="checkbox" id="c-36428339" checked=""/><div class="controls bullet"><span class="by">wolfgang42</span><span>|</span><a href="#36426125">root</a><span>|</span><a href="#36427177">parent</a><span>|</span><a href="#36428757">next</a><span>|</span><label class="collapse" for="c-36428339">[-]</label><label class="expand" for="c-36428339">[1 more]</label></div><br/><div class="children"><div class="content">The debunking, for those not immediately inclined to follow the link:<p>&gt; “...we had not set any weapon or projectile types, so what the kangaroos fired at us was in fact the default object for the simulation, which happened to be large multicoloured beachballs.”</div><br/></div></div><div id="36428757" class="c"><input type="checkbox" id="c-36428757" checked=""/><div class="controls bullet"><span class="by">bemusedthrow75</span><span>|</span><a href="#36426125">root</a><span>|</span><a href="#36427177">parent</a><span>|</span><a href="#36428339">prev</a><span>|</span><a href="#36426403">next</a><span>|</span><label class="collapse" for="c-36428757">[-]</label><label class="expand" for="c-36428757">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, this would be the one I guess.<p>The lecture in question took place in late &#x27;94 or early &#x27;95, in the UK -- so four or five years before that telling.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36426568" class="c"><input type="checkbox" id="c-36426568" checked=""/><div class="controls bullet"><span class="by">inasio</span><span>|</span><a href="#36426125">prev</a><span>|</span><a href="#36427449">next</a><span>|</span><label class="collapse" for="c-36426568">[-]</label><label class="expand" for="c-36426568">[2 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t be surprised if the urban legend had been inspired by Feynman&#x27;s famous anecdote of the mouse maze-running experiment [0] (recently discussed here, the link is also by the author of this post)<p>[0] <a href="https:&#x2F;&#x2F;gwern.net&#x2F;maze" rel="nofollow noreferrer">https:&#x2F;&#x2F;gwern.net&#x2F;maze</a><p>(edit: the earliest refs for the tank story predate Feynman&#x27;s, so this would be wrong)</div><br/><div id="36426867" class="c"><input type="checkbox" id="c-36426867" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#36426568">parent</a><span>|</span><a href="#36427449">next</a><span>|</span><label class="collapse" for="c-36426867">[-]</label><label class="expand" for="c-36426867">[1 more]</label></div><br/><div class="children"><div class="content">The Author and that site are ironically the polar opposite of any ai generated text output of NNs.  These stories are the art of long form essays thoughtfully ideated and crafted over years.  Amazing guy and finding something like this is the reason HN is awesome.</div><br/></div></div></div></div><div id="36427449" class="c"><input type="checkbox" id="c-36427449" checked=""/><div class="controls bullet"><span class="by">ctoth</span><span>|</span><a href="#36426568">prev</a><span>|</span><a href="#36425413">next</a><span>|</span><label class="collapse" for="c-36427449">[-]</label><label class="expand" for="c-36427449">[1 more]</label></div><br/><div class="children"><div class="content">Gwern,<p>If we&#x27;re still around in 2030, you&#x27;re gonna have to rewrite this same post about the AI drone that blew up its controller.<p>Here&#x27;s hoping!</div><br/></div></div><div id="36425413" class="c"><input type="checkbox" id="c-36425413" checked=""/><div class="controls bullet"><span class="by">riskneutral</span><span>|</span><a href="#36427449">prev</a><span>|</span><a href="#36429420">next</a><span>|</span><label class="collapse" for="c-36425413">[-]</label><label class="expand" for="c-36425413">[3 more]</label></div><br/><div class="children"><div class="content">Oh wow, I read this story as evidence that neural nets are not the future back when I was an undergrad studying machine learning. Maybe I should have followed my instincts back then because even then neural nets seemed intuitively very interesting even if the statistics and math professors hated them because they weren&#x27;t derived from any first principals.</div><br/><div id="36429561" class="c"><input type="checkbox" id="c-36429561" checked=""/><div class="controls bullet"><span class="by">bemusedthrow75</span><span>|</span><a href="#36425413">parent</a><span>|</span><a href="#36429043">next</a><span>|</span><label class="collapse" for="c-36429561">[-]</label><label class="expand" for="c-36429561">[1 more]</label></div><br/><div class="children"><div class="content">Side note &#x2F; linguistic nit &#x2F; minor correction:<p>While it would seem logical that &quot;first principals&quot; is just one of those weird tautologies that stuck, and it would fit the meaning of the phrase just fine, this one is actually &quot;first principles&quot; (as in assumptions).<p><i>That is, we are referring to the principal assumptions when we talk about first principles. ;-)</i><p>(My brain tends to make the opposite error on this one)</div><br/></div></div><div id="36429043" class="c"><input type="checkbox" id="c-36429043" checked=""/><div class="controls bullet"><span class="by">sgt101</span><span>|</span><a href="#36425413">parent</a><span>|</span><a href="#36429561">prev</a><span>|</span><a href="#36429420">next</a><span>|</span><label class="collapse" for="c-36429043">[-]</label><label class="expand" for="c-36429043">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t the derivative chain rule count?</div><br/></div></div></div></div><div id="36429420" class="c"><input type="checkbox" id="c-36429420" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#36425413">prev</a><span>|</span><a href="#36427152">next</a><span>|</span><label class="collapse" for="c-36429420">[-]</label><label class="expand" for="c-36429420">[1 more]</label></div><br/><div class="children"><div class="content">&gt;[...] with a probable origin in a speculative question in the 1960s by Edward Fredkin at an AI conference about some early NN research [...]<p>RIP Edward Fredkin, who recently passed away on June 13, 9 days ago.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Edward_Fredkin" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Edward_Fredkin</a><p>&gt;Edward Fredkin (born October 2, 1934, died June 13, 2023) was a distinguished career professor at Carnegie Mellon University (CMU), and an early pioneer of digital physics.<p>&gt;Fredkin&#x27;s primary contributions include work on reversible computing and cellular automata. While Konrad Zuse&#x27;s book, Calculating Space (1969), mentioned the importance of reversible computation, the Fredkin gate represented the essential breakthrough. In recent work, he uses the term digital philosophy (DP).<p>&gt;During his career, Fredkin has been a professor of computer science at the Massachusetts Institute of Technology, a Fairchild Distinguished Scholar at Caltech, and Research Professor of Physics at Boston University.<p>Ed Fredkin - Reversible Computing (Keynote from the CCC&#x27;s Workshop on Reversible Computing)<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ROv1HX-gdas">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ROv1HX-gdas</a><p>Fredkin tells a great story about making Stephen Wolfram&#x27;s eyes pop out of his head by showing him how to transform his own rule into a reversible rule.<p>Reversible Computing<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Reversible_computing" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Reversible_computing</a><p>Fredkin Gate<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fredkin_gate" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fredkin_gate</a><p>Digital Physics<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Digital_physics" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Digital_physics</a><p>Conservative Logic, by Edward Fredkin and Tommaso Toffoli<p><a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20061017232512&#x2F;http:&#x2F;&#x2F;www.digitalphilosophy.org&#x2F;download_documents&#x2F;ConservativeLogic.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20061017232512&#x2F;http:&#x2F;&#x2F;www.digita...</a><p>Digital Philosophy<p><a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20170729191558&#x2F;http:&#x2F;&#x2F;www.digitalphilosophy.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20170729191558&#x2F;http:&#x2F;&#x2F;www.digita...</a><p>Rudy Rucker writes about his CAM-6 in the CelLab manual:<p>Cellular Automata Laboratory: Fourmilab home: Origins of CelLab: Classical Era: Von Neumann to Gosper<p><a href="http:&#x2F;&#x2F;www.fourmilab.ch&#x2F;cellab&#x2F;manual&#x2F;chap5.html" rel="nofollow noreferrer">http:&#x2F;&#x2F;www.fourmilab.ch&#x2F;cellab&#x2F;manual&#x2F;chap5.html</a><p>&gt;Computer science is still so new that many of the people at the cutting edge have come from other fields. Though Toffoli holds degrees in physics and computer science, Bennett&#x27;s Ph.D. is in physical chemistry. And twenty-nine year old Margolus is still a graduate student in physics, his dissertation delayed by the work of inventing, with Toffoli, the CAM-6 Cellular Automaton Machine.<p>&gt;After watching the CAM in operation at Margolus&#x27;s office, I am sure the thing will be a hit. Just as the Moog synthesizer changed the sound of music, cellular automata will change the look of video.<p>&gt;I tell this to Toffoli and Margolus, and they look unconcerned. What they care most deeply about is science, about Edward Fredkin&#x27;s vision of explaining the world in terms of cellular automata and information mechanics. Margolus talks about computer hackers, and how a successful program is called “a good hack.” As the unbelievably bizarre cellular automata images flash by on his screen, Margolus leans back in his chair and smiles slyly. And then he tells me his conception of the world we live in.<p>&gt;“The universe is a good hack.”<p>[...]</div><br/></div></div><div id="36427152" class="c"><input type="checkbox" id="c-36427152" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#36429420">prev</a><span>|</span><a href="#36427659">next</a><span>|</span><label class="collapse" for="c-36427152">[-]</label><label class="expand" for="c-36427152">[1 more]</label></div><br/><div class="children"><div class="content">Common element to these stories seems to be that the error is only found too late, and then apparently the whole project is scrapped. Most of the real projects I&#x27;m familiar with discovered some flaws in data or training, but continued working afterwards. Like nobody who heard this story ever thought to ask, so what happened after you trained it on some more photos?</div><br/></div></div><div id="36427659" class="c"><input type="checkbox" id="c-36427659" checked=""/><div class="controls bullet"><span class="by">kasey_junk</span><span>|</span><a href="#36427152">prev</a><span>|</span><a href="#36427737">next</a><span>|</span><label class="collapse" for="c-36427659">[-]</label><label class="expand" for="c-36427659">[1 more]</label></div><br/><div class="children"><div class="content">In an AI class I took circa 1999 a professor recounted this story to us but it was “shadows” that the neural net detected.<p>The funny thing is he told us it was an urban legend but one that had a valid point.</div><br/></div></div><div id="36425707" class="c"><input type="checkbox" id="c-36425707" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#36427737">prev</a><span>|</span><a href="#36426007">next</a><span>|</span><label class="collapse" for="c-36425707">[-]</label><label class="expand" for="c-36425707">[5 more]</label></div><br/><div class="children"><div class="content">While this may be an urban legend, I have definitely played with ML and seen things overfit in comical ways.</div><br/><div id="36425827" class="c"><input type="checkbox" id="c-36425827" checked=""/><div class="controls bullet"><span class="by">morkalork</span><span>|</span><a href="#36425707">parent</a><span>|</span><a href="#36429534">next</a><span>|</span><label class="collapse" for="c-36425827">[-]</label><label class="expand" for="c-36425827">[2 more]</label></div><br/><div class="children"><div class="content">It reminds me of a similar story about using deep learning on medical imagery for diagnosis. In one study, it supposedly learned the to tell which device was used to take the images. Apparently that was somewhat correlated with the results as more serious &#x2F; heavily suspected cases were sent to a specific hospital in the region.</div><br/><div id="36426359" class="c"><input type="checkbox" id="c-36426359" checked=""/><div class="controls bullet"><span class="by">timy2shoes</span><span>|</span><a href="#36425707">root</a><span>|</span><a href="#36425827">parent</a><span>|</span><a href="#36429534">next</a><span>|</span><label class="collapse" for="c-36426359">[-]</label><label class="expand" for="c-36426359">[1 more]</label></div><br/><div class="children"><div class="content">Similarly, I recall a talk by Daphne Koller where she talks about a heart attack predictor using X-rays as input. They found that stents were the biggest factor for positive prediction. Which is useless because the doctor would know if the patient had a stent.</div><br/></div></div></div></div><div id="36429534" class="c"><input type="checkbox" id="c-36429534" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#36425707">parent</a><span>|</span><a href="#36425827">prev</a><span>|</span><a href="#36426451">next</a><span>|</span><label class="collapse" for="c-36429534">[-]</label><label class="expand" for="c-36429534">[1 more]</label></div><br/><div class="children"><div class="content">Clever Hans was real!<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Clever_Hans" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Clever_Hans</a><p>&gt;Clever Hans (German: der Kluge Hans; c. 1895 – c. 1916) was a horse that was claimed to have performed arithmetic and other intellectual tasks. After a formal investigation in 1907, psychologist Oskar Pfungst demonstrated that the horse was not actually performing these mental tasks, but was watching the reactions of his trainer. He discovered this artifact in the research methodology, wherein the horse was responding directly to involuntary cues in the body language of the human trainer, who was entirely unaware that he was providing such cues. In honour of Pfungst&#x27;s study, the anomalous artifact has since been referred to as the Clever Hans effect and has continued to be important knowledge in the observer-expectancy effect and later studies in animal cognition. Pfungst was an assistant to German philosopher and psychologist Carl Stumpf, who incorporated the experience with Hans into his further work on animal psychology and his ideas on phenomenology.<p>Finding and removing Clever Hans: Using explanation methods to debug and improve deep models:<p><a href="https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S1566253521001573" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S156625352...</a><p>Is your AI a “Clever Hans”?<p><a href="https:&#x2F;&#x2F;medium.com&#x2F;high-stakes-design&#x2F;is-your-ai-a-clever-hans-736214670e00" rel="nofollow noreferrer">https:&#x2F;&#x2F;medium.com&#x2F;high-stakes-design&#x2F;is-your-ai-a-clever-ha...</a><p>NLP&#x27;s Clever Hans Moment Has Arrived (thegradient.pub)<p><a href="https:&#x2F;&#x2F;thegradient.pub&#x2F;nlps-clever-hans-moment-has-arrived&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;thegradient.pub&#x2F;nlps-clever-hans-moment-has-arrived&#x2F;</a><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20861586">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20861586</a><p>The Clever Hans Effect in Machine Learning: an overview by Bhusan Chettri<p><a href="https:&#x2F;&#x2F;www.issuewire.com&#x2F;the-clever-hans-effect-in-machine-learning-an-overview-by-bhusan-chettri-1767401061368276" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.issuewire.com&#x2F;the-clever-hans-effect-in-machine-...</a><p>Deep Learning, Meet Clever Hans<p><a href="https:&#x2F;&#x2F;towardsdatascience.com&#x2F;deep-learning-meet-clever-hans-3576144dc5a9" rel="nofollow noreferrer">https:&#x2F;&#x2F;towardsdatascience.com&#x2F;deep-learning-meet-clever-han...</a></div><br/></div></div><div id="36426451" class="c"><input type="checkbox" id="c-36426451" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#36425707">parent</a><span>|</span><a href="#36429534">prev</a><span>|</span><a href="#36426007">next</a><span>|</span><label class="collapse" for="c-36426451">[-]</label><label class="expand" for="c-36426451">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a big reason why the urban legend is so popular.</div><br/></div></div></div></div><div id="36426007" class="c"><input type="checkbox" id="c-36426007" checked=""/><div class="controls bullet"><span class="by">ryanschneider</span><span>|</span><a href="#36425707">prev</a><span>|</span><a href="#36426629">next</a><span>|</span><label class="collapse" for="c-36426007">[-]</label><label class="expand" for="c-36426007">[1 more]</label></div><br/><div class="children"><div class="content">I’m pretty sure I first heard this anecdote in Andrew Ng’s original machine learning course on Coursera.</div><br/></div></div><div id="36428007" class="c"><input type="checkbox" id="c-36428007" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#36426629">prev</a><span>|</span><a href="#36417170">next</a><span>|</span><label class="collapse" for="c-36428007">[-]</label><label class="expand" for="c-36428007">[1 more]</label></div><br/><div class="children"><div class="content">Even if it&#x27;s a myth, the moral is right.</div><br/></div></div><div id="36425794" class="c"><input type="checkbox" id="c-36425794" checked=""/><div class="controls bullet"><span class="by">morkalork</span><span>|</span><a href="#36417170">prev</a><span>|</span><a href="#36426869">next</a><span>|</span><label class="collapse" for="c-36425794">[-]</label><label class="expand" for="c-36425794">[1 more]</label></div><br/><div class="children"><div class="content">I vividly remember hearing that story from a friend when I was in highschool around the mid 2000s.</div><br/></div></div><div id="36426869" class="c"><input type="checkbox" id="c-36426869" checked=""/><div class="controls bullet"><span class="by">oh_my_goodness</span><span>|</span><a href="#36425794">prev</a><span>|</span><label class="collapse" for="c-36426869">[-]</label><label class="expand" for="c-36426869">[1 more]</label></div><br/><div class="children"><div class="content">tldr: &quot;I think it&#x27;s probably an urban legend, because whatever.&quot;</div><br/></div></div></div></div></div></div></div></body></html>