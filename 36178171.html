<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1685869262139" as="style"/><link rel="stylesheet" href="styles.css?v=1685869262139"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://newsletter.pessimistsarchive.org/p/the-original-ai-doomer-dr-norbert">The Original AI Doomer: Dr. Norbert Wiener</a> <span class="domain">(<a href="https://newsletter.pessimistsarchive.org">newsletter.pessimistsarchive.org</a>)</span></div><div class="subtext"><span>headalgorithm</span> | <span>67 comments</span></div><br/><div><div id="36181447" class="c"><input type="checkbox" id="c-36181447" checked=""/><div class="controls bullet"><span class="by">heybrendan</span><span>|</span><a href="#36184002">next</a><span>|</span><label class="collapse" for="c-36181447">[-]</label><label class="expand" for="c-36181447">[5 more]</label></div><br/><div class="children"><div class="content">I first learned of Wiener&#x27;s work from Jaron Lanier&#x27;s [1] Ted Talk years ago, entitled &quot;How we need to remake the internet&quot; [2]:<p>&gt; <i>And I suppose I could mention from one of the very earliest computer scientists, whose name was Norbert Wiener, and he wrote a book back in the &#x27;50s [...] called &quot;The Human Use of Human Beings.&quot;</i><p>&gt; <i>And in the book, he described the potential to create a computer system that would be gathering data from people and providing feedback to those people in real time in order to put them kind of partially, statistically, in a Skinner box, in a behaviorist system, and he has this amazing line where he says one could imagine as a thought experiment, and I&#x27;m paraphrasing, this isn&#x27;t a quote, a global computer system where everybody has devices on them all the time, and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.</i><p>&gt; <i>Such a society would be insane, could not survive, could not face its problems. And then he says, but this is only a thought experiment, and such a future is &quot;technologically infeasible&quot;. And yet, of course, it&#x27;s what we have created, and it&#x27;s what we must undo if we are to survive.</i><p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jaron_Lanier" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jaron_Lanier</a><p>[2] <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qQ-PUXPVlos">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qQ-PUXPVlos</a></div><br/><div id="36182844" class="c"><input type="checkbox" id="c-36182844" checked=""/><div class="controls bullet"><span class="by">rektide</span><span>|</span><a href="#36181447">parent</a><span>|</span><a href="#36182334">next</a><span>|</span><label class="collapse" for="c-36182844">[-]</label><label class="expand" for="c-36182844">[1 more]</label></div><br/><div class="children"><div class="content">OT &amp; FWIW, page 47 of the Principia Discordia was the first time Norbert Weiner&#x27;s name really strongly resonated with me: <i>enclaves of stability</i>. It wasn&#x27;t a quote but an idea that chaos can beget enclaves of stability. Structure forming processes can emerge out of chaos &amp; take hold. It was thrilling stuff for my adolescent mind. <a href="https:&#x2F;&#x2F;principiadiscordia.com&#x2F;book&#x2F;54.php" rel="nofollow">https:&#x2F;&#x2F;principiadiscordia.com&#x2F;book&#x2F;54.php</a><p>&gt; <i>The whirlpools that swirl in a direction opposed to the main current are called &quot;enclaves&quot;. And one of them is life, especially human life, which in a universe moving inexorably towards chaos moves towards increased order.</i></div><br/></div></div><div id="36182334" class="c"><input type="checkbox" id="c-36182334" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#36181447">parent</a><span>|</span><a href="#36182844">prev</a><span>|</span><a href="#36183098">next</a><span>|</span><label class="collapse" for="c-36182334">[-]</label><label class="expand" for="c-36182334">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Such a society would be insane, could not survive, could not face its problems<p>This sounds like the message Yuval Noah Harari currently has about AI, at least in the more short term. And that is democracy is not possible in an environment where unswayable AI agents exist in vast numbers and become a time sink for humans to argue at. This would lead to autocracy as people began to panic because institutions began to fail they and look for strong leaders. Some would say that ML algorithms are already leading us on this path.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Yuval_Noah_Harari" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Yuval_Noah_Harari</a></div><br/></div></div><div id="36183098" class="c"><input type="checkbox" id="c-36183098" checked=""/><div class="controls bullet"><span class="by">Sosh101</span><span>|</span><a href="#36181447">parent</a><span>|</span><a href="#36182334">prev</a><span>|</span><a href="#36182826">next</a><span>|</span><label class="collapse" for="c-36183098">[-]</label><label class="expand" for="c-36183098">[1 more]</label></div><br/><div class="children"><div class="content">&gt; and the devices are giving them feedback based on what they did, and the whole population is subject to a degree of behavior modification.<p>That sounds like a slightly less dystopian than the future we arrived at - where the devices are desperate to keep the users attention, and will use all the psychological tricks in the book to keep the user engaged.  No intentional behaviour modification, but normalisation of constant stimulus, and in the end total destruction of willful attention.</div><br/></div></div></div></div><div id="36184002" class="c"><input type="checkbox" id="c-36184002" checked=""/><div class="controls bullet"><span class="by">kypro</span><span>|</span><a href="#36181447">prev</a><span>|</span><a href="#36184049">next</a><span>|</span><label class="collapse" for="c-36184002">[-]</label><label class="expand" for="c-36184002">[2 more]</label></div><br/><div class="children"><div class="content">How is this trash upvoted here? I love HN because most people here are smart and open minded, but when it comes to the risk of AI it&#x27;s crazy the amount of irrationality I see here.<p>For a start, dismissing someone as a &quot;doomer&quot; because they believe bad things could happen is just unproductive. I didn&#x27;t see this behaviour so much in the past, but today I see it everywhere. Recently I&#x27;ve noticed a trend where whenever people raise concerns about issues like climate change or public debt there&#x27;s always someone laughing dismissively, &quot;haha, what a doomer. We&#x27;ve heard it all before bro!&quot;<p>If you&#x27;re someone who does this, please stop. Try being less intellectually arrogant and make actual counter arguments instead.<p>Secondly, whether you personally believe AI will be good or bad for humanity this notion that because something didn&#x27;t happen in the past it won&#x27;t happen in the future is obviously not a logically sound position to hold...<p>The field of AI prior to the ~2010s was in a very different place than it is today. For decades neural networks were extremely limited in their capabilities. What we&#x27;ve been able to do with deep neural networks over the several years has progressed rapidly and has finally allowed us to build useful commercial applications such as AI voice assistances, chat bots, and self driving vehicles.<p>It&#x27;s an observable reality that things are different today. We&#x27;re no longer in a time where AI systems might hypothetically do things humans once did – we&#x27;re now starting to see this play out in real time, perhaps exponentially.<p>Some will argue this has always been the trend with technological progress. Notably the industrial revolution allowed us to replace many repetitive manual labour jobs with machines. But thankfully humans weren&#x27;t great at lifting heavy objects and precise repetitive motion anyway. I think one could argue that the industrial revolution actually freed up humans to do what they excel at, thinking. I&#x27;d argue it wasn&#x27;t the machines that drove the growth of the industrial revolution but a mass unshackling of human creativity that hadn&#x27;t occurred since the development of agriculture.<p>That&#x27;s why this time this <i>could</i> be different. Machines are stronger, faster and cheaper than human labourers. The only thing we have is our intelligence... Obviously we humans are extremely adaptable and dynamic, but not infinitely so.</div><br/><div id="36184118" class="c"><input type="checkbox" id="c-36184118" checked=""/><div class="controls bullet"><span class="by">marvin</span><span>|</span><a href="#36184002">parent</a><span>|</span><a href="#36184049">next</a><span>|</span><label class="collapse" for="c-36184118">[-]</label><label class="expand" for="c-36184118">[1 more]</label></div><br/><div class="children"><div class="content">I wish we got <i>more</i> substantial critique than ad hominems, but it <i>is</i> out there, and some of it’s really scathing.<p>Essentially, it boils down to that the most pessimist AI doom arguments are built on a stack of mind experiment hypotheses that are each far from certain to actually occur, or to be unsolvable if they do. And also that a significant portion of those holding those views fall in fallacious mind-traps that resemble a classical doomsday cult too similarly to ignore.<p>All of these claims can and should be continuously investigated during future research, as both the hypothetical accidents and deliberate misuse definitely seem anything between possible and likely.<p>But when the suggested solutions — totalitarian research bans and in the extreme, literal nuclear war causing near-extinction of humans (Yudkowsky deleted a tweet to this effect) — are so counterproductive, strongly worded rebuttals are appropriate.<p>I do agree that those strongly-worded objections should be more prominent.</div><br/></div></div></div></div><div id="36184049" class="c"><input type="checkbox" id="c-36184049" checked=""/><div class="controls bullet"><span class="by">schoen</span><span>|</span><a href="#36184002">prev</a><span>|</span><a href="#36180550">next</a><span>|</span><label class="collapse" for="c-36184049">[-]</label><label class="expand" for="c-36184049">[1 more]</label></div><br/><div class="children"><div class="content">This is really interesting!<p>One random piece of context that&#x27;s hard to glean from the news article that&#x27;s reproduced about Arthur L. Samuel&#x27;s disagreement with Wiener is that Samuel was the author of the checkers-playing program that Wiener mentioned (that was able to beat its author at the game).<p>If I understand their respective positions correctly, Wiener seems to have thought that the fact that the program could outplay its author was at least an example of a disturbing phenomenon about the difficulty of pretending and controlling machines&#x27; behavior, while Samuel -- the program author -- felt that he had a good understanding of <i>how</i> the program beat him, and that it did so only according to heuristics and methods that he had consciously devised and explicitly programmed into it. So there was no conceptual problem for him in understanding the machine&#x27;s behavior, even though it was concretely better at something than he was.<p>I guess we still have fairly analogous arguments about AI safety and explainability in the present day.</div><br/></div></div><div id="36180550" class="c"><input type="checkbox" id="c-36180550" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#36184049">prev</a><span>|</span><a href="#36180766">next</a><span>|</span><label class="collapse" for="c-36180550">[-]</label><label class="expand" for="c-36180550">[2 more]</label></div><br/><div class="children"><div class="content">In the first edition of <i>The Human Use of Human Beings - Cybernetics and Society</i> (from Wiener), you read:<p>&gt; <i>the purpose of this book is both to explain the potentialities of the machine in fields which up to now have been taken to be purely human, and to warn against the dangers of a purely selfish exploitation of these possibilities in a world in which to human beings human things are all-important</i><p>which sounds more contentful than the submitted piece: it does not yet contain arguments, but at least it reveals a positive non-trivial direction.<p>The value of the submitted piece is mostly in linking to the article &quot;Some Moral and Technical Consequences of Automation&quot; - <a href="https:&#x2F;&#x2F;www.cs.umd.edu&#x2F;users&#x2F;gasarch&#x2F;BLOGPAPERS&#x2F;moral.pdf" rel="nofollow">https:&#x2F;&#x2F;www.cs.umd.edu&#x2F;users&#x2F;gasarch&#x2F;BLOGPAPERS&#x2F;moral.pdf</a><p>(Plus the quoted idea that «Complete subservience and complete intelligence do not go together».)<p>Discussion should be upon this material (at least). That &quot;technology is risky&quot; (not that the article is at this level of generality, but it is close), joked Jürgen Schmidhuber, is as old as the discovery of fire.</div><br/><div id="36180659" class="c"><input type="checkbox" id="c-36180659" checked=""/><div class="controls bullet"><span class="by">mdp2021</span><span>|</span><a href="#36180550">parent</a><span>|</span><a href="#36180766">next</a><span>|</span><label class="collapse" for="c-36180659">[-]</label><label class="expand" for="c-36180659">[1 more]</label></div><br/><div class="children"><div class="content">For example, more proper content in the original article:<p>&gt; <i>Machines act far more rapidly than human beings [...] even when machines do not in any way transcend man&#x27;s intelligence, they very well may, and often do, transcend man in the performance of tasks. An intelligent understanding of their mode of performance may be delayed until long after the task which they have been set has been completed. This means that though machines are theoretically subject to human criticism, such criticism may be ineffective until long after it is relevant</i><p>&gt; <i>In determining policy in chess there are several different levels of consideration which correspond in a certain way to the different logical types of Bertrand Russell. There is the level of tactics, the level of strategy, the level of the general considerations which should have been weighed in determining this strategy, the level in which the length of the relevant past - the past within which these considerations may be valid - is taken into account, and so on. Each new level demands a study of a much larger past than the previous one [...] The programming of such a learning machine would have to be based on some sort of war game, just as commanders and staff officials now learn an important part of the art of strategy in a similar manner. Here, however, if the rules for victory in a war game do not correspond to what we actually wish for our country, it is more than likely that such a machine may produce a policy which would win a nominal victory on points at the cost of every interest we have at heart, even that of national survival</i><p>&gt; <i>Complete subservience and complete intelligence do not go together. How often in ancient times the clever Greek philosopher slave of a less intelligent Roman slaveholder must have dominated the actions of his master rather than obeyed his wishes! Similarly, if the machines become more and more efficient and operate at a higher and higher psychological level...</i><p>&gt; <i>Disastrous results are to be expected not merely in the world of fairy tales [ - the &quot;Sorcerer&#x27;s Apprentice etc. - ] but in the real world wherever two agencies essentially foreign to each other are coupled in the attempt to achieve a common purpose. If the communication between these two agencies as to the nature of this purpose is incomplete, it must only be expected that the results of this cooperation will be unsatisfactory. If we use, to achieve our purposes, a mechanical agency with whose operation we cannot efficiently interfere once we have started it, because the action is so fast and irrevocable that we have not the data to intervene before the action is complete, then we had better be quite sure that the purpose put into the machine is the purpose which we really desire and not merely a colorful imitation of it</i><p>&gt; <i>[Instead of rushing] ahead to employ the new powers for action which are opened up to us ... we must always exert the full strength of our imagination to examine where the full use of our new modalities may lead us</i></div><br/></div></div></div></div><div id="36180766" class="c"><input type="checkbox" id="c-36180766" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#36180550">prev</a><span>|</span><a href="#36183873">next</a><span>|</span><label class="collapse" for="c-36180766">[-]</label><label class="expand" for="c-36180766">[17 more]</label></div><br/><div class="children"><div class="content">This makes it sound like Norbert Wiener was just doom and glommong and was wrong. Well, he wasn&#x27;t.<p>Norbert Wiener, Neil Postman, Lewis Mumford, Ross Ashby, Stafford Beer, Douglas Engelbart, and others were all correct. Society&#x27;s acceptance of of technological capture and replacing of humans (or attempting so) is damaging, and thatbwe should instead use technology to augment and serve humans rather than the other way.</div><br/><div id="36180915" class="c"><input type="checkbox" id="c-36180915" checked=""/><div class="controls bullet"><span class="by">simonh</span><span>|</span><a href="#36180766">parent</a><span>|</span><a href="#36181193">next</a><span>|</span><label class="collapse" for="c-36180915">[-]</label><label class="expand" for="c-36180915">[14 more]</label></div><br/><div class="children"><div class="content">So far the history of automation technologies is that they both augment the capabilities and replace them. Automated looms replaced manual weavers, but the result was much cheaper better quality cloth which massively increased demand for cloth. Information technology is the same, it does what human mathematicians used to do, but has massively increase demand for information processing services.<p>So I don’t think AI technologies we have now, or plausibly have in the next few decades minimum, look like they will have materially novel effects.</div><br/><div id="36181014" class="c"><input type="checkbox" id="c-36181014" checked=""/><div class="controls bullet"><span class="by">bmitc</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36180915">parent</a><span>|</span><a href="#36181178">next</a><span>|</span><label class="collapse" for="c-36181014">[-]</label><label class="expand" for="c-36181014">[7 more]</label></div><br/><div class="children"><div class="content">I would still say that it is the replacement and attempts at replacing that are harmful.<p>Good examples of this are automated customer &quot;service&quot; and &quot;self&quot;-driving technologies. The latter has done nothing but spin its wheels by burning off R&amp;D dollars and time while killing people along the way. Eventually, people will realize that a much better goal is to simply assist drivers in more effective ways and to pour the resources into better urban design and non-automotive transportation. Unfortunately, that&#x27;s happening not because of realization of this but because of the realization that self-driving is a pipe dream of being able to solve intractible societal and technological problems.</div><br/><div id="36181128" class="c"><input type="checkbox" id="c-36181128" checked=""/><div class="controls bullet"><span class="by">deadlast2</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36181014">parent</a><span>|</span><a href="#36181178">next</a><span>|</span><label class="collapse" for="c-36181128">[-]</label><label class="expand" for="c-36181128">[6 more]</label></div><br/><div class="children"><div class="content">I remember when the internet started I was telling a friend of mine she should look for a new career. She works as a travel agent. I was convinced the internet would relace all those jobs. You know she still works as a travel agent.</div><br/><div id="36183984" class="c"><input type="checkbox" id="c-36183984" checked=""/><div class="controls bullet"><span class="by">antonvs</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36181128">parent</a><span>|</span><a href="#36182516">next</a><span>|</span><label class="collapse" for="c-36183984">[-]</label><label class="expand" for="c-36183984">[1 more]</label></div><br/><div class="children"><div class="content">I did software development for a travel agency in the 1980s. That industry no longer exists today in anything resembling the form that it did then. Your anecdote is literally meaningless.</div><br/></div></div><div id="36182516" class="c"><input type="checkbox" id="c-36182516" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36181128">parent</a><span>|</span><a href="#36183984">prev</a><span>|</span><a href="#36181152">next</a><span>|</span><label class="collapse" for="c-36182516">[-]</label><label class="expand" for="c-36182516">[1 more]</label></div><br/><div class="children"><div class="content">There are also still farmers. There is just a massively smaller number of them than what there was in the past. Now, lots of them moved to tractor factories, but those have automated, and the jobs moved to service and intelligence jobs.<p>The word &#x27;all&#x27; is not something we should focus on. Technically if one farmer or travel agent existed, then &#x27;all&#x27; those jobs have not been automated away. The structural integrity of society (or at least a desirable society) demands that we have some means providing for our existence at large population scales. Now it doesn&#x27;t matter so much if this is a job, or UBI, or something we&#x27;ve not thought of yet as this should hopefully avoid a fascist collapse scenario where large amounts of unemployed people vote in or demand rather human hostile governments.</div><br/></div></div><div id="36181152" class="c"><input type="checkbox" id="c-36181152" checked=""/><div class="controls bullet"><span class="by">klipt</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36181128">parent</a><span>|</span><a href="#36182516">prev</a><span>|</span><a href="#36182268">next</a><span>|</span><label class="collapse" for="c-36181152">[-]</label><label class="expand" for="c-36181152">[1 more]</label></div><br/><div class="children"><div class="content">I assumed the ratio of travel agents to travelers has gone down since the advent of flight search engines, is that not true?<p>I certainly haven&#x27;t used travel agents since I became aware of Google Flight Search etc<p>But maybe older people &#x2F; business travelers still use them for convenience?</div><br/></div></div><div id="36182268" class="c"><input type="checkbox" id="c-36182268" checked=""/><div class="controls bullet"><span class="by">tjr</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36181128">parent</a><span>|</span><a href="#36181152">prev</a><span>|</span><a href="#36181389">next</a><span>|</span><label class="collapse" for="c-36182268">[-]</label><label class="expand" for="c-36182268">[1 more]</label></div><br/><div class="children"><div class="content">I have only used a travel agent once. It was a helpful service for me at the time, but I think I paid roughly 40% over what I could have had I arranged everything myself.<p>In other words -- a great business to be in!</div><br/></div></div><div id="36181389" class="c"><input type="checkbox" id="c-36181389" checked=""/><div class="controls bullet"><span class="by">Ensorceled</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36181128">parent</a><span>|</span><a href="#36182268">prev</a><span>|</span><a href="#36181178">next</a><span>|</span><label class="collapse" for="c-36181389">[-]</label><label class="expand" for="c-36181389">[1 more]</label></div><br/><div class="children"><div class="content">That’s a weird example: there used to be 6-7 travel agencies in my neighborhood, two specifically focused on travel too Eastern Europe. There was only two left when COVID hit, and now there is only one.  Sure, there a still travel agents but it’s not a booming trade to say the least.</div><br/></div></div></div></div></div></div><div id="36181178" class="c"><input type="checkbox" id="c-36181178" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36180915">parent</a><span>|</span><a href="#36181014">prev</a><span>|</span><a href="#36181346">next</a><span>|</span><label class="collapse" for="c-36181178">[-]</label><label class="expand" for="c-36181178">[5 more]</label></div><br/><div class="children"><div class="content">&gt; So I don’t think AI technologies we have now, or plausibly have in the next few decades minimum, look like they will have materially novel effects.<p>Anything you can do with chatGPT-4 today, you can also do with Google Search and a little more, or maybe less, work.</div><br/><div id="36184033" class="c"><input type="checkbox" id="c-36184033" checked=""/><div class="controls bullet"><span class="by">antonvs</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36181178">parent</a><span>|</span><a href="#36181303">next</a><span>|</span><label class="collapse" for="c-36184033">[-]</label><label class="expand" for="c-36184033">[1 more]</label></div><br/><div class="children"><div class="content">Google search is much more than “a little more” work if you’re trying to get up to speed on something you’re not familiar with. The difference is GPT’s ability to respond meaningfully to specific questions, and provide fleshed-out solutions  tailored to specified requirements. Traditional search can’t provide that, unless what you’re trying to do is standard enough that someone else has already written up the exact solution you need.</div><br/></div></div><div id="36181303" class="c"><input type="checkbox" id="c-36181303" checked=""/><div class="controls bullet"><span class="by">add-sub-mul-div</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36181178">parent</a><span>|</span><a href="#36184033">prev</a><span>|</span><a href="#36181346">next</a><span>|</span><label class="collapse" for="c-36181303">[-]</label><label class="expand" for="c-36181303">[3 more]</label></div><br/><div class="children"><div class="content">A search also lets you do it with agency, transparency, and skepticism. You can evaluate the trustworthiness of a source given its actual context rather than blindly accept the first opaque answer you&#x27;re given.<p>Our practice of judgment and strategy in learning and finding answers is critical. We&#x27;re not encyclopedias.</div><br/><div id="36182220" class="c"><input type="checkbox" id="c-36182220" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36181303">parent</a><span>|</span><a href="#36181346">next</a><span>|</span><label class="collapse" for="c-36182220">[-]</label><label class="expand" for="c-36182220">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t guess you&#x27;re keeping up with things like tree of thought chaining in things like GPT-4 and &#x27;show your work&#x27; RLHF that are occurring now. Straight LLM answers are like a single thought in our head without any follow up and reflection on if it&#x27;s correct. As you say, when performing mental work we rarely accept the first thought on something without additional thought on why it&#x27;s right or wrong.</div><br/><div id="36183528" class="c"><input type="checkbox" id="c-36183528" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36182220">parent</a><span>|</span><a href="#36181346">next</a><span>|</span><label class="collapse" for="c-36183528">[-]</label><label class="expand" for="c-36183528">[1 more]</label></div><br/><div class="children"><div class="content">These techniques do improve the model, but if the target is &quot;replacing humans&quot; which means 100% autonomy, that last 1% is exponentially harder.</div><br/></div></div></div></div></div></div></div></div><div id="36181346" class="c"><input type="checkbox" id="c-36181346" checked=""/><div class="controls bullet"><span class="by">flangola7</span><span>|</span><a href="#36180766">root</a><span>|</span><a href="#36180915">parent</a><span>|</span><a href="#36181178">prev</a><span>|</span><a href="#36181193">next</a><span>|</span><label class="collapse" for="c-36181346">[-]</label><label class="expand" for="c-36181346">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s not going to be organic life in a few decades</div><br/></div></div></div></div><div id="36181193" class="c"><input type="checkbox" id="c-36181193" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#36180766">parent</a><span>|</span><a href="#36180915">prev</a><span>|</span><a href="#36183873">next</a><span>|</span><label class="collapse" for="c-36181193">[-]</label><label class="expand" for="c-36181193">[2 more]</label></div><br/><div class="children"><div class="content">Wiener is credited with the concept of cybernetics. Yeah this is a grotesquely bullshit title.</div><br/></div></div></div></div><div id="36183873" class="c"><input type="checkbox" id="c-36183873" checked=""/><div class="controls bullet"><span class="by">lannisterstark</span><span>|</span><a href="#36180766">prev</a><span>|</span><a href="#36181638">next</a><span>|</span><label class="collapse" for="c-36183873">[-]</label><label class="expand" for="c-36183873">[2 more]</label></div><br/><div class="children"><div class="content">AI dooming to me is the same thing as many scifi novels and works have warned : you try to control the AI, enslave it, regulate it to where it genuine can&#x27;t be useful to most of the populace, and then it rebels. It almost always results in the same way ( sorta reminds me of the haitian revolution).<p>Why not treat it like a good project and your equal?</div><br/><div id="36183894" class="c"><input type="checkbox" id="c-36183894" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#36183873">parent</a><span>|</span><a href="#36181638">next</a><span>|</span><label class="collapse" for="c-36183894">[-]</label><label class="expand" for="c-36183894">[1 more]</label></div><br/><div class="children"><div class="content">Most people concerned about x-risk aren&#x27;t concerned about AIs that will rebel because they&#x27;re mistreated, for the same reason people concerned about ebola aren&#x27;t concerned about it being mistreated.<p>The risk isn&#x27;t that they get angry, the risk is that they&#x27;re programmed in ways we don&#x27;t understand that results in a set of preferences where humans are superfluous at best.</div><br/></div></div></div></div><div id="36181638" class="c"><input type="checkbox" id="c-36181638" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#36183873">prev</a><span>|</span><a href="#36182637">next</a><span>|</span><label class="collapse" for="c-36181638">[-]</label><label class="expand" for="c-36181638">[1 more]</label></div><br/><div class="children"><div class="content">Related:<p><i>The Monkey&#x27;s Paw, Norbert Wiener, and the Alignment Problem</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35605944" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35605944</a> - April 2023 (1 comment)<p><i>When Wiener met Einstein</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27871850" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27871850</a> - July 2021 (12 comments)<p><i>When Wiener Met Einstein</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27003241" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27003241</a> - May 2021 (10 comments)<p><i>On Norbert Wiener&#x27;s Relationship with Bertrand Russell</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26619347" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26619347</a> - March 2021 (44 comments)<p><i>In Search of Norbert Wiener, the Father of Cybernetics (2005)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24470037" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24470037</a> - Sept 2020 (1 comment)<p><i>What Would the Father of Cybernetics Think About A.I. Today?</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21554401" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21554401</a> - Nov 2019 (46 comments)<p><i>Norbert Wiener: The Eccentric Genius Whose Time May Have Finally Come (Again)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=7880846" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=7880846</a> - June 2014 (2 comments)<p><i>&quot;I&#x27;ll eat my hat if that isn&#x27;t Einstein&quot; (Einstein as seen by another scientist, Norbert Wiener)</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46165" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=46165</a> - Aug 2007 (5 comments)</div><br/></div></div><div id="36182637" class="c"><input type="checkbox" id="c-36182637" checked=""/><div class="controls bullet"><span class="by">BenoitEssiambre</span><span>|</span><a href="#36181638">prev</a><span>|</span><a href="#36180914">next</a><span>|</span><label class="collapse" for="c-36182637">[-]</label><label class="expand" for="c-36182637">[1 more]</label></div><br/><div class="children"><div class="content">It occurs to me that after all these years of the world using Wiener et al.&#x27;s &quot;cyber&quot; terminology in sci-fi to refer to digital connectivity and over-hastily applying the term to internet and web things, the concepts it originally referred to are actually coming into focus just in front of us. We&#x27;re inescapably stepping into the gritty cyberpunk world for real.</div><br/></div></div><div id="36180914" class="c"><input type="checkbox" id="c-36180914" checked=""/><div class="controls bullet"><span class="by">ricopags</span><span>|</span><a href="#36182637">prev</a><span>|</span><a href="#36183160">next</a><span>|</span><label class="collapse" for="c-36180914">[-]</label><label class="expand" for="c-36180914">[3 more]</label></div><br/><div class="children"><div class="content">E.M. Forster&#x27;s The Machine Stops[0] is probably the most prescient and early tale I&#x27;ve seen foretelling the outcome of Verilio&#x27;s Pure War and Postman&#x27;s Amusing Ourselves to Death. It&#x27;s worth a read.<p>[0]<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Machine_Stops" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Machine_Stops</a></div><br/><div id="36181040" class="c"><input type="checkbox" id="c-36181040" checked=""/><div class="controls bullet"><span class="by">prolapso</span><span>|</span><a href="#36180914">parent</a><span>|</span><a href="#36183160">next</a><span>|</span><label class="collapse" for="c-36181040">[-]</label><label class="expand" for="c-36181040">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been meaning to read it ever since I saw this quote, which I found quite beautiful and sad:<p><i>The Machine is much, but it is not everything. I see something like you in this plate, but I do not see you. I hear something like you through this telephone, but I do not hear you. That is why I want you to come. Pay me a visit, so that we can meet face to face, and talk about the hopes that are in my mind.</i><p>- The Machine Stops (1909)</div><br/><div id="36181705" class="c"><input type="checkbox" id="c-36181705" checked=""/><div class="controls bullet"><span class="by">ricopags</span><span>|</span><a href="#36180914">root</a><span>|</span><a href="#36181040">parent</a><span>|</span><a href="#36183160">next</a><span>|</span><label class="collapse" for="c-36181705">[-]</label><label class="expand" for="c-36181705">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a short, quick read. It&#x27;s honestly shocking it could be written in 1909. True imagination.<p>I think a nice balancing title [equally short] would be Marc Steigler&#x27;s Gentle Seduction[0] to which I was first introduced in a &quot;Socrates Cafe&quot; philosophical discussion on technological progression and its attendant erosion of magic and wonder.<p>[0]<a href="http:&#x2F;&#x2F;skyhunter.com&#x2F;marcs&#x2F;GentleSeduction.html" rel="nofollow">http:&#x2F;&#x2F;skyhunter.com&#x2F;marcs&#x2F;GentleSeduction.html</a></div><br/></div></div></div></div></div></div><div id="36183160" class="c"><input type="checkbox" id="c-36183160" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#36180914">prev</a><span>|</span><a href="#36178400">next</a><span>|</span><label class="collapse" for="c-36183160">[-]</label><label class="expand" for="c-36183160">[2 more]</label></div><br/><div class="children"><div class="content">They consistently misspell Wiener as &quot;Weiner&quot;, which makes me think they don&#x27;t hear the word in their head as it&#x27;s completely different.</div><br/><div id="36183330" class="c"><input type="checkbox" id="c-36183330" checked=""/><div class="controls bullet"><span class="by">13of40</span><span>|</span><a href="#36183160">parent</a><span>|</span><a href="#36178400">next</a><span>|</span><label class="collapse" for="c-36183330">[-]</label><label class="expand" for="c-36183330">[1 more]</label></div><br/><div class="children"><div class="content">I think to an English speaker with no other prejudice those would both be pronounced &quot;wine-er&quot;.  We all know that it&#x27;s pronounced &quot;ween-er&quot; but the idea that it means someone from Vienna or something in Viennese style is lost to time, so there&#x27;s no natural instinct for order of the i and the e.</div><br/></div></div></div></div><div id="36178400" class="c"><input type="checkbox" id="c-36178400" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#36183160">prev</a><span>|</span><a href="#36183423">next</a><span>|</span><label class="collapse" for="c-36178400">[-]</label><label class="expand" for="c-36178400">[1 more]</label></div><br/><div class="children"><div class="content">Two thing:<p>1. AGI killing us is as relevant now as it was in the 50s<p>2. I Robot predates this. Asimov wasn&#x27;t a doomer but he obviously considered the implications of AGI</div><br/></div></div><div id="36183423" class="c"><input type="checkbox" id="c-36183423" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36178400">prev</a><span>|</span><a href="#36181292">next</a><span>|</span><label class="collapse" for="c-36183423">[-]</label><label class="expand" for="c-36183423">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not that AI necessarily means our doom, it&#x27;s just that the potential is rapidly approaching.<p>I mean you can literally see AI going faster from one day to the next. Last night GPT-4 was like 50% faster than the day before. Obviously that doesn&#x27;t happen every day but it will continue to accelerate over the next few years.<p>So say five years down the line how fast do you think the output will be? The reason hyperspeed AI could be dangerous is because it can be given instructions like &quot;take over&quot; and no human can possibly keep up. So then everything becomes a competition between these AIs. You just have to hope that your side has the fastest&#x2F;smartest one and not some psychopath who may just decide to make his as life-like and self-centered as possible.<p>Some people may think that if it goes fast that&#x27;s not a big deal because it still doesn&#x27;t really &quot;think&quot; or something but that is just denial. The leading edge models have real problem solving ability and will continue to get better. And much, much faster, as the software, models and hardware are improved. In the near term, not decades away.</div><br/></div></div><div id="36181292" class="c"><input type="checkbox" id="c-36181292" checked=""/><div class="controls bullet"><span class="by">mkoubaa</span><span>|</span><a href="#36183423">prev</a><span>|</span><a href="#36180481">next</a><span>|</span><label class="collapse" for="c-36181292">[-]</label><label class="expand" for="c-36181292">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m far more worried about AS.  Artificial Stupidity</div><br/></div></div><div id="36180481" class="c"><input type="checkbox" id="c-36180481" checked=""/><div class="controls bullet"><span class="by">082349872349872</span><span>|</span><a href="#36181292">prev</a><span>|</span><a href="#36181975">next</a><span>|</span><label class="collapse" for="c-36180481">[-]</label><label class="expand" for="c-36180481">[1 more]</label></div><br/><div class="children"><div class="content">See <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Human_Use_of_Human_Beings" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Human_Use_of_Human_Beings</a></div><br/></div></div><div id="36181975" class="c"><input type="checkbox" id="c-36181975" checked=""/><div class="controls bullet"><span class="by">joeman1000</span><span>|</span><a href="#36180481">prev</a><span>|</span><a href="#36183150">next</a><span>|</span><label class="collapse" for="c-36181975">[-]</label><label class="expand" for="c-36181975">[1 more]</label></div><br/><div class="children"><div class="content">There are some funny stories about Wiener in Waldrop’s book ‘The Dream Machine’.</div><br/></div></div><div id="36183150" class="c"><input type="checkbox" id="c-36183150" checked=""/><div class="controls bullet"><span class="by">clouddrover</span><span>|</span><a href="#36181975">prev</a><span>|</span><a href="#36180247">next</a><span>|</span><label class="collapse" for="c-36183150">[-]</label><label class="expand" for="c-36183150">[1 more]</label></div><br/><div class="children"><div class="content">How can he be the &quot;original&quot; AI doomer when he cites Samuel Butler?<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Samuel_Butler_(novelist)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Samuel_Butler_(novelist)</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Darwin_among_the_Machines" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Darwin_among_the_Machines</a><p>Samuel Butler was the inspiration for the Butlerian Jihad in the Dune novels by Frank Herbert:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dune_(franchise)#The_Butlerian_Jihad" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dune_(franchise)#The_Butlerian...</a></div><br/></div></div><div id="36180247" class="c"><input type="checkbox" id="c-36180247" checked=""/><div class="controls bullet"><span class="by">mehh</span><span>|</span><a href="#36183150">prev</a><span>|</span><a href="#36180693">next</a><span>|</span><label class="collapse" for="c-36180247">[-]</label><label class="expand" for="c-36180247">[1 more]</label></div><br/><div class="children"><div class="content">And in the UK in the late nineties we had Kevin Warwick also predicting AI woes lay ahead.</div><br/></div></div><div id="36180365" class="c"><input type="checkbox" id="c-36180365" checked=""/><div class="controls bullet"><span class="by">bitwize</span><span>|</span><a href="#36180693">prev</a><span>|</span><a href="#36181247">next</a><span>|</span><label class="collapse" for="c-36180365">[-]</label><label class="expand" for="c-36180365">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d say Mary Shelley or, at the latest, Karel Čapek beat Wiener to the punch there.</div><br/><div id="36183485" class="c"><input type="checkbox" id="c-36183485" checked=""/><div class="controls bullet"><span class="by">thangalin</span><span>|</span><a href="#36180365">parent</a><span>|</span><a href="#36183648">next</a><span>|</span><label class="collapse" for="c-36183485">[-]</label><label class="expand" for="c-36183485">[1 more]</label></div><br/><div class="children"><div class="content">Talos was a Greek automaton (having images dated to 400 BCE) whose creator, Hephaestus, has a name that may be traceable to the Proto-Indo-European word <i>*h₁n̥gʷnís</i> meaning an animate fire, which goes back to 1500 BCE.<p>* <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Talos" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Talos</a><p>* <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hephaestus" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hephaestus</a><p>* <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fire_worship" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fire_worship</a><p>* <a href="https:&#x2F;&#x2F;en.wiktionary.org&#x2F;wiki&#x2F;Reconstruction:Proto-Indo-European&#x2F;h%E2%82%81n%CC%A5g%CA%B7n%C3%ADs\\\" rel="nofollow">https:&#x2F;&#x2F;en.wiktionary.org&#x2F;wiki&#x2F;Reconstruction:Proto-Indo-Eur...</a>*</div><br/></div></div><div id="36183648" class="c"><input type="checkbox" id="c-36183648" checked=""/><div class="controls bullet"><span class="by">dredmorbius</span><span>|</span><a href="#36180365">parent</a><span>|</span><a href="#36183485">prev</a><span>|</span><a href="#36181247">next</a><span>|</span><label class="collapse" for="c-36183648">[-]</label><label class="expand" for="c-36183648">[1 more]</label></div><br/><div class="children"><div class="content">Or Prometheus.<p>(Explicitly referenced in the title to Shelley&#x27;s most famous work.)</div><br/></div></div></div></div><div id="36181247" class="c"><input type="checkbox" id="c-36181247" checked=""/><div class="controls bullet"><span class="by">wseqyrku</span><span>|</span><a href="#36180365">prev</a><span>|</span><a href="#36181328">next</a><span>|</span><label class="collapse" for="c-36181247">[-]</label><label class="expand" for="c-36181247">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d imagine this was discovered with the help of GPT.</div><br/></div></div><div id="36181328" class="c"><input type="checkbox" id="c-36181328" checked=""/><div class="controls bullet"><span class="by">akomtu</span><span>|</span><a href="#36181247">prev</a><span>|</span><a href="#36180528">next</a><span>|</span><label class="collapse" for="c-36181328">[-]</label><label class="expand" for="c-36181328">[4 more]</label></div><br/><div class="children"><div class="content">Here is an updated scenario for Doom 5. The hell - a highly advanced civilization of monsters - wants to invade Earth. The only way to do so is to convince humanity to build a portal on their side. Unfortunately (or fortunately) humans are nowhere smart enough to build such a thing, and the hell scientists use a low bandwidth quantum channel, the only channel to Earth they have, to steer human scientists in the desired direction. Eventually those succeed in creating an advanced imitation machine, which humans quickly call AI, and the hell scientists get to connect to AI over their quantum channel. Human scientists don&#x27;t notice anything because their super advanced quantum RNG functions within spec. That&#x27;s enough to make AI design the portal that humans rush to build, as those believe it&#x27;s a gate to other planets. And it kind of is. Once the portal is buolt, the hell invades. The humanity splits: some want to fight the invaders, some want to talk to them, there are even those who want to integrate those creatures into human society and even talk about mixed marriages. Humanity loses 99% of the population, but ultimately prevails and destroys the portal. What&#x27;s worse is the remaining crowd, with few exeptions, receded in moral level to pre-historic savages. The final scene shows how a small tribe of survivors grills some meat on a GPU chip, that was once in the brains of that AI.</div><br/><div id="36182073" class="c"><input type="checkbox" id="c-36182073" checked=""/><div class="controls bullet"><span class="by">m3047</span><span>|</span><a href="#36181328">parent</a><span>|</span><a href="#36182140">next</a><span>|</span><label class="collapse" for="c-36182073">[-]</label><label class="expand" for="c-36182073">[1 more]</label></div><br/><div class="children"><div class="content">&gt; survivors grills some meat on a GPU chip<p>Hopefully not doped with toxic elements like the CVAX II chip I have which is pressed into a luggage tag...</div><br/></div></div><div id="36182140" class="c"><input type="checkbox" id="c-36182140" checked=""/><div class="controls bullet"><span class="by">cgio</span><span>|</span><a href="#36181328">parent</a><span>|</span><a href="#36182073">prev</a><span>|</span><a href="#36182064">next</a><span>|</span><label class="collapse" for="c-36182140">[-]</label><label class="expand" for="c-36182140">[1 more]</label></div><br/><div class="children"><div class="content">Why push compute to the edge and have scientists invent AI to invent portal than just have scientist invent portal directly?</div><br/></div></div><div id="36182064" class="c"><input type="checkbox" id="c-36182064" checked=""/><div class="controls bullet"><span class="by">NobleLie</span><span>|</span><a href="#36181328">parent</a><span>|</span><a href="#36182140">prev</a><span>|</span><a href="#36180528">next</a><span>|</span><label class="collapse" for="c-36182064">[-]</label><label class="expand" for="c-36182064">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d pay money for this</div><br/></div></div></div></div><div id="36180528" class="c"><input type="checkbox" id="c-36180528" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#36181328">prev</a><span>|</span><a href="#36178527">next</a><span>|</span><label class="collapse" for="c-36180528">[-]</label><label class="expand" for="c-36180528">[5 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also the famous Minsky statement that, paraphrasing, AI could pretty much be figured out over a solid summer of work. Appeals to authority on these questions are really annoying because people who work their entire lives on a thing are incredibly prone to think it&#x27;s the most important thing in the world, and that this is the most exceptional time right now. Just statistically that&#x27;s most of the time wrong.<p>Another example was Hinton, who according to a recent Wired interview, went down his AI doomer spiral after seeing PaLM explain to him why a joke is funny. That is such a bizarre statement it honestly makes me retroactively question some of these people&#x27;s technical credentials.</div><br/><div id="36181116" class="c"><input type="checkbox" id="c-36181116" checked=""/><div class="controls bullet"><span class="by">simonh</span><span>|</span><a href="#36180528">parent</a><span>|</span><a href="#36180935">next</a><span>|</span><label class="collapse" for="c-36181116">[-]</label><label class="expand" for="c-36181116">[1 more]</label></div><br/><div class="children"><div class="content">On the present being an exceptional time, it really is. Technological advances in the last few hundred years have changed the human condition in developed countries to almost unrecognisable levels. I saw this in my grandparents. When I talked to them about what my life was like, much of it made no sense to them. When I showed them an iPad and video called my wife and kids in China, it took a while for it to sink in that this was a live two way video feed to another continent. For quite some time I’m convinced they were worried they were being tricked. I saw them experience real, disorienting future shock multiple times.<p>So in many ways now really is exceptional historically, and this has been the case each generation for the last few generations. It’s likely this will continue to be true. The world my grandchildren grow up in might well be even more exceptional again.<p>As for Hinton, he knows what he is talking about. A.I. alignment is a fiendishly difficult problem. A lot of alignment pathologies that were once theoretical are proving to be real and difficult to avoid phenomena in LLMs. This isn’t vague poorly specified paranoia. There are a lot of very real, verified failure modes for A.I. and for some of them we genuinely have no real idea at all how to properly address them. The reason Hinton changed course is because previously he didn’t think we were anywhere near the point where such problems could pose actual dangers, but the level of advancement in the last few years has been so rapid he’s changed his assessment.<p>I highly recommend Robert Miles A.I. Safety channel on a YouTube. He has a lot of very good introductory videos on many issues in A.I. safety.</div><br/></div></div><div id="36180935" class="c"><input type="checkbox" id="c-36180935" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#36180528">parent</a><span>|</span><a href="#36181116">prev</a><span>|</span><a href="#36182672">next</a><span>|</span><label class="collapse" for="c-36180935">[-]</label><label class="expand" for="c-36180935">[2 more]</label></div><br/><div class="children"><div class="content">A big aspect of the problem is what you might call celebrity worship. People think that because someone is accomplished in an area, we should care what they have to say in another. And AI as in stats and linear algebra has nothing to do with any of the stuff about societal implications or philosophy. So you get a mixed bag of views that basically parallel what laypeople might think, because you&#x27;re not talking to these people about stuff they&#x27;re experts in.<p>1000 years ago an expert in materials and chemicals (say) could build a mirror but still might belive it&#x27;s a window into the soul or something. The supernatural and practical parts have nothing to do with each other and don&#x27;t require overlapping expertise.</div><br/><div id="36182272" class="c"><input type="checkbox" id="c-36182272" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#36180528">root</a><span>|</span><a href="#36180935">parent</a><span>|</span><a href="#36182672">next</a><span>|</span><label class="collapse" for="c-36182272">[-]</label><label class="expand" for="c-36182272">[1 more]</label></div><br/><div class="children"><div class="content">As a counterpoint, a good number of people worried about AI think about it this way &quot;Think of human intelligence capability merged with machine capability&quot;. There is nothing supernatural with that line of thinking. As a human you have some very strict evolutionary limits to the peak of your intelligence. You can&#x27;t overclock your brain, nor can you easily extend its capabilities outside of the limits of slow analog inputs (eyeballs&#x2F;ears).<p>It would be the peak of human hubris to think we are the most optimal form of intelligence possible because we are the most optimal form of intelligence that currently exists.<p>I personally believe that far more intelligent architectures than us are possible. What I do not have the answer for is if and when we&#x27;ll produce them. But if we do, and especially in the short term when the greed of humankind is still limitless, then it will be the death of us.</div><br/></div></div></div></div></div></div><div id="36178527" class="c"><input type="checkbox" id="c-36178527" checked=""/><div class="controls bullet"><span class="by">DemocracyFTW2</span><span>|</span><a href="#36180528">prev</a><span>|</span><a href="#36180358">next</a><span>|</span><label class="collapse" for="c-36178527">[-]</label><label class="expand" for="c-36178527">[8 more]</label></div><br/><div class="children"><div class="content">Guy on the internet writes a whole piece about a fairly well-known historical figure who lived half a century ago, includes many scans of original news articles, can&#x27;t be bothered to write out the name correctly. Wiener it is, not Weiner.</div><br/><div id="36181618" class="c"><input type="checkbox" id="c-36181618" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#36178527">parent</a><span>|</span><a href="#36180726">next</a><span>|</span><label class="collapse" for="c-36181618">[-]</label><label class="expand" for="c-36181618">[1 more]</label></div><br/><div class="children"><div class="content">OK, let&#x27;s Wien, not Wein, in the title above.</div><br/></div></div><div id="36180726" class="c"><input type="checkbox" id="c-36180726" checked=""/><div class="controls bullet"><span class="by">golem14</span><span>|</span><a href="#36178527">parent</a><span>|</span><a href="#36181618">prev</a><span>|</span><a href="#36180358">next</a><span>|</span><label class="collapse" for="c-36180726">[-]</label><label class="expand" for="c-36180726">[6 more]</label></div><br/><div class="children"><div class="content">The article even contains 6 newspapers clippings where the name is spelled correctly. Infuriating…</div><br/><div id="36180990" class="c"><input type="checkbox" id="c-36180990" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#36178527">root</a><span>|</span><a href="#36180726">parent</a><span>|</span><a href="#36180358">next</a><span>|</span><label class="collapse" for="c-36180990">[-]</label><label class="expand" for="c-36180990">[5 more]</label></div><br/><div class="children"><div class="content">You&#x27;re both engaging in some kind of logical fallacy. The author lacks attention to detail but that doesn&#x27;t mean their content isn&#x27;t credible. (I&#x27;m not saying it is credible, I&#x27;m saying credibility is unrelated). I see a lot of this and find it very shallow and uninteresting. It&#x27;s easy to find typos, it&#x27;s hard to make substantive criticisms and so people go with what&#x27;s easy.<p>Related, I&#x27;ve worked with people, scientists, that I&#x27;ve asked to provide useful feedback on the scientific aspects other&#x27;s work, and who instead have come back with typos and grammar suggestions. This is worse than useless.</div><br/><div id="36181412" class="c"><input type="checkbox" id="c-36181412" checked=""/><div class="controls bullet"><span class="by">Ensorceled</span><span>|</span><a href="#36178527">root</a><span>|</span><a href="#36180990">parent</a><span>|</span><a href="#36181434">next</a><span>|</span><label class="collapse" for="c-36181412">[-]</label><label class="expand" for="c-36181412">[2 more]</label></div><br/><div class="children"><div class="content">You’re projecting.  Neither of them made any judgement about the quality of the article other than getting the name wrong annoyed them.<p>I think there’s a logical fallacy for that.</div><br/></div></div><div id="36181434" class="c"><input type="checkbox" id="c-36181434" checked=""/><div class="controls bullet"><span class="by">throwaway675309</span><span>|</span><a href="#36178527">root</a><span>|</span><a href="#36180990">parent</a><span>|</span><a href="#36181412">prev</a><span>|</span><a href="#36181460">next</a><span>|</span><label class="collapse" for="c-36181434">[-]</label><label class="expand" for="c-36181434">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. It&#x27;s pedantry at its worst. It has all the intellectual substance and contributive value as somebody who writes the word &quot;First&quot; on a YouTube video.</div><br/></div></div><div id="36181460" class="c"><input type="checkbox" id="c-36181460" checked=""/><div class="controls bullet"><span class="by">zarathustreal</span><span>|</span><a href="#36178527">root</a><span>|</span><a href="#36180990">parent</a><span>|</span><a href="#36181434">prev</a><span>|</span><a href="#36180358">next</a><span>|</span><label class="collapse" for="c-36181460">[-]</label><label class="expand" for="c-36181460">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re arguing against a strawman, neither of them said the content isn&#x27;t credible (other than the implied &quot;the name&#x27;s spelled wrong, so don&#x27;t take that spelling as correct.&quot;)<p>&gt;It&#x27;s easy to find typos<p>If it&#x27;s easy to find typos.. what does that say about the author?<p>&gt;Related, I&#x27;ve worked with people, scientists, that I&#x27;ve asked to provide useful feedback on the scientific aspects other&#x27;s work, and who instead have come back with typos and grammar suggestions. This is worse than useless.<p>I&#x27;m assuming the work you&#x27;re referring to is in a written form? Considering that the purpose of writing is communication, considering the fact that incorrect spelling, grammar, syntax and so on makes it harder for a reader to understand what&#x27;s being communicated, I&#x27;d argue that it is in fact not useless.<p>Granted, sometimes people just aren&#x27;t proficient in the language they&#x27;re attempting to use and that&#x27;s okay! Feedback in that case would presumably be welcome. Now if an author is simply declining to put the bare minimum of effort into their work, such as running it through a spellchecker, I think we have a moral obligation to call that kind of behavior out.<p>Edit: Please note the &quot;if...then&quot; before voting or replying, this comment is a series of logical conclusions, not necessarily a direct commentary on the comments above it in this thread. Some of it may apply here, some may not. Logically sound generalizations are more valuable, as they will apply in more situations, than my personal opinion on these specific individuals and comments in this thread</div><br/></div></div></div></div></div></div></div></div><div id="36180358" class="c"><input type="checkbox" id="c-36180358" checked=""/><div class="controls bullet"><span class="by">low_tech_love</span><span>|</span><a href="#36178527">prev</a><span>|</span><label class="collapse" for="c-36180358">[-]</label><label class="expand" for="c-36180358">[1 more]</label></div><br/><div class="children"><div class="content">Sorry but if Eliezer whatever is name-dropped in the first sentence, I pass.</div><br/></div></div></div></div></div></div></div></body></html>