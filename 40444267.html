<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1716454870978" as="style"/><link rel="stylesheet" href="styles.css?v=1716454870978"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://materializedview.io/p/s3-is-showing-its-age">S3 is showing its age</a> <span class="domain">(<a href="https://materializedview.io">materializedview.io</a>)</span></div><div class="subtext"><span>pulisse</span> | <span>121 comments</span></div><br/><div><div id="40449476" class="c"><input type="checkbox" id="c-40449476" checked=""/><div class="controls bullet"><span class="by">QuadrupleA</span><span>|</span><a href="#40446140">next</a><span>|</span><label class="collapse" for="c-40449476">[-]</label><label class="expand" for="c-40449476">[20 more]</label></div><br/><div class="children"><div class="content">Good. The first S in S3 is simple, despite nobody in software appreciating simplicity anymore.<p>Adding features makes documentation more complicated, makes the tech harder to learn, makes libraries bigger, likely harms performance a bit, increases bug surface area, etc.<p>When it gets too out of hand, people will paper it over with a new, simpler abstraction layer, and the process starts again, only with a layer of garbage spaghetti underneath.<p>Show your age and be proud, Simple Storage Service.</div><br/><div id="40449857" class="c"><input type="checkbox" id="c-40449857" checked=""/><div class="controls bullet"><span class="by">klodolph</span><span>|</span><a href="#40449476">parent</a><span>|</span><a href="#40451188">next</a><span>|</span><label class="collapse" for="c-40449857">[-]</label><label class="expand" for="c-40449857">[9 more]</label></div><br/><div class="children"><div class="content">Multi-region is pretty essential IMO. You can’t get the same cost effectiveness by building your own multi-region S3, stapling multiple buckets together. The basic premise of S3 is that you get a keystore interface, and S3 handles error correction and distributing the chunks among multiple physical machines on the cheap. Multi-region is the same product, at a larger scale. The complicated part is that somebody has to pay for the network bandwidth (whereas in a single region, it’s so cheap it’s unmetered).<p>The CAS thing is also pretty essential. Everybody wants to build some simple storage system on top of S3 and without CAS it’s pretty damn hard to have any kind of consistency guarantees, even for very simple systems… you end up having to build something outside S3 to manage consistency. An easy to understand use case is backups. Suppose you are using S3 as a backend for a backup system which deduplicates backups. You want to make backups from multiple locations, you want to deduplicate because there’s a lot of duplicate data floating around (maybe you have terabytes of video files getting copied, ML model weights, something else big that you copy around), and you want to expire old backups. You can <i>almost</i> build this on top of plain S3, and the only reason you can’t is because it’s unsafe to expire old data in such a system if any backup is writing (because the other backup may add a new reference to data, racing against the expiration &#x2F; garbage collection process). A simple CAS gives you a lot of tools to solve this. The alternative to CAS is doing something kinda silly, like running a DynamoDB table as a layer of indirection.<p>Neither of these things add much complexity to S3.<p>(I think append is less useful and potentially a lot more complicated, both in terms of its API implications and in terms of the underlying complexity. If I want “append”, then I can use multipart uploads, or just upload multiple objects and reassemble them on the client side.)</div><br/><div id="40449932" class="c"><input type="checkbox" id="c-40449932" checked=""/><div class="controls bullet"><span class="by">QuadrupleA</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40449857">parent</a><span>|</span><a href="#40451840">next</a><span>|</span><label class="collapse" for="c-40449932">[-]</label><label class="expand" for="c-40449932">[4 more]</label></div><br/><div class="children"><div class="content">Essential for who? Lots of other storage solutions if S3 is too simple. Distributed databases. Or fire up an EC2 cluster and install anything you want on it.</div><br/><div id="40449966" class="c"><input type="checkbox" id="c-40449966" checked=""/><div class="controls bullet"><span class="by">klodolph</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40449932">parent</a><span>|</span><a href="#40451537">next</a><span>|</span><label class="collapse" for="c-40449966">[-]</label><label class="expand" for="c-40449966">[2 more]</label></div><br/><div class="children"><div class="content">The multi-region thing should be pretty apparent. It’s part of the core S3 design to provide distributed storage. Multi-region is distributing it over a larger area. If you want to implement multi-region storage yourself, you can do it on S3 and pay a high cost for duplicated data, or you can try to implement your own S3 alternative.<p>For CAS, one example is backup jobs. You can run backup jobs to S3, but there are some safety issues if you want deduplication and you want to expire old data.<p>&gt; if S3 is too simple<p>CAS isn’t some kind of super complicated, technical thing.<p>It would be nice if S3 had this small, incremental additional feature. That’s all. It would mean that some people don’t need to fire up DynamoDB just to do something you can already do in, say, GCS.</div><br/><div id="40451584" class="c"><input type="checkbox" id="c-40451584" checked=""/><div class="controls bullet"><span class="by">altdataseller</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40449966">parent</a><span>|</span><a href="#40451537">next</a><span>|</span><label class="collapse" for="c-40451584">[-]</label><label class="expand" for="c-40451584">[1 more]</label></div><br/><div class="children"><div class="content">None of those are essential.<p>The only essential thing it needs to do is store my files, with some assurity that they will exist x years from now in a cost efficient manner.</div><br/></div></div></div></div></div></div><div id="40451840" class="c"><input type="checkbox" id="c-40451840" checked=""/><div class="controls bullet"><span class="by">peoplefromibiza</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40449857">parent</a><span>|</span><a href="#40449932">prev</a><span>|</span><a href="#40451974">next</a><span>|</span><label class="collapse" for="c-40451840">[-]</label><label class="expand" for="c-40451840">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Multi-region is pretty essential IMO<p>if we are talking about less than 1% of the applications, probably yes.</div><br/></div></div><div id="40451974" class="c"><input type="checkbox" id="c-40451974" checked=""/><div class="controls bullet"><span class="by">iLoveOncall</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40449857">parent</a><span>|</span><a href="#40451840">prev</a><span>|</span><a href="#40449930">next</a><span>|</span><label class="collapse" for="c-40451974">[-]</label><label class="expand" for="c-40451974">[1 more]</label></div><br/><div class="children"><div class="content">There essentially is multi-region buckets. You can configure automatic replication, and then use Multi-Region access points: <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;MultiRegionAccessPoints.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;MultiR...</a></div><br/></div></div><div id="40449930" class="c"><input type="checkbox" id="c-40449930" checked=""/><div class="controls bullet"><span class="by">AdamJacobMuller</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40449857">parent</a><span>|</span><a href="#40451974">prev</a><span>|</span><a href="#40451188">next</a><span>|</span><label class="collapse" for="c-40449930">[-]</label><label class="expand" for="c-40449930">[2 more]</label></div><br/><div class="children"><div class="content">&gt; you can’t is because it’s unsafe to expire old data in such a system if any backup is writing<p>I did this, I just don&#x27;t expire any object created in the past week.</div><br/><div id="40449935" class="c"><input type="checkbox" id="c-40449935" checked=""/><div class="controls bullet"><span class="by">klodolph</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40449930">parent</a><span>|</span><a href="#40451188">next</a><span>|</span><label class="collapse" for="c-40449935">[-]</label><label class="expand" for="c-40449935">[1 more]</label></div><br/><div class="children"><div class="content">A currently running backup process can create a new reference to an object which is more than a week old. Meanwhile, the garbage collection process can be deleting that object, but the deletion operation hasn’t finished yet. CAS gives you a lot of options to do this safely.</div><br/></div></div></div></div></div></div><div id="40451188" class="c"><input type="checkbox" id="c-40451188" checked=""/><div class="controls bullet"><span class="by">KronisLV</span><span>|</span><a href="#40449476">parent</a><span>|</span><a href="#40449857">prev</a><span>|</span><a href="#40449707">next</a><span>|</span><label class="collapse" for="c-40451188">[-]</label><label class="expand" for="c-40451188">[2 more]</label></div><br/><div class="children"><div class="content">&gt; When it gets too out of hand, people will paper it over with a new, simpler abstraction layer, and the process starts again, only with a layer of garbage spaghetti underneath.<p>I&#x27;m pretty happy that there are S3 compatible stores that you can host yourself, that aren&#x27;t insanely complex.<p>MinIO: <a href="https:&#x2F;&#x2F;min.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;min.io&#x2F;</a><p>SeaweedFS: <a href="https:&#x2F;&#x2F;github.com&#x2F;seaweedfs&#x2F;seaweedfs">https:&#x2F;&#x2F;github.com&#x2F;seaweedfs&#x2F;seaweedfs</a> (this one&#x27;s particularly nice and is permissively licensed, in contrast to everything else)<p>There was also Zenko, but I don&#x27;t think they gained a lot of traction for the most part: <a href="https:&#x2F;&#x2F;www.zenko.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.zenko.io&#x2F;</a><p>Of course, many will prefer hosted&#x2F;managed solutions and that&#x27;s perfectly fine, but at least when you run software yourself, you are more in control over it and for the most part can also make the judgement on how hard it is to operate and keep operational (e.g. similar to what you&#x27;d experience when running PostgreSQL&#x2F;MariaDB&#x2F;MySQL or trying to run Oracle).<p>That said, my needs (both in regards to features and scaling) are pretty basic, so it&#x27;s okay to pay any of the vendors for something a bit more advanced and scalable.</div><br/><div id="40451928" class="c"><input type="checkbox" id="c-40451928" checked=""/><div class="controls bullet"><span class="by">Already__Taken</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40451188">parent</a><span>|</span><a href="#40449707">next</a><span>|</span><label class="collapse" for="c-40451928">[-]</label><label class="expand" for="c-40451928">[1 more]</label></div><br/><div class="children"><div class="content">seaweedfs has worked really nice for our small use for 2 years. some docs polish wouldn&#x27;t hurt but reading the source isn&#x27;t hard and I don&#x27;t know golang.</div><br/></div></div></div></div><div id="40449707" class="c"><input type="checkbox" id="c-40449707" checked=""/><div class="controls bullet"><span class="by">charlie0</span><span>|</span><a href="#40449476">parent</a><span>|</span><a href="#40451188">prev</a><span>|</span><a href="#40451573">next</a><span>|</span><label class="collapse" for="c-40449707">[-]</label><label class="expand" for="c-40449707">[1 more]</label></div><br/><div class="children"><div class="content">This. There&#x27;s always a small group of people pushing feature requests (ahem scope creep) into services that were never designed for those things. Unfortunately, those people win a lot of the time. Ie, see all the simple JS frameworks that were initially meant to solve relatively simple problems, only for them to become bloated and be replaced by something else that promised simplicity.</div><br/></div></div><div id="40451573" class="c"><input type="checkbox" id="c-40451573" checked=""/><div class="controls bullet"><span class="by">vbezhenar</span><span>|</span><a href="#40449476">parent</a><span>|</span><a href="#40449707">prev</a><span>|</span><a href="#40450124">next</a><span>|</span><label class="collapse" for="c-40451573">[-]</label><label class="expand" for="c-40451573">[3 more]</label></div><br/><div class="children"><div class="content">S3 is anything but simple.<p>Here&#x27;s simple protocol:<p><pre><code>  PUT &#x2F;my&#x2F;key
  Content-Type: plain&#x2F;text

  Hello, world


  GET &#x2F;my&#x2F;key
</code></pre>
Did you ever tried to use S3 without libraries? Did you ever checked size of AWS SDK? It&#x27;s incredibly overengineered.</div><br/><div id="40452001" class="c"><input type="checkbox" id="c-40452001" checked=""/><div class="controls bullet"><span class="by">zokier</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40451573">parent</a><span>|</span><a href="#40451632">next</a><span>|</span><label class="collapse" for="c-40452001">[-]</label><label class="expand" for="c-40452001">[1 more]</label></div><br/><div class="children"><div class="content">The S3 is that simple. Only complication is AWS auth, but you can easily do stuff on S3 with e.g. plain curl:<p>$ curl \
    -H &#x27;Content-type: text&#x2F;plain&#x27; \
    --aws-sigv4 &#x27;aws:amz:eu-west-1:s3&#x27; \
    -u &quot;$AWS_ACCESS_KEY_ID&quot;:&quot;$AWS_SECRET_ACCESS_KEY&quot; \
    -H &quot;x-amz-security-token: $AWS_SESSION_TOKEN&quot; \
    -XPUT --data &#x27;hello world&#x27; \
    <a href="https:&#x2F;&#x2F;mybucket.s3.eu-west-1.amazonaws.com&#x2F;my&#x2F;key" rel="nofollow">https:&#x2F;&#x2F;mybucket.s3.eu-west-1.amazonaws.com&#x2F;my&#x2F;key</a><p>$ curl \
    --aws-sigv4 &#x27;aws:amz:eu-west-1:s3&#x27; \
    -u &quot;$AWS_ACCESS_KEY_ID&quot;:&quot;$AWS_SECRET_ACCESS_KEY&quot; \
    -H &quot;x-amz-security-token: $AWS_SESSION_TOKEN&quot; \
    <a href="https:&#x2F;&#x2F;mybucket.s3.eu-west-1.amazonaws.com&#x2F;my&#x2F;key" rel="nofollow">https:&#x2F;&#x2F;mybucket.s3.eu-west-1.amazonaws.com&#x2F;my&#x2F;key</a><p>just works.</div><br/></div></div><div id="40451632" class="c"><input type="checkbox" id="c-40451632" checked=""/><div class="controls bullet"><span class="by">l5870uoo9y</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40451573">parent</a><span>|</span><a href="#40452001">prev</a><span>|</span><a href="#40450124">next</a><span>|</span><label class="collapse" for="c-40451632">[-]</label><label class="expand" for="c-40451632">[1 more]</label></div><br/><div class="children"><div class="content">S3 does handle authentication by giving you a temporary upload URL so your bucket isn&#x27;t wide open. But I agree it isn&#x27;t the simplest solution.</div><br/></div></div></div></div><div id="40450124" class="c"><input type="checkbox" id="c-40450124" checked=""/><div class="controls bullet"><span class="by">notatoad</span><span>|</span><a href="#40449476">parent</a><span>|</span><a href="#40451573">prev</a><span>|</span><a href="#40450703">next</a><span>|</span><label class="collapse" for="c-40450124">[-]</label><label class="expand" for="c-40450124">[3 more]</label></div><br/><div class="children"><div class="content">i think S3 passed beyond the &quot;simple&quot; a long time ago.  is this simple?  <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a4jGu0Z" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;a4jGu0Z</a></div><br/><div id="40452199" class="c"><input type="checkbox" id="c-40452199" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40450124">parent</a><span>|</span><a href="#40451711">next</a><span>|</span><label class="collapse" for="c-40452199">[-]</label><label class="expand" for="c-40452199">[1 more]</label></div><br/><div class="children"><div class="content">The simple things are simple. Other are possible to do. I don&#x27;t think that image is representative. &quot;I want to go for a walk, but there&#x27;s whole world to choose the path from&quot; - you can still go around the block, the world is not in the way. (There&#x27;s are simple, generic read-only and read write policies available)</div><br/></div></div><div id="40451711" class="c"><input type="checkbox" id="c-40451711" checked=""/><div class="controls bullet"><span class="by">CodinM</span><span>|</span><a href="#40449476">root</a><span>|</span><a href="#40450124">parent</a><span>|</span><a href="#40452199">prev</a><span>|</span><a href="#40450703">next</a><span>|</span><label class="collapse" for="c-40451711">[-]</label><label class="expand" for="c-40451711">[1 more]</label></div><br/><div class="children"><div class="content">As someone who had to make a company pass an audit, and the company massively relied on S3 buckets...this so much.</div><br/></div></div></div></div><div id="40450703" class="c"><input type="checkbox" id="c-40450703" checked=""/><div class="controls bullet"><span class="by">rcleveng</span><span>|</span><a href="#40449476">parent</a><span>|</span><a href="#40450124">prev</a><span>|</span><a href="#40446140">next</a><span>|</span><label class="collapse" for="c-40450703">[-]</label><label class="expand" for="c-40450703">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely this.  Sounds like the author wants CS2 (Complex Storage Service).  Appreciate simplicity</div><br/></div></div></div></div><div id="40446140" class="c"><input type="checkbox" id="c-40446140" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#40449476">prev</a><span>|</span><a href="#40451715">next</a><span>|</span><label class="collapse" for="c-40446140">[-]</label><label class="expand" for="c-40446140">[30 more]</label></div><br/><div class="children"><div class="content">S3 was&#x2F;is optimised for a specific bunch of use cases.<p>Because EC2&#x27;s hypervisor was (when it was launched) lacking features (no hot swap, not shared block storage, no host movements, no online backup&#x2F;clone, no live recovery, no Highly available host failover ) S3 had to step in to pick up some of the slack that proper block or file storage would have taken.<p>For better or for worse, people adopted the ephemeral style of computing, and used s3 as the state store.<p>S3 got away with it because it was the only practical object store in town.<p>The biggest drawback that is still has (and will likely always have) is that you can&#x27;t write parts to a file. its either replace or nothing.<p>But that&#x27;s by design.<p>So I suspect it&#x27;ll stay like that.</div><br/><div id="40449005" class="c"><input type="checkbox" id="c-40449005" checked=""/><div class="controls bullet"><span class="by">amzn-throw</span><span>|</span><a href="#40446140">parent</a><span>|</span><a href="#40447576">next</a><span>|</span><label class="collapse" for="c-40449005">[-]</label><label class="expand" for="c-40449005">[2 more]</label></div><br/><div class="children"><div class="content">Sounds good, but not true: <a href="https:&#x2F;&#x2F;www.awsgeek.com&#x2F;AWS-History&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.awsgeek.com&#x2F;AWS-History&#x2F;</a><p>S3 launched in 2006.<p>EC2 didn&#x27;t go GA until 2008.<p>Elastic Block Store (a proper block store) showed up in 2008 too, actually went GA before even EC2.<p>S3 was for the longest time pitched as storage for the internet, and remains so today.<p>I super doubt these limitations are there because of any EC2 requirements.</div><br/><div id="40449105" class="c"><input type="checkbox" id="c-40449105" checked=""/><div class="controls bullet"><span class="by">easton</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40449005">parent</a><span>|</span><a href="#40447576">next</a><span>|</span><label class="collapse" for="c-40449105">[-]</label><label class="expand" for="c-40449105">[1 more]</label></div><br/><div class="children"><div class="content">I think OP isn’t saying S3 was created to service EC2, but people deploying EC2 used it as a substitute for EC2 having certain features.</div><br/></div></div></div></div><div id="40447576" class="c"><input type="checkbox" id="c-40447576" checked=""/><div class="controls bullet"><span class="by">rowanseymour</span><span>|</span><a href="#40446140">parent</a><span>|</span><a href="#40449005">prev</a><span>|</span><a href="#40447192">next</a><span>|</span><label class="collapse" for="c-40447576">[-]</label><label class="expand" for="c-40447576">[11 more]</label></div><br/><div class="children"><div class="content">Sigh append would be such game changer for us. Pulling a big S3 object over the wire to append to it and send it back is far from ideal.</div><br/><div id="40447665" class="c"><input type="checkbox" id="c-40447665" checked=""/><div class="controls bullet"><span class="by">afavour</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40447576">parent</a><span>|</span><a href="#40451230">next</a><span>|</span><label class="collapse" for="c-40447665">[-]</label><label class="expand" for="c-40447665">[5 more]</label></div><br/><div class="children"><div class="content">Try Azure’s equivalent. I’ve already forgotten what it’s called but it has append operations.</div><br/><div id="40448763" class="c"><input type="checkbox" id="c-40448763" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40447665">parent</a><span>|</span><a href="#40448018">next</a><span>|</span><label class="collapse" for="c-40448763">[-]</label><label class="expand" for="c-40448763">[2 more]</label></div><br/><div class="children"><div class="content">The <i>design</i> of Azure&#x27;s blob-store abstraction is great progress toward the ideal form of an object-store: a serverless managed store for all types of data buffers, where handles can be efficiently transformed&#x2F;exchanged between between different &quot;states of matter&quot; — immutable objects, vs append-only streamable logs, vs multi-reader multi-writer random-access disks; and where all three of these states of data-buffer can be consumed interchangeably by a consumer through the same set of APIs — where these APIs might work most efficiently for data buffers that are in the right state, but they still <i>work</i> for data buffers that aren&#x27;t.<p>Sadly, Azure&#x27;s <i>implementation</i> of its blob-store, is kind of underwhelming — especially for any kind of infrastructure-level use-cases.<p>For example, while there is a change feed for blob events, akin to S3 lifecycle event notifications, it stops exactly where S3&#x27;s API stops; so there is no event generated by an append to an appendable blob, nor a write to a page in a page blob or a block in a block blob. (And even if there were, they make no guarantees of the change feed being linearized — saying that changes to some resources might arrive out-of-order or not at all; and that if you <i>want</i> a linearized change feed, you need to read it out of a log-multiplexer, which puts a several-minute delay and multi-minute step-granularity on reads from it.)<p>As such, you can&#x27;t use Append Blobs as the storage layer for a Kafka-alike; and nor can you use Page Blobs as the transport to enable an embedded LMDB-alike to be network-replicated. (Or rather, you <i>can</i>, but in both cases you won&#x27;t receive timely notifications that new data has been added &#x2F; that pages have been invalidated at the origin, so unless you&#x27;re operating with zero caching, your cache will end up stale and your state from successive reads will end up incoherent.)</div><br/><div id="40450214" class="c"><input type="checkbox" id="c-40450214" checked=""/><div class="controls bullet"><span class="by">d0gsg0w00f</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40448763">parent</a><span>|</span><a href="#40448018">next</a><span>|</span><label class="collapse" for="c-40450214">[-]</label><label class="expand" for="c-40450214">[1 more]</label></div><br/><div class="children"><div class="content">In my 1 year of experience with Azure 3 years ago I saw this same story play out across every product line. Layers 1-3 look amazing then layers 4-6 are total head scratcher deal breakers. Very frustrating.</div><br/></div></div></div></div><div id="40448018" class="c"><input type="checkbox" id="c-40448018" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40447665">parent</a><span>|</span><a href="#40448763">prev</a><span>|</span><a href="#40450667">next</a><span>|</span><label class="collapse" for="c-40448018">[-]</label><label class="expand" for="c-40448018">[1 more]</label></div><br/><div class="children"><div class="content">So simple it&#x27;s hard: append blobs[1].<p>[1]: <a href="https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;rest&#x2F;api&#x2F;storageservices&#x2F;understanding-block-blobs--append-blobs--and-page-blobs#about-append-blobs" rel="nofollow">https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;rest&#x2F;api&#x2F;storageservices&#x2F;u...</a></div><br/></div></div><div id="40450667" class="c"><input type="checkbox" id="c-40450667" checked=""/><div class="controls bullet"><span class="by">nosefrog</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40447665">parent</a><span>|</span><a href="#40448018">prev</a><span>|</span><a href="#40451230">next</a><span>|</span><label class="collapse" for="c-40450667">[-]</label><label class="expand" for="c-40450667">[1 more]</label></div><br/><div class="children"><div class="content">Sure, how many 9&#x27;s of availability does it have again?</div><br/></div></div></div></div><div id="40451230" class="c"><input type="checkbox" id="c-40451230" checked=""/><div class="controls bullet"><span class="by">nathants</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40447576">parent</a><span>|</span><a href="#40447665">prev</a><span>|</span><a href="#40448522">next</a><span>|</span><label class="collapse" for="c-40451230">[-]</label><label class="expand" for="c-40451230">[1 more]</label></div><br/><div class="children"><div class="content">the correct pattern is to append immutable objects into a common prefix.</div><br/></div></div><div id="40448522" class="c"><input type="checkbox" id="c-40448522" checked=""/><div class="controls bullet"><span class="by">verticalscaler</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40447576">parent</a><span>|</span><a href="#40451230">prev</a><span>|</span><a href="#40447192">next</a><span>|</span><label class="collapse" for="c-40448522">[-]</label><label class="expand" for="c-40448522">[4 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;mpuoverview.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;mpuove...</a><p><pre><code>  Multipart upload allows you to upload a single object as a set of parts. Each part is a contiguous portion of the object&#x27;s data. You can upload these object parts independently and in any order. If transmission of any part fails, you can retransmit that part without affecting other parts. After all parts of your object are uploaded, Amazon S3 assembles these parts and creates the object. In general, when your object size reaches 100 MB, you should consider using multipart uploads instead of uploading the object in a single operation.</code></pre></div><br/><div id="40449125" class="c"><input type="checkbox" id="c-40449125" checked=""/><div class="controls bullet"><span class="by">ericbarrett</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40448522">parent</a><span>|</span><a href="#40449134">next</a><span>|</span><label class="collapse" for="c-40449125">[-]</label><label class="expand" for="c-40449125">[2 more]</label></div><br/><div class="children"><div class="content">Multipart uploads are not the same as append; an object being multipart-uploaded doesn&#x27;t exist in the bucket namespace until the upload is finalized, and once that is done it cannot be modified without overwriting.</div><br/><div id="40450284" class="c"><input type="checkbox" id="c-40450284" checked=""/><div class="controls bullet"><span class="by">dabiged</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40449125">parent</a><span>|</span><a href="#40449134">next</a><span>|</span><label class="collapse" for="c-40450284">[-]</label><label class="expand" for="c-40450284">[1 more]</label></div><br/><div class="children"><div class="content">They don&#x27;t exist in the bucket name space, but they sure as hell exist in the bucket bill!</div><br/></div></div></div></div><div id="40449134" class="c"><input type="checkbox" id="c-40449134" checked=""/><div class="controls bullet"><span class="by">joombaga</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40448522">parent</a><span>|</span><a href="#40449125">prev</a><span>|</span><a href="#40447192">next</a><span>|</span><label class="collapse" for="c-40449134">[-]</label><label class="expand" for="c-40449134">[1 more]</label></div><br/><div class="children"><div class="content">This doesn&#x27;t really help Rowan. You cannot edit an individual part after completing the upload.</div><br/></div></div></div></div></div></div><div id="40447192" class="c"><input type="checkbox" id="c-40447192" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#40446140">parent</a><span>|</span><a href="#40447576">prev</a><span>|</span><a href="#40449494">next</a><span>|</span><label class="collapse" for="c-40447192">[-]</label><label class="expand" for="c-40447192">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The biggest drawback that is still has (and will likely always have) is that you can&#x27;t write parts to a file. its either replace or nothing.<p>You can emulate it though via UploadPartCopy in many cases, no?</div><br/></div></div><div id="40449494" class="c"><input type="checkbox" id="c-40449494" checked=""/><div class="controls bullet"><span class="by">harrison_clarke</span><span>|</span><a href="#40446140">parent</a><span>|</span><a href="#40447192">prev</a><span>|</span><a href="#40449277">next</a><span>|</span><label class="collapse" for="c-40449494">[-]</label><label class="expand" for="c-40449494">[2 more]</label></div><br/><div class="children"><div class="content">you can get append or edit-like behavior if you use S3 to store B-trees or something, rather than flat files<p>i wish it had a CAS mechanism, though. (google&#x27;s does, with the x-goog-if-generation-match header)</div><br/><div id="40449674" class="c"><input type="checkbox" id="c-40449674" checked=""/><div class="controls bullet"><span class="by">xyzzy_plugh</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40449494">parent</a><span>|</span><a href="#40449277">next</a><span>|</span><label class="collapse" for="c-40449674">[-]</label><label class="expand" for="c-40449674">[1 more]</label></div><br/><div class="children"><div class="content">It is crazy that S3 still does not have a comparable header. It&#x27;s the single biggest miss they&#x27;re sitting on right now as far as I&#x27;m concerned.</div><br/></div></div></div></div><div id="40449277" class="c"><input type="checkbox" id="c-40449277" checked=""/><div class="controls bullet"><span class="by">RachelF</span><span>|</span><a href="#40446140">parent</a><span>|</span><a href="#40449494">prev</a><span>|</span><a href="#40446183">next</a><span>|</span><label class="collapse" for="c-40449277">[-]</label><label class="expand" for="c-40449277">[5 more]</label></div><br/><div class="children"><div class="content">Yes, it can&#x27;t write to parts of a file.<p>It also can&#x27;t read (seek) into the file (or couldn&#x27;t when I last looked at it).<p>It is not a file system, but is often mistaken for one.</div><br/><div id="40449722" class="c"><input type="checkbox" id="c-40449722" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40449277">parent</a><span>|</span><a href="#40449309">next</a><span>|</span><label class="collapse" for="c-40449722">[-]</label><label class="expand" for="c-40449722">[3 more]</label></div><br/><div class="children"><div class="content">You can request specific byte ranges from S3 objects. It’s had this feature since at least 2012.<p><a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;26964626&#x2F;specify-byte-range-via-query-string-in-get-object-s3-request" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;26964626&#x2F;specify-byte-ra...</a></div><br/><div id="40450634" class="c"><input type="checkbox" id="c-40450634" checked=""/><div class="controls bullet"><span class="by">RachelF</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40449722">parent</a><span>|</span><a href="#40450461">next</a><span>|</span><label class="collapse" for="c-40450634">[-]</label><label class="expand" for="c-40450634">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for that.</div><br/></div></div></div></div><div id="40449309" class="c"><input type="checkbox" id="c-40449309" checked=""/><div class="controls bullet"><span class="by">th0ma5</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40449277">parent</a><span>|</span><a href="#40449722">prev</a><span>|</span><a href="#40446183">next</a><span>|</span><label class="collapse" for="c-40449309">[-]</label><label class="expand" for="c-40449309">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been able to pass byte offsets and ranges to S3 requests.</div><br/></div></div></div></div><div id="40446183" class="c"><input type="checkbox" id="c-40446183" checked=""/><div class="controls bullet"><span class="by">cduzz</span><span>|</span><a href="#40446140">parent</a><span>|</span><a href="#40449277">prev</a><span>|</span><a href="#40451715">next</a><span>|</span><label class="collapse" for="c-40446183">[-]</label><label class="expand" for="c-40446183">[8 more]</label></div><br/><div class="children"><div class="content">At scale, running on commodity servers, why would want those features even today?</div><br/><div id="40446217" class="c"><input type="checkbox" id="c-40446217" checked=""/><div class="controls bullet"><span class="by">kbolino</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40446183">parent</a><span>|</span><a href="#40446599">next</a><span>|</span><label class="collapse" for="c-40446217">[-]</label><label class="expand" for="c-40446217">[5 more]</label></div><br/><div class="children"><div class="content">Partial updates could be useful for certain kinds of (mostly binary) files, but block storage is going to handle that much better in general than object storage. The concurrency and consistency guarantees are quite different between object and block storage. Making partial updates atomic would be quite difficult in general in S3, though simple preconditions like compare-and-swap (which is sorely needed anyway) might be sufficient to make it possible for certain use cases.</div><br/><div id="40446600" class="c"><input type="checkbox" id="c-40446600" checked=""/><div class="controls bullet"><span class="by">skrtskrt</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40446217">parent</a><span>|</span><a href="#40448765">next</a><span>|</span><label class="collapse" for="c-40446600">[-]</label><label class="expand" for="c-40446600">[1 more]</label></div><br/><div class="children"><div class="content">The paradigm can be flipped now for these distributed storage systems.<p>The blocks of a filesystem can now be objects, replicated or erasure-coded - like Ceph running filesystems on top of its low-level object storage protocol, which is done on raw disks, not a filesystem.<p>This can&#x27;t be done for something like Minio just running on your filesystem, but if you&#x27;re building the storage system from the ground up it can.<p>We will see more and more of these products appearing.<p>Vast Data is another interesting one. Global deduplication and compression for your data, with an S3, block, or NFS interface.
Storing differential backups for thousands or millions of VMs?
You&#x27;ll only store the data from base Ubuntu image once.</div><br/></div></div><div id="40448765" class="c"><input type="checkbox" id="c-40448765" checked=""/><div class="controls bullet"><span class="by">cduzz</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40446217">parent</a><span>|</span><a href="#40446600">prev</a><span>|</span><a href="#40446514">next</a><span>|</span><label class="collapse" for="c-40448765">[-]</label><label class="expand" for="c-40448765">[1 more]</label></div><br/><div class="children"><div class="content">I was referring more to the list of hypervisor features not implemented:<p>&gt;&gt;   Because EC2&#x27;s hypervisor was (when it was launched) lacking features (no hot swap, not shared block storage, no host movements, no online backup&#x2F;clone, no live recovery, no Highly available host failover ) S3 had to step in to pick up some of the slack that proper block or file storage would have taken.<p>I don&#x27;t want any of that nonsense in my compute layer or an application (at scale) that relies on shared block storage or host movements or live recovery.<p>I&#x27;m sure S3 append would be super handy.</div><br/></div></div><div id="40446514" class="c"><input type="checkbox" id="c-40446514" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40446217">parent</a><span>|</span><a href="#40448765">prev</a><span>|</span><a href="#40446599">next</a><span>|</span><label class="collapse" for="c-40446514">[-]</label><label class="expand" for="c-40446514">[2 more]</label></div><br/><div class="children"><div class="content">I think gcloud has CAS by comparing etags. Surprised to hear S3 can’t.</div><br/><div id="40451251" class="c"><input type="checkbox" id="c-40451251" checked=""/><div class="controls bullet"><span class="by">nathants</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40446514">parent</a><span>|</span><a href="#40446599">next</a><span>|</span><label class="collapse" for="c-40451251">[-]</label><label class="expand" for="c-40451251">[1 more]</label></div><br/><div class="children"><div class="content">the common approach is cas dynamodb pointers to uuid named objects in a named s3 prefix.<p>would it be better to merge ddb and s3? maybe, maybe not.<p>gcp&#x2F;azure&#x2F;etc are there to provide fancy cloud solutions. no need for aws to serve that market as well.</div><br/></div></div></div></div></div></div><div id="40446599" class="c"><input type="checkbox" id="c-40446599" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40446183">parent</a><span>|</span><a href="#40446217">prev</a><span>|</span><a href="#40451715">next</a><span>|</span><label class="collapse" for="c-40446599">[-]</label><label class="expand" for="c-40446599">[2 more]</label></div><br/><div class="children"><div class="content">At scale?<p>transparent HA means that I can fail over services to other regions without having to get the programmers to think about it. Most of the busy work at scale is managing state or, more correctly recovering state from broken machines.<p>If I can make something else do that reliably, rather than engineer it myself, thats a win.<p>So much of the work of standing up a cluster (be it k8s or something else) is getting to the point where you can arbitrarily kill a datastore and it self heal.<p>If you&#x27;re talking about s3 partial updates, its about cost&#x2F;and or performance. If you dealing with megabyte chunks, and you want to flip a few bytes over hundreds of thousands, thats going to eat into transfer costs.<p>Sure you could chunk up the files even smaller, but then you hit into access latency (s3 aint that fast. )</div><br/><div id="40448788" class="c"><input type="checkbox" id="c-40448788" checked=""/><div class="controls bullet"><span class="by">cduzz</span><span>|</span><a href="#40446140">root</a><span>|</span><a href="#40446599">parent</a><span>|</span><a href="#40451715">next</a><span>|</span><label class="collapse" for="c-40448788">[-]</label><label class="expand" for="c-40448788">[1 more]</label></div><br/><div class="children"><div class="content">I was referring to the notion that &quot;failings&quot; in the hypervisor layer like &quot;hot swap, shared block storage, host movements, online backup&#x2F;clone, live recovery,  Highly available host failover&quot; are a problem.  At scale, I don&#x27;t want my application to rely on any of that magic.<p>Reliability is always <i>your</i> problem not something to be punted to another layer of the stack that lets you pretend stuff doesn&#x27;t go wrong.</div><br/></div></div></div></div></div></div></div></div><div id="40451715" class="c"><input type="checkbox" id="c-40451715" checked=""/><div class="controls bullet"><span class="by">andyjohnson0</span><span>|</span><a href="#40446140">prev</a><span>|</span><a href="#40446921">next</a><span>|</span><label class="collapse" for="c-40451715">[-]</label><label class="expand" for="c-40451715">[1 more]</label></div><br/><div class="children"><div class="content">The mere fact that abstractions like S3 even <i>exist</i> still boggles my mind. Infinitely scalable, indefinitely persistent, inexpensive, super-high reliability, software-addressable storage accessible from (almost) anywhere on the planet. I&#x27;m sure tfa&#x27;s critique is valid, but also... we have miraculous tools.</div><br/></div></div><div id="40446921" class="c"><input type="checkbox" id="c-40446921" checked=""/><div class="controls bullet"><span class="by">kylehotchkiss</span><span>|</span><a href="#40451715">prev</a><span>|</span><a href="#40451210">next</a><span>|</span><label class="collapse" for="c-40446921">[-]</label><label class="expand" for="c-40446921">[15 more]</label></div><br/><div class="children"><div class="content">I want somewhere reasonably priced to keep my files where I can confidently know they&#x27;ll be there a decade from now.<p>For that purpose, I think S3&#x27;s age is a killer feature. I won&#x27;t be surprised when we see the HN post &quot;google cloud storage has been sent to the graveyard&quot;</div><br/><div id="40448506" class="c"><input type="checkbox" id="c-40448506" checked=""/><div class="controls bullet"><span class="by">jimt1234</span><span>|</span><a href="#40446921">parent</a><span>|</span><a href="#40447446">next</a><span>|</span><label class="collapse" for="c-40448506">[-]</label><label class="expand" for="c-40448506">[8 more]</label></div><br/><div class="children"><div class="content">I put all my &quot;decade from now&quot; files on three separate 500GB USB drives, each storing the same data, and each drive from different manufacturers&#x2F;dates. Two drives stored in a safe at my house, and one in a safe at my brother&#x27;s house. I used to store in S3, and it was more convenient, but I just felt weird about storing really important files on someone else&#x27;s cloud -- what if I don&#x27;t login to the AWS account for 9 years, and then when I need my files, I find out AWS kindly deleted&#x2F;disabled my account and I didn&#x27;t know about it? That situation is my biggest concern.</div><br/><div id="40451366" class="c"><input type="checkbox" id="c-40451366" checked=""/><div class="controls bullet"><span class="by">vineyardmike</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40448506">parent</a><span>|</span><a href="#40449068">next</a><span>|</span><label class="collapse" for="c-40451366">[-]</label><label class="expand" for="c-40451366">[1 more]</label></div><br/><div class="children"><div class="content">&gt; what if I don&#x27;t login to the AWS account for 9 years, and then when I need my files, I find out AWS kindly deleted&#x2F;disabled my account and I didn&#x27;t know about it? That situation is my biggest concern.<p>Understandable concern, but AWS being targeted at enterprise gives me confidence they don&#x27;t do any funny stuff like that. On and of course, they bill you monthly, so ideally you&#x27;d have a tell if something goes wrong.<p>I also store my files locally on a USB drive in alternative locations, but I conceptually trust S3, but maybe actions speak louder.</div><br/></div></div><div id="40449068" class="c"><input type="checkbox" id="c-40449068" checked=""/><div class="controls bullet"><span class="by">daydream</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40448506">parent</a><span>|</span><a href="#40451366">prev</a><span>|</span><a href="#40449672">next</a><span>|</span><label class="collapse" for="c-40449068">[-]</label><label class="expand" for="c-40449068">[3 more]</label></div><br/><div class="children"><div class="content">Local vs cloud backups each have their own tradeoffs. I use both.<p>For cloud backup I use Arq backing up daily to AWS (no affiliation with Arq other than being a happy customer). You get client side encryption and the daily backup directly mitigates your concern, if there’s an AWS account issue you will know immediately and can fix it. For my storage amount and use it only costs about $2 a month.</div><br/><div id="40449542" class="c"><input type="checkbox" id="c-40449542" checked=""/><div class="controls bullet"><span class="by">skulk</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40449068">parent</a><span>|</span><a href="#40449672">next</a><span>|</span><label class="collapse" for="c-40449542">[-]</label><label class="expand" for="c-40449542">[2 more]</label></div><br/><div class="children"><div class="content">if you accidentally create way too much data and it gets automatically hacked up, do you get a huge bill? Or is it capped somehow?</div><br/><div id="40449645" class="c"><input type="checkbox" id="c-40449645" checked=""/><div class="controls bullet"><span class="by">daydream</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40449542">parent</a><span>|</span><a href="#40449672">next</a><span>|</span><label class="collapse" for="c-40449645">[-]</label><label class="expand" for="c-40449645">[1 more]</label></div><br/><div class="children"><div class="content">I don’t know. I’ve been using this setup for 7+ years, daily backups, and never had this problem.<p>I have about 80 GB or so of data being backed up. The daily backups upload only new files plus files that are changed. The largest monthly AWS bill I ever got was $6. The next month it went back to the usual ~$2 range.</div><br/></div></div></div></div></div></div><div id="40449672" class="c"><input type="checkbox" id="c-40449672" checked=""/><div class="controls bullet"><span class="by">wnolens</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40448506">parent</a><span>|</span><a href="#40449068">prev</a><span>|</span><a href="#40451339">next</a><span>|</span><label class="collapse" for="c-40449672">[-]</label><label class="expand" for="c-40449672">[1 more]</label></div><br/><div class="children"><div class="content">What kind of files? I can&#x27;t think of anything I have that I would go through this effort for.</div><br/></div></div><div id="40451339" class="c"><input type="checkbox" id="c-40451339" checked=""/><div class="controls bullet"><span class="by">genewitch</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40448506">parent</a><span>|</span><a href="#40449672">prev</a><span>|</span><a href="#40451320">next</a><span>|</span><label class="collapse" for="c-40451339">[-]</label><label class="expand" for="c-40451339">[1 more]</label></div><br/><div class="children"><div class="content">you have to pay to store stuff on S3 (or glacier), monthly. So i don&#x27;t think they care if you log in - if your credit card on file allows billing for 9 years.</div><br/></div></div><div id="40451320" class="c"><input type="checkbox" id="c-40451320" checked=""/><div class="controls bullet"><span class="by">nathants</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40448506">parent</a><span>|</span><a href="#40451339">prev</a><span>|</span><a href="#40447446">next</a><span>|</span><label class="collapse" for="c-40451320">[-]</label><label class="expand" for="c-40451320">[1 more]</label></div><br/><div class="children"><div class="content">i do the same thing!<p>i use spinning rust in x3 single usb external enclosures[1].<p>i mirror s3 data, both as an extra backup and to prevent s3 egress billing for random access.<p>s3 egress is for disaster recovery only.<p>1. <a href="https:&#x2F;&#x2F;github.com&#x2F;nathants&#x2F;mirror">https:&#x2F;&#x2F;github.com&#x2F;nathants&#x2F;mirror</a></div><br/></div></div></div></div><div id="40447446" class="c"><input type="checkbox" id="c-40447446" checked=""/><div class="controls bullet"><span class="by">szundi</span><span>|</span><a href="#40446921">parent</a><span>|</span><a href="#40448506">prev</a><span>|</span><a href="#40451210">next</a><span>|</span><label class="collapse" for="c-40447446">[-]</label><label class="expand" for="c-40447446">[6 more]</label></div><br/><div class="children"><div class="content">Google can do that. How could they kill even the IoT core, my fleet of devices just died. (No resources to migrate)</div><br/><div id="40447690" class="c"><input type="checkbox" id="c-40447690" checked=""/><div class="controls bullet"><span class="by">kylehotchkiss</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40447446">parent</a><span>|</span><a href="#40447916">next</a><span>|</span><label class="collapse" for="c-40447690">[-]</label><label class="expand" for="c-40447690">[4 more]</label></div><br/><div class="children"><div class="content">Their killing of domains, selling that to Squarespace, then Squarespace selling to PE was the most incredible degradation of service I&#x27;ve seen in a while!</div><br/><div id="40450261" class="c"><input type="checkbox" id="c-40450261" checked=""/><div class="controls bullet"><span class="by">dpkirchner</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40447690">parent</a><span>|</span><a href="#40451774">next</a><span>|</span><label class="collapse" for="c-40450261">[-]</label><label class="expand" for="c-40450261">[2 more]</label></div><br/><div class="children"><div class="content">It was such a bizarre choice, I don&#x27;t understand. Why wouldn&#x27;t they want new businesses to come to them first? Naming a company often involves getting a domain and then paying for hosting, email, and&#x2F;or other services. This all makes me think gsuite will be next on the chopping block.</div><br/><div id="40451390" class="c"><input type="checkbox" id="c-40451390" checked=""/><div class="controls bullet"><span class="by">vineyardmike</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40450261">parent</a><span>|</span><a href="#40451774">next</a><span>|</span><label class="collapse" for="c-40451390">[-]</label><label class="expand" for="c-40451390">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This all makes me think gsuite will be next on the chopping block.<p>GSuite is the most profitable part of GCP, and it&#x27;s totally propping that division up. It&#x27;ll be the last to go - it&#x27;s a lot easier to recognize bad management.<p>Domains probably was expensive to maintain or understaffed for some reason, and some exec knew a guy a Squarespace.</div><br/></div></div></div></div><div id="40451774" class="c"><input type="checkbox" id="c-40451774" checked=""/><div class="controls bullet"><span class="by">antihero</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40447690">parent</a><span>|</span><a href="#40450261">prev</a><span>|</span><a href="#40447916">next</a><span>|</span><label class="collapse" for="c-40451774">[-]</label><label class="expand" for="c-40451774">[1 more]</label></div><br/><div class="children"><div class="content">Wait what&#x27;s the latter part of this? I know they were sold to Squarespace, but who&#x27;s PE?</div><br/></div></div></div></div><div id="40447916" class="c"><input type="checkbox" id="c-40447916" checked=""/><div class="controls bullet"><span class="by">justinclift</span><span>|</span><a href="#40446921">root</a><span>|</span><a href="#40447446">parent</a><span>|</span><a href="#40447690">prev</a><span>|</span><a href="#40451210">next</a><span>|</span><label class="collapse" for="c-40447916">[-]</label><label class="expand" for="c-40447916">[1 more]</label></div><br/><div class="children"><div class="content">Oh wow, I didn&#x27;t realise they&#x27;d dont that.  Going to the page though:<p><a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;iot-core" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;iot-core</a><p>... shows this:<p><pre><code>    Google Cloud IoT Core has been retired.
</code></pre>
Several years ago a startup owner I was friends with was doing IoT stuff.  If they&#x27;d ended up choosing the Google option for their device comms they&#x27;d have been in a bad place from this.  Pretty sure they went with the AWS IoT stuff though.<p>At this point, I wonder if there&#x27;s anyone left on Earth who Google <i>haven&#x27;t</i> screwed over in some significant way?</div><br/></div></div></div></div></div></div><div id="40451210" class="c"><input type="checkbox" id="c-40451210" checked=""/><div class="controls bullet"><span class="by">personomas</span><span>|</span><a href="#40446921">prev</a><span>|</span><a href="#40446150">next</a><span>|</span><label class="collapse" for="c-40451210">[-]</label><label class="expand" for="c-40451210">[1 more]</label></div><br/><div class="children"><div class="content">S3 _does_ support CAS on <i>copyObject</i> [0].<p>Cloudflare supports CAS on <i>copyObject</i> and on <i>putObject</i> [1]. It doesn&#x27;t support CAS on <i>deleteObject</i>.<p>I don&#x27;t know about the others though (ABS, GCS, Tigris, MinIO).<p><a href="https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;r2&#x2F;api&#x2F;s3&#x2F;extensions&#x2F;#conditional-operations-in-putobject" rel="nofollow">https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;r2&#x2F;api&#x2F;s3&#x2F;extensions&#x2F;#cond...</a><p>[0] <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;API&#x2F;API_CopyObject.html#API_CopyObject_RequestSyntax" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;API&#x2F;API_CopyObje...</a><p>[1] <a href="https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;r2&#x2F;api&#x2F;s3&#x2F;extensions&#x2F;#conditional-operations-in-putobject" rel="nofollow">https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;r2&#x2F;api&#x2F;s3&#x2F;extensions&#x2F;#cond...</a></div><br/></div></div><div id="40446150" class="c"><input type="checkbox" id="c-40446150" checked=""/><div class="controls bullet"><span class="by">laurencerowe</span><span>|</span><a href="#40451210">prev</a><span>|</span><a href="#40449508">next</a><span>|</span><label class="collapse" for="c-40446150">[-]</label><label class="expand" for="c-40446150">[9 more]</label></div><br/><div class="children"><div class="content">The lack of If-Match&#x2F;If-None-Match preconditions in S3 is definitely frustrating.</div><br/><div id="40446928" class="c"><input type="checkbox" id="c-40446928" checked=""/><div class="controls bullet"><span class="by">loevborg</span><span>|</span><a href="#40446150">parent</a><span>|</span><a href="#40448461">next</a><span>|</span><label class="collapse" for="c-40446928">[-]</label><label class="expand" for="c-40446928">[4 more]</label></div><br/><div class="children"><div class="content">This or some other way of CAS would enable so many useful applications, like a simple mutex based on an S3 object.</div><br/><div id="40448505" class="c"><input type="checkbox" id="c-40448505" checked=""/><div class="controls bullet"><span class="by">DaiPlusPlus</span><span>|</span><a href="#40446150">root</a><span>|</span><a href="#40446928">parent</a><span>|</span><a href="#40448461">next</a><span>|</span><label class="collapse" for="c-40448505">[-]</label><label class="expand" for="c-40448505">[3 more]</label></div><br/><div class="children"><div class="content">Content-Addressable-Storage? You can do that yourself: just use the hash of an S3 object as its name, and mark the object as immutable.</div><br/><div id="40448572" class="c"><input type="checkbox" id="c-40448572" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#40446150">root</a><span>|</span><a href="#40448505">parent</a><span>|</span><a href="#40448461">next</a><span>|</span><label class="collapse" for="c-40448572">[-]</label><label class="expand" for="c-40448572">[2 more]</label></div><br/><div class="children"><div class="content">Compare and swap</div><br/><div id="40451353" class="c"><input type="checkbox" id="c-40451353" checked=""/><div class="controls bullet"><span class="by">nathants</span><span>|</span><a href="#40446150">root</a><span>|</span><a href="#40448572">parent</a><span>|</span><a href="#40448461">next</a><span>|</span><label class="collapse" for="c-40451353">[-]</label><label class="expand" for="c-40451353">[1 more]</label></div><br/><div class="children"><div class="content">in an immutable context, cas updates the content hash a named pointer points to.</div><br/></div></div></div></div></div></div></div></div><div id="40448461" class="c"><input type="checkbox" id="c-40448461" checked=""/><div class="controls bullet"><span class="by">wiml</span><span>|</span><a href="#40446150">parent</a><span>|</span><a href="#40446928">prev</a><span>|</span><a href="#40449508">next</a><span>|</span><label class="collapse" for="c-40448461">[-]</label><label class="expand" for="c-40448461">[4 more]</label></div><br/><div class="children"><div class="content">Until recently, S3 had an eventual-consistency model (a given file&#x2F;object would be internally consistent, but different readers would see creations&#x2F;deletions&#x2F;etc in different orders). It&#x27;s favoring availability over consistency.<p>Using file operations for mutexes makes sense in Unix because of the filesystem semantics there but it makes less sense in a distributed object store.</div><br/><div id="40449517" class="c"><input type="checkbox" id="c-40449517" checked=""/><div class="controls bullet"><span class="by">jameshart</span><span>|</span><a href="#40446150">root</a><span>|</span><a href="#40448461">parent</a><span>|</span><a href="#40450044">next</a><span>|</span><label class="collapse" for="c-40449517">[-]</label><label class="expand" for="c-40449517">[2 more]</label></div><br/><div class="children"><div class="content">S3 has had read-after-write strong consistency since 2020, so... yeah, I guess that&#x27;s still &#x27;recently&#x27;, given that S3 existed for 14 years prior to that with eventual consistency.</div><br/><div id="40451385" class="c"><input type="checkbox" id="c-40451385" checked=""/><div class="controls bullet"><span class="by">nathants</span><span>|</span><a href="#40446150">root</a><span>|</span><a href="#40449517">parent</a><span>|</span><a href="#40450044">next</a><span>|</span><label class="collapse" for="c-40451385">[-]</label><label class="expand" for="c-40451385">[1 more]</label></div><br/><div class="children"><div class="content">that was when it rolled out to all regions. prior to that it existed in a single region only. not sure when that initially rolled out.</div><br/></div></div></div></div><div id="40450044" class="c"><input type="checkbox" id="c-40450044" checked=""/><div class="controls bullet"><span class="by">klodolph</span><span>|</span><a href="#40446150">root</a><span>|</span><a href="#40448461">parent</a><span>|</span><a href="#40449517">prev</a><span>|</span><a href="#40449508">next</a><span>|</span><label class="collapse" for="c-40450044">[-]</label><label class="expand" for="c-40450044">[1 more]</label></div><br/><div class="children"><div class="content">CAS (or If-Match, If-None-Match) is something that is atomic but localized to a single key. You don’t have to provide any additional consistency guarantees beyond what S3 already provides. You are providing a couple new atomic operation with the same radius as existing operations—everything is already atomic on a single key, you’re just adding conditions to those operations.</div><br/></div></div></div></div></div></div><div id="40449508" class="c"><input type="checkbox" id="c-40449508" checked=""/><div class="controls bullet"><span class="by">estebarb</span><span>|</span><a href="#40446150">prev</a><span>|</span><a href="#40451208">next</a><span>|</span><label class="collapse" for="c-40449508">[-]</label><label class="expand" for="c-40449508">[7 more]</label></div><br/><div class="children"><div class="content">Append would allow to build a lot of other systems. I mean, the only functional difference between S3 and GFS is append operation. Google build BigTable, Megastore and who knows what more over GFS. You can&#x27;t do the same with S3 (without having to implement the append somewhere else yourself).</div><br/><div id="40449895" class="c"><input type="checkbox" id="c-40449895" checked=""/><div class="controls bullet"><span class="by">klodolph</span><span>|</span><a href="#40449508">parent</a><span>|</span><a href="#40451208">next</a><span>|</span><label class="collapse" for="c-40449895">[-]</label><label class="expand" for="c-40449895">[6 more]</label></div><br/><div class="children"><div class="content">GFS? Google hasn’t used GFS for, like, fifteen years.<p>You can totally build stuff like Megastore or Bigtable (or Spanner) on top of S3. You use a log-structured merge tree. That’s how these systems work in the first place. In the log-structured merge tree, you have a set of files containing your data but you don’t modify them. Instead, you write new files containing the changes (the <i>log</i>). Eventually you compact them by writing a complete copy and deleting the old versions.<p>This works just fine on S3, and there are even some key-value stores built on top of S3 that work this way. Colossus is cheaper for short-lived data.</div><br/><div id="40450355" class="c"><input type="checkbox" id="c-40450355" checked=""/><div class="controls bullet"><span class="by">estebarb</span><span>|</span><a href="#40449508">root</a><span>|</span><a href="#40449895">parent</a><span>|</span><a href="#40450279">next</a><span>|</span><label class="collapse" for="c-40450355">[-]</label><label class="expand" for="c-40450355">[2 more]</label></div><br/><div class="children"><div class="content">I think you missed the point. GFS supported append operations and was created around 24 years ago. S3 still hasn&#x27;t caught up with this particular feature. Although they clearly implemented it, as you can do a long multipart upload and S3 will join the file for you.<p>At a high level, yes, you can implement systems like Megastore or Bigtable over S3. However, there are many details you must take into account. You cannot simply wave away the complexity and potential failure scenarios.<p>For starters, how are you going to create the newest SST?<p>If you keep it in memory or on disk, it must be replicated to prevent data loss if a machine fails. This approach could lead to losing the most recent changes. Additionally, you end up with a hybrid system that needs to read data from multiple sources, which adds complexity. If you essentially reimplement the system, why use S3 at all?<p>What if the data volume gets too low and you end up writing many small, expensive files?<p>Using something like Kinesis for batching might work, but the data won&#x27;t be visible for N minutes.<p>Merging partial tables also requires maintaining an external index to track availability. Transactions would be helpful, but how do you handle failures?<p>And we haven&#x27;t even mentioned managing garbage collection. It would require an external lock or reference count system.</div><br/><div id="40450597" class="c"><input type="checkbox" id="c-40450597" checked=""/><div class="controls bullet"><span class="by">klodolph</span><span>|</span><a href="#40449508">root</a><span>|</span><a href="#40450355">parent</a><span>|</span><a href="#40450279">next</a><span>|</span><label class="collapse" for="c-40450597">[-]</label><label class="expand" for="c-40450597">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think you missed the point.<p>Maybe I am thinking more broadly when imagine what it means to implement something like Spanner on top of S3.<p>We know that Spanner on top of S3 is not going to give you the same price&#x2F;performance as building Spanner on top of Colossus while giving you the same semantics. You either relax the semantics a little bit, you pay out the nose for a lot of little files, or you find a durable place outside S3 to store the newest data.<p>&gt; At a high level, yes, you can implement systems like Megastore or Bigtable over S3. However, there are many details you must take into account. You cannot simply wave away the complexity and potential failure scenarios.<p>Most of the complexity is the same whether you implement Megastore on top of S3 or on top of GFS. You can’t handwave it in either scenario.<p>&gt; If you essentially reimplement the system, why use S3 at all?<p>It’s highly durable, highly available, and cheap (under certain usage scenarios).<p>GFS is not available for anyone to use, inside or outside Google. Its successor, Colossus, is not available outside Google. They’re just not available.</div><br/></div></div></div></div><div id="40450279" class="c"><input type="checkbox" id="c-40450279" checked=""/><div class="controls bullet"><span class="by">dpkirchner</span><span>|</span><a href="#40449508">root</a><span>|</span><a href="#40449895">parent</a><span>|</span><a href="#40450355">prev</a><span>|</span><a href="#40451208">next</a><span>|</span><label class="collapse" for="c-40450279">[-]</label><label class="expand" for="c-40450279">[3 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t used S3: does compacting work within their system, like with an API call, or do you have to download all the chunks, upload the concatenated result, and then delete the chunks?</div><br/><div id="40450607" class="c"><input type="checkbox" id="c-40450607" checked=""/><div class="controls bullet"><span class="by">klodolph</span><span>|</span><a href="#40449508">root</a><span>|</span><a href="#40450279">parent</a><span>|</span><a href="#40451208">next</a><span>|</span><label class="collapse" for="c-40450607">[-]</label><label class="expand" for="c-40450607">[2 more]</label></div><br/><div class="children"><div class="content">Compacting is a database operation. It would happen in your database, not at the underlying storage layer.<p>Your database may use multiple underlying storage layers anyway.</div><br/><div id="40450632" class="c"><input type="checkbox" id="c-40450632" checked=""/><div class="controls bullet"><span class="by">dpkirchner</span><span>|</span><a href="#40449508">root</a><span>|</span><a href="#40450607">parent</a><span>|</span><a href="#40451208">next</a><span>|</span><label class="collapse" for="c-40450632">[-]</label><label class="expand" for="c-40450632">[1 more]</label></div><br/><div class="children"><div class="content">Ah, I guess I misunderstood the part about writing the complete copy. The data isn&#x27;t really <i>written</i>, it&#x27;s just abstracted access to multiple chunks.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40451208" class="c"><input type="checkbox" id="c-40451208" checked=""/><div class="controls bullet"><span class="by">nathants</span><span>|</span><a href="#40449508">prev</a><span>|</span><a href="#40449169">next</a><span>|</span><label class="collapse" for="c-40451208">[-]</label><label class="expand" for="c-40451208">[1 more]</label></div><br/><div class="children"><div class="content">s3 is not perfect, but close enough.<p>the ideal design is to use s3 for immutable objects, then build a similar system on ec2 nvme for mutable&#x2F;ephemeral data.<p>the one i use by default is s4[1].<p>1. <a href="https:&#x2F;&#x2F;github.com&#x2F;nathants&#x2F;s4">https:&#x2F;&#x2F;github.com&#x2F;nathants&#x2F;s4</a></div><br/></div></div><div id="40449169" class="c"><input type="checkbox" id="c-40449169" checked=""/><div class="controls bullet"><span class="by">menacingly</span><span>|</span><a href="#40451208">prev</a><span>|</span><a href="#40446338">next</a><span>|</span><label class="collapse" for="c-40449169">[-]</label><label class="expand" for="c-40449169">[2 more]</label></div><br/><div class="children"><div class="content">Good. This is a part of the stack I want to be boring. I don&#x27;t need innovative features.<p>It&#x27;s the actual federal hate crime that are the egress costs I could do without.</div><br/><div id="40450052" class="c"><input type="checkbox" id="c-40450052" checked=""/><div class="controls bullet"><span class="by">klodolph</span><span>|</span><a href="#40449169">parent</a><span>|</span><a href="#40446338">next</a><span>|</span><label class="collapse" for="c-40450052">[-]</label><label class="expand" for="c-40450052">[1 more]</label></div><br/><div class="children"><div class="content">CAS and multi-region are pretty boring. I’d go as far as to say they’re not even innovative.</div><br/></div></div></div></div><div id="40446338" class="c"><input type="checkbox" id="c-40446338" checked=""/><div class="controls bullet"><span class="by">watermelon0</span><span>|</span><a href="#40449169">prev</a><span>|</span><a href="#40447525">next</a><span>|</span><label class="collapse" for="c-40446338">[-]</label><label class="expand" for="c-40446338">[5 more]</label></div><br/><div class="children"><div class="content">&gt; S3 doesn’t have dual-region or multi-region buckets<p>This is true, but S3 does support replication (including deletion markers), and even 2-way replication, between two regions. Definitely not the same thing as a dual-region bucket, but it can satisfy many use cases where dual-region bucket would be used otherwise.<p><a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;replication.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;replic...</a></div><br/><div id="40448975" class="c"><input type="checkbox" id="c-40448975" checked=""/><div class="controls bullet"><span class="by">deanCommie</span><span>|</span><a href="#40446338">parent</a><span>|</span><a href="#40446468">next</a><span>|</span><label class="collapse" for="c-40448975">[-]</label><label class="expand" for="c-40448975">[1 more]</label></div><br/><div class="children"><div class="content">It can do more than 2.<p>Also you can then create a single multi-region endpoint for those so I don&#x27;t know why this person says it doesn&#x27;t exist: <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;MultiRegionAccessPoints.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;MultiR...</a></div><br/></div></div><div id="40446468" class="c"><input type="checkbox" id="c-40446468" checked=""/><div class="controls bullet"><span class="by">beastman82</span><span>|</span><a href="#40446338">parent</a><span>|</span><a href="#40448975">prev</a><span>|</span><a href="#40447525">next</a><span>|</span><label class="collapse" for="c-40446468">[-]</label><label class="expand" for="c-40446468">[3 more]</label></div><br/><div class="children"><div class="content">think it costs 1 or 2 cents&#x2F;GB depending on region</div><br/><div id="40447458" class="c"><input type="checkbox" id="c-40447458" checked=""/><div class="controls bullet"><span class="by">szundi</span><span>|</span><a href="#40446338">root</a><span>|</span><a href="#40446468">parent</a><span>|</span><a href="#40447525">next</a><span>|</span><label class="collapse" for="c-40447458">[-]</label><label class="expand" for="c-40447458">[2 more]</label></div><br/><div class="children"><div class="content">Multi region pricing probably would be higher anyway</div><br/><div id="40450207" class="c"><input type="checkbox" id="c-40450207" checked=""/><div class="controls bullet"><span class="by">klodolph</span><span>|</span><a href="#40446338">root</a><span>|</span><a href="#40447458">parent</a><span>|</span><a href="#40447525">next</a><span>|</span><label class="collapse" for="c-40450207">[-]</label><label class="expand" for="c-40450207">[1 more]</label></div><br/><div class="children"><div class="content">One two-region bucket would be cheaper than two one-region buckets. I’ve done analyses of similar systems and calculated the costs necessary.<p>You pay for durability and availability in the form of disk overhead, CPU, and network. Each encoding scheme has some expected cost. If your overhead for one-region is $X per gigabyte, then generally speaking, the overhead for two-region is going to be less than $2X—each region is more durable + available because of the copy stored in the other region.</div><br/></div></div></div></div></div></div></div></div><div id="40447525" class="c"><input type="checkbox" id="c-40447525" checked=""/><div class="controls bullet"><span class="by">pryz</span><span>|</span><a href="#40446338">prev</a><span>|</span><a href="#40449809">next</a><span>|</span><label class="collapse" for="c-40447525">[-]</label><label class="expand" for="c-40447525">[3 more]</label></div><br/><div class="children"><div class="content">&gt; By embracing DynamoDB as your metadata layer, systems stand to gain a lot.<p>Yes yes yes. However, DynamoDB can be expensive very quickly :]</div><br/><div id="40447899" class="c"><input type="checkbox" id="c-40447899" checked=""/><div class="controls bullet"><span class="by">kennu</span><span>|</span><a href="#40447525">parent</a><span>|</span><a href="#40449809">next</a><span>|</span><label class="collapse" for="c-40447899">[-]</label><label class="expand" for="c-40447899">[2 more]</label></div><br/><div class="children"><div class="content">Interestingly, DynamoDB is cheaper than S3 though, compared by number of requests. DynamoDB costs $1.25 per million write request units and $0.25 per million read request units. While S3 is $5 per million PUT requests and $0.4 per million GET requests.</div><br/><div id="40450851" class="c"><input type="checkbox" id="c-40450851" checked=""/><div class="controls bullet"><span class="by">Skinney</span><span>|</span><a href="#40447525">root</a><span>|</span><a href="#40447899">parent</a><span>|</span><a href="#40449809">next</a><span>|</span><label class="collapse" for="c-40450851">[-]</label><label class="expand" for="c-40450851">[1 more]</label></div><br/><div class="children"><div class="content">Keep in mind that a write capacity unit in DDB is capped to 1kb. Writing a 10kb file to DDB? That&#x27;s 10 write capacity units.</div><br/></div></div></div></div></div></div><div id="40449809" class="c"><input type="checkbox" id="c-40449809" checked=""/><div class="controls bullet"><span class="by">niuzeta</span><span>|</span><a href="#40447525">prev</a><span>|</span><a href="#40449702">next</a><span>|</span><label class="collapse" for="c-40449809">[-]</label><label class="expand" for="c-40449809">[1 more]</label></div><br/><div class="children"><div class="content">This is perfectly fine. S3 is simple and stable, and that&#x27;s their selling point. There&#x27;s no competition to the history and the proven stability rather than chasing shiny features.</div><br/></div></div><div id="40449702" class="c"><input type="checkbox" id="c-40449702" checked=""/><div class="controls bullet"><span class="by">mythz</span><span>|</span><a href="#40449809">prev</a><span>|</span><a href="#40446689">next</a><span>|</span><label class="collapse" for="c-40449702">[-]</label><label class="expand" for="c-40449702">[1 more]</label></div><br/><div class="children"><div class="content">S3 does simple, reliable object storage well. If anything its draconian pricing model for charging exuberant pricing for bandwidth is showing its age and why we&#x27;ve moved to Cloudflare R2 for their zero egress fees.<p>Being able to reuse the s3 command-line and existing S3 libraries has made the migration painless, so I&#x27;m thankful they&#x27;ve created a defacto standard that other S3 compatible object storage providers can implement.</div><br/></div></div><div id="40446689" class="c"><input type="checkbox" id="c-40446689" checked=""/><div class="controls bullet"><span class="by">chucke1992</span><span>|</span><a href="#40449702">prev</a><span>|</span><a href="#40446529">next</a><span>|</span><label class="collapse" for="c-40446689">[-]</label><label class="expand" for="c-40446689">[3 more]</label></div><br/><div class="children"><div class="content">How is S3 right now in comparison to the Azure Storage Account?</div><br/><div id="40446867" class="c"><input type="checkbox" id="c-40446867" checked=""/><div class="controls bullet"><span class="by">andrewguenther</span><span>|</span><a href="#40446689">parent</a><span>|</span><a href="#40446529">next</a><span>|</span><label class="collapse" for="c-40446867">[-]</label><label class="expand" for="c-40446867">[2 more]</label></div><br/><div class="children"><div class="content">Azure Storage Accounts have major problems with key partitioning that you have to be aware of at the application level that S3 has no problem with. Additionally, Azure Storage accounts have bandwidth throttle limits that can force you to shard across multiple accounts which is pretty painful. Azure SDKs outside of C# and Java are also not well supported in my experience.</div><br/><div id="40449011" class="c"><input type="checkbox" id="c-40449011" checked=""/><div class="controls bullet"><span class="by">mcaravey</span><span>|</span><a href="#40446689">root</a><span>|</span><a href="#40446867">parent</a><span>|</span><a href="#40446529">next</a><span>|</span><label class="collapse" for="c-40449011">[-]</label><label class="expand" for="c-40449011">[1 more]</label></div><br/><div class="children"><div class="content">I would consider the documented performance targets [0] for a standard Azure Blob account to be very good. We&#x27;re talking 60 Gbps in&#x2F;120 Gbps out, with 20,000 requests per second as the default request rate.<p>From what I can tell, the S3 request rate is about 9,000 requests per second [1] split between reads and writes for a single partition. From my perspective it really just depends on what you&#x27;re trying to build but I don&#x27;t see the performance of Azure Storage as being an issue in any way for a typical application.<p>Partitioning will also depend heavily on what kind of application you&#x27;re building, but the documentation does point out that load balancing will kick in once it starts to see a lot of traffic on a partition [2]. Since you have to use partitioning for S3 in order to get better performance, I don&#x27;t really see how that&#x27;s a point against Azure.<p>As for SDKs [3] I have no idea how good support is, but they all have commits within the last day.<p>[0] <a href="https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;azure&#x2F;storage&#x2F;common&#x2F;scalability-targets-standard-account#scale-targets-for-standard-storage-accounts" rel="nofollow">https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;azure&#x2F;storage&#x2F;common&#x2F;scala...</a><p>[1] <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;optimizing-performance.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;optimi...</a><p>[2] <a href="https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;azure&#x2F;storage&#x2F;blobs&#x2F;storage-performance-checklist#partitioning" rel="nofollow">https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;azure&#x2F;storage&#x2F;blobs&#x2F;storag...</a><p>[3] <a href="https:&#x2F;&#x2F;azure.microsoft.com&#x2F;en-us&#x2F;downloads&#x2F;" rel="nofollow">https:&#x2F;&#x2F;azure.microsoft.com&#x2F;en-us&#x2F;downloads&#x2F;</a></div><br/></div></div></div></div></div></div><div id="40446529" class="c"><input type="checkbox" id="c-40446529" checked=""/><div class="controls bullet"><span class="by">miniman1337</span><span>|</span><a href="#40446689">prev</a><span>|</span><a href="#40445981">next</a><span>|</span><label class="collapse" for="c-40446529">[-]</label><label class="expand" for="c-40446529">[1 more]</label></div><br/><div class="children"><div class="content">S3 Object Lambda solves a lot of these &quot;problems&quot; with this design</div><br/></div></div><div id="40445981" class="c"><input type="checkbox" id="c-40445981" checked=""/><div class="controls bullet"><span class="by">fred_is_fred</span><span>|</span><a href="#40446529">prev</a><span>|</span><a href="#40451872">next</a><span>|</span><label class="collapse" for="c-40445981">[-]</label><label class="expand" for="c-40445981">[4 more]</label></div><br/><div class="children"><div class="content">The title should have been &quot;S3 is missing features others have&quot;. There are no references that I saw to &quot;Product age&quot; causing his concerns.</div><br/><div id="40446231" class="c"><input type="checkbox" id="c-40446231" checked=""/><div class="controls bullet"><span class="by">vrosas</span><span>|</span><a href="#40445981">parent</a><span>|</span><a href="#40451872">next</a><span>|</span><label class="collapse" for="c-40446231">[-]</label><label class="expand" for="c-40446231">[3 more]</label></div><br/><div class="children"><div class="content">You could argue that the reticence to add features to your service due to the the sheer complexity, time commitment, or flat out unwillingness to not upset the apple cart is a sign of age.</div><br/><div id="40447384" class="c"><input type="checkbox" id="c-40447384" checked=""/><div class="controls bullet"><span class="by">andyferris</span><span>|</span><a href="#40445981">root</a><span>|</span><a href="#40446231">parent</a><span>|</span><a href="#40447005">next</a><span>|</span><label class="collapse" for="c-40447384">[-]</label><label class="expand" for="c-40447384">[1 more]</label></div><br/><div class="children"><div class="content">I personally doubt age has much to do with it. Consider Windows - how old is it now? MS are adding crazy new features on top now more than ever.</div><br/></div></div><div id="40447005" class="c"><input type="checkbox" id="c-40447005" checked=""/><div class="controls bullet"><span class="by">bigstrat2003</span><span>|</span><a href="#40445981">root</a><span>|</span><a href="#40446231">parent</a><span>|</span><a href="#40447384">prev</a><span>|</span><a href="#40451872">next</a><span>|</span><label class="collapse" for="c-40447005">[-]</label><label class="expand" for="c-40447005">[1 more]</label></div><br/><div class="children"><div class="content">I would argue it doesn&#x27;t have much to do with age, but rather with market dominance. If you are the top dog you don&#x27;t need to fight for users by implementing various features.</div><br/></div></div></div></div></div></div><div id="40451872" class="c"><input type="checkbox" id="c-40451872" checked=""/><div class="controls bullet"><span class="by">brcmthrowaway</span><span>|</span><a href="#40445981">prev</a><span>|</span><a href="#40448256">next</a><span>|</span><label class="collapse" for="c-40451872">[-]</label><label class="expand" for="c-40451872">[1 more]</label></div><br/><div class="children"><div class="content">How is s3 implemented?<p>Is there a data center with many solid state disks?<p>Are tape drives used?</div><br/></div></div><div id="40448256" class="c"><input type="checkbox" id="c-40448256" checked=""/><div class="controls bullet"><span class="by">Lucasoato</span><span>|</span><a href="#40451872">prev</a><span>|</span><a href="#40451091">next</a><span>|</span><label class="collapse" for="c-40448256">[-]</label><label class="expand" for="c-40448256">[1 more]</label></div><br/><div class="children"><div class="content">One feature that I definitely miss is the lack of a strongly consistent putIfAbsent API. A lot of big data table formats like Delta.io would benefit so much from it, right now you need to work around it by connecting to DynamoDB :&#x2F;</div><br/></div></div><div id="40451091" class="c"><input type="checkbox" id="c-40451091" checked=""/><div class="controls bullet"><span class="by">esteer</span><span>|</span><a href="#40448256">prev</a><span>|</span><a href="#40447386">next</a><span>|</span><label class="collapse" for="c-40451091">[-]</label><label class="expand" for="c-40451091">[1 more]</label></div><br/><div class="children"><div class="content">That is a very cool name for a blog.</div><br/></div></div><div id="40447386" class="c"><input type="checkbox" id="c-40447386" checked=""/><div class="controls bullet"><span class="by">someguy4242</span><span>|</span><a href="#40451091">prev</a><span>|</span><a href="#40450204">next</a><span>|</span><label class="collapse" for="c-40447386">[-]</label><label class="expand" for="c-40447386">[3 more]</label></div><br/><div class="children"><div class="content">Can anybody clarify how the author proposed two phase commit&#x2F;write with DDB and S3?</div><br/><div id="40448312" class="c"><input type="checkbox" id="c-40448312" checked=""/><div class="controls bullet"><span class="by">paulgb</span><span>|</span><a href="#40447386">parent</a><span>|</span><a href="#40447650">next</a><span>|</span><label class="collapse" for="c-40448312">[-]</label><label class="expand" for="c-40448312">[1 more]</label></div><br/><div class="children"><div class="content">Assuming you want to write to dest_path with put-if-absent semantics, here&#x27;s a sketch:<p>- Write to a unique temporary path (call this temp_path)<p>- Commit a record to DynamoDB with put-if-absent semantics on the key (dest_path) and the value (temp_path, &quot;incomplete&quot;)<p>- Three possible outcomes:<p>1. Your write succeeded; proceed to issue a CopyObject call from temp_path to dest_path and if successful mark as complete in DynamoDB.<p>2. The row already existed in DynamoDB as &quot;complete&quot; -&gt; do nothing<p>3. The row already existed in DynamoDB as &quot;incomplete&quot; -&gt; another write has been committed, but is not complete; attempt to repair it by issuing a CopyObject for the path in DynamoDB. On success, mark as complete in DynamoDB. (&quot;repair&quot; step)<p>Reads could also hit DynamoDB before S3 in order to perform the &quot;repair&quot; step if applicable.</div><br/></div></div><div id="40447650" class="c"><input type="checkbox" id="c-40447650" checked=""/><div class="controls bullet"><span class="by">nvartolomei</span><span>|</span><a href="#40447386">parent</a><span>|</span><a href="#40448312">prev</a><span>|</span><a href="#40450204">next</a><span>|</span><label class="collapse" for="c-40447650">[-]</label><label class="expand" for="c-40447650">[1 more]</label></div><br/><div class="children"><div class="content">Example: <a href="https:&#x2F;&#x2F;delta.io&#x2F;blog&#x2F;2022-05-18-multi-cluster-writes-to-delta-lake-storage-in-s3&#x2F;" rel="nofollow">https:&#x2F;&#x2F;delta.io&#x2F;blog&#x2F;2022-05-18-multi-cluster-writes-to-del...</a></div><br/></div></div></div></div><div id="40450204" class="c"><input type="checkbox" id="c-40450204" checked=""/><div class="controls bullet"><span class="by">robertclaus</span><span>|</span><a href="#40447386">prev</a><span>|</span><a href="#40447155">next</a><span>|</span><label class="collapse" for="c-40450204">[-]</label><label class="expand" for="c-40450204">[1 more]</label></div><br/><div class="children"><div class="content">It feels like the S3 Team has managed to avoid chasing the marginal user with features. A great example of restraint. It does beg the question of whether the system could be improved in other areas like optimizations to reduce price.</div><br/></div></div><div id="40447155" class="c"><input type="checkbox" id="c-40447155" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#40450204">prev</a><span>|</span><a href="#40449872">next</a><span>|</span><label class="collapse" for="c-40447155">[-]</label><label class="expand" for="c-40447155">[1 more]</label></div><br/><div class="children"><div class="content">&gt; By embracing DynamoDB as your metadata layer, systems stand to gain a lot.<p>I just implemented a &quot;posix-like&quot; filesystem on top of it.  Which means large object offload to s3 is not a problem or even an &quot;ugly abstraction.&quot;  In fact it looks quite natural once you get down to the layer that does this.<p>You also get something like regular file locks which extend to s3 objects,  and if you&#x27;re using cognito,  you can simplify your permissions management and run it all through the file system as well.</div><br/></div></div><div id="40449872" class="c"><input type="checkbox" id="c-40449872" checked=""/><div class="controls bullet"><span class="by">jonstewart</span><span>|</span><a href="#40447155">prev</a><span>|</span><a href="#40447875">next</a><span>|</span><label class="collapse" for="c-40449872">[-]</label><label class="expand" for="c-40449872">[1 more]</label></div><br/><div class="children"><div class="content">When I have a problem figuring something out with S3, I slide into my shared slack channel with my AWS account rep and solutions engineers and ask them for help, and they help. Is this a feature other cloud storage providers have?<p>(But this rarely happens with S3, because it&#x27;s so simple.)</div><br/></div></div><div id="40446980" class="c"><input type="checkbox" id="c-40446980" checked=""/><div class="controls bullet"><span class="by">AtlasBarfed</span><span>|</span><a href="#40447875">prev</a><span>|</span><a href="#40449911">next</a><span>|</span><label class="collapse" for="c-40446980">[-]</label><label class="expand" for="c-40446980">[5 more]</label></div><br/><div class="children"><div class="content">The biggest problem is the cost.<p>Actual storage cost is &quot;meh&quot; but...<p>My god the absolute highway robbery of the bandwidth costs.</div><br/><div id="40447683" class="c"><input type="checkbox" id="c-40447683" checked=""/><div class="controls bullet"><span class="by">mjhay</span><span>|</span><a href="#40446980">parent</a><span>|</span><a href="#40448981">next</a><span>|</span><label class="collapse" for="c-40447683">[-]</label><label class="expand" for="c-40447683">[1 more]</label></div><br/><div class="children"><div class="content">Amazon&#x27;s profit margins on data transfer are out of this world, like probably &gt; 80%. Data transfer costs are hard and confusing to predict (especially with different regions, etc), so it makes sense they&#x27;d gouge on it more than storage.<p><a href="https:&#x2F;&#x2F;www.cnbc.com&#x2F;2021&#x2F;09&#x2F;05&#x2F;how-amazon-web-services-makes-money-estimated-margins-by-service.html" rel="nofollow">https:&#x2F;&#x2F;www.cnbc.com&#x2F;2021&#x2F;09&#x2F;05&#x2F;how-amazon-web-services-make...</a></div><br/></div></div><div id="40448981" class="c"><input type="checkbox" id="c-40448981" checked=""/><div class="controls bullet"><span class="by">cageface</span><span>|</span><a href="#40446980">parent</a><span>|</span><a href="#40447683">prev</a><span>|</span><a href="#40449911">next</a><span>|</span><label class="collapse" for="c-40448981">[-]</label><label class="expand" for="c-40448981">[3 more]</label></div><br/><div class="children"><div class="content">Cloudflare R2 has an S3 compatible API and no egress costs.</div><br/><div id="40450045" class="c"><input type="checkbox" id="c-40450045" checked=""/><div class="controls bullet"><span class="by">beeeeerp</span><span>|</span><a href="#40446980">root</a><span>|</span><a href="#40448981">parent</a><span>|</span><a href="#40449911">next</a><span>|</span><label class="collapse" for="c-40450045">[-]</label><label class="expand" for="c-40450045">[2 more]</label></div><br/><div class="children"><div class="content">I like Cloudflare, but this is also what makes me skeptical. There&#x27;s no such thing as a free lunch, and I&#x27;ve had the rug pulled out from underneath me many times before. I wish they at least charged a sustainable amount for egress, because I feel like it&#x27;s coming eventually.</div><br/><div id="40450171" class="c"><input type="checkbox" id="c-40450171" checked=""/><div class="controls bullet"><span class="by">cageface</span><span>|</span><a href="#40446980">root</a><span>|</span><a href="#40450045">parent</a><span>|</span><a href="#40449911">next</a><span>|</span><label class="collapse" for="c-40450171">[-]</label><label class="expand" for="c-40450171">[1 more]</label></div><br/><div class="children"><div class="content">Yeah you do have to wonder if this is destined for enshittification at some point. It does seem a bit to good to be true.</div><br/></div></div></div></div></div></div></div></div><div id="40449911" class="c"><input type="checkbox" id="c-40449911" checked=""/><div class="controls bullet"><span class="by">at_a_remove</span><span>|</span><a href="#40446980">prev</a><span>|</span><label class="collapse" for="c-40449911">[-]</label><label class="expand" for="c-40449911">[1 more]</label></div><br/><div class="children"><div class="content">I suppose that means I have to learn it now.  I&#x27;m about half-joking: I&#x27;ve deliberately sought to limit myself to tech further on in the hype cycle.</div><br/></div></div></div></div></div></div></div></body></html>