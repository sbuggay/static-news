<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1717491672767" as="style"/><link rel="stylesheet" href="styles.css?v=1717491672767"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2405.20233">Grokfast: Accelerated Grokking by Amplifying Slow Gradients</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>johnsutor</span> | <span>30 comments</span></div><br/><div><div id="40567799" class="c"><input type="checkbox" id="c-40567799" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#40567744">next</a><span>|</span><label class="collapse" for="c-40567799">[-]</label><label class="expand" for="c-40567799">[6 more]</label></div><br/><div class="children"><div class="content">I missed the beginning of the story. Why and when does grokking occur? It seems to be a case of reaching a new basin, casting doubt on the shallow basin hypothesis in over-parameterized neural networks? The last I checked all the extrema in such models were supposed to be good, and easy to reach?</div><br/><div id="40569223" class="c"><input type="checkbox" id="c-40569223" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40567799">parent</a><span>|</span><a href="#40568693">next</a><span>|</span><label class="collapse" for="c-40569223">[-]</label><label class="expand" for="c-40569223">[4 more]</label></div><br/><div class="children"><div class="content">i&#x27;ve worked in this field for 6 years and have never heard of the &#x27;shallow basin hypothesis&#x27;, care to explain more? is it just the idea that there are many good solutions that can be reached in very different parts of parameter space?<p>all that grokking really means is that the &#x27;correct&#x27;, generalizable solution is often simpler than the overfit &#x27;memorize all the datapoints&#x27; solution, so if you apply some sort of regularization to a model that you overfit, the regularization will make the memorized solution unstable and you will eventually tunnel over to the &#x27;correct&#x27; solution<p>actual DNNs nowadays are usually not obviously overfit because they are trained on only one epoch</div><br/><div id="40569355" class="c"><input type="checkbox" id="c-40569355" checked=""/><div class="controls bullet"><span class="by">dontwearitout</span><span>|</span><a href="#40567799">root</a><span>|</span><a href="#40569223">parent</a><span>|</span><a href="#40568693">next</a><span>|</span><label class="collapse" for="c-40569355">[-]</label><label class="expand" for="c-40569355">[3 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t heard the term &quot;shallow basin hypothesis&quot; but I know what it refers to, these two papers spring to mind for me:<p>1) Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1802.10026" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1802.10026</a><p>2) Visualizing the Loss Landscape of Neural Nets <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1712.09913" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1712.09913</a><p>There&#x27;s also a very interesting body of work on merging trained models, such as by interpolating between points in weight space, which relates to the concept of &quot;basins&quot; of similar solutions. Skim the intro of this if you&#x27;re interested in learning more: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.08403" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.08403</a></div><br/><div id="40570694" class="c"><input type="checkbox" id="c-40570694" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#40567799">root</a><span>|</span><a href="#40569355">parent</a><span>|</span><a href="#40569394">next</a><span>|</span><label class="collapse" for="c-40570694">[-]</label><label class="expand" for="c-40570694">[1 more]</label></div><br/><div class="children"><div class="content">Yes, you both understood what I meant. I just coined the term, having in mind illustrations like Fig. 1 in <i>Low-Pass Filtering SGD for Recovering Flat Optima in the Deep Learning Optimization Landscape</i> (<a href="https:&#x2F;&#x2F;proceedings.mlr.press&#x2F;v151&#x2F;bisla22a.html" rel="nofollow">https:&#x2F;&#x2F;proceedings.mlr.press&#x2F;v151&#x2F;bisla22a.html</a>)<p>Reviewing the literature, I see the concept is more commonly referred to as &quot;flat&#x2F;wide minima&quot;; e.g., <a href="https:&#x2F;&#x2F;www.pnas.org&#x2F;doi&#x2F;10.1073&#x2F;pnas.1908636117" rel="nofollow">https:&#x2F;&#x2F;www.pnas.org&#x2F;doi&#x2F;10.1073&#x2F;pnas.1908636117</a></div><br/></div></div><div id="40569394" class="c"><input type="checkbox" id="c-40569394" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40567799">root</a><span>|</span><a href="#40569355">parent</a><span>|</span><a href="#40570694">prev</a><span>|</span><a href="#40568693">next</a><span>|</span><label class="collapse" for="c-40569394">[-]</label><label class="expand" for="c-40569394">[1 more]</label></div><br/><div class="children"><div class="content">cheers! i&#x27;m familiar with those first two papers, just not with the specific term. my intuition was more relatively deep points connected by tunnels than shallow basin - but it might just be the difficulty of describing high dimensional spaces</div><br/></div></div></div></div></div></div><div id="40568693" class="c"><input type="checkbox" id="c-40568693" checked=""/><div class="controls bullet"><span class="by">killerstorm</span><span>|</span><a href="#40567799">parent</a><span>|</span><a href="#40569223">prev</a><span>|</span><a href="#40567744">next</a><span>|</span><label class="collapse" for="c-40568693">[-]</label><label class="expand" for="c-40568693">[1 more]</label></div><br/><div class="children"><div class="content">IIRC it was observed in a training mode with weight decay. Perhaps a basin with proper generalization is more stable.</div><br/></div></div></div></div><div id="40567744" class="c"><input type="checkbox" id="c-40567744" checked=""/><div class="controls bullet"><span class="by">svara</span><span>|</span><a href="#40567799">prev</a><span>|</span><a href="#40569566">next</a><span>|</span><label class="collapse" for="c-40567744">[-]</label><label class="expand" for="c-40567744">[8 more]</label></div><br/><div class="children"><div class="content">Grokking is certainly an interesting phenomenon, but have practical applications of it been discovered yet?<p>I remember seeing grokking demonstrated for MNIST (are there any other non synthetic datasets for which it has been shown?), but the authors of that paper had to make the training data smaller and got a test error far below state of the art.<p>I&#x27;m very interested in this research, just curious about how practically relevant it is (yet).</div><br/><div id="40567887" class="c"><input type="checkbox" id="c-40567887" checked=""/><div class="controls bullet"><span class="by">fwlr</span><span>|</span><a href="#40567744">parent</a><span>|</span><a href="#40569174">next</a><span>|</span><label class="collapse" for="c-40567887">[-]</label><label class="expand" for="c-40567887">[2 more]</label></div><br/><div class="children"><div class="content">My gut instinct from reading about the phenomenon says that a “grokked” model of X parameters on Y tokens is not going to outperform an “ungrokked” model with 2X parameters on 2Y tokens - since “grokking” uses the same resources as parameter and token scaling, it’s simply not a competitive scaling mechanism at the moment. It might make sense in some applications where some other hard limit (e.g. memory capacity at inference time) occurs before your resource limit AND you would still see good returns on improvements in quality, but I suspect those are still fairly narrow and&#x2F;or rare applications.</div><br/><div id="40571095" class="c"><input type="checkbox" id="c-40571095" checked=""/><div class="controls bullet"><span class="by">joelthelion</span><span>|</span><a href="#40567744">root</a><span>|</span><a href="#40567887">parent</a><span>|</span><a href="#40569174">next</a><span>|</span><label class="collapse" for="c-40571095">[-]</label><label class="expand" for="c-40571095">[1 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t it be super useful in cases where data is limited?</div><br/></div></div></div></div><div id="40569174" class="c"><input type="checkbox" id="c-40569174" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40567744">parent</a><span>|</span><a href="#40567887">prev</a><span>|</span><a href="#40568695">next</a><span>|</span><label class="collapse" for="c-40569174">[-]</label><label class="expand" for="c-40569174">[1 more]</label></div><br/><div class="children"><div class="content">grokking doesn&#x27;t and will not have practical uses, imo - it is just an experiment that revealed cool things that we mostly already suspected about implicit regularization<p>however, techniques we learn from grokking about implicit regularization might be helpful for the training regimes we actually use</div><br/></div></div><div id="40568695" class="c"><input type="checkbox" id="c-40568695" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#40567744">parent</a><span>|</span><a href="#40569174">prev</a><span>|</span><a href="#40569566">next</a><span>|</span><label class="collapse" for="c-40568695">[-]</label><label class="expand" for="c-40568695">[4 more]</label></div><br/><div class="children"><div class="content">Nobody is really looking for practical applications for it, and you shouldn&#x27;t necessarily expect them from this kind of academic research.</div><br/><div id="40569287" class="c"><input type="checkbox" id="c-40569287" checked=""/><div class="controls bullet"><span class="by">svara</span><span>|</span><a href="#40567744">root</a><span>|</span><a href="#40568695">parent</a><span>|</span><a href="#40569566">next</a><span>|</span><label class="collapse" for="c-40569287">[-]</label><label class="expand" for="c-40569287">[3 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t sound right at all.<p>Improving generalization in deep learning is a big deal. The phenomenon is academically interesting either way, but e.g. making sota nets more training data economical seems like a practical result that might be entirely within reach.</div><br/><div id="40569345" class="c"><input type="checkbox" id="c-40569345" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40567744">root</a><span>|</span><a href="#40569287">parent</a><span>|</span><a href="#40569566">next</a><span>|</span><label class="collapse" for="c-40569345">[-]</label><label class="expand" for="c-40569345">[2 more]</label></div><br/><div class="children"><div class="content">i think y&#x27;all are both right. grokking is a phenomenon that by definition applies to severely overfit neural networks, which is a very different regime than modern ML - but we might learn something from this that we can use to improve regularization</div><br/><div id="40570359" class="c"><input type="checkbox" id="c-40570359" checked=""/><div class="controls bullet"><span class="by">barfbagginus</span><span>|</span><a href="#40567744">root</a><span>|</span><a href="#40569345">parent</a><span>|</span><a href="#40569566">next</a><span>|</span><label class="collapse" for="c-40570359">[-]</label><label class="expand" for="c-40570359">[1 more]</label></div><br/><div class="children"><div class="content">Looks like grokking could give better reasoning and generalization to LLMs, but I&#x27;m not sure how practical it would be to overfit a larger LLM<p>See:
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.15071" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.15071</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="40569566" class="c"><input type="checkbox" id="c-40569566" checked=""/><div class="controls bullet"><span class="by">curious_cat_163</span><span>|</span><a href="#40567744">prev</a><span>|</span><a href="#40567854">next</a><span>|</span><label class="collapse" for="c-40569566">[-]</label><label class="expand" for="c-40569566">[1 more]</label></div><br/><div class="children"><div class="content">Cute! The signal processing folks have entered the room... :)</div><br/></div></div><div id="40567854" class="c"><input type="checkbox" id="c-40567854" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#40569566">prev</a><span>|</span><label class="collapse" for="c-40567854">[-]</label><label class="expand" for="c-40567854">[14 more]</label></div><br/><div class="children"><div class="content">Why only MNIST and a Graph CNN? Those are small and somewhat odd choices. Scale these days should be at least 100 million param models and something like OpenWebText as a dataset in my opinion. Not sure what the SoTA is for visionm but same argument there.</div><br/><div id="40568025" class="c"><input type="checkbox" id="c-40568025" checked=""/><div class="controls bullet"><span class="by">dzdt</span><span>|</span><a href="#40567854">parent</a><span>|</span><a href="#40569514">next</a><span>|</span><label class="collapse" for="c-40568025">[-]</label><label class="expand" for="c-40568025">[9 more]</label></div><br/><div class="children"><div class="content">This paper is from a small group at an academic institution. They are trying to innovate in the idea space and are probably quite compute constrained. But for proving ideas smaller problems can make easier analysis even leaving aside compute resources. Not all research can jump straight to SOTA applications. It looks quite interesting, and I wouldn&#x27;t be surprised to see it applied soon to larger problems.</div><br/><div id="40568502" class="c"><input type="checkbox" id="c-40568502" checked=""/><div class="controls bullet"><span class="by">krasin</span><span>|</span><a href="#40567854">root</a><span>|</span><a href="#40568025">parent</a><span>|</span><a href="#40568441">next</a><span>|</span><label class="collapse" for="c-40568502">[-]</label><label class="expand" for="c-40568502">[3 more]</label></div><br/><div class="children"><div class="content">&gt; They are trying to innovate in the idea space and are probably quite compute constrained.<p>Training a GPT-2 sized model costs ~$20 nowadays in respect to compute: <a href="https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;llm.c&#x2F;discussions&#x2F;481">https:&#x2F;&#x2F;github.com&#x2F;karpathy&#x2F;llm.c&#x2F;discussions&#x2F;481</a></div><br/><div id="40571715" class="c"><input type="checkbox" id="c-40571715" checked=""/><div class="controls bullet"><span class="by">olaulaja</span><span>|</span><a href="#40567854">root</a><span>|</span><a href="#40568502">parent</a><span>|</span><a href="#40571148">next</a><span>|</span><label class="collapse" for="c-40571715">[-]</label><label class="expand" for="c-40571715">[1 more]</label></div><br/><div class="children"><div class="content">Baseline time to grok something looks to be around 1000x normal training time so make that $20k per attempt. Probably takes a while too. Their headline number (50x faster than baseline, $400) looks pretty doable if you can make grokking happen reliably at that speed.</div><br/></div></div><div id="40571148" class="c"><input type="checkbox" id="c-40571148" checked=""/><div class="controls bullet"><span class="by">orlp</span><span>|</span><a href="#40567854">root</a><span>|</span><a href="#40568502">parent</a><span>|</span><a href="#40571715">prev</a><span>|</span><a href="#40568441">next</a><span>|</span><label class="collapse" for="c-40571148">[-]</label><label class="expand" for="c-40571148">[1 more]</label></div><br/><div class="children"><div class="content">$20 per attempt. A paper typically comes after trying hundreds of things. That said, the final version of your idea could certainly try it.</div><br/></div></div></div></div><div id="40568441" class="c"><input type="checkbox" id="c-40568441" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#40567854">root</a><span>|</span><a href="#40568025">parent</a><span>|</span><a href="#40568502">prev</a><span>|</span><a href="#40569514">next</a><span>|</span><label class="collapse" for="c-40568441">[-]</label><label class="expand" for="c-40568441">[5 more]</label></div><br/><div class="children"><div class="content">I’ve been in a small group at an academic institution. With our meager resources we trained larger models than this on many different vision problems. I personally train LLMs on OpenWebText than this using a few 4090s (not work related). Is that too much for a small group?<p>MNIST is solvable using two pixels. It shouldn’t be one of two benchmarks in a paper, again just in my opinion. It’s useful for debugging only.</div><br/><div id="40572028" class="c"><input type="checkbox" id="c-40572028" checked=""/><div class="controls bullet"><span class="by">muskmusk</span><span>|</span><a href="#40567854">root</a><span>|</span><a href="#40568441">parent</a><span>|</span><a href="#40568475">next</a><span>|</span><label class="collapse" for="c-40572028">[-]</label><label class="expand" for="c-40572028">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a free world. Nothing stops you from applying their findings to bigger datasets. It would be a valuable contribution.</div><br/></div></div><div id="40568475" class="c"><input type="checkbox" id="c-40568475" checked=""/><div class="controls bullet"><span class="by">all2</span><span>|</span><a href="#40567854">root</a><span>|</span><a href="#40568441">parent</a><span>|</span><a href="#40572028">prev</a><span>|</span><a href="#40569476">next</a><span>|</span><label class="collapse" for="c-40568475">[-]</label><label class="expand" for="c-40568475">[2 more]</label></div><br/><div class="children"><div class="content">Again, a small academic institution may not have the experience or know-how to know these things.</div><br/><div id="40568501" class="c"><input type="checkbox" id="c-40568501" checked=""/><div class="controls bullet"><span class="by">olnluis</span><span>|</span><a href="#40567854">root</a><span>|</span><a href="#40568475">parent</a><span>|</span><a href="#40569476">next</a><span>|</span><label class="collapse" for="c-40568501">[-]</label><label class="expand" for="c-40568501">[1 more]</label></div><br/><div class="children"><div class="content">I thought so at first, but the repo&#x27;s[0] owner and the first name listed in the article has Seoul National University on their Github profile.
Far away from a small academic institution.<p>[0]: <a href="https:&#x2F;&#x2F;github.com&#x2F;ironjr&#x2F;grokfast">https:&#x2F;&#x2F;github.com&#x2F;ironjr&#x2F;grokfast</a></div><br/></div></div></div></div><div id="40569476" class="c"><input type="checkbox" id="c-40569476" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40567854">root</a><span>|</span><a href="#40568441">parent</a><span>|</span><a href="#40568475">prev</a><span>|</span><a href="#40569514">next</a><span>|</span><label class="collapse" for="c-40569476">[-]</label><label class="expand" for="c-40569476">[1 more]</label></div><br/><div class="children"><div class="content">&gt; MNIST is solvable using two pixels.<p>really? do you have any details?<p>agree it has no business being in a modern paper</div><br/></div></div></div></div></div></div><div id="40569514" class="c"><input type="checkbox" id="c-40569514" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#40567854">parent</a><span>|</span><a href="#40568025">prev</a><span>|</span><a href="#40568800">next</a><span>|</span><label class="collapse" for="c-40569514">[-]</label><label class="expand" for="c-40569514">[1 more]</label></div><br/><div class="children"><div class="content">Grokking may not even occur for datasets of that scale. Even the MNIST experiments require dropping the training data size from 50k examples to 1k. The reason for this is that the phenomenon seems to occur at a critical zone of having just barely enough training data to make generalization possible. See <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2205.10343" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2205.10343</a> for details.<p>Even figuring out how to induce grokking behavior on a 100M model or OpenWebText would be a big leap in the understanding of grokking. It&#x27;s perfectly reasonable for a paper like this to show results on the standard tasks for which grokking has already been characterized.</div><br/></div></div><div id="40568800" class="c"><input type="checkbox" id="c-40568800" checked=""/><div class="controls bullet"><span class="by">QuadmasterXLII</span><span>|</span><a href="#40567854">parent</a><span>|</span><a href="#40569514">prev</a><span>|</span><a href="#40569233">next</a><span>|</span><label class="collapse" for="c-40568800">[-]</label><label class="expand" for="c-40568800">[1 more]</label></div><br/><div class="children"><div class="content">It’s because that’s where the effect is showing upright now. This is the situation where the analogy to pre-paradigmatic optics is pretty strong. If you telescope to take pictures of Jupiter was having problems with rainbow fringes, so you designed the defraction grading to investigate the fringes</div><br/></div></div><div id="40569233" class="c"><input type="checkbox" id="c-40569233" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#40567854">parent</a><span>|</span><a href="#40568800">prev</a><span>|</span><label class="collapse" for="c-40569233">[-]</label><label class="expand" for="c-40569233">[2 more]</label></div><br/><div class="children"><div class="content">i don&#x27;t think grokking has been demonstrated in a large model yet</div><br/><div id="40569452" class="c"><input type="checkbox" id="c-40569452" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#40567854">root</a><span>|</span><a href="#40569233">parent</a><span>|</span><label class="collapse" for="c-40569452">[-]</label><label class="expand" for="c-40569452">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a recent paper here where they&#x27;ve seen in a deeper model.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.19454" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.19454</a><p>It&#x27;s a bit surprising that apparently this hasn&#x27;t been done before - to see how universal of a phenomenon this is.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>