<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="apple-mobile-web-app-capable" content="yes"/><link rel="preload" href="styles.css?v=1682488128755" as="style"/><link rel="stylesheet" href="styles.css?v=1682488128755"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.parand.com/a-completely-non-technical-explanation-of-ai.html">A non-technical explanation of deep learning</a> <span class="domain">(<a href="https://www.parand.com">www.parand.com</a>)</span></div><div class="subtext"><span>tworats</span> | <span>116 comments</span></div><br/><div><div id="35703927" class="c"><input type="checkbox" id="c-35703927" checked=""/><div class="controls bullet"><span class="by">jstx1</span><span>|</span><a href="#35704446">next</a><span>|</span><label class="collapse" for="c-35703927">[-]</label><label class="expand" for="c-35703927">[29 more]</label></div><br/><div class="children"><div class="content">Does stuff like this help anyone?<p>I still haven’t forgiven CGP Grey for changing the title to his 2017 ML video to “How AIs, like ChatGPT, learn”. The video is about genetic algorithms and has nothing to do with ChatGPT. (or with anything else in modern AI)</div><br/><div id="35707045" class="c"><input type="checkbox" id="c-35707045" checked=""/><div class="controls bullet"><span class="by">gnicholas</span><span>|</span><a href="#35703927">parent</a><span>|</span><a href="#35704518">next</a><span>|</span><label class="collapse" for="c-35707045">[-]</label><label class="expand" for="c-35707045">[8 more]</label></div><br/><div class="children"><div class="content">I read this to see if it would be useful to share with my 9 year old. After reading it, I think it is not any more useful (alone) than watching the 3b1b video on this topic. The video is longer, but has more visualizations.<p>I think that perhaps reading this description after watching the video might make the process more memorable. My guess is that if I had my daughter read this first, it wouldn&#x27;t do much to make the video easier to parse. Reading this real-world example after watching the video could help solidify the concept.<p>Disclaimer: I don&#x27;t know a lot about AI&#x2F;ML, so it&#x27;s possible that I am 100% wrong here!</div><br/><div id="35709130" class="c"><input type="checkbox" id="c-35709130" checked=""/><div class="controls bullet"><span class="by">kaycebasques</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707045">parent</a><span>|</span><a href="#35709336">next</a><span>|</span><label class="collapse" for="c-35709130">[-]</label><label class="expand" for="c-35709130">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I think it is not any more useful (alone) than watching the 3b1b video on this topic<p>This one? <a href="https:&#x2F;&#x2F;youtube.com&#x2F;playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">https:&#x2F;&#x2F;youtube.com&#x2F;playlist?list=PLZHQObOWTQDNU6R1_67000Dx_...</a></div><br/><div id="35709629" class="c"><input type="checkbox" id="c-35709629" checked=""/><div class="controls bullet"><span class="by">gnicholas</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35709130">parent</a><span>|</span><a href="#35709336">next</a><span>|</span><label class="collapse" for="c-35709629">[-]</label><label class="expand" for="c-35709629">[1 more]</label></div><br/><div class="children"><div class="content">Yep! I&#x27;ve only watched the first two in the series so far.</div><br/></div></div></div></div><div id="35709336" class="c"><input type="checkbox" id="c-35709336" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707045">parent</a><span>|</span><a href="#35709130">prev</a><span>|</span><a href="#35707878">next</a><span>|</span><label class="collapse" for="c-35709336">[-]</label><label class="expand" for="c-35709336">[3 more]</label></div><br/><div class="children"><div class="content">Sorry if this is a personal question, but why would you get a 9 year old into machine learning ?</div><br/><div id="35709588" class="c"><input type="checkbox" id="c-35709588" checked=""/><div class="controls bullet"><span class="by">gnicholas</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35709336">parent</a><span>|</span><a href="#35709392">next</a><span>|</span><label class="collapse" for="c-35709588">[-]</label><label class="expand" for="c-35709588">[1 more]</label></div><br/><div class="children"><div class="content">Fair question. She&#x27;s very curious about all sorts of things and always wants to know how they work. I also assume she&#x27;ll find out about ChatGPT in the next year or two, at school. I figure she will probably ask me about how chatbots work, whether they are actually smart, etc. So for now I&#x27;ve been keeping an eye out for explainers that would help her understand things as I&#x27;ve been learning myself.<p>Sorry if this is a personal question, but how did you choose your username?</div><br/></div></div><div id="35709392" class="c"><input type="checkbox" id="c-35709392" checked=""/><div class="controls bullet"><span class="by">gibolt</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35709336">parent</a><span>|</span><a href="#35709588">prev</a><span>|</span><a href="#35707878">next</a><span>|</span><label class="collapse" for="c-35709392">[-]</label><label class="expand" for="c-35709392">[1 more]</label></div><br/><div class="children"><div class="content">Why not? Get them into a little bit of everything, and let them dig further into the topics that they find exciting.<p>Kids are just as capable as most adults (if not more). Give them a foot in the door and they have all the time in the world to build in that knowledge.</div><br/></div></div></div></div><div id="35707878" class="c"><input type="checkbox" id="c-35707878" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707045">parent</a><span>|</span><a href="#35709336">prev</a><span>|</span><a href="#35704518">next</a><span>|</span><label class="collapse" for="c-35707878">[-]</label><label class="expand" for="c-35707878">[2 more]</label></div><br/><div class="children"><div class="content">You could just let your daughter see it. To what extent can you &quot;protect&quot; her exposure to the world?</div><br/><div id="35708220" class="c"><input type="checkbox" id="c-35708220" checked=""/><div class="controls bullet"><span class="by">gnicholas</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707878">parent</a><span>|</span><a href="#35704518">next</a><span>|</span><label class="collapse" for="c-35708220">[-]</label><label class="expand" for="c-35708220">[1 more]</label></div><br/><div class="children"><div class="content">Huh? It’s about efficiency and not wasting time on something that’s not very useful. Should she see A and B, both (in what order), or neither? That’s the question.</div><br/></div></div></div></div></div></div><div id="35704518" class="c"><input type="checkbox" id="c-35704518" checked=""/><div class="controls bullet"><span class="by">SnooSux</span><span>|</span><a href="#35703927">parent</a><span>|</span><a href="#35707045">prev</a><span>|</span><a href="#35704402">next</a><span>|</span><label class="collapse" for="c-35704518">[-]</label><label class="expand" for="c-35704518">[13 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve barely forgiven him for explaining genetic algorithms and acting like they have any relevance to contemporary ML research.<p>The footnote video was an alright explanation of backprop. If that were part of the main video that would have been reasonable.<p>I really like his history&#x2F;geography videos but anything technical leave a lot to be desired. And don&#x27;t get me started on Humans Need Not Apply.</div><br/><div id="35704738" class="c"><input type="checkbox" id="c-35704738" checked=""/><div class="controls bullet"><span class="by">jstx1</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35704518">parent</a><span>|</span><a href="#35705744">next</a><span>|</span><label class="collapse" for="c-35704738">[-]</label><label class="expand" for="c-35704738">[11 more]</label></div><br/><div class="children"><div class="content">&gt; And don&#x27;t get me started on Humans Need Not Apply.<p>Well now you have to tell us. :) Many of the concrete examples in that video are exaggerated and&#x2F;or misunderstood but the general question it asks - what to do when automation makes many people unemployable through no fault of their own - seems valid.</div><br/><div id="35707966" class="c"><input type="checkbox" id="c-35707966" checked=""/><div class="controls bullet"><span class="by">musicale</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35704738">parent</a><span>|</span><a href="#35707603">next</a><span>|</span><label class="collapse" for="c-35707966">[-]</label><label class="expand" for="c-35707966">[9 more]</label></div><br/><div class="children"><div class="content">&gt; what to do when automation makes many people unemployable through no fault of their own - seems valid<p>Unfortunately the video doesn&#x27;t answer its own question directly.<p>The answer for the past 40 years or so seems to be &quot;move them to lower-paying service jobs, or out of the job market entirely.&quot;</div><br/><div id="35708289" class="c"><input type="checkbox" id="c-35708289" checked=""/><div class="controls bullet"><span class="by">j33zusjuice</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707966">parent</a><span>|</span><a href="#35708261">next</a><span>|</span><label class="collapse" for="c-35708289">[-]</label><label class="expand" for="c-35708289">[1 more]</label></div><br/><div class="children"><div class="content">I find this discussion fascinating, but YouTube is one of the last places I’d  go for that discussion, unless it’s a debate between two highly-regarded minds on the topic (like Chomsky vs Foucault back in the day). I’m  not very interested in listening to random people tell me their ideas without any good pathways for critiques or questions.</div><br/></div></div><div id="35708261" class="c"><input type="checkbox" id="c-35708261" checked=""/><div class="controls bullet"><span class="by">robotresearcher</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707966">parent</a><span>|</span><a href="#35708289">prev</a><span>|</span><a href="#35707603">next</a><span>|</span><label class="collapse" for="c-35708261">[-]</label><label class="expand" for="c-35708261">[7 more]</label></div><br/><div class="children"><div class="content">Another part of the answer over the last 40 (or 200) years, is to repeatedly create totally new industries that employ lots of people, including a large fraction of HN readers.</div><br/><div id="35708280" class="c"><input type="checkbox" id="c-35708280" checked=""/><div class="controls bullet"><span class="by">ketzo</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35708261">parent</a><span>|</span><a href="#35707603">next</a><span>|</span><label class="collapse" for="c-35708280">[-]</label><label class="expand" for="c-35708280">[6 more]</label></div><br/><div class="children"><div class="content">Yeah, but what does the Venn diagram look like there?<p>Yes, new technologies create new jobs.<p>But it’s not usually the people from the old jobs who are taking those new jobs.</div><br/><div id="35708485" class="c"><input type="checkbox" id="c-35708485" checked=""/><div class="controls bullet"><span class="by">robotresearcher</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35708280">parent</a><span>|</span><a href="#35707603">next</a><span>|</span><label class="collapse" for="c-35708485">[-]</label><label class="expand" for="c-35708485">[5 more]</label></div><br/><div class="children"><div class="content">That can be terribly hard on people, while great for other people. What would you suggest would be better?</div><br/><div id="35708965" class="c"><input type="checkbox" id="c-35708965" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35708485">parent</a><span>|</span><a href="#35708945">next</a><span>|</span><label class="collapse" for="c-35708965">[-]</label><label class="expand" for="c-35708965">[1 more]</label></div><br/><div class="children"><div class="content">A progressive income tax <i>that does not exclude or favor</i> capital income, so that funding ideally targeted transitional assistance, UBI (with a rate ratcheting up with sustained increases in per capita revenue), or, ideally, both so that the adverse effects of labor market shifts which shuffle or concentrate labor demand or shift from labor-intensive to capital-intensive methods are buffered.</div><br/></div></div><div id="35708945" class="c"><input type="checkbox" id="c-35708945" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35708485">parent</a><span>|</span><a href="#35708965">prev</a><span>|</span><a href="#35707603">next</a><span>|</span><label class="collapse" for="c-35708945">[-]</label><label class="expand" for="c-35708945">[3 more]</label></div><br/><div class="children"><div class="content">Tax robots. At a minimum, at the highest income tax rate bracket.</div><br/><div id="35709562" class="c"><input type="checkbox" id="c-35709562" checked=""/><div class="controls bullet"><span class="by">mikewarot</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35708945">parent</a><span>|</span><a href="#35707603">next</a><span>|</span><label class="collapse" for="c-35709562">[-]</label><label class="expand" for="c-35709562">[2 more]</label></div><br/><div class="children"><div class="content">How? What should a Roomba owner have to pay? Or a dishwasher owner? Or someone who has a calculator?<p>Computer used to be a job description, do we all owe?<p>Where would you draw the line?<p>How would you enforce it?</div><br/><div id="35709614" class="c"><input type="checkbox" id="c-35709614" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35709562">parent</a><span>|</span><a href="#35707603">next</a><span>|</span><label class="collapse" for="c-35709614">[-]</label><label class="expand" for="c-35709614">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What should a Roomba owner have to pay?<p>The same amount that someone with a stay-at-home spouse who cleans the house pays.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="35705744" class="c"><input type="checkbox" id="c-35705744" checked=""/><div class="controls bullet"><span class="by">flangola7</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35704518">parent</a><span>|</span><a href="#35704738">prev</a><span>|</span><a href="#35704402">next</a><span>|</span><label class="collapse" for="c-35705744">[-]</label><label class="expand" for="c-35705744">[1 more]</label></div><br/><div class="children"><div class="content">Humans Need Not Apply is one of the most phenomenal videos on YouTube, what do you think is wrong with it?</div><br/></div></div></div></div><div id="35707622" class="c"><input type="checkbox" id="c-35707622" checked=""/><div class="controls bullet"><span class="by">Trufa</span><span>|</span><a href="#35703927">parent</a><span>|</span><a href="#35704402">prev</a><span>|</span><a href="#35704446">next</a><span>|</span><label class="collapse" for="c-35707622">[-]</label><label class="expand" for="c-35707622">[6 more]</label></div><br/><div class="children"><div class="content">What a strange word to use in that context, why would he need to be forgiven by you? How has he wronged you? Seems at worst, an honest mistake in a complicated topic.</div><br/><div id="35707848" class="c"><input type="checkbox" id="c-35707848" checked=""/><div class="controls bullet"><span class="by">Cpoll</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707622">parent</a><span>|</span><a href="#35707673">next</a><span>|</span><label class="collapse" for="c-35707848">[-]</label><label class="expand" for="c-35707848">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re not using &quot;at worst&quot; correctly. What you describe is an &quot;at best&quot;. Worse would be that CGP Grey deliberately picked a misleading title in order to optimize views, algorithm, etc.<p>This is, I think, the case. But I don&#x27;t begrudge them too much, YouTube is cutthroat.</div><br/></div></div><div id="35707673" class="c"><input type="checkbox" id="c-35707673" checked=""/><div class="controls bullet"><span class="by">gregschlom</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707622">parent</a><span>|</span><a href="#35707848">prev</a><span>|</span><a href="#35704446">next</a><span>|</span><label class="collapse" for="c-35707673">[-]</label><label class="expand" for="c-35707673">[4 more]</label></div><br/><div class="children"><div class="content">Maybe GP is a non-native English speaker? This construct would be pretty common way for a native French speaker to say they are angry at something. Not sure if it&#x27;s common in English as well.</div><br/><div id="35707773" class="c"><input type="checkbox" id="c-35707773" checked=""/><div class="controls bullet"><span class="by">mrbombastic</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707673">parent</a><span>|</span><a href="#35704446">next</a><span>|</span><label class="collapse" for="c-35707773">[-]</label><label class="expand" for="c-35707773">[3 more]</label></div><br/><div class="children"><div class="content">This is a pretty common phrase in English as well, it is not meant to be taken literally.</div><br/><div id="35709027" class="c"><input type="checkbox" id="c-35709027" checked=""/><div class="controls bullet"><span class="by">freedomben</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707773">parent</a><span>|</span><a href="#35707936">next</a><span>|</span><label class="collapse" for="c-35709027">[-]</label><label class="expand" for="c-35709027">[1 more]</label></div><br/><div class="children"><div class="content">Yep, it may be more common in some English-speaking cultures, but in the midwest of the US it&#x27;s extremely common to say stuff like, &quot;I&#x27;ll never forgive him for &lt;thing&gt;&quot; and it&#x27;s not meant to be taken literally.  A more literal translation would be, &quot;I&#x27;m very disappointed in this person&#x27;s decision to &lt;thing&gt;.&quot;</div><br/></div></div><div id="35707936" class="c"><input type="checkbox" id="c-35707936" checked=""/><div class="controls bullet"><span class="by">musicale</span><span>|</span><a href="#35703927">root</a><span>|</span><a href="#35707773">parent</a><span>|</span><a href="#35709027">prev</a><span>|</span><a href="#35704446">next</a><span>|</span><label class="collapse" for="c-35707936">[-]</label><label class="expand" for="c-35707936">[1 more]</label></div><br/><div class="children"><div class="content">The interesting things that one can learn about English usage on HN. ;-)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="35704446" class="c"><input type="checkbox" id="c-35704446" checked=""/><div class="controls bullet"><span class="by">zvmaz</span><span>|</span><a href="#35703927">prev</a><span>|</span><a href="#35707667">next</a><span>|</span><label class="collapse" for="c-35704446">[-]</label><label class="expand" for="c-35704446">[10 more]</label></div><br/><div class="children"><div class="content">I have met people who think they understand a particular topic I am versed in, but actually don&#x27;t. Similarly, I am often wary that I get superficial knowledge about a topic I don&#x27;t know much about through &quot;laymen&quot; resources, and I doubt one can have an appropriate level of understanding mainly through analogies and metaphors. It&#x27;s a kind of &quot;epistemic anxiety&quot;. Of course, there are &quot;laymen&quot; books I stumbled upon which I think go to appropriate levels of depth and do not &quot;dumb down&quot; to shallow levels the topics, yet remain accessible, like Gödel&#x27;s Proof, by Ernest Nagel. I&#x27;d be glad to read about similar books on all topics, including the one discussed in this thread.<p>Knowledge is hard to attain...</div><br/><div id="35704750" class="c"><input type="checkbox" id="c-35704750" checked=""/><div class="controls bullet"><span class="by">sainez</span><span>|</span><a href="#35704446">parent</a><span>|</span><a href="#35705292">next</a><span>|</span><label class="collapse" for="c-35704750">[-]</label><label class="expand" for="c-35704750">[3 more]</label></div><br/><div class="children"><div class="content">I find the best way to learn technical topics is to build a simplified version of the thing. The trick is to understand the relationship between the high level components without getting lost in the details. This high level understanding then helps inform you when you drill down into specifics.<p>I think this book is a shining example of that philosophy: <a href="https:&#x2F;&#x2F;www.buildyourownlisp.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.buildyourownlisp.com&#x2F;</a>. In the book, you implement an extremely bare-bones version of lisp, but it has been invaluable in my career. I found I was able to understand nuanced language features much more quickly because I have a clear model of how programming languages are decomposed into their components.</div><br/><div id="35705057" class="c"><input type="checkbox" id="c-35705057" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#35704446">root</a><span>|</span><a href="#35704750">parent</a><span>|</span><a href="#35705292">next</a><span>|</span><label class="collapse" for="c-35705057">[-]</label><label class="expand" for="c-35705057">[2 more]</label></div><br/><div class="children"><div class="content"><i>I find the best way to learn technical topics is to build a simplified version of the thing. The trick is to understand the relationship between the high level components without getting lost in the details. This high level understanding then helps inform you when you drill down into specifics.</i><p>I agree but that&#x27;s a good guide to build a technical understanding of a complex subject, not sufficient-in-itself tool set for considering questions in that complex subject.<p>Especially, I&#x27;ll people combining some &quot;non-technical summary&quot; of quantum-mechanics&#x2F;Newton Gravity&#x2F;genetic engineer&#x2F;etc with their personal common sense are constant annoyance to me whenever such topics come here.</div><br/><div id="35706284" class="c"><input type="checkbox" id="c-35706284" checked=""/><div class="controls bullet"><span class="by">nomel</span><span>|</span><a href="#35704446">root</a><span>|</span><a href="#35705057">parent</a><span>|</span><a href="#35705292">next</a><span>|</span><label class="collapse" for="c-35706284">[-]</label><label class="expand" for="c-35706284">[1 more]</label></div><br/><div class="children"><div class="content">&gt; constant annoyance to me whenever such topics come here.<p>I&#x27;ll say that thinking about things at the edge of my understanding, where &quot;Eureka!&quot; moments are low hanging fruit, results in the highest dump of dopamine out of any other activity. Having silly fun speculating (and I make it clear when I am) my way through some thought process is literally the most fun I can have. Seeing those types of conversations, full of <i>genuine</i> curiosity, thoughtful speculation, and all the resulting corrections&#x2F;discussions&#x2F;insight, etc, is why I love HN so much, and I hope it&#x27;s always a place to nerd out.<p>One mans trash is another mans treasure, I suppose. :)</div><br/></div></div></div></div></div></div><div id="35705292" class="c"><input type="checkbox" id="c-35705292" checked=""/><div class="controls bullet"><span class="by">somenameforme</span><span>|</span><a href="#35704446">parent</a><span>|</span><a href="#35704750">prev</a><span>|</span><a href="#35705722">next</a><span>|</span><label class="collapse" for="c-35705292">[-]</label><label class="expand" for="c-35705292">[1 more]</label></div><br/><div class="children"><div class="content">There are a million e.g. number parsing (image to digit) neural network type programs on GitHub. Go pick one in your preferred language and break it apart, and rebuild it, looking up the concepts behind parts you don&#x27;t understand. After you finish up with the above, look up &#x27;the xor problem&#x27; to see a common practical problem (which creating a network to replicate xor <i>illustrates</i>, rather than <i>is</i>) and you&#x27;ll be well on your way to a nice fundamental understanding, built from the ground up.<p>One of the most interesting things about this topic is that the fundamental concepts and implementations are all <i>really</i> simple. It&#x27;s the fact that it actually works that&#x27;s mind boggling. In any case, the above is not a months like affair - but like one week of dedicated work.</div><br/></div></div><div id="35705722" class="c"><input type="checkbox" id="c-35705722" checked=""/><div class="controls bullet"><span class="by">lxe</span><span>|</span><a href="#35704446">parent</a><span>|</span><a href="#35705292">prev</a><span>|</span><a href="#35707068">next</a><span>|</span><label class="collapse" for="c-35705722">[-]</label><label class="expand" for="c-35705722">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve noticed that the learning curve stary fairly flat when it comes to understanding weights, and layers, and neural networks, heck, even what gradient descent is for... but then when it comes to actually understanding why optimization algorithms are needed, and how they work, things just spiral into very hard math territory.<p>I do think that maybe it feels inaccessible because we transition from discrete concepts easily digestible by CS grads into some complicated math with very terse mathematic notation, yet the math might not be as hard if presented in a way that doesn&#x27;t scare away programmers.</div><br/></div></div><div id="35707068" class="c"><input type="checkbox" id="c-35707068" checked=""/><div class="controls bullet"><span class="by">commandlinefan</span><span>|</span><a href="#35704446">parent</a><span>|</span><a href="#35705722">prev</a><span>|</span><a href="#35707991">next</a><span>|</span><label class="collapse" for="c-35707068">[-]</label><label class="expand" for="c-35707068">[2 more]</label></div><br/><div class="children"><div class="content">&gt; an appropriate level of understanding mainly through analogies and metaphors<p>I think it&#x27;s actually worse than that - somebody who doesn&#x27;t know actually realizes that he doesn&#x27;t know, but somebody who _thinks_ he understands through analogies and metaphors will confidently come to the incorrect conclusion and then argue with somebody who actually does understand the topic - often managing to convince innocent bystanders because his reasoning is easier to grasp and the so-called expert seems to be getting more and more flustered (as he tries to explain why the analogy is actually correct, but oversimplified).</div><br/><div id="35708033" class="c"><input type="checkbox" id="c-35708033" checked=""/><div class="controls bullet"><span class="by">dmreedy</span><span>|</span><a href="#35704446">root</a><span>|</span><a href="#35707068">parent</a><span>|</span><a href="#35707991">next</a><span>|</span><label class="collapse" for="c-35708033">[-]</label><label class="expand" for="c-35708033">[1 more]</label></div><br/><div class="children"><div class="content">I am fascinated by this phenomenon, and the double-edged sword that metaphors are.<p>On the one hand they&#x27;re jargon used as short hand to technical concepts understood well by domain experts. And the concision they afford can lead to <i>deeper</i> understanding as they transcend their composite or adapted meanings and become base terminology in and of themselves (I think of e.g. Latin in English legal terminology. &quot;Habeas corpus&quot; has a literal meaning when translated, but the understood jargon has a deeper, and more specific meaning). At that point, they are powerful because of the precision of meaning and concision of expression they afford.<p>On the other hand, they lift intuitive terminology from a base language that is understood in vaguer terms by a broader audience. And this creates invisible disconnects because the abstraction created by these terms leaks like a sieve unless you know the precise semantics and have the model to use them.<p>By translating a discourse into a higher metaphoric level, we increase precision and efficiency amongst mutual understanders, but at the same time, we increase the level of ambiguity, the number of possible interpretations, and the availability of terms familiar to (and thus, handles to grab on to) non-understanders.
And that latter situation allows non-understanders to string together what sound superficially like well-formed thoughts using jargon terms, but based on the base language semantics. But without the deeper knowledge required to understand whether a given utterance scans or not.<p>That&#x27;s how I&#x27;ve been trying to wrap my head around it at least. I hope it doesn&#x27;t sound like moralizing or condescension, I don&#x27;t mean it to. I know I&#x27;m &quot;guilty&quot; of trying to manipulate metaphoric models that I don&#x27;t actually understand, based on the lay-semantics of their jargon.</div><br/></div></div></div></div><div id="35707991" class="c"><input type="checkbox" id="c-35707991" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#35704446">parent</a><span>|</span><a href="#35707068">prev</a><span>|</span><a href="#35707663">next</a><span>|</span><label class="collapse" for="c-35707991">[-]</label><label class="expand" for="c-35707991">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re basically describing a lot of generative AI developers who are applying their technology to fields they don&#x27;t really understand</div><br/></div></div><div id="35707663" class="c"><input type="checkbox" id="c-35707663" checked=""/><div class="controls bullet"><span class="by">wanderlust123</span><span>|</span><a href="#35704446">parent</a><span>|</span><a href="#35707991">prev</a><span>|</span><a href="#35707667">next</a><span>|</span><label class="collapse" for="c-35707663">[-]</label><label class="expand" for="c-35707663">[1 more]</label></div><br/><div class="children"><div class="content">Can you please suggest other books similar in spirit to the Nagel book? Would love to read some over summer</div><br/></div></div></div></div><div id="35707667" class="c"><input type="checkbox" id="c-35707667" checked=""/><div class="controls bullet"><span class="by">lhnz</span><span>|</span><a href="#35704446">prev</a><span>|</span><a href="#35704525">next</a><span>|</span><label class="collapse" for="c-35707667">[-]</label><label class="expand" for="c-35707667">[1 more]</label></div><br/><div class="children"><div class="content">I have a few funny analogies that I think kind of work.<p>1. &quot;gradient descent&quot; is like tuning a guitar by ear and listening to the beat frequencies (&quot;loss&quot;) and then decreasing these by tuning a string up or down.<p>2. the best I can come up with for &quot;backpropagation&quot; is to imagine a clever device that can tirelessly optimize a Rube Goldberg machine for you but as a science, not an art.</div><br/></div></div><div id="35704525" class="c"><input type="checkbox" id="c-35704525" checked=""/><div class="controls bullet"><span class="by">clarle</span><span>|</span><a href="#35707667">prev</a><span>|</span><a href="#35703485">next</a><span>|</span><label class="collapse" for="c-35704525">[-]</label><label class="expand" for="c-35704525">[11 more]</label></div><br/><div class="children"><div class="content">Totally aware that this isn&#x27;t a fully formal definition of deep learning, but one interesting takeaway for me is realizing that in a way, corporations with their formal and informal reporting structures are structured in a way similar to neural networks too.<p>It seems like these sort of structures just regularly arise to help regulate the flow of information through a system.</div><br/><div id="35704867" class="c"><input type="checkbox" id="c-35704867" checked=""/><div class="controls bullet"><span class="by">0xBABAD00C</span><span>|</span><a href="#35704525">parent</a><span>|</span><a href="#35705179">next</a><span>|</span><label class="collapse" for="c-35704867">[-]</label><label class="expand" for="c-35704867">[7 more]</label></div><br/><div class="children"><div class="content">There is research claiming the entire universe is a neural network: <a href="https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC7712105&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC7712105&#x2F;</a></div><br/><div id="35707995" class="c"><input type="checkbox" id="c-35707995" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#35704525">root</a><span>|</span><a href="#35704867">parent</a><span>|</span><a href="#35707680">next</a><span>|</span><label class="collapse" for="c-35707995">[-]</label><label class="expand" for="c-35707995">[4 more]</label></div><br/><div class="children"><div class="content">Frankly, stuff like this makes me more skeptical of the ML community. Remember when people thought Brains were just really complicated hydraulic systems?</div><br/><div id="35709643" class="c"><input type="checkbox" id="c-35709643" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#35704525">root</a><span>|</span><a href="#35707995">parent</a><span>|</span><a href="#35708566">next</a><span>|</span><label class="collapse" for="c-35709643">[-]</label><label class="expand" for="c-35709643">[2 more]</label></div><br/><div class="children"><div class="content">The author is basically a crank, it looks like they held some teaching positions in an unrelated subject at various universities yielding the “professor” title, and originally studied&#x2F;published actual research in cosmology decades back.<p>Might as well be skeptical of the math community because of circle squarers</div><br/><div id="35709871" class="c"><input type="checkbox" id="c-35709871" checked=""/><div class="controls bullet"><span class="by">0xBABAD00C</span><span>|</span><a href="#35704525">root</a><span>|</span><a href="#35709643">parent</a><span>|</span><a href="#35708566">next</a><span>|</span><label class="collapse" for="c-35709871">[-]</label><label class="expand" for="c-35709871">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The author is basically a crank<p>Really not sure why do you say this. Is it something personal against him? Are you against people exploring weird interdisciplinary topics?<p>He has tons of publications [1], including co-authorship with people like this guy:
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eugene_Koonin" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eugene_Koonin</a><p>Koonin is certainly not a crank, and is a rather well-known interdisciplinary researcher at the intersection of biology and physics.<p>[1] <a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?hl=en&amp;user=nEEFLp0AAAAJ&amp;view_op=list_works" rel="nofollow">https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?hl=en&amp;user=nEEFLp0AAAAJ...</a></div><br/></div></div></div></div><div id="35708566" class="c"><input type="checkbox" id="c-35708566" checked=""/><div class="controls bullet"><span class="by">0xBABAD00C</span><span>|</span><a href="#35704525">root</a><span>|</span><a href="#35707995">parent</a><span>|</span><a href="#35709643">prev</a><span>|</span><a href="#35707680">next</a><span>|</span><label class="collapse" for="c-35708566">[-]</label><label class="expand" for="c-35708566">[1 more]</label></div><br/><div class="children"><div class="content">Vanchurin is a physics professor, but ok
<a href="https:&#x2F;&#x2F;twitter.com&#x2F;vanchurin?lang=en" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;vanchurin?lang=en</a><p>I actually think that interdisciplinary work like this can shed light into common structures across physics, biology, neuroscience, CS, etc. If anything, I wish there were more attempts to explore the connections between these disciplines.</div><br/></div></div></div></div><div id="35707680" class="c"><input type="checkbox" id="c-35707680" checked=""/><div class="controls bullet"><span class="by">mcbuilder</span><span>|</span><a href="#35704525">root</a><span>|</span><a href="#35704867">parent</a><span>|</span><a href="#35707995">prev</a><span>|</span><a href="#35704971">next</a><span>|</span><label class="collapse" for="c-35707680">[-]</label><label class="expand" for="c-35707680">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the sort of blue sky research I&#x27;m glad exists.</div><br/></div></div><div id="35704971" class="c"><input type="checkbox" id="c-35704971" checked=""/><div class="controls bullet"><span class="by">mxkopy</span><span>|</span><a href="#35704525">root</a><span>|</span><a href="#35704867">parent</a><span>|</span><a href="#35707680">prev</a><span>|</span><a href="#35705179">next</a><span>|</span><label class="collapse" for="c-35704971">[-]</label><label class="expand" for="c-35704971">[1 more]</label></div><br/><div class="children"><div class="content">Indra&#x27;s Net is, in fact, a neural network</div><br/></div></div></div></div><div id="35705179" class="c"><input type="checkbox" id="c-35705179" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#35704525">parent</a><span>|</span><a href="#35704867">prev</a><span>|</span><a href="#35703485">next</a><span>|</span><label class="collapse" for="c-35705179">[-]</label><label class="expand" for="c-35705179">[3 more]</label></div><br/><div class="children"><div class="content">Uh,<p>The similarity of corporations and neural nets is pretty much only that both are information processing systems. An operating system or missile guidance system is far more like a corporation than a neural network.<p>Neural networks have no memory and generally don&#x27;t seek particular goals, they simply recognize, predict and generate similar instances.</div><br/><div id="35708972" class="c"><input type="checkbox" id="c-35708972" checked=""/><div class="controls bullet"><span class="by">d0gsg0w00f</span><span>|</span><a href="#35704525">root</a><span>|</span><a href="#35705179">parent</a><span>|</span><a href="#35707267">next</a><span>|</span><label class="collapse" for="c-35708972">[-]</label><label class="expand" for="c-35708972">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; Neural networks have no memory and generally don&#x27;t seek particular goals, they simply recognize, predict and generate similar instances.
</code></pre>
Sounds exactly like every corporation I&#x27;ve ever worked in.</div><br/></div></div><div id="35707267" class="c"><input type="checkbox" id="c-35707267" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#35704525">root</a><span>|</span><a href="#35705179">parent</a><span>|</span><a href="#35708972">prev</a><span>|</span><a href="#35703485">next</a><span>|</span><label class="collapse" for="c-35707267">[-]</label><label class="expand" for="c-35707267">[1 more]</label></div><br/><div class="children"><div class="content">Plenty of ways to think about this stuff. IMO neural networks don’t inherently do anything, it’s just a data structure.<p>Different ways you can interact with that data structure can however provide meaning and store information in the weights etc.</div><br/></div></div></div></div></div></div><div id="35703485" class="c"><input type="checkbox" id="c-35703485" checked=""/><div class="controls bullet"><span class="by">pkdpic</span><span>|</span><a href="#35704525">prev</a><span>|</span><a href="#35704811">next</a><span>|</span><label class="collapse" for="c-35703485">[-]</label><label class="expand" for="c-35703485">[5 more]</label></div><br/><div class="children"><div class="content">I love this, but Im always confused in these kinds of analogies what the reward &#x2F; punishment system really  equates to...<p>Also reminds me of Ted Chiang warning us that we will torture innumerable AI entities long before we start having real conversations about treating them with compassion.</div><br/><div id="35703833" class="c"><input type="checkbox" id="c-35703833" checked=""/><div class="controls bullet"><span class="by">time_to_smile</span><span>|</span><a href="#35703485">parent</a><span>|</span><a href="#35707095">next</a><span>|</span><label class="collapse" for="c-35703833">[-]</label><label class="expand" for="c-35703833">[3 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t love it, it&#x27;s not correct.<p>&gt; what the reward &#x2F; punishment system really equates to<p>Nothing, and least as far as neural network training goes. This is an extremely poor analogy regarding how neural networks learn.<p>If you&#x27;ve ever done any kind of physical training and have had a trainer sightly adjust the position of your limbs until what ever activity you&#x27;re doing feels better, that&#x27;s a much closer analogy. You&#x27;re gently searching the space of possible correct positions, guided by an algorithm (your trainer) that knows how to move you towards a more correct solution.<p>There&#x27;s nothing analogous to a &quot;reward&quot; or &quot;punishment&quot; when neural networks are learning.</div><br/><div id="35704220" class="c"><input type="checkbox" id="c-35704220" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#35703485">root</a><span>|</span><a href="#35703833">parent</a><span>|</span><a href="#35707095">next</a><span>|</span><label class="collapse" for="c-35704220">[-]</label><label class="expand" for="c-35704220">[2 more]</label></div><br/><div class="children"><div class="content">&gt;There&#x27;s nothing analogous to a &quot;reward&quot; or &quot;punishment&quot; when neural networks are learning.<p>Well deep reinforcement learning.</div><br/><div id="35709249" class="c"><input type="checkbox" id="c-35709249" checked=""/><div class="controls bullet"><span class="by">cshimmin</span><span>|</span><a href="#35703485">root</a><span>|</span><a href="#35704220">parent</a><span>|</span><a href="#35707095">next</a><span>|</span><label class="collapse" for="c-35709249">[-]</label><label class="expand" for="c-35709249">[1 more]</label></div><br/><div class="children"><div class="content">Yeah but even in that case, &quot;reward&quot; is just the thing a NN is trying to predict. The NN itself is not receiving the reward (or any punishment). Instead, it&#x27;s following gradient signals to improve that estimate of reward, which is then used as a proxy for an optimal policy decision.</div><br/></div></div></div></div></div></div><div id="35707095" class="c"><input type="checkbox" id="c-35707095" checked=""/><div class="controls bullet"><span class="by">commandlinefan</span><span>|</span><a href="#35703485">parent</a><span>|</span><a href="#35703833">prev</a><span>|</span><a href="#35704811">next</a><span>|</span><label class="collapse" for="c-35707095">[-]</label><label class="expand" for="c-35707095">[1 more]</label></div><br/><div class="children"><div class="content">&gt; what the reward &#x2F; punishment system really equates to<p>Well, in the article, it says the punishment was a slap.  On the other hand, he just says &quot;she gives you a wonderful reward&quot;... so you&#x27;re left to use your imagination there.</div><br/></div></div></div></div><div id="35704811" class="c"><input type="checkbox" id="c-35704811" checked=""/><div class="controls bullet"><span class="by">sainez</span><span>|</span><a href="#35703485">prev</a><span>|</span><a href="#35702442">next</a><span>|</span><label class="collapse" for="c-35704811">[-]</label><label class="expand" for="c-35704811">[1 more]</label></div><br/><div class="children"><div class="content">If anyone is looking for a quick overview of how LLMs are built, I highly recommend this video by Steve Seitz: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lnA9DMvHtfI">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lnA9DMvHtfI</a>.<p>It does an excellent job of taking you from 0 to a decent understanding without dumbing down the content or abusing analogies.</div><br/></div></div><div id="35702442" class="c"><input type="checkbox" id="c-35702442" checked=""/><div class="controls bullet"><span class="by">onikolas7</span><span>|</span><a href="#35704811">prev</a><span>|</span><a href="#35702540">next</a><span>|</span><label class="collapse" for="c-35702442">[-]</label><label class="expand" for="c-35702442">[4 more]</label></div><br/><div class="children"><div class="content">Funny. In the game black&amp;white you would slap or pet your avatar to train it. The lead AI programmer on that was Demis Hassabis of deepmind fame.</div><br/><div id="35707023" class="c"><input type="checkbox" id="c-35707023" checked=""/><div class="controls bullet"><span class="by">Maultasche</span><span>|</span><a href="#35702442">parent</a><span>|</span><a href="#35705049">next</a><span>|</span><label class="collapse" for="c-35707023">[-]</label><label class="expand" for="c-35707023">[1 more]</label></div><br/><div class="children"><div class="content">The description made me think of Black &amp; White as well. I still have memories of smacking my creature around every time he ate someone.</div><br/></div></div><div id="35705049" class="c"><input type="checkbox" id="c-35705049" checked=""/><div class="controls bullet"><span class="by">redog</span><span>|</span><a href="#35702442">parent</a><span>|</span><a href="#35707023">prev</a><span>|</span><a href="#35702540">next</a><span>|</span><label class="collapse" for="c-35705049">[-]</label><label class="expand" for="c-35705049">[2 more]</label></div><br/><div class="children"><div class="content">Somehow he knew AI would be our Gods.</div><br/><div id="35708007" class="c"><input type="checkbox" id="c-35708007" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#35702442">root</a><span>|</span><a href="#35705049">parent</a><span>|</span><a href="#35702540">next</a><span>|</span><label class="collapse" for="c-35708007">[-]</label><label class="expand" for="c-35708007">[1 more]</label></div><br/><div class="children"><div class="content">False idols maybe</div><br/></div></div></div></div></div></div><div id="35702540" class="c"><input type="checkbox" id="c-35702540" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#35702442">prev</a><span>|</span><a href="#35707356">next</a><span>|</span><label class="collapse" for="c-35702540">[-]</label><label class="expand" for="c-35702540">[10 more]</label></div><br/><div class="children"><div class="content">The problem with deep learning is opposite. You can understand most of it with just high school math. Advanced math is mostly useless because of the dimensionality of neural nets.</div><br/><div id="35707133" class="c"><input type="checkbox" id="c-35707133" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#35702540">parent</a><span>|</span><a href="#35703668">next</a><span>|</span><label class="collapse" for="c-35707133">[-]</label><label class="expand" for="c-35707133">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Advanced math is mostly useless because of the dimensionality of neural nets.<p>It depends what you mean by advanced math. There is a lot of math that only really comes into play <i>because</i> of the high dimensionality! For example math related to tensor wrangling, low rank approximations, spectral theory, harmonic theory, matrix calculus derivatives, universality principles, and other concepts that could be interesting or bewildering or horrifying depending how you react to it. Of course some of it is only linear algebra of the &#x27;just high school math&#x27; kind but that&#x27;s not how I would normally describe it. If you look at the math in the proofs in the appendices of the more technical AI papers on arxiv there is often some weird stuff in there, not just matrix multiply and softmax.</div><br/></div></div><div id="35703668" class="c"><input type="checkbox" id="c-35703668" checked=""/><div class="controls bullet"><span class="by">mach1ne</span><span>|</span><a href="#35702540">parent</a><span>|</span><a href="#35707133">prev</a><span>|</span><a href="#35704547">next</a><span>|</span><label class="collapse" for="c-35703668">[-]</label><label class="expand" for="c-35703668">[4 more]</label></div><br/><div class="children"><div class="content">Yes, it’s really rather like alchemy in some sense. Stuff works, and often nobody knows exactly why.</div><br/><div id="35704566" class="c"><input type="checkbox" id="c-35704566" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#35702540">root</a><span>|</span><a href="#35703668">parent</a><span>|</span><a href="#35705753">prev</a><span>|</span><a href="#35704547">next</a><span>|</span><label class="collapse" for="c-35704566">[-]</label><label class="expand" for="c-35704566">[2 more]</label></div><br/><div class="children"><div class="content">&quot;I don&#x27;t follow the latest ML scaling and theory research&quot; does not in any way equate to &quot;these things are unknowable&quot;.</div><br/><div id="35707255" class="c"><input type="checkbox" id="c-35707255" checked=""/><div class="controls bullet"><span class="by">lhnz</span><span>|</span><a href="#35702540">root</a><span>|</span><a href="#35704566">parent</a><span>|</span><a href="#35704547">next</a><span>|</span><label class="collapse" for="c-35707255">[-]</label><label class="expand" for="c-35707255">[1 more]</label></div><br/><div class="children"><div class="content">Hm, watching Neel Nanda videos recently and I do get the feeling that there are lots of unknowns in ML and also in what trained networks have learnt.</div><br/></div></div></div></div></div></div><div id="35704547" class="c"><input type="checkbox" id="c-35704547" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#35702540">parent</a><span>|</span><a href="#35703668">prev</a><span>|</span><a href="#35703666">next</a><span>|</span><label class="collapse" for="c-35704547">[-]</label><label class="expand" for="c-35704547">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s like saying you understand state-of-the-art CFD code because you can read Fortran.<p>There are many aspects to learning systems that we still don&#x27;t have any kind of grasp on, and will take more than a little advanced math (statistics&#x2F;probability theory, transport theory, topology, etc.) to understand as a community.<p>Dunning-Kruger is probably more common in spaces like this one, where people carry social capital for being able to &quot;spin up quickly&quot;. But the true meta-skill of upskilling is turning unknown unknowns (UU) into known unknowns (KU), and then into known knowns (KK). It&#x27;s not enough to just jump from UU to KK through osmosis by reading blog posts on a news aggregator, because there will still be a huge space of unknowns not covered by that approach.</div><br/></div></div><div id="35703666" class="c"><input type="checkbox" id="c-35703666" checked=""/><div class="controls bullet"><span class="by">Utkarsh_Mood</span><span>|</span><a href="#35702540">parent</a><span>|</span><a href="#35704547">prev</a><span>|</span><a href="#35707356">next</a><span>|</span><label class="collapse" for="c-35703666">[-]</label><label class="expand" for="c-35703666">[3 more]</label></div><br/><div class="children"><div class="content">can you elaborate further on what you mean by &#x27;dimensionality of neural nets&#x27;? Thanks!</div><br/><div id="35704337" class="c"><input type="checkbox" id="c-35704337" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#35702540">root</a><span>|</span><a href="#35703666">parent</a><span>|</span><a href="#35703841">next</a><span>|</span><label class="collapse" for="c-35704337">[-]</label><label class="expand" for="c-35704337">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I mean the huge number of trainable parameters.</div><br/></div></div></div></div></div></div><div id="35707356" class="c"><input type="checkbox" id="c-35707356" checked=""/><div class="controls bullet"><span class="by">Myrmornis</span><span>|</span><a href="#35702540">prev</a><span>|</span><a href="#35709410">next</a><span>|</span><label class="collapse" for="c-35707356">[-]</label><label class="expand" for="c-35707356">[2 more]</label></div><br/><div class="children"><div class="content">&gt; they see 3 spreadsheets of numbers representing the RGB values of the picture.<p>This needs expanding: it&#x27;s the sort of thing that&#x27;s easy for a programmer to say, but few non-{programmer,mathematically trained person} are going to see that an RGB value has 3 parts and so a collection of RGB values could be sliced into 3 sheets.</div><br/><div id="35707690" class="c"><input type="checkbox" id="c-35707690" checked=""/><div class="controls bullet"><span class="by">romwell</span><span>|</span><a href="#35707356">parent</a><span>|</span><a href="#35709410">next</a><span>|</span><label class="collapse" for="c-35707690">[-]</label><label class="expand" for="c-35707690">[1 more]</label></div><br/><div class="children"><div class="content">...or know what Ruth Ginsburg Bader has anything to do with it all.<p>The RGB color model and representation of images in it is already technical. Anyone who knows what it means also wouldn&#x27;t need to be told the following quip:<p>&gt;Also note that computers see things as multi-dimensional tables of data. They don&#x27;t look at a &quot;picture&quot; - they see 3 spreadsheets of numbers representing the RGB values of the picture.<p>...which is the only time RGB is mentioned in the article.<p>That&#x27;s before we get to the part that &quot;multidimensional&quot; here is extraneous, and doesn&#x27;t even match the typical usage (where RGBA is stored as a single 32-bit value). Everything is a tape of 1&#x27;s and 0&#x27;s, &quot;multidimensionality&quot; comes from  interpretation of data.<p>The <i>dimension</i> of image data is still 2: each pixel is a sample a 2D projection of a 3D world, and is related to other pixels in a way that&#x27;s different than, say, those of letters in a line of text, or voxels (letters don&#x27;t have a a well-defined &quot;up&quot; neighbor, voxels have <i>more</i> well-defined neighbors than pixels do).</div><br/></div></div></div></div><div id="35709410" class="c"><input type="checkbox" id="c-35709410" checked=""/><div class="controls bullet"><span class="by">kagaw</span><span>|</span><a href="#35707356">prev</a><span>|</span><a href="#35709028">next</a><span>|</span><label class="collapse" for="c-35709410">[-]</label><label class="expand" for="c-35709410">[1 more]</label></div><br/><div class="children"><div class="content">I see, so neural network works like Naruto&#x27;s Kage Bunshin technique where the learning of the clones will pass to its origin</div><br/></div></div><div id="35702292" class="c"><input type="checkbox" id="c-35702292" checked=""/><div class="controls bullet"><span class="by">great_wubwub</span><span>|</span><a href="#35709028">prev</a><span>|</span><a href="#35703109">next</a><span>|</span><label class="collapse" for="c-35702292">[-]</label><label class="expand" for="c-35702292">[2 more]</label></div><br/><div class="children"><div class="content">As someone who knows barely enough to be dangerous, I like this. I&#x27;m sure it leaves enough out to make most experts angry, but it makes a lot of sense to me.</div><br/><div id="35702418" class="c"><input type="checkbox" id="c-35702418" checked=""/><div class="controls bullet"><span class="by">time_to_smile</span><span>|</span><a href="#35702292">parent</a><span>|</span><a href="#35703109">next</a><span>|</span><label class="collapse" for="c-35702418">[-]</label><label class="expand" for="c-35702418">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m sure it leaves enough out to make most experts angry<p>It&#x27;s not that it leaves out details, it&#x27;s that the articles metaphors are not actually correct in regards to the way deep learning works.<p>This post mostly confuses both reinforcement learning and ensemble models with deep learning. If you only enough &quot;enough to be dangerous&quot; then this post will steer your intuition in the <i>wrong</i> direction.</div><br/></div></div></div></div><div id="35703109" class="c"><input type="checkbox" id="c-35703109" checked=""/><div class="controls bullet"><span class="by">hgsgm</span><span>|</span><a href="#35702292">prev</a><span>|</span><a href="#35702328">next</a><span>|</span><label class="collapse" for="c-35703109">[-]</label><label class="expand" for="c-35703109">[1 more]</label></div><br/><div class="children"><div class="content">Non-technical, non-accurate. &quot;Truthy&quot;, buzzfeed&#x2F;huffpo quality.</div><br/></div></div><div id="35702328" class="c"><input type="checkbox" id="c-35702328" checked=""/><div class="controls bullet"><span class="by">time_to_smile</span><span>|</span><a href="#35703109">prev</a><span>|</span><a href="#35702680">next</a><span>|</span><label class="collapse" for="c-35702328">[-]</label><label class="expand" for="c-35702328">[2 more]</label></div><br/><div class="children"><div class="content">&gt; This is how neural networks work: they see many examples and get rewarded or punished based on whether their guesses are correct.<p>This description more closely describes reinforcement learning, rather than gradient based optimization.<p>In fact, the entire metaphor of a confused individual being slapped or rewarded without understanding what&#x27;s going on doesn&#x27;t really make sense when considering gradient optimization because the gradient wrt the to loss function tells the network <i>exactly</i> how to change it&#x27;s behavior to improve it&#x27;s performance.<p>This last point is incredibly important to understand correctly since it contains one of the biggest assumptions about network behavior: that the optimal solution, or at least good enough for our concerns solution, <i>can be found</i> by slowing taking small steps in the right direction.<p>Neural networks are great at <i>refining</i> their beliefs but have a difficult time radically changing them. A better analogy might be trying to very slowly convince your uncle that climate change is real, and not a liberal conspiracy.<p>edit: it also does a poor job of explaining layers, which reads much more similar to how ensemble methods work (lots of little classifiers voting) than how deep networks work.</div><br/><div id="35709337" class="c"><input type="checkbox" id="c-35709337" checked=""/><div class="controls bullet"><span class="by">cshimmin</span><span>|</span><a href="#35702328">parent</a><span>|</span><a href="#35702680">next</a><span>|</span><label class="collapse" for="c-35709337">[-]</label><label class="expand" for="c-35709337">[1 more]</label></div><br/><div class="children"><div class="content">Well said re: gradient optimization vs. &quot;getting slapped&quot;. However, note that since NN optimization is almost always nonconvex, we are NOT guaranteed to arrive an a optimal (or even close-enough) solution. A major limitation of gradient based optimization on nonconvex problems is that they are very susceptible to getting trapped in local minima.<p>But, for now it&#x27;s the best tool we have, so we just have to hope that we get close enough, or just empirically run lots of times to find the best local minimum we can. Incidentally, this actually is more like a brute-force approach, but at the ensemble level, which is quite different than the article means it.</div><br/></div></div></div></div><div id="35702680" class="c"><input type="checkbox" id="c-35702680" checked=""/><div class="controls bullet"><span class="by">wrs</span><span>|</span><a href="#35702328">prev</a><span>|</span><a href="#35707984">next</a><span>|</span><label class="collapse" for="c-35702680">[-]</label><label class="expand" for="c-35702680">[6 more]</label></div><br/><div class="children"><div class="content">This is the funniest refutation of the Chinese Room argument that I’ve seen. Note that at the end, it’s still the case that none of these people can recognize a cat.</div><br/><div id="35703163" class="c"><input type="checkbox" id="c-35703163" checked=""/><div class="controls bullet"><span class="by">pringk02</span><span>|</span><a href="#35702680">parent</a><span>|</span><a href="#35707984">next</a><span>|</span><label class="collapse" for="c-35703163">[-]</label><label class="expand" for="c-35703163">[5 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t that mean it supports the Chinese room argument? I&#x27;m not sure I follow your reasoning.<p>(also, popular conciousness forgets that technically the Chinese Room argument is only arguing against the much narrower, and now philosophically unfashionable, &quot;Hard AI&quot; stance as it was held in the 70s)</div><br/><div id="35704320" class="c"><input type="checkbox" id="c-35704320" checked=""/><div class="controls bullet"><span class="by">tasty_freeze</span><span>|</span><a href="#35702680">root</a><span>|</span><a href="#35703163">parent</a><span>|</span><a href="#35703655">next</a><span>|</span><label class="collapse" for="c-35704320">[-]</label><label class="expand" for="c-35704320">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the Chinese Room argument is only arguing against the much narrower, and now philosophically unfashionable, &quot;Hard AI&quot; stance as it was held in the 70s<p>Searle has stood behind his argument in the 70s, but in every decade since then too.<p>The main failure is that most people fundamentally don&#x27;t believe they are mechanistic. If one believe in dualism, then it easy to attribute various mental states to that dualism, and of course a computer neural network cannot experience qualia like humans do.<p>I don&#x27;t believe in a soul, and thus believe that a computer neural network, probably not today&#x27;s models but a future one that is large enough and has the right recurrent topology, will be able to have qualia similar to what humans and animals experience.</div><br/></div></div><div id="35703655" class="c"><input type="checkbox" id="c-35703655" checked=""/><div class="controls bullet"><span class="by">wrs</span><span>|</span><a href="#35702680">root</a><span>|</span><a href="#35703163">parent</a><span>|</span><a href="#35704320">prev</a><span>|</span><a href="#35707984">next</a><span>|</span><label class="collapse" for="c-35703655">[-]</label><label class="expand" for="c-35703655">[3 more]</label></div><br/><div class="children"><div class="content">I understand the Chinese Room argument to be that because the human in the room doesn’t understand Chinese, the system doesn’t understand Chinese. In this case, none of the humans can recognize cats, but the collective can.</div><br/><div id="35706549" class="c"><input type="checkbox" id="c-35706549" checked=""/><div class="controls bullet"><span class="by">cscurmudgeon</span><span>|</span><a href="#35702680">root</a><span>|</span><a href="#35703655">parent</a><span>|</span><a href="#35707984">next</a><span>|</span><label class="collapse" for="c-35706549">[-]</label><label class="expand" for="c-35706549">[2 more]</label></div><br/><div class="children"><div class="content">Thats not the Chinese Room argument. The argument says just because a system processes X doesn&#x27;t imply it has consciousness of X.</div><br/><div id="35707935" class="c"><input type="checkbox" id="c-35707935" checked=""/><div class="controls bullet"><span class="by">wrs</span><span>|</span><a href="#35702680">root</a><span>|</span><a href="#35706549">parent</a><span>|</span><a href="#35707984">next</a><span>|</span><label class="collapse" for="c-35707935">[-]</label><label class="expand" for="c-35707935">[1 more]</label></div><br/><div class="children"><div class="content">The flaw is the unsupported assertion that the whole system being conscious of X depends on a part of the system being conscious of X. The same assertion would fail here in the same way.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="35707984" class="c"><input type="checkbox" id="c-35707984" checked=""/><div class="controls bullet"><span class="by">tartakovsky</span><span>|</span><a href="#35702680">prev</a><span>|</span><a href="#35705654">next</a><span>|</span><label class="collapse" for="c-35707984">[-]</label><label class="expand" for="c-35707984">[1 more]</label></div><br/><div class="children"><div class="content">Made me laugh because it&#x27;s true, funny. Well done!</div><br/></div></div><div id="35705654" class="c"><input type="checkbox" id="c-35705654" checked=""/><div class="controls bullet"><span class="by">lxe</span><span>|</span><a href="#35707984">prev</a><span>|</span><a href="#35708288">next</a><span>|</span><label class="collapse" for="c-35705654">[-]</label><label class="expand" for="c-35705654">[1 more]</label></div><br/><div class="children"><div class="content">This has Three-Body Problem vibes :)</div><br/></div></div><div id="35708288" class="c"><input type="checkbox" id="c-35708288" checked=""/><div class="controls bullet"><span class="by">dukeofdoom</span><span>|</span><a href="#35705654">prev</a><span>|</span><a href="#35703658">next</a><span>|</span><label class="collapse" for="c-35708288">[-]</label><label class="expand" for="c-35708288">[2 more]</label></div><br/><div class="children"><div class="content">I asked ChatGPT:<p>Sure, I can explain deep learning using the analogy of mixing paint colors.<p>When you mix different colors of paint, you can create new colors that are a combination of the original colors. Similarly, in deep learning, you can combine different types of data, such as images, text, and audio, to create a more comprehensive understanding of the information.<p>In a neural network, which is the basic building block of deep learning, each layer is like a different color of paint. The input layer represents the initial data, which is like a blank canvas. As the data passes through each layer, the network extracts increasingly complex features, similar to how mixing different colors creates more complex hues.<p>Each layer in a neural network can be thought of as a different color that is mixed with the previous layer&#x27;s color. As the colors mix, the resulting color becomes more complex and nuanced, just as the data becomes more sophisticated and detailed as it passes through the layers of the neural network.<p>At the end of the process, the output layer represents the final result, which is like a finished painting. The deep learning algorithm can then use this final output to make predictions or classifications based on the input data.<p>So, in essence, deep learning is like mixing paint colors to create new and more complex hues, but instead of colors, the mixtures are made up of data and the neural network layers are the different colors being mixed.</div><br/><div id="35708295" class="c"><input type="checkbox" id="c-35708295" checked=""/><div class="controls bullet"><span class="by">dukeofdoom</span><span>|</span><a href="#35708288">parent</a><span>|</span><a href="#35703658">next</a><span>|</span><label class="collapse" for="c-35708295">[-]</label><label class="expand" for="c-35708295">[1 more]</label></div><br/><div class="children"><div class="content">Certainly! Here&#x27;s an explanation of how a neural network is trained using the analogy of mixing paint colors.<p>Initialization: The weights and biases of the neural network are like the starting colors of the paint mixture. Just like how you need to start with some base colors to mix new ones, the neural network needs some initial weights and biases to begin the training process.<p>Forward Pass: During the forward pass, the input data is fed into the neural network, and the network produces an output. This output is like the mixed color of paint that results from combining different colors.<p>Backward Pass: During the backward pass, the error between the predicted output and the actual output is calculated using a loss function. This error is like a measure of how close the mixed color is to the desired color. Just like how you would adjust the mixture of colors to get the desired hue, the neural network adjusts the weights and biases of the neurons to minimize the error between the predicted output and the actual output.<p>Repeat: Steps 2 and 3 are repeated many times with different input data points, and the weights and biases of the neural network are updated after each iteration. This process is like adding more colors to the mixture and adjusting the amounts until the desired color is achieved.<p>Validation: After several epochs, the neural network is evaluated using a validation set of data to determine if it&#x27;s overfitting or underfitting the training data. This step is like checking the mixture of colors to see if it matches the desired color under different lighting conditions.<p>Testing: Once the neural network has been trained and evaluated, it can be used to make predictions on new data. This step is like using the paint mixture to create a painting.<p>In summary, just like mixing paint colors to achieve a desired hue, the neural network adjusts its weights and biases to minimize the error between the predicted output and the actual output until it accurately predicts the output for new data.</div><br/></div></div></div></div><div id="35703658" class="c"><input type="checkbox" id="c-35703658" checked=""/><div class="controls bullet"><span class="by">charcircuit</span><span>|</span><a href="#35708288">prev</a><span>|</span><a href="#35702400">next</a><span>|</span><label class="collapse" for="c-35703658">[-]</label><label class="expand" for="c-35703658">[1 more]</label></div><br/><div class="children"><div class="content">Why is violence and praise being used to illustrate gradient descent? Why does each person get to see the entire input data?</div><br/></div></div><div id="35702400" class="c"><input type="checkbox" id="c-35702400" checked=""/><div class="controls bullet"><span class="by">giardini</span><span>|</span><a href="#35703658">prev</a><span>|</span><a href="#35702347">next</a><span>|</span><label class="collapse" for="c-35702400">[-]</label><label class="expand" for="c-35702400">[4 more]</label></div><br/><div class="children"><div class="content">Nothing about LLMs?!</div><br/><div id="35704311" class="c"><input type="checkbox" id="c-35704311" checked=""/><div class="controls bullet"><span class="by">fifteen1506</span><span>|</span><a href="#35702400">parent</a><span>|</span><a href="#35702347">next</a><span>|</span><label class="collapse" for="c-35704311">[-]</label><label class="expand" for="c-35704311">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, I need something to explain me about those Transformers things.
I know it was published by Google in 2017 and that it is &#x27;magic&#x27;.<p>End of knowledge.<p>Maybe I should ask ChatGPT?</div><br/><div id="35708175" class="c"><input type="checkbox" id="c-35708175" checked=""/><div class="controls bullet"><span class="by">Izkata</span><span>|</span><a href="#35702400">root</a><span>|</span><a href="#35704311">parent</a><span>|</span><a href="#35704749">next</a><span>|</span><label class="collapse" for="c-35708175">[-]</label><label class="expand" for="c-35708175">[1 more]</label></div><br/><div class="children"><div class="content">2-hour video posted a month or two ago in a comment here:  &quot;Let&#x27;s build GPT: from scratch, in code, spelled out.&quot;<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=kCc8FmEb1nY">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=kCc8FmEb1nY</a><p>(I haven&#x27;t gotten around to watching it yet)</div><br/></div></div><div id="35704749" class="c"><input type="checkbox" id="c-35704749" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#35702400">root</a><span>|</span><a href="#35704311">parent</a><span>|</span><a href="#35708175">prev</a><span>|</span><a href="#35702347">next</a><span>|</span><label class="collapse" for="c-35704749">[-]</label><label class="expand" for="c-35704749">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Maybe I should ask ChatGPT?<p>You actually should, it spits out a pretty good explanation (sometimes).</div><br/></div></div></div></div></div></div><div id="35702347" class="c"><input type="checkbox" id="c-35702347" checked=""/><div class="controls bullet"><span class="by">nailer</span><span>|</span><a href="#35702400">prev</a><span>|</span><a href="#35704305">next</a><span>|</span><label class="collapse" for="c-35702347">[-]</label><label class="expand" for="c-35702347">[7 more]</label></div><br/><div class="children"><div class="content">Does this article imply there are circumstances where a spreadsheet is a cat? What a poor example of technical writing.</div><br/><div id="35703754" class="c"><input type="checkbox" id="c-35703754" checked=""/><div class="controls bullet"><span class="by">andysinclair</span><span>|</span><a href="#35702347">parent</a><span>|</span><a href="#35702851">next</a><span>|</span><label class="collapse" for="c-35703754">[-]</label><label class="expand" for="c-35703754">[1 more]</label></div><br/><div class="children"><div class="content">He’s saying that the spreadsheet represents the “picture” of the cat in terms of pixels and RGB values etc.<p>The algorithm&#x2F;workers are not really “looking” at a picture of a cat, they are analysing and looking for patterns in the data that defines the picture of the cat.</div><br/></div></div><div id="35702851" class="c"><input type="checkbox" id="c-35702851" checked=""/><div class="controls bullet"><span class="by">teacpde</span><span>|</span><a href="#35702347">parent</a><span>|</span><a href="#35703754">prev</a><span>|</span><a href="#35704305">next</a><span>|</span><label class="collapse" for="c-35702851">[-]</label><label class="expand" for="c-35702851">[5 more]</label></div><br/><div class="children"><div class="content">Not the author, but to the author&#x27;s defense, it is meant to be non-technical. And the first paragraph reads interesting to me.</div><br/><div id="35703552" class="c"><input type="checkbox" id="c-35703552" checked=""/><div class="controls bullet"><span class="by">nailer</span><span>|</span><a href="#35702347">root</a><span>|</span><a href="#35702851">parent</a><span>|</span><a href="#35704305">next</a><span>|</span><label class="collapse" for="c-35703552">[-]</label><label class="expand" for="c-35703552">[4 more]</label></div><br/><div class="children"><div class="content">Most non technical people would think there are zero circumstances where a spreadsheet could be a cat.</div><br/><div id="35704190" class="c"><input type="checkbox" id="c-35704190" checked=""/><div class="controls bullet"><span class="by">adrianmonk</span><span>|</span><a href="#35702347">root</a><span>|</span><a href="#35703552">parent</a><span>|</span><a href="#35703743">next</a><span>|</span><label class="collapse" for="c-35704190">[-]</label><label class="expand" for="c-35704190">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s obvious from context that it&#x27;s the content of the media. To me at least.<p>If I play you a song on Spotify and say, &quot;Is this a saxophone?&quot;, you wouldn&#x27;t say, &quot;No, it&#x27;s a iPhone running Spotify.&quot;<p>If a policeman holds up a photograph of a person and says, &quot;Is this the person who attacked you?&quot;, the victim doesn&#x27;t say, &quot;No, it&#x27;s an 8 by 10 glossy print.&quot;</div><br/><div id="35709354" class="c"><input type="checkbox" id="c-35709354" checked=""/><div class="controls bullet"><span class="by">cshimmin</span><span>|</span><a href="#35702347">root</a><span>|</span><a href="#35704190">parent</a><span>|</span><a href="#35703743">next</a><span>|</span><label class="collapse" for="c-35709354">[-]</label><label class="expand" for="c-35709354">[1 more]</label></div><br/><div class="children"><div class="content">mais ceci n&#x27;est pas une pipe!</div><br/></div></div></div></div><div id="35703743" class="c"><input type="checkbox" id="c-35703743" checked=""/><div class="controls bullet"><span class="by">ricardobeat</span><span>|</span><a href="#35702347">root</a><span>|</span><a href="#35703552">parent</a><span>|</span><a href="#35704190">prev</a><span>|</span><a href="#35704305">next</a><span>|</span><label class="collapse" for="c-35703743">[-]</label><label class="expand" for="c-35703743">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s part of the explanation. It might not make sense at first, but you&#x27;ll figure something out to avoid being slapped.</div><br/></div></div></div></div></div></div></div></div><div id="35705196" class="c"><input type="checkbox" id="c-35705196" checked=""/><div class="controls bullet"><span class="by">_gmax0</span><span>|</span><a href="#35705668">prev</a><span>|</span><label class="collapse" for="c-35705196">[-]</label><label class="expand" for="c-35705196">[11 more]</label></div><br/><div class="children"><div class="content">The most concise and intuitive line of explanation I&#x27;ve been given goes along the lines of this:<p>1 - We want to model data, representative of some system, through functions.<p>2 - Virtually any function can be expressed by a n-th order polynomial.<p>3 - We wish to learn the parameters, the coefficients, of such polynomials.<p>4 - Neural networks allow us to brute-force test candidate values of such parameters (finding optimal candidate parameters such that error between expected and actual values of our dataset are minimized)<p>Whereas prior, methods (e.g. PCA) could only model linear relationships, neural networks allowed us to begin modeling non-linear ones.</div><br/><div id="35707145" class="c"><input type="checkbox" id="c-35707145" checked=""/><div class="controls bullet"><span class="by">civilized</span><span>|</span><a href="#35705196">parent</a><span>|</span><a href="#35707349">next</a><span>|</span><label class="collapse" for="c-35707145">[-]</label><label class="expand" for="c-35707145">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need neural networks to do polynomial regression. Polynomial regression, perhaps surprisingly, can be implemented using only (multivariable) linear regression. You just include powers of your predictor x as terms in the regression formula:<p><pre><code>  y = a + bx + cx^2 + dx^3 + ...
</code></pre>
The resulting model is linear, even though there are powers of x in your formula. Because x and y are <i>known</i> from the data. They&#x27;re not what you&#x27;re solving for, you&#x27;re solving for the unknown <i>coefficients</i> (a, b, c, d...). This gives you a linear system of equations in those unknown coefficients, which can be solved using standard linear least squares methods.<p>So fitting polynomials is easy. The problem is that it&#x27;s not that useful. Deep learning has to solve much harder problems to get to a useful model.</div><br/></div></div><div id="35707349" class="c"><input type="checkbox" id="c-35707349" checked=""/><div class="controls bullet"><span class="by">lhnz</span><span>|</span><a href="#35705196">parent</a><span>|</span><a href="#35707145">prev</a><span>|</span><a href="#35706716">next</a><span>|</span><label class="collapse" for="c-35707349">[-]</label><label class="expand" for="c-35707349">[1 more]</label></div><br/><div class="children"><div class="content">Hm, I don&#x27;t think that&#x27;s quite it. I went through my own process of learning how neural networks work recently and wrote this based on my learning: <a href="https:&#x2F;&#x2F;sebinsua.com&#x2F;bridging-the-gap" rel="nofollow">https:&#x2F;&#x2F;sebinsua.com&#x2F;bridging-the-gap</a><p>As far as my understanding goes, you can represent practically any function as layers of linear transformations followed by non-linear functions (e.g. `ReLU(x) = max(0, x)`). It&#x27;s this sprinkling of non-linearity that allows the networks to be able to model complex functions.<p>However, from my perspective, the secret sauce is (1) composability and (2) differentiability. These enable the backpropagation process (which is just &quot;the chain rule&quot; from calculus) and this is what allows these massive mathematical expressions to learn parameters (weights and biases) that perform well.</div><br/></div></div><div id="35706716" class="c"><input type="checkbox" id="c-35706716" checked=""/><div class="controls bullet"><span class="by">pedrosorio</span><span>|</span><a href="#35705196">parent</a><span>|</span><a href="#35707349">prev</a><span>|</span><a href="#35708665">next</a><span>|</span><label class="collapse" for="c-35706716">[-]</label><label class="expand" for="c-35706716">[2 more]</label></div><br/><div class="children"><div class="content">Mentioning polynomials is a pretty poor way to explain it for two reasons:<p>- It requires some mathematical understanding so will exclude some part of the non-technical audience<p>- It is the incorrect analogy. Non-linearities in neural networks have nothing to do with polynomials. In fact, polynomial regression is a type of linear regression, and  for the most part, it sucks.<p>Also, as someone mentioned, all the “serious” alternative ML methods prior to the deep learning revolution allow modeling non linearities (even if just through modification of linear regressions, like polynomial regression).</div><br/><div id="35707904" class="c"><input type="checkbox" id="c-35707904" checked=""/><div class="controls bullet"><span class="by">_gmax0</span><span>|</span><a href="#35705196">root</a><span>|</span><a href="#35706716">parent</a><span>|</span><a href="#35708665">next</a><span>|</span><label class="collapse" for="c-35707904">[-]</label><label class="expand" for="c-35707904">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the correction. It&#x27;s been some time since I actively thought about the theory (evidently I didn&#x27;t digest it correctly the first time!).</div><br/></div></div></div></div><div id="35708665" class="c"><input type="checkbox" id="c-35708665" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#35705196">parent</a><span>|</span><a href="#35706716">prev</a><span>|</span><a href="#35706521">next</a><span>|</span><label class="collapse" for="c-35708665">[-]</label><label class="expand" for="c-35708665">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Virtually any function can be expressed by a n-th order polynomial.<p>But there are many things that are not functions.  Like circles.  And they tend to crop up a lot in the real world, no pun intended.</div><br/><div id="35709307" class="c"><input type="checkbox" id="c-35709307" checked=""/><div class="controls bullet"><span class="by">cshimmin</span><span>|</span><a href="#35705196">root</a><span>|</span><a href="#35708665">parent</a><span>|</span><a href="#35706521">next</a><span>|</span><label class="collapse" for="c-35709307">[-]</label><label class="expand" for="c-35709307">[1 more]</label></div><br/><div class="children"><div class="content">Well, technically a circle can&#x27;t be said to be a function but not for the reason you mean. A circle is a collection or a <i>set</i> of points, for example in a 2d plane, that are equidistant from a center point.<p>Probably what you are trying to say is that &quot;a circle is not the image of a function&quot;, but that is also not true. You&#x27;re assuming since in cartesian coordinates you can solve for y = +&#x2F;- sqrt(R^2 - x^2), the fact that y is multi-valued means it&#x27;s not a function. This is what they teach in highschool pre-calculus anyway.<p>But for example, we can associate the points on a circle with the image of the function e^{i theta}. Or equivalently, with the R^2-valued function f(theta) = (cos(theta), sin(theta)).</div><br/></div></div></div></div><div id="35706521" class="c"><input type="checkbox" id="c-35706521" checked=""/><div class="controls bullet"><span class="by">teruakohatu</span><span>|</span><a href="#35705196">parent</a><span>|</span><a href="#35708665">prev</a><span>|</span><a href="#35705369">next</a><span>|</span><label class="collapse" for="c-35706521">[-]</label><label class="expand" for="c-35706521">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Whereas prior, methods (e.g. PCA) could only model linear relationships,<p>Prior methods also allowed modelling of non-linear relationships, eg. Random Forests.</div><br/></div></div><div id="35705369" class="c"><input type="checkbox" id="c-35705369" checked=""/><div class="controls bullet"><span class="by">jacksnipe</span><span>|</span><a href="#35705196">parent</a><span>|</span><a href="#35706521">prev</a><span>|</span><label class="collapse" for="c-35705369">[-]</label><label class="expand" for="c-35705369">[3 more]</label></div><br/><div class="children"><div class="content">Except gradient descent is about as far from brute force as it gets</div><br/><div id="35705517" class="c"><input type="checkbox" id="c-35705517" checked=""/><div class="controls bullet"><span class="by">_gmax0</span><span>|</span><a href="#35705196">root</a><span>|</span><a href="#35705369">parent</a><span>|</span><label class="collapse" for="c-35705517">[-]</label><label class="expand" for="c-35705517">[2 more]</label></div><br/><div class="children"><div class="content">Sure, under the assumption that your parameter space is convex.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>