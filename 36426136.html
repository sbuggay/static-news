<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1687424459210" as="style"/><link rel="stylesheet" href="styles.css?v=1687424459210"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2305.20030">Tree-Ring Watermark: Invisible Robust Fingerprints of Diffusion Images</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>anjel</span> | <span>38 comments</span></div><br/><div><div id="36427329" class="c"><input type="checkbox" id="c-36427329" checked=""/><div class="controls bullet"><span class="by">pdntspa</span><span>|</span><a href="#36426555">next</a><span>|</span><label class="collapse" for="c-36427329">[-]</label><label class="expand" for="c-36427329">[11 more]</label></div><br/><div class="children"><div class="content">And, once again, people seek to add additional, unnecessary steps and abstractions to perfectly fine processes, because of contrived bullshit (&quot;copyright!&quot;)<p>Stop abstracting input away from output. Attribution here is a fools errand built on overbearing, unjust, and misinterpreted concerns over copyright, the relevance of which have yet to be proven in a legal sense. This is going to give The Man yet another way to suppress actors they don&#x27;t like.<p>Repeat it with me, folks: YOU CANNOT CONTROL THAT WHICH HAS BEEN RELEASED TO THE PUBLIC. If you do not want things (people&#x2F;their agents) to perceive your works, then keep them private.</div><br/><div id="36428678" class="c"><input type="checkbox" id="c-36428678" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#36427329">parent</a><span>|</span><a href="#36428255">next</a><span>|</span><label class="collapse" for="c-36428678">[-]</label><label class="expand" for="c-36428678">[1 more]</label></div><br/><div class="children"><div class="content">On the contrary — copyrighted data industry(?) is quickly converging into copyright by appearance and not by provenance or by means. The dataset problem is kind of forgiven, but regurgitation problem continues to exist.<p>I think copyright as understood in IT is a bit of marsupials, that copyright is considered a property inherited by exact copies and intentional reconstructions. The criteria used in the real world is similar, but slightly different.<p>Also, this is going to be tone policing, but raging don’t make you right. If anything, it’ll do opposite of that.</div><br/></div></div><div id="36428255" class="c"><input type="checkbox" id="c-36428255" checked=""/><div class="controls bullet"><span class="by">gpvos</span><span>|</span><a href="#36427329">parent</a><span>|</span><a href="#36428678">prev</a><span>|</span><a href="#36428624">next</a><span>|</span><label class="collapse" for="c-36428255">[-]</label><label class="expand" for="c-36428255">[8 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t care about copyright one iota, but this may be useful in distinguishing fake images from real photos.</div><br/><div id="36428552" class="c"><input type="checkbox" id="c-36428552" checked=""/><div class="controls bullet"><span class="by">TheBrokenRail</span><span>|</span><a href="#36427329">root</a><span>|</span><a href="#36428255">parent</a><span>|</span><a href="#36428352">next</a><span>|</span><label class="collapse" for="c-36428552">[-]</label><label class="expand" for="c-36428552">[2 more]</label></div><br/><div class="children"><div class="content">People generating fake photos will just use an AI that doesn&#x27;t leave a watermark. We are quickly approaching the point at which AI-generated and real images just cannot be distinguished, and we&#x27;re going to have to adapt to that.</div><br/><div id="36429416" class="c"><input type="checkbox" id="c-36429416" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#36427329">root</a><span>|</span><a href="#36428552">parent</a><span>|</span><a href="#36428352">next</a><span>|</span><label class="collapse" for="c-36429416">[-]</label><label class="expand" for="c-36429416">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s value is raising the bar of difficulty, even if you don&#x27;t make it completely impossible.</div><br/></div></div></div></div><div id="36428352" class="c"><input type="checkbox" id="c-36428352" checked=""/><div class="controls bullet"><span class="by">justinjlynn</span><span>|</span><a href="#36427329">root</a><span>|</span><a href="#36428255">parent</a><span>|</span><a href="#36428552">prev</a><span>|</span><a href="#36428624">next</a><span>|</span><label class="collapse" for="c-36428352">[-]</label><label class="expand" for="c-36428352">[5 more]</label></div><br/><div class="children"><div class="content">All photos are edited in their taking. As such, all images represent a &quot;fake&quot; reality. The only difference between an AI &quot;fake&quot; image and photograph is the camera.</div><br/><div id="36428487" class="c"><input type="checkbox" id="c-36428487" checked=""/><div class="controls bullet"><span class="by">Tepix</span><span>|</span><a href="#36427329">root</a><span>|</span><a href="#36428352">parent</a><span>|</span><a href="#36428624">next</a><span>|</span><label class="collapse" for="c-36428487">[-]</label><label class="expand" for="c-36428487">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a lonely hill to die on..</div><br/><div id="36429586" class="c"><input type="checkbox" id="c-36429586" checked=""/><div class="controls bullet"><span class="by">bandrami</span><span>|</span><a href="#36427329">root</a><span>|</span><a href="#36428487">parent</a><span>|</span><a href="#36428899">next</a><span>|</span><label class="collapse" for="c-36429586">[-]</label><label class="expand" for="c-36429586">[1 more]</label></div><br/><div class="children"><div class="content">No, it&#x27;s a point people forget. Even 20 years ago people were asking &quot;is this photo photoshopped?&quot;, but if you&#x27;re viewing it on a webpage, it has absolutely been photoshopped. The problem is we aren&#x27;t good at specifying what we mean by &quot;photoshopped&quot;. Any photo you view has been digitally altered, getting more specific gets into the alterer&#x27;s intent which gets really messy really quick.</div><br/></div></div><div id="36428899" class="c"><input type="checkbox" id="c-36428899" checked=""/><div class="controls bullet"><span class="by">parineum</span><span>|</span><a href="#36427329">root</a><span>|</span><a href="#36428487">parent</a><span>|</span><a href="#36429586">prev</a><span>|</span><a href="#36428886">next</a><span>|</span><label class="collapse" for="c-36428899">[-]</label><label class="expand" for="c-36428899">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a rather extreme view but there is a lot that can be done with photography that can be very misleading. If you see a photo that seems incredible, it might be. People&#x27;s general skepticism of photos is too low, AI might bring that skepticism a bit higher which I think would be a good thing.<p>You can think of a photo like a news article, the author can be completely truthful while omitting certain facts to give a false impression. The same can be done with how a photo is framed, cropped and processed.<p>The intent of a photographer can definitely be translated into the photograph or it wouldn&#x27;t be an artform.</div><br/></div></div><div id="36428886" class="c"><input type="checkbox" id="c-36428886" checked=""/><div class="controls bullet"><span class="by">A4ET8a8uTh0</span><span>|</span><a href="#36427329">root</a><span>|</span><a href="#36428487">parent</a><span>|</span><a href="#36428899">prev</a><span>|</span><a href="#36428624">next</a><span>|</span><label class="collapse" for="c-36428886">[-]</label><label class="expand" for="c-36428886">[1 more]</label></div><br/><div class="children"><div class="content">&lt;&lt; As such, all images represent a &quot;fake&quot; reality.<p>Parent may not be expressing it right, but he does have a point. There is a level of &#x27;interpretation&#x27; that is being done during the taking of a picture. If you add to this recent attempts to incorporate AI into picture taking to add&#x2F;remove parts thereof all of a sudden parent&#x27;s proposition does not sound so far fetched.<p>Granted, it is still a different level than just generating an image from a prompt, but I would not dismiss the thought outright.</div><br/></div></div></div></div></div></div></div></div><div id="36428624" class="c"><input type="checkbox" id="c-36428624" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#36427329">parent</a><span>|</span><a href="#36428255">prev</a><span>|</span><a href="#36426555">next</a><span>|</span><label class="collapse" for="c-36428624">[-]</label><label class="expand" for="c-36428624">[1 more]</label></div><br/><div class="children"><div class="content">It won&#x27;t even work for copyright, that is a legal process not a technical one,  for which rights and limitations exists independently of the medium.</div><br/></div></div></div></div><div id="36426555" class="c"><input type="checkbox" id="c-36426555" checked=""/><div class="controls bullet"><span class="by">BugsJustFindMe</span><span>|</span><a href="#36427329">prev</a><span>|</span><a href="#36426286">next</a><span>|</span><label class="collapse" for="c-36426555">[-]</label><label class="expand" for="c-36426555">[8 more]</label></div><br/><div class="children"><div class="content">&gt; <i>the watermark signal is detected by inverting the diffusion process</i><p>Which, by definition, requires you to know in advance the exact process and parameters that were used? That seems untenable.</div><br/><div id="36426682" class="c"><input type="checkbox" id="c-36426682" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#36426555">parent</a><span>|</span><a href="#36426286">next</a><span>|</span><label class="collapse" for="c-36426682">[-]</label><label class="expand" for="c-36426682">[7 more]</label></div><br/><div class="children"><div class="content">That seems to be the point. Sure, anyone can inject their own noise into the initial image, but the best place to be for that would be the people hosting the model. A host could watermark their service and be able to identify images that they&#x27;d produced down the line in a way that the end user can&#x27;t remove and can&#x27;t perceive.</div><br/><div id="36426934" class="c"><input type="checkbox" id="c-36426934" checked=""/><div class="controls bullet"><span class="by">BugsJustFindMe</span><span>|</span><a href="#36426555">root</a><span>|</span><a href="#36426682">parent</a><span>|</span><a href="#36426286">next</a><span>|</span><label class="collapse" for="c-36426934">[-]</label><label class="expand" for="c-36426934">[6 more]</label></div><br/><div class="children"><div class="content">&quot;I need to protect the copyright of my AI generated image&quot; is some big lol thought process. If that&#x27;s all this is then it&#x27;s not nearly as useful as claimed.</div><br/><div id="36426974" class="c"><input type="checkbox" id="c-36426974" checked=""/><div class="controls bullet"><span class="by">singleshot_</span><span>|</span><a href="#36426555">root</a><span>|</span><a href="#36426934">parent</a><span>|</span><a href="#36427311">next</a><span>|</span><label class="collapse" for="c-36426974">[-]</label><label class="expand" for="c-36426974">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it seems like exactly the wrong thing to be watermarking. I&#x27;d much prefer to be able to verify that something was human-generated, but of course that ship has sailed.</div><br/></div></div><div id="36427311" class="c"><input type="checkbox" id="c-36427311" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#36426555">root</a><span>|</span><a href="#36426934">parent</a><span>|</span><a href="#36426974">prev</a><span>|</span><a href="#36427151">next</a><span>|</span><label class="collapse" for="c-36427311">[-]</label><label class="expand" for="c-36427311">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s to trace down abuse.<p>People using products for fraud, defamation, illegal categories of porn, etc.</div><br/><div id="36428322" class="c"><input type="checkbox" id="c-36428322" checked=""/><div class="controls bullet"><span class="by">onion2k</span><span>|</span><a href="#36426555">root</a><span>|</span><a href="#36427311">parent</a><span>|</span><a href="#36427151">next</a><span>|</span><label class="collapse" for="c-36428322">[-]</label><label class="expand" for="c-36428322">[2 more]</label></div><br/><div class="children"><div class="content">I would be very surprised if a company running a generative AI app wanted to be able to prove someone made illegal porn with it. I&#x27;d have thought they&#x27;d want people to believe that wasn&#x27;t possible on their platform.</div><br/><div id="36428389" class="c"><input type="checkbox" id="c-36428389" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#36426555">root</a><span>|</span><a href="#36428322">parent</a><span>|</span><a href="#36427151">next</a><span>|</span><label class="collapse" for="c-36428389">[-]</label><label class="expand" for="c-36428389">[1 more]</label></div><br/><div class="children"><div class="content">In a world where other startups can attribute outputs to particular tools, it&#x27;d be better to be able to show the database record, payment details, and IP address of those creating bad content.<p>You can internally investigate and see what users are doing to escape the guardrails. There&#x27;s probably lots of legal but definitely juvenile and borderline offensive content that could also be studied.<p>There are even non-abuse analytical reasons for wanting this. If you sample the social media deluge for your watermarks, you could see how far your tool spreads and in which user clusters.</div><br/></div></div></div></div></div></div><div id="36427151" class="c"><input type="checkbox" id="c-36427151" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#36426555">root</a><span>|</span><a href="#36426934">parent</a><span>|</span><a href="#36427311">prev</a><span>|</span><a href="#36426286">next</a><span>|</span><label class="collapse" for="c-36427151">[-]</label><label class="expand" for="c-36427151">[1 more]</label></div><br/><div class="children"><div class="content">Didn&#x27;t say anything about copyright, in the US at least that&#x27;s already been ruled on saying that the raw output of one of these models is not copyrightable. Being able to trace something back to a service can be useful anyway. Imagine stuffing metadata in there, such as the prompt or the identity of the user who generated it. It&#x27;d be a powerful tool to combat everything from generated CSAM to political disinformation. If nothing else, a nice ghost story to tell the AI kiddies around the campfire.</div><br/></div></div></div></div></div></div></div></div><div id="36426286" class="c"><input type="checkbox" id="c-36426286" checked=""/><div class="controls bullet"><span class="by">davideg</span><span>|</span><a href="#36426555">prev</a><span>|</span><a href="#36427906">next</a><span>|</span><label class="collapse" for="c-36426286">[-]</label><label class="expand" for="c-36426286">[1 more]</label></div><br/><div class="children"><div class="content">GitHub repo with code: <a href="https:&#x2F;&#x2F;github.com&#x2F;YuxinWenRick&#x2F;tree-ring-watermark">https:&#x2F;&#x2F;github.com&#x2F;YuxinWenRick&#x2F;tree-ring-watermark</a></div><br/></div></div><div id="36427906" class="c"><input type="checkbox" id="c-36427906" checked=""/><div class="controls bullet"><span class="by">esjeon</span><span>|</span><a href="#36426286">prev</a><span>|</span><a href="#36426312">next</a><span>|</span><label class="collapse" for="c-36427906">[-]</label><label class="expand" for="c-36427906">[2 more]</label></div><br/><div class="children"><div class="content">I wonder how deep watermarks would perform against attacks using Image2Image. Running an image through I2I as-is would be able to destroy the watermark with minimal&#x2F;minor changes, and out-painting may significantly impact certain watermarking methods by wrapping images with random contents.</div><br/><div id="36428596" class="c"><input type="checkbox" id="c-36428596" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#36427906">parent</a><span>|</span><a href="#36426312">next</a><span>|</span><label class="collapse" for="c-36428596">[-]</label><label class="expand" for="c-36428596">[1 more]</label></div><br/><div class="children"><div class="content">With control net guidance it&#x27;s going to be even easier to maintain the image extracting the idea from the noise</div><br/></div></div></div></div><div id="36426312" class="c"><input type="checkbox" id="c-36426312" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#36427906">prev</a><span>|</span><a href="#36428157">next</a><span>|</span><label class="collapse" for="c-36426312">[-]</label><label class="expand" for="c-36426312">[7 more]</label></div><br/><div class="children"><div class="content">Nice. If the work holds up to scrutiny, it&#x27;s immediately useful for many.</div><br/><div id="36427663" class="c"><input type="checkbox" id="c-36427663" checked=""/><div class="controls bullet"><span class="by">thot_experiment</span><span>|</span><a href="#36426312">parent</a><span>|</span><a href="#36426499">next</a><span>|</span><label class="collapse" for="c-36427663">[-]</label><label class="expand" for="c-36427663">[2 more]</label></div><br/><div class="children"><div class="content">also like... why would I voluntarily watermark my images that I want to pass off as &quot;real art&quot; (my personal stance is that AI art is absolutely real art)</div><br/><div id="36428017" class="c"><input type="checkbox" id="c-36428017" checked=""/><div class="controls bullet"><span class="by">prox</span><span>|</span><a href="#36426312">root</a><span>|</span><a href="#36427663">parent</a><span>|</span><a href="#36426499">next</a><span>|</span><label class="collapse" for="c-36428017">[-]</label><label class="expand" for="c-36428017">[1 more]</label></div><br/><div class="children"><div class="content">I would argue that AI works are expressions like a poem or a song. The word “art” has a diluted meaning, it means everything and nothing in common parlance. “Real” art has to have certain attributes like a certain timelessness and character, something that can only be really be ascertained after a certain time has passed.<p>I feel that if you never studied art or never really learned or did the effort on studying it, and gone to the processes of art creation, most people probably aren’t making art. It still can be beautiful, creative, meaningful but “real” art, something that adds to the cultural lexicon, probably not.<p>The book “But is it art?” by Cynthia Freeland I can recommend.</div><br/></div></div></div></div><div id="36426499" class="c"><input type="checkbox" id="c-36426499" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36426312">parent</a><span>|</span><a href="#36427663">prev</a><span>|</span><a href="#36428157">next</a><span>|</span><label class="collapse" for="c-36426499">[-]</label><label class="expand" for="c-36426499">[4 more]</label></div><br/><div class="children"><div class="content">Who?</div><br/><div id="36426677" class="c"><input type="checkbox" id="c-36426677" checked=""/><div class="controls bullet"><span class="by">chii</span><span>|</span><a href="#36426312">root</a><span>|</span><a href="#36426499">parent</a><span>|</span><a href="#36428157">next</a><span>|</span><label class="collapse" for="c-36426677">[-]</label><label class="expand" for="c-36426677">[3 more]</label></div><br/><div class="children"><div class="content">People who want to treat AI generated works differently, even tho by objective examination, it is not differentiable from a man made one.</div><br/><div id="36426826" class="c"><input type="checkbox" id="c-36426826" checked=""/><div class="controls bullet"><span class="by">ptero</span><span>|</span><a href="#36426312">root</a><span>|</span><a href="#36426677">parent</a><span>|</span><a href="#36427392">next</a><span>|</span><label class="collapse" for="c-36426826">[-]</label><label class="expand" for="c-36426826">[1 more]</label></div><br/><div class="children"><div class="content">The sister thread notes that this requires inverting the process, so it is likely only useful to those hosting the particular AI model; not an outside person who wants to check if a specific image is AI generated.</div><br/></div></div><div id="36427392" class="c"><input type="checkbox" id="c-36427392" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#36426312">root</a><span>|</span><a href="#36426677">parent</a><span>|</span><a href="#36426826">prev</a><span>|</span><a href="#36428157">next</a><span>|</span><label class="collapse" for="c-36427392">[-]</label><label class="expand" for="c-36427392">[1 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t work for that purpose because nothing mandates that AI-generated works be watermarked, and latent diffusion models are easily run on a desktop GPU now.</div><br/></div></div></div></div></div></div></div></div><div id="36428157" class="c"><input type="checkbox" id="c-36428157" checked=""/><div class="controls bullet"><span class="by">altairprime</span><span>|</span><a href="#36426312">prev</a><span>|</span><a href="#36427127">next</a><span>|</span><label class="collapse" for="c-36428157">[-]</label><label class="expand" for="c-36428157">[1 more]</label></div><br/><div class="children"><div class="content">Is the watermark carried forward through — that is, expressed in the subsequent output of — a diffusion kernel trained on watermarked images?</div><br/></div></div><div id="36427127" class="c"><input type="checkbox" id="c-36427127" checked=""/><div class="controls bullet"><span class="by">classicmotto</span><span>|</span><a href="#36428157">prev</a><span>|</span><a href="#36426750">next</a><span>|</span><label class="collapse" for="c-36427127">[-]</label><label class="expand" for="c-36427127">[5 more]</label></div><br/><div class="children"><div class="content">So just blurring the image and resharpening using AI can remove the watermark, right? Asking just in case i need to steal some AI generated artwork few years down the line.</div><br/><div id="36427437" class="c"><input type="checkbox" id="c-36427437" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#36427127">parent</a><span>|</span><a href="#36426750">next</a><span>|</span><label class="collapse" for="c-36427437">[-]</label><label class="expand" for="c-36427437">[4 more]</label></div><br/><div class="children"><div class="content">No need, AI generated imagery isn&#x27;t copyrightable.</div><br/><div id="36427654" class="c"><input type="checkbox" id="c-36427654" checked=""/><div class="controls bullet"><span class="by">thot_experiment</span><span>|</span><a href="#36427127">root</a><span>|</span><a href="#36427437">parent</a><span>|</span><a href="#36426750">next</a><span>|</span><label class="collapse" for="c-36427654">[-]</label><label class="expand" for="c-36427654">[3 more]</label></div><br/><div class="children"><div class="content">incorrect, AI generated imagery has weaker copyright protections as of right now, but there is limited precedent, this stuff will need to be argued up and down the courts before we know exactly how copyrightable it is (but it&#x27;s absolutely not zero)<p>fwiw i think copyright should be greatly weakened in general, just correcting you on the facts</div><br/><div id="36429410" class="c"><input type="checkbox" id="c-36429410" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#36427127">root</a><span>|</span><a href="#36427654">parent</a><span>|</span><a href="#36427810">next</a><span>|</span><label class="collapse" for="c-36429410">[-]</label><label class="expand" for="c-36429410">[1 more]</label></div><br/><div class="children"><div class="content">? Anything might happen in the future, but the <i>current</i> guidance is not ambiguous.<p><a href="https:&#x2F;&#x2F;www.copyright.gov&#x2F;ai&#x2F;ai_policy_guidance.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.copyright.gov&#x2F;ai&#x2F;ai_policy_guidance.pdf</a><p>(It’s not copyrightable in the US)<p>&gt; fwiw i think<p>Doesn’t really seem relevant, legally speaking, and unless there’s a specific precedent you’d care to share, you are not correcting the parent post, you are simply incorrect.</div><br/></div></div><div id="36427810" class="c"><input type="checkbox" id="c-36427810" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#36427127">root</a><span>|</span><a href="#36427654">parent</a><span>|</span><a href="#36429410">prev</a><span>|</span><a href="#36426750">next</a><span>|</span><label class="collapse" for="c-36427810">[-]</label><label class="expand" for="c-36427810">[1 more]</label></div><br/><div class="children"><div class="content">As of right now it isn&#x27;t. Any legal fact is subject to change in the future pursuant to litigation or legislation.</div><br/></div></div></div></div></div></div></div></div><div id="36426750" class="c"><input type="checkbox" id="c-36426750" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#36427127">prev</a><span>|</span><label class="collapse" for="c-36426750">[-]</label><label class="expand" for="c-36426750">[2 more]</label></div><br/><div class="children"><div class="content">It’s fascinating that it’s robust to noise injections, especially lossy compression and blurring. I suppose it makes sense given the latent space water mark presumably makes global changes to the significant features even if imperceptible. It feels like this might be possible to use as a upscaling technique to inject the watermark into existing photographs without directly manipulating the photographic content.</div><br/><div id="36426997" class="c"><input type="checkbox" id="c-36426997" checked=""/><div class="controls bullet"><span class="by">XorNot</span><span>|</span><a href="#36426750">parent</a><span>|</span><label class="collapse" for="c-36426997">[-]</label><label class="expand" for="c-36426997">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m skeptical this survives very long: these diffusor systems <i>are</i> noise removal systems, this is just inventing a noise injection they currently haven&#x27;t had to deal with.<p>Particularly if the idea is it leads to a big change in the latent space representation as the mode of action, the question to ask is how hard is it for another system to learn what that latent space anomaly looks like and remove it?</div><br/></div></div></div></div></div></div></div></div></div></body></html>