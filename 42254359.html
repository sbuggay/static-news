<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1732957257155" as="style"/><link rel="stylesheet" href="styles.css?v=1732957257155"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.ruliad.co/news/introducing-deepthought8b">DeepThought-8B: A small, capable reasoning model</a> <span class="domain">(<a href="https://www.ruliad.co">www.ruliad.co</a>)</span></div><div class="subtext"><span>AnhTho_FR</span> | <span>33 comments</span></div><br/><div><div id="42279732" class="c"><input type="checkbox" id="c-42279732" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#42279990">next</a><span>|</span><label class="collapse" for="c-42279732">[-]</label><label class="expand" for="c-42279732">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s been a rush of releases of reasoning models in the past couple of weeks. This one looks interesting, too.<p>I found the following video from Sam Witteveen to be a useful introduction to a few of those models:<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;vN8jBxEKkVo" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;vN8jBxEKkVo</a></div><br/></div></div><div id="42279990" class="c"><input type="checkbox" id="c-42279990" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#42279732">prev</a><span>|</span><a href="#42280450">next</a><span>|</span><label class="collapse" for="c-42279990">[-]</label><label class="expand" for="c-42279990">[4 more]</label></div><br/><div class="children"><div class="content">A bit off-topic, but that comparison graph is a great example why you should buy your designer a cheap secondary screen. I was viewing it on my second monitor and had to lean in to make out the off-white bar for Model D on the light-grey background. Moved the window over to my main screen and it&#x27;s clear as day, five nice shades of coffee on a light-gray background.</div><br/><div id="42280378" class="c"><input type="checkbox" id="c-42280378" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#42279990">parent</a><span>|</span><a href="#42280073">next</a><span>|</span><label class="collapse" for="c-42280378">[-]</label><label class="expand" for="c-42280378">[1 more]</label></div><br/><div class="children"><div class="content">The body text is also quite hard to read because the font has a tall x-height and line spacing is very tight.<p>This makes paragraphs look very dense, almost like it was set in uppercase only, because the lowercase letters don’t create a varying flow between lines for the eye to follow.<p>The model may be good, but the web design doesn’t win any prizes.</div><br/></div></div><div id="42280073" class="c"><input type="checkbox" id="c-42280073" checked=""/><div class="controls bullet"><span class="by">peterkos</span><span>|</span><a href="#42279990">parent</a><span>|</span><a href="#42280378">prev</a><span>|</span><a href="#42280026">next</a><span>|</span><label class="collapse" for="c-42280073">[-]</label><label class="expand" for="c-42280073">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a pretty egregious mistake for a designer to make -- and that&#x27;s not even mentioning the lack of accessibility. WebAIM&#x27;s contrast checker says it&#x27;s a 1:1 contrast ratio!<p>If someone is releasing a model that claims to have a level of reasoning, one would <i>hope</i> that their training dataset was scrutinized and monitored for unintended bias (as any statistical dataset is susceptible to: see overfitting). But if the graph on the announcement page is literally unreadable to seemingly anyone but the creator... that&#x27;s damning proof that there is little empathy in the process, no?</div><br/></div></div><div id="42280026" class="c"><input type="checkbox" id="c-42280026" checked=""/><div class="controls bullet"><span class="by">AYBABTME</span><span>|</span><a href="#42279990">parent</a><span>|</span><a href="#42280073">prev</a><span>|</span><a href="#42280450">next</a><span>|</span><label class="collapse" for="c-42280026">[-]</label><label class="expand" for="c-42280026">[1 more]</label></div><br/><div class="children"><div class="content">Even on a high quality screen, it&#x27;s a bit much.</div><br/></div></div></div></div><div id="42280450" class="c"><input type="checkbox" id="c-42280450" checked=""/><div class="controls bullet"><span class="by">chvid</span><span>|</span><a href="#42279990">prev</a><span>|</span><a href="#42280186">next</a><span>|</span><label class="collapse" for="c-42280450">[-]</label><label class="expand" for="c-42280450">[1 more]</label></div><br/><div class="children"><div class="content">Is the source code available for this? And who is behind the company?</div><br/></div></div><div id="42280186" class="c"><input type="checkbox" id="c-42280186" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#42280450">prev</a><span>|</span><a href="#42280207">next</a><span>|</span><label class="collapse" for="c-42280186">[-]</label><label class="expand" for="c-42280186">[1 more]</label></div><br/><div class="children"><div class="content">In what way did they &quot;release&quot; this? I can&#x27;t find it in hugging face or ollama, and they only seem to have a &quot;try online&quot; link in the article. &quot;Self-sovereign intelligence&quot;, indeed.</div><br/></div></div><div id="42280207" class="c"><input type="checkbox" id="c-42280207" checked=""/><div class="controls bullet"><span class="by">lowyek</span><span>|</span><a href="#42280186">prev</a><span>|</span><a href="#42280169">next</a><span>|</span><label class="collapse" for="c-42280207">[-]</label><label class="expand" for="c-42280207">[3 more]</label></div><br/><div class="children"><div class="content">I asked it &#x27;find two primes whose sum is 123&#x27; .. it is in deep thought from 5 minutes just looping and looping over seemingly repeated hallucinations of right path. (btw, chatgpt immediately answers 61 and 62 lol.. so much for intelligence)</div><br/><div id="42280458" class="c"><input type="checkbox" id="c-42280458" checked=""/><div class="controls bullet"><span class="by">utdiscant</span><span>|</span><a href="#42280207">parent</a><span>|</span><a href="#42280169">next</a><span>|</span><label class="collapse" for="c-42280458">[-]</label><label class="expand" for="c-42280458">[2 more]</label></div><br/><div class="children"><div class="content">Here is what I got from o1:<p>To find two prime numbers that sum to 123, let’s consider the properties of prime numbers and the nature of their sums:
 1. Prime Numbers Greater Than 2 Are Odd: Except for 2, all prime numbers are odd.
 2. Sum of Two Odd Numbers Is Even: Adding two odd numbers results in an even number.
 3. Sum of an Even and an Odd Number Is Odd: Adding an even number (like 2) and an odd number results in an odd sum.<p>Given that 123 is an odd number, the only way two primes can sum to 123 is if one of them is 2 (the only even prime) and the other is an odd prime. Let’s test this possibility:
 • 2 + x = 123 ⇒ x = 121<p>However, 121 is not a prime number (since  ).<p>Next, consider the possibility of adding two odd primes:
 • Odd Prime + Odd Prime = Even Number<p>Since adding two odd primes yields an even number, it’s impossible for two odd primes to sum to 123 (an odd number).<p>Conclusion: There are no two prime numbers that sum to 123.<p>Answer: There are no two prime numbers whose sum is 123; such primes do not exist.</div><br/><div id="42280472" class="c"><input type="checkbox" id="c-42280472" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#42280207">root</a><span>|</span><a href="#42280458">parent</a><span>|</span><a href="#42280169">next</a><span>|</span><label class="collapse" for="c-42280472">[-]</label><label class="expand" for="c-42280472">[1 more]</label></div><br/><div class="children"><div class="content">Well explained!</div><br/></div></div></div></div></div></div><div id="42280169" class="c"><input type="checkbox" id="c-42280169" checked=""/><div class="controls bullet"><span class="by">jb_briant</span><span>|</span><a href="#42280207">prev</a><span>|</span><a href="#42280013">next</a><span>|</span><label class="collapse" for="c-42280169">[-]</label><label class="expand" for="c-42280169">[7 more]</label></div><br/><div class="children"><div class="content">Am I wrong to think that &quot;reasoning model&quot; is a misleading marketing term?<p>Isn&#x27;t it a LLM with an algo wrapper?</div><br/><div id="42280408" class="c"><input type="checkbox" id="c-42280408" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#42280169">parent</a><span>|</span><a href="#42280245">next</a><span>|</span><label class="collapse" for="c-42280408">[-]</label><label class="expand" for="c-42280408">[1 more]</label></div><br/><div class="children"><div class="content">&quot;reasoning model&quot; means nothing so I don&#x27;t think it&#x27;s misleading.</div><br/></div></div><div id="42280245" class="c"><input type="checkbox" id="c-42280245" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#42280169">parent</a><span>|</span><a href="#42280408">prev</a><span>|</span><a href="#42280256">next</a><span>|</span><label class="collapse" for="c-42280245">[-]</label><label class="expand" for="c-42280245">[4 more]</label></div><br/><div class="children"><div class="content">Whether you bake the behaviour in or wrap it in an external loop, you need to train&#x2F;tune the expected behaviour. Generic models can do chain of thought if asked for, but will be worse than the specialised one.</div><br/><div id="42280261" class="c"><input type="checkbox" id="c-42280261" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42280169">root</a><span>|</span><a href="#42280245">parent</a><span>|</span><a href="#42280256">next</a><span>|</span><label class="collapse" for="c-42280261">[-]</label><label class="expand" for="c-42280261">[3 more]</label></div><br/><div class="children"><div class="content">They&#x27;re not baking anything in. Reasoning, as it is defined by AI marketing departments, is just beam search.</div><br/><div id="42280289" class="c"><input type="checkbox" id="c-42280289" checked=""/><div class="controls bullet"><span class="by">jb_briant</span><span>|</span><a href="#42280169">root</a><span>|</span><a href="#42280261">parent</a><span>|</span><a href="#42280256">next</a><span>|</span><label class="collapse" for="c-42280289">[-]</label><label class="expand" for="c-42280289">[2 more]</label></div><br/><div class="children"><div class="content">Could you educate me on what is beam search ? Or link a good ressource<p>EDIT: <a href="https:&#x2F;&#x2F;www.width.ai&#x2F;post&#x2F;what-is-beam-search" rel="nofollow">https:&#x2F;&#x2F;www.width.ai&#x2F;post&#x2F;what-is-beam-search</a><p>So the wider the beam, the better the outcome?<p>Yep, no reasoning, just a marketing term to say 
&quot;more accurate probabilities&quot;</div><br/><div id="42280432" class="c"><input type="checkbox" id="c-42280432" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42280169">root</a><span>|</span><a href="#42280289">parent</a><span>|</span><a href="#42280256">next</a><span>|</span><label class="collapse" for="c-42280432">[-]</label><label class="expand" for="c-42280432">[1 more]</label></div><br/><div class="children"><div class="content">Beam search just traverses different paths and assigns each path a probability of being correct. The paths with the higher probabilities are kept and the ones with lower probabilities are pruned until the search terminates with an &quot;answer&quot;. The marketing department calls it &quot;reasoning&quot; and &quot;test-time compute&quot; because the average consumer does not care whether it&#x27;s beam search or something else.<p>Your link seems to do a good job of explaining beam search but it&#x27;s a classic algorithm in state space exploration so any book on algorithms will have a section about it.</div><br/></div></div></div></div></div></div></div></div><div id="42280256" class="c"><input type="checkbox" id="c-42280256" checked=""/><div class="controls bullet"><span class="by">benchmarkist</span><span>|</span><a href="#42280169">parent</a><span>|</span><a href="#42280245">prev</a><span>|</span><a href="#42280013">next</a><span>|</span><label class="collapse" for="c-42280256">[-]</label><label class="expand" for="c-42280256">[1 more]</label></div><br/><div class="children"><div class="content">AI marketing departments are fond of anthropomorphic language but it&#x27;s actually just regular beam search.</div><br/></div></div></div></div><div id="42280013" class="c"><input type="checkbox" id="c-42280013" checked=""/><div class="controls bullet"><span class="by">kgeist</span><span>|</span><a href="#42280169">prev</a><span>|</span><a href="#42280248">next</a><span>|</span><label class="collapse" for="c-42280013">[-]</label><label class="expand" for="c-42280013">[12 more]</label></div><br/><div class="children"><div class="content">Not bad, asked it to count Rs in &quot;strawberry&quot; and Ns in &quot;international&quot;, it answered correctly, and it was fast.</div><br/><div id="42280214" class="c"><input type="checkbox" id="c-42280214" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#42280013">parent</a><span>|</span><a href="#42280074">next</a><span>|</span><label class="collapse" for="c-42280214">[-]</label><label class="expand" for="c-42280214">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s still not quite perfect at letter counting, but it handles questions like &quot;which is heavier? 2kg of feathers or 1kg of lead&quot; really well. The reasoning steps seem to prevent it from jumping to pattern-matched answers</div><br/><div id="42280255" class="c"><input type="checkbox" id="c-42280255" checked=""/><div class="controls bullet"><span class="by">jb_briant</span><span>|</span><a href="#42280013">root</a><span>|</span><a href="#42280214">parent</a><span>|</span><a href="#42280074">next</a><span>|</span><label class="collapse" for="c-42280255">[-]</label><label class="expand" for="c-42280255">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get why this question is relevant to evaluate the reasoning capacity. Gpt4o (no reasoning in an anthropomorphic sense) answers correctly<p>---
The reasoning lies in the concept of mass and weight. The weight of an object is determined by its mass, not its material.<p>1. Mass comparison:<p>2kg of feathers has a mass of 2 kilograms.<p>1kg of lead has a mass of 1 kilogram.<p>Since 2 kilograms is greater than 1 kilogram, the feathers are heavier.<p>2. Irrelevance of material:<p>The type of material (feathers or lead) does not change the mass measurement.<p>Lead is denser than feathers, so 1kg of lead takes up much less space than 2kg of feathers, but the weight is still based on the total mass.<p>Thus, 2kg of any substance, even something as light as feathers, is heavier than 1kg of a dense material like lead.</div><br/><div id="42280341" class="c"><input type="checkbox" id="c-42280341" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#42280013">root</a><span>|</span><a href="#42280255">parent</a><span>|</span><a href="#42280074">next</a><span>|</span><label class="collapse" for="c-42280341">[-]</label><label class="expand" for="c-42280341">[1 more]</label></div><br/><div class="children"><div class="content">Large models have no issues with this question at all. Even llama-70B can handle it without issues, and that is a lot smaller than GPT-4o. But for small models this is a challenging question. llama-8B gets it confidently wrong 4 out of 5 times. gemma-2-9B gets it wrong pretty much every time. quen-coder-7B can handle it, so it&#x27;s not impossible. It&#x27;s just uncommon for small models to reliably get this question right, which is why I find it noteworthy that this model does.</div><br/></div></div></div></div></div></div><div id="42280074" class="c"><input type="checkbox" id="c-42280074" checked=""/><div class="controls bullet"><span class="by">raffraffraff</span><span>|</span><a href="#42280013">parent</a><span>|</span><a href="#42280214">prev</a><span>|</span><a href="#42280270">next</a><span>|</span><label class="collapse" for="c-42280074">[-]</label><label class="expand" for="c-42280074">[4 more]</label></div><br/><div class="children"><div class="content">I know that this is a typical test of an LLM&#x27;s ability to reason, but I wonder how much time could be saved by teaching an LLM how to recognise the type of problem that it&#x27;s inherently bad at, bundling a python interpreter and asking it to to write a short function to solve the problem? Are we not pushing a boulder uphill?</div><br/><div id="42280090" class="c"><input type="checkbox" id="c-42280090" checked=""/><div class="controls bullet"><span class="by">throwaway314155</span><span>|</span><a href="#42280013">root</a><span>|</span><a href="#42280074">parent</a><span>|</span><a href="#42280168">next</a><span>|</span><label class="collapse" for="c-42280090">[-]</label><label class="expand" for="c-42280090">[2 more]</label></div><br/><div class="children"><div class="content">&gt; teaching an LLM how to recognise the type of problem that it&#x27;s inherently bad at<p>Solving this is the actual hard part and is either adjacent to or even equivalent to solving the problem of LLM&#x27;s hallucinating. ChatGPT already includes a Python interpreter tool which can be used if the context indicates its appropriate.</div><br/><div id="42280262" class="c"><input type="checkbox" id="c-42280262" checked=""/><div class="controls bullet"><span class="by">raffraffraff</span><span>|</span><a href="#42280013">root</a><span>|</span><a href="#42280090">parent</a><span>|</span><a href="#42280168">next</a><span>|</span><label class="collapse" for="c-42280262">[-]</label><label class="expand" for="c-42280262">[1 more]</label></div><br/><div class="children"><div class="content">I suppose my question is pointing to another, which is: can one make an LLM that doesn&#x27;t hallucinate? Isn&#x27;t that problem inherent to the way that LLMs work? Obviously we can try to clean the data so there isn&#x27;t any nonsense fed into it, but that&#x27;ll only get you so far with a probabilistic, stochastic system. As an LLM once told me &quot;Some experts argue that hallucination is an innate limitation of LLMs, akin to confabulation in humans, where false memories are created without the intention to deceive&quot;. I&#x27;m not sure if I believe that though.</div><br/></div></div></div></div></div></div><div id="42280270" class="c"><input type="checkbox" id="c-42280270" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#42280013">parent</a><span>|</span><a href="#42280074">prev</a><span>|</span><a href="#42280047">next</a><span>|</span><label class="collapse" for="c-42280270">[-]</label><label class="expand" for="c-42280270">[1 more]</label></div><br/><div class="children"><div class="content">This is a bad test for reasoning. The model is either trained on the spelling of its tokens or specific words, or not. It&#x27;s not a thing reasoning would help with in any way. (Ok, maybe accidentally if it tried different splits it&#x27;s trained to spell, but that&#x27;s not the reasoning part either)</div><br/></div></div><div id="42280047" class="c"><input type="checkbox" id="c-42280047" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#42280013">parent</a><span>|</span><a href="#42280270">prev</a><span>|</span><a href="#42280248">next</a><span>|</span><label class="collapse" for="c-42280047">[-]</label><label class="expand" for="c-42280047">[3 more]</label></div><br/><div class="children"><div class="content">Does it still count correctly if you ask for variations like &quot;strawerberry&quot;?</div><br/><div id="42280189" class="c"><input type="checkbox" id="c-42280189" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#42280013">root</a><span>|</span><a href="#42280047">parent</a><span>|</span><a href="#42280248">next</a><span>|</span><label class="collapse" for="c-42280189">[-]</label><label class="expand" for="c-42280189">[2 more]</label></div><br/><div class="children"><div class="content">I found the following transcript of the thought process to that question equally enlightening and funny:<p>Thought for 4 seconds<p>1 problem understanding<p>The task is to count the number of instances of the letter &#x27;r&#x27; in the word &#x27;strawerberry&#x27;. This requires identifying each occurrence of &#x27;r&#x27; in the given word and keeping a count.<p>2 data gathering<p>The word to analyze is &#x27;strawerberry&#x27;. I need to examine each character in this word.<p>3 hypothesis formation<p>Based on a quick glance, I hypothesize that there are 2 instances of &#x27;r&#x27; in &#x27;strawerberry&#x27;.<p>4 analysis<p>Let&#x27;s break down the word into individual characters: s, t, r, a, w, e, r, b, e, r, r, y<p>5 calculation<p>Now, let&#x27;s count the &#x27;r&#x27;s: 1) First &#x27;r&#x27; at position 3, 2) Second &#x27;r&#x27; at position 7, 3) Third &#x27;r&#x27; at position 10. Total count: 3<p>6 verification<p>Double-checking the count: s(0), t(0), r(1), a(0), w(0), e(0), r(2), b(0), e(0), r(3), r(3), y(0). Confirmed: 3 instances of &#x27;r&#x27;.<p>7 error checking<p>The initial hypothesis was incorrect. The actual count (3) differs from the initial guess (2). This highlights the importance of careful analysis rather than quick assumptions.<p>8 conclusion drawing<p>The letter &#x27;r&#x27; appears 3 times in the word &#x27;strawerberry&#x27;.<p>9 implementation<p>The final response should be the number 3, as this is the correct count of &#x27;r&#x27; instances in &#x27;strawerberry&#x27;.</div><br/><div id="42280203" class="c"><input type="checkbox" id="c-42280203" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#42280013">root</a><span>|</span><a href="#42280189">parent</a><span>|</span><a href="#42280248">next</a><span>|</span><label class="collapse" for="c-42280203">[-]</label><label class="expand" for="c-42280203">[1 more]</label></div><br/><div class="children"><div class="content">I get:<p>&gt;Alright, I need to figure out how many &#x27;r&#x27;s are in the word &#x27;strawerberry&#x27;. Let&#x27;s look at it carefully. I&#x27;ll write it down: s-t-r-a-w-e-r-b-e-r-r-y. Now, I&#x27;ll go through each letter one by one.<p>&gt;Starting from the beginning: s, t, r – that&#x27;s one &#x27;r&#x27;. Then a, w, e, r – that&#x27;s the second &#x27;r&#x27;. Next, b, e, r – that&#x27;s the third &#x27;r&#x27;. And finally, another r before the y, making it the fourth &#x27;r&#x27;. So, I count four &#x27;r&#x27;s in total.<p>&gt;The word &quot;strawberry&quot; contains four &#x27;r&#x27;s.</div><br/></div></div></div></div></div></div></div></div><div id="42280248" class="c"><input type="checkbox" id="c-42280248" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#42280013">prev</a><span>|</span><a href="#42254367">next</a><span>|</span><label class="collapse" for="c-42280248">[-]</label><label class="expand" for="c-42280248">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Model A 13B&quot;, &quot;Model B 20B&quot; etc are pretty vapid claims. Which <i>actual models</i>? There are plenty of terrible high-param-count models from a year or two ago. The benchmark seems meaningless without saying what models are actually being compared against... And &quot;13B&quot; in particular is pretty sketchy: are they comparing it against <i>Llama 2 13B</i>? Even an untuned Llama 3.1 8B would destroy that in any benchmark.<p>Smells a little grifty to me...</div><br/></div></div></div></div></div></div></div></body></html>