<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735722057169" as="style"/><link rel="stylesheet" href="styles.css?v=1735722057169"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://simonwillison.net/2024/Dec/31/llms-in-2024/">Things we learned about LLMs in 2024</a> <span class="domain">(<a href="https://simonwillison.net">simonwillison.net</a>)</span></div><div class="subtext"><span>simonw</span> | <span>330 comments</span></div><br/><div><div id="42564850" class="c"><input type="checkbox" id="c-42564850" checked=""/><div class="controls bullet"><span class="by">nobodywillobsrv</span><span>|</span><a href="#42561151">next</a><span>|</span><label class="collapse" for="c-42564850">[-]</label><label class="expand" for="c-42564850">[1 more]</label></div><br/><div class="children"><div class="content">One interesting test that I see nearly all LLMs fail is coherent responses to tax questions.</div><br/></div></div><div id="42561151" class="c"><input type="checkbox" id="c-42561151" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42564850">prev</a><span>|</span><a href="#42561874">next</a><span>|</span><label class="collapse" for="c-42561151">[-]</label><label class="expand" for="c-42561151">[109 more]</label></div><br/><div class="children"><div class="content">About &quot;people still thinking LLMs are quite useless&quot;, I still believe that the problem is that most people are exposed to ChatGPT 4o that at this point for my use case (programming &#x2F; design partner) is basically a useless toy. And I guess that in tech many folks try LLMs for the same use cases. Try Claude Sonnet 3.5 (not Haiku!) and tell me if, while still flawed, is not helpful.<p>But there is more: a key thing with LLMs is that their ability to help, as a tool, changes vastly based on your communication ability. The prompt is the king to make those models 10x better than they are with the lazy one-liner question. Drop your files in the context window; ask very precise questions explaining the background. They work great to explore what is at the borders of your knowledge. They are also great at doing boring tasks for which you can provide perfect guidance (but that still would take you hours). The best LLMs (in my case <i>just</i> Claude Sonnet 3.5, I must admit) out there are able to accelerate you.</div><br/><div id="42562111" class="c"><input type="checkbox" id="c-42562111" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42561349">next</a><span>|</span><label class="collapse" for="c-42562111">[-]</label><label class="expand" for="c-42562111">[35 more]</label></div><br/><div class="children"><div class="content">I&#x27;m surprised at the description that it&#x27;s &quot;useless&quot; as a programming &#x2F; design partner. Even if it doesn&#x27;t make &quot;elegant&quot; code (whatever that means), it&#x27;s the difference between an app existing at all, or not.<p>I built and shipped a Swift app to the App Store, currently generating $10,200 in MRR, exclusively using LLMs.<p>I wouldn&#x27;t describe myself as a programmer, and didn&#x27;t plan to ever build an app, mostly because in the attempts I made, I&#x27;d get stuck and couldn&#x27;t google my way out.<p>LLMs are the great un-stickers. For that reason per se, they are incredibly useful.</div><br/><div id="42562541" class="c"><input type="checkbox" id="c-42562541" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42562283">next</a><span>|</span><label class="collapse" for="c-42562541">[-]</label><label class="expand" for="c-42562541">[14 more]</label></div><br/><div class="children"><div class="content">The context here is super-important - the commenter is the author of Redis. So, a super-experienced and productive low-level programmer. It’s not surprising that Staff-plus experts find LLMs much less useful.<p>Though I’d be interested if this was an opinion on “help me write this gnarly C algorithm” or “help me to be productive in &lt;new language&gt;” as I find a big productivity increase from the latter.</div><br/><div id="42562943" class="c"><input type="checkbox" id="c-42562943" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562541">parent</a><span>|</span><a href="#42562945">next</a><span>|</span><label class="collapse" for="c-42562943">[-]</label><label class="expand" for="c-42562943">[6 more]</label></div><br/><div class="children"><div class="content">Quick example. I was implementing dot product between two quantized vectors that have two different min&#x2F;max quantization ranges (later I changed the implementation to just centered range quantization, thanks to Claude and what I&#x27;m writing in this comment). I wanted to still have the math with the integers and adjust for the ranges at the end. Claude was able to mathematically scompose the operations as multiplication and accumulation of a sum of integers and later adjust the result, using a math trick that I didn&#x27;t know but was understandable after having seen it. This way I was able to benchmark this implementation understanding that my old centered quantization was not less precise in practice and faster (I can multiply integers without taking the sum, and later fix for the square of the range factor). I&#x27;d do it without LLMs but probably I would not try at all because of the time needed.<p>Other examples: Claude was able multiple times to spot bugs in my C code, when I asked for a code review. All bugs I would eventually find but that it&#x27;s better to fix ASAP.<p>Finally sometimes I put relevant papers and implementations and ask for variations of a given algoritm among the paper and the implementations around, to gain insights about what people do in the practice. Then engage in discussions about how to improve it. It is never able to come up with novel ideas but is able to recognize often times when my idea is flawed or if it seems sounding.<p>All this and more helps me to deliver better code. I can venture in things I otherwise would not do for lack of time.</div><br/><div id="42564353" class="c"><input type="checkbox" id="c-42564353" checked=""/><div class="controls bullet"><span class="by">beoberha</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562943">parent</a><span>|</span><a href="#42563449">next</a><span>|</span><label class="collapse" for="c-42564353">[-]</label><label class="expand" for="c-42564353">[3 more]</label></div><br/><div class="children"><div class="content">LLMs being able to detect bugs in my own code is absolutely mind blowing to me. These things are “just” predicting the next token, but somehow are able to take in code that has never been written before and somehow understand it and find what’s wrong with it.<p>I think I’m more amazed by them because I know how they work. They shouldn’t be able to do this, but the fact that they can is absolutely jaw dropping science fiction shit.</div><br/><div id="42564801" class="c"><input type="checkbox" id="c-42564801" checked=""/><div class="controls bullet"><span class="by">inciampati</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42564353">parent</a><span>|</span><a href="#42564656">next</a><span>|</span><label class="collapse" for="c-42564801">[-]</label><label class="expand" for="c-42564801">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They shouldn&#x27;t be able to do this<p>Really? ;) I guess you don&#x27;t believe in the universal approximation theorem?<p>UAT makes a strong case that by reading all of our text (aka computational traces) the models have learned a human &quot;state transition function&quot; that understands context and can integrate within it to guess the next token. Basically, by transfer learning from us they have learned to behave like universal reasoners.</div><br/></div></div><div id="42564656" class="c"><input type="checkbox" id="c-42564656" checked=""/><div class="controls bullet"><span class="by">zmgsabst</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42564353">parent</a><span>|</span><a href="#42564801">prev</a><span>|</span><a href="#42563449">next</a><span>|</span><label class="collapse" for="c-42564656">[-]</label><label class="expand" for="c-42564656">[1 more]</label></div><br/><div class="children"><div class="content">Why shouldn’t they be able to do this?<p>DNNs implicitly learn a type theory, which they then reason in. Even though the code itself is new, it’s expressible in the learned theory — so the DNN can operate on it.</div><br/></div></div></div></div><div id="42563449" class="c"><input type="checkbox" id="c-42563449" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562943">parent</a><span>|</span><a href="#42564353">prev</a><span>|</span><a href="#42562945">next</a><span>|</span><label class="collapse" for="c-42563449">[-]</label><label class="expand" for="c-42563449">[2 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; scompose the operations<p>I wonder whether that is some specialised terminology I&#x27;m not familiar with - or it just means to decompose the operations (but with an Italian s- for negation)?</div><br/><div id="42563527" class="c"><input type="checkbox" id="c-42563527" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563449">parent</a><span>|</span><a href="#42562945">next</a><span>|</span><label class="collapse" for="c-42563527">[-]</label><label class="expand" for="c-42563527">[1 more]</label></div><br/><div class="children"><div class="content">Decompose indeed :)</div><br/></div></div></div></div></div></div><div id="42562945" class="c"><input type="checkbox" id="c-42562945" checked=""/><div class="controls bullet"><span class="by">tyre</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562541">parent</a><span>|</span><a href="#42562943">prev</a><span>|</span><a href="#42562595">next</a><span>|</span><label class="collapse" for="c-42562945">[-]</label><label class="expand" for="c-42562945">[1 more]</label></div><br/><div class="children"><div class="content">antirez has written publicly, only a few weeks ago[0], about their experience working with LLMs. Partial quote:<p>&gt; And now, at the end of 2024, I’m finally seeing incredible results in the field, things that looked like sci-fi a few years ago are now possible: Claude AI is my reasoning &#x2F; editor &#x2F; coding partner lately. I’m able to accomplish a lot more than I was able to do in the past. I often do <i>more work</i> because of AI, but I do better work.<p>&gt;…<p>&gt; Basically, AI didn’t replace me, AI accelerated me or improved me with feedback about my work<p>[0]: <a href="https:&#x2F;&#x2F;antirez.com&#x2F;news&#x2F;144" rel="nofollow">https:&#x2F;&#x2F;antirez.com&#x2F;news&#x2F;144</a></div><br/></div></div><div id="42562595" class="c"><input type="checkbox" id="c-42562595" checked=""/><div class="controls bullet"><span class="by">JambalayaJimbo</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562541">parent</a><span>|</span><a href="#42562945">prev</a><span>|</span><a href="#42562696">next</a><span>|</span><label class="collapse" for="c-42562595">[-]</label><label class="expand" for="c-42562595">[2 more]</label></div><br/><div class="children"><div class="content">Why would the author of Redis describe himself as “not a programmer”? That’s a little odd.</div><br/><div id="42562620" class="c"><input type="checkbox" id="c-42562620" checked=""/><div class="controls bullet"><span class="by">harrisi</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562595">parent</a><span>|</span><a href="#42562696">next</a><span>|</span><label class="collapse" for="c-42562620">[-]</label><label class="expand" for="c-42562620">[1 more]</label></div><br/><div class="children"><div class="content">They didn&#x27;t.<p>EDIT: antirez is the creator of redis, not mvkel.</div><br/></div></div></div></div><div id="42562696" class="c"><input type="checkbox" id="c-42562696" checked=""/><div class="controls bullet"><span class="by">duggan</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562541">parent</a><span>|</span><a href="#42562595">prev</a><span>|</span><a href="#42562283">next</a><span>|</span><label class="collapse" for="c-42562696">[-]</label><label class="expand" for="c-42562696">[4 more]</label></div><br/><div class="children"><div class="content">antirez is clearly going to be “Staff-plus” for almost any definition.<p>Can you clarify what you mean?</div><br/><div id="42563300" class="c"><input type="checkbox" id="c-42563300" checked=""/><div class="controls bullet"><span class="by">cj</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562696">parent</a><span>|</span><a href="#42562283">next</a><span>|</span><label class="collapse" for="c-42563300">[-]</label><label class="expand" for="c-42563300">[3 more]</label></div><br/><div class="children"><div class="content">(Not original commenter) “Staff” engineer is typically one of the most senior and highest paid engineer titles in very large tech company. “Staff plus” is implying they are the best of the best.</div><br/><div id="42563448" class="c"><input type="checkbox" id="c-42563448" checked=""/><div class="controls bullet"><span class="by">sarchertech</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563300">parent</a><span>|</span><a href="#42562283">next</a><span>|</span><label class="collapse" for="c-42563448">[-]</label><label class="expand" for="c-42563448">[2 more]</label></div><br/><div class="children"><div class="content">Staff plus just means staff or higher. Staff, senior staff, principal, mega ultra principal etc…</div><br/><div id="42563589" class="c"><input type="checkbox" id="c-42563589" checked=""/><div class="controls bullet"><span class="by">cj</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563448">parent</a><span>|</span><a href="#42562283">next</a><span>|</span><label class="collapse" for="c-42563589">[-]</label><label class="expand" for="c-42563589">[1 more]</label></div><br/><div class="children"><div class="content">Outside of big tech, those titles aren’t common. Level X SWE vs staff vs principal doesn’t mean anything to a lot of people who aren’t in that orbit.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42562283" class="c"><input type="checkbox" id="c-42562283" checked=""/><div class="controls bullet"><span class="by">egometry</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42562541">prev</a><span>|</span><a href="#42564777">next</a><span>|</span><label class="collapse" for="c-42562283">[-]</label><label class="expand" for="c-42562283">[6 more]</label></div><br/><div class="children"><div class="content">To the un-sticking point: it&#x27;s also great at letting people ask questions without being perceived as dumb<p>Tragically - admitting ignorance,  even with the desire to learn, often has negative social reprocussions</div><br/><div id="42562311" class="c"><input type="checkbox" id="c-42562311" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562283">parent</a><span>|</span><a href="#42562951">next</a><span>|</span><label class="collapse" for="c-42562311">[-]</label><label class="expand" for="c-42562311">[4 more]</label></div><br/><div class="children"><div class="content">Asking &quot;stupid&quot; questions without fear of judgement is legit one of my favorite personal applications of LLMs.</div><br/><div id="42562663" class="c"><input type="checkbox" id="c-42562663" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562311">parent</a><span>|</span><a href="#42563290">next</a><span>|</span><label class="collapse" for="c-42562663">[-]</label><label class="expand" for="c-42562663">[1 more]</label></div><br/><div class="children"><div class="content">That is one of the great strengths of LLMs for school education as well.  Students often refrain from asking questions in class out of embarrassment at showing their ignorance or hesitation at interrupting the flow of the class. When used well, LLMs offer a good way for motivated learners to fill in the gaps in their understanding.<p>The pervasive problem of low student motivation won&#x27;t be solved by LLMs, though. Human teachers will, I think, still be needed.</div><br/></div></div><div id="42563290" class="c"><input type="checkbox" id="c-42563290" checked=""/><div class="controls bullet"><span class="by">james_marks</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562311">parent</a><span>|</span><a href="#42562663">prev</a><span>|</span><a href="#42563273">next</a><span>|</span><label class="collapse" for="c-42563290">[-]</label><label class="expand" for="c-42563290">[1 more]</label></div><br/><div class="children"><div class="content">I find myself doing this all the time, as an experienced dev.<p>All the little nooks of missing knowledge are now very easy to fill in.</div><br/></div></div><div id="42563273" class="c"><input type="checkbox" id="c-42563273" checked=""/><div class="controls bullet"><span class="by">foundart</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562311">parent</a><span>|</span><a href="#42563290">prev</a><span>|</span><a href="#42562951">next</a><span>|</span><label class="collapse" for="c-42563273">[-]</label><label class="expand" for="c-42563273">[1 more]</label></div><br/><div class="children"><div class="content">Yes! In the time it would take to organize a question in a form that won’t be downvoted&#x2F;closed on StackOverflow you can ask a whole series of LLM questions and learn quite a bit.</div><br/></div></div></div></div><div id="42562951" class="c"><input type="checkbox" id="c-42562951" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562283">parent</a><span>|</span><a href="#42562311">prev</a><span>|</span><a href="#42564777">next</a><span>|</span><label class="collapse" for="c-42562951">[-]</label><label class="expand" for="c-42562951">[1 more]</label></div><br/><div class="children"><div class="content">Most of the time it doesn&#x27;t actually, and most people should definitely do it way more instead of pretending to understand thinks they don&#x27;t, but this bad habit is probably gained thanks to the school system where asking a stupid question is going to get you mocked by your peers. The thing is, IRL your peers don&#x27;t get to hear your stupid questions and knowledgeable people are happy to answer them no matter how &quot;dumb&quot; they are (or they don&#x27;t like questions at all, and you&#x27;ll bother them even if you asked interesting questions).<p>See <a href="https:&#x2F;&#x2F;danluu.com&#x2F;look-stupid&#x2F;" rel="nofollow">https:&#x2F;&#x2F;danluu.com&#x2F;look-stupid&#x2F;</a></div><br/></div></div></div></div><div id="42564777" class="c"><input type="checkbox" id="c-42564777" checked=""/><div class="controls bullet"><span class="by">archagon</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42562283">prev</a><span>|</span><a href="#42562763">next</a><span>|</span><label class="collapse" for="c-42564777">[-]</label><label class="expand" for="c-42564777">[1 more]</label></div><br/><div class="children"><div class="content">Off topic, but I&#x27;m a bit confused. Your iOS apps as listed on your website are CarPrep and Brocly, neither of which appear to have notable review activity or buzz in the media. If the app you&#x27;re referring to is one of these, the more interesting question (to me) is: how on Earth are you generating $10,200 MRR from it? Or is there another app that I&#x27;m missing?<p>(In my experience as an app developer, getting any traction and&#x2F;or money from your app can be much more difficult than actually building it.)</div><br/></div></div><div id="42562763" class="c"><input type="checkbox" id="c-42562763" checked=""/><div class="controls bullet"><span class="by">mellosouls</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42564777">prev</a><span>|</span><a href="#42563010">next</a><span>|</span><label class="collapse" for="c-42562763">[-]</label><label class="expand" for="c-42562763">[1 more]</label></div><br/><div class="children"><div class="content">I interpreted it as saying that ymmv wrt the models you try and how you use them, and sole exposure to one that doesn&#x27;t work for you can put you off the whole lot - in this case antirez finds Claude sonnet (with good prompting) very helpful, but gpt 4o (by far the best known due to ChatGPT), not so much and if the latter is representative of others experience it may be why many are still sceptical.</div><br/></div></div><div id="42563010" class="c"><input type="checkbox" id="c-42563010" checked=""/><div class="controls bullet"><span class="by">Ruxbin</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42562763">prev</a><span>|</span><a href="#42563717">next</a><span>|</span><label class="collapse" for="c-42563010">[-]</label><label class="expand" for="c-42563010">[3 more]</label></div><br/><div class="children"><div class="content">May you expand how you did this? I&#x27;m seeing a number of apps that claim to do just this and there are number that are becoming super popular.<p>Not just the development of the code but the entire the thing from the code, infra, auth, cc payments, etc.</div><br/><div id="42563123" class="c"><input type="checkbox" id="c-42563123" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563010">parent</a><span>|</span><a href="#42563635">next</a><span>|</span><label class="collapse" for="c-42563123">[-]</label><label class="expand" for="c-42563123">[1 more]</label></div><br/><div class="children"><div class="content">Planning to write a lengthy blog post on this. Will reply here.</div><br/></div></div><div id="42563635" class="c"><input type="checkbox" id="c-42563635" checked=""/><div class="controls bullet"><span class="by">8n4vidtmkvmk</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563010">parent</a><span>|</span><a href="#42563123">prev</a><span>|</span><a href="#42563717">next</a><span>|</span><label class="collapse" for="c-42563635">[-]</label><label class="expand" for="c-42563635">[1 more]</label></div><br/><div class="children"><div class="content">For CC payments, just use Stripe. The docs are great!</div><br/></div></div></div></div><div id="42563717" class="c"><input type="checkbox" id="c-42563717" checked=""/><div class="controls bullet"><span class="by">yogrish</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42563010">prev</a><span>|</span><a href="#42563620">next</a><span>|</span><label class="collapse" for="c-42563717">[-]</label><label class="expand" for="c-42563717">[1 more]</label></div><br/><div class="children"><div class="content">May I know what is the name of app that is built using LLM? 10k MRR is highly successful app.</div><br/></div></div><div id="42563620" class="c"><input type="checkbox" id="c-42563620" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42563717">prev</a><span>|</span><a href="#42563069">next</a><span>|</span><label class="collapse" for="c-42563620">[-]</label><label class="expand" for="c-42563620">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I built and shipped a Swift app to the App Store, currently generating $10,200 in MRR, exclusively using LLMs.<p>My experience is that people who claim they build worthwhile software &quot;exclusively&quot; using LLMs are lying. I don&#x27;t know you and I don&#x27;t know if you are lying, but I would be willing to bet my paycheck you are.</div><br/><div id="42564515" class="c"><input type="checkbox" id="c-42564515" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563620">parent</a><span>|</span><a href="#42563069">next</a><span>|</span><label class="collapse" for="c-42564515">[-]</label><label class="expand" for="c-42564515">[1 more]</label></div><br/><div class="children"><div class="content">They are also usually selling another AI-wrapper. I don&#x27;t know the parent poster either but if your LLM product is generating $10k&#x2F;month, your moat is really weak and you&#x27;ll probably shut the f* up because your only moat is obscurity. Why risk that?</div><br/></div></div></div></div><div id="42563069" class="c"><input type="checkbox" id="c-42563069" checked=""/><div class="controls bullet"><span class="by">fijiaarone</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42563620">prev</a><span>|</span><a href="#42564310">next</a><span>|</span><label class="collapse" for="c-42563069">[-]</label><label class="expand" for="c-42563069">[1 more]</label></div><br/><div class="children"><div class="content">Strange that you don’t mention your product. Making too much money already?</div><br/></div></div><div id="42564310" class="c"><input type="checkbox" id="c-42564310" checked=""/><div class="controls bullet"><span class="by">oblio</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42563069">prev</a><span>|</span><a href="#42562212">next</a><span>|</span><label class="collapse" for="c-42564310">[-]</label><label class="expand" for="c-42564310">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I built and shipped a Swift app to the App Store, currently generating $10,200 in MRR, exclusively using LLMs.<p>That&#x27;s great, but professional programmers are afraid of the future maintenance burden.</div><br/></div></div><div id="42562212" class="c"><input type="checkbox" id="c-42562212" checked=""/><div class="controls bullet"><span class="by">raydev</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42564310">prev</a><span>|</span><a href="#42562396">next</a><span>|</span><label class="collapse" for="c-42562212">[-]</label><label class="expand" for="c-42562212">[2 more]</label></div><br/><div class="children"><div class="content">Which service&#x2F;LLM performed the best for you?</div><br/><div id="42563147" class="c"><input type="checkbox" id="c-42563147" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562212">parent</a><span>|</span><a href="#42562396">next</a><span>|</span><label class="collapse" for="c-42563147">[-]</label><label class="expand" for="c-42563147">[1 more]</label></div><br/><div class="children"><div class="content">Sonnet-3.5 seemed to churn out the best code, so I would default to that. If it got stuck in circular reasoning, 4o would usually resolve it. Then back to Sonnet.</div><br/></div></div></div></div><div id="42562396" class="c"><input type="checkbox" id="c-42562396" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562111">parent</a><span>|</span><a href="#42562212">prev</a><span>|</span><a href="#42561349">next</a><span>|</span><label class="collapse" for="c-42562396">[-]</label><label class="expand" for="c-42562396">[2 more]</label></div><br/><div class="children"><div class="content">Did you need a Mac for that, or is it possible to use Linux to develop a Swift app targeting iOS?<p>Would you mind sharing which app you released?</div><br/><div id="42562507" class="c"><input type="checkbox" id="c-42562507" checked=""/><div class="controls bullet"><span class="by">MYEUHD</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562396">parent</a><span>|</span><a href="#42561349">next</a><span>|</span><label class="collapse" for="c-42562507">[-]</label><label class="expand" for="c-42562507">[1 more]</label></div><br/><div class="children"><div class="content">You need macOS, which you can run in a VM (e.g. <a href="https:&#x2F;&#x2F;github.com&#x2F;kholia&#x2F;OSX-KVM">https:&#x2F;&#x2F;github.com&#x2F;kholia&#x2F;OSX-KVM</a> ) or by setting up a hackintosh.</div><br/></div></div></div></div></div></div><div id="42561349" class="c"><input type="checkbox" id="c-42561349" checked=""/><div class="controls bullet"><span class="by">ninth_ant</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42562111">prev</a><span>|</span><a href="#42561504">next</a><span>|</span><label class="collapse" for="c-42561349">[-]</label><label class="expand" for="c-42561349">[12 more]</label></div><br/><div class="children"><div class="content">I think a lot of the confusion is in how we approach LLMs. Perhaps stemming from the over-broad term “AI”.<p>There are certain classes of problems that LLMs are good at. Accurately regurgitating all accumulated world knowledge ever is not one, so don’t ask a language model to diagnose your medical condition or choose a political candidate.<p>But <i>do</i> ask them to perform suitable tasks for a language model! Every day by automation I feed in the hourly weather forecast my home ollama server and it builds me a nice readable concise weather report. It’s super cool!<p>There are lots of cases like this where you can give an LLM reliable data and ask it to do a language related task and it will do an excellent job of it.<p>If nothing else it’s an extremely useful computer-human interface.</div><br/><div id="42561420" class="c"><input type="checkbox" id="c-42561420" checked=""/><div class="controls bullet"><span class="by">rrix2</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561349">parent</a><span>|</span><a href="#42562236">next</a><span>|</span><label class="collapse" for="c-42561420">[-]</label><label class="expand" for="c-42561420">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Every day by automation I feed in the hourly weather forecast my home ollama server and it builds me a nice readable concise weather report.<p>not to dissuade you from a thing you find useful but are you aware that the national weather service produces an Area Forecast Discussion product in each local NWS office daily or more often that accomplishes this with human meteorologists and clickable jargon glossary?<p><a href="https:&#x2F;&#x2F;forecast.weather.gov&#x2F;product.php?site=SEW&amp;issuedby=SEW&amp;product=AFD&amp;format=CI&amp;version=1&amp;glossary=1" rel="nofollow">https:&#x2F;&#x2F;forecast.weather.gov&#x2F;product.php?site=SEW&amp;issuedby=S...</a></div><br/><div id="42562266" class="c"><input type="checkbox" id="c-42562266" checked=""/><div class="controls bullet"><span class="by">ninth_ant</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561420">parent</a><span>|</span><a href="#42562236">next</a><span>|</span><label class="collapse" for="c-42562266">[-]</label><label class="expand" for="c-42562266">[2 more]</label></div><br/><div class="children"><div class="content">Doesn’t dissuade me at all, that’s a really neat service. I’m not American though, and even if my own country had a similar service I still enjoying tuning the results to focus on what I’m interested in. And it was just an example of the kinds of computer-human interfaces that are newly possible from this technology.<p>Anytime you have data and want it explained in a casual way —  and it’s not mission critical to be extremely precise — LLMs are going to be a good option to consider.<p>More useful AGI-like behaviours may be enabled by combining LLMs with other technologies down the line, but we shouldn’t try to pretend that LLMs can do everything nor are they useless.</div><br/><div id="42564571" class="c"><input type="checkbox" id="c-42564571" checked=""/><div class="controls bullet"><span class="by">LtWorf</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562266">parent</a><span>|</span><a href="#42562236">next</a><span>|</span><label class="collapse" for="c-42564571">[-]</label><label class="expand" for="c-42564571">[1 more]</label></div><br/><div class="children"><div class="content">The best forecast available on the internet is norwegian.</div><br/></div></div></div></div></div></div><div id="42562236" class="c"><input type="checkbox" id="c-42562236" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561349">parent</a><span>|</span><a href="#42561420">prev</a><span>|</span><a href="#42562912">next</a><span>|</span><label class="collapse" for="c-42562236">[-]</label><label class="expand" for="c-42562236">[2 more]</label></div><br/><div class="children"><div class="content">&gt;don’t ask a language model to diagnose your medical condition<p>Honestly they are very decent at it if you give them accurate information in which to make the diagnosis. The typical problem people have is being unable to feed accurate information to the model. They&#x27;ll cut out parts they don&#x27;t want to think about or not put full test results in for consideration.</div><br/><div id="42564576" class="c"><input type="checkbox" id="c-42564576" checked=""/><div class="controls bullet"><span class="by">LtWorf</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562236">parent</a><span>|</span><a href="#42562912">next</a><span>|</span><label class="collapse" for="c-42564576">[-]</label><label class="expand" for="c-42564576">[1 more]</label></div><br/><div class="children"><div class="content">Yes so basically bias it into what you think it should reply in the question and it will magically somehow give the reply you wanted! Very useful :D</div><br/></div></div></div></div><div id="42562912" class="c"><input type="checkbox" id="c-42562912" checked=""/><div class="controls bullet"><span class="by">pella</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561349">parent</a><span>|</span><a href="#42562236">prev</a><span>|</span><a href="#42562827">next</a><span>|</span><label class="collapse" for="c-42562912">[-]</label><label class="expand" for="c-42562912">[1 more]</label></div><br/><div class="children"><div class="content">&gt; so don’t ask a language model to diagnose your medical condition<p>(o1-preview) LLMs show promise in clinical reasoning but fall short in probabilistic tasks, underscoring why AI shouldn&#x27;t replace doctors for diagnosis just yet.<p>&quot;Superhuman performance of a large language model on the reasoning tasks of a physician&quot; <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2412.10849" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2412.10849</a> [14 Dec 2024]</div><br/></div></div><div id="42562827" class="c"><input type="checkbox" id="c-42562827" checked=""/><div class="controls bullet"><span class="by">dinosaurdynasty</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561349">parent</a><span>|</span><a href="#42562912">prev</a><span>|</span><a href="#42563171">next</a><span>|</span><label class="collapse" for="c-42562827">[-]</label><label class="expand" for="c-42562827">[1 more]</label></div><br/><div class="children"><div class="content">&gt; choose a political candidate<p>I actually found 4o+search to be really good at this... Admittedly what I did was more &quot;research these candidates, tell me anything newsworthy, pros&#x2F;cons, etc&quot; (much longer prompt) and well, it was way faster&#x2F;patient at finding sources than I ever would&#x27;ve been, telling me things I never would&#x27;ve figured out with &lt;5 minutes of googling each set of candidates (which is what I&#x27;ve done before).<p>Honestly my big rule for what LLMs are good at is stuff like &quot;hard&#x2F;tedious&#x2F;annoying to do, easy to verify&quot; and maybe a little more than that. (I think after using a model for a while you can get a &quot;feel&quot; for when it&#x27;s likely BSing.)</div><br/></div></div><div id="42562813" class="c"><input type="checkbox" id="c-42562813" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561349">parent</a><span>|</span><a href="#42563171">prev</a><span>|</span><a href="#42563626">next</a><span>|</span><label class="collapse" for="c-42562813">[-]</label><label class="expand" for="c-42562813">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Perhaps stemming from the over-broad term “AI”.<p>No, I think if we follow the money, we will find the problem.</div><br/></div></div><div id="42563626" class="c"><input type="checkbox" id="c-42563626" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561349">parent</a><span>|</span><a href="#42562813">prev</a><span>|</span><a href="#42561504">next</a><span>|</span><label class="collapse" for="c-42563626">[-]</label><label class="expand" for="c-42563626">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Every day by automation I feed in the hourly weather forecast my home ollama server and it builds me a nice readable concise weather report. It’s super cool!<p>You feed it a weather report and it responds with a weather report? How is that useful?</div><br/><div id="42564202" class="c"><input type="checkbox" id="c-42564202" checked=""/><div class="controls bullet"><span class="by">hansvm</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563626">parent</a><span>|</span><a href="#42561504">next</a><span>|</span><label class="collapse" for="c-42564202">[-]</label><label class="expand" for="c-42564202">[1 more]</label></div><br/><div class="children"><div class="content">It distilled bulk information into a form the author cared about. If nothing else it was probably fun, and a personal report on the things you care about can save minutes each day.<p>I did something similar awhile back without LLMs. I enjoy kayaking, but for a variety of reasons [0] it&#x27;s usually unwieldy to break out of the surf and actually get out into the ocean at my local beach. I eventually started feeding the data into an old-school ML model where I&#x27;d manually check the ocean and report on a few factors (breaking waves, unsafe wind magnitude&#x2F;direction, ...). The model converted those weather&#x2F;tide reports into signals I cared about, and then my forecast could simply AND all those together and plot them on a calendar.<p>An LLM is less custom in some sense, but if you have certain routines you care about (e.g., commuting to my last job I&#x27;d always avoid the 101 in favor of 280 if there was heavy rain), it&#x27;s easy to let the computer translate raw weather information into signals you care about (should you take an alternate route, should you alter your schedule, ...).<p>Off-topic, do you know of a good source of weather covariates? E.g., a report with a 50% chance of rain for 2hr can easily mean light rain guaranteed for 2hr, a guaranteed 1hr of rain sometime in that 2hr period, a 50% chance that a 2hr storm will hit your town or the next town over, or all kinds of things. Does anybody report those raw model outputs?<p>[0] There isn&#x27;t any protection from the open ocean (combined with a kayak that&#x27;s a bit too top-heavy for the task at hand), which doesn&#x27;t help, but the big problem is a sand bar just off the coast. If the tide isn&#x27;t just right, even small swells are amplified into large breaking waves, and I don&#x27;t particularly mind getting dumped upside down onto a sand bar, but I&#x27;d really prefer to spend that time in slightly calmer waters.</div><br/></div></div></div></div></div></div><div id="42561504" class="c"><input type="checkbox" id="c-42561504" checked=""/><div class="controls bullet"><span class="by">uludag</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42561349">prev</a><span>|</span><a href="#42564225">next</a><span>|</span><label class="collapse" for="c-42561504">[-]</label><label class="expand" for="c-42561504">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think people finding LLMs useless is a good representation of the general sentiment though.  I feel that more than anything, people are annoyed at LLM slop.  Someone uses an LLM too much to write code, they create &quot;slop,&quot; which ends up making things worse.</div><br/><div id="42561815" class="c"><input type="checkbox" id="c-42561815" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561504">parent</a><span>|</span><a href="#42561632">next</a><span>|</span><label class="collapse" for="c-42561815">[-]</label><label class="expand" for="c-42561815">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately complex tools will be misused by part of the population. There is no easy escape from that in the modernity of possibilities. Look at the Internet itself.</div><br/></div></div><div id="42561632" class="c"><input type="checkbox" id="c-42561632" checked=""/><div class="controls bullet"><span class="by">gre</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561504">parent</a><span>|</span><a href="#42561815">prev</a><span>|</span><a href="#42564225">next</a><span>|</span><label class="collapse" for="c-42561632">[-]</label><label class="expand" for="c-42561632">[1 more]</label></div><br/><div class="children"><div class="content">Yes but then they can prompt it to golf the code and most of the slop goes away. This sometimes breaks the code.</div><br/></div></div></div></div><div id="42564225" class="c"><input type="checkbox" id="c-42564225" checked=""/><div class="controls bullet"><span class="by">mikehollinger</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42561504">prev</a><span>|</span><a href="#42563804">next</a><span>|</span><label class="collapse" for="c-42564225">[-]</label><label class="expand" for="c-42564225">[5 more]</label></div><br/><div class="children"><div class="content">&gt; About &quot;people still thinking LLMs are quite useless&quot;, I still believe that the problem is that most people are exposed to ChatGPT 4o that at this point for my use case (programming &#x2F; design partner) is basically a useless toy....<p>and<p>&gt; a key thing with LLMs is that their ability to help, as a tool, changes vastly based on your communication ability.<p>I still hold that the innovations we&#x27;ve seen as an industry with text transfer to the data from other domains. And there&#x27;s an odd misbehavior with people that I&#x27;ve now seen play out twice -- back in 2017 with vision models (please don&#x27;t shove a picture of a spectrogram into an object detector), and today. People are trying to coerce text models to do stuff with data series, or (again!) pictures of charts, rather than paying attention to timeseries foundation models which directly can work on the data.[1]<p>Further, the tricks we&#x27;re seeing with encoder &#x2F; decoder pipelines should work for other domains. And we&#x27;re not yet recognizing that as an industry. For example, whisper or the emerging video models are getting there, but think about multi-spectral satellite data, fraud detection (a type graph problem).<p>There&#x27;s lots of value to unlock from coding models. They&#x27;re just text models. So what if you were to shove an abstract syntax tree in as the data representation, or the intermediate code from LLVM or a JVM or whatever runtime and interact with that?<p>[1] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;ibm-granite&#x2F;granite-timeseries-ttm-r1" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;ibm-granite&#x2F;granite-timeseries-ttm-r1</a> - shout-out to some former colleagues!</div><br/><div id="42564233" class="c"><input type="checkbox" id="c-42564233" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42564225">parent</a><span>|</span><a href="#42564255">next</a><span>|</span><label class="collapse" for="c-42564233">[-]</label><label class="expand" for="c-42564233">[2 more]</label></div><br/><div class="children"><div class="content">Andrej Karpathy: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;karpathy&#x2F;status&#x2F;1835024197506187617" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;karpathy&#x2F;status&#x2F;1835024197506187617</a><p>&gt; It&#x27;s a bit sad and confusing that LLMs (&quot;Large Language Models&quot;) have little to do with language; It&#x27;s just historical. They are highly general purpose technology for statistical modeling of token streams. A better name would be Autoregressive Transformers or something.<p>&gt; They don&#x27;t care if the tokens happen to represent little text chunks. It could just as well be little image patches, audio chunks, action choices, molecules, or whatever. If you can reduce your problem to that of modeling token streams (for any arbitrary vocabulary of some set of discrete tokens), you can &quot;throw an LLM at it&quot;.</div><br/><div id="42564701" class="c"><input type="checkbox" id="c-42564701" checked=""/><div class="controls bullet"><span class="by">vbezhenar</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42564233">parent</a><span>|</span><a href="#42564255">next</a><span>|</span><label class="collapse" for="c-42564701">[-]</label><label class="expand" for="c-42564701">[1 more]</label></div><br/><div class="children"><div class="content">But I need enormous amounts of learning data and enormous amount of computing to learn new models, right? So it&#x27;s kind of useless advice for most people who can&#x27;t just parse github repositories and teach their new model using AST tokens. They have to use existing opensourced models or API and those happened to use text.</div><br/></div></div></div></div><div id="42564255" class="c"><input type="checkbox" id="c-42564255" checked=""/><div class="controls bullet"><span class="by">monero-xmr</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42564225">parent</a><span>|</span><a href="#42564233">prev</a><span>|</span><a href="#42563804">next</a><span>|</span><label class="collapse" for="c-42564255">[-]</label><label class="expand" for="c-42564255">[2 more]</label></div><br/><div class="children"><div class="content">The environmental arguments are hilarious to me as a diehard crypto guy. The ultimate answer to “waste” of electricity arguments is that energy is a free market and people pay the price if it’s useful for them. As long as the activity isn’t illegal then training LLMs or mining bitcoins, it doesn’t matter. I pay for the electricity I use.</div><br/><div id="42564318" class="c"><input type="checkbox" id="c-42564318" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42564255">parent</a><span>|</span><a href="#42563804">next</a><span>|</span><label class="collapse" for="c-42564318">[-]</label><label class="expand" for="c-42564318">[1 more]</label></div><br/><div class="children"><div class="content">Do you think that it we should make it illegal to mine coins if the majority of people think the environmental cost is too high?</div><br/></div></div></div></div></div></div><div id="42563804" class="c"><input type="checkbox" id="c-42563804" checked=""/><div class="controls bullet"><span class="by">worldsayshi</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42564225">prev</a><span>|</span><a href="#42562099">next</a><span>|</span><label class="collapse" for="c-42563804">[-]</label><label class="expand" for="c-42563804">[1 more]</label></div><br/><div class="children"><div class="content">I ponder if LLM:s are very useful but at a quite narrower set of tasks than we expect. Like fuzzy manipulation of logical specifications.<p>I.e. over time it constitute a fundamental shift in how we interact with abstractions in computers. The current fundamentals will still remain but they will become increasingly malleable. Details in code will become less important. Architecture will become increasingly important. But at the same time the cost of refactoring or changing architecture will quickly drop.<p>Any details that are easily lost when passing through an LLM will be details that have the highest maintenance cost. Any important details that can be retained by an LLM can move up and down the ladder of abstraction at will.<p>Can an LLM based solution maintain software architectures without introducing noise? The answer to that is the difference between somewhat useful and game changing.</div><br/></div></div><div id="42562099" class="c"><input type="checkbox" id="c-42562099" checked=""/><div class="controls bullet"><span class="by">swalsh</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42563804">prev</a><span>|</span><a href="#42562926">next</a><span>|</span><label class="collapse" for="c-42562099">[-]</label><label class="expand" for="c-42562099">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a big believer in Claude.  I&#x27;ve accomplished some huge productivity gains by leveraging it.  That said, I can see places where the models are strong and weak.  If you&#x27;re doing react, or python.  These models are incredible.  C#, C++ they&#x27;re not terrible.  Rust though, it&#x27;s not great.  If your experience is exclusively trying to use it to write Rust, it doesn&#x27;t matter if you&#x27;re using o1, Claude or anything else.  It&#x27;s just not great at it yet.</div><br/></div></div><div id="42562926" class="c"><input type="checkbox" id="c-42562926" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42562099">prev</a><span>|</span><a href="#42561315">next</a><span>|</span><label class="collapse" for="c-42562926">[-]</label><label class="expand" for="c-42562926">[1 more]</label></div><br/><div class="children"><div class="content">LLMs have given computers the ability to communicate with us in natural language, we didn&#x27;t have that before at this level. In order to do this, they&#x27;ve been fed with a lot of coherent stuff and give the impression of being coherent, but we know they&#x27;re just statistical machines. But at least they can now communicate naturally with us, so now we have that infrastructure available, as we do have TTS or ASR or monitors and keyboards available. It&#x27;s still up to us to now make proper agents out of them. Agents for the software we&#x27;ve been using for decades. They can take over a lot of tedious work for us.</div><br/></div></div><div id="42561315" class="c"><input type="checkbox" id="c-42561315" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42562926">prev</a><span>|</span><a href="#42561890">next</a><span>|</span><label class="collapse" for="c-42561315">[-]</label><label class="expand" for="c-42561315">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Claude Sonnet 3.5 (not Haiku!)<p>A very big surprise is just <i>how</i> much better Sonnet 3.5 is than Haiku. Even the confusingly-more-expensive-Haiku-variant Haiku 3.5 that&#x27;s more recent than Sonnet 3.5 is still much worse.</div><br/></div></div><div id="42561890" class="c"><input type="checkbox" id="c-42561890" checked=""/><div class="controls bullet"><span class="by">duped</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42561315">prev</a><span>|</span><a href="#42562458">next</a><span>|</span><label class="collapse" for="c-42561890">[-]</label><label class="expand" for="c-42561890">[14 more]</label></div><br/><div class="children"><div class="content">&gt; Try Claude Sonnet 3.5 (not Haiku!) and tell me if, while still flawed, is not helpful.<p>It&#x27;s not <i>as</i> helpful as Google was ten years ago. It&#x27;s more helpful than Google today, because Google search has slowly been corrupted by garbage SEO and other LLM spam, including their own suggestions.</div><br/><div id="42562105" class="c"><input type="checkbox" id="c-42562105" checked=""/><div class="controls bullet"><span class="by">ChicagoDave</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561890">parent</a><span>|</span><a href="#42562228">next</a><span>|</span><label class="collapse" for="c-42562105">[-]</label><label class="expand" for="c-42562105">[8 more]</label></div><br/><div class="children"><div class="content">Claude Sonnet 3.5 can write whole React applications with proper contextual clues and some minor iterations. Google has never coded for you.<p>I’ve written two large applications and about a dozen smaller ones using Claude as an assistant.<p>I’m a terrible front-end developer and almost none of that work was possible without Claude. The API and AWS deployment were sped up tremendously.<p>I’ve created unit tests and I’ve read through the resulting code and it’s very clean. One of my core pre-prompt requirements has always been to follow domain-driven design principles, something a novice would never understand.<p>I also start with design principles and a checklist that Claude is excellent at providing.<p>My only complaint is you only have a 3-4 hour window before you’re cutoff for a few hours.<p>And needing an enterprise agreement to have a walled garden for proprietary purposes.<p>I was not a fan in Q1. Q2 improved. Q3 was a massive leap forward.</div><br/><div id="42562296" class="c"><input type="checkbox" id="c-42562296" checked=""/><div class="controls bullet"><span class="by">duped</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562105">parent</a><span>|</span><a href="#42562704">next</a><span>|</span><label class="collapse" for="c-42562296">[-]</label><label class="expand" for="c-42562296">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never really used Claude for writing code, becuase I&#x27;m not really bottlenecked by that problem. I have used it quite a bit for asking questions about what code to write and it&#x27;s almost always wrong (usually in subtle ways that would trick someone with little experience).<p>Maybe it was overtrained on react sources, but for me it&#x27;s pretty useless.<p>The big annoyance for me is it just makes up APIs that don&#x27;t exist. While that&#x27;s useful for suggesting to me what APIs I should add to my own code, it&#x27;s really pointless if I ask a question like &quot;using libfoo how do I bar&quot; and it tells me &quot;call the doBar() function&quot; which does not exist.</div><br/><div id="42564548" class="c"><input type="checkbox" id="c-42564548" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562296">parent</a><span>|</span><a href="#42562661">next</a><span>|</span><label class="collapse" for="c-42564548">[-]</label><label class="expand" for="c-42564548">[1 more]</label></div><br/><div class="children"><div class="content">They are mostly useful for front-end&#x2F;React because front-end shouldn&#x27;t been code in the first place. They can do the UX but not the state management. Honestly, as someone who sucks and dread UX building (and having to frequently adjust my divs&#x2F;components), they are a life saver when you are doing very conventional things. That is things you can find 100s of examples of but will take you hours to glue together.</div><br/></div></div><div id="42562661" class="c"><input type="checkbox" id="c-42562661" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562296">parent</a><span>|</span><a href="#42564548">prev</a><span>|</span><a href="#42562704">next</a><span>|</span><label class="collapse" for="c-42562661">[-]</label><label class="expand" for="c-42562661">[1 more]</label></div><br/><div class="children"><div class="content">They can&#x27;t think at all. The task must be strict macroexpansion of original input(doesn&#x27;t mean that always works).<p>I&#x27;m suspecting LLM works for a lot of front end and app coding just because code in those fields are insanely overbloated and value proposition is almost disconnected from logic. There must be metric tons of typing in those fields, and in those areas LLMs must be useful. They certainly handle paper test questions well.</div><br/></div></div></div></div><div id="42562704" class="c"><input type="checkbox" id="c-42562704" checked=""/><div class="controls bullet"><span class="by">deadbabe</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562105">parent</a><span>|</span><a href="#42562296">prev</a><span>|</span><a href="#42562228">next</a><span>|</span><label class="collapse" for="c-42562704">[-]</label><label class="expand" for="c-42562704">[4 more]</label></div><br/><div class="children"><div class="content">Imagine not needing Claude to do any of that.</div><br/><div id="42562919" class="c"><input type="checkbox" id="c-42562919" checked=""/><div class="controls bullet"><span class="by">ChicagoDave</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562704">parent</a><span>|</span><a href="#42562228">next</a><span>|</span><label class="collapse" for="c-42562919">[-]</label><label class="expand" for="c-42562919">[3 more]</label></div><br/><div class="children"><div class="content">This is one of those things I like about Claude.<p>I’m hitting my 40th year as a professional software developer and architect. I’ve written thousands of blocks of code from scratch. It gets boring.<p>But then in the 2000’s me (and everyone else) started building code generators, often from ERD structures, but also UML designs.<p>These tools were massively useful and (initially) reduced costs. The future balls of mud problems took over ten years to arrive.<p>But code generation has always been considered a smart and cost-effective approach to building software.<p>GenAI has “issues” and those have been exposed. One of my recent revelations is that Claude is best at TypeScript and python. C# (my home turf) is much lower in its skills capacity.<p>So in the last two months I’ve been building my apps in TypeScript instead of C# and have dramatically increased my productivity.<p>Claude will definitely fail if it doesn’t have the correct information. A good example is writing Bluesky apps. The docs are a mess and contradictory. But there are up to date docs on GitHub and if you include those in your project with instructions to only use those references, Claude’s hallucinations can be eliminated.<p>I don’t think AGI is a real possibility in my lifetime, and I do fear the future of software development when no one has actual coding experience, but for us boomers, it’s pretty darn useful.</div><br/><div id="42563012" class="c"><input type="checkbox" id="c-42563012" checked=""/><div class="controls bullet"><span class="by">deadbabe</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562919">parent</a><span>|</span><a href="#42562228">next</a><span>|</span><label class="collapse" for="c-42563012">[-]</label><label class="expand" for="c-42563012">[2 more]</label></div><br/><div class="children"><div class="content">How are you measuring your productivity?</div><br/><div id="42563243" class="c"><input type="checkbox" id="c-42563243" checked=""/><div class="controls bullet"><span class="by">ChicagoDave</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563012">parent</a><span>|</span><a href="#42562228">next</a><span>|</span><label class="collapse" for="c-42563243">[-]</label><label class="expand" for="c-42563243">[1 more]</label></div><br/><div class="children"><div class="content">In many cases I have no frame of reference for the expected code, like React and css. Typescript is perfectly readable, but I’m not really a script kiddie, so I’d go very slow on the React tsx files. The services are probably a slightly faster set of work, especially if I always have unit tests.<p>If someone was an expert React+TypeScript programmer with decent css knowledge the productivity may be a marginal improvement.<p>But I haven’t been a full-time programmer in ten years.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42562139" class="c"><input type="checkbox" id="c-42562139" checked=""/><div class="controls bullet"><span class="by">bdangubic</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561890">parent</a><span>|</span><a href="#42562228">prev</a><span>|</span><a href="#42561917">next</a><span>|</span><label class="collapse" for="c-42562139">[-]</label><label class="expand" for="c-42562139">[2 more]</label></div><br/><div class="children"><div class="content">comparing google to claude 3.5 is like comparing tesla s plaid with a horse</div><br/></div></div><div id="42562205" class="c"><input type="checkbox" id="c-42562205" checked=""/><div class="controls bullet"><span class="by">emptiestplace</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561890">parent</a><span>|</span><a href="#42561917">prev</a><span>|</span><a href="#42562458">next</a><span>|</span><label class="collapse" for="c-42562205">[-]</label><label class="expand" for="c-42562205">[1 more]</label></div><br/><div class="children"><div class="content">What a hilariously absurd statement. You might want to actually try it.</div><br/></div></div></div></div><div id="42562458" class="c"><input type="checkbox" id="c-42562458" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42561890">prev</a><span>|</span><a href="#42563715">next</a><span>|</span><label class="collapse" for="c-42562458">[-]</label><label class="expand" for="c-42562458">[1 more]</label></div><br/><div class="children"><div class="content">Both new Sonnet and Haiku have a masking overhead.<p>Using a few messages to get them out of &quot;I aim to be direct&quot; AI assistant mode gets much better overall results for the rest of the chat.<p>Haiku is actually incredibly good at high level systems thinking. Somehow when they moved to a smaller model the &quot;human-like&quot; parts fell away but the logical parts remained at a similar level.<p>Like if you were taking meeting notes from a business strategy meeting and wanted insights, use Haiku over Sonnet, and thank me later.</div><br/></div></div><div id="42563715" class="c"><input type="checkbox" id="c-42563715" checked=""/><div class="controls bullet"><span class="by">zahlman</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42562458">prev</a><span>|</span><a href="#42562778">next</a><span>|</span><label class="collapse" for="c-42563715">[-]</label><label class="expand" for="c-42563715">[1 more]</label></div><br/><div class="children"><div class="content">&gt;They are also great at doing boring tasks for which you can provide perfect guidance (but that still would take you hours)<p>All the tasks I can think of dealing with on my own computer that would take hours, a) are actually pretty interesting to me and b) would equally well take hours to &quot;provide perfect guidance&quot;. The drudge work of programming that I notice comes in blocks of seconds at a time, and the mental context switch to using an LLM would be costlier.</div><br/></div></div><div id="42562778" class="c"><input type="checkbox" id="c-42562778" checked=""/><div class="controls bullet"><span class="by">atombender</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42563715">prev</a><span>|</span><a href="#42561597">next</a><span>|</span><label class="collapse" for="c-42562778">[-]</label><label class="expand" for="c-42562778">[5 more]</label></div><br/><div class="children"><div class="content">Is there a way to use this in Jetbrains IDEs? (I&#x27;ve not been impressed with their AI Assistant.) There are a few plugins, but from the reviews they all seem kind of mediocre.</div><br/><div id="42563364" class="c"><input type="checkbox" id="c-42563364" checked=""/><div class="controls bullet"><span class="by">cube2222</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562778">parent</a><span>|</span><a href="#42564045">next</a><span>|</span><label class="collapse" for="c-42563364">[-]</label><label class="expand" for="c-42563364">[1 more]</label></div><br/><div class="children"><div class="content">I personally use the Zed editor AI assistant integration with Sonnet for anything AI-related, while using a JetBrains IDE for coding &#x2F; code reading, side-by-side.<p>I haven’t found anything comparably good for JetBrains IDEs yet, but I’m also not switching to something else as my main editor.</div><br/></div></div><div id="42564045" class="c"><input type="checkbox" id="c-42564045" checked=""/><div class="controls bullet"><span class="by">Sn0wCoder</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562778">parent</a><span>|</span><a href="#42563364">prev</a><span>|</span><a href="#42562900">next</a><span>|</span><label class="collapse" for="c-42564045">[-]</label><label class="expand" for="c-42564045">[1 more]</label></div><br/><div class="children"><div class="content">I use IntelliJ as my main coding tool but also use VSCode and Sublime text.  If you have access to local LLMs or have an API key for some the Continue Plugin (basically Cursor but can use in IntelliJ) is the Best of the Best for IntelliJ (IMO).  I have a box running some local models including Phind and StarCoder (plus some small embeddings) and have been super happy with the end product.  The next up is Google Gemini Code Assist has been the best of the IntelliJ (non-configured) AI tools I have tried.  There are better ones out there but IMO not for IntelliJ.  It&#x27;s still free for a few more weeks and I have been using it since the free release, fun to use.  Can pre-prompt, say you are an expert XXX, please be funny, fill in the rest of your regular prompts.  The Co-Pilot I use for work is very limited and will only answer coding questions.  I tried to tell it that it was my coding buddy, and its name was Phil and told me it cannot have a personality or be funny. I believe the paid personal Co-Pilot allows you to choose which LLM it uses (I cannot confirm).   The Phind VSCode plugin works really well.  Also, the Phind coding models are on par with some of the other big ones and free if you have a subscription (or run locally).  Sublime is around to open those GIG+ files as VSCode chocks and not worth the RAM of opening another IntelliJ.<p>Each task &#x2F; programming language &#x2F; query requires trying different LLM models and novel ways of prompting. If it&#x27;s not work-related (or work pays for the one you use) sending as much of the code as relevant also helps the answers be more useful.<p>Most of the people I meet that say LLMs are not useful have only tried one (flavor &#x2F; plugin), do not know how to pre-prompt or prompt, and do not give the tools a chance.  Try one or two things, say yep, it&#x27;s not good and give up.<p>Still hard for me to admit that Prompt Engineering is a profession, but it&#x27;s the same as Google Fu.  Once you learn it you can become an LLM Ninja!<p>I do not believe LLMs are coming for my job (just yet) but do believe they are going to be able to replace some people, are useful and those that do not use them will be at a disadvantage.</div><br/></div></div><div id="42562900" class="c"><input type="checkbox" id="c-42562900" checked=""/><div class="controls bullet"><span class="by">cpursley</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562778">parent</a><span>|</span><a href="#42564045">prev</a><span>|</span><a href="#42561597">next</a><span>|</span><label class="collapse" for="c-42562900">[-]</label><label class="expand" for="c-42562900">[2 more]</label></div><br/><div class="children"><div class="content">Try Cursor. I’m serious.</div><br/><div id="42562915" class="c"><input type="checkbox" id="c-42562915" checked=""/><div class="controls bullet"><span class="by">atombender</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562900">parent</a><span>|</span><a href="#42561597">next</a><span>|</span><label class="collapse" for="c-42562915">[-]</label><label class="expand" for="c-42562915">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure it&#x27;s good, but that&#x27;s not what I&#x27;m asking about.</div><br/></div></div></div></div></div></div><div id="42561597" class="c"><input type="checkbox" id="c-42561597" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42562778">prev</a><span>|</span><a href="#42561887">next</a><span>|</span><label class="collapse" for="c-42561597">[-]</label><label class="expand" for="c-42561597">[6 more]</label></div><br/><div class="children"><div class="content">I swear these goalposts keep getting moved, I remember being told that GPT3.5 is a useless toy but the paid GPT4 is lifechanging, and now that GPT4 is free I&#x27;m told that it&#x27;s a useless toy but paid o1 or paid Sonnet are lifechanging. Looking forward to o1 and Sonnet becoming useless toys, unlike the lifechanging o3.</div><br/><div id="42563671" class="c"><input type="checkbox" id="c-42563671" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561597">parent</a><span>|</span><a href="#42561712">next</a><span>|</span><label class="collapse" for="c-42563671">[-]</label><label class="expand" for="c-42563671">[1 more]</label></div><br/><div class="children"><div class="content">Except GPT4 isn&#x27;t free.<p>The GP is claiming GPT4o is bad but Sonnet is good. GPT4o is about only 20% cheaper than Sonnet.</div><br/></div></div><div id="42561712" class="c"><input type="checkbox" id="c-42561712" checked=""/><div class="controls bullet"><span class="by">aetherson</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561597">parent</a><span>|</span><a href="#42563671">prev</a><span>|</span><a href="#42561887">next</a><span>|</span><label class="collapse" for="c-42561712">[-]</label><label class="expand" for="c-42561712">[4 more]</label></div><br/><div class="children"><div class="content">You will also be dismayed to hear that a 2011 iPhone is no longer state-of-the-art, and indeed can&#x27;t run most modern apps.</div><br/><div id="42561914" class="c"><input type="checkbox" id="c-42561914" checked=""/><div class="controls bullet"><span class="by">jpc0</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561712">parent</a><span>|</span><a href="#42561925">next</a><span>|</span><label class="collapse" for="c-42561914">[-]</label><label class="expand" for="c-42561914">[1 more]</label></div><br/><div class="children"><div class="content">GPT4 is a 13 year old technology? Compared to o1 and Sonnet 3.5?<p>If someone told me an iPhone 4 is terrible but an iPhone 5 would definitely serve my needs, then when I get an iPhone 5 they say the same of the 6 you really want me to believe them a second time? Then a third time? Then a 4th? In the mean time my time and money is wasted?</div><br/></div></div><div id="42561925" class="c"><input type="checkbox" id="c-42561925" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561712">parent</a><span>|</span><a href="#42561914">prev</a><span>|</span><a href="#42562677">next</a><span>|</span><label class="collapse" for="c-42561925">[-]</label><label class="expand" for="c-42561925">[1 more]</label></div><br/><div class="children"><div class="content">Holy false-equivalency, Batman! The definitions of &quot;useless toy &#x2F; lifechanging tool&quot; are _not_ changing over time (or, at least, not over the timescale being explored here), whereas the expectations and requirements of processing power of a phone are.</div><br/></div></div><div id="42562677" class="c"><input type="checkbox" id="c-42562677" checked=""/><div class="controls bullet"><span class="by">johnrob</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561712">parent</a><span>|</span><a href="#42561925">prev</a><span>|</span><a href="#42561887">next</a><span>|</span><label class="collapse" for="c-42562677">[-]</label><label class="expand" for="c-42562677">[1 more]</label></div><br/><div class="children"><div class="content">It would be quite useful if that were the only phone available.</div><br/></div></div></div></div></div></div><div id="42561887" class="c"><input type="checkbox" id="c-42561887" checked=""/><div class="controls bullet"><span class="by">qsort</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42561597">prev</a><span>|</span><a href="#42561218">next</a><span>|</span><label class="collapse" for="c-42561887">[-]</label><label class="expand" for="c-42561887">[3 more]</label></div><br/><div class="children"><div class="content">I believe it&#x27;s more frustration directed at the mismatch between marketing and reality, combined with the general <i>well deserved</i> growing hatred for SV culture, and, more broadly, software engineers. The sentiment would be completely different if the entire industry marketed themselves like the helpful tools they are rather than the second coming of Christ they aren&#x27;t. This distinction is hard to make on &quot;fast food&quot; forums like this one.<p>If you aren&#x27;t a coder, it&#x27;s hard to find much utility in &quot;Google, but it burns a tree whenever you make an API call, and everything it tells you might be wrong&quot;. I for one have never used it for anything else. It just hasn&#x27;t ever come up.<p>It&#x27;s great at cheating on homework, kids love GPTs. It&#x27;s great at cheating in general, in interviews for instance. Or at ruining Christmas, after this year&#x27;s LLM debacle it&#x27;s unclear if we&#x27;ll have another edition of Advent of Code. None of this is the technology&#x27;s fault, of course, you could say the same about the Internet, phones or what have you, but it&#x27;s hardly a point in favor either.<p>And if you are a coder, models like Claude actually do help you, but you have to monitor their output and thoroughly test whatever comes out of them, a far cry from the promises of complete automation and insane productivity gains.<p>If you are only a consumer of this technology, like the vast majority of us here, there isn&#x27;t that much of an upside in being an early adopter. I&#x27;ll sit and wait, slowly integrating new technology in my workflow if and when it makes sense to do so.<p>Happy new year, I guess.</div><br/><div id="42563307" class="c"><input type="checkbox" id="c-42563307" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561887">parent</a><span>|</span><a href="#42561218">next</a><span>|</span><label class="collapse" for="c-42563307">[-]</label><label class="expand" for="c-42563307">[2 more]</label></div><br/><div class="children"><div class="content">&gt; there isn&#x27;t that much of an upside in being an early adopter.<p>Other than, y&#x27;know, using the new tools. As a programmer heavy forum, we focus a lot on LLMs&#x27; (lack of) correctness. There&#x27;s more than a little bit of annoyance when things are wrong, like being asked to grab the red blanket and then getting into an argument over it being orange instead of what was important, someone needed the blanket because they were cold.<p>Most of the non-tech people who use ChatGPT that I&#x27;ve talked to absolutely love it because they don&#x27;t feel it judges them for asking stupid questions and they have conversations about absolutely everything in their lives with it down to which outfit to wear to the party. There are wrong answers to that question as well, but they&#x27;re far more subjective and just having another opinion in the room is invaluable. It&#x27;s just a computer and won&#x27;t get hurt if you totally ignore it&#x27;s recommendations, and even better, it won&#x27;t gloat (unless you ask it to) if you tell it later that it was right and you were wrong.<p>Some people have found upsides for themselves in their lives, even at this nascent stage. No one&#x27;s forcing you to use one, but your job isn&#x27;t going to be taken by AI, it&#x27;s going to be taken by someone else who can outperform you that&#x27;s using AI.</div><br/><div id="42563714" class="c"><input type="checkbox" id="c-42563714" checked=""/><div class="controls bullet"><span class="by">saltcured</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563307">parent</a><span>|</span><a href="#42561218">next</a><span>|</span><label class="collapse" for="c-42563714">[-]</label><label class="expand" for="c-42563714">[1 more]</label></div><br/><div class="children"><div class="content">Yikes.<p>Clearly said, yet the general sentiment awakens in me a feeling more gothic horror than bright futurism. I am stuck with wonder and worry at the question of how rapidly this stuff will infiltrate into the global tech supply chain, and the eventual consequences of misguided trust.<p>To my eye, too much current AI and related tech are just exaggerated versions of magic 8-balls, Ouija boards, horoscopes, or Weizenbaum&#x27;s ELIZA. The fundamental problem is people personifying these toys and letting their guard down. Human instincts take over and people effectively social engineer themselves, putting trust in plausible fictions.<p>It&#x27;s not just LLMs though. It&#x27;s been a long time coming, the way modern tech platforms have been exaggerating their capability with smoke and mirrors UX tricks, where a gleaming facade promises more reality and truth than it actually delivers. Individual users and user populations are left to soak up the errors and omissions and convince themselves everything is working as it should.<p>Someday, maybe, anthropologists will look back on us and recognize something like cargo cults. When we kept going through the motions of Search and Retrieval even though real information was no longer coming in for a landing.</div><br/></div></div></div></div></div></div><div id="42561218" class="c"><input type="checkbox" id="c-42561218" checked=""/><div class="controls bullet"><span class="by">hdjjhhvvhga</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42561887">prev</a><span>|</span><a href="#42563429">next</a><span>|</span><label class="collapse" for="c-42561218">[-]</label><label class="expand" for="c-42561218">[8 more]</label></div><br/><div class="children"><div class="content">While Claude Sonnet is superior than 4o for most my use cases, there are still occasionally some specific tasks where it performs slightly better.</div><br/><div id="42561249" class="c"><input type="checkbox" id="c-42561249" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561218">parent</a><span>|</span><a href="#42562403">next</a><span>|</span><label class="collapse" for="c-42561249">[-]</label><label class="expand" for="c-42561249">[6 more]</label></div><br/><div class="children"><div class="content">Probably. But statistically to work with 4o is a lose of time for me. LLMs is like an investment: you write the prompts, you &quot;work&quot; with them. If the LLM is too weak, this is a lose of time. You need to have a return on the investment that is positive. With ChatGPT 4o &#x2F; o1 most of the times for me the investment of time has almost zero return. Before Claude Sonnet 3.5 I already had a ChatGPT PRO account but never used it for coding since it was most of the times useless if not for throw away scripts that I didn&#x27;t want to do myself or as a stack overflow replacement for trivial stuff. Now it&#x27;s different.</div><br/><div id="42561357" class="c"><input type="checkbox" id="c-42561357" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561249">parent</a><span>|</span><a href="#42562404">next</a><span>|</span><label class="collapse" for="c-42561357">[-]</label><label class="expand" for="c-42561357">[2 more]</label></div><br/><div class="children"><div class="content">This mirrors my experience 100%. I&#x27;m not even sure why I still pay for OpenAI at this point. Claude 3.5 is just incredibly superior. And I totally agree on the point about dropping in context and asking very specific questions. I&#x27;ve had Claude pinpoint a bug in a 2k LOC module that I was struggling to find the cause for. After wasting a lot of time on it on my own, I thought &quot;what the heck, maybe Claude can figure it out&quot; and it did. It&#x27;s objectively useful, even if flawed sometimes.</div><br/><div id="42564423" class="c"><input type="checkbox" id="c-42564423" checked=""/><div class="controls bullet"><span class="by">hanikesn</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561357">parent</a><span>|</span><a href="#42562404">next</a><span>|</span><label class="collapse" for="c-42564423">[-]</label><label class="expand" for="c-42564423">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious. Can you go into more detail what kind of bug it found?</div><br/></div></div></div></div><div id="42562404" class="c"><input type="checkbox" id="c-42562404" checked=""/><div class="controls bullet"><span class="by">d0mine</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561249">parent</a><span>|</span><a href="#42561357">prev</a><span>|</span><a href="#42562403">next</a><span>|</span><label class="collapse" for="c-42562404">[-]</label><label class="expand" for="c-42562404">[3 more]</label></div><br/><div class="children"><div class="content">why &quot;lose of time&quot; instead of &quot;loss of time&quot;
Is it a typo or fingerprinting?</div><br/><div id="42564326" class="c"><input type="checkbox" id="c-42564326" checked=""/><div class="controls bullet"><span class="by">squirrel</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562404">parent</a><span>|</span><a href="#42563318">next</a><span>|</span><label class="collapse" for="c-42564326">[-]</label><label class="expand" for="c-42564326">[1 more]</label></div><br/><div class="children"><div class="content">Typo</div><br/></div></div><div id="42563318" class="c"><input type="checkbox" id="c-42563318" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42562404">parent</a><span>|</span><a href="#42564326">prev</a><span>|</span><a href="#42562403">next</a><span>|</span><label class="collapse" for="c-42563318">[-]</label><label class="expand" for="c-42563318">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s &quot;proof&quot; that it wasn&#x27;t written by an LLM (but let me delve into this issue).</div><br/></div></div></div></div></div></div><div id="42562403" class="c"><input type="checkbox" id="c-42562403" checked=""/><div class="controls bullet"><span class="by">tootie</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561218">parent</a><span>|</span><a href="#42561249">prev</a><span>|</span><a href="#42563429">next</a><span>|</span><label class="collapse" for="c-42562403">[-]</label><label class="expand" for="c-42562403">[1 more]</label></div><br/><div class="children"><div class="content">Like what? Claude has become my go-to, but I find that it&#x27;s wrong enough often enough that I really can&#x27;t trust it for anything. If it says something I have to go dig through it&#x27;s citations very carefully.</div><br/></div></div></div></div><div id="42561316" class="c"><input type="checkbox" id="c-42561316" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42563429">prev</a><span>|</span><a href="#42563565">next</a><span>|</span><label class="collapse" for="c-42561316">[-]</label><label class="expand" for="c-42561316">[3 more]</label></div><br/><div class="children"><div class="content">Hopefully things have narrowed but you can see from the trends data just how few people (API may be a different story) use claude relative to chatgpt.</div><br/><div id="42561320" class="c"><input type="checkbox" id="c-42561320" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561316">parent</a><span>|</span><a href="#42563565">next</a><span>|</span><label class="collapse" for="c-42561320">[-]</label><label class="expand" for="c-42561320">[2 more]</label></div><br/><div class="children"><div class="content">Brand awareness is a hell of a drug.</div><br/><div id="42561453" class="c"><input type="checkbox" id="c-42561453" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561320">parent</a><span>|</span><a href="#42563565">next</a><span>|</span><label class="collapse" for="c-42561453">[-]</label><label class="expand" for="c-42561453">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, although I find myself reaching for o1 more than Claude for matters other than programming, solely because it has better LaTeX (...)</div><br/></div></div></div></div></div></div><div id="42563565" class="c"><input type="checkbox" id="c-42563565" checked=""/><div class="controls bullet"><span class="by">salawat</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42561316">prev</a><span>|</span><a href="#42561293">next</a><span>|</span><label class="collapse" for="c-42563565">[-]</label><label class="expand" for="c-42563565">[3 more]</label></div><br/><div class="children"><div class="content">Why are you pasting huge chunks of potentially crown jewels code into a 3rd party service where prompts are going to most likely be turned into training&#x2F;surveillance material?</div><br/><div id="42563584" class="c"><input type="checkbox" id="c-42563584" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563565">parent</a><span>|</span><a href="#42561293">next</a><span>|</span><label class="collapse" for="c-42563584">[-]</label><label class="expand" for="c-42563584">[2 more]</label></div><br/><div class="children"><div class="content">A lot of vendors promise not to train on input to their models. I choose to believe those promises.</div><br/><div id="42563672" class="c"><input type="checkbox" id="c-42563672" checked=""/><div class="controls bullet"><span class="by">askl56</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42563584">parent</a><span>|</span><a href="#42561293">next</a><span>|</span><label class="collapse" for="c-42563672">[-]</label><label class="expand" for="c-42563672">[1 more]</label></div><br/><div class="children"><div class="content">A scorpion, not knowing how to swim, asked a frog to carry it across the river. “Do I look like a fool?” said the frog. “You’d sting me if I let you on my back!”<p>“Be logical,” said the scorpion. “If I stung you I’d certainly drown myself.”<p>“That’s true,” the frog acknowledged. “Climb aboard, then!” But no sooner than they were halfway across the river, the scorpion stung the frog, and they both began to thrash and drown. “Why on earth did you do that?” the frog said morosely. “Now we’re both going to die.”<p>“I can’t help it,” said the scorpion. “It’s my nature.”</div><br/></div></div></div></div></div></div><div id="42561293" class="c"><input type="checkbox" id="c-42561293" checked=""/><div class="controls bullet"><span class="by">brookst</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42563565">prev</a><span>|</span><a href="#42561175">next</a><span>|</span><label class="collapse" for="c-42561293">[-]</label><label class="expand" for="c-42561293">[1 more]</label></div><br/><div class="children"><div class="content">I’m surprised you only have one use case. I use LLMs to research travel, adjust recipes, check biographies and book reviews, and many many more things.</div><br/></div></div><div id="42561175" class="c"><input type="checkbox" id="c-42561175" checked=""/><div class="controls bullet"><span class="by">wslh</span><span>|</span><a href="#42561151">parent</a><span>|</span><a href="#42561293">prev</a><span>|</span><a href="#42561874">next</a><span>|</span><label class="collapse" for="c-42561175">[-]</label><label class="expand" for="c-42561175">[3 more]</label></div><br/><div class="children"><div class="content">Right, in simpler terms: The measure of LLMs success is how effectively they help you achieve your goal faster.</div><br/><div id="42561192" class="c"><input type="checkbox" id="c-42561192" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561175">parent</a><span>|</span><a href="#42561874">next</a><span>|</span><label class="collapse" for="c-42561192">[-]</label><label class="expand" for="c-42561192">[2 more]</label></div><br/><div class="children"><div class="content">Exactly, and right now the LLMs acceleration effect is <i>a tool</i>, not &quot;give me the final solution&quot;. Even people that can&#x27;t code, using LLMs to build applications from scratch, still have this tool mindset. This is why they can use them effectively: they don&#x27;t stop at the first failed solution; they provide hints to the LLM, test the code, try to figure what&#x27;s the problem (also with the LLM help), and so forth. It&#x27;s a matter of mindset.</div><br/><div id="42562502" class="c"><input type="checkbox" id="c-42562502" checked=""/><div class="controls bullet"><span class="by">d0mine</span><span>|</span><a href="#42561151">root</a><span>|</span><a href="#42561192">parent</a><span>|</span><a href="#42561874">next</a><span>|</span><label class="collapse" for="c-42562502">[-]</label><label class="expand" for="c-42562502">[1 more]</label></div><br/><div class="children"><div class="content">btw, fusion has arrived by that definition: No reactors that would produce more energy than they consume, But net positive reactions have been achieved. Tasks where LLMs output is more than 1x are few and far between.</div><br/></div></div></div></div></div></div></div></div><div id="42561874" class="c"><input type="checkbox" id="c-42561874" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42561151">prev</a><span>|</span><a href="#42560993">next</a><span>|</span><label class="collapse" for="c-42561874">[-]</label><label class="expand" for="c-42561874">[57 more]</label></div><br/><div class="children"><div class="content">&gt; There’s a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can’t see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire!<p>I wish the author qualified this more. How does one develop that skill?<p>What makes LLMs so powerful on a day to day basis without a large RAG system around it?<p>Personally, I try LLMs every now and then, but haven’t seen any indication of their usefulness for my day to day outside of being a smarter auto complete.</div><br/><div id="42561937" class="c"><input type="checkbox" id="c-42561937" checked=""/><div class="controls bullet"><span class="by">lumost</span><span>|</span><a href="#42561874">parent</a><span>|</span><a href="#42562086">next</a><span>|</span><label class="collapse" for="c-42561937">[-]</label><label class="expand" for="c-42561937">[15 more]</label></div><br/><div class="children"><div class="content">When I started my career in 2010, google was a semi-serious skill. All of the little things that we know how to do now such as ignoring certain sites, lingering on others, and iteratively refining our search queries were not universally known at the time. Experienced engineers often relied on encyclopedic knowledge of their environment or by &quot;reading the manual&quot;.<p>In my experience, LLM tools are the same, you ask for something basic initially and then iteratively refine the query either via dialog or a new prompt until you get what you are looking for or hit the end of the LLM&#x27;s capability. Knowing when you&#x27;ve reached the latter is critically important.</div><br/><div id="42562726" class="c"><input type="checkbox" id="c-42562726" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42561937">parent</a><span>|</span><a href="#42562170">next</a><span>|</span><label class="collapse" for="c-42562726">[-]</label><label class="expand" for="c-42562726">[2 more]</label></div><br/><div class="children"><div class="content">One difference is that skillful googling still only involved typing a few keywords or a short phrase and some syntax, and then knowing how to skim the results and iterate, and how to operate your browser efficiently. With LLMs, you have to type a lot more (and&#x2F;or use voice input), and often also read more, it’s also not stateless&#x2F;repeatable like following a web link, and most output looks the same (as opposed to the variations in web sites). I pride(d) myself on my Google foo, it was fun, but I find using LLMs to be quite exhausting in comparison.</div><br/><div id="42563722" class="c"><input type="checkbox" id="c-42563722" checked=""/><div class="controls bullet"><span class="by">j_bum</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562726">parent</a><span>|</span><a href="#42562170">next</a><span>|</span><label class="collapse" for="c-42563722">[-]</label><label class="expand" for="c-42563722">[1 more]</label></div><br/><div class="children"><div class="content">I also find LLMs to be more exhausting than Googling, but for me they’ve been ultimately more enriching and efficient.<p>Specifically, I’ve been using Kagi Assistant over the past 1.5 months for serious and lengthy searches, and I can’t imagine going back to traditional search.<p>I’m currently sold on this model of LLM assisted search (where explicit links are provided) over the old Google foo skills I developed during grad school.<p>Example search topics include deep dives and guidance for my first NAS build, finding new bioinformatics methods, and other random biomedical info.</div><br/></div></div></div></div><div id="42562170" class="c"><input type="checkbox" id="c-42562170" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42561937">parent</a><span>|</span><a href="#42562726">prev</a><span>|</span><a href="#42563558">next</a><span>|</span><label class="collapse" for="c-42562170">[-]</label><label class="expand" for="c-42562170">[11 more]</label></div><br/><div class="children"><div class="content">The problems with that skill is that:<p>* Most existing LLM interfaces are very bad at <i>editing</i> history, instead focusing entirely on <i>appending</i> to history. You can sort of ignore this for one-shot, and this can be properly fixed with additional custom tools, but ...<p>* By the time you refine your input enough to patch over all the errors in the LLM&#x27;s output for your sensible input, you&#x27;re bigger than the LLM can actually handle (much smaller than the alleged context window), so it starts randomly ignoring significant chunks of what you wrote (unlike context-window problems, the ignored parts can be <i>anywhere</i> in the input).</div><br/><div id="42562866" class="c"><input type="checkbox" id="c-42562866" checked=""/><div class="controls bullet"><span class="by">dinosaurdynasty</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562170">parent</a><span>|</span><a href="#42562214">next</a><span>|</span><label class="collapse" for="c-42562866">[-]</label><label class="expand" for="c-42562866">[2 more]</label></div><br/><div class="children"><div class="content">ChatGPT basically lets you edit any of your messages at any point in the conversation, which I definitely use (e.g., if the conversation has gotten into a bad basin, the LLM misunderstood me, etc).<p>Also ChatGPT has a pretty big context window. Gemini supposedly has the biggest useful context window (~millions of tokens), though I don&#x27;t have personal experience.</div><br/><div id="42562873" class="c"><input type="checkbox" id="c-42562873" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562866">parent</a><span>|</span><a href="#42562214">next</a><span>|</span><label class="collapse" for="c-42562873">[-]</label><label class="expand" for="c-42562873">[1 more]</label></div><br/><div class="children"><div class="content">I tend to avoid editing previous messages because it breaks my mental model of the sequence that got me to the current state. That&#x27;s more of a bias from my goal to do &quot;research&quot; into how these models work though - I&#x27;m always trying to maintain the cleanest possible record of what I did so I can learn from the transcript later.</div><br/></div></div></div></div><div id="42562214" class="c"><input type="checkbox" id="c-42562214" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562170">parent</a><span>|</span><a href="#42562866">prev</a><span>|</span><a href="#42563567">next</a><span>|</span><label class="collapse" for="c-42562214">[-]</label><label class="expand" for="c-42562214">[7 more]</label></div><br/><div class="children"><div class="content">Yeah, a key thing to understand about LLMs is that managing the context is <i>everything</i>. You need to know when to wipe the slate by starting a new chat session and then pasting across a subset of the previous conversation.<p>A lot of my most complex LLM interactions take place across multiple sessions - and in some cases I&#x27;ll even move the project from Claude 3.5 Sonnet to OpenAI o1 (or vice versa) to help get out of a rut.<p>It&#x27;s infuriatingly difficult to explain why I decide to do that though!</div><br/><div id="42562394" class="c"><input type="checkbox" id="c-42562394" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562214">parent</a><span>|</span><a href="#42562366">next</a><span>|</span><label class="collapse" for="c-42562394">[-]</label><label class="expand" for="c-42562394">[5 more]</label></div><br/><div class="children"><div class="content">What kinds of things do you with these LLMs?<p>I feel like I’m good at understanding context. I’ve been working in AI startups over the last 2 years. Currently at an AI search startup.<p>Managing context for info retrieval is the name of the game.<p>But for my personal use as a developer, they’ve caused me much headache.<p>Answers that are subtly wrong in such a way that it took me a week to realize my initial assumption based on the LLM response was totally bunk.<p>This happened twice. With the yjs library, it gave me half incorrect information that led me to misimplementing the sync protocol. Granted it’s a fairly new library.<p>And again with the web history api. It said that the history stack only exists until a page reload.
The examples it gave me ran as it described, but that isn’t how the history api works.<p>I lost a week of time because of that assumption.<p>I’ve been hesitant to dive back in since then. I ask questions every now and again, but I jump off much faster now if I even think it may be wrong.</div><br/><div id="42563175" class="c"><input type="checkbox" id="c-42563175" checked=""/><div class="controls bullet"><span class="by">gavindean90</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562394">parent</a><span>|</span><a href="#42563469">next</a><span>|</span><label class="collapse" for="c-42563175">[-]</label><label class="expand" for="c-42563175">[1 more]</label></div><br/><div class="children"><div class="content">There is no substitute for cold hard facts. LLMs do not provide that unless it’s literally the easiest thing for them to do and even then not always.<p>In the case you were in I would go out of my way to feed the docs to the LLM and then use the LLM to interrogate the docs and then verify the understanding I got from the LLM with a personal reading of the docs that were relevant.<p>You might think it takes just as long of not longer to do it my way rather than just reading the docs myself. Sometimes it can. But as you get good at the workflow you find that the time sien finding the relevant docs goes down and you get an instant plausible interpretation of the docs added too. You can then very quickly produce application code right away and then docs of the code you write.</div><br/></div></div><div id="42563469" class="c"><input type="checkbox" id="c-42563469" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562394">parent</a><span>|</span><a href="#42563175">prev</a><span>|</span><a href="#42563392">next</a><span>|</span><label class="collapse" for="c-42563469">[-]</label><label class="expand" for="c-42563469">[1 more]</label></div><br/><div class="children"><div class="content">Not OP, but I&#x27;ve just gotten really used to verifying implementation details. Yup, those subtle ones really suck. It&#x27;s pretty much just up to intuition if something in the response (or your followups) rings the `not quite right` bell for you.</div><br/></div></div><div id="42563392" class="c"><input type="checkbox" id="c-42563392" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562394">parent</a><span>|</span><a href="#42563469">prev</a><span>|</span><a href="#42562366">next</a><span>|</span><label class="collapse" for="c-42563392">[-]</label><label class="expand" for="c-42563392">[2 more]</label></div><br/><div class="children"><div class="content">Here are a bunch of things I use LLMs for relating to code.<p>- Running micro-benchmarks (using Python in Code Interpreter) - if I have a question about which of two approaches is faster I often use this pattern: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Apr&#x2F;12&#x2F;code-interpreter&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Apr&#x2F;12&#x2F;code-interpreter&#x2F;</a><p>- Building small ad-hoc one-off tools. Many of the examples in <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Oct&#x2F;21&#x2F;claude-artifacts&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Oct&#x2F;21&#x2F;claude-artifacts&#x2F;</a> fit that bill, and I have a bunch more in my tools tag here: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;tools&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;tools&#x2F;</a> - Geoffrey Litt wrote a great piece the other day about custom developer tools which matches how I think about this: <a href="https:&#x2F;&#x2F;www.geoffreylitt.com&#x2F;2024&#x2F;12&#x2F;22&#x2F;making-programming-more-fun-with-an-ai-generated-debugger.html" rel="nofollow">https:&#x2F;&#x2F;www.geoffreylitt.com&#x2F;2024&#x2F;12&#x2F;22&#x2F;making-programming-m...</a><p>- Building front-end prototypes - I use Claude Artifacts for this all the time, if I have an idea for a UI I&#x27;ll get Claude to spin up an almost instant demo so I can interact with it and see if it feels right. I&#x27;ll often copy the code out and use it as the starting point for my production feature.<p>- DSLs like SQL, Bash scripts, jq, AppleScript, grep - I use these WAY more than I used to because 9&#x2F;10 times Claude gives me exactly what I needed from a single prompt. I built a CLI tool for prompt-driven jq programs recently: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Oct&#x2F;27&#x2F;llm-jq&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Oct&#x2F;27&#x2F;llm-jq&#x2F;</a><p>- Ad-hoc sidequests. This is a pretty broad category, but it&#x27;s effectively little coding projects which I shouldn&#x27;t actually be working on at all but I&#x27;ll let myself get distracted if an LLM can get me there in a few minutes: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Mar&#x2F;22&#x2F;claude-and-chatgpt-case-study&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Mar&#x2F;22&#x2F;claude-and-chatgpt-cas...</a><p>- Writing C extensions for SQLite while I&#x27;m walking my dog on the beach. I am not a C programmer but I find it extremely entertaining that ChatGPT Code Interpreter, prompted from my phone, can write, compile and test C extension for SQLite for me: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Mar&#x2F;23&#x2F;building-c-extensions-for-sqlite-with-chatgpt-code-interpreter&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Mar&#x2F;23&#x2F;building-c-extensions-...</a><p>- That&#x27;s actually a good example of a general pattern: I use this stuff for exploratory prototyping outside of my usual (Python+JavaScript) stack <i>all the time</i>. Usually this leads nowhere, but occasionally it might turn into a real project (like this AppleScript example: <a href="https:&#x2F;&#x2F;til.simonwillison.net&#x2F;gpt3&#x2F;chatgpt-applescript" rel="nofollow">https:&#x2F;&#x2F;til.simonwillison.net&#x2F;gpt3&#x2F;chatgpt-applescript</a> )<p>- Actually writing code. Here&#x27;s a Python&#x2F;Django app I wrote almost entirely with Claude: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Aug&#x2F;8&#x2F;django-http-debug&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Aug&#x2F;8&#x2F;django-http-debug&#x2F;</a> - again, this was something of a side-project - not something worth spending a full day on but worthwhile if I could get it done in a couple of hours.<p>- Mucking around with APIs. Having a web UI for exploring an API is really useful, and Claude can often knock those out from a single prompt. <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Dec&#x2F;17&#x2F;openai-webrtc&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Dec&#x2F;17&#x2F;openai-webrtc&#x2F;</a> is a good example of that.<p>There&#x27;s a TON more, but this probably represents the majority of my usage.</div><br/><div id="42563514" class="c"><input type="checkbox" id="c-42563514" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42563392">parent</a><span>|</span><a href="#42562366">next</a><span>|</span><label class="collapse" for="c-42563514">[-]</label><label class="expand" for="c-42563514">[1 more]</label></div><br/><div class="children"><div class="content">Thank you!<p>I’ll read through these and try again in the new year.</div><br/></div></div></div></div></div></div><div id="42562366" class="c"><input type="checkbox" id="c-42562366" checked=""/><div class="controls bullet"><span class="by">grimgrin</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562214">parent</a><span>|</span><a href="#42562394">prev</a><span>|</span><a href="#42563567">next</a><span>|</span><label class="collapse" for="c-42562366">[-]</label><label class="expand" for="c-42562366">[1 more]</label></div><br/><div class="children"><div class="content">I bought in early to typingmind, a great web based frontend. Good for editing context, and switching from say gemini to claude. This is a very normal flow for me, and whatever tool you use should enable this<p>also nice to interact with an LLM in vim, as the context is the buffer<p>obviously simon’s llm tool rules. I’ve wrapped it for vim</div><br/></div></div></div></div><div id="42563567" class="c"><input type="checkbox" id="c-42563567" checked=""/><div class="controls bullet"><span class="by">cruffle_duffle</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562170">parent</a><span>|</span><a href="#42562214">prev</a><span>|</span><a href="#42563558">next</a><span>|</span><label class="collapse" for="c-42563567">[-]</label><label class="expand" for="c-42563567">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Most existing LLM interfaces are very bad at editing history, instead focusing entirely on appending to history. You can sort of ignore this for one-shot, and this can be properly fixed with additional custom tools, but ...<p>Somebody somewhere needs to provide a threaded interface to an LLM.</div><br/></div></div></div></div><div id="42563558" class="c"><input type="checkbox" id="c-42563558" checked=""/><div class="controls bullet"><span class="by">Obscurity4340</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42561937">parent</a><span>|</span><a href="#42562170">prev</a><span>|</span><a href="#42562086">next</a><span>|</span><label class="collapse" for="c-42563558">[-]</label><label class="expand" for="c-42563558">[1 more]</label></div><br/><div class="children"><div class="content">Googlefu is how its usually called. It would be fantastic if there was a general course to teach it</div><br/></div></div></div></div><div id="42562086" class="c"><input type="checkbox" id="c-42562086" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">parent</a><span>|</span><a href="#42561937">prev</a><span>|</span><a href="#42561965">next</a><span>|</span><label class="collapse" for="c-42562086">[-]</label><label class="expand" for="c-42562086">[4 more]</label></div><br/><div class="children"><div class="content">One of the things I find most frustrating about LLMs is how resistant they are to teaching other people how to use them!<p>I&#x27;d love to figure this out. I&#x27;ve written more about them than most people at this point, and my goal has always been to help people learn what they can and cannot do - but distilling that down to a concise set of lessons continues to defeat me.<p>The only way to really get to grips with them is to use them, a lot. You need to try things that fail, and other things that work, and build up an intuition about their strengths and weaknesses.<p>The problem with intuition is it&#x27;s really hard to download that into someone else&#x27;s head.<p>I share a <i>ton</i> of chat conversations to show how I use them - <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;tools&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;tools&#x2F;</a> and <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;ai-assisted-programming&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;ai-assisted-programming&#x2F;</a> have a bunch of links to my exported Claude transcripts.</div><br/><div id="42562333" class="c"><input type="checkbox" id="c-42562333" checked=""/><div class="controls bullet"><span class="by">bjt</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562086">parent</a><span>|</span><a href="#42563980">next</a><span>|</span><label class="collapse" for="c-42562333">[-]</label><label class="expand" for="c-42562333">[2 more]</label></div><br/><div class="children"><div class="content">Thank you for doing this work, though.<p>My first stab at trying ChatGPT last year was asking it to write some Rust code to do audio processing.  It was not a happy experience. I stepped back and didn&#x27;t play with LLMs at all for a while after that.  Reading your posts has helped me keep tabs on the state of the art and decide to jump back in (though with different&#x2F;easier problems this time).</div><br/><div id="42564617" class="c"><input type="checkbox" id="c-42564617" checked=""/><div class="controls bullet"><span class="by">djhn</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562333">parent</a><span>|</span><a href="#42563980">next</a><span>|</span><label class="collapse" for="c-42564617">[-]</label><label class="expand" for="c-42564617">[1 more]</label></div><br/><div class="children"><div class="content">To be fair I think that is a hard task even for a human expert, in the sense that there isn’t much prior art.</div><br/></div></div></div></div></div></div><div id="42561965" class="c"><input type="checkbox" id="c-42561965" checked=""/><div class="controls bullet"><span class="by">perrygeo</span><span>|</span><a href="#42561874">parent</a><span>|</span><a href="#42562086">prev</a><span>|</span><a href="#42562168">next</a><span>|</span><label class="collapse" for="c-42561965">[-]</label><label class="expand" for="c-42561965">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a similar dynamic in building reliable distributed systems on top of an unreliable network. The parts are prone to failure but the system can keep on working.<p>The tricky problem with LLMs is identifying failures - if you&#x27;re asking the question, it&#x27;s implied that you don&#x27;t have enough context to assess whether it&#x27;s a hallucination or a good recommendation! One approach is to build ensembles of agents that can check each other&#x27;s work, but that&#x27;s a resource-intensive solution.</div><br/></div></div><div id="42562168" class="c"><input type="checkbox" id="c-42562168" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#42561874">parent</a><span>|</span><a href="#42561965">prev</a><span>|</span><a href="#42563656">next</a><span>|</span><label class="collapse" for="c-42562168">[-]</label><label class="expand" for="c-42562168">[12 more]</label></div><br/><div class="children"><div class="content">I think most tech folks struggle with it because they treat LLMs as computer programs, and their experience is that SW should be extremely reliable - imagine using a calculator that was wrong 5% of the time - no one would accept that!<p>Instead, think of an LLM as the equivalent of giving a human a menial task. You <i>know</i> that they&#x27;re not 100% reliable, and so you give them only tasks that you can quickly verify and correct.<p>Abstract that out a bit further, and realize that most managers don&#x27;t expect their reports to be 100% reliable.<p>Don&#x27;t use LLMs where accuracy is paramount. Use it to automate away tedious stuff. Examples for me:<p>Cleaning up speech recognition. I use a traditional voice recognition tool to transcribe, and then have GPT clean it up. I&#x27;ve tried voice recognition tools for  dictation on and off for over a decade, and always gave up because even a 95% accuracy is a pain to clean up. But now, I route the output to GPT automatically. It still has issues, but I now often go paragraphs before I have to correct anything. For personal notes, I mostly don&#x27;t even bother checking its accuracy - I do it only when dictating things others will look at.<p>And then add embellishments to that. I was dictating out a recipe I needed to send to someone. I told GPT up front to write any number that appears next to an ingredient as a numeral (i.e. 3 instead of &quot;three&quot;). Did a great job - didn&#x27;t need to correct anything.<p>And then there are always the &quot;I could do this myself but I didn&#x27;t have time so I gave it to GPT&quot; category. I was giving a presentation that involved graphs (nodes, edges, etc). I was on a tight deadline and didn&#x27;t want to figure out how to draw graphs. So I made a tabular representation of my graph, gave it to GPT, and asked it to write graphviz code to make that graph. It did it perfectly (correct nodes and edges, too!)<p>Sure, if I had time, I&#x27;d go learn graphviz myself. But I wouldn&#x27;t have. The chances I&#x27;ll need graphviz again in the next few years is virtually 0.<p>I&#x27;ve actually used LLMs to do quick reformatting of data a few times. You just have to be careful that you can verify the output <i>quickly</i>. If it&#x27;s a long table, then don&#x27;t use LLMs for this.<p>Another example: I have a custom note taking tool. It&#x27;s just for me. For convenience, I also made an HTML export. Wouldn&#x27;t it be great if it automatically made alt text for each image I have in my notes? I would just need to send it to the LLM and get the text. It&#x27;s fractions of a cent per image! The current services are a lot more accurate at image recognition than I need them to be for this purpose!<p>Oh, and then of course, having it write Bash scripts and CSS for me :-) (not a frontend developer - I&#x27;ve learned CSS in the past, but it&#x27;s quicker to verify whatever it throws at me than Google it).<p>Any time you have a task and lament &quot;Oh, this is likely easy, but I just don&#x27;t have the time&quot; consider how you could make an LLM do it.</div><br/><div id="42562805" class="c"><input type="checkbox" id="c-42562805" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562168">parent</a><span>|</span><a href="#42563808">next</a><span>|</span><label class="collapse" for="c-42562805">[-]</label><label class="expand" for="c-42562805">[8 more]</label></div><br/><div class="children"><div class="content">&gt; Don&#x27;t use LLMs where accuracy is paramount.<p>Then why do people keep pushing it for code related tasks?<p>Accuracy and precision is paramount with code. It needs to express exactly what needs to be done and how.</div><br/><div id="42563399" class="c"><input type="checkbox" id="c-42563399" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562805">parent</a><span>|</span><a href="#42562838">next</a><span>|</span><label class="collapse" for="c-42563399">[-]</label><label class="expand" for="c-42563399">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Then why do people keep pushing it for code related tasks?<p>They don&#x27;t. You are likely experiencing selection bias. My guess is you work in SW, and so it makes sense that you&#x27;re the target of those campaigns. The bulk of ChatGPT subscribers are not doing SW, and no one is bugging them to use it for code related tasks.</div><br/><div id="42563703" class="c"><input type="checkbox" id="c-42563703" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42563399">parent</a><span>|</span><a href="#42562838">next</a><span>|</span><label class="collapse" for="c-42563703">[-]</label><label class="expand" for="c-42563703">[1 more]</label></div><br/><div class="children"><div class="content">I mean people in the software field absolutely push for LLMs to write code…<p>Obviously people not in the software field wouldn’t care…</div><br/></div></div></div></div><div id="42562838" class="c"><input type="checkbox" id="c-42562838" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562805">parent</a><span>|</span><a href="#42563399">prev</a><span>|</span><a href="#42563808">next</a><span>|</span><label class="collapse" for="c-42562838">[-]</label><label class="expand" for="c-42562838">[5 more]</label></div><br/><div class="children"><div class="content">Code is the best possible application of LLMs because you can TEST the output.<p>If the LLM hallucinates something the code won&#x27;t compile or run.<p>If the LLM makes a logic error you&#x27;ll catch it in the manual QA process.<p>(If you don&#x27;t have good personal manual QA habits, don&#x27;t try using LLMs to write your code. And maybe don&#x27;t hit &quot;accept&quot; on other developer&#x27;s code reviews either?)</div><br/><div id="42563118" class="c"><input type="checkbox" id="c-42563118" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562838">parent</a><span>|</span><a href="#42563808">next</a><span>|</span><label class="collapse" for="c-42563118">[-]</label><label class="expand" for="c-42563118">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Code is the best possible application of LLMs because you can TEST the output.<p>This is an overly simplistic view of software development.<p>Poorly made abstractions and functions will have knock on effects on future code that can be hard to predict.<p>Not to mention that code can have side effects that may not affect a given test case, or the code could be poorly optimized, etc.<p>Just because code compiles or passes a test does not mean it’s entirely correct. If it did, we wouldn’t have bugs anymore.<p>The usual response to this is something like “we can use the LLM to refactor LLM code if we need” but, in my experience, this leads to very complex, hard to reason about codebases.<p>Especially if the stack isn’t Python or JavaScript.</div><br/><div id="42563125" class="c"><input type="checkbox" id="c-42563125" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42563118">parent</a><span>|</span><a href="#42563808">next</a><span>|</span><label class="collapse" for="c-42563125">[-]</label><label class="expand" for="c-42563125">[3 more]</label></div><br/><div class="children"><div class="content">So code review LLM-generated code and reject it (or require changes to it) if it doesn&#x27;t fit your idea of what good code looks like.</div><br/><div id="42563264" class="c"><input type="checkbox" id="c-42563264" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42563125">parent</a><span>|</span><a href="#42563808">next</a><span>|</span><label class="collapse" for="c-42563264">[-]</label><label class="expand" for="c-42563264">[2 more]</label></div><br/><div class="children"><div class="content">Or… yknow… I could just write the code…<p>Instead of going through a multi step process to get an LLM to generate it, review it, reject it, and repeat…<p>I wonder why you reply to these comments, but not my other asking what you use LLMs for and specifically explaining how they failed me.</div><br/><div id="42563344" class="c"><input type="checkbox" id="c-42563344" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42563264">parent</a><span>|</span><a href="#42563808">next</a><span>|</span><label class="collapse" for="c-42563344">[-]</label><label class="expand" for="c-42563344">[1 more]</label></div><br/><div class="children"><div class="content">Found that comment here, about to reply: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42562394">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42562394</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42563808" class="c"><input type="checkbox" id="c-42563808" checked=""/><div class="controls bullet"><span class="by">zahlman</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562168">parent</a><span>|</span><a href="#42562805">prev</a><span>|</span><a href="#42562789">next</a><span>|</span><label class="collapse" for="c-42563808">[-]</label><label class="expand" for="c-42563808">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Don&#x27;t use LLMs where accuracy is paramount. Use it to automate away tedious stuff.<p>My programmer mind tells me that &quot;tedious stuff&quot; is where accuracy is the most important.</div><br/></div></div><div id="42562789" class="c"><input type="checkbox" id="c-42562789" checked=""/><div class="controls bullet"><span class="by">jaredsohn</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562168">parent</a><span>|</span><a href="#42563808">prev</a><span>|</span><a href="#42562773">next</a><span>|</span><label class="collapse" for="c-42562789">[-]</label><label class="expand" for="c-42562789">[1 more]</label></div><br/><div class="children"><div class="content">A similar use case for me - I wrote some technical documentation for our wiki about a somewhat complicated relationship between ids in some database tables. I copied my text explanation into an LLM and asked it to make a diagram and it did so. Took very little time from me and it was fast&#x2F;easy to verify that the quality was good.</div><br/></div></div><div id="42562773" class="c"><input type="checkbox" id="c-42562773" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562168">parent</a><span>|</span><a href="#42562789">prev</a><span>|</span><a href="#42563656">next</a><span>|</span><label class="collapse" for="c-42562773">[-]</label><label class="expand" for="c-42562773">[1 more]</label></div><br/><div class="children"><div class="content">I think there’s the added reason that a lot of folks went into tech because (consciously or unconsciously) they prefer dealing with predictable machines than with unreliable humans. And now that career choice begins to look like a bait and switch. ;)</div><br/></div></div></div></div><div id="42563656" class="c"><input type="checkbox" id="c-42563656" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#42561874">parent</a><span>|</span><a href="#42562168">prev</a><span>|</span><a href="#42561986">next</a><span>|</span><label class="collapse" for="c-42563656">[-]</label><label class="expand" for="c-42563656">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s really important to go and read the code that the author of this article actually produces with LLMs. He posted on hacker news a few months ago, a post called something like &quot;everything I&#x27;ve made with ChatGPT in the month of September&quot; or something. He&#x27;s producing little toy applications that don&#x27;t even begin to resemble real production code. He thinks these &quot;tools&quot; are useful because they help him write pointless slop.</div><br/></div></div><div id="42562147" class="c"><input type="checkbox" id="c-42562147" checked=""/><div class="controls bullet"><span class="by">swalsh</span><span>|</span><a href="#42561874">parent</a><span>|</span><a href="#42561986">prev</a><span>|</span><a href="#42560993">next</a><span>|</span><label class="collapse" for="c-42562147">[-]</label><label class="expand" for="c-42562147">[20 more]</label></div><br/><div class="children"><div class="content">It&#x27;s amazing this is still an opinion in 2025.  I now ask devs how they use AI as part of their workflows when I interview.  It&#x27;s a standard skill I expect my guys to have.</div><br/><div id="42562636" class="c"><input type="checkbox" id="c-42562636" checked=""/><div class="controls bullet"><span class="by">sramam</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562147">parent</a><span>|</span><a href="#42562412">next</a><span>|</span><label class="collapse" for="c-42562636">[-]</label><label class="expand" for="c-42562636">[1 more]</label></div><br/><div class="children"><div class="content">I concur that asking devs how they use AI is a great idea.<p>Recently, I shared a code base with a junior dev and she was surprised with the speed and sophistication of the code. The LLM did 80+% of the &quot;coding&quot;.<p>What was telling was as she was grokking the code (for helping the ~20%), she was surprised at the quality of the code - her use of the LLM did not yield code of similar quality.<p>I find that the more domain awareness one brings to the table, the better the output is. Basically the clearer one&#x27;s vision of the end-state, the better the output.<p>One other positive side-effect of using &quot;LLMs as a junior-dev&quot; for me has been that my ambitions are greater. I want it all - better code, more sophisticated capabilities even for relatively not-important projects, documentation, tests, debug-ability. And once the basic structure is in place, many a time it is trivial to get the rest.<p>It&#x27;s never 100%, but even with 80+%, I am faster than ever before, deliver better quality code, and can switch domains multiple times a week and never feel drained.<p>Sharing best AI hacks within a team will have the same effect as code-reviews do in ensuring consistency. Perhaps an &quot;LLM chat review&quot;, especially when something particularly novel was accomplished!</div><br/></div></div><div id="42562412" class="c"><input type="checkbox" id="c-42562412" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562147">parent</a><span>|</span><a href="#42562636">prev</a><span>|</span><a href="#42562746">next</a><span>|</span><label class="collapse" for="c-42562412">[-]</label><label class="expand" for="c-42562412">[7 more]</label></div><br/><div class="children"><div class="content">I feel bad for your team.<p>Let people work how they want. I wouldn’t not hire someone on the basis of them not using a language server.<p>The creator of the Odin language famously doesn’t use one. He’s says that he, specifically, is faster without one.</div><br/><div id="42562563" class="c"><input type="checkbox" id="c-42562563" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562412">parent</a><span>|</span><a href="#42564019">next</a><span>|</span><label class="collapse" for="c-42562563">[-]</label><label class="expand" for="c-42562563">[5 more]</label></div><br/><div class="children"><div class="content">No, it’s reasonable. If your team uses Git then it’s a valid question to establish if someone has only worked with Perforce.<p>They didn’t say how heavily they weight the question.<p>(All that said I expect that, soon, experience with the appropriate LLM tooling will be as important as having experience with the language  your system is implemented in.)</div><br/><div id="42562757" class="c"><input type="checkbox" id="c-42562757" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562563">parent</a><span>|</span><a href="#42562896">next</a><span>|</span><label class="collapse" for="c-42562757">[-]</label><label class="expand" for="c-42562757">[2 more]</label></div><br/><div class="children"><div class="content">Right, but using git is a team wide thing.<p>I can’t use perforce while my company is on git.<p>But if I do or do not use an LLM to assist me while coding, my team is unaffected.<p>If someone liked jetbrains, but your team used neovim, would you force them to use neovim?</div><br/><div id="42564775" class="c"><input type="checkbox" id="c-42564775" checked=""/><div class="controls bullet"><span class="by">Kwpolska</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562757">parent</a><span>|</span><a href="#42562896">next</a><span>|</span><label class="collapse" for="c-42564775">[-]</label><label class="expand" for="c-42564775">[1 more]</label></div><br/><div class="children"><div class="content">Editors may also be a team decision in some places. Some teams are using features unique to one IDE, for example.</div><br/></div></div></div></div><div id="42562896" class="c"><input type="checkbox" id="c-42562896" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562563">parent</a><span>|</span><a href="#42562757">prev</a><span>|</span><a href="#42564019">next</a><span>|</span><label class="collapse" for="c-42562896">[-]</label><label class="expand" for="c-42562896">[2 more]</label></div><br/><div class="children"><div class="content">You hire people based on their fundamental knowledge and the ability to learn, not skills in arbitrary tools and frameworks which come and go every other day. If someone has used Perforce they will be able to get perfectly comfortable with Git by the end of their first week. So not knowing Git is an idiotic reason to reject a skilled developer. Same with programming languages, and just about every other aspect of software development.</div><br/><div id="42564040" class="c"><input type="checkbox" id="c-42564040" checked=""/><div class="controls bullet"><span class="by">swalsh</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562896">parent</a><span>|</span><a href="#42564019">next</a><span>|</span><label class="collapse" for="c-42564040">[-]</label><label class="expand" for="c-42564040">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really test any specific tools or frameworks, what i&#x27;m using has changed twice just in the last year.  More so, I just want to hear that the candidate has some knowledge of what the current models can do well, what they can&#x27;t do, and how they&#x27;re integrating it.  Whether you&#x27;re copying pasting code or using something like cursor is not what i&#x27;m concerned about.</div><br/></div></div></div></div></div></div><div id="42564019" class="c"><input type="checkbox" id="c-42564019" checked=""/><div class="controls bullet"><span class="by">swalsh</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562412">parent</a><span>|</span><a href="#42562563">prev</a><span>|</span><a href="#42562746">next</a><span>|</span><label class="collapse" for="c-42564019">[-]</label><label class="expand" for="c-42564019">[1 more]</label></div><br/><div class="children"><div class="content">My expectations around productivity are going to assume you&#x27;re using AI.  That means stuff that might have taken a few days, i&#x27;m going to expect in a few hours or less.  It&#x27;s not unreasonable, i&#x27;ve seen over and over agian that kind of speed up.  I have a lot less approval to hire people than I used to... so it&#x27;s really important to me that I can extract that level of productivity out of my team.<p>If you&#x27;re &quot;working the way you want to&quot; ie still handrolling all your code, you&#x27;re going to find my expectations unrealistic, and that is certainly not fair to you.</div><br/></div></div></div></div><div id="42562746" class="c"><input type="checkbox" id="c-42562746" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562147">parent</a><span>|</span><a href="#42562412">prev</a><span>|</span><a href="#42562173">next</a><span>|</span><label class="collapse" for="c-42562746">[-]</label><label class="expand" for="c-42562746">[8 more]</label></div><br/><div class="children"><div class="content">Using cloud-based AI is a no-go where I work, for IP and contractual reasons. And on-premises AI is not as capable and more difficult to integrate.</div><br/><div id="42562759" class="c"><input type="checkbox" id="c-42562759" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562746">parent</a><span>|</span><a href="#42562173">next</a><span>|</span><label class="collapse" for="c-42562759">[-]</label><label class="expand" for="c-42562759">[7 more]</label></div><br/><div class="children"><div class="content">Have you tried the latest open weight models? They&#x27;re SO MUCH better today than they were even six months ago.<p>If I was in an environment that didn&#x27;t allow hosted API models I&#x27;d absolutely be looking into the various Llama 3 models or Qwen2.5-Coder-32B.</div><br/><div id="42562911" class="c"><input type="checkbox" id="c-42562911" checked=""/><div class="controls bullet"><span class="by">3eb7988a1663</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562759">parent</a><span>|</span><a href="#42562913">next</a><span>|</span><label class="collapse" for="c-42562911">[-]</label><label class="expand" for="c-42562911">[2 more]</label></div><br/><div class="children"><div class="content">Legal does not even want us running offline models for reasons. I assume that comes down to not knowing what offline-only means, but such is life.</div><br/><div id="42562967" class="c"><input type="checkbox" id="c-42562967" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562911">parent</a><span>|</span><a href="#42562913">next</a><span>|</span><label class="collapse" for="c-42562967">[-]</label><label class="expand" for="c-42562967">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they&#x27;re concerned that code written with AI assistance can&#x27;t be copyrighted? I&#x27;ve seen that idea floated in a few places.</div><br/></div></div></div></div><div id="42562913" class="c"><input type="checkbox" id="c-42562913" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562759">parent</a><span>|</span><a href="#42562911">prev</a><span>|</span><a href="#42562173">next</a><span>|</span><label class="collapse" for="c-42562913">[-]</label><label class="expand" for="c-42562913">[4 more]</label></div><br/><div class="children"><div class="content">What do you use so that you can throw in a set of documents and&#x2F;or a nontrivial code base into an LLM workspace and ask questions about it etc.? What the cloud-based services provide goes way beyond a simple chat interface or mere code completion (as you know, of course).</div><br/><div id="42562983" class="c"><input type="checkbox" id="c-42562983" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562913">parent</a><span>|</span><a href="#42562173">next</a><span>|</span><label class="collapse" for="c-42562983">[-]</label><label class="expand" for="c-42562983">[3 more]</label></div><br/><div class="children"><div class="content">I use my <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;files-to-prompt">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;files-to-prompt</a> tool like this:<p><pre><code>  files-to-prompt . -e py -e md -c | pbcopy
</code></pre>
Now I have all the Python and Markdown files from the current project on my clipboard, in Claude&#x27;s recommended XML-like format (which I find works well with other models too).<p>Then I paste that into the Claude web interface or Google&#x27;s AI Studio if it&#x27;s too long for Claude and ask questions there.<p>Sometimes I&#x27;ll pipe it straight into my own LLM CLI tool and ask questions that way:<p><pre><code>  files-to-prompt . -e py -e md -c | \
    llm -m gemini-2.0-flash-exp &#x27;which files handle JWT verification?&#x27;
</code></pre>
I can later start a chat session on top of the accumulated context like this:<p><pre><code>  llm chat -c
</code></pre>
(The -c means &quot;continue most recent conversation in the chat&quot;).</div><br/><div id="42563089" class="c"><input type="checkbox" id="c-42563089" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562983">parent</a><span>|</span><a href="#42562173">next</a><span>|</span><label class="collapse" for="c-42563089">[-]</label><label class="expand" for="c-42563089">[2 more]</label></div><br/><div class="children"><div class="content">Thanks. Google AI Studio isn’t local, I think, is it? I’ll have to test this, but our project sizes and specification documents are likely to run into size limitations for local models (or for the clipboard at the very least ;)). And what I’d be most interested in are big-picture questions and global analyses.</div><br/><div id="42563096" class="c"><input type="checkbox" id="c-42563096" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42563089">parent</a><span>|</span><a href="#42562173">next</a><span>|</span><label class="collapse" for="c-42563096">[-]</label><label class="expand" for="c-42563096">[1 more]</label></div><br/><div class="children"><div class="content">No, it&#x27;s not. I&#x27;ve not seen any local models that can handle 1m+ tokens.<p>I haven&#x27;t actually done many experiments with long context local models - I tend to hit the hosted API models for that kind of thing.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42562173" class="c"><input type="checkbox" id="c-42562173" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562147">parent</a><span>|</span><a href="#42562746">prev</a><span>|</span><a href="#42560993">next</a><span>|</span><label class="collapse" for="c-42562173">[-]</label><label class="expand" for="c-42562173">[3 more]</label></div><br/><div class="children"><div class="content">Just curious, but what AI related skills do you expect them to have?</div><br/><div id="42562648" class="c"><input type="checkbox" id="c-42562648" checked=""/><div class="controls bullet"><span class="by">eschaton</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562173">parent</a><span>|</span><a href="#42564054">next</a><span>|</span><label class="collapse" for="c-42562648">[-]</label><label class="expand" for="c-42562648">[1 more]</label></div><br/><div class="children"><div class="content">The ability to recognize and join a hype train, I presume. It’s one way to appear proactively leading-edge to marginally-informed product managers, marketers, execs and press.</div><br/></div></div><div id="42564054" class="c"><input type="checkbox" id="c-42564054" checked=""/><div class="controls bullet"><span class="by">swalsh</span><span>|</span><a href="#42561874">root</a><span>|</span><a href="#42562173">parent</a><span>|</span><a href="#42562648">prev</a><span>|</span><a href="#42560993">next</a><span>|</span><label class="collapse" for="c-42564054">[-]</label><label class="expand" for="c-42564054">[1 more]</label></div><br/><div class="children"><div class="content">I ask what their current workflow is, how they check and verify things, what their approach to prompting is etc.  I&#x27;m looking to see that they&#x27;ve developed basic skills, have a reasonable mental model of what models can do well, what they currently can&#x27;t do, and have an approach to be productive using the tools.</div><br/></div></div></div></div></div></div></div></div><div id="42560993" class="c"><input type="checkbox" id="c-42560993" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#42561874">prev</a><span>|</span><a href="#42562106">next</a><span>|</span><label class="collapse" for="c-42560993">[-]</label><label class="expand" for="c-42560993">[69 more]</label></div><br/><div class="children"><div class="content">&gt; Some of those GPT-4 models run on my laptop<p>That&#x27;s an indication that most business-sized models won&#x27;t need some giant data center. This is going to be a cheap technology most of the time.
OpenAI is thus way overvalued.</div><br/><div id="42561892" class="c"><input type="checkbox" id="c-42561892" checked=""/><div class="controls bullet"><span class="by">thinkingemote</span><span>|</span><a href="#42560993">parent</a><span>|</span><a href="#42561145">next</a><span>|</span><label class="collapse" for="c-42561892">[-]</label><label class="expand" for="c-42561892">[1 more]</label></div><br/><div class="children"><div class="content">Most of the laptops that the models can run on today are in the high end of dedicated bare metal servers. Most shared VM servers are way below these laptops. Most people buying a new laptop today won&#x27;t be able to run them, most devs getting a website up with a server won&#x27;t be able to run them.<p>This means that the definitions of &quot;laptop&quot; and &quot;server&quot; are dependent on use. We should instead talk about RAM, GPU and CPU speed which is more useful and informative but less engaging than &quot;my laptop&quot;.</div><br/></div></div><div id="42561145" class="c"><input type="checkbox" id="c-42561145" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#42560993">parent</a><span>|</span><a href="#42561892">prev</a><span>|</span><a href="#42561042">next</a><span>|</span><label class="collapse" for="c-42561145">[-]</label><label class="expand" for="c-42561145">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think openai&#x27;s valuation comes from a data center bet -- rather, I&#x27;d suppose, investors think it has a first-mover advantage on model quality that it can (maybe?) attract some buy-out interest or otherwise use in yet-to-be-specified product lines.<p>However, it has been clear for a long time that meta are just demolishing any competitor&#x27;s moats, driving the whole megacorp AI competition to razor thin margins.<p>It&#x27;s a very welcome strategy from a consumer pov, but -- it has to be said -- genius from a business pov. By deciding that no one will win, it can prevent anyone leapfrogging them at a relatively cheap price.</div><br/></div></div><div id="42561042" class="c"><input type="checkbox" id="c-42561042" checked=""/><div class="controls bullet"><span class="by">shihab</span><span>|</span><a href="#42560993">parent</a><span>|</span><a href="#42561145">prev</a><span>|</span><a href="#42561785">next</a><span>|</span><label class="collapse" for="c-42561042">[-]</label><label class="expand" for="c-42561042">[56 more]</label></div><br/><div class="children"><div class="content">The last OpenAI valuation I read about was 157 billion. I am struggling to understand what justifies this. To me, it feels like OpenAI is at best few months ahead of competitors in <i>some</i> areas. But even if I am underestimating the advantage, it&#x27;s few years instead of few months, why does it matter? It&#x27;s not like AI companies are going to enjoy the first-mover advantage internet giants had over the competition.</div><br/><div id="42561089" class="c"><input type="checkbox" id="c-42561089" checked=""/><div class="controls bullet"><span class="by">datadrivenangel</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561042">parent</a><span>|</span><a href="#42561111">next</a><span>|</span><label class="collapse" for="c-42561089">[-]</label><label class="expand" for="c-42561089">[42 more]</label></div><br/><div class="children"><div class="content">It&#x27;s justified if AGI is possible. If AGI is possible, then the entire human economy stops making sense as far as money goes, and &#x27;owning&#x27; part of OpenAI gives you power.<p>That is of course, assuming AGI is possible and exponential, and that marketshare goes to a single entity instead of a set of entities. Lots of big assumptions. Seems like we&#x27;re heading towards a slow-lackluster singularity though.</div><br/><div id="42561766" class="c"><input type="checkbox" id="c-42561766" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561089">parent</a><span>|</span><a href="#42561123">next</a><span>|</span><label class="collapse" for="c-42561766">[-]</label><label class="expand" for="c-42561766">[5 more]</label></div><br/><div class="children"><div class="content">I was thinking about how the economy has been actively makes less sense and gets divorced more and more from reality year after year, AI or not.<p>It&#x27;s the simple fact that the ability of assets to generate wealth has far outstripped the abiliy of individuals to earn money by working.<p>Somehow real estate has become so expensive <i>everywhere</i> that owning a shitty apartment is impossible for the vast majority.<p>When the world&#x27;s population was exploding during the 20th century, housing prices were not a problem, yet somehow nowadays, it&#x27;s impossible to build affordable housing to bring the prices down, though the population is stagnant or growing slowly.<p>A company can be worth $1B if someone invests $10m in it for 1% stake - where did the remaining $990m come from? Likewise, the stock market is full of trillion-dollar companies whose valuations beggar all explanation, considering the sizes of the markets they are serving.<p>The rich elites are using the wealth to control access to basic human needs (namely housing and healthcare) to squeeze the working population for every drop of money. Every wealth metric shows the 1% and the 1% of the 1% control successively larger portions of the economic pie. At this point money is ceasing to be a proxy for value and is becoming a tool for population control.<p>And the weird thing is it didn&#x27;t use to be nearly this bad even a decade ago, and we can only guess how bad it will get in a decade, AGI or not.<p>Anyway, I don&#x27;t want to turn this into a fully-written manifesto, but I have trouble expressing these ideas in a concise manner.</div><br/><div id="42563839" class="c"><input type="checkbox" id="c-42563839" checked=""/><div class="controls bullet"><span class="by">zahlman</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561766">parent</a><span>|</span><a href="#42562220">next</a><span>|</span><label class="collapse" for="c-42563839">[-]</label><label class="expand" for="c-42563839">[1 more]</label></div><br/><div class="children"><div class="content">&gt; When the world&#x27;s population was exploding during the 20th century, housing prices were not a problem, yet somehow nowadays, it&#x27;s impossible to build affordable housing to bring the prices down, though the population is stagnant or growing slowly.<p>In Canada, the population is still growing at a fairly impressive rate (<a href="https:&#x2F;&#x2F;www.macrotrends.net&#x2F;global-metrics&#x2F;countries&#x2F;CAN&#x2F;canada&#x2F;population-growth-rate" rel="nofollow">https:&#x2F;&#x2F;www.macrotrends.net&#x2F;global-metrics&#x2F;countries&#x2F;CAN&#x2F;can...</a>), and that growth tends to concentrate in major population centres. There are advocacy groups that seek to push Canadian population growth well above UN projections (e.g. the <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Century_Initiative" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Century_Initiative</a> &quot;aims to increase Canada&#x27;s population to 100 million by 2100&quot;) through immigration.
In Japan, where the population is declining, housing prices are not anything like the problem we observe in North America.<p>There&#x27;s also the supply side. &quot;Impossible to build affordable housing&quot; is in many cases a consequence of zoning restrictions. (Economists also hold very strongly that rent control doesn&#x27;t work - see e.g. <a href="https:&#x2F;&#x2F;www.brookings.edu&#x2F;articles&#x2F;what-does-economic-evidence-tell-us-about-the-effects-of-rent-control&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.brookings.edu&#x2F;articles&#x2F;what-does-economic-eviden...</a> and <a href="https:&#x2F;&#x2F;www.nmhc.org&#x2F;research-insight&#x2F;research-notes&#x2F;2023&#x2F;rent-control-vs-rent-stabilization-a-new-name-for-a-failed-concept&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nmhc.org&#x2F;research-insight&#x2F;research-notes&#x2F;2023&#x2F;re...</a> ; real &quot;affordable housing&quot; is just the effect of <i>more housing</i>.)</div><br/></div></div><div id="42562220" class="c"><input type="checkbox" id="c-42562220" checked=""/><div class="controls bullet"><span class="by">ac29</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561766">parent</a><span>|</span><a href="#42563839">prev</a><span>|</span><a href="#42562282">next</a><span>|</span><label class="collapse" for="c-42562220">[-]</label><label class="expand" for="c-42562220">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Somehow real estate has become so expensive everywhere that owning a shitty apartment is impossible for the vast majority.<p>Approximately 2&#x2F;3s of homes in the US are owner occupied.</div><br/></div></div><div id="42562282" class="c"><input type="checkbox" id="c-42562282" checked=""/><div class="controls bullet"><span class="by">orangecat</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561766">parent</a><span>|</span><a href="#42562220">prev</a><span>|</span><a href="#42561901">next</a><span>|</span><label class="collapse" for="c-42562282">[-]</label><label class="expand" for="c-42562282">[1 more]</label></div><br/><div class="children"><div class="content"><i>Somehow real estate has become so expensive everywhere that owning a shitty apartment is impossible for the vast majority.</i><p>That&#x27;s to be expected when governments forbid people from building housing. The only thing I find surprising is when people blame this on &quot;capitalism&quot;.</div><br/></div></div><div id="42561901" class="c"><input type="checkbox" id="c-42561901" checked=""/><div class="controls bullet"><span class="by">nyarlathotep_</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561766">parent</a><span>|</span><a href="#42562282">prev</a><span>|</span><a href="#42561123">next</a><span>|</span><label class="collapse" for="c-42561901">[-]</label><label class="expand" for="c-42561901">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And the weird thing is it didn&#x27;t use to be nearly this bad even a decade ago, and we can only guess how bad it will get in a decade, AGI or not.<p>The last 5 years have reflected a substantial decline in QOL in the states; you don&#x27;t even have to to look back that far.<p>The coronacircus money-printing really accelerated the decline.</div><br/></div></div></div></div><div id="42561123" class="c"><input type="checkbox" id="c-42561123" checked=""/><div class="controls bullet"><span class="by">philipkglass</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561089">parent</a><span>|</span><a href="#42561766">prev</a><span>|</span><a href="#42561193">next</a><span>|</span><label class="collapse" for="c-42561123">[-]</label><label class="expand" for="c-42561123">[14 more]</label></div><br/><div class="children"><div class="content"><i>If AGI is possible, then the entire human economy stops making sense as far as money goes, and &#x27;owning&#x27; part of OpenAI gives you power.</i><p>That&#x27;s if AGI is possible <i>and not easily replicated</i>. If AGI can be copied and&#x2F;or re-developed like other software then the value of owning OpenAI stock is more like owning stock in copper producers or other commodity sector companies. (It might even be a poorer investment. Even AGI can&#x27;t create copper atoms, so owners of real physical resources could be in a better position in a post-human-labor world.)</div><br/><div id="42561300" class="c"><input type="checkbox" id="c-42561300" checked=""/><div class="controls bullet"><span class="by">whatshisface</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561123">parent</a><span>|</span><a href="#42561493">next</a><span>|</span><label class="collapse" for="c-42561300">[-]</label><label class="expand" for="c-42561300">[5 more]</label></div><br/><div class="children"><div class="content">This belief comes from confusing the singularity (every atom on Earth is converted into a giant image of Sam Altman) with AGI (a store employee navigates a confrontation with an unruly customer, then goes home and wins at Super Mario).</div><br/><div id="42561813" class="c"><input type="checkbox" id="c-42561813" checked=""/><div class="controls bullet"><span class="by">baobabKoodaa</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561300">parent</a><span>|</span><a href="#42562764">next</a><span>|</span><label class="collapse" for="c-42561813">[-]</label><label class="expand" for="c-42561813">[1 more]</label></div><br/><div class="children"><div class="content">If I recall correctly, these terms were used more or less interchangeably for a few decades, until 2020 or so, when OpenAI started making actual progress towards AGI, and it was clear that the type of AGI that could be imagined at that point, would not be of the type that would produce singularity.</div><br/></div></div><div id="42562764" class="c"><input type="checkbox" id="c-42562764" checked=""/><div class="controls bullet"><span class="by">Teever</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561300">parent</a><span>|</span><a href="#42561813">prev</a><span>|</span><a href="#42561702">next</a><span>|</span><label class="collapse" for="c-42562764">[-]</label><label class="expand" for="c-42562764">[2 more]</label></div><br/><div class="children"><div class="content">But what if that AGI can fit inside a humanoid robot and that robot is capable of self replication even if it means digging the sand out of the ground to make silicon with a spade?</div><br/><div id="42564528" class="c"><input type="checkbox" id="c-42564528" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42562764">parent</a><span>|</span><a href="#42561702">next</a><span>|</span><label class="collapse" for="c-42564528">[-]</label><label class="expand" for="c-42564528">[1 more]</label></div><br/><div class="children"><div class="content">We already have humanoid intelligeces that self-assemble and power from common materials, as a colony of incredibly advanced nanobots.</div><br/></div></div></div></div><div id="42561702" class="c"><input type="checkbox" id="c-42561702" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561300">parent</a><span>|</span><a href="#42562764">prev</a><span>|</span><a href="#42561493">next</a><span>|</span><label class="collapse" for="c-42561702">[-]</label><label class="expand" for="c-42561702">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. I continually fail to see how &quot;the entire human economy ends&quot; overnight with another human like agent out there - especially if its confined to a server in the first place - it can&#x27;t even &quot;go home&quot; :)</div><br/></div></div></div></div><div id="42561493" class="c"><input type="checkbox" id="c-42561493" checked=""/><div class="controls bullet"><span class="by">richardw</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561123">parent</a><span>|</span><a href="#42561300">prev</a><span>|</span><a href="#42561334">next</a><span>|</span><label class="collapse" for="c-42561493">[-]</label><label class="expand" for="c-42561493">[1 more]</label></div><br/><div class="children"><div class="content">The first AGI will have such an advantage. It’ll be the first thing that is smart and tireless, can do anything from continuously hacking enemy networks to trading across all investment classes, to basically taking over the news cycle on social media. It would print money and power.</div><br/></div></div><div id="42561334" class="c"><input type="checkbox" id="c-42561334" checked=""/><div class="controls bullet"><span class="by">AnimalMuppet</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561123">parent</a><span>|</span><a href="#42561493">prev</a><span>|</span><a href="#42561193">next</a><span>|</span><label class="collapse" for="c-42561334">[-]</label><label class="expand" for="c-42561334">[7 more]</label></div><br/><div class="children"><div class="content">The GP said, &quot;and exponential&quot;.  If AGI is exponential, then the first one will have a head start advantage that compounds over time.  That is going to be hard to overcome.</div><br/><div id="42561392" class="c"><input type="checkbox" id="c-42561392" checked=""/><div class="controls bullet"><span class="by">philipkglass</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561334">parent</a><span>|</span><a href="#42561193">next</a><span>|</span><label class="collapse" for="c-42561392">[-]</label><label class="expand" for="c-42561392">[6 more]</label></div><br/><div class="children"><div class="content">I believe that AGI cannot be exponential for long because any intelligent agent can only approach nature&#x27;s limits asymptotically. The first company with AGI will be about as much ahead as, say, the first company with electrical generators [1]. A lot of science fiction about a technological singularity assumes that AGI will discover and apply new physics to develop currently-believed-impossible inventions, but I don&#x27;t consider that plausible myself. I believe that the discovery of new physics will be intellectually satisfying but generally inapplicable to industry, much like how solving the cosmological lithium problem will be career-defining for whoever does it but won&#x27;t have any application to lithium batteries.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cosmological_lithium_problem" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cosmological_lithium_problem</a><p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Siemens#1847_to_1901" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Siemens#1847_to_1901</a></div><br/><div id="42561505" class="c"><input type="checkbox" id="c-42561505" checked=""/><div class="controls bullet"><span class="by">datadrivenangel</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561392">parent</a><span>|</span><a href="#42561193">next</a><span>|</span><label class="collapse" for="c-42561505">[-]</label><label class="expand" for="c-42561505">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t recall editing my message, but HN can be wonky sometimes. :)<p>Nothing is truly exponential for long, but the logistic curve could be big enough to do almost anything if you get imaginative. Without new physics, there are still some places where we can do some amazing things with the equivalent of several trillion dollars of applied R&amp;D, which AGI gets you.</div><br/><div id="42561656" class="c"><input type="checkbox" id="c-42561656" checked=""/><div class="controls bullet"><span class="by">terribleperson</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561505">parent</a><span>|</span><a href="#42561590">next</a><span>|</span><label class="collapse" for="c-42561656">[-]</label><label class="expand" for="c-42561656">[1 more]</label></div><br/><div class="children"><div class="content">This depends on what a hypothetical &#x27;AGI&#x27; actually  costs. If a real AGI is achieved, but it costs more per unit of work than a human does... it won&#x27;t do anyone much good.</div><br/></div></div><div id="42561590" class="c"><input type="checkbox" id="c-42561590" checked=""/><div class="controls bullet"><span class="by">philipkglass</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561505">parent</a><span>|</span><a href="#42561656">prev</a><span>|</span><a href="#42561732">next</a><span>|</span><label class="collapse" for="c-42561590">[-]</label><label class="expand" for="c-42561590">[1 more]</label></div><br/><div class="children"><div class="content">I had to edit <i>my</i> message just now because I was actually unsure if you edited. Sorry for any miscommunication.</div><br/></div></div><div id="42561732" class="c"><input type="checkbox" id="c-42561732" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561505">parent</a><span>|</span><a href="#42561590">prev</a><span>|</span><a href="#42561193">next</a><span>|</span><label class="collapse" for="c-42561732">[-]</label><label class="expand" for="c-42561732">[2 more]</label></div><br/><div class="children"><div class="content">Sure but think of the Higgs... how long that took for just _one_ particle. You think an AGI, or even an ASI is going to make an experimental effort like that go any bit faster? Dream on!<p>It astounds me that people dont realize how much of this cutting edge science stuff literally does NOT happen overnight, and not even close to that; typically it takes on the order of decades!</div><br/><div id="42561853" class="c"><input type="checkbox" id="c-42561853" checked=""/><div class="controls bullet"><span class="by">datadrivenangel</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561732">parent</a><span>|</span><a href="#42561193">next</a><span>|</span><label class="collapse" for="c-42561853">[-]</label><label class="expand" for="c-42561853">[1 more]</label></div><br/><div class="children"><div class="content">Science takes decades, but there are many places where we could have more amazing things if we spent 10 times as much on applied R&amp;D and manufacturing. It wouldn&#x27;t happen overnight, but it will be transformative if people can get access to much more automated R&amp;D. We&#x27;ve seen a proliferation in makers over the last few decades as access to information is easier, and with better tools individuals will be able to do even more.<p>My point being that even if Science ends today, we still have  a lot more engineering we can benefit from.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42561193" class="c"><input type="checkbox" id="c-42561193" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561089">parent</a><span>|</span><a href="#42561123">prev</a><span>|</span><a href="#42561230">next</a><span>|</span><label class="collapse" for="c-42561193">[-]</label><label class="expand" for="c-42561193">[1 more]</label></div><br/><div class="children"><div class="content">If AGI is invented and the inventor tries to keep it secret then everyone in the world will be trying to steal it. And funding to independently create it would become effectively unlimited once it has been proven possible, much like with nuclear weapons.</div><br/></div></div><div id="42561230" class="c"><input type="checkbox" id="c-42561230" checked=""/><div class="controls bullet"><span class="by">robertlagrant</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561089">parent</a><span>|</span><a href="#42561193">prev</a><span>|</span><a href="#42561385">next</a><span>|</span><label class="collapse" for="c-42561230">[-]</label><label class="expand" for="c-42561230">[10 more]</label></div><br/><div class="children"><div class="content">&gt; If AGI is possible, then the entire human economy stops making sense as far as money goes,<p>What does this mean in terms of making me coffee or building houses?</div><br/><div id="42561350" class="c"><input type="checkbox" id="c-42561350" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561230">parent</a><span>|</span><a href="#42561842">next</a><span>|</span><label class="collapse" for="c-42561350">[-]</label><label class="expand" for="c-42561350">[8 more]</label></div><br/><div class="children"><div class="content">If we can simulate a full human intelligence at a reasonable speed, we can simulate 100 of them and ask the AGI to figure out how to make itself 10x faster.<p>Rinse and repeat.<p>That is exponential take off.<p>At the point where you have an army of AIs running at 1000x human speed it can just ask it to design the mechanisms for and write the code to make robots that automate any possible physical task.</div><br/><div id="42562290" class="c"><input type="checkbox" id="c-42562290" checked=""/><div class="controls bullet"><span class="by">edflsafoiewq</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561350">parent</a><span>|</span><a href="#42561526">next</a><span>|</span><label class="collapse" for="c-42562290">[-]</label><label class="expand" for="c-42562290">[2 more]</label></div><br/><div class="children"><div class="content">There are about 8 billion human intelligences walking around right now and they&#x27;ve got no idea how to begin making even a stupid AGI, let alone a superhuman one. Where does the idea that 100 more are going to help come from?</div><br/><div id="42563265" class="c"><input type="checkbox" id="c-42563265" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42562290">parent</a><span>|</span><a href="#42561526">next</a><span>|</span><label class="collapse" for="c-42563265">[-]</label><label class="expand" for="c-42563265">[1 more]</label></div><br/><div class="children"><div class="content">This was my argument a long time ago. The common counter was that we’d have a bunch of geniuses that knew tons of research. Well, we probably already have millions of geniuses. If anything, they use their brains for self-enrichment (eg money, entertainment) or on a huge assortment of topics. If all the human geniuses didn’t do it, then why would the AGI instances do it?<p>We also have people brilliant enough to maybe solve the AGI problem or cause our extinction. Some are amoral. Many mechanisms pushed human intelligences in other directions. They probably will for our AGI’s assuming we even give them all the power unchecked. Why are they so worried the intelligent agents will not likewise be misdirected or restrained?<p>What smart, resourceful humans have done (and not done) is a good, starting point for what AGI would do. At best, they’ll probably help optimize some chips and LLM runtimes. Patent minefields with sub-28nm design, especially mask-making, will keep unit volumes of true AGI’s much lower at higher prices than systems driven by low-paid workers with some automation.</div><br/></div></div></div></div><div id="42561526" class="c"><input type="checkbox" id="c-42561526" checked=""/><div class="controls bullet"><span class="by">GOD_Over_Djinn</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561350">parent</a><span>|</span><a href="#42562290">prev</a><span>|</span><a href="#42561842">next</a><span>|</span><label class="collapse" for="c-42561526">[-]</label><label class="expand" for="c-42561526">[5 more]</label></div><br/><div class="children"><div class="content">This sounds like magic, not science.</div><br/><div id="42561581" class="c"><input type="checkbox" id="c-42561581" checked=""/><div class="controls bullet"><span class="by">EMIRELADERO</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561526">parent</a><span>|</span><a href="#42561842">next</a><span>|</span><label class="collapse" for="c-42561581">[-]</label><label class="expand" for="c-42561581">[4 more]</label></div><br/><div class="children"><div class="content">What do you mean by this? Is there any fundamental property of intelligence, physicality, or the universe, that you think wouldn&#x27;t let this work?</div><br/><div id="42561750" class="c"><input type="checkbox" id="c-42561750" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561581">parent</a><span>|</span><a href="#42561842">next</a><span>|</span><label class="collapse" for="c-42561750">[-]</label><label class="expand" for="c-42561750">[3 more]</label></div><br/><div class="children"><div class="content">Not OP but yes. Electron size vs band gap, computing costs (in terms of electricity) any other raw materials needed for that energy, etc... sigh... its physics, always physics... what fundamental property of physics do you think would let a vertical take off in intelligence occur?</div><br/><div id="42561880" class="c"><input type="checkbox" id="c-42561880" checked=""/><div class="controls bullet"><span class="by">datadrivenangel</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561750">parent</a><span>|</span><a href="#42561842">next</a><span>|</span><label class="collapse" for="c-42561880">[-]</label><label class="expand" for="c-42561880">[2 more]</label></div><br/><div class="children"><div class="content">If you look at the rate of mathematical operations conducted, we&#x27;re already going hard vertical.  Physics and material limitations will slow that eventually as we reach a marginal return on converting the planet to computer chips, but we&#x27;re in the singularity as proxy measured by mathematical operations.</div><br/><div id="42564556" class="c"><input type="checkbox" id="c-42564556" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561880">parent</a><span>|</span><a href="#42561842">next</a><span>|</span><label class="collapse" for="c-42564556">[-]</label><label class="expand" for="c-42564556">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If you look at the rate of mathematical operations conducted, we&#x27;re already going hard vertical.<p>Not if you remember to count all the computations being done by the quintillions of nanobots across the world known as &quot;human cells.&quot;<p>That&#x27;s not only inside cells, and not just neurons either. For example, your thyroid is busy brute-forcing the impossibly large space of antibody combinations, and putting every candidate cell-release through a very rigorous set of acceptance tests.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42561842" class="c"><input type="checkbox" id="c-42561842" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561230">parent</a><span>|</span><a href="#42561350">prev</a><span>|</span><a href="#42561385">next</a><span>|</span><label class="collapse" for="c-42561842">[-]</label><label class="expand" for="c-42561842">[1 more]</label></div><br/><div class="children"><div class="content">Nothing and the hilarious thing is that the AI figureheads admit that technology (as in defined by new theorems produced and new code written), will do pathetically little to move the needle on human happiness forward.<p>The guy running Anthropic thinks the future is in biotech, developing the cure to all diseases, eternal youth etc.<p>Which is technology all right, but it&#x27;s unclear to me how these chatbots (or other AI systems) are the quickest way to get there.</div><br/></div></div></div></div><div id="42561385" class="c"><input type="checkbox" id="c-42561385" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561089">parent</a><span>|</span><a href="#42561230">prev</a><span>|</span><a href="#42561135">next</a><span>|</span><label class="collapse" for="c-42561385">[-]</label><label class="expand" for="c-42561385">[1 more]</label></div><br/><div class="children"><div class="content">We may not need smarter AI. Just less stupid AI.<p>The big problem with LLMs is that most of the time they act smart, and some of the time they do really, really dumb things and don&#x27;t notice. It&#x27;s not the ceiling that&#x27;s the problem. It&#x27;s the floor. Which is why, as the article points out, &quot;agents&quot; aren&#x27;t very useful yet. You can&#x27;t trust them to not screw up big-time.</div><br/></div></div><div id="42561135" class="c"><input type="checkbox" id="c-42561135" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561089">parent</a><span>|</span><a href="#42561385">prev</a><span>|</span><a href="#42561143">next</a><span>|</span><label class="collapse" for="c-42561135">[-]</label><label class="expand" for="c-42561135">[1 more]</label></div><br/><div class="children"><div class="content">One strata in that assumption-heap to call out explicitly: Assuming LLMs are an enabling route to AGI and not a dead-end or supplemental feature.</div><br/></div></div><div id="42561143" class="c"><input type="checkbox" id="c-42561143" checked=""/><div class="controls bullet"><span class="by">parpfish</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561089">parent</a><span>|</span><a href="#42561135">prev</a><span>|</span><a href="#42561117">next</a><span>|</span><label class="collapse" for="c-42561143">[-]</label><label class="expand" for="c-42561143">[2 more]</label></div><br/><div class="children"><div class="content">Well, AGI would make the brainy information worker part of the economy obsolete. Well still need the jobs that interact with the physical world for quite a while. So… all us HN types should get ready to work the mines or pick vegetables</div><br/><div id="42561326" class="c"><input type="checkbox" id="c-42561326" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561143">parent</a><span>|</span><a href="#42561117">next</a><span>|</span><label class="collapse" for="c-42561326">[-]</label><label class="expand" for="c-42561326">[1 more]</label></div><br/><div class="children"><div class="content">If we hit true AGI, physical labor won’t be far behind the knowledge workers. The first thing industrial manufacturers will do is turn it towards designing robotics, automating  the design of factories, and researching better electromechanical components like synthetic muscle to replace human dexterity.<p>IMO we’re going to hit the point where AI can work on designing automation to replace physical labor before we hit true AGI, much like we’re seeing with coding.</div><br/></div></div></div></div><div id="42561188" class="c"><input type="checkbox" id="c-42561188" checked=""/><div class="controls bullet"><span class="by">hdjjhhvvhga</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561089">parent</a><span>|</span><a href="#42561117">prev</a><span>|</span><a href="#42561314">next</a><span>|</span><label class="collapse" for="c-42561188">[-]</label><label class="expand" for="c-42561188">[4 more]</label></div><br/><div class="children"><div class="content">&gt;  If AGI is possible, then the entire human economy stops making sense as far as money goes<p>I heard people on HN saying this (even without the money condition) and I fail to grasp the reasoning behind it. Suppose in a few years Altman announces a model, say o11, that is supposedly AGI, and in several benchmarks it hits over 90%. I don&#x27;t believe it&#x27;s possible with LLMs because of their inherent limitations but let&#x27;s assume it can solve general tasks in a way similar to an average human.<p>Now, how come that &quot;the entire human economy stops making sense&quot;? In order to eat, we need farmers, we need construction workers, shops etc. As for white collar workers, you will need a whole range of people to maintain and further develop this AGI. So IMHO the opposite is true: the human economy will work exactly as before but the job market will continue to evolve withe people using AGI in a similar way that they use LLMs now but probably with greater confidence. (Or not.)</div><br/><div id="42561433" class="c"><input type="checkbox" id="c-42561433" checked=""/><div class="controls bullet"><span class="by">SmooL</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561188">parent</a><span>|</span><a href="#42561422">next</a><span>|</span><label class="collapse" for="c-42561433">[-]</label><label class="expand" for="c-42561433">[1 more]</label></div><br/><div class="children"><div class="content">The thinking goes:
- any job that can be done on a computer is immediately outsourced to AI, since the AI is smarter and cheaper than humans
- humanoid robots are built that are cheap to produce, using tech advances that the AI discovered
- any job that can be done by a human is immediately outsourced to a robot, since the robot is better&#x2F;faster&#x2F;stronger&#x2F;cheaper than humans</div><br/></div></div><div id="42561422" class="c"><input type="checkbox" id="c-42561422" checked=""/><div class="controls bullet"><span class="by">datadrivenangel</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561188">parent</a><span>|</span><a href="#42561433">prev</a><span>|</span><a href="#42561427">next</a><span>|</span><label class="collapse" for="c-42561422">[-]</label><label class="expand" for="c-42561422">[1 more]</label></div><br/><div class="children"><div class="content">Why do we work?  Ultimately, we work to live.* If the value of our labor is determined by scarcity, then what happens when productivity goes nearly infinite and the scarcity goes away?  We still have needs and wants, but the current market will be completely inverted.</div><br/></div></div><div id="42561427" class="c"><input type="checkbox" id="c-42561427" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561188">parent</a><span>|</span><a href="#42561422">prev</a><span>|</span><a href="#42561314">next</a><span>|</span><label class="collapse" for="c-42561427">[-]</label><label class="expand" for="c-42561427">[1 more]</label></div><br/><div class="children"><div class="content">If you think about all the people trying to automate away farming, construction, transport&#x2F;delivery - these people doing the automation themselves get automated out first, and the automation figures out how to do the rest. So a fully robotic economy is not far off, if you can achieve AGI.</div><br/></div></div></div></div><div id="42561139" class="c"><input type="checkbox" id="c-42561139" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561089">parent</a><span>|</span><a href="#42561314">prev</a><span>|</span><a href="#42561111">next</a><span>|</span><label class="collapse" for="c-42561139">[-]</label><label class="expand" for="c-42561139">[1 more]</label></div><br/><div class="children"><div class="content">If AGI is possible then that too becomes a commodity and we experience a massive round of deflation in the cost of everything not intrinsically rare. Land, food, rare materials, energy, and anything requiring human labor is expensive and everything else is almost free.<p>I don&#x27;t see how OpenAI wouldn&#x27;t crash and burn here. Given the history of models it would be at most a year before you&#x27;d have open AGI, then the horse is out of the barn and the horse begins to self-improve. Pretty soon the horse is a unicorn, then it&#x27;s a Satyr, and so on.<p>(I am a near-term AGI skeptic BTW, but I could be wrong.)<p>OpenAI&#x27;s valuation is a mixture of hype speculation and the &quot;golden boy&quot; cult around Sam Altman. In the latter sense it&#x27;s similar to the golden boy cults around Elon Musk and (politically) Donald Trump. To some extent these cults work because they are self-fulfilling feedback loops: these people raise tons of capital (economic or political) because everyone knows they&#x27;re going to raise tons of capital so they raise tons of capital.</div><br/></div></div></div></div><div id="42561111" class="c"><input type="checkbox" id="c-42561111" checked=""/><div class="controls bullet"><span class="by">criddell</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561042">parent</a><span>|</span><a href="#42561089">prev</a><span>|</span><a href="#42562779">next</a><span>|</span><label class="collapse" for="c-42561111">[-]</label><label class="expand" for="c-42561111">[1 more]</label></div><br/><div class="children"><div class="content">&gt; what justifies this<p>People are buying shares at $x because they believe they will be able to sell them for more later. I don’t think there’s a whole to more to it than that.</div><br/></div></div><div id="42562779" class="c"><input type="checkbox" id="c-42562779" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561042">parent</a><span>|</span><a href="#42561111">prev</a><span>|</span><a href="#42561110">next</a><span>|</span><label class="collapse" for="c-42562779">[-]</label><label class="expand" for="c-42562779">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI is becoming synonymous with consumer AI. It has potential of disrupting Google’s cash cow, which explains at least a chunk of the valuation.<p>OpenAI predicts more revenue from ChatGPT than api access through 2029.<p>It’s the old Netflix &#x2F; HBO trope of which can become the other first: hbo figure out streaming or Netflix figure out original programming.<p>I bet Google will figure this out and thus OpenAI won’t disrupt as much as people think it will.</div><br/></div></div><div id="42561110" class="c"><input type="checkbox" id="c-42561110" checked=""/><div class="controls bullet"><span class="by">throwpoaster</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561042">parent</a><span>|</span><a href="#42562779">prev</a><span>|</span><a href="#42561088">next</a><span>|</span><label class="collapse" for="c-42561110">[-]</label><label class="expand" for="c-42561110">[7 more]</label></div><br/><div class="children"><div class="content">157 billion implies about a 1% chance at dominating a 1.5 trillion market. Seems reasonable.</div><br/><div id="42561132" class="c"><input type="checkbox" id="c-42561132" checked=""/><div class="controls bullet"><span class="by">asqueella</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561110">parent</a><span>|</span><a href="#42561413">next</a><span>|</span><label class="collapse" for="c-42561132">[-]</label><label class="expand" for="c-42561132">[2 more]</label></div><br/><div class="children"><div class="content">10%, no?</div><br/><div id="42563888" class="c"><input type="checkbox" id="c-42563888" checked=""/><div class="controls bullet"><span class="by">throwpoaster</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561132">parent</a><span>|</span><a href="#42561413">next</a><span>|</span><label class="collapse" for="c-42563888">[-]</label><label class="expand" for="c-42563888">[1 more]</label></div><br/><div class="children"><div class="content">No, there’s a risk term I’m skipping over.</div><br/></div></div></div></div><div id="42561413" class="c"><input type="checkbox" id="c-42561413" checked=""/><div class="controls bullet"><span class="by">airstrike</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561110">parent</a><span>|</span><a href="#42561132">prev</a><span>|</span><a href="#42561088">next</a><span>|</span><label class="collapse" for="c-42561413">[-]</label><label class="expand" for="c-42561413">[4 more]</label></div><br/><div class="children"><div class="content">that&#x27;s 10% and who&#x27;s to say that market is worth 1.5 trillion to begin with</div><br/><div id="42563890" class="c"><input type="checkbox" id="c-42563890" checked=""/><div class="controls bullet"><span class="by">throwpoaster</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561413">parent</a><span>|</span><a href="#42562280">next</a><span>|</span><label class="collapse" for="c-42563890">[-]</label><label class="expand" for="c-42563890">[1 more]</label></div><br/><div class="children"><div class="content">There’s a risk term I’m not including and the comparable is the size of the American economy ($27 trillion).<p>So take the entire economy and ask the question: what does AI not impact? Net that out and assume there’s pricing efficiencies, then build in a risk buffer.<p>1.5t to 15t seems right.</div><br/></div></div><div id="42562280" class="c"><input type="checkbox" id="c-42562280" checked=""/><div class="controls bullet"><span class="by">cloverich</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561413">parent</a><span>|</span><a href="#42563890">prev</a><span>|</span><a href="#42561088">next</a><span>|</span><label class="collapse" for="c-42562280">[-]</label><label class="expand" for="c-42562280">[2 more]</label></div><br/><div class="children"><div class="content">Market cap of apple, google, facebook.</div><br/><div id="42562603" class="c"><input type="checkbox" id="c-42562603" checked=""/><div class="controls bullet"><span class="by">tantalor</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42562280">parent</a><span>|</span><a href="#42561088">next</a><span>|</span><label class="collapse" for="c-42562603">[-]</label><label class="expand" for="c-42562603">[1 more]</label></div><br/><div class="children"><div class="content">Market cap and market size are totally different measures</div><br/></div></div></div></div></div></div></div></div><div id="42561088" class="c"><input type="checkbox" id="c-42561088" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561042">parent</a><span>|</span><a href="#42561110">prev</a><span>|</span><a href="#42561785">next</a><span>|</span><label class="collapse" for="c-42561088">[-]</label><label class="expand" for="c-42561088">[4 more]</label></div><br/><div class="children"><div class="content">Us skeptics believe that valuation prices in some form of regulatory capture or other non-market factor.<p>The non-skeptical interpretation is that it&#x27;s a threshold function, a flat-out race with an unambiguous finish line. If someone actually hit self-improving AGI first there&#x27;s an argument that no one would ever catch up.</div><br/><div id="42561376" class="c"><input type="checkbox" id="c-42561376" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561088">parent</a><span>|</span><a href="#42561785">next</a><span>|</span><label class="collapse" for="c-42561376">[-]</label><label class="expand" for="c-42561376">[3 more]</label></div><br/><div class="children"><div class="content">There are some really good books about wars between cultures that have AGI and it always comes down to math - whoever can get their hands on more compute faster wins.</div><br/><div id="42561580" class="c"><input type="checkbox" id="c-42561580" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561376">parent</a><span>|</span><a href="#42561785">next</a><span>|</span><label class="collapse" for="c-42561580">[-]</label><label class="expand" for="c-42561580">[2 more]</label></div><br/><div class="children"><div class="content">This is also a strong argument for immigration, particularly high-skill immigration. In the absence of synthetic AGI whoever imports the most human AGI wins.</div><br/><div id="42561684" class="c"><input type="checkbox" id="c-42561684" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561580">parent</a><span>|</span><a href="#42561785">next</a><span>|</span><label class="collapse" for="c-42561684">[-]</label><label class="expand" for="c-42561684">[1 more]</label></div><br/><div class="children"><div class="content">Which suggests that total AGI compute doesn&#x27;t matter that much, as India isn&#x27;t the world leader the amount of human compute they posses would suggest then.<p>What matters is how you use the AGI, not how much you have, with wrong or bad or limiting regulations it will not lead anywhere.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42561785" class="c"><input type="checkbox" id="c-42561785" checked=""/><div class="controls bullet"><span class="by">hyperpape</span><span>|</span><a href="#42560993">parent</a><span>|</span><a href="#42561042">prev</a><span>|</span><a href="#42561027">next</a><span>|</span><label class="collapse" for="c-42561785">[-]</label><label class="expand" for="c-42561785">[1 more]</label></div><br/><div class="children"><div class="content">This seems like a non-sequitur unless you’re assuming something about the amount that people use models.<p>Most web servers can run some number of QPS on a developer laptop, but AWS is a big business, because there are a heck of a lot of QPS across all the servers.</div><br/></div></div><div id="42561027" class="c"><input type="checkbox" id="c-42561027" checked=""/><div class="controls bullet"><span class="by">slimsag</span><span>|</span><a href="#42560993">parent</a><span>|</span><a href="#42561785">prev</a><span>|</span><a href="#42561077">next</a><span>|</span><label class="collapse" for="c-42561027">[-]</label><label class="expand" for="c-42561027">[1 more]</label></div><br/><div class="children"><div class="content">Unless the best models themselves are costly&#x2F;hard to produce, and there is not a company providing them to people free of charge AND for commercial use.</div><br/></div></div><div id="42561077" class="c"><input type="checkbox" id="c-42561077" checked=""/><div class="controls bullet"><span class="by">epicureanideal</span><span>|</span><a href="#42560993">parent</a><span>|</span><a href="#42561027">prev</a><span>|</span><a href="#42562131">next</a><span>|</span><label class="collapse" for="c-42561077">[-]</label><label class="expand" for="c-42561077">[1 more]</label></div><br/><div class="children"><div class="content">And of course, as processors improve this becomes more and more the case.</div><br/></div></div><div id="42562131" class="c"><input type="checkbox" id="c-42562131" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#42560993">parent</a><span>|</span><a href="#42561077">prev</a><span>|</span><a href="#42561095">next</a><span>|</span><label class="collapse" for="c-42562131">[-]</label><label class="expand" for="c-42562131">[1 more]</label></div><br/><div class="children"><div class="content">The best models are always out of reach on desktops.  You can have ok models but AGI will come in a datacenter first</div><br/></div></div><div id="42561095" class="c"><input type="checkbox" id="c-42561095" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42560993">parent</a><span>|</span><a href="#42562131">prev</a><span>|</span><a href="#42562106">next</a><span>|</span><label class="collapse" for="c-42561095">[-]</label><label class="expand" for="c-42561095">[6 more]</label></div><br/><div class="children"><div class="content">Been in the Mac ecosystem since 2008, love it, but there is, and always has been, a tendency to talk about inevitabilities from scaling bespoke, extremely expensive configurations, and with LLMs, there&#x27;s heavy eliding of what the user experience is, beyond noting response generation speed in tokens&#x2F;s.<p>They run on a laptop, yes - you might squeeze up to 10 token&#x2F;sec out of a kinda sorta GPT-4 if you paid $5K plus for an Apple laptop in the last 18 months.<p>And that&#x27;s after you spent <i>2 minutes</i> watching 1000 token* prompt prefill at 10 tokens&#x2F;sec.<p>Usually it&#x27;d be obvious this&#x27;d trickle down, things always do, right?<p>But...Apple infamously has been stuck on 8GB of RAM in even $1500 base models for years. I have 0 idea why, but my intuition is RAM was ~doubling capacity at same cost every 3 years till early 2010s, then it mostly stalled out post 2015.<p>And regardless of any of the above, this absolutely <i>melts</i> your battery. Like, your 16 hr battery life becomes 40 minutes, no exaggeration.<p>I don&#x27;t know why prefill (loading in your prompt) is so slow for local LLMs, but it is. I assume if you have a bunch of servers there&#x27;s some caching you can do that works across all prompts.<p>I expect the local LLM community to be roughly the same size it is today 5 years from now.<p>* ~3 pages &#x2F; ~750 words; what I expect is a conservative average for prompt size when coding</div><br/><div id="42561161" class="c"><input type="checkbox" id="c-42561161" checked=""/><div class="controls bullet"><span class="by">lowercased</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561095">parent</a><span>|</span><a href="#42562106">next</a><span>|</span><label class="collapse" for="c-42561161">[-]</label><label class="expand" for="c-42561161">[5 more]</label></div><br/><div class="children"><div class="content">I have a 2023 mbp, and I get about 100-150 tok&#x2F;sec locally with lmstudio.</div><br/><div id="42561441" class="c"><input type="checkbox" id="c-42561441" checked=""/><div class="controls bullet"><span class="by">datadrivenangel</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561161">parent</a><span>|</span><a href="#42562106">next</a><span>|</span><label class="collapse" for="c-42561441">[-]</label><label class="expand" for="c-42561441">[4 more]</label></div><br/><div class="children"><div class="content">Which models?</div><br/><div id="42561973" class="c"><input type="checkbox" id="c-42561973" checked=""/><div class="controls bullet"><span class="by">lowercased</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561441">parent</a><span>|</span><a href="#42561870">next</a><span>|</span><label class="collapse" for="c-42561973">[-]</label><label class="expand" for="c-42561973">[2 more]</label></div><br/><div class="children"><div class="content">hugging-quants&#x2F;llama-3.2-1b-instruct-q8_0-gguf - 100-150 tok&#x2F;sec<p>second-state&#x2F;llama-2-7b-chat-gguf net me around ~35 tok&#x2F;sec<p>lmstudio-community&#x2F;granite-3.1.-8b-instruct-GGUF - ~50 tok&#x2F;sec<p>MBP M3 Max, 64g. - $3k</div><br/><div id="42562084" class="c"><input type="checkbox" id="c-42562084" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561973">parent</a><span>|</span><a href="#42561870">next</a><span>|</span><label class="collapse" for="c-42562084">[-]</label><label class="expand" for="c-42562084">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure if you&#x27;re pointing out any &#x2F; all of these:<p>#1. It is possible to get an arbitrarily fast tokens&#x2F;second number, given you can pick model size.<p>#2. Llama 1B is roughly GPT-4.<p>#3. Given Llama 1B runs at 100 tokens&#x2F;sec, and given performance at a given model size has continued to improve over the past 2 years, we can assume there will eventually be a GPT-4 quality model at 1B.<p>On my end:<p>#1. Agreed.<p>#2. Vehemently disagree.<p>#3. TL;DR: I don&#x27;t expect that, at least, the trend line isn&#x27;t steep enough for me to expect that in the next decade.</div><br/></div></div></div></div><div id="42561870" class="c"><input type="checkbox" id="c-42561870" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42560993">root</a><span>|</span><a href="#42561441">parent</a><span>|</span><a href="#42561973">prev</a><span>|</span><a href="#42562106">next</a><span>|</span><label class="collapse" for="c-42561870">[-]</label><label class="expand" for="c-42561870">[1 more]</label></div><br/><div class="children"><div class="content">For context, I got M2 Max MBP, 64 GB shared RAM, bought it March 2023 for $5-6K.<p><pre><code>  Llama 3.2 1.0B - 650 t&#x2F;s
  Phi 3.5   3.8B - 60 t&#x2F;s.
  Llama 3.1 8.0B - 37 t&#x2F;s.
  Mixtral  14.0B - 24 t&#x2F;s.
</code></pre>
Full GPU acceleration, using llama.cpp, just like LM Studio.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42562106" class="c"><input type="checkbox" id="c-42562106" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#42560993">prev</a><span>|</span><a href="#42562715">next</a><span>|</span><label class="collapse" for="c-42562106">[-]</label><label class="expand" for="c-42562106">[2 more]</label></div><br/><div class="children"><div class="content">Great summary of highlights. Don&#x27;t agree with all, but I think it&#x27;s a very sound attempt at a year in review summary<p>&gt;LLM prices crashed<p>This one has me a little spooked. The white knight on this front (DS) has both announced increases and has had staff poached. There is still Gemini free tier which is ofc basically impossible to beat (solid &amp; functionally unlimited&#x2F;free) but it&#x27;s google so reluctant to trust.<p>Seriously worried about seeing a regression on pricing in first half of 2025. Especially with the OAI $200 price anchoring.<p>&gt;“Agents” still haven’t really happened yet<p>Think that&#x27;s largely because it&#x27;s a poorly defined concept and true &quot;agent&quot; implies some sort of pseudo-agi autonomy. This is a definition&#x2F;expectation issue rather than technical in my mind<p>&gt;LLMs somehow got even harder to use<p>I don&#x27;t think that&#x27;s 100%. An explosion of options is not equal to harder to use. And the guidance for noobs is still pretty much same as always (llama.cp or one of the common frontends like text-generation-webui). It&#x27;s become harder to tell what is good, but not to get going.<p>----<p>One key theme I think is missing is just how hard it has become to tell what is &quot;good&quot; for the average user. There is so much benchmark shenanigans going on that it&#x27;s just impossible to tell. I&#x27;m literally at the &quot;I&#x27;m just going to build my own testing framework&quot; stage. Not because I can do better technically (I can&#x27;t)...but because I can gear it towards things I care about and I can be confident my DIY sample hasn&#x27;t been gamed.</div><br/><div id="42562298" class="c"><input type="checkbox" id="c-42562298" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42562106">parent</a><span>|</span><a href="#42562715">next</a><span>|</span><label class="collapse" for="c-42562298">[-]</label><label class="expand" for="c-42562298">[1 more]</label></div><br/><div class="children"><div class="content">The biggest reason I&#x27;m not worried about prices going back up again is Llama. The Llama 3 models are <i>really good</i>, and because they are open weight there are a growing number of API providers competing to provide access to them.<p>These companies are incentivized to figure out fast and efficient hosting for the models. They don&#x27;t need to train any models themselves, their value is added entirely in continuing to drive the price of inference down.<p>Groq and Cerberus are particularly interesting here because WOW they serve Llama fast.</div><br/></div></div></div></div><div id="42562715" class="c"><input type="checkbox" id="c-42562715" checked=""/><div class="controls bullet"><span class="by">andrethegiant</span><span>|</span><a href="#42562106">prev</a><span>|</span><a href="#42561303">next</a><span>|</span><label class="collapse" for="c-42562715">[-]</label><label class="expand" for="c-42562715">[7 more]</label></div><br/><div class="children"><div class="content">&gt; I find the term “agents” extremely frustrating. It lacks a single, clear and widely understood meaning... but the people who use the term never seem to acknowledge that.<p>This 100%. “Agentic” especially as a buzzword can piss off</div><br/><div id="42562935" class="c"><input type="checkbox" id="c-42562935" checked=""/><div class="controls bullet"><span class="by">phillipcarter</span><span>|</span><a href="#42562715">parent</a><span>|</span><a href="#42562901">next</a><span>|</span><label class="collapse" for="c-42562935">[-]</label><label class="expand" for="c-42562935">[2 more]</label></div><br/><div class="children"><div class="content">I find that Anthropic has a good, clarifying set of definitions with examples: <a href="https:&#x2F;&#x2F;www.anthropic.com&#x2F;research&#x2F;building-effective-agents" rel="nofollow">https:&#x2F;&#x2F;www.anthropic.com&#x2F;research&#x2F;building-effective-agents</a></div><br/><div id="42562953" class="c"><input type="checkbox" id="c-42562953" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42562715">root</a><span>|</span><a href="#42562935">parent</a><span>|</span><a href="#42562901">next</a><span>|</span><label class="collapse" for="c-42562953">[-]</label><label class="expand" for="c-42562953">[1 more]</label></div><br/><div class="children"><div class="content">Genuinely the best piece of writing I&#x27;ve seen about agents anywhere.</div><br/></div></div></div></div><div id="42562901" class="c"><input type="checkbox" id="c-42562901" checked=""/><div class="controls bullet"><span class="by">cbeach</span><span>|</span><a href="#42562715">parent</a><span>|</span><a href="#42562935">prev</a><span>|</span><a href="#42563227">next</a><span>|</span><label class="collapse" for="c-42562901">[-]</label><label class="expand" for="c-42562901">[3 more]</label></div><br/><div class="children"><div class="content">The software &quot;has agency&quot;? That is, I can entrust it to carry out the task I&#x27;ve described, to completion, without telling it how to perform the task?</div><br/><div id="42562963" class="c"><input type="checkbox" id="c-42562963" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42562715">root</a><span>|</span><a href="#42562901">parent</a><span>|</span><a href="#42563227">next</a><span>|</span><label class="collapse" for="c-42562963">[-]</label><label class="expand" for="c-42562963">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s one of the more common definitions people use - especially people who aren&#x27;t directly building agents, since the builders tend to get more hung up on &quot;LLM with access to tools&quot; or similar.<p>My problem is when people use that definition (or any other) without clarifying, because they assume it&#x27;s THE obvious definition.</div><br/><div id="42563595" class="c"><input type="checkbox" id="c-42563595" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#42562715">root</a><span>|</span><a href="#42562963">parent</a><span>|</span><a href="#42563227">next</a><span>|</span><label class="collapse" for="c-42563595">[-]</label><label class="expand" for="c-42563595">[1 more]</label></div><br/><div class="children"><div class="content">Workflows aside, I think &quot;interruptible work&quot; is what matters, really. That is, maintaining state in-between inferences so that it follows some well-defined goal.</div><br/></div></div></div></div></div></div></div></div><div id="42561303" class="c"><input type="checkbox" id="c-42561303" checked=""/><div class="controls bullet"><span class="by">sowbug</span><span>|</span><a href="#42562715">prev</a><span>|</span><a href="#42560952">next</a><span>|</span><label class="collapse" for="c-42561303">[-]</label><label class="expand" for="c-42561303">[10 more]</label></div><br/><div class="children"><div class="content">Simon has mentioned in multiple articles how cool it is to use 64GB DRAM for GPU tasks on his MacBook. I agree it&#x27;s cool, but I don&#x27;t understand why it is remarkable. Is Apple doing something special with DRAM that other hardware manufacturers haven&#x27;t figured out? Assuming data centers are hoovering up nearly all the world&#x27;s RAM manufacturing capacity, how is Apple still managing to ship machines with DRAM that performs close enough for Simon&#x27;s needs to VRAM? Is this just a temporary blip, and PC manufacturers in 2025 will be catching up and shipping mini PCs that have 64GB RAM ceilings with similar memory performance? What gives?</div><br/><div id="42561342" class="c"><input type="checkbox" id="c-42561342" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#42561303">parent</a><span>|</span><a href="#42561325">next</a><span>|</span><label class="collapse" for="c-42561342">[-]</label><label class="expand" for="c-42561342">[3 more]</label></div><br/><div class="children"><div class="content">LLMs run on the GPU, and the unified memory of Apple silicon means that the 64 GB can be used by the GPU.<p>Consumer GPUs top out at 24 GB VRAM.</div><br/><div id="42561830" class="c"><input type="checkbox" id="c-42561830" checked=""/><div class="controls bullet"><span class="by">karolist</span><span>|</span><a href="#42561303">root</a><span>|</span><a href="#42561342">parent</a><span>|</span><a href="#42561325">next</a><span>|</span><label class="collapse" for="c-42561830">[-]</label><label class="expand" for="c-42561830">[2 more]</label></div><br/><div class="children"><div class="content">llama.cpp can run LLMs on CPU. iGPU can also use system memory, the novel thing is not that, it&#x27;s that the LLM inference is mostly memory bandwidth bound and memory bandwidth of a custom built PC with really fast DDR5 RAM is around 100GB&#x2F;s, nVidia consumer GPUs at the top end are around 1TB&#x2F;s, with mid range GPUs at around half that. M1 Max has 400GB&#x2F;s, M1 Ultra is 800GB&#x2F;s, but you can have Apple Silicon Macs with up to 192GB of 800GB&#x2F;s memory usable by GPU, this means much faster inference than just CPU+system memory due to bandwidth and more affordable than building a multi-GPU system to match the memory amount.</div><br/><div id="42562025" class="c"><input type="checkbox" id="c-42562025" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#42561303">root</a><span>|</span><a href="#42561830">parent</a><span>|</span><a href="#42561325">next</a><span>|</span><label class="collapse" for="c-42562025">[-]</label><label class="expand" for="c-42562025">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;d be really nice to have good memory bandwidth usage metrics collected from a wide range of devices while doing inference.<p>For example, how close does it get to the peak, and what&#x27;s the median bandwidth during inference?  And is that bandwidth, rather than some other clever optimization elsewhere, actually providing the Mac&#x27;s performance?<p>Personally, I don&#x27;t develop HPC stuff on a laptop - I am much more interested in what a modern PC with Intel or AMD and nvidia can do, when maxxed out.  But it&#x27;s certainly interesting to see that some of Apple&#x27;s arch decisions have worked out well for local LLMs.</div><br/></div></div></div></div></div></div><div id="42561325" class="c"><input type="checkbox" id="c-42561325" checked=""/><div class="controls bullet"><span class="by">post-it</span><span>|</span><a href="#42561303">parent</a><span>|</span><a href="#42561342">prev</a><span>|</span><a href="#42561333">next</a><span>|</span><label class="collapse" for="c-42561325">[-]</label><label class="expand" for="c-42561325">[2 more]</label></div><br/><div class="children"><div class="content">Apple designs its own chips, so the RAM and CPU are on the same die and can talk at very high speeds. This is not the case for PCs, where RAM is connected externally.</div><br/><div id="42563831" class="c"><input type="checkbox" id="c-42563831" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#42561303">root</a><span>|</span><a href="#42561325">parent</a><span>|</span><a href="#42561333">next</a><span>|</span><label class="collapse" for="c-42563831">[-]</label><label class="expand" for="c-42563831">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s on the same package but the same die?</div><br/></div></div></div></div><div id="42561333" class="c"><input type="checkbox" id="c-42561333" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#42561303">parent</a><span>|</span><a href="#42561325">prev</a><span>|</span><a href="#42560952">next</a><span>|</span><label class="collapse" for="c-42561333">[-]</label><label class="expand" for="c-42561333">[4 more]</label></div><br/><div class="children"><div class="content">Apple uses HBM, basically RAM on the same die as the CPU. It has a lot more memory bandwidth than typically PC dram, but still less than many GPUs. (Although the highest end macs have bandwidth that is in the same ballpark as GPUs)</div><br/><div id="42561844" class="c"><input type="checkbox" id="c-42561844" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#42561303">root</a><span>|</span><a href="#42561333">parent</a><span>|</span><a href="#42561852">next</a><span>|</span><label class="collapse" for="c-42561844">[-]</label><label class="expand" for="c-42561844">[2 more]</label></div><br/><div class="children"><div class="content">Apple does not use HBM, they use LPDDR. The way they use it is similar in principle to HBM (on-package, very wide bus) but it&#x27;s not the same thing.</div><br/><div id="42562413" class="c"><input type="checkbox" id="c-42562413" checked=""/><div class="controls bullet"><span class="by">karmakaze</span><span>|</span><a href="#42561303">root</a><span>|</span><a href="#42561844">parent</a><span>|</span><a href="#42561852">next</a><span>|</span><label class="collapse" for="c-42562413">[-]</label><label class="expand" for="c-42562413">[1 more]</label></div><br/><div class="children"><div class="content">Right so Apple uses high-bandwidth memory, but not HBM.</div><br/></div></div></div></div><div id="42561852" class="c"><input type="checkbox" id="c-42561852" checked=""/><div class="controls bullet"><span class="by">justincormack</span><span>|</span><a href="#42561303">root</a><span>|</span><a href="#42561333">parent</a><span>|</span><a href="#42561844">prev</a><span>|</span><a href="#42560952">next</a><span>|</span><label class="collapse" for="c-42561852">[-]</label><label class="expand" for="c-42561852">[1 more]</label></div><br/><div class="children"><div class="content">Its not HBM, which GPUs tend to use, but it is on package and wider interface than other PCs</div><br/></div></div></div></div></div></div><div id="42560952" class="c"><input type="checkbox" id="c-42560952" checked=""/><div class="controls bullet"><span class="by">throwanem</span><span>|</span><a href="#42561303">prev</a><span>|</span><a href="#42563367">next</a><span>|</span><label class="collapse" for="c-42560952">[-]</label><label class="expand" for="c-42560952">[9 more]</label></div><br/><div class="children"><div class="content">&gt; I’ve heard from sources I trust that both Google Gemini and Amazon Nova charge less than their energy costs for running inference...<p>Then, several headings later:<p>&gt; I have it on good authority that neither Google Gemini nor Amazon Nova (two of the least expensive model providers) are running prompts at a loss.<p>So...which is it?</div><br/><div id="42560987" class="c"><input type="checkbox" id="c-42560987" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42560952">parent</a><span>|</span><a href="#42563367">next</a><span>|</span><label class="collapse" for="c-42560987">[-]</label><label class="expand" for="c-42560987">[8 more]</label></div><br/><div class="children"><div class="content">Oh whoops! That&#x27;s an embarrassing mistake, and I didn&#x27;t realize I had that point twice.<p>They&#x27;re not running at a loss. I&#x27;ll fix that.</div><br/><div id="42561010" class="c"><input type="checkbox" id="c-42561010" checked=""/><div class="controls bullet"><span class="by">cess11</span><span>|</span><a href="#42560952">root</a><span>|</span><a href="#42560987">parent</a><span>|</span><a href="#42563367">next</a><span>|</span><label class="collapse" for="c-42561010">[-]</label><label class="expand" for="c-42561010">[7 more]</label></div><br/><div class="children"><div class="content">If they are subsidised they can make a profit while still not making enough money to cover energy costs.</div><br/><div id="42561048" class="c"><input type="checkbox" id="c-42561048" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42560952">root</a><span>|</span><a href="#42561010">parent</a><span>|</span><a href="#42561036">next</a><span>|</span><label class="collapse" for="c-42561048">[-]</label><label class="expand" for="c-42561048">[3 more]</label></div><br/><div class="children"><div class="content">The tip I got about both Gemini and Nova is that the low prices they are charging still cover their energy costs.</div><br/><div id="42561469" class="c"><input type="checkbox" id="c-42561469" checked=""/><div class="controls bullet"><span class="by">cess11</span><span>|</span><a href="#42560952">root</a><span>|</span><a href="#42561048">parent</a><span>|</span><a href="#42561465">next</a><span>|</span><label class="collapse" for="c-42561469">[-]</label><label class="expand" for="c-42561469">[1 more]</label></div><br/><div class="children"><div class="content">OK!</div><br/></div></div></div></div><div id="42561036" class="c"><input type="checkbox" id="c-42561036" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#42560952">root</a><span>|</span><a href="#42561010">parent</a><span>|</span><a href="#42561048">prev</a><span>|</span><a href="#42563367">next</a><span>|</span><label class="collapse" for="c-42561036">[-]</label><label class="expand" for="c-42561036">[3 more]</label></div><br/><div class="children"><div class="content">Subsidised by whom?</div><br/><div id="42561471" class="c"><input type="checkbox" id="c-42561471" checked=""/><div class="controls bullet"><span class="by">cess11</span><span>|</span><a href="#42560952">root</a><span>|</span><a href="#42561036">parent</a><span>|</span><a href="#42563367">next</a><span>|</span><label class="collapse" for="c-42561471">[-]</label><label class="expand" for="c-42561471">[2 more]</label></div><br/><div class="children"><div class="content">E.g. tax payers.</div><br/><div id="42561659" class="c"><input type="checkbox" id="c-42561659" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#42560952">root</a><span>|</span><a href="#42561471">parent</a><span>|</span><a href="#42563367">next</a><span>|</span><label class="collapse" for="c-42561659">[-]</label><label class="expand" for="c-42561659">[1 more]</label></div><br/><div class="children"><div class="content">Are tax payers subsiding that particular activity of Google or Amazon? If they do, “they make enough money” to cover costs. If they don’t, how does it become profitable if it doesn’t even cover the cost of one of the inputs?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42563367" class="c"><input type="checkbox" id="c-42563367" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#42560952">prev</a><span>|</span><a href="#42561072">next</a><span>|</span><label class="collapse" for="c-42563367">[-]</label><label class="expand" for="c-42563367">[1 more]</label></div><br/><div class="children"><div class="content">Simon does great work serving as a LLM historian. Have a happy 2025!</div><br/></div></div><div id="42561072" class="c"><input type="checkbox" id="c-42561072" checked=""/><div class="controls bullet"><span class="by">dtquad</span><span>|</span><a href="#42563367">prev</a><span>|</span><a href="#42562957">next</a><span>|</span><label class="collapse" for="c-42561072">[-]</label><label class="expand" for="c-42561072">[3 more]</label></div><br/><div class="children"><div class="content">What is the current status on pushing &quot;reasoning&quot; down to latent&#x2F;neural space? Seems like a vaste of tokens to let a model converse with itself especially when this internal monologue often has very little to do with the final output so it&#x27;s not useful as a log of how the final output was derived.</div><br/><div id="42561178" class="c"><input type="checkbox" id="c-42561178" checked=""/><div class="controls bullet"><span class="by">dmd</span><span>|</span><a href="#42561072">parent</a><span>|</span><a href="#42561099">next</a><span>|</span><label class="collapse" for="c-42561178">[-]</label><label class="expand" for="c-42561178">[1 more]</label></div><br/><div class="children"><div class="content">See <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42555320">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42555320</a></div><br/></div></div></div></div><div id="42562957" class="c"><input type="checkbox" id="c-42562957" checked=""/><div class="controls bullet"><span class="by">JCM9</span><span>|</span><a href="#42561072">prev</a><span>|</span><a href="#42561922">next</a><span>|</span><label class="collapse" for="c-42562957">[-]</label><label class="expand" for="c-42562957">[3 more]</label></div><br/><div class="children"><div class="content">Nice overview. The challenge ahead for “AI” companies is that it appears there’s really no technical moat here. Someone comes out with something amazing and new and within months (if not weeks or days) it’s quickly copied. That environment where everything quickly becomes a commodity is a recipe for many&#x2F;most companies in this space to quickly get washed out as it becomes economically unviable to play in such an environment.<p>The money is still flowing, for now, to subsidize that fiasco but as soon as that starts to slow, even just a bit, things are gonna get bumpy real quick. Super excited about this tech but there are dark storm clouds building on the horizon and absent a major “moat” breakthrough it’s gonna get rough soon.</div><br/><div id="42563478" class="c"><input type="checkbox" id="c-42563478" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#42562957">parent</a><span>|</span><a href="#42561922">next</a><span>|</span><label class="collapse" for="c-42563478">[-]</label><label class="expand" for="c-42563478">[2 more]</label></div><br/><div class="children"><div class="content">That may be a challenge for AI companies but that doesn&#x27;t sound like a problem to me. Commodities are great for consumers.</div><br/><div id="42563631" class="c"><input type="checkbox" id="c-42563631" checked=""/><div class="controls bullet"><span class="by">JCM9</span><span>|</span><a href="#42562957">root</a><span>|</span><a href="#42563478">parent</a><span>|</span><a href="#42561922">next</a><span>|</span><label class="collapse" for="c-42563631">[-]</label><label class="expand" for="c-42563631">[1 more]</label></div><br/><div class="children"><div class="content">Not necessarily. The playbook of what tends to happen is first a bunch of players go bust in the race to the bottom, then the survivors are free to raise prices a bit when others realize there’s not much point in entering a race to the bottom. Those left then let quality slip as competition cools.<p>That’s exactly what happened with rideshare companies. It was an amazing new thing but subsidized in an unsustainable way, then a bunch of companies exited the space when it was an commoditized race to the bottom and those left let quality slip. Now when you order an Uber a car shows up that smells bad and has wheels about to fall off. The consumer experience was a lot better when Uber was a VC subsidized bonanza</div><br/></div></div></div></div></div></div><div id="42561922" class="c"><input type="checkbox" id="c-42561922" checked=""/><div class="controls bullet"><span class="by">dash2</span><span>|</span><a href="#42562957">prev</a><span>|</span><a href="#42562179">next</a><span>|</span><label class="collapse" for="c-42561922">[-]</label><label class="expand" for="c-42561922">[6 more]</label></div><br/><div class="children"><div class="content">Look, when are these models going to not just talk to me, but do stuff for me? If they&#x27;re so clever, why can&#x27;t I tell one to buy chocolates and send them to my wife? Meanwhile, they can allegedly solve frontier maths problems. What&#x27;s the holdup to models that go online and perform simple tasks?</div><br/><div id="42562512" class="c"><input type="checkbox" id="c-42562512" checked=""/><div class="controls bullet"><span class="by">munchler</span><span>|</span><a href="#42561922">parent</a><span>|</span><a href="#42562184">next</a><span>|</span><label class="collapse" for="c-42562512">[-]</label><label class="expand" for="c-42562512">[1 more]</label></div><br/><div class="children"><div class="content">LLM&#x27;s are inherently untrustworthy. They&#x27;re very good at some tasks, but they still need to be checked and&#x2F;or constrained carefully, which is probably not the best technology on which to base real-world autonomous agents.</div><br/></div></div><div id="42562184" class="c"><input type="checkbox" id="c-42562184" checked=""/><div class="controls bullet"><span class="by">gs17</span><span>|</span><a href="#42561922">parent</a><span>|</span><a href="#42562512">prev</a><span>|</span><a href="#42561955">next</a><span>|</span><label class="collapse" for="c-42562184">[-]</label><label class="expand" for="c-42562184">[1 more]</label></div><br/><div class="children"><div class="content">&gt; why can&#x27;t I tell one to buy chocolates and send them to my wife?<p>I&#x27;m pretty sure that&#x27;s been possible for a while. There was an example where Claude&#x27;s computer use feature ordered pizza for the dev team through DoorDash: <a href="https:&#x2F;&#x2F;x.com&#x2F;alexalbert__&#x2F;status&#x2F;1848777260503077146?lang=en" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;alexalbert__&#x2F;status&#x2F;1848777260503077146?lang=e...</a><p>I don&#x27;t think the released version of the feature can do it, but it should be possible with today&#x27;s tech.</div><br/></div></div><div id="42563971" class="c"><input type="checkbox" id="c-42563971" checked=""/><div class="controls bullet"><span class="by">ripped_britches</span><span>|</span><a href="#42561922">parent</a><span>|</span><a href="#42561955">prev</a><span>|</span><a href="#42561940">next</a><span>|</span><label class="collapse" for="c-42563971">[-]</label><label class="expand" for="c-42563971">[1 more]</label></div><br/><div class="children"><div class="content">Same reason that a powerful graphing calculator can’t teach a math class. “Unhobbling” needs to occur. This means a lot of things but includes modalities, reliability, persistence, alignment, etc.</div><br/></div></div><div id="42561940" class="c"><input type="checkbox" id="c-42561940" checked=""/><div class="controls bullet"><span class="by">icelancer</span><span>|</span><a href="#42561922">parent</a><span>|</span><a href="#42563971">prev</a><span>|</span><a href="#42562179">next</a><span>|</span><label class="collapse" for="c-42561940">[-]</label><label class="expand" for="c-42561940">[1 more]</label></div><br/><div class="children"><div class="content">The last mile problem remains undefeated.</div><br/></div></div></div></div><div id="42562179" class="c"><input type="checkbox" id="c-42562179" checked=""/><div class="controls bullet"><span class="by">voidhorse</span><span>|</span><a href="#42561922">prev</a><span>|</span><a href="#42563977">next</a><span>|</span><label class="collapse" for="c-42562179">[-]</label><label class="expand" for="c-42562179">[1 more]</label></div><br/><div class="children"><div class="content">Great write up! Unfortunately, I think this article accurately reflects how we&#x27;ve made little progress on the most important aspects of LLM hype and use: the social ones.<p>A small number of people with lots of power are essentially deciding to go all in on this technology presumably because significant gains will mean the long term reduction of human labor needs, and thus human labor power. As the article mentions, this also comes at huge expenditure and environmental impact, which is already a very important domain in crisis that we&#x27;ve neglected. The whole thing especially becomes laughable when you consider that many people are still using these tools to perform tasks that could be preformed with a margin of more effort using existing deterministic tools. Instead we are now opting for a computationally more expensive solution that has a higher margin of error.<p>I get that making technical progress in this area is interesting, but I really think the lower level workers and researchers exploring the space need to be more emphatic about thinking about socioeconomic impact. Some will argue that this is analogous to any other technological change and markets will adjust to account for new tool use, but I am not so sure about this one. If the technology is really as groundbreaking as everyone wants us to believe then logically we might be facing a situation that isn&#x27;t as easy to adapt to, and I guarantee those with power will not &quot;give a little back&quot; to the disenfranchised masses out of the goodness of their hearts.<p>This doesn&#x27;t even raise all the problems these tools create when it comes to establishing coherent viewpoints and truth in ostensibly democratic societies, which is another massive can of worms.</div><br/></div></div><div id="42563977" class="c"><input type="checkbox" id="c-42563977" checked=""/><div class="controls bullet"><span class="by">whatshisface</span><span>|</span><a href="#42562179">prev</a><span>|</span><a href="#42563813">next</a><span>|</span><label class="collapse" for="c-42563977">[-]</label><label class="expand" for="c-42563977">[2 more]</label></div><br/><div class="children"><div class="content">Can someone please just tell me what model and workflow is so productive? I&#x27;ve seen so many allusions to the concept of skills for LLM use but no explanations of what they are.</div><br/><div id="42564137" class="c"><input type="checkbox" id="c-42564137" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42563977">parent</a><span>|</span><a href="#42563813">next</a><span>|</span><label class="collapse" for="c-42564137">[-]</label><label class="expand" for="c-42564137">[1 more]</label></div><br/><div class="children"><div class="content">The best LLM for code right now, in my opinion, is still Claude 3.5 Sonnet.<p>The big challenge is figuring out how to use it. I usually like working at the function level: I figure out the exact function signature I want in Python or JavaScript and then get Claude to implement it for me.<p>Claude Artifacts are neat too: Claude can build a full HTML+JavaScript UI, and then iterate on it. I use this for interactive UI prototypes and building small tools.<p>I&#x27;ve published a whole lot of notes on this stuff here: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;ai-assisted-programming&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;ai-assisted-programming&#x2F;</a></div><br/></div></div></div></div><div id="42563813" class="c"><input type="checkbox" id="c-42563813" checked=""/><div class="controls bullet"><span class="by">n144q</span><span>|</span><a href="#42563977">prev</a><span>|</span><a href="#42562432">next</a><span>|</span><label class="collapse" for="c-42563813">[-]</label><label class="expand" for="c-42563813">[1 more]</label></div><br/><div class="children"><div class="content">About &quot;knowledge is incredibly unevenly distributed&quot;, an interesting fact is that women is much less likely to use LLMs, if they hear about them&#x2F;follow updates in the first place:<p><a href="https:&#x2F;&#x2F;www.economist.com&#x2F;finance-and-economics&#x2F;2024&#x2F;08&#x2F;21&#x2F;why-dont-women-use-artificial-intelligence" rel="nofollow">https:&#x2F;&#x2F;www.economist.com&#x2F;finance-and-economics&#x2F;2024&#x2F;08&#x2F;21&#x2F;w...</a></div><br/></div></div><div id="42562432" class="c"><input type="checkbox" id="c-42562432" checked=""/><div class="controls bullet"><span class="by">nektro</span><span>|</span><a href="#42563813">prev</a><span>|</span><a href="#42561445">next</a><span>|</span><label class="collapse" for="c-42562432">[-]</label><label class="expand" for="c-42562432">[1 more]</label></div><br/><div class="children"><div class="content">i learned this industry has lower morals and standards for excellence than i ever previously expected</div><br/></div></div><div id="42561445" class="c"><input type="checkbox" id="c-42561445" checked=""/><div class="controls bullet"><span class="by">submeta</span><span>|</span><a href="#42562432">prev</a><span>|</span><a href="#42560990">next</a><span>|</span><label class="collapse" for="c-42561445">[-]</label><label class="expand" for="c-42561445">[1 more]</label></div><br/><div class="children"><div class="content">Thank you Simon for the excellent work you do! I learned a lot from you and enjoy reading everything you write. Keep up. And happy new year.</div><br/></div></div><div id="42560990" class="c"><input type="checkbox" id="c-42560990" checked=""/><div class="controls bullet"><span class="by">pkoird</span><span>|</span><a href="#42561445">prev</a><span>|</span><a href="#42562066">next</a><span>|</span><label class="collapse" for="c-42560990">[-]</label><label class="expand" for="c-42560990">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to read a semi-technical book on everything that we&#x27;ve learned about what works and what does not on LLMs.</div><br/><div id="42561189" class="c"><input type="checkbox" id="c-42561189" checked=""/><div class="controls bullet"><span class="by">nkingsy</span><span>|</span><a href="#42560990">parent</a><span>|</span><a href="#42562066">next</a><span>|</span><label class="collapse" for="c-42561189">[-]</label><label class="expand" for="c-42561189">[3 more]</label></div><br/><div class="children"><div class="content">It would be out of date in months.<p>Things that didn’t work 6 months ago do now. Things that don’t work now, who knows…</div><br/><div id="42561360" class="c"><input type="checkbox" id="c-42561360" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#42560990">root</a><span>|</span><a href="#42561189">parent</a><span>|</span><a href="#42561434">next</a><span>|</span><label class="collapse" for="c-42561360">[-]</label><label class="expand" for="c-42561360">[1 more]</label></div><br/><div class="children"><div class="content">There are still some tropes from the GPT-3 days that are fundamental to the construction of LLMs that affect how they can be used and will not change unless they no longer are trained to optimize for next-token-prediction (e.g. hallucinations and the need for prompt engineering)</div><br/></div></div><div id="42561434" class="c"><input type="checkbox" id="c-42561434" checked=""/><div class="controls bullet"><span class="by">DoctorOetker</span><span>|</span><a href="#42560990">root</a><span>|</span><a href="#42561189">parent</a><span>|</span><a href="#42561360">prev</a><span>|</span><a href="#42562066">next</a><span>|</span><label class="collapse" for="c-42561434">[-]</label><label class="expand" for="c-42561434">[1 more]</label></div><br/><div class="children"><div class="content">Do you mean performance that was missing in the past is now routinely achieved?<p>Or do you actually mean that the same routines and data that didn&#x27;t work before suddenly work?</div><br/></div></div></div></div></div></div><div id="42562066" class="c"><input type="checkbox" id="c-42562066" checked=""/><div class="controls bullet"><span class="by">legendofbrando</span><span>|</span><a href="#42560990">prev</a><span>|</span><a href="#42561340">next</a><span>|</span><label class="collapse" for="c-42562066">[-]</label><label class="expand" for="c-42562066">[1 more]</label></div><br/><div class="children"><div class="content">@simonw you’ve been awesome all year; loved this recap and look forward to more next year</div><br/></div></div><div id="42561340" class="c"><input type="checkbox" id="c-42561340" checked=""/><div class="controls bullet"><span class="by">viccis</span><span>|</span><a href="#42562066">prev</a><span>|</span><a href="#42562185">next</a><span>|</span><label class="collapse" for="c-42561340">[-]</label><label class="expand" for="c-42561340">[4 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t realize &quot;agent&quot; designs were that ambiguously defined. Every AI engineer I&#x27;ve talked to uses it to mean a design that combines several separate LLM prompts (or even models) to solve problems in multiple stages.</div><br/><div id="42561541" class="c"><input type="checkbox" id="c-42561541" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561340">parent</a><span>|</span><a href="#42561727">next</a><span>|</span><label class="collapse" for="c-42561541">[-]</label><label class="expand" for="c-42561541">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll add that one to the list. Surprisingly it doesn&#x27;t closely match most of the 211 definitions I&#x27;ve collected already!<p>The closest in that collection is &quot;A division of responsibilities between LLMs that results in some sort of flow?&quot; - <a href="https:&#x2F;&#x2F;lite.datasette.io&#x2F;?json=https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;bdc7b894eedcfd54f0a2422ea8feaa80#&#x2F;data&#x2F;raw?_filter_column=tweet&amp;_filter_op=contains&amp;_filter_value=Division&amp;_sort=rowid" rel="nofollow">https:&#x2F;&#x2F;lite.datasette.io&#x2F;?json=https:&#x2F;&#x2F;gist.github.com&#x2F;simo...</a></div><br/></div></div><div id="42561727" class="c"><input type="checkbox" id="c-42561727" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42561340">parent</a><span>|</span><a href="#42561541">prev</a><span>|</span><a href="#42561902">next</a><span>|</span><label class="collapse" for="c-42561727">[-]</label><label class="expand" for="c-42561727">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like ensemble chain of thought.</div><br/></div></div><div id="42561902" class="c"><input type="checkbox" id="c-42561902" checked=""/><div class="controls bullet"><span class="by">datadrivenangel</span><span>|</span><a href="#42561340">parent</a><span>|</span><a href="#42561727">prev</a><span>|</span><a href="#42562185">next</a><span>|</span><label class="collapse" for="c-42561902">[-]</label><label class="expand" for="c-42561902">[1 more]</label></div><br/><div class="children"><div class="content">If the investors ask, those same AI engineers will probably allow the answer to be much more ambiguous.</div><br/></div></div></div></div><div id="42562185" class="c"><input type="checkbox" id="c-42562185" checked=""/><div class="controls bullet"><span class="by">bwhiting2356</span><span>|</span><a href="#42561340">prev</a><span>|</span><a href="#42561838">next</a><span>|</span><label class="collapse" for="c-42562185">[-]</label><label class="expand" for="c-42562185">[2 more]</label></div><br/><div class="children"><div class="content">Some amount of LLM gullibility may be needed. Let&#x27;s say I have a RAG use case for internal documents about how my business works. I need the LLM to accept what I&#x27;m telling it about my business as the truth without questioning it. If I got responses like &quot;this return policy is not correct&quot;, LLMs would fail at my use case.</div><br/><div id="42562844" class="c"><input type="checkbox" id="c-42562844" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42562185">parent</a><span>|</span><a href="#42561838">next</a><span>|</span><label class="collapse" for="c-42562844">[-]</label><label class="expand" for="c-42562844">[1 more]</label></div><br/><div class="children"><div class="content">You don’t need gullibility for that, just the ability to work based on premises (hypotheticals) that you feed it. To the LLM it shouldn’t matter if the hypotheticals are real or not. That’s independent of whether the LLMs judges them as plausible or not. Not being able to semi-accurately judge the plausibility of things would make it gullible.</div><br/></div></div></div></div><div id="42561753" class="c"><input type="checkbox" id="c-42561753" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42561838">prev</a><span>|</span><a href="#42560903">next</a><span>|</span><label class="collapse" for="c-42561753">[-]</label><label class="expand" for="c-42561753">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been surprised that ChatGPT has hung on as long as it has. Maybe 2025 is the year Microsoft pushes harder for their brand of LLM.</div><br/></div></div><div id="42560903" class="c"><input type="checkbox" id="c-42560903" checked=""/><div class="controls bullet"><span class="by">agentultra</span><span>|</span><a href="#42561753">prev</a><span>|</span><a href="#42561640">next</a><span>|</span><label class="collapse" for="c-42560903">[-]</label><label class="expand" for="c-42560903">[17 more]</label></div><br/><div class="children"><div class="content">Don’t forget that 2024 was also a record year for new methane power plant projects. Some 200 new projects in the US alone and I’d wager most of them are funded directly by big tech for AI data centres.<p><a href="https:&#x2F;&#x2F;www.bnnbloomberg.ca&#x2F;investing&#x2F;2024&#x2F;09&#x2F;16&#x2F;ai-boom-is-driving-a-surprise-resurgence-of-us-gas-fired-power&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.bnnbloomberg.ca&#x2F;investing&#x2F;2024&#x2F;09&#x2F;16&#x2F;ai-boom-is-...</a><p>This is definitely extending the runway of O&amp;G at a crisis point in the climate disaster when we’re supposed to be reducing and shutting down these power plants.<p><i>Update</i>: clarified the 200 number is in the US. There are far more world wide.</div><br/><div id="42561019" class="c"><input type="checkbox" id="c-42561019" checked=""/><div class="controls bullet"><span class="by">comte7092</span><span>|</span><a href="#42560903">parent</a><span>|</span><a href="#42561346">next</a><span>|</span><label class="collapse" for="c-42561019">[-]</label><label class="expand" for="c-42561019">[2 more]</label></div><br/><div class="children"><div class="content">Energy generation methods aren’t fungible.<p>Methane is favored in many cases because they can be quickly ramped up and down to handle momentary peaks in demand or spotty supply generated from renewables.<p>Without knowing more details about those projects it is difficult to make the claim that these plants have anything to do with increased demand due to LLMs, though if anything, they’d just add to base load demands and lead to slower decommissioning of old coal plants like we’ve seen with bitcoin mines.</div><br/><div id="42561124" class="c"><input type="checkbox" id="c-42561124" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42561019">parent</a><span>|</span><a href="#42561346">next</a><span>|</span><label class="collapse" for="c-42561124">[-]</label><label class="expand" for="c-42561124">[1 more]</label></div><br/><div class="children"><div class="content">Methane is also worth burning to lessen the GHG impact since we produce so much of it as a byproduct of both resource extraction and waste disposal anyway.</div><br/></div></div></div></div><div id="42561346" class="c"><input type="checkbox" id="c-42561346" checked=""/><div class="controls bullet"><span class="by">uludag</span><span>|</span><a href="#42560903">parent</a><span>|</span><a href="#42561019">prev</a><span>|</span><a href="#42560949">next</a><span>|</span><label class="collapse" for="c-42561346">[-]</label><label class="expand" for="c-42561346">[3 more]</label></div><br/><div class="children"><div class="content">But according to the author, apparently bringing this up isn&#x27;t helpful criticism.<p>I&#x27;m curious what peoples thoughts are of what the future of LLMs would be like if we severely overshoot our carbon goals. How bad would thinks have to get for people to stop caring about this technology?</div><br/><div id="42561549" class="c"><input type="checkbox" id="c-42561549" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42561346">parent</a><span>|</span><a href="#42560949">next</a><span>|</span><label class="collapse" for="c-42561549">[-]</label><label class="expand" for="c-42561549">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s helpful criticism as <i>part</i> of the conversation. What frustrates me is when people go &quot;LLMs are burning the planet!&quot; and leave it at that.</div><br/><div id="42562054" class="c"><input type="checkbox" id="c-42562054" checked=""/><div class="controls bullet"><span class="by">agentultra</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42561549">parent</a><span>|</span><a href="#42560949">next</a><span>|</span><label class="collapse" for="c-42562054">[-]</label><label class="expand" for="c-42562054">[1 more]</label></div><br/><div class="children"><div class="content">It is a rather contrasting opinion that the trade-offs to have AI aren’t worth the value they bring.<p>The growth in this technology isn’t outpacing car pollution and O&amp;G extraction… yet, but the growth rate has been enough in recent years to put it on the radar of industries to watch out for.<p>I hope the compute efficiencies are rapid and more than commensurate with the rate of growth so that we can make progress on our climate targets.<p>However it seems unlikely to me.<p>It’s been a year of progress for the tech… but also a lot of setbacks for the rest of the world. I’m fairly certain we don’t need AGI to tell us how to cope with the climate crisis; we already have the answer for that.<p>Although if the industry does continue to grow and the efficiency gains aren’t enough… will society&#x2F;investors be willing to scale back growth in order to meet climate targets (assuming that AI becomes a large enough segment of global emissions to warrant reductions)?<p>Interesting times for the field.</div><br/></div></div></div></div></div></div><div id="42560949" class="c"><input type="checkbox" id="c-42560949" checked=""/><div class="controls bullet"><span class="by">ToucanLoucan</span><span>|</span><a href="#42560903">parent</a><span>|</span><a href="#42561346">prev</a><span>|</span><a href="#42560940">next</a><span>|</span><label class="collapse" for="c-42560949">[-]</label><label class="expand" for="c-42560949">[7 more]</label></div><br/><div class="children"><div class="content">It would be really cool if big tech could find a new hyperscaler model that didn&#x27;t <i>also</i> require offsetting the goals of green energy projects worldwide. Between LLM and crypto you&#x27;d swear they&#x27;re trying to find the most energy-wasteful tech possible.</div><br/><div id="42561086" class="c"><input type="checkbox" id="c-42561086" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42560949">parent</a><span>|</span><a href="#42561064">next</a><span>|</span><label class="collapse" for="c-42561086">[-]</label><label class="expand" for="c-42561086">[3 more]</label></div><br/><div class="children"><div class="content">Cryptocurrency, at least PoW, the point is indeed to be the most wasteful — a literal Dyson swarm powered Bitcoin would provide <i>exactly the same utility</i> as the BTC network already had in 2010.<p>LLMs (and the image, sound, and movie generating models) are more <i>coincidentally</i> power-hogs — people are at least trying to make them better at fixed compute, and lower compute at fixed quality.</div><br/><div id="42561273" class="c"><input type="checkbox" id="c-42561273" checked=""/><div class="controls bullet"><span class="by">ToucanLoucan</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42561086">parent</a><span>|</span><a href="#42561064">next</a><span>|</span><label class="collapse" for="c-42561273">[-]</label><label class="expand" for="c-42561273">[2 more]</label></div><br/><div class="children"><div class="content">I mean, I appreciate that distinction and don&#x27;t disagree. <i>And,</i> if this is going to continue being a trend, I think we need more stringent restrictions on what sorts of resources are permitted to be consumed in the power plants that are constructed to meet the needs of hyperscaler data centers.<p>Because whether we&#x27;re using tons of compute to provide value or not doesn&#x27;t change that <i>we are using tons of compute</i> and tons of compute requires tons of energy, both for the chips themselves, and the extensive infrastructure that has to built around them to let them work. And not just electricity: refrigerants, many of which are environmentally questionable themselves, are a big part; hell, just water. Clean, usable water.<p>If we truly need these data centers, then fine. Then they should be powered by renewable energy, or if they absolutely cannot be, then the costs their nonrenewable energy sources inflict on the biosphere should be priced into their construction and use, and in turn, priced into the tech that is apparently so critical for them to have.<p>This is like, a basic calculus that every grown person makes dozens of times a day: do I need this? And they don&#x27;t get to distribute the cost of that need, however prescient it may be, on their wider community because they can&#x27;t afford it otherwise. I don&#x27;t see why Microsoft should be able to either. If this is truly the tech of the future as it is constantly propped up to be, cool. Then charge a price for it that reflects what it costs to use.</div><br/><div id="42562850" class="c"><input type="checkbox" id="c-42562850" checked=""/><div class="controls bullet"><span class="by">lucubratory</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42561273">parent</a><span>|</span><a href="#42561064">next</a><span>|</span><label class="collapse" for="c-42562850">[-]</label><label class="expand" for="c-42562850">[1 more]</label></div><br/><div class="children"><div class="content">I think basically everyone should support a carbon tax. It&#x27;s a really obvious solution that is both environmentally friendly and should be acceptable to free market fanatics because it is explicitly and only taxing a negative externality on the public - it&#x27;s hard to imagine a more justified tax.<p>Combined with the increased cost effectiveness of renewables &amp; batteries, &amp; the new build-out of nuclear, it could plausibly speed up the clean energy transition, rather than just disincentivising building out more polluting power plants.<p>There are two main options for what to do with revenue from a carbon tax. The one that makes the most macroeconomic sense is to use those proceeds to fund subsidies for clean energy roll outs &amp; grid adaptation. You are directly taxing the polluting power grid to fund the construction of a non-polluting power grid. As CO2 emitting industry (and thus carbon tax revenue) declines, we have less required spend on clean energy roll out, so the tax would balance nicely. The downside would be that a carbon tax would increase cost of living and this does nothing about that.<p>The other option is a disbursement. Give everyone in society a payment directly from the proceeds of the carbon tax. This would offset the regressive aspects of a carbon tax (because that tax would increase consumer costs), and would also act as a sort of auto-stimulus to stop the economy from turning down due to consumption costs increasing. The downside of this is that the clean energy transition happens slower than the above, and that there may be political instability &amp; perverse incentives as people maybe come to rely on this payment that has to go away over the next few decades.<p>They&#x27;re both good options. I don&#x27;t know which is better and I think that&#x27;s likely something individual countries will probably choose based on their situation. But we do need some sort of way to make those emitting CO2 pay for its negative externalities.</div><br/></div></div></div></div></div></div><div id="42561064" class="c"><input type="checkbox" id="c-42561064" checked=""/><div class="controls bullet"><span class="by">zachrip</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42560949">parent</a><span>|</span><a href="#42561086">prev</a><span>|</span><a href="#42560940">next</a><span>|</span><label class="collapse" for="c-42561064">[-]</label><label class="expand" for="c-42561064">[3 more]</label></div><br/><div class="children"><div class="content">It seems odd to put crypto and LLMs in the same boat in this regard - I might be wrong but are there any crypto projects that actually provide value? I&#x27;m sure there are ones that do folding or something but among the big ones?</div><br/><div id="42561207" class="c"><input type="checkbox" id="c-42561207" checked=""/><div class="controls bullet"><span class="by">rileymat2</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42561064">parent</a><span>|</span><a href="#42563419">next</a><span>|</span><label class="collapse" for="c-42561207">[-]</label><label class="expand" for="c-42561207">[1 more]</label></div><br/><div class="children"><div class="content">Value is a hard term, this link will seem snarky, but:
<a href="https:&#x2F;&#x2F;www.axios.com&#x2F;2024&#x2F;12&#x2F;25&#x2F;russia-bitcoin-evade-sanctions-crypto" rel="nofollow">https:&#x2F;&#x2F;www.axios.com&#x2F;2024&#x2F;12&#x2F;25&#x2F;russia-bitcoin-evade-sancti...</a><p>So in a way, it is providing value to someone, whether we like it or not.<p>Or Drug Cartels.
<a href="https:&#x2F;&#x2F;www.context.news&#x2F;digital-rights&#x2F;how-crypto-helps-latin-americas-drug-cartels-do-business" rel="nofollow">https:&#x2F;&#x2F;www.context.news&#x2F;digital-rights&#x2F;how-crypto-helps-lat...</a><p>But this is the promise of uncontrollable decentralization providing value, for good or bad?</div><br/></div></div><div id="42563419" class="c"><input type="checkbox" id="c-42563419" checked=""/><div class="controls bullet"><span class="by">blibble</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42561064">parent</a><span>|</span><a href="#42561207">prev</a><span>|</span><a href="#42560940">next</a><span>|</span><label class="collapse" for="c-42563419">[-]</label><label class="expand" for="c-42563419">[1 more]</label></div><br/><div class="children"><div class="content">crypto has real uses, most of them illegal<p>meanwhile &quot;AI&quot; is used to produce infinity+1 pictures of shrimp jesus and more spam than we&#x27;ve ever known before<p>and if we&#x27;re really lucky, it will put us all out of work</div><br/></div></div></div></div></div></div><div id="42560940" class="c"><input type="checkbox" id="c-42560940" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#42560903">parent</a><span>|</span><a href="#42560949">prev</a><span>|</span><a href="#42561065">next</a><span>|</span><label class="collapse" for="c-42560940">[-]</label><label class="expand" for="c-42560940">[3 more]</label></div><br/><div class="children"><div class="content">The only thing that will stop this is for battery storage to get cheap and available enough that it can cover for renewables. If we are still building gas turbines it means that hasn’t happened yet.<p>AI is a red herring. If it wasn’t that it would be EV power demand. If it wasn’t that it would be reshoring of manufacturing. If it wasn’t that it would be population growth from immigration. If it wasn’t that it would be replacing old coal power plants reaching EOL.<p>Replacing coal with gas is an improvement by the way. It’s around half the CO2 per kWh, sometimes less if you factor in that gas turbines are often more efficient than aging old coal plants.</div><br/><div id="42561041" class="c"><input type="checkbox" id="c-42561041" checked=""/><div class="controls bullet"><span class="by">agentultra</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42560940">parent</a><span>|</span><a href="#42561622">next</a><span>|</span><label class="collapse" for="c-42561041">[-]</label><label class="expand" for="c-42561041">[1 more]</label></div><br/><div class="children"><div class="content">Methane has a shorter half-life than CO2 but is a far worse green house gas; retaining far more heat.<p>And delivering methane leaks like a sieve into the atmosphere from all parts of the process.<p>Sure it’s probably “better than coal,” but not by much. It’s a bit like comparing what’s worse: getting burned by fire or being drowned in acid.</div><br/></div></div><div id="42561622" class="c"><input type="checkbox" id="c-42561622" checked=""/><div class="controls bullet"><span class="by">Nition</span><span>|</span><a href="#42560903">root</a><span>|</span><a href="#42560940">parent</a><span>|</span><a href="#42561041">prev</a><span>|</span><a href="#42561065">next</a><span>|</span><label class="collapse" for="c-42561622">[-]</label><label class="expand" for="c-42561622">[1 more]</label></div><br/><div class="children"><div class="content">Pumped hydro is an excellent form of storage if you have the terrain for it. A whole order of magnitude cheaper than battery storage at the moment.</div><br/></div></div></div></div></div></div><div id="42561640" class="c"><input type="checkbox" id="c-42561640" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42560903">prev</a><span>|</span><a href="#42562039">next</a><span>|</span><label class="collapse" for="c-42561640">[-]</label><label class="expand" for="c-42561640">[2 more]</label></div><br/><div class="children"><div class="content">Double checking, I don&#x27;t think I saw anything about video generation. Not sure if those fall under the &quot;LLM&quot; umbrella. It came very late in the year, but the Google Veo 2 limited testing are astounding. There are at least a half-dozen other services where you can pay to generate video.</div><br/><div id="42561825" class="c"><input type="checkbox" id="c-42561825" checked=""/><div class="controls bullet"><span class="by">baobabKoodaa</span><span>|</span><a href="#42561640">parent</a><span>|</span><a href="#42562039">next</a><span>|</span><label class="collapse" for="c-42561825">[-]</label><label class="expand" for="c-42561825">[1 more]</label></div><br/><div class="children"><div class="content">Video generation was covered in OP</div><br/></div></div></div></div><div id="42562039" class="c"><input type="checkbox" id="c-42562039" checked=""/><div class="controls bullet"><span class="by">orsenthil</span><span>|</span><a href="#42561640">prev</a><span>|</span><a href="#42561011">next</a><span>|</span><label class="collapse" for="c-42562039">[-]</label><label class="expand" for="c-42562039">[1 more]</label></div><br/><div class="children"><div class="content">One of the best written summary of LLMs for the year 2024.<p>We all have silently started to realize Slops, hopefully we can recognize them more easily and prevent them.<p>Test Driven Development (Integration Tests or functional tests specifically) for Prompt Driven Development seems like the way to go.<p>Thank you, Simon.</div><br/></div></div><div id="42561011" class="c"><input type="checkbox" id="c-42561011" checked=""/><div class="controls bullet"><span class="by">neom</span><span>|</span><a href="#42562039">prev</a><span>|</span><a href="#42562190">next</a><span>|</span><label class="collapse" for="c-42561011">[-]</label><label class="expand" for="c-42561011">[6 more]</label></div><br/><div class="children"><div class="content">&quot;learned out about&quot; - is that an Australian phraseology by chance? Sounds Australian or British of some manner.</div><br/><div id="42561050" class="c"><input type="checkbox" id="c-42561050" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561011">parent</a><span>|</span><a href="#42563778">next</a><span>|</span><label class="collapse" for="c-42561050">[-]</label><label class="expand" for="c-42561050">[2 more]</label></div><br/><div class="children"><div class="content">That was a very dumb typo in my title!</div><br/><div id="42561068" class="c"><input type="checkbox" id="c-42561068" checked=""/><div class="controls bullet"><span class="by">neom</span><span>|</span><a href="#42561011">root</a><span>|</span><a href="#42561050">parent</a><span>|</span><a href="#42563778">next</a><span>|</span><label class="collapse" for="c-42561068">[-]</label><label class="expand" for="c-42561068">[1 more]</label></div><br/><div class="children"><div class="content">I figured as much, although I wondered if you were going for the kinda &quot;he learn out about not pissing people off real sharpish&quot; kinda tone I&#x27;ve heard in Scotland before, but wasn&#x27;t sure. Big fan btw, happy new years Simon! :)</div><br/></div></div></div></div><div id="42563778" class="c"><input type="checkbox" id="c-42563778" checked=""/><div class="controls bullet"><span class="by">slyall</span><span>|</span><a href="#42561011">parent</a><span>|</span><a href="#42561050">prev</a><span>|</span><a href="#42561150">next</a><span>|</span><label class="collapse" for="c-42563778">[-]</label><label class="expand" for="c-42563778">[1 more]</label></div><br/><div class="children"><div class="content">Australians or Brits would tend so day &quot;learnt&quot; rather than &quot;learned&quot;</div><br/></div></div><div id="42561150" class="c"><input type="checkbox" id="c-42561150" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#42561011">parent</a><span>|</span><a href="#42563778">prev</a><span>|</span><a href="#42561031">next</a><span>|</span><label class="collapse" for="c-42561150">[-]</label><label class="expand" for="c-42561150">[1 more]</label></div><br/><div class="children"><div class="content">Good ear -- the use of &#x27;out&#x27; as an abbreviation of anything is a britishism.<p>Nowt, owt, -- nothing, anything</div><br/></div></div><div id="42561031" class="c"><input type="checkbox" id="c-42561031" checked=""/><div class="controls bullet"><span class="by">user982</span><span>|</span><a href="#42561011">parent</a><span>|</span><a href="#42561150">prev</a><span>|</span><a href="#42562190">next</a><span>|</span><label class="collapse" for="c-42561031">[-]</label><label class="expand" for="c-42561031">[1 more]</label></div><br/><div class="children"><div class="content">You can find out, you can learn about, but you can&#x27;t learn out about.</div><br/></div></div></div></div><div id="42562190" class="c"><input type="checkbox" id="c-42562190" checked=""/><div class="controls bullet"><span class="by">calebm</span><span>|</span><a href="#42561011">prev</a><span>|</span><a href="#42562674">next</a><span>|</span><label class="collapse" for="c-42562190">[-]</label><label class="expand" for="c-42562190">[3 more]</label></div><br/><div class="children"><div class="content">I love your breadth-first approach of having an outline at the top.</div><br/><div id="42562241" class="c"><input type="checkbox" id="c-42562241" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42562190">parent</a><span>|</span><a href="#42562674">next</a><span>|</span><label class="collapse" for="c-42562241">[-]</label><label class="expand" for="c-42562241">[2 more]</label></div><br/><div class="children"><div class="content">I wrote custom software for that! <a href="https:&#x2F;&#x2F;tools.simonwillison.net&#x2F;render-markdown" rel="nofollow">https:&#x2F;&#x2F;tools.simonwillison.net&#x2F;render-markdown</a> - If you paste in some Markdown with ## section headings in it the output will start with a &lt;ul&gt; list of links to those headings.</div><br/><div id="42562861" class="c"><input type="checkbox" id="c-42562861" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42562190">root</a><span>|</span><a href="#42562241">parent</a><span>|</span><a href="#42562674">next</a><span>|</span><label class="collapse" for="c-42562861">[-]</label><label class="expand" for="c-42562861">[1 more]</label></div><br/><div class="children"><div class="content">It’s somehow funny to experience the juxtaposition of the technological progress with LLMs and how decades-old basic functions like TOC creation for a blog post still require custom software. ;)</div><br/></div></div></div></div></div></div><div id="42562674" class="c"><input type="checkbox" id="c-42562674" checked=""/><div class="controls bullet"><span class="by">k__</span><span>|</span><a href="#42562190">prev</a><span>|</span><a href="#42561109">next</a><span>|</span><label class="collapse" for="c-42562674">[-]</label><label class="expand" for="c-42562674">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m glad that so many open source and even &quot;small&quot; models like Gemma are better than gpt4.</div><br/></div></div><div id="42561109" class="c"><input type="checkbox" id="c-42561109" checked=""/><div class="controls bullet"><span class="by">k2xl</span><span>|</span><a href="#42562674">prev</a><span>|</span><label class="collapse" for="c-42561109">[-]</label><label class="expand" for="c-42561109">[3 more]</label></div><br/><div class="children"><div class="content">Something not mentioned is AI generated music. Suno&#x27;s development this year is impressive. Unclear what this will mean for music artists over next few years.</div><br/><div id="42561184" class="c"><input type="checkbox" id="c-42561184" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42561109">parent</a><span>|</span><a href="#42561765">next</a><span>|</span><label class="collapse" for="c-42561184">[-]</label><label class="expand" for="c-42561184">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, this year I decided to just focus on LLMs - I didn&#x27;t touch on any of the image or music generation advances either. I haven&#x27;t been following those closely enough to have particularly useful things to say about them.</div><br/></div></div><div id="42561765" class="c"><input type="checkbox" id="c-42561765" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#42561109">parent</a><span>|</span><a href="#42561184">prev</a><span>|</span><label class="collapse" for="c-42561765">[-]</label><label class="expand" for="c-42561765">[1 more]</label></div><br/><div class="children"><div class="content">Very clear; I like buying music produced by people who play instruments.</div><br/></div></div></div></div></div></div></div></div></div></body></html>