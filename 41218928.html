<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1723453264502" as="style"/><link rel="stylesheet" href="styles.css?v=1723453264502"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2408.04093">Tree Attention: Topology-Aware Decoding for Long-Context</a>Â <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>diwank</span> | <span>9 comments</span></div><br/><div><div id="41220320" class="c"><input type="checkbox" id="c-41220320" checked=""/><div class="controls bullet"><span class="by">brrrrrm</span><span>|</span><a href="#41221473">next</a><span>|</span><label class="collapse" for="c-41220320">[-]</label><label class="expand" for="c-41220320">[1 more]</label></div><br/><div class="children"><div class="content">how does this approach differ from Nvidia&#x27;s 2019 writeup on using trees to improve allreduce operations? <a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;massively-scale-deep-learning-training-nccl-2-4&#x2F;" rel="nofollow">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;massively-scale-deep-learn...</a></div><br/></div></div><div id="41221473" class="c"><input type="checkbox" id="c-41221473" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#41220320">prev</a><span>|</span><a href="#41220479">next</a><span>|</span><label class="collapse" for="c-41221473">[-]</label><label class="expand" for="c-41221473">[2 more]</label></div><br/><div class="children"><div class="content">I recall reading recently that someone went back and trained an RNN at a similar scale to a GPT and got similar performance on modern hardware (perhaps someone can link me that paper?).<p>ie., the innovation in statistical AI isn&#x27;t in making the algorithms &quot;smarter&quot;, it&#x27;s finding ways to align the computation with modern GPU hardware -- this has been the story since 2012.<p>In the end, the function all such algs are approximating is a conditional probability. ie., the perfect answer to any prompt is to ignore training entirely, and at inference time, compute an expectation across all historical data. All training does is essentially optimally cache a large part of that computation.<p>This is very different to how it&#x27;s typically sold&#x2F;understood, in the sense that there&#x27;s an appearance that at inference-time some unbounded computation is going on, ie., &quot;thinking&quot;&#x2F;&quot;reasoning&quot;&#x2F;etc. But at inference time <i>for any prompt</i> the same amount of computation is used, regardless of the question complexity. So the system will appear to reason (etc.) if it can sample convincingly from its pre-cached computation.<p>This means &quot;innovation&quot; here follows a moore&#x27;s law S-curve for GPU hardware.</div><br/><div id="41221597" class="c"><input type="checkbox" id="c-41221597" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#41221473">parent</a><span>|</span><a href="#41220479">next</a><span>|</span><label class="collapse" for="c-41221597">[-]</label><label class="expand" for="c-41221597">[1 more]</label></div><br/><div class="children"><div class="content">But often, less training performs better.</div><br/></div></div></div></div><div id="41220479" class="c"><input type="checkbox" id="c-41220479" checked=""/><div class="controls bullet"><span class="by">Narhem</span><span>|</span><a href="#41221473">prev</a><span>|</span><label class="collapse" for="c-41220479">[-]</label><label class="expand" for="c-41220479">[5 more]</label></div><br/><div class="children"><div class="content">How often do papers like this make it to industry applications&#x2F;published research. Seems stuck in between the two.</div><br/><div id="41221450" class="c"><input type="checkbox" id="c-41221450" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#41220479">parent</a><span>|</span><a href="#41220576">next</a><span>|</span><label class="collapse" for="c-41221450">[-]</label><label class="expand" for="c-41221450">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s from industry. It&#x27;s a funded research startup.</div><br/></div></div><div id="41220576" class="c"><input type="checkbox" id="c-41220576" checked=""/><div class="controls bullet"><span class="by">mithametacs</span><span>|</span><a href="#41220479">parent</a><span>|</span><a href="#41221450">prev</a><span>|</span><label class="collapse" for="c-41220576">[-]</label><label class="expand" for="c-41220576">[3 more]</label></div><br/><div class="children"><div class="content">This is going to shred when it reaches industry.<p>But yeah very math heavy for a software engineering paper.</div><br/><div id="41220769" class="c"><input type="checkbox" id="c-41220769" checked=""/><div class="controls bullet"><span class="by">ynniv</span><span>|</span><a href="#41220479">root</a><span>|</span><a href="#41220576">parent</a><span>|</span><label class="collapse" for="c-41220769">[-]</label><label class="expand" for="c-41220769">[2 more]</label></div><br/><div class="children"><div class="content">How long can a page of python take? <a href="https:&#x2F;&#x2F;github.com&#x2F;Zyphra&#x2F;tree_attention&#x2F;blob&#x2F;main&#x2F;tree_shard_test.py">https:&#x2F;&#x2F;github.com&#x2F;Zyphra&#x2F;tree_attention&#x2F;blob&#x2F;main&#x2F;tree_shar...</a></div><br/><div id="41221480" class="c"><input type="checkbox" id="c-41221480" checked=""/><div class="controls bullet"><span class="by">mithametacs</span><span>|</span><a href="#41220479">root</a><span>|</span><a href="#41220769">parent</a><span>|</span><label class="collapse" for="c-41221480">[-]</label><label class="expand" for="c-41221480">[1 more]</label></div><br/><div class="children"><div class="content">You seem to know your stuff.<p>Will this technique work with existing model weights?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>