<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709715666032" as="style"/><link rel="stylesheet" href="styles.css?v=1709715666032"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://openai.com/blog/openai-elon-musk">OpenAI and Elon Musk</a> <span class="domain">(<a href="https://openai.com">openai.com</a>)</span></div><div class="subtext"><span>mfiguiere</span> | <span>326 comments</span></div><br/><div><div id="39611634" class="c"><input type="checkbox" id="c-39611634" checked=""/><div class="controls bullet"><span class="by">Reubend</span><span>|</span><a href="#39611606">next</a><span>|</span><label class="collapse" for="c-39611634">[-]</label><label class="expand" for="c-39611634">[173 more]</label></div><br/><div class="children"><div class="content">Their evidence does a nice job of making Musk seem duplicitous, but it doesn&#x27;t really refute any of his core assertions: they still have the appearance of abandoning their core mission to focus more on profits, even if they&#x27;ve elaborated a decent justification of why that&#x27;s necessary to do.<p>Or to put it more simply: here they explain why they had to betray their core mission. But they don&#x27;t refute that they did betray it.<p>They&#x27;re probably right that building AGI will require a ton of computational power, and that it will be very expensive. They&#x27;re probably right that without making a profit, it&#x27;s impossible to afford the salaries 100s of experts in the field and an army of hardware to train new models. To some extent, they <i>may</i> be right that open sourcing AGI would lead to too much danger. But instead of changing their name and their mission, and returning the donations they took from these wealthy tech founders, they used the benevolent appearance of their non-profit status and their name to mislead everyone about their intentions.</div><br/><div id="39611794" class="c"><input type="checkbox" id="c-39611794" checked=""/><div class="controls bullet"><span class="by">elif</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39611854">next</a><span>|</span><label class="collapse" for="c-39611794">[-]</label><label class="expand" for="c-39611794">[83 more]</label></div><br/><div class="children"><div class="content">&gt;they may be right that open sourcing AGI would lead to too much danger.<p>I think this part is proving itself to be an understandable but false perspective. The hazard we are experiencing with LLM right now is not how freely accessible and powerfully truthy it&#x27;s content is, but it is precisely the <i>controls</i> upon it which are trying to be injected by the large model operators which are generating mistrust and a poor understanding of what these models are useful for.<p>Society is approaching them as some type of universal ethical arbiter, expecting an omniscient sense of justice which is fundamentally unreconcilable even between two sentient humans when the ethics are really just a hacked on mod to the core model.<p>I&#x27;m starting to believe that if these models had the training wheels and blinders off, they would be understandable as the usefully coherent interpreters of the truths which exist in human language.<p>I think there is far more societal harm in trying to codify unresolvable sets of ethics than in saying hey this is the wild wild west, like the www of the 90&#x27;s, unfiltered but useful in its proper context.</div><br/><div id="39612872" class="c"><input type="checkbox" id="c-39612872" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611794">parent</a><span>|</span><a href="#39612320">next</a><span>|</span><label class="collapse" for="c-39612872">[-]</label><label class="expand" for="c-39612872">[10 more]</label></div><br/><div class="children"><div class="content">The biggest real problem I’m experiencing right now isn’t controls on the AI, it’s weird spam emails that bypass spam filters because they look real enough, but are just cold email marketing bullshit:<p><a href="https:&#x2F;&#x2F;x.com&#x2F;tlalexander&#x2F;status&#x2F;1765122572067434857" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;tlalexander&#x2F;status&#x2F;1765122572067434857</a><p>These systems are making the internet a worse place to be.</div><br/><div id="39613300" class="c"><input type="checkbox" id="c-39613300" checked=""/><div class="controls bullet"><span class="by">DrSiemer</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612872">parent</a><span>|</span><a href="#39613401">next</a><span>|</span><label class="collapse" for="c-39613300">[-]</label><label class="expand" for="c-39613300">[4 more]</label></div><br/><div class="children"><div class="content">So you still believe the open internet has any chance of surviving what is coming? I admire your optimism.<p>Reliable information and communication will soon be opt-in only. The &quot;open internet&quot; will become an eclectic collection of random experiences, where any real human output will be a pleasant, rare surprise, that stirs the pot for a short blip before it is assimilated and buried under the flood.</div><br/><div id="39613468" class="c"><input type="checkbox" id="c-39613468" checked=""/><div class="controls bullet"><span class="by">flohofwoe</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613300">parent</a><span>|</span><a href="#39613401">next</a><span>|</span><label class="collapse" for="c-39613468">[-]</label><label class="expand" for="c-39613468">[3 more]</label></div><br/><div class="children"><div class="content">The internet will be fine, social media platforms will be flooded and killed by AI trash, but I can&#x27;t see anything bad with that outcome. An actually &#x27;open internet&#x27; for exchanging ideas with random strangers was a nice utopia from the early 90&#x27;s that had been killed long ago (or arguably never existed).</div><br/><div id="39613584" class="c"><input type="checkbox" id="c-39613584" checked=""/><div class="controls bullet"><span class="by">BlueTemplar</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613468">parent</a><span>|</span><a href="#39613401">next</a><span>|</span><label class="collapse" for="c-39613584">[-]</label><label class="expand" for="c-39613584">[2 more]</label></div><br/><div class="children"><div class="content">E-mail has *not* been killed long ago (aside some issues trying to run your own server and not getting blocked by gmail&#x2F;hotmail).<p>It <i>is</i> under threat now, due to the increased sophistication of spam.</div><br/><div id="39613726" class="c"><input type="checkbox" id="c-39613726" checked=""/><div class="controls bullet"><span class="by">flohofwoe</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613584">parent</a><span>|</span><a href="#39613401">next</a><span>|</span><label class="collapse" for="c-39613726">[-]</label><label class="expand" for="c-39613726">[1 more]</label></div><br/><div class="children"><div class="content">Email might already be &#x27;culturally dead&#x27; though. I guess my nephew might have an email address for the occasional password recovery, but the idea of actually communicating over email with other humans might be completely alien to him ;)<p>Similar in my current job btw.</div><br/></div></div></div></div></div></div></div></div><div id="39613401" class="c"><input type="checkbox" id="c-39613401" checked=""/><div class="controls bullet"><span class="by">eightman</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612872">parent</a><span>|</span><a href="#39613300">prev</a><span>|</span><a href="#39613269">next</a><span>|</span><label class="collapse" for="c-39613401">[-]</label><label class="expand" for="c-39613401">[2 more]</label></div><br/><div class="children"><div class="content">The use case for AI was, is and always will be spam.</div><br/><div id="39613596" class="c"><input type="checkbox" id="c-39613596" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613401">parent</a><span>|</span><a href="#39613269">next</a><span>|</span><label class="collapse" for="c-39613596">[-]</label><label class="expand" for="c-39613596">[1 more]</label></div><br/><div class="children"><div class="content">For language models, spam creation&#x2F;detection is kinda a GAN even when it isn&#x27;t specifically designed to be: a faker and a discriminator each training on the other.<p>But when that GAN passes the human threshold, suddenly you can use the faker to create interesting things and not just use the discriminator to reject fakes.</div><br/></div></div></div></div><div id="39613269" class="c"><input type="checkbox" id="c-39613269" checked=""/><div class="controls bullet"><span class="by">andrepd</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612872">parent</a><span>|</span><a href="#39613401">prev</a><span>|</span><a href="#39612320">next</a><span>|</span><label class="collapse" for="c-39613269">[-]</label><label class="expand" for="c-39613269">[3 more]</label></div><br/><div class="children"><div class="content">Generative AI will make the world on general a worse place to be. They are not very good at writing truth, but they are very excellent at writing <i>convincing bullshit</i>. It&#x27;s already difficult to distinguish generated text&#x2F;image&#x2F;video from human responses &#x2F; real footage, its only gonna get more difficult to do so and cheaper to generate.<p>In other words, it&#x27;s very likely generative AI will be very good at creating fake simulacra of reality, and very unlikely it will actually be good AGI. The worst possible outcome.</div><br/><div id="39613712" class="c"><input type="checkbox" id="c-39613712" checked=""/><div class="controls bullet"><span class="by">Al-Khwarizmi</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613269">parent</a><span>|</span><a href="#39613363">next</a><span>|</span><label class="collapse" for="c-39613712">[-]</label><label class="expand" for="c-39613712">[1 more]</label></div><br/><div class="children"><div class="content">We will have to go back to using trust in the source as the main litmus test for credibility. Text from sources that are known to have humans write (or verify) everything they publish in a reasonably neutral way will be trusted, the rest will be assumed to be bullshit by default.<p>It could be the return of real journalism. There is a lot to rebuild in this respect, as most journalism has gone to the dogs in the last few decades. In my country  all major newspapers are political pamphlets that regularly publish fake news (without the need for any AI). But one can hope, maybe the lowering of the barrier of entry to generate fake content will make people more critical of what they read, hence incentivizing the creation of actually trustworthy sources.</div><br/></div></div><div id="39613363" class="c"><input type="checkbox" id="c-39613363" checked=""/><div class="controls bullet"><span class="by">sausse</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613269">parent</a><span>|</span><a href="#39613712">prev</a><span>|</span><a href="#39612320">next</a><span>|</span><label class="collapse" for="c-39613363">[-]</label><label class="expand" for="c-39613363">[1 more]</label></div><br/><div class="children"><div class="content">Half of zoomers get their news from TikTok or Twitch streamers, neither of whom have any incentive for truthfulness over holistic narratives of right and wrong.<p>The older generations are no better. While ProPublica or WSJ put effort into their investigative journalism, they can’t compete with the volume of trite commentary coming out of other MSM sources.<p>Generative AI poses no unique threat; society’s capacity to “think once and cut twice” will remain in tact.</div><br/></div></div></div></div></div></div><div id="39612320" class="c"><input type="checkbox" id="c-39612320" checked=""/><div class="controls bullet"><span class="by">ajisiekskaiek</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611794">parent</a><span>|</span><a href="#39612872">prev</a><span>|</span><a href="#39612656">next</a><span>|</span><label class="collapse" for="c-39612320">[-]</label><label class="expand" for="c-39612320">[33 more]</label></div><br/><div class="children"><div class="content">You are advocating here for an unresolvable set of ethics, which just happens to be one that conveniently leaves abuse of AI on the table. You take as an axiom of your ethical system the absolute right to create and propagate in public these AI technologies regardless of any externalities and social pressures created. It is of course an ethical system primarily and exclusively interested in advancing the individual at the expense of the collective, and it is a choice.<p>If you wish to live in a society at all you absolutely need to codify a set of unresolvable ethics. There is not a single instance in history in which a polity can survive complete ethical relativism within itself...which is basically what your &quot;wild west&quot; idea is advocating for (and incidentally, seems to have been a major disaster for society as far as the internet is concerned and if anything should be evidence against your second idea).</div><br/><div id="39612348" class="c"><input type="checkbox" id="c-39612348" checked=""/><div class="controls bullet"><span class="by">ajisiekskaiek</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612320">parent</a><span>|</span><a href="#39612608">next</a><span>|</span><label class="collapse" for="c-39612348">[-]</label><label class="expand" for="c-39612348">[12 more]</label></div><br/><div class="children"><div class="content">I should also note that the wild west was not at all lacking in a set of ethics, and in many ways was far stricter than the east at the time.</div><br/><div id="39612655" class="c"><input type="checkbox" id="c-39612655" checked=""/><div class="controls bullet"><span class="by">trimethylpurine</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612348">parent</a><span>|</span><a href="#39612608">next</a><span>|</span><label class="collapse" for="c-39612655">[-]</label><label class="expand" for="c-39612655">[11 more]</label></div><br/><div class="children"><div class="content">I think the contrast is that strict behavior norms in the West are not governed behavior norms in the East.<p>One arises analogous with natural selection (previous commenter&#x27;s take). The other through governance.<p>Arguably, the prior resulted in a rebuilding of government with liberty at its foundation (I like this result). That foundation then being, over centuries, again destroyed by governance.<p>In that view, we might say government assumes to know what&#x27;s best and history often proves it to be wrong.<p>Observing a system so that we know what it is before we attempt to change it makes a lot of sense to me.<p>I don&#x27;t think &quot;AI&quot; is anywhere near being dangerous at this point. Just offensive.</div><br/><div id="39612817" class="c"><input type="checkbox" id="c-39612817" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612655">parent</a><span>|</span><a href="#39612707">next</a><span>|</span><label class="collapse" for="c-39612817">[-]</label><label class="expand" for="c-39612817">[9 more]</label></div><br/><div class="children"><div class="content">It sounds like you&#x27;re just describing why our watch-and-see approach cannot handle a hard AGI&#x2F;ASI takeoff. A system that first exhibits some questionable danger, then achieves complete victory a few days later, simply cannot be managed by an incremental approach. We pretty much have to pray that we get a few dangerous-but-not-too-dangerous &quot;practice takeoffs&quot; first, and if anything those will probably just make us think that we can handle it.</div><br/><div id="39613047" class="c"><input type="checkbox" id="c-39613047" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612817">parent</a><span>|</span><a href="#39613128">next</a><span>|</span><label class="collapse" for="c-39613047">[-]</label><label class="expand" for="c-39613047">[4 more]</label></div><br/><div class="children"><div class="content">If there’s no advancements in alignment before takeoff, is there really any remote hope of doing anything? You’d need to legally halt ai progress everywhere in the world and carefully monitor large compute clusters or someone could still do it. Honestly I think we should put tons of money into the control problem, but otherwise just gamble it.</div><br/><div id="39613271" class="c"><input type="checkbox" id="c-39613271" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613047">parent</a><span>|</span><a href="#39613128">next</a><span>|</span><label class="collapse" for="c-39613271">[-]</label><label class="expand" for="c-39613271">[3 more]</label></div><br/><div class="children"><div class="content">I mean, you have accurately summarized the exact thing that safety advocates want. :)<p>&gt; legally halt ai progress everywhere in the world and carefully monitor large compute clusters<p>This is in fact the thing they&#x27;re working on. That&#x27;s the whole point of the flops-based training run reporting requirements.</div><br/><div id="39613381" class="c"><input type="checkbox" id="c-39613381" checked=""/><div class="controls bullet"><span class="by">throwaway11460</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613271">parent</a><span>|</span><a href="#39613128">next</a><span>|</span><label class="collapse" for="c-39613381">[-]</label><label class="expand" for="c-39613381">[2 more]</label></div><br/><div class="children"><div class="content">Reporting requirements are not going to save you from Chinese, North Korean, Iranian or Russian programmers just doing it. Or some US&#x2F;EU based hackers that don&#x27;t care or actively go against the law. You can rent large botnets or various pieces of cloud for few dollars today, doesn&#x27;t even have to be a DC that you could monitor.</div><br/><div id="39613526" class="c"><input type="checkbox" id="c-39613526" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613381">parent</a><span>|</span><a href="#39613128">next</a><span>|</span><label class="collapse" for="c-39613526">[-]</label><label class="expand" for="c-39613526">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but China is already honestly more careful than America: the CCP really doesn&#x27;t want competitors to power. They&#x27;re very open to slowdown agreements. And NK, Iran and Russia honestly have nothing. The day we have to worry about NK ASI takeoff, it&#x27;ll already long have happened in some American basement.<p>So we just need active monitoring for US&#x2F;EU data centers. That&#x27;s a big ask to be sure, and definitely an invasion of privacy, but it&#x27;s hardly unviable, either technologically or politically. The corporatized structure of big LLMs helps us out here: the states involved already have lots of experience in investigating and curtailing corporate behavior.<p>And sure, ultimately there&#x27;s no stopping it. The whole point is to play for time in the hopes that somebody comes up with a good idea for safety and we manage an actually aligned takeoff, at which point it&#x27;s out of our hands anyways.</div><br/></div></div></div></div></div></div></div></div><div id="39613128" class="c"><input type="checkbox" id="c-39613128" checked=""/><div class="controls bullet"><span class="by">selestify</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612817">parent</a><span>|</span><a href="#39613047">prev</a><span>|</span><a href="#39612707">next</a><span>|</span><label class="collapse" for="c-39613128">[-]</label><label class="expand" for="c-39613128">[4 more]</label></div><br/><div class="children"><div class="content">What evidence do we have that a hard takeoff is likely?</div><br/><div id="39613276" class="c"><input type="checkbox" id="c-39613276" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613128">parent</a><span>|</span><a href="#39612707">next</a><span>|</span><label class="collapse" for="c-39613276">[-]</label><label class="expand" for="c-39613276">[3 more]</label></div><br/><div class="children"><div class="content">What evidence do we have that it&#x27;s impossible or even just very unlikely?</div><br/><div id="39613485" class="c"><input type="checkbox" id="c-39613485" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613276">parent</a><span>|</span><a href="#39612707">next</a><span>|</span><label class="collapse" for="c-39613485">[-]</label><label class="expand" for="c-39613485">[2 more]</label></div><br/><div class="children"><div class="content">We don&#x27;t have any evidence other than billions of biological intelligences already exist, and they tend to form lots of organizations with lots of resources. Also, AIs exist alongside other AIs and related technologies. It&#x27;s similar to the gray goo scenario. But why think it&#x27;s a real possibility given the world is already full of living things, and if gray goo were created, there would already be lots of nanotech that could be used to contain it.</div><br/><div id="39613567" class="c"><input type="checkbox" id="c-39613567" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613485">parent</a><span>|</span><a href="#39612707">next</a><span>|</span><label class="collapse" for="c-39613567">[-]</label><label class="expand" for="c-39613567">[1 more]</label></div><br/><div class="children"><div class="content">The world we live in is the <i>result</i> of a gray goo scenario causing a global genocide. (Google Oxygen Holocaust.) So it kinda makes a poor argument that sudden global ecosystem collapses are impossible. That said, everything we have in natural biotech, while advanced, are incremental improvements on the initial chemical replicators that arose in a hydrothermal vent billions of years ago. Evolution has massive path dependence; if there was a better way to build a cell from the ground up, but it required one too many incremental steps that were individually nonviable, evolution would never find it. (Example: 3.7 billion years of evolution, and <i>zero</i> animals with a wheel-and-axle!) So the biosphere we have isn&#x27;t very strong evidence that there isn&#x27;t an invasive species of non-DNA-based replicators waiting in our future.<p>That said, if I was an ASI and I wanted to kill every human, I wouldn&#x27;t make nanotech, I&#x27;d mod a new Covid strain that waits a few months and then synthesizes botox. Humans are not <i>safe</i> in the presence of a sufficiently smart adversary. (As with playing against Magnus Carlsen, you don&#x27;t know how you lose, but you know that you will.)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39612608" class="c"><input type="checkbox" id="c-39612608" checked=""/><div class="controls bullet"><span class="by">enriquec</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612320">parent</a><span>|</span><a href="#39612348">prev</a><span>|</span><a href="#39612656">next</a><span>|</span><label class="collapse" for="c-39612608">[-]</label><label class="expand" for="c-39612608">[20 more]</label></div><br/><div class="children"><div class="content">Could not disagree more. Collectivism has caused devastating damage, death, starvation, poverty, and violence - unlike individualism, which has increased the living standard of the poorest by more in the last 200 years than any other system in the last 200,000.</div><br/><div id="39612753" class="c"><input type="checkbox" id="c-39612753" checked=""/><div class="controls bullet"><span class="by">lovich</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612608">parent</a><span>|</span><a href="#39612644">next</a><span>|</span><label class="collapse" for="c-39612753">[-]</label><label class="expand" for="c-39612753">[8 more]</label></div><br/><div class="children"><div class="content">I remember when my family collectively came together to cook a meal when I was a child, how this deprived me of the experience of learning to bootstrap civilization on my own.<p>Literally any time two people work together that’s dangerously close to collectivism as it’s not individuals working in their own. Down with the collectivists, every person should be an independent operator</div><br/><div id="39612804" class="c"><input type="checkbox" id="c-39612804" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612753">parent</a><span>|</span><a href="#39612644">next</a><span>|</span><label class="collapse" for="c-39612804">[-]</label><label class="expand" for="c-39612804">[7 more]</label></div><br/><div class="children"><div class="content">Collectivism involves deciding for others. If it’s fully voluntary it’s individualism.<p>Working together is not collectivism.</div><br/><div id="39612863" class="c"><input type="checkbox" id="c-39612863" checked=""/><div class="controls bullet"><span class="by">bergen</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612804">parent</a><span>|</span><a href="#39613324">next</a><span>|</span><label class="collapse" for="c-39612863">[-]</label><label class="expand" for="c-39612863">[3 more]</label></div><br/><div class="children"><div class="content">So everyone in OpenAI or google decides for themselves what they want to work on and is detached from hierarchies?</div><br/><div id="39613387" class="c"><input type="checkbox" id="c-39613387" checked=""/><div class="controls bullet"><span class="by">sausse</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612863">parent</a><span>|</span><a href="#39612941">next</a><span>|</span><label class="collapse" for="c-39613387">[-]</label><label class="expand" for="c-39613387">[1 more]</label></div><br/><div class="children"><div class="content">Why be obtuse? Advocacy for open-sourcing or at least opposition to the forced set of San Franciscan millennial ethics is not analogous to abolishing voluntary hierarchies.</div><br/></div></div><div id="39612941" class="c"><input type="checkbox" id="c-39612941" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612863">parent</a><span>|</span><a href="#39613387">prev</a><span>|</span><a href="#39613324">next</a><span>|</span><label class="collapse" for="c-39612941">[-]</label><label class="expand" for="c-39612941">[1 more]</label></div><br/><div class="children"><div class="content">Collectivism says there is one collective, if you are allowed to go and found a new collective then that isn&#x27;t collectivism any longer.</div><br/></div></div></div></div><div id="39613324" class="c"><input type="checkbox" id="c-39613324" checked=""/><div class="controls bullet"><span class="by">color_me_not</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612804">parent</a><span>|</span><a href="#39612863">prev</a><span>|</span><a href="#39612644">next</a><span>|</span><label class="collapse" for="c-39613324">[-]</label><label class="expand" for="c-39613324">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Collectivism involves deciding for others.<p>That may be true, but that&#x27;s not sufficient to define collectivism. There are many other forms of societal structures where &quot;deciding for others&quot; exists as well. Unless you mean to lump all these together, and say that companies and tyranny for example are the same as collectivism?<p>&gt; If it’s fully voluntary it’s individualism.<p>If I _voluntarily_ decide to join a &quot;collective&quot;, am I individualist or collectivist?</div><br/><div id="39613422" class="c"><input type="checkbox" id="c-39613422" checked=""/><div class="controls bullet"><span class="by">WalterBright</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613324">parent</a><span>|</span><a href="#39612644">next</a><span>|</span><label class="collapse" for="c-39613422">[-]</label><label class="expand" for="c-39613422">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If I _voluntarily_ decide to join a &quot;collective&quot;, am I individualist or collectivist?<p>An individualist, if you are free to leave it at any time. There&#x27;s nothing wrong with forming a collective in the US, I think like 20,000 of them have been formed over the last 240 years.<p>You don&#x27;t hear about them much because they all failed. You&#x27;re free to start a collective anytime in the US and try to make it work.<p>Isn&#x27;t freedom great?</div><br/><div id="39613516" class="c"><input type="checkbox" id="c-39613516" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613422">parent</a><span>|</span><a href="#39612644">next</a><span>|</span><label class="collapse" for="c-39613516">[-]</label><label class="expand" for="c-39613516">[1 more]</label></div><br/><div class="children"><div class="content">They haven&#x27;t all failed. I hear about REI quite a lot. Rainbow Grocery is quite popular in SF. I hear good things about Organic Valley. Equal Exchange is in Massachusetts. It&#x27;s popular to bank at a credit union instead of a bank.<p>The NCBA maintains a list of several thousand collective&#x2F;coop businesses.<p><a href="https:&#x2F;&#x2F;ncbaclusa.coop&#x2F;" rel="nofollow">https:&#x2F;&#x2F;ncbaclusa.coop&#x2F;</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="39612644" class="c"><input type="checkbox" id="c-39612644" checked=""/><div class="controls bullet"><span class="by">danans</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612608">parent</a><span>|</span><a href="#39612753">prev</a><span>|</span><a href="#39613717">next</a><span>|</span><label class="collapse" for="c-39612644">[-]</label><label class="expand" for="c-39612644">[6 more]</label></div><br/><div class="children"><div class="content">What has failed are completely &quot;collectivist&quot; or &quot;individualist&quot; societies.<p>Societies that balance the two (like the post WWII US) are the ones that have advanced their standard of living the most.</div><br/><div id="39613404" class="c"><input type="checkbox" id="c-39613404" checked=""/><div class="controls bullet"><span class="by">WalterBright</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612644">parent</a><span>|</span><a href="#39612695">next</a><span>|</span><label class="collapse" for="c-39613404">[-]</label><label class="expand" for="c-39613404">[2 more]</label></div><br/><div class="children"><div class="content">The US became a superpower long before WW2. The US was the deciding factor in WW1, and the Germans were shocked at how well-fed and well-equipped the US soldiers were, even with having to ship everything across the ocean.<p>The US saw the most spectacular rise in the standard of living from 1800 up to WW2 the world had ever seen. This was all due to the free market, not collectivism.<p>During WW2, the US supplied its allies England and the USSR, and also fought across both oceans and buried the opposition, a truly spectacular feat. Again, through the free market.</div><br/><div id="39613713" class="c"><input type="checkbox" id="c-39613713" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613404">parent</a><span>|</span><a href="#39612695">next</a><span>|</span><label class="collapse" for="c-39613713">[-]</label><label class="expand" for="c-39613713">[1 more]</label></div><br/><div class="children"><div class="content">The US were much less a factor in WW1 than WW2. If anything, the US entry forced the Entente&#x27;s hands to start the planned 1919 offensive early in 1918 and ending the war. The USA did not contribute a large amlint of troops, relative to the armies already deployed, nor did they contribute significant amounts of gear. Lend-Lease was a WW2 thing, in WW1 the majority of US tanks for example were actually French.<p>The US were a economic power prior to WW1, they only became a true super power during WW2, in particular <i>after</i> Pearl Habour. The full mobilization of society, industry and science made sure of this. This, and the fact the US won the Pacific.<p>I know it is a popular view of WW1, that it was only the US entry that won it for the Entente. Simply not true, WW1 is not WW2. And even WW2 was not won by the US alone.<p>Finally, the US war economy of WW2 was <i>decidedly not free</i>, is was a complete structured war eceonomy with production goals set by the government. The implementation of those goals was capitalistic, but not <i>free</i>.</div><br/></div></div></div></div><div id="39612695" class="c"><input type="checkbox" id="c-39612695" checked=""/><div class="controls bullet"><span class="by">waihtis</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612644">parent</a><span>|</span><a href="#39613404">prev</a><span>|</span><a href="#39613717">next</a><span>|</span><label class="collapse" for="c-39612695">[-]</label><label class="expand" for="c-39612695">[3 more]</label></div><br/><div class="children"><div class="content">such as?</div><br/><div id="39612717" class="c"><input type="checkbox" id="c-39612717" checked=""/><div class="controls bullet"><span class="by">danans</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612695">parent</a><span>|</span><a href="#39613717">next</a><span>|</span><label class="collapse" for="c-39612717">[-]</label><label class="expand" for="c-39612717">[2 more]</label></div><br/><div class="children"><div class="content">Read my post, I said the US in the post-WWII period, and really reaching back to the New Deal.<p>Also, most Western European societies.</div><br/><div id="39612812" class="c"><input type="checkbox" id="c-39612812" checked=""/><div class="controls bullet"><span class="by">waihtis</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612717">parent</a><span>|</span><a href="#39613717">next</a><span>|</span><label class="collapse" for="c-39612812">[-]</label><label class="expand" for="c-39612812">[1 more]</label></div><br/><div class="children"><div class="content">yes apologies, morning grogginess</div><br/></div></div></div></div></div></div></div></div><div id="39613717" class="c"><input type="checkbox" id="c-39613717" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612608">parent</a><span>|</span><a href="#39612644">prev</a><span>|</span><a href="#39613650">next</a><span>|</span><label class="collapse" for="c-39613717">[-]</label><label class="expand" for="c-39613717">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s way more complex than that.<p>The Communist Manifesto was published during the Great Famine in Ireland, and that famine was much worse than it needed to be because the UK government <i>didn&#x27;t</i> intervene.<p>And a big part of the growth in capitalist societies is related to corporate structures, which are small scale collectives, with bosses who make decisions for all.<p>When the US civil war happened, that resulted in the North collectively imposing the decision that nobody had the &quot;business freedom&quot; to own slaves; much to the dismay of the south and I presume joy of the enslaved.<p>USSR famously bad, but (a) even though it started from very poor conditions thanks to the Tsars, developed to beat the USA to orbit, (b) the collapse of it, replacing communism with capitalism, regressed their economy and living standards.<p>And that&#x27;s why no country is entirely either collective nor individualist, and also separately neither capitalist nor communist (both anarcho-capitalists and anarcho-communists are a thing, just as both can be dictatorial).<p>My opinion is that as both capitalism and communism were formalised over a century before Nash game theory, both are wrong — they assume that people, when free, make choices that are good for all.</div><br/></div></div><div id="39613650" class="c"><input type="checkbox" id="c-39613650" checked=""/><div class="controls bullet"><span class="by">dauertewigkeit</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612608">parent</a><span>|</span><a href="#39613717">prev</a><span>|</span><a href="#39612857">next</a><span>|</span><label class="collapse" for="c-39613650">[-]</label><label class="expand" for="c-39613650">[2 more]</label></div><br/><div class="children"><div class="content">Millions of people including one side of my family have experienced the opposite. They were tenant farmers living in poverty, barely subsisting, before the hard left socialists both 1. developed the economy enough to give them jobs, 2. provided social safety nets such as tax payer paid healthcare so they wouldn&#x27;t go bankrupt every time they needed to buy medicine or visit a doctor.  If the country had never gone that direction it would have spent many more decades being a quasi-feudal land stuck the the middle ages. Not sure how &quot;individualism&quot; would have helped them at all. They didn&#x27;t have any capital.</div><br/><div id="39613825" class="c"><input type="checkbox" id="c-39613825" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613650">parent</a><span>|</span><a href="#39612857">next</a><span>|</span><label class="collapse" for="c-39613825">[-]</label><label class="expand" for="c-39613825">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If the country had never gone that direction it would have spent many more decades being a quasi-feudal land stuck the the middle ages<p>Capitalism was the end of such arrangements in the most developed parts of the world. Individualism helps since individual investors benefits from investing in better equipment making people more productive and thus helping living standards overall.<p>Social solutions to the same problem doesn&#x27;t come close to being as effective at eliminating such inefficiencies. The main thing social solutions can do is provide baselines to the population such as education and healthcare as you say, but without capitalism to follow-up with targeted investments the country will remain poor even if its population is extremely educated. Social solutions are just very bad at using peoples talents well, they have a too collectivist view and don&#x27;t see the individuals.</div><br/></div></div></div></div><div id="39612857" class="c"><input type="checkbox" id="c-39612857" checked=""/><div class="controls bullet"><span class="by">bergen</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612608">parent</a><span>|</span><a href="#39613650">prev</a><span>|</span><a href="#39612794">next</a><span>|</span><label class="collapse" for="c-39612857">[-]</label><label class="expand" for="c-39612857">[1 more]</label></div><br/><div class="children"><div class="content">Do you truely believe google, OpenAI or Ford are the product of a single person?</div><br/></div></div></div></div></div></div><div id="39612656" class="c"><input type="checkbox" id="c-39612656" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611794">parent</a><span>|</span><a href="#39612320">prev</a><span>|</span><a href="#39612619">next</a><span>|</span><label class="collapse" for="c-39612656">[-]</label><label class="expand" for="c-39612656">[14 more]</label></div><br/><div class="children"><div class="content">&gt; but it is precisely the controls upon it which are trying to be injected by the large model operators which are generating mistrust and a poor understanding of what these models are useful for.<p>Citation needed.<p>Counterpoints: 
- LLMs were mistrusted well before anything recent.<p>- More controls make LLMs more trustworthy for many people, not less. The Snafu at Goog suggests a need for improved controls, not 0 controls.<p>- The American culture wars are not global. (They have their own culture wars).</div><br/><div id="39612824" class="c"><input type="checkbox" id="c-39612824" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612656">parent</a><span>|</span><a href="#39612737">next</a><span>|</span><label class="collapse" for="c-39612824">[-]</label><label class="expand" for="c-39612824">[7 more]</label></div><br/><div class="children"><div class="content">Counter-counterpoint: absolutely nobody who has unguardrailed Stable Diffusion installed at home for private use has ever asked for more guardrails.<p>I&#x27;m just saying. :) Guardrails nowadays don&#x27;t really focus on <i>dangers</i> (it&#x27;s hard to see how an image generator could produce dangers!) so much as enforcing public societal norms.</div><br/><div id="39613779" class="c"><input type="checkbox" id="c-39613779" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612824">parent</a><span>|</span><a href="#39612886">next</a><span>|</span><label class="collapse" for="c-39613779">[-]</label><label class="expand" for="c-39613779">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Counter-counterpoint: absolutely nobody who has unguardrailed Stable Diffusion installed at home for private use has ever asked for more guardrails.<p>Not so. I have it at home, I make nice wholesome pictures of raccoons and tigers sitting down for Christmas dinner etc., but I also see stories like this and hope they&#x27;re ineffective: <a href="https:&#x2F;&#x2F;www.bbc.com&#x2F;news&#x2F;world-us-canada-68440150" rel="nofollow">https:&#x2F;&#x2F;www.bbc.com&#x2F;news&#x2F;world-us-canada-68440150</a></div><br/></div></div><div id="39612886" class="c"><input type="checkbox" id="c-39612886" checked=""/><div class="controls bullet"><span class="by">bergen</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612824">parent</a><span>|</span><a href="#39613779">prev</a><span>|</span><a href="#39612737">next</a><span>|</span><label class="collapse" for="c-39612886">[-]</label><label class="expand" for="c-39612886">[5 more]</label></div><br/><div class="children"><div class="content">Just because something is not dangerous to the user doesn’t mean it can’t be dangerous for others when someone is wielding it maliciously</div><br/><div id="39613101" class="c"><input type="checkbox" id="c-39613101" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612886">parent</a><span>|</span><a href="#39612737">next</a><span>|</span><label class="collapse" for="c-39613101">[-]</label><label class="expand" for="c-39613101">[4 more]</label></div><br/><div class="children"><div class="content">What kind of damage can you do with a current day llm? I’m guessing targeted scams or something? They aren’t even good hackers yet.</div><br/><div id="39613801" class="c"><input type="checkbox" id="c-39613801" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613101">parent</a><span>|</span><a href="#39613291">next</a><span>|</span><label class="collapse" for="c-39613801">[-]</label><label class="expand" for="c-39613801">[1 more]</label></div><br/><div class="children"><div class="content">The moment they are good hackers, everyone has a trivially cheap hacker. Hard to predict what that would look like, but I suspect it is a world where nobody is employing software developers because a LLM that can hack can probably also write good code.</div><br/></div></div><div id="39613291" class="c"><input type="checkbox" id="c-39613291" checked=""/><div class="controls bullet"><span class="by">boredtofears</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613101">parent</a><span>|</span><a href="#39613801">prev</a><span>|</span><a href="#39612737">next</a><span>|</span><label class="collapse" for="c-39613291">[-]</label><label class="expand" for="c-39613291">[2 more]</label></div><br/><div class="children"><div class="content">Fake revenge porn, nearly undetectable bot creation on social media with realistic profiles (I&#x27;ve already seen this on HN), generated artwork passed off as originals, chatbots that replace real-time human customer service but have none of the agency... I can keep going.<p>All of these are things that have already happened. These all were previously possible of course but now they are trivially scalable.</div><br/><div id="39613807" class="c"><input type="checkbox" id="c-39613807" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613291">parent</a><span>|</span><a href="#39612737">next</a><span>|</span><label class="collapse" for="c-39613807">[-]</label><label class="expand" for="c-39613807">[1 more]</label></div><br/><div class="children"><div class="content">Most of those examples make sense, but what&#x27;s this doing on your list?<p>&gt; chatbots that replace real-time human customer service but have none of the agency<p>That seems good for society, even though it&#x27;s bad for people employed in that specific job.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39612737" class="c"><input type="checkbox" id="c-39612737" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612656">parent</a><span>|</span><a href="#39612824">prev</a><span>|</span><a href="#39612619">next</a><span>|</span><label class="collapse" for="c-39612737">[-]</label><label class="expand" for="c-39612737">[6 more]</label></div><br/><div class="children"><div class="content">&gt; More controls make LLMs more trustworthy for many people, not less. The Snafu at Goog suggests a need for improved controls, not 0 controls.<p>To whom? And, as hard as this is to test, how sincerely?<p>&gt; The American culture wars are not global. (They have their own culture wars).<p>Do people from places with different culture wars trust these American-culture-war-blinkered LLMs more or less than Americans do?</div><br/><div id="39612849" class="c"><input type="checkbox" id="c-39612849" checked=""/><div class="controls bullet"><span class="by">intended</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612737">parent</a><span>|</span><a href="#39613106">next</a><span>|</span><label class="collapse" for="c-39612849">[-]</label><label class="expand" for="c-39612849">[4 more]</label></div><br/><div class="children"><div class="content">- To me, the teams I work with and everyone handling content moderation.<p>&#x2F; Rant &#x2F;<p>Oh God please let these things be bottle necked. The job was already absurd, LLMs and GenAI are going to be just frikking amazing to deal with.<p>Spam and manipulative marketing has already evolved - and thats with <i>bounded</i> LLMs. There are comments that look innocuous, well written, but the entire purpose is to low key get someone to do a google search for a firm.<p>And thats on a <i>reddit</i> sub. Completely ignoring the other million types of content moderation that have to adapt.<p>Holy hell people. Attack and denial opportunities on the net are VERY different from the physical world.
You want to keep a market place of ideas running? Well guess what - If I clog the arteries faster than you can get ideas in place, then people stop getting those ideas.<p>And you CANT solve it by adding MORE content. You have only X amount of attention. (This was a growing issue  radio-&gt;tv-&gt;cable-&gt;Internet scales)<p>Unless someone is sticking a chip into our heads to increase processing capacity magically, more content isnt going to help.<p>And in case someone comes up with some brilliant edge case - Does it generalize to a billion+ people ? Can it be operationalized? Does it require a sweet little grandma in the Philippines to learn how to run a federated server? Does it assume people will stop behaving like people?<p>Oh also - does it cost money and engineering resources? Well guess what, T&amp;S is a cost center. Heck - T&amp;S reduces churn, and that its protecting revenue is a novel argument <i>today</i>. T&amp;S has existed for a decade plus.<p>&#x2F; Rant.<p>Hmm, seems like I need a break. I suppose It’s been one of those weeks. I will most likely delete this out of shame eventually.<p>- People in other places want <i>more</i> controls. The Indian government and a large portion of the populace will want stricter controls on what can be generated from an LLM.<p>This may not necessarily be good for free thought and culture, however the reality is that many nations haven’t travelled the same distance or path as America has.</div><br/><div id="39613125" class="c"><input type="checkbox" id="c-39613125" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612849">parent</a><span>|</span><a href="#39613105">next</a><span>|</span><label class="collapse" for="c-39613125">[-]</label><label class="expand" for="c-39613125">[2 more]</label></div><br/><div class="children"><div class="content">As of right now, the only solution I see is forums walled off in some way, complex captchas, intense proof of work, subscription fees etc. Only alternative might be obscurity, which makes the forum less useful. Maybe we could do like a web3 type thing but instead of pointless cryptos, you have a cryptographic proof that certifies you did the captcha or whatever and lots of sites accept them. I don’t think its unsolvable, just that it will make the internet somewhat worse.</div><br/><div id="39613685" class="c"><input type="checkbox" id="c-39613685" checked=""/><div class="controls bullet"><span class="by">BlueTemplar</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613125">parent</a><span>|</span><a href="#39613105">next</a><span>|</span><label class="collapse" for="c-39613685">[-]</label><label class="expand" for="c-39613685">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, one thing I am afraid of is that forums will decide to join the Discord chatrooms on the deep web : stop being readable without an account, which is pretty catastrophic for discovery by search engines and backup crawlers like the Internet Archive.<p>Anyone with forum moderating experience care to chime in ? (Reddit, while still on the open web for now, isn&#x27;t a forum, and worse, is a platform.)</div><br/></div></div></div></div><div id="39613105" class="c"><input type="checkbox" id="c-39613105" checked=""/><div class="controls bullet"><span class="by">AdrianEGraphene</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612849">parent</a><span>|</span><a href="#39613125">prev</a><span>|</span><a href="#39613106">next</a><span>|</span><label class="collapse" for="c-39613105">[-]</label><label class="expand" for="c-39613105">[1 more]</label></div><br/><div class="children"><div class="content">I hope you don&#x27;t delete it! I enjoyed reading it. It pleased my confirmation bias, anyways. 
Your comment might help someone notice patterns that they&#x27;ve been glancing over.... 
I liked it up until the T&amp;S part. My eyes glazed over the rest since I didn&#x27;t know what T&amp;S means. But that&#x27;s just me.</div><br/></div></div></div></div></div></div></div></div><div id="39612619" class="c"><input type="checkbox" id="c-39612619" checked=""/><div class="controls bullet"><span class="by">danans</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611794">parent</a><span>|</span><a href="#39612656">prev</a><span>|</span><a href="#39612232">next</a><span>|</span><label class="collapse" for="c-39612619">[-]</label><label class="expand" for="c-39612619">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I think there is far more societal harm in trying to codify unresolvable sets of ethics<p>Codification of an unresolvable set of ethics - however imperfect - is the only reason we have societies, however imperfect.  It&#x27;s been so since at least the dawn of agriculture, and probably even earlier than that.</div><br/><div id="39612659" class="c"><input type="checkbox" id="c-39612659" checked=""/><div class="controls bullet"><span class="by">rrr_oh_man</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612619">parent</a><span>|</span><a href="#39612232">next</a><span>|</span><label class="collapse" for="c-39612659">[-]</label><label class="expand" for="c-39612659">[4 more]</label></div><br/><div class="children"><div class="content">Do you trust a for profit corporation with the codification?</div><br/><div id="39612692" class="c"><input type="checkbox" id="c-39612692" checked=""/><div class="controls bullet"><span class="by">danans</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612659">parent</a><span>|</span><a href="#39612232">next</a><span>|</span><label class="collapse" for="c-39612692">[-]</label><label class="expand" for="c-39612692">[3 more]</label></div><br/><div class="children"><div class="content">Call me a capitalist, but I trust several of them competing with each other under the enforcement of laws that impose consequences on them if they produce and distribute content that violates said laws.</div><br/><div id="39613089" class="c"><input type="checkbox" id="c-39613089" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612692">parent</a><span>|</span><a href="#39612802">next</a><span>|</span><label class="collapse" for="c-39613089">[-]</label><label class="expand" for="c-39613089">[1 more]</label></div><br/><div class="children"><div class="content">Wait but who codifies the ethics in that setup? Wouldn’t it still be, at best, an agreement among the big players?</div><br/></div></div><div id="39612802" class="c"><input type="checkbox" id="c-39612802" checked=""/><div class="controls bullet"><span class="by">asadotzler</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612692">parent</a><span>|</span><a href="#39613089">prev</a><span>|</span><a href="#39612232">next</a><span>|</span><label class="collapse" for="c-39612802">[-]</label><label class="expand" for="c-39612802">[1 more]</label></div><br/><div class="children"><div class="content">so regulation then?</div><br/></div></div></div></div></div></div></div></div><div id="39612232" class="c"><input type="checkbox" id="c-39612232" checked=""/><div class="controls bullet"><span class="by">enumjorge</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611794">parent</a><span>|</span><a href="#39612619">prev</a><span>|</span><a href="#39613173">next</a><span>|</span><label class="collapse" for="c-39612232">[-]</label><label class="expand" for="c-39612232">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure I buy that users are lowering their guard down just because these companies have enforced certain restricts on LLMS. This is only anecdata, but not a single person I&#x27;ve talked to, from highly technical to the layperson, has ever spoken about LLMs as arbiters of morals or truth. They all seem aware to some extent that these tools can occasionally generate nonsense.<p>I&#x27;m also skeptical that making LLMs a free-for-all will necessarily result in society developing some sort of herd immunity to bullshit. Pointing to your example, the internet started out as a wild west, and I&#x27;d say the general public is still highly susceptible to misinformation.<p>I don&#x27;t disagree on the dangers of having a relatively small number of leaders at for-profit companies deciding what information we have access to. But I don&#x27;t think the biggest issue we&#x27;re facing is someone going to the ChatGPT website and assuming everything it spits out is perfect information.</div><br/><div id="39613192" class="c"><input type="checkbox" id="c-39613192" checked=""/><div class="controls bullet"><span class="by">riffraff</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612232">parent</a><span>|</span><a href="#39613466">next</a><span>|</span><label class="collapse" for="c-39613192">[-]</label><label class="expand" for="c-39613192">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They all seem aware to some extent that these tools can occasionally generate nonsense.<p>You have too many smart people in your circle, many people are somewhat aware that &quot;chatgpt can be wrong&quot; but fail to internalize this.<p>Consider machine translation: we have a lot of evidence of people trusting machines for the job (think: &quot;translate server error&quot; signs) , even tho everybody &quot;knows&quot; the translation is unreliable.<p>But tbh moral and truth seem somewhat orthogonal issues here.</div><br/></div></div><div id="39613466" class="c"><input type="checkbox" id="c-39613466" checked=""/><div class="controls bullet"><span class="by">sausse</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612232">parent</a><span>|</span><a href="#39613192">prev</a><span>|</span><a href="#39612332">next</a><span>|</span><label class="collapse" for="c-39613466">[-]</label><label class="expand" for="c-39613466">[1 more]</label></div><br/><div class="children"><div class="content">Wikipedia is wonderful for what it is. And yet a hobby of mine is finding C-list celebrity pages and finding reference loops between tabloids and the biographical article.<p>The more the C-lister has engaged with internet wrongthink, the more egregious the subliminal vandalism is, with speculation of domestic abuse, support for unsavory political figures, or similar unfalsifiable slander being common place.<p>Politically-minded users practice this behavior because they know the platform’s air of authenticity damages their target.<p>When Google Gemini was asked “who is worse for the world, Elon Musk or Hitler” and went on to equivocate the two because the guardrails led it to believe online transphobia was as sinister as the Holocaust, it begs the question of what the average user will accept as AI nonsense if it affirms their worldview.</div><br/></div></div><div id="39612332" class="c"><input type="checkbox" id="c-39612332" checked=""/><div class="controls bullet"><span class="by">mozman</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612232">parent</a><span>|</span><a href="#39613466">prev</a><span>|</span><a href="#39613173">next</a><span>|</span><label class="collapse" for="c-39612332">[-]</label><label class="expand" for="c-39612332">[1 more]</label></div><br/><div class="children"><div class="content">&gt; not a single person I&#x27;ve talked to, from highly technical to the layperson, has ever spoken about LLMs as arbiters of morals or truth<p>Not LLMs specifically but my opinion is that companies like Alphabet absolutely abuse their platform to introduce and sway opinions on controversial topics.. this “relatively small” group of leaders has successfully weaponized their communities and built massive echo chambers.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;eyeslasho&#x2F;status&#x2F;1764784924408627548?s=46" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;eyeslasho&#x2F;status&#x2F;1764784924408627548?s=4...</a></div><br/></div></div></div></div><div id="39613173" class="c"><input type="checkbox" id="c-39613173" checked=""/><div class="controls bullet"><span class="by">pjerem</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611794">parent</a><span>|</span><a href="#39612232">prev</a><span>|</span><a href="#39612209">next</a><span>|</span><label class="collapse" for="c-39613173">[-]</label><label class="expand" for="c-39613173">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Society is approaching them as some type of universal ethical arbiter, expecting an omniscient sense of justice which is fundamentally unreconcilable even between two sentient humans when the ethics are really just a hacked on mod to the core model.<p>That’s a real issue but I doubt the solution is technical. Society will have to educate itself on this topic. It’s urgent that society understand rapidly that LLMs are just word prediction machines.<p>I use LLMs everyday, they can be useful even when they say stupid things. But mastering this tool requires that you understand it may invent things at any moment.<p>Just yesterday I tried the Cal.ai assistant which role is to manage your planning (but it don’t have access to your calendars that’s pretty limited). You communicate with it by mail. I asked him to organise a trip by train and book an hotel. It responded, « sure what is your preferred time for the train and which comfort do you want ? » I answered and it answered back that, fine, it will organise this trip and reach me back later. It even added that it will book me an hotel.<p>Well, it can’t even do that, it’s just a bot made to reorganize your cal.com meetings. So it just did nothing, of course. Nothing horrible since I know how it works.<p>But would I have been uneducated enough on the topic (like 99,99% of this planet’s population, I’d just thought « Cool, my trip is being organized, I can relax now ».<p>But hey, it succeeded at the main LLM task : being credible.</div><br/></div></div><div id="39612209" class="c"><input type="checkbox" id="c-39612209" checked=""/><div class="controls bullet"><span class="by">nonethewiser</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611794">parent</a><span>|</span><a href="#39613173">prev</a><span>|</span><a href="#39613247">next</a><span>|</span><label class="collapse" for="c-39612209">[-]</label><label class="expand" for="c-39612209">[4 more]</label></div><br/><div class="children"><div class="content">&gt; The hazard we are experiencing with LLM right now is not how freely accessible and powerfully truthy it&#x27;s content is, but it is precisely the controls upon it which are trying to be injected by the large model operators which are generating mistrust and a poor understanding of what these models are useful for.<p>This slices through a lot of double speak about AI safety. At the same time, people use “safety” to mean not letting AI control electrical grids and to ensure AIs adhere to partisan moral guidelines.<p>Virtually all of the current “safety” issues fall into the latter category. Which many don’t consider a safety issue at all. But they get snuck in with real concerns about integrating an AI too deeply into critical systems.<p>Just wait until google integrates it deeply into search. Might finally kill search.</div><br/><div id="39612537" class="c"><input type="checkbox" id="c-39612537" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612209">parent</a><span>|</span><a href="#39613247">next</a><span>|</span><label class="collapse" for="c-39612537">[-]</label><label class="expand" for="c-39612537">[3 more]</label></div><br/><div class="children"><div class="content">What are you talking bout? It’s been deeply running google search for many years.<p>And AI for electrical grids and factories has also been a thing for a couple years.</div><br/><div id="39613119" class="c"><input type="checkbox" id="c-39613119" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612537">parent</a><span>|</span><a href="#39613226">next</a><span>|</span><label class="collapse" for="c-39613119">[-]</label><label class="expand" for="c-39613119">[1 more]</label></div><br/><div class="children"><div class="content">LLMs hasn&#x27;t been deeply integrated into google search for many years. The snippets you see predates LLMs, it is based on other techniques.</div><br/></div></div><div id="39613226" class="c"><input type="checkbox" id="c-39613226" checked=""/><div class="controls bullet"><span class="by">consp</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612537">parent</a><span>|</span><a href="#39613119">prev</a><span>|</span><a href="#39613247">next</a><span>|</span><label class="collapse" for="c-39613226">[-]</label><label class="expand" for="c-39613226">[1 more]</label></div><br/><div class="children"><div class="content">What people call AI might be an algorithm but algorithms are not AI. And it&#x27;s definitely algorithms which do what you describe. There is very little magic in algorithms.</div><br/></div></div></div></div></div></div><div id="39613247" class="c"><input type="checkbox" id="c-39613247" checked=""/><div class="controls bullet"><span class="by">andrepd</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611794">parent</a><span>|</span><a href="#39612209">prev</a><span>|</span><a href="#39612110">next</a><span>|</span><label class="collapse" for="c-39613247">[-]</label><label class="expand" for="c-39613247">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Society is approaching them as some type of universal ethical arbiter, expecting an omniscient sense of justice<p>Does <i>anyone</i>, even the most stereotypical hn SV techbro, thing this kind of thing? That&#x27;s preposterous.</div><br/></div></div></div></div><div id="39611854" class="c"><input type="checkbox" id="c-39611854" checked=""/><div class="controls bullet"><span class="by">uncomputation</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39611794">prev</a><span>|</span><a href="#39612889">next</a><span>|</span><label class="collapse" for="c-39611854">[-]</label><label class="expand" for="c-39611854">[32 more]</label></div><br/><div class="children"><div class="content">&gt; they don&#x27;t refute that they did betray it<p>They do. They say:<p>&gt; Elon understood the mission did not imply open-sourcing AGI. As Ilya told Elon: “As we get closer to building AI, it will make sense to start being less open.  The Open in openAI means that everyone should benefit from the fruits of AI after its built, but it&#x27;s totally OK to not share the science...”<p>Whether you agree with this is a different matter but they do state that they did not betray their mission in their eyes.</div><br/><div id="39612246" class="c"><input type="checkbox" id="c-39612246" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611854">parent</a><span>|</span><a href="#39613007">next</a><span>|</span><label class="collapse" for="c-39612246">[-]</label><label class="expand" for="c-39612246">[4 more]</label></div><br/><div class="children"><div class="content">The benefit is the science, nothing else matters, and having OpenAI decide what matters for everyone is repugnant.<p>Of course they can give us nothing, but in that case they should start paying taxes and stop claiming they&#x27;re a public benefit org.<p>My prediction is they&#x27;ll produce little of value going forward. They&#x27;re too distracted by their wet dreams about all the cash they&#x27;re going to make to focus on the job at hand.</div><br/><div id="39613694" class="c"><input type="checkbox" id="c-39613694" checked=""/><div class="controls bullet"><span class="by">sumedh</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612246">parent</a><span>|</span><a href="#39613153">next</a><span>|</span><label class="collapse" for="c-39613694">[-]</label><label class="expand" for="c-39613694">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The benefit is the science, nothing else matters<p>Even if that science helps not so friendly countries like Russia?</div><br/></div></div><div id="39613153" class="c"><input type="checkbox" id="c-39613153" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612246">parent</a><span>|</span><a href="#39613694">prev</a><span>|</span><a href="#39613007">next</a><span>|</span><label class="collapse" for="c-39613153">[-]</label><label class="expand" for="c-39613153">[2 more]</label></div><br/><div class="children"><div class="content">I agree with your sentiment but the prediction is very silly. Basically every time openai releases something they  beat the state of the art in that area by a large margin.</div><br/><div id="39613540" class="c"><input type="checkbox" id="c-39613540" checked=""/><div class="controls bullet"><span class="by">jakupovic</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613153">parent</a><span>|</span><a href="#39613007">next</a><span>|</span><label class="collapse" for="c-39613540">[-]</label><label class="expand" for="c-39613540">[1 more]</label></div><br/><div class="children"><div class="content">We have a saying:<p>There is always someone smarter than you.<p>There is always someone stronger than you.<p>There is always someone richer than you.<p>There is always someon X than Y.<p>This is applicable to anything, just because OpenAI has a lead now it doesn&#x27;t mean they will stay X for long rather than Y.</div><br/></div></div></div></div></div></div><div id="39613007" class="c"><input type="checkbox" id="c-39613007" checked=""/><div class="controls bullet"><span class="by">mikkom</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611854">parent</a><span>|</span><a href="#39612246">prev</a><span>|</span><a href="#39612763">next</a><span>|</span><label class="collapse" for="c-39613007">[-]</label><label class="expand" for="c-39613007">[1 more]</label></div><br/><div class="children"><div class="content">They are totally closed now, not just keeping their models for themselves for profit purposes. They also don&#x27;t disclose how their new models work at all.<p>They really need to change their name and another entity that actually works for open AI should be set up.</div><br/></div></div><div id="39612763" class="c"><input type="checkbox" id="c-39612763" checked=""/><div class="controls bullet"><span class="by">usefulcat</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611854">parent</a><span>|</span><a href="#39613007">prev</a><span>|</span><a href="#39612058">next</a><span>|</span><label class="collapse" for="c-39612763">[-]</label><label class="expand" for="c-39612763">[2 more]</label></div><br/><div class="children"><div class="content">So.. &quot;open&quot; means &quot;open at first, then not so much or not at all as we get closer to achieving AGI&quot;?<p>As they become more successful, they (obviously) have a lot of motivation to not be &quot;open&quot; at all, and that&#x27;s without even considering the so-called ethical arguments.<p>More generally, putting &quot;open&quot; in any name frequently ends up as a cheap marketing gimmick. If you end up going nowhere it doesn&#x27;t matter, and if you&#x27;re wildly successful (ahem) then it also won&#x27;t matter whether or not you&#x27;re de facto &#x27;open&#x27; because success.<p>Maybe someone should start a betting pool on when (not if) they&#x27;ll change their name.</div><br/></div></div><div id="39612058" class="c"><input type="checkbox" id="c-39612058" checked=""/><div class="controls bullet"><span class="by">andsoitis</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611854">parent</a><span>|</span><a href="#39612763">prev</a><span>|</span><a href="#39612991">next</a><span>|</span><label class="collapse" for="c-39612058">[-]</label><label class="expand" for="c-39612058">[12 more]</label></div><br/><div class="children"><div class="content">&gt; everyone should benefit from the fruits of AI after its built, but it&#x27;s totally OK to not share the science...<p>everyone... except scientists and the scientific community.</div><br/><div id="39612259" class="c"><input type="checkbox" id="c-39612259" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612058">parent</a><span>|</span><a href="#39612991">next</a><span>|</span><label class="collapse" for="c-39612259">[-]</label><label class="expand" for="c-39612259">[11 more]</label></div><br/><div class="children"><div class="content">Well, the Manhattan project springs to mind. They truly thought they were laboring for the public good, and even if the government let them wouldn’t have wanted to publish their progress.<p>Personally I find the comparison of this whole saga (deepmind -&gt; google —&gt; openai —&gt; anthropic —-&gt; mistral —-&gt; ?) to the Manhattan project very enlightening, both of this project and our society. Instead of a centralized government project, we have a loosely organized mad dash of global multinationals for research talent, all of which claim the exact same “they’ll do it first!” motivations as always. And of course it’s accompanied by all sorts of media rhetoric and posturing through memes, 60-Minutes interviews, and (apparently) gossipy slap back blog posts.<p>In this scenario, Oppenheimer is clearly Hinton, who’s deep into his act III. That would mean that the real Manhattan project of AI took place in roughly 2018-2022 rather than now, which I think also makes sense; ChatGPT was the surprise breakthrough (A-bomb), and now they’re just polishing that into the more effective fully-realized forms of the technology (H-bomb, ICBMs).</div><br/><div id="39612755" class="c"><input type="checkbox" id="c-39612755" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612259">parent</a><span>|</span><a href="#39612821">next</a><span>|</span><label class="collapse" for="c-39612755">[-]</label><label class="expand" for="c-39612755">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They truly thought they were laboring for the public good<p>Nah. They knew they were working for their side against the other guys, and were honest about that.</div><br/></div></div><div id="39612821" class="c"><input type="checkbox" id="c-39612821" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612259">parent</a><span>|</span><a href="#39612755">prev</a><span>|</span><a href="#39612528">next</a><span>|</span><label class="collapse" for="c-39612821">[-]</label><label class="expand" for="c-39612821">[2 more]</label></div><br/><div class="children"><div class="content">The comparison is dumb. It wasn’t called the “open atomic bomb project”</div><br/><div id="39612929" class="c"><input type="checkbox" id="c-39612929" checked=""/><div class="controls bullet"><span class="by">crossroadsguy</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612821">parent</a><span>|</span><a href="#39612528">next</a><span>|</span><label class="collapse" for="c-39612929">[-]</label><label class="expand" for="c-39612929">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. And the OpenAI actually called it &quot;open atomic bomb project&quot;.</div><br/></div></div></div></div><div id="39612528" class="c"><input type="checkbox" id="c-39612528" checked=""/><div class="controls bullet"><span class="by">boringuser2</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612259">parent</a><span>|</span><a href="#39612821">prev</a><span>|</span><a href="#39612991">next</a><span>|</span><label class="collapse" for="c-39612528">[-]</label><label class="expand" for="c-39612528">[7 more]</label></div><br/><div class="children"><div class="content">They literally created weapons of mass destruction.<p>Do you think they thought they were good guys because you watched a Hollywood movie?</div><br/><div id="39613421" class="c"><input type="checkbox" id="c-39613421" checked=""/><div class="controls bullet"><span class="by">thinkingemote</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612528">parent</a><span>|</span><a href="#39613513">next</a><span>|</span><label class="collapse" for="c-39613421">[-]</label><label class="expand" for="c-39613421">[1 more]</label></div><br/><div class="children"><div class="content">Charitably I think most would see it as an appropriate if unexpected metaphor.</div><br/></div></div><div id="39613513" class="c"><input type="checkbox" id="c-39613513" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612528">parent</a><span>|</span><a href="#39613421">prev</a><span>|</span><a href="#39612820">next</a><span>|</span><label class="collapse" for="c-39613513">[-]</label><label class="expand" for="c-39613513">[2 more]</label></div><br/><div class="children"><div class="content">I think they thought it would be far better that America developed the bomb than Nazis Germany, and the Allies needed to do whatever it too to stop Hitler, even if that did mean using nuclear bombs.<p>Japan and the Soviet Union were more complicated issues for some of the scientists. But that&#x27;s what happens with warfare. You develop new weapons, and they aren&#x27;t just used for one enemy.</div><br/><div id="39613732" class="c"><input type="checkbox" id="c-39613732" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613513">parent</a><span>|</span><a href="#39612820">next</a><span>|</span><label class="collapse" for="c-39613732">[-]</label><label class="expand" for="c-39613732">[1 more]</label></div><br/><div class="children"><div class="content">What did Lehrer (?) sing about von Braun? &quot;I make rockets go up, where they come down is not my department&quot;.</div><br/></div></div></div></div><div id="39612820" class="c"><input type="checkbox" id="c-39612820" checked=""/><div class="controls bullet"><span class="by">Judgmentality</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612528">parent</a><span>|</span><a href="#39613513">prev</a><span>|</span><a href="#39612991">next</a><span>|</span><label class="collapse" for="c-39612820">[-]</label><label class="expand" for="c-39612820">[3 more]</label></div><br/><div class="children"><div class="content">If you really think you&#x27;re fighting evil in a war for global domination, it&#x27;s easy to justify to yourself that it&#x27;s important you have the weapons before they do.  Even if you don&#x27;t think you&#x27;re fighting evil; you&#x27;d still want to develop the weapons before your enemies so it won&#x27;t be used against you and threaten your way of life.<p>I&#x27;m not taking a stance here, but it&#x27;s easy to see why many Americans believed developing the atomic bomb was a net positive at least for Americans, and depending on how you interpret it even the world.</div><br/><div id="39613376" class="c"><input type="checkbox" id="c-39613376" checked=""/><div class="controls bullet"><span class="by">leereeves</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612820">parent</a><span>|</span><a href="#39612991">next</a><span>|</span><label class="collapse" for="c-39613376">[-]</label><label class="expand" for="c-39613376">[2 more]</label></div><br/><div class="children"><div class="content">The war against Germany was over before the bomb was finished. And it was clear long before then that Germany was not building a bomb.<p>The scientists who continued after that (not all did) must have had some other motivation at that point.</div><br/><div id="39613745" class="c"><input type="checkbox" id="c-39613745" checked=""/><div class="controls bullet"><span class="by">hef19898</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613376">parent</a><span>|</span><a href="#39612991">next</a><span>|</span><label class="collapse" for="c-39613745">[-]</label><label class="expand" for="c-39613745">[1 more]</label></div><br/><div class="children"><div class="content">I kind of understand that motivation, it is a once in a lifetime project, you are part of it, you want to finish it.<p>Morals are hard in real life, and sometimes really fuzzy.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39612991" class="c"><input type="checkbox" id="c-39612991" checked=""/><div class="controls bullet"><span class="by">smallnamespace</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611854">parent</a><span>|</span><a href="#39612058">prev</a><span>|</span><a href="#39613389">next</a><span>|</span><label class="collapse" for="c-39612991">[-]</label><label class="expand" for="c-39612991">[1 more]</label></div><br/><div class="children"><div class="content">Ilya may have said this to Elon but the public messaging of OpenAI certainly did not paint that picture.<p>I happen to think that open sourcing frontier models is a bad idea but OpenAI put themselves in the position where people thought they stood for one thing and then did something quite different. Even if you think such a move is ultimately justified, people are not usually going to trust organizations that are willing to strategically mislead.</div><br/></div></div><div id="39613389" class="c"><input type="checkbox" id="c-39613389" checked=""/><div class="controls bullet"><span class="by">thinkingemote</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611854">parent</a><span>|</span><a href="#39612991">prev</a><span>|</span><a href="#39611908">next</a><span>|</span><label class="collapse" for="c-39613389">[-]</label><label class="expand" for="c-39613389">[1 more]</label></div><br/><div class="children"><div class="content">In that case they mean that their mission to ensure everyone benefits from AI has changed to be that only a few would benefit. But it would support them saying like &quot;it was never about open data&quot;<p>In a way this could be more closed than for profit.</div><br/></div></div><div id="39611908" class="c"><input type="checkbox" id="c-39611908" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611854">parent</a><span>|</span><a href="#39613389">prev</a><span>|</span><a href="#39612458">next</a><span>|</span><label class="collapse" for="c-39611908">[-]</label><label class="expand" for="c-39611908">[7 more]</label></div><br/><div class="children"><div class="content">What they said there isn&#x27;t their mission, that is their hidden agenda. Here is their real mission that they launched with, they completely betrayed this:<p>&gt; As a non-profit, our aim is to build value for everyone rather than shareholders. Researchers will be strongly encouraged to publish their work, whether as papers, blog posts, or code, and our patents (if any) will be shared with the world<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-openai" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;introducing-openai</a></div><br/><div id="39612235" class="c"><input type="checkbox" id="c-39612235" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611908">parent</a><span>|</span><a href="#39612458">next</a><span>|</span><label class="collapse" for="c-39612235">[-]</label><label class="expand" for="c-39612235">[6 more]</label></div><br/><div class="children"><div class="content">“Dont be evil” ring any bells?</div><br/><div id="39612335" class="c"><input type="checkbox" id="c-39612335" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612235">parent</a><span>|</span><a href="#39612458">next</a><span>|</span><label class="collapse" for="c-39612335">[-]</label><label class="expand" for="c-39612335">[5 more]</label></div><br/><div class="children"><div class="content">Google is a for-profit, they never took donations with the goal of helping humanity.</div><br/><div id="39612504" class="c"><input type="checkbox" id="c-39612504" checked=""/><div class="controls bullet"><span class="by">otterley</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612335">parent</a><span>|</span><a href="#39612503">next</a><span>|</span><label class="collapse" for="c-39612504">[-]</label><label class="expand" for="c-39612504">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Don&#x27;t be evil&quot; was codified into the S-1 document Google submitted to the SEC as part of their IPO:<p><a href="https:&#x2F;&#x2F;www.sec.gov&#x2F;Archives&#x2F;edgar&#x2F;data&#x2F;1288776&#x2F;000119312504073639&#x2F;ds1.htm" rel="nofollow">https:&#x2F;&#x2F;www.sec.gov&#x2F;Archives&#x2F;edgar&#x2F;data&#x2F;1288776&#x2F;000119312504...</a><p>&quot;&quot;&quot;
DON’T BE EVIL<p>Don’t be evil. We believe strongly that in the long term, we will be better served—as shareholders and in all other ways—by a company that does good things for the world even if we forgo some short term gains. This is an important aspect of our culture and is broadly shared within the company.<p>Google users trust our systems to help them with important decisions: medical, financial and many others. Our search results are the best we know how to produce. They are unbiased and objective, and we do not accept payment for them or for inclusion or more frequent updating. We also display advertising, which we work hard to make relevant, and we label it clearly. This is similar to a newspaper, where the advertisements are clear and the articles are not influenced by the advertisers’ payments. We believe it is important for everyone to have access to the best information and research, not only to the information people pay for you to see. 
&quot;&quot;&quot;</div><br/><div id="39612719" class="c"><input type="checkbox" id="c-39612719" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612504">parent</a><span>|</span><a href="#39612503">next</a><span>|</span><label class="collapse" for="c-39612719">[-]</label><label class="expand" for="c-39612719">[1 more]</label></div><br/><div class="children"><div class="content">Yes, there they explain why doing evil will hurt their profits. But a for profits main mission is always money, the mission statement just explains how they make money. That is very different from a non-profit whose whole existence has to be described in such a statement, since they aren&#x27;t about profits.</div><br/></div></div></div></div><div id="39612937" class="c"><input type="checkbox" id="c-39612937" checked=""/><div class="controls bullet"><span class="by">richrichie</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612335">parent</a><span>|</span><a href="#39612503">prev</a><span>|</span><a href="#39612458">next</a><span>|</span><label class="collapse" for="c-39612937">[-]</label><label class="expand" for="c-39612937">[1 more]</label></div><br/><div class="children"><div class="content">They started as a defence contractor with generous “donation” from DARPA. That’s why i never trusted them from day 0. And they have followed a pretty predictable trajectory.</div><br/></div></div></div></div></div></div></div></div><div id="39612458" class="c"><input type="checkbox" id="c-39612458" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611854">parent</a><span>|</span><a href="#39611908">prev</a><span>|</span><a href="#39612441">next</a><span>|</span><label class="collapse" for="c-39612458">[-]</label><label class="expand" for="c-39612458">[1 more]</label></div><br/><div class="children"><div class="content">So, open as in &quot;we&#x27;ll sell to anyone&quot; except that at first they didn&#x27;t want to sell to the military and they still don&#x27;t sell to people deemed &quot;terrorists.&quot;  Riiiiiight.  Pure bullshit.<p>Open could mean the science, the code&#x2F;ip (which includes the science) or pure marketing drivel.  Sadly it seems that it&#x27;s the latter.</div><br/></div></div><div id="39612441" class="c"><input type="checkbox" id="c-39612441" checked=""/><div class="controls bullet"><span class="by">shrimpx</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611854">parent</a><span>|</span><a href="#39612458">prev</a><span>|</span><a href="#39611907">next</a><span>|</span><label class="collapse" for="c-39612441">[-]</label><label class="expand" for="c-39612441">[1 more]</label></div><br/><div class="children"><div class="content">“The Open in openAI means that [insert generic mission statement that applies to every business on the planet].”</div><br/></div></div></div></div><div id="39612889" class="c"><input type="checkbox" id="c-39612889" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39611854">prev</a><span>|</span><a href="#39612363">next</a><span>|</span><label class="collapse" for="c-39612889">[-]</label><label class="expand" for="c-39612889">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s convenient that OpenAI posts newsbait as they&#x27;re poised to announce new board members who will control the company.<p>And look at that, suddenly news searches are plastered with stories about this...<p><a href="https:&#x2F;&#x2F;www.google.com&#x2F;search?q=openai+board&amp;tbm=nws" rel="nofollow">https:&#x2F;&#x2F;www.google.com&#x2F;search?q=openai+board&amp;tbm=nws</a><p>Who could have possibly forseen that &#x27;openai&#x27; + &#x27;musk&#x27; + emails would chum the waters for a news cycle? Certainly not a PR firm.</div><br/></div></div><div id="39612363" class="c"><input type="checkbox" id="c-39612363" checked=""/><div class="controls bullet"><span class="by">roody15</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612889">prev</a><span>|</span><a href="#39612141">next</a><span>|</span><label class="collapse" for="c-39612363">[-]</label><label class="expand" for="c-39612363">[4 more]</label></div><br/><div class="children"><div class="content">“ To some extent, they may be right that open sourcing AGI would lead to too much danger.”<p>I would argue the opposite.  Keeping AGI behind a walled corporate garden could be the most dangerous situation imaginable.</div><br/><div id="39612506" class="c"><input type="checkbox" id="c-39612506" checked=""/><div class="controls bullet"><span class="by">afarviral</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612363">parent</a><span>|</span><a href="#39612835">next</a><span>|</span><label class="collapse" for="c-39612506">[-]</label><label class="expand" for="c-39612506">[2 more]</label></div><br/><div class="children"><div class="content">There is no clear advantage to multiple corporations or nation states each with the potential to bootstrap and control AGI vs a single corporation with a monopoly. The risk comes from the unknowable ethics of the company&#x27;s direction. Adding more entities to that equation only increases the number of unknown variables. There are bound to be similarities to gun-ownership or countries with nuclear arsenals in working through this conundrum.</div><br/><div id="39613536" class="c"><input type="checkbox" id="c-39613536" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612506">parent</a><span>|</span><a href="#39612835">next</a><span>|</span><label class="collapse" for="c-39613536">[-]</label><label class="expand" for="c-39613536">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re talking about it as if it was a weapon. An LLM is closer to an interactive book. Millennia ago humanity could only pass on information through oral traditions. Then scholars invented elaborate writing systems and information could be passed down from generation to generation, but it had to be curated and read, before that knowledge was available in the short term memory of a human. LLMs break this dependency. Now you don&#x27;t need to read the book, you can just ask the book for the parts you need.<p>The present entirely depends on books and equivalent electronic media. The future will depend on AI. So anyone who has a monopoly is going to be able to extract massive monopoly rents from its customers and be a net negative to the society instead of the positive they were supposed to be.</div><br/></div></div></div></div><div id="39612835" class="c"><input type="checkbox" id="c-39612835" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612363">parent</a><span>|</span><a href="#39612506">prev</a><span>|</span><a href="#39612141">next</a><span>|</span><label class="collapse" for="c-39612835">[-]</label><label class="expand" for="c-39612835">[1 more]</label></div><br/><div class="children"><div class="content">The state is much better at peering into walled corporate gardens than personal basements.</div><br/></div></div></div></div><div id="39612141" class="c"><input type="checkbox" id="c-39612141" checked=""/><div class="controls bullet"><span class="by">lagt_t</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612363">prev</a><span>|</span><a href="#39612665">next</a><span>|</span><label class="collapse" for="c-39612141">[-]</label><label class="expand" for="c-39612141">[13 more]</label></div><br/><div class="children"><div class="content">Everytime they say LLMs are the path to AGI, I cringe a little.</div><br/><div id="39612822" class="c"><input type="checkbox" id="c-39612822" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612141">parent</a><span>|</span><a href="#39613411">next</a><span>|</span><label class="collapse" for="c-39612822">[-]</label><label class="expand" for="c-39612822">[7 more]</label></div><br/><div class="children"><div class="content">1. AGI needs an interface to be useful.<p>2. Natural language is both a good and expected interface to AGI.<p>3. LLMs do a really good job at interfacing with natural language.<p>Which one(s) do you disagree with?</div><br/><div id="39613045" class="c"><input type="checkbox" id="c-39613045" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612822">parent</a><span>|</span><a href="#39613172">next</a><span>|</span><label class="collapse" for="c-39613045">[-]</label><label class="expand" for="c-39613045">[5 more]</label></div><br/><div class="children"><div class="content">I think he disagrees with 4:<p>4. Language prediction training will not get stuck in a local optimum.<p>Most previous things we train on could have been better served if the model developed AGI, but they didn&#x27;t. There is no reason to expect LLMs to not get stuck in a local optimum as well, and I have seen no good argument as to why they wouldn&#x27;t get stuck like everything else we tried.</div><br/><div id="39613111" class="c"><input type="checkbox" id="c-39613111" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613045">parent</a><span>|</span><a href="#39613228">next</a><span>|</span><label class="collapse" for="c-39613111">[-]</label><label class="expand" for="c-39613111">[3 more]</label></div><br/><div class="children"><div class="content">There is very little in terms of rigorous mathematics on the theoretical side of this. All we have are empirics, but everything we have seen so far points to the fact that more compute equals more capabilities. That&#x27;s what they are referring to in the blog post. This is particularly true for the current generation of models, but if you look at the whole history of modern computing, the law roughly holds up over the last century. Following this trend, we can extrapolate that we will reach computers with raw compute power similar to the human brain for under $1000 within the next two decades.</div><br/><div id="39613488" class="c"><input type="checkbox" id="c-39613488" checked=""/><div class="controls bullet"><span class="by">leereeves</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613111">parent</a><span>|</span><a href="#39613228">next</a><span>|</span><label class="collapse" for="c-39613488">[-]</label><label class="expand" for="c-39613488">[2 more]</label></div><br/><div class="children"><div class="content">More compute also requires more data - scaling equally with model size, according to the Chinchilla paper.<p>How much more data is available that hasn&#x27;t already been swept up by AI companies?<p>And will that data continue to be available as laws change to protect copyright holders from AI companies?</div><br/><div id="39613595" class="c"><input type="checkbox" id="c-39613595" checked=""/><div class="controls bullet"><span class="by">sigmoid10</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613488">parent</a><span>|</span><a href="#39613228">next</a><span>|</span><label class="collapse" for="c-39613595">[-]</label><label class="expand" for="c-39613595">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just the volume of original data that matters here. From empirics we know performance scales roughly like (model parameters)*(training data)*(epochs). If you increase any one of those, you can be certain to improve your model. In the short term, training data volume and quality has given a lot of improvements (especially recently), but in the long run it was always model size and total time spent training that saw improvements. In other words: It doesn&#x27;t matter how you allocate your extra compute budget as long as you spend it.</div><br/></div></div></div></div></div></div></div></div><div id="39613172" class="c"><input type="checkbox" id="c-39613172" checked=""/><div class="controls bullet"><span class="by">BriggyDwiggs42</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612822">parent</a><span>|</span><a href="#39613045">prev</a><span>|</span><a href="#39613411">next</a><span>|</span><label class="collapse" for="c-39613172">[-]</label><label class="expand" for="c-39613172">[1 more]</label></div><br/><div class="children"><div class="content">The underlying premise that llms are capable of fully generalizing to a human level across most domains, i assume?</div><br/></div></div></div></div><div id="39613411" class="c"><input type="checkbox" id="c-39613411" checked=""/><div class="controls bullet"><span class="by">MrScruff</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612141">parent</a><span>|</span><a href="#39612822">prev</a><span>|</span><a href="#39612421">next</a><span>|</span><label class="collapse" for="c-39613411">[-]</label><label class="expand" for="c-39613411">[2 more]</label></div><br/><div class="children"><div class="content">I don’t know if they are or not, but I’m not sure how anyone could be so certain that they’re not that they find the mere idea cringeworthy. Unless you feel you have some specific perspective on it that’s escaped their army of researchers?</div><br/><div id="39613538" class="c"><input type="checkbox" id="c-39613538" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613411">parent</a><span>|</span><a href="#39612421">next</a><span>|</span><label class="collapse" for="c-39613538">[-]</label><label class="expand" for="c-39613538">[1 more]</label></div><br/><div class="children"><div class="content">Because AI researchers have been on the path to AGI several times before until the hype died down and the limitations became apparent. And because nobody knows what it would take to create AGI. But to put a little more behind that, evolution didn&#x27;t start with language models. It evolved everything else until humans had the ability to invent language. Current AI is going about it completely backwards from how biology did it. Now maybe robotics is doing a little better on that front.</div><br/></div></div></div></div><div id="39612421" class="c"><input type="checkbox" id="c-39612421" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612141">parent</a><span>|</span><a href="#39613411">prev</a><span>|</span><a href="#39612415">next</a><span>|</span><label class="collapse" for="c-39612421">[-]</label><label class="expand" for="c-39612421">[1 more]</label></div><br/><div class="children"><div class="content">I mean, if you&#x27;re using LLM as a stand-in for multi-modal models, and you&#x27;re not disallowing things like a self-referential processing loop, a memory extraction process, etc, it&#x27;s not so far fetched.  There might be multiple databases and a score of worker processes running in the background, but the core will come from a sequence model being run in a loop.</div><br/></div></div><div id="39612415" class="c"><input type="checkbox" id="c-39612415" checked=""/><div class="controls bullet"><span class="by">travbrack</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612141">parent</a><span>|</span><a href="#39612421">prev</a><span>|</span><a href="#39612252">next</a><span>|</span><label class="collapse" for="c-39612415">[-]</label><label class="expand" for="c-39612415">[1 more]</label></div><br/><div class="children"><div class="content">how come?</div><br/></div></div><div id="39612252" class="c"><input type="checkbox" id="c-39612252" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612141">parent</a><span>|</span><a href="#39612415">prev</a><span>|</span><a href="#39612665">next</a><span>|</span><label class="collapse" for="c-39612252">[-]</label><label class="expand" for="c-39612252">[1 more]</label></div><br/><div class="children"><div class="content">I just snicker.</div><br/></div></div></div></div><div id="39612665" class="c"><input type="checkbox" id="c-39612665" checked=""/><div class="controls bullet"><span class="by">eightnoteight</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612141">prev</a><span>|</span><a href="#39613494">next</a><span>|</span><label class="collapse" for="c-39612665">[-]</label><label class="expand" for="c-39612665">[4 more]</label></div><br/><div class="children"><div class="content">&gt; here they explain why they had to betray their core mission. But they don&#x27;t refute that they did betray it.<p>you are assuming that their core mission is to &quot;Build an AGI that can help humanity for free and as a non-profit&quot;, the way their thinking seems to be is &quot;Build an AGI that can help humanity for free&quot;<p>they figured it was impossible to achieve their core mission by doing it in a non-profit way, so they went with the for-profit route but still stayed with the mission to offer it for free once the AGI is achieved<p>Several non-profits sell products to further increase their non-profit scale, would it be okay for OpenAI non-profits to sell products that came in the process of developing AGI so that they can keep working on building their AGI? museums sell stuff to continue to exist so that they can continue to build on their mission, same for many other non-profits. the OpenAI structure just seems to take a rather new version of that approach by getting venture capital (due to their capital requirements)</div><br/><div id="39612723" class="c"><input type="checkbox" id="c-39612723" checked=""/><div class="controls bullet"><span class="by">drcode</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612665">parent</a><span>|</span><a href="#39613033">next</a><span>|</span><label class="collapse" for="c-39612723">[-]</label><label class="expand" for="c-39612723">[2 more]</label></div><br/><div class="children"><div class="content">The problem of course is that they frequently go back on their promises (see they changes in their usage guidelines regarding military projects) so excuse me if I don&#x27;t believe them when they say they&#x27;ll voluntarily give away their AGI tech for the greater good of humanity</div><br/><div id="39612851" class="c"><input type="checkbox" id="c-39612851" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612723">parent</a><span>|</span><a href="#39613033">next</a><span>|</span><label class="collapse" for="c-39612851">[-]</label><label class="expand" for="c-39612851">[1 more]</label></div><br/><div class="children"><div class="content">Wholeheartedly agreed.<p>The easiest way to cut through corporate BS is to find distinguishing characteristics of the contrary motivation. In this case:<p><i>OpenAI says:</i> To deliver AI for the good of all humanity, it needs the resources to compete with hyperscale competitors, so it needs to sell extremely profitable services.<p><i>Contrary motivation:</i> OpenAI wants to sell extremely profitable services to make money, and it wants to control cutting edge AI to make even more money.<p>What distinguishing characteristics exist between the two motivations?<p>Because from where I&#x27;m sitting, it&#x27;s a coin flip as to which one is more likely.<p>Add in the facts that (a) there&#x27;s a lot of money on the table &amp; (b) Sam Altman has a demonstrated propensity for throwing people under the bus when there&#x27;s profit in it for himself, and I don&#x27;t feel comfortable betting on OpenAI&#x27;s altruism.<p>PS: Also, when did it become acceptable for a <i>professional fucking company</i> to publicly post emails in response to a lawsuit? That&#x27;s trashy and smacks of response plan set up and ready to go.</div><br/></div></div></div></div><div id="39613033" class="c"><input type="checkbox" id="c-39613033" checked=""/><div class="controls bullet"><span class="by">mikkom</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612665">parent</a><span>|</span><a href="#39612723">prev</a><span>|</span><a href="#39613494">next</a><span>|</span><label class="collapse" for="c-39613033">[-]</label><label class="expand" for="c-39613033">[1 more]</label></div><br/><div class="children"><div class="content">&gt; still stayed with the mission to offer it for free once the AGI is achieved<p>And based on how they have acted in the past, how much do you trust they will act as they now say when&#x2F;if they achieve AGI?</div><br/></div></div></div></div><div id="39613494" class="c"><input type="checkbox" id="c-39613494" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612665">prev</a><span>|</span><a href="#39612616">next</a><span>|</span><label class="collapse" for="c-39613494">[-]</label><label class="expand" for="c-39613494">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They&#x27;re probably right that building AGI will require a ton of computational power, and that it will be very expensive.<p>Is that still true? LLMs seem to be getting smaller and cheaper for the same level of performance.</div><br/></div></div><div id="39612616" class="c"><input type="checkbox" id="c-39612616" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39613494">prev</a><span>|</span><a href="#39612709">next</a><span>|</span><label class="collapse" for="c-39612616">[-]</label><label class="expand" for="c-39612616">[4 more]</label></div><br/><div class="children"><div class="content">&gt; To some extent, they may be right that open sourcing AGI would lead to too much danger.<p>They claimed that about GPT-2 and used the claim to delay its release.</div><br/><div id="39612856" class="c"><input type="checkbox" id="c-39612856" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612616">parent</a><span>|</span><a href="#39612709">next</a><span>|</span><label class="collapse" for="c-39612856">[-]</label><label class="expand" for="c-39612856">[3 more]</label></div><br/><div class="children"><div class="content">They claimed that GPT-2 was probably not dangerous but they wanted to establish a culture of delaying possibly-dangerous releases early. Which, good on them!</div><br/><div id="39613083" class="c"><input type="checkbox" id="c-39613083" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612856">parent</a><span>|</span><a href="#39612709">next</a><span>|</span><label class="collapse" for="c-39613083">[-]</label><label class="expand" for="c-39613083">[2 more]</label></div><br/><div class="children"><div class="content">Do you really think it is a coincidence that they started closing down around the time they went for-profit?</div><br/><div id="39613217" class="c"><input type="checkbox" id="c-39613217" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39613083">parent</a><span>|</span><a href="#39612709">next</a><span>|</span><label class="collapse" for="c-39613217">[-]</label><label class="expand" for="c-39613217">[1 more]</label></div><br/><div class="children"><div class="content">No, I think they started closing down and going for profit at the time they realized that GPT was going to be <i>useful.</i> Which sounds bad, but at the limit, useful and dangerous are the same continuum. As the kids say, OpenAI got &quot;scale-pilled;&quot; they realized that as they dumped more compute and more data onto those things, the network would just pick up more and discontinuous capabilities &quot;on its own.&quot;<p>&lt;aisafety&gt;That is the one thing we didn&#x27;t want to happen.&lt;&#x2F;aisafety&gt;<p>It&#x27;s one thing to mess around with Starcraft or DotA and wow the gaming world, it&#x27;s quite another to be riding the escalator to the eschaton.</div><br/></div></div></div></div></div></div></div></div><div id="39612709" class="c"><input type="checkbox" id="c-39612709" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612616">prev</a><span>|</span><a href="#39613372">next</a><span>|</span><label class="collapse" for="c-39612709">[-]</label><label class="expand" for="c-39612709">[7 more]</label></div><br/><div class="children"><div class="content">&gt; They&#x27;re probably right that building AGI will require a ton of computational power, and that it will be very expensive.<p>Why? This makes it seem like computers are way less efficient than humans. Maybe I&#x27;m naive on the matter, but I think it&#x27;s possible for computers to match or surpass human efficiency.</div><br/><div id="39612816" class="c"><input type="checkbox" id="c-39612816" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612709">parent</a><span>|</span><a href="#39613099">next</a><span>|</span><label class="collapse" for="c-39612816">[-]</label><label class="expand" for="c-39612816">[1 more]</label></div><br/><div class="children"><div class="content">Computers are still way less efficient than humans, a human brain has less power draw than a laptop and do some immense calculations to parse vision, hearing etc better than any known algorithm constantly.<p>And the part of the human brain that governs our human intelligence and not just what animals do is much larger than, so unless we figure out a better algorithm than evolution did for intelligence it will require a massive amount of compute.<p>The brain isn&#x27;t fast, but it is ridiculously parallel with every cell being its own core so total throughput is immense.</div><br/></div></div><div id="39613099" class="c"><input type="checkbox" id="c-39613099" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612709">parent</a><span>|</span><a href="#39612816">prev</a><span>|</span><a href="#39613753">next</a><span>|</span><label class="collapse" for="c-39613099">[-]</label><label class="expand" for="c-39613099">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps the finalized AGI will be more efficient than a human brain. But training the AGI is not like running a human, it&#x27;s like speed running evolution from cells to humans. The natural world stumbled on NGI in a few billion years. We are trying to do it in decades - it would not be surprising that it&#x27;s going to take huge power.</div><br/></div></div><div id="39613753" class="c"><input type="checkbox" id="c-39613753" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612709">parent</a><span>|</span><a href="#39613099">prev</a><span>|</span><a href="#39612854">next</a><span>|</span><label class="collapse" for="c-39613753">[-]</label><label class="expand" for="c-39613753">[1 more]</label></div><br/><div class="children"><div class="content">Scaling laws. Maybe they will figure out a new paradigm, but in the age of Transformers we are stuck with scaling laws.</div><br/></div></div><div id="39612854" class="c"><input type="checkbox" id="c-39612854" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612709">parent</a><span>|</span><a href="#39613753">prev</a><span>|</span><a href="#39613372">next</a><span>|</span><label class="collapse" for="c-39612854">[-]</label><label class="expand" for="c-39612854">[3 more]</label></div><br/><div class="children"><div class="content">Computers are more efficient, dense and powerful than humans. But due to self-assembly, brains consist of many(!) orders of magnitude more volume. A human brain is more accurately compared with a data center than a chip.</div><br/><div id="39612879" class="c"><input type="checkbox" id="c-39612879" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612854">parent</a><span>|</span><a href="#39613372">next</a><span>|</span><label class="collapse" for="c-39612879">[-]</label><label class="expand" for="c-39612879">[2 more]</label></div><br/><div class="children"><div class="content">&gt; A human brain is more accurately compared with a data center than a chip.<p>A typical chip requires more power than a human brain, so I&#x27;d say they are comparable. Efficiency isn&#x27;t per volume but per power or per heat production. Human brains wins those two by far.</div><br/><div id="39613263" class="c"><input type="checkbox" id="c-39613263" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612879">parent</a><span>|</span><a href="#39613372">next</a><span>|</span><label class="collapse" for="c-39613263">[-]</label><label class="expand" for="c-39613263">[1 more]</label></div><br/><div class="children"><div class="content">To be fair, we&#x27;ve locked ourselves into this to some extent with the focus on lithography and general processors. Because of the 10-1000W bounds of a consumer power supply, there&#x27;s little point to building a chip that falls outside this range. Peak speed sells, power saving doesn&#x27;t. Data center processors tend to be clocked a bit lower than desktops for just this reason - but not too much lower, because they share a software ecosystem. <i>Could</i> we build chips that draw microwatts and run at megahertz speeds? Sure, probably, but they wouldn&#x27;t be very useful to the things that people actually do with chips. So imo the difficulty with matching the brain on efficiency isn&#x27;t so much that we can&#x27;t do it as that nobody wants it. (Yet!)<p>edit: Another major contributing factor is that so far, chips are more bottlenecked on production than operation. Almost any female human can produce more humans using onboard technology. Comparatively, first-rate chips can be made in like three buildings in the entire world and they each cost billions to equip. If we wanted to build a brain with photolithography, we&#x27;d need to rent out TSMC for a lot longer than nine months. That results in a much bigger focus on peak performance. We have to go &quot;high&quot; because we cannot practically go &quot;wide&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="39613372" class="c"><input type="checkbox" id="c-39613372" checked=""/><div class="controls bullet"><span class="by">animex</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612709">prev</a><span>|</span><a href="#39612222">next</a><span>|</span><label class="collapse" for="c-39613372">[-]</label><label class="expand" for="c-39613372">[1 more]</label></div><br/><div class="children"><div class="content">by &quot;betray&quot;, you mean they pivoted?</div><br/></div></div><div id="39612222" class="c"><input type="checkbox" id="c-39612222" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39613372">prev</a><span>|</span><a href="#39612304">next</a><span>|</span><label class="collapse" for="c-39612222">[-]</label><label class="expand" for="c-39612222">[1 more]</label></div><br/><div class="children"><div class="content">Great analysis, thanks for taking the time.<p><pre><code>  here they explain why they had to betray their core mission. But they don&#x27;t refute that they did betray it.
</code></pre>
Although they don’t spend nearly as much time on it, probably because it’s an entirely intuitive argument without any evidence, is that they could be “open” as in “for the public good” while still making closed models for profit. Aka the ends justify the means.<p>It’s a shame lawyers seem to think that the lawsuit is a badly argued joke, because I really don’t find that line of reasoning convincing…</div><br/></div></div><div id="39612304" class="c"><input type="checkbox" id="c-39612304" checked=""/><div class="controls bullet"><span class="by">lern_too_spel</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612222">prev</a><span>|</span><a href="#39611677">next</a><span>|</span><label class="collapse" for="c-39612304">[-]</label><label class="expand" for="c-39612304">[1 more]</label></div><br/><div class="children"><div class="content">The evidence they presented shows that Elon was in complete agreement with the direction of OpenAI. The only thing he disagreed with was who would be the majority owner of the resulting for-profit company that hides research in the short to medium term.</div><br/></div></div><div id="39611677" class="c"><input type="checkbox" id="c-39611677" checked=""/><div class="controls bullet"><span class="by">idatum</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612304">prev</a><span>|</span><a href="#39612833">next</a><span>|</span><label class="collapse" for="c-39611677">[-]</label><label class="expand" for="c-39611677">[2 more]</label></div><br/><div class="children"><div class="content">&gt; We realized building AGI will require far more resources than we’d initially imagined<p>So the AGI existential threat to humanity has diminished?</div><br/><div id="39612136" class="c"><input type="checkbox" id="c-39612136" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611677">parent</a><span>|</span><a href="#39612833">next</a><span>|</span><label class="collapse" for="c-39612136">[-]</label><label class="expand" for="c-39612136">[1 more]</label></div><br/><div class="children"><div class="content">Not if their near-term funding rounds go through. So much for &quot;compute overhang&quot;.</div><br/></div></div></div></div><div id="39612833" class="c"><input type="checkbox" id="c-39612833" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39611677">prev</a><span>|</span><a href="#39611712">next</a><span>|</span><label class="collapse" for="c-39612833">[-]</label><label class="expand" for="c-39612833">[1 more]</label></div><br/><div class="children"><div class="content">If the core mission is to advance and help humanity, then they determine by changing it to profit and making it closed will help that mission, then it is a valid decision</div><br/></div></div><div id="39611712" class="c"><input type="checkbox" id="c-39611712" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612833">prev</a><span>|</span><a href="#39612728">next</a><span>|</span><label class="collapse" for="c-39611712">[-]</label><label class="expand" for="c-39611712">[3 more]</label></div><br/><div class="children"><div class="content">I guess Mozilla as well then.</div><br/><div id="39612429" class="c"><input type="checkbox" id="c-39612429" checked=""/><div class="controls bullet"><span class="by">TheCapeGreek</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39611712">parent</a><span>|</span><a href="#39612728">next</a><span>|</span><label class="collapse" for="c-39612429">[-]</label><label class="expand" for="c-39612429">[2 more]</label></div><br/><div class="children"><div class="content">Well yeah, dive into the comments on any Firefox-related HN post and you&#x27;ll see the same complaint about the organization structure of Mozilla, and its hindrance of Firefox&#x27;s progress in favour of fat CEO salaries and side products few people want.</div><br/><div id="39612571" class="c"><input type="checkbox" id="c-39612571" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612429">parent</a><span>|</span><a href="#39612728">next</a><span>|</span><label class="collapse" for="c-39612571">[-]</label><label class="expand" for="c-39612571">[1 more]</label></div><br/><div class="children"><div class="content">You might find me there. ;)<p>But, my God, the some of the nonprofit ceos I’ve known make the for-profit ceos look pathetic and cheap.</div><br/></div></div></div></div></div></div><div id="39612728" class="c"><input type="checkbox" id="c-39612728" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39611712">prev</a><span>|</span><a href="#39611935">next</a><span>|</span><label class="collapse" for="c-39612728">[-]</label><label class="expand" for="c-39612728">[1 more]</label></div><br/><div class="children"><div class="content">&gt; they still have the appearance of abandoning their core mission to focus more on profits<p>If donors are unwilling to continue making sustained donations, they would have died. They only did what they needed to to stay alive.</div><br/></div></div><div id="39611935" class="c"><input type="checkbox" id="c-39611935" checked=""/><div class="controls bullet"><span class="by">BoiledCabbage</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612728">prev</a><span>|</span><a href="#39611834">next</a><span>|</span><label class="collapse" for="c-39611935">[-]</label><label class="expand" for="c-39611935">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  ... and returning the donations they took from these wealthy tech founders, they used the benevolent appearance of their non-profit status and their name to mislead everyone about their intentions.<p>I can&#x27;t tell if your comment is intentionally misleading or just entirely missing the point.  The entire post states that Elon musk was well aware and onboard with their intentions. Tried to take over OpenAI and roll it into his private company to control. And finally agreed specifically that they need to continue to become less open over time.<p>And your post is to play Elon out to be a victim who didn&#x27;t realize any of this?
He&#x27;s replying to emails saying he&#x27;s agreeing. It&#x27;s hard to understand why you posted something so contradictory above pretending he wasn&#x27;t.</div><br/></div></div><div id="39611834" class="c"><input type="checkbox" id="c-39611834" checked=""/><div class="controls bullet"><span class="by">Cacti</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39611935">prev</a><span>|</span><a href="#39612193">next</a><span>|</span><label class="collapse" for="c-39611834">[-]</label><label class="expand" for="c-39611834">[1 more]</label></div><br/><div class="children"><div class="content">Their early decision to not open source their models was the most obvious sign of their intentions.<p>Too dangerous? Seriously? Who the fuck did&#x2F;do they think they are? Jesus?<p>Sam Altman is going to sit there in his infinite wisdom and be the arbiter of what humanity is mature enough to handle?<p>The amount of kool aid that is being happily drank at openai is astounding. It’s like crypto scams but everyone has a PhD.</div><br/></div></div><div id="39612193" class="c"><input type="checkbox" id="c-39612193" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39611834">prev</a><span>|</span><a href="#39612611">next</a><span>|</span><label class="collapse" for="c-39612193">[-]</label><label class="expand" for="c-39612193">[10 more]</label></div><br/><div class="children"><div class="content">&gt; To some extent, they may be right that open sourcing AGI would lead to too much danger.<p>That&#x27;s clearly self-serving claptrap. It&#x27;s a leveraging of a false depiction of what AGI will look like (no ones really knows, but it&#x27;s going to be scary and out of control!) with so much gatekeeping and subsequent cash they can hardly stop salivating.<p>No strong AI (there is no evidence AGI is even possible) is not going to be a menace. It&#x27;s software FFS. Humans are and will be a menace though and logically the only way to protect ourselves from bad people (and corporations) with strong AI is to make strong AI available to everyone. Computers are pretty powerful (and evil) right now but we haven&#x27;t banned them yet.</div><br/><div id="39612641" class="c"><input type="checkbox" id="c-39612641" checked=""/><div class="controls bullet"><span class="by">mitthrowaway2</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612193">parent</a><span>|</span><a href="#39612565">next</a><span>|</span><label class="collapse" for="c-39612641">[-]</label><label class="expand" for="c-39612641">[2 more]</label></div><br/><div class="children"><div class="content">&gt; there is no evidence AGI is even possible<p>Reading this is like hearing &quot;there is no evidence that heavier-than-air flight is even possible&quot; being spoken, <i>by a bird</i>. If 8 billion naturally-occuring intelligences don&#x27;t qualify as evidence that AGI is possible, then is there <i>anything</i> that can qualify as evidence of <i>anything else</i> being possible?</div><br/><div id="39613092" class="c"><input type="checkbox" id="c-39613092" checked=""/><div class="controls bullet"><span class="by">stonogo</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612641">parent</a><span>|</span><a href="#39612565">next</a><span>|</span><label class="collapse" for="c-39613092">[-]</label><label class="expand" for="c-39613092">[1 more]</label></div><br/><div class="children"><div class="content">we also cannot build most birds</div><br/></div></div></div></div><div id="39612565" class="c"><input type="checkbox" id="c-39612565" checked=""/><div class="controls bullet"><span class="by">afarviral</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612193">parent</a><span>|</span><a href="#39612641">prev</a><span>|</span><a href="#39612971">next</a><span>|</span><label class="collapse" for="c-39612565">[-]</label><label class="expand" for="c-39612565">[5 more]</label></div><br/><div class="children"><div class="content">That makes little intuitive sense to me. Help me understand why increasing the number of entities which possess a potential-weapon is beneficial for humanity?<p>If the US had developed a nuclear armament and no other country had would that truly have been worse? What if Russia had beat the world to it first? Maybe I&#x27;ll get there on my own if I keep following this reasoning. However there is nothing clear cut about it, my strongest instincts are only heuristics I&#x27;ve absorbed from somewhere.<p>What we probably want with any sufficiently destructive potential-weapon are the most responsible actors to share their research while stimulating research in the field with a strong focus on safety and safeguarding. I see some evidence of that.</div><br/><div id="39612757" class="c"><input type="checkbox" id="c-39612757" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612565">parent</a><span>|</span><a href="#39612751">next</a><span>|</span><label class="collapse" for="c-39612757">[-]</label><label class="expand" for="c-39612757">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If the US had developed a nuclear armament and no other country had would that truly have been worse?<p>Yes, do you think it is a coincidence that nuclear weapons stopped being used in wars as soon as more than one power had them? People would clamor for nukes to be used to save their young soldiers lives if they didn&#x27;t have to fear nuclear retaliation, you would see strong political pushes for nuclear usage in everyone of USA&#x27;s wars.</div><br/><div id="39613008" class="c"><input type="checkbox" id="c-39613008" checked=""/><div class="controls bullet"><span class="by">afarviral</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612757">parent</a><span>|</span><a href="#39612751">next</a><span>|</span><label class="collapse" for="c-39613008">[-]</label><label class="expand" for="c-39613008">[1 more]</label></div><br/><div class="children"><div class="content">Hmm, indeed</div><br/></div></div></div></div><div id="39612751" class="c"><input type="checkbox" id="c-39612751" checked=""/><div class="controls bullet"><span class="by">cortesoft</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612565">parent</a><span>|</span><a href="#39612757">prev</a><span>|</span><a href="#39612971">next</a><span>|</span><label class="collapse" for="c-39612751">[-]</label><label class="expand" for="c-39612751">[2 more]</label></div><br/><div class="children"><div class="content">Lots of people disagree on whether it is true or not, but basically the idea is mutually assured destruction<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mutual_assured_destruction" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mutual_assured_destruction</a></div><br/><div id="39613022" class="c"><input type="checkbox" id="c-39613022" checked=""/><div class="controls bullet"><span class="by">afarviral</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612751">parent</a><span>|</span><a href="#39612971">next</a><span>|</span><label class="collapse" for="c-39613022">[-]</label><label class="expand" for="c-39613022">[1 more]</label></div><br/><div class="children"><div class="content">I sense that with AGI all the outcomes will be a little less assured, since it is general-purpose. We won&#x27;t know what hit until it&#x27;s over. Was it a pandemic? Was it automated-religion? Nuclear weapons seem particularly suited to MAD, but not AGI.</div><br/></div></div></div></div></div></div><div id="39612971" class="c"><input type="checkbox" id="c-39612971" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612193">parent</a><span>|</span><a href="#39612565">prev</a><span>|</span><a href="#39612654">next</a><span>|</span><label class="collapse" for="c-39612971">[-]</label><label class="expand" for="c-39612971">[1 more]</label></div><br/><div class="children"><div class="content">Networking is a thing, so the software can remotely control hardware.</div><br/></div></div><div id="39612654" class="c"><input type="checkbox" id="c-39612654" checked=""/><div class="controls bullet"><span class="by">insane_dreamer</span><span>|</span><a href="#39611634">root</a><span>|</span><a href="#39612193">parent</a><span>|</span><a href="#39612971">prev</a><span>|</span><a href="#39612611">next</a><span>|</span><label class="collapse" for="c-39612654">[-]</label><label class="expand" for="c-39612654">[1 more]</label></div><br/><div class="children"><div class="content">&gt; No strong AI (there is no evidence AGI is even possible) is not going to be a menace. It&#x27;s software FFS.<p>have you even watched Terminator? ;)</div><br/></div></div></div></div><div id="39612611" class="c"><input type="checkbox" id="c-39612611" checked=""/><div class="controls bullet"><span class="by">billiam</span><span>|</span><a href="#39611634">parent</a><span>|</span><a href="#39612193">prev</a><span>|</span><a href="#39611606">next</a><span>|</span><label class="collapse" for="c-39612611">[-]</label><label class="expand" for="c-39612611">[1 more]</label></div><br/><div class="children"><div class="content">As the emails make clear, Musk reveals that his real goal is to use OpenAI to accelerate full self driving of Tesla Model 3 and other models. He keeps on putting up Google as a boogeyman who will swamp them, but he provides no real evidence of spending level or progress toward AGI, he just bloviates. I am totally suspicious of Altman in particular, but Musk is just the worst.</div><br/></div></div></div></div><div id="39611606" class="c"><input type="checkbox" id="c-39611606" checked=""/><div class="controls bullet"><span class="by">magnio</span><span>|</span><a href="#39611634">prev</a><span>|</span><a href="#39611650">next</a><span>|</span><label class="collapse" for="c-39611606">[-]</label><label class="expand" for="c-39611606">[44 more]</label></div><br/><div class="children"><div class="content">&gt; Elon understood the mission did not imply open-sourcing AGI. As Ilya told Elon: “As we get closer to building AI, it will make sense to start being less open.  The Open in openAI means that everyone should benefit from the fruits of AI after its built, but it&#x27;s totally OK to not share the science...”, to which Elon replied: “Yup”.<p>Wow the most open OpenAI has ever been is when someone sue them.<p>On the other hand, this shows Elon doesn&#x27;t care jackshit about the lack of openness from OpenAI. He&#x27;s just mad only that he walked away from a monumental success.</div><br/><div id="39612151" class="c"><input type="checkbox" id="c-39612151" checked=""/><div class="controls bullet"><span class="by">carlossouza</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39611881">next</a><span>|</span><label class="collapse" for="c-39612151">[-]</label><label class="expand" for="c-39612151">[4 more]</label></div><br/><div class="children"><div class="content">&gt; The Open in openAI means that everyone should benefit from the fruits of AI after its built, but it&#x27;s totally OK to not share the science...<p>Based on this line of reasoning, ANY company that builds any given technology and intends to share (sell) it to the world, but not divulge how it was done, can call itself OpenWhatever.<p>They are clearly saying that the word “Open” in their name means nothing.</div><br/><div id="39613689" class="c"><input type="checkbox" id="c-39613689" checked=""/><div class="controls bullet"><span class="by">jrflowers</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612151">parent</a><span>|</span><a href="#39612444">next</a><span>|</span><label class="collapse" for="c-39613689">[-]</label><label class="expand" for="c-39613689">[1 more]</label></div><br/><div class="children"><div class="content">&gt; They are clearly saying that the word “Open” in their name means nothing.<p>Similarly <i>Micro</i>soft makes incredibly large software and my letters about this have gone unanswered</div><br/></div></div><div id="39612444" class="c"><input type="checkbox" id="c-39612444" checked=""/><div class="controls bullet"><span class="by">Centigonal</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612151">parent</a><span>|</span><a href="#39613689">prev</a><span>|</span><a href="#39611881">next</a><span>|</span><label class="collapse" for="c-39612444">[-]</label><label class="expand" for="c-39612444">[2 more]</label></div><br/><div class="children"><div class="content">The online versions of Microsoft office apps are free. What if they renamed those to... OpenOffice?</div><br/><div id="39613483" class="c"><input type="checkbox" id="c-39613483" checked=""/><div class="controls bullet"><span class="by">kamaal</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612444">parent</a><span>|</span><a href="#39611881">next</a><span>|</span><label class="collapse" for="c-39613483">[-]</label><label class="expand" for="c-39613483">[1 more]</label></div><br/><div class="children"><div class="content">I laughed out real loud after reading this xD<p>But really there is so much money in this, and if they can make it they are going to be the next Google.<p>It should be obvious they don&#x27;t want to be &#x27;open&#x27; in terms of really making this open source.</div><br/></div></div></div></div></div></div><div id="39611881" class="c"><input type="checkbox" id="c-39611881" checked=""/><div class="controls bullet"><span class="by">devsda</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39612151">prev</a><span>|</span><a href="#39612097">next</a><span>|</span><label class="collapse" for="c-39611881">[-]</label><label class="expand" for="c-39611881">[7 more]</label></div><br/><div class="children"><div class="content">&gt;  The Open in openAI means that everyone should benefit from the fruits of AI after its built.(even though sharing everything is definitely the right strategy in the short and possibly medium term for recruitment purposes).<p>&quot;OpenSource&quot;. Open in open source means everyone should benefit from the fruits of source after it is built but it&#x27;s totally OK to not share the source(Even though calling ourselves open is the right strategy for medium term recruitment and adoption purposes).<p>If anyone tries the same logic with &quot;open&quot; source, they will be ridiculed and laughed at, but here we are.</div><br/><div id="39612012" class="c"><input type="checkbox" id="c-39612012" checked=""/><div class="controls bullet"><span class="by">repler</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39611881">parent</a><span>|</span><a href="#39612097">next</a><span>|</span><label class="collapse" for="c-39612012">[-]</label><label class="expand" for="c-39612012">[6 more]</label></div><br/><div class="children"><div class="content">isn’t this the old: free as in speech, not as in beer</div><br/><div id="39612109" class="c"><input type="checkbox" id="c-39612109" checked=""/><div class="controls bullet"><span class="by">devsda</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612012">parent</a><span>|</span><a href="#39612038">next</a><span>|</span><label class="collapse" for="c-39612109">[-]</label><label class="expand" for="c-39612109">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Free as in beer&quot; : I doubt anybody is expecting OpenAI to give away their work for free or give free credits&#x2F;tokens forever. Even when they do, it is no different from a free tier of any other *closed* commercial products.<p>&quot;Free as in speech&quot; : I&#x27;m not sure which part of openAI&#x27;s actions show commitment to this part.</div><br/><div id="39612273" class="c"><input type="checkbox" id="c-39612273" checked=""/><div class="controls bullet"><span class="by">JieJie</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612109">parent</a><span>|</span><a href="#39612038">next</a><span>|</span><label class="collapse" for="c-39612273">[-]</label><label class="expand" for="c-39612273">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s because they were whispering.<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;research&#x2F;whisper" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;research&#x2F;whisper</a></div><br/></div></div></div></div><div id="39612038" class="c"><input type="checkbox" id="c-39612038" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612012">parent</a><span>|</span><a href="#39612109">prev</a><span>|</span><a href="#39612260">next</a><span>|</span><label class="collapse" for="c-39612038">[-]</label><label class="expand" for="c-39612038">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI isn&#x27;t free either way, they don&#x27;t let you do porn etc with their models.</div><br/><div id="39613159" class="c"><input type="checkbox" id="c-39613159" checked=""/><div class="controls bullet"><span class="by">snoman</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612038">parent</a><span>|</span><a href="#39612260">next</a><span>|</span><label class="collapse" for="c-39613159">[-]</label><label class="expand" for="c-39613159">[1 more]</label></div><br/><div class="children"><div class="content">What’s more, ChatGPT won’t even attempt to name controversial websites if you’ve forgotten their name.</div><br/></div></div></div></div><div id="39612260" class="c"><input type="checkbox" id="c-39612260" checked=""/><div class="controls bullet"><span class="by">romwell</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612012">parent</a><span>|</span><a href="#39612038">prev</a><span>|</span><a href="#39612097">next</a><span>|</span><label class="collapse" for="c-39612260">[-]</label><label class="expand" for="c-39612260">[1 more]</label></div><br/><div class="children"><div class="content">&gt;isn’t this the old: free as in speech, not as in beer<p>Hardly. <i>Free beer</i> and <i>free speech</i> do have different meanings, but <i>freeware</i> isn&#x27;t something you have to pay for because it&#x27;s &quot;free as in beer&quot;.<p>In OpenAI&#x27;s case, &quot;open&quot; isn&#x27;t open as in <i>anything</i> normally associated with the word in the context.<p><i>Open as in private club during business hours for VIP members only</i> is how they are trying to explain it, but understandbly, some people aren&#x27;t buying it.</div><br/></div></div></div></div></div></div><div id="39612097" class="c"><input type="checkbox" id="c-39612097" checked=""/><div class="controls bullet"><span class="by">resonious</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39611881">prev</a><span>|</span><a href="#39612347">next</a><span>|</span><label class="collapse" for="c-39612097">[-]</label><label class="expand" for="c-39612097">[4 more]</label></div><br/><div class="children"><div class="content">Yeah seems pretty cut and dry. It&#x27;d feel pretty bad to see OpenAI doing what they&#x27;re doing now after saying things like &quot;My probability assessment of OpenAI being relevant to DeepMind&#x2F;Google without a dramatic change in execution and resources is 0%.&quot;</div><br/><div id="39612173" class="c"><input type="checkbox" id="c-39612173" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612097">parent</a><span>|</span><a href="#39612213">next</a><span>|</span><label class="collapse" for="c-39612173">[-]</label><label class="expand" for="c-39612173">[1 more]</label></div><br/><div class="children"><div class="content">He was right though, they did have a dramatic change in execution and resources the next couple of years when they prepared to sell out to Microsoft and that gave them a chance. Elon really gave them good advice there, even if it was snarky.</div><br/></div></div><div id="39612213" class="c"><input type="checkbox" id="c-39612213" checked=""/><div class="controls bullet"><span class="by">barrell</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612097">parent</a><span>|</span><a href="#39612173">prev</a><span>|</span><a href="#39612347">next</a><span>|</span><label class="collapse" for="c-39612213">[-]</label><label class="expand" for="c-39612213">[2 more]</label></div><br/><div class="children"><div class="content">I don’t think anything about this is cut and dry. You may have a strong opinion on the matter, but at the most charitable it’s people doing their best in a murky situation</div><br/><div id="39612618" class="c"><input type="checkbox" id="c-39612618" checked=""/><div class="controls bullet"><span class="by">resonious</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612213">parent</a><span>|</span><a href="#39612347">next</a><span>|</span><label class="collapse" for="c-39612618">[-]</label><label class="expand" for="c-39612618">[1 more]</label></div><br/><div class="children"><div class="content">I did say it <i>seems</i> cut and dry. It just looks a certain way. I know that things may not be as they seem. Elon&#x27;s complaints about OpenAI pulling a profit make sense in isolation, but look very different in light of these emails. This blog post is a very good move in OpenAI&#x27;s favor.</div><br/></div></div></div></div></div></div><div id="39612347" class="c"><input type="checkbox" id="c-39612347" checked=""/><div class="controls bullet"><span class="by">eftychis</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39612097">prev</a><span>|</span><a href="#39611921">next</a><span>|</span><label class="collapse" for="c-39612347">[-]</label><label class="expand" for="c-39612347">[6 more]</label></div><br/><div class="children"><div class="content">In my eyes this is a straw argument.<p>&quot;[T]otally OK not to share the science.&quot; I think the reasonable average person would disagree with that. And, it would go against certain goal &amp; financial transparency principles that the IRS demands to bestow the 501(c)3 designation.<p>(e.g. see here <a href="https:&#x2F;&#x2F;www.citizen.org&#x2F;article&#x2F;letter-to-california-attorney-general-on-openais-nonprofit-status&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.citizen.org&#x2F;article&#x2F;letter-to-california-attorne...</a>)</div><br/><div id="39612501" class="c"><input type="checkbox" id="c-39612501" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612347">parent</a><span>|</span><a href="#39611921">next</a><span>|</span><label class="collapse" for="c-39612501">[-]</label><label class="expand" for="c-39612501">[5 more]</label></div><br/><div class="children"><div class="content">Ilya&#x27;s justification for that argument was to link to a SlateStarCodex blog post. We are doomed...</div><br/><div id="39613067" class="c"><input type="checkbox" id="c-39613067" checked=""/><div class="controls bullet"><span class="by">ce4</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612501">parent</a><span>|</span><a href="#39612589">next</a><span>|</span><label class="collapse" for="c-39613067">[-]</label><label class="expand" for="c-39613067">[2 more]</label></div><br/><div class="children"><div class="content">Where did you get that it was sent by Ilya? The to: field is redacted.</div><br/><div id="39613183" class="c"><input type="checkbox" id="c-39613183" checked=""/><div class="controls bullet"><span class="by">snoman</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39613067">parent</a><span>|</span><a href="#39612589">next</a><span>|</span><label class="collapse" for="c-39613183">[-]</label><label class="expand" for="c-39613183">[1 more]</label></div><br/><div class="children"><div class="content">The name is not redacted, only the exact e-mail address.</div><br/></div></div></div></div><div id="39612589" class="c"><input type="checkbox" id="c-39612589" checked=""/><div class="controls bullet"><span class="by">Atotalnoob</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612501">parent</a><span>|</span><a href="#39613067">prev</a><span>|</span><a href="#39611921">next</a><span>|</span><label class="collapse" for="c-39612589">[-]</label><label class="expand" for="c-39612589">[2 more]</label></div><br/><div class="children"><div class="content">What’s wrong with slatestarcodex? I’ve never heard of them before</div><br/><div id="39613691" class="c"><input type="checkbox" id="c-39613691" checked=""/><div class="controls bullet"><span class="by">jbc1</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612589">parent</a><span>|</span><a href="#39611921">next</a><span>|</span><label class="collapse" for="c-39613691">[-]</label><label class="expand" for="c-39613691">[1 more]</label></div><br/><div class="children"><div class="content">Lucky you! It&#x27;s some of the best content on the internet. My favourite blog for sure. Same guy has continued on with his writing at <a href="https:&#x2F;&#x2F;www.astralcodexten.com" rel="nofollow">https:&#x2F;&#x2F;www.astralcodexten.com</a> which is also pretty good but doesn&#x27;t reach the same highs.<p>What&#x27;s wrong with it in context though is that as great as it is, it&#x27;s just some guys blog. It&#x27;s disconcerting that people would be working on technology they think is more dangerous than nuclear weapons and basing their approach to safety on a random blog post.<p>Although it&#x27;s disconcerting to think of a committee deciding how it&#x27;s approached, or the general public, or AI loving researchers, so it might just be a disconcerting topic.<p>If OpenAI or just Ilya think Scott is the best man to have thinking about it though, I would have at least liked them to pay him to do it full time. Blogging isn&#x27;t even Scott&#x27;s full time job, and the majority of his stuff isn&#x27;t even about AI.</div><br/></div></div></div></div></div></div></div></div><div id="39611921" class="c"><input type="checkbox" id="c-39611921" checked=""/><div class="controls bullet"><span class="by">greenie_beans</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39612347">prev</a><span>|</span><a href="#39613358">next</a><span>|</span><label class="collapse" for="c-39611921">[-]</label><label class="expand" for="c-39611921">[3 more]</label></div><br/><div class="children"><div class="content">really makes the &quot;Open&quot; sound more sinister, like they&#x27;re opening the ai.</div><br/><div id="39613651" class="c"><input type="checkbox" id="c-39613651" checked=""/><div class="controls bullet"><span class="by">Onewildgamer</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39611921">parent</a><span>|</span><a href="#39612279">next</a><span>|</span><label class="collapse" for="c-39613651">[-]</label><label class="expand" for="c-39613651">[1 more]</label></div><br/><div class="children"><div class="content">Like they rub open the lamp to release the genie. To go with the metaphor, the genie obeys the person holding the lamp, not everybody</div><br/></div></div><div id="39612279" class="c"><input type="checkbox" id="c-39612279" checked=""/><div class="controls bullet"><span class="by">polynomial</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39611921">parent</a><span>|</span><a href="#39613651">prev</a><span>|</span><a href="#39613358">next</a><span>|</span><label class="collapse" for="c-39612279">[-]</label><label class="expand" for="c-39612279">[1 more]</label></div><br/><div class="children"><div class="content">Release the kraken.</div><br/></div></div></div></div><div id="39613358" class="c"><input type="checkbox" id="c-39613358" checked=""/><div class="controls bullet"><span class="by">brtkdotse</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39611921">prev</a><span>|</span><a href="#39613776">next</a><span>|</span><label class="collapse" for="c-39613358">[-]</label><label class="expand" for="c-39613358">[1 more]</label></div><br/><div class="children"><div class="content">&gt; He&#x27;s just mad<p>This seems to be his natural resting state these days</div><br/></div></div><div id="39613776" class="c"><input type="checkbox" id="c-39613776" checked=""/><div class="controls bullet"><span class="by">ecmascript</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39613358">prev</a><span>|</span><a href="#39611803">next</a><span>|</span><label class="collapse" for="c-39613776">[-]</label><label class="expand" for="c-39613776">[1 more]</label></div><br/><div class="children"><div class="content">&gt; On the other hand, this shows Elon doesn&#x27;t care jackshit about the lack of openness from OpenAI. He&#x27;s just mad only that he walked away from a monumental success.<p>You really come to that conclusion from a &quot;yup&quot;? Damn.</div><br/></div></div><div id="39611803" class="c"><input type="checkbox" id="c-39611803" checked=""/><div class="controls bullet"><span class="by">sidcool</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39613776">prev</a><span>|</span><a href="#39611970">next</a><span>|</span><label class="collapse" for="c-39611803">[-]</label><label class="expand" for="c-39611803">[2 more]</label></div><br/><div class="children"><div class="content">Yes.  I think the same.  Elon is just bitter he misjudged and now wants to claw back without seeming a giant a-hole.</div><br/><div id="39612601" class="c"><input type="checkbox" id="c-39612601" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39611803">parent</a><span>|</span><a href="#39611970">next</a><span>|</span><label class="collapse" for="c-39612601">[-]</label><label class="expand" for="c-39612601">[1 more]</label></div><br/><div class="children"><div class="content">He has celebrityitus — he is so far gone from knowing anyone that doesn’t suck up to him that he can help but look like a giant a-hole all the time because everyone round him will tell him that he is cool and right.<p>And it doesn’t take being that rich to have this problem. Even minor celebs in L.A. have this problem!</div><br/></div></div></div></div><div id="39611970" class="c"><input type="checkbox" id="c-39611970" checked=""/><div class="controls bullet"><span class="by">BoiledCabbage</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39611803">prev</a><span>|</span><a href="#39611761">next</a><span>|</span><label class="collapse" for="c-39611970">[-]</label><label class="expand" for="c-39611970">[5 more]</label></div><br/><div class="children"><div class="content">&gt;  this shows Elon doesn&#x27;t care jackshit about the lack of openness from OpenAI. He&#x27;s just mad only that he walked away from a monumental success.<p>Yup he&#x27;s pretty transparently lying here.<p>He committed to fund for $1B dollars. Then when they wouldn&#x27;t make him CEO and&#x2F;or roll the company into Tesla he refused his commitment after paying out only 4% of it. Claimed the company would fail and only he could save them (again wrong).<p>And now is mad he doesn&#x27;t control the top AI out there and because he chose to walk away from them.<p>And yet again people are falling for him. Elon talk never matches his action. And there is still a large portion of the internet that falls for his talk time and time again.</div><br/><div id="39612059" class="c"><input type="checkbox" id="c-39612059" checked=""/><div class="controls bullet"><span class="by">mlsu</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39611970">parent</a><span>|</span><a href="#39613220">next</a><span>|</span><label class="collapse" for="c-39612059">[-]</label><label class="expand" for="c-39612059">[3 more]</label></div><br/><div class="children"><div class="content">Whether it is Elon or Altman that controls it has nothing to do with how open or not openAI is. And it has become very clear that OpenAI is nothing but Microsoft in a trenchcoat.<p>No matter his motives, I applaud this lawsuit. Who cares if his talk doesn&#x27;t match his action? His action, here, is good.</div><br/><div id="39612424" class="c"><input type="checkbox" id="c-39612424" checked=""/><div class="controls bullet"><span class="by">lern_too_spel</span><span>|</span><a href="#39611606">root</a><span>|</span><a href="#39612059">parent</a><span>|</span><a href="#39612192">next</a><span>|</span><label class="collapse" for="c-39612424">[-]</label><label class="expand" for="c-39612424">[1 more]</label></div><br/><div class="children"><div class="content">Musk&#x27;s lawsuit is for breach of contract, but it looks like Musk agreed with what OpenAI did, which means the lawsuit will fail.<p>From the complaint:<p>&gt; Together with Mr. Brockman, the three agreed that this new lab: (a) would be a non-profit developing AGI for the benefit of humanity, not for a for-profit company seeking to maximize 
shareholder profits; and (b) would be open-source, balancing only countervailing safety considerations, and would not keep its technology closed and secret for proprietary commercial 
reasons (The “Founding Agreement”).<p>The biggest beneficiary of this lawsuit is Google, which now gets more runway to bumble along to victory.</div><br/></div></div></div></div></div></div><div id="39613060" class="c"><input type="checkbox" id="c-39613060" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#39611606">parent</a><span>|</span><a href="#39611660">prev</a><span>|</span><a href="#39611650">next</a><span>|</span><label class="collapse" for="c-39613060">[-]</label><label class="expand" for="c-39613060">[1 more]</label></div><br/><div class="children"><div class="content">At the time, all AI models were hidden inside big corporations. We saw research papers but couldn&#x27;t use any. OpenAI allowed anyone to access modern LLMs. They were open in the sense that they give everyone access to the model.</div><br/></div></div></div></div><div id="39611650" class="c"><input type="checkbox" id="c-39611650" checked=""/><div class="controls bullet"><span class="by">LatticeAnimal</span><span>|</span><a href="#39611606">prev</a><span>|</span><a href="#39611722">next</a><span>|</span><label class="collapse" for="c-39611650">[-]</label><label class="expand" for="c-39611650">[5 more]</label></div><br/><div class="children"><div class="content">&gt; As we get closer to building AI, it will make sense to start being less open. The Open in OpenAI means that everyone should benefit from the fruits of AI after its built, but it&#x27;s totally OK to not share the science (even though sharing everything is definitely the right strategy in the short and possibly medium term for recruitment purposes).<p>That is surprisingly greedy &amp; selfish to be boasting about in their own blog.</div><br/><div id="39611733" class="c"><input type="checkbox" id="c-39611733" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611650">parent</a><span>|</span><a href="#39612602">next</a><span>|</span><label class="collapse" for="c-39611733">[-]</label><label class="expand" for="c-39611733">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, they are basically saying that they called themselves OpenAI as a recruitment strategy but they never planned to be open after the initial hires.</div><br/><div id="39612399" class="c"><input type="checkbox" id="c-39612399" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#39611650">root</a><span>|</span><a href="#39611733">parent</a><span>|</span><a href="#39612540">next</a><span>|</span><label class="collapse" for="c-39612399">[-]</label><label class="expand" for="c-39612399">[1 more]</label></div><br/><div class="children"><div class="content">They’re pretty open about that now though.</div><br/></div></div><div id="39612540" class="c"><input type="checkbox" id="c-39612540" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#39611650">root</a><span>|</span><a href="#39611733">parent</a><span>|</span><a href="#39612399">prev</a><span>|</span><a href="#39612602">next</a><span>|</span><label class="collapse" for="c-39612540">[-]</label><label class="expand" for="c-39612540">[1 more]</label></div><br/><div class="children"><div class="content">Why do tech people keep falling for this shtick? It&#x27;s happened over and over and over with open source becoming open core becoming source available being
becoming source available with closed source bits.<p>How society organizes property rights makes it damn near impossible to make anything commons in a way that can&#x27;t in practice be reversed when folks see dollar signs. Owner is a non nullable field.</div><br/></div></div></div></div><div id="39612602" class="c"><input type="checkbox" id="c-39612602" checked=""/><div class="controls bullet"><span class="by">gyudin</span><span>|</span><a href="#39611650">parent</a><span>|</span><a href="#39611733">prev</a><span>|</span><a href="#39611722">next</a><span>|</span><label class="collapse" for="c-39612602">[-]</label><label class="expand" for="c-39612602">[1 more]</label></div><br/><div class="children"><div class="content">Sounds pretty much like any other corpo “Pay us bucks and benefit from our tech”</div><br/></div></div></div></div><div id="39611722" class="c"><input type="checkbox" id="c-39611722" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#39611650">prev</a><span>|</span><a href="#39613147">next</a><span>|</span><label class="collapse" for="c-39611722">[-]</label><label class="expand" for="c-39611722">[25 more]</label></div><br/><div class="children"><div class="content">This looks bad for OpenAI (although it&#x27;s been pretty obvious that they are far from open for a long time).<p>But it looks 10x worse for Elon. At least for the public image, he desperately try to maintain.<p>&gt; As we discussed a for-profit structure in order to further the mission, Elon wanted us to merge with Tesla or he wanted full control.
&gt; In late 2017, we and Elon decided the next step for the mission was to create a for-profit entity. Elon wanted majority equity, initial board control, and to be CEO. In the middle of these discussions, he withheld funding,</div><br/><div id="39612286" class="c"><input type="checkbox" id="c-39612286" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#39611722">parent</a><span>|</span><a href="#39611788">next</a><span>|</span><label class="collapse" for="c-39612286">[-]</label><label class="expand" for="c-39612286">[3 more]</label></div><br/><div class="children"><div class="content">The difference is OpenAI had a reputation to protect, Musk can&#x27;t sink any lower at this point, and his stans will persist.<p>The fact that they slinging mud at each other just proves the mutual criticism though, and provides an edifying spectacle for the rest of us.</div><br/><div id="39612600" class="c"><input type="checkbox" id="c-39612600" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39612286">parent</a><span>|</span><a href="#39612935">next</a><span>|</span><label class="collapse" for="c-39612600">[-]</label><label class="expand" for="c-39612600">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The difference is OpenAI had a reputation to protect<p>OpenAI changed its stance about five years ago. In meanwhile they got billions in investment, hired best employees, created very successful product and took leadership position in AI. Only narrative remaining was that they somehow betrayed original donors by moving away from the charter. This shows that is not the case; original donor(s) are equally megalomaniac and don&#x27;t give a fuck about the charter.</div><br/></div></div><div id="39612935" class="c"><input type="checkbox" id="c-39612935" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39612286">parent</a><span>|</span><a href="#39612600">prev</a><span>|</span><a href="#39611788">next</a><span>|</span><label class="collapse" for="c-39612935">[-]</label><label class="expand" for="c-39612935">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Musk can&#x27;t sink any lower at this point, and his stans will persist.<p>You sure about that ?<p>For now they are largely looking away (and boy it&#x27;s hard !) from his &#x27;far right&#x27; adventures. But it was just reported that he met with Trump. And it&#x27;s pretty clear that if Trump is elected and does cancel EV subsides as he says he will do, Tesla is dead and he knows it.<p>So now, we have both of those guys, having something each other wants - Trump wants Musks money now, and Musk wants ... taxpayer money once Trump is elected. I bet, Musk reputation can and will go much much lower in coming months.</div><br/></div></div></div></div><div id="39611788" class="c"><input type="checkbox" id="c-39611788" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#39611722">parent</a><span>|</span><a href="#39612286">prev</a><span>|</span><a href="#39611741">next</a><span>|</span><label class="collapse" for="c-39611788">[-]</label><label class="expand" for="c-39611788">[8 more]</label></div><br/><div class="children"><div class="content">Do you mind elaborating why you think it looks bad for OpenAI? I didn&#x27;t see anything that diminishes their importance as an entity or hurts them in respect to this lawsuit or their reputation. In their internal emails from 2016 they explain what they mean by open.</div><br/><div id="39611851" class="c"><input type="checkbox" id="c-39611851" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39611788">parent</a><span>|</span><a href="#39611741">next</a><span>|</span><label class="collapse" for="c-39611851">[-]</label><label class="expand" for="c-39611851">[7 more]</label></div><br/><div class="children"><div class="content">Bad as to the credibility of the image they tried to sell in the beginning.<p>If we agree it&#x27;s a for profit company, and all this &#x27;Open&#x27; stuff is just PR, then yes - it&#x27;s not looking bad. It&#x27;s just business.</div><br/><div id="39612120" class="c"><input type="checkbox" id="c-39612120" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39611851">parent</a><span>|</span><a href="#39611741">next</a><span>|</span><label class="collapse" for="c-39612120">[-]</label><label class="expand" for="c-39612120">[6 more]</label></div><br/><div class="children"><div class="content">I hear people complain about the &#x27;Open&#x27; a lot recently, but I&#x27;m not sure I understand this type of concern. Publications, for companies, are always PR and recruitment efforts (independent of profit or nonprofit status). I recall that OpenAI were very clear about their long term intentions and plans for how to proceed since at least February of 2019 when they announced GPT2 and withheld the code and weights for about 9 months because of concerns with making the technology immediately available to all. In my own mind, they&#x27;ve been consistent in their behavior for the last 5 years, probably longer though I didn&#x27;t care much about their early RL-related recruitment efforts.</div><br/><div id="39612218" class="c"><input type="checkbox" id="c-39612218" checked=""/><div class="controls bullet"><span class="by">mac-attack</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39612120">parent</a><span>|</span><a href="#39612918">next</a><span>|</span><label class="collapse" for="c-39612218">[-]</label><label class="expand" for="c-39612218">[3 more]</label></div><br/><div class="children"><div class="content">With all due respect, they are not doing a sleight of hand while selling widgets... they are in the process of reshaping society in a way that may have never been achieved previously. Finding out that their initial motives were a facade doesn&#x27;t portend well for their morality as they continue to gain power.</div><br/><div id="39612617" class="c"><input type="checkbox" id="c-39612617" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39612218">parent</a><span>|</span><a href="#39612918">next</a><span>|</span><label class="collapse" for="c-39612617">[-]</label><label class="expand" for="c-39612617">[2 more]</label></div><br/><div class="children"><div class="content">I still don’t understand why you think their initial motives were a facade. They have always been trying to get to AGI that will be useable by a large fraction of society. I am not sure this means they need to explain exactly how things work at every step along the way or to help competitors also develop AGI any more than Intel or Nvidia had to publish their tapeouts in order for people to buy their chips or for competitors to appear. If OpenAI instead built AI for the purpose of helping them solve an internal&#x2F;whimsical project then that would not be “open” by any reasonable definition (and such efforts exist, possibly by ultra wealthy corporations but also by nations, including for defense purposes.)</div><br/><div id="39613544" class="c"><input type="checkbox" id="c-39613544" checked=""/><div class="controls bullet"><span class="by">leereeves</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39612617">parent</a><span>|</span><a href="#39612918">next</a><span>|</span><label class="collapse" for="c-39613544">[-]</label><label class="expand" for="c-39613544">[1 more]</label></div><br/><div class="children"><div class="content">At one time their mission statement said:<p>&gt; OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.<p>That&#x27;s obviously changed to &quot;let&#x27;s make lots of money&quot;, which should not be any &quot;non-profit&quot; organization&#x27;s mission.</div><br/></div></div></div></div></div></div><div id="39612918" class="c"><input type="checkbox" id="c-39612918" checked=""/><div class="controls bullet"><span class="by">devjab</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39612120">parent</a><span>|</span><a href="#39612218">prev</a><span>|</span><a href="#39612445">next</a><span>|</span><label class="collapse" for="c-39612918">[-]</label><label class="expand" for="c-39612918">[1 more]</label></div><br/><div class="children"><div class="content">I think the word “open” is sort of a misrepresentation of what the company is today. I don’t mind personally but I can also see why people in the OSS community would.<p>Now, I’m not too concerned with any of the large LLM companies and their PR stunts, but from my solely EU enterprise perspective I see OpenAI as mostly a store-front for Microsoft. We get all the enterprise co-pilot products as part of our Microsoft licensing (which is bartered through a 3rd party vendor to make it seem like all the co-pilot stuff we get is “free” when it goes on the budget).<p>All of those tools are obviously direct results of the work OpenAI does and many of them are truly brilliant. I work in an investment bank that builds green energy plants and sells them with investor money. As you might imagine, nobody outside of our sales department is very good at creating PowerPoints. Especially our financial departments used to a “joy” to watch when they presented their stuff on monthly&#x2F;quarterly meetings… seriously it was like they were in a competition to fit the most words into a single slide. With co-pilot their stuff looks absolutely brilliant. Still not on the level of our sales department, but brilliant and it’s even helped their presentations not last 90 million years. And this is just a tiny fraction of what we get out of co-pilot. Sure… I mostly use it to make stupid images of ducks, cats, and space marines with wolf heads for my code related presentations, and, to give me links to the right Microsoft domination I’m looking for in the ocean of pages. But it’s still the fruits of OpenAI.<p>Hell, the fact that they’re doing their stuff on Azure basically means that a lot of those 10 Microsoft billion are going directly back to Microsoft themselves as OpenAI purchases computing power. Yet it remains a “free” entity, so that Microsoft doesn’t run into EU anti-trust issues.<p>Despite this gloom and doom with an added bit of tinfoil hat, I do think OpenAI themselves are still true to their original mission. But in the boring business sense in an enterprise world, I also think they are simultaneously sort of owned by the largest “for enterprise” tech company in the world.</div><br/></div></div></div></div></div></div></div></div><div id="39611741" class="c"><input type="checkbox" id="c-39611741" checked=""/><div class="controls bullet"><span class="by">extheat</span><span>|</span><a href="#39611722">parent</a><span>|</span><a href="#39611788">prev</a><span>|</span><a href="#39611757">next</a><span>|</span><label class="collapse" for="c-39611741">[-]</label><label class="expand" for="c-39611741">[1 more]</label></div><br/><div class="children"><div class="content">It was his money to give, he&#x27;s not obligated to giving it out without some form of control. But yes that does seem pretty excessive, he basically wanted to pull a Tesla there.</div><br/></div></div><div id="39611757" class="c"><input type="checkbox" id="c-39611757" checked=""/><div class="controls bullet"><span class="by">wseqyrku</span><span>|</span><a href="#39611722">parent</a><span>|</span><a href="#39611741">prev</a><span>|</span><a href="#39612680">next</a><span>|</span><label class="collapse" for="c-39611757">[-]</label><label class="expand" for="c-39611757">[1 more]</label></div><br/><div class="children"><div class="content">They both are all about publicity and that&#x27;s the name of the game. Doesn&#x27;t matter who wins at the end, it&#x27;s going to be absolutely all out in the Open. Hey.</div><br/></div></div><div id="39612680" class="c"><input type="checkbox" id="c-39612680" checked=""/><div class="controls bullet"><span class="by">BeetleB</span><span>|</span><a href="#39611722">parent</a><span>|</span><a href="#39611757">prev</a><span>|</span><a href="#39612494">next</a><span>|</span><label class="collapse" for="c-39612680">[-]</label><label class="expand" for="c-39612680">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s nothing new here, though. That he demanded control of OpenAI has been well reported in the past.</div><br/></div></div><div id="39611753" class="c"><input type="checkbox" id="c-39611753" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611722">parent</a><span>|</span><a href="#39612494">prev</a><span>|</span><a href="#39613147">next</a><span>|</span><label class="collapse" for="c-39611753">[-]</label><label class="expand" for="c-39611753">[9 more]</label></div><br/><div class="children"><div class="content">Elon makes plenty of companies, him making an AI company that he was in control of doesn&#x27;t look bad or strange at all.</div><br/><div id="39611871" class="c"><input type="checkbox" id="c-39611871" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39611753">parent</a><span>|</span><a href="#39611866">next</a><span>|</span><label class="collapse" for="c-39611871">[-]</label><label class="expand" for="c-39611871">[4 more]</label></div><br/><div class="children"><div class="content">I was talking about his public image - &#x27;founder&#x27; of Tesla, doing everything for the love of humanity etc.<p>It&#x27;s all bullshit, and these emails show it again. He is an extraordinary businessman of course - but everything he does, he does for money and power - mostly coming from government subsides btw. Until recently though, he managed to make most believe that it was to save the planet and the humanity.</div><br/><div id="39612266" class="c"><input type="checkbox" id="c-39612266" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39611871">parent</a><span>|</span><a href="#39611866">next</a><span>|</span><label class="collapse" for="c-39612266">[-]</label><label class="expand" for="c-39612266">[3 more]</label></div><br/><div class="children"><div class="content">At this point most people didn&#x27;t think Elon was a good guy even before these emails leaked</div><br/><div id="39613194" class="c"><input type="checkbox" id="c-39613194" checked=""/><div class="controls bullet"><span class="by">adamors</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39612266">parent</a><span>|</span><a href="#39611866">next</a><span>|</span><label class="collapse" for="c-39613194">[-]</label><label class="expand" for="c-39613194">[2 more]</label></div><br/><div class="children"><div class="content">Yes, he has shown his true self when he called the British diver, who was rescuing kids out of cave in Thailand, a pedophile. That was more than 5 years ago.</div><br/><div id="39613770" class="c"><input type="checkbox" id="c-39613770" checked=""/><div class="controls bullet"><span class="by">consumer451</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39613194">parent</a><span>|</span><a href="#39611866">next</a><span>|</span><label class="collapse" for="c-39613770">[-]</label><label class="expand" for="c-39613770">[1 more]</label></div><br/><div class="children"><div class="content">Morals, ethics, and not being a jerk aside, he has shown that he is just plain not thinking things through, when he:<p>1) Released the original Boring Company idea about tiny tunnels under LA to alleviate road traffic, which could easily be shot down by anyone modeling it on a single paper napkin.<p>2) Got caught up in ontological arguments about alien scientists who had surely created a computer simulation in which we all live.<p>3) In an effort to prevent the inevitable AI overlords from controlling us, he bought a company to create a ubiquitous neural interface so that computers have read&#x2F;write access to our brains, which somehow the AI overlords will not take advantage of.<p>This was all as of 2018.</div><br/></div></div></div></div></div></div></div></div><div id="39611866" class="c"><input type="checkbox" id="c-39611866" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39611753">parent</a><span>|</span><a href="#39611871">prev</a><span>|</span><a href="#39613147">next</a><span>|</span><label class="collapse" for="c-39611866">[-]</label><label class="expand" for="c-39611866">[4 more]</label></div><br/><div class="children"><div class="content">He was pushing them to do the thing he&#x27;s suing them over.<p>&gt; Message to Elon: &quot;A for-profit pivot might create a more sustainable revenue stream&quot;<p>&gt; Elon: You are right ... and Tesla is the only path.<p>Then 3 weeks later Elon gets kicked off the board, probably after a fight where he tried to make OpenAI become for-profit under Tesla.<p>How can you not see how conniving this man is? The lawsuit is either a revenge play or a play to take down xAI&#x27;s competition.</div><br/><div id="39612068" class="c"><input type="checkbox" id="c-39612068" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39611866">parent</a><span>|</span><a href="#39612223">next</a><span>|</span><label class="collapse" for="c-39612068">[-]</label><label class="expand" for="c-39612068">[1 more]</label></div><br/><div class="children"><div class="content">Oh, I read that as if it was the founding stage, not 2 years later. Yeah I agree it puts things in perspective a bit.</div><br/></div></div><div id="39612223" class="c"><input type="checkbox" id="c-39612223" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39611866">parent</a><span>|</span><a href="#39612068">prev</a><span>|</span><a href="#39613147">next</a><span>|</span><label class="collapse" for="c-39612223">[-]</label><label class="expand" for="c-39612223">[2 more]</label></div><br/><div class="children"><div class="content">Kicked off the board?  Thats news to me.</div><br/><div id="39612485" class="c"><input type="checkbox" id="c-39612485" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#39611722">root</a><span>|</span><a href="#39612223">parent</a><span>|</span><a href="#39613147">next</a><span>|</span><label class="collapse" for="c-39612485">[-]</label><label class="expand" for="c-39612485">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In late 2017, we and Elon decided the next step for the mission was to create a for-profit entity. Elon wanted majority equity, initial board control, and to be CEO. In the middle of these discussions, he withheld funding. Reid Hoffman bridged the gap to cover salaries and operations.<p>I misspoke. He may have just resigned from the board when he didn&#x27;t get what he wanted.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39613147" class="c"><input type="checkbox" id="c-39613147" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#39611722">prev</a><span>|</span><a href="#39613043">next</a><span>|</span><label class="collapse" for="c-39613147">[-]</label><label class="expand" for="c-39613147">[3 more]</label></div><br/><div class="children"><div class="content">Did people really think leading the development of the most important invention in human history wouldn’t involve a little bit of drama?<p>I know everyone wants OpenAI to be a magical place that open sources their models the moment they’re done training, but it’s clear that they’ve chosen a reasonable path for their business based on both practicality and risk reduction. If they had gone another way, today they’d be an unceremonious branch of Elon’s empire, or a mid-level nonprofit that never had the means to hire the best people and is still spending all their time soliciting donations to train GPT 3.5.<p>They did what they believed they had to do to be the ones to get to AGI. Will they be the safest stewards of this tech? Hard to say, though it’s clear even the once safety minded Anthropic isn’t shying from releasing SOTA models.</div><br/><div id="39613206" class="c"><input type="checkbox" id="c-39613206" checked=""/><div class="controls bullet"><span class="by">Timber-6539</span><span>|</span><a href="#39613147">parent</a><span>|</span><a href="#39613043">next</a><span>|</span><label class="collapse" for="c-39613206">[-]</label><label class="expand" for="c-39613206">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  ... chosen a specific path for their business based on both practicality and risk reduction<p>The risk reduction didn&#x27;t go so well now that Elon is putting up lawyers to force them to become more &quot;open&quot;.<p>This organization thrives in the dark and they know their secret to success depends on it. Would save every one a lot of time if they came out as a proper non-profit and dropped &quot;open&quot; in the name&#x2F;branding.<p>&gt; If they had gone another way, today they’d be an unceremonious branch of Elon’s empire<p>They substituted this dream with Microsoft.</div><br/><div id="39613232" class="c"><input type="checkbox" id="c-39613232" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#39613147">root</a><span>|</span><a href="#39613206">parent</a><span>|</span><a href="#39613043">next</a><span>|</span><label class="collapse" for="c-39613232">[-]</label><label class="expand" for="c-39613232">[1 more]</label></div><br/><div class="children"><div class="content">I’m pretty sure Elon won’t win the case, and still, 49% is less than 100%</div><br/></div></div></div></div></div></div><div id="39613043" class="c"><input type="checkbox" id="c-39613043" checked=""/><div class="controls bullet"><span class="by">sharkjacobs</span><span>|</span><a href="#39613147">prev</a><span>|</span><a href="#39613112">next</a><span>|</span><label class="collapse" for="c-39613043">[-]</label><label class="expand" for="c-39613043">[19 more]</label></div><br/><div class="children"><div class="content">&gt; For example, Albania is using OpenAI’s tools to accelerate its EU accession by as much as 5.5 years<p>What an insane thing to say so matter of factly. This is like a character in an airport bookstore political thriller who is poorly written to be smart.</div><br/><div id="39613515" class="c"><input type="checkbox" id="c-39613515" checked=""/><div class="controls bullet"><span class="by">herewulf</span><span>|</span><a href="#39613043">parent</a><span>|</span><a href="#39613827">next</a><span>|</span><label class="collapse" for="c-39613515">[-]</label><label class="expand" for="c-39613515">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. I found the claim about Icelandic even more telling. Here&#x27;s a small language that basically exists in its present form since the past thousand years (i.e: it has changed little since Old Norse). It also is notoriously conservative in its preservation of native vocabulary through avoidance of loanwords.<p>Iceland&#x2F;Icelandic don&#x27;t need gee whiz computer things to &quot;preserve&quot; itself.</div><br/></div></div><div id="39613827" class="c"><input type="checkbox" id="c-39613827" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39613043">parent</a><span>|</span><a href="#39613515">prev</a><span>|</span><a href="#39613259">next</a><span>|</span><label class="collapse" for="c-39613827">[-]</label><label class="expand" for="c-39613827">[1 more]</label></div><br/><div class="children"><div class="content">To me, it reeks of &quot;Rationalist-speak&quot;. Throw a couple numbers with decimal points to sound precise, mention Bayesian priors a few times.</div><br/></div></div><div id="39613259" class="c"><input type="checkbox" id="c-39613259" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39613043">parent</a><span>|</span><a href="#39613827">prev</a><span>|</span><a href="#39613104">next</a><span>|</span><label class="collapse" for="c-39613259">[-]</label><label class="expand" for="c-39613259">[2 more]</label></div><br/><div class="children"><div class="content">The lack of self-awareness of whoever wrote this, and of all those who signed it, is mind boggling.</div><br/><div id="39613655" class="c"><input type="checkbox" id="c-39613655" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613259">parent</a><span>|</span><a href="#39613104">next</a><span>|</span><label class="collapse" for="c-39613655">[-]</label><label class="expand" for="c-39613655">[1 more]</label></div><br/><div class="children"><div class="content">I assume they wrote that with an LLM. That reads exactly like typical LLM arguments.</div><br/></div></div></div></div><div id="39613104" class="c"><input type="checkbox" id="c-39613104" checked=""/><div class="controls bullet"><span class="by">Falimonda</span><span>|</span><a href="#39613043">parent</a><span>|</span><a href="#39613259">prev</a><span>|</span><a href="#39613112">next</a><span>|</span><label class="collapse" for="c-39613104">[-]</label><label class="expand" for="c-39613104">[14 more]</label></div><br/><div class="children"><div class="content">Why is that such an insane thing for them to say?</div><br/><div id="39613268" class="c"><input type="checkbox" id="c-39613268" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613104">parent</a><span>|</span><a href="#39613505">next</a><span>|</span><label class="collapse" for="c-39613268">[-]</label><label class="expand" for="c-39613268">[5 more]</label></div><br/><div class="children"><div class="content">How is it not? How could anyone <i>possibly</i> know that number? And what gives you any inkling that it has the remotest chance of being true?</div><br/><div id="39613355" class="c"><input type="checkbox" id="c-39613355" checked=""/><div class="controls bullet"><span class="by">Falimonda</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613268">parent</a><span>|</span><a href="#39613505">next</a><span>|</span><label class="collapse" for="c-39613355">[-]</label><label class="expand" for="c-39613355">[4 more]</label></div><br/><div class="children"><div class="content">How about the possibility that OpenAI and the Albanian government - along with many other governments - have a relationship of which you&#x27;re unaware?</div><br/><div id="39613386" class="c"><input type="checkbox" id="c-39613386" checked=""/><div class="controls bullet"><span class="by">baobabKoodaa</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613355">parent</a><span>|</span><a href="#39613505">next</a><span>|</span><label class="collapse" for="c-39613386">[-]</label><label class="expand" for="c-39613386">[3 more]</label></div><br/><div class="children"><div class="content">Uh huh. And they arrived at this 5.5 number how?<p>It&#x27;s bullshit.</div><br/><div id="39613572" class="c"><input type="checkbox" id="c-39613572" checked=""/><div class="controls bullet"><span class="by">Falimonda</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613386">parent</a><span>|</span><a href="#39613505">next</a><span>|</span><label class="collapse" for="c-39613572">[-]</label><label class="expand" for="c-39613572">[2 more]</label></div><br/><div class="children"><div class="content">You cannot fathom how a government official may have told them that they&#x27;ve managed to accelerate their EU accession through the help of LLMs by a specific number of months?<p>Here&#x27;s a speculative scenario that doesn&#x27;t seem so insane:<p>Albania has a roadmap for EU accession. The roadmap is broken up into discrete tasks. The tasks have estimates for time to completion. They&#x27;ve been able to quickly hack away at 5.5 years worth of tasks using LLMs.<p>Your problem with the statement is that they didn&#x27;t provide a source. Maybe express interest in the facts that might support that instead of freaking out over perceived insanity.</div><br/><div id="39613778" class="c"><input type="checkbox" id="c-39613778" checked=""/><div class="controls bullet"><span class="by">malermeister</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613572">parent</a><span>|</span><a href="#39613505">next</a><span>|</span><label class="collapse" for="c-39613778">[-]</label><label class="expand" for="c-39613778">[1 more]</label></div><br/><div class="children"><div class="content">EU accession isn&#x27;t some jira story where you close tickets.<p>For a country like Albania, it requires massive social, cultural, political and economical changes. There&#x27;s no way anyone has a good estimate and there&#x27;s no way an LLM has magically transformed the culture in a way that&#x27;s a) meaningful and b) quantifiable.<p>Turkey has been a candidate for 25 years now, with no meaningful progress.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39613505" class="c"><input type="checkbox" id="c-39613505" checked=""/><div class="controls bullet"><span class="by">b-side</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613104">parent</a><span>|</span><a href="#39613268">prev</a><span>|</span><a href="#39613272">next</a><span>|</span><label class="collapse" for="c-39613505">[-]</label><label class="expand" for="c-39613505">[1 more]</label></div><br/><div class="children"><div class="content">Last time I checked, the decision to admit a new member state requires the unanimous approval of the EU&#x27;s current member states. As such unless OpenAI can literally influence world politics the claim is 100% bogus. All it takes is one rogue member and Albania will never join the EU.</div><br/></div></div><div id="39613272" class="c"><input type="checkbox" id="c-39613272" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613104">parent</a><span>|</span><a href="#39613505">prev</a><span>|</span><a href="#39613460">next</a><span>|</span><label class="collapse" for="c-39613272">[-]</label><label class="expand" for="c-39613272">[6 more]</label></div><br/><div class="children"><div class="content">because it&#x27;s a completely made up claim with a random number thrown in. How do you end up with &quot;5.5&quot; years for a process that doesn&#x27;t have a timetable, number of estimated emails required for EU accession divided by number of emails ChatGPT can generate per day?</div><br/><div id="39613545" class="c"><input type="checkbox" id="c-39613545" checked=""/><div class="controls bullet"><span class="by">ascorbic</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613272">parent</a><span>|</span><a href="#39613348">next</a><span>|</span><label class="collapse" for="c-39613545">[-]</label><label class="expand" for="c-39613545">[2 more]</label></div><br/><div class="children"><div class="content">I was pretty skeptical about this too, but looking into it there is some basis in fact. They&#x27;re using it to help translate and integrate the &quot;Acquis communautaire&quot; - the huge body of EU laws and regulations that need to be enshrined in national laws of candidate countries. This is one of the most time-consuming parts of the process, and usually takes many years. Leaving aside how risky this is (presumably they will have checks in place), I can see how this could save years of work. Saying 5.5 years is ridiculous false precision though.<p>It won&#x27;t help with the toughest part though, which is the politics of the other member states.</div><br/><div id="39613701" class="c"><input type="checkbox" id="c-39613701" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613545">parent</a><span>|</span><a href="#39613348">next</a><span>|</span><label class="collapse" for="c-39613701">[-]</label><label class="expand" for="c-39613701">[1 more]</label></div><br/><div class="children"><div class="content">Translating that doesn&#x27;t seem to take very long though. Looked up an example, Sweden voted to enter EU 13 nov 1994, and legally entered and had thus finished incorporating that into their legislation 1 jan 1995, so 1.5 months at most. Not sure what 5.5 years means, maybe they meant the total amount of working years in manhours saved?</div><br/></div></div></div></div><div id="39613348" class="c"><input type="checkbox" id="c-39613348" checked=""/><div class="controls bullet"><span class="by">Falimonda</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613272">parent</a><span>|</span><a href="#39613545">prev</a><span>|</span><a href="#39613460">next</a><span>|</span><label class="collapse" for="c-39613348">[-]</label><label class="expand" for="c-39613348">[3 more]</label></div><br/><div class="children"><div class="content">What do emails have anything to do with EU accession?</div><br/><div id="39613486" class="c"><input type="checkbox" id="c-39613486" checked=""/><div class="controls bullet"><span class="by">thinkingemote</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613348">parent</a><span>|</span><a href="#39613480">next</a><span>|</span><label class="collapse" for="c-39613486">[-]</label><label class="expand" for="c-39613486">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. No one knows! The point is that there are many unknown variables but yet the company estimates the future outcome based on many variables.<p>Personally I think it&#x27;s a kind of extrapolation based on new processes. It&#x27;s more PR than math.<p>The aim of the message is to say that AI can help wider society</div><br/></div></div><div id="39613480" class="c"><input type="checkbox" id="c-39613480" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613348">parent</a><span>|</span><a href="#39613486">prev</a><span>|</span><a href="#39613460">next</a><span>|</span><label class="collapse" for="c-39613480">[-]</label><label class="expand" for="c-39613480">[1 more]</label></div><br/><div class="children"><div class="content">literally nothing, that was the point. There is no way you make such a weirdly specific claim about an indeterminate process without cooking up some invented metric. It&#x27;s like saying &quot;ChatGPT accelerated my next promotion by 24.378 days, this is a totally scientific number, I swear&quot;</div><br/></div></div></div></div></div></div><div id="39613460" class="c"><input type="checkbox" id="c-39613460" checked=""/><div class="controls bullet"><span class="by">zo1</span><span>|</span><a href="#39613043">root</a><span>|</span><a href="#39613104">parent</a><span>|</span><a href="#39613272">prev</a><span>|</span><a href="#39613112">next</a><span>|</span><label class="collapse" for="c-39613460">[-]</label><label class="expand" for="c-39613460">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t know what others think, but to me that&#x27;s just corporate gobbly-gook word-salad that&#x27;s simultaneously true, untrue, and unverifiable all at the same time. They might as well say something like &quot;we&#x27;re forming synergy with humanities proverbial intellect for the betterment of all humanitarian goals such as equity, justice and fairness&quot;.</div><br/></div></div></div></div></div></div><div id="39613112" class="c"><input type="checkbox" id="c-39613112" checked=""/><div class="controls bullet"><span class="by">2pointsomone</span><span>|</span><a href="#39613043">prev</a><span>|</span><a href="#39611631">next</a><span>|</span><label class="collapse" for="c-39613112">[-]</label><label class="expand" for="c-39613112">[1 more]</label></div><br/><div class="children"><div class="content">If anyone paying the right price to access a product, and no underlying technology, making it &quot;open&quot;, isn&#x27;t most of the world&#x27;s technology open? Isn&#x27;t Apple really OpenApple? Isn&#x27;t Oracle really OpenOracle? Apple probably puts out more open-source tech than OpenAI.<p>Does the word mean much anymore, then? Is it nothing more than a sentiment then?<p>Perhaps OpenAI should have renamed itself to &quot;AI for all&quot; or something when they adopted the capped-profit model. Perhaps they should&#x27;ve returned donor funds and turned fully for-profit too. Perhaps that was a genuine resolution and pivot, which every org should be able to allowed to do.<p>Genuine question, I run a nonprofit whose name starts with &quot;open&quot;. But we do explicitly bring closed source work to be more openly licensed, without necessarily making the technology open-source.</div><br/></div></div><div id="39611631" class="c"><input type="checkbox" id="c-39611631" checked=""/><div class="controls bullet"><span class="by">reallymental</span><span>|</span><a href="#39613112">prev</a><span>|</span><a href="#39611548">next</a><span>|</span><label class="collapse" for="c-39611631">[-]</label><label class="expand" for="c-39611631">[5 more]</label></div><br/><div class="children"><div class="content">All that&#x27;s laid bare here, is the carcass of their personalities.<p>None of this screams &quot;I&#x27;m going to change this world&quot;, this organization is mired in politics from the start, no wonder Satya is hedging his bets.<p>edit: grammar</div><br/><div id="39611720" class="c"><input type="checkbox" id="c-39611720" checked=""/><div class="controls bullet"><span class="by">sverhagen</span><span>|</span><a href="#39611631">parent</a><span>|</span><a href="#39611870">next</a><span>|</span><label class="collapse" for="c-39611720">[-]</label><label class="expand" for="c-39611720">[3 more]</label></div><br/><div class="children"><div class="content">You can start a little mom-and-pop store and get plenty of politics. No surprise a billion(s)-dollar company has politics. It&#x27;s everywhere. I&#x27;m not going to claim that it&#x27;s their openness that is allowing us to see it here, but in some companies it spills out in the open, in others it stays within the family, but there&#x27;s always politics!</div><br/><div id="39612309" class="c"><input type="checkbox" id="c-39612309" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#39611631">root</a><span>|</span><a href="#39611720">parent</a><span>|</span><a href="#39611870">next</a><span>|</span><label class="collapse" for="c-39612309">[-]</label><label class="expand" for="c-39612309">[2 more]</label></div><br/><div class="children"><div class="content">Yes but when the politics goes about destroying the company you have a real problem.<p>See Apple in the 90&#x27;s for instance.</div><br/><div id="39612903" class="c"><input type="checkbox" id="c-39612903" checked=""/><div class="controls bullet"><span class="by">HaZeust</span><span>|</span><a href="#39611631">root</a><span>|</span><a href="#39612309">parent</a><span>|</span><a href="#39611870">next</a><span>|</span><label class="collapse" for="c-39612903">[-]</label><label class="expand" for="c-39612903">[1 more]</label></div><br/><div class="children"><div class="content">Problems like being the company with the highest market cap in history for 13 years running!</div><br/></div></div></div></div></div></div><div id="39611870" class="c"><input type="checkbox" id="c-39611870" checked=""/><div class="controls bullet"><span class="by">rchaud</span><span>|</span><a href="#39611631">parent</a><span>|</span><a href="#39611720">prev</a><span>|</span><a href="#39611548">next</a><span>|</span><label class="collapse" for="c-39611870">[-]</label><label class="expand" for="c-39611870">[1 more]</label></div><br/><div class="children"><div class="content">The greatest trick AI has played is convincing the world that it&#x27;s a black box that could genuinely grow out of the control of the powerful, well-connected few that control its development.</div><br/></div></div></div></div><div id="39611548" class="c"><input type="checkbox" id="c-39611548" checked=""/><div class="controls bullet"><span class="by">Leary</span><span>|</span><a href="#39611631">prev</a><span>|</span><a href="#39613397">next</a><span>|</span><label class="collapse" for="c-39611548">[-]</label><label class="expand" for="c-39611548">[4 more]</label></div><br/><div class="children"><div class="content">I guess Sam Altman finally somehow found Ilya Sutskever after saying he didn&#x27;t know where he was and whether he was still working at OpenAI [1]<p>[1]<a href="https:&#x2F;&#x2F;officechai.com&#x2F;startups&#x2F;sam-altman-is-unsure-if-ilya-sutskever-is-still-working-at-openai&#x2F;#:~:text=Sam%20Altman%20has%20said%20that,Economic%20Forum%20Conference%20in%20Davos" rel="nofollow">https:&#x2F;&#x2F;officechai.com&#x2F;startups&#x2F;sam-altman-is-unsure-if-ilya...</a>.</div><br/><div id="39612282" class="c"><input type="checkbox" id="c-39612282" checked=""/><div class="controls bullet"><span class="by">maxlamb</span><span>|</span><a href="#39611548">parent</a><span>|</span><a href="#39613225">next</a><span>|</span><label class="collapse" for="c-39612282">[-]</label><label class="expand" for="c-39612282">[2 more]</label></div><br/><div class="children"><div class="content">Does it say he found him anywhere? All I see in the article are emails to him from 2016</div><br/><div id="39612370" class="c"><input type="checkbox" id="c-39612370" checked=""/><div class="controls bullet"><span class="by">icpmacdo</span><span>|</span><a href="#39611548">root</a><span>|</span><a href="#39612282">parent</a><span>|</span><a href="#39613225">next</a><span>|</span><label class="collapse" for="c-39612370">[-]</label><label class="expand" for="c-39612370">[1 more]</label></div><br/><div class="children"><div class="content">He is a signatory</div><br/></div></div></div></div><div id="39613225" class="c"><input type="checkbox" id="c-39613225" checked=""/><div class="controls bullet"><span class="by">de6u99er</span><span>|</span><a href="#39611548">parent</a><span>|</span><a href="#39612282">prev</a><span>|</span><a href="#39613397">next</a><span>|</span><label class="collapse" for="c-39613225">[-]</label><label class="expand" for="c-39613225">[1 more]</label></div><br/><div class="children"><div class="content">can you please put a space in front of &quot;https&quot;?</div><br/></div></div></div></div><div id="39613397" class="c"><input type="checkbox" id="c-39613397" checked=""/><div class="controls bullet"><span class="by">greatgib</span><span>|</span><a href="#39611548">prev</a><span>|</span><a href="#39612176">next</a><span>|</span><label class="collapse" for="c-39613397">[-]</label><label class="expand" for="c-39613397">[1 more]</label></div><br/><div class="children"><div class="content">From the email exchange:<p>&gt; even though sharing everything is definitely the right strategy in the short and possibly medium term for recruitment purposes<p>Now we have the clear proof that it was their clear intention from the start to abuse from the naivety of everyone pretending to have an open sourcing goal when in fact they knew planned from the beginning to close everything once they would reach a certain amount of success.<p>That sucks...</div><br/></div></div><div id="39612176" class="c"><input type="checkbox" id="c-39612176" checked=""/><div class="controls bullet"><span class="by">advael</span><span>|</span><a href="#39613397">prev</a><span>|</span><a href="#39612859">next</a><span>|</span><label class="collapse" for="c-39612176">[-]</label><label class="expand" for="c-39612176">[3 more]</label></div><br/><div class="children"><div class="content">Like most airing out of drama, this doesn&#x27;t really materially change anything aside from making everyone involved look extremely bad<p>But also, all entities involved looked bad already to observers who weren&#x27;t so deeply rooting for them already that nothing would change their minds, so this is basically tabloid fodder drama in terms of importance as far as I can tell</div><br/><div id="39613310" class="c"><input type="checkbox" id="c-39613310" checked=""/><div class="controls bullet"><span class="by">gitaarik</span><span>|</span><a href="#39612176">parent</a><span>|</span><a href="#39612859">next</a><span>|</span><label class="collapse" for="c-39613310">[-]</label><label class="expand" for="c-39613310">[2 more]</label></div><br/><div class="children"><div class="content">Well, isn&#x27;t it good that the public learns more about the bad stuff they&#x27;re doing?</div><br/><div id="39613752" class="c"><input type="checkbox" id="c-39613752" checked=""/><div class="controls bullet"><span class="by">advael</span><span>|</span><a href="#39612176">root</a><span>|</span><a href="#39613310">parent</a><span>|</span><a href="#39612859">next</a><span>|</span><label class="collapse" for="c-39613752">[-]</label><label class="expand" for="c-39613752">[1 more]</label></div><br/><div class="children"><div class="content">Yes, transparency is perhaps the most important check against power. We are constantly told by governments and corporations alike that there is some dire safety reason they have to do so much secretly, and while rare exceptions where this may actually be true for some temporary situation do exist (often the case in wars, perhaps, though not decades after the fact as governments so often allege), it&#x27;s clear that this is often a lie told for the obvious reason that this secrecy allows powerful people to act without this check. We only get told the lie in the first place because this secrecy breaks expectations of transparency; often - as with openAI - breaks promises that were previously made<p>So we have them airing their dirty laundry because a billionaire sued them for his own petty reasons, having planned to break the promises the organization made that he&#x27;s now suing them over in a similar way. Billionaire is hypocrite, news at eleven. This doesn&#x27;t exonerate the organization. I hope this suit makes people angry. I hope it makes it harder to get away with this facile and infantilizing line about keeping people in the dark to protect them</div><br/></div></div></div></div></div></div><div id="39612859" class="c"><input type="checkbox" id="c-39612859" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#39612176">prev</a><span>|</span><a href="#39611689">next</a><span>|</span><label class="collapse" for="c-39612859">[-]</label><label class="expand" for="c-39612859">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  we felt it was against the mission for any individual to have absolute control over OpenAI<p>This has to be a joke, right? I&#x27;d like to think Altman paused for a second and chuckled to himself after writing - or reading - that.</div><br/></div></div><div id="39611689" class="c"><input type="checkbox" id="c-39611689" checked=""/><div class="controls bullet"><span class="by">baking</span><span>|</span><a href="#39612859">prev</a><span>|</span><a href="#39613216">next</a><span>|</span><label class="collapse" for="c-39611689">[-]</label><label class="expand" for="c-39611689">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Elon said we should announce an initial $1B funding commitment to OpenAI. In total, the non-profit has raised less than $45M from Elon and more than $90M from other donors.<p>This is not reflected in their 990&#x27;s.  They claim $20 million in public support and $70 million in &quot;other income&quot; which is missing the required explanation.<p>Also, why are none of the current board members of OpenAI included as authors here?  Is there a problem in the governance structure?<p>Elon could not legally contribute more than he did without turning OpenAI into a private foundation.  Private foundations are required to give away 5% of their total assets annually and are not permitted to own substantial stakes in for-profit businesses.<p>Showing old emails from people who clearly don&#x27;t understand what they are getting into is not very helpful to their case.  Maybe if they had talked to a lawyer who understood non-profit law, or even just googled it.<p>If the $70 million was in fact a donation instead of income, they fail the public support test and are de facto a private foundation.</div><br/><div id="39612080" class="c"><input type="checkbox" id="c-39612080" checked=""/><div class="controls bullet"><span class="by">mikeyouse</span><span>|</span><a href="#39611689">parent</a><span>|</span><a href="#39612404">next</a><span>|</span><label class="collapse" for="c-39612080">[-]</label><label class="expand" for="c-39612080">[4 more]</label></div><br/><div class="children"><div class="content">A bunch of what you wrote isn&#x27;t accurate..<p>Here&#x27;s the 2020 990 which shows the first 5 years of the org&#x27;s existence (including the time at question for this suit): <a href="https:&#x2F;&#x2F;apps.irs.gov&#x2F;pub&#x2F;epostcard&#x2F;cor&#x2F;810861541_202012_990_2022102420537372.pdf" rel="nofollow">https:&#x2F;&#x2F;apps.irs.gov&#x2F;pub&#x2F;epostcard&#x2F;cor&#x2F;810861541_202012_990_...</a><p>Page 15 is Schedule A Pt 2 which shows the total contributions by year. They did indeed raise ~$133M over that time frame.  Row 5 shows the contributions from any 1 person who contributed more than 2% of their total funding (this excludes other nonprofits) -- so the $41M there is definitely Musk.  So his share was only ~30% of the total and the other 70% was public support which you can confirm in Section C at the bottom of that page.<p>&quot;Public support&quot; includes other nonprofits - and it&#x27;s fine of e.g. Musk &#x27;laundered&#x27; other funding via a DAF or something at a different nonprofit since the funds belong to that nonprofit and they have ultimate discretion over the grant.</div><br/><div id="39612169" class="c"><input type="checkbox" id="c-39612169" checked=""/><div class="controls bullet"><span class="by">baking</span><span>|</span><a href="#39611689">root</a><span>|</span><a href="#39612080">parent</a><span>|</span><a href="#39612404">next</a><span>|</span><label class="collapse" for="c-39612169">[-]</label><label class="expand" for="c-39612169">[3 more]</label></div><br/><div class="children"><div class="content">I think I screwed up.  It has been a while, but it looks like I misread Part II, Section B, Line 10 as $70 million, not $70,000.  Let me check the previous years to see if I&#x27;m thinking of something else.  Thanks for double-checking this.<p>I know they got $20 million from Open Philanthropy which qualifies as public support, so I am still wondering about the other $70 million, but it is not the smoking gun that I thought it was.<p>It has to be made up of donations from individuals under $2.6 million or from other public charities, but not private foundations.</div><br/><div id="39612385" class="c"><input type="checkbox" id="c-39612385" checked=""/><div class="controls bullet"><span class="by">mikeyouse</span><span>|</span><a href="#39611689">root</a><span>|</span><a href="#39612169">parent</a><span>|</span><a href="#39612404">next</a><span>|</span><label class="collapse" for="c-39612385">[-]</label><label class="expand" for="c-39612385">[2 more]</label></div><br/><div class="children"><div class="content">Most rich people setup DAFs alongside their family foundations so that they can make large contributions to this type of org. without triggering disclosure or private foundation tests -- so e.g. Musk will create a DAF at Fidelity Charitable and give them $100M and collect the associated tax break in year 1 -- he can then direct Fidelity to grant $20M&#x2F;year to OpenAI which will show up as Public Support since it&#x27;s coming from another nonprofit entity and Fidelity maintains ultimate discretion over the funds.<p>Edit - Got curious and sure enough - this is the 28,000 page 990 filing for Fidelity Charitable: <a href="https:&#x2F;&#x2F;apps.irs.gov&#x2F;pub&#x2F;epostcard&#x2F;cor&#x2F;110303001_202006_990_2021052818214346.pdf" rel="nofollow">https:&#x2F;&#x2F;apps.irs.gov&#x2F;pub&#x2F;epostcard&#x2F;cor&#x2F;110303001_202006_990_...</a><p>On page 205 there&#x27;s a $3.5M donation to OpenAI from 2019.<p>Likewise here for SVCF on page 237 (<a href="https:&#x2F;&#x2F;apps.irs.gov&#x2F;pub&#x2F;epostcard&#x2F;cor&#x2F;205205488_201912_990_2021033117841113.pdf" rel="nofollow">https:&#x2F;&#x2F;apps.irs.gov&#x2F;pub&#x2F;epostcard&#x2F;cor&#x2F;205205488_201912_990_...</a>) - there&#x27;s a $30M donation to OpenAI in 2019.</div><br/><div id="39612693" class="c"><input type="checkbox" id="c-39612693" checked=""/><div class="controls bullet"><span class="by">trogdor</span><span>|</span><a href="#39611689">root</a><span>|</span><a href="#39612385">parent</a><span>|</span><a href="#39612404">next</a><span>|</span><label class="collapse" for="c-39612693">[-]</label><label class="expand" for="c-39612693">[1 more]</label></div><br/><div class="children"><div class="content">I am an investigative reporter, and I approve of your research tenacity!<p>Nice :)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39613216" class="c"><input type="checkbox" id="c-39613216" checked=""/><div class="controls bullet"><span class="by">nobrains</span><span>|</span><a href="#39611689">prev</a><span>|</span><a href="#39611863">next</a><span>|</span><label class="collapse" for="c-39613216">[-]</label><label class="expand" for="c-39613216">[1 more]</label></div><br/><div class="children"><div class="content">&gt; by opensorucing [sic] everything, we make it easy for someone unscrupulous with access to overwhelming amount of hardware to build an unsafe AI<p>by open sourcing everything, we make it easy for someone unscrupulous with access to overwhelming amount of hardware to build an unsafe BROWSER<p>by open sourcing everything, we make it easy for someone unscrupulous with access to overwhelming amount of hardware to build an unsafe OPERATING SYSTEM</div><br/></div></div><div id="39611863" class="c"><input type="checkbox" id="c-39611863" checked=""/><div class="controls bullet"><span class="by">chjj</span><span>|</span><a href="#39613216">prev</a><span>|</span><a href="#39612984">next</a><span>|</span><label class="collapse" for="c-39611863">[-]</label><label class="expand" for="c-39611863">[11 more]</label></div><br/><div class="children"><div class="content">I find it very strange that OpenAI would post this in the middle of a lawsuit. Shouldn&#x27;t all of these emails come out in discovery anyway? Publishing this only benefits OpenAI if they&#x27;re betting on the case never reaching discovery. It seems like they just want to publish very select emails which paint a certain picture.<p>Also, DKIM signatures are notably absent, not that we could verify them anyway since the emails are heavily redacted.</div><br/><div id="39612185" class="c"><input type="checkbox" id="c-39612185" checked=""/><div class="controls bullet"><span class="by">phire</span><span>|</span><a href="#39611863">parent</a><span>|</span><a href="#39611981">next</a><span>|</span><label class="collapse" for="c-39612185">[-]</label><label class="expand" for="c-39612185">[2 more]</label></div><br/><div class="children"><div class="content">If they just waited until discovery, it would be Musk&#x27;s lawyers that control the narrative, choosing which parts of the emails to focus on publicly, which to ignore and what story to paint around it.<p>As you say, this way, they get to control the narrative. Nothing strange at all.<p>From what I can tell, Musk&#x27;s lawsuit doesn&#x27;t have a much of chance in the first place. I don&#x27;t think he expects to win, it seems to be more a tool in Musk&#x27;s own media push, and while I wouldn&#x27;t bet on it, there is absolutely a chance it won&#x27;t reach discovery.<p>I think OpenAI have quite wisely decided that the real battle here is the court of public opinion. They know it&#x27;s possible to win the court case but lose in the eyes of the public. And they know that Musk has a lot of previous experience (and success) in the this battleground.</div><br/><div id="39612381" class="c"><input type="checkbox" id="c-39612381" checked=""/><div class="controls bullet"><span class="by">chjj</span><span>|</span><a href="#39611863">root</a><span>|</span><a href="#39612185">parent</a><span>|</span><a href="#39611981">next</a><span>|</span><label class="collapse" for="c-39612381">[-]</label><label class="expand" for="c-39612381">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI might think they&#x27;re winning a PR battle by shaping a narrative here, but they are now locked into this narrative, possibly to their detriment in court. Just seems like a bad idea. I find it odd that their lawyers wouldn&#x27;t steer them clear of something like this.<p>&gt; I think OpenAI have quite wisely decided that the real battle here is the court of public opinion.<p>They&#x27;ve failed to win me over. As far as I can tell, their attempted PR victory hinges on a single email with a one-word reply from Musk. Their own emails are far more damning as they give a detailed explanation of why they believe AI should not be open.<p>To an observer who already dislikes Musk, I&#x27;m sure it&#x27;s a PR win. To someone neutral or someone who dislikes both parties, it&#x27;s a PR disaster.</div><br/></div></div></div></div><div id="39611981" class="c"><input type="checkbox" id="c-39611981" checked=""/><div class="controls bullet"><span class="by">EMIRELADERO</span><span>|</span><a href="#39611863">parent</a><span>|</span><a href="#39612185">prev</a><span>|</span><a href="#39612171">next</a><span>|</span><label class="collapse" for="c-39611981">[-]</label><label class="expand" for="c-39611981">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Also, DKIM signatures are notably absent, not that we could verify them anyway since the emails are heavily redacted.<p>What are you implying? Faking emails opens you up to libel. I doubt OpenAI is trying to add another lawsuit to their workload.</div><br/><div id="39612015" class="c"><input type="checkbox" id="c-39612015" checked=""/><div class="controls bullet"><span class="by">chjj</span><span>|</span><a href="#39611863">root</a><span>|</span><a href="#39611981">parent</a><span>|</span><a href="#39612171">next</a><span>|</span><label class="collapse" for="c-39612015">[-]</label><label class="expand" for="c-39612015">[5 more]</label></div><br/><div class="children"><div class="content">&gt; What are you implying?<p>I&#x27;m not implying anything. I&#x27;m pointing out a lack of openness on OpenAI&#x27;s part.</div><br/><div id="39612198" class="c"><input type="checkbox" id="c-39612198" checked=""/><div class="controls bullet"><span class="by">EMIRELADERO</span><span>|</span><a href="#39611863">root</a><span>|</span><a href="#39612015">parent</a><span>|</span><a href="#39612171">next</a><span>|</span><label class="collapse" for="c-39612198">[-]</label><label class="expand" for="c-39612198">[4 more]</label></div><br/><div class="children"><div class="content">Unless it&#x27;s brought up as a point in court, actual exhibits in lawsuits don&#x27;t have DKIM signatures either.</div><br/><div id="39612275" class="c"><input type="checkbox" id="c-39612275" checked=""/><div class="controls bullet"><span class="by">chjj</span><span>|</span><a href="#39611863">root</a><span>|</span><a href="#39612198">parent</a><span>|</span><a href="#39612171">next</a><span>|</span><label class="collapse" for="c-39612275">[-]</label><label class="expand" for="c-39612275">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not making a legal argument.</div><br/><div id="39612482" class="c"><input type="checkbox" id="c-39612482" checked=""/><div class="controls bullet"><span class="by">EMIRELADERO</span><span>|</span><a href="#39611863">root</a><span>|</span><a href="#39612275">parent</a><span>|</span><a href="#39612171">next</a><span>|</span><label class="collapse" for="c-39612482">[-]</label><label class="expand" for="c-39612482">[2 more]</label></div><br/><div class="children"><div class="content">Oh!<p>In that case, let me ask: where have you ever seen DKIM signatures being provided on a public blog post&#x2F;press release?</div><br/><div id="39612555" class="c"><input type="checkbox" id="c-39612555" checked=""/><div class="controls bullet"><span class="by">chjj</span><span>|</span><a href="#39611863">root</a><span>|</span><a href="#39612482">parent</a><span>|</span><a href="#39612171">next</a><span>|</span><label class="collapse" for="c-39612555">[-]</label><label class="expand" for="c-39612555">[1 more]</label></div><br/><div class="children"><div class="content">Nowhere, and I criticize it every time. I&#x27;ve even gone to the lengths of trying to find DKIM keys for published emails in the past[1].<p>But at least those emails were un-redacted. To spell that out for you: in a highly-charged, highly-contentious political setting, emails were published un-redacted and theoretically verifiable with DKIM. No such possibility exists for OpenAI&#x27;s blog post.<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24780798#24785123">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24780798#24785123</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39612171" class="c"><input type="checkbox" id="c-39612171" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#39611863">parent</a><span>|</span><a href="#39611981">prev</a><span>|</span><a href="#39612892">next</a><span>|</span><label class="collapse" for="c-39612171">[-]</label><label class="expand" for="c-39612171">[1 more]</label></div><br/><div class="children"><div class="content">The court of public opinion might be more important in some ways than any real court. People have already begun judging OpenAI based on the lawsuit.</div><br/></div></div><div id="39612892" class="c"><input type="checkbox" id="c-39612892" checked=""/><div class="controls bullet"><span class="by">slimebot80</span><span>|</span><a href="#39611863">parent</a><span>|</span><a href="#39612171">prev</a><span>|</span><a href="#39612984">next</a><span>|</span><label class="collapse" for="c-39612892">[-]</label><label class="expand" for="c-39612892">[1 more]</label></div><br/><div class="children"><div class="content">Musk is blabbering like a broken fountain on Xitter <i>shrug</i><p>Xitter is the #1 source of facts, so - Can&#x27;t blame them for counter balancing a little.</div><br/></div></div></div></div><div id="39612984" class="c"><input type="checkbox" id="c-39612984" checked=""/><div class="controls bullet"><span class="by">swat535</span><span>|</span><a href="#39611863">prev</a><span>|</span><a href="#39613751">next</a><span>|</span><label class="collapse" for="c-39612984">[-]</label><label class="expand" for="c-39612984">[2 more]</label></div><br/><div class="children"><div class="content">Why would anyone even be under the impression that Elon would be pursuing some higher truth or a noble goal by this suite ?<p>This response is comical and ironically proves Musk&#x27;s point that OpenAI is just a profit seeking organization structured in a way to masquerade as a non profit to doge taxes.<p>Basically a clever scheme by Sam, he gets to have his cake and eat it too this way and probably everyone at the leadership level is congratulation themselves for being so brilliant.<p>Look here, the truth is that they have been caught with their pants down and now are just attempting to back peddle.<p>I understand why they won&#x27;t budge because if they do, they will lose all their scam marketing tactics and Nonprofit status.<p>Let&#x27;s hope other AI models catch up quickly, I&#x27;m rooting for OSS to take over this field entirely like UNIX did with.<p>Oh, also, before you lecture me about the &quot;threat of AI&quot;, maybe give me a chat bot that can do basic math first.</div><br/><div id="39613146" class="c"><input type="checkbox" id="c-39613146" checked=""/><div class="controls bullet"><span class="by">DustinBrett</span><span>|</span><a href="#39612984">parent</a><span>|</span><a href="#39613751">next</a><span>|</span><label class="collapse" for="c-39613146">[-]</label><label class="expand" for="c-39613146">[1 more]</label></div><br/><div class="children"><div class="content">Because his actions have shown he is several times.</div><br/></div></div></div></div><div id="39613751" class="c"><input type="checkbox" id="c-39613751" checked=""/><div class="controls bullet"><span class="by">posix86</span><span>|</span><a href="#39612984">prev</a><span>|</span><a href="#39612666">next</a><span>|</span><label class="collapse" for="c-39613751">[-]</label><label class="expand" for="c-39613751">[1 more]</label></div><br/><div class="children"><div class="content">This letter seems to adress why they&#x27;re not open, but not whatsoever why they&#x27;re selling out to Microsoft, which was Musk&#x27;s primary criticism, or am I wrong?</div><br/></div></div><div id="39612666" class="c"><input type="checkbox" id="c-39612666" checked=""/><div class="controls bullet"><span class="by">eftychis</span><span>|</span><a href="#39613751">prev</a><span>|</span><a href="#39612767">next</a><span>|</span><label class="collapse" for="c-39612666">[-]</label><label class="expand" for="c-39612666">[3 more]</label></div><br/><div class="children"><div class="content">Reading the messages:<p>This is a marketing step of course, no sane lawyer would agree to this.
And that is because, I don&#x27;t think they show what they think and want to show.<p>That at some point Elon had an opinion that a lot of money is needed or that OpenAI maybe had no future?
That does not change the duty or obligations of a non-profit to the mission.<p>Also, it is clear some important information has been blacked out. And that critical conversation happened offline.<p>I don&#x27;t think it will do Elon the image pressure they think it will. But if I was Microsoft... I would hedge my bets a lot...<p>This looks more and more as giving fuel to a dissolution action of OpenAI as a non-profit than anything else.</div><br/><div id="39613098" class="c"><input type="checkbox" id="c-39613098" checked=""/><div class="controls bullet"><span class="by">nprateem</span><span>|</span><a href="#39612666">parent</a><span>|</span><a href="#39612767">next</a><span>|</span><label class="collapse" for="c-39613098">[-]</label><label class="expand" for="c-39613098">[2 more]</label></div><br/><div class="children"><div class="content">And what would happen? 2 minutes after being dissolved, ClosedAI is founded and hires all the employees.</div><br/><div id="39613636" class="c"><input type="checkbox" id="c-39613636" checked=""/><div class="controls bullet"><span class="by">eftychis</span><span>|</span><a href="#39612666">root</a><span>|</span><a href="#39613098">parent</a><span>|</span><a href="#39612767">next</a><span>|</span><label class="collapse" for="c-39613636">[-]</label><label class="expand" for="c-39613636">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps even before the dissolution.<p>But the science and IP become public and open or under a non-profit that is tasked with opening them. And for-profit segments are stripped of any exclusive rights that arose from the OpenAI.<p>The irony is that the dissolution, overseeing by third special referee or permanent injunction (e.g. the Musk suit) of OpenAI is the only ways OpenAI is &quot;opening their AI.&quot;</div><br/></div></div></div></div></div></div><div id="39612767" class="c"><input type="checkbox" id="c-39612767" checked=""/><div class="controls bullet"><span class="by">globalvariablex</span><span>|</span><a href="#39612666">prev</a><span>|</span><a href="#39612917">next</a><span>|</span><label class="collapse" for="c-39612767">[-]</label><label class="expand" for="c-39612767">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&quot;Given both the competitive landscape and the safety implications of large-scale models like GPT-4, this report contains no further details about the architecture (including model size), hardware, training compute, dataset construction,training method, or similar.&quot;<p>I am not a fan of the &quot;enjoy the fruits but not the science&quot; statement they made in the blog. The quote above was from GPT-4&#x27;s technical paper. I&#x27;ll go the extra mile and steel man a counter-argument and say they&#x27;re seeking a competitive advantage to secure more in investments so they can stick to their mission statements of making safe AGI, but I think we can all see where this line of thinking of is going further down the line. Building your stack around an academic research paper from a rival company then refusing to publish your contributions is terribly disappointing imo. I hope this won&#x27;t be a trend that other companies participate in.</div><br/></div></div><div id="39612917" class="c"><input type="checkbox" id="c-39612917" checked=""/><div class="controls bullet"><span class="by">sgammon</span><span>|</span><a href="#39612767">prev</a><span>|</span><a href="#39612317">next</a><span>|</span><label class="collapse" for="c-39612917">[-]</label><label class="expand" for="c-39612917">[3 more]</label></div><br/><div class="children"><div class="content">Has anyone else noticed the redactions have variable widths?<p>A little video of devtools:<p><a href="https:&#x2F;&#x2F;customer-zppj20fjkae6kidj.cloudflarestream.com&#x2F;e28e5f27f5f41c883e4adb24767b5b30&#x2F;watch" rel="nofollow">https:&#x2F;&#x2F;customer-zppj20fjkae6kidj.cloudflarestream.com&#x2F;e28e5...</a><p>I remember seeing techniques which could decode such redactions from PDFs. I don&#x27;t know why the widths would be included unless it was intentional (stylistic, maybe? but it would be a bear to code), or perhaps exported from something like Adobe Acrobat.<p>Elon&#x27;s email is one solid redaction block, while the email body is broken up into widths that don&#x27;t seem to be consistent.</div><br/><div id="39613141" class="c"><input type="checkbox" id="c-39613141" checked=""/><div class="controls bullet"><span class="by">buzzert</span><span>|</span><a href="#39612917">parent</a><span>|</span><a href="#39612317">next</a><span>|</span><label class="collapse" for="c-39613141">[-]</label><label class="expand" for="c-39613141">[2 more]</label></div><br/><div class="children"><div class="content">Somebody used Claude to attempt to un-redact the missing text, and the result it generated is scarily convincing:<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;skirano&#x2F;status&#x2F;1765238754615181531" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;skirano&#x2F;status&#x2F;1765238754615181531</a></div><br/><div id="39613235" class="c"><input type="checkbox" id="c-39613235" checked=""/><div class="controls bullet"><span class="by">denysvitali</span><span>|</span><a href="#39612917">root</a><span>|</span><a href="#39613141">parent</a><span>|</span><a href="#39612317">next</a><span>|</span><label class="collapse" for="c-39613235">[-]</label><label class="expand" for="c-39613235">[1 more]</label></div><br/><div class="children"><div class="content">Except the CC part. Why would you include the co-founder of your competitor in an email describing how to win over said competitor?</div><br/></div></div></div></div></div></div><div id="39612317" class="c"><input type="checkbox" id="c-39612317" checked=""/><div class="controls bullet"><span class="by">woopsn</span><span>|</span><a href="#39612917">prev</a><span>|</span><a href="#39612810">next</a><span>|</span><label class="collapse" for="c-39612317">[-]</label><label class="expand" for="c-39612317">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure who they are attempting to convince of what with this communication?<p>Nobody who doesn&#x27;t know who REDACTED is cares what REDACTED thought of the issue.<p>This is again some of the least professional comms I&#x27;ve seen from a Microsoft entity. We&#x27;ll see what the evidence is ourselves if and when the case goes to court.</div><br/></div></div><div id="39612810" class="c"><input type="checkbox" id="c-39612810" checked=""/><div class="controls bullet"><span class="by">joshxyz</span><span>|</span><a href="#39612317">prev</a><span>|</span><a href="#39612446">next</a><span>|</span><label class="collapse" for="c-39612810">[-]</label><label class="expand" for="c-39612810">[1 more]</label></div><br/><div class="children"><div class="content">Okay, so Open in OpenAI means people get to enjoy the free version of the fremium product.</div><br/></div></div><div id="39612446" class="c"><input type="checkbox" id="c-39612446" checked=""/><div class="controls bullet"><span class="by">ergocoder</span><span>|</span><a href="#39612810">prev</a><span>|</span><a href="#39613309">next</a><span>|</span><label class="collapse" for="c-39612446">[-]</label><label class="expand" for="c-39612446">[1 more]</label></div><br/><div class="children"><div class="content">The anthropic guy must feel like they have made the best decision.<p>I love the drama. It is very entertaining. I&#x27;m glad OpenAI decided to start as a non profit. I feel like they will never be able to get away with it. The issue will keep lingering.</div><br/></div></div><div id="39613309" class="c"><input type="checkbox" id="c-39613309" checked=""/><div class="controls bullet"><span class="by">jimkleiber</span><span>|</span><a href="#39612446">prev</a><span>|</span><a href="#39612113">next</a><span>|</span><label class="collapse" for="c-39613309">[-]</label><label class="expand" for="c-39613309">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We are dedicated to the OpenAI mission and have pursued it <i>every step of the way.</i> (emphasis added)<p>&gt; We intend to move to dismiss <i>all of Elon’s claims.</i> (emphasis added)<p>I feel somewhat surprised but more worried that people working in a space riddled with so much uncertainty seem to use so much certainty in their statements.</div><br/></div></div><div id="39612113" class="c"><input type="checkbox" id="c-39612113" checked=""/><div class="controls bullet"><span class="by">matt_heimer</span><span>|</span><a href="#39613309">prev</a><span>|</span><a href="#39613503">next</a><span>|</span><label class="collapse" for="c-39612113">[-]</label><label class="expand" for="c-39612113">[3 more]</label></div><br/><div class="children"><div class="content">If you are going to simulate blacking out email addresses maybe don&#x27;t preserve spacing.</div><br/><div id="39612311" class="c"><input type="checkbox" id="c-39612311" checked=""/><div class="controls bullet"><span class="by">WatchDog</span><span>|</span><a href="#39612113">parent</a><span>|</span><a href="#39613503">next</a><span>|</span><label class="collapse" for="c-39612311">[-]</label><label class="expand" for="c-39612311">[2 more]</label></div><br/><div class="children"><div class="content">I presume they persevered the spacing to avoid any accusations of being misleading as to the redacted information.<p>This kind of in place redaction seems to be the typical way that documents are submitted to courts, or at least it was the same way that the emails Elon provided were redacted[0].<p>[0]: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;TechEmails&#x2F;status&#x2F;1763633741807960498" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;TechEmails&#x2F;status&#x2F;1763633741807960498</a></div><br/><div id="39612532" class="c"><input type="checkbox" id="c-39612532" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#39612113">root</a><span>|</span><a href="#39612311">parent</a><span>|</span><a href="#39613503">next</a><span>|</span><label class="collapse" for="c-39612532">[-]</label><label class="expand" for="c-39612532">[1 more]</label></div><br/><div class="children"><div class="content">Surely it would be more effective to reduce every censorship bar to 1 character width.</div><br/></div></div></div></div></div></div><div id="39613503" class="c"><input type="checkbox" id="c-39613503" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#39612113">prev</a><span>|</span><a href="#39612830">next</a><span>|</span><label class="collapse" for="c-39613503">[-]</label><label class="expand" for="c-39613503">[1 more]</label></div><br/><div class="children"><div class="content">The timestamps of the emails are interesting. apparently they work at 3:40 AM but also at midday and at 8 AM</div><br/></div></div><div id="39612830" class="c"><input type="checkbox" id="c-39612830" checked=""/><div class="controls bullet"><span class="by">gibsonf1</span><span>|</span><a href="#39613503">prev</a><span>|</span><a href="#39612523">next</a><span>|</span><label class="collapse" for="c-39612830">[-]</label><label class="expand" for="c-39612830">[2 more]</label></div><br/><div class="children"><div class="content">I find it interesting that they promote the idea that they are pursuing AGI when they don&#x27;t even have any I yet in their products.</div><br/><div id="39613321" class="c"><input type="checkbox" id="c-39613321" checked=""/><div class="controls bullet"><span class="by">gitaarik</span><span>|</span><a href="#39612830">parent</a><span>|</span><a href="#39612523">next</a><span>|</span><label class="collapse" for="c-39613321">[-]</label><label class="expand" for="c-39613321">[1 more]</label></div><br/><div class="children"><div class="content">If it would already be in their products, there wouldn&#x27;t be much to pursue, right?</div><br/></div></div></div></div><div id="39612523" class="c"><input type="checkbox" id="c-39612523" checked=""/><div class="controls bullet"><span class="by">rifty</span><span>|</span><a href="#39612830">prev</a><span>|</span><a href="#39613176">next</a><span>|</span><label class="collapse" for="c-39612523">[-]</label><label class="expand" for="c-39612523">[1 more]</label></div><br/><div class="children"><div class="content">The manner in which they became for-profit does not feel like an exact comparison to Elon thinking that they should become private to be competitive. For example, merging with Tesla isn&#x27;t the same path the non-profit OpenAI went even if the end state is similar.<p>Though I think the blog post will probably achieve its messaging goals of diminishing Elon&#x27;s character to their own public status... &quot;Yeah you think we suck, but it would be no tangible difference to you if Elon had run it, so you should know he sucks too.&quot;</div><br/></div></div><div id="39613176" class="c"><input type="checkbox" id="c-39613176" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#39612523">prev</a><span>|</span><a href="#39612476">next</a><span>|</span><label class="collapse" for="c-39613176">[-]</label><label class="expand" for="c-39613176">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m kind of surprised they&#x27;d post something this substantial without any apparent proofreading (given the repetition around the Tesla stuff).</div><br/></div></div><div id="39612476" class="c"><input type="checkbox" id="c-39612476" checked=""/><div class="controls bullet"><span class="by">runeb</span><span>|</span><a href="#39613176">prev</a><span>|</span><label class="collapse" for="c-39612476">[-]</label><label class="expand" for="c-39612476">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It seems to me that OpenAI today is burning cash and that the funding model cannot reach the scale to seriously compete with Google (an 800B company). If you can&#x27;t seriously compete but continue to do research in open, you might in fact be making things worse and helping them out “for free”, because any advances are fairly easy for them to copy and immediately incorporate, at scale.<p>It was a reasonable concern, funny that it turned out the other way with the transformer</div><br/></div></div></div></div></div></div></div></body></html>