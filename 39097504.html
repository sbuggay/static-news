<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706086859910" as="style"/><link rel="stylesheet" href="styles.css?v=1706086859910"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.abortretry.fail/p/the-itanic-saga">The Itanic Saga: The History of VLIW and Itanium</a> <span class="domain">(<a href="https://www.abortretry.fail">www.abortretry.fail</a>)</span></div><div class="subtext"><span>blakespot</span> | <span>33 comments</span></div><br/><div><div id="39110511" class="c"><input type="checkbox" id="c-39110511" checked=""/><div class="controls bullet"><span class="by">cpr</span><span>|</span><a href="#39112982">next</a><span>|</span><label class="collapse" for="c-39110511">[-]</label><label class="expand" for="c-39110511">[5 more]</label></div><br/><div class="children"><div class="content">Was at Multiflow (Yale spinoff with Josh Fisher and John O&#x27;Donnell) &#x27;85-90 and saw the VLIW problem up close (was in the OS group, eventually running it).<p>The main problem was compiler complexity -- the hoped-for &quot;junk parallelism&quot; gains really never panned out (maybe 2-3X?), so the compiler was best when it could discover, or be fed, vector operations.<p>But Convex (main competitor at the time) already had the &quot;minisupercomputer vector&quot; market locked up.<p>So Multiflow folded in early &#x27;90 (I had already bailed, seeing the handwriting mural) after burning through $60M in VC, which was a record at the time, I believe.</div><br/><div id="39114926" class="c"><input type="checkbox" id="c-39114926" checked=""/><div class="controls bullet"><span class="by">Taniwha</span><span>|</span><a href="#39110511">parent</a><span>|</span><a href="#39114461">next</a><span>|</span><label class="collapse" for="c-39114926">[-]</label><label class="expand" for="c-39114926">[1 more]</label></div><br/><div class="children"><div class="content">I worked at Chromatic, we built a series of 2-wide VLIWs, writing a compiler (actually just the assembler) that could extract that parallelism was pretty easy, just some low level register flow analysis, I can imagine getting something like 6 way would be a lot harder though</div><br/></div></div><div id="39114461" class="c"><input type="checkbox" id="c-39114461" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#39110511">parent</a><span>|</span><a href="#39114926">prev</a><span>|</span><a href="#39112864">next</a><span>|</span><label class="collapse" for="c-39114461">[-]</label><label class="expand" for="c-39114461">[1 more]</label></div><br/><div class="children"><div class="content">Funny how today burning through that amount is entirely ordinary and expected for most startups working on much more trivial problems.<p>Just the other day it was reported that Brex, an expense management SaaS, has a $17M &#x2F; month burn rate. That’s almost $60M in one quarter.</div><br/></div></div><div id="39112864" class="c"><input type="checkbox" id="c-39112864" checked=""/><div class="controls bullet"><span class="by">OhMeadhbh</span><span>|</span><a href="#39110511">parent</a><span>|</span><a href="#39114461">prev</a><span>|</span><a href="#39112982">next</a><span>|</span><label class="collapse" for="c-39112864">[-]</label><label class="expand" for="c-39112864">[2 more]</label></div><br/><div class="children"><div class="content">And hilariously*, Convex was eventually eaten by HP.  Though the PowerPC Altivec&#x2F;Velocity engine always looked a lot like Parsec to me.  The past lives on in weird places.<p>[*] And by &quot;hilariously,&quot; I mean &quot;painfully.&quot;</div><br/><div id="39113542" class="c"><input type="checkbox" id="c-39113542" checked=""/><div class="controls bullet"><span class="by">mkhnews</span><span>|</span><a href="#39110511">root</a><span>|</span><a href="#39112864">parent</a><span>|</span><a href="#39112982">next</a><span>|</span><label class="collapse" for="c-39113542">[-]</label><label class="expand" for="c-39113542">[1 more]</label></div><br/><div class="children"><div class="content">Was at Convex and then HP (and then Convey) and worked quite hard porting&#x2F;optimizing numerical&#x2F;scientific apps for the I2.  Eventually, I think performance for some apps was ok, I mean considering a 900 Mhz clock and all.</div><br/></div></div></div></div></div></div><div id="39112982" class="c"><input type="checkbox" id="c-39112982" checked=""/><div class="controls bullet"><span class="by">ghaff</span><span>|</span><a href="#39110511">prev</a><span>|</span><a href="#39112933">next</a><span>|</span><label class="collapse" for="c-39112982">[-]</label><label class="expand" for="c-39112982">[8 more]</label></div><br/><div class="children"><div class="content">I actually have a short book on the Itanic&#x2F;Itanium done and planned to have it released as a free download by now. But various schedule-related stuff happened and it just hasn&#x27;t happened yet.<p>I was a mostly hardware-focused industry analyst during Itanium&#x27;s heyday so I find the topic really interesting. From a technical perspective, compilers (and dependency on them) certainly played a role but there were a bunch of other lessons too around market timing, partner strategies, fighting the last war, etc.</div><br/><div id="39113803" class="c"><input type="checkbox" id="c-39113803" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#39112982">parent</a><span>|</span><a href="#39113018">next</a><span>|</span><label class="collapse" for="c-39113803">[-]</label><label class="expand" for="c-39113803">[2 more]</label></div><br/><div class="children"><div class="content">Curious question on the period.<p>Assuming Itanium released as actually happened... (timeline, performance, compiler support, etc)<p>What else would have had to change for it to get market adoption and come out on top? (competitors, x86 clock rate running into ceiling sooner, etc)</div><br/><div id="39115178" class="c"><input type="checkbox" id="c-39115178" checked=""/><div class="controls bullet"><span class="by">hinoki</span><span>|</span><a href="#39112982">root</a><span>|</span><a href="#39113803">parent</a><span>|</span><a href="#39113018">next</a><span>|</span><label class="collapse" for="c-39115178">[-]</label><label class="expand" for="c-39115178">[1 more]</label></div><br/><div class="children"><div class="content">My uninformed opinion: lots of speculative execution is good for single core performance, but terrible for power efficiency.<p>Have data centres always been limited by power&#x2F;cooling costs, or did that only become a major consideration during the move to more commodity hardware?</div><br/></div></div></div></div><div id="39113018" class="c"><input type="checkbox" id="c-39113018" checked=""/><div class="controls bullet"><span class="by">BirAdam</span><span>|</span><a href="#39112982">parent</a><span>|</span><a href="#39113803">prev</a><span>|</span><a href="#39113585">next</a><span>|</span><label class="collapse" for="c-39113018">[-]</label><label class="expand" for="c-39113018">[2 more]</label></div><br/><div class="children"><div class="content">Do it, do it, do it!</div><br/><div id="39113040" class="c"><input type="checkbox" id="c-39113040" checked=""/><div class="controls bullet"><span class="by">ghaff</span><span>|</span><a href="#39112982">root</a><span>|</span><a href="#39113018">parent</a><span>|</span><a href="#39113585">next</a><span>|</span><label class="collapse" for="c-39113040">[-]</label><label class="expand" for="c-39113040">[1 more]</label></div><br/><div class="children"><div class="content">I will but I want to use it as part of a website relaunch and, for various reasons, the appropriate timing of that relaunch slipped out.</div><br/></div></div></div></div><div id="39113585" class="c"><input type="checkbox" id="c-39113585" checked=""/><div class="controls bullet"><span class="by">demondemidi</span><span>|</span><a href="#39112982">parent</a><span>|</span><a href="#39113018">prev</a><span>|</span><a href="#39113528">next</a><span>|</span><label class="collapse" for="c-39113585">[-]</label><label class="expand" for="c-39113585">[2 more]</label></div><br/><div class="children"><div class="content">I worked on Merced post-silicon, and McKinley presilicon. I wasn&#x27;t an architect on the project, I just worked on keeping the power grid alive and thermals under control. It reminded me of working on the 486: the team was small and engaged, even though HP was problematic for parts of it. Pentium Pro was sucking up all the marketing air, so we were kind of left alone to do our own thing since the part wasn&#x27;t making money yet. This was also during the corporate wide transition to Linux, removing AIX&#x2F;SunOS&#x2F;HPUX.  I had a Merced in my office but sadly it was running linux in 32-bit compatibility mode, which is where we spent a lot of time fixing bugs because we knew lots of people weren&#x27;t going to port to IA64 right away, and that ate up a ton of debug resources. The world was still migrating to Windows NT 3.5 and Windows 95, so migrating to 64 bit was way too soon. I don&#x27;t remember when the linux kernel finally ported to IA64, but it seemed odd to have a platform without an OS (or an OS running in 32-bit mode). We had plenty of emulators, there&#x27;s no reason why pre-silicon kernel development couldn&#x27;t have happened faster (which was what HP was supposed to be doing). Kind of a bummer but it was a fun time, before the race to 1 GHz became the next $$$ sink &#x2F; pissing contest.</div><br/><div id="39114276" class="c"><input type="checkbox" id="c-39114276" checked=""/><div class="controls bullet"><span class="by">hawflakes</span><span>|</span><a href="#39112982">root</a><span>|</span><a href="#39113585">parent</a><span>|</span><a href="#39113528">next</a><span>|</span><label class="collapse" for="c-39114276">[-]</label><label class="expand" for="c-39114276">[1 more]</label></div><br/><div class="children"><div class="content">I was at HP pre-Merced tape-out and HP did have a number of simulators available. I worked on a compiler-related team so we were downstream.<p>As for running linux in 32-bit compatibility mode, wasn&#x27;t that the worst of all worlds on Merced? When I was there which was pre-Merced tape-out, a tiny bit of the chip was devoted to the IVE (Intel Value Engine) which the docs stated were supposed to be just good enough to book the firmware and then jump into IA64 mode. I figured at the time that this was the goal — boot in 32-bit x86 and then jump to 64-bit mode.</div><br/></div></div></div></div></div></div><div id="39112933" class="c"><input type="checkbox" id="c-39112933" checked=""/><div class="controls bullet"><span class="by">quic_bcain</span><span>|</span><a href="#39112982">prev</a><span>|</span><a href="#39101843">next</a><span>|</span><label class="collapse" for="c-39112933">[-]</label><label class="expand" for="c-39112933">[3 more]</label></div><br/><div class="children"><div class="content">A modern history of VLIW should also include mention the Hexagon FSP architecture used by Qualcomm in its SoCs.<p>With a smaller target market it&#x27;s probably more sustainable than Itanium was.<p>Disclaimer: Qualcomm employee working on hexagon toolchain.</div><br/><div id="39115145" class="c"><input type="checkbox" id="c-39115145" checked=""/><div class="controls bullet"><span class="by">p_l</span><span>|</span><a href="#39112933">parent</a><span>|</span><a href="#39114376">next</a><span>|</span><label class="collapse" for="c-39115145">[-]</label><label class="expand" for="c-39115145">[1 more]</label></div><br/><div class="children"><div class="content">Also, GPU VLIW architectures (including GCN and it&#x27;s successors CDNA and RDNA) and yes, various coprocessors.<p>Once heard comparison that Itanium was pretty good for a fast DSP, but too expensive XD</div><br/></div></div><div id="39114376" class="c"><input type="checkbox" id="c-39114376" checked=""/><div class="controls bullet"><span class="by">chasil</span><span>|</span><a href="#39112933">parent</a><span>|</span><a href="#39115145">prev</a><span>|</span><a href="#39101843">next</a><span>|</span><label class="collapse" for="c-39114376">[-]</label><label class="expand" for="c-39114376">[1 more]</label></div><br/><div class="children"><div class="content">Sophie Wilson also mentions Firepath in several of her YouTube lectures.</div><br/></div></div></div></div><div id="39101843" class="c"><input type="checkbox" id="c-39101843" checked=""/><div class="controls bullet"><span class="by">gregw2</span><span>|</span><a href="#39112933">prev</a><span>|</span><a href="#39113856">next</a><span>|</span><label class="collapse" for="c-39101843">[-]</label><label class="expand" for="c-39101843">[12 more]</label></div><br/><div class="children"><div class="content">I’d be interested in understanding why the compilers never panned out but have never seen a good writeup on that. Or why people thought the compilers would be able to succeed in the first place at the mission.</div><br/><div id="39103147" class="c"><input type="checkbox" id="c-39103147" checked=""/><div class="controls bullet"><span class="by">clausecker</span><span>|</span><a href="#39101843">parent</a><span>|</span><a href="#39113856">next</a><span>|</span><label class="collapse" for="c-39103147">[-]</label><label class="expand" for="c-39103147">[11 more]</label></div><br/><div class="children"><div class="content">There are a number of reasons for the Itanium&#x27;s poor performance, and it&#x27;s the combination of these various factors that did it in.  I wasn&#x27;t present back in the Itanium&#x27;s heyday, but this is what I gathered.<p>As a quick recap, superscalar processors have multiple execution units, each of which can execute one instruction each cycle.  So if you have three execution units, your CPU can execute up to three instructions every cycle.  The conventional way to make use of the power of more than one execution unit is to have an out-of-order design, where a complicated mechanism (Tomasulo algorithm) decodes multiple instructions in parallel, tracks their dependencies and dispatches them onto execution units as they can be executed.  Dependencies are resolved by having a large physical register file, which is dynamically mapped onto the programmer-visible logical register file (register renaming).  This works well, but is notoriously complex to implement and requires a couple of extra pipeline stages before decode and execution, increasing the latency of mispredicted branches.<p>The idea of VLIW architectures was to improve on this idea by moving the decision which instruction to execute on which port to the compiler.  The compiler, having prescient knowledge about what your code is going to do next, can compute the optimal assignment of instructions to execution units.  Each instruction word is a pack of multiple instructions, one for each port, that are executed simultaneously (these words become very wide, hence VLIW for Very Long Instruction Word). In essence, all the bits of the out-of-order mechanism between decoding and execution ports can be done away with and the decoder is much simpler, too.<p>However, things fail in practice:<p>* the whole idea hinges on the compiler being able to figure out the correct instruction schedule ahead of time.
   While feasible for Intel&#x27;s&#x2F;HP&#x27;s in house compiler team, the authors of other toolchains largely did not bother,
   instead opting for more conventional code generation that did not performed all too well.<p>* This issue was exacerbated by the Itanium&#x27;s dreadful model for fast memory loads.  You see, loads can take a
   long time to finish, especially if cache misses or page faults occur.  To fix that, the Itanium has the option
   to do a speculative load, which may or may not succeed at a later point.  So you can do a load from a dubious
   pointer, then check if the pointer is fine (e.g. is it in bounds?  Is it a null pointer?), and only once it has
   been validated you make use of the result.  This allows you to hide the latency of the load, significantly
   speeding up typical business logic.  However, the load can still fail (e.g. due to to pagefault), in which case
   your code has to roll back to where the load should be performed and then do a conventional load as a back-up.
   Understandably, few, if any compilers ever made use of this feature and load latency was dealt with rather
   poorly.<p>* Relatedly, the latency of some instructions like loads and division is variable and cannot easily be predicted.
   So there usually isn&#x27;t even the one perfect schedule the compiler could find.  Turns out the schedule is much
   better when you leave it to the Tomasulo mechanism, which has accurate knowledge of the latency of already
   executing long-latency instructions.<p>* By design, VLIW instruction sets encode a lot about how the execution units work in the instruction format.  For
   example, Itanium is designed for a machine with three execution units and each instruction pack has up to three
   instructions, one for each of them.  But what if you want to put more execution units into the CPU in a future
   iteration of the design?  Well, it&#x27;s not straightforward.  One approach is to ship executables in a bytecode,
   which is only scheduled and encoded on the machine it is installed on, allowed the instruction encoding and thus
   number of ports to vary.  Intel had chosen a different approach and instead implemented later Itanium CPUs as
   out-of-order designs, combining the worst of both worlds.<p>* Due to not having register renaming, VLIW architectures conventionally have a large register file (128 registers
   in the case of the Itanium).  This slows down context switches, further reducing performance.  Out-of-order CPUs
   can cheat by having a comparably small programmer-visible state, with most of the state hidden in the bowels of
   the processor and consequently not in need of saving or restoring.<p>* Branch prediction rapidly grew more and more accurate shortly after the Itanium&#x27;s release, reducing the importance
   of fast recovery from mispredictions.  These days, branch prediction is up to 99% accurate and out-of-order CPUs
   can evaluate multiple branches per cycle using speculative execution.  A feature, that is not possible with a
   straightforward VLIW design due to the lack of register renaming.  So Intel locked itself out of one of the most
   crucial strategies for better performance with this approach.<p>* Another enginering issue was that x86 simulation on the Itanium performed quite poorly, giving existing customers
   no incentive to switch.  And those that did decide to switch found that if they invest into porting their
   software, they might as well make it fully portable and be independent of the architecture.  This is the same problem
   that led to the death of DEC: by forcing their customers to rewrite all the VAX software for the Alpha, the created
   a bunch of customers that were no longer locked into their ecosystem and could now buy whatever UNIX box was cheapest
   on the free market.</div><br/><div id="39105192" class="c"><input type="checkbox" id="c-39105192" checked=""/><div class="controls bullet"><span class="by">Kon-Peki</span><span>|</span><a href="#39101843">root</a><span>|</span><a href="#39103147">parent</a><span>|</span><a href="#39112834">next</a><span>|</span><label class="collapse" for="c-39105192">[-]</label><label class="expand" for="c-39105192">[4 more]</label></div><br/><div class="children"><div class="content">&gt; To fix that, the Itanium has the option to do a speculative load, which may or may not succeed at a later point. So you can do a load from a dubious pointer, then check if the pointer is fine (e.g. is it in bounds? Is it a null pointer?), and only once it has been validated you make use of the result.<p>Way back in the day, as a fairly young engineer, I was assigned to a project to get a bunch of legacy code migrated from Alpha to Itanium.  The assignment was to &quot;make it compile, run, and pass the tests.  Do nothing else. At all.&quot;<p>We were using the Intel C compiler on OpenVMS and every once in a while would encounter a crash in a block of code that looked something like this:<p><pre><code>   if(ptr != NULL &amp;&amp; ptr-&gt;val &gt; 0) {
     &#x2F;&#x2F;do something
   } else {
     &#x2F;&#x2F;init the ptr
   }
</code></pre>
It was evaluating both parts of the if statement simultaneously and crashing on the second.  Not being allowed to spend too much time debugging or investigating the compiler options, we did the following:<p><pre><code>   if(ptr != NULL) {
     if(ptr-&gt;val &gt; 0) {
       &#x2F;&#x2F;do something
     }
   } else {
     &#x2F;&#x2F;init the ptr
   }
</code></pre>
Which resolved the problem!<p>EDIT - I recognize that the above change introduces a potential bug in the program ;) Obviously I wasn&#x27;t copying code verbatim - it was 10-15 years ago!  But you get the picture - the compiler was wonky, even the one you paid money for.</div><br/><div id="39114647" class="c"><input type="checkbox" id="c-39114647" checked=""/><div class="controls bullet"><span class="by">quux</span><span>|</span><a href="#39101843">root</a><span>|</span><a href="#39105192">parent</a><span>|</span><a href="#39113501">next</a><span>|</span><label class="collapse" for="c-39114647">[-]</label><label class="expand" for="c-39114647">[1 more]</label></div><br/><div class="children"><div class="content">Is this one of those rare cases where using a goto would be reasonable?</div><br/></div></div><div id="39113501" class="c"><input type="checkbox" id="c-39113501" checked=""/><div class="controls bullet"><span class="by">jandrese</span><span>|</span><a href="#39101843">root</a><span>|</span><a href="#39105192">parent</a><span>|</span><a href="#39114647">prev</a><span>|</span><a href="#39112734">next</a><span>|</span><label class="collapse" for="c-39113501">[-]</label><label class="expand" for="c-39113501">[1 more]</label></div><br/><div class="children"><div class="content">When I was learning C many years ago I was warned that some compilers don&#x27;t support boolean short circuiting and thus you had to be careful with it.</div><br/></div></div></div></div><div id="39112834" class="c"><input type="checkbox" id="c-39112834" checked=""/><div class="controls bullet"><span class="by">acdha</span><span>|</span><a href="#39101843">root</a><span>|</span><a href="#39103147">parent</a><span>|</span><a href="#39105192">prev</a><span>|</span><a href="#39110859">next</a><span>|</span><label class="collapse" for="c-39112834">[-]</label><label class="expand" for="c-39112834">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the whole idea hinges on the compiler being able to figure out the correct instruction schedule ahead of time. While feasible for Intel&#x27;s&#x2F;HP&#x27;s in house compiler team, the authors of other toolchains largely did not bother, instead opting for more conventional code generation that did not performed all too well.<p>I definitely think that keeping their compilers as an expensive license was a somewhat legendary bit of self-sabotage but I’m not sure it would’ve helped even if they’d given them away or merged everything into GCC. I worked for a commercial software vendor at the time before moving into web development, and it seemed like they basically over-focused on HPC benchmarks and a handful of other things like encryption. All of the business code we tried was usually slower even before you considered price, and nobody wanted to spend time hand-coding it hoping to make it less uneven. I do sometimes wonder if Intel’s compiler team would have been able to make it more competitive now with LLVM, WASM, etc. making the general problem of optimizing everything more realistic but I think the areas where the concept works best are increasingly sewn up by GPUs.<p>Your comment with DEC was spot-on. A lot of people I met had memories of the microcomputer era and were not keen on locking themselves in. The company I worked for had a pretty large support matrix because we had customers running most of the “open systems” platforms to ensure they could switch easily if one vendor got greedy.</div><br/></div></div><div id="39110859" class="c"><input type="checkbox" id="c-39110859" checked=""/><div class="controls bullet"><span class="by">sillywalk</span><span>|</span><a href="#39101843">root</a><span>|</span><a href="#39103147">parent</a><span>|</span><a href="#39112834">prev</a><span>|</span><a href="#39114380">next</a><span>|</span><label class="collapse" for="c-39110859">[-]</label><label class="expand" for="c-39110859">[1 more]</label></div><br/><div class="children"><div class="content">&gt;By design, VLIW instruction sets encode a lot about how the execution units work in the instruction format. For example, Itanium is designed for a machine with three execution units and each instruction pack has up to three instructions, one for each of them. But what if you want to put more execution units into the CPU in a future iteration of the design? Well, it&#x27;s not straightforward. One approach is to ship executables in a bytecode, which is only scheduled and encoded on the machine it is installed on, allowed the instruction encoding and thus number of ports to vary.<p>This was how Sun&#x27;s MAJC[0] worked -<p>&quot; For instance, if a particular implementation took three cycles to complete a floating-point multiplication, MAJC compilers would attempt to schedule in other instructions that took three cycles to complete and were not currently stalled. A change in the actual implementation might reduce this delay to only two instructions, however, and the compiler would need to be aware of this change.<p>This means that the compiler was not tied to MAJC as a whole, but a particular implementation of MAJC, each individual CPU based on the MAJC design.<p>...<p>The developer ships only a single bytecode version of their program, and the user&#x27;s machine compiles that to the underlying platform. &quot;[0]<p>[0] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;MAJC" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;MAJC</a></div><br/></div></div><div id="39114380" class="c"><input type="checkbox" id="c-39114380" checked=""/><div class="controls bullet"><span class="by">hawflakes</span><span>|</span><a href="#39101843">root</a><span>|</span><a href="#39103147">parent</a><span>|</span><a href="#39110859">prev</a><span>|</span><a href="#39112791">next</a><span>|</span><label class="collapse" for="c-39114380">[-]</label><label class="expand" for="c-39114380">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Itanium is designed for a machine with three execution units and each instruction pack has up to three instructions, one for each of them. 
The design was that each bundle had some extra bits including a stop which was a sort of barrier to execution. The idea was that you could have a series of bundles  with no stop bit and the last one would set it. That meant the whole series could be safely scheduled on a future wide IA64 machine. Of course that meant the compiler had to be explicit about that parallelism (hence EPIC) but future machines would be able to schedule on the extra execution units.
This also addressed the problem where VLIW traditionally would require re-compilation to run&#x2F;run more efficiently on newer hardware.<p>&gt; Due to not having register renaming, VLIW architectures conventionally have a large register file (128 registers in the case of the Itanium). This slows down context switches, further reducing performance. Out-of-order CPUs can cheat by having a comparably small programmer-visible state, with most of the state hidden in the bowels of the processor and consequently not in need of saving or restoring.<p>Itanium borrowed the register windows from SPARC. It was effectively a hardware stack that had a minimum of 128 physical registers but were referenced in instructions by 6 bits — e.g. 64 virtual registers, iirc.
So you could make a function call and the stack would push. And a return would pop. Just like SPARC execept they weren&#x27;t fixed-sized windows.<p>That said, the penalty for spilling the RSE (They called this part the Register Stack Engine) for say, an OS context switch was quite heavy since you&#x27;d have to write the whoe RSE state to memory.<p>It was pretty cool reading about this stuff as a new grad.<p>&gt;  Another enginering issue was that x86 simulation on the Itanium performed quite poorly, giving existing customers no incentive to switch.<p>As I mentioned in my previous comment Merced had a tiny corner of the chip devoted to the IVE, Intel Value Engine which was meant to be the very simple 32-bit x86 chip meant mainly for booting the system. The intent was (and the docs also had sample code) to boot, do some set up of system state, and then jump into IA64 mode where you would actually get a fast system.<p>I think they did devote more silicon to x86 support but I had already served my very short time at HP and Merced still took 2+ years to tape out.</div><br/></div></div><div id="39112791" class="c"><input type="checkbox" id="c-39112791" checked=""/><div class="controls bullet"><span class="by">xoranth</span><span>|</span><a href="#39101843">root</a><span>|</span><a href="#39103147">parent</a><span>|</span><a href="#39114380">prev</a><span>|</span><a href="#39113856">next</a><span>|</span><label class="collapse" for="c-39112791">[-]</label><label class="expand" for="c-39112791">[3 more]</label></div><br/><div class="children"><div class="content">&gt; * the whole idea hinges on the compiler being able to figure out the correct instruction schedule ahead of time. While feasible for Intel&#x27;s&#x2F;HP&#x27;s in house compiler team, the authors of other toolchains largely did not bother, instead opting for more conventional code generation that did not performed all too well.<p>Was Intel&#x27;s compiler actually able to get good performance on Itanium? How much less screwed would Itanium have been if other toolchains matched the performance on Intel&#x27;s compiler?<p>Also, I vaguely remember reading that Itanium also had a different page table structure (like a hash table?). Did that cause problems too?</div><br/><div id="39113282" class="c"><input type="checkbox" id="c-39113282" checked=""/><div class="controls bullet"><span class="by">BirAdam</span><span>|</span><a href="#39101843">root</a><span>|</span><a href="#39112791">parent</a><span>|</span><a href="#39113708">next</a><span>|</span><label class="collapse" for="c-39113282">[-]</label><label class="expand" for="c-39113282">[1 more]</label></div><br/><div class="children"><div class="content">Intel’s compiler was a bit better than some but still wasn’t great. Largely, Intel quickly lost interest in Itanium when AMD64 started selling well. HP had their own tooling, and HP was pretty much the only customer buying Itaniums. Intel quit investing in Itanium beyond what their contractual obligations to HP dictated.<p>I am curious about what could have been, but my assumption is that a mature and optimized software industry would be required. This was never going to happen after the launch of AMD64.</div><br/></div></div><div id="39113708" class="c"><input type="checkbox" id="c-39113708" checked=""/><div class="controls bullet"><span class="by">martinpw</span><span>|</span><a href="#39101843">root</a><span>|</span><a href="#39112791">parent</a><span>|</span><a href="#39113282">prev</a><span>|</span><a href="#39113856">next</a><span>|</span><label class="collapse" for="c-39113708">[-]</label><label class="expand" for="c-39113708">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a long time ago but the thing I remember the most is that the binaries were huge, around 3x the size of x86 binaries. At the time we were very space constrained and that aspect alone was big concern. If the performance had been there it might still have been worth pursuing, but the performance never exceeded the fastest x86 processors at the time.</div><br/></div></div></div></div></div></div></div></div><div id="39113856" class="c"><input type="checkbox" id="c-39113856" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#39101843">prev</a><span>|</span><label class="collapse" for="c-39113856">[-]</label><label class="expand" for="c-39113856">[4 more]</label></div><br/><div class="children"><div class="content">When will compilers be good enough to take another swing at VLIW?</div><br/><div id="39115192" class="c"><input type="checkbox" id="c-39115192" checked=""/><div class="controls bullet"><span class="by">p_l</span><span>|</span><a href="#39113856">parent</a><span>|</span><a href="#39113956">next</a><span>|</span><label class="collapse" for="c-39115192">[-]</label><label class="expand" for="c-39115192">[1 more]</label></div><br/><div class="children"><div class="content">VLIW is pretty well represented in the TOP500 supercomputers and in various other performance niches.<p>What isn&#x27;t is not so much VLIW as EPIC - the explicit parallelism of Itanium, which among others didn&#x27;t really support out of order or branch prediction in ways other than compiler code generator.<p>High levels of SMT (sometimes with just a barrel execution models) are used in GPUs to smooth out the performance characteristics involved, from my understanding.</div><br/></div></div><div id="39113956" class="c"><input type="checkbox" id="c-39113956" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#39113856">parent</a><span>|</span><a href="#39115192">prev</a><span>|</span><a href="#39114710">next</a><span>|</span><label class="collapse" for="c-39113956">[-]</label><label class="expand" for="c-39113956">[1 more]</label></div><br/><div class="children"><div class="content">Now, but temporally rather than spatially.<p>A VLIW has a lot of functional units that are used simultaneously.*  Modern processors (out of order, superscalar, using speculative execution, pick your techniques and buzzwords) allow these units to be used simultaneously and dynamically depending on the instruction mix.  With VLIW some instruction units won’t be used and so won’t contribute to performance.<p>The compilers can give hints to the execution CPU but it also decides what to do when.  With VLIW (EPIC is probably a better name in this regard) you have to guess right up front, without knowing what the data will be.<p>* So does SIMD, but in VLIW you don’t have to have a single instruction.</div><br/></div></div><div id="39114710" class="c"><input type="checkbox" id="c-39114710" checked=""/><div class="controls bullet"><span class="by">drivebycomment</span><span>|</span><a href="#39113856">parent</a><span>|</span><a href="#39113956">prev</a><span>|</span><label class="collapse" for="c-39114710">[-]</label><label class="expand" for="c-39114710">[1 more]</label></div><br/><div class="children"><div class="content">Approximately never for non-HPC code.</div><br/></div></div></div></div></div></div></div></div></div></body></html>