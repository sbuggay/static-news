<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1704790865241" as="style"/><link rel="stylesheet" href="styles.css?v=1704790865241"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://openreview.net/forum?id=MGWsPGogLH">Turing Complete Transformers: Two Transformers Are More Powerful Than One</a> <span class="domain">(<a href="https://openreview.net">openreview.net</a>)</span></div><div class="subtext"><span>georgehill</span> | <span>53 comments</span></div><br/><div><div id="38920753" class="c"><input type="checkbox" id="c-38920753" checked=""/><div class="controls bullet"><span class="by">qsort</span><span>|</span><a href="#38921324">next</a><span>|</span><label class="collapse" for="c-38920753">[-]</label><label class="expand" for="c-38920753">[22 more]</label></div><br/><div class="children"><div class="content">These reviews are <i>brutal</i>. It&#x27;s basically science-speak for &quot;the paper is utter trash&quot;.<p>&quot;The main claim [...] is both somewhat obvious and previously already stated&quot;<p>&quot;Many pieces of writing are overly assertive and inaccurate.&quot;<p>&quot;I do not think it deserves spending half a page demonstrating that {0^n 1^n} is not in the regular language.&quot;</div><br/><div id="38922862" class="c"><input type="checkbox" id="c-38922862" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#38920753">parent</a><span>|</span><a href="#38923354">next</a><span>|</span><label class="collapse" for="c-38922862">[-]</label><label class="expand" for="c-38922862">[15 more]</label></div><br/><div class="children"><div class="content">Yes. Anything with finite memory is not Turing-complete, and transformers are finite-state machines. So what? Anything with infinite memory is un-buildable.<p>Yes, there&#x27;s a school of philosophy that claims that AI cannot be built with digital hardware because it needs infinite state. Penrose is the leading exponent of this argument.[1] This isn&#x27;t taken too seriously any more, now that finite machines are doing so well at AI.<p>This is close to theology. Man must be special, right? Only humans can play chess, right?  Play Go? Pass the Turing test? Create art and music? We&#x27;re running out of boxes to check. Common sense (as in getting through the next 30 seconds without a major screwup) and manipulation in unstructured settings are still in bad shape, but we only need squirrel-level AI for that.<p>On that subject, there was a &quot;what does the cerebellum do&quot; article on HN a few days ago. That&#x27;s a big issue. The lower mammal brains are mostly cerebellum. The weak areas in AI at present are mostly cerebellum functions. That area has never gotten enough attention in AI research. Today, though, the amount of hardware to do a low-end mammal cerebellum equivalent doesn&#x27;t seem at all unreasonable.<p>[1] <a href="https:&#x2F;&#x2F;sortingsearching.com&#x2F;2021&#x2F;07&#x2F;18&#x2F;roger-penrose-ai-skepticism.html" rel="nofollow">https:&#x2F;&#x2F;sortingsearching.com&#x2F;2021&#x2F;07&#x2F;18&#x2F;roger-penrose-ai-ske...</a></div><br/><div id="38923415" class="c"><input type="checkbox" id="c-38923415" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38922862">parent</a><span>|</span><a href="#38923780">next</a><span>|</span><label class="collapse" for="c-38923415">[-]</label><label class="expand" for="c-38923415">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think we are running out of boxes. We just try to determine <i>the minimum</i> requirement that we could constitute as general AI, and that bound is hard to find. It’s quite trivial to find less than minimal bounds, say, writing a novel research paper, making a discovery&#x2F;invention, etc.</div><br/></div></div><div id="38923780" class="c"><input type="checkbox" id="c-38923780" checked=""/><div class="controls bullet"><span class="by">drowsspa</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38922862">parent</a><span>|</span><a href="#38923415">prev</a><span>|</span><a href="#38923572">next</a><span>|</span><label class="collapse" for="c-38923780">[-]</label><label class="expand" for="c-38923780">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is close to theology<p>Yeah, even the arguments reek of basically &quot;God of the gaps&quot; and &quot;moving the goalposts&quot; stuff</div><br/></div></div><div id="38923572" class="c"><input type="checkbox" id="c-38923572" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38922862">parent</a><span>|</span><a href="#38923780">prev</a><span>|</span><a href="#38922943">next</a><span>|</span><label class="collapse" for="c-38923572">[-]</label><label class="expand" for="c-38923572">[1 more]</label></div><br/><div class="children"><div class="content">This is such a philosophical rabbit hole  that I will get into when time allows it.</div><br/></div></div><div id="38922943" class="c"><input type="checkbox" id="c-38922943" checked=""/><div class="controls bullet"><span class="by">colechristensen</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38922862">parent</a><span>|</span><a href="#38923572">prev</a><span>|</span><a href="#38923354">next</a><span>|</span><label class="collapse" for="c-38922943">[-]</label><label class="expand" for="c-38922943">[11 more]</label></div><br/><div class="children"><div class="content">Penrose claims that human intelligence relies on quantum effects and demonstrates certain structures in neurons that makes it at least a plausible argument.<p>It would follow that comparable intelligence would not be possible with current digital computer architectures.<p>I also think a lot of people are a little too fooled by the “intelligence” of current models which are mimics with enormous libraries of “knowledge”.  It is not too hard to be frustrated by the enormous limitations of current models.  Impressive, yes, smart, no.  Though to refute claims of their intelligence is really pushing to refine the philosophical definition of intelligence which has been rather vague so far.  We can’t just say “i know it when i see it” because computers pretending is getting very good.</div><br/><div id="38923201" class="c"><input type="checkbox" id="c-38923201" checked=""/><div class="controls bullet"><span class="by">madhadron</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38922943">parent</a><span>|</span><a href="#38923097">next</a><span>|</span><label class="collapse" for="c-38923201">[-]</label><label class="expand" for="c-38923201">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Penrose claims that human intelligence relies on quantum effects and demonstrates certain structures in neurons that makes it at least a plausible argument.<p>Except that Penrose&#x27;s argument is biologically nonsense, which probably means that he has an incorrect definition of intelligence, since I&#x27;m pretty confident in his ability to reason from axioms.</div><br/></div></div><div id="38923097" class="c"><input type="checkbox" id="c-38923097" checked=""/><div class="controls bullet"><span class="by">patrakov</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38922943">parent</a><span>|</span><a href="#38923201">prev</a><span>|</span><a href="#38923011">next</a><span>|</span><label class="collapse" for="c-38923097">[-]</label><label class="expand" for="c-38923097">[5 more]</label></div><br/><div class="children"><div class="content">And so what? Your existence, as well as existence of Earth and anything else made of nuclei and electrons, relies on quantum effects.</div><br/><div id="38923149" class="c"><input type="checkbox" id="c-38923149" checked=""/><div class="controls bullet"><span class="by">colechristensen</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38923097">parent</a><span>|</span><a href="#38923011">next</a><span>|</span><label class="collapse" for="c-38923149">[-]</label><label class="expand" for="c-38923149">[4 more]</label></div><br/><div class="children"><div class="content">The point being you would need a kind of quantum computer for real intelligence.  It is at least a plausible requirement.</div><br/><div id="38923243" class="c"><input type="checkbox" id="c-38923243" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38923149">parent</a><span>|</span><a href="#38923261">next</a><span>|</span><label class="collapse" for="c-38923243">[-]</label><label class="expand" for="c-38923243">[1 more]</label></div><br/><div class="children"><div class="content">Yet the digital computer is based on quantum effects in transistors. We engineer the weirdness away to give the illusion of a digital computer. Eventually we will go back and see what can be done without that. Boolean algebra is nice a clean but there are other ways.</div><br/></div></div><div id="38923261" class="c"><input type="checkbox" id="c-38923261" checked=""/><div class="controls bullet"><span class="by">teaearlgraycold</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38923149">parent</a><span>|</span><a href="#38923243">prev</a><span>|</span><a href="#38923011">next</a><span>|</span><label class="collapse" for="c-38923261">[-]</label><label class="expand" for="c-38923261">[2 more]</label></div><br/><div class="children"><div class="content">Even then, it sounds like a speed issue. Quantum computers can be simulated on traditional computers. And quantum is coming, so those that repeat this theory to comfort themselves are at best buying time.</div><br/><div id="38923342" class="c"><input type="checkbox" id="c-38923342" checked=""/><div class="controls bullet"><span class="by">drdeca</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38923261">parent</a><span>|</span><a href="#38923011">next</a><span>|</span><label class="collapse" for="c-38923342">[-]</label><label class="expand" for="c-38923342">[1 more]</label></div><br/><div class="children"><div class="content">While quantum computers can be simulated classically, you can’t have the simulated state of a simulated quantum computer, be entangled with something outside of the classical computer doing the simulating, while a quantum computer could have qubits entangled with something outside of the quantum computer.<p>So, if that was somehow important, then the “you can simulate the quantum computer classically (at the cost of exponential slowdown)” point wouldn’t handle that kind of thing.<p>But, it seems rather unlikely to me that we’ll find any significant evidence of that kind of thing being important for intelligence.</div><br/></div></div></div></div></div></div></div></div><div id="38923011" class="c"><input type="checkbox" id="c-38923011" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38922943">parent</a><span>|</span><a href="#38923097">prev</a><span>|</span><a href="#38923354">next</a><span>|</span><label class="collapse" for="c-38923011">[-]</label><label class="expand" for="c-38923011">[4 more]</label></div><br/><div class="children"><div class="content">There is no way to effectively pretend to be smart without <i>actually</i> being smart.<p>This comes up a lot in things like science fiction, movies, etc...<p>E.g.: an author can state that a character has &quot;superhuman intelligence&quot;, but the author themselves would need to actually posses this superhuman intelligence to write the actions or dialogue of that character.[1] Because authors are &quot;just human&quot;, they obviously can&#x27;t be superhuman, so they generally avoid directly demonstrating the actions of superhumanly intelligent characters. I.e.: the &quot;tell, not show&quot; instead of the usual &quot;show, don&#x27;t tell.&quot;<p>The current crop of AIs are 100% &quot;show&quot;. They demonstrate intelligence directly, by <i>answering questions</i> instead of just talking about how they <i>would</i> answer questions, which is what fake intelligence would do.<p>PS: Next time you see a politician promise to deliver a solution, but not actually state what that solution is... well... now you know what&#x27;s going on with that particular situation!<p>[1] There&#x27;s a degree of cheating available to authors, because they have information that the in-world fictional characters don&#x27;t. Similarly, they can set up the question to lead to an answer they already have. The chat-based AIs can&#x27;t cheat like this, they have to answer the questions given to them.</div><br/><div id="38923197" class="c"><input type="checkbox" id="c-38923197" checked=""/><div class="controls bullet"><span class="by">colechristensen</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38923011">parent</a><span>|</span><a href="#38923354">next</a><span>|</span><label class="collapse" for="c-38923197">[-]</label><label class="expand" for="c-38923197">[3 more]</label></div><br/><div class="children"><div class="content">Sure there is.  Know the answers to questions already.  Being trained on a noninsignificant proportion of all questions ever asked on the Internet means you have to wonder how smart LLMs really are.  Seeing the ways they fail, confirms not so much.  They are able to abstract a bit of knowledge an statically match it to questions and answers already seen.  Confident hallucinations help you see this.<p>The best hallucinations I saw was asking chatgpt for a list of references for a topic I was researching.  They all looked entirely believable, titles, authors, institutions, summaries… IIRC there were about twenty of them.  Only one actually existed.</div><br/><div id="38923845" class="c"><input type="checkbox" id="c-38923845" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38923197">parent</a><span>|</span><a href="#38923374">next</a><span>|</span><label class="collapse" for="c-38923845">[-]</label><label class="expand" for="c-38923845">[1 more]</label></div><br/><div class="children"><div class="content">How many leaf URLs have you memorised? I don&#x27;t mean &quot;google.com&quot;, I mean the URL of a specific paper in a journal, or an article in some random news site?<p>If you were forced at gunpoint to provide such URLs -- valid or not -- with literally no option other than to keep talking, you would... make up some vaguely correct-sounding URLs!<p>The AIs are doing precisely what an intelligent human in their place would do. Blurting out something, <i>anything</i>, even if they don&#x27;t have the answers.<p>That&#x27;s because the current crop of AIs are essentially being forced to provide the next token, directly equivalent to a human being forced to continue speaking against their will.<p>There are fixes being put in place already for this, such as using human feedback to tune the AI so that it answers with a generic &quot;I don&#x27;t know&quot; blurb if it&#x27;s not sufficiently confident in the next token.<p>There are also variations of neural networks that encode not just &quot;values&quot;, but probabilities and hence confidence intervals. These can directly output both tokens <i>and</i> the true confidence values, which would allow complex tree searches, etc... and avoid outputting this kind of gibberish entirely. The maths for this is well established, but it would be much more expensive to run models using it, so nobody has bothered yet.</div><br/></div></div><div id="38923374" class="c"><input type="checkbox" id="c-38923374" checked=""/><div class="controls bullet"><span class="by">Aeolos</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38923197">parent</a><span>|</span><a href="#38923845">prev</a><span>|</span><a href="#38923354">next</a><span>|</span><label class="collapse" for="c-38923374">[-]</label><label class="expand" for="c-38923374">[1 more]</label></div><br/><div class="children"><div class="content">Ask a human the same question and force them to answer (instead of saying I don&#x27;t know), and they will hallucinate a list of references for you just the same. Does that mean humans are not intelligent?<p>I don&#x27;t think your argument proves what you claim.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38923354" class="c"><input type="checkbox" id="c-38923354" checked=""/><div class="controls bullet"><span class="by">zubairq</span><span>|</span><a href="#38920753">parent</a><span>|</span><a href="#38922862">prev</a><span>|</span><a href="#38920787">next</a><span>|</span><label class="collapse" for="c-38923354">[-]</label><label class="expand" for="c-38923354">[1 more]</label></div><br/><div class="children"><div class="content">I actually really appreciate these brutal reviews</div><br/></div></div><div id="38920787" class="c"><input type="checkbox" id="c-38920787" checked=""/><div class="controls bullet"><span class="by">jakderrida</span><span>|</span><a href="#38920753">parent</a><span>|</span><a href="#38923354">prev</a><span>|</span><a href="#38921945">next</a><span>|</span><label class="collapse" for="c-38920787">[-]</label><label class="expand" for="c-38920787">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t even have a phD. I just find openreview&#x27;s feedback fun to read. For the same reason I love watching Gordon Ramsey give feedback.</div><br/><div id="38920873" class="c"><input type="checkbox" id="c-38920873" checked=""/><div class="controls bullet"><span class="by">qsort</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38920787">parent</a><span>|</span><a href="#38921945">next</a><span>|</span><label class="collapse" for="c-38920873">[-]</label><label class="expand" for="c-38920873">[2 more]</label></div><br/><div class="children"><div class="content">Me neither, but I know what the process is like from having co-authored some stuff at work. This is not the kind of review you get if the paper is simply not good enough. Those are some seriously pissed off reviewers. Compare for example with this:<p><a href="https:&#x2F;&#x2F;openreview.net&#x2F;forum?id=cXs5md5wAq" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;forum?id=cXs5md5wAq</a></div><br/><div id="38922041" class="c"><input type="checkbox" id="c-38922041" checked=""/><div class="controls bullet"><span class="by">jakderrida</span><span>|</span><a href="#38920753">root</a><span>|</span><a href="#38920873">parent</a><span>|</span><a href="#38921945">next</a><span>|</span><label class="collapse" for="c-38922041">[-]</label><label class="expand" for="c-38922041">[1 more]</label></div><br/><div class="children"><div class="content">Aw man... I was looking forward to a whole night of attempted savage takedowns. Not mature constructive criticisms.</div><br/></div></div></div></div></div></div><div id="38921945" class="c"><input type="checkbox" id="c-38921945" checked=""/><div class="controls bullet"><span class="by">Cacti</span><span>|</span><a href="#38920753">parent</a><span>|</span><a href="#38920787">prev</a><span>|</span><a href="#38922593">next</a><span>|</span><label class="collapse" for="c-38921945">[-]</label><label class="expand" for="c-38921945">[1 more]</label></div><br/><div class="children"><div class="content">These are just jokes with reviewers having some fun after doing 20 other reviews. The review process isn&#x27;t really needed for a paper this bad, but they have to go through the motions, and so people have fun with it.<p>It’s not a big deal. Shitty papers exist.</div><br/></div></div><div id="38922593" class="c"><input type="checkbox" id="c-38922593" checked=""/><div class="controls bullet"><span class="by">axiom92</span><span>|</span><a href="#38920753">parent</a><span>|</span><a href="#38921945">prev</a><span>|</span><a href="#38921324">next</a><span>|</span><label class="collapse" for="c-38922593">[-]</label><label class="expand" for="c-38922593">[1 more]</label></div><br/><div class="children"><div class="content">Welcome to one of the most hated parts of the academia.</div><br/></div></div></div></div><div id="38921324" class="c"><input type="checkbox" id="c-38921324" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#38920753">prev</a><span>|</span><a href="#38920856">next</a><span>|</span><label class="collapse" for="c-38921324">[-]</label><label class="expand" for="c-38921324">[4 more]</label></div><br/><div class="children"><div class="content">The reviews are pretty harsh, but after reading the paper, I feel they may be too generous. Somehow this paper spends several pages proving things that are both trivial and irrelevant, and spends zero words explaining the architecture of their model. This is borderline crackpot territory.</div><br/><div id="38921447" class="c"><input type="checkbox" id="c-38921447" checked=""/><div class="controls bullet"><span class="by">davesque</span><span>|</span><a href="#38921324">parent</a><span>|</span><a href="#38923267">next</a><span>|</span><label class="collapse" for="c-38921447">[-]</label><label class="expand" for="c-38921447">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, I sort of agree.  It hardly provides any details about the model that they supposedly used to achieve only two benchmark results which are poorly described.  It comes across as being written by someone that only dabbles in the topic but seems to believe they&#x27;ve taken some great leap forward ahead of the entire field.</div><br/><div id="38922910" class="c"><input type="checkbox" id="c-38922910" checked=""/><div class="controls bullet"><span class="by">im3w1l</span><span>|</span><a href="#38921324">root</a><span>|</span><a href="#38921447">parent</a><span>|</span><a href="#38923267">next</a><span>|</span><label class="collapse" for="c-38922910">[-]</label><label class="expand" for="c-38922910">[1 more]</label></div><br/><div class="children"><div class="content">Sounds consistent with some non-scientists working in the field, maybe for some smaller software company? They find something cool, and try to write a paper about it, which is something they aren&#x27;t very experienced with.</div><br/></div></div></div></div><div id="38923267" class="c"><input type="checkbox" id="c-38923267" checked=""/><div class="controls bullet"><span class="by">utopcell</span><span>|</span><a href="#38921324">parent</a><span>|</span><a href="#38921447">prev</a><span>|</span><a href="#38920856">next</a><span>|</span><label class="collapse" for="c-38923267">[-]</label><label class="expand" for="c-38923267">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. Why is this on HN again ?</div><br/></div></div></div></div><div id="38920856" class="c"><input type="checkbox" id="c-38920856" checked=""/><div class="controls bullet"><span class="by">davesque</span><span>|</span><a href="#38921324">prev</a><span>|</span><a href="#38920668">next</a><span>|</span><label class="collapse" for="c-38920856">[-]</label><label class="expand" for="c-38920856">[7 more]</label></div><br/><div class="children"><div class="content">Something I noticed when skimming the paper that is also called out by one of the reviewers:<p>&quot;Moreover, in the submission the authors considered only Transformers with input and output of bounded lengths, which are quite strange since Turing machines do not pose constraints on the tape length. If the length is constrained in Transformers, they clearly do not match Turing machines.&quot;</div><br/><div id="38921097" class="c"><input type="checkbox" id="c-38921097" checked=""/><div class="controls bullet"><span class="by">Azertinv</span><span>|</span><a href="#38920856">parent</a><span>|</span><a href="#38920668">next</a><span>|</span><label class="collapse" for="c-38921097">[-]</label><label class="expand" for="c-38921097">[6 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the comparison apply in this way, Turing machine may operate on an unconstrained tape but they only look at a single cell at each step.
This find and replace technique operate on a bounded context but, in the same way as a turing machine, they can &quot;technically&quot; operate on an unconstrained tape (technically here because the find transformer wouldn&#x27;t be able to lookup an infinite tape in the real world).
I guess you could say that a turing machine has a bounded input length of 1.</div><br/><div id="38921260" class="c"><input type="checkbox" id="c-38921260" checked=""/><div class="controls bullet"><span class="by">davesque</span><span>|</span><a href="#38920856">root</a><span>|</span><a href="#38921097">parent</a><span>|</span><a href="#38920668">next</a><span>|</span><label class="collapse" for="c-38921260">[-]</label><label class="expand" for="c-38921260">[5 more]</label></div><br/><div class="children"><div class="content">Okay, actually I think I just misunderstood the argument in the paper.  After taking a second look, I think their argument goes as follows:<p>A typical autoregressive transformer model operates on a fixed-size context that acts as both input and a queue to which the output of the model is appended.  If a model operates on a context of length k with n possible symbols in its alphabet, then there are n^k possible contexts.<p>If you run such a model for n^k iterations, then<p>1) if the &lt;eos&gt; (end of sequence) symbol appears in the context, then the model halts.<p>2) if the &lt;eos&gt; symbol never appears in the context, then you know the model never halts because it must repeat a context string by the pigeon hole principal and must be in an infinite loop.<p>Therefore, the halting problem is decidable for transformer models with finite length contexts that are autoregressive in this way and that would imply a contradiction if we claim they are Turing complete (because the halting problem is known to be undecidable for Turing complete systems).<p>I&#x27;m not entirely sure this proves anything (it sounds believable I guess?), but at least I think it describes the argument they are making.<p>It is sort of interesting how it highlights the different between a system that can write to any position in memory vs. one that can only append to memory while being required to delete the first memory cell (where memory is a queue).<p>However, the overall paper is awful and pretty hard to take seriously.</div><br/><div id="38923064" class="c"><input type="checkbox" id="c-38923064" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#38920856">root</a><span>|</span><a href="#38921260">parent</a><span>|</span><a href="#38923600">next</a><span>|</span><label class="collapse" for="c-38923064">[-]</label><label class="expand" for="c-38923064">[1 more]</label></div><br/><div class="children"><div class="content">This seems at least plausible, and it agrees with my preconceived notions that a good chunk of LLM capability is driven by memorization and not computation[0]. Is there any substantive critique of the underlying idea from the other reviewers, and not just the (evidently terrible) presentation of it?<p>[0] For a good idea as to why I think this way, see <a href="https:&#x2F;&#x2F;not-just-memorization.github.io&#x2F;extracting-training-data-from-chatgpt.html" rel="nofollow">https:&#x2F;&#x2F;not-just-memorization.github.io&#x2F;extracting-training-...</a></div><br/></div></div><div id="38923600" class="c"><input type="checkbox" id="c-38923600" checked=""/><div class="controls bullet"><span class="by">cornel_io</span><span>|</span><a href="#38920856">root</a><span>|</span><a href="#38921260">parent</a><span>|</span><a href="#38923064">prev</a><span>|</span><a href="#38921323">next</a><span>|</span><label class="collapse" for="c-38923600">[-]</label><label class="expand" for="c-38923600">[1 more]</label></div><br/><div class="children"><div class="content">A modern computer can be cast as a seq-to-seq model, too, so their &quot;arguments&quot; apply to those as well, just with larger n and k. Any finite machine suffers from this.</div><br/></div></div><div id="38921323" class="c"><input type="checkbox" id="c-38921323" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#38920856">root</a><span>|</span><a href="#38921260">parent</a><span>|</span><a href="#38923600">prev</a><span>|</span><a href="#38920668">next</a><span>|</span><label class="collapse" for="c-38921323">[-]</label><label class="expand" for="c-38921323">[2 more]</label></div><br/><div class="children"><div class="content">Where did you find the paper? It&#x27;s not on arxiv?</div><br/><div id="38921336" class="c"><input type="checkbox" id="c-38921336" checked=""/><div class="controls bullet"><span class="by">davesque</span><span>|</span><a href="#38920856">root</a><span>|</span><a href="#38921323">parent</a><span>|</span><a href="#38920668">next</a><span>|</span><label class="collapse" for="c-38921336">[-]</label><label class="expand" for="c-38921336">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a PDF link next to the title on the linked page, but here&#x27;s a direct link: <a href="https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=MGWsPGogLH" rel="nofollow">https:&#x2F;&#x2F;openreview.net&#x2F;pdf?id=MGWsPGogLH</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="38920668" class="c"><input type="checkbox" id="c-38920668" checked=""/><div class="controls bullet"><span class="by">DoubleDerper</span><span>|</span><a href="#38920856">prev</a><span>|</span><a href="#38920688">next</a><span>|</span><label class="collapse" for="c-38920668">[-]</label><label class="expand" for="c-38920668">[6 more]</label></div><br/><div class="children"><div class="content">Hear me out.  Try three transformers.</div><br/><div id="38920728" class="c"><input type="checkbox" id="c-38920728" checked=""/><div class="controls bullet"><span class="by">_jal</span><span>|</span><a href="#38920668">parent</a><span>|</span><a href="#38920706">next</a><span>|</span><label class="collapse" for="c-38920728">[-]</label><label class="expand" for="c-38920728">[4 more]</label></div><br/><div class="children"><div class="content">To save time:<p><a href="https:&#x2F;&#x2F;www.theonion.com&#x2F;fuck-everything-were-doing-five-blades-1819584036" rel="nofollow">https:&#x2F;&#x2F;www.theonion.com&#x2F;fuck-everything-were-doing-five-bla...</a></div><br/><div id="38922390" class="c"><input type="checkbox" id="c-38922390" checked=""/><div class="controls bullet"><span class="by">zontorol</span><span>|</span><a href="#38920668">root</a><span>|</span><a href="#38920728">parent</a><span>|</span><a href="#38921835">next</a><span>|</span><label class="collapse" for="c-38922390">[-]</label><label class="expand" for="c-38922390">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;gillette.com&#x2F;en-us&#x2F;products&#x2F;razors-trimmers-and-blades&#x2F;fusion5-razor" rel="nofollow">https:&#x2F;&#x2F;gillette.com&#x2F;en-us&#x2F;products&#x2F;razors-trimmers-and-blad...</a></div><br/><div id="38922928" class="c"><input type="checkbox" id="c-38922928" checked=""/><div class="controls bullet"><span class="by">Groxx</span><span>|</span><a href="#38920668">root</a><span>|</span><a href="#38922390">parent</a><span>|</span><a href="#38921835">next</a><span>|</span><label class="collapse" for="c-38922928">[-]</label><label class="expand" for="c-38922928">[1 more]</label></div><br/><div class="children"><div class="content">Bah.  You need at least 7 to get a close enough shave.  <a href="https:&#x2F;&#x2F;www.kroger.com&#x2F;p&#x2F;bromley-s-for-men-get-a-grip-razor&#x2F;0004126000789" rel="nofollow">https:&#x2F;&#x2F;www.kroger.com&#x2F;p&#x2F;bromley-s-for-men-get-a-grip-razor&#x2F;...</a></div><br/></div></div></div></div><div id="38921835" class="c"><input type="checkbox" id="c-38921835" checked=""/><div class="controls bullet"><span class="by">pseudosavant</span><span>|</span><a href="#38920668">root</a><span>|</span><a href="#38920728">parent</a><span>|</span><a href="#38922390">prev</a><span>|</span><a href="#38920706">next</a><span>|</span><label class="collapse" for="c-38921835">[-]</label><label class="expand" for="c-38921835">[1 more]</label></div><br/><div class="children"><div class="content">The link to that Onion article was worth a double up vote!</div><br/></div></div></div></div><div id="38920706" class="c"><input type="checkbox" id="c-38920706" checked=""/><div class="controls bullet"><span class="by">compacct27</span><span>|</span><a href="#38920668">parent</a><span>|</span><a href="#38920728">prev</a><span>|</span><a href="#38920688">next</a><span>|</span><label class="collapse" for="c-38920706">[-]</label><label class="expand" for="c-38920706">[1 more]</label></div><br/><div class="children"><div class="content">Can’t. Three Body Problem.</div><br/></div></div></div></div><div id="38920688" class="c"><input type="checkbox" id="c-38920688" checked=""/><div class="controls bullet"><span class="by">junipertea</span><span>|</span><a href="#38920668">prev</a><span>|</span><a href="#38921972">next</a><span>|</span><label class="collapse" for="c-38920688">[-]</label><label class="expand" for="c-38920688">[4 more]</label></div><br/><div class="children"><div class="content">Is the discussion about the paper, or about how it was unilaterally rejected?</div><br/><div id="38921214" class="c"><input type="checkbox" id="c-38921214" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#38920688">parent</a><span>|</span><a href="#38920949">prev</a><span>|</span><a href="#38921972">next</a><span>|</span><label class="collapse" for="c-38921214">[-]</label><label class="expand" for="c-38921214">[2 more]</label></div><br/><div class="children"><div class="content">Meh, let’s see an open license implementation.<p>Unfortunately, I don’t find the acceptance or rejection of a paper in this field has much predictive value these days.  By and large, the reviewers tend to be more and more like Wikipedia editors as time goes on.</div><br/><div id="38921540" class="c"><input type="checkbox" id="c-38921540" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#38920688">root</a><span>|</span><a href="#38921214">parent</a><span>|</span><a href="#38921972">next</a><span>|</span><label class="collapse" for="c-38921540">[-]</label><label class="expand" for="c-38921540">[1 more]</label></div><br/><div class="children"><div class="content">Whether or not the review process works, open review is a slightly different process. I’d expect a skeptic of the review process to celebrate the idea of reviewers “showing their work.”</div><br/></div></div></div></div></div></div><div id="38921972" class="c"><input type="checkbox" id="c-38921972" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#38920688">prev</a><span>|</span><a href="#38920695">next</a><span>|</span><label class="collapse" for="c-38921972">[-]</label><label class="expand" for="c-38921972">[3 more]</label></div><br/><div class="children"><div class="content">Out of curiosity, what do people think of the comments to the reviewers by the authors?<p>I was pretty surprised to see them challenge the reviewers. Maybe open review is different, but I was trained to try find ways to defer to the reviewers or, basically, placate them if possible. It look like the authors have tried to argue back, for example finding a contradiction between the reviews… it seems like a risky strategy to me. Then again I haven’t ever received feedback this negative, thank goodness.</div><br/><div id="38922578" class="c"><input type="checkbox" id="c-38922578" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#38921972">parent</a><span>|</span><a href="#38922890">next</a><span>|</span><label class="collapse" for="c-38922578">[-]</label><label class="expand" for="c-38922578">[1 more]</label></div><br/><div class="children"><div class="content">After skimming the paper I kind of agree with the reviewers on this one, there&#x27;s too much time spent going over undergrad level TCS material, and not much in the way of related papers cited (for instance, not one mention of circuit complexity). It&#x27;s a good introduction to the material for people a bit rusty in the field, but if I as a layman can nod along with my meager TCS knowledge then those parts are probably a bit _too_ trivial to include (at least for a journal submission. An addendum or blog post would be fine).<p>It may be quite possible that they did stumble upon a model that beats gpt-4 on their tasks, in which case they should release the code&#x2F;model and let those results stand for itself. But as a _paper_ it&#x27;s not very good since the main novel contribution (this &quot;Find&#x2F;Replace modification to transformer architecture&quot; has less than a page dedicated to describing it).</div><br/></div></div><div id="38922890" class="c"><input type="checkbox" id="c-38922890" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#38921972">parent</a><span>|</span><a href="#38922578">prev</a><span>|</span><a href="#38920695">next</a><span>|</span><label class="collapse" for="c-38922890">[-]</label><label class="expand" for="c-38922890">[1 more]</label></div><br/><div class="children"><div class="content">I think there are two situations in which you might see this kind of rebuttal:<p>1) The reviewers were truly unreasonable, and the authors feel they have no hope of winning them over. Instead, they try to highlight the flaws in the reviews to play to the Area Chair, and hope the reviewers are overruled. It&#x27;s a longshot, but worth a try if you don&#x27;t feel there&#x27;s another path.<p>2) The authors aren&#x27;t really familiar with the review process, and are just upset with the negative feedback. They&#x27;re just looking to argue for the sake of arguing, and not as part of a strategy to get accepted. I think that&#x27;s what we&#x27;re seeing here.</div><br/></div></div></div></div><div id="38921587" class="c"><input type="checkbox" id="c-38921587" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#38920695">prev</a><span>|</span><a href="#38920681">next</a><span>|</span><label class="collapse" for="c-38921587">[-]</label><label class="expand" for="c-38921587">[1 more]</label></div><br/><div class="children"><div class="content">Why not as many as possible like how gpus have shader processors</div><br/></div></div><div id="38920681" class="c"><input type="checkbox" id="c-38920681" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#38921587">prev</a><span>|</span><a href="#38920795">next</a><span>|</span><label class="collapse" for="c-38920681">[-]</label><label class="expand" for="c-38920681">[1 more]</label></div><br/><div class="children"><div class="content">Looks like things are about to get interesting, between this work and iterative, self directed AI REPL type architecture.</div><br/></div></div><div id="38920795" class="c"><input type="checkbox" id="c-38920795" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#38920681">prev</a><span>|</span><label class="collapse" for="c-38920795">[-]</label><label class="expand" for="c-38920795">[3 more]</label></div><br/><div class="children"><div class="content">Dupe of <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38917829">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38917829</a> ?</div><br/><div id="38920864" class="c"><input type="checkbox" id="c-38920864" checked=""/><div class="controls bullet"><span class="by">georgehill</span><span>|</span><a href="#38920795">parent</a><span>|</span><label class="collapse" for="c-38920864">[-]</label><label class="expand" for="c-38920864">[2 more]</label></div><br/><div class="children"><div class="content">I am not sure what&#x27;s wrong with the HN search, but I searched the URL before posting it and found nothing. As of writing this comment, it still shows only this URL. Maybe slow indexing time or Am I doing something wrong?<p><a href="https:&#x2F;&#x2F;hn.algolia.com&#x2F;?q=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DMGWsPGogLH" rel="nofollow">https:&#x2F;&#x2F;hn.algolia.com&#x2F;?q=https%3A%2F%2Fopenreview.net%2Ffor...</a></div><br/><div id="38922847" class="c"><input type="checkbox" id="c-38922847" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#38920795">root</a><span>|</span><a href="#38920864">parent</a><span>|</span><label class="collapse" for="c-38922847">[-]</label><label class="expand" for="c-38922847">[1 more]</label></div><br/><div class="children"><div class="content">One trick - after submitting, check page 1 of the domain submissions link.<p>I enjoyed this discussion though, so glad things went the way they did.  Cheers.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>