<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1692435656830" as="style"/><link rel="stylesheet" href="styles.css?v=1692435656830"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.quantamagazine.org/complexity-theorys-50-year-journey-to-the-limits-of-knowledge-20230817/">Complexity theory’s 50-year journey to the limits of knowledge</a> <span class="domain">(<a href="https://www.quantamagazine.org">www.quantamagazine.org</a>)</span></div><div class="subtext"><span>nsoonhui</span> | <span>64 comments</span></div><br/><div><div id="37182868" class="c"><input type="checkbox" id="c-37182868" checked=""/><div class="controls bullet"><span class="by">bumbledraven</span><span>|</span><a href="#37183167">next</a><span>|</span><label class="collapse" for="c-37182868">[-]</label><label class="expand" for="c-37182868">[24 more]</label></div><br/><div class="children"><div class="content">&gt; Suppose that P = NP. To prove it, researchers would need to find a fast algorithm for an NP-complete problem, which might be hiding in some obscure corner of that vast landscape.<p>They wouldn&#x27;t need to <i>find</i> such an algorithm. They would just need to prove that such an algorithm <i>exists</i>.</div><br/><div id="37184422" class="c"><input type="checkbox" id="c-37184422" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#37182868">parent</a><span>|</span><a href="#37182926">next</a><span>|</span><label class="collapse" for="c-37184422">[-]</label><label class="expand" for="c-37184422">[4 more]</label></div><br/><div class="children"><div class="content">Technically it is impossible for this to happen for P=NP since if P=NP then there is a straight forward algorithm for solving  SAT by universal search.</div><br/><div id="37185130" class="c"><input type="checkbox" id="c-37185130" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37184422">parent</a><span>|</span><a href="#37182926">next</a><span>|</span><label class="collapse" for="c-37185130">[-]</label><label class="expand" for="c-37185130">[3 more]</label></div><br/><div class="children"><div class="content">Can you explain your comment? NP-completeness to my understanding simply means that there exists a polynomial time reduction to SAT. How can SAT constructively get a P algorithm implementation merely from proving that an NP-complete problem <i>has</i> a solution in P without the algorithm itself?<p>I don’t want to accuse you of being incorrect if you’re alluding to something I’m ignorant of, but since it’s certainly possible in my mind that an NP-complete problem could be non-constructively proven to be in P, what you wrote doesn’t sound right.</div><br/><div id="37185470" class="c"><input type="checkbox" id="c-37185470" checked=""/><div class="controls bullet"><span class="by">CaptainNegative</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37185130">parent</a><span>|</span><a href="#37182926">next</a><span>|</span><label class="collapse" for="c-37185470">[-]</label><label class="expand" for="c-37185470">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s already a known algorithm M <i>you can implement right now</i> that can find satisfying assignments to satisfiable SAT instances in polynomial time conditioned only on P=NP.<p>Note: I&#x27;ll be glossing over a few technicalities in this explanation, feel free to ask about them.<p>Roughly, the algorithm M is as follows. Suppose you have input x of length n. For each integer c between 1 and n, encode c in binary and try to decode it in UTF-8. If it decodes, try to interpret it as a Python program, and run it on input x for 100n^c steps. If it executes successfully and outputs a valid assignment, return the assignment. Otherwise, continue onto the next c. If c=n and you haven&#x27;t found an assignment yet, do a brute force search over assignments and return what you find.<p>Now suppose P=NP, so some Python program finds SAT solutions in polynomial time. In fact, there are infinitely many such programs, since each valid program can be prefixed with as many &quot;pass&quot; expressions as we want. Interpreting the UTF-8 encoding of any such program p in binary gives us some integer c.<p>There are only finitely many inputs of length ≤ c, so the slowest of them still runs in finite (and thus polynomial) time. For any input of length &gt; c, the above algorithm M will spend at most 100(c-1)n^c time trying to execute the (c-1) different strings in Python for at most 100n^c steps each. If M happens on a solution before then, great! If it doesn&#x27;t, then now we run p -- which by assumption does find solutions in polynomial time -- for 100n^c steps.<p>If 100n^c is an upper bound on the true running time of p, then this necessarily returns a valid assignment, meaning that we can find assignments in time O(c n^c) time for some integer c, i.e. polynomial time. Otherwise, if 100n^c is too small, we just wait for the next copy p&#x27; of p (with a pass prefixed to it) that will have an even looser time bound of 100n^c&#x27; . This also may not be enough, but eventually we will find some p&#x27;&#x27;&#x27;&#x27;&#x27; for which the time bound does suffice (depending on the true running time of p). And so we find valid solutions in O(c&#x27;&#x27;&#x27;&#x27;&#x27;n^c&#x27;&#x27;&#x27;&#x27;&#x27;) time.<p>None of this required us to know what p is; effectively M makes the non-constructive constructive by trying every program out in a systematic way that the running time never exceeds some (also unknown) polynomial bound.<p>Is it practical? Suppose that the shortest Python program finding SAT assignments is at least 100 bytes long. Then c &gt; 256^100, and thus the running time is something like O(n^(256^100)). So be sure to get a good CPU.</div><br/><div id="37186072" class="c"><input type="checkbox" id="c-37186072" checked=""/><div class="controls bullet"><span class="by">skinner_</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37185470">parent</a><span>|</span><a href="#37182926">next</a><span>|</span><label class="collapse" for="c-37186072">[-]</label><label class="expand" for="c-37186072">[1 more]</label></div><br/><div class="children"><div class="content">Very nice explanation! I think it&#x27;s worth mentioning that this is called universal search (you mention this in passing) or Levin Search or Levin&#x27;s universal search algorithm. It was invented by Leonid Levin in 1972.<p><a href="https:&#x2F;&#x2F;steemit.com&#x2F;steemstem&#x2F;@markgritter&#x2F;leonid-levin-s-universal-algorithm" rel="nofollow noreferrer">https:&#x2F;&#x2F;steemit.com&#x2F;steemstem&#x2F;@markgritter&#x2F;leonid-levin-s-un...</a></div><br/></div></div></div></div></div></div></div></div><div id="37182926" class="c"><input type="checkbox" id="c-37182926" checked=""/><div class="controls bullet"><span class="by">wddkcs</span><span>|</span><a href="#37182868">parent</a><span>|</span><a href="#37184422">prev</a><span>|</span><a href="#37183769">next</a><span>|</span><label class="collapse" for="c-37182926">[-]</label><label class="expand" for="c-37182926">[18 more]</label></div><br/><div class="children"><div class="content">Can you really separate the two? For something like NP-completeness, I&#x27;m having trouble conceptualizing how a proof for existence would not require demonstration.</div><br/><div id="37183315" class="c"><input type="checkbox" id="c-37183315" checked=""/><div class="controls bullet"><span class="by">danbruc</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37182926">parent</a><span>|</span><a href="#37183168">next</a><span>|</span><label class="collapse" for="c-37183315">[-]</label><label class="expand" for="c-37183315">[1 more]</label></div><br/><div class="children"><div class="content">Yes, there are non-constructive proofs for the existence of polynomial time algorithms [1]. The Robertson–Seymour theorem [2] is a common example, it shows that certain classes of graphs can be characterized by finite sets of forbidden subgraphs [3] which can be checked for in polynomial time but it does say what those sets of forbidden subgraphs are or how they can be found.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Non-constructive_algorithm_existence_proofs" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Non-constructive_algorithm_exi...</a><p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Robertson%E2%80%93Seymour_theorem" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Robertson%E2%80%93Seymour_theo...</a><p>[3] More precisely forbidden minors.</div><br/></div></div><div id="37183168" class="c"><input type="checkbox" id="c-37183168" checked=""/><div class="controls bullet"><span class="by">linkgoron</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37182926">parent</a><span>|</span><a href="#37183315">prev</a><span>|</span><a href="#37182960">next</a><span>|</span><label class="collapse" for="c-37183168">[-]</label><label class="expand" for="c-37183168">[9 more]</label></div><br/><div class="children"><div class="content">An example for such a proof would be using the probabilistic method. However, even if we are ignoring some artificial problems, there are some &quot;natural&quot; problems that are known to be in P that we do not have algorithms for.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Non-constructive_algorithm_existence_proofs" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Non-constructive_algorithm_exi...</a><p>Also see:<p><a href="https:&#x2F;&#x2F;cs.stackexchange.com&#x2F;questions&#x2F;92087&#x2F;are-there-any-problems-in-p-which-we-do-not-know-any-p-algorithms" rel="nofollow noreferrer">https:&#x2F;&#x2F;cs.stackexchange.com&#x2F;questions&#x2F;92087&#x2F;are-there-any-p...</a></div><br/><div id="37183332" class="c"><input type="checkbox" id="c-37183332" checked=""/><div class="controls bullet"><span class="by">wddkcs</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37183168">parent</a><span>|</span><a href="#37185071">next</a><span>|</span><label class="collapse" for="c-37183332">[-]</label><label class="expand" for="c-37183332">[3 more]</label></div><br/><div class="children"><div class="content">Thank you- your link to non-constructive proofs led me to this HN comment, which seems to flesh out why such proofs are not applicable to P = NP<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29022963">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29022963</a><p>Im just reading about constructive vs. Non-constructive proofs, but my intuition seems to be that a proof would P = NP would have to be constructive.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19720511">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19720511</a></div><br/><div id="37183931" class="c"><input type="checkbox" id="c-37183931" checked=""/><div class="controls bullet"><span class="by">linkgoron</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37183332">parent</a><span>|</span><a href="#37185514">next</a><span>|</span><label class="collapse" for="c-37183931">[-]</label><label class="expand" for="c-37183931">[1 more]</label></div><br/><div class="children"><div class="content">That &quot;proof&quot; is applicable to any algorithm that &quot;exists&quot;. As &quot;an algorithm exists, so we can enumerate all of the Turing machines &quot;in parallel&quot; and find it&quot; would work for anything in P, other algorithms as well. However, good luck actually running that algorithm... Enumerating Turing machines in parallel, executing them, and n could be many times larger than the age of the universe. You want something that you can execute, not something that in theory exists.</div><br/></div></div><div id="37185514" class="c"><input type="checkbox" id="c-37185514" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37183332">parent</a><span>|</span><a href="#37183931">prev</a><span>|</span><a href="#37185071">next</a><span>|</span><label class="collapse" for="c-37185514">[-]</label><label class="expand" for="c-37185514">[1 more]</label></div><br/><div class="children"><div class="content">The kind of ultra-shoddy &quot;construction&quot; you get from &quot;Here is an impossible to build machine that would give us the proof&quot; would still not get you a demonstration.  It would still be something we don&#x27;t have the algorithm for.</div><br/></div></div></div></div><div id="37185071" class="c"><input type="checkbox" id="c-37185071" checked=""/><div class="controls bullet"><span class="by">cinquemb</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37183168">parent</a><span>|</span><a href="#37183332">prev</a><span>|</span><a href="#37182960">next</a><span>|</span><label class="collapse" for="c-37185071">[-]</label><label class="expand" for="c-37185071">[5 more]</label></div><br/><div class="children"><div class="content">Probably very silly, but for a long time, when I&#x27;ve seen &quot;p=np&quot; thrown around, I&#x27;ve always considered it some kind of matrix math problem where n could be substituted by an identity matrix which itself could be substituted by some kind of sampling (which would represent observations of events bounded by np-space) unitary matrix multiplied by its conjugate transpose[0](thus, p = np -&gt; p = ip -&gt; p = uu*p, or p= u*up), which seems like that would be in line with a probabilistic method, is that the case? Or is this a wrong way to think about this?<p>[0] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Unitary_matrix" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Unitary_matrix</a></div><br/><div id="37186154" class="c"><input type="checkbox" id="c-37186154" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37185071">parent</a><span>|</span><a href="#37182960">next</a><span>|</span><label class="collapse" for="c-37186154">[-]</label><label class="expand" for="c-37186154">[4 more]</label></div><br/><div class="children"><div class="content">Substitute the N?  No, you can&#x27;t substitute &quot;try every solution simultaneously&quot; by &quot;some kind of sampling&quot;.<p>Let&#x27;s use a very simple example.  How could sampling help you find the password that hashes to 21e400789a8ad12adb89d72ca8d92cc72400fea4?</div><br/><div id="37186571" class="c"><input type="checkbox" id="c-37186571" checked=""/><div class="controls bullet"><span class="by">cinquemb</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37186154">parent</a><span>|</span><a href="#37182960">next</a><span>|</span><label class="collapse" for="c-37186571">[-]</label><label class="expand" for="c-37186571">[3 more]</label></div><br/><div class="children"><div class="content">You couldn&#x27;t sample from anything if the password that hashes to 21e400789a8ad12adb89d72ca8d92cc72400fea4 is never used to encrypt any text. Though if the password that hashes to 21e400789a8ad12adb89d72ca8d92cc72400fea4 goes on to be used to encrypt any text, and one has access to the cipher text, then you can sample from the cipher text.</div><br/><div id="37186643" class="c"><input type="checkbox" id="c-37186643" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37186571">parent</a><span>|</span><a href="#37182960">next</a><span>|</span><label class="collapse" for="c-37186643">[-]</label><label class="expand" for="c-37186643">[2 more]</label></div><br/><div class="children"><div class="content">Okay, so you can&#x27;t design anything for my example problem?  It&#x27;s not being used to encrypt anything, all you get is the hash.  Which is solvable very very fast with an NP machine.  If you can&#x27;t apply your idea to that, you haven&#x27;t found a general solution.</div><br/><div id="37186782" class="c"><input type="checkbox" id="c-37186782" checked=""/><div class="controls bullet"><span class="by">cinquemb</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37186643">parent</a><span>|</span><a href="#37182960">next</a><span>|</span><label class="collapse" for="c-37186782">[-]</label><label class="expand" for="c-37186782">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, a general solution wouldn&#x27;t be useful in the wild against keys that are never used in the probabilistic approach i am thinking of, observations of cipher text are needed (which isn&#x27;t unbounded).</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="37182960" class="c"><input type="checkbox" id="c-37182960" checked=""/><div class="controls bullet"><span class="by">fooker</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37182926">parent</a><span>|</span><a href="#37183168">prev</a><span>|</span><a href="#37182964">next</a><span>|</span><label class="collapse" for="c-37182960">[-]</label><label class="expand" for="c-37182960">[1 more]</label></div><br/><div class="children"><div class="content">Yes, proofs don&#x27;t have to be constructive.<p>Consider proofs by contradiction, you could potentially show that if such an algorithm does not exist some important true statement would be rendered false.</div><br/></div></div><div id="37182964" class="c"><input type="checkbox" id="c-37182964" checked=""/><div class="controls bullet"><span class="by">viscountchocula</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37182926">parent</a><span>|</span><a href="#37182960">prev</a><span>|</span><a href="#37185149">next</a><span>|</span><label class="collapse" for="c-37182964">[-]</label><label class="expand" for="c-37182964">[5 more]</label></div><br/><div class="children"><div class="content">Sure. There is definitely a googolth digit of pi. Computing what the digit is, however, is not necessary to prove that such a digit exists.</div><br/><div id="37185416" class="c"><input type="checkbox" id="c-37185416" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37182964">parent</a><span>|</span><a href="#37183238">next</a><span>|</span><label class="collapse" for="c-37185416">[-]</label><label class="expand" for="c-37185416">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a quite bad analogy because the googolth digit of pi is completely constructive. (You don&#x27;t need to calculate it, but it is constructive)<p>P = NP proof could be not constructive.</div><br/><div id="37185961" class="c"><input type="checkbox" id="c-37185961" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37185416">parent</a><span>|</span><a href="#37185466">next</a><span>|</span><label class="collapse" for="c-37185961">[-]</label><label class="expand" for="c-37185961">[1 more]</label></div><br/><div class="children"><div class="content">Proving the Nth digit of pi exists is not (necessarily) constructive.<p>Though to make it an actual proof and not a truism you might say &quot;when writing pi in the shortest decimal representation, there is a millionth digit&quot;.<p>Proving pi is irrational would suffice, without actually calculating the first million digits.</div><br/></div></div></div></div><div id="37183238" class="c"><input type="checkbox" id="c-37183238" checked=""/><div class="controls bullet"><span class="by">wddkcs</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37182964">parent</a><span>|</span><a href="#37185416">prev</a><span>|</span><a href="#37185149">next</a><span>|</span><label class="collapse" for="c-37183238">[-]</label><label class="expand" for="c-37183238">[1 more]</label></div><br/><div class="children"><div class="content">My intuition was that if a proof for P = NP exists, it would be incomparable to the kind of Pi example you provide- Pi is defined as an irrational ratio, so the existence of whether x digit of Pi exists. It would instead be like saying, &#x27;the x digit of P is 7, and here is a proof that is not a straight calculation&#x27;. The idea of a proof which can demonstrate knowledge of X digit of Pi, without verification, doesn&#x27;t click for me.</div><br/></div></div></div></div><div id="37185149" class="c"><input type="checkbox" id="c-37185149" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#37182868">root</a><span>|</span><a href="#37182926">parent</a><span>|</span><a href="#37182964">prev</a><span>|</span><a href="#37183769">next</a><span>|</span><label class="collapse" for="c-37185149">[-]</label><label class="expand" for="c-37185149">[1 more]</label></div><br/><div class="children"><div class="content">suppose NP-complete problem X is in NP but not P. From this premise I arrive at a contradiction and conclude X is in P. Thus P=NP with no polynomial algorithm for solving any NP-complete problem provided</div><br/></div></div></div></div></div></div><div id="37183167" class="c"><input type="checkbox" id="c-37183167" checked=""/><div class="controls bullet"><span class="by">tetrazine</span><span>|</span><a href="#37182868">prev</a><span>|</span><a href="#37186565">next</a><span>|</span><label class="collapse" for="c-37183167">[-]</label><label class="expand" for="c-37183167">[21 more]</label></div><br/><div class="children"><div class="content">This is an aside. But I twigged on a caption for one of the figures: “Every computational problem takes longer to solve as its input grows larger, but not all problems grow harder at the same rate.”<p>It’s obvious from CS201 that this phrase is generally true and I have no pedantic objection to its inclusion in the article. However, I’m curious if this is strictly true or if we can find a (nontrivial) counterexample. Are there any algorithms that run faster as input grows? My first intuition is some kind of probabilistic question solved to a given correctness bound.<p>Edit: it is trivial to construct an algorithm with this property. My precise question is whether any meaningful problems have optimal algorithms with this property.</div><br/><div id="37186000" class="c"><input type="checkbox" id="c-37186000" checked=""/><div class="controls bullet"><span class="by">daveFNbuck</span><span>|</span><a href="#37183167">parent</a><span>|</span><a href="#37184412">next</a><span>|</span><label class="collapse" for="c-37186000">[-]</label><label class="expand" for="c-37186000">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Edit: it is trivial to construct an algorithm with this property.<p>It&#x27;s actually impossible to construct an algorithm that has its runtime decrease  as the input size grows. You can do this for finitely many examples, but we&#x27;re talking about asymptotics here. With discrete run-times and a lower-bound of 1 operation, the run-time will have to stop decreasing at some point and just stay at the same constant value for all but finitely-many exceptions. This makes it a constant-time algorithm.<p>A constant run-time is a counter-example to that caption though, as the problem doesn&#x27;t take longer as the input grows. An example would be checking if a number is divisible by 2. You only need to check 1 bit, so it doesn&#x27;t take any longer as you add more bits that the algorithm doesn&#x27;t touch.</div><br/><div id="37186604" class="c"><input type="checkbox" id="c-37186604" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37186000">parent</a><span>|</span><a href="#37186271">next</a><span>|</span><label class="collapse" for="c-37186604">[-]</label><label class="expand" for="c-37186604">[2 more]</label></div><br/><div class="children"><div class="content">Maybe not! With O(log N) such as binary search you are assuming some sort of structure to the data. It is not necessary for an algorithm to scan (otherwise O(N) is as good as it would get)<p>What if we devise a data structure that becomes more efficient as it grows to do a certain (perhaps useless - but that is OK!) operation.<p>For example we have a data structure at N=0 with a million disconnected nodes and one of them being the target node.<p>As N increases add a node with a pointer to the target node. The algorithm to find the target node is a random search through nodes until it finds one with a pointer then halts. As N increases, time on average decreases with complexity O(1-N&#x2F;(N-K)) where K=1000000</div><br/><div id="37186739" class="c"><input type="checkbox" id="c-37186739" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37186604">parent</a><span>|</span><a href="#37186271">next</a><span>|</span><label class="collapse" for="c-37186739">[-]</label><label class="expand" for="c-37186739">[1 more]</label></div><br/><div class="children"><div class="content">The bit I glossed over is picking a random number as per sister comment. More thinking needed!</div><br/></div></div></div></div><div id="37186271" class="c"><input type="checkbox" id="c-37186271" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37186000">parent</a><span>|</span><a href="#37186604">prev</a><span>|</span><a href="#37186228">next</a><span>|</span><label class="collapse" for="c-37186271">[-]</label><label class="expand" for="c-37186271">[2 more]</label></div><br/><div class="children"><div class="content">I guess even if you allow probabilistic algorithms and expected runtime, you still can&#x27;t have an algorithm that runs faster as the input size grows. Because... it takes O(log n) time to calculate any random variable whose expected value has a denominator of size n? I&#x27;m not entirely sure but that seems right to me.</div><br/><div id="37186349" class="c"><input type="checkbox" id="c-37186349" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37186271">parent</a><span>|</span><a href="#37186228">next</a><span>|</span><label class="collapse" for="c-37186349">[-]</label><label class="expand" for="c-37186349">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s for randomly sampling a large input?<p>If each piece of input is already independent, then you don&#x27;t have to calculate that, you can just use the input in order.</div><br/></div></div></div></div><div id="37186228" class="c"><input type="checkbox" id="c-37186228" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37186000">parent</a><span>|</span><a href="#37186271">prev</a><span>|</span><a href="#37184412">next</a><span>|</span><label class="collapse" for="c-37186228">[-]</label><label class="expand" for="c-37186228">[1 more]</label></div><br/><div class="children"><div class="content">You <i>could</i> use just the asymptote and call it &quot;constant time&quot;.<p>But that&#x27;s an extremely limited and misleading analysis, so you should not do that.  If the time taken goes from a quadrillion to 7 as the problem size grows, don&#x27;t call it constant.</div><br/></div></div></div></div><div id="37184412" class="c"><input type="checkbox" id="c-37184412" checked=""/><div class="controls bullet"><span class="by">dilawar</span><span>|</span><a href="#37183167">parent</a><span>|</span><a href="#37186000">prev</a><span>|</span><a href="#37186172">next</a><span>|</span><label class="collapse" for="c-37184412">[-]</label><label class="expand" for="c-37184412">[2 more]</label></div><br/><div class="children"><div class="content">Finding a set of mututally orthogonal vectors. For a given sparsity, after a large enough dimention, two randomly chosen vector will almost always be orthogonal.</div><br/><div id="37185909" class="c"><input type="checkbox" id="c-37185909" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37184412">parent</a><span>|</span><a href="#37186172">next</a><span>|</span><label class="collapse" for="c-37185909">[-]</label><label class="expand" for="c-37185909">[1 more]</label></div><br/><div class="children"><div class="content">That would be a case of higher probability of finding a solution in one step.<p>But the solution would still need to be checked and another candidates generated until a solution is found.<p>Average time would be minimized by generating random vectors each time.<p>But that would increase the worst case to unbounded (effectively infinite) time since an increasingly vanishingly small but finite chance that a solution has not yet been found will exist after any number of steps.<p>Some kind of simple search would be vastly more bounded, but in practice require more computation.</div><br/></div></div></div></div><div id="37186172" class="c"><input type="checkbox" id="c-37186172" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#37183167">parent</a><span>|</span><a href="#37184412">prev</a><span>|</span><a href="#37183316">next</a><span>|</span><label class="collapse" for="c-37186172">[-]</label><label class="expand" for="c-37186172">[5 more]</label></div><br/><div class="children"><div class="content">&gt; it is trivial to construct an algorithm with this property<p>Actually, it is <i>impossible</i> to construct an algorithm with this property, at least under any usual computational model.<p>Every computational model has discrete time units; therefore the amount of time taken cannot be vanishingly small.<p>(This is assuming the usual notion of complexity, where only the <i>asymptotic</i> behavior matters. It doesn&#x27;t matter if it gets increasingly faster over the first million input sizes...it only matters what the behavior is as n -&gt; infinity.)<p>A program cannot be increasingly faster forever.</div><br/><div id="37186212" class="c"><input type="checkbox" id="c-37186212" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37186172">parent</a><span>|</span><a href="#37183316">next</a><span>|</span><label class="collapse" for="c-37186212">[-]</label><label class="expand" for="c-37186212">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Faster as the input grows&quot; is perfectly compatible with a minimum number of time units.  If your definition insists the minimum of time units must be 0, with infinitesimal time getting involved, then your definition sucks.</div><br/><div id="37186443" class="c"><input type="checkbox" id="c-37186443" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37186212">parent</a><span>|</span><a href="#37183316">next</a><span>|</span><label class="collapse" for="c-37186443">[-]</label><label class="expand" for="c-37186443">[3 more]</label></div><br/><div class="children"><div class="content">For a function to strictly decrease forever, at least one of two statements is true:<p>1. It decreases by vanishingly smaller amount.<p>2. It decreases to negative infinity.<p>So...which is it? Infinitesimal time units, or negative time?</div><br/><div id="37186552" class="c"><input type="checkbox" id="c-37186552" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37186443">parent</a><span>|</span><a href="#37186656">next</a><span>|</span><label class="collapse" for="c-37186552">[-]</label><label class="expand" for="c-37186552">[1 more]</label></div><br/><div class="children"><div class="content">Strictly speaking it either tends to negative infinity, or tends to so real number X, which could be any number positive or negative.</div><br/></div></div><div id="37186656" class="c"><input type="checkbox" id="c-37186656" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37186443">parent</a><span>|</span><a href="#37186552">prev</a><span>|</span><a href="#37183316">next</a><span>|</span><label class="collapse" for="c-37186656">[-]</label><label class="expand" for="c-37186656">[1 more]</label></div><br/><div class="children"><div class="content">3. Nobody said &quot;strictly&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="37183316" class="c"><input type="checkbox" id="c-37183316" checked=""/><div class="controls bullet"><span class="by">Q6T46nT668w6i3m</span><span>|</span><a href="#37183167">parent</a><span>|</span><a href="#37186172">prev</a><span>|</span><a href="#37183321">next</a><span>|</span><label class="collapse" for="c-37183316">[-]</label><label class="expand" for="c-37183316">[1 more]</label></div><br/><div class="children"><div class="content">Of course. The obvious examples are probabilistic, e.g., Monte Carlo methods, as an increase in the problem space decreases the number of samples needed.</div><br/></div></div><div id="37183321" class="c"><input type="checkbox" id="c-37183321" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#37183167">parent</a><span>|</span><a href="#37183316">prev</a><span>|</span><a href="#37184300">next</a><span>|</span><label class="collapse" for="c-37183321">[-]</label><label class="expand" for="c-37183321">[1 more]</label></div><br/><div class="children"><div class="content">I could imagine some behaviour along those lines in search engines, specifically if you&#x27;re searching for similar documents. Which none of them seem to — would be useful! Let me know if I&#x27;m wrong! — but imagine a search engine that lets you look for documents &#x27;similar to this document here&#x27;. Also imagine that&#x27;s threshold-based; you want equal levels of similarity regardless of the rarity of the input document.<p>In that case, as the size of the corpus grows it should get easier to find ones in the right range of similarity.</div><br/></div></div><div id="37184300" class="c"><input type="checkbox" id="c-37184300" checked=""/><div class="controls bullet"><span class="by">mjcohen</span><span>|</span><a href="#37183167">parent</a><span>|</span><a href="#37183321">prev</a><span>|</span><a href="#37184426">next</a><span>|</span><label class="collapse" for="c-37184300">[-]</label><label class="expand" for="c-37184300">[2 more]</label></div><br/><div class="children"><div class="content">Depends what you mean by larger. The example that occurs to me is the priblem of determining whether or not an integer is prime. This can be done relatively quickly for numbers of the form 2^p-1 where p is prime, but would take much longer for a much smaller prime not of this form.</div><br/><div id="37185924" class="c"><input type="checkbox" id="c-37185924" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#37183167">root</a><span>|</span><a href="#37184300">parent</a><span>|</span><a href="#37184426">next</a><span>|</span><label class="collapse" for="c-37185924">[-]</label><label class="expand" for="c-37185924">[1 more]</label></div><br/><div class="children"><div class="content">Those would be effectively different problems.<p>Adding the constraint of only needing to classify a particular form of prime will always result in an algorithm of equal or lesser complexity order.</div><br/></div></div></div></div><div id="37184426" class="c"><input type="checkbox" id="c-37184426" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#37183167">parent</a><span>|</span><a href="#37184300">prev</a><span>|</span><a href="#37186494">next</a><span>|</span><label class="collapse" for="c-37184426">[-]</label><label class="expand" for="c-37184426">[1 more]</label></div><br/><div class="children"><div class="content">If you are willing to settle for expected instead of worst case time, there are many string-related algorithms that are O(m&#x2F;n). Intuition is that as the string size grows it&#x27;s &quot;more likely&quot; to have some property on expectation.</div><br/></div></div><div id="37186494" class="c"><input type="checkbox" id="c-37186494" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#37183167">parent</a><span>|</span><a href="#37184426">prev</a><span>|</span><a href="#37184190">next</a><span>|</span><label class="collapse" for="c-37186494">[-]</label><label class="expand" for="c-37186494">[1 more]</label></div><br/><div class="children"><div class="content">If your computational model requires that the algorithm reads the input then I don&#x27;t see how it&#x27;s possible.  Even if above some size the algorithm does nothing but exits the time will still grow linearly with the input from reading.<p>You could imagine an algorithm that takes some astronomical time for size 1, less for 2, etc.. but for any finite time at size 1 there will be some size N where the reading time finally dominates the computation.</div><br/></div></div><div id="37184190" class="c"><input type="checkbox" id="c-37184190" checked=""/><div class="controls bullet"><span class="by">downWidOutaFite</span><span>|</span><a href="#37183167">parent</a><span>|</span><a href="#37186494">prev</a><span>|</span><a href="#37186565">next</a><span>|</span><label class="collapse" for="c-37184190">[-]</label><label class="expand" for="c-37184190">[1 more]</label></div><br/><div class="children"><div class="content">caches? the more input the fewer cache misses</div><br/></div></div></div></div><div id="37186565" class="c"><input type="checkbox" id="c-37186565" checked=""/><div class="controls bullet"><span class="by">inciampati</span><span>|</span><a href="#37183167">prev</a><span>|</span><a href="#37183306">next</a><span>|</span><label class="collapse" for="c-37186565">[-]</label><label class="expand" for="c-37186565">[1 more]</label></div><br/><div class="children"><div class="content">I can no longer read these articles from Quanta and so I instead have generated a TLDR and I&#x27;m happy to share it here for others.<p>Computational complexity theory studies how difficult computational problems are to solve. The P versus NP problem asks whether problems that are easy to check (NP) are also easy to solve (P). This open question has major implications for cryptography, optimization, and more. Researchers have found barriers that suggest proving P ≠ NP will be very difficult. The field of &quot;meta-complexity&quot; studies the complexity of proving hardness results like P ≠ NP. Recent breakthroughs in meta-complexity have advanced our understanding of average-case complexity and brought us closer to resolving the status of problems like MCSP that are important for cryptography. While the P versus NP problem remains open, progress is being made on foundational questions about the nature of efficient computation.</div><br/></div></div><div id="37183306" class="c"><input type="checkbox" id="c-37183306" checked=""/><div class="controls bullet"><span class="by">canvascritic</span><span>|</span><a href="#37186565">prev</a><span>|</span><a href="#37183538">next</a><span>|</span><label class="collapse" for="c-37183306">[-]</label><label class="expand" for="c-37183306">[6 more]</label></div><br/><div class="children"><div class="content">One thing I&#x27;ve always found fascinating is the relationship between quantum computing and complexity classes. With the promise of quantum computers solving certain problems exponentially faster, it&#x27;ll be interesting to see how they fit into our established P vs. NP paradigm. On a side note, the term &quot;limits of knowledge&quot; in the title feels a bit hyperbolic.<p>I always appreciate how Quanta conveys the intricacies of deeply technical topics to a wider audience.</div><br/><div id="37185799" class="c"><input type="checkbox" id="c-37185799" checked=""/><div class="controls bullet"><span class="by">bawolff</span><span>|</span><a href="#37183306">parent</a><span>|</span><a href="#37185386">next</a><span>|</span><label class="collapse" for="c-37185799">[-]</label><label class="expand" for="c-37185799">[2 more]</label></div><br/><div class="children"><div class="content">&gt; With the promise of quantum computers solving certain problems exponentially faster, it&#x27;ll be interesting to see how they fit into our established P vs. NP paradigm.<p>Its been studied for a while now. One of the most interesting things, is there may be problems in BQP that are not in NP.</div><br/><div id="37185835" class="c"><input type="checkbox" id="c-37185835" checked=""/><div class="controls bullet"><span class="by">canvascritic</span><span>|</span><a href="#37183306">root</a><span>|</span><a href="#37185799">parent</a><span>|</span><a href="#37185386">next</a><span>|</span><label class="collapse" for="c-37185835">[-]</label><label class="expand" for="c-37185835">[1 more]</label></div><br/><div class="children"><div class="content">Yes indeed. it&#x27;s intriguing to consider problems in BQP that may not fall into NP. this opens up a world of possibilities and challenges our current understanding of computational complexity.<p>It suggests there are problems solvable by quantum computers that classical ones can&#x27;t even verify the results of. This could lead to fascinating developments in fields like cryptography, where solutions could be found but not easily checked.<p>on the other, it raises questions about the practicality of quantum computing. if we can&#x27;t verify a solution, how do we trust it?<p>Maybe we need to rethink our definitions of &#x27;solving&#x27; and &#x27;verifying&#x27;. after all, these concepts were developed with classical computing in mind.<p>But maybe this this is just a limitation or topological property of our current theoretical framework? Like we&#x27;re trying to fit quantum computing into a model that just isn&#x27;t equipped to handle it.<p>either way, it feels like we are on the cusp of a paradigm shift. Pretty exciting<p>Anyway interested to hear more thoughts on this</div><br/></div></div></div></div><div id="37185386" class="c"><input type="checkbox" id="c-37185386" checked=""/><div class="controls bullet"><span class="by">l33t7332273</span><span>|</span><a href="#37183306">parent</a><span>|</span><a href="#37185799">prev</a><span>|</span><a href="#37183538">next</a><span>|</span><label class="collapse" for="c-37185386">[-]</label><label class="expand" for="c-37185386">[3 more]</label></div><br/><div class="children"><div class="content">It’s interesting to think about, but the complexity classes are actually equal[1]. This sort of makes sense if you think of quantum computers as simulatable by a classical computer.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2001.04383" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2001.04383</a></div><br/><div id="37185767" class="c"><input type="checkbox" id="c-37185767" checked=""/><div class="controls bullet"><span class="by">drdeca</span><span>|</span><a href="#37183306">root</a><span>|</span><a href="#37185386">parent</a><span>|</span><a href="#37185782">next</a><span>|</span><label class="collapse" for="c-37185767">[-]</label><label class="expand" for="c-37185767">[1 more]</label></div><br/><div class="children"><div class="content">Huh? Assuming I understand your comment correctly, that is, <i>not</i> what that paper is showing.<p>That paper is showing that if the verifier has polynomial time computational power, with two provers who each have unlimited computational power, and who have some shared quantum entanglement, are communicating individually with the prover, and the prover also has access to randomness and such, then there is a protocol that can allow the provers to, <i>for any recursively enumerable language</i>, demonstrate to the verifier, for any string, whether that string is in that language.<p>RE is a WAY bigger class than what the verifier can compute alone.
And, is also way bigger than the without-entanglement version, MIP.<p>That paper is showing that adding quantum entanglement to the setup for MIP, allows for <i>way</i> more problems to be in the class.</div><br/></div></div><div id="37185782" class="c"><input type="checkbox" id="c-37185782" checked=""/><div class="controls bullet"><span class="by">bawolff</span><span>|</span><a href="#37183306">root</a><span>|</span><a href="#37185386">parent</a><span>|</span><a href="#37185767">prev</a><span>|</span><a href="#37183538">next</a><span>|</span><label class="collapse" for="c-37185782">[-]</label><label class="expand" for="c-37185782">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not really what that paper is saying.<p>The class of problems computable by a quantum computer is equal to that of a classical computer. That does not neccesarily imply anything about the relationship between BQP and P or BQP and NP.</div><br/></div></div></div></div></div></div><div id="37183538" class="c"><input type="checkbox" id="c-37183538" checked=""/><div class="controls bullet"><span class="by">blintz</span><span>|</span><a href="#37183306">prev</a><span>|</span><a href="#37182805">next</a><span>|</span><label class="collapse" for="c-37183538">[-]</label><label class="expand" for="c-37183538">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s exciting that cryptographic constructions (like m&#x2F;n secret sharing where m is hidden) can solve problems in complexity; I would have expected things to flow mostly the other way.</div><br/></div></div><div id="37182805" class="c"><input type="checkbox" id="c-37182805" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#37183538">prev</a><span>|</span><a href="#37183033">next</a><span>|</span><label class="collapse" for="c-37182805">[-]</label><label class="expand" for="c-37182805">[4 more]</label></div><br/><div class="children"><div class="content">This is easily one of the most well written articles published by quanta. Truly a pleasure to read.</div><br/><div id="37182900" class="c"><input type="checkbox" id="c-37182900" checked=""/><div class="controls bullet"><span class="by">xmonkee</span><span>|</span><a href="#37182805">parent</a><span>|</span><a href="#37183180">next</a><span>|</span><label class="collapse" for="c-37182900">[-]</label><label class="expand" for="c-37182900">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, a lot of love went into this. Could be made into a book, i would buy.</div><br/></div></div><div id="37183180" class="c"><input type="checkbox" id="c-37183180" checked=""/><div class="controls bullet"><span class="by">guga42k</span><span>|</span><a href="#37182805">parent</a><span>|</span><a href="#37182900">prev</a><span>|</span><a href="#37183033">next</a><span>|</span><label class="collapse" for="c-37183180">[-]</label><label class="expand" for="c-37183180">[2 more]</label></div><br/><div class="children"><div class="content">nitpick: I wonder how TSP became NP complete. It would require to polynomial time algorithm to validate the solution. I doubt such algorithm does exist.</div><br/><div id="37183392" class="c"><input type="checkbox" id="c-37183392" checked=""/><div class="controls bullet"><span class="by">teraflop</span><span>|</span><a href="#37182805">root</a><span>|</span><a href="#37183180">parent</a><span>|</span><a href="#37183033">next</a><span>|</span><label class="collapse" for="c-37183392">[-]</label><label class="expand" for="c-37183392">[1 more]</label></div><br/><div class="children"><div class="content">Yes, TSP is in NP.<p>Strictly speaking, the only problems in NP are <i>decision</i> problems, so when we say &quot;TSP is in NP&quot;, we&#x27;re talking about the &quot;decision version of TSP&quot;: given a graph G, does there exist a Hamiltonian circuit with total length &lt;= K?<p>And it&#x27;s straightforward to show that this problem is in NP, because if the answer is &quot;yes&quot;, then simply exhibiting such a tour is enough to provide a polynomial-time-verifiable proof of the answer&#x27;s correctness.<p>(Note that it is not known whether TSP is in co-NP, so it is not known whether one can produce a polynomial-time-verifiable proof of a &quot;no&quot; answer.)<p>But note that if it were to turn out that the decision version of TSP was solvable in polynomial time, then the optimization version would also be in P, because you can just binary-search on all of the possible values of K. This results in at most a polynomial slowdown.</div><br/></div></div></div></div></div></div><div id="37183033" class="c"><input type="checkbox" id="c-37183033" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#37182805">prev</a><span>|</span><a href="#37184800">next</a><span>|</span><label class="collapse" for="c-37183033">[-]</label><label class="expand" for="c-37183033">[3 more]</label></div><br/><div class="children"><div class="content">Is there a missed connection between entropy and circuit complexity? It looks like one might be able to draw some parallels between the two.<p>Other thoughts; it&#x27;s interesting that PvsNP is essentially about the lengths of proofs, and thus it is the task of deciding in poly time whether you can decide all decidable problems whose proofs are polynomial to their encoding.</div><br/><div id="37183331" class="c"><input type="checkbox" id="c-37183331" checked=""/><div class="controls bullet"><span class="by">Q6T46nT668w6i3m</span><span>|</span><a href="#37183033">parent</a><span>|</span><a href="#37184800">next</a><span>|</span><label class="collapse" for="c-37183331">[-]</label><label class="expand" for="c-37183331">[2 more]</label></div><br/><div class="children"><div class="content">This is addressed, rather extensively, in the article.</div><br/><div id="37184201" class="c"><input type="checkbox" id="c-37184201" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#37183033">root</a><span>|</span><a href="#37183331">parent</a><span>|</span><a href="#37184800">next</a><span>|</span><label class="collapse" for="c-37184201">[-]</label><label class="expand" for="c-37184201">[1 more]</label></div><br/><div class="children"><div class="content">Entropy or it beying a metaproof?</div><br/></div></div></div></div></div></div><div id="37184800" class="c"><input type="checkbox" id="c-37184800" checked=""/><div class="controls bullet"><span class="by">mrwnmonm</span><span>|</span><a href="#37183033">prev</a><span>|</span><label class="collapse" for="c-37184800">[-]</label><label class="expand" for="c-37184800">[3 more]</label></div><br/><div class="children"><div class="content">Who can read an article this long these days?</div><br/><div id="37186881" class="c"><input type="checkbox" id="c-37186881" checked=""/><div class="controls bullet"><span class="by">calderknight</span><span>|</span><a href="#37184800">parent</a><span>|</span><a href="#37184934">next</a><span>|</span><label class="collapse" for="c-37186881">[-]</label><label class="expand" for="c-37186881">[1 more]</label></div><br/><div class="children"><div class="content">[delayed]</div><br/></div></div></div></div></div></div></div></div></div></body></html>