<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706000462890" as="style"/><link rel="stylesheet" href="styles.css?v=1706000462890"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/stas00/ml-engineering">ML Engineering Online Book</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>tim_sw</span> | <span>20 comments</span></div><br/><div><div id="39097814" class="c"><input type="checkbox" id="c-39097814" checked=""/><div class="controls bullet"><span class="by">jebarker</span><span>|</span><a href="#39097981">next</a><span>|</span><label class="collapse" for="c-39097814">[-]</label><label class="expand" for="c-39097814">[1 more]</label></div><br/><div class="children"><div class="content">This is gold. I spend my days debugging LLM training setups in support of research and I&#x27;d have loved these notes when I started!</div><br/></div></div><div id="39097981" class="c"><input type="checkbox" id="c-39097981" checked=""/><div class="controls bullet"><span class="by">cyrux004</span><span>|</span><a href="#39097814">prev</a><span>|</span><a href="#39100734">next</a><span>|</span><label class="collapse" for="c-39097981">[-]</label><label class="expand" for="c-39097981">[4 more]</label></div><br/><div class="children"><div class="content">As somebody who works along with Applied Scientist helping them with tasks related to model training and deployemnt; how does one get exposure to more lower level engineering work like optimization, performance etc.
We have an ML infra team; but their goal is building tools around the platform, not necessarily getting workloads run optimially</div><br/><div id="39099139" class="c"><input type="checkbox" id="c-39099139" checked=""/><div class="controls bullet"><span class="by">dayeye2006</span><span>|</span><a href="#39097981">parent</a><span>|</span><a href="#39099531">next</a><span>|</span><label class="collapse" for="c-39099139">[-]</label><label class="expand" for="c-39099139">[2 more]</label></div><br/><div class="children"><div class="content">I think no optimization is possible withoutprofiling. I think getting yourself familiar with the tools to understand the performance of a model might be the 1st step, e.g., <a href="https:&#x2F;&#x2F;pytorch.org&#x2F;tutorials&#x2F;recipes&#x2F;recipes&#x2F;profiler_recipe.html" rel="nofollow">https:&#x2F;&#x2F;pytorch.org&#x2F;tutorials&#x2F;recipes&#x2F;recipes&#x2F;profiler_recip...</a></div><br/><div id="39099237" class="c"><input type="checkbox" id="c-39099237" checked=""/><div class="controls bullet"><span class="by">tanelpoder</span><span>|</span><a href="#39097981">root</a><span>|</span><a href="#39099139">parent</a><span>|</span><a href="#39099531">next</a><span>|</span><label class="collapse" for="c-39099237">[-]</label><label class="expand" for="c-39099237">[1 more]</label></div><br/><div class="children"><div class="content">Yes - understand first, then fix. And you’ll understand by measuring&#x2F;profiling things.<p>I’d also recommend the detailed pytorch optimization case studies by Paul Bridger:<p><a href="https:&#x2F;&#x2F;paulbridger.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;paulbridger.com&#x2F;</a></div><br/></div></div></div></div><div id="39099531" class="c"><input type="checkbox" id="c-39099531" checked=""/><div class="controls bullet"><span class="by">grepLeigh</span><span>|</span><a href="#39097981">parent</a><span>|</span><a href="#39099139">prev</a><span>|</span><a href="#39100734">next</a><span>|</span><label class="collapse" for="c-39099531">[-]</label><label class="expand" for="c-39099531">[1 more]</label></div><br/><div class="children"><div class="content">Brendan Gregg&#x27;s work on system performance and profiling is a good place to start. A lot of ML perf boils down to Linux perf or what the heck is happening in an HPC scheduling system like SLURM. 
<a href="https:&#x2F;&#x2F;www.brendangregg.com&#x2F;linuxperf.html" rel="nofollow">https:&#x2F;&#x2F;www.brendangregg.com&#x2F;linuxperf.html</a></div><br/></div></div></div></div><div id="39100734" class="c"><input type="checkbox" id="c-39100734" checked=""/><div class="controls bullet"><span class="by">hahnchen</span><span>|</span><a href="#39097981">prev</a><span>|</span><a href="#39099906">next</a><span>|</span><label class="collapse" for="c-39100734">[-]</label><label class="expand" for="c-39100734">[2 more]</label></div><br/><div class="children"><div class="content">How do you get experience in this stuff without having a job?</div><br/><div id="39100869" class="c"><input type="checkbox" id="c-39100869" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#39100734">parent</a><span>|</span><a href="#39099906">next</a><span>|</span><label class="collapse" for="c-39100869">[-]</label><label class="expand" for="c-39100869">[1 more]</label></div><br/><div class="children"><div class="content">By reading books like the one submitted, and doing your own small projects?<p>It&#x27;s not that different from learning how to program without already having a programming job.<p>(That isn&#x27;t to say either of these two is easy.  They both require a lot of dedication.)</div><br/></div></div></div></div><div id="39099906" class="c"><input type="checkbox" id="c-39099906" checked=""/><div class="controls bullet"><span class="by">Scene_Cast2</span><span>|</span><a href="#39100734">prev</a><span>|</span><a href="#39097926">next</a><span>|</span><label class="collapse" for="c-39099906">[-]</label><label class="expand" for="c-39099906">[2 more]</label></div><br/><div class="children"><div class="content">I randomly clicked on repeatability and am still curious about how it&#x27;s achieved with distributed training. Wouldn&#x27;t deterministic synchronization make things slow? But I have heard that at least in a couple of big companies, their training is repeatable.</div><br/><div id="39100901" class="c"><input type="checkbox" id="c-39100901" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#39099906">parent</a><span>|</span><a href="#39097926">next</a><span>|</span><label class="collapse" for="c-39100901">[-]</label><label class="expand" for="c-39100901">[1 more]</label></div><br/><div class="children"><div class="content">You would want to make training updates commutative as much as possible.  That way it doesn&#x27;t matter which order you apply the updates in.</div><br/></div></div></div></div><div id="39097926" class="c"><input type="checkbox" id="c-39097926" checked=""/><div class="controls bullet"><span class="by">legerdemain</span><span>|</span><a href="#39099906">prev</a><span>|</span><label class="collapse" for="c-39097926">[-]</label><label class="expand" for="c-39097926">[10 more]</label></div><br/><div class="children"><div class="content">How widespread is Slurm?</div><br/><div id="39098818" class="c"><input type="checkbox" id="c-39098818" checked=""/><div class="controls bullet"><span class="by">p4ul</span><span>|</span><a href="#39097926">parent</a><span>|</span><a href="#39097946">next</a><span>|</span><label class="collapse" for="c-39098818">[-]</label><label class="expand" for="c-39098818">[1 more]</label></div><br/><div class="children"><div class="content">Slurm is absolutely ubiquitous in the high-performance computing (HPC) community. I believe its only similar competitors in the HPC space are the SGE [1] and Torque&#x2F;PBS [2] resource schedulers.<p>I&#x27;m not sure of the exact numbers, but I would guess that an overwhelming majority of the Top 500 Supercomputers [3] are running Slurm. And as others have noted, research computing centers in academia all mostly run Slurm. And Slurm also dominates in the DoE national labs in the US.<p>Oh, and as a [potentially apocryphal] fun fact, the name &quot;Simple Linux Utility for Resource Management (SLURM)&quot; is a backronym from the soda in Futurama! [4]<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Oracle_Grid_Engine" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Oracle_Grid_Engine</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;adaptivecomputing&#x2F;torque">https:&#x2F;&#x2F;github.com&#x2F;adaptivecomputing&#x2F;torque</a><p>[3] <a href="https:&#x2F;&#x2F;www.top500.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.top500.org&#x2F;</a><p>[4] <a href="https:&#x2F;&#x2F;futurama.fandom.com&#x2F;wiki&#x2F;Slurm" rel="nofollow">https:&#x2F;&#x2F;futurama.fandom.com&#x2F;wiki&#x2F;Slurm</a></div><br/></div></div><div id="39097946" class="c"><input type="checkbox" id="c-39097946" checked=""/><div class="controls bullet"><span class="by">jhfdbkofdchk</span><span>|</span><a href="#39097926">parent</a><span>|</span><a href="#39098818">prev</a><span>|</span><a href="#39099141">next</a><span>|</span><label class="collapse" for="c-39097946">[-]</label><label class="expand" for="c-39097946">[1 more]</label></div><br/><div class="children"><div class="content">According to Wikipedia, &quot;Slurm is the workload manager on about 60% of the TOP500 supercomputers.&quot; I have used it as a job manager front end for most computational clusters in the last 10 years or so.</div><br/></div></div><div id="39099141" class="c"><input type="checkbox" id="c-39099141" checked=""/><div class="controls bullet"><span class="by">claytonjy</span><span>|</span><a href="#39097926">parent</a><span>|</span><a href="#39097946">prev</a><span>|</span><a href="#39099125">next</a><span>|</span><label class="collapse" for="c-39099141">[-]</label><label class="expand" for="c-39099141">[1 more]</label></div><br/><div class="children"><div class="content">related, has anyone had success moving from Slurm to Kubernetes for a physical (non-cloud) cluster primarily used for training large models on lots of GPUs?</div><br/></div></div><div id="39099125" class="c"><input type="checkbox" id="c-39099125" checked=""/><div class="controls bullet"><span class="by">nikhilsimha</span><span>|</span><a href="#39097926">parent</a><span>|</span><a href="#39099141">prev</a><span>|</span><a href="#39098102">next</a><span>|</span><label class="collapse" for="c-39099125">[-]</label><label class="expand" for="c-39099125">[1 more]</label></div><br/><div class="children"><div class="content">Llama 2 models were trained on slurm</div><br/></div></div><div id="39098102" class="c"><input type="checkbox" id="c-39098102" checked=""/><div class="controls bullet"><span class="by">vulcan01</span><span>|</span><a href="#39097926">parent</a><span>|</span><a href="#39099125">prev</a><span>|</span><label class="collapse" for="c-39098102">[-]</label><label class="expand" for="c-39098102">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s used in most high-performance computing clusters (except for the folks that are still on Torque, I guess).</div><br/><div id="39098258" class="c"><input type="checkbox" id="c-39098258" checked=""/><div class="controls bullet"><span class="by">legerdemain</span><span>|</span><a href="#39097926">root</a><span>|</span><a href="#39098102">parent</a><span>|</span><label class="collapse" for="c-39098258">[-]</label><label class="expand" for="c-39098258">[4 more]</label></div><br/><div class="children"><div class="content">I see, so it&#x27;s limited to HPC contexts? I&#x27;m just surprised that as a data engineer, I&#x27;ve never seen it in real life.</div><br/><div id="39098510" class="c"><input type="checkbox" id="c-39098510" checked=""/><div class="controls bullet"><span class="by">a_bonobo</span><span>|</span><a href="#39097926">root</a><span>|</span><a href="#39098258">parent</a><span>|</span><label class="collapse" for="c-39098510">[-]</label><label class="expand" for="c-39098510">[3 more]</label></div><br/><div class="children"><div class="content">Definitely! I was in academia for ten years and SLURM is everywhere. It&#x27;s free! Now outside academia, SLURM is nowhere. AWS and Slowflake are king.</div><br/><div id="39098908" class="c"><input type="checkbox" id="c-39098908" checked=""/><div class="controls bullet"><span class="by">jebarker</span><span>|</span><a href="#39097926">root</a><span>|</span><a href="#39098510">parent</a><span>|</span><a href="#39099376">next</a><span>|</span><label class="collapse" for="c-39098908">[-]</label><label class="expand" for="c-39098908">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Now outside academia, SLURM is nowhere<p>Do you mean outside of academia _and_ HPC? Industry HPC clusters using slurm are quite common.</div><br/></div></div><div id="39099376" class="c"><input type="checkbox" id="c-39099376" checked=""/><div class="controls bullet"><span class="by">0cf8612b2e1e</span><span>|</span><a href="#39097926">root</a><span>|</span><a href="#39098510">parent</a><span>|</span><a href="#39098908">prev</a><span>|</span><label class="collapse" for="c-39099376">[-]</label><label class="expand" for="c-39099376">[1 more]</label></div><br/><div class="children"><div class="content">Both of my last two companies used Slurm. Probably just comes down to if the company maintains its own internal compute cluster.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>