<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1703235655988" as="style"/><link rel="stylesheet" href="styles.css?v=1703235655988"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.marginalia.nu/log/94_warc_warc/">WARC&#x27;in the Crawler</a> <span class="domain">(<a href="https://www.marginalia.nu">www.marginalia.nu</a>)</span></div><div class="subtext"><span>Brajeshwar</span> | <span>11 comments</span></div><br/><div><div id="38731000" class="c"><input type="checkbox" id="c-38731000" checked=""/><div class="controls bullet"><span class="by">Smerity</span><span>|</span><a href="#38730776">next</a><span>|</span><label class="collapse" for="c-38731000">[-]</label><label class="expand" for="c-38731000">[4 more]</label></div><br/><div class="children"><div class="content">In the distant past I was the lone engineer of Common Crawl almost a decade ago. Common Crawl heavily leverages the WARC format.<p>My favorite capability of the WARC format borrows from the fact that most compression formats can be written to allow random access. Compression formats such as `gzip` and `zstandard` allow multiple compressed streams to be stuck together and act during decompression as if it&#x27;s one contiguous file.<p>Hence you can create multiple compressions and literally stick them together:<p><pre><code>  $ echo cat &gt; cat.txt
  $ echo dog &gt; dog.txt
  $ zstd cat.txt dog.txt
  $ cat cat.txt.zst dog.txt.zst &gt; catdog.zst
  $ zstdcat catdog.zst
  cat
  dog
</code></pre>
For files composed of only a textual &#x2F; clearly delimited format that means you can fairly trivially leap to a different offset assuming each of the inputs is compressed individually. You lose out on some amount of compression but random lookup seems a fairly reasonable tradeoff.
Common Crawl was able to use this to allow entirely random lookups into web crawl datasets dozens &#x2F; hundreds of terabytes in size without any change in file format for example and utilizing Amazon S3&#x27;s support for HTTP Range requests[1].<p>Trading compression for random lookup is even more forgiving if you create a separate compression dictionary tailored toward your dataset. For web crawling you&#x27;d likely get you the majority of the compression gains back unless pages from the same website are sequentially written which is unlikely in most situations. The website&#x27;s shared template&#x2F;s would result in very high compression gains across files which you&#x27;d lose by allowing random lookup but most crawlers don&#x27;t don&#x27;t operate sequentially so local compression gains are likely smaller than larger.<p>[1]: <a href="https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;HTTP&#x2F;Range_requests" rel="nofollow noreferrer">https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;HTTP&#x2F;Range_requ...</a></div><br/><div id="38731151" class="c"><input type="checkbox" id="c-38731151" checked=""/><div class="controls bullet"><span class="by">electroly</span><span>|</span><a href="#38731000">parent</a><span>|</span><a href="#38730776">next</a><span>|</span><label class="collapse" for="c-38731151">[-]</label><label class="expand" for="c-38731151">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this a benefit you&#x27;d trivially get just by using .zip? I pull individual files out of large .zip archives in S3 using HTTP range requests; works exactly as you&#x27;d expect. You know the zip header is at the end of the file, and the header tells you the offset and length of the compressed entry data so you can request the range. Two requests if you&#x27;ve never seen the .zip before, one if you&#x27;ve got the zip header cached.</div><br/><div id="38732251" class="c"><input type="checkbox" id="c-38732251" checked=""/><div class="controls bullet"><span class="by">Smerity</span><span>|</span><a href="#38731000">root</a><span>|</span><a href="#38731151">parent</a><span>|</span><a href="#38731194">next</a><span>|</span><label class="collapse" for="c-38732251">[-]</label><label class="expand" for="c-38732251">[1 more]</label></div><br/><div class="children"><div class="content">As mentioned it&#x27;s trivial across the spread of compression algorithms supporting this type of behaviour (`gzip`, `zstandard`, `zip`, ...), the header in `zip` making it even more convenient as you note!<p>WARC as a format essentially states that unless you have good reason &quot;record at a time&quot; compression is the preferred[1].
The mixture of &quot;technically possible&quot; and &quot;part of spec&quot; is what makes it so useful - any generic WARC tool can support random access, there are explicit fields to index over (URL), and even non-conforming WARC files can be easily rewritten to add such a capability.<p>[1]: <a href="https:&#x2F;&#x2F;iipc.github.io&#x2F;warc-specifications&#x2F;specifications&#x2F;warc-format&#x2F;warc-1.0&#x2F;#record-at-time-compression" rel="nofollow noreferrer">https:&#x2F;&#x2F;iipc.github.io&#x2F;warc-specifications&#x2F;specifications&#x2F;wa...</a></div><br/></div></div></div></div></div></div><div id="38730776" class="c"><input type="checkbox" id="c-38730776" checked=""/><div class="controls bullet"><span class="by">kingforaday</span><span>|</span><a href="#38731000">prev</a><span>|</span><a href="#38732045">next</a><span>|</span><label class="collapse" for="c-38730776">[-]</label><label class="expand" for="c-38730776">[3 more]</label></div><br/><div class="children"><div class="content">If anyone&#x27;s interested in web crawling technology, check out Heretrix [1], been around since 2004 and while not the most performant it has incorporated many responsible disciplines in the design and as this article pointed out, WARC format.<p>1. <a href="https:&#x2F;&#x2F;heritrix.readthedocs.io" rel="nofollow noreferrer">https:&#x2F;&#x2F;heritrix.readthedocs.io</a></div><br/><div id="38730956" class="c"><input type="checkbox" id="c-38730956" checked=""/><div class="controls bullet"><span class="by">fosstrack</span><span>|</span><a href="#38730776">parent</a><span>|</span><a href="#38730924">next</a><span>|</span><label class="collapse" for="c-38730956">[-]</label><label class="expand" for="c-38730956">[1 more]</label></div><br/><div class="children"><div class="content">Second that. Anyone interested in studying web crawler tech should definitely take a look at Heritrix. I had used it extensively when it was still in 2.x. They got so many things right about writing well-behaved and fault tolerant crawlers. Plus the code is very modular, and extensible, if you know some Java. The other popular option then was Apache Nutch, but it had too much hadoop baggage.</div><br/></div></div><div id="38730924" class="c"><input type="checkbox" id="c-38730924" checked=""/><div class="controls bullet"><span class="by">abracadaniel</span><span>|</span><a href="#38730776">parent</a><span>|</span><a href="#38730956">prev</a><span>|</span><a href="#38732045">next</a><span>|</span><label class="collapse" for="c-38730924">[-]</label><label class="expand" for="c-38730924">[1 more]</label></div><br/><div class="children"><div class="content">Its performance shines in larger scales. It’s designed for politeness to individual domains, but scales out well for very wide crawls of many domains. It’s pretty much endlessly configurable, but not the easiest to learn.</div><br/></div></div></div></div><div id="38732045" class="c"><input type="checkbox" id="c-38732045" checked=""/><div class="controls bullet"><span class="by">lawik</span><span>|</span><a href="#38730776">prev</a><span>|</span><a href="#38730935">next</a><span>|</span><label class="collapse" for="c-38732045">[-]</label><label class="expand" for="c-38732045">[1 more]</label></div><br/><div class="children"><div class="content">If you are working a lot with those parquet files it might be worth looking at Apache Arrow which is an in-memory&#x2F;wire format for working with columnar data. It has a lot of good support for parquet from what I gather and is really focused on allowing efficient wrangling of data. Zero-copy and all that.<p>Note: no affiliation, just in a deep rabbit hole on data</div><br/></div></div><div id="38730935" class="c"><input type="checkbox" id="c-38730935" checked=""/><div class="controls bullet"><span class="by">keyle</span><span>|</span><a href="#38732045">prev</a><span>|</span><a href="#38731103">next</a><span>|</span><label class="collapse" for="c-38730935">[-]</label><label class="expand" for="c-38730935">[1 more]</label></div><br/><div class="children"><div class="content">Love reading updates from marginalia. Always good technical posts of a DIY solution with good balance between efficient and good enough.</div><br/></div></div><div id="38731103" class="c"><input type="checkbox" id="c-38731103" checked=""/><div class="controls bullet"><span class="by">sergiomattei</span><span>|</span><a href="#38730935">prev</a><span>|</span><label class="collapse" for="c-38731103">[-]</label><label class="expand" for="c-38731103">[1 more]</label></div><br/><div class="children"><div class="content">I wish Apple would’ve open sourced the .webarchive format.<p>Nothing beats the user experience: Cmd-S in Safari and select “Web Archive”. It’s downloaded in permanent copy, indexed by Spotlight and accessible on all your devices.<p>I use it for collecting recipes around the web. However, I’m a bit concerned about data longevity. I’ve tried other more open formats (loved Singlefile) but none have the UX and support that this has. It’s so simple (as it should be).</div><br/></div></div></div></div></div></div></div></body></html>