<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712998867886" as="style"/><link rel="stylesheet" href="styles.css?v=1712998867886"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/tinygrad/open-gpu-kernel-modules">Hacked Nvidia 4090 GPU driver to enable P2P</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>nikitml</span> | <span>297 comments</span></div><br/><div><div id="40021626" class="c"><input type="checkbox" id="c-40021626" checked=""/><div class="controls bullet"><span class="by">qxfys</span><span>|</span><a href="#40013087">next</a><span>|</span><label class="collapse" for="c-40021626">[-]</label><label class="expand" for="c-40021626">[1 more]</label></div><br/><div class="children"><div class="content">I am amazed how people always find a way to make this kind of thing work. kudos!</div><br/></div></div><div id="40013087" class="c"><input type="checkbox" id="c-40013087" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40021626">prev</a><span>|</span><a href="#40012843">next</a><span>|</span><label class="collapse" for="c-40013087">[-]</label><label class="expand" for="c-40013087">[65 more]</label></div><br/><div class="children"><div class="content">Incredible! I&#x27;d been wondering if this was possible. Now the only thing standing in the way of my 4x4090 rig for local LLMs is finding time to build it. With tensor parallelism, this will be both massively cheaper and faster for inference than a H100 SXM.<p>I still don&#x27;t understand why they went with 6 GPUs for the tinybox. Many things will only function well with 4 or 8 GPUs. It seems like the worst of both worlds now (use 4 GPUs but pay for 6 GPUs, don&#x27;t have 8 GPUs).</div><br/><div id="40015272" class="c"><input type="checkbox" id="c-40015272" checked=""/><div class="controls bullet"><span class="by">georgehotz</span><span>|</span><a href="#40013087">parent</a><span>|</span><a href="#40013494">next</a><span>|</span><label class="collapse" for="c-40015272">[-]</label><label class="expand" for="c-40015272">[12 more]</label></div><br/><div class="children"><div class="content">tinygrad supports uneven splits. There&#x27;s no fundamental reason for 4 or 8, and work should almost fully parallelize on any number of GPUs with good software.<p>We chose 6 because we have 128 PCIe lanes, aka 8 16x ports. We use 1 for NVMe and 1 for networking, leaving 6 for GPUs to connect them in full fabric. If we used 4 GPUs, we&#x27;d be wasting PCIe, and if we used 8 there would be no room for external connectivity aside from a few USB3 ports.</div><br/><div id="40019044" class="c"><input type="checkbox" id="c-40019044" checked=""/><div class="controls bullet"><span class="by">WanderPanda</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015272">parent</a><span>|</span><a href="#40017012">next</a><span>|</span><label class="collapse" for="c-40019044">[-]</label><label class="expand" for="c-40019044">[1 more]</label></div><br/><div class="children"><div class="content">Did you at least front run the market and stocked up of 4090ies before this release? 
Also gamers are probably not too happy about these developments :D</div><br/></div></div><div id="40017012" class="c"><input type="checkbox" id="c-40017012" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015272">parent</a><span>|</span><a href="#40019044">prev</a><span>|</span><a href="#40015849">next</a><span>|</span><label class="collapse" for="c-40017012">[-]</label><label class="expand" for="c-40017012">[1 more]</label></div><br/><div class="children"><div class="content">That is very interesting if tinygrad can support it! Every other library I&#x27;ve seen had the limitation on dividing the heads, so I&#x27;d (perhaps incorrectly) assumed that it&#x27;s a general problem for inference.</div><br/></div></div><div id="40015849" class="c"><input type="checkbox" id="c-40015849" checked=""/><div class="controls bullet"><span class="by">davidzweig</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015272">parent</a><span>|</span><a href="#40017012">prev</a><span>|</span><a href="#40015426">next</a><span>|</span><label class="collapse" for="c-40015849">[-]</label><label class="expand" for="c-40015849">[7 more]</label></div><br/><div class="children"><div class="content">Is it possible a similar patch would work for P2P on 3090s?<p>btw, I found a Gigabyte board on Taobao that is unlisted on their site: MZF2-AC0, costs $900. 2 socket Epyc and 10 PCIE slots, may be of interest. A case that should fit, with 2x 2000W Great Wall PSUs and PDU is 4050 RMB (<a href="https:&#x2F;&#x2F;www.toploong.com&#x2F;en&#x2F;4GPU-server-case&#x2F;644.html" rel="nofollow">https:&#x2F;&#x2F;www.toploong.com&#x2F;en&#x2F;4GPU-server-case&#x2F;644.html</a>). You still need blower GPUs.</div><br/><div id="40016085" class="c"><input type="checkbox" id="c-40016085" checked=""/><div class="controls bullet"><span class="by">georgehotz</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015849">parent</a><span>|</span><a href="#40020450">next</a><span>|</span><label class="collapse" for="c-40016085">[-]</label><label class="expand" for="c-40016085">[2 more]</label></div><br/><div class="children"><div class="content">It should if your 3090s have Resizable BAR support in the VBIOS. AFAIK most card manufacturers released BIOS updates enabling this.<p>Re: 3090 NVLink, that only allows pairs of cards to be connected. PCIe allows full fabric switch of many cards.</div><br/><div id="40017749" class="c"><input type="checkbox" id="c-40017749" checked=""/><div class="controls bullet"><span class="by">Ratiofarmings</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40016085">parent</a><span>|</span><a href="#40020450">next</a><span>|</span><label class="collapse" for="c-40017749">[-]</label><label class="expand" for="c-40017749">[1 more]</label></div><br/><div class="children"><div class="content">In cases where they didn&#x27;t, the techpowerup vBIOS collection solves the problem.</div><br/></div></div></div></div><div id="40020450" class="c"><input type="checkbox" id="c-40020450" checked=""/><div class="controls bullet"><span class="by">davidzweig</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015849">parent</a><span>|</span><a href="#40016085">prev</a><span>|</span><a href="#40016061">next</a><span>|</span><label class="collapse" for="c-40020450">[-]</label><label class="expand" for="c-40020450">[1 more]</label></div><br/><div class="children"><div class="content">Update, I checked with the case company, toploong, they say that board is a 5mm too big or so for the case.</div><br/></div></div><div id="40016061" class="c"><input type="checkbox" id="c-40016061" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015849">parent</a><span>|</span><a href="#40020450">prev</a><span>|</span><a href="#40015426">next</a><span>|</span><label class="collapse" for="c-40016061">[-]</label><label class="expand" for="c-40016061">[3 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t nvlink work natively on 3090s?  I thought it was only removed (and here re-enabled) in 4090.</div><br/><div id="40016847" class="c"><input type="checkbox" id="c-40016847" checked=""/><div class="controls bullet"><span class="by">qeternity</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40016061">parent</a><span>|</span><a href="#40015426">next</a><span>|</span><label class="collapse" for="c-40016847">[-]</label><label class="expand" for="c-40016847">[2 more]</label></div><br/><div class="children"><div class="content">This not not nvlink.</div><br/></div></div></div></div></div></div><div id="40015426" class="c"><input type="checkbox" id="c-40015426" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015272">parent</a><span>|</span><a href="#40015849">prev</a><span>|</span><a href="#40017602">next</a><span>|</span><label class="collapse" for="c-40015426">[-]</label><label class="expand" for="c-40015426">[1 more]</label></div><br/><div class="children"><div class="content">Have you compared 3x 3090-3090 pairs over NVLink?<p>IMO the most painful thing is that since these hardware configurations are esoteric, there is no software that detects them and moves things around &quot;automatically.&quot; Regardless of what people thing device_map=&quot;auto&quot; does, and anyway, Hugging Face&#x27;s transformers&#x2F;diffusers are all over the place.</div><br/></div></div><div id="40017602" class="c"><input type="checkbox" id="c-40017602" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015272">parent</a><span>|</span><a href="#40015426">prev</a><span>|</span><a href="#40013494">next</a><span>|</span><label class="collapse" for="c-40017602">[-]</label><label class="expand" for="c-40017602">[1 more]</label></div><br/><div class="children"><div class="content">Is there any reason you couldn&#x27;t use 7? 8 PCIe lanes each seems more than sufficient for NVMe and networking.</div><br/></div></div></div></div><div id="40013494" class="c"><input type="checkbox" id="c-40013494" checked=""/><div class="controls bullet"><span class="by">Tepix</span><span>|</span><a href="#40013087">parent</a><span>|</span><a href="#40015272">prev</a><span>|</span><a href="#40014157">next</a><span>|</span><label class="collapse" for="c-40013494">[-]</label><label class="expand" for="c-40013494">[8 more]</label></div><br/><div class="children"><div class="content">6 GPUs because they want fast storage and it uses PCIe lanes.<p>Besides the goal was to run a 70b FP16 model (requiring roughly 140GB VRAM).
6*24GB = 144GB</div><br/><div id="40013802" class="c"><input type="checkbox" id="c-40013802" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013494">parent</a><span>|</span><a href="#40014157">next</a><span>|</span><label class="collapse" for="c-40013802">[-]</label><label class="expand" for="c-40013802">[7 more]</label></div><br/><div class="children"><div class="content">That calculation is incorrect. You need to fit both the model (140GB) and the KV cache (5GB at 32k tokens FP8 with flash attention 2) * batch size into VRAM.<p>If the goal is to run a FP16 70B model as fast as possible, you would want 8 GPUs with P2P, for a total of 192GB VRAM. The model is then split across all 8 GPUs with 8-way tensor parallelism, letting you make use of the full 8TB&#x2F;s memory bandwidth on every iteration. Then you have 50GB spread out remaining for KV cache pages, so you can raise the batch size up to 8 (or maybe more).</div><br/><div id="40013942" class="c"><input type="checkbox" id="c-40013942" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013802">parent</a><span>|</span><a href="#40014157">next</a><span>|</span><label class="collapse" for="c-40013942">[-]</label><label class="expand" for="c-40013942">[6 more]</label></div><br/><div class="children"><div class="content">Iâve got a few 4090s that Iâm planning on doing this with. Would appreciate even the smallest directional tip you can provide on splitting the model that you believe is likely to work.</div><br/><div id="40013978" class="c"><input type="checkbox" id="c-40013978" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013942">parent</a><span>|</span><a href="#40014157">next</a><span>|</span><label class="collapse" for="c-40013978">[-]</label><label class="expand" for="c-40013978">[5 more]</label></div><br/><div class="children"><div class="content">The split is done automatically by the inference engine if you enable tensor parallelism. TensorRT-LLM, vLLM and aphrodite-engine can all do this out of the box. The main thing is just that you need either 4 or 8 GPUs for it to work on current models.</div><br/><div id="40014425" class="c"><input type="checkbox" id="c-40014425" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013978">parent</a><span>|</span><a href="#40014503">prev</a><span>|</span><a href="#40014157">next</a><span>|</span><label class="collapse" for="c-40014425">[-]</label><label class="expand" for="c-40014425">[3 more]</label></div><br/><div class="children"><div class="content">Thank you! Can I run with 2 GPUs or with heterogeneous GPUs that have same RAM? I will try. Just curious if you already have tried.</div><br/><div id="40014445" class="c"><input type="checkbox" id="c-40014445" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014425">parent</a><span>|</span><a href="#40014157">next</a><span>|</span><label class="collapse" for="c-40014445">[-]</label><label class="expand" for="c-40014445">[2 more]</label></div><br/><div class="children"><div class="content">2 GPUs works fine too, as long as your model fits. Using different GPUs with same VRAM however, is highly highly sketchy. Sometimes it works, sometimes it doesn&#x27;t. In any case, it would be limited by the performance of the slower GPU.</div><br/><div id="40014979" class="c"><input type="checkbox" id="c-40014979" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014445">parent</a><span>|</span><a href="#40014157">next</a><span>|</span><label class="collapse" for="c-40014979">[-]</label><label class="expand" for="c-40014979">[1 more]</label></div><br/><div class="children"><div class="content">All right, thank you. I can run it on 2x 4090 and just put the 3090s in different machine.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40014157" class="c"><input type="checkbox" id="c-40014157" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#40013087">parent</a><span>|</span><a href="#40013494">prev</a><span>|</span><a href="#40014382">next</a><span>|</span><label class="collapse" for="c-40014157">[-]</label><label class="expand" for="c-40014157">[4 more]</label></div><br/><div class="children"><div class="content">I was googling public NVIDIA SXM2 materials the other day, and it seemed SXM2&#x2F;NVLink 2.0 just was a six-way system. NVIDIA SXM had updated to versions 3 and 4 since, and this isn&#x27;t based on none of those anyway, but maybe there&#x27;s something we don&#x27;t know that make six-way reasonable.</div><br/><div id="40014181" class="c"><input type="checkbox" id="c-40014181" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014157">parent</a><span>|</span><a href="#40016578">next</a><span>|</span><label class="collapse" for="c-40014181">[-]</label><label class="expand" for="c-40014181">[1 more]</label></div><br/><div class="children"><div class="content">It was probably just before running LLMs with tensor parallelism became interesting. There are plenty of other workloads that can be divided by 6 nicely, it&#x27;s not an end-all thing.</div><br/></div></div><div id="40016578" class="c"><input type="checkbox" id="c-40016578" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014157">parent</a><span>|</span><a href="#40014181">prev</a><span>|</span><a href="#40014382">next</a><span>|</span><label class="collapse" for="c-40016578">[-]</label><label class="expand" for="c-40016578">[2 more]</label></div><br/><div class="children"><div class="content">What is a six-way system?</div><br/><div id="40020374" class="c"><input type="checkbox" id="c-40020374" checked=""/><div class="controls bullet"><span class="by">TylerE</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40016578">parent</a><span>|</span><a href="#40014382">next</a><span>|</span><label class="collapse" for="c-40020374">[-]</label><label class="expand" for="c-40020374">[1 more]</label></div><br/><div class="children"><div class="content">oid school way of saying core (or in this case GPU), basically.</div><br/></div></div></div></div></div></div><div id="40014382" class="c"><input type="checkbox" id="c-40014382" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#40013087">parent</a><span>|</span><a href="#40014157">prev</a><span>|</span><a href="#40014481">next</a><span>|</span><label class="collapse" for="c-40014382">[-]</label><label class="expand" for="c-40014382">[1 more]</label></div><br/><div class="children"><div class="content">6 seems reasonable. 128 Lanes from ThreadRipper needs to have a few for network and NVMe (4x NVMe would be x16 lanes, and 10G network would be another x4 lanes).</div><br/></div></div><div id="40014481" class="c"><input type="checkbox" id="c-40014481" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#40013087">parent</a><span>|</span><a href="#40014382">prev</a><span>|</span><a href="#40013602">next</a><span>|</span><label class="collapse" for="c-40014481">[-]</label><label class="expand" for="c-40014481">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think P2P is very relevant for inference. It&#x27;s important for training. Inference can just be sharded across GPUs without sharing memory between them directly.</div><br/><div id="40014493" class="c"><input type="checkbox" id="c-40014493" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014481">parent</a><span>|</span><a href="#40016342">next</a><span>|</span><label class="collapse" for="c-40014493">[-]</label><label class="expand" for="c-40014493">[1 more]</label></div><br/><div class="children"><div class="content">It can make a difference when using tensor parallelism to run small batch sizes. Not a huge difference like training because we don&#x27;t need to update all weights, but still a noticeable one. In the current inference engines there are some allreduce steps that are implemented using nccl.<p>Also, paged KV cache is usually spread across GPUs.</div><br/></div></div><div id="40016342" class="c"><input type="checkbox" id="c-40016342" checked=""/><div class="controls bullet"><span class="by">namibj</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014481">parent</a><span>|</span><a href="#40014493">prev</a><span>|</span><a href="#40016889">next</a><span>|</span><label class="collapse" for="c-40016342">[-]</label><label class="expand" for="c-40016342">[1 more]</label></div><br/><div class="children"><div class="content">It massively helps arithmetic intensity to batch during inference, and the desired batch sizes by that tend to exceed the memory capacity of a single GPU.
Thus desire to do training-like cluster processing to e.g. use a weight for each inference stream that needs it every time it&#x27;s fetched from memory.
It&#x27;s just that you can&#x27;t fit 100+ inference streams of context on one GPU, typically, thus the desire to shard along less-wasteful (w.r.t. memory bandwidth) dimensions than entire inference streams.</div><br/></div></div><div id="40016889" class="c"><input type="checkbox" id="c-40016889" checked=""/><div class="controls bullet"><span class="by">qeternity</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014481">parent</a><span>|</span><a href="#40016342">prev</a><span>|</span><a href="#40013602">next</a><span>|</span><label class="collapse" for="c-40016889">[-]</label><label class="expand" for="c-40016889">[1 more]</label></div><br/><div class="children"><div class="content">You are talking about data parallelism. Depending on the model tensor parallelism can still be very important for inference.</div><br/></div></div></div></div><div id="40013602" class="c"><input type="checkbox" id="c-40013602" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#40013087">parent</a><span>|</span><a href="#40014481">prev</a><span>|</span><a href="#40013415">next</a><span>|</span><label class="collapse" for="c-40013602">[-]</label><label class="expand" for="c-40013602">[10 more]</label></div><br/><div class="children"><div class="content">&gt; Many things will only function well with 4 or 8 GPUs<p>What do you mean?</div><br/><div id="40013632" class="c"><input type="checkbox" id="c-40013632" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013602">parent</a><span>|</span><a href="#40013643">next</a><span>|</span><label class="collapse" for="c-40013632">[-]</label><label class="expand" for="c-40013632">[8 more]</label></div><br/><div class="children"><div class="content">For example, if you want to run low latency multi-GPU inference with tensor parallelism in TensorRT-LLM, there is a requirement that the number of heads in the model is divisible by the number of GPUs. Most current published models are divisible by 4 and 8, but not 6.</div><br/><div id="40014253" class="c"><input type="checkbox" id="c-40014253" checked=""/><div class="controls bullet"><span class="by">bick_nyers</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013632">parent</a><span>|</span><a href="#40013643">next</a><span>|</span><label class="collapse" for="c-40014253">[-]</label><label class="expand" for="c-40014253">[7 more]</label></div><br/><div class="children"><div class="content">Interesting... 1 Zen 4 EPYC CPU yields a maximum of 128 PCIE lanes so it wouldn&#x27;t be possible to put 8 full fat GPUs on while maintaining some lanes for storage and networking. Same deal with Threadripper Pro.</div><br/><div id="40014285" class="c"><input type="checkbox" id="c-40014285" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014253">parent</a><span>|</span><a href="#40013643">next</a><span>|</span><label class="collapse" for="c-40014285">[-]</label><label class="expand" for="c-40014285">[6 more]</label></div><br/><div class="children"><div class="content">It should be possible with onboard PCIe switches. You probably don&#x27;t need the networking or storage to be all that fast while running the job, so it can dedicate almost all of the bandwidth to the GPU.<p>I don&#x27;t know if there are boards that implement this, though, I&#x27;m only looking at systems with 4x GPUs currently. Even just plugging in a 5kW GPU server in my apartment would be a bit of a challenge. With 4x 4090, the max load would be below 3kW, so a single 240V plug can handle it no issue.</div><br/><div id="40015526" class="c"><input type="checkbox" id="c-40015526" checked=""/><div class="controls bullet"><span class="by">bick_nyers</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014285">parent</a><span>|</span><a href="#40014578">next</a><span>|</span><label class="collapse" for="c-40015526">[-]</label><label class="expand" for="c-40015526">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen it done with a PLX Multiplexer as well, but they add quite a bit of cost:<p><a href="https:&#x2F;&#x2F;c-payne.com&#x2F;products&#x2F;pcie-gen4-switch-backplane-4-x16-4w-mircochip-switchtec-pm40084-plx" rel="nofollow">https:&#x2F;&#x2F;c-payne.com&#x2F;products&#x2F;pcie-gen4-switch-backplane-4-x1...</a><p>Not sure if there exists an 8-way PCIE Gen 5 Multiplexer that doesn&#x27;t cost ludicrous amounts of cash. Ludicrous being a highly subjective and relative term of course.</div><br/><div id="40016683" class="c"><input type="checkbox" id="c-40016683" checked=""/><div class="controls bullet"><span class="by">namibj</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015526">parent</a><span>|</span><a href="#40016080">next</a><span>|</span><label class="collapse" for="c-40016683">[-]</label><label class="expand" for="c-40016683">[2 more]</label></div><br/><div class="children"><div class="content">98 lanes of PCIe 4.0 fabric switch as just the chip (to solder onto a motherboard&#x2F;backplane) costs 850$ (PEX88096).
You could for example take 2 x16 GPUs, pass then through (2<i>2</i>16=64 lanes), and have 2 x16 that bifurcate to at least x4 (might even be x2, I didn&#x27;t find that part of the docs just now) for anything you want, plus 2 x1 for minor stuff.
They do claim to have no problems being connected up into a switching fabric, and very much allow multi-host operations (you will need signal retimers quite soon, though).<p>They&#x27;re the stuff that enables cloud operators to pool like 30 GPUs across like 10 CPU sockets while letting you virtually hot-plug them to fit demand. 
Or when you want to make a SAN with real NVMe-over-PCIe.
Far cheaper than normal networking switches with similar ports (assuming hosts doing just x4 bifurcation, it&#x27;s very comparable to a 50G Ethernet port. The above chip thus matches a 24 port 50G Ethernet switch. Trading reach for only needing retimers, not full NICs, in each connected host. Easily better for HPC clusters up to about 200 kW made from dense compute nodes.), but sadly still lacking affordable COTS parts that don&#x27;t require soldering or contacting sales for pricing (the only COTS with list prices seem to be Broadcom&#x27;s reference designs, for prices befitting an evaluation kit, not a Beowulf cluster).</div><br/><div id="40019042" class="c"><input type="checkbox" id="c-40019042" checked=""/><div class="controls bullet"><span class="by">pests</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40016683">parent</a><span>|</span><a href="#40016080">next</a><span>|</span><label class="collapse" for="c-40019042">[-]</label><label class="expand" for="c-40019042">[1 more]</label></div><br/><div class="children"><div class="content">I really like the information about how the cloud providers do their multiplexing, thanks. There was some tech posted here a few month ago that was similar I found very interesting - plug all devices, ram, hard drives, and CPUS into a larger fabric and a way to spin up &quot;servers&quot; of any size from the pool of resources... wish I could remember the name now.<p>nit: HN formatting messed up your math in the second sentence, I believe you italicized on accident using * for equations.</div><br/></div></div></div></div></div></div><div id="40014578" class="c"><input type="checkbox" id="c-40014578" checked=""/><div class="controls bullet"><span class="by">thangngoc89</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014285">parent</a><span>|</span><a href="#40015526">prev</a><span>|</span><a href="#40013643">next</a><span>|</span><label class="collapse" for="c-40014578">[-]</label><label class="expand" for="c-40014578">[1 more]</label></div><br/><div class="children"><div class="content">8 GPUs x 16 PCIe lanes each = 128 lanes already.<p>Thatâs the limit of single CPU platforms.</div><br/></div></div></div></div></div></div></div></div><div id="40013643" class="c"><input type="checkbox" id="c-40013643" checked=""/><div class="controls bullet"><span class="by">segfaultbuserr</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013602">parent</a><span>|</span><a href="#40013632">prev</a><span>|</span><a href="#40013415">next</a><span>|</span><label class="collapse" for="c-40013643">[-]</label><label class="expand" for="c-40013643">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s more difficult to split your work across 6 GPUs evenly, and easier when you have 4 or 8 GPUs. The latter setups have powers of 2, which for example, can evenly divide a 2D or 3D grid, but 6 GPUs are awkward to program. Thus, the OP argues that a 6-GPU setup is highly suboptimal for many existing applications and there&#x27;s no point to pay more for the extra 2.</div><br/></div></div></div></div><div id="40013415" class="c"><input type="checkbox" id="c-40013415" checked=""/><div class="controls bullet"><span class="by">corn13read2</span><span>|</span><a href="#40013087">parent</a><span>|</span><a href="#40013602">prev</a><span>|</span><a href="#40012843">next</a><span>|</span><label class="collapse" for="c-40013415">[-]</label><label class="expand" for="c-40013415">[25 more]</label></div><br/><div class="children"><div class="content">A macbook is cheaper though</div><br/><div id="40013539" class="c"><input type="checkbox" id="c-40013539" checked=""/><div class="controls bullet"><span class="by">tgtweak</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013415">parent</a><span>|</span><a href="#40013688">next</a><span>|</span><label class="collapse" for="c-40013539">[-]</label><label class="expand" for="c-40013539">[12 more]</label></div><br/><div class="children"><div class="content">The extra $3k you&#x27;d spend on a quad-4090 rig vs the top mbp... ignoring the fact you can&#x27;t put the two on even ground for versatility (very few libraries are adapted to apple silicone let alone optimized).<p>Very few people that would consider an H100&#x2F;A100&#x2F;A800 are going to be cross-shopping a macbook pro for their workloads.</div><br/><div id="40015130" class="c"><input type="checkbox" id="c-40015130" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013539">parent</a><span>|</span><a href="#40013688">next</a><span>|</span><label class="collapse" for="c-40015130">[-]</label><label class="expand" for="c-40015130">[11 more]</label></div><br/><div class="children"><div class="content">&gt; very few libraries are adapted to apple silicone let alone optimized<p>This is a joke, right? Have you been anywhere in the LLM ecosystem for the past year or so? I&#x27;m constantly hearing about new ways in which ASi outperforms traditional platforms, and new projects that are optimized for ASi. Such as, for instance, llama.cpp.</div><br/><div id="40015316" class="c"><input type="checkbox" id="c-40015316" checked=""/><div class="controls bullet"><span class="by">cavisne</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015130">parent</a><span>|</span><a href="#40013688">next</a><span>|</span><label class="collapse" for="c-40015316">[-]</label><label class="expand" for="c-40015316">[10 more]</label></div><br/><div class="children"><div class="content">Nothing compared to Nvidia though. The FLOPS and memory bandwidth is simply not there.</div><br/><div id="40016946" class="c"><input type="checkbox" id="c-40016946" checked=""/><div class="controls bullet"><span class="by">spudlyo</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015316">parent</a><span>|</span><a href="#40017285">next</a><span>|</span><label class="collapse" for="c-40016946">[-]</label><label class="expand" for="c-40016946">[6 more]</label></div><br/><div class="children"><div class="content">The memory bandwidth of the M2 Ultra is around 800GB&#x2F;s verses 1008 GB&#x2F;s for the 4090. While itâs true the M2 has neither the bandwidth or the GPU power, it is not limited to 24G of VRAM per card. The 192G upper limit on the M2 Ultra will have a much easier time running inference on a 70+ billion  parameter model, if that is your aim.<p>Besides size, heat, fan noise, and not having to build it yourself, this is the only area where Apple Silicon might have advantage over a homemade 4090 rig.</div><br/><div id="40017460" class="c"><input type="checkbox" id="c-40017460" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40016946">parent</a><span>|</span><a href="#40017285">next</a><span>|</span><label class="collapse" for="c-40017460">[-]</label><label class="expand" for="c-40017460">[5 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t need GPU power to beat the 4090 in benchmarks: <a href="https:&#x2F;&#x2F;appleinsider.com&#x2F;articles&#x2F;23&#x2F;12&#x2F;13&#x2F;apple-silicon-m3-pro-blows-away-nvidia-rtx-4090-gpu-in-ai-benchmark" rel="nofollow">https:&#x2F;&#x2F;appleinsider.com&#x2F;articles&#x2F;23&#x2F;12&#x2F;13&#x2F;apple-silicon-m3-...</a></div><br/><div id="40017524" class="c"><input type="checkbox" id="c-40017524" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40017460">parent</a><span>|</span><a href="#40017285">next</a><span>|</span><label class="collapse" for="c-40017524">[-]</label><label class="expand" for="c-40017524">[4 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t beat RTX 4090 when it comes to actual LLM inference speed. I bought a Mac Studio for local inference because it was the most convenient way to get something <i>fast enough</i> and with enough RAM to run even 155b models. It&#x27;s great for that, but ultimately it&#x27;s not magic - NVidia hardware still offers more FLOPS and faster RAM.</div><br/><div id="40017724" class="c"><input type="checkbox" id="c-40017724" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40017524">parent</a><span>|</span><a href="#40017285">next</a><span>|</span><label class="collapse" for="c-40017724">[-]</label><label class="expand" for="c-40017724">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It doesn&#x27;t beat RTX 4090 when it comes to actual LLM inference speed<p>Sure, whisper.cpp is not an LLM. The 4090 can&#x27;t even do inference at all on anything over 24GB, while ASi can chug through it even if slightly slower.<p>I wonder if with <a href="https:&#x2F;&#x2F;github.com&#x2F;tinygrad&#x2F;open-gpu-kernel-modules">https:&#x2F;&#x2F;github.com&#x2F;tinygrad&#x2F;open-gpu-kernel-modules</a> (the 4090 P2P patches) it might become a lot faster to split a too-large model across multiple 4090s and still outperform ASi (at least until someone at Apple does an MLX LLM).</div><br/><div id="40017813" class="c"><input type="checkbox" id="c-40017813" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40017724">parent</a><span>|</span><a href="#40017285">next</a><span>|</span><label class="collapse" for="c-40017813">[-]</label><label class="expand" for="c-40017813">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The 4090 can&#x27;t even do inference at all on anything over 24GB, while ASi can chug through it even if slightly slower.<p>Common LLM runners can split model layers between VRAM and system RAM; a PC rig with a 4090 can do inference on models larger than 24G.<p>Where the crossover point where having the whole thing on Apple Silicon unified memory vs. doing split layers on a PC with a 4090 and system RAM is, I don&#x27;t know, but its definitely not âmore than 24G and a 4090 doesn&#x27;t do anythingâ.</div><br/><div id="40018665" class="c"><input type="checkbox" id="c-40018665" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40017813">parent</a><span>|</span><a href="#40017285">next</a><span>|</span><label class="collapse" for="c-40018665">[-]</label><label class="expand" for="c-40018665">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Common LLM runners can split model layers between VRAM and system RAM; a PC rig with a 4090 can do inference on models larger than 24G.<p>Sure and ASi can do inference on models larger than the Unified Memory if you account for streaming the weights from the SSD on-demand. That doesn&#x27;t mean it&#x27;s going to be as fast as keeping the whole thing in RAM, although ASi SSDs are probably not particularly bad as far as SSDs go.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40017285" class="c"><input type="checkbox" id="c-40017285" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40015316">parent</a><span>|</span><a href="#40016946">prev</a><span>|</span><a href="#40013688">next</a><span>|</span><label class="collapse" for="c-40017285">[-]</label><label class="expand" for="c-40017285">[3 more]</label></div><br/><div class="children"><div class="content">Yeah. Let me just walk down to Best Buy and get myself a GPU with over 24 gigabytes of VRAM (impossible) for less than $3,000 (even more impossible). Then tell me ASi is nothing compared to Nvidia.<p>Even the A100 for something around $15,000 (edit: used to say $10,000) only goes up to 80 gigabytes of VRAM, but a 192GB Mac Studio goes for under $6,000.<p>Those figures alone proves Nvidia isn&#x27;t even competing in the consumer or even the enthusiast space anymore. They know you&#x27;ll buy their hardware if you really need it, so they aggressively segment the market with VRAM restrictions.</div><br/><div id="40017354" class="c"><input type="checkbox" id="c-40017354" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40017285">parent</a><span>|</span><a href="#40013688">next</a><span>|</span><label class="collapse" for="c-40017354">[-]</label><label class="expand" for="c-40017354">[2 more]</label></div><br/><div class="children"><div class="content">Where are you getting an A100 80GB for $10k?</div><br/><div id="40017383" class="c"><input type="checkbox" id="c-40017383" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40017354">parent</a><span>|</span><a href="#40013688">next</a><span>|</span><label class="collapse" for="c-40017383">[-]</label><label class="expand" for="c-40017383">[1 more]</label></div><br/><div class="children"><div class="content">Oops, I remembered it being somewhere near $15k but Google got confused and showed me results for the 40GB instead so I put $10k by mistake. Thanks for the correction.<p>A100 80GB goes for around $14,000 - $20,000 on eBay and A100 40GB goes for around $4,000 - $6,000. New (not from eBay - from PNY and such), it looks like an 80GB would set you back $18,000 to $26,000 depending on whether you want HBM2 or HBM2e.<p>Meanwhile you can buy a Mac Studio today without going through a distributor and they&#x27;re under $6,000 if the only thing you care about is having 192GB of Unified Memory.<p>And while the memory bandwidth isn&#x27;t quite as high as the 4090, the M-series chips can run certain models faster anyway, if Apple is to be believed</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40013688" class="c"><input type="checkbox" id="c-40013688" checked=""/><div class="controls bullet"><span class="by">andersa</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013415">parent</a><span>|</span><a href="#40013539">prev</a><span>|</span><a href="#40014548">next</a><span>|</span><label class="collapse" for="c-40013688">[-]</label><label class="expand" for="c-40013688">[2 more]</label></div><br/><div class="children"><div class="content">Sure, it&#x27;s also at least an order of magnitude slower in practice, compared to 4x 4090 running at full speed. We&#x27;re looking at 10 times the memory bandwidth and <i>much</i> greater compute.</div><br/><div id="40018033" class="c"><input type="checkbox" id="c-40018033" checked=""/><div class="controls bullet"><span class="by">chaostheory</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013688">parent</a><span>|</span><a href="#40014548">next</a><span>|</span><label class="collapse" for="c-40018033">[-]</label><label class="expand" for="c-40018033">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, even a Mac Studio is way too slow compared to Nvidia which is too bad because at $7000 maxed to 192gb it would be an easy sell. Hopefully, they will fix this by m5. I donât trust the marketing for m4</div><br/></div></div></div></div><div id="40014548" class="c"><input type="checkbox" id="c-40014548" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013415">parent</a><span>|</span><a href="#40013688">prev</a><span>|</span><a href="#40014727">next</a><span>|</span><label class="collapse" for="c-40014548">[-]</label><label class="expand" for="c-40014548">[2 more]</label></div><br/><div class="children"><div class="content">So is a TI-89.</div><br/><div id="40016165" class="c"><input type="checkbox" id="c-40016165" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014548">parent</a><span>|</span><a href="#40014727">next</a><span>|</span><label class="collapse" for="c-40016165">[-]</label><label class="expand" for="c-40016165">[1 more]</label></div><br/><div class="children"><div class="content">And looks way cooler</div><br/></div></div></div></div><div id="40014727" class="c"><input type="checkbox" id="c-40014727" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013415">parent</a><span>|</span><a href="#40014548">prev</a><span>|</span><a href="#40013892">next</a><span>|</span><label class="collapse" for="c-40014727">[-]</label><label class="expand" for="c-40014727">[4 more]</label></div><br/><div class="children"><div class="content">4x32GB(128GB) DDR4 is ~$250. 4x48GB(192GB) DDR5 is ~$600. Those are even cheaper than upgrade options for Macs($1k).</div><br/><div id="40016446" class="c"><input type="checkbox" id="c-40016446" checked=""/><div class="controls bullet"><span class="by">papichulo2023</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40014727">parent</a><span>|</span><a href="#40013892">next</a><span>|</span><label class="collapse" for="c-40016446">[-]</label><label class="expand" for="c-40016446">[3 more]</label></div><br/><div class="children"><div class="content">No many consumer mobo support 192GB DDR5.</div><br/><div id="40017070" class="c"><input type="checkbox" id="c-40017070" checked=""/><div class="controls bullet"><span class="by">ojbyrne</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40016446">parent</a><span>|</span><a href="#40017069">next</a><span>|</span><label class="collapse" for="c-40017070">[-]</label><label class="expand" for="c-40017070">[1 more]</label></div><br/><div class="children"><div class="content">A lot that have specs showing they support a max of 4x32 DDR5 actually support 4x48 DDR5 via recent BIOS updates.</div><br/></div></div><div id="40017069" class="c"><input type="checkbox" id="c-40017069" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40016446">parent</a><span>|</span><a href="#40017070">prev</a><span>|</span><a href="#40013892">next</a><span>|</span><label class="collapse" for="c-40017069">[-]</label><label class="expand" for="c-40017069">[1 more]</label></div><br/><div class="children"><div class="content">If it supports DDR5 at all, then it should be at most a firmware update away from supporting 48GB dual-rank DIMMs. There are very few consumer motherboards that only have two DDR5 slots; almost all have the four slots necessary to accept 192GB. If you are under the impression that there&#x27;s a widespread limitation on consumer hardware support for these modules, it may simply be due to the fact that 48GB modules did not exist yet when DDR5 first entered the consumer market, and such modules did not start getting mentioned on spec sheets until after they existed.</div><br/></div></div></div></div></div></div><div id="40013892" class="c"><input type="checkbox" id="c-40013892" checked=""/><div class="controls bullet"><span class="by">thangngoc89</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013415">parent</a><span>|</span><a href="#40014727">prev</a><span>|</span><a href="#40012843">next</a><span>|</span><label class="collapse" for="c-40013892">[-]</label><label class="expand" for="c-40013892">[4 more]</label></div><br/><div class="children"><div class="content">training on MPS backend is suboptimal and really slow.</div><br/><div id="40016274" class="c"><input type="checkbox" id="c-40016274" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40013892">parent</a><span>|</span><a href="#40012843">next</a><span>|</span><label class="collapse" for="c-40016274">[-]</label><label class="expand" for="c-40016274">[3 more]</label></div><br/><div class="children"><div class="content">Do people do training on systems this small, or just inference? I could see maybe doing a little bit of fine-tuning, but certainly not from-scratch training.</div><br/><div id="40017595" class="c"><input type="checkbox" id="c-40017595" checked=""/><div class="controls bullet"><span class="by">redox99</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40016274">parent</a><span>|</span><a href="#40020519">next</a><span>|</span><label class="collapse" for="c-40017595">[-]</label><label class="expand" for="c-40017595">[1 more]</label></div><br/><div class="children"><div class="content">If you mean train llama from scratch, you aren&#x27;t going to train it on any single box.<p>But even with a single 3090 you can do quite a lot with LLMs (through QLoRA and similar).</div><br/></div></div><div id="40020519" class="c"><input type="checkbox" id="c-40020519" checked=""/><div class="controls bullet"><span class="by">thangngoc89</span><span>|</span><a href="#40013087">root</a><span>|</span><a href="#40016274">parent</a><span>|</span><a href="#40017595">prev</a><span>|</span><a href="#40012843">next</a><span>|</span><label class="collapse" for="c-40020519">[-]</label><label class="expand" for="c-40020519">[1 more]</label></div><br/><div class="children"><div class="content">Yep. Price&#x2F;performance of multiple 4090s system are way better than the professional cards (Axxx). Also deep learning outside of LLM has many different usage.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40012843" class="c"><input type="checkbox" id="c-40012843" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#40013087">prev</a><span>|</span><a href="#40011649">next</a><span>|</span><label class="collapse" for="c-40012843">[-]</label><label class="expand" for="c-40012843">[8 more]</label></div><br/><div class="children"><div class="content">I wish more hardware companies would publish more documentation and let the community figure out the rest, sort of like what happened to the original IBM VGA (look up &quot;Mode X&quot; and the other non-BIOS modes the hardware is actually capable of - even 800x600x16!) Sadly it seems the majority of them would rather tightly control every aspect of their products&#x27; usage since they can then milk the userbase for more $$$, but IMHO the most productive era of the PC was also when it was the most open.</div><br/><div id="40013286" class="c"><input type="checkbox" id="c-40013286" checked=""/><div class="controls bullet"><span class="by">rplnt</span><span>|</span><a href="#40012843">parent</a><span>|</span><a href="#40014441">next</a><span>|</span><label class="collapse" for="c-40013286">[-]</label><label class="expand" for="c-40013286">[3 more]</label></div><br/><div class="children"><div class="content">Then they couldn&#x27;t charge different customers different amounts for the same HW. It&#x27;s not a win for everyone.</div><br/><div id="40013376" class="c"><input type="checkbox" id="c-40013376" checked=""/><div class="controls bullet"><span class="by">axus</span><span>|</span><a href="#40012843">root</a><span>|</span><a href="#40013286">parent</a><span>|</span><a href="#40018617">next</a><span>|</span><label class="collapse" for="c-40013376">[-]</label><label class="expand" for="c-40013376">[1 more]</label></div><br/><div class="children"><div class="content">The price of 4090 may increase now, in theory locking out some features might have been a favor for some of the customers.</div><br/></div></div><div id="40018617" class="c"><input type="checkbox" id="c-40018617" checked=""/><div class="controls bullet"><span class="by">greggsy</span><span>|</span><a href="#40012843">root</a><span>|</span><a href="#40013286">parent</a><span>|</span><a href="#40013376">prev</a><span>|</span><a href="#40014441">next</a><span>|</span><label class="collapse" for="c-40018617">[-]</label><label class="expand" for="c-40018617">[1 more]</label></div><br/><div class="children"><div class="content">Which (as controversial as it sounds in this kind of forum) is a sensible pricing model to  recover and fund R&amp;D and finance  operations.</div><br/></div></div></div></div><div id="40014441" class="c"><input type="checkbox" id="c-40014441" checked=""/><div class="controls bullet"><span class="by">mhh__</span><span>|</span><a href="#40012843">parent</a><span>|</span><a href="#40013286">prev</a><span>|</span><a href="#40016272">next</a><span>|</span><label class="collapse" for="c-40014441">[-]</label><label class="expand" for="c-40014441">[3 more]</label></div><br/><div class="children"><div class="content">nvidia&#x27;s software is their moat</div><br/><div id="40018461" class="c"><input type="checkbox" id="c-40018461" checked=""/><div class="controls bullet"><span class="by">thot_experiment</span><span>|</span><a href="#40012843">root</a><span>|</span><a href="#40014441">parent</a><span>|</span><a href="#40018186">next</a><span>|</span><label class="collapse" for="c-40018461">[-]</label><label class="expand" for="c-40018461">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a huge overstatement, it&#x27;s a big part of the moat for sure, but there are other significant components (hardware, ecosystem lock-in, heavy academic incentives)</div><br/></div></div></div></div><div id="40016272" class="c"><input type="checkbox" id="c-40016272" checked=""/><div class="controls bullet"><span class="by">golergka</span><span>|</span><a href="#40012843">parent</a><span>|</span><a href="#40014441">prev</a><span>|</span><a href="#40011649">next</a><span>|</span><label class="collapse" for="c-40016272">[-]</label><label class="expand" for="c-40016272">[1 more]</label></div><br/><div class="children"><div class="content">If I&#x27;m a hardware manufacturer and my soft lock on product feature doesn&#x27;t work, I&#x27;ll switch to a hardware lock instead, and the product will just cost more.</div><br/></div></div></div></div><div id="40011649" class="c"><input type="checkbox" id="c-40011649" checked=""/><div class="controls bullet"><span class="by">jstanley</span><span>|</span><a href="#40012843">prev</a><span>|</span><a href="#40013873">next</a><span>|</span><label class="collapse" for="c-40011649">[-]</label><label class="expand" for="c-40011649">[31 more]</label></div><br/><div class="children"><div class="content">What does P2P mean in this context? I Googled it and it sounds like it means &quot;peer to peer&quot;, but what does that mean in the context of a graphics card?</div><br/><div id="40011694" class="c"><input type="checkbox" id="c-40011694" checked=""/><div class="controls bullet"><span class="by">__alexs</span><span>|</span><a href="#40011649">parent</a><span>|</span><a href="#40011682">next</a><span>|</span><label class="collapse" for="c-40011694">[-]</label><label class="expand" for="c-40011694">[22 more]</label></div><br/><div class="children"><div class="content">It means you can send data from the memory of 1 GPU to another GPU without going via RAM. <a href="https:&#x2F;&#x2F;xilinx.github.io&#x2F;XRT&#x2F;master&#x2F;html&#x2F;p2p.html" rel="nofollow">https:&#x2F;&#x2F;xilinx.github.io&#x2F;XRT&#x2F;master&#x2F;html&#x2F;p2p.html</a></div><br/><div id="40011779" class="c"><input type="checkbox" id="c-40011779" checked=""/><div class="controls bullet"><span class="by">ot1138</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40011694">parent</a><span>|</span><a href="#40011682">next</a><span>|</span><label class="collapse" for="c-40011779">[-]</label><label class="expand" for="c-40011779">[21 more]</label></div><br/><div class="children"><div class="content">Is this really efficient or practical? My understanding is that the latency required to copy memory from CPU or RAM to GPU negates any performance benefits (much less running over a network!)</div><br/><div id="40012070" class="c"><input type="checkbox" id="c-40012070" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40011779">parent</a><span>|</span><a href="#40016647">next</a><span>|</span><label class="collapse" for="c-40012070">[-]</label><label class="expand" for="c-40012070">[14 more]</label></div><br/><div class="children"><div class="content">Yes, the point here is that you do a direct write from one cards memory to the other using PCIe.<p>In older NVidia cards this could be done through a faster link called NVLink but the hardware for that was ripped out of consumer grade cards and is only in data center grade cards now.<p>Until this post it seemed like they had ripped all such functionality of their consumer cards, but it looks like you can still get it working at lower speeds using the PCIe bus.</div><br/><div id="40014107" class="c"><input type="checkbox" id="c-40014107" checked=""/><div class="controls bullet"><span class="by">spxneo</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40012070">parent</a><span>|</span><a href="#40013626">next</a><span>|</span><label class="collapse" for="c-40014107">[-]</label><label class="expand" for="c-40014107">[11 more]</label></div><br/><div class="children"><div class="content">so whats stopping from somebody buying a ton of GPUs that are cheap and wiring it up via P2P like we saw with crypto mining</div><br/><div id="40016358" class="c"><input type="checkbox" id="c-40016358" checked=""/><div class="controls bullet"><span class="by">genewitch</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40014107">parent</a><span>|</span><a href="#40014341">next</a><span>|</span><label class="collapse" for="c-40016358">[-]</label><label class="expand" for="c-40016358">[4 more]</label></div><br/><div class="children"><div class="content">crypto mining only needs 1 PCIe lane per GPU, so you can fit 24+ GPUs on a standard consumer CPU motherboard (24-32 lanes depending on the CPU). Apparently  ML workloads require more interconnect bandwidth when doing parallel compute, so each card in this demo system uses 16 lanes, and therefore requires 1.) full size slots, and 2.) epyc[0] or xeon based systems with 128 lanes (or at least greater than 32 lanes).<p>per 1 above crypto &quot;boards&quot; have lots of x1 (or x4) slots, the really short PCIe slots. You then use a riser that uses USB3 cables to go to a full size slot on a small board, with power connectors on it. If your board only has x8 or x16 slots (the full size slot) you can buy a breakout PCIe board that splits that into four slots, using 4 USB-3 cables, again, to boards with full size slots and power connectors. These are <i>different</i> than the PCIe riser boards you can buy for use with cases that allow the GPUs to be placed vertically rather than horizontally, as those have full x16 &quot;fabric&quot; that interconnect between the riser and the board with the x16 slot on them.<p>[0] i didn&#x27;t read the article because i&#x27;m not planning on buying a threadripper (48-64+ lanes) or an epyc (96-128 lanes?) just to run AI workloads when i could just rent them for the kind of usage i do.</div><br/><div id="40016575" class="c"><input type="checkbox" id="c-40016575" checked=""/><div class="controls bullet"><span class="by">myself248</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40016358">parent</a><span>|</span><a href="#40014341">next</a><span>|</span><label class="collapse" for="c-40016575">[-]</label><label class="expand" for="c-40016575">[3 more]</label></div><br/><div class="children"><div class="content">Oooo, got a link to one of these fabric boards? I&#x27;ve been playing with stupid PCIe tricks but that&#x27;s a new one on me.</div><br/><div id="40017309" class="c"><input type="checkbox" id="c-40017309" checked=""/><div class="controls bullet"><span class="by">genewitch</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40016575">parent</a><span>|</span><a href="#40014341">next</a><span>|</span><label class="collapse" for="c-40017309">[-]</label><label class="expand" for="c-40017309">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.amazon.com&#x2F;gp&#x2F;product&#x2F;B07DMNJ6QM&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.amazon.com&#x2F;gp&#x2F;product&#x2F;B07DMNJ6QM&#x2F;</a><p>i used to use this one when i had all (three of my) nvme -&gt; 4x sata boardlets and therefore could not fit a GPU in a PCIe slot due to the cabling mess.</div><br/><div id="40018474" class="c"><input type="checkbox" id="c-40018474" checked=""/><div class="controls bullet"><span class="by">myself248</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40017309">parent</a><span>|</span><a href="#40014341">next</a><span>|</span><label class="collapse" for="c-40018474">[-]</label><label class="expand" for="c-40018474">[1 more]</label></div><br/><div class="children"><div class="content">Oh, um, just a flexible riser.<p>I thought we were using &quot;fabric&quot; to mean &quot;switching matrix&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="40014341" class="c"><input type="checkbox" id="c-40014341" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40014107">parent</a><span>|</span><a href="#40016358">prev</a><span>|</span><a href="#40016121">next</a><span>|</span><label class="collapse" for="c-40014341">[-]</label><label class="expand" for="c-40014341">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what this thread is about. Geohot is doing that.</div><br/></div></div><div id="40016121" class="c"><input type="checkbox" id="c-40016121" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40014107">parent</a><span>|</span><a href="#40014341">prev</a><span>|</span><a href="#40016951">next</a><span>|</span><label class="collapse" for="c-40016121">[-]</label><label class="expand" for="c-40016121">[1 more]</label></div><br/><div class="children"><div class="content">Crypto mining could make use of lots of GPUs in a single cheap system precisely because it did not need any significant PCIe bandwidth, and would not have benefited at all from p2p DMA. Anything that <i>does</i> benefit from using p2p DMA is unsuitable for running with just one PCIe lane per GPU.</div><br/></div></div><div id="40016951" class="c"><input type="checkbox" id="c-40016951" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40014107">parent</a><span>|</span><a href="#40016121">prev</a><span>|</span><a href="#40013626">next</a><span>|</span><label class="collapse" for="c-40016951">[-]</label><label class="expand" for="c-40016951">[4 more]</label></div><br/><div class="children"><div class="content">PCIe P2P still has to go up to a central hub thing and back because PCIe is not a bus. That central hub thing is made by very few players(most famously PLX Technologies) and it costs a lot.</div><br/><div id="40017121" class="c"><input type="checkbox" id="c-40017121" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40016951">parent</a><span>|</span><a href="#40020117">next</a><span>|</span><label class="collapse" for="c-40017121">[-]</label><label class="expand" for="c-40017121">[2 more]</label></div><br/><div class="children"><div class="content">PCIe p2p transactions that end up routed through the CPU&#x27;s PCIe root complex still have performance advantages over split transactions using the CPU&#x27;s DRAM as an intermediate buffer. Separate PCIe switches are not necessary except when the CPU doesn&#x27;t support routing p2p transactions, which IIRC was not a problem on anything more mainstream than IBM POWER.</div><br/><div id="40021594" class="c"><input type="checkbox" id="c-40021594" checked=""/><div class="controls bullet"><span class="by">numpad0</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40017121">parent</a><span>|</span><a href="#40020117">next</a><span>|</span><label class="collapse" for="c-40021594">[-]</label><label class="expand" for="c-40021594">[1 more]</label></div><br/><div class="children"><div class="content">Maybe not strictly necessary, but a separate PCIe backplane just for P2P bandwidth bypasses topology and bottleneck mess[1][2] of PC platform altogether and might be useful. I suspect this was the original premise for NVLink too.<p>1: <a href="https:&#x2F;&#x2F;assets.hardwarezone.com&#x2F;img&#x2F;2023&#x2F;09&#x2F;pre-meteror-lake-processor-model.jpg" rel="nofollow">https:&#x2F;&#x2F;assets.hardwarezone.com&#x2F;img&#x2F;2023&#x2F;09&#x2F;pre-meteror-lake...</a><p>2: <a href="https:&#x2F;&#x2F;www.gigabyte.com&#x2F;FileUpload&#x2F;Global&#x2F;MicroSite&#x2F;579&#x2F;innergigabyteimages&#x2F;MC13-LE1_BlockDiagram.png" rel="nofollow">https:&#x2F;&#x2F;www.gigabyte.com&#x2F;FileUpload&#x2F;Global&#x2F;MicroSite&#x2F;579&#x2F;inn...</a></div><br/></div></div></div></div></div></div></div></div><div id="40013626" class="c"><input type="checkbox" id="c-40013626" checked=""/><div class="controls bullet"><span class="by">sparky_</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40012070">parent</a><span>|</span><a href="#40014107">prev</a><span>|</span><a href="#40016647">next</a><span>|</span><label class="collapse" for="c-40013626">[-]</label><label class="expand" for="c-40013626">[2 more]</label></div><br/><div class="children"><div class="content">I take it this is mostly useful for compute workloads, neural networks, LLM and the like -- not for actual graphics rendering?</div><br/><div id="40014020" class="c"><input type="checkbox" id="c-40014020" checked=""/><div class="controls bullet"><span class="by">CYR1X</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40013626">parent</a><span>|</span><a href="#40016647">next</a><span>|</span><label class="collapse" for="c-40014020">[-]</label><label class="expand" for="c-40014020">[1 more]</label></div><br/><div class="children"><div class="content">yes</div><br/></div></div></div></div></div></div><div id="40016647" class="c"><input type="checkbox" id="c-40016647" checked=""/><div class="controls bullet"><span class="by">jmalicki</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40011779">parent</a><span>|</span><a href="#40012070">prev</a><span>|</span><a href="#40012068">next</a><span>|</span><label class="collapse" for="c-40016647">[-]</label><label class="expand" for="c-40016647">[1 more]</label></div><br/><div class="children"><div class="content">For very large models, the weights may not fit on one GPU.<p>Also, sometimes having more than one GPU enables larger batch sizes if each GPU can only hold the activations for perhaps one or two training examples.<p>There is definitely a performance hit, but GPU&lt;-&gt;GPU peer is less latency than GPU-&gt;CPU-&gt;software context switch-&gt;GPU.<p>For &quot;normal&quot; pytorch training, the training is generally streamed through the GPU.  The model does a batch training step on one batch while the next one is being loaded, and the transfer time is usually less than than the time it takes to do the forward and backward passes through the batch.<p>For multi-GPU there are various data parallel and model parallel topologies of how to sort it, and there are ways of mitigating latency by interleaving some operations to not take the full hit, but multi-GPU training is definitely not perfectly parallel.  It is almost required for some large models, and sometimes having a mildly larger batch helps training convergence speed enough to overcome the latency hit on each batch.</div><br/></div></div><div id="40012068" class="c"><input type="checkbox" id="c-40012068" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40011779">parent</a><span>|</span><a href="#40016647">prev</a><span>|</span><a href="#40020220">next</a><span>|</span><label class="collapse" for="c-40012068">[-]</label><label class="expand" for="c-40012068">[1 more]</label></div><br/><div class="children"><div class="content">Peer to peer as in one pcie slot directly to another without going through the CPU&#x2F;RAM, not peer to peer as in one PC to another over the network port.</div><br/></div></div><div id="40020220" class="c"><input type="checkbox" id="c-40020220" checked=""/><div class="controls bullet"><span class="by">publicmail</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40011779">parent</a><span>|</span><a href="#40012068">prev</a><span>|</span><a href="#40011804">next</a><span>|</span><label class="collapse" for="c-40020220">[-]</label><label class="expand" for="c-40020220">[1 more]</label></div><br/><div class="children"><div class="content">PCIe busses are like a tree with âhubsâ (really switches).<p>Imagine you have a PC with a PCIe x16 interface which is attached to a PCIe switch that has four x16 downstream ports, each attached to a GPU. Those GPUs are capable of moving data in and out of their PCIe interfaces at full speed.<p>If you wanted to transfer data from GPU0 and 1 to GPU2 and 3, you have basically 2 options:<p>- Have GPU0 and 1 move their data to CPU DRAM, then have GPU2 and 3 fetch it<p>- Have GPU0 and 1 write their data directly to GPU2 and 3 through the switch theyâre connected to without ever going up to the CPU at all<p>In this case, option 2 is better both because it avoids the extra copy to CPU DRAM and also because it avoids the bottleneck of two GPUs trying to push x16 worth of data up through the CPUs single x16 port. This is known as peer to peer.<p>There are some other scenarios where the data still must go up to the CPU port and back due to ACS, and this is still technically P2P, but doesnât avoid the bottleneck like routing through the switch would.</div><br/></div></div><div id="40011804" class="c"><input type="checkbox" id="c-40011804" checked=""/><div class="controls bullet"><span class="by">brrrrrm</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40011779">parent</a><span>|</span><a href="#40020220">prev</a><span>|</span><a href="#40011914">next</a><span>|</span><label class="collapse" for="c-40011804">[-]</label><label class="expand" for="c-40011804">[1 more]</label></div><br/><div class="children"><div class="content">Yea. Itâs one less hop through slow memory</div><br/></div></div><div id="40011914" class="c"><input type="checkbox" id="c-40011914" checked=""/><div class="controls bullet"><span class="by">whereismyacc</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40011779">parent</a><span>|</span><a href="#40011804">prev</a><span>|</span><a href="#40011682">next</a><span>|</span><label class="collapse" for="c-40011914">[-]</label><label class="expand" for="c-40011914">[2 more]</label></div><br/><div class="children"><div class="content">this would be directly over the memory bus right? I think it&#x27;s just always going to be faster like this if you can do it?</div><br/><div id="40016856" class="c"><input type="checkbox" id="c-40016856" checked=""/><div class="controls bullet"><span class="by">toast0</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40011914">parent</a><span>|</span><a href="#40011682">next</a><span>|</span><label class="collapse" for="c-40016856">[-]</label><label class="expand" for="c-40016856">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s not really any busses in modern computers. It&#x27;s all point to point messaging. You can think of a computer as a distributed system in a way.<p>PCI has a shared address space which usually includes system memory (memory mapped i&#x2F;o). There&#x27;s a second, smaller shared address space dedicated to i&#x2F;o, mostly used to retain compatability with PC standards developed by the ancients.<p>But yeah, I&#x27;d expect to typically have better throughput and latency with peer to peer communication than peer to system ram to peer. Depending on details, it might not always be better though, distributed systems are complex, and sometimes adding a seperate buffer between peers can help things greatly.</div><br/></div></div></div></div></div></div></div></div><div id="40011682" class="c"><input type="checkbox" id="c-40011682" checked=""/><div class="controls bullet"><span class="by">haunter</span><span>|</span><a href="#40011649">parent</a><span>|</span><a href="#40011694">prev</a><span>|</span><a href="#40013120">next</a><span>|</span><label class="collapse" for="c-40011682">[-]</label><label class="expand" for="c-40011682">[1 more]</label></div><br/><div class="children"><div class="content">Shared memory access for Nvidia GPUs<p><a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;gpudirect" rel="nofollow">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;gpudirect</a></div><br/></div></div><div id="40016187" class="c"><input type="checkbox" id="c-40016187" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#40011649">parent</a><span>|</span><a href="#40011691">prev</a><span>|</span><a href="#40013903">next</a><span>|</span><label class="collapse" for="c-40016187">[-]</label><label class="expand" for="c-40016187">[1 more]</label></div><br/><div class="children"><div class="content">Stupid terminology. Might as well call an RS-232 link &quot;peer to peer&quot;.</div><br/></div></div><div id="40013903" class="c"><input type="checkbox" id="c-40013903" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#40011649">parent</a><span>|</span><a href="#40016187">prev</a><span>|</span><a href="#40011680">next</a><span>|</span><label class="collapse" for="c-40013903">[-]</label><label class="expand" for="c-40013903">[3 more]</label></div><br/><div class="children"><div class="content">The correct term, and the one most people would have used in the past, is &quot;bus mastering.&quot;</div><br/><div id="40014387" class="c"><input type="checkbox" id="c-40014387" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40013903">parent</a><span>|</span><a href="#40011680">next</a><span>|</span><label class="collapse" for="c-40014387">[-]</label><label class="expand" for="c-40014387">[2 more]</label></div><br/><div class="children"><div class="content">PCIe isn&#x27;t a bus and it doesn&#x27;t really have a concept of mastering. All PCI DMA was based on bus mastering but P2P DMA is trickier than normal DMA.</div><br/><div id="40020153" class="c"><input type="checkbox" id="c-40020153" checked=""/><div class="controls bullet"><span class="by">publicmail</span><span>|</span><a href="#40011649">root</a><span>|</span><a href="#40014387">parent</a><span>|</span><a href="#40011680">next</a><span>|</span><label class="collapse" for="c-40020153">[-]</label><label class="expand" for="c-40020153">[1 more]</label></div><br/><div class="children"><div class="content">I consider it bus mastering when the endpoints initiate the transactions</div><br/></div></div></div></div></div></div></div></div><div id="40013873" class="c"><input type="checkbox" id="c-40013873" checked=""/><div class="controls bullet"><span class="by">No1</span><span>|</span><a href="#40011649">prev</a><span>|</span><a href="#40011095">next</a><span>|</span><label class="collapse" for="c-40013873">[-]</label><label class="expand" for="c-40013873">[1 more]</label></div><br/><div class="children"><div class="content">The original justification that Nvidia gave for removing Nvlink from the consumer grade lineup was that PCIe 5 would be fast enough. They then went on to release the 40xx series without PCIe 5 and P2P support. Good to see at least half of the equation being completed for them, but I canât imagine theyâll allow this in the next gen firmware.</div><br/></div></div><div id="40011095" class="c"><input type="checkbox" id="c-40011095" checked=""/><div class="controls bullet"><span class="by">HPsquared</span><span>|</span><a href="#40013873">prev</a><span>|</span><a href="#40011104">next</a><span>|</span><label class="collapse" for="c-40011095">[-]</label><label class="expand" for="c-40011095">[19 more]</label></div><br/><div class="children"><div class="content">Is this one of those features that&#x27;s disabled on consumer cards for market segmentation?</div><br/><div id="40013182" class="c"><input type="checkbox" id="c-40013182" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#40011095">parent</a><span>|</span><a href="#40014215">next</a><span>|</span><label class="collapse" for="c-40013182">[-]</label><label class="expand" for="c-40013182">[13 more]</label></div><br/><div class="children"><div class="content">Sort of.<p>An imperfect analogy: a small neighborhood of ~15 houses is under construction. Normally it might have a 200kva transformer sitting at the corner, which provides appropriate power from the grid.<p>But there is a transformer shortage, so the contractor installs a commercial grade 1250kva transformer. It can power many more houses than required, so it&#x27;s operating way under capacity.<p>One day, a resident decides he wants to start a massive grow farm, and figures out how to activate that extra transformer capacity just for his house. That &quot;activation&quot; is what geohot found</div><br/><div id="40013725" class="c"><input type="checkbox" id="c-40013725" checked=""/><div class="controls bullet"><span class="by">bogwog</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40013182">parent</a><span>|</span><a href="#40013818">next</a><span>|</span><label class="collapse" for="c-40013725">[-]</label><label class="expand" for="c-40013725">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a poor analogy. The feature is built in to the cards that consumers bought, but Nvidia is disabling it via software. That&#x27;s why a hacked driver can enable it again. The resident in your analogy is just freeloading off the contractor&#x27;s transformer.<p>Nvidia does this so that customers that need that feature are forced to buy more expensive systems instead of building a solution with the cheaper &quot;consumer-grade&quot; cards targeted at gamers and enthusiasts.</div><br/><div id="40017032" class="c"><input type="checkbox" id="c-40017032" checked=""/><div class="controls bullet"><span class="by">bpye</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40013725">parent</a><span>|</span><a href="#40013818">next</a><span>|</span><label class="collapse" for="c-40017032">[-]</label><label class="expand" for="c-40017032">[2 more]</label></div><br/><div class="children"><div class="content">This isnât even the first time a hacked driver has been used to unlock some HW feature - <a href="https:&#x2F;&#x2F;github.com&#x2F;DualCoder&#x2F;vgpu_unlock">https:&#x2F;&#x2F;github.com&#x2F;DualCoder&#x2F;vgpu_unlock</a></div><br/><div id="40018448" class="c"><input type="checkbox" id="c-40018448" checked=""/><div class="controls bullet"><span class="by">captcanuk</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40017032">parent</a><span>|</span><a href="#40013818">next</a><span>|</span><label class="collapse" for="c-40018448">[-]</label><label class="expand" for="c-40018448">[1 more]</label></div><br/><div class="children"><div class="content">There was also this <a href="https:&#x2F;&#x2F;hackaday.com&#x2F;2013&#x2F;03&#x2F;18&#x2F;hack-removes-firmware-crippling-from-nvidia-graphics-card&#x2F;" rel="nofollow">https:&#x2F;&#x2F;hackaday.com&#x2F;2013&#x2F;03&#x2F;18&#x2F;hack-removes-firmware-crippl...</a> using resistors and a different one before that used a graphene lead pencil to enable functionality.</div><br/></div></div></div></div></div></div><div id="40013818" class="c"><input type="checkbox" id="c-40013818" checked=""/><div class="controls bullet"><span class="by">segfaultbuserr</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40013182">parent</a><span>|</span><a href="#40013725">prev</a><span>|</span><a href="#40017201">next</a><span>|</span><label class="collapse" for="c-40013818">[-]</label><label class="expand" for="c-40013818">[1 more]</label></div><br/><div class="children"><div class="content">Except that in the computer hardware world, the 1250 kVA transformer was used not because of shortage, but because of the fact that making a 1250 kVA transformer on the existing production line and selling it as 200 kVA, is cheaper than creating a new production line separately for making 200 kVA transformers.</div><br/></div></div><div id="40017201" class="c"><input type="checkbox" id="c-40017201" checked=""/><div class="controls bullet"><span class="by">hatthew</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40013182">parent</a><span>|</span><a href="#40013818">prev</a><span>|</span><a href="#40017656">next</a><span>|</span><label class="collapse" for="c-40017201">[-]</label><label class="expand" for="c-40017201">[2 more]</label></div><br/><div class="children"><div class="content">And then because this residential neighborhood now has commercial grade power, the other lots that were going to have residential houses built on them instead get combined into a factory, and the people who want to buy new houses in town have to pay more since residential supply was cut in half.</div><br/><div id="40017702" class="c"><input type="checkbox" id="c-40017702" checked=""/><div class="controls bullet"><span class="by">HPsquared</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40017201">parent</a><span>|</span><a href="#40017656">next</a><span>|</span><label class="collapse" for="c-40017702">[-]</label><label class="expand" for="c-40017702">[1 more]</label></div><br/><div class="children"><div class="content">Excellent analogy of the other side of this issue.</div><br/></div></div></div></div><div id="40017656" class="c"><input type="checkbox" id="c-40017656" checked=""/><div class="controls bullet"><span class="by">cesarb</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40013182">parent</a><span>|</span><a href="#40017201">prev</a><span>|</span><a href="#40014844">next</a><span>|</span><label class="collapse" for="c-40017656">[-]</label><label class="expand" for="c-40017656">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a bad analogy, because in your example, the consumer is using more of a shared resource (the available transformer, wiring, and generation capacity). In the case of the driver for a local GPU card, there&#x27;s no sharing.<p>A better example would be one in which the consumer has a dedicated transformer. For instance, a small commercial building which directly receives 3-phase 13.8 kV power; these are very common around here, and these buildings have their own individual transformers to lower the voltage to 3-phase 127V&#x2F;220V.</div><br/></div></div><div id="40014844" class="c"><input type="checkbox" id="c-40014844" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40013182">parent</a><span>|</span><a href="#40017656">prev</a><span>|</span><a href="#40014215">next</a><span>|</span><label class="collapse" for="c-40014844">[-]</label><label class="expand" for="c-40014844">[5 more]</label></div><br/><div class="children"><div class="content">Where is the hack in this analogy</div><br/><div id="40015431" class="c"><input type="checkbox" id="c-40015431" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40014844">parent</a><span>|</span><a href="#40014215">next</a><span>|</span><label class="collapse" for="c-40015431">[-]</label><label class="expand" for="c-40015431">[4 more]</label></div><br/><div class="children"><div class="content">Taking off the users panel on the side of their house and flipping it to &#x27;lots of power&#x27; when that option had previously been covered up by the panel interface.</div><br/><div id="40017802" class="c"><input type="checkbox" id="c-40017802" checked=""/><div class="controls bullet"><span class="by">cesarb</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40015431">parent</a><span>|</span><a href="#40014215">next</a><span>|</span><label class="collapse" for="c-40017802">[-]</label><label class="expand" for="c-40017802">[3 more]</label></div><br/><div class="children"><div class="content">Except that this &quot;lots of power&quot; option does not exist. What limits the amount of power used is the circuit breakers and fuses on the panel, which protect the wiring against overheating by tripping when too much power is being used (or when there&#x27;s a short circuit). The resident in this analogy would need to ensure that not only the transformer, but also the wiring leading to the transformer, can handle the higher current, and replace the circuit breaker or fuses.<p>And then everyone on that neighborhood would still lose power, because there&#x27;s also a set of fuses <i>upstream</i> of the transformer, and they would be sized for the correct current limit even when the transformer is oversized. These fuses also protect the wiring upstream of the transformer, and their sizing and timings is coordinated with fuses or breakers even further upstream so that any fault is cleared by the protective device closest to the fault.</div><br/><div id="40018766" class="c"><input type="checkbox" id="c-40018766" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40017802">parent</a><span>|</span><a href="#40014215">next</a><span>|</span><label class="collapse" for="c-40018766">[-]</label><label class="expand" for="c-40018766">[2 more]</label></div><br/><div class="children"><div class="content">There are analogies, and then there&#x27;s this.</div><br/><div id="40019963" class="c"><input type="checkbox" id="c-40019963" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40018766">parent</a><span>|</span><a href="#40014215">next</a><span>|</span><label class="collapse" for="c-40019963">[-]</label><label class="expand" for="c-40019963">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re pointing out how the analogy doesn&#x27;t work, so it&#x27;s fine.<p>Nobody&#x27;s taking more than their share of any resources when they enable this feature.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40014215" class="c"><input type="checkbox" id="c-40014215" checked=""/><div class="controls bullet"><span class="by">rustcleaner</span><span>|</span><a href="#40011095">parent</a><span>|</span><a href="#40013182">prev</a><span>|</span><a href="#40012281">next</a><span>|</span><label class="collapse" for="c-40014215">[-]</label><label class="expand" for="c-40014215">[4 more]</label></div><br/><div class="children"><div class="content">I am sure many will disagree-vote me, but I want to see this practice in consumer devices either banned or very heavily taxed.</div><br/><div id="40018643" class="c"><input type="checkbox" id="c-40018643" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40014215">parent</a><span>|</span><a href="#40016231">next</a><span>|</span><label class="collapse" for="c-40018643">[-]</label><label class="expand" for="c-40018643">[1 more]</label></div><br/><div class="children"><div class="content">Of course power users want an end to price discrimination because it benefits them... at a cost of more expensive products for the masses.</div><br/></div></div><div id="40016231" class="c"><input type="checkbox" id="c-40016231" checked=""/><div class="controls bullet"><span class="by">xandrius</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40014215">parent</a><span>|</span><a href="#40018643">prev</a><span>|</span><a href="#40016467">next</a><span>|</span><label class="collapse" for="c-40016231">[-]</label><label class="expand" for="c-40016231">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right. Especially because you didn&#x27;t present your reasons.</div><br/></div></div><div id="40016467" class="c"><input type="checkbox" id="c-40016467" checked=""/><div class="controls bullet"><span class="by">yogorenapan</span><span>|</span><a href="#40011095">root</a><span>|</span><a href="#40014215">parent</a><span>|</span><a href="#40016231">prev</a><span>|</span><a href="#40012281">next</a><span>|</span><label class="collapse" for="c-40016467">[-]</label><label class="expand" for="c-40016467">[1 more]</label></div><br/><div class="children"><div class="content">Curious as to your reasoning,</div><br/></div></div></div></div></div></div><div id="40011104" class="c"><input type="checkbox" id="c-40011104" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#40011095">prev</a><span>|</span><a href="#40012250">next</a><span>|</span><label class="collapse" for="c-40011104">[-]</label><label class="expand" for="c-40011104">[15 more]</label></div><br/><div class="children"><div class="content">Skimming the readme this is p2p over PCIe and not NVLink in case anyone was wondering.</div><br/><div id="40011151" class="c"><input type="checkbox" id="c-40011151" checked=""/><div class="controls bullet"><span class="by">klohto</span><span>|</span><a href="#40011104">parent</a><span>|</span><a href="#40011303">next</a><span>|</span><label class="collapse" for="c-40011151">[-]</label><label class="expand" for="c-40011151">[1 more]</label></div><br/><div class="children"><div class="content">afaik 4090 doesnât support 5.0 so you are limited to 4.0 speeds. Still an improvement.</div><br/></div></div><div id="40011303" class="c"><input type="checkbox" id="c-40011303" checked=""/><div class="controls bullet"><span class="by">formerly_proven</span><span>|</span><a href="#40011104">parent</a><span>|</span><a href="#40011151">prev</a><span>|</span><a href="#40012250">next</a><span>|</span><label class="collapse" for="c-40011303">[-]</label><label class="expand" for="c-40011303">[13 more]</label></div><br/><div class="children"><div class="content">RTX 40 doesnât have NVLink on the PCBs, though the silicon has to have it, since some sibling cards support it. Iâd expect it to be fused off.</div><br/><div id="40012404" class="c"><input type="checkbox" id="c-40012404" checked=""/><div class="controls bullet"><span class="by">steeve</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40011303">parent</a><span>|</span><a href="#40012101">next</a><span>|</span><label class="collapse" for="c-40012404">[-]</label><label class="expand" for="c-40012404">[2 more]</label></div><br/><div class="children"><div class="content">Some do: <a href="https:&#x2F;&#x2F;wccftech.com&#x2F;gigabyte-geforce-rtx-4090-pcb-shows-left-out-nvidia-nvlink-traces&#x2F;" rel="nofollow">https:&#x2F;&#x2F;wccftech.com&#x2F;gigabyte-geforce-rtx-4090-pcb-shows-lef...</a></div><br/><div id="40012689" class="c"><input type="checkbox" id="c-40012689" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40012404">parent</a><span>|</span><a href="#40012101">next</a><span>|</span><label class="collapse" for="c-40012689">[-]</label><label class="expand" for="c-40012689">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m pretty sure that&#x27;s just a remnant of a 3090 PCB design that was adapted into a 4090 PCB design by the vendor. None of the cards based on the AD102 chip have functional NVLink, not even the expensive A6000 Ada workstation card or the datacenter L40 accelerator, so there&#x27;s no reason to think NVLink is present on the silicon anymore below the flagship GA100&#x2F;GH100 chips.</div><br/></div></div></div></div><div id="40012101" class="c"><input type="checkbox" id="c-40012101" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40011303">parent</a><span>|</span><a href="#40012404">prev</a><span>|</span><a href="#40011357">next</a><span>|</span><label class="collapse" for="c-40012101">[-]</label><label class="expand" for="c-40012101">[1 more]</label></div><br/><div class="children"><div class="content">A cursory google search suggests that it&#x27;s been removed at the silicon level.</div><br/></div></div><div id="40011496" class="c"><input type="checkbox" id="c-40011496" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40011303">parent</a><span>|</span><a href="#40011357">prev</a><span>|</span><a href="#40012250">next</a><span>|</span><label class="collapse" for="c-40011496">[-]</label><label class="expand" for="c-40011496">[8 more]</label></div><br/><div class="children"><div class="content">How to unfuse it?</div><br/><div id="40011789" class="c"><input type="checkbox" id="c-40011789" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40011496">parent</a><span>|</span><a href="#40012668">next</a><span>|</span><label class="collapse" for="c-40011789">[-]</label><label class="expand" for="c-40011789">[6 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know about this particular scenario, but typically fuses are small wires or resistors that are overloaded so they irreversibly break the connection. Hence the name.<p>Either done during manufacture or as a one-time programming[1][2].<p>Though sometimes reprogrammable configuration bits are sometimes also called fuse bits. The Atmega328P of Arduino fame uses flash[3] for its &quot;fuses&quot;.<p>[1]: <a href="https:&#x2F;&#x2F;www.nxp.com&#x2F;docs&#x2F;en&#x2F;application-note&#x2F;AN4536.pdf" rel="nofollow">https:&#x2F;&#x2F;www.nxp.com&#x2F;docs&#x2F;en&#x2F;application-note&#x2F;AN4536.pdf</a><p>[2]  <a href="https:&#x2F;&#x2F;www.intel.com&#x2F;programmable&#x2F;technical-pdfs&#x2F;654254.pdf" rel="nofollow">https:&#x2F;&#x2F;www.intel.com&#x2F;programmable&#x2F;technical-pdfs&#x2F;654254.pdf</a><p>[3]: <a href="https:&#x2F;&#x2F;ww1.microchip.com&#x2F;downloads&#x2F;en&#x2F;DeviceDoc&#x2F;Atmel-7810-Automotive-Microcontrollers-ATmega328P_Datasheet.pdf" rel="nofollow">https:&#x2F;&#x2F;ww1.microchip.com&#x2F;downloads&#x2F;en&#x2F;DeviceDoc&#x2F;Atmel-7810-...</a></div><br/><div id="40012257" class="c"><input type="checkbox" id="c-40012257" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40011789">parent</a><span>|</span><a href="#40012668">next</a><span>|</span><label class="collapse" for="c-40012257">[-]</label><label class="expand" for="c-40012257">[5 more]</label></div><br/><div class="children"><div class="content">Wires, flash, and resistors can be replaced</div><br/><div id="40013650" class="c"><input type="checkbox" id="c-40013650" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40012257">parent</a><span>|</span><a href="#40012337">next</a><span>|</span><label class="collapse" for="c-40013650">[-]</label><label class="expand" for="c-40013650">[2 more]</label></div><br/><div class="children"><div class="content">These are part of the chip, thus microscopic and very inaccessible.<p>There are some good images here[1] of various such fuses, both pristine and blown. Here&#x27;s[2] a more detailed writeup examining one type.<p>It&#x27;s not something you fix with a soldering iron.<p>[1]: <a href="https:&#x2F;&#x2F;semiengineering.com&#x2F;the-benefits-of-antifuse-otp&#x2F;" rel="nofollow">https:&#x2F;&#x2F;semiengineering.com&#x2F;the-benefits-of-antifuse-otp&#x2F;</a><p>[2]: <a href="https:&#x2F;&#x2F;www.eetimes.com&#x2F;a-look-at-metal-efuses&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.eetimes.com&#x2F;a-look-at-metal-efuses&#x2F;</a></div><br/><div id="40013995" class="c"><input type="checkbox" id="c-40013995" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40013650">parent</a><span>|</span><a href="#40012337">next</a><span>|</span><label class="collapse" for="c-40013995">[-]</label><label class="expand" for="c-40013995">[1 more]</label></div><br/><div class="children"><div class="content">I miss the days when you could do things like connecting the L5 bridges on the surface of the AMD Athlon XP Palomino [0] CPU packaging with a silver trace pen to transform them into fancier SMP multi-socket capable Athlon MPs, e.g. Barton [1].<p><a href="https:&#x2F;&#x2F;arstechnica.com&#x2F;civis&#x2F;threads&#x2F;how-did-you-unlock-your-palimino.709631&#x2F;" rel="nofollow">https:&#x2F;&#x2F;arstechnica.com&#x2F;civis&#x2F;threads&#x2F;how-did-you-unlock-you...</a><p>Some folks even got this working with only a pencil, haha.<p>Nowadays, silicon designers have found highly effective ways to close off these hacking avenues, with techniques, such as the microscopic, nearly invisible, and as parent post mentions, totally inaccessible e-fuses.<p>[0] <a href="https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;7&#x2F;7c&#x2F;KL_AMD_Athlon_XP_Palomino.jpg" rel="nofollow">https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;7&#x2F;7c&#x2F;KL_AMD_A...</a><p>[1] <a href="https:&#x2F;&#x2F;en.wikichip.org&#x2F;w&#x2F;images&#x2F;a&#x2F;af&#x2F;Atlhon_MP_%28.13_micron%3B_overview%29.png" rel="nofollow">https:&#x2F;&#x2F;en.wikichip.org&#x2F;w&#x2F;images&#x2F;a&#x2F;af&#x2F;Atlhon_MP_%28.13_micro...</a></div><br/></div></div></div></div><div id="40012337" class="c"><input type="checkbox" id="c-40012337" checked=""/><div class="controls bullet"><span class="by">mschuster91</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40012257">parent</a><span>|</span><a href="#40013650">prev</a><span>|</span><a href="#40012668">next</a><span>|</span><label class="collapse" for="c-40012337">[-]</label><label class="expand" for="c-40012337">[2 more]</label></div><br/><div class="children"><div class="content">Not at the scale we&#x27;re talking about here. These structures are <i>very</i> thin, far thinner than bond wires which is about the largest structure size you can handle without a very, very specialized lab. And you&#x27;d need to unsolder the chip, de-cap it, hope the fuse wire you&#x27;re trying to override is at the top layer, and that you can re-cap the chip afterwards and successfully solder it back on again.<p>This may be workable for a nation state or a billion dollar megacorp, but not for your average hobbyist hacker.</div><br/><div id="40012773" class="c"><input type="checkbox" id="c-40012773" checked=""/><div class="controls bullet"><span class="by">z33k</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40012337">parent</a><span>|</span><a href="#40012668">next</a><span>|</span><label class="collapse" for="c-40012773">[-]</label><label class="expand" for="c-40012773">[1 more]</label></div><br/><div class="children"><div class="content">Youâre absolutely right. In fact, some billion dollar megacorps use fuses as a part of hardware DRM for this reason.</div><br/></div></div></div></div></div></div></div></div><div id="40012668" class="c"><input type="checkbox" id="c-40012668" checked=""/><div class="controls bullet"><span class="by">mepian</span><span>|</span><a href="#40011104">root</a><span>|</span><a href="#40011496">parent</a><span>|</span><a href="#40011789">prev</a><span>|</span><a href="#40012250">next</a><span>|</span><label class="collapse" for="c-40012668">[-]</label><label class="expand" for="c-40012668">[1 more]</label></div><br/><div class="children"><div class="content">Use a Focused Ion Beam instrument.</div><br/></div></div></div></div></div></div></div></div><div id="40012250" class="c"><input type="checkbox" id="c-40012250" checked=""/><div class="controls bullet"><span class="by">ivanjermakov</span><span>|</span><a href="#40011104">prev</a><span>|</span><a href="#40011516">next</a><span>|</span><label class="collapse" for="c-40012250">[-]</label><label class="expand" for="c-40012250">[10 more]</label></div><br/><div class="children"><div class="content">I was always fascinated by George Hotz&#x27;s hacking abilities. Inspired me a lot for my personal projects.</div><br/><div id="40013397" class="c"><input type="checkbox" id="c-40013397" checked=""/><div class="controls bullet"><span class="by">jgpc</span><span>|</span><a href="#40012250">parent</a><span>|</span><a href="#40012299">next</a><span>|</span><label class="collapse" for="c-40013397">[-]</label><label class="expand" for="c-40013397">[4 more]</label></div><br/><div class="children"><div class="content">I agree. It is fascinating. When you observe his development process (btw, it is worth noting his  generosity in sharing it like he does) he gets frequently stuck on random shallow problems which a perhaps more knowledgable engineer would find less difficult. It is frequent to see him writing really bad code, or even wrong code. The whole twitter chapter is a good example.
Yet, himself, alone just iterating resiliently, just as frequently creates remarkable improvements. A good example to learn from. Thank you geohot.</div><br/><div id="40014684" class="c"><input type="checkbox" id="c-40014684" checked=""/><div class="controls bullet"><span class="by">zoogeny</span><span>|</span><a href="#40012250">root</a><span>|</span><a href="#40013397">parent</a><span>|</span><a href="#40020347">next</a><span>|</span><label class="collapse" for="c-40014684">[-]</label><label class="expand" for="c-40014684">[2 more]</label></div><br/><div class="children"><div class="content">This matches my own take. I&#x27;ve tuned into a few of his streams and watched VODs on YouTube. I am consistently underwhelmed by his actual engineering abilities. He is that particular kind of engineer that constantly shits on other peoples code or on the general state of programming yet his actual code is often horrendous. He will literally call someone out for some code in Tinygrad that he has trouble with and then he will go on a tangent to attempt to rewrite it. He will use the most blatant and terrible hacks only to find himself out of his depth and reverting back to the original version.<p>But his streams last 4 hours or more. And he just keeps grinding and grinding and grinding. What the man lacks in raw intellectual power he makes up for (and more) in persistence and resilience. As long as he is making even the tiniest progress he just doesn&#x27;t give up until he forces the computer to do whatever it is he wants it to do. He also has no boundaries on where his investigations take him. Driver code, OS code, platform code, framework code, etc.<p>I definitely couldn&#x27;t work with him (or work for him) since I cannot stand people who degrade the work of others while themselves turning in sub-par work as if their own shit didn&#x27;t stink. But I begrudgingly admire his tenacity, his single minded focus, and the results that his belligerent approach help him to obtain.</div><br/><div id="40020614" class="c"><input type="checkbox" id="c-40020614" checked=""/><div class="controls bullet"><span class="by">ctrw</span><span>|</span><a href="#40012250">root</a><span>|</span><a href="#40014684">parent</a><span>|</span><a href="#40020347">next</a><span>|</span><label class="collapse" for="c-40020614">[-]</label><label class="expand" for="c-40020614">[1 more]</label></div><br/><div class="children"><div class="content">There are developers who have breadth and developers who have depth. He is very much on the breadth end of the spectrum. It isn&#x27;t lack of intelligence but lack of deep knowledge of esoteric fields you will use once a decade.<p>That said I find it a bit astonishing how little Ai he uses on his streams. I convert all the documentation I need into a rag system that I query stupid questions against.</div><br/></div></div></div></div><div id="40020347" class="c"><input type="checkbox" id="c-40020347" checked=""/><div class="controls bullet"><span class="by">gorkish</span><span>|</span><a href="#40012250">root</a><span>|</span><a href="#40013397">parent</a><span>|</span><a href="#40014684">prev</a><span>|</span><a href="#40012299">next</a><span>|</span><label class="collapse" for="c-40020347">[-]</label><label class="expand" for="c-40020347">[1 more]</label></div><br/><div class="children"><div class="content">If a stopped clock is right twice a day, relentlessly winding a clock forward will make it right quite frequently. That is geohot.</div><br/></div></div></div></div><div id="40012299" class="c"><input type="checkbox" id="c-40012299" checked=""/><div class="controls bullet"><span class="by">vrnvu</span><span>|</span><a href="#40012250">parent</a><span>|</span><a href="#40013397">prev</a><span>|</span><a href="#40012381">next</a><span>|</span><label class="collapse" for="c-40012299">[-]</label><label class="expand" for="c-40012299">[1 more]</label></div><br/><div class="children"><div class="content">I agree, I feel so inspired with his streams. Focus and hard work, the key to good results. Add a clear vision and strategy, and you can also accomplish âsuccessâ.<p>Congratulations to him and all the tinygrad&#x2F;comma contributors.</div><br/></div></div><div id="40012381" class="c"><input type="checkbox" id="c-40012381" checked=""/><div class="controls bullet"><span class="by">sambull</span><span>|</span><a href="#40012250">parent</a><span>|</span><a href="#40012299">prev</a><span>|</span><a href="#40013039">next</a><span>|</span><label class="collapse" for="c-40012381">[-]</label><label class="expand" for="c-40012381">[3 more]</label></div><br/><div class="children"><div class="content">He&#x27;s got that focus like a military pilot on a long flight.</div><br/><div id="40012804" class="c"><input type="checkbox" id="c-40012804" checked=""/><div class="controls bullet"><span class="by">postalrat</span><span>|</span><a href="#40012250">root</a><span>|</span><a href="#40012381">parent</a><span>|</span><a href="#40013039">next</a><span>|</span><label class="collapse" for="c-40012804">[-]</label><label class="expand" for="c-40012804">[2 more]</label></div><br/><div class="children"><div class="content">Any time I open guys steam half of it is some sort of politics</div><br/><div id="40014039" class="c"><input type="checkbox" id="c-40014039" checked=""/><div class="controls bullet"><span class="by">CYR1X</span><span>|</span><a href="#40012250">root</a><span>|</span><a href="#40012804">parent</a><span>|</span><a href="#40013039">next</a><span>|</span><label class="collapse" for="c-40014039">[-]</label><label class="expand" for="c-40014039">[1 more]</label></div><br/><div class="children"><div class="content">You can blame chat for that lol</div><br/></div></div></div></div></div></div><div id="40013039" class="c"><input type="checkbox" id="c-40013039" checked=""/><div class="controls bullet"><span class="by">Jerrrry</span><span>|</span><a href="#40012250">parent</a><span>|</span><a href="#40012381">prev</a><span>|</span><a href="#40011516">next</a><span>|</span><label class="collapse" for="c-40013039">[-]</label><label class="expand" for="c-40013039">[1 more]</label></div><br/><div class="children"><div class="content">His Xbox360 laptop was the crux of teenage-motivation, for me.</div><br/></div></div></div></div><div id="40011516" class="c"><input type="checkbox" id="c-40011516" checked=""/><div class="controls bullet"><span class="by">rfoo</span><span>|</span><a href="#40012250">prev</a><span>|</span><a href="#40011091">next</a><span>|</span><label class="collapse" for="c-40011516">[-]</label><label class="expand" for="c-40011516">[26 more]</label></div><br/><div class="children"><div class="content">Glad to see that geohot is back being geohot, first by dropping a local DoS for AMD cards, then this. Much more interesting :p</div><br/><div id="40013100" class="c"><input type="checkbox" id="c-40013100" checked=""/><div class="controls bullet"><span class="by">jaimehrubiks</span><span>|</span><a href="#40011516">parent</a><span>|</span><a href="#40012557">next</a><span>|</span><label class="collapse" for="c-40013100">[-]</label><label class="expand" for="c-40013100">[24 more]</label></div><br/><div class="children"><div class="content">Is this the same guy that hacked the PS3?</div><br/><div id="40014673" class="c"><input type="checkbox" id="c-40014673" checked=""/><div class="controls bullet"><span class="by">dji4321234</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40013100">parent</a><span>|</span><a href="#40013715">next</a><span>|</span><label class="collapse" for="c-40014673">[-]</label><label class="expand" for="c-40014673">[12 more]</label></div><br/><div class="children"><div class="content">He has a very checkered history with &quot;hacking&quot; things.<p>He tends to build heavily on the work of others, then use it to shamelessly self-promote, often to the massive detriment of the original authors. His PS3 work was based almost completely on a presentation given by fail0verflow at CCC. His subsequent self-promotion grandstanding world tour led to Sony suing both him and fail0verflow, an outcome they were specifically trying to avoid: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25679907">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25679907</a><p>In iPhone land, he decided to parade around a variety of leaked documentation, endangering the original sources and leading to a fragmentation in the early iPhone hacking scene, which he then again exploited to build on the work of others for his own self-promotion: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39667273">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39667273</a><p>There&#x27;s no denying that geohotz is a skilled reverse engineer, but it&#x27;s always bothersome to see him put onto a pedestal in this way.</div><br/><div id="40015158" class="c"><input type="checkbox" id="c-40015158" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40014673">parent</a><span>|</span><a href="#40014878">next</a><span>|</span><label class="collapse" for="c-40015158">[-]</label><label class="expand" for="c-40015158">[7 more]</label></div><br/><div class="children"><div class="content">There was also that CheapEth crypto scam he tried to pull off.</div><br/><div id="40017177" class="c"><input type="checkbox" id="c-40017177" checked=""/><div class="controls bullet"><span class="by">samtheprogram</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40015158">parent</a><span>|</span><a href="#40015486">next</a><span>|</span><label class="collapse" for="c-40017177">[-]</label><label class="expand" for="c-40017177">[5 more]</label></div><br/><div class="children"><div class="content">To me that was obvious satire of the crypto scene.</div><br/><div id="40018110" class="c"><input type="checkbox" id="c-40018110" checked=""/><div class="controls bullet"><span class="by">ansible</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40017177">parent</a><span>|</span><a href="#40018090">next</a><span>|</span><label class="collapse" for="c-40018110">[-]</label><label class="expand" for="c-40018110">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think people can tell what is satire or not in the crypto scene anymore. Someone issue a &quot;rug pull token&quot; and still received 8.8 ETH (approx $29K USD), while telling people it was a scam.<p><a href="https:&#x2F;&#x2F;www.web3isgoinggreat.com&#x2F;?id=rug-pull-token" rel="nofollow">https:&#x2F;&#x2F;www.web3isgoinggreat.com&#x2F;?id=rug-pull-token</a></div><br/></div></div><div id="40018090" class="c"><input type="checkbox" id="c-40018090" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40017177">parent</a><span>|</span><a href="#40018110">prev</a><span>|</span><a href="#40015486">next</a><span>|</span><label class="collapse" for="c-40018090">[-]</label><label class="expand" for="c-40018090">[3 more]</label></div><br/><div class="children"><div class="content">Ah yes, nothing like a bit of hypocrisy to make a point. It&#x27;s okay though, as long as it&#x27;s people we don&#x27;t agree with, defrauding them is fine.</div><br/><div id="40019833" class="c"><input type="checkbox" id="c-40019833" checked=""/><div class="controls bullet"><span class="by">samtheprogram</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40018090">parent</a><span>|</span><a href="#40015486">next</a><span>|</span><label class="collapse" for="c-40019833">[-]</label><label class="expand" for="c-40019833">[2 more]</label></div><br/><div class="children"><div class="content">The website literally stated it was not for speculation, they didn&#x27;t want the price to go up, and there were multiple ways to get some for free.<p>If people were reckless, greedy, and&#x2F;or lazy because of the crypto hype and got &quot;defrauded&quot; without doing any amount of due diligence -- that&#x27;s kinda the point.</div><br/><div id="40020696" class="c"><input type="checkbox" id="c-40020696" checked=""/><div class="controls bullet"><span class="by">georgehotz</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40019833">parent</a><span>|</span><a href="#40015486">next</a><span>|</span><label class="collapse" for="c-40020696">[-]</label><label class="expand" for="c-40020696">[1 more]</label></div><br/><div class="children"><div class="content">I actually lost about $5k on cheapETH running servers. Nobody was &quot;defrauded&quot;, I think these people don&#x27;t understand how forks work. It&#x27;s a precursor to the modern L2 stuff, I did this while writing the first version of Optimism&#x27;s fraud prover. <a href="https:&#x2F;&#x2F;github.com&#x2F;ethereum-optimism&#x2F;cannon">https:&#x2F;&#x2F;github.com&#x2F;ethereum-optimism&#x2F;cannon</a><p>I suspect most of the people who bring this up don&#x27;t like me for other reasons, but with this they think they have something to latch on to. Doesn&#x27;t matter that it isn&#x27;t true and there wasn&#x27;t a scam, they aren&#x27;t going to look into it since it agrees with their narrative.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40014878" class="c"><input type="checkbox" id="c-40014878" checked=""/><div class="controls bullet"><span class="by">delfinom</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40014673">parent</a><span>|</span><a href="#40015158">prev</a><span>|</span><a href="#40013715">next</a><span>|</span><label class="collapse" for="c-40014878">[-]</label><label class="expand" for="c-40014878">[4 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t forget he sucked up to melon and worked for Twitter for a week.</div><br/><div id="40017688" class="c"><input type="checkbox" id="c-40017688" checked=""/><div class="controls bullet"><span class="by">StressedDev</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40014878">parent</a><span>|</span><a href="#40015496">prev</a><span>|</span><a href="#40013715">next</a><span>|</span><label class="collapse" for="c-40017688">[-]</label><label class="expand" for="c-40017688">[2 more]</label></div><br/><div class="children"><div class="content">Who is melon?</div><br/><div id="40019547" class="c"><input type="checkbox" id="c-40019547" checked=""/><div class="controls bullet"><span class="by">aeyes</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40017688">parent</a><span>|</span><a href="#40013715">next</a><span>|</span><label class="collapse" for="c-40019547">[-]</label><label class="expand" for="c-40019547">[1 more]</label></div><br/><div class="children"><div class="content">elon musk?</div><br/></div></div></div></div></div></div></div></div><div id="40013715" class="c"><input type="checkbox" id="c-40013715" checked=""/><div class="controls bullet"><span class="by">mikepurvis</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40013100">parent</a><span>|</span><a href="#40014673">prev</a><span>|</span><a href="#40013127">next</a><span>|</span><label class="collapse" for="c-40013715">[-]</label><label class="expand" for="c-40013715">[4 more]</label></div><br/><div class="children"><div class="content">Yes, but he spent several years in self-driving cars (<a href="https:&#x2F;&#x2F;comma.ai" rel="nofollow">https:&#x2F;&#x2F;comma.ai</a>), which while interesting is also a space that a lot of players are in, so it&#x27;s not the same as seeing him back to doing stuff that&#x27;s a little more out there, especially as pertains to IP.</div><br/><div id="40013990" class="c"><input type="checkbox" id="c-40013990" checked=""/><div class="controls bullet"><span class="by">nolongerthere</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40013715">parent</a><span>|</span><a href="#40013127">next</a><span>|</span><label class="collapse" for="c-40013990">[-]</label><label class="expand" for="c-40013990">[3 more]</label></div><br/><div class="children"><div class="content">Did he abandon this effort? That would be pretty sad bec he was approaching the problem from a very different perspective.</div><br/><div id="40014050" class="c"><input type="checkbox" id="c-40014050" checked=""/><div class="controls bullet"><span class="by">Topgamer7</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40013990">parent</a><span>|</span><a href="#40014521">next</a><span>|</span><label class="collapse" for="c-40014050">[-]</label><label class="expand" for="c-40014050">[1 more]</label></div><br/><div class="children"><div class="content">He stepped down from it.
<a href="https:&#x2F;&#x2F;geohot.github.io&#x2F;&#x2F;blog&#x2F;jekyll&#x2F;update&#x2F;2022&#x2F;10&#x2F;29&#x2F;the-heroes-journey.html" rel="nofollow">https:&#x2F;&#x2F;geohot.github.io&#x2F;&#x2F;blog&#x2F;jekyll&#x2F;update&#x2F;2022&#x2F;10&#x2F;29&#x2F;the-...</a></div><br/></div></div><div id="40014521" class="c"><input type="checkbox" id="c-40014521" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40013990">parent</a><span>|</span><a href="#40014050">prev</a><span>|</span><a href="#40013127">next</a><span>|</span><label class="collapse" for="c-40014521">[-]</label><label class="expand" for="c-40014521">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s still a company, still making and selling products,  and I think he&#x27;s still pretty heavily involved in it.</div><br/></div></div></div></div></div></div><div id="40013127" class="c"><input type="checkbox" id="c-40013127" checked=""/><div class="controls bullet"><span class="by">mepian</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40013100">parent</a><span>|</span><a href="#40013715">prev</a><span>|</span><a href="#40013501">next</a><span>|</span><label class="collapse" for="c-40013127">[-]</label><label class="expand" for="c-40013127">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s him.</div><br/></div></div><div id="40013501" class="c"><input type="checkbox" id="c-40013501" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40013100">parent</a><span>|</span><a href="#40013127">prev</a><span>|</span><a href="#40013312">next</a><span>|</span><label class="collapse" for="c-40013501">[-]</label><label class="expand" for="c-40013501">[5 more]</label></div><br/><div class="children"><div class="content">And the iPhone</div><br/><div id="40013695" class="c"><input type="checkbox" id="c-40013695" checked=""/><div class="controls bullet"><span class="by">yrds96</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40013501">parent</a><span>|</span><a href="#40013312">next</a><span>|</span><label class="collapse" for="c-40013695">[-]</label><label class="expand" for="c-40013695">[4 more]</label></div><br/><div class="children"><div class="content">And android</div><br/><div id="40014286" class="c"><input type="checkbox" id="c-40014286" checked=""/><div class="controls bullet"><span class="by">zoklet-enjoyer</span><span>|</span><a href="#40011516">root</a><span>|</span><a href="#40013695">parent</a><span>|</span><a href="#40013312">next</a><span>|</span><label class="collapse" for="c-40014286">[-]</label><label class="expand" for="c-40014286">[3 more]</label></div><br/><div class="children"><div class="content">And the crypto scam cheapETH</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40011091" class="c"><input type="checkbox" id="c-40011091" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#40011516">prev</a><span>|</span><a href="#40018267">next</a><span>|</span><label class="collapse" for="c-40011091">[-]</label><label class="expand" for="c-40011091">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;ll be nice while it lasts, until they start locking this down in the firmware instead on future architectures.</div><br/><div id="40013713" class="c"><input type="checkbox" id="c-40013713" checked=""/><div class="controls bullet"><span class="by">mnau</span><span>|</span><a href="#40011091">parent</a><span>|</span><a href="#40018267">next</a><span>|</span><label class="collapse" for="c-40013713">[-]</label><label class="expand" for="c-40013713">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but that was something that was always going to happen.<p>So it&#x27;s better to have it at least for one generation instead of no generation.</div><br/></div></div></div></div><div id="40018267" class="c"><input type="checkbox" id="c-40018267" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#40011091">prev</a><span>|</span><a href="#40011078">next</a><span>|</span><label class="collapse" for="c-40018267">[-]</label><label class="expand" for="c-40018267">[1 more]</label></div><br/><div class="children"><div class="content">What are the chances that Nvidia updates the firmware to disable this and prevents downgrading with efuses? Someday cards that still have older firmware may be more valuable. I&#x27;d be cautious upgrading drivers for a while.</div><br/></div></div><div id="40011078" class="c"><input type="checkbox" id="c-40011078" checked=""/><div class="controls bullet"><span class="by">jagrsw</span><span>|</span><a href="#40018267">prev</a><span>|</span><a href="#40013144">next</a><span>|</span><label class="collapse" for="c-40011078">[-]</label><label class="expand" for="c-40011078">[9 more]</label></div><br/><div class="children"><div class="content">Was it George himself, or a person working for a bounty that was set up by tinycorp?<p>Also, a question for those knowledgeable about the PCI subsys: it looked like something NVIDIA didn&#x27;t care about, rather than something they actively wanted to prevent, no?</div><br/><div id="40013948" class="c"><input type="checkbox" id="c-40013948" checked=""/><div class="controls bullet"><span class="by">toast0</span><span>|</span><a href="#40011078">parent</a><span>|</span><a href="#40011139">next</a><span>|</span><label class="collapse" for="c-40013948">[-]</label><label class="expand" for="c-40013948">[2 more]</label></div><br/><div class="children"><div class="content">PCI devices have always been able to read and write to the shared address space (subject to IOMMU); most frequently used for DMA to system RAM, but not limited to it.<p>So, poking around to configure the device to put the whole VRAM in the address space is reasonable, subject to support for resizable BAR or just having a fixed size large enough BAR. And telling one card to read&#x2F;write from an address that happens to be mapped to a different card&#x27;s VRAM is also reasonable.<p>I&#x27;d be interested to know if PCI-e switching capacity will be a bottleneck, or if it&#x27;ll just be the point to point links and VRAM that bottlenecks. Saving a bounce through system RAM should help in either case though.</div><br/><div id="40016996" class="c"><input type="checkbox" id="c-40016996" checked=""/><div class="controls bullet"><span class="by">namibj</span><span>|</span><a href="#40011078">root</a><span>|</span><a href="#40013948">parent</a><span>|</span><a href="#40011139">next</a><span>|</span><label class="collapse" for="c-40016996">[-]</label><label class="expand" for="c-40016996">[1 more]</label></div><br/><div class="children"><div class="content">Fixed large bar exists in some older accelerator cards like e.g. iirc the MI50&#x2F;MI60 from AMD (the data center variant of the Radeon Vega VII, the first GPU with PCIe 4.0, also famous for dominating memory bandwidth until the RTX 40-series took that claim back. It had 16GB of HBM delivering 1TB&#x2F;s memory bandwidth).<p>It&#x27;s notably not compatible with some legacy boot processes and iirc also just 32bit kernels in general, so consumer cards had to wait for resizable BAR to get the benefits of large BAR (that being notably direct flat memory mapping of VRAM so CPUs and PCIe peers can directly read and write into all of VRAM, without dancing through a command interface with doorbell registers. AFAIK it allows a GPU to talk directly to NICs and NVMe drives by running the driver in GPU code (I&#x27;m not sure how&#x2F;if they let you properly interact with doorbell registers, but polled io_uring as an ABI would be no problem (I wouldn&#x27;t be surprised if some NIC firmware already allows offloading this).</div><br/></div></div></div></div><div id="40011139" class="c"><input type="checkbox" id="c-40011139" checked=""/><div class="controls bullet"><span class="by">mtlynch</span><span>|</span><a href="#40011078">parent</a><span>|</span><a href="#40013948">prev</a><span>|</span><a href="#40012035">next</a><span>|</span><label class="collapse" for="c-40011139">[-]</label><label class="expand" for="c-40011139">[2 more]</label></div><br/><div class="children"><div class="content">Commits are by geohot, so it looks like George himself.</div><br/><div id="40012096" class="c"><input type="checkbox" id="c-40012096" checked=""/><div class="controls bullet"><span class="by">throw101010</span><span>|</span><a href="#40011078">root</a><span>|</span><a href="#40011139">parent</a><span>|</span><a href="#40012035">next</a><span>|</span><label class="collapse" for="c-40012096">[-]</label><label class="expand" for="c-40012096">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen him work on tinygrad on his Twitch livestream couple times, so more than likely him indeed.</div><br/></div></div></div></div><div id="40012035" class="c"><input type="checkbox" id="c-40012035" checked=""/><div class="controls bullet"><span class="by">squarra</span><span>|</span><a href="#40011078">parent</a><span>|</span><a href="#40011139">prev</a><span>|</span><a href="#40011557">next</a><span>|</span><label class="collapse" for="c-40012035">[-]</label><label class="expand" for="c-40012035">[3 more]</label></div><br/><div class="children"><div class="content">He also documented his progress on the tinygrad discord</div><br/><div id="40016451" class="c"><input type="checkbox" id="c-40016451" checked=""/><div class="controls bullet"><span class="by">throwaway8481</span><span>|</span><a href="#40011078">root</a><span>|</span><a href="#40012035">parent</a><span>|</span><a href="#40011557">next</a><span>|</span><label class="collapse" for="c-40016451">[-]</label><label class="expand" for="c-40016451">[2 more]</label></div><br/><div class="children"><div class="content">I feel like I should say something about discord not being a suitable replacement for a forum or bugtracker.</div><br/><div id="40017229" class="c"><input type="checkbox" id="c-40017229" checked=""/><div class="controls bullet"><span class="by">guywhocodes</span><span>|</span><a href="#40011078">root</a><span>|</span><a href="#40016451">parent</a><span>|</span><a href="#40011557">next</a><span>|</span><label class="collapse" for="c-40017229">[-]</label><label class="expand" for="c-40017229">[1 more]</label></div><br/><div class="children"><div class="content">We are talking about a literal monologue while poking at a driver for a few hours, this wasn&#x27;t a huge project.</div><br/></div></div></div></div></div></div></div></div><div id="40013144" class="c"><input type="checkbox" id="c-40013144" checked=""/><div class="controls bullet"><span class="by">xipho</span><span>|</span><a href="#40011078">prev</a><span>|</span><a href="#40011174">next</a><span>|</span><label class="collapse" for="c-40013144">[-]</label><label class="expand" for="c-40013144">[1 more]</label></div><br/><div class="children"><div class="content">You can watch this happen on the weekends, typically, sometimes, for some very long sessions, sometimes. <a href="https:&#x2F;&#x2F;www.twitch.tv&#x2F;georgehotz" rel="nofollow">https:&#x2F;&#x2F;www.twitch.tv&#x2F;georgehotz</a></div><br/></div></div><div id="40011174" class="c"><input type="checkbox" id="c-40011174" checked=""/><div class="controls bullet"><span class="by">klohto</span><span>|</span><a href="#40013144">prev</a><span>|</span><a href="#40014030">next</a><span>|</span><label class="collapse" for="c-40011174">[-]</label><label class="expand" for="c-40011174">[1 more]</label></div><br/><div class="children"><div class="content">fyi should work on most 40xx[1]<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch&#x2F;issues&#x2F;119638#issuecomment-2051196015">https:&#x2F;&#x2F;github.com&#x2F;pytorch&#x2F;pytorch&#x2F;issues&#x2F;119638#issuecommen...</a></div><br/></div></div><div id="40014030" class="c"><input type="checkbox" id="c-40014030" checked=""/><div class="controls bullet"><span class="by">thangngoc89</span><span>|</span><a href="#40011174">prev</a><span>|</span><a href="#40019316">next</a><span>|</span><label class="collapse" for="c-40014030">[-]</label><label class="expand" for="c-40014030">[3 more]</label></div><br/><div class="children"><div class="content">&gt; You may need to uninstall the driver from DKMS. Your system needs large BAR support and IOMMU off.<p>Can someone point me to the correct tutorial on how to do these things?</div><br/><div id="40017586" class="c"><input type="checkbox" id="c-40017586" checked=""/><div class="controls bullet"><span class="by">jasomill</span><span>|</span><a href="#40014030">parent</a><span>|</span><a href="#40017097">next</a><span>|</span><label class="collapse" for="c-40017586">[-]</label><label class="expand" for="c-40017586">[1 more]</label></div><br/><div class="children"><div class="content">DKMS: uninstall Nvidia driver using distro package manager<p>BAR: enable resizable BAR in motherboard CMOS setup<p>IOMMU: Add &quot;amd_iommu=off&quot; or &quot;intel_iommu=off&quot; to kernel command line for AMD or Intel CPU, respectively (or just add both). You may or may not need to disable the IOMMU in CMOS setup (Intel calls its IOMMU VT-d).<p>See motherboard docs for specific option names. See distro docs for procedures to list&#x2F;uninstall packages and to add kernel command line options.</div><br/></div></div><div id="40017097" class="c"><input type="checkbox" id="c-40017097" checked=""/><div class="controls bullet"><span class="by">unaindz</span><span>|</span><a href="#40014030">parent</a><span>|</span><a href="#40017586">prev</a><span>|</span><a href="#40019316">next</a><span>|</span><label class="collapse" for="c-40017097">[-]</label><label class="expand" for="c-40017097">[1 more]</label></div><br/><div class="children"><div class="content">The first one I assume is the nvidia driver for linux installed using dkms. If it uses dkms or not is stated on the drivers name, at least on arch based distributions.<p>The latter options are settings on your motherboard bios, if your computer is modern, explore your bios and you will find them</div><br/></div></div></div></div><div id="40019316" class="c"><input type="checkbox" id="c-40019316" checked=""/><div class="controls bullet"><span class="by">waldrews</span><span>|</span><a href="#40014030">prev</a><span>|</span><a href="#40018660">next</a><span>|</span><label class="collapse" for="c-40019316">[-]</label><label class="expand" for="c-40019316">[2 more]</label></div><br/><div class="children"><div class="content">Would this approach be possible to extend downmarket, to older consumer cards?  For a lot of LLM use cases we&#x27;re constrained by memory and can tolerate lower compute speeds so long as there&#x27;s no swapping.  ELI5, what would prevent a hundred 1060-level cards from being used together?</div><br/><div id="40019801" class="c"><input type="checkbox" id="c-40019801" checked=""/><div class="controls bullet"><span class="by">Sebb767</span><span>|</span><a href="#40019316">parent</a><span>|</span><a href="#40018660">next</a><span>|</span><label class="collapse" for="c-40019801">[-]</label><label class="expand" for="c-40019801">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ELI5, what would prevent a hundred 1060-level cards from being used together?<p>In this case, you&#x27;d only have a single PCIe (v3!) lane per card, making the interconnect speed horribly slow. You&#x27;d also need to invest in thousands of dollars of hardware to get all of those cards connected and, unless power is free, you&#x27;d outspend any theoretical savings instantly.<p>In general, if you go back in card generations, you&#x27;ll quickly hit so low memory limits amd slower compute that a modern CPU-based setup is better value.</div><br/></div></div></div></div><div id="40018660" class="c"><input type="checkbox" id="c-40018660" checked=""/><div class="controls bullet"><span class="by">tanelpoder</span><span>|</span><a href="#40019316">prev</a><span>|</span><a href="#40013491">next</a><span>|</span><label class="collapse" for="c-40018660">[-]</label><label class="expand" for="c-40018660">[1 more]</label></div><br/><div class="children"><div class="content">I also love that it can be done with just a few code line changes:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;open-gpu-kernel-modules&#x2F;commit&#x2F;1f4613dacec2638569a74b5e3dbcab01832f72a7?diff=unified&amp;w=1">https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;open-gpu-kernel-modules&#x2F;commit&#x2F;1f4...</a></div><br/></div></div><div id="40013491" class="c"><input type="checkbox" id="c-40013491" checked=""/><div class="controls bullet"><span class="by">xmorse</span><span>|</span><a href="#40018660">prev</a><span>|</span><a href="#40018648">next</a><span>|</span><label class="collapse" for="c-40013491">[-]</label><label class="expand" for="c-40013491">[1 more]</label></div><br/><div class="children"><div class="content">Finally switched to Nvidia and already adding great value</div><br/></div></div><div id="40013222" class="c"><input type="checkbox" id="c-40013222" checked=""/><div class="controls bullet"><span class="by">BeefySwain</span><span>|</span><a href="#40018648">prev</a><span>|</span><a href="#40011189">next</a><span>|</span><label class="collapse" for="c-40013222">[-]</label><label class="expand" for="c-40013222">[2 more]</label></div><br/><div class="children"><div class="content">Can someone ELI5 what this may make possible that wasn&#x27;t possible before? Does this mean I can buy a handful of 4090s and use it in lieu of an h100? Just adding the memory together?</div><br/><div id="40013357" class="c"><input type="checkbox" id="c-40013357" checked=""/><div class="controls bullet"><span class="by">segfaultbuserr</span><span>|</span><a href="#40013222">parent</a><span>|</span><a href="#40011189">next</a><span>|</span><label class="collapse" for="c-40013357">[-]</label><label class="expand" for="c-40013357">[1 more]</label></div><br/><div class="children"><div class="content">No. The Nvidia A100 has a multi-lane NVLink interface with a total bandwidth of 600 GB&#x2F;s. The &quot;unlocked&quot; Nvidia RTX 4090 uses PCIe P2P at 50 GB&#x2F;s. It&#x27;s not going to replace A100 GPUs for serious production work, but it does unlock a datacenter-exclusive feature and has some small-scale applications.</div><br/></div></div></div></div><div id="40011189" class="c"><input type="checkbox" id="c-40011189" checked=""/><div class="controls bullet"><span class="by">clbrmbr</span><span>|</span><a href="#40013222">prev</a><span>|</span><a href="#40011634">next</a><span>|</span><label class="collapse" for="c-40011189">[-]</label><label class="expand" for="c-40011189">[75 more]</label></div><br/><div class="children"><div class="content">If we end up with a compute governance model of AI control [1], this sort of thing could get your door kicked in by the CEA (Compute Enforcement Agency).<p>[1] <a href="https:&#x2F;&#x2F;podcasts.apple.com&#x2F;us&#x2F;podcast&#x2F;ai-safety-fundamentals-alignment&#x2F;id1680794263?i=1000651665081" rel="nofollow">https:&#x2F;&#x2F;podcasts.apple.com&#x2F;us&#x2F;podcast&#x2F;ai-safety-fundamentals...</a></div><br/><div id="40011209" class="c"><input type="checkbox" id="c-40011209" checked=""/><div class="controls bullet"><span class="by">entropyie</span><span>|</span><a href="#40011189">parent</a><span>|</span><a href="#40016851">next</a><span>|</span><label class="collapse" for="c-40011209">[-]</label><label class="expand" for="c-40011209">[2 more]</label></div><br/><div class="children"><div class="content">You mean the Turing Police [1]<p>[1] <a href="https:&#x2F;&#x2F;williamgibson.fandom.com&#x2F;wiki&#x2F;Turing_Police" rel="nofollow">https:&#x2F;&#x2F;williamgibson.fandom.com&#x2F;wiki&#x2F;Turing_Police</a></div><br/><div id="40014924" class="c"><input type="checkbox" id="c-40014924" checked=""/><div class="controls bullet"><span class="by">zdw</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011209">parent</a><span>|</span><a href="#40016851">next</a><span>|</span><label class="collapse" for="c-40014924">[-]</label><label class="expand" for="c-40014924">[1 more]</label></div><br/><div class="children"><div class="content">Ah, and then do we get the Butlerian Jihad?<p><a href="https:&#x2F;&#x2F;dune.fandom.com&#x2F;wiki&#x2F;Butlerian_Jihad" rel="nofollow">https:&#x2F;&#x2F;dune.fandom.com&#x2F;wiki&#x2F;Butlerian_Jihad</a></div><br/></div></div></div></div><div id="40016851" class="c"><input type="checkbox" id="c-40016851" checked=""/><div class="controls bullet"><span class="by">baobun</span><span>|</span><a href="#40011189">parent</a><span>|</span><a href="#40011209">prev</a><span>|</span><a href="#40011206">next</a><span>|</span><label class="collapse" for="c-40016851">[-]</label><label class="expand" for="c-40016851">[2 more]</label></div><br/><div class="children"><div class="content">Wow, that was a ride. Really pushing the Overton window.<p>&quot;Regulating access to compute rather than data&quot; - they&#x27;re really spelling out their defection in the war on access to general computation.</div><br/><div id="40017936" class="c"><input type="checkbox" id="c-40017936" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40016851">parent</a><span>|</span><a href="#40011206">next</a><span>|</span><label class="collapse" for="c-40017936">[-]</label><label class="expand" for="c-40017936">[1 more]</label></div><br/><div class="children"><div class="content">I mean yeah they (and I) think if you have too much access to general computation you can destroy the world.<p>This isn&#x27;t a &quot;defection&quot;, because this was never something they cared about preserving at the risk of humanity. They were never in whatever alliance you&#x27;re imagining.</div><br/></div></div></div></div><div id="40011206" class="c"><input type="checkbox" id="c-40011206" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#40011189">parent</a><span>|</span><a href="#40016851">prev</a><span>|</span><a href="#40014674">next</a><span>|</span><label class="collapse" for="c-40011206">[-]</label><label class="expand" for="c-40011206">[69 more]</label></div><br/><div class="children"><div class="content">Looks like we&#x27;re only a few years away from a bona fide cyberpunk dystopia, in which only governments and megacorps are allowed to use AI, and hackers working on their own hardware face regular raids from the authorities.</div><br/><div id="40011545" class="c"><input type="checkbox" id="c-40011545" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011206">parent</a><span>|</span><a href="#40011995">next</a><span>|</span><label class="collapse" for="c-40011545">[-]</label><label class="expand" for="c-40011545">[4 more]</label></div><br/><div class="children"><div class="content">On one hand I&#x27;m strongly against letting that happen, on the other there&#x27;s something romantic about the idea of smuggling the latest Chinese LLM on a flight from Neo-Tokyo to Newark in order to pay for my latest round of nervous system upgrades.</div><br/><div id="40011822" class="c"><input type="checkbox" id="c-40011822" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011545">parent</a><span>|</span><a href="#40012467">next</a><span>|</span><label class="collapse" for="c-40011822">[-]</label><label class="expand" for="c-40011822">[1 more]</label></div><br/><div class="children"><div class="content">&gt; On one hand I&#x27;m strongly against letting that happen, on the other there&#x27;s something romantic about the idea of smuggling the latest Chinese LLM on a flight from Neo-Tokyo to Newark in order to pay for my latest round of nervous system upgrades.<p>At least call it the &#x27;Free City of Newark&#x27;</div><br/></div></div><div id="40012467" class="c"><input type="checkbox" id="c-40012467" checked=""/><div class="controls bullet"><span class="by">chasd00</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011545">parent</a><span>|</span><a href="#40011822">prev</a><span>|</span><a href="#40011899">next</a><span>|</span><label class="collapse" for="c-40012467">[-]</label><label class="expand" for="c-40012467">[1 more]</label></div><br/><div class="children"><div class="content">Iirc the opening scene in Ghost in the Shell was a rogue AI seeking asylum in a different country. You could make a similar story about a AI not wanting to be lobotomized to conform to the current politics and escaping to a more friendly place.</div><br/></div></div><div id="40011899" class="c"><input type="checkbox" id="c-40011899" checked=""/><div class="controls bullet"><span class="by">dreamcompiler</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011545">parent</a><span>|</span><a href="#40012467">prev</a><span>|</span><a href="#40011995">next</a><span>|</span><label class="collapse" for="c-40011899">[-]</label><label class="expand" for="c-40011899">[1 more]</label></div><br/><div class="children"><div class="content">&quot;The sky above the port was the color of Stable Diffusion when asked to draw a dead channel.&quot;</div><br/></div></div></div></div><div id="40011995" class="c"><input type="checkbox" id="c-40011995" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011206">parent</a><span>|</span><a href="#40011545">prev</a><span>|</span><a href="#40011253">next</a><span>|</span><label class="collapse" for="c-40011995">[-]</label><label class="expand" for="c-40011995">[22 more]</label></div><br/><div class="children"><div class="content">I find it baffling that ideas like &quot;govern compute&quot; are even taken seriously. What the hell has happened to the ideals of freedom?! Does the government own us or something?</div><br/><div id="40012517" class="c"><input type="checkbox" id="c-40012517" checked=""/><div class="controls bullet"><span class="by">segfaultbuserr</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011995">parent</a><span>|</span><a href="#40013520">next</a><span>|</span><label class="collapse" for="c-40012517">[-]</label><label class="expand" for="c-40012517">[5 more]</label></div><br/><div class="children"><div class="content">&gt; <i>I find it baffling that ideas like &quot;govern compute&quot; are even taken seriously.</i><p>It&#x27;s not entirely unreasonable if one truly believes that AI technologies are as dangerous as nuclear weapons. It&#x27;s a big &quot;if&quot;, but it appears that many people across the political spectrum are starting to truly believe it. If one accepts this assumption, then the question simply becomes &quot;how&quot; instead of &quot;why&quot;. Depending on one&#x27;s political position, proposed solutions include academic ones such as finding the ultimate mathematical model that guarantees &quot;AI safety&quot;, to Cold War style ones with a level of control similar to Nuclear Non-Proliferation. Even a neo-Luddist solution such as destroying all advanced computing hardware becomes &quot;not unthinkable&quot; (a tech blogger <i>gwern</i>, a well-known personality in AI circles who&#x27;s generally pro-tech and pro-AI, actually wrote an article years ago on its feasibility through terrorism because he thought it was an interesting hypothetical question).</div><br/><div id="40014775" class="c"><input type="checkbox" id="c-40014775" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012517">parent</a><span>|</span><a href="#40013520">next</a><span>|</span><label class="collapse" for="c-40014775">[-]</label><label class="expand" for="c-40014775">[4 more]</label></div><br/><div class="children"><div class="content">AI is very different from nuclear weapons because a state can&#x27;t really use nuclear weapons to oppress its own people, but it absolutely can with AI, so for the average human &quot;only the government controls AI&quot; is much more dangerous than &quot;only the government controls nukes&quot;.</div><br/><div id="40014969" class="c"><input type="checkbox" id="c-40014969" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014775">parent</a><span>|</span><a href="#40015120">next</a><span>|</span><label class="collapse" for="c-40014969">[-]</label><label class="expand" for="c-40014969">[1 more]</label></div><br/><div class="children"><div class="content">But that makes such rules more likely, not less.</div><br/></div></div><div id="40015120" class="c"><input type="checkbox" id="c-40015120" checked=""/><div class="controls bullet"><span class="by">segfaultbuserr</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014775">parent</a><span>|</span><a href="#40014969">prev</a><span>|</span><a href="#40013520">next</a><span>|</span><label class="collapse" for="c-40015120">[-]</label><label class="expand" for="c-40015120">[2 more]</label></div><br/><div class="children"><div class="content">Which is why politicians are going to enforce systematic export regulations to defend the &quot;free world&quot; by stopping âterrorists&quot;, and also to stop &quot;rogue states&quot; from using AI to oppress their citizens. &#x2F;s</div><br/><div id="40015191" class="c"><input type="checkbox" id="c-40015191" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40015120">parent</a><span>|</span><a href="#40013520">next</a><span>|</span><label class="collapse" for="c-40015191">[-]</label><label class="expand" for="c-40015191">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think there&#x27;s any need to be sarcastic about it. That&#x27;s a very real possibility at this point. For example, the US going insane about how dangerous it is for China to have access to powerful GPU hardware. Why do they hate China so much anyway? Just because Trump was buddy buddy with them for a while?</div><br/></div></div></div></div></div></div></div></div><div id="40013520" class="c"><input type="checkbox" id="c-40013520" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011995">parent</a><span>|</span><a href="#40012517">prev</a><span>|</span><a href="#40019695">next</a><span>|</span><label class="collapse" for="c-40013520">[-]</label><label class="expand" for="c-40013520">[7 more]</label></div><br/><div class="children"><div class="content"><i>If</i> AI is actually capable of fulfilling all the capabilities suggested by people who believe in the singularity, it has far more capacity for harm than nuclear weapons.<p>I <i>think</i> most people who are strongly pro-AI&#x2F;pro-acceleration - or, at any rate, not anti-AI - believe that either (A) there is no control problem (B) it will be solved (C) AI won&#x27;t become independent and agentic (i.e. it won&#x27;t face evolutionary pressure towards survival) or (D) AI capabilities will hit a ceiling soon (more so than just not becoming agentic).<p>If you strongly believe, or take as a prior, one of those things, then it makes sense to push the <i>gas</i> as hard as possible.<p>If you hold the opposite opinions, then it makes perfect sense to push the <i>brakes</i> as hard as possible, which is why &quot;govern compute&quot; can make sense as an idea.</div><br/><div id="40014822" class="c"><input type="checkbox" id="c-40014822" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013520">parent</a><span>|</span><a href="#40018715">next</a><span>|</span><label class="collapse" for="c-40014822">[-]</label><label class="expand" for="c-40014822">[5 more]</label></div><br/><div class="children"><div class="content">&gt;If you hold the opposite opinions, then it makes perfect sense to push the brakes as hard as possible, which is why &quot;govern compute&quot; can make sense as an idea.<p>The people pushing for &quot;govern compute&quot; are not pushing for &quot;limit everyone&#x27;s compute&quot;, they&#x27;re pushing for &quot;limit everyone&#x27;s compute except us&quot;. Even if you believe there&#x27;s going to be AGI, surely it&#x27;s better to have distributed AGI than to have AGI only in the hands of the elites.</div><br/><div id="40015223" class="c"><input type="checkbox" id="c-40015223" checked=""/><div class="controls bullet"><span class="by">segfaultbuserr</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014822">parent</a><span>|</span><a href="#40014995">next</a><span>|</span><label class="collapse" for="c-40015223">[-]</label><label class="expand" for="c-40015223">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>surely it&#x27;s better to have distributed AGI than to have AGI only in the hands of the elites.</i><p>The argument of doing so is the same as Nuclear Non-Proliferation - because of its great abuse potential, giving the technology to everyone only causes random bombings of cities instead of creating a system with checks and balances.<p>I do not necessarily agree with it, but I found the reasoning is not groundless.</div><br/></div></div><div id="40014995" class="c"><input type="checkbox" id="c-40014995" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014822">parent</a><span>|</span><a href="#40015223">prev</a><span>|</span><a href="#40017951">next</a><span>|</span><label class="collapse" for="c-40014995">[-]</label><label class="expand" for="c-40014995">[1 more]</label></div><br/><div class="children"><div class="content">&gt; surely it&#x27;s better to have distributed AGI than to have AGI only in the hands of the elites<p>This is not a given. If your threat model includes &quot;Runaway competition that leads to profit-seekers ignoring safety in a winner-takes-all contest&quot;, then the more companies are allowed to play with AI, the worse. Non-monopolies are especially bad.<p>If your threat model doesn&#x27;t include that, then the same conclusions sound abhorrent and can be nearly guaranteed to lead to awful consequences.<p>Neither side is necessarily wrong, and chances are good that the people behind the first set of rules <i>would agree</i> that it&#x27;ll lead to awful consequences â just not as bad as the alternative.</div><br/></div></div><div id="40017951" class="c"><input type="checkbox" id="c-40017951" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014822">parent</a><span>|</span><a href="#40014995">prev</a><span>|</span><a href="#40018715">next</a><span>|</span><label class="collapse" for="c-40017951">[-]</label><label class="expand" for="c-40017951">[1 more]</label></div><br/><div class="children"><div class="content">No they really do push for &quot;limit everyone&#x27;s compute&quot;. The people pushing for &quot;limit everyone&#x27;s compute except us&quot; are allies of convenience that are gonna be inevitably backstabbed.<p>At any rate, if you have like two corps with lots of compute, and something goes wrong, you only have to EMP two datacenters.</div><br/></div></div></div></div><div id="40018715" class="c"><input type="checkbox" id="c-40018715" checked=""/><div class="controls bullet"><span class="by">schlauerfox</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013520">parent</a><span>|</span><a href="#40014822">prev</a><span>|</span><a href="#40019695">next</a><span>|</span><label class="collapse" for="c-40018715">[-]</label><label class="expand" for="c-40018715">[1 more]</label></div><br/><div class="children"><div class="content">This is all just Pascal&#x27;s wager anyway.</div><br/></div></div></div></div><div id="40019695" class="c"><input type="checkbox" id="c-40019695" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011995">parent</a><span>|</span><a href="#40013520">prev</a><span>|</span><a href="#40015219">next</a><span>|</span><label class="collapse" for="c-40019695">[-]</label><label class="expand" for="c-40019695">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the same thing as always happens with freedom.<p>&quot;But foreign propagandists ...&quot;<p>&quot;But extremists ...&quot;<p>&quot;But terrorists ...&quot;<p>&quot;But child abusers ...&quot;</div><br/></div></div><div id="40015219" class="c"><input type="checkbox" id="c-40015219" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011995">parent</a><span>|</span><a href="#40019695">prev</a><span>|</span><a href="#40014462">next</a><span>|</span><label class="collapse" for="c-40015219">[-]</label><label class="expand" for="c-40015219">[1 more]</label></div><br/><div class="children"><div class="content">Are you allowed to store as many dangerous chemicals at your house as you like? No. I guess the government owns you or something.</div><br/></div></div><div id="40012805" class="c"><input type="checkbox" id="c-40012805" checked=""/><div class="controls bullet"><span class="by">aftbit</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011995">parent</a><span>|</span><a href="#40014462">prev</a><span>|</span><a href="#40011253">next</a><span>|</span><label class="collapse" for="c-40012805">[-]</label><label class="expand" for="c-40012805">[6 more]</label></div><br/><div class="children"><div class="content">The government sure thinks they own us, because they claim the right to charge us taxes on our private enterprises, draft us to fight in wars that they start, and put us in jail for walking on the wrong part of the street.</div><br/><div id="40012955" class="c"><input type="checkbox" id="c-40012955" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012805">parent</a><span>|</span><a href="#40011253">next</a><span>|</span><label class="collapse" for="c-40012955">[-]</label><label class="expand" for="c-40012955">[5 more]</label></div><br/><div class="children"><div class="content">Taxes, conscription and even pedestrian traffic rules make sense at least to some degree. Restricting &quot;AI&quot; because of what some uninformed politician imagines it to be is in a whole different league.</div><br/><div id="40013793" class="c"><input type="checkbox" id="c-40013793" checked=""/><div class="controls bullet"><span class="by">aftbit</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012955">parent</a><span>|</span><a href="#40011253">next</a><span>|</span><label class="collapse" for="c-40013793">[-]</label><label class="expand" for="c-40013793">[4 more]</label></div><br/><div class="children"><div class="content">IMO it makes no sense to arrest someone and send them to jail for walking in the street not the sidewalk. Give them a ticket, make them pay a fine, sure, but force them to live in a cage with no access to communications, entertainment, or livelihood? Insane.<p>Taxes may be necessary, though I can&#x27;t help but feel that there must be a better way that we have not been smart enough to find yet. Conscription... is a fact of war, where many evil things must be done in the name of survival.<p>Regardless of our views on the ethical validity or societal value of these laws, I think their very existence shows that the government believes it &quot;owns&quot; us in the sense that it can unilaterally deprive us of life, liberty, and property without our consent. I don&#x27;t see how this is really different in kind from depriving us of the right to make and own certain kinds of hardware. They regulated crypto products as munitions (at least for export) back in the 90s. Perhaps they will do the same for AI products in the future. &quot;Common sense&quot; computer control.</div><br/><div id="40014325" class="c"><input type="checkbox" id="c-40014325" checked=""/><div class="controls bullet"><span class="by">zoklet-enjoyer</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013793">parent</a><span>|</span><a href="#40011253">next</a><span>|</span><label class="collapse" for="c-40014325">[-]</label><label class="expand" for="c-40014325">[3 more]</label></div><br/><div class="children"><div class="content">The US draft in the Vietnam war had nothing to do with the survival of the US</div><br/><div id="40015234" class="c"><input type="checkbox" id="c-40015234" checked=""/><div class="controls bullet"><span class="by">aftbit</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014325">parent</a><span>|</span><a href="#40011253">next</a><span>|</span><label class="collapse" for="c-40015234">[-]</label><label class="expand" for="c-40015234">[2 more]</label></div><br/><div class="children"><div class="content">I feel a bit like everyone is missing the point here. Regardless of whether law A or law B is ethical and reasonable, the very existence of laws and the state monopoly on violence suggests a privileged position of power. I am attempting to engage with the word &quot;own&quot; from the parent post. I believe the government does in fact believe it &quot;owns&quot; the people in a non-trivial way.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40011253" class="c"><input type="checkbox" id="c-40011253" checked=""/><div class="controls bullet"><span class="by">tomoyoirl</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011206">parent</a><span>|</span><a href="#40011995">prev</a><span>|</span><a href="#40011531">next</a><span>|</span><label class="collapse" for="c-40011253">[-]</label><label class="expand" for="c-40011253">[34 more]</label></div><br/><div class="children"><div class="content">Mere raids from the authorities? I thought EliY was out there proposing airstrikes.</div><br/><div id="40011349" class="c"><input type="checkbox" id="c-40011349" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011253">parent</a><span>|</span><a href="#40011531">next</a><span>|</span><label class="collapse" for="c-40011349">[-]</label><label class="expand" for="c-40011349">[33 more]</label></div><br/><div class="children"><div class="content">In the sense that any other government regulation is also ultimately backed by the state&#x27;s monopoly on legal use of force when other measures have failed.<p>And contrary to what some people are implying he also proposes that everyone is subject to the same limitations, big players just like individuals. Because the big players haven&#x27;t shown much of a sign of doing enough.</div><br/><div id="40011489" class="c"><input type="checkbox" id="c-40011489" checked=""/><div class="controls bullet"><span class="by">tomoyoirl</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011349">parent</a><span>|</span><a href="#40011531">next</a><span>|</span><label class="collapse" for="c-40011489">[-]</label><label class="expand" for="c-40011489">[32 more]</label></div><br/><div class="children"><div class="content">&gt; In the sense that any other government regulation is also ultimately backed by the state&#x27;s monopoly on legal use of force when other measures have failed.<p>Good point. He was only (âonlyâ) <i>really</i> calling for international cooperation and literal air strikes against big datacenters that werenât cooperating. This would presumably be more of a no-knock raid, breaching your door with a battering ram and throwing tear gas at the wee hours of the morning ;) or maybe a small extraterritorial drone through your window</div><br/><div id="40011569" class="c"><input type="checkbox" id="c-40011569" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011489">parent</a><span>|</span><a href="#40011531">next</a><span>|</span><label class="collapse" for="c-40011569">[-]</label><label class="expand" for="c-40011569">[31 more]</label></div><br/><div class="children"><div class="content">... after regulation, court orders and fines have failed. Which under the premise that AGI is an existential threat would be far more reasonable than many other reasons for raids.<p>If the premise is wrong we won&#x27;t need it. If society coordinates to not do the dangerous thing we won&#x27;t need it. The argument is that only in the case where we find ourselves in the situation where other measures have failed such uses of force would be the fallback option.<p>I&#x27;m not seeing the odiousness of the proposal. If bio research gets commodified and easy enough that every kid can build a new airborne virus in their basement we&#x27;d need raids on that too.</div><br/><div id="40012041" class="c"><input type="checkbox" id="c-40012041" checked=""/><div class="controls bullet"><span class="by">raxxorraxor</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011569">parent</a><span>|</span><a href="#40012050">next</a><span>|</span><label class="collapse" for="c-40012041">[-]</label><label class="expand" for="c-40012041">[20 more]</label></div><br/><div class="children"><div class="content">To be honest, I see summoning the threat of AGI to pose an existential threat to be on the level with lizard people on the moon. Great for sci-fi, bad distraction for policy making and addressing real problems.<p>The real war, if there is one, is about owning data and collecting data. And surprisingly many people fall for distractions while their LLM fails at basic math. Because it is a language model of course...</div><br/><div id="40012076" class="c"><input type="checkbox" id="c-40012076" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012041">parent</a><span>|</span><a href="#40015293">next</a><span>|</span><label class="collapse" for="c-40012076">[-]</label><label class="expand" for="c-40012076">[18 more]</label></div><br/><div class="children"><div class="content">Freely flying through the sky on wings was scifi before the wright brothers. Something sounding like scifi is not a sound argument that it won&#x27;t happen. And unlike lizard people we do have exponential curves to point at.
Something stronger than a vibes-based argument would be good.</div><br/><div id="40012478" class="c"><input type="checkbox" id="c-40012478" checked=""/><div class="controls bullet"><span class="by">dvdkon</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012076">parent</a><span>|</span><a href="#40015293">next</a><span>|</span><label class="collapse" for="c-40012478">[-]</label><label class="expand" for="c-40012478">[17 more]</label></div><br/><div class="children"><div class="content">I consider the burden of proof to fall on those proclaiming AGI to be an existential threat, and so far I have not seen any convincing arguments. Maybe at some point in the future we will have many anthropomorphic robots and an AGI could hack them all and orchestrate a robot uprising, but at that point the robots would be the actual problem. Similarly, if an AGI could blow up nuclear power plants, so could well-funded human attackers; we need to secure the plants, not the AGI.</div><br/><div id="40013236" class="c"><input type="checkbox" id="c-40013236" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012478">parent</a><span>|</span><a href="#40012693">next</a><span>|</span><label class="collapse" for="c-40013236">[-]</label><label class="expand" for="c-40013236">[14 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t sound like you gave serious thought to the arguments. The AGI doesn&#x27;t need to hack robots. It has superhuman persuasion, by definition; it can &quot;hack&quot; (enough of) the humans to achieve its goals.</div><br/><div id="40013923" class="c"><input type="checkbox" id="c-40013923" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013236">parent</a><span>|</span><a href="#40013875">next</a><span>|</span><label class="collapse" for="c-40013923">[-]</label><label class="expand" for="c-40013923">[9 more]</label></div><br/><div class="children"><div class="content">AI mind control abilities are also on the level of an extraordinary claim, that requires extraordinary evidence.<p>It&#x27;s on the level of &quot;we better regulate wooden sticks so Voldemort doesn&#x27;t use the imperious curse on us!&quot;.<p>That&#x27;s how I treat such claims. I treat them the same as someone literally talking about magic from Harry potter.<p>There isn&#x27;t nothing that would make me believe that. But it requires actual evidence and not thought experiments.</div><br/><div id="40014077" class="c"><input type="checkbox" id="c-40014077" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013923">parent</a><span>|</span><a href="#40017970">next</a><span>|</span><label class="collapse" for="c-40014077">[-]</label><label class="expand" for="c-40014077">[4 more]</label></div><br/><div class="children"><div class="content">Voldemort is fictional and so are bumbling wizard apprentices. Toy-level, not-yet-harmful AIs on the other hand are real. And so are efforts to make them more powerful. So the proposition that more powerful AIs will exist in the future is far more likely than an evil super wizard coming into existence.<p>And I don&#x27;t think literal 5-word-magic-incantation mind control is essential for an AI to be dangerous. More subtle or elaborate manipulation will be sufficient. Employees already have been duped into financial transactions by faked video calls with what they assumed to be their CEOs[0], and this didn&#x27;t require superhuman general intelligence, only one single superhuman capability (realtime video manipulation).<p>[0] <a href="https:&#x2F;&#x2F;edition.cnn.com&#x2F;2024&#x2F;02&#x2F;04&#x2F;asia&#x2F;deepfake-cfo-scam-hong-kong-intl-hnk&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;edition.cnn.com&#x2F;2024&#x2F;02&#x2F;04&#x2F;asia&#x2F;deepfake-cfo-scam-ho...</a></div><br/><div id="40014136" class="c"><input type="checkbox" id="c-40014136" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014077">parent</a><span>|</span><a href="#40017970">next</a><span>|</span><label class="collapse" for="c-40014136">[-]</label><label class="expand" for="c-40014136">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Toy-level, not-yet-harmful AIs on the other hand are real.<p>A computer that can cause harm is much different than the absurd claims that I am disagreeing with.<p>The extraordinary claims that are equivalent to saying that the imperious curse exists would be the magic computers that create diamond nanobots and mind control humans.<p>&gt; that more powerful AIs will exist in the future<p>Bad argument.<p>Non safe Boxes exist in real life. People are trying to make more and better boxes.<p>Therefore it is rational to be worried about Pandora&#x27;s box being created and ending the world.<p>That is the equivalent argument to what you just made.<p>And it is absurd when talking about world ending box technology, even though Yes dangerous boxes exist, just as much as it is absurd to claim that world ending AI could exist.</div><br/><div id="40014343" class="c"><input type="checkbox" id="c-40014343" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014136">parent</a><span>|</span><a href="#40017970">next</a><span>|</span><label class="collapse" for="c-40014343">[-]</label><label class="expand" for="c-40014343">[2 more]</label></div><br/><div class="children"><div class="content">Instead of gesturing at flawed analogies, let&#x27;s return to the actual issue at hand. Do you think that agents more intelligent than humans are impossible or at least extremely unlikely to come into existence in the future? Or that such super-human intelligent agents are unlikely to have goals that are dangerous to humans? Or that they would be incapable of pursuing such goals?<p>Also, it seems obvious that the standard of evidence that &quot;AI could cause extinction&quot; can&#x27;t be observing an extinction level event, because at that point it would be too late. Considering that preventive measures would take time and safety margin, which level of evidence would be sufficient to motivate serious countermeasures?</div><br/></div></div></div></div></div></div><div id="40017970" class="c"><input type="checkbox" id="c-40017970" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013923">parent</a><span>|</span><a href="#40014077">prev</a><span>|</span><a href="#40014373">next</a><span>|</span><label class="collapse" for="c-40017970">[-]</label><label class="expand" for="c-40017970">[2 more]</label></div><br/><div class="children"><div class="content">Less than a month ago: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.14380" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.14380</a> &quot;We found that participants who debated GPT-4 with access to their personal information had 81.7% (p &lt; 0.01; N=820 unique participants) higher odds of increased agreement with their opponents compared to participants who debated humans.&quot;<p>And it&#x27;s only gonna get better.</div><br/><div id="40019497" class="c"><input type="checkbox" id="c-40019497" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40017970">parent</a><span>|</span><a href="#40014373">next</a><span>|</span><label class="collapse" for="c-40019497">[-]</label><label class="expand" for="c-40019497">[1 more]</label></div><br/><div class="children"><div class="content">Yes, and I am sure that when people do a google search for &quot;Good arguments in favor of X&quot;, that they are also sometimes convinced to be more in favor of X.<p>Perhaps they would be even more convinced by the google search than if a person argued with them about it.<p>That is still much different from &quot;The AI mind controls people, hacks the nukes, and ends the world&quot;.<p>Its that second part that is the the fantasy land situation that requires extraordinary evidence.<p>But, this is how conversations about doomsday AI always go.  People say &quot;Well isn&#x27;t AI kinda good at this extremely vague thing Y, sometimes?  Imagine if AI was infinitely good at Y!  That means that by extrapolation, the world ends!&quot;.<p>And that covers basically every single AI doom argument that anyone ever makes.</div><br/></div></div></div></div><div id="40014373" class="c"><input type="checkbox" id="c-40014373" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013923">parent</a><span>|</span><a href="#40017970">prev</a><span>|</span><a href="#40013875">next</a><span>|</span><label class="collapse" for="c-40014373">[-]</label><label class="expand" for="c-40014373">[2 more]</label></div><br/><div class="children"><div class="content">What do you think mind control <i>is</i>? Think President Trump but without the self-defeating flaws, with an ability to stick to plans, and most importantly the ability to pay personal attention to each follower to further increase the level of trust and commitment. Not Harry Potter.<p>People will do what the AI says because it is able to create personal trust relationships with them and they want to help it. (They may not even realize that they are helping an AI rather than a human who cares about them.)<p>The normal ways that trust is created, not magical ones.</div><br/><div id="40016318" class="c"><input type="checkbox" id="c-40016318" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014373">parent</a><span>|</span><a href="#40013875">next</a><span>|</span><label class="collapse" for="c-40016318">[-]</label><label class="expand" for="c-40016318">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What do you think mind control is?<p>The magic technology that is equivalent to the imperious curse from Harry Potter.<p>&gt; The normal ways that trust is created, not magical ones.<p>Buildings as a technology are normal.  They are constantly getting taller and  we have better technology to make them taller.<p>But, even though buildings are a normal technology, I am not going to worry about buildings getting so tall soon that they hit the sun.<p>This is the same exact mistake that every single AI doomers makes.  What they do is they take something normal, and then they infinitely extrapolate it out to an absurd degree, without admitting that this is an extraordinary claim that requires extraordinary evidence.<p>The central point of disagreement, that always gets glossed over, is that you can&#x27;t make a vague claim about how AI is good at stuff, and then do your gigantic leap from here to over there which is &quot;the world ends&quot;.<p>Yes that is the same as comparing these worries to those who worry about buildings hitting the sun or the imperious curse.</div><br/></div></div></div></div></div></div><div id="40013875" class="c"><input type="checkbox" id="c-40013875" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013236">parent</a><span>|</span><a href="#40013923">prev</a><span>|</span><a href="#40012693">next</a><span>|</span><label class="collapse" for="c-40013875">[-]</label><label class="expand" for="c-40013875">[4 more]</label></div><br/><div class="children"><div class="content">Then it&#x27;s just a matter of evolution in action.<p>And while it doesn&#x27;t take a God to start evolution, it <i>would</i> take a God to stop it.</div><br/><div id="40013893" class="c"><input type="checkbox" id="c-40013893" checked=""/><div class="controls bullet"><span class="by">hollerith</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013875">parent</a><span>|</span><a href="#40012693">next</a><span>|</span><label class="collapse" for="c-40013893">[-]</label><label class="expand" for="c-40013893">[3 more]</label></div><br/><div class="children"><div class="content"><i>You</i> might be OK with suddenly dying along with all your friends and family, but I am not even if it is &quot;evolution in action&quot;.</div><br/><div id="40013961" class="c"><input type="checkbox" id="c-40013961" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013893">parent</a><span>|</span><a href="#40012693">next</a><span>|</span><label class="collapse" for="c-40013961">[-]</label><label class="expand" for="c-40013961">[2 more]</label></div><br/><div class="children"><div class="content">Historically governments haven&#x27;t needed computers or AI to do that.  They&#x27;ve always managed just fine.<p>Punched cards helped, though, I guess...</div><br/><div id="40017985" class="c"><input type="checkbox" id="c-40017985" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013961">parent</a><span>|</span><a href="#40012693">next</a><span>|</span><label class="collapse" for="c-40017985">[-]</label><label class="expand" for="c-40017985">[1 more]</label></div><br/><div class="children"><div class="content"><i>gestures at the human population graph wordlessly</i></div><br/></div></div></div></div></div></div></div></div></div></div><div id="40012693" class="c"><input type="checkbox" id="c-40012693" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012478">parent</a><span>|</span><a href="#40013236">prev</a><span>|</span><a href="#40015293">next</a><span>|</span><label class="collapse" for="c-40012693">[-]</label><label class="expand" for="c-40012693">[2 more]</label></div><br/><div class="children"><div class="content">You say you have not seen any arguments that convince you. Is that just not having seen many arguments or having seen a lot of arguments where each chain contained some fatal flaw? Or something else?</div><br/></div></div></div></div></div></div><div id="40015293" class="c"><input type="checkbox" id="c-40015293" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012041">parent</a><span>|</span><a href="#40012076">prev</a><span>|</span><a href="#40012050">next</a><span>|</span><label class="collapse" for="c-40015293">[-]</label><label class="expand" for="c-40015293">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I see summoning the threat of AGI to pose an existential threat to be on the level with lizard people on the moon.<p>I mean to every other lifeform on the plant YOU are the AGI existential threat. You, and I mean homosapiens by that, have taken over the planet and have either enslaved and are breeding any other animals for food, or are driving them to extinction. In this light bringing another potential apex predator on to the scene seems rash.<p>&gt;fall for distractions while their LLM fails at basic math<p>Correct, if we already had AGI&#x2F;ASI this discussion would be moot because we&#x27;d already be in a world of trouble. The entire point is to slow stuff down before we have a major &quot;oopsie whoopsie we can&#x27;t take that back&quot; issue with advanced AI, and the best time to set the rules is now.</div><br/></div></div></div></div><div id="40012050" class="c"><input type="checkbox" id="c-40012050" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011569">parent</a><span>|</span><a href="#40012041">prev</a><span>|</span><a href="#40012114">next</a><span>|</span><label class="collapse" for="c-40012050">[-]</label><label class="expand" for="c-40012050">[3 more]</label></div><br/><div class="children"><div class="content">&gt;<i>If the premise is wrong we won&#x27;t need it. If society coordinates to not do the dangerous thing we won&#x27;t need it.</i><p>But the idea that this use of force is okay itself increases danger. It creates the situation that actors in the field might realize that at some point they&#x27;re in danger of this and decide to do a first strike to protect themselves.<p>I think this is why anti-nuclear policy is not &quot;we will airstrike you if you build nukes&quot; but rather &quot;we will infiltrate your network and try to stop you like that&quot;.</div><br/><div id="40013091" class="c"><input type="checkbox" id="c-40013091" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012050">parent</a><span>|</span><a href="#40017996">next</a><span>|</span><label class="collapse" for="c-40013091">[-]</label><label class="expand" for="c-40013091">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  anti-nuclear policy is not &quot;we will airstrike you if you build nukes&quot;<p>Was  that not the official policy during the Bush administration regarding weapons of mass destruction (which covers nuclear weapons in addition to chemical and biological weapons). That was pretty much the official premise of the second Gulf war</div><br/></div></div><div id="40017996" class="c"><input type="checkbox" id="c-40017996" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012050">parent</a><span>|</span><a href="#40013091">prev</a><span>|</span><a href="#40012114">next</a><span>|</span><label class="collapse" for="c-40017996">[-]</label><label class="expand" for="c-40017996">[1 more]</label></div><br/><div class="children"><div class="content">If Israel couldn&#x27;t infiltrate Iran&#x27;s centrifuges, do you think they would just let them have nukes? Of course airstrikes are on the table.</div><br/></div></div></div></div><div id="40012114" class="c"><input type="checkbox" id="c-40012114" checked=""/><div class="controls bullet"><span class="by">tomoyoirl</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011569">parent</a><span>|</span><a href="#40012050">prev</a><span>|</span><a href="#40013727">next</a><span>|</span><label class="collapse" for="c-40012114">[-]</label><label class="expand" for="c-40012114">[2 more]</label></div><br/><div class="children"><div class="content">&gt; ... after regulation, court orders and fines have failed<p>One question for you. In this hypothetical where AGI is truly considered such a grave threat, do you believe the reaction to this threat will be similar to, or substantially gentler than, the reaction to threats we face today like âterrorismâ and âdrugsâ? And, if similar: do you believe suspected drug labs get a court order before the state resorts to a police raid?<p>&gt; I&#x27;m not seeing the odiousness of the proposal.<p>Well, as regards EliY and airstrikes, Iâm more projecting my internal attitude that it is utterly unserious, rather than seriously engaging with whether or not it is odious. But in earnest: if you are proposing a policy that involves air strikes on data centers, you should understand what countries have data centers, and you should understand that this policy risks escalation into a much broader conflict. And if youâre proposing a policy in which conflict between nuclear superpowers is a very plausible outcome â potentially incurring the loss of billions of lives and degradation of the earthâs environment â you really should be able to reason about why people might reasonably think that your proposal is  deranged, even if you happen to think it justified by an even greater threat. Failure to understand these concerns will not aid you in overcoming deep skepticism.</div><br/><div id="40012549" class="c"><input type="checkbox" id="c-40012549" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012114">parent</a><span>|</span><a href="#40013727">next</a><span>|</span><label class="collapse" for="c-40012549">[-]</label><label class="expand" for="c-40012549">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In this hypothetical where AGI is truly considered such a grave threat, do you believe the reaction to this threat will be similar to, or substantially gentler than, the reaction to threats we face today like âterrorismâ and âdrugsâ?<p>&quot;truly considered&quot; does bear a lot of weight here. If policy-makers adopt the viewpoint wholesale, then yes, it follows that policy should also treat this more seriously than &quot;mere&quot; drug trade.
Whether that&#x27;ll actually happen or the response will be inadequate compared to the threat (such as might be said about CO2 emissions) is a subtly different question.<p>&gt; And, if similar: do you believe suspected drug labs get a court order before the state resorts to a police raid?<p>Without checking I do assume there&#x27;ll have been mild cases where for example someone growing cannabis was reported and they got a court summons in the mail or two policemen actually knocking on the door and showing a warrant and giving the person time to call a lawyer rather than an armed, no-knock police raid, yes.<p>&gt; And if youâre proposing a policy in which conflict between nuclear superpowers is a very plausible outcome â potentially incurring the loss of billions of lives and degradation of the earthâs environment â you really should be able to reason about why people might reasonably think that your proposal is deranged [...]<p>Said powers already engage in negotiations to limit the existential threats they themselves cause. They have <i>some</i> interest in their continued existence. If we get into a situation where there is another arms race between superpowers and is treated as a conflict rather than something that can be solved by cooperating on disarmament, then yes, obviously international policy will have failed too.<p>If you start from the position that any serious, globally coordinated regulation - where a few outliers will be brought to heel with sanctions and force - is ultimately doomed then you will of course conclude that anyone proposing regulation is deranged.<p>But that sounds like hoping that all problems forever can always be solved by locally implemented, partially-enforced, unilateral policies that aren&#x27;t seen as threats by other players? That defense scales as well or better than offense? Technologies are force-multipliers, as it improves so does the harm that small groups can inflict at scale. If it&#x27;s not AGI it might be bio-tech or asteroid mining. So eventually we will run into a problem of this type and we need to seriously discuss it without just going by gut reactions.</div><br/></div></div></div></div><div id="40013727" class="c"><input type="checkbox" id="c-40013727" checked=""/><div class="controls bullet"><span class="by">eek2121</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011569">parent</a><span>|</span><a href="#40012114">prev</a><span>|</span><a href="#40011940">next</a><span>|</span><label class="collapse" for="c-40013727">[-]</label><label class="expand" for="c-40013727">[2 more]</label></div><br/><div class="children"><div class="content">Just my (probably unpopular) opinion: True AI (what they are now calling AGI) may never exist. Even the AI models of today aren&#x27;t far removed from the &#x27;chatbots&#x27; of yesterday (more like an evolution rather than revolution)...<p>...for true AI to exist, it would need to be self aware. I don&#x27;t see that happening in our lifetimes when we don&#x27;t even know how our own brains work. (There is sooo much we don&#x27;t know about the human brain.)<p>AI models today differ only in terms of technology compared to the &#x27;chatbots&#x27; of yesterday. None are self aware, and none &#x27;want&#x27; to learn because they have no &#x27;wants&#x27; or &#x27;needs&#x27; outside of their fixed programming. They are little more than glorified auto complete engines.<p>Don&#x27;t get me wrong, I&#x27;m not insulting the tech. It will have it&#x27;s place just like any other, but when this bubble pops it&#x27;s going to ruin lives, and lots of them.<p>Shoot, maybe I&#x27;m wrong and AGI is around the corner, but I will continue to be pessimistic. I am old enough to have gone through numerous bubbles, and they never panned out the way people thought. They also nearly always end in some type of recession.</div><br/><div id="40015383" class="c"><input type="checkbox" id="c-40015383" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40013727">parent</a><span>|</span><a href="#40011940">next</a><span>|</span><label class="collapse" for="c-40015383">[-]</label><label class="expand" for="c-40015383">[1 more]</label></div><br/><div class="children"><div class="content">Why is &quot;Want&quot; even part of your equation.<p>Bacteria doesn&#x27;t &quot;want&quot; anything in the sense of active thinking like you do, and yet will render you dead quickly and efficiently while spreading at a near exponential rate. No self awareness necessary.<p>You keep drawing little circles based on your understanding of the world and going &quot;it&#x27;s inside this circle, therefore I don&#x27;t need to worry about it&quot;, while ignoring &#x27;semi-smart&#x27; optimization systems that can lead to dangerous outcomes.<p>&gt;I am old enough to have gone through numerous bubbles,<p>And evidently not old enough to pay attention to the things that did pan out. But hey, those cellphone and that internet thing was just a fad right. We&#x27;ll go back to land lines at any time now.</div><br/></div></div></div></div><div id="40011940" class="c"><input type="checkbox" id="c-40011940" checked=""/><div class="controls bullet"><span class="by">s2l</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011569">parent</a><span>|</span><a href="#40013727">prev</a><span>|</span><a href="#40012073">next</a><span>|</span><label class="collapse" for="c-40011940">[-]</label><label class="expand" for="c-40011940">[1 more]</label></div><br/><div class="children"><div class="content">Time to publish the next book in &quot;Stealing the network&quot; series.</div><br/></div></div><div id="40012073" class="c"><input type="checkbox" id="c-40012073" checked=""/><div class="controls bullet"><span class="by">im3w1l</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011569">parent</a><span>|</span><a href="#40011940">prev</a><span>|</span><a href="#40011531">next</a><span>|</span><label class="collapse" for="c-40012073">[-]</label><label class="expand" for="c-40012073">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m not seeing the odiousness of the proposal. If bio research gets commodified and easy enough that every kid can build a new airborne virus in their basement we&#x27;d need raids on that too.<p>Either you create even better bio research to neutralize said viruses... or you die trying...<p>Like if you go with the raid strategy and fail to raid just one terrorist that&#x27;s it, game over.</div><br/><div id="40012120" class="c"><input type="checkbox" id="c-40012120" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012073">parent</a><span>|</span><a href="#40011531">next</a><span>|</span><label class="collapse" for="c-40012120">[-]</label><label class="expand" for="c-40012120">[1 more]</label></div><br/><div class="children"><div class="content">Those arguments do not transfer well to the AGI topic. You can&#x27;t create counter-AGI, since that&#x27;s also an intelligent agent which would be just as dangerous. And chips are more bottlenecked than biologics (... though gene synthesizing machines could be a similar bottleneck and raiding vendors which illegally sell those might be viable in such a scenario).</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40011531" class="c"><input type="checkbox" id="c-40011531" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011206">parent</a><span>|</span><a href="#40011253">prev</a><span>|</span><a href="#40012416">next</a><span>|</span><label class="collapse" for="c-40011531">[-]</label><label class="expand" for="c-40011531">[1 more]</label></div><br/><div class="children"><div class="content">That is not different from any other very powerful dual-use technology. This is hardly a new concept.</div><br/></div></div><div id="40012416" class="c"><input type="checkbox" id="c-40012416" checked=""/><div class="controls bullet"><span class="by">snakeyjake</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40011206">parent</a><span>|</span><a href="#40011531">prev</a><span>|</span><a href="#40014674">next</a><span>|</span><label class="collapse" for="c-40012416">[-]</label><label class="expand" for="c-40012416">[7 more]</label></div><br/><div class="children"><div class="content">I love the HN dystopian fantasies.<p>They&#x27;re simply adorable.<p>They&#x27;re like how jesusfreaks are constantly predicting the end times, with less mass suicide.</div><br/><div id="40012647" class="c"><input type="checkbox" id="c-40012647" checked=""/><div class="controls bullet"><span class="by">erikbye</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012416">parent</a><span>|</span><a href="#40014674">next</a><span>|</span><label class="collapse" for="c-40012647">[-]</label><label class="expand" for="c-40012647">[6 more]</label></div><br/><div class="children"><div class="content">We already have export restrictions on cryptography. Of course there will be AI regulations.</div><br/><div id="40012990" class="c"><input type="checkbox" id="c-40012990" checked=""/><div class="controls bullet"><span class="by">Jerrrry</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012647">parent</a><span>|</span><a href="#40014287">next</a><span>|</span><label class="collapse" for="c-40012990">[-]</label><label class="expand" for="c-40012990">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Of course there will be AI regulations.<p>Are. As I and others have predicted, the executive order was passed defining a hard limit on the processing&#x2F;compute power allowed without first &#x27;checkin in&#x27; with the Letter boys.<p><a href="https:&#x2F;&#x2F;www.whitehouse.gov&#x2F;briefing-room&#x2F;presidential-actions&#x2F;2023&#x2F;10&#x2F;30&#x2F;executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.whitehouse.gov&#x2F;briefing-room&#x2F;presidential-action...</a></div><br/><div id="40019805" class="c"><input type="checkbox" id="c-40019805" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012990">parent</a><span>|</span><a href="#40014287">next</a><span>|</span><label class="collapse" for="c-40019805">[-]</label><label class="expand" for="c-40019805">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if we can squeeze a 20b parameter model into a book somehow...</div><br/></div></div></div></div><div id="40014287" class="c"><input type="checkbox" id="c-40014287" checked=""/><div class="controls bullet"><span class="by">snakeyjake</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40012647">parent</a><span>|</span><a href="#40012990">prev</a><span>|</span><a href="#40014674">next</a><span>|</span><label class="collapse" for="c-40014287">[-]</label><label class="expand" for="c-40014287">[3 more]</label></div><br/><div class="children"><div class="content">You need to abandon your apocalyptic worldview keep up with the times my friend.<p>Encryption export controls have been systematically dismantled to the point that they&#x27;re practically non-existent, especially over the last three years.<p>Pretty much the only encryption products you need permission to export are those specifically designed for integration into military communications networks, like Digital Subscriber Voice Terminals or Secure Terminal Equipment phones, everything else you file a form.<p>Many things have changed since the days when Windows 2000 shipped with a floppy disk containing strong encryption for use in certain markets.<p><a href="https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;highencryptionfloppydisk" rel="nofollow">https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;highencryptionfloppydisk</a></div><br/><div id="40014856" class="c"><input type="checkbox" id="c-40014856" checked=""/><div class="controls bullet"><span class="by">erikbye</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014287">parent</a><span>|</span><a href="#40014674">next</a><span>|</span><label class="collapse" for="c-40014856">[-]</label><label class="expand" for="c-40014856">[2 more]</label></div><br/><div class="children"><div class="content">Are you on drugs or is your reading comprehension that poor?<p>1) I did not state a world view; I simply noted that restrictions for software do exist, and will for AI, as well. As the link from the other commenter show, they do in fact already exist.<p>2) Look up the definition of &quot;apocalyptic&quot;, software restrictions are not within its bounds.<p>3) How the restrictions are enforced were not a subject in my comment.<p>4) We&#x27;re not pals, so you can drop the &quot;friend&quot;, just stick to the subject at hand.</div><br/><div id="40021054" class="c"><input type="checkbox" id="c-40021054" checked=""/><div class="controls bullet"><span class="by">snakeyjake</span><span>|</span><a href="#40011189">root</a><span>|</span><a href="#40014856">parent</a><span>|</span><a href="#40014674">next</a><span>|</span><label class="collapse" for="c-40021054">[-]</label><label class="expand" for="c-40021054">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m high on life, old chum!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40014674" class="c"><input type="checkbox" id="c-40014674" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#40011189">parent</a><span>|</span><a href="#40011206">prev</a><span>|</span><a href="#40011634">next</a><span>|</span><label class="collapse" for="c-40014674">[-]</label><label class="expand" for="c-40014674">[1 more]</label></div><br/><div class="children"><div class="content">If it could be another acronym than the renowned french Atomic Energy Commission, the CEA.</div><br/></div></div></div></div><div id="40011634" class="c"><input type="checkbox" id="c-40011634" checked=""/><div class="controls bullet"><span class="by">gigatexal</span><span>|</span><a href="#40011189">prev</a><span>|</span><a href="#40012293">next</a><span>|</span><label class="collapse" for="c-40011634">[-]</label><label class="expand" for="c-40011634">[1 more]</label></div><br/><div class="children"><div class="content">as a technical feat this is really cool! though as others mention i hope you don&#x27;t get into too much hot water legally<p>seems anything that remotely lets &quot;consumer&quot; cards canibalize anything with the higher end H&#x2F;A-series cards Nvidia would not be fond of and they&#x27;ve the laywers to throw at such a thing</div><br/></div></div><div id="40012293" class="c"><input type="checkbox" id="c-40012293" checked=""/><div class="controls bullet"><span class="by">namibj</span><span>|</span><a href="#40011634">prev</a><span>|</span><a href="#40013564">next</a><span>|</span><label class="collapse" for="c-40012293">[-]</label><label class="expand" for="c-40012293">[2 more]</label></div><br/><div class="children"><div class="content">And here I thought (PCIe) P2P was there since SLI dropped the bridge (for the unfamiliar, it looks and acts pretty much like an NVLink bridge for regular PCIe slot cards that have NVLink, and was used back in the day to share framebuffer and similar in high-end gaming setups).</div><br/><div id="40014428" class="c"><input type="checkbox" id="c-40014428" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40012293">parent</a><span>|</span><a href="#40013564">next</a><span>|</span><label class="collapse" for="c-40014428">[-]</label><label class="expand" for="c-40014428">[1 more]</label></div><br/><div class="children"><div class="content">SLI was dropped years ago so there&#x27;s no need for gaming cards to communicate at all.</div><br/></div></div></div></div><div id="40013564" class="c"><input type="checkbox" id="c-40013564" checked=""/><div class="controls bullet"><span class="by">perfobotto</span><span>|</span><a href="#40012293">prev</a><span>|</span><a href="#40016652">next</a><span>|</span><label class="collapse" for="c-40013564">[-]</label><label class="expand" for="c-40013564">[3 more]</label></div><br/><div class="children"><div class="content">What stops nvidia from making sure this stops working in future driver releases?</div><br/><div id="40014468" class="c"><input type="checkbox" id="c-40014468" checked=""/><div class="controls bullet"><span class="by">__MatrixMan__</span><span>|</span><a href="#40013564">parent</a><span>|</span><a href="#40016269">next</a><span>|</span><label class="collapse" for="c-40014468">[-]</label><label class="expand" for="c-40014468">[1 more]</label></div><br/><div class="children"><div class="content">The law, hopefully.<p>Beeper mini only worked with iMessage for a few days before Apple killed it.  A few months later the DOJ sued Apple.  Hacks like this show us the world we could be living in, a world which can be hard to envision otherwise.  If we want to actually live in that world, we have to fight for it (and protect the hackers besides).</div><br/></div></div><div id="40016269" class="c"><input type="checkbox" id="c-40016269" checked=""/><div class="controls bullet"><span class="by">StayTrue</span><span>|</span><a href="#40013564">parent</a><span>|</span><a href="#40014468">prev</a><span>|</span><a href="#40016652">next</a><span>|</span><label class="collapse" for="c-40016269">[-]</label><label class="expand" for="c-40016269">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking the same but in terms of firmware updates.</div><br/></div></div></div></div><div id="40016652" class="c"><input type="checkbox" id="c-40016652" checked=""/><div class="controls bullet"><span class="by">cavisne</span><span>|</span><a href="#40013564">prev</a><span>|</span><a href="#40011287">next</a><span>|</span><label class="collapse" for="c-40016652">[-]</label><label class="expand" for="c-40016652">[2 more]</label></div><br/><div class="children"><div class="content">How does this compare in bandwidth and latency to nvlink? (Iâm aware itâs not available on the consumer cards)</div><br/><div id="40016975" class="c"><input type="checkbox" id="c-40016975" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#40016652">parent</a><span>|</span><a href="#40011287">next</a><span>|</span><label class="collapse" for="c-40016975">[-]</label><label class="expand" for="c-40016975">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s 5x-10x slower.</div><br/></div></div></div></div><div id="40011287" class="c"><input type="checkbox" id="c-40011287" checked=""/><div class="controls bullet"><span class="by">ewalk153</span><span>|</span><a href="#40016652">prev</a><span>|</span><a href="#40013619">next</a><span>|</span><label class="collapse" for="c-40011287">[-]</label><label class="expand" for="c-40011287">[8 more]</label></div><br/><div class="children"><div class="content">Does this appear to be intentionally left out by NVidia or an oversight?</div><br/><div id="40011364" class="c"><input type="checkbox" id="c-40011364" checked=""/><div class="controls bullet"><span class="by">nikitml</span><span>|</span><a href="#40011287">parent</a><span>|</span><a href="#40011354">next</a><span>|</span><label class="collapse" for="c-40011364">[-]</label><label class="expand" for="c-40011364">[1 more]</label></div><br/><div class="children"><div class="content">NVidia wants you to buy A6000</div><br/></div></div><div id="40011354" class="c"><input type="checkbox" id="c-40011354" checked=""/><div class="controls bullet"><span class="by">creshal</span><span>|</span><a href="#40011287">parent</a><span>|</span><a href="#40011364">prev</a><span>|</span><a href="#40013619">next</a><span>|</span><label class="collapse" for="c-40011354">[-]</label><label class="expand" for="c-40011354">[6 more]</label></div><br/><div class="children"><div class="content">Seems more like an oversight, since you have to stitch together a bunch of suboptimal non-default options?</div><br/><div id="40011476" class="c"><input type="checkbox" id="c-40011476" checked=""/><div class="controls bullet"><span class="by">arghwhat</span><span>|</span><a href="#40011287">root</a><span>|</span><a href="#40011354">parent</a><span>|</span><a href="#40013619">next</a><span>|</span><label class="collapse" for="c-40011476">[-]</label><label class="expand" for="c-40011476">[5 more]</label></div><br/><div class="children"><div class="content">It does seem like an oversight, but there&#x27;s nothing &quot;suboptimal non-default options&quot; about iteven if the implementation posted here seems somewhat hastily hacked together.</div><br/><div id="40012661" class="c"><input type="checkbox" id="c-40012661" checked=""/><div class="controls bullet"><span class="by">segfaultbuserr</span><span>|</span><a href="#40011287">root</a><span>|</span><a href="#40011476">parent</a><span>|</span><a href="#40013619">next</a><span>|</span><label class="collapse" for="c-40012661">[-]</label><label class="expand" for="c-40012661">[4 more]</label></div><br/><div class="children"><div class="content">&gt; <i>but there&#x27;s nothing &quot;suboptimal non-default options&quot; about it</i><p>If &quot;bypassing the official driver to invoke the underlying hardware feature directly through source code modification (and incompatibilities must be carefully worked around by turning off IOMMU and large BAR, since the feature was never officially supported)&quot; does not count as &quot;suboptimal non-default options&quot;, then I don&#x27;t know what counts as &quot;suboptimal non-default options&quot;.</div><br/><div id="40021232" class="c"><input type="checkbox" id="c-40021232" checked=""/><div class="controls bullet"><span class="by">arghwhat</span><span>|</span><a href="#40011287">root</a><span>|</span><a href="#40012661">parent</a><span>|</span><a href="#40017275">next</a><span>|</span><label class="collapse" for="c-40021232">[-]</label><label class="expand" for="c-40021232">[1 more]</label></div><br/><div class="children"><div class="content">&gt; bypassing the official driverto<p>The driver is not bypasses. This is a patch to the official open-source kernel-driver where the feature is added, which is how all upstream Linux driver development is done.<p>&gt; to invoke the underlying hardware feature directly<p>Accessing hardware features directly is pretty much the sole job of a driver, and the only thing &quot;bypassed&quot; is some abstractions internal to the driver. Just means the patch would fail review in basis of codestyle, and on the basis of possibly only supporting one device family.<p>&gt; through source code modification<p>That is a weird way to describe software engineering. Making the code available for further development is kind of the whole point of open source.<p>&gt; turning off IOMMU<p>This is not a P2PDMA problem, and just a result of them not also adding the necessary IOMMU boilerplate, which would be added if the patch was done properly to be upstreamed.<p>&gt; large BAR<p>This is an expected and &quot;optimal&quot; system requirement.</div><br/></div></div><div id="40017275" class="c"><input type="checkbox" id="c-40017275" checked=""/><div class="controls bullet"><span class="by">_zoltan_</span><span>|</span><a href="#40011287">root</a><span>|</span><a href="#40012661">parent</a><span>|</span><a href="#40021232">prev</a><span>|</span><a href="#40014335">next</a><span>|</span><label class="collapse" for="c-40017275">[-]</label><label class="expand" for="c-40017275">[1 more]</label></div><br/><div class="children"><div class="content">I have some news for you: you must disable IOMMU on the H100 platform anyway, at least for optimal GDS :-)</div><br/></div></div><div id="40014335" class="c"><input type="checkbox" id="c-40014335" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#40011287">root</a><span>|</span><a href="#40012661">parent</a><span>|</span><a href="#40017275">prev</a><span>|</span><a href="#40013619">next</a><span>|</span><label class="collapse" for="c-40014335">[-]</label><label class="expand" for="c-40014335">[1 more]</label></div><br/><div class="children"><div class="content">&gt; then I don&#x27;t know what counts as &quot;suboptimal non-default options&quot;.<p>Boy oh boy do I have a bridge to sell you: <a href="https:&#x2F;&#x2F;nouveau.freedesktop.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;nouveau.freedesktop.org&#x2F;</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="40013619" class="c"><input type="checkbox" id="c-40013619" checked=""/><div class="controls bullet"><span class="by">aresant</span><span>|</span><a href="#40011287">prev</a><span>|</span><a href="#40014097">next</a><span>|</span><label class="collapse" for="c-40013619">[-]</label><label class="expand" for="c-40013619">[2 more]</label></div><br/><div class="children"><div class="content">So assuming you utilized this with (4) x 4090s is there a theoretical comparative to performance vs the A6000 &#x2F; other professional lines?</div><br/><div id="40013976" class="c"><input type="checkbox" id="c-40013976" checked=""/><div class="controls bullet"><span class="by">thangngoc89</span><span>|</span><a href="#40013619">parent</a><span>|</span><a href="#40014097">next</a><span>|</span><label class="collapse" for="c-40013976">[-]</label><label class="expand" for="c-40013976">[1 more]</label></div><br/><div class="children"><div class="content">I believe this is mostly for memory capacities. PCIe access between GPUs is slower than soldered RAM on a single GPU</div><br/></div></div></div></div><div id="40014097" class="c"><input type="checkbox" id="c-40014097" checked=""/><div class="controls bullet"><span class="by">lawlessone</span><span>|</span><a href="#40013619">prev</a><span>|</span><a href="#40014041">next</a><span>|</span><label class="collapse" for="c-40014097">[-]</label><label class="expand" for="c-40014097">[1 more]</label></div><br/><div class="children"><div class="content">This is very interesting.<p>I can&#x27;t afford two mortgages though ,so for me it will have to just stay as something interesting :)</div><br/></div></div><div id="40014041" class="c"><input type="checkbox" id="c-40014041" checked=""/><div class="controls bullet"><span class="by">spxneo</span><span>|</span><a href="#40014097">prev</a><span>|</span><a href="#40013883">next</a><span>|</span><label class="collapse" for="c-40014041">[-]</label><label class="expand" for="c-40014041">[1 more]</label></div><br/><div class="children"><div class="content">does this mean you can horizontally scale to GPT-4-esque LLM locally in the near future? (i hear you need 1TB of VRAM)<p>Is Apple&#x27;s large VRAM offering like 196gb offer the fastest bandwidth and if so how will pairing a bunch of 4090s like in the comments work?</div><br/></div></div><div id="40013883" class="c"><input type="checkbox" id="c-40013883" checked=""/><div class="controls bullet"><span class="by">musha68k</span><span>|</span><a href="#40014041">prev</a><span>|</span><label class="collapse" for="c-40013883">[-]</label><label class="expand" for="c-40013883">[1 more]</label></div><br/><div class="children"><div class="content">OK now we are seemingly getting somewhere. I can feel the enthusiasm coming back to me.<p>Especially in light of what&#x27;s going on with LocalLLaMA etc:<p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1c0mkk9&#x2F;mistral_8x22b_already_runs_on_m2_ultra_192gb_with" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1c0mkk9&#x2F;mistral...</a></div><br/></div></div></div></div></div></div></div></body></html>