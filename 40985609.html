<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1721293263115" as="style"/><link rel="stylesheet" href="styles.css?v=1721293263115"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Launch HN: Traceloop (YC W23) – Detecting LLM Hallucinations with OpenTelemetry</a> </div><div class="subtext"><span>GalKlm</span> | <span>65 comments</span></div><br/><div><div id="40987046" class="c"><input type="checkbox" id="c-40987046" checked=""/><div class="controls bullet"><span class="by">resiros</span><span>|</span><a href="#40992336">next</a><span>|</span><label class="collapse" for="c-40987046">[-]</label><label class="expand" for="c-40987046">[6 more]</label></div><br/><div class="children"><div class="content">Just wanted to say great work on standardizing otel for LLM applications (<a href="https:&#x2F;&#x2F;github.com&#x2F;open-telemetry&#x2F;semantic-conventions&#x2F;tree&#x2F;main&#x2F;docs&#x2F;gen-ai">https:&#x2F;&#x2F;github.com&#x2F;open-telemetry&#x2F;semantic-conventions&#x2F;tree&#x2F;...</a>] and opensourcing OpenLLMetry. We&#x27;re also building in this space, focusing more on eval (agenta). I think using otel would make the whole space move much faster.</div><br/><div id="40987185" class="c"><input type="checkbox" id="c-40987185" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40987046">parent</a><span>|</span><a href="#40992336">next</a><span>|</span><label class="collapse" for="c-40987185">[-]</label><label class="expand" for="c-40987185">[5 more]</label></div><br/><div class="children"><div class="content">Thanks so much! I always say that I&#x27;m a strong believer in open protocols so I&#x27;d love to assist you if you want to use OpenLLMetry as your SDK. We onboarded other startups &#x2F; competitors like Helicone and Honeyhive and it&#x27;s been tremendously successful (hopefully that&#x27;s what they&#x27;ll tell you as well)</div><br/><div id="40988504" class="c"><input type="checkbox" id="c-40988504" checked=""/><div class="controls bullet"><span class="by">mshcodez</span><span>|</span><a href="#40987046">root</a><span>|</span><a href="#40987185">parent</a><span>|</span><a href="#40992336">next</a><span>|</span><label class="collapse" for="c-40988504">[-]</label><label class="expand" for="c-40988504">[4 more]</label></div><br/><div class="children"><div class="content">HoneyHive founder here.<p>Nir and team have built an amazing OSS package and have been fantastic to collaborate with (despite being competitors)! As an industry, I think more of us need to work together to standardize telemetry protocols, schemas, naming conventions, etc. since it’s currently all over the place and leads to a ton of confusion and headache for developers (which ultimately goes against the whole point of using devtools in the first place).<p>We recently integrated OpenLLMetry into our SDKs with the sole purpose of offering standardization and interoperability with customers’ existing DevSecOps stacks. Customers have been loving it so far!</div><br/><div id="40990280" class="c"><input type="checkbox" id="c-40990280" checked=""/><div class="controls bullet"><span class="by">lukan</span><span>|</span><a href="#40987046">root</a><span>|</span><a href="#40988504">parent</a><span>|</span><a href="#40989338">next</a><span>|</span><label class="collapse" for="c-40990280">[-]</label><label class="expand" for="c-40990280">[1 more]</label></div><br/><div class="children"><div class="content">No idea how honest this is (I might have gotten a bit cynical) - but reading this sounds like you guys have a really healthy constructive competition with elements of cooperation! Love to see that.</div><br/></div></div><div id="40989338" class="c"><input type="checkbox" id="c-40989338" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#40987046">root</a><span>|</span><a href="#40988504">parent</a><span>|</span><a href="#40990280">prev</a><span>|</span><a href="#40992336">next</a><span>|</span><label class="collapse" for="c-40989338">[-]</label><label class="expand" for="c-40989338">[2 more]</label></div><br/><div class="children"><div class="content">Your startup is as deceptive as Traceloop.<p>You make claims like &quot;detect LLM errors like hallucination&quot; even though you have no guaranteed ability to do this.<p>At best you can assist in detection.<p>As someone who works at a large enterprise deploying LLMs I can tell you many people are getting pretty tired of the false claims.</div><br/><div id="40989464" class="c"><input type="checkbox" id="c-40989464" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40987046">root</a><span>|</span><a href="#40989338">parent</a><span>|</span><a href="#40992336">next</a><span>|</span><label class="collapse" for="c-40989464">[-]</label><label class="expand" for="c-40989464">[1 more]</label></div><br/><div class="children"><div class="content">I replied to you in a different thread, I don&#x27;t think calling our companies &quot;deceptive&quot; will help you or me get anywhere. While I agree with you that detection will never be hermetic, I don&#x27;t think this is the goal. By design you&#x27;ll have hallucinations and the question should be how can you monitor the rate and look for changes and anomalies.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40992336" class="c"><input type="checkbox" id="c-40992336" checked=""/><div class="controls bullet"><span class="by">altdataseller</span><span>|</span><a href="#40987046">prev</a><span>|</span><a href="#40987200">next</a><span>|</span><label class="collapse" for="c-40992336">[-]</label><label class="expand" for="c-40992336">[3 more]</label></div><br/><div class="children"><div class="content">I dont know if they are just casually using logos on their homepage but why the heck would Google (and even IBM) be using a product like this? Like… your entire future depends on getting this right and youre using a startup with 2-5 people to do this for you?!!<p>Make it make sense..</div><br/><div id="40992688" class="c"><input type="checkbox" id="c-40992688" checked=""/><div class="controls bullet"><span class="by">sakjur</span><span>|</span><a href="#40992336">parent</a><span>|</span><a href="#40987200">next</a><span>|</span><label class="collapse" for="c-40992688">[-]</label><label class="expand" for="c-40992688">[2 more]</label></div><br/><div class="children"><div class="content">If that’s true, they should want to evaluate all the options out there to ensure they’re not missing out.<p>Though I think it’s more likely there’s some Googler who happen to use this service, note how the wording is “Engineers […] use our products[…]” rather than “Companies”.</div><br/><div id="40993038" class="c"><input type="checkbox" id="c-40993038" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#40992336">root</a><span>|</span><a href="#40992688">parent</a><span>|</span><a href="#40987200">next</a><span>|</span><label class="collapse" for="c-40993038">[-]</label><label class="expand" for="c-40993038">[1 more]</label></div><br/><div class="children"><div class="content">Someone with a gmail address most likely.</div><br/></div></div></div></div></div></div><div id="40987200" class="c"><input type="checkbox" id="c-40987200" checked=""/><div class="controls bullet"><span class="by">Lienetic</span><span>|</span><a href="#40992336">prev</a><span>|</span><a href="#40985705">next</a><span>|</span><label class="collapse" for="c-40987200">[-]</label><label class="expand" for="c-40987200">[7 more]</label></div><br/><div class="children"><div class="content">Where can I learn more detail about the metrics you support and how they work?<p>I tried multiple other solutions but kept running into the problem that occasionally the framework would give me some score&#x2F;evaluation of an LLM response that didn&#x27;t make any sense, and there was minimal information about how it came up with the score. Often, I&#x27;d end up digging into the implementation of the framework to find the underlying evaluation prompt or classifier only to realize that the metric name is confusing or results are low confidence. I&#x27;m more cautious about using these tools now and look more deeply at how they work so that I can assess grading quality before relying on them to identify problematic outputs (e.g. hallucinations).</div><br/><div id="40987261" class="c"><input type="checkbox" id="c-40987261" checked=""/><div class="controls bullet"><span class="by">resiros</span><span>|</span><a href="#40987200">parent</a><span>|</span><a href="#40987356">next</a><span>|</span><label class="collapse" for="c-40987261">[-]</label><label class="expand" for="c-40987261">[5 more]</label></div><br/><div class="children"><div class="content">I think the issue is that many of these metrics (e.g. RAGAS) are LLM as a judge metrics. These are very far from reliable. Making them reliable is still a research problem. I&#x27;ve seen a couple of startups training their own LLM judge models to solve this problem. There are also some work to attempt to improve the reliability through sampling such as G-eval (<a href="https:&#x2F;&#x2F;github.com&#x2F;nlpyang&#x2F;geval">https:&#x2F;&#x2F;github.com&#x2F;nlpyang&#x2F;geval</a>).<p>One need to think of these metrics as a way to filter all the data to find potential issues, and not as a final evaluation criteria. The golden criteria should be human evaluators.</div><br/><div id="40987481" class="c"><input type="checkbox" id="c-40987481" checked=""/><div class="controls bullet"><span class="by">Lienetic</span><span>|</span><a href="#40987200">root</a><span>|</span><a href="#40987261">parent</a><span>|</span><a href="#40987356">next</a><span>|</span><label class="collapse" for="c-40987481">[-]</label><label class="expand" for="c-40987481">[4 more]</label></div><br/><div class="children"><div class="content">Are there any approaches today that you&#x27;ve found are at least mostly reliable? Bonus points if it is somewhat clear&#x2F;easy&#x2F;predictable to know when it isn&#x27;t or won&#x27;t be.<p>We use human evaluation but that is naturally far from scalable, which has especially been a problem when working on more complicated workflows&#x2F;chains where changes can have a cascading effect. I&#x27;ve been encouraging a lot of dev experimentation on my team but would like to get a more consistent eval approach so we can evaluate and discuss changes with more grounded results. If all of these metrics are low confidence, they become counterproductive since people easily fall into the trap of optimizing the metric.</div><br/><div id="40987509" class="c"><input type="checkbox" id="c-40987509" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40987200">root</a><span>|</span><a href="#40987481">parent</a><span>|</span><a href="#40987356">next</a><span>|</span><label class="collapse" for="c-40987509">[-]</label><label class="expand" for="c-40987509">[3 more]</label></div><br/><div class="children"><div class="content">I tend to find classic NLP metric more predictable and stable than &quot;LLM as a judge&quot; metrics so I&#x27;d try to see if you rely on them more.<p>We&#x27;ve written a couple of blog posts about some of them:
<a href="https:&#x2F;&#x2F;www.traceloop.com&#x2F;blog">https:&#x2F;&#x2F;www.traceloop.com&#x2F;blog</a></div><br/><div id="40987592" class="c"><input type="checkbox" id="c-40987592" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#40987200">root</a><span>|</span><a href="#40987509">parent</a><span>|</span><a href="#40987356">next</a><span>|</span><label class="collapse" for="c-40987592">[-]</label><label class="expand" for="c-40987592">[2 more]</label></div><br/><div class="children"><div class="content">for your blog can i offer a big downvote for the massive ai generated cover image thing? its a trend for normies but for developers its absolutely meaningless. give us info density pls</div><br/><div id="40987613" class="c"><input type="checkbox" id="c-40987613" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40987200">root</a><span>|</span><a href="#40987592">parent</a><span>|</span><a href="#40987356">next</a><span>|</span><label class="collapse" for="c-40987613">[-]</label><label class="expand" for="c-40987613">[1 more]</label></div><br/><div class="children"><div class="content">roger that! I like them though (am I a normie then?)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40987356" class="c"><input type="checkbox" id="c-40987356" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40987200">parent</a><span>|</span><a href="#40987261">prev</a><span>|</span><a href="#40985705">next</a><span>|</span><label class="collapse" for="c-40987356">[-]</label><label class="expand" for="c-40987356">[1 more]</label></div><br/><div class="children"><div class="content">We trained our own models for some of them, and we combined some well known NLP metrics (like Gruen [1]) to make this work.<p>You&#x27;re right that it&#x27;s hard to figure out how to &quot;trust&quot; these metrics. But you shouldn&#x27;t look at them as a way to get an objective number about your app&#x27;s performance. They&#x27;re more of a way to detect deltas - regressions or changes in performance. When you get more alerts, or more negative results (or less alerts &#x2F; less negative results) - you can tell you&#x27;re improving. And this works for tools like RAGAS as well as our own metrics in my view.<p>[1] <a href="https:&#x2F;&#x2F;www.traceloop.com&#x2F;blog&#x2F;gruens-outstanding-performance-in-llm-quality-evaluation">https:&#x2F;&#x2F;www.traceloop.com&#x2F;blog&#x2F;gruens-outstanding-performanc...</a></div><br/></div></div></div></div><div id="40985705" class="c"><input type="checkbox" id="c-40985705" checked=""/><div class="controls bullet"><span class="by">Oras</span><span>|</span><a href="#40987200">prev</a><span>|</span><a href="#40989064">next</a><span>|</span><label class="collapse" for="c-40985705">[-]</label><label class="expand" for="c-40985705">[11 more]</label></div><br/><div class="children"><div class="content">Congratulations on launch.<p>This is a crowded market, and there are many tools doing the same thing.<p>How are you differentiating yourself from other tools like:<p>Langfuse 
Portkey
Keywords ai 
Promptfoo</div><br/><div id="40985857" class="c"><input type="checkbox" id="c-40985857" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40985705">parent</a><span>|</span><a href="#40987116">next</a><span>|</span><label class="collapse" for="c-40985857">[-]</label><label class="expand" for="c-40985857">[1 more]</label></div><br/><div class="children"><div class="content">Thanks!<p>We differentiate in 2 ways:<p>1. We focus on real-time monitoring. This is where we see the biggest pain with our customers, so we spent a lot of time researching and building the right metrics that can run at scale, fast and at low cost (and you can try them all in our platform).<p>2. OpenTelemetry - we think this is the best way to observe LLM app. It gives you a better understanding of how other parts of the system are interacting with your LLM. Say you&#x27;re calling a vector DB, or making an HTTP call - you get them all on the same trace. It&#x27;s also better for the customers - they&#x27;re not vendor locked to us and can easily switch to another platform (or even use them in parallel).</div><br/></div></div><div id="40987116" class="c"><input type="checkbox" id="c-40987116" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#40985705">parent</a><span>|</span><a href="#40985857">prev</a><span>|</span><a href="#40989064">next</a><span>|</span><label class="collapse" for="c-40987116">[-]</label><label class="expand" for="c-40987116">[9 more]</label></div><br/><div class="children"><div class="content">not to mention langsmith? braintrust? humanloop? does that count? not sure what else - lets crowdsource a list here so that people can find them in future</div><br/><div id="40987794" class="c"><input type="checkbox" id="c-40987794" checked=""/><div class="controls bullet"><span class="by">R21M1214</span><span>|</span><a href="#40985705">root</a><span>|</span><a href="#40987116">parent</a><span>|</span><a href="#40987269">next</a><span>|</span><label class="collapse" for="c-40987794">[-]</label><label class="expand" for="c-40987794">[4 more]</label></div><br/><div class="children"><div class="content">Im not sure which ones are Otel compliant. Im only aware of 3 that are Otel compliant:<p>1. Traceloop Otel
2. Langtrace.ai Otel
3. OpenLIT Otel
4. Portkey
5. Langfuse
6. Arize LLM
7. Phoniex SDK
8. Truera LLM
9. Truelens
10. Context
11. Braintrust
12. Parea
13. Context AI
14. openlayer.com
15. Deepchecks
16. langsmith
17. Confident AI
18. Helicone
19. Langwatch.ai
20. Arthur
21. Aporia
22. scale.com
23. Whylabs
24. gentrace.ai
25. humanloop.com
26. fixpoint.co
27. W n B Traces
28. Langtail
29. Fiddler
30. Evidently Ai
31. Superwise
32. Exxa
33. Honeyhive
34. Flowstack
35. Log10
36. Giskard
37. Raga AI
38. AgentOps
39. Patronus AI
40. Mona
41. Bricks Ai
42. Sentify
43. LogSpend
44. Nebuly
45. Autoblocks
46. Radar &#x2F; Langcheck
47. Dokulabs
48. Missing studio
49. Lunary.ai
50. Censius.ai
51. ML flow
52. Galileo
53. trubrics
54. Prompt Layer
55. Athina
56. getnomos.com
57. c3.ai
58. baselime.io
59. Honeycomb llm</div><br/><div id="40988087" class="c"><input type="checkbox" id="c-40988087" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#40985705">root</a><span>|</span><a href="#40987794">parent</a><span>|</span><a href="#40987269">next</a><span>|</span><label class="collapse" for="c-40988087">[-]</label><label class="expand" for="c-40988087">[3 more]</label></div><br/><div class="children"><div class="content">dear god, where is this list from? surely not hand curated?</div><br/><div id="40989273" class="c"><input type="checkbox" id="c-40989273" checked=""/><div class="controls bullet"><span class="by">mloncode</span><span>|</span><a href="#40985705">root</a><span>|</span><a href="#40988087">parent</a><span>|</span><a href="#40987269">next</a><span>|</span><label class="collapse" for="c-40989273">[-]</label><label class="expand" for="c-40989273">[2 more]</label></div><br/><div class="children"><div class="content">60. Radiant.AI
61.  Weights &amp; Biases (Weave)
62. Quotient AI (some observability there)</div><br/><div id="40991365" class="c"><input type="checkbox" id="c-40991365" checked=""/><div class="controls bullet"><span class="by">whoisdat</span><span>|</span><a href="#40985705">root</a><span>|</span><a href="#40989273">parent</a><span>|</span><a href="#40987269">next</a><span>|</span><label class="collapse" for="c-40991365">[-]</label><label class="expand" for="c-40991365">[1 more]</label></div><br/><div class="children"><div class="content">* 6. Arize LLM Otel (OpenInference)</div><br/></div></div></div></div></div></div></div></div><div id="40987269" class="c"><input type="checkbox" id="c-40987269" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40985705">root</a><span>|</span><a href="#40987116">parent</a><span>|</span><a href="#40987794">prev</a><span>|</span><a href="#40992409">next</a><span>|</span><label class="collapse" for="c-40987269">[-]</label><label class="expand" for="c-40987269">[3 more]</label></div><br/><div class="children"><div class="content">I have it internally, I can share it if you want!<p>But to the point of comparison between these and tools like Traceloop - it&#x27;s interesting to see this space and how each platform takes it&#x27;s own path and finds its own use cases.<p>LangSmith works well within the LangChain ecosystem together with LangGraph, LangServe. But if you&#x27;re using LlamaIndex, or even just vanilla OpenAI you&#x27;ll be spending hours to set up your observability systems.<p>Braintrust and Humanloop (and to some extend other tools I saw in this area) take the path of &quot;full development platform for LLMs&quot;.<p>We try to look at it as developers look at tools like Sentry. Continue working in your own IDE with your own tools (wanna manage your prompts in a DB or in git? Wanna use LLMs your own way with no frameworks? no problem). We install in your app, with one line and we work around your existing code base and make monitoring, evaluation and tracing work.</div><br/><div id="40987591" class="c"><input type="checkbox" id="c-40987591" checked=""/><div class="controls bullet"><span class="by">Lienetic</span><span>|</span><a href="#40985705">root</a><span>|</span><a href="#40987269">parent</a><span>|</span><a href="#40992409">next</a><span>|</span><label class="collapse" for="c-40987591">[-]</label><label class="expand" for="c-40987591">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to see that list!</div><br/><div id="40987622" class="c"><input type="checkbox" id="c-40987622" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40985705">root</a><span>|</span><a href="#40987591">parent</a><span>|</span><a href="#40992409">next</a><span>|</span><label class="collapse" for="c-40987622">[-]</label><label class="expand" for="c-40987622">[1 more]</label></div><br/><div class="children"><div class="content">Ping me over slack (traceloop.com&#x2F;slack) or email nir at traceloop dot com</div><br/></div></div></div></div></div></div><div id="40992409" class="c"><input type="checkbox" id="c-40992409" checked=""/><div class="controls bullet"><span class="by">sid-grayscale</span><span>|</span><a href="#40985705">root</a><span>|</span><a href="#40987116">parent</a><span>|</span><a href="#40987269">prev</a><span>|</span><a href="#40989064">next</a><span>|</span><label class="collapse" for="c-40992409">[-]</label><label class="expand" for="c-40992409">[1 more]</label></div><br/><div class="children"><div class="content">I started an open list (on github) of awesome open source repos for AI Engineers. It covers repos that help with building RAG apps, Agents, Dataset preparation, Fine tuning, Evaluation, Observability etc. Good to crowdsource these repos and products. <a href="https:&#x2F;&#x2F;github.com&#x2F;sydverma123&#x2F;awesome-ai-repositories">https:&#x2F;&#x2F;github.com&#x2F;sydverma123&#x2F;awesome-ai-repositories</a></div><br/></div></div></div></div></div></div><div id="40989064" class="c"><input type="checkbox" id="c-40989064" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#40985705">prev</a><span>|</span><a href="#40991743">next</a><span>|</span><label class="collapse" for="c-40989064">[-]</label><label class="expand" for="c-40989064">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Know when your LLM app is hallucinating or malfunctioning<p>It astonishes me that you are willing to make so many deceptive claims on your website like this.<p>You have no ability to detect with any certainty hallucinations. No one in the industry does.</div><br/><div id="40989197" class="c"><input type="checkbox" id="c-40989197" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40989064">parent</a><span>|</span><a href="#40989097">next</a><span>|</span><label class="collapse" for="c-40989197">[-]</label><label class="expand" for="c-40989197">[1 more]</label></div><br/><div class="children"><div class="content">I think it depends on the use case and how you define hallucinations. We&#x27;ve seen our metrics perform well (=correlates with human feedback) for use cases like summarization, RAG question-answering pipeline, and entity extraction.<p>At the end of the day things like &quot;answer relevancy&quot; are pretty dichotomic in a sense that for a human evaluator it will be pretty clear whether an answer is answering a question or not.<p>I wonder if you can elaborate on why you claim that there&#x27;s no ability to detect with any certainty hallucinations.</div><br/></div></div><div id="40989097" class="c"><input type="checkbox" id="c-40989097" checked=""/><div class="controls bullet"><span class="by">xyst</span><span>|</span><a href="#40989064">parent</a><span>|</span><a href="#40989197">prev</a><span>|</span><a href="#40991743">next</a><span>|</span><label class="collapse" for="c-40989097">[-]</label><label class="expand" for="c-40989097">[3 more]</label></div><br/><div class="children"><div class="content">clearly LLM app has added such logic to their app:<p>```
if (query.IsHallucinated()) { notifyHumanOfHallucination(); }
```<p>this one line will get them that unicorn eval</div><br/><div id="40989217" class="c"><input type="checkbox" id="c-40989217" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40989064">root</a><span>|</span><a href="#40989097">parent</a><span>|</span><a href="#40991743">next</a><span>|</span><label class="collapse" for="c-40989217">[-]</label><label class="expand" for="c-40989217">[2 more]</label></div><br/><div class="children"><div class="content">I think that LLMs are hallucinating by design. I&#x27;m not sure we&#x27;ll ever get to a 0% hallucinations and we should be ok with it (at least for the next coming years?). So getting an alert on hallucination becomes less interesting. What is more interesting perhaps is knowing the rate that this happens. And keeping track on whether this rate increases or decreases with time or with changes to models.</div><br/></div></div></div></div></div></div><div id="40991743" class="c"><input type="checkbox" id="c-40991743" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40989064">prev</a><span>|</span><a href="#40991184">next</a><span>|</span><label class="collapse" for="c-40991743">[-]</label><label class="expand" for="c-40991743">[3 more]</label></div><br/><div class="children"><div class="content">As users of otel, we are looking at reusing otel for our LLM stack, and as it is easy to instrument, don&#x27;t need a new framework for that part.<p>However, the more interesting part is the storage: Imagine ingesting 100pg PDFs or 1M tweets, and doing many&#x2F;big LLM map&#x2F;reduce with big (128K+) context. In observability land, we generally have small payloads, sample data, and retire data... and backends + pricing assumes that. In LLMs, we instead might want some hot, rest in the DWH, and store everything.<p>How have folks been dealing with these kind of mismatches? Eg, Clickhouse backends for otel? Something else? Small stuff in otel and big stuff manually in a doc store &#x2F; s3 json &#x2F; parquet?</div><br/><div id="40992871" class="c"><input type="checkbox" id="c-40992871" checked=""/><div class="controls bullet"><span class="by">roh26it</span><span>|</span><a href="#40991743">parent</a><span>|</span><a href="#40993030">next</a><span>|</span><label class="collapse" for="c-40992871">[-]</label><label class="expand" for="c-40992871">[1 more]</label></div><br/><div class="children"><div class="content">At Portkey, this is a problem we deal with quite a bit. Also the reason that Datadog and the traditional observability vendors did not work for LLM use cases since they&#x27;re not built to handle large volumes of data.<p>We&#x27;ve done this through a careful combination of Clickhouse + MinIO for fast retrieval of log items + selected retrieval from the MinIO buckets.<p>Cost becomes a very big factor when managing, filtering and searching through TBs of data even for fairly small use cases.<p>One thing we lost in the process is full-text search over the request &amp; response pairs and while we try to intelligently add metadata to requests to make searching easier, it isn&#x27;t the complete experience yet. Still WIP as a problem statement to solve and maybe the last straw here. Any suggestions?</div><br/></div></div><div id="40993030" class="c"><input type="checkbox" id="c-40993030" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40991743">parent</a><span>|</span><a href="#40992871">prev</a><span>|</span><a href="#40991184">next</a><span>|</span><label class="collapse" for="c-40993030">[-]</label><label class="expand" for="c-40993030">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right. We faced those same issues. So we plan to move those prompts and completions to be sent as log events with some reference to the trace&#x2F;span and not actually on the span.<p>The span can then only contain the most important data like the prompt template, model that was used, token usage, etc. You can then split the metadata (spans and traces) and the large payloads (prompts + completions) to different data stores.</div><br/></div></div></div></div><div id="40991184" class="c"><input type="checkbox" id="c-40991184" checked=""/><div class="controls bullet"><span class="by">navaed01</span><span>|</span><a href="#40991743">prev</a><span>|</span><a href="#40988854">next</a><span>|</span><label class="collapse" for="c-40991184">[-]</label><label class="expand" for="c-40991184">[2 more]</label></div><br/><div class="children"><div class="content">Thank you for spending your time on something that is a barrier to AI adoption.<p>Can you talk about your detection rates? False positives and false negatives. Perhaps you are still figuring this out<p>I’m not sure why so many folks are being so derisive on this post.</div><br/><div id="40993081" class="c"><input type="checkbox" id="c-40993081" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40991184">parent</a><span>|</span><a href="#40988854">next</a><span>|</span><label class="collapse" for="c-40993081">[-]</label><label class="expand" for="c-40993081">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! It can vary greatly between use cases - but we&#x27;ve seen extremely high detection rates for tagged texts (&gt;95%). When switching to production, this gets trickier since you don&#x27;t know what you don&#x27;t know (so it&#x27;s hard to tell how many &quot;bad examples&quot; we&#x27;re missing). Our false positive rate (number of examples that were tagged as bad but weren&#x27;t) has been around 2-3% out of the overall examples tagged as bad (positive) and we always work on decreasing this.</div><br/></div></div></div></div><div id="40988854" class="c"><input type="checkbox" id="c-40988854" checked=""/><div class="controls bullet"><span class="by">kcorbitt</span><span>|</span><a href="#40991184">prev</a><span>|</span><a href="#40987049">next</a><span>|</span><label class="collapse" for="c-40988854">[-]</label><label class="expand" for="c-40988854">[1 more]</label></div><br/><div class="children"><div class="content">Big congrats on the official launch!<p>Slightly tooting my own horn here, but at OpenPipe we&#x27;ve got a collaboration set up with Traceloop. That means you can record your production traces in Traceloop then export them to OpenPipe where you can filter&#x2F;enrich them and use them to fine-tune a super strong model. :)</div><br/></div></div><div id="40987049" class="c"><input type="checkbox" id="c-40987049" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#40988854">prev</a><span>|</span><a href="#40990482">next</a><span>|</span><label class="collapse" for="c-40987049">[-]</label><label class="expand" for="c-40987049">[5 more]</label></div><br/><div class="children"><div class="content">congrats on launch!<p>the thing about OTel is that it is by nature vendor agnostic. so if i use OpenLLMetry, i should be able to pipe my otel traces to whatever existing o11y tool I use right? what is the benefit of a dedicated monitoring platform?<p>(not cynical, just inviting you to explain more)</div><br/><div id="40987213" class="c"><input type="checkbox" id="c-40987213" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40987049">parent</a><span>|</span><a href="#40987106">next</a><span>|</span><label class="collapse" for="c-40987213">[-]</label><label class="expand" for="c-40987213">[1 more]</label></div><br/><div class="children"><div class="content">Great question and I see you already got a similar answer but I&#x27;ll add some of my thoughts on this. 
We are actively promoting OpenLLMetry as a vendor agnostic way of observing LLMs (see some examples [1], [2]). We believe that people may start with whatever vendor they work with today and may gradually shift or use something like Traceloop because of specific features we have - for example the ability to take the raw data that we output with OpenLLMetry and add another layer of &quot;smart metrics&quot; (like qa relevancy, faithfulness, etc.) that we calculate on our backend &#x2F; pipelines; or better tooling around observability of LLM calls, agents, etc.<p>[1] <a href="https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;opentelemetry&#x2F;get-started&#x2F;traceloop-llm-observability&#x2F;traceloop-llm-observability-intro&#x2F;" rel="nofollow">https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;opentelemetry&#x2F;get-started&#x2F;tra...</a><p>[2] <a href="https:&#x2F;&#x2F;docs.dynatrace.com&#x2F;docs&#x2F;observe-and-explore&#x2F;dynatrace-for-ai-observability&#x2F;traceloop-openllmetry" rel="nofollow">https:&#x2F;&#x2F;docs.dynatrace.com&#x2F;docs&#x2F;observe-and-explore&#x2F;dynatrac...</a></div><br/></div></div><div id="40987106" class="c"><input type="checkbox" id="c-40987106" checked=""/><div class="controls bullet"><span class="by">resiros</span><span>|</span><a href="#40987049">parent</a><span>|</span><a href="#40987213">prev</a><span>|</span><a href="#40990482">next</a><span>|</span><label class="collapse" for="c-40987106">[-]</label><label class="expand" for="c-40987106">[3 more]</label></div><br/><div class="children"><div class="content">Not OP here (but building in the same space). 
The reason you instrument LLM data is usually to improve quality&#x2F;speed of your applications. The tools to extract the insights to enable that, and the integration with your LLM experimentation workflow is the differentiator between a general observability solution and LLM specific one.</div><br/><div id="40987127" class="c"><input type="checkbox" id="c-40987127" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#40987049">root</a><span>|</span><a href="#40987106">parent</a><span>|</span><a href="#40990482">next</a><span>|</span><label class="collapse" for="c-40987127">[-]</label><label class="expand" for="c-40987127">[2 more]</label></div><br/><div class="children"><div class="content">oh cool. do you also consume OTel? or something else?</div><br/><div id="40987171" class="c"><input type="checkbox" id="c-40987171" checked=""/><div class="controls bullet"><span class="by">resiros</span><span>|</span><a href="#40987049">root</a><span>|</span><a href="#40987127">parent</a><span>|</span><a href="#40990482">next</a><span>|</span><label class="collapse" for="c-40987171">[-]</label><label class="expand" for="c-40987171">[1 more]</label></div><br/><div class="children"><div class="content">Right now we have our own instrumentation but we&#x27;re working towards Otel compatibility.</div><br/></div></div></div></div></div></div></div></div><div id="40990482" class="c"><input type="checkbox" id="c-40990482" checked=""/><div class="controls bullet"><span class="by">nonameiguess</span><span>|</span><a href="#40987049">prev</a><span>|</span><a href="#40988123">next</a><span>|</span><label class="collapse" for="c-40990482">[-]</label><label class="expand" for="c-40990482">[3 more]</label></div><br/><div class="children"><div class="content">This is poorly worded. Detecting &quot;hallucinations&quot; as the term is commonly used, as in a model making up answers not actually in its source text, or answers that are generally untrue, is fundamentally impossible. Verifying the truth of a statement requires empirical investigation. It isn&#x27;t a feature of language itself. This is just the basic analytic&#x2F;synthetic distinction identified by Kant centuries ago. It&#x27;s why we have science in the first place and don&#x27;t generate new knowledge by reading and learning to make convincing sounding arguments.<p>Your far more scaled-down claim, however, that you can detect answers that don&#x27;t address a prompt at all, or make claims when summarizing known other text that isn&#x27;t actually in the original text, is definitely doable, but raises a maybe naive or stupid question. If you can do this, why not sell an LLM that simply doesn&#x27;t do these stupid things in the first place? Or why do the people currently selling LLMs not just automatically detect obvious errors and not make them? Doesn&#x27;t your business as constituted depend upon LLM vendors never figuring out how to do this themselves?</div><br/><div id="40992838" class="c"><input type="checkbox" id="c-40992838" checked=""/><div class="controls bullet"><span class="by">altdataseller</span><span>|</span><a href="#40990482">parent</a><span>|</span><a href="#40993330">next</a><span>|</span><label class="collapse" for="c-40992838">[-]</label><label class="expand" for="c-40992838">[1 more]</label></div><br/><div class="children"><div class="content">And whats the false positive rate? Its good and dandy that you find most answers that are hallucinations but do you flag a significant % of answers that are not really hallucinations too? For instance, if a summarization doesnt use any sentences or even words from the original text, that doesnt necessarily mean its a hallucination. It could simply be a full paraphrased summary</div><br/></div></div><div id="40993330" class="c"><input type="checkbox" id="c-40993330" checked=""/><div class="controls bullet"><span class="by">autonomousErwin</span><span>|</span><a href="#40990482">parent</a><span>|</span><a href="#40992838">prev</a><span>|</span><a href="#40988123">next</a><span>|</span><label class="collapse" for="c-40993330">[-]</label><label class="expand" for="c-40993330">[1 more]</label></div><br/><div class="children"><div class="content">Could you not detect likely hallucinations by running the same prompt multiple times between different models and looking at the vector divergence between the outputs? Kind of like an agreement between say GPT, Llama, other models which all agree - yes, this is likely a hallucination.<p>It&#x27;s not 100% but enough to basically say to the human: &quot;hey, look at this&quot;.</div><br/></div></div></div></div><div id="40988123" class="c"><input type="checkbox" id="c-40988123" checked=""/><div class="controls bullet"><span class="by">bionhoward</span><span>|</span><a href="#40990482">prev</a><span>|</span><a href="#40988895">next</a><span>|</span><label class="collapse" for="c-40988123">[-]</label><label class="expand" for="c-40988123">[2 more]</label></div><br/><div class="children"><div class="content">Check out these Wikipedia articles:<p>Confabulation
<a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Confabulation" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Confabulation</a><p>Hallucination
<a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Hallucination" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Hallucination</a><p>What drove the AI industry to blow off accepted naming from psychopathology and use the word for PERCEPTUAL errors to refer to LANGUAGE OUTPUT errors?<p>When AI hallucinates, and AI people already use the preferred term “hallucination” to label confabulations, then what’s the new word for “hallucinations?”<p>How will we avoid serious errors in understanding if hallucination in AI means confabulation in humans and $NEW_TERM in AI means hallucination in humans?<p>Just seems harmful to gloss over this humongous vocabulary error.<p>How can we claim to respect the difficulty of naming things if we all select the wrong answer to a basic undergrad psychology multiple choice question with only two options?<p>It feels like painting ourselves into a corner which will inevitably make computer scientists look dumb. Who here wants to look dumb for no reason?<p>I don’t want to be negative, but is using the blatantly wrong word for confabulation a good idea in the long term?</div><br/><div id="40990067" class="c"><input type="checkbox" id="c-40990067" checked=""/><div class="controls bullet"><span class="by">cmcconomy</span><span>|</span><a href="#40988123">parent</a><span>|</span><a href="#40988895">next</a><span>|</span><label class="collapse" for="c-40990067">[-]</label><label class="expand" for="c-40990067">[1 more]</label></div><br/><div class="children"><div class="content">if i may theorize: one of these two terms is generally recognised by the broader english speaking community</div><br/></div></div></div></div><div id="40988895" class="c"><input type="checkbox" id="c-40988895" checked=""/><div class="controls bullet"><span class="by">remram</span><span>|</span><a href="#40988123">prev</a><span>|</span><a href="#40989609">next</a><span>|</span><label class="collapse" for="c-40988895">[-]</label><label class="expand" for="c-40988895">[9 more]</label></div><br/><div class="children"><div class="content">Acknowledging that AI is unreliable, the solution is to layer another AI to hopefully let you know about it. Of course, brilliant, why did I expect anything different from the AI industry.</div><br/><div id="40989117" class="c"><input type="checkbox" id="c-40989117" checked=""/><div class="controls bullet"><span class="by">xyst</span><span>|</span><a href="#40988895">parent</a><span>|</span><a href="#40989223">next</a><span>|</span><label class="collapse" for="c-40989117">[-]</label><label class="expand" for="c-40989117">[7 more]</label></div><br/><div class="children"><div class="content">?? but who is monitoring the AI layer monitoring the AI who produced the original output ??<p>openai audited by claudeai which is then audited by gemini ai...<p>then to close the loop, gemini ai is then audited by openai</div><br/><div id="40989627" class="c"><input type="checkbox" id="c-40989627" checked=""/><div class="controls bullet"><span class="by">its_ethan</span><span>|</span><a href="#40988895">root</a><span>|</span><a href="#40989117">parent</a><span>|</span><a href="#40989140">next</a><span>|</span><label class="collapse" for="c-40989627">[-]</label><label class="expand" for="c-40989627">[5 more]</label></div><br/><div class="children"><div class="content">I had read the OP&#x27;s comment as sarcastic, but you never know these days lol<p>Your concern would be exactly mine as well, and why I assumed &quot;brilliant&quot; was sarcasm, cause it <i>feels like</i> handing over the problem to the same solution that got you the problem in the first place?</div><br/><div id="40989693" class="c"><input type="checkbox" id="c-40989693" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40988895">root</a><span>|</span><a href="#40989627">parent</a><span>|</span><a href="#40991784">next</a><span>|</span><label class="collapse" for="c-40989693">[-]</label><label class="expand" for="c-40989693">[3 more]</label></div><br/><div class="children"><div class="content">It has the same logic of saying you dont want to use a computer to monitor or test your code since it will mean that a computer will monitor a computer. AI is a broad term, I agree you can use GPT (or any LLM) to grade an LLM in an accurate way but that’s not the only way you can monitor.</div><br/><div id="40990029" class="c"><input type="checkbox" id="c-40990029" checked=""/><div class="controls bullet"><span class="by">its_ethan</span><span>|</span><a href="#40988895">root</a><span>|</span><a href="#40989693">parent</a><span>|</span><a href="#40991784">next</a><span>|</span><label class="collapse" for="c-40990029">[-]</label><label class="expand" for="c-40990029">[2 more]</label></div><br/><div class="children"><div class="content">&gt; computer to monitor or test your code since it will mean that a computer will monitor a computer<p>I mean... you don&#x27;t trust the computer in that case, you trust the <i>person</i> who wrote the test code. Computers do what they&#x27;re told to do, so there&#x27;s no trust required of the computer itself. If you swap out the person (that you&#x27;re trusting) writing that code with an AI writing that test code, then it&#x27;s closer to your analogy - and in that case, I (and the guy above me, it seems) wouldn&#x27;t trust for anything impactful.<p>Even if you&#x27;re not using an LLM specifically (which no one in this chain even said you were), an AI built off some training set to eliminate hallucinations is still just an AI. So you&#x27;re still using an AI to keep an AI in check, which begs the question (posed above) of: what keeps your AI in check?<p>Poking fun at a chain of AI&#x27;s all keeping each other in check isn&#x27;t really a dig at you or your company. It&#x27;s more of a comment on the current industry moment.<p>Best of luck to you in your endeavor anyway, by the way!</div><br/><div id="40990095" class="c"><input type="checkbox" id="c-40990095" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40988895">root</a><span>|</span><a href="#40990029">parent</a><span>|</span><a href="#40991784">next</a><span>|</span><label class="collapse" for="c-40990095">[-]</label><label class="expand" for="c-40990095">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! I wasn’t offended or anything, don’t get the wrong impression.<p>What strikes me odd is the fact that an AI that checks AI is an issue. Because AI can mean a lot of things - from a encoder architecture, a neural network, or a simple regression function. And at the end of the day, similar to what you said - there was a human building and fine tuning that AI.<p>Anyway, this feels more of a philosophical question than an engineering one.</div><br/></div></div></div></div></div></div><div id="40991784" class="c"><input type="checkbox" id="c-40991784" checked=""/><div class="controls bullet"><span class="by">remram</span><span>|</span><a href="#40988895">root</a><span>|</span><a href="#40989627">parent</a><span>|</span><a href="#40989693">prev</a><span>|</span><a href="#40989140">next</a><span>|</span><label class="collapse" for="c-40991784">[-]</label><label class="expand" for="c-40991784">[1 more]</label></div><br/><div class="children"><div class="content">(it was sarcastic. Too late to edit in a &#x2F;s)</div><br/></div></div></div></div><div id="40989140" class="c"><input type="checkbox" id="c-40989140" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#40988895">root</a><span>|</span><a href="#40989117">parent</a><span>|</span><a href="#40989627">prev</a><span>|</span><a href="#40989223">next</a><span>|</span><label class="collapse" for="c-40989140">[-]</label><label class="expand" for="c-40989140">[1 more]</label></div><br/><div class="children"><div class="content">people are lazy, we&#x27;re more than happy to not be in the loop</div><br/></div></div></div></div><div id="40989223" class="c"><input type="checkbox" id="c-40989223" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40988895">parent</a><span>|</span><a href="#40989117">prev</a><span>|</span><a href="#40989609">next</a><span>|</span><label class="collapse" for="c-40989223">[-]</label><label class="expand" for="c-40989223">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sorry but this is not what we do. We don&#x27;t use LLMs to grade your LLM calls.</div><br/></div></div></div></div><div id="40989609" class="c"><input type="checkbox" id="c-40989609" checked=""/><div class="controls bullet"><span class="by">phillipcarter</span><span>|</span><a href="#40988895">prev</a><span>|</span><a href="#40991724">next</a><span>|</span><label class="collapse" for="c-40989609">[-]</label><label class="expand" for="c-40989609">[1 more]</label></div><br/><div class="children"><div class="content">Congrats on the official launch, Nir and Gal! Deeply appreciate your contributions to OTel as well.</div><br/></div></div><div id="40991724" class="c"><input type="checkbox" id="c-40991724" checked=""/><div class="controls bullet"><span class="by">believ3</span><span>|</span><a href="#40989609">prev</a><span>|</span><a href="#40987070">next</a><span>|</span><label class="collapse" for="c-40991724">[-]</label><label class="expand" for="c-40991724">[2 more]</label></div><br/><div class="children"><div class="content">&quot;accross&quot; is misspelled on your front page</div><br/><div id="40991731" class="c"><input type="checkbox" id="c-40991731" checked=""/><div class="controls bullet"><span class="by">believ3</span><span>|</span><a href="#40991724">parent</a><span>|</span><a href="#40987070">next</a><span>|</span><label class="collapse" for="c-40991731">[-]</label><label class="expand" for="c-40991731">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Support Respons&quot; is also misspelled in your product screenshot</div><br/></div></div></div></div><div id="40987070" class="c"><input type="checkbox" id="c-40987070" checked=""/><div class="controls bullet"><span class="by">BeautifulOrb</span><span>|</span><a href="#40991724">prev</a><span>|</span><label class="collapse" for="c-40987070">[-]</label><label class="expand" for="c-40987070">[4 more]</label></div><br/><div class="children"><div class="content">there&#x27;s a well known artist named traceloops who has a prolific&#x2F;longstanding body of work. why did you choose this name?</div><br/><div id="40987286" class="c"><input type="checkbox" id="c-40987286" checked=""/><div class="controls bullet"><span class="by">nirga</span><span>|</span><a href="#40987070">parent</a><span>|</span><a href="#40988507">next</a><span>|</span><label class="collapse" for="c-40987286">[-]</label><label class="expand" for="c-40987286">[2 more]</label></div><br/><div class="children"><div class="content">I know! When we started every time I was googling &quot;traceloop&quot; this was the first result.<p>2 reasons why we chose it (in this order):<p>1. traceloop.com was available<p>2. we work with traces</div><br/><div id="40988496" class="c"><input type="checkbox" id="c-40988496" checked=""/><div class="controls bullet"><span class="by">Hansenq</span><span>|</span><a href="#40987070">root</a><span>|</span><a href="#40987286">parent</a><span>|</span><a href="#40988507">next</a><span>|</span><label class="collapse" for="c-40988496">[-]</label><label class="expand" for="c-40988496">[1 more]</label></div><br/><div class="children"><div class="content">an available .com is basically the only reason you should use <a href="https:&#x2F;&#x2F;paulgraham.com&#x2F;name.html" rel="nofollow">https:&#x2F;&#x2F;paulgraham.com&#x2F;name.html</a></div><br/></div></div></div></div><div id="40988507" class="c"><input type="checkbox" id="c-40988507" checked=""/><div class="controls bullet"><span class="by">aaronvg</span><span>|</span><a href="#40987070">parent</a><span>|</span><a href="#40987286">prev</a><span>|</span><label class="collapse" for="c-40988507">[-]</label><label class="expand" for="c-40988507">[1 more]</label></div><br/><div class="children"><div class="content">I doubt anyone would be confused with Traceloops the artist vs Traceloop the LLM Observability Platform</div><br/></div></div></div></div></div></div></div></div></div></body></html>