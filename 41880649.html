<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1729501267894" as="style"/><link rel="stylesheet" href="styles.css?v=1729501267894"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/">US probes Tesla&#x27;s Full Self-Driving software after fatal crash</a> <span class="domain">(<a href="https://www.reuters.com">www.reuters.com</a>)</span></div><div class="subtext"><span>jjulius</span> | <span>820 comments</span></div><br/><div><div id="41892630" class="c"><input type="checkbox" id="c-41892630" checked=""/><div class="controls bullet"><span class="by">rootusrootus</span><span>|</span><a href="#41895565">next</a><span>|</span><label class="collapse" for="c-41892630">[-]</label><label class="expand" for="c-41892630">[46 more]</label></div><br/><div class="children"><div class="content">I&#x27;m on my second free FSD trial, just started for me today.  Gave it another shot, and it seems largely similar to the last free trial they gave.  Fun party trick, surprisingly good, right up until it&#x27;s not.  A hallmark of AI everywhere, is how great it is and just how abruptly and catastrophically it fails occasionally.<p>Please, if you&#x27;re going to try it, keep both hands on the wheel and your foot ready for the brake.  When it goes off the rails, it usually does so in surprising ways with little warning and little time to correct.  And since it&#x27;s so good much of the time, you can get lulled into complacence.<p>I never really understand the comments from people who think it&#x27;s the greatest thing ever and makes their drive less stressful.  Does the opposite for me.  Entertaining but exhausting to supervise.</div><br/><div id="41896317" class="c"><input type="checkbox" id="c-41896317" checked=""/><div class="controls bullet"><span class="by">tverbeure</span><span>|</span><a href="#41892630">parent</a><span>|</span><a href="#41894715">next</a><span>|</span><label class="collapse" for="c-41896317">[-]</label><label class="expand" for="c-41896317">[15 more]</label></div><br/><div class="children"><div class="content">I just gave it another try after my last failed attempt. (<a href="https:&#x2F;&#x2F;tomverbeure.github.io&#x2F;2024&#x2F;05&#x2F;20&#x2F;Tesla-FSD-First-and-Last-Impressions.html" rel="nofollow">https:&#x2F;&#x2F;tomverbeure.github.io&#x2F;2024&#x2F;05&#x2F;20&#x2F;Tesla-FSD-First-and...</a>)<p>I still find it shockingly bad, especially in the way it reacts, or doesn’t, to the way things change around the car (think a car on the left in front of you who switches on indicators to merge in front of you) or the way it makes the most random lane changing decisions and changes it’s mind in the middle of that maneuver.<p>Those don’t count as disengagements, but they’re jarring and drivers around you will rightfully question your behavior.<p>And that’s all over just a few miles of driving in an easy environment if interstate or highway.<p>I totally agree that it’s an impressive party trick, but it has no business being on the road.<p>My experience with Waymo in SF couldn’t have been more different.</div><br/><div id="41896795" class="c"><input type="checkbox" id="c-41896795" checked=""/><div class="controls bullet"><span class="by">y-c-o-m-b</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896317">parent</a><span>|</span><a href="#41901241">next</a><span>|</span><label class="collapse" for="c-41896795">[-]</label><label class="expand" for="c-41896795">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it makes the most random lane changing decisions and changes it’s mind in the middle of that maneuver.<p>This happened to me during my first month of trialing FSD last year and was a big contributing factor for me not subscribing. I did NOT appreciate the mess the vehicle made in this type of situation. If I saw another driver doing the same, I&#x27;d seriously question if they were intoxicated.</div><br/></div></div><div id="41901241" class="c"><input type="checkbox" id="c-41901241" checked=""/><div class="controls bullet"><span class="by">avar</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896317">parent</a><span>|</span><a href="#41896795">prev</a><span>|</span><a href="#41896758">next</a><span>|</span><label class="collapse" for="c-41901241">[-]</label><label class="expand" for="c-41901241">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s an interesting trope among Tesla owners to feel the need to put a disclaimer like this in (quoting your post):<p><pre><code>    &gt; &quot;I’ve had a Model Y for more
    &gt; than 3 years now, well before
    &gt; Elon revealed himself as
    &gt; the kind of person he really is&quot;
</code></pre>
It&#x27;s always fun to compare the timeline of Elon Musk&#x27;s well-known shenanigans with the &quot;But I got a Tesla in &lt;year&gt;!&quot;.<p>E.g. you got one around 3 years after the &quot;pedo guy&quot; incident[1].<p>I suppose to whatever extent you factor in the personalities of the executives whose companies you make car purchases from, that didn&#x27;t rate as much of a factor?<p>One is left wondering what it was that did.<p>1. <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tham_Luang_cave_rescue#Elon_Musk" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tham_Luang_cave_rescue#Elon_Mu...</a></div><br/></div></div><div id="41896758" class="c"><input type="checkbox" id="c-41896758" checked=""/><div class="controls bullet"><span class="by">sokoloff</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896317">parent</a><span>|</span><a href="#41901241">prev</a><span>|</span><a href="#41894715">next</a><span>|</span><label class="collapse" for="c-41896758">[-]</label><label class="expand" for="c-41896758">[12 more]</label></div><br/><div class="children"><div class="content">&gt; (think a car on the left in front of you who switches on indicators to merge in front of you)<p>That car is signaling an intention to merge into your lane <i>once it is safe for them to do so</i>. What does the Tesla do (or not do) in this case that&#x27;s bad?</div><br/><div id="41900474" class="c"><input type="checkbox" id="c-41900474" checked=""/><div class="controls bullet"><span class="by">tverbeure</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896758">parent</a><span>|</span><a href="#41896861">next</a><span>|</span><label class="collapse" for="c-41900474">[-]</label><label class="expand" for="c-41900474">[1 more]</label></div><br/><div class="children"><div class="content">What I expect it to do is to be a courteous driver, and back off a little bit to signal to the car in front that I got the message and that it&#x27;s safe to merge.<p>FSD is already defensive to a fault, with frequent stop-and-go indecisions of when to merge onto a highway, but that&#x27;s a whole other story.<p>A major part of safe driving is about being predictable. You either commit and claim your right of way, or you don&#x27;t. In this situation, both can be signaled easily to the other party by being a bit of a jerk (e.g. accelerating to close the gap and prevent somebody else from merging) or the opposite. Both are better than not doing anything at all and keeping the other dangling in a state of uncertainty.<p>FSD is in an almost permanent state of being indecisive and unpredictable. It behaves like a scared teenager with a learner&#x27;s permit. Again, totally different than my experience in Waymo in the urban jungle of San Francisco, who&#x27;s a defensive but confident driver.</div><br/></div></div><div id="41896861" class="c"><input type="checkbox" id="c-41896861" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896758">parent</a><span>|</span><a href="#41900474">prev</a><span>|</span><a href="#41897374">next</a><span>|</span><label class="collapse" for="c-41896861">[-]</label><label class="expand" for="c-41896861">[2 more]</label></div><br/><div class="children"><div class="content">Defensive driving is to assume they might not check their blindspot, etc. And just generally ease off in this situation if they would merge in tight if they began merging now.</div><br/><div id="41898363" class="c"><input type="checkbox" id="c-41898363" checked=""/><div class="controls bullet"><span class="by">tverbeure</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896861">parent</a><span>|</span><a href="#41897374">next</a><span>|</span><label class="collapse" for="c-41898363">[-]</label><label class="expand" for="c-41898363">[1 more]</label></div><br/><div class="children"><div class="content">That’s the issue: I would immediately slow a little bit to let the other one merge. FSD seems to be noticing something, and eventually slow down, but the action is too subtle (if at all) to signal the other guy that you’re letting them merge.</div><br/></div></div></div></div><div id="41897374" class="c"><input type="checkbox" id="c-41897374" checked=""/><div class="controls bullet"><span class="by">hotspot_one</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896758">parent</a><span>|</span><a href="#41896861">prev</a><span>|</span><a href="#41894715">next</a><span>|</span><label class="collapse" for="c-41897374">[-]</label><label class="expand" for="c-41897374">[8 more]</label></div><br/><div class="children"><div class="content">&gt; That car is signaling an intention to merge into your lane once it is safe for them to do so.<p>Only under the assumption that the driver was trained in the US, to follow US traffic law, and is following that training.<p>For example, in the EU, you switch on the indicators when you start the merge; the indicator shows that you ARE moving.</div><br/><div id="41897546" class="c"><input type="checkbox" id="c-41897546" checked=""/><div class="controls bullet"><span class="by">sokoloff</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41897374">parent</a><span>|</span><a href="#41898177">next</a><span>|</span><label class="collapse" for="c-41897546">[-]</label><label class="expand" for="c-41897546">[5 more]</label></div><br/><div class="children"><div class="content">That seems odd to the point of uselessness, and does not match the required training I received in Germany from my work colleagues at Daimler prior to being able to sign out company cars.<p><a href="https:&#x2F;&#x2F;www.gesetze-im-internet.de&#x2F;stvo_2013&#x2F;__9.html" rel="nofollow">https:&#x2F;&#x2F;www.gesetze-im-internet.de&#x2F;stvo_2013&#x2F;__9.html</a> seems to be the relevant law in Germany, which Google translates to &quot;(1) Anyone wishing to turn must announce this clearly and in good time; direction indicators must be used.&quot;</div><br/><div id="41897705" class="c"><input type="checkbox" id="c-41897705" checked=""/><div class="controls bullet"><span class="by">nielsole</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41897546">parent</a><span>|</span><a href="#41899319">next</a><span>|</span><label class="collapse" for="c-41897705">[-]</label><label class="expand" for="c-41897705">[1 more]</label></div><br/><div class="children"><div class="content">Merging into the lane is probably better addressed by §7, with the same content: <a href="https:&#x2F;&#x2F;dejure.org&#x2F;gesetze&#x2F;StVO&#x2F;7.html" rel="nofollow">https:&#x2F;&#x2F;dejure.org&#x2F;gesetze&#x2F;StVO&#x2F;7.html</a></div><br/></div></div><div id="41899319" class="c"><input type="checkbox" id="c-41899319" checked=""/><div class="controls bullet"><span class="by">throw4950sh06</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41897546">parent</a><span>|</span><a href="#41897705">prev</a><span>|</span><a href="#41898177">next</a><span>|</span><label class="collapse" for="c-41899319">[-]</label><label class="expand" for="c-41899319">[3 more]</label></div><br/><div class="children"><div class="content">Maybe the guy was talking about the reality, not the theory. From my autobahn travels it seems like the Germans don&#x27;t know how to turn on the blinkers.</div><br/><div id="41899776" class="c"><input type="checkbox" id="c-41899776" checked=""/><div class="controls bullet"><span class="by">xattt</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41899319">parent</a><span>|</span><a href="#41898177">next</a><span>|</span><label class="collapse" for="c-41899776">[-]</label><label class="expand" for="c-41899776">[2 more]</label></div><br/><div class="children"><div class="content">&gt; … the Germans don’t know how turn on the blinkers.<p>[Insert nationality&#x2F;regional area here] don’t know how to turn on the blinkers.</div><br/><div id="41901455" class="c"><input type="checkbox" id="c-41901455" checked=""/><div class="controls bullet"><span class="by">throw4950sh06</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41899776">parent</a><span>|</span><a href="#41898177">next</a><span>|</span><label class="collapse" for="c-41901455">[-]</label><label class="expand" for="c-41901455">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t say so. It&#x27;s a very marked difference with a sharp change the moment I drive through the border.</div><br/></div></div></div></div></div></div></div></div><div id="41898177" class="c"><input type="checkbox" id="c-41898177" checked=""/><div class="controls bullet"><span class="by">Zanfa</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41897374">parent</a><span>|</span><a href="#41897546">prev</a><span>|</span><a href="#41900948">next</a><span>|</span><label class="collapse" for="c-41898177">[-]</label><label class="expand" for="c-41898177">[1 more]</label></div><br/><div class="children"><div class="content">&gt; For example, in the EU, you switch on the indicators when you start the merge; the indicator shows that you ARE moving.<p>In my EU country it&#x27;s theoretically at least 3 seconds <i>before</i> initiating the move.</div><br/></div></div><div id="41900948" class="c"><input type="checkbox" id="c-41900948" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41897374">parent</a><span>|</span><a href="#41898177">prev</a><span>|</span><a href="#41894715">next</a><span>|</span><label class="collapse" for="c-41900948">[-]</label><label class="expand" for="c-41900948">[1 more]</label></div><br/><div class="children"><div class="content">For anyone confused, this person’s statement about the EU is total bs.</div><br/></div></div></div></div></div></div></div></div><div id="41894715" class="c"><input type="checkbox" id="c-41894715" checked=""/><div class="controls bullet"><span class="by">darknavi</span><span>|</span><a href="#41892630">parent</a><span>|</span><a href="#41896317">prev</a><span>|</span><a href="#41896773">next</a><span>|</span><label class="collapse" for="c-41894715">[-]</label><label class="expand" for="c-41894715">[26 more]</label></div><br/><div class="children"><div class="content">You slowly build a relationship with it and understand where it will fail.<p>I drive my 20-30 minute commutes largely with FSD, as well as our 8-10 hour road trips.  It works great, but 100% needs to be supervised and is basically just nicer cruise control.</div><br/><div id="41895891" class="c"><input type="checkbox" id="c-41895891" checked=""/><div class="controls bullet"><span class="by">eschneider</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41894715">parent</a><span>|</span><a href="#41895075">next</a><span>|</span><label class="collapse" for="c-41895891">[-]</label><label class="expand" for="c-41895891">[6 more]</label></div><br/><div class="children"><div class="content">&quot;You slowly build a relationship with it and understand where it will fail.&quot;<p>I spent over a decade working on production computer vision products. You think you can do this, and for some percentage of failures you can. The thing is, there will ALWAYS be some percentage of failure cases where you really can&#x27;t perceive anything different from a success case.<p>If you want to trust your life to that, fine, but I certainly wouldn&#x27;t.</div><br/><div id="41896009" class="c"><input type="checkbox" id="c-41896009" checked=""/><div class="controls bullet"><span class="by">sandworm101</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895891">parent</a><span>|</span><a href="#41898583">next</a><span>|</span><label class="collapse" for="c-41896009">[-]</label><label class="expand" for="c-41896009">[1 more]</label></div><br/><div class="children"><div class="content">Or until a software update quietly resets the relationship and introduces novel failure modes.  There is little more dangerous on the road than false confidence.</div><br/></div></div><div id="41898583" class="c"><input type="checkbox" id="c-41898583" checked=""/><div class="controls bullet"><span class="by">peutetre</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895891">parent</a><span>|</span><a href="#41896009">prev</a><span>|</span><a href="#41895075">next</a><span>|</span><label class="collapse" for="c-41898583">[-]</label><label class="expand" for="c-41898583">[4 more]</label></div><br/><div class="children"><div class="content">Elon Musk is a technologist. He knows a lot about computers. The last thing Musk would do is trust a computer program:<p><a href="https:&#x2F;&#x2F;www.nbcnews.com&#x2F;tech&#x2F;tech-news&#x2F;musk-pushes-debunked-dominion-voting-conspiracy-theory-campaign-appear-rcna175985" rel="nofollow">https:&#x2F;&#x2F;www.nbcnews.com&#x2F;tech&#x2F;tech-news&#x2F;musk-pushes-debunked-...</a><p>So I guess that&#x27;s game over for full self-driving.</div><br/><div id="41898739" class="c"><input type="checkbox" id="c-41898739" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41898583">parent</a><span>|</span><a href="#41900961">next</a><span>|</span><label class="collapse" for="c-41898739">[-]</label><label class="expand" for="c-41898739">[1 more]</label></div><br/><div class="children"><div class="content">Oooo maybe he&#x27;ll get a similar treatment as Fox did versus Dominion.</div><br/></div></div><div id="41900961" class="c"><input type="checkbox" id="c-41900961" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41898583">parent</a><span>|</span><a href="#41898739">prev</a><span>|</span><a href="#41895075">next</a><span>|</span><label class="collapse" for="c-41900961">[-]</label><label class="expand" for="c-41900961">[2 more]</label></div><br/><div class="children"><div class="content">Yea he’s just dedicating his life on something that he knows won’t even work. What are you on about?</div><br/><div id="41901059" class="c"><input type="checkbox" id="c-41901059" checked=""/><div class="controls bullet"><span class="by">voganmother42</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41900961">parent</a><span>|</span><a href="#41895075">next</a><span>|</span><label class="collapse" for="c-41901059">[-]</label><label class="expand" for="c-41901059">[1 more]</label></div><br/><div class="children"><div class="content">Everyone else’s life seems to be completely irrelevant</div><br/></div></div></div></div></div></div></div></div><div id="41895075" class="c"><input type="checkbox" id="c-41895075" checked=""/><div class="controls bullet"><span class="by">coffeefirst</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41894715">parent</a><span>|</span><a href="#41895891">prev</a><span>|</span><a href="#41895464">next</a><span>|</span><label class="collapse" for="c-41895075">[-]</label><label class="expand" for="c-41895075">[15 more]</label></div><br/><div class="children"><div class="content">This feels like the most dangerous possible combination (not for you, just to have on the road in large numbers).<p>Good enough that the average user will stop paying attention, but not actually good enough to be left alone.<p>And when the machine goes to do something lethally dumb, you have 5 seconds to notice and intervene.</div><br/><div id="41895427" class="c"><input type="checkbox" id="c-41895427" checked=""/><div class="controls bullet"><span class="by">jvolkman</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895075">parent</a><span>|</span><a href="#41895956">next</a><span>|</span><label class="collapse" for="c-41895427">[-]</label><label class="expand" for="c-41895427">[12 more]</label></div><br/><div class="children"><div class="content">This is what Waymo realized a decade ago and what helped define their rollout strategy: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;tiwVMrTLUWg?t=247&amp;si=Twi_fQJC7whg3Oey" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;tiwVMrTLUWg?t=247&amp;si=Twi_fQJC7whg3Oey</a></div><br/><div id="41895700" class="c"><input type="checkbox" id="c-41895700" checked=""/><div class="controls bullet"><span class="by">nh2</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895427">parent</a><span>|</span><a href="#41895956">next</a><span>|</span><label class="collapse" for="c-41895700">[-]</label><label class="expand" for="c-41895700">[11 more]</label></div><br/><div class="children"><div class="content">This video is great.<p>It looks like Wayno really understood the problem.<p>It explains concisely why it&#x27;s a bad idea to roll our incremental progress, how difficult the problem really is, and why you should really throw all sensors you can at it.<p>I also appreciate the &quot;we don&#x27;t know when it&#x27;s going to be ready&quot; attitude. It shows they have a better understanding of what their task actually is than anybody who claims &quot;next year&quot; every year.</div><br/><div id="41896208" class="c"><input type="checkbox" id="c-41896208" checked=""/><div class="controls bullet"><span class="by">trompetenaccoun</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895700">parent</a><span>|</span><a href="#41895788">next</a><span>|</span><label class="collapse" for="c-41896208">[-]</label><label class="expand" for="c-41896208">[4 more]</label></div><br/><div class="children"><div class="content">All their sensors didn&#x27;t prevent them from crashing into stationary object. You&#x27;d think that would be the absolute easiest to avoid, especially with both radar and lidar on board. Accidents like that show the training data and software will be much more important than number of sensors.<p><a href="https:&#x2F;&#x2F;techcrunch.com&#x2F;2024&#x2F;06&#x2F;12&#x2F;waymo-second-robotaxi-recall-autonomous-vehicle&#x2F;" rel="nofollow">https:&#x2F;&#x2F;techcrunch.com&#x2F;2024&#x2F;06&#x2F;12&#x2F;waymo-second-robotaxi-reca...</a></div><br/><div id="41896467" class="c"><input type="checkbox" id="c-41896467" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896208">parent</a><span>|</span><a href="#41895788">next</a><span>|</span><label class="collapse" for="c-41896467">[-]</label><label class="expand" for="c-41896467">[3 more]</label></div><br/><div class="children"><div class="content">The issue was fixed, now handling 100&#x27;000 trips per week, and all seems to go well in the last 4 months, this is 1.5 million trips.</div><br/><div id="41896970" class="c"><input type="checkbox" id="c-41896970" checked=""/><div class="controls bullet"><span class="by">trompetenaccoun</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896467">parent</a><span>|</span><a href="#41896990">next</a><span>|</span><label class="collapse" for="c-41896970">[-]</label><label class="expand" for="c-41896970">[1 more]</label></div><br/><div class="children"><div class="content">So they had &quot;better understanding&quot; of the problem as the other user put it, but their software was still flawed and needed fixing. That&#x27;s my point. This happened two weeks ago btw: <a href="https:&#x2F;&#x2F;www.msn.com&#x2F;en-in&#x2F;autos&#x2F;news&#x2F;waymo-self-driving-car-crashes-into-san-francisco-bus-ceos-help-confused-robot&#x2F;ar-AA1rWWP2" rel="nofollow">https:&#x2F;&#x2F;www.msn.com&#x2F;en-in&#x2F;autos&#x2F;news&#x2F;waymo-self-driving-car-...</a><p>I don&#x27;t mean Waymo is bad or unsafe, it&#x27;s pretty cool. My point is about true automation needing data and intelligence. A lot more data than we currently have, because the problem is in the &quot;edge&quot; cases, the kind of situation the software has never encountered. Waymo is in the lead for now but they have fewer cars on the road, which means less data.</div><br/></div></div><div id="41896990" class="c"><input type="checkbox" id="c-41896990" checked=""/><div class="controls bullet"><span class="by">jraby3</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896467">parent</a><span>|</span><a href="#41896970">prev</a><span>|</span><a href="#41895788">next</a><span>|</span><label class="collapse" for="c-41896990">[-]</label><label class="expand" for="c-41896990">[1 more]</label></div><br/><div class="children"><div class="content">Any idea how many accidents and how many fatalities? And how that compares to human drivers?</div><br/></div></div></div></div></div></div><div id="41895788" class="c"><input type="checkbox" id="c-41895788" checked=""/><div class="controls bullet"><span class="by">yborg</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895700">parent</a><span>|</span><a href="#41896208">prev</a><span>|</span><a href="#41895956">next</a><span>|</span><label class="collapse" for="c-41895788">[-]</label><label class="expand" for="c-41895788">[6 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t get a $700B market cap by telling investors &quot;We don&#x27;t know.&quot;</div><br/><div id="41895903" class="c"><input type="checkbox" id="c-41895903" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895788">parent</a><span>|</span><a href="#41896777">next</a><span>|</span><label class="collapse" for="c-41895903">[-]</label><label class="expand" for="c-41895903">[4 more]</label></div><br/><div class="children"><div class="content">Ironically, Robotaxis from Waymo are actually working really well. It&#x27;s a true unsupervised system, very safe, used in production, where the manufacturer takes the full responsibility.<p>So the gradual rollout strategy is actually great.<p>Tesla wants to do &quot;all or nothing&quot;, and ends up with nothing for now (example with Europe, where FSD is sold since 2016 but it is &quot;pending regulatory approval&quot;, when actually, the problem is the tech that is not finished yet, sadly).<p>It&#x27;s genuinely a difficult problem to solve, so it&#x27;s better to do it step-by-step than a &quot;big-bang deploy&quot;.</div><br/><div id="41897819" class="c"><input type="checkbox" id="c-41897819" checked=""/><div class="controls bullet"><span class="by">nh2</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895903">parent</a><span>|</span><a href="#41896634">next</a><span>|</span><label class="collapse" for="c-41897819">[-]</label><label class="expand" for="c-41897819">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So the gradual rollout strategy is actually great.<p>I think you misunderstood, or it&#x27;s a terminology problem.<p>Waymo&#x27;s point in the video is that in contrast to Tesla, they are _not_ doing gradual rollout of seemingly-working-still-often-catastropically-failing tech.<p>See e.g. minute 5:33 -&gt; 6:06. They are stating that they are targeting directly the shown upper curve of safety, and that they are not aiming for the &quot;good enough that the average user will stop paying attention, but not actually good enough to be left alone&quot;.</div><br/></div></div><div id="41896634" class="c"><input type="checkbox" id="c-41896634" checked=""/><div class="controls bullet"><span class="by">mattgreenrocks</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895903">parent</a><span>|</span><a href="#41897819">prev</a><span>|</span><a href="#41896777">next</a><span>|</span><label class="collapse" for="c-41896634">[-]</label><label class="expand" for="c-41896634">[2 more]</label></div><br/><div class="children"><div class="content">Does Tesla take full responsibility for FSD incidents?<p>It seemed like most players in tech a few years ago were using legal shenanigans to dodge liability here, which, to me, indicates a lack of seriousness toward the safety implications.</div><br/><div id="41900980" class="c"><input type="checkbox" id="c-41900980" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41896634">parent</a><span>|</span><a href="#41896777">next</a><span>|</span><label class="collapse" for="c-41900980">[-]</label><label class="expand" for="c-41900980">[1 more]</label></div><br/><div class="children"><div class="content">What does that mean? Tesla’s system isn’t unsupervised, so why would they take responsibility?</div><br/></div></div></div></div></div></div><div id="41896777" class="c"><input type="checkbox" id="c-41896777" checked=""/><div class="controls bullet"><span class="by">zbentley</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895788">parent</a><span>|</span><a href="#41895903">prev</a><span>|</span><a href="#41895956">next</a><span>|</span><label class="collapse" for="c-41896777">[-]</label><label class="expand" for="c-41896777">[1 more]</label></div><br/><div class="children"><div class="content">Not sure how tongue-in-cheek that was, but I think your statement is the heart of the problem. Investment money chases confidence and moonshots rather than backing organizations that pitch a more pragmatic (read: asterisks and unknowns) approach.</div><br/></div></div></div></div></div></div></div></div><div id="41895956" class="c"><input type="checkbox" id="c-41895956" checked=""/><div class="controls bullet"><span class="by">ricardobeat</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895075">parent</a><span>|</span><a href="#41895427">prev</a><span>|</span><a href="#41895464">next</a><span>|</span><label class="collapse" for="c-41895956">[-]</label><label class="expand" for="c-41895956">[2 more]</label></div><br/><div class="children"><div class="content">Five seconds is a <i>long</i> time in driving, usually you’ll need to react in under 2 seconds in situations where it disengages, those never happen while going straight.</div><br/><div id="41896128" class="c"><input type="checkbox" id="c-41896128" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895956">parent</a><span>|</span><a href="#41895464">next</a><span>|</span><label class="collapse" for="c-41896128">[-]</label><label class="expand" for="c-41896128">[1 more]</label></div><br/><div class="children"><div class="content">Not if you are reading your emails…</div><br/></div></div></div></div></div></div><div id="41895464" class="c"><input type="checkbox" id="c-41895464" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41894715">parent</a><span>|</span><a href="#41895075">prev</a><span>|</span><a href="#41895943">next</a><span>|</span><label class="collapse" for="c-41895464">[-]</label><label class="expand" for="c-41895464">[3 more]</label></div><br/><div class="children"><div class="content">When an update comes out does that relationship get reset (does it start failing on things that used to work), or has it been a uniform upward march?<p>I&#x27;m thinking of how every SaaS product I ever have to use regularly breaks my workflow to make &#x27;improvements&#x27;.</div><br/><div id="41895742" class="c"><input type="checkbox" id="c-41895742" checked=""/><div class="controls bullet"><span class="by">bdndndndbve</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895464">parent</a><span>|</span><a href="#41895741">next</a><span>|</span><label class="collapse" for="c-41895742">[-]</label><label class="expand" for="c-41895742">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t take OP&#x27;s word for it, if they really believe they know how it&#x27;s going to react in every situation in the first place. Studies have shown this is a gross overestimation of their own ability to pay attention.</div><br/></div></div><div id="41895741" class="c"><input type="checkbox" id="c-41895741" checked=""/><div class="controls bullet"><span class="by">xur17</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41895464">parent</a><span>|</span><a href="#41895742">prev</a><span>|</span><a href="#41895943">next</a><span>|</span><label class="collapse" for="c-41895741">[-]</label><label class="expand" for="c-41895741">[1 more]</label></div><br/><div class="children"><div class="content">For me it does, but only somewhat. I&#x27;m much more cautious &#x2F; aware for the first few drives while I figure it out again.<p>I also feel like it takes a bit (5-10 minutes of driving) for it to recalibrate after an update, and it&#x27;s slightly worse than usual at the very beginning. I know they have to calibrate the cameras to the car, so it might be related to that, or it could just be me getting used to its quarks.</div><br/></div></div></div></div><div id="41895943" class="c"><input type="checkbox" id="c-41895943" checked=""/><div class="controls bullet"><span class="by">sumodm</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41894715">parent</a><span>|</span><a href="#41895464">prev</a><span>|</span><a href="#41896773">next</a><span>|</span><label class="collapse" for="c-41895943">[-]</label><label class="expand" for="c-41895943">[1 more]</label></div><br/><div class="children"><div class="content">Something along this lines is the real danger. People will understand common failure modes and assume they have understood its behavior for most scenarios. Unlike common deterministic and even some probabilistic systems, where behavior boundaries are well behaved, there could be discontinuities in &#x27;rarer&#x27; seen parts of the boundary. And these &#x27;rarer&#x27; parts need not be obvious to us humans, since few pixel changes might cause wrinkles.<p>*vocabulary use is for a broad stroke explanation.</div><br/></div></div></div></div><div id="41896773" class="c"><input type="checkbox" id="c-41896773" checked=""/><div class="controls bullet"><span class="by">650REDHAIR</span><span>|</span><a href="#41892630">parent</a><span>|</span><a href="#41894715">prev</a><span>|</span><a href="#41898671">next</a><span>|</span><label class="collapse" for="c-41896773">[-]</label><label class="expand" for="c-41896773">[1 more]</label></div><br/><div class="children"><div class="content">This was my experience as well. It tried to drive us (me, my wife, and my FIL) into a tree on a gentle low speed uphill turn and I’ll never trust it again.</div><br/></div></div><div id="41898129" class="c"><input type="checkbox" id="c-41898129" checked=""/><div class="controls bullet"><span class="by">jerb</span><span>|</span><a href="#41892630">parent</a><span>|</span><a href="#41898671">prev</a><span>|</span><a href="#41895565">next</a><span>|</span><label class="collapse" for="c-41898129">[-]</label><label class="expand" for="c-41898129">[2 more]</label></div><br/><div class="children"><div class="content">But it’s clearly statistically much safer (<a href="https:&#x2F;&#x2F;www.tesla.com&#x2F;VehicleSafetyReport" rel="nofollow">https:&#x2F;&#x2F;www.tesla.com&#x2F;VehicleSafetyReport</a>)
7 million miles before an accident w FSD vs. 1 million when disengaged.
I agree I didn’t like the feel of FSD either, but the numbers speak for themselves.</div><br/><div id="41898183" class="c"><input type="checkbox" id="c-41898183" checked=""/><div class="controls bullet"><span class="by">bpfrh</span><span>|</span><a href="#41892630">root</a><span>|</span><a href="#41898129">parent</a><span>|</span><a href="#41895565">next</a><span>|</span><label class="collapse" for="c-41898183">[-]</label><label class="expand" for="c-41898183">[1 more]</label></div><br/><div class="children"><div class="content">Teslas numbers have biases in them which paint a wrong picture:<p><a href="https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;bradtempleton&#x2F;2023&#x2F;04&#x2F;26&#x2F;tesla-again-paints-a-very-misleading-story-with-their-crash-data&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;bradtempleton&#x2F;2023&#x2F;04&#x2F;26&#x2F;tesla-...</a><p>They compare incomparable data(city miles vs highway miles), autopilot is also mostly used on higways which is not where most accidents happen.</div><br/></div></div></div></div></div></div><div id="41895565" class="c"><input type="checkbox" id="c-41895565" checked=""/><div class="controls bullet"><span class="by">Fomite</span><span>|</span><a href="#41892630">prev</a><span>|</span><a href="#41893777">next</a><span>|</span><label class="collapse" for="c-41895565">[-]</label><label class="expand" for="c-41895565">[8 more]</label></div><br/><div class="children"><div class="content">&quot;Driver is mostly disengaged, but then must intervene in a sudden fail state&quot; is also one of the most dangerous types of automation due to how long it takes the driver to reach full control as well.</div><br/><div id="41896399" class="c"><input type="checkbox" id="c-41896399" checked=""/><div class="controls bullet"><span class="by">drowsspa</span><span>|</span><a href="#41895565">parent</a><span>|</span><a href="#41893777">next</a><span>|</span><label class="collapse" for="c-41896399">[-]</label><label class="expand" for="c-41896399">[7 more]</label></div><br/><div class="children"><div class="content">Yeah, I don&#x27;t drive but I would think it would be worse than actually paying attention all the time</div><br/><div id="41897417" class="c"><input type="checkbox" id="c-41897417" checked=""/><div class="controls bullet"><span class="by">lopkeny12ko</span><span>|</span><a href="#41895565">root</a><span>|</span><a href="#41896399">parent</a><span>|</span><a href="#41896694">next</a><span>|</span><label class="collapse" for="c-41897417">[-]</label><label class="expand" for="c-41897417">[3 more]</label></div><br/><div class="children"><div class="content">You are required to pay attention all the time. That&#x27;s what the &quot;supervised&quot; in &quot;FSD (supervised)&quot; means.</div><br/><div id="41898255" class="c"><input type="checkbox" id="c-41898255" checked=""/><div class="controls bullet"><span class="by">freejazz</span><span>|</span><a href="#41895565">root</a><span>|</span><a href="#41897417">parent</a><span>|</span><a href="#41896694">next</a><span>|</span><label class="collapse" for="c-41898255">[-]</label><label class="expand" for="c-41898255">[2 more]</label></div><br/><div class="children"><div class="content">FSD stands for Fully Supervised Driving, right?</div><br/><div id="41898379" class="c"><input type="checkbox" id="c-41898379" checked=""/><div class="controls bullet"><span class="by">dhdaadhd</span><span>|</span><a href="#41895565">root</a><span>|</span><a href="#41898255">parent</a><span>|</span><a href="#41896694">next</a><span>|</span><label class="collapse" for="c-41898379">[-]</label><label class="expand" for="c-41898379">[1 more]</label></div><br/><div class="children"><div class="content">yeah, that sounds like Elon’s marketing to me.</div><br/></div></div></div></div></div></div><div id="41896694" class="c"><input type="checkbox" id="c-41896694" checked=""/><div class="controls bullet"><span class="by">pessimizer</span><span>|</span><a href="#41895565">root</a><span>|</span><a href="#41896399">parent</a><span>|</span><a href="#41897417">prev</a><span>|</span><a href="#41893777">next</a><span>|</span><label class="collapse" for="c-41896694">[-]</label><label class="expand" for="c-41896694">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s also a problem that gets worse as the software gets better. Having to intervene once every 5 minutes is a lot easier than having to intervene once every 5 weeks. If lack of intervention causes an accident, I&#x27;d bet on the 5 minute car avoiding an accident longer than the 5 week car for any span of time longer than 10 weeks.</div><br/><div id="41897154" class="c"><input type="checkbox" id="c-41897154" checked=""/><div class="controls bullet"><span class="by">jakub_g</span><span>|</span><a href="#41895565">root</a><span>|</span><a href="#41896694">parent</a><span>|</span><a href="#41893777">next</a><span>|</span><label class="collapse" for="c-41897154">[-]</label><label class="expand" for="c-41897154">[2 more]</label></div><br/><div class="children"><div class="content">I feel like the full self driving cars should have a &quot;budget&quot;. Every time you drive, say, 1000 km in FSD, you then need to drive 100 km in &quot;normal&quot; mode to keep sharp. Or whatever the ratio &#x2F; exact numbers TBD. You can reset the counter upfront by driving smaller mileage more regularly.</div><br/><div id="41901002" class="c"><input type="checkbox" id="c-41901002" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#41895565">root</a><span>|</span><a href="#41897154">parent</a><span>|</span><a href="#41893777">next</a><span>|</span><label class="collapse" for="c-41901002">[-]</label><label class="expand" for="c-41901002">[1 more]</label></div><br/><div class="children"><div class="content">Just as driving practice?<p>It&#x27;s not going to help the problem of keeping up vigilance when monitoring a level 3 system.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41893777" class="c"><input type="checkbox" id="c-41893777" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#41895565">prev</a><span>|</span><a href="#41889192">next</a><span>|</span><label class="collapse" for="c-41893777">[-]</label><label class="expand" for="c-41893777">[21 more]</label></div><br/><div class="children"><div class="content">Tesla released a promotional video in 2016 saying that with FSD a human driver is not necessary and that &quot;The person in the driver&#x27;s seat is only there for legal reasons&quot;. The video was staged as we&#x27;ve learned in 2022.<p>2016 folks... Even with today&#x27;s FSD which is several orders of magnitude better than the one in the video, you would still probably have a serious accident within a week (and I&#x27;m being generous here) if you didn&#x27;t seat in the driver&#x27;s seat.<p>How Trevor Milton got sentenced for fraud and the people responsible for this were not is a mystery to me.</div><br/><div id="41895579" class="c"><input type="checkbox" id="c-41895579" checked=""/><div class="controls bullet"><span class="by">1f60c</span><span>|</span><a href="#41893777">parent</a><span>|</span><a href="#41895029">next</a><span>|</span><label class="collapse" for="c-41895579">[-]</label><label class="expand" for="c-41895579">[3 more]</label></div><br/><div class="children"><div class="content">AFAIK the owner&#x27;s manual says you have to keep your hands on the wheel and be ready to take over at all times, but Elon Musk and co. love to pretend otherwise.</div><br/><div id="41896763" class="c"><input type="checkbox" id="c-41896763" checked=""/><div class="controls bullet"><span class="by">Flameancer</span><span>|</span><a href="#41893777">root</a><span>|</span><a href="#41895579">parent</a><span>|</span><a href="#41895029">next</a><span>|</span><label class="collapse" for="c-41896763">[-]</label><label class="expand" for="c-41896763">[2 more]</label></div><br/><div class="children"><div class="content">This part doesn’t seem to be common knowledge. I don’t own a Tesla but I have been a few. From my understanding the feature as always said it was in beta and that it still required that you have your hands on the wheel.<p>I like the idea of FSD, but I think we should have a serious talk about how the safety implications of making this more broadly available and also compatibility with making a mesh network so FSD vehicles can communicate. I’m not well versed in the tech but I feel like it would be safer if you have like say have more cars on the road that can communicate and making decisions together than separate cars existing in a vacuum having to make a decision.</div><br/><div id="41896865" class="c"><input type="checkbox" id="c-41896865" checked=""/><div class="controls bullet"><span class="by">y-c-o-m-b</span><span>|</span><a href="#41893777">root</a><span>|</span><a href="#41896763">parent</a><span>|</span><a href="#41895029">next</a><span>|</span><label class="collapse" for="c-41896865">[-]</label><label class="expand" for="c-41896865">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve wondered about the networked vehicle communication for a while. It doesn&#x27;t even need to be FSD. I might be slightly wrong on this, but I would guess most cars going back at least a decade can have their software&#x2F;firmware modified to do this if the manufacturers so choose. I imagine it would improve the reliability and reaction-times of FSD considerably.</div><br/></div></div></div></div></div></div></div></div><div id="41889192" class="c"><input type="checkbox" id="c-41889192" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41893777">prev</a><span>|</span><a href="#41896361">next</a><span>|</span><label class="collapse" for="c-41889192">[-]</label><label class="expand" for="c-41889192">[301 more]</label></div><br/><div class="children"><div class="content">Lots of people are asking how good the self driving has to be before we tolerate it. I got a one month free trial of FSD and turned it off after two weeks. Quite simply: it&#x27;s dangerous.<p>- It failed with a cryptic system error while driving<p>- It started making a left turn far too early that would have scraped the left side of the car on a sign. I had to manually intervene.<p>- In my opinion, the default setting accelerates way too aggressively. I&#x27;d call myself a fairly aggressive driver and it is too aggressive for my taste.<p>- It tried to make way too many right turns on red when it wasn&#x27;t safe to. It would creep into the road, almost into the path of oncoming vehicles.<p>- It didn&#x27;t merge left to make room for vehicles merging onto the highway. The vehicles then tried to cut in. The system should have avoided an unsafe situation like this in the first place.<p>- It would switch lanes to go faster on the highway, but then missed an exit on at least one occasion because it couldn&#x27;t make it back into the right lane in time. Stupid.<p>After the system error, I lost all trust in FSD from Tesla. Until I ride in one and <i>feel</i> safe, I can&#x27;t have any faith that this is a reasonable system. Hell, even autopilot does dumb shit on a regular basis. I&#x27;m grateful to be getting a car from another manufacturer this year.</div><br/><div id="41890342" class="c"><input type="checkbox" id="c-41890342" checked=""/><div class="controls bullet"><span class="by">TheCleric</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41895301">next</a><span>|</span><label class="collapse" for="c-41890342">[-]</label><label class="expand" for="c-41890342">[137 more]</label></div><br/><div class="children"><div class="content">&gt; Lots of people are asking how good the self driving has to be before we tolerate it.<p>There’s a simple answer to this. As soon as it’s good enough for Tesla to accept liability for accidents. Until then if Tesla doesn’t trust it, why should I?</div><br/><div id="41894342" class="c"><input type="checkbox" id="c-41894342" checked=""/><div class="controls bullet"><span class="by">ndsipa_pomu</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890342">parent</a><span>|</span><a href="#41890435">next</a><span>|</span><label class="collapse" for="c-41894342">[-]</label><label class="expand" for="c-41894342">[13 more]</label></div><br/><div class="children"><div class="content">&gt; As soon as it’s good enough for Tesla to accept liability for accidents.<p>That makes a lot of sense and not just from a selfish point of view. When a person drives a vehicle, then the person is held responsible for how the vehicle behaves on the roads, so it&#x27;s logical that when a machine drives a vehicle that the machine&#x27;s manufacturer&#x2F;designer is held responsible.<p>It&#x27;s a complete con that Tesla is promoting their autonomous driving, but also having their vehicles suddenly switch to non-autonomous driving which they claim moves the responsibility to the human in the driver seat. Presumably, the idea is that the human should have been watching and approving everything that the vehicle has done up to that point.</div><br/><div id="41894666" class="c"><input type="checkbox" id="c-41894666" checked=""/><div class="controls bullet"><span class="by">andrewaylett</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894342">parent</a><span>|</span><a href="#41894794">next</a><span>|</span><label class="collapse" for="c-41894666">[-]</label><label class="expand" for="c-41894666">[9 more]</label></div><br/><div class="children"><div class="content">The responsibility doesn&#x27;t shift, it <i>always</i> lies with the human.  One problem is that humans are notoriously poor at maintaining attention when supervising automation<p>Until the car is ready to take over as <i>legal</i> driver, it&#x27;s foolish to set the human driver up for failure in the way that Tesla (and the humans driving Tesla cars) do.</div><br/><div id="41896371" class="c"><input type="checkbox" id="c-41896371" checked=""/><div class="controls bullet"><span class="by">mannykannot</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894666">parent</a><span>|</span><a href="#41894801">next</a><span>|</span><label class="collapse" for="c-41896371">[-]</label><label class="expand" for="c-41896371">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The responsibility doesn&#x27;t shift, it always lies with the human.<p>Indeed, and that goes for the person or persons who say that the products they sell are safe when used in a certain way.</div><br/></div></div><div id="41894801" class="c"><input type="checkbox" id="c-41894801" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894666">parent</a><span>|</span><a href="#41896371">prev</a><span>|</span><a href="#41894794">next</a><span>|</span><label class="collapse" for="c-41894801">[-]</label><label class="expand" for="c-41894801">[7 more]</label></div><br/><div class="children"><div class="content">What?! So if there is a failure and the car goes full throttle (no autonomous car) it is my responsibility?! You are pretty wrong!!!</div><br/><div id="41895481" class="c"><input type="checkbox" id="c-41895481" checked=""/><div class="controls bullet"><span class="by">kgermino</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894801">parent</a><span>|</span><a href="#41895527">next</a><span>|</span><label class="collapse" for="c-41895481">[-]</label><label class="expand" for="c-41895481">[5 more]</label></div><br/><div class="children"><div class="content">You are responsible (Legally, contractually, morally) for supervising FSD today. If the car decided to stomp on the throttle you are expected to be ready to hit the brakes.<p>The whole point is that is somewhat of an unreasonable expectation but it’s what Tesla expects you to do today</div><br/><div id="41896164" class="c"><input type="checkbox" id="c-41896164" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895481">parent</a><span>|</span><a href="#41896283">next</a><span>|</span><label class="collapse" for="c-41896164">[-]</label><label class="expand" for="c-41896164">[1 more]</label></div><br/><div class="children"><div class="content">My example was clear about NOT about autonomous driving. Because the previous comment seems to imply for everything you are responsible</div><br/></div></div><div id="41896283" class="c"><input type="checkbox" id="c-41896283" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895481">parent</a><span>|</span><a href="#41896164">prev</a><span>|</span><a href="#41895527">next</a><span>|</span><label class="collapse" for="c-41896283">[-]</label><label class="expand" for="c-41896283">[3 more]</label></div><br/><div class="children"><div class="content">&gt; If the car decided to stomp on the throttle you are expected to be ready to hit the brakes.<p>Didn&#x27;t Tesla have an issue a couple of years ago where pressing the brake did <i>not</i> disengage any throttle? i.e. if the car has a bug and puts throttle to 100% and you stand on the brake, the car should say &quot;cut throttle to 0&quot;, but instead, you just had 100% throttle, 100% brake?</div><br/><div id="41897359" class="c"><input type="checkbox" id="c-41897359" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41896283">parent</a><span>|</span><a href="#41895527">next</a><span>|</span><label class="collapse" for="c-41897359">[-]</label><label class="expand" for="c-41897359">[2 more]</label></div><br/><div class="children"><div class="content">If it did, it wouldn’t matter. Brakes are required to be stronger than engines.</div><br/><div id="41897796" class="c"><input type="checkbox" id="c-41897796" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41897359">parent</a><span>|</span><a href="#41895527">next</a><span>|</span><label class="collapse" for="c-41897796">[-]</label><label class="expand" for="c-41897796">[1 more]</label></div><br/><div class="children"><div class="content">That makes no sense. Yes, they are. But brakes are going to be more reactive and performant with the throttle at 0 than 100.<p>You can&#x27;t imagine that the stopping distances will be the same.</div><br/></div></div></div></div></div></div></div></div><div id="41895527" class="c"><input type="checkbox" id="c-41895527" checked=""/><div class="controls bullet"><span class="by">xondono</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894801">parent</a><span>|</span><a href="#41895481">prev</a><span>|</span><a href="#41894794">next</a><span>|</span><label class="collapse" for="c-41895527">[-]</label><label class="expand" for="c-41895527">[1 more]</label></div><br/><div class="children"><div class="content">Autopilot, FSD, etc.. are all legally classified as ADAS, so it’s different from e.g. your car not responding to controls.<p>The liability lies with the driver, and all Tesla needs to prove is that input from the driver will override any decision made by the ADAS.</div><br/></div></div></div></div></div></div><div id="41894794" class="c"><input type="checkbox" id="c-41894794" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894342">parent</a><span>|</span><a href="#41894666">prev</a><span>|</span><a href="#41890435">next</a><span>|</span><label class="collapse" for="c-41894794">[-]</label><label class="expand" for="c-41894794">[3 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; When a person drives a vehicle, then the person is held responsible for how the vehicle behaves on the roads, so it&#x27;s logical that when a machine drives a vehicle that the machine&#x27;s manufacturer&#x2F;designer is held responsible.<p>Never really understood the supposed dilemma. What happens when the brakes fail because of bad quality?</div><br/><div id="41895747" class="c"><input type="checkbox" id="c-41895747" checked=""/><div class="controls bullet"><span class="by">ndsipa_pomu</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894794">parent</a><span>|</span><a href="#41894839">next</a><span>|</span><label class="collapse" for="c-41895747">[-]</label><label class="expand" for="c-41895747">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What happens when the brakes fail because of bad quality?<p>Depends on the root cause of the failure. Manufacturing faults would put the liability on the manufacturer; installation mistakes would put the liability on the mechanic; using them past their useful life would put the liability on the owner for not maintaining them in working order.</div><br/></div></div><div id="41894839" class="c"><input type="checkbox" id="c-41894839" checked=""/><div class="controls bullet"><span class="by">arzig</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894794">parent</a><span>|</span><a href="#41895747">prev</a><span>|</span><a href="#41890435">next</a><span>|</span><label class="collapse" for="c-41894839">[-]</label><label class="expand" for="c-41894839">[1 more]</label></div><br/><div class="children"><div class="content">Then this would be manufacturing liability because they are not fit for purpose.</div><br/></div></div></div></div></div></div><div id="41890435" class="c"><input type="checkbox" id="c-41890435" checked=""/><div class="controls bullet"><span class="by">genocidicbunny</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890342">parent</a><span>|</span><a href="#41894342">prev</a><span>|</span><a href="#41894760">next</a><span>|</span><label class="collapse" for="c-41890435">[-]</label><label class="expand" for="c-41890435">[1 more]</label></div><br/><div class="children"><div class="content">I think this is probably both the most concise and most reasonable take. It doesn&#x27;t require anyone to define some level of autonomy or argue about specific edge cases of how the self driving system behaves. And it&#x27;s easy to apply this principle to not only Tesla, but to all companies making self driving cars and similar features.</div><br/></div></div><div id="41894760" class="c"><input type="checkbox" id="c-41894760" checked=""/><div class="controls bullet"><span class="by">jefftk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890342">parent</a><span>|</span><a href="#41890435">prev</a><span>|</span><a href="#41890927">next</a><span>|</span><label class="collapse" for="c-41894760">[-]</label><label class="expand" for="c-41894760">[4 more]</label></div><br/><div class="children"><div class="content">Note that Mercedes does take liability for accidents with their (very limited level) level 3 system: <a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;9&#x2F;27&#x2F;23892154&#x2F;mercedes-benz-drive-pilot-autonomous-level-3-test" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;9&#x2F;27&#x2F;23892154&#x2F;mercedes-benz-dr...</a></div><br/><div id="41894805" class="c"><input type="checkbox" id="c-41894805" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894760">parent</a><span>|</span><a href="#41899207">next</a><span>|</span><label class="collapse" for="c-41894805">[-]</label><label class="expand" for="c-41894805">[1 more]</label></div><br/><div class="children"><div class="content">Yes. That is the only way. That being said, I want to see the first incidents, and how are they resolved.</div><br/></div></div><div id="41899207" class="c"><input type="checkbox" id="c-41899207" checked=""/><div class="controls bullet"><span class="by">iknowstuff</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894760">parent</a><span>|</span><a href="#41894805">prev</a><span>|</span><a href="#41890927">next</a><span>|</span><label class="collapse" for="c-41899207">[-]</label><label class="expand" for="c-41899207">[2 more]</label></div><br/><div class="children"><div class="content">its pathetic. &lt;40mph following a vehicle directly ahead. basically only usable in stop and go traffic<p><a href="https:&#x2F;&#x2F;www.notebookcheck.net&#x2F;Tesla-vs-Mercedes-self-driving-test-ends-in-40-interventions-as-Elon-Musk-says-FSD-is-years-ahead.835805.0.html" rel="nofollow">https:&#x2F;&#x2F;www.notebookcheck.net&#x2F;Tesla-vs-Mercedes-self-driving...</a></div><br/><div id="41899255" class="c"><input type="checkbox" id="c-41899255" checked=""/><div class="controls bullet"><span class="by">jefftk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41899207">parent</a><span>|</span><a href="#41890927">next</a><span>|</span><label class="collapse" for="c-41899255">[-]</label><label class="expand" for="c-41899255">[1 more]</label></div><br/><div class="children"><div class="content">The Mercedes system is definitely, as I said, very limited. But within it&#x27;s operating conditions the Mercedes system is much more useful: you can safely and legally read, work, or watch a movie while in the driver&#x27;s seat, literally not paying any attention to the road.</div><br/></div></div></div></div></div></div><div id="41890927" class="c"><input type="checkbox" id="c-41890927" checked=""/><div class="controls bullet"><span class="by">bdcravens</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890342">parent</a><span>|</span><a href="#41894760">prev</a><span>|</span><a href="#41896173">next</a><span>|</span><label class="collapse" for="c-41890927">[-]</label><label class="expand" for="c-41890927">[85 more]</label></div><br/><div class="children"><div class="content">The liability for killing someone can include prison time.</div><br/><div id="41891164" class="c"><input type="checkbox" id="c-41891164" checked=""/><div class="controls bullet"><span class="by">TheCleric</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890927">parent</a><span>|</span><a href="#41896926">next</a><span>|</span><label class="collapse" for="c-41891164">[-]</label><label class="expand" for="c-41891164">[78 more]</label></div><br/><div class="children"><div class="content">Good. If you write software that people rely on with their lives, and it fails, you should be held liable for that criminally.</div><br/><div id="41895710" class="c"><input type="checkbox" id="c-41895710" checked=""/><div class="controls bullet"><span class="by">hibikir</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41896899">next</a><span>|</span><label class="collapse" for="c-41895710">[-]</label><label class="expand" for="c-41895710">[1 more]</label></div><br/><div class="children"><div class="content">Remember that this is neural networks doing the driving, more than old expert systems: What makes a crash happen is a network that fails to read an image correctly, or a network that fails to capture what is going on when melding input from different sensors.<p>So the blame won&#x27;t be on a guy who got an if statement backwards, but signing off on stopping training, failing to have certain kinds of pictures in the set, or other similar, higher order problem. Blame will be incredibly nebulous.</div><br/></div></div><div id="41896899" class="c"><input type="checkbox" id="c-41896899" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41895710">prev</a><span>|</span><a href="#41892022">next</a><span>|</span><label class="collapse" for="c-41896899">[-]</label><label class="expand" for="c-41896899">[2 more]</label></div><br/><div class="children"><div class="content">Do we send Boeing engineers to jail when their plane crashes?<p>Intention matters when passing crime judgement. If a mother causes the death of her baby due to some poor decision (say feed her something contaminated), no one proposes or tries to jail the mother, because they know the intention was the opposite.</div><br/><div id="41901773" class="c"><input type="checkbox" id="c-41901773" checked=""/><div class="controls bullet"><span class="by">davkan</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41896899">parent</a><span>|</span><a href="#41892022">next</a><span>|</span><label class="collapse" for="c-41901773">[-]</label><label class="expand" for="c-41901773">[1 more]</label></div><br/><div class="children"><div class="content">This is why we have criminal negligence. Did the mother open a sealed package from the grocery store or did she find an open one on the ground?<p>Harder to apply to software but maybe there should be a some legal liability involved when a sysadmin uses admin&#x2F;admin and health information is leaked.<p>Some employees should be absolutely in jail from boeing regarding the MCAS system and the hundreds of people who died as a result. But the actions there go beyond negligence anyway.</div><br/></div></div></div></div><div id="41892022" class="c"><input type="checkbox" id="c-41892022" checked=""/><div class="controls bullet"><span class="by">bdcravens</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41896899">prev</a><span>|</span><a href="#41891445">next</a><span>|</span><label class="collapse" for="c-41892022">[-]</label><label class="expand" for="c-41892022">[1 more]</label></div><br/><div class="children"><div class="content">Assuming there&#x27;s the kind of guard rails as in other industries where this is true, absolutely. (In other words, proper licensing and credentialing, and the ability to prevent a deployment legally)<p>I would also say that if something gets signed off on by management, that carries an implicit transfer of accountability up the chain from the individual contributor to whoever signed off.</div><br/></div></div><div id="41891445" class="c"><input type="checkbox" id="c-41891445" checked=""/><div class="controls bullet"><span class="by">beej71</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41892022">prev</a><span>|</span><a href="#41894610">next</a><span>|</span><label class="collapse" for="c-41891445">[-]</label><label class="expand" for="c-41891445">[1 more]</label></div><br/><div class="children"><div class="content">And such coders should carry malpractice insurance.</div><br/></div></div><div id="41894610" class="c"><input type="checkbox" id="c-41894610" checked=""/><div class="controls bullet"><span class="by">mensetmanusman</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41891445">prev</a><span>|</span><a href="#41891844">next</a><span>|</span><label class="collapse" for="c-41894610">[-]</label><label class="expand" for="c-41894610">[6 more]</label></div><br/><div class="children"><div class="content">Software requires hardware that can bit flip with gamma rays.</div><br/><div id="41894885" class="c"><input type="checkbox" id="c-41894885" checked=""/><div class="controls bullet"><span class="by">aaronmdjones</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894610">parent</a><span>|</span><a href="#41894887">next</a><span>|</span><label class="collapse" for="c-41894885">[-]</label><label class="expand" for="c-41894885">[3 more]</label></div><br/><div class="children"><div class="content">Which is why hardware used to run safety-critical software is made redundant.<p>Take the Boeing 777 Primary Flight Computer for example. This is a fully digital fly-by-wire aircraft. There are 3 separate racks of equipment housing identical flight computers; 2 in the avionics bay underneath the flight deck, 1 in the aft cargo section. Each flight computer has 3 separate processors, supporting 2 dissimilar instruction set architectures, running the same software built by 3 separate compilers. Each flight computer captures instances of the software not agreeing about an action to be undertaken and wins by majority vote. The processor that makes these decisions is different in each flight computer.<p>The power systems that provide each flight computer are also fully redundant; each computer gets power from a power supply assembly, which receives 2 power feeds from 3 separate power supplies; no 2 power supply assemblies share the same 2 sources of power. 2 of the 3 power systems (L engine generator, R engine generator, and the hot battery bus) would have to fail and the APU would have to be unavailable in order to knock out 1 of the 3 computers.<p>This system has never failed in 30 years of service. There&#x27;s still a primary flight computer disconnect switch on the overhead panel in the cockpit, taking the software out of the loop, to logically connect all of your control inputs to the flight surface actuators. I&#x27;m not aware of it ever being used (edit: in a commercial flight).</div><br/><div id="41895814" class="c"><input type="checkbox" id="c-41895814" checked=""/><div class="controls bullet"><span class="by">mensetmanusman</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894885">parent</a><span>|</span><a href="#41894887">next</a><span>|</span><label class="collapse" for="c-41895814">[-]</label><label class="expand" for="c-41895814">[2 more]</label></div><br/><div class="children"><div class="content">You can’t guarantee the hardware was properly built.</div><br/><div id="41895873" class="c"><input type="checkbox" id="c-41895873" checked=""/><div class="controls bullet"><span class="by">aaronmdjones</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895814">parent</a><span>|</span><a href="#41894887">next</a><span>|</span><label class="collapse" for="c-41895873">[-]</label><label class="expand" for="c-41895873">[1 more]</label></div><br/><div class="children"><div class="content">Unless Intel, Motorola, and AMD all conspire to give you a faulty processor, you will get a working primary flight computer.<p>Besides, this is what flight testing is for. Aviation certification authorities don&#x27;t let an aircraft serve passengers unless you can demonstrate that all of its safety-critical systems work properly and that it performs as described.<p>I find it hard to believe that automotive works much differently in this regard, which is what things like crumple zone crash tests are for.</div><br/></div></div></div></div></div></div><div id="41894887" class="c"><input type="checkbox" id="c-41894887" checked=""/><div class="controls bullet"><span class="by">chgs</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894610">parent</a><span>|</span><a href="#41894885">prev</a><span>|</span><a href="#41894643">next</a><span>|</span><label class="collapse" for="c-41894887">[-]</label><label class="expand" for="c-41894887">[1 more]</label></div><br/><div class="children"><div class="content">You can control for that. Multiple machines doing is rival calculations for example</div><br/></div></div></div></div><div id="41891844" class="c"><input type="checkbox" id="c-41891844" checked=""/><div class="controls bullet"><span class="by">dansiemens</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41894610">prev</a><span>|</span><a href="#41894812">next</a><span>|</span><label class="collapse" for="c-41891844">[-]</label><label class="expand" for="c-41891844">[6 more]</label></div><br/><div class="children"><div class="content">Are you suggesting that individuals should carry that liability?</div><br/><div id="41893851" class="c"><input type="checkbox" id="c-41893851" checked=""/><div class="controls bullet"><span class="by">izacus</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891844">parent</a><span>|</span><a href="#41894812">next</a><span>|</span><label class="collapse" for="c-41893851">[-]</label><label class="expand" for="c-41893851">[5 more]</label></div><br/><div class="children"><div class="content">The ones that are identified as making decisions leading to death, yes.<p>It&#x27;s completely normal in other fields where engineers build systems that can kill.</div><br/><div id="41901038" class="c"><input type="checkbox" id="c-41901038" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893851">parent</a><span>|</span><a href="#41894849">next</a><span>|</span><label class="collapse" for="c-41901038">[-]</label><label class="expand" for="c-41901038">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s liability for defective design, not <i>any time it fails</i> as suggested above.</div><br/></div></div><div id="41894849" class="c"><input type="checkbox" id="c-41894849" checked=""/><div class="controls bullet"><span class="by">A4ET8a8uTh0</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893851">parent</a><span>|</span><a href="#41901038">prev</a><span>|</span><a href="#41894812">next</a><span>|</span><label class="collapse" for="c-41894849">[-]</label><label class="expand" for="c-41894849">[3 more]</label></div><br/><div class="children"><div class="content">Pretty much. Fuck. I just watched higher ups sign off on a project I know for a fact has defects all over the place going into production despite our very explicit: don&#x27;t do it ( not quite Tesla level consequences, but still resulting in real issues for real people ). The sooner we can start having people in jail for knowingly approving half-baked software, the sooner it will improve.</div><br/><div id="41895257" class="c"><input type="checkbox" id="c-41895257" checked=""/><div class="controls bullet"><span class="by">IX-103</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894849">parent</a><span>|</span><a href="#41894812">next</a><span>|</span><label class="collapse" for="c-41895257">[-]</label><label class="expand" for="c-41895257">[2 more]</label></div><br/><div class="children"><div class="content">Should we require Professional Engineers to sign off on such projects the same way they are required to for other safety critical infrastructure (like bridges and dams)? The Professional Engineer that signed off is liable for defects in the design. (Though, of course, if the design is not followed then liability can shift back to the company that built it)</div><br/><div id="41898367" class="c"><input type="checkbox" id="c-41898367" checked=""/><div class="controls bullet"><span class="by">A4ET8a8uTh0</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895257">parent</a><span>|</span><a href="#41894812">next</a><span>|</span><label class="collapse" for="c-41898367">[-]</label><label class="expand" for="c-41898367">[1 more]</label></div><br/><div class="children"><div class="content">I hesitate, because I shudder at government deciding which algorithm is best for a given scenario ( because that is effectively is where it would go ). Maybe the distinction is, the moment money changes hands based on product?<p>I am not an engineer, but I have watched clearly bad decisions take place from technical perspective so that a person with title that went to their head and a bonus that is not aligned with right incentives mess things up for us. Maybe some proffesionalization of software engineering is in order.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41894812" class="c"><input type="checkbox" id="c-41894812" checked=""/><div class="controls bullet"><span class="by">ekianjo</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41891844">prev</a><span>|</span><a href="#41895100">next</a><span>|</span><label class="collapse" for="c-41894812">[-]</label><label class="expand" for="c-41894812">[2 more]</label></div><br/><div class="children"><div class="content">How is that working with Boeing?</div><br/><div id="41895001" class="c"><input type="checkbox" id="c-41895001" checked=""/><div class="controls bullet"><span class="by">mlinhares</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894812">parent</a><span>|</span><a href="#41895100">next</a><span>|</span><label class="collapse" for="c-41895001">[-]</label><label class="expand" for="c-41895001">[1 more]</label></div><br/><div class="children"><div class="content">People often forget corporations don’t go to jail. Murder when you’re not a person ends up with a slap.</div><br/></div></div></div></div><div id="41895100" class="c"><input type="checkbox" id="c-41895100" checked=""/><div class="controls bullet"><span class="by">bossyTeacher</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41894812">prev</a><span>|</span><a href="#41891631">next</a><span>|</span><label class="collapse" for="c-41895100">[-]</label><label class="expand" for="c-41895100">[2 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t seem to happen in the medical and airplane industries, otherwise, Boeing would most likely not exist as a company anymore.</div><br/><div id="41895177" class="c"><input type="checkbox" id="c-41895177" checked=""/><div class="controls bullet"><span class="by">jsvlrtmred</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895100">parent</a><span>|</span><a href="#41891631">next</a><span>|</span><label class="collapse" for="c-41895177">[-]</label><label class="expand" for="c-41895177">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps one can debate whether it happens often enough or severely enough, but it certainly <i>happens</i>. For example, and only the first one to come to mind - the president of PIP went to jail.</div><br/></div></div></div></div><div id="41891631" class="c"><input type="checkbox" id="c-41891631" checked=""/><div class="controls bullet"><span class="by">dmix</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41895100">prev</a><span>|</span><a href="#41892572">next</a><span>|</span><label class="collapse" for="c-41891631">[-]</label><label class="expand" for="c-41891631">[20 more]</label></div><br/><div class="children"><div class="content">Drug companies and the FDA (circa 1906) play a very dangerous and delicate dance all the time releasing new drugs to the public. But for over a century now we&#x27;ve managed to figure it out without holding pharma companies criminally liable for every death.<p>&gt; If you write software that people rely on with their lives, and it fails, you should be held liable for that criminally.<p>Easy to type those words on the internet than make it a policy IRL. That sort of policy IRL would likely result in a) killing off all commercial efforts to solve traffic deaths via technology and vast amounts of other semi-autonomous technology like farm equipment or b) government&#x2F;car companies mandating filming the driver every time they turn it on, because it&#x27;s technically supposed to be human assisted autopilot in these testing stages (outside restricted pilot programs like Waymo taxis). Those distinctions would matter in a criminal court room, even if humans can&#x27;t always be relied upon to always follow the instructions on the bottle&#x27;s label.</div><br/><div id="41893456" class="c"><input type="checkbox" id="c-41893456" checked=""/><div class="controls bullet"><span class="by">ywvcbk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891631">parent</a><span>|</span><a href="#41892069">next</a><span>|</span><label class="collapse" for="c-41893456">[-]</label><label class="expand" for="c-41893456">[9 more]</label></div><br/><div class="children"><div class="content">&gt; criminally liable for every death.<p>The fact that people generally consume drugs voluntarily and make that decision after being informed about most of the known risks probably mitigates that to some extent. Being killed by someone else’s FSD car seems to be very different</div><br/><div id="41893905" class="c"><input type="checkbox" id="c-41893905" checked=""/><div class="controls bullet"><span class="by">sokoloff</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893456">parent</a><span>|</span><a href="#41894860">next</a><span>|</span><label class="collapse" for="c-41893905">[-]</label><label class="expand" for="c-41893905">[6 more]</label></div><br/><div class="children"><div class="content">Imagine that in 2031, FSD cars could exactly halve all aspects of auto crashes (minor, major, single car, multi car, vs pedestrian, fatal&#x2F;non, etc.)<p>Would you want FSD software to be developed or not? If you do, do you think holding devs or companies criminally liable for half of all crashes is the best way to ensure that progress happens?</div><br/><div id="41895047" class="c"><input type="checkbox" id="c-41895047" checked=""/><div class="controls bullet"><span class="by">ywvcbk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893905">parent</a><span>|</span><a href="#41894272">next</a><span>|</span><label class="collapse" for="c-41895047">[-]</label><label class="expand" for="c-41895047">[4 more]</label></div><br/><div class="children"><div class="content">From a utilitarian perspective sure, you might be right but how do you exempt those companies from civil liability and make it impossible for victims&#x2F;their families to sue the manufacturer? Might be legally tricky (driver&#x2F;owner can explicitly&#x2F;implicitly agree with the EULA or other agreements, imposing that on third parties wouldn’t be right).</div><br/><div id="41895366" class="c"><input type="checkbox" id="c-41895366" checked=""/><div class="controls bullet"><span class="by">Majromax</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895047">parent</a><span>|</span><a href="#41894272">next</a><span>|</span><label class="collapse" for="c-41895366">[-]</label><label class="expand" for="c-41895366">[3 more]</label></div><br/><div class="children"><div class="content">&gt; how do you exempt those companies from civil liability and make it impossible for victims&#x2F;their families to sue the manufacturer?<p>I don&#x27;t think anyone in this thread has talked about an exemption from <i>civil</i> liability (sue for money), just criminal liability (go to jail).<p>Civil liability is the far less controversial issue because it&#x27;s transferred all the time: governments even mandate that drivers carry insurance for this purpose.<p>With civil liability transfer, imperfect FSD can still make economic sense.  Just as an insurance company needs to collect enough premium to pay claims, the FSD manufacturer would need to reserve enough revenue to pay its expected claims.  In this case, FSD doesn&#x27;t even need to be better than humans to make economic sense, in the same way that bad drivers can still buy (expensive) insurance.</div><br/><div id="41895467" class="c"><input type="checkbox" id="c-41895467" checked=""/><div class="controls bullet"><span class="by">ywvcbk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895366">parent</a><span>|</span><a href="#41895767">next</a><span>|</span><label class="collapse" for="c-41895467">[-]</label><label class="expand" for="c-41895467">[1 more]</label></div><br/><div class="children"><div class="content">&gt; just criminal liability (go to jail).<p>That just seems like a theoretical possibility (even if that). I don’t see how any engineer or even someone in management could go to jail unless intent or gross negligence can be proven.<p>&gt; drivers carry insurance for this purpose.<p>The mandatory limit is extremely  low in many US states.<p>&gt; expected claims<p>That seems like the problem. It might take a while until we reach an equilibrium of some sort.<p>&gt; that bad drivers can still buy<p>That’s still capped by the amount of coverage + total assets held by that bad driver. In Tesl’s case there is no real limit (without legislation&#x2F;established precedent). Juries&#x2F;courts would likely be influenced by that fact as well.</div><br/></div></div><div id="41895767" class="c"><input type="checkbox" id="c-41895767" checked=""/><div class="controls bullet"><span class="by">DennisP</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895366">parent</a><span>|</span><a href="#41895467">prev</a><span>|</span><a href="#41894272">next</a><span>|</span><label class="collapse" for="c-41895767">[-]</label><label class="expand" for="c-41895767">[1 more]</label></div><br/><div class="children"><div class="content">In fact, if you buy your insurance from Tesla, you effectively do put civil responsibility for FSD back in their hands.</div><br/></div></div></div></div></div></div><div id="41894272" class="c"><input type="checkbox" id="c-41894272" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893905">parent</a><span>|</span><a href="#41895047">prev</a><span>|</span><a href="#41894860">next</a><span>|</span><label class="collapse" for="c-41894272">[-]</label><label class="expand" for="c-41894272">[1 more]</label></div><br/><div class="children"><div class="content">Say cars have near 0 casualty in northern hemisphere but occasionally fails for cars driving topsy turvy in south. If company knew about it and chooses to ignore it because of profits, yes they should be charged criminally.</div><br/></div></div></div></div><div id="41894860" class="c"><input type="checkbox" id="c-41894860" checked=""/><div class="controls bullet"><span class="by">ekianjo</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893456">parent</a><span>|</span><a href="#41893905">prev</a><span>|</span><a href="#41892069">next</a><span>|</span><label class="collapse" for="c-41894860">[-]</label><label class="expand" for="c-41894860">[2 more]</label></div><br/><div class="children"><div class="content">&gt; make that decision after being informed about most of the known risks<p>Like for the COVID-19 vaccines? Experimental yet given to billions without ever showing them a consent form.</div><br/><div id="41895076" class="c"><input type="checkbox" id="c-41895076" checked=""/><div class="controls bullet"><span class="by">ywvcbk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894860">parent</a><span>|</span><a href="#41892069">next</a><span>|</span><label class="collapse" for="c-41895076">[-]</label><label class="expand" for="c-41895076">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but worse. Nobody physically forced anyone to get vaccinated so you still had some choice. Of course legally banning individuals from using public roads or sidewalks unless they give up their right to sue Tesla&#x2F;etc. might be an option.</div><br/></div></div></div></div></div></div><div id="41892069" class="c"><input type="checkbox" id="c-41892069" checked=""/><div class="controls bullet"><span class="by">hilsdev</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891631">parent</a><span>|</span><a href="#41893456">prev</a><span>|</span><a href="#41892028">next</a><span>|</span><label class="collapse" for="c-41892069">[-]</label><label class="expand" for="c-41892069">[1 more]</label></div><br/><div class="children"><div class="content">We should hold Pharma companies liable for every death. They make money off the success cases. Not doing so is another example of privatized profits and socialized risks&#x2F;costs. Something like a program with reduced costs for those willing to sign away liability to help balance social good vs risk analysis</div><br/></div></div><div id="41892028" class="c"><input type="checkbox" id="c-41892028" checked=""/><div class="controls bullet"><span class="by">ryandrake</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891631">parent</a><span>|</span><a href="#41892069">prev</a><span>|</span><a href="#41892572">next</a><span>|</span><label class="collapse" for="c-41892028">[-]</label><label class="expand" for="c-41892028">[9 more]</label></div><br/><div class="children"><div class="content">Your take is understandable and not surprising on a site full of software developers. Somehow, the general software industry has ingrained this pessimistic and fatalistic dogma that says bugs are inevitable and there’s nothing you can do to prevent them. Since everyone believes it, it is a self-fulfilling prophecy and we just accept it as some kind of law of nature.<p>Holding software developers (or their companies) liable for defects would definitely kill off a part of the industry: the very large part that YOLOs code into production and races to get features released without rigorous and exhaustive testing. And why don’t they spend 90% of their time testing and verifying and proving their software has no defects? Because defects are inevitable and they’re not held accountable for them!</div><br/><div id="41892653" class="c"><input type="checkbox" id="c-41892653" checked=""/><div class="controls bullet"><span class="by">everforward</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892028">parent</a><span>|</span><a href="#41893804">next</a><span>|</span><label class="collapse" for="c-41892653">[-]</label><label class="expand" for="c-41892653">[4 more]</label></div><br/><div class="children"><div class="content">It is true of every field I can think of. Food gets salmonella and what not frequently. Surgeons forget sponges inside of people (and worse). Truckers run over cars. Manufacturers miss some failures in QA.<p>Literally everywhere else, we accept that the costs of 100% safety are just unreasonably high. People would rather have a mostly safe device for $1 than a definitely safe one for $5. No one wants to pay to have every head of lettuce tested for E Coli, or truckers to drive at 10mph so they can’t kill anyone.<p>Software isn’t different. For the vast majority of applications where the costs of failure are low to none, people want it to be free and rapidly iterated on even if it fails. No one wants to pay for a formally verified Facebook or DoorDash.</div><br/><div id="41893620" class="c"><input type="checkbox" id="c-41893620" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892653">parent</a><span>|</span><a href="#41893804">next</a><span>|</span><label class="collapse" for="c-41893620">[-]</label><label class="expand" for="c-41893620">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Literally everywhere else, we accept that the costs of 100% safety are just unreasonably high.<p>Yes, but also in none of these situations would the consumer&#x2F;customer&#x2F;patient be held responsible. I don’t expect a  system to be perfect, but I won’t accept any liability if it malfunctions as I use it the way it is intended. And even worse, I would not accept that the designers evade their responsibilities if it kills someone I know.<p>As the other poster said, I am happy to consider it safe enough the day the company accepts to own its issues and the associated responsibility.<p>&gt; No one wants to pay for a formally verified Facebook or DoorDash.<p>This is untenable. Does nobody want a formally verified avionics system in their airliner, either?</div><br/><div id="41895466" class="c"><input type="checkbox" id="c-41895466" checked=""/><div class="controls bullet"><span class="by">everforward</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893620">parent</a><span>|</span><a href="#41893804">next</a><span>|</span><label class="collapse" for="c-41895466">[-]</label><label class="expand" for="c-41895466">[2 more]</label></div><br/><div class="children"><div class="content">You could be held liable if it impacts someone else. A restaurant serving improperly cooked chicken that gives people E Coli is liable. Private citizens may not have that duty, I’m not sure.<p>You would likely also be liable if you overloaded an electrical cable, causing a fire that killed someone.<p>“Using it in the way it was intended” is largely circular reasoning; of course it wasn’t intended to hurt anyone, so any usage that does hurt someone was clearly unintended. People frequently harm each other by misusing items in ways they didn’t realize were misuses.<p>&gt; This is untenable. Does nobody want a formally verified avionics system in their airliner, either?<p>Not for the price it would cost. Airbus is the pioneer here, and even they apply formal verification sparingly. Here’s a paper from a few years ago about it, and how it’s untenable to formally verify the whole thing: <a href="https:&#x2F;&#x2F;www.di.ens.fr&#x2F;~delmas&#x2F;papers&#x2F;fm09.pdf" rel="nofollow">https:&#x2F;&#x2F;www.di.ens.fr&#x2F;~delmas&#x2F;papers&#x2F;fm09.pdf</a><p>Software development effort generally tends to scale superlinearly with complexity. I am not an expert, but the impression I get is that formal verification grows exponentially with complexity to the point that it is untenable for most things beyond research and fairly simple problems. It is a huge pain in the ass to do something like putting time bounds around reading a config file.<p>IO also sucks in formal verification from what I hear, and that’s like 80% of what a plane does. Read these 300 signals, do some standard math, output new signals to controls.<p>These things are much easier to do with tests, but tests only check for scenarios you’ve thought of already</div><br/><div id="41898516" class="c"><input type="checkbox" id="c-41898516" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895466">parent</a><span>|</span><a href="#41893804">next</a><span>|</span><label class="collapse" for="c-41898516">[-]</label><label class="expand" for="c-41898516">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You could be held liable if it impacts someone else. A restaurant serving improperly cooked chicken that gives people E Coli is liable. Private citizens may not have that duty, I’m not sure.
&gt; You would likely also be liable if you overloaded an electrical cable, causing a fire that killed someone.<p>Right. But neither of these examples are following guidelines or proper use. If I turn the car into people on the pavement, I am responsible. If the steering wheel breaks and the car does it, then the manufacturer is responsible (or the mechanic, if the steering wheel was changed). The question at hand is whose responsibility it is if the car’s software does it.<p>&gt; “Using it in the way it was intended” is largely circular reasoning; of course it wasn’t intended to hurt anyone, so any usage that does hurt someone was clearly unintended.<p>This is puzzling. You seem to be conflating use and consequences and I am not quite sure how you read that in what I wrote. Using a device normally should not make it kill people, I guess at least we can agree on that. Therefore, if a device kills people, then it is either improper use (and the fault of the user), or a defective device, at which point it is the fault of the designer or manufacturer (or whoever did the maintenance, as the case might be, but that’s irrelevant in this case).<p>Each device has a manual and a bunch of regulations about its expected behaviour and standard operating procedures. There is nothing circular about it.<p>&gt; Not for the price it would cost.<p>Ok, if you want to go full pedantic, note that I wrote “want”, not “expect”.</div><br/></div></div></div></div></div></div></div></div><div id="41893804" class="c"><input type="checkbox" id="c-41893804" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892028">parent</a><span>|</span><a href="#41892653">prev</a><span>|</span><a href="#41893464">next</a><span>|</span><label class="collapse" for="c-41893804">[-]</label><label class="expand" for="c-41893804">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And why don’t they spend 90% of their time testing and verifying and proving their software has no defects? Because defects are inevitable and they’re not held accountable for them!<p>For a huge part of the industry, the reason is entirely different. It is because software that mostly works today but has defects is <i>much</i> more valuable than software that always works and has no defects 10 years from now. Extremely well informed business customers will pay for delivering a buggy feature today rather than wait two more months for a comprehensively tested feature. This is the reality of the majority of the industry: consumers care little about bugs (below some defect rate) and care far more about timeliness.<p>This of course doesn&#x27;t apply to critical systems like automatic drivers or medical devices. But the vast majority of the industry is not building these types of systems.</div><br/></div></div><div id="41893464" class="c"><input type="checkbox" id="c-41893464" checked=""/><div class="controls bullet"><span class="by">ywvcbk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892028">parent</a><span>|</span><a href="#41893804">prev</a><span>|</span><a href="#41892592">next</a><span>|</span><label class="collapse" for="c-41893464">[-]</label><label class="expand" for="c-41893464">[2 more]</label></div><br/><div class="children"><div class="content">Punishing individual developers is of course absurd (unless intent can be proven) the company itself and the upper management on the hand? Would make perfect sense.</div><br/><div id="41894921" class="c"><input type="checkbox" id="c-41894921" checked=""/><div class="controls bullet"><span class="by">chgs</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893464">parent</a><span>|</span><a href="#41892592">next</a><span>|</span><label class="collapse" for="c-41894921">[-]</label><label class="expand" for="c-41894921">[1 more]</label></div><br/><div class="children"><div class="content">You have one person in that RACI accountable box. That’s the engineer signing it off as fit. They are held accountable, including with jail if required.</div><br/></div></div></div></div><div id="41892592" class="c"><input type="checkbox" id="c-41892592" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892028">parent</a><span>|</span><a href="#41893464">prev</a><span>|</span><a href="#41892572">next</a><span>|</span><label class="collapse" for="c-41892592">[-]</label><label class="expand" for="c-41892592">[1 more]</label></div><br/><div class="children"><div class="content">&gt; that says bugs are inevitable and there’s nothing you can do to prevent them<p>I don&#x27;t think people believe this as such. It may be the short way to write it, but actually what devs mean is &quot;bugs are inevitable at the funding&#x2F;time available&quot;. I often say &quot;bugs are inevitable&quot; when it practice it means &quot;you&#x27;re not going to pay a team for formal specification, validated implementation and enough reliable hardware&quot;.<p>Which business will agree to making the process 5x longer and require extra people? Especially if they&#x27;re not forced there by regulation or potential liability?</div><br/></div></div></div></div></div></div><div id="41892572" class="c"><input type="checkbox" id="c-41892572" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41891631">prev</a><span>|</span><a href="#41891890">next</a><span>|</span><label class="collapse" for="c-41892572">[-]</label><label class="expand" for="c-41892572">[25 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a dangerous line and I don&#x27;t think it&#x27;s correct. Software I write shouldn&#x27;t be relied on in critical situations. If someone makes that decision then it&#x27;s on them not on me.<p>The line should be where a person tells others that they can rely on the software with their lives - as in the integrator for the end product. Even if I was working on the software for self driving, the same thing would apply - if I wrote some alpha level stuff for the internal demonstration and some manager decided &quot;good enough, ship it&quot;, they should be liable for that decision. (Because I wouldn&#x27;t be able to stop them &#x2F; may have already left by then)</div><br/><div id="41893594" class="c"><input type="checkbox" id="c-41893594" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892572">parent</a><span>|</span><a href="#41892970">next</a><span>|</span><label class="collapse" for="c-41893594">[-]</label><label class="expand" for="c-41893594">[12 more]</label></div><br/><div class="children"><div class="content">It’s not that complicated or outlandish. That’s how most engineering fields work. If a building collapses because of design flaws, then the builders and architects can be held responsible. Hell, if a car crashes because of a design or assembly flaw, the manufacturer is held responsible. Why should self-driving software be any different?<p>If the software is not reliable enough, then don’t use it in a context where it could kill people.</div><br/><div id="41894185" class="c"><input type="checkbox" id="c-41894185" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893594">parent</a><span>|</span><a href="#41892970">next</a><span>|</span><label class="collapse" for="c-41894185">[-]</label><label class="expand" for="c-41894185">[11 more]</label></div><br/><div class="children"><div class="content">I think the example here is that the designer draws a bridge for a railway model, and someone decides to use the same design and sends real locomotives across it. Is the original designer (who neither intended nor could have foreseen this) liable in your understanding?</div><br/><div id="41894354" class="c"><input type="checkbox" id="c-41894354" checked=""/><div class="controls bullet"><span class="by">ndsipa_pomu</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894185">parent</a><span>|</span><a href="#41894366">next</a><span>|</span><label class="collapse" for="c-41894354">[-]</label><label class="expand" for="c-41894354">[7 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a ridiculous argument.<p>If a construction firm takes an arbitrary design and then tries to build it in a totally different environment and for a different purpose, then the construction firm is liable, not the original designer. It&#x27;d be like Boeing taking a child&#x27;s paper aeroplane design and making a passenger jet out of it and then blaming the child when it inevitably fails.</div><br/><div id="41894653" class="c"><input type="checkbox" id="c-41894653" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894354">parent</a><span>|</span><a href="#41895101">next</a><span>|</span><label class="collapse" for="c-41894653">[-]</label><label class="expand" for="c-41894653">[1 more]</label></div><br/><div class="children"><div class="content">Or alternatively, if Boeing uses wood screws to attach an airplane door and the screw fails that&#x27;s on Boeing, not the airline, pilot or screw manufacturer. But if it&#x27;s sold as aerospace-grade attachment bolt with attachments for safety wire and a spec sheet that suggests the required loads are within design parameters then it&#x27;s the bolt manufacturers fault when it fails, and they might have to answer for any deaths resulting from that. Unless Boeing knew or should have known that the bolts weren&#x27;t actually as good as claimed, then the buck passes back to them<p>Of course that&#x27;s wildly oversimplifying and multiple entities can be at fault at once. My point is that these are normal things considered in regular engineering and manufacturing</div><br/></div></div><div id="41895101" class="c"><input type="checkbox" id="c-41895101" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894354">parent</a><span>|</span><a href="#41894653">prev</a><span>|</span><a href="#41894574">next</a><span>|</span><label class="collapse" for="c-41895101">[-]</label><label class="expand" for="c-41895101">[4 more]</label></div><br/><div class="children"><div class="content">&gt; That&#x27;s a ridiculous argument.<p>Not making an argument. Asking a clarifying question about someone else’s.<p>&gt; It&#x27;d be like Boeing taking a child&#x27;s paper aeroplane design and making a passenger jet out of it and then blaming the child when it inevitably fails.<p>Yes exactly. You are using the same example I used to say the same thing. So which part of my message was ridiculous?</div><br/><div id="41895440" class="c"><input type="checkbox" id="c-41895440" checked=""/><div class="controls bullet"><span class="by">ndsipa_pomu</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895101">parent</a><span>|</span><a href="#41894574">next</a><span>|</span><label class="collapse" for="c-41895440">[-]</label><label class="expand" for="c-41895440">[3 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s not an argument, then you&#x27;re just misrepresenting your parent poster&#x27;s comment by introducing a scenario that never happens.<p>If you didn&#x27;t intend your comment as a criticism, then you phrased it poorly. Do you actually believe that your scenario happens in reality?</div><br/><div id="41897990" class="c"><input type="checkbox" id="c-41897990" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895440">parent</a><span>|</span><a href="#41895781">next</a><span>|</span><label class="collapse" for="c-41897990">[-]</label><label class="expand" for="c-41897990">[1 more]</label></div><br/><div class="children"><div class="content">&gt; you&#x27;re just misrepresenting your parent poster&#x27;s comment<p>I did not represent or misrepresent anything. I have asked a question to better understand their thinking.<p>&gt; If you didn&#x27;t intend your comment as a criticism, then you phrased it poorly.<p>Quite probably. I will have to meditate on it.<p>&gt; Do you actually believe that your scenario happens in reality?<p>With railway bridges? Never. It would ring alarm bells for everyone from the fabricators to the locomotive engineer.<p>With software? All the time. Someone publishes some open source code, someone else at a corporation bolts the open source code into some application and now the former “toy train bridge” is a loadbearing key-component of something the original developer could never imagine nor plan for.<p>This is not theoretical. Very often I’m the one doing the bolting.<p>And to be clear: my opinion is that the liability should fall with whoever integrated the code and certified it to be fit for some safety critical purpose. As an example if you publish leftpad and i put it into a train brake controller it is my job to make sure it is doing the right thing. If the train crashes you as the author of leftpad bear no responsibility but me as the manufacturer of discount train brakes do.</div><br/></div></div><div id="41895781" class="c"><input type="checkbox" id="c-41895781" checked=""/><div class="controls bullet"><span class="by">lcnPylGDnU4H9OF</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895440">parent</a><span>|</span><a href="#41897990">prev</a><span>|</span><a href="#41894574">next</a><span>|</span><label class="collapse" for="c-41895781">[-]</label><label class="expand" for="c-41895781">[1 more]</label></div><br/><div class="children"><div class="content">It was not a misrepresentation of anything. They were just restating the worry that was stated in the GP comment. <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41892572">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41892572</a><p>And the only reason the commenter I linked to had that response is because its parent comment was slightly careless in its phrasing. Probably just change “write” to “deploy” to capture the intended meaning.</div><br/></div></div></div></div></div></div></div></div><div id="41894366" class="c"><input type="checkbox" id="c-41894366" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894185">parent</a><span>|</span><a href="#41894354">prev</a><span>|</span><a href="#41894816">next</a><span>|</span><label class="collapse" for="c-41894366">[-]</label><label class="expand" for="c-41894366">[1 more]</label></div><br/><div class="children"><div class="content">Someone, at some point signed off on this being released. Not thinking things through seriously is not an excuse to sell defective cars.</div><br/></div></div><div id="41894816" class="c"><input type="checkbox" id="c-41894816" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894185">parent</a><span>|</span><a href="#41894366">prev</a><span>|</span><a href="#41892970">next</a><span>|</span><label class="collapse" for="c-41894816">[-]</label><label class="expand" for="c-41894816">[2 more]</label></div><br/><div class="children"><div class="content">Are you serious?! You must be trolling!</div><br/><div id="41895151" class="c"><input type="checkbox" id="c-41895151" checked=""/><div class="controls bullet"><span class="by">krisoft</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894816">parent</a><span>|</span><a href="#41892970">next</a><span>|</span><label class="collapse" for="c-41895151">[-]</label><label class="expand" for="c-41895151">[1 more]</label></div><br/><div class="children"><div class="content">I assure you I am not trolling. You appear to have misread my message.<p>Take a deep breath. Read my message one more time carefully.  Notice the question mark at the end of the last sentence. Think about it. If after that you still think I’m trolling you or anyone else I will be here and happy to respond to your further questions.</div><br/></div></div></div></div></div></div></div></div><div id="41892970" class="c"><input type="checkbox" id="c-41892970" checked=""/><div class="controls bullet"><span class="by">presentation</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892572">parent</a><span>|</span><a href="#41893594">prev</a><span>|</span><a href="#41895839">next</a><span>|</span><label class="collapse" for="c-41892970">[-]</label><label class="expand" for="c-41892970">[11 more]</label></div><br/><div class="children"><div class="content">To be fair maybe the software you write shouldn’t be relied on in critical situations but in this case the only place this software could be used in are critical situations</div><br/><div id="41893226" class="c"><input type="checkbox" id="c-41893226" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892970">parent</a><span>|</span><a href="#41895839">next</a><span>|</span><label class="collapse" for="c-41893226">[-]</label><label class="expand" for="c-41893226">[10 more]</label></div><br/><div class="children"><div class="content">Ultimately - yes. But as I mentioned, the fact it&#x27;s sold as ready for critical situations doesn&#x27;t mean the developers thought&#x2F;said it&#x27;s ready.</div><br/><div id="41893726" class="c"><input type="checkbox" id="c-41893726" checked=""/><div class="controls bullet"><span class="by">gmueckl</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893226">parent</a><span>|</span><a href="#41893722">next</a><span>|</span><label class="collapse" for="c-41893726">[-]</label><label class="expand" for="c-41893726">[5 more]</label></div><br/><div class="children"><div class="content">But someone slapped that label on it and made a pinky promise that it&#x27;s true. That person needs to accept liability if things go wrong. If person A is loud and clear that something isn&#x27;t ready, but person B tells the customer otherwise, B is at fault.<p>Look, there are well established procedures in a lot of industries where products are relied on to keep people safe. They all require quite rigorous development and certification processes and sneaking untested alpha quality software through such a process would be actively malicious and quite possibly criminal in and of itself, at least in some industries.</div><br/><div id="41893832" class="c"><input type="checkbox" id="c-41893832" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893726">parent</a><span>|</span><a href="#41893722">next</a><span>|</span><label class="collapse" for="c-41893832">[-]</label><label class="expand" for="c-41893832">[4 more]</label></div><br/><div class="children"><div class="content">This is the beginning of the thread <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41891164">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41891164</a><p>You&#x27;re in violent agreement with me ;)</div><br/><div id="41893935" class="c"><input type="checkbox" id="c-41893935" checked=""/><div class="controls bullet"><span class="by">latexr</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893832">parent</a><span>|</span><a href="#41893722">next</a><span>|</span><label class="collapse" for="c-41893935">[-]</label><label class="expand" for="c-41893935">[3 more]</label></div><br/><div class="children"><div class="content">No, the beginning of the thread is earlier. And with that context it seems clear to me that the “you” in the post you linked means “the company”, not “the individual software developer”. No one else in your replies seems confused by that, we all understand self-driving software wasn’t written by a single person that has ultimate decision power within a company.</div><br/><div id="41894186" class="c"><input type="checkbox" id="c-41894186" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893935">parent</a><span>|</span><a href="#41893722">next</a><span>|</span><label class="collapse" for="c-41894186">[-]</label><label class="expand" for="c-41894186">[2 more]</label></div><br/><div class="children"><div class="content">If the message said &quot;you release software&quot;, or &quot;approve&quot; or &quot;produce&quot;, or something like that, sure. But it said &quot;you write software&quot; - and I don&#x27;t think that can apply to a company, because writing is what individuals do. But yeah, maybe that&#x27;s not what the author meant.</div><br/><div id="41894422" class="c"><input type="checkbox" id="c-41894422" checked=""/><div class="controls bullet"><span class="by">latexr</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894186">parent</a><span>|</span><a href="#41893722">next</a><span>|</span><label class="collapse" for="c-41894422">[-]</label><label class="expand" for="c-41894422">[1 more]</label></div><br/><div class="children"><div class="content">&gt; and I don&#x27;t think that can apply to a company, because writing is what individuals do.<p>By that token, no action could ever apply to a company—including approving, producing, or releasing—since it is a legal entity, a concept, not a physical thing. For all those actions there was a person actually doing it in the name of the company.<p>It’s perfectly normal to say, for example, “GenericCorp wrote a press-release about their new product”.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41893722" class="c"><input type="checkbox" id="c-41893722" checked=""/><div class="controls bullet"><span class="by">elric</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893226">parent</a><span>|</span><a href="#41893726">prev</a><span>|</span><a href="#41895839">next</a><span>|</span><label class="collapse" for="c-41893722">[-]</label><label class="expand" for="c-41893722">[4 more]</label></div><br/><div class="children"><div class="content">I think it should be fairly obvious that it&#x27;s not the individual developers who are responsible&#x2F;liable. In critical systems there is a whole chain of liability. That one guy in Nebraska who thanklessly maintains some open source lib that BigCorp is using in their car should obviously not be liable.</div><br/><div id="41894847" class="c"><input type="checkbox" id="c-41894847" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893722">parent</a><span>|</span><a href="#41895839">next</a><span>|</span><label class="collapse" for="c-41894847">[-]</label><label class="expand" for="c-41894847">[3 more]</label></div><br/><div class="children"><div class="content">It depends. If you do bad sw and skip reviews and processes, you may be liable. Even if you are told to do something, if you know is wrong, you should say it. Right now I’m in middle of s*t because of I spoked up.</div><br/><div id="41896160" class="c"><input type="checkbox" id="c-41896160" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894847">parent</a><span>|</span><a href="#41895839">next</a><span>|</span><label class="collapse" for="c-41896160">[-]</label><label class="expand" for="c-41896160">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Right now I’m in middle of s*t because of I spoked up.<p>And you believe that, despite experiencing what happens if you speak up?<p>We shouldn’t simultaneously require people to take heroic responsibility, while also leaving them high and dry if they do.</div><br/><div id="41896521" class="c"><input type="checkbox" id="c-41896521" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41896160">parent</a><span>|</span><a href="#41895839">next</a><span>|</span><label class="collapse" for="c-41896521">[-]</label><label class="expand" for="c-41896521">[1 more]</label></div><br/><div class="children"><div class="content">I do believe I am responsible. I recognize I’am now in a position that I can speak without fear. If I get fired I would make a party tbh.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41895839" class="c"><input type="checkbox" id="c-41895839" checked=""/><div class="controls bullet"><span class="by">sigh_again</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892572">parent</a><span>|</span><a href="#41892970">prev</a><span>|</span><a href="#41891890">next</a><span>|</span><label class="collapse" for="c-41895839">[-]</label><label class="expand" for="c-41895839">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Software I write shouldn&#x27;t be relied on in critical situations.<p>Then don&#x27;t write software to be used in things that are literally always critical situations, like cars.</div><br/></div></div></div></div><div id="41891890" class="c"><input type="checkbox" id="c-41891890" checked=""/><div class="controls bullet"><span class="by">_rm</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891164">parent</a><span>|</span><a href="#41892572">prev</a><span>|</span><a href="#41896926">next</a><span>|</span><label class="collapse" for="c-41891890">[-]</label><label class="expand" for="c-41891890">[11 more]</label></div><br/><div class="children"><div class="content">What a laugh, would you take that deal?<p>Upside: you get paid a 200k salary, if all your code works perfectly. Downside: if it doesn&#x27;t, you go to prison.<p>The users aren&#x27;t compelled to use it. They can choose not to. They get to choose their own risks.<p>The internet is a gold mine of creatively moronic opinions.</div><br/><div id="41894907" class="c"><input type="checkbox" id="c-41894907" checked=""/><div class="controls bullet"><span class="by">chgs</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891890">parent</a><span>|</span><a href="#41892279">next</a><span>|</span><label class="collapse" for="c-41894907">[-]</label><label class="expand" for="c-41894907">[2 more]</label></div><br/><div class="children"><div class="content">Need far more regulation of the software industry, far too many people working in it fail to understand the scope of what they do.<p>Civil engineer kills someone with a bad building, jail. Surgeon removes the wrong lung, jail. Computer programmer kills someone, “oh well it’s your own fault”.</div><br/><div id="41895200" class="c"><input type="checkbox" id="c-41895200" checked=""/><div class="controls bullet"><span class="by">caddemon</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894907">parent</a><span>|</span><a href="#41892279">next</a><span>|</span><label class="collapse" for="c-41895200">[-]</label><label class="expand" for="c-41895200">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never heard of a surgeon going to jail over a genuine mistake even if it did kill someone. I&#x27;m also not sure what that would accomplish - take away their license to practice medicine sure, but they&#x27;re not a threat to society more broadly.</div><br/></div></div></div></div><div id="41892279" class="c"><input type="checkbox" id="c-41892279" checked=""/><div class="controls bullet"><span class="by">thunky</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891890">parent</a><span>|</span><a href="#41894907">prev</a><span>|</span><a href="#41892070">next</a><span>|</span><label class="collapse" for="c-41892279">[-]</label><label class="expand" for="c-41892279">[7 more]</label></div><br/><div class="children"><div class="content">You can go to prison or die for being a bad driver, yet people choose to drive.</div><br/><div id="41893006" class="c"><input type="checkbox" id="c-41893006" checked=""/><div class="controls bullet"><span class="by">_rm</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892279">parent</a><span>|</span><a href="#41892668">next</a><span>|</span><label class="collapse" for="c-41893006">[-]</label><label class="expand" for="c-41893006">[3 more]</label></div><br/><div class="children"><div class="content">Arguing for the sake of it; you wouldn&#x27;t take that risk reward.<p>Most code has bugs from time to time even when highly skilled developers are being careful. None of them would drive if the fault rate was similar and the outcome was death.</div><br/><div id="41894194" class="c"><input type="checkbox" id="c-41894194" checked=""/><div class="controls bullet"><span class="by">notahacker</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893006">parent</a><span>|</span><a href="#41897174">next</a><span>|</span><label class="collapse" for="c-41894194">[-]</label><label class="expand" for="c-41894194">[1 more]</label></div><br/><div class="children"><div class="content">Or to put even more straightforwardly: people who choose to drive rarely expect to drive more than a few 10s of k per year. People who choose to write autonomous software&#x27;s lines of code potentially drive a billion miles per year, experiencing a lot more edge cases they are expected to handle in a non-dangerous manner, and have to handle them via advance planning and interactions with a lot of other people&#x27;s code.<p>The only practical way around this which permits autonomous vehicles (which are apparently dependent on much more complex and intractable codebases than, say, avionics) is a much higher threshold of criminal responsibility than the &quot;the serious consequences resulted from the one-off execution of an dangerous manoeuvre which couldn&#x27;t be justified in context&quot; which sends human drivers to jail. And of course that double standard will be problematic if &quot;willingness to accept liability&quot; is the only safety threshold.</div><br/></div></div><div id="41897174" class="c"><input type="checkbox" id="c-41897174" checked=""/><div class="controls bullet"><span class="by">7sidedmarble</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893006">parent</a><span>|</span><a href="#41894194">prev</a><span>|</span><a href="#41892668">next</a><span>|</span><label class="collapse" for="c-41897174">[-]</label><label class="expand" for="c-41897174">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think anyone&#x27;s seriously suggesting people be held accountable for bugs which are ultimately accidents. But if you knowingly sign off on, oversea, or are otherwise directly responsible for the construction of software that you know has a good chance of killing people, then yes, there should be consequences for that.</div><br/></div></div></div></div><div id="41892668" class="c"><input type="checkbox" id="c-41892668" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892279">parent</a><span>|</span><a href="#41893006">prev</a><span>|</span><a href="#41892070">next</a><span>|</span><label class="collapse" for="c-41892668">[-]</label><label class="expand" for="c-41892668">[3 more]</label></div><br/><div class="children"><div class="content">Systems evolve to handle such liability: Drivers pass theory and practical tests to get licensed to drive (and periodically thereafter), and an insurance framework that gauges your risk-level and charges you accordingly.</div><br/><div id="41893635" class="c"><input type="checkbox" id="c-41893635" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892668">parent</a><span>|</span><a href="#41894827">next</a><span>|</span><label class="collapse" for="c-41893635">[-]</label><label class="expand" for="c-41893635">[1 more]</label></div><br/><div class="children"><div class="content">Requiring formal licensing and possibly insurance for developers working on life-critical systems is not that outlandish. On the contrary, that is already the case in serious engineering fields.</div><br/></div></div><div id="41894827" class="c"><input type="checkbox" id="c-41894827" checked=""/><div class="controls bullet"><span class="by">ekianjo</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892668">parent</a><span>|</span><a href="#41893635">prev</a><span>|</span><a href="#41892070">next</a><span>|</span><label class="collapse" for="c-41894827">[-]</label><label class="expand" for="c-41894827">[1 more]</label></div><br/><div class="children"><div class="content">And yet tens of thousands of people die on the roads right now every year. Working well?</div><br/></div></div></div></div></div></div><div id="41892070" class="c"><input type="checkbox" id="c-41892070" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891890">parent</a><span>|</span><a href="#41892279">prev</a><span>|</span><a href="#41896926">next</a><span>|</span><label class="collapse" for="c-41892070">[-]</label><label class="expand" for="c-41892070">[1 more]</label></div><br/><div class="children"><div class="content">Read the site rules.<p>And also, of course some people would take that deal, and of course some others wouldn&#x27;t. Your argument is moot.</div><br/></div></div></div></div></div></div><div id="41896926" class="c"><input type="checkbox" id="c-41896926" checked=""/><div class="controls bullet"><span class="by">lowbloodsugar</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890927">parent</a><span>|</span><a href="#41891164">prev</a><span>|</span><a href="#41894710">next</a><span>|</span><label class="collapse" for="c-41896926">[-]</label><label class="expand" for="c-41896926">[1 more]</label></div><br/><div class="children"><div class="content">And corporations are people now, so Tesla can go to jail.</div><br/></div></div><div id="41894710" class="c"><input type="checkbox" id="c-41894710" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890927">parent</a><span>|</span><a href="#41896926">prev</a><span>|</span><a href="#41896173">next</a><span>|</span><label class="collapse" for="c-41894710">[-]</label><label class="expand" for="c-41894710">[5 more]</label></div><br/><div class="children"><div class="content">In the United States? Come on. Boeing executives are not in jail - they are getting bonuses.</div><br/><div id="41894852" class="c"><input type="checkbox" id="c-41894852" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894710">parent</a><span>|</span><a href="#41896173">next</a><span>|</span><label class="collapse" for="c-41894852">[-]</label><label class="expand" for="c-41894852">[4 more]</label></div><br/><div class="children"><div class="content">But some little boy down the line will pay for it. Look for Eschede ICE accident.</div><br/><div id="41894991" class="c"><input type="checkbox" id="c-41894991" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894852">parent</a><span>|</span><a href="#41896173">next</a><span>|</span><label class="collapse" for="c-41894991">[-]</label><label class="expand" for="c-41894991">[3 more]</label></div><br/><div class="children"><div class="content">There are many examples.<p>The Koch brothers, famous &quot;anti-regulatory state&quot; warriors, have fought oversight so hard that their gas pipelines were allowed to be barely intact.<p>Two teens get into a truck, turn the ignition key - and the air explodes:<p><a href="https:&#x2F;&#x2F;www.southcoasttoday.com&#x2F;story&#x2F;news&#x2F;nation-world&#x2F;1996&#x2F;08&#x2F;26&#x2F;2-texas-teens-killed-when&#x2F;50633658007&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.southcoasttoday.com&#x2F;story&#x2F;news&#x2F;nation-world&#x2F;1996...</a><p>Does anyone go to jail? F*K NO.</div><br/><div id="41895304" class="c"><input type="checkbox" id="c-41895304" checked=""/><div class="controls bullet"><span class="by">IX-103</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894991">parent</a><span>|</span><a href="#41896173">next</a><span>|</span><label class="collapse" for="c-41895304">[-]</label><label class="expand" for="c-41895304">[2 more]</label></div><br/><div class="children"><div class="content">To be fair, the teens knew about the gas leak and started the truck in an attempt to get away. Gas leaks like that shouldn&#x27;t happen easily, but people near pipelines like that should also be made aware of the risks of gas leaks, as some leaks are inevitable.</div><br/><div id="41897806" class="c"><input type="checkbox" id="c-41897806" checked=""/><div class="controls bullet"><span class="by">8note</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895304">parent</a><span>|</span><a href="#41896173">next</a><span>|</span><label class="collapse" for="c-41897806">[-]</label><label class="expand" for="c-41897806">[1 more]</label></div><br/><div class="children"><div class="content">As an alternative though, the company also failed at handling that the gas leak started. They could have had people all over the place guiding people out and away from the leak safely, and keeping the public away while the leak is fixed.<p>Or, they could buy sufficient buffer land around the pipeline such that the gas leak will be found and stopped before it could explode down the road</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41896173" class="c"><input type="checkbox" id="c-41896173" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890342">parent</a><span>|</span><a href="#41890927">prev</a><span>|</span><a href="#41894269">next</a><span>|</span><label class="collapse" for="c-41896173">[-]</label><label class="expand" for="c-41896173">[1 more]</label></div><br/><div class="children"><div class="content">Presumably that is exactly when their taxi service rolls out?<p>While this has a dramatic rhetorical flourish,  I don’t think it’s a good proxy. Even if it was safer, it would be an unnecessarily high burden to clear. You’d be effectively writing a free insurance policy which is obviously not free.<p>Just look at total accidents &#x2F; deaths per mile driven, it’s the obvious and standard metric for measuring car safety. (You need to be careful to not stop the clock as soon as the system disengages of course. )</div><br/></div></div><div id="41894269" class="c"><input type="checkbox" id="c-41894269" checked=""/><div class="controls bullet"><span class="by">mrjin</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890342">parent</a><span>|</span><a href="#41896173">prev</a><span>|</span><a href="#41890716">next</a><span>|</span><label class="collapse" for="c-41894269">[-]</label><label class="expand" for="c-41894269">[8 more]</label></div><br/><div class="children"><div class="content">Even if it does, can it resurrect the deceased?</div><br/><div id="41894616" class="c"><input type="checkbox" id="c-41894616" checked=""/><div class="controls bullet"><span class="by">LadyCailin</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894269">parent</a><span>|</span><a href="#41890716">next</a><span>|</span><label class="collapse" for="c-41894616">[-]</label><label class="expand" for="c-41894616">[7 more]</label></div><br/><div class="children"><div class="content">But people driving manually kill people all the time too. The bar for self driving isn’t «does it never kill anyone», it’s «does it kill people less than manual driving». We’re not there yet, and Tesla’s «FSD» is marketing bullshit, but we certainly will be there one day, and at that point, we need to understand what we as a society will do when a self driving car kills someone. It’s not obvious what the best solution is there, and we need to continue to have societal discussions to hash that out, but the correct solution definitely isn’t «don’t use self driving».</div><br/><div id="41894637" class="c"><input type="checkbox" id="c-41894637" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894616">parent</a><span>|</span><a href="#41895419">next</a><span>|</span><label class="collapse" for="c-41894637">[-]</label><label class="expand" for="c-41894637">[4 more]</label></div><br/><div class="children"><div class="content">No, because every driver thinks they are better than average.<p>So nobody will accept it.</div><br/><div id="41901080" class="c"><input type="checkbox" id="c-41901080" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894637">parent</a><span>|</span><a href="#41894755">next</a><span>|</span><label class="collapse" for="c-41901080">[-]</label><label class="expand" for="c-41901080">[1 more]</label></div><br/><div class="children"><div class="content">The level where someone personally uses it and the level where they accept it being on the road are different.  Beating the average driver is all about the latter.<p>Also I will happily use self driving that matches the median driver in safety.</div><br/></div></div><div id="41894755" class="c"><input type="checkbox" id="c-41894755" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894637">parent</a><span>|</span><a href="#41901080">prev</a><span>|</span><a href="#41894992">next</a><span>|</span><label class="collapse" for="c-41894755">[-]</label><label class="expand" for="c-41894755">[1 more]</label></div><br/><div class="children"><div class="content">I expect insurance to figure out the relative risks and put a price sticker on that decision.</div><br/></div></div><div id="41894992" class="c"><input type="checkbox" id="c-41894992" checked=""/><div class="controls bullet"><span class="by">A4ET8a8uTh0</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894637">parent</a><span>|</span><a href="#41894755">prev</a><span>|</span><a href="#41895419">next</a><span>|</span><label class="collapse" for="c-41894992">[-]</label><label class="expand" for="c-41894992">[1 more]</label></div><br/><div class="children"><div class="content">Assuming I understand the argument flow correctly, I think I disagree. If there is one thing that the past few decades have confirmed quite conclusively, it is that people will trade a lot of control and sense away in the name of convenience. The moment FSD reaches that sweet spot of &#x27;take me home -- I am too drunk to drive&#x27; of reliability, I think it would be accepted; maybe even required by law. It does not seem there.</div><br/></div></div></div></div><div id="41895419" class="c"><input type="checkbox" id="c-41895419" checked=""/><div class="controls bullet"><span class="by">Majromax</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894616">parent</a><span>|</span><a href="#41894637">prev</a><span>|</span><a href="#41890716">next</a><span>|</span><label class="collapse" for="c-41895419">[-]</label><label class="expand" for="c-41895419">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The bar for self driving isn’t «does it never kill anyone», it’s «does it kill people less than manual driving».<p>Socially, that&#x27;s not quite the standard.  As a society, we&#x27;re at ease with auto fatalities because there&#x27;s often Someone To Blame.  &quot;Alcohol was involved in the incident,&quot; a report might say, and we&#x27;re more comfortable even though nobody&#x27;s been brought back to life.  Alternatively, &quot;he was asking for it, walking at night in dark clothing, nobody could have seen him.&quot;<p>This is an emotional standard that speaks to us as human, story-telling creatures that look for order in the universe, but this is not a proper actuarial standard.  We might need FSD to be manifestly safer than even the best human drivers before we&#x27;re comfortable with its universal use.</div><br/><div id="41901703" class="c"><input type="checkbox" id="c-41901703" checked=""/><div class="controls bullet"><span class="by">LadyCailin</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895419">parent</a><span>|</span><a href="#41890716">next</a><span>|</span><label class="collapse" for="c-41901703">[-]</label><label class="expand" for="c-41901703">[1 more]</label></div><br/><div class="children"><div class="content">That may be true, but I think I personally would find it extremely hard to argue against when the numbers are clearly showing that it’s safer. I think once the numbers are unambiguously showing that autopilots are safer, it will be super hard for people to argue against it. Of course there is a huge intermediate state where the numbers aren’t clear (or at least not clear to the average person), and during that stage, emotions may rule the debate. But if the underlying data is there, I’m certain car companies can change the narrative - just look at how much American hates public transit and jaywalkers.</div><br/></div></div></div></div></div></div></div></div><div id="41890716" class="c"><input type="checkbox" id="c-41890716" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890342">parent</a><span>|</span><a href="#41894269">prev</a><span>|</span><a href="#41892829">next</a><span>|</span><label class="collapse" for="c-41890716">[-]</label><label class="expand" for="c-41890716">[12 more]</label></div><br/><div class="children"><div class="content">Whats the current total liability cost for all Tesla drivers?<p>The average for all USA cars seems to be around $2000&#x2F;year, so even if FSD was half as dangerous Tesla would still be paying $1000&#x2F;year equivalent (not sure how big insurance margins are, assuming nominal) per car.<p>Now, if legally the driver could avoid paying insurance for the few times they want&#x2F;need to drive themselves (e.g. snow? Dunno what FSD supports atm) then it might make sense economically, but otherwise I don&#x27;t think it would work out.</div><br/><div id="41890796" class="c"><input type="checkbox" id="c-41890796" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890716">parent</a><span>|</span><a href="#41893401">next</a><span>|</span><label class="collapse" for="c-41890796">[-]</label><label class="expand" for="c-41890796">[10 more]</label></div><br/><div class="children"><div class="content">Liability alone isn’t nearly that high.<p>Car insurance payments include  people stealing your car, uninsured motorists, rental cars, and other issues not the drivers fault. Further insurance payments also include profits for the insurance company, advertising, billing, and other overhead from running a business.<p>Also, if Tesla was taking on these risks you’d expect your insurance costs to drop.</div><br/><div id="41893427" class="c"><input type="checkbox" id="c-41893427" checked=""/><div class="controls bullet"><span class="by">ywvcbk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890796">parent</a><span>|</span><a href="#41890817">next</a><span>|</span><label class="collapse" for="c-41893427">[-]</label><label class="expand" for="c-41893427">[1 more]</label></div><br/><div class="children"><div class="content">How much would every death or severe injury caused by FSD cost Tesla? We probably won’t know anytime soon but since unlike anyone else they can afford to pay out virtually unlimited amounts and courts will presumably take that into account</div><br/></div></div><div id="41890817" class="c"><input type="checkbox" id="c-41890817" checked=""/><div class="controls bullet"><span class="by">TheCleric</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890796">parent</a><span>|</span><a href="#41893427">prev</a><span>|</span><a href="#41890872">next</a><span>|</span><label class="collapse" for="c-41890817">[-]</label><label class="expand" for="c-41890817">[7 more]</label></div><br/><div class="children"><div class="content">Yeah any automaker doing this would just negotiate a flat rate per car in the US and the insurer would average the danger to make a rate. This would be much cheaper than the average individual’s cost for liability on their insurance.</div><br/><div id="41893444" class="c"><input type="checkbox" id="c-41893444" checked=""/><div class="controls bullet"><span class="by">ywvcbk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890817">parent</a><span>|</span><a href="#41892045">next</a><span>|</span><label class="collapse" for="c-41893444">[-]</label><label class="expand" for="c-41893444">[4 more]</label></div><br/><div class="children"><div class="content">What if someone gets killed because of some clear bug&#x2F;error and the jury decides to award 100s of millions just for that single ? I’m not sure it’s trivial to insurance companies to account for that sort of risk</div><br/><div id="41894784" class="c"><input type="checkbox" id="c-41894784" checked=""/><div class="controls bullet"><span class="by">kalenx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893444">parent</a><span>|</span><a href="#41894378">next</a><span>|</span><label class="collapse" for="c-41894784">[-]</label><label class="expand" for="c-41894784">[2 more]</label></div><br/><div class="children"><div class="content">It is trivial and they&#x27;ve done it for ages. It&#x27;s called reinsurance.<p>Basically (_very_ basically, there&#x27;s more to it) the insurance company insures itself against large claims.</div><br/><div id="41895090" class="c"><input type="checkbox" id="c-41895090" checked=""/><div class="controls bullet"><span class="by">ywvcbk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894784">parent</a><span>|</span><a href="#41894378">next</a><span>|</span><label class="collapse" for="c-41895090">[-]</label><label class="expand" for="c-41895090">[1 more]</label></div><br/><div class="children"><div class="content">I’m not sure Boeing etc. could have insured any liability risk resulting from engineering&#x2F;design flaws in their vehicles?</div><br/></div></div></div></div><div id="41894378" class="c"><input type="checkbox" id="c-41894378" checked=""/><div class="controls bullet"><span class="by">ndsipa_pomu</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893444">parent</a><span>|</span><a href="#41894784">prev</a><span>|</span><a href="#41892045">next</a><span>|</span><label class="collapse" for="c-41894378">[-]</label><label class="expand" for="c-41894378">[1 more]</label></div><br/><div class="children"><div class="content">Not trivial, but that is exactly the kind of thing that successful insurance companies factor into their premiums, or specifically exclude those scenarios (e.g. not covering war zones for house insurance).</div><br/></div></div></div></div><div id="41892045" class="c"><input type="checkbox" id="c-41892045" checked=""/><div class="controls bullet"><span class="by">ryandrake</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890817">parent</a><span>|</span><a href="#41893444">prev</a><span>|</span><a href="#41892322">next</a><span>|</span><label class="collapse" for="c-41892045">[-]</label><label class="expand" for="c-41892045">[1 more]</label></div><br/><div class="children"><div class="content">Somehow I doubt those savings would be passed along to the individual car buyer. Surely buying a car insured by the manufacturer would be much more expensive than buying the car plus your own individual insurance, because the car company would want to profit from both.</div><br/></div></div><div id="41892322" class="c"><input type="checkbox" id="c-41892322" checked=""/><div class="controls bullet"><span class="by">thedougd</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890817">parent</a><span>|</span><a href="#41892045">prev</a><span>|</span><a href="#41890872">next</a><span>|</span><label class="collapse" for="c-41892322">[-]</label><label class="expand" for="c-41892322">[1 more]</label></div><br/><div class="children"><div class="content">And it would be supplementary to the driver’s insurance, only covering incidents that happen while FSD is engaged. Arguably they would self insure and only purchase insurance for Tesla as a back stop to their liability, maybe through a reinsurance market.</div><br/></div></div></div></div><div id="41890872" class="c"><input type="checkbox" id="c-41890872" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890796">parent</a><span>|</span><a href="#41890817">prev</a><span>|</span><a href="#41893401">next</a><span>|</span><label class="collapse" for="c-41890872">[-]</label><label class="expand" for="c-41890872">[1 more]</label></div><br/><div class="children"><div class="content">Good points, thanks.</div><br/></div></div></div></div><div id="41893401" class="c"><input type="checkbox" id="c-41893401" checked=""/><div class="controls bullet"><span class="by">ywvcbk</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890716">parent</a><span>|</span><a href="#41890796">prev</a><span>|</span><a href="#41892829">next</a><span>|</span><label class="collapse" for="c-41893401">[-]</label><label class="expand" for="c-41893401">[1 more]</label></div><br/><div class="children"><div class="content">Also I wouldn’t be surprised if any potential wrongful death lawsuits could cost Tesla several magnitudes more than the current average.</div><br/></div></div></div></div><div id="41892829" class="c"><input type="checkbox" id="c-41892829" checked=""/><div class="controls bullet"><span class="by">tiahura</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890342">parent</a><span>|</span><a href="#41890716">prev</a><span>|</span><a href="#41891560">next</a><span>|</span><label class="collapse" for="c-41892829">[-]</label><label class="expand" for="c-41892829">[1 more]</label></div><br/><div class="children"><div class="content">I think that’s implicit in the promise of the upcoming-any-year-now unattended full self driving.</div><br/></div></div><div id="41891560" class="c"><input type="checkbox" id="c-41891560" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890342">parent</a><span>|</span><a href="#41892829">prev</a><span>|</span><a href="#41895301">next</a><span>|</span><label class="collapse" for="c-41891560">[-]</label><label class="expand" for="c-41891560">[11 more]</label></div><br/><div class="children"><div class="content">This is how I feel about nuclear energy. Every single plant should need to form a full insurance fund dedicated to paying out if there’s trouble. And the plant should have strict liability: anything that happens from materials it releases are its responsibility.<p>But people get upset about this. We need corporations to take responsibility.</div><br/><div id="41894412" class="c"><input type="checkbox" id="c-41894412" checked=""/><div class="controls bullet"><span class="by">ndsipa_pomu</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891560">parent</a><span>|</span><a href="#41891771">next</a><span>|</span><label class="collapse" for="c-41894412">[-]</label><label class="expand" for="c-41894412">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not a workable idea as it&#x27;d just encourage corporations to obfuscate the ownership of the plant (e.g. shell companies) and drastically underestimate the actual risks of catastrophes. Ultimately, the government will be left holding the bill for nuclear catastrophes, so it&#x27;s better to just recognise that and get the government to regulate the energy companies.</div><br/><div id="41894859" class="c"><input type="checkbox" id="c-41894859" checked=""/><div class="controls bullet"><span class="by">f1shy</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894412">parent</a><span>|</span><a href="#41891771">next</a><span>|</span><label class="collapse" for="c-41894859">[-]</label><label class="expand" for="c-41894859">[1 more]</label></div><br/><div class="children"><div class="content">The problem I see there is that if “corporations are responsible” then no one is. That is, no real person has the responsibility, and acts accordingly.</div><br/></div></div></div></div><div id="41891771" class="c"><input type="checkbox" id="c-41891771" checked=""/><div class="controls bullet"><span class="by">idiotsecant</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891560">parent</a><span>|</span><a href="#41894412">prev</a><span>|</span><a href="#41895301">next</a><span>|</span><label class="collapse" for="c-41891771">[-]</label><label class="expand" for="c-41891771">[8 more]</label></div><br/><div class="children"><div class="content">While we&#x27;re at it how about why apply the same standard to coal and natural gas plants? For some reason when we start taking about nuclear plants we all of a sudden become adverse to the idea of unfunded externalities but when we&#x27;re talking about &#x27;old&#x27; tech that has been steadily irradiating your community and changing the gas composition <i>of the entire planet</i> it becomes less concerning.</div><br/><div id="41894020" class="c"><input type="checkbox" id="c-41894020" checked=""/><div class="controls bullet"><span class="by">moooo99</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891771">parent</a><span>|</span><a href="#41895652">next</a><span>|</span><label class="collapse" for="c-41894020">[-]</label><label class="expand" for="c-41894020">[6 more]</label></div><br/><div class="children"><div class="content">I think it is a matter of perceived risk.<p>Realistically speaking, nuclear power is pretty safe. In the history of nuclear power, there were two major incidents. Considering the number of nuclear power plants around the planet, that is pretty good. However, as those two accidents demonstrated, the potential fallout of those incidents is pretty severe and widespread. I think this massively contributes to the perceived risks. The warnings towards the public were pretty clear. I remember my mom telling stories from the time the Chernobyl incident became known to the public and people became worried about the produce they usually had from their gardens. Meanwhile, everything that has been done to address the hazards of fossil based power generation is pretty much happening behind the scenes.<p>With coal and natural gas, it seems like people perceive the risks as more abstract. The radioactive emissions of coal power plants have been known for a while and the (potential) dangers of fine particulate matters resulting from combustion are somewhat well known nowadays as well. However, the effects of those danger seem much more abstract and delayed, leading people to not be as worried about it. It also shows on a smaller, more individual scale: people still buy ICE cars at large and install gas stoves into their houses despite induction being readily available and at times even cheaper.</div><br/><div id="41894445" class="c"><input type="checkbox" id="c-41894445" checked=""/><div class="controls bullet"><span class="by">pyrale</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894020">parent</a><span>|</span><a href="#41894935">next</a><span>|</span><label class="collapse" for="c-41894445">[-]</label><label class="expand" for="c-41894445">[2 more]</label></div><br/><div class="children"><div class="content">&gt; However, the effects of those danger seem much more abstract and delayed, leading people to not be as worried about it.<p>Climate change is very visible in the present day to me. People are protesting about it frequently enough that it&#x27;s hard to claim they are not worried.</div><br/><div id="41895351" class="c"><input type="checkbox" id="c-41895351" checked=""/><div class="controls bullet"><span class="by">moooo99</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894445">parent</a><span>|</span><a href="#41894935">next</a><span>|</span><label class="collapse" for="c-41895351">[-]</label><label class="expand" for="c-41895351">[1 more]</label></div><br/><div class="children"><div class="content">Climate change is certainly visible, although the extend to which areas are affected varies wildly. However, there are still shockingly many people who have a hard time attributing ever increasing natural disasters and more extreme weather patterns to climate  change.</div><br/></div></div></div></div><div id="41894935" class="c"><input type="checkbox" id="c-41894935" checked=""/><div class="controls bullet"><span class="by">brightball</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894020">parent</a><span>|</span><a href="#41894445">prev</a><span>|</span><a href="#41895652">next</a><span>|</span><label class="collapse" for="c-41894935">[-]</label><label class="expand" for="c-41894935">[3 more]</label></div><br/><div class="children"><div class="content">During power outages, having natural gas in your home is a huge benefit. Many in my area just experienced it with Helene.<p>You can still cook. You can still get hot water. If you have gas logs you still have a heat source in the winter too.<p>These trade offs are far more important to a lot of people.</div><br/><div id="41895342" class="c"><input type="checkbox" id="c-41895342" checked=""/><div class="controls bullet"><span class="by">moooo99</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894935">parent</a><span>|</span><a href="#41895652">next</a><span>|</span><label class="collapse" for="c-41895342">[-]</label><label class="expand" for="c-41895342">[2 more]</label></div><br/><div class="children"><div class="content">Granted, that is a valid concern if power outages are more frequent in your area. I have never experienced a power outage personally, so that is nothing I ever thought of. However, I feel like with solar power and battery storage systems becoming increasingly widespread, this won&#x27;t be a major concern for much longer</div><br/><div id="41898444" class="c"><input type="checkbox" id="c-41898444" checked=""/><div class="controls bullet"><span class="by">brightball</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895342">parent</a><span>|</span><a href="#41895652">next</a><span>|</span><label class="collapse" for="c-41898444">[-]</label><label class="expand" for="c-41898444">[1 more]</label></div><br/><div class="children"><div class="content">They aren’t frequent but in the last 15-16 years there have been 2 outages that lasted almost 2 weeks in some areas around here. The first one was in the winter and the only gas appliance I had was a set of gas logs in the den.<p>It heated my whole house and we used a pan to cook over it. When we moved the first thing I did was install gas logs, gas stove and a gas water heater.<p>It’s nice to have options and backup plans. That’s one of the reasons I was a huge fan of the Chevy Volt when it first came out. I could easily take it on a long trip but still averaged 130mpg over 3 years (twice). Now I’ve got a Tesla and when there are fuel shortages it’s also really nice.<p>A friend of ours owns a cybertruck and was without power for 9 days, but just powered the whole house with the cybertruck. Every couple of days he’d drive to a supercharger station to recharge.</div><br/></div></div></div></div></div></div></div></div><div id="41895652" class="c"><input type="checkbox" id="c-41895652" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891771">parent</a><span>|</span><a href="#41894020">prev</a><span>|</span><a href="#41895301">next</a><span>|</span><label class="collapse" for="c-41895652">[-]</label><label class="expand" for="c-41895652">[1 more]</label></div><br/><div class="children"><div class="content">Sure, we can have a carbon tax on everything. That&#x27;s fine. And then the nuclear plant has to pay for a Pripyat-sized exclusion zone around it. Just like the guy said about Tesla. All fair.</div><br/></div></div></div></div></div></div></div></div><div id="41895301" class="c"><input type="checkbox" id="c-41895301" checked=""/><div class="controls bullet"><span class="by">rainsford</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41890342">prev</a><span>|</span><a href="#41890213">next</a><span>|</span><label class="collapse" for="c-41895301">[-]</label><label class="expand" for="c-41895301">[1 more]</label></div><br/><div class="children"><div class="content">Arguably the problem with Tesla self-driving is that it&#x27;s stuck in an uncanny valley of performance where it&#x27;s worse than better performing systems but <i>also</i> worse from a user experience perspective than even less capable systems.<p>Less capable driver assistance type systems might help the driver out (e.g. adaptive cruise control), but leave no doubt that the human is still driving.  Tesla though goes far enough that it takes over driving from the human but it isn&#x27;t reliable enough that the human can stop paying attention and be ready to take over at a moment&#x27;s notice.  This seems like the worst of all possible worlds since you are both disengaged by having to maintain alertness.<p>Autopilots in airplanes are much the same way, pilots can&#x27;t just turn it on and take a nap.  But the difference is that nothing an autopilot is going to do will instantly crash the plane, while Tesla screwing up will require split second reactions from the driver to correct for.<p>I feel like the real answer to your question is that having reasonable confidence in self-driving cars beyond &quot;driver assistance&quot; type features will ultimately require a car that will literally get from A to B reliably even if you&#x27;re taking a nap.  Anything close to that but not quite there is in my mind almost worse than something more basic.</div><br/></div></div><div id="41890213" class="c"><input type="checkbox" id="c-41890213" checked=""/><div class="controls bullet"><span class="by">dreamcompiler</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41895301">prev</a><span>|</span><a href="#41889518">next</a><span>|</span><label class="collapse" for="c-41890213">[-]</label><label class="expand" for="c-41890213">[14 more]</label></div><br/><div class="children"><div class="content">&gt;  It didn&#x27;t merge left to make room for vehicles merging onto the highway. The vehicles then tried to cut in. The system should have avoided an unsafe situation like this in the first place.<p>This is what bugs me about ordinary autopilot. Autopilot doesn&#x27;t switch lanes, but I like to slow down or speed up as needed to allow merging cars to enter my lane. Autopilot never does that, and I&#x27;ve had some close calls with irate mergers who expected me to work with them. And I don&#x27;t think they&#x27;re wrong.<p>Just means that when I&#x27;m cruising in the right lane with autopilot I have to take over if a car tries to merge.</div><br/><div id="41894008" class="c"><input type="checkbox" id="c-41894008" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890213">parent</a><span>|</span><a href="#41898653">next</a><span>|</span><label class="collapse" for="c-41894008">[-]</label><label class="expand" for="c-41894008">[7 more]</label></div><br/><div class="children"><div class="content">While I certainly wouldn&#x27;t object to how you handle merging cars (it&#x27;s a nice, helpful thing to do!), I was always taught that if you want to merge into a lane, you are the sole person responsible for making that possible and making that safe.  You need to get your speed and position right, and if you can&#x27;t do that, you don&#x27;t merge.<p>(That&#x27;s for merging onto a highway from an entrance ramp, at least.  If you&#x27;re talking about a zipper merge due to a lane ending or a lane closure, sure, cooperation with other drivers is always the right thing to do.)</div><br/><div id="41895109" class="c"><input type="checkbox" id="c-41895109" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894008">parent</a><span>|</span><a href="#41895127">next</a><span>|</span><label class="collapse" for="c-41895109">[-]</label><label class="expand" for="c-41895109">[2 more]</label></div><br/><div class="children"><div class="content">More Americans should go drive on the Autobahn. Everyone thinks the magic is “omg no speed limits!” which is neat but the <i>really</i> amazing thing is that NO ONE sits in the left hand lane and EVERYONE will let you merge <i>immediately</i> upon signaling.<p>It’s like a children’s book explanation of the nice things you can have (no speed limits) if everyone could just stop being such obscenely selfish people (like sitting in the left lane or preventing merges because of some weird “I need my car to be in front of their car” fixation).</div><br/><div id="41895129" class="c"><input type="checkbox" id="c-41895129" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895109">parent</a><span>|</span><a href="#41895127">next</a><span>|</span><label class="collapse" for="c-41895129">[-]</label><label class="expand" for="c-41895129">[1 more]</label></div><br/><div class="children"><div class="content">Tesla FSD on German Autobahn = most dangerous thing ever. The car has never seen this rule and it&#x27;s not ready for a 300km&#x2F;h car behind you.</div><br/></div></div></div></div><div id="41895127" class="c"><input type="checkbox" id="c-41895127" checked=""/><div class="controls bullet"><span class="by">macNchz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894008">parent</a><span>|</span><a href="#41895109">prev</a><span>|</span><a href="#41895052">next</a><span>|</span><label class="collapse" for="c-41895127">[-]</label><label class="expand" for="c-41895127">[1 more]</label></div><br/><div class="children"><div class="content">At least in the northeast&#x2F;east coast US there are still lots of old parkways without modern onramps, where moving over to let people merge is super helpful. Frequently these have bad visibility and limited room to accelerate if any at all, so doing it your way is not really possible.<p>For example:<p>I use this onramp fairly frequently. It’s rural and rarely has much traffic, but when there is you can get stuck for a while trying to get on because it’s hard to see the coming cars, and there’s not much room to accelerate (unless people move over, which they often do). 
<a href="https:&#x2F;&#x2F;maps.app.goo.gl&#x2F;ALt8UmJDzvn89uvM7?g_st=ic" rel="nofollow">https:&#x2F;&#x2F;maps.app.goo.gl&#x2F;ALt8UmJDzvn89uvM7?g_st=ic</a><p>Preemptively getting in the left lane before going under this bridge is a defensive safety maneuver I always make—being in the right lane nearly guarantees some amount of conflict with merging traffic.<p><a href="https:&#x2F;&#x2F;maps.app.goo.gl&#x2F;PumaSM9Bx8iyaH9n6?g_st=ic" rel="nofollow">https:&#x2F;&#x2F;maps.app.goo.gl&#x2F;PumaSM9Bx8iyaH9n6?g_st=ic</a></div><br/></div></div><div id="41895052" class="c"><input type="checkbox" id="c-41895052" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894008">parent</a><span>|</span><a href="#41895127">prev</a><span>|</span><a href="#41895325">next</a><span>|</span><label class="collapse" for="c-41895052">[-]</label><label class="expand" for="c-41895052">[1 more]</label></div><br/><div class="children"><div class="content">I was taught that in <i>every</i> situation you should act as though you are the sole person responsible for making the interaction safe.<p>If you&#x27;re the one merging? It&#x27;s on you. If you&#x27;re the one being merged into? Also you.<p>If you assume that every other driver has a malfunctioning vehicle or is driving irresponsibly then your odds of a crash go way down because you <i>assume</i> that they&#x27;re going to try to merge incorrectly.</div><br/></div></div><div id="41895325" class="c"><input type="checkbox" id="c-41895325" checked=""/><div class="controls bullet"><span class="by">rainsford</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894008">parent</a><span>|</span><a href="#41895052">prev</a><span>|</span><a href="#41894884">next</a><span>|</span><label class="collapse" for="c-41895325">[-]</label><label class="expand" for="c-41895325">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  You need to get your speed and position right, and if you can&#x27;t do that, you don&#x27;t merge.<p>I agree, but my observation has been that the majority of drivers are absolutely trash at doing that and I&#x27;d rather they not crash into me, even if would be their fault.<p>Honestly I think Tesla&#x27;s self-driving technology is long on marketing and short on performance, but it really helps their case that a lot of the competition is human drivers who are completely terrible at the job.</div><br/></div></div><div id="41894884" class="c"><input type="checkbox" id="c-41894884" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894008">parent</a><span>|</span><a href="#41895325">prev</a><span>|</span><a href="#41898653">next</a><span>|</span><label class="collapse" for="c-41894884">[-]</label><label class="expand" for="c-41894884">[1 more]</label></div><br/><div class="children"><div class="content">&gt;cooperation with other drivers is always the right thing to do<p>Correct, including when the other driver may not have the strictly interpreted legal right of way.  You don&#x27;t know if their vehicle is malfunctioning, or if the driver is malfunctioning, or if they are being overly aggressive or distracted on their phone.<p>But most of the time, on an onramp to a highway, people on the highway in the lane that is being merged into need to be taking into account the potential conflicts due to people merging in from the acceleration lane.  Acceleration lanes can be too short, other cars may not have the capability to accelerate quickly, other drivers may not be as confident, etc.<p>So while technically, the onus is on people merging in, a more realistic rule is to take turns whenever congestion appears, even if you have right of way.</div><br/></div></div></div></div><div id="41898653" class="c"><input type="checkbox" id="c-41898653" checked=""/><div class="controls bullet"><span class="by">dham</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890213">parent</a><span>|</span><a href="#41894008">prev</a><span>|</span><a href="#41894575">next</a><span>|</span><label class="collapse" for="c-41898653">[-]</label><label class="expand" for="c-41898653">[4 more]</label></div><br/><div class="children"><div class="content">Autopilot is just adaptive cruise control with lane keep.  Literally every car has this now.  I don&#x27;t see people on Toyota, Honda, or Ford forums complaining that a table-stakes feature of a car doesn&#x27;t adjust speed or change lanes as a car is merging in.  Do you know how insane that sounds.  I&#x27;m assuming you&#x27;re in software since you&#x27;re on Hacker news.</div><br/><div id="41901125" class="c"><input type="checkbox" id="c-41901125" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41898653">parent</a><span>|</span><a href="#41899897">next</a><span>|</span><label class="collapse" for="c-41901125">[-]</label><label class="expand" for="c-41901125">[1 more]</label></div><br/><div class="children"><div class="content">It sounds zero insane.  Adaptive cruise control taking into account merging would be great.  And it&#x27;s valid to complain about automations that make your car worse at cooperating.</div><br/></div></div><div id="41899897" class="c"><input type="checkbox" id="c-41899897" checked=""/><div class="controls bullet"><span class="by">twoWhlsGud</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41898653">parent</a><span>|</span><a href="#41901125">prev</a><span>|</span><a href="#41894575">next</a><span>|</span><label class="collapse" for="c-41899897">[-]</label><label class="expand" for="c-41899897">[2 more]</label></div><br/><div class="children"><div class="content">My Audi doesn&#x27;t advertise its predictive cruise control as Full Self Driving. So expectations are more controlled...</div><br/><div id="41901111" class="c"><input type="checkbox" id="c-41901111" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41899897">parent</a><span>|</span><a href="#41894575">next</a><span>|</span><label class="collapse" for="c-41901111">[-]</label><label class="expand" for="c-41901111">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re not talking about FSD.</div><br/></div></div></div></div></div></div><div id="41894575" class="c"><input type="checkbox" id="c-41894575" checked=""/><div class="controls bullet"><span class="by">japhyr</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890213">parent</a><span>|</span><a href="#41898653">prev</a><span>|</span><a href="#41892057">next</a><span>|</span><label class="collapse" for="c-41894575">[-]</label><label class="expand" for="c-41894575">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Just means that when I&#x27;m cruising in the right lane with autopilot I have to take over if a car tries to merge.<p>Which brings it right back to the original criticism of Tesla&#x27;s &quot;self driving&quot; program. What you&#x27;re describing is assisted driving, not anything close to &quot;full self driving&quot;.</div><br/></div></div><div id="41892057" class="c"><input type="checkbox" id="c-41892057" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890213">parent</a><span>|</span><a href="#41894575">prev</a><span>|</span><a href="#41889518">next</a><span>|</span><label class="collapse" for="c-41892057">[-]</label><label class="expand" for="c-41892057">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. Automatic lane changes are the only feature of enhanced autopilot that I think I&#x27;d be interested in, solely for this reason.</div><br/></div></div></div></div><div id="41889518" class="c"><input type="checkbox" id="c-41889518" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41890213">prev</a><span>|</span><a href="#41889213">next</a><span>|</span><label class="collapse" for="c-41889518">[-]</label><label class="expand" for="c-41889518">[71 more]</label></div><br/><div class="children"><div class="content">Tesla jumped the gun on the FSD free trial earlier this year. It was nowhere near good enough at the time. Most people who tried it for the first time probably share your opinion.<p>That said, there is a night and day difference between FSD 12.3 that you experienced earlier this year and the latest version 12.6. It will still make mistakes from time to time but the improvement is massive and obvious. More importantly, the rate of improvement in the past two months has been much faster than before.<p>Yesterday I spent an hour in the car over three drives and did not have to turn the steering wheel at all except for parking. That <i>never</i> happened on 12.3. And I don&#x27;t even have 12.6 yet, this is still 12.5; others report that 12.6 is a noticeable improvement over 12.5. And version 13 is scheduled for release in the next two weeks, and the FSD team has actually hit their last few release milestones.<p>People are right that it is still not ready yet, but if they think it will stay that way forever they are about to be very surprised. At the current rate of improvement it will be quite good within a year and in two or three I could see it actually reaching the point where it could operate unsupervised.</div><br/><div id="41890395" class="c"><input type="checkbox" id="c-41890395" checked=""/><div class="controls bullet"><span class="by">wstrange</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41889593">next</a><span>|</span><label class="collapse" for="c-41890395">[-]</label><label class="expand" for="c-41890395">[6 more]</label></div><br/><div class="children"><div class="content">I have a 2024 Model 3, and it&#x27;s a a great car. That being said, I&#x27;m under no illusion that the car will <i>ever</i> be self driving (unsupervised).<p>12.5.6 Still fails to read very obvious signs for 30 Km&#x2F;h playgrounds zones.<p>The current vehicles lack sufficient sensors, and likely do not have enough compute power and memory to cover all edge cases.<p>I think it&#x27;s a matter of time before Tesla faces a lawsuit over continual FSD claims.<p>My hope is that the board will grow a spine and bring in a more focused CEO.<p>Hats off to Elon for getting Tesla to this point, but right now they need a mature (and boring) CEO.</div><br/><div id="41891728" class="c"><input type="checkbox" id="c-41891728" checked=""/><div class="controls bullet"><span class="by">pelorat</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890395">parent</a><span>|</span><a href="#41889593">next</a><span>|</span><label class="collapse" for="c-41891728">[-]</label><label class="expand" for="c-41891728">[5 more]</label></div><br/><div class="children"><div class="content">The board is family and friends, so them ousting him will never happen.</div><br/><div id="41893514" class="c"><input type="checkbox" id="c-41893514" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891728">parent</a><span>|</span><a href="#41889593">next</a><span>|</span><label class="collapse" for="c-41893514">[-]</label><label class="expand" for="c-41893514">[4 more]</label></div><br/><div class="children"><div class="content">At some point the risk of going to prison overtakes family loyalty.</div><br/><div id="41894646" class="c"><input type="checkbox" id="c-41894646" checked=""/><div class="controls bullet"><span class="by">dlisboa</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893514">parent</a><span>|</span><a href="#41889593">next</a><span>|</span><label class="collapse" for="c-41894646">[-]</label><label class="expand" for="c-41894646">[3 more]</label></div><br/><div class="children"><div class="content">There is no risk of going to prison. It just doesn’t happen, never have and never will, no matter how unfair that is. Board members and CEOs are not held accountable, ever.</div><br/><div id="41894892" class="c"><input type="checkbox" id="c-41894892" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894646">parent</a><span>|</span><a href="#41895119">next</a><span>|</span><label class="collapse" for="c-41894892">[-]</label><label class="expand" for="c-41894892">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;01&#x2F;24&#x2F;google-meta-spotify-layoffs-ceo-sundar-pichai-mark-zuckerberg-daniel-ek-take-full-responsibility-what-that-means&#x2F;" rel="nofollow">https:&#x2F;&#x2F;fortune.com&#x2F;2023&#x2F;01&#x2F;24&#x2F;google-meta-spotify-layoffs-c...</a><p>As they say, they take &quot;full responsibility&quot;</div><br/></div></div><div id="41895119" class="c"><input type="checkbox" id="c-41895119" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894646">parent</a><span>|</span><a href="#41894892">prev</a><span>|</span><a href="#41889593">next</a><span>|</span><label class="collapse" for="c-41895119">[-]</label><label class="expand" for="c-41895119">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.justice.gov&#x2F;opa&#x2F;pr&#x2F;former-enron-ceo-jeffrey-skilling-resentenced-168-months-fraud-conspiracy-charges" rel="nofollow">https:&#x2F;&#x2F;www.justice.gov&#x2F;opa&#x2F;pr&#x2F;former-enron-ceo-jeffrey-skil...</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="41889593" class="c"><input type="checkbox" id="c-41889593" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41890395">prev</a><span>|</span><a href="#41893970">next</a><span>|</span><label class="collapse" for="c-41889593">[-]</label><label class="expand" for="c-41889593">[13 more]</label></div><br/><div class="children"><div class="content">I have yet to see a difference. I let it highway drive for an hour and it cut off a semi, coming within 9 to 12 inches of the bumper for no reason. I heard about that one believe me.<p>It got stuck in a side street trying to get to a target parking lot, shaking the wheel back and forth.<p>It&#x27;s no better so far and this is the first day.</div><br/><div id="41889602" class="c"><input type="checkbox" id="c-41889602" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889593">parent</a><span>|</span><a href="#41889978">next</a><span>|</span><label class="collapse" for="c-41889602">[-]</label><label class="expand" for="c-41889602">[6 more]</label></div><br/><div class="children"><div class="content">You have 12.6?<p>As I said, it still makes mistakes and it is not ready yet. But 12.3 was much worse. It&#x27;s the rate of improvement I am impressed with.<p>I will also note that the predicted epidemic of crashes from people abusing FSD never happened. It&#x27;s been on the road for a long time now. The idea that it is &quot;irresponsible&quot; to deploy it in its current state seems conclusively disproven. You can argue about exactly what the rate of crashes is but it seems clear that it has been at the very least no worse than normal driving.</div><br/><div id="41889623" class="c"><input type="checkbox" id="c-41889623" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889602">parent</a><span>|</span><a href="#41889978">next</a><span>|</span><label class="collapse" for="c-41889623">[-]</label><label class="expand" for="c-41889623">[5 more]</label></div><br/><div class="children"><div class="content">Hm. I thought that was the latest release but it looks like no. But there seems to be no improvements from the last trial, so maybe 12.6 is magically better.</div><br/><div id="41889648" class="c"><input type="checkbox" id="c-41889648" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889623">parent</a><span>|</span><a href="#41889978">next</a><span>|</span><label class="collapse" for="c-41889648">[-]</label><label class="expand" for="c-41889648">[4 more]</label></div><br/><div class="children"><div class="content">A lot of people have been getting the free trial with 12.3 still on their cars today. Tesla has really screwed up on the free trial for sure. Nobody should be getting it unless they have 12.6 at least.</div><br/><div id="41889731" class="c"><input type="checkbox" id="c-41889731" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889648">parent</a><span>|</span><a href="#41889978">next</a><span>|</span><label class="collapse" for="c-41889731">[-]</label><label class="expand" for="c-41889731">[3 more]</label></div><br/><div class="children"><div class="content">I have 12.5. maybe 12.6 is better but I&#x27;ve heard that before.<p>Don&#x27;t get me wrong without a concerted data team building maps a priori, this is pretty incredible. But from a pure performance standpoint it&#x27;s a shaky product.</div><br/><div id="41889788" class="c"><input type="checkbox" id="c-41889788" checked=""/><div class="controls bullet"><span class="by">KaoruAoiShiho</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889731">parent</a><span>|</span><a href="#41889978">next</a><span>|</span><label class="collapse" for="c-41889788">[-]</label><label class="expand" for="c-41889788">[2 more]</label></div><br/><div class="children"><div class="content">The latest version is 12.5.6, I think he got confused by the .6 at the end. If you think that&#x27;s bad then there isn&#x27;t a better version available. However it is a dramatic improvement over 12.3, don&#x27;t know how much you tested on it.</div><br/><div id="41889893" class="c"><input type="checkbox" id="c-41889893" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889788">parent</a><span>|</span><a href="#41889978">next</a><span>|</span><label class="collapse" for="c-41889893">[-]</label><label class="expand" for="c-41889893">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right, thanks. One of the biggest updates in 12.5.6 is transitioning the highway Autopilot to FSD. If he has 12.5.4 then it may still be using the old non-FSD Autopilot on highways which would explain why he hasn&#x27;t noticed improvement there; there hasn&#x27;t been any until 12.5.6.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41889978" class="c"><input type="checkbox" id="c-41889978" checked=""/><div class="controls bullet"><span class="by">hilux</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889593">parent</a><span>|</span><a href="#41889602">prev</a><span>|</span><a href="#41890441">next</a><span>|</span><label class="collapse" for="c-41889978">[-]</label><label class="expand" for="c-41889978">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ... coming within 9 to 12 inches of the bumper for no reason. I heard about that one believe me.<p>Oh dear.<p>Glad you&#x27;re okay!</div><br/></div></div><div id="41890441" class="c"><input type="checkbox" id="c-41890441" checked=""/><div class="controls bullet"><span class="by">eric_cc</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889593">parent</a><span>|</span><a href="#41889978">prev</a><span>|</span><a href="#41893970">next</a><span>|</span><label class="collapse" for="c-41890441">[-]</label><label class="expand" for="c-41890441">[5 more]</label></div><br/><div class="children"><div class="content">Is it possible you have a lemon? Genuine question. I’ve had nothing but positive experiences with FSD for the last several months and many thousands of miles.</div><br/><div id="41890737" class="c"><input type="checkbox" id="c-41890737" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890441">parent</a><span>|</span><a href="#41893857">next</a><span>|</span><label class="collapse" for="c-41890737">[-]</label><label class="expand" for="c-41890737">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had nothing but positive experiences with ChatGPT-4o, that doesn&#x27;t make people wrong to criticise either as modelling their training data too much and generalising too little when they need to use it for something where the inference domain is too far outside the training domain.</div><br/></div></div><div id="41893857" class="c"><input type="checkbox" id="c-41893857" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890441">parent</a><span>|</span><a href="#41890737">prev</a><span>|</span><a href="#41894414">next</a><span>|</span><label class="collapse" for="c-41893857">[-]</label><label class="expand" for="c-41893857">[1 more]</label></div><br/><div class="children"><div class="content">If the incidence of problems is some relatively small number, like 5% or 10%, it&#x27;s very easily possible that you&#x27;ve never personally seen a problem, but overall we&#x27;d still consider that the total incidence of problems is unacceptable.<p>Please stop presenting arguments of the form &quot;I haven&#x27;t seen problems so people who have problems must be extreme outliers&quot;.  At best it&#x27;s ignorant, at worst it&#x27;s actively in bad faith.</div><br/></div></div><div id="41894414" class="c"><input type="checkbox" id="c-41894414" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890441">parent</a><span>|</span><a href="#41893857">prev</a><span>|</span><a href="#41898678">next</a><span>|</span><label class="collapse" for="c-41894414">[-]</label><label class="expand" for="c-41894414">[1 more]</label></div><br/><div class="children"><div class="content">I suspect the performance might vary widely depending on if you&#x27;re on a road in california they have a lot of data on, or if its a road FSD has rarely seen before.</div><br/></div></div><div id="41898678" class="c"><input type="checkbox" id="c-41898678" checked=""/><div class="controls bullet"><span class="by">dham</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890441">parent</a><span>|</span><a href="#41894414">prev</a><span>|</span><a href="#41893970">next</a><span>|</span><label class="collapse" for="c-41898678">[-]</label><label class="expand" for="c-41898678">[1 more]</label></div><br/><div class="children"><div class="content">A lot of haters mistake safety critical disengagements with &quot;oh the car is doing something I don&#x27;t like or I wouldn&#x27;t do&quot;<p>If you treat the car like it&#x27;s a student driver or someone else driving, disengagements will go do.  If you treat it like you&#x27;re driving there&#x27;s also something to complain about.</div><br/></div></div></div></div></div></div><div id="41893970" class="c"><input type="checkbox" id="c-41893970" checked=""/><div class="controls bullet"><span class="by">latexr</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41889593">prev</a><span>|</span><a href="#41890163">next</a><span>|</span><label class="collapse" for="c-41893970">[-]</label><label class="expand" for="c-41893970">[2 more]</label></div><br/><div class="children"><div class="content">&gt; At the current rate of improvement it will be quite good within a year and in two or three I could see it actually reaching the point where it could operate unsupervised.<p>That’s not a reasonable assumption. You can’t just extrapolate “software rate of improvement”, that’s not how it works.</div><br/><div id="41895883" class="c"><input type="checkbox" id="c-41895883" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893970">parent</a><span>|</span><a href="#41890163">next</a><span>|</span><label class="collapse" for="c-41895883">[-]</label><label class="expand" for="c-41895883">[1 more]</label></div><br/><div class="children"><div class="content">The timing of the rate of improvement increasing corresponds with finishing their switch to end-to-end machine learning. ML does have scaling laws actually.<p>Tesla collects their own data, builds their own training clusters with both Nvidia hardware and their own custom hardware, and deploys their own custom inference hardware in the cars. There is no obstacle to them scaling up massively in all dimensions, which basically guarantees significant progress. Obviously you can disagree about whether that progress will be enough, but based on the evidence I see from using it, I think it will be.</div><br/></div></div></div></div><div id="41890163" class="c"><input type="checkbox" id="c-41890163" checked=""/><div class="controls bullet"><span class="by">snypher</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41893970">prev</a><span>|</span><a href="#41893442">next</a><span>|</span><label class="collapse" for="c-41890163">[-]</label><label class="expand" for="c-41890163">[13 more]</label></div><br/><div class="children"><div class="content">So just a few more years of death and injury until they reach a finished product?</div><br/><div id="41895317" class="c"><input type="checkbox" id="c-41895317" checked=""/><div class="controls bullet"><span class="by">Peanuts99</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890163">parent</a><span>|</span><a href="#41894278">next</a><span>|</span><label class="collapse" for="c-41895317">[-]</label><label class="expand" for="c-41895317">[2 more]</label></div><br/><div class="children"><div class="content">If this is what society has to pay to improve Tesla&#x27;s product, then perhaps they should have to share the software with other car manufacturers too.<p>Otherwise every car brand will have to kill a whole heap of people too until they manage to make a FSD system.</div><br/><div id="41896045" class="c"><input type="checkbox" id="c-41896045" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895317">parent</a><span>|</span><a href="#41894278">next</a><span>|</span><label class="collapse" for="c-41896045">[-]</label><label class="expand" for="c-41896045">[1 more]</label></div><br/><div class="children"><div class="content">Elon has said many times that they are willing to license FSD but nobody else has been interested so far. Clearly that will change if they reach their goals.<p>Also, &quot;years of death and injury&quot; is a bald-faced lie. NHTSA would have shut down FSD a long time ago if it were happening. The statistics Tesla has released to the public are lacking, it&#x27;s true, but they cannot hide things from the NHTSA. FSD has been on the road for years and a billion miles and if it was overall significantly worse than normal driving (when supervised, of course) the NHTSA would know by now.<p>The current investigation is about performance under specific conditions, and it&#x27;s possible that improvement is possible and necessary. But overall crash rates have not reflected any significant extra danger by public use of FSD even in its primitive and flawed form of earlier this year and before.</div><br/></div></div></div></div><div id="41894278" class="c"><input type="checkbox" id="c-41894278" checked=""/><div class="controls bullet"><span class="by">quailfarmer</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890163">parent</a><span>|</span><a href="#41895317">prev</a><span>|</span><a href="#41894434">next</a><span>|</span><label class="collapse" for="c-41894278">[-]</label><label class="expand" for="c-41894278">[1 more]</label></div><br/><div class="children"><div class="content">If the answer was yes, presumably there’s a tradeoff where that deal would be reasonable.</div><br/></div></div><div id="41894434" class="c"><input type="checkbox" id="c-41894434" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890163">parent</a><span>|</span><a href="#41894278">prev</a><span>|</span><a href="#41895493">next</a><span>|</span><label class="collapse" for="c-41894434">[-]</label><label class="expand" for="c-41894434">[7 more]</label></div><br/><div class="children"><div class="content">So far, data points to it having far fewer crashes than a human alone.     Teslas data shows that, but 3rd party data seems to imply the same.</div><br/><div id="41895126" class="c"><input type="checkbox" id="c-41895126" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894434">parent</a><span>|</span><a href="#41894584">next</a><span>|</span><label class="collapse" for="c-41895126">[-]</label><label class="expand" for="c-41895126">[5 more]</label></div><br/><div class="children"><div class="content">Tesla does not release the data required to substantiate such a claim. It simply doesn’t and you’re either lying or being lied to.</div><br/><div id="41895194" class="c"><input type="checkbox" id="c-41895194" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895126">parent</a><span>|</span><a href="#41894584">next</a><span>|</span><label class="collapse" for="c-41895194">[-]</label><label class="expand" for="c-41895194">[4 more]</label></div><br/><div class="children"><div class="content">tesla releases this data:  <a href="https:&#x2F;&#x2F;www.tesla.com&#x2F;VehicleSafetyReport" rel="nofollow">https:&#x2F;&#x2F;www.tesla.com&#x2F;VehicleSafetyReport</a></div><br/><div id="41895375" class="c"><input type="checkbox" id="c-41895375" checked=""/><div class="controls bullet"><span class="by">rainsford</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895194">parent</a><span>|</span><a href="#41897290">next</a><span>|</span><label class="collapse" for="c-41895375">[-]</label><label class="expand" for="c-41895375">[1 more]</label></div><br/><div class="children"><div class="content">That data is not an apples to apples comparison unless autopilot is used in exactly the same mix of conditions as human driving.  Tesla doesn&#x27;t share that in the report, but I&#x27;d bet it&#x27;s not equivalent.  I personally tend to turn on driving automation features (in my non-Tesla car) in easier conditions and drive myself when anything unusual or complicated is going on, and I&#x27;d bet most drivers of Teslas and otherwise do the same.<p>This is important because I&#x27;d bet similar data on the use of standard, non-adaptive cruise control would similarly show it&#x27;s much safer than human drivers.  But of course that would be because people use cruise control most in long-distance highway driving outside of congested areas, where you&#x27;re least likely to have an accident.</div><br/></div></div><div id="41897290" class="c"><input type="checkbox" id="c-41897290" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895194">parent</a><span>|</span><a href="#41895375">prev</a><span>|</span><a href="#41896186">next</a><span>|</span><label class="collapse" for="c-41897290">[-]</label><label class="expand" for="c-41897290">[1 more]</label></div><br/><div class="children"><div class="content">No, it releases enough data to actively mislead you (because there is no way Tesla&#x27;s data people are unaware of these factors):<p>The report measures accidents in FSD mode. Qualifiers to FSD mode: the conditions, weather, road, location, traffic all have to meet a certain quality threshold before the system will be enabled (or not disable itself). Compare Sunnyvale on a clear spring day to Pittsburgh December nights.<p>There&#x27;s no qualifier to the &quot;comparison&quot;: all drivers, all conditions, all weather, all roads, all location, all traffic.<p>It&#x27;s not remotely comparable, and Tesla&#x27;s data people are not that stupid, so it&#x27;s willfully misleading.<p>This report does not include fatalities. It also doesn&#x27;t consider any incident where there was not airbag deployment to be an accident. Sounds potentially reasonable until you consider:<p>- first gen airbag systems were primitive: collision exceeds threshold, deploy. Currently, vehicle safety systems consider duration of impact, speeds, G-forces, amount of intrusion, angle of collision, and a multitude of other factors before deciding what, if any, systems to fire (seatbelt tensioners, airbags, etc.) So hit something at 30mph with the right variables? Tesla: &quot;this is not an accident&quot;.<p>- Tesla also does not consider &quot;incident was so catastrophic that airbags COULD NOT deploy*&quot; to be an accident, because &quot;airbags didn&#x27;t deploy&quot;. This umbrella could also include egregious, &quot;systems failed to deploy for any reason up to and including poor assembly line quality control&quot;, as also not an accident and also &quot;not counted&quot;.</div><br/></div></div><div id="41896186" class="c"><input type="checkbox" id="c-41896186" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895194">parent</a><span>|</span><a href="#41897290">prev</a><span>|</span><a href="#41894584">next</a><span>|</span><label class="collapse" for="c-41896186">[-]</label><label class="expand" for="c-41896186">[1 more]</label></div><br/><div class="children"><div class="content">Per the other comment: no, they don&#x27;t. This data is not enough to evaluate its safety. This is enough data to mislead people who spend &lt;30 seconds thinking about the question though, so I guess that&#x27;s something (something == misdirection and dishonesty).<p>You&#x27;ve been lied to.</div><br/></div></div></div></div></div></div><div id="41894584" class="c"><input type="checkbox" id="c-41894584" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894434">parent</a><span>|</span><a href="#41895126">prev</a><span>|</span><a href="#41895493">next</a><span>|</span><label class="collapse" for="c-41894584">[-]</label><label class="expand" for="c-41894584">[1 more]</label></div><br/><div class="children"><div class="content">It disconnects in case of dangerous situations, so every 33 miles to 77 miles driven (depending on the version), versus 400&#x27;000 miles for a human</div><br/></div></div></div></div><div id="41895493" class="c"><input type="checkbox" id="c-41895493" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890163">parent</a><span>|</span><a href="#41894434">prev</a><span>|</span><a href="#41893442">next</a><span>|</span><label class="collapse" for="c-41895493">[-]</label><label class="expand" for="c-41895493">[2 more]</label></div><br/><div class="children"><div class="content">We also pay this price with every new human driver we train. again and again.</div><br/><div id="41898694" class="c"><input type="checkbox" id="c-41898694" checked=""/><div class="controls bullet"><span class="by">dham</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895493">parent</a><span>|</span><a href="#41893442">next</a><span>|</span><label class="collapse" for="c-41898694">[-]</label><label class="expand" for="c-41898694">[1 more]</label></div><br/><div class="children"><div class="content">You won&#x27;t be able to bring logic to people with Elon derangement syndrome.</div><br/></div></div></div></div></div></div><div id="41893442" class="c"><input type="checkbox" id="c-41893442" checked=""/><div class="controls bullet"><span class="by">m463</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41890163">prev</a><span>|</span><a href="#41890547">next</a><span>|</span><label class="collapse" for="c-41893442">[-]</label><label class="expand" for="c-41893442">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the rate of improvement in the past two months has been much faster than before.<p>I suspect the free trials let tesla collect orders of magnitude more data on events requiring human intervention.  If each one is a learning event, it could exponentially improve things.<p>I tried it on a loaner car and thought it was pretty good.<p>One bit of feedback I would give tesla - when you get some sort of FSD message on the center screen, make the text BIG and either make it linger more, or let you recall it.<p>For example, it took me a couple tries to read the message that gave instructions on how to give tesla feedback on why you intervened.<p>EDIT: look at this graph<p><a href="https:&#x2F;&#x2F;electrek.co&#x2F;wp-content&#x2F;uploads&#x2F;sites&#x2F;3&#x2F;2024&#x2F;10&#x2F;Screenshot-2024-10-14-at-4.12.48%E2%80%AFPM.jpg" rel="nofollow">https:&#x2F;&#x2F;electrek.co&#x2F;wp-content&#x2F;uploads&#x2F;sites&#x2F;3&#x2F;2024&#x2F;10&#x2F;Scree...</a></div><br/></div></div><div id="41890547" class="c"><input type="checkbox" id="c-41890547" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41893442">prev</a><span>|</span><a href="#41890374">next</a><span>|</span><label class="collapse" for="c-41890547">[-]</label><label class="expand" for="c-41890547">[10 more]</label></div><br/><div class="children"><div class="content">If I had a dime for every hackernews who commented that FSD version X was like a revelation compared to FSD version X-ε I&#x27;d have like thirty bucks. I will grant you that every release has surprisingly different behaviors.<p>Here&#x27;s an unintentionally hilarious meta-post on the subject <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29531915">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29531915</a></div><br/><div id="41890595" class="c"><input type="checkbox" id="c-41890595" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890547">parent</a><span>|</span><a href="#41896509">next</a><span>|</span><label class="collapse" for="c-41890595">[-]</label><label class="expand" for="c-41890595">[6 more]</label></div><br/><div class="children"><div class="content">Sure, plenty of people have been saying it&#x27;s great for a long time, when it clearly was not (looking at you, Whole Mars Catalog). <i>I</i> was not saying it was super great back then. I have consistently been critical of Elon for promising human level self driving &quot;next year&quot; for like 10 years in a row and being wrong every time. He said it this year again and I still think he&#x27;s wrong.<p>But the rate of progress I see right now has me thinking that it may not be more than two or three years before that threshold is finally reached.</div><br/><div id="41890818" class="c"><input type="checkbox" id="c-41890818" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890595">parent</a><span>|</span><a href="#41896509">next</a><span>|</span><label class="collapse" for="c-41890818">[-]</label><label class="expand" for="c-41890818">[5 more]</label></div><br/><div class="children"><div class="content">The most important lesson I&#x27;ve had from me incorrectly predicting in 2009 that we&#x27;d have cars that don&#x27;t come with steering wheels in 2018, and thinking that the progress I saw each year up to then was consistent with that prediction, is that it&#x27;s really hard to guess how long it takes to walk the fractal path that is software R&amp;D.<p>How far are we now, 6 years later than I expected?<p>Dunno.<p>I suspect it&#x27;s gonna need an invention on the same level as Diffusion or Transformer models to be able to get all the edge cases we can get, and that might mean we only get it with human level AGI.<p>But I don&#x27;t know that, it might be we&#x27;ve already got all we need architecture-wise and it&#x27;s just a matter of scale.<p>Only thing I can be really sure of is we&#x27;re making progress &quot;quite fast&quot; in a non-objective use of the words — it&#x27;s not going to need a re-run of 6 million years of mammilian evolution or anything like that, but even 20 years wall clock time would be a disappointment.</div><br/><div id="41890938" class="c"><input type="checkbox" id="c-41890938" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890818">parent</a><span>|</span><a href="#41896509">next</a><span>|</span><label class="collapse" for="c-41890938">[-]</label><label class="expand" for="c-41890938">[4 more]</label></div><br/><div class="children"><div class="content">Waymo went driverless in 2020, maybe you weren&#x27;t that far off. Predicting that in 2009 would have been pretty good. They could and should have had vehicles without steering wheels anytime since then, it&#x27;s just a matter of hardware development. Their steering wheel free car program was derailed when they hired traditional car company executives.</div><br/><div id="41891427" class="c"><input type="checkbox" id="c-41891427" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890938">parent</a><span>|</span><a href="#41896509">next</a><span>|</span><label class="collapse" for="c-41891427">[-]</label><label class="expand" for="c-41891427">[3 more]</label></div><br/><div class="children"><div class="content">Waymo for sure, but I meant also without any geolock etc., so I can&#x27;t claim credit for my prediction.<p>They may well best Tesla to this, though.</div><br/><div id="41896217" class="c"><input type="checkbox" id="c-41896217" checked=""/><div class="controls bullet"><span class="by">IX-103</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891427">parent</a><span>|</span><a href="#41896509">next</a><span>|</span><label class="collapse" for="c-41896217">[-]</label><label class="expand" for="c-41896217">[2 more]</label></div><br/><div class="children"><div class="content">Waymo is using full lidar and other sensors, whereas Tesla is relying on pure vision systems (to the point of removing radar on newer models). So they&#x27;re solving a much harder problem.<p>As for whether it&#x27;s worthwhile to solve that problem when having more sensors will always be safer, that&#x27;s another issue...</div><br/><div id="41896547" class="c"><input type="checkbox" id="c-41896547" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41896217">parent</a><span>|</span><a href="#41896509">next</a><span>|</span><label class="collapse" for="c-41896547">[-]</label><label class="expand" for="c-41896547">[1 more]</label></div><br/><div class="children"><div class="content">Indeed.<p>While it ought to be possible to solve for just RGB… making it needlessly hard for yourself is a fun hack-day side project, not a valuable business solution.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41896509" class="c"><input type="checkbox" id="c-41896509" checked=""/><div class="controls bullet"><span class="by">kylecordes</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890547">parent</a><span>|</span><a href="#41890595">prev</a><span>|</span><a href="#41890815">next</a><span>|</span><label class="collapse" for="c-41896509">[-]</label><label class="expand" for="c-41896509">[1 more]</label></div><br/><div class="children"><div class="content">On one hand, it really has gotten much better over time. It&#x27;s quite impressive.<p>On the other hand, I fear&#x2F;suspect it is asymptotically, rather than linearly, approaching good enough to be unsupervised. It might get halfway there, each year, forever.</div><br/></div></div><div id="41890815" class="c"><input type="checkbox" id="c-41890815" checked=""/><div class="controls bullet"><span class="by">Laaas</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890547">parent</a><span>|</span><a href="#41896509">prev</a><span>|</span><a href="#41890374">next</a><span>|</span><label class="collapse" for="c-41890815">[-]</label><label class="expand" for="c-41890815">[2 more]</label></div><br/><div class="children"><div class="content">Doesn’t this just mean it’s improving rapidly which is a good thing?</div><br/><div id="41891562" class="c"><input type="checkbox" id="c-41891562" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890815">parent</a><span>|</span><a href="#41890374">next</a><span>|</span><label class="collapse" for="c-41891562">[-]</label><label class="expand" for="c-41891562">[1 more]</label></div><br/><div class="children"><div class="content">No, the fact that people say FSD is on the verge of readiness constantly for a decade means there is no widely shared benchmark.</div><br/></div></div></div></div></div></div><div id="41890374" class="c"><input type="checkbox" id="c-41890374" checked=""/><div class="controls bullet"><span class="by">delusional</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41890547">prev</a><span>|</span><a href="#41894426">next</a><span>|</span><label class="collapse" for="c-41890374">[-]</label><label class="expand" for="c-41890374">[5 more]</label></div><br/><div class="children"><div class="content">&gt; That said, there is a night and day difference between FSD 12.3 that you experienced earlier this year and the latest version 12.6<p>&gt;And I don&#x27;t even have 12.6 yet, this is still 12.5;<p>How am i supposed to take anything you say seriously when your only claim is a personal anecdote that doesn&#x27;t even apply to your own argument. Please, think about what you&#x27;re writing, and please stop repeating information you heard on youtube as if it&#x27;s fact.<p>The is one of the reasons (among many) that I can&#x27;t take Tesla booster seriously. I have absolutely zero faith in your anecdote that you didn&#x27;t touch the steering wheel. I bet it&#x27;s a lie.</div><br/><div id="41891686" class="c"><input type="checkbox" id="c-41891686" checked=""/><div class="controls bullet"><span class="by">jsjohnst</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890374">parent</a><span>|</span><a href="#41890462">next</a><span>|</span><label class="collapse" for="c-41891686">[-]</label><label class="expand" for="c-41891686">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I have absolutely zero faith in your anecdote that you didn&#x27;t touch the steering wheel. I bet it&#x27;s a lie.<p>I’m not GP, but I can share video showing it driving across residential, city, highway, and even gravel roads all in a single trip without touching the steering wheel a single time over a 90min trip (using 12.5.4.1).</div><br/><div id="41892020" class="c"><input type="checkbox" id="c-41892020" checked=""/><div class="controls bullet"><span class="by">jsjohnst</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891686">parent</a><span>|</span><a href="#41890462">next</a><span>|</span><label class="collapse" for="c-41892020">[-]</label><label class="expand" for="c-41892020">[1 more]</label></div><br/><div class="children"><div class="content">And if someone wants to claim I’m cherry picking the video, happy to shoot a new video with this post visible on an iPad in the seat next to me. Is it autonomous? Hell no. Can it drive in Manhattan? Nope. But can it do &gt;80% of my regular city (suburb outside nyc) and highway driving, yep.</div><br/></div></div></div></div><div id="41890462" class="c"><input type="checkbox" id="c-41890462" checked=""/><div class="controls bullet"><span class="by">eric_cc</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890374">parent</a><span>|</span><a href="#41891686">prev</a><span>|</span><a href="#41890454">next</a><span>|</span><label class="collapse" for="c-41890462">[-]</label><label class="expand" for="c-41890462">[1 more]</label></div><br/><div class="children"><div class="content">I can second this experience. I rarely touch the wheel anymore. I’d say I’m 98% FSD. I take over in school zones, parking lots, and complex construction.</div><br/></div></div><div id="41890454" class="c"><input type="checkbox" id="c-41890454" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890374">parent</a><span>|</span><a href="#41890462">prev</a><span>|</span><a href="#41894426">next</a><span>|</span><label class="collapse" for="c-41890454">[-]</label><label class="expand" for="c-41890454">[1 more]</label></div><br/><div class="children"><div class="content">The version I have is already a night and day difference from 12.3 and the current version is better still. Nothing I said is contradictory in the slightest. Apply some basic reasoning, please.<p>I didn&#x27;t say I didn&#x27;t touch the steering wheel. I had my hands lightly touching it most of the time, as one should for safety. I occasionally used the controls on the wheel as well as the accelerator pedal to adjust the set speed, and I used the turn signal to suggest lane changes from time to time, though most lane choices were made automatically. But I did not <i>turn</i> the wheel. All turning was performed by the system. (If you turn the wheel manually the system disengages). Other than parking, as I mentioned, though FSD did handle some navigation into and inside parking lots.</div><br/></div></div></div></div><div id="41894426" class="c"><input type="checkbox" id="c-41894426" checked=""/><div class="controls bullet"><span class="by">josefx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41890374">prev</a><span>|</span><a href="#41890177">next</a><span>|</span><label class="collapse" for="c-41894426">[-]</label><label class="expand" for="c-41894426">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it will be quite good within a year<p>The regressions are getting worse. For the first release anouncement it was only hitting regulatory hurdles and now the entire software stack is broken? They should fire whoever is in charge and restore the state Elon tried to release a decade ago.</div><br/></div></div><div id="41890177" class="c"><input type="checkbox" id="c-41890177" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41894426">prev</a><span>|</span><a href="#41890174">next</a><span>|</span><label class="collapse" for="c-41890177">[-]</label><label class="expand" for="c-41890177">[3 more]</label></div><br/><div class="children"><div class="content">&gt; At the current rate of improvement it will be quite good within a year<p>I&#x27;ll believe it when I see it. I&#x27;m not sure &quot;quite good&quot; is the next step after &quot;feels dangerous&quot;.</div><br/><div id="41894658" class="c"><input type="checkbox" id="c-41894658" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890177">parent</a><span>|</span><a href="#41890174">next</a><span>|</span><label class="collapse" for="c-41894658">[-]</label><label class="expand" for="c-41894658">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Just round the corner&quot; (2016)</div><br/><div id="41897808" class="c"><input type="checkbox" id="c-41897808" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894658">parent</a><span>|</span><a href="#41890174">next</a><span>|</span><label class="collapse" for="c-41897808">[-]</label><label class="expand" for="c-41897808">[1 more]</label></div><br/><div class="children"><div class="content">Musk in 2016 (these are quotes, not paraphrases): &quot;Self driving is a solved problem. We are just tuning the details.&quot;<p>Musk in 2021: &quot;Right now our highest priority is working on solving the problem.&quot;</div><br/></div></div></div></div></div></div><div id="41890174" class="c"><input type="checkbox" id="c-41890174" checked=""/><div class="controls bullet"><span class="by">misiti3780</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41890177">prev</a><span>|</span><a href="#41889570">next</a><span>|</span><label class="collapse" for="c-41890174">[-]</label><label class="expand" for="c-41890174">[15 more]</label></div><br/><div class="children"><div class="content">i have the same experience 12.5 is insanely good. HN is full of people that dont want self driving to succeed for some reason. fortunately, it&#x27;s clear as day to some of us  that tesla approach will work</div><br/><div id="41893961" class="c"><input type="checkbox" id="c-41893961" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890174">parent</a><span>|</span><a href="#41890270">next</a><span>|</span><label class="collapse" for="c-41893961">[-]</label><label class="expand" for="c-41893961">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>HN is full of people that dont want self driving to succeed for some reason.</i><p>I would love for self-driving to succeed.  I do long-ish car trips several times a year, and it would be wonderful if instead of driving, I could be watching a movie or working on something on my laptop.<p>I&#x27;ve tried Waymo a few times, and it feels like magic, and feels safe.  Their record backs up that feeling.  After everything I&#x27;ve seen and read and heard about Tesla, if I got into a Tesla with someone who uses FSD, I&#x27;d ask them to drive manually, and probably decline the ride entirely if they wouldn&#x27;t honor my request.<p>&gt; <i>fortunately, it&#x27;s clear as day to some of us that tesla approach will work</i><p>And based on my experience with Tesla FSD boosters, I expect you&#x27;re basing that on feelings, not on any empirical evidence or actual understanding of the hardware or software.</div><br/></div></div><div id="41890270" class="c"><input type="checkbox" id="c-41890270" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890174">parent</a><span>|</span><a href="#41893961">prev</a><span>|</span><a href="#41897823">next</a><span>|</span><label class="collapse" for="c-41890270">[-]</label><label class="expand" for="c-41890270">[10 more]</label></div><br/><div class="children"><div class="content">Curiousity about why they&#x27;re against it and enunciating your why you think it will work would be more helpful.</div><br/><div id="41890659" class="c"><input type="checkbox" id="c-41890659" checked=""/><div class="controls bullet"><span class="by">misiti3780</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890270">parent</a><span>|</span><a href="#41897823">next</a><span>|</span><label class="collapse" for="c-41890659">[-]</label><label class="expand" for="c-41890659">[9 more]</label></div><br/><div class="children"><div class="content">It&#x27;s evident to Tesla drivers using Full Self-Driving (FSD) that the technology is rapidly improving and will likely succeed. The key reason for this anticipated success is data: any reasonably intelligent observer recognizes that training exceptional deep neural networks requires vast amounts of data, and Tesla has accumulated more relevant data than any of its competitors. Tesla recently held a robotaxi event, explicitly informing investors of their plans to launch an autonomous competitor to Uber. While Elon Musk&#x27;s timeline predictions and politics may be controversial, his ability to achieve results and attract top engineering and management talent is undeniable.</div><br/><div id="41893945" class="c"><input type="checkbox" id="c-41893945" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890659">parent</a><span>|</span><a href="#41894709">next</a><span>|</span><label class="collapse" for="c-41893945">[-]</label><label class="expand" for="c-41893945">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>It&#x27;s evident to Tesla drivers using Full Self-Driving (FSD) that the technology is rapidly improving and will likely succeed</i><p>Sounds like Tesla drivers have been at the Kool-Aid then.<p>But to be a bit more serious, the problem isn&#x27;t necessarily that people don&#x27;t think it&#x27;s improving (I do believe it is) or that they will likely succeed (I&#x27;m not sure where I stand on this).  The problem is that every year Musk says the next year will be the Year of FSD.  And every next year, it doesn&#x27;t materialize.  This is like the Boy Who Cried Wolf; Musk has zero credibility with me when it comes to predictions.  And that loss of credibility affects my feeling as to whether he&#x27;ll be successful at all.<p>On top of that, I&#x27;m not convinced that autonomous driving that only makes use of cameras will ever be reliably safer than human drivers.</div><br/><div id="41896091" class="c"><input type="checkbox" id="c-41896091" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41893945">parent</a><span>|</span><a href="#41894709">next</a><span>|</span><label class="collapse" for="c-41896091">[-]</label><label class="expand" for="c-41896091">[1 more]</label></div><br/><div class="children"><div class="content">I have consistently been critical of Musk for this over the many years it&#x27;s been happening. Even right now, I don&#x27;t believe FSD will be unsupervised next year like he just claimed. And yet, I can see the real progress and I am convinced that while it won&#x27;t be next year, it could absolutely happen within two or three years.<p>One of these years, he is going to be right. And at that point, the fact that he was wrong for a long time won&#x27;t diminish their achievement. As he likes to say, he specializes in transforming technology from &quot;impossible&quot; to &quot;late&quot;.<p>&gt; I&#x27;m not convinced that autonomous driving that only makes use of cameras will ever be reliably safer than human drivers.<p>Believing this means that you believe AIs will never match or surpass the human brain. Which I think is a much less common view today than it was a few years ago. Personally I think it is obviously wrong. And also I don&#x27;t believe surpassing the human brain in every respect will be necessary to beat humans in driving safety. Unsupervised FSD will come before AGI.</div><br/></div></div></div></div><div id="41894709" class="c"><input type="checkbox" id="c-41894709" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890659">parent</a><span>|</span><a href="#41893945">prev</a><span>|</span><a href="#41892088">next</a><span>|</span><label class="collapse" for="c-41894709">[-]</label><label class="expand" for="c-41894709">[3 more]</label></div><br/><div class="children"><div class="content">&gt;  and Tesla has accumulated more relevant data than any of its competitors.<p>Has it really? How much data is each car sending to Tesla HQ? Anybody actually know?  That&#x27;s a lot of cell phone bandwidth to pay for, and a lot of data to digest.<p>Vast amounts of data about routine driving is not all that useful, anyway. A &quot;highlights reel&quot; of interesting situations is probably more valuable for training. Waymo has shown some highlights reels like that, such as the one were someone in a powered wheelchair is chasing a duck in the middle of a residential street.</div><br/><div id="41896324" class="c"><input type="checkbox" id="c-41896324" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894709">parent</a><span>|</span><a href="#41892088">next</a><span>|</span><label class="collapse" for="c-41896324">[-]</label><label class="expand" for="c-41896324">[2 more]</label></div><br/><div class="children"><div class="content">Anyone who believes Tesla beats Google because they are better at collecting and handling data can be safely ignored.</div><br/><div id="41900783" class="c"><input type="checkbox" id="c-41900783" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41896324">parent</a><span>|</span><a href="#41892088">next</a><span>|</span><label class="collapse" for="c-41900783">[-]</label><label class="expand" for="c-41900783">[1 more]</label></div><br/><div class="children"><div class="content">The argument wouldn&#x27;t be &quot;better at&quot; but simply &quot;more&quot;.<p>Sensor platforms deployed at scale, that you have the right to take data from, are difficult to replicate.</div><br/></div></div></div></div></div></div><div id="41892088" class="c"><input type="checkbox" id="c-41892088" checked=""/><div class="controls bullet"><span class="by">ryandrake</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890659">parent</a><span>|</span><a href="#41894709">prev</a><span>|</span><a href="#41895153">next</a><span>|</span><label class="collapse" for="c-41892088">[-]</label><label class="expand" for="c-41892088">[1 more]</label></div><br/><div class="children"><div class="content">Then why have we been just a year or two away from actual working self-driving, for the last 10 years? If I told my boss that my project would be done in a year, and then the following year said the same thing, and continued that for years, that’s not what “achieving results” means.</div><br/></div></div><div id="41895153" class="c"><input type="checkbox" id="c-41895153" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890659">parent</a><span>|</span><a href="#41892088">prev</a><span>|</span><a href="#41895855">next</a><span>|</span><label class="collapse" for="c-41895153">[-]</label><label class="expand" for="c-41895153">[1 more]</label></div><br/><div class="children"><div class="content">The crux of the issue is that <i>your interpretation of performance cannot be trusted</i>. It is absolutely irrelevant.<p>Even a system that is 99% reliable will <i>honestly feel</i> very, very good to an individual operator, but would result in <i>huge</i> loss of life when scaled up.<p>Tesla can earn more trust be releasing the data necessary to evaluate the system’s performance. The fact that they do not is <i>far</i> more informative than a bunch of commentators saying “hey it’s better than it was last month!” for the last several years — even if it is true that it’s getting better and even if it’s true it’s hypothetically possible to get to the finish line.</div><br/></div></div><div id="41895855" class="c"><input type="checkbox" id="c-41895855" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890659">parent</a><span>|</span><a href="#41895153">prev</a><span>|</span><a href="#41897823">next</a><span>|</span><label class="collapse" for="c-41895855">[-]</label><label class="expand" for="c-41895855">[1 more]</label></div><br/><div class="children"><div class="content">Tesla&#x27;s sensor suite does not support safe FSD.<p>It relies on inferred depth from a single point of view. This means that the depth&#x2F;positioning info for the entire world is noisy.<p>From a safety critical point of view its also bollocks, because a single birdshit&#x2F;smear&#x2F;raindrop&#x2F;oil can render the entire system inoperable. Does it degrade safely? does it fuck.<p>&gt; recognizes that training exceptional deep neural networks requires vast amounts of data,<p>You missed <i>good</i> data. Recording generic driver&#x27;s journeys isn&#x27;t going to yield good data, especially if the people who are driving aren&#x27;t very good. You need to have a bunch of decent drivers doing specific scenarios.<p>Moreover that data isn&#x27;t easily generalisable to other sensor suites. Add another camera? yeahna, new model.<p>&gt; Tesla recently held a robotaxi event, explicitly informing investors of their plans<p>When has Musk ever delivered on time?<p>&gt;  his ability to achieve results<p>most of those results aren&#x27;t that great. Tesla isn&#x27;t growing anymore, its reliant on state subsidies to be profitable. They still only ship 400k units a quarter, which is tiny compared to VW&#x27;s 2.2million.<p>&gt; attract top engineering and management talent is undeniable<p>Most of the decent computer vision people are not in tesla. Hardware wise, their factories aren&#x27;t fun places to be. He&#x27;s a dick to work for, capricious and vindictive.</div><br/></div></div></div></div></div></div><div id="41897823" class="c"><input type="checkbox" id="c-41897823" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890174">parent</a><span>|</span><a href="#41890270">prev</a><span>|</span><a href="#41890473">next</a><span>|</span><label class="collapse" for="c-41897823">[-]</label><label class="expand" for="c-41897823">[1 more]</label></div><br/><div class="children"><div class="content">I would love self-driving to succeed. I should be a Tesla fan, because I&#x27;m very much a fan of geekery and tech anywhere and everywhere.<p>But no. I want self-driving to succeed, and when it does (which I don&#x27;t think is that soon, because the last 10% takes 90% of the time), I don&#x27;t think Tesla or their approach will be the &quot;winner&quot;.</div><br/></div></div><div id="41890473" class="c"><input type="checkbox" id="c-41890473" checked=""/><div class="controls bullet"><span class="by">eric_cc</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890174">parent</a><span>|</span><a href="#41897823">prev</a><span>|</span><a href="#41889570">next</a><span>|</span><label class="collapse" for="c-41890473">[-]</label><label class="expand" for="c-41890473">[2 more]</label></div><br/><div class="children"><div class="content">Completely agree. It’s very strange. But honestly it’s their loss. FSD is fantastic.</div><br/><div id="41895165" class="c"><input type="checkbox" id="c-41895165" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890473">parent</a><span>|</span><a href="#41889570">next</a><span>|</span><label class="collapse" for="c-41895165">[-]</label><label class="expand" for="c-41895165">[1 more]</label></div><br/><div class="children"><div class="content">Very strange not wanting poorly controlled 4,000lb steel cages driving around at 70mph stewarded by people calling “only had to stop it from killing me 4 times today!” as great success.</div><br/></div></div></div></div></div></div><div id="41889570" class="c"><input type="checkbox" id="c-41889570" checked=""/><div class="controls bullet"><span class="by">seizethecheese</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889518">parent</a><span>|</span><a href="#41890174">prev</a><span>|</span><a href="#41889213">next</a><span>|</span><label class="collapse" for="c-41889570">[-]</label><label class="expand" for="c-41889570">[1 more]</label></div><br/><div class="children"><div class="content"><i>If</i> this is the case, the calls for heavy regulation in this thread will lead to many more deaths than otherwise.</div><br/></div></div></div></div><div id="41889213" class="c"><input type="checkbox" id="c-41889213" checked=""/><div class="controls bullet"><span class="by">frabjoused</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41889518">prev</a><span>|</span><a href="#41890380">next</a><span>|</span><label class="collapse" for="c-41889213">[-]</label><label class="expand" for="c-41889213">[37 more]</label></div><br/><div class="children"><div class="content">The thing that doesn&#x27;t make sense is the numbers. If it is dangerous in your anecdotes, why don&#x27;t the reported numbers show more accidents when FSD is on?<p>When I did the trial on my Tesla, I also noted these kinds of things and felt like I had to take control.<p>But at the end of the day, only the numbers matter.</div><br/><div id="41889251" class="c"><input type="checkbox" id="c-41889251" checked=""/><div class="controls bullet"><span class="by">timabdulla</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41889339">next</a><span>|</span><label class="collapse" for="c-41889251">[-]</label><label class="expand" for="c-41889251">[5 more]</label></div><br/><div class="children"><div class="content">&gt;  If it is dangerous in your anecdotes, why don&#x27;t the reported numbers show more accidents when FSD is on?<p>Even if it is true that the data show that with FSD (not Autopilot) enabled, drivers are in fewer crashes, I would be worried about other confounding factors.<p>For instance, I would assume that drivers are more likely to engage FSD in situations of lower complexity (less traffic, little construction or other impediments, overall lesser traffic flow control complexity, etc.) I also believe that at least initially, Tesla only released FSD to drivers with high safety scores relative to their total driver base, another obvious confounding factor.<p>Happy to be proven wrong though if you have a link to a recent study that goes through all of this.</div><br/><div id="41890026" class="c"><input type="checkbox" id="c-41890026" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889251">parent</a><span>|</span><a href="#41889339">next</a><span>|</span><label class="collapse" for="c-41890026">[-]</label><label class="expand" for="c-41890026">[4 more]</label></div><br/><div class="children"><div class="content">Either the system causes less loss of life than a human driver or it doesn’t. The confounding factors don’t matter, as Tesla hasn’t presented a study on the subject. That’s in the future, and all stats that are being gathered right now are just that.</div><br/><div id="41890292" class="c"><input type="checkbox" id="c-41890292" checked=""/><div class="controls bullet"><span class="by">unbrice</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890026">parent</a><span>|</span><a href="#41894083">next</a><span>|</span><label class="collapse" for="c-41890292">[-]</label><label class="expand" for="c-41890292">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Either the system causes less loss of life than a human driver or it doesn’t. The confounding factors don’t matter.<p>Confounding factors are what allows one to tell appart &quot;the system cause less loss of life&quot; from &quot;the system causes more loss of life yet it is only enabled in situations were fewer lives are lost&quot;.</div><br/></div></div><div id="41894083" class="c"><input type="checkbox" id="c-41894083" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890026">parent</a><span>|</span><a href="#41890292">prev</a><span>|</span><a href="#41889339">next</a><span>|</span><label class="collapse" for="c-41894083">[-]</label><label class="expand" for="c-41894083">[2 more]</label></div><br/><div class="children"><div class="content">No, that&#x27;s absolutely not how this works.  Confounding factors are things that make your data not tell you what you are actually trying to understand.  You can&#x27;t just hand-wave that away, sorry.<p>Consider: what I expect is <i>actually</i> true based on the data is that Tesla FSD is as safe or safer than the average human driver, but only if the driver is paying attention and is ready to take over in case FSD does something unsafe, even if FSD doesn&#x27;t warn the driver it needs to disengage.<p>That&#x27;s not an autonomous driving system.  Which is potentially fine, but the value prop of that system is low to me: I have to pay just as much attention as if I were driving manually, with the added problem that my attention is going to start to wander because the car is doing most of the work, and the longer the car successfully does most of the work, the more I&#x27;m going to unconsciously believe I can allow my attention to slip.<p>I do like current common ADAS features because they hit a good sweet spot: I still need to actively hold onto the wheel and handle initiating lane changes, turns, stopping and starting at traffic lights and stop signs, etc.  I look at the ADAS as a sort of &quot;backup&quot; to my own driving, and not as what&#x27;s primarily in control of the car.  In contrast, Tesla FSD wants to be primarily in control of the car, but it&#x27;s not trustworthy enough to do that without constant supervision.</div><br/><div id="41901681" class="c"><input type="checkbox" id="c-41901681" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894083">parent</a><span>|</span><a href="#41889339">next</a><span>|</span><label class="collapse" for="c-41901681">[-]</label><label class="expand" for="c-41901681">[1 more]</label></div><br/><div class="children"><div class="content">Like I said, the time for studies is in the future. FSD is a product in development and they know which stats they need to track in order to track progress.<p>You’re arguing for something that:
1. Isn’t under contention and
2. Isn’t rooted in the real world.<p>You’re right FSD isn’t an autonomous driving system. It’s not meant to be, right now.</div><br/></div></div></div></div></div></div></div></div><div id="41889339" class="c"><input type="checkbox" id="c-41889339" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41889251">prev</a><span>|</span><a href="#41889239">next</a><span>|</span><label class="collapse" for="c-41889339">[-]</label><label class="expand" for="c-41889339">[8 more]</label></div><br/><div class="children"><div class="content">There is an easy way to know what is really behind the numbers: look who is paying in case of accident.<p>You have a Mercedes, Mercedes takes responsibility.<p>You have a Tesla, you take the responsibility.<p>Says a lot.</div><br/><div id="41890421" class="c"><input type="checkbox" id="c-41890421" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889339">parent</a><span>|</span><a href="#41890160">next</a><span>|</span><label class="collapse" for="c-41890421">[-]</label><label class="expand" for="c-41890421">[1 more]</label></div><br/><div class="children"><div class="content">Mercedes had the insight that if no one is able to actually use the system then it can&#x27;t cause any crashes.<p>Technically, that is the easiest way to get a perfect safety record and journalists will seemingly just go along with the charade.</div><br/></div></div><div id="41890160" class="c"><input type="checkbox" id="c-41890160" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889339">parent</a><span>|</span><a href="#41890421">prev</a><span>|</span><a href="#41892425">next</a><span>|</span><label class="collapse" for="c-41890160">[-]</label><label class="expand" for="c-41890160">[5 more]</label></div><br/><div class="children"><div class="content">You have a Mercedes, and you have a system that works virtually nowhere.</div><br/><div id="41890605" class="c"><input type="checkbox" id="c-41890605" checked=""/><div class="controls bullet"><span class="by">therouwboat</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890160">parent</a><span>|</span><a href="#41892425">next</a><span>|</span><label class="collapse" for="c-41890605">[-]</label><label class="expand" for="c-41890605">[4 more]</label></div><br/><div class="children"><div class="content">Better that way than &quot;Oh it tried to run red light, but otherwise it&#x27;s great.&quot;</div><br/><div id="41891047" class="c"><input type="checkbox" id="c-41891047" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890605">parent</a><span>|</span><a href="#41892425">next</a><span>|</span><label class="collapse" for="c-41891047">[-]</label><label class="expand" for="c-41891047">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Oh we tried to build it but no one bought it! So we gave up.&quot; - Mercedes before Tesla.<p>Perhaps FSD isn&#x27;t ready for city streets yet, but it&#x27;s great on the highways and I&#x27;d 1000x prefer we make progress rather than settle for the status quo garbage that the legacy makers put out.  Also, human drivers are the most dangerous, by far, we need to make progress to eventual phase them out.</div><br/><div id="41891619" class="c"><input type="checkbox" id="c-41891619" checked=""/><div class="controls bullet"><span class="by">meibo</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891047">parent</a><span>|</span><a href="#41892425">next</a><span>|</span><label class="collapse" for="c-41891619">[-]</label><label class="expand" for="c-41891619">[2 more]</label></div><br/><div class="children"><div class="content">2-ton blocks of metal that go 80mph next to me on the highway is not the place I would want people to go &quot;fuck it let&#x27;s just do it&quot; with their new tech. Human drivers might be dangerous but adding more danger and unpredictability on top just because we can skip a few steps in the engineering process is crazy.<p>Maybe you have a deathwish, but I definitely don&#x27;t. Your choices affect other humans in traffic.</div><br/><div id="41898339" class="c"><input type="checkbox" id="c-41898339" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891619">parent</a><span>|</span><a href="#41892425">next</a><span>|</span><label class="collapse" for="c-41898339">[-]</label><label class="expand" for="c-41898339">[1 more]</label></div><br/><div class="children"><div class="content">It sounds like you are the one with a deathwish, because objectively by the numbers Autopilot on the highway has greatly reduced death. So you are literally advocating for more death.<p>You have two imperfect systems for highway driving: Autopilot with human oversight, and humans. The first has far far less death. Yet you are choosing the second.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41892425" class="c"><input type="checkbox" id="c-41892425" checked=""/><div class="controls bullet"><span class="by">diebeforei485</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889339">parent</a><span>|</span><a href="#41890160">prev</a><span>|</span><a href="#41889239">next</a><span>|</span><label class="collapse" for="c-41892425">[-]</label><label class="expand" for="c-41892425">[1 more]</label></div><br/><div class="children"><div class="content">While I don&#x27;t disagree with your point in general, it should be noted that there is more to taking responsibility than just paying. Even if Mercedes Drive Pilot was enabled, anything that involves court appearances and criminal liability is still your problem if you&#x27;re in the driver&#x27;s seat.</div><br/></div></div></div></div><div id="41889239" class="c"><input type="checkbox" id="c-41889239" checked=""/><div class="controls bullet"><span class="by">jsight</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41889339">prev</a><span>|</span><a href="#41894050">next</a><span>|</span><label class="collapse" for="c-41889239">[-]</label><label class="expand" for="c-41889239">[3 more]</label></div><br/><div class="children"><div class="content">Because it is bad enough that people really do supervise it. I see people who say that wouldn&#x27;t happen because the drivers become complacent.<p>Maybe that could be a problem with future versions, but I don&#x27;t see it happening with 12.3.x. I&#x27;ve also heard that driver attention monitoring is pretty good in the later versions, but I have no first hand experience yet.</div><br/><div id="41890002" class="c"><input type="checkbox" id="c-41890002" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889239">parent</a><span>|</span><a href="#41894050">next</a><span>|</span><label class="collapse" for="c-41890002">[-]</label><label class="expand" for="c-41890002">[2 more]</label></div><br/><div class="children"><div class="content">Very good point. The product that requires supervision and tells the user to keep their hands on the wheel every 10 seconds is not good enough to be used unsupervised.<p>I wonder how things are inside your head. Are you ignorant or affected by some strong bias?</div><br/><div id="41892321" class="c"><input type="checkbox" id="c-41892321" checked=""/><div class="controls bullet"><span class="by">jsight</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890002">parent</a><span>|</span><a href="#41894050">next</a><span>|</span><label class="collapse" for="c-41892321">[-]</label><label class="expand" for="c-41892321">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it definitely isn&#x27;t good enough to be used unsupervised. TBH, they&#x27;ve switched to eye and head tracking as the primary mechanism of attention monitoring now. It seems to work pretty well, now that I&#x27;ve had a chance to try it.<p>I&#x27;m not quite sure what you meant by your second paragraph, but I&#x27;m sure I have my blind spots and biases. I do have direct experience with various versions of 12.x though (12.3 and now 12.5).</div><br/></div></div></div></div></div></div><div id="41894050" class="c"><input type="checkbox" id="c-41894050" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41889239">prev</a><span>|</span><a href="#41889246">next</a><span>|</span><label class="collapse" for="c-41894050">[-]</label><label class="expand" for="c-41894050">[1 more]</label></div><br/><div class="children"><div class="content">Agree that only the numbers matter, but only if the numbers are comprehensive and useful.<p>How often does an autonomous driving system get the driver into a dicey situation, but the driver notices the bad behavior, takes control, and avoids a crash?  I don&#x27;t think we have publicly-available data on that at all.<p>You admit that you ran into some of these sorts of situations during your trial.  Those situations are unacceptable.  An autonomous driving system should be safer than a human driver, and should not make mistakes that a human driver would not make.<p>Despite all the YouTube videos out there of people doing unsafe things with Tesla FSD, I expect that most people that use it are pretty responsible, are paying attention, and are ready to take over if they notice FSD doing something wrong.  But if people need to do that, it&#x27;s not a safe, successful autonomous driving system.  Safety means everyone can watch TV, mess around on their phone, or even take a nap, and we <i>still</i> end up with a lower crash rate than with human drivers.<p>The numbers that are available can&#x27;t tell us if that would be the case.  My belief is that we&#x27;re absolutely not there.</div><br/></div></div><div id="41889246" class="c"><input type="checkbox" id="c-41889246" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41894050">prev</a><span>|</span><a href="#41889279">next</a><span>|</span><label class="collapse" for="c-41889246">[-]</label><label class="expand" for="c-41889246">[7 more]</label></div><br/><div class="children"><div class="content">Is Tesla required to report system failures or the vehicle damaging itself? How do we know they&#x27;re not optimizing for the benchmark (what they&#x27;re legally required to report)?</div><br/><div id="41889358" class="c"><input type="checkbox" id="c-41889358" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889246">parent</a><span>|</span><a href="#41890792">next</a><span>|</span><label class="collapse" for="c-41889358">[-]</label><label class="expand" for="c-41889358">[3 more]</label></div><br/><div class="children"><div class="content">If the question is: “was FSD activated at the time of the accident: yes&#x2F;no”, they can legally claim no, for example if luckily the FSD disconnects half a second before a dangerous situation (eg: glare obstructing cameras), which may coincide exactly with the times of some accidents.</div><br/><div id="41892440" class="c"><input type="checkbox" id="c-41892440" checked=""/><div class="controls bullet"><span class="by">diebeforei485</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889358">parent</a><span>|</span><a href="#41890792">next</a><span>|</span><label class="collapse" for="c-41892440">[-]</label><label class="expand" for="c-41892440">[2 more]</label></div><br/><div class="children"><div class="content">&gt; To ensure our statistics are conservative, we count any crash in which Autopilot was deactivated within 5 seconds before impact, and we count all crashes in which the incident alert indicated an airbag or other active restraint deployed.<p>Scroll down to Methodology at <a href="https:&#x2F;&#x2F;www.tesla.com&#x2F;VehicleSafetyReport" rel="nofollow">https:&#x2F;&#x2F;www.tesla.com&#x2F;VehicleSafetyReport</a></div><br/><div id="41894536" class="c"><input type="checkbox" id="c-41894536" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892440">parent</a><span>|</span><a href="#41890792">next</a><span>|</span><label class="collapse" for="c-41894536">[-]</label><label class="expand" for="c-41894536">[1 more]</label></div><br/><div class="children"><div class="content">This is for Autopilot, which is the car following system on highways. If you are in cruise control and staying on your lane, not much is supposed to happen.<p>The FSD numbers are much more hidden.<p>The general accident rate is 1 per 400’000 miles driven.<p>FSD has one “critical disengagement” (aka before accident if human or safety braking doesn’t intervene) every 33 miles driven.<p>It means to reach unsupervised with human quality they would need to improve it 10’000 times in few months. Not saying it is impossible, just highly optimistic. In 10 years we will be there, but in 2 months, sounds a bit overpromising.</div><br/></div></div></div></div></div></div><div id="41890792" class="c"><input type="checkbox" id="c-41890792" checked=""/><div class="controls bullet"><span class="by">Uzza</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889246">parent</a><span>|</span><a href="#41889358">prev</a><span>|</span><a href="#41889279">next</a><span>|</span><label class="collapse" for="c-41890792">[-]</label><label class="expand" for="c-41890792">[3 more]</label></div><br/><div class="children"><div class="content">All manufacturers have for some time been required by regulators to report any accident where an autonomous or partially autonomous system was active within 30 seconds of an accident.</div><br/><div id="41892580" class="c"><input type="checkbox" id="c-41892580" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890792">parent</a><span>|</span><a href="#41889279">next</a><span>|</span><label class="collapse" for="c-41892580">[-]</label><label class="expand" for="c-41892580">[2 more]</label></div><br/><div class="children"><div class="content">My question is better rephrased as &quot;what is legally considered an accident that needs to be reported?&quot; If the car scrapes a barricade or curbs it hard but the airbags don&#x27;t deploy and the car doesn&#x27;t sense the damage, clearly they don&#x27;t. There&#x27;s a wide spectrum of issues up to the point where someone is injured or another car is damaged.</div><br/><div id="41894118" class="c"><input type="checkbox" id="c-41894118" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892580">parent</a><span>|</span><a href="#41889279">next</a><span>|</span><label class="collapse" for="c-41894118">[-]</label><label class="expand" for="c-41894118">[1 more]</label></div><br/><div class="children"><div class="content">And not to move the goalposts, but I think we should also be tracking any time the human driver feels they need to take control because the autonomous system did something they didn&#x27;t believe was safe.<p>That&#x27;s not a crash (fortunately!), but it <i>is</i> a failure of the autonomous system.<p>This is hard to track, though, of course: people might take over control for reasons unrelated to safety, or people may misinterpret something that&#x27;s safe as unsafe.  So you can&#x27;t just track this from a simple &quot;human driver took control&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="41889279" class="c"><input type="checkbox" id="c-41889279" checked=""/><div class="controls bullet"><span class="by">nkrisc</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41889246">prev</a><span>|</span><a href="#41889230">next</a><span>|</span><label class="collapse" for="c-41889279">[-]</label><label class="expand" for="c-41889279">[1 more]</label></div><br/><div class="children"><div class="content">What numbers? Who’s measuring? What are they measuring?</div><br/></div></div><div id="41889230" class="c"><input type="checkbox" id="c-41889230" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41889279">prev</a><span>|</span><a href="#41890713">next</a><span>|</span><label class="collapse" for="c-41889230">[-]</label><label class="expand" for="c-41889230">[1 more]</label></div><br/><div class="children"><div class="content">You can measure risks without having to witness disaster.</div><br/></div></div><div id="41890713" class="c"><input type="checkbox" id="c-41890713" checked=""/><div class="controls bullet"><span class="by">johnneville</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41889230">prev</a><span>|</span><a href="#41895142">next</a><span>|</span><label class="collapse" for="c-41890713">[-]</label><label class="expand" for="c-41890713">[1 more]</label></div><br/><div class="children"><div class="content">are there even transparent reported numbers available ?<p>for whatever does exist, it is also easy to imagine how they could be misleading. for instance i&#x27;ve disengaged FSD when i noticed i was about to be in an accident. if i couldn&#x27;t recover in time, the accident would not be when FSD is on and depending on the metric, would not be reported as a FSD induced accident.</div><br/></div></div><div id="41895142" class="c"><input type="checkbox" id="c-41895142" checked=""/><div class="controls bullet"><span class="by">kybernetikos</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41890713">prev</a><span>|</span><a href="#41889234">next</a><span>|</span><label class="collapse" for="c-41895142">[-]</label><label class="expand" for="c-41895142">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But at the end of the day, only the numbers matter.<p>Are these the numbers reported by tesla, or by some third party?</div><br/></div></div><div id="41889234" class="c"><input type="checkbox" id="c-41889234" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41895142">prev</a><span>|</span><a href="#41890197">next</a><span>|</span><label class="collapse" for="c-41889234">[-]</label><label class="expand" for="c-41889234">[1 more]</label></div><br/><div class="children"><div class="content">Maybe other human drivers are reacting quickly and avoiding potential accidents from dangerous computer driving? That would be ironic, but I&#x27;m sure it&#x27;s possible in some situations.</div><br/></div></div><div id="41890197" class="c"><input type="checkbox" id="c-41890197" checked=""/><div class="controls bullet"><span class="by">lawn</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41889234">prev</a><span>|</span><a href="#41890367">next</a><span>|</span><label class="collapse" for="c-41890197">[-]</label><label class="expand" for="c-41890197">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The thing that doesn&#x27;t make sense is the numbers.<p>Oh? Who are presenting the numbers?<p>Is a crash that fails to trigger the airbags still not counted as a crash?<p>What about the car turning off FSD right before a crash?<p>How about adjusting for factors such as age of driver and the type of miles driven?<p>The numbers don&#x27;t make sense because they&#x27;re not good comparisons and are made to make Tesla look good.</div><br/></div></div><div id="41890367" class="c"><input type="checkbox" id="c-41890367" checked=""/><div class="controls bullet"><span class="by">gamblor956</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41890197">prev</a><span>|</span><a href="#41890522">next</a><span>|</span><label class="collapse" for="c-41890367">[-]</label><label class="expand" for="c-41890367">[1 more]</label></div><br/><div class="children"><div class="content">The numbers collected by the NHTSA and insurance companies do show that FSD is dangerous...that&#x27;s why the NHTSA started investigating and its why most insurance companies won&#x27;t insure Tesla vehicles or charge significantly higher rates.<p>Also, Tesla is known to disable self-driving features right before collisions to give the appearance of driver fault.<p>And the coup de grace: if Tesla&#x27;s own data showed that FSD was actually safer, they&#x27;d be shouting it from the moon, using that data to get self-driving permits in CA, and offering to assume liability if FSD actually caused an accident (like Mercedes does with its self driving system).</div><br/></div></div><div id="41890522" class="c"><input type="checkbox" id="c-41890522" checked=""/><div class="controls bullet"><span class="by">throwaway562if1</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889213">parent</a><span>|</span><a href="#41890367">prev</a><span>|</span><a href="#41890380">next</a><span>|</span><label class="collapse" for="c-41890522">[-]</label><label class="expand" for="c-41890522">[5 more]</label></div><br/><div class="children"><div class="content">AIUI the numbers are for accidents where FSD is in control. Which means if it does a turn into oncoming traffic and the driver yanks the wheel or slams the brakes 500ms before collision, it&#x27;s not considered a crash during FSD.</div><br/><div id="41890770" class="c"><input type="checkbox" id="c-41890770" checked=""/><div class="controls bullet"><span class="by">Uzza</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890522">parent</a><span>|</span><a href="#41890811">next</a><span>|</span><label class="collapse" for="c-41890770">[-]</label><label class="expand" for="c-41890770">[2 more]</label></div><br/><div class="children"><div class="content">That is not correct. Tesla counts any accident within 5 seconds of Autopilot&#x2F;FSD turning off as the system being involved.
Regulators extend that period to 30 seconds, and Tesla must comply with that when reporting to them.</div><br/><div id="41894128" class="c"><input type="checkbox" id="c-41894128" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890770">parent</a><span>|</span><a href="#41890811">next</a><span>|</span><label class="collapse" for="c-41894128">[-]</label><label class="expand" for="c-41894128">[1 more]</label></div><br/><div class="children"><div class="content">How about when it turns into oncoming traffic, the driver yanks the wheel, manages to get back on track, and avoids a crash?  Do we know how often things like that happen?  Because that&#x27;s also a failure of the system, and that should affect how reliable and safe we rate these things.  I expect we don&#x27;t have data on that.<p>Also how about: it turns into oncoming traffic, but there isn&#x27;t much oncoming traffic, and that traffic swerves to get out of the way, before FSD realizes what it&#x27;s done and pulls back into the correct lane.  We <i>certainly</i> don&#x27;t have data on that.</div><br/></div></div></div></div><div id="41890811" class="c"><input type="checkbox" id="c-41890811" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890522">parent</a><span>|</span><a href="#41890770">prev</a><span>|</span><a href="#41890380">next</a><span>|</span><label class="collapse" for="c-41890811">[-]</label><label class="expand" for="c-41890811">[2 more]</label></div><br/><div class="children"><div class="content">Several people in this thread have been saying this or similar. It&#x27;s incorrect, from Tesla:<p>&quot;To ensure our statistics are conservative, we count any crash in which Autopilot was deactivated within 5 seconds before impact&quot;<p><a href="https:&#x2F;&#x2F;www.tesla.com&#x2F;en_gb&#x2F;VehicleSafetyReport" rel="nofollow">https:&#x2F;&#x2F;www.tesla.com&#x2F;en_gb&#x2F;VehicleSafetyReport</a><p>Situations which inevitably cause a crash more than 5 seconds later seem like they would be extremely rare.</div><br/><div id="41894673" class="c"><input type="checkbox" id="c-41894673" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890811">parent</a><span>|</span><a href="#41890380">next</a><span>|</span><label class="collapse" for="c-41894673">[-]</label><label class="expand" for="c-41894673">[1 more]</label></div><br/><div class="children"><div class="content">This is Autopilot, not FSD which is an entirely different product</div><br/></div></div></div></div></div></div></div></div><div id="41890380" class="c"><input type="checkbox" id="c-41890380" checked=""/><div class="controls bullet"><span class="by">mike_d</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41889213">prev</a><span>|</span><a href="#41890785">next</a><span>|</span><label class="collapse" for="c-41890380">[-]</label><label class="expand" for="c-41890380">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Lots of people are asking how good the self driving has to be before we tolerate it.<p>When I feel as safe as I do sitting in the back of a Waymo.</div><br/></div></div><div id="41890785" class="c"><input type="checkbox" id="c-41890785" checked=""/><div class="controls bullet"><span class="by">dchichkov</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41890380">prev</a><span>|</span><a href="#41892569">next</a><span>|</span><label class="collapse" for="c-41890785">[-]</label><label class="expand" for="c-41890785">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m grateful to be getting a car from another manufacturer this year.<p>I&#x27;m curious, what is the alternative that you are considering?  I&#x27;ve been delaying an upgrade to electric for some time.  And now, a car manufacturer that is contributing to the making of another Jan 6th, 2021 is not an option, in my opinion.</div><br/><div id="41892061" class="c"><input type="checkbox" id="c-41892061" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890785">parent</a><span>|</span><a href="#41894929">next</a><span>|</span><label class="collapse" for="c-41892061">[-]</label><label class="expand" for="c-41892061">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve got a deposit on the Dodge Charger Daytona EV</div><br/></div></div><div id="41894929" class="c"><input type="checkbox" id="c-41894929" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890785">parent</a><span>|</span><a href="#41892061">prev</a><span>|</span><a href="#41892569">next</a><span>|</span><label class="collapse" for="c-41894929">[-]</label><label class="expand" for="c-41894929">[3 more]</label></div><br/><div class="children"><div class="content">I also went into car shopping with that opinion, but the options are bleak in terms of other carmakers&#x27; software.  For some reason, if you want basic software features of a Tesla, the other carmakers want an extra $20k+ (and still don&#x27;t have some).<p>A big example is why do the other carmakers not yet offer camera recording on their cars?  They are all using cameras all around, but only Tesla makes it available to you in case you want the footage?  Bizarre.  And then they want to charge you an extra $500+ for one dash cam on the windshield.<p>I even had Carplay&#x2F;Android Auto as a basic requirement, but I was willing to forgo that after trying out the other brands.  And not having to spend hours at a dealership doing paperwork was amazing.  Literally bought the car on my phone and was out the door within 15 minutes on the day of my appointment.</div><br/><div id="41896711" class="c"><input type="checkbox" id="c-41896711" checked=""/><div class="controls bullet"><span class="by">bink</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894929">parent</a><span>|</span><a href="#41892569">next</a><span>|</span><label class="collapse" for="c-41896711">[-]</label><label class="expand" for="c-41896711">[2 more]</label></div><br/><div class="children"><div class="content">Rivian also allows recording drives to an SSD. They also just released a feature where you can view the cameras while it&#x27;s parked. I&#x27;m kinda surprised other manufacturers aren&#x27;t allowing that.</div><br/><div id="41896762" class="c"><input type="checkbox" id="c-41896762" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41896711">parent</a><span>|</span><a href="#41892569">next</a><span>|</span><label class="collapse" for="c-41896762">[-]</label><label class="expand" for="c-41896762">[1 more]</label></div><br/><div class="children"><div class="content">Rivians start at $30k more than Teslas, and while they may be nice, they don’t have the track record yet that Tesla does, and there is a risk the company goes bust since it is currently losing a lot of money.</div><br/></div></div></div></div></div></div></div></div><div id="41892569" class="c"><input type="checkbox" id="c-41892569" checked=""/><div class="controls bullet"><span class="by">browningstreet</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41890785">prev</a><span>|</span><a href="#41895150">next</a><span>|</span><label class="collapse" for="c-41892569">[-]</label><label class="expand" for="c-41892569">[2 more]</label></div><br/><div class="children"><div class="content">Was this the last version, or the version released today?<p>I’ve been pretty skeptical of FSD and didn’t use the last version much. Today I used the latest test version, enabled yesterday, and rode around SF, to and from GGP, and it did really well.<p>Waymo well? Almost. But whereas I haven’t ridden Waymo on the highway yet, FSD got me from Hunters Point to the east bay with no disruptions.<p>The biggest improvement I noticed was its optimizations on highway progress.. it’ll change lanes, nicely, when the lane you’re in is slower than the surrounding lanes. And when you’re in the fast&#x2F;passing lane it’ll return to the next closest lane.<p>Definitely better than the last release.</div><br/><div id="41892600" class="c"><input type="checkbox" id="c-41892600" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892569">parent</a><span>|</span><a href="#41895150">next</a><span>|</span><label class="collapse" for="c-41892600">[-]</label><label class="expand" for="c-41892600">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m clearly not using the FSD today because I refused to complete my free trial of it a few months ago. The post of mine that you&#x27;re responding to doesn&#x27;t mention my troubles with Autopilot, which I highly doubt are addressed by today&#x27;s update (see my other comment for a list of problems). They need to really, really prove to me that Autopilot is working reliably before I&#x27;d even consider accepting another free trial of FSD, which I doubt they&#x27;d do anyway.</div><br/></div></div></div></div><div id="41895150" class="c"><input type="checkbox" id="c-41895150" checked=""/><div class="controls bullet"><span class="by">anonu</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41892569">prev</a><span>|</span><a href="#41894964">next</a><span>|</span><label class="collapse" for="c-41895150">[-]</label><label class="expand" for="c-41895150">[2 more]</label></div><br/><div class="children"><div class="content">My experience has been directionally the same as yours but not of the same magnitude. There&#x27;s a lot of room from improvement but it&#x27;s still very good. I&#x27;m in a slightly suburban setting... I suspect you&#x27;re in a fender denser location that me, in which case your experience may be different.</div><br/><div id="41895212" class="c"><input type="checkbox" id="c-41895212" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895150">parent</a><span>|</span><a href="#41894964">next</a><span>|</span><label class="collapse" for="c-41895212">[-]</label><label class="expand" for="c-41895212">[1 more]</label></div><br/><div class="children"><div class="content">Their irresponsible behavior says enough. Even if they fix all their technical issues, they are not driven by a safety culture.<p>The first question that comes to their minds is not &quot;how can we prevent this accident?&quot; but it&#x27;s &quot;how can we further inflate this bubble?&quot;</div><br/></div></div></div></div><div id="41894964" class="c"><input type="checkbox" id="c-41894964" checked=""/><div class="controls bullet"><span class="by">herdcall</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41895150">prev</a><span>|</span><a href="#41894644">next</a><span>|</span><label class="collapse" for="c-41894964">[-]</label><label class="expand" for="c-41894964">[3 more]</label></div><br/><div class="children"><div class="content">Same here, but I tried the new 12.5.4.1 yesterday and the difference is night and day. It was near flawless except for some unexplained slowdowns and you don&#x27;t even need to hold the steering anymore (it detects attention by looking at your face), they clearly are improving rapidly.</div><br/><div id="41895025" class="c"><input type="checkbox" id="c-41895025" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894964">parent</a><span>|</span><a href="#41894644">next</a><span>|</span><label class="collapse" for="c-41895025">[-]</label><label class="expand" for="c-41895025">[2 more]</label></div><br/><div class="children"><div class="content">How many miles have you driven since the update yesterday? OP described a half dozen different failure modes in a variety of situations that seem to indicate quite extensive testing before they turned it off. How far did you drive the new version and in what circumstances?</div><br/><div id="41895241" class="c"><input type="checkbox" id="c-41895241" checked=""/><div class="controls bullet"><span class="by">AndroidKitKat</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895025">parent</a><span>|</span><a href="#41894644">next</a><span>|</span><label class="collapse" for="c-41895241">[-]</label><label class="expand" for="c-41895241">[1 more]</label></div><br/><div class="children"><div class="content">I recently took a 3000 mile road trip on 12.5.4.1 on a mix of interstate, country roads, and city streets and there were only a small handful of instances where I felt like FSD completely failed. It&#x27;s certainly not perfect, but I have never had the same failures that the original thread poster had.</div><br/></div></div></div></div></div></div><div id="41894644" class="c"><input type="checkbox" id="c-41894644" checked=""/><div class="controls bullet"><span class="by">averageRoyalty</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41894964">prev</a><span>|</span><a href="#41894770">next</a><span>|</span><label class="collapse" for="c-41894644">[-]</label><label class="expand" for="c-41894644">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not disagreeing with your experience. But if it&#x27;s as bad as you say, why aren&#x27;t we seeing tens or hundreds of FSD fatalities per day or at least per week? Even if only 1000 people globally have it on, these issues sound like we should be seeing tens per week.</div><br/><div id="41896004" class="c"><input type="checkbox" id="c-41896004" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894644">parent</a><span>|</span><a href="#41894770">next</a><span>|</span><label class="collapse" for="c-41896004">[-]</label><label class="expand" for="c-41896004">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps having more accidents doesn&#x27;t mean more fatal accidents.</div><br/></div></div></div></div><div id="41894770" class="c"><input type="checkbox" id="c-41894770" checked=""/><div class="controls bullet"><span class="by">kingkongjaffa</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41894644">prev</a><span>|</span><a href="#41894279">next</a><span>|</span><label class="collapse" for="c-41894770">[-]</label><label class="expand" for="c-41894770">[3 more]</label></div><br/><div class="children"><div class="content">&gt; right turns on red<p>This is a idiosyncrasy of the US (maybe other places too?) and I wonder if it&#x27;s easier to do self driving at junctions, in countries without this rule.</div><br/><div id="41895828" class="c"><input type="checkbox" id="c-41895828" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894770">parent</a><span>|</span><a href="#41894279">next</a><span>|</span><label class="collapse" for="c-41895828">[-]</label><label class="expand" for="c-41895828">[2 more]</label></div><br/><div class="children"><div class="content">Only some states allow turn on red, and it&#x27;s also often overridden by a road sign that forbids. But for me the ultimate test of AGI is four-or-perhaps-three-or-perhaps-two way stop intersections. You have to know whether the other drivers have a stop sign or not in order to understand how to proceed, and you can&#x27;t see that information. As an immigrant to the US this baffles me, but my US-native family members shrug like there&#x27;s some telepathy way to know. There&#x27;s also a rule that you yield to vehicles on your right at uncontrolled intersections (if you can determine that it is uncontrolled...) that almost no drivers here seem to have heard of. You have to eye-ball the other driver to determine whether or not they look like they remember road rules. Not sure how a Tesla will do that.</div><br/><div id="41896732" class="c"><input type="checkbox" id="c-41896732" checked=""/><div class="controls bullet"><span class="by">bink</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41895828">parent</a><span>|</span><a href="#41894279">next</a><span>|</span><label class="collapse" for="c-41896732">[-]</label><label class="expand" for="c-41896732">[1 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s all-way stop there will often be a small placard below the stop sign. If there&#x27;s no placard there then (usually) cross traffic doesn&#x27;t stop. Sometimes there&#x27;s a placard that says &quot;two-way&quot; stop or one that says &quot;cross traffic does not stop&quot;, but that&#x27;s not as common in my experience.</div><br/></div></div></div></div></div></div><div id="41894279" class="c"><input type="checkbox" id="c-41894279" checked=""/><div class="controls bullet"><span class="by">mrjin</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41894770">prev</a><span>|</span><a href="#41890801">next</a><span>|</span><label class="collapse" for="c-41894279">[-]</label><label class="expand" for="c-41894279">[1 more]</label></div><br/><div class="children"><div class="content">I would not even try. The reason is simple, there is absolutely no ability of understanding in any of current self claimed auto driving approach, no matter how well they market them.</div><br/></div></div><div id="41890801" class="c"><input type="checkbox" id="c-41890801" checked=""/><div class="controls bullet"><span class="by">pbasista</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41894279">prev</a><span>|</span><a href="#41891175">next</a><span>|</span><label class="collapse" for="c-41890801">[-]</label><label class="expand" for="c-41890801">[5 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m grateful to be getting a car from another manufacturer this year.<p>I have no illusions about Tesla&#x27;s ability to deliver an unsupervised self-driving car any time soon. However, as far as I understand, their autosteer system, in spite of all its flaws, is still the best out there.<p>Do you have any reason to believe that there actually is something better?</div><br/><div id="41892086" class="c"><input type="checkbox" id="c-41892086" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890801">parent</a><span>|</span><a href="#41890881">next</a><span>|</span><label class="collapse" for="c-41892086">[-]</label><label class="expand" for="c-41892086">[3 more]</label></div><br/><div class="children"><div class="content">Autopilot has not been good. I have a cabin four hours from my home and I&#x27;ve used autopilot for long stretches on the highway. Some of the problems:<p>- Certain exits are not detected as such and the car violently veers right before returning to the lane. I simply can&#x27;t believe they don&#x27;t have telemetry to remedy this.<p>- Sometimes the GPS becomes miscalibrated. This makes the car think I&#x27;m taking an exit when I&#x27;m not, causing the car to abruptly reduce its speed to the speed of the ramp. It does not readjust.<p>- It frequently slows for &quot;emergency lights&quot; that don&#x27;t exist.<p>- If traffic comes to a complete stop, the car accelerates way too hard and brakes hard when the car in front moves any substantial amount.<p>At this point, I&#x27;d rather have something less good than something which is an active danger. For all intents and purposes, my Tesla doesn&#x27;t have reliable cruise control, period.<p>Beyond that, though, I simply don&#x27;t have trust in Tesla software. I&#x27;ve encountered <i>so many</i> problems at this point that I can&#x27;t possibly expect them to deliver a product that works reliably at any point in the future. What reason do I have to believe things will magically improve?</div><br/><div id="41892206" class="c"><input type="checkbox" id="c-41892206" checked=""/><div class="controls bullet"><span class="by">absoflutely</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892086">parent</a><span>|</span><a href="#41890881">next</a><span>|</span><label class="collapse" for="c-41892206">[-]</label><label class="expand" for="c-41892206">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll add that it randomly brakes hard on the interstate because it thinks the speed limit drops to 45. There aren&#x27;t speed limit signs anywhere nearby on different roads that it could be mistakenly reading either.</div><br/><div id="41892575" class="c"><input type="checkbox" id="c-41892575" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892206">parent</a><span>|</span><a href="#41890881">next</a><span>|</span><label class="collapse" for="c-41892575">[-]</label><label class="expand" for="c-41892575">[1 more]</label></div><br/><div class="children"><div class="content">I noticed that this happens when the triangle on the map is slightly offset from the road, which I&#x27;ve attributed to miscalibrated GPS. It happens consistently when I&#x27;m in the right lane and pass an exit when the triangle is ever so slightly misaligned.</div><br/></div></div></div></div></div></div><div id="41890881" class="c"><input type="checkbox" id="c-41890881" checked=""/><div class="controls bullet"><span class="by">throwaway314155</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890801">parent</a><span>|</span><a href="#41892086">prev</a><span>|</span><a href="#41891175">next</a><span>|</span><label class="collapse" for="c-41890881">[-]</label><label class="expand" for="c-41890881">[1 more]</label></div><br/><div class="children"><div class="content">I believe they&#x27;re fine with losing auto steering capabilities, based on the tone of their comment.</div><br/></div></div></div></div><div id="41891175" class="c"><input type="checkbox" id="c-41891175" checked=""/><div class="controls bullet"><span class="by">geoka9</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41890801">prev</a><span>|</span><a href="#41894722">next</a><span>|</span><label class="collapse" for="c-41891175">[-]</label><label class="expand" for="c-41891175">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It didn&#x27;t merge left to make room for vehicles merging onto the highway. The vehicles then tried to cut in. The system should have avoided an unsafe situation like this in the first place.<p>I&#x27;ve been on the receiving end of this with the offender being a Tesla so many times that I figured it must be FSD.</div><br/><div id="41892065" class="c"><input type="checkbox" id="c-41892065" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41891175">parent</a><span>|</span><a href="#41894722">next</a><span>|</span><label class="collapse" for="c-41892065">[-]</label><label class="expand" for="c-41892065">[1 more]</label></div><br/><div class="children"><div class="content">Probably autopilot, honestly.</div><br/></div></div></div></div><div id="41894722" class="c"><input type="checkbox" id="c-41894722" checked=""/><div class="controls bullet"><span class="by">heresie-dabord</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41891175">prev</a><span>|</span><a href="#41890238">next</a><span>|</span><label class="collapse" for="c-41894722">[-]</label><label class="expand" for="c-41894722">[2 more]</label></div><br/><div class="children"><div class="content">&gt; After the system error, I lost all trust in FSD from Tesla.<p>May I ask how this initial trust was established?</div><br/><div id="41896029" class="c"><input type="checkbox" id="c-41896029" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894722">parent</a><span>|</span><a href="#41890238">next</a><span>|</span><label class="collapse" for="c-41896029">[-]</label><label class="expand" for="c-41896029">[1 more]</label></div><br/><div class="children"><div class="content">The numbers that are reported aren&#x27;t abysmal, and people have anecdotally said good things. I was willing to give it a try while being hyper vigilant.</div><br/></div></div></div></div><div id="41890238" class="c"><input type="checkbox" id="c-41890238" checked=""/><div class="controls bullet"><span class="by">paulcole</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41894722">prev</a><span>|</span><a href="#41889323">next</a><span>|</span><label class="collapse" for="c-41890238">[-]</label><label class="expand" for="c-41890238">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Until I ride in one and feel safe, I can&#x27;t have any faith that this is a reasonable system<p>This is probably the worst way to evaluate self-driving for society though, right?</div><br/><div id="41892113" class="c"><input type="checkbox" id="c-41892113" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890238">parent</a><span>|</span><a href="#41889323">next</a><span>|</span><label class="collapse" for="c-41892113">[-]</label><label class="expand" for="c-41892113">[4 more]</label></div><br/><div class="children"><div class="content">Why would I be supportive of a system that has actively scared me for objectively scary reasons? Even if it&#x27;s the worst reason, it&#x27;s not a bad reason.</div><br/><div id="41894891" class="c"><input type="checkbox" id="c-41894891" checked=""/><div class="controls bullet"><span class="by">paulcole</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41892113">parent</a><span>|</span><a href="#41889323">next</a><span>|</span><label class="collapse" for="c-41894891">[-]</label><label class="expand" for="c-41894891">[3 more]</label></div><br/><div class="children"><div class="content">How you feel while riding isn’t an objective thing. It’s entirely subjective. You and I can sit side by side and feel differently about the same experience.<p>I don’t see how this is in any way objective besides the fact that you want it to be objective.<p>You can support things for society that scare you and feel unsafe because you can admit your feelings are subjective and the thing is actually safer than it feels to you personally.</div><br/><div id="41896060" class="c"><input type="checkbox" id="c-41896060" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41894891">parent</a><span>|</span><a href="#41889323">next</a><span>|</span><label class="collapse" for="c-41896060">[-]</label><label class="expand" for="c-41896060">[2 more]</label></div><br/><div class="children"><div class="content">I also did write about times when the car would have damaged itself or likely caused an accident, and those are indeed objective problems.</div><br/><div id="41896487" class="c"><input type="checkbox" id="c-41896487" checked=""/><div class="controls bullet"><span class="by">paulcole</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41896060">parent</a><span>|</span><a href="#41889323">next</a><span>|</span><label class="collapse" for="c-41896487">[-]</label><label class="expand" for="c-41896487">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It failed with a cryptic system error while driving<p>I’ll give you this one.<p>&gt; In my opinion, the default setting accelerates way too aggressively. I&#x27;d call myself a fairly aggressive driver and it is too aggressive for my taste<p>Subjective.<p>&gt; It started making a left turn far too early that would have scraped the left side of the car on a sign. I had to manually intervene.<p>Since you intervened and don’t know what would’ve happened, subjective.<p>&gt; It tried to make way too many right turns on red when it wasn&#x27;t safe to. It would creep into the road, almost into the path of oncoming vehicles<p>Subjective.<p>&gt; It would switch lanes to go faster on the highway, but then missed an exit on at least one occasion because it couldn&#x27;t make it back into the right lane in time. Stupid.<p>Objective.<p>You’ve got some fair complaints but the idea that <i>feeling</i> safe is what’s needed remains subjective.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41889323" class="c"><input type="checkbox" id="c-41889323" checked=""/><div class="controls bullet"><span class="by">thomastjeffery</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41890238">prev</a><span>|</span><a href="#41890729">next</a><span>|</span><label class="collapse" for="c-41889323">[-]</label><label class="expand" for="c-41889323">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just about relative safety compared to all human driving.<p>We all know that some humans are sometimes terrible drivers!<p>We also know what that looks like: Driving too fast or slow relative to surroundings. Quickly turning every once in a while to stay in their lane. Aggressively weaving through traffic. Going through an intersection without spending the time to actually look for pedestrians. The list goes on..<p>Bad human driving can be seen. Bad automated driving <i>is invisible</i>. Do you think the people who were about to be hit by a Tesla even realized that was the case? I sincerely doubt it.</div><br/><div id="41890207" class="c"><input type="checkbox" id="c-41890207" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41889323">parent</a><span>|</span><a href="#41890729">next</a><span>|</span><label class="collapse" for="c-41890207">[-]</label><label class="expand" for="c-41890207">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Bad automated driving is invisible.<p>I&#x27;m literally saying that it is visible, to me, the passenger. And for reasons that aren&#x27;t just bad vibes. If I&#x27;m in an Uber and I feel unsafe, I&#x27;ll report the driver. Why would I pay for my car to do that to me?</div><br/><div id="41892052" class="c"><input type="checkbox" id="c-41892052" checked=""/><div class="controls bullet"><span class="by">thomastjeffery</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890207">parent</a><span>|</span><a href="#41890261">next</a><span>|</span><label class="collapse" for="c-41892052">[-]</label><label class="expand" for="c-41892052">[1 more]</label></div><br/><div class="children"><div class="content">We are taking about the same thing: unpredictability. If you and everyone else <i>can&#x27;t predict</i> what your car will do, then that seems objectively unsafe to me. It also sounds like we agree with each other.</div><br/></div></div><div id="41890261" class="c"><input type="checkbox" id="c-41890261" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890207">parent</a><span>|</span><a href="#41892052">prev</a><span>|</span><a href="#41890729">next</a><span>|</span><label class="collapse" for="c-41890261">[-]</label><label class="expand" for="c-41890261">[1 more]</label></div><br/><div class="children"><div class="content">GP means that the signs aren&#x27;t obvious to other drivers. We generally underestimate how important psychological modelling is for communication, because it&#x27;s transparent to most of us under most circumstances, but AI systems have <i>very</i> different psychology to humans. It is easier to interpret the body language of a fox than a self-driving car.</div><br/></div></div></div></div></div></div><div id="41890729" class="c"><input type="checkbox" id="c-41890729" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#41889192">parent</a><span>|</span><a href="#41889323">prev</a><span>|</span><a href="#41895291">next</a><span>|</span><label class="collapse" for="c-41890729">[-]</label><label class="expand" for="c-41890729">[2 more]</label></div><br/><div class="children"><div class="content">This would be more helpful with a date. Was this in 2020 or 2024? I&#x27;ve been told FSD had a complete rearchitecting.</div><br/><div id="41892091" class="c"><input type="checkbox" id="c-41892091" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889192">root</a><span>|</span><a href="#41890729">parent</a><span>|</span><a href="#41895291">next</a><span>|</span><label class="collapse" for="c-41892091">[-]</label><label class="expand" for="c-41892091">[1 more]</label></div><br/><div class="children"><div class="content">It was a few months ago</div><br/></div></div></div></div></div></div><div id="41896361" class="c"><input type="checkbox" id="c-41896361" checked=""/><div class="controls bullet"><span class="by">deergomoo</span><span>|</span><a href="#41889192">prev</a><span>|</span><a href="#41885131">next</a><span>|</span><label class="collapse" for="c-41896361">[-]</label><label class="expand" for="c-41896361">[18 more]</label></div><br/><div class="children"><div class="content">This is an opinion almost certainly based more in emotion than logic, but I don&#x27;t think I could trust any sort of fully autonomous driving system that didn&#x27;t involve communication with transmitters along the road itself (like a glideslope and localiser for aircraft approaches) and with other cars on the road.<p>Motorway driving sure, there it&#x27;s closer to fancy cruise control. But around town, no thank you. I regularly drive through some really crappily designed bits of road, like unlabelled approaches to multi-lane roundabouts where the lane you need to be in for a particular exit sorta just depends on what the people in front and to the side of you happen to have chosen. If it&#x27;s difficult as a human to work out what the intent is, I don&#x27;t trust a largely computer vision-based system to work it out.<p>The roads here are also in a terrible state, and the lines on them even moreso. There&#x27;s one particular patch of road where the lane keep assist in my car regularly tries to steer me into the central reservation, because repair work has left what looks a bit like lane markings diagonally across the lane.</div><br/><div id="41896739" class="c"><input type="checkbox" id="c-41896739" checked=""/><div class="controls bullet"><span class="by">sokoloff</span><span>|</span><a href="#41896361">parent</a><span>|</span><a href="#41897125">next</a><span>|</span><label class="collapse" for="c-41896739">[-]</label><label class="expand" for="c-41896739">[3 more]</label></div><br/><div class="children"><div class="content">&gt; didn&#x27;t involve communication with transmitters along the road itself (like a glideslope and localiser for aircraft approaches) and with other cars on the road<p>There will be a large number of non-participating vehicles on the road for at least another 50 years. (The <i>average</i> age of a car in the US is a little over 12 years and rising. I doubt we&#x27;ll see a comms-based standard emerge and be required equipment on new cars for at least another 20 years.)</div><br/><div id="41897074" class="c"><input type="checkbox" id="c-41897074" checked=""/><div class="controls bullet"><span class="by">lukan</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41896739">parent</a><span>|</span><a href="#41898775">next</a><span>|</span><label class="collapse" for="c-41897074">[-]</label><label class="expand" for="c-41897074">[1 more]</label></div><br/><div class="children"><div class="content">&quot;There will be a large number of non-participating vehicles on the road for at least another 50 years.&quot;<p>I think so too, but I also think, if we would really want to, all it would take is a GPS device with internet connection, like a smart phone, to make a normal car into a realtime connected one.<p>But I also think we need to work out some social and institutional issues first.<p>Currently I would not like my position to be avaiable in real time to some obscure agency.</div><br/></div></div><div id="41898775" class="c"><input type="checkbox" id="c-41898775" checked=""/><div class="controls bullet"><span class="by">stouset</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41896739">parent</a><span>|</span><a href="#41897074">prev</a><span>|</span><a href="#41897125">next</a><span>|</span><label class="collapse" for="c-41898775">[-]</label><label class="expand" for="c-41898775">[1 more]</label></div><br/><div class="children"><div class="content">Hell, ignore vehicles. What about pedestrians, cyclists, animals, construction equipment, potholes, etc?</div><br/></div></div></div></div><div id="41897125" class="c"><input type="checkbox" id="c-41897125" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#41896361">parent</a><span>|</span><a href="#41896739">prev</a><span>|</span><a href="#41897320">next</a><span>|</span><label class="collapse" for="c-41897125">[-]</label><label class="expand" for="c-41897125">[1 more]</label></div><br/><div class="children"><div class="content">I agree with you about the trust issues and feel similarly, but also feel like the younger generations who grow up with these technologies might be less skeptical about adopting them.<p>I&#x27;ve been kind of amazed how much younger people take some newer technologies for granted, the ability of humans to adapt to changes is marvelous.</div><br/></div></div><div id="41897320" class="c"><input type="checkbox" id="c-41897320" checked=""/><div class="controls bullet"><span class="by">vmladenov</span><span>|</span><a href="#41896361">parent</a><span>|</span><a href="#41897125">prev</a><span>|</span><a href="#41897006">next</a><span>|</span><label class="collapse" for="c-41897320">[-]</label><label class="expand" for="c-41897320">[1 more]</label></div><br/><div class="children"><div class="content">Once insurance requires it or makes you pay triple to drive manually, that will likely be the tipping point for many people.</div><br/></div></div><div id="41897006" class="c"><input type="checkbox" id="c-41897006" checked=""/><div class="controls bullet"><span class="by">emmelaich</span><span>|</span><a href="#41896361">parent</a><span>|</span><a href="#41897320">prev</a><span>|</span><a href="#41896472">next</a><span>|</span><label class="collapse" for="c-41897006">[-]</label><label class="expand" for="c-41897006">[5 more]</label></div><br/><div class="children"><div class="content">Potential problem with transmitters is that they could be faked.<p>You could certainly never rely on them alone.</div><br/><div id="41897185" class="c"><input type="checkbox" id="c-41897185" checked=""/><div class="controls bullet"><span class="by">wtallis</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41897006">parent</a><span>|</span><a href="#41896472">next</a><span>|</span><label class="collapse" for="c-41897185">[-]</label><label class="expand" for="c-41897185">[4 more]</label></div><br/><div class="children"><div class="content">There are lots of other areas where intentionally violating FCC regulations to transmit harmful signals is already technologically feasible and cheap, but hasn&#x27;t become a widespread problem in practice. Why would it be any worse for cars communicating with each other? If anything, having lots of cars on the road logging what they receive from other cars (spoofed or otherwise) would make it too easy to identify which signals are fake, thwarting potential use cases like insurance fraud (since it&#x27;s safe to assume the car broadcasting fake data is at fault in any collision).</div><br/><div id="41897292" class="c"><input type="checkbox" id="c-41897292" checked=""/><div class="controls bullet"><span class="by">johnisgood</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41897185">parent</a><span>|</span><a href="#41896472">next</a><span>|</span><label class="collapse" for="c-41897292">[-]</label><label class="expand" for="c-41897292">[3 more]</label></div><br/><div class="children"><div class="content">I agree, the problem has been solved.<p>If a consensus mechanism similar to those used in blockchain were implemented, vehicles could cross-reference the data they receive with data from multiple other vehicles. If inconsistencies are detected (for example, a car reporting a different speed than what others are observing), that data could be flagged as potentially fraudulent.<p>Just as blockchain technologies can provide a means of verifying the authenticity of transactions, a network of cars could establish a decentralized validation process for the data they exchange. If one car broadcasts false data, the consensus mechanism among the surrounding vehicles would allow for the identification of this &quot;anomaly&quot;, similar to how fraudulent transactions can be identified and rejected in a blockchain system.<p>What you mentioned with regarding to insurance could be used as a deterrent, too, along with laws making it illegal to spoof relevant data.<p>In any case, privacy is going to take a toll here, I believe.</div><br/><div id="41897629" class="c"><input type="checkbox" id="c-41897629" checked=""/><div class="controls bullet"><span class="by">15155</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41897292">parent</a><span>|</span><a href="#41896472">next</a><span>|</span><label class="collapse" for="c-41897629">[-]</label><label class="expand" for="c-41897629">[2 more]</label></div><br/><div class="children"><div class="content">This is a complicated, technical solution looking for a problem.<p>Simple, asymmetrically-authenticated signals and felonies for the edge cases solve this problem without any futuristic computer wizardry.</div><br/><div id="41897869" class="c"><input type="checkbox" id="c-41897869" checked=""/><div class="controls bullet"><span class="by">johnisgood</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41897629">parent</a><span>|</span><a href="#41896472">next</a><span>|</span><label class="collapse" for="c-41897869">[-]</label><label class="expand" for="c-41897869">[1 more]</label></div><br/><div class="children"><div class="content">I did not intend to state that we ought to use the blockchain, at all, for what it is worth. Vehicles should cross-reference the data they receive with data from multiple other vehicles and detect inconsistencies, any consensus mechanism could work, if we could call it that.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41896472" class="c"><input type="checkbox" id="c-41896472" checked=""/><div class="controls bullet"><span class="by">michaelt</span><span>|</span><a href="#41896361">parent</a><span>|</span><a href="#41897006">prev</a><span>|</span><a href="#41885131">next</a><span>|</span><label class="collapse" for="c-41896472">[-]</label><label class="expand" for="c-41896472">[7 more]</label></div><br/><div class="children"><div class="content"><i>&gt; If it&#x27;s difficult as a human to work out what the intent is, I don&#x27;t trust a largely computer vision-based system to work it out.</i><p>Most likely, every self-driving car company will send drivers down every road in the country, recording everything they see. Then they&#x27;ll have human labellers figure out any junctions where the road markings are ambiguous.<p>They&#x27;ve had sat nav maps covering every road for decades, and the likes of Google Street View, so to have a detailed map of every junction is totally possible.</div><br/><div id="41896569" class="c"><input type="checkbox" id="c-41896569" checked=""/><div class="controls bullet"><span class="by">deergomoo</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41896472">parent</a><span>|</span><a href="#41885131">next</a><span>|</span><label class="collapse" for="c-41896569">[-]</label><label class="expand" for="c-41896569">[6 more]</label></div><br/><div class="children"><div class="content">In that case I hope they&#x27;re prepared to work with local authorities to immediately update the map every time road layouts change, temporarily or permanently. Google Maps gets lane guidance wrong very often in my experience, so that doesn&#x27;t exactly fill me with confidence.</div><br/><div id="41896690" class="c"><input type="checkbox" id="c-41896690" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41896569">parent</a><span>|</span><a href="#41896644">next</a><span>|</span><label class="collapse" for="c-41896690">[-]</label><label class="expand" for="c-41896690">[4 more]</label></div><br/><div class="children"><div class="content">I kind of assumed that already happened. Does it not? Is anyone pushing for it?<p>Honestly it seems like it ought to be federal law by now that municipalities need to notify a designated centralized service of all road&#x2F;lane&#x2F;sign&#x2F;etc. changes in a standardized format, that all digital mapping providers can ingest from.<p>Is this not a thing? If not, is anyone lobbying for it? Is there opposition?</div><br/><div id="41896824" class="c"><input type="checkbox" id="c-41896824" checked=""/><div class="controls bullet"><span class="by">jjav</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41896690">parent</a><span>|</span><a href="#41897116">next</a><span>|</span><label class="collapse" for="c-41896824">[-]</label><label class="expand" for="c-41896824">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I kind of assumed that already happened.<p>Road layout can change daily, sometimes multiple times per day. Sometimes in a second, like when a tree falls on a lane and now you have to reroute on the oncoming lane for some distance, etc.</div><br/></div></div><div id="41897116" class="c"><input type="checkbox" id="c-41897116" checked=""/><div class="controls bullet"><span class="by">fweimer</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41896690">parent</a><span>|</span><a href="#41896824">prev</a><span>|</span><a href="#41897109">next</a><span>|</span><label class="collapse" for="c-41897116">[-]</label><label class="expand" for="c-41897116">[1 more]</label></div><br/><div class="children"><div class="content">Coordinating roadwork is challenging in most places, I think. Over here, it&#x27;s apparently cheaper to open up a road multiple times in a year, rather than coordinating all the different parties that need underground access in the foreseeable future.</div><br/></div></div><div id="41897109" class="c"><input type="checkbox" id="c-41897109" checked=""/><div class="controls bullet"><span class="by">lukan</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41896690">parent</a><span>|</span><a href="#41897116">prev</a><span>|</span><a href="#41896644">next</a><span>|</span><label class="collapse" for="c-41897109">[-]</label><label class="expand" for="c-41897109">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Honestly it seems like it ought to be federal law by now that municipalities need to notify a designated centralized service of all road&#x2F;lane&#x2F;sign&#x2F;etc. changes in a standardized format, that all digital mapping providers can ingest from&quot;<p>Why not just anyone and make that data openly avaiable?</div><br/></div></div></div></div><div id="41896644" class="c"><input type="checkbox" id="c-41896644" checked=""/><div class="controls bullet"><span class="by">tjpnz</span><span>|</span><a href="#41896361">root</a><span>|</span><a href="#41896569">parent</a><span>|</span><a href="#41896690">prev</a><span>|</span><a href="#41885131">next</a><span>|</span><label class="collapse" for="c-41896644">[-]</label><label class="expand" for="c-41896644">[1 more]</label></div><br/><div class="children"><div class="content">And the contractors employed by the local authorities to do roadworks big and small.</div><br/></div></div></div></div></div></div></div></div><div id="41885131" class="c"><input type="checkbox" id="c-41885131" checked=""/><div class="controls bullet"><span class="by">massysett</span><span>|</span><a href="#41896361">prev</a><span>|</span><a href="#41889077">next</a><span>|</span><label class="collapse" for="c-41885131">[-]</label><label class="expand" for="c-41885131">[76 more]</label></div><br/><div class="children"><div class="content">&quot;Tesla says on its website its FSD software in on-road vehicles requires active driver supervision and does not make vehicles autonomous.&quot;<p>Despite it being called &quot;Full Self-Driving.&quot;<p>Tesla should be sued out of existence.</div><br/><div id="41885429" class="c"><input type="checkbox" id="c-41885429" checked=""/><div class="controls bullet"><span class="by">hedora</span><span>|</span><a href="#41885131">parent</a><span>|</span><a href="#41885238">next</a><span>|</span><label class="collapse" for="c-41885429">[-]</label><label class="expand" for="c-41885429">[7 more]</label></div><br/><div class="children"><div class="content">Our non-Tesla has steering assist.  In my 500 miles of driving before I found the buried setting that let me completely disable it, the active safety systems never made it more than 10-20 miles without attempting to actively steer the car left-of-center or into another vehicle, even when it was &quot;turned off&quot; via the steering wheel controls.<p>When it was turned on according to the dashboard UI, things were even worse.  It&#x27;d disengage less than every ten miles.  However, there wasn&#x27;t an alarm when it disengaged, just a tiny gray blinking icon on the dash.  A second or so after the blinking, it&#x27;d beep once and then pull crap like attempt a sharp left on an exit ramp that curved to the right.<p>I can&#x27;t imagine this model kills fewer people per mile than Tesla FSD.<p>I think there should be a recall, but it should hit pretty much all manufacturers shipping stuff in this space.</div><br/><div id="41885534" class="c"><input type="checkbox" id="c-41885534" checked=""/><div class="controls bullet"><span class="by">noapologies</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41885429">parent</a><span>|</span><a href="#41886113">next</a><span>|</span><label class="collapse" for="c-41885534">[-]</label><label class="expand" for="c-41885534">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure how any of this is related to the article. Does this non-Tesla manufacturer claim that their steering assist is &quot;full self driving&quot;?<p>If you believe their steering assist kills more people than Tesla FSD then you&#x27;re welcome, encouraged even, to file a report with the NHTSA here [1].<p>[1] <a href="https:&#x2F;&#x2F;www.nhtsa.gov&#x2F;report-a-safety-problem" rel="nofollow">https:&#x2F;&#x2F;www.nhtsa.gov&#x2F;report-a-safety-problem</a></div><br/></div></div><div id="41886113" class="c"><input type="checkbox" id="c-41886113" checked=""/><div class="controls bullet"><span class="by">HeadsUpHigh</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41885429">parent</a><span>|</span><a href="#41885534">prev</a><span>|</span><a href="#41885522">next</a><span>|</span><label class="collapse" for="c-41886113">[-]</label><label class="expand" for="c-41886113">[3 more]</label></div><br/><div class="children"><div class="content">Ive had similar experience with a Hyundai with steering assist. It would get confused by messed road lining all the time. Meanwhile it had no problem climbing a road curb that was unmarked. And it would try to constantly nudge the steering wheel meaning I had to put force into holding it in place all the time since it which was extra fatigue.<p>Oh and it was on by default, meaning I had to disable it every time I turned the car on.</div><br/><div id="41890921" class="c"><input type="checkbox" id="c-41890921" checked=""/><div class="controls bullet"><span class="by">shepherdjerred</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41886113">parent</a><span>|</span><a href="#41885522">next</a><span>|</span><label class="collapse" for="c-41890921">[-]</label><label class="expand" for="c-41890921">[2 more]</label></div><br/><div class="children"><div class="content">What model year? I&#x27;m guessing it&#x27;s an older one?<p>My Hyundai is a 2021 and I have to turn on the steering assist every time which I find annoying. My guess is that you had an earlier model where the steering assist was more liability than asset.<p>It&#x27;s understandable that earlier versions of this kind of thing wouldn&#x27;t function as well, but it is very strange that they would have it on by default.</div><br/><div id="41901288" class="c"><input type="checkbox" id="c-41901288" checked=""/><div class="controls bullet"><span class="by">HeadsUpHigh</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41890921">parent</a><span>|</span><a href="#41885522">next</a><span>|</span><label class="collapse" for="c-41901288">[-]</label><label class="expand" for="c-41901288">[1 more]</label></div><br/><div class="children"><div class="content">&gt;What model year? I&#x27;m guessing it&#x27;s an older one?<p>Not 100% sure which year since it wasn&#x27;t mine I think around 2018 +-2y. It was good at following bright painted white lines and nothing else. I didn&#x27;t mind the beeping and the vibration when I stepped on a line but it wanted to actively steer the wheel which was infuriating. I wouldn&#x27;t mind it if it was just a suggestion.</div><br/></div></div></div></div></div></div><div id="41885522" class="c"><input type="checkbox" id="c-41885522" checked=""/><div class="controls bullet"><span class="by">shepherdjerred</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41885429">parent</a><span>|</span><a href="#41886113">prev</a><span>|</span><a href="#41885730">next</a><span>|</span><label class="collapse" for="c-41885522">[-]</label><label class="expand" for="c-41885522">[1 more]</label></div><br/><div class="children"><div class="content">My Hyundai has a similar feature and it&#x27;s excellent. I don&#x27;t think you should be painting with such a broad brush.</div><br/></div></div><div id="41885730" class="c"><input type="checkbox" id="c-41885730" checked=""/><div class="controls bullet"><span class="by">gamblor956</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41885429">parent</a><span>|</span><a href="#41885522">prev</a><span>|</span><a href="#41885238">next</a><span>|</span><label class="collapse" for="c-41885730">[-]</label><label class="expand" for="c-41885730">[1 more]</label></div><br/><div class="children"><div class="content">If what you say is true, name the car model and file a report with the NHTSA.</div><br/></div></div></div></div><div id="41885238" class="c"><input type="checkbox" id="c-41885238" checked=""/><div class="controls bullet"><span class="by">bagels</span><span>|</span><a href="#41885131">parent</a><span>|</span><a href="#41885429">prev</a><span>|</span><a href="#41885656">next</a><span>|</span><label class="collapse" for="c-41885238">[-]</label><label class="expand" for="c-41885238">[2 more]</label></div><br/><div class="children"><div class="content">It didn&#x27;t always say that. It used to be more misleading, and claim that the cars have &quot;Full Self Driving Hardware&quot;, with an exercise for the reader to deduce that it didn&#x27;t come with &quot;Full Self Driving Software&quot; too.</div><br/><div id="41885546" class="c"><input type="checkbox" id="c-41885546" checked=""/><div class="controls bullet"><span class="by">peutetre</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41885238">parent</a><span>|</span><a href="#41885656">next</a><span>|</span><label class="collapse" for="c-41885546">[-]</label><label class="expand" for="c-41885546">[1 more]</label></div><br/><div class="children"><div class="content">And Musk doesn&#x27;t want to &quot;get nuanced&quot; about the hardware:<p><a href="https:&#x2F;&#x2F;electrek.co&#x2F;2024&#x2F;10&#x2F;15&#x2F;tesla-needs-to-come-clean-about-hw3-before-the-word-fraud-comes-out&#x2F;" rel="nofollow">https:&#x2F;&#x2F;electrek.co&#x2F;2024&#x2F;10&#x2F;15&#x2F;tesla-needs-to-come-clean-abo...</a></div><br/></div></div></div></div><div id="41885656" class="c"><input type="checkbox" id="c-41885656" checked=""/><div class="controls bullet"><span class="by">m463</span><span>|</span><a href="#41885131">parent</a><span>|</span><a href="#41885238">prev</a><span>|</span><a href="#41885242">next</a><span>|</span><label class="collapse" for="c-41885656">[-]</label><label class="expand" for="c-41885656">[7 more]</label></div><br/><div class="children"><div class="content">I believe it&#x27;s called &quot;Full Self Driving (Supervised)&quot;</div><br/><div id="41894353" class="c"><input type="checkbox" id="c-41894353" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41885656">parent</a><span>|</span><a href="#41886156">next</a><span>|</span><label class="collapse" for="c-41894353">[-]</label><label class="expand" for="c-41894353">[1 more]</label></div><br/><div class="children"><div class="content">The correct name would be &quot;Not Self Driving&quot;. Or, at least, Partial Self Driving.</div><br/></div></div><div id="41886156" class="c"><input type="checkbox" id="c-41886156" checked=""/><div class="controls bullet"><span class="by">maeil</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41885656">parent</a><span>|</span><a href="#41894353">prev</a><span>|</span><a href="#41885242">next</a><span>|</span><label class="collapse" for="c-41886156">[-]</label><label class="expand" for="c-41886156">[5 more]</label></div><br/><div class="children"><div class="content">The part in parentheses has only recently been added.</div><br/><div id="41889157" class="c"><input type="checkbox" id="c-41889157" checked=""/><div class="controls bullet"><span class="by">tharant</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41886156">parent</a><span>|</span><a href="#41887897">next</a><span>|</span><label class="collapse" for="c-41889157">[-]</label><label class="expand" for="c-41889157">[3 more]</label></div><br/><div class="children"><div class="content">Prior to that, FSD was labeled ‘Full Self Driving (Beta)’ and enabling it triggered a modal that required two confirmations explaining that the human driver must always pay attention and is ultimately responsible for the vehicle.  The feature also had&#x2F;has active driver monitoring (via both vision and steering-torque sensors) that would disengage FSD if the driver ignored the loud audible alarm to “Pay attention”.  Since changing the label to ‘(Supervised)’, the audible nag is significantly reduced.</div><br/><div id="41894365" class="c"><input type="checkbox" id="c-41894365" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41889157">parent</a><span>|</span><a href="#41895640">next</a><span>|</span><label class="collapse" for="c-41894365">[-]</label><label class="expand" for="c-41894365">[1 more]</label></div><br/><div class="children"><div class="content">The problem is not so much the lack of disclaimers, it is the adberitising. Tesla is asking for something like 15 000 dollars for access to this &quot;beta&quot;, and you don&#x27;t get two modal dialogs before you sign up for that.<p>This is called &quot;false advertising&quot;, and even worse - recognizing revenue on a feature you are not delivering (a beta is not a delivered feature) is not GAAP.</div><br/></div></div><div id="41895640" class="c"><input type="checkbox" id="c-41895640" checked=""/><div class="controls bullet"><span class="by">rty32</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41889157">parent</a><span>|</span><a href="#41894365">prev</a><span>|</span><a href="#41887897">next</a><span>|</span><label class="collapse" for="c-41895640">[-]</label><label class="expand" for="c-41895640">[1 more]</label></div><br/><div class="children"><div class="content">Do they have warnings as big as &quot;full self driving&quot; texts in advertisements? And if it is NOT actually full self driving, why call it full self driving?<p>That&#x27;s just false advertising. You can&#x27;t get around that.<p>I can&#x27;t believe our current laws let Tesla get away like that.</div><br/></div></div></div></div><div id="41887897" class="c"><input type="checkbox" id="c-41887897" checked=""/><div class="controls bullet"><span class="by">rsynnott</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41886156">parent</a><span>|</span><a href="#41889157">prev</a><span>|</span><a href="#41885242">next</a><span>|</span><label class="collapse" for="c-41887897">[-]</label><label class="expand" for="c-41887897">[1 more]</label></div><br/><div class="children"><div class="content">And is, well, entirely contradictory. An absolute absurdity; what happens when the irresistible force of the legal department meets the immovable object of marketing.</div><br/></div></div></div></div></div></div><div id="41885242" class="c"><input type="checkbox" id="c-41885242" checked=""/><div class="controls bullet"><span class="by">fhdsgbbcaA</span><span>|</span><a href="#41885131">parent</a><span>|</span><a href="#41885656">prev</a><span>|</span><a href="#41885322">next</a><span>|</span><label class="collapse" for="c-41885242">[-]</label><label class="expand" for="c-41885242">[1 more]</label></div><br/><div class="children"><div class="content">“Sixty percent of the time, it works every time”</div><br/></div></div><div id="41893664" class="c"><input type="checkbox" id="c-41893664" checked=""/><div class="controls bullet"><span class="by">innocentoldguy</span><span>|</span><a href="#41885131">parent</a><span>|</span><a href="#41885351">prev</a><span>|</span><a href="#41889077">next</a><span>|</span><label class="collapse" for="c-41893664">[-]</label><label class="expand" for="c-41893664">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s called &quot;Full Self-Driving (Supervised) Beta&quot; and you agree that you understand that you have to pay attention and are responsible for the safety of the car before you turn it on.</div><br/><div id="41894493" class="c"><input type="checkbox" id="c-41894493" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41893664">parent</a><span>|</span><a href="#41895643">next</a><span>|</span><label class="collapse" for="c-41894493">[-]</label><label class="expand" for="c-41894493">[1 more]</label></div><br/><div class="children"><div class="content">So the name of it is a contradiction, and the fine print contradicts the name.  &quot;Full self driving&quot; (the concept, not the Tesla product) does not need to be supervised.</div><br/></div></div><div id="41895643" class="c"><input type="checkbox" id="c-41895643" checked=""/><div class="controls bullet"><span class="by">rty32</span><span>|</span><a href="#41885131">root</a><span>|</span><a href="#41893664">parent</a><span>|</span><a href="#41894493">prev</a><span>|</span><a href="#41889077">next</a><span>|</span><label class="collapse" for="c-41895643">[-]</label><label class="expand" for="c-41895643">[1 more]</label></div><br/><div class="children"><div class="content">Come on, you know it&#x27;s an oxymoron. &quot;full&quot; and &quot;supervised&quot; don&#x27;t belong to the same sentence. Ask any 10 year old or a non native English speaker who only learned the language from textbooks for 5 years can tell you that. Just... stop defending Tesla.</div><br/></div></div></div></div></div></div><div id="41889077" class="c"><input type="checkbox" id="c-41889077" checked=""/><div class="controls bullet"><span class="by">AlchemistCamp</span><span>|</span><a href="#41885131">prev</a><span>|</span><a href="#41888998">next</a><span>|</span><label class="collapse" for="c-41889077">[-]</label><label class="expand" for="c-41889077">[91 more]</label></div><br/><div class="children"><div class="content">The interesting question is how good self-driving has to be before people tolerate it.<p>It&#x27;s clear that having half the casualty rate per distance traveled of the median human driver isn&#x27;t acceptable. How about a quarter? Or a tenth? Accidents caused by human drivers are one of the largest causes of injury and death, but they&#x27;re not newsworthy the way an accident involving automated driving is. It&#x27;s all too easy to see a potential future where many people die needlessly because technology that could save lives is regulated into a greatly reduced role.</div><br/><div id="41889128" class="c"><input type="checkbox" id="c-41889128" checked=""/><div class="controls bullet"><span class="by">Arainach</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41894281">next</a><span>|</span><label class="collapse" for="c-41889128">[-]</label><label class="expand" for="c-41889128">[20 more]</label></div><br/><div class="children"><div class="content">This is about lying to the public and stoking false expectations for years.<p>If it&#x27;s &quot;fully self driving&quot; Tesla should be liable for when its vehicles kill people. If it&#x27;s not fully self driving and Tesla keeps using that name in all its marketing, regardless of any fine print, then Tesla should be liable for people acting as though their cars could FULLY self drive and be sued accordingly.<p>You don&#x27;t get to lie just because you&#x27;re allegedly safer than a human.</div><br/><div id="41889149" class="c"><input type="checkbox" id="c-41889149" checked=""/><div class="controls bullet"><span class="by">jeremyjh</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889128">parent</a><span>|</span><a href="#41893587">next</a><span>|</span><label class="collapse" for="c-41889149">[-]</label><label class="expand" for="c-41889149">[14 more]</label></div><br/><div class="children"><div class="content">I think this is the answer: the company takes on full liability. If a Tesla is Fully Self Driving then Tesla is driving it. The insurance market will ensure that dodgy software&#x2F;hardware developers exit the industry.</div><br/><div id="41889184" class="c"><input type="checkbox" id="c-41889184" checked=""/><div class="controls bullet"><span class="by">blagie</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889149">parent</a><span>|</span><a href="#41890241">next</a><span>|</span><label class="collapse" for="c-41889184">[-]</label><label class="expand" for="c-41889184">[4 more]</label></div><br/><div class="children"><div class="content">This is very much what I would like to see.<p>The price of insurance is baked into the price of a car. If the car is as safe as I am, I pay the same price in the end. If it&#x27;s safer, I pay less.<p>From my perspective:<p>1) I would *much* rather have Honda kill someone than myself. If I killed someone, the psychological impact on myself would be horrible. In the city I live in, I dread ageing; as my reflexes get slower, I&#x27;m more and more likely to kill someone.<p>2) As a pedestrian, most of the risk seems to come from outliers -- people who drive hyper-aggressively. Replacing all cars with a median driver would make me much safer (and traffic, much more predictable).<p>If we want safer cars, we can simply raise insurance payouts, and vice-versa. The market works everything else out.<p>But my stress levels go way down, whether in a car, on a bike, or on foot.</div><br/><div id="41889228" class="c"><input type="checkbox" id="c-41889228" checked=""/><div class="controls bullet"><span class="by">gambiting</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889184">parent</a><span>|</span><a href="#41890241">next</a><span>|</span><label class="collapse" for="c-41889228">[-]</label><label class="expand" for="c-41889228">[3 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; I would <i>much</i> rather have Honda kill someone than myself. If I killed someone, the psychological impact on myself would be horrible.<p>Except that we know that it doesn&#x27;t work like that. Train drivers are ridden with extreme guilt every time &quot;their&quot; train runs over someone, even though they know that logically there was absolutely nothing they could have done to prevent it. Don&#x27;t see why it would be any different here.<p>&gt;&gt;If we want safer cars, we can simply raise insurance payouts, and vice-versa<p>In what way? In the EU the minimum covered amount for any car insurance is 5 million euro, it has had no impact on the safety of cars. And of course the recent increase in payouts(due to the general increase in labour and parts cost) has led to a dramatic increase in insurance premiums which in turn has lead to a drastic increase in the number of people driving without insurance. So now that needs increased policing and enforcement, which we pay for through taxes. So no, market doesn&#x27;t &quot;work everything out&quot;.</div><br/><div id="41894294" class="c"><input type="checkbox" id="c-41894294" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889228">parent</a><span>|</span><a href="#41890554">next</a><span>|</span><label class="collapse" for="c-41894294">[-]</label><label class="expand" for="c-41894294">[1 more]</label></div><br/><div class="children"><div class="content">Being in a vehicle that collides with someone and kills them is going to be traumatic regardless of whether or not you&#x27;re driving.<p>But it&#x27;s almost certainly going to be more traumatic and more guilt-inducing if you <i>are</i> driving.<p>If I only had two choices, I would much rather my car kill someone than I kill someone with my car.  I&#x27;m gonna feel bad about it either way, but one is much worse than the other.</div><br/></div></div><div id="41890554" class="c"><input type="checkbox" id="c-41890554" checked=""/><div class="controls bullet"><span class="by">blagie</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889228">parent</a><span>|</span><a href="#41894294">prev</a><span>|</span><a href="#41890241">next</a><span>|</span><label class="collapse" for="c-41890554">[-]</label><label class="expand" for="c-41890554">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Except that we know that it doesn&#x27;t work like that. Train drivers are ridden with extreme guilt every time &quot;their&quot; train runs over someone, even though they know that logically there was absolutely nothing they could have done to prevent it. Don&#x27;t see why it would be any different here.<p>It&#x27;s not binary. Someone dying -- even with no involvement -- can be traumatic. I&#x27;ve been in a position where I could have taken actions to prevent someone from being harmed. Rationally not my fault, but in retrospect, I can describe the exact set of steps needed to prevent it. I feel guilty about it, even though I know rationally it&#x27;s not my fault (there&#x27;s no way I could have known ahead of time).<p>However, it&#x27;s a manageable guilt. I don&#x27;t think it would be if I knew rationally that it was my fault.<p>&gt; So no, market doesn&#x27;t &quot;work everything out&quot;.<p>Whether or not a market works things out depends on issues like transparency and information. Parties will offload costs wherever possible. In the model you gave, there is no direct cost to a car maker making less safe cars or vice-versa. It assumes the car buyer will even look at insurance premiums, and a whole chain of events beyond that.<p>That&#x27;s different if it&#x27;s the same party making cars, paying money, and doing so at scale.<p>If Tesla pays for everyone damaged in any accident a Tesla car has, then Tesla has a very, very strong incentive to make safe cars to whatever optimum is set by the damages. Scales are big enough -- millions of cars and billions of dollars -- where Tesla can afford to hire actuaries and a team of analysts to make sure they&#x27;re at the optimum.<p>As an individual car buyer, I have no chance of doing that.<p>Ergo, in one case, the market will work it out. In the other, it won&#x27;t.</div><br/></div></div></div></div></div></div><div id="41890241" class="c"><input type="checkbox" id="c-41890241" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889149">parent</a><span>|</span><a href="#41889184">prev</a><span>|</span><a href="#41890189">next</a><span>|</span><label class="collapse" for="c-41890241">[-]</label><label class="expand" for="c-41890241">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s just reducing the value of a life to a number. It can be gamed to a situation where it&#x27;s just more profitable to mow down people.<p>What&#x27;s an acceptable number&#x2F;financial cost is also just an indirect approximated way of implementing a more direct&#x2F;scientific regulation. Not everything needs to be reduced to money.</div><br/><div id="41890691" class="c"><input type="checkbox" id="c-41890691" checked=""/><div class="controls bullet"><span class="by">jeremyjh</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41890241">parent</a><span>|</span><a href="#41890189">next</a><span>|</span><label class="collapse" for="c-41890691">[-]</label><label class="expand" for="c-41890691">[2 more]</label></div><br/><div class="children"><div class="content">There is no way to game it successfully; if your insurance costs are much higher than your competitors you will lose in the long run. That doesn’t mean there can’t be other penalties when there is gross negligence.</div><br/><div id="41891750" class="c"><input type="checkbox" id="c-41891750" checked=""/><div class="controls bullet"><span class="by">KoolKat23</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41890691">parent</a><span>|</span><a href="#41890189">next</a><span>|</span><label class="collapse" for="c-41891750">[-]</label><label class="expand" for="c-41891750">[1 more]</label></div><br/><div class="children"><div class="content">Who said management and shareholders are in it for the long run. Plenty of examples where businesses are purely run in the short term. Bonuses and stock pumps.</div><br/></div></div></div></div></div></div><div id="41890189" class="c"><input type="checkbox" id="c-41890189" checked=""/><div class="controls bullet"><span class="by">stormfather</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889149">parent</a><span>|</span><a href="#41890241">prev</a><span>|</span><a href="#41890181">next</a><span>|</span><label class="collapse" for="c-41890189">[-]</label><label class="expand" for="c-41890189">[5 more]</label></div><br/><div class="children"><div class="content">That would be good because it would incentivize all FSD cars communicating with each other. Imagine how safe driving would be if they are all broadcasting their speed and position to each other. And each vehicle sending&#x2F;receiving gets cheaper insurance.</div><br/><div id="41890733" class="c"><input type="checkbox" id="c-41890733" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41890189">parent</a><span>|</span><a href="#41899496">next</a><span>|</span><label class="collapse" for="c-41890733">[-]</label><label class="expand" for="c-41890733">[3 more]</label></div><br/><div class="children"><div class="content">It goes kinda dsytopic if access to the network becomes a monopolistic barrier.</div><br/><div id="41896451" class="c"><input type="checkbox" id="c-41896451" checked=""/><div class="controls bullet"><span class="by">tmtvl</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41890733">parent</a><span>|</span><a href="#41899496">next</a><span>|</span><label class="collapse" for="c-41896451">[-]</label><label class="expand" for="c-41896451">[2 more]</label></div><br/><div class="children"><div class="content">Not to mention the possibility of requiring pedestrians and cyclists to also be connected to the same network. Anyone with access to the automotive network could track any pedestrian who passes by the vicinity of a road.</div><br/><div id="41899155" class="c"><input type="checkbox" id="c-41899155" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41896451">parent</a><span>|</span><a href="#41899496">next</a><span>|</span><label class="collapse" for="c-41899155">[-]</label><label class="expand" for="c-41899155">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s hard to think of a good blend of traffic safety, privacy guarantees, and resistance to bad-actors. Having&#x2F;avoiding persistent identification is certainly a factor.<p>Perhaps one approach would be to declare that automated systems are responsible for determining the position&#x2F;speed of everything around them using regular sensors,  but may elect to take hints from anonymous &quot;notice me&quot; marks or beacons.</div><br/></div></div></div></div></div></div><div id="41899496" class="c"><input type="checkbox" id="c-41899496" checked=""/><div class="controls bullet"><span class="by">iknowstuff</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41890189">parent</a><span>|</span><a href="#41890733">prev</a><span>|</span><a href="#41890181">next</a><span>|</span><label class="collapse" for="c-41899496">[-]</label><label class="expand" for="c-41899496">[1 more]</label></div><br/><div class="children"><div class="content">no need.</div><br/></div></div></div></div><div id="41890181" class="c"><input type="checkbox" id="c-41890181" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889149">parent</a><span>|</span><a href="#41890189">prev</a><span>|</span><a href="#41893587">next</a><span>|</span><label class="collapse" for="c-41890181">[-]</label><label class="expand" for="c-41890181">[1 more]</label></div><br/><div class="children"><div class="content">I’m for this as long as the company also takes on liability for human errors they could prevent. I’d want to see cars enforcing speed limits and similar things. Humans are too dangerous to drive.</div><br/></div></div></div></div><div id="41893587" class="c"><input type="checkbox" id="c-41893587" checked=""/><div class="controls bullet"><span class="by">awongh</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889128">parent</a><span>|</span><a href="#41889149">prev</a><span>|</span><a href="#41890885">next</a><span>|</span><label class="collapse" for="c-41893587">[-]</label><label class="expand" for="c-41893587">[1 more]</label></div><br/><div class="children"><div class="content">Also force other auto makers to be liable when their over-tall SUVs cause more deaths than sedan type cars.</div><br/></div></div><div id="41890885" class="c"><input type="checkbox" id="c-41890885" checked=""/><div class="controls bullet"><span class="by">mrpippy</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889128">parent</a><span>|</span><a href="#41893587">prev</a><span>|</span><a href="#41889881">next</a><span>|</span><label class="collapse" for="c-41890885">[-]</label><label class="expand" for="c-41890885">[2 more]</label></div><br/><div class="children"><div class="content">Tesla officially renamed it to “Full Self Driving (supervised)” a few months ago, previously it was “Full Self Driving (beta)”<p>Both names are ridiculous, for different reasons. Nothing called a “beta” should be tested on public roads without a trained employee supervising it (i.e. being paid to pay attention). And of course it was not “full”, it always required supervision.<p>And “Full Self Driving (supervised)” is an absurd oxymoron. Given the deaths and crashes that we’ve already seen, I’m skeptical of the entire concept of a system that works 98% of the time, but also needs to be closely supervised for the 2% of the time when it tries to kill you or others (with no alerts).<p>It’s an abdication of duty that NHTSA has let this continue for so long, they’ve picked up the pace recently and I wouldn’t be surprised if they come down hard on Tesla (unless Trump wins, in which case Elon will be put in charge of NHTSA, the SEC, and FAA)</div><br/><div id="41892629" class="c"><input type="checkbox" id="c-41892629" checked=""/><div class="controls bullet"><span class="by">ilyagr</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41890885">parent</a><span>|</span><a href="#41889881">next</a><span>|</span><label class="collapse" for="c-41892629">[-]</label><label class="expand" for="c-41892629">[1 more]</label></div><br/><div class="children"><div class="content">I hope they soon rename it into &quot;Fully Supervised Driving&quot;.</div><br/></div></div></div></div><div id="41889881" class="c"><input type="checkbox" id="c-41889881" checked=""/><div class="controls bullet"><span class="by">SoftTalker</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889128">parent</a><span>|</span><a href="#41890885">prev</a><span>|</span><a href="#41894281">next</a><span>|</span><label class="collapse" for="c-41889881">[-]</label><label class="expand" for="c-41889881">[2 more]</label></div><br/><div class="children"><div class="content">It’s your car, so ultimately the liability is yours. That’s why you have insurance. If Tesla retains ownership, and just lets you drive it, then they have (more) liability.</div><br/><div id="41894328" class="c"><input type="checkbox" id="c-41894328" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889881">parent</a><span>|</span><a href="#41894281">next</a><span>|</span><label class="collapse" for="c-41894328">[-]</label><label class="expand" for="c-41894328">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>It’s your car, so ultimately the liability is yours</i><p>No, that&#x27;s not how it works.  The driver and the driver&#x27;s insurer are on the hook when something bad happens.  The owner is not, except when the owner is also the one driving, or if the owner has been negligent with maintenance, and the crash was caused by mechanical failure related to that negligence.<p>If someone else is driving my car and I&#x27;m a passenger, and they hurt someone with it, the driver is liable, not me.  If that &quot;someone else&quot; is a piece of software, and that piece of software has been licensed&#x2F;certified&#x2F;whatever to drive a car, why should I be liable for its failures?  That piece of software needs to be insured, certainly.  It doesn&#x27;t matter if I&#x27;m required to insure it, or if the manufacturer is required to insure it.<p>Tesla FSD doesn&#x27;t fit into this scenario because it&#x27;s not the driver.  You are still the driver when you engage FSD, because despite its name, FSD is not capable of filling that role.</div><br/></div></div></div></div></div></div><div id="41894281" class="c"><input type="checkbox" id="c-41894281" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889128">prev</a><span>|</span><a href="#41889120">next</a><span>|</span><label class="collapse" for="c-41894281">[-]</label><label class="expand" for="c-41894281">[1 more]</label></div><br/><div class="children"><div class="content">If Tesla&#x27;s FSD was actually self-driving, maybe half the casualty rate of the median human driver would be fine.<p>But it&#x27;s not.  It requires constant supervision, and drivers sometimes have to take control (without the system disengaging on its own) in order to correct it from doing something unsafe.<p>If we had stats for what the casualty rate would be if every driver using it never took control back unless the car signaled it was going to disengage, I suspect that casualty rate would be much worse than the median human driver.  But we don&#x27;t have those stats, so we shouldn&#x27;t trust it until we do.<p>This is why Waymo is safe and tolerated and Tesla FSD is not.  Waymo test drivers record every time they have to take over control of the car for safety reasons.  That was a metric they had to track and improve, or it would have been impossible to offer people rides without someone in the driver&#x27;s seat.</div><br/></div></div><div id="41889120" class="c"><input type="checkbox" id="c-41889120" checked=""/><div class="controls bullet"><span class="by">triyambakam</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41894281">prev</a><span>|</span><a href="#41889176">next</a><span>|</span><label class="collapse" for="c-41889120">[-]</label><label class="expand" for="c-41889120">[2 more]</label></div><br/><div class="children"><div class="content">Hesitation around self-driving technology is not just about the raw accident rate, but the nature of the accidents. Self-driving failures often involve highly visible, preventable mistakes that seem avoidable by a human (e.g., failing to stop for an obvious obstacle). Humans find such incidents harder to tolerate because they can seem fundamentally different from human error.</div><br/><div id="41889173" class="c"><input type="checkbox" id="c-41889173" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889120">parent</a><span>|</span><a href="#41889176">next</a><span>|</span><label class="collapse" for="c-41889173">[-]</label><label class="expand" for="c-41889173">[1 more]</label></div><br/><div class="children"><div class="content">Exactly -- it&#x27;s not just the overall accident rate, but the rate <i>per accident type</i>.<p>Imagine if self-driving is 10x safer on freeways, but on the other hand is 3x more likely to run over your dog in the driveway.<p>Or it&#x27;s 5x safer on city streets overall, but actually 2x <i>worse</i> in rain and ice.<p>We&#x27;re fundamentally wired for loss aversion. So I&#x27;d say it&#x27;s less about what the total improvement rate is, and more about whether it has categorizable scenarios where it&#x27;s still worse than a human.</div><br/></div></div></div></div><div id="41889176" class="c"><input type="checkbox" id="c-41889176" checked=""/><div class="controls bullet"><span class="by">gambiting</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889120">prev</a><span>|</span><a href="#41889249">next</a><span>|</span><label class="collapse" for="c-41889176">[-]</label><label class="expand" for="c-41889176">[25 more]</label></div><br/><div class="children"><div class="content">&gt;&gt;. How about a quarter? Or a tenth?<p>The answer is zero. An airplane autopilot has increased the overall safety of airplanes by several orders of magnitude compared to human pilots, but literally no errors in its operation are tolerated, whether they are deadly or not. The exact same standard has to apply to cars or any automated machine for that matter. If there is any issue discovered in any car with this tech then it should be disabled worldwide until the root cause is found and eliminated.<p>&gt;&gt; It&#x27;s all too easy to see a potential future where many people die needlessly because technology that could save lives is regulated into a greatly reduced role.<p>I really don&#x27;t like this argument, because we could already prevent literally all automotive deaths tomorrow through existing technology and legislation and yet we are choosing not to do this for economic and social reasons.</div><br/><div id="41889247" class="c"><input type="checkbox" id="c-41889247" checked=""/><div class="controls bullet"><span class="by">esaym</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889176">parent</a><span>|</span><a href="#41889255">next</a><span>|</span><label class="collapse" for="c-41889247">[-]</label><label class="expand" for="c-41889247">[4 more]</label></div><br/><div class="children"><div class="content">You can&#x27;t equate airplane safety with automotive safety. I worked at an aircraft repair facility doing government contracts for a number of years. In one instance, somebody lost the toilet paper holder for one of the aircraft. This holder was simply a piece of 10 gauge wire that was bent in a way to hold it and supported by wire clamps screwed to the wall. Making a new one was easy but since it was a new part going on the aircraft we had to send it to a lab to be certified to hold a roll of toilet paper to 9 g&#x27;s. In case the airplane crashed you wouldn&#x27;t want a roll of toilet paper flying around I guess. And that cost $1,200.</div><br/><div id="41889341" class="c"><input type="checkbox" id="c-41889341" checked=""/><div class="controls bullet"><span class="by">gambiting</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889247">parent</a><span>|</span><a href="#41889255">next</a><span>|</span><label class="collapse" for="c-41889341">[-]</label><label class="expand" for="c-41889341">[3 more]</label></div><br/><div class="children"><div class="content">No, I&#x27;m pretty sure I can in this regard - any automotive &quot;autopilot&quot; has to be held to the same standard. It&#x27;s either zero accidents or nothing.</div><br/><div id="41891911" class="c"><input type="checkbox" id="c-41891911" checked=""/><div class="controls bullet"><span class="by">murderfs</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889341">parent</a><span>|</span><a href="#41889255">next</a><span>|</span><label class="collapse" for="c-41891911">[-]</label><label class="expand" for="c-41891911">[2 more]</label></div><br/><div class="children"><div class="content">This only works for aerospace because everything and everyone is held to that standard. It&#x27;s stupid to hold automotive autopilots to the same standard as a plane&#x27;s autopilot when a third of fatalities in cars are caused by the pilots being drunk.</div><br/><div id="41894352" class="c"><input type="checkbox" id="c-41894352" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41891911">parent</a><span>|</span><a href="#41889255">next</a><span>|</span><label class="collapse" for="c-41894352">[-]</label><label class="expand" for="c-41894352">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s a useful argument.<p>I think we should start allowing autonomous driving when the &quot;driver&quot; is at least as safe as the median driver when the software is unsupervised.  (Teslas may or may not be that safe when supervised, but they absolutely are not when unsupervised.)<p>But once we get to that point, we should absolutely ratchet those standards so automobile safety over time becomes just as safe as airline safety.  Safer, if possible.<p>&gt; <i>It&#x27;s stupid to hold automotive autopilots to the same standard as a plane&#x27;s autopilot when a third of fatalities in cars are caused by the pilots being drunk.</i><p>That&#x27;s a weird argument, because both pilots and drivers get thrown in jail if they fly&#x2F;drive drunk.  The standard is the same.</div><br/></div></div></div></div></div></div></div></div><div id="41889255" class="c"><input type="checkbox" id="c-41889255" checked=""/><div class="controls bullet"><span class="by">travem</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889176">parent</a><span>|</span><a href="#41889247">prev</a><span>|</span><a href="#41890925">next</a><span>|</span><label class="collapse" for="c-41889255">[-]</label><label class="expand" for="c-41889255">[10 more]</label></div><br/><div class="children"><div class="content">&gt; The answer is zero<p>If autopilot is 10x safer then preventing its use would lead to more preventable deaths and injuries than allowing it.<p>I agree that it should be regulated and incidents thoroughly investigated, however letting perfect be the enemy of good leads to stagnation and lack of practical improvement and greater injury to the population as a whole.</div><br/><div id="41889357" class="c"><input type="checkbox" id="c-41889357" checked=""/><div class="controls bullet"><span class="by">gambiting</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889255">parent</a><span>|</span><a href="#41889900">next</a><span>|</span><label class="collapse" for="c-41889357">[-]</label><label class="expand" for="c-41889357">[6 more]</label></div><br/><div class="children"><div class="content">&gt;&gt;If autopilot is 10x safer then preventing its use would lead to more preventable deaths and injuries than allowing it.<p>And yet whenever there is a problem with any plane autopilot it&#x27;s preemptively disabled fleet wide and pilots have to fly manually even though we absolutely beyond a shadow of a doubt know that it&#x27;s less safe.<p>If an automated system makes a wrong decision and it contributes to harm&#x2F;death then it cannot be allowed on public roads full stop, no matter how many lives it saves otherwise.</div><br/><div id="41891568" class="c"><input type="checkbox" id="c-41891568" checked=""/><div class="controls bullet"><span class="by">Aloisius</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889357">parent</a><span>|</span><a href="#41889557">next</a><span>|</span><label class="collapse" for="c-41891568">[-]</label><label class="expand" for="c-41891568">[1 more]</label></div><br/><div class="children"><div class="content">Depends on what one considers a &quot;problem.&quot; As long as the autopilot&#x27;s failures conditions and mitigation procedures are documented, the burden is largely shifted to the operator.<p>Autopilot didn&#x27;t prevent slamming into a mountain? Not a problem as long as it wasn&#x27;t designed to.<p>Crashed on landing? No problem, the manual says not to operate it below 500 feet.<p>Runaway pitch trim? The manual says you must constantly be monitoring the autopilot  and disengage it when it&#x27;s not operating as expected and to pull the autopilot and pitch trim circuit breakers. Clearly insufficient operator training is to blame.</div><br/></div></div><div id="41889557" class="c"><input type="checkbox" id="c-41889557" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889357">parent</a><span>|</span><a href="#41891568">prev</a><span>|</span><a href="#41891095">next</a><span>|</span><label class="collapse" for="c-41889557">[-]</label><label class="expand" for="c-41889557">[2 more]</label></div><br/><div class="children"><div class="content">&gt; And yet whenever there is a problem with any plane autopilot it&#x27;s preemptively disabled fleet wide and pilots have to fly manually even though we absolutely beyond a shadow of a doubt know that it&#x27;s less safe.<p>just because we do something dumb in one scenario isn&#x27;t a very persuasive reason to do the same in another.<p>&gt; then it cannot be allowed on public roads full stop, no matter how many lives it saves otherwise.<p>ambulances sometimes get into accidents - we should ban all ambulances, no matter how many lives they save otherwise.</div><br/></div></div><div id="41891095" class="c"><input type="checkbox" id="c-41891095" checked=""/><div class="controls bullet"><span class="by">CrimsonRain</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889357">parent</a><span>|</span><a href="#41889557">prev</a><span>|</span><a href="#41889900">next</a><span>|</span><label class="collapse" for="c-41891095">[-]</label><label class="expand" for="c-41891095">[2 more]</label></div><br/><div class="children"><div class="content">So your only concern is, when something goes wrong, need someone to blame. Who cares about lives saved.
Vaccines can cause adverse effects. Let&#x27;s ban all of them.<p>If people like you were in charge of anything, we&#x27;d still be hitting rocks for fire in caves.</div><br/><div id="41899449" class="c"><input type="checkbox" id="c-41899449" checked=""/><div class="controls bullet"><span class="by">gambiting</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41891095">parent</a><span>|</span><a href="#41889900">next</a><span>|</span><label class="collapse" for="c-41899449">[-]</label><label class="expand" for="c-41899449">[1 more]</label></div><br/><div class="children"><div class="content">Ok, consider this for a second. You&#x27;re a director of a hospital that owns a Therac radiotherapy machine for treating cancer. The machine is without any shadow of a doubt saving lives. People without access to it would die or have their prognosis worsen. Yet one day you get a report saying that the machine <i>might</i> sometimes, extremely rarely, accidentally deliver a lethal dose of radiation instead of the therapeutic one.<p>Do you decide to keep using the machine, or do you order it turned off until that defect can be fixed? Why yes or why not? Why does the same argument apply&#x2F;not apply in the discussion about self driving cars?<p>(And in case you haven&#x27;t heard about it - the Therac radiotherapy machine fault was a real thing, it&#x27;s being used as a cautionary tell for software development but I sometimes wonder if it should be used in philosophy classes too)</div><br/></div></div></div></div></div></div><div id="41889900" class="c"><input type="checkbox" id="c-41889900" checked=""/><div class="controls bullet"><span class="by">penjelly</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889255">parent</a><span>|</span><a href="#41889357">prev</a><span>|</span><a href="#41890925">next</a><span>|</span><label class="collapse" for="c-41889900">[-]</label><label class="expand" for="c-41889900">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d challenge the legitimacy of the claim that it&#x27;s 10x safer, or even safer at all. The safety data provided isn&#x27;t compelling to me, it can be games or misrepresented in various ways, as pointed out by others.</div><br/><div id="41890184" class="c"><input type="checkbox" id="c-41890184" checked=""/><div class="controls bullet"><span class="by">yCombLinks</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889900">parent</a><span>|</span><a href="#41890925">next</a><span>|</span><label class="collapse" for="c-41890184">[-]</label><label class="expand" for="c-41890184">[2 more]</label></div><br/><div class="children"><div class="content">That claim wasn&#x27;t made. It was a hypothetical, what if it was 10x safer? Then would people tolerate it.</div><br/><div id="41896727" class="c"><input type="checkbox" id="c-41896727" checked=""/><div class="controls bullet"><span class="by">penjelly</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41890184">parent</a><span>|</span><a href="#41890925">next</a><span>|</span><label class="collapse" for="c-41896727">[-]</label><label class="expand" for="c-41896727">[1 more]</label></div><br/><div class="children"><div class="content">yes people would, if we had a reliable metric for safety of these systems besides engaged&#x2F;disengaged. We don&#x27;t, and 10x safer with the current metrics is not satisfactory.</div><br/></div></div></div></div></div></div></div></div><div id="41890925" class="c"><input type="checkbox" id="c-41890925" checked=""/><div class="controls bullet"><span class="by">V99</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889176">parent</a><span>|</span><a href="#41889255">prev</a><span>|</span><a href="#41893571">next</a><span>|</span><label class="collapse" for="c-41890925">[-]</label><label class="expand" for="c-41890925">[7 more]</label></div><br/><div class="children"><div class="content">Airplane autopilots follow a lateral &amp; sometimes vertical path through the sky prescribed by the pilot(s).  They are good at doing that.  This does increase safety, because it frees up the pilot(s) from having to carefully maintain a straight 3d line through the sky for hours at a time.<p>But they do not listen to ATC.  They do not know where other planes are.  They do not keep themselves away from other planes.  Or the ground.  Or a flock of birds.  They do not handle emergencies.  They make only the most basic control-loop decisions about the control surface and power (if even autothrottle equipped, otherwise that&#x27;s still the meatbag&#x27;s job) changes needed to follow the magenta line drawn by the pilot given a very small set of input data (position, airspeed, current control positions, etc).<p>The next nearest airplane is typically at least 3 miles laterally and&#x2F;or 500&#x27; vertically away, because the errors allowed with all these components are measured in hundreds of feet.<p>None of this is even remotely comparable to a car using a dozen cameras (or lidar) to make real-time decisions to drive itself around imperfect public streets full of erratic drivers and other pedestrians a few feet away.<p>What it is a lot like is what Tesla actually sells (despite the marketing name).  Yes it&#x27;s &quot;flying&quot; the plane, but you&#x27;re still responsible for making sure it&#x27;s doing the right thing, the right way, and not and not going to hit anything or kill anybody.</div><br/><div id="41894377" class="c"><input type="checkbox" id="c-41894377" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41890925">parent</a><span>|</span><a href="#41895396">next</a><span>|</span><label class="collapse" for="c-41894377">[-]</label><label class="expand" for="c-41894377">[4 more]</label></div><br/><div class="children"><div class="content">Thank you for this.  The number of people conflating Tesla&#x27;s Autopilot with an airliner&#x27;s autopilot, and expecting that use and policies and situations surrounding the two should be directly comparable, is staggering.  You&#x27;d think people would be better at critical thinking with this, but... here we are.</div><br/><div id="41894817" class="c"><input type="checkbox" id="c-41894817" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41894377">parent</a><span>|</span><a href="#41895396">next</a><span>|</span><label class="collapse" for="c-41894817">[-]</label><label class="expand" for="c-41894817">[3 more]</label></div><br/><div class="children"><div class="content">Ah. Few people realize how dumb aircraft autopilots really are. Even the fanciest ones just follow a series of waypoints.<p>There is one exception - Garmin Safe Return. That&#x27;s strictly an emergency system. If it activates, the plane is squawking emergency to ATC and and demanding that airspace and a runway be cleared for it.[1] This has been available since 2019 and does not seem to have yet been activated in an emergency.<p>[1] <a href="https:&#x2F;&#x2F;youtu.be&#x2F;PiGkzgfR_c0?t=87" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;PiGkzgfR_c0?t=87</a></div><br/><div id="41897922" class="c"><input type="checkbox" id="c-41897922" checked=""/><div class="controls bullet"><span class="by">V99</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41894817">parent</a><span>|</span><a href="#41895396">next</a><span>|</span><label class="collapse" for="c-41897922">[-]</label><label class="expand" for="c-41897922">[2 more]</label></div><br/><div class="children"><div class="content">It does do that and it&#x27;s pretty neat, if you have one of the very few modern turboprops or small jets that have G3000s &amp; auto throttle to support it.<p>Airliners don&#x27;t have this, but they have a 2nd pilot.  A real-world activation needs a single-pilot operation where they&#x27;re incapacitated, in one of the maybe few hundred nice-but-not-too-nice private planes it&#x27;s equipped in, and a passenger is there to push it.<p>But this is all still largely using the current magenta line AP system, and that&#x27;s how it&#x27;s verifiable and certifiable.  There&#x27;s still no cameras or vision or AI deciding things, there are a few new bits of relatively simple standalone steps combined to get a good result.<p>- Pick a new magenta line to an airport (like pressing NRST Enter Enter if you have filtering set to only suitable fields)<p>- Pick a vertical path that intersects with the runway (Load a straight-in visual approach from the database)<p>- Ensure that line doesn&#x27;t hit anything in the terrain&#x2F;obstacle database. (Terrain warning system has all this info, not sure how it changes the plan if there is a conflict.  This is probably the hardest part, with an actual decision to make).<p>- Look up the tower frequency in DB and broadcast messages.  As you said it&#x27;s telling and not asking&#x2F;listening.<p>- Other humans know to get out of the way because this IS what&#x27;s going to happen. This is normal, an emergency aircraft gets whatever it wants.<p>- Standard AP and autothrottle flies the newly prescribed path.<p>- The radio altimeter lets it know when to flare.<p>- Wheel weight sensors let it know to apply the brakes.<p>- The airport helps people out and tows the plane away, because it doesn&#x27;t know how to taxi.<p>There&#x27;s also &quot;auto glide&quot; on the more accessible G3x suite for planes that aren&#x27;t necessarily $3m+.  That will do most of the same stuff and get you almost, but not all the way, to the ground in front of a runway automatically.</div><br/><div id="41899097" class="c"><input type="checkbox" id="c-41899097" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41897922">parent</a><span>|</span><a href="#41895396">next</a><span>|</span><label class="collapse" for="c-41899097">[-]</label><label class="expand" for="c-41899097">[1 more]</label></div><br/><div class="children"><div class="content">&gt; and a passenger is there to push it.<p>I think it will also activate if the pilot is unconscious, for solo flights. It has something like a driver alertness detection system that will alarm if the pilot does nothing for too long. The pilot can reset the alarm, but if they do nothing, the auto return system takes over and lands the plane someplace.</div><br/></div></div></div></div></div></div></div></div><div id="41895396" class="c"><input type="checkbox" id="c-41895396" checked=""/><div class="controls bullet"><span class="by">josephcsible</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41890925">parent</a><span>|</span><a href="#41894377">prev</a><span>|</span><a href="#41893571">next</a><span>|</span><label class="collapse" for="c-41895396">[-]</label><label class="expand" for="c-41895396">[2 more]</label></div><br/><div class="children"><div class="content">&gt; They do not know where other planes are.<p>Yes they do. It&#x27;s called TCAS.<p>&gt; Or the ground.<p>Yes they do. It&#x27;s called Auto-GCAS.</div><br/><div id="41897516" class="c"><input type="checkbox" id="c-41897516" checked=""/><div class="controls bullet"><span class="by">V99</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41895396">parent</a><span>|</span><a href="#41893571">next</a><span>|</span><label class="collapse" for="c-41897516">[-]</label><label class="expand" for="c-41897516">[1 more]</label></div><br/><div class="children"><div class="content">Yes those are optional systems that exist, but they are unrelated to the autopilot (in at least the vast majority of avionics).<p>They are warning systems that humans respond to.  For a TCAS RA the first thing you&#x27;re doing is disengaging the autopilot.<p>If you tell the autopilot to fly straight into the path of a mountain, it will happily comply and kill you while the ground proximity warnings blare.<p>Humans make the decisions in planes.  Autopilots are a useful but very basic tool, much more akin to cruise control in a 1998 Civic than a self-driving Tesla&#x2F;Waymo&#x2F;erc.</div><br/></div></div></div></div></div></div><div id="41893571" class="c"><input type="checkbox" id="c-41893571" checked=""/><div class="controls bullet"><span class="by">AlchemistCamp</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889176">parent</a><span>|</span><a href="#41890925">prev</a><span>|</span><a href="#41891217">next</a><span>|</span><label class="collapse" for="c-41893571">[-]</label><label class="expand" for="c-41893571">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>”The answer is zero…”</i><p>&gt; <i>”If there is any issue discovered in any car with this tech then it should be disabled worldwide until the root cause is found and eliminated.”</i><p>This would literally cost millions of needless deaths in a situation where AI drivers had 1&#x2F;10th the accident injury rate of human drivers.</div><br/></div></div><div id="41891217" class="c"><input type="checkbox" id="c-41891217" checked=""/><div class="controls bullet"><span class="by">peterdsharpe</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889176">parent</a><span>|</span><a href="#41893571">prev</a><span>|</span><a href="#41891202">next</a><span>|</span><label class="collapse" for="c-41891217">[-]</label><label class="expand" for="c-41891217">[1 more]</label></div><br/><div class="children"><div class="content">&gt; literally no errors in its operation are tolerated<p>Aircraft designer here, this is not true. We typically certify to &lt;1 catastrophic failure per 1e9 flight hours. Not zero.</div><br/></div></div><div id="41891202" class="c"><input type="checkbox" id="c-41891202" checked=""/><div class="controls bullet"><span class="by">Aloisius</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889176">parent</a><span>|</span><a href="#41891217">prev</a><span>|</span><a href="#41889249">next</a><span>|</span><label class="collapse" for="c-41891202">[-]</label><label class="expand" for="c-41891202">[1 more]</label></div><br/><div class="children"><div class="content">Autopilots aren&#x27;t held to a zero error standard let alone a zero accident standard.</div><br/></div></div></div></div><div id="41889249" class="c"><input type="checkbox" id="c-41889249" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889176">prev</a><span>|</span><a href="#41889898">next</a><span>|</span><label class="collapse" for="c-41889249">[-]</label><label class="expand" for="c-41889249">[6 more]</label></div><br/><div class="children"><div class="content">&gt; traveled of the median human driver isn&#x27;t acceptable.<p>It&#x27;s completely acceptable.  In fact the numbers are lower than they have been since we&#x27;ve started driving.<p>&gt; Accidents caused by human drivers<p>Are there any other types of drivers?<p>&gt; are one of the largest causes of injury and death<p>More than half the fatalities on the road are actually caused by the use of drugs and alcohol.  The statistics are very clear on this.  Impaired people cannot drive well.  Non impaired people drive orders of magnitude better.<p>&gt; technology that could save lives<p>There is absolutely zero evidence this is true.  Everyone is basing this off of a total misunderstanding of the source of fatalities and a willful misapprehension of the technology.</div><br/><div id="41889370" class="c"><input type="checkbox" id="c-41889370" checked=""/><div class="controls bullet"><span class="by">blargey</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889249">parent</a><span>|</span><a href="#41894388">next</a><span>|</span><label class="collapse" for="c-41889370">[-]</label><label class="expand" for="c-41889370">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Non impaired people drive orders of magnitude better.<p>That raises the question - how many <i>impaired</i> driver-miles are being baked into the collision statistics for &quot;median human&quot; driver-miles? Shouldn&#x27;t we demand non-impaired driving as the standard for automation, rather than &quot;averaged with drunk &#x2F; phone-fiddling &#x2F;senile&quot; driving? We don&#x27;t give people N-mile allowances for drunk driving based on the size of the drunk driver population, after all.</div><br/><div id="41892049" class="c"><input type="checkbox" id="c-41892049" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889370">parent</a><span>|</span><a href="#41894391">next</a><span>|</span><label class="collapse" for="c-41892049">[-]</label><label class="expand" for="c-41892049">[1 more]</label></div><br/><div class="children"><div class="content">Motorcycles account for a further 15% of all fatalities in a typical year.  Weather is often a factor.  Road design is sometimes a factor,  remembering several rollover crashes that ended in a body of water and no one in the vehicle surviving.  Likewise ejections during fatalities due to lack of seatbelt use is also noticeable.<p>Once you dig into the data you see that almost every crash,  at this point in history,  is really a mini-story detailing the confluence of several factors that turned a basic accident into something fatal.<p>Also,  and I only saw this once,  but if you literally have a heart attack behind the wheel,  you are technically a roadway fatality.  The driver was 99.  He just died while sitting in slow moving traffic.<p>Which brings me to my final point which is the rear seats in automobiles are less safe than the front seats.  This is true for almost every vehicle on the road.  You see _a lot_ of accidents where two 40 to 50 year old passengers are up front and two 70 to 80 year old passengers are in back.  The ones up front survive.  One or both passengers in the back typically die.</div><br/></div></div><div id="41894391" class="c"><input type="checkbox" id="c-41894391" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889370">parent</a><span>|</span><a href="#41892049">prev</a><span>|</span><a href="#41894388">next</a><span>|</span><label class="collapse" for="c-41894391">[-]</label><label class="expand" for="c-41894391">[2 more]</label></div><br/><div class="children"><div class="content">No, that makes no sense, because we can&#x27;t ensure that human drivers aren&#x27;t impaired.  We test and compare against the reality, not the ideal we&#x27;d prefer.</div><br/><div id="41896967" class="c"><input type="checkbox" id="c-41896967" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41894391">parent</a><span>|</span><a href="#41894388">next</a><span>|</span><label class="collapse" for="c-41896967">[-]</label><label class="expand" for="c-41896967">[1 more]</label></div><br/><div class="children"><div class="content">We can sample rate of impairment.  We do this quite often actually.  It turns out the rate depends on the time of day.</div><br/></div></div></div></div></div></div><div id="41894388" class="c"><input type="checkbox" id="c-41894388" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889249">parent</a><span>|</span><a href="#41889370">prev</a><span>|</span><a href="#41889898">next</a><span>|</span><label class="collapse" for="c-41894388">[-]</label><label class="expand" for="c-41894388">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Are there any other types of drivers [than human drivers]?</i><p>Waymo says yes, there are.</div><br/></div></div></div></div><div id="41889898" class="c"><input type="checkbox" id="c-41889898" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889249">prev</a><span>|</span><a href="#41889205">next</a><span>|</span><label class="collapse" for="c-41889898">[-]</label><label class="expand" for="c-41889898">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s clear that having half the casualty rate per distance traveled of the median human driver isn&#x27;t acceptable.<p>Even if we optimistically assume no &quot;gotchas&quot; in the statistics [0], distilling performance down to a casualty&#x2F;injury&#x2F;accident-rate can still be dangerously reductive, when the have a different <i>distribution</i> of failure-modes which do&#x2F;don&#x27;t mesh with our other systems and defenses.<p>A quick thought experiment to prove the point: Imagine a system which compared to human drivers had only half the rate of accidents... But many of those are because it unpredictably decides to jump the sidewalk curb and kill a targeted pedestrian.<p>The raw numbers are encouraging, but it represents a risk profile that clashes horribly with our other systems of road design, car design, and what incidents humans are expecting and capable of preventing or recovering-from.<p>[0] Ex: Automation is only being used on certain <i>subsets</i> of all travel which are the &quot;easier&quot; miles or circumstances than the whole gamut a human would handle.</div><br/><div id="41894403" class="c"><input type="checkbox" id="c-41894403" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889898">parent</a><span>|</span><a href="#41889205">next</a><span>|</span><label class="collapse" for="c-41894403">[-]</label><label class="expand" for="c-41894403">[1 more]</label></div><br/><div class="children"><div class="content">Re: gotchas: an even easier one is that the Tesla FSD statistics don&#x27;t include when the car does something unsafe and the driver intervenes and takes control, averting a crash.<p>How often does that happen?  We have no idea.  Tesla can certainly tell when a driver intervenes, but they can&#x27;t count every occurrence as safety-related, because a driver might take control for all sorts of reasons.<p>This is why we can make stronger statements about the safety of Waymo.  Their software was only tested by people trained and paid to test it, who were also recording every time they had to intervene because of safety, even if there was no crash.  That&#x27;s a metric they could track and improve.</div><br/></div></div></div></div><div id="41889205" class="c"><input type="checkbox" id="c-41889205" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889898">prev</a><span>|</span><a href="#41889210">next</a><span>|</span><label class="collapse" for="c-41889205">[-]</label><label class="expand" for="c-41889205">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s clear that having half the casualty rate per distance traveled of the median human driver isn&#x27;t acceptable.<p>Were the Teslas driving under all weather conditions at any location like humans do or is it just cherry picked from the easy travelling conditions?</div><br/></div></div><div id="41889210" class="c"><input type="checkbox" id="c-41889210" checked=""/><div class="controls bullet"><span class="by">jakelazaroff</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889205">prev</a><span>|</span><a href="#41895039">next</a><span>|</span><label class="collapse" for="c-41889210">[-]</label><label class="expand" for="c-41889210">[5 more]</label></div><br/><div class="children"><div class="content">I think we should not be satisfied with merely “better than a human”. Flying is so safe precisely because we treat any casualty as unacceptable. We should aspire to make automobiles <i>at least</i> that safe.</div><br/><div id="41894433" class="c"><input type="checkbox" id="c-41894433" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889210">parent</a><span>|</span><a href="#41895416">next</a><span>|</span><label class="collapse" for="c-41894433">[-]</label><label class="expand" for="c-41894433">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the question was what we should be satisfied with or what we should aspire to.  I absolutely agree with you that we should strive to make autonomous driving as safe as airline travel.<p>But the question was when should we allow autonomous driving on our public roads.  And I think &quot;when it&#x27;s at least as safe as the median human driver&quot; is a reasonable threshold.<p>(The thing about Tesla FSD is that it -- unsupervised -- would probably fall super short of that metric.  FSD needs to be supervised to be safer than the median human driver, assuming that&#x27;s evn currently the case, and not every driver is going to be equally good at supervising it.)</div><br/></div></div><div id="41895416" class="c"><input type="checkbox" id="c-41895416" checked=""/><div class="controls bullet"><span class="by">josephcsible</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889210">parent</a><span>|</span><a href="#41894433">prev</a><span>|</span><a href="#41894364">next</a><span>|</span><label class="collapse" for="c-41895416">[-]</label><label class="expand" for="c-41895416">[1 more]</label></div><br/><div class="children"><div class="content">Aspire to, yes. But if we say &quot;we&#x27;re going to ban FSD until it&#x27;s perfect, even though it already saves lives relative to the average human driver&quot;, you&#x27;re making automobiles <i>less</i> safe.</div><br/></div></div><div id="41894364" class="c"><input type="checkbox" id="c-41894364" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889210">parent</a><span>|</span><a href="#41895416">prev</a><span>|</span><a href="#41890066">next</a><span>|</span><label class="collapse" for="c-41894364">[-]</label><label class="expand" for="c-41894364">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think we should not be satisfied with merely “better than a human”.<p>The question is whether you want to outlaw automatic driving just because the system is, say, &quot;only&quot; 50% safer than us.</div><br/></div></div><div id="41890066" class="c"><input type="checkbox" id="c-41890066" checked=""/><div class="controls bullet"><span class="by">aantix</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889210">parent</a><span>|</span><a href="#41894364">prev</a><span>|</span><a href="#41895039">next</a><span>|</span><label class="collapse" for="c-41890066">[-]</label><label class="expand" for="c-41890066">[1 more]</label></div><br/><div class="children"><div class="content">Before FSD is allowed on public roads?<p>It’s a net positive, saving lives right now.</div><br/></div></div></div></div><div id="41895039" class="c"><input type="checkbox" id="c-41895039" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889210">prev</a><span>|</span><a href="#41889331">next</a><span>|</span><label class="collapse" for="c-41895039">[-]</label><label class="expand" for="c-41895039">[1 more]</label></div><br/><div class="children"><div class="content">The key here is insurers. Because they pick up the bill when things go wrong. As soon as self driving becomes clearly better than humans, they&#x27;ll be insisting we stop risking their money by driving ourselves whenever that is feasible. And they&#x27;ll do that with price incentives. They&#x27;ll happily insure you if you want to drive yourself. But you&#x27;ll pay a premium. And a discount if you are happy to let the car do the driving.<p>Eventually, manual driving should come with a lot more scrutiny. Because once it becomes a choice rather than an economic necessity, other people on the road will want to be sure that you are not needlessly endangering them. So, stricter requirements for getting a drivers license with more training and fitness&#x2F;health requirements. This too will be driven by insurers. They&#x27;ll want to make sure you are fit to drive.<p>And of course when manual driving people get into trouble, taking away their driving license is always a possibility. The main argument against doing that right now is that a lot of people depend economically on being able to drive. But if that argument goes away, there&#x27;s no reason to not be a lot stricter for e.g. driving under influence, or routinely breaking laws for speeding and other traffic violations. Think higher fines and driving license suspensions.</div><br/></div></div><div id="41889331" class="c"><input type="checkbox" id="c-41889331" checked=""/><div class="controls bullet"><span class="by">smitty1110</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41895039">prev</a><span>|</span><a href="#41889122">next</a><span>|</span><label class="collapse" for="c-41889331">[-]</label><label class="expand" for="c-41889331">[1 more]</label></div><br/><div class="children"><div class="content">There’s two things going on here with there average person that you need to overcome: That when Tesla dodges responsibility all anyone sees is a liar, and that people amalgamate all the FSD crashes and treat the system like a dangerous local driver that nobody can get off the road.<p>Tesla markets FSD like it’s a silver bullet, and the name is truly misleading. The fine print says you need attention and all that. But again, people read “Full Self Driving” and all the marketing copy and think the system is assuming responsibility for the outcomes. Then a crash happens, Tesla throws the driver under the bus, and everyone gets a bit more skeptical of the system. Plus, doing that to a person rubs people the wrong way, and is in some respects a barrier to sales.<p>Which leads to the other point: People are tallying up all the accidents and treating the system like a person, and wondering why this dangerous driver is still on the road. Most accidents with dead pedestrian start with someone doing something stupid, which is when they assume all responsibility, legally speaking. Drunk, speeding, etc. Normal drivers in poor conditions slow down and drive carefully. People see this accident, and treat FSD like a serial drunk driver. It’s to the point that I know people that openly say they treat teslas on roads like they’re erratic drivers just for existing.<p>Until Elon figures out how to fix his perception problem, the calls for investigations and to keep his robotaxis is off the road will only grow.</div><br/></div></div><div id="41889122" class="c"><input type="checkbox" id="c-41889122" checked=""/><div class="controls bullet"><span class="by">becquerel</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889331">prev</a><span>|</span><a href="#41889686">next</a><span>|</span><label class="collapse" for="c-41889122">[-]</label><label class="expand" for="c-41889122">[8 more]</label></div><br/><div class="children"><div class="content">My dream is of a future where humans are banned from driving without special licenses.</div><br/><div id="41889187" class="c"><input type="checkbox" id="c-41889187" checked=""/><div class="controls bullet"><span class="by">gambiting</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889122">parent</a><span>|</span><a href="#41889200">next</a><span>|</span><label class="collapse" for="c-41889187">[-]</label><label class="expand" for="c-41889187">[5 more]</label></div><br/><div class="children"><div class="content">So.........like right now you mean? You need a special licence to drive on a public road right now.</div><br/><div id="41889312" class="c"><input type="checkbox" id="c-41889312" checked=""/><div class="controls bullet"><span class="by">nkrisc</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889187">parent</a><span>|</span><a href="#41894441">next</a><span>|</span><label class="collapse" for="c-41889312">[-]</label><label class="expand" for="c-41889312">[2 more]</label></div><br/><div class="children"><div class="content">The problem is it’s obviously too easy to get one and keep one, based on some of the drivers I see on the road.</div><br/><div id="41889365" class="c"><input type="checkbox" id="c-41889365" checked=""/><div class="controls bullet"><span class="by">gambiting</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889312">parent</a><span>|</span><a href="#41894441">next</a><span>|</span><label class="collapse" for="c-41889365">[-]</label><label class="expand" for="c-41889365">[1 more]</label></div><br/><div class="children"><div class="content">That sounds like a legislative problem where you live, sure it can be fixed by overbearing technology but we already have all the tools we need to fix it, we are just choosing not to for some reason.</div><br/></div></div></div></div><div id="41894441" class="c"><input type="checkbox" id="c-41894441" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889187">parent</a><span>|</span><a href="#41889312">prev</a><span>|</span><a href="#41889262">next</a><span>|</span><label class="collapse" for="c-41894441">[-]</label><label class="expand" for="c-41894441">[1 more]</label></div><br/><div class="children"><div class="content">No, you need an entirely common, unspecial license drive on a public road right now.</div><br/></div></div><div id="41889262" class="c"><input type="checkbox" id="c-41889262" checked=""/><div class="controls bullet"><span class="by">seizethecheese</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889187">parent</a><span>|</span><a href="#41894441">prev</a><span>|</span><a href="#41889200">next</a><span>|</span><label class="collapse" for="c-41889262">[-]</label><label class="expand" for="c-41889262">[1 more]</label></div><br/><div class="children"><div class="content">Geez, clearly they mean like a CDL</div><br/></div></div></div></div><div id="41889200" class="c"><input type="checkbox" id="c-41889200" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889122">parent</a><span>|</span><a href="#41889187">prev</a><span>|</span><a href="#41889686">next</a><span>|</span><label class="collapse" for="c-41889200">[-]</label><label class="expand" for="c-41889200">[2 more]</label></div><br/><div class="children"><div class="content">And yet Tesla&#x27;s FSD never passed a driving test.</div><br/><div id="41894570" class="c"><input type="checkbox" id="c-41894570" checked=""/><div class="controls bullet"><span class="by">grecy</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889200">parent</a><span>|</span><a href="#41889686">next</a><span>|</span><label class="collapse" for="c-41894570">[-]</label><label class="expand" for="c-41894570">[1 more]</label></div><br/><div class="children"><div class="content">And it can’t legally drive a vehicle</div><br/></div></div></div></div></div></div><div id="41889686" class="c"><input type="checkbox" id="c-41889686" checked=""/><div class="controls bullet"><span class="by">danans</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889122">prev</a><span>|</span><a href="#41889307">next</a><span>|</span><label class="collapse" for="c-41889686">[-]</label><label class="expand" for="c-41889686">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The interesting question is how good self-driving has to be before people tolerate it.<p>It&#x27;s pretty simple: as good as it can be given available technologies and techniques, without sacrificing safety for cost or style.<p>With AVs, function and safety should obviate concerns of style, cost, and marketing.  If that doesn&#x27;t work with your business model, well tough luck.<p>Airplanes are far safer than cars yet we subject their manufacturers to rigorous standards, or seemingly did until recently, as the 737 max saga has revealed.  Even still the rigor is very high compared to road vehicles.<p>And AVs do have to be way better than people at driving because they are machines that have no sense of human judgement, though they operate in a human physical context.<p>Machines run by corporations are less accountable than human drivers, not at the least because of the wealth and legal armies of those corporations who may have interests other than making the safest possible AV.</div><br/><div id="41889699" class="c"><input type="checkbox" id="c-41889699" checked=""/><div class="controls bullet"><span class="by">mavhc</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889686">parent</a><span>|</span><a href="#41889307">next</a><span>|</span><label class="collapse" for="c-41889699">[-]</label><label class="expand" for="c-41889699">[2 more]</label></div><br/><div class="children"><div class="content">Surely the number of cars than can do it, and the price, also matters, unless you&#x27;re going to ban private cars</div><br/><div id="41890064" class="c"><input type="checkbox" id="c-41890064" checked=""/><div class="controls bullet"><span class="by">danans</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889699">parent</a><span>|</span><a href="#41889307">next</a><span>|</span><label class="collapse" for="c-41890064">[-]</label><label class="expand" for="c-41890064">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Surely the number of cars than can do it, and the price, also matters, unless you&#x27;re going to ban private cars<p>Indeed, like this: the more cars sold that claim fully autonomous capability, and the more affordable they get, the higher the standards should be compared to their <i>AV</i> predecessors, even if they have long eclipsed human driver&#x27;s safety record.<p>If this is unpalatable, then let&#x27;s assign 100% liability with steep monetary penalties to the AV manufacturer for any crash that happens under autonomous driving mode.</div><br/></div></div></div></div></div></div><div id="41889307" class="c"><input type="checkbox" id="c-41889307" checked=""/><div class="controls bullet"><span class="by">aithrowawaycomm</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889686">prev</a><span>|</span><a href="#41893035">next</a><span>|</span><label class="collapse" for="c-41889307">[-]</label><label class="expand" for="c-41889307">[2 more]</label></div><br/><div class="children"><div class="content">Many people don&#x27;t (and shouldn&#x27;t) take the &quot;half the casualty rate&quot; at face value. My biggest concern is that Waymo and Tesla are juking the stats to make self-driving cars seem safer than they really are. I believe this is largely an unintentional consequence of bad actuary science coming from bad qualitative statistics; the worst kind of lying with numbers is lying to yourself.<p>The biggest gap in these studies: I have yet to see a comparison with human drivers that filters out DUIs, reckless speeding, or mechanical failures. Without doing this it is simply not a fair comparison, because:<p>1) Self-driving cars won&#x27;t end drunk driving unless it&#x27;s made mandatory by outlawing manual driving or ignition is tied to a breathalyzer. Many people will continue to make the dumb decision to drive themselves home because they are drunk and driving is fun. This needs regulation, not technology. And DUIs need to be filtered from the crash statistics when comparing with Waymo.<p>2) A self-driving car which speeds and runs red lights might well be more dangerous than a similar human, but the data says nothing about this since Waymo is currently on their best behavior. Yet Tesla&#x27;s own behavior and customers prove that there is demand for reckless self-driving cars, and manufacturers will meet the demand unless the law steps in. Imagine a Waymo competitor that promises Uber-level ETAs for people in a hurry. Technology could in theory solve this but in practice the market could make things worse for several decades until the next research breakthrough. Human accidents coming from distraction are a fair comparison to Waymo, but speeding or aggressiveness should be filtered out. The difficulty of doing so is one of the many reasons I am so skeptical of these stats.<p>3) Mechanical failures are a hornets&#x27; nest of ML edge cases that might work in the lab but fail miserably on the road. Currently it&#x27;s not a big deal because the cars are shiny and new. Eventually we&#x27;ll have self-driving clunkers owned by drivers who don&#x27;t want to pay for the maintenance.<p>And that&#x27;s not even mentioning that Waymos are not self-driving, they rely on close remote oversight to guide AI through the many billions of common-sense problems that computets will not able to solve for at least the next decade, probably much longer. True self-driving cars will continue to make inexplicably stupid decisions: these machines are still much dumber than lizards. Stories like &quot;the Tesla slammed into an overturned tractor trailer because the AI wasn&#x27;t trained on overturned trucks&quot; are a huge problem and society will not let Tesla try to launder it away with statistics.<p>Self-driving cars might end up saving lives. But would they save more lives than adding mandatory breathalyzers and GPS-based speed limits? And if market competition overtakes business ethics, would they cost more lives than they save? The stats say very little about this.</div><br/><div id="41894458" class="c"><input type="checkbox" id="c-41894458" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889307">parent</a><span>|</span><a href="#41893035">next</a><span>|</span><label class="collapse" for="c-41894458">[-]</label><label class="expand" for="c-41894458">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>My biggest concern is that Waymo and Tesla are juking the stats to make self-driving cars seem safer than they really are</i><p>Even intentional juking aside, you can&#x27;t really compare the two.<p>Waymo cars drive completely autonomously, without a supervising driver in the car.  If it does something unsafe, there&#x27;s no one there to correct it, and it may get into a crash, in the same way a human driver doing that same unsafe thing might.<p>With Tesla FSD, we have no idea how good it really is.  We know that a human is supervising it, and despite all the reports we see of people doing super irresponsible things while &quot;driving&quot; a Tesla (like taking a nap), I imagine most Tesla FSD users are actually attentively supervising for the most part.  If all FSD users stopped supervising and started taking naps, I suspect the crash rate and fatality rate would start looking like the rate for the worst drivers on the road... or even worse than that.<p>So it&#x27;s not that they&#x27;re juking their stats (although they may be), it&#x27;s that they don&#x27;t actually have all the stats that matter.  Waymo has and had those stats, because their trained human test drivers were reporting when the car did something unsafe and they had to take over.  Tesla FSD users don&#x27;t report when they have to do that.  The data is just not there.</div><br/></div></div></div></div><div id="41893035" class="c"><input type="checkbox" id="c-41893035" checked=""/><div class="controls bullet"><span class="by">moogly</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889307">prev</a><span>|</span><a href="#41890101">next</a><span>|</span><label class="collapse" for="c-41893035">[-]</label><label class="expand" for="c-41893035">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Accidents caused by human drivers are one of the largest causes of injury and death<p>In some parts of the world. Perhaps some countries should look deeper into why and why self-driving cars might not be the No. 1 answer to reduce traffic accidents.</div><br/></div></div><div id="41890101" class="c"><input type="checkbox" id="c-41890101" checked=""/><div class="controls bullet"><span class="by">alkonaut</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41893035">prev</a><span>|</span><a href="#41894476">next</a><span>|</span><label class="collapse" for="c-41890101">[-]</label><label class="expand" for="c-41890101">[1 more]</label></div><br/><div class="children"><div class="content">&gt; How about a quarter? Or a tenth?<p>Probably closer to the latter. The &quot;skin in the game&quot; (physically) argument makes me more willing to accept drunk drivers than greedy manufacturers when it comes to making mistakes or being negligent.</div><br/></div></div><div id="41894476" class="c"><input type="checkbox" id="c-41894476" checked=""/><div class="controls bullet"><span class="by">fma</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41890101">prev</a><span>|</span><a href="#41900280">next</a><span>|</span><label class="collapse" for="c-41894476">[-]</label><label class="expand" for="c-41894476">[1 more]</label></div><br/><div class="children"><div class="content">Flying is safer than driving but Boeing isn&#x27;t getting a free pass on quality issues. Why would Tesla?</div><br/></div></div><div id="41900280" class="c"><input type="checkbox" id="c-41900280" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41894476">prev</a><span>|</span><a href="#41890057">next</a><span>|</span><label class="collapse" for="c-41900280">[-]</label><label class="expand" for="c-41900280">[1 more]</label></div><br/><div class="children"><div class="content">How about fewer accidents per distance of equivalent driving?</div><br/></div></div><div id="41890057" class="c"><input type="checkbox" id="c-41890057" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41900280">prev</a><span>|</span><a href="#41889114">next</a><span>|</span><label class="collapse" for="c-41890057">[-]</label><label class="expand" for="c-41890057">[1 more]</label></div><br/><div class="children"><div class="content">The problem is that Tesla is way behind the industry standards here and it&#x27;s misrepresenting how good their tech is.</div><br/></div></div><div id="41889114" class="c"><input type="checkbox" id="c-41889114" checked=""/><div class="controls bullet"><span class="by">iovrthoughtthis</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41890057">prev</a><span>|</span><a href="#41890451">next</a><span>|</span><label class="collapse" for="c-41889114">[-]</label><label class="expand" for="c-41889114">[7 more]</label></div><br/><div class="children"><div class="content">at least 10x better than a human</div><br/><div id="41889127" class="c"><input type="checkbox" id="c-41889127" checked=""/><div class="controls bullet"><span class="by">becquerel</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889114">parent</a><span>|</span><a href="#41890451">next</a><span>|</span><label class="collapse" for="c-41889127">[-]</label><label class="expand" for="c-41889127">[6 more]</label></div><br/><div class="children"><div class="content">I believe Waymo has already beaten this metric.</div><br/><div id="41889189" class="c"><input type="checkbox" id="c-41889189" checked=""/><div class="controls bullet"><span class="by">szundi</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889127">parent</a><span>|</span><a href="#41890451">next</a><span>|</span><label class="collapse" for="c-41889189">[-]</label><label class="expand" for="c-41889189">[5 more]</label></div><br/><div class="children"><div class="content">Waymo is limited to cities that their engineers has to map and this map maintained.<p>You cannot put a waymo in a new city before that. With Tesla, what you get is universal.</div><br/><div id="41894466" class="c"><input type="checkbox" id="c-41894466" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889189">parent</a><span>|</span><a href="#41889466">next</a><span>|</span><label class="collapse" for="c-41894466">[-]</label><label class="expand" for="c-41894466">[1 more]</label></div><br/><div class="children"><div class="content">Waymo is safe where they&#x27;ve mapped and trained and tested, because they track when their test drivers have to take control.<p>Tesla FSD is just everywhere, without any accountability or trained testing on all the roads people use them on.  We have no idea how often Tesla FSD users have to take control from FSD due to a safety issue.<p>Waymo is objectively safer, and their entire approach is objectively safer, and is actually measurable, whereas Tesla FSD&#x27;s safety cannot actually be accurately measured.</div><br/></div></div><div id="41889466" class="c"><input type="checkbox" id="c-41889466" checked=""/><div class="controls bullet"><span class="by">RivieraKid</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889189">parent</a><span>|</span><a href="#41894466">prev</a><span>|</span><a href="#41894346">next</a><span>|</span><label class="collapse" for="c-41889466">[-]</label><label class="expand" for="c-41889466">[1 more]</label></div><br/><div class="children"><div class="content">Waymo is robust to removing the map &#x2F; lidars &#x2F; radars &#x2F; cameras or adding inaccuracies to any of these 4 inputs.<p>(Not sure if this is true for the production system or the one they&#x27;re still working on.)</div><br/></div></div><div id="41894346" class="c"><input type="checkbox" id="c-41894346" checked=""/><div class="controls bullet"><span class="by">dageshi</span><span>|</span><a href="#41889077">root</a><span>|</span><a href="#41889189">parent</a><span>|</span><a href="#41889466">prev</a><span>|</span><a href="#41889238">next</a><span>|</span><label class="collapse" for="c-41894346">[-]</label><label class="expand" for="c-41894346">[1 more]</label></div><br/><div class="children"><div class="content">I think the Waymo approach is the one that will actually deliver some measure of self driving cars that people will be comfortable to use.<p>It won&#x27;t operate everywhere, but it will gradually expand to cover large areas and it will keep expanding till it&#x27;s near ubiquitous.<p>I&#x27;m dubious that the Tesla approach will actually ever work.</div><br/></div></div></div></div></div></div></div></div><div id="41890451" class="c"><input type="checkbox" id="c-41890451" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41889077">parent</a><span>|</span><a href="#41889114">prev</a><span>|</span><a href="#41888998">next</a><span>|</span><label class="collapse" for="c-41890451">[-]</label><label class="expand" for="c-41890451">[1 more]</label></div><br/><div class="children"><div class="content">&gt;It&#x27;s clear that having half the casualty rate per distance traveled of the median human driver isn&#x27;t acceptable.<p>Are you sure? Right now FSD is active with no one actually knowing its casualty rate, and the for the most part the only people upset about it are terminally online people on twitter or luddites on HN.</div><br/></div></div></div></div><div id="41888998" class="c"><input type="checkbox" id="c-41888998" checked=""/><div class="controls bullet"><span class="by">alexjplant</span><span>|</span><a href="#41889077">prev</a><span>|</span><a href="#41895040">next</a><span>|</span><label class="collapse" for="c-41888998">[-]</label><label class="expand" for="c-41888998">[36 more]</label></div><br/><div class="children"><div class="content">&gt; The collision happened because the sun was in the Tesla driver&#x27;s eyes, so the Tesla driver was not charged, said Raul Garcia, public information officer for the department.<p>Am I missing something or is this the gross miscarriage of justice that it sounds like? The driver could afford a $40k vehicle but not $20 polarized shades from Amazon? Negligence is negligence.</div><br/><div id="41889061" class="c"><input type="checkbox" id="c-41889061" checked=""/><div class="controls bullet"><span class="by">smdyc1</span><span>|</span><a href="#41888998">parent</a><span>|</span><a href="#41889188">next</a><span>|</span><label class="collapse" for="c-41889061">[-]</label><label class="expand" for="c-41889061">[12 more]</label></div><br/><div class="children"><div class="content">Not to mention that when you can&#x27;t see, you slow down? Does the self-driving system do that sufficiently in low visibility? Clearly not if it hit a pedestrian with enough force to kill them.<p>The article mentions that Tesla&#x27;s only use cameras in their system and Musk believes they are enough, because humans only use their eyes. Well firstly, don&#x27;t you want self-driving systems to be <i>better</i> than humans? Secondly, humans don&#x27;t just respond to visual cues as a computer would. We also hear and respond to feelings, like the sudden surge of anxiety or fear as our visibility is suddenly reduced at high speed.</div><br/><div id="41889276" class="c"><input type="checkbox" id="c-41889276" checked=""/><div class="controls bullet"><span class="by">jsight</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889061">parent</a><span>|</span><a href="#41889167">next</a><span>|</span><label class="collapse" for="c-41889276">[-]</label><label class="expand" for="c-41889276">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately there is also an AI training problem embedded in this. As Mobileye says, there are a lot of driver decisions that are common, but wrong. The famous example is rolling stops, but also failing to slow down for conditions is really common.<p>It wouldn&#x27;t shock me if they don&#x27;t have nearly enough training samples of people slowing appropriately for visibility with eyes, much less slowing for the somewhat different limitations of cameras.</div><br/></div></div><div id="41889167" class="c"><input type="checkbox" id="c-41889167" checked=""/><div class="controls bullet"><span class="by">hshshshshsh</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889061">parent</a><span>|</span><a href="#41889276">prev</a><span>|</span><a href="#41889132">next</a><span>|</span><label class="collapse" for="c-41889167">[-]</label><label class="expand" for="c-41889167">[6 more]</label></div><br/><div class="children"><div class="content">I think one of the reasons they focus only on vision is basically the entire transportation infra is designed using human eyes a primary way to channel information.<p>Useful information for driving are communicated through images in form of road signs, traffic signals etc.</div><br/><div id="41889325" class="c"><input type="checkbox" id="c-41889325" checked=""/><div class="controls bullet"><span class="by">nkrisc</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889167">parent</a><span>|</span><a href="#41889494">next</a><span>|</span><label class="collapse" for="c-41889325">[-]</label><label class="expand" for="c-41889325">[3 more]</label></div><br/><div class="children"><div class="content">I dunno, knowing the exact relative velocity of the car in front of you seems like it could be useful and is something humans can’t do very well.<p>I’ve always wanted a car that shows my speed and the relative speed (+&#x2F;-) of the car in front of me. My car’s cruise control can maintain a set distance so obviously it’s capable of it but it doesn’t show it.</div><br/><div id="41898782" class="c"><input type="checkbox" id="c-41898782" checked=""/><div class="controls bullet"><span class="by">dham</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889325">parent</a><span>|</span><a href="#41889494">next</a><span>|</span><label class="collapse" for="c-41898782">[-]</label><label class="expand" for="c-41898782">[2 more]</label></div><br/><div class="children"><div class="content">If your car is maintaining speed of the car in front then the car in front is going speed that is showing on your speedometer.</div><br/><div id="41901514" class="c"><input type="checkbox" id="c-41901514" checked=""/><div class="controls bullet"><span class="by">nkrisc</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41898782">parent</a><span>|</span><a href="#41889494">next</a><span>|</span><label class="collapse" for="c-41901514">[-]</label><label class="expand" for="c-41901514">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that’s true, but I don’t see how that relates to my comment at all.<p>I said the relative speed. If the car is going the same speed as me then the relative speed is 0mph. I want to see that when <i>I’m not</i> using cruise control.</div><br/></div></div></div></div></div></div><div id="41889494" class="c"><input type="checkbox" id="c-41889494" checked=""/><div class="controls bullet"><span class="by">SahAssar</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889167">parent</a><span>|</span><a href="#41889325">prev</a><span>|</span><a href="#41889132">next</a><span>|</span><label class="collapse" for="c-41889494">[-]</label><label class="expand" for="c-41889494">[2 more]</label></div><br/><div class="children"><div class="content">We are &quot;designed&quot; (via evolution) to perceive and understand the environment around us. The signage is designed to be easily readable for us.<p>The models that drive these cars clearly either have some more evolution to do or for us to design the world more to their liking.</div><br/><div id="41891086" class="c"><input type="checkbox" id="c-41891086" checked=""/><div class="controls bullet"><span class="by">hshshshshsh</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889494">parent</a><span>|</span><a href="#41889132">next</a><span>|</span><label class="collapse" for="c-41891086">[-]</label><label class="expand" for="c-41891086">[1 more]</label></div><br/><div class="children"><div class="content">Yes. I was talking why Tesla choose to use vision. Since they can&#x27;t control designing the transport infra to their liking at least for now.</div><br/></div></div></div></div></div></div><div id="41889132" class="c"><input type="checkbox" id="c-41889132" checked=""/><div class="controls bullet"><span class="by">plorg</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889061">parent</a><span>|</span><a href="#41889167">prev</a><span>|</span><a href="#41889125">next</a><span>|</span><label class="collapse" for="c-41889132">[-]</label><label class="expand" for="c-41889132">[1 more]</label></div><br/><div class="children"><div class="content">I would think one relevant factor is that human vision is different than and in some ways significantly better than cameras.</div><br/></div></div><div id="41889125" class="c"><input type="checkbox" id="c-41889125" checked=""/><div class="controls bullet"><span class="by">pmorici</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889061">parent</a><span>|</span><a href="#41889132">prev</a><span>|</span><a href="#41889188">next</a><span>|</span><label class="collapse" for="c-41889125">[-]</label><label class="expand" for="c-41889125">[3 more]</label></div><br/><div class="children"><div class="content">The Tesla knows when it&#x27;s cameras and blinded by sun and act accordingly or tells the human to take over.</div><br/><div id="41889303" class="c"><input type="checkbox" id="c-41889303" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889125">parent</a><span>|</span><a href="#41890912">next</a><span>|</span><label class="collapse" for="c-41889303">[-]</label><label class="expand" for="c-41889303">[1 more]</label></div><br/><div class="children"><div class="content">Expect when it doesn&#x27;t actually do that, I guess? Like when this pedestrian was killed?</div><br/></div></div><div id="41890912" class="c"><input type="checkbox" id="c-41890912" checked=""/><div class="controls bullet"><span class="by">eptcyka</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889125">parent</a><span>|</span><a href="#41889303">prev</a><span>|</span><a href="#41889188">next</a><span>|</span><label class="collapse" for="c-41890912">[-]</label><label class="expand" for="c-41890912">[1 more]</label></div><br/><div class="children"><div class="content">If we were able to know when a neural net is failing to categorize something, wouldn’t we get AGI for free?</div><br/></div></div></div></div></div></div><div id="41889188" class="c"><input type="checkbox" id="c-41889188" checked=""/><div class="controls bullet"><span class="by">jabroni_salad</span><span>|</span><a href="#41888998">parent</a><span>|</span><a href="#41889061">prev</a><span>|</span><a href="#41896741">next</a><span>|</span><label class="collapse" for="c-41889188">[-]</label><label class="expand" for="c-41889188">[4 more]</label></div><br/><div class="children"><div class="content">Negligence is negligence but people tend to view vehicle collisions as &quot;accidents&quot;, as in random occurrences dealt by the hand of fate completely outside of anyone&#x27;s control. As such, there is a chronic failure to charge motorists with negligence, even when they have killed someone.<p>If you end up in court, just ask for a jury and you&#x27;ll be okay. I&#x27;m pretty sure this guy didnt even go to court, sounds like it got prosecutor&#x27;s discretion.</div><br/><div id="41894320" class="c"><input type="checkbox" id="c-41894320" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889188">parent</a><span>|</span><a href="#41894052">next</a><span>|</span><label class="collapse" for="c-41894320">[-]</label><label class="expand" for="c-41894320">[2 more]</label></div><br/><div class="children"><div class="content">That sounds like the justice system living up to its ideals. If the 12 jurors know they would have done the same in your situation, as would their family and friends, then they can&#x27;t in good conscience convict you for negligence.</div><br/><div id="41896775" class="c"><input type="checkbox" id="c-41896775" checked=""/><div class="controls bullet"><span class="by">pessimizer</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41894320">parent</a><span>|</span><a href="#41894052">next</a><span>|</span><label class="collapse" for="c-41896775">[-]</label><label class="expand" for="c-41896775">[1 more]</label></div><br/><div class="children"><div class="content">It sounds like the kind of narcissism that perverts justice. People understand things they could see themselves doing, don&#x27;t understand things that they can&#x27;t see themselves doing, and disregard the law entirely. It makes non-doctors and non-engineers incapable of judging doctors and engineers, rich people incapable of judging poor people, and poor people incapable of judging rich people.<p>It&#x27;s just a variation of letting off the defendant that looks like your kid, or brutalizing someone whose victim looks like your kid, it&#x27;s no ideal of justice.</div><br/></div></div></div></div><div id="41894052" class="c"><input type="checkbox" id="c-41894052" checked=""/><div class="controls bullet"><span class="by">sokoloff</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889188">parent</a><span>|</span><a href="#41894320">prev</a><span>|</span><a href="#41896741">next</a><span>|</span><label class="collapse" for="c-41894052">[-]</label><label class="expand" for="c-41894052">[1 more]</label></div><br/><div class="children"><div class="content">Negligence is the failure to act with the level of care that a reasonable person would exercise in a similar situation; if a reasonable person likely would have done the things that led to that person’s death, they’re not guilty of negligence.</div><br/></div></div></div></div><div id="41896741" class="c"><input type="checkbox" id="c-41896741" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41888998">parent</a><span>|</span><a href="#41889188">prev</a><span>|</span><a href="#41889026">next</a><span>|</span><label class="collapse" for="c-41896741">[-]</label><label class="expand" for="c-41896741">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m genuinely not sure what the answer is.<p>When you&#x27;re driving directly in the direction of a setting sun, polarized sunglasses won&#x27;t help you at all. That&#x27;s what sun visors are for, but they won&#x27;t always work if you&#x27;re short, and can block too much of the environment if you&#x27;re too tall.<p>The only truly safe answer is really to pull to the side of the road and wait for the sun to set. But in my life I&#x27;ve never seen anybody do that ever, and it would absolutely wreck traffic with little jams all over the city that would cascade.</div><br/><div id="41896922" class="c"><input type="checkbox" id="c-41896922" checked=""/><div class="controls bullet"><span class="by">kjkjadksj</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41896741">parent</a><span>|</span><a href="#41889026">next</a><span>|</span><label class="collapse" for="c-41896922">[-]</label><label class="expand" for="c-41896922">[5 more]</label></div><br/><div class="children"><div class="content">No, polarized sunglasses work fine. I drive into a setting sun probably once a week to no incident.</div><br/><div id="41897216" class="c"><input type="checkbox" id="c-41897216" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41896922">parent</a><span>|</span><a href="#41889026">next</a><span>|</span><label class="collapse" for="c-41897216">[-]</label><label class="expand" for="c-41897216">[4 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t make any sense to me.<p>First of all, polarization is irrelevant when looking at the sun. It only affects light that is <i>reflected</i> off things like other cars&#x27; windows, or water on the street. In fact, it&#x27;s often recommended <i>not</i> to use polarized sunglasses while driving because you can miss wet or icy patches on the road.<p>Secondly, standard sunglasses don&#x27;t let you look directly at the sun, even a setting one. The sun is still dangerously bright.</div><br/><div id="41898007" class="c"><input type="checkbox" id="c-41898007" checked=""/><div class="controls bullet"><span class="by">kjkjadksj</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41897216">parent</a><span>|</span><a href="#41889026">next</a><span>|</span><label class="collapse" for="c-41898007">[-]</label><label class="expand" for="c-41898007">[3 more]</label></div><br/><div class="children"><div class="content">I’m not looking directly at the sun I am looking at the road. Either way it makes a big difference and you don’t get much black ice here in sunny southern california.</div><br/><div id="41898455" class="c"><input type="checkbox" id="c-41898455" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41898007">parent</a><span>|</span><a href="#41889026">next</a><span>|</span><label class="collapse" for="c-41898455">[-]</label><label class="expand" for="c-41898455">[2 more]</label></div><br/><div class="children"><div class="content">But the scenario we&#x27;re talking about is when the sun is just a few degrees away from the road. It&#x27;s still entering your eyeball directly. It&#x27;s still literally blinding, so I just... don&#x27;t understand how you can do that? Like, I certainly can&#x27;t. Sunglasses -- polarized or otherwise -- don&#x27;t make the slightest difference. It&#x27;s why sun visors exist.<p>Also, I&#x27;m assuming you get rain in SoCal at least sometimes, that then mostly dries up but not completely? Or leaking fire hydrants and so forth? It&#x27;s the unexpected wet patches.</div><br/><div id="41899626" class="c"><input type="checkbox" id="c-41899626" checked=""/><div class="controls bullet"><span class="by">kjkjadksj</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41898455">parent</a><span>|</span><a href="#41889026">next</a><span>|</span><label class="collapse" for="c-41899626">[-]</label><label class="expand" for="c-41899626">[1 more]</label></div><br/><div class="children"><div class="content">When we get rain in socal its a deluge. The first couple months of 2024 we had more rain than seattle. That being said there is a big difference wearing sunglasses and not. Actually I was in a parking garage today and thought of this very thread, because the sun was shining on the cement ground through the side and was literally blinding. To my naked eye it was like a blown out photograph, just pure light on the ground. I put the  sunglasses on that were around my neck and what do you know. Not only did the glare go down it went down to the point I could now make out the little half rainbow streaks the cement pavers added to the floor. Same thing happens on our cement highways or when you get bad glare off of someones relatively freshly waxed car. I had a period of two weeks where I lost my polarized glasses and it was like I was disabled going outside in the day; I had to squint to even stand it because of how many white painted or cement surfaces we have here in socal. I grew up in the midwest where I did not really own sunglasses at all fwiw. Here it is mandatory for the amount of unclouded sunlight coupled with the usually white or light grey surface treatment on a lot of things.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41889026" class="c"><input type="checkbox" id="c-41889026" checked=""/><div class="controls bullet"><span class="by">theossuary</span><span>|</span><a href="#41888998">parent</a><span>|</span><a href="#41896741">prev</a><span>|</span><a href="#41891582">next</a><span>|</span><label class="collapse" for="c-41889026">[-]</label><label class="expand" for="c-41889026">[3 more]</label></div><br/><div class="children"><div class="content">You know what they say, if you want to kill someone in the US, do it in a car.</div><br/><div id="41889060" class="c"><input type="checkbox" id="c-41889060" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889026">parent</a><span>|</span><a href="#41890196">next</a><span>|</span><label class="collapse" for="c-41889060">[-]</label><label class="expand" for="c-41889060">[1 more]</label></div><br/><div class="children"><div class="content"><i>Crash Course: If You Want to Get Away With Murder Buy a Car</i> 
Woodrow Phoenix</div><br/></div></div><div id="41890196" class="c"><input type="checkbox" id="c-41890196" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889026">parent</a><span>|</span><a href="#41889060">prev</a><span>|</span><a href="#41891582">next</a><span>|</span><label class="collapse" for="c-41890196">[-]</label><label class="expand" for="c-41890196">[1 more]</label></div><br/><div class="children"><div class="content">In the US it seems you&#x27;d do it with a gun, but in Germany it&#x27;s cars.<p>There was this elderly driver who mowed down a family in a bike lane waiting to cross the road in Berlin, driving over the barriers between the bike lane and the car lane because the cars in the car lane were too slow. Released without conviction - it was an unforeseeable accident.</div><br/></div></div></div></div><div id="41891582" class="c"><input type="checkbox" id="c-41891582" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#41888998">parent</a><span>|</span><a href="#41889026">prev</a><span>|</span><a href="#41889033">next</a><span>|</span><label class="collapse" for="c-41891582">[-]</label><label class="expand" for="c-41891582">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I have a couple of mirrors placed around my car that reflect light into my face so that I can get out of running into someone. Tbh I understand why they do this. Someone on HN explained it to me: Yield to gross tonnage. So I just drive where I want. If other people die, that’s on them: the graveyards are full of people with the right of way, as people say.</div><br/></div></div><div id="41889033" class="c"><input type="checkbox" id="c-41889033" checked=""/><div class="controls bullet"><span class="by">macintux</span><span>|</span><a href="#41888998">parent</a><span>|</span><a href="#41891582">prev</a><span>|</span><a href="#41895040">next</a><span>|</span><label class="collapse" for="c-41889033">[-]</label><label class="expand" for="c-41889033">[9 more]</label></div><br/><div class="children"><div class="content">I have no idea what the conditions were like for this incident, but I’ve blown through a 4-way stop sign when the sun was setting. There’s only so much sunglasses can do.</div><br/><div id="41889072" class="c"><input type="checkbox" id="c-41889072" checked=""/><div class="controls bullet"><span class="by">eptcyka</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889033">parent</a><span>|</span><a href="#41894249">next</a><span>|</span><label class="collapse" for="c-41889072">[-]</label><label class="expand" for="c-41889072">[1 more]</label></div><br/><div class="children"><div class="content">If environmental factors incapacitate you, should you not slow down or stop?</div><br/></div></div><div id="41894249" class="c"><input type="checkbox" id="c-41894249" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889033">parent</a><span>|</span><a href="#41889072">prev</a><span>|</span><a href="#41890072">next</a><span>|</span><label class="collapse" for="c-41894249">[-]</label><label class="expand" for="c-41894249">[1 more]</label></div><br/><div class="children"><div class="content">Your license should be suspended.  If conditions don&#x27;t allow you to see things like that, you slow down until you can.  If you still can&#x27;t, then you need to pull over and wait until conditions make it safe to drive again.<p>Gross.</div><br/></div></div><div id="41890072" class="c"><input type="checkbox" id="c-41890072" checked=""/><div class="controls bullet"><span class="by">singleshot_</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889033">parent</a><span>|</span><a href="#41894249">prev</a><span>|</span><a href="#41889130">next</a><span>|</span><label class="collapse" for="c-41890072">[-]</label><label class="expand" for="c-41890072">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There’s only so much sunglasses can do.<p>For everything else, you have brakes.</div><br/></div></div><div id="41889130" class="c"><input type="checkbox" id="c-41889130" checked=""/><div class="controls bullet"><span class="by">alexjplant</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889033">parent</a><span>|</span><a href="#41890072">prev</a><span>|</span><a href="#41889438">next</a><span>|</span><label class="collapse" for="c-41889130">[-]</label><label class="expand" for="c-41889130">[1 more]</label></div><br/><div class="children"><div class="content">¯\_(ツ)_&#x2F;¯ If I can&#x27;t see because of rain, hail, intense sun reflections, frost re-forming on my windshield, etc. then I pull over and put my flashers on until the problem subsides. Should I have kept the 4700 lb vehicle in fifth gear at 55 mph without the ability to see in front of me in each of these instances? I submit that I should not have and that I did the right thing.</div><br/></div></div><div id="41889438" class="c"><input type="checkbox" id="c-41889438" checked=""/><div class="controls bullet"><span class="by">ablation</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889033">parent</a><span>|</span><a href="#41889130">prev</a><span>|</span><a href="#41889776">next</a><span>|</span><label class="collapse" for="c-41889438">[-]</label><label class="expand" for="c-41889438">[1 more]</label></div><br/><div class="children"><div class="content">Yet so much more YOU could have done, don’t you think?</div><br/></div></div><div id="41889776" class="c"><input type="checkbox" id="c-41889776" checked=""/><div class="controls bullet"><span class="by">Doctor_Fegg</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889033">parent</a><span>|</span><a href="#41889438">prev</a><span>|</span><a href="#41889126">next</a><span>|</span><label class="collapse" for="c-41889776">[-]</label><label class="expand" for="c-41889776">[1 more]</label></div><br/><div class="children"><div class="content">Yes, officer, this one right here.</div><br/></div></div><div id="41889126" class="c"><input type="checkbox" id="c-41889126" checked=""/><div class="controls bullet"><span class="by">vortegne</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889033">parent</a><span>|</span><a href="#41889776">prev</a><span>|</span><a href="#41892591">next</a><span>|</span><label class="collapse" for="c-41889126">[-]</label><label class="expand" for="c-41889126">[1 more]</label></div><br/><div class="children"><div class="content">You shouldn&#x27;t be on the road then? If you can&#x27;t see, you should slow down. If you can&#x27;t handle driving in given conditions safely for everyone involved, you should slow down or stop. If everybody would drive like you, there&#x27;d be a whole lot more death on the roads.</div><br/></div></div><div id="41892591" class="c"><input type="checkbox" id="c-41892591" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#41888998">root</a><span>|</span><a href="#41889033">parent</a><span>|</span><a href="#41889126">prev</a><span>|</span><a href="#41895040">next</a><span>|</span><label class="collapse" for="c-41892591">[-]</label><label class="expand" for="c-41892591">[1 more]</label></div><br/><div class="children"><div class="content">I know right? Once I got something in my eye so I couldn&#x27;t see at all, but I decided that since I couldn&#x27;t do anything about it the best thing was to keep driving. I killed a few pedestrians but... eh, what was I going to do?</div><br/></div></div></div></div></div></div><div id="41895040" class="c"><input type="checkbox" id="c-41895040" checked=""/><div class="controls bullet"><span class="by">InsomniacL</span><span>|</span><a href="#41888998">prev</a><span>|</span><a href="#41889014">next</a><span>|</span><label class="collapse" for="c-41895040">[-]</label><label class="expand" for="c-41895040">[4 more]</label></div><br/><div class="children"><div class="content">As I come over the top of a crest, there was suddenly a lot of sun glare and the my Model Y violently swerved to the left, fortunately I had just overtaken a car on a two lane, dual carriageway and hadn&#x27;t moved back to the left hand lane yet.<p>The driver I had just overtaken, although he wasn&#x27;t very close anymore slowed right down to get away from me and I didn&#x27;t blame him.<p>That manoeuvre in another car likely would have put it on two wheels.<p>They say FSD crashes less often than a human per mile driven, but I can only use FSD on roads like motorways, so I don&#x27;t think it&#x27;s a fair comparison.<p>I don&#x27;t trust FSD, I still use it occasionally but never in less than ideal conditions. Typically when doing something like changing the music on a motorway.<p>It probably is safer than just me driving alone, when it&#x27;s in good conditions on a straight road with light traffic with an alert driver.</div><br/><div id="41895063" class="c"><input type="checkbox" id="c-41895063" checked=""/><div class="controls bullet"><span class="by">mglz</span><span>|</span><a href="#41895040">parent</a><span>|</span><a href="#41899469">next</a><span>|</span><label class="collapse" for="c-41895063">[-]</label><label class="expand" for="c-41895063">[2 more]</label></div><br/><div class="children"><div class="content">The underlying problem is that the current FSD architecture doesn&#x27;t seem to have good guard rails for these outlier situations you describe (sunlight blinding the camera from just the right angle probably?) and it is probably not possible to add such rules without limiting the system enormously.<p>Fundamentally driving consists of a set of fairly clear cut rules with a ridiculous amount of &quot;it depends&quot; cases.</div><br/><div id="41899486" class="c"><input type="checkbox" id="c-41899486" checked=""/><div class="controls bullet"><span class="by">iknowstuff</span><span>|</span><a href="#41895040">root</a><span>|</span><a href="#41895063">parent</a><span>|</span><a href="#41899469">next</a><span>|</span><label class="collapse" for="c-41899486">[-]</label><label class="expand" for="c-41899486">[1 more]</label></div><br/><div class="children"><div class="content">it actually does. he’s in europe, on a 5 year old autopilot, basically.<p>current fsd uses a multiexposure camera feed so its not really much susceptible to sun glare.</div><br/></div></div></div></div><div id="41899469" class="c"><input type="checkbox" id="c-41899469" checked=""/><div class="controls bullet"><span class="by">iknowstuff</span><span>|</span><a href="#41895040">parent</a><span>|</span><a href="#41895063">prev</a><span>|</span><a href="#41889014">next</a><span>|</span><label class="collapse" for="c-41899469">[-]</label><label class="expand" for="c-41899469">[1 more]</label></div><br/><div class="children"><div class="content">what do you mean you can only use fsd on motorways? Just by phrasing I assume you’re referring to the old FSD which is just beefed up autopilot based on heuristics - europe is stuck on a gimped 5 year old autopilot stack due to overzealous regulation.<p>American FSD is a completely different beast, usable on every road and street, so your anecdote is actually not relevant to the thread</div><br/></div></div></div></div><div id="41889014" class="c"><input type="checkbox" id="c-41889014" checked=""/><div class="controls bullet"><span class="by">rKarpinski</span><span>|</span><a href="#41895040">prev</a><span>|</span><a href="#41885410">next</a><span>|</span><label class="collapse" for="c-41889014">[-]</label><label class="expand" for="c-41889014">[39 more]</label></div><br/><div class="children"><div class="content">&#x27;Pedestrian&#x27; in this context seems pretty misleading<p>&quot;Two vehicles collided on the freeway, blocking the left lane. A Toyota 4Runner stopped, and two people got out to help with traffic control. A red Tesla Model Y then hit the 4Runner and one of the people who exited from it. &quot;<p>edit: Parent article was changed... I was referring to the title of the NPR article.</div><br/><div id="41889087" class="c"><input type="checkbox" id="c-41889087" checked=""/><div class="controls bullet"><span class="by">danans</span><span>|</span><a href="#41889014">parent</a><span>|</span><a href="#41889049">next</a><span>|</span><label class="collapse" for="c-41889087">[-]</label><label class="expand" for="c-41889087">[10 more]</label></div><br/><div class="children"><div class="content">&gt; Pedestrian&#x27; in this context seems pretty misleading<p>What&#x27;s misleading? The full quote:<p>&quot;A red Tesla Model Y then <i>hit the 4Runner and one of the people who exited from it</i>. A 71-year-old woman from Mesa, Arizona, was pronounced dead at the scene.&quot;<p>If you exit a vehicle, and are on foot, you are a pedestrian.<p>I wouldn&#x27;t expect FSD&#x27;s object recognition system to treat a human who has just exited a car differently than a human walking across a crosswalk.  A human on foot is a human on foot.<p>However, from the sound of it, the object recognition system didn&#x27;t even see the 4Runner, much less a person, so perhaps there&#x27;s a more fundamental problem with it?<p>Perhaps this is something that lidar or radar, if the car had them, would have helped the OR system to see.</div><br/><div id="41889174" class="c"><input type="checkbox" id="c-41889174" checked=""/><div class="controls bullet"><span class="by">jfoster</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889087">parent</a><span>|</span><a href="#41889724">next</a><span>|</span><label class="collapse" for="c-41889174">[-]</label><label class="expand" for="c-41889174">[7 more]</label></div><br/><div class="children"><div class="content">The description has me wondering if this was definitely a case where FSD was being used. There have been other cases in the past where drivers had an accident and claimed they were using autopilot when they actually were not.<p>I don&#x27;t know for sure, but I would think that the car could detect a collision. I also don&#x27;t know for sure, but I would think that FSD would stop once a collision has been detected.</div><br/><div id="41889332" class="c"><input type="checkbox" id="c-41889332" checked=""/><div class="controls bullet"><span class="by">pell</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889174">parent</a><span>|</span><a href="#41889576">next</a><span>|</span><label class="collapse" for="c-41889332">[-]</label><label class="expand" for="c-41889332">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There have been other cases in the past where drivers had an accident and claimed they were using autopilot when they actually were not.<p>Wouldn’t this be protocoled by the event data recorder?</div><br/></div></div><div id="41889576" class="c"><input type="checkbox" id="c-41889576" checked=""/><div class="controls bullet"><span class="by">danans</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889174">parent</a><span>|</span><a href="#41889332">prev</a><span>|</span><a href="#41889296">next</a><span>|</span><label class="collapse" for="c-41889576">[-]</label><label class="expand" for="c-41889576">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There have been other cases in the past where drivers had an accident and claimed they were using autopilot when they actually were not.<p>If that were the case here, there wouldn&#x27;t be a government probe, right?  It would be a normal &quot;multi car pileup with a fatality&quot; and added to statistics.<p>With the strong incentive on the part of both the driver and Tesla to lie about this,  there should strong regulations around event data recorders [1] for self driving systems, and huge penalties for violating those.   A search across that site doesn&#x27;t return a hit for the word &quot;retention&quot; but it&#x27;s gotta be expressed in some way there.<p>1. <a href="https:&#x2F;&#x2F;www.ecfr.gov&#x2F;current&#x2F;title-49&#x2F;subtitle-B&#x2F;chapter-V&#x2F;part-563" rel="nofollow">https:&#x2F;&#x2F;www.ecfr.gov&#x2F;current&#x2F;title-49&#x2F;subtitle-B&#x2F;chapter-V&#x2F;p...</a></div><br/></div></div><div id="41889296" class="c"><input type="checkbox" id="c-41889296" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889174">parent</a><span>|</span><a href="#41889576">prev</a><span>|</span><a href="#41889223">next</a><span>|</span><label class="collapse" for="c-41889296">[-]</label><label class="expand" for="c-41889296">[2 more]</label></div><br/><div class="children"><div class="content">&gt; FSD would stop once a collision has been detected.<p>Fun fact, at least until very recently, if not even to this moment, AEB (emergency braking) is not a part of FSD.</div><br/><div id="41891537" class="c"><input type="checkbox" id="c-41891537" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889296">parent</a><span>|</span><a href="#41889223">next</a><span>|</span><label class="collapse" for="c-41891537">[-]</label><label class="expand" for="c-41891537">[1 more]</label></div><br/><div class="children"><div class="content">I believe AEB can trigger even while FSD is active. Certainly I have seen the forward collision warning trigger during FSD.</div><br/></div></div></div></div><div id="41889223" class="c"><input type="checkbox" id="c-41889223" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889174">parent</a><span>|</span><a href="#41889296">prev</a><span>|</span><a href="#41889724">next</a><span>|</span><label class="collapse" for="c-41889223">[-]</label><label class="expand" for="c-41889223">[2 more]</label></div><br/><div class="children"><div class="content">Did the article say the Tesla didn&#x27;t stop after the collision?</div><br/><div id="41889343" class="c"><input type="checkbox" id="c-41889343" checked=""/><div class="controls bullet"><span class="by">jfoster</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889223">parent</a><span>|</span><a href="#41889724">next</a><span>|</span><label class="collapse" for="c-41889343">[-]</label><label class="expand" for="c-41889343">[1 more]</label></div><br/><div class="children"><div class="content">If it hit the vehicle and then hit one of the people who had exited the vehicle with enough force for it to result in a fatality, it sounds like it might not have applied any braking.<p>Of course, that depends on the speed it was traveling at to begin with.</div><br/></div></div></div></div></div></div><div id="41889724" class="c"><input type="checkbox" id="c-41889724" checked=""/><div class="controls bullet"><span class="by">potato3732842</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889087">parent</a><span>|</span><a href="#41889174">prev</a><span>|</span><a href="#41889116">next</a><span>|</span><label class="collapse" for="c-41889724">[-]</label><label class="expand" for="c-41889724">[1 more]</label></div><br/><div class="children"><div class="content">Tesla&#x27;s were famously poor at detecting partial lane obstructions for a long time.  I wonder if that&#x27;s what happened here.</div><br/></div></div></div></div><div id="41889049" class="c"><input type="checkbox" id="c-41889049" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#41889014">parent</a><span>|</span><a href="#41889087">prev</a><span>|</span><a href="#41889056">next</a><span>|</span><label class="collapse" for="c-41889049">[-]</label><label class="expand" for="c-41889049">[19 more]</label></div><br/><div class="children"><div class="content">More clarity may change people’s opinion of the accident, but IMO pedestrian meaningfully represents someone who is limited to human locomotion and lacks any sort of protection in a collision.<p>Which seems like a reasonable description of the type of failure involved in the final few seconds before impact.</div><br/><div id="41889482" class="c"><input type="checkbox" id="c-41889482" checked=""/><div class="controls bullet"><span class="by">rKarpinski</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889049">parent</a><span>|</span><a href="#41890039">next</a><span>|</span><label class="collapse" for="c-41889482">[-]</label><label class="expand" for="c-41889482">[10 more]</label></div><br/><div class="children"><div class="content">Omitting that the pedestrian was on a freeway meaningfully mis-represents the situation.</div><br/><div id="41890503" class="c"><input type="checkbox" id="c-41890503" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889482">parent</a><span>|</span><a href="#41894022">next</a><span>|</span><label class="collapse" for="c-41890503">[-]</label><label class="expand" for="c-41890503">[7 more]</label></div><br/><div class="children"><div class="content">People walking on freeways may be rare from the perspective of an individual driver but not a self driving system operating on millions of vehicles.</div><br/><div id="41890663" class="c"><input type="checkbox" id="c-41890663" checked=""/><div class="controls bullet"><span class="by">rKarpinski</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41890503">parent</a><span>|</span><a href="#41894022">next</a><span>|</span><label class="collapse" for="c-41890663">[-]</label><label class="expand" for="c-41890663">[6 more]</label></div><br/><div class="children"><div class="content">What does that have to do with the original article&#x27;s misleading title?</div><br/><div id="41890810" class="c"><input type="checkbox" id="c-41890810" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41890663">parent</a><span>|</span><a href="#41894022">next</a><span>|</span><label class="collapse" for="c-41890810">[-]</label><label class="expand" for="c-41890810">[5 more]</label></div><br/><div class="children"><div class="content">I don’t think it’s misleading.  It’s a tile not some hundred word description of what exactly happened.<p>Calling them motorists would definitely be misleading by comparison. Using the simple “fatal crash” of the linked title  implies the other people might in be responsible which is misleading.<p>Using accident but saying Tesla was at fault could open them up to liability and therefore isn’t an option.</div><br/><div id="41890974" class="c"><input type="checkbox" id="c-41890974" checked=""/><div class="controls bullet"><span class="by">rKarpinski</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41890810">parent</a><span>|</span><a href="#41894022">next</a><span>|</span><label class="collapse" for="c-41890974">[-]</label><label class="expand" for="c-41890974">[4 more]</label></div><br/><div class="children"><div class="content">&gt; I don’t think it’s misleading. It’s a tile not some hundred word description of what exactly happened.<p>&quot;Pedestrian killed on freeway&quot; instead of &quot;pedestrian killed&quot; doesn&#x27;t take 100 words and doesn&#x27;t give the impression Tesla&#x27;s are mowing people down on crosswalks (although that&#x27;s a feature to get clicks, not a bug).</div><br/><div id="41890979" class="c"><input type="checkbox" id="c-41890979" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41890974">parent</a><span>|</span><a href="#41894022">next</a><span>|</span><label class="collapse" for="c-41890979">[-]</label><label class="expand" for="c-41890979">[3 more]</label></div><br/><div class="children"><div class="content">Without context that implies the pedestrians shouldn’t have been on the freeway.<p>It’s not an issue for Tesla, but it does imply bad things about the victims.</div><br/><div id="41891136" class="c"><input type="checkbox" id="c-41891136" checked=""/><div class="controls bullet"><span class="by">rKarpinski</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41890979">parent</a><span>|</span><a href="#41894022">next</a><span>|</span><label class="collapse" for="c-41891136">[-]</label><label class="expand" for="c-41891136">[2 more]</label></div><br/><div class="children"><div class="content">A title of &quot;U.S. to probe Tesla&#x27;s &#x27;Full Self-Driving&#x27; system after pedestrian killed on freeway&quot; would in no way imply bad things about the pedestrian who was killed.</div><br/><div id="41891642" class="c"><input type="checkbox" id="c-41891642" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41891136">parent</a><span>|</span><a href="#41894022">next</a><span>|</span><label class="collapse" for="c-41891642">[-]</label><label class="expand" for="c-41891642">[1 more]</label></div><br/><div class="children"><div class="content">It was my first assumption when I was read pedestrian on freeway in someone’s comment without context.  Possibly due to Uber self driving fatality.<p>Stranded motorists who exit their vehicle, construction workers, first responders, tow truck drivers, etc are the most common victims but that’s not the association I had.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="41894022" class="c"><input type="checkbox" id="c-41894022" checked=""/><div class="controls bullet"><span class="by">nkrisc</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889482">parent</a><span>|</span><a href="#41890503">prev</a><span>|</span><a href="#41893497">next</a><span>|</span><label class="collapse" for="c-41894022">[-]</label><label class="expand" for="c-41894022">[1 more]</label></div><br/><div class="children"><div class="content">No, you’re not allowed to hit pedestrians on the freeway either.<p>There are many reasons why a pedestrian might be on the freeway. It’s not common but I see it at least once a month and I drive extra carefully when I do, moving over if I can and slowing down.</div><br/></div></div><div id="41893497" class="c"><input type="checkbox" id="c-41893497" checked=""/><div class="controls bullet"><span class="by">Arn_Thor</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889482">parent</a><span>|</span><a href="#41894022">prev</a><span>|</span><a href="#41890039">next</a><span>|</span><label class="collapse" for="c-41893497">[-]</label><label class="expand" for="c-41893497">[1 more]</label></div><br/><div class="children"><div class="content">Why? I would hope we all expect pedestrian detection (and object detection in general) to be just as good on a freeway as on a city street? It seems the Tesla barreled full-speed into an accident ahead of it. I would call it insane but that would be anthropomorphizing it.</div><br/></div></div></div></div><div id="41889710" class="c"><input type="checkbox" id="c-41889710" checked=""/><div class="controls bullet"><span class="by">potato3732842</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889049">parent</a><span>|</span><a href="#41890039">prev</a><span>|</span><a href="#41889121">next</a><span>|</span><label class="collapse" for="c-41889710">[-]</label><label class="expand" for="c-41889710">[6 more]</label></div><br/><div class="children"><div class="content">This sort of framing you&#x27;re engaging in is exactly what the person you&#x27;re replying to is complaining about.<p>Yeah, the person who got hit was technically a pedestrian but just using that word with no other context doesn&#x27;t covey that it was a pedestrian on a limited access highway vs somewhere pedestrians are allowed and expected.  Without additional explanation people assume normalcy and think that the pedestrian was crossing a city street or something pedestrians do all the time and are expected to do all the time when that is very much not what happened here.</div><br/><div id="41890469" class="c"><input type="checkbox" id="c-41890469" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889710">parent</a><span>|</span><a href="#41889121">next</a><span>|</span><label class="collapse" for="c-41890469">[-]</label><label class="expand" for="c-41890469">[5 more]</label></div><br/><div class="children"><div class="content">Dealing with people on freeways is the kind of edge case humans aren’t good at but self driving cars have zero excuses.  It’s a common enough situation that someone will exit a vehicle after a collision to make it a very predictable edge case.<p>Remember all of the bad press Uber got when a pedestrian was struck and killed walking their bike across the middle of a street at night?  People are going to be on limited access freeways and these systems need to be able to deal with it.  <a href="https:&#x2F;&#x2F;www.bbc.com&#x2F;news&#x2F;technology-54175359" rel="nofollow">https:&#x2F;&#x2F;www.bbc.com&#x2F;news&#x2F;technology-54175359</a></div><br/><div id="41891388" class="c"><input type="checkbox" id="c-41891388" checked=""/><div class="controls bullet"><span class="by">potato3732842</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41890469">parent</a><span>|</span><a href="#41891405">next</a><span>|</span><label class="collapse" for="c-41891388">[-]</label><label class="expand" for="c-41891388">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d make the argument that people are very good at dealing with random things that shouldn&#x27;t be on freeways as long as they don&#x27;t coincide with blinding sun or other visual impairment.<p>Tesla had a long standing issue detecting partial lane obstructions. I wonder if the logic around that has anything to do with this.</div><br/><div id="41891810" class="c"><input type="checkbox" id="c-41891810" checked=""/><div class="controls bullet"><span class="by">Retric</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41891388">parent</a><span>|</span><a href="#41891405">next</a><span>|</span><label class="collapse" for="c-41891810">[-]</label><label class="expand" for="c-41891810">[2 more]</label></div><br/><div class="children"><div class="content">17 percent of pedestrian fatalities occur on freeways. Considering how rarely pedestrians are on freeways that suggests to me people aren’t very good at noticing them in time to stop &#x2F; avoid them.<p><a href="https:&#x2F;&#x2F;usa.streetsblog.org&#x2F;2022&#x2F;06&#x2F;09&#x2F;why-20-of-pedestrians-deaths-are-on-freeways-and-how-we-stop-that" rel="nofollow">https:&#x2F;&#x2F;usa.streetsblog.org&#x2F;2022&#x2F;06&#x2F;09&#x2F;why-20-of-pedestrians...</a></div><br/><div id="41893502" class="c"><input type="checkbox" id="c-41893502" checked=""/><div class="controls bullet"><span class="by">Arn_Thor</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41891810">parent</a><span>|</span><a href="#41891405">next</a><span>|</span><label class="collapse" for="c-41893502">[-]</label><label class="expand" for="c-41893502">[1 more]</label></div><br/><div class="children"><div class="content">That, and&#x2F;or freeway speeds make the situation inherently more dangerous. When the traffic flows freeway speeds are fine but if a freeway-speed car has to handle a stationary object…problem.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41889056" class="c"><input type="checkbox" id="c-41889056" checked=""/><div class="controls bullet"><span class="by">neom</span><span>|</span><a href="#41889014">parent</a><span>|</span><a href="#41889049">prev</a><span>|</span><a href="#41885410">next</a><span>|</span><label class="collapse" for="c-41889056">[-]</label><label class="expand" for="c-41889056">[9 more]</label></div><br/><div class="children"><div class="content">That is the correct use of pedestrian as a noun.</div><br/><div id="41889079" class="c"><input type="checkbox" id="c-41889079" checked=""/><div class="controls bullet"><span class="by">echoangle</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889056">parent</a><span>|</span><a href="#41889081">next</a><span>|</span><label class="collapse" for="c-41889079">[-]</label><label class="expand" for="c-41889079">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes using a word correctly is still confusing because it’s used in a different context 90% of the time.</div><br/></div></div><div id="41889081" class="c"><input type="checkbox" id="c-41889081" checked=""/><div class="controls bullet"><span class="by">szundi</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889056">parent</a><span>|</span><a href="#41889079">prev</a><span>|</span><a href="#41889154">next</a><span>|</span><label class="collapse" for="c-41889081">[-]</label><label class="expand" for="c-41889081">[2 more]</label></div><br/><div class="children"><div class="content">I think parent commenter emphasized the context.<p>Leaving out context that would otherwise change the interpretation of most or targeted people is the main way to misled those people without technically lying.</div><br/><div id="41889153" class="c"><input type="checkbox" id="c-41889153" checked=""/><div class="controls bullet"><span class="by">neom</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889081">parent</a><span>|</span><a href="#41889154">next</a><span>|</span><label class="collapse" for="c-41889153">[-]</label><label class="expand" for="c-41889153">[1 more]</label></div><br/><div class="children"><div class="content">I mean it&#x27;s the literal language they use in the report[1]. Personally, would much prefer a publication to be technically correct, a person on foot on a motorway is referred to as a pedestrian, that is the name for that.<p>[1]<a href="https:&#x2F;&#x2F;static.nhtsa.gov&#x2F;odi&#x2F;inv&#x2F;2024&#x2F;INOA-PE24031-23232.pdf" rel="nofollow">https:&#x2F;&#x2F;static.nhtsa.gov&#x2F;odi&#x2F;inv&#x2F;2024&#x2F;INOA-PE24031-23232.pdf</a></div><br/></div></div></div></div><div id="41889154" class="c"><input type="checkbox" id="c-41889154" checked=""/><div class="controls bullet"><span class="by">varenc</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889056">parent</a><span>|</span><a href="#41889081">prev</a><span>|</span><a href="#41890485">next</a><span>|</span><label class="collapse" for="c-41889154">[-]</label><label class="expand" for="c-41889154">[3 more]</label></div><br/><div class="children"><div class="content">By a stricter definition, a pedestrian is one who <i>travels</i> by foot. Of course, they are walking, but they’re traveling via their car, so by some interpretations you wouldn’t call them a pedestrian. You could call them a “motorist” or a “stranded vehicle occupant”.<p>For understanding the accident it does seem meaningful that they were motorists that got out of their car on a highway and not pedestrians at a street crossing. (Still inexcusable of course, but changes the context)</div><br/><div id="41889232" class="c"><input type="checkbox" id="c-41889232" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889154">parent</a><span>|</span><a href="#41889330">next</a><span>|</span><label class="collapse" for="c-41889232">[-]</label><label class="expand" for="c-41889232">[1 more]</label></div><br/><div class="children"><div class="content">Cars and drivers ideally shouldn&#x27;t hit people who exited their vehicles after an accident on a highway. Identifying and avoiding hazards is part of driving.</div><br/></div></div><div id="41889330" class="c"><input type="checkbox" id="c-41889330" checked=""/><div class="controls bullet"><span class="by">neom</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889154">parent</a><span>|</span><a href="#41889232">prev</a><span>|</span><a href="#41890485">next</a><span>|</span><label class="collapse" for="c-41889330">[-]</label><label class="expand" for="c-41889330">[1 more]</label></div><br/><div class="children"><div class="content">As far as I am aware, pes doesn&#x27;t carry an inherent meaning of travel. Pedestrian just means foot on, they don&#x27;t need to be moving, they&#x27;re just not in carriage. As an aside, distinguishing a person&#x27;s mode of presence is precisely what reports aim to capture.<p>(I also do tend to avoid this level of pedantry, the points here are all well taken to be clear. I do think the original poster was fine in their comment, I was just sayin&#x27; - but this isn&#x27;t a cross I would die on :))</div><br/></div></div></div></div><div id="41890485" class="c"><input type="checkbox" id="c-41890485" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#41889014">root</a><span>|</span><a href="#41889056">parent</a><span>|</span><a href="#41889154">prev</a><span>|</span><a href="#41889098">next</a><span>|</span><label class="collapse" for="c-41890485">[-]</label><label class="expand" for="c-41890485">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s why he said misleading rather than an outright lie. He is not disputing that it is techincally correct to refer to the deceased as a pedestrian, but this scenario (someone out of their car on a freeway) is not what is going to spring to the mind of someone just reading the headline.</div><br/></div></div></div></div></div></div><div id="41885410" class="c"><input type="checkbox" id="c-41885410" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#41889014">prev</a><span>|</span><a href="#41889190">next</a><span>|</span><label class="collapse" for="c-41885410">[-]</label><label class="expand" for="c-41885410">[38 more]</label></div><br/><div class="children"><div class="content">I&#x27;m astonished at how long Musk has been able to keep his autonomous driving con going. He has been lying about it to inflate Tesla shares for 10 years now.</div><br/><div id="41885430" class="c"><input type="checkbox" id="c-41885430" checked=""/><div class="controls bullet"><span class="by">ryandrake</span><span>|</span><a href="#41885410">parent</a><span>|</span><a href="#41894628">next</a><span>|</span><label class="collapse" for="c-41885430">[-]</label><label class="expand" for="c-41885430">[4 more]</label></div><br/><div class="children"><div class="content">Without consequences, there is no reason to stop.</div><br/><div id="41885438" class="c"><input type="checkbox" id="c-41885438" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41885430">parent</a><span>|</span><a href="#41894628">next</a><span>|</span><label class="collapse" for="c-41885438">[-]</label><label class="expand" for="c-41885438">[3 more]</label></div><br/><div class="children"><div class="content">When is the market going to realize Tesla is NEVER going to have real level 4 autonomy where Tesla takes legal liability for crashes the way Waymo has?</div><br/><div id="41885561" class="c"><input type="checkbox" id="c-41885561" checked=""/><div class="controls bullet"><span class="by">tstrimple</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41885438">parent</a><span>|</span><a href="#41886986">next</a><span>|</span><label class="collapse" for="c-41885561">[-]</label><label class="expand" for="c-41885561">[1 more]</label></div><br/><div class="children"><div class="content">Market cares far more about money than lives. Until the lives lost cost more than their profit, they give less than zero fucks. Capitalism. Yay!</div><br/></div></div></div></div></div></div><div id="41894628" class="c"><input type="checkbox" id="c-41894628" checked=""/><div class="controls bullet"><span class="by">heisenbit</span><span>|</span><a href="#41885410">parent</a><span>|</span><a href="#41885430">prev</a><span>|</span><a href="#41885487">next</a><span>|</span><label class="collapse" for="c-41894628">[-]</label><label class="expand" for="c-41894628">[1 more]</label></div><br/><div class="children"><div class="content">&quot;I&#x27;m a technologist, I know a lot about computers,&quot; Musk told the crowd during the event. &quot;And I&#x27;m like, the last thing I would do is trust a computer program, because it&#x27;s just too easy to hack.&quot;</div><br/></div></div><div id="41885487" class="c"><input type="checkbox" id="c-41885487" checked=""/><div class="controls bullet"><span class="by">porphyra</span><span>|</span><a href="#41885410">parent</a><span>|</span><a href="#41894628">prev</a><span>|</span><a href="#41885475">next</a><span>|</span><label class="collapse" for="c-41885487">[-]</label><label class="expand" for="c-41885487">[16 more]</label></div><br/><div class="children"><div class="content">Just because it has taken 10 years longer than promised doesn&#x27;t mean that it will never happen. FSD has made huge improvements this year and is on track to keep up the current pace so it actually does seem closer than ever.</div><br/><div id="41885527" class="c"><input type="checkbox" id="c-41885527" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41885487">parent</a><span>|</span><a href="#41888830">next</a><span>|</span><label class="collapse" for="c-41885527">[-]</label><label class="expand" for="c-41885527">[12 more]</label></div><br/><div class="children"><div class="content">The current vision-only system is a clear technological dead-end that can&#x27;t go much more than 10 miles between &quot;disengagements&quot;. To be clear, &quot;disengagements&quot; would be crashes if a human wasn&#x27;t ready to take over. And not needing a human driver is THE ENTIRE POINT!
    I will admit Musk isn&#x27;t a liar when Tesla has FSD at least as good as Waymo&#x27;s system and Tesla accepts legal liability for any crashes.</div><br/><div id="41886198" class="c"><input type="checkbox" id="c-41886198" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41885527">parent</a><span>|</span><a href="#41888830">next</a><span>|</span><label class="collapse" for="c-41886198">[-]</label><label class="expand" for="c-41886198">[11 more]</label></div><br/><div class="children"><div class="content">You’re wrong. Nothing about this is clear, and you’d be silly to claim otherwise.<p>You should explore your bias and where it’s coming from.</div><br/><div id="41887902" class="c"><input type="checkbox" id="c-41887902" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41886198">parent</a><span>|</span><a href="#41888830">next</a><span>|</span><label class="collapse" for="c-41887902">[-]</label><label class="expand" for="c-41887902">[10 more]</label></div><br/><div class="children"><div class="content">No Tesla vehicle has legally driven even a single mile with no driver in the driver&#x27;s seat. They aren&#x27;t even trying to play Waymo&#x27;s game. The latest FSD software&#x27;s failure rate is at least 100 times higher than it needs to be.</div><br/><div id="41888135" class="c"><input type="checkbox" id="c-41888135" checked=""/><div class="controls bullet"><span class="by">fallingknife</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41887902">parent</a><span>|</span><a href="#41888830">next</a><span>|</span><label class="collapse" for="c-41888135">[-]</label><label class="expand" for="c-41888135">[9 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a stupid point.  I&#x27;ve been in a Tesla that&#x27;s driven a mile by itself.  It makes no difference if a person is in the seat.</div><br/><div id="41888440" class="c"><input type="checkbox" id="c-41888440" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41888135">parent</a><span>|</span><a href="#41888830">next</a><span>|</span><label class="collapse" for="c-41888440">[-]</label><label class="expand" for="c-41888440">[8 more]</label></div><br/><div class="children"><div class="content">&quot;It makes no difference if a person is in the seat.&quot;
It does when Musk is claiming that Tesla is going to sell a car with no steering wheel!<p>The current Tesla FSD fails so often that a human HAS to be in the driver seat ready to take over at any moment.<p>You really don&#x27;t understand the enormous difference between the current crappy level 2 Tesla FSD and Waymo&#x27;s level 4 system?</div><br/><div id="41897998" class="c"><input type="checkbox" id="c-41897998" checked=""/><div class="controls bullet"><span class="by">fallingknife</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41888440">parent</a><span>|</span><a href="#41889921">next</a><span>|</span><label class="collapse" for="c-41897998">[-]</label><label class="expand" for="c-41897998">[2 more]</label></div><br/><div class="children"><div class="content">Who said anything about Waymo?  Waymo is building a very high cost commercial grade system intended for use on revenue generating vehicles.  Tesla is building a low cost system intended for personal vehicles where Waymo&#x27;s system would be cost prohibitive.  Obviously Waymo&#x27;s system is massively more capable.  But that is about as surprising as the fact that a Ferrari is faster than a Ford Ranger.<p>But this is all irrelevant to my point.  You said a Tesla is not capable of driving itself for a mile.  I have personally seen one do it.  Whether a person is sitting in the driver&#x27;s seat, or the regulators will allow it, has nothing to do with the fact that the vehicle does, in fact, have that capability.</div><br/></div></div><div id="41889921" class="c"><input type="checkbox" id="c-41889921" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41888440">parent</a><span>|</span><a href="#41897998">prev</a><span>|</span><a href="#41888830">next</a><span>|</span><label class="collapse" for="c-41889921">[-]</label><label class="expand" for="c-41889921">[5 more]</label></div><br/><div class="children"><div class="content">The difference is that Tesla has a general algorithm, while Waymo is hard coding scenarios.<p>I never really got why people bring Waymo up every time Tesla’s FSD is mentioned. Waymo isn’t competing with Tesla’s vision.</div><br/><div id="41890584" class="c"><input type="checkbox" id="c-41890584" checked=""/><div class="controls bullet"><span class="by">porphyra</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41889921">parent</a><span>|</span><a href="#41891302">next</a><span>|</span><label class="collapse" for="c-41890584">[-]</label><label class="expand" for="c-41890584">[2 more]</label></div><br/><div class="children"><div class="content">Waymo uses a learned planner and is far from &quot;hardcoded&quot;. In any case, imo both of these can be true:<p>* Tesla FSD works surprisingly well and improving capabilities to hands free actual autonomy isn&#x27;t as far fetched as one might think.<p>* Waymo beat them to robotaxi deployment and scaling up to multiple cities may not be as hard as people say.<p>It seems that self driving car fans are way too tribal and seem to be convinced that the &quot;other side&quot; sucks and is guaranteed to fail. In reality, it is very unclear as both strategies have their merits and only time will tell in the long run.</div><br/><div id="41891319" class="c"><input type="checkbox" id="c-41891319" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41890584">parent</a><span>|</span><a href="#41891302">next</a><span>|</span><label class="collapse" for="c-41891319">[-]</label><label class="expand" for="c-41891319">[1 more]</label></div><br/><div class="children"><div class="content">&quot; Tesla FSD works surprisingly well and improving capabilities to hands free actual autonomy isn&#x27;t as far fetched as one might think&quot;<p>Except FSD doesn&#x27;t work surprisingly well and there is no way it will get as good as Waymo using vision-only.<p>&quot;It seems that self driving car fans are way too tribal and seem to be convinced that the &quot;other side&quot; sucks and is guaranteed to fail.&quot;<p>I&#x27;m not being tribal, I&#x27;m being realistic based on the very public performance of both systems.<p>If Musk was serious about his Robotaxi claims then Tesla would be operating very  differently. Instead it is pretty obvious it all a con to inflate Tesla shares beyond all reason.</div><br/></div></div></div></div><div id="41891302" class="c"><input type="checkbox" id="c-41891302" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41889921">parent</a><span>|</span><a href="#41890584">prev</a><span>|</span><a href="#41888830">next</a><span>|</span><label class="collapse" for="c-41891302">[-]</label><label class="expand" for="c-41891302">[2 more]</label></div><br/><div class="children"><div class="content">The difference is that Waymo has a very well engineered system using vision, LIDAR, and millimeter wave RADAR that works well enough in limited areas to provide tens of thousands of actual driver-less rides. Tesla has a vision only system that sucks so bad a human has to be ready to take over for it at any time like a parent monitoring a toddler near stairs.</div><br/><div id="41901655" class="c"><input type="checkbox" id="c-41901655" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41891302">parent</a><span>|</span><a href="#41888830">next</a><span>|</span><label class="collapse" for="c-41901655">[-]</label><label class="expand" for="c-41901655">[1 more]</label></div><br/><div class="children"><div class="content">Wait until you hear Waymo has people ready to step in with remote controls at all times.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="41888830" class="c"><input type="checkbox" id="c-41888830" checked=""/><div class="controls bullet"><span class="by">gitaarik</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41885487">parent</a><span>|</span><a href="#41885527">prev</a><span>|</span><a href="#41885475">next</a><span>|</span><label class="collapse" for="c-41888830">[-]</label><label class="expand" for="c-41888830">[3 more]</label></div><br/><div class="children"><div class="content">Just like AGI and the year of the Linux desktop ;P</div><br/><div id="41890545" class="c"><input type="checkbox" id="c-41890545" checked=""/><div class="controls bullet"><span class="by">porphyra</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41888830">parent</a><span>|</span><a href="#41885475">next</a><span>|</span><label class="collapse" for="c-41890545">[-]</label><label class="expand" for="c-41890545">[2 more]</label></div><br/><div class="children"><div class="content">Honestly LLMs were a big step towards AGI, and gaming on Linux is practically flawless now. Just played through Black Myth Wukong with no issues out of the box.</div><br/><div id="41891323" class="c"><input type="checkbox" id="c-41891323" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#41885410">root</a><span>|</span><a href="#41890545">parent</a><span>|</span><a href="#41885475">next</a><span>|</span><label class="collapse" for="c-41891323">[-]</label><label class="expand" for="c-41891323">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are to AGI<p>as<p>A ladder is to getting to orbit.<p>I can seem LLMs serving as a kind of memory for an AGI but something fundamentally different will be needed for true reasoning and continues self-improvement.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41889190" class="c"><input type="checkbox" id="c-41889190" checked=""/><div class="controls bullet"><span class="by">testfrequency</span><span>|</span><a href="#41885410">prev</a><span>|</span><a href="#41880780">next</a><span>|</span><label class="collapse" for="c-41889190">[-]</label><label class="expand" for="c-41889190">[2 more]</label></div><br/><div class="children"><div class="content">I was in a Model 3 Uber yesterday and my driver had to serve onto and up a curb to avoid an (idiot) who was trying to turn into traffic going in the other direction.<p>The Model 3 had every opportunity in the world to brake and it didn’t, we were probably only going 25mph. I know this is about FSD here, but that moment 100% made me realize Tesla has awful obstacle avoidance.<p>I just happen to be looking forward and it was a very plain and clear T-Bone avoidance, and at no point did the car handle or trigger anything.<p>Thankfully everyone was ok, but the front lip got pretty beat up from driving up the curb. Of course the driver at fault that caused the whole incident drove off.</div><br/><div id="41894660" class="c"><input type="checkbox" id="c-41894660" checked=""/><div class="controls bullet"><span class="by">averageRoyalty</span><span>|</span><a href="#41889190">parent</a><span>|</span><a href="#41880780">next</a><span>|</span><label class="collapse" for="c-41894660">[-]</label><label class="expand" for="c-41894660">[1 more]</label></div><br/><div class="children"><div class="content">Was the Uber driver using FSD or autopilot?<p>Obstacle avoidance and automatic braking can easily be switched on or off by the driver.</div><br/></div></div></div></div><div id="41880780" class="c"><input type="checkbox" id="c-41880780" checked=""/><div class="controls bullet"><span class="by">daghamm</span><span>|</span><a href="#41889190">prev</a><span>|</span><a href="#41886285">next</a><span>|</span><label class="collapse" for="c-41880780">[-]</label><label class="expand" for="c-41880780">[13 more]</label></div><br/><div class="children"><div class="content">While at it, please also investigate why it is sometimes impossible to leave a damaged vehicle. This has resulted in people dying more than once:<p><a href="https:&#x2F;&#x2F;apnews.com&#x2F;article&#x2F;car-crash-tesla-france-fire-be8ec1ef2253bd725f164c285d83317b" rel="nofollow">https:&#x2F;&#x2F;apnews.com&#x2F;article&#x2F;car-crash-tesla-france-fire-be8ec...</a></div><br/><div id="41880976" class="c"><input type="checkbox" id="c-41880976" checked=""/><div class="controls bullet"><span class="by">MadnessASAP</span><span>|</span><a href="#41880780">parent</a><span>|</span><a href="#41886285">next</a><span>|</span><label class="collapse" for="c-41880976">[-]</label><label class="expand" for="c-41880976">[12 more]</label></div><br/><div class="children"><div class="content">The why is pretty well understood, no investigation needed. I don&#x27;t like the design but it&#x27;s because the doors are electronic and people don&#x27;t know where the manual release is.<p>In a panic people go on muscle memory, which is push the useless button. They don&#x27;t remember to pull the unmarked unobtrusive handle that they may not even know exists.<p>If it was up to me, sure have your electronic release, but make the manual release a big handle that looks like the ejection handle on a jet (yellow with black stripes, can&#x27;t miss it).<p>* Or even better, have the standard door handle mechanically connected to the latch through a spring loaded solenoid that disengages the mechanism. Thus when used under normal conditions it does the thing electronically but the moment power fails the door handle connects to the manual release.</div><br/><div id="41881784" class="c"><input type="checkbox" id="c-41881784" checked=""/><div class="controls bullet"><span class="by">Clamchop</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41880976">parent</a><span>|</span><a href="#41881063">next</a><span>|</span><label class="collapse" for="c-41881784">[-]</label><label class="expand" for="c-41881784">[2 more]</label></div><br/><div class="children"><div class="content">Or just use normal handles, inside and outside, like other cars. What they&#x27;ve done is made things worse by any objective metric in exchange for a &quot;huh, nifty&quot; that wears off after a few weeks.</div><br/><div id="41882071" class="c"><input type="checkbox" id="c-41882071" checked=""/><div class="controls bullet"><span class="by">nomel</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41881784">parent</a><span>|</span><a href="#41881063">next</a><span>|</span><label class="collapse" for="c-41882071">[-]</label><label class="expand" for="c-41882071">[1 more]</label></div><br/><div class="children"><div class="content">I think this is the way. Light pull does the electronic thing. Hard pull does the mechanical thing. They could have done this with the mechanical handle that&#x27;s there already (that I have pulled almost every time I&#x27;ve used a Tesla, getting anger and weather stripping inspection from the owner).</div><br/></div></div></div></div><div id="41881063" class="c"><input type="checkbox" id="c-41881063" checked=""/><div class="controls bullet"><span class="by">daghamm</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41880976">parent</a><span>|</span><a href="#41881784">prev</a><span>|</span><a href="#41881843">next</a><span>|</span><label class="collapse" for="c-41881063">[-]</label><label class="expand" for="c-41881063">[2 more]</label></div><br/><div class="children"><div class="content">There are situations where manual release has not worked<p><a href="https:&#x2F;&#x2F;www.businessinsider.com&#x2F;how-to-manually-open-tesla-door-if-battery-power-dies-2023-8?op=1" rel="nofollow">https:&#x2F;&#x2F;www.businessinsider.com&#x2F;how-to-manually-open-tesla-d...</a></div><br/><div id="41889104" class="c"><input type="checkbox" id="c-41889104" checked=""/><div class="controls bullet"><span class="by">willy_k</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41881063">parent</a><span>|</span><a href="#41881843">next</a><span>|</span><label class="collapse" for="c-41889104">[-]</label><label class="expand" for="c-41889104">[1 more]</label></div><br/><div class="children"><div class="content">The article you provided does not say that. The only failure related to the manual release it mentions is that using it breaks the window.<p>&gt; Exton said he followed the instructions for the manual release to open the door, but that this &quot;somehow broke the driver&#x27;s window.&quot;</div><br/></div></div></div></div><div id="41881843" class="c"><input type="checkbox" id="c-41881843" checked=""/><div class="controls bullet"><span class="by">carimura</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41880976">parent</a><span>|</span><a href="#41881063">prev</a><span>|</span><a href="#41885504">next</a><span>|</span><label class="collapse" for="c-41881843">[-]</label><label class="expand" for="c-41881843">[2 more]</label></div><br/><div class="children"><div class="content">it&#x27;s worse than that, at least in ours, the backseat latches are under some mat, literally hidden. i had no idea it was there for the first 6 months.</div><br/><div id="41893476" class="c"><input type="checkbox" id="c-41893476" checked=""/><div class="controls bullet"><span class="by">Schiendelman</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41881843">parent</a><span>|</span><a href="#41885504">next</a><span>|</span><label class="collapse" for="c-41893476">[-]</label><label class="expand" for="c-41893476">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s at the behest of the federal government. Child lock rules require they aren&#x27;t accessible.</div><br/></div></div></div></div><div id="41885504" class="c"><input type="checkbox" id="c-41885504" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41880976">parent</a><span>|</span><a href="#41881843">prev</a><span>|</span><a href="#41883134">next</a><span>|</span><label class="collapse" for="c-41885504">[-]</label><label class="expand" for="c-41885504">[2 more]</label></div><br/><div class="children"><div class="content">I’ve seen an innovative car with a single door release. As you pull it, it first triggers the electronic mechanism (which lowers the window a bit, which is useful in a door with no frame above the window) and then, as you pull it farther, it mechanically unlatches the door.<p>Tesla should build their doors like this. Oh, wait, the car I’m talking about is an older Tesla. Maybe Tesla should <i>remember</i> how to build doors like this.</div><br/><div id="41890252" class="c"><input type="checkbox" id="c-41890252" checked=""/><div class="controls bullet"><span class="by">crooked-v</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41885504">parent</a><span>|</span><a href="#41883134">next</a><span>|</span><label class="collapse" for="c-41890252">[-]</label><label class="expand" for="c-41890252">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not very &#x27;innovative&#x27; these days. My 2012 Mini Cooper has it.</div><br/></div></div></div></div><div id="41883134" class="c"><input type="checkbox" id="c-41883134" checked=""/><div class="controls bullet"><span class="by">Zigurd</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41880976">parent</a><span>|</span><a href="#41885504">prev</a><span>|</span><a href="#41892894">next</a><span>|</span><label class="collapse" for="c-41883134">[-]</label><label class="expand" for="c-41883134">[1 more]</label></div><br/><div class="children"><div class="content">The inside trunk release on most cars has a glow-in-the-dark fluorescent color handle</div><br/></div></div><div id="41892894" class="c"><input type="checkbox" id="c-41892894" checked=""/><div class="controls bullet"><span class="by">leoh</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41880976">parent</a><span>|</span><a href="#41883134">prev</a><span>|</span><a href="#41895267">next</a><span>|</span><label class="collapse" for="c-41892894">[-]</label><label class="expand" for="c-41892894">[1 more]</label></div><br/><div class="children"><div class="content">Crazy that with all of NHTSA&#x27;s regulations, this is still legal.</div><br/></div></div><div id="41895267" class="c"><input type="checkbox" id="c-41895267" checked=""/><div class="controls bullet"><span class="by">greenie_beans</span><span>|</span><a href="#41880780">root</a><span>|</span><a href="#41880976">parent</a><span>|</span><a href="#41892894">prev</a><span>|</span><a href="#41886285">next</a><span>|</span><label class="collapse" for="c-41895267">[-]</label><label class="expand" for="c-41895267">[1 more]</label></div><br/><div class="children"><div class="content">that&#x27;s just bad ux</div><br/></div></div></div></div></div></div><div id="41886285" class="c"><input type="checkbox" id="c-41886285" checked=""/><div class="controls bullet"><span class="by">gitaarik</span><span>|</span><a href="#41880780">prev</a><span>|</span><a href="#41885050">next</a><span>|</span><label class="collapse" for="c-41886285">[-]</label><label class="expand" for="c-41886285">[4 more]</label></div><br/><div class="children"><div class="content">It concerns me that these Tesla&#x27;s can suddenly start acting differently after a software update. Seems like a great target for a cyber attack. Or just a fail from the company. A little bug that is accidentally spread to millions of cars all over the world.<p>And how is this regulated? Say the software gets to a point that we deem it safe for full self driving, then it gets approved on the road, and then Tesla adds a new fancy feature to their software and rolls out an update. How are we to be confident that it&#x27;s safe?</div><br/><div id="41891812" class="c"><input type="checkbox" id="c-41891812" checked=""/><div class="controls bullet"><span class="by">boshalfoshal</span><span>|</span><a href="#41886285">parent</a><span>|</span><a href="#41887425">next</a><span>|</span><label class="collapse" for="c-41891812">[-]</label><label class="expand" for="c-41891812">[2 more]</label></div><br/><div class="children"><div class="content">&gt; how are we to be confident that its safe?<p>I hope you realize that these companies dont just push updates to your car like vscode does.<p>Every change has to be unit tested, integration tested, tested in simulation, driven on a multiple cars on an internal fleet (in multiple countries) for multiple days&#x2F;weeks, then is sent out in waves, then finally, once a bunch of metrics&#x2F;feedback comes back, they start sending it out wider.<p>Admittedly you pretty much have to just trust that the above catches most egregious issues, but there will always be unknown unknowns that will be hard to account for, even with all that. Either that or legitimately willful negligence, in which case, yes they should be held accountable.<p>These aren&#x27;t scrappy startups pushing fast and breaking things, there is an actual process to this.</div><br/><div id="41895546" class="c"><input type="checkbox" id="c-41895546" checked=""/><div class="controls bullet"><span class="by">madeforhnyo</span><span>|</span><a href="#41886285">root</a><span>|</span><a href="#41891812">parent</a><span>|</span><a href="#41887425">next</a><span>|</span><label class="collapse" for="c-41895546">[-]</label><label class="expand" for="c-41895546">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=17835760">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=17835760</a></div><br/></div></div></div></div><div id="41887425" class="c"><input type="checkbox" id="c-41887425" checked=""/><div class="controls bullet"><span class="by">rightbyte</span><span>|</span><a href="#41886285">parent</a><span>|</span><a href="#41891812">prev</a><span>|</span><a href="#41885050">next</a><span>|</span><label class="collapse" for="c-41887425">[-]</label><label class="expand" for="c-41887425">[1 more]</label></div><br/><div class="children"><div class="content">Imagine all Teslas doing a full left right now. And full right in left steer countries.<p>OTA updates and auto updates in general is just a thing that should not be in vehicles. The ecu:s should have to be air gaped to the internet to be considered road worthy.</div><br/></div></div></div></div><div id="41885050" class="c"><input type="checkbox" id="c-41885050" checked=""/><div class="controls bullet"><span class="by">botanical</span><span>|</span><a href="#41886285">prev</a><span>|</span><a href="#41880940">next</a><span>|</span><label class="collapse" for="c-41885050">[-]</label><label class="expand" for="c-41885050">[11 more]</label></div><br/><div class="children"><div class="content">Only the US government can allow corporations to beta test unproven technology on the public.<p>Governments should carry out comprehensive tests on a self-driving car&#x27;s claimed capabilities. This is the same as cars without proven passenger safety (Euro NCAP) aren&#x27;t allowed to be on roads carrying passengers.</div><br/><div id="41885052" class="c"><input type="checkbox" id="c-41885052" checked=""/><div class="controls bullet"><span class="by">krasin</span><span>|</span><a href="#41885050">parent</a><span>|</span><a href="#41885399">next</a><span>|</span><label class="collapse" for="c-41885052">[-]</label><label class="expand" for="c-41885052">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Only the US government can allow corporations to beta test unproven technology on the public.<p>China and Russia do it too. It&#x27;s not an excuse, but definitely not just the US.</div><br/></div></div><div id="41885399" class="c"><input type="checkbox" id="c-41885399" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41885050">parent</a><span>|</span><a href="#41885052">prev</a><span>|</span><a href="#41898836">next</a><span>|</span><label class="collapse" for="c-41885399">[-]</label><label class="expand" for="c-41885399">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Only the US government<p>Any Legislative body can do so.  There&#x27;s no reason to limit this strictly to the federal government.  States and municipalities should have a say in this as well.  The _citizens_ are the only entity that _decide_ if beta technology can be used or not.<p>&gt; comprehensive tests on a self-driving car&#x27;s claimed capabilities.<p>This presupposes the government is naturally capable of performing an adequate job at this task or that the automakers won&#x27;t sue the government to interfere with the testing regime and efficacy of it&#x27;s standards.<p>&gt; aren&#x27;t allowed to be on roads carrying passengers.<p>According to Wikipedia Euro NCAP is a _voluntary_ organization and describes the situation thusly &quot;legislation sets a minimum compulsory standard whilst Euro NCAP is concerned with best possible current practice.&quot;  Which effectively highlights the above problems perfectly.</div><br/></div></div><div id="41898836" class="c"><input type="checkbox" id="c-41898836" checked=""/><div class="controls bullet"><span class="by">dham</span><span>|</span><a href="#41885050">parent</a><span>|</span><a href="#41885399">prev</a><span>|</span><a href="#41885127">next</a><span>|</span><label class="collapse" for="c-41898836">[-]</label><label class="expand" for="c-41898836">[1 more]</label></div><br/><div class="children"><div class="content">Uhh, have you heard of the FDA?  It&#x27;s approved hundreds of chemicals that are put in all of food.  And we&#x27;re not talking about a few deaths, we&#x27;re talking hundreds of thousands if not millions.</div><br/></div></div><div id="41885127" class="c"><input type="checkbox" id="c-41885127" checked=""/><div class="controls bullet"><span class="by">CTDOCodebases</span><span>|</span><a href="#41885050">parent</a><span>|</span><a href="#41898836">prev</a><span>|</span><a href="#41885132">next</a><span>|</span><label class="collapse" for="c-41885127">[-]</label><label class="expand" for="c-41885127">[2 more]</label></div><br/><div class="children"><div class="content">Meh. Happens all around the world. Even if the product works there is no guarantee that it will be safe.<p>Asbestos products are a good example of this. A more recent one is Teflon made with PFOAs or engineered stone like Caesarstone.</div><br/></div></div><div id="41885132" class="c"><input type="checkbox" id="c-41885132" checked=""/><div class="controls bullet"><span class="by">dzhiurgis</span><span>|</span><a href="#41885050">parent</a><span>|</span><a href="#41885127">prev</a><span>|</span><a href="#41880940">next</a><span>|</span><label class="collapse" for="c-41885132">[-]</label><label class="expand" for="c-41885132">[5 more]</label></div><br/><div class="children"><div class="content">If it takes 3 months to approve where steel rocket falls you might as well give up iterating something as complex as FSD.</div><br/><div id="41885183" class="c"><input type="checkbox" id="c-41885183" checked=""/><div class="controls bullet"><span class="by">AlotOfReading</span><span>|</span><a href="#41885050">root</a><span>|</span><a href="#41885132">parent</a><span>|</span><a href="#41885153">next</a><span>|</span><label class="collapse" for="c-41885183">[-]</label><label class="expand" for="c-41885183">[1 more]</label></div><br/><div class="children"><div class="content">There <i>are</i> industry standards for this stuff. ISO 21448, UL-4600, UNECE R157 for example, and even commercial certification programs like the one run by TÜV Süd for European homologation. It&#x27;s a deliberate series of decisions on Tesla&#x27;s part to make their regulatory life as difficult as possible.</div><br/></div></div><div id="41885153" class="c"><input type="checkbox" id="c-41885153" checked=""/><div class="controls bullet"><span class="by">bckr</span><span>|</span><a href="#41885050">root</a><span>|</span><a href="#41885132">parent</a><span>|</span><a href="#41885183">prev</a><span>|</span><a href="#41880940">next</a><span>|</span><label class="collapse" for="c-41885153">[-]</label><label class="expand" for="c-41885153">[3 more]</label></div><br/><div class="children"><div class="content">Drive it in larger and larger closed courses. Expand to neighboring areas with consent of the communities involved. Agree on limited conditions until enough data has been gathered to expand those conditions.</div><br/><div id="41885423" class="c"><input type="checkbox" id="c-41885423" checked=""/><div class="controls bullet"><span class="by">romon</span><span>|</span><a href="#41885050">root</a><span>|</span><a href="#41885153">parent</a><span>|</span><a href="#41880940">next</a><span>|</span><label class="collapse" for="c-41885423">[-]</label><label class="expand" for="c-41885423">[2 more]</label></div><br/><div class="children"><div class="content">While controlled conditions promote safety, they do not yield effective training data.</div><br/><div id="41885523" class="c"><input type="checkbox" id="c-41885523" checked=""/><div class="controls bullet"><span class="by">AlotOfReading</span><span>|</span><a href="#41885050">root</a><span>|</span><a href="#41885423">parent</a><span>|</span><a href="#41880940">next</a><span>|</span><label class="collapse" for="c-41885523">[-]</label><label class="expand" for="c-41885523">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s how all autonomous testing programs currently work around the world. That is, every driverless vehicle system on roads today was developed this way. You&#x27;re going to have to be more specific when you say that it doesn&#x27;t work.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41880940" class="c"><input type="checkbox" id="c-41880940" checked=""/><div class="controls bullet"><span class="by">dietsche</span><span>|</span><a href="#41885050">prev</a><span>|</span><a href="#41890540">next</a><span>|</span><label class="collapse" for="c-41880940">[-]</label><label class="expand" for="c-41880940">[16 more]</label></div><br/><div class="children"><div class="content">I would like more details. There are definitely situations where neither a car nor a human could respond quickly enough to a situation on the road.<p>for example, I recently hit a deer. The dashcam shows that I had less than 100 feet from when the deer became visible due to terrain to impact while driving at 60 mph. Keeping in mind that stopping a car in 100 feet at 60 mph is impossible. Most vehicles need more than triple that without accounting for human reaction time.</div><br/><div id="41881347" class="c"><input type="checkbox" id="c-41881347" checked=""/><div class="controls bullet"><span class="by">ra7</span><span>|</span><a href="#41880940">parent</a><span>|</span><a href="#41882116">next</a><span>|</span><label class="collapse" for="c-41881347">[-]</label><label class="expand" for="c-41881347">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately, Tesla requests NHTSA to redact almost all useful information from their crash reports. So it&#x27;s impossible to get more details.<p>Here is the public database of all ADAS crashes: <a href="https:&#x2F;&#x2F;static.nhtsa.gov&#x2F;odi&#x2F;ffdd&#x2F;sgo-2021-01&#x2F;SGO-2021-01_Incident_Reports_ADAS.csv" rel="nofollow">https:&#x2F;&#x2F;static.nhtsa.gov&#x2F;odi&#x2F;ffdd&#x2F;sgo-2021-01&#x2F;SGO-2021-01_In...</a></div><br/></div></div><div id="41882116" class="c"><input type="checkbox" id="c-41882116" checked=""/><div class="controls bullet"><span class="by">arcanemachiner</span><span>|</span><a href="#41880940">parent</a><span>|</span><a href="#41881347">prev</a><span>|</span><a href="#41882099">next</a><span>|</span><label class="collapse" for="c-41882116">[-]</label><label class="expand" for="c-41882116">[11 more]</label></div><br/><div class="children"><div class="content">This is called &quot;overdriving your vision&quot;, and it&#x27;s so common that it boggles my mind. (This opinion might have something to do with the deer I hit when I first started driving...)<p>Drive according to the conditions, folks.</div><br/><div id="41883203" class="c"><input type="checkbox" id="c-41883203" checked=""/><div class="controls bullet"><span class="by">Zigurd</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41882116">parent</a><span>|</span><a href="#41886298">next</a><span>|</span><label class="collapse" for="c-41883203">[-]</label><label class="expand" for="c-41883203">[1 more]</label></div><br/><div class="children"><div class="content">We will inevitably see &quot;AVs are too cautious! Let me go faster!&quot; complaints as AVs drive in more places. But, really humans just suck at risk assessment. And at driving. Driving like a human is comforting in some contexts, but that should not be a goal when it trades away too much safety.</div><br/></div></div><div id="41886298" class="c"><input type="checkbox" id="c-41886298" checked=""/><div class="controls bullet"><span class="by">thebruce87m</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41882116">parent</a><span>|</span><a href="#41883203">prev</a><span>|</span><a href="#41882997">next</a><span>|</span><label class="collapse" for="c-41886298">[-]</label><label class="expand" for="c-41886298">[2 more]</label></div><br/><div class="children"><div class="content">There is a difference between driving too fast around a corner to stop for something stationary on the road and driving through countryside where something might jump out.<p>I live in a country with deer but the number of incidences of them interacting with road users is so low that it does not factor in to my risk tolerance.</div><br/><div id="41888742" class="c"><input type="checkbox" id="c-41888742" checked=""/><div class="controls bullet"><span class="by">Zigurd</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41886298">parent</a><span>|</span><a href="#41882997">next</a><span>|</span><label class="collapse" for="c-41888742">[-]</label><label class="expand" for="c-41888742">[1 more]</label></div><br/><div class="children"><div class="content">The risks vary with speed. At 30mph a deer will be injured and damage your car, and you might have to call animal control to find the deer if it was able to get away. At 45mph there is a good chance the deer will impact your windshield. If it breaks through, that&#x27;s how people die in animal collisions. They get kicked to death by a frantic, panicked, injured animal.</div><br/></div></div></div></div><div id="41882997" class="c"><input type="checkbox" id="c-41882997" checked=""/><div class="controls bullet"><span class="by">Kirby64</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41882116">parent</a><span>|</span><a href="#41886298">prev</a><span>|</span><a href="#41882099">next</a><span>|</span><label class="collapse" for="c-41882997">[-]</label><label class="expand" for="c-41882997">[7 more]</label></div><br/><div class="children"><div class="content">On many roads if a deer jumps across the road at the wrong time there’s literally nothing you can do. You can’t always drive at 30mph on back country roads just because a deer might hop out at you.</div><br/><div id="41885144" class="c"><input type="checkbox" id="c-41885144" checked=""/><div class="controls bullet"><span class="by">seadan83</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41882997">parent</a><span>|</span><a href="#41882099">next</a><span>|</span><label class="collapse" for="c-41885144">[-]</label><label class="expand" for="c-41885144">[6 more]</label></div><br/><div class="children"><div class="content">World of difference between, 30, 40, 50 and 60. Feels like something I have noticed between west and east coast drivers. Latter really send it on country turns and just trust the road. West coast, particularly montana, when vision is reduced, speed slows down. Just too many animals or road obstacles (eg: rocks, planks of wood) to just trust the road.</div><br/><div id="41885187" class="c"><input type="checkbox" id="c-41885187" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41885144">parent</a><span>|</span><a href="#41885416">next</a><span>|</span><label class="collapse" for="c-41885187">[-]</label><label class="expand" for="c-41885187">[2 more]</label></div><br/><div class="children"><div class="content">&gt; West coast, particularly montana<p>Montana is not &quot;West coast&quot;.</div><br/><div id="41887962" class="c"><input type="checkbox" id="c-41887962" checked=""/><div class="controls bullet"><span class="by">seadan83</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41885187">parent</a><span>|</span><a href="#41885416">next</a><span>|</span><label class="collapse" for="c-41887962">[-]</label><label class="expand" for="c-41887962">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I was a bit glib. My impression is more specifically of the greater northwest vs rest. Perhaps just &quot;the west&quot; vs &quot;the east&quot;.<p>Indiana drivers for example really do send it (in my experience). Which is not east coast of course.<p>There is a good bit of nuance... I would perhaps say more simply east of Mississippi vs west, but Texas varies by region and so-Cal drivers vary a lot as well, particularly compared to nor-Cal and central+eastern california.  (I don&#x27;t have an impression for nevada and new mexico drivers - I dont have any experience on country roads in those states)</div><br/></div></div></div></div><div id="41885416" class="c"><input type="checkbox" id="c-41885416" checked=""/><div class="controls bullet"><span class="by">Kirby64</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41885144">parent</a><span>|</span><a href="#41885187">prev</a><span>|</span><a href="#41882099">next</a><span>|</span><label class="collapse" for="c-41885416">[-]</label><label class="expand" for="c-41885416">[3 more]</label></div><br/><div class="children"><div class="content">Road obstacles are static and can be seen by not “out driving your headlights”. Animals flinging themselves into the road cannot, in many instances.</div><br/><div id="41887825" class="c"><input type="checkbox" id="c-41887825" checked=""/><div class="controls bullet"><span class="by">amenhotep</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41885416">parent</a><span>|</span><a href="#41882099">next</a><span>|</span><label class="collapse" for="c-41887825">[-]</label><label class="expand" for="c-41887825">[2 more]</label></div><br/><div class="children"><div class="content">You are responding in a thread about a person saying they were driving at 60 when the deer only became visible &quot;due to terrain&quot; at 100 feet away, and therefore hitting it is no reflection on their skill or choices as a driver.<p>I suppose we&#x27;re meant to interpret charitably here, but it really seems to me like there is a big difference between the scenario described and the one you&#x27;re talking about, where the deer really does fling itself out in front of you.</div><br/><div id="41891354" class="c"><input type="checkbox" id="c-41891354" checked=""/><div class="controls bullet"><span class="by">dietsche</span><span>|</span><a href="#41880940">root</a><span>|</span><a href="#41887825">parent</a><span>|</span><a href="#41882099">next</a><span>|</span><label class="collapse" for="c-41891354">[-]</label><label class="expand" for="c-41891354">[1 more]</label></div><br/><div class="children"><div class="content">op here. you nailed it on the head. also, the car started breaking before i could!<p>incidentally, i’ve also had the tesla dodge a deer successfully!<p>autopilot has improved in BIG ways over the past 2 years. went 700 miles in one day on autopilot thru the mountains. no issues at all.<p>that said expecting perfection from a machine or a human is a fools errand.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41882099" class="c"><input type="checkbox" id="c-41882099" checked=""/><div class="controls bullet"><span class="by">nomel</span><span>|</span><a href="#41880940">parent</a><span>|</span><a href="#41882116">prev</a><span>|</span><a href="#41883140">next</a><span>|</span><label class="collapse" for="c-41882099">[-]</label><label class="expand" for="c-41882099">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had a person, high on drugs, walk out from between bushes that were along the road. I screeched to a halt in front of them, but 1 second later and physics would have made it impossible, regardless of reaction time (or non-negligible speed).</div><br/></div></div><div id="41883140" class="c"><input type="checkbox" id="c-41883140" checked=""/><div class="controls bullet"><span class="by">freejazz</span><span>|</span><a href="#41880940">parent</a><span>|</span><a href="#41882099">prev</a><span>|</span><a href="#41881614">next</a><span>|</span><label class="collapse" for="c-41883140">[-]</label><label class="expand" for="c-41883140">[1 more]</label></div><br/><div class="children"><div class="content">The article explains the investigation is based upon visibility issues... what is your point? I don&#x27;t think any reasonable person doubts there are circumstances where nothing could adequately respond in order to prevent a crash. It seems a rather odd assumption to reach that these crashes would be in one of those scenarios such that we should be explained to otherwise, no less so when the report facially explains this to not be the case.</div><br/></div></div><div id="41881614" class="c"><input type="checkbox" id="c-41881614" checked=""/><div class="controls bullet"><span class="by">Log_out_</span><span>|</span><a href="#41880940">parent</a><span>|</span><a href="#41883140">prev</a><span>|</span><a href="#41890540">next</a><span>|</span><label class="collapse" for="c-41881614">[-]</label><label class="expand" for="c-41881614">[1 more]</label></div><br/><div class="children"><div class="content">just have a drone fly ahead and have the lidar pointcloud on hud. This are very bio-logic excuses :)</div><br/></div></div></div></div><div id="41890540" class="c"><input type="checkbox" id="c-41890540" checked=""/><div class="controls bullet"><span class="by">drodio</span><span>|</span><a href="#41880940">prev</a><span>|</span><a href="#41885142">next</a><span>|</span><label class="collapse" for="c-41890540">[-]</label><label class="expand" for="c-41890540">[3 more]</label></div><br/><div class="children"><div class="content">I drive a 2024 Tesla Model Y and another person in my family drives a 2021 Model Y. Both cars are substantially similar (the 2021 actually has <i>more</i> sensors than the 2024, which is strictly cameras-only).<p>Both cars are running 12.5 -- and I agree that it&#x27;s dramatically improved over 12.3.<p>I really enjoy driving. I&#x27;ve got a #vanlife Sprinter that I&#x27;ll do 14 hour roadtrips in with my kids. For me, the Tesla&#x27;s self-driving capability is a &quot;nice to have&quot; -- it sometimes drives like a 16 year old who just got their license (especially around braking. Somehow it&#x27;s really hard to nail the &quot;soft brake at a stop sign&quot; which seems like it should be be easy. I find that passengers in the car are most uncomfortable when the car brakes like this -- and I&#x27;m the most embarrassed because they all look at me like I completely forgot how to do a smooth stop at a stop sign).<p>Other times, the Tesla&#x27;s self-driving is magical and nearly flawless -- especially on long highway road trips, like up to Tahoe. Even someone like me who loves doing road trips really appreciates the ability to relax and not have to be driving.<p>But here&#x27;s one observation I&#x27;ve had that I don&#x27;t see quite sufficiently represented in the comments:<p>The other person in my family with the 2021 Model Y does not like to drive like I do, and they really appreciate that the Tesla is a better driver than they feel themselves to be. And as a passenger in their car, I also really appreciate that when the Tesla is driving, I generally feel much more comfortable in the car. Not always, but often.<p>There&#x27;s so much variance in us as humans around driving skills and enjoyment. It&#x27;s easy to lump us together and say &quot;the car isn&#x27;t as good as the human.&quot; And I know there&#x27;s conflicting data from Tesla and NHTSA about whether in aggregate, Teslas are safer than human drivers or not.<p>But what I definitely know from my experience is that the Tesla is already a better driver than <i>many</i> humans are -- especially those that don&#x27;t enjoy driving. And as @modeless points out, the rate of improvement is now vastly accelerating.</div><br/><div id="41900816" class="c"><input type="checkbox" id="c-41900816" checked=""/><div class="controls bullet"><span class="by">magnetowasright</span><span>|</span><a href="#41890540">parent</a><span>|</span><a href="#41897035">next</a><span>|</span><label class="collapse" for="c-41900816">[-]</label><label class="expand" for="c-41900816">[1 more]</label></div><br/><div class="children"><div class="content">Has this relative considered that they may not be capable of driving safely at all if they (and others) really do believe that their tesla (whose driving software drives like a freshly licensed 16 year old per your comment) is a better driver? Isn&#x27;t intervening when the tesla does something stupid&#x2F;dangerous more difficult than just driving?<p>&gt; Even someone like me who loves doing road trips really appreciates the ability to relax and not have to be driving.<p>Pardon the nitpick (and please excuse me if I&#x27;m interpreting your comment wrong here) but if someone is using whatever maximum capability self driving functionality is available, they are in fact still driving and should not be &#x27;relaxed&#x27; as if they&#x27;re a passenger.<p>I would posit that your observation about your relative and the variance in driving skills is not commonly discussed because there&#x27;s no self driving cars that can actually replace a driver yet, and an unsafe driver relying on &#x27;self driving&#x27; software is still an unsafe driver who should not drive.<p>I realise that there&#x27;s many understandable reasons people can&#x27;t just give up their cars and carry on like normal. Helping people to stay mobile, connected, and independent is important, but an unsafe driver is, well, unsafe. It kinda terrifies me that people might be encouraging the elderly people (for example) in their lives to get teslas to keep them driving when they aren&#x27;t capable of driving safely any more because it&#x27;s still unsafe.</div><br/></div></div><div id="41897035" class="c"><input type="checkbox" id="c-41897035" checked=""/><div class="controls bullet"><span class="by">lowbloodsugar</span><span>|</span><a href="#41890540">parent</a><span>|</span><a href="#41900816">prev</a><span>|</span><a href="#41885142">next</a><span>|</span><label class="collapse" for="c-41897035">[-]</label><label class="expand" for="c-41897035">[1 more]</label></div><br/><div class="children"><div class="content">You are a living example of survivorship bias. One day your car will kill you or someone else, and then maybe you’ll be able to come back here and tell us how wrong you were. How, with your new experience, you can see how the car only “seemed” competent, how it was that very seeming competence that got someone killed, because you trusted it.</div><br/></div></div></div></div><div id="41885142" class="c"><input type="checkbox" id="c-41885142" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41890540">prev</a><span>|</span><a href="#41878712">next</a><span>|</span><label class="collapse" for="c-41885142">[-]</label><label class="expand" for="c-41885142">[4 more]</label></div><br/><div class="children"><div class="content">I love how the image in the article has a caption that says it tells you to pay attention to the road, but I had to zoom in all the way to figure out where that message actually was.<p>I’d expect something big and red with a warning triangle or something, but it’s a tiny white message in the center of the screen.</div><br/><div id="41885196" class="c"><input type="checkbox" id="c-41885196" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#41885142">parent</a><span>|</span><a href="#41885508">next</a><span>|</span><label class="collapse" for="c-41885196">[-]</label><label class="expand" for="c-41885196">[2 more]</label></div><br/><div class="children"><div class="content">It gets progressively bigger and louder the longer you ignore it. After 30ish seconds it sounds an alarm and kicks you out.</div><br/><div id="41885292" class="c"><input type="checkbox" id="c-41885292" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41885142">root</a><span>|</span><a href="#41885196">parent</a><span>|</span><a href="#41885508">next</a><span>|</span><label class="collapse" for="c-41885292">[-]</label><label class="expand" for="c-41885292">[1 more]</label></div><br/><div class="children"><div class="content">&gt; After 30ish seconds it sounds an alarm and kicks you out.<p>That&#x27;s much better. When AP functionality was introduced, the alarm was <i>fifteen MINUTES</i>.</div><br/></div></div></div></div><div id="41885508" class="c"><input type="checkbox" id="c-41885508" checked=""/><div class="controls bullet"><span class="by">taspeotis</span><span>|</span><a href="#41885142">parent</a><span>|</span><a href="#41885196">prev</a><span>|</span><a href="#41878712">next</a><span>|</span><label class="collapse" for="c-41885508">[-]</label><label class="expand" for="c-41885508">[1 more]</label></div><br/><div class="children"><div class="content">Ah yes, red with a warning like “WARNING: ERROR: THE SITUATION IS NORMAL!”<p>Some cars that have cruise control but an analog gauge cluster that can’t display WARNING ERRORs even hide stuff like “you still have to drive the car” in a manual you have to read yet nobody cares about that.<p>Honestly driving a car should require some sort of license for a bare minimum of competence.</div><br/></div></div></div></div><div id="41878712" class="c"><input type="checkbox" id="c-41878712" checked=""/><div class="controls bullet"><span class="by">jqpabc123</span><span>|</span><a href="#41885142">prev</a><span>|</span><a href="#41885194">next</a><span>|</span><label class="collapse" for="c-41878712">[-]</label><label class="expand" for="c-41878712">[18 more]</label></div><br/><div class="children"><div class="content">By now, most people have probably heard that Tesla&#x27;s attempt at &quot;Full Self Driving&quot; is really anything but --- after a decade of promises. The vehicle owners manual spells this out.<p>As I understand it, the contentious issue is the fact that unlike most others, their attempt works mostly from visual feedback.<p>In low visibility situations, their FSD has limited feedback and is essentially driving blind.<p>It appears that Musk may be seeking  a political solution to this technical problem.</div><br/><div id="41879568" class="c"><input type="checkbox" id="c-41879568" checked=""/><div class="controls bullet"><span class="by">whamlastxmas</span><span>|</span><a href="#41878712">parent</a><span>|</span><a href="#41880058">next</a><span>|</span><label class="collapse" for="c-41879568">[-]</label><label class="expand" for="c-41879568">[8 more]</label></div><br/><div class="children"><div class="content">It’s really weird how much you comment about FSD being fake. My Tesla drives me 10+ miles daily and the only time I touch any controls is pulling in and out of my garage. Literally daily. I maybe disengage once every couple days just to be on the safe side in uncertain situations,  it I’m sure it’d likely do fine there too.<p>FSD works. It drives itself fine 99.99% of the time. It is better than most human drivers. I don’t know how you keep claiming it doesn’t or doesn’t exist.</div><br/><div id="41879614" class="c"><input type="checkbox" id="c-41879614" checked=""/><div class="controls bullet"><span class="by">sottol</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41879568">parent</a><span>|</span><a href="#41879611">next</a><span>|</span><label class="collapse" for="c-41879614">[-]</label><label class="expand" for="c-41879614">[1 more]</label></div><br/><div class="children"><div class="content">The claim was about _full_ driving being anything but, ie not _fully_ self-driving, not being completely fake. Disengaging every 10-110 miles  is just not &quot;full&quot;, it&#x27;s partial.<p>And then the gp went into details in which specific situations fsd is especially problematic.</div><br/></div></div><div id="41879611" class="c"><input type="checkbox" id="c-41879611" checked=""/><div class="controls bullet"><span class="by">jqpabc123</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41879568">parent</a><span>|</span><a href="#41879614">prev</a><span>|</span><a href="#41898860">next</a><span>|</span><label class="collapse" for="c-41879611">[-]</label><label class="expand" for="c-41879611">[1 more]</label></div><br/><div class="children"><div class="content">So you agree with Musk, the main problem with FSD is political?<p><i>Tesla says on its website its &quot;Full Self-Driving&quot; software in on-road vehicles requires active driver supervision and does not make vehicles autonomous.</i><p><a href="https:&#x2F;&#x2F;www.reuters.com&#x2F;business&#x2F;autos-transportation&#x2F;nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reuters.com&#x2F;business&#x2F;autos-transportation&#x2F;nhtsa-...</a></div><br/></div></div><div id="41898860" class="c"><input type="checkbox" id="c-41898860" checked=""/><div class="controls bullet"><span class="by">dham</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41879568">parent</a><span>|</span><a href="#41879611">prev</a><span>|</span><a href="#41879880">next</a><span>|</span><label class="collapse" for="c-41898860">[-]</label><label class="expand" for="c-41898860">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s similar to when DHH said they were not bundling code in production and all the Javascript bros said &quot;No you can&#x27;t do that it won&#x27;t work&quot;.  DHH was like &quot;yes but I&#x27;m doing it&quot;<p>That&#x27;s how it feels in FSD land right now. Everyone&#x27;s saying FSD doesn&#x27;t work and it&#x27;ll never be here, but I&#x27;m literally using it every day lol.</div><br/></div></div><div id="41879880" class="c"><input type="checkbox" id="c-41879880" checked=""/><div class="controls bullet"><span class="by">peutetre</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41879568">parent</a><span>|</span><a href="#41898860">prev</a><span>|</span><a href="#41880058">next</a><span>|</span><label class="collapse" for="c-41879880">[-]</label><label class="expand" for="c-41879880">[4 more]</label></div><br/><div class="children"><div class="content">The problem is Tesla and Musk have been lying about full self-driving for years. They have made specific claims of full autonomy with specific timelines and it&#x27;s been a lie every time: <a href="https:&#x2F;&#x2F;motherfrunker.ca&#x2F;fsd&#x2F;" rel="nofollow">https:&#x2F;&#x2F;motherfrunker.ca&#x2F;fsd&#x2F;</a><p>In 2016 a video purporting to show full self-driving with the driver there purely &quot;for legal reasons&quot; was staged and faked: <a href="https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;tesla-video-promoting-self-driving-was-staged-engineer-testifies-2023-01-17&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;tesla-video-promoting-sel...</a><p>In 2016 Tesla said that &quot;as of today, all Tesla vehicles produced in our factory – including Model 3 – will have the hardware needed for full self-driving capability at a safety level substantially greater than that of a human driver.&quot; That was a lie: <a href="https:&#x2F;&#x2F;electrek.co&#x2F;2024&#x2F;08&#x2F;24&#x2F;tesla-deletes-its-blog-post-stating-all-cars-have-self-driving-hardware&#x2F;" rel="nofollow">https:&#x2F;&#x2F;electrek.co&#x2F;2024&#x2F;08&#x2F;24&#x2F;tesla-deletes-its-blog-post-s...</a><p>Musk claimed there would be 1 million Tesla robotaxis on the road in 2020. That was a lie: <a href="https:&#x2F;&#x2F;www.thedrive.com&#x2F;news&#x2F;38129&#x2F;elon-musk-promised-1-million-tesla-robotaxis-by-the-end-of-2020-where-are-they" rel="nofollow">https:&#x2F;&#x2F;www.thedrive.com&#x2F;news&#x2F;38129&#x2F;elon-musk-promised-1-mil...</a><p>Tesla claimed Hardware 3 would be capable of full self-driving. When asked about Hardware 3 at Tesla&#x27;s recent robotaxi event, Musk didn&#x27;t want to &quot;get nuanced&quot;. That&#x27;s starting to look like fraud: <a href="https:&#x2F;&#x2F;electrek.co&#x2F;2024&#x2F;10&#x2F;15&#x2F;tesla-needs-to-come-clean-about-hw3-before-the-word-fraud-comes-out&#x2F;" rel="nofollow">https:&#x2F;&#x2F;electrek.co&#x2F;2024&#x2F;10&#x2F;15&#x2F;tesla-needs-to-come-clean-abo...</a><p>Had Tesla simply called it &quot;driver assistance&quot; that wouldn&#x27;t be a lie. But they didn&#x27;t do that. They doubled, tripled, quadrupled down on the claim that it is &quot;full self-driving&quot; making the car &quot;an appreciating asset&quot; that it would be &quot;financially insane&quot; not to buy:<p><a href="https:&#x2F;&#x2F;www.cnbc.com&#x2F;2019&#x2F;04&#x2F;23&#x2F;elon-musk-any-other-car-than-a-tesla-in-3-years-like-owning-a-horse.html" rel="nofollow">https:&#x2F;&#x2F;www.cnbc.com&#x2F;2019&#x2F;04&#x2F;23&#x2F;elon-musk-any-other-car-than...</a><p><a href="https:&#x2F;&#x2F;edition.cnn.com&#x2F;2024&#x2F;03&#x2F;03&#x2F;cars&#x2F;musk-tesla-cars-value-ev-prices&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;edition.cnn.com&#x2F;2024&#x2F;03&#x2F;03&#x2F;cars&#x2F;musk-tesla-cars-valu...</a><p>It&#x27;s not even bullshit artistry. It&#x27;s just bullshit.<p>Lying is part of the company culture at Tesla. Musk keeps lying because the lies keep working.</div><br/><div id="41881832" class="c"><input type="checkbox" id="c-41881832" checked=""/><div class="controls bullet"><span class="by">whamlastxmas</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41879880">parent</a><span>|</span><a href="#41880058">next</a><span>|</span><label class="collapse" for="c-41881832">[-]</label><label class="expand" for="c-41881832">[3 more]</label></div><br/><div class="children"><div class="content">Most of this is extreme hyperbole and it’s really hard to believe this is a genuine good faith attempt at conversation instead of weird astroturfing, bc these tired inaccurate talking points are what come up in literally every single even remotely associated to Elon. It’s like there’s a dossier of talking points everyone is sharing<p>The car drives itself. This is literally undeniable. You can test it today for free. Yeah it doesn’t have the last 0.01% done yet and yeah that’s probably a lot of work. But commenting like the GP is exhausting and just not reflective of reality</div><br/><div id="41883818" class="c"><input type="checkbox" id="c-41883818" checked=""/><div class="controls bullet"><span class="by">peutetre</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41881832">parent</a><span>|</span><a href="#41882109">next</a><span>|</span><label class="collapse" for="c-41883818">[-]</label><label class="expand" for="c-41883818">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>bc these tired inaccurate talking points are what come up in literally every single even remotely associated to Elon</i><p>You understand that the false claims, the inaccuracies, and the lies come <i>from</i> Elon, right? They&#x27;re associated with him because he is the source of them.<p>They&#x27;re only tired because he&#x27;s been telling the same lie year after year.</div><br/></div></div><div id="41882109" class="c"><input type="checkbox" id="c-41882109" checked=""/><div class="controls bullet"><span class="by">jqpabc123</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41881832">parent</a><span>|</span><a href="#41883818">prev</a><span>|</span><a href="#41880058">next</a><span>|</span><label class="collapse" for="c-41882109">[-]</label><label class="expand" for="c-41882109">[1 more]</label></div><br/><div class="children"><div class="content"><i>... not reflective of reality</i><p>Kinda like repeated claims of &quot;Full Self Driving&quot; for over a decade.</div><br/></div></div></div></div></div></div></div></div><div id="41880058" class="c"><input type="checkbox" id="c-41880058" checked=""/><div class="controls bullet"><span class="by">enslavedrobot</span><span>|</span><a href="#41878712">parent</a><span>|</span><a href="#41879568">prev</a><span>|</span><a href="#41885194">next</a><span>|</span><label class="collapse" for="c-41880058">[-]</label><label class="expand" for="c-41880058">[9 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a video of FSD driving the same route as a waymo 42% faster with zero interventions. 23 min vs 33. This is my everyday. Enjoy.<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;Kswp1DwUAAI?si=rX4L5FhMrPXpGx4V" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;Kswp1DwUAAI?si=rX4L5FhMrPXpGx4V</a></div><br/><div id="41880348" class="c"><input type="checkbox" id="c-41880348" checked=""/><div class="controls bullet"><span class="by">ck2</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41880058">parent</a><span>|</span><a href="#41880841">next</a><span>|</span><label class="collapse" for="c-41880348">[-]</label><label class="expand" for="c-41880348">[7 more]</label></div><br/><div class="children"><div class="content">There are also endless videos of teslas driving into pedestrians, plowing full speed into emergency vehicles parked with flashing lights, veering wildly from strange markings on the road, etc. etc.<p>&quot;works for me&quot; is a very strange response for someone on Hacker News if you have any coding background - you should realize you are a beta tester unwittingly if not a full blown alpha tester in some cases<p>All it will take is a non-standard event happening on your daily drive. Most certainly not wishing it on you, quite the opposite, trying to get you to accept that a perfect drive 99 times out of 100 is not enough.</div><br/><div id="41880614" class="c"><input type="checkbox" id="c-41880614" checked=""/><div class="controls bullet"><span class="by">enslavedrobot</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41880348">parent</a><span>|</span><a href="#41880841">next</a><span>|</span><label class="collapse" for="c-41880614">[-]</label><label class="expand" for="c-41880614">[6 more]</label></div><br/><div class="children"><div class="content">Those are Autopilot videos this discussion is about FSD. FSD has driven ~2 billion miles at this point and had potentially 2 fatal accidents.<p>The US average is 1.33 deaths&#x2F;100 million miles. Tesla on FSD is easily 10x safer.<p>Every day it gets safer.</div><br/><div id="41890087" class="c"><input type="checkbox" id="c-41890087" checked=""/><div class="controls bullet"><span class="by">hilux</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41880614">parent</a><span>|</span><a href="#41881791">next</a><span>|</span><label class="collapse" for="c-41890087">[-]</label><label class="expand" for="c-41890087">[3 more]</label></div><br/><div class="children"><div class="content">Considering HN is mostly technologists, the extent of Tesla-hate in here surprises me. My best guess is that it is sublimated Elon-hate. (Not a fan of my former neighbor myself, but let&#x27;s separate the man from his creations.)<p>People seem to be comparing Tesla FSD to perfection, when the more fair and relevant comparison is to real-world American drivers. Who are, on average, pretty bad.<p>Sure, I wouldn&#x27;t trust data coming from Tesla. But we have government data.</div><br/><div id="41897149" class="c"><input type="checkbox" id="c-41897149" checked=""/><div class="controls bullet"><span class="by">lowbloodsugar</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41890087">parent</a><span>|</span><a href="#41881791">next</a><span>|</span><label class="collapse" for="c-41897149">[-]</label><label class="expand" for="c-41897149">[2 more]</label></div><br/><div class="children"><div class="content">That seems an odd take. This is a technologist website, and a good number of technologists believe in building robust systems that don’t fail in production. We don’t stand for demos, and we have to fight off consultants peddling crapware that demos well but dies in production. 
I own a Tesla, despite my dislike of Musk, because it is an insanely fun car. I will never enable FSD, did not even do so when it was free. I see even the best teams have production outages. Until Tesla legally accepts, and the laws allows them to, legal responsibility, and until it’s good enough that it doesn’t disengage, ever, then I’m never using it and nobody else should.</div><br/><div id="41900413" class="c"><input type="checkbox" id="c-41900413" checked=""/><div class="controls bullet"><span class="by">hilux</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41897149">parent</a><span>|</span><a href="#41881791">next</a><span>|</span><label class="collapse" for="c-41900413">[-]</label><label class="expand" for="c-41900413">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ... systems that don’t fail in production.<p>I&#x27;ll say it again: &quot;compared to what?&quot;</div><br/></div></div></div></div></div></div><div id="41881791" class="c"><input type="checkbox" id="c-41881791" checked=""/><div class="controls bullet"><span class="by">diggernet</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41880614">parent</a><span>|</span><a href="#41890087">prev</a><span>|</span><a href="#41880841">next</a><span>|</span><label class="collapse" for="c-41881791">[-]</label><label class="expand" for="c-41881791">[2 more]</label></div><br/><div class="children"><div class="content">How many miles does it have on the latest software?
Because any miles driven on previous software are no longer relevant.
Especially with that big change in v12.</div><br/><div id="41883175" class="c"><input type="checkbox" id="c-41883175" checked=""/><div class="controls bullet"><span class="by">enslavedrobot</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41881791">parent</a><span>|</span><a href="#41880841">next</a><span>|</span><label class="collapse" for="c-41883175">[-]</label><label class="expand" for="c-41883175">[1 more]</label></div><br/><div class="children"><div class="content">The miles driven are rising exponentially as the versions improve according to company filings. If the miles driven on previous versions are no longer relevant how can the NHTSA investigation of previous versions impact FSD regulation today?<p>Given that the performance has improved dramatically over the last 6 months, it is very reasonable to assume that the miles driven to fatality ratio also improving.<p>Using the value of 1.33 deaths per 100 million miles driven vs 2 deaths in 2 billion miles driven, FSD has saved approximately 24 lives so far.</div><br/></div></div></div></div></div></div></div></div><div id="41880841" class="c"><input type="checkbox" id="c-41880841" checked=""/><div class="controls bullet"><span class="by">jqpabc123</span><span>|</span><a href="#41878712">root</a><span>|</span><a href="#41880058">parent</a><span>|</span><a href="#41880348">prev</a><span>|</span><a href="#41885194">next</a><span>|</span><label class="collapse" for="c-41880841">[-]</label><label class="expand" for="c-41880841">[1 more]</label></div><br/><div class="children"><div class="content">Can it drive the same route without a human behind the wheel?<p>Not legally and not according to Tesla either --- because Tesla&#x27;s FSD is not &quot;Fully Self Driving&quot; ---  unlike Waymo.</div><br/></div></div></div></div></div></div><div id="41885194" class="c"><input type="checkbox" id="c-41885194" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#41878712">prev</a><span>|</span><a href="#41889107">next</a><span>|</span><label class="collapse" for="c-41885194">[-]</label><label class="expand" for="c-41885194">[7 more]</label></div><br/><div class="children"><div class="content">&quot;Move fast and kill people&quot;<p>Look, I don&#x27;t know who needs to hear this, but just stop supporting this asshole&#x27;s companies. You don&#x27;t need internet when you&#x27;re camping, you don&#x27;t need a robot to do your laundry, you don&#x27;t need twitter, you can find more profitable and reliable places to invest.</div><br/><div id="41885221" class="c"><input type="checkbox" id="c-41885221" checked=""/><div class="controls bullet"><span class="by">hnburnsy</span><span>|</span><a href="#41885194">parent</a><span>|</span><a href="#41891857">next</a><span>|</span><label class="collapse" for="c-41885221">[-]</label><label class="expand" for="c-41885221">[2 more]</label></div><br/><div class="children"><div class="content">Move slow and kill people...<p>GM ignition switch deaths 124<p><a href="https:&#x2F;&#x2F;money.cnn.com&#x2F;2015&#x2F;12&#x2F;10&#x2F;news&#x2F;companies&#x2F;gm-recall-ignition-switch-death-toll&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;money.cnn.com&#x2F;2015&#x2F;12&#x2F;10&#x2F;news&#x2F;companies&#x2F;gm-recall-ig...</a></div><br/><div id="41887288" class="c"><input type="checkbox" id="c-41887288" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#41885194">root</a><span>|</span><a href="#41885221">parent</a><span>|</span><a href="#41891857">next</a><span>|</span><label class="collapse" for="c-41887288">[-]</label><label class="expand" for="c-41887288">[1 more]</label></div><br/><div class="children"><div class="content">And?</div><br/></div></div></div></div><div id="41891857" class="c"><input type="checkbox" id="c-41891857" checked=""/><div class="controls bullet"><span class="by">CrimsonRain</span><span>|</span><a href="#41885194">parent</a><span>|</span><a href="#41885221">prev</a><span>|</span><a href="#41885217">next</a><span>|</span><label class="collapse" for="c-41891857">[-]</label><label class="expand" for="c-41891857">[3 more]</label></div><br/><div class="children"><div class="content">Nobody needs to hear your nonsense rants. A 50k model 3 makes almost all offerings up to 80k (including electrics) from legacy automakers look like garbage.</div><br/><div id="41892902" class="c"><input type="checkbox" id="c-41892902" checked=""/><div class="controls bullet"><span class="by">leoh</span><span>|</span><a href="#41885194">root</a><span>|</span><a href="#41891857">parent</a><span>|</span><a href="#41893299">next</a><span>|</span><label class="collapse" for="c-41892902">[-]</label><label class="expand" for="c-41892902">[1 more]</label></div><br/><div class="children"><div class="content">I read their &quot;nonsense rant&quot; and I appreciated it.<p>&gt;A 50k model 3 makes almost all offerings up to 80k (including electrics) from legacy automakers look like garbage.<p>This is a nonsense rant in my opinion.</div><br/></div></div><div id="41893299" class="c"><input type="checkbox" id="c-41893299" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#41885194">root</a><span>|</span><a href="#41891857">parent</a><span>|</span><a href="#41892902">prev</a><span>|</span><a href="#41885217">next</a><span>|</span><label class="collapse" for="c-41893299">[-]</label><label class="expand" for="c-41893299">[1 more]</label></div><br/><div class="children"><div class="content">Found the guy who bought $TSLA at its ATH</div><br/></div></div></div></div><div id="41885217" class="c"><input type="checkbox" id="c-41885217" checked=""/><div class="controls bullet"><span class="by">hnburnsy</span><span>|</span><a href="#41885194">parent</a><span>|</span><a href="#41891857">prev</a><span>|</span><a href="#41889107">next</a><span>|</span><label class="collapse" for="c-41885217">[-]</label><label class="expand" for="c-41885217">[1 more]</label></div><br/><div class="children"><div class="content">Move slow and kill peo</div><br/></div></div></div></div><div id="41889107" class="c"><input type="checkbox" id="c-41889107" checked=""/><div class="controls bullet"><span class="by">frabjoused</span><span>|</span><a href="#41885194">prev</a><span>|</span><a href="#41896997">next</a><span>|</span><label class="collapse" for="c-41889107">[-]</label><label class="expand" for="c-41889107">[7 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand why this debate&#x2F;probing is not just data driven. Driving is all big data.<p><a href="https:&#x2F;&#x2F;www.tesla.com&#x2F;VehicleSafetyReport" rel="nofollow">https:&#x2F;&#x2F;www.tesla.com&#x2F;VehicleSafetyReport</a><p>This report does not include fatalities, which seems to be the key point in question. Unless the above report has some bias or is false, Teslas in autopilot appear 10 times safer than the US average.<p>Is there public data on deaths reported by Tesla?<p>And otherwise, if the stats say it is safer, why is there any debate at all?</div><br/><div id="41889437" class="c"><input type="checkbox" id="c-41889437" checked=""/><div class="controls bullet"><span class="by">jsight</span><span>|</span><a href="#41889107">parent</a><span>|</span><a href="#41889250">next</a><span>|</span><label class="collapse" for="c-41889437">[-]</label><label class="expand" for="c-41889437">[1 more]</label></div><br/><div class="children"><div class="content">The report from Tesla is very biased. It doesn&#x27;t normalize for the difficulty of the conditions involved, and is basically for marketing purposes.<p>IMO, the challenge for NHTSA is that they can get tremendous detail from Tesla but not from other makes. This will make it very difficult for them to get a solid baseline for collisions due to glare in non-FSD equipped vehicles.</div><br/></div></div><div id="41889250" class="c"><input type="checkbox" id="c-41889250" checked=""/><div class="controls bullet"><span class="by">JTatters</span><span>|</span><a href="#41889107">parent</a><span>|</span><a href="#41889437">prev</a><span>|</span><a href="#41889261">next</a><span>|</span><label class="collapse" for="c-41889250">[-]</label><label class="expand" for="c-41889250">[1 more]</label></div><br/><div class="children"><div class="content">Those statistics are incredibly misleading.<p>- It is safe to assume that the vast majority of autopilot miles are on highways (although Tesla don&#x27;t release this information).<p>- By far the safest roads per mile driven are highways.<p>- Autopilot will engage least during the most dangerous conditions (heavy rain, snow, fog, nighttime).</div><br/></div></div><div id="41889261" class="c"><input type="checkbox" id="c-41889261" checked=""/><div class="controls bullet"><span class="by">notshift</span><span>|</span><a href="#41889107">parent</a><span>|</span><a href="#41889250">prev</a><span>|</span><a href="#41889209">next</a><span>|</span><label class="collapse" for="c-41889261">[-]</label><label class="expand" for="c-41889261">[1 more]</label></div><br/><div class="children"><div class="content">Without opening the link, the problem with every piece of data I’ve seen from Tesla is they’re comparing apples to oranges. FSD won’t activate in adverse driving conditions, aka when accidents are much more likely to occur. And&#x2F;or drivers are choosing not to use it in those conditions.</div><br/></div></div><div id="41889209" class="c"><input type="checkbox" id="c-41889209" checked=""/><div class="controls bullet"><span class="by">bastawhiz</span><span>|</span><a href="#41889107">parent</a><span>|</span><a href="#41889261">prev</a><span>|</span><a href="#41889273">next</a><span>|</span><label class="collapse" for="c-41889209">[-]</label><label class="expand" for="c-41889209">[2 more]</label></div><br/><div class="children"><div class="content">Autopilot is not FSD.</div><br/><div id="41889220" class="c"><input type="checkbox" id="c-41889220" checked=""/><div class="controls bullet"><span class="by">frabjoused</span><span>|</span><a href="#41889107">root</a><span>|</span><a href="#41889209">parent</a><span>|</span><a href="#41889273">next</a><span>|</span><label class="collapse" for="c-41889220">[-]</label><label class="expand" for="c-41889220">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a good point. Are there no published numbers on FSD?</div><br/></div></div></div></div><div id="41889273" class="c"><input type="checkbox" id="c-41889273" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41889107">parent</a><span>|</span><a href="#41889209">prev</a><span>|</span><a href="#41896997">next</a><span>|</span><label class="collapse" for="c-41889273">[-]</label><label class="expand" for="c-41889273">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Unless the above report has some bias or is false<p>Welcome to Tesla.<p>The report measures accidents in FSD mode. Qualifiers to FSD mode: the conditions, weather, road, location, traffic all have to meet a certain quality threshold before the system will be enabled (or not disable itself). Compare Sunnyvale on a clear spring day to Pittsburgh December nights.<p>There&#x27;s no qualifier to the &quot;comparison&quot;: all drivers, all conditions, all weather, all roads, all location, all traffic.<p>It&#x27;s not remotely comparable, and Tesla&#x27;s data people are not that stupid, so it&#x27;s willfully misleading.<p>&gt; This report does not include fatalities<p>It also doesn&#x27;t consider any incident where there was not airbag deployment to be an accident. Sounds potentially reasonable until you consider:<p>- first gen airbag systems were primitive: collision exceeds threshold, deploy. Currently, vehicle safety systems consider duration of impact, speeds, G-forces, amount of intrusion, angle of collision, and a multitude of other factors before deciding what, if any, systems to fire (seatbelt tensioners, airbags, etc.) So hit something at 30mph with the right variables? Tesla: &quot;this is not an accident&quot;.<p>- Tesla also does not consider &quot;incident was so catastrophic that airbags COULD NOT deploy*&quot; to be an accident, because &quot;airbags didn&#x27;t deploy&quot;. This umbrella could also include egregious, &quot;systems failed to deploy for any reason up to and including poor assembly line quality control&quot;, as also not an accident and also &quot;not counted&quot;.<p>&gt; Is there public data on deaths reported by Tesla?<p>They do not.<p>They also refuse to give the public much of any data beyond these carefully curated numbers. Hell, NHTSA&#x2F;NTSB also mostly have to drag heavily redacted data kicking and screaming out of Tesla&#x27;s hands.</div><br/></div></div></div></div><div id="41896997" class="c"><input type="checkbox" id="c-41896997" checked=""/><div class="controls bullet"><span class="by">metabagel</span><span>|</span><a href="#41889107">prev</a><span>|</span><a href="#41895749">next</a><span>|</span><label class="collapse" for="c-41896997">[-]</label><label class="expand" for="c-41896997">[1 more]</label></div><br/><div class="children"><div class="content">Cruise control with automatic following distance and lane-keeping are such game changers, that autonomous driving isn’t necessary for able drivers.<p>OK, the lane-keeping isn’t quite there, but I feel like that’s solvable.</div><br/></div></div><div id="41895749" class="c"><input type="checkbox" id="c-41895749" checked=""/><div class="controls bullet"><span class="by">siliconc0w</span><span>|</span><a href="#41896997">prev</a><span>|</span><a href="#41885023">next</a><span>|</span><label class="collapse" for="c-41895749">[-]</label><label class="expand" for="c-41895749">[1 more]</label></div><br/><div class="children"><div class="content">Traffic jams and long monotonous roads are really where these features, getting to level 3 on those should be the focus over trying to maintain a fiction of level 5 everywhere.  (And like other comments, &gt;2 should automatically mean liability)</div><br/></div></div><div id="41885023" class="c"><input type="checkbox" id="c-41885023" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#41895749">prev</a><span>|</span><a href="#41896331">next</a><span>|</span><label class="collapse" for="c-41885023">[-]</label><label class="expand" for="c-41885023">[23 more]</label></div><br/><div class="children"><div class="content">My Tesla routinely tries to kill me on absolutely normal California roads in normal sunny conditions, especially when there are cars parked on the side of the road (it often brakes thinking I&#x27;m about to crash into them, or even swerves into them thinking that&#x27;s the &quot;real&quot; lane).<p>Elon&#x27;s Unsupervised FSD dreams are a good bit off. I do hope they happen though.</div><br/><div id="41885102" class="c"><input type="checkbox" id="c-41885102" checked=""/><div class="controls bullet"><span class="by">jrflowers</span><span>|</span><a href="#41885023">parent</a><span>|</span><a href="#41885402">next</a><span>|</span><label class="collapse" for="c-41885102">[-]</label><label class="expand" for="c-41885102">[3 more]</label></div><br/><div class="children"><div class="content">&gt; My Tesla routinely tries to kill me<p>&gt; Elon&#x27;s Unsupervised FSD dreams are a good bit off. I do hope they happen though.<p>It is very generous that you would selflessly sacrifice your own life so that others might one day enjoy Elon’s dream of robot taxis without steering wheels</div><br/><div id="41885140" class="c"><input type="checkbox" id="c-41885140" checked=""/><div class="controls bullet"><span class="by">massysett</span><span>|</span><a href="#41885023">root</a><span>|</span><a href="#41885102">parent</a><span>|</span><a href="#41885583">next</a><span>|</span><label class="collapse" for="c-41885140">[-]</label><label class="expand" for="c-41885140">[1 more]</label></div><br/><div class="children"><div class="content">Even more generous to selflessly sacrifice the lives and property of others that the vehicle &quot;self-drives&quot; itself into.</div><br/></div></div><div id="41885583" class="c"><input type="checkbox" id="c-41885583" checked=""/><div class="controls bullet"><span class="by">judge2020</span><span>|</span><a href="#41885023">root</a><span>|</span><a href="#41885102">parent</a><span>|</span><a href="#41885140">prev</a><span>|</span><a href="#41885402">next</a><span>|</span><label class="collapse" for="c-41885583">[-]</label><label class="expand" for="c-41885583">[1 more]</label></div><br/><div class="children"><div class="content">If the data sharing checkboxes are clicked, OP can still help send in training data while driving on his own.</div><br/></div></div></div></div><div id="41885402" class="c"><input type="checkbox" id="c-41885402" checked=""/><div class="controls bullet"><span class="by">left-struck</span><span>|</span><a href="#41885023">parent</a><span>|</span><a href="#41885102">prev</a><span>|</span><a href="#41888890">next</a><span>|</span><label class="collapse" for="c-41885402">[-]</label><label class="expand" for="c-41885402">[1 more]</label></div><br/><div class="children"><div class="content">That’s hilariously ironic because I have a pretty standard newish Japanese petrol car (I’m not mentioning the brand because my point isn’t that brand x is better than brand y), and it has no ai self driving functions just pretty basic radar adaptive cruise control and emergency brake assist where it will stop if there’s a car brake hard in front of you… and it does a remarkable job at rejecting cars which are slowing down or stopped in other lanes, even when you’re going around a corner and the car is pointing straight towards the other cars but not actually heading towards them since it’s turning. I assume they are using the steering input to help reject other vehicles and dopler effects to detect differences in speed, but it’s remarkable how accurate it is at matching the speed of the car in front of you and only the car in front of you, even when that car is over 15 seconds in front of you. If teslas can’t beat that, it’s sad</div><br/></div></div><div id="41888890" class="c"><input type="checkbox" id="c-41888890" checked=""/><div class="controls bullet"><span class="by">gitaarik</span><span>|</span><a href="#41885023">parent</a><span>|</span><a href="#41885402">prev</a><span>|</span><a href="#41885232">next</a><span>|</span><label class="collapse" for="c-41888890">[-]</label><label class="expand" for="c-41888890">[2 more]</label></div><br/><div class="children"><div class="content">I wonder, how are you &quot;driving&quot;? Are you sitting behind the wheel doing nothing except watch really good everything the car does so you can take over when needed? Isn&#x27;t that a stressful experience? Wouldn&#x27;t it be more comfortable to just do everything yourself so you know nothing weird can happen?<p>Also, if the car does something crazy, how much time do you have to react? I can imagine in some situations you might have too little time to prevent the accident the car is creating.</div><br/><div id="41892228" class="c"><input type="checkbox" id="c-41892228" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#41885023">root</a><span>|</span><a href="#41888890">parent</a><span>|</span><a href="#41885232">next</a><span>|</span><label class="collapse" for="c-41892228">[-]</label><label class="expand" for="c-41892228">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Isn&#x27;t that a stressful experience?<p>It&#x27;s actually really easy and kind of relaxing. For long drives, it dramatically reduces cognitive load leading to less fatigue and more alertness on the road.<p>My hand is always on the wheel so I can react as soon as I feel the car doing something weird.</div><br/></div></div></div></div><div id="41885232" class="c"><input type="checkbox" id="c-41885232" checked=""/><div class="controls bullet"><span class="by">bogantech</span><span>|</span><a href="#41885023">parent</a><span>|</span><a href="#41888890">prev</a><span>|</span><a href="#41885038">next</a><span>|</span><label class="collapse" for="c-41885232">[-]</label><label class="expand" for="c-41885232">[2 more]</label></div><br/><div class="children"><div class="content">&gt; My Tesla routinely tries to kill me<p>Why on earth would you continue to use it? If it does succeed someday that&#x27;s on you</div><br/><div id="41887432" class="c"><input type="checkbox" id="c-41887432" checked=""/><div class="controls bullet"><span class="by">newdee</span><span>|</span><a href="#41885023">root</a><span>|</span><a href="#41885232">parent</a><span>|</span><a href="#41885038">next</a><span>|</span><label class="collapse" for="c-41887432">[-]</label><label class="expand" for="c-41887432">[1 more]</label></div><br/><div class="children"><div class="content">&gt; that’s on you<p>They’d be dead, doubt it’s a concern at that point.</div><br/></div></div></div></div><div id="41885038" class="c"><input type="checkbox" id="c-41885038" checked=""/><div class="controls bullet"><span class="by">delichon</span><span>|</span><a href="#41885023">parent</a><span>|</span><a href="#41885232">prev</a><span>|</span><a href="#41885155">next</a><span>|</span><label class="collapse" for="c-41885038">[-]</label><label class="expand" for="c-41885038">[3 more]</label></div><br/><div class="children"><div class="content">Why do you drive a car that routinely tries to kill you? That would put me right off. Can&#x27;t you just turn off the autopilot?</div><br/><div id="41885076" class="c"><input type="checkbox" id="c-41885076" checked=""/><div class="controls bullet"><span class="by">ddingus</span><span>|</span><a href="#41885023">root</a><span>|</span><a href="#41885038">parent</a><span>|</span><a href="#41886018">next</a><span>|</span><label class="collapse" for="c-41885076">[-]</label><label class="expand" for="c-41885076">[1 more]</label></div><br/><div class="children"><div class="content">My guess is the driver tests it regularly.<p>How does it do X, Y, ooh Z works, etc...</div><br/></div></div><div id="41886018" class="c"><input type="checkbox" id="c-41886018" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#41885023">root</a><span>|</span><a href="#41885038">parent</a><span>|</span><a href="#41885076">prev</a><span>|</span><a href="#41885155">next</a><span>|</span><label class="collapse" for="c-41886018">[-]</label><label class="expand" for="c-41886018">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a pretty nice car when it&#x27;s not trying to kill me</div><br/></div></div></div></div><div id="41885155" class="c"><input type="checkbox" id="c-41885155" checked=""/><div class="controls bullet"><span class="by">Renaud</span><span>|</span><a href="#41885023">parent</a><span>|</span><a href="#41885038">prev</a><span>|</span><a href="#41885170">next</a><span>|</span><label class="collapse" for="c-41885155">[-]</label><label class="expand" for="c-41885155">[3 more]</label></div><br/><div class="children"><div class="content">And what if the car swerves, and you aren&#x27;t able to correct in time and end up killing someone?<p>Is that your fault or the car&#x27;s?<p>I would bet that since it&#x27;s your car, and you&#x27;re using a knowingly unproven technology, it would be your fault?</div><br/><div id="41885160" class="c"><input type="checkbox" id="c-41885160" checked=""/><div class="controls bullet"><span class="by">ra7</span><span>|</span><a href="#41885023">root</a><span>|</span><a href="#41885155">parent</a><span>|</span><a href="#41885170">next</a><span>|</span><label class="collapse" for="c-41885160">[-]</label><label class="expand" for="c-41885160">[2 more]</label></div><br/><div class="children"><div class="content">The driver’s fault. Tesla never accepts liability.</div><br/><div id="41885952" class="c"><input type="checkbox" id="c-41885952" checked=""/><div class="controls bullet"><span class="by">LunicLynx</span><span>|</span><a href="#41885023">root</a><span>|</span><a href="#41885160">parent</a><span>|</span><a href="#41885170">next</a><span>|</span><label class="collapse" for="c-41885952">[-]</label><label class="expand" for="c-41885952">[1 more]</label></div><br/><div class="children"><div class="content">And they have been very clear about that</div><br/></div></div></div></div></div></div></div></div><div id="41896331" class="c"><input type="checkbox" id="c-41896331" checked=""/><div class="controls bullet"><span class="by">TeslaCoils</span><span>|</span><a href="#41885023">prev</a><span>|</span><a href="#41884966">next</a><span>|</span><label class="collapse" for="c-41896331">[-]</label><label class="expand" for="c-41896331">[1 more]</label></div><br/><div class="children"><div class="content">Works most of the time, Fails at the worst time - Supervision absolutely necessary...</div><br/></div></div><div id="41884966" class="c"><input type="checkbox" id="c-41884966" checked=""/><div class="controls bullet"><span class="by">graeme</span><span>|</span><a href="#41896331">prev</a><span>|</span><a href="#41880878">next</a><span>|</span><label class="collapse" for="c-41884966">[-]</label><label class="expand" for="c-41884966">[20 more]</label></div><br/><div class="children"><div class="content">Will the review assess overall mortality of the vehicles compared to similar cars, and overall mortality while FSD is in use?</div><br/><div id="41885159" class="c"><input type="checkbox" id="c-41885159" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#41884966">parent</a><span>|</span><a href="#41884993">next</a><span>|</span><label class="collapse" for="c-41885159">[-]</label><label class="expand" for="c-41885159">[5 more]</label></div><br/><div class="children"><div class="content">I get where you’re coming from and would also be interested to see, but based on the clips I’ve seen that wouldn’t be enough in this case. Of course the bias is inherent in what people choose to post (not normal <i>and</i> not terrible&#x2F;litigable), but I think there’s enough at this point to perceive a stable pattern.<p>Long story short, my argument is this: it doesn’t matter if you reduce serious crashes from 100PPM to 50PPM if 25PPM of those are <i>new</i> crash sources, speaking from a psychological and sociological perspective. Everyone should know that driving drunk, driving distracted, driving in bad weather, and in rural areas at dawn or dusk is dangerous, and takes appropriate precautions. But what do you do if your car might crash because someone ahead flashed their high beams, or because the sun was reflecting off another car in an unusual way? Could you really load up your kids and take your hands off the wheel knowing that at any moment you might hit an unexpected edge condition?<p>Self driving cars are (presumably!) hard enough to trust already, since you’re giving away so much control. There’s a reason planes have to be way more than “better, statistically speaking” — we expect them to be nearly flawless, safety-wise.</div><br/><div id="41885169" class="c"><input type="checkbox" id="c-41885169" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885159">parent</a><span>|</span><a href="#41884993">next</a><span>|</span><label class="collapse" for="c-41885169">[-]</label><label class="expand" for="c-41885169">[4 more]</label></div><br/><div class="children"><div class="content">&gt; But what do you do if your car might crash because someone ahead flashed their high beams, or because the sun was reflecting off another car in an unusual way?<p>These are -- like drunk driving, driving distract, and driving in bad weather -- things that actually do cause accidents with human drivers.</div><br/><div id="41885289" class="c"><input type="checkbox" id="c-41885289" checked=""/><div class="controls bullet"><span class="by">hunter-gatherer</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885169">parent</a><span>|</span><a href="#41885316">next</a><span>|</span><label class="collapse" for="c-41885289">[-]</label><label class="expand" for="c-41885289">[1 more]</label></div><br/><div class="children"><div class="content">The point is the choice of taking precaution part that you left out of the quote. The other day I was taking my kid to school, and when we turned east the sun was in my eyes and I couldn&#x27;t see anything, so I pulled over as fast as I could and changed my route. Had I chosen to press forward and been in an accident, it is explainable (albeit still unfortunate and often unnecessary!). However, if I&#x27;m under the impression that my robot car can handle such circumstances because it does most of the time and then it glitches, that is harder to explain.</div><br/></div></div><div id="41885316" class="c"><input type="checkbox" id="c-41885316" checked=""/><div class="controls bullet"><span class="by">paulryanrogers</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885169">parent</a><span>|</span><a href="#41885289">prev</a><span>|</span><a href="#41885311">next</a><span>|</span><label class="collapse" for="c-41885316">[-]</label><label class="expand" for="c-41885316">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, yet humans can anticipate such things and rely on their experience to reason about what&#x27;s happening and how to react. Like slow down or shift lanes or just move ones head for a different perfective. A Tesla with only two cameras (&quot;because that&#x27;s all humans need&quot;) is unlikely to provably match that performance for a long time.<p>Tesla could also change its software without telling the driver at any point.</div><br/></div></div><div id="41885311" class="c"><input type="checkbox" id="c-41885311" checked=""/><div class="controls bullet"><span class="by">dfxm12</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885169">parent</a><span>|</span><a href="#41885316">prev</a><span>|</span><a href="#41884993">next</a><span>|</span><label class="collapse" for="c-41885311">[-]</label><label class="expand" for="c-41885311">[1 more]</label></div><br/><div class="children"><div class="content">This language is a bit of a sticking point for me. If you&#x27;re drunk driving or driving distracted, there&#x27;s no &quot;accident&quot;. You&#x27;re <i>intentionally</i> doing something wrong and <i>committing a crime</i>.</div><br/></div></div></div></div></div></div><div id="41884993" class="c"><input type="checkbox" id="c-41884993" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#41884966">parent</a><span>|</span><a href="#41885159">prev</a><span>|</span><a href="#41885407">next</a><span>|</span><label class="collapse" for="c-41884993">[-]</label><label class="expand" for="c-41884993">[1 more]</label></div><br/><div class="children"><div class="content">No, that is not part of a review.  They may use some reference aggregated industry data, but it&#x27;s out of scope to answwer the question I think you&#x27;re trying to imply.</div><br/></div></div><div id="41885407" class="c"><input type="checkbox" id="c-41885407" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41884966">parent</a><span>|</span><a href="#41884993">prev</a><span>|</span><a href="#41885312">next</a><span>|</span><label class="collapse" for="c-41885407">[-]</label><label class="expand" for="c-41885407">[5 more]</label></div><br/><div class="children"><div class="content">Fatalities per passenger mile driven is the only statistic that would matter.  I actually doubt this figure differs much,  either way,  from the overall fleet of vehicles.<p>This is because &quot;inattentive driving&quot; is _rarely_ the cause of fatalities on the road.  The winner there is,  and probably always will be,  Alcohol.</div><br/><div id="41885496" class="c"><input type="checkbox" id="c-41885496" checked=""/><div class="controls bullet"><span class="by">porphyra</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885407">parent</a><span>|</span><a href="#41885470">next</a><span>|</span><label class="collapse" for="c-41885496">[-]</label><label class="expand" for="c-41885496">[2 more]</label></div><br/><div class="children"><div class="content">Distracted driving cost 3308 lives in 2022 [1].<p>Alcohol is at 13384 in 2021 [2].<p>Although you&#x27;re right that alcohol does claim more lives, distracted driving is still highly dangerous and isn&#x27;t all that rare.<p>[1] <a href="https:&#x2F;&#x2F;www.nhtsa.gov&#x2F;risky-driving&#x2F;distracted-driving" rel="nofollow">https:&#x2F;&#x2F;www.nhtsa.gov&#x2F;risky-driving&#x2F;distracted-driving</a><p>[2] <a href="https:&#x2F;&#x2F;www.nhtsa.gov&#x2F;book&#x2F;countermeasures-that-work&#x2F;alcohol-impaired-driving" rel="nofollow">https:&#x2F;&#x2F;www.nhtsa.gov&#x2F;book&#x2F;countermeasures-that-work&#x2F;alcohol...</a></div><br/><div id="41885593" class="c"><input type="checkbox" id="c-41885593" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885496">parent</a><span>|</span><a href="#41885470">next</a><span>|</span><label class="collapse" for="c-41885593">[-]</label><label class="expand" for="c-41885593">[1 more]</label></div><br/><div class="children"><div class="content">They do a disservice by not further breaking down distracted driving by age.  Once you see it that way it&#x27;s hard to accept that distracted driving on it&#x27;s own is the appropriate target.<p>Anyways..  NHTSA publishes the FARS.  This is the definitive source if you want to understand the demographics of fatalities in the USA.<p><a href="https:&#x2F;&#x2F;www.nhtsa.gov&#x2F;research-data&#x2F;fatality-analysis-reporting-system-fars" rel="nofollow">https:&#x2F;&#x2F;www.nhtsa.gov&#x2F;research-data&#x2F;fatality-analysis-report...</a></div><br/></div></div></div></div><div id="41885470" class="c"><input type="checkbox" id="c-41885470" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885407">parent</a><span>|</span><a href="#41885496">prev</a><span>|</span><a href="#41885312">next</a><span>|</span><label class="collapse" for="c-41885470">[-]</label><label class="expand" for="c-41885470">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The winner there is, and probably always will be, Alcohol.<p>I&#x27;d imagine mobile device use will overtake alcohol soon enough</div><br/><div id="41885600" class="c"><input type="checkbox" id="c-41885600" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885470">parent</a><span>|</span><a href="#41885312">next</a><span>|</span><label class="collapse" for="c-41885600">[-]</label><label class="expand" for="c-41885600">[1 more]</label></div><br/><div class="children"><div class="content">Mobile devices have been here for 40 years.  The volume of alcohol sold every year suggests this overtake point will never occur.</div><br/></div></div></div></div></div></div><div id="41885312" class="c"><input type="checkbox" id="c-41885312" checked=""/><div class="controls bullet"><span class="by">FireBeyond</span><span>|</span><a href="#41884966">parent</a><span>|</span><a href="#41885407">prev</a><span>|</span><a href="#41885048">next</a><span>|</span><label class="collapse" for="c-41885312">[-]</label><label class="expand" for="c-41885312">[3 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re trying to hint at Tesla&#x27;s own stats, then at this point those are hopelessly, and knowingly, misleading.<p>All they compare is &quot;On the subsets of driving on only the roads where FSD is available, active, and has not or did not turn itself off because of weather, road, traffic or any other conditions&quot; versus &quot;all drivers, all vehicles, all roads, all weather, all traffic, all conditions&quot;.<p>There&#x27;s a reason Tesla doesn&#x27;t release the raw data.</div><br/><div id="41885381" class="c"><input type="checkbox" id="c-41885381" checked=""/><div class="controls bullet"><span class="by">rblatz</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885312">parent</a><span>|</span><a href="#41885048">next</a><span>|</span><label class="collapse" for="c-41885381">[-]</label><label class="expand" for="c-41885381">[2 more]</label></div><br/><div class="children"><div class="content">I have to disengage FSD multiple times a day and I’m only driving 16 miles round trip. And routinely have to stop it from doing dumb things like stopping at green traffic lights, attempting to do a u turn from the wrong turn lane, or switching to the wrong lane right before a turn.</div><br/><div id="41889993" class="c"><input type="checkbox" id="c-41889993" checked=""/><div class="controls bullet"><span class="by">rad_gruchalski</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885381">parent</a><span>|</span><a href="#41885048">next</a><span>|</span><label class="collapse" for="c-41889993">[-]</label><label class="expand" for="c-41889993">[1 more]</label></div><br/><div class="children"><div class="content">Why would you even turn it on at this point…</div><br/></div></div></div></div></div></div><div id="41885048" class="c"><input type="checkbox" id="c-41885048" checked=""/><div class="controls bullet"><span class="by">infamouscow</span><span>|</span><a href="#41884966">parent</a><span>|</span><a href="#41885312">prev</a><span>|</span><a href="#41885028">next</a><span>|</span><label class="collapse" for="c-41885048">[-]</label><label class="expand" for="c-41885048">[3 more]</label></div><br/><div class="children"><div class="content">Lawyers are not known for their prowess in mathematics, let alone statistics.<p>Making these arguments from the standpoint of an engineer is counterproductive.</div><br/><div id="41885247" class="c"><input type="checkbox" id="c-41885247" checked=""/><div class="controls bullet"><span class="by">fallingknife</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885048">parent</a><span>|</span><a href="#41885028">next</a><span>|</span><label class="collapse" for="c-41885247">[-]</label><label class="expand" for="c-41885247">[2 more]</label></div><br/><div class="children"><div class="content">Which is why they are the wrong people to run the country</div><br/><div id="41885342" class="c"><input type="checkbox" id="c-41885342" checked=""/><div class="controls bullet"><span class="by">paulryanrogers</span><span>|</span><a href="#41884966">root</a><span>|</span><a href="#41885247">parent</a><span>|</span><a href="#41885028">next</a><span>|</span><label class="collapse" for="c-41885342">[-]</label><label class="expand" for="c-41885342">[1 more]</label></div><br/><div class="children"><div class="content">Whom? Because math is important and so is law, among a variety of other things.<p>s&#x2F; Thankfully the US presidential choices are at least rational, of sound mind, and well rounded people. Certainly no spoiled man children among them. &#x2F;s</div><br/></div></div></div></div></div></div><div id="41885090" class="c"><input type="checkbox" id="c-41885090" checked=""/><div class="controls bullet"><span class="by">johnthebaptist</span><span>|</span><a href="#41884966">parent</a><span>|</span><a href="#41885028">prev</a><span>|</span><a href="#41880878">next</a><span>|</span><label class="collapse" for="c-41885090">[-]</label><label class="expand" for="c-41885090">[1 more]</label></div><br/><div class="children"><div class="content">Yes, if tesla complies and provides that data</div><br/></div></div></div></div><div id="41880878" class="c"><input type="checkbox" id="c-41880878" checked=""/><div class="controls bullet"><span class="by">aanet</span><span>|</span><a href="#41884966">prev</a><span>|</span><a href="#41894599">next</a><span>|</span><label class="collapse" for="c-41880878">[-]</label><label class="expand" for="c-41880878">[3 more]</label></div><br/><div class="children"><div class="content">About damn time NHTSA opened this full scale investigation. Tesla&#x27;s &quot;autonowashing&quot; has gone on for far too long.<p>Per Reuters [1] 
&quot;The probe covers 2016-2024 Model S and X vehicles with the optional system as well as 2017-2024 Model 3, 2020-2024 Model Y, and 2023-2024 Cybertruck vehicles.
The preliminary evaluation is the first step before the agency could seek to demand a recall of the vehicles if it believes they pose an unreasonable risk to safety.&quot;<p>Roughly 2.4 million Teslas in question, with &quot;Full Self Driving&quot; software after 4 reported collisions and one fatality.<p>NHTSA is reviewing the ability of FSD’s engineering controls to &quot;detect and respond appropriately to reduced roadway visibility conditions.&quot;<p>Tesla has, of course, rather two-facedly called its FSD as SAE Level-2 for regulatory purposes, while selling its &quot;full self driving&quot; but also requiring supervision. ¯\_(ツ)_&#x2F;¯ ¯\_(ツ)_&#x2F;¯<p>No other company has been so irresponsible to its users, and without a care for any negative externalities imposed on non-consenting road users.<p>I treat every Tesla driver as a drunk driver, steering away whenever I see them on highways.<p>[FWIW, yes, I work in automated driving and know a thing or two about automotive safety.]<p>[1] <a href="https:&#x2F;&#x2F;archive.is&#x2F;20241018151106&#x2F;https:&#x2F;&#x2F;www.reuters.com&#x2F;business&#x2F;autos-transportation&#x2F;nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18&#x2F;#selection-1453.0-1457.165" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;20241018151106&#x2F;https:&#x2F;&#x2F;www.reuters.com&#x2F;bu...</a></div><br/><div id="41893484" class="c"><input type="checkbox" id="c-41893484" checked=""/><div class="controls bullet"><span class="by">buzzert</span><span>|</span><a href="#41880878">parent</a><span>|</span><a href="#41883520">next</a><span>|</span><label class="collapse" for="c-41893484">[-]</label><label class="expand" for="c-41893484">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I treat every Tesla driver as a drunk driver, steering away whenever I see them on highways.<p>Would you rather drive near a drunk driver using Tesla&#x27;s FSD, or one without FSD?</div><br/></div></div><div id="41883520" class="c"><input type="checkbox" id="c-41883520" checked=""/><div class="controls bullet"><span class="by">ivewonyoung</span><span>|</span><a href="#41880878">parent</a><span>|</span><a href="#41893484">prev</a><span>|</span><a href="#41894599">next</a><span>|</span><label class="collapse" for="c-41883520">[-]</label><label class="expand" for="c-41883520">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Roughly 2.4 million Teslas in question, with &quot;Full Self Driving&quot; software after 4 reported collisions and one fatality.<p>45000 people die yearly just in the US in auto accidents. Those numbers and timeline you quoted  seem insignificant at first glance magnified by people with an axe to grind like that guy running anti Tesla superbowl ads, who makes self driving software like you.</div><br/></div></div></div></div><div id="41894599" class="c"><input type="checkbox" id="c-41894599" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#41880878">prev</a><span>|</span><a href="#41891555">next</a><span>|</span><label class="collapse" for="c-41894599">[-]</label><label class="expand" for="c-41894599">[1 more]</label></div><br/><div class="children"><div class="content">Add it to the list ...<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_Tesla_Autopilot_crashes" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_Tesla_Autopilot_crashe...</a></div><br/></div></div><div id="41891555" class="c"><input type="checkbox" id="c-41891555" checked=""/><div class="controls bullet"><span class="by">lrvick</span><span>|</span><a href="#41894599">prev</a><span>|</span><a href="#41885204">next</a><span>|</span><label class="collapse" for="c-41891555">[-]</label><label class="expand" for="c-41891555">[2 more]</label></div><br/><div class="children"><div class="content">All these self driving car companies are competing to see whose proprietary firmware and sensors kill the fewest people. This is insane.<p>I will -never- own a self driving car unless the firmware is open source, reproducible, remotely attestable, and built&#x2F;audited by several security research firms and any interested security researchers from the public before all new updates ship.<p>It is the only way to avoid greedy execs from cutting corners to up profit margins like VW did with faking emissions tests.<p>Proprietary safety tech is evil, and must be made illegal. Compete with nicer looking more comfortable cars with better miles-to-charge, not peoples lives.</div><br/><div id="41891758" class="c"><input type="checkbox" id="c-41891758" checked=""/><div class="controls bullet"><span class="by">boshalfoshal</span><span>|</span><a href="#41891555">parent</a><span>|</span><a href="#41885204">next</a><span>|</span><label class="collapse" for="c-41891758">[-]</label><label class="expand" for="c-41891758">[1 more]</label></div><br/><div class="children"><div class="content">You are conflating two seperate problems (security vs functionality).<p>&quot;Firmware&quot; can be open source and secure, but how does this translate to driving performance at all? Why does it matter if the firmware is validated by security researchers, who presumably don&#x27;t know anything about motion planning, perception, etc? And this is even assuming that the code can be reasonably verified statically. You probably need to to run that code on a car for millions of miles (maybe in simulation) in an uncoutable number of scenarios to run through every edge case.<p>The other main problem with what you&#x27;re asking is that most of the &quot;alpha&quot; of these self driving companies is in proprietary _models_, not software. No one is giving up their models. That is a business edge.<p>As someone who has been at multiple AV companies, no one is cutting corners on &quot;firmware&quot; or &quot;sensors&quot; (apart from making it reasonably cost effective so normal people can buy their cars). Its just that AV is a really really really difficult problem with no closed form solution.<p>Your normal car has all the same pitfalls of &quot;unverified software running on a safety critical system,&quot; except that its easier to verify that straightforward device firmware works vs a very complex engine whose job is to ingest sensor data and output a trajectory.</div><br/></div></div></div></div><div id="41885204" class="c"><input type="checkbox" id="c-41885204" checked=""/><div class="controls bullet"><span class="by">wg0</span><span>|</span><a href="#41891555">prev</a><span>|</span><label class="collapse" for="c-41885204">[-]</label><label class="expand" for="c-41885204">[4 more]</label></div><br/><div class="children"><div class="content">In all the hype of AI etc, if you think about it then the foundational problem is that even Computer Vision is not a solved problem at the human level of accuracy and that&#x27;s at the heart of the issue of both Tesla and that Amazon checkout.<p>Otherwise as thought experiment, imagine just a tiny 1 Inch tall person glued to the grocery trolley and another sitting on each shelf - just these two alone are all you need for &quot;automated checkout&quot;.</div><br/><div id="41885275" class="c"><input type="checkbox" id="c-41885275" checked=""/><div class="controls bullet"><span class="by">vineyardmike</span><span>|</span><a href="#41885204">parent</a><span>|</span><label class="collapse" for="c-41885275">[-]</label><label class="expand" for="c-41885275">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Otherwise as thought experiment, imagine just a tiny 1 Inch tall person glued to the grocery trolley and another sitting on each shelf - just these two alone are all you need for &quot;automated checkout&quot;.<p>I don’t think this would actually work, as silly a thought experiment as it is.<p>The problem isn’t the vision, it’s state management and cost. It was very easy (but expensive) to see and classify via CV if a person picked something up, it just requires hundreds of concurrent high resolution streams and a way to stitch the global state from all the videos.<p>A little 1 inch person on each shelf needs a good way to communicate to every other tiny person what they say, and come to consensus. If 5 people&#x2F;cameras detect person A picking something up, you need to differentiate between every permutation within 5 discrete actions and 1 seen 5 times.<p>In case you didn’t know, Amazon actually hired hundreds of people in India to review the footage and correct mistakes (for training the models). They literally had a human on each shelf. And they still had issues with the state management. With people.</div><br/><div id="41885317" class="c"><input type="checkbox" id="c-41885317" checked=""/><div class="controls bullet"><span class="by">wg0</span><span>|</span><a href="#41885204">root</a><span>|</span><a href="#41885275">parent</a><span>|</span><label class="collapse" for="c-41885317">[-]</label><label class="expand" for="c-41885317">[2 more]</label></div><br/><div class="children"><div class="content">Yeah - that&#x27;s exactly is my point that humans were required to recognize and computer vision is NOT a solved problem regardless of tech bros misleading techno optimism.<p>Distributed communication and state management on the other hand is a solved problem already mostly with known parameters. How else do you think thousand and thousands of Kubernetes work in the wild.</div><br/><div id="41893525" class="c"><input type="checkbox" id="c-41893525" checked=""/><div class="controls bullet"><span class="by">Schiendelman</span><span>|</span><a href="#41885204">root</a><span>|</span><a href="#41885317">parent</a><span>|</span><label class="collapse" for="c-41893525">[-]</label><label class="expand" for="c-41893525">[1 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re missing the point GP made: humans couldn&#x27;t do it. They tried to get humans to do it, and humans had an unacceptable error rate.<p>This is important. The autonomous driving problem and the grocery store problem are both about trade-offs, one isn&#x27;t clearly better than the other.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>