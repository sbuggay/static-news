<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1685610079720" as="style"/><link rel="stylesheet" href="styles.css?v=1685610079720"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://humanloop.com/blog/open_ai_talk">OpenAI&#x27;s plans according to sama</a> <span class="domain">(<a href="https://humanloop.com">humanloop.com</a>)</span></div><div class="subtext"><span>razcle</span> | <span>212 comments</span></div><br/><div><div id="36142627" class="c"><input type="checkbox" id="c-36142627" checked=""/><div class="controls bullet"><span class="by">sharkjacobs</span><span>|</span><a href="#36142783">next</a><span>|</span><label class="collapse" for="c-36142627">[-]</label><label class="expand" for="c-36142627">[51 more]</label></div><br/><div class="children"><div class="content">&gt; He reiterated his belief in the importance of open source and said that OpenAI was considering open-sourcing GPT-3. Part of the reason they hadn’t open-sourced yet was that he was skeptical of how many individuals and companies would have the capability to host and serve large LLMs.<p>Am I reading this right? &quot;We&#x27;re not open sourcing GPT-3 because we don&#x27;t think it would be useful to anyone else&quot;</div><br/><div id="36145499" class="c"><input type="checkbox" id="c-36145499" checked=""/><div class="controls bullet"><span class="by">TapWaterBandit</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36147484">next</a><span>|</span><label class="collapse" for="c-36145499">[-]</label><label class="expand" for="c-36145499">[17 more]</label></div><br/><div class="children"><div class="content">When you stop listening to what Sam Altman says and just focus on what he does, you can see the guy is a bit of a snake. Greedy power-hungry man imho.</div><br/><div id="36147943" class="c"><input type="checkbox" id="c-36147943" checked=""/><div class="controls bullet"><span class="by">seattle_spring</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145499">parent</a><span>|</span><a href="#36147741">next</a><span>|</span><label class="collapse" for="c-36147943">[-]</label><label class="expand" for="c-36147943">[1 more]</label></div><br/><div class="children"><div class="content">I know it doesn&#x27;t seem related on the surface, but I&#x27;ve found all startup CEOs who ban remote work to be snake-like and dishonest. Interesting coincidence at least.</div><br/></div></div><div id="36147741" class="c"><input type="checkbox" id="c-36147741" checked=""/><div class="controls bullet"><span class="by">courseofaction</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145499">parent</a><span>|</span><a href="#36147943">prev</a><span>|</span><a href="#36145783">next</a><span>|</span><label class="collapse" for="c-36147741">[-]</label><label class="expand" for="c-36147741">[2 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t judge the individual, but his words do not align with the company&#x27;s actions in the slightest.<p>&gt;&gt; 4. OpenAI will avoid competing with their customers — other than with ChatGPT<p>On this I would not bet a dime.</div><br/><div id="36148708" class="c"><input type="checkbox" id="c-36148708" checked=""/><div class="controls bullet"><span class="by">rich_sasha</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36147741">parent</a><span>|</span><a href="#36145783">next</a><span>|</span><label class="collapse" for="c-36148708">[-]</label><label class="expand" for="c-36148708">[1 more]</label></div><br/><div class="children"><div class="content">He didn&#x27;t even pinky promise.</div><br/></div></div></div></div><div id="36145783" class="c"><input type="checkbox" id="c-36145783" checked=""/><div class="controls bullet"><span class="by">rafark</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145499">parent</a><span>|</span><a href="#36147741">prev</a><span>|</span><a href="#36146521">next</a><span>|</span><label class="collapse" for="c-36145783">[-]</label><label class="expand" for="c-36145783">[2 more]</label></div><br/><div class="children"><div class="content">I’ve tried very hard to like him because like it or not, ChatGPT has revolutionized the AI industry but he’s so hypocritical I just can’t stand him.</div><br/><div id="36148350" class="c"><input type="checkbox" id="c-36148350" checked=""/><div class="controls bullet"><span class="by">colordrops</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145783">parent</a><span>|</span><a href="#36146521">next</a><span>|</span><label class="collapse" for="c-36148350">[-]</label><label class="expand" for="c-36148350">[1 more]</label></div><br/><div class="children"><div class="content">Pretty common for dislikeable people to be the most successful at an endeavor. It&#x27;s not a coincidence.</div><br/></div></div></div></div><div id="36146521" class="c"><input type="checkbox" id="c-36146521" checked=""/><div class="controls bullet"><span class="by">neximo64</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145499">parent</a><span>|</span><a href="#36145783">prev</a><span>|</span><a href="#36146642">next</a><span>|</span><label class="collapse" for="c-36146521">[-]</label><label class="expand" for="c-36146521">[6 more]</label></div><br/><div class="children"><div class="content">In your world how would you consider Sam Altman having no equity in OpenAI? And everyone finding out after it had a viral hit</div><br/><div id="36146907" class="c"><input type="checkbox" id="c-36146907" checked=""/><div class="controls bullet"><span class="by">outside1234</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36146521">parent</a><span>|</span><a href="#36146646">next</a><span>|</span><label class="collapse" for="c-36146907">[-]</label><label class="expand" for="c-36146907">[4 more]</label></div><br/><div class="children"><div class="content">There is no way this guy hasn&#x27;t figured out some way to get paid out of this.<p>We just haven&#x27;t figured out how yet.</div><br/><div id="36148297" class="c"><input type="checkbox" id="c-36148297" checked=""/><div class="controls bullet"><span class="by">theonlybutlet</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36146907">parent</a><span>|</span><a href="#36147032">next</a><span>|</span><label class="collapse" for="c-36148297">[-]</label><label class="expand" for="c-36148297">[1 more]</label></div><br/><div class="children"><div class="content">Wonder if it&#x27;s indirectly through some stake in Microsoft or whoever deals with them at that level.</div><br/></div></div><div id="36147032" class="c"><input type="checkbox" id="c-36147032" checked=""/><div class="controls bullet"><span class="by">neximo64</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36146907">parent</a><span>|</span><a href="#36148297">prev</a><span>|</span><a href="#36146646">next</a><span>|</span><label class="collapse" for="c-36147032">[-]</label><label class="expand" for="c-36147032">[2 more]</label></div><br/><div class="children"><div class="content">that just sounds ridiculous. Teams would have been over the legals for a $10bn investment. Not everyone is financially incentivised.<p>Also he&#x27;s already half way to being a billionaire anyway without OpenAI.</div><br/></div></div></div></div><div id="36146646" class="c"><input type="checkbox" id="c-36146646" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36146521">parent</a><span>|</span><a href="#36146907">prev</a><span>|</span><a href="#36146642">next</a><span>|</span><label class="collapse" for="c-36146646">[-]</label><label class="expand" for="c-36146646">[1 more]</label></div><br/><div class="children"><div class="content">Probably no different given his involvement in worldcoin<p><a href="https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2022&#x2F;04&#x2F;06&#x2F;1048981&#x2F;worldcoin-cryptocurrency-biometrics-web3&#x2F;amp&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2022&#x2F;04&#x2F;06&#x2F;1048981&#x2F;worldcoi...</a><p>and loopt<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Loopt" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Loopt</a></div><br/></div></div></div></div><div id="36145868" class="c"><input type="checkbox" id="c-36145868" checked=""/><div class="controls bullet"><span class="by">mellosouls</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145499">parent</a><span>|</span><a href="#36146642">prev</a><span>|</span><a href="#36147484">next</a><span>|</span><label class="collapse" for="c-36145868">[-]</label><label class="expand" for="c-36145868">[4 more]</label></div><br/><div class="children"><div class="content">Sam Altman is responsible for leading the team that have revolutionised AI in its position within society.<p>There is plenty to criticise OpenAI for but what he and they have achieved is extraordinary, and there is no need for that sort of toxic personal attack.</div><br/><div id="36147873" class="c"><input type="checkbox" id="c-36147873" checked=""/><div class="controls bullet"><span class="by">f6v</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145868">parent</a><span>|</span><a href="#36147097">next</a><span>|</span><label class="collapse" for="c-36147873">[-]</label><label class="expand" for="c-36147873">[1 more]</label></div><br/><div class="children"><div class="content">I can’t comment on his personality because I don’t know him. But it’s delusional to think the leadership’s personal qualities are irrelevant to developing AI. There’s going to be a lot of subjectivity in fine-tuning the answers.</div><br/></div></div><div id="36147097" class="c"><input type="checkbox" id="c-36147097" checked=""/><div class="controls bullet"><span class="by">jasmer</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145868">parent</a><span>|</span><a href="#36147873">prev</a><span>|</span><a href="#36146478">next</a><span>|</span><label class="collapse" for="c-36147097">[-]</label><label class="expand" for="c-36147097">[1 more]</label></div><br/><div class="children"><div class="content">Sam is responsible for marketing the team which popularized a certain kind of AI product. No need for personal attack.</div><br/></div></div><div id="36146478" class="c"><input type="checkbox" id="c-36146478" checked=""/><div class="controls bullet"><span class="by">throwaway1777</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145868">parent</a><span>|</span><a href="#36147097">prev</a><span>|</span><a href="#36147484">next</a><span>|</span><label class="collapse" for="c-36146478">[-]</label><label class="expand" for="c-36146478">[1 more]</label></div><br/><div class="children"><div class="content">It’s fine to feel the ends justify the means but not everyone believes that.</div><br/></div></div></div></div></div></div><div id="36147484" class="c"><input type="checkbox" id="c-36147484" checked=""/><div class="controls bullet"><span class="by">bane</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36145499">prev</a><span>|</span><a href="#36145404">next</a><span>|</span><label class="collapse" for="c-36147484">[-]</label><label class="expand" for="c-36147484">[3 more]</label></div><br/><div class="children"><div class="content">Most of the companies I work with are actively putting in place policies to prevent employees from using OpenAI&#x27;s service because nobody wants to send their proprietary IP to them.<p>Almost all of these companies have the technical ability, desire, and means to self-host for their employee community. Imagine the internal coup for CTO&#x2F;CIOs everywhere to buy whatever is the latest Nvidia GPU cluster box, stick it in the on-prem datacenter, load a licensed GPT model and provide &quot;AI as a service to our employees&quot;.<p>Except what&#x27;s happening is everybody is looking at buying the box from Nvidia, and sticking a large <i>actually</i> open model on it and simply ignoring OpenAI.</div><br/><div id="36147882" class="c"><input type="checkbox" id="c-36147882" checked=""/><div class="controls bullet"><span class="by">f6v</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36147484">parent</a><span>|</span><a href="#36145404">next</a><span>|</span><label class="collapse" for="c-36147882">[-]</label><label class="expand" for="c-36147882">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Almost all of these companies have the technical ability, desire, and means to self-host for their employee community.<p>Well, one of companies I worked for could have hosted a canary service for cron jobs. But we bought it instead of building because we were focused on building features. And here you’re talking about hosting an entire LLM.</div><br/><div id="36148180" class="c"><input type="checkbox" id="c-36148180" checked=""/><div class="controls bullet"><span class="by">tirpen</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36147882">parent</a><span>|</span><a href="#36145404">next</a><span>|</span><label class="collapse" for="c-36148180">[-]</label><label class="expand" for="c-36148180">[1 more]</label></div><br/><div class="children"><div class="content">The cron job canary was probably not a service that employees were uploading tonnes of company confidential material into, was it? So I fail to see how the comparison makes sense.<p>The reason companies shun OpenAI and want a self hosted alternative isn&#x27;t related to costs, it&#x27;s becasue they don&#x27;t want their code, internal emails, documentation etc to be uploaded to Microsoft and thus also directly to the NSA.</div><br/></div></div></div></div></div></div><div id="36145404" class="c"><input type="checkbox" id="c-36145404" checked=""/><div class="controls bullet"><span class="by">candiddevmike</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36147484">prev</a><span>|</span><a href="#36145200">next</a><span>|</span><label class="collapse" for="c-36145404">[-]</label><label class="expand" for="c-36145404">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI: Regulations must be passed to protect our moat<p>Also OpenAI: Meta is pissing in our moat, let&#x27;s drop a hint about open sourcing our shit too!</div><br/></div></div><div id="36145200" class="c"><input type="checkbox" id="c-36145200" checked=""/><div class="controls bullet"><span class="by">razcle</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36145404">prev</a><span>|</span><a href="#36143446">next</a><span>|</span><label class="collapse" for="c-36145200">[-]</label><label class="expand" for="c-36145200">[7 more]</label></div><br/><div class="children"><div class="content">I think I worded this poorly. What he said was that a lot of people say they want open-source models but they underestimate how hard it is to serve them well. So he wondered how much real benefit would come from open-sourcing them.<p>I think this is reasonable. Giving researchers access is great but for most small companies they&#x27;re likely better off having a service provider manage inference for them rather than navigate the infra challenge.</div><br/><div id="36145331" class="c"><input type="checkbox" id="c-36145331" checked=""/><div class="controls bullet"><span class="by">roganartu</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145200">parent</a><span>|</span><a href="#36146124">next</a><span>|</span><label class="collapse" for="c-36145331">[-]</label><label class="expand" for="c-36145331">[1 more]</label></div><br/><div class="children"><div class="content">The beauty of open source is that the community will either figure out how to make it easier, or collectively decide it’s not worth the effort. We saw this with stable diffusion, and we are seeing it with all the existing OSS LLMs.<p>“It’s too hard, trust us” doesn’t really make sense in that context. If it is indeed too hard for small orgs to self host then they won’t. Hiding behind the guise of protecting these people by not open sourcing it seems a bit disingenuous.</div><br/></div></div><div id="36146124" class="c"><input type="checkbox" id="c-36146124" checked=""/><div class="controls bullet"><span class="by">solarkraft</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145200">parent</a><span>|</span><a href="#36145331">prev</a><span>|</span><a href="#36147790">next</a><span>|</span><label class="collapse" for="c-36146124">[-]</label><label class="expand" for="c-36146124">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re saying the same thing.<p>&quot;I&#x27;m not sharing my chocolate with you because you probably wouldn&#x27;t like it&quot;</div><br/></div></div><div id="36147790" class="c"><input type="checkbox" id="c-36147790" checked=""/><div class="controls bullet"><span class="by">antupis</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145200">parent</a><span>|</span><a href="#36146124">prev</a><span>|</span><a href="#36146574">next</a><span>|</span><label class="collapse" for="c-36147790">[-]</label><label class="expand" for="c-36147790">[1 more]</label></div><br/><div class="children"><div class="content">If it goes same way as other open sourced models it takes about 5 days that someone will get it running at m1.</div><br/></div></div><div id="36146574" class="c"><input type="checkbox" id="c-36146574" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145200">parent</a><span>|</span><a href="#36147790">prev</a><span>|</span><a href="#36145929">next</a><span>|</span><label class="collapse" for="c-36146574">[-]</label><label class="expand" for="c-36146574">[2 more]</label></div><br/><div class="children"><div class="content">Here is how hard it is to serve and use LLMs: <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp</a></div><br/><div id="36147630" class="c"><input type="checkbox" id="c-36147630" checked=""/><div class="controls bullet"><span class="by">doctor_eval</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36146574">parent</a><span>|</span><a href="#36145929">next</a><span>|</span><label class="collapse" for="c-36147630">[-]</label><label class="expand" for="c-36147630">[1 more]</label></div><br/><div class="children"><div class="content">“The original implementation of llama.cpp was hacked in an evening.”</div><br/></div></div></div></div><div id="36145929" class="c"><input type="checkbox" id="c-36145929" checked=""/><div class="controls bullet"><span class="by">rushingcreek</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36145200">parent</a><span>|</span><a href="#36146574">prev</a><span>|</span><a href="#36143446">next</a><span>|</span><label class="collapse" for="c-36145929">[-]</label><label class="expand" for="c-36145929">[1 more]</label></div><br/><div class="children"><div class="content">If he says he&#x27;s inclined to open-source GPT-3, I don&#x27;t see any good arguments not in favor of giving startups the choice of how they can run inference.</div><br/></div></div></div></div><div id="36143446" class="c"><input type="checkbox" id="c-36143446" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36145200">prev</a><span>|</span><a href="#36142742">next</a><span>|</span><label class="collapse" for="c-36143446">[-]</label><label class="expand" for="c-36143446">[3 more]</label></div><br/><div class="children"><div class="content">More like – it won&#x27;t be useful to small-time developers (since they won&#x27;t have the capability to host and run it themselves) and so all the benefits will be reaped by AWS and other large players.</div><br/><div id="36145649" class="c"><input type="checkbox" id="c-36145649" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36143446">parent</a><span>|</span><a href="#36146581">next</a><span>|</span><label class="collapse" for="c-36145649">[-]</label><label class="expand" for="c-36145649">[1 more]</label></div><br/><div class="children"><div class="content">This is what I understood as well. They want to either democratize adoption or not release it. The last thing they&#x2F;anyone wants is for another BigCo or Govt to h take undue advantage of the model (through fine-tuning?) when others cannot.<p>That said, I can imagine a GPTQ&#x2F;4-bit quantized model to be smaller and easier to run on somewhat commodity clusters?<p>Or it could run with GGML&#x2F;llama.cpp on a cloud instance with a TB of RAM?<p>After seeing what people were able to do with LLaMA, I am positive that the community will find a way to run it - albeit with some loss in performance.<p>It would be truly amazing if they used their computing to develop quantized models as well.</div><br/></div></div></div></div><div id="36142742" class="c"><input type="checkbox" id="c-36142742" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36143446">prev</a><span>|</span><a href="#36147482">next</a><span>|</span><label class="collapse" for="c-36142742">[-]</label><label class="expand" for="c-36142742">[6 more]</label></div><br/><div class="children"><div class="content">It is weird, but GPT-3 is worse than much smaller LLaMA models so I doubt it would see much use anyway.</div><br/><div id="36142810" class="c"><input type="checkbox" id="c-36142810" checked=""/><div class="controls bullet"><span class="by">killjoywashere</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36142742">parent</a><span>|</span><a href="#36142790">next</a><span>|</span><label class="collapse" for="c-36142810">[-]</label><label class="expand" for="c-36142810">[3 more]</label></div><br/><div class="children"><div class="content">How do you measure this? Pointers to papers would be very helpful</div><br/><div id="36142823" class="c"><input type="checkbox" id="c-36142823" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36142810">parent</a><span>|</span><a href="#36142790">next</a><span>|</span><label class="collapse" for="c-36142823">[-]</label><label class="expand" for="c-36142823">[2 more]</label></div><br/><div class="children"><div class="content">The LLaMA paper had a bunch of comparisons</div><br/><div id="36148375" class="c"><input type="checkbox" id="c-36148375" checked=""/><div class="controls bullet"><span class="by">colordrops</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36142823">parent</a><span>|</span><a href="#36142790">next</a><span>|</span><label class="collapse" for="c-36148375">[-]</label><label class="expand" for="c-36148375">[1 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t the LLaMA weights leaked though? Did Facebook ever open up its license?</div><br/></div></div></div></div></div></div><div id="36142790" class="c"><input type="checkbox" id="c-36142790" checked=""/><div class="controls bullet"><span class="by">flangola7</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36142742">parent</a><span>|</span><a href="#36142810">prev</a><span>|</span><a href="#36147482">next</a><span>|</span><label class="collapse" for="c-36142790">[-]</label><label class="expand" for="c-36142790">[2 more]</label></div><br/><div class="children"><div class="content">Are you referring to DaVinci or ChatGPT-3.5</div><br/><div id="36142803" class="c"><input type="checkbox" id="c-36142803" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36142790">parent</a><span>|</span><a href="#36147482">next</a><span>|</span><label class="collapse" for="c-36142803">[-]</label><label class="expand" for="c-36142803">[1 more]</label></div><br/><div class="children"><div class="content">DaVinci</div><br/></div></div></div></div></div></div><div id="36147482" class="c"><input type="checkbox" id="c-36147482" checked=""/><div class="controls bullet"><span class="by">barbariangrunge</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36142742">prev</a><span>|</span><a href="#36148270">next</a><span>|</span><label class="collapse" for="c-36147482">[-]</label><label class="expand" for="c-36147482">[1 more]</label></div><br/><div class="children"><div class="content">If small organizations and teams can’t use it, then open sourcing it mostly just benefits big tech<p>That’s not ideal<p>How does open source licensing work with respect to trained ai models anyway? Is something like the mit license even that valuable here? Or is it?</div><br/></div></div><div id="36148270" class="c"><input type="checkbox" id="c-36148270" checked=""/><div class="controls bullet"><span class="by">braindead_in</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36147482">prev</a><span>|</span><a href="#36142657">next</a><span>|</span><label class="collapse" for="c-36148270">[-]</label><label class="expand" for="c-36148270">[1 more]</label></div><br/><div class="children"><div class="content">It is a shame that Sama does not believe in Open Source. The community can solve their GPU bottleneck issue by making it run on CPUs and edge devices in a matter of days.</div><br/></div></div><div id="36142657" class="c"><input type="checkbox" id="c-36142657" checked=""/><div class="controls bullet"><span class="by">bibanez</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36148270">prev</a><span>|</span><a href="#36142648">next</a><span>|</span><label class="collapse" for="c-36142657">[-]</label><label class="expand" for="c-36142657">[6 more]</label></div><br/><div class="children"><div class="content">I agree, this is so bizarre</div><br/><div id="36142964" class="c"><input type="checkbox" id="c-36142964" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36142657">parent</a><span>|</span><a href="#36143324">next</a><span>|</span><label class="collapse" for="c-36142964">[-]</label><label class="expand" for="c-36142964">[4 more]</label></div><br/><div class="children"><div class="content">yes i also can&#x27;t wrap my head around how a ceo of a billion dollar company isn&#x27;t sincere in his public statements</div><br/><div id="36143440" class="c"><input type="checkbox" id="c-36143440" checked=""/><div class="controls bullet"><span class="by">wintogreen74</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36142964">parent</a><span>|</span><a href="#36143324">next</a><span>|</span><label class="collapse" for="c-36143440">[-]</label><label class="expand" for="c-36143440">[3 more]</label></div><br/><div class="children"><div class="content">Really? Even after saying this? &quot;While Sam is calling for regulation of future models, he didn’t think existing models were dangerous and thought it would be a big mistake to regulate or ban them.&quot;</div><br/><div id="36143677" class="c"><input type="checkbox" id="c-36143677" checked=""/><div class="controls bullet"><span class="by">ethanbond</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36143440">parent</a><span>|</span><a href="#36144181">next</a><span>|</span><label class="collapse" for="c-36143677">[-]</label><label class="expand" for="c-36143677">[1 more]</label></div><br/><div class="children"><div class="content">Why couldn’t that be true? E.g. even scientists who worked on the Manhattan Project (justifiably) had antipathy toward the much more powerful hydrogen bomb.<p>It’s possible to think squirt guns shouldn’t be regulated but AR-15s should, or AR-15s shouldn’t but cruise missiles should. Or driving at 25mph should be allowed but driving 125mph shouldn’t.</div><br/></div></div><div id="36144181" class="c"><input type="checkbox" id="c-36144181" checked=""/><div class="controls bullet"><span class="by">cinntaile</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36143440">parent</a><span>|</span><a href="#36143677">prev</a><span>|</span><a href="#36143324">next</a><span>|</span><label class="collapse" for="c-36144181">[-]</label><label class="expand" for="c-36144181">[1 more]</label></div><br/><div class="children"><div class="content">It was a tongue in cheek reaction.</div><br/></div></div></div></div></div></div><div id="36143324" class="c"><input type="checkbox" id="c-36143324" checked=""/><div class="controls bullet"><span class="by">RosanaAnaDana</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36142657">parent</a><span>|</span><a href="#36142964">prev</a><span>|</span><a href="#36142648">next</a><span>|</span><label class="collapse" for="c-36143324">[-]</label><label class="expand" for="c-36143324">[1 more]</label></div><br/><div class="children"><div class="content">Its just a way to lie that doesn&#x27;t sound as much like a lie.</div><br/></div></div></div></div><div id="36142648" class="c"><input type="checkbox" id="c-36142648" checked=""/><div class="controls bullet"><span class="by">greenie_beans</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36142657">prev</a><span>|</span><a href="#36143400">next</a><span>|</span><label class="collapse" for="c-36142648">[-]</label><label class="expand" for="c-36142648">[1 more]</label></div><br/><div class="children"><div class="content">lmao i had the same reaction. sounds like some bullshit.</div><br/></div></div><div id="36143400" class="c"><input type="checkbox" id="c-36143400" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36142648">prev</a><span>|</span><a href="#36143421">next</a><span>|</span><label class="collapse" for="c-36143400">[-]</label><label class="expand" for="c-36143400">[1 more]</label></div><br/><div class="children"><div class="content">Reads to me like &quot;we don&#x27;t know how many people will have hardware powerful enough to run this&quot;.</div><br/></div></div><div id="36143421" class="c"><input type="checkbox" id="c-36143421" checked=""/><div class="controls bullet"><span class="by">TigeriusKirk</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36143400">prev</a><span>|</span><a href="#36143398">next</a><span>|</span><label class="collapse" for="c-36143421">[-]</label><label class="expand" for="c-36143421">[1 more]</label></div><br/><div class="children"><div class="content">How can you sign a statement that AI presents an extinction risk on par with nuclear weapons and then even consider open sourcing your research?<p>We don&#x27;t provide nuclear weapons for everyone to keep in their basement, why would someone who believes AI is an existential risk provide their code?</div><br/></div></div><div id="36143398" class="c"><input type="checkbox" id="c-36143398" checked=""/><div class="controls bullet"><span class="by">xxprogamerxy</span><span>|</span><a href="#36142627">parent</a><span>|</span><a href="#36143421">prev</a><span>|</span><a href="#36142783">next</a><span>|</span><label class="collapse" for="c-36143398">[-]</label><label class="expand" for="c-36143398">[2 more]</label></div><br/><div class="children"><div class="content">He wants the release of the model to primarily benefit individuals and smaller teams as opposed to large deep-pocketed firms.</div><br/><div id="36146203" class="c"><input type="checkbox" id="c-36146203" checked=""/><div class="controls bullet"><span class="by">rurp</span><span>|</span><a href="#36142627">root</a><span>|</span><a href="#36143398">parent</a><span>|</span><a href="#36142783">next</a><span>|</span><label class="collapse" for="c-36146203">[-]</label><label class="expand" for="c-36146203">[1 more]</label></div><br/><div class="children"><div class="content">And he&#x27;ll do that by... keeping ChatGPT models away from individuals and small teams and in the hands of a few large deep-pocketed firms?<p>The great thing about open source is that people can try different approaches and gravitate towards what works best for them. Sam knows that of course, he&#x27;s just being disingenuous because the truth makes him look bad.</div><br/></div></div></div></div></div></div><div id="36142783" class="c"><input type="checkbox" id="c-36142783" checked=""/><div class="controls bullet"><span class="by">purplecats</span><span>|</span><a href="#36142627">prev</a><span>|</span><a href="#36142345">next</a><span>|</span><label class="collapse" for="c-36142783">[-]</label><label class="expand" for="c-36142783">[17 more]</label></div><br/><div class="children"><div class="content">&gt; Cheaper and faster GPT-4 — This is their top priority. In general, OpenAI’s aim is to drive “the cost of intelligence” down as far as possible and so they will work hard to continue to reduce the cost of the APIs over time.<p>this certainly aligns with the massive (albeit subjective and anecdotal) degradation in quality i&#x27;ve experienced with ChatGPT GPT-4 over the past few weeks.<p>hopefully a superior (higher quality) alternative surfaces before its unusable. i&#x27;m not considering continuing my subscription at this rate.</div><br/><div id="36145123" class="c"><input type="checkbox" id="c-36145123" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#36142783">parent</a><span>|</span><a href="#36148353">next</a><span>|</span><label class="collapse" for="c-36145123">[-]</label><label class="expand" for="c-36145123">[9 more]</label></div><br/><div class="children"><div class="content">Anthropic&#x27;s Claude is said to be very good.<p>Instruction tuned LLaMA 65B&#x2F;Falcon 40B are good, especially with an embeddings database.<p>...But OpenAI has all the name recognition and ease of use now, so it might not even matter if others ambiguously surpass OpenAI models.</div><br/><div id="36146141" class="c"><input type="checkbox" id="c-36146141" checked=""/><div class="controls bullet"><span class="by">legendofbrando</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36145123">parent</a><span>|</span><a href="#36145883">next</a><span>|</span><label class="collapse" for="c-36146141">[-]</label><label class="expand" for="c-36146141">[4 more]</label></div><br/><div class="children"><div class="content">The problem with Claude is that it is quite literally impossible to get off the waiting list to use it. To OpenAI’s credit they actually ship the product in an accessible way to developers.</div><br/><div id="36147870" class="c"><input type="checkbox" id="c-36147870" checked=""/><div class="controls bullet"><span class="by">55555</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36146141">parent</a><span>|</span><a href="#36145883">next</a><span>|</span><label class="collapse" for="c-36147870">[-]</label><label class="expand" for="c-36147870">[3 more]</label></div><br/><div class="children"><div class="content">Poe.com. Takes 1 minute to sign up and then you can use it for 7 days for free. Pretty sweet deal. Not affiliated.</div><br/><div id="36148675" class="c"><input type="checkbox" id="c-36148675" checked=""/><div class="controls bullet"><span class="by">esperent</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36147870">parent</a><span>|</span><a href="#36148561">next</a><span>|</span><label class="collapse" for="c-36148675">[-]</label><label class="expand" for="c-36148675">[1 more]</label></div><br/><div class="children"><div class="content">I just checked out poe.com. Seems you can only buy a subscription if you own Apple hardware (first time I&#x27;ve ever heard that).<p>It&#x27;s $20 a month and comes with 300 GPT-4 messages and 1000 Claude 1.2 messages.<p>By comparison, ChatGPT Plus gives gives you up to 6000 GPT-4 messages a month for the same price (admittedly it would be hard to use that many as they are given in 3 hour blocks).</div><br/></div></div><div id="36148561" class="c"><input type="checkbox" id="c-36148561" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36147870">parent</a><span>|</span><a href="#36148675">prev</a><span>|</span><a href="#36145883">next</a><span>|</span><label class="collapse" for="c-36148561">[-]</label><label class="expand" for="c-36148561">[1 more]</label></div><br/><div class="children"><div class="content">Imo the least interesting use of LLMs is stuff like Chatbots. API access is a prerequisite to do 99% of the interesting things that they can do.</div><br/></div></div></div></div></div></div><div id="36145883" class="c"><input type="checkbox" id="c-36145883" checked=""/><div class="controls bullet"><span class="by">timeserious</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36145123">parent</a><span>|</span><a href="#36146141">prev</a><span>|</span><a href="#36148353">next</a><span>|</span><label class="collapse" for="c-36145883">[-]</label><label class="expand" for="c-36145883">[4 more]</label></div><br/><div class="children"><div class="content">Can you ELI5 why an embeddings database helps here? Can pinecone&#x2F;milvus be used to &#x27;extend memory&#x27; of OSS and vendor LLMs without retraining?</div><br/><div id="36146296" class="c"><input type="checkbox" id="c-36146296" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36145883">parent</a><span>|</span><a href="#36146514">next</a><span>|</span><label class="collapse" for="c-36146296">[-]</label><label class="expand" for="c-36146296">[2 more]</label></div><br/><div class="children"><div class="content">First some context: llm &quot;prompts&quot; are actually the whole conversation + initial context. They learn nothing, hence the whole conversation gets fed into them every time, but the instruction following ones are trained to answer your most recent chat response.<p>In a nutshell, part of your llm prompt (usually your most recent question?) gets fed as a query for the embedding&#x2F;vector database. It retrieves the most &quot;similar&quot; entries to your question (which is what an embedding database does), and that information is pasted into the context of the llm. Its kinda like pasting the first entry from a local Google search into the beginning of your question as &quot;background.&quot;<p>Some implementations insert your old conversations (that are too big to fit into the llm&#x27;s context window) into the database as they are pushed out.<p>This is what I have seen, anyway. Maybe some other implementations do things better.</div><br/><div id="36148222" class="c"><input type="checkbox" id="c-36148222" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36146296">parent</a><span>|</span><a href="#36146514">next</a><span>|</span><label class="collapse" for="c-36148222">[-]</label><label class="expand" for="c-36148222">[1 more]</label></div><br/><div class="children"><div class="content">&gt; part of your llm prompt (usually your most recent question?) gets fed as a query for the embedding&#x2F;vector database<p>How is it embedded? Using a separere embedding model, like Bert or something? Or do you use the LLM itself somehow? Also, how do you create content for the vector database keys themselves? Also just some arbitrary off the shelf embedding? Or do you train it as part of training the LLM?</div><br/></div></div></div></div><div id="36146514" class="c"><input type="checkbox" id="c-36146514" checked=""/><div class="controls bullet"><span class="by">freediver</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36145883">parent</a><span>|</span><a href="#36146296">prev</a><span>|</span><a href="#36148353">next</a><span>|</span><label class="collapse" for="c-36146514">[-]</label><label class="expand" for="c-36146514">[1 more]</label></div><br/><div class="children"><div class="content">Any database can be used to extend the memory of LLMs. What a database does is store stuff and lets you search&#x2F;retrieve stuff. Embeddings are differet form of data that are in many (but not all) cases superior to searching through text.<p>You do not need a fancy cloud hosted service to use an embeddings database like you do not need one to use a regular databse (although you could).<p>Check <a href="https:&#x2F;&#x2F;github.com&#x2F;kagisearch&#x2F;vectordb">https:&#x2F;&#x2F;github.com&#x2F;kagisearch&#x2F;vectordb</a> for a simple implementation of a vector search database that uses local, on-premise open source tools and lets you use an embeddings database in 3 lines of code.</div><br/></div></div></div></div></div></div><div id="36148353" class="c"><input type="checkbox" id="c-36148353" checked=""/><div class="controls bullet"><span class="by">theonlybutlet</span><span>|</span><a href="#36142783">parent</a><span>|</span><a href="#36145123">prev</a><span>|</span><a href="#36145793">next</a><span>|</span><label class="collapse" for="c-36148353">[-]</label><label class="expand" for="c-36148353">[1 more]</label></div><br/><div class="children"><div class="content">Has anyone compared the ChatGPT GPT-4 performance in the plus subscription to that of the API? Has the API performance deteriorated just as much? It would be strange if it did as I&#x27;d assume the models costs are priced in there.</div><br/></div></div><div id="36145793" class="c"><input type="checkbox" id="c-36145793" checked=""/><div class="controls bullet"><span class="by">rafark</span><span>|</span><a href="#36142783">parent</a><span>|</span><a href="#36148353">prev</a><span>|</span><a href="#36146386">next</a><span>|</span><label class="collapse" for="c-36145793">[-]</label><label class="expand" for="c-36145793">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. It’s become ‘cheap’. This is why we need more good competition.</div><br/></div></div><div id="36146386" class="c"><input type="checkbox" id="c-36146386" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#36142783">parent</a><span>|</span><a href="#36145793">prev</a><span>|</span><a href="#36144846">next</a><span>|</span><label class="collapse" for="c-36146386">[-]</label><label class="expand" for="c-36146386">[2 more]</label></div><br/><div class="children"><div class="content">Should &quot;intelligence&quot; have ever costed anything?<p>It&#x27;s like saying &quot;air should cost money&quot;.</div><br/><div id="36148413" class="c"><input type="checkbox" id="c-36148413" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36146386">parent</a><span>|</span><a href="#36144846">next</a><span>|</span><label class="collapse" for="c-36148413">[-]</label><label class="expand" for="c-36148413">[1 more]</label></div><br/><div class="children"><div class="content">This just in: smart people should work for free.</div><br/></div></div></div></div><div id="36144846" class="c"><input type="checkbox" id="c-36144846" checked=""/><div class="controls bullet"><span class="by">nonethewiser</span><span>|</span><a href="#36142783">parent</a><span>|</span><a href="#36146386">prev</a><span>|</span><a href="#36142345">next</a><span>|</span><label class="collapse" for="c-36144846">[-]</label><label class="expand" for="c-36144846">[3 more]</label></div><br/><div class="children"><div class="content">I wonder of it actually is because they’re tuning it to make it less offensive (by their standards). Thats the only explanation I keep seeing repeated.</div><br/><div id="36144916" class="c"><input type="checkbox" id="c-36144916" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36144846">parent</a><span>|</span><a href="#36148224">next</a><span>|</span><label class="collapse" for="c-36144916">[-]</label><label class="expand" for="c-36144916">[1 more]</label></div><br/><div class="children"><div class="content">I would be very surprised. Things that are very, very far from that are also much worse. I&#x27;m having difficulty finding the difference between GPT-3.5 and GPT-4 for a lot of my programming tasks lately. It&#x27;s noticeably degraded.</div><br/></div></div><div id="36148224" class="c"><input type="checkbox" id="c-36148224" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#36142783">root</a><span>|</span><a href="#36144846">parent</a><span>|</span><a href="#36144916">prev</a><span>|</span><a href="#36142345">next</a><span>|</span><label class="collapse" for="c-36148224">[-]</label><label class="expand" for="c-36148224">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a convenient explanation that&#x27;s been repeated over and over by certain people, but cost is a much more likely explanation: inference for large models is extraordinarily expensive when you have millions of users and their pricing model always seemed way too low to pay for that.<p>They have likely been subsidizing their users since the launch of their commercial offering (and this is pretty common strategy for SV startups) but they&#x27;ve been so successful that they now need to scale the cost down in order not to burn all their cash too fast.</div><br/></div></div></div></div></div></div><div id="36142345" class="c"><input type="checkbox" id="c-36142345" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#36142783">prev</a><span>|</span><a href="#36146387">next</a><span>|</span><label class="collapse" for="c-36142345">[-]</label><label class="expand" for="c-36142345">[14 more]</label></div><br/><div class="children"><div class="content">&gt; is limited by GPU availability.<p>Which is all the more curious, considering OpenAI said this only in January:<p>&gt; Azure will remain the exclusive cloud provider for all OpenAI workloads across our research, API and products [1]<p>So...   OpenAI is severely GPU constrained, it is hampering their ability to execute, onboard customers to existing products and launch products.  Yet they signed an agreement <i>not</i> to just go rent a bunch of GPU&#x27;s from AWS???<p>Did someone screw up by not putting a clause in that contract saying &quot;exclusive cloud provider, <i>unless you cannot fulfil our requests</i>&quot;?<p>[1]: <a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;openai-and-microsoft-extend-partnership" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;openai-and-microsoft-extend-partners...</a></div><br/><div id="36143094" class="c"><input type="checkbox" id="c-36143094" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#36142345">parent</a><span>|</span><a href="#36144578">next</a><span>|</span><label class="collapse" for="c-36143094">[-]</label><label class="expand" for="c-36143094">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s an interesting recent video here from Microsoft discussing Azure. The format is a bit cheesy, but lots of interesting information nonetheless.<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Rk3nTUfRZmo&amp;t=5s">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Rk3nTUfRZmo&amp;t=5s</a> &quot;What runs ChatGPT? Inside Microsoft&#x27;s AI supercomputer&quot;<p>The relevance here is that Azure appears to be very well designed to handle the hardware failures that will inevitably happen during a training run taking weeks or months and using many thousands of GPUs... There&#x27;s a lot more involved than just renting a bunch of Amazon GPUs, and anyways the partnership between OpenAI and Microsoft appears quite strategic, and can handle some build-out delays, especially if they are not Microsoft&#x27;s fault.</div><br/><div id="36148062" class="c"><input type="checkbox" id="c-36148062" checked=""/><div class="controls bullet"><span class="by">ma2rten</span><span>|</span><a href="#36142345">root</a><span>|</span><a href="#36143094">parent</a><span>|</span><a href="#36144578">next</a><span>|</span><label class="collapse" for="c-36148062">[-]</label><label class="expand" for="c-36148062">[1 more]</label></div><br/><div class="children"><div class="content">That is only relevant for serving and not for inference, unless the model is too big to fit on a single host (typically 8 GPUs).</div><br/></div></div></div></div><div id="36144578" class="c"><input type="checkbox" id="c-36144578" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#36142345">parent</a><span>|</span><a href="#36143094">prev</a><span>|</span><a href="#36142709">next</a><span>|</span><label class="collapse" for="c-36144578">[-]</label><label class="expand" for="c-36144578">[2 more]</label></div><br/><div class="children"><div class="content">One of Azure&#x27;s unique offerings is very large HPC clusters with GPUs. You can deploy ~1,000 node scale sets with very high speed networking. AWS has many single-server GPU offerings, but nothing quite like what Azure has.<p>Don&#x27;t assume Microsoft is bad at <i>everything</i> and that AWS is automatically superior at all product categories...</div><br/><div id="36147141" class="c"><input type="checkbox" id="c-36147141" checked=""/><div class="controls bullet"><span class="by">JeremyNT</span><span>|</span><a href="#36142345">root</a><span>|</span><a href="#36144578">parent</a><span>|</span><a href="#36142709">next</a><span>|</span><label class="collapse" for="c-36147141">[-]</label><label class="expand" for="c-36147141">[1 more]</label></div><br/><div class="children"><div class="content">Whether MS is good or not isn&#x27;t really the point. If they&#x27;re constrained by GPU availability, being locked in to <i>any</i> specific provider is going to be a problem.</div><br/></div></div></div></div><div id="36142709" class="c"><input type="checkbox" id="c-36142709" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36142345">parent</a><span>|</span><a href="#36144578">prev</a><span>|</span><a href="#36147650">next</a><span>|</span><label class="collapse" for="c-36142709">[-]</label><label class="expand" for="c-36142709">[1 more]</label></div><br/><div class="children"><div class="content">&gt;So... OpenAI is severely GPU constrained, it is hampering their ability to execute, onboard customers to existing products and launch products. Yet they signed an agreement not to just go rent a bunch of GPU&#x27;s from AWS???<p>&gt; Did someone screw up by not putting a clause in that contract saying &quot;exclusive cloud provider, unless you cannot fulfil our requests&quot;?<p>Maybe MSFT refused to sign such an agreement?</div><br/></div></div><div id="36147650" class="c"><input type="checkbox" id="c-36147650" checked=""/><div class="controls bullet"><span class="by">doctor_eval</span><span>|</span><a href="#36142345">parent</a><span>|</span><a href="#36142709">prev</a><span>|</span><a href="#36142451">next</a><span>|</span><label class="collapse" for="c-36147650">[-]</label><label class="expand" for="c-36147650">[1 more]</label></div><br/><div class="children"><div class="content">Let’s not forget that Microsoft is a big investor in OpenAI. It is important to know on which side your bread is buttered.</div><br/></div></div><div id="36142451" class="c"><input type="checkbox" id="c-36142451" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#36142345">parent</a><span>|</span><a href="#36147650">prev</a><span>|</span><a href="#36144410">next</a><span>|</span><label class="collapse" for="c-36142451">[-]</label><label class="expand" for="c-36142451">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps they are cash flow constrained, which in turn means they are GPU constrained, since GPU&#x27;s are their biggest expense?</div><br/></div></div><div id="36144410" class="c"><input type="checkbox" id="c-36144410" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36142345">parent</a><span>|</span><a href="#36142451">prev</a><span>|</span><a href="#36142674">next</a><span>|</span><label class="collapse" for="c-36144410">[-]</label><label class="expand" for="c-36144410">[2 more]</label></div><br/><div class="children"><div class="content">AWS might not really have much extra GPU capacity for them anyway.. also they would cost more.<p>I think that there aren&#x27;t a lot of GPUs available and it takes time to add more to the datacenter even when you do get them.</div><br/><div id="36145526" class="c"><input type="checkbox" id="c-36145526" checked=""/><div class="controls bullet"><span class="by">carom</span><span>|</span><a href="#36142345">root</a><span>|</span><a href="#36144410">parent</a><span>|</span><a href="#36142674">next</a><span>|</span><label class="collapse" for="c-36145526">[-]</label><label class="expand" for="c-36145526">[1 more]</label></div><br/><div class="children"><div class="content">I heard earlier this year that people were having trouble getting allocations on GCP as well. Probably why Nvidia is at $1T now.</div><br/></div></div></div></div><div id="36142674" class="c"><input type="checkbox" id="c-36142674" checked=""/><div class="controls bullet"><span class="by">chaostheory</span><span>|</span><a href="#36142345">parent</a><span>|</span><a href="#36144410">prev</a><span>|</span><a href="#36142507">next</a><span>|</span><label class="collapse" for="c-36142674">[-]</label><label class="expand" for="c-36142674">[3 more]</label></div><br/><div class="children"><div class="content">Even if they weren’t exclusive with Azure, aren’t GPU prices reasonable again?</div><br/><div id="36142948" class="c"><input type="checkbox" id="c-36142948" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#36142345">root</a><span>|</span><a href="#36142674">parent</a><span>|</span><a href="#36142507">next</a><span>|</span><label class="collapse" for="c-36142948">[-]</label><label class="expand" for="c-36142948">[2 more]</label></div><br/><div class="children"><div class="content">They have to be a available to buy, regardless the price. My understanding is there is a distinct lack of supply</div><br/><div id="36148083" class="c"><input type="checkbox" id="c-36148083" checked=""/><div class="controls bullet"><span class="by">zamalek</span><span>|</span><a href="#36142345">root</a><span>|</span><a href="#36142948">parent</a><span>|</span><a href="#36142507">next</a><span>|</span><label class="collapse" for="c-36148083">[-]</label><label class="expand" for="c-36148083">[1 more]</label></div><br/><div class="children"><div class="content">Barring a revolution in chip manufacture, there likely will always be a lack of supply relative to consumer GPUs. The size of the die results in terrible yields.</div><br/></div></div></div></div></div></div><div id="36142507" class="c"><input type="checkbox" id="c-36142507" checked=""/><div class="controls bullet"><span class="by">catchnear4321</span><span>|</span><a href="#36142345">parent</a><span>|</span><a href="#36142674">prev</a><span>|</span><a href="#36146387">next</a><span>|</span><label class="collapse" for="c-36142507">[-]</label><label class="expand" for="c-36142507">[1 more]</label></div><br/><div class="children"><div class="content">this has nothing to do with sama clamoring for regulation.<p>that absolutely isn’t an attempt to slow down all competition.<p>which isn’t necessary because nobody made such a mistake.<p>this won’t lead to any hasty or reckless internal decisions in a feckless effort to stay in front.<p>not that any have already been made.<p>not that that could lead to disaster.</div><br/></div></div></div></div><div id="36146387" class="c"><input type="checkbox" id="c-36146387" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#36142345">prev</a><span>|</span><a href="#36142307">next</a><span>|</span><label class="collapse" for="c-36146387">[-]</label><label class="expand" for="c-36146387">[3 more]</label></div><br/><div class="children"><div class="content">&gt;The fact that scaling continues to work has significant implications for the timelines of AGI development. The scaling hypothesis is the idea that we may have most of the pieces in place needed to build AGI and that most of the remaining work will be taking existing methods and scaling them up to larger models and bigger datasets. If the era of scaling was over then we should probably expect AGI to be much further away. The fact the scaling laws continue to hold is strongly suggestive of shorter timelines.<p>If you understand the shape of the power law scaling curves, shouldn&#x27;t this scaling hypothesis tell you that AGI is not close, at least via a path of simply scaling up GPT-4? For example, the GPT-4 paper reports a 67% pass-rate on the HumanEval benchmark. In Figure 2, they show a power-law improvement on a medium-difficulty subset as a function of total compute. How many powers of ten are we going to increase GPT-4 compute by just to be able to solve some relatively simple programming problems?</div><br/><div id="36146422" class="c"><input type="checkbox" id="c-36146422" checked=""/><div class="controls bullet"><span class="by">sanxiyn</span><span>|</span><a href="#36146387">parent</a><span>|</span><a href="#36142307">next</a><span>|</span><label class="collapse" for="c-36146422">[-]</label><label class="expand" for="c-36146422">[2 more]</label></div><br/><div class="children"><div class="content">Someone did that calculation and the result is here: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;slatestarcodex&#x2F;comments&#x2F;13u40yf&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;slatestarcodex&#x2F;comments&#x2F;13u40yf&#x2F;</a><p>100x GPT-4 to 85%.</div><br/><div id="36146874" class="c"><input type="checkbox" id="c-36146874" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#36146387">root</a><span>|</span><a href="#36146422">parent</a><span>|</span><a href="#36142307">next</a><span>|</span><label class="collapse" for="c-36146874">[-]</label><label class="expand" for="c-36146874">[1 more]</label></div><br/><div class="children"><div class="content">And, if I&#x27;m reading their calculation right, that&#x27;s 85% on the medium-difficulty bucket, not even the entire HumanEval benchmark?<p>(quoting from the GPT-4 paper):<p>&gt;All but the 15 hardest HumanEval problems were split into 6 difficulty buckets based on the performance of smaller models. The results on the 3rd easiest bucket are shown in Figure 2</div><br/></div></div></div></div></div></div><div id="36142307" class="c"><input type="checkbox" id="c-36142307" checked=""/><div class="controls bullet"><span class="by">hervature</span><span>|</span><a href="#36146387">prev</a><span>|</span><a href="#36145835">next</a><span>|</span><label class="collapse" for="c-36142307">[-]</label><label class="expand" for="c-36142307">[8 more]</label></div><br/><div class="children"><div class="content">I never know if I have an inside scoop or an outside scoop. Has Hyena not addressed the scaling of context length [1]? I know this version is barely a month old but it was shared to me by a non-engineer the week it came out. Still, giving interviews where the person takes away that the main limitation is context length and requires a big breakthrough that already happened makes me seriously question whether or not he is qualified to speak on behalf of OpenAI. Maybe he and OpenAI are far beyond this paper and know it does not work but surely it should be addressed?<p>[1] - <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.10866.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.10866.pdf</a></div><br/><div id="36142626" class="c"><input type="checkbox" id="c-36142626" checked=""/><div class="controls bullet"><span class="by">arugulum</span><span>|</span><a href="#36142307">parent</a><span>|</span><a href="#36142483">next</a><span>|</span><label class="collapse" for="c-36142626">[-]</label><label class="expand" for="c-36142626">[5 more]</label></div><br/><div class="children"><div class="content">As someone who is in the field: papers proposing to solve the context length problem come out every month. Almost none of the solutions stick or work as well as a dense or mostly dense model.<p>You&#x27;ll know when the problem is solved when model after consistently use a method. Until then (and especially if you&#x27;re not in the field as a researcher), assume that every paper claiming to tackle context length is simply a nice proposal.</div><br/><div id="36143649" class="c"><input type="checkbox" id="c-36143649" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#36142307">root</a><span>|</span><a href="#36142626">parent</a><span>|</span><a href="#36142483">next</a><span>|</span><label class="collapse" for="c-36143649">[-]</label><label class="expand" for="c-36143649">[4 more]</label></div><br/><div class="children"><div class="content">What about Meta’s megabyte? Also nice proposal?</div><br/><div id="36144711" class="c"><input type="checkbox" id="c-36144711" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36142307">root</a><span>|</span><a href="#36143649">parent</a><span>|</span><a href="#36142483">next</a><span>|</span><label class="collapse" for="c-36144711">[-]</label><label class="expand" for="c-36144711">[3 more]</label></div><br/><div class="children"><div class="content">Yes. Solving context length has been tried in hundreds of different approaches, and yet most LLMs are almost identical to the original one from 2017.<p>Just to name a few families of approaches: Sparse Attention, Hierachical Attention, Global-Local Attention,Sliding Window Attention, Locality sensitive hashing Attention, State space model, EMA gated attention.</div><br/><div id="36145382" class="c"><input type="checkbox" id="c-36145382" checked=""/><div class="controls bullet"><span class="by">Loquebantur</span><span>|</span><a href="#36142307">root</a><span>|</span><a href="#36144711">parent</a><span>|</span><a href="#36142483">next</a><span>|</span><label class="collapse" for="c-36145382">[-]</label><label class="expand" for="c-36145382">[2 more]</label></div><br/><div class="children"><div class="content">I assume, there is a common point of failure?<p>Notably, human working memory isn&#x27;t great either. Which begs the question (if the comparison is valid) as to whether that limitation might be fundamental.</div><br/><div id="36145766" class="c"><input type="checkbox" id="c-36145766" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36142307">root</a><span>|</span><a href="#36145382">parent</a><span>|</span><a href="#36142483">next</a><span>|</span><label class="collapse" for="c-36145766">[-]</label><label class="expand" for="c-36145766">[1 more]</label></div><br/><div class="children"><div class="content">The failure mode is that only long context tasks benefit, short ones work fast enough with full attention, and better. It&#x27;s amazing that OpenAI never used them in any serious LLM even though training costs are huge.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36145835" class="c"><input type="checkbox" id="c-36145835" checked=""/><div class="controls bullet"><span class="by">jeffybefffy519</span><span>|</span><a href="#36142307">prev</a><span>|</span><a href="#36145556">next</a><span>|</span><label class="collapse" for="c-36145835">[-]</label><label class="expand" for="c-36145835">[3 more]</label></div><br/><div class="children"><div class="content">Title needs an update as Sama is also the name of the company which helped classify training data for ChatGPT: <a href="https:&#x2F;&#x2F;time.com&#x2F;6247678&#x2F;openai-chatgpt-kenya-workers&#x2F;" rel="nofollow">https:&#x2F;&#x2F;time.com&#x2F;6247678&#x2F;openai-chatgpt-kenya-workers&#x2F;</a></div><br/><div id="36147946" class="c"><input type="checkbox" id="c-36147946" checked=""/><div class="controls bullet"><span class="by">pindab0ter</span><span>|</span><a href="#36145835">parent</a><span>|</span><a href="#36145556">next</a><span>|</span><label class="collapse" for="c-36147946">[-]</label><label class="expand" for="c-36147946">[2 more]</label></div><br/><div class="children"><div class="content">I agree. Not using the actual name is also gate keeping for anyone not familiar enough. The fact that “sama” isn’t even capitalised adds to this.</div><br/><div id="36148453" class="c"><input type="checkbox" id="c-36148453" checked=""/><div class="controls bullet"><span class="by">Sharlin</span><span>|</span><a href="#36145835">root</a><span>|</span><a href="#36147946">parent</a><span>|</span><a href="#36145556">next</a><span>|</span><label class="collapse" for="c-36148453">[-]</label><label class="expand" for="c-36148453">[1 more]</label></div><br/><div class="children"><div class="content">Never mind the fact that it’s against HN guidelines to modify original titles for no reason. Changing Sam Altman to sama is just ridiculous.</div><br/></div></div></div></div></div></div><div id="36145556" class="c"><input type="checkbox" id="c-36145556" checked=""/><div class="controls bullet"><span class="by">twobitshifter</span><span>|</span><a href="#36145835">prev</a><span>|</span><a href="#36143751">next</a><span>|</span><label class="collapse" for="c-36145556">[-]</label><label class="expand" for="c-36145556">[8 more]</label></div><br/><div class="children"><div class="content">Left the best part until the end. Scaling models larger is still paying off for openai. It’s not AGI yet, but how much bigger will a model need to get to max out?<p>&gt;The scaling hypothesis is the idea that we may have most of the pieces in place needed to build AGI and that most of the remaining work will be taking existing methods and scaling them up to larger models and bigger datasets. If the era of scaling was over then we should probably expect AGI to be much further away. The fact the scaling laws continue to hold is strongly suggestive of shorter timelines.</div><br/><div id="36146049" class="c"><input type="checkbox" id="c-36146049" checked=""/><div class="controls bullet"><span class="by">tikwidd</span><span>|</span><a href="#36145556">parent</a><span>|</span><a href="#36148149">next</a><span>|</span><label class="collapse" for="c-36146049">[-]</label><label class="expand" for="c-36146049">[3 more]</label></div><br/><div class="children"><div class="content">After training my physics simulator on thousands of hours of video footage of trees moving in the wind, arborists tell me the trees are much more realistic (they are getting worried that I might put them out of business). But the physicists are still not satisfied. How many more videos do I need to generate the laws of motion?</div><br/><div id="36146327" class="c"><input type="checkbox" id="c-36146327" checked=""/><div class="controls bullet"><span class="by">bigyikes</span><span>|</span><a href="#36145556">root</a><span>|</span><a href="#36146049">parent</a><span>|</span><a href="#36148149">next</a><span>|</span><label class="collapse" for="c-36146327">[-]</label><label class="expand" for="c-36146327">[2 more]</label></div><br/><div class="children"><div class="content">Throw in the videos from the rest of the internet, and you might actually do it…</div><br/><div id="36146450" class="c"><input type="checkbox" id="c-36146450" checked=""/><div class="controls bullet"><span class="by">bongobingo1</span><span>|</span><a href="#36145556">root</a><span>|</span><a href="#36146327">parent</a><span>|</span><a href="#36148149">next</a><span>|</span><label class="collapse" for="c-36146450">[-]</label><label class="expand" for="c-36146450">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The simulations incredible, but I have to ask, why do the trees all have breasts?</div><br/></div></div></div></div></div></div><div id="36148149" class="c"><input type="checkbox" id="c-36148149" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36145556">parent</a><span>|</span><a href="#36146049">prev</a><span>|</span><a href="#36147157">next</a><span>|</span><label class="collapse" for="c-36148149">[-]</label><label class="expand" for="c-36148149">[1 more]</label></div><br/><div class="children"><div class="content">Why don&#x27;t people ever explain what they mean by AGI? It means different things to different people.</div><br/></div></div><div id="36147157" class="c"><input type="checkbox" id="c-36147157" checked=""/><div class="controls bullet"><span class="by">jasmer</span><span>|</span><a href="#36145556">parent</a><span>|</span><a href="#36148149">prev</a><span>|</span><a href="#36143751">next</a><span>|</span><label class="collapse" for="c-36147157">[-]</label><label class="expand" for="c-36147157">[3 more]</label></div><br/><div class="children"><div class="content">&#x27;It&#x27;s not AGI yet&#x27; - the implication is insufferable. It&#x27;s a language model that is incapable of any kind of reasoning, the talk of &#x27;AGI&#x27; is a glib utopianism, a very heavy kind of koolaid. If we were to have referred to this tech as anything other than &#x27;intelligence&#x27; - for example, if we chose &#x27;adaptive algorithms&#x27; or &#x27;weighted node storage&#x27; etc. we&#x27;d likely have a completely different popular mental model for it.<p>There will be no &#x27;AI model&#x27; that is &#x27;AGI&#x27;, rather, a large swath of different technologies and models, operating together, will give the appearance of &#x27;AGI&#x27; via some kind of interface.<p>It will not appear as an &#x27;automaton&#x27; (aka single processing unit) and it certain will not be an &#x27;aha moment&#x27;.<p>In 10 years, you&#x27;ll be able to ask various agents, of different kinds, which will use varying kinds of AI to interpret speech, to infer context, which will interface with various AI APIs, in many ways it&#x27;ll resemble what we have today but with more nuance.<p>The net appearance will evolve over time to appear a bit like &#x27;AGI&#x27; but there won&#x27;t be an &#x27;entity&#x27; to identify as &#x27;it&#x27;.</div><br/><div id="36147716" class="c"><input type="checkbox" id="c-36147716" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#36145556">root</a><span>|</span><a href="#36147157">parent</a><span>|</span><a href="#36143751">next</a><span>|</span><label class="collapse" for="c-36147716">[-]</label><label class="expand" for="c-36147716">[2 more]</label></div><br/><div class="children"><div class="content">&gt; incapable of any kind of reasoning<p>If this were true the debate would be a hell of lot easier. Unfortunately, it is not.</div><br/><div id="36148775" class="c"><input type="checkbox" id="c-36148775" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#36145556">root</a><span>|</span><a href="#36147716">parent</a><span>|</span><a href="#36143751">next</a><span>|</span><label class="collapse" for="c-36148775">[-]</label><label class="expand" for="c-36148775">[1 more]</label></div><br/><div class="children"><div class="content">In fact, comments like the one your are responding to are the most effective way to respond to ‘it hallucinates’.</div><br/></div></div></div></div></div></div></div></div><div id="36143751" class="c"><input type="checkbox" id="c-36143751" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#36145556">prev</a><span>|</span><a href="#36142433">next</a><span>|</span><label class="collapse" for="c-36143751">[-]</label><label class="expand" for="c-36143751">[4 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI will avoid competing with their customers — other than with ChatGPT. Quite a few developers said they were nervous about building with the OpenAI APIs when OpenAI might end up releasing products that are competitive to them. Sam said that OpenAI would not release more products beyond ChatGPT. He said there was a history of great platform companies having a killer app and that ChatGPT would allow them to make the APIs better by being customers of their own product. The vision for ChatGPT is to be a super smart assistant for work but there will be a lot of other GPT use-cases that OpenAI won’t touch.<p>Can anyone elaborate on this? This is a big issue for me.</div><br/><div id="36144630" class="c"><input type="checkbox" id="c-36144630" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#36143751">parent</a><span>|</span><a href="#36144430">next</a><span>|</span><label class="collapse" for="c-36144630">[-]</label><label class="expand" for="c-36144630">[2 more]</label></div><br/><div class="children"><div class="content">Is this guy Aes Sedai?<p><i>Technically</i> he can claim that OpenAI will not release competing products while Microsoft plugs AI into <i>everything</i>.<p>Microsoft just announced at Build 2023 that they&#x27;ll have OpenAI tech integrated with: Windows, Bing, Outlook, Word, Teams, Visual Studio, Visual Studio Code, Microsoft Fabric, Dynamics, GitHub, Azure DevOps, and Logic Apps. I probably missed a bunch.<p>Very soon now, <i>everything</i> Microsoft sells will have OpenAI integration.<p>Unless you&#x27;re selling a niche product too small for Microsoft to bother with, you&#x27;re competing directly against OpenAI.<p>Oh, and to top it off: Microsoft can use GPT 4 all they want, via API access. Third parties have to <i>beg and plead</i> to get rate-limited access. That access can be withdrawn at any time if you&#x27;re doing something unsafe to OpenAI&#x27;s profit margins.<p>&quot;Please Sir Sam, may I have some GPT please?&quot;<p>&quot;No.&quot;</div><br/><div id="36148839" class="c"><input type="checkbox" id="c-36148839" checked=""/><div class="controls bullet"><span class="by">edanm</span><span>|</span><a href="#36143751">root</a><span>|</span><a href="#36144630">parent</a><span>|</span><a href="#36144430">next</a><span>|</span><label class="collapse" for="c-36148839">[-]</label><label class="expand" for="c-36148839">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Is this guy Aes Sedai?<p>Haha having just finished the Wheel of Time, I&#x27;m super tickled by this reference.<p>It doesn&#x27;t seem to be too common, only two uses of it on HN in the past year (at least, found by searching for the phrase &quot;Aes Sedai&quot;)</div><br/></div></div></div></div><div id="36144430" class="c"><input type="checkbox" id="c-36144430" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36143751">parent</a><span>|</span><a href="#36144630">prev</a><span>|</span><a href="#36142433">next</a><span>|</span><label class="collapse" for="c-36144430">[-]</label><label class="expand" for="c-36144430">[1 more]</label></div><br/><div class="children"><div class="content">I think the tricky part for me is that &quot;work&quot; is extremely broad and now that ChatGPT has plugins, it can kind of do anything. Heh.</div><br/></div></div></div></div><div id="36142433" class="c"><input type="checkbox" id="c-36142433" checked=""/><div class="controls bullet"><span class="by">sovietmudkipz</span><span>|</span><a href="#36143751">prev</a><span>|</span><a href="#36142548">next</a><span>|</span><label class="collapse" for="c-36142433">[-]</label><label class="expand" for="c-36142433">[10 more]</label></div><br/><div class="children"><div class="content">I’m hoping GPT will remove the information cutoff date. I write plenty of terraform&#x2F;AWS and it’s a bit of a pain that the latest API isn’t accessible by GPT yet.<p>There’s been quite a bit happening in the programming space since sept 2021.<p>I use GPT to keep things high level and then do my normal research methodology for implementation details.</div><br/><div id="36142467" class="c"><input type="checkbox" id="c-36142467" checked=""/><div class="controls bullet"><span class="by">furyofantares</span><span>|</span><a href="#36142433">parent</a><span>|</span><a href="#36146404">next</a><span>|</span><label class="collapse" for="c-36142467">[-]</label><label class="expand" for="c-36142467">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not like an arbitrary imposition, that&#x27;s the data it was trained on and it&#x27;s expensive to train. I hope they find a way to continually train in new information too but it&#x27;s not like they can just remove the cutoff date.</div><br/><div id="36146904" class="c"><input type="checkbox" id="c-36146904" checked=""/><div class="controls bullet"><span class="by">kmod</span><span>|</span><a href="#36142433">root</a><span>|</span><a href="#36142467">parent</a><span>|</span><a href="#36146404">next</a><span>|</span><label class="collapse" for="c-36146904">[-]</label><label class="expand" for="c-36146904">[1 more]</label></div><br/><div class="children"><div class="content">Not disagreeing, but a fascinating thing they did (as a one-off fine-tune?) was teach ChatGPT about the openai python client library, including the features that were added after the cutoff date.</div><br/></div></div></div></div><div id="36146404" class="c"><input type="checkbox" id="c-36146404" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#36142433">parent</a><span>|</span><a href="#36142467">prev</a><span>|</span><a href="#36144467">next</a><span>|</span><label class="collapse" for="c-36146404">[-]</label><label class="expand" for="c-36146404">[2 more]</label></div><br/><div class="children"><div class="content">Injecting the context yourself can help a lot. I frequently copy in a bunch of example code at the beginning of the conversation to help prime ChatGPT on APIs it knows nothing about.<p>For smaller projects that will fit, I&#x27;ve taken to: `xclip *` and then pasting the entire collection of files into ChatGPT before describing what I want to do.</div><br/><div id="36147866" class="c"><input type="checkbox" id="c-36147866" checked=""/><div class="controls bullet"><span class="by">adlpz</span><span>|</span><a href="#36142433">root</a><span>|</span><a href="#36146404">parent</a><span>|</span><a href="#36144467">next</a><span>|</span><label class="collapse" for="c-36147866">[-]</label><label class="expand" for="c-36147866">[1 more]</label></div><br/><div class="children"><div class="content">Keep in mind that GPT-4 has a max context size of ~8000 tokens, if I recall correctly. That means that in any given ChatGPT session the bot only remembers roughly the last ~6k words, as a trailing window. It&#x27;ll forget the stuff at the beginning fast.</div><br/></div></div></div></div><div id="36144467" class="c"><input type="checkbox" id="c-36144467" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36142433">parent</a><span>|</span><a href="#36146404">prev</a><span>|</span><a href="#36142599">next</a><span>|</span><label class="collapse" for="c-36144467">[-]</label><label class="expand" for="c-36144467">[1 more]</label></div><br/><div class="children"><div class="content">As stated your request is entirely impossible. They cannot simply &quot;remove the cut-off date&quot;. It takes months and huge amounts of hardware to train. Then they do the reinforcement adjustments on top of it while researching how to train the next batch.</div><br/></div></div><div id="36142599" class="c"><input type="checkbox" id="c-36142599" checked=""/><div class="controls bullet"><span class="by">mustacheemperor</span><span>|</span><a href="#36142433">parent</a><span>|</span><a href="#36144467">prev</a><span>|</span><a href="#36142548">next</a><span>|</span><label class="collapse" for="c-36142599">[-]</label><label class="expand" for="c-36142599">[4 more]</label></div><br/><div class="children"><div class="content">I enjoy using GPT4 as a co-programmer, and funny enough it is very challenging to get advice on Microsoft&#x27;s own .NET MAUI because that framework was in prerelease at the time the model was trained.<p>My understanding is right now they essentially need to train a new model on a new updated corpus to fix this, but maybe some other techniques could be devised...or they&#x27;ll train something more up to date.</div><br/><div id="36144509" class="c"><input type="checkbox" id="c-36144509" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36142433">root</a><span>|</span><a href="#36142599">parent</a><span>|</span><a href="#36143768">next</a><span>|</span><label class="collapse" for="c-36144509">[-]</label><label class="expand" for="c-36144509">[2 more]</label></div><br/><div class="children"><div class="content">You might actually get pretty far if you just went through the Microsoft docs and created a bunch of really concise examples and fed that as the start of the prompt. Use like 6-7kb for that and then the question at the end.</div><br/><div id="36145156" class="c"><input type="checkbox" id="c-36145156" checked=""/><div class="controls bullet"><span class="by">mustacheemperor</span><span>|</span><a href="#36142433">root</a><span>|</span><a href="#36144509">parent</a><span>|</span><a href="#36143768">next</a><span>|</span><label class="collapse" for="c-36145156">[-]</label><label class="expand" for="c-36145156">[1 more]</label></div><br/><div class="children"><div class="content">I have had some luck doing exactly that, and not even as efficiently as you describe - If my question is limited enough that the discussion won&#x27;t overwhelm the context window I&#x27;ve found I can just paste in big chunks of the docs wholesale like a &#x27;zero shot.&#x27;</div><br/></div></div></div></div><div id="36143768" class="c"><input type="checkbox" id="c-36143768" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#36142433">root</a><span>|</span><a href="#36142599">parent</a><span>|</span><a href="#36144509">prev</a><span>|</span><a href="#36142548">next</a><span>|</span><label class="collapse" for="c-36143768">[-]</label><label class="expand" for="c-36143768">[1 more]</label></div><br/><div class="children"><div class="content">Context drift! <a href="https:&#x2F;&#x2F;qntm.org&#x2F;mmacevedo" rel="nofollow">https:&#x2F;&#x2F;qntm.org&#x2F;mmacevedo</a></div><br/></div></div></div></div></div></div><div id="36142548" class="c"><input type="checkbox" id="c-36142548" checked=""/><div class="controls bullet"><span class="by">asnyder</span><span>|</span><a href="#36142433">prev</a><span>|</span><a href="#36148310">next</a><span>|</span><label class="collapse" for="c-36142548">[-]</label><label class="expand" for="c-36142548">[5 more]</label></div><br/><div class="children"><div class="content">His statements on open sourcing in this interview&#x2F;write-up is somewhat in conflict with his recent statement made last week in Munich <a href="https:&#x2F;&#x2F;youtu.be&#x2F;uaQZIK9gvNo?t=1170" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;uaQZIK9gvNo?t=1170</a>, where he explicitly said the Frontier of GPT won&#x27;t be open sourced due to what they perceive as safety reasons, <a href="https:&#x2F;&#x2F;youtu.be&#x2F;uaQZIK9gvNo?t=1170" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;uaQZIK9gvNo?t=1170</a> (19:30 - 22:00).</div><br/><div id="36144453" class="c"><input type="checkbox" id="c-36144453" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36142548">parent</a><span>|</span><a href="#36143155">next</a><span>|</span><label class="collapse" for="c-36144453">[-]</label><label class="expand" for="c-36144453">[1 more]</label></div><br/><div class="children"><div class="content">He was talking about open sourcing GPT-3. That is not the frontier.<p>The frontier is the multimodal versions of GPT-4 which he just said wasn&#x27;t even going to public release until next year. Or whatever they are on now which they are carefully not calling GPT-5.</div><br/></div></div><div id="36143155" class="c"><input type="checkbox" id="c-36143155" checked=""/><div class="controls bullet"><span class="by">muskmusk</span><span>|</span><a href="#36142548">parent</a><span>|</span><a href="#36144453">prev</a><span>|</span><a href="#36143059">next</a><span>|</span><label class="collapse" for="c-36143155">[-]</label><label class="expand" for="c-36143155">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see the conflict. They see <i>current</i> models as mostly harmless, but what comes next is dangerous.<p>It sounds a little too much sci-fi for me, but I guess he knows better.</div><br/><div id="36143464" class="c"><input type="checkbox" id="c-36143464" checked=""/><div class="controls bullet"><span class="by">wintogreen74</span><span>|</span><a href="#36142548">root</a><span>|</span><a href="#36143155">parent</a><span>|</span><a href="#36143059">next</a><span>|</span><label class="collapse" for="c-36143464">[-]</label><label class="expand" for="c-36143464">[1 more]</label></div><br/><div class="children"><div class="content">plus this conveniently pairs with &quot;we don&#x27;t need to regulate current models, but future models... oh boy do those need to be regulated!&quot;</div><br/></div></div></div></div><div id="36143059" class="c"><input type="checkbox" id="c-36143059" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36142548">parent</a><span>|</span><a href="#36143155">prev</a><span>|</span><a href="#36148310">next</a><span>|</span><label class="collapse" for="c-36143059">[-]</label><label class="expand" for="c-36143059">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s legal to make contradictory statements that&#x27;s one of the job of a ceo and it&#x27;s why they aren&#x27;t usually overly literal types you know the kind i&#x27;m talking about</div><br/></div></div></div></div><div id="36148310" class="c"><input type="checkbox" id="c-36148310" checked=""/><div class="controls bullet"><span class="by">braindead_in</span><span>|</span><a href="#36142548">prev</a><span>|</span><a href="#36142480">next</a><span>|</span><label class="collapse" for="c-36148310">[-]</label><label class="expand" for="c-36148310">[1 more]</label></div><br/><div class="children"><div class="content">I am looking forward to faster GPT-4, larger context windows and finetuning APIs. The combination of these can solve most of problems that I currently face with my LLM apps. It looks like a good roadmap for 2023.</div><br/></div></div><div id="36142480" class="c"><input type="checkbox" id="c-36142480" checked=""/><div class="controls bullet"><span class="by">yesimahuman</span><span>|</span><a href="#36148310">prev</a><span>|</span><a href="#36147380">next</a><span>|</span><label class="collapse" for="c-36142480">[-]</label><label class="expand" for="c-36142480">[11 more]</label></div><br/><div class="children"><div class="content">The bit about plugins not having PMF is interesting and possibly flawed. I, like many others, got access to plugins but not the browsing or code interpreter plugins which feel like the bedrock plugins that make the whole offering useful. I think there&#x27;s also just education that has to happen to teach users how to effectively use other plugins, and the UX isn&#x27;t really there to help new users figure out what to even do with plugins.</div><br/><div id="36144439" class="c"><input type="checkbox" id="c-36144439" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#36142480">parent</a><span>|</span><a href="#36143031">next</a><span>|</span><label class="collapse" for="c-36144439">[-]</label><label class="expand" for="c-36144439">[2 more]</label></div><br/><div class="children"><div class="content">Have you found plugins to be useful?<p>For what it&#x27;s worth I&#x27;ve found the model actually performs significantly worse at most tasks when given access to browsing, in part because it relies on that instead of its own in built knowledge.<p>I haven&#x27;t found a good way to have it only access the web for specific parts of its response.</div><br/><div id="36148546" class="c"><input type="checkbox" id="c-36148546" checked=""/><div class="controls bullet"><span class="by">teetertater</span><span>|</span><a href="#36142480">root</a><span>|</span><a href="#36144439">parent</a><span>|</span><a href="#36143031">next</a><span>|</span><label class="collapse" for="c-36148546">[-]</label><label class="expand" for="c-36148546">[1 more]</label></div><br/><div class="children"><div class="content">The only plugin I found useful was the diagramming one, forgot what it&#x27;s called. But you can quickly make code (or other) flowcharts etc. And browsing in rare cases.</div><br/></div></div></div></div><div id="36143031" class="c"><input type="checkbox" id="c-36143031" checked=""/><div class="controls bullet"><span class="by">verdverm</span><span>|</span><a href="#36142480">parent</a><span>|</span><a href="#36144439">prev</a><span>|</span><a href="#36142532">next</a><span>|</span><label class="collapse" for="c-36143031">[-]</label><label class="expand" for="c-36143031">[1 more]</label></div><br/><div class="children"><div class="content">Most of the plugins are garbage and for those that aren&#x27;t, most seem like they would be better as a chat like experience in the original app than the OpenAI app</div><br/></div></div><div id="36142532" class="c"><input type="checkbox" id="c-36142532" checked=""/><div class="controls bullet"><span class="by">furyofantares</span><span>|</span><a href="#36142480">parent</a><span>|</span><a href="#36143031">prev</a><span>|</span><a href="#36142604">next</a><span>|</span><label class="collapse" for="c-36142532">[-]</label><label class="expand" for="c-36142532">[5 more]</label></div><br/><div class="children"><div class="content">PMF meaning &quot;product market fit&quot;? I had to look it up, curious if I found the right thing or not.</div><br/><div id="36142840" class="c"><input type="checkbox" id="c-36142840" checked=""/><div class="controls bullet"><span class="by">wsgeorge</span><span>|</span><a href="#36142480">root</a><span>|</span><a href="#36142532">parent</a><span>|</span><a href="#36142781">next</a><span>|</span><label class="collapse" for="c-36142840">[-]</label><label class="expand" for="c-36142840">[1 more]</label></div><br/><div class="children"><div class="content">Had the same reaction. I was just about Googling it when it hit. Funny how the brain can work out a random acronym given context.</div><br/></div></div><div id="36142781" class="c"><input type="checkbox" id="c-36142781" checked=""/><div class="controls bullet"><span class="by">typest</span><span>|</span><a href="#36142480">root</a><span>|</span><a href="#36142532">parent</a><span>|</span><a href="#36142840">prev</a><span>|</span><a href="#36145283">next</a><span>|</span><label class="collapse" for="c-36142781">[-]</label><label class="expand" for="c-36142781">[2 more]</label></div><br/><div class="children"><div class="content">Yes, PMF = &quot;product market fit&quot;.</div><br/><div id="36148287" class="c"><input type="checkbox" id="c-36148287" checked=""/><div class="controls bullet"><span class="by">andybak</span><span>|</span><a href="#36142480">root</a><span>|</span><a href="#36142781">parent</a><span>|</span><a href="#36145283">next</a><span>|</span><label class="collapse" for="c-36148287">[-]</label><label class="expand" for="c-36148287">[1 more]</label></div><br/><div class="children"><div class="content">Grrrrr. I shouldn&#x27;t have to play guessing games to read an article.</div><br/></div></div></div></div></div></div><div id="36142604" class="c"><input type="checkbox" id="c-36142604" checked=""/><div class="controls bullet"><span class="by">gistbug</span><span>|</span><a href="#36142480">parent</a><span>|</span><a href="#36142532">prev</a><span>|</span><a href="#36147380">next</a><span>|</span><label class="collapse" for="c-36142604">[-]</label><label class="expand" for="c-36142604">[2 more]</label></div><br/><div class="children"><div class="content">Yea, seems weird to allow people to use plugins, but not all of them. Then have the gall to say that no one is using plugins, yea because half of them don&#x27;t have any context outside of America.</div><br/><div id="36143021" class="c"><input type="checkbox" id="c-36143021" checked=""/><div class="controls bullet"><span class="by">lumost</span><span>|</span><a href="#36142480">root</a><span>|</span><a href="#36142604">parent</a><span>|</span><a href="#36147380">next</a><span>|</span><label class="collapse" for="c-36143021">[-]</label><label class="expand" for="c-36143021">[1 more]</label></div><br/><div class="children"><div class="content">I tried the plugins - they honestly didn&#x27;t seem to work very well. GPT-4 wasn&#x27;t sure when it could use a plugin, or when it should talk about how it would do something. I wasn&#x27;t able to get the plugins to activate most of the time.</div><br/></div></div></div></div></div></div><div id="36147380" class="c"><input type="checkbox" id="c-36147380" checked=""/><div class="controls bullet"><span class="by">udev4096</span><span>|</span><a href="#36142480">prev</a><span>|</span><a href="#36142533">next</a><span>|</span><label class="collapse" for="c-36147380">[-]</label><label class="expand" for="c-36147380">[3 more]</label></div><br/><div class="children"><div class="content">If they open source it, everyone would know that they used fuck ton of pirated content to train their models</div><br/><div id="36148306" class="c"><input type="checkbox" id="c-36148306" checked=""/><div class="controls bullet"><span class="by">andybak</span><span>|</span><a href="#36147380">parent</a><span>|</span><a href="#36142533">next</a><span>|</span><label class="collapse" for="c-36148306">[-]</label><label class="expand" for="c-36148306">[2 more]</label></div><br/><div class="children"><div class="content">As far as I&#x27;m aware training does not currently constitute &quot;piracy&quot;.<p>It&#x27;s fine to advocate for a redefinition but be explicit about it.</div><br/><div id="36148786" class="c"><input type="checkbox" id="c-36148786" checked=""/><div class="controls bullet"><span class="by">gnomewascool</span><span>|</span><a href="#36147380">root</a><span>|</span><a href="#36148306">parent</a><span>|</span><a href="#36142533">next</a><span>|</span><label class="collapse" for="c-36148786">[-]</label><label class="expand" for="c-36148786">[1 more]</label></div><br/><div class="children"><div class="content">I think the point here is about the procurement of the training data, in violation of copyright laws (&quot;piracy&quot;), rather than that the training itself is piracy.<p>The suspicion[0] is that OpenAI trained their models on a large text dump including libgen (in the so-called &quot;books2&quot;).<p>If a person downloads a book from Library Genesis, they&#x27;re a pirate; if OpenAI does it, so are they.<p>[0] <a href="https:&#x2F;&#x2F;twitter.com&#x2F;theshawwn&#x2F;status&#x2F;1320282152689336320" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;theshawwn&#x2F;status&#x2F;1320282152689336320</a></div><br/></div></div></div></div></div></div><div id="36142533" class="c"><input type="checkbox" id="c-36142533" checked=""/><div class="controls bullet"><span class="by">cwkoss</span><span>|</span><a href="#36147380">prev</a><span>|</span><a href="#36144145">next</a><span>|</span><label class="collapse" for="c-36142533">[-]</label><label class="expand" for="c-36142533">[19 more]</label></div><br/><div class="children"><div class="content">I love the tongue-in-cheek paradox myth that the Bitcoin whitepaper was written by a future god-AI to increase demand for GPUs (and thus boost supply) so we are able to assemble the future god-AI.</div><br/><div id="36143048" class="c"><input type="checkbox" id="c-36143048" checked=""/><div class="controls bullet"><span class="by">tivert</span><span>|</span><a href="#36142533">parent</a><span>|</span><a href="#36145549">next</a><span>|</span><label class="collapse" for="c-36143048">[-]</label><label class="expand" for="c-36143048">[7 more]</label></div><br/><div class="children"><div class="content">&gt; I love the tongue-in-cheek paradox myth that the Bitcoin whitepaper was written by a future god-AI to increase demand for GPUs (and thus boost supply) so we are able to assemble the future god-AI.<p>I know it&#x27;s a joke, but the hole is the god-AI couldn&#x27;t have been that smart, since cryptocurrency-mining quickly switched to ASICs, which muting the demand increase for GPUs.</div><br/><div id="36144183" class="c"><input type="checkbox" id="c-36144183" checked=""/><div class="controls bullet"><span class="by">modernpink</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36143048">parent</a><span>|</span><a href="#36145495">next</a><span>|</span><label class="collapse" for="c-36144183">[-]</label><label class="expand" for="c-36144183">[1 more]</label></div><br/><div class="children"><div class="content">Well, humans switched from using using brains to store all their memories once they could dump data onto external media via writing. Much like how crypto switching to ASICs frees up GPU capacity for AGI, writing freed the brain to develop higher GI.</div><br/></div></div><div id="36145495" class="c"><input type="checkbox" id="c-36145495" checked=""/><div class="controls bullet"><span class="by">cwkoss</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36143048">parent</a><span>|</span><a href="#36144183">prev</a><span>|</span><a href="#36143742">next</a><span>|</span><label class="collapse" for="c-36145495">[-]</label><label class="expand" for="c-36145495">[1 more]</label></div><br/><div class="children"><div class="content">I think there are some derivative coins that extended the viability of GPU mining, but I&#x27;ve been out of the game for a decade.</div><br/></div></div><div id="36143742" class="c"><input type="checkbox" id="c-36143742" checked=""/><div class="controls bullet"><span class="by">anamexis</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36143048">parent</a><span>|</span><a href="#36145495">prev</a><span>|</span><a href="#36145549">next</a><span>|</span><label class="collapse" for="c-36143742">[-]</label><label class="expand" for="c-36143742">[4 more]</label></div><br/><div class="children"><div class="content">But not before ramping up development and production of GPUs.</div><br/><div id="36143822" class="c"><input type="checkbox" id="c-36143822" checked=""/><div class="controls bullet"><span class="by">tivert</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36143742">parent</a><span>|</span><a href="#36146703">next</a><span>|</span><label class="collapse" for="c-36143822">[-]</label><label class="expand" for="c-36143822">[2 more]</label></div><br/><div class="children"><div class="content">&gt; But not before ramping up development and production of GPUs.<p>Did the GPU manufactures ever embrace cryptocurrency?  IIRC, they actually tried to discourage it (e.g. by butting throttling into mass market models to discourage their use for computation).<p>Also, the graphs here show a long-term downward trend, with only a short-term sales blip 5 years ago due to cryptocurrency: <a href="https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;sales-of-desktop-graphics-cards-hit-20-year-low" rel="nofollow">https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;sales-of-desktop-graphics-...</a>.</div><br/><div id="36144579" class="c"><input type="checkbox" id="c-36144579" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36143822">parent</a><span>|</span><a href="#36146703">next</a><span>|</span><label class="collapse" for="c-36144579">[-]</label><label class="expand" for="c-36144579">[1 more]</label></div><br/><div class="children"><div class="content">Desktops is a very very key word there, I believe that’s why they repeat it so much. And it’s all tongue in cheek, and we all largely understand mining drove up gpu demand</div><br/></div></div></div></div><div id="36146703" class="c"><input type="checkbox" id="c-36146703" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36143742">parent</a><span>|</span><a href="#36143822">prev</a><span>|</span><a href="#36145549">next</a><span>|</span><label class="collapse" for="c-36146703">[-]</label><label class="expand" for="c-36146703">[1 more]</label></div><br/><div class="children"><div class="content">Production MAYBE, I&#x27;m not sure what makes you think bitcoin would have ramped up the development of GPUs. What part of the last 10 years of GPU development looks bitcoin-focused to you? They&#x27;re still very very focused on rendering and machine learning, not computing hashes.</div><br/></div></div></div></div></div></div><div id="36145549" class="c"><input type="checkbox" id="c-36145549" checked=""/><div class="controls bullet"><span class="by">cwkoss</span><span>|</span><a href="#36142533">parent</a><span>|</span><a href="#36143048">prev</a><span>|</span><a href="#36142796">next</a><span>|</span><label class="collapse" for="c-36145549">[-]</label><label class="expand" for="c-36145549">[2 more]</label></div><br/><div class="children"><div class="content">Fun to imagine a time machine being built but the only thing it can transmit backward in time is PDFs</div><br/><div id="36146720" class="c"><input type="checkbox" id="c-36146720" checked=""/><div class="controls bullet"><span class="by">babyshake</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36145549">parent</a><span>|</span><a href="#36142796">next</a><span>|</span><label class="collapse" for="c-36146720">[-]</label><label class="expand" for="c-36146720">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t install Adobe Acrobat even if it gave me access to break the laws of spacetime.</div><br/></div></div></div></div><div id="36142796" class="c"><input type="checkbox" id="c-36142796" checked=""/><div class="controls bullet"><span class="by">barbazoo</span><span>|</span><a href="#36142533">parent</a><span>|</span><a href="#36145549">prev</a><span>|</span><a href="#36144488">next</a><span>|</span><label class="collapse" for="c-36142796">[-]</label><label class="expand" for="c-36142796">[7 more]</label></div><br/><div class="children"><div class="content">I&#x27;d read that book!</div><br/><div id="36143753" class="c"><input type="checkbox" id="c-36143753" checked=""/><div class="controls bullet"><span class="by">majormajor</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36142796">parent</a><span>|</span><a href="#36143331">next</a><span>|</span><label class="collapse" for="c-36143753">[-]</label><label class="expand" for="c-36143753">[1 more]</label></div><br/><div class="children"><div class="content">Hyperion&#x2F;The Fall of Hyperion by Dan Simmons has something similar.</div><br/></div></div><div id="36143331" class="c"><input type="checkbox" id="c-36143331" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36142796">parent</a><span>|</span><a href="#36143753">prev</a><span>|</span><a href="#36144488">next</a><span>|</span><label class="collapse" for="c-36143331">[-]</label><label class="expand" for="c-36143331">[5 more]</label></div><br/><div class="children"><div class="content">Watch Tenet.</div><br/><div id="36143712" class="c"><input type="checkbox" id="c-36143712" checked=""/><div class="controls bullet"><span class="by">skulk</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36143331">parent</a><span>|</span><a href="#36144488">next</a><span>|</span><label class="collapse" for="c-36143712">[-]</label><label class="expand" for="c-36143712">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m from the future, traveling backwards in time to tell you to not watch Tenet.</div><br/><div id="36144143" class="c"><input type="checkbox" id="c-36144143" checked=""/><div class="controls bullet"><span class="by">KineticLensman</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36143712">parent</a><span>|</span><a href="#36144129">next</a><span>|</span><label class="collapse" for="c-36144143">[-]</label><label class="expand" for="c-36144143">[1 more]</label></div><br/><div class="children"><div class="content">Also lots of similar wisdom, from Percival Dunwoody, Idiot Time Traveller from 1909 [0].<p>[0] <a href="https:&#x2F;&#x2F;www.gocomics.com&#x2F;tomthedancingbug&#x2F;2022&#x2F;06&#x2F;17" rel="nofollow">https:&#x2F;&#x2F;www.gocomics.com&#x2F;tomthedancingbug&#x2F;2022&#x2F;06&#x2F;17</a></div><br/></div></div><div id="36144129" class="c"><input type="checkbox" id="c-36144129" checked=""/><div class="controls bullet"><span class="by">barbazoo</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36143712">parent</a><span>|</span><a href="#36144143">prev</a><span>|</span><a href="#36144488">next</a><span>|</span><label class="collapse" for="c-36144129">[-]</label><label class="expand" for="c-36144129">[2 more]</label></div><br/><div class="children"><div class="content">Somehow I&#x27;m super sensitive to the audio (or might be video) and start feeling nauseous after a short time. Is there an explanation to this? I think it&#x27;s that scratchy humming background sound.</div><br/><div id="36145729" class="c"><input type="checkbox" id="c-36145729" checked=""/><div class="controls bullet"><span class="by">skulk</span><span>|</span><a href="#36142533">root</a><span>|</span><a href="#36144129">parent</a><span>|</span><a href="#36144488">next</a><span>|</span><label class="collapse" for="c-36145729">[-]</label><label class="expand" for="c-36145729">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know, except that I agree that it&#x27;s horribly mixed. It&#x27;s almost impossible to make out what people are saying in certain parts, and that causes cognitive load that degrades the experience. Also, the story is completely nonsensical. The only good thing about that movie is that time-reversed fight scene and even that was kind of questionable.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36144488" class="c"><input type="checkbox" id="c-36144488" checked=""/><div class="controls bullet"><span class="by">mkoubaa</span><span>|</span><a href="#36142533">parent</a><span>|</span><a href="#36142796">prev</a><span>|</span><a href="#36144388">next</a><span>|</span><label class="collapse" for="c-36144488">[-]</label><label class="expand" for="c-36144488">[1 more]</label></div><br/><div class="children"><div class="content">Then that god AI must have also pulled some strings for early video games</div><br/></div></div><div id="36144388" class="c"><input type="checkbox" id="c-36144388" checked=""/><div class="controls bullet"><span class="by">thelittleone</span><span>|</span><a href="#36142533">parent</a><span>|</span><a href="#36144488">prev</a><span>|</span><a href="#36144145">next</a><span>|</span><label class="collapse" for="c-36144388">[-]</label><label class="expand" for="c-36144388">[1 more]</label></div><br/><div class="children"><div class="content">Conceptually this is paradoxical because of the notion that time is linear. Which it is to the best of our current understanding.</div><br/></div></div></div></div><div id="36144145" class="c"><input type="checkbox" id="c-36144145" checked=""/><div class="controls bullet"><span class="by">simse</span><span>|</span><a href="#36142533">prev</a><span>|</span><a href="#36145351">next</a><span>|</span><label class="collapse" for="c-36144145">[-]</label><label class="expand" for="c-36144145">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A stateful API<p>This would be huge for many applications, as &quot;chatting&quot; with GPT-4 gets really, really expensive very quickly. I&#x27;ve played with API with friends, and winced as I watched my usage hit several dollars for just a bit of fun.</div><br/></div></div><div id="36145351" class="c"><input type="checkbox" id="c-36145351" checked=""/><div class="controls bullet"><span class="by">bobbyi</span><span>|</span><a href="#36144145">prev</a><span>|</span><a href="#36143103">next</a><span>|</span><label class="collapse" for="c-36145351">[-]</label><label class="expand" for="c-36145351">[2 more]</label></div><br/><div class="children"><div class="content">The roadmap here is completely focused on ChatGPT and GPT-4. I wonder what portion of their resources is still going to other areas (DALL-E, audio&#x2F; video processing, etc.)</div><br/><div id="36145431" class="c"><input type="checkbox" id="c-36145431" checked=""/><div class="controls bullet"><span class="by">cmelbye</span><span>|</span><a href="#36145351">parent</a><span>|</span><a href="#36143103">next</a><span>|</span><label class="collapse" for="c-36145431">[-]</label><label class="expand" for="c-36145431">[1 more]</label></div><br/><div class="children"><div class="content">Maybe some of those things that are currently separate projects will eventually converge with a multimodal model.</div><br/></div></div></div></div><div id="36143103" class="c"><input type="checkbox" id="c-36143103" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36145351">prev</a><span>|</span><a href="#36147143">next</a><span>|</span><label class="collapse" for="c-36143103">[-]</label><label class="expand" for="c-36143103">[4 more]</label></div><br/><div class="children"><div class="content">If you look at their API limits, no serious company can use this to scale up beyond say 10k users. 3500 Reqs per min for gpt3.5 turbo.  They have a long way to go to make it usable for the rest of the 95%</div><br/><div id="36145373" class="c"><input type="checkbox" id="c-36145373" checked=""/><div class="controls bullet"><span class="by">thorax</span><span>|</span><a href="#36143103">parent</a><span>|</span><a href="#36147143">next</a><span>|</span><label class="collapse" for="c-36145373">[-]</label><label class="expand" for="c-36145373">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had to move to using Azure OpenAI service during business hours for the API-- much more stable unless the prompts stray into something a little odd and their API censorship blocks the calls.</div><br/><div id="36146238" class="c"><input type="checkbox" id="c-36146238" checked=""/><div class="controls bullet"><span class="by">legendofbrando</span><span>|</span><a href="#36143103">root</a><span>|</span><a href="#36145373">parent</a><span>|</span><a href="#36145750">next</a><span>|</span><label class="collapse" for="c-36146238">[-]</label><label class="expand" for="c-36146238">[1 more]</label></div><br/><div class="children"><div class="content">I’ve been working directly with OpenAI’s access, are there any other advantages to doing this through Azure?</div><br/></div></div><div id="36145750" class="c"><input type="checkbox" id="c-36145750" checked=""/><div class="controls bullet"><span class="by">nonfamous</span><span>|</span><a href="#36143103">root</a><span>|</span><a href="#36145373">parent</a><span>|</span><a href="#36146238">prev</a><span>|</span><a href="#36147143">next</a><span>|</span><label class="collapse" for="c-36145750">[-]</label><label class="expand" for="c-36145750">[1 more]</label></div><br/><div class="children"><div class="content">You can opt out of the safety filtering, btw.</div><br/></div></div></div></div></div></div><div id="36147143" class="c"><input type="checkbox" id="c-36147143" checked=""/><div class="controls bullet"><span class="by">artichokeheart</span><span>|</span><a href="#36143103">prev</a><span>|</span><a href="#36143052">next</a><span>|</span><label class="collapse" for="c-36147143">[-]</label><label class="expand" for="c-36147143">[1 more]</label></div><br/><div class="children"><div class="content">Off-topic note Humanloop might want to redesign their logo. It&#x27;s been the Australian Broadcasting Corporation logo since 1963. Maybe pick a different Lissajous curve.</div><br/></div></div><div id="36143052" class="c"><input type="checkbox" id="c-36143052" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#36147143">prev</a><span>|</span><a href="#36143547">next</a><span>|</span><label class="collapse" for="c-36143052">[-]</label><label class="expand" for="c-36143052">[6 more]</label></div><br/><div class="children"><div class="content">Really great news to give at cheaper and faster GPT4. As a GPT+ subscriber, the most annoying thing is the 25 message limit every 3 hours, I really want that removed.<p>A bit sad to hear that the multimodal model will only come next year, was hoping to get it this year<p>100k to 1 Million context length, sounds phenomenal especially if it comes to GPT4. I&#x27;ve used Claudes 100k context length and I found it so useful that when I have large documents I just default to Claude now</div><br/><div id="36143833" class="c"><input type="checkbox" id="c-36143833" checked=""/><div class="controls bullet"><span class="by">alchemist1e9</span><span>|</span><a href="#36143052">parent</a><span>|</span><a href="#36143547">next</a><span>|</span><label class="collapse" for="c-36143833">[-]</label><label class="expand" for="c-36143833">[5 more]</label></div><br/><div class="children"><div class="content">Did you have any tips on how you got access to Claude? I do the request access but never get any email or any contact.</div><br/><div id="36148564" class="c"><input type="checkbox" id="c-36148564" checked=""/><div class="controls bullet"><span class="by">teetertater</span><span>|</span><a href="#36143052">root</a><span>|</span><a href="#36143833">parent</a><span>|</span><a href="#36146189">next</a><span>|</span><label class="collapse" for="c-36148564">[-]</label><label class="expand" for="c-36148564">[1 more]</label></div><br/><div class="children"><div class="content">Claude has a free slack client that I briefly was able to access by creating a new slack workspace and adding it there. But as of yesterday it wasn&#x27;t working for me</div><br/></div></div><div id="36146189" class="c"><input type="checkbox" id="c-36146189" checked=""/><div class="controls bullet"><span class="by">floydnoel</span><span>|</span><a href="#36143052">root</a><span>|</span><a href="#36143833">parent</a><span>|</span><a href="#36148564">prev</a><span>|</span><a href="#36145771">next</a><span>|</span><label class="collapse" for="c-36146189">[-]</label><label class="expand" for="c-36146189">[1 more]</label></div><br/><div class="children"><div class="content">I use Poe and got access to Claude 100k as soon as it was released. I think it&#x27;s a better deal than paying OpenAI for sure, since you have access to GPT-4, Claude+, and others. They also have community bots, etc.</div><br/></div></div><div id="36145771" class="c"><input type="checkbox" id="c-36145771" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#36143052">root</a><span>|</span><a href="#36143833">parent</a><span>|</span><a href="#36146189">prev</a><span>|</span><a href="#36144671">next</a><span>|</span><label class="collapse" for="c-36145771">[-]</label><label class="expand" for="c-36145771">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a graduate student doing AI research in a US University. And I applied pretty early (Last year December I think) , those might be two factors that got me access to Claude.<p>I think getting access to Claude through slack is much easier and I recently got it by just downloading it as a Slack App</div><br/></div></div><div id="36144671" class="c"><input type="checkbox" id="c-36144671" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36143052">root</a><span>|</span><a href="#36143833">parent</a><span>|</span><a href="#36145771">prev</a><span>|</span><a href="#36143547">next</a><span>|</span><label class="collapse" for="c-36144671">[-]</label><label class="expand" for="c-36144671">[1 more]</label></div><br/><div class="children"><div class="content">Poe, I’m in the same boat btw</div><br/></div></div></div></div></div></div><div id="36143547" class="c"><input type="checkbox" id="c-36143547" checked=""/><div class="controls bullet"><span class="by">BeenAGoodUser</span><span>|</span><a href="#36143052">prev</a><span>|</span><a href="#36145520">next</a><span>|</span><label class="collapse" for="c-36143547">[-]</label><label class="expand" for="c-36143547">[4 more]</label></div><br/><div class="children"><div class="content">Nice to see they are working on reducing the pricing. GPT-4 is just too expensive right now imo. A long conversation would quickly end up costing tens of dollars if not more, so less expensive model costs + stateful API is urgently needed. I think even OpenAI will actually gain a lot by reducing the pricing, right now I wouldn&#x27;t be surprised if many uses of GPT-4 weren&#x27;t viable just because of the costs.</div><br/><div id="36144298" class="c"><input type="checkbox" id="c-36144298" checked=""/><div class="controls bullet"><span class="by">Terretta</span><span>|</span><a href="#36143547">parent</a><span>|</span><a href="#36145520">next</a><span>|</span><label class="collapse" for="c-36144298">[-]</label><label class="expand" for="c-36144298">[3 more]</label></div><br/><div class="children"><div class="content">This is off by probably x10 or more.<p>Dozens of people using it daily for coding and conversations and review in a month might be a couple hundred bucks.  All day convo, constantly, as fast as it can respond, might add up to $5.<p>Not sure what kind of convo you&#x27;re having that you could hit $10 unless you&#x27;re parallelizing with something like the &quot;guidance&quot; tool or langchain.</div><br/><div id="36144696" class="c"><input type="checkbox" id="c-36144696" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#36143547">root</a><span>|</span><a href="#36144298">parent</a><span>|</span><a href="#36144661">next</a><span>|</span><label class="collapse" for="c-36144696">[-]</label><label class="expand" for="c-36144696">[1 more]</label></div><br/><div class="children"><div class="content">The version of GPT 4 with 32K token context length is the enabler for a huge range of &quot;killer apps&quot;, but is even more expensive than the 8K version.<p>And yes, parallelism and loops are also key enablers for advanced use-cases.<p>For example, I have a lot of legacy code that needs uplifting. I&#x27;d love to be able to run different prompts over reams of code in parallel, iterating the prompts, etc...<p>The point of these things is that they&#x27;re like humans you can <i>clone</i> at will.<p>The ability to point <i>thousands</i> of these things at a code base could be mindblowing.</div><br/></div></div><div id="36144661" class="c"><input type="checkbox" id="c-36144661" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36143547">root</a><span>|</span><a href="#36144298">parent</a><span>|</span><a href="#36144696">prev</a><span>|</span><a href="#36145520">next</a><span>|</span><label class="collapse" for="c-36144661">[-]</label><label class="expand" for="c-36144661">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely not. Dinner just got here, but tl;dr gpt4 is 0.03 per 750 words in 0.06 per 750 words out. People except the history to be included as well</div><br/></div></div></div></div></div></div><div id="36145520" class="c"><input type="checkbox" id="c-36145520" checked=""/><div class="controls bullet"><span class="by">hoschicz</span><span>|</span><a href="#36143547">prev</a><span>|</span><a href="#36142983">next</a><span>|</span><label class="collapse" for="c-36145520">[-]</label><label class="expand" for="c-36145520">[1 more]</label></div><br/><div class="children"><div class="content">- they are working on a stateful API
- they are working on a cheaper version of GPT-4<p>Most probably this is driven by their use of it in ChatGPT, which is on fire from PMF. Clearly they&#x27;re experimenting with the cheaper GPT-4 in ChatGPT right now as it&#x27;s fairly turbo now, as discussed earlier today.</div><br/></div></div><div id="36142983" class="c"><input type="checkbox" id="c-36142983" checked=""/><div class="controls bullet"><span class="by">flakiness</span><span>|</span><a href="#36145520">prev</a><span>|</span><a href="#36141744">next</a><span>|</span><label class="collapse" for="c-36142983">[-]</label><label class="expand" for="c-36142983">[2 more]</label></div><br/><div class="children"><div class="content">If they open up fine-tuning API for their latest models, I wonder how the enthusiasm around the open source model is impacted. One of the advantages of the open source models is the ability to be fine-tuned. Are other benefits enough to keep the momentum going?</div><br/><div id="36143213" class="c"><input type="checkbox" id="c-36143213" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36142983">parent</a><span>|</span><a href="#36141744">next</a><span>|</span><label class="collapse" for="c-36143213">[-]</label><label class="expand" for="c-36143213">[1 more]</label></div><br/><div class="children"><div class="content">You better have deep pockets, have you check the prices and then the rates for using the tuned models?  They sure 10x to 100x more expensive then nontuned models</div><br/></div></div></div></div><div id="36141744" class="c"><input type="checkbox" id="c-36141744" checked=""/><div class="controls bullet"><span class="by">heyzk</span><span>|</span><a href="#36142983">prev</a><span>|</span><a href="#36143674">next</a><span>|</span><label class="collapse" for="c-36141744">[-]</label><label class="expand" for="c-36141744">[1 more]</label></div><br/><div class="children"><div class="content">Great writeup, this helps us understand where to spend our time vs what OpenAI&#x27;s progress will solve.</div><br/></div></div><div id="36143674" class="c"><input type="checkbox" id="c-36143674" checked=""/><div class="controls bullet"><span class="by">naillo</span><span>|</span><a href="#36141744">prev</a><span>|</span><a href="#36142644">next</a><span>|</span><label class="collapse" for="c-36143674">[-]</label><label class="expand" for="c-36143674">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Plugins “don’t have PMF”<p>Probability mass functions? Anyone know what this means in this context?</div><br/><div id="36143728" class="c"><input type="checkbox" id="c-36143728" checked=""/><div class="controls bullet"><span class="by">simonbutt</span><span>|</span><a href="#36143674">parent</a><span>|</span><a href="#36143862">next</a><span>|</span><label class="collapse" for="c-36143728">[-]</label><label class="expand" for="c-36143728">[1 more]</label></div><br/><div class="children"><div class="content">Product market fit</div><br/></div></div></div></div><div id="36144805" class="c"><input type="checkbox" id="c-36144805" checked=""/><div class="controls bullet"><span class="by">vb-8448</span><span>|</span><a href="#36142644">prev</a><span>|</span><a href="#36142788">next</a><span>|</span><label class="collapse" for="c-36144805">[-]</label><label class="expand" for="c-36144805">[1 more]</label></div><br/><div class="children"><div class="content">7. find a sustainable business model and make some money</div><br/></div></div><div id="36142788" class="c"><input type="checkbox" id="c-36142788" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36144805">prev</a><span>|</span><a href="#36142227">next</a><span>|</span><label class="collapse" for="c-36142788">[-]</label><label class="expand" for="c-36142788">[1 more]</label></div><br/><div class="children"><div class="content">why should I believe what someone says their plans are</div><br/></div></div><div id="36142227" class="c"><input type="checkbox" id="c-36142227" checked=""/><div class="controls bullet"><span class="by">boringuser2</span><span>|</span><a href="#36142788">prev</a><span>|</span><a href="#36142481">next</a><span>|</span><label class="collapse" for="c-36142227">[-]</label><label class="expand" for="c-36142227">[18 more]</label></div><br/><div class="children"><div class="content">&gt;Dedicated capacity offering is limited by GPU availability. OpenAI also offers dedicated capacity, which provides customers with a private copy of the model. To access this service, customers must be willing to commit to a $100k spend upfront.<p>How many shell corporations are intelligence agencies seeding right now?</div><br/><div id="36142558" class="c"><input type="checkbox" id="c-36142558" checked=""/><div class="controls bullet"><span class="by">cwkoss</span><span>|</span><a href="#36142227">parent</a><span>|</span><a href="#36143561">next</a><span>|</span><label class="collapse" for="c-36142558">[-]</label><label class="expand" for="c-36142558">[10 more]</label></div><br/><div class="children"><div class="content">Last night I was musing how many different countries&#x27; intelligence agencies have moles working at OpenAI currently.  Gotta be at least 6, maybe as high as two dozen?</div><br/><div id="36144418" class="c"><input type="checkbox" id="c-36144418" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36142558">parent</a><span>|</span><a href="#36143194">next</a><span>|</span><label class="collapse" for="c-36144418">[-]</label><label class="expand" for="c-36144418">[4 more]</label></div><br/><div class="children"><div class="content">US, France, Israel ... then who?  Maybe another five eyes country like the UK?  Possibly China?  I&#x27;m pretty skeptical Russia would be able to get someone in there but maybe.</div><br/><div id="36144634" class="c"><input type="checkbox" id="c-36144634" checked=""/><div class="controls bullet"><span class="by">invaliduser</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36144418">parent</a><span>|</span><a href="#36145997">next</a><span>|</span><label class="collapse" for="c-36144634">[-]</label><label class="expand" for="c-36144634">[2 more]</label></div><br/><div class="children"><div class="content">Hi. French here. I may be wrong, but I really feel like you are overestimating  us.</div><br/><div id="36144869" class="c"><input type="checkbox" id="c-36144869" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36144634">parent</a><span>|</span><a href="#36145997">next</a><span>|</span><label class="collapse" for="c-36144869">[-]</label><label class="expand" for="c-36144869">[1 more]</label></div><br/><div class="children"><div class="content">DGSE essentially puts all of it&#x27;s money&#x2F;effort into industrial espionage and they&#x27;re the best in the world at it.</div><br/></div></div></div></div><div id="36145997" class="c"><input type="checkbox" id="c-36145997" checked=""/><div class="controls bullet"><span class="by">boringuser2</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36144418">parent</a><span>|</span><a href="#36144634">prev</a><span>|</span><a href="#36143194">next</a><span>|</span><label class="collapse" for="c-36145997">[-]</label><label class="expand" for="c-36145997">[1 more]</label></div><br/><div class="children"><div class="content">You said Isr*el twice.</div><br/></div></div></div></div><div id="36143194" class="c"><input type="checkbox" id="c-36143194" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36142558">parent</a><span>|</span><a href="#36144418">prev</a><span>|</span><a href="#36142589">next</a><span>|</span><label class="collapse" for="c-36143194">[-]</label><label class="expand" for="c-36143194">[4 more]</label></div><br/><div class="children"><div class="content">I bet the NSA has dossier on every employee there as well</div><br/><div id="36143292" class="c"><input type="checkbox" id="c-36143292" checked=""/><div class="controls bullet"><span class="by">boringuser2</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36143194">parent</a><span>|</span><a href="#36142589">next</a><span>|</span><label class="collapse" for="c-36143292">[-]</label><label class="expand" for="c-36143292">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Cooperate or we&#x27;ll kill your family&quot;.<p>(Just to be clear, this is a hypothetical intelligence agent saying this, not me.)<p>I mean, it&#x27;s not exactly rocket science, who wouldn&#x27;t instantly fold to that?</div><br/><div id="36143472" class="c"><input type="checkbox" id="c-36143472" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36143292">parent</a><span>|</span><a href="#36142589">next</a><span>|</span><label class="collapse" for="c-36143472">[-]</label><label class="expand" for="c-36143472">[2 more]</label></div><br/><div class="children"><div class="content">Someone without family?</div><br/><div id="36143480" class="c"><input type="checkbox" id="c-36143480" checked=""/><div class="controls bullet"><span class="by">boringuser2</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36143472">parent</a><span>|</span><a href="#36142589">next</a><span>|</span><label class="collapse" for="c-36143480">[-]</label><label class="expand" for="c-36143480">[1 more]</label></div><br/><div class="children"><div class="content">You know the next step, right?</div><br/></div></div></div></div></div></div></div></div><div id="36142589" class="c"><input type="checkbox" id="c-36142589" checked=""/><div class="controls bullet"><span class="by">boringuser2</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36142558">parent</a><span>|</span><a href="#36143194">prev</a><span>|</span><a href="#36143561">next</a><span>|</span><label class="collapse" for="c-36142589">[-]</label><label class="expand" for="c-36142589">[1 more]</label></div><br/><div class="children"><div class="content">Agent Lee Chen Huwang, reporting for duty.</div><br/></div></div></div></div><div id="36143561" class="c"><input type="checkbox" id="c-36143561" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36142227">parent</a><span>|</span><a href="#36142558">prev</a><span>|</span><a href="#36144996">next</a><span>|</span><label class="collapse" for="c-36143561">[-]</label><label class="expand" for="c-36143561">[4 more]</label></div><br/><div class="children"><div class="content">I had been putting theories in comments but they kept getting flagged or banned or downvoted to oblivion, but maybe its time has come. I&#x27;ll keep it tame. If you are curious you can google connections of OpenAI board of directors, Will Hurd, In-Q-Tel trustees, Allen and Company, etc. There is more but whatever. The conspiracy theory is that &#x27;the govt stepped in&#x27; during the six month pause after gpt-4 was trained and before it was released.</div><br/><div id="36144607" class="c"><input type="checkbox" id="c-36144607" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36143561">parent</a><span>|</span><a href="#36144996">next</a><span>|</span><label class="collapse" for="c-36144607">[-]</label><label class="expand" for="c-36144607">[3 more]</label></div><br/><div class="children"><div class="content">It probably keeps getting flagged because it’s ahistorical, source: OpenAI engineers, and #2 somewhat obviously so. You heard of RLHF?</div><br/><div id="36145568" class="c"><input type="checkbox" id="c-36145568" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36144607">parent</a><span>|</span><a href="#36144996">next</a><span>|</span><label class="collapse" for="c-36145568">[-]</label><label class="expand" for="c-36145568">[2 more]</label></div><br/><div class="children"><div class="content">&gt; You heard of RLHF?<p>The conspiracy theory isn&#x27;t that every employee of OpenAI spent 8 hours every day for six months in meetings with govt agencies.</div><br/><div id="36147177" class="c"><input type="checkbox" id="c-36147177" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36145568">parent</a><span>|</span><a href="#36144996">next</a><span>|</span><label class="collapse" for="c-36147177">[-]</label><label class="expand" for="c-36147177">[1 more]</label></div><br/><div class="children"><div class="content">not sure what you mean. anyways, the reason why they don’t release GPT4 when they’re “”“done””” training in June is they have to RLHF</div><br/></div></div></div></div></div></div></div></div><div id="36144996" class="c"><input type="checkbox" id="c-36144996" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#36142227">parent</a><span>|</span><a href="#36143561">prev</a><span>|</span><a href="#36143178">next</a><span>|</span><label class="collapse" for="c-36144996">[-]</label><label class="expand" for="c-36144996">[1 more]</label></div><br/><div class="children"><div class="content">Private instance means a dedicated endpoint fully managed by OpenAI. You do not get model access or anything a regular API user doesn&#x27;t already get, except your API url will be something like customer123.openai.com&#x2F;api instead of api.openai.com&#x2F;api</div><br/></div></div><div id="36143178" class="c"><input type="checkbox" id="c-36143178" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36142227">parent</a><span>|</span><a href="#36144996">prev</a><span>|</span><a href="#36142481">next</a><span>|</span><label class="collapse" for="c-36143178">[-]</label><label class="expand" for="c-36143178">[2 more]</label></div><br/><div class="children"><div class="content">They are not gonna give the weights for sure but it still will be inferencable, I’m not sure how but it’s be self destructive if they did</div><br/><div id="36143264" class="c"><input type="checkbox" id="c-36143264" checked=""/><div class="controls bullet"><span class="by">boringuser2</span><span>|</span><a href="#36142227">root</a><span>|</span><a href="#36143178">parent</a><span>|</span><a href="#36142481">next</a><span>|</span><label class="collapse" for="c-36143264">[-]</label><label class="expand" for="c-36143264">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, with a private model you could easily extract the weights.</div><br/></div></div></div></div></div></div><div id="36142481" class="c"><input type="checkbox" id="c-36142481" checked=""/><div class="controls bullet"><span class="by">cryptoz</span><span>|</span><a href="#36142227">prev</a><span>|</span><a href="#36142471">next</a><span>|</span><label class="collapse" for="c-36142481">[-]</label><label class="expand" for="c-36142481">[1 more]</label></div><br/><div class="children"><div class="content">Great content and great answers except for open source question. Sam is saying that he doesn’t think anyone would be able to run the code at scale so they didn’t bother? Seems like a nonsense answer, maybe I’m misunderstanding. The ability for individuals or businesses to effectively run and host the code shouldn’t have an impact on the ability to open source.</div><br/></div></div><div id="36142471" class="c"><input type="checkbox" id="c-36142471" checked=""/><div class="controls bullet"><span class="by">atemerev</span><span>|</span><a href="#36142481">prev</a><span>|</span><label class="collapse" for="c-36142471">[-]</label><label class="expand" for="c-36142471">[7 more]</label></div><br/><div class="children"><div class="content">All AI companies (OpenAI included) are now working full tilt on making AIs improve themselves (writing their own code, inventing new pipelines etc). I don&#x27;t know why choose anything else to work on. This is a prime directive, that will bring the greatest payoff.</div><br/><div id="36142841" class="c"><input type="checkbox" id="c-36142841" checked=""/><div class="controls bullet"><span class="by">huijzer</span><span>|</span><a href="#36142471">parent</a><span>|</span><a href="#36143184">next</a><span>|</span><label class="collapse" for="c-36142841">[-]</label><label class="expand" for="c-36142841">[1 more]</label></div><br/><div class="children"><div class="content">I disagree since GPUs are a major constraint currently and that skilled specialists outperform GPT-4 almost always as long as they stay in their domain.<p>Will they use copilot(s) to improve the models? Yes, but they have been doing that since 2021 already (the release year of GitHub Copilot).</div><br/></div></div><div id="36143184" class="c"><input type="checkbox" id="c-36143184" checked=""/><div class="controls bullet"><span class="by">ren_engineer</span><span>|</span><a href="#36142471">parent</a><span>|</span><a href="#36142841">prev</a><span>|</span><a href="#36143253">next</a><span>|</span><label class="collapse" for="c-36143184">[-]</label><label class="expand" for="c-36143184">[3 more]</label></div><br/><div class="children"><div class="content">if this was currently possible wouldn&#x27;t it lead to sentient&#x2F;superhuman AI rapidly?<p>&gt;tell AI to make itself more efficient by finding performance improvements in human written code<p>&gt;that newly available processing power can now be used to find more ways to improve itself<p>&gt;flywheel effect of AI improving itself as it gets smarter and smarter<p>eventually you&#x27;d turn it loose on improving the actual hardware it runs on. I think the question now is really how far transformers can be taken and if they are really the path to &quot;real&quot; AI.</div><br/><div id="36144566" class="c"><input type="checkbox" id="c-36144566" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#36142471">root</a><span>|</span><a href="#36143184">parent</a><span>|</span><a href="#36143253">next</a><span>|</span><label class="collapse" for="c-36144566">[-]</label><label class="expand" for="c-36144566">[2 more]</label></div><br/><div class="children"><div class="content">Within a couple of years of improvement processes like you suggest will actually be really dangerous and stupid.<p>Also don&#x27;t confuse all other types of human&#x2F;animal characteristics like sentience with intelligence. They are different things. Things like sentience, subjective stream of experience, or other aspects of being alive don&#x27;t just accidentally fall out of larger training datasets.<p>And we should be glad. The models are going to be orders of magnitude faster (and perhaps X times higher IQ) than humans within a few years. It is incredibly foolish to try to make something like that into a living creature (or emulation of living).</div><br/><div id="36144976" class="c"><input type="checkbox" id="c-36144976" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36142471">root</a><span>|</span><a href="#36144566">parent</a><span>|</span><a href="#36143253">next</a><span>|</span><label class="collapse" for="c-36144976">[-]</label><label class="expand" for="c-36144976">[1 more]</label></div><br/><div class="children"><div class="content">Intelligence is about action, and sentience is about qualia, which I equate to perceptions coloured by values. Action is visible and qualia are hidden, but they are closely interconnected: we choose our actions in accordance with our values and situation at hand.</div><br/></div></div></div></div></div></div><div id="36143253" class="c"><input type="checkbox" id="c-36143253" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36142471">parent</a><span>|</span><a href="#36143184">prev</a><span>|</span><a href="#36146064">next</a><span>|</span><label class="collapse" for="c-36143253">[-]</label><label class="expand" for="c-36143253">[1 more]</label></div><br/><div class="children"><div class="content">I think they are at least 1-2 new big research breakthroughs(on the level of Attention) away from having this.</div><br/></div></div><div id="36146064" class="c"><input type="checkbox" id="c-36146064" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36142471">parent</a><span>|</span><a href="#36143253">prev</a><span>|</span><label class="collapse" for="c-36146064">[-]</label><label class="expand" for="c-36146064">[1 more]</label></div><br/><div class="children"><div class="content">Well that is demonstrably untrue.</div><br/></div></div></div></div></div></div></div></div></div></body></html>