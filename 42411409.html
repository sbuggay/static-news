<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1734426072227" as="style"/><link rel="stylesheet" href="styles.css?v=1734426072227"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://venturebeat.com/ai/new-llm-optimization-technique-slashes-memory-costs-up-to-75/">New LLM optimization technique slashes memory costs</a> <span class="domain">(<a href="https://venturebeat.com">venturebeat.com</a>)</span></div><div class="subtext"><span>hochmartinez</span> | <span>96 comments</span></div><br/><div><div id="42437226" class="c"><input type="checkbox" id="c-42437226" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42438070">next</a><span>|</span><label class="collapse" for="c-42437226">[-]</label><label class="expand" for="c-42437226">[4 more]</label></div><br/><div class="children"><div class="content">Wonder how this compares with Microsoft&#x27;s HeadKV paper [1] which claims a 98% percent reduction in memory while retaining 97% of the performance.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;html&#x2F;2410.19258v3" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;html&#x2F;2410.19258v3</a></div><br/><div id="42439503" class="c"><input type="checkbox" id="c-42439503" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#42437226">parent</a><span>|</span><a href="#42438070">next</a><span>|</span><label class="collapse" for="c-42439503">[-]</label><label class="expand" for="c-42439503">[3 more]</label></div><br/><div class="children"><div class="content">Seems like a different thing. That paper appears to be memory reduction in caching while article appears to be memory reduction in content.</div><br/><div id="42439617" class="c"><input type="checkbox" id="c-42439617" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42437226">root</a><span>|</span><a href="#42439503">parent</a><span>|</span><a href="#42438070">next</a><span>|</span><label class="collapse" for="c-42439617">[-]</label><label class="expand" for="c-42439617">[2 more]</label></div><br/><div class="children"><div class="content">They’re both exploring the same space of optimizing the memory needed by the KV cache which is essentially another name for the context window (no one elides the KV cache as otherwise you’re doing N^2 math to do attention). They’re exploring different approaches to achieve the same goal and they may be both possible to apply simultaneously to reduce the attention mechanism to almost 0 memory usage which would be really cool, but I’m curious how they compare against each other individually.</div><br/><div id="42439655" class="c"><input type="checkbox" id="c-42439655" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#42437226">root</a><span>|</span><a href="#42439617">parent</a><span>|</span><a href="#42438070">next</a><span>|</span><label class="collapse" for="c-42439655">[-]</label><label class="expand" for="c-42439655">[1 more]</label></div><br/><div class="children"><div class="content">That sounds like a stretch to me.</div><br/></div></div></div></div></div></div></div></div><div id="42438070" class="c"><input type="checkbox" id="c-42438070" checked=""/><div class="controls bullet"><span class="by">odyssey7</span><span>|</span><a href="#42437226">prev</a><span>|</span><a href="#42437228">next</a><span>|</span><label class="collapse" for="c-42438070">[-]</label><label class="expand" for="c-42438070">[29 more]</label></div><br/><div class="children"><div class="content">Is it possible that after 3-4 years of performance optimizations, both algorithmic and in hardware efficiency, it will turn out that we didn’t really need all of the nuclear plants we’re currently in the process of setting up to satisfy the power demands of AI data centers?</div><br/><div id="42438156" class="c"><input type="checkbox" id="c-42438156" checked=""/><div class="controls bullet"><span class="by">_aavaa_</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438540">next</a><span>|</span><label class="collapse" for="c-42438156">[-]</label><label class="expand" for="c-42438156">[10 more]</label></div><br/><div class="children"><div class="content">Nobody is building nuclear power plants for data centres. A few people have signed some paperwork saying that they would buy electricity from new nuclear plants if they could deliver it at a certain price, a price mind you that has not been done before. Others are trying to restart an existing reactor at three mile island (a thing that has never been done before, and likely won&#x27;t be done now since the reactor was shut down due to being too expensive to run).<p>And certainly nobody is building one in the next 3-4 years; they&#x27;d be lucky to finish the paperwork in that time.<p>What is actually going to power them is solar, wind, and batteries: <a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2024&#x2F;12&#x2F;10&#x2F;24317888&#x2F;googles-data-center-solar-wind-renewable-energy-intersect-partnership" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2024&#x2F;12&#x2F;10&#x2F;24317888&#x2F;googles-data-ce...</a></div><br/><div id="42438475" class="c"><input type="checkbox" id="c-42438475" checked=""/><div class="controls bullet"><span class="by">standeven</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438156">parent</a><span>|</span><a href="#42438750">next</a><span>|</span><label class="collapse" for="c-42438475">[-]</label><label class="expand" for="c-42438475">[1 more]</label></div><br/><div class="children"><div class="content">And unfortunately, gas and coal in the meantime.<p><a href="https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2024&#x2F;sep&#x2F;15&#x2F;data-center-gas-emissions-tech" rel="nofollow">https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2024&#x2F;sep&#x2F;15&#x2F;data-cent...</a></div><br/></div></div><div id="42438750" class="c"><input type="checkbox" id="c-42438750" checked=""/><div class="controls bullet"><span class="by">aitchnyu</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438156">parent</a><span>|</span><a href="#42438475">prev</a><span>|</span><a href="#42438847">next</a><span>|</span><label class="collapse" for="c-42438750">[-]</label><label class="expand" for="c-42438750">[1 more]</label></div><br/><div class="children"><div class="content">Could be a good candidate for factobattery. Overbuild the system, run them at full speed at peak solar generation, then underclock them at night.<p><a href="https:&#x2F;&#x2F;www.moderndescartes.com&#x2F;essays&#x2F;factobattery&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.moderndescartes.com&#x2F;essays&#x2F;factobattery&#x2F;</a></div><br/></div></div><div id="42438847" class="c"><input type="checkbox" id="c-42438847" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438156">parent</a><span>|</span><a href="#42438750">prev</a><span>|</span><a href="#42438917">next</a><span>|</span><label class="collapse" for="c-42438847">[-]</label><label class="expand" for="c-42438847">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Nobody is building nuclear power plants for data centres. A few people have signed some paperwork saying that they would buy electricity from new nuclear plants if they could deliver it at a certain price, a price mind you that has not been done before.<p>Not building new, but I think Microsoft paying to restart a reactor at Three Mile Island for their datacenter is much more significant than you make the deals sound:<p><a href="https:&#x2F;&#x2F;www.theguardian.com&#x2F;environment&#x2F;2024&#x2F;sep&#x2F;20&#x2F;three-mile-island-nuclear-plant-reopen-microsoft" rel="nofollow">https:&#x2F;&#x2F;www.theguardian.com&#x2F;environment&#x2F;2024&#x2F;sep&#x2F;20&#x2F;three-mi...</a></div><br/><div id="42439598" class="c"><input type="checkbox" id="c-42439598" checked=""/><div class="controls bullet"><span class="by">portaouflop</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438847">parent</a><span>|</span><a href="#42438917">next</a><span>|</span><label class="collapse" for="c-42439598">[-]</label><label class="expand" for="c-42439598">[1 more]</label></div><br/><div class="children"><div class="content">They say it’s going to be online in 2028.<p>Are you willing to bet that they won’t have 3 mile island operational by 2030?</div><br/></div></div></div></div><div id="42438917" class="c"><input type="checkbox" id="c-42438917" checked=""/><div class="controls bullet"><span class="by">yunohn</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438156">parent</a><span>|</span><a href="#42438847">prev</a><span>|</span><a href="#42438779">next</a><span>|</span><label class="collapse" for="c-42438917">[-]</label><label class="expand" for="c-42438917">[4 more]</label></div><br/><div class="children"><div class="content">Look, I agree that nuclear is difficult, but Google and Microsoft have publicly committed to those projects you’re mentioning. I don’t understand your dismissive tone that all of it is hogwash? This is one of those HN armchair comments.</div><br/><div id="42439612" class="c"><input type="checkbox" id="c-42439612" checked=""/><div class="controls bullet"><span class="by">portaouflop</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438917">parent</a><span>|</span><a href="#42438965">next</a><span>|</span><label class="collapse" for="c-42439612">[-]</label><label class="expand" for="c-42439612">[1 more]</label></div><br/><div class="children"><div class="content">Microsoft also committed publicly to prioritise security. And Google says they prioritise privacy of their users above all else.<p>I pity the fool that believes anything these corporations put out publicly.<p>Actions matter, words are wind</div><br/></div></div><div id="42438965" class="c"><input type="checkbox" id="c-42438965" checked=""/><div class="controls bullet"><span class="by">dx034</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438917">parent</a><span>|</span><a href="#42439612">prev</a><span>|</span><a href="#42439188">next</a><span>|</span><label class="collapse" for="c-42438965">[-]</label><label class="expand" for="c-42438965">[1 more]</label></div><br/><div class="children"><div class="content">But not just for AI, for all their data center operations.</div><br/></div></div><div id="42439188" class="c"><input type="checkbox" id="c-42439188" checked=""/><div class="controls bullet"><span class="by">yard2010</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438917">parent</a><span>|</span><a href="#42438965">prev</a><span>|</span><a href="#42438779">next</a><span>|</span><label class="collapse" for="c-42439188">[-]</label><label class="expand" for="c-42439188">[1 more]</label></div><br/><div class="children"><div class="content">Google and Microsoft won&#x27;t do anything that doesn&#x27;t translate to money. These days are over.</div><br/></div></div></div></div><div id="42438779" class="c"><input type="checkbox" id="c-42438779" checked=""/><div class="controls bullet"><span class="by">adelpozo</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438156">parent</a><span>|</span><a href="#42438917">prev</a><span>|</span><a href="#42438540">next</a><span>|</span><label class="collapse" for="c-42438779">[-]</label><label class="expand" for="c-42438779">[1 more]</label></div><br/><div class="children"><div class="content">Or solar in space, which some have already heard of Lumen Orbit <a href="https:&#x2F;&#x2F;www.ycombinator.com&#x2F;companies&#x2F;lumen-orbit">https:&#x2F;&#x2F;www.ycombinator.com&#x2F;companies&#x2F;lumen-orbit</a></div><br/></div></div></div></div><div id="42438540" class="c"><input type="checkbox" id="c-42438540" checked=""/><div class="controls bullet"><span class="by">owenpalmer</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438156">prev</a><span>|</span><a href="#42438196">next</a><span>|</span><label class="collapse" for="c-42438540">[-]</label><label class="expand" for="c-42438540">[2 more]</label></div><br/><div class="children"><div class="content">No. This is a classic case of Jevon&#x27;s paradox. Increased efficiency in resource use can lead to increased consumption of that resource, rather than decreased consumption.<p>Example:<p>1. To decrease total gas consumption, more fuel efficient vehicles are invented.<p>2. Instead of using less gas, people drive <i>more miles</i>. They take longer road trips, commute farther for work, and more people can now afford to drive.<p>3. This increased driving leads to higher overall gasoline consumption, despite each car using gas more efficiently.</div><br/><div id="42439170" class="c"><input type="checkbox" id="c-42439170" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438540">parent</a><span>|</span><a href="#42438196">next</a><span>|</span><label class="collapse" for="c-42439170">[-]</label><label class="expand" for="c-42439170">[1 more]</label></div><br/><div class="children"><div class="content">See also <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Induced_demand" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Induced_demand</a></div><br/></div></div></div></div><div id="42438196" class="c"><input type="checkbox" id="c-42438196" checked=""/><div class="controls bullet"><span class="by">sbierwagen</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438540">prev</a><span>|</span><a href="#42439547">next</a><span>|</span><label class="collapse" for="c-42438196">[-]</label><label class="expand" for="c-42438196">[3 more]</label></div><br/><div class="children"><div class="content">Congrats, you have independently reinvented the Hardware Overhang hypothesis: that early AGI could be very inefficient, undergo several optimization passes, and go from needing a datacenter of compute to, say, a single video game console&#x27;s worth: <a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;75dnjiD8kv2khe9eQ&#x2F;measuring-hardware-overhang" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;75dnjiD8kv2khe9eQ&#x2F;measuring-...</a><p>In that scenario, you can go from 0 independent artificial intelligences to tens of millions of them, very quickly.</div><br/><div id="42438377" class="c"><input type="checkbox" id="c-42438377" checked=""/><div class="controls bullet"><span class="by">philipswood</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438196">parent</a><span>|</span><a href="#42438344">next</a><span>|</span><label class="collapse" for="c-42438377">[-]</label><label class="expand" for="c-42438377">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing. Worth its own submission: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newest">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newest</a></div><br/></div></div><div id="42438344" class="c"><input type="checkbox" id="c-42438344" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438196">parent</a><span>|</span><a href="#42438377">prev</a><span>|</span><a href="#42439547">next</a><span>|</span><label class="collapse" for="c-42438344">[-]</label><label class="expand" for="c-42438344">[1 more]</label></div><br/><div class="children"><div class="content">it would seem perfectly reasonable to expect the first AIs to be very unoptimized and if the AIs are any good they will be able to optimize themselves a lot and even help design ASICs to help run them.</div><br/></div></div></div></div><div id="42439547" class="c"><input type="checkbox" id="c-42439547" checked=""/><div class="controls bullet"><span class="by">ndr</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438196">prev</a><span>|</span><a href="#42438101">next</a><span>|</span><label class="collapse" for="c-42439547">[-]</label><label class="expand" for="c-42439547">[1 more]</label></div><br/><div class="children"><div class="content">Wirth&#x27;s law: software is getting slower more rapidly than hardware is becoming faster.<p>I think there&#x27;s the energy parallel: Software is becoming more energy-hungry faster than algorithms are becoming efficient.<p>So we&#x27;ll still need the energy.</div><br/></div></div><div id="42438101" class="c"><input type="checkbox" id="c-42438101" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42439547">prev</a><span>|</span><a href="#42438096">next</a><span>|</span><label class="collapse" for="c-42438101">[-]</label><label class="expand" for="c-42438101">[1 more]</label></div><br/><div class="children"><div class="content">No, as the things using that power get better (newer models keep getting less garbagey) and cheaper (faster hardware and more efficient use of power), people will keep coming up with more things to use them for.</div><br/></div></div><div id="42438096" class="c"><input type="checkbox" id="c-42438096" checked=""/><div class="controls bullet"><span class="by">Trasmatta</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438101">prev</a><span>|</span><a href="#42438341">next</a><span>|</span><label class="collapse" for="c-42438096">[-]</label><label class="expand" for="c-42438096">[2 more]</label></div><br/><div class="children"><div class="content">Are we setting up nuclear plants for AI data centers? If so, I see that as a win all around. We need to rely more on nuclear power, and I&#x27;ll take whatever we can get to push us in that direction.</div><br/><div id="42438241" class="c"><input type="checkbox" id="c-42438241" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#42438070">root</a><span>|</span><a href="#42438096">parent</a><span>|</span><a href="#42438341">next</a><span>|</span><label class="collapse" for="c-42438241">[-]</label><label class="expand" for="c-42438241">[1 more]</label></div><br/><div class="children"><div class="content">How else will we get manufacturing gains for a mars base nuclear system?</div><br/></div></div></div></div><div id="42438341" class="c"><input type="checkbox" id="c-42438341" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438096">prev</a><span>|</span><a href="#42439412">next</a><span>|</span><label class="collapse" for="c-42438341">[-]</label><label class="expand" for="c-42438341">[1 more]</label></div><br/><div class="children"><div class="content">You have it flipped. But it&#x27;s both.<p>AI compute is measured in gigawatts, not gigaflops.<p>It&#x27;s &quot;how any gigawatts of compute can we get allocated?&quot;<p>Not<p>&quot;How much compute can we fit inside of a gigawatt?&quot;<p>There&#x27;s no such thing as &quot;enough&quot;</div><br/></div></div><div id="42439412" class="c"><input type="checkbox" id="c-42439412" checked=""/><div class="controls bullet"><span class="by">lm28469</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438341">prev</a><span>|</span><a href="#42438114">next</a><span>|</span><label class="collapse" for="c-42439412">[-]</label><label class="expand" for="c-42439412">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s called the rebound effect, at no point in modern history efficiency reduced our energy needs, we just use the extra energy to either run more of the same thing or run other things</div><br/></div></div><div id="42438114" class="c"><input type="checkbox" id="c-42438114" checked=""/><div class="controls bullet"><span class="by">TkTech</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42439412">prev</a><span>|</span><a href="#42438340">next</a><span>|</span><label class="collapse" for="c-42438114">[-]</label><label class="expand" for="c-42438114">[1 more]</label></div><br/><div class="children"><div class="content">No, not really. AWS getting more power and space efficient chips didn&#x27;t reduce total power demand, they just added more cores.<p>Even if the data centers didn&#x27;t keep up with available capacity, energy demanding industry move to and expand with sources of power, like aluminum production.</div><br/></div></div><div id="42438264" class="c"><input type="checkbox" id="c-42438264" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438340">prev</a><span>|</span><a href="#42438092">next</a><span>|</span><label class="collapse" for="c-42438264">[-]</label><label class="expand" for="c-42438264">[1 more]</label></div><br/><div class="children"><div class="content">I think they can easily eat up the new capacity with larger multimodal  models that ground language on video.</div><br/></div></div><div id="42438092" class="c"><input type="checkbox" id="c-42438092" checked=""/><div class="controls bullet"><span class="by">groceryheist</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438264">prev</a><span>|</span><a href="#42438612">next</a><span>|</span><label class="collapse" for="c-42438092">[-]</label><label class="expand" for="c-42438092">[1 more]</label></div><br/><div class="children"><div class="content">If we&#x27;re &quot;lucky&quot; (in an AI-optimist sense) we&#x27;ll need the nuclear plants despite efficiency increases.</div><br/></div></div><div id="42438612" class="c"><input type="checkbox" id="c-42438612" checked=""/><div class="controls bullet"><span class="by">m463</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438092">prev</a><span>|</span><a href="#42438082">next</a><span>|</span><label class="collapse" for="c-42438612">[-]</label><label class="expand" for="c-42438612">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t you think people will just add better models to meet available memory?<p>If we run 7B now, why wouldn&#x27;t we run 700b with memory optimizations?</div><br/></div></div><div id="42438082" class="c"><input type="checkbox" id="c-42438082" checked=""/><div class="controls bullet"><span class="by">NhanH</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438612">prev</a><span>|</span><a href="#42438100">next</a><span>|</span><label class="collapse" for="c-42438082">[-]</label><label class="expand" for="c-42438082">[1 more]</label></div><br/><div class="children"><div class="content">It seems (feels?) likely that demand for LLM is elastic, especially when it comes to specialized niche. Less power requirements just mean we run more of them in parallel for stuffs, so the power needs is gonna be growing anyway.</div><br/></div></div><div id="42438100" class="c"><input type="checkbox" id="c-42438100" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#42438070">parent</a><span>|</span><a href="#42438082">prev</a><span>|</span><a href="#42437228">next</a><span>|</span><label class="collapse" for="c-42438100">[-]</label><label class="expand" for="c-42438100">[1 more]</label></div><br/><div class="children"><div class="content">Jevons paradox says as things get more efficient, usage goes up. In this case, even if AI data centers don&#x27;t pan out, I think we&#x27;ll still find use for the electricity they generate.</div><br/></div></div></div></div><div id="42437228" class="c"><input type="checkbox" id="c-42437228" checked=""/><div class="controls bullet"><span class="by">ComputerGuru</span><span>|</span><a href="#42438070">prev</a><span>|</span><a href="#42437202">next</a><span>|</span><label class="collapse" for="c-42437228">[-]</label><label class="expand" for="c-42437228">[7 more]</label></div><br/><div class="children"><div class="content">This only decreases memory cost of input context window, not the memory cost to load and run the models.</div><br/><div id="42437514" class="c"><input type="checkbox" id="c-42437514" checked=""/><div class="controls bullet"><span class="by">solarkraft</span><span>|</span><a href="#42437228">parent</a><span>|</span><a href="#42437391">next</a><span>|</span><label class="collapse" for="c-42437514">[-]</label><label class="expand" for="c-42437514">[1 more]</label></div><br/><div class="children"><div class="content">And that’s what matters the most! To me, at small model sizes (1-8B), anyway. A few thousans tokens already bog my RAM down quite a lot and I’d love to have more - I’d go as far as saying that context greatly determines LLM capability at this point.</div><br/></div></div><div id="42437391" class="c"><input type="checkbox" id="c-42437391" checked=""/><div class="controls bullet"><span class="by">freehorse</span><span>|</span><a href="#42437228">parent</a><span>|</span><a href="#42437514">prev</a><span>|</span><a href="#42437483">next</a><span>|</span><label class="collapse" for="c-42437391">[-]</label><label class="expand" for="c-42437391">[1 more]</label></div><br/><div class="children"><div class="content">Context window requires ram too.</div><br/></div></div><div id="42437483" class="c"><input type="checkbox" id="c-42437483" checked=""/><div class="controls bullet"><span class="by">keyle</span><span>|</span><a href="#42437228">parent</a><span>|</span><a href="#42437391">prev</a><span>|</span><a href="#42437457">next</a><span>|</span><label class="collapse" for="c-42437483">[-]</label><label class="expand" for="c-42437483">[2 more]</label></div><br/><div class="children"><div class="content">I agree with you though, the title is misleading.</div><br/><div id="42438775" class="c"><input type="checkbox" id="c-42438775" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#42437228">root</a><span>|</span><a href="#42437483">parent</a><span>|</span><a href="#42437457">next</a><span>|</span><label class="collapse" for="c-42438775">[-]</label><label class="expand" for="c-42438775">[1 more]</label></div><br/><div class="children"><div class="content">Title is perfect. Their typical audience probably understands &quot;memory&quot; better than &quot;context window&quot;, but then if you&#x27;ve actually deployed these systems it&#x27;s not difficult to go the other way, from &quot;memory&quot; to &quot;context window&quot; since the context window specifically is known to take additional VRAM over the model itself</div><br/></div></div></div></div><div id="42437457" class="c"><input type="checkbox" id="c-42437457" checked=""/><div class="controls bullet"><span class="by">ynniv</span><span>|</span><a href="#42437228">parent</a><span>|</span><a href="#42437483">prev</a><span>|</span><a href="#42437682">next</a><span>|</span><label class="collapse" for="c-42437457">[-]</label><label class="expand" for="c-42437457">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Only&quot;</div><br/></div></div></div></div><div id="42437202" class="c"><input type="checkbox" id="c-42437202" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#42437228">prev</a><span>|</span><a href="#42438187">next</a><span>|</span><label class="collapse" for="c-42437202">[-]</label><label class="expand" for="c-42437202">[2 more]</label></div><br/><div class="children"><div class="content">TFP: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2410.13166" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2410.13166</a></div><br/><div id="42437217" class="c"><input type="checkbox" id="c-42437217" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42437202">parent</a><span>|</span><a href="#42438187">next</a><span>|</span><label class="collapse" for="c-42437217">[-]</label><label class="expand" for="c-42437217">[1 more]</label></div><br/><div class="children"><div class="content">TFS: <a href="https:&#x2F;&#x2F;github.com&#x2F;SakanaAI&#x2F;evo-memory">https:&#x2F;&#x2F;github.com&#x2F;SakanaAI&#x2F;evo-memory</a></div><br/></div></div></div></div><div id="42438187" class="c"><input type="checkbox" id="c-42438187" checked=""/><div class="controls bullet"><span class="by">gcanyon</span><span>|</span><a href="#42437202">prev</a><span>|</span><a href="#42438227">next</a><span>|</span><label class="collapse" for="c-42438187">[-]</label><label class="expand" for="c-42438187">[2 more]</label></div><br/><div class="children"><div class="content">Given that the algorithms powering present LLM models hadn&#x27;t been invented ten years ago, I have to think that they are (potentially) <i>far</i> from optimal.<p>Brains have gone through millions of iterations where being efficient was a huge driver of success. We should not be surprised if someone finds a new ML method that is both wildly more efficient and wildly more effective.</div><br/><div id="42438271" class="c"><input type="checkbox" id="c-42438271" checked=""/><div class="controls bullet"><span class="by">mycall</span><span>|</span><a href="#42438187">parent</a><span>|</span><a href="#42438227">next</a><span>|</span><label class="collapse" for="c-42438271">[-]</label><label class="expand" for="c-42438271">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps LLM++ will start iterating the algorithms via synthetic data until they are far more optimal</div><br/></div></div></div></div><div id="42438227" class="c"><input type="checkbox" id="c-42438227" checked=""/><div class="controls bullet"><span class="by">solarkraft</span><span>|</span><a href="#42438187">prev</a><span>|</span><a href="#42438061">next</a><span>|</span><label class="collapse" for="c-42438227">[-]</label><label class="expand" for="c-42438227">[6 more]</label></div><br/><div class="children"><div class="content">It’s mind bogglingly crazy that language models rivaling ones that used to require huge GPUs with a ton of VRAM to run now run on my upper-mid-range laptop from 4 years ago. At usable speed. Crazy.<p>I didn’t expect capable language models to be practical&#x2F;possible to run loyally, much less on hardware I already have.</div><br/><div id="42439524" class="c"><input type="checkbox" id="c-42439524" checked=""/><div class="controls bullet"><span class="by">prox</span><span>|</span><a href="#42438227">parent</a><span>|</span><a href="#42439196">next</a><span>|</span><label class="collapse" for="c-42439524">[-]</label><label class="expand" for="c-42439524">[3 more]</label></div><br/><div class="children"><div class="content">I might have a go at installing one, what is a good source or install at the moment?</div><br/><div id="42439576" class="c"><input type="checkbox" id="c-42439576" checked=""/><div class="controls bullet"><span class="by">wint3rmute</span><span>|</span><a href="#42438227">root</a><span>|</span><a href="#42439524">parent</a><span>|</span><a href="#42439599">next</a><span>|</span><label class="collapse" for="c-42439576">[-]</label><label class="expand" for="c-42439576">[1 more]</label></div><br/><div class="children"><div class="content">Ollama was the easiest way to set up local LLMs for me.<p><a href="https:&#x2F;&#x2F;ollama.com&#x2F;">https:&#x2F;&#x2F;ollama.com&#x2F;</a></div><br/></div></div><div id="42439599" class="c"><input type="checkbox" id="c-42439599" checked=""/><div class="controls bullet"><span class="by">spacemanspiff01</span><span>|</span><a href="#42438227">root</a><span>|</span><a href="#42439524">parent</a><span>|</span><a href="#42439576">prev</a><span>|</span><a href="#42439196">next</a><span>|</span><label class="collapse" for="c-42439599">[-]</label><label class="expand" for="c-42439599">[1 more]</label></div><br/><div class="children"><div class="content">lmstudio is very easy if you are running on local desktop.</div><br/></div></div></div></div><div id="42439196" class="c"><input type="checkbox" id="c-42439196" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#42438227">parent</a><span>|</span><a href="#42439524">prev</a><span>|</span><a href="#42438061">next</a><span>|</span><label class="collapse" for="c-42439196">[-]</label><label class="expand" for="c-42439196">[2 more]</label></div><br/><div class="children"><div class="content">You have a sota multi-modal LLM running in your head at 20W, shared with best in class sensor package and top performing robotics control unit.<p>There’s soooo much more to optimize.</div><br/><div id="42439515" class="c"><input type="checkbox" id="c-42439515" checked=""/><div class="controls bullet"><span class="by">fecal_henge</span><span>|</span><a href="#42438227">root</a><span>|</span><a href="#42439196">parent</a><span>|</span><a href="#42438061">next</a><span>|</span><label class="collapse" for="c-42439515">[-]</label><label class="expand" for="c-42439515">[1 more]</label></div><br/><div class="children"><div class="content">But can it know love?</div><br/></div></div></div></div></div></div><div id="42438061" class="c"><input type="checkbox" id="c-42438061" checked=""/><div class="controls bullet"><span class="by">iandanforth</span><span>|</span><a href="#42438227">prev</a><span>|</span><a href="#42439297">next</a><span>|</span><label class="collapse" for="c-42438061">[-]</label><label class="expand" for="c-42438061">[1 more]</label></div><br/><div class="children"><div class="content">Boringness classifier! Pretty cool because this implies the large models already know what is useless and what isn&#x27;t.</div><br/></div></div><div id="42439297" class="c"><input type="checkbox" id="c-42439297" checked=""/><div class="controls bullet"><span class="by">Euphorbium</span><span>|</span><a href="#42438061">prev</a><span>|</span><a href="#42437600">next</a><span>|</span><label class="collapse" for="c-42439297">[-]</label><label class="expand" for="c-42439297">[1 more]</label></div><br/><div class="children"><div class="content">Stop words in extra steps.</div><br/></div></div><div id="42437600" class="c"><input type="checkbox" id="c-42437600" checked=""/><div class="controls bullet"><span class="by">lawlessone</span><span>|</span><a href="#42439297">prev</a><span>|</span><a href="#42437230">next</a><span>|</span><label class="collapse" for="c-42437600">[-]</label><label class="expand" for="c-42437600">[4 more]</label></div><br/><div class="children"><div class="content">So it&#x27;s like a garbage collector for prompts?</div><br/><div id="42438003" class="c"><input type="checkbox" id="c-42438003" checked=""/><div class="controls bullet"><span class="by">cowsandmilk</span><span>|</span><a href="#42437600">parent</a><span>|</span><a href="#42437230">next</a><span>|</span><label class="collapse" for="c-42438003">[-]</label><label class="expand" for="c-42438003">[3 more]</label></div><br/><div class="children"><div class="content">More of lossy compression</div><br/><div id="42438026" class="c"><input type="checkbox" id="c-42438026" checked=""/><div class="controls bullet"><span class="by">aziaziazi</span><span>|</span><a href="#42437600">root</a><span>|</span><a href="#42438003">parent</a><span>|</span><a href="#42437230">next</a><span>|</span><label class="collapse" for="c-42438026">[-]</label><label class="expand" for="c-42438026">[2 more]</label></div><br/><div class="children"><div class="content">Does lossy means you may see previous inputs change ?!</div><br/><div id="42438123" class="c"><input type="checkbox" id="c-42438123" checked=""/><div class="controls bullet"><span class="by">TkTech</span><span>|</span><a href="#42437600">root</a><span>|</span><a href="#42438026">parent</a><span>|</span><a href="#42437230">next</a><span>|</span><label class="collapse" for="c-42438123">[-]</label><label class="expand" for="c-42438123">[1 more]</label></div><br/><div class="children"><div class="content">Lossy doesn&#x27;t necessarily imply that it is non-deterministic, just irreversible.</div><br/></div></div></div></div></div></div></div></div><div id="42437230" class="c"><input type="checkbox" id="c-42437230" checked=""/><div class="controls bullet"><span class="by">richwater</span><span>|</span><a href="#42437600">prev</a><span>|</span><a href="#42438474">next</a><span>|</span><label class="collapse" for="c-42437230">[-]</label><label class="expand" for="c-42437230">[6 more]</label></div><br/><div class="children"><div class="content">This is for inference right? Not training?</div><br/><div id="42439015" class="c"><input type="checkbox" id="c-42439015" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#42437230">parent</a><span>|</span><a href="#42437634">next</a><span>|</span><label class="collapse" for="c-42439015">[-]</label><label class="expand" for="c-42439015">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s for KV caching. In most conversations that will mean inference. But you <i>can</i> do reinforcement learning using sampled sequences, and you <i>could</i> use KV caching to speed that up too, so that would be an instance where training could get a slight boost.</div><br/></div></div><div id="42437634" class="c"><input type="checkbox" id="c-42437634" checked=""/><div class="controls bullet"><span class="by">lawlessone</span><span>|</span><a href="#42437230">parent</a><span>|</span><a href="#42439015">prev</a><span>|</span><a href="#42438474">next</a><span>|</span><label class="collapse" for="c-42437634">[-]</label><label class="expand" for="c-42437634">[4 more]</label></div><br/><div class="children"><div class="content">doesn&#x27;t training require inference? so i guess it would help there too?</div><br/><div id="42438248" class="c"><input type="checkbox" id="c-42438248" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#42437230">root</a><span>|</span><a href="#42437634">parent</a><span>|</span><a href="#42437801">next</a><span>|</span><label class="collapse" for="c-42438248">[-]</label><label class="expand" for="c-42438248">[1 more]</label></div><br/><div class="children"><div class="content">Yeah but training requires the larger memory deployment data center infra</div><br/></div></div><div id="42437801" class="c"><input type="checkbox" id="c-42437801" checked=""/><div class="controls bullet"><span class="by">fzzzy</span><span>|</span><a href="#42437230">root</a><span>|</span><a href="#42437634">parent</a><span>|</span><a href="#42438248">prev</a><span>|</span><a href="#42438474">next</a><span>|</span><label class="collapse" for="c-42437801">[-]</label><label class="expand" for="c-42437801">[2 more]</label></div><br/><div class="children"><div class="content">Training doesn&#x27;t require inference. It uses back-propagation, a different algorithm.</div><br/><div id="42437887" class="c"><input type="checkbox" id="c-42437887" checked=""/><div class="controls bullet"><span class="by">bitvoid</span><span>|</span><a href="#42437230">root</a><span>|</span><a href="#42437801">parent</a><span>|</span><a href="#42438474">next</a><span>|</span><label class="collapse" for="c-42437887">[-]</label><label class="expand" for="c-42437887">[1 more]</label></div><br/><div class="children"><div class="content">Backpropagation happens after some number of inferences. You need to infer to calculate a loss function to then backprop from.</div><br/></div></div></div></div></div></div></div></div><div id="42438474" class="c"><input type="checkbox" id="c-42438474" checked=""/><div class="controls bullet"><span class="by">bamboozled</span><span>|</span><a href="#42437230">prev</a><span>|</span><a href="#42438073">next</a><span>|</span><label class="collapse" for="c-42438474">[-]</label><label class="expand" for="c-42438474">[1 more]</label></div><br/><div class="children"><div class="content">Really exciting news.</div><br/></div></div><div id="42438073" class="c"><input type="checkbox" id="c-42438073" checked=""/><div class="controls bullet"><span class="by">ironfootnz</span><span>|</span><a href="#42438474">prev</a><span>|</span><a href="#42411743">next</a><span>|</span><label class="collapse" for="c-42438073">[-]</label><label class="expand" for="c-42438073">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a big fan of their papers, this one didn&#x27;t disappoint</div><br/></div></div><div id="42437729" class="c"><input type="checkbox" id="c-42437729" checked=""/><div class="controls bullet"><span class="by">tharmas</span><span>|</span><a href="#42411743">prev</a><span>|</span><a href="#42437442">next</a><span>|</span><label class="collapse" for="c-42437729">[-]</label><label class="expand" for="c-42437729">[2 more]</label></div><br/><div class="children"><div class="content">Does this mean us plebs can run LLMs on gimped VRAM Nvidia lower end cards?</div><br/><div id="42437825" class="c"><input type="checkbox" id="c-42437825" checked=""/><div class="controls bullet"><span class="by">swifthesitation</span><span>|</span><a href="#42437729">parent</a><span>|</span><a href="#42437442">next</a><span>|</span><label class="collapse" for="c-42437825">[-]</label><label class="expand" for="c-42437825">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think so. It seems to just lower the ram needed for the context window. Not for loading the model on the vram.</div><br/></div></div></div></div><div id="42437442" class="c"><input type="checkbox" id="c-42437442" checked=""/><div class="controls bullet"><span class="by">yishanchuan</span><span>|</span><a href="#42437729">prev</a><span>|</span><a href="#42437939">next</a><span>|</span><label class="collapse" for="c-42437442">[-]</label><label class="expand" for="c-42437442">[1 more]</label></div><br/><div class="children"><div class="content">interesting</div><br/></div></div><div id="42437939" class="c"><input type="checkbox" id="c-42437939" checked=""/><div class="controls bullet"><span class="by">voltagex_</span><span>|</span><a href="#42437442">prev</a><span>|</span><a href="#42437335">next</a><span>|</span><label class="collapse" for="c-42437939">[-]</label><label class="expand" for="c-42437939">[9 more]</label></div><br/><div class="children"><div class="content">Imagine if we put this kind of optimisation effort into something worthwhile.</div><br/><div id="42438072" class="c"><input type="checkbox" id="c-42438072" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#42437939">parent</a><span>|</span><a href="#42438050">next</a><span>|</span><label class="collapse" for="c-42438072">[-]</label><label class="expand" for="c-42438072">[3 more]</label></div><br/><div class="children"><div class="content">We are putting lots of optimisation efforts into lots of worthwhile endeavours.</div><br/><div id="42438168" class="c"><input type="checkbox" id="c-42438168" checked=""/><div class="controls bullet"><span class="by">voltagex_</span><span>|</span><a href="#42437939">root</a><span>|</span><a href="#42438072">parent</a><span>|</span><a href="#42438050">next</a><span>|</span><label class="collapse" for="c-42438168">[-]</label><label class="expand" for="c-42438168">[2 more]</label></div><br/><div class="children"><div class="content">I dunno, software seems to be getting worse, hardware is getting more expensive and both Microsoft and Apple are distracted by AI, not to mention NVIDIA who seem to have bet the farm on Deus Ex Shovel</div><br/><div id="42438480" class="c"><input type="checkbox" id="c-42438480" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#42437939">root</a><span>|</span><a href="#42438168">parent</a><span>|</span><a href="#42438050">next</a><span>|</span><label class="collapse" for="c-42438480">[-]</label><label class="expand" for="c-42438480">[1 more]</label></div><br/><div class="children"><div class="content">Hardware is still getting cheaper all the time as far as I can tell.<p>Though I had thought you were talking about stuff like eg producing more corn on a given piece of land, or making more furniture from less wood or so.  Or even just making better batteries and solar cells.</div><br/></div></div></div></div></div></div><div id="42438050" class="c"><input type="checkbox" id="c-42438050" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#42437939">parent</a><span>|</span><a href="#42438072">prev</a><span>|</span><a href="#42437335">next</a><span>|</span><label class="collapse" for="c-42438050">[-]</label><label class="expand" for="c-42438050">[5 more]</label></div><br/><div class="children"><div class="content">Like what?</div><br/><div id="42438085" class="c"><input type="checkbox" id="c-42438085" checked=""/><div class="controls bullet"><span class="by">h0l0cube</span><span>|</span><a href="#42437939">root</a><span>|</span><a href="#42438050">parent</a><span>|</span><a href="#42437335">next</a><span>|</span><label class="collapse" for="c-42438085">[-]</label><label class="expand" for="c-42438085">[4 more]</label></div><br/><div class="children"><div class="content">Oh, I don’t know, how about reducing the search space&#x2F;accelerating the search speed for potential room temperature superconductors? Or how about the same for viable battery chemistries?</div><br/><div id="42438193" class="c"><input type="checkbox" id="c-42438193" checked=""/><div class="controls bullet"><span class="by">AuryGlenz</span><span>|</span><a href="#42437939">root</a><span>|</span><a href="#42438085">parent</a><span>|</span><a href="#42439024">next</a><span>|</span><label class="collapse" for="c-42438193">[-]</label><label class="expand" for="c-42438193">[1 more]</label></div><br/><div class="children"><div class="content">It’s a good thing humanity can multitask.</div><br/></div></div><div id="42439024" class="c"><input type="checkbox" id="c-42439024" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#42437939">root</a><span>|</span><a href="#42438085">parent</a><span>|</span><a href="#42438193">prev</a><span>|</span><a href="#42438665">next</a><span>|</span><label class="collapse" for="c-42439024">[-]</label><label class="expand" for="c-42439024">[1 more]</label></div><br/><div class="children"><div class="content">Would you like that with or without tokens?</div><br/></div></div><div id="42438665" class="c"><input type="checkbox" id="c-42438665" checked=""/><div class="controls bullet"><span class="by">bubaumba</span><span>|</span><a href="#42437939">root</a><span>|</span><a href="#42438085">parent</a><span>|</span><a href="#42439024">prev</a><span>|</span><a href="#42437335">next</a><span>|</span><label class="collapse" for="c-42438665">[-]</label><label class="expand" for="c-42438665">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  search speed for potential room temperature superconductors?<p>and what if it&#x27;s a dead end?</div><br/></div></div></div></div></div></div></div></div><div id="42437335" class="c"><input type="checkbox" id="c-42437335" checked=""/><div class="controls bullet"><span class="by">asdev</span><span>|</span><a href="#42437939">prev</a><span>|</span><label class="collapse" for="c-42437335">[-]</label><label class="expand" for="c-42437335">[18 more]</label></div><br/><div class="children"><div class="content">LLM hype is fizzling</div><br/><div id="42437475" class="c"><input type="checkbox" id="c-42437475" checked=""/><div class="controls bullet"><span class="by">popinman322</span><span>|</span><a href="#42437335">parent</a><span>|</span><a href="#42437675">next</a><span>|</span><label class="collapse" for="c-42437475">[-]</label><label class="expand" for="c-42437475">[4 more]</label></div><br/><div class="children"><div class="content">Google Trends make it seem like we&#x27;re out of the exponential growth phase for LLMs-- search interest is possibly plateauing.<p>A decline in search interest outside of academia makes sense. The groups who can get by on APIs don&#x27;t care so much how the sausage is made and just want to see prices come down. Interested parties have likely already found tools that work for them.<p>There&#x27;s definitely some academic interest outside of CS in producing tools using LLMs. I know plenty of astro folks working to build domain specific tools with open models as their backbone. They&#x27;re typically not interested in more operational work, I guess because they operate under the assumption that relevant optimizations will eventually make their way into public inference engines.<p>And CS interest in these models will probably sustain for at least 5-10 more years, even if performance plateaus, as work continues into how LLMs function.<p>All that to say, maybe we&#x27;re just seeing the trend die for laypeople?</div><br/><div id="42437924" class="c"><input type="checkbox" id="c-42437924" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437475">parent</a><span>|</span><a href="#42437615">next</a><span>|</span><label class="collapse" for="c-42437924">[-]</label><label class="expand" for="c-42437924">[2 more]</label></div><br/><div class="children"><div class="content">Or maybe it’s Google Search usage that’s plateauing, as LLM interest is answered elsewhere?<p>I am only half kidding.</div><br/><div id="42438079" class="c"><input type="checkbox" id="c-42438079" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437924">parent</a><span>|</span><a href="#42437615">next</a><span>|</span><label class="collapse" for="c-42438079">[-]</label><label class="expand" for="c-42438079">[1 more]</label></div><br/><div class="children"><div class="content">Well, Google Search trends are also only an imperfect proxy for what we are actually interested in.<p>Eg tap water is really, really useful and widely deployed.  Approximately every household is a user, and that&#x27;s unlikely to change.  But I doubt you&#x27;ll find much evidence of that in Google Search trends.</div><br/></div></div></div></div><div id="42437615" class="c"><input type="checkbox" id="c-42437615" checked=""/><div class="controls bullet"><span class="by">Agentus</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437475">parent</a><span>|</span><a href="#42437924">prev</a><span>|</span><a href="#42437675">next</a><span>|</span><label class="collapse" for="c-42437615">[-]</label><label class="expand" for="c-42437615">[1 more]</label></div><br/><div class="children"><div class="content">well gary marcus a non lay person is helping spread word that ai winter is again upon us.<p>but maybe statistical learning from pretraining is near its limit.  not enough data or not enough juice to squeeze more performance out of averages.<p>though with all the narrow ais it does seem plausible you might be able to cram all what these narrow ais can do in on big goliath model.  wonder if reinforcement learning and reasoning can manage to keep the exponential curve of ai going if there are still hiccups in the short term.<p>the difficulty in just shoehorning llms as they are in any and every day task without a hitch might be behind the temporary hype-dying down trend.</div><br/></div></div></div></div><div id="42437675" class="c"><input type="checkbox" id="c-42437675" checked=""/><div class="controls bullet"><span class="by">elorant</span><span>|</span><a href="#42437335">parent</a><span>|</span><a href="#42437475">prev</a><span>|</span><a href="#42437482">next</a><span>|</span><label class="collapse" for="c-42437675">[-]</label><label class="expand" for="c-42437675">[1 more]</label></div><br/><div class="children"><div class="content">For the general public, not the HN audience.</div><br/></div></div><div id="42437482" class="c"><input type="checkbox" id="c-42437482" checked=""/><div class="controls bullet"><span class="by">mouse_</span><span>|</span><a href="#42437335">parent</a><span>|</span><a href="#42437675">prev</a><span>|</span><a href="#42437898">next</a><span>|</span><label class="collapse" for="c-42437482">[-]</label><label class="expand" for="c-42437482">[11 more]</label></div><br/><div class="children"><div class="content">True. Microsoft&#x27;s all in, Apple&#x27;s all in, Nvidia is selling shovels, insurance companies are all in, police &amp; military are all in, education is all in, office management is all in. Who is left to pump line up?</div><br/><div id="42437909" class="c"><input type="checkbox" id="c-42437909" checked=""/><div class="controls bullet"><span class="by">asdev</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437482">parent</a><span>|</span><a href="#42437552">next</a><span>|</span><label class="collapse" for="c-42437909">[-]</label><label class="expand" for="c-42437909">[6 more]</label></div><br/><div class="children"><div class="content">no one is successfully using LLMs for anything other than customer service related things and text generation(coding, writing)</div><br/><div id="42437994" class="c"><input type="checkbox" id="c-42437994" checked=""/><div class="controls bullet"><span class="by">mode80</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437909">parent</a><span>|</span><a href="#42438446">next</a><span>|</span><label class="collapse" for="c-42437994">[-]</label><label class="expand" for="c-42437994">[1 more]</label></div><br/><div class="children"><div class="content">mere trillian dollar industries. so far.</div><br/></div></div><div id="42438446" class="c"><input type="checkbox" id="c-42438446" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437909">parent</a><span>|</span><a href="#42437994">prev</a><span>|</span><a href="#42437552">next</a><span>|</span><label class="collapse" for="c-42438446">[-]</label><label class="expand" for="c-42438446">[4 more]</label></div><br/><div class="children"><div class="content">Rubbish. I built a pipeline to handle document classification that successfully took care of ~70TB of mostly unstructured and unorganized  data, by myself, in a couple weeks, with no data engineering background whatsoever. This was quite literally impossible a couple years ago. The amount of work that saved was massive and is going to save us a shit ton of money on storage costs. Decades worth of invoices and random PDFs are now siloed properly so we can organize and sort them. This was almost intractable a few years ago.</div><br/><div id="42439649" class="c"><input type="checkbox" id="c-42439649" checked=""/><div class="controls bullet"><span class="by">nwmcsween</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42438446">parent</a><span>|</span><a href="#42438825">next</a><span>|</span><label class="collapse" for="c-42439649">[-]</label><label class="expand" for="c-42439649">[1 more]</label></div><br/><div class="children"><div class="content">I mean considering I did document classification back in 2010 using tesseract, I wouldn&#x27;t say it was impossible.</div><br/></div></div><div id="42438825" class="c"><input type="checkbox" id="c-42438825" checked=""/><div class="controls bullet"><span class="by">musha68k</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42438446">parent</a><span>|</span><a href="#42439649">prev</a><span>|</span><a href="#42438769">next</a><span>|</span><label class="collapse" for="c-42438825">[-]</label><label class="expand" for="c-42438825">[1 more]</label></div><br/><div class="children"><div class="content">Very interesting. If I may ask: how are you handling the correctness issue? What&#x27;s the workflow there if even able to spot a mishap?</div><br/></div></div><div id="42438769" class="c"><input type="checkbox" id="c-42438769" checked=""/><div class="controls bullet"><span class="by">aitchnyu</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42438446">parent</a><span>|</span><a href="#42438825">prev</a><span>|</span><a href="#42437552">next</a><span>|</span><label class="collapse" for="c-42438769">[-]</label><label class="expand" for="c-42438769">[1 more]</label></div><br/><div class="children"><div class="content">Could you describe your stack and how its much more effective than two years ago? I heard of printed-table OCR and doc classification years back.</div><br/></div></div></div></div></div></div><div id="42437552" class="c"><input type="checkbox" id="c-42437552" checked=""/><div class="controls bullet"><span class="by">guerrilla</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437482">parent</a><span>|</span><a href="#42437909">prev</a><span>|</span><a href="#42437898">next</a><span>|</span><label class="collapse" for="c-42437552">[-]</label><label class="expand" for="c-42437552">[4 more]</label></div><br/><div class="children"><div class="content">As far as I know, finance is not all in. I see Goldman Sachs doing experiments, for example, but it doesn&#x27;t feel like they&#x27;re convinced yet.</div><br/><div id="42437869" class="c"><input type="checkbox" id="c-42437869" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437552">parent</a><span>|</span><a href="#42437898">next</a><span>|</span><label class="collapse" for="c-42437869">[-]</label><label class="expand" for="c-42437869">[3 more]</label></div><br/><div class="children"><div class="content">Finance is basically all of the reasons not to use (generative, LLM based) AI , all in one vertical. The poster child of determinism.</div><br/><div id="42439212" class="c"><input type="checkbox" id="c-42439212" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437869">parent</a><span>|</span><a href="#42438167">next</a><span>|</span><label class="collapse" for="c-42439212">[-]</label><label class="expand" for="c-42439212">[1 more]</label></div><br/><div class="children"><div class="content">Finance is all in on reading 10-Ks and generating summaries. If you have decisions in mind, I’ll be referring to IBM 1979 slide until an HR LLM fires me.</div><br/></div></div><div id="42438167" class="c"><input type="checkbox" id="c-42438167" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#42437335">root</a><span>|</span><a href="#42437869">parent</a><span>|</span><a href="#42439212">prev</a><span>|</span><a href="#42437898">next</a><span>|</span><label class="collapse" for="c-42438167">[-]</label><label class="expand" for="c-42438167">[1 more]</label></div><br/><div class="children"><div class="content">Could you please explain?<p>Finance is a big industry, and they are doing lots of different things.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>