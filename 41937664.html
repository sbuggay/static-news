<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1729846877298" as="style"/><link rel="stylesheet" href="styles.css?v=1729846877298"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://security.apple.com/blog/pcc-security-research/">Security research on Private Cloud Compute</a> <span class="domain">(<a href="https://security.apple.com">security.apple.com</a>)</span></div><div class="subtext"><span>todsacerdoti</span> | <span>86 comments</span></div><br/><div><div id="41943472" class="c"><input type="checkbox" id="c-41943472" checked=""/><div class="controls bullet"><span class="by">doulouUS</span><span>|</span><a href="#41939524">next</a><span>|</span><label class="collapse" for="c-41943472">[-]</label><label class="expand" for="c-41943472">[1 more]</label></div><br/><div class="children"><div class="content">Will there be SDKs to enable any developer to build things leveraging PCC? Like building a performant RAG system on personal&#x2F;sensitive data.</div><br/></div></div><div id="41939524" class="c"><input type="checkbox" id="c-41939524" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41943472">prev</a><span>|</span><a href="#41938088">next</a><span>|</span><label class="collapse" for="c-41939524">[-]</label><label class="expand" for="c-41939524">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been working on technology like this for the past six years.<p>The benefits of transparent systems are likely considerable. The combination of reproducible builds, remote attestation and transparency logging allows trivial detection of a range of supply chain attacks. It can allow users to retroactively audit the source code of remote running systems. Yes, there are attacks that the threat model doesn&#x27;t protect against. That doesn&#x27;t mean it isn&#x27;t immensely useful.</div><br/><div id="41941739" class="c"><input type="checkbox" id="c-41941739" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#41939524">parent</a><span>|</span><a href="#41941954">next</a><span>|</span><label class="collapse" for="c-41941739">[-]</label><label class="expand" for="c-41941739">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve also worked in this field but it feels like a foundation built on quicksand. You depend on so many turtle layers and only one of them has to be adversarial and game over.</div><br/><div id="41943476" class="c"><input type="checkbox" id="c-41943476" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41939524">root</a><span>|</span><a href="#41941739">parent</a><span>|</span><a href="#41941959">next</a><span>|</span><label class="collapse" for="c-41943476">[-]</label><label class="expand" for="c-41943476">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it feels like a foundation built on quicksand. You depend on so many turtle layers and only one of them has to be adversarial and game over<p>Interesting. Please elaborate.<p>Here&#x27;s how I see it.<p>Reproducible builds: I think we&#x27;ll eventually see Linux distributions like Debian make reproducible builds mandatory by enforcing it in apt-get&#x27;s trust policy. The trust policy could be expressed as &quot;I will only trust .deb packages where their build hash and source hash are signed by three different build pipelines I trust&quot;.<p>Remote attestation: If you ensure that the server&#x27;s CPU SoC and the TPM have different supply chains, you could construct a protocol where the supply chain attacker would have to own both supply chains in order to impersonate the server.<p>Transparency logging: One of the projects I&#x27;ve been working on for the past four years is Sigsum (sigsum.org). It is a transparency log with distributed trust assumptions. Our goal was to figure out the essence of transparency logging technology, identify the most significant design parameters, and for each parameter minimise the attack surface. You&#x27;ll find the threat model on our website.<p>Here&#x27;s a recent presentation by my colleague Rasmus on the subject: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Mp23yQxYm2c" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Mp23yQxYm2c</a><p>Here&#x27;s a recent presentation by me on the subject of system transparency &#x2F; runtime transparency &#x2F; the technology underlying Apple PCC: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Lo0gxBWwwQE" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Lo0gxBWwwQE</a></div><br/></div></div><div id="41941959" class="c"><input type="checkbox" id="c-41941959" checked=""/><div class="controls bullet"><span class="by">bitexploder</span><span>|</span><a href="#41939524">root</a><span>|</span><a href="#41941739">parent</a><span>|</span><a href="#41943476">prev</a><span>|</span><a href="#41941954">next</a><span>|</span><label class="collapse" for="c-41941959">[-]</label><label class="expand" for="c-41941959">[1 more]</label></div><br/><div class="children"><div class="content">Each layer needs more than one safeguard then. If breaking the layer breaks the system then the layer needs better safe guards.</div><br/></div></div></div></div><div id="41941954" class="c"><input type="checkbox" id="c-41941954" checked=""/><div class="controls bullet"><span class="by">bitexploder</span><span>|</span><a href="#41939524">parent</a><span>|</span><a href="#41941739">prev</a><span>|</span><a href="#41941506">next</a><span>|</span><label class="collapse" for="c-41941954">[-]</label><label class="expand" for="c-41941954">[1 more]</label></div><br/><div class="children"><div class="content">The xz backdoor would have been a yawn instead the many hands fire drill it was at most big orgs. It was scary.</div><br/></div></div></div></div><div id="41938088" class="c"><input type="checkbox" id="c-41938088" checked=""/><div class="controls bullet"><span class="by">dewey</span><span>|</span><a href="#41939524">prev</a><span>|</span><a href="#41938972">next</a><span>|</span><label class="collapse" for="c-41938088">[-]</label><label class="expand" for="c-41938088">[11 more]</label></div><br/><div class="children"><div class="content">Looks like they are really writing everything in Swift on the server side.<p>Repo: <a href="https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;security-pcc">https:&#x2F;&#x2F;github.com&#x2F;apple&#x2F;security-pcc</a></div><br/><div id="41938940" class="c"><input type="checkbox" id="c-41938940" checked=""/><div class="controls bullet"><span class="by">tessela</span><span>|</span><a href="#41938088">parent</a><span>|</span><a href="#41942787">next</a><span>|</span><label class="collapse" for="c-41938940">[-]</label><label class="expand" for="c-41938940">[2 more]</label></div><br/><div class="children"><div class="content">I hope this helps people to consider Swift 6 as a viable option for server-side development, since it offers many of the modern safety features of Rust, including simpler memory management through ARC, compared to Rust’s more complex ownership system and more predictable than Go&#x27;s garbage collector.</div><br/><div id="41943180" class="c"><input type="checkbox" id="c-41943180" checked=""/><div class="controls bullet"><span class="by">willtemperley</span><span>|</span><a href="#41938088">root</a><span>|</span><a href="#41938940">parent</a><span>|</span><a href="#41942787">next</a><span>|</span><label class="collapse" for="c-41943180">[-]</label><label class="expand" for="c-41943180">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to use Swift on Cloudflare Workers, but SwiftWASM doesn&#x27;t seem production ready whereas Rust just works (mostly) on workers. Swift on AWS Lambda looks promising though.</div><br/></div></div></div></div><div id="41942787" class="c"><input type="checkbox" id="c-41942787" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#41938088">parent</a><span>|</span><a href="#41938940">prev</a><span>|</span><a href="#41939749">next</a><span>|</span><label class="collapse" for="c-41942787">[-]</label><label class="expand" for="c-41942787">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s worth keeping in mind that these AI machines run an environment very similar to Mac OS, XNU kernel and all, and are powered by Apple Silicon. Using Swift in that context makes sense.<p>At least according to what we publicly know, no other backend Apple services follow this model.</div><br/></div></div><div id="41939749" class="c"><input type="checkbox" id="c-41939749" checked=""/><div class="controls bullet"><span class="by">danielhep</span><span>|</span><a href="#41938088">parent</a><span>|</span><a href="#41942787">prev</a><span>|</span><a href="#41938972">next</a><span>|</span><label class="collapse" for="c-41939749">[-]</label><label class="expand" for="c-41939749">[7 more]</label></div><br/><div class="children"><div class="content">Is using something other than XCode viable? I&#x27;d love to do more with swift but I hate that IDE.</div><br/><div id="41940119" class="c"><input type="checkbox" id="c-41940119" checked=""/><div class="controls bullet"><span class="by">dewey</span><span>|</span><a href="#41938088">root</a><span>|</span><a href="#41939749">parent</a><span>|</span><a href="#41942967">next</a><span>|</span><label class="collapse" for="c-41940119">[-]</label><label class="expand" for="c-41940119">[1 more]</label></div><br/><div class="children"><div class="content">Most editors will do, Xcode is mostly needed for iOS &#x2F; macOS development if you want to submit to the App Store or work with a lot of Apple frameworks.</div><br/></div></div><div id="41942967" class="c"><input type="checkbox" id="c-41942967" checked=""/><div class="controls bullet"><span class="by">willtemperley</span><span>|</span><a href="#41938088">root</a><span>|</span><a href="#41939749">parent</a><span>|</span><a href="#41940119">prev</a><span>|</span><a href="#41940256">next</a><span>|</span><label class="collapse" for="c-41942967">[-]</label><label class="expand" for="c-41942967">[1 more]</label></div><br/><div class="children"><div class="content">Have you used it recently, on an M series Mac? I used to feel the same, it was sluggish and crashed frequently. It&#x27;s become usable now, even pleasant to use. Also it&#x27;s great they support Vim keybindings now out-of-the-box.</div><br/></div></div><div id="41940256" class="c"><input type="checkbox" id="c-41940256" checked=""/><div class="controls bullet"><span class="by">iforgotmysocks</span><span>|</span><a href="#41938088">root</a><span>|</span><a href="#41939749">parent</a><span>|</span><a href="#41942967">prev</a><span>|</span><a href="#41940028">next</a><span>|</span><label class="collapse" for="c-41940256">[-]</label><label class="expand" for="c-41940256">[1 more]</label></div><br/><div class="children"><div class="content">There is a Swift LSP. See - <a href="https:&#x2F;&#x2F;github.com&#x2F;swiftlang&#x2F;sourcekit-lsp">https:&#x2F;&#x2F;github.com&#x2F;swiftlang&#x2F;sourcekit-lsp</a></div><br/></div></div><div id="41940028" class="c"><input type="checkbox" id="c-41940028" checked=""/><div class="controls bullet"><span class="by">selectodude</span><span>|</span><a href="#41938088">root</a><span>|</span><a href="#41939749">parent</a><span>|</span><a href="#41940256">prev</a><span>|</span><a href="#41941066">next</a><span>|</span><label class="collapse" for="c-41940028">[-]</label><label class="expand" for="c-41940028">[1 more]</label></div><br/><div class="children"><div class="content">VS Code?<p><a href="https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=sswg.swift-lang" rel="nofollow">https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=sswg.swi...</a></div><br/></div></div><div id="41941066" class="c"><input type="checkbox" id="c-41941066" checked=""/><div class="controls bullet"><span class="by">russelg</span><span>|</span><a href="#41938088">root</a><span>|</span><a href="#41939749">parent</a><span>|</span><a href="#41940028">prev</a><span>|</span><a href="#41938972">next</a><span>|</span><label class="collapse" for="c-41941066">[-]</label><label class="expand" for="c-41941066">[2 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re a Jetbrains user, they have their AppCode IDE.</div><br/><div id="41941253" class="c"><input type="checkbox" id="c-41941253" checked=""/><div class="controls bullet"><span class="by">ceejayoz</span><span>|</span><a href="#41938088">root</a><span>|</span><a href="#41941066">parent</a><span>|</span><a href="#41938972">next</a><span>|</span><label class="collapse" for="c-41941253">[-]</label><label class="expand" for="c-41941253">[1 more]</label></div><br/><div class="children"><div class="content">That was discontinued in 2022.</div><br/></div></div></div></div></div></div></div></div><div id="41938972" class="c"><input type="checkbox" id="c-41938972" checked=""/><div class="controls bullet"><span class="by">mmastrac</span><span>|</span><a href="#41938088">prev</a><span>|</span><a href="#41939941">next</a><span>|</span><label class="collapse" for="c-41938972">[-]</label><label class="expand" for="c-41938972">[41 more]</label></div><br/><div class="children"><div class="content">I feel like this is all smoke and mirrors to redirect from the likelihood intentional silicon backdoors that are effectively undetectable. Without open silicon, there&#x27;s no way to detect that -- say -- when registers r0-rN are set to values [A, ..., N] and a jump to address 0xCONSTANT occurs, additional access is granted to a monitor process.<p>Of course, this limits the potential attackers to 1) exactly one government (or N number of eyes) or 2) one company, but there&#x27;s really no way that you can trust remote hardware.<p>This _does_ increase the trust that the VMs are safe from other attackers, but I guess this depends on your threat model.</div><br/><div id="41939741" class="c"><input type="checkbox" id="c-41939741" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41940306">next</a><span>|</span><label class="collapse" for="c-41939741">[-]</label><label class="expand" for="c-41939741">[4 more]</label></div><br/><div class="children"><div class="content">&gt; I feel like this is all smoke and mirrors to redirect from the likelihood intentional silicon backdoors that are effectively undetectable.<p>The technologies Apple PCC is using has real benefits and is most certainly not &quot;all smoke and mirrors&quot;. Reproducible builds, remote attestation and transparency logging are individually useful, and the combination of them even more so.<p>As for the likelihood of Apple launching Apple PCC to redirect attention from backdoors in their silicon, that seems extremely unlikely. We can debate how unlikely, but there are many far more likely explanations. One is that Apple PCC is simply good business. It&#x27;ll likely reduce security costs for Apple, and strengthen the perception that Apple respects users&#x27; privacy.<p>&gt; when registers r0-rN are set to values [A, ..., N] and a jump to address 0xCONSTANT occurs<p>I would recommend something more deniable, or at the very least something that can&#x27;t easily be replayed. Put a challenge-response in there, or attack the TRNG. It is trivial to make a stream of bytes appear random while actually being deterministic. Such an attack would be more deniable, while also allowing a passive network attacker to read all user data. No need to get code execution on the machines.</div><br/><div id="41939900" class="c"><input type="checkbox" id="c-41939900" checked=""/><div class="controls bullet"><span class="by">formerly_proven</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939741">parent</a><span>|</span><a href="#41940306">next</a><span>|</span><label class="collapse" for="c-41939900">[-]</label><label class="expand" for="c-41939900">[3 more]</label></div><br/><div class="children"><div class="content">Apple forgot to disable some cache debugging registers a while back which in effect was similar to something GP described, although exploitation required root privileges and would allow circumventing their in-kernel protections; protections most other systems do not have. (And they still didn&#x27;t manage to achieve persistence, despite having beyond-root privileges).</div><br/><div id="41940112" class="c"><input type="checkbox" id="c-41940112" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939900">parent</a><span>|</span><a href="#41940643">next</a><span>|</span><label class="collapse" for="c-41940112">[-]</label><label class="expand" for="c-41940112">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Apple forgot to disable some cache debugging registers a while back which in effect was similar to something GP described<p>Thank you for bringing that up. Yes, it is an excellent example that proves the existence of silicon vulnerabilities that allow privilege escalation. Who knows whether it was left there intentionally or not, and if so by whom.<p>I was primarily arguing that (1) the technologies of Apple PCC are useful and (2) it is _very_ unlikely that Apple PCC is a ploy by Apple, to direct attention away from backdoors in the silicon.</div><br/></div></div><div id="41940643" class="c"><input type="checkbox" id="c-41940643" checked=""/><div class="controls bullet"><span class="by">password4321</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939900">parent</a><span>|</span><a href="#41940112">prev</a><span>|</span><a href="#41940306">next</a><span>|</span><label class="collapse" for="c-41940643">[-]</label><label class="expand" for="c-41940643">[1 more]</label></div><br/><div class="children"><div class="content">20231227 <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38783112">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38783112</a> Operation Triangulation: What you get when attack iPhones of researchers<p>20231229 <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38801275">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38801275</a> Kaspersky discloses iPhone hardware feature vital in Operation Triangulation</div><br/></div></div></div></div></div></div><div id="41940306" class="c"><input type="checkbox" id="c-41940306" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41939741">prev</a><span>|</span><a href="#41940917">next</a><span>|</span><label class="collapse" for="c-41940306">[-]</label><label class="expand" for="c-41940306">[3 more]</label></div><br/><div class="children"><div class="content">The economics of silicon manufacturing and Apple&#x27;s own security goals (including the security of their business model) restrict the kinds of backdoors you can embed in their servers at that level.<p>Let&#x27;s assume Apple has been compromised in some way and releases new chips with a backdoor. It&#x27;s expensive to insert extra logic into just one particular spin of a chip; that involves extra tooling cost that would be noticeable line-items and show up in discovery were Apple to be sued about their false claims. So it needs to be on all the chips, not just a specific &quot;defeat PCC&quot; spin of their silicon. So they&#x27;d be shipping iPads and iPhones with hardware backdoors.<p>What happens when those backdoors inevitably leak? Well, now you have a trivial jailbreak vector that Apple can&#x27;t patch. Apple&#x27;s security model could be roughly boiled down as &quot;our DRM is your security&quot;; while they also have lots of actual security, they pride themselves on the fact that they have an economic incentive to lock the system down to keep both bad actors and competing app stores out. So if this backdoor was inserted without the knowledge of Apple management, there are going to be heads rolling. And if it was, then they&#x27;re going to be sued up the ass once people realize the implications of such a thing, because Tim Cook went up on stage and promised everyone they were building servers that would refuse to let them read your Siri queries.</div><br/><div id="41943354" class="c"><input type="checkbox" id="c-41943354" checked=""/><div class="controls bullet"><span class="by">mike_hearn</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41940306">parent</a><span>|</span><a href="#41943158">next</a><span>|</span><label class="collapse" for="c-41943354">[-]</label><label class="expand" for="c-41943354">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately that&#x27;s not the case.<p>All remote attestation technology is rooted by a PKI (the DCA certificate authority in this case). There&#x27;s some data somewhere that simply asserts that a particular key was generated inside a CPU, and everything is chained off that. There&#x27;s currently no good way to prove this step so you just have to take it on faith. Forge such an assertion and you can sign statements that device X is actually a Y and it&#x27;s game over, it&#x27;s not detectable remotely.<p>Therefore, you must take on faith the <i>organization</i> providing the root of trust i.e. the CPU. No way around it. Apple does the best it can within this constraint by trying to have numerous employees be involved, and there&#x27;s this third party auditor they hired, but that auditor is ultimately engaging in a process controlled by Apple. It&#x27;s a good start but the whole thing assumes either that Apple employees will become whistleblowers if given a sufficiently powerful order, or that the third party auditor will be willing and able to shut down Apple Intelligence if they aren&#x27;t satisfied with the audit. Given Apple&#x27;s legal resources and famously leak-proof operation, is this a convincing proposition?<p>Conventional confidential computing conceptually works, because the people designing and selling the CPUs are different to the people deploying them to run confidential workloads. The deployers can&#x27;t forge an attestation (assuming absence of bugs) because they don&#x27;t have access to the root signing keys. The CPU makers could, theoretically, but they have no reason to because they aren&#x27;t running any confidential workloads so there&#x27;s no data to steal. And they are in practice constrained by basic problems like not knowing what CPU the deployers actually have, not being able to force changes to other people&#x27;s hardware, not being able to intercept the network connections and so on.<p>So you need a higher authority that can force them to conspire which in practice means only the US government.<p>In this case, Apple is doing everything right except that the root of trust for everything is Apple itself. They can publish in their log an entry that claims to be an Apple CPU but for which the key was generated outside of the manufacturing process, and that&#x27;s all it takes to dismantle the entire architecture. Apple know this and are doing the best they can within the &quot;don&#x27;t team up with competitors&quot; constraint they obviously are placed under. But trust is ultimately a human thing and the purpose of corporations is to let us abstract and to some extent anthropomorphize large groups. So I&#x27;m not totally sure this works, socially.</div><br/></div></div><div id="41943158" class="c"><input type="checkbox" id="c-41943158" checked=""/><div class="controls bullet"><span class="by">Jerrrrrrry</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41940306">parent</a><span>|</span><a href="#41943354">prev</a><span>|</span><a href="#41940917">next</a><span>|</span><label class="collapse" for="c-41943158">[-]</label><label class="expand" for="c-41943158">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  &gt;backdoors inevitably leak? Well, now you have a trivial jailbreak vector
</code></pre>
the discover-ability of an exploit vector relates little to its trivialness, definitely when considering the context (nation-state-APTs)<p>You can hold the enter key down for 40 seconds to login into any certain Linux Server distro, for years. No one knew, ez to do.<p>You can have a chip inside your chip that only accepts encrypted and signed microcode and has control over the superior chip. Everyone knows - nothing you can do.<p>Nation state actors however, can facilitate either; APT&#x27;s can forge fake digital forensics that imply another motive&#x2F;state&#x2F;false flag.</div><br/></div></div></div></div><div id="41940917" class="c"><input type="checkbox" id="c-41940917" checked=""/><div class="controls bullet"><span class="by">stouset</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41940306">prev</a><span>|</span><a href="#41939039">next</a><span>|</span><label class="collapse" for="c-41940917">[-]</label><label class="expand" for="c-41940917">[4 more]</label></div><br/><div class="children"><div class="content">If you take as a fundamental assumption that all your hardware is backdoored by Mossad who has unlimited resources and capacity to intercept and process all your traffic, the game is already lost and there’s no point in doing anything.<p>If instead you assume your attackers have limited resources, things like this increase the costs attackers have to spend to compromise targets, reducing the number of viable targets and&#x2F;or the depth to which they can penetrate them.<p>One of these threat models is actually useful.</div><br/><div id="41943118" class="c"><input type="checkbox" id="c-41943118" checked=""/><div class="controls bullet"><span class="by">Jerrrrrrry</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41940917">parent</a><span>|</span><a href="#41942841">next</a><span>|</span><label class="collapse" for="c-41943118">[-]</label><label class="expand" for="c-41943118">[1 more]</label></div><br/><div class="children"><div class="content">Soviets used typewriters.<p>American Lawyers of the highest pedigree (HNWI) don&#x27;t even use email.<p>Your hardware is back-doored, as Intel is named &quot;Intel&quot; for a (nearly too poignant) reason.</div><br/></div></div><div id="41942841" class="c"><input type="checkbox" id="c-41942841" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41940917">parent</a><span>|</span><a href="#41943118">prev</a><span>|</span><a href="#41939039">next</a><span>|</span><label class="collapse" for="c-41942841">[-]</label><label class="expand" for="c-41942841">[2 more]</label></div><br/><div class="children"><div class="content">Some of us just assume Apple itself is a bad actor planning to use and sell customer data for profit; makes all of this smoke and mirrors like GP said.<p>There is absolutely no technical solution where Apple can prove our data isn&#x27;t exfiltrated as long as this is their software that runs on their hardware.</div><br/><div id="41943189" class="c"><input type="checkbox" id="c-41943189" checked=""/><div class="controls bullet"><span class="by">rnts08</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41942841">parent</a><span>|</span><a href="#41939039">next</a><span>|</span><label class="collapse" for="c-41943189">[-]</label><label class="expand" for="c-41943189">[1 more]</label></div><br/><div class="children"><div class="content">Anyone assuming otherwise is just foolish. No mega-corp is protecting the individuals privacy when developing products.</div><br/></div></div></div></div></div></div><div id="41939039" class="c"><input type="checkbox" id="c-41939039" checked=""/><div class="controls bullet"><span class="by">yalogin</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41940917">prev</a><span>|</span><a href="#41941792">next</a><span>|</span><label class="collapse" for="c-41939039">[-]</label><label class="expand" for="c-41939039">[10 more]</label></div><br/><div class="children"><div class="content">This is an interesting idea. However what does open hardware mean? How can you prove that the design or architecture that was “opened” is actually what was built? What does the attestation even mean in this scenario?</div><br/><div id="41939907" class="c"><input type="checkbox" id="c-41939907" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939039">parent</a><span>|</span><a href="#41939278">next</a><span>|</span><label class="collapse" for="c-41939907">[-]</label><label class="expand" for="c-41939907">[4 more]</label></div><br/><div class="children"><div class="content">&gt; what does open hardware mean?<p>Great question. Most hardware projects I&#x27;ve seen that market themselves as open source hardware provide the schematic and PCB design, but still use ICs that are proprietary. One of my companies, Tillitis, uses an FPGA as the main IC, and we provide the hardware design configured on the FPGA. Still, the FPGA itself is proprietary.<p>Another aspect to consider is whether you can audit and modify the design artefacts with open source tooling. If the schematics and PCB design is stored in a proprietary format I&#x27;d say that&#x27;s slightly less open source hardware than if the format was KiCad EDA, which is open source. Similarly, in order to configure the HDL onto the FPGA, do you need to use 50 GB of proprietary Xilinx tooling, or can you use open tools for synthesis, place-and-route, and configuration? That also affects the level of openness in my opinion.<p>We can ask similar questions of open source software. People who run a Linux distribution typically don&#x27;t compile packages themselves. If those packages are not reproducible from source, in what sense is the binary open source? It seems we consider it to be open source software because someone we trust claimed it was built from open source code.</div><br/><div id="41940471" class="c"><input type="checkbox" id="c-41940471" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939907">parent</a><span>|</span><a href="#41942016">next</a><span>|</span><label class="collapse" for="c-41940471">[-]</label><label class="expand" for="c-41940471">[2 more]</label></div><br/><div class="children"><div class="content">And what attestation do you have that the FPGA isn&#x27;t compromised.<p>We can play this game all the way down.</div><br/><div id="41940565" class="c"><input type="checkbox" id="c-41940565" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41940471">parent</a><span>|</span><a href="#41942016">next</a><span>|</span><label class="collapse" for="c-41940565">[-]</label><label class="expand" for="c-41940565">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right. It is very hard, if not impossible, to get absolute guarantees. Having said that, FPGAs can make supply chain attacks harder. See my other comments in this thread.</div><br/></div></div></div></div><div id="41942016" class="c"><input type="checkbox" id="c-41942016" checked=""/><div class="controls bullet"><span class="by">yalogin</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939907">parent</a><span>|</span><a href="#41940471">prev</a><span>|</span><a href="#41939278">next</a><span>|</span><label class="collapse" for="c-41942016">[-]</label><label class="expand" for="c-41942016">[1 more]</label></div><br/><div class="children"><div class="content">No, you trust the HW and so starting with secure boot you can get measurements cryptographically vouched for. That you can prove and verify.<p>So at some point you have no option but to trust something&#x2F;someone</div><br/></div></div></div></div><div id="41939278" class="c"><input type="checkbox" id="c-41939278" checked=""/><div class="controls bullet"><span class="by">dented42</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939039">parent</a><span>|</span><a href="#41939907">prev</a><span>|</span><a href="#41941792">next</a><span>|</span><label class="collapse" for="c-41939278">[-]</label><label class="expand" for="c-41939278">[5 more]</label></div><br/><div class="children"><div class="content">This is my thought exactly. I really love the idea of open hardware, but I don’t see how it would protect against cover surveillance. What’s stopping a company&#x2F;government&#x2F;etc from adding surveillance to an open design? How would you determine that the hardware being used is identical to the open hardware design? You still ultimately have to trust that the organisations involved in manufacturing&#x2F;assembling&#x2F;installing&#x2F;operating the hardware in question hasn’t done something nefarious. And that brings us back to square one.</div><br/><div id="41939931" class="c"><input type="checkbox" id="c-41939931" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939278">parent</a><span>|</span><a href="#41939620">next</a><span>|</span><label class="collapse" for="c-41939931">[-]</label><label class="expand" for="c-41939931">[3 more]</label></div><br/><div class="children"><div class="content">&gt; How would you determine that the hardware being used is identical to the open hardware design?<p>FPGAs can help with this. They allow you to inspect the HDL, synthesize it and configure it onto the FPGA chip yourself. The FPGA chip is still proprietary, but by using an FPGA you are making certain supply chain attacks harder.</div><br/><div id="41940141" class="c"><input type="checkbox" id="c-41940141" checked=""/><div class="controls bullet"><span class="by">warkdarrior</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939931">parent</a><span>|</span><a href="#41939620">next</a><span>|</span><label class="collapse" for="c-41940141">[-]</label><label class="expand" for="c-41940141">[2 more]</label></div><br/><div class="children"><div class="content">How do you know the proprietary part of the FPGA chip performs as expected and does not covertly gather data from the configured gates?</div><br/><div id="41940400" class="c"><input type="checkbox" id="c-41940400" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41940141">parent</a><span>|</span><a href="#41939620">next</a><span>|</span><label class="collapse" for="c-41940400">[-]</label><label class="expand" for="c-41940400">[1 more]</label></div><br/><div class="children"><div class="content">&gt; How do you know the proprietary part of the FPGA chip performs as expected and does not covertly gather data from the configured gates?<p>We don&#x27;t, but using an FPGA can make supply chain attacks harder.<p>Let&#x27;s assume you have a chip design for a microcontroller and you do a tapeout, i.e. you have chips made. An attacker in your supply chain might attack your chip design before the design makes it to the fab, maybe the attacker is at the fab, or they change out the chips after you&#x27;ve placed them on your PCB.<p>If you use an FPGA, your customer could stress test the chip by configuring a variety of designs onto the FPGA. These designs should stress test timing, compute and memory at the very least. This requires the attacker&#x27;s chip to perform at least as well as the FPGA you&#x27;re using, while still having the same footprint. An attacker might stack the real FPGA die on top of the attacker&#x27;s die, but such an attack is much easier to detect than a few malicious gates on a die. As for covertly gathering or manipulating data, on an FPGA you can choose where to place your cores. That makes it harder for the attacker to predict where on the FPGA substrate they should place probes, or which gates to attack in order to attack your TRNG, or your master key memory. Those are just some examples.<p>If you&#x27;re curious about this type of technology or line of thinking you can check out the website of one of my companies: tillitis.se</div><br/></div></div></div></div></div></div><div id="41939620" class="c"><input type="checkbox" id="c-41939620" checked=""/><div class="controls bullet"><span class="by">mdhb</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939278">parent</a><span>|</span><a href="#41939931">prev</a><span>|</span><a href="#41941792">next</a><span>|</span><label class="collapse" for="c-41939620">[-]</label><label class="expand" for="c-41939620">[1 more]</label></div><br/><div class="children"><div class="content">This website in particular tends to get very upset and is all too happy to point out irrelevant counter examples every time I point this out but the actual ground truth of the matter here is that you aren’t going to find yourself on a US intel targeting list by accident and unless you are doing something incredibly stupid you can use Apple &#x2F; Google cloud services without a second thought.</div><br/></div></div></div></div></div></div><div id="41941792" class="c"><input type="checkbox" id="c-41941792" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41939039">prev</a><span>|</span><a href="#41939433">next</a><span>|</span><label class="collapse" for="c-41941792">[-]</label><label class="expand" for="c-41941792">[1 more]</label></div><br/><div class="children"><div class="content">Transparency through things like attestation is capable of proving nothing unexpected is running; for instance you can provide power&#x2F;CPU time numbers or hashes of arbitrary memory and this can make it arbitrarily hard to run extra code since it would take more time.<p>And the secure routing does make most of these attacks infeasible.</div><br/></div></div><div id="41940097" class="c"><input type="checkbox" id="c-41940097" checked=""/><div class="controls bullet"><span class="by">ryandv</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41939433">prev</a><span>|</span><a href="#41940200">next</a><span>|</span><label class="collapse" for="c-41940097">[-]</label><label class="expand" for="c-41940097">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s been some limited research in this space; see for instance xoreaxeaxeax&#x27;s sandsifter tool which has found millions of undocumented processor instructions [0].<p>[0] <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ajccZ7LdvoQ" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ajccZ7LdvoQ</a></div><br/></div></div><div id="41940200" class="c"><input type="checkbox" id="c-41940200" checked=""/><div class="controls bullet"><span class="by">brokenmachine</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41940097">prev</a><span>|</span><a href="#41939212">next</a><span>|</span><label class="collapse" for="c-41940200">[-]</label><label class="expand" for="c-41940200">[1 more]</label></div><br/><div class="children"><div class="content">Relevant:<p>37C3 - Operation Triangulation: What You Get When Attack iPhones of Researchers
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=1f6YyH62jFE" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=1f6YyH62jFE</a><p>Absolutely insane attack. Really opens your eyes on what nation-state attackers are capable of.</div><br/></div></div><div id="41939212" class="c"><input type="checkbox" id="c-41939212" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41940200">prev</a><span>|</span><a href="#41939868">next</a><span>|</span><label class="collapse" for="c-41939212">[-]</label><label class="expand" for="c-41939212">[7 more]</label></div><br/><div class="children"><div class="content">Concrete example of such backdoors: <a href="https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;features&#x2F;2018-10-04&#x2F;the-big-hack-how-china-used-a-tiny-chip-to-infiltrate-america-s-top-companies" rel="nofollow">https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;features&#x2F;2018-10-04&#x2F;the-big-h...</a><p>The system is protecting you against Apple employees, but not against law enforcement.<p>No matter how much layer of technology you put, at the end of the day, the US companies have to respect the law of the US.<p>The requests can be routed to specific investigation &#x2F; debugging &#x2F; beta nodes.<p>Just to turn-on a flag on specific users.<p>It&#x27;s not like ultimate privacy, but at least it will prevent Apple engineers from snooping into private chatlogs.<p>(like some pervert at Gmail was stalking a little girl <a href="https:&#x2F;&#x2F;www.gawkerarchives.com&#x2F;5637234&#x2F;gcreep-google-engineer-stalked-teens-spied-on-chats" rel="nofollow">https:&#x2F;&#x2F;www.gawkerarchives.com&#x2F;5637234&#x2F;gcreep-google-enginee...</a> , or Zuckerberg himself reading chatlogs <a href="https:&#x2F;&#x2F;www.vanityfair.com&#x2F;news&#x2F;2010&#x2F;03&#x2F;mark-zuckerberg-allegedly-used-the-powers-of-facebook-to-hack-reporters-emails" rel="nofollow">https:&#x2F;&#x2F;www.vanityfair.com&#x2F;news&#x2F;2010&#x2F;03&#x2F;mark-zuckerberg-alle...</a> )</div><br/><div id="41939586" class="c"><input type="checkbox" id="c-41939586" checked=""/><div class="controls bullet"><span class="by">bri3d</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939212">parent</a><span>|</span><a href="#41939715">next</a><span>|</span><label class="collapse" for="c-41939586">[-]</label><label class="expand" for="c-41939586">[1 more]</label></div><br/><div class="children"><div class="content">The Bloomberg SuperMicro implant in its various forms is an exceptionally poor example here: it&#x27;s been widely criticized, never corroborated, and, Apple&#x27;s Private Compute architecture has extensive mitigation against every type of purported attack in the various forms the SuperMicro story has taken. UEFI&#x2F;BIOS backdoors, implanted chips affecting the BMC firmware, and malicious&#x2F;tampered storage device firmware are all accounted for in the Private Compute trust model.</div><br/></div></div><div id="41939715" class="c"><input type="checkbox" id="c-41939715" checked=""/><div class="controls bullet"><span class="by">artimaeis</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939212">parent</a><span>|</span><a href="#41939586">prev</a><span>|</span><a href="#41941807">next</a><span>|</span><label class="collapse" for="c-41939715">[-]</label><label class="expand" for="c-41939715">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t believe Bloomberg still hasn&#x27;t retracted that article. As other commenters have indicated - it has never in any way been corroborated.<p><a href="https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;articles&#x2F;2018-10-04&#x2F;the-big-hack-amazon-apple-supermicro-and-beijing-respond" rel="nofollow">https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;articles&#x2F;2018-10-04&#x2F;the-big-h...</a></div><br/></div></div><div id="41941807" class="c"><input type="checkbox" id="c-41941807" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939212">parent</a><span>|</span><a href="#41939715">prev</a><span>|</span><a href="#41941742">next</a><span>|</span><label class="collapse" for="c-41941807">[-]</label><label class="expand" for="c-41941807">[1 more]</label></div><br/><div class="children"><div class="content">That article is literally completely made up and didn&#x27;t happen.<p>&gt; The requests can be routed to specific investigation &#x2F; debugging &#x2F; beta nodes.<p>No, this is not possible with the design of PCC; they can&#x27;t control how your requests are routed and there cannot be nodes with extra debugging.</div><br/></div></div><div id="41941742" class="c"><input type="checkbox" id="c-41941742" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939212">parent</a><span>|</span><a href="#41941807">prev</a><span>|</span><a href="#41939277">next</a><span>|</span><label class="collapse" for="c-41941742">[-]</label><label class="expand" for="c-41941742">[1 more]</label></div><br/><div class="children"><div class="content">The threat is real but that article is disinformation.</div><br/></div></div><div id="41939277" class="c"><input type="checkbox" id="c-41939277" checked=""/><div class="controls bullet"><span class="by">SheinhardtWigCo</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939212">parent</a><span>|</span><a href="#41941742">prev</a><span>|</span><a href="#41939257">next</a><span>|</span><label class="collapse" for="c-41939277">[-]</label><label class="expand" for="c-41939277">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Concrete example<p>This has not been corroborated and Bloomberg has not produced any supporting evidence.</div><br/></div></div><div id="41939257" class="c"><input type="checkbox" id="c-41939257" checked=""/><div class="controls bullet"><span class="by">0xCMP</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41939212">parent</a><span>|</span><a href="#41939277">prev</a><span>|</span><a href="#41939868">next</a><span>|</span><label class="collapse" for="c-41939257">[-]</label><label class="expand" for="c-41939257">[1 more]</label></div><br/><div class="children"><div class="content">iirc, no real proof was ever provided for that bloomberg article (despite it also never being retracted). many looked for the chips and from everything I heard there was never a concrete situation where this was discovered.<p>Doesn&#x27;t make the possible threat less real (see recent news in Lebanon), but that story in particular seems to have not stood up to closer inquiry.</div><br/></div></div></div></div><div id="41939868" class="c"><input type="checkbox" id="c-41939868" checked=""/><div class="controls bullet"><span class="by">greenthrow</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41939212">prev</a><span>|</span><a href="#41939115">next</a><span>|</span><label class="collapse" for="c-41939868">[-]</label><label class="expand" for="c-41939868">[1 more]</label></div><br/><div class="children"><div class="content">If this is your position then you might as well stop using any computing devices of any kind. Which includes any kind of smart devices. Since you obviously aren&#x27;t doing that, then you&#x27;re trying to hold Apple to a standard you won&#x27;t even follow yourself.<p>On top of which, your comment is a complete non-sequitur to the topic at hand. You could reply with this take to literally any security&#x2F;privacy related thread.</div><br/></div></div><div id="41939115" class="c"><input type="checkbox" id="c-41939115" checked=""/><div class="controls bullet"><span class="by">SheinhardtWigCo</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41939868">prev</a><span>|</span><a href="#41940768">next</a><span>|</span><label class="collapse" for="c-41939115">[-]</label><label class="expand" for="c-41939115">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but, considering the sheer complexity of modern CPUs and SoCs, this is still the case even if you have the silicon in front of you. That ship sailed some time ago.</div><br/></div></div><div id="41940768" class="c"><input type="checkbox" id="c-41940768" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41939115">prev</a><span>|</span><a href="#41940455">next</a><span>|</span><label class="collapse" for="c-41940768">[-]</label><label class="expand" for="c-41940768">[4 more]</label></div><br/><div class="children"><div class="content">With virtualized hardware the backdoor doesn’t even strictly need to be in silicon.</div><br/><div id="41941812" class="c"><input type="checkbox" id="c-41941812" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41940768">parent</a><span>|</span><a href="#41940455">next</a><span>|</span><label class="collapse" for="c-41941812">[-]</label><label class="expand" for="c-41941812">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s detectable through timing measurements, for the same reason you can&#x27;t have data-dependent operations in cryptography.</div><br/><div id="41941872" class="c"><input type="checkbox" id="c-41941872" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41941812">parent</a><span>|</span><a href="#41940455">next</a><span>|</span><label class="collapse" for="c-41941872">[-]</label><label class="expand" for="c-41941872">[2 more]</label></div><br/><div class="children"><div class="content">Ok, where are the timing measurements?</div><br/><div id="41942736" class="c"><input type="checkbox" id="c-41942736" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41941872">parent</a><span>|</span><a href="#41940455">next</a><span>|</span><label class="collapse" for="c-41942736">[-]</label><label class="expand" for="c-41942736">[1 more]</label></div><br/><div class="children"><div class="content">In the hardware secure boot chain ;)<p>You do have to trust the SEP&#x2F;TPM here, it sounds like. That is verified by having a third party auditor watch them get installed, and by the anonymous proxy routing thingy making it so they can&#x27;t fake only some of them but would have to fake all of them to be reliable.<p>If they were okay with it being unreliable, then clients could tell via timing because some of the nodes would perform differently, or they&#x27;d perform differently depending on which client or what prompt it was processing. It&#x27;s surprisingly difficult to hide timing differences, eg all those Spectre cache-reading attacks on browsers.<p>It does look like there&#x27;s room to add more verification (like the client asking the server to do more intensive proofs, or homomorphic encryption). Could always go ask for it.</div><br/></div></div></div></div></div></div></div></div><div id="41940455" class="c"><input type="checkbox" id="c-41940455" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41938972">parent</a><span>|</span><a href="#41940768">prev</a><span>|</span><a href="#41939941">next</a><span>|</span><label class="collapse" for="c-41940455">[-]</label><label class="expand" for="c-41940455">[2 more]</label></div><br/><div class="children"><div class="content">You have to be serious here.<p>The level of conspiracy needed to keep something like this a secret would be unprecedented.<p>And if Apple was able to do that why wouldn&#x27;t they just backdoor iOS&#x2F;OSX instead of baking it into the hardware.</div><br/><div id="41942119" class="c"><input type="checkbox" id="c-41942119" checked=""/><div class="controls bullet"><span class="by">azinman2</span><span>|</span><a href="#41938972">root</a><span>|</span><a href="#41940455">parent</a><span>|</span><a href="#41939941">next</a><span>|</span><label class="collapse" for="c-41942119">[-]</label><label class="expand" for="c-41942119">[1 more]</label></div><br/><div class="children"><div class="content">Or just not make any hardware promises, and do it like iCloud or OpenAI or Gemini or any other cloud product.</div><br/></div></div></div></div></div></div><div id="41939941" class="c"><input type="checkbox" id="c-41939941" checked=""/><div class="controls bullet"><span class="by">aabhay</span><span>|</span><a href="#41938972">prev</a><span>|</span><a href="#41942429">next</a><span>|</span><label class="collapse" for="c-41939941">[-]</label><label class="expand" for="c-41939941">[4 more]</label></div><br/><div class="children"><div class="content">A lot of people seem to be focusing on how this program isn’t sufficient as a guarantee, but those people are missing the point.<p>The real value of this system is that Apple is making legally enforceable claims about their system. Shareholders can, and do, sue companies that make inaccurate claims about their infrastructure.<p>I’m 100% sure that Apple’s massive legal team would never let this kind of program exist if _they_ weren’t also confident in these claims. And a legal team at Apple certainly has both internal and external obligations to verify these claims.<p>America’s legal system is in my opinion what allows the US to dominate economically, creating virtuous cycles like this.</div><br/><div id="41940844" class="c"><input type="checkbox" id="c-41940844" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#41939941">parent</a><span>|</span><a href="#41942429">next</a><span>|</span><label class="collapse" for="c-41940844">[-]</label><label class="expand" for="c-41940844">[3 more]</label></div><br/><div class="children"><div class="content">Unfortunately that doesn’t help anyone outside the US, not because of differences in the legal systems, but because as an American company Apple will always have to defer to the US agencies first.</div><br/><div id="41941611" class="c"><input type="checkbox" id="c-41941611" checked=""/><div class="controls bullet"><span class="by">aabhay</span><span>|</span><a href="#41939941">root</a><span>|</span><a href="#41940844">parent</a><span>|</span><a href="#41942429">next</a><span>|</span><label class="collapse" for="c-41941611">[-]</label><label class="expand" for="c-41941611">[2 more]</label></div><br/><div class="children"><div class="content">I’m pretty sure a foreign shareholder can sue in a US court of law. While I agree that “shareholder” in this case means extra-massive moneyed entity, I firmly believe that even this provides a deterrence effect. At the very least, for the scale of operations in the US, there’s an extremely high trust environment. That level of trust doesn’t exist even for orders of magnitude smaller issues in most other countries</div><br/><div id="41941691" class="c"><input type="checkbox" id="c-41941691" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#41939941">root</a><span>|</span><a href="#41941611">parent</a><span>|</span><a href="#41942429">next</a><span>|</span><label class="collapse" for="c-41941691">[-]</label><label class="expand" for="c-41941691">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this is why we don&#x27;t see bad behavior and willful abuse of the legal system by companies in the US.</div><br/></div></div></div></div></div></div></div></div><div id="41942429" class="c"><input type="checkbox" id="c-41942429" checked=""/><div class="controls bullet"><span class="by">ram_rattle</span><span>|</span><a href="#41939941">prev</a><span>|</span><a href="#41938197">next</a><span>|</span><label class="collapse" for="c-41942429">[-]</label><label class="expand" for="c-41942429">[2 more]</label></div><br/><div class="children"><div class="content">Something similar published by samsung, but sad that they are not as agile as apple in this area<p><a href="https:&#x2F;&#x2F;research.samsung.com&#x2F;blog&#x2F;The-Next-New-Normal-in-Computing-On-Device-Confidential-Computing" rel="nofollow">https:&#x2F;&#x2F;research.samsung.com&#x2F;blog&#x2F;The-Next-New-Normal-in-Com...</a></div><br/><div id="41942487" class="c"><input type="checkbox" id="c-41942487" checked=""/><div class="controls bullet"><span class="by">axoltl</span><span>|</span><a href="#41942429">parent</a><span>|</span><a href="#41938197">next</a><span>|</span><label class="collapse" for="c-41942487">[-]</label><label class="expand" for="c-41942487">[1 more]</label></div><br/><div class="children"><div class="content">This doesn&#x27;t look to be the same. Apple&#x27;s talking about performing computation in their cloud in a secure, privacy-preserving fashion. Samsung&#x27;s paper seems to be just on local enclaves (which Apple&#x27;s also been doing since iPhone 5S in the form of the Secure Enclave Processor (SEP)).</div><br/></div></div></div></div><div id="41938197" class="c"><input type="checkbox" id="c-41938197" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41942429">prev</a><span>|</span><a href="#41939136">next</a><span>|</span><label class="collapse" for="c-41938197">[-]</label><label class="expand" for="c-41938197">[1 more]</label></div><br/><div class="children"><div class="content">Wow! This is great!<p>I hope you&#x27;ll consider adding witness cosignatures on your transparency log though. :)</div><br/></div></div><div id="41939136" class="c"><input type="checkbox" id="c-41939136" checked=""/><div class="controls bullet"><span class="by">ngneer</span><span>|</span><a href="#41938197">prev</a><span>|</span><a href="#41943377">next</a><span>|</span><label class="collapse" for="c-41939136">[-]</label><label class="expand" for="c-41939136">[4 more]</label></div><br/><div class="children"><div class="content">How is this different than a bug bounty?</div><br/><div id="41939210" class="c"><input type="checkbox" id="c-41939210" checked=""/><div class="controls bullet"><span class="by">alemanek</span><span>|</span><a href="#41939136">parent</a><span>|</span><a href="#41939276">next</a><span>|</span><label class="collapse" for="c-41939210">[-]</label><label class="expand" for="c-41939210">[1 more]</label></div><br/><div class="children"><div class="content">Well they are providing a dedicated environment from which to attack their infrastructure.  But also they have a section called “ Apple Security Bounty for Private Cloud Compute” in the linked article so this is a bug bounty + additional goodies to help you test their security.</div><br/></div></div><div id="41939276" class="c"><input type="checkbox" id="c-41939276" checked=""/><div class="controls bullet"><span class="by">floam</span><span>|</span><a href="#41939136">parent</a><span>|</span><a href="#41939210">prev</a><span>|</span><a href="#41939192">next</a><span>|</span><label class="collapse" for="c-41939276">[-]</label><label class="expand" for="c-41939276">[1 more]</label></div><br/><div class="children"><div class="content">There is a bug bounty too, but the ability to run one the same infrastructure, OS, models locally is big.</div><br/></div></div><div id="41939192" class="c"><input type="checkbox" id="c-41939192" checked=""/><div class="controls bullet"><span class="by">davidczech</span><span>|</span><a href="#41939136">parent</a><span>|</span><a href="#41939276">prev</a><span>|</span><a href="#41943377">next</a><span>|</span><label class="collapse" for="c-41939192">[-]</label><label class="expand" for="c-41939192">[1 more]</label></div><br/><div class="children"><div class="content">Similar, but a lot of documentation is provided, source code for cross reference, and a VM based research environment instead of applying for a physical security research device.</div><br/></div></div></div></div><div id="41940084" class="c"><input type="checkbox" id="c-41940084" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#41943377">prev</a><span>|</span><label class="collapse" for="c-41940084">[-]</label><label class="expand" for="c-41940084">[14 more]</label></div><br/><div class="children"><div class="content">No amount of remote attestation and &quot;transparency logs&quot; and other bombastic statements like this would make up for the fact that they are fully in control of the servers and the software. There is absolutely no way for a customer to verify their claims that the data is not saved or transferred elsewhere.<p>So unless they offer a way for us to run the &quot;cloud services&quot; on our own hardware where we can strictly monitor and firewall all network activity, they are almost guaranteed to be misusing that data, especially given Apple&#x27;s proven track record of giving in to government&#x27;s demands for data access (see China).</div><br/><div id="41940518" class="c"><input type="checkbox" id="c-41940518" checked=""/><div class="controls bullet"><span class="by">kfreds</span><span>|</span><a href="#41940084">parent</a><span>|</span><a href="#41941827">next</a><span>|</span><label class="collapse" for="c-41940518">[-]</label><label class="expand" for="c-41940518">[1 more]</label></div><br/><div class="children"><div class="content">&gt; No amount of remote attestation and &quot;transparency logs&quot; and other bombastic statements like this would make up for the fact that they are fully in control of the servers and the software. There is absolutely no way for a customer to verify their claims that the data is not saved or transferred elsewhere.<p>You are right. Apple is fully in control of the servers and the software, and there is no way for a customer to verify Apple&#x27;s claims. Nevertheless system transparency is a useful concept. It can effectively reduce the number of things you have to blindly trust to a short and explicit list. Conversely it forces the operator, in this case Apple, to explicitly lie. As others have pointed out, that is quite a business risk.<p>As for transparency logs, it is an amazing technology which I can highly recommend you take a look at in case you don&#x27;t know what it is or how it works. Check out transparency.dev or the project I&#x27;m involved in, sigsum.org.<p>&gt; they are almost guaranteed to be misusing that data<p>That is very unlikely because of the liability, as others have pointed out. They are making claims which the Apple PCC architecture helps make falsifiable.</div><br/></div></div><div id="41941827" class="c"><input type="checkbox" id="c-41941827" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41940084">parent</a><span>|</span><a href="#41940518">prev</a><span>|</span><label class="collapse" for="c-41941827">[-]</label><label class="expand" for="c-41941827">[12 more]</label></div><br/><div class="children"><div class="content">&gt; There is absolutely no way for a customer to verify their claims that the data is not saved or transferred elsewhere.<p>Transparency logs are capable of verifying that, it&#x27;s more or less the whole point of them. (Strictly speaking, you can make it arbitrarily expensive to fake it.)<p>Also, if they were &quot;transferring your data elsewhere&quot; it would be a GDPR violation. Ironically wrt your China claim, it would also be illegal in China, which does in fact have privacy laws.</div><br/><div id="41942226" class="c"><input type="checkbox" id="c-41942226" checked=""/><div class="controls bullet"><span class="by">ls612</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41941827">parent</a><span>|</span><a href="#41942255">next</a><span>|</span><label class="collapse" for="c-41942226">[-]</label><label class="expand" for="c-41942226">[2 more]</label></div><br/><div class="children"><div class="content">Are transparency logs akin to Certificate Transparency but for signed code? I’ve read through the section a couple times and still don’t fully understand it.</div><br/><div id="41942772" class="c"><input type="checkbox" id="c-41942772" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41942226">parent</a><span>|</span><a href="#41942255">next</a><span>|</span><label class="collapse" for="c-41942772">[-]</label><label class="expand" for="c-41942772">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it&#x27;s a log of all the software that runs on the server. If you trust the secure boot process then you trust the log describes its contents.<p>If you don&#x27;t trust the boot process&#x2F;code signing system then you&#x27;d want to do something else, like ask the server to show you parts of its memory on demand in case you catch it lying to you. (Not sure if that&#x27;s doable here because the server has other people&#x27;s data on it, which is the whole point.)</div><br/></div></div></div></div><div id="41942255" class="c"><input type="checkbox" id="c-41942255" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41941827">parent</a><span>|</span><a href="#41942226">prev</a><span>|</span><label class="collapse" for="c-41942255">[-]</label><label class="expand" for="c-41942255">[9 more]</label></div><br/><div class="children"><div class="content">That makes no sense at all. They control the servers and services entirely; they can choose to emit whatever logs they want into the &quot;transparent logs&quot; and then emit whatever else they don&#x27;t want into non-transparent logs.<p>Even if they were running open source software with cryptographically verified &#x2F; reproducible builds, it&#x27;s still running on their hardware (any component or the OS &#x2F; kernel or even hardware can be hooked into to exfiltrate unencrypted data).<p>Companies like Apple don&#x27;t give a crap about GDPR violations (you can look at their &quot;DMA compliance&quot; BS games to see to what extent they&#x27;re willing to go to skirt regulations in the name of profit).</div><br/><div id="41942361" class="c"><input type="checkbox" id="c-41942361" checked=""/><div class="controls bullet"><span class="by">davidczech</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41942255">parent</a><span>|</span><a href="#41942413">next</a><span>|</span><label class="collapse" for="c-41942361">[-]</label><label class="expand" for="c-41942361">[5 more]</label></div><br/><div class="children"><div class="content">&gt; they can choose to emit whatever logs they want into the &quot;transparent logs&quot; and then emit whatever else they don&#x27;t want into non-transparent logs.<p>The log is publicly accessible and append-only, so such an event would not go un-noticed. Not sure what a non-transparent log is.</div><br/><div id="41942479" class="c"><input type="checkbox" id="c-41942479" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41942361">parent</a><span>|</span><a href="#41942413">next</a><span>|</span><label class="collapse" for="c-41942479">[-]</label><label class="expand" for="c-41942479">[4 more]</label></div><br/><div class="children"><div class="content">Ok, but they write and fully control the closed-source software that appends to the log. How can anyone verify that all the code paths append to the log? I&#x27;m pretty sure they can just not append to the log from their ExfiltrateDataForAdvertisment() and ExfiltrateDataForGovernments() functions.<p>Maybe I&#x27;m not being clear; transparent logs solve the problem of supply chain attacks (that is, Apple can use the logs to some degree to ensure some 3rd party isn&#x27;t modifying their code), but I&#x27;m trying to say Apple themselves ARE the bad actor, they will exfiltrate customer data for their own profit (to personalize ads, or continue building user profiles, or sell to governments and so on).</div><br/><div id="41942573" class="c"><input type="checkbox" id="c-41942573" checked=""/><div class="controls bullet"><span class="by">davidczech</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41942479">parent</a><span>|</span><a href="#41942413">next</a><span>|</span><label class="collapse" for="c-41942573">[-]</label><label class="expand" for="c-41942573">[3 more]</label></div><br/><div class="children"><div class="content">&gt; How can anyone verify that all the code paths append to the log? I&#x27;m pretty sure they can just not append to the log from their ExfiltrateDataForAdvertisment() and ExfiltrateDataForGovernments() functions.<p>I think we have different understandings of what the transparency log is utilized for.<p>The log is used effectively as an append-only hash set of trusted software hashes a PCC node is allowed to run, accomplished using Merkle Trees. The client device (iPhone) uses the log to determine if the software measurements from an attestation should be rejected or not.<p><a href="https:&#x2F;&#x2F;security.apple.com&#x2F;documentation&#x2F;private-cloud-compute&#x2F;appendix_transparencylog#Log-integrity-verification" rel="nofollow">https:&#x2F;&#x2F;security.apple.com&#x2F;documentation&#x2F;private-cloud-compu...</a></div><br/><div id="41942689" class="c"><input type="checkbox" id="c-41942689" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41942573">parent</a><span>|</span><a href="#41942413">next</a><span>|</span><label class="collapse" for="c-41942689">[-]</label><label class="expand" for="c-41942689">[2 more]</label></div><br/><div class="children"><div class="content">One of the replies in this thread sent me to transparency.dev which describes transparency logs as something different. But reading Apple&#x27;s description doesn&#x27;t change my opinion on this. It is a supply-chain &#x2F; MITM protection measure and does absolutely nothing to assuage my privacy concerns.<p>Bottom line, I just hope that there will be a big checkbox in the iPhone&#x27;s settings that completely turns off all &quot;cloud compute&quot; for AI scenarios (checked by default) and I hope it gets respected everywhere. But they&#x27;re making such a big deal of how &quot;private&quot; this data exfiltration service is that I fear they plan to just make it default on (or not even provide an opt-out at all).</div><br/><div id="41942956" class="c"><input type="checkbox" id="c-41942956" checked=""/><div class="controls bullet"><span class="by">davidczech</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41942689">parent</a><span>|</span><a href="#41942413">next</a><span>|</span><label class="collapse" for="c-41942956">[-]</label><label class="expand" for="c-41942956">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  It is a supply-chain &#x2F; MITM protection measure<p>It is so much more than that, but you are entitled to your own opinion.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41942413" class="c"><input type="checkbox" id="c-41942413" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41942255">parent</a><span>|</span><a href="#41942361">prev</a><span>|</span><label class="collapse" for="c-41942413">[-]</label><label class="expand" for="c-41942413">[3 more]</label></div><br/><div class="children"><div class="content">&gt; They control the servers and services entirely<p>There&#x27;s a key signing ceremony with a third-party auditor watching; it seems to rely on trusting them together with the secure boot process. But there are other things you can add to this, basically along the lines of making the machine continually prove that it behaves like the system described in the log.<p>They don&#x27;t control all of the service though; part of the system is that the server can&#x27;t identify the user because everything goes through third party proxies owned by several different companies.<p>&gt; Companies like Apple don&#x27;t give a crap about GDPR violations<p>GDPR fines are 4% of the company&#x27;s yearly global revenue. If you&#x27;re a cold logical profit maximizer, you&#x27;re going to care about that a lot!<p>Beyond that, they&#x27;ve published a document saying all this stuff, which means you can sue them for securities fraud if it turns out to be a lie. It&#x27;s illegal for US companies to lie to their shareholders.</div><br/><div id="41942510" class="c"><input type="checkbox" id="c-41942510" checked=""/><div class="controls bullet"><span class="by">gigel82</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41942413">parent</a><span>|</span><label class="collapse" for="c-41942510">[-]</label><label class="expand" for="c-41942510">[2 more]</label></div><br/><div class="children"><div class="content">&quot;ceremony&quot; is a good choice of word; it&#x27;s all ceremonial and nonsense; as long as they control the hardware and the software there is absolutely no way for someone to verify this claim.<p>Apple has lied to shareholders before, remember those &quot;what happens on your iPhone, stays on your iPhone&quot; billboards back in the day they used to fool everyone into thinking Apple cares about privacy? A couple years later, they were proudly announcing how everyone&#x27;s iPhone will scan their files and literally send them to law enforcement if they match some opaque government-controlled database of hashes (yes, they backed out of that plan eventually, but not before massive public outcry and going through a few &quot;you&#x27;re holding it wrong&quot; explanations).</div><br/><div id="41942724" class="c"><input type="checkbox" id="c-41942724" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#41940084">root</a><span>|</span><a href="#41942510">parent</a><span>|</span><label class="collapse" for="c-41942724">[-]</label><label class="expand" for="c-41942724">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Apple has lied to shareholders before<p>So sue them.<p>&gt; how everyone&#x27;s iPhone will scan their files and literally send them to law enforcement<p>That was a solution for if you opted into a cloud service, was a strict privacy improvement because it came alongside end-to-end encryption in the cloud, and I think was mandated by upcoming EU regulations (although I think they changed the regulations so it was dropped.)<p>Note in the US service providers are required to report CSAM to NCMEC if they see it; it&#x27;s literally the only thing they&#x27;re required to do. But NCMEC is not &quot;law enforcement&quot; or &quot;government&quot;, it&#x27;s a private organization specially named in the law. Very important distinction because if anyone does give your private information to law enforcement you&#x27;d lose your 4th Amendment rights over it, since the government can share it with itself.<p>(I think it may actually be illegal to proactively send PII to law enforcement without them getting a subpoena first, but don&#x27;t remember. There&#x27;s an exception for emergency situations, and those self service portals that large corporations have are definitely questionable here.)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>