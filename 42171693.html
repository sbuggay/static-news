<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1732352514043" as="style"/><link rel="stylesheet" href="styles.css?v=1732352514043"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://lucumr.pocoo.org/2024/11/18/threads-beat-async-await/">Playground Wisdom: Threads Beat Async/Await</a> <span class="domain">(<a href="https://lucumr.pocoo.org">lucumr.pocoo.org</a>)</span></div><div class="subtext"><span>samwillis</span> | <span>46 comments</span></div><br/><div><div id="42179081" class="c"><input type="checkbox" id="c-42179081" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#42175674">next</a><span>|</span><label class="collapse" for="c-42179081">[-]</label><label class="expand" for="c-42179081">[8 more]</label></div><br/><div class="children"><div class="content">The article seems specific to JavaScript, C# is different.<p>&gt; you cannot await in a sync function<p>In C# it’s easy to block the current thread waiting for an async task to complete, see Task.Wait method.<p>&gt; since it will never resolve, you can also never await it<p>In C#, awaiting for things which never complete is not that bad, the standard library has Task.WhenAny() method for that.<p>&gt; let&#x27;s talk about C#. Here the origin story is once again entirely different<p>Originally, NT kernel was designed for SMP from the ground up, supports asynchronous operations on handles like files and sockets, and since NT 3.5 the kernel includes support for thread pool to dispatch IO completions: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Input&#x2F;output_completion_port" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Input&#x2F;output_completion_port</a><p>Overlapped I&#x2F;O and especially IOCP are hard to use directly. When Microsoft designed initial version of .NET, they implemented thread pool and IOCP inside the runtime, and exposed higher-level APIs to use them. Stuff like Stream.BeginRead &#x2F; Stream.EndRead available since .NET 1.1 in 2003, the design pattern is called Asynchronous Programming Model (APM).<p>Async&#x2F;await language feature introduced in .NET 4.5 in 2012 is a thin layer of sugar on top of these begin&#x2F;end asynchronous APIs which were always there. BTW, if you have a pair of begin&#x2F;end methods, converting into async&#x2F;await takes 1 line of code, see TaskFactory.FromAsync.</div><br/><div id="42181507" class="c"><input type="checkbox" id="c-42181507" checked=""/><div class="controls bullet"><span class="by">the_mitsuhiko</span><span>|</span><a href="#42179081">parent</a><span>|</span><a href="#42179219">next</a><span>|</span><label class="collapse" for="c-42181507">[-]</label><label class="expand" for="c-42181507">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re probably right that this is leaning in on JavaScript and Python more, but I did try to make a point that the origin story for this feature is quite a bit different between languages.  C# is the originator of that feature, but the implications of that feature in C# are quite different than in for instance JavaScript or Python.  But when people have a discussion about async&#x2F;await it often loses these nuances very quickly.<p>&gt; Async&#x2F;await language feature introduced in .NET 4.5 in 2012 is a thin layer of sugar on top of these begin&#x2F;end asynchronous APIs which were always there.<p>You are absolutely right.  That said, it was a conscious decision to keep the callback model and provide &quot;syntactic sugar&quot; on top of it to make it work.  That is not the only model that could have been chosen.</div><br/></div></div><div id="42179219" class="c"><input type="checkbox" id="c-42179219" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#42179081">parent</a><span>|</span><a href="#42181507">prev</a><span>|</span><a href="#42184388">next</a><span>|</span><label class="collapse" for="c-42179219">[-]</label><label class="expand" for="c-42179219">[1 more]</label></div><br/><div class="children"><div class="content">Task.Wait() is just using the normal &quot;thread&quot; (in the way the author defines it later) blocking logic to do that in said case but I think the author is trying to talk about pure async&#x2F;await approaches there as an example of why you still want exactly that kind of non-async &quot;thread&quot; blocking to fall back on for differently colored functions.<p>Task.WhenAny() is similar to Promise.any()&#x2F;Promise.race(). I&#x27;m not sure this is where the author is focusing attention on though. Regardless if your execution is able to move on and out of that scope those other promises may still never finish or get cleaned up.</div><br/></div></div><div id="42184388" class="c"><input type="checkbox" id="c-42184388" checked=""/><div class="controls bullet"><span class="by">throwitaway1123</span><span>|</span><a href="#42179081">parent</a><span>|</span><a href="#42179219">prev</a><span>|</span><a href="#42219210">next</a><span>|</span><label class="collapse" for="c-42184388">[-]</label><label class="expand" for="c-42184388">[3 more]</label></div><br/><div class="children"><div class="content">&gt; In C#, awaiting for things which never complete is not that bad, the standard library has Task.WhenAny() method for that.<p>It&#x27;s not that bad in JS either. JS has both Promise.any and Promise.race that can trivially set a timeout to prevent a function from waiting infinitely for a non-resolving promise. And as someone pointed out in the Lobsters thread, runtimes that rely on multi-threading for concurrency are also often prone to deadlocks and infinite loops [1].<p><pre><code>  import { setTimeout } from &#x27;node:timers&#x2F;promises&#x27;
  
  const neverResolves = new Promise(() =&gt; {})
  
  await Promise.any([neverResolves, setTimeout(0)])
  await Promise.race([neverResolves, setTimeout(0)])
  
  console.trace()

</code></pre>
[1] <a href="https:&#x2F;&#x2F;lobste.rs&#x2F;s&#x2F;hlz4kt&#x2F;threads_beat_async_await#c_cf4wa1" rel="nofollow">https:&#x2F;&#x2F;lobste.rs&#x2F;s&#x2F;hlz4kt&#x2F;threads_beat_async_await#c_cf4wa1</a></div><br/><div id="42219028" class="c"><input type="checkbox" id="c-42219028" checked=""/><div class="controls bullet"><span class="by">cyberax</span><span>|</span><a href="#42179081">root</a><span>|</span><a href="#42184388">parent</a><span>|</span><a href="#42219210">next</a><span>|</span><label class="collapse" for="c-42219028">[-]</label><label class="expand" for="c-42219028">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Promise.race<p>Ding! You now have a memory leak! Collect your $200 and advance two steps.<p>Promise.race will waste memory until _all_ of its promises are resolved. So if a promise never gets resolved, it will stick around forever.<p>It&#x27;s braindead, but it&#x27;s the spec: <a href="https:&#x2F;&#x2F;github.com&#x2F;nodejs&#x2F;node&#x2F;issues&#x2F;17469">https:&#x2F;&#x2F;github.com&#x2F;nodejs&#x2F;node&#x2F;issues&#x2F;17469</a></div><br/><div id="42219756" class="c"><input type="checkbox" id="c-42219756" checked=""/><div class="controls bullet"><span class="by">throwitaway1123</span><span>|</span><a href="#42179081">root</a><span>|</span><a href="#42219028">parent</a><span>|</span><a href="#42219210">next</a><span>|</span><label class="collapse" for="c-42219756">[-]</label><label class="expand" for="c-42219756">[1 more]</label></div><br/><div class="children"><div class="content">This doesn&#x27;t even really appear to be a flaw in the Promise.race implementation [1], but rather a natural result of the fact that native promises don&#x27;t have any notion of manual unsubscription. Every time you call the then method on a promise and pass in a callback, the JS engine appends the callback to the list of &quot;reactions&quot; [2]. This isn&#x27;t too dissimilar to registering a ton of event listeners and never calling `removeEventListener`. Unfortunately, unlike events, promises don&#x27;t have any manual unsubscription primitive (e.g. a hypothetical `removePromiseListener`), and instead rely on automatic unsubscription when the underlying promise resolves or rejects. You can of course polyfill this missing behavior if you&#x27;re in the habit of consistently waiting on infinitely non-settling promises, but I would definitely like to see TC39 standardize this [3].<p>[1] <a href="https:&#x2F;&#x2F;issues.chromium.org&#x2F;issues&#x2F;42213031#comment5" rel="nofollow">https:&#x2F;&#x2F;issues.chromium.org&#x2F;issues&#x2F;42213031#comment5</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;nodejs&#x2F;node&#x2F;issues&#x2F;17469#issuecomment-349794909">https:&#x2F;&#x2F;github.com&#x2F;nodejs&#x2F;node&#x2F;issues&#x2F;17469#issuecomment-349...</a><p>[3] <a href="https:&#x2F;&#x2F;github.com&#x2F;cefn&#x2F;watchable&#x2F;tree&#x2F;main&#x2F;packages&#x2F;unpromise#under-the-hood-step-3---unsubscribe">https:&#x2F;&#x2F;github.com&#x2F;cefn&#x2F;watchable&#x2F;tree&#x2F;main&#x2F;packages&#x2F;unpromi...</a></div><br/></div></div></div></div></div></div><div id="42219210" class="c"><input type="checkbox" id="c-42219210" checked=""/><div class="controls bullet"><span class="by">User23</span><span>|</span><a href="#42179081">parent</a><span>|</span><a href="#42184388">prev</a><span>|</span><a href="#42175674">next</a><span>|</span><label class="collapse" for="c-42219210">[-]</label><label class="expand" for="c-42219210">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Originally, NT kernel was designed for SMP from the ground up, supports asynchronous operations on handles like files and sockets, and since NT 3.5 the kernel includes support for thread pool to dispatch IO completions: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Input&#x2F;output_completion_port" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Input&#x2F;output_completion_port</a><p>Say what you will about Microsoft in that era (and there&#x27;s a lot to be said), the NT kernel team absolutely crushed it for their customers&#x27; use cases. IOCP were years ahead of anything else.<p>I pretty much hated all of the userspace Win32 work I did (MIDL, COM, DCOM, UGGGGGGGGH), but the Kernel interfaces were wonderful to code against. To this day I have fond memories of Jeffrey Richter&#x27;s book.</div><br/><div id="42219251" class="c"><input type="checkbox" id="c-42219251" checked=""/><div class="controls bullet"><span class="by">wbl</span><span>|</span><a href="#42179081">root</a><span>|</span><a href="#42219210">parent</a><span>|</span><a href="#42175674">next</a><span>|</span><label class="collapse" for="c-42219251">[-]</label><label class="expand" for="c-42219251">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not enough to have a nicish abstraction, how did it work in practice and eek out performance? I&#x27;ve heard Bryan Cantrell say there wasn&#x27;t much there and would be curious to really know what the truth is and more explanation on both sides.</div><br/></div></div></div></div></div></div><div id="42175674" class="c"><input type="checkbox" id="c-42175674" checked=""/><div class="controls bullet"><span class="by">arctek</span><span>|</span><a href="#42179081">prev</a><span>|</span><a href="#42178791">next</a><span>|</span><label class="collapse" for="c-42175674">[-]</label><label class="expand" for="c-42175674">[1 more]</label></div><br/><div class="children"><div class="content">I actually think out of any language async&#x2F;await makes the most sense for javascript.<p>In the first example: there is no such thing as a blocking sleep in javascript. What people use as sleep is just a promise wrapper around a setTimeout call. setTimeout has always created microtasks, so calling a sleep inline would do nothing to halt execution.<p>I do agree that dangling Promises are annoying and Promise.race is especially bad as it doesn&#x27;t do what you expect: finish the fastest promise and cancel the other. It will actually eventually resolve both but you will only get one result.<p>Realistically in JS you write your long running async functions to take an AbortController wrapper that also provides a sleep function, then in your outer loop you check the signal isn&#x27;t aborted and the wrapper class also handles calling clearTimeout on wrapped sleep functions to stop sleeping&#x2F;pending setTimeouts and exit your loop&#x2F;function.</div><br/></div></div><div id="42178791" class="c"><input type="checkbox" id="c-42178791" checked=""/><div class="controls bullet"><span class="by">serbuvlad</span><span>|</span><a href="#42175674">prev</a><span>|</span><a href="#42219022">next</a><span>|</span><label class="collapse" for="c-42178791">[-]</label><label class="expand" for="c-42178791">[17 more]</label></div><br/><div class="children"><div class="content">As someone who has only written serious applications in single-threaded, or manually threaded C&#x2F;C++, and concurrent applications in go using goroutines, channels, and all that fun stuff, I always find the discussion around async&#x2F;await fascinating. Especially since it seems to be so ubiquitous in modern programming, outside of my sphere.<p>But one thing is: I don&#x27;t get it. Why can&#x27;t I await in a normal function? await sounds blocking. If async functions return promises, why can&#x27;t I launch multiple async functions, then await on each of them, in a non-async function that does not return a promise?<p>I get there are answers to my questions. I get await means &quot;yeald if not ready&quot; and if the function is not async &quot;yeald&quot; is meaningless. But I find it a very strange way of thinking nonetheless.</div><br/><div id="42219003" class="c"><input type="checkbox" id="c-42219003" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42218662">next</a><span>|</span><label class="collapse" for="c-42219003">[-]</label><label class="expand" for="c-42219003">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why can&#x27;t I await in a normal function?<p>You can.  promise.then(callback).  If you want the rest of your logic to be &quot;blocking&quot; then the rest of it goes in the callback.  the &#x27;then&#x27; method itself returns a promise,  so you can return that from a non async function,  if you like.<p>&gt; why can&#x27;t I launch multiple async functions, then await on each of them, in a non-async function that does not return a promise?<p>Typically?  Exception handling semantics.  See the difference between Promise.race, Promise.all and Promise.allSettled.</div><br/></div></div><div id="42218662" class="c"><input type="checkbox" id="c-42218662" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42219003">prev</a><span>|</span><a href="#42219088">next</a><span>|</span><label class="collapse" for="c-42218662">[-]</label><label class="expand" for="c-42218662">[1 more]</label></div><br/><div class="children"><div class="content">The `await` keyword means &quot;turn the rest of this function into a callback for the when the Task I&#x27;m waiting on finishes, and return the resulting Task&quot;. Returning a Task only works if your function is declared to return a Task.<p>The `async` keyword flags functions that are allowed to be transformed like that. I assume it could have been made implicit.<p>You can do a blocking wait on a Task or collection of Tasks. But you don&#x27;t want to do that from a place that might be called from the event loop&#x27;s thread pool (such as anything called from a Task&#x27;s completion callback), since it can lock up.</div><br/></div></div><div id="42219088" class="c"><input type="checkbox" id="c-42219088" checked=""/><div class="controls bullet"><span class="by">binary132</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42218662">prev</a><span>|</span><a href="#42218668">next</a><span>|</span><label class="collapse" for="c-42219088">[-]</label><label class="expand" for="c-42219088">[1 more]</label></div><br/><div class="children"><div class="content">I found it all very confusing until I eventually wrote a little async task scheduler in Lua.  Lua has an async &#x2F; cooperative-coroutine API that is both very simple and easy to express meaningful coroutines with.  The API is almost like a sort of system of safer gotos, but in practice it’s very much like Go channel receives, if waiting for a value from a channel was how you passed control to the producer side, and instead of a channel, the producer was just a function call that would return the next value every time you passed it control.<p>What’s interesting is that C++20 coroutines have very nearly the same API and semantics as Lua’s coroutines.  Still haven’t taken the time to dive into that, but now that 23 is published and has working ranges, std::generator looks very promising since it’s kind of a lazy bridge between coroutines and ranges.</div><br/></div></div><div id="42218668" class="c"><input type="checkbox" id="c-42218668" checked=""/><div class="controls bullet"><span class="by">shepherdjerred</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42219088">prev</a><span>|</span><a href="#42218667">next</a><span>|</span><label class="collapse" for="c-42218668">[-]</label><label class="expand" for="c-42218668">[1 more]</label></div><br/><div class="children"><div class="content">At least in JavaScript, you could mark all of your functions as `async`.<p>This would mean that function would have to return a Promise and go back to the event loop which would add overhead. I imagine it&#x27;d kill performance since you&#x27;d essentially be context switching on every function call.<p>The obvious workaround for this is to say &quot;I want some of my code to run serially without promises&quot;, which is essentially  is asking for a `sync` keyword (or, `async` which would be the inverse).</div><br/></div></div><div id="42218667" class="c"><input type="checkbox" id="c-42218667" checked=""/><div class="controls bullet"><span class="by">Rohansi</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42218668">prev</a><span>|</span><a href="#42180466">next</a><span>|</span><label class="collapse" for="c-42218667">[-]</label><label class="expand" for="c-42218667">[1 more]</label></div><br/><div class="children"><div class="content">`await` is only logically blocking. Internally the code in an async function is split up between each `await` so that each fragment can be called separately. They are cooperatively scheduled so `await` is sugar for 1) ending a fragment, 2) registering a new fragment to run when X completes, and 3) yielding control back to the scheduler. None of this internal behavior is present for non-async functions - in C# they run directly on bare threads like C++.<p>Go&#x27;s goroutines are comparable to async&#x2F;await but everything is transparent. In that case it&#x27;s managed by the runtime instead of a bit of syntactic sugar + libraries.</div><br/></div></div><div id="42180466" class="c"><input type="checkbox" id="c-42180466" checked=""/><div class="controls bullet"><span class="by">mrkeen</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42218667">prev</a><span>|</span><a href="#42186359">next</a><span>|</span><label class="collapse" for="c-42180466">[-]</label><label class="expand" for="c-42180466">[5 more]</label></div><br/><div class="children"><div class="content">You can:<p><a href="https:&#x2F;&#x2F;hackage.haskell.org&#x2F;package&#x2F;async-2.2.5&#x2F;docs&#x2F;Control-Concurrent-Async.html#g:4" rel="nofollow">https:&#x2F;&#x2F;hackage.haskell.org&#x2F;package&#x2F;async-2.2.5&#x2F;docs&#x2F;Control...</a><p>As long as you don&#x27;t mind - what did the article say? -<p>&gt;&gt; transcending to a higher plane and looking down to the folks who are stitching together if statements, for loops, make side effects everywhere, and are doing highly inappropriate things with IO.</div><br/></div></div><div id="42186359" class="c"><input type="checkbox" id="c-42186359" checked=""/><div class="controls bullet"><span class="by">mr_coleman</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42180466">prev</a><span>|</span><a href="#42219362">next</a><span>|</span><label class="collapse" for="c-42186359">[-]</label><label class="expand" for="c-42186359">[1 more]</label></div><br/><div class="children"><div class="content">In C# you can do a collection of Task&lt;T&gt;, start them and then do a Task.WaitAll() on the collection. For example a batch of web requests at the same time and then collect the results once everything is done. I&#x27;m not sure how it&#x27;s done in other languages but I imagine there&#x27;s something similar.</div><br/></div></div><div id="42219362" class="c"><input type="checkbox" id="c-42219362" checked=""/><div class="controls bullet"><span class="by">MatmaRex</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42186359">prev</a><span>|</span><a href="#42178953">next</a><span>|</span><label class="collapse" for="c-42219362">[-]</label><label class="expand" for="c-42219362">[2 more]</label></div><br/><div class="children"><div class="content">You can await in a normal function in better languages, just not in JavaScript.</div><br/><div id="42219463" class="c"><input type="checkbox" id="c-42219463" checked=""/><div class="controls bullet"><span class="by">egeozcan</span><span>|</span><a href="#42178791">root</a><span>|</span><a href="#42219362">parent</a><span>|</span><a href="#42178953">next</a><span>|</span><label class="collapse" for="c-42219463">[-]</label><label class="expand" for="c-42219463">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why can&#x27;t I await in a normal function? await sounds blocking<p>&gt; You can await in a normal function in better languages, just not in JavaScript.<p>Await, per common definition, makes you wait asynchronously for a Task&#x2F;Promise. How on earth are you going to &quot;await&quot; for a Promise which also runs on the same thread on a synchronous function? That function needs to be psuedo-async as in &quot;return myPromise.then(() =&gt; { &#x2F;* all fn code here *&#x2F; }), or you need to use threads, which brings us to the second point...<p>With the closest thing to threads (workers) in JavaScript and using SharedArrayBuffer and a simple while loop, perhaps (didn&#x27;t think too much on it), you can implement the same thing with a user defined Promise alternative but then why would you want to block the main thread which usually has GUI&#x2F;Web-Server code?</div><br/></div></div></div></div><div id="42178953" class="c"><input type="checkbox" id="c-42178953" checked=""/><div class="controls bullet"><span class="by">avandekleut</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42219362">prev</a><span>|</span><a href="#42219222">next</a><span>|</span><label class="collapse" for="c-42178953">[-]</label><label class="expand" for="c-42178953">[1 more]</label></div><br/><div class="children"><div class="content">At least in node, its because the runtime is an event loop.</div><br/></div></div><div id="42219222" class="c"><input type="checkbox" id="c-42219222" checked=""/><div class="controls bullet"><span class="by">chrisweekly</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42178953">prev</a><span>|</span><a href="#42218703">next</a><span>|</span><label class="collapse" for="c-42219222">[-]</label><label class="expand" for="c-42219222">[1 more]</label></div><br/><div class="children"><div class="content">yeald -&gt; yield</div><br/></div></div><div id="42218703" class="c"><input type="checkbox" id="c-42218703" checked=""/><div class="controls bullet"><span class="by">AlienRobot</span><span>|</span><a href="#42178791">parent</a><span>|</span><a href="#42219222">prev</a><span>|</span><a href="#42219022">next</a><span>|</span><label class="collapse" for="c-42218703">[-]</label><label class="expand" for="c-42218703">[1 more]</label></div><br/><div class="children"><div class="content">In my experience with web browsers, you can&#x27;t do this because Javascript can NEVER block. For example, if a function takes too long to run, it blocks rendering of the page. If there were ways to make Javascript asynchronously, browsers would have implemented it already, so I assume they can&#x27;t do it without potential backward incompatibility.<p>One exception is alert(), which blocks and shows a dialog. But I don&#x27;t think I&#x27;ve ever seen a website use it instead of showing a &quot;normal&quot; popup with CSS. It looks ugly so it&#x27;s only used to debug that code actually runs.<p>I&#x27;m not knowledgeable about low-level interruptions, but I think you would need at least some runtime code to implement blocking the thread. In any case, even if the language provides this, you can&#x27;t use it because the main thread is normally a GUI thread that can&#x27;t respond to user interaction if it&#x27;s blocked by another thread. That&#x27;s the main point of using (background) threads in the first place: so the main thread never blocks from IO bottlenecks.</div><br/></div></div></div></div><div id="42219022" class="c"><input type="checkbox" id="c-42219022" checked=""/><div class="controls bullet"><span class="by">whoisthemachine</span><span>|</span><a href="#42178791">prev</a><span>|</span><a href="#42219409">next</a><span>|</span><label class="collapse" for="c-42219022">[-]</label><label class="expand" for="c-42219022">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Your Child Loves Actor Frameworks<p>It turns out, Promises <i>are</i> actors. Very simple actors that can have one and only one message that upon resolution they dispatch to all other subscribed actors [0]. So children might love Promises and async&#x2F;await then?<p>Personally, I&#x27;ve often thought the resolution to the &quot;color&quot; debate would be for a new language to make all public interfaces between modules &quot;Promises&quot; by default. Then the default assumption is &quot;if I call this public function it could take some time to complete&quot;. Everything acting synchronously should be an implementation detail that is nice if it works out.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Futures_and_promises#Semantics_of_futures_in_the_actor_model" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Futures_and_promises#Semantics...</a></div><br/><div id="42219081" class="c"><input type="checkbox" id="c-42219081" checked=""/><div class="controls bullet"><span class="by">emadda</span><span>|</span><a href="#42219022">parent</a><span>|</span><a href="#42219409">next</a><span>|</span><label class="collapse" for="c-42219081">[-]</label><label class="expand" for="c-42219081">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a nice mental model for promises.<p>But it is not always true that one promise instance can be awaited in multiple places.<p>In Swift you cannot get the ref to the Promise instance, so you cannot store it or await it at multiple places.<p>Once you start an async fn the compiler forces you to await it where it was started (you can use `await task.value`, but that is a getter fn that creates a new hidden promise ref on every call).</div><br/><div id="42219097" class="c"><input type="checkbox" id="c-42219097" checked=""/><div class="controls bullet"><span class="by">whoisthemachine</span><span>|</span><a href="#42219022">root</a><span>|</span><a href="#42219081">parent</a><span>|</span><a href="#42219409">next</a><span>|</span><label class="collapse" for="c-42219097">[-]</label><label class="expand" for="c-42219097">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not familiar with Swift, but it still sounds like it&#x27;s describing an actor model, just one with a subset of the functionality.</div><br/></div></div></div></div></div></div><div id="42219409" class="c"><input type="checkbox" id="c-42219409" checked=""/><div class="controls bullet"><span class="by">cryptonector</span><span>|</span><a href="#42219022">prev</a><span>|</span><a href="#42179512">next</a><span>|</span><label class="collapse" for="c-42219409">[-]</label><label class="expand" for="c-42219409">[1 more]</label></div><br/><div class="children"><div class="content">Threads are definitely not _the_ answer but _an_ answer.<p>You can have as many threads as hardware threads, but in each thread you want continuation passing style (CPS) or async-await (which is a lot like syntactic sugar for CPS).  Why?  Because threads let you smear program state over a large stack, increasing memory footprint, while CPS &#x2F; async-await forces you to make all the state explicit and compressed, thus optimizing memory footprint.  This is not a small thing.  If you have thread-per-client services, each thread will need a sizeable stack, each stack with a guard page -- even with virtual memory that&#x27;s expensive, both to set up and in terms of total memory footprint.<p>Between memory per client, L1&#x2F;L2 cache footprint per client, page faults (to grow the stack), and context switching overhead, thread-per-client is much more expensive than NPROC threads doing CPS or async-await.  If you compress the program state per client you can fit more clients in the same amount of memory, and the overhead of switching from one client to another is lower, thus you can have more clients.<p>This is the reason that async I&#x2F;O is the key to solving the &quot;C10K&quot; problem: it forces the programmer to compress per-client program state.<p>But if you don&#x27;t need to cater to C10K (or C10M) then thread-per-client is definitely simpler.<p>So IMO it&#x27;s really about trade-offs.  Does your service need to be C10K?  How much are you paying for the hardware&#x2F;cloud you&#x27;re running it on?  And so on.  Being more efficient will be more costly in developer cycles -- that can be <i>very</i> expensive, and that&#x27;s the reason that research into async-await is ongoing: hopefully it can make C10K dev cheaper.<p>But remember, rewrites cost even more than doing it right the first time.</div><br/></div></div><div id="42179512" class="c"><input type="checkbox" id="c-42179512" checked=""/><div class="controls bullet"><span class="by">RantyDave</span><span>|</span><a href="#42219409">prev</a><span>|</span><a href="#42172003">next</a><span>|</span><label class="collapse" for="c-42179512">[-]</label><label class="expand" for="c-42179512">[4 more]</label></div><br/><div class="children"><div class="content">Almost as an aside the article makes an interesting point: memory accesses can block. Presumably if it blocks because it&#x27;s accessing a piece of hardware the operating system schedules another thread on that core ... but what if it blocks on a &#x27;normal&#x27; memory access? Does it stall the core entirely? Can &#x27;hyperthreading&#x27; briefly run another thread? Does out of order execution make it suddenly not a problem? Surely it doesn&#x27;t go all the way down to the OS?</div><br/><div id="42219050" class="c"><input type="checkbox" id="c-42219050" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#42179512">parent</a><span>|</span><a href="#42181450">next</a><span>|</span><label class="collapse" for="c-42219050">[-]</label><label class="expand" for="c-42219050">[1 more]</label></div><br/><div class="children"><div class="content">&gt; what if it blocks on a &#x27;normal&#x27; memory access?<p>If the CPU gotta wait for memory it&#x27;s gotta wait, and so it just won&#x27;t make progress. Though we typically say that the CPU has stalled.<p>How long depends on if it&#x27;s found in one of the caches, they&#x27;re progressively slower, or main memory.<p>All the fancy techniques like out of order execution, speculative execution and hyperthreads are mainly there to trigger memory reads as soon as possible to reduce how long it is stalled.<p>Some nice detailed SE answer here[1] with some details.<p>[1]: <a href="https:&#x2F;&#x2F;electronics.stackexchange.com&#x2F;a&#x2F;622912" rel="nofollow">https:&#x2F;&#x2F;electronics.stackexchange.com&#x2F;a&#x2F;622912</a></div><br/></div></div><div id="42181450" class="c"><input type="checkbox" id="c-42181450" checked=""/><div class="controls bullet"><span class="by">the_mitsuhiko</span><span>|</span><a href="#42179512">parent</a><span>|</span><a href="#42219050">prev</a><span>|</span><a href="#42218773">next</a><span>|</span><label class="collapse" for="c-42181450">[-]</label><label class="expand" for="c-42181450">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but what if it blocks on a &#x27;normal&#x27; memory access? Does it stall the core entirely?<p>You won&#x27;t be able to suspend a virtual thread, so that OS thread is going to be blocked no matter what.  As far as kernel threads are concerned I think in practice when a page fault happens the kernel yields and lets another thread take over.</div><br/></div></div><div id="42218773" class="c"><input type="checkbox" id="c-42218773" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#42179512">parent</a><span>|</span><a href="#42181450">prev</a><span>|</span><a href="#42172003">next</a><span>|</span><label class="collapse" for="c-42218773">[-]</label><label class="expand" for="c-42218773">[1 more]</label></div><br/><div class="children"><div class="content">Hyperthreading is a feature where a single core can process two unrelated instruction streams (i.e. two threads) which is useful for software that executes few instructions per cycle.</div><br/></div></div></div></div><div id="42172003" class="c"><input type="checkbox" id="c-42172003" checked=""/><div class="controls bullet"><span class="by">NeutralForest</span><span>|</span><a href="#42179512">prev</a><span>|</span><a href="#42185372">next</a><span>|</span><label class="collapse" for="c-42172003">[-]</label><label class="expand" for="c-42172003">[5 more]</label></div><br/><div class="children"><div class="content">I thought that was interesting and I definitely get the frustration in some aspect. I&#x27;m mostly familiar with Python and the function &quot;coloring&quot; issue is so annoying as it forces you to have two APIs depending on async or not (look at SQLAlchemy for example). The ergonomics are bad in general and I don&#x27;t really like having to deal with, for example, awaiting for a result that will be needed in a sync function.<p>That being said, some alternatives were mentioned (structured concurrency à la Go) but I&#x27;d like to hear about people in BEAM land (Elixir) and what they think about it. Though I understand that for system languages, handling concurrency through a VM is not an option.</div><br/><div id="42172131" class="c"><input type="checkbox" id="c-42172131" checked=""/><div class="controls bullet"><span class="by">the_mitsuhiko</span><span>|</span><a href="#42172003">parent</a><span>|</span><a href="#42218719">next</a><span>|</span><label class="collapse" for="c-42172131">[-]</label><label class="expand" for="c-42172131">[2 more]</label></div><br/><div class="children"><div class="content">&gt; structured concurrency à la Go<p>Go does not have structured concurrency.  Goroutines as far as I know don&#x27;t have much of a relationship with each other at all.</div><br/><div id="42172144" class="c"><input type="checkbox" id="c-42172144" checked=""/><div class="controls bullet"><span class="by">NeutralForest</span><span>|</span><a href="#42172003">root</a><span>|</span><a href="#42172131">parent</a><span>|</span><a href="#42218719">next</a><span>|</span><label class="collapse" for="c-42172144">[-]</label><label class="expand" for="c-42172144">[1 more]</label></div><br/><div class="children"><div class="content">My bad, thanks for the correction.</div><br/></div></div></div></div><div id="42218719" class="c"><input type="checkbox" id="c-42218719" checked=""/><div class="controls bullet"><span class="by">toast0</span><span>|</span><a href="#42172003">parent</a><span>|</span><a href="#42172131">prev</a><span>|</span><a href="#42179417">next</a><span>|</span><label class="collapse" for="c-42218719">[-]</label><label class="expand" for="c-42218719">[1 more]</label></div><br/><div class="children"><div class="content">Sorry, I kind of spaced on reading the article, but from BEAM land, everything is built around concurrent processes with asynchronous messaging.<p>You can send a message to something else and wait for the response immediately if you want to write in a more blocking style. And you can write a function that does bot the sending a message and the waiting, so you don&#x27;t really need to think about it if you don&#x27;t want to. All I&#x2F;O pretty much feels the same way, although you get into back pressure with some I&#x2F;O where if there&#x27;s a queue you can opt to fail immediately or block your process until the send fits in the queue.<p>The underlying reality is that your processes don&#x27;t actually block, BEAM processes are essentialy green threads that are executed by a scheduler (which is an OS thread), so blocking things become yields, <i>and</i> the VM also checks if it should yield at every function call. BEAM is built around functional languages, so it lacks loops and looping is handled by recursive function calls, so a process <i>must</i> make a function call in a finite amount of code, and so BEAM&#x27;s green threading is effectively pre-emptive.<p>The end result of all this is you can spawn as many processes as you like (i&#x27;ve operated systems with one process per client connection, and millions of client connections per node). And you can write most of your code like normal imperitive blocking code. Sometimes you do want to separate out sending messages and receiving responses, and you can easily do that too. This is way nicer than languages with async&#x2F;await, IMHO; there&#x27;s no trickyness where calling a blocking function from a async context breaks scheduling, and calling an async function from a non-async context may not be possible... You do still have the possibility of a function blocking when you didn&#x27;t expect it to, but it will only block the process that called it and transitively, those processes that are waiting for messages from the now blocked process.<p>Java&#x27;s Project Loom seems like it will get to a pretty similar place, eventually. But I&#x27;ve seen articles about some hurdles on the way; there&#x27;s some things that still actually block a thread rather than being (magically) changed to yielding.<p>Again, IMHO, people didn&#x27;t build async&#x2F;await because it is good. They built it because threads were unavailable (Javascript) or to work around the inability to run as many threads as would make the code simple. If you could spawn a million OS threads without worrying about resource use, only constrained languages would have async&#x2F;await. But OS threads are too heavy to spawn so many, and too heavy to regularly spawn and let die for ephemeral tasks.</div><br/></div></div><div id="42179417" class="c"><input type="checkbox" id="c-42179417" checked=""/><div class="controls bullet"><span class="by">lbrindze</span><span>|</span><a href="#42172003">parent</a><span>|</span><a href="#42218719">prev</a><span>|</span><a href="#42185372">next</a><span>|</span><label class="collapse" for="c-42179417">[-]</label><label class="expand" for="c-42179417">[1 more]</label></div><br/><div class="children"><div class="content">BEAM very much falls into the same camp as the author&#x27;s description of Scratch does at the beginning of the article. You have a lot more granular control than Scratch, of course, but it also loosely follows the actor model</div><br/></div></div></div></div><div id="42185372" class="c"><input type="checkbox" id="c-42185372" checked=""/><div class="controls bullet"><span class="by">andrewstuart</span><span>|</span><a href="#42172003">prev</a><span>|</span><a href="#42180578">next</a><span>|</span><label class="collapse" for="c-42185372">[-]</label><label class="expand" for="c-42185372">[3 more]</label></div><br/><div class="children"><div class="content">Feels academic because despite the concerns raised, I only experience async&#x2F;await as a good thing in real world.</div><br/><div id="42193696" class="c"><input type="checkbox" id="c-42193696" checked=""/><div class="controls bullet"><span class="by">BugsJustFindMe</span><span>|</span><a href="#42185372">parent</a><span>|</span><a href="#42180578">next</a><span>|</span><label class="collapse" for="c-42193696">[-]</label><label class="expand" for="c-42193696">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t. Now what?
I agree with the author, especially in Python. The core Python developers so lost their minds fleeing from the GIL that they forgot historical lessons about how much more ergonomic preemptive multitasking is vs cooperative.</div><br/><div id="42218762" class="c"><input type="checkbox" id="c-42218762" checked=""/><div class="controls bullet"><span class="by">smitty1e</span><span>|</span><a href="#42185372">root</a><span>|</span><a href="#42193696">parent</a><span>|</span><a href="#42180578">next</a><span>|</span><label class="collapse" for="c-42218762">[-]</label><label class="expand" for="c-42218762">[1 more]</label></div><br/><div class="children"><div class="content">&gt; so lost their minds fleeing from the GIL that they forgot historical lessons<p>I just don&#x27;t agree. `async def` gets the fact that we&#x27;ve departed Kansas, good Toto, right out front.<p>Async moves the coder a step in the direction of the operating system itself. The juice is not worth the squeeze unless the project bears fruit.<p>I hardly do enough networky stuff to make this facility useful to me, but I&#x27;m grateful to the hours poured into making it part of Python.<p>Contra the author of The Famous Article, threads seem gnarlier still, and I would likely architect out any async parts of a system into another service and talk to it over a port.</div><br/></div></div></div></div></div></div><div id="42180578" class="c"><input type="checkbox" id="c-42180578" checked=""/><div class="controls bullet"><span class="by">unscaled</span><span>|</span><a href="#42185372">prev</a><span>|</span><label class="collapse" for="c-42180578">[-]</label><label class="expand" for="c-42180578">[3 more]</label></div><br/><div class="children"><div class="content">I think most of the arguments in this essay rely on this single premise: &quot;The second thing I want you to take away is that imperative languages are not inferior to functional ones.&quot;<p>There is an implied assumption that async&#x2F;await is a &quot;functional feature&quot; that was pushed into a bunch of innocent imperative languages and polluted them. But there is one giant problem with this assumption: async&#x2F;await is not a functional feature. If anything, it&#x27;s the epitome of an imperative flow-control feature.<p>There are many kinds of functional languages out there, but I think the best common denominator for a primarily functional language nowadays is exactly this: in functional languages control flow structures are first class citizens, and they can be customized by the programmer. In fact, most control flow structures are basically just functions, and the one that aren&#x27;t (e.g. pattern matching in ML-like languages and monadic comprehensions in Haskell-inspired languages) are extremely generic, and their behavior depends on the types you feed into them. There are other emphasis points that you see in particular families of languages such as pattern matching, strict data immutability or lazy computation — but none of these is a core functional concept.<p>The interesting point I want to point out is that no primarily functional language that I know actually has async&#x2F;await. Some of them have monads and these monads could be used for something like async&#x2F;await but that&#x27;s not a very common use, and monad comprehensions can be used for other things. For instance, you could use do expressions in Haskell (or for expressions in Scala) to operate on multiple lists at once. The same behavior is possible with nested for-loops in virtually every modern imperative language, but nobody has blamed Algol for &quot;polluting&quot; the purity of our Fortran gotos and arithmetic ifs with this &quot;fancy functional garbage monad from damned ivory tower Academia&quot;. That would be absurd, not only because no programming language with monadic comprehensions existed back then, but also because for loops are a very syntax for a very specific thing that can be done with monadic expression. They turn a very abstract functional concept into a highly specific — and highly <i>imperative</i> — feature. The same is true for await. It&#x27;s an imperative construct that instructs the runtime to suspend (or the compiler to turn the current function into a state machine).<p>So no, async&#x2F;await does not have anything to do with functional-language envy and is, in fact, a feature that is quite antithetical to functional programming. If there is any theoretical paradigm behind async&#x2F;await (vs. just using green threads), it&#x27;s strong typing and especially the idea of representing effects by types. This is somewhat close to fully-fledged Effect Systems (in languages such as a Koka), but not as powerful. The general idea is that certain functions behave in a way that is &quot;infective&quot; — in other words, if foo() calls bar() which in-turn calls doStuff(), it might be impacted by some side-effect of doStuff(). In order to prevent unpleasant surprises, we want to mark this thing that doStuff does in the function signature (either using an extra argument, a return type wrapper or just an extra modifier like &quot;async&quot;).<p>In a pure language like Haskell, everything from I&#x2F;O to mutable memory requires specifying an effect and this is usually done through monadic return types. But even the very first version of Java (Ron Pressler&#x27;s ideal untarnished &quot;imperative&quot; language) has effects (or &quot;colors&quot;) which still remain in the language: checked exceptions. They are just as infective as async I&#x2F;O. If you don&#x27;t handle exceptions in place, a function marked with &quot;throws IOException&quot; (basically almost any function that deals with I&#x2F;O) can only be called by another function marked with &quot;throws IOException&quot;. What&#x27;s worse, unlike JavaScript which only has two colors (async and non-async), Java has an infinite number colors!<p>The description above sounds horrible, but it&#x27;s not. Checked exceptions are widely believed to be a mistake[1], but they don&#x27;t bother Java developers enough to make the language unusable. You can always just wrap them with another exception and rethrow. The ergonomics could have been made slightly better, but they&#x27;re decent enough. But the same can be said for async&#x2F;await. If you take a language with a similar feature that is close to Java (C# or Kotlin), you&#x27;ll see the asynchronous functions can still run as blocking code from inside synchronous functions, while synchronous functions can be scheduled on another thread from a synchronous function. The ergonomics for doing that are not any harder than wrapping exceptions.<p>In addition to that, the advantages of marking a function that runs asynchronous I&#x2F;O (just like marking a function that throws an exception) are obvious, even if the move itself is controversial. These functions generally involve potentially slow network I&#x2F;O and you don&#x27;t want to call them by mistake. If you think that never happens, here is the standard Java API for constructing an InetAddress object from a string representing an IPv4 or IPv6 address: InetAddress.getByName()[2]. Unfortunately, if your IP address is invalid, this function may block while trying to resolve it as a domain name. That&#x27;s plain bad API design, but APIs that can block in surprising ways are abundant, so you cannot argue that async&#x2F;await doesn&#x27;t introduce additional safety.<p>But let&#x27;s face it — in most cases choosing async&#x2F;await vs. green threads for an imperative language is a matter of getting the right trade-off. Async&#x2F;Await schedulers are easier to implement (they don&#x27;t need to deal with segmented&#x2F;relocatable&#x2F;growable stacks) and do not require runtime support. Async&#x2F;await also exhibits more efficient memory usage, and arguably better performance in scenarios that do not involve a long call-graph of async functions. Async&#x2F;await schedulers also integrates more nicely with blocking native code that is used as a library (i.e. C&#x2F;C++, Objective C or Rust code). With green threads, you just cannot run this code directly from the virtual thread and if the code is blocking, your life becomes even harder (especially if you don&#x27;t have access to kernel threads). Even with full control of the runtime, you&#x27;d usually end up with a certain amount of overhead for native calls[3].<p>Considering these trade-offs, async&#x2F;await is perfect in scenarios like below:<p>1. JavaScript had multiple implementations. Not only were most of them single-threaded, they would also need a major overhaul to support virtual threads even if a thread API was specified.<p>2. Rust actually tried green threads and abandoned them. The performance was abysmal for a language that seeks zero-cost abstraction and the system programming requirements for Rust made them a deal breaker even if this wasn&#x27;t the case. Rust just had to support pluggable runtimes and mandating dynamic stacks just won&#x27;t work inside the Kernel or in soft real-time systems.<p>3. Swift had to interoperate with a large amount of Objective C called that was already using callbacks for asynchronous I&#x2F;O (this is what they had). In addition, it is not garbage-collected language, and it still needed to call a lot of C and Objective C APIs, even if that was wrapped by nice Swift classes.<p>4. C# already had a Promise-like Task mechanism that evolved around wrapping native windows asynchronous I&#x2F;O. If .Net was redesigned from scratch nowadays, they could have very well went with green threads, but the way .Net developed, this would have just introduced a lot of compatibility issues for almost no gains.<p>5. Python had the GIL, as the article already mentioned. But even with patching runtime I&#x2F;O functions (like greenlet — or more accurately, gevent[4] — did), there were many third party libraries relying on native code. Python just went with the more compatible approach.<p>6. Java did not have any established standard for asynchronous I&#x2F;O. CompletableFuture was introuced in Java 8, but it wasn&#x27;t as widely adopted (especially in the standard library) as the C# Task was. Java also had gauranteed full control of the runtime (unlike JavaScript and Rust), it was garbage collected (unlike Rust and Swift) and it had less reliance on native code than Swift, Pre-.NET Core C# or Python. On the other hand, Java had a lot of crucial blocking APIs that haven&#x27;t been updated to use CompletableFuture, like JDBC and Servlet (Async Servlets were cumbersome and never caught on). Introducing async&#x2F;await to Java would mean having to rewrite or significantly refactor all existing frameworks in order to support them. That was not a very palatable choice, so again, Java did the correct thing and went with virtual threads.<p>If you look at all of these use cases, you&#x27;d see all of these languages seem to have made the right pragmatic choice. Unless you are designing a new language from scratch (and that language is garbage collected and doesn&#x27;t need to be compatible with another language or deal with a lot of existing native code), you can go with the ideological argument of &quot;I want my function to be colorless&quot; (or, inversely, you can go with the ideological argument of &quot;I want all suspending functions to be marked explicitly&quot;). In all other cases, pragmatism should win.<p>---<p>[1] Although it mostly comes to bad composability — checked result types work very well in Rust.<p>[2] <a href="https:&#x2F;&#x2F;docs.oracle.com&#x2F;en&#x2F;java&#x2F;javase&#x2F;17&#x2F;docs&#x2F;api&#x2F;java.base&#x2F;java&#x2F;net&#x2F;InetAddress.html#getByName(java.lang.String)" rel="nofollow">https:&#x2F;&#x2F;docs.oracle.com&#x2F;en&#x2F;java&#x2F;javase&#x2F;17&#x2F;docs&#x2F;api&#x2F;java.base...</a><p>[3] See the article blelow for the overhead in Go. Keep in mind that the Go team has put a lot of effort into optimizing Cgo calls and reducing this overhead, but they still cannot eliminate it entirely. <a href="https:&#x2F;&#x2F;shane.ai&#x2F;posts&#x2F;cgo-performance-in-go1.21&#x2F;" rel="nofollow">https:&#x2F;&#x2F;shane.ai&#x2F;posts&#x2F;cgo-performance-in-go1.21&#x2F;</a><p>[4] <a href="https:&#x2F;&#x2F;www.gevent.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.gevent.org&#x2F;</a></div><br/><div id="42203891" class="c"><input type="checkbox" id="c-42203891" checked=""/><div class="controls bullet"><span class="by">solidninja</span><span>|</span><a href="#42180578">parent</a><span>|</span><a href="#42181574">next</a><span>|</span><label class="collapse" for="c-42203891">[-]</label><label class="expand" for="c-42203891">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for writing this - it is more detailed that I could come up with!<p>I would like to add that I feel like functional approaches are more the &quot;future&quot; of programming than trying to iterate over imperative ones to make them as &quot;nice&quot; to use. So I don&#x27;t really see the big deal of trying to add-on features to existing languages when you can adopt new ones (or experiment with existing ones e.g. <a href="https:&#x2F;&#x2F;github.com&#x2F;getkyo&#x2F;kyo">https:&#x2F;&#x2F;github.com&#x2F;getkyo&#x2F;kyo</a> for a new take on effects in Scala).</div><br/></div></div><div id="42181574" class="c"><input type="checkbox" id="c-42181574" checked=""/><div class="controls bullet"><span class="by">the_mitsuhiko</span><span>|</span><a href="#42180578">parent</a><span>|</span><a href="#42203891">prev</a><span>|</span><label class="collapse" for="c-42181574">[-]</label><label class="expand" for="c-42181574">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There is an implied assumption that async&#x2F;await is a &quot;functional feature&quot; that was pushed into a bunch of innocent imperative languages and polluted them. But there is one giant problem with this assumption: async&#x2F;await is not a functional feature. If anything, it&#x27;s the epitome of an imperative flow-control feature.<p>async&#x2F;await comes from C# and C# got this as an &quot;appoximation&quot; of what was possible with F#.  You can go back to 2011 where there are a series of videos on Channel 9 by Anders Hejlsberg where he goes into that.<p>That said, I don&#x27;t think my post relies on the premise that this is a fight about imperative to functional programming.  If anything the core premise is that there is value in being able to yield anywhere, and not just at await points.<p>&gt; If you look at all of these use cases, you&#x27;d see all of these languages seem to have made the right pragmatic choice.<p>Potentially, who am I to judge.  However that choice was made at a certain point in time and the consequences are here to stay.  Other than in JavaScript where it&#x27;s self evident that this is a great improvement over promise chaining (sans the challenge of unresolved promises), I&#x27;m not sure the benefits are all that evident in all languages.  I do a fair amount of async programming in JavaScript, Python and Rust and the interplay between threads and async code is very complex and hard to understand, and a lot of the challenges on a day to day would really feel like they are better solved in the scheduler and virtual threads.<p>&gt; Unless you are designing a new language from scratch (and that language is garbage collected and doesn&#x27;t need to be compatible with another language or deal with a lot of existing native code), you can go with the ideological argument of &quot;I want my function to be colorless&quot; (or, inversely, you can go with the ideological argument of &quot;I want all suspending functions to be marked explicitly&quot;). In all other cases, pragmatism should win.<p>I will make the counter argument: even in some languages with async&#x2F;await like Python, you could very pragmatically implement virtual threads.  At the end of the day in Python for instance, async&#x2F;await is already implemented on top of coroutines anyways.  The &quot;only&quot; thing that this would require, is to come to terms with the idea that the event loop&#x2F;reactor would have to move closer to the core of the language.  I think on a long enough time horizon Python would actually start moving towards that, particularly now that the GIL is going and that the language is quite suffering from the complexities of having two entirely incompatible ecosystems in one place (two sets of future systems, two sets of synchronization directives, two independent ways to spawn real threads etc.).</div><br/></div></div></div></div></div></div></div></div></div></body></html>