<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1716886857253" as="style"/><link rel="stylesheet" href="styles.css?v=1716886857253"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2405.17399">Transformers Can Do Arithmetic with the Right Embeddings</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>byt3h3ad</span> | <span>16 comments</span></div><br/><div><div id="40498257" class="c"><input type="checkbox" id="c-40498257" checked=""/><div class="controls bullet"><span class="by">msoad</span><span>|</span><a href="#40498149">next</a><span>|</span><label class="collapse" for="c-40498257">[-]</label><label class="expand" for="c-40498257">[4 more]</label></div><br/><div class="children"><div class="content">It seems like a hack to be honest. Problem at hand is not to make transformers do addition of 100 digit numbers. Problem is the current systems can’t reason about things, math included.<p>Optimizing for a certain use case is not gonna take us where we wanna be. We want to have a system that can learn to reason.</div><br/><div id="40498401" class="c"><input type="checkbox" id="c-40498401" checked=""/><div class="controls bullet"><span class="by">josehackernews</span><span>|</span><a href="#40498257">parent</a><span>|</span><a href="#40498149">next</a><span>|</span><label class="collapse" for="c-40498401">[-]</label><label class="expand" for="c-40498401">[3 more]</label></div><br/><div class="children"><div class="content">how do you argue that these models are not able to reason?<p>deductive reasoning is just drawing specific conclusion from general patterns. something I would argue this models can do (of course not always and are still pretty bad in most cases)<p>the point i’m trying to make is that sometimes reasoning is overrated and put on the top of the cognitive ladder, sometimes I have seen it compared to self-awareness or stuff like that. I know that you are not probably saying it in this way, just wanted to let it out.<p>I believe there is fundamental work still to be done, maybe models that are able to draw patterns comparing experience, but this kind of work can be useful as make us reflect in every step of what these models do, and how much the internal representation learned can be optimized</div><br/><div id="40498482" class="c"><input type="checkbox" id="c-40498482" checked=""/><div class="controls bullet"><span class="by">msoad</span><span>|</span><a href="#40498257">root</a><span>|</span><a href="#40498401">parent</a><span>|</span><a href="#40498416">next</a><span>|</span><label class="collapse" for="c-40498482">[-]</label><label class="expand" for="c-40498482">[1 more]</label></div><br/><div class="children"><div class="content">&gt; how do you argue that these models are not able to reason?<p>I don&#x27;t make this argument. Benchmarks like CLUTRR[1] show how poorly LLMs do in reasoning.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;clutrr">https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;clutrr</a></div><br/></div></div><div id="40498416" class="c"><input type="checkbox" id="c-40498416" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#40498257">root</a><span>|</span><a href="#40498401">parent</a><span>|</span><a href="#40498482">prev</a><span>|</span><a href="#40498149">next</a><span>|</span><label class="collapse" for="c-40498416">[-]</label><label class="expand" for="c-40498416">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; deductive reasoning is just drawing specific conclusion from general patterns.<p>This is according to whom, please?</div><br/></div></div></div></div></div></div><div id="40498149" class="c"><input type="checkbox" id="c-40498149" checked=""/><div class="controls bullet"><span class="by">infogulch</span><span>|</span><a href="#40498257">prev</a><span>|</span><a href="#40498464">next</a><span>|</span><label class="collapse" for="c-40498149">[-]</label><label class="expand" for="c-40498149">[2 more]</label></div><br/><div class="children"><div class="content">The other day I was wondering if LLMs are bad at at maths because they don&#x27;t have readily apparent access to the concept of &quot;columns&quot;. Apparently the answer is yes.<p>Vertical alignment across lines is pretty important for humans to learn operations on digits, but the way we encode lines with a \n separator doesn&#x27;t really help. In a recent codebullet video gpt really struggled with any kind of vertical alignment task. I wonder if it would do better on a fixed 80 column width...</div><br/><div id="40498489" class="c"><input type="checkbox" id="c-40498489" checked=""/><div class="controls bullet"><span class="by">Terr_</span><span>|</span><a href="#40498149">parent</a><span>|</span><a href="#40498464">next</a><span>|</span><label class="collapse" for="c-40498489">[-]</label><label class="expand" for="c-40498489">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t it more that they don&#x27;t have ready access to the much-more-fundamental concept of decimal numbers?<p>My understanding was that they tokenized them into chunks and tried to learn associations between the chunks, the same as if one was breaking apart English words.<p>So &quot;2+2=4&quot; isn&#x27;t being treated that differently from &quot;all&#x27;s well that ends well.&quot; This might lead to a kind of Benny&#x27;s Rules [0] situation, where sufficient brute-force can make a collection of overfitted non-arithmetic rules <i>appear</i> to work.<p>[0] <a href="https:&#x2F;&#x2F;blog.mathed.net&#x2F;2011&#x2F;07&#x2F;rysk-erlwangers-bennys-conception-of.html?m=1" rel="nofollow">https:&#x2F;&#x2F;blog.mathed.net&#x2F;2011&#x2F;07&#x2F;rysk-erlwangers-bennys-conce...</a></div><br/></div></div></div></div><div id="40498464" class="c"><input type="checkbox" id="c-40498464" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#40498149">prev</a><span>|</span><a href="#40498251">next</a><span>|</span><label class="collapse" for="c-40498464">[-]</label><label class="expand" for="c-40498464">[5 more]</label></div><br/><div class="children"><div class="content">What is the point of this work? 99% on 100-digit arithmetic means there&#x27;s a 0% chance anyone will ever use a Transformer as an ALU or anything of the kind. We already know how to hard-code a (literally) infinitely more accurate addition machine.<p>And not only addition: all four arithmetic operations. The technique proposed in the article -imposing a strong inductive bias for addition- kiind of works for multiplication, but not for subtraction or division (clearly; I can&#x27;t even find the words in the paper). As a practical way to build a machine to do arithmetic this is out of the question.<p>We&#x27;ve known how to mechanise arithmetic since the 1850&#x27;s with Blaize Pascal and his Pascaline. What is the point in demonstrating it&#x27;s possible to reinvent a broken, partial, buggy version of an arithmetic machine if one tries really hard and shoehorns the necessary patterns in a neural net? We&#x27;ve known <i>that</i> for a long time, too (every proof that a neural net can simulate this or that Turing machine if you design the network diagram and set the weights by hand, ever).<p>So <i>what is the point</i> of this? Transformers are supposed to be the &quot;sparks of AGI&quot; and they can almost do arithmetic if we try very hard to shove it down their heads? Who cares?</div><br/><div id="40498531" class="c"><input type="checkbox" id="c-40498531" checked=""/><div class="controls bullet"><span class="by">zarzavat</span><span>|</span><a href="#40498464">parent</a><span>|</span><a href="#40498560">next</a><span>|</span><label class="collapse" for="c-40498531">[-]</label><label class="expand" for="c-40498531">[1 more]</label></div><br/><div class="children"><div class="content">It’s not about arithmetic but about embeddings. The positional embeddings used in transformers are rather simplistic. If they can add this one new capability to transformers by using different embeddings then maybe there are other capabilities that are within reach.</div><br/></div></div><div id="40498560" class="c"><input type="checkbox" id="c-40498560" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#40498464">parent</a><span>|</span><a href="#40498531">prev</a><span>|</span><a href="#40498513">next</a><span>|</span><label class="collapse" for="c-40498560">[-]</label><label class="expand" for="c-40498560">[1 more]</label></div><br/><div class="children"><div class="content">I think there is a good reason to find low-hanging fruits that pay dividends on these types of tasks, not because solving addition with a transformer is a good idea, but because it could improve performance in other parts of the network. Maybe there are other subsequences that could be annotated in this way? Per paragraph, tokens per word, who knows.<p>Obviously, the &quot;best&quot; way to do addition on a computer is by doing it exactly.</div><br/></div></div><div id="40498513" class="c"><input type="checkbox" id="c-40498513" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#40498464">parent</a><span>|</span><a href="#40498560">prev</a><span>|</span><a href="#40498586">next</a><span>|</span><label class="collapse" for="c-40498513">[-]</label><label class="expand" for="c-40498513">[1 more]</label></div><br/><div class="children"><div class="content">There are two sides to this that jump out<p>One is that research into what the limits of the architecture are is useful. Maths has a nice property of being very easy to verify and you can construct logical processes with it. It&#x27;s a useful testbed.<p>Second is there are a lot more places that understanding how to do arithmetic help, outside of just doing sums on their own.</div><br/></div></div><div id="40498586" class="c"><input type="checkbox" id="c-40498586" checked=""/><div class="controls bullet"><span class="by">Xcelerate</span><span>|</span><a href="#40498464">parent</a><span>|</span><a href="#40498513">prev</a><span>|</span><a href="#40498251">next</a><span>|</span><label class="collapse" for="c-40498586">[-]</label><label class="expand" for="c-40498586">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What is the point of this work?<p>Seriously? They say it right in the introduction. The goal is to learn how to infer algorithmic processes directly from data. Much like how MNIST was used in the early days of NNs, you have to start with small toy problems that are representative of the problem domain. Once you have success with that, you can scale up problem complexity.<p>General algorithmic capability is one of the key traits that we think AGI should have, and it’s currently missing. If you have a better approach for getting there quicker than everyone else in the field, please share it.<p>I would even appreciate seeing more papers on approaches that <i>didn’t</i> work very well so it saves other researchers from going in the wrong direction. That alone would be enough justification for publishing an article.</div><br/></div></div></div></div><div id="40498251" class="c"><input type="checkbox" id="c-40498251" checked=""/><div class="controls bullet"><span class="by">michaelnny</span><span>|</span><a href="#40498464">prev</a><span>|</span><a href="#40498594">next</a><span>|</span><label class="collapse" for="c-40498251">[-]</label><label class="expand" for="c-40498251">[3 more]</label></div><br/><div class="children"><div class="content">I think the main problem is the way we turn the raw mathematics symbols or equations into tokens, and these suboptimal tokenization may decreases the performance</div><br/><div id="40498732" class="c"><input type="checkbox" id="c-40498732" checked=""/><div class="controls bullet"><span class="by">ynik</span><span>|</span><a href="#40498251">parent</a><span>|</span><a href="#40498682">next</a><span>|</span><label class="collapse" for="c-40498732">[-]</label><label class="expand" for="c-40498732">[1 more]</label></div><br/><div class="children"><div class="content">I thinks that&#x27;s far from the only problem.
To me the most obvious problem is that we use right-to-left numbers (think about the order you&#x27;re writing digits when doing long addition) in a left-to-right language.
Without a special number-flipping step; the transformer is forced to produce the output token-by-token, i.e. from left-to-right. Without the ability to store additional internal state, this turns addition into an O(N²) problem purely due to the suboptimal output ordering!</div><br/></div></div><div id="40498682" class="c"><input type="checkbox" id="c-40498682" checked=""/><div class="controls bullet"><span class="by">threatofrain</span><span>|</span><a href="#40498251">parent</a><span>|</span><a href="#40498732">prev</a><span>|</span><a href="#40498594">next</a><span>|</span><label class="collapse" for="c-40498682">[-]</label><label class="expand" for="c-40498682">[1 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t stop decent code output for many computer languages.</div><br/></div></div></div></div><div id="40498594" class="c"><input type="checkbox" id="c-40498594" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#40498251">prev</a><span>|</span><label class="collapse" for="c-40498594">[-]</label><label class="expand" for="c-40498594">[1 more]</label></div><br/><div class="children"><div class="content">Something I&#x27;ve been thinking about is how the Minds -- the super-human AI hyper-computers that fly the ships in the Culture series of novels are described. The image built up in my head[1] is that they&#x27;re <i>hybrids</i> blending neural networks and regular compute substrates. They can calculate, simulate, and reason in combination.<p>There have been crude attempts at this already, hooking in Mathematica and Python into ChatGPT. I say crude, because these add-ons are controlled via output tokens.<p>What I would like to see is a GPT-style AI that also has <i>compute blocks</i>, not just transformer blocks. I don&#x27;t mean compute in the sense of &quot;matrix multiply for weights and biases&quot;, but literally an ALU-style block of basic maths operations available for use by the neurons.<p>One thought that I had was that this could be via activations that have both a floating-point activation value <i>and</i> &quot;baggage&quot; such as a numerical value from the input. Like a token in a traditional parser, that can represent a constant string or an integer with its decoded value.<p>The newer, truly multi-modal models gave me a related idea: Just like how they can have &quot;image&quot; tokens and &quot;audio&quot; tokens, I wonder if they could be given &quot;numeric data&quot; tokens or &quot;math symbol&quot; tokens. Not in the same way that they&#x27;re given mixed-language text tokens, but dedicated tokens that are fed into both the transformer blocks <i>and also</i> into ALU blocks.<p>Just an idle thought...<p>[1] Every reader reads into a story something unique, which may or may not align with what the author intended. This is my understanding, coloured by my own knowledge, etc, etc...</div><br/></div></div></div></div></div></div></div></body></html>