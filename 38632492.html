<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1702544459156" as="style"/><link rel="stylesheet" href="styles.css?v=1702544459156"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://smerf-3d.github.io/">SMERF: Streamable Memory Efficient Radiance Fields</a> <span class="domain">(<a href="https://smerf-3d.github.io">smerf-3d.github.io</a>)</span></div><div class="subtext"><span>duckworthd</span> | <span>105 comments</span></div><br/><div><div id="38637653" class="c"><input type="checkbox" id="c-38637653" checked=""/><div class="controls bullet"><span class="by">nojvek</span><span>|</span><a href="#38633406">next</a><span>|</span><label class="collapse" for="c-38637653">[-]</label><label class="expand" for="c-38637653">[2 more]</label></div><br/><div class="children"><div class="content">Holy mother of god. Wow!<p>Either matterport takes and runs with this or this is a startup waiting to disrupt Realestate.<p>I can’t believe how smooth this ran on my smartphone.<p>Feedback: if there was a mode to use the phone compass and gyro for navigation, it’d feel natural. Felt weird to navigate with fingers and figure how to move in xyz dimension.<p>As others have said, VR mode would be epic.</div><br/><div id="38638604" class="c"><input type="checkbox" id="c-38638604" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38637653">parent</a><span>|</span><a href="#38633406">next</a><span>|</span><label class="collapse" for="c-38638604">[-]</label><label class="expand" for="c-38638604">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the feedback!<p>I agree, we could do better with the movement UX. A challenge for another day.</div><br/></div></div></div></div><div id="38633406" class="c"><input type="checkbox" id="c-38633406" checked=""/><div class="controls bullet"><span class="by">barrkel</span><span>|</span><a href="#38637653">prev</a><span>|</span><a href="#38633486">next</a><span>|</span><label class="collapse" for="c-38633406">[-]</label><label class="expand" for="c-38633406">[13 more]</label></div><br/><div class="children"><div class="content">The mirror on the wall of the bathroom in the Berlin location looks through to the kitchen in the next room. I guess the depth gauging algorithm uses parallax, and mirrors confuse it, seeming like windows. The kitchen has a blob of blurriness as the rear of the mirror intrudes into kitchen, but you can see through the blurriness to either room.<p>The effect is a bit spooky. I felt like a ghost going through walls.</div><br/><div id="38633485" class="c"><input type="checkbox" id="c-38633485" checked=""/><div class="controls bullet"><span class="by">nightpool</span><span>|</span><a href="#38633406">parent</a><span>|</span><a href="#38635127">next</a><span>|</span><label class="collapse" for="c-38633485">[-]</label><label class="expand" for="c-38633485">[9 more]</label></div><br/><div class="children"><div class="content">The refigerator in the NYC scene has a very slick specular lighting effect based on the angle you&#x27;re viewing it from, and if you go &quot;into&quot; the fridge you can see it&#x27;s actually generating a whole 3d scene with blurry grey and white colors that turn out to precisely mimic the effects of the light from the windows bouncing off the metal, and you can look &quot;out&quot; from the fridge into the rest of the room. Same as the full-length mirror in the bedroom in the same scene—there&#x27;s a whole virtual &quot;mirror room&quot; that&#x27;s been built out behind the mirror to give the illusion of depth as you look through it. Very cool and unique consequence of the technology</div><br/><div id="38633681" class="c"><input type="checkbox" id="c-38633681" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#38633406">root</a><span>|</span><a href="#38633485">parent</a><span>|</span><a href="#38633819">next</a><span>|</span><label class="collapse" for="c-38633681">[-]</label><label class="expand" for="c-38633681">[3 more]</label></div><br/><div class="children"><div class="content">Wow, thanks for the tip. Fridge reflection world is so cool. Feels like something David Lynch might dream up.<p>A girl is eating her morning cereal. Suddenly she looks apprehensively at the fridge. Camera dollies towards the appliance and seamlessly penetrates the reflective surface, revealing a deep hidden space that exactly matches the reflection. At the dark end of the tunnel, something stirs... A wildly grinning man takes a step forward and screams.</div><br/><div id="38636901" class="c"><input type="checkbox" id="c-38636901" checked=""/><div class="controls bullet"><span class="by">throwaway17_17</span><span>|</span><a href="#38633406">root</a><span>|</span><a href="#38633681">parent</a><span>|</span><a href="#38633819">next</a><span>|</span><label class="collapse" for="c-38636901">[-]</label><label class="expand" for="c-38636901">[2 more]</label></div><br/><div class="children"><div class="content">Would you be offended if I animated that scene? It is really well described?</div><br/><div id="38637357" class="c"><input type="checkbox" id="c-38637357" checked=""/><div class="controls bullet"><span class="by">npace12</span><span>|</span><a href="#38633406">root</a><span>|</span><a href="#38636901">parent</a><span>|</span><a href="#38633819">next</a><span>|</span><label class="collapse" for="c-38637357">[-]</label><label class="expand" for="c-38637357">[1 more]</label></div><br/><div class="children"><div class="content">Please share if you do, that sounded spooky af</div><br/></div></div></div></div></div></div><div id="38633819" class="c"><input type="checkbox" id="c-38633819" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#38633406">root</a><span>|</span><a href="#38633485">parent</a><span>|</span><a href="#38633681">prev</a><span>|</span><a href="#38634321">next</a><span>|</span><label class="collapse" for="c-38633819">[-]</label><label class="expand" for="c-38633819">[1 more]</label></div><br/><div class="children"><div class="content">Oh wow yeah. It&#x27;s interesting because when I look at the fridge my eye maps that to &quot;this is a reflective surface&quot;, which makes sense because that&#x27;s true in the source images, but then it&#x27;s actually rendered as a cavity with appropriate features rendered in 3D space. What&#x27;s a strange feeling is to enter the fridge and then turn around! I just watched Hbomberguy&#x27;s Patreon-only video on the video game Myst, and in Myst the characters are trapped in books. If you choose the wrong path at the end of the game you get trapped in a book, and the view you get trapped in a book looks very similar to the view from inside the NYC fridge!</div><br/></div></div><div id="38634321" class="c"><input type="checkbox" id="c-38634321" checked=""/><div class="controls bullet"><span class="by">chpatrick</span><span>|</span><a href="#38633406">root</a><span>|</span><a href="#38633485">parent</a><span>|</span><a href="#38633819">prev</a><span>|</span><a href="#38633693">next</a><span>|</span><label class="collapse" for="c-38634321">[-]</label><label class="expand" for="c-38634321">[1 more]</label></div><br/><div class="children"><div class="content">This happens with any 3D reconstruction. It&#x27;s because any mirror is indistinguishable from a window into a mirrored room. The tricky thing is if there&#x27;s actually a something behind the mirror as well.</div><br/></div></div><div id="38633693" class="c"><input type="checkbox" id="c-38633693" checked=""/><div class="controls bullet"><span class="by">daemonologist</span><span>|</span><a href="#38633406">root</a><span>|</span><a href="#38633485">parent</a><span>|</span><a href="#38634321">prev</a><span>|</span><a href="#38637236">next</a><span>|</span><label class="collapse" for="c-38633693">[-]</label><label class="expand" for="c-38633693">[1 more]</label></div><br/><div class="children"><div class="content">Neat! Here are some screenshots of the same phenomenon with the TV in Berlin: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;3zAA5K8" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;3zAA5K8</a></div><br/></div></div><div id="38637236" class="c"><input type="checkbox" id="c-38637236" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#38633406">root</a><span>|</span><a href="#38633485">parent</a><span>|</span><a href="#38633693">prev</a><span>|</span><a href="#38633912">next</a><span>|</span><label class="collapse" for="c-38637236">[-]</label><label class="expand" for="c-38637236">[1 more]</label></div><br/><div class="children"><div class="content">Yes!<p>The barely-there reflection on the Berlin TV is also a trip to enter, and observe the room from.</div><br/></div></div><div id="38633912" class="c"><input type="checkbox" id="c-38633912" checked=""/><div class="controls bullet"><span class="by">deltaburnt</span><span>|</span><a href="#38633406">root</a><span>|</span><a href="#38633485">parent</a><span>|</span><a href="#38637236">prev</a><span>|</span><a href="#38635127">next</a><span>|</span><label class="collapse" for="c-38633912">[-]</label><label class="expand" for="c-38633912">[1 more]</label></div><br/><div class="children"><div class="content">Mirror worlds are a pretty common effect you&#x27;ll see in NeRFs. Otherwise you would need a significantly more complex view dependent feature rendered onto a flat surface.</div><br/></div></div></div></div><div id="38635127" class="c"><input type="checkbox" id="c-38635127" checked=""/><div class="controls bullet"><span class="by">rzzzt</span><span>|</span><a href="#38633406">parent</a><span>|</span><a href="#38633485">prev</a><span>|</span><a href="#38635097">next</a><span>|</span><label class="collapse" for="c-38635127">[-]</label><label class="expand" for="c-38635127">[1 more]</label></div><br/><div class="children"><div class="content">You can also get inside the bookcase for the ultimate Matthew McConaughey experience.</div><br/></div></div><div id="38635097" class="c"><input type="checkbox" id="c-38635097" checked=""/><div class="controls bullet"><span class="by">Zetobal</span><span>|</span><a href="#38633406">parent</a><span>|</span><a href="#38635127">prev</a><span>|</span><a href="#38637119">next</a><span>|</span><label class="collapse" for="c-38635097">[-]</label><label class="expand" for="c-38635097">[1 more]</label></div><br/><div class="children"><div class="content">It has exactly the same drawbacks as photogrammetry in regards of highly reflective surfaces.</div><br/></div></div></div></div><div id="38633486" class="c"><input type="checkbox" id="c-38633486" checked=""/><div class="controls bullet"><span class="by">promiseofbeans</span><span>|</span><a href="#38633406">prev</a><span>|</span><a href="#38633516">next</a><span>|</span><label class="collapse" for="c-38633486">[-]</label><label class="expand" for="c-38633486">[4 more]</label></div><br/><div class="children"><div class="content">It runs impressively well on my 2yo s21fe.
It was super impressive how it streamed in more images as I explored the space. The tv reflections in the Berlin demo were super impressive.<p>My one note is that it look a really long time to load all the images - the scene wouldn&#x27;t render until all ~40 initial images loaded. Would it be possible to start partially rendering as the images arrive, or do you need to wait for all of them before you can do the first big render?</div><br/><div id="38634753" class="c"><input type="checkbox" id="c-38634753" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633486">parent</a><span>|</span><a href="#38633516">next</a><span>|</span><label class="collapse" for="c-38634753">[-]</label><label class="expand" for="c-38634753">[3 more]</label></div><br/><div class="children"><div class="content">Pardon our dust: &quot;images&quot; is a bad name for what&#x27;s being loaded. Past versions of this approach (MERF) stored feature vectors in PNG images. We replace them with binary arrays. Unfortunately, all such arrays need to be loaded before the first frame can be rendered.<p>You do however point out one weakness of SMERF: large payload sizes. If we can figure out how to compress them by 10x, it&#x27;ll be a very different experience!</div><br/><div id="38636176" class="c"><input type="checkbox" id="c-38636176" checked=""/><div class="controls bullet"><span class="by">promiseofbeans</span><span>|</span><a href="#38633486">root</a><span>|</span><a href="#38634753">parent</a><span>|</span><a href="#38633516">next</a><span>|</span><label class="collapse" for="c-38636176">[-]</label><label class="expand" for="c-38636176">[2 more]</label></div><br/><div class="children"><div class="content">Or even just breaking them down into smaller chunks (prioritise loading the ones closer to where the user is looking) could help</div><br/><div id="38638610" class="c"><input type="checkbox" id="c-38638610" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633486">root</a><span>|</span><a href="#38636176">parent</a><span>|</span><a href="#38633516">next</a><span>|</span><label class="collapse" for="c-38638610">[-]</label><label class="expand" for="c-38638610">[1 more]</label></div><br/><div class="children"><div class="content">The viewer biases towards assets closer to user&#x27;s camera (otherwise you&#x27;d have to load the whole scene!). We tried training SMERF with a larger number of smaller submodels, but at some point, it becomes too onerous to train and quality begins to suffer.</div><br/></div></div></div></div></div></div></div></div><div id="38633516" class="c"><input type="checkbox" id="c-38633516" checked=""/><div class="controls bullet"><span class="by">VikingCoder</span><span>|</span><a href="#38633486">prev</a><span>|</span><a href="#38637078">next</a><span>|</span><label class="collapse" for="c-38633516">[-]</label><label class="expand" for="c-38633516">[8 more]</label></div><br/><div class="children"><div class="content">Wow.  Some questions:<p>Take for instance the fulllivingroom demo.  (I prefer fps mode.)<p>1) How many images are input?<p>2) How long does it take to compute these models?<p>3) How long does it take to prepare these models for this browser, with all levels, etc?<p>4) Have you tried this in VR yet?</div><br/><div id="38634825" class="c"><input type="checkbox" id="c-38634825" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633516">parent</a><span>|</span><a href="#38634397">next</a><span>|</span><label class="collapse" for="c-38634825">[-]</label><label class="expand" for="c-38634825">[6 more]</label></div><br/><div class="children"><div class="content">Glad you liked our work!<p>1) Around 100-150 if memory serves. This scene is part of the mip-NeRF 360 benchmark, which you can download from the corresponding project website: <a href="https:&#x2F;&#x2F;jonbarron.info&#x2F;mipnerf360&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;jonbarron.info&#x2F;mipnerf360&#x2F;</a><p>2) Between 12 and 48 hours, depending on the scene. We train on 8x V100s or 16x A100s.<p>3) The time for preparing assets is included in 2). I don&#x27;t have a breakdown for you, but it&#x27;s something like 50&#x2F;50.<p>4) Nope! A keen hacker might be able to do this themselves by editing the JavaScript code. Open your browser&#x27;s DevTools and have a look -- the code is all there!</div><br/><div id="38636074" class="c"><input type="checkbox" id="c-38636074" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633516">root</a><span>|</span><a href="#38634825">parent</a><span>|</span><a href="#38635067">next</a><span>|</span><label class="collapse" for="c-38636074">[-]</label><label class="expand" for="c-38636074">[3 more]</label></div><br/><div class="children"><div class="content">Update: Code for the web viewer is here,<p><a href="https:&#x2F;&#x2F;github.com&#x2F;smerf-3d&#x2F;smerf-3d.github.io&#x2F;blob&#x2F;main&#x2F;viewer&#x2F;index.html">https:&#x2F;&#x2F;github.com&#x2F;smerf-3d&#x2F;smerf-3d.github.io&#x2F;blob&#x2F;main&#x2F;vie...</a></div><br/><div id="38636706" class="c"><input type="checkbox" id="c-38636706" checked=""/><div class="controls bullet"><span class="by">nh2</span><span>|</span><a href="#38633516">root</a><span>|</span><a href="#38636074">parent</a><span>|</span><a href="#38635067">next</a><span>|</span><label class="collapse" for="c-38636706">[-]</label><label class="expand" for="c-38636706">[2 more]</label></div><br/><div class="children"><div class="content">What is the license? The repo doesn&#x27;t say.</div><br/><div id="38638615" class="c"><input type="checkbox" id="c-38638615" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633516">root</a><span>|</span><a href="#38636706">parent</a><span>|</span><a href="#38635067">next</a><span>|</span><label class="collapse" for="c-38638615">[-]</label><label class="expand" for="c-38638615">[1 more]</label></div><br/><div class="children"><div class="content">Oops, I need to update the license files.<p>Our code is released under the Apache 2.0 license, as in this repo:
<a href="https:&#x2F;&#x2F;github.com&#x2F;google-research&#x2F;google-research&#x2F;blob&#x2F;master&#x2F;LICENSE">https:&#x2F;&#x2F;github.com&#x2F;google-research&#x2F;google-research&#x2F;blob&#x2F;mast...</a></div><br/></div></div></div></div></div></div><div id="38635067" class="c"><input type="checkbox" id="c-38635067" checked=""/><div class="controls bullet"><span class="by">dougmwne</span><span>|</span><a href="#38633516">root</a><span>|</span><a href="#38634825">parent</a><span>|</span><a href="#38636074">prev</a><span>|</span><a href="#38634397">next</a><span>|</span><label class="collapse" for="c-38635067">[-]</label><label class="expand" for="c-38635067">[2 more]</label></div><br/><div class="children"><div class="content">Do you need position data to go along with the photos or just the photos?<p>For VR, there’s going to be some very weird depth data from those reflections, but maybe they would not be so bad when you are in headset.</div><br/><div id="38636085" class="c"><input type="checkbox" id="c-38636085" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633516">root</a><span>|</span><a href="#38635067">parent</a><span>|</span><a href="#38634397">next</a><span>|</span><label class="collapse" for="c-38636085">[-]</label><label class="expand" for="c-38636085">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Do you need position data to go along with the photos or just the photos?<p>Short answer: Yes.<p>Long answer: Yes, but it can typically be derived from images. Structure-from-motion methods are typically used to derive lens and position information for each photo in the training set. These are then used by Zip-NeRF (our teacher) and SMERF (our model) to train a model.</div><br/></div></div></div></div></div></div><div id="38634397" class="c"><input type="checkbox" id="c-38634397" checked=""/><div class="controls bullet"><span class="by">vyrotek</span><span>|</span><a href="#38633516">parent</a><span>|</span><a href="#38634825">prev</a><span>|</span><a href="#38637078">next</a><span>|</span><label class="collapse" for="c-38634397">[-]</label><label class="expand" for="c-38634397">[1 more]</label></div><br/><div class="children"><div class="content">Not exactly what you asked for. But I recently came across this VR example using Gaussian Splatting instead. Exciting times.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;gracia_vr&#x2F;status&#x2F;1731731549886787634" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;gracia_vr&#x2F;status&#x2F;1731731549886787634</a><p><a href="https:&#x2F;&#x2F;www.gracia.ai" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.gracia.ai</a></div><br/></div></div></div></div><div id="38637078" class="c"><input type="checkbox" id="c-38637078" checked=""/><div class="controls bullet"><span class="by">zyang</span><span>|</span><a href="#38633516">prev</a><span>|</span><a href="#38634936">next</a><span>|</span><label class="collapse" for="c-38637078">[-]</label><label class="expand" for="c-38637078">[2 more]</label></div><br/><div class="children"><div class="content">Why is there a 300m^2 footprint limit if the sub-models are dynamically loaded. Is this constrained by training, rasterizing, or both?</div><br/><div id="38638618" class="c"><input type="checkbox" id="c-38638618" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38637078">parent</a><span>|</span><a href="#38634936">next</a><span>|</span><label class="collapse" for="c-38638618">[-]</label><label class="expand" for="c-38638618">[1 more]</label></div><br/><div class="children"><div class="content">In terms of the live viewer, there&#x27;s actually no limit on footprint size. 300 m^2 is simply the biggest indoor capture we had!</div><br/></div></div></div></div><div id="38634936" class="c"><input type="checkbox" id="c-38634936" checked=""/><div class="controls bullet"><span class="by">tomatotomato31</span><span>|</span><a href="#38637078">prev</a><span>|</span><a href="#38636329">next</a><span>|</span><label class="collapse" for="c-38634936">[-]</label><label class="expand" for="c-38634936">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m following this through two minutes paper and I&#x27;m looking forward to using it.<p>My grandpa died 2 years ago and in hindsight I took pictures for using them as in your demo.<p>Awesome thanks:)</div><br/><div id="38635039" class="c"><input type="checkbox" id="c-38635039" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38634936">parent</a><span>|</span><a href="#38636329">next</a><span>|</span><label class="collapse" for="c-38635039">[-]</label><label class="expand" for="c-38635039">[1 more]</label></div><br/><div class="children"><div class="content">It would be my dream to make capturing 3D memories as easy and natural as taking a 2D photos with your smartphone today. Someday!</div><br/></div></div></div></div><div id="38636329" class="c"><input type="checkbox" id="c-38636329" checked=""/><div class="controls bullet"><span class="by">westurner</span><span>|</span><a href="#38634936">prev</a><span>|</span><a href="#38638938">next</a><span>|</span><label class="collapse" for="c-38636329">[-]</label><label class="expand" for="c-38636329">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Researchers create open-source platform for Neural Radiance Field development&quot; (2023) 
<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36966076">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36966076</a><p>NeRF Studio &gt; Included Methods, Third-party Methods: 
<a href="https:&#x2F;&#x2F;docs.nerf.studio&#x2F;#supported-methods" rel="nofollow noreferrer">https:&#x2F;&#x2F;docs.nerf.studio&#x2F;#supported-methods</a><p>Neural Radiance Field: 
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Neural_radiance_field" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Neural_radiance_field</a></div><br/></div></div><div id="38638938" class="c"><input type="checkbox" id="c-38638938" checked=""/><div class="controls bullet"><span class="by">azinman2</span><span>|</span><a href="#38636329">prev</a><span>|</span><a href="#38634821">next</a><span>|</span><label class="collapse" for="c-38638938">[-]</label><label class="expand" for="c-38638938">[1 more]</label></div><br/><div class="children"><div class="content">Will there be any notebooks or other code released to train our own models?</div><br/></div></div><div id="38634821" class="c"><input type="checkbox" id="c-38634821" checked=""/><div class="controls bullet"><span class="by">yarg</span><span>|</span><a href="#38638938">prev</a><span>|</span><a href="#38637703">next</a><span>|</span><label class="collapse" for="c-38634821">[-]</label><label class="expand" for="c-38634821">[3 more]</label></div><br/><div class="children"><div class="content">What I&#x27;m seeing from all of these things is very accurate single navigable 3D images.<p>What I haven&#x27;t seen anything of is feature and object detection, blocking and extraction.<p>Hopefully a more efficient and streamable codec necessitates the sort of structure that lends itself more easily to analysis.</div><br/><div id="38636167" class="c"><input type="checkbox" id="c-38636167" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38634821">parent</a><span>|</span><a href="#38637703">next</a><span>|</span><label class="collapse" for="c-38636167">[-]</label><label class="expand" for="c-38636167">[2 more]</label></div><br/><div class="children"><div class="content">3D understanding as a field is very much in its infancy. Good work is being done in this area, but we&#x27;ve got a long ways to go yet. SMERF is all about &quot;view synthesis&quot; -- rendering realistic images -- with no attempt at semantic understanding or segmentation.</div><br/><div id="38637040" class="c"><input type="checkbox" id="c-38637040" checked=""/><div class="controls bullet"><span class="by">cooper_ganglia</span><span>|</span><a href="#38634821">root</a><span>|</span><a href="#38636167">parent</a><span>|</span><a href="#38637703">next</a><span>|</span><label class="collapse" for="c-38637040">[-]</label><label class="expand" for="c-38637040">[1 more]</label></div><br/><div class="children"><div class="content">&quot;It&#x27;s <i>my</i> VR-deployed SMERF CLIP model with LLM integration, and I want it now!&quot;<p>It is funny how quickly goalposts move! I love to see progress though, and wow, is progress happening fast!</div><br/></div></div></div></div></div></div><div id="38637703" class="c"><input type="checkbox" id="c-38637703" checked=""/><div class="controls bullet"><span class="by">digdugdirk</span><span>|</span><a href="#38634821">prev</a><span>|</span><a href="#38635960">next</a><span>|</span><label class="collapse" for="c-38637703">[-]</label><label class="expand" for="c-38637703">[2 more]</label></div><br/><div class="children"><div class="content">Can you recommend a good entry point into the theory&#x2F;math behind these? This is one of those true &quot;wtf, we can do this now?&quot; moments, I&#x27;m super curious about how these are generated&#x2F;created.</div><br/><div id="38638635" class="c"><input type="checkbox" id="c-38638635" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38637703">parent</a><span>|</span><a href="#38635960">next</a><span>|</span><label class="collapse" for="c-38638635">[-]</label><label class="expand" for="c-38638635">[1 more]</label></div><br/><div class="children"><div class="content">Oof, there&#x27;s a lot of machinery here. It depends a lot on your academic background.<p>I&#x27;d recommend starting with a tutorial on neural radiance fields, aka NeRF, (<a href="https:&#x2F;&#x2F;sites.google.com&#x2F;berkeley.edu&#x2F;nerf-tutorial&#x2F;home" rel="nofollow noreferrer">https:&#x2F;&#x2F;sites.google.com&#x2F;berkeley.edu&#x2F;nerf-tutorial&#x2F;home</a>) and an applied overview of Deep Learning with tools like PyTorch or JAX. This line of work is still &quot;cutting edge&quot; research, so a lot of knowledge hasn&#x27;t been rolled up into textbook or article form yet.</div><br/></div></div></div></div><div id="38635960" class="c"><input type="checkbox" id="c-38635960" checked=""/><div class="controls bullet"><span class="by">edrxty</span><span>|</span><a href="#38637703">prev</a><span>|</span><a href="#38635765">next</a><span>|</span><label class="collapse" for="c-38635960">[-]</label><label class="expand" for="c-38635960">[7 more]</label></div><br/><div class="children"><div class="content">Is there any relation between this class of rendering techniques and the way the BD scenes in Cyberpunk 2077 were created?  The behavior of the volume and the &quot;voxels&quot; seem eerily similar.</div><br/><div id="38638735" class="c"><input type="checkbox" id="c-38638735" checked=""/><div class="controls bullet"><span class="by">9dev</span><span>|</span><a href="#38635960">parent</a><span>|</span><a href="#38635999">next</a><span>|</span><label class="collapse" for="c-38638735">[-]</label><label class="expand" for="c-38638735">[1 more]</label></div><br/><div class="children"><div class="content">I doubt Cyberpunk uses more than a special shader for the BD sequences, but what’s a lot more remarkable to me is how similar the idea is at heart. Maybe we’re actually going to see this (maybe sans the brain-implant to record them, but hey) after all. Amazing technology, that’s for sure.</div><br/></div></div><div id="38635999" class="c"><input type="checkbox" id="c-38635999" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38635960">parent</a><span>|</span><a href="#38638735">prev</a><span>|</span><a href="#38635765">next</a><span>|</span><label class="collapse" for="c-38635999">[-]</label><label class="expand" for="c-38635999">[5 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t say. I&#x27;m not familiar with BD in Cyberpunk.</div><br/><div id="38636032" class="c"><input type="checkbox" id="c-38636032" checked=""/><div class="controls bullet"><span class="by">edrxty</span><span>|</span><a href="#38635960">root</a><span>|</span><a href="#38635999">parent</a><span>|</span><a href="#38635765">next</a><span>|</span><label class="collapse" for="c-38636032">[-]</label><label class="expand" for="c-38636032">[4 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;youtu.be&#x2F;KXXGS3MGCro?t=118" rel="nofollow noreferrer">https:&#x2F;&#x2F;youtu.be&#x2F;KXXGS3MGCro?t=118</a><p>It&#x27;s a sort of replayable cutscene that happens a couple times in the game where you can wander through it.  The noteworthy bit is it&#x27;s rendered out of voxels that look very similar to the demos but at a much lower resolution and if you push the frustrum into any objects, you get the same kind of effect where the surface breaks into blocks.</div><br/><div id="38636154" class="c"><input type="checkbox" id="c-38636154" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38635960">root</a><span>|</span><a href="#38636032">parent</a><span>|</span><a href="#38635765">next</a><span>|</span><label class="collapse" for="c-38636154">[-]</label><label class="expand" for="c-38636154">[3 more]</label></div><br/><div class="children"><div class="content">Interesting effect. It does look very voxel-y. I&#x27;m not a video game developer at heart, so I can only guess how it was implemented. I doubt NeRF models were involved, but I wouldn&#x27;t be surprised if some sort of voxel discretization was.</div><br/><div id="38636191" class="c"><input type="checkbox" id="c-38636191" checked=""/><div class="controls bullet"><span class="by">promiseofbeans</span><span>|</span><a href="#38635960">root</a><span>|</span><a href="#38636154">parent</a><span>|</span><a href="#38635765">next</a><span>|</span><label class="collapse" for="c-38636191">[-]</label><label class="expand" for="c-38636191">[2 more]</label></div><br/><div class="children"><div class="content">It seems like it might even just be some kind of shader</div><br/><div id="38639221" class="c"><input type="checkbox" id="c-38639221" checked=""/><div class="controls bullet"><span class="by">vanderZwan</span><span>|</span><a href="#38635960">root</a><span>|</span><a href="#38636191">parent</a><span>|</span><a href="#38635765">next</a><span>|</span><label class="collapse" for="c-38639221">[-]</label><label class="expand" for="c-38639221">[1 more]</label></div><br/><div class="children"><div class="content">If you think about how they created this from the POV of the game creation pipeline, then that probably is the way. If this is done by creating a shader on top of &quot;plain old&quot; 3D assets, then aside from the programmers&#x2F;artists involved with creating that shader everyone else can go about their business with minimal retraining. There probably was a lot of content to create, to that optimization likely took priority over other methods of implementing this effect.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38635765" class="c"><input type="checkbox" id="c-38635765" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#38635960">prev</a><span>|</span><a href="#38637933">next</a><span>|</span><label class="collapse" for="c-38635765">[-]</label><label class="expand" for="c-38635765">[4 more]</label></div><br/><div class="children"><div class="content">Does the an open source toolchain exist for capturing, processing, and hosting navigable 3D walkthroughs like this (e.g. something like an open-source Matterport)?</div><br/><div id="38635888" class="c"><input type="checkbox" id="c-38635888" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38635765">parent</a><span>|</span><a href="#38635992">next</a><span>|</span><label class="collapse" for="c-38635888">[-]</label><label class="expand" for="c-38635888">[2 more]</label></div><br/><div class="children"><div class="content">Not yet, as far as I&#x27;m aware. The current flow involves a DSLR for capture, COLMAP for camera parameter estimation, one codebase for training a teacher model, our codebase for training SMERF, and our web viewer for rendering models.<p>Sounds like an opportunity!</div><br/><div id="38639270" class="c"><input type="checkbox" id="c-38639270" checked=""/><div class="controls bullet"><span class="by">strofocles</span><span>|</span><a href="#38635765">root</a><span>|</span><a href="#38635888">parent</a><span>|</span><a href="#38635992">next</a><span>|</span><label class="collapse" for="c-38639270">[-]</label><label class="expand" for="c-38639270">[1 more]</label></div><br/><div class="children"><div class="content">Is there a significant advantage for capturing using DSLRs vs using the phone camera of a decent phone?</div><br/></div></div></div></div><div id="38635992" class="c"><input type="checkbox" id="c-38635992" checked=""/><div class="controls bullet"><span class="by">gorkish</span><span>|</span><a href="#38635765">parent</a><span>|</span><a href="#38635888">prev</a><span>|</span><a href="#38637933">next</a><span>|</span><label class="collapse" for="c-38635992">[-]</label><label class="expand" for="c-38635992">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need a toolchain for capturing; you just need the data. Get it now; process it when better tools become available. There are guides for shooting for Photogrammetry and NeRF that are generally applicable to what you need to do.</div><br/></div></div></div></div><div id="38637933" class="c"><input type="checkbox" id="c-38637933" checked=""/><div class="controls bullet"><span class="by">slalomskiing</span><span>|</span><a href="#38635765">prev</a><span>|</span><a href="#38635743">next</a><span>|</span><label class="collapse" for="c-38637933">[-]</label><label class="expand" for="c-38637933">[4 more]</label></div><br/><div class="children"><div class="content">I wonder since this runs at real time framerate if it would be possible for someone to composite a regular rasterized frame on top of something like this (with correct depth testing) to make a game<p>For example a 3rd person game where the character you control and the NPCs&#x2F;enemies is raster but the environment is all radiance fields</div><br/><div id="38637964" class="c"><input type="checkbox" id="c-38637964" checked=""/><div class="controls bullet"><span class="by">jasonwatkinspdx</span><span>|</span><a href="#38637933">parent</a><span>|</span><a href="#38638641">next</a><span>|</span><label class="collapse" for="c-38637964">[-]</label><label class="expand" for="c-38637964">[1 more]</label></div><br/><div class="children"><div class="content">If you go to one of the demos the space bar will cycle through some debug modes. One shows a surface reconstruction. It comes from the usual structure from motion techniques I presume, so it&#x27;s coarse and noisy, but I think the fundamental idea is viable.</div><br/></div></div><div id="38638641" class="c"><input type="checkbox" id="c-38638641" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38637933">parent</a><span>|</span><a href="#38637964">prev</a><span>|</span><a href="#38635743">next</a><span>|</span><label class="collapse" for="c-38638641">[-]</label><label class="expand" for="c-38638641">[2 more]</label></div><br/><div class="children"><div class="content">This should absolutely be possible! The hard part is making it look natural: NeRF models (including SMERF) have no explicit materials or lighting. That means that any character inserted into the game will look out of place.</div><br/><div id="38639229" class="c"><input type="checkbox" id="c-38639229" checked=""/><div class="controls bullet"><span class="by">vanderZwan</span><span>|</span><a href="#38637933">root</a><span>|</span><a href="#38638641">parent</a><span>|</span><a href="#38635743">next</a><span>|</span><label class="collapse" for="c-38639229">[-]</label><label class="expand" for="c-38639229">[1 more]</label></div><br/><div class="children"><div class="content">Why bother to make it look natural when you can have a really awkward greenscreen-like effect for nostalgic and &quot;artistic&quot; purposes?</div><br/></div></div></div></div></div></div><div id="38635743" class="c"><input type="checkbox" id="c-38635743" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#38637933">prev</a><span>|</span><a href="#38634201">next</a><span>|</span><label class="collapse" for="c-38635743">[-]</label><label class="expand" for="c-38635743">[3 more]</label></div><br/><div class="children"><div class="content">Very impressive! Any information on how this compares to 3D Gaussian splatting in terms of performance, quality or data size?</div><br/><div id="38635895" class="c"><input type="checkbox" id="c-38635895" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38635743">parent</a><span>|</span><a href="#38634201">next</a><span>|</span><label class="collapse" for="c-38635895">[-]</label><label class="expand" for="c-38635895">[2 more]</label></div><br/><div class="children"><div class="content">All these details and more in our technical paper! In short: SMERF training takes much longer, SMERF rendering is nearly as fast as 3DGS when a CUDA GPU is available, and quality is visibly higher than 3DGS on large scenes and slightly higher on smaller scenes.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.07541" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2312.07541</a></div><br/><div id="38637563" class="c"><input type="checkbox" id="c-38637563" checked=""/><div class="controls bullet"><span class="by">zyang</span><span>|</span><a href="#38635743">root</a><span>|</span><a href="#38635895">parent</a><span>|</span><a href="#38634201">next</a><span>|</span><label class="collapse" for="c-38637563">[-]</label><label class="expand" for="c-38637563">[1 more]</label></div><br/><div class="children"><div class="content">Is it possible to use zip-nerf to train GS to eliminate the floaters.</div><br/></div></div></div></div></div></div><div id="38634201" class="c"><input type="checkbox" id="c-38634201" checked=""/><div class="controls bullet"><span class="by">catskul2</span><span>|</span><a href="#38635743">prev</a><span>|</span><a href="#38633771">next</a><span>|</span><label class="collapse" for="c-38634201">[-]</label><label class="expand" for="c-38634201">[5 more]</label></div><br/><div class="children"><div class="content">When might we see this in consumer VR? I&#x27;m surprised we don&#x27;t already but I was suspecting it was a computation constraint.<p>Does this relieve the computation constraint enough to run on Quest 2&#x2F;3?<p>Is there something else that would prevent binocular use?</div><br/><div id="38634848" class="c"><input type="checkbox" id="c-38634848" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38634201">parent</a><span>|</span><a href="#38634746">next</a><span>|</span><label class="collapse" for="c-38634848">[-]</label><label class="expand" for="c-38634848">[3 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t predict the future, but I imagine soon: all of the tools are there. The reason we didn&#x27;t develop for VR is actually simpler than you&#x27;d think: we just don&#x27;t have the developer time! At the end of the day, only a handful of people actively wrote code for this project.</div><br/><div id="38637682" class="c"><input type="checkbox" id="c-38637682" checked=""/><div class="controls bullet"><span class="by">nojvek</span><span>|</span><a href="#38634201">root</a><span>|</span><a href="#38634848">parent</a><span>|</span><a href="#38634746">next</a><span>|</span><label class="collapse" for="c-38637682">[-]</label><label class="expand" for="c-38637682">[2 more]</label></div><br/><div class="children"><div class="content">Any plans to open source the code?</div><br/><div id="38638654" class="c"><input type="checkbox" id="c-38638654" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38634201">root</a><span>|</span><a href="#38637682">parent</a><span>|</span><a href="#38634746">next</a><span>|</span><label class="collapse" for="c-38638654">[-]</label><label class="expand" for="c-38638654">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I hope so! But it&#x27;ll take at least a few months of work. We have some tight dependencies to not-yet-open-sourced code, and until that&#x27;s released, any code we put out will be dead on arrival.<p>In the meantime, feel free to explore the live viewer code!<p><a href="https:&#x2F;&#x2F;github.com&#x2F;smerf-3d&#x2F;smerf-3d.github.io&#x2F;blob&#x2F;main&#x2F;viewer&#x2F;index.html">https:&#x2F;&#x2F;github.com&#x2F;smerf-3d&#x2F;smerf-3d.github.io&#x2F;blob&#x2F;main&#x2F;vie...</a></div><br/></div></div></div></div></div></div><div id="38634746" class="c"><input type="checkbox" id="c-38634746" checked=""/><div class="controls bullet"><span class="by">doctoboggan</span><span>|</span><a href="#38634201">parent</a><span>|</span><a href="#38634848">prev</a><span>|</span><a href="#38633771">next</a><span>|</span><label class="collapse" for="c-38634746">[-]</label><label class="expand" for="c-38634746">[1 more]</label></div><br/><div class="children"><div class="content">I recently got a new quest and I am wondering the same thing. The fact that this is currently running in a browser (and can run on a mobile device) gives me hope that we will see something like this in VR sooner rather than later.</div><br/></div></div></div></div><div id="38633771" class="c"><input type="checkbox" id="c-38633771" checked=""/><div class="controls bullet"><span class="by">heliophobicdude</span><span>|</span><a href="#38634201">prev</a><span>|</span><a href="#38632622">next</a><span>|</span><label class="collapse" for="c-38633771">[-]</label><label class="expand" for="c-38633771">[2 more]</label></div><br/><div class="children"><div class="content">Great work!!<p>Question for the authors, are there opportunities, where they exist, to not use optimization or tuning methods for reconstructing a model of a scene?<p>We are refining efficient ways of rendering a view of a scene from these models but the scenes remain static. The scenes also take a while to reconstruct too.<p>Can we still achieve the great look and details of RF and GS without paying for an expensive reconstruction per instance of the scene?<p>Are there ways of greedily reconstructing a scene with traditional CG methods into these new representations now that they are fast to render?<p>Please forgive any misconceptions that I may have in advanced! We really appreciate the work y&#x27;all are advancing!</div><br/><div id="38634897" class="c"><input type="checkbox" id="c-38634897" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633771">parent</a><span>|</span><a href="#38632622">next</a><span>|</span><label class="collapse" for="c-38634897">[-]</label><label class="expand" for="c-38634897">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Are there opportunities, where they exist, to not use optimization or tuning methods for reconstructing a model of a scene?<p>If you know a way, let me know! Every system I&#x27;m aware of involves optimization in one way or another, from COLMAP to 3D Gaussian Splatting to Instant NGP and more. Optimization is a powerful workhorse that gives us a far wider range of models than a direct solver ever could.
&gt; Can we still achieve the great look and details of RF and GS without paying for an expensive reconstruction per instance of the scene?<p>In the future I hope so. We don&#x27;t have a convincing way to generate 3D scenes yet, but given the progress in 2D, I think it&#x27;s only a matter of time.<p>&gt; Are there ways of greedily reconstructing a scene with traditional CG methods into these new representations now that they are fast to render?<p>Not that I&#x27;m aware of! If there were, I think these works should be on the front page instead of SMERF.</div><br/></div></div></div></div><div id="38632622" class="c"><input type="checkbox" id="c-38632622" checked=""/><div class="controls bullet"><span class="by">sim7c00</span><span>|</span><a href="#38633771">prev</a><span>|</span><a href="#38633189">next</a><span>|</span><label class="collapse" for="c-38632622">[-]</label><label class="expand" for="c-38632622">[3 more]</label></div><br/><div class="children"><div class="content">this looks really amazing. i have a relatively old smartphone (2019) and its really surprisingly smooth and high fidently. amazing job!</div><br/><div id="38633269" class="c"><input type="checkbox" id="c-38633269" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38632622">parent</a><span>|</span><a href="#38633189">next</a><span>|</span><label class="collapse" for="c-38633269">[-]</label><label class="expand" for="c-38633269">[2 more]</label></div><br/><div class="children"><div class="content">Thank you :). I&#x27;m glad to hear it! Which model are you using?</div><br/><div id="38633847" class="c"><input type="checkbox" id="c-38633847" checked=""/><div class="controls bullet"><span class="by">sim7c00</span><span>|</span><a href="#38632622">root</a><span>|</span><a href="#38633269">parent</a><span>|</span><a href="#38633189">next</a><span>|</span><label class="collapse" for="c-38633847">[-]</label><label class="expand" for="c-38633847">[1 more]</label></div><br/><div class="children"><div class="content">samsung galaxy 10se</div><br/></div></div></div></div></div></div><div id="38633189" class="c"><input type="checkbox" id="c-38633189" checked=""/><div class="controls bullet"><span class="by">zeusk</span><span>|</span><a href="#38632622">prev</a><span>|</span><a href="#38633841">next</a><span>|</span><label class="collapse" for="c-38633189">[-]</label><label class="expand" for="c-38633189">[3 more]</label></div><br/><div class="children"><div class="content">Are radiance fields related to Gaussian splattering?</div><br/><div id="38633260" class="c"><input type="checkbox" id="c-38633260" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633189">parent</a><span>|</span><a href="#38634633">next</a><span>|</span><label class="collapse" for="c-38633260">[-]</label><label class="expand" for="c-38633260">[1 more]</label></div><br/><div class="children"><div class="content">Gaussian Splatting is heavily inspired by work in radiance fields (or NeRF) models. They use much of the same technology!</div><br/></div></div><div id="38634633" class="c"><input type="checkbox" id="c-38634633" checked=""/><div class="controls bullet"><span class="by">corysama</span><span>|</span><a href="#38633189">parent</a><span>|</span><a href="#38633260">prev</a><span>|</span><a href="#38633841">next</a><span>|</span><label class="collapse" for="c-38634633">[-]</label><label class="expand" for="c-38634633">[1 more]</label></div><br/><div class="children"><div class="content">Similar inputs, similar outputs, different representation.</div><br/></div></div></div></div><div id="38633841" class="c"><input type="checkbox" id="c-38633841" checked=""/><div class="controls bullet"><span class="by">annoyingnoob</span><span>|</span><a href="#38633189">prev</a><span>|</span><a href="#38633391">next</a><span>|</span><label class="collapse" for="c-38633841">[-]</label><label class="expand" for="c-38633841">[4 more]</label></div><br/><div class="children"><div class="content">There is a market here for Realtors to upload pictures and produce walk-throughs of homes for sale.</div><br/><div id="38634516" class="c"><input type="checkbox" id="c-38634516" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#38633841">parent</a><span>|</span><a href="#38634983">next</a><span>|</span><label class="collapse" for="c-38634516">[-]</label><label class="expand" for="c-38634516">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;matterport.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;matterport.com&#x2F;</a></div><br/></div></div><div id="38634983" class="c"><input type="checkbox" id="c-38634983" checked=""/><div class="controls bullet"><span class="by">ibrarmalik</span><span>|</span><a href="#38633841">parent</a><span>|</span><a href="#38634516">prev</a><span>|</span><a href="#38633391">next</a><span>|</span><label class="collapse" for="c-38634983">[-]</label><label class="expand" for="c-38634983">[2 more]</label></div><br/><div class="children"><div class="content">The Luma folks made something similar: <a href="https:&#x2F;&#x2F;apps.apple.com&#x2F;app&#x2F;luma-flythroughs&#x2F;id6450376609?l=en-GB" rel="nofollow noreferrer">https:&#x2F;&#x2F;apps.apple.com&#x2F;app&#x2F;luma-flythroughs&#x2F;id6450376609?l=e...</a></div><br/><div id="38635911" class="c"><input type="checkbox" id="c-38635911" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633841">root</a><span>|</span><a href="#38634983">parent</a><span>|</span><a href="#38633391">next</a><span>|</span><label class="collapse" for="c-38635911">[-]</label><label class="expand" for="c-38635911">[1 more]</label></div><br/><div class="children"><div class="content">Be careful with this one! Luma&#x27;s offering requires that the camera follow the recorded video path. Our method lets the camera go wherever you desire!</div><br/></div></div></div></div></div></div><div id="38633391" class="c"><input type="checkbox" id="c-38633391" checked=""/><div class="controls bullet"><span class="by">jacoblambda</span><span>|</span><a href="#38633841">prev</a><span>|</span><a href="#38634573">next</a><span>|</span><label class="collapse" for="c-38633391">[-]</label><label class="expand" for="c-38633391">[3 more]</label></div><br/><div class="children"><div class="content">Is there a relatively easy way to apply these kinds of techniques (either NeRFs or gaussian splats) to larger environments even if it&#x27;s lower precision? Like say small towns&#x2F;a few blocks worth of env.</div><br/><div id="38635188" class="c"><input type="checkbox" id="c-38635188" checked=""/><div class="controls bullet"><span class="by">ibrarmalik</span><span>|</span><a href="#38633391">parent</a><span>|</span><a href="#38634926">next</a><span>|</span><label class="collapse" for="c-38635188">[-]</label><label class="expand" for="c-38635188">[1 more]</label></div><br/><div class="children"><div class="content">You’re under the right paper for doing this. Instead of one big model, they have several smaller ones for regions in the scene. This way rendering is fast for large scenes.<p>This is similar to Block-NeRF [0], in their project page they show some videos of what you’re asking.<p>As for an easy way of doing this, nothing out-of-the-box. You can keep an eye on nerfstudio [1], and if you feel brave you could implement this paper and make a PR!<p>[0] <a href="https:&#x2F;&#x2F;waymo.com&#x2F;intl&#x2F;es&#x2F;research&#x2F;block-nerf&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;waymo.com&#x2F;intl&#x2F;es&#x2F;research&#x2F;block-nerf&#x2F;</a><p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;nerfstudio-project&#x2F;nerfstudio">https:&#x2F;&#x2F;github.com&#x2F;nerfstudio-project&#x2F;nerfstudio</a></div><br/></div></div><div id="38634926" class="c"><input type="checkbox" id="c-38634926" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633391">parent</a><span>|</span><a href="#38635188">prev</a><span>|</span><a href="#38634573">next</a><span>|</span><label class="collapse" for="c-38634926">[-]</label><label class="expand" for="c-38634926">[1 more]</label></div><br/><div class="children"><div class="content">In principle, there&#x27;s no reason you can&#x27;t fit multiple City blocks at the same time with Instant NGP on a regular desktop. The challenge is in estimating the camera and lens parameters over such a large space. I expect such a reconstruction to be quite fuzzy given the low space resolution.</div><br/></div></div></div></div><div id="38634573" class="c"><input type="checkbox" id="c-38634573" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#38633391">prev</a><span>|</span><a href="#38635823">next</a><span>|</span><label class="collapse" for="c-38634573">[-]</label><label class="expand" for="c-38634573">[7 more]</label></div><br/><div class="children"><div class="content">How long until you can stitch Street View into a seamless streaming NeRF of every street in the world? I hope that&#x27;s the goal you&#x27;re working towards!</div><br/><div id="38635784" class="c"><input type="checkbox" id="c-38635784" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#38634573">parent</a><span>|</span><a href="#38635397">next</a><span>|</span><label class="collapse" for="c-38635784">[-]</label><label class="expand" for="c-38635784">[1 more]</label></div><br/><div class="children"><div class="content">Not every street yet: <a href="https:&#x2F;&#x2F;waymo.com&#x2F;research&#x2F;block-nerf&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;waymo.com&#x2F;research&#x2F;block-nerf&#x2F;</a></div><br/></div></div><div id="38635397" class="c"><input type="checkbox" id="c-38635397" checked=""/><div class="controls bullet"><span class="by">deelowe</span><span>|</span><a href="#38634573">parent</a><span>|</span><a href="#38635784">prev</a><span>|</span><a href="#38634853">next</a><span>|</span><label class="collapse" for="c-38635397">[-]</label><label class="expand" for="c-38635397">[3 more]</label></div><br/><div class="children"><div class="content">I read another article talking about what waymo was working on and this looks oddly similar... My understanding is that the goal is to use this to reconstruct 3d models of street view images in real time.</div><br/><div id="38636190" class="c"><input type="checkbox" id="c-38636190" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38634573">root</a><span>|</span><a href="#38635397">parent</a><span>|</span><a href="#38634853">next</a><span>|</span><label class="collapse" for="c-38636190">[-]</label><label class="expand" for="c-38636190">[2 more]</label></div><br/><div class="children"><div class="content">Block-NeRF is a predecessor work that helped inspire SMERF, in fact!<p><a href="https:&#x2F;&#x2F;waymo.com&#x2F;research&#x2F;block-nerf&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;waymo.com&#x2F;research&#x2F;block-nerf&#x2F;</a></div><br/><div id="38636555" class="c"><input type="checkbox" id="c-38636555" checked=""/><div class="controls bullet"><span class="by">deelowe</span><span>|</span><a href="#38634573">root</a><span>|</span><a href="#38636190">parent</a><span>|</span><a href="#38634853">next</a><span>|</span><label class="collapse" for="c-38636555">[-]</label><label class="expand" for="c-38636555">[1 more]</label></div><br/><div class="children"><div class="content">Very cool. Thanks!</div><br/></div></div></div></div></div></div><div id="38634853" class="c"><input type="checkbox" id="c-38634853" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38634573">parent</a><span>|</span><a href="#38635397">prev</a><span>|</span><a href="#38635823">next</a><span>|</span><label class="collapse" for="c-38634853">[-]</label><label class="expand" for="c-38634853">[2 more]</label></div><br/><div class="children"><div class="content">;)</div><br/><div id="38635178" class="c"><input type="checkbox" id="c-38635178" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#38634573">root</a><span>|</span><a href="#38634853">parent</a><span>|</span><a href="#38635823">next</a><span>|</span><label class="collapse" for="c-38635178">[-]</label><label class="expand" for="c-38635178">[1 more]</label></div><br/><div class="children"><div class="content">Haha, too bad the Earth VR team was disbanded because that would be the Holy Grail. If someone can get the budget to work on that I&#x27;d be tempted to come back to Google just to help get it done! It&#x27;s what I always wanted when I was building the first Earth VR demo...</div><br/></div></div></div></div></div></div><div id="38635823" class="c"><input type="checkbox" id="c-38635823" checked=""/><div class="controls bullet"><span class="by">germandiago</span><span>|</span><a href="#38634573">prev</a><span>|</span><a href="#38633554">next</a><span>|</span><label class="collapse" for="c-38635823">[-]</label><label class="expand" for="c-38635823">[2 more]</label></div><br/><div class="children"><div class="content">Amazing, impressive, almost unbelievable :O</div><br/><div id="38635897" class="c"><input type="checkbox" id="c-38635897" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38635823">parent</a><span>|</span><a href="#38633554">next</a><span>|</span><label class="collapse" for="c-38635897">[-]</label><label class="expand" for="c-38635897">[1 more]</label></div><br/><div class="children"><div class="content">Thank you!</div><br/></div></div></div></div><div id="38633554" class="c"><input type="checkbox" id="c-38633554" checked=""/><div class="controls bullet"><span class="by">durag</span><span>|</span><a href="#38635823">prev</a><span>|</span><a href="#38633748">next</a><span>|</span><label class="collapse" for="c-38633554">[-]</label><label class="expand" for="c-38633554">[2 more]</label></div><br/><div class="children"><div class="content">Any plans to do this in VR? I would love to try this.</div><br/><div id="38634953" class="c"><input type="checkbox" id="c-38634953" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633554">parent</a><span>|</span><a href="#38633748">next</a><span>|</span><label class="collapse" for="c-38634953">[-]</label><label class="expand" for="c-38634953">[1 more]</label></div><br/><div class="children"><div class="content">Not at the moment but an intrepid hacker could surely extend our JavaScript code and put something together.<p>UPDATE: The code for our web viewer is here: <a href="https:&#x2F;&#x2F;github.com&#x2F;smerf-3d&#x2F;smerf-3d.github.io&#x2F;blob&#x2F;main&#x2F;viewer&#x2F;index.html">https:&#x2F;&#x2F;github.com&#x2F;smerf-3d&#x2F;smerf-3d.github.io&#x2F;blob&#x2F;main&#x2F;vie...</a></div><br/></div></div></div></div><div id="38633748" class="c"><input type="checkbox" id="c-38633748" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#38633554">prev</a><span>|</span><a href="#38635628">next</a><span>|</span><label class="collapse" for="c-38633748">[-]</label><label class="expand" for="c-38633748">[2 more]</label></div><br/><div class="children"><div class="content">Since you&#x27;re here @author :) Do you mind giving a quick rundown on how this competes with the quality of zip-nerf?</div><br/><div id="38635232" class="c"><input type="checkbox" id="c-38635232" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633748">parent</a><span>|</span><a href="#38635628">next</a><span>|</span><label class="collapse" for="c-38635232">[-]</label><label class="expand" for="c-38635232">[1 more]</label></div><br/><div class="children"><div class="content">Check out our explainer video for answers to this question and more!
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=zhO8iUBpnCc" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=zhO8iUBpnCc</a></div><br/></div></div></div></div><div id="38635628" class="c"><input type="checkbox" id="c-38635628" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#38633748">prev</a><span>|</span><a href="#38635358">next</a><span>|</span><label class="collapse" for="c-38635628">[-]</label><label class="expand" for="c-38635628">[2 more]</label></div><br/><div class="children"><div class="content">This is very impressive but given its by Google, will some code ever be released?</div><br/><div id="38636174" class="c"><input type="checkbox" id="c-38636174" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38635628">parent</a><span>|</span><a href="#38635358">next</a><span>|</span><label class="collapse" for="c-38636174">[-]</label><label class="expand" for="c-38636174">[1 more]</label></div><br/><div class="children"><div class="content">I hope to release the code in the new year, but we have some big dependencies that need to be released worse. In the meantime, you can already begin hacking on the live viewer,
<a href="https:&#x2F;&#x2F;github.com&#x2F;smerf-3d&#x2F;smerf-3d.github.io&#x2F;blob&#x2F;main&#x2F;viewer&#x2F;index.html">https:&#x2F;&#x2F;github.com&#x2F;smerf-3d&#x2F;smerf-3d.github.io&#x2F;blob&#x2F;main&#x2F;vie...</a></div><br/></div></div></div></div><div id="38635358" class="c"><input type="checkbox" id="c-38635358" checked=""/><div class="controls bullet"><span class="by">rzzzt</span><span>|</span><a href="#38635628">prev</a><span>|</span><a href="#38634852">next</a><span>|</span><label class="collapse" for="c-38635358">[-]</label><label class="expand" for="c-38635358">[2 more]</label></div><br/><div class="children"><div class="content">What kind of modes does the viewer cycle through when I press the space key?</div><br/><div id="38635899" class="c"><input type="checkbox" id="c-38635899" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38635358">parent</a><span>|</span><a href="#38634852">next</a><span>|</span><label class="collapse" for="c-38635899">[-]</label><label class="expand" for="c-38635899">[1 more]</label></div><br/><div class="children"><div class="content">Nice discovery :). Check the developer console: it&#x27;ll tell you.</div><br/></div></div></div></div><div id="38634852" class="c"><input type="checkbox" id="c-38634852" checked=""/><div class="controls bullet"><span class="by">fngjdflmdflg</span><span>|</span><a href="#38635358">prev</a><span>|</span><a href="#38633054">next</a><span>|</span><label class="collapse" for="c-38634852">[-]</label><label class="expand" for="c-38634852">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Google DeepMind Google Research Google Inc.<p>What a variety of groups! How did this come about?</div><br/><div id="38635917" class="c"><input type="checkbox" id="c-38635917" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38634852">parent</a><span>|</span><a href="#38633054">next</a><span>|</span><label class="collapse" for="c-38635917">[-]</label><label class="expand" for="c-38635917">[1 more]</label></div><br/><div class="children"><div class="content">Collaboration is a thing at the Big G :)</div><br/></div></div></div></div><div id="38633054" class="c"><input type="checkbox" id="c-38633054" checked=""/><div class="controls bullet"><span class="by">guywithabowtie</span><span>|</span><a href="#38634852">prev</a><span>|</span><a href="#38633935">next</a><span>|</span><label class="collapse" for="c-38633054">[-]</label><label class="expand" for="c-38633054">[4 more]</label></div><br/><div class="children"><div class="content">Any plans to release the models ?</div><br/><div id="38633276" class="c"><input type="checkbox" id="c-38633276" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633054">parent</a><span>|</span><a href="#38633935">next</a><span>|</span><label class="collapse" for="c-38633276">[-]</label><label class="expand" for="c-38633276">[3 more]</label></div><br/><div class="children"><div class="content">The pretrained models are already available online! Check out the &quot;demo&quot; section of the website. Your browser is fetching the model when you run the demo.</div><br/><div id="38635276" class="c"><input type="checkbox" id="c-38635276" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#38633054">root</a><span>|</span><a href="#38633276">parent</a><span>|</span><a href="#38633935">next</a><span>|</span><label class="collapse" for="c-38635276">[-]</label><label class="expand" for="c-38635276">[2 more]</label></div><br/><div class="children"><div class="content">Will the code be released, or an API endpoint? Otherwise it will be impossible for us to use it for anything.. since it&#x27;s Google I assume it will just end up in a black hole like most of the research.. or five years later some AI researchers leave and finally create a startup.</div><br/><div id="38635930" class="c"><input type="checkbox" id="c-38635930" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633054">root</a><span>|</span><a href="#38635276">parent</a><span>|</span><a href="#38633935">next</a><span>|</span><label class="collapse" for="c-38635930">[-]</label><label class="expand" for="c-38635930">[1 more]</label></div><br/><div class="children"><div class="content">I hope to release code in the new year, but it&#x27;ll take a while. The codebase is heavily wired into other not-yet-open-sourced libraries, and it&#x27;ll take a while to disentangle them.</div><br/></div></div></div></div></div></div></div></div><div id="38633935" class="c"><input type="checkbox" id="c-38633935" checked=""/><div class="controls bullet"><span class="by">jerpint</span><span>|</span><a href="#38633054">prev</a><span>|</span><a href="#38633386">next</a><span>|</span><label class="collapse" for="c-38633935">[-]</label><label class="expand" for="c-38633935">[2 more]</label></div><br/><div class="children"><div class="content">Just ran this on my phone through a browser, this is very impressive</div><br/><div id="38634928" class="c"><input type="checkbox" id="c-38634928" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633935">parent</a><span>|</span><a href="#38633386">next</a><span>|</span><label class="collapse" for="c-38634928">[-]</label><label class="expand" for="c-38634928">[1 more]</label></div><br/><div class="children"><div class="content">Thank you :)</div><br/></div></div></div></div><div id="38633386" class="c"><input type="checkbox" id="c-38633386" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#38633935">prev</a><span>|</span><label class="collapse" for="c-38633386">[-]</label><label class="expand" for="c-38633386">[3 more]</label></div><br/><div class="children"><div class="content">This is __really__ stunning work, huge, huge, deal that I&#x27;m seeing this in a web browser on my phone. Congratulations!<p>When I look at the NYC scene in the highest quality on desktop, I&#x27;m surprised by how low-quality ex. the stuff on the counter and shelves is. So then I load the lego model, and see that&#x27;s _very_ detailed, so it doesn&#x27;t seem inherent to the method.<p>Is it a consequence of input photo quality, or something else?</div><br/><div id="38635025" class="c"><input type="checkbox" id="c-38635025" checked=""/><div class="controls bullet"><span class="by">duckworthd</span><span>|</span><a href="#38633386">parent</a><span>|</span><label class="collapse" for="c-38635025">[-]</label><label class="expand" for="c-38635025">[2 more]</label></div><br/><div class="children"><div class="content">&gt; This is __really__ stunning work<p>Thank you :)<p>&gt; Is it a consequence of input photo quality, or something else?<p>It&#x27;s more a consequence of spatial resolution: the bigger the space, the more voxels you need to maintain a fixed resolution (e.g. 1 mm^3). At some point, we have to give up spatial resolution to represent larger scenes.<p>A second limitation is the teacher model we&#x27;re distilling. Zip-NeRF (<a href="https:&#x2F;&#x2F;jonbarron.info&#x2F;zipnerf&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;jonbarron.info&#x2F;zipnerf&#x2F;</a>) is good, but it&#x27;s not _perfect_. SMERF reconstruction quality is upper-bounded by its Zip-NeRF teacher.</div><br/></div></div></div></div></div></div></div></div></div></body></html>