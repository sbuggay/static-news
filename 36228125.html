<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1686214885893" as="style"/><link rel="stylesheet" href="styles.css?v=1686214885893"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.nature.com/articles/s41586-023-06004-9">Deepmind Alphadev: Faster sorting algorithms discovered using deep RL</a> <span class="domain">(<a href="https://www.nature.com">www.nature.com</a>)</span></div><div class="subtext"><span>anjneymidha</span> | <span>153 comments</span></div><br/><div><div id="36229099" class="c"><input type="checkbox" id="c-36229099" checked=""/><div class="controls bullet"><span class="by">danlark</span><span>|</span><a href="#36229068">next</a><span>|</span><label class="collapse" for="c-36229099">[-]</label><label class="expand" for="c-36229099">[25 more]</label></div><br/><div class="children"><div class="content">You can see hashing optimizations as well <a href="https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;alphadev-discovers-faster-sorting-algorithms" rel="nofollow">https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;alphadev-discovers-faster-sort...</a>, <a href="https:&#x2F;&#x2F;github.com&#x2F;abseil&#x2F;abseil-cpp&#x2F;commit&#x2F;74eee2aff683cc7dcd2dbaa69b2c654596d8024e">https:&#x2F;&#x2F;github.com&#x2F;abseil&#x2F;abseil-cpp&#x2F;commit&#x2F;74eee2aff683cc7d...</a><p>I was one of the members who reviewed expertly what has been done both in sorting and hashing. Overall it&#x27;s more about assembly, finding missed compiler optimizations and balancing between correctness and distribution (in hashing in particular).<p>It was not revolutionary in a sense it hasn&#x27;t found completely new approaches but converged to something incomprehensible for humans but relatively good for performance which proves the point that optimal programs are very inhuman.<p>Note that for instructions in sorting, removing them does not always lead to better performance, for example, instructions can run in parallel and the effect can be less profound. Benchmarks can lie and compiler could do something differently when recompiling the sort3 function which was changed.<p>For hashing it was even funnier, very small strings up to 64 bit already used 3 instructions like add some constant -&gt; multiply 64x64 -&gt; xor upper&#x2F;lower. For bigger ones the question becomes more complicated, that&#x27;s why 9-16 was a better spot and it simplified from 2 multiplications to just one and a rotation. Distribution on real workloads was good, it almost passed smhasher and we decided it was good enough to try out in prod. We did not rollback as you can see from abseil :)<p>But even given all that, it was fascinating to watch how this system was searching and was able to find particular programs can be further simplified. Kudos to everyone involved, it&#x27;s a great incremental change that can bring more results in the future.</div><br/><div id="36238211" class="c"><input type="checkbox" id="c-36238211" checked=""/><div class="controls bullet"><span class="by">moonchild</span><span>|</span><a href="#36229099">parent</a><span>|</span><a href="#36229538">next</a><span>|</span><label class="collapse" for="c-36238211">[-]</label><label class="expand" for="c-36238211">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 9-16 was a better spot and it simplified from 2 multiplications to just one and a rotation<p>I&#x27;m very confused as to why rotation was at all useful.  Xoring with a random-ish constant makes sense, because the constant has high entropy and is likely to decorrelate bits from the input (also can use a different constant per hash table).  But rotating by a constant—and a fixed one at that—seems like it just accounts for expected input distribution.  Especially (assuming this is intended for text) if shifting by a value &gt;8 makes a significant difference (vs shifting by the same value mod 8), it smells like serious overfit.  Could be useful for something like a perfect hash, but seems problematic and prone to issues as a general hash.<p>Edit: to make my objection clearer: the hash simply replaces lo with rotr(lo, 53).  If rotr(lo, 53) performs significantly better than rotr(lo, 53 mod 8), then that implies the following.  I can take a set of strings, and I can apply <i>the same</i> permutation to the characters of all of the strings in the set, and this will significantly affect the quality of the hash function.  That seems like an undesirable property, even for a non-cryptographic hash.</div><br/></div></div><div id="36229538" class="c"><input type="checkbox" id="c-36229538" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36229099">parent</a><span>|</span><a href="#36238211">prev</a><span>|</span><a href="#36230197">next</a><span>|</span><label class="collapse" for="c-36229538">[-]</label><label class="expand" for="c-36229538">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;m disappointed a the hashing is just based on training on microbenchmarks and SMHasher, rather than designing a fast _provably_ universal hash.
Suites like SMHasher are never complete. They are just trying to catch the most common weaknesses. If you train on the test cases you&#x27;ll only get an algorithm that passes the tests, but people can always find a set of values on which you will do badly.</div><br/><div id="36231714" class="c"><input type="checkbox" id="c-36231714" checked=""/><div class="controls bullet"><span class="by">eklitzke</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36229538">parent</a><span>|</span><a href="#36229693">next</a><span>|</span><label class="collapse" for="c-36231714">[-]</label><label class="expand" for="c-36231714">[4 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re confusing proving that the hash function is collision resistant with the other goal which is hashing speed. If you really need a collision resistant hash you need to use a cryptographic hash function, but outside of cryptographic applications that is rarely the requirement. And (huge caveat, this isn&#x27;t my domain expertise) I&#x27;m not sure what security properties are really &quot;proven&quot; about existing cryptographic hash functions, AFAIK existing cryptographic hash functions are considered secure because we don&#x27;t know how to break them, not because of some fundamental mathematical property about them.<p>For the other 99.999% of hashing applications there is a balance between collision resistance and hashing latency. For example, in a hash table (probably the most common use for a non-cryptographic hash function) there is a cost incurred by hash collisions because lookups on keys with collisions may have to do extra probing. On the other hand, <i>every</i> hash table lookup requires doing at least one hash operation, regardless of whether or not it collides. So it may make sense to have a slightly worse hash function (in the sense that it is more likely to have collisions with pathological inputs) if it has slightly lower latency. The only way to really know what is faster for a real world application is to have some kind of benchmark to train against as a loss function.</div><br/><div id="36231928" class="c"><input type="checkbox" id="c-36231928" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36231714">parent</a><span>|</span><a href="#36232110">next</a><span>|</span><label class="collapse" for="c-36231928">[-]</label><label class="expand" for="c-36231928">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think you&#x27;re confusing proving that the hash function is collision resistant with the other goal which is hashing speed. If you really need a collision resistant hash you need to use a cryptographic hash function.<p>I wish this misconception would die. There is a great theory of algorithmic probabilistic hash functions, completely distinct from cryptographic hash functions. If you are designing a hash table, or a different algorithm using a hash function, you nearly always want the former kind.<p>The idea is that `Pr[h(x) = h(y)]` is small _no matter the inputs x and y_.
Here the probability is over the random seed of h.
Lots of good hash functions, like UMASH (<a href="https:&#x2F;&#x2F;engineering.backtrace.io&#x2F;2020-08-24-umash-fast-enough-almost-universal-fingerprinting&#x2F;" rel="nofollow">https:&#x2F;&#x2F;engineering.backtrace.io&#x2F;2020-08-24-umash-fast-enoug...</a>) has this guarantee.
Other fast hash functions, like MURMUR don&#x27;t.<p>When a function doesn&#x27;t have this guarantee, it means I can find sets of values x1, x2, ... that will likely collide under _any_ or most seeds!
Sure, if your inputs are basically random, this probably won&#x27;t happen, but people can still use this to DDoS your hash table, or whatever you are coding.<p>Notice again, this has nothing to do with cryptography. It is all about probabilistic guarantees.
You can&#x27;t just test the hash function on a fixed number of inputs and say it&#x27;s good, since you may just have moved the &quot;bad set&quot; to somewhere else.<p>In this day and age there are super fast algorithmic hash functions with guaranteed low expected collisions. It&#x27;s just silly to use one that you can break so easily.</div><br/></div></div><div id="36232110" class="c"><input type="checkbox" id="c-36232110" checked=""/><div class="controls bullet"><span class="by">tga_d</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36231714">parent</a><span>|</span><a href="#36231928">prev</a><span>|</span><a href="#36233786">next</a><span>|</span><label class="collapse" for="c-36232110">[-]</label><label class="expand" for="c-36232110">[1 more]</label></div><br/><div class="children"><div class="content">&gt;If you really need a collision resistant hash you need to use a cryptographic hash function, but outside of cryptographic applications that is rarely the requirement.<p>There are reasons to use (strongly) collision resistant hashes outside of cryptographic settings. E.g., the default Rust hash function, used in hash maps and sets, has strong collision resistance, because otherwise you could open up applications to DoS attacks (the attacker uses lots of inserts with collisions to kill performance of accesses and further inserts at those buckets).[0]<p>&gt;I&#x27;m not sure what security properties are really &quot;proven&quot; about existing cryptographic hash functions, AFAIK existing cryptographic hash functions are considered secure because we don&#x27;t know how to break them, not because of some fundamental mathematical property about them.<p>There are provably secure hash functions[1] (typically using the same sort of primitives as public key crypto), but they&#x27;re generally only used when certain properties need to be composed, and are often less secure than the non-provable ones in practice anyway. This is pretty similar to the state of symmetric vs. asymmetric cryptography in general: primitives like RSA, DH, etc. have much stronger proofs than AES, but algorithms built using AES for security are generally viewed as a lot less likely to be broken any time soon than algorithms built using typical asymmetric primitives for security, even ignoring things like quantum advantage.<p>[0] <a href="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;std&#x2F;collections&#x2F;struct.HashMap.html" rel="nofollow">https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;std&#x2F;collections&#x2F;struct.HashMap.htm...</a><p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Security_of_cryptographic_hash_functions#More_practical_provably_secure_hash_functions" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Security_of_cryptographic_hash...</a></div><br/></div></div><div id="36233786" class="c"><input type="checkbox" id="c-36233786" checked=""/><div class="controls bullet"><span class="by">Someone</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36231714">parent</a><span>|</span><a href="#36232110">prev</a><span>|</span><a href="#36229693">next</a><span>|</span><label class="collapse" for="c-36233786">[-]</label><label class="expand" for="c-36233786">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m not sure what security properties are really &quot;proven&quot; about existing cryptographic hash functions<p>AFAIK, we don’t even know whether trapdoor functions <i>exist</i>.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trapdoor_function" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trapdoor_function</a>:<p><i>“As of 2004, the best known trapdoor function (family) candidates are the RSA and Rabin families of functions”</i><p>Also note that the ‘examples’ section starts with:<p><i>“In the following two examples, we always assume it is difficult to factorize a large composite number (see Integer factorization).”</i></div><br/></div></div></div></div><div id="36229693" class="c"><input type="checkbox" id="c-36229693" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36229538">parent</a><span>|</span><a href="#36231714">prev</a><span>|</span><a href="#36230197">next</a><span>|</span><label class="collapse" for="c-36229693">[-]</label><label class="expand" for="c-36229693">[3 more]</label></div><br/><div class="children"><div class="content">Indeed, and this has been the case for quite a while now. You can <i>always</i> improve on some general algorithm by taking advantage of knowledge of the data but that never generalizes and usually leads to either worse performance on other data and&#x2F;or new pathological cases that result in results that are unusable.<p>It&#x27;s an instance of overfitting.</div><br/><div id="36236785" class="c"><input type="checkbox" id="c-36236785" checked=""/><div class="controls bullet"><span class="by">matteoraso</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36229693">parent</a><span>|</span><a href="#36230808">next</a><span>|</span><label class="collapse" for="c-36236785">[-]</label><label class="expand" for="c-36236785">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Indeed, and this has been the case for quite a while now. You can always improve on some general algorithm by taking advantage of knowledge of the data but that never generalizes and usually leads to either worse performance on other data and&#x2F;or new pathological cases that result in results that are unusable.<p>Deepmind did the exact same thing with AlphaTensor. While they do some geniunely incredible things, there&#x27;s always a massive caveat that the media ignores. Still, I think it&#x27;s great that they figured out a way to search a massive space where most of the solutions are wrong, and with only 16 TPUs running for 2 days max. Hopefully this can be repurposed into a more useful program, like one that finds proofs for theorems.</div><br/></div></div><div id="36230808" class="c"><input type="checkbox" id="c-36230808" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36229693">parent</a><span>|</span><a href="#36236785">prev</a><span>|</span><a href="#36230197">next</a><span>|</span><label class="collapse" for="c-36230808">[-]</label><label class="expand" for="c-36230808">[1 more]</label></div><br/><div class="children"><div class="content">Ship the optimization framework in with the application, sample from the user data, and optimize for that? It isn’t overfitting if you overfit on the data you care about, right?</div><br/></div></div></div></div></div></div><div id="36230197" class="c"><input type="checkbox" id="c-36230197" checked=""/><div class="controls bullet"><span class="by">CalChris</span><span>|</span><a href="#36229099">parent</a><span>|</span><a href="#36229538">prev</a><span>|</span><a href="#36230091">next</a><span>|</span><label class="collapse" for="c-36230197">[-]</label><label class="expand" for="c-36230197">[2 more]</label></div><br/><div class="children"><div class="content">This sounds like a more intelligent version of superoptimization. The original Masselin SO, albeit for its time, also created surprising results which is similar to AlphaDev&#x27;s <i>incomprehensible for humans</i>. You see the same thing in computer chess which Agadmator calls <i>disgusting engine lines</i>.<p><a href="https:&#x2F;&#x2F;courses.cs.washington.edu&#x2F;courses&#x2F;cse501&#x2F;15sp&#x2F;papers&#x2F;massalin.pdf" rel="nofollow">https:&#x2F;&#x2F;courses.cs.washington.edu&#x2F;courses&#x2F;cse501&#x2F;15sp&#x2F;papers...</a></div><br/><div id="36238278" class="c"><input type="checkbox" id="c-36238278" checked=""/><div class="controls bullet"><span class="by">mtlmtlmtlmtl</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36230197">parent</a><span>|</span><a href="#36230091">next</a><span>|</span><label class="collapse" for="c-36238278">[-]</label><label class="expand" for="c-36238278">[1 more]</label></div><br/><div class="children"><div class="content">Stockfish actually use machine learning to pick the best magic numbers for their code.</div><br/></div></div></div></div><div id="36230091" class="c"><input type="checkbox" id="c-36230091" checked=""/><div class="controls bullet"><span class="by">hajile</span><span>|</span><a href="#36229099">parent</a><span>|</span><a href="#36230197">prev</a><span>|</span><a href="#36229780">next</a><span>|</span><label class="collapse" for="c-36230091">[-]</label><label class="expand" for="c-36230091">[3 more]</label></div><br/><div class="children"><div class="content">To what extent is this simply working around the weirdness of x86? Do these improvements apply to something like MIPS, ARM64, or RISC-V that have inherently simpler ISAs?</div><br/><div id="36231221" class="c"><input type="checkbox" id="c-36231221" checked=""/><div class="controls bullet"><span class="by">danlark</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36230091">parent</a><span>|</span><a href="#36229780">next</a><span>|</span><label class="collapse" for="c-36231221">[-]</label><label class="expand" for="c-36231221">[2 more]</label></div><br/><div class="children"><div class="content">In this particular case they were universal but in paper it&#x27;s said the optimizations were done on x86. One of the ideas was to use LLVM IR but intuition for optimizer over optimizer was unlikely to work properly.</div><br/><div id="36233917" class="c"><input type="checkbox" id="c-36233917" checked=""/><div class="controls bullet"><span class="by">ndesaulniers</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36231221">parent</a><span>|</span><a href="#36229780">next</a><span>|</span><label class="collapse" for="c-36233917">[-]</label><label class="expand" for="c-36233917">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but intuition for optimizer over optimizer was unlikely to work properly.<p>Wut?</div><br/></div></div></div></div></div></div><div id="36229780" class="c"><input type="checkbox" id="c-36229780" checked=""/><div class="controls bullet"><span class="by">13of40</span><span>|</span><a href="#36229099">parent</a><span>|</span><a href="#36230091">prev</a><span>|</span><a href="#36230080">next</a><span>|</span><label class="collapse" for="c-36229780">[-]</label><label class="expand" for="c-36229780">[1 more]</label></div><br/><div class="children"><div class="content">&gt; something incomprehensible for humans<p>This might be buggy whip talk, but I wonder if you could take the same system and apply it to smaller problems (e.g. computing an 8-bit hash) so the novel techniques could be identified and used by humans.</div><br/></div></div><div id="36230080" class="c"><input type="checkbox" id="c-36230080" checked=""/><div class="controls bullet"><span class="by">cabalamat</span><span>|</span><a href="#36229099">parent</a><span>|</span><a href="#36229780">prev</a><span>|</span><a href="#36230236">next</a><span>|</span><label class="collapse" for="c-36230080">[-]</label><label class="expand" for="c-36230080">[5 more]</label></div><br/><div class="children"><div class="content">&gt; proves the point that optimal programs are very inhuman<p>Maybe there should be an AI that produces optimally-readable&#x2F;understandable programs? That&#x27;s what I would want if I was adding the output to a codebase.</div><br/><div id="36231839" class="c"><input type="checkbox" id="c-36231839" checked=""/><div class="controls bullet"><span class="by">whatever1</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36230080">parent</a><span>|</span><a href="#36230375">next</a><span>|</span><label class="collapse" for="c-36231839">[-]</label><label class="expand" for="c-36231839">[1 more]</label></div><br/><div class="children"><div class="content">Optimal routing of delivery vehicles for UPS&#x2F;Fedex etc is also non-compressible to the drivers, so the planners often intentionally generate suboptimal solutions.<p>A suboptimal implemented solution is a better than an optimal not implemented one.</div><br/></div></div><div id="36230375" class="c"><input type="checkbox" id="c-36230375" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36230080">parent</a><span>|</span><a href="#36231839">prev</a><span>|</span><a href="#36231100">next</a><span>|</span><label class="collapse" for="c-36230375">[-]</label><label class="expand" for="c-36230375">[1 more]</label></div><br/><div class="children"><div class="content">It’s not that is written like obfuscated, the routine&#x2F; algo is just hard to understand even if they commented every line.  Likely some recursive trick is involved, those are always hard to follow</div><br/></div></div><div id="36231100" class="c"><input type="checkbox" id="c-36231100" checked=""/><div class="controls bullet"><span class="by">make3</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36230080">parent</a><span>|</span><a href="#36230375">prev</a><span>|</span><a href="#36230236">next</a><span>|</span><label class="collapse" for="c-36231100">[-]</label><label class="expand" for="c-36231100">[2 more]</label></div><br/><div class="children"><div class="content">that&#x27;s what LLMs can with rl from human (or ai) readability feedback &amp; instruction tuning + prompting. we will 100% see this if gpt-4 doesn&#x27;t already do this.</div><br/><div id="36231316" class="c"><input type="checkbox" id="c-36231316" checked=""/><div class="controls bullet"><span class="by">ska</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36231100">parent</a><span>|</span><a href="#36230236">next</a><span>|</span><label class="collapse" for="c-36231316">[-]</label><label class="expand" for="c-36231316">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t classify any of the output I&#x27;ve seen so far as &quot;optimally readable&#x2F;understandable&quot;.<p>Some if it looks pretty ok, especially where it overlaps with well established approaches.</div><br/></div></div></div></div></div></div><div id="36230236" class="c"><input type="checkbox" id="c-36230236" checked=""/><div class="controls bullet"><span class="by">thesz</span><span>|</span><a href="#36229099">parent</a><span>|</span><a href="#36230080">prev</a><span>|</span><a href="#36230923">next</a><span>|</span><label class="collapse" for="c-36230236">[-]</label><label class="expand" for="c-36230236">[1 more]</label></div><br/><div class="children"><div class="content">So it works as a superoptimizer of sorts.</div><br/></div></div><div id="36230923" class="c"><input type="checkbox" id="c-36230923" checked=""/><div class="controls bullet"><span class="by">gumby</span><span>|</span><a href="#36229099">parent</a><span>|</span><a href="#36230236">prev</a><span>|</span><a href="#36231267">next</a><span>|</span><label class="collapse" for="c-36230923">[-]</label><label class="expand" for="c-36230923">[2 more]</label></div><br/><div class="children"><div class="content">Your description makes the approach sound like applying ca 1980s simulated annealing, also a form of gradient descent.  Am I missing something?</div><br/><div id="36231413" class="c"><input type="checkbox" id="c-36231413" checked=""/><div class="controls bullet"><span class="by">ska</span><span>|</span><a href="#36229099">root</a><span>|</span><a href="#36230923">parent</a><span>|</span><a href="#36231267">next</a><span>|</span><label class="collapse" for="c-36231413">[-]</label><label class="expand" for="c-36231413">[1 more]</label></div><br/><div class="children"><div class="content">This doesn&#x27;t really sound like SA, which is a principled approach to avoid the local min problem in descent algorithms and end up with a true global optimization.  The general result is clean and impractical, the approximations hard to analyze.</div><br/></div></div></div></div><div id="36231267" class="c"><input type="checkbox" id="c-36231267" checked=""/><div class="controls bullet"><span class="by">sytelus</span><span>|</span><a href="#36229099">parent</a><span>|</span><a href="#36230923">prev</a><span>|</span><a href="#36229068">next</a><span>|</span><label class="collapse" for="c-36231267">[-]</label><label class="expand" for="c-36231267">[1 more]</label></div><br/><div class="children"><div class="content">If more compute is spent than before but in parallel to reduce latency then wouldn&#x27;t this increase power? Shouldn&#x27;t latency and power both be objective?</div><br/></div></div></div></div><div id="36229068" class="c"><input type="checkbox" id="c-36229068" checked=""/><div class="controls bullet"><span class="by">fwlr</span><span>|</span><a href="#36229099">prev</a><span>|</span><a href="#36231147">next</a><span>|</span><label class="collapse" for="c-36229068">[-]</label><label class="expand" for="c-36229068">[8 more]</label></div><br/><div class="children"><div class="content">Some very cool improvements found in already highly optimized algorithms.<p>They found that in a sorting network handling 3 inputs, the AI found a way to save an instruction by reducing a &quot;min(A, B, C)&quot; operation to just &quot;min(A, B)&quot; by taking advantage of the fact that previous operations guaranteed that B &lt;= C. They also found that in a sorting network handling 4 inputs, when it is part of a &quot;sort 8&quot; network, there are similar guarantees (D &gt;= min(A, C) in this case) that can be taken advantage of to remove an instruction as well. The compiler may not be able to compete with hand-written assembly, but it seems an AI can hand-write assembly code that&#x27;s even better in some cases.<p>Another improvement is also very cool. They discuss VarSort4, which takes a list that may be 2, 3, or 4 elements long, and sorts it. The existing algorithm is<p><pre><code>    if (len = 4) { 
        sort4
    }
    elif (len = 3) {
        sort3
    }
    elif (len = 2) {
        sort2
    }

</code></pre>
The AI found an algorithm that looks totally different:<p><pre><code>    if (len = 2) {
        sort2
    }
    else {
        sort3
        if (len = 4) {
            sortspecial
        }
    }
</code></pre>
It&#x27;s pretty wild! It immediately runs Sort3 on something that may be either 3 elements or 4 elements long, and only afterwards does it check to see how long it really is. If it&#x27;s 3 elements long, we&#x27;re done; otherwise, run Sort4 - but because (having already run Sort3) you know the first three elements are sorted, you can use a special and much simpler algorithm to simply put the 4th element in the right spot.<p>Very cool. Improving on core LLVM sorting algorithms that have already been heavily hand-optimized by the best in the world is definitely a &quot;it&#x27;s 1997 and Deep Blue defeats the World Champion in chess&quot; kind of feeling.</div><br/><div id="36229745" class="c"><input type="checkbox" id="c-36229745" checked=""/><div class="controls bullet"><span class="by">ComputerGuru</span><span>|</span><a href="#36229068">parent</a><span>|</span><a href="#36229554">next</a><span>|</span><label class="collapse" for="c-36229745">[-]</label><label class="expand" for="c-36229745">[2 more]</label></div><br/><div class="children"><div class="content">Interesting that it took AI to pull this off. I think mutagen testing would have discovered the first (by virtue of checking which code isn’t necessary <i>globally</i>) though likely not the second (which needs a new branch, unless that branch was already there?).</div><br/><div id="36229845" class="c"><input type="checkbox" id="c-36229845" checked=""/><div class="controls bullet"><span class="by">fkarg</span><span>|</span><a href="#36229068">root</a><span>|</span><a href="#36229745">parent</a><span>|</span><a href="#36229554">next</a><span>|</span><label class="collapse" for="c-36229845">[-]</label><label class="expand" for="c-36229845">[1 more]</label></div><br/><div class="children"><div class="content">As I understand it it kind of _did that_, just in an extremely guided kind of way, which is why it produced results in some reasonable amount of time (probably)</div><br/></div></div></div></div><div id="36229554" class="c"><input type="checkbox" id="c-36229554" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36229068">parent</a><span>|</span><a href="#36229745">prev</a><span>|</span><a href="#36236351">next</a><span>|</span><label class="collapse" for="c-36229554">[-]</label><label class="expand" for="c-36229554">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m surprised they only report results up to sort5.
It seems at that level, you could just iterate through all possible programs.
AI generated code seems more interested once you get to 10+ values, where classical methods break down.</div><br/><div id="36231577" class="c"><input type="checkbox" id="c-36231577" checked=""/><div class="controls bullet"><span class="by">cypherpunks01</span><span>|</span><a href="#36229068">root</a><span>|</span><a href="#36229554">parent</a><span>|</span><a href="#36231641">next</a><span>|</span><label class="collapse" for="c-36231577">[-]</label><label class="expand" for="c-36231577">[1 more]</label></div><br/><div class="children"><div class="content">I believe that&#x27;s because above 5 elements, fixed sorting networks are no longer used. Introsort takes over and dispatches to insertion sort, quicksort, or heap sort as appropriate.<p>Divide and conquer strategies are used for larger sorts, and the smaller arrays could include the fixed lengths 3, 4, 5.</div><br/></div></div><div id="36231641" class="c"><input type="checkbox" id="c-36231641" checked=""/><div class="controls bullet"><span class="by">bitshiftfaced</span><span>|</span><a href="#36229068">root</a><span>|</span><a href="#36229554">parent</a><span>|</span><a href="#36231577">prev</a><span>|</span><a href="#36236351">next</a><span>|</span><label class="collapse" for="c-36231641">[-]</label><label class="expand" for="c-36231641">[1 more]</label></div><br/><div class="children"><div class="content">The paper notes that they brute forced all solutions for sort3 to verify that it was optimal. It said that this wasn&#x27;t possible for 4+.</div><br/></div></div></div></div><div id="36236351" class="c"><input type="checkbox" id="c-36236351" checked=""/><div class="controls bullet"><span class="by">dools</span><span>|</span><a href="#36229068">parent</a><span>|</span><a href="#36229554">prev</a><span>|</span><a href="#36231147">next</a><span>|</span><label class="collapse" for="c-36236351">[-]</label><label class="expand" for="c-36236351">[2 more]</label></div><br/><div class="children"><div class="content">“ The compiler may not be able to compete with hand-written assembly, but it seems an AI can hand-write assembly code that&#x27;s even better in some cases.”<p>This made me think “imagine if AI was the compiler”, that is to say you went from C or whatever to assembly via AI directly so it was “hand writing” the equivalent assembly for your instructions instead of using generic compilation.<p>We might find everything runs much faster.</div><br/><div id="36236922" class="c"><input type="checkbox" id="c-36236922" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#36229068">root</a><span>|</span><a href="#36236351">parent</a><span>|</span><a href="#36231147">next</a><span>|</span><label class="collapse" for="c-36236922">[-]</label><label class="expand" for="c-36236922">[1 more]</label></div><br/><div class="children"><div class="content">Everything except the compiler, that is</div><br/></div></div></div></div></div></div><div id="36231147" class="c"><input type="checkbox" id="c-36231147" checked=""/><div class="controls bullet"><span class="by">orlp</span><span>|</span><a href="#36229068">prev</a><span>|</span><a href="#36228824">next</a><span>|</span><label class="collapse" for="c-36231147">[-]</label><label class="expand" for="c-36231147">[47 more]</label></div><br/><div class="children"><div class="content">&gt; AlphaDev uncovered new sorting algorithms that led to improvements in the LLVM libc++ sorting library that were up to 70% faster for shorter sequences and about 1.7% faster for sequences exceeding 250,000 elements.<p>As someone that knows a thing or two about sorting... bullshit. No new algorithms were uncovered, and the work here did not <i>lead</i> to the claimed improvements.<p>They found a sequence of assembly that saves... one MOV. That&#x27;s it. And it&#x27;s not even novel, it&#x27;s simply an unrolled insertion sort on three elements. That their patch for libc++ is 70% faster for small inputs is only due to the library not having an efficient implementation with a *branchless* sorting network beforehand. Those are not novel either, they already exist, made by humans.<p>&gt; By open sourcing our new sorting algorithms in the main C++ library, millions of developers and companies around the world now use it on AI applications across industries from cloud computing and online shopping to supply chain management. This is the first change to this part of the sorting library in over a decade and the first time an algorithm designed through reinforcement learning has been added to this library. We see this as an important stepping stone for using AI to optimise the world’s code, one algorithm at a time.<p>I&#x27;m happy for the researchers that the reinforcement learning approach worked, and that it gave good code. But the paper and surrounding press release is self-aggrandizing in both its results and impact. That this is the first change to &#x27;this part&#x27; of the sorting routine in a decade is also just completely cherry-picked. For example, I would say that my 2014 report and (ignored patch of) the fact that the libc++ sorting routine was QUADRATIC (<a href="https:&#x2F;&#x2F;bugs.llvm.org&#x2F;show_bug.cgi?id=20837" rel="nofollow">https:&#x2F;&#x2F;bugs.llvm.org&#x2F;show_bug.cgi?id=20837</a>) finally being fixed late 2021 <a href="https:&#x2F;&#x2F;reviews.llvm.org&#x2F;D113413" rel="nofollow">https:&#x2F;&#x2F;reviews.llvm.org&#x2F;D113413</a> is quite the notable change. If anything it shows that there wasn&#x27;t a particularly active development schedule on the libc++ sorting routine the past decade.</div><br/><div id="36234903" class="c"><input type="checkbox" id="c-36234903" checked=""/><div class="controls bullet"><span class="by">saiojd</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36232190">next</a><span>|</span><label class="collapse" for="c-36234903">[-]</label><label class="expand" for="c-36234903">[9 more]</label></div><br/><div class="children"><div class="content">I feel like your take is overly cynical. The fact that humans can do the same thing by hand is not really the point. The contribution lies in the fact that their method derived this improvement *automatically*, which is where the impact lies. No one cares all that much if a human can make a sorting routine 2% faster, but if a program can do it, it suddenly becomes interesting (since it suggests that a similar approach can be applied to many other routines).</div><br/><div id="36235057" class="c"><input type="checkbox" id="c-36235057" checked=""/><div class="controls bullet"><span class="by">orlp</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36234903">parent</a><span>|</span><a href="#36236707">next</a><span>|</span><label class="collapse" for="c-36235057">[-]</label><label class="expand" for="c-36235057">[4 more]</label></div><br/><div class="children"><div class="content">I am not cynical about the research itself, I am critical of claims such as &quot;new sorting algorithm uncovered&quot;, &quot;up to 70% faster&quot;, or &quot;first change in a decade&quot;. The research is good. The achieved results are massively inflated.<p>What they achieved: automatically generated good code.<p>What they claim: automatically generated code that is revolutionary and an improvement on the state of the art.<p>And as another commenter noted, superoptimizers are also already a thing: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Superoptimization" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Superoptimization</a><p>There&#x27;s also automatic searching being done on faster sorting networks that <i>actually</i> recently produced better than state of the art sorting networks: <a href="https:&#x2F;&#x2F;github.com&#x2F;bertdobbelaere&#x2F;SorterHunter">https:&#x2F;&#x2F;github.com&#x2F;bertdobbelaere&#x2F;SorterHunter</a></div><br/><div id="36235354" class="c"><input type="checkbox" id="c-36235354" checked=""/><div class="controls bullet"><span class="by">saiojd</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36235057">parent</a><span>|</span><a href="#36235088">next</a><span>|</span><label class="collapse" for="c-36235354">[-]</label><label class="expand" for="c-36235354">[1 more]</label></div><br/><div class="children"><div class="content">While I agree that the claims are hyperbolic, I think you are approaching this paper from the point of view of someone who knows a lot about sorting. Because of this, its normal that the claims of these guys who probably don&#x27;t know much about it are grating for you.<p>But, at its core, this is really a RL paper. The objective is to see how far a generic approach can work while understanding as little as possible about the actual domain. After AlphaGo exceeded expectations, the question becomes: &quot;What else can RL do, and can it do anything actually useful?&quot;, and this paper seems to suggest that it can optimize code pretty well! I&#x27;m really not sure they are self-aggrandizing in terms of impact. The impact of an approach like this could potentially be very large (although I&#x27;m not saying that it actually is, I don&#x27;t know enough).</div><br/></div></div><div id="36235088" class="c"><input type="checkbox" id="c-36235088" checked=""/><div class="controls bullet"><span class="by">touisteur</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36235057">parent</a><span>|</span><a href="#36235354">prev</a><span>|</span><a href="#36237111">next</a><span>|</span><label class="collapse" for="c-36235088">[-]</label><label class="expand" for="c-36235088">[1 more]</label></div><br/><div class="children"><div class="content">I somehow agree that I&#x27;d be far more impressed by something that would find optimal or even just better sorting (or selection) networks for sizes higher than 17 (last time I looked at SOTA).</div><br/></div></div><div id="36237111" class="c"><input type="checkbox" id="c-36237111" checked=""/><div class="controls bullet"><span class="by">runsWphotons</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36235057">parent</a><span>|</span><a href="#36235088">prev</a><span>|</span><a href="#36236707">next</a><span>|</span><label class="collapse" for="c-36237111">[-]</label><label class="expand" for="c-36237111">[1 more]</label></div><br/><div class="children"><div class="content">how automatically generated was the code that wrote the code</div><br/></div></div></div></div><div id="36236707" class="c"><input type="checkbox" id="c-36236707" checked=""/><div class="controls bullet"><span class="by">x86x87</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36234903">parent</a><span>|</span><a href="#36235057">prev</a><span>|</span><a href="#36238012">next</a><span>|</span><label class="collapse" for="c-36236707">[-]</label><label class="expand" for="c-36236707">[1 more]</label></div><br/><div class="children"><div class="content">i don&#x27;t read it as cynical. It&#x27;s fair game to call bullshit on bullshit. If an approach exists and is known the &quot;insert your favorite AI here&quot; does not discover anything.</div><br/></div></div><div id="36238012" class="c"><input type="checkbox" id="c-36238012" checked=""/><div class="controls bullet"><span class="by">mtlmtlmtlmtl</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36234903">parent</a><span>|</span><a href="#36236707">prev</a><span>|</span><a href="#36234978">next</a><span>|</span><label class="collapse" for="c-36238012">[-]</label><label class="expand" for="c-36238012">[1 more]</label></div><br/><div class="children"><div class="content">Automatic tuning and optimisation of code is not new.</div><br/></div></div><div id="36234978" class="c"><input type="checkbox" id="c-36234978" checked=""/><div class="controls bullet"><span class="by">smeagull</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36234903">parent</a><span>|</span><a href="#36238012">prev</a><span>|</span><a href="#36232190">next</a><span>|</span><label class="collapse" for="c-36234978">[-]</label><label class="expand" for="c-36234978">[2 more]</label></div><br/><div class="children"><div class="content">A thing that is also not novel. People have done search for optimisations for at least the past decade.</div><br/><div id="36235241" class="c"><input type="checkbox" id="c-36235241" checked=""/><div class="controls bullet"><span class="by">saiojd</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36234978">parent</a><span>|</span><a href="#36232190">next</a><span>|</span><label class="collapse" for="c-36235241">[-]</label><label class="expand" for="c-36235241">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but the whole point is to reduce this kind of search to RL, which is a very general framework. Their paper shows that such a generic approach can solve a very specific problem, and solve it well. But, their paper is about improving RL, not about improving sorting.</div><br/></div></div></div></div></div></div><div id="36232190" class="c"><input type="checkbox" id="c-36232190" checked=""/><div class="controls bullet"><span class="by">blazespin</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36234903">prev</a><span>|</span><a href="#36237669">next</a><span>|</span><label class="collapse" for="c-36232190">[-]</label><label class="expand" for="c-36232190">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, this type of grifting is very proforma for Researchers.  I used to stress about it, but realize it just sort of goes with the territory.<p>It&#x27;s also worth noting that the paper is blindingly obvious and everyone started doing this a long time ago but didn&#x27;t want to tip their cards.<p>And that&#x27;s the real contribution here - Google is tipping their cards.  We now have a rough baseline to compare our results against.</div><br/><div id="36234830" class="c"><input type="checkbox" id="c-36234830" checked=""/><div class="controls bullet"><span class="by">ryao</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232190">parent</a><span>|</span><a href="#36237669">next</a><span>|</span><label class="collapse" for="c-36234830">[-]</label><label class="expand" for="c-36234830">[1 more]</label></div><br/><div class="children"><div class="content">It is likely meant to help secure further research funds.</div><br/></div></div></div></div><div id="36237669" class="c"><input type="checkbox" id="c-36237669" checked=""/><div class="controls bullet"><span class="by">wsdookadr</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36232190">prev</a><span>|</span><a href="#36237219">next</a><span>|</span><label class="collapse" for="c-36237669">[-]</label><label class="expand" for="c-36237669">[2 more]</label></div><br/><div class="children"><div class="content">What&#x27;s surprising is that anyone would&#x27;ve expected an AI to come up with a brand-new algorithm with better complexity than pre-exsiting human-made solutions.
How could it possibly come up with something better when it doesn&#x27;t even understand how the original authors of qsort&#x2F;mergesort&#x2F;etc came up with their own..<p>Sure, it&#x27;s great PR for the company, but.. the results just aren&#x27;t there.</div><br/><div id="36238176" class="c"><input type="checkbox" id="c-36238176" checked=""/><div class="controls bullet"><span class="by">congoe</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36237669">parent</a><span>|</span><a href="#36237219">next</a><span>|</span><label class="collapse" for="c-36238176">[-]</label><label class="expand" for="c-36238176">[1 more]</label></div><br/><div class="children"><div class="content">How could AlphaZero possibly play better chess than humans when it doesn’t even understand the history of chess theory?<p>RL doesn’t stop at human levels</div><br/></div></div></div></div><div id="36237219" class="c"><input type="checkbox" id="c-36237219" checked=""/><div class="controls bullet"><span class="by">tlringer</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36237669">prev</a><span>|</span><a href="#36233581">next</a><span>|</span><label class="collapse" for="c-36237219">[-]</label><label class="expand" for="c-36237219">[1 more]</label></div><br/><div class="children"><div class="content">Every DeepMind press release is like this.</div><br/></div></div><div id="36233581" class="c"><input type="checkbox" id="c-36233581" checked=""/><div class="controls bullet"><span class="by">dundarious</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36237219">prev</a><span>|</span><a href="#36233139">next</a><span>|</span><label class="collapse" for="c-36233581">[-]</label><label class="expand" for="c-36233581">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I believe what they&#x27;re doing already exists in the literature as &quot;supercompilation&quot;, though good to see its application under any name.</div><br/></div></div><div id="36233139" class="c"><input type="checkbox" id="c-36233139" checked=""/><div class="controls bullet"><span class="by">danlark</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36233581">prev</a><span>|</span><a href="#36234882">next</a><span>|</span><label class="collapse" for="c-36233139">[-]</label><label class="expand" for="c-36233139">[2 more]</label></div><br/><div class="children"><div class="content">I agree on the sorting front. Removing one cmov is not likely to improve much.</div><br/><div id="36233291" class="c"><input type="checkbox" id="c-36233291" checked=""/><div class="controls bullet"><span class="by">orlp</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36233139">parent</a><span>|</span><a href="#36234882">next</a><span>|</span><label class="collapse" for="c-36233291">[-]</label><label class="expand" for="c-36233291">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not even a cmov. Look at Figure 3 in the paper: <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06004-9" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-023-06004-9</a><p>They eliminated a register-register mov.</div><br/></div></div></div></div><div id="36234882" class="c"><input type="checkbox" id="c-36234882" checked=""/><div class="controls bullet"><span class="by">as4296</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36233139">prev</a><span>|</span><a href="#36232145">next</a><span>|</span><label class="collapse" for="c-36234882">[-]</label><label class="expand" for="c-36234882">[2 more]</label></div><br/><div class="children"><div class="content">Lol I was about to say  that would be incredibly crazy if they found a new sorting algorithm. My time complexity in USACO bout to go crazy.</div><br/><div id="36235009" class="c"><input type="checkbox" id="c-36235009" checked=""/><div class="controls bullet"><span class="by">dataflow</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36234882">parent</a><span>|</span><a href="#36232145">next</a><span>|</span><label class="collapse" for="c-36235009">[-]</label><label class="expand" for="c-36235009">[1 more]</label></div><br/><div class="children"><div class="content">I get your sentiment but note that discovering a new algorithm doesn&#x27;t have to imply a better time complexity. Bubble Sort and Insertion Sort have the same time complexity but are different algorithms.</div><br/></div></div></div></div><div id="36232145" class="c"><input type="checkbox" id="c-36232145" checked=""/><div class="controls bullet"><span class="by">TaupeRanger</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36234882">prev</a><span>|</span><a href="#36232631">next</a><span>|</span><label class="collapse" for="c-36232145">[-]</label><label class="expand" for="c-36232145">[21 more]</label></div><br/><div class="children"><div class="content">This is DeepMind&#x27;s modus operandi. Every press release is just utterly hyperbolic nonsense that doesn&#x27;t withstand the slightest scrutiny. AlphaGo, AlphaFold, AlphaDev... they&#x27;ve done literally nothing to improve the human condition, and may have actually made things worse. Go players have DECREASED their Elo after playing AlphaGo (or just quit the game altogether). I would be embarrassed to be associated with DeepMind.</div><br/><div id="36234292" class="c"><input type="checkbox" id="c-36234292" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232145">parent</a><span>|</span><a href="#36233076">next</a><span>|</span><label class="collapse" for="c-36234292">[-]</label><label class="expand" for="c-36234292">[2 more]</label></div><br/><div class="children"><div class="content">This is unbelievably wrong. Deepmind has probably the best academic group in RL.  The difference between Deepmind and OpenAI is that Deepmind favors academic endeavours and novelty much more, while completely ignoring any commercialization or products, while OpenAI is the stark opposite in that they almost entirely focus on products first, and typically their academic endeavours are just slight modifications of other works scaled up.<p>Don&#x27;t get me wrong, Sutskyver (et al) has done incredibly good work previously, but when it comes to the products, they&#x27;re much more engineering and marketing polish than scientific endeavours.<p>Botvinick&#x27;s work on metaRL for example is an interesting direction that Deepmind has shown that few other companies that are only interested in engineering would venture towards.</div><br/><div id="36238204" class="c"><input type="checkbox" id="c-36238204" checked=""/><div class="controls bullet"><span class="by">mtlmtlmtlmtl</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36234292">parent</a><span>|</span><a href="#36233076">next</a><span>|</span><label class="collapse" for="c-36238204">[-]</label><label class="expand" for="c-36238204">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the thing with Deepmind though. They almost never actually end up advancing things because A) they don&#x27;t release weights and B) they don&#x27;t usually develop their ideas into useful tools themselves, forcing others to redo all their work.<p>So yeah, it&#x27;s essentially a PoC PR stunt factory. Just look at AlphaZero. They make a huge deal about a suspiciously set up match against Stockfish. Supposedly revolutionising computer chess. But the problem is the computer chess community had to redo <i>all of the work</i>, including all the training to build Leela Chess Zero. Due to lack of Google-sized datacentres the training took <i>years</i> to catch up to the weights in AlphaZero. Same thing with AlphaGo, same thing with transformers.<p>Now, in AI, usually getting a proof of concept is the easy part. Developing that into an idea that actually works in real world situations is usually the <i>hardest</i> part. I completely reject your idea that somehow the work by OpenAI is less worthy of recognition. I think that&#x27;s just nonsense.<p>And surely, Google created Deepmind to actually make <i>them</i> product ideas, not create new competitors, which is what has happened.</div><br/></div></div></div></div><div id="36233076" class="c"><input type="checkbox" id="c-36233076" checked=""/><div class="controls bullet"><span class="by">rcxdude</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232145">parent</a><span>|</span><a href="#36234292">prev</a><span>|</span><a href="#36233259">next</a><span>|</span><label class="collapse" for="c-36233076">[-]</label><label class="expand" for="c-36233076">[2 more]</label></div><br/><div class="children"><div class="content">I think this is a bit far in the other direction. Deepmind&#x27;s stuff is often deeply impressive, they just have a tendency to exaggerate on top of that.</div><br/><div id="36234050" class="c"><input type="checkbox" id="c-36234050" checked=""/><div class="controls bullet"><span class="by">jprd</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36233076">parent</a><span>|</span><a href="#36233259">next</a><span>|</span><label class="collapse" for="c-36234050">[-]</label><label class="expand" for="c-36234050">[1 more]</label></div><br/><div class="children"><div class="content">+1<p>There must be a &quot;demonstrate (1) DeepMind #Win per &lt;interval&gt;&quot; requirement somewhere that gets the once-over from the marketing dept. to meet some MBOs.</div><br/></div></div></div></div><div id="36233259" class="c"><input type="checkbox" id="c-36233259" checked=""/><div class="controls bullet"><span class="by">programmer_dude</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232145">parent</a><span>|</span><a href="#36233076">prev</a><span>|</span><a href="#36235469">next</a><span>|</span><label class="collapse" for="c-36233259">[-]</label><label class="expand" for="c-36233259">[1 more]</label></div><br/><div class="children"><div class="content">BTW Elo is not an abbreviation it is a persons name: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Arpad_Elo" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Arpad_Elo</a></div><br/></div></div><div id="36235469" class="c"><input type="checkbox" id="c-36235469" checked=""/><div class="controls bullet"><span class="by">chpatrick</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232145">parent</a><span>|</span><a href="#36233259">prev</a><span>|</span><a href="#36232455">next</a><span>|</span><label class="collapse" for="c-36235469">[-]</label><label class="expand" for="c-36235469">[2 more]</label></div><br/><div class="children"><div class="content">Massive improvements in protein folding do nothing to improve the human condition? What?</div><br/><div id="36236280" class="c"><input type="checkbox" id="c-36236280" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36235469">parent</a><span>|</span><a href="#36232455">next</a><span>|</span><label class="collapse" for="c-36236280">[-]</label><label class="expand" for="c-36236280">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s fair to say that it (where &quot;it&quot; is defined as &quot;DeepMind&#x27;s contribution to the protein folding problem&quot;) hasn&#x27;t yet given us massive improvements to the human condition.<p>It might, and in fact I think it probably will. But it hasn&#x27;t yet.</div><br/></div></div></div></div><div id="36232455" class="c"><input type="checkbox" id="c-36232455" checked=""/><div class="controls bullet"><span class="by">vosper</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232145">parent</a><span>|</span><a href="#36235469">prev</a><span>|</span><a href="#36232241">next</a><span>|</span><label class="collapse" for="c-36232455">[-]</label><label class="expand" for="c-36232455">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Go players have DECREASED their ELO after playing AlphaGo (or just quit the game altogether)<p>Can you explain this for someone unfamiliar with the game?</div><br/><div id="36232805" class="c"><input type="checkbox" id="c-36232805" checked=""/><div class="controls bullet"><span class="by">dfan</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232455">parent</a><span>|</span><a href="#36234848">next</a><span>|</span><label class="collapse" for="c-36232805">[-]</label><label class="expand" for="c-36232805">[1 more]</label></div><br/><div class="children"><div class="content">I am familiar with the game and I cannot explain it. Go is not typically rated with the Elo system, and the quality of top-level human play has increased since 2016.</div><br/></div></div><div id="36234848" class="c"><input type="checkbox" id="c-36234848" checked=""/><div class="controls bullet"><span class="by">schaefer</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232455">parent</a><span>|</span><a href="#36232805">prev</a><span>|</span><a href="#36232586">next</a><span>|</span><label class="collapse" for="c-36234848">[-]</label><label class="expand" for="c-36234848">[1 more]</label></div><br/><div class="children"><div class="content">Lee Sedol retired in 2019 following his 2016 defeat by Alpha Go in a 5 round match.  At the start of the match most people were confident an AI could never defeat a top human player at Go.  By the end of the match, watching (arguable) world champ Sedol suffer lost game after lost game the story had changed dramatically.  Sedol fans were championing his single win against the unstoppable AI.<p>We (hacker news) discussed Lee Sedol&#x27;s retirement here: [1]<p>To active go players at the time, Alpha Go and Alpha Zero really were as shocking as the debut of Chat GTP was recently.<p>[1]: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21649495" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21649495</a></div><br/></div></div><div id="36232586" class="c"><input type="checkbox" id="c-36232586" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232455">parent</a><span>|</span><a href="#36234848">prev</a><span>|</span><a href="#36232241">next</a><span>|</span><label class="collapse" for="c-36232586">[-]</label><label class="expand" for="c-36232586">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they just lost so their ELO went down? Or do loses against AI not count?</div><br/></div></div></div></div><div id="36232241" class="c"><input type="checkbox" id="c-36232241" checked=""/><div class="controls bullet"><span class="by">blazespin</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232145">parent</a><span>|</span><a href="#36232455">prev</a><span>|</span><a href="#36233688">next</a><span>|</span><label class="collapse" for="c-36232241">[-]</label><label class="expand" for="c-36232241">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a bit surprising how poorly DeepMind has lived up to their hype.  But they&#x27;re an OK lab, maybe a bit overly vain.</div><br/><div id="36232307" class="c"><input type="checkbox" id="c-36232307" checked=""/><div class="controls bullet"><span class="by">TaupeRanger</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232241">parent</a><span>|</span><a href="#36233688">next</a><span>|</span><label class="collapse" for="c-36232307">[-]</label><label class="expand" for="c-36232307">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s probably very fun to be <i>at</i> DeepMind, I just don&#x27;t think I&#x27;d want to be a part of the cringey hype machine.</div><br/></div></div></div></div><div id="36233688" class="c"><input type="checkbox" id="c-36233688" checked=""/><div class="controls bullet"><span class="by">29athrowaway</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232145">parent</a><span>|</span><a href="#36232241">prev</a><span>|</span><a href="#36233416">next</a><span>|</span><label class="collapse" for="c-36233688">[-]</label><label class="expand" for="c-36233688">[1 more]</label></div><br/><div class="children"><div class="content">Around the time of the AlphaGo challenge and afterwards...<p>1) you could see increased activity in go clubs and online go servers<p>2) the analysis of the games published by Deepmind has resulted in interesting &quot;discoveries&quot; (or rediscoveries) and changes to what is considered joseki.<p>3) many people started analyzing their kifus using AI, to find fluctuations in estimated win rate across moves.<p>So I disagree entirely</div><br/></div></div><div id="36233416" class="c"><input type="checkbox" id="c-36233416" checked=""/><div class="controls bullet"><span class="by">gdy</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232145">parent</a><span>|</span><a href="#36233688">prev</a><span>|</span><a href="#36232702">next</a><span>|</span><label class="collapse" for="c-36233416">[-]</label><label class="expand" for="c-36233416">[3 more]</label></div><br/><div class="children"><div class="content">&quot;may have actually made things worse. Go players...&quot;<p>Go players are using AI to get better at Go.</div><br/><div id="36236257" class="c"><input type="checkbox" id="c-36236257" checked=""/><div class="controls bullet"><span class="by">ipaddr</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36233416">parent</a><span>|</span><a href="#36233450">next</a><span>|</span><label class="collapse" for="c-36236257">[-]</label><label class="expand" for="c-36236257">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s like wearing a baseball glove on your dominate hand and taking it off to throw the ball.  It&#x27;s easier but at some point you need to relearn how to play to make it to the next level</div><br/></div></div><div id="36233450" class="c"><input type="checkbox" id="c-36233450" checked=""/><div class="controls bullet"><span class="by">TaupeRanger</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36233416">parent</a><span>|</span><a href="#36236257">prev</a><span>|</span><a href="#36232702">next</a><span>|</span><label class="collapse" for="c-36233450">[-]</label><label class="expand" for="c-36233450">[1 more]</label></div><br/><div class="children"><div class="content">That claim is often made, and never substantiated.</div><br/></div></div></div></div><div id="36232702" class="c"><input type="checkbox" id="c-36232702" checked=""/><div class="controls bullet"><span class="by">malux85</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232145">parent</a><span>|</span><a href="#36233416">prev</a><span>|</span><a href="#36232631">next</a><span>|</span><label class="collapse" for="c-36232702">[-]</label><label class="expand" for="c-36232702">[3 more]</label></div><br/><div class="children"><div class="content">I thought the same thing - it smacks of desperation at the moment, any tiny win is exaggerated  .<p>It’s not hard to see why, with the emergence (ha) of OpenAI, Midjourney and all of this generative modelling, what has DeepMind done? I imagine the execs at Google are asking them some very probing questions on their mediocre performance over the last 5 years.</div><br/><div id="36234351" class="c"><input type="checkbox" id="c-36234351" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232702">parent</a><span>|</span><a href="#36238132">next</a><span>|</span><label class="collapse" for="c-36234351">[-]</label><label class="expand" for="c-36234351">[1 more]</label></div><br/><div class="children"><div class="content">Deepmind has done quite an enormous amount actually, but it&#x27;s been in <i>academia</i> not in the commercial product sphere.
Just because something is not on a little web page available to average Joe&#x27;s does not mean there isn&#x27;t value in it.
For example, Deepmind&#x27;s work towards estimating quantum properties of materials via density functional theory may not be the best toy for your grandma to play around with, but it certainly does move academia way further ahead of where it once was.</div><br/></div></div><div id="36238132" class="c"><input type="checkbox" id="c-36238132" checked=""/><div class="controls bullet"><span class="by">gusennan</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232702">parent</a><span>|</span><a href="#36234351">prev</a><span>|</span><a href="#36232631">next</a><span>|</span><label class="collapse" for="c-36238132">[-]</label><label class="expand" for="c-36238132">[1 more]</label></div><br/><div class="children"><div class="content">They solved an open challenge problem, Protein Structure Prediction, with AlphaFold, which has been nothing short of revolutionary in the structural biology and biochemistry fields. I do scientific research in these fields and the capabilities AlphaFold provides are used now everywhere.</div><br/></div></div></div></div></div></div><div id="36232631" class="c"><input type="checkbox" id="c-36232631" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36232145">prev</a><span>|</span><a href="#36233362">next</a><span>|</span><label class="collapse" for="c-36232631">[-]</label><label class="expand" for="c-36232631">[3 more]</label></div><br/><div class="children"><div class="content">Shouldn&#x27;t libc++ be kinda good? Since it&#x27;s the standard and all? Why isn&#x27;t&#x2F;wasn&#x27;t it?</div><br/><div id="36232904" class="c"><input type="checkbox" id="c-36232904" checked=""/><div class="controls bullet"><span class="by">petschge</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232631">parent</a><span>|</span><a href="#36233362">next</a><span>|</span><label class="collapse" for="c-36232904">[-]</label><label class="expand" for="c-36232904">[2 more]</label></div><br/><div class="children"><div class="content">The LLVM implementation of libc++ is very young compared to other implementations (it was started 5 years ago or so), so there is still a lot of things missing and a lot of things that can be improved.</div><br/><div id="36233201" class="c"><input type="checkbox" id="c-36233201" checked=""/><div class="controls bullet"><span class="by">bigcheesegs</span><span>|</span><a href="#36231147">root</a><span>|</span><a href="#36232904">parent</a><span>|</span><a href="#36233362">next</a><span>|</span><label class="collapse" for="c-36233201">[-]</label><label class="expand" for="c-36233201">[1 more]</label></div><br/><div class="children"><div class="content">libc++ was open sourced May 11th 2010. 13 years ago. <a href="https:&#x2F;&#x2F;blog.llvm.org&#x2F;2010&#x2F;05&#x2F;new-libc-c-standard-library.html" rel="nofollow">https:&#x2F;&#x2F;blog.llvm.org&#x2F;2010&#x2F;05&#x2F;new-libc-c-standard-library.ht...</a></div><br/></div></div></div></div></div></div><div id="36233362" class="c"><input type="checkbox" id="c-36233362" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36232631">prev</a><span>|</span><a href="#36233039">next</a><span>|</span><label class="collapse" for="c-36233362">[-]</label><label class="expand" for="c-36233362">[1 more]</label></div><br/><div class="children"><div class="content">A decade ago Google had people with breadth and context who could have adjusted the framing of the result of this work (and maybe even re-targeted it yo something useful). Today however Google is a mix of hyper-narrow expert ICs and leaders who lack domain expertise.  Paper in Nature? Sure let’s take it!</div><br/></div></div><div id="36235697" class="c"><input type="checkbox" id="c-36235697" checked=""/><div class="controls bullet"><span class="by">neximo64</span><span>|</span><a href="#36231147">parent</a><span>|</span><a href="#36233039">prev</a><span>|</span><a href="#36228824">next</a><span>|</span><label class="collapse" for="c-36235697">[-]</label><label class="expand" for="c-36235697">[1 more]</label></div><br/><div class="children"><div class="content">What you&#x27;re saying is a certain perspective which seeks to look at it from first principles.<p>To the brutalist, the algorithm change is faster, and thats all that matters. A human didn&#x27;t previously come up with the optimisation. You might as well say a computer sorting an algorithm is bullshit vs a person because the difference is just a bloated chip does it instead, and thats it.</div><br/></div></div></div></div><div id="36228824" class="c"><input type="checkbox" id="c-36228824" checked=""/><div class="controls bullet"><span class="by">bgirard</span><span>|</span><a href="#36231147">prev</a><span>|</span><a href="#36228343">next</a><span>|</span><label class="collapse" for="c-36228824">[-]</label><label class="expand" for="c-36228824">[9 more]</label></div><br/><div class="children"><div class="content">The title implies it found an entirely new algorithmic approach to sorting (like quick sort) which would have been a fantastic discovery. But it feels a lot like micro-optimizing the control flow and codegen.</div><br/><div id="36229308" class="c"><input type="checkbox" id="c-36229308" checked=""/><div class="controls bullet"><span class="by">fwlr</span><span>|</span><a href="#36228824">parent</a><span>|</span><a href="#36228994">next</a><span>|</span><label class="collapse" for="c-36229308">[-]</label><label class="expand" for="c-36229308">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure there is a new algorithmic approach to sorting like you&#x27;re thinking of. From a high level you can divide sorting algorithms into roughly two camps, &quot;those that use divide-and-conquer&quot;, and &quot;those that do not&quot;. The divide-and-conquer (split into smaller sub-lists, sort the sub-lists, and merge them while preserving sort order) algorithms are better. From this perspective, algorithms that we think of as quite distinct like quicksort and mergesort are not that different - quicksort just does the &quot;divide&quot; step of divide-and-conquer in a smarter way.<p>In the end, no matter what divide-and-conquer sorting algorithm you pick, you will be doing lots of &quot;small sorts&quot;. And it is those small sorts that DeepMind has optimized here.</div><br/><div id="36229759" class="c"><input type="checkbox" id="c-36229759" checked=""/><div class="controls bullet"><span class="by">ozr</span><span>|</span><a href="#36228824">root</a><span>|</span><a href="#36229308">parent</a><span>|</span><a href="#36229631">next</a><span>|</span><label class="collapse" for="c-36229759">[-]</label><label class="expand" for="c-36229759">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m not sure there is a new algorithmic approach to sorting like you&#x27;re thinking of. From a high level you can divide sorting algorithms into roughly two camps, &quot;those that use divide-and-conquer&quot;, and &quot;those that do not&quot;. ...<p>I think the sci-fi-but-possibly-real hope is that for sorting (among other things), we may have the perspective that there isn&#x27;t any new algorithmic approach available, but an AI finds one for us.</div><br/><div id="36236589" class="c"><input type="checkbox" id="c-36236589" checked=""/><div class="controls bullet"><span class="by">fwlr</span><span>|</span><a href="#36228824">root</a><span>|</span><a href="#36229759">parent</a><span>|</span><a href="#36229631">next</a><span>|</span><label class="collapse" for="c-36236589">[-]</label><label class="expand" for="c-36236589">[1 more]</label></div><br/><div class="children"><div class="content">That would be awesome! Obviously it’s hard to imagine what that would look like (since a necessary part of it is “the AI comes up with something we couldn’t imagine”), but here’s one potential idea, based on these DeepMind discoveries being “exploiting guarantees of previous steps” and “you can use simpler sorts when the first part of the list is sorted”: the AI might be able to find some way to perform a cheap-but-weak “divide” step and a cheap-but-weak “merge” step, such that the guarantees from each step happen to interact in a way that produces fully correct sorting.</div><br/></div></div></div></div><div id="36229631" class="c"><input type="checkbox" id="c-36229631" checked=""/><div class="controls bullet"><span class="by">bgirard</span><span>|</span><a href="#36228824">root</a><span>|</span><a href="#36229308">parent</a><span>|</span><a href="#36229759">prev</a><span>|</span><a href="#36228994">next</a><span>|</span><label class="collapse" for="c-36229631">[-]</label><label class="expand" for="c-36229631">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s lot of accepted sorting algorithms [1]. I&#x27;m sure we can come up with novel new algorithms, even if they&#x27;re not optimal. Like Wikipedia mentions, they all fall within some small number of higher level categories (eg. Partitioning, Merging, Selection, Insertion). I&#x27;m still not convinced that the optimizations presented in the article amount to the discovery of NEW sorting algorithms but merely optimizations of existing ones.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sorting_algorithm" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sorting_algorithm</a></div><br/></div></div></div></div><div id="36228994" class="c"><input type="checkbox" id="c-36228994" checked=""/><div class="controls bullet"><span class="by">GravityLabs</span><span>|</span><a href="#36228824">parent</a><span>|</span><a href="#36229308">prev</a><span>|</span><a href="#36229716">next</a><span>|</span><label class="collapse" for="c-36228994">[-]</label><label class="expand" for="c-36228994">[2 more]</label></div><br/><div class="children"><div class="content">Still a fantastic discovery, because now there are more powerful automated algorithm improvement discovery pipelines. I wonder what will happen when those improvements are added to the processing that found the improvements. :D</div><br/><div id="36229090" class="c"><input type="checkbox" id="c-36229090" checked=""/><div class="controls bullet"><span class="by">bgirard</span><span>|</span><a href="#36228824">root</a><span>|</span><a href="#36228994">parent</a><span>|</span><a href="#36229716">next</a><span>|</span><label class="collapse" for="c-36229090">[-]</label><label class="expand" for="c-36229090">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I&#x27;m not discounting the results. I think it&#x27;s a very interesting approach. I just think the language is important here. If you ask a CS class turn in their own quick sort implementation, you have n implementations of 1 algorithm, not n new algorithms.</div><br/></div></div></div></div><div id="36229716" class="c"><input type="checkbox" id="c-36229716" checked=""/><div class="controls bullet"><span class="by">ozr</span><span>|</span><a href="#36228824">parent</a><span>|</span><a href="#36228994">prev</a><span>|</span><a href="#36231653">next</a><span>|</span><label class="collapse" for="c-36229716">[-]</label><label class="expand" for="c-36229716">[1 more]</label></div><br/><div class="children"><div class="content">I think this is still super interesting.  It&#x27;s something humans are unable to do&#x2F;there&#x27;s few humans that can.  I very much like the pattern of writing basic logic myself and then using a coding model to optimize it.  It&#x27;s effectively what we do with compilers already, this just makes it better.</div><br/></div></div><div id="36231653" class="c"><input type="checkbox" id="c-36231653" checked=""/><div class="controls bullet"><span class="by">nurettin</span><span>|</span><a href="#36228824">parent</a><span>|</span><a href="#36229716">prev</a><span>|</span><a href="#36228343">next</a><span>|</span><label class="collapse" for="c-36231653">[-]</label><label class="expand" for="c-36231653">[1 more]</label></div><br/><div class="children"><div class="content">My first intuition, knowing the limitations of generating first-order logic sequences, was that they must have somehow restricted the sorting sequence to a number of elements.</div><br/></div></div></div></div><div id="36228343" class="c"><input type="checkbox" id="c-36228343" checked=""/><div class="controls bullet"><span class="by">SethTro</span><span>|</span><a href="#36228824">prev</a><span>|</span><a href="#36228460">next</a><span>|</span><label class="collapse" for="c-36228343">[-]</label><label class="expand" for="c-36228343">[2 more]</label></div><br/><div class="children"><div class="content">LLVM merge: <a href="https:&#x2F;&#x2F;reviews.llvm.org&#x2F;D118029" rel="nofollow">https:&#x2F;&#x2F;reviews.llvm.org&#x2F;D118029</a>
Benchmark: <a href="https:&#x2F;&#x2F;bit.ly&#x2F;3AtesYf" rel="nofollow">https:&#x2F;&#x2F;bit.ly&#x2F;3AtesYf</a><p>Benchmark seems to be in the range of a 1-5% improvement for 80% of sizes.</div><br/><div id="36228990" class="c"><input type="checkbox" id="c-36228990" checked=""/><div class="controls bullet"><span class="by">andreamichi</span><span>|</span><a href="#36228343">parent</a><span>|</span><a href="#36228460">next</a><span>|</span><label class="collapse" for="c-36228990">[-]</label><label class="expand" for="c-36228990">[1 more]</label></div><br/><div class="children"><div class="content">And for the hashing patch this is the commit to Abseil:
<a href="https:&#x2F;&#x2F;github.com&#x2F;abseil&#x2F;abseil-cpp&#x2F;commit&#x2F;74eee2aff683cc7dcd2dbaa69b2c654596d8024e">https:&#x2F;&#x2F;github.com&#x2F;abseil&#x2F;abseil-cpp&#x2F;commit&#x2F;74eee2aff683cc7d...</a></div><br/></div></div></div></div><div id="36228460" class="c"><input type="checkbox" id="c-36228460" checked=""/><div class="controls bullet"><span class="by">finitestateuni</span><span>|</span><a href="#36228343">prev</a><span>|</span><a href="#36229960">next</a><span>|</span><label class="collapse" for="c-36228460">[-]</label><label class="expand" for="c-36228460">[9 more]</label></div><br/><div class="children"><div class="content">The most interesting part of this paper to me is that they let the agent guess how efficient it’s own solutions were and only had the model experimentally verify it’s guesses in 0.002% of cases. This allowed the model to search much faster than another program that didn’t guess and had to run every program.</div><br/><div id="36229119" class="c"><input type="checkbox" id="c-36229119" checked=""/><div class="controls bullet"><span class="by">tux3</span><span>|</span><a href="#36228460">parent</a><span>|</span><a href="#36229315">next</a><span>|</span><label class="collapse" for="c-36229119">[-]</label><label class="expand" for="c-36229119">[2 more]</label></div><br/><div class="children"><div class="content">This is the same sort of &quot;more guesses faster beats smarter guesses slower&quot; that made afl-fuzz by far the best at exploring large search spaces in program fuzzing<p>Fast search often beats accurate search. Sometimes adding clever heuristics or more complex scoring &quot;works&quot; but slows down the search enough that it&#x27;s an overall loss. Another kind of a bitter lesson, perhaps</div><br/><div id="36234768" class="c"><input type="checkbox" id="c-36234768" checked=""/><div class="controls bullet"><span class="by">lqr</span><span>|</span><a href="#36228460">root</a><span>|</span><a href="#36229119">parent</a><span>|</span><a href="#36229315">next</a><span>|</span><label class="collapse" for="c-36234768">[-]</label><label class="expand" for="c-36234768">[1 more]</label></div><br/><div class="children"><div class="content">But why isn&#x27;t the proposed method an instance of smart guessing? It reduces oracle complexity with heuristics. The heuristic is &quot;build a machine learning model of the objective function and use it to fake oracle queries most of the time.&quot;</div><br/></div></div></div></div><div id="36229315" class="c"><input type="checkbox" id="c-36229315" checked=""/><div class="controls bullet"><span class="by">blackbear_</span><span>|</span><a href="#36228460">parent</a><span>|</span><a href="#36229119">prev</a><span>|</span><a href="#36231200">next</a><span>|</span><label class="collapse" for="c-36229315">[-]</label><label class="expand" for="c-36229315">[1 more]</label></div><br/><div class="children"><div class="content">This is actually quite common to optimize stuff in several disciplines. You essentially fit a surrogate model (keyword if you want to look up more) to whatever you want to optimize, then use the model to guide the procedure, making sure that the model is correct every one in a while.</div><br/></div></div><div id="36231200" class="c"><input type="checkbox" id="c-36231200" checked=""/><div class="controls bullet"><span class="by">dsign</span><span>|</span><a href="#36228460">parent</a><span>|</span><a href="#36229315">prev</a><span>|</span><a href="#36228728">next</a><span>|</span><label class="collapse" for="c-36231200">[-]</label><label class="expand" for="c-36231200">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been wondering about a similar approach for biomolecular simulations, where exact computations are still a hard bottleneck. I wonder if something like this could give us a few orders of magnitude more speed.</div><br/></div></div><div id="36228728" class="c"><input type="checkbox" id="c-36228728" checked=""/><div class="controls bullet"><span class="by">Zamicol</span><span>|</span><a href="#36228460">parent</a><span>|</span><a href="#36231200">prev</a><span>|</span><a href="#36229960">next</a><span>|</span><label class="collapse" for="c-36228728">[-]</label><label class="expand" for="c-36228728">[4 more]</label></div><br/><div class="children"><div class="content">That sounds like intuition.</div><br/><div id="36228914" class="c"><input type="checkbox" id="c-36228914" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#36228460">root</a><span>|</span><a href="#36228728">parent</a><span>|</span><a href="#36229960">next</a><span>|</span><label class="collapse" for="c-36228914">[-]</label><label class="expand" for="c-36228914">[3 more]</label></div><br/><div class="children"><div class="content">Intuition is the only thing we&#x27;ve figured out how to automate. Reason turns out to be higher hanging fruit.</div><br/><div id="36229108" class="c"><input type="checkbox" id="c-36229108" checked=""/><div class="controls bullet"><span class="by">the_other</span><span>|</span><a href="#36228460">root</a><span>|</span><a href="#36228914">parent</a><span>|</span><a href="#36232813">prev</a><span>|</span><a href="#36229960">next</a><span>|</span><label class="collapse" for="c-36229108">[-]</label><label class="expand" for="c-36229108">[1 more]</label></div><br/><div class="children"><div class="content">Like humans’ “slow” and “fast” thinking, then?</div><br/></div></div></div></div></div></div></div></div><div id="36229960" class="c"><input type="checkbox" id="c-36229960" checked=""/><div class="controls bullet"><span class="by">VikingCoder</span><span>|</span><a href="#36228460">prev</a><span>|</span><a href="#36229728">next</a><span>|</span><label class="collapse" for="c-36229960">[-]</label><label class="expand" for="c-36229960">[9 more]</label></div><br/><div class="children"><div class="content">Dumb question -<p>Where are the machine learning de-compilers?<p>Given an executable program, give me human-readable code that generates the executable exactly.  With machine learning guessed function, type, variable names...?<p>I get that it&#x27;s a very hard problem.  But...  Does it just not work?  Or have people not done it yet?  Or have I missed it?</div><br/><div id="36230038" class="c"><input type="checkbox" id="c-36230038" checked=""/><div class="controls bullet"><span class="by">sl-1</span><span>|</span><a href="#36229960">parent</a><span>|</span><a href="#36230484">next</a><span>|</span><label class="collapse" for="c-36230038">[-]</label><label class="expand" for="c-36230038">[1 more]</label></div><br/><div class="children"><div class="content">That is a good question!<p>Training datasets should be pretty trivial for this, all open source software that is buildable on the internet could provide training sets (source code &amp; compiled code).<p>But I guess it would have to be trained specifically for every architechture.</div><br/></div></div><div id="36230484" class="c"><input type="checkbox" id="c-36230484" checked=""/><div class="controls bullet"><span class="by">skeaker</span><span>|</span><a href="#36229960">parent</a><span>|</span><a href="#36230038">prev</a><span>|</span><a href="#36233159">next</a><span>|</span><label class="collapse" for="c-36230484">[-]</label><label class="expand" for="c-36230484">[1 more]</label></div><br/><div class="children"><div class="content">Personally I think this would be very exciting. Currently there are a ton of projects to decompile older games (see the Mario 64 and Ocarina of Time de-compilations and subsequent native PC ports as an example), but those projects are huge and take whole teams years to finish. If you could simply point an AI at a project like that and have usable source code in a reasonable amount of time, it would be huge for those scenes. You would have a sort of defacto-open source moment for just about all software. It feels like the stuff of far off sci-fi.</div><br/></div></div><div id="36233159" class="c"><input type="checkbox" id="c-36233159" checked=""/><div class="controls bullet"><span class="by">pitaj</span><span>|</span><a href="#36229960">parent</a><span>|</span><a href="#36230484">prev</a><span>|</span><a href="#36230022">next</a><span>|</span><label class="collapse" for="c-36233159">[-]</label><label class="expand" for="c-36233159">[1 more]</label></div><br/><div class="children"><div class="content">This actually doesn&#x27;t sound that difficult, given we can produce a practically infinite training dataset using a compiler with existing programs.<p>What&#x27;s more interesting to me would be a model that can automatically port a program between languages, such as converting a C program to a fairly idiomatic Rust program.</div><br/></div></div><div id="36230022" class="c"><input type="checkbox" id="c-36230022" checked=""/><div class="controls bullet"><span class="by">VMG</span><span>|</span><a href="#36229960">parent</a><span>|</span><a href="#36233159">prev</a><span>|</span><a href="#36235428">next</a><span>|</span><label class="collapse" for="c-36230022">[-]</label><label class="expand" for="c-36230022">[1 more]</label></div><br/><div class="children"><div class="content">You can already do that to some extent with ChatGPT. Paste in the assembly and it gives pretty good results</div><br/></div></div><div id="36235428" class="c"><input type="checkbox" id="c-36235428" checked=""/><div class="controls bullet"><span class="by">optimalsolver</span><span>|</span><a href="#36229960">parent</a><span>|</span><a href="#36230022">prev</a><span>|</span><a href="#36230449">next</a><span>|</span><label class="collapse" for="c-36235428">[-]</label><label class="expand" for="c-36235428">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2010.00770" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2010.00770</a></div><br/></div></div><div id="36230449" class="c"><input type="checkbox" id="c-36230449" checked=""/><div class="controls bullet"><span class="by">xwdv</span><span>|</span><a href="#36229960">parent</a><span>|</span><a href="#36235428">prev</a><span>|</span><a href="#36229728">next</a><span>|</span><label class="collapse" for="c-36230449">[-]</label><label class="expand" for="c-36230449">[3 more]</label></div><br/><div class="children"><div class="content">This is the killer app for me with AI. A way to get a non-copyrighted code for any program you already have binary code for.</div><br/><div id="36230680" class="c"><input type="checkbox" id="c-36230680" checked=""/><div class="controls bullet"><span class="by">ealexhudson</span><span>|</span><a href="#36229960">root</a><span>|</span><a href="#36230449">parent</a><span>|</span><a href="#36229728">next</a><span>|</span><label class="collapse" for="c-36230680">[-]</label><label class="expand" for="c-36230680">[2 more]</label></div><br/><div class="children"><div class="content">That sounds obviously transformative and on any non-trivial scale I can&#x27;t see why copyright would be avoided.</div><br/><div id="36230815" class="c"><input type="checkbox" id="c-36230815" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#36229960">root</a><span>|</span><a href="#36230680">parent</a><span>|</span><a href="#36229728">next</a><span>|</span><label class="collapse" for="c-36230815">[-]</label><label class="expand" for="c-36230815">[1 more]</label></div><br/><div class="children"><div class="content">I think you mean &quot;non-transformative&quot;, although in this context I can see there&#x27;s a bit of an ambiguity in how people would use the word &quot;transform&quot; to mean one thing w.r.t copyright and the &quot;opposite&quot; for code (really, orthogonal, but boolean evaluation would yield the opposite true&#x2F;false).<p>In copyright, &quot;transformative&quot; refers to modifying or adapting a copyrighted work in a way that creates a new and original expression; resulting in a new work with a different purpose or meaning.<p>In terms of code, you&#x27;d &quot;just be transforming&quot; the assembly code to a systems language of your choice.</div><br/></div></div></div></div></div></div></div></div><div id="36229728" class="c"><input type="checkbox" id="c-36229728" checked=""/><div class="controls bullet"><span class="by">cypherpunks01</span><span>|</span><a href="#36229960">prev</a><span>|</span><a href="#36238797">next</a><span>|</span><label class="collapse" for="c-36229728">[-]</label><label class="expand" for="c-36229728">[1 more]</label></div><br/><div class="children"><div class="content">This was educational because I learned about Sorting Networks.<p>I didn&#x27;t hear of them in CS undergrad algorithms, perhaps because they can be thought of as a special case or optimization, rather than fundamental and generic variable-length sort algos.<p>It&#x27;s a simple concept, and forms the basis of all the sort optimizations described here.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sorting_network" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sorting_network</a></div><br/></div></div><div id="36238797" class="c"><input type="checkbox" id="c-36238797" checked=""/><div class="controls bullet"><span class="by">sebstefan</span><span>|</span><a href="#36229728">prev</a><span>|</span><a href="#36228355">next</a><span>|</span><label class="collapse" for="c-36238797">[-]</label><label class="expand" for="c-36238797">[1 more]</label></div><br/><div class="children"><div class="content">If they went for an integration in LLVM I wonder why they tuned their model on x86 instead of LLVM IR, the intermediate representation the compiler uses</div><br/></div></div><div id="36228355" class="c"><input type="checkbox" id="c-36228355" checked=""/><div class="controls bullet"><span class="by">jonbaer</span><span>|</span><a href="#36238797">prev</a><span>|</span><a href="#36228506">next</a><span>|</span><label class="collapse" for="c-36228355">[-]</label><label class="expand" for="c-36228355">[7 more]</label></div><br/><div class="children"><div class="content">&quot;AlphaDev uncovered new sorting algorithms that led to improvements in the LLVM libc++ sorting library that were up to 70% faster for shorter sequences and about 1.7% faster for sequences exceeding 250,000 elements.&quot;</div><br/><div id="36228748" class="c"><input type="checkbox" id="c-36228748" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#36228355">parent</a><span>|</span><a href="#36228506">next</a><span>|</span><label class="collapse" for="c-36228748">[-]</label><label class="expand" for="c-36228748">[6 more]</label></div><br/><div class="children"><div class="content">&gt; up to 70% faster<p>So O(0.3(N log N))? That&#x27;s still O(N log N)</div><br/><div id="36228781" class="c"><input type="checkbox" id="c-36228781" checked=""/><div class="controls bullet"><span class="by">caturopath</span><span>|</span><a href="#36228355">root</a><span>|</span><a href="#36228748">parent</a><span>|</span><a href="#36228775">next</a><span>|</span><label class="collapse" for="c-36228781">[-]</label><label class="expand" for="c-36228781">[3 more]</label></div><br/><div class="children"><div class="content">They&#x27;re not going to find a general sorting algorithm faster than O(n log n), but that doesn&#x27;t mean all O(n log n) sorts are created equal.</div><br/><div id="36229278" class="c"><input type="checkbox" id="c-36229278" checked=""/><div class="controls bullet"><span class="by">ralfn</span><span>|</span><a href="#36228355">root</a><span>|</span><a href="#36228781">parent</a><span>|</span><a href="#36229673">next</a><span>|</span><label class="collapse" for="c-36229278">[-]</label><label class="expand" for="c-36229278">[1 more]</label></div><br/><div class="children"><div class="content">If the thing you have to sort is within a known domain you can definitely beat o(n log(n)). Just expect crazy memory usage.<p>And that&#x27;s only not the case in theory. But nobody owns a real Turing machine with infinite tape and truly infinite numbers. It doesn&#x27;t exist in reality.<p>You can always divide time by multiplying space with the same factor.</div><br/></div></div><div id="36229673" class="c"><input type="checkbox" id="c-36229673" checked=""/><div class="controls bullet"><span class="by">iopq</span><span>|</span><a href="#36228355">root</a><span>|</span><a href="#36228781">parent</a><span>|</span><a href="#36229278">prev</a><span>|</span><a href="#36228775">next</a><span>|</span><label class="collapse" for="c-36229673">[-]</label><label class="expand" for="c-36229673">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not true because Thorup&#x27;s algorithm is O(n log log n)</div><br/></div></div></div></div><div id="36228775" class="c"><input type="checkbox" id="c-36228775" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#36228355">root</a><span>|</span><a href="#36228748">parent</a><span>|</span><a href="#36228781">prev</a><span>|</span><a href="#36228506">next</a><span>|</span><label class="collapse" for="c-36228775">[-]</label><label class="expand" for="c-36228775">[2 more]</label></div><br/><div class="children"><div class="content">In the real world, we care about runtime as much as, if not more than, computational complexity.</div><br/><div id="36228850" class="c"><input type="checkbox" id="c-36228850" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#36228355">root</a><span>|</span><a href="#36228775">parent</a><span>|</span><a href="#36228506">next</a><span>|</span><label class="collapse" for="c-36228850">[-]</label><label class="expand" for="c-36228850">[1 more]</label></div><br/><div class="children"><div class="content">Definitely more. There are lots of things that might be more optimal in terms of raw complexity but end up having abysmal performance due to things like cache locality. Anything with pointer chasing usually kills performance.</div><br/></div></div></div></div></div></div></div></div><div id="36228506" class="c"><input type="checkbox" id="c-36228506" checked=""/><div class="controls bullet"><span class="by">greenflag</span><span>|</span><a href="#36228355">prev</a><span>|</span><a href="#36228382">next</a><span>|</span><label class="collapse" for="c-36228506">[-]</label><label class="expand" for="c-36228506">[3 more]</label></div><br/><div class="children"><div class="content">Does anyone have high level guidance on when (deep) RL is worth pursuing for optimization (e.g. optimizing algorithm design) rather than other approaches (e.g genetic)?</div><br/><div id="36228839" class="c"><input type="checkbox" id="c-36228839" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#36228506">parent</a><span>|</span><a href="#36229569">next</a><span>|</span><label class="collapse" for="c-36228839">[-]</label><label class="expand" for="c-36228839">[1 more]</label></div><br/><div class="children"><div class="content">Less of a scale problem than a type problem usually in my experience.<p>My rule of thumb is when it’s easy to specify a reward function but infinite ways to traverse the action space - versus having a constrained state and action space (small n solution traversal pathways) and only a few possible paths to traverse.</div><br/></div></div><div id="36229569" class="c"><input type="checkbox" id="c-36229569" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#36228506">parent</a><span>|</span><a href="#36228839">prev</a><span>|</span><a href="#36228382">next</a><span>|</span><label class="collapse" for="c-36229569">[-]</label><label class="expand" for="c-36229569">[1 more]</label></div><br/><div class="children"><div class="content">Start with a planet-scale computer that makes the marginal cost of RL be nearly zero, and at the same time spend a lot of money on hashing and sorting so the micro-optimization pays off.</div><br/></div></div></div></div><div id="36228382" class="c"><input type="checkbox" id="c-36228382" checked=""/><div class="controls bullet"><span class="by">mellosouls</span><span>|</span><a href="#36228506">prev</a><span>|</span><a href="#36235442">next</a><span>|</span><label class="collapse" for="c-36228382">[-]</label><label class="expand" for="c-36228382">[1 more]</label></div><br/><div class="children"><div class="content">Broken link. Ok it&#x27;s there now, maybe a Nature snafu.<p>News Release:<p><a href="https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;alphadev-discovers-faster-sorting-algorithms" rel="nofollow">https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;alphadev-discovers-faster-sort...</a></div><br/></div></div><div id="36228795" class="c"><input type="checkbox" id="c-36228795" checked=""/><div class="controls bullet"><span class="by">mmaunder</span><span>|</span><a href="#36235442">prev</a><span>|</span><a href="#36228773">next</a><span>|</span><label class="collapse" for="c-36228795">[-]</label><label class="expand" for="c-36228795">[1 more]</label></div><br/><div class="children"><div class="content">In 2023 we saw the first glimpse of machines becoming better at programming than humans when an AI created a new sorting algorithm that was faster than anything humans had yet created.</div><br/></div></div><div id="36228773" class="c"><input type="checkbox" id="c-36228773" checked=""/><div class="controls bullet"><span class="by">whywhywhydude</span><span>|</span><a href="#36228795">prev</a><span>|</span><a href="#36232617">next</a><span>|</span><label class="collapse" for="c-36228773">[-]</label><label class="expand" for="c-36228773">[6 more]</label></div><br/><div class="children"><div class="content">It is astounding how something as well as studied as sorting still has opportunities for further improvements!</div><br/><div id="36228929" class="c"><input type="checkbox" id="c-36228929" checked=""/><div class="controls bullet"><span class="by">zzbn00</span><span>|</span><a href="#36228773">parent</a><span>|</span><a href="#36229073">next</a><span>|</span><label class="collapse" for="c-36228929">[-]</label><label class="expand" for="c-36228929">[1 more]</label></div><br/><div class="children"><div class="content">It is not the sorting per-se which was improved here, but sorting (particularly short sequences) on modern CPUs with really the complexity being on the difficulty of predicting what will work quickly on these modern CPUs.<p>Doing an empirical algorithm search to find which algorithms fit well on modern CPUs&#x2F;memory systems is pretty common, see e.g. FFTW, ATLAS, <a href="https:&#x2F;&#x2F;halide-lang.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;halide-lang.org&#x2F;</a></div><br/></div></div><div id="36229073" class="c"><input type="checkbox" id="c-36229073" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#36228773">parent</a><span>|</span><a href="#36228929">prev</a><span>|</span><a href="#36228985">next</a><span>|</span><label class="collapse" for="c-36229073">[-]</label><label class="expand" for="c-36229073">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s well studies is theoretical algorithmic sorting.<p>For practical sorting, for a particular CPU architecture, there is still plenty of low hanging fruit:<p>&gt; Today we&#x27;re sharing open source code that can sort arrays of numbers about ten times as fast as the C++ std::sort, and outperforms state of the art architecture-specific algorithms, while being portable across all modern CPU architectures<p><a href="https:&#x2F;&#x2F;opensource.googleblog.com&#x2F;2022&#x2F;06&#x2F;Vectorized%20and%20performance%20portable%20Quicksort.html" rel="nofollow">https:&#x2F;&#x2F;opensource.googleblog.com&#x2F;2022&#x2F;06&#x2F;Vectorized%20and%2...</a></div><br/></div></div><div id="36228985" class="c"><input type="checkbox" id="c-36228985" checked=""/><div class="controls bullet"><span class="by">jackmott42</span><span>|</span><a href="#36228773">parent</a><span>|</span><a href="#36229073">prev</a><span>|</span><a href="#36232617">next</a><span>|</span><label class="collapse" for="c-36228985">[-]</label><label class="expand" for="c-36228985">[3 more]</label></div><br/><div class="children"><div class="content">Part of it is because hardware properties are always changing. The instructions available, the relative speed of CPU to memory and the various caches, how big and numerous and fast the various caches are, etc etc.</div><br/><div id="36229022" class="c"><input type="checkbox" id="c-36229022" checked=""/><div class="controls bullet"><span class="by">GravityLabs</span><span>|</span><a href="#36228773">root</a><span>|</span><a href="#36228985">parent</a><span>|</span><a href="#36232617">next</a><span>|</span><label class="collapse" for="c-36229022">[-]</label><label class="expand" for="c-36229022">[2 more]</label></div><br/><div class="children"><div class="content">I am curious why things can&#x27;t just get better on a base that doesn&#x27;t change, until the base changes because the improvements with the new base are just that much better...<p>Or is that why hardware properties change so much?</div><br/><div id="36231607" class="c"><input type="checkbox" id="c-36231607" checked=""/><div class="controls bullet"><span class="by">zerodensity</span><span>|</span><a href="#36228773">root</a><span>|</span><a href="#36229022">parent</a><span>|</span><a href="#36232617">next</a><span>|</span><label class="collapse" for="c-36231607">[-]</label><label class="expand" for="c-36231607">[1 more]</label></div><br/><div class="children"><div class="content">For a time that is what happened. Every year you would get a new CPU and that would be faster at pretty much everything than the version the year before. But then we hit the clockspeed wall and the only way of making faster CPUs was to add complexity to the internals of the CPUs. So branch prediction, micro code pipelining, larger caches, simd instructions more CPU cores ect was the result.<p>So nowadays a new CPU might not be better at everything then the previous version but it will most likely have more cache and some internal improvements to pipelining&#x2F;concurrency.<p>Given this, for newer versions it can be useful to add instructions to take advantage of extra pipelining or using a different instruction that happen to be faster now.</div><br/></div></div></div></div></div></div></div></div><div id="36232617" class="c"><input type="checkbox" id="c-36232617" checked=""/><div class="controls bullet"><span class="by">skellington</span><span>|</span><a href="#36228773">prev</a><span>|</span><a href="#36229500">next</a><span>|</span><label class="collapse" for="c-36232617">[-]</label><label class="expand" for="c-36232617">[1 more]</label></div><br/><div class="children"><div class="content">So clickbait to claim a faster algorithm when all it did was find a faster machine optimization for a particular CPU. It&#x27;s fun&#x2F;cool, but not the leap they seem to be representing.</div><br/></div></div><div id="36229500" class="c"><input type="checkbox" id="c-36229500" checked=""/><div class="controls bullet"><span class="by">usgroup</span><span>|</span><a href="#36232617">prev</a><span>|</span><a href="#36229932">next</a><span>|</span><label class="collapse" for="c-36229500">[-]</label><label class="expand" for="c-36229500">[1 more]</label></div><br/><div class="children"><div class="content">“ The fixed sort solutions for sort 3, sort 4 and sort 5 discovered by AlphaDev have been integrated into the standard sort function in the LLVM standard C++ library3.”<p>Not exactly what the title would lead you to believe.</div><br/></div></div><div id="36229932" class="c"><input type="checkbox" id="c-36229932" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#36229500">prev</a><span>|</span><a href="#36228730">next</a><span>|</span><label class="collapse" for="c-36229932">[-]</label><label class="expand" for="c-36229932">[1 more]</label></div><br/><div class="children"><div class="content">The sorting seems cool but I am more interested in the varint decoder. Does anyone know where the source code of that landed, if it did?</div><br/></div></div><div id="36228730" class="c"><input type="checkbox" id="c-36228730" checked=""/><div class="controls bullet"><span class="by">hexomancer</span><span>|</span><a href="#36229932">prev</a><span>|</span><a href="#36237474">next</a><span>|</span><label class="collapse" for="c-36228730">[-]</label><label class="expand" for="c-36228730">[5 more]</label></div><br/><div class="children"><div class="content">&gt; The confidence  intervals are represented as latency ± (lower, upper), in which latency corresponds to the fifth  percentile of latency measurements across 100 different machines. Lower and upper refer to  the bounds of the 95% confidence interval for this percentile.<p>Does anybody know why they chose fifth percentile? I though we should always choose the fastest time when measuring performance.</div><br/><div id="36229187" class="c"><input type="checkbox" id="c-36229187" checked=""/><div class="controls bullet"><span class="by">ajuc</span><span>|</span><a href="#36228730">parent</a><span>|</span><a href="#36228827">next</a><span>|</span><label class="collapse" for="c-36229187">[-]</label><label class="expand" for="c-36229187">[2 more]</label></div><br/><div class="children"><div class="content">Usually you discard extreme values to reduce noise, and in fact they wrote that&#x27;s why they did it:<p>&gt; We then take the fifth percentile as our final measurement, because we assume that most noise sources are one-sided (for example, cache misses, pre-emptions and so on). During training we process the measurements across ten machines for computational efficiency.<p>&gt; I though we should always choose the fastest time when measuring performance.<p>Depends. For games you usually do sth similar to what they did - exclude small percentage of worst results to reduce influence of noise and then optimize the worst scenario to make the game run consistent and smooth.</div><br/><div id="36238912" class="c"><input type="checkbox" id="c-36238912" checked=""/><div class="controls bullet"><span class="by">janwas</span><span>|</span><a href="#36228730">root</a><span>|</span><a href="#36229187">parent</a><span>|</span><a href="#36228827">next</a><span>|</span><label class="collapse" for="c-36238912">[-]</label><label class="expand" for="c-36238912">[1 more]</label></div><br/><div class="children"><div class="content">One possibility which seems not so well-known is that clocks with per-core state might not be perfectly synchronized. If your initial measurement is from core0, then we migrate to core1, the end measurement could even be &#x27;before&#x27; the initial.<p>Then there are manufacturing differences between cores that affect e.g. their leakage current and thus the (turbo) frequency at which they can run.<p>So the measurement noise is indeed not one-sided, that is to say: measurements are not always overestimates. Thus a trimmed mean on both sides is a good idea, and pinning threads to a core when measuring is also helpful.</div><br/></div></div></div></div><div id="36228827" class="c"><input type="checkbox" id="c-36228827" checked=""/><div class="controls bullet"><span class="by">gcr</span><span>|</span><a href="#36228730">parent</a><span>|</span><a href="#36229187">prev</a><span>|</span><a href="#36237474">next</a><span>|</span><label class="collapse" for="c-36228827">[-]</label><label class="expand" for="c-36228827">[2 more]</label></div><br/><div class="children"><div class="content">Because they want to make sure that the sorting algorithm works well for all possible workloads, not just the most preferable ones.<p>If we measured sorting algorithms by the fastest measurement, we might conclude that BubbleSort is the fastest possible sort algorithm on some inputs. (Bubblesorting an already-sorted list makes at most one comparison per list element)</div><br/><div id="36229034" class="c"><input type="checkbox" id="c-36229034" checked=""/><div class="controls bullet"><span class="by">hexomancer</span><span>|</span><a href="#36228730">root</a><span>|</span><a href="#36228827">parent</a><span>|</span><a href="#36237474">next</a><span>|</span><label class="collapse" for="c-36229034">[-]</label><label class="expand" for="c-36229034">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s what they meant (or I have misunderstood). Running the same algorithm on the same input still has variations because of OS&#x2F;CPU idiosyncrasies. When measuring performance we usually run the algorithm on the same input multiple times and report the fastest performance.</div><br/></div></div></div></div></div></div><div id="36237474" class="c"><input type="checkbox" id="c-36237474" checked=""/><div class="controls bullet"><span class="by">keiuseki</span><span>|</span><a href="#36228730">prev</a><span>|</span><a href="#36237469">next</a><span>|</span><label class="collapse" for="c-36237474">[-]</label><label class="expand" for="c-36237474">[2 more]</label></div><br/><div class="children"><div class="content">How about focus on making BERT better.   So far BERT is much worse than ChatGPT.</div><br/><div id="36237544" class="c"><input type="checkbox" id="c-36237544" checked=""/><div class="controls bullet"><span class="by">HereBePandas</span><span>|</span><a href="#36237474">parent</a><span>|</span><a href="#36237469">next</a><span>|</span><label class="collapse" for="c-36237544">[-]</label><label class="expand" for="c-36237544">[1 more]</label></div><br/><div class="children"><div class="content">?<p>BERT was 5 years ago. Of course it&#x27;s worse than anything introduced more recently (both inside and outside Google).<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;BERT_(language_model)" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;BERT_(language_model)</a></div><br/></div></div></div></div><div id="36237469" class="c"><input type="checkbox" id="c-36237469" checked=""/><div class="controls bullet"><span class="by">keiuseki</span><span>|</span><a href="#36237474">prev</a><span>|</span><a href="#36235283">next</a><span>|</span><label class="collapse" for="c-36237469">[-]</label><label class="expand" for="c-36237469">[1 more]</label></div><br/><div class="children"><div class="content">Try make BERT better. So far it is much worse than ChatGPT.</div><br/></div></div><div id="36235283" class="c"><input type="checkbox" id="c-36235283" checked=""/><div class="controls bullet"><span class="by">ayakang31415</span><span>|</span><a href="#36237469">prev</a><span>|</span><a href="#36231505">next</a><span>|</span><label class="collapse" for="c-36235283">[-]</label><label class="expand" for="c-36235283">[1 more]</label></div><br/><div class="children"><div class="content">Shouldn&#x27;t the paper named faster sorting algorithm &quot;optimized&quot; using deep RL instead since no new sorting algorithm is introduced at all?</div><br/></div></div><div id="36231505" class="c"><input type="checkbox" id="c-36231505" checked=""/><div class="controls bullet"><span class="by">shpx</span><span>|</span><a href="#36235283">prev</a><span>|</span><a href="#36228573">next</a><span>|</span><label class="collapse" for="c-36231505">[-]</label><label class="expand" for="c-36231505">[2 more]</label></div><br/><div class="children"><div class="content">I (don&#x27;t) want to see an agent learn to rowhammer the memory address storing its reward quantity.</div><br/><div id="36233868" class="c"><input type="checkbox" id="c-36233868" checked=""/><div class="controls bullet"><span class="by">orlp</span><span>|</span><a href="#36231505">parent</a><span>|</span><a href="#36228573">next</a><span>|</span><label class="collapse" for="c-36233868">[-]</label><label class="expand" for="c-36233868">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;ll love this list of examples where the AI successfully accomplished reward hacking: <a href="https:&#x2F;&#x2F;docs.google.com&#x2F;spreadsheets&#x2F;d&#x2F;e&#x2F;2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR7Ea5eWtvsWzuxo8bjOxCG84dAg&#x2F;pubhtml" rel="nofollow">https:&#x2F;&#x2F;docs.google.com&#x2F;spreadsheets&#x2F;d&#x2F;e&#x2F;2PACX-1vRPiprOaC3Hs...</a></div><br/></div></div></div></div><div id="36228573" class="c"><input type="checkbox" id="c-36228573" checked=""/><div class="controls bullet"><span class="by">lumb63</span><span>|</span><a href="#36231505">prev</a><span>|</span><a href="#36234080">next</a><span>|</span><label class="collapse" for="c-36228573">[-]</label><label class="expand" for="c-36228573">[2 more]</label></div><br/><div class="children"><div class="content">This is really cool. I’ll be interested to see if the team can produce useful and provably hard cryptographic hash functions with this tech. The other interesting application that this inspires is use of this tech to optimize the optimization algorithms used by compilers. Perhaps we can all benefit from optimized optimizers.</div><br/><div id="36228687" class="c"><input type="checkbox" id="c-36228687" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#36228573">parent</a><span>|</span><a href="#36234080">next</a><span>|</span><label class="collapse" for="c-36228687">[-]</label><label class="expand" for="c-36228687">[1 more]</label></div><br/><div class="children"><div class="content">There’s already been quite a bit of work done on replacing compiler heuristics with ML models. Google has productionized it with MLGO and there have been quite a few papers&#x2F;experiments on the topic.</div><br/></div></div></div></div><div id="36234080" class="c"><input type="checkbox" id="c-36234080" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#36228573">prev</a><span>|</span><a href="#36230498">next</a><span>|</span><label class="collapse" for="c-36234080">[-]</label><label class="expand" for="c-36234080">[1 more]</label></div><br/><div class="children"><div class="content">I like the high impact dynamic of this thinking.<p>If that can be done say OS wide I could see that having an actual impact on global energy usage</div><br/></div></div><div id="36230498" class="c"><input type="checkbox" id="c-36230498" checked=""/><div class="controls bullet"><span class="by">gfd</span><span>|</span><a href="#36234080">prev</a><span>|</span><a href="#36230814">next</a><span>|</span><label class="collapse" for="c-36230498">[-]</label><label class="expand" for="c-36230498">[1 more]</label></div><br/><div class="children"><div class="content">Can someone summarize how it achieves &quot;provable correctness&quot;?</div><br/></div></div><div id="36230814" class="c"><input type="checkbox" id="c-36230814" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#36230498">prev</a><span>|</span><a href="#36228983">next</a><span>|</span><label class="collapse" for="c-36230814">[-]</label><label class="expand" for="c-36230814">[1 more]</label></div><br/><div class="children"><div class="content">From &quot;It can&#x27;t Code&quot; to publishing articles in Nature.</div><br/></div></div><div id="36229821" class="c"><input type="checkbox" id="c-36229821" checked=""/><div class="controls bullet"><span class="by">hamilyon2</span><span>|</span><a href="#36228983">prev</a><span>|</span><a href="#36228701">next</a><span>|</span><label class="collapse" for="c-36229821">[-]</label><label class="expand" for="c-36229821">[1 more]</label></div><br/><div class="children"><div class="content">I want this for sql compilation, plan choosing. So much effort is wasted on suboptimal database performance and trying to improve that. I think even sorting pales in comparison.</div><br/></div></div><div id="36228701" class="c"><input type="checkbox" id="c-36228701" checked=""/><div class="controls bullet"><span class="by">ComputerGuru</span><span>|</span><a href="#36229821">prev</a><span>|</span><label class="collapse" for="c-36228701">[-]</label><label class="expand" for="c-36228701">[1 more]</label></div><br/><div class="children"><div class="content">RL: Reinforcement Learning</div><br/></div></div></div></div></div></div></div></body></html>