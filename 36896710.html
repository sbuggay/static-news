<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1690534870399" as="style"/><link rel="stylesheet" href="styles.css?v=1690534870399"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://lucaspauker.com/articles/llms-unleashed-the-power-of-fine-tuning">LLMs Unleashed: The Power of Fine-Tuning</a> <span class="domain">(<a href="https://lucaspauker.com">lucaspauker.com</a>)</span></div><div class="subtext"><span>lucaspauker</span> | <span>75 comments</span></div><br/><div><div id="36900969" class="c"><input type="checkbox" id="c-36900969" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#36901437">next</a><span>|</span><label class="collapse" for="c-36900969">[-]</label><label class="expand" for="c-36900969">[2 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;<i>The idea of fine-tuning has a strong research pedigree. The approach can be traced back to 2018, when two influential papers were published.</i>&quot;<p>The article refers to the BERT and GPT papers as the source of the fine-tuning idea. However, we actually first demonstrated it for universal models in 2017 and published the ULMFiT (Howard and Ruder) paper in early 2018. Prior to that, Dai and Le demonstrated the technique for in-corpus datasets. So it would be more accurate to say the approach can be traced back to those two papers, rather than to BERT and GPT.<p>BERT and GPT showed the effectiveness of scaling up the amount of data and compute, and switching the model architecture to Transformers (amongst other things).</div><br/><div id="36901290" class="c"><input type="checkbox" id="c-36901290" checked=""/><div class="controls bullet"><span class="by">newhaus1994</span><span>|</span><a href="#36900969">parent</a><span>|</span><a href="#36901437">next</a><span>|</span><label class="collapse" for="c-36901290">[-]</label><label class="expand" for="c-36901290">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, my understanding is the ULMFit paper was the “genesis”
Of fine-tuning in the way we mean it now.</div><br/></div></div></div></div><div id="36901437" class="c"><input type="checkbox" id="c-36901437" checked=""/><div class="controls bullet"><span class="by">LASR</span><span>|</span><a href="#36900969">prev</a><span>|</span><a href="#36901664">next</a><span>|</span><label class="collapse" for="c-36901437">[-]</label><label class="expand" for="c-36901437">[16 more]</label></div><br/><div class="children"><div class="content">We’ve found that 1-shot or few-shot methods with 3.5Turbo or 4 are vastly simpler and exceeds the quality of fine-tuned models from the GPT-3 era.<p>We have some 100k context models too that can ingest entire documents.<p>So right now, I would say fine-tuning is probably only useful for a very narrow set of use cases.</div><br/><div id="36903541" class="c"><input type="checkbox" id="c-36903541" checked=""/><div class="controls bullet"><span class="by">jamesblonde</span><span>|</span><a href="#36901437">parent</a><span>|</span><a href="#36901687">next</a><span>|</span><label class="collapse" for="c-36903541">[-]</label><label class="expand" for="c-36903541">[1 more]</label></div><br/><div class="children"><div class="content">There is some debate about whether in-context learning is real or not, but there are many data points (and articles) showing that it is an emergent pronomena, and it emergence in models of that order of magnitude (gpt-3.5-turbo, gpt-4, and beyond).<p>References found here:
<a href="https:&#x2F;&#x2F;www.hopsworks.ai&#x2F;dictionary&#x2F;in-context-learning-icl" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.hopsworks.ai&#x2F;dictionary&#x2F;in-context-learning-icl</a></div><br/></div></div><div id="36901687" class="c"><input type="checkbox" id="c-36901687" checked=""/><div class="controls bullet"><span class="by">danenania</span><span>|</span><a href="#36901437">parent</a><span>|</span><a href="#36903541">prev</a><span>|</span><a href="#36902999">next</a><span>|</span><label class="collapse" for="c-36901687">[-]</label><label class="expand" for="c-36901687">[12 more]</label></div><br/><div class="children"><div class="content">Even 100k still seems very limiting for many applications naturally suited to LLMs.<p>What if I want an AI assistant that is specifically trained on a large codebase? Or all my product’s docs (which might easily exceed 100k characters for a big project). Or one that knows the exact details of the entire tax code? Or one that knows every line of Dostoyevsky’s novels so I can have angsty existential conversations with it? Or that can fully remember conversations with me that stretch on for years?<p>It seems like you’d need fine tuning for these kinds of use cases? Or am I missing something?</div><br/><div id="36904103" class="c"><input type="checkbox" id="c-36904103" checked=""/><div class="controls bullet"><span class="by">SanderNL</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901687">parent</a><span>|</span><a href="#36901728">next</a><span>|</span><label class="collapse" for="c-36904103">[-]</label><label class="expand" for="c-36904103">[1 more]</label></div><br/><div class="children"><div class="content">You basically can&#x27;t. We haven&#x27;t developed that kind of AI.<p>Some of us hope that just-in-time retrieval of data from an external source (usually a vector db) is going to work. Like, say, &quot;retrieve chapter 3 of Dostoyevsky&#x27;s CP and make an interesting comment about it&quot;. For the record, you can have plenty of interesting angsty existential conversations with both GPTs about D right now if you so desire. Just preface your dialogue with something slightly more sophisticated than &quot;let us have an angsty existential conversation about Dostoyevsky&quot;.<p>This JIT retrieval might work for some cases, but my guess is it won&#x27;t for large holistic pieces of work where you have to integrate and &quot;understand&quot; the entire edifice at once. I&#x27;m not completely sure if codebases merit such a distinction though, but you can imagine a domain like &quot;law&quot; might. We can push the context limit and this might bring some temporary relief, but I&#x27;m not convinced. The recent pushes to 100K seem to rely on &quot;dropping&quot; attention in an intelligent way. It sounds like cheating and while it might work OK for some cases, I think it&#x27;ll drop the ball eventually.<p>The integrated understanding that results from, somehow, internalizing the relation between all the hundreds of thousands of seemingly unrelated datapoints is what makes us interesting. That&#x27;s also what makes an LLM interesting. It&#x27;s just that an LLM only has access to that level of development when it&#x27;s training.<p>If I were to guess I think we somehow need to enable &quot;always-training&quot; and I&#x27;m not sure anyone has the faintest idea how. You can only go so far if you step out of school and never learn <i>anything</i> ever again, no matter how brilliant you are. GPT4 is quite the scholar, but we&#x27;re stretching it.</div><br/></div></div><div id="36901728" class="c"><input type="checkbox" id="c-36901728" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901687">parent</a><span>|</span><a href="#36904103">prev</a><span>|</span><a href="#36904175">next</a><span>|</span><label class="collapse" for="c-36901728">[-]</label><label class="expand" for="c-36901728">[5 more]</label></div><br/><div class="children"><div class="content">You use a (probably vector, ideally) database and a framework of behind-the-scenes prompting that uses it to do a “research loop” to gather info to answer questions. You might also fine tune it on the source you want it to incorporate, but training (including fine tuning) is most useful (as I understand) to provide “understanding”, not exact recall, whereas a searchable auxiliary memory and a framework which accesses it as part of the process of generating user responses is a way to provide exact recall over a larger dataset.</div><br/><div id="36901839" class="c"><input type="checkbox" id="c-36901839" checked=""/><div class="controls bullet"><span class="by">danenania</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901728">parent</a><span>|</span><a href="#36904175">next</a><span>|</span><label class="collapse" for="c-36901839">[-]</label><label class="expand" for="c-36901839">[4 more]</label></div><br/><div class="children"><div class="content">Ok, I see what you&#x27;re saying, but at least for the big codebase example, and I&#x27;d imagine for many other applications as well, are you really going to get good output by just loading in bits and pieces, even if they are intelligently selected? It seems like holistic &quot;understanding&quot; is exactly what you want in that case, so that the model can take into account the full architecture and know how every component and sub-component fits together.<p>I wouldn&#x27;t look forward to a PR for a significant feature from a human developer that just skimmed through all of a project&#x27;s files and only read a handful of them in depth, so I guess I&#x27;m also skeptical this would lead to good results from an LLM.</div><br/><div id="36904076" class="c"><input type="checkbox" id="c-36904076" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901839">parent</a><span>|</span><a href="#36901963">next</a><span>|</span><label class="collapse" for="c-36904076">[-]</label><label class="expand" for="c-36904076">[1 more]</label></div><br/><div class="children"><div class="content">But finetuning wouldn&#x27;t give the LLM a holistic understanding. LLMs are finetuned to predict the next token. At best you give them a full file at a time, but more likely, you create batches of similar length sequences. So while finetuning will lead to the LLM seeing all the codebase, it won&#x27;t necessarily know how all the files fit together (for example I&#x27;m pretty sure it won&#x27;t see folder structure, unless you somehow include it via preprocessing)</div><br/></div></div><div id="36901963" class="c"><input type="checkbox" id="c-36901963" checked=""/><div class="controls bullet"><span class="by">taberiand</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901839">parent</a><span>|</span><a href="#36904076">prev</a><span>|</span><a href="#36904175">next</a><span>|</span><label class="collapse" for="c-36901963">[-]</label><label class="expand" for="c-36901963">[2 more]</label></div><br/><div class="children"><div class="content">I think the suggested process is to ingest all of the code base into a vector database and provide prompts and APIs for the model to search and focus on relevant areas while developing a feature, which is analogous (identical, even) to how a human would approach the process - with long term and short term memory and applying general and specific experience.</div><br/><div id="36902401" class="c"><input type="checkbox" id="c-36902401" checked=""/><div class="controls bullet"><span class="by">XenophileJKO</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901963">parent</a><span>|</span><a href="#36904175">next</a><span>|</span><label class="collapse" for="c-36902401">[-]</label><label class="expand" for="c-36902401">[1 more]</label></div><br/><div class="children"><div class="content">You can also create hierarchical summaries that help the model select the right starting place in the code base.<p>Additionally fine tuning isn&#x27;t a great fit for mutable knowledge like a code base.</div><br/></div></div></div></div></div></div></div></div><div id="36904175" class="c"><input type="checkbox" id="c-36904175" checked=""/><div class="controls bullet"><span class="by">zbyforgotp</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901687">parent</a><span>|</span><a href="#36901728">prev</a><span>|</span><a href="#36901724">next</a><span>|</span><label class="collapse" for="c-36904175">[-]</label><label class="expand" for="c-36904175">[1 more]</label></div><br/><div class="children"><div class="content">Finetuning is not useful for teaching new facts, you need RAG for that: <a href="https:&#x2F;&#x2F;zzbbyy.substack.com&#x2F;p&#x2F;why-you-need-rag-not-finetuning" rel="nofollow noreferrer">https:&#x2F;&#x2F;zzbbyy.substack.com&#x2F;p&#x2F;why-you-need-rag-not-finetunin...</a></div><br/></div></div><div id="36901724" class="c"><input type="checkbox" id="c-36901724" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901687">parent</a><span>|</span><a href="#36904175">prev</a><span>|</span><a href="#36902999">next</a><span>|</span><label class="collapse" for="c-36901724">[-]</label><label class="expand" for="c-36901724">[4 more]</label></div><br/><div class="children"><div class="content">You use a vector database with a query similarity search to find portions of documents that might be relevant to your prompt, rank them, take the top n, put them into the context and run through your LLM to generate an answer to your question.</div><br/><div id="36901898" class="c"><input type="checkbox" id="c-36901898" checked=""/><div class="controls bullet"><span class="by">fzliu</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901724">parent</a><span>|</span><a href="#36902999">next</a><span>|</span><label class="collapse" for="c-36901898">[-]</label><label class="expand" for="c-36901898">[3 more]</label></div><br/><div class="children"><div class="content">This paradigm applies for much more than just answering questions - I&#x27;ve found the in-context learning capabilities to be very relevant as well. For example, you can query a vector database and input that information into an LLM and ask it to make a prediction across the input data.<p><a href="https:&#x2F;&#x2F;zilliz.com&#x2F;blog&#x2F;ChatGPT-VectorDB-Prompt-as-code" rel="nofollow noreferrer">https:&#x2F;&#x2F;zilliz.com&#x2F;blog&#x2F;ChatGPT-VectorDB-Prompt-as-code</a></div><br/><div id="36902411" class="c"><input type="checkbox" id="c-36902411" checked=""/><div class="controls bullet"><span class="by">alach11</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901898">parent</a><span>|</span><a href="#36901917">next</a><span>|</span><label class="collapse" for="c-36902411">[-]</label><label class="expand" for="c-36902411">[1 more]</label></div><br/><div class="children"><div class="content">Can you elaborate? I don’t understand how the article you linked is different from normal question answering with context.</div><br/></div></div><div id="36901917" class="c"><input type="checkbox" id="c-36901917" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36901437">root</a><span>|</span><a href="#36901898">parent</a><span>|</span><a href="#36902411">prev</a><span>|</span><a href="#36902999">next</a><span>|</span><label class="collapse" for="c-36901917">[-]</label><label class="expand" for="c-36901917">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s pretty cool, thanks for sharing!</div><br/></div></div></div></div></div></div></div></div><div id="36902999" class="c"><input type="checkbox" id="c-36902999" checked=""/><div class="controls bullet"><span class="by">tornato7</span><span>|</span><a href="#36901437">parent</a><span>|</span><a href="#36901687">prev</a><span>|</span><a href="#36903039">next</a><span>|</span><label class="collapse" for="c-36902999">[-]</label><label class="expand" for="c-36902999">[1 more]</label></div><br/><div class="children"><div class="content">What I could see fine-tuning being very useful for is efficiency, either getting GPT-4 Level performance out of a smaller model or pruning GPT-4 for your specific needs.<p>After all, if I just want to detect from text what color and brightness the user wants to adjust their lights to, it seems inefficient to use a model that&#x27;s been trained on all of human knowledge, even if I&#x27;m sure it&#x27;ll work just fine.</div><br/></div></div><div id="36903039" class="c"><input type="checkbox" id="c-36903039" checked=""/><div class="controls bullet"><span class="by">az226</span><span>|</span><a href="#36901437">parent</a><span>|</span><a href="#36902999">prev</a><span>|</span><a href="#36901664">next</a><span>|</span><label class="collapse" for="c-36903039">[-]</label><label class="expand" for="c-36903039">[1 more]</label></div><br/><div class="children"><div class="content">That depends on the scale and balance of inferencing vs. training.</div><br/></div></div></div></div><div id="36901664" class="c"><input type="checkbox" id="c-36901664" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#36901437">prev</a><span>|</span><a href="#36903707">next</a><span>|</span><label class="collapse" for="c-36901664">[-]</label><label class="expand" for="c-36901664">[10 more]</label></div><br/><div class="children"><div class="content">This is basically an ad for fine-tuning as a service.<p>Can anyone offer an example of a free public-facing LLM which has been fine-tuned by adding much specific info about some narrow area? Say, one that knows all the PR about some car brand or fandom? Somebody must have tried that by now.</div><br/><div id="36902306" class="c"><input type="checkbox" id="c-36902306" checked=""/><div class="controls bullet"><span class="by">joshka</span><span>|</span><a href="#36901664">parent</a><span>|</span><a href="#36901718">next</a><span>|</span><label class="collapse" for="c-36902306">[-]</label><label class="expand" for="c-36902306">[2 more]</label></div><br/><div class="children"><div class="content">Take a look at <a href="https:&#x2F;&#x2F;replicate.com&#x2F;blog&#x2F;fine-tune-llama-to-speak-like-homer-simpson">https:&#x2F;&#x2F;replicate.com&#x2F;blog&#x2F;fine-tune-llama-to-speak-like-hom...</a> (and the related blog posts) for a good example of this.</div><br/><div id="36902778" class="c"><input type="checkbox" id="c-36902778" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#36901664">root</a><span>|</span><a href="#36902306">parent</a><span>|</span><a href="#36901718">next</a><span>|</span><label class="collapse" for="c-36902778">[-]</label><label class="expand" for="c-36902778">[1 more]</label></div><br/><div class="children"><div class="content">Well, OK. They put in 61,000 lines, the entire first 12 seasons of the Simpsons&#x27;s. Lines such as<p><pre><code>    {&#x27;previous&#x27;: &#x27;Marge Simpson: Ooo, careful, Homer.&#x27;,
     &#x27;character&#x27;: &#x27;Homer Simpson&#x27;,
     &#x27;line&#x27;: &quot;There&#x27;s no time to be careful.&quot;}
</code></pre>
and then used it to generate more Simpsons dialogue. With a data set so well matched to the goal, the algorithm barely matters. Remember that recent paper, &quot;Copy is all you need.&quot;?[1] This is the ideal case for that approach.<p>I&#x27;m thinking more in terms of loading in the detailed product descriptions and maybe manuals from a catalog, then letting users ask questions about how to do things with the products.<p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36758233">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36758233</a></div><br/></div></div></div></div><div id="36901718" class="c"><input type="checkbox" id="c-36901718" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36901664">parent</a><span>|</span><a href="#36902306">prev</a><span>|</span><a href="#36901855">next</a><span>|</span><label class="collapse" for="c-36901718">[-]</label><label class="expand" for="c-36901718">[6 more]</label></div><br/><div class="children"><div class="content">The only known to me is LLaMA 2 to remove censorship using LoRA.</div><br/><div id="36901796" class="c"><input type="checkbox" id="c-36901796" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#36901664">root</a><span>|</span><a href="#36901718">parent</a><span>|</span><a href="#36901878">next</a><span>|</span><label class="collapse" for="c-36901796">[-]</label><label class="expand" for="c-36901796">[3 more]</label></div><br/><div class="children"><div class="content">Hm. Why aren&#x27;t those things all over the place?</div><br/><div id="36901824" class="c"><input type="checkbox" id="c-36901824" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36901664">root</a><span>|</span><a href="#36901796">parent</a><span>|</span><a href="#36902718">next</a><span>|</span><label class="collapse" for="c-36901824">[-]</label><label class="expand" for="c-36901824">[1 more]</label></div><br/><div class="children"><div class="content">They kinda are, HuggingFace hub is already full of them. Most of them were released like 3-4 days ago so that might be a reason why you don&#x27;t see them. I already put one of them into production.</div><br/></div></div><div id="36902718" class="c"><input type="checkbox" id="c-36902718" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#36901664">root</a><span>|</span><a href="#36901796">parent</a><span>|</span><a href="#36901824">prev</a><span>|</span><a href="#36901878">next</a><span>|</span><label class="collapse" for="c-36902718">[-]</label><label class="expand" for="c-36902718">[1 more]</label></div><br/><div class="children"><div class="content">The people that make them often post them or comment in the sub-Reddit below. I&#x27;ve linked to a search for uncensored models in there. Usernames of main people involved are faldore and The-Bloke. Most had Wizard Uncensored in their names.<p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;search&#x2F;?q=uncensored&amp;restrict_sr=1" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;search&#x2F;?q=uncensored&amp;res...</a><p>People have posted comparisons showing it works pretty well. Some foundational models have enough censorship built in that they still try to resist it. You have to prompt those cleverly to do what you want them to do.</div><br/></div></div></div></div><div id="36901878" class="c"><input type="checkbox" id="c-36901878" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#36901664">root</a><span>|</span><a href="#36901718">parent</a><span>|</span><a href="#36901796">prev</a><span>|</span><a href="#36901855">next</a><span>|</span><label class="collapse" for="c-36901878">[-]</label><label class="expand" for="c-36901878">[2 more]</label></div><br/><div class="children"><div class="content">There are tons of them for other models, often Alpaca or LLaMA.<p>This is a popular tool for finetuning Alpaca:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;tloen&#x2F;alpaca-lora">https:&#x2F;&#x2F;github.com&#x2F;tloen&#x2F;alpaca-lora</a></div><br/><div id="36901886" class="c"><input type="checkbox" id="c-36901886" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36901664">root</a><span>|</span><a href="#36901878">parent</a><span>|</span><a href="#36901855">next</a><span>|</span><label class="collapse" for="c-36901886">[-]</label><label class="expand" for="c-36901886">[1 more]</label></div><br/><div class="children"><div class="content">LLaMA or Alpaca aren&#x27;t free outside research though, so it&#x27;s better to focus on LLaMA 2.</div><br/></div></div></div></div></div></div><div id="36901855" class="c"><input type="checkbox" id="c-36901855" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#36901664">parent</a><span>|</span><a href="#36901718">prev</a><span>|</span><a href="#36903707">next</a><span>|</span><label class="collapse" for="c-36901855">[-]</label><label class="expand" for="c-36901855">[1 more]</label></div><br/><div class="children"><div class="content">There are lots of guides out there, but most these days tend to be selling something under the covers. Here’s one a quick Kagi found on llama 2:<p><a href="https:&#x2F;&#x2F;towardsdatascience.com&#x2F;fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32" rel="nofollow noreferrer">https:&#x2F;&#x2F;towardsdatascience.com&#x2F;fine-tune-your-own-llama-2-mo...</a></div><br/></div></div></div></div><div id="36903707" class="c"><input type="checkbox" id="c-36903707" checked=""/><div class="controls bullet"><span class="by">coffee_am</span><span>|</span><a href="#36901664">prev</a><span>|</span><a href="#36900955">next</a><span>|</span><label class="collapse" for="c-36903707">[-]</label><label class="expand" for="c-36903707">[1 more]</label></div><br/><div class="children"><div class="content">Noob question: when folks talk about fine-tuning LLM, do they usually fine-tune the encoder (of the prompt), the decoder (that generates the text) or both ?</div><br/></div></div><div id="36900955" class="c"><input type="checkbox" id="c-36900955" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36903707">prev</a><span>|</span><a href="#36899979">next</a><span>|</span><label class="collapse" for="c-36900955">[-]</label><label class="expand" for="c-36900955">[26 more]</label></div><br/><div class="children"><div class="content">This is 2020-level stuff. These days with emergent abilities in LLMs trained with over 1T tokens like GPT-4 a single-shot chain-of-thought beats most fine-tunings. I did research on transformer adapters i.e. parameter-efficient fine-tuning and that stuff is now completely obsolete outside of some restricted domains where small models can still perform well.</div><br/><div id="36900996" class="c"><input type="checkbox" id="c-36900996" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#36900955">parent</a><span>|</span><a href="#36901298">next</a><span>|</span><label class="collapse" for="c-36900996">[-]</label><label class="expand" for="c-36900996">[5 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t seen any recent papers that show that fine-tuning is obsolete - I&#x27;ve only seen papers showing the opposite. I&#x27;d be very interested to see any papers that have demonstrated applications where fine-tuning is not effective nowadays, if you have any links.<p>Here&#x27;s an example of a paper that shows good results from fine-tuning for instance: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.02301" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.02301</a></div><br/><div id="36901299" class="c"><input type="checkbox" id="c-36901299" checked=""/><div class="controls bullet"><span class="by">ssivark</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36900996">parent</a><span>|</span><a href="#36901015">next</a><span>|</span><label class="collapse" for="c-36901299">[-]</label><label class="expand" for="c-36901299">[2 more]</label></div><br/><div class="children"><div class="content">What’s your take on the argument that fine tuning might be destroying model calibration and causing it to overfit to aspects of the finetuning dataset eg: causing it to appear more confident, rather than becoming more correct?<p>See <a href="https:&#x2F;&#x2F;twitter.com&#x2F;animaanandkumar&#x2F;status&#x2F;1681690654060187648" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;animaanandkumar&#x2F;status&#x2F;16816906540601876...</a></div><br/><div id="36902087" class="c"><input type="checkbox" id="c-36902087" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901299">parent</a><span>|</span><a href="#36901015">next</a><span>|</span><label class="collapse" for="c-36902087">[-]</label><label class="expand" for="c-36902087">[1 more]</label></div><br/><div class="children"><div class="content">That tweet is about a specific type of fine tuning: instruction tuning and RLHF. It causes to get better at the thing that it&#x27;s being fine tuned for, which is making users feel better about the answer. Whether that&#x27;s actually desirable in all cases is the question -- but that&#x27;s not really related to whether fine tuning is a useful tool in general.</div><br/></div></div></div></div><div id="36901015" class="c"><input type="checkbox" id="c-36901015" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36900996">parent</a><span>|</span><a href="#36901299">prev</a><span>|</span><a href="#36901298">next</a><span>|</span><label class="collapse" for="c-36901015">[-]</label><label class="expand" for="c-36901015">[2 more]</label></div><br/><div class="children"><div class="content">This Stanford seminar video can provide some references:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=tVtOevLrt5U">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=tVtOevLrt5U</a></div><br/><div id="36902107" class="c"><input type="checkbox" id="c-36902107" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901015">parent</a><span>|</span><a href="#36901298">next</a><span>|</span><label class="collapse" for="c-36902107">[-]</label><label class="expand" for="c-36902107">[1 more]</label></div><br/><div class="children"><div class="content">That video shows examples of new models with one-shot performance better than old models with fine-tuning. It doesn&#x27;t compare new models with fine-tuning to new models without fine-tuning.</div><br/></div></div></div></div></div></div><div id="36901298" class="c"><input type="checkbox" id="c-36901298" checked=""/><div class="controls bullet"><span class="by">royal__</span><span>|</span><a href="#36900955">parent</a><span>|</span><a href="#36900996">prev</a><span>|</span><a href="#36902170">next</a><span>|</span><label class="collapse" for="c-36901298">[-]</label><label class="expand" for="c-36901298">[2 more]</label></div><br/><div class="children"><div class="content">I would agree with other commenters that fine tuning is very much not obsolete, and for another important reason: many people and domains do not have the resources or even desire to work with extremely large models like GPT-4. The world outside of OpenAIs monoliths is still very much important.</div><br/><div id="36901974" class="c"><input type="checkbox" id="c-36901974" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901298">parent</a><span>|</span><a href="#36902170">next</a><span>|</span><label class="collapse" for="c-36901974">[-]</label><label class="expand" for="c-36901974">[1 more]</label></div><br/><div class="children"><div class="content">Yep as soon as query per second matters, and cost per query... Definitely going through that on some work now, where we use GPT4 on subset and rest on GPT3 or tuned. Only slow user-facing and other low-volume &#x2F; high-latency goes to GPT4..</div><br/></div></div></div></div><div id="36902170" class="c"><input type="checkbox" id="c-36902170" checked=""/><div class="controls bullet"><span class="by">cypress66</span><span>|</span><a href="#36900955">parent</a><span>|</span><a href="#36901298">prev</a><span>|</span><a href="#36901555">next</a><span>|</span><label class="collapse" for="c-36902170">[-]</label><label class="expand" for="c-36902170">[1 more]</label></div><br/><div class="children"><div class="content">Finetuning is more relevant than ever now. People are fine tuning LLaMA every single day.</div><br/></div></div><div id="36901555" class="c"><input type="checkbox" id="c-36901555" checked=""/><div class="controls bullet"><span class="by">winddude</span><span>|</span><a href="#36900955">parent</a><span>|</span><a href="#36902170">prev</a><span>|</span><a href="#36901228">next</a><span>|</span><label class="collapse" for="c-36901555">[-]</label><label class="expand" for="c-36901555">[1 more]</label></div><br/><div class="children"><div class="content">GPT-4 is a fine tuned model.</div><br/></div></div><div id="36901228" class="c"><input type="checkbox" id="c-36901228" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#36900955">parent</a><span>|</span><a href="#36901555">prev</a><span>|</span><a href="#36901651">next</a><span>|</span><label class="collapse" for="c-36901228">[-]</label><label class="expand" for="c-36901228">[15 more]</label></div><br/><div class="children"><div class="content">Gosh you are so wrong. Literally every bit of fine tuning and fine tuning related work is more important than ever. Being able to fine tune a giant model like GPT-4 would be a game changer. I don’t get why people like to come on here and tell blatant lies like this.</div><br/><div id="36901264" class="c"><input type="checkbox" id="c-36901264" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901228">parent</a><span>|</span><a href="#36902476">next</a><span>|</span><label class="collapse" for="c-36901264">[-]</label><label class="expand" for="c-36901264">[12 more]</label></div><br/><div class="children"><div class="content">What would be my incentive to lie? I am getting absolutely breathtaking results from multi-task single shot prompts with one &gt;1T model where I would need to fine-tune dozens of models to get anywhere close, and likely with less reliability. While fine-tuning might be important to bring some benefits to smaller models, in the really big models CoT is often much better.</div><br/><div id="36901311" class="c"><input type="checkbox" id="c-36901311" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901264">parent</a><span>|</span><a href="#36901740">next</a><span>|</span><label class="collapse" for="c-36901311">[-]</label><label class="expand" for="c-36901311">[8 more]</label></div><br/><div class="children"><div class="content">General models are useful to the general public, and they&#x27;re useful as a starting point to find tune to a smaller model.  The purpose matters.  Research and most products benefit heavily from having a <i>much</i> smaller model (speed) to do <i>one</i> thing very well on trillions of documents.  General chatting from big models is mostly a gimmick, but they&#x27;re still very useful to find tune.</div><br/><div id="36901376" class="c"><input type="checkbox" id="c-36901376" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901311">parent</a><span>|</span><a href="#36901740">next</a><span>|</span><label class="collapse" for="c-36901376">[-]</label><label class="expand" for="c-36901376">[7 more]</label></div><br/><div class="children"><div class="content">The thing is that those super large models with CoT are often much more reliable than specialized fine-tuned smaller models you&#x27;d like to use on trillions of documents, as I am observing right now. You are not trading just speed but also quality with smaller models. The only relevant use case for fine-tuning for me recently was to apply wizard dataset to LLaMA 2 for a less censored model and that was done using LoRA.</div><br/><div id="36901452" class="c"><input type="checkbox" id="c-36901452" checked=""/><div class="controls bullet"><span class="by">byt143</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901376">parent</a><span>|</span><a href="#36901740">next</a><span>|</span><label class="collapse" for="c-36901452">[-]</label><label class="expand" for="c-36901452">[6 more]</label></div><br/><div class="children"><div class="content">What tasks?</div><br/><div id="36901500" class="c"><input type="checkbox" id="c-36901500" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901452">parent</a><span>|</span><a href="#36901740">next</a><span>|</span><label class="collapse" for="c-36901500">[-]</label><label class="expand" for="c-36901500">[5 more]</label></div><br/><div class="children"><div class="content">For processing trillion documents for example NER can be done much better.</div><br/><div id="36903316" class="c"><input type="checkbox" id="c-36903316" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901500">parent</a><span>|</span><a href="#36902217">next</a><span>|</span><label class="collapse" for="c-36903316">[-]</label><label class="expand" for="c-36903316">[1 more]</label></div><br/><div class="children"><div class="content">This tradeoff is ridiculous, even if it is &quot;better&quot; by .01% F score.  I would much rather have a dataset created in 1 day from BERT at 98% F-score than 1000 years at 98.01% F-score from a 540B parameter model, or even a 33B parameter model.  The performance in million parameter models for NER is still excellent, and works at speed that are usable.  Running things through OpenAI is also useless, as it would cost a few million $.</div><br/></div></div><div id="36902217" class="c"><input type="checkbox" id="c-36902217" checked=""/><div class="controls bullet"><span class="by">byt143</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901500">parent</a><span>|</span><a href="#36903316">prev</a><span>|</span><a href="#36901751">next</a><span>|</span><label class="collapse" for="c-36902217">[-]</label><label class="expand" for="c-36902217">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s really depressing that a handful of big corporations will be able to exert such control over labor and productivity</div><br/></div></div><div id="36901751" class="c"><input type="checkbox" id="c-36901751" checked=""/><div class="controls bullet"><span class="by">jerrygenser</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901500">parent</a><span>|</span><a href="#36902217">prev</a><span>|</span><a href="#36901740">next</a><span>|</span><label class="collapse" for="c-36901751">[-]</label><label class="expand" for="c-36901751">[2 more]</label></div><br/><div class="children"><div class="content">You are literally using trillion documents? Or are you exaggerating?</div><br/><div id="36901879" class="c"><input type="checkbox" id="c-36901879" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901751">parent</a><span>|</span><a href="#36901740">next</a><span>|</span><label class="collapse" for="c-36901879">[-]</label><label class="expand" for="c-36901879">[1 more]</label></div><br/><div class="children"><div class="content">chaxor above mentioned it so I quickly recalled a task I saw a super large LLM demolishing fine-tuned models on documents.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36901740" class="c"><input type="checkbox" id="c-36901740" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901264">parent</a><span>|</span><a href="#36901311">prev</a><span>|</span><a href="#36902476">next</a><span>|</span><label class="collapse" for="c-36901740">[-]</label><label class="expand" for="c-36901740">[3 more]</label></div><br/><div class="children"><div class="content">I’d like to generate Minecraft fan fic. GPT4 does a terrible job because it’s been lobotomized. Fine tuning a model with a corpus of fan fic generates better fan fic. If I could fine tune GPT4 then ok I agree. But “general purpose lobotomized oracle” is only one use case for a language model, albeit a useful one, is the least creative one.</div><br/><div id="36901764" class="c"><input type="checkbox" id="c-36901764" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901740">parent</a><span>|</span><a href="#36902476">next</a><span>|</span><label class="collapse" for="c-36901764">[-]</label><label class="expand" for="c-36901764">[2 more]</label></div><br/><div class="children"><div class="content">OK, understood. You might do that with uncensored versions of LLaMA 2 now. Role playing&#x2F;fan fic is much better with those.</div><br/><div id="36902677" class="c"><input type="checkbox" id="c-36902677" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901764">parent</a><span>|</span><a href="#36902476">next</a><span>|</span><label class="collapse" for="c-36902677">[-]</label><label class="expand" for="c-36902677">[1 more]</label></div><br/><div class="children"><div class="content">They tend to not have the right base of training materials - the models are constrained not just by the lobotomization but by some specialized writing not being part of the corpus. Training a lora on a specific corpus - fan fic, alt.sex.stories, or a persons specific writing, can help induce behavior or language choices specific to that corpus.  You can also use context injection but I’ve found combining a model weight adjustment with priming the context to be the most effective.<p>I think over time it’ll become standard practice to train special purpose models on top of general purpose models. If I have a very specific task domain a model tuned to that domain will less often wander off and will be more likely to respond in the desired way.</div><br/></div></div></div></div></div></div></div></div><div id="36902476" class="c"><input type="checkbox" id="c-36902476" checked=""/><div class="controls bullet"><span class="by">hooande</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36901228">parent</a><span>|</span><a href="#36901264">prev</a><span>|</span><a href="#36901651">next</a><span>|</span><label class="collapse" for="c-36902476">[-]</label><label class="expand" for="c-36902476">[2 more]</label></div><br/><div class="children"><div class="content">Such a strong dismissal of another comment should come with some kind of objective evidence. Is there any way to prove that fine tuning is as valuable as you say it is?</div><br/><div id="36904275" class="c"><input type="checkbox" id="c-36904275" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#36900955">root</a><span>|</span><a href="#36902476">parent</a><span>|</span><a href="#36901651">next</a><span>|</span><label class="collapse" for="c-36904275">[-]</label><label class="expand" for="c-36904275">[1 more]</label></div><br/><div class="children"><div class="content">It’s self evident to anyone whose seriously worked in the field.</div><br/></div></div></div></div></div></div><div id="36901651" class="c"><input type="checkbox" id="c-36901651" checked=""/><div class="controls bullet"><span class="by">Blahah</span><span>|</span><a href="#36900955">parent</a><span>|</span><a href="#36901228">prev</a><span>|</span><a href="#36899979">next</a><span>|</span><label class="collapse" for="c-36901651">[-]</label><label class="expand" for="c-36901651">[1 more]</label></div><br/><div class="children"><div class="content">This claim is meaningless without being specific about the tasks.</div><br/></div></div></div></div><div id="36899979" class="c"><input type="checkbox" id="c-36899979" checked=""/><div class="controls bullet"><span class="by">mickeyfrac</span><span>|</span><a href="#36900955">prev</a><span>|</span><a href="#36900736">next</a><span>|</span><label class="collapse" for="c-36899979">[-]</label><label class="expand" for="c-36899979">[2 more]</label></div><br/><div class="children"><div class="content">The link to your terra cotta product, which I assume is the point of the article, is broken.</div><br/></div></div><div id="36900736" class="c"><input type="checkbox" id="c-36900736" checked=""/><div class="controls bullet"><span class="by">SpaceManNabs</span><span>|</span><a href="#36899979">prev</a><span>|</span><a href="#36902933">next</a><span>|</span><label class="collapse" for="c-36900736">[-]</label><label class="expand" for="c-36900736">[1 more]</label></div><br/><div class="children"><div class="content">I like that your article was well cited. Fun read. Nothing stands out as too inaccurate.<p>You should try a post on parameter efficient tuning next!</div><br/></div></div><div id="36902933" class="c"><input type="checkbox" id="c-36902933" checked=""/><div class="controls bullet"><span class="by">zmmmmm</span><span>|</span><a href="#36900736">prev</a><span>|</span><a href="#36901112">next</a><span>|</span><label class="collapse" for="c-36902933">[-]</label><label class="expand" for="c-36902933">[2 more]</label></div><br/><div class="children"><div class="content">Fine tuning seems to me to be dangerously close to a new snake oil of AI these days.<p>The narrative goes, &quot;look how awesome ChatGPT is, imagine how good it would be trained on just your company&#x27;s documents&quot;.<p>Which 1000% misses the point. ChatGPT is because (a) it is trained on almost nothing short of the entire corpus of human language ever created. At &gt; 1 trillion parameters, it can have ~1000 parameters for every human on the planet. Let that sink in. And then (b) because it has been subjected to an unknown but likely massive amount of human reinforcement feedback.<p>The idea that you can meaningfully impact the output of the model towards factual accuracy or logical correctness just by doing a small amount of fully automated training using a tiny corpus of company documents is seductive, but super far from robustly demonstrated as far as I&#x27;m aware. Yet this is the pitch being sold very often.</div><br/><div id="36903137" class="c"><input type="checkbox" id="c-36903137" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36902933">parent</a><span>|</span><a href="#36901112">next</a><span>|</span><label class="collapse" for="c-36903137">[-]</label><label class="expand" for="c-36903137">[1 more]</label></div><br/><div class="children"><div class="content">What? Fine tuning has been a common technique for years now. Fine tuned BERT models were behind a lot of retrieval-based systems and they work well.<p>A more recent example is stable diffusion fine tuned on specific subjects.<p>Whether fine tuning can reduce hallucination is first of all a question which only pertains to decoders and which is highly dependent on how the model has been fine tuned.</div><br/></div></div></div></div><div id="36901112" class="c"><input type="checkbox" id="c-36901112" checked=""/><div class="controls bullet"><span class="by">phas0ruk</span><span>|</span><a href="#36902933">prev</a><span>|</span><a href="#36901593">next</a><span>|</span><label class="collapse" for="c-36901112">[-]</label><label class="expand" for="c-36901112">[3 more]</label></div><br/><div class="children"><div class="content">Helpful. I was thinking today about when it makes sense to fine tune vs use embeddings to feed into the LLM prompt and this helped solidify my understanding.</div><br/><div id="36901304" class="c"><input type="checkbox" id="c-36901304" checked=""/><div class="controls bullet"><span class="by">DebtDeflation</span><span>|</span><a href="#36901112">parent</a><span>|</span><a href="#36902328">next</a><span>|</span><label class="collapse" for="c-36901304">[-]</label><label class="expand" for="c-36901304">[1 more]</label></div><br/><div class="children"><div class="content">Except that the article didn&#x27;t cover that distinction at all.  It looked at (manual) prompt engineering vs fine tuning.  What you are describing is Retrieval Augmented Generation (RAG) which is creating embeddings from a knowledgebase, doing a similarity search using an embedding of the search query, and then programmatically generating a prompt from the search query and the returned content.  IMO, this design pattern should be preferred to fine tuning in the vast majority of use cases.  Fine tuning should be used to get the model to perform new tasks; RAG should be used instead to add knowledge.</div><br/></div></div><div id="36902328" class="c"><input type="checkbox" id="c-36902328" checked=""/><div class="controls bullet"><span class="by">joshka</span><span>|</span><a href="#36901112">parent</a><span>|</span><a href="#36901304">prev</a><span>|</span><a href="#36901593">next</a><span>|</span><label class="collapse" for="c-36902328">[-]</label><label class="expand" for="c-36902328">[1 more]</label></div><br/><div class="children"><div class="content">Realistically this seems like a question that would be difficult to generalize an answer to without measuring it. Intuition is unlikely to yield a better result than actually trying it.</div><br/></div></div></div></div><div id="36901593" class="c"><input type="checkbox" id="c-36901593" checked=""/><div class="controls bullet"><span class="by">autokad</span><span>|</span><a href="#36901112">prev</a><span>|</span><a href="#36901368">next</a><span>|</span><label class="collapse" for="c-36901593">[-]</label><label class="expand" for="c-36901593">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve tried text generation on gpt3 and it was very very bad. has anyone done so and got good results? care to share the code?</div><br/></div></div><div id="36901368" class="c"><input type="checkbox" id="c-36901368" checked=""/><div class="controls bullet"><span class="by">marcopicentini</span><span>|</span><a href="#36901593">prev</a><span>|</span><a href="#36901010">next</a><span>|</span><label class="collapse" for="c-36901368">[-]</label><label class="expand" for="c-36901368">[4 more]</label></div><br/><div class="children"><div class="content">What if we fine tune a model like LLaMA on all published research papers? Would be able to product new knowledge?</div><br/><div id="36904292" class="c"><input type="checkbox" id="c-36904292" checked=""/><div class="controls bullet"><span class="by">zbyforgotp</span><span>|</span><a href="#36901368">parent</a><span>|</span><a href="#36903214">next</a><span>|</span><label class="collapse" for="c-36904292">[-]</label><label class="expand" for="c-36904292">[1 more]</label></div><br/><div class="children"><div class="content">Finetuning is not useful for teaching new facts, the current solution for that is using RAG: <a href="https:&#x2F;&#x2F;zzbbyy.substack.com&#x2F;p&#x2F;why-you-need-rag-not-finetuning" rel="nofollow noreferrer">https:&#x2F;&#x2F;zzbbyy.substack.com&#x2F;p&#x2F;why-you-need-rag-not-finetunin...</a></div><br/></div></div><div id="36903214" class="c"><input type="checkbox" id="c-36903214" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#36901368">parent</a><span>|</span><a href="#36904292">prev</a><span>|</span><a href="#36901442">next</a><span>|</span><label class="collapse" for="c-36903214">[-]</label><label class="expand" for="c-36903214">[1 more]</label></div><br/><div class="children"><div class="content">The value of research isn’t just in the ideas. It’s in the grounding of ideas in fact. It might be able to suggest interesting experiments, but those experiments still need to be carried out.</div><br/></div></div><div id="36901442" class="c"><input type="checkbox" id="c-36901442" checked=""/><div class="controls bullet"><span class="by">capableweb</span><span>|</span><a href="#36901368">parent</a><span>|</span><a href="#36903214">prev</a><span>|</span><a href="#36901010">next</a><span>|</span><label class="collapse" for="c-36901442">[-]</label><label class="expand" for="c-36901442">[1 more]</label></div><br/><div class="children"><div class="content">Depends on what you mean with &quot;new knowledge&quot;. A lot of inventions are &quot;just&quot; novel combinations of things we already knew.</div><br/></div></div></div></div><div id="36901010" class="c"><input type="checkbox" id="c-36901010" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#36901368">prev</a><span>|</span><a href="#36901031">next</a><span>|</span><label class="collapse" for="c-36901010">[-]</label><label class="expand" for="c-36901010">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Fine tuning is better for complex tasks where the model’s generated output must be accurate and trusted.<p>uhhh.  I understand what was intended there but while fine tuning may reduce the rate of hallucinations and make hallucinations more plausible, it&#x27;s not magic accurate and trust-worthy dust.<p>Unfortunately many people think this stuff is magic and care should be taken to not encourage people to confuse improvements with resolving the issue.<p>One way of characterizing the LLM accuracy problem is that it often <i>looks</i> very accurate and convincing even when it is emitting nonsense.  If you cast the problem in those terms-- as a problem of looking more trustworthy than it actually is-- fine tuning actually exacerbates the problem.</div><br/></div></div><div id="36901031" class="c"><input type="checkbox" id="c-36901031" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#36901010">prev</a><span>|</span><a href="#36901421">next</a><span>|</span><label class="collapse" for="c-36901031">[-]</label><label class="expand" for="c-36901031">[1 more]</label></div><br/><div class="children"><div class="content">Are there any good tutorials on fine-tuning the quantitized versions of the LLama models anywhere? I have a few NLP tasks I’d like to test out, with plenty of training data, but everything I’ve seen doesn’t seem generalizable enough or lacks necessary details.</div><br/></div></div><div id="36901421" class="c"><input type="checkbox" id="c-36901421" checked=""/><div class="controls bullet"><span class="by">ramesh31</span><span>|</span><a href="#36901031">prev</a><span>|</span><label class="collapse" for="c-36901421">[-]</label><label class="expand" for="c-36901421">[4 more]</label></div><br/><div class="children"><div class="content">Can anyone provide a step-by-step ELI5 guide to fine tuning Llama? I still don&#x27;t quite understand.</div><br/><div id="36902317" class="c"><input type="checkbox" id="c-36902317" checked=""/><div class="controls bullet"><span class="by">popohack</span><span>|</span><a href="#36901421">parent</a><span>|</span><a href="#36902342">next</a><span>|</span><label class="collapse" for="c-36902317">[-]</label><label class="expand" for="c-36902317">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;trl&#x2F;sft_trainer" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;trl&#x2F;sft_trainer</a> and <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;trl&#x2F;using_llama_models" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;trl&#x2F;using_llama_models</a>, supervised fine-tuning and another llama example with rlhf</div><br/></div></div><div id="36902342" class="c"><input type="checkbox" id="c-36902342" checked=""/><div class="controls bullet"><span class="by">joshka</span><span>|</span><a href="#36901421">parent</a><span>|</span><a href="#36902317">prev</a><span>|</span><a href="#36901510">next</a><span>|</span><label class="collapse" for="c-36902342">[-]</label><label class="expand" for="c-36902342">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;replicate.com&#x2F;blog&#x2F;fine-tune-llama-to-speak-like-homer-simpson">https:&#x2F;&#x2F;replicate.com&#x2F;blog&#x2F;fine-tune-llama-to-speak-like-hom...</a></div><br/></div></div><div id="36901510" class="c"><input type="checkbox" id="c-36901510" checked=""/><div class="controls bullet"><span class="by">treprinum</span><span>|</span><a href="#36901421">parent</a><span>|</span><a href="#36902342">prev</a><span>|</span><label class="collapse" for="c-36901510">[-]</label><label class="expand" for="c-36901510">[1 more]</label></div><br/><div class="children"><div class="content">Look up LoRA.</div><br/></div></div></div></div></div></div></div></div></div></body></html>