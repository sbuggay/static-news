<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1718182855991" as="style"/><link rel="stylesheet" href="styles.css?v=1718182855991"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arcprize.org/blog/launch">ARC Prize – a $1M+ competition towards open AGI progress</a> <span class="domain">(<a href="https://arcprize.org">arcprize.org</a>)</span></div><div class="subtext"><span>mikeknoop</span> | <span>168 comments</span></div><br/><div><div id="40652704" class="c"><input type="checkbox" id="c-40652704" checked=""/><div class="controls bullet"><span class="by">neoneye2</span><span>|</span><a href="#40652463">next</a><span>|</span><label class="collapse" for="c-40652704">[-]</label><label class="expand" for="c-40652704">[11 more]</label></div><br/><div class="children"><div class="content">I&#x27;m Simon Strandgaard and I participated in ARCathon 2022 (solved 3 tasks) and ARCathon 2023 (solved 8 tasks).<p>I&#x27;m collecting data for how humans are solving ARC tasks, and so far collected 4100 interaction histories (<a href="https:&#x2F;&#x2F;github.com&#x2F;neoneye&#x2F;ARC-Interactive-History-Dataset">https:&#x2F;&#x2F;github.com&#x2F;neoneye&#x2F;ARC-Interactive-History-Dataset</a>). Besides ARC-AGI, there are other ARC like datasets, these can be tried in my editor (<a href="https:&#x2F;&#x2F;neoneye.github.io&#x2F;arc&#x2F;" rel="nofollow">https:&#x2F;&#x2F;neoneye.github.io&#x2F;arc&#x2F;</a>).<p>I have made some videos about ARC:<p>Replaying the interaction histories, and you can see people have different approaches. It&#x27;s 100ms per interaction. IRL people doesn&#x27;t solve task that fast.
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=vQt7UZsYooQ" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=vQt7UZsYooQ</a><p>When I&#x27;m manually solving an ARC task, it looks like this, and you can see I&#x27;m rather slow.
<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=PRdFLRpC6dk" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=PRdFLRpC6dk</a><p>What is weird. The way that I implement a solver for a specific ARC task is much different than the way that I would manually solve the puzzle. Having to deal with all kinds of edge cases.<p>Huge thanks to the team behind the ARC Prize. Well done.</div><br/><div id="40654564" class="c"><input type="checkbox" id="c-40654564" checked=""/><div class="controls bullet"><span class="by">parentheses</span><span>|</span><a href="#40652704">parent</a><span>|</span><a href="#40654552">next</a><span>|</span><label class="collapse" for="c-40654564">[-]</label><label class="expand" for="c-40654564">[2 more]</label></div><br/><div class="children"><div class="content">The UX of your solution entry is _way_ better than the ARC site itself.</div><br/><div id="40655688" class="c"><input type="checkbox" id="c-40655688" checked=""/><div class="controls bullet"><span class="by">neoneye2</span><span>|</span><a href="#40652704">root</a><span>|</span><a href="#40654564">parent</a><span>|</span><a href="#40654552">next</a><span>|</span><label class="collapse" for="c-40655688">[-]</label><label class="expand" for="c-40655688">[1 more]</label></div><br/><div class="children"><div class="content">That warms my heart. Thank you.<p>The short story. I needed something that could render thumbnails of tasks, so I could visual debug what was going on in my solver. However I have never gotten around to make the visual inspection tool. After having the thumbnail renderer, mid january 2024, then it eventually turned into what it is now.</div><br/></div></div></div></div></div></div><div id="40652463" class="c"><input type="checkbox" id="c-40652463" checked=""/><div class="controls bullet"><span class="by">salamo</span><span>|</span><a href="#40652704">prev</a><span>|</span><a href="#40655527">next</a><span>|</span><label class="collapse" for="c-40652463">[-]</label><label class="expand" for="c-40652463">[53 more]</label></div><br/><div class="children"><div class="content">This is super cool. I share Francois&#x27; intuition that the presently data-hungry learning paradigm is not only not generalizable but unsustainable: humans do not need 10,000 examples to tell the difference between cats and dogs, and the main reason computers can today is because we have millions of examples. As a result, it may be hard to transfer knowledge to more esoteric domains where data is expensive, rare, and hard to synthesize.<p>If I can make one criticism&#x2F;observation of the tests, it seems that most of them reason about perfect information in a game-theoretic sense. However, many if not most of the more challenging problems we encounter involve hidden information. Poker and negotiations are examples of problem solving in imperfect information scenarios. Smoothly navigating social situations also requires a related problem of working with hidden information.<p>One of the really interesting things we humans are able to do is to take the rules of a game and generate strategies. While we do have some algorithms which can &quot;teach themselves&quot; e.g. to play go or chess, those same self-play algorithms don&#x27;t work on hidden information games. One of the really interesting capabilities of any generally-intelligent system would be synthesizing a general problem solver for those kinds of situations as well.</div><br/><div id="40652978" class="c"><input type="checkbox" id="c-40652978" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#40652463">parent</a><span>|</span><a href="#40654017">next</a><span>|</span><label class="collapse" for="c-40652978">[-]</label><label class="expand" for="c-40652978">[23 more]</label></div><br/><div class="children"><div class="content">&gt; humans do not need 10,000 examples to tell the difference between cats and dogs,<p>I swear, not enough people have kids.<p>Now, is it 10k examples? No, but I think it was on the order of hundreds, if not thousands.<p>One thing kids do is they&#x27;ll ask for confirmation of their guess. You&#x27;ll be reading a book you&#x27;ve read 50 times before and the kid will stop you, point at a dog in the book, and ask &quot;dog?&quot;<p>And there is a development phase where this happens <i>a lot</i>.<p>Also kids can get mad if they are told an object doesn&#x27;t match up to the expected label, e.g. my son gets really mad if someone calls something by the wrong color.<p>Another thing toddlers like to do is play silly labeling games, which is different than calling something the wrong name on accident, instead this is done on purpose for fun. e.g. you point to a fish and say &quot;isn&#x27;t that a lovely llama!&quot; at which point the kid will fall down giggling at how silly you are being.<p>The human brain develops <i>really</i> slowly[1], and a sense of linear time encoding doesn&#x27;t really exist for quite awhile. (Even at 3, everything is either yesterday, today, or tomorrow) so who the hell knows how things are being processed, but what we do know is that kids gather information through a bunch of senses, that are operating at an absurd data collection rate 12-14 hours a day, with another 10-12 hours of downtime to process the information.<p>[1] Watch a baby discover they have a right foot. Then a few days later figure out they also have a left foot. Watch kids who are learning to stand develop a sense of &quot;up above me&quot; after they bonk their heads a few time on a table bottom. Kids only learn &quot;fast&quot; in the sense that they have nothing else to do for years on end.</div><br/><div id="40653461" class="c"><input type="checkbox" id="c-40653461" checked=""/><div class="controls bullet"><span class="by">PheonixPharts</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40655266">next</a><span>|</span><label class="collapse" for="c-40653461">[-]</label><label class="expand" for="c-40653461">[10 more]</label></div><br/><div class="children"><div class="content">&gt; Now, is it 10k examples? No, but I think it was on the order of hundreds, if not thousands.<p>I have kids so I&#x27;m presuming I&#x27;m allowed to have an opinion here.<p>This is ignoring the fact that babies are not just learning labels, they&#x27;re learning the whole of language, motion planning, sensory processing, etc.<p>Once they have the basics down concept acquisition time shrinks rapidly and kids can easily learn their new favorite animal in as little as a single example.<p>Compare this to LLMs which can one-shot certain tasks, but only if they have essentially already memorized enough information to know about that task. It gives the illusion that these models are learning like children do, when in reality they are not even entirely capable of learning novel concepts.<p>Beyond just learning a new animal, humans are able to learn entirely new systems of reasoning in surprisingly few examples (though it does take quite a bit of time to process them). How many homework questions did your entire calc 1 class have? I&#x27;m guessing less than 100 and (hopefully) you successfully learned differential calculus.</div><br/><div id="40655824" class="c"><input type="checkbox" id="c-40655824" checked=""/><div class="controls bullet"><span class="by">dimask</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653461">parent</a><span>|</span><a href="#40655228">next</a><span>|</span><label class="collapse" for="c-40655824">[-]</label><label class="expand" for="c-40655824">[2 more]</label></div><br/><div class="children"><div class="content">&gt; How many homework questions did your entire calc 1 class have? I&#x27;m guessing less than 100 and (hopefully) you successfully learned differential calculus.<p>Not just that: people learn mathematics mainly by _thinking over and solving problems_, not by memorising solutions to problems. During my mathematics education I had to practice solving a lot of problems dissimilar what I had seen before. Even in the theory part, a lot of it was actually about filling in details in proofs and arguments, and reformulating challenging steps (by words or drawings). My notes on top of a mathematical textbook are much more than the text itself.<p>People think that knowledge lies in the texts themselves; it does not, it lies in what these texts relate to and the processes that they are part of, a lot of which are out in the real world and in our interactions. The original article is spot on that there is no AGI pathway in the current research direction. But there are huge incentives for ignoring this.</div><br/><div id="40656014" class="c"><input type="checkbox" id="c-40656014" checked=""/><div class="controls bullet"><span class="by">whyever</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40655824">parent</a><span>|</span><a href="#40655228">next</a><span>|</span><label class="collapse" for="c-40656014">[-]</label><label class="expand" for="c-40656014">[1 more]</label></div><br/><div class="children"><div class="content">I think there is a component of memorizing solutions. For example, for mathematical proofs there is a set of standard &quot;tricks&quot; that you should have memorized.</div><br/></div></div></div></div><div id="40655228" class="c"><input type="checkbox" id="c-40655228" checked=""/><div class="controls bullet"><span class="by">educasean</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653461">parent</a><span>|</span><a href="#40655824">prev</a><span>|</span><a href="#40654611">next</a><span>|</span><label class="collapse" for="c-40655228">[-]</label><label class="expand" for="c-40655228">[2 more]</label></div><br/><div class="children"><div class="content">&gt; kids can easily learn their new favorite animal in as little as a single example<p>Until they encounter a similar animal and get confused, at which point you understand the implicit heuristic they were relying on. (Eg. They confused a dairy cow as a zebra, which means their heuristic was a black-and-white quadrupedal)<p>Doesn&#x27;t this seem remarkably close to how LLMs behave with one-shot or few-shot learning? I think there are a lot more similarities here than you give it credit for.<p>Also, I grew up in South Korea where early math education is highly prioritized (for better or for worse). I remember having to solve 2 dozen arithmetic problems every week after school with a private tutor. Yes, it was torture and I was miserable, but it did expose me to thousands more arithmetic questions than my American peers. All that misery paid off when I moved to the U.S. at the age of 12 and realized that my math level was 3-4 years above my peers. So yes, I think human intelligence accuracy also does improve with more training data.</div><br/><div id="40655345" class="c"><input type="checkbox" id="c-40655345" checked=""/><div class="controls bullet"><span class="by">interloxia</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40655228">parent</a><span>|</span><a href="#40654611">next</a><span>|</span><label class="collapse" for="c-40655345">[-]</label><label class="expand" for="c-40655345">[1 more]</label></div><br/><div class="children"><div class="content">Not many zebras where I live but lots of little dogs. Small dogs were clearly cats for a long time no matter what I said. The training can take a while.</div><br/></div></div></div></div><div id="40654611" class="c"><input type="checkbox" id="c-40654611" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653461">parent</a><span>|</span><a href="#40655228">prev</a><span>|</span><a href="#40654090">next</a><span>|</span><label class="collapse" for="c-40654611">[-]</label><label class="expand" for="c-40654611">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is ignoring the fact that babies are not just learning labels, they&#x27;re learning the whole of language, motion planning, sensory processing, etc.<p>Sure, but they learn a <i>lot</i> of labels.<p>&gt; How many homework questions did your entire calc 1 class have? I&#x27;m guessing less than 100<p>At least 20 to 30 a week, for about 10 weeks of class. Some weeks were more, and I remember plenty of days where we had 20 problems assigned a day.<p>Indeed, I am a huge fan of &quot;the best way to learn math is to do hundreds upon hundreds of problems&quot;, because IMHO some concepts just require massive amounts of repetition.</div><br/></div></div><div id="40654090" class="c"><input type="checkbox" id="c-40654090" checked=""/><div class="controls bullet"><span class="by">aamar</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653461">parent</a><span>|</span><a href="#40654611">prev</a><span>|</span><a href="#40653904">next</a><span>|</span><label class="collapse" for="c-40654090">[-]</label><label class="expand" for="c-40654090">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  How many homework questions did your entire calc 1 class have? I&#x27;m guessing less than 100…<p>I’m quite surprised at this guess and intrigued by your school’s methodology. I would have estimated &gt;30 problems average across 20 weeks for myself.<p>My kids are still in pre-algebra, but they get way more drilling still, well over 1000 problems per semester once Zern, IReady, etc. are factored in. I believe it’s too much, but it does seem like the typical approach here in California.</div><br/></div></div><div id="40653904" class="c"><input type="checkbox" id="c-40653904" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653461">parent</a><span>|</span><a href="#40654090">prev</a><span>|</span><a href="#40653731">next</a><span>|</span><label class="collapse" for="c-40653904">[-]</label><label class="expand" for="c-40653904">[2 more]</label></div><br/><div class="children"><div class="content"><i>illusion that these models are learning like children do, when in reality they are not even entirely capable of learning novel concepts</i><p>Now imagine how much would your kid learn if the only input he ever received was a sequence of words?</div><br/><div id="40655950" class="c"><input type="checkbox" id="c-40655950" checked=""/><div class="controls bullet"><span class="by">_flux</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653904">parent</a><span>|</span><a href="#40653731">next</a><span>|</span><label class="collapse" for="c-40655950">[-]</label><label class="expand" for="c-40655950">[1 more]</label></div><br/><div class="children"><div class="content">Are you saying it&#x27;s not fair for LLMs, because of the way they are taught is different?<p>The difference is that we don&#x27;t know better methods for them, but we do know of better methods for people.</div><br/></div></div></div></div><div id="40653731" class="c"><input type="checkbox" id="c-40653731" checked=""/><div class="controls bullet"><span class="by">_carbyau_</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653461">parent</a><span>|</span><a href="#40653904">prev</a><span>|</span><a href="#40655266">next</a><span>|</span><label class="collapse" for="c-40653731">[-]</label><label class="expand" for="c-40653731">[1 more]</label></div><br/><div class="children"><div class="content">Two other points - I&#x27;ve also forgotten a bunch, but also know I could &quot;relearn&quot; it  faster than the first time around.<p>To continue your example, I know I&#x27;ve learned calculus and was lauded at the time. Now I could only give you the vagaries, nothing practical. However I know if I was pressed, I could learn it again in short order.</div><br/></div></div></div></div><div id="40655266" class="c"><input type="checkbox" id="c-40655266" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40653461">prev</a><span>|</span><a href="#40655367">next</a><span>|</span><label class="collapse" for="c-40655266">[-]</label><label class="expand" for="c-40655266">[1 more]</label></div><br/><div class="children"><div class="content">My kid is about 3 and has been slow on language development. He can barely speak a few short sentences now. Learning names of things and concepts made a big difference for him and that&#x27;s a fascinating watch and realization.<p>This reminds of the story of Adam learning names, or how some languages can express a lot more in fewer words. And it makes sense that LLMs look intelligent to us.<p>My kid loves repeating the names of things he learned recently. For past few weeks, after learning &#x27;spider&#x27; and &#x27;snake&#x27; and &#x27;dangerous&#x27; he keeps finding spiders around, no snakes so makes up snakes from curly drawn lines and tells us they are dangerous.<p>I think we learn fast because of stereo (3d) vision. I have no idea how these models learn and don&#x27;t know if 3d vision will make multi model LLMs better and require exponentially less examples.</div><br/></div></div><div id="40655367" class="c"><input type="checkbox" id="c-40655367" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40655266">prev</a><span>|</span><a href="#40653093">next</a><span>|</span><label class="collapse" for="c-40655367">[-]</label><label class="expand" for="c-40655367">[1 more]</label></div><br/><div class="children"><div class="content">Babies, unlike machine learning models, aren&#x27;t placed in limbo when they aren&#x27;t running back propagation.<p>Babies need few examples for complex tasks because they get constant infinitely complex examples on tasks which are used for transfer learning.<p>Current models take a nuclear reactors worth of power to run back prop on top of a small countries GDP worth of hardware.<p>They are _not_ going to generalize to AGI because we can&#x27;t afford to run them.</div><br/></div></div><div id="40653093" class="c"><input type="checkbox" id="c-40653093" checked=""/><div class="controls bullet"><span class="by">9cb14c1ec0</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40655367">prev</a><span>|</span><a href="#40653401">next</a><span>|</span><label class="collapse" for="c-40653093">[-]</label><label class="expand" for="c-40653093">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  not enough people have kids.<p>Second that.  I think I&#x27;ve learned as much as my children have.<p>&gt; Watch a baby discover they have a right foot. Then a few days later figure out they also have a left foot.<p>Watching a baby&#x27;s awareness grow from pretty much nothing to a fully developed ability to understand the world around is one of the most fascinating parts of being a parent.</div><br/></div></div><div id="40653401" class="c"><input type="checkbox" id="c-40653401" checked=""/><div class="controls bullet"><span class="by">Nition</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40653093">prev</a><span>|</span><a href="#40653174">next</a><span>|</span><label class="collapse" for="c-40653401">[-]</label><label class="expand" for="c-40653401">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the kid will stop you, point at a dog in the book, and ask &quot;dog?&quot;<p>Of course for a human this can either mean &quot;I have an idea about what a dog is, but I&#x27;m not sure whether this is one&quot; or it can mean &quot;Hey this is a... one of those, what&#x27;s the word for it again?&quot;</div><br/></div></div><div id="40653174" class="c"><input type="checkbox" id="c-40653174" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40653401">prev</a><span>|</span><a href="#40655414">next</a><span>|</span><label class="collapse" for="c-40653174">[-]</label><label class="expand" for="c-40653174">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I swear, not enough people have kids.<p>My friends toddler, who grew up with a cat in the house, would initially call all dogs &quot;cat&quot;. :-D</div><br/></div></div><div id="40655414" class="c"><input type="checkbox" id="c-40655414" checked=""/><div class="controls bullet"><span class="by">ein0p</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40653174">prev</a><span>|</span><a href="#40655111">next</a><span>|</span><label class="collapse" for="c-40655414">[-]</label><label class="expand" for="c-40655414">[1 more]</label></div><br/><div class="children"><div class="content">Not to mention that babies receive petabytes of visual input to go with other stimuli. It’s up for debate how sample efficient humans actually are in the first few years of their lives.</div><br/></div></div><div id="40655111" class="c"><input type="checkbox" id="c-40655111" checked=""/><div class="controls bullet"><span class="by">bamboozled</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40655414">prev</a><span>|</span><a href="#40653649">next</a><span>|</span><label class="collapse" for="c-40655111">[-]</label><label class="expand" for="c-40655111">[1 more]</label></div><br/><div class="children"><div class="content">I think your comment over intellectualises the way children experience the world.<p>My child experiences the world in a really pure way. They don’t care much about labels or colours or any other human inventions like that. He picks up his carrot, he doesn’t care about the name or the color . He just enjoys it through purely experiencing eating it. He can also find incredible flow state like joy from playing with river stones or looking at the moon.<p>I personally feel bad I have to each them to label things and but things in boxes. I think your child is frustrated at times because it’s a punish of a game. The departure from “the oceanic feeling.<p>Your comment would make sense to me if the end game of our brains and human experience is labelling things. It’s not. It’s useful but it’s not what living is about.</div><br/></div></div><div id="40654005" class="c"><input type="checkbox" id="c-40654005" checked=""/><div class="controls bullet"><span class="by">resource0x</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40653649">prev</a><span>|</span><a href="#40654819">next</a><span>|</span><label class="collapse" for="c-40654005">[-]</label><label class="expand" for="c-40654005">[2 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t seen 1000 cats in my entire life. I&#x27;m sure I learned how to tell a dog from a cat after being exposed to just a single instance of each.</div><br/><div id="40654202" class="c"><input type="checkbox" id="c-40654202" checked=""/><div class="controls bullet"><span class="by">lostmsu</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40654005">parent</a><span>|</span><a href="#40654819">next</a><span>|</span><label class="collapse" for="c-40654202">[-]</label><label class="expand" for="c-40654202">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure you saw over 1B images of cats though, assuming 24 images per second from vision.</div><br/></div></div></div></div><div id="40654819" class="c"><input type="checkbox" id="c-40654819" checked=""/><div class="controls bullet"><span class="by">AuryGlenz</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652978">parent</a><span>|</span><a href="#40654005">prev</a><span>|</span><a href="#40654017">next</a><span>|</span><label class="collapse" for="c-40654819">[-]</label><label class="expand" for="c-40654819">[1 more]</label></div><br/><div class="children"><div class="content">That’s all true, yet my 2.5 year old sometimes one-shots specific information. I told my daughter that woodpeckers eat bugs out of trees after doing what you said and asking “what’s that noise?” for the fifth time in a few minutes when we heard some this spring. She brought it up again at least a week later, randomly.  Developing brains are amazing.<p>She also saw an eagle this spring out the car window and said “an eagle!  …no, it’s a bird,” so I guess she’s still working on those image classifications ;)</div><br/></div></div></div></div><div id="40654017" class="c"><input type="checkbox" id="c-40654017" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#40652463">parent</a><span>|</span><a href="#40652978">prev</a><span>|</span><a href="#40652922">next</a><span>|</span><label class="collapse" for="c-40654017">[-]</label><label class="expand" for="c-40654017">[5 more]</label></div><br/><div class="children"><div class="content">&gt; humans do not need 10,000 examples to tell the difference between cats and dogs<p>The optimization process that trained the human brain is called evolution, and it took a lot more than 10,000 examples to produce a system that can differentiate cats vs dogs.<p>Put differently, an LLM is pre-trained with very light priors, starting almost from scratch, whereas a human brain is pre-loaded with extremely strong priors.</div><br/><div id="40655371" class="c"><input type="checkbox" id="c-40655371" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40654017">parent</a><span>|</span><a href="#40654476">next</a><span>|</span><label class="collapse" for="c-40655371">[-]</label><label class="expand" for="c-40655371">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The optimization process that trained the human brain is called evolution<p>A human brain that doesn&#x27;t get visual stimulus at the critical age between 0 and 3 years old will never be able to tell the difference between a cat and a dog because it will be forevermore blind.</div><br/></div></div><div id="40654476" class="c"><input type="checkbox" id="c-40654476" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40654017">parent</a><span>|</span><a href="#40655371">prev</a><span>|</span><a href="#40655023">next</a><span>|</span><label class="collapse" for="c-40654476">[-]</label><label class="expand" for="c-40654476">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The optimization process that trained the human brain is called evolution, and it took a lot more than 10,000 examples to produce a system that can differentiate cats vs dogs.<p>Asserted without evidence. We have essentially no idea at what point living systems were capable of differentiating cats from dogs (we don&#x27;t even know for sure which living systems can do this).</div><br/><div id="40654601" class="c"><input type="checkbox" id="c-40654601" checked=""/><div class="controls bullet"><span class="by">choeger</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40654476">parent</a><span>|</span><a href="#40655023">next</a><span>|</span><label class="collapse" for="c-40654601">[-]</label><label class="expand" for="c-40654601">[1 more]</label></div><br/><div class="children"><div class="content">We know for a fact that cats, dogs, and humans do.</div><br/></div></div></div></div></div></div><div id="40652922" class="c"><input type="checkbox" id="c-40652922" checked=""/><div class="controls bullet"><span class="by">pants2</span><span>|</span><a href="#40652463">parent</a><span>|</span><a href="#40654017">prev</a><span>|</span><a href="#40652656">next</a><span>|</span><label class="collapse" for="c-40652922">[-]</label><label class="expand" for="c-40652922">[3 more]</label></div><br/><div class="children"><div class="content">Humans, I would bet, could distinguish between two animals they&#x27;ve never seen based only on a loose or tangential description. I.e. &quot;A dog hunts animals by tracking and chasing them long enough to exhaust their energy, but a cat is opportunistic and strikes using stealth and agility.&quot;<p>A human that has never seen a dog or a cat could probably determine which is which based on looking at the two animals and their adaptations. This would be an interesting test for AIs, but I&#x27;m not quite sure how one would formulate a eval for this.</div><br/><div id="40653134" class="c"><input type="checkbox" id="c-40653134" checked=""/><div class="controls bullet"><span class="by">ryankrage77</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652922">parent</a><span>|</span><a href="#40653504">next</a><span>|</span><label class="collapse" for="c-40653134">[-]</label><label class="expand" for="c-40653134">[1 more]</label></div><br/><div class="children"><div class="content">A possible way to this idea would be to draw two aliens with different hunting strategies and do a poll of which is which. I&#x27;d try it but my drawing skills are terrible and I&#x27;m averse to using generated images.</div><br/></div></div><div id="40653504" class="c"><input type="checkbox" id="c-40653504" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652922">parent</a><span>|</span><a href="#40653134">prev</a><span>|</span><a href="#40652656">next</a><span>|</span><label class="collapse" for="c-40653504">[-]</label><label class="expand" for="c-40653504">[1 more]</label></div><br/><div class="children"><div class="content">Only after being exposed to (at least pictures and descriptions of) dozens if not hundreds of different types of animal and their different attributes. Literal decades of training time and carefully curated curriculum learning are required for a human to perform at what we consider ‘human level’.</div><br/></div></div></div></div><div id="40652656" class="c"><input type="checkbox" id="c-40652656" checked=""/><div class="controls bullet"><span class="by">jules</span><span>|</span><a href="#40652463">parent</a><span>|</span><a href="#40652922">prev</a><span>|</span><a href="#40653218">next</a><span>|</span><label class="collapse" for="c-40652656">[-]</label><label class="expand" for="c-40652656">[2 more]</label></div><br/><div class="children"><div class="content">Do computers need 10,000 examples to distinguish dogs from cats when pretrained on other tasks?</div><br/><div id="40653686" class="c"><input type="checkbox" id="c-40653686" checked=""/><div class="controls bullet"><span class="by">curious_cat_163</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652656">parent</a><span>|</span><a href="#40653218">next</a><span>|</span><label class="collapse" for="c-40653686">[-]</label><label class="expand" for="c-40653686">[1 more]</label></div><br/><div class="children"><div class="content">No.</div><br/></div></div></div></div><div id="40653218" class="c"><input type="checkbox" id="c-40653218" checked=""/><div class="controls bullet"><span class="by">AIorNot</span><span>|</span><a href="#40652463">parent</a><span>|</span><a href="#40652656">prev</a><span>|</span><a href="#40654269">next</a><span>|</span><label class="collapse" for="c-40653218">[-]</label><label class="expand" for="c-40653218">[2 more]</label></div><br/><div class="children"><div class="content">There’s a great episode from Darkwish Patels podcast discussing this today<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;UakqL6Pj9xo?si=iDH6iSNyz1Net8j7" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;UakqL6Pj9xo?si=iDH6iSNyz1Net8j7</a></div><br/><div id="40655659" class="c"><input type="checkbox" id="c-40655659" checked=""/><div class="controls bullet"><span class="by">nphard85</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653218">parent</a><span>|</span><a href="#40654269">next</a><span>|</span><label class="collapse" for="c-40655659">[-]</label><label class="expand" for="c-40655659">[1 more]</label></div><br/><div class="children"><div class="content">Dwarkesh*</div><br/></div></div></div></div><div id="40654269" class="c"><input type="checkbox" id="c-40654269" checked=""/><div class="controls bullet"><span class="by">allanrbo</span><span>|</span><a href="#40652463">parent</a><span>|</span><a href="#40653218">prev</a><span>|</span><a href="#40655062">next</a><span>|</span><label class="collapse" for="c-40654269">[-]</label><label class="expand" for="c-40654269">[1 more]</label></div><br/><div class="children"><div class="content">If a human eye works at say 10 fps, then 8 minutes with a cat is about 10k images :-D</div><br/></div></div><div id="40655062" class="c"><input type="checkbox" id="c-40655062" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#40652463">parent</a><span>|</span><a href="#40654269">prev</a><span>|</span><a href="#40652911">next</a><span>|</span><label class="collapse" for="c-40655062">[-]</label><label class="expand" for="c-40655062">[1 more]</label></div><br/><div class="children"><div class="content">&gt; humans do not need 10,000 examples to tell the difference between cats and dogs<p>Humans learn through a lifetime.<p>Or are we talking about newborn infants?</div><br/></div></div><div id="40652911" class="c"><input type="checkbox" id="c-40652911" checked=""/><div class="controls bullet"><span class="by">goertzen</span><span>|</span><a href="#40652463">parent</a><span>|</span><a href="#40655062">prev</a><span>|</span><a href="#40652699">next</a><span>|</span><label class="collapse" for="c-40652911">[-]</label><label class="expand" for="c-40652911">[1 more]</label></div><br/><div class="children"><div class="content">I don’t know enough of biology or genetics or evolution, but 
surely the millions of years of training that is hardcoded into our genes and expressed in our biology had much larger “training” runs.</div><br/></div></div><div id="40652699" class="c"><input type="checkbox" id="c-40652699" checked=""/><div class="controls bullet"><span class="by">VirusNewbie</span><span>|</span><a href="#40652463">parent</a><span>|</span><a href="#40652911">prev</a><span>|</span><a href="#40655179">next</a><span>|</span><label class="collapse" for="c-40652699">[-]</label><label class="expand" for="c-40652699">[13 more]</label></div><br/><div class="children"><div class="content">&gt;: humans do not need 10,000 examples to tell the difference between cats and dogs<p>well, maybe. We view things in three dimensions at high fidelity:  viewing a single dog or cat actually ends up being thousands of training samples, no?</div><br/><div id="40652753" class="c"><input type="checkbox" id="c-40652753" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652699">parent</a><span>|</span><a href="#40652849">next</a><span>|</span><label class="collapse" for="c-40652753">[-]</label><label class="expand" for="c-40652753">[9 more]</label></div><br/><div class="children"><div class="content">Yes, but we do not call a couch in a leopard print a leopard. Because we understand that the print is secondary to the function.</div><br/><div id="40653467" class="c"><input type="checkbox" id="c-40653467" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652753">parent</a><span>|</span><a href="#40654278">next</a><span>|</span><label class="collapse" for="c-40653467">[-]</label><label class="expand" for="c-40653467">[1 more]</label></div><br/><div class="children"><div class="content">Hah. My toddler gladly calls her former walking aid toy a &quot;lawn mower&quot;. Random toys become pie and cakes she brings to us to eat.</div><br/></div></div><div id="40654278" class="c"><input type="checkbox" id="c-40654278" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652753">parent</a><span>|</span><a href="#40653467">prev</a><span>|</span><a href="#40653047">next</a><span>|</span><label class="collapse" for="c-40654278">[-]</label><label class="expand" for="c-40654278">[1 more]</label></div><br/><div class="children"><div class="content">But we have a lot more sensory input and context to verify all of that.<p>If you kept training LLMs with all that data, it would be interesting to see what the results would be.</div><br/></div></div><div id="40653047" class="c"><input type="checkbox" id="c-40653047" checked=""/><div class="controls bullet"><span class="by">VirusNewbie</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652753">parent</a><span>|</span><a href="#40654278">prev</a><span>|</span><a href="#40652849">next</a><span>|</span><label class="collapse" for="c-40653047">[-]</label><label class="expand" for="c-40653047">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure it&#x27;s as simple as you say.  The first time my very young son saw a horse, he made the ASL sign for &#x27;dog&#x27;.<p>He had only ever seen cats and dogs in his life previous to that.</div><br/><div id="40653816" class="c"><input type="checkbox" id="c-40653816" checked=""/><div class="controls bullet"><span class="by">clipsy</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653047">parent</a><span>|</span><a href="#40652849">next</a><span>|</span><label class="collapse" for="c-40653816">[-]</label><label class="expand" for="c-40653816">[5 more]</label></div><br/><div class="children"><div class="content">Did he require 9,999 more examples of horses before learning the difference?</div><br/><div id="40654137" class="c"><input type="checkbox" id="c-40654137" checked=""/><div class="controls bullet"><span class="by">VirusNewbie</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40653816">parent</a><span>|</span><a href="#40652849">next</a><span>|</span><label class="collapse" for="c-40654137">[-]</label><label class="expand" for="c-40654137">[4 more]</label></div><br/><div class="children"><div class="content">In another comment I replied that 3D high fidelity images do end up being thousands of training samples, so the answer is yes.</div><br/><div id="40655970" class="c"><input type="checkbox" id="c-40655970" checked=""/><div class="controls bullet"><span class="by">_flux</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40654137">parent</a><span>|</span><a href="#40654468">next</a><span>|</span><label class="collapse" for="c-40655970">[-]</label><label class="expand" for="c-40655970">[1 more]</label></div><br/><div class="children"><div class="content">Are you suggesting that if a group of kids were given a book of zoo animals before going to the zoo, they would have difficulties identifing any new animals, because they only have seen one picture of each?</div><br/></div></div><div id="40654468" class="c"><input type="checkbox" id="c-40654468" checked=""/><div class="controls bullet"><span class="by">clipsy</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40654137">parent</a><span>|</span><a href="#40655970">prev</a><span>|</span><a href="#40652849">next</a><span>|</span><label class="collapse" for="c-40654468">[-]</label><label class="expand" for="c-40654468">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m deeply skeptical that training AI on (effectively) thousands of images of one horse will perform very well at training to recognize horses in general.</div><br/><div id="40655798" class="c"><input type="checkbox" id="c-40655798" checked=""/><div class="controls bullet"><span class="by">jpc0</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40654468">parent</a><span>|</span><a href="#40652849">next</a><span>|</span><label class="collapse" for="c-40655798">[-]</label><label class="expand" for="c-40655798">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll double down with you on this.<p>Then train the AI using a binaural video of a  thoroughbred and see if it can distinguish a draft horse and a quarter horse as horse...</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40652849" class="c"><input type="checkbox" id="c-40652849" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652699">parent</a><span>|</span><a href="#40652753">prev</a><span>|</span><a href="#40655179">next</a><span>|</span><label class="collapse" for="c-40652849">[-]</label><label class="expand" for="c-40652849">[3 more]</label></div><br/><div class="children"><div class="content">Eh, still doesn’t hold up. I really don’t think there’s many psychologists working on the posited mechanism of simple NN-like backprop learning. Aka conditioning, I guess. As Chomsky reminds us every time we let him: human children learn to understand and use language — an incredibly complex and nuanced domain, to say the least — with shockingly little data and often zero-to-none intentional instruction. We definitely employ principles and patterns that are far more complex (more “emergent”?) than linear regression.<p>Tho I only ever did undergrad stats, maybe ML isn’t even technically a linear regression at this point. Still, hopefully my gist is clear</div><br/><div id="40653561" class="c"><input type="checkbox" id="c-40653561" checked=""/><div class="controls bullet"><span class="by">ekidd</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652849">parent</a><span>|</span><a href="#40653056">next</a><span>|</span><label class="collapse" for="c-40653561">[-]</label><label class="expand" for="c-40653561">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Chomsky reminds us every time we let him: human children learn to understand and use language — an incredibly complex and nuanced domain, to say the least — with shockingly little data and often zero-to-none intentional instruction.</i><p>Chomsky&#x27;s arguments about &quot;poverty of the stimulus&quot; rely on using non-probabistic grammars. Norvig discusses this here: <a href="https:&#x2F;&#x2F;norvig.com&#x2F;chomsky.html" rel="nofollow">https:&#x2F;&#x2F;norvig.com&#x2F;chomsky.html</a><p>&gt; <i>In 1967, Gold&#x27;s Theorem showed some theoretical limitations of logical deduction on formal mathematical languages. But this result has nothing to do with the task faced by learners of natural language. In any event, by 1969 we knew that probabilistic inference (over probabilistic context-free grammars) is not subject to those limitations (Horning showed that learning of PCFGs is possible).</i><p>If I recall correctly, human toddlers hear about 3-13 million spoken words per year, and the higher ranges are correlated with better performance in school. Which:<p>- Is a lot, in an absolute sense.<p>- But is still <i>much</i> less training data than LLMs require.<p>Adult learners moving between English and romance languages can get a pretty decent grasp of the language (C1 or C2 reading ability) with about 3 million words of reading. Which is obviously exploiting transfer learning and prior knowledge, because it&#x27;s harder in a less related language.<p>So yeah, humans are impressive. But Chomsky doesn&#x27;t really seem to have the theoretical toolkit to deal with probabilistic or statistical learning. And LLMs are closer to statistical learning than to Chomsky&#x27;s formal models.</div><br/></div></div><div id="40653056" class="c"><input type="checkbox" id="c-40653056" checked=""/><div class="controls bullet"><span class="by">VirusNewbie</span><span>|</span><a href="#40652463">root</a><span>|</span><a href="#40652849">parent</a><span>|</span><a href="#40653561">prev</a><span>|</span><a href="#40655179">next</a><span>|</span><label class="collapse" for="c-40653056">[-]</label><label class="expand" for="c-40653056">[1 more]</label></div><br/><div class="children"><div class="content">&gt;human children learn to understand and use language — an incredibly complex and nuanced domain, to say the least — with shockingly little data and often zero-to-none intentional instruction<p>This isn&#x27;t accurate comparison imo, because we&#x27;re mapping language to a world model which was built through a ton of trial and error.<p>Children aren&#x27;t understanding language at six months old, there seems to be a minimum amount of experience with physics and the world before language can click for them.</div><br/></div></div></div></div></div></div></div></div><div id="40655527" class="c"><input type="checkbox" id="c-40655527" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#40652463">prev</a><span>|</span><a href="#40651428">next</a><span>|</span><label class="collapse" for="c-40655527">[-]</label><label class="expand" for="c-40655527">[2 more]</label></div><br/><div class="children"><div class="content">&gt; the only eval which measures AGI.<p>That&#x27;s a stretch. This is a problem at which LLMs are bad. That does not imply it&#x27;s a good measure of artificial general intelligence.<p>After working a few of the problems, I was wondering how many different transformation rules the problem generator has. Not very many, it seems. So the problem breaks down into extracting the set of transformation rules from the data, then applying them to new problems.
The first part of that is hard. It&#x27;s a feature extraction problem. The transformations seem to be applied rigidly, so once you have the transformation rules, and have selected the ones that work for all the input cases, application should be straightforward.<p>This seems to need explicit feature extraction, rather than the combined feature extraction and exploitation LLMs use. Has anyone extracted the rule set from the test cases yet?</div><br/><div id="40655996" class="c"><input type="checkbox" id="c-40655996" checked=""/><div class="controls bullet"><span class="by">slicerdicer1</span><span>|</span><a href="#40655527">parent</a><span>|</span><a href="#40651428">next</a><span>|</span><label class="collapse" for="c-40655996">[-]</label><label class="expand" for="c-40655996">[1 more]</label></div><br/><div class="children"><div class="content">AGI is not when the AI is good at some particular thing, AGI is when we have nothing left at which the AI is bad at (compared to humans).</div><br/></div></div></div></div><div id="40651428" class="c"><input type="checkbox" id="c-40651428" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#40655527">prev</a><span>|</span><a href="#40651993">next</a><span>|</span><label class="collapse" for="c-40651428">[-]</label><label class="expand" for="c-40651428">[27 more]</label></div><br/><div class="children"><div class="content">I really like the idea of ARC. But to me the problems seem like they require a lot of spatial world knowledge, more than they require abstract reasoning. Shapes overlapping each other, containing each other, slicing up and reassembling pieces, denoising regular geometric shapes, you can call them &quot;core knowledge&quot; but to me it seems like they are more like &quot;things that are intuitive to human visual processing&quot;.<p>Would an intelligent but blind human be able to solve these problems?<p>I&#x27;m worried that we will need more than 800 examples to solve these problems, not because the abstract reasoning is so difficult, but because the problems require spatial knowledge that we intelligent humans learn with far more than 800 training examples.</div><br/><div id="40652876" class="c"><input type="checkbox" id="c-40652876" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#40651428">parent</a><span>|</span><a href="#40655727">next</a><span>|</span><label class="collapse" for="c-40652876">[-]</label><label class="expand" for="c-40652876">[1 more]</label></div><br/><div class="children"><div class="content">&gt; to me it seems like they are more like &quot;things that are intuitive to human visual processing&quot;.<p>Yann LeCun argues that humans are not general intelligence and that such a thing doesn&#x27;t really exist. Intelligence can only be measured in specific domains. To the extent that this test represents a domain where humans greatly outperform AI, it&#x27;s a useful test. We need more tests like that, because AIs are acing all of our regular tests despite being obviously less capable than humans in many domains.<p>&gt; the problems require spatial knowledge that we intelligent humans learn with far more than 800 training examples.<p>Pretraining on unlimited amounts of data is fair game. Generalizing from readily available data to the test tasks is exactly what humans are doing.<p>&gt; Would an intelligent but blind human be able to solve these problems?<p>I&#x27;m confident that they would, given a translation of the colors to tactile sensation. Blind humans still understand spatial relationships.</div><br/></div></div><div id="40655727" class="c"><input type="checkbox" id="c-40655727" checked=""/><div class="controls bullet"><span class="by">dimask</span><span>|</span><a href="#40651428">parent</a><span>|</span><a href="#40652876">prev</a><span>|</span><a href="#40652843">next</a><span>|</span><label class="collapse" for="c-40655727">[-]</label><label class="expand" for="c-40655727">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Would an intelligent but blind human be able to solve these problems?<p>Blind people can have spatial reasoning just fine. Visual =&#x2F;= spatial [0]. Now, one would have to adapt the colour-based tasks to something that would be more meaningful for a blind person, I guess.<p>[0] <a href="https:&#x2F;&#x2F;hal.science&#x2F;hal-03373840&#x2F;document" rel="nofollow">https:&#x2F;&#x2F;hal.science&#x2F;hal-03373840&#x2F;document</a></div><br/></div></div><div id="40652843" class="c"><input type="checkbox" id="c-40652843" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#40651428">parent</a><span>|</span><a href="#40655727">prev</a><span>|</span><a href="#40653815">next</a><span>|</span><label class="collapse" for="c-40652843">[-]</label><label class="expand" for="c-40652843">[11 more]</label></div><br/><div class="children"><div class="content">I just did the first 5 of the &quot;public eval set&quot; without having looked at the &quot;public training set&quot;, and found them easy enough. If we&#x27;re defining AGI as at least human level, then the AGI should also be able to do these without seeing any more examples.<p>I don&#x27;t think there&#x27;s any rules about what knowledge&#x2F;experience you build into your solution.</div><br/><div id="40654303" class="c"><input type="checkbox" id="c-40654303" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40652843">parent</a><span>|</span><a href="#40653815">next</a><span>|</span><label class="collapse" for="c-40654303">[-]</label><label class="expand" for="c-40654303">[10 more]</label></div><br/><div class="children"><div class="content">AGI should obviously be able to do them. But AI being able to do those 100 percent wouldn&#x27;t be evidence of AGI however. It is a very narrow domain.</div><br/><div id="40655005" class="c"><input type="checkbox" id="c-40655005" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40654303">parent</a><span>|</span><a href="#40653815">next</a><span>|</span><label class="collapse" for="c-40655005">[-]</label><label class="expand" for="c-40655005">[9 more]</label></div><br/><div class="children"><div class="content">Why not? If the only thing that can solve problem X is AGI (e.g. humans), and something else comes along that solves it, then rationally that should be evidence that the something else is AGI right?<p>Unless you have strong prior beliefs (like &quot;computers can&#x27;t be AGI&quot;) or something else that&#x27;s problem specific (&quot;these problems can be solved by these techniques which don&#x27;t count as AGI&quot;). So I guess that&#x27;s my real question.</div><br/><div id="40655335" class="c"><input type="checkbox" id="c-40655335" checked=""/><div class="controls bullet"><span class="by">lucianbr</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40655005">parent</a><span>|</span><a href="#40655376">next</a><span>|</span><label class="collapse" for="c-40655335">[-]</label><label class="expand" for="c-40655335">[4 more]</label></div><br/><div class="children"><div class="content">That makes no sense at all. Any problem is initially only solvable by humans, until some technology is developed to solve it. Calculating a logarithm was at some point only doable by humans, and then digital computers came along. This would be in your view evidence that digital computers are AGI!? As in, an 8086 with some math code is AGI. We&#x27;ve had it for decades now, only nobody noticed :)</div><br/><div id="40655496" class="c"><input type="checkbox" id="c-40655496" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40655335">parent</a><span>|</span><a href="#40655376">next</a><span>|</span><label class="collapse" for="c-40655496">[-]</label><label class="expand" for="c-40655496">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s just Bayes theorem - there are basically two variables that control how strong the evidence is:<p>* How likely you think AGI is in general.<p>* How solvable you think the problem is, independently of what&#x27;s solving it.<p>In the cases you&#x27;ve brought up that latter probability is very high, which means that they are extremely weak evidence that computers are AGI. So we agree!<p>In this case the latter probability seems to be quite low - attempts to solve it with computers have largely failed so far!</div><br/><div id="40655606" class="c"><input type="checkbox" id="c-40655606" checked=""/><div class="controls bullet"><span class="by">lucianbr</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40655496">parent</a><span>|</span><a href="#40655376">next</a><span>|</span><label class="collapse" for="c-40655606">[-]</label><label class="expand" for="c-40655606">[2 more]</label></div><br/><div class="children"><div class="content">We don&#x27;t agree. You&#x27;re now saying anything is evidence of anything, which just makes the word &quot;evidence&quot; meaningless.<p>In real life, when people say &quot;A is evidence of B&quot; they mean strong evidence, or even overwhelming evidence. You just backpedalled by redefining evidence to mean anything and nothing, so you can salvage an obviously false claim.<p>Nobody in the real world says &quot;rain is evidence of aliens&quot; with the implicit assumption that it&#x27;s just extremely weak evidence. The way English is used by people makes that sentence simply false, as is yours that anything previously not solved is evidence of AGI.</div><br/><div id="40655613" class="c"><input type="checkbox" id="c-40655613" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40655606">parent</a><span>|</span><a href="#40655376">next</a><span>|</span><label class="collapse" for="c-40655613">[-]</label><label class="expand" for="c-40655613">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re talking about a specific problem here - the competition in the OP. Not aliens in the rain.</div><br/></div></div></div></div></div></div></div></div><div id="40655376" class="c"><input type="checkbox" id="c-40655376" checked=""/><div class="controls bullet"><span class="by">educasean</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40655005">parent</a><span>|</span><a href="#40655335">prev</a><span>|</span><a href="#40653815">next</a><span>|</span><label class="collapse" for="c-40655376">[-]</label><label class="expand" for="c-40655376">[4 more]</label></div><br/><div class="children"><div class="content">This flies directly in the face of technologies such as Deep Blue and AlphaGo. They excel in tiny domains previously thought to be the pinnacle of intelligence, and now they dominate humans. Are they AGI in your definition?</div><br/><div id="40655512" class="c"><input type="checkbox" id="c-40655512" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40655376">parent</a><span>|</span><a href="#40653815">next</a><span>|</span><label class="collapse" for="c-40655512">[-]</label><label class="expand" for="c-40655512">[3 more]</label></div><br/><div class="children"><div class="content">See my response to the other commenter. In these cases as well I would conclude it&#x27;s very weak evidence of AGI, so I don&#x27;t think we disagree.<p>Edit: I think maybe the disagreement here is about the nature of evidence. I think there can be evidence that something is AGI even if it isn&#x27;t, in fact, AGI. You seem to believe that if there&#x27;s any evidence that something is AGI, it must be AGI, I think?</div><br/><div id="40655643" class="c"><input type="checkbox" id="c-40655643" checked=""/><div class="controls bullet"><span class="by">educasean</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40655512">parent</a><span>|</span><a href="#40653815">next</a><span>|</span><label class="collapse" for="c-40655643">[-]</label><label class="expand" for="c-40655643">[2 more]</label></div><br/><div class="children"><div class="content">I personally don&#x27;t find this line of rhetoric useful or relevant. Let&#x27;s agree to disagree.</div><br/><div id="40655690" class="c"><input type="checkbox" id="c-40655690" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40655643">parent</a><span>|</span><a href="#40653815">next</a><span>|</span><label class="collapse" for="c-40655690">[-]</label><label class="expand" for="c-40655690">[1 more]</label></div><br/><div class="children"><div class="content">Okay, that&#x27;s fair. But to be clear - this is a theorem of probability theory, not rhetoric.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40653815" class="c"><input type="checkbox" id="c-40653815" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40651428">parent</a><span>|</span><a href="#40652843">prev</a><span>|</span><a href="#40651640">next</a><span>|</span><label class="collapse" for="c-40653815">[-]</label><label class="expand" for="c-40653815">[3 more]</label></div><br/><div class="children"><div class="content">I would argue that spatial reasoning encompasses all reasoning. All the things you mentioned have a direct analogue to abstract models and logic we employ and are engrained deeply into language. For example, shapes containing eachother:<p>There are two countries both which lay claim to the same territory. There is a set X that contains Y and there is a set Z that contains Y. In the case that the common overlap is 3D and one in on top of the other, we can extend this to there is a set X that contains -Y and a set Z that contains Y, and just as you can only see one on top and not both depending on where you stand, we can apply the same property here and say set X and Z cannot both exist, and therefore if set X is on then -Y and if set Z then Y.<p>If you pay attention to the language you use youll start to realize how much of it uses spatial relationships to describe completely abstract things. For example, one can speak of disintigrating hegonomic economies. i.e <i>turning</i> things built <i>on top</i> of eachother <i>into</i> nothing, to <i>where</i> it <i>came</i><p>We are after all, reasoning about things which happen in time and space.<p>And spatial != visual. Even if you were blind youd have to reason spatially, because again any set of facts are facts in space-time. What does it take to understand history? People in space, living at various distances from each other, producing goods from various locations of the earth using physical processes, and physically exchanging them. To understand battles you have to understand how armies are arranged physically, how moving supplies works, weather conditions, how weapons and their physical forms affect what they can physically do, etc.<p>Hell LLMs, the largest advancement we had in artificial intelligence do what exactly? Encode tokens into multi dimensional space.</div><br/><div id="40654627" class="c"><input type="checkbox" id="c-40654627" checked=""/><div class="controls bullet"><span class="by">parentheses</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40653815">parent</a><span>|</span><a href="#40651640">next</a><span>|</span><label class="collapse" for="c-40654627">[-]</label><label class="expand" for="c-40654627">[2 more]</label></div><br/><div class="children"><div class="content">Spatial reasoning is easily isomorphic to many kinds of reasoning - just not all of them. Spatial reasoning in this case also limits the AI to 2 dimensions. I concede that with more dimensions, there will be more isomorphisms.<p>Is there a number of dimensions that captures all reasoning? I don&#x27;t know..</div><br/><div id="40655733" class="c"><input type="checkbox" id="c-40655733" checked=""/><div class="controls bullet"><span class="by">dimask</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40654627">parent</a><span>|</span><a href="#40651640">next</a><span>|</span><label class="collapse" for="c-40655733">[-]</label><label class="expand" for="c-40655733">[1 more]</label></div><br/><div class="children"><div class="content">Claims of isomorphisms are really strong claims to not be backed up with some kind of evidence.</div><br/></div></div></div></div></div></div><div id="40651640" class="c"><input type="checkbox" id="c-40651640" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#40651428">parent</a><span>|</span><a href="#40653815">prev</a><span>|</span><a href="#40652019">next</a><span>|</span><label class="collapse" for="c-40651640">[-]</label><label class="expand" for="c-40651640">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the intent is to learn the entire problem domain from the examples, but the specific rule that is being applied.<p>There may (almost certainly will be) additional knowledge encoded in the solver to cover the spacial concepts etc.   The distinction with the AGI-ARC test is the disparity between human and AI performance, and that it focuses on puzzles that are easier for humans.<p>It would be interesting to see a finetuned LLM just try and express the rule for each puzzle as english.  It could have full knowledge of what ARC-AGI is and how the tests operate, but the proof of the pudding is simply how it does on the test set.</div><br/></div></div><div id="40652019" class="c"><input type="checkbox" id="c-40652019" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#40651428">parent</a><span>|</span><a href="#40651640">prev</a><span>|</span><a href="#40651575">next</a><span>|</span><label class="collapse" for="c-40652019">[-]</label><label class="expand" for="c-40652019">[7 more]</label></div><br/><div class="children"><div class="content">“Would an intelligent but blind human be able to solve these problems?”<p>This is the wrong way to think about it IMO. Spatial relationships are just another type of logical relationship and we should expect AGI to be able to analyze relationships and generate algorithms on the fly to solve problems.<p>Just because humans can be biased in various ways doesn’t mean these biases are inherent to all intelligences.</div><br/><div id="40652371" class="c"><input type="checkbox" id="c-40652371" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40652019">parent</a><span>|</span><a href="#40652170">next</a><span>|</span><label class="collapse" for="c-40652371">[-]</label><label class="expand" for="c-40652371">[4 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Spatial relationships are just another type of logical relationship and we should expect AGI to be able to analyze relationships and generate algorithms on the fly to solve problems.</i><p>Not really. By that reasoning, 5-dimensional spatial reasoning is &quot;just another type of logical relationship&quot; and yet humans mostly can&#x27;t do that at all.<p>It&#x27;s clear that we have incredibly specialized capabilities for dealing with two- and three-dimensional spatiality that don&#x27;t have much of anything to do with general logical intelligence at all.</div><br/><div id="40653925" class="c"><input type="checkbox" id="c-40653925" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40652371">parent</a><span>|</span><a href="#40653142">next</a><span>|</span><label class="collapse" for="c-40653925">[-]</label><label class="expand" for="c-40653925">[2 more]</label></div><br/><div class="children"><div class="content">Literally every single thing you reason about is something happening in space-time.</div><br/><div id="40655364" class="c"><input type="checkbox" id="c-40655364" checked=""/><div class="controls bullet"><span class="by">lucianbr</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40653925">parent</a><span>|</span><a href="#40653142">next</a><span>|</span><label class="collapse" for="c-40655364">[-]</label><label class="expand" for="c-40655364">[1 more]</label></div><br/><div class="children"><div class="content">Where exactly in space-time are complex numbers? Could you point me to 2+i for example?<p>How about some aliens in a SF book. When we reason about them, where are they exactly? Literally on the pages of the book?<p>How about a context-free grammar?</div><br/></div></div></div></div><div id="40653142" class="c"><input type="checkbox" id="c-40653142" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40652371">parent</a><span>|</span><a href="#40653925">prev</a><span>|</span><a href="#40652170">next</a><span>|</span><label class="collapse" for="c-40653142">[-]</label><label class="expand" for="c-40653142">[1 more]</label></div><br/><div class="children"><div class="content">Yes really. Problem solving on the fly doesn&#x27;t mean the algorithm can instantly learn anything. Reality is HEAVILY biased towards two and three spatial dimensions so our brains have hours and hours of training on that dataset. But, with time, humans can learn to be good at all sorts of things.<p>It&#x27;s important that we try to think from the perspective of an algorithm, not a human. And it&#x27;s also important that we don&#x27;t jump to extremes.<p>It seems like you interpreted &quot;solving problems on the fly&quot; to mean &quot;instantly being an expert on a completely different and novel domain&quot;. What it does mean is flexibility, resilience to novel situations, and being able to adapt over time.</div><br/></div></div></div></div><div id="40652170" class="c"><input type="checkbox" id="c-40652170" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40652019">parent</a><span>|</span><a href="#40652371">prev</a><span>|</span><a href="#40651575">next</a><span>|</span><label class="collapse" for="c-40652170">[-]</label><label class="expand" for="c-40652170">[2 more]</label></div><br/><div class="children"><div class="content">Part of the concern might be that visual reasoning problems are overrepresented in ARC in the space of all abstract reasoning problems.<p>It’s similar to how chess problems are technically reasoning problems but they are not representative of general reasoning.</div><br/><div id="40653106" class="c"><input type="checkbox" id="c-40653106" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40652170">parent</a><span>|</span><a href="#40651575">next</a><span>|</span><label class="collapse" for="c-40653106">[-]</label><label class="expand" for="c-40653106">[1 more]</label></div><br/><div class="children"><div class="content">ARC is meant to test fundamental algorithms. It&#x27;s entirely ok to train a model specifically for this task. Part of the beauty of ARC is that it&#x27;s resistant to memorization.</div><br/></div></div></div></div></div></div><div id="40651575" class="c"><input type="checkbox" id="c-40651575" checked=""/><div class="controls bullet"><span class="by">nickpsecurity</span><span>|</span><a href="#40651428">parent</a><span>|</span><a href="#40652019">prev</a><span>|</span><a href="#40651993">next</a><span>|</span><label class="collapse" for="c-40651575">[-]</label><label class="expand" for="c-40651575">[2 more]</label></div><br/><div class="children"><div class="content">To parent: the spatial reasoning and blind person were great counterexamples. It still might be OK despite the blind exceptions if it showed general reasoning.<p>To OP: I like your project goal. I think you should look at prior, reasoning engines that tried to build common sense. Cyc and OpenMind are examples. You also might find use for the list of AGI goals in Section 2 of this paper:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2308.04445" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2308.04445</a><p>When studying intros of brain function, I also noted many regions tie into the hippocampus which might do both sense-neutral storage of concepts and make inner models (or approximations) of external world. The former helps tie concepts together through various senses. The latter helps in planning when we are imagining possibilities to evaluate and iterate on them.<p>Seems like AGI should have these hippocampus-like traits and those in the Cyc paper. One could test if an architecture could do such things in theory or on a small scale. It shouldn’t tie into just one type of sensory input either. At least two with the ability to act on what only exists in one or what is in both.<p>Edit: Children also have an enormous amount of unsupervised training on visual and spatial data. They get reinforcement through play and supervised training by parents. A realistic benchmark might similarly require GB of prettaining.</div><br/><div id="40652879" class="c"><input type="checkbox" id="c-40652879" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#40651428">root</a><span>|</span><a href="#40651575">parent</a><span>|</span><a href="#40651993">next</a><span>|</span><label class="collapse" for="c-40652879">[-]</label><label class="expand" for="c-40652879">[1 more]</label></div><br/><div class="children"><div class="content">CYC was an expert system, which is arguably what LLMs are.<p>A similar vintage GOFAI project that might do better on these, with a suitable visual front end, is SOAR - a general purpose problem solver.</div><br/></div></div></div></div></div></div><div id="40651993" class="c"><input type="checkbox" id="c-40651993" checked=""/><div class="controls bullet"><span class="by">pmayrgundter</span><span>|</span><a href="#40651428">prev</a><span>|</span><a href="#40651841">next</a><span>|</span><label class="collapse" for="c-40651993">[-]</label><label class="expand" for="c-40651993">[19 more]</label></div><br/><div class="children"><div class="content">This claim that these tests are easy for humans seems dubious, and so I went looking a bit.  Melanie Mitchell chimed in on Chollet&#x27;s thread and posted their related test [ConceptARC].<p>In it they question the ease of Chollet&#x27;s tests: &quot;One limitation on ARC’s usefulness for AI research is that it might be too challenging. Many of the tasks in Chollet’s corpus are difficult even for humans, and the corpus as a whole might be sufficiently difficult for machines that it does not reveal real progress on machine acquisition of core knowledge.&quot;<p>ConceptARC is designed to be easier, but then also has to filter ~15% of its own test takers for &quot;[failing] at solving two or more minimal tasks... or they provided empty or nonsensical explanations for their solutions&quot;<p>After this filtering, ConceptARC finds another 10-15% failure rate amongst humans on the main corpus questions, so they&#x27;re seeing maybe 25-30% unable to solve these simpler questions meant to test for &quot;AGI&quot;.<p>ConceptARC&#x27;s main results show CG4 scoring well below the filtered humans, which would agree with a [Mensa] test result that its IQ=85.<p>Chollet and Mitchell could instead stratify their human groups to estimate IQ then compare with the Mensa measures and see if e.g. Claude3@IQ=100 compares with their ARC scores for their average human<p>[ConceptArc]<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.07141" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.07141</a>
[Mensa]<a href="https:&#x2F;&#x2F;www.maximumtruth.org&#x2F;p&#x2F;ais-ranked-by-iq-ai-passes-100-iq" rel="nofollow">https:&#x2F;&#x2F;www.maximumtruth.org&#x2F;p&#x2F;ais-ranked-by-iq-ai-passes-10...</a></div><br/><div id="40652600" class="c"><input type="checkbox" id="c-40652600" checked=""/><div class="controls bullet"><span class="by">mikeknoop</span><span>|</span><a href="#40651993">parent</a><span>|</span><a href="#40652869">next</a><span>|</span><label class="collapse" for="c-40652600">[-]</label><label class="expand" for="c-40652600">[1 more]</label></div><br/><div class="children"><div class="content">Here is some published research on the human difficulty of ARC-AGI: <a href="https:&#x2F;&#x2F;cims.nyu.edu&#x2F;~brenden&#x2F;papers&#x2F;JohnsonEtAl2021CogSci.pdf" rel="nofollow">https:&#x2F;&#x2F;cims.nyu.edu&#x2F;~brenden&#x2F;papers&#x2F;JohnsonEtAl2021CogSci.p...</a><p>&gt; We found that humans were able to infer the underlying program
and generate the correct test output for a novel test input example, with an average of 84% of tasks solved per participant</div><br/></div></div><div id="40652869" class="c"><input type="checkbox" id="c-40652869" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#40651993">parent</a><span>|</span><a href="#40652600">prev</a><span>|</span><a href="#40652618">next</a><span>|</span><label class="collapse" for="c-40652869">[-]</label><label class="expand" for="c-40652869">[11 more]</label></div><br/><div class="children"><div class="content">I just tried the first puzzle and I can&#x27;t get it right.  I think my solution makes logical sense and I explain why the patterns are consistent with the input, but it says its wrong.  I&#x27;m either a lot dumber than I thought or they need to do a better job of vetting their tests.</div><br/><div id="40652941" class="c"><input type="checkbox" id="c-40652941" checked=""/><div class="controls bullet"><span class="by">mikeknoop</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40652869">parent</a><span>|</span><a href="#40652949">next</a><span>|</span><label class="collapse" for="c-40652941">[-]</label><label class="expand" for="c-40652941">[1 more]</label></div><br/><div class="children"><div class="content">(You can direct link to a task like this: <a href="https:&#x2F;&#x2F;arcprize.org&#x2F;play?task=009d5c81" rel="nofollow">https:&#x2F;&#x2F;arcprize.org&#x2F;play?task=009d5c81</a> in case you want to share!)</div><br/></div></div><div id="40652949" class="c"><input type="checkbox" id="c-40652949" checked=""/><div class="controls bullet"><span class="by">saati</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40652869">parent</a><span>|</span><a href="#40652941">prev</a><span>|</span><a href="#40652618">next</a><span>|</span><label class="collapse" for="c-40652949">[-]</label><label class="expand" for="c-40652949">[9 more]</label></div><br/><div class="children"><div class="content">It&#x27;s pretty easy, just follow the second example with the colors from the test input. (if it&#x27;s the same puzzle 00576224 for you too)</div><br/><div id="40653021" class="c"><input type="checkbox" id="c-40653021" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40652949">parent</a><span>|</span><a href="#40652618">next</a><span>|</span><label class="collapse" for="c-40653021">[-]</label><label class="expand" for="c-40653021">[8 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;arcprize.org&#x2F;play?task=00576224" rel="nofollow">https:&#x2F;&#x2F;arcprize.org&#x2F;play?task=00576224</a>  Yes the same puzzle.<p>And I followed the second example.  This was my solution:<p>GRG<p>OBO<p>RGR<p>B is the cyan like blue color. My solution looks right, but it says it’s wrong.</div><br/><div id="40653133" class="c"><input type="checkbox" id="c-40653133" checked=""/><div class="controls bullet"><span class="by">halter73</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40653021">parent</a><span>|</span><a href="#40653194">next</a><span>|</span><label class="collapse" for="c-40653133">[-]</label><label class="expand" for="c-40653133">[6 more]</label></div><br/><div class="children"><div class="content">You need to resize the output grid to 6x6.</div><br/><div id="40654126" class="c"><input type="checkbox" id="c-40654126" checked=""/><div class="controls bullet"><span class="by">kenjackson</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40653133">parent</a><span>|</span><a href="#40653194">next</a><span>|</span><label class="collapse" for="c-40654126">[-]</label><label class="expand" for="c-40654126">[5 more]</label></div><br/><div class="children"><div class="content">How come? The pattern should work for any size grid.</div><br/><div id="40654162" class="c"><input type="checkbox" id="c-40654162" checked=""/><div class="controls bullet"><span class="by">bigyikes</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40654126">parent</a><span>|</span><a href="#40653194">next</a><span>|</span><label class="collapse" for="c-40654162">[-]</label><label class="expand" for="c-40654162">[4 more]</label></div><br/><div class="children"><div class="content">You might be technically correct, but if you extend that logic, why not just make the grid 1x1 and select a single color?<p>The grid size <i>is part of the pattern</i> in the same way that the colors are part of the pattern. It’s not just a color pattern, it’s a generalized mapping of input to output.<p>In short: you need to resize the grid because that’s what the examples do.</div><br/><div id="40655456" class="c"><input type="checkbox" id="c-40655456" checked=""/><div class="controls bullet"><span class="by">lucianbr</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40654162">parent</a><span>|</span><a href="#40654772">next</a><span>|</span><label class="collapse" for="c-40655456">[-]</label><label class="expand" for="c-40655456">[1 more]</label></div><br/><div class="children"><div class="content">What is even the meaning of &quot;correct&quot; in this case?<p>This makes me think of &quot;math&quot; problems requiring you to find the next number in a series. They give you 5 numbers, and ask for the 6th. When I can build a polynomial than can generate the first 5 and any 6th number. Any.<p>Sounds like the point of these exercises it to guess what the author had in mind, more than some universal intelligence test. Though of course the author thinks their own thoughts are the measure of universal intelligence. It&#x27;s a tempting thing to believe.</div><br/></div></div><div id="40654772" class="c"><input type="checkbox" id="c-40654772" checked=""/><div class="controls bullet"><span class="by">johndough</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40654162">parent</a><span>|</span><a href="#40655456">prev</a><span>|</span><a href="#40653194">next</a><span>|</span><label class="collapse" for="c-40654772">[-]</label><label class="expand" for="c-40654772">[2 more]</label></div><br/><div class="children"><div class="content">&gt; why not just make the grid 1x1 and select a single color?<p>For two reasons:<p>1. The initially suggested grid size was 3x3.<p>2. Filling in a 3x3 grid is sufficient to show that you understood the pattern, but filling in a 1x1 (or even 2x2) grid is insufficient.<p>Requiring the user fill in a larger grid is a waste of time. The existence of the grid size selector would still make sense in cases where a 2x2 grid would be sufficient to show the solution, so it is not obvious at all that a 6x6 grid should be chosen.<p>&gt; The grid size is part of the pattern in the same way that the colors are part of the pattern.<p>To understand a pattern, you have to see at least two valid inputs and corresponding outputs. For the first example, a valid example for the expected output grid size is missing.<p>I arrived at the &quot;correct&quot; conclusion eventually, but the only indicator was that the reading direction for the UI was absolutely ridiculous ( <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;CuQ2z2N.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;CuQ2z2N.png</a> ), suggesting that the authors did not think this through properly, so the solution had to be weird as well.</div><br/><div id="40655470" class="c"><input type="checkbox" id="c-40655470" checked=""/><div class="controls bullet"><span class="by">lucianbr</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40654772">parent</a><span>|</span><a href="#40653194">next</a><span>|</span><label class="collapse" for="c-40655470">[-]</label><label class="expand" for="c-40655470">[1 more]</label></div><br/><div class="children"><div class="content">The fact that two intelligent beings are debating what the correct answer is shows that there is no fixed correct answer that proves &quot;intelligence&quot;.<p>This is IQ tests all over again. Actually testing how alike you think to the author of the test.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40652618" class="c"><input type="checkbox" id="c-40652618" checked=""/><div class="controls bullet"><span class="by">salamo</span><span>|</span><a href="#40651993">parent</a><span>|</span><a href="#40652869">prev</a><span>|</span><a href="#40652613">next</a><span>|</span><label class="collapse" for="c-40652618">[-]</label><label class="expand" for="c-40652618">[2 more]</label></div><br/><div class="children"><div class="content">They claim that the average score for humans is between 85% and 100%, so I think there&#x27;s a disagreement on whether the test is actually too hard. Taking them at their word, if no existing model can score even half what the average human can, the test is certainly measuring some kind of significant difference.<p>I guess there might be a disagreement of whether the problems in ARC are a representative sample of all of the possible abstract programs which could be synthesized, but then again most LLMs are also trained on human data.</div><br/><div id="40655474" class="c"><input type="checkbox" id="c-40655474" checked=""/><div class="controls bullet"><span class="by">gkbrk</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40652618">parent</a><span>|</span><a href="#40652613">next</a><span>|</span><label class="collapse" for="c-40655474">[-]</label><label class="expand" for="c-40655474">[1 more]</label></div><br/><div class="children"><div class="content">The tasks are very easy for humans. Out of the 6 tasks assigned when I opened the web page, I got all of them correct on the first try.<p>Maybe if you run into some exceptionally difficult tasks it might not be 100%, but there&#x27;s no way the challenge can be called unfair because it&#x27;s too difficult for humans too.</div><br/></div></div></div></div><div id="40652613" class="c"><input type="checkbox" id="c-40652613" checked=""/><div class="controls bullet"><span class="by">mark_l_watson</span><span>|</span><a href="#40651993">parent</a><span>|</span><a href="#40652618">prev</a><span>|</span><a href="#40651841">next</a><span>|</span><label class="collapse" for="c-40652613">[-]</label><label class="expand" for="c-40652613">[4 more]</label></div><br/><div class="children"><div class="content">I saw Melanie’s post and I am intrigued by an easier AGI suite. I would like some experimenting done by individuals like myself snd smaller organizations.</div><br/><div id="40655998" class="c"><input type="checkbox" id="c-40655998" checked=""/><div class="controls bullet"><span class="by">neoneye2</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40652613">parent</a><span>|</span><a href="#40652894">next</a><span>|</span><label class="collapse" for="c-40655998">[-]</label><label class="expand" for="c-40655998">[1 more]</label></div><br/><div class="children"><div class="content">Melanie is coauthor&#x2F;supervisor of ConceptARC, that can be tried here:
<a href="https:&#x2F;&#x2F;neoneye.github.io&#x2F;arc&#x2F;?dataset=ConceptARC" rel="nofollow">https:&#x2F;&#x2F;neoneye.github.io&#x2F;arc&#x2F;?dataset=ConceptARC</a></div><br/></div></div><div id="40652894" class="c"><input type="checkbox" id="c-40652894" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40652613">parent</a><span>|</span><a href="#40655998">prev</a><span>|</span><a href="#40654526">next</a><span>|</span><label class="collapse" for="c-40652894">[-]</label><label class="expand" for="c-40652894">[1 more]</label></div><br/><div class="children"><div class="content">Are you working on (a book detailing) AGI also? It’s a lonely field but I have no doubt there are a sea of malcontent engineers across the world who saw the truth early on and are pushing solo for AGI. It’s going well for me, but I’m not sure whether to take that as “you’re great” or “it’s really that easy”, so was interested to see such a fellow brazen American on HN of all places.<p>Game on for the million, if so :). If not, apologies for distracting from the good fight for OSS&#x2F;noncorp devs!<p>E: it occurred to me on the drive home how easily we (engineers) can fall into competitiveness, even when we’ve all read the thinkpieces about why an AI Race would&#x2F;will be&#x2F;is incredibly dangerous. Maybe not “game on”, perhaps… “god I hope it’s impossible but best of luck anyway to both of us”?</div><br/></div></div><div id="40654526" class="c"><input type="checkbox" id="c-40654526" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#40651993">root</a><span>|</span><a href="#40652613">parent</a><span>|</span><a href="#40652894">prev</a><span>|</span><a href="#40651841">next</a><span>|</span><label class="collapse" for="c-40654526">[-]</label><label class="expand" for="c-40654526">[1 more]</label></div><br/><div class="children"><div class="content">You actually think that has <i>not</i> been going for 30, 40 or 50 years?</div><br/></div></div></div></div></div></div><div id="40651841" class="c"><input type="checkbox" id="c-40651841" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#40651993">prev</a><span>|</span><a href="#40654875">next</a><span>|</span><label class="collapse" for="c-40651841">[-]</label><label class="expand" for="c-40651841">[6 more]</label></div><br/><div class="children"><div class="content">While I agree with the spirit of the competition, a $1M prize seems a little too low considering tens of billions of dollars have already been invested in the race to AGI, and we will see many times that put into the space in the coming years. The impact of AGI will be measured in <i>trillions</i> at minimum. So what you are ultimately rewarding isn&#x27;t AGI research but fine tuning the newest public LLM release to best meet the parameters of the test.<p>I&#x27;d also urge you to use a different platform for communicating with the public because x.com links are now inaccessible without creating an account.</div><br/><div id="40652544" class="c"><input type="checkbox" id="c-40652544" checked=""/><div class="controls bullet"><span class="by">mikeknoop</span><span>|</span><a href="#40651841">parent</a><span>|</span><a href="#40655448">next</a><span>|</span><label class="collapse" for="c-40652544">[-]</label><label class="expand" for="c-40652544">[1 more]</label></div><br/><div class="children"><div class="content">I agree, $1M is ~trivial in AI. The primary goal with the prize is to raise public awareness about how close (or far today) we are from AGI: <a href="https:&#x2F;&#x2F;arcprize.org&#x2F;leaderboard" rel="nofollow">https:&#x2F;&#x2F;arcprize.org&#x2F;leaderboard</a> and we hope that understanding will shift more would-be AI researchers to working new ideas</div><br/></div></div><div id="40655448" class="c"><input type="checkbox" id="c-40655448" checked=""/><div class="controls bullet"><span class="by">hackerlight</span><span>|</span><a href="#40651841">parent</a><span>|</span><a href="#40652544">prev</a><span>|</span><a href="#40652988">next</a><span>|</span><label class="collapse" for="c-40655448">[-]</label><label class="expand" for="c-40655448">[1 more]</label></div><br/><div class="children"><div class="content">The $1M ARC prize is advertising, just like being #1 on the huggingface leaderboard. It won&#x27;t matter for end consumers, but for attracting the best talent it could be valuable.</div><br/></div></div><div id="40652988" class="c"><input type="checkbox" id="c-40652988" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#40651841">parent</a><span>|</span><a href="#40655448">prev</a><span>|</span><a href="#40652532">next</a><span>|</span><label class="collapse" for="c-40652988">[-]</label><label class="expand" for="c-40652988">[1 more]</label></div><br/><div class="children"><div class="content">That was my initial reaction too.<p>&quot;Endow circuitry with consciousness and win a gift certificate for Denny&#x27;s (may not be used in conjunction with other specials)&quot;</div><br/></div></div><div id="40652532" class="c"><input type="checkbox" id="c-40652532" checked=""/><div class="controls bullet"><span class="by">ks2048</span><span>|</span><a href="#40651841">parent</a><span>|</span><a href="#40652988">prev</a><span>|</span><a href="#40654875">next</a><span>|</span><label class="collapse" for="c-40652532">[-]</label><label class="expand" for="c-40652532">[2 more]</label></div><br/><div class="children"><div class="content">The submissions can&#x27;t use the internet. And I imagine can&#x27;t be too huge - so you can&#x27;t use &quot;newest public LLMs&quot; on this task.</div><br/><div id="40652563" class="c"><input type="checkbox" id="c-40652563" checked=""/><div class="controls bullet"><span class="by">mikeknoop</span><span>|</span><a href="#40651841">root</a><span>|</span><a href="#40652532">parent</a><span>|</span><a href="#40654875">next</a><span>|</span><label class="collapse" for="c-40652563">[-]</label><label class="expand" for="c-40652563">[1 more]</label></div><br/><div class="children"><div class="content">That is correct for ARC Prize: limited Kaggle compute (to target efficiency) and no internet (to reduce cheating).<p>We are also trialing a secondary leaderboard called ARC-AGI-Pub that imposes no limits or constraints. Not part of the prize today but could be in the future: <a href="https:&#x2F;&#x2F;arcprize.org&#x2F;leaderboard" rel="nofollow">https:&#x2F;&#x2F;arcprize.org&#x2F;leaderboard</a></div><br/></div></div></div></div></div></div><div id="40654875" class="c"><input type="checkbox" id="c-40654875" checked=""/><div class="controls bullet"><span class="by">ks2048</span><span>|</span><a href="#40651841">prev</a><span>|</span><a href="#40655651">next</a><span>|</span><label class="collapse" for="c-40654875">[-]</label><label class="expand" for="c-40654875">[1 more]</label></div><br/><div class="children"><div class="content">This is interesting. I&#x27;ve been looking at the data today and made a helper to quickly view the ARC dataset: <a href="https:&#x2F;&#x2F;kts.github.io&#x2F;arc-viewer&#x2F;" rel="nofollow">https:&#x2F;&#x2F;kts.github.io&#x2F;arc-viewer&#x2F;</a><p>So you can view 100 per page instead of clicking through one-by-one: <a href="https:&#x2F;&#x2F;kts.github.io&#x2F;arc-viewer&#x2F;page1&#x2F;" rel="nofollow">https:&#x2F;&#x2F;kts.github.io&#x2F;arc-viewer&#x2F;page1&#x2F;</a></div><br/></div></div><div id="40655651" class="c"><input type="checkbox" id="c-40655651" checked=""/><div class="controls bullet"><span class="by">ryanoptimus</span><span>|</span><a href="#40654875">prev</a><span>|</span><a href="#40655309">next</a><span>|</span><label class="collapse" for="c-40655651">[-]</label><label class="expand" for="c-40655651">[1 more]</label></div><br/><div class="children"><div class="content">Looks like bongard problems for the referenced problem solving tasks
<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bongard_problem" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bongard_problem</a></div><br/></div></div><div id="40655309" class="c"><input type="checkbox" id="c-40655309" checked=""/><div class="controls bullet"><span class="by">nmca</span><span>|</span><a href="#40655651">prev</a><span>|</span><a href="#40651663">next</a><span>|</span><label class="collapse" for="c-40655309">[-]</label><label class="expand" for="c-40655309">[1 more]</label></div><br/><div class="children"><div class="content">Prediction markets on the outcome:<p><a href="https:&#x2F;&#x2F;manifold.markets&#x2F;JacobPfau&#x2F;will-the-arcagi-grand-prize-be-clai?r=Tk1jQQ" rel="nofollow">https:&#x2F;&#x2F;manifold.markets&#x2F;JacobPfau&#x2F;will-the-arcagi-grand-pri...</a></div><br/></div></div><div id="40651663" class="c"><input type="checkbox" id="c-40651663" checked=""/><div class="controls bullet"><span class="by">elicksaur</span><span>|</span><a href="#40655309">prev</a><span>|</span><a href="#40653245">next</a><span>|</span><label class="collapse" for="c-40651663">[-]</label><label class="expand" for="c-40651663">[1 more]</label></div><br/><div class="children"><div class="content">I’m a big fan of the ARC as a problem set to tackle. The sparseness of the data and infinite-ness of the rules which could apply make it much tougher than existing ML problem sets.<p>However, I do disagree that this problem represents “AGI”. It’s just a different dataset than what we’ve seen with existing ML successes, but the approaches are generally similar to what’s come before. It could be that some truly novel breakthrough which is AGI solves the problem set, but I don’t think solving the problem set is a guaranteed indicator of AGI.</div><br/></div></div><div id="40653245" class="c"><input type="checkbox" id="c-40653245" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#40651663">prev</a><span>|</span><a href="#40652984">next</a><span>|</span><label class="collapse" for="c-40653245">[-]</label><label class="expand" for="c-40653245">[4 more]</label></div><br/><div class="children"><div class="content">Interesting. It seems most of these task target a very specific part of the brain that recognizes visual patterns. But that alone is cannot possibly be the only definition of intelligence.<p>What about Theory of Mind which talks about the problem of multiple agents in the real world acting together? Like driving a car cannot be done right now without oodles of data or any robot - human problem that requires the robot to model human&#x27;s goals and intentions.<p>I think the problem is definition of general intelligence: Intelligence in the context of what? How much effort(kwh, $$ etc) is the human willing to amortize over the learning cycle of a machine to teach it what it needs to do and how that relates to a personally needed outcome( like build me a sandwich or construct a house)? Hopefully this should decrease over time.<p>I believe the answer is that the only intelligence that really matters is Human-AI cooperative intelligence and our goals and whether a machine understands them. The problems then need to be framed as optimization of a multi attribute goal with the attribute weights adjusted as one learns from the human.<p>I know a few labs working on this, one is in ASU(Kambhampati, Rao et. al) and possibly Google and now maybe open ai.</div><br/><div id="40653880" class="c"><input type="checkbox" id="c-40653880" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40653245">parent</a><span>|</span><a href="#40652984">next</a><span>|</span><label class="collapse" for="c-40653880">[-]</label><label class="expand" for="c-40653880">[3 more]</label></div><br/><div class="children"><div class="content">I made another comment here saying the same thing, but visual patterns and other patterns are nonetheless <i>spatial</i> patterns. Audio, understanding music, or speech, rtc are things that are happening spatially, and they can just as easily be mapped as visual problems. This makes a lot of sense, as after all our senses are telling us what&#x27;s happening in space-time.<p>Take for example a simple audiotory pattern like &quot;clap clap clap&quot;. This has a very trival mapping as visual like so:<p>x x x<p>- - -<p>house house house<p>whereas anyone would agree the sound of three equally spaced claps would not be analogous to say:<p>aa b b b<p>-- --- -- -- ---<p>This ability to relate or equate two entirely different senses should clue you in that there is a deeper framework at play</div><br/><div id="40654015" class="c"><input type="checkbox" id="c-40654015" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#40653245">root</a><span>|</span><a href="#40653880">parent</a><span>|</span><a href="#40652984">next</a><span>|</span><label class="collapse" for="c-40654015">[-]</label><label class="expand" for="c-40654015">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just mapping events in space and time, it&#x27;s also bringing in appropriate context and expectation of future (goals, intentions) into the present, other people&#x27;s mental models into our prediction.<p>I am not sure how abstract thinking for generalized pattern matching make it AGI to solve these kind of problems(not that they are not amazing abilities). If these ToM problems are reducible to these tasks posted by the OP then there would need to be some kind of theorem proving business to convert between the two sets of problems efficiently no?</div><br/><div id="40654073" class="c"><input type="checkbox" id="c-40654073" checked=""/><div class="controls bullet"><span class="by">andoando</span><span>|</span><a href="#40653245">root</a><span>|</span><a href="#40654015">parent</a><span>|</span><a href="#40652984">next</a><span>|</span><label class="collapse" for="c-40654073">[-]</label><label class="expand" for="c-40654073">[1 more]</label></div><br/><div class="children"><div class="content">Its not just a matter of mapping, no, but imo its a critical first step. You need a model of space-time. You need to be able to place all the facts into a spatial world following the physical laws.<p>Take this problem, and assume you dont know a single thing about battles&#x2F;military history, etc.
There are two groups of men standing few hundred feet apart. It is raining, the ground is muddy. One group of men has these wooden curved sticks with a string and iron with pointy ends. The other group has people on horses, and men with very long pointy iron sticks and theyre all covered in steel plating.<p>Who will win if they all fight against each other? There&#x27;s really no correct answer but Id expect an intelligent agent to give some detailed reasoning for their decision and to infer details or possibilities and ask questions based again not on previous knowledge but what physically makes sense in the description that was given.<p>This isnt just a matter of statistics or knowing facts like &quot;rain, mud = heavy armored units will be slower or even trapped&quot;, &quot;horses are fast&quot;, &quot;bows can penetrate steel&quot;, etc. If I give you the full detailed description of the battlefield, very small details can completely change your perception. For example if I said theres big giant logs in the middle of battle, you need to reason about how horses jump, and whether it&#x27;s something they can clear. You can do this barely knowing horses if you understand how animals in general move. Perhaps there is even some small difference in horses that would make you think they are capable of making large jumps whereas all the animals youve seen before cannot<p>What Im saying is, to truly reason you need to understand spatial relations very deeply. Indeed id say spatial relations (through time) are all there is to reason about.</div><br/></div></div></div></div></div></div></div></div><div id="40652984" class="c"><input type="checkbox" id="c-40652984" checked=""/><div class="controls bullet"><span class="by">levocardia</span><span>|</span><a href="#40653245">prev</a><span>|</span><a href="#40651875">next</a><span>|</span><label class="collapse" for="c-40652984">[-]</label><label class="expand" for="c-40652984">[3 more]</label></div><br/><div class="children"><div class="content">François Chollet&#x27;s original paper is incredibly insightful and I&#x27;m consistently shocked more people don&#x27;t talk about it. Some parts are quite technical but at a high level it is the best answer to &quot;what do we mean by general intelligence?&quot; that I&#x27;ve yet seen.<p>Defining intelligence as an <i>efficiency of learning</i>, after accounting for any explicit or implicit priors about the world, makes it much easier to understand why human intelligence is so impressive.</div><br/><div id="40654950" class="c"><input type="checkbox" id="c-40654950" checked=""/><div class="controls bullet"><span class="by">ildon</span><span>|</span><a href="#40652984">parent</a><span>|</span><a href="#40651875">next</a><span>|</span><label class="collapse" for="c-40654950">[-]</label><label class="expand" for="c-40654950">[2 more]</label></div><br/><div class="children"><div class="content">Do you remember the title&#x2F;where to find it?</div><br/><div id="40655597" class="c"><input type="checkbox" id="c-40655597" checked=""/><div class="controls bullet"><span class="by">mischa_u</span><span>|</span><a href="#40652984">root</a><span>|</span><a href="#40654950">parent</a><span>|</span><a href="#40651875">next</a><span>|</span><label class="collapse" for="c-40655597">[-]</label><label class="expand" for="c-40655597">[1 more]</label></div><br/><div class="children"><div class="content">&quot;On the Measure of Intelligence&quot; <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1911.01547" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1911.01547</a></div><br/></div></div></div></div></div></div><div id="40651875" class="c"><input type="checkbox" id="c-40651875" checked=""/><div class="controls bullet"><span class="by">bigyikes</span><span>|</span><a href="#40652984">prev</a><span>|</span><a href="#40655102">next</a><span>|</span><label class="collapse" for="c-40651875">[-]</label><label class="expand" for="c-40651875">[1 more]</label></div><br/><div class="children"><div class="content">Dwarkesh just released an interview with Francois Chollet (partner of OP). I’ve only listened to a few minutes so far, but I’m very interested in hearing more about his conceptions of the limitations of LLMs.<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;UakqL6Pj9xo" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;UakqL6Pj9xo</a></div><br/></div></div><div id="40655102" class="c"><input type="checkbox" id="c-40655102" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#40651875">prev</a><span>|</span><a href="#40651825">next</a><span>|</span><label class="collapse" for="c-40655102">[-]</label><label class="expand" for="c-40655102">[4 more]</label></div><br/><div class="children"><div class="content">Chollet&#x27;s argument is that LLMs just imitate and recombine patterns. This might be true if you&#x27;re looking at LLMs in isolation, but when they chat with people something different happens. The system made of humans+LLMs is an AGI. It is no longer just a parrot, it ingests new information, gets guidance, feedback and is basically embodied in a chat room with human and tools.<p>This scales for 200M users and 1 billion sessions per moth for OpenAI, which can interpret every human response as a feedback signal, implicit or explicit. Even more if you take multiple sessions of chat spreading over days, that continue the same topic and incorporate real world feedback. The scale of interaction is just staggering, the LLM can incorporate this experience to iteratively improve.<p>If you take a look at humans, we&#x27;re very incapable alone. Think feral Einstein on a remote island - what could he achieve without the social context and language based learning? Just as a human brain is severely limited without society, LLMs also need society, diversity of agents and experiences, and sharing of those experiences in language.<p>It is unfair to compare a human immersed in society with a standalone model. That is why they appear limited. But even as a system of memorization+recombination they can be a powerful element of the AGI. I think AGI will be social and distributed, won&#x27;t be a singleton. Its evolution is based on learning from the world, no longer just a parrot of human text. The data engine would be: World &lt;-&gt; People &lt;-&gt; LLM, a full feedback cycle, all three components evolve in time. Intelligence evolves socially.</div><br/><div id="40655310" class="c"><input type="checkbox" id="c-40655310" checked=""/><div class="controls bullet"><span class="by">8organicbits</span><span>|</span><a href="#40655102">parent</a><span>|</span><a href="#40651825">next</a><span>|</span><label class="collapse" for="c-40655310">[-]</label><label class="expand" for="c-40655310">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The system made of humans+LLMs is an AGI.<p>Pay no attention to the man behind the curtain.<p>This type of thinking would claim that mechanical turk is AGI, or perhaps that human+pen and paper is AGI. While they are great tools, that&#x27;s not how I&#x27;d characterize them.</div><br/><div id="40655388" class="c"><input type="checkbox" id="c-40655388" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#40655102">root</a><span>|</span><a href="#40655310">parent</a><span>|</span><a href="#40651825">next</a><span>|</span><label class="collapse" for="c-40655388">[-]</label><label class="expand" for="c-40655388">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Pay no attention to the man behind the curtain.<p>I could say the same for us, pay no attention to the other humans who are behind the curtain.<p>Humans in isolation are dumb, limited, and can get nowhere with understanding the world. Intelligence is mostly nurture over nature, the collective activity of society nurtures intelligence. It&#x27;s smart because it learns from many diverse experiences and has a common language for sharing discoveries.<p>A human, even the smartest of us, can&#x27;t solve cutting edge problems on demand, we&#x27;re not that smart. But we can stumble on discoveries, especially in large numbers, and can share good ideas. We&#x27;re smart by stumbling onto good ideas, and we can build upon these discoveries because we have a common language. Just a massive search program based on real world outcomes, that is what looks like general intelligence at societal level.<p>If you take the social aspect of intelligence into consideration then LLMs are judged in an inappropriate way, as stand alone agents. Of course they are limited, and we&#x27;re almost as limited alone. The real locus of intelligence is the language-world system.</div><br/><div id="40655544" class="c"><input type="checkbox" id="c-40655544" checked=""/><div class="controls bullet"><span class="by">8organicbits</span><span>|</span><a href="#40655102">root</a><span>|</span><a href="#40655388">parent</a><span>|</span><a href="#40651825">next</a><span>|</span><label class="collapse" for="c-40655544">[-]</label><label class="expand" for="c-40655544">[1 more]</label></div><br/><div class="children"><div class="content">The A in AGI stands for artificial, so a human+LLM system would not qualify as it has a natural, human component. That doesn&#x27;t mean it&#x27;s not an interesting topic, or that it won&#x27;t help humans discover our world better, it&#x27;s just the wrong label. Remove the human and you&#x27;d just have LLMs talking nonsense at each other. It&#x27;s not surprising that you get an intelligent system when you include natural intelligence.</div><br/></div></div></div></div></div></div></div></div><div id="40651825" class="c"><input type="checkbox" id="c-40651825" checked=""/><div class="controls bullet"><span class="by">bigyikes</span><span>|</span><a href="#40655102">prev</a><span>|</span><a href="#40655350">next</a><span>|</span><label class="collapse" for="c-40651825">[-]</label><label class="expand" for="c-40651825">[5 more]</label></div><br/><div class="children"><div class="content">What is the fundamental difference between ARC and a standard IQ test? On the surface they seem similar in that they both involve deducing and generalizing visual patterns.<p>Is there something special about these questions that makes them resistant to memorization? Or is it more just the fact that there are 100 secret tasks?</div><br/><div id="40653526" class="c"><input type="checkbox" id="c-40653526" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#40651825">parent</a><span>|</span><a href="#40655350">next</a><span>|</span><label class="collapse" for="c-40653526">[-]</label><label class="expand" for="c-40653526">[4 more]</label></div><br/><div class="children"><div class="content">I’ve always found this kind of puzzle infuriating because it’s way underspecified. You’re not trying to find a pattern, you’re trying to guess what pattern the test writer would expect.</div><br/><div id="40655488" class="c"><input type="checkbox" id="c-40655488" checked=""/><div class="controls bullet"><span class="by">gkbrk</span><span>|</span><a href="#40651825">root</a><span>|</span><a href="#40653526">parent</a><span>|</span><a href="#40653958">next</a><span>|</span><label class="collapse" for="c-40655488">[-]</label><label class="expand" for="c-40655488">[1 more]</label></div><br/><div class="children"><div class="content">Most of the ARC tasks are intuitive and have one obvious answer. Both on IQ tests and the ARC challenge, people manage to guess what the test writer expects.<p>For an AI that&#x27;s more useful anyway. If the task is specified completely non-ambiguously, you wouldn&#x27;t need AI. But if it can correctly guess what you want from a limited number of obvious examples that&#x27;s much more useful.</div><br/></div></div><div id="40653958" class="c"><input type="checkbox" id="c-40653958" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#40651825">root</a><span>|</span><a href="#40653526">parent</a><span>|</span><a href="#40655488">prev</a><span>|</span><a href="#40655350">next</a><span>|</span><label class="collapse" for="c-40653958">[-]</label><label class="expand" for="c-40653958">[2 more]</label></div><br/><div class="children"><div class="content">countless of problems in the world are underspecified in exactly this way, that is effectively what common sense reasoning is. Or what Charles Sanders Peirce called abductive reasoning, making a sensible best guess under conditions of uncertainty.</div><br/><div id="40654487" class="c"><input type="checkbox" id="c-40654487" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#40651825">root</a><span>|</span><a href="#40653958">parent</a><span>|</span><a href="#40655350">next</a><span>|</span><label class="collapse" for="c-40654487">[-]</label><label class="expand" for="c-40654487">[1 more]</label></div><br/><div class="children"><div class="content">Yes, real-world problems are often underspecified but also they tend to come with much more context, and to be much more interactive. These sorts of problems are deliberately minimal and abstract meaning there&#x27;s nothing for &#x27;common sense&#x27; to work with.</div><br/></div></div></div></div></div></div></div></div><div id="40655350" class="c"><input type="checkbox" id="c-40655350" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#40651825">prev</a><span>|</span><a href="#40653486">next</a><span>|</span><label class="collapse" for="c-40655350">[-]</label><label class="expand" for="c-40655350">[2 more]</label></div><br/><div class="children"><div class="content">Why doesn&#x27;t Chollet just make a challenge that reads like &quot;Solve cancer&quot;, surely there is no solution in any books.<p>If the AI is really AGI it could presumably do it. But not even the whole human society can do it in one go, it&#x27;s a slow iterative process of ideation and validation. Even though this is a life and death matter, we can&#x27;t simply solve it.<p>This is why AGI won&#x27;t look like we expect, it will be a continuation of how societies solve problems. Intelligence of a single AI in isolation is not comparable to that of societies of agents with diverse real world interactions.</div><br/><div id="40655723" class="c"><input type="checkbox" id="c-40655723" checked=""/><div class="controls bullet"><span class="by">isaacfrond</span><span>|</span><a href="#40655350">parent</a><span>|</span><a href="#40653486">next</a><span>|</span><label class="collapse" for="c-40655723">[-]</label><label class="expand" for="c-40655723">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. Because I&#x27;m sure that the minute some program aces the ARC test, we&#x27;ll all say, ahhh, but that, that wasn&#x27;t real intelligence. And they would be right, if you solve the ARC test, you can do ARC like puzzles. Say something about your reasoning abilities I guess, but it surely does not say you have super human intelligence.</div><br/></div></div></div></div><div id="40653486" class="c"><input type="checkbox" id="c-40653486" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#40655350">prev</a><span>|</span><a href="#40651329">next</a><span>|</span><label class="collapse" for="c-40653486">[-]</label><label class="expand" for="c-40653486">[1 more]</label></div><br/><div class="children"><div class="content">Related ongoing thread:<p><i>Francois Chollet: OpenAI has set back the progress towards AGI by 5-10 years</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40652818">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40652818</a> - June 2024 (5 comments)</div><br/></div></div><div id="40651329" class="c"><input type="checkbox" id="c-40651329" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#40653486">prev</a><span>|</span><a href="#40655191">next</a><span>|</span><label class="collapse" for="c-40651329">[-]</label><label class="expand" for="c-40651329">[1 more]</label></div><br/><div class="children"><div class="content">I watched a video that covered ARC-AGI a few days ago, It had links to the old competition. It gave me much to think about. Nice to see a new run at it.<p>Not sure If I have the skills to make an entry, but I&#x27;ll be watching at least.</div><br/></div></div><div id="40655191" class="c"><input type="checkbox" id="c-40655191" checked=""/><div class="controls bullet"><span class="by">KBme</span><span>|</span><a href="#40651329">prev</a><span>|</span><a href="#40655082">next</a><span>|</span><label class="collapse" for="c-40655191">[-]</label><label class="expand" for="c-40655191">[1 more]</label></div><br/><div class="children"><div class="content">How can people believe that a censored politically correct process can get even close to something like AGI is baffling to me.
Lysenkoism in computing.</div><br/></div></div><div id="40655082" class="c"><input type="checkbox" id="c-40655082" checked=""/><div class="controls bullet"><span class="by">geor9e</span><span>|</span><a href="#40655191">prev</a><span>|</span><a href="#40654330">next</a><span>|</span><label class="collapse" for="c-40655082">[-]</label><label class="expand" for="c-40655082">[3 more]</label></div><br/><div class="children"><div class="content">I found them all extremely easy for a while, but then I couldn&#x27;t figure out the rules of this one at all: e6de6e8f <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;ExMFGqU.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;ExMFGqU.png</a></div><br/><div id="40655346" class="c"><input type="checkbox" id="c-40655346" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#40655082">parent</a><span>|</span><a href="#40655975">next</a><span>|</span><label class="collapse" for="c-40655346">[-]</label><label class="expand" for="c-40655346">[1 more]</label></div><br/><div class="children"><div class="content">Each of the red shapes in the input are separated by black squares. Starting from the green block, rotate the red shapes 90 degrees and stack them downwards.<p>Thats the general pattern although my description wasn’t very good.</div><br/></div></div><div id="40655975" class="c"><input type="checkbox" id="c-40655975" checked=""/><div class="controls bullet"><span class="by">zurfer</span><span>|</span><a href="#40655082">parent</a><span>|</span><a href="#40655346">prev</a><span>|</span><a href="#40654330">next</a><span>|</span><label class="collapse" for="c-40655975">[-]</label><label class="expand" for="c-40655975">[1 more]</label></div><br/><div class="children"><div class="content">yeah it&#x27;s off somehow.
rule 1: start at the green dot?<p>rule 2: glue the left outer piece to the bottom<p>rule 3: overlap every now and then :D<p>rule 4: invert some of the pieces every now and then</div><br/></div></div></div></div><div id="40654330" class="c"><input type="checkbox" id="c-40654330" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#40655082">prev</a><span>|</span><a href="#40653728">next</a><span>|</span><label class="collapse" for="c-40654330">[-]</label><label class="expand" for="c-40654330">[3 more]</label></div><br/><div class="children"><div class="content">Are we allowed to combine multiple tools including gpt-4 to solve this? E.g. a script that does image processing, passes the results to gpt, where gpt can invoke further runs of scripts using other tools?</div><br/><div id="40654760" class="c"><input type="checkbox" id="c-40654760" checked=""/><div class="controls bullet"><span class="by">montag</span><span>|</span><a href="#40654330">parent</a><span>|</span><a href="#40653728">next</a><span>|</span><label class="collapse" for="c-40654760">[-]</label><label class="expand" for="c-40654760">[2 more]</label></div><br/><div class="children"><div class="content">&gt; submissions to Kaggle will not have access to the internet. Using a 3rd-party, cloud-hosted LLM is not possible.<p><a href="https:&#x2F;&#x2F;arcprize.org&#x2F;guide" rel="nofollow">https:&#x2F;&#x2F;arcprize.org&#x2F;guide</a></div><br/><div id="40654982" class="c"><input type="checkbox" id="c-40654982" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#40654330">root</a><span>|</span><a href="#40654760">parent</a><span>|</span><a href="#40653728">next</a><span>|</span><label class="collapse" for="c-40654982">[-]</label><label class="expand" for="c-40654982">[1 more]</label></div><br/><div class="children"><div class="content">This largely takes away any odds at solving this. You definitely can&#x27;t reproduce that under a million dollars.<p>I have some ideas I want to try, I might still though. But all of it would require external tools.</div><br/></div></div></div></div></div></div><div id="40653728" class="c"><input type="checkbox" id="c-40653728" checked=""/><div class="controls bullet"><span class="by">curious_cat_163</span><span>|</span><a href="#40654330">prev</a><span>|</span><a href="#40649828">next</a><span>|</span><label class="collapse" for="c-40653728">[-]</label><label class="expand" for="c-40653728">[2 more]</label></div><br/><div class="children"><div class="content">So, this is a good idea. Having opinions about what AGI benchmarks should look like is a great way to argue about the kind of technology we want to build for the future.<p>However, why are the 100 test tasks secret? I don&#x27;t understand why how resisting “memorization” techniques requires it. Maybe someone can enlighten me.</div><br/><div id="40653746" class="c"><input type="checkbox" id="c-40653746" checked=""/><div class="controls bullet"><span class="by">muglug</span><span>|</span><a href="#40653728">parent</a><span>|</span><a href="#40649828">next</a><span>|</span><label class="collapse" for="c-40653746">[-]</label><label class="expand" for="c-40653746">[1 more]</label></div><br/><div class="children"><div class="content">If the tasks were public then it would be trivial to have a human figure out the answers, and then to train an LLM to memorise those answers.</div><br/></div></div></div></div><div id="40649828" class="c"><input type="checkbox" id="c-40649828" checked=""/><div class="controls bullet"><span class="by">freediver</span><span>|</span><a href="#40653728">prev</a><span>|</span><a href="#40654281">next</a><span>|</span><label class="collapse" for="c-40649828">[-]</label><label class="expand" for="c-40649828">[2 more]</label></div><br/><div class="children"><div class="content">This is amazing, and much needed. Thanks for organizing this. Makes me want to flex the programming muscle again.</div><br/><div id="40655244" class="c"><input type="checkbox" id="c-40655244" checked=""/><div class="controls bullet"><span class="by">dailykoder</span><span>|</span><a href="#40649828">parent</a><span>|</span><a href="#40654281">next</a><span>|</span><label class="collapse" for="c-40655244">[-]</label><label class="expand" for="c-40655244">[1 more]</label></div><br/><div class="children"><div class="content">Haha, great post! Well meme&#x27;d my friend!</div><br/></div></div></div></div><div id="40654281" class="c"><input type="checkbox" id="c-40654281" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#40649828">prev</a><span>|</span><a href="#40653348">next</a><span>|</span><label class="collapse" for="c-40654281">[-]</label><label class="expand" for="c-40654281">[1 more]</label></div><br/><div class="children"><div class="content">Maybe this is a dumb question, but in order to pass, is the program or model only allowed to use the 400 training tasks? I assume it is allowed to train on other data, just not the actual public test tasks?<p>Things like SORA and gpt-4o that use [diffusion transformers etc. or whatever the SOTA is for multimodal large models] seem to be able to generalize quite well. Have these latest models been tested against this task?</div><br/></div></div><div id="40653348" class="c"><input type="checkbox" id="c-40653348" checked=""/><div class="controls bullet"><span class="by">Geee</span><span>|</span><a href="#40654281">prev</a><span>|</span><a href="#40655344">next</a><span>|</span><label class="collapse" for="c-40653348">[-]</label><label class="expand" for="c-40653348">[4 more]</label></div><br/><div class="children"><div class="content">Any details on how these tests were created? I.e. which kind of program was used for generation.</div><br/><div id="40653382" class="c"><input type="checkbox" id="c-40653382" checked=""/><div class="controls bullet"><span class="by">neoneye2</span><span>|</span><a href="#40653348">parent</a><span>|</span><a href="#40655344">next</a><span>|</span><label class="collapse" for="c-40653382">[-]</label><label class="expand" for="c-40653382">[3 more]</label></div><br/><div class="children"><div class="content">I think the ARC-AGI tasks was manually drawn with an early version of fchollet&#x27;s editor.<p>Recently Michael Hodel has reverse engineered 400 of the tasks, so more tasks can be generated. Interestingly it can generate python programs that solves the tasks too.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;michaelhodel&#x2F;re-arc">https:&#x2F;&#x2F;github.com&#x2F;michaelhodel&#x2F;re-arc</a></div><br/><div id="40655202" class="c"><input type="checkbox" id="c-40655202" checked=""/><div class="controls bullet"><span class="by">montag</span><span>|</span><a href="#40653348">root</a><span>|</span><a href="#40653382">parent</a><span>|</span><a href="#40654021">next</a><span>|</span><label class="collapse" for="c-40655202">[-]</label><label class="expand" for="c-40655202">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean it can &#x27;generate python programs that solve the tasks&#x27;?  I can&#x27;t find any mention of that. I only see hand-coded solutions.</div><br/></div></div><div id="40654021" class="c"><input type="checkbox" id="c-40654021" checked=""/><div class="controls bullet"><span class="by">sestep</span><span>|</span><a href="#40653348">root</a><span>|</span><a href="#40653382">parent</a><span>|</span><a href="#40655202">prev</a><span>|</span><a href="#40655344">next</a><span>|</span><label class="collapse" for="c-40654021">[-]</label><label class="expand" for="c-40654021">[1 more]</label></div><br/><div class="children"><div class="content">This is exactly what my first step was going to be. Thanks for the link! Saves a lot of time for someone to have already done it.</div><br/></div></div></div></div></div></div><div id="40655344" class="c"><input type="checkbox" id="c-40655344" checked=""/><div class="controls bullet"><span class="by">nmca</span><span>|</span><a href="#40653348">prev</a><span>|</span><a href="#40653505">next</a><span>|</span><label class="collapse" for="c-40655344">[-]</label><label class="expand" for="c-40655344">[1 more]</label></div><br/><div class="children"><div class="content">ARC is a noble endeavour but mistakes visual&#x2F;spatial reasoning for reasoning and thus fails.</div><br/></div></div><div id="40653505" class="c"><input type="checkbox" id="c-40653505" checked=""/><div class="controls bullet"><span class="by">chairhairair</span><span>|</span><a href="#40655344">prev</a><span>|</span><a href="#40654631">next</a><span>|</span><label class="collapse" for="c-40653505">[-]</label><label class="expand" for="c-40653505">[1 more]</label></div><br/><div class="children"><div class="content">These puzzles are fun and challenging in the same way that puzzles from video games like The Witness and Baba Is You are.<p>I bet you could use those puzzles as benchmarks as well.</div><br/></div></div><div id="40654631" class="c"><input type="checkbox" id="c-40654631" checked=""/><div class="controls bullet"><span class="by">z3phyr</span><span>|</span><a href="#40653505">prev</a><span>|</span><a href="#40654480">next</a><span>|</span><label class="collapse" for="c-40654631">[-]</label><label class="expand" for="c-40654631">[1 more]</label></div><br/><div class="children"><div class="content">I can see many problems can be solved with modern symbolic approaches like theorem provers, dependent types, pattern matching etc. But I will have to dive in to actually confirm it.</div><br/></div></div><div id="40654480" class="c"><input type="checkbox" id="c-40654480" checked=""/><div class="controls bullet"><span class="by">arcastroe</span><span>|</span><a href="#40654631">prev</a><span>|</span><a href="#40652267">next</a><span>|</span><label class="collapse" for="c-40654480">[-]</label><label class="expand" for="c-40654480">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious, if it turns out that a simple rule-based algorithm exists, specifically tailored to solve (only!) ARC style problems, without generalization, would that still qualify for the reward?</div><br/><div id="40654766" class="c"><input type="checkbox" id="c-40654766" checked=""/><div class="controls bullet"><span class="by">montag</span><span>|</span><a href="#40654480">parent</a><span>|</span><a href="#40652267">next</a><span>|</span><label class="collapse" for="c-40654766">[-]</label><label class="expand" for="c-40654766">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s breaking any rules, and in fact it would help to expose a whole class of weaknesses in the test.</div><br/></div></div></div></div><div id="40652267" class="c"><input type="checkbox" id="c-40652267" checked=""/><div class="controls bullet"><span class="by">david_shi</span><span>|</span><a href="#40654480">prev</a><span>|</span><label class="collapse" for="c-40652267">[-]</label><label class="expand" for="c-40652267">[3 more]</label></div><br/><div class="children"><div class="content">What is the fastest way to get up to speed with techniques that led to the current SOTA?</div><br/><div id="40652494" class="c"><input type="checkbox" id="c-40652494" checked=""/><div class="controls bullet"><span class="by">gkamradt</span><span>|</span><a href="#40652267">parent</a><span>|</span><a href="#40653186">next</a><span>|</span><label class="collapse" for="c-40652494">[-]</label><label class="expand" for="c-40652494">[1 more]</label></div><br/><div class="children"><div class="content">Check out the SOTA resources on the guide<p><a href="https:&#x2F;&#x2F;arcprize.org&#x2F;guide" rel="nofollow">https:&#x2F;&#x2F;arcprize.org&#x2F;guide</a><p>Happy to answer any questions you have along the way<p>(I&#x27;m helping run ARC Prize)</div><br/></div></div><div id="40653186" class="c"><input type="checkbox" id="c-40653186" checked=""/><div class="controls bullet"><span class="by">ks2048</span><span>|</span><a href="#40652267">parent</a><span>|</span><a href="#40652494">prev</a><span>|</span><label class="collapse" for="c-40653186">[-]</label><label class="expand" for="c-40653186">[1 more]</label></div><br/><div class="children"><div class="content">This looks very helpful: <a href="https:&#x2F;&#x2F;github.com&#x2F;neoneye&#x2F;arc-notes&#x2F;tree&#x2F;main&#x2F;awesome">https:&#x2F;&#x2F;github.com&#x2F;neoneye&#x2F;arc-notes&#x2F;tree&#x2F;main&#x2F;awesome</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>