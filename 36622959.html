<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1688720460405" as="style"/><link rel="stylesheet" href="styles.css?v=1688720460405"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://hai.stanford.edu/news/ai-agents-self-reflect-perform-better-changing-environments">AI agents that “self-reflect” perform better in changing environments</a> <span class="domain">(<a href="https://hai.stanford.edu">hai.stanford.edu</a>)</span></div><div class="subtext"><span>chdoyle</span> | <span>40 comments</span></div><br/><div><div id="36623394" class="c"><input type="checkbox" id="c-36623394" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36628845">next</a><span>|</span><label class="collapse" for="c-36623394">[-]</label><label class="expand" for="c-36623394">[20 more]</label></div><br/><div class="children"><div class="content">So from this hacker news title I definitely thought it was saying that when you give some AI agents a self reflection like maybe by putting an internal monologue loop then they unlock an emergent animal-like exploration behavior.<p>But this is not what happened. Instead, some guys told AI agents to explore in the way that the guys think that animals explore. &quot;Stanford researchers invented the “curious replay” training method based on studying mice to help AI agents&quot;</div><br/><div id="36625136" class="c"><input type="checkbox" id="c-36625136" checked=""/><div class="controls bullet"><span class="by">neuronerd1</span><span>|</span><a href="#36623394">parent</a><span>|</span><a href="#36626318">next</a><span>|</span><label class="collapse" for="c-36625136">[-]</label><label class="expand" for="c-36625136">[11 more]</label></div><br/><div class="children"><div class="content">Author here, a key thing is that we didn&#x27;t prescribe that the mechanism of exploration was the same, but rather we found that the AI agent explored poorly (i.e. unlike animals) until we included Curious Replay. Interestingly, we found that the benefits of Curious Replay also led to state of the art performance on Crafter.</div><br/><div id="36625294" class="c"><input type="checkbox" id="c-36625294" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36625136">parent</a><span>|</span><a href="#36625315">next</a><span>|</span><label class="collapse" for="c-36625294">[-]</label><label class="expand" for="c-36625294">[3 more]</label></div><br/><div class="children"><div class="content">OK here is the arxiv <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.15934" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.15934</a> called &quot;Curious Replay for Model-based Adaptation&quot; and from the abstract it says &quot;we present Curious Replay -- a form of prioritized experience replay tailored to model-based agents through use of a curiosity-based priority signal&quot; and &quot;DreamerV3 with Curious Replay surpasses state-of-the-art performance on Crafter&quot; here is the crafter benchmark <a href="https:&#x2F;&#x2F;github.com&#x2F;danijar&#x2F;crafter">https:&#x2F;&#x2F;github.com&#x2F;danijar&#x2F;crafter</a> but it appears to have out of date baselines at the bottom of that page.<p>That arxiv stuff looks perfectly normal but I kind of hate how it got more and more caricatured as it went through the university press office and hacker news clickbait pipeline.</div><br/><div id="36626529" class="c"><input type="checkbox" id="c-36626529" checked=""/><div class="controls bullet"><span class="by">tnecniv</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36625294">parent</a><span>|</span><a href="#36625315">next</a><span>|</span><label class="collapse" for="c-36626529">[-]</label><label class="expand" for="c-36626529">[2 more]</label></div><br/><div class="children"><div class="content">That’s standard. Me and others in my PhD cohort have had experiences where we saw so many minor inaccuracies in the copy we only fixed things that were flat out wrong, otherwise we’d have rewritten the whole article. It’s the result of a combination of non-experts having a 30 minute conversation with you then writing based off their notes a week later and the fact that their job is to hype up research so that it gets more attention from a broader audience. Everyone I knew said they wouldn’t let that happen to them when the press office called, but rewriting someone’s whole article because you feel like they missed nuances is hard to take a strong stance on, especially as an early career researcher.</div><br/><div id="36626652" class="c"><input type="checkbox" id="c-36626652" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36626529">parent</a><span>|</span><a href="#36625315">next</a><span>|</span><label class="collapse" for="c-36626652">[-]</label><label class="expand" for="c-36626652">[1 more]</label></div><br/><div class="children"><div class="content">yes it&#x27;s better now that the hn mods have changed the headline</div><br/></div></div></div></div></div></div><div id="36625315" class="c"><input type="checkbox" id="c-36625315" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36625136">parent</a><span>|</span><a href="#36625294">prev</a><span>|</span><a href="#36625930">next</a><span>|</span><label class="collapse" for="c-36625315">[-]</label><label class="expand" for="c-36625315">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s very cool work.<p>I&#x27;ve been wondering for a while at what the next steps in adding &#x27;inefficiencies&#x27; to AI processing would look like, commenting the other day to a friend that what&#x27;s needed in the next 18 months is getting AI to be able to replicate the Eureka moments in the shower where latent information is reconstructed in parallel to processing tangential topics.<p>Going from &quot;attention is all you need&quot; to &quot;attention and curiosity is what you need&quot; seems like a great next step!</div><br/><div id="36627645" class="c"><input type="checkbox" id="c-36627645" checked=""/><div class="controls bullet"><span class="by">selalipop</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36625315">parent</a><span>|</span><a href="#36625930">next</a><span>|</span><label class="collapse" for="c-36627645">[-]</label><label class="expand" for="c-36627645">[1 more]</label></div><br/><div class="children"><div class="content">&gt; getting AI to be able to replicate the Eureka moments in the shower where latent information is reconstructed in parallel to processing tangential topics.<p>I&#x27;ve been playing with this part specifically and it&#x27;s really amazing stuff.<p>Having the model concurrently model internal monologue and output for a task, but allowing the internal monologue to be as focused or unfocused as the model sees fit.<p>You end up with situations where you have it working on a naming task for example, and the model starts imagining the warmth of a coffee cup on the desk, or traffic building up outside for a future appointment with a non-existent person, and then returns back to the task at hand with non-obvious tangents that it&#x27;d probably never have uncovered if it was only predicting on tokens related to the original goal of naming something.<p>It gets even more interesting when you inject variability into the process via the API (for example, telling it to use certain letters pulled from an RNG inside the next iteration of internal monologue).</div><br/></div></div></div></div><div id="36625930" class="c"><input type="checkbox" id="c-36625930" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36625136">parent</a><span>|</span><a href="#36625315">prev</a><span>|</span><a href="#36625723">next</a><span>|</span><label class="collapse" for="c-36625930">[-]</label><label class="expand" for="c-36625930">[1 more]</label></div><br/><div class="children"><div class="content">Maybe I&#x27;m missing something (I only did a quick read) but aren&#x27;t you explicitly telling the model to re-explore low density regions of the action space? Essentially turning of the exploration (and turning down exploitation) with a weighting towards low density regions?<p>As not an RL person (I&#x27;m in generative), have people not re-increased the exploration variable after the model has been initially trained? It seems natural to vary that ee trade-off.</div><br/></div></div><div id="36625723" class="c"><input type="checkbox" id="c-36625723" checked=""/><div class="controls bullet"><span class="by">hirundo</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36625136">parent</a><span>|</span><a href="#36625930">prev</a><span>|</span><a href="#36626318">next</a><span>|</span><label class="collapse" for="c-36625723">[-]</label><label class="expand" for="c-36625723">[4 more]</label></div><br/><div class="children"><div class="content">Is there a possible Crafter benchmark that is too high for safety? For instance, a number beyond which it would be dangerous to release a well equipped agent into meatspace with the goal of maximizing paperclips?</div><br/><div id="36625775" class="c"><input type="checkbox" id="c-36625775" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36625723">parent</a><span>|</span><a href="#36626207">next</a><span>|</span><label class="collapse" for="c-36625775">[-]</label><label class="expand" for="c-36625775">[1 more]</label></div><br/><div class="children"><div class="content">human level is about 50 and as long as they don&#x27;t allow to craft paperclips i think it&#x27;s ok</div><br/></div></div><div id="36626207" class="c"><input type="checkbox" id="c-36626207" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36625723">parent</a><span>|</span><a href="#36625775">prev</a><span>|</span><a href="#36625761">next</a><span>|</span><label class="collapse" for="c-36626207">[-]</label><label class="expand" for="c-36626207">[1 more]</label></div><br/><div class="children"><div class="content">Dumb machines already kill people for mundane reasons.</div><br/></div></div><div id="36625761" class="c"><input type="checkbox" id="c-36625761" checked=""/><div class="controls bullet"><span class="by">izzygonzalez</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36625723">parent</a><span>|</span><a href="#36626207">prev</a><span>|</span><a href="#36626318">next</a><span>|</span><label class="collapse" for="c-36625761">[-]</label><label class="expand" for="c-36625761">[1 more]</label></div><br/><div class="children"><div class="content">This is absurd.</div><br/></div></div></div></div></div></div><div id="36626318" class="c"><input type="checkbox" id="c-36626318" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#36623394">parent</a><span>|</span><a href="#36625136">prev</a><span>|</span><a href="#36624737">next</a><span>|</span><label class="collapse" for="c-36626318">[-]</label><label class="expand" for="c-36626318">[2 more]</label></div><br/><div class="children"><div class="content">(Submitted title was &quot;“Self-reflecting” AI agents explore like animals&quot;. We changed it in keeping with the HN guidelines - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a>.)</div><br/></div></div><div id="36624737" class="c"><input type="checkbox" id="c-36624737" checked=""/><div class="controls bullet"><span class="by">sva_</span><span>|</span><a href="#36623394">parent</a><span>|</span><a href="#36626318">prev</a><span>|</span><a href="#36624938">next</a><span>|</span><label class="collapse" for="c-36624737">[-]</label><label class="expand" for="c-36624737">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Instead, some guys told AI agents to explore in the way that the guys think that animals explore.<p>Something, something, The Bitter Lesson.</div><br/></div></div><div id="36624938" class="c"><input type="checkbox" id="c-36624938" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36623394">parent</a><span>|</span><a href="#36624737">prev</a><span>|</span><a href="#36624973">next</a><span>|</span><label class="collapse" for="c-36624938">[-]</label><label class="expand" for="c-36624938">[3 more]</label></div><br/><div class="children"><div class="content">I hate that titles can differ from the article here. It’s patronizing and commonly inaccurate or misleading.</div><br/><div id="36625567" class="c"><input type="checkbox" id="c-36625567" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36624938">parent</a><span>|</span><a href="#36625509">next</a><span>|</span><label class="collapse" for="c-36625567">[-]</label><label class="expand" for="c-36625567">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t like the misleading titles either, but honestly if you want the real titles you probably want some kind of arxiv feed. The paper title is &quot;Curious Replay for Model-based Adaptation&quot; which is too dry for social media or whatever hacker news is or for whoever is the audience of the stanford university press office. You have to expect more juicy (and therefore somewhat misleading or sensationalized) titles if you don&#x27;t get your news straight from an arxiv feed.</div><br/></div></div><div id="36625509" class="c"><input type="checkbox" id="c-36625509" checked=""/><div class="controls bullet"><span class="by">lcnPylGDnU4H9OF</span><span>|</span><a href="#36623394">root</a><span>|</span><a href="#36624938">parent</a><span>|</span><a href="#36625567">prev</a><span>|</span><a href="#36624973">next</a><span>|</span><label class="collapse" for="c-36625509">[-]</label><label class="expand" for="c-36625509">[1 more]</label></div><br/><div class="children"><div class="content">“Patronizing” seems to be a matter of taste. I’ve never considered it to be patronizing; indeed, that’s often much unlike articles which have their title changed.<p>As far as simply differing, much of the time there’s a character limit that’s hit. I’ve seen many posts with comment from the poster calling out their edit to the title and the character limit is usually cited.<p>It would be especially difficult to keep the character limit (I think there are legitimate design reasons for this) while also requiring that the title matches the submission as closely as possible. Who decides what words are omitted without it potentially being any of: patronizing, inaccurate, or misleading?</div><br/></div></div></div></div></div></div><div id="36628845" class="c"><input type="checkbox" id="c-36628845" checked=""/><div class="controls bullet"><span class="by">sethammons</span><span>|</span><a href="#36623394">prev</a><span>|</span><a href="#36623870">next</a><span>|</span><label class="collapse" for="c-36628845">[-]</label><label class="expand" for="c-36628845">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not an AI expert or even novice nor am I a neuroscientist, but I have been thinking about how I interact with the world.<p>My current imagining says that novelty and unexpected inputs drive our immediate understanding of the world around us. To have expectations you have to have to have a model. When that model breaks and is adjusted you have a novel experience and the model can be updated. This feedback loop is critical.<p>Example: other day I was grilling food and my digital food thermometer was on the metal prep area near the hot griddle. As I was walking away I reached for it, grabbed it, and expected to pick it up. However! I didn&#x27;t know it had a magnet and it gave me back unexpected stimulus.<p>I immediately jerked my hand away and several thoughts happened near instantly. My thoughts went from I burned my hand to no, no pain, maybe a really bad burn, to no, no heat, no sizzling of flesh, to oops, wrong stimulus, something resisted, resisted how, it slid but wouldn&#x27;t pick up easy, ah, a magnet.<p>The researchers here are right, I expect. You need curiosity and some goal, but you need to constantly tune the input for expectations and tweak the (mental) model of the world.<p>How many times do you, for a split second, totally misinterpret what you see or feel but near instantly self correct? Better AI will require putting forth it&#x27;s initial result and then validating the result with feedback. The more unexpected the feedback the more novel the experience and more learning that can happen.</div><br/></div></div><div id="36623870" class="c"><input type="checkbox" id="c-36623870" checked=""/><div class="controls bullet"><span class="by">xianshou</span><span>|</span><a href="#36628845">prev</a><span>|</span><a href="#36623411">next</a><span>|</span><label class="collapse" for="c-36623870">[-]</label><label class="expand" for="c-36623870">[1 more]</label></div><br/><div class="children"><div class="content">The result is mildly interesting - improvement on an isolated task but none on the full benchmark - but what would be much more compelling is curiosity-driven replay in an LLM context combined with chain- or tree-of-thought techniques. This would be the machine analogy to noticing your confusion, a sort of &quot;what do I need to know&quot; or &quot;what am I overlooking&quot;? Anecdotally, language models perform better when you prompt them to ask their own questions in the process of answering yours, so I would expect curiosity to have a meaningful impact.</div><br/></div></div><div id="36623411" class="c"><input type="checkbox" id="c-36623411" checked=""/><div class="controls bullet"><span class="by">piyh</span><span>|</span><a href="#36623870">prev</a><span>|</span><a href="#36626607">next</a><span>|</span><label class="collapse" for="c-36623411">[-]</label><label class="expand" for="c-36623411">[2 more]</label></div><br/><div class="children"><div class="content">Direct arxiv link:
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2306.15934.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2306.15934.pdf</a></div><br/><div id="36626196" class="c"><input type="checkbox" id="c-36626196" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#36623411">parent</a><span>|</span><a href="#36626607">next</a><span>|</span><label class="collapse" for="c-36626196">[-]</label><label class="expand" for="c-36626196">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.semanticscholar.org&#x2F;paper&#x2F;Curious-Replay-for-Model-based-Adaptation-Kauvar-Doyle&#x2F;bd09f1477ff5ea1fe1b9ea57a0272978844ee6ad" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.semanticscholar.org&#x2F;paper&#x2F;Curious-Replay-for-Mod...</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;AutonomousAgentsLab&#x2F;curiousreplay">https:&#x2F;&#x2F;github.com&#x2F;AutonomousAgentsLab&#x2F;curiousreplay</a></div><br/></div></div></div></div><div id="36626607" class="c"><input type="checkbox" id="c-36626607" checked=""/><div class="controls bullet"><span class="by">martyvis</span><span>|</span><a href="#36623411">prev</a><span>|</span><a href="#36627840">next</a><span>|</span><label class="collapse" for="c-36626607">[-]</label><label class="expand" for="c-36626607">[2 more]</label></div><br/><div class="children"><div class="content">And here I am halfway through Michael Crichton&#x27;s novel &quot;Prey&quot; ...</div><br/><div id="36627904" class="c"><input type="checkbox" id="c-36627904" checked=""/><div class="controls bullet"><span class="by">lannisterstark</span><span>|</span><a href="#36626607">parent</a><span>|</span><a href="#36627840">next</a><span>|</span><label class="collapse" for="c-36627904">[-]</label><label class="expand" for="c-36627904">[1 more]</label></div><br/><div class="children"><div class="content">Huh. Looks interesting but I have a weird feeling it might be the same old sappy boring thriller. Opinions so far?</div><br/></div></div></div></div><div id="36627840" class="c"><input type="checkbox" id="c-36627840" checked=""/><div class="controls bullet"><span class="by">axiom92</span><span>|</span><a href="#36626607">prev</a><span>|</span><a href="#36627406">next</a><span>|</span><label class="collapse" for="c-36627840">[-]</label><label class="expand" for="c-36627840">[1 more]</label></div><br/><div class="children"><div class="content">Some of our recent&#x2F;relevant work: <a href="https:&#x2F;&#x2F;selfrefine.info&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;selfrefine.info&#x2F;</a></div><br/></div></div><div id="36627406" class="c"><input type="checkbox" id="c-36627406" checked=""/><div class="controls bullet"><span class="by">ano88888</span><span>|</span><a href="#36627840">prev</a><span>|</span><a href="#36628679">next</a><span>|</span><label class="collapse" for="c-36627406">[-]</label><label class="expand" for="c-36627406">[1 more]</label></div><br/><div class="children"><div class="content">humans need to do self reflection too. It is usually in the form of journaling daily for self reflection</div><br/></div></div><div id="36628679" class="c"><input type="checkbox" id="c-36628679" checked=""/><div class="controls bullet"><span class="by">ly3xqhl8g9</span><span>|</span><a href="#36627406">prev</a><span>|</span><a href="#36625307">next</a><span>|</span><label class="collapse" for="c-36628679">[-]</label><label class="expand" for="c-36628679">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps one would drop the quotes around self-reflect if one would implement something more akin to a Markov blanket [1], blankets within blankets, model ourselves modelling the world.<p>[1] 2018, &quot;The Markov blankets of life: autonomy, active inference and the free energy principle&quot;, <a href="https:&#x2F;&#x2F;royalsocietypublishing.org&#x2F;doi&#x2F;10.1098&#x2F;rsif.2017.0792" rel="nofollow noreferrer">https:&#x2F;&#x2F;royalsocietypublishing.org&#x2F;doi&#x2F;10.1098&#x2F;rsif.2017.079...</a></div><br/></div></div><div id="36625307" class="c"><input type="checkbox" id="c-36625307" checked=""/><div class="controls bullet"><span class="by">Schnitzkitz</span><span>|</span><a href="#36628679">prev</a><span>|</span><a href="#36625938">next</a><span>|</span><label class="collapse" for="c-36625307">[-]</label><label class="expand" for="c-36625307">[7 more]</label></div><br/><div class="children"><div class="content">Makes sense. AI lacks rationality, and animals lack rationality. Of course, humans are the rational animal, and hence we know when we truly understand things or when we just repeat or spitball.</div><br/><div id="36625685" class="c"><input type="checkbox" id="c-36625685" checked=""/><div class="controls bullet"><span class="by">mandmandam</span><span>|</span><a href="#36625307">parent</a><span>|</span><a href="#36625938">next</a><span>|</span><label class="collapse" for="c-36625685">[-]</label><label class="expand" for="c-36625685">[6 more]</label></div><br/><div class="children"><div class="content">Nah, not really.<p>History has been repeating itself for thousands of years. We keep killing the prophets, and putting the absolute worst of us on pedestals. What&#x27;s rational about that?<p>Dolphins mucking about in the water - <i>that&#x27;s</i> rational.</div><br/><div id="36626329" class="c"><input type="checkbox" id="c-36626329" checked=""/><div class="controls bullet"><span class="by">Art9681</span><span>|</span><a href="#36625307">root</a><span>|</span><a href="#36625685">parent</a><span>|</span><a href="#36625804">next</a><span>|</span><label class="collapse" for="c-36626329">[-]</label><label class="expand" for="c-36626329">[1 more]</label></div><br/><div class="children"><div class="content">Individuals are a completely different organism than groups, and groups than societies, and societies than...<p>You hopefully get the picture. We may get better at remembering history if united via a common cause under a common leadership. Otherwise it&#x27;s just an organism looking for food and trying to survive.</div><br/></div></div><div id="36625804" class="c"><input type="checkbox" id="c-36625804" checked=""/><div class="controls bullet"><span class="by">Schnitzkitz</span><span>|</span><a href="#36625307">root</a><span>|</span><a href="#36625685">parent</a><span>|</span><a href="#36626329">prev</a><span>|</span><a href="#36625938">next</a><span>|</span><label class="collapse" for="c-36625804">[-]</label><label class="expand" for="c-36625804">[4 more]</label></div><br/><div class="children"><div class="content">By pointing to rational or moral failures, you already imply that we are supposed to act in a certain way. If there are people who are the worst, it begs the question of what a good human is, and who or what we should actually follow. Clearly, we don&#x27;t think that raw power is what makes someone good, because otherwise these worst people on the pedestals would be by default good people, through all the power they have over their followers.<p>If it is irrational that history repeats itself, do you think that it would be rational if history progressed towards some goal, and if yes, what is that goal?</div><br/><div id="36626039" class="c"><input type="checkbox" id="c-36626039" checked=""/><div class="controls bullet"><span class="by">mandmandam</span><span>|</span><a href="#36625307">root</a><span>|</span><a href="#36625804">parent</a><span>|</span><a href="#36625938">next</a><span>|</span><label class="collapse" for="c-36626039">[-]</label><label class="expand" for="c-36626039">[3 more]</label></div><br/><div class="children"><div class="content">&gt; By pointing to rational or moral failures, you already imply that we are supposed to act in a certain way.<p>Don&#x27;t keep such an open mind that your brain falls out.<p>&gt; If it is irrational that history repeats itself, do you think that it would be rational if history progressed towards some goal<p>It has, often. For example, 50 years ago a bunch of  fossil fuel executives decided it would be best to let the planet burn, so they can keep making money.<p>History progressed toward their goal, and now we&#x27;re starting to really suffer. But they have their megayachts.<p>Do <i>you</i> think that&#x27;s rational?</div><br/><div id="36627609" class="c"><input type="checkbox" id="c-36627609" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#36625307">root</a><span>|</span><a href="#36626039">parent</a><span>|</span><a href="#36627283">next</a><span>|</span><label class="collapse" for="c-36627609">[-]</label><label class="expand" for="c-36627609">[1 more]</label></div><br/><div class="children"><div class="content">This is a major question in philosophy, not just some random aside in an HN comment thread.<p>Most famously, Hegel believed that human history trends &amp; tends towards the perfection of human nature and society. Many other philosophers and philosophies fundamentally disagree with Hegel, and assert that history has no teleological purpose built into it.<p>Perhaps acknowledge the depth and history of this question before throwing out some quick asides about it?</div><br/></div></div><div id="36627283" class="c"><input type="checkbox" id="c-36627283" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#36625307">root</a><span>|</span><a href="#36626039">parent</a><span>|</span><a href="#36627609">prev</a><span>|</span><a href="#36625938">next</a><span>|</span><label class="collapse" for="c-36627283">[-]</label><label class="expand" for="c-36627283">[1 more]</label></div><br/><div class="children"><div class="content">Rationality, and by extension rationalism, refuses to investigate the question of whether the axiomatic assumptions upon which the rational conclusions are based are valid.<p>So of course superyachts are perfectly rational. But of course they are far from <i>reasonable</i>.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36625938" class="c"><input type="checkbox" id="c-36625938" checked=""/><div class="controls bullet"><span class="by">riwsky</span><span>|</span><a href="#36625307">prev</a><span>|</span><a href="#36623439">next</a><span>|</span><label class="collapse" for="c-36625938">[-]</label><label class="expand" for="c-36625938">[1 more]</label></div><br/><div class="children"><div class="content">How does this differ from existing approaches that just follow the entropy?</div><br/></div></div><div id="36623439" class="c"><input type="checkbox" id="c-36623439" checked=""/><div class="controls bullet"><span class="by">FrustratedMonky</span><span>|</span><a href="#36625938">prev</a><span>|</span><a href="#36624217">next</a><span>|</span><label class="collapse" for="c-36623439">[-]</label><label class="expand" for="c-36623439">[1 more]</label></div><br/><div class="children"><div class="content">Exactly.
We keep leaving out &#x27;motivation&#x27; on these models.
Since they are reacting to prompts.
But put them on a loop with goals and see what happens.<p>And, things like GPT are not &#x27;embodied&#x27;, since they don&#x27;t live in the &#x27;world&#x27; they can&#x27;t associate language with physical reality.  Put them in a simulated environment like a game, and it looks a lot more &#x27;conscious&#x27;.</div><br/></div></div><div id="36624217" class="c"><input type="checkbox" id="c-36624217" checked=""/><div class="controls bullet"><span class="by">jjtheblunt</span><span>|</span><a href="#36623439">prev</a><span>|</span><label class="collapse" for="c-36624217">[-]</label><label class="expand" for="c-36624217">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s kind of interesting how increasingly frequently &quot;stanford.edu&quot; is finding its way into HN submissions, and did the increasing frequency start with the GPT-4 enthusiasm?<p>is that coincidence?</div><br/></div></div></div></div></div></div></div></body></html>