<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706518866943" as="style"/><link rel="stylesheet" href="styles.css?v=1706518866943"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://duckdb.org/2024/01/26/multi-database-support-in-duckdb.html">Multi-database support in DuckDB</a> <span class="domain">(<a href="https://duckdb.org">duckdb.org</a>)</span></div><div class="subtext"><span>nalgeon</span> | <span>30 comments</span></div><br/><div><div id="39171598" class="c"><input type="checkbox" id="c-39171598" checked=""/><div class="controls bullet"><span class="by">atombender</span><span>|</span><a href="#39171691">next</a><span>|</span><label class="collapse" for="c-39171598">[-]</label><label class="expand" for="c-39171598">[3 more]</label></div><br/><div class="children"><div class="content">Very cool. I wonder if the pluggable storage engine also supports query pushdown.<p>For example, if you do SELECT ... FROM mytable WHERE key = 42, then if this is a Postgres table, you want the key predicate to be pushed down to Postgres so you don&#x27;t need to scan the whole table. Same for ORDER BY, joins, LIMIT, OFFSET. For joins between foreign tables from different sources, you&#x27;d want the optimizer to be aware of table&#x2F;column stats in order to pick the right join strategy.<p>Sqlite has a &quot;virtual table&quot; mechanism where you can plug in your own engine. But it&#x27;s relatively simplistic when it comes to pushdown.</div><br/><div id="39173461" class="c"><input type="checkbox" id="c-39173461" checked=""/><div class="controls bullet"><span class="by">maxxen</span><span>|</span><a href="#39171598">parent</a><span>|</span><a href="#39172862">next</a><span>|</span><label class="collapse" for="c-39173461">[-]</label><label class="expand" for="c-39173461">[1 more]</label></div><br/><div class="children"><div class="content">It does push down filters! Not sure if other nodes are pushed down, I think for now the database boundary is at the scan node, but you could add additional optimizer&#x2F;rewrite rules in the postgres&#x2F;sqlite&#x2F;mysql extensions to push down other parts of the plans when applicable.</div><br/></div></div><div id="39172862" class="c"><input type="checkbox" id="c-39172862" checked=""/><div class="controls bullet"><span class="by">zacblanco</span><span>|</span><a href="#39171598">parent</a><span>|</span><a href="#39173461">prev</a><span>|</span><a href="#39171691">next</a><span>|</span><label class="collapse" for="c-39172862">[-]</label><label class="expand" for="c-39172862">[1 more]</label></div><br/><div class="children"><div class="content">We have some of this functionality in Presto (<a href="https:&#x2F;&#x2F;github.com&#x2F;prestodb&#x2F;presto">https:&#x2F;&#x2F;github.com&#x2F;prestodb&#x2F;presto</a>), but it takes fair bit of work to implement it for all the different backends.</div><br/></div></div></div></div><div id="39171691" class="c"><input type="checkbox" id="c-39171691" checked=""/><div class="controls bullet"><span class="by">fbdab103</span><span>|</span><a href="#39171598">prev</a><span>|</span><a href="#39172912">next</a><span>|</span><label class="collapse" for="c-39171691">[-]</label><label class="expand" for="c-39171691">[2 more]</label></div><br/><div class="children"><div class="content">How big is the DuckDB team? I am blown away at the quality of life improvements they keep bringing into the project.</div><br/><div id="39173538" class="c"><input type="checkbox" id="c-39173538" checked=""/><div class="controls bullet"><span class="by">maxxen</span><span>|</span><a href="#39171691">parent</a><span>|</span><a href="#39172912">next</a><span>|</span><label class="collapse" for="c-39173538">[-]</label><label class="expand" for="c-39173538">[1 more]</label></div><br/><div class="children"><div class="content">We’re currently 16~ software engineers at DuckDB Labs! I think its a good size to be productive but also stay nimble.</div><br/></div></div></div></div><div id="39172912" class="c"><input type="checkbox" id="c-39172912" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#39171691">prev</a><span>|</span><a href="#39171447">next</a><span>|</span><label class="collapse" for="c-39172912">[-]</label><label class="expand" for="c-39172912">[1 more]</label></div><br/><div class="children"><div class="content">Fantastic!<p>If Kuzu and LanceDB are added we could have a perfect way of dealing with graphs, vector, and tables all together in one ecosystem.  Honestly may be worthy of a thin wrapper project around those.<p>They would work so incredibly well together to free people from the horrible corporate &quot;cloud&quot; mess&#x2F;B&#x27;s everyone keeps trying to push.</div><br/></div></div><div id="39171447" class="c"><input type="checkbox" id="c-39171447" checked=""/><div class="controls bullet"><span class="by">alextheparrot</span><span>|</span><a href="#39172912">prev</a><span>|</span><a href="#39173894">next</a><span>|</span><label class="collapse" for="c-39171447">[-]</label><label class="expand" for="c-39171447">[6 more]</label></div><br/><div class="children"><div class="content">Exactly what I want from DuckDB.  Was playing with using it as a quicker cache for a data app backed in Snowflake, wonder how hard it’d be to write the attach for that vs doing it at the client level</div><br/><div id="39171690" class="c"><input type="checkbox" id="c-39171690" checked=""/><div class="controls bullet"><span class="by">buremba</span><span>|</span><a href="#39171447">parent</a><span>|</span><a href="#39173894">next</a><span>|</span><label class="collapse" for="c-39171690">[-]</label><label class="expand" for="c-39171690">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m waiting for them to support BigQuery and Snowflake with the same pushdown capabilities. Hope it doesn&#x27;t end up in their cloud offering!</div><br/><div id="39172497" class="c"><input type="checkbox" id="c-39172497" checked=""/><div class="controls bullet"><span class="by">izyda</span><span>|</span><a href="#39171447">root</a><span>|</span><a href="#39171690">parent</a><span>|</span><a href="#39173894">next</a><span>|</span><label class="collapse" for="c-39172497">[-]</label><label class="expand" for="c-39172497">[4 more]</label></div><br/><div class="children"><div class="content">I have been wondering how to support interactive &#x2F; real-time web apps based on Snowflake data. I suppose pushing down to DuckDB a subset of data needed for a chart would be one way to do this...</div><br/><div id="39172801" class="c"><input type="checkbox" id="c-39172801" checked=""/><div class="controls bullet"><span class="by">hipadev23</span><span>|</span><a href="#39171447">root</a><span>|</span><a href="#39172497">parent</a><span>|</span><a href="#39173894">next</a><span>|</span><label class="collapse" for="c-39172801">[-]</label><label class="expand" for="c-39172801">[3 more]</label></div><br/><div class="children"><div class="content">If you’re pushing down the data, you’re losing the real-time capability no?<p>If you want fast, adhoc, real-time querying, load the data as it’s created directly into duckdb or clickhouse. Now you’ll have sub-100ms responses for most of your queries.</div><br/><div id="39172906" class="c"><input type="checkbox" id="c-39172906" checked=""/><div class="controls bullet"><span class="by">alextheparrot</span><span>|</span><a href="#39171447">root</a><span>|</span><a href="#39172801">parent</a><span>|</span><a href="#39173894">next</a><span>|</span><label class="collapse" for="c-39172906">[-]</label><label class="expand" for="c-39172906">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d assume they mean users interacting with the chart vs first load.  So the user sees the base chart (Let&#x27;s say 1MB of data on the server, less depending what gets pushed to the user) and then additional filters, aggregations, etc. are pretty cheap because the server has a local copy to query against</div><br/><div id="39172978" class="c"><input type="checkbox" id="c-39172978" checked=""/><div class="controls bullet"><span class="by">izyda</span><span>|</span><a href="#39171447">root</a><span>|</span><a href="#39172906">parent</a><span>|</span><a href="#39173894">next</a><span>|</span><label class="collapse" for="c-39172978">[-]</label><label class="expand" for="c-39172978">[1 more]</label></div><br/><div class="children"><div class="content">Yes -- sorry, I meant exactly the above.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39173894" class="c"><input type="checkbox" id="c-39173894" checked=""/><div class="controls bullet"><span class="by">oulipo</span><span>|</span><a href="#39171447">prev</a><span>|</span><a href="#39172025">next</a><span>|</span><label class="collapse" for="c-39173894">[-]</label><label class="expand" for="c-39173894">[1 more]</label></div><br/><div class="children"><div class="content">I guess this should allow to connect duckdb to a BigQuery instance since there is a Postgres compatibility layer?</div><br/></div></div><div id="39172025" class="c"><input type="checkbox" id="c-39172025" checked=""/><div class="controls bullet"><span class="by">seanlaff</span><span>|</span><a href="#39173894">prev</a><span>|</span><a href="#39171774">next</a><span>|</span><label class="collapse" for="c-39172025">[-]</label><label class="expand" for="c-39172025">[1 more]</label></div><br/><div class="children"><div class="content">Does duckdb support remote-duckdb as a storage engine? Seems like a way to support distributed duckdbs. Ducks all the way down? :)</div><br/></div></div><div id="39171774" class="c"><input type="checkbox" id="c-39171774" checked=""/><div class="controls bullet"><span class="by">nitinreddy88</span><span>|</span><a href="#39172025">prev</a><span>|</span><a href="#39171785">next</a><span>|</span><label class="collapse" for="c-39171774">[-]</label><label class="expand" for="c-39171774">[9 more]</label></div><br/><div class="children"><div class="content">I wish if there&#x27;s a way we can hook DuckDB as Extension to Postgres itself.
Currently there&#x27;s no proper columnar database&#x2F;extension exist in PG. In most of the use cases, one doesn&#x27;t really require dedicated &quot;analytics&quot; only DB and sometimes everything has to be done through &quot;Primary DB&quot; (typically in enterprise products world).<p>By hooking DuckDB as Extension, we get best of both of worlds from PG and DuckDB while retaining the persistence and analytical capabilities without hosting yet another DB infrastructure.</div><br/><div id="39173491" class="c"><input type="checkbox" id="c-39173491" checked=""/><div class="controls bullet"><span class="by">ako</span><span>|</span><a href="#39171774">parent</a><span>|</span><a href="#39171992">next</a><span>|</span><label class="collapse" for="c-39173491">[-]</label><label class="expand" for="c-39173491">[1 more]</label></div><br/><div class="children"><div class="content">Wouldn’t you still miss the part about storing tables column based in your database rather than row based? Would be nice to have “create table” or “create materialized” view with columnar storage option.</div><br/></div></div><div id="39171992" class="c"><input type="checkbox" id="c-39171992" checked=""/><div class="controls bullet"><span class="by">wenc</span><span>|</span><a href="#39171774">parent</a><span>|</span><a href="#39173491">prev</a><span>|</span><a href="#39171800">next</a><span>|</span><label class="collapse" for="c-39171992">[-]</label><label class="expand" for="c-39171992">[5 more]</label></div><br/><div class="children"><div class="content">Seems like someone has tried it:<p><a href="https:&#x2F;&#x2F;medium.com&#x2F;@ahuarte&#x2F;loading-parquet-in-postgresql-via-duckdb-testing-queries-and-exploring-the-core-1d667ae67dc2" rel="nofollow">https:&#x2F;&#x2F;medium.com&#x2F;@ahuarte&#x2F;loading-parquet-in-postgresql-vi...</a></div><br/><div id="39172178" class="c"><input type="checkbox" id="c-39172178" checked=""/><div class="controls bullet"><span class="by">nitinreddy88</span><span>|</span><a href="#39171774">root</a><span>|</span><a href="#39171992">parent</a><span>|</span><a href="#39171800">next</a><span>|</span><label class="collapse" for="c-39172178">[-]</label><label class="expand" for="c-39172178">[4 more]</label></div><br/><div class="children"><div class="content">Now we need to write parquet files from Postgres. Its essentially what do we need to do for end to end solution with PG by leveraging extensions</div><br/><div id="39173209" class="c"><input type="checkbox" id="c-39173209" checked=""/><div class="controls bullet"><span class="by">ibotty</span><span>|</span><a href="#39171774">root</a><span>|</span><a href="#39172178">parent</a><span>|</span><a href="#39172245">next</a><span>|</span><label class="collapse" for="c-39173209">[-]</label><label class="expand" for="c-39173209">[1 more]</label></div><br/><div class="children"><div class="content">This can be done using duckdb_fdw.  It needs one additional copy though.<p>You insert into the duckdb table and then export from duckdb using duckdb_execute.</div><br/></div></div><div id="39172245" class="c"><input type="checkbox" id="c-39172245" checked=""/><div class="controls bullet"><span class="by">tehlike</span><span>|</span><a href="#39171774">root</a><span>|</span><a href="#39172178">parent</a><span>|</span><a href="#39173209">prev</a><span>|</span><a href="#39171800">next</a><span>|</span><label class="collapse" for="c-39172245">[-]</label><label class="expand" for="c-39172245">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;adjust&#x2F;parquet_fdw">https:&#x2F;&#x2F;github.com&#x2F;adjust&#x2F;parquet_fdw</a></div><br/><div id="39172621" class="c"><input type="checkbox" id="c-39172621" checked=""/><div class="controls bullet"><span class="by">nitinreddy88</span><span>|</span><a href="#39171774">root</a><span>|</span><a href="#39172245">parent</a><span>|</span><a href="#39171800">next</a><span>|</span><label class="collapse" for="c-39172621">[-]</label><label class="expand" for="c-39172621">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t support writing data. One has to hookup worker to write data efficiently to parquet on regular basis or some fashion using PG. Its like bits and pieces everywhere but didnt create end to end usecase</div><br/></div></div></div></div></div></div></div></div><div id="39171800" class="c"><input type="checkbox" id="c-39171800" checked=""/><div class="controls bullet"><span class="by">tehlike</span><span>|</span><a href="#39171774">parent</a><span>|</span><a href="#39171992">prev</a><span>|</span><a href="#39172051">next</a><span>|</span><label class="collapse" for="c-39171800">[-]</label><label class="expand" for="c-39171800">[1 more]</label></div><br/><div class="children"><div class="content">+1. I checked Citus, hydra, etc, and nothing comes close, all has its restrictions or gotchas.<p>I also really want to have a LSM based storage engine, but noone implemented it yet. 
Yugabyte built a postgres compatible database, but it has some management-related stuff not opensource... Cockroach similarly...</div><br/></div></div><div id="39172051" class="c"><input type="checkbox" id="c-39172051" checked=""/><div class="controls bullet"><span class="by">nattaylor</span><span>|</span><a href="#39171774">parent</a><span>|</span><a href="#39171800">prev</a><span>|</span><a href="#39171785">next</a><span>|</span><label class="collapse" for="c-39172051">[-]</label><label class="expand" for="c-39172051">[1 more]</label></div><br/><div class="children"><div class="content">pg_analytics looks promising here <a href="https:&#x2F;&#x2F;github.com&#x2F;paradedb&#x2F;paradedb&#x2F;tree&#x2F;dev&#x2F;pg_analytics">https:&#x2F;&#x2F;github.com&#x2F;paradedb&#x2F;paradedb&#x2F;tree&#x2F;dev&#x2F;pg_analytics</a></div><br/></div></div></div></div><div id="39171785" class="c"><input type="checkbox" id="c-39171785" checked=""/><div class="controls bullet"><span class="by">totalhack</span><span>|</span><a href="#39171774">prev</a><span>|</span><a href="#39173529">next</a><span>|</span><label class="collapse" for="c-39171785">[-]</label><label class="expand" for="c-39171785">[1 more]</label></div><br/><div class="children"><div class="content">What are the performance implications, if any? I assume it&#x27;s just translating queries as needed into the database engine language, in which case I wouldn&#x27;t expect much of a performance issue.</div><br/></div></div><div id="39173529" class="c"><input type="checkbox" id="c-39173529" checked=""/><div class="controls bullet"><span class="by">fithisux</span><span>|</span><a href="#39171785">prev</a><span>|</span><a href="#39171876">next</a><span>|</span><label class="collapse" for="c-39173529">[-]</label><label class="expand" for="c-39173529">[1 more]</label></div><br/><div class="children"><div class="content">I also wait for their spark emulation too.</div><br/></div></div><div id="39171876" class="c"><input type="checkbox" id="c-39171876" checked=""/><div class="controls bullet"><span class="by">jgalt212</span><span>|</span><a href="#39173529">prev</a><span>|</span><label class="collapse" for="c-39171876">[-]</label><label class="expand" for="c-39171876">[4 more]</label></div><br/><div class="children"><div class="content">Can someone provide an example of where someone is using some other tech, but when you get to X records, or Y columns, and Z sorts of queries it makes sense to switch from MySQL&#x2F;SQLite&#x2F;PostGres&#x2F;etc to DuckDB?</div><br/><div id="39172281" class="c"><input type="checkbox" id="c-39172281" checked=""/><div class="controls bullet"><span class="by">wild_egg</span><span>|</span><a href="#39171876">parent</a><span>|</span><a href="#39173172">next</a><span>|</span><label class="collapse" for="c-39172281">[-]</label><label class="expand" for="c-39172281">[1 more]</label></div><br/><div class="children"><div class="content">You generally wouldn&#x27;t &quot;switch&quot; from one to the other, they&#x27;d be used in concert for different purposes<p>MySQL&#x2F;SQLite&#x2F;PostGres fall under the &quot;transactional&quot; database category and others like DuckDB, Redshift, or Clickhouse are considered &quot;analytical&quot; ones and are meant for aggregating large volumes of data<p>It&#x27;s a pretty deep topic so searching for something like &quot;OLTP vs OLAP databases&quot; will give you a lot of reading material</div><br/></div></div><div id="39173172" class="c"><input type="checkbox" id="c-39173172" checked=""/><div class="controls bullet"><span class="by">twotwotwo</span><span>|</span><a href="#39171876">parent</a><span>|</span><a href="#39172281">prev</a><span>|</span><a href="#39172994">next</a><span>|</span><label class="collapse" for="c-39173172">[-]</label><label class="expand" for="c-39173172">[1 more]</label></div><br/><div class="children"><div class="content">Other replies are also right--this is in a family of analytics databases that are unusable for single-row transactions but great at reporting over large amounts of data.<p>The other tool with a similar focus on querying data where&#x2F;how it is Trino. (Trino is the engine underlying Amazon Athena. Trino was initially released as Presto, which is now the less-active side of a fork; most of the project founders work on Trino.) ClickHouse, Redshift, and Snowflake are slightly different analytics tools more focused on querying data stored their own way.<p>Common themes across the whole family include storing each column of data separately, compressed in large (&gt;=1MB) blocks, often using &#x27;min-max&#x27; indices or other types of index that just allow skipping whole irrelevant blocks, not finding individual entries. Even data not in a columnar format is still compressed, minimally &#x27;indexed&#x27; (maybe just partitioned by month), and more compact than it typically is in an OLTP DB.<p>Also, while something like MySQL wants a server to serve many concurrent transactions so would rather avoid a single query using lots of cores and RAM, these analytics DBs are happy to use lots of resources for a short burst.<p>Combining all the above, I&#x27;ve seen this family of database chew through reporting tasks in seconds that take minutes on a well-provisioned MySQL node.<p>Compared to the others, DuckDB lives in a host process you provide and does not itself do multi-node deployments. However, nodes get pretty big, and the columnar tricks pack data down tight, so (as much as in OLTP-land or, likely, more) you shouldn&#x27;t underestimate what one node is capable of doing!</div><br/></div></div><div id="39172994" class="c"><input type="checkbox" id="c-39172994" checked=""/><div class="controls bullet"><span class="by">corasaurus-hex</span><span>|</span><a href="#39171876">parent</a><span>|</span><a href="#39173172">prev</a><span>|</span><label class="collapse" for="c-39172994">[-]</label><label class="expand" for="c-39172994">[1 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t really fully get the advantages of columnar stores until I read this (which won&#x27;t load for me right now but it&#x27;s on wayback machine): <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230603123119&#x2F;https:&#x2F;&#x2F;www.the-paper-trail.org&#x2F;post&#x2F;2013-01-30-columnar-storage&#x2F;" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230603123119&#x2F;https:&#x2F;&#x2F;www.the-p...</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>