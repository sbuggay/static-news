<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1709974863926" as="style"/><link rel="stylesheet" href="styles.css?v=1709974863926"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Launch HN: Relari (YC W24) – Identify the root cause of problems in LLM apps</a> </div><div class="subtext"><span>antonap</span> | <span>14 comments</span></div><br/><div><div id="39641803" class="c"><input type="checkbox" id="c-39641803" checked=""/><div class="controls bullet"><span class="by">atomon</span><span>|</span><a href="#39642521">next</a><span>|</span><label class="collapse" for="c-39641803">[-]</label><label class="expand" for="c-39641803">[2 more]</label></div><br/><div class="children"><div class="content">This looks very cool, will try it out on my next project.<p>There have been a number of solutions popping up to address this problem, and I think the need is very real. Decomposing these LLM tasks into subtasks seems to be one of the best ways to work around the shortcomings of LLMs in production apps (hallucinations, context window limits, etc). But then you end up with complicated pipelines that are difficult to debug, improve, reason about, etc.</div><br/><div id="39642667" class="c"><input type="checkbox" id="c-39642667" checked=""/><div class="controls bullet"><span class="by">antonap</span><span>|</span><a href="#39641803">parent</a><span>|</span><a href="#39642521">next</a><span>|</span><label class="collapse" for="c-39642667">[-]</label><label class="expand" for="c-39642667">[1 more]</label></div><br/><div class="children"><div class="content">Indeed - decomposition improves reliability but also makes the testing more challenging. That’s why we made the framework modular! Let us know of any feedback as you try it out!</div><br/></div></div></div></div><div id="39642521" class="c"><input type="checkbox" id="c-39642521" checked=""/><div class="controls bullet"><span class="by">petervandijck</span><span>|</span><a href="#39641803">prev</a><span>|</span><a href="#39642193">next</a><span>|</span><label class="collapse" for="c-39642521">[-]</label><label class="expand" for="c-39642521">[2 more]</label></div><br/><div class="children"><div class="content">Love that you&#x27;re tackling this and congrats on the launch.<p>Feedback: the synthetic data demo shows nicely what that piece does, but the page is really messy, it would be nice to have that demo cleanly on a dedicated page: <a href="https:&#x2F;&#x2F;www.relari.ai&#x2F;#synthetic_data_demo" rel="nofollow">https:&#x2F;&#x2F;www.relari.ai&#x2F;#synthetic_data_demo</a></div><br/><div id="39642689" class="c"><input type="checkbox" id="c-39642689" checked=""/><div class="controls bullet"><span class="by">antonap</span><span>|</span><a href="#39642521">parent</a><span>|</span><a href="#39642193">next</a><span>|</span><label class="collapse" for="c-39642689">[-]</label><label class="expand" for="c-39642689">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for the feedback! That’s a great suggestion. We do want to make the demo into a separate page, and also add a live evaluation demo using the synthetic data generated on the fly.</div><br/></div></div></div></div><div id="39642193" class="c"><input type="checkbox" id="c-39642193" checked=""/><div class="controls bullet"><span class="by">lancehasson</span><span>|</span><a href="#39642521">prev</a><span>|</span><a href="#39643395">next</a><span>|</span><label class="collapse" for="c-39642193">[-]</label><label class="expand" for="c-39642193">[2 more]</label></div><br/><div class="children"><div class="content">Looks very cool! Will check it out later. FYI - search on the docs isn&#x27;t loading on safari for me</div><br/><div id="39642673" class="c"><input type="checkbox" id="c-39642673" checked=""/><div class="controls bullet"><span class="by">antonap</span><span>|</span><a href="#39642193">parent</a><span>|</span><a href="#39643395">next</a><span>|</span><label class="collapse" for="c-39642673">[-]</label><label class="expand" for="c-39642673">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for catching that! Looking into it now.</div><br/></div></div></div></div><div id="39643395" class="c"><input type="checkbox" id="c-39643395" checked=""/><div class="controls bullet"><span class="by">nextworddev</span><span>|</span><a href="#39642193">prev</a><span>|</span><a href="#39644477">next</a><span>|</span><label class="collapse" for="c-39643395">[-]</label><label class="expand" for="c-39643395">[4 more]</label></div><br/><div class="children"><div class="content">Ok this is entering the same space as Arize AI which I have been using for a year. What’s the main benefit of this product?</div><br/><div id="39643986" class="c"><input type="checkbox" id="c-39643986" checked=""/><div class="controls bullet"><span class="by">antonap</span><span>|</span><a href="#39643395">parent</a><span>|</span><a href="#39644477">next</a><span>|</span><label class="collapse" for="c-39643986">[-]</label><label class="expand" for="c-39643986">[3 more]</label></div><br/><div class="children"><div class="content">Arize is a great tool for observability, and their open source product, Phoenix, offers many great features for LLM evaluation as well.<p>Some key unique advantages we offer:<p>- Component-level evaluation, not just observability: Many great tools on the market can help you observe different components (or execution steps) in a GenAI system for each data sample. What we offer on top of that is the ability to do automatic evaluation and have metrics for each step of the pipeline. For example, you will be able to have metrics on the accuracy of agent tool usage, precision &#x2F; recall for each retriever step, and relevant metrics on each LLM call.<p>- Leverage user feedback for offline evaluation: We allow you to create custom metrics based on your past user feedback data. Unlike predefined metrics, these custom metrics are trained to learn your specific user preferences. In a sense, these metrics simulate user ratings.<p>- Synthetic Data Generation: Large amounts of synthetic data can help you stress test your AI system beyond your existing data. They also come in greater granularity than human curated datasets and can help you test and validate.</div><br/><div id="39644483" class="c"><input type="checkbox" id="c-39644483" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#39643395">root</a><span>|</span><a href="#39643986">parent</a><span>|</span><a href="#39644477">next</a><span>|</span><label class="collapse" for="c-39644483">[-]</label><label class="expand" for="c-39644483">[2 more]</label></div><br/><div class="children"><div class="content">I always recommend a comparison page. Help prospects decide.</div><br/><div id="39644581" class="c"><input type="checkbox" id="c-39644581" checked=""/><div class="controls bullet"><span class="by">antonap</span><span>|</span><a href="#39643395">root</a><span>|</span><a href="#39644483">parent</a><span>|</span><a href="#39644477">next</a><span>|</span><label class="collapse" for="c-39644581">[-]</label><label class="expand" for="c-39644581">[1 more]</label></div><br/><div class="children"><div class="content">Great suggestion, thanks!</div><br/></div></div></div></div></div></div></div></div><div id="39644477" class="c"><input type="checkbox" id="c-39644477" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#39643395">prev</a><span>|</span><label class="collapse" for="c-39644477">[-]</label><label class="expand" for="c-39644477">[3 more]</label></div><br/><div class="children"><div class="content">qtn: why Launch so early? why not Show first?</div><br/><div id="39646916" class="c"><input type="checkbox" id="c-39646916" checked=""/><div class="controls bullet"><span class="by">antonap</span><span>|</span><a href="#39644477">parent</a><span>|</span><label class="collapse" for="c-39646916">[-]</label><label class="expand" for="c-39646916">[2 more]</label></div><br/><div class="children"><div class="content">Originally, we were going to do a Show HN for the modular evaluation and another Show HN for the synthetic data, because our understanding is that the Show HNs are for individual projects. But then we realized that it&#x27;s the combination of the various pieces that brings the most value, so we decided to put them together as a single Launch HN instead.</div><br/><div id="39648205" class="c"><input type="checkbox" id="c-39648205" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#39644477">root</a><span>|</span><a href="#39646916">parent</a><span>|</span><label class="collapse" for="c-39648205">[-]</label><label class="expand" for="c-39648205">[1 more]</label></div><br/><div class="children"><div class="content">interesting. standard advice i hear is do a bunch of Shows first, to get users and social proof, and then to show off the social proof + put fuel on a launch with a Launch since you only get one. anyway, all the best!</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>