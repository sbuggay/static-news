<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1707296468241" as="style"/><link rel="stylesheet" href="styles.css?v=1707296468241"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://huggingface.co/blog/TimothyAlexisVass/explaining-the-sdxl-latent-space">Explaining the SDXL Latent Space</a> <span class="domain">(<a href="https://huggingface.co">huggingface.co</a>)</span></div><div class="subtext"><span>thesephist</span> | <span>21 comments</span></div><br/><div><div id="39282166" class="c"><input type="checkbox" id="c-39282166" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#39282307">next</a><span>|</span><label class="collapse" for="c-39282166">[-]</label><label class="expand" for="c-39282166">[6 more]</label></div><br/><div class="children"><div class="content">I’ve been playing with diffusion a ton for the past few months, writing a new sampler that implements an iterative blending technique described in a recent paper. The latent space is rich in semantic information, so it can be a great place to apply various transformations rather than operating on the image directly. Yet it still has a significant spatial component, so things you do in one spatial area will affect that same area of the image.<p>Stable Diffusion 1.5 may be quite old now, but it is an incredibly rich model that still yields shockingly good results. SDXL is newer and more high tech, but it’s not a revolutionary improvement. It can be less malleable than the older model and harder to work with to achieve a given desired result.</div><br/><div id="39282277" class="c"><input type="checkbox" id="c-39282277" checked=""/><div class="controls bullet"><span class="by">fpgaminer</span><span>|</span><a href="#39282166">parent</a><span>|</span><a href="#39285990">next</a><span>|</span><label class="collapse" for="c-39282277">[-]</label><label class="expand" for="c-39282277">[4 more]</label></div><br/><div class="children"><div class="content">&gt; It can be less malleable than the older model and harder to work with to achieve a given desired result.<p>That has been my experience as well.  It&#x27;s frustrating because SDXL can be exquisite, but SD 1.5 is more &quot;fun&quot; to work with and more creative.  I can throw random ideas into a mish-mash of a prompt and SD 1.5 will output an array of interesting things while SDXL will just seem to fall back to something &quot;reasonable&quot;, ignoring anything &quot;weird&quot; in the prompt.  SDXL also seems to have a lot more position bias in the prompt.  SD 1.5 had a bit of that, paying more attention to words earlier in the prompt, but SDXL takes that to a new level.<p>But SDXL can draw hands consistently, so ... it&#x27;s a tough choice.</div><br/><div id="39285799" class="c"><input type="checkbox" id="c-39285799" checked=""/><div class="controls bullet"><span class="by">lrasinen</span><span>|</span><a href="#39282166">root</a><span>|</span><a href="#39282277">parent</a><span>|</span><a href="#39283892">next</a><span>|</span><label class="collapse" for="c-39285799">[-]</label><label class="expand" for="c-39285799">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But SDXL can draw hands consistently, so ... it&#x27;s a tough choice.<p>Looking at the article photos it still has some way to go. I counted 3 cases of missing fingers, two cases of extra fingers (on the cartoon girl), and a few arm poses that in real life would need medical attention.</div><br/></div></div><div id="39283892" class="c"><input type="checkbox" id="c-39283892" checked=""/><div class="controls bullet"><span class="by">designium</span><span>|</span><a href="#39282166">root</a><span>|</span><a href="#39282277">parent</a><span>|</span><a href="#39285799">prev</a><span>|</span><a href="#39285990">next</a><span>|</span><label class="collapse" for="c-39283892">[-]</label><label class="expand" for="c-39283892">[2 more]</label></div><br/><div class="children"><div class="content">With comfyui, you can do SDXL &gt; SD1.5 or SD1.5 &gt; SDXL, it makes more sense to generate basic image in SDXL Turbo and apply the effects of a checkpoint later.</div><br/><div id="39284254" class="c"><input type="checkbox" id="c-39284254" checked=""/><div class="controls bullet"><span class="by">SV_BubbleTime</span><span>|</span><a href="#39282166">root</a><span>|</span><a href="#39283892">parent</a><span>|</span><a href="#39285990">next</a><span>|</span><label class="collapse" for="c-39284254">[-]</label><label class="expand" for="c-39284254">[1 more]</label></div><br/><div class="children"><div class="content">Kind of blowing my mind here.<p>Coming from Auto1111 for a year, I thought comfy was most like always using img2img, then I figured out it wasn’t that but laten2latent… which is cool, but using XL to get the better prompting and 1.5 to get checkpoints and Loras I want is making it all click now.</div><br/></div></div></div></div></div></div><div id="39285990" class="c"><input type="checkbox" id="c-39285990" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#39282166">parent</a><span>|</span><a href="#39282277">prev</a><span>|</span><a href="#39282307">next</a><span>|</span><label class="collapse" for="c-39285990">[-]</label><label class="expand" for="c-39285990">[1 more]</label></div><br/><div class="children"><div class="content">I am curious what do you mean by high tech?</div><br/></div></div></div></div><div id="39282307" class="c"><input type="checkbox" id="c-39282307" checked=""/><div class="controls bullet"><span class="by">nomel</span><span>|</span><a href="#39282166">prev</a><span>|</span><a href="#39269583">next</a><span>|</span><label class="collapse" for="c-39282307">[-]</label><label class="expand" for="c-39282307">[7 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the reason for using RGB rather than, say, HSV? RGB seems like it would be fairly discontinuous. Or, do I have that backwards?</div><br/><div id="39282534" class="c"><input type="checkbox" id="c-39282534" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#39282307">parent</a><span>|</span><a href="#39284703">next</a><span>|</span><label class="collapse" for="c-39282534">[-]</label><label class="expand" for="c-39282534">[1 more]</label></div><br/><div class="children"><div class="content">I think there might be an opinion that since most colour space conversions can be expressed with relatively small neural nets (since they are mostly accumulations of variously scaled values), the autoencoder can dedicate a negligible proportion of its parameters towards that job and that gives it the potential to choose whatever color space training dictates.<p>I&#x27;m not entirely convinced by this idea myself.  I have seen a few networks where a range of -1..1 inputs do a lot better than inputs in the range of 0..2 even though translation should be an easyish step for the network to figure out.    The benefit from preprocessing the inputs, to me seem to be more advantageous than my common sense tells me it should be.</div><br/></div></div><div id="39284703" class="c"><input type="checkbox" id="c-39284703" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#39282307">parent</a><span>|</span><a href="#39282534">prev</a><span>|</span><a href="#39283855">next</a><span>|</span><label class="collapse" for="c-39284703">[-]</label><label class="expand" for="c-39284703">[4 more]</label></div><br/><div class="children"><div class="content">The format isn&#x27;t explicit to the network. But the data trained on is usually in RGB format, so probably the reasoning. I found a repo where someone tried different formats but it&#x27;s wroth noting that this was for discrimination so just because it can discriminate doesn&#x27;t mean it does the same thing. Maybe I&#x27;ll run some experiments. You could use a UNet for classification and then look at the bottom layer and do the same thing. Be hard to do with SD (or SDXL) because you&#x27;d need to retrain with the format. Tuning could possibly work but the network would likely be biased to understand the RGB encoding.<p>Edit: ops, forgot the link<p><a href="https:&#x2F;&#x2F;github.com&#x2F;ducha-aiki&#x2F;caffenet-benchmark&#x2F;blob&#x2F;master&#x2F;Colorspace.md">https:&#x2F;&#x2F;github.com&#x2F;ducha-aiki&#x2F;caffenet-benchmark&#x2F;blob&#x2F;master...</a></div><br/><div id="39285211" class="c"><input type="checkbox" id="c-39285211" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#39282307">root</a><span>|</span><a href="#39284703">parent</a><span>|</span><a href="#39283855">next</a><span>|</span><label class="collapse" for="c-39285211">[-]</label><label class="expand" for="c-39285211">[3 more]</label></div><br/><div class="children"><div class="content">&gt; But the data trained on is usually in RGB format, so probably the reasoning.<p>It&#x27;s trivial to convert the values for training - basically 0% of the cost of the process. But there&#x27;s likely more &quot;meaning&quot; in HSV than in RGB. So I don&#x27;t think that would account for the difference.</div><br/><div id="39286094" class="c"><input type="checkbox" id="c-39286094" checked=""/><div class="controls bullet"><span class="by">incrudible</span><span>|</span><a href="#39282307">root</a><span>|</span><a href="#39285211">parent</a><span>|</span><a href="#39283855">next</a><span>|</span><label class="collapse" for="c-39286094">[-]</label><label class="expand" for="c-39286094">[2 more]</label></div><br/><div class="children"><div class="content">ML systems generally do not care about human semantics, and they will not produce them naturally. The VAE works at 16 bits float per channel, so compression is not an issue either, but if it was, HSV would be a poor choice too.</div><br/><div id="39286149" class="c"><input type="checkbox" id="c-39286149" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#39282307">root</a><span>|</span><a href="#39286094">parent</a><span>|</span><a href="#39283855">next</a><span>|</span><label class="collapse" for="c-39286149">[-]</label><label class="expand" for="c-39286149">[1 more]</label></div><br/><div class="children"><div class="content">ML systems don&#x27;t care, but humans do and better semantically-meaningful representations in training data usually lead to better results for us. In images you often care about &quot;different colours of similar brightness&quot; rather than &quot;matching levels of 3 colour components&quot;, so there&#x27;s a non-zero chance HSV&#x2F;HLS would do better than RGB. It&#x27;s nothing to do with compression.</div><br/></div></div></div></div></div></div></div></div><div id="39283855" class="c"><input type="checkbox" id="c-39283855" checked=""/><div class="controls bullet"><span class="by">Dwedit</span><span>|</span><a href="#39282307">parent</a><span>|</span><a href="#39284703">prev</a><span>|</span><a href="#39269583">next</a><span>|</span><label class="collapse" for="c-39283855">[-]</label><label class="expand" for="c-39283855">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s more like YCbCr or YCgCo color space than RGB.</div><br/></div></div></div></div><div id="39269583" class="c"><input type="checkbox" id="c-39269583" checked=""/><div class="controls bullet"><span class="by">Sabinus</span><span>|</span><a href="#39282307">prev</a><span>|</span><a href="#39282334">next</a><span>|</span><label class="collapse" for="c-39269583">[-]</label><label class="expand" for="c-39269583">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s very cool. I had no idea the latent space was that accessible and obviously manipulatable.<p>Also interesting is how the way sdxl structures latents affects how it thinks about images.</div><br/></div></div><div id="39282334" class="c"><input type="checkbox" id="c-39282334" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#39269583">prev</a><span>|</span><a href="#39283005">next</a><span>|</span><label class="collapse" for="c-39282334">[-]</label><label class="expand" for="c-39282334">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s as simple as this naive approach suggests, but it&#x27;s a good preliminary analysis.   It&#x27;s a good lesson that while being absolutely correct might be quite difficult,  diving in and having a go might get you further than you think.</div><br/></div></div><div id="39283005" class="c"><input type="checkbox" id="c-39283005" checked=""/><div class="controls bullet"><span class="by">01HNNWZ0MV43FF</span><span>|</span><a href="#39282334">prev</a><span>|</span><a href="#39285043">next</a><span>|</span><label class="collapse" for="c-39283005">[-]</label><label class="expand" for="c-39283005">[1 more]</label></div><br/><div class="children"><div class="content">All the patterns and textures are expressed by only one dimension? Bizarre.</div><br/></div></div><div id="39285043" class="c"><input type="checkbox" id="c-39285043" checked=""/><div class="controls bullet"><span class="by">HanClinto</span><span>|</span><a href="#39283005">prev</a><span>|</span><a href="#39285813">next</a><span>|</span><label class="collapse" for="c-39285043">[-]</label><label class="expand" for="c-39285043">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for the excellent article! Top notch work!</div><br/></div></div><div id="39285813" class="c"><input type="checkbox" id="c-39285813" checked=""/><div class="controls bullet"><span class="by">rgmmm</span><span>|</span><a href="#39285043">prev</a><span>|</span><a href="#39284220">next</a><span>|</span><label class="collapse" for="c-39285813">[-]</label><label class="expand" for="c-39285813">[1 more]</label></div><br/><div class="children"><div class="content">Enhance.</div><br/></div></div><div id="39284220" class="c"><input type="checkbox" id="c-39284220" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#39285813">prev</a><span>|</span><a href="#39284217">next</a><span>|</span><label class="collapse" for="c-39284220">[-]</label><label class="expand" for="c-39284220">[1 more]</label></div><br/><div class="children"><div class="content">Anyone know if the work shown here has been implemented in Automatic1111 or ComfyUI as an extension? If not, than that might be my first project to add since these are quite simple (relatively speaking) in the code to implement.</div><br/></div></div><div id="39284217" class="c"><input type="checkbox" id="c-39284217" checked=""/><div class="controls bullet"><span class="by">SV_BubbleTime</span><span>|</span><a href="#39284220">prev</a><span>|</span><label class="collapse" for="c-39284217">[-]</label><label class="expand" for="c-39284217">[1 more]</label></div><br/><div class="children"><div class="content">That was an excellently written article.<p>I for sure thought a discussion about latent spaces would instantly be over my head. It was, but took a few paragraphs.</div><br/></div></div></div></div></div></div></div></body></html>