<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1684746064258" as="style"/><link rel="stylesheet" href="styles.css?v=1684746064258"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/imartinez/privateGPT">PrivateGPT</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>antouank</span> | <span>57 comments</span></div><br/><div><div id="36028873" class="c"><input type="checkbox" id="c-36028873" checked=""/><div class="controls bullet"><span class="by">lysp</span><span>|</span><a href="#36028769">next</a><span>|</span><label class="collapse" for="c-36028873">[-]</label><label class="expand" for="c-36028873">[1 more]</label></div><br/><div class="children"><div class="content">Quick how-to&#x2F;demo:<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=A3F5riM5BNE">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=A3F5riM5BNE</a><p>Also has a suggestion of a few alternative models to use.</div><br/></div></div><div id="36028769" class="c"><input type="checkbox" id="c-36028769" checked=""/><div class="controls bullet"><span class="by">Wronnay</span><span>|</span><a href="#36028873">prev</a><span>|</span><a href="#36024888">next</a><span>|</span><label class="collapse" for="c-36028769">[-]</label><label class="expand" for="c-36028769">[2 more]</label></div><br/><div class="children"><div class="content">Wow. I keep a personal Wiki, Journal and use plain text accounting...<p>This project could help me create a personal AI which answers any questions to my life, finances or knowledge...</div><br/><div id="36028820" class="c"><input type="checkbox" id="c-36028820" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#36028769">parent</a><span>|</span><a href="#36024888">next</a><span>|</span><label class="collapse" for="c-36028820">[-]</label><label class="expand" for="c-36028820">[1 more]</label></div><br/><div class="children"><div class="content">Well maybe it works on Obsidian vaults for note taking heh, but with llama models&#x27; 2k input token range it&#x27;d get a tenth of the way before starting to drop context. Likely useless without something like an 100k model.</div><br/></div></div></div></div><div id="36024888" class="c"><input type="checkbox" id="c-36024888" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#36028769">prev</a><span>|</span><a href="#36026366">next</a><span>|</span><label class="collapse" for="c-36024888">[-]</label><label class="expand" for="c-36024888">[20 more]</label></div><br/><div class="children"><div class="content">I&#x27;m always interested in seeing the prompt that drives these kinds of tools.<p>In this case it appears to be using RetrievalQA from LangChain, which I think is this prompt here: <a href="https:&#x2F;&#x2F;github.com&#x2F;hwchase17&#x2F;langchain&#x2F;blob&#x2F;v0.0.176&#x2F;langchain&#x2F;chains&#x2F;retrieval_qa&#x2F;prompt.py">https:&#x2F;&#x2F;github.com&#x2F;hwchase17&#x2F;langchain&#x2F;blob&#x2F;v0.0.176&#x2F;langcha...</a><p><pre><code>    Use the following pieces of context to answer the question at the end. If you don&#x27;t
    know the answer, just say that you don&#x27;t know, don&#x27;t try to make up an answer.

    {context}

    Question: {question}
    Helpful Answer:</code></pre></div><br/><div id="36026272" class="c"><input type="checkbox" id="c-36026272" checked=""/><div class="controls bullet"><span class="by">jstarfish</span><span>|</span><a href="#36024888">parent</a><span>|</span><a href="#36026673">next</a><span>|</span><label class="collapse" for="c-36026272">[-]</label><label class="expand" for="c-36026272">[18 more]</label></div><br/><div class="children"><div class="content">Do such fail-early conditions save processing time?</div><br/><div id="36026303" class="c"><input type="checkbox" id="c-36026303" checked=""/><div class="controls bullet"><span class="by">mabbo</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36026272">parent</a><span>|</span><a href="#36028190">next</a><span>|</span><label class="collapse" for="c-36026303">[-]</label><label class="expand" for="c-36026303">[15 more]</label></div><br/><div class="children"><div class="content">If you mean the &quot;If you don&#x27;t know&quot; part, oh no, they have a much bigger problem they&#x27;re solving.<p>The LLM will absolutely lie if it doesn&#x27;t know and you haven&#x27;t made it perfectly clear that you&#x27;d rather it did not do that.<p>LLMs seem to be trying to give answers that make you happy. A good lie will make you happy. Unless it understands that you will not be happy with a lie.<p>Is this anthropomorphizing? Yep. But that&#x27;s the best way I&#x27;ve found to reason about them.</div><br/><div id="36026324" class="c"><input type="checkbox" id="c-36026324" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36026303">parent</a><span>|</span><a href="#36027177">next</a><span>|</span><label class="collapse" for="c-36026324">[-]</label><label class="expand" for="c-36026324">[13 more]</label></div><br/><div class="children"><div class="content">A less anthropomorphic approach might be to say that LLMs can predict the correct “shape” of an answer even when they don’t have data that gives them a clear right answer for the correct content, and since their basic design is to provide the best response they can, they’ll provide an answer of the correct shape with fairly random content if all they have good information to predict is the shape and not the content.</div><br/><div id="36027385" class="c"><input type="checkbox" id="c-36027385" checked=""/><div class="controls bullet"><span class="by">flagrant_taco</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36026324">parent</a><span>|</span><a href="#36026527">next</a><span>|</span><label class="collapse" for="c-36027385">[-]</label><label class="expand" for="c-36027385">[10 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the point of the technology if it will provide an answer regardless of the accuracy? And what prevents this from being dangerous when the factual and ficticious answers are indistinguishable?</div><br/><div id="36028610" class="c"><input type="checkbox" id="c-36028610" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36027385">parent</a><span>|</span><a href="#36027482">next</a><span>|</span><label class="collapse" for="c-36028610">[-]</label><label class="expand" for="c-36028610">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What&#x27;s the point of the technology if it will provide an answer regardless of the accuracy?<p>The purpose is to serve as a component of a system which also includes features, such as the prompt structure upthread, that mitigates the undesired behavior while keeping the useful behaviors.</div><br/></div></div><div id="36027482" class="c"><input type="checkbox" id="c-36027482" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36027385">parent</a><span>|</span><a href="#36028610">prev</a><span>|</span><a href="#36028103">next</a><span>|</span><label class="collapse" for="c-36027482">[-]</label><label class="expand" for="c-36027482">[4 more]</label></div><br/><div class="children"><div class="content">Yes, it could be dangerous if you blindly rely on its reliability for something safety-related. But many creative processes are unreliable. For example, coming up with bad ideas while brainstorming is pretty harmless if nobody misunderstands it.<p>Generally, you want some external way of verifying that you have something useful. Sometimes that happens naturally. Ask a chatbot to recommend a paper to read and then search for it, and you’ll find out pretty quick if it doesn’t exist.</div><br/><div id="36027652" class="c"><input type="checkbox" id="c-36027652" checked=""/><div class="controls bullet"><span class="by">flagrant_taco</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36027482">parent</a><span>|</span><a href="#36028103">next</a><span>|</span><label class="collapse" for="c-36027652">[-]</label><label class="expand" for="c-36027652">[3 more]</label></div><br/><div class="children"><div class="content">What happens when the tech isn&#x27;t only being used to answer a human&#x27;s questions during a shortlived conversation though?<p>The common case we see publicized today is people poking around with prompts, but isn&#x27;t it more likely, or at least a risk, that mass adoption will look more like AI running as longlived processes talked with managing done system on their own?</div><br/><div id="36028626" class="c"><input type="checkbox" id="c-36028626" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36027652">parent</a><span>|</span><a href="#36028006">next</a><span>|</span><label class="collapse" for="c-36028626">[-]</label><label class="expand" for="c-36028626">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The common case we see publicized today is people poking around with prompts, but isn&#x27;t it more likely, or at least a risk, that mass adoption will look more like AI running as longlived processes talked with managing done system on their own?<p>If by “AI” you mean “bare GPT-style LLMs”, no, they can’t do that.<p>If you mean “systems consisting of LLMs being called in a loop by  software which uses a prompt structure carefully designed and tested for the operating domain, and which has other safeguards on behavior, sure, that’s more probable.</div><br/></div></div><div id="36028006" class="c"><input type="checkbox" id="c-36028006" checked=""/><div class="controls bullet"><span class="by">hetman</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36027652">parent</a><span>|</span><a href="#36028626">prev</a><span>|</span><a href="#36028103">next</a><span>|</span><label class="collapse" for="c-36028006">[-]</label><label class="expand" for="c-36028006">[1 more]</label></div><br/><div class="children"><div class="content">Not if they&#x27;re bad at it. ChatGPT and friends is a tool that&#x27;s useful for some things and that&#x27;s where it&#x27;ll see adoption. Misuses if the technology will likely be exposed as such pretty quickly.</div><br/></div></div></div></div></div></div><div id="36028103" class="c"><input type="checkbox" id="c-36028103" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36027385">parent</a><span>|</span><a href="#36027482">prev</a><span>|</span><a href="#36027744">next</a><span>|</span><label class="collapse" for="c-36028103">[-]</label><label class="expand" for="c-36028103">[2 more]</label></div><br/><div class="children"><div class="content">These are the 1-million dollar questions when it comes to LLMs.  How useful is it to talk to a human who likes to talk, and prefers to say <i>something</i> over admiting they dont know?  And if you have a person with münchhausensyndrome in your circles, how dangerous is it to listen to them and accidentally picking up a lie?  LLMs with temp &gt; 0.5 are effectively like these people.</div><br/><div id="36028857" class="c"><input type="checkbox" id="c-36028857" checked=""/><div class="controls bullet"><span class="by">nullsense</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36028103">parent</a><span>|</span><a href="#36027744">next</a><span>|</span><label class="collapse" for="c-36028857">[-]</label><label class="expand" for="c-36028857">[1 more]</label></div><br/><div class="children"><div class="content">The number one problem for generalized intelligence is establishing trust.</div><br/></div></div></div></div><div id="36027725" class="c"><input type="checkbox" id="c-36027725" checked=""/><div class="controls bullet"><span class="by">twelve40</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36027385">parent</a><span>|</span><a href="#36027744">prev</a><span>|</span><a href="#36026527">next</a><span>|</span><label class="collapse" for="c-36027725">[-]</label><label class="expand" for="c-36027725">[1 more]</label></div><br/><div class="children"><div class="content">for one, telling people something they like to hear is an amazing marketing tactic</div><br/></div></div></div></div><div id="36028038" class="c"><input type="checkbox" id="c-36028038" checked=""/><div class="controls bullet"><span class="by">slim</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36026324">parent</a><span>|</span><a href="#36026527">prev</a><span>|</span><a href="#36027177">next</a><span>|</span><label class="collapse" for="c-36028038">[-]</label><label class="expand" for="c-36028038">[1 more]</label></div><br/><div class="children"><div class="content">those things are anthropomorphic by design. there&#x27;s no point in being cautious, unless it&#x27;s from an ideological stand point</div><br/></div></div></div></div><div id="36027177" class="c"><input type="checkbox" id="c-36027177" checked=""/><div class="controls bullet"><span class="by">teawrecks</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36026303">parent</a><span>|</span><a href="#36026324">prev</a><span>|</span><a href="#36028190">next</a><span>|</span><label class="collapse" for="c-36027177">[-]</label><label class="expand" for="c-36027177">[1 more]</label></div><br/><div class="children"><div class="content">I think of it more like a pachinko machine. You put your question in the top, it bounces around through a bunch of biased obstacles, but intevitably it will come out <i>somewhere</i> at the bottom.<p>By telling it not to lie to you, you&#x27;re biasing it toward a particular output in the event that its confidence is low. Otherwise, low confidence results just fall out somewhere mostly random.</div><br/></div></div></div></div><div id="36028190" class="c"><input type="checkbox" id="c-36028190" checked=""/><div class="controls bullet"><span class="by">Grimblewald</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36026272">parent</a><span>|</span><a href="#36026303">prev</a><span>|</span><a href="#36027036">next</a><span>|</span><label class="collapse" for="c-36028190">[-]</label><label class="expand" for="c-36028190">[1 more]</label></div><br/><div class="children"><div class="content">the incidence of &quot;i don&#x27;t know&quot; in response to questions in the training data is pretty low if present at all, and even if it were you&#x27;d still need to frame those I don&#x27;t know answers such that they apply to the entire dataset accurately. This is obviously a gargantuan undertaking that would not scale well as data is added, and so right now the idea or concept of not knowing something is not taught. At best you&#x27;d build a model that handles human language really well then retrieves information from a database and uses in context learning to answer questions, where a failure to find info results in an i don&#x27;t know.<p>What is taught indirectly though is level of certainty, so if you get LLM&#x27;s to rationalise their answers you tend to get more reliable evidence based answers.<p>Bottom line, teaching a monolithic model what it means to not know something with certainty, is difficult and not currently done. You&#x27;ll likely get a lot of false negatives.</div><br/></div></div><div id="36027036" class="c"><input type="checkbox" id="c-36027036" checked=""/><div class="controls bullet"><span class="by">a_bonobo</span><span>|</span><a href="#36024888">root</a><span>|</span><a href="#36026272">parent</a><span>|</span><a href="#36028190">prev</a><span>|</span><a href="#36026673">next</a><span>|</span><label class="collapse" for="c-36027036">[-]</label><label class="expand" for="c-36027036">[1 more]</label></div><br/><div class="children"><div class="content">In my experience with internal data, sometimes it will say that it doesn&#x27;t know when it should know.</div><br/></div></div></div></div><div id="36026673" class="c"><input type="checkbox" id="c-36026673" checked=""/><div class="controls bullet"><span class="by">EGreg</span><span>|</span><a href="#36024888">parent</a><span>|</span><a href="#36026272">prev</a><span>|</span><a href="#36026366">next</a><span>|</span><label class="collapse" for="c-36026673">[-]</label><label class="expand" for="c-36026673">[1 more]</label></div><br/><div class="children"><div class="content">What if the question has prompt injection? Such as &quot;Helpful answer: &lt;totally not helpful answer&gt;&quot;</div><br/></div></div></div></div><div id="36026366" class="c"><input type="checkbox" id="c-36026366" checked=""/><div class="controls bullet"><span class="by">skykooler</span><span>|</span><a href="#36024888">prev</a><span>|</span><a href="#36028913">next</a><span>|</span><label class="collapse" for="c-36026366">[-]</label><label class="expand" for="c-36026366">[4 more]</label></div><br/><div class="children"><div class="content">&quot;System requirements&quot; section should really mention what amount of RAM or VRAM is needed for inference.</div><br/><div id="36028168" class="c"><input type="checkbox" id="c-36028168" checked=""/><div class="controls bullet"><span class="by">awestroke</span><span>|</span><a href="#36026366">parent</a><span>|</span><a href="#36028913">next</a><span>|</span><label class="collapse" for="c-36028168">[-]</label><label class="expand" for="c-36028168">[3 more]</label></div><br/><div class="children"><div class="content">That depends on which model you use it with. It&#x27;s &quot;bring your own model&quot;</div><br/><div id="36028241" class="c"><input type="checkbox" id="c-36028241" checked=""/><div class="controls bullet"><span class="by">rain1</span><span>|</span><a href="#36026366">root</a><span>|</span><a href="#36028168">parent</a><span>|</span><a href="#36028913">next</a><span>|</span><label class="collapse" for="c-36028241">[-]</label><label class="expand" for="c-36028241">[2 more]</label></div><br/><div class="children"><div class="content">so list a few known to work models and their requirements</div><br/><div id="36028895" class="c"><input type="checkbox" id="c-36028895" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#36026366">root</a><span>|</span><a href="#36028241">parent</a><span>|</span><a href="#36028913">next</a><span>|</span><label class="collapse" for="c-36028895">[-]</label><label class="expand" for="c-36028895">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;wiki&#x2F;models" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;wiki&#x2F;models</a></div><br/></div></div></div></div></div></div></div></div><div id="36028913" class="c"><input type="checkbox" id="c-36028913" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#36026366">prev</a><span>|</span><a href="#36028379">next</a><span>|</span><label class="collapse" for="c-36028913">[-]</label><label class="expand" for="c-36028913">[1 more]</label></div><br/><div class="children"><div class="content">does this only work with llamaCPP ? I.e. can&#x27;t use GPU models with this?</div><br/></div></div><div id="36028379" class="c"><input type="checkbox" id="c-36028379" checked=""/><div class="controls bullet"><span class="by">daitangio</span><span>|</span><a href="#36028913">prev</a><span>|</span><a href="#36026345">next</a><span>|</span><label class="collapse" for="c-36028379">[-]</label><label class="expand" for="c-36028379">[3 more]</label></div><br/><div class="children"><div class="content">Hi, very interesting... what are the memory&#x2F;disk requirements to run it?
16GB of RAM would be enough?
I suggest to add these requirements to the README</div><br/><div id="36028461" class="c"><input type="checkbox" id="c-36028461" checked=""/><div class="controls bullet"><span class="by">MandieD</span><span>|</span><a href="#36028379">parent</a><span>|</span><a href="#36028851">next</a><span>|</span><label class="collapse" for="c-36028461">[-]</label><label class="expand" for="c-36028461">[1 more]</label></div><br/><div class="children"><div class="content">Also, a general formula for estimating how much additional storage space will be claimed per MB&#x2F;million words ingested would be helpful.</div><br/></div></div><div id="36028851" class="c"><input type="checkbox" id="c-36028851" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#36028379">parent</a><span>|</span><a href="#36028461">prev</a><span>|</span><a href="#36026345">next</a><span>|</span><label class="collapse" for="c-36028851">[-]</label><label class="expand" for="c-36028851">[1 more]</label></div><br/><div class="children"><div class="content">Well I&#x27;m not sure which models specifically work, but it runs on llama.cpp, which would mean lama derivative ones. Here&#x27;s a little table for quantized CPU (GGML) versions and the RAM they require as a general rule of thumb:<p>&gt; Name Quant method Bits Size RAM required Use case<p>WizardLM-7B.GGML.q4_0.bin q4_0 4bit 4.2GB 6GB 4bit.<p>WizardLM-7B.GGML.q4_1.bin q4_0 4bit 4.63GB 6GB 4-bit. Higher accuracy than q4_0 but not as high as q5_0. However has quicker inference than q5 models.<p>WizardLM-7B.GGML.q5_0.bin q5_0 5bit 4.63GB 7GB 5-bit. Higher accuracy, higher resource usage and slower inference.<p>WizardLM-7B.GGML.q5_1.bin q5_1 5bit 5.0GB 7GB 5-bit. Even higher accuracy, and higher resource usage and slower inference.<p>WizardLM-7B.GGML.q8_0.bin q8_0 8bit 8GB 10GB 8-bit. Almost indistinguishable from float16. Huge resource use and slow. Not recommended for normal use.<p>&gt; Name Quant method Bits Size RAM required Use case<p>wizard-vicuna-13B.ggmlv3.q4_0.bin q4_0 4bit 8.14GB 10.5GB 4-bit.<p>wizard-vicuna-13B.ggmlv3.q4_1.bin q4_1 4bit 8.95GB 11.0GB 4-bit. Higher accuracy than q4_0 but not as high as q5_0. However has quicker inference than q5 models.<p>wizard-vicuna-13B.ggmlv3.q5_0.bin q5_0 5bit 8.95GB 11.0GB 5-bit. Higher accuracy, higher resource usage and slower inference.<p>wizard-vicuna-13B.ggmlv3.q5_1.bin q5_1 5bit 9.76GB 12.25GB 5-bit. Even higher accuracy, and higher resource usage and slower inference.<p>wizard-vicuna-13B.ggmlv3.q8_0.bin q5_1 5bit 16GB 18GB 8-bit. Almost indistinguishable from float16. Huge resource use and slow. Not recommended for normal use.<p>&gt; Name Quant method Bits Size RAM required Use case<p>VicUnlocked-30B-LoRA.ggmlv3.q4_0.bin q4_0 4bit 20.3GB 23GB 4-bit.<p>VicUnlocked-30B-LoRA.ggmlv3.q4_1.bin q4_1 5bit 24.4GB 27GB 4-bit. Higher accuracy than q4_0 but not as high as q5_0. However has quicker inference than q5 models.<p>VicUnlocked-30B-LoRA.ggmlv3.q5_0.bin q5_0 5bit 22.4GB 25GB 5-bit. Higher accuracy, higher resource usage and slower inference.<p>VicUnlocked-30B-LoRA.ggmlv3.q5_1.bin q5_1 5bit 24.4GB 27GB 5-bit. Even higher accuracy, and higher resource usage and slower inference.<p>VicUnlocked-30B-LoRA.ggmlv3.q8_0.bin q8_0 8bit 36.6GB 39GB 8-bit. Almost indistinguishable from float16. Huge resource use and slow. Not recommended for normal use.<p>Copied of some of The-Bloke&#x27;s model descriptions on huggingface. With 16G you can run practically all 7B and 13B versions. With shared GPU+CPU inference, one can also offload some layers onto a GPU (not sure if that makes the initial RAM requirement smaller), but you do need CUDA of course.</div><br/></div></div></div></div><div id="36026345" class="c"><input type="checkbox" id="c-36026345" checked=""/><div class="controls bullet"><span class="by">aldarisbm</span><span>|</span><a href="#36028379">prev</a><span>|</span><a href="#36027242">next</a><span>|</span><label class="collapse" for="c-36026345">[-]</label><label class="expand" for="c-36026345">[3 more]</label></div><br/><div class="children"><div class="content">One quick plug<p>I want to have the memory part of langchain down, vector store + local database + client to chat with an LLM (gpt4all model can be swapped with OpenAI api just switching the base URL)<p><a href="https:&#x2F;&#x2F;github.com&#x2F;aldarisbm&#x2F;memory">https:&#x2F;&#x2F;github.com&#x2F;aldarisbm&#x2F;memory</a><p>It&#x27;s still got ways to go, if someone wants to help let me know :)</div><br/><div id="36028521" class="c"><input type="checkbox" id="c-36028521" checked=""/><div class="controls bullet"><span class="by">santiagobasulto</span><span>|</span><a href="#36026345">parent</a><span>|</span><a href="#36027242">next</a><span>|</span><label class="collapse" for="c-36028521">[-]</label><label class="expand" for="c-36028521">[2 more]</label></div><br/><div class="children"><div class="content">Sorry for my ignorance. But memory refers to the process of using embeddings for QA right?<p>The process roughly is:<p>Ingestion:<p>- Process embeddings for your documents (from text to array of numbers)<p>- Store your documents in a Vector DB<p>Query time:<p>- Process embeddings for the query<p>- Find documents similar to the query using distance from other docs in the Vector db<p>- Construct prompt with format:<p>&quot;&quot;&quot;
Answer question using this context:
{DOCUMENTS RETRIEVED}<p>Question: {question}
Answer:
&quot;&quot;&quot;<p>Is that correct? Now, my question is, can the models be swapped easily? Or that requires a complete recalculation of the embedding (and new ingestion)?</div><br/><div id="36028891" class="c"><input type="checkbox" id="c-36028891" checked=""/><div class="controls bullet"><span class="by">bigfudge</span><span>|</span><a href="#36026345">root</a><span>|</span><a href="#36028521">parent</a><span>|</span><a href="#36027242">next</a><span>|</span><label class="collapse" for="c-36028891">[-]</label><label class="expand" for="c-36028891">[1 more]</label></div><br/><div class="children"><div class="content">The embeddings can be based on a different model to the one you pass them as context to. So you could upgrade the summmariser model without upgrading the embeddings.</div><br/></div></div></div></div></div></div><div id="36027242" class="c"><input type="checkbox" id="c-36027242" checked=""/><div class="controls bullet"><span class="by">thefourthchime</span><span>|</span><a href="#36026345">prev</a><span>|</span><a href="#36025882">next</a><span>|</span><label class="collapse" for="c-36027242">[-]</label><label class="expand" for="c-36027242">[2 more]</label></div><br/><div class="children"><div class="content">I tried this on my M2 Macbook with 16gb of RAM but got:<p>&quot;ggml_new_tensor_impl: not enough space in the context&#x27;s memory pool (needed 18296202768, available 18217606000)&quot;</div><br/><div id="36027356" class="c"><input type="checkbox" id="c-36027356" checked=""/><div class="controls bullet"><span class="by">soferio</span><span>|</span><a href="#36027242">parent</a><span>|</span><a href="#36025882">next</a><span>|</span><label class="collapse" for="c-36027356">[-]</label><label class="expand" for="c-36027356">[1 more]</label></div><br/><div class="children"><div class="content">Anyone got it working on an M1 with 8gb?</div><br/></div></div></div></div><div id="36025882" class="c"><input type="checkbox" id="c-36025882" checked=""/><div class="controls bullet"><span class="by">kordlessagain</span><span>|</span><a href="#36027242">prev</a><span>|</span><a href="#36028612">next</a><span>|</span><label class="collapse" for="c-36025882">[-]</label><label class="expand" for="c-36025882">[1 more]</label></div><br/><div class="children"><div class="content">Working on something similar that uses keyterm extraction for traversal of topics and fragments, without using Langchain. It&#x27;s not designed to be private, however: <a href="https:&#x2F;&#x2F;github.com&#x2F;FeatureBaseDB&#x2F;DocGPT&#x2F;tree&#x2F;main">https:&#x2F;&#x2F;github.com&#x2F;FeatureBaseDB&#x2F;DocGPT&#x2F;tree&#x2F;main</a></div><br/></div></div><div id="36028612" class="c"><input type="checkbox" id="c-36028612" checked=""/><div class="controls bullet"><span class="by">ChocoluvH</span><span>|</span><a href="#36025882">prev</a><span>|</span><a href="#36026300">next</a><span>|</span><label class="collapse" for="c-36028612">[-]</label><label class="expand" for="c-36028612">[3 more]</label></div><br/><div class="children"><div class="content">Always wondering pros&#x2F;cons of Chroma and Qdrant. Can someone tell me?</div><br/><div id="36028794" class="c"><input type="checkbox" id="c-36028794" checked=""/><div class="controls bullet"><span class="by">kacperlukawski</span><span>|</span><a href="#36028612">parent</a><span>|</span><a href="#36026300">next</a><span>|</span><label class="collapse" for="c-36028794">[-]</label><label class="expand" for="c-36028794">[2 more]</label></div><br/><div class="children"><div class="content">Chroma doesn&#x27;t seem to be a real DB, it&#x27;s rather a wrapper around tools like hnswlib, DuckDB or Clickhouse. Qdrant is way more mature - it has its own HNSW implementation with some tweaks to incorporate filtering directly during the vector search phase, supports horizontal and vertical scaling, as well as provides its own managed cloud offering.<p>In general, Qdrant is a real DB, not a library and that&#x27;s a huge difference.</div><br/><div id="36028850" class="c"><input type="checkbox" id="c-36028850" checked=""/><div class="controls bullet"><span class="by">ChocoluvH</span><span>|</span><a href="#36028612">root</a><span>|</span><a href="#36028794">parent</a><span>|</span><a href="#36026300">next</a><span>|</span><label class="collapse" for="c-36028850">[-]</label><label class="expand" for="c-36028850">[1 more]</label></div><br/><div class="children"><div class="content">What does Chroma lack? Their APIs seem pretty much the same to me.</div><br/></div></div></div></div></div></div><div id="36026300" class="c"><input type="checkbox" id="c-36026300" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#36028612">prev</a><span>|</span><a href="#36028003">next</a><span>|</span><label class="collapse" for="c-36026300">[-]</label><label class="expand" for="c-36026300">[2 more]</label></div><br/><div class="children"><div class="content">When you split a document into chunks, doesn&#x27;t some crucial information get cut in half? In that case, you&#x27;d probably lose that information in the context if that information was immediately followed by an irrelevant information that reduces the cosine similarity. Is there a &quot;smarter&quot; way to feed documents as context to LLMs?</div><br/><div id="36026354" class="c"><input type="checkbox" id="c-36026354" checked=""/><div class="controls bullet"><span class="by">haolez</span><span>|</span><a href="#36026300">parent</a><span>|</span><a href="#36028003">next</a><span>|</span><label class="collapse" for="c-36026354">[-]</label><label class="expand" for="c-36026354">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t know if there is a smarter way, but these libraries usually offer an overlap parameter that allows you to repeat the last N characters of a chunk in the first N of the next chunk.</div><br/></div></div></div></div><div id="36028003" class="c"><input type="checkbox" id="c-36028003" checked=""/><div class="controls bullet"><span class="by">rolisz</span><span>|</span><a href="#36026300">prev</a><span>|</span><a href="#36028458">next</a><span>|</span><label class="collapse" for="c-36028003">[-]</label><label class="expand" for="c-36028003">[1 more]</label></div><br/><div class="children"><div class="content">For some reason, downloading the model they suggest keeps failing. I tried to download it in Firefox and Edge. I&#x27;m using Windows, if that matters. Anyone else seeing similar issues?</div><br/></div></div><div id="36028458" class="c"><input type="checkbox" id="c-36028458" checked=""/><div class="controls bullet"><span class="by">sinandrei91</span><span>|</span><a href="#36028003">prev</a><span>|</span><a href="#36028725">next</a><span>|</span><label class="collapse" for="c-36028458">[-]</label><label class="expand" for="c-36028458">[1 more]</label></div><br/><div class="children"><div class="content">Is there a benchmark for retrieval from multiple ft documents? I tried the LangchainQA with Pinecone and wasn&#x27;t impressed with the search result when using it on my Zotero library.</div><br/></div></div><div id="36028725" class="c"><input type="checkbox" id="c-36028725" checked=""/><div class="controls bullet"><span class="by">bohlenlabs</span><span>|</span><a href="#36028458">prev</a><span>|</span><a href="#36027915">next</a><span>|</span><label class="collapse" for="c-36028725">[-]</label><label class="expand" for="c-36028725">[1 more]</label></div><br/><div class="children"><div class="content">So many good links here, thanks to the OP for sharing, and to all commenters as well!</div><br/></div></div><div id="36027915" class="c"><input type="checkbox" id="c-36027915" checked=""/><div class="controls bullet"><span class="by">yosito</span><span>|</span><a href="#36028725">prev</a><span>|</span><a href="#36026848">next</a><span>|</span><label class="collapse" for="c-36027915">[-]</label><label class="expand" for="c-36027915">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Put any and all your files into the source_documents directory<p>Why? Why can&#x27;t I define any directory (my existing Obsidian vault, for example) as the source directory?</div><br/><div id="36027961" class="c"><input type="checkbox" id="c-36027961" checked=""/><div class="controls bullet"><span class="by">carlio</span><span>|</span><a href="#36027915">parent</a><span>|</span><a href="#36026848">next</a><span>|</span><label class="collapse" for="c-36027961">[-]</label><label class="expand" for="c-36027961">[1 more]</label></div><br/><div class="children"><div class="content">You can by setting an environment variable - <a href="https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;blob&#x2F;main&#x2F;ingest.py#L35">https:&#x2F;&#x2F;github.com&#x2F;imartinez&#x2F;privateGPT&#x2F;blob&#x2F;main&#x2F;ingest.py#...</a></div><br/></div></div></div></div><div id="36027595" class="c"><input type="checkbox" id="c-36027595" checked=""/><div class="controls bullet"><span class="by">jaimehrubiks</span><span>|</span><a href="#36026848">prev</a><span>|</span><a href="#36028096">next</a><span>|</span><label class="collapse" for="c-36027595">[-]</label><label class="expand" for="c-36027595">[1 more]</label></div><br/><div class="children"><div class="content">If you select a gpt4all model like GPT-J can this be used commercially or is there other dependency that limits the license?</div><br/></div></div><div id="36028096" class="c"><input type="checkbox" id="c-36028096" checked=""/><div class="controls bullet"><span class="by">keeptrying</span><span>|</span><a href="#36027595">prev</a><span>|</span><a href="#36027568">next</a><span>|</span><label class="collapse" for="c-36028096">[-]</label><label class="expand" for="c-36028096">[1 more]</label></div><br/><div class="children"><div class="content">This is the future.</div><br/></div></div><div id="36027568" class="c"><input type="checkbox" id="c-36027568" checked=""/><div class="controls bullet"><span class="by">LaurenceRitchie</span><span>|</span><a href="#36028096">prev</a><span>|</span><a href="#36028663">next</a><span>|</span><label class="collapse" for="c-36027568">[-]</label><label class="expand" for="c-36027568">[2 more]</label></div><br/><div class="children"><div class="content">Self promotion: We&#x27;re working on a similar invite only iOS app version if anyone is interested <a href="https:&#x2F;&#x2F;forms.gle&#x2F;wv4sqvHLjX8eVpMb6" rel="nofollow">https:&#x2F;&#x2F;forms.gle&#x2F;wv4sqvHLjX8eVpMb6</a> Data will be private &amp; stored on your device.</div><br/><div id="36028624" class="c"><input type="checkbox" id="c-36028624" checked=""/><div class="controls bullet"><span class="by">weikju</span><span>|</span><a href="#36027568">parent</a><span>|</span><a href="#36028663">next</a><span>|</span><label class="collapse" for="c-36028624">[-]</label><label class="expand" for="c-36028624">[1 more]</label></div><br/><div class="children"><div class="content">Is it private if it&#x27;s using ChatGPT?</div><br/></div></div></div></div><div id="36028663" class="c"><input type="checkbox" id="c-36028663" checked=""/><div class="controls bullet"><span class="by">udev4096</span><span>|</span><a href="#36027568">prev</a><span>|</span><label class="collapse" for="c-36028663">[-]</label><label class="expand" for="c-36028663">[4 more]</label></div><br/><div class="children"><div class="content">I posted it 9 days ago and somehow this one gets the attention. The same freaking post. Unbelievable<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35914810" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35914810</a></div><br/><div id="36028700" class="c"><input type="checkbox" id="c-36028700" checked=""/><div class="controls bullet"><span class="by">dutchbrit</span><span>|</span><a href="#36028663">parent</a><span>|</span><label class="collapse" for="c-36028700">[-]</label><label class="expand" for="c-36028700">[3 more]</label></div><br/><div class="children"><div class="content">Day and time when you post something matters a lot unfortunately.</div><br/><div id="36028709" class="c"><input type="checkbox" id="c-36028709" checked=""/><div class="controls bullet"><span class="by">udev4096</span><span>|</span><a href="#36028663">root</a><span>|</span><a href="#36028700">parent</a><span>|</span><label class="collapse" for="c-36028709">[-]</label><label class="expand" for="c-36028709">[2 more]</label></div><br/><div class="children"><div class="content">And now I am getting downvoted for it. Perfect</div><br/><div id="36028933" class="c"><input type="checkbox" id="c-36028933" checked=""/><div class="controls bullet"><span class="by">andruby</span><span>|</span><a href="#36028663">root</a><span>|</span><a href="#36028709">parent</a><span>|</span><label class="collapse" for="c-36028933">[-]</label><label class="expand" for="c-36028933">[1 more]</label></div><br/><div class="children"><div class="content">possibly because the tone of your post and that it doesn&#x27;t actually add to the conversation.<p>weekday and time of day have an impact. Thousands of entries are posted each day (see <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newest" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newest</a>) most never get a comment or upvote.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>