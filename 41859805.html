<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1729155666290" as="style"/><link rel="stylesheet" href="styles.css?v=1729155666290"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://nvlabs.github.io/Sana/">Efficient high-resolution image synthesis with linear diffusion transformer</a> <span class="domain">(<a href="https://nvlabs.github.io">nvlabs.github.io</a>)</span></div><div class="subtext"><span>Vt71fcAqt7</span> | <span>35 comments</span></div><br/><div><div id="41866579" class="c"><input type="checkbox" id="c-41866579" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#41861846">next</a><span>|</span><label class="collapse" for="c-41866579">[-]</label><label class="expand" for="c-41866579">[1 more]</label></div><br/><div class="children"><div class="content">There really are some “free lunches” in generative models. Really impressive work by this group. Ultimately, their model may not be the winner, because so much of what makes a good image gen model is the images and captioning that go into it, and the fine-tuning for aesthetic quality — something Midjourney and Flux both excel at. But the architecture here certainly will get into the hands of the people who can make the next great model.<p>Looking forward to it. This space just keeps getting more interesting.</div><br/></div></div><div id="41861846" class="c"><input type="checkbox" id="c-41861846" checked=""/><div class="controls bullet"><span class="by">cube2222</span><span>|</span><a href="#41866579">prev</a><span>|</span><a href="#41866524">next</a><span>|</span><label class="collapse" for="c-41861846">[-]</label><label class="expand" for="c-41861846">[13 more]</label></div><br/><div class="children"><div class="content">This looks like quite a huge breakthrough, unless I&#x27;m missing something?<p>~25x faster performance than Flux-dev, while offering comparable quality in benchmarks. And visually the examples (surely cherry-picked, but still) look great!<p>Especially since with GenAI the best way to get good results is to just generate a large amount of them and pick the best (imo). Performance like this will make that much easier&#x2F;faster&#x2F;cheaper.<p>Code is unfortunately &quot;(Coming soon)&quot; for now. Can&#x27;t wait to play with it!</div><br/><div id="41865018" class="c"><input type="checkbox" id="c-41865018" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#41861846">parent</a><span>|</span><a href="#41864501">next</a><span>|</span><label class="collapse" for="c-41865018">[-]</label><label class="expand" for="c-41865018">[5 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  &gt; surely cherry-picked
</code></pre>
As someone who works in generative vision, this is one of the most frustrating aspects (especially for those with less GPU resources). There&#x27;s been a silent competition for picking the best images and not showing random results (even when there are random results they may be a selected batch). So it is hard to judge actual quality until you can play around.<p>Also, I&#x27;m not sure what laptop that is but they say 0.37s to generate a 1024x1024 image on a 4090. They also mention that it requires 16GB VRAM. But that laptop looks like a MSI Titan, which has a 4090, and correct me if I&#x27;m wrong, but I think the 4090 is the only mobile card with 16GB?[0] (I know desktop graphics have 16 for most cards). The laptop demo takes 4s to generate a 1024x1024 image. But they are chopped down quite a bit[1]<p>I wonder if that&#x27;s with or without TensorRT<p>[0] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_Nvidia_graphics_processing_units#GeForce_40_series" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_Nvidia_graphics_proces...</a><p>[1] <a href="https:&#x2F;&#x2F;gpu.userbenchmark.com&#x2F;Compare&#x2F;Nvidia-RTX-4090-Laptop-vs-Nvidia-RTX-4090&#x2F;m2036852vs4136" rel="nofollow">https:&#x2F;&#x2F;gpu.userbenchmark.com&#x2F;Compare&#x2F;Nvidia-RTX-4090-Laptop...</a></div><br/><div id="41867104" class="c"><input type="checkbox" id="c-41867104" checked=""/><div class="controls bullet"><span class="by">bemmu</span><span>|</span><a href="#41861846">root</a><span>|</span><a href="#41865018">parent</a><span>|</span><a href="#41865131">next</a><span>|</span><label class="collapse" for="c-41867104">[-]</label><label class="expand" for="c-41867104">[2 more]</label></div><br/><div class="children"><div class="content">0.37s is only 11x away from realtime 30fps. I wonder if that will enable some cool new popular application for it besides batch image generation.</div><br/><div id="41867207" class="c"><input type="checkbox" id="c-41867207" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#41861846">root</a><span>|</span><a href="#41867104">parent</a><span>|</span><a href="#41865131">next</a><span>|</span><label class="collapse" for="c-41867207">[-]</label><label class="expand" for="c-41867207">[1 more]</label></div><br/><div class="children"><div class="content">You can do much much better with GANs at that resolution. I&#x27;m sure you could combine the two for upsampling</div><br/></div></div></div></div><div id="41865131" class="c"><input type="checkbox" id="c-41865131" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#41861846">root</a><span>|</span><a href="#41865018">parent</a><span>|</span><a href="#41867104">prev</a><span>|</span><a href="#41864501">next</a><span>|</span><label class="collapse" for="c-41865131">[-]</label><label class="expand" for="c-41865131">[2 more]</label></div><br/><div class="children"><div class="content">The GeForce RTX 3080 Mobile and GeForce RTX 3080 Ti Mobile also have 16 GB versions as noted directly above the linked section on [0].</div><br/><div id="41865443" class="c"><input type="checkbox" id="c-41865443" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#41861846">root</a><span>|</span><a href="#41865131">parent</a><span>|</span><a href="#41864501">next</a><span>|</span><label class="collapse" for="c-41865443">[-]</label><label class="expand" for="c-41865443">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! I forgot about that (usually mobile cards have less VRAM, not more lol). I don&#x27;t necessarily doubt the paper&#x27;s generation claim, but there are of course many factors that could help clarify what that number actually represents</div><br/></div></div></div></div></div></div><div id="41864501" class="c"><input type="checkbox" id="c-41864501" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#41861846">parent</a><span>|</span><a href="#41865018">prev</a><span>|</span><a href="#41861942">next</a><span>|</span><label class="collapse" for="c-41864501">[-]</label><label class="expand" for="c-41864501">[1 more]</label></div><br/><div class="children"><div class="content">&gt;<i>This looks like quite a huge breakthrough, unless I&#x27;m missing something?</i><p>Looking at their methodology,  it seems like it&#x27;s more of an accumulation of existing good ideas into the one model.<p>If it performs as well as they say, perhaps you can say the breakthrough is discovering just how much can be gained by combining recent advances.<p>It&#x27;s sitting on just the edge of sounding too good to be true to me.  I will certainly be pleased if it holds up to scrutiny.</div><br/></div></div><div id="41861942" class="c"><input type="checkbox" id="c-41861942" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#41861846">parent</a><span>|</span><a href="#41864501">prev</a><span>|</span><a href="#41863225">next</a><span>|</span><label class="collapse" for="c-41861942">[-]</label><label class="expand" for="c-41861942">[1 more]</label></div><br/><div class="children"><div class="content">If you read closer to the benchmark, it seems to be slightly worse than FLUX [dev] on prompt adherence and quality. However, the best is to evaluate the result oneself, and the track-record of PixArt Sigma (from the same author?) is pretty good!</div><br/></div></div><div id="41863225" class="c"><input type="checkbox" id="c-41863225" checked=""/><div class="controls bullet"><span class="by">Archit3ch</span><span>|</span><a href="#41861846">parent</a><span>|</span><a href="#41861942">prev</a><span>|</span><a href="#41866524">next</a><span>|</span><label class="collapse" for="c-41863225">[-]</label><label class="expand" for="c-41863225">[5 more]</label></div><br/><div class="children"><div class="content">If you generate 25x more images, you can afford to cherry-pick.</div><br/><div id="41864455" class="c"><input type="checkbox" id="c-41864455" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#41861846">root</a><span>|</span><a href="#41863225">parent</a><span>|</span><a href="#41863739">next</a><span>|</span><label class="collapse" for="c-41864455">[-]</label><label class="expand" for="c-41864455">[1 more]</label></div><br/><div class="children"><div class="content">That transfers computer time to user time.    It&#x27;s great when you want variations,  less so when you want precision and consistency.   Picking the best image tires the brain quite quickly, you have to take into account the at a glance quality without it overriding the detail quality.<p>I&#x27;d be curious to see how a vision model would go if it were finetuned to select the best image match to a given criteria.<p>It&#x27;s possible that you could do O1 style training to build a final stage auto-cherrypicker.</div><br/></div></div><div id="41863739" class="c"><input type="checkbox" id="c-41863739" checked=""/><div class="controls bullet"><span class="by">cube2222</span><span>|</span><a href="#41861846">root</a><span>|</span><a href="#41863225">parent</a><span>|</span><a href="#41864455">prev</a><span>|</span><a href="#41866524">next</a><span>|</span><label class="collapse" for="c-41863739">[-]</label><label class="expand" for="c-41863739">[3 more]</label></div><br/><div class="children"><div class="content">It would be interesting to have benchmarks that take this into account (maybe they already do or I’m misunderstanding how those benchmarks work). I.e. when comparing quality between two different models of vastly different performance, you could be doing best-of-n in the faster model.</div><br/><div id="41863919" class="c"><input type="checkbox" id="c-41863919" checked=""/><div class="controls bullet"><span class="by">Vt71fcAqt7</span><span>|</span><a href="#41861846">root</a><span>|</span><a href="#41863739">parent</a><span>|</span><a href="#41866524">next</a><span>|</span><label class="collapse" for="c-41863919">[-]</label><label class="expand" for="c-41863919">[2 more]</label></div><br/><div class="children"><div class="content">That sounds like it could be an intiresting metric. Worth noting that there is a difference between an algorithmic &quot;best of n&quot; selection (via eg. an FID score) vs. manual cherry picking which takes more factors into account such as user preference and also takes time to evaluate, which is what GP was suggesting.</div><br/><div id="41864044" class="c"><input type="checkbox" id="c-41864044" checked=""/><div class="controls bullet"><span class="by">cube2222</span><span>|</span><a href="#41861846">root</a><span>|</span><a href="#41863919">parent</a><span>|</span><a href="#41866524">next</a><span>|</span><label class="collapse" for="c-41864044">[-]</label><label class="expand" for="c-41864044">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I’d likely just pick the best scoring one (that is, the pick is made by the evaluation tool, not the model) - to simulate “whatever the receiver deemed best for what they wanted”.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41866524" class="c"><input type="checkbox" id="c-41866524" checked=""/><div class="controls bullet"><span class="by">wiradikusuma</span><span>|</span><a href="#41861846">prev</a><span>|</span><a href="#41864743">next</a><span>|</span><label class="collapse" for="c-41866524">[-]</label><label class="expand" for="c-41866524">[1 more]</label></div><br/><div class="children"><div class="content">In my opinion, what&#x27;s missing in these &quot;image GenAI&quot; tech is the ability to generate subsequent images consistently.<p>That would be useful for e.g. book illustration, comic strips, icon sets. Otherwise, people would think you pick those images all over the internet and not from one source&#x2F;theme.</div><br/></div></div><div id="41864743" class="c"><input type="checkbox" id="c-41864743" checked=""/><div class="controls bullet"><span class="by">cpldcpu</span><span>|</span><a href="#41866524">prev</a><span>|</span><a href="#41862602">next</a><span>|</span><label class="collapse" for="c-41864743">[-]</label><label class="expand" for="c-41864743">[2 more]</label></div><br/><div class="children"><div class="content">&gt;We introduce a new Autoencoder (AE) that aggressively increases the scaling factor to 32. Compared with AE-F8, our AE-F32 outputs 16× fewer latent tokens,<p>Basically they compress&#x2F;decompress the images more, which means they need less computation during generation. But on the flip side this should mean less variability.<p>Isn&#x27;t this more of a design trade-off than an optimization?</div><br/><div id="41865236" class="c"><input type="checkbox" id="c-41865236" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#41864743">parent</a><span>|</span><a href="#41862602">next</a><span>|</span><label class="collapse" for="c-41865236">[-]</label><label class="expand" for="c-41865236">[1 more]</label></div><br/><div class="children"><div class="content">It might not be compressing more (haven&#x27;t yet looked at the paper).  You can have fewer but larger tokens for the same amount of data.<p>It would decrease the workload by having fewer things to compare against balanced against workload per comparison.   For normal N² that makes sense but the page says.<p><i>We introduce a new linear DiT, replacing vanilla quadratic attention and reducing complexity from O(N²) to O(N) Mix-FFN</i><p>So not sure what&#x27;s up there.</div><br/></div></div></div></div><div id="41862602" class="c"><input type="checkbox" id="c-41862602" checked=""/><div class="controls bullet"><span class="by">lpasselin</span><span>|</span><a href="#41864743">prev</a><span>|</span><a href="#41864489">next</a><span>|</span><label class="collapse" for="c-41862602">[-]</label><label class="expand" for="c-41862602">[1 more]</label></div><br/><div class="children"><div class="content">This comes from the same group as the EfficientViT model. A few months ago, their EfficientViT model was the only modern and small ViT style model I could find that had raw pytorch code available. No dependencies to the shitty framework and libraries that other ViT are using.</div><br/></div></div><div id="41860976" class="c"><input type="checkbox" id="c-41860976" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#41864489">prev</a><span>|</span><a href="#41860021">next</a><span>|</span><label class="collapse" for="c-41860976">[-]</label><label class="expand" for="c-41860976">[1 more]</label></div><br/><div class="children"><div class="content">Image models are going to be widely available. They&#x27;ll probably be a dime a dozen soon. It&#x27;s great that an increasing number of models are going open, because these are the ecosystems that will grow.<p>3D models (sculpts, texture, retopo, etc.) are following a similar trend and trajectory.<p>Open video models are lagging behind by several years. While CogVideo and Pyramid are promising,  video models are petabyte scale and so much more costly to build and train.<p>I&#x27;m hoping video becomes free and cheap, but it&#x27;s looking like we might be waiting a while.<p>Major kudos to all of the teams building and training open source models!</div><br/></div></div><div id="41860021" class="c"><input type="checkbox" id="c-41860021" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#41860976">prev</a><span>|</span><a href="#41861676">next</a><span>|</span><label class="collapse" for="c-41860021">[-]</label><label class="expand" for="c-41860021">[2 more]</label></div><br/><div class="children"><div class="content">&gt; (e.g. Flux-12B), being 20 times smaller and 100+ times faster in measured throughput. Moreover, Sana-0.6B can be deployed on a 16GB laptop GPU, taking less than 1 second to generate a 1024 × 1024 resolution image.</div><br/></div></div><div id="41862727" class="c"><input type="checkbox" id="c-41862727" checked=""/><div class="controls bullet"><span class="by">henning</span><span>|</span><a href="#41861676">prev</a><span>|</span><label class="collapse" for="c-41862727">[-]</label><label class="expand" for="c-41862727">[11 more]</label></div><br/><div class="children"><div class="content">Trained on stolen copyrighted work? Or fairly licensed? Not that AI bros give a shit about the law or treating people fairly.</div><br/><div id="41863751" class="c"><input type="checkbox" id="c-41863751" checked=""/><div class="controls bullet"><span class="by">david-gpu</span><span>|</span><a href="#41862727">parent</a><span>|</span><a href="#41865266">next</a><span>|</span><label class="collapse" for="c-41863751">[-]</label><label class="expand" for="c-41863751">[6 more]</label></div><br/><div class="children"><div class="content">Do you believe that human artists should pay license fees for all the art that they have ever seen, studied or drawn inspiration from? Whether graphic artists, writers or what have you.</div><br/><div id="41865729" class="c"><input type="checkbox" id="c-41865729" checked=""/><div class="controls bullet"><span class="by">accrual</span><span>|</span><a href="#41862727">root</a><span>|</span><a href="#41863751">parent</a><span>|</span><a href="#41863881">next</a><span>|</span><label class="collapse" for="c-41865729">[-]</label><label class="expand" for="c-41865729">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m still trying to figure out which side to be on. On one hand I agree with you - there would be little modern art if it wasn&#x27;t for centuries of preceding inspiration.<p>On the other hand, at least one suit was making headway as of 2024-08-14, about 2 months ago [0]. It seems like there must be some merit to GPs claim if this is moving forward. But again, I&#x27;m still trying to figure out where to stand.<p>[0] <a href="https:&#x2F;&#x2F;arstechnica.com&#x2F;tech-policy&#x2F;2024&#x2F;08&#x2F;artists-claim-big-win-in-copyright-suit-fighting-ai-image-generators&#x2F;" rel="nofollow">https:&#x2F;&#x2F;arstechnica.com&#x2F;tech-policy&#x2F;2024&#x2F;08&#x2F;artists-claim-bi...</a></div><br/><div id="41867524" class="c"><input type="checkbox" id="c-41867524" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#41862727">root</a><span>|</span><a href="#41865729">parent</a><span>|</span><a href="#41863881">next</a><span>|</span><label class="collapse" for="c-41867524">[-]</label><label class="expand" for="c-41867524">[1 more]</label></div><br/><div class="children"><div class="content">Or not.    They claimed a big win but it was not at all that. It was essentially not completely falling at the first hurdle.  All bar one of their claims were dismissed.<p>The remaining claim may not be a good claim, but it isn&#x27;t completely laughable.<p><a href="https:&#x2F;&#x2F;cdn.arstechnica.net&#x2F;wp-content&#x2F;uploads&#x2F;2024&#x2F;08&#x2F;Andersen-v-Stability-AI-" rel="nofollow">https:&#x2F;&#x2F;cdn.arstechnica.net&#x2F;wp-content&#x2F;uploads&#x2F;2024&#x2F;08&#x2F;Ander...</a>
Order-on-Motions-to-Dismiss-8-12-2024.pdf<p><i>In October 2023, I largely granted the motions to dismiss brought by defendants Stability, Midjourney and DeviantArt. The only claim that survived was the direct infringement claim asserted against Stability, based on Stability’s alleged “creation and use of ‘Training Images’ scraped from the internet into the LAION datasets and then used to train Stable Diffusion.”</i><p>I think you could have grounds for saying that construction of LAION violates copyright which would be covered by this.  It doesn&#x27;t necessarily mean training on LAION is copyright violation.<p>None of this has been decided.   It might be wrong.<p>The rest of the case was &quot;Not even wrong&quot;</div><br/></div></div></div></div><div id="41863881" class="c"><input type="checkbox" id="c-41863881" checked=""/><div class="controls bullet"><span class="by">kadoban</span><span>|</span><a href="#41862727">root</a><span>|</span><a href="#41863751">parent</a><span>|</span><a href="#41865729">prev</a><span>|</span><a href="#41865266">next</a><span>|</span><label class="collapse" for="c-41863881">[-]</label><label class="expand" for="c-41863881">[3 more]</label></div><br/><div class="children"><div class="content">Human artists get in copyright trouble if the spam out a copy of something they studied and sell it. The businesses using AI artists do not seem to.</div><br/><div id="41864676" class="c"><input type="checkbox" id="c-41864676" checked=""/><div class="controls bullet"><span class="by">david-gpu</span><span>|</span><a href="#41862727">root</a><span>|</span><a href="#41863881">parent</a><span>|</span><a href="#41864492">next</a><span>|</span><label class="collapse" for="c-41864676">[-]</label><label class="expand" for="c-41864676">[1 more]</label></div><br/><div class="children"><div class="content">Artists who think that their copyright has been infringed upon are free to sue, just as they do when the alleged plagiarist is a human. I fail to see the difference.</div><br/></div></div><div id="41864492" class="c"><input type="checkbox" id="c-41864492" checked=""/><div class="controls bullet"><span class="by">ClassyJacket</span><span>|</span><a href="#41862727">root</a><span>|</span><a href="#41863881">parent</a><span>|</span><a href="#41864676">prev</a><span>|</span><a href="#41865266">next</a><span>|</span><label class="collapse" for="c-41864492">[-]</label><label class="expand" for="c-41864492">[1 more]</label></div><br/><div class="children"><div class="content">Image generation models don&#x27;t do that either</div><br/></div></div></div></div></div></div><div id="41865266" class="c"><input type="checkbox" id="c-41865266" checked=""/><div class="controls bullet"><span class="by">zaptrem</span><span>|</span><a href="#41862727">parent</a><span>|</span><a href="#41863751">prev</a><span>|</span><a href="#41864499">next</a><span>|</span><label class="collapse" for="c-41865266">[-]</label><label class="expand" for="c-41865266">[3 more]</label></div><br/><div class="children"><div class="content">Copyright means you own the right to reproduce a given work. It doesn&#x27;t mean you own the <i>ideas</i> behind that work. If that were true, then all of modern music would instantly be a copyright violation.</div><br/><div id="41865935" class="c"><input type="checkbox" id="c-41865935" checked=""/><div class="controls bullet"><span class="by">jrm4</span><span>|</span><a href="#41862727">root</a><span>|</span><a href="#41865266">parent</a><span>|</span><a href="#41864499">next</a><span>|</span><label class="collapse" for="c-41865935">[-]</label><label class="expand" for="c-41865935">[2 more]</label></div><br/><div class="children"><div class="content">Did you see the results of the Marvin Gaye &#x2F; Pharrell Williams case? Sadly, it&#x27;s getting pretty close to that.</div><br/><div id="41865949" class="c"><input type="checkbox" id="c-41865949" checked=""/><div class="controls bullet"><span class="by">zaptrem</span><span>|</span><a href="#41862727">root</a><span>|</span><a href="#41865935">parent</a><span>|</span><a href="#41864499">next</a><span>|</span><label class="collapse" for="c-41865949">[-]</label><label class="expand" for="c-41865949">[1 more]</label></div><br/><div class="children"><div class="content">Exactly what the labels want, since if that type of thing keeps going their way they will soon own not just every song like they currently do, but every future song forever.</div><br/></div></div></div></div></div></div><div id="41864499" class="c"><input type="checkbox" id="c-41864499" checked=""/><div class="controls bullet"><span class="by">ClassyJacket</span><span>|</span><a href="#41862727">parent</a><span>|</span><a href="#41865266">prev</a><span>|</span><label class="collapse" for="c-41864499">[-]</label><label class="expand" for="c-41864499">[1 more]</label></div><br/><div class="children"><div class="content">This argument is only fair if you also think human artists should be banned, from birth, from ever looking at any other art. After all that would be training on stolen copyrighted work.</div><br/></div></div></div></div></div></div></div></div></div></body></html>