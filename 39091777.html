<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1706000462890" as="style"/><link rel="stylesheet" href="styles.css?v=1706000462890"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://lightning.ai/lightning-ai/studios/code-lora-from-scratch?view=public&amp;section=all">LoRA from scratch: implementation for LLM finetuning</a> <span class="domain">(<a href="https://lightning.ai">lightning.ai</a>)</span></div><div class="subtext"><span>rasbt</span> | <span>81 comments</span></div><br/><div><div id="39092491" class="c"><input type="checkbox" id="c-39092491" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#39093789">next</a><span>|</span><label class="collapse" for="c-39092491">[-]</label><label class="expand" for="c-39092491">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been keeping track of the techniques through Maxime Labonne&#x27;s LLMs 101: <a href="https:&#x2F;&#x2F;github.com&#x2F;mlabonne&#x2F;llm-course#4-supervised-fine-tuning">https:&#x2F;&#x2F;github.com&#x2F;mlabonne&#x2F;llm-course#4-supervised-fine-tun...</a></div><br/><div id="39093419" class="c"><input type="checkbox" id="c-39093419" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#39092491">parent</a><span>|</span><a href="#39093789">next</a><span>|</span><label class="collapse" for="c-39093419">[-]</label><label class="expand" for="c-39093419">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the resource.  It seems useful enough to warrant its own thread here.</div><br/></div></div></div></div><div id="39093789" class="c"><input type="checkbox" id="c-39093789" checked=""/><div class="controls bullet"><span class="by">rsweeney21</span><span>|</span><a href="#39092491">prev</a><span>|</span><a href="#39094278">next</a><span>|</span><label class="collapse" for="c-39093789">[-]</label><label class="expand" for="c-39093789">[23 more]</label></div><br/><div class="children"><div class="content">It&#x27;s still strange to me to work in a field of computer science where we say things like &quot;we&#x27;re not exactly sure how these numbers (hyper parameters) affect the result, so just try a bunch of different values and see which one works best.&quot;</div><br/><div id="39095542" class="c"><input type="checkbox" id="c-39095542" checked=""/><div class="controls bullet"><span class="by">TacticalCoder</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39094333">next</a><span>|</span><label class="collapse" for="c-39095542">[-]</label><label class="expand" for="c-39095542">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;we&#x27;re not exactly sure how these numbers (hyper parameters) affect the result, so just try a bunch of different values and see which one works best.&quot;<p>Isn&#x27;t it the same for anything that uses a Monte Carlo simulation to find a value? At times you&#x27;ll end up on a local maxima (instead of the best&#x2F;correct) answer, but it works.<p>We cannot solve something used a closed formula so we just do a billion (or whatever) random samplings and find what we&#x27;re after.<p>I&#x27;m not saying it&#x27;s the same for LLMs but &quot;trying a bunch of different values and see which one works best&quot; is something we do a lot.</div><br/></div></div><div id="39094333" class="c"><input type="checkbox" id="c-39094333" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39095542">prev</a><span>|</span><a href="#39095596">next</a><span>|</span><label class="collapse" for="c-39094333">[-]</label><label class="expand" for="c-39094333">[9 more]</label></div><br/><div class="children"><div class="content">I feel like it&#x27;s the difference between something that has been engineered and something that has been discovered.<p>I feel like most of our industry up until now has been engineered.<p>LLMs were discovered.</div><br/><div id="39100718" class="c"><input type="checkbox" id="c-39100718" checked=""/><div class="controls bullet"><span class="by">mejutoco</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39094333">parent</a><span>|</span><a href="#39099487">next</a><span>|</span><label class="collapse" for="c-39100718">[-]</label><label class="expand" for="c-39100718">[1 more]</label></div><br/><div class="children"><div class="content">I believe, from what I saw in Mathematics, this is a matter of taste. Discovered or invented are 2 perspectives. Some people prefer to think that light is reaching in previously dark corners of knowledge waiting to be discovered(discover). Others prefer to think that by force of genius they brought the thing into the world.<p>To me, personally, these are 2 sides of the coin, without one having more proof than the other.</div><br/></div></div><div id="39099487" class="c"><input type="checkbox" id="c-39099487" checked=""/><div class="controls bullet"><span class="by">herval</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39094333">parent</a><span>|</span><a href="#39100718">prev</a><span>|</span><a href="#39095628">next</a><span>|</span><label class="collapse" for="c-39099487">[-]</label><label class="expand" for="c-39099487">[2 more]</label></div><br/><div class="children"><div class="content">LLMs were very much engineered... the exact results they yield are hard to determine since they&#x27;re large statistical models, but I don&#x27;t think that categorizes the LLMs themselves as a &#x27;discovery&#x27; (like say Penicilin)</div><br/><div id="39100615" class="c"><input type="checkbox" id="c-39100615" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39099487">parent</a><span>|</span><a href="#39095628">next</a><span>|</span><label class="collapse" for="c-39100615">[-]</label><label class="expand" for="c-39100615">[1 more]</label></div><br/><div class="children"><div class="content">There’s an argument that all maths are discovered instead of invented or engineered. LLM hardware certainly is hard engineering but the numbers you put in it aren’t, once you have them; if you stumbled upon them by chance or they were revealed to you in your sleep it’d work just as well. (‘ollama run mixtral’ is good enough for a dream to me!)</div><br/></div></div></div></div><div id="39095628" class="c"><input type="checkbox" id="c-39095628" checked=""/><div class="controls bullet"><span class="by">SkyMarshal</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39094333">parent</a><span>|</span><a href="#39099487">prev</a><span>|</span><a href="#39094534">next</a><span>|</span><label class="collapse" for="c-39095628">[-]</label><label class="expand" for="c-39095628">[1 more]</label></div><br/><div class="children"><div class="content">If the Black Swan model of science is true, then most of the consequential innovations and advances are discovered rather than engineered.</div><br/></div></div><div id="39094534" class="c"><input type="checkbox" id="c-39094534" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39094333">parent</a><span>|</span><a href="#39095628">prev</a><span>|</span><a href="#39094632">next</a><span>|</span><label class="collapse" for="c-39094534">[-]</label><label class="expand" for="c-39094534">[3 more]</label></div><br/><div class="children"><div class="content">I understand your distinction, I think, but I would say it is more engineering than ever. It&#x27;s like the early days of the steam engine or firearms development. It&#x27;s not a hard science, not formal analysis, it&#x27;s engineering: tinkering, testing, experimenting, iterating.</div><br/><div id="39095338" class="c"><input type="checkbox" id="c-39095338" checked=""/><div class="controls bullet"><span class="by">peddling-brink</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39094534">parent</a><span>|</span><a href="#39095695">next</a><span>|</span><label class="collapse" for="c-39095338">[-]</label><label class="expand" for="c-39095338">[1 more]</label></div><br/><div class="children"><div class="content">&gt; tinkering, testing, experimenting, iterating<p>But that describes science. <a href="http:&#x2F;&#x2F;imgur.com&#x2F;1h3K2TT&#x2F;" rel="nofollow">http:&#x2F;&#x2F;imgur.com&#x2F;1h3K2TT&#x2F;</a></div><br/></div></div><div id="39095695" class="c"><input type="checkbox" id="c-39095695" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39094534">parent</a><span>|</span><a href="#39095338">prev</a><span>|</span><a href="#39094632">next</a><span>|</span><label class="collapse" for="c-39095695">[-]</label><label class="expand" for="c-39095695">[1 more]</label></div><br/><div class="children"><div class="content">AI requires a lot of engineering. However, the engineering is not what makes working in AI interesting. It&#x27;s the plumbing, basically.</div><br/></div></div></div></div><div id="39094632" class="c"><input type="checkbox" id="c-39094632" checked=""/><div class="controls bullet"><span class="by">justanotheratom</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39094333">parent</a><span>|</span><a href="#39094534">prev</a><span>|</span><a href="#39095596">next</a><span>|</span><label class="collapse" for="c-39094632">[-]</label><label class="expand" for="c-39094632">[1 more]</label></div><br/><div class="children"><div class="content">and finally, this justifies the &quot;science&quot; in Computer Science.</div><br/></div></div></div></div><div id="39095596" class="c"><input type="checkbox" id="c-39095596" checked=""/><div class="controls bullet"><span class="by">SkyMarshal</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39094333">prev</a><span>|</span><a href="#39095128">next</a><span>|</span><label class="collapse" for="c-39095596">[-]</label><label class="expand" for="c-39095596">[1 more]</label></div><br/><div class="children"><div class="content">That bottom-up tinkering is kinda how CS started in the US, as observed by Dijkstra himself:  <a href="https:&#x2F;&#x2F;www.cs.utexas.edu&#x2F;users&#x2F;EWD&#x2F;transcriptions&#x2F;EWD06xx&#x2F;EWD611.html" rel="nofollow">https:&#x2F;&#x2F;www.cs.utexas.edu&#x2F;users&#x2F;EWD&#x2F;transcriptions&#x2F;EWD06xx&#x2F;E...</a><p>Ideally we want theoretical foundations, but sometimes random explorations are necessary to tease out enough data to construct or validate theory.</div><br/></div></div><div id="39095128" class="c"><input type="checkbox" id="c-39095128" checked=""/><div class="controls bullet"><span class="by">UberFly</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39095596">prev</a><span>|</span><a href="#39096747">next</a><span>|</span><label class="collapse" for="c-39095128">[-]</label><label class="expand" for="c-39095128">[1 more]</label></div><br/><div class="children"><div class="content">This is what researching different Stable Diffusion settings is like. You quickly learn that there&#x27;s a lot of guessing going on.</div><br/></div></div><div id="39096747" class="c"><input type="checkbox" id="c-39096747" checked=""/><div class="controls bullet"><span class="by">fierro</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39095128">prev</a><span>|</span><a href="#39096341">next</a><span>|</span><label class="collapse" for="c-39096747">[-]</label><label class="expand" for="c-39096747">[1 more]</label></div><br/><div class="children"><div class="content">we have no theories of intelligence.  We&#x27;re like people in the 1500s trying to figure out why and how people get sick, with no concept of bacteria, germs, transmission, etc</div><br/></div></div><div id="39096341" class="c"><input type="checkbox" id="c-39096341" checked=""/><div class="controls bullet"><span class="by">thatguysaguy</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39096747">prev</a><span>|</span><a href="#39099613">next</a><span>|</span><label class="collapse" for="c-39096341">[-]</label><label class="expand" for="c-39096341">[1 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t seen this key&#x2F;buzzword mentioned yet, so I think part of it is the fact that we&#x27;re now working on complex systems. This was already true (a social network is a complex system), but now we have the impenetrability of a complex system within the scope of a single process. It&#x27;s hard to figure out generalizable principles about this kind of thing!</div><br/></div></div><div id="39099613" class="c"><input type="checkbox" id="c-39099613" checked=""/><div class="controls bullet"><span class="by">FuckButtons</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39096341">prev</a><span>|</span><a href="#39094022">next</a><span>|</span><label class="collapse" for="c-39099613">[-]</label><label class="expand" for="c-39099613">[1 more]</label></div><br/><div class="children"><div class="content">I mean, it’s kind of in the name isn’t it? Computer <i>science</i>. Science is empirical, often poorly understood and even the best theories don’t fully explain all observations, especially when a field gets new tools to observe phenomena. It takes a while for a good theory to come along and make sense of everything in science and that seems like more or less exactly where we are today.</div><br/></div></div><div id="39094022" class="c"><input type="checkbox" id="c-39094022" checked=""/><div class="controls bullet"><span class="by">manojlds</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39099613">prev</a><span>|</span><a href="#39095660">next</a><span>|</span><label class="collapse" for="c-39094022">[-]</label><label class="expand" for="c-39094022">[1 more]</label></div><br/><div class="children"><div class="content">Divine benevolence</div><br/></div></div><div id="39095660" class="c"><input type="checkbox" id="c-39095660" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39094022">prev</a><span>|</span><a href="#39095305">next</a><span>|</span><label class="collapse" for="c-39095660">[-]</label><label class="expand" for="c-39095660">[1 more]</label></div><br/><div class="children"><div class="content">AI is more like gardening than engineering. You try things without knowing the outcome. And you wait a very long time to see the outcome.</div><br/></div></div><div id="39095305" class="c"><input type="checkbox" id="c-39095305" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39095660">prev</a><span>|</span><a href="#39095644">next</a><span>|</span><label class="collapse" for="c-39095305">[-]</label><label class="expand" for="c-39095305">[3 more]</label></div><br/><div class="children"><div class="content">This can be laid at the feet of Minsky and others who dismissed perceptrons because they couldn&#x27;t model nonlinear functions.  LLMs were never going to happen until modern CPUs and GPUs came along, but that doesn&#x27;t mean we couldn&#x27;t have a better theoretical foundation in place.  We are years behind where we should be.<p>When I worked in the games industry in the 1990s, it was &quot;common knowledge&quot; that neural nets were a dead end at best and a con job at worst.  Really a shame to lose so much time because a few senior authority figures warned everyone off.  We need to make sure that doesn&#x27;t happen this time.</div><br/><div id="39096098" class="c"><input type="checkbox" id="c-39096098" checked=""/><div class="controls bullet"><span class="by">spidersenses</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39095305">parent</a><span>|</span><a href="#39095644">next</a><span>|</span><label class="collapse" for="c-39096098">[-]</label><label class="expand" for="c-39096098">[2 more]</label></div><br/><div class="children"><div class="content">What is the point you&#x27;re trying to make?</div><br/><div id="39096374" class="c"><input type="checkbox" id="c-39096374" checked=""/><div class="controls bullet"><span class="by">CamperBob2</span><span>|</span><a href="#39093789">root</a><span>|</span><a href="#39096098">parent</a><span>|</span><a href="#39095644">next</a><span>|</span><label class="collapse" for="c-39096374">[-]</label><label class="expand" for="c-39096374">[1 more]</label></div><br/><div class="children"><div class="content"><i>What is the point you&#x27;re trying to make?</i><p>Answering the GP&#x27;s point regarding why deep learning textbooks, articles, and blog posts are full of sentences that begin with &quot;We think...&quot; and &quot;We&#x27;re not sure, but...&quot; and &quot;It appears that...&quot;<p>What&#x27;s yours?</div><br/></div></div></div></div></div></div><div id="39095644" class="c"><input type="checkbox" id="c-39095644" checked=""/><div class="controls bullet"><span class="by">stormfather</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39095305">prev</a><span>|</span><a href="#39094676">next</a><span>|</span><label class="collapse" for="c-39095644">[-]</label><label class="expand" for="c-39095644">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s how God programs</div><br/></div></div><div id="39094676" class="c"><input type="checkbox" id="c-39094676" checked=""/><div class="controls bullet"><span class="by">jejeyyy77</span><span>|</span><a href="#39093789">parent</a><span>|</span><a href="#39095644">prev</a><span>|</span><a href="#39094278">next</a><span>|</span><label class="collapse" for="c-39094676">[-]</label><label class="expand" for="c-39094676">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s a new paradigm</div><br/></div></div></div></div><div id="39094278" class="c"><input type="checkbox" id="c-39094278" checked=""/><div class="controls bullet"><span class="by">denysvitali</span><span>|</span><a href="#39093789">prev</a><span>|</span><a href="#39093873">next</a><span>|</span><label class="collapse" for="c-39094278">[-]</label><label class="expand" for="c-39094278">[11 more]</label></div><br/><div class="children"><div class="content">LoRA != LoRa. I keep on getting confused and hate that they chose to reuse an existing acronym</div><br/><div id="39094920" class="c"><input type="checkbox" id="c-39094920" checked=""/><div class="controls bullet"><span class="by">daemonologist</span><span>|</span><a href="#39094278">parent</a><span>|</span><a href="#39098003">next</a><span>|</span><label class="collapse" for="c-39094920">[-]</label><label class="expand" for="c-39094920">[2 more]</label></div><br/><div class="children"><div class="content">Likewise.  My day job is machine learning and I still, or maybe consequently, do a double-take every time I see the acronym with minimal context (like on the HN front page, where either usage would be normal).</div><br/><div id="39097871" class="c"><input type="checkbox" id="c-39097871" checked=""/><div class="controls bullet"><span class="by">travisgriggs</span><span>|</span><a href="#39094278">root</a><span>|</span><a href="#39094920">parent</a><span>|</span><a href="#39098003">next</a><span>|</span><label class="collapse" for="c-39097871">[-]</label><label class="expand" for="c-39097871">[1 more]</label></div><br/><div class="children"><div class="content">And my day job involves a lot of LoRa. I always do a double take on these. I&#x27;m grateful that at least the caps is now being done differently.</div><br/></div></div></div></div><div id="39098003" class="c"><input type="checkbox" id="c-39098003" checked=""/><div class="controls bullet"><span class="by">blopp99</span><span>|</span><a href="#39094278">parent</a><span>|</span><a href="#39094920">prev</a><span>|</span><a href="#39098168">next</a><span>|</span><label class="collapse" for="c-39098003">[-]</label><label class="expand" for="c-39098003">[1 more]</label></div><br/><div class="children"><div class="content">I hate the trend of software guys naming things after hardware related stuff</div><br/></div></div><div id="39098168" class="c"><input type="checkbox" id="c-39098168" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#39094278">parent</a><span>|</span><a href="#39098003">prev</a><span>|</span><a href="#39095071">next</a><span>|</span><label class="collapse" for="c-39098168">[-]</label><label class="expand" for="c-39098168">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what happens when people specialize and don&#x27;t pay attention to what&#x27;s going on outside their bubble.</div><br/><div id="39098626" class="c"><input type="checkbox" id="c-39098626" checked=""/><div class="controls bullet"><span class="by">HKH2</span><span>|</span><a href="#39094278">root</a><span>|</span><a href="#39098168">parent</a><span>|</span><a href="#39095071">next</a><span>|</span><label class="collapse" for="c-39098626">[-]</label><label class="expand" for="c-39098626">[1 more]</label></div><br/><div class="children"><div class="content">A quick websearch could fix that.</div><br/></div></div></div></div><div id="39095071" class="c"><input type="checkbox" id="c-39095071" checked=""/><div class="controls bullet"><span class="by">sbrother</span><span>|</span><a href="#39094278">parent</a><span>|</span><a href="#39098168">prev</a><span>|</span><a href="#39094385">next</a><span>|</span><label class="collapse" for="c-39095071">[-]</label><label class="expand" for="c-39095071">[3 more]</label></div><br/><div class="children"><div class="content">Wait, what is the meaning other than &quot;Low-Rank Adaptation&quot;? It&#x27;s hard to google the difference.</div><br/><div id="39095250" class="c"><input type="checkbox" id="c-39095250" checked=""/><div class="controls bullet"><span class="by">cristoperb</span><span>|</span><a href="#39094278">root</a><span>|</span><a href="#39095071">parent</a><span>|</span><a href="#39095235">next</a><span>|</span><label class="collapse" for="c-39095250">[-]</label><label class="expand" for="c-39095250">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the name of a &quot;Lo&quot;ng &quot;Ra&quot;nge wifi-like technology:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;LoRa" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;LoRa</a></div><br/></div></div><div id="39095235" class="c"><input type="checkbox" id="c-39095235" checked=""/><div class="controls bullet"><span class="by">boolemancer</span><span>|</span><a href="#39094278">root</a><span>|</span><a href="#39095071">parent</a><span>|</span><a href="#39095250">prev</a><span>|</span><a href="#39094385">next</a><span>|</span><label class="collapse" for="c-39095235">[-]</label><label class="expand" for="c-39095235">[1 more]</label></div><br/><div class="children"><div class="content">I assume the radio technology:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;LoRa" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;LoRa</a></div><br/></div></div></div></div><div id="39094385" class="c"><input type="checkbox" id="c-39094385" checked=""/><div class="controls bullet"><span class="by">sschueller</span><span>|</span><a href="#39094278">parent</a><span>|</span><a href="#39095071">prev</a><span>|</span><a href="#39093873">next</a><span>|</span><label class="collapse" for="c-39094385">[-]</label><label class="expand" for="c-39094385">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s unfortunate that those two so far unrelated technologies have the same acronym.</div><br/><div id="39098343" class="c"><input type="checkbox" id="c-39098343" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#39094278">root</a><span>|</span><a href="#39094385">parent</a><span>|</span><a href="#39093873">next</a><span>|</span><label class="collapse" for="c-39098343">[-]</label><label class="expand" for="c-39098343">[1 more]</label></div><br/><div class="children"><div class="content">LoRa the radio tech was first, so as far as I&#x27;m concerned it&#x27;s the canonical definition of the acronym. But I&#x27;m biased, I&#x27;m an embedded firmware dev</div><br/></div></div></div></div></div></div><div id="39093873" class="c"><input type="checkbox" id="c-39093873" checked=""/><div class="controls bullet"><span class="by">chenxi9649</span><span>|</span><a href="#39094278">prev</a><span>|</span><a href="#39095746">next</a><span>|</span><label class="collapse" for="c-39093873">[-]</label><label class="expand" for="c-39093873">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s still not too clear to me when we should fine tune versus RAG.<p>In the past, I used to believe that finetuning is mostly for model behavioral change, but recently it seems that certain companies are also using fine-tuning for knowledge addition.<p>What are the main use cases for fine tuning?</div><br/><div id="39093975" class="c"><input type="checkbox" id="c-39093975" checked=""/><div class="controls bullet"><span class="by">rasbt</span><span>|</span><a href="#39093873">parent</a><span>|</span><a href="#39094794">next</a><span>|</span><label class="collapse" for="c-39093975">[-]</label><label class="expand" for="c-39093975">[1 more]</label></div><br/><div class="children"><div class="content">I think the main use case remains behavior changes: instruction finetuning, finetuning for classification, etc. Knowledge addition to the weights is best done via pretraining. Or, if you have an external database or documentation that you want to query during the generation, RAG as you mention.<p>PS: All winners of the NeurIPS 2023 LLM Efficiency Challenge (finetuning the &quot;best&quot; LLM in 24h on 1 GPU) used LoRA or QLoRA (quantized LoRA).</div><br/></div></div><div id="39094794" class="c"><input type="checkbox" id="c-39094794" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#39093873">parent</a><span>|</span><a href="#39093975">prev</a><span>|</span><a href="#39099489">next</a><span>|</span><label class="collapse" for="c-39094794">[-]</label><label class="expand" for="c-39094794">[1 more]</label></div><br/><div class="children"><div class="content">Fine tuning is better than RAG when the additional data isn&#x27;t concise, or requires context.  This is because too much context (or &quot;unfocused&quot; context) can dilute prompt following behavior, and RAG doesn&#x27;t help the model with higher order token associations so you have to get lucky and pull what you need from the augmentation material, at which point it&#x27;s not much better than a fancy search engine.  Of course this is mostly an issue when you&#x27;re dealing with a specialized corpus with its own micro-dialect that isn&#x27;t well represented in public data sets, such as with government&#x2F;big corporation internal documents.</div><br/></div></div><div id="39099489" class="c"><input type="checkbox" id="c-39099489" checked=""/><div class="controls bullet"><span class="by">pizza</span><span>|</span><a href="#39093873">parent</a><span>|</span><a href="#39094794">prev</a><span>|</span><a href="#39094514">next</a><span>|</span><label class="collapse" for="c-39099489">[-]</label><label class="expand" for="c-39099489">[1 more]</label></div><br/><div class="children"><div class="content">These are autoregressive models. When you have a new type of sequence where future elements are able to be predicted from previous parts of the sequence, but in a new kind of way than the models have seen before, it would make sense to finetune.<p>Admittedly, that&#x27;s a pretty vague descriptor for how to decide what to do for a given data scenario, but it might be good enough as a rough heuristic. Now, whether knowledge addition falls under that, might be a question of taste (without experiments).</div><br/></div></div><div id="39094514" class="c"><input type="checkbox" id="c-39094514" checked=""/><div class="controls bullet"><span class="by">ignoramous</span><span>|</span><a href="#39093873">parent</a><span>|</span><a href="#39099489">prev</a><span>|</span><a href="#39095746">next</a><span>|</span><label class="collapse" for="c-39094514">[-]</label><label class="expand" for="c-39094514">[1 more]</label></div><br/><div class="children"><div class="content">From what I gather, fine-tuning is unreasonably effective [0] because in-context learning really depends on how powerful the underlying model is <i>and</i> just how you do RAG (process queries, retrieve embeddings, rank outcomes, etc [1]). Per this paper I read, fine-tuning <i>may</i> add new domain knowledge (but as another commenter pointed out, knowledge is better represented from data of the pre-training stage) or boost specific knowledge; while RAG is limited to <i>boosting</i> only; nevertheless, both techniques turn out to be similarly capable with different trade-offs [2].<p>--<p>[0] <i>Fast.ai: Can Models learn from one sample</i>, <a href="https:&#x2F;&#x2F;www.fast.ai&#x2F;posts&#x2F;2023-09-04-learning-jumps&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.fast.ai&#x2F;posts&#x2F;2023-09-04-learning-jumps&#x2F;</a> &#x2F; <a href="https:&#x2F;&#x2F;archive.is&#x2F;eJMPR" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;eJMPR</a><p>[1] <i>LlamaIndex: Advanced RAG</i>, <a href="https:&#x2F;&#x2F;blog.llamaindex.ai&#x2F;a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b" rel="nofollow">https:&#x2F;&#x2F;blog.llamaindex.ai&#x2F;a-cheat-sheet-and-some-recipes-fo...</a> &#x2F; <a href="https:&#x2F;&#x2F;archive.is&#x2F;qtBXX" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;qtBXX</a><p>[2] <i>Microsoft: RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study</i>, <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;html&#x2F;2401.08406v2#S6" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;html&#x2F;2401.08406v2#S6</a> &#x2F; <a href="https:&#x2F;&#x2F;archive.is&#x2F;UQ8Sa#S6" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;UQ8Sa#S6</a></div><br/></div></div></div></div><div id="39095746" class="c"><input type="checkbox" id="c-39095746" checked=""/><div class="controls bullet"><span class="by">somethingsome</span><span>|</span><a href="#39093873">prev</a><span>|</span><a href="#39093262">next</a><span>|</span><label class="collapse" for="c-39095746">[-]</label><label class="expand" for="c-39095746">[5 more]</label></div><br/><div class="children"><div class="content">Nice article, I&#x27;m not in this field, however, my understanding of the original paper was that the LoRA was applied only on the last dense layer, and not to all independently (maybe I misread it originally).<p>Digging a bit in why the implementation is like this in the link, I found that in QLoRA they used this and it seems to have some interesting effects, maybe adding a note on the QLoRA decision would be nice :)<p>I&#x27;m not sure I understand why it works though, my neophyte view was that applying LoRA to the last layer made sense, but, I do not wrap my mind on the rationale of applying it repeadly to each linear layer. Can someone explain their intuition?</div><br/><div id="39095840" class="c"><input type="checkbox" id="c-39095840" checked=""/><div class="controls bullet"><span class="by">icyfox</span><span>|</span><a href="#39095746">parent</a><span>|</span><a href="#39093262">next</a><span>|</span><label class="collapse" for="c-39095840">[-]</label><label class="expand" for="c-39095840">[4 more]</label></div><br/><div class="children"><div class="content">Like most things in ML, the answer of which layers to use come down to empirical evidence more than theory. In a typical Lora training pipeline, you freeze the contents of the base model and just adjust the Lora layers. The more layers you convert to lora layers the more degrees of freedom you have for the optimization.<p>There are some finetuning regimens that only recommend finetuning the last layer since this is theorized to have the &quot;highest order&quot; representation of the inputs. Other training regimens will finetune all layers. It&#x27;s largely data and problem dependent. Lora just mirrors this convention.</div><br/><div id="39097110" class="c"><input type="checkbox" id="c-39097110" checked=""/><div class="controls bullet"><span class="by">somethingsome</span><span>|</span><a href="#39095746">root</a><span>|</span><a href="#39095840">parent</a><span>|</span><a href="#39093262">next</a><span>|</span><label class="collapse" for="c-39097110">[-]</label><label class="expand" for="c-39097110">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, but if I remember correctly the paper, LoRA followed the logic that only the last layers on a llm changed drastically during finetuning, and the layers above remained almost unchanged, so it made sense to alterate only the last ones, breaking this by adding a LoRA at each linear layer doesn&#x27;t seem to follow the logic of why LoRA was created and why it works.</div><br/><div id="39097870" class="c"><input type="checkbox" id="c-39097870" checked=""/><div class="controls bullet"><span class="by">icyfox</span><span>|</span><a href="#39095746">root</a><span>|</span><a href="#39097110">parent</a><span>|</span><a href="#39093262">next</a><span>|</span><label class="collapse" for="c-39097870">[-]</label><label class="expand" for="c-39097870">[2 more]</label></div><br/><div class="children"><div class="content">Well, Lora works just because it&#x27;s a low rank approximation of full updates - much in the same way that SVD works, and regular gradient updating works. It delivers good results by both acting as a regularizer and by allowing larger models to be updated with smaller memory footprints.<p>My point is that the original Lora paper choosing the last layer is one choice. And it is likely the most common one because of its higher symbolic nature typically being all that&#x27;s needed for good performance on downstream tasks.<p>Depending on the size of your finetuning job I&#x27;ve personally seen updating more layers (or updating some only on a certain learning rate schedule) to be more effective. Lora is just the mathematical technique of updating, it doesn&#x27;t really have a hypothesis on the ideal training regimen.</div><br/><div id="39099691" class="c"><input type="checkbox" id="c-39099691" checked=""/><div class="controls bullet"><span class="by">somethingsome</span><span>|</span><a href="#39095746">root</a><span>|</span><a href="#39097870">parent</a><span>|</span><a href="#39093262">next</a><span>|</span><label class="collapse" for="c-39099691">[-]</label><label class="expand" for="c-39099691">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, I&#x27;ll meditate on that and re read the paper with this view in mind.<p>The last sentence makes sense to me, if the finetuning job changes significatively more the weights of other layers than just the last one, it is kinda normal to to use Lora on them. I had the impression that it was rarely the case, but I must be mistaken. I&#x27;ll think about applications where this is the case.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39093262" class="c"><input type="checkbox" id="c-39093262" checked=""/><div class="controls bullet"><span class="by">ijhuygft776</span><span>|</span><a href="#39095746">prev</a><span>|</span><a href="#39100508">next</a><span>|</span><label class="collapse" for="c-39093262">[-]</label><label class="expand" for="c-39093262">[1 more]</label></div><br/><div class="children"><div class="content">I wish the wireless LoRa protocol would be open source...</div><br/></div></div><div id="39100508" class="c"><input type="checkbox" id="c-39100508" checked=""/><div class="controls bullet"><span class="by">tussa</span><span>|</span><a href="#39093262">prev</a><span>|</span><a href="#39094184">next</a><span>|</span><label class="collapse" for="c-39100508">[-]</label><label class="expand" for="c-39100508">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s cheap and sleazy to steal a name from another project to ride it&#x27;s fame.</div><br/></div></div><div id="39094184" class="c"><input type="checkbox" id="c-39094184" checked=""/><div class="controls bullet"><span class="by">jamesblonde</span><span>|</span><a href="#39100508">prev</a><span>|</span><a href="#39096881">next</a><span>|</span><label class="collapse" for="c-39094184">[-]</label><label class="expand" for="c-39094184">[3 more]</label></div><br/><div class="children"><div class="content">I prefer the not from scratch, but from configuration approach by Axolotl. Aolotl supports fine-tuning mistral, llama-2, with lots of the latest techniques - sample packing, flash attention, xformers.<p>I concentrate on collecting and curating the fine-tuning data, do &quot;data-centric&quot; fine-tuning - not learning LoRA from scratch.</div><br/><div id="39096466" class="c"><input type="checkbox" id="c-39096466" checked=""/><div class="controls bullet"><span class="by">wfalcon</span><span>|</span><a href="#39094184">parent</a><span>|</span><a href="#39096881">next</a><span>|</span><label class="collapse" for="c-39096466">[-]</label><label class="expand" for="c-39096466">[2 more]</label></div><br/><div class="children"><div class="content">this is also what our (Lightning AI) lit-gpt library does.
<a href="https:&#x2F;&#x2F;github.com&#x2F;Lightning-AI&#x2F;lit-gpt">https:&#x2F;&#x2F;github.com&#x2F;Lightning-AI&#x2F;lit-gpt</a></div><br/><div id="39100135" class="c"><input type="checkbox" id="c-39100135" checked=""/><div class="controls bullet"><span class="by">jamesblonde</span><span>|</span><a href="#39094184">root</a><span>|</span><a href="#39096466">parent</a><span>|</span><a href="#39096881">next</a><span>|</span><label class="collapse" for="c-39100135">[-]</label><label class="expand" for="c-39100135">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, hadn&#x27;t seen this.</div><br/></div></div></div></div></div></div><div id="39096881" class="c"><input type="checkbox" id="c-39096881" checked=""/><div class="controls bullet"><span class="by">mintrain</span><span>|</span><a href="#39094184">prev</a><span>|</span><a href="#39095318">next</a><span>|</span><label class="collapse" for="c-39096881">[-]</label><label class="expand" for="c-39096881">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve added an exercise to practice implementing the LoRA forward pass from scratch: <a href="https:&#x2F;&#x2F;tensorgym.com&#x2F;exercises&#x2F;17" rel="nofollow">https:&#x2F;&#x2F;tensorgym.com&#x2F;exercises&#x2F;17</a>
The idea behind LoRA is beautiful, and the implementation is pretty straightforward.</div><br/><div id="39097418" class="c"><input type="checkbox" id="c-39097418" checked=""/><div class="controls bullet"><span class="by">Rudeg</span><span>|</span><a href="#39096881">parent</a><span>|</span><a href="#39095318">next</a><span>|</span><label class="collapse" for="c-39097418">[-]</label><label class="expand" for="c-39097418">[1 more]</label></div><br/><div class="children"><div class="content">nice, looks very cool and useful! I&#x27;ll definitely try it!</div><br/></div></div></div></div><div id="39095318" class="c"><input type="checkbox" id="c-39095318" checked=""/><div class="controls bullet"><span class="by">yandrypozo</span><span>|</span><a href="#39096881">prev</a><span>|</span><a href="#39096832">next</a><span>|</span><label class="collapse" for="c-39095318">[-]</label><label class="expand" for="c-39095318">[1 more]</label></div><br/><div class="children"><div class="content">gotta say naming is hard I thought this was about LoRa (from &quot;long range&quot;) or LoRaWAN, the IoT sensors communication.</div><br/></div></div><div id="39096832" class="c"><input type="checkbox" id="c-39096832" checked=""/><div class="controls bullet"><span class="by">helloericsf</span><span>|</span><a href="#39095318">prev</a><span>|</span><a href="#39098960">next</a><span>|</span><label class="collapse" for="c-39096832">[-]</label><label class="expand" for="c-39096832">[2 more]</label></div><br/><div class="children"><div class="content">HN friends, What are the most popular libraries for fine-tuning? (Not from scratch)</div><br/><div id="39098471" class="c"><input type="checkbox" id="c-39098471" checked=""/><div class="controls bullet"><span class="by">jasonjmcghee</span><span>|</span><a href="#39096832">parent</a><span>|</span><a href="#39098960">next</a><span>|</span><label class="collapse" for="c-39098471">[-]</label><label class="expand" for="c-39098471">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;OpenAccess-AI-Collective&#x2F;axolotl">https:&#x2F;&#x2F;github.com&#x2F;OpenAccess-AI-Collective&#x2F;axolotl</a></div><br/></div></div></div></div><div id="39098960" class="c"><input type="checkbox" id="c-39098960" checked=""/><div class="controls bullet"><span class="by">fnordfnordfnord</span><span>|</span><a href="#39096832">prev</a><span>|</span><a href="#39093590">next</a><span>|</span><label class="collapse" for="c-39098960">[-]</label><label class="expand" for="c-39098960">[2 more]</label></div><br/><div class="children"><div class="content">I thought this was going to be some neat software defined radio stuff. Still quite interesting though.</div><br/><div id="39098985" class="c"><input type="checkbox" id="c-39098985" checked=""/><div class="controls bullet"><span class="by">z3ugma</span><span>|</span><a href="#39098960">parent</a><span>|</span><a href="#39093590">next</a><span>|</span><label class="collapse" for="c-39098985">[-]</label><label class="expand" for="c-39098985">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s all about whether the &#x27;A&#x27; is capitalized or not. 
LoRa - radio 
LoRA - machine learning</div><br/></div></div></div></div><div id="39093590" class="c"><input type="checkbox" id="c-39093590" checked=""/><div class="controls bullet"><span class="by">broabprobe</span><span>|</span><a href="#39098960">prev</a><span>|</span><a href="#39093097">next</a><span>|</span><label class="collapse" for="c-39093590">[-]</label><label class="expand" for="c-39093590">[1 more]</label></div><br/><div class="children"><div class="content">wow definitely thought this was about LoRa at first.</div><br/></div></div><div id="39093097" class="c"><input type="checkbox" id="c-39093097" checked=""/><div class="controls bullet"><span class="by">huqedato</span><span>|</span><a href="#39093590">prev</a><span>|</span><a href="#39094883">next</a><span>|</span><label class="collapse" for="c-39093097">[-]</label><label class="expand" for="c-39093097">[1 more]</label></div><br/><div class="children"><div class="content">Excellent and practical example! I&#x27;m curious if there&#x27;s a comparable one using Julia or JavaScript.</div><br/></div></div><div id="39094883" class="c"><input type="checkbox" id="c-39094883" checked=""/><div class="controls bullet"><span class="by">facu17y</span><span>|</span><a href="#39093097">prev</a><span>|</span><a href="#39092946">next</a><span>|</span><label class="collapse" for="c-39094883">[-]</label><label class="expand" for="c-39094883">[2 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the performance penalty of LoRA?</div><br/><div id="39095122" class="c"><input type="checkbox" id="c-39095122" checked=""/><div class="controls bullet"><span class="by">rasbt</span><span>|</span><a href="#39094883">parent</a><span>|</span><a href="#39092946">next</a><span>|</span><label class="collapse" for="c-39095122">[-]</label><label class="expand" for="c-39095122">[1 more]</label></div><br/><div class="children"><div class="content">During training, it&#x27;s more efficient than full finetuning because you only update a fraction of the parameters via backprop. 
During inference, it can ...<p>1) ... be theoretically a tad slower if you add the LoRA values dynamically during the forward pass (however, this is also an advantage if you want to keep a separate small weight set per customer, for example; you run only one large base model and can apply the different LoRA weights per customer on the fly)<p>2) ... have the exact same performance as the base model if you merge the LoRA weights back with the base model.</div><br/></div></div></div></div><div id="39092946" class="c"><input type="checkbox" id="c-39092946" checked=""/><div class="controls bullet"><span class="by">andy99</span><span>|</span><a href="#39094883">prev</a><span>|</span><a href="#39092720">next</a><span>|</span><label class="collapse" for="c-39092946">[-]</label><label class="expand" for="c-39092946">[5 more]</label></div><br/><div class="children"><div class="content">&quot;From scratch&quot; seems to be a matter of opinion. &quot;Pure pytorch&quot; maybe, except it uses HF transformers. So it&#x27;s LoRA on top of common frameworks...</div><br/><div id="39100334" class="c"><input type="checkbox" id="c-39100334" checked=""/><div class="controls bullet"><span class="by">michaelnny</span><span>|</span><a href="#39092946">parent</a><span>|</span><a href="#39093000">next</a><span>|</span><label class="collapse" for="c-39100334">[-]</label><label class="expand" for="c-39100334">[1 more]</label></div><br/><div class="children"><div class="content">If anyone is interested in a more &#x27;pure&#x27; or &#x27;scratch&#x27; implementation, check out <a href="https:&#x2F;&#x2F;github.com&#x2F;michaelnny&#x2F;QLoRA-LLM">https:&#x2F;&#x2F;github.com&#x2F;michaelnny&#x2F;QLoRA-LLM</a>. (author here) It also supports 4-bit quantized LoRA, using only PyTorch and bitsandbytes, without any other tools.</div><br/></div></div><div id="39093000" class="c"><input type="checkbox" id="c-39093000" checked=""/><div class="controls bullet"><span class="by">rasbt</span><span>|</span><a href="#39092946">parent</a><span>|</span><a href="#39100334">prev</a><span>|</span><a href="#39093036">next</a><span>|</span><label class="collapse" for="c-39093000">[-]</label><label class="expand" for="c-39093000">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the LoRA part is from scratch. The LLM backbone in this example is not, this is to provide a concrete example. But you could apply the exact same LoRA from scratch code to a pure PyTorch model if you wanted to:<p>E.g.<p><pre><code>    class MultilayerPerceptron(nn.Module):

        def __init__(self, num_features, num_hidden_1, num_hidden_2, num_classes):
            super().__init__()

            self.layers = nn.Sequential(
                nn.Linear(num_features, num_hidden_1),
                nn.ReLU(),
                nn.Linear(num_hidden_1, num_hidden_2),
                nn.ReLU(),
                nn.Linear(num_hidden_2, num_classes)
            )

        def forward(self, x):
            x = self.layers(x)
            return x

    model = MultilayerPerceptron(
        num_features=num_features,
        num_hidden_1=num_hidden_1,
        num_hidden_2=num_hidden_2, 
        num_classes=num_classes
    )

    model.layers[0] = LinearWithLoRA(model.layers[0], rank=4, alpha=1)
    model.layers[2] = LinearWithLoRA(model.layers[2], rank=4, alpha=1)
    model.layers[4] = LinearWithLoRA(model.layers[4], rank=4, alpha=1)</code></pre></div><br/></div></div><div id="39093036" class="c"><input type="checkbox" id="c-39093036" checked=""/><div class="controls bullet"><span class="by">2024throwaway</span><span>|</span><a href="#39092946">parent</a><span>|</span><a href="#39093000">prev</a><span>|</span><a href="#39093206">next</a><span>|</span><label class="collapse" for="c-39093036">[-]</label><label class="expand" for="c-39093036">[1 more]</label></div><br/><div class="children"><div class="content">This apple pie recipe claims to be from scratch, but they cooked it in an off the shelf oven. So it&#x27;s from scratch on top of the universe...</div><br/></div></div></div></div><div id="39092720" class="c"><input type="checkbox" id="c-39092720" checked=""/><div class="controls bullet"><span class="by">dymk</span><span>|</span><a href="#39092946">prev</a><span>|</span><a href="#39093783">next</a><span>|</span><label class="collapse" for="c-39092720">[-]</label><label class="expand" for="c-39092720">[8 more]</label></div><br/><div class="children"><div class="content">Not to be confused with LoRa (&quot;long range&quot;), a radio communication protocol. At first I thought this could be about using LLMs to find optimal protocol parameters, but alas.</div><br/><div id="39092814" class="c"><input type="checkbox" id="c-39092814" checked=""/><div class="controls bullet"><span class="by">OJFord</span><span>|</span><a href="#39092720">parent</a><span>|</span><a href="#39092751">next</a><span>|</span><label class="collapse" for="c-39092814">[-]</label><label class="expand" for="c-39092814">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the first thing that comes to my mind too, but this is mentioned in every thread (and there are far more of them for LoRA than LoRa atm), and in this case there&#x27;s unlikely to be much confusion because it starts by spelling out the acronym: &#x27;LoRA, which stands for Low Rank Adaptation, [...]&#x27;.</div><br/></div></div><div id="39092751" class="c"><input type="checkbox" id="c-39092751" checked=""/><div class="controls bullet"><span class="by">cpfohl</span><span>|</span><a href="#39092720">parent</a><span>|</span><a href="#39092814">prev</a><span>|</span><a href="#39093513">next</a><span>|</span><label class="collapse" for="c-39092751">[-]</label><label class="expand" for="c-39092751">[1 more]</label></div><br/><div class="children"><div class="content">I had the exact same confusion</div><br/></div></div><div id="39093513" class="c"><input type="checkbox" id="c-39093513" checked=""/><div class="controls bullet"><span class="by">the__alchemist</span><span>|</span><a href="#39092720">parent</a><span>|</span><a href="#39092751">prev</a><span>|</span><a href="#39092856">next</a><span>|</span><label class="collapse" for="c-39093513">[-]</label><label class="expand" for="c-39093513">[1 more]</label></div><br/><div class="children"><div class="content">Concur; or at least don&#x27;t use a mix of lower and upper-case, like the radio. I think there would be less mis-assumptions if they had called it &quot;LORA&quot;, &quot;Lora&quot;, &quot;lora&quot; etc. &quot;LoRA&quot; is asking for trouble.</div><br/></div></div><div id="39092856" class="c"><input type="checkbox" id="c-39092856" checked=""/><div class="controls bullet"><span class="by">rasbt</span><span>|</span><a href="#39092720">parent</a><span>|</span><a href="#39093513">prev</a><span>|</span><a href="#39093173">next</a><span>|</span><label class="collapse" for="c-39092856">[-]</label><label class="expand" for="c-39092856">[1 more]</label></div><br/><div class="children"><div class="content">Hah, yeah that&#x27;s LoRA as in Low-Rank Adaptation :P</div><br/></div></div><div id="39093087" class="c"><input type="checkbox" id="c-39093087" checked=""/><div class="controls bullet"><span class="by">thelastparadise</span><span>|</span><a href="#39092720">parent</a><span>|</span><a href="#39093173">prev</a><span>|</span><a href="#39093195">next</a><span>|</span><label class="collapse" for="c-39093087">[-]</label><label class="expand" for="c-39093087">[1 more]</label></div><br/><div class="children"><div class="content">This caught me off-guard as well.<p>I really wish they could have used abother acronym.</div><br/></div></div></div></div><div id="39093763" class="c"><input type="checkbox" id="c-39093763" checked=""/><div class="controls bullet"><span class="by">gourabmi</span><span>|</span><a href="#39093783">prev</a><span>|</span><a href="#39093905">next</a><span>|</span><label class="collapse" for="c-39093763">[-]</label><label class="expand" for="c-39093763">[1 more]</label></div><br/><div class="children"><div class="content">Someone somewhere is already working on naming their project Lehsun.. &#x2F;s</div><br/></div></div></div></div></div></div></div></body></html>