<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1734253257894" as="style"/><link rel="stylesheet" href="styles.css?v=1734253257894"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.quantamagazine.org/what-is-entropy-a-measure-of-just-how-little-we-really-know-20241213/">What is entropy? A measure of just how little we know</a> <span class="domain">(<a href="https://www.quantamagazine.org">www.quantamagazine.org</a>)</span></div><div class="subtext"><span>nsoonhui</span> | <span>124 comments</span></div><br/><div><div id="42416887" class="c"><input type="checkbox" id="c-42416887" checked=""/><div class="controls bullet"><span class="by">plank</span><span>|</span><a href="#42418411">next</a><span>|</span><label class="collapse" for="c-42416887">[-]</label><label class="expand" for="c-42416887">[9 more]</label></div><br/><div class="children"><div class="content">Interesting to read this, 27 years after my PhD* (theoretical physics), in which I did compare the view WITH and the view WITHOUT ‘unknowns’ causing entropy as a driver.<p>* My PhD was about how to treat a (quantum mechanical) system inside a cavity: a cavity with one perfect mirror and one 99.999999% perfect mirror. The (one dimensional) universe was made whole by another perfect mirror at the other side of the non-perfect mirror (in ASCII art:<p>[100%] —l— [100-epsilon] ——L——— [100%]<p>With L &gt;&gt; l.
The ‘whole universe’ solution was simple (using standard quantum mechanics techniques), the ‘lossy’ ‘small universe’ was not. But they needed to be the same (physically).
Thus using the exact solution for the ‘complete’ (l+L) universe and comparing it to possible ‘small’ (l) universe models in which some non-linear term accounted for loss.
The connection between how a lossy system (in which entropy exists&#x2F;is a driving ‘force’) and a losless system (in which everything is conserved) is thus not a new insight;-0</div><br/><div id="42417396" class="c"><input type="checkbox" id="c-42417396" checked=""/><div class="controls bullet"><span class="by">mojomark</span><span>|</span><a href="#42416887">parent</a><span>|</span><a href="#42419034">next</a><span>|</span><label class="collapse" for="c-42417396">[-]</label><label class="expand" for="c-42417396">[5 more]</label></div><br/><div class="children"><div class="content">I read you&#x27;re comment with interest, but ultimately I can&#x27;t understand the point being made because I don&#x27;t know what kind of mirror you&#x27;re referring to (optical?), I don&#x27;t know what &#x27;l&#x27; or &#x27;L&#x27; represent (lateral spacing of mirrors?, vacuum energy desnities?), and the last sentence I think maybe the word &#x27;how&#x27; should be deleted?</div><br/><div id="42418269" class="c"><input type="checkbox" id="c-42418269" checked=""/><div class="controls bullet"><span class="by">IIAOPSW</span><span>|</span><a href="#42416887">root</a><span>|</span><a href="#42417396">parent</a><span>|</span><a href="#42417574">next</a><span>|</span><label class="collapse" for="c-42418269">[-]</label><label class="expand" for="c-42418269">[2 more]</label></div><br/><div class="children"><div class="content">The imperfect mirror means that epsilon% of the time the light goes through to a much larger &quot;back room&quot; whereas (1-epsilon)% of the time the light just reflects like normal. The point being made is that this is an extension of an ordinary ideal cavity to include unavoidable (but weak) interaction with the much larger system outside of it (aka the whole universe). It just so happens the much larger external system is also being modeled as a simple 1d cavity.<p>In other words, entropy is equivalent to bits of information needed to specify the complete state of the system leaking outside of the confines of where those bits are being observed by an experiment (eg tunneling through an imperfect mirror).<p>Entropy is an accounting tool to keep track of how many bits are missing, and how far this ignorance has percolated into what you can safely predict about the system.</div><br/></div></div><div id="42417574" class="c"><input type="checkbox" id="c-42417574" checked=""/><div class="controls bullet"><span class="by">plank</span><span>|</span><a href="#42416887">root</a><span>|</span><a href="#42417396">parent</a><span>|</span><a href="#42418269">prev</a><span>|</span><a href="#42419034">next</a><span>|</span><label class="collapse" for="c-42417574">[-]</label><label class="expand" for="c-42417574">[2 more]</label></div><br/><div class="children"><div class="content">Answers to your questions: 
1): all the way to the left, a mirror with a reflectivity|r| of 1 (or a 100%). In the middle an |r| of slightly below 1. Yes, optical, system with photons (a and a^dagger with [a,a^dagger]=1).
2) distance between mirrors 1 and 2: l. Distance mirror 2 and 3:L. (Later taking the limit L&#x2F;l ==&gt;&gt; infinity) 
3) the how is actually correct, I guess the word behaves is missing twice: .... how .... behaves and a .... behaves.</div><br/><div id="42422346" class="c"><input type="checkbox" id="c-42422346" checked=""/><div class="controls bullet"><span class="by">dfee</span><span>|</span><a href="#42416887">root</a><span>|</span><a href="#42417574">parent</a><span>|</span><a href="#42419034">next</a><span>|</span><label class="collapse" for="c-42422346">[-]</label><label class="expand" for="c-42422346">[1 more]</label></div><br/><div class="children"><div class="content">This is madness.</div><br/></div></div></div></div></div></div><div id="42419034" class="c"><input type="checkbox" id="c-42419034" checked=""/><div class="controls bullet"><span class="by">mike_ivanov</span><span>|</span><a href="#42416887">parent</a><span>|</span><a href="#42417396">prev</a><span>|</span><a href="#42418166">next</a><span>|</span><label class="collapse" for="c-42419034">[-]</label><label class="expand" for="c-42419034">[2 more]</label></div><br/><div class="children"><div class="content">Interesting. Could you share a link to your thesis?</div><br/><div id="42422320" class="c"><input type="checkbox" id="c-42422320" checked=""/><div class="controls bullet"><span class="by">plank</span><span>|</span><a href="#42416887">root</a><span>|</span><a href="#42419034">parent</a><span>|</span><a href="#42418166">next</a><span>|</span><label class="collapse" for="c-42422320">[-]</label><label class="expand" for="c-42422320">[1 more]</label></div><br/><div class="children"><div class="content">Sure.<p>Had to do some searching;-)<p>Info on thesis: <a href="https:&#x2F;&#x2F;dare.uva.nl&#x2F;search?identifier=0ae63403-264b-4bf0-91c0-95be9a15e16e" rel="nofollow">https:&#x2F;&#x2F;dare.uva.nl&#x2F;search?identifier=0ae63403-264b-4bf0-91c...</a><p>The document itself (self hosted)
<a href="https:&#x2F;&#x2F;gofile.me&#x2F;7uDSJ&#x2F;sGJCFD3W7" rel="nofollow">https:&#x2F;&#x2F;gofile.me&#x2F;7uDSJ&#x2F;sGJCFD3W7</a><p>Probably most important article: (sorry, only abstract): <a href="https:&#x2F;&#x2F;journals.aps.org&#x2F;pra&#x2F;abstract&#x2F;10.1103&#x2F;PhysRevA.54.2464" rel="nofollow">https:&#x2F;&#x2F;journals.aps.org&#x2F;pra&#x2F;abstract&#x2F;10.1103&#x2F;PhysRevA.54.24...</a></div><br/></div></div></div></div></div></div><div id="42418411" class="c"><input type="checkbox" id="c-42418411" checked=""/><div class="controls bullet"><span class="by">zV62drdTw6CM</span><span>|</span><a href="#42416887">prev</a><span>|</span><a href="#42419202">next</a><span>|</span><label class="collapse" for="c-42418411">[-]</label><label class="expand" for="c-42418411">[6 more]</label></div><br/><div class="children"><div class="content">Happy to see the article being discussed here!
I was responsible for the technical implementation of the interactives. If you are interested in the source code, you can find it here: <a href="https:&#x2F;&#x2F;github.com&#x2F;jnsprnw&#x2F;mip-entropy">https:&#x2F;&#x2F;github.com&#x2F;jnsprnw&#x2F;mip-entropy</a>
It’s built in Svelte 5 with Tailwind.</div><br/><div id="42418460" class="c"><input type="checkbox" id="c-42418460" checked=""/><div class="controls bullet"><span class="by">azemetre</span><span>|</span><a href="#42418411">parent</a><span>|</span><a href="#42419202">next</a><span>|</span><label class="collapse" for="c-42418460">[-]</label><label class="expand" for="c-42418460">[5 more]</label></div><br/><div class="children"><div class="content">May I ask why you chose svelte 5 rather than something else? I’ve noticed that a lot of “one off” interactions are being built with svelte nowadays. What are the benefits of using it?</div><br/><div id="42418560" class="c"><input type="checkbox" id="c-42418560" checked=""/><div class="controls bullet"><span class="by">zV62drdTw6CM</span><span>|</span><a href="#42418411">root</a><span>|</span><a href="#42418460">parent</a><span>|</span><a href="#42419202">next</a><span>|</span><label class="collapse" for="c-42418560">[-]</label><label class="expand" for="c-42418560">[4 more]</label></div><br/><div class="children"><div class="content">First, when I joined the project, it wasn’t clear how it would be published. Svelte, which outputs compiled JavaScript, can fit into many CMS workflows that newspapers&#x2F;publishers use.<p>I believe Svelte was developed by Rich Harris at the NY Times for this very reason.<p>We ended up using iFrames, so other frameworks like React could have been used.<p>Second, Svelte is very well suited for these small interactives because it has built-in state, transitions, and reactivity with low overhead.<p>Third, it was a personal choice, as I now do most of my work in Svelte.</div><br/><div id="42418666" class="c"><input type="checkbox" id="c-42418666" checked=""/><div class="controls bullet"><span class="by">kqr</span><span>|</span><a href="#42418411">root</a><span>|</span><a href="#42418560">parent</a><span>|</span><a href="#42419202">next</a><span>|</span><label class="collapse" for="c-42418666">[-]</label><label class="expand" for="c-42418666">[3 more]</label></div><br/><div class="children"><div class="content">&gt; We ended up using iFrames, so other frameworks like React could have been used.<p>Wait, wasn&#x27;t one of the original selling points of React that it could be embedded piecewise to enhance interactivity of the parts of pages that needed it? It should certainly not need a separate page!</div><br/><div id="42419001" class="c"><input type="checkbox" id="c-42419001" checked=""/><div class="controls bullet"><span class="by">gligorot</span><span>|</span><a href="#42418411">root</a><span>|</span><a href="#42418666">parent</a><span>|</span><a href="#42419200">next</a><span>|</span><label class="collapse" for="c-42419001">[-]</label><label class="expand" for="c-42419001">[1 more]</label></div><br/><div class="children"><div class="content">It’s a PITA to extract a stateful react component to a standalone piece of code that can be inserted in a random place (in another page, served via API etc.). Not sure about Svelte, but achieving this in React was unexpectedly hard&#x2F;impossible in our use case.</div><br/></div></div><div id="42419200" class="c"><input type="checkbox" id="c-42419200" checked=""/><div class="controls bullet"><span class="by">codethief</span><span>|</span><a href="#42418411">root</a><span>|</span><a href="#42418666">parent</a><span>|</span><a href="#42419001">prev</a><span>|</span><a href="#42419202">next</a><span>|</span><label class="collapse" for="c-42419200">[-]</label><label class="expand" for="c-42419200">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42419202" class="c"><input type="checkbox" id="c-42419202" checked=""/><div class="controls bullet"><span class="by">TexanFeller</span><span>|</span><a href="#42418411">prev</a><span>|</span><a href="#42422224">next</a><span>|</span><label class="collapse" for="c-42419202">[-]</label><label class="expand" for="c-42419202">[1 more]</label></div><br/><div class="children"><div class="content">Entropy got a lot more exciting to me after hearing Sean Carroll talk about it. He has a foundational&#x2F;philosophical bent and  likes to point out that there are competing definitions of entropy set on different philosophical foundations, one of them seemingly observer dependent:<p>- <a href="https:&#x2F;&#x2F;youtu.be&#x2F;x9COqqqsFtc?si=cQkfV5IpLC039Cl5" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;x9COqqqsFtc?si=cQkfV5IpLC039Cl5</a><p>- <a href="https:&#x2F;&#x2F;youtu.be&#x2F;XJ14ZO-e9NY?si=xi8idD5JmQbT5zxN" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;XJ14ZO-e9NY?si=xi8idD5JmQbT5zxN</a><p>Leonard Susskind has lots of great talks and books about quantum information and calculating the entropy of black holes which led to a lot of wild new hypotheses.<p>Stephen Wolfram gave a long talk about the history of the concept of entropy which was pretty good: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;live&#x2F;ocOHxPs1LQ0?si=zvQNsj_FEGbTX2R3" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;live&#x2F;ocOHxPs1LQ0?si=zvQNsj_FEGbTX2R3</a></div><br/></div></div><div id="42422224" class="c"><input type="checkbox" id="c-42422224" checked=""/><div class="controls bullet"><span class="by">rwoerz</span><span>|</span><a href="#42419202">prev</a><span>|</span><a href="#42415797">next</a><span>|</span><label class="collapse" for="c-42422224">[-]</label><label class="expand" for="c-42422224">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get the example under &quot;What is entropy?&quot;. This works only under the assumption that reality (phase space in particular) is somehow &quot;pixelated&quot;. If reality is continuous, 9 particles that are clumped together can already be in uncountalbly many states.</div><br/></div></div><div id="42415797" class="c"><input type="checkbox" id="c-42415797" checked=""/><div class="controls bullet"><span class="by">kqr</span><span>|</span><a href="#42422224">prev</a><span>|</span><a href="#42419092">next</a><span>|</span><label class="collapse" for="c-42415797">[-]</label><label class="expand" for="c-42415797">[46 more]</label></div><br/><div class="children"><div class="content">&gt; As physicists have worked to unite seemingly disparate fields over the past century, they have cast entropy in a new light — turning the microscope back on the seer and shifting the notion of disorder to one of ignorance. Entropy is seen not as a property intrinsic to a system but as one that’s relative to an observer who interacts with that system.<p>Maybe I have the benefit of giant shoulders, but this seems like a fairly mundane observation. High-entropy states are those macrostates which have many corresponding microstates. The classification of several microstates into the same macrostate, is this not a distinctly observer-centred function?<p>I.e. if I consider 5 or 6 to be essentially the same outcome of the die, then that will be a more probable (higher-entropy) outcome. But that&#x27;s just due to my classification, not inherent to the system!</div><br/><div id="42417034" class="c"><input type="checkbox" id="c-42417034" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#42415797">parent</a><span>|</span><a href="#42415944">next</a><span>|</span><label class="collapse" for="c-42417034">[-]</label><label class="expand" for="c-42417034">[32 more]</label></div><br/><div class="children"><div class="content">&gt; Maybe I have the benefit of giant shoulders, but this seems like a fairly mundane observation.<p>It is not mundane, and it is also not right, at least for entropy in Physics and Thermodynamics.<p>&gt; High-entropy states are those macrostates which have many corresponding microstates.<p>That is how you deduce entropy form a given model. But entropy is also something that we can get from experimental measurements. In this case, the experimental setup does not care about microstates and macrostates, it just has properties like enthalpy, heat capacity and temperature.<p>We can build models after the fact and say that e.g. the entropy of a given gas matches that predicted by our model for ideal gases, or that the entropy of a given solid matches what we know about vibrational entropy.<p>That’s how we say that e.g. hydrogen atoms are indistinguishable. It’s not that they become indistinguishable because we decide so. It’s because we can calculate entropy in both cases and reality does not match the model with distinguishable atoms.<p>&gt; The classification of several microstates into the same macrostate, is this not a distinctly observer-centred function?<p>It seems that way if we consider only our neat models, but it fails to explain why experimental measurements of the entropy of a given materials are consistent and independent of whatever model the people doing the experiment were operating on. Fundamentally, entropy depends on the probability distribution, not the observer.</div><br/><div id="42417780" class="c"><input type="checkbox" id="c-42417780" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417034">parent</a><span>|</span><a href="#42421637">next</a><span>|</span><label class="collapse" for="c-42417780">[-]</label><label class="expand" for="c-42417780">[6 more]</label></div><br/><div class="children"><div class="content">&gt; But entropy is also something that we can get from experimental measurements. In this case, the experimental setup does not care about microstates and macrostates, it just has properties like enthalpy, heat capacity and temperature. […] experimental measurements of the entropy of a given materials are consistent and independent of whatever model the people doing the experiment were operating on. Fundamentally, entropy depends on the probability distribution, not the observer.<p><a href="https:&#x2F;&#x2F;bayes.wustl.edu&#x2F;etj&#x2F;articles&#x2F;gibbs.vs.boltzmann.pdf" rel="nofollow">https:&#x2F;&#x2F;bayes.wustl.edu&#x2F;etj&#x2F;articles&#x2F;gibbs.vs.boltzmann.pdf</a><p>Thermodynamics does have the concept of the entropy of a thermodynamic system; but a given physical system corresponds to many different thermodynamic systems. […] It is clearly meaningless to ask, “What is the entropy of the crystal?” unless we first specify the set of parameters which define its thermodynamic state. […] There is no end to this search for the ultimate &quot;true&quot; entropy until we have reached the point where we control the location of each atom independently. But just at that point the notion of entropy collapses, and we are no longer talking thermodynamics! […] From this we see that entropy is an anthropomorphic concept, not only in the well-known statistical sense that it measures the extent of human ignorance as to the microstate. Even at the purely phenomenological level, entropy is an anthropomorphic concept. For it is a property, not of the physical system, but of the particular experiments you or I choose to perform on it.</div><br/><div id="42420947" class="c"><input type="checkbox" id="c-42420947" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417780">parent</a><span>|</span><a href="#42421637">next</a><span>|</span><label class="collapse" for="c-42420947">[-]</label><label class="expand" for="c-42420947">[5 more]</label></div><br/><div class="children"><div class="content">Temperature is not just an anthropomorphic concept, and temperature and entropy are directly linked concept you can&#x27;t have one without the other.</div><br/><div id="42421693" class="c"><input type="checkbox" id="c-42421693" checked=""/><div class="controls bullet"><span class="by">BenoitEssiambre</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42420947">parent</a><span>|</span><a href="#42421273">next</a><span>|</span><label class="collapse" for="c-42421693">[-]</label><label class="expand" for="c-42421693">[2 more]</label></div><br/><div class="children"><div class="content">It is though. Temperature is an aggregate summary statistic used when the observer doesn&#x27;t know the details of individual particles. If you did know their position, speed and velocities, you could violate the laws of entropy as Maxwell&#x27;s thought experiment demonstrated in 1867 <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Maxwell%27s_demon" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Maxwell%27s_demon</a></div><br/><div id="42421850" class="c"><input type="checkbox" id="c-42421850" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42421693">parent</a><span>|</span><a href="#42421273">next</a><span>|</span><label class="collapse" for="c-42421850">[-]</label><label class="expand" for="c-42421850">[1 more]</label></div><br/><div class="children"><div class="content">Maxwell&#x27;s demon is a thought experiment that involves a magical being. It&#x27;s an interesting thought experiment, and it provides some insights about the relationship between macro states and micro states, but it&#x27;s not actually a refutation of anything, and it doesn&#x27;t describe any physically realizable system, even in theory. There is no way to build a physical system that can act as the demon, and so it follows that entropy is not actually dependent on the information actually available to physical systems.<p>This is obviously visible in the observer-independence of many phenomena linked to temperature. A piece of ice will melt in a large enough bath of hot water regardless of whether you know the microstates of every atom in the bath and the ice crystal.</div><br/></div></div></div></div><div id="42421283" class="c"><input type="checkbox" id="c-42421283" checked=""/><div class="controls bullet"><span class="by">mitthrowaway2</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42420947">parent</a><span>|</span><a href="#42421273">prev</a><span>|</span><a href="#42421637">next</a><span>|</span><label class="collapse" for="c-42421283">[-]</label><label class="expand" for="c-42421283">[1 more]</label></div><br/><div class="children"><div class="content">Temperature and entropy are directly linked; it follows that temperature is also anthropomorphic. Although I think &quot;observer-dependent&quot; would be a better way to put it; it doesn&#x27;t have to specifically be relative to a human.</div><br/></div></div></div></div></div></div><div id="42421637" class="c"><input type="checkbox" id="c-42421637" checked=""/><div class="controls bullet"><span class="by">BenoitEssiambre</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417034">parent</a><span>|</span><a href="#42417780">prev</a><span>|</span><a href="#42420938">next</a><span>|</span><label class="collapse" for="c-42421637">[-]</label><label class="expand" for="c-42421637">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Fundamentally, entropy depends on the probability distribution, not the observer.<p>Right but a probability distribution represents the uncertainty in an observer so there is no inconsistency here (else you&#x27;re falling for the Mind Projection Fallacy <a href="http:&#x2F;&#x2F;www-biba.inrialpes.fr&#x2F;Jaynes&#x2F;cc10k.pdf" rel="nofollow">http:&#x2F;&#x2F;www-biba.inrialpes.fr&#x2F;Jaynes&#x2F;cc10k.pdf</a>).</div><br/><div id="42422408" class="c"><input type="checkbox" id="c-42422408" checked=""/><div class="controls bullet"><span class="by">tsimionescu</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42421637">parent</a><span>|</span><a href="#42420938">next</a><span>|</span><label class="collapse" for="c-42422408">[-]</label><label class="expand" for="c-42422408">[1 more]</label></div><br/><div class="children"><div class="content">This is only true if one assumes that (a) physical processes are fundamentally completely deterministic, and that (b) it is possible to measure the initial state of a system to at least the same level of precision as the factors that influence the outcome.<p>Assumption (a) is currently believed to be false in the case of measuring a quantum system: to the best of our current knowledge, the result of measuring a quantum system is a perfectly random sampling of a probability distribution determined by its wave function.<p>Assumption (b) is also believed to be false, and is certainly known to be false in many practical experiments. Especially given that measurement is a time-consuming process, events that happen at a high frequency may be fundamentally unpredictable on computational grounds (that is, measuring the initial state to enough precision and then computing a probability may be physically impossible in the time that it takes for the event to happen - similar to the concept of computational irreducibility).<p>So, even in theory, the outcomes of certain kinds of experiments are probabilistic in a way that is entirely observer-independent; this is especially true in quantum mechanics, but it is also true in many types of classical experiments.</div><br/></div></div></div></div><div id="42420938" class="c"><input type="checkbox" id="c-42420938" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417034">parent</a><span>|</span><a href="#42421637">prev</a><span>|</span><a href="#42417404">next</a><span>|</span><label class="collapse" for="c-42420938">[-]</label><label class="expand" for="c-42420938">[2 more]</label></div><br/><div class="children"><div class="content">&gt; That’s how we say that e.g. hydrogen atoms are indistinguishable. It’s not that they become indistinguishable because we decide so. It’s because we can calculate entropy in both cases and reality does not match the model with distinguishable atoms.<p>How does using isotopes that allow atoms to be distinguished affect entropy?</div><br/><div id="42421252" class="c"><input type="checkbox" id="c-42421252" checked=""/><div class="controls bullet"><span class="by">foobarbecue</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42420938">parent</a><span>|</span><a href="#42417404">next</a><span>|</span><label class="collapse" for="c-42421252">[-]</label><label class="expand" for="c-42421252">[1 more]</label></div><br/><div class="children"><div class="content">Add more particles, get more possible states. Hydrogen is a proton and an electron. Deuterium adds a neutron. More possible states means more entropy, assuming your knowledge of the system stayed constant.</div><br/></div></div></div></div><div id="42417404" class="c"><input type="checkbox" id="c-42417404" checked=""/><div class="controls bullet"><span class="by">LudwigNagasena</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417034">parent</a><span>|</span><a href="#42420938">prev</a><span>|</span><a href="#42418442">next</a><span>|</span><label class="collapse" for="c-42417404">[-]</label><label class="expand" for="c-42417404">[10 more]</label></div><br/><div class="children"><div class="content">&gt; It is not mundane, and it is also not right, at least for entropy in Physics and Thermodynamics.<p>Articles about MaxEnt thermodynamics by E.T. Jaynes where he talks about the “anthropomorphic” nature of entropy date back to 1960s. How is that not right in physics?</div><br/><div id="42418332" class="c"><input type="checkbox" id="c-42418332" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417404">parent</a><span>|</span><a href="#42418442">next</a><span>|</span><label class="collapse" for="c-42418332">[-]</label><label class="expand" for="c-42418332">[9 more]</label></div><br/><div class="children"><div class="content">By the look of it, it is another misguided attempt to apply information theory concepts to thermodynamics. Entropy as information is seductive because that way we think we can understand it better, and it looks like it works. But we need to be careful because even though we can get useful insights from it (like Hawking radiation) it’s easy to reach unphysical conclusions.<p>&gt; How is that not right in physics?<p>Why would it be right? Was it used to make predictions that were subsequently verified?</div><br/><div id="42418441" class="c"><input type="checkbox" id="c-42418441" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42418332">parent</a><span>|</span><a href="#42418450">next</a><span>|</span><label class="collapse" for="c-42418441">[-]</label><label class="expand" for="c-42418441">[5 more]</label></div><br/><div class="children"><div class="content">That misguided attempt has resulted in full graduate courses and textbooks. Maybe one look is not all that it takes to fully assess its worthiness.<p><a href="https:&#x2F;&#x2F;www.amazon.com&#x2F;Microphysics-Macrophysics-Applications-Statistical-Mathematical&#x2F;dp&#x2F;3540454691" rel="nofollow">https:&#x2F;&#x2F;www.amazon.com&#x2F;Microphysics-Macrophysics-Application...</a><p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;cond-mat&#x2F;0501322" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;cond-mat&#x2F;0501322</a></div><br/><div id="42419524" class="c"><input type="checkbox" id="c-42419524" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42418441">parent</a><span>|</span><a href="#42418450">next</a><span>|</span><label class="collapse" for="c-42419524">[-]</label><label class="expand" for="c-42419524">[4 more]</label></div><br/><div class="children"><div class="content">Plenty of bad stuff made its way into textbooks, I saw some really dodgy stuff at uni. And for every uncontroversial statement we can find a textbook that argues that it is wrong. Sorting the good from the bad is the main point of studying science and it is not easy. What is also important is that approaches that can work in some field or context might be misleading or lead to wrong outcomes in others. Information theory is obviously successful and there is nothing fundamentally wrong with it.<p>Where we should be careful is when we want to apply some reasoning verbatim to a different problem. Sometimes it works, and sometimes it does not. Entropy is a particularly good example. It is abstract enough to be mysterious for a vast majority of the population, hence why these terribly misleading vulgarisation articles pop up so often. Thinking of it in terms of information is sometimes useful, but going from information to knowledge is a leap, and then circling back to Physics is a bit adventurous.</div><br/><div id="42419550" class="c"><input type="checkbox" id="c-42419550" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42419524">parent</a><span>|</span><a href="#42418450">next</a><span>|</span><label class="collapse" for="c-42419550">[-]</label><label class="expand" for="c-42419550">[3 more]</label></div><br/><div class="children"><div class="content">Plenty of bad stuff makes its way into hackernews comments as well. Saying that “it could be wrong” doesn’t really support the “it’s wrong” claim, does it?</div><br/><div id="42419692" class="c"><input type="checkbox" id="c-42419692" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42419550">parent</a><span>|</span><a href="#42418450">next</a><span>|</span><label class="collapse" for="c-42419692">[-]</label><label class="expand" for="c-42419692">[2 more]</label></div><br/><div class="children"><div class="content">I did not make that point, though. I rejected an appeal to authority because something was in a textbook. I made no comment about the validity of that person’s work in his field, I just pointed out that this transferability was limited.</div><br/><div id="42419698" class="c"><input type="checkbox" id="c-42419698" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42419692">parent</a><span>|</span><a href="#42418450">next</a><span>|</span><label class="collapse" for="c-42419698">[-]</label><label class="expand" for="c-42419698">[1 more]</label></div><br/><div class="children"><div class="content">My bad, I thought you considered Balian’s work another misguided attempt to apply information theory concepts to thermodynamics.<p>For the record, this is the abstract of the “Information in statistical physics” article: “We review with a tutorial scope the information theory foundations of quantum statistical physics. Only a small proportion of the variables that characterize a system at the microscopic scale can be controlled, for both practical and theoretical reasons, and a probabilistic description involving the observers is required. The criterion of maximum von Neumann
entropy is then used for making reasonable inferences. It means that no spurious information is introduced besides the known data. Its outcomes can be given a direct justification based on the principle of indifference
of Laplace. We introduce the concept of relevant entropy associated with some set of relevant variables; it characterizes the information that is missing at the microscopic level when only these variables are known. For
equilibrium problems, the relevant variables are the conserved ones, and the Second Law is recovered as a second step of the inference process. For non-equilibrium problems, the increase of the relevant entropy expresses
an irretrievable loss of information from the relevant variables towards the irrelevant ones. Two examples illustrate the flexibility of the choice of relevant variables and the multiplicity of the associated entropies: the thermodynamic entropy (satisfying the Clausius–Duhem inequality) and the Boltzmann entropy (satisfying the H-theorem). The identification of entropy with missing information is also supported by the paradox of
Maxwell’s demon. Spin-echo experiments show that irreversibility itself is not an absolute concept: use of hidden information may overcome the arrow of time.”</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42418450" class="c"><input type="checkbox" id="c-42418450" checked=""/><div class="controls bullet"><span class="by">oh_my_goodness</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42418332">parent</a><span>|</span><a href="#42418441">prev</a><span>|</span><a href="#42418442">next</a><span>|</span><label class="collapse" for="c-42418450">[-]</label><label class="expand" for="c-42418450">[3 more]</label></div><br/><div class="children"><div class="content">&quot;We need to be careful&quot;, agreed. &quot;It&#x27;s not mundane&quot;, agreed. (It&#x27;s mundane in information theory because that&#x27;s how they define entropy.)<p>&quot;It&#x27;s [...] not right&quot; (from your first comment), can you give&#x2F;link a specific physical example? It would be very cool to have a clear counterexample.</div><br/><div id="42419676" class="c"><input type="checkbox" id="c-42419676" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42418450">parent</a><span>|</span><a href="#42418442">next</a><span>|</span><label class="collapse" for="c-42419676">[-]</label><label class="expand" for="c-42419676">[2 more]</label></div><br/><div class="children"><div class="content">&gt; can you give&#x2F;link a specific physical example?<p>About the lack of subjectivity of the states? If we consider any bit of matter (for example a crystal or an ideal gas), the macrostate is completely independent of the observer: it’s just the state in which the law of physics say that bit of matter should be. In an ideal gas it is entirely determined by the pressure and volume, which are anything but subjective. For a crystal it is more complex because we have to account for things like its shape but the reasoning is the same.<p>Then, the microstates are just accessible states, and this is also dictated by Physics. For example, it is quite easy to see that a crystal has fewer accessible states than a gas (the atoms’ positions are constrained and the velocities are limited to the crystal’s vibration modes). We can calculate the entropy in the experimental conditions within that framework, or in the case of correlated liquids, or amorphous solids, or whatever. But the fact that we can come up with different entropies if we make different hypotheses does not mean that any of these hypotheses is actually valid. If we measure the entropy directly we might have a value that is consistent with several models, or none. The actual entropy is what we observe, not the theoretical scaffolding we use to try to make sense of it. And again, this is not subjective.</div><br/><div id="42420028" class="c"><input type="checkbox" id="c-42420028" checked=""/><div class="controls bullet"><span class="by">oh_my_goodness</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42419676">parent</a><span>|</span><a href="#42418442">next</a><span>|</span><label class="collapse" for="c-42420028">[-]</label><label class="expand" for="c-42420028">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, sure. Of course it&#x27;s not subjective.<p>Is there a concrete physical example where the information-theory definition of entropy conflicts with experiment?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42417769" class="c"><input type="checkbox" id="c-42417769" checked=""/><div class="controls bullet"><span class="by">markisus</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417034">parent</a><span>|</span><a href="#42418442">prev</a><span>|</span><a href="#42415944">next</a><span>|</span><label class="collapse" for="c-42417769">[-]</label><label class="expand" for="c-42417769">[10 more]</label></div><br/><div class="children"><div class="content">Maybe the experimental apparatus is not objective. The quantities we choose to measure are dictated by our psychological and physiological limitations. The volume of a container is not objectively defined. An organism which lives at a faster time scale will see the walls of the container vibrating and oscillating. You must convince the organism to average these measurements over a certain time scale. This averaging throws away information. This is the same with other thermodynamic quantities.</div><br/><div id="42418237" class="c"><input type="checkbox" id="c-42418237" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417769">parent</a><span>|</span><a href="#42418479">next</a><span>|</span><label class="collapse" for="c-42418237">[-]</label><label class="expand" for="c-42418237">[8 more]</label></div><br/><div class="children"><div class="content">&gt; The quantities we choose to measure are dictated by our psychological and physiological limitations.<p>No. The enthalpy changes measured by a calorimeter are not dependent on our psychological limitations.<p>&gt; The volume of a container is not objectively defined.<p>Yes, it is, for any reasonable definition of &quot;objective&quot;. We know how to measure lengths, we know how they change when we use different frames of reference so there is no situation in which a volume is subjective.<p>&gt; An organism which lives at a faster time scale will see the walls of the container vibrating and oscillating.<p>This does not matter. We defined a time scale from periodic physical phenomena, and then we know how time changes depending on the frame of reference. There is no subjectivity in this, whatever is doing the measurement has no role in it. Time does not depend on how you feel. It’s Physics, not Psychology.<p>&gt; This is the same with other thermodynamic quantities.<p>No, it’s really not. You seem to know just enough vocabulary to be dangerous and I encourage you to read an introductory Physics textbook.</div><br/><div id="42418563" class="c"><input type="checkbox" id="c-42418563" checked=""/><div class="controls bullet"><span class="by">notfed</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42418237">parent</a><span>|</span><a href="#42418669">next</a><span>|</span><label class="collapse" for="c-42418563">[-]</label><label class="expand" for="c-42418563">[2 more]</label></div><br/><div class="children"><div class="content">Sometimes I wish HN had merit badges. Or if you like,  a device to measure the amount of information contained within a post.</div><br/><div id="42419464" class="c"><input type="checkbox" id="c-42419464" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42418563">parent</a><span>|</span><a href="#42418669">next</a><span>|</span><label class="collapse" for="c-42419464">[-]</label><label class="expand" for="c-42419464">[1 more]</label></div><br/><div class="children"><div class="content">I am not sure it would help, I think it would just enhance groupthink. I like how you need to write something obviously stupid or offensive for the downvotes to have a visible effect and that upvotes have no visible effect at all. (Yes, it changes ranking, but there are other factors). People are less prejudiced when they read the comment than if they see that it is already at -3 or +5.<p>Yes, it means that some posts should be more (or less) visible than they are but overall I think it’s a good balance.<p>Besides, I am not that interested in the absolute amount of information in a post. I want information that is relevant to me, and <i>that</i> is very subjective :)</div><br/></div></div></div></div><div id="42418669" class="c"><input type="checkbox" id="c-42418669" checked=""/><div class="controls bullet"><span class="by">whatshisface</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42418237">parent</a><span>|</span><a href="#42418563">prev</a><span>|</span><a href="#42418479">next</a><span>|</span><label class="collapse" for="c-42418669">[-]</label><label class="expand" for="c-42418669">[5 more]</label></div><br/><div class="children"><div class="content">The enthalpy changes measured by a calorimeter are dependent on the design of the calorimeter, which could have been a different piece of equipment. In a sense, that makes it dependent on the definition of enthalpy.<p>If you introduced a new bit of macro information to the definition of an ensemble, you&#x27;d divide the number of microstates by some factor. That&#x27;s the micro level equivalent of macroscopic entropy being undefined up to an additive constant.<p>The measurables don&#x27;t tell you S, they only tell you dS.</div><br/><div id="42419423" class="c"><input type="checkbox" id="c-42419423" checked=""/><div class="controls bullet"><span class="by">kergonath</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42418669">parent</a><span>|</span><a href="#42418479">next</a><span>|</span><label class="collapse" for="c-42419423">[-]</label><label class="expand" for="c-42419423">[4 more]</label></div><br/><div class="children"><div class="content">&gt; The enthalpy changes measured by a calorimeter are dependent on the design of the calorimeter, which could have been a different piece of equipment.<p>Right, but that is true of anything. Measuring devices need to be calibrated and maintained properly. It does not make something like a distance subjective, just because someone is measuring it in cm and someone else in km.<p>&gt; If you introduced a new bit of macro information to the definition of an ensemble, you&#x27;d divide the number of microstates by some factor. That&#x27;s the micro level equivalent of macroscopic entropy being undefined up to an additive constant.<p>It would change the entropy <i>of your model</i>. An ensemble in statistical Physics is not a physical object. It is a mental construct and a tool to calculate properties. An actual material would have whatever entropy it wants to have regardless of any assumptions we make. You would just find that the entropy of the material would match the entropy of one of the models better than the other one. If you change your mind and re-run the experiment, you’d still find the same entropy. This happens e.g. if we assume that the experiment is at a constant volume while it is actually under constant pressure, or the other way around.<p>&gt; In a sense, that makes it dependent on the definition of enthalpy.<p>Not really. A joule is a joule, a kelvin is a kelvin, and the basic laws of thermodynamics are some of the most well tested in all of science. The entropy of a bunch of atoms is not more dependent on arbitrary definitions than the energy levels of the atoms.<p>&gt; The measurables don&#x27;t tell you S, they only tell you dS.<p>That’s true in itself, the laws of Thermodynamics are invariant if we add a constant term to the entropy. But it does not mean that entropy is subjective: two observers agreeing that the thing they are observing has an entropy of 0 at 0 K will always measure the same entropy in the same conditions. And it does not mean that actual entropy is dependent on specific assumptions about the state of the thing.<p>This is also true of energy, and electromagnetic potentials (and potentials in general). This is unrelated to entropy being something special or subjective.</div><br/><div id="42420092" class="c"><input type="checkbox" id="c-42420092" checked=""/><div class="controls bullet"><span class="by">whatshisface</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42419423">parent</a><span>|</span><a href="#42418479">next</a><span>|</span><label class="collapse" for="c-42420092">[-]</label><label class="expand" for="c-42420092">[3 more]</label></div><br/><div class="children"><div class="content">Entropy isn&#x27;t subjective, but it is relative to what you can measure about a given system, or what measurements you are analyzing a system with respect to. In quantum mechanics there are degenerate ground states, and in classical mechanics there are cases where the individual objects (such as stars) are visible but averaged over. You should take a look at the Gibbs paradox.</div><br/><div id="42420692" class="c"><input type="checkbox" id="c-42420692" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42420092">parent</a><span>|</span><a href="#42418479">next</a><span>|</span><label class="collapse" for="c-42420692">[-]</label><label class="expand" for="c-42420692">[2 more]</label></div><br/><div class="children"><div class="content">I would say an even more limiting measure of entropy shows that entropy isn&#x27;t subjective. That is entropy is the ability to extract useful work from a system by moving the system from a state of lower entropy to a state of higher entropy (in a closed system)<p>No subjective measure of entropy can allow you to create a perpetual motion machine. The measurements of any two separate closed systems could be arbitrary, but when said systems are compared with each other units and measurements standardize.</div><br/><div id="42420806" class="c"><input type="checkbox" id="c-42420806" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42420692">parent</a><span>|</span><a href="#42418479">next</a><span>|</span><label class="collapse" for="c-42420806">[-]</label><label class="expand" for="c-42420806">[1 more]</label></div><br/><div class="children"><div class="content">&gt; entropy is the ability to extract useful work from a system<p><a href="https:&#x2F;&#x2F;www.damtp.cam.ac.uk&#x2F;user&#x2F;tong&#x2F;statphys&#x2F;jaynes.pdf" rel="nofollow">https:&#x2F;&#x2F;www.damtp.cam.ac.uk&#x2F;user&#x2F;tong&#x2F;statphys&#x2F;jaynes.pdf</a><p>The amount of useful work that we can extract from any system depends - obviously and necessarily - on how much “subjective” information we have about its microstate, because that tells us which interactions will extract energy and which will not; this is not a paradox, but a platitude. If the entropy we ascribe to a macrostate did not represent some kind of human information about the underlying microstates, it could not perform its thermodynamic function of determining the amount of work that can be extracted reproducibly from that macrostate. […] the rules of thermodynamics are valid and correctly describe the measurements that it is possible to make by manipulating the macro variables within the set that we have chosen to use. This useful versatility - a direct result of and illustration of the “anthropomorphic” nature of entropy - would not be apparent to, and perhaps not believed by, someone who thought that entropy was, like energy, a physical property of the microstate.<p>Edit: I’ve just noticed that the article discussed links to this paper, and quotes the first sentence above, and details the whifnium example given in the […] above.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="42415944" class="c"><input type="checkbox" id="c-42415944" checked=""/><div class="controls bullet"><span class="by">niemandhier</span><span>|</span><a href="#42415797">parent</a><span>|</span><a href="#42417034">prev</a><span>|</span><a href="#42416040">next</a><span>|</span><label class="collapse" for="c-42415944">[-]</label><label class="expand" for="c-42415944">[8 more]</label></div><br/><div class="children"><div class="content">In physics the requirement for a valid changing the frame of reference is, that the laws of physics transform according to the transformation.<p>Every observer should discover the same fundamental laws when performing experiments and using the scientific method.<p>To stay in your analogy, saying 5 and 6 are the same would only work if the rules of the game you play could transform in such a way that an observer making a distinction between the two would arrive at the correctly transformed rules in his frame of reference.<p>Given that we have things like neutron stars, black holes and other objects that are at the same time objects of quantum physics and general relativity, the statement feels pretty fundamental to me, to a degree even that I wonder if it might be phrased to strongly.</div><br/><div id="42416099" class="c"><input type="checkbox" id="c-42416099" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42415944">parent</a><span>|</span><a href="#42416040">next</a><span>|</span><label class="collapse" for="c-42416099">[-]</label><label class="expand" for="c-42416099">[7 more]</label></div><br/><div class="children"><div class="content">I think you may have misunderstood the OP&#x27;s point - the entropy you calculate for a system depends on how you factor the system into micro and macro states. This doesn&#x27;t really have anything to do with changes of reference frame - in practice it&#x27;s more about limitations on the kinds of measurements you can make of the system.<p>(you can&#x27;t measure the individual states of all the particles in a body of gas, for instance, so you factor it into macrostate variables like pressure&#x2F;temperature&#x2F;volume and such)</div><br/><div id="42417240" class="c"><input type="checkbox" id="c-42417240" checked=""/><div class="controls bullet"><span class="by">niemandhier</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42416099">parent</a><span>|</span><a href="#42416940">next</a><span>|</span><label class="collapse" for="c-42417240">[-]</label><label class="expand" for="c-42417240">[2 more]</label></div><br/><div class="children"><div class="content">From a thermodynamics point of view only the differential of the entropy matters, so if there is only a fixed difference between the two computations they do not influence the physics.<p>If the way one does the coarse graining of states results in different differentials, one way should be the correct one.<p>There is only one physics.<p>If I remember one of Plancks relevations was that he could explain why a certain  corrections factor was needed in entropy calculations, since phase space had finished cell size.</div><br/><div id="42417935" class="c"><input type="checkbox" id="c-42417935" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417240">parent</a><span>|</span><a href="#42416940">next</a><span>|</span><label class="collapse" for="c-42417935">[-]</label><label class="expand" for="c-42417935">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s true - for instance I believe many of the results of statistical mechanics rely on further assumptions about your choice of macrostates, like the fact that they are ergodic (i.e. the system visits each microstate within a macrostate with equal probability on average). Obviously exotic choices of macrostates will violate these assumptions, and so I would expect the predictions such a model makes to be incorrect.<p>But ultimately that&#x27;s an empirical question. Entropy is a more general concept that&#x27;s definable regardless of whether the model is accurate or not.</div><br/></div></div></div></div><div id="42416940" class="c"><input type="checkbox" id="c-42416940" checked=""/><div class="controls bullet"><span class="by">lizzas</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42416099">parent</a><span>|</span><a href="#42417240">prev</a><span>|</span><a href="#42416040">next</a><span>|</span><label class="collapse" for="c-42416940">[-]</label><label class="expand" for="c-42416940">[4 more]</label></div><br/><div class="children"><div class="content">Can we take the anthropic out of this? I reckon it&#x27;ll make things easier.<p>Instead of me knowing, do other physical objects get affected. I might get anemsia and forget what the dots on a dice mean and say they are all the same: all dotty!<p>Imagine each hydrogen atom has a hidden guid but this is undetectable and has no effect on anything else. This is a secret from the rest of physics!<p>I guess!!! (Armchair pondering!) that that guid cannot be taken into account for entropy changes. At least from any practical standpoint.<p>You could imagine each atom having a guid and come up with a scheme to hash the atom based on where it came from ... but is that info really there and if so does it affect anything physically beyond that atoms current state (as defined by stuff that affects other stuff).</div><br/><div id="42416977" class="c"><input type="checkbox" id="c-42416977" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42416940">parent</a><span>|</span><a href="#42416040">next</a><span>|</span><label class="collapse" for="c-42416977">[-]</label><label class="expand" for="c-42416977">[3 more]</label></div><br/><div class="children"><div class="content">What anthropic do you mean? I&#x27;m describing properties of models, not people. Physics (probably) doesn&#x27;t care what you &quot;know&quot;.<p>On the guid idea - fundamental particles are indistinguishable from one another in quantum mechanics, so they don&#x27;t have anything like a guid even in principle. There is no experiment you could perform on an electron to determine whether it had been swapped out for a &quot;different&quot; one, for instance.<p>Maybe I&#x27;m missing your point though?</div><br/><div id="42417030" class="c"><input type="checkbox" id="c-42417030" checked=""/><div class="controls bullet"><span class="by">lizzas</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42416977">parent</a><span>|</span><a href="#42416040">next</a><span>|</span><label class="collapse" for="c-42417030">[-]</label><label class="expand" for="c-42417030">[2 more]</label></div><br/><div class="children"><div class="content">Sorry ... I am replying mostly to the dice idea which wasn&#x27;t you.<p>Yes correct about the guid idea. My point is the discussion is easier to follow if grounded in reality (as best modelled since that is all we have plus some evidence stored in the same &quot;SSD&quot;!)</div><br/><div id="42417057" class="c"><input type="checkbox" id="c-42417057" checked=""/><div class="controls bullet"><span class="by">bubblyworld</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417030">parent</a><span>|</span><a href="#42416040">next</a><span>|</span><label class="collapse" for="c-42417057">[-]</label><label class="expand" for="c-42417057">[1 more]</label></div><br/><div class="children"><div class="content">Oh I see. But on your guid thing, people often describe entropy in terms of the set of micro states of your system (the actually physical states in your model) and the macro states (sets of microstates that are described by a collection of high-level state variables like pressure&#x2F;temperature).<p>Physically indistinguishable stuff would have the same <i>micro state</i>, so yeah, they wouldn&#x27;t affect entropy calculations at all, no matter what macro states you picked.<p>But I disagree a bit about grounding things in reality - some concepts are quite abstract and having clean examples can be helpful, before you start applying them to the mess that is our universe!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42416040" class="c"><input type="checkbox" id="c-42416040" checked=""/><div class="controls bullet"><span class="by">guerrilla</span><span>|</span><a href="#42415797">parent</a><span>|</span><a href="#42415944">prev</a><span>|</span><a href="#42419092">next</a><span>|</span><label class="collapse" for="c-42416040">[-]</label><label class="expand" for="c-42416040">[5 more]</label></div><br/><div class="children"><div class="content">&gt; mundane observation<p>What makes an observation mundane? I think what you said is insightful and demonstrates intelligence. I don&#x27;t think it&#x27;s at all obvious to the masses of students that have poured over introductory physics textbooks. In fact, it seems to me that often entropy is taught poorly and that very few people understood it well but that we are beginning to correct that. I point to the heaps of popsci magazines, documentaries and YouTube videos failing to do anything but confuse the public as additional evidence.</div><br/><div id="42417378" class="c"><input type="checkbox" id="c-42417378" checked=""/><div class="controls bullet"><span class="by">LudwigNagasena</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42416040">parent</a><span>|</span><a href="#42419092">next</a><span>|</span><label class="collapse" for="c-42417378">[-]</label><label class="expand" for="c-42417378">[4 more]</label></div><br/><div class="children"><div class="content">Maybe if you opened only introductory physics textbooks then it’s not mundane; but If you opened introductory information theory textbooks, statistical textbooks, introductions to Bayesian probability theory, articles about MaxEnt thermodynamics including articles by E.T. Jaynes, then it’s a quite mundane observation.</div><br/><div id="42418507" class="c"><input type="checkbox" id="c-42418507" checked=""/><div class="controls bullet"><span class="by">mitthrowaway2</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417378">parent</a><span>|</span><a href="#42418390">prev</a><span>|</span><a href="#42417696">next</a><span>|</span><label class="collapse" for="c-42418507">[-]</label><label class="expand" for="c-42418507">[1 more]</label></div><br/><div class="children"><div class="content">Jaynes definitely made the case for this a long time ago, and in my opinion he&#x27;s correct, but I think that view is still not mainstream; or even if mainstream, certainly not dominant. So I think we should welcome other people who reach it on their own journey, even if they aren&#x27;t the first to arrive there.</div><br/></div></div><div id="42417696" class="c"><input type="checkbox" id="c-42417696" checked=""/><div class="controls bullet"><span class="by">guerrilla</span><span>|</span><a href="#42415797">root</a><span>|</span><a href="#42417378">parent</a><span>|</span><a href="#42418507">prev</a><span>|</span><a href="#42419092">next</a><span>|</span><label class="collapse" for="c-42417696">[-]</label><label class="expand" for="c-42417696">[1 more]</label></div><br/><div class="children"><div class="content">So, what you&#x27;re saying is, not very mundane at all and, in fact, that it&#x27;s specialized knowledge requiring advanced education. ;)</div><br/></div></div></div></div></div></div></div></div><div id="42419092" class="c"><input type="checkbox" id="c-42419092" checked=""/><div class="controls bullet"><span class="by">shorefire</span><span>|</span><a href="#42415797">prev</a><span>|</span><a href="#42416483">next</a><span>|</span><label class="collapse" for="c-42419092">[-]</label><label class="expand" for="c-42419092">[1 more]</label></div><br/><div class="children"><div class="content">For the longest time I had no real intuition of what entropy actually represented. This veritasium video explained it in a way that finally clicked for me: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=DxL2HoqLbyA" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=DxL2HoqLbyA</a></div><br/></div></div><div id="42416483" class="c"><input type="checkbox" id="c-42416483" checked=""/><div class="controls bullet"><span class="by">inshard</span><span>|</span><a href="#42419092">prev</a><span>|</span><a href="#42416103">next</a><span>|</span><label class="collapse" for="c-42416483">[-]</label><label class="expand" for="c-42416483">[1 more]</label></div><br/><div class="children"><div class="content">Fails to mention Heisenberg uncertainty, which in my opinion is a theoretical ceiling to this approach. Also it needs to account for cost of compute relative potential useful work from these quantum engines. If the energy cost of compute exceeds potential useful work, then it’s still net negative (or useless work). Finally there’s the question of hidden patterns and the spectrum of randomness. Some systems are more random than others. The potential for useful work within a reasonable energy cost of compute will decline when we travel down the spectrum of randomness. Systems which are at maximal Heisenberg uncertainty, I.e. particles are not entangled, and have no correlation with a superstructure of other entangled particles, will not hold any further improvement to knowledge and thus zero potential work. This is the ultimate entropy of the local and macro system. Probably also the cause of certain violation of conservation of energy principles, such as dark energy.</div><br/></div></div><div id="42416103" class="c"><input type="checkbox" id="c-42416103" checked=""/><div class="controls bullet"><span class="by">perihelions</span><span>|</span><a href="#42416483">prev</a><span>|</span><a href="#42416542">next</a><span>|</span><label class="collapse" for="c-42416103">[-]</label><label class="expand" for="c-42416103">[1 more]</label></div><br/><div class="children"><div class="content">A related thread from earlier this year,<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41037981">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41037981</a> (<i>&quot;What Is Entropy? (johncarlosbaez.wordpress.com)&quot;</i>, 209 comments)</div><br/></div></div><div id="42416542" class="c"><input type="checkbox" id="c-42416542" checked=""/><div class="controls bullet"><span class="by">daoboy</span><span>|</span><a href="#42416103">prev</a><span>|</span><a href="#42416120">next</a><span>|</span><label class="collapse" for="c-42416542">[-]</label><label class="expand" for="c-42416542">[5 more]</label></div><br/><div class="children"><div class="content">The interactive graphic that tries to show entropy is subjective doesn&#x27;t sit right for me.<p>They fail to properly define the macrostate of the system under consideration, then show two different observed entropies for two different macrostates (Colors for Alice and Shapes for Bob).<p>That doesn&#x27;t show entropy is subjective, it shows that defining the system is subjective. The same two macrostates would still have the same entropy</div><br/><div id="42421507" class="c"><input type="checkbox" id="c-42421507" checked=""/><div class="controls bullet"><span class="by">derbOac</span><span>|</span><a href="#42416542">parent</a><span>|</span><a href="#42418061">next</a><span>|</span><label class="collapse" for="c-42421507">[-]</label><label class="expand" for="c-42421507">[1 more]</label></div><br/><div class="children"><div class="content">I had a lot of questions about similar issues, mostly surrounding the question of &quot;what is the nature of &#x27;subjective&#x27;?&quot;<p>The article deals with this a bit but not as much as I would like — maybe because of the state of the literature?<p>The linked paper by Safranek et al on observational entropy was sort of interesting, noting how a choice of coarse graining in to macrostates could lead to different entropies, but it doesn&#x27;t really address the question of why you&#x27;d choose a coarse graining or macrostate to begin with, which seems critical in all of this?<p>In the information theory literature, there&#x27;s a certain information cost (in a Kolmogorov complexity sense) associated with choosing a given coarse graining or macrostate to begin with — in their example, choosing shape or color to define entropy against. So my intuition is that the observational entropy is kind of part of a larger entropy or informational cost including that of the coarse graining that&#x27;s chosen.<p>This kind of loops back to what they discuss later about costs of observation and information bottlenecks, but it (and the articles it links to) don&#x27;t really seem to address this issue of differential macrostate costs explicitly in detail? It&#x27;s a bit unclear to me; it seems like there&#x27;s discussion that there <i>is</i> a thermodynamic cost but not how that cost accrues, or why you&#x27;d adopt one macrostate vs another (note Alice and Bob in their subjectivity example are defined by different physical constraints, and can be thought of two observational systems with different constraints).<p>It&#x27;s also interesting to me to think about it from another perspective, which is let&#x27;s say you have a box full of a large number of particles that are &quot;purely random&quot;. In that scenario it doesn&#x27;t really matter what Alice and Bob see, only the number of particles etc. The entropy with regard to say, color, will depend on the number of colors, not the position of the particles because they&#x27;re maximally entropic. In reorganizing the particles with reference to a certain property, they&#x27;re each decreasing the entropy from that purely random state by a certain amount that I can think be related in some way to the information involved in returning the particles to a purely random state?<p>A lot of the article has links to other scientific and mathematical domains. Some of the stuff about information costs of observation has ties in the math and computer science literature through Wolpert (2008) who approaches it from a computational perspective, and later Rukavicka. There&#x27;s similar ideas in the neuroscience literature about entropy reduction efficiency (the names of some of the people involved there I&#x27;m forgetting).<p>I really liked this Quanta piece but there&#x27;s a lot of fuzziness around certain areas and I couldn&#x27;t tell if that was just due to fuzzy writing,fuzzy state of the literature, or my poor understanding of things.</div><br/></div></div><div id="42418061" class="c"><input type="checkbox" id="c-42418061" checked=""/><div class="controls bullet"><span class="by">markisus</span><span>|</span><a href="#42416542">parent</a><span>|</span><a href="#42421507">prev</a><span>|</span><a href="#42417499">next</a><span>|</span><label class="collapse" for="c-42418061">[-]</label><label class="expand" for="c-42418061">[1 more]</label></div><br/><div class="children"><div class="content">Maybe if you take Alice and Bob to be two separate alien species it could make more sense. Alice’s species has no measurement devices capable of detecting Bob’s version of entropy, and therefore Alice is not able to extract any useful work from Bob’s system and vice versa. Therefore any objective definition of entropy needs to include the capabilities of the measurer. Which is just the same as what you were saying about macrostates.</div><br/></div></div><div id="42417499" class="c"><input type="checkbox" id="c-42417499" checked=""/><div class="controls bullet"><span class="by">Serenade</span><span>|</span><a href="#42416542">parent</a><span>|</span><a href="#42418061">prev</a><span>|</span><a href="#42416120">next</a><span>|</span><label class="collapse" for="c-42417499">[-]</label><label class="expand" for="c-42417499">[2 more]</label></div><br/><div class="children"><div class="content">Thank you for articulating what was bothering me about this.<p>I couldn&#x27;t quite put my finger on it, but you&#x27;re right. They are confusing defining the system with defining the entropy of a system and then saying it&#x27;s the entropy that is subjective. That isn&#x27;t the case at all. Entropy is just a measurement.</div><br/><div id="42421303" class="c"><input type="checkbox" id="c-42421303" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#42416542">root</a><span>|</span><a href="#42417499">parent</a><span>|</span><a href="#42416120">next</a><span>|</span><label class="collapse" for="c-42421303">[-]</label><label class="expand" for="c-42421303">[1 more]</label></div><br/><div class="children"><div class="content">That can&#x27;t be right, because the arrow of time depends on the universe being in a high entropy state when the Big Bang happened. There were no observers then. Also, the 2nd law of thermodynamics doesn&#x27;t depend on observers. The universe overall will continue to evolve into a higher entropy state without any intelligent observers making measurements. As in stars will burn out and blackholes will evaporate, and the temperature of the universe will get close to absolute zero.</div><br/></div></div></div></div></div></div><div id="42416120" class="c"><input type="checkbox" id="c-42416120" checked=""/><div class="controls bullet"><span class="by">ChaitanyaSai</span><span>|</span><a href="#42416542">prev</a><span>|</span><a href="#42417257">next</a><span>|</span><label class="collapse" for="c-42416120">[-]</label><label class="expand" for="c-42416120">[2 more]</label></div><br/><div class="children"><div class="content">Lovely article. The subjective nature of entropy and information immediately makes me think of the IIT theory (integrated information theory) of consciousness and its foundational futility. Information cannot be discussed without perspective. Someone has to define the states. A die have 6 states only to us humans. What about an ant that&#x27;s likely to have the die land on it? Bringing the observer back into discussions of information is fascinating because it then begs the question: How is the observer put together? And how does a perspective, an I, emerge in a multi-trillion-cell entity?
For those interested in this detour, you might like reading this and our book (mentioned in there)<p><a href="https:&#x2F;&#x2F;saigaddam.medium.com&#x2F;consciousness-is-a-consensus-mechanism-2b399c9ec4b5" rel="nofollow">https:&#x2F;&#x2F;saigaddam.medium.com&#x2F;consciousness-is-a-consensus-me...</a></div><br/><div id="42417245" class="c"><input type="checkbox" id="c-42417245" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#42416120">parent</a><span>|</span><a href="#42417257">next</a><span>|</span><label class="collapse" for="c-42417245">[-]</label><label class="expand" for="c-42417245">[1 more]</label></div><br/><div class="children"><div class="content">For me CS with Physics BSc, it&#x27;s always fascinating to still see how entropy is still sich a wild measure.</div><br/></div></div></div></div><div id="42417257" class="c"><input type="checkbox" id="c-42417257" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42416120">prev</a><span>|</span><a href="#42416256">next</a><span>|</span><label class="collapse" for="c-42417257">[-]</label><label class="expand" for="c-42417257">[11 more]</label></div><br/><div class="children"><div class="content">Makes sense. If we knew the theory of everything and the initial conditions of the universe, then we could just compute the next episode of a series instead of streaming it.</div><br/><div id="42417355" class="c"><input type="checkbox" id="c-42417355" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#42417257">parent</a><span>|</span><a href="#42420181">next</a><span>|</span><label class="collapse" for="c-42417355">[-]</label><label class="expand" for="c-42417355">[5 more]</label></div><br/><div class="children"><div class="content">Not necessarily. A theory of everything does not imply either the computability of a future state or determinism.<p>Even if our ToE is deterministic the universe may be computationally irreducible, meaning it cannot be computed accurately at lower resolution in all cases. Note that such a universe could contain within it regions that are computationally reducible, just not the whole and not all regions.<p>I would expect a ToE to give us knowable bounds to either determinism or computability. It should tell us what is precisely knowable or predictable and what isn’t.<p>Edit: to understand how a ToE could leave some things unknowable (but tell us what they are) consider the Hubble horizon. Light beyond it will never reach us making sufficiently distant things unknowable.<p>Limits may be great. It means we can at least subjectively consider ourselves as having free will — even with a deterministic theory it may be unknowable determinism. It’s just like how the speed of light might be why we got to evolve before being bum rushed by aliens.</div><br/><div id="42417569" class="c"><input type="checkbox" id="c-42417569" checked=""/><div class="controls bullet"><span class="by">FrustratedMonky</span><span>|</span><a href="#42417257">root</a><span>|</span><a href="#42417355">parent</a><span>|</span><a href="#42420181">next</a><span>|</span><label class="collapse" for="c-42417569">[-]</label><label class="expand" for="c-42417569">[4 more]</label></div><br/><div class="children"><div class="content">&quot;cannot be computed accurately at lower resolution&quot;<p>The Map is not the Territory.<p>Our universe is the lowest resolution. So to compute the next instant in our Universe, would need another entire Universe.<p>We could be the computation occurring.</div><br/><div id="42421332" class="c"><input type="checkbox" id="c-42421332" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#42417257">root</a><span>|</span><a href="#42417569">parent</a><span>|</span><a href="#42417668">next</a><span>|</span><label class="collapse" for="c-42421332">[-]</label><label class="expand" for="c-42421332">[1 more]</label></div><br/><div class="children"><div class="content">The entire universe could be the quantum many worlds (branches in higher dimensional Hilbert space), and you would have to compute the wave function of the universe.</div><br/></div></div><div id="42417668" class="c"><input type="checkbox" id="c-42417668" checked=""/><div class="controls bullet"><span class="by">api</span><span>|</span><a href="#42417257">root</a><span>|</span><a href="#42417569">parent</a><span>|</span><a href="#42421332">prev</a><span>|</span><a href="#42420181">next</a><span>|</span><label class="collapse" for="c-42417668">[-]</label><label class="expand" for="c-42417668">[2 more]</label></div><br/><div class="children"><div class="content">That’s what I meant, but perhaps did not describe well.</div><br/><div id="42417733" class="c"><input type="checkbox" id="c-42417733" checked=""/><div class="controls bullet"><span class="by">FrustratedMonky</span><span>|</span><a href="#42417257">root</a><span>|</span><a href="#42417668">parent</a><span>|</span><a href="#42420181">next</a><span>|</span><label class="collapse" for="c-42417733">[-]</label><label class="expand" for="c-42417733">[1 more]</label></div><br/><div class="children"><div class="content">Sorry, I was really just re-stating it, to see if I was grasping the point.</div><br/></div></div></div></div></div></div></div></div><div id="42420181" class="c"><input type="checkbox" id="c-42420181" checked=""/><div class="controls bullet"><span class="by">monadINtop</span><span>|</span><a href="#42417257">parent</a><span>|</span><a href="#42417355">prev</a><span>|</span><a href="#42417813">next</a><span>|</span><label class="collapse" for="c-42420181">[-]</label><label class="expand" for="c-42420181">[1 more]</label></div><br/><div class="children"><div class="content">a theory of everything would have to have quantum mechanics as an emergent theory and quantum mechanics is fundamentally non-deterministic. and even if it was, a theory of everything is almost certainly not going to be practically computable for the same reason that even basic non-relativistic quantum mechanics cannot even solve for a reasonably sized molecule numerically (let alone exactly - just as classical mechanics is unsolvable for more than two bodies)</div><br/></div></div><div id="42417813" class="c"><input type="checkbox" id="c-42417813" checked=""/><div class="controls bullet"><span class="by">j7ake</span><span>|</span><a href="#42417257">parent</a><span>|</span><a href="#42420181">prev</a><span>|</span><a href="#42416256">next</a><span>|</span><label class="collapse" for="c-42417813">[-]</label><label class="expand" for="c-42417813">[4 more]</label></div><br/><div class="children"><div class="content">Try it with a chaotic system like a double pendulum you’ll see the dynamics are not predictive in the long term.</div><br/><div id="42417872" class="c"><input type="checkbox" id="c-42417872" checked=""/><div class="controls bullet"><span class="by">adrianN</span><span>|</span><a href="#42417257">root</a><span>|</span><a href="#42417813">parent</a><span>|</span><a href="#42416256">next</a><span>|</span><label class="collapse" for="c-42417872">[-]</label><label class="expand" for="c-42417872">[3 more]</label></div><br/><div class="children"><div class="content">Is that true? It was my understanding that chaotic systems (with a known initial state) could be predicted to arbitrary precision by throwing enough compute at the problem. Of course knowing the initial state is impossible in the real world, „enough“ compute might not fit in the observable universe, and quantum mechanics contains true randomness…</div><br/><div id="42417981" class="c"><input type="checkbox" id="c-42417981" checked=""/><div class="controls bullet"><span class="by">philipov</span><span>|</span><a href="#42417257">root</a><span>|</span><a href="#42417872">parent</a><span>|</span><a href="#42416256">next</a><span>|</span><label class="collapse" for="c-42417981">[-]</label><label class="expand" for="c-42417981">[2 more]</label></div><br/><div class="children"><div class="content">Yes, chaotic systems can be simulated, and that&#x27;s the <i>only</i> way to find out what happens with them. The thing one can&#x27;t do is reduce them to a closed-form function of <i>x</i> and compute their value for any point along their domain. The only thing we can do is inductively figure out the next <i>x</i> from the current <i>x</i>.</div><br/><div id="42418546" class="c"><input type="checkbox" id="c-42418546" checked=""/><div class="controls bullet"><span class="by">mitthrowaway2</span><span>|</span><a href="#42417257">root</a><span>|</span><a href="#42417981">parent</a><span>|</span><a href="#42416256">next</a><span>|</span><label class="collapse" for="c-42418546">[-]</label><label class="expand" for="c-42418546">[1 more]</label></div><br/><div class="children"><div class="content">The issue is more that simulations diverge exponentially with time from any nonzero error in the initial state. With perfect knowledge of the initial conditions and parameters you could simulate the system perfectly, but you&#x27;d also need to accumulate zero numerical error along the way.<p>If you don&#x27;t demand perfection, then in practice you can do pretty well for short times.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42416256" class="c"><input type="checkbox" id="c-42416256" checked=""/><div class="controls bullet"><span class="by">tsoukase</span><span>|</span><a href="#42417257">prev</a><span>|</span><a href="#42421841">next</a><span>|</span><label class="collapse" for="c-42416256">[-]</label><label class="expand" for="c-42416256">[5 more]</label></div><br/><div class="children"><div class="content">My perspective:<p>1) entropy is a mathematical concept. Physics apply it, like any other mathematical one<p>2) math entropy does not change, everything is reversible, as it is based on known quantities<p>3) entropy measures how far we are from perfectly knowing a system<p>4) logarithm is chosen to measure entropy because of its convenient properties, not because of any deeper law. It could be a sum, a product etc<p>5) the Second thermodynamic law is a tautology: &quot;every system tends to higher entropy state because it is more common&quot; becomes &quot;the more common is the more common&quot;</div><br/><div id="42420844" class="c"><input type="checkbox" id="c-42420844" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#42416256">parent</a><span>|</span><a href="#42418791">next</a><span>|</span><label class="collapse" for="c-42420844">[-]</label><label class="expand" for="c-42420844">[3 more]</label></div><br/><div class="children"><div class="content">5) there is no every system, there is only the universe in which all systems increase in entropy even if individual objects (block of ice) do not. You&#x27;re bleeding off entropy into the universe you can never get back.</div><br/><div id="42420955" class="c"><input type="checkbox" id="c-42420955" checked=""/><div class="controls bullet"><span class="by">kgwgk</span><span>|</span><a href="#42416256">root</a><span>|</span><a href="#42420844">parent</a><span>|</span><a href="#42418791">next</a><span>|</span><label class="collapse" for="c-42420955">[-]</label><label class="expand" for="c-42420955">[2 more]</label></div><br/><div class="children"><div class="content">In classical thermodynamics, the entropy of a system is defined if and only if it is in a thermodynamic equilibrium.</div><br/><div id="42421311" class="c"><input type="checkbox" id="c-42421311" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#42416256">root</a><span>|</span><a href="#42420955">parent</a><span>|</span><a href="#42418791">next</a><span>|</span><label class="collapse" for="c-42421311">[-]</label><label class="expand" for="c-42421311">[1 more]</label></div><br/><div class="children"><div class="content">The universe isn&#x27;t in thermodynamic equilibrium, thus the arrow of time.</div><br/></div></div></div></div></div></div><div id="42418791" class="c"><input type="checkbox" id="c-42418791" checked=""/><div class="controls bullet"><span class="by">currymj</span><span>|</span><a href="#42416256">parent</a><span>|</span><a href="#42420844">prev</a><span>|</span><a href="#42421841">next</a><span>|</span><label class="collapse" for="c-42418791">[-]</label><label class="expand" for="c-42418791">[1 more]</label></div><br/><div class="children"><div class="content">i think those convenient properties are the sign of some deeper law. you do want to work with the exponential and logarithm, same as in so many other places. you don’t necessarily want some other generalized “entropy”.</div><br/></div></div></div></div><div id="42421841" class="c"><input type="checkbox" id="c-42421841" checked=""/><div class="controls bullet"><span class="by">timonoko</span><span>|</span><a href="#42416256">prev</a><span>|</span><a href="#42421984">next</a><span>|</span><label class="collapse" for="c-42421841">[-]</label><label class="expand" for="c-42421841">[1 more]</label></div><br/><div class="children"><div class="content">Mr Action Lab of Youtube defined Entropy something like &quot;Not a measure of how many states a system reaches, but a measure of how many states a system <i>can</i> reach&quot;.<p>I like this very much as it neatly summarizes information and other shit too.</div><br/></div></div><div id="42421984" class="c"><input type="checkbox" id="c-42421984" checked=""/><div class="controls bullet"><span class="by">mjan22640</span><span>|</span><a href="#42421841">prev</a><span>|</span><a href="#42417997">next</a><span>|</span><label class="collapse" for="c-42421984">[-]</label><label class="expand" for="c-42421984">[1 more]</label></div><br/><div class="children"><div class="content">Entropy is the opposite of potential.</div><br/></div></div><div id="42417997" class="c"><input type="checkbox" id="c-42417997" checked=""/><div class="controls bullet"><span class="by">ziofill</span><span>|</span><a href="#42421984">prev</a><span>|</span><a href="#42420017">next</a><span>|</span><label class="collapse" for="c-42417997">[-]</label><label class="expand" for="c-42417997">[2 more]</label></div><br/><div class="children"><div class="content">Very nice article. There’s an alternative way of thinking of the Gibbs paradox, which is to attach labels to the particles. This naturally makes them distinguishable and increases the total number of possible configurations, and with it the maximum value of the entropy.</div><br/><div id="42418238" class="c"><input type="checkbox" id="c-42418238" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#42417997">parent</a><span>|</span><a href="#42420017">next</a><span>|</span><label class="collapse" for="c-42418238">[-]</label><label class="expand" for="c-42418238">[1 more]</label></div><br/><div class="children"><div class="content">Attaching labels to the particles would make them fundamentally different types of particles, right? So it doesn’t seem that surprising that a system with different types of particles would be different.</div><br/></div></div></div></div><div id="42420017" class="c"><input type="checkbox" id="c-42420017" checked=""/><div class="controls bullet"><span class="by">kayo_20211030</span><span>|</span><a href="#42417997">prev</a><span>|</span><a href="#42417634">next</a><span>|</span><label class="collapse" for="c-42420017">[-]</label><label class="expand" for="c-42420017">[1 more]</label></div><br/><div class="children"><div class="content">Why has Quanta degenerated into a mad combination of ineffective science communication and breathless, and slightly envious references to yoga retreats in the North of England. It&#x27;s become a lifestyle magazine for the self-important, science-adjacent middlebrows. Most obviously, it&#x27;s nerd-sniping for HN.<p>And before you _instinctively_ (it will be instinctive) downvote me to oblivion, please read the piece and assure yourself that it&#x27;s not truly a piece of rote trash.</div><br/></div></div><div id="42417634" class="c"><input type="checkbox" id="c-42417634" checked=""/><div class="controls bullet"><span class="by">noiv</span><span>|</span><a href="#42420017">prev</a><span>|</span><a href="#42420979">next</a><span>|</span><label class="collapse" for="c-42417634">[-]</label><label class="expand" for="c-42417634">[3 more]</label></div><br/><div class="children"><div class="content">What about the efficiency to remove entropy? Is there a threshold our combined efforts called science cannot surpass?<p>Do we need Frank Herbert’s spice to progress?</div><br/><div id="42417746" class="c"><input type="checkbox" id="c-42417746" checked=""/><div class="controls bullet"><span class="by">Trasmatta</span><span>|</span><a href="#42417634">parent</a><span>|</span><a href="#42420979">next</a><span>|</span><label class="collapse" for="c-42417746">[-]</label><label class="expand" for="c-42417746">[2 more]</label></div><br/><div class="children"><div class="content">A localized reduction of entropy will always result in an increase of entropy in the larger system.<p>It doesn&#x27;t matter how efficient your process is, the entropy of the surrounding system will ALWAYS increase as the result of the work needed to effect a localized reduction.</div><br/><div id="42418017" class="c"><input type="checkbox" id="c-42418017" checked=""/><div class="controls bullet"><span class="by">ganzuul</span><span>|</span><a href="#42417634">root</a><span>|</span><a href="#42417746">parent</a><span>|</span><a href="#42420979">next</a><span>|</span><label class="collapse" for="c-42418017">[-]</label><label class="expand" for="c-42418017">[1 more]</label></div><br/><div class="children"><div class="content">Unless the surrounding system is already at infinite entropy.</div><br/></div></div></div></div></div></div><div id="42420979" class="c"><input type="checkbox" id="c-42420979" checked=""/><div class="controls bullet"><span class="by">kwoff</span><span>|</span><a href="#42417634">prev</a><span>|</span><a href="#42415920">next</a><span>|</span><label class="collapse" for="c-42420979">[-]</label><label class="expand" for="c-42420979">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Carnot’s book was largely disregarded by the scientific community, and he died several years later of cholera. His body was burned, as were many of his papers.&quot; Poetic? albeit depressing.</div><br/></div></div><div id="42415920" class="c"><input type="checkbox" id="c-42415920" checked=""/><div class="controls bullet"><span class="by">widea</span><span>|</span><a href="#42420979">prev</a><span>|</span><a href="#42417361">next</a><span>|</span><label class="collapse" for="c-42415920">[-]</label><label class="expand" for="c-42415920">[2 more]</label></div><br/><div class="children"><div class="content">Entropy, a measure of freedom in a contained environment.</div><br/><div id="42418109" class="c"><input type="checkbox" id="c-42418109" checked=""/><div class="controls bullet"><span class="by">rapjr9</span><span>|</span><a href="#42415920">parent</a><span>|</span><a href="#42417361">next</a><span>|</span><label class="collapse" for="c-42418109">[-]</label><label class="expand" for="c-42418109">[1 more]</label></div><br/><div class="children"><div class="content">Life, a short term attempt to reverse some entropy by creating more entropy.</div><br/></div></div></div></div><div id="42417361" class="c"><input type="checkbox" id="c-42417361" checked=""/><div class="controls bullet"><span class="by">wtcactus</span><span>|</span><a href="#42415920">prev</a><span>|</span><a href="#42419242">next</a><span>|</span><label class="collapse" for="c-42417361">[-]</label><label class="expand" for="c-42417361">[1 more]</label></div><br/><div class="children"><div class="content">I remember that somewhere during my physics degree this idea of the article clicked with me.<p>Entropy is just a simpler way of manifesting properties of a system that we didn’t measure because it is too difficult (when I was still at classical physics level) or it’s not possible to measure (when quantum mechanics became present in everything we learned).<p>We use it because we can’t measure the position and momentum of every particle (same goes for temperature) so we created theories on how a system with a particular entropy behaves, but it’s just a clever way to work with aproximations.<p>I find this idea fascinating.</div><br/></div></div><div id="42419242" class="c"><input type="checkbox" id="c-42419242" checked=""/><div class="controls bullet"><span class="by">Jerrrry</span><span>|</span><a href="#42417361">prev</a><span>|</span><a href="#42418918">next</a><span>|</span><label class="collapse" for="c-42419242">[-]</label><label class="expand" for="c-42419242">[1 more]</label></div><br/><div class="children"><div class="content">Computers are finite ergo the largest number any computer can compute is all ones in binary.<p>That&#x27;s it&#x27;s Busy Beaver number, but think how easy all ones in binary is to compress from an information theory standpoint.<p>So the most entrophic state would be the one state requiring the most compression.</div><br/></div></div><div id="42418918" class="c"><input type="checkbox" id="c-42418918" checked=""/><div class="controls bullet"><span class="by">johnea</span><span>|</span><a href="#42419242">prev</a><span>|</span><a href="#42416387">next</a><span>|</span><label class="collapse" for="c-42418918">[-]</label><label class="expand" for="c-42418918">[1 more]</label></div><br/><div class="children"><div class="content">But consider the &quot;monkeycide paradox&quot;. If we start a nuclear war, and kill every single primate on the planet, does the universe cease to exist? Does time start running in reverse? Maybe time would go back to before we nuked everyone out of existence, and life would be like one of those endless time loop anime? Will matter start spewing out of black holes instead of going in because there was no monkey there to watch it? Would it be enough if a dog observed the universe? (they&#x27;re &quot;like our family&quot; after all) or a squid? What about a yeast cell?<p>Obviously this is hyperbole 8-) but I think the point is clear. If anyone really believes that the existence of primate life on our little planet &quot;observing the universe&quot; is what makes all physical processes advance, they have some serious issues of overcharged ego.<p>Of course a theory doesn&#x27;t have to be completely correct to be useful. Old ideas of heat as a fluid have been supplanted, but they still helped design working systems in their time. Modern ideas of quantum mechanics, as incomplete as they are, still model a concept of &quot;tunneling&quot; that&#x27;s sufficiently accurate to make semiconductors work.<p>Or, you can just run with the Rovelli quote from the article: “What they’re telling me is bullshit” 8-)</div><br/></div></div><div id="42416387" class="c"><input type="checkbox" id="c-42416387" checked=""/><div class="controls bullet"><span class="by">openrisk</span><span>|</span><a href="#42418918">prev</a><span>|</span><a href="#42415861">next</a><span>|</span><label class="collapse" for="c-42416387">[-]</label><label class="expand" for="c-42416387">[7 more]</label></div><br/><div class="children"><div class="content">Is there a specific name for the art and craft of presenting a topic online (as a web page) using a flow of text interspersed with interactive activities?<p>Whatever the name of this approach, quantamagazine is definitely good at it!</div><br/><div id="42416422" class="c"><input type="checkbox" id="c-42416422" checked=""/><div class="controls bullet"><span class="by">gyomu</span><span>|</span><a href="#42416387">parent</a><span>|</span><a href="#42416453">next</a><span>|</span><label class="collapse" for="c-42416422">[-]</label><label class="expand" for="c-42416422">[2 more]</label></div><br/><div class="children"><div class="content">Some people have coined the term explorable explanation&#x2F;explorables<p><a href="https:&#x2F;&#x2F;explorabl.es&#x2F;" rel="nofollow">https:&#x2F;&#x2F;explorabl.es&#x2F;</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Explorable_explanation" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Explorable_explanation</a></div><br/><div id="42416588" class="c"><input type="checkbox" id="c-42416588" checked=""/><div class="controls bullet"><span class="by">openrisk</span><span>|</span><a href="#42416387">root</a><span>|</span><a href="#42416422">parent</a><span>|</span><a href="#42416453">next</a><span>|</span><label class="collapse" for="c-42416588">[-]</label><label class="expand" for="c-42416588">[1 more]</label></div><br/><div class="children"><div class="content">aah, this is nailing it. It helps to differentiate from game-like experiences and special purpose apps.<p>Another interesting term from the wiki link is &quot;active essays&quot;:<p>&gt; The related term &quot;active essays&quot; was used by Alan Kay to refer to text-based explorable explanations<p>But I don&#x27;t know if by text-based he meant strictly no visuals. Like just ASCII art? :-)</div><br/></div></div></div></div><div id="42416453" class="c"><input type="checkbox" id="c-42416453" checked=""/><div class="controls bullet"><span class="by">TheSpiceIsLife</span><span>|</span><a href="#42416387">parent</a><span>|</span><a href="#42416422">prev</a><span>|</span><a href="#42418991">next</a><span>|</span><label class="collapse" for="c-42416453">[-]</label><label class="expand" for="c-42416453">[2 more]</label></div><br/><div class="children"><div class="content">Multimedia?<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Multimedia" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Multimedia</a><p><i>Multimedia refers to the integration of multiple forms of content such as text, audio, images, video, and interactive elements into a single digital platform or application.</i></div><br/><div id="42416546" class="c"><input type="checkbox" id="c-42416546" checked=""/><div class="controls bullet"><span class="by">openrisk</span><span>|</span><a href="#42416387">root</a><span>|</span><a href="#42416453">parent</a><span>|</span><a href="#42418991">next</a><span>|</span><label class="collapse" for="c-42416546">[-]</label><label class="expand" for="c-42416546">[1 more]</label></div><br/><div class="children"><div class="content">Multimedia is fairly general, so it includes this but also much more.<p>Including video in particular tends to highjack the experience (you switch mode), whereas interactive elements that you explore as you keep reading feel more integrated.</div><br/></div></div></div></div><div id="42418991" class="c"><input type="checkbox" id="c-42418991" checked=""/><div class="controls bullet"><span class="by">johnea</span><span>|</span><a href="#42416387">parent</a><span>|</span><a href="#42416453">prev</a><span>|</span><a href="#42416621">next</a><span>|</span><label class="collapse" for="c-42418991">[-]</label><label class="expand" for="c-42418991">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m pretty sure this is called &quot;writing&quot;</div><br/></div></div></div></div><div id="42415861" class="c"><input type="checkbox" id="c-42415861" checked=""/><div class="controls bullet"><span class="by">pndy</span><span>|</span><a href="#42416387">prev</a><span>|</span><a href="#42416785">next</a><span>|</span><label class="collapse" for="c-42415861">[-]</label><label class="expand" for="c-42415861">[10 more]</label></div><br/><div class="children"><div class="content"><a href="http:&#x2F;&#x2F;www.thelastquestion.net&#x2F;" rel="nofollow">http:&#x2F;&#x2F;www.thelastquestion.net&#x2F;</a> - in case someone missed it somehow</div><br/><div id="42415989" class="c"><input type="checkbox" id="c-42415989" checked=""/><div class="controls bullet"><span class="by">niemandhier</span><span>|</span><a href="#42415861">parent</a><span>|</span><a href="#42420034">next</a><span>|</span><label class="collapse" for="c-42415989">[-]</label><label class="expand" for="c-42415989">[3 more]</label></div><br/><div class="children"><div class="content">Wow.<p>When did we take the turn from sci-fi like that to the ever dystopian laments we read today.</div><br/><div id="42417778" class="c"><input type="checkbox" id="c-42417778" checked=""/><div class="controls bullet"><span class="by">rcxdude</span><span>|</span><a href="#42415861">root</a><span>|</span><a href="#42415989">parent</a><span>|</span><a href="#42418357">next</a><span>|</span><label class="collapse" for="c-42417778">[-]</label><label class="expand" for="c-42417778">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s pretty cyclical, there&#x27;s older sci-fi that&#x27;s more dystopian and still older sci-fi then that which is optimistic. (and of course, the trends are only trends)</div><br/></div></div><div id="42418357" class="c"><input type="checkbox" id="c-42418357" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#42415861">root</a><span>|</span><a href="#42415989">parent</a><span>|</span><a href="#42417778">prev</a><span>|</span><a href="#42420034">next</a><span>|</span><label class="collapse" for="c-42418357">[-]</label><label class="expand" for="c-42418357">[1 more]</label></div><br/><div class="children"><div class="content">I mean they had dystopian sci-fi back then too...<p>Technology changes, yet people remain ever the assholes.</div><br/></div></div></div></div><div id="42420034" class="c"><input type="checkbox" id="c-42420034" checked=""/><div class="controls bullet"><span class="by">WillAdams</span><span>|</span><a href="#42415861">parent</a><span>|</span><a href="#42415989">prev</a><span>|</span><a href="#42416011">next</a><span>|</span><label class="collapse" for="c-42420034">[-]</label><label class="expand" for="c-42420034">[1 more]</label></div><br/><div class="children"><div class="content">Anyone know how to contact the person responsible for that site?<p>Typo:<p>&gt;Planetarv<p>should be &quot;Planetary&quot;.</div><br/></div></div><div id="42416011" class="c"><input type="checkbox" id="c-42416011" checked=""/><div class="controls bullet"><span class="by">guerrilla</span><span>|</span><a href="#42415861">parent</a><span>|</span><a href="#42420034">prev</a><span>|</span><a href="#42416785">next</a><span>|</span><label class="collapse" for="c-42416011">[-]</label><label class="expand" for="c-42416011">[5 more]</label></div><br/><div class="children"><div class="content">This is my favorite Isaac Asimov story and the reason I started reading him.</div><br/><div id="42417013" class="c"><input type="checkbox" id="c-42417013" checked=""/><div class="controls bullet"><span class="by">lizzas</span><span>|</span><a href="#42415861">root</a><span>|</span><a href="#42416011">parent</a><span>|</span><a href="#42416240">next</a><span>|</span><label class="collapse" for="c-42417013">[-]</label><label class="expand" for="c-42417013">[1 more]</label></div><br/><div class="children"><div class="content">This will be my favorite Issac Asimov story and the reason I will start reading him</div><br/></div></div><div id="42416240" class="c"><input type="checkbox" id="c-42416240" checked=""/><div class="controls bullet"><span class="by">srean</span><span>|</span><a href="#42415861">root</a><span>|</span><a href="#42416011">parent</a><span>|</span><a href="#42417013">prev</a><span>|</span><a href="#42416785">next</a><span>|</span><label class="collapse" for="c-42416240">[-]</label><label class="expand" for="c-42416240">[3 more]</label></div><br/><div class="children"><div class="content">For all who haven&#x27;t, please read the other two as well.<p>Last Answer<p>Nightfall</div><br/><div id="42416458" class="c"><input type="checkbox" id="c-42416458" checked=""/><div class="controls bullet"><span class="by">pndy</span><span>|</span><a href="#42415861">root</a><span>|</span><a href="#42416240">parent</a><span>|</span><a href="#42416785">next</a><span>|</span><label class="collapse" for="c-42416458">[-]</label><label class="expand" for="c-42416458">[2 more]</label></div><br/><div class="children"><div class="content">Gotta mention that <i>Nightfall</i> exists as both Asimov&#x27;s short story and a novel he co-wrote with Robert Silverberg nearly 50 years later</div><br/><div id="42418366" class="c"><input type="checkbox" id="c-42418366" checked=""/><div class="controls bullet"><span class="by">pessimizer</span><span>|</span><a href="#42415861">root</a><span>|</span><a href="#42416458">parent</a><span>|</span><a href="#42416785">next</a><span>|</span><label class="collapse" for="c-42418366">[-]</label><label class="expand" for="c-42418366">[1 more]</label></div><br/><div class="children"><div class="content">And that the short story is the important one.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>