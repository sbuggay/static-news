<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1738227667500" as="style"/><link rel="stylesheet" href="styles.css?v=1738227667500"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.ft.com/content/a0dfedd1-5255-4fa9-8ccc-1fe01de87ea6">OpenAI says it has evidence DeepSeek used its model to train competitor</a> <span class="domain">(<a href="https://www.ft.com">www.ft.com</a>)</span></div><div class="subtext"><span>timsuchanek</span> | <span>417 comments</span></div><br/><div><div id="42861503" class="c"><input type="checkbox" id="c-42861503" checked=""/><div class="controls bullet"><span class="by">udev</span><span>|</span><a href="#42867899">next</a><span>|</span><label class="collapse" for="c-42861503">[-]</label><label class="expand" for="c-42861503">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.is&#x2F;KiSYM" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;KiSYM</a></div><br/></div></div><div id="42867899" class="c"><input type="checkbox" id="c-42867899" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#42861503">prev</a><span>|</span><a href="#42866072">next</a><span>|</span><label class="collapse" for="c-42867899">[-]</label><label class="expand" for="c-42867899">[163 more]</label></div><br/><div class="children"><div class="content">I think there&#x27;s two different things going on here:<p>&quot;DeepSeek trained on our outputs and that&#x27;s not fair because those outputs are ours, and you shouldn&#x27;t take other peoples&#x27; data!&quot; This is obviously extremely silly, because that&#x27;s exactly how OpenAI got all of its training data in the first place - by scraping other peoples&#x27; data off the internet.<p>&quot;DeepSeek trained on our outputs, and so their claims of replicating o1-level performance from scratch are not really true&quot; This is at least plausibly a valid claim. The DeepSeek R1 paper shows that distillation is really powerful (e.g. they show Llama models get a huge boost by finetuning on R1 outputs), and if it were the case that DeepSeek were using a bunch of o1 outputs to train their model, that would legitimately cast doubt on the narrative of training efficiency. But that&#x27;s a separate question from whether it&#x27;s somehow unethical to use OpenAI&#x27;s data the same way OpenAI uses everyone else&#x27;s data.</div><br/><div id="42869501" class="c"><input type="checkbox" id="c-42869501" checked=""/><div class="controls bullet"><span class="by">riantogo</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42871917">next</a><span>|</span><label class="collapse" for="c-42869501">[-]</label><label class="expand" for="c-42869501">[84 more]</label></div><br/><div class="children"><div class="content">Why would it cast any doubt? If you can use o1 output to build a better R1. Then use R1 output to build a better X1... then a better X2.. XN, that just shows a method to create better systems for a fraction of the cost from where we stand. If it was that obvious OpenAI should have themselves done. But the disruptors did it. It hindsight it might sound obvious, but that is true for all innovations. It is all good stuff.</div><br/><div id="42869941" class="c"><input type="checkbox" id="c-42869941" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42876001">next</a><span>|</span><label class="collapse" for="c-42869941">[-]</label><label class="expand" for="c-42869941">[49 more]</label></div><br/><div class="children"><div class="content">I think it would cast doubt on the narrative &quot;you could have trained o1 with much less compute, and r1 is proof of that&quot;, if it turned out that in order to train r1 in the first place, you had to have access to bunch of outputs from o1. In other words, you had to do the really expensive o1 training in the first place.<p>(with the caveat that all we have right now are accusations that DeepSeek made use of OpenAI data - it might just as well turn out that DeepSeek really did work independently, and you really could have gotten o1-like performance with much less compute)</div><br/><div id="42870588" class="c"><input type="checkbox" id="c-42870588" checked=""/><div class="controls bullet"><span class="by">deepGem</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869941">parent</a><span>|</span><a href="#42873427">next</a><span>|</span><label class="collapse" for="c-42870588">[-]</label><label class="expand" for="c-42870588">[14 more]</label></div><br/><div class="children"><div class="content">From the R1 paper<p>In this study, we demonstrate that reasoning capabilities can be significantly
improved through large-scale reinforcement learning (RL), even without using supervised
fine-tuning (SFT) as a cold start. Furthermore, performance can be further enhanced with
the inclusion of a small amount of cold-start data<p>Is this cold start data what OpenAI is claiming their output ? If so what&#x27;s the big deal ?</div><br/><div id="42871090" class="c"><input type="checkbox" id="c-42871090" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870588">parent</a><span>|</span><a href="#42873427">next</a><span>|</span><label class="collapse" for="c-42871090">[-]</label><label class="expand" for="c-42871090">[13 more]</label></div><br/><div class="children"><div class="content">DeepSeek claims that the cold-start data is from DeepSeekV3, which is the model that has the $5.5M pricetag. If that data were actually the output of o1 (a model that had a much higher training cost, and its own RL post-training), that would significantly change the narrative of R1&#x27;s development, and what&#x27;s possible to build from scratch on a comparable training budget.</div><br/><div id="42875467" class="c"><input type="checkbox" id="c-42875467" checked=""/><div class="controls bullet"><span class="by">Loic</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871090">parent</a><span>|</span><a href="#42871224">next</a><span>|</span><label class="collapse" for="c-42875467">[-]</label><label class="expand" for="c-42875467">[3 more]</label></div><br/><div class="children"><div class="content">Not for me. As I build a chemical factory, I do not reinvent everything.<p>They are using the current SOTA tools and models to build new models for cheaper.</div><br/><div id="42875685" class="c"><input type="checkbox" id="c-42875685" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42875467">parent</a><span>|</span><a href="#42871224">next</a><span>|</span><label class="collapse" for="c-42875685">[-]</label><label class="expand" for="c-42875685">[2 more]</label></div><br/><div class="children"><div class="content">If R1 were better than O1, yes you would be right. But the reporting I’ve seen is that it’s almost as good. Being able to copy cutting edge models won’t advance the state of the art in terms of intelligence. They have made improvements in other area, but if they reused O1 to train their model, that would be effectively a ctrl-c &#x2F; ctrl-v strictly in terms of task performance.</div><br/><div id="42876117" class="c"><input type="checkbox" id="c-42876117" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42875685">parent</a><span>|</span><a href="#42871224">next</a><span>|</span><label class="collapse" for="c-42876117">[-]</label><label class="expand" for="c-42876117">[1 more]</label></div><br/><div class="children"><div class="content">Strong disagree. Copy&#x2F;paste would mean they took o1&#x27;s weights and started finetuning from there. That is  ot what happened here at all.</div><br/></div></div></div></div></div></div><div id="42871224" class="c"><input type="checkbox" id="c-42871224" checked=""/><div class="controls bullet"><span class="by">TheGeminon</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871090">parent</a><span>|</span><a href="#42875467">prev</a><span>|</span><a href="#42871846">next</a><span>|</span><label class="collapse" for="c-42871224">[-]</label><label class="expand" for="c-42871224">[5 more]</label></div><br/><div class="children"><div class="content">In the paper DeepSeek just says they have ~800k responses that they used for the cold start data on R1, and are very vague about how they got it:<p>&gt; To collect such data, we have explored several approaches: using few-shot prompting with a long CoT as an example, directly prompting models to generate detailed answers with reflection and verification, gathering DeepSeek-R1-Zero outputs in a readable format, and refining the results through post-processing by human annotators.</div><br/><div id="42872155" class="c"><input type="checkbox" id="c-42872155" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871224">parent</a><span>|</span><a href="#42871846">next</a><span>|</span><label class="collapse" for="c-42872155">[-]</label><label class="expand" for="c-42872155">[4 more]</label></div><br/><div class="children"><div class="content">My surface-level reading of these two sections is that the 800k samples come from R1-Zero (i.e. &quot;the above RL training&quot;) and V3:<p>&gt;We curate reasoning prompts and generate reasoning trajectories by performing rejection sampling from the checkpoint from the above RL training. In the previous stage, we only included data that could be evaluated using rule-based rewards. However, in this stage, we expand the dataset by incorporating additional data, some of which use a generative reward model by feeding the ground-truth and model predictions into DeepSeek-V3 for judgment.<p>&gt;For non-reasoning data, such as writing, factual QA, self-cognition, and translation, we adopt the DeepSeek-V3 pipeline and reuse portions of the SFT dataset of DeepSeek-V3. For certain non-reasoning tasks, we call DeepSeek-V3 to generate a potential chain-of-thought before answering the question by prompting.<p>The non-reasoning portion of the DeepSeek-V3 dataset is described as:<p>&gt;For non-reasoning data, such as creative writing, role-play, and simple question answering, we utilize DeepSeek-V2.5 to generate responses and enlist human annotators to verify the accuracy and correctness of the data.<p>I think if we were to take them at their word on all this, it would imply there is no specific OpenAI data in their pipeline (other than perhaps their pretraining corpus containing some incidental ChatGPT outputs that are posted on the web). I guess it&#x27;s unclear where they got the &quot;reasoning prompts&quot; and corresponding answers, so you could sneak in some OpenAI data there?</div><br/><div id="42872995" class="c"><input type="checkbox" id="c-42872995" checked=""/><div class="controls bullet"><span class="by">deepGem</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872155">parent</a><span>|</span><a href="#42871846">next</a><span>|</span><label class="collapse" for="c-42872995">[-]</label><label class="expand" for="c-42872995">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what I am gathering as well. Where is OpenAI going to have substantial proof to claim that their outputs were used ?<p>The reasoning prompts and answers for SFT from V3 you mean ? No idea. For that matter you have no idea where OpenAI got this data from either. If they open this can of worms, their can of worms will be opened as well.</div><br/><div id="42875403" class="c"><input type="checkbox" id="c-42875403" checked=""/><div class="controls bullet"><span class="by">IAmGraydon</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872995">parent</a><span>|</span><a href="#42875563">next</a><span>|</span><label class="collapse" for="c-42875403">[-]</label><label class="expand" for="c-42875403">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Where is OpenAI going to have substantial proof to claim that their outputs were used ?<p>I assume in their API logs.</div><br/></div></div><div id="42875563" class="c"><input type="checkbox" id="c-42875563" checked=""/><div class="controls bullet"><span class="by">rekttrader</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872995">parent</a><span>|</span><a href="#42875403">prev</a><span>|</span><a href="#42871846">next</a><span>|</span><label class="collapse" for="c-42875563">[-]</label><label class="expand" for="c-42875563">[1 more]</label></div><br/><div class="children"><div class="content">Shibboleths in output data</div><br/></div></div></div></div></div></div></div></div><div id="42871846" class="c"><input type="checkbox" id="c-42871846" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871090">parent</a><span>|</span><a href="#42871224">prev</a><span>|</span><a href="#42873427">next</a><span>|</span><label class="collapse" for="c-42871846">[-]</label><label class="expand" for="c-42871846">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s like the claim &quot;they showed anyone create a powerful from scratch&quot; becomes &quot;false yet true&quot;.<p>Maybe they needed OpenAI for their process. But now that their model is open source, anyone can use that as their cold start and spend the same amount.<p>&quot;From scratch&quot; is a moving target. No one who makes their model with massive data from the net is really doing anything from scratch.</div><br/><div id="42872102" class="c"><input type="checkbox" id="c-42872102" checked=""/><div class="controls bullet"><span class="by">bmicraft</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871846">parent</a><span>|</span><a href="#42873427">next</a><span>|</span><label class="collapse" for="c-42872102">[-]</label><label class="expand" for="c-42872102">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, but that kills the implied hope of building a better model for cheaper. Like this you&#x27;ll always have a ceiling of being a bit worse then the openai models.</div><br/><div id="42875337" class="c"><input type="checkbox" id="c-42875337" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872102">parent</a><span>|</span><a href="#42872903">next</a><span>|</span><label class="collapse" for="c-42875337">[-]</label><label class="expand" for="c-42875337">[1 more]</label></div><br/><div class="children"><div class="content">The logic doesn&#x27;t exactly hold, it is like saying that a student is limited by their teachers. It is certainly possible that a bad teacher will hold the student back, but ultimately a student can lag or improve on the teacher without only a little extra stimulus.<p>They probably would need some other source of truth than an existing model, but it isn&#x27;t clear how much additional data is needed.</div><br/></div></div><div id="42872903" class="c"><input type="checkbox" id="c-42872903" checked=""/><div class="controls bullet"><span class="by">reassess_blind</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872102">parent</a><span>|</span><a href="#42875337">prev</a><span>|</span><a href="#42873427">next</a><span>|</span><label class="collapse" for="c-42872903">[-]</label><label class="expand" for="c-42872903">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t DeepSeek a bit better, not worse?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42873427" class="c"><input type="checkbox" id="c-42873427" checked=""/><div class="controls bullet"><span class="by">manquer</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869941">parent</a><span>|</span><a href="#42870588">prev</a><span>|</span><a href="#42870313">next</a><span>|</span><label class="collapse" for="c-42873427">[-]</label><label class="expand" for="c-42873427">[2 more]</label></div><br/><div class="children"><div class="content">&gt; you had to do the really expensive o1 training in the first place<p>It is no better for OpenAI in this scenario either,  any competitor can easily copy their expensive training <i>without spending</i> the same, i.e. there is a second mover advantage and no economic incentive to be the first one.<p>To put it another way, the $500 Billion Stargate investment will be worth just $5Billion once the models become available for consumption, because it only will take that much to replicate the same outcomes with new techniques even if the cold start needed o1 output for RL.</div><br/><div id="42873629" class="c"><input type="checkbox" id="c-42873629" checked=""/><div class="controls bullet"><span class="by">hattmall</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42873427">parent</a><span>|</span><a href="#42870313">next</a><span>|</span><label class="collapse" for="c-42873629">[-]</label><label class="expand" for="c-42873629">[1 more]</label></div><br/><div class="children"><div class="content">Shouldn&#x27;t OpenAI be able to rather easily detect such usage?</div><br/></div></div></div></div><div id="42870313" class="c"><input type="checkbox" id="c-42870313" checked=""/><div class="controls bullet"><span class="by">MrLeap</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869941">parent</a><span>|</span><a href="#42873427">prev</a><span>|</span><a href="#42871441">next</a><span>|</span><label class="collapse" for="c-42870313">[-]</label><label class="expand" for="c-42870313">[21 more]</label></div><br/><div class="children"><div class="content">o1 wouldn&#x27;t exist without the combined compute of every mind that led to the training data they used in the first place. How many h100 equivalents are the rolling continuum of all of human history?</div><br/><div id="42870738" class="c"><input type="checkbox" id="c-42870738" checked=""/><div class="controls bullet"><span class="by">dchichkov</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870313">parent</a><span>|</span><a href="#42871441">next</a><span>|</span><label class="collapse" for="c-42870738">[-]</label><label class="expand" for="c-42870738">[20 more]</label></div><br/><div class="children"><div class="content">It should be possible to learn to reason from scratch. And the ability to reason in a long context seems to be very general.</div><br/><div id="42876142" class="c"><input type="checkbox" id="c-42876142" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870738">parent</a><span>|</span><a href="#42871107">next</a><span>|</span><label class="collapse" for="c-42876142">[-]</label><label class="expand" for="c-42876142">[1 more]</label></div><br/><div class="children"><div class="content">Possible? I guess evolution did it over the  course of a few billion years. For engineering purposes, starting from the best advanced position seems far more efficient.</div><br/></div></div><div id="42871107" class="c"><input type="checkbox" id="c-42871107" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870738">parent</a><span>|</span><a href="#42876142">prev</a><span>|</span><a href="#42871230">next</a><span>|</span><label class="collapse" for="c-42871107">[-]</label><label class="expand" for="c-42871107">[13 more]</label></div><br/><div class="children"><div class="content">How does one learn reasoning from scratch?<p>Human reasoning, as it exists today, is the result of tens of thousands of years of intuition slowly distilled down to efficient abstract concepts like &quot;numbers&quot;, &quot;zero&quot;, &quot;angles&quot;, &quot;cause&quot;, &quot;effect&quot;, &quot;energy&quot;, &quot;true&quot;, &quot;false&quot;, ...<p>I don&#x27;t know what reasoning from scratch would look like without training on examples from other reasoning beings. As human children do.</div><br/><div id="42872017" class="c"><input type="checkbox" id="c-42872017" checked=""/><div class="controls bullet"><span class="by">dchichkov</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871107">parent</a><span>|</span><a href="#42871402">next</a><span>|</span><label class="collapse" for="c-42872017">[-]</label><label class="expand" for="c-42872017">[2 more]</label></div><br/><div class="children"><div class="content">There are examples of learning reasoning from scratch with reinforcement learning.<p>Emergent tool use from multi-agent interaction is a good example - <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;emergent-tool-use&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;emergent-tool-use&#x2F;</a></div><br/><div id="42874401" class="c"><input type="checkbox" id="c-42874401" checked=""/><div class="controls bullet"><span class="by">ipaddr</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872017">parent</a><span>|</span><a href="#42871402">next</a><span>|</span><label class="collapse" for="c-42874401">[-]</label><label class="expand" for="c-42874401">[1 more]</label></div><br/><div class="children"><div class="content">Now you are asking for a perfect modeling of the system.  Reinforcement learning works by discovering boundaries.</div><br/></div></div></div></div><div id="42871402" class="c"><input type="checkbox" id="c-42871402" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871107">parent</a><span>|</span><a href="#42872017">prev</a><span>|</span><a href="#42873257">next</a><span>|</span><label class="collapse" for="c-42871402">[-]</label><label class="expand" for="c-42871402">[7 more]</label></div><br/><div class="children"><div class="content">Actually i also think it&#x27;s possible. Start with natural numbers axiom system. Form all valid sentences of increasing length. RL on a model to search for counter example or proofs. This on sufficient computer should produce superhuman math performance (efficiency) even at compute parity</div><br/><div id="42871692" class="c"><input type="checkbox" id="c-42871692" checked=""/><div class="controls bullet"><span class="by">MrLeap</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871402">parent</a><span>|</span><a href="#42871958">next</a><span>|</span><label class="collapse" for="c-42871692">[-]</label><label class="expand" for="c-42871692">[5 more]</label></div><br/><div class="children"><div class="content">I wonder how much discovery in math happens as a result in lateral thinking epiphanies. IE: A mathematician is trying to solve a problem, their mind is open to inspiration, and something in nature, or their childhood or a book synthesizes with their mental model and gives them the next node in their mental graph that leads to a solution and advancement.<p>In an axiomatic system, those solutions are checkable, but how discoverable are they when your search space starts from infinity? How much do you lose by disregarding the gritty <i>reality</i> and foam of human experience? It provides inspirational texture that helps mathematicians in the search at least.<p>Reality is a massive corpus of cause and effect that can be modeled mathematically. I think you&#x27;re throwing the baby out with the bathwater if you even want to be able to math in a vacuum. Maybe there is a self optimization spider that can crawl up the axioms and solve all of math. I think you&#x27;ll find that you can generate new math infinitely, and reality grounds it and provides the gravity to direct efforts towards things that are useful, meaningful and interesting to us.</div><br/><div id="42875349" class="c"><input type="checkbox" id="c-42875349" checked=""/><div class="controls bullet"><span class="by">danenania</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871692">parent</a><span>|</span><a href="#42871911">next</a><span>|</span><label class="collapse" for="c-42875349">[-]</label><label class="expand" for="c-42875349">[1 more]</label></div><br/><div class="children"><div class="content">A question is: what algorithms does the brain use to make these creative lateral leaps? Are they replicable?<p>Unless the brain is using physics that we don’t understand or can’t replicate, it seems that, at least theoretically, there should be a way to model what it’s doing with silicon and code.<p>States like inspiration and creativity seem to correlate in an interesting way with ‘temperature’, ‘top p’, and other LLM inputs. By turning up the randomness and accepting a wider range of output, you get more nonsense, but you also potentially get more novel insights and connections. Human creativity seems to work in a somewhat similar way.</div><br/></div></div><div id="42871911" class="c"><input type="checkbox" id="c-42871911" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871692">parent</a><span>|</span><a href="#42875349">prev</a><span>|</span><a href="#42873013">next</a><span>|</span><label class="collapse" for="c-42871911">[-]</label><label class="expand" for="c-42871911">[2 more]</label></div><br/><div class="children"><div class="content">As I mentioned in a sister comment, Gödel&#x27;s incompleteness theorems also throw a wrench into things, because you will be able to construct logically consistent &quot;truths&quot; that may not actually exist in reality. At which point, your model of reality becomes decreasingly useful.<p>At the end of the day, all theory must be empirically verified, and contextually useful reasoning simply cannot develop in a vacuum.</div><br/><div id="42875682" class="c"><input type="checkbox" id="c-42875682" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871911">parent</a><span>|</span><a href="#42873013">next</a><span>|</span><label class="collapse" for="c-42875682">[-]</label><label class="expand" for="c-42875682">[1 more]</label></div><br/><div class="children"><div class="content">Those theorems are only relevant if &quot;reasoning&quot; is taken to its logical extreme (no pun intended). If reasoning is developed&#x2F;trained&#x2F;evolved purely in order to be useful and not pushed beyond practical applications, the question of &quot;what might happen with arbitrarily long proofs&quot; doesn&#x27;t even come up.<p>On the contrary, when reasoning about the real world, one must reason starting from assumptions that are uncertain (at best) or even &quot;clearly wrong but still probably useful for this particular question&quot; (at worst). Any long and logic-heavy proof would make the results highly dubious.</div><br/></div></div></div></div><div id="42873013" class="c"><input type="checkbox" id="c-42873013" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871692">parent</a><span>|</span><a href="#42871911">prev</a><span>|</span><a href="#42871958">next</a><span>|</span><label class="collapse" for="c-42873013">[-]</label><label class="expand" for="c-42873013">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Monstrous_moonshine#Origin_of_the_term" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Monstrous_moonshine#Origin_of_...</a></div><br/></div></div></div></div><div id="42871958" class="c"><input type="checkbox" id="c-42871958" checked=""/><div class="controls bullet"><span class="by">iczero</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871402">parent</a><span>|</span><a href="#42871692">prev</a><span>|</span><a href="#42873257">next</a><span>|</span><label class="collapse" for="c-42871958">[-]</label><label class="expand" for="c-42871958">[1 more]</label></div><br/><div class="children"><div class="content">I believe <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;G%C3%B6del%27s_incompleteness_theorems" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;G%C3%B6del%27s_incompleteness_...</a> (Gödel&#x27;s incompleteness theorems) applies here</div><br/></div></div></div></div><div id="42873257" class="c"><input type="checkbox" id="c-42873257" checked=""/><div class="controls bullet"><span class="by">soerxpso</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871107">parent</a><span>|</span><a href="#42871402">prev</a><span>|</span><a href="#42871230">next</a><span>|</span><label class="collapse" for="c-42873257">[-]</label><label class="expand" for="c-42873257">[3 more]</label></div><br/><div class="children"><div class="content">There was necessarily a &quot;first reasoning being&quot; who learned reasoning from scratch, and then it&#x27;s improved from there. Humans needed tens of thousands of years because:<p>- humans experience reality at a slower pace than AI could theoretically experience a simulated reality<p>- humans have to transfer knowledge to the next generation every 80 years (in a manner that&#x27;s very lossy), and around half of each human lifespan is spent learning things that the previous generation already knew</div><br/><div id="42873677" class="c"><input type="checkbox" id="c-42873677" checked=""/><div class="controls bullet"><span class="by">addicted</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42873257">parent</a><span>|</span><a href="#42871230">next</a><span>|</span><label class="collapse" for="c-42873677">[-]</label><label class="expand" for="c-42873677">[2 more]</label></div><br/><div class="children"><div class="content">The idea that there was “necessarily a first reasoning being” is neither obvious nor likely.<p>Reasoning could very well have originally been an emergent property of a group of beings.<p>The animal kingdom is full of examples of groups being more intelligent than individuals, including in human animals as of today.<p>It’s entirely possible that reasoning emerged as a property of a group before it emerged in any individual first.</div><br/><div id="42875662" class="c"><input type="checkbox" id="c-42875662" checked=""/><div class="controls bullet"><span class="by">carlob</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42873677">parent</a><span>|</span><a href="#42871230">next</a><span>|</span><label class="collapse" for="c-42875662">[-]</label><label class="expand" for="c-42875662">[1 more]</label></div><br/><div class="children"><div class="content">I think you are focusing too much on the fact that a being needs to be an individual organism, which is kind of an implementation detail.<p>What I wonder instead is whether reasoning is a property that is either there or not there, with a sharp boundary of existence.</div><br/></div></div></div></div></div></div></div></div><div id="42871230" class="c"><input type="checkbox" id="c-42871230" checked=""/><div class="controls bullet"><span class="by">MrLeap</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870738">parent</a><span>|</span><a href="#42871107">prev</a><span>|</span><a href="#42871967">next</a><span>|</span><label class="collapse" for="c-42871230">[-]</label><label class="expand" for="c-42871230">[1 more]</label></div><br/><div class="children"><div class="content">Creating reasoning from scratch is the same task as creating an apple pie from scratch.<p>First you must invent the universe.</div><br/></div></div><div id="42871967" class="c"><input type="checkbox" id="c-42871967" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870738">parent</a><span>|</span><a href="#42871230">prev</a><span>|</span><a href="#42871894">next</a><span>|</span><label class="collapse" for="c-42871967">[-]</label><label class="expand" for="c-42871967">[3 more]</label></div><br/><div class="children"><div class="content">It <i>is</i> possible to learn to reason from scratch, that&#x27;s what R1-0 did, but the resulting chains of thought aren&#x27;t legible to humans.<p>To quote DeepSeek directly:<p>&gt; DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning. With RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. However, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates cold-start data before RL.</div><br/><div id="42872152" class="c"><input type="checkbox" id="c-42872152" checked=""/><div class="controls bullet"><span class="by">dchichkov</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871967">parent</a><span>|</span><a href="#42871894">next</a><span>|</span><label class="collapse" for="c-42872152">[-]</label><label class="expand" for="c-42872152">[2 more]</label></div><br/><div class="children"><div class="content">If you look at the benchmarks of the DeepSeek-V3-Base, it is quite capable, even in 0-shot: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;deepseek-ai&#x2F;DeepSeek-V3-Base#base-model" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;deepseek-ai&#x2F;DeepSeek-V3-Base#base-mod...</a>  This is not from scratch. These benchmark numbers are an indication that the base model already had a large number of reasoning&#x2F;LLM tokens in the pre-training set.<p>On the other hand, my take on it, the ability to do reasoning <i>in a long context</i> is a general capability. And my guess is that it can be bootstrapped from scratch, without having to do training on all of the internet or having to distill models trained on the internet.</div><br/><div id="42873475" class="c"><input type="checkbox" id="c-42873475" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872152">parent</a><span>|</span><a href="#42871894">next</a><span>|</span><label class="collapse" for="c-42873475">[-]</label><label class="expand" for="c-42873475">[1 more]</label></div><br/><div class="children"><div class="content">&gt; These benchmark numbers are an indication that the base model already had a large number of reasoning&#x2F;LLM tokens in the pre-training set.<p>But we already know that is the case: the Deepseek v3 paper says it was posttrained partly with an internal version of R1:<p>&gt; Reasoning Data. For reasoning-related datasets, including those focused on mathematics,
code competition problems, and logic puzzles, we generate the data by leveraging an internal
DeepSeek-R1 model. Specifically, while the R1-generated data demonstrates strong accuracy, it
suffers from issues such as overthinking, poor formatting, and excessive length. Our objective is
to balance the high accuracy of R1-generated reasoning data and the clarity and conciseness of
regularly formatted reasoning data.<p>And deepseekmath did a repeated cycle of this kind of thing mixing in 10% of old previously seen data with new generated data from last gen in a continuous bootstrap.</div><br/></div></div></div></div></div></div><div id="42871894" class="c"><input type="checkbox" id="c-42871894" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870738">parent</a><span>|</span><a href="#42871967">prev</a><span>|</span><a href="#42871441">next</a><span>|</span><label class="collapse" for="c-42871894">[-]</label><label class="expand" for="c-42871894">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been giving this a lot of thought over the last few months. My personal insight is that &quot;reasoning&quot; is simply the application of a probabilistic reasoning manifold on an input in order to transform it into constrained output that serves the stability or evolution of a system.<p>This manifold is constructed via learning a decontextualized pattern space on a given set of inputs. Given the inherent probabilistic nature of sampling, true reasoning is expressed in terms of probabilities, not axioms. It may be possible to discover axioms by locating fixed points or attractors on the manifold, but ultimately you&#x27;re looking at a probabilistic manifold constructed from your input set.<p>But I don&#x27;t think you can untie this &quot;reasoning&quot; from your input data. It&#x27;s possible you will find &quot;meta-reasoning&quot;, or similar structures found in any sufficiently advanced reasoning manifold, but these highly decontextualized structures might be entirely useless without proper recontextualization, necessitating that a reasoning manifold is trained on input whose patterns follow learnable underlying rules, if the manifold is to be useful for processing input of that kind.<p>Decontextualization <i>is</i> learning, decomposing aspects of an input into context-agnostic relationships. But recontextualization is the other half of that, knowing how to take highly abstract, sometimes inexpressible, context-agnostic relationships and transform them into useful analysis in novel domains.<p>This doesn&#x27;t mean a well-trained model can&#x27;t reason about input it hasn&#x27;t encountered before, just that the input needs to be in <i>some</i> way causally connected to the same laws which governed the input the manifold was trained on.<p>I&#x27;m sure we could create a fully generalized reasoning manifold which could handle <i>anything</i>, but I don&#x27;t see how we possibly get that without first considering and encountering all possible inputs. But these inputs still have to have <i>some</i> form of constraint governed by laws that <i>must</i> be learned through sampling, otherwise you&#x27;d just be training on effectively random data.<p>The other commenter who suggested simply generating all possible sentences and training on internal consistency should probably consider Gödel&#x27;s incompleteness theorems, and that internal consistency isn&#x27;t enough to accurately model and interpret the universe. One could construct a thought experiment about an isolated brain in a jar with effectively unlimited neuronal connections, but no sensory connection to the outside world. It&#x27;s possible, with enough connections, that the likelihood of the brain conceiving of true events it hasn&#x27;t actually encountered does increase meaningfully. But the brain still has nothing to validate against, and can&#x27;t simply assume that because something is internally logically consistent, that it must exist or have existed.</div><br/></div></div></div></div></div></div><div id="42871441" class="c"><input type="checkbox" id="c-42871441" checked=""/><div class="controls bullet"><span class="by">hmottestad</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869941">parent</a><span>|</span><a href="#42870313">prev</a><span>|</span><a href="#42870269">next</a><span>|</span><label class="collapse" for="c-42871441">[-]</label><label class="expand" for="c-42871441">[3 more]</label></div><br/><div class="children"><div class="content">At the pace that DeepSeek is developing we should expect them to surpass OpenAI in not that long.<p>The big question really is, are we doing it wrong, could we have created o1 for a fraction of the price. Will o4 cost less to train than o1 did?<p>The second question is naturally. If we create a smarter LLM, can we use it to create another LLM that is even smarter?<p>It would have been fantastic if DeepSeek could have come out with an o3 competitor before o3 even became publicly available. That way we would have known for sure that we’re doing it wrong. Cause then either we could have used o1 to train a better AI or we could have just trained in a smarter and cheaper way.</div><br/><div id="42871543" class="c"><input type="checkbox" id="c-42871543" checked=""/><div class="controls bullet"><span class="by">pertymcpert</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871441">parent</a><span>|</span><a href="#42870269">next</a><span>|</span><label class="collapse" for="c-42871543">[-]</label><label class="expand" for="c-42871543">[2 more]</label></div><br/><div class="children"><div class="content">The whole discussion is about whether or not the second case of using o1 outputs to fine tune R1 is what allowed R1 to become so good. If that&#x27;s the case then your assertion that DeepSeek will surpass OpenAI doesn&#x27;t really make sense because they&#x27;re dependent on a frontier model in order to match, not surpass.</div><br/><div id="42875907" class="c"><input type="checkbox" id="c-42875907" checked=""/><div class="controls bullet"><span class="by">hmottestad</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871543">parent</a><span>|</span><a href="#42870269">next</a><span>|</span><label class="collapse" for="c-42875907">[-]</label><label class="expand" for="c-42875907">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that&#x27;s my point. If they do end up surpassing OpenAI then it would seem likely that they aren&#x27;t just relying on copying from o1, or whatever model is the frontier model at that time.</div><br/></div></div></div></div></div></div><div id="42870269" class="c"><input type="checkbox" id="c-42870269" checked=""/><div class="controls bullet"><span class="by">SpaceManNabs</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869941">parent</a><span>|</span><a href="#42871441">prev</a><span>|</span><a href="#42871429">next</a><span>|</span><label class="collapse" for="c-42870269">[-]</label><label class="expand" for="c-42870269">[1 more]</label></div><br/><div class="children"><div class="content">My question is if deepseek r1 is just a distilled o1, i wonder if you can build a fine tuned r1 through distillation without having to fine tune o1.</div><br/></div></div><div id="42871429" class="c"><input type="checkbox" id="c-42871429" checked=""/><div class="controls bullet"><span class="by">zombiwoof</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869941">parent</a><span>|</span><a href="#42870269">prev</a><span>|</span><a href="#42871217">next</a><span>|</span><label class="collapse" for="c-42871429">[-]</label><label class="expand" for="c-42871429">[5 more]</label></div><br/><div class="children"><div class="content">Exactly. They piggybacked of lots of compute and used less. There still is a total sum of a massive amount of compute</div><br/><div id="42872632" class="c"><input type="checkbox" id="c-42872632" checked=""/><div class="controls bullet"><span class="by">cratermoon</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871429">parent</a><span>|</span><a href="#42871502">next</a><span>|</span><label class="collapse" for="c-42872632">[-]</label><label class="expand" for="c-42872632">[3 more]</label></div><br/><div class="children"><div class="content">OpenAI piggybacked on the whole internet and the catalogued and shared human knowledge therein.</div><br/><div id="42876154" class="c"><input type="checkbox" id="c-42876154" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872632">parent</a><span>|</span><a href="#42875510">next</a><span>|</span><label class="collapse" for="c-42876154">[-]</label><label class="expand" for="c-42876154">[1 more]</label></div><br/><div class="children"><div class="content">And lets not forget a gazillion hours of human reinforcement by armies of 3rd world mechanical turks.</div><br/></div></div><div id="42875510" class="c"><input type="checkbox" id="c-42875510" checked=""/><div class="controls bullet"><span class="by">fmbb</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872632">parent</a><span>|</span><a href="#42876154">prev</a><span>|</span><a href="#42871502">next</a><span>|</span><label class="collapse" for="c-42875510">[-]</label><label class="expand" for="c-42875510">[1 more]</label></div><br/><div class="children"><div class="content">That’s a lot of watt hours!</div><br/></div></div></div></div><div id="42871502" class="c"><input type="checkbox" id="c-42871502" checked=""/><div class="controls bullet"><span class="by">da_chicken</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871429">parent</a><span>|</span><a href="#42872632">prev</a><span>|</span><a href="#42871217">next</a><span>|</span><label class="collapse" for="c-42871502">[-]</label><label class="expand" for="c-42871502">[1 more]</label></div><br/><div class="children"><div class="content">I mean, yes that&#x27;s how progress works. Has OpenAI got a patent? If not it&#x27;s fair game.<p>We don&#x27;t make people figure out how to domesticate a cow every time they want a hamburger. Or test hundreds of thousands of filaments before they can have a lightbulb. Inventions, once invented, exist as giants to stand upon. The inventor can either choose to disclose the invention and earn a patent for exclusive rights, or they can try to keep it a secret and hope nobody reverse engineers it.</div><br/></div></div></div></div><div id="42871217" class="c"><input type="checkbox" id="c-42871217" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869941">parent</a><span>|</span><a href="#42871429">prev</a><span>|</span><a href="#42870540">next</a><span>|</span><label class="collapse" for="c-42871217">[-]</label><label class="expand" for="c-42871217">[1 more]</label></div><br/><div class="children"><div class="content">If OpenAi had to account for the cost of producing all the copyrighted material they trained their LLM on, their system would be worth negative trillions of dollars.<p>Let&#x27;s just assume that the cost of training can be externalized to other people for free.</div><br/></div></div><div id="42870540" class="c"><input type="checkbox" id="c-42870540" checked=""/><div class="controls bullet"><span class="by">cherry_tree</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869941">parent</a><span>|</span><a href="#42871217">prev</a><span>|</span><a href="#42876001">next</a><span>|</span><label class="collapse" for="c-42870540">[-]</label><label class="expand" for="c-42870540">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think it would cast doubt on the narrative &quot;you could have trained o1 with much less compute, and r1 is proof of that&quot;<p>Whether or not you could have, you can now.</div><br/></div></div></div></div><div id="42876001" class="c"><input type="checkbox" id="c-42876001" checked=""/><div class="controls bullet"><span class="by">patcon</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42869941">prev</a><span>|</span><a href="#42869559">next</a><span>|</span><label class="collapse" for="c-42876001">[-]</label><label class="expand" for="c-42876001">[1 more]</label></div><br/><div class="children"><div class="content">Are we it rediscovering the evolutionary benefit of progeny (from an information theoretic lens)?<p>And is this related to the lottery ticket hypothesis?<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1803.03635.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1803.03635.pdf</a></div><br/></div></div><div id="42869559" class="c"><input type="checkbox" id="c-42869559" checked=""/><div class="controls bullet"><span class="by">rockemsockem</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42876001">prev</a><span>|</span><a href="#42875278">next</a><span>|</span><label class="collapse" for="c-42869559">[-]</label><label class="expand" for="c-42869559">[16 more]</label></div><br/><div class="children"><div class="content">I think the prevailing narrative ATM is that DeepSeek&#x27;s own innovation was done in isolation and they surpassed OpenAI. Even though in the paper they give a lot of credit to Llama for their techniques. The idea that they used o1&#x27;s outputs for their distillation further shows that models like o1 are necessary.<p>All of this should have been clear anyway from the start, but that&#x27;s the Internet for you.</div><br/><div id="42870136" class="c"><input type="checkbox" id="c-42870136" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869559">parent</a><span>|</span><a href="#42869662">next</a><span>|</span><label class="collapse" for="c-42870136">[-]</label><label class="expand" for="c-42870136">[8 more]</label></div><br/><div class="children"><div class="content"><i>The idea that they used o1&#x27;s outputs for their distillation further shows that models like o1 are necessary.</i><p>Hmm, I think the narrative of the rise of LLMs is that once the output of humans has been distilled by the model, the human isn&#x27;t necessary.<p>As far as I know, DeepSeek adds only a little to the transformers model while o1&#x2F;o3 added a special &quot;reasoning component&quot; - if DeepSeek is as good as o1&#x2F;o3, even taking data from it, then it seems the reasoning component isn&#x27;t needed.</div><br/><div id="42870288" class="c"><input type="checkbox" id="c-42870288" checked=""/><div class="controls bullet"><span class="by">david-gpu</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870136">parent</a><span>|</span><a href="#42870599">next</a><span>|</span><label class="collapse" for="c-42870288">[-]</label><label class="expand" for="c-42870288">[5 more]</label></div><br/><div class="children"><div class="content"><i>&gt; I think the narrative of the rise of LLMs is that once the output of humans has been distilled by the model</i><p>Distillation is a term of art in AI and it is fundamentally incorrect to talk about distilling human-created data. Only an AI model can be distilled.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Knowledge_distillation#Methods" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Knowledge_distillation#Metho...</a></div><br/><div id="42871695" class="c"><input type="checkbox" id="c-42871695" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870288">parent</a><span>|</span><a href="#42870599">next</a><span>|</span><label class="collapse" for="c-42871695">[-]</label><label class="expand" for="c-42871695">[4 more]</label></div><br/><div class="children"><div class="content">Meh,<p>It seems clear that the term can be used informally to denote the boiling down of human knowledge, indeed it was used that way before AI appeared in the popular imagination.</div><br/><div id="42871872" class="c"><input type="checkbox" id="c-42871872" checked=""/><div class="controls bullet"><span class="by">david-gpu</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871695">parent</a><span>|</span><a href="#42870599">next</a><span>|</span><label class="collapse" for="c-42871872">[-]</label><label class="expand" for="c-42871872">[3 more]</label></div><br/><div class="children"><div class="content">In the context in which you said it, it matters a lot.<p><i>&gt;&gt; The idea that they used o1&#x27;s outputs for their distillation further shows that models like o1 are necessary.</i><p><i>&gt; Hmm, I think the narrative of the rise of LLMs is that once the output of humans has been distilled by the model, the human isn&#x27;t necessary.</i><p>If deepseek was produced through the distillation (term of art) of o1, then the cost of producing deepseek is strictly higher than the cost of producing o1, and can&#x27;t be avoided.<p>Continuing this argument, if the premise is true then deepseek can&#x27;t be significantly improved without first producing a very expensive hypothetical o1-next model from which to distill better knowledge.<p>That is the argument that is being made. Please avoid shallow dismissals.<p>Edit: just to be clear, I doubt that deepseek was produced via distillation (term of art) of o1, since that would require access to o1&#x27;s weights. It may have used some of o1&#x27;s outputs to fine tune the model, which still would mean that the cost of training deepseek is strictly higher than training o1.</div><br/><div id="42871986" class="c"><input type="checkbox" id="c-42871986" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871872">parent</a><span>|</span><a href="#42870599">next</a><span>|</span><label class="collapse" for="c-42871986">[-]</label><label class="expand" for="c-42871986">[2 more]</label></div><br/><div class="children"><div class="content"><i>just to be clear, I doubt that deepseek was produced via distillation</i><p>Yeah, your technical point is kind of ridiculous here that in all my uses of  distillation (and in the comment I quoted), distillation is used in informal sense and there&#x27;s no allegation that DeepSeek could have been in possession of OpenAI&#x27;s model weights, which is what&#x27;s needed for your &quot;Distillation (term of Art)&quot;.</div><br/><div id="42875391" class="c"><input type="checkbox" id="c-42875391" checked=""/><div class="controls bullet"><span class="by">ada1981</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871986">parent</a><span>|</span><a href="#42870599">next</a><span>|</span><label class="collapse" for="c-42875391">[-]</label><label class="expand" for="c-42875391">[1 more]</label></div><br/><div class="children"><div class="content">I’m not sure why folks don’t speculate China is able to obtain copies of OpenAI&#x27;s weights.<p>Seems reasonable they would be investing heavily in plaing state assets within OpenAI so they can copy the models.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42870599" class="c"><input type="checkbox" id="c-42870599" checked=""/><div class="controls bullet"><span class="by">PontifexCipher</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870136">parent</a><span>|</span><a href="#42870288">prev</a><span>|</span><a href="#42869662">next</a><span>|</span><label class="collapse" for="c-42870599">[-]</label><label class="expand" for="c-42870599">[2 more]</label></div><br/><div class="children"><div class="content">Some info that may be missing:<p>- v2&#x2F;v3 (not r1) seem to be cloned from o1&#x2F;4o output, and perform worse (this cost the oft-repeated 5ish mm USD)<p>- r1 is specifically a reasoning step (using RL) _on top of_ v2&#x2F;v3 and performs similarly to o1 (the cost of this is _not reported anywhere_)<p>- In the o1 blog post, they specifically say they use RL to add reasoning to LLMs: <a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;learning-to-reason-with-llms&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;learning-to-reason-with-llms&#x2F;</a></div><br/><div id="42870727" class="c"><input type="checkbox" id="c-42870727" checked=""/><div class="controls bullet"><span class="by">sudosysgen</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870599">parent</a><span>|</span><a href="#42869662">next</a><span>|</span><label class="collapse" for="c-42870727">[-]</label><label class="expand" for="c-42870727">[1 more]</label></div><br/><div class="children"><div class="content">The R1-Zero paper shows how many training steps the RL took, and it&#x27;s not many. The cost of the RL is likely a small fraction of the cost of the foundational model.</div><br/></div></div></div></div></div></div><div id="42869662" class="c"><input type="checkbox" id="c-42869662" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869559">parent</a><span>|</span><a href="#42870136">prev</a><span>|</span><a href="#42875278">next</a><span>|</span><label class="collapse" for="c-42869662">[-]</label><label class="expand" for="c-42869662">[7 more]</label></div><br/><div class="children"><div class="content">&gt; the prevailing narrative ATM is that DeepSeek&#x27;s own innovation was done in isolation and they surpassed OpenAI<p>I did not think this, nor did I think this was what others assumed. The narrative, I thought, was that there is little point in paying OpenAI for LLM usage when a much cheaper, similar &#x2F; better version can be made and used for a fraction of the cost (whether it&#x27;s on the back of existing LLM research doesn&#x27;t factor in)</div><br/><div id="42870403" class="c"><input type="checkbox" id="c-42870403" checked=""/><div class="controls bullet"><span class="by">TheGRS</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869662">parent</a><span>|</span><a href="#42870549">next</a><span>|</span><label class="collapse" for="c-42870403">[-]</label><label class="expand" for="c-42870403">[3 more]</label></div><br/><div class="children"><div class="content">Yes, well the narrative that rocked the stock market is different. Its looking at what DeepSeek did and assuming they may have competitive advantage in this space and could outperform OpenAI at their own game.<p>If the narrative is actually that DeepSeek can only reach whatever heights OpenAI has already gotten to with some new tricks, then markets will probably refocus on OpenAI&#x27;s innovations and price things accordingly, even if the initial cost is huge. It also means OpenAI probably needs a better moat to protect its interests.<p>I&#x27;m not sure where the reality is exactly, but market reactions so far have basically followed that initial narrative and now the rebuttal.</div><br/><div id="42873703" class="c"><input type="checkbox" id="c-42873703" checked=""/><div class="controls bullet"><span class="by">addicted</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870403">parent</a><span>|</span><a href="#42875198">next</a><span>|</span><label class="collapse" for="c-42873703">[-]</label><label class="expand" for="c-42873703">[1 more]</label></div><br/><div class="children"><div class="content">The idea that someone can easily replicate an OpenAI model based simply on OpenAI outputs is, I’d argue, immeasurably worse for OpenAI’s valuation than the idea that someone happened to come up with a few innovations that leapfrogged OpenAI.<p>The latter could be a one time thing, and&#x2F;or OpenAi Could still use their financial might to leverage those innovations and get even better with them.<p>However, the former destroys their business model and no amount of intelligence and innovation from OpenAI protects them from being copied at a fraction of the cost.</div><br/></div></div><div id="42875198" class="c"><input type="checkbox" id="c-42875198" checked=""/><div class="controls bullet"><span class="by">aprilthird2021</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870403">parent</a><span>|</span><a href="#42873703">prev</a><span>|</span><a href="#42870549">next</a><span>|</span><label class="collapse" for="c-42875198">[-]</label><label class="expand" for="c-42875198">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Yes, well the narrative that rocked the stock market is different.<p>How do you know this?<p>&gt; If the narrative is actually that DeepSeek can only reach whatever heights OpenAI has already gotten to with some new tricks, then markets will probably refocus on OpenAI&#x27;s innovations and price things accordingly<p>Why? If every innovation OpenAI is trying to keep as secret sauce becomes commoditized quickly and cheaply, then why would markets care about any innovations they have? They will be unable to monetize them.</div><br/></div></div></div></div><div id="42870549" class="c"><input type="checkbox" id="c-42870549" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869662">parent</a><span>|</span><a href="#42870403">prev</a><span>|</span><a href="#42870090">next</a><span>|</span><label class="collapse" for="c-42870549">[-]</label><label class="expand" for="c-42870549">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>I did not think this, nor did I think this was what others assumed.</i><p>That&#x27;s what I thought and assumed. This is the narrative that&#x27;s been running through all the major news outlets.<p>It didn&#x27;t even occur to me that DeepSeek could have been training their models using the output of other models until reading this article.</div><br/><div id="42875801" class="c"><input type="checkbox" id="c-42875801" checked=""/><div class="controls bullet"><span class="by">bigfudge</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870549">parent</a><span>|</span><a href="#42870090">next</a><span>|</span><label class="collapse" for="c-42875801">[-]</label><label class="expand" for="c-42875801">[1 more]</label></div><br/><div class="children"><div class="content">Fwiw  I assumed they were using o1 to train. But it doesn’t matter: the big story here is that massive compute resources are unlikely to be as important in the future as we thought. It cuts the legs off stargate etc just as it’s announced. The CCP must be highly entertained by the timeline.</div><br/></div></div></div></div><div id="42870090" class="c"><input type="checkbox" id="c-42870090" checked=""/><div class="controls bullet"><span class="by">aiono</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869662">parent</a><span>|</span><a href="#42870549">prev</a><span>|</span><a href="#42875278">next</a><span>|</span><label class="collapse" for="c-42870090">[-]</label><label class="expand" for="c-42870090">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s only the case if you don&#x27;t need to use the output of a much more expensive model.</div><br/></div></div></div></div></div></div><div id="42875278" class="c"><input type="checkbox" id="c-42875278" checked=""/><div class="controls bullet"><span class="by">herodoturtle</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42869559">prev</a><span>|</span><a href="#42869782">next</a><span>|</span><label class="collapse" for="c-42875278">[-]</label><label class="expand" for="c-42875278">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the insightful comment.<p>I have a question (disclaimer: reinforcement learning noob here):<p>Is there a risk of broken telephone with this?<p>Kinda like repeatedly compressing an already compressed image eventually leads to a fuzzy blur.<p>If that is the case then I’m curious how this is monitored and &#x2F; or mitigated.</div><br/></div></div><div id="42869782" class="c"><input type="checkbox" id="c-42869782" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42875278">prev</a><span>|</span><a href="#42871869">next</a><span>|</span><label class="collapse" for="c-42869782">[-]</label><label class="expand" for="c-42869782">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI couldn&#x27;t do it, when the high cost of training and access to GPUs is their competitive advance against startups, they can&#x27;t admit that it does not exist.</div><br/></div></div><div id="42871869" class="c"><input type="checkbox" id="c-42871869" checked=""/><div class="controls bullet"><span class="by">ospray</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42869782">prev</a><span>|</span><a href="#42871456">next</a><span>|</span><label class="collapse" for="c-42871869">[-]</label><label class="expand" for="c-42871869">[1 more]</label></div><br/><div class="children"><div class="content">They did do that themselves it&#x27;s called o3.</div><br/></div></div><div id="42871456" class="c"><input type="checkbox" id="c-42871456" checked=""/><div class="controls bullet"><span class="by">dontreact</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42871869">prev</a><span>|</span><a href="#42871202">next</a><span>|</span><label class="collapse" for="c-42871456">[-]</label><label class="expand" for="c-42871456">[1 more]</label></div><br/><div class="children"><div class="content">Is there any evidence R1 is better than O1?<p>It seems like if they in fact distilled then what we have found is that you can create a worse copy of the model for ~5m dollars in compute by training on its outputs.</div><br/></div></div><div id="42871202" class="c"><input type="checkbox" id="c-42871202" checked=""/><div class="controls bullet"><span class="by">Sophira</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42871456">prev</a><span>|</span><a href="#42870508">next</a><span>|</span><label class="collapse" for="c-42871202">[-]</label><label class="expand" for="c-42871202">[3 more]</label></div><br/><div class="children"><div class="content">Honestly, it&#x27;s kind of silly that this technology is in the hands of companies whose only aim is to make money, IMO.</div><br/><div id="42871604" class="c"><input type="checkbox" id="c-42871604" checked=""/><div class="controls bullet"><span class="by">lenerdenator</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871202">parent</a><span>|</span><a href="#42871459">next</a><span>|</span><label class="collapse" for="c-42871604">[-]</label><label class="expand" for="c-42871604">[1 more]</label></div><br/><div class="children"><div class="content">Well, originally, OpenAI wasn&#x27;t supposed to be that kind of organization.<p>But if you leave someone in the tech industry of SV&#x2F;SF long enough, they&#x27;ll start to get high on their own supply and think they&#x27;re entitled to insane amounts of value, so...</div><br/></div></div><div id="42871459" class="c"><input type="checkbox" id="c-42871459" checked=""/><div class="controls bullet"><span class="by">goatlover</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871202">parent</a><span>|</span><a href="#42871604">prev</a><span>|</span><a href="#42870508">next</a><span>|</span><label class="collapse" for="c-42871459">[-]</label><label class="expand" for="c-42871459">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s because they&#x27;re the ones who could raise the money to make those models. Academics don&#x27;t have access to that kind of compute. But the free models exist.</div><br/></div></div></div></div><div id="42870508" class="c"><input type="checkbox" id="c-42870508" checked=""/><div class="controls bullet"><span class="by">iforgot22</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42871202">prev</a><span>|</span><a href="#42872068">next</a><span>|</span><label class="collapse" for="c-42870508">[-]</label><label class="expand" for="c-42870508">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Then use R1 output to build a better X1&quot; is the part I&#x27;m not sure about. Is X1 going to actually be better than R1?</div><br/></div></div><div id="42872068" class="c"><input type="checkbox" id="c-42872068" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42870508">prev</a><span>|</span><a href="#42875292">next</a><span>|</span><label class="collapse" for="c-42872068">[-]</label><label class="expand" for="c-42872068">[1 more]</label></div><br/><div class="children"><div class="content">What does “better” really even mean here?<p>Better benchmark scores can be cooked</div><br/></div></div><div id="42875292" class="c"><input type="checkbox" id="c-42875292" checked=""/><div class="controls bullet"><span class="by">anothernewdude</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42872068">prev</a><span>|</span><a href="#42871247">next</a><span>|</span><label class="collapse" for="c-42875292">[-]</label><label class="expand" for="c-42875292">[1 more]</label></div><br/><div class="children"><div class="content">If they&#x27;re training R1 on o1 output on the benchmarks - then I don&#x27;t trust those benchmarks results for R1. It means the model is liable to be brittle, and they need to prove otherwise.</div><br/></div></div><div id="42871247" class="c"><input type="checkbox" id="c-42871247" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42875292">prev</a><span>|</span><a href="#42869825">next</a><span>|</span><label class="collapse" for="c-42871247">[-]</label><label class="expand" for="c-42871247">[5 more]</label></div><br/><div class="children"><div class="content">They&#x27;re standing on the shoulders of giants, not only in terms of re-using expensive computing power almost for free by using the outputs of expensive models. It&#x27;s a bit of a tradition in that country, also in manufacturing.</div><br/><div id="42872334" class="c"><input type="checkbox" id="c-42872334" checked=""/><div class="controls bullet"><span class="by">unreal37</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871247">parent</a><span>|</span><a href="#42875809">next</a><span>|</span><label class="collapse" for="c-42872334">[-]</label><label class="expand" for="c-42872334">[3 more]</label></div><br/><div class="children"><div class="content">I thought OpenAI GPT took Wikipedia and the content of every book as inputs to train their models?<p>Everyone is standing on the shoulders of giants.</div><br/><div id="42874949" class="c"><input type="checkbox" id="c-42874949" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872334">parent</a><span>|</span><a href="#42875809">next</a><span>|</span><label class="collapse" for="c-42874949">[-]</label><label class="expand" for="c-42874949">[2 more]</label></div><br/><div class="children"><div class="content">What I meant to say was that OpenAI did put a lot of money into extracting value out of the pile of (partially copyrighted) data, and that DeepSeek was freeloading on that investment without disclosing it, making them look more efficient than they truly are.</div><br/></div></div></div></div><div id="42875809" class="c"><input type="checkbox" id="c-42875809" checked=""/><div class="controls bullet"><span class="by">bigfudge</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871247">parent</a><span>|</span><a href="#42872334">prev</a><span>|</span><a href="#42869825">next</a><span>|</span><label class="collapse" for="c-42875809">[-]</label><label class="expand" for="c-42875809">[1 more]</label></div><br/><div class="children"><div class="content">How do you think manufacturing in the US got started? Everyone is on someone’s shoulders.</div><br/></div></div></div></div><div id="42869825" class="c"><input type="checkbox" id="c-42869825" checked=""/><div class="controls bullet"><span class="by">gmd63</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869501">parent</a><span>|</span><a href="#42871247">prev</a><span>|</span><a href="#42871917">next</a><span>|</span><label class="collapse" for="c-42869825">[-]</label><label class="expand" for="c-42869825">[2 more]</label></div><br/><div class="children"><div class="content">Why not just copy and paste the model and change the name? That&#x27;s an even more efficient form of distillation.</div><br/><div id="42870515" class="c"><input type="checkbox" id="c-42870515" checked=""/><div class="controls bullet"><span class="by">wgjordan</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869825">parent</a><span>|</span><a href="#42871917">next</a><span>|</span><label class="collapse" for="c-42870515">[-]</label><label class="expand" for="c-42870515">[1 more]</label></div><br/><div class="children"><div class="content">Even assuming the model was somehow publicly available in a form that could be directly copied, that would be a more blatant form of copyright infringement. Distillation launders copyrighted material in a way that OpenAI specifically has argued falls under fair use.</div><br/></div></div></div></div></div></div><div id="42871917" class="c"><input type="checkbox" id="c-42871917" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42869501">prev</a><span>|</span><a href="#42869668">next</a><span>|</span><label class="collapse" for="c-42871917">[-]</label><label class="expand" for="c-42871917">[40 more]</label></div><br/><div class="children"><div class="content">&gt; This is obviously extremely silly, because that&#x27;s exactly how OpenAI got all of its training data<p>IANAL, but It is worth noting here that DeepSeek <i>has explicitly consented to a license that doesn&#x27;t allow them to do this</i>. That is a condition of using the Chat GPT and the OpenAI API.<p>Even if the courts affirm that there&#x27;s a fair use defence for AI training, DeepSeek may still be in the wrong here, not because of copyright infringement, but because of a breach of contract.<p>I don&#x27;t think OpenAI would have much of a problem if you train your model on data scraped from the internet, some of which incidentally ends up being generated by Chat GPT.<p>Compare this to training AI models on Kindle Books randomly scraped off the internet, versus making a Kindle account, agreeing to the Kindle ToS, buying some books, breaking Amazon&#x27;s DRM and then training your AI on that. What DeepSeek did is more analogous to the latter than the former.</div><br/><div id="42872194" class="c"><input type="checkbox" id="c-42872194" checked=""/><div class="controls bullet"><span class="by">anon373839</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871917">parent</a><span>|</span><a href="#42872014">next</a><span>|</span><label class="collapse" for="c-42872194">[-]</label><label class="expand" for="c-42872194">[1 more]</label></div><br/><div class="children"><div class="content">&gt; DeepSeek has explicitly consented to a license that doesn&#x27;t allow them to do this.<p>You actually don’t know this. Even if it were true that they used OpenAI outputs (and I’m very doubtful) it’s not necessary to sign an agreement with OpenAI to get API outputs. You simply acquire them from an intermediary, so that you have no contractual relationship with OpenAI to begin with.</div><br/></div></div><div id="42872014" class="c"><input type="checkbox" id="c-42872014" checked=""/><div class="controls bullet"><span class="by">krust</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871917">parent</a><span>|</span><a href="#42872194">prev</a><span>|</span><a href="#42872511">next</a><span>|</span><label class="collapse" for="c-42872014">[-]</label><label class="expand" for="c-42872014">[1 more]</label></div><br/><div class="children"><div class="content">&gt;IANAL, but It is worth noting here that DeepSeek has explicitly consented to a license that doesn&#x27;t allow them to do this. That is a condition of using the Chat GPT and the OpenAI API.<p>I have some news for you</div><br/></div></div><div id="42872511" class="c"><input type="checkbox" id="c-42872511" checked=""/><div class="controls bullet"><span class="by">blibble</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871917">parent</a><span>|</span><a href="#42872014">prev</a><span>|</span><a href="#42872053">next</a><span>|</span><label class="collapse" for="c-42872511">[-]</label><label class="expand" for="c-42872511">[8 more]</label></div><br/><div class="children"><div class="content">training is either fair use, or it isn&#x27;t<p>OpenAI can&#x27;t have it both ways</div><br/><div id="42872813" class="c"><input type="checkbox" id="c-42872813" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872511">parent</a><span>|</span><a href="#42874640">next</a><span>|</span><label class="collapse" for="c-42872813">[-]</label><label class="expand" for="c-42872813">[1 more]</label></div><br/><div class="children"><div class="content">Right, but it was never about doing the right thing for humanity, it was about doing the right thing for their profits.<p>Like I’ve said time and time again, nobody in this space gives a fuck about anyone that isn’t directly contributing money to their bottom line at that particular instant. The fundamental idea is selfish, damages the fundamental machinery that makes the internet useful by penalizing people that actually make things, and will never, ever do anything for the greater good if it even stands a chance of reducing their standing in this ridiculously overhyped market. Giving people free access to what is for all intents and purposes a black box is not “open” anything, is no more <i>free</i> (as in speech) than Slack is, and all of this is obviously them selling a product at a huge loss to put competing media out of business and grab market share.</div><br/></div></div><div id="42874640" class="c"><input type="checkbox" id="c-42874640" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872511">parent</a><span>|</span><a href="#42872813">prev</a><span>|</span><a href="#42873911">next</a><span>|</span><label class="collapse" for="c-42874640">[-]</label><label class="expand" for="c-42874640">[4 more]</label></div><br/><div class="children"><div class="content">The issue here is breach of contract, not copyright.</div><br/><div id="42875702" class="c"><input type="checkbox" id="c-42875702" checked=""/><div class="controls bullet"><span class="by">glooglork</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42874640">parent</a><span>|</span><a href="#42875560">next</a><span>|</span><label class="collapse" for="c-42875702">[-]</label><label class="expand" for="c-42875702">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s quite unlikely that OpenAI didn&#x27;t break any TOS with all the data they used for training their models. 
Not just OpenAI but all companies that are developing LLMs.<p>IMO, it would look bad for OpenAI to push strongly with this story, it would look like they&#x27;re losing the technological edge and are now looking for other ways to make sure they remain on top.</div><br/></div></div><div id="42875560" class="c"><input type="checkbox" id="c-42875560" checked=""/><div class="controls bullet"><span class="by">staticman2</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42874640">parent</a><span>|</span><a href="#42875702">prev</a><span>|</span><a href="#42875657">next</a><span>|</span><label class="collapse" for="c-42875560">[-]</label><label class="expand" for="c-42875560">[1 more]</label></div><br/><div class="children"><div class="content">Similar to how a patent contract becomes void when a patent expires regardless of what the terms of the contract says, it&#x27;s not clear to me OpenAI can enforce a contract provision for an API output they own no copyright in.<p>Since they have no intellectual property rights in the output, it&#x27;s not clear to me they have a cause of action to sue over how the output is used.<p>I wonder if any lawyers have written about this topic.</div><br/></div></div><div id="42875657" class="c"><input type="checkbox" id="c-42875657" checked=""/><div class="controls bullet"><span class="by">prmoustache</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42874640">parent</a><span>|</span><a href="#42875560">prev</a><span>|</span><a href="#42873911">next</a><span>|</span><label class="collapse" for="c-42875657">[-]</label><label class="expand" for="c-42875657">[1 more]</label></div><br/><div class="children"><div class="content">What makes you think they had a contract with them in the first place? You can use openAI through intermediaries&#x2F;proxies.</div><br/></div></div></div></div><div id="42873911" class="c"><input type="checkbox" id="c-42873911" checked=""/><div class="controls bullet"><span class="by">avs733</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872511">parent</a><span>|</span><a href="#42874640">prev</a><span>|</span><a href="#42872934">next</a><span>|</span><label class="collapse" for="c-42873911">[-]</label><label class="expand" for="c-42873911">[1 more]</label></div><br/><div class="children"><div class="content">They can sure try though, and I would be damned surprise if this wasn’t related to Sam’s event with trump last week.</div><br/></div></div><div id="42872934" class="c"><input type="checkbox" id="c-42872934" checked=""/><div class="controls bullet"><span class="by">windexh8er</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872511">parent</a><span>|</span><a href="#42873911">prev</a><span>|</span><a href="#42872053">next</a><span>|</span><label class="collapse" for="c-42872934">[-]</label><label class="expand" for="c-42872934">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Free for me, not for thee!&quot; - Sam Altman &#x2F;s<p>But in all reality I&#x27;m happy to see this day. The fact that OpenAI ripped off everyone and everything they could and, to this day pretend like they didn&#x27;t, is fantastic.<p>Sam Altman is a con and it&#x27;s not surprising that given all the positive press DeepSeek got that it was a full court assault on them within 48 hours.</div><br/></div></div></div></div><div id="42872053" class="c"><input type="checkbox" id="c-42872053" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871917">parent</a><span>|</span><a href="#42872511">prev</a><span>|</span><a href="#42872509">next</a><span>|</span><label class="collapse" for="c-42872053">[-]</label><label class="expand" for="c-42872053">[6 more]</label></div><br/><div class="children"><div class="content">TOS are not contracts.</div><br/><div id="42872267" class="c"><input type="checkbox" id="c-42872267" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872053">parent</a><span>|</span><a href="#42874454">next</a><span>|</span><label class="collapse" for="c-42872267">[-]</label><label class="expand" for="c-42872267">[4 more]</label></div><br/><div class="children"><div class="content">Citation? My understanding was that they are provided that someone has to affirmatively accept them in order to use your site. So Terms of Service stuck at the bottom in the footer likely would not count as a contract because there&#x27;s no consent, but Terms of Service included in a check box on a login form likely would count.<p>But IANAL, so if you have a citation that says otherwise I&#x27;d be happy to see it!</div><br/><div id="42873725" class="c"><input type="checkbox" id="c-42873725" checked=""/><div class="controls bullet"><span class="by">addicted</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872267">parent</a><span>|</span><a href="#42873195">next</a><span>|</span><label class="collapse" for="c-42873725">[-]</label><label class="expand" for="c-42873725">[1 more]</label></div><br/><div class="children"><div class="content">You don’t need a citation.<p>You just need to read OpenAI’s arguments about why TOS and copyright laws don’t apply to them when they’re training on other people’s copyrighted and TOS protected data and running roughshod over every legal protection.</div><br/></div></div><div id="42873195" class="c"><input type="checkbox" id="c-42873195" checked=""/><div class="controls bullet"><span class="by">xdennis</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872267">parent</a><span>|</span><a href="#42873725">prev</a><span>|</span><a href="#42874454">next</a><span>|</span><label class="collapse" for="c-42873195">[-]</label><label class="expand" for="c-42873195">[2 more]</label></div><br/><div class="children"><div class="content">IANAGL, but in Germany a ToS is not a contract and can be declared void if it&#x27;s deemed by courts to be unfair.</div><br/><div id="42875867" class="c"><input type="checkbox" id="c-42875867" checked=""/><div class="controls bullet"><span class="by">vanviegen</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42873195">parent</a><span>|</span><a href="#42874454">next</a><span>|</span><label class="collapse" for="c-42875867">[-]</label><label class="expand" for="c-42875867">[1 more]</label></div><br/><div class="children"><div class="content">Yes, though this is especially true when it&#x27;s consumers &#x27;agreeing&#x27; to the TOS. Anything even somewhat surprising within such a TOS is basically thrown out the window in European courtrooms without a second look.<p>For actual, legally binding consent, you&#x27;ll need to make some real effort to make sure the consumer understands what they are agreeing to.</div><br/></div></div></div></div></div></div><div id="42874454" class="c"><input type="checkbox" id="c-42874454" checked=""/><div class="controls bullet"><span class="by">Spooky23</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872053">parent</a><span>|</span><a href="#42872267">prev</a><span>|</span><a href="#42872509">next</a><span>|</span><label class="collapse" for="c-42874454">[-]</label><label class="expand" for="c-42874454">[1 more]</label></div><br/><div class="children"><div class="content">People here will argue that. But the Chinese DNGAF.</div><br/></div></div></div></div><div id="42872509" class="c"><input type="checkbox" id="c-42872509" checked=""/><div class="controls bullet"><span class="by">like_any_other</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871917">parent</a><span>|</span><a href="#42872053">prev</a><span>|</span><a href="#42872245">next</a><span>|</span><label class="collapse" for="c-42872509">[-]</label><label class="expand" for="c-42872509">[1 more]</label></div><br/><div class="children"><div class="content">Legally, I understand your point, but morally, I find it repellent that a breach of contract (especially terms-of-service) could be considered more important than a breach of law. Especially since simply existing in modern society requires us to &quot;agree&quot; to dozens of such &quot;contracts&quot; daily.<p>I hope voters and governments put a long-overdue stop to this cancer of contract-maximalism that has given us such benefits as mandatory arbitration, anti-benchmarking, general circumvention of consumer rights, or, in this case, blatantly anti-competitive terms, by effectively banning reverse-engineering (i.e. examining how something works, i.e. mandating that we live in ignorance).<p>Because if they don&#x27;t, laws will slowly become irrelevant, and our lives governed by one-sided contracts.</div><br/></div></div><div id="42872245" class="c"><input type="checkbox" id="c-42872245" checked=""/><div class="controls bullet"><span class="by">dmitrygr</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871917">parent</a><span>|</span><a href="#42872509">prev</a><span>|</span><a href="#42871944">next</a><span>|</span><label class="collapse" for="c-42872245">[-]</label><label class="expand" for="c-42872245">[2 more]</label></div><br/><div class="children"><div class="content">&gt; DeepSeek has explicitly consented to a license that doesn&#x27;t allow them to do this.<p>By existing in USA, OpenAI consented to comply with copyright law, and how did that go?</div><br/></div></div><div id="42871944" class="c"><input type="checkbox" id="c-42871944" checked=""/><div class="controls bullet"><span class="by">freen</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871917">parent</a><span>|</span><a href="#42872245">prev</a><span>|</span><a href="#42875677">next</a><span>|</span><label class="collapse" for="c-42871944">[-]</label><label class="expand" for="c-42871944">[18 more]</label></div><br/><div class="children"><div class="content">Did OpenAI abide by my service’s terms of service when it ingested my data?</div><br/><div id="42871968" class="c"><input type="checkbox" id="c-42871968" checked=""/><div class="controls bullet"><span class="by">cortesoft</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871944">parent</a><span>|</span><a href="#42875677">next</a><span>|</span><label class="collapse" for="c-42871968">[-]</label><label class="expand" for="c-42871968">[17 more]</label></div><br/><div class="children"><div class="content">Did OpenAI have to sign up for your service to gain access?</div><br/><div id="42872019" class="c"><input type="checkbox" id="c-42872019" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871968">parent</a><span>|</span><a href="#42872355">next</a><span>|</span><label class="collapse" for="c-42872019">[-]</label><label class="expand" for="c-42872019">[5 more]</label></div><br/><div class="children"><div class="content">It probably ignored hundreds of thousands of &quot;by using this site you consent to our Terms and Conditions&quot; notices, many of which probably would be read as prohibiting training. But that&#x27;s also a great example of why these implicit contracts don&#x27;t really work as contracts.</div><br/><div id="42872211" class="c"><input type="checkbox" id="c-42872211" checked=""/><div class="controls bullet"><span class="by">otherme123</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872019">parent</a><span>|</span><a href="#42872186">next</a><span>|</span><label class="collapse" for="c-42872211">[-]</label><label class="expand" for="c-42872211">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI scrapped my blog so aggressively that I had to ban their IPs. They ignored the robots.txt (which is kind of ToS) by 2 orders of magnitude, they ignored the explicit ToS that I copypasted blindly from somewhere but turns out it forbids what they did (something like you can&#x27;t make money with the content). Not that I&#x27;m going to enforce it, but they should at least shut up.</div><br/></div></div><div id="42872186" class="c"><input type="checkbox" id="c-42872186" checked=""/><div class="controls bullet"><span class="by">freen</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872019">parent</a><span>|</span><a href="#42872211">prev</a><span>|</span><a href="#42872355">next</a><span>|</span><label class="collapse" for="c-42872186">[-]</label><label class="expand" for="c-42872186">[3 more]</label></div><br/><div class="children"><div class="content">Civil law is only available to deep pockets.<p>Contracts are enforceable to the degree to which you can pay lawyers to enforce them.<p>I will run out of money trying to enforce my terms of service against openAI, while they have a massive war chest to enforce theirs.<p>Ain’t libertarianism great?</div><br/><div id="42872519" class="c"><input type="checkbox" id="c-42872519" checked=""/><div class="controls bullet"><span class="by">blibble</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872186">parent</a><span>|</span><a href="#42872355">next</a><span>|</span><label class="collapse" for="c-42872519">[-]</label><label class="expand" for="c-42872519">[2 more]</label></div><br/><div class="children"><div class="content">solution: live in a country OpenAI can&#x27;t get to you<p>e.g China</div><br/><div id="42875737" class="c"><input type="checkbox" id="c-42875737" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872519">parent</a><span>|</span><a href="#42872355">next</a><span>|</span><label class="collapse" for="c-42875737">[-]</label><label class="expand" for="c-42875737">[1 more]</label></div><br/><div class="children"><div class="content">Are you suggesting it&#x27;s easier to successfully sue OpenAI for copyright infringement if you live in China?</div><br/></div></div></div></div></div></div></div></div><div id="42872355" class="c"><input type="checkbox" id="c-42872355" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871968">parent</a><span>|</span><a href="#42872019">prev</a><span>|</span><a href="#42873730">next</a><span>|</span><label class="collapse" for="c-42872355">[-]</label><label class="expand" for="c-42872355">[1 more]</label></div><br/><div class="children"><div class="content">No, but some of the data is licensed.<p>For example, my digital garden is under GFDL, and my blog is CC BY-NC-SA. IOW, They can&#x27;t remix my digital garden with any other license than GFDL, and they have to credit me if they remix my blog, and can&#x27;t use it for any commercial endeavor, which OpenAI certainly does now.<p>So, by scraping my webpages, they agree to my licensing of my data. So they&#x27;re de-facto breaching my licenses, but they cry &quot;fair-use&quot;.<p>If I tell that they&#x27;re breaching the license terms, they&#x27;d laugh at me, and maybe give me 2 cents of API access to mock me further. When somebody <i>allegedly</i> uses their API with their unenforcable ToS, they scream like an agitated cuckatoo (which is an insult to the cuckatoo, BTW. They&#x27;re devilishly intelligent birds).<p>Drinking their own poison was mildly painful, I guess...<p>BTW, I don&#x27;t believe that Deepseek has copied&#x2F;used OpenAI models&#x27; outputs or training data to train theirs, even if they did, &quot;the cat is out of the bag&quot;, &quot;they did something amazing so they needed no permissions&quot;, &quot;they moved fast and broke things&quot;, and &quot;all is fair-use because it&#x27;s just research&quot; regardless of how they did it.<p><i>Heh.</i></div><br/></div></div><div id="42873730" class="c"><input type="checkbox" id="c-42873730" checked=""/><div class="controls bullet"><span class="by">addicted</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871968">parent</a><span>|</span><a href="#42872355">prev</a><span>|</span><a href="#42875486">next</a><span>|</span><label class="collapse" for="c-42873730">[-]</label><label class="expand" for="c-42873730">[1 more]</label></div><br/><div class="children"><div class="content">They probably did to access the NYTimes articles.</div><br/></div></div><div id="42875486" class="c"><input type="checkbox" id="c-42875486" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871968">parent</a><span>|</span><a href="#42873730">prev</a><span>|</span><a href="#42872132">next</a><span>|</span><label class="collapse" for="c-42875486">[-]</label><label class="expand" for="c-42875486">[1 more]</label></div><br/><div class="children"><div class="content">Have their scraping bots consented to cookies?</div><br/></div></div><div id="42872132" class="c"><input type="checkbox" id="c-42872132" checked=""/><div class="controls bullet"><span class="by">freen</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871968">parent</a><span>|</span><a href="#42875486">prev</a><span>|</span><a href="#42872069">next</a><span>|</span><label class="collapse" for="c-42872132">[-]</label><label class="expand" for="c-42872132">[1 more]</label></div><br/><div class="children"><div class="content">Actually, yes, they actively agreed to them. Clicked the button and everything.</div><br/></div></div><div id="42872069" class="c"><input type="checkbox" id="c-42872069" checked=""/><div class="controls bullet"><span class="by">outside1234</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871968">parent</a><span>|</span><a href="#42872132">prev</a><span>|</span><a href="#42872013">next</a><span>|</span><label class="collapse" for="c-42872069">[-]</label><label class="expand" for="c-42872069">[1 more]</label></div><br/><div class="children"><div class="content">That isn&#x27;t required to be in violation of copyright</div><br/></div></div><div id="42872013" class="c"><input type="checkbox" id="c-42872013" checked=""/><div class="controls bullet"><span class="by">thorncorona</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871968">parent</a><span>|</span><a href="#42872069">prev</a><span>|</span><a href="#42875677">next</a><span>|</span><label class="collapse" for="c-42872013">[-]</label><label class="expand" for="c-42872013">[6 more]</label></div><br/><div class="children"><div class="content">Can you steal someone else’s laptop if they stood up to get a drink?</div><br/><div id="42873743" class="c"><input type="checkbox" id="c-42873743" checked=""/><div class="controls bullet"><span class="by">addicted</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872013">parent</a><span>|</span><a href="#42873816">next</a><span>|</span><label class="collapse" for="c-42873743">[-]</label><label class="expand" for="c-42873743">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI itself has argued, to the degree that your analogy applies, that if the goal of stealing the laptop is to train AI then the answer is Yes.</div><br/></div></div><div id="42873816" class="c"><input type="checkbox" id="c-42873816" checked=""/><div class="controls bullet"><span class="by">cortesoft</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872013">parent</a><span>|</span><a href="#42873743">prev</a><span>|</span><a href="#42872372">next</a><span>|</span><label class="collapse" for="c-42873816">[-]</label><label class="expand" for="c-42873816">[1 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t this analogy be more like, &quot;can you read my laptop screen if I stood up to get a drink?&quot;</div><br/></div></div><div id="42872372" class="c"><input type="checkbox" id="c-42872372" checked=""/><div class="controls bullet"><span class="by">gizajob</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872013">parent</a><span>|</span><a href="#42873816">prev</a><span>|</span><a href="#42872452">next</a><span>|</span><label class="collapse" for="c-42872372">[-]</label><label class="expand" for="c-42872372">[1 more]</label></div><br/><div class="children"><div class="content">If their OS is open to the internet and you can scrape it and copy it off while they’re gone, then that would be about the right analogy. And OpenAi and DeepSeek have done the same thing in that case.</div><br/></div></div><div id="42872452" class="c"><input type="checkbox" id="c-42872452" checked=""/><div class="controls bullet"><span class="by">secstate</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872013">parent</a><span>|</span><a href="#42872372">prev</a><span>|</span><a href="#42872392">next</a><span>|</span><label class="collapse" for="c-42872452">[-]</label><label class="expand" for="c-42872452">[1 more]</label></div><br/><div class="children"><div class="content">Yes, if you can pay off any witnesses.</div><br/></div></div><div id="42872392" class="c"><input type="checkbox" id="c-42872392" checked=""/><div class="controls bullet"><span class="by">rpastuszak</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872013">parent</a><span>|</span><a href="#42872452">prev</a><span>|</span><a href="#42875677">next</a><span>|</span><label class="collapse" for="c-42872392">[-]</label><label class="expand" for="c-42872392">[1 more]</label></div><br/><div class="children"><div class="content">What?</div><br/></div></div></div></div></div></div></div></div><div id="42875677" class="c"><input type="checkbox" id="c-42875677" checked=""/><div class="controls bullet"><span class="by">anothernewdude</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871917">parent</a><span>|</span><a href="#42871944">prev</a><span>|</span><a href="#42872506">next</a><span>|</span><label class="collapse" for="c-42875677">[-]</label><label class="expand" for="c-42875677">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not hard to get someone else to submit queries and post the results, without agreeing to the license.</div><br/></div></div></div></div><div id="42869668" class="c"><input type="checkbox" id="c-42869668" checked=""/><div class="controls bullet"><span class="by">tempeler</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42871917">prev</a><span>|</span><a href="#42875006">next</a><span>|</span><label class="collapse" for="c-42869668">[-]</label><label class="expand" for="c-42869668">[11 more]</label></div><br/><div class="children"><div class="content">On another subject, if it belongs to OpenAI because it uses OpenAI, then doesn&#x27;t that mean that everything produced using OpenAI belongs to OpenAI? Isn&#x27;t that a reason not to use OpenAI? It&#x27;s very similar to saying that you used Google and searched; now this product belongs to Google. They couldn&#x27;t figure out how to respond; they went crazy.</div><br/><div id="42870514" class="c"><input type="checkbox" id="c-42870514" checked=""/><div class="controls bullet"><span class="by">dathinab</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869668">parent</a><span>|</span><a href="#42871540">next</a><span>|</span><label class="collapse" for="c-42870514">[-]</label><label class="expand" for="c-42870514">[7 more]</label></div><br/><div class="children"><div class="content">The US ruled that AI produced things are by themself not copyrightable.<p>So no, it doesn&#x27;t belong to OpenAI.<p>You might be able to sue for penalties for breach of contract of the TOS, but that doesn&#x27;t give them the right to the model. And even if it doesn&#x27;t give them any right to invalidate unbound copyright grants they have given to 3rd parties (here literally everyone).  Nor does it prevent anyone from training their own new models based on it or prevent anyone from using it. Oh, and the one breaching the TOS might not even have been the company behind DeepSeek but some in-between 3rd party.<p>Naturally this is under a few assumptions:<p>- the US consistently applies it&#x27;s own law, but they have a long history of not doing so<p>- the US doesn&#x27;t abuse their power to force their economical opinions (ban DeepSeek) on other countries<p>- it actually was trained on OpenAI, but uh, OpenAI has IMHO shown over the years very clearly that they can&#x27;t be trusted and they are fully in-transparent. How do we trust their claim? How do we trust them to not retrospectively have tweaked their model to make it look as if DeepSeek copied it?</div><br/><div id="42872557" class="c"><input type="checkbox" id="c-42872557" checked=""/><div class="controls bullet"><span class="by">protocolture</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870514">parent</a><span>|</span><a href="#42871540">next</a><span>|</span><label class="collapse" for="c-42872557">[-]</label><label class="expand" for="c-42872557">[6 more]</label></div><br/><div class="children"><div class="content">&gt;The US ruled that AI produced things are by themself not copyrightable.<p>The US ruled that the AI cannot be the author, that doesn&#x27;t lead like so many clickbait articles suggest, that no AI products can be copyrighted.<p>1 Activist tried to get the US copyright office to acknowledge his LLM as the author, who would then provide him a license to the work.<p>There was no issue with himself being the original author and copyright holder of the AI works. But thats not what was being challenged.</div><br/><div id="42873236" class="c"><input type="checkbox" id="c-42873236" checked=""/><div class="controls bullet"><span class="by">Aloisius</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872557">parent</a><span>|</span><a href="#42872707">next</a><span>|</span><label class="collapse" for="c-42873236">[-]</label><label class="expand" for="c-42873236">[2 more]</label></div><br/><div class="children"><div class="content">The copyright office ruled AI output is uncopyrightable without sufficient human contribution to expression.<p>Prompts, they said, were unlikely enough to satisfy the requirement of a human controlling the expressive elements thus most AI output today is probably not copyrightable.<p><a href="https:&#x2F;&#x2F;www.copyright.gov&#x2F;ai&#x2F;Copyright-and-Artificial-Intelligence-Part-2-Copyrightability-Report.pdf" rel="nofollow">https:&#x2F;&#x2F;www.copyright.gov&#x2F;ai&#x2F;Copyright-and-Artificial-Intell...</a></div><br/><div id="42874266" class="c"><input type="checkbox" id="c-42874266" checked=""/><div class="controls bullet"><span class="by">protocolture</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42873236">parent</a><span>|</span><a href="#42872707">next</a><span>|</span><label class="collapse" for="c-42874266">[-]</label><label class="expand" for="c-42874266">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The Office concludes that, given current generally available technology, prompts alone
do not provide sufficient human control to make users of an AI system the authors of the
output.<p>Prompts alone.<p>But there are almost no cases of &quot;Prompts Alone&quot; products seeking copyright.<p>Even what 3-4 years ago?, AI tools moved into a collaborative footing. Novel AI forces a collaborative process (and gives you output that can demonstrate your input which is nice). ChatGPT effectively forces it due to limited memory.<p>There was a case, posted here to ycombinator, where a chinese judge upheld &quot;significant&quot; human interaction was involved when a user made 20-odd adjustments to their prompt iterating over produced images and then added a watermark to the result. I would be very surprised if most sensible jurisdictions didn&#x27;t follow suit.<p>Midjourney and ChatGPT already include tools to mask and identify parts of the image to be regenerated. And multiple image generators allow dumb stuff like stick figures and so forth to stand in as part of an uploaded image prompt.<p>And then theres AI voice which is another whole bag of tricks.<p>&gt;thus most AI output today is probably not copyrightable.<p>Unless it was worked on even slightly as above. In fact it would be hard to imagine much AI work that isn&#x27;t copyrightable. Maybe those facebook pages that just prompt &quot;Cyberpunk Girl&quot; and spit out endless variations. But I doubt copyright is at the forefront of their mind.</div><br/></div></div></div></div><div id="42872707" class="c"><input type="checkbox" id="c-42872707" checked=""/><div class="controls bullet"><span class="by">dathinab</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872557">parent</a><span>|</span><a href="#42873236">prev</a><span>|</span><a href="#42871540">next</a><span>|</span><label class="collapse" for="c-42872707">[-]</label><label class="expand" for="c-42872707">[3 more]</label></div><br/><div class="children"><div class="content">but even then wouldn&#x27;t the people using OpenAI still be the author&#x2F;copyright holder and never OpenAI? (as no human on OpenAIs side is involved in the process of creating the works)</div><br/><div id="42872914" class="c"><input type="checkbox" id="c-42872914" checked=""/><div class="controls bullet"><span class="by">protocolture</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872707">parent</a><span>|</span><a href="#42871540">next</a><span>|</span><label class="collapse" for="c-42872914">[-]</label><label class="expand" for="c-42872914">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI is a company of humans, the product is ChatGPT. Theres a grey area regarding who owns the content, so OpenAI&#x27;s terms and conditions state that all ownership of the resulting content belongs to the user. This is actually advantageous because it means that they dont hold ownership on bad things created by their tool.</div><br/><div id="42872968" class="c"><input type="checkbox" id="c-42872968" checked=""/><div class="controls bullet"><span class="by">protocolture</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872914">parent</a><span>|</span><a href="#42871540">next</a><span>|</span><label class="collapse" for="c-42872968">[-]</label><label class="expand" for="c-42872968">[1 more]</label></div><br/><div class="children"><div class="content">That said you can still provide terms to access the tool, IIRC midjourney allows creators to own their content but also forces them to license it back to midjourney for advertising. Prompts too from memory.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42871540" class="c"><input type="checkbox" id="c-42871540" checked=""/><div class="controls bullet"><span class="by">johndhi</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42869668">parent</a><span>|</span><a href="#42870514">prev</a><span>|</span><a href="#42875006">next</a><span>|</span><label class="collapse" for="c-42871540">[-]</label><label class="expand" for="c-42871540">[3 more]</label></div><br/><div class="children"><div class="content">to be clear, their terms of service are pretty clear that the USER owns the outputs.</div><br/><div id="42872377" class="c"><input type="checkbox" id="c-42872377" checked=""/><div class="controls bullet"><span class="by">jonathanstrange</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871540">parent</a><span>|</span><a href="#42875006">next</a><span>|</span><label class="collapse" for="c-42872377">[-]</label><label class="expand" for="c-42872377">[2 more]</label></div><br/><div class="children"><div class="content">The official stance in the US is currently that there is no copyright on AI output.</div><br/><div id="42872564" class="c"><input type="checkbox" id="c-42872564" checked=""/><div class="controls bullet"><span class="by">protocolture</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872377">parent</a><span>|</span><a href="#42875006">next</a><span>|</span><label class="collapse" for="c-42872564">[-]</label><label class="expand" for="c-42872564">[1 more]</label></div><br/><div class="children"><div class="content">The US ruled that the AI cannot be the author, that doesn&#x27;t lead like so many clickbait articles suggest, that no AI products can be copyrighted.<p>1 Activist tried to get the US copyright office to acknowledge his LLM as the author, who would then provide him a license to the work.<p>There was no issue with himself being the original author and copyright holder of the AI works. But that&#x27;s not what was being challenged.</div><br/></div></div></div></div></div></div></div></div><div id="42875006" class="c"><input type="checkbox" id="c-42875006" checked=""/><div class="controls bullet"><span class="by">m348e912</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42869668">prev</a><span>|</span><a href="#42869939">next</a><span>|</span><label class="collapse" for="c-42875006">[-]</label><label class="expand" for="c-42875006">[2 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;DeepSeek trained on our outputs&quot;<p>I&#x27;m wondering how Deepseek could have made 100s of millions of training queries to OpenAI and not one person at OpenAI caught on.</div><br/><div id="42875760" class="c"><input type="checkbox" id="c-42875760" checked=""/><div class="controls bullet"><span class="by">tisc</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42875006">parent</a><span>|</span><a href="#42869939">next</a><span>|</span><label class="collapse" for="c-42875760">[-]</label><label class="expand" for="c-42875760">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they use AI to monitor traffic, but it is still learning :)</div><br/></div></div></div></div><div id="42869939" class="c"><input type="checkbox" id="c-42869939" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42875006">prev</a><span>|</span><a href="#42875949">next</a><span>|</span><label class="collapse" for="c-42869939">[-]</label><label class="expand" for="c-42869939">[1 more]</label></div><br/><div class="children"><div class="content">The existence of R1-zero is evidence against any sort of theft of OpenAI&#x27;s internal COT data. The model sometimes outputs illegible text that&#x27;s useful only to R1. You can&#x27;t do distillation without a shared vocabulary. The only way R1 could exist is if they trained it with RL.</div><br/></div></div><div id="42875949" class="c"><input type="checkbox" id="c-42875949" checked=""/><div class="controls bullet"><span class="by">fanfanfly</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42869939">prev</a><span>|</span><a href="#42871333">next</a><span>|</span><label class="collapse" for="c-42875949">[-]</label><label class="expand" for="c-42875949">[1 more]</label></div><br/><div class="children"><div class="content">The data that OpenAI has certainly is better than what Deepseek has in your second argument. And OpenAI always has access to this kind of data, right?</div><br/></div></div><div id="42871333" class="c"><input type="checkbox" id="c-42871333" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42875949">prev</a><span>|</span><a href="#42871016">next</a><span>|</span><label class="collapse" for="c-42871333">[-]</label><label class="expand" for="c-42871333">[1 more]</label></div><br/><div class="children"><div class="content">DeepSeek-R0 (based on DeepSeek-V3 base model) was <i>only</i> trained with RL, no SFT, so this isn&#x27;t at all like the &quot;distillation&quot; (i.e SFT on synthetic data generated by R1) that they also demonstrated by fine tuning Qwen and LLaMa.<p>Now, DeepSeek may (or may not) have used some O1 generated data for the R0 RL training, but if so that&#x27;s just a cost saving vs having to source some reasoning data some other way, and in no way reduces the legitimacy of what they accomplished (which is not something any of the AI CEOs are saying).</div><br/></div></div><div id="42871016" class="c"><input type="checkbox" id="c-42871016" checked=""/><div class="controls bullet"><span class="by">s17n</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42871333">prev</a><span>|</span><a href="#42872527">next</a><span>|</span><label class="collapse" for="c-42871016">[-]</label><label class="expand" for="c-42871016">[4 more]</label></div><br/><div class="children"><div class="content">&gt; This is obviously extremely silly, because that&#x27;s exactly how OpenAI got all of its training data in the first place - by scraping other peoples&#x27; data off the internet.<p>OpenAI has also invested heavily in human annotation and RLHF.  If all DeepSeek wanted was a proxy for scraped training data, they&#x27;d probably just scrape it themselves.  Using existing RLHF&#x27;d models as replacement for expensive humans in the training loop is the real game changer for anyone trying to replicate these results.</div><br/><div id="42871070" class="c"><input type="checkbox" id="c-42871070" checked=""/><div class="controls bullet"><span class="by">KennyBlanken</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871016">parent</a><span>|</span><a href="#42872527">next</a><span>|</span><label class="collapse" for="c-42871070">[-]</label><label class="expand" for="c-42871070">[3 more]</label></div><br/><div class="children"><div class="content">&quot;We spent a lot of labor processing everything we stole&quot; is...not how that works.<p>That&#x27;s like the mafia complaining that they worked so hard to steal those barrels of beer that someone made off with in the middle of the night and really that&#x27;s not fair and won&#x27;t someone do something about it?</div><br/><div id="42872197" class="c"><input type="checkbox" id="c-42872197" checked=""/><div class="controls bullet"><span class="by">s17n</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42871070">parent</a><span>|</span><a href="#42872527">next</a><span>|</span><label class="collapse" for="c-42872197">[-]</label><label class="expand" for="c-42872197">[2 more]</label></div><br/><div class="children"><div class="content">Oh, I don&#x27;t really care about IP theft and agree that it&#x27;s funny that openai is complaining.  But I don&#x27;t think its true that deepseek is just doing this because they are too lazy to scrape the internet themselves - its all about the human labor that they would otherwise have to pay for.</div><br/><div id="42874500" class="c"><input type="checkbox" id="c-42874500" checked=""/><div class="controls bullet"><span class="by">KennyBlanken</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872197">parent</a><span>|</span><a href="#42872527">next</a><span>|</span><label class="collapse" for="c-42874500">[-]</label><label class="expand" for="c-42874500">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s assuming what a known prolific liar has said is true...<p>The most famous example would be him contacting ScarJo&#x27;s agent to hire her to provide her voice for their text-to-speech bot, them being told to go pound sand, and doing it anyway, and then lying about (which they got away with until her agent released a statement saying they&#x27;d approached her and she told them to fuck off.)</div><br/></div></div></div></div></div></div></div></div><div id="42872527" class="c"><input type="checkbox" id="c-42872527" checked=""/><div class="controls bullet"><span class="by">pizzathyme</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42871016">prev</a><span>|</span><a href="#42871037">next</a><span>|</span><label class="collapse" for="c-42872527">[-]</label><label class="expand" for="c-42872527">[2 more]</label></div><br/><div class="children"><div class="content">This is a fascinating development because AI models may turn out to be like pharmaceuticals. The first pill costs $500 million to make, the second one costs pennies.</div><br/><div id="42875877" class="c"><input type="checkbox" id="c-42875877" checked=""/><div class="controls bullet"><span class="by">chupy</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42872527">parent</a><span>|</span><a href="#42871037">next</a><span>|</span><label class="collapse" for="c-42875877">[-]</label><label class="expand" for="c-42875877">[1 more]</label></div><br/><div class="children"><div class="content">Companies are still charging 100x for the pills that cost pennies to produce.<p>Besides deals with insurance companies and governments, one of the ways that they are still able to pull this is convincing everyone that it&#x27;s too dangerous to play with this at home or buying it from an Asian supplier.<p>At least with software we had until now a way to build and run most things without requiring dedicated super expensive equipment. OpenAI pulled a big Pharma move but hopefully there will be enough disruptors to not let them continue it.</div><br/></div></div></div></div><div id="42871037" class="c"><input type="checkbox" id="c-42871037" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42872527">prev</a><span>|</span><a href="#42873541">next</a><span>|</span><label class="collapse" for="c-42871037">[-]</label><label class="expand" for="c-42871037">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right that the first claim is silly, but the second claim is pretty silly too — they&#x27;re not claiming industrial espionage, they&#x27;re claiming a breach in ToS. The outputs of the o1 thinking process aren&#x27;t user-visible, and never leave OpenAI&#x27;s datacenters. Unless DeepSeek actually had a mole that stole their o1 outputs, there&#x27;s nothing useful DeepSeek could&#x27;ve distilled to get to R1&#x27;s thought processes.<p>And if DeepSeek had a mole, <i>why would they bother running a massive job internally to steal the data generated</i>? It would be way easier for the mole to just leak the RL training process, and DeepSeek could quietly copy it rather than bothering with exfiltrating massive datasets to distill. The training process is most likely like, on the order of a hundred lines of Python or so, and you don&#x27;t even need the file: you just need someone to describe it to you. Much simpler than snatching hundreds of gigabytes of training data off of internal servers...<p>Plus, the RL process described in DeepSeek&#x27;s paper has already been replicated by a PhD student at Berkeley: <a href="https:&#x2F;&#x2F;x.com&#x2F;karpathy&#x2F;status&#x2F;1884678601704169965" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;karpathy&#x2F;status&#x2F;1884678601704169965</a> So, it seems pretty unlikely they simply distilled R1 and lied about it, or else how does their RL training algo actually... work?<p>This is mainly cope from OpenAI that their supposedly super duper advanced models got caught by China within a few months of release, for way cheaper than it cost OpenAI to train.</div><br/></div></div><div id="42873541" class="c"><input type="checkbox" id="c-42873541" checked=""/><div class="controls bullet"><span class="by">therealpygon</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42871037">prev</a><span>|</span><a href="#42872021">next</a><span>|</span><label class="collapse" for="c-42873541">[-]</label><label class="expand" for="c-42873541">[1 more]</label></div><br/><div class="children"><div class="content">Guess it is a good thing the AI output can’t be copyrighted, so at most they violated a policy.</div><br/></div></div><div id="42872021" class="c"><input type="checkbox" id="c-42872021" checked=""/><div class="controls bullet"><span class="by">alach11</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42873541">prev</a><span>|</span><a href="#42873114">next</a><span>|</span><label class="collapse" for="c-42872021">[-]</label><label class="expand" for="c-42872021">[1 more]</label></div><br/><div class="children"><div class="content">If we assume distillation remains viable, the game theory implications are huge.<p>It’s going to shift the market of how foundation models are used. Companies creating models will be incentivized to vertically integrate, owning the full stack of model usage. Exposing powerful models via APIs just lets a competitor clone your work. In a way OpenAI’s Operator is a hint of what’s to come</div><br/></div></div><div id="42873114" class="c"><input type="checkbox" id="c-42873114" checked=""/><div class="controls bullet"><span class="by">blantonl</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42872021">prev</a><span>|</span><a href="#42873441">next</a><span>|</span><label class="collapse" for="c-42873114">[-]</label><label class="expand" for="c-42873114">[1 more]</label></div><br/><div class="children"><div class="content">It’s literally a race to the bottom by “theft of data”<p>Whatever that means. The legal system right now in shambles and flat footed.<p>Knowing our current government leadership, I think we’re going to see some brute force action backed up by the United States military.</div><br/></div></div><div id="42873441" class="c"><input type="checkbox" id="c-42873441" checked=""/><div class="controls bullet"><span class="by">naet</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42873114">prev</a><span>|</span><a href="#42870569">next</a><span>|</span><label class="collapse" for="c-42873441">[-]</label><label class="expand" for="c-42873441">[2 more]</label></div><br/><div class="children"><div class="content">“We engage in countermeasures to protect our IP, including a careful process for which frontier capabilities to include in released models, and believe . . . it is critically important that we are working closely with the US government to best protect the most capable models from efforts by adversaries and competitors to take US technology.”<p>The above OpenAI quote from the article leans heavily towards #1 and IMO not at all towards #2.  The later would be an extremely charitable reading of their statement.</div><br/><div id="42873477" class="c"><input type="checkbox" id="c-42873477" checked=""/><div class="controls bullet"><span class="by">ripped_britches</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42873441">parent</a><span>|</span><a href="#42870569">next</a><span>|</span><label class="collapse" for="c-42873477">[-]</label><label class="expand" for="c-42873477">[1 more]</label></div><br/><div class="children"><div class="content">What they say explicitly is not what they say implicitly. PR is an art.</div><br/></div></div></div></div><div id="42870569" class="c"><input type="checkbox" id="c-42870569" checked=""/><div class="controls bullet"><span class="by">me551ah</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42873441">prev</a><span>|</span><a href="#42872399">next</a><span>|</span><label class="collapse" for="c-42870569">[-]</label><label class="expand" for="c-42870569">[4 more]</label></div><br/><div class="children"><div class="content">This is going to have a catastrophic effect on closed source AI startup valuations. Because this means that anyone can copy any LLM. The person who trains the model, spends the most amount of money. Everyone else can create a replica at lower cost</div><br/><div id="42872369" class="c"><input type="checkbox" id="c-42872369" checked=""/><div class="controls bullet"><span class="by">amlib</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870569">parent</a><span>|</span><a href="#42873010">next</a><span>|</span><label class="collapse" for="c-42872369">[-]</label><label class="expand" for="c-42872369">[1 more]</label></div><br/><div class="children"><div class="content">Why is that bad? If a powerful entity can scrape every piece of media humanity has to offer and ignore copyright then why should society let then profit unrestricted from it? It&#x27;s only fair that such models have no legal protection around their usage and can be used and analyzed by anyone as they see fit. The only reason this hasn&#x27;t been codified into laws is because those same powerful entities have been busy trying to do regulatory capture.</div><br/></div></div><div id="42873010" class="c"><input type="checkbox" id="c-42873010" checked=""/><div class="controls bullet"><span class="by">matt-p</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870569">parent</a><span>|</span><a href="#42872369">prev</a><span>|</span><a href="#42871833">next</a><span>|</span><label class="collapse" for="c-42873010">[-]</label><label class="expand" for="c-42873010">[1 more]</label></div><br/><div class="children"><div class="content">Good.</div><br/></div></div><div id="42871833" class="c"><input type="checkbox" id="c-42871833" checked=""/><div class="controls bullet"><span class="by">iforgot22</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870569">parent</a><span>|</span><a href="#42873010">prev</a><span>|</span><a href="#42872399">next</a><span>|</span><label class="collapse" for="c-42871833">[-]</label><label class="expand" for="c-42871833">[1 more]</label></div><br/><div class="children"><div class="content">Maybe anyone can copy any LLM with sufficient querying. There are still ways to guard one.</div><br/></div></div></div></div><div id="42872399" class="c"><input type="checkbox" id="c-42872399" checked=""/><div class="controls bullet"><span class="by">bjourne</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42870569">prev</a><span>|</span><a href="#42872694">next</a><span>|</span><label class="collapse" for="c-42872399">[-]</label><label class="expand" for="c-42872399">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;DeepSeek trained on our outputs, and so their claims of replicating o1-level performance from scratch are not really true&quot;<p>Someone has to correct me if I&#x27;m wrong, but I believe in ML research you always have a dataset and a model. They are distinct entities. It is plausible that output from OpenAI&#x27;s model improved the quality of DeepSeek&#x27;s dataset. Just like everyone publishing their code on GitHub improved the quality of OpenAI&#x27;s dataset. What has been the thinking so far is that the dataset is not &quot;part of&quot; or &quot;in&quot; the model any more than the GPUs used to train the model are. It seems strange that that thinking should now change just because Chinese researchers did it better.</div><br/></div></div><div id="42872694" class="c"><input type="checkbox" id="c-42872694" checked=""/><div class="controls bullet"><span class="by">hintymad</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42872399">prev</a><span>|</span><a href="#42874971">next</a><span>|</span><label class="collapse" for="c-42872694">[-]</label><label class="expand" for="c-42872694">[1 more]</label></div><br/><div class="children"><div class="content">&gt; DeepSeek trained on our outputs, and so their claims of replicating o1-level performance from scratch are not really true&quot; This is at least plausibly a valid claim.<p>Some may view this as partially true, given that o-1 does not output its CoT process.</div><br/></div></div><div id="42874971" class="c"><input type="checkbox" id="c-42874971" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42872694">prev</a><span>|</span><a href="#42873387">next</a><span>|</span><label class="collapse" for="c-42874971">[-]</label><label class="expand" for="c-42874971">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s still problematic because any model that OpenAI trains can now be &quot;stolen&quot; and essentially rendered &quot;open&quot;.</div><br/></div></div><div id="42873387" class="c"><input type="checkbox" id="c-42873387" checked=""/><div class="controls bullet"><span class="by">javier2</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42874971">prev</a><span>|</span><a href="#42870739">next</a><span>|</span><label class="collapse" for="c-42873387">[-]</label><label class="expand" for="c-42873387">[1 more]</label></div><br/><div class="children"><div class="content">Its a decent point if their models were not trained in isolation, but used o1 to improve it. But its rich from OpenAI to come complain DeepSeek or anyone else used their data for training. Get out fellow theives.</div><br/></div></div><div id="42870739" class="c"><input type="checkbox" id="c-42870739" checked=""/><div class="controls bullet"><span class="by">ComputerGuru</span><span>|</span><a href="#42867899">parent</a><span>|</span><a href="#42873387">prev</a><span>|</span><a href="#42866072">next</a><span>|</span><label class="collapse" for="c-42870739">[-]</label><label class="expand" for="c-42870739">[2 more]</label></div><br/><div class="children"><div class="content">The suggestion that <i>any</i> large-scale AI model research today isn’t ingesting output of its predecessors is laughable.<p><i>Even if</i> they didn’t directly, intentionally use o1 output (and they didn’t claim they didn’t, so far as I know), AI slop is everywhere. We passed peak original content years ago. Everything is tainted and everything should be understand in that context.</div><br/><div id="42871711" class="c"><input type="checkbox" id="c-42871711" checked=""/><div class="controls bullet"><span class="by">brianstrimp</span><span>|</span><a href="#42867899">root</a><span>|</span><a href="#42870739">parent</a><span>|</span><a href="#42866072">next</a><span>|</span><label class="collapse" for="c-42871711">[-]</label><label class="expand" for="c-42871711">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We passed peak original content years ago.<p>In relative terms, that&#x27;s obviously and most definitely true.<p>In absolute terms, that&#x27;s obviously and most definitely false.</div><br/></div></div></div></div></div></div><div id="42866072" class="c"><input type="checkbox" id="c-42866072" checked=""/><div class="controls bullet"><span class="by">bilekas</span><span>|</span><a href="#42867899">prev</a><span>|</span><a href="#42871905">next</a><span>|</span><label class="collapse" for="c-42866072">[-]</label><label class="expand" for="c-42866072">[46 more]</label></div><br/><div class="children"><div class="content">&gt; “It’s also extremely hard to rally a big talented research team to charge a new hill in the fog together,” he added. “This is the key to driving progress forward.”<p>Well I think DeepSeek releasing it open source and on an MIT license will rally the big talent. The open sourcing of a new technology has always driven progress in the past.<p>The last paragraph too is where OpenAi seems to be focusing their efforts..<p>&gt; we engage in countermeasures to protect our IP, including a careful process for which frontier capabilities to include in released models ..<p>&gt; ... we are working closely with the US government to best protect the most capable models from efforts by adversaries and competitors to take US technology.<p>So they&#x27;ll go for getting DeepSeek banned like TikTok was now that a precedent has been set ?</div><br/><div id="42871290" class="c"><input type="checkbox" id="c-42871290" checked=""/><div class="controls bullet"><span class="by">zelphirkalt</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42869420">next</a><span>|</span><label class="collapse" for="c-42871290">[-]</label><label class="expand" for="c-42871290">[4 more]</label></div><br/><div class="children"><div class="content">Actually the &quot;our IP&quot; argument is ridiculous. What they are doing is stealing data from all over the web, without people&#x27;s consent for that data to be used in training ML models. If anything, then &quot;Open&quot;AI should be sued and forced to publish their whole product. The people should demand knowing exactly what is going on with their data.<p>Also still an unresolved issue is how they will ever comply with a deletion request, should any model output personal data of someone. They are heavily in a gray area, with regards to what should be allowed. If anything, they should really shut up now.</div><br/><div id="42875790" class="c"><input type="checkbox" id="c-42875790" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42871290">parent</a><span>|</span><a href="#42871392">next</a><span>|</span><label class="collapse" for="c-42875790">[-]</label><label class="expand" for="c-42875790">[1 more]</label></div><br/><div class="children"><div class="content">They can still have IP while using copyrighted training materials - the actual model source code.<p>But DeepSeek didn&#x27;t use that presumably (since it&#x27;s secret). They definitely can&#x27;t argue that using copyrighted material for training is fine, but using output from other commercial models isn&#x27;t. That&#x27;s too inconsistent.</div><br/></div></div><div id="42871392" class="c"><input type="checkbox" id="c-42871392" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42871290">parent</a><span>|</span><a href="#42875790">prev</a><span>|</span><a href="#42869420">next</a><span>|</span><label class="collapse" for="c-42871392">[-]</label><label class="expand" for="c-42871392">[2 more]</label></div><br/><div class="children"><div class="content">If there&#x27;s any litigation, a counterclaim would be interesting. But DeepSeek would need to partner with parties that have been damaged by OpenAI&#x27;s scraping.</div><br/><div id="42873585" class="c"><input type="checkbox" id="c-42873585" checked=""/><div class="controls bullet"><span class="by">greenavocado</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42871392">parent</a><span>|</span><a href="#42869420">next</a><span>|</span><label class="collapse" for="c-42873585">[-]</label><label class="expand" for="c-42873585">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m getting popcorn ready for the trial where an apparatus of the Chinese Communist Party files a counterclaim in an American Court together with the common people - millions of John Does - as litigants against an organization that has aggressively and in many cases of oppressively scraped their websites (DDoS)</div><br/></div></div></div></div></div></div><div id="42869420" class="c"><input type="checkbox" id="c-42869420" checked=""/><div class="controls bullet"><span class="by">buyucu</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42871290">prev</a><span>|</span><a href="#42869262">next</a><span>|</span><label class="collapse" for="c-42869420">[-]</label><label class="expand" for="c-42869420">[19 more]</label></div><br/><div class="children"><div class="content">I&#x27;m willing to bet &#x27;&#x27;ban DeepSeek&#x27;&#x27; voices will start soon.  Why compete, when you can just ban?</div><br/><div id="42869583" class="c"><input type="checkbox" id="c-42869583" checked=""/><div class="controls bullet"><span class="by">cmiles74</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869420">parent</a><span>|</span><a href="#42871300">next</a><span>|</span><label class="collapse" for="c-42869583">[-]</label><label class="expand" for="c-42869583">[7 more]</label></div><br/><div class="children"><div class="content">They&#x27;ve started already, I&#x27;ve seen posts on LinkedIn implying or outright stating that DeepSeek is a national security risk (IMHO, LinkedIn being the social media outlet  most corporate-sycophantic). I went ahead and just picked this one at random from my feed.<p><a href="https:&#x2F;&#x2F;www.linkedin.com&#x2F;posts&#x2F;kevinkeller_deepseek-privacy-security-activity-7289673454142771200-G0MU?utm_source=share&amp;utm_medium=member_desktop" rel="nofollow">https:&#x2F;&#x2F;www.linkedin.com&#x2F;posts&#x2F;kevinkeller_deepseek-privacy-...</a></div><br/><div id="42874995" class="c"><input type="checkbox" id="c-42874995" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869583">parent</a><span>|</span><a href="#42870546">next</a><span>|</span><label class="collapse" for="c-42874995">[-]</label><label class="expand" for="c-42874995">[1 more]</label></div><br/><div class="children"><div class="content">At least this guy can differentiate between running your own model and using the web&#x2F;mobile app where DeepSeek process your data. I&#x27;ve watched a TV show yesterday (I think it was France24) where the &quot;experts&quot; can&#x27;t really tell the difference or are not aware of it. Shut down the TV and went to sleep.</div><br/></div></div><div id="42870546" class="c"><input type="checkbox" id="c-42870546" checked=""/><div class="controls bullet"><span class="by">flybarrel</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869583">parent</a><span>|</span><a href="#42874995">prev</a><span>|</span><a href="#42871206">next</a><span>|</span><label class="collapse" for="c-42870546">[-]</label><label class="expand" for="c-42870546">[1 more]</label></div><br/><div class="children"><div class="content">Oh this post...calling out DeepSeek&#x27;s T&amp;C but not comparing it with OpenAI&#x27;s is really disingenuous IMO.</div><br/></div></div><div id="42872142" class="c"><input type="checkbox" id="c-42872142" checked=""/><div class="controls bullet"><span class="by">ijidak</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869583">parent</a><span>|</span><a href="#42871206">prev</a><span>|</span><a href="#42871300">next</a><span>|</span><label class="collapse" for="c-42872142">[-]</label><label class="expand" for="c-42872142">[3 more]</label></div><br/><div class="children"><div class="content">NBC Nightly News, on Monday, had an expert -- at 8:05 in the video -- who claimed there might be national security risks to Deepseek.<p>I&#x27;m not going to take a side on whether there is or not.<p>But, it does sound reminiscent of the reasons used to ban Tik-tok.<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;uE6F6eTyAVc?si=BLZo3FMVRvjEy6Xa" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;uE6F6eTyAVc?si=BLZo3FMVRvjEy6Xa</a></div><br/><div id="42875236" class="c"><input type="checkbox" id="c-42875236" checked=""/><div class="controls bullet"><span class="by">ulbu</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42872142">parent</a><span>|</span><a href="#42873776">next</a><span>|</span><label class="collapse" for="c-42875236">[-]</label><label class="expand" for="c-42875236">[1 more]</label></div><br/><div class="children"><div class="content">as if openai is not an (inter)national security risk</div><br/></div></div><div id="42873776" class="c"><input type="checkbox" id="c-42873776" checked=""/><div class="controls bullet"><span class="by">Mistletoe</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42872142">parent</a><span>|</span><a href="#42875236">prev</a><span>|</span><a href="#42871300">next</a><span>|</span><label class="collapse" for="c-42873776">[-]</label><label class="expand" for="c-42873776">[1 more]</label></div><br/><div class="children"><div class="content">Next they will say it is to protect the children and that terrorists use it.  You start to recognize the playbook after about the millionth time.</div><br/></div></div></div></div></div></div><div id="42871300" class="c"><input type="checkbox" id="c-42871300" checked=""/><div class="controls bullet"><span class="by">zelphirkalt</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869420">parent</a><span>|</span><a href="#42869583">prev</a><span>|</span><a href="#42875127">next</a><span>|</span><label class="collapse" for="c-42871300">[-]</label><label class="expand" for="c-42871300">[3 more]</label></div><br/><div class="children"><div class="content">Actually asking for banning DeepSeek would be the ultimate admit of defeat by ClosedAI.</div><br/><div id="42874226" class="c"><input type="checkbox" id="c-42874226" checked=""/><div class="controls bullet"><span class="by">cscurmudgeon</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42871300">parent</a><span>|</span><a href="#42875127">next</a><span>|</span><label class="collapse" for="c-42874226">[-]</label><label class="expand" for="c-42874226">[2 more]</label></div><br/><div class="children"><div class="content">No need to ban DeepSeek, just ban Chinese companies from using US frontier models.</div><br/><div id="42875780" class="c"><input type="checkbox" id="c-42875780" checked=""/><div class="controls bullet"><span class="by">buyucu</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42874226">parent</a><span>|</span><a href="#42875127">next</a><span>|</span><label class="collapse" for="c-42875780">[-]</label><label class="expand" for="c-42875780">[1 more]</label></div><br/><div class="children"><div class="content">that will have no effect.  best frontier models are now chinese.</div><br/></div></div></div></div></div></div><div id="42875127" class="c"><input type="checkbox" id="c-42875127" checked=""/><div class="controls bullet"><span class="by">vitaflo</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869420">parent</a><span>|</span><a href="#42871300">prev</a><span>|</span><a href="#42873250">next</a><span>|</span><label class="collapse" for="c-42875127">[-]</label><label class="expand" for="c-42875127">[1 more]</label></div><br/><div class="children"><div class="content">All you would do by banning it is killing US progress in AI.  The rest of the world is still going to be able to use DS.  You&#x27;re just giving the rest of the world a leg up.<p>TikTok is a consumption tool, DS is a productive one.  They aren&#x27;t the same.</div><br/></div></div><div id="42873250" class="c"><input type="checkbox" id="c-42873250" checked=""/><div class="controls bullet"><span class="by">razster</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869420">parent</a><span>|</span><a href="#42875127">prev</a><span>|</span><a href="#42870268">next</a><span>|</span><label class="collapse" for="c-42873250">[-]</label><label class="expand" for="c-42873250">[2 more]</label></div><br/><div class="children"><div class="content">The fact it is out and improving day by day. Unsloth.ai is on a roll with their advancements. If DeepSeek is banned hundreds more will popup and change the data ever so slightly to skirt the ban. Pandora&#x27;s box exploded on this one.</div><br/><div id="42875642" class="c"><input type="checkbox" id="c-42875642" checked=""/><div class="controls bullet"><span class="by">Logiar</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42873250">parent</a><span>|</span><a href="#42870268">next</a><span>|</span><label class="collapse" for="c-42875642">[-]</label><label class="expand" for="c-42875642">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d imagine a ban would be on their service, not the model itself.</div><br/></div></div></div></div><div id="42870268" class="c"><input type="checkbox" id="c-42870268" checked=""/><div class="controls bullet"><span class="by">namuol</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869420">parent</a><span>|</span><a href="#42873250">prev</a><span>|</span><a href="#42870162">next</a><span>|</span><label class="collapse" for="c-42870268">[-]</label><label class="expand" for="c-42870268">[1 more]</label></div><br/><div class="children"><div class="content">Already happening within tech company policy. Mostly as a security concern. Local or controlled hosting of the model is okay in theory based on this concern, but it taints everything regarding deepseek in effect.</div><br/></div></div><div id="42870162" class="c"><input type="checkbox" id="c-42870162" checked=""/><div class="controls bullet"><span class="by">Freedom2</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869420">parent</a><span>|</span><a href="#42870268">prev</a><span>|</span><a href="#42869262">next</a><span>|</span><label class="collapse" for="c-42870162">[-]</label><label class="expand" for="c-42870162">[4 more]</label></div><br/><div class="children"><div class="content">Competing is hard and expensive, whereas banning is for sure the faster way to make stock values go up and exec&#x27;s total package as a result.</div><br/><div id="42874228" class="c"><input type="checkbox" id="c-42874228" checked=""/><div class="controls bullet"><span class="by">cscurmudgeon</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42870162">parent</a><span>|</span><a href="#42869262">next</a><span>|</span><label class="collapse" for="c-42874228">[-]</label><label class="expand" for="c-42874228">[3 more]</label></div><br/><div class="children"><div class="content">Banning worked for China all these decades.</div><br/><div id="42874996" class="c"><input type="checkbox" id="c-42874996" checked=""/><div class="controls bullet"><span class="by">caseyy</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42874228">parent</a><span>|</span><a href="#42869262">next</a><span>|</span><label class="collapse" for="c-42874996">[-]</label><label class="expand" for="c-42874996">[2 more]</label></div><br/><div class="children"><div class="content">It’s simply because banning removes a market force in the US that’d drive technological advancement.<p>This is already evident with CNSA&#x2F;NASA, Huawei&#x2F;Android, TikTok&#x2F;Western social media. The Western tech gets mothballed because we stick our heads in the sand and pretend we are undisputed leaders of the world in tech, whereas it is slowly becoming disputable.</div><br/><div id="42875100" class="c"><input type="checkbox" id="c-42875100" checked=""/><div class="controls bullet"><span class="by">cscurmudgeon</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42874996">parent</a><span>|</span><a href="#42869262">next</a><span>|</span><label class="collapse" for="c-42875100">[-]</label><label class="expand" for="c-42875100">[1 more]</label></div><br/><div class="children"><div class="content">The US won&#x27;t ban DeepSeek from US, but more likely we will ban DeepSeek (and other Chinese companies) from accessing US frontier models.<p>&gt;  Western tech gets mothballed because we stick our heads in the sand and pretend we are undisputed leaders of the world in tech, whereas it is slowly becoming disputable.<p>I am hearing Chinese tech is now the best and they achieved it with banning things left and right.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42869262" class="c"><input type="checkbox" id="c-42869262" checked=""/><div class="controls bullet"><span class="by">bangaladore</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42869420">prev</a><span>|</span><a href="#42875026">next</a><span>|</span><label class="collapse" for="c-42869262">[-]</label><label class="expand" for="c-42869262">[6 more]</label></div><br/><div class="children"><div class="content">&gt; So they&#x27;ll go for getting DeepSeek banned like TikTok was now that a precedent has been set ?<p>Can&#x27;t really ban what can be downloaded for free and hosted by anyone. There are many providers hosting the ~700B parameter version that aren&#x27;t CCP aligned.</div><br/><div id="42869819" class="c"><input type="checkbox" id="c-42869819" checked=""/><div class="controls bullet"><span class="by">runako</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869262">parent</a><span>|</span><a href="#42875320">next</a><span>|</span><label class="collapse" for="c-42869819">[-]</label><label class="expand" for="c-42869819">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m old enough to remember when the US government did something very similar. For years (decades?), we banned any implementation of public-key cryptography under the guise of the technology being akin to munitions.<p>People made shirts with printouts of the code to RSA under the heading  &quot;this shirt is a munition.&quot; Apparently such shirts are still for sale, even though they are not classified as munitions anymore.<p>[1] - <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Export_of_cryptography_from_the_United_States" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Export_of_cryptography_from_th...</a></div><br/><div id="42875043" class="c"><input type="checkbox" id="c-42875043" checked=""/><div class="controls bullet"><span class="by">maeil</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869819">parent</a><span>|</span><a href="#42871616">next</a><span>|</span><label class="collapse" for="c-42875043">[-]</label><label class="expand" for="c-42875043">[2 more]</label></div><br/><div class="children"><div class="content">Were these implementations already easily open source accessible at the time, with tens of thousands of people already actively using them on their computers? No, right? Doesn&#x27;t seem feasible this time around.</div><br/><div id="42876114" class="c"><input type="checkbox" id="c-42876114" checked=""/><div class="controls bullet"><span class="by">hnlmorg</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42875043">parent</a><span>|</span><a href="#42871616">next</a><span>|</span><label class="collapse" for="c-42876114">[-]</label><label class="expand" for="c-42876114">[1 more]</label></div><br/><div class="children"><div class="content">Yes they were.<p>The ban was on exporting the code, not having the code in possession.<p>Furthermore it was only the US who had this ban.<p>I am old enough to remember this and the scoffing that European PGP users had towards their American counterparts</div><br/></div></div></div></div><div id="42871616" class="c"><input type="checkbox" id="c-42871616" checked=""/><div class="controls bullet"><span class="by">beepbooptheory</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869819">parent</a><span>|</span><a href="#42875043">prev</a><span>|</span><a href="#42875320">next</a><span>|</span><label class="collapse" for="c-42871616">[-]</label><label class="expand" for="c-42871616">[1 more]</label></div><br/><div class="children"><div class="content">I am not that old, but I did a deep dive on this in the past because it was just so extremely fascinating, especially reading the archives of Cypherpunk.  There is a very solid, if rather bendy, line connecting all that to &quot;crypto culture&quot; today.</div><br/></div></div></div></div><div id="42875320" class="c"><input type="checkbox" id="c-42875320" checked=""/><div class="controls bullet"><span class="by">seizethecheese</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42869262">parent</a><span>|</span><a href="#42869819">prev</a><span>|</span><a href="#42875026">next</a><span>|</span><label class="collapse" for="c-42875320">[-]</label><label class="expand" for="c-42875320">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Can&#x27;t really ban what can be downloaded for free and hosted by anyone.<p>Like music? They banned napster</div><br/></div></div></div></div><div id="42875026" class="c"><input type="checkbox" id="c-42875026" checked=""/><div class="controls bullet"><span class="by">emsign</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42869262">prev</a><span>|</span><a href="#42873124">next</a><span>|</span><label class="collapse" for="c-42875026">[-]</label><label class="expand" for="c-42875026">[2 more]</label></div><br/><div class="children"><div class="content">500 billion for a few US companies  yet the Chinese will probably still be better for way less money. This might turn out to be a historical mistake of the new administration.</div><br/><div id="42875634" class="c"><input type="checkbox" id="c-42875634" checked=""/><div class="controls bullet"><span class="by">tw1984</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42875026">parent</a><span>|</span><a href="#42873124">next</a><span>|</span><label class="collapse" for="c-42875634">[-]</label><label class="expand" for="c-42875634">[1 more]</label></div><br/><div class="children"><div class="content">the biggest mistake was made 20 years by allowing China to join the WTO.<p>everything is already too late.</div><br/></div></div></div></div><div id="42873124" class="c"><input type="checkbox" id="c-42873124" checked=""/><div class="controls bullet"><span class="by">tdb7893</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42875026">prev</a><span>|</span><a href="#42871781">next</a><span>|</span><label class="collapse" for="c-42873124">[-]</label><label class="expand" for="c-42873124">[1 more]</label></div><br/><div class="children"><div class="content">The fact that they are <i>still</i> called &quot;Open&quot;AI adds such a delicious irony to this whole thing. I could not imagine a company I had less sympathy for in this situation.</div><br/></div></div><div id="42871781" class="c"><input type="checkbox" id="c-42871781" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42873124">prev</a><span>|</span><a href="#42875374">next</a><span>|</span><label class="collapse" for="c-42871781">[-]</label><label class="expand" for="c-42871781">[1 more]</label></div><br/><div class="children"><div class="content">Explain to me how one ban&#x27;s opensource?  That concept is foreign to me.</div><br/></div></div><div id="42875374" class="c"><input type="checkbox" id="c-42875374" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42871781">prev</a><span>|</span><a href="#42875069">next</a><span>|</span><label class="collapse" for="c-42875374">[-]</label><label class="expand" for="c-42875374">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So they&#x27;ll go for getting DeepSeek banned like TikTok<p>The UAE (where I live, happily, and by choice), which desperately wants to be the center of the world in AI and is spending vast time and treasure to make it happen (they&#x27;ve even got their own excellent, government-funded foundation model), would _love_ this. Any attempt to ban DeepSeek in the US would be the most gigantic self-own. Combine that with no income tax, a fantastic standard of living, and a willingness to very easily give out visas to smart people from anywhere in the world, and I have to imagine it is one of several countries desperate for the US to do something so utterly stupid.</div><br/></div></div><div id="42875069" class="c"><input type="checkbox" id="c-42875069" checked=""/><div class="controls bullet"><span class="by">cscurmudgeon</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42875374">prev</a><span>|</span><a href="#42867286">next</a><span>|</span><label class="collapse" for="c-42875069">[-]</label><label class="expand" for="c-42875069">[2 more]</label></div><br/><div class="children"><div class="content">The US doesn&#x27;t need to ban DeepSeek from US<p>The US should only ban DeepSeek (and other Chinese companies) from accessing US frontier models.</div><br/><div id="42875637" class="c"><input type="checkbox" id="c-42875637" checked=""/><div class="controls bullet"><span class="by">tw1984</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42875069">parent</a><span>|</span><a href="#42867286">next</a><span>|</span><label class="collapse" for="c-42875637">[-]</label><label class="expand" for="c-42875637">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The US should only ban DeepSeek (and other Chinese companies) from accessing US frontier models.<p>The US should only ban DeepSeek (and other Chinese companies) from accessing US frontier models designed and trained by Chinese Americans.<p>fixed for you.</div><br/></div></div></div></div><div id="42867286" class="c"><input type="checkbox" id="c-42867286" checked=""/><div class="controls bullet"><span class="by">hujun</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42875069">prev</a><span>|</span><a href="#42872612">next</a><span>|</span><label class="collapse" for="c-42867286">[-]</label><label class="expand" for="c-42867286">[4 more]</label></div><br/><div class="children"><div class="content">or sold to US
I could totally see this happening soon</div><br/><div id="42867833" class="c"><input type="checkbox" id="c-42867833" checked=""/><div class="controls bullet"><span class="by">trissi1996</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42867286">parent</a><span>|</span><a href="#42872612">next</a><span>|</span><label class="collapse" for="c-42867833">[-]</label><label class="expand" for="c-42867833">[3 more]</label></div><br/><div class="children"><div class="content">Why would they want to sell ?</div><br/><div id="42868245" class="c"><input type="checkbox" id="c-42868245" checked=""/><div class="controls bullet"><span class="by">kavalg</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42867833">parent</a><span>|</span><a href="#42872612">next</a><span>|</span><label class="collapse" for="c-42868245">[-]</label><label class="expand" for="c-42868245">[2 more]</label></div><br/><div class="children"><div class="content">And what are they going to sell? The weights and the model architecture are already open source. I doubt the datasets of DeepSeek are better than OpenAI&#x27;s</div><br/><div id="42869095" class="c"><input type="checkbox" id="c-42869095" checked=""/><div class="controls bullet"><span class="by">Dansvidania</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42868245">parent</a><span>|</span><a href="#42872612">next</a><span>|</span><label class="collapse" for="c-42869095">[-]</label><label class="expand" for="c-42869095">[1 more]</label></div><br/><div class="children"><div class="content">plus, if the US were to decide to ban DeepSeek (the company) wouldn&#x27;t non-chinese companies be able to pick up the models and run them at a relatively low expense?</div><br/></div></div></div></div></div></div></div></div><div id="42872612" class="c"><input type="checkbox" id="c-42872612" checked=""/><div class="controls bullet"><span class="by">portaouflop</span><span>|</span><a href="#42866072">parent</a><span>|</span><a href="#42867286">prev</a><span>|</span><a href="#42871905">next</a><span>|</span><label class="collapse" for="c-42872612">[-]</label><label class="expand" for="c-42872612">[5 more]</label></div><br/><div class="children"><div class="content">TikTok is banned in the US?</div><br/><div id="42874272" class="c"><input type="checkbox" id="c-42874272" checked=""/><div class="controls bullet"><span class="by">bagels</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42872612">parent</a><span>|</span><a href="#42874257">next</a><span>|</span><label class="collapse" for="c-42874272">[-]</label><label class="expand" for="c-42874272">[3 more]</label></div><br/><div class="children"><div class="content">Yes, it was removed from the app stores, and briefly, from the web.</div><br/><div id="42874935" class="c"><input type="checkbox" id="c-42874935" checked=""/><div class="controls bullet"><span class="by">daveguy</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42874272">parent</a><span>|</span><a href="#42874257">next</a><span>|</span><label class="collapse" for="c-42874935">[-]</label><label class="expand" for="c-42874935">[2 more]</label></div><br/><div class="children"><div class="content">Except access to the app didn&#x27;t have to stop. TikTok chose to manipulate users and Trump by going beyond the law and kissing Trump&#x27;s rear. It was only US companies that couldn&#x27;t host the app (eg Google and Apple). Users in the US could have still accessed the app, and even side-loaded it on Android, but TikTok purposely blocked them and pretended it was the ban. They were able to do it because they know the exact location of every TikTok user whether you use a VPN or not.<p>Source:<p>&gt; If not sold within a year, the law would make it illegal for web-hosting services to support TikTok, and it would force Google and Apple to remove TikTok from app stores — rendering the app unusable with time.<p><a href="https:&#x2F;&#x2F;www.npr.org&#x2F;2024&#x2F;04&#x2F;24&#x2F;1246663779&#x2F;biden-ban-tiktok-u" rel="nofollow">https:&#x2F;&#x2F;www.npr.org&#x2F;2024&#x2F;04&#x2F;24&#x2F;1246663779&#x2F;biden-ban-tiktok-u</a>...</div><br/><div id="42875680" class="c"><input type="checkbox" id="c-42875680" checked=""/><div class="controls bullet"><span class="by">rcbdev</span><span>|</span><a href="#42866072">root</a><span>|</span><a href="#42874935">parent</a><span>|</span><a href="#42874257">next</a><span>|</span><label class="collapse" for="c-42875680">[-]</label><label class="expand" for="c-42875680">[1 more]</label></div><br/><div class="children"><div class="content">From a strategic point of view, they took the smartest gamble (or call it calculated risk) I&#x27;ve seen a company of this size take in a while. Kudos.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42871905" class="c"><input type="checkbox" id="c-42871905" checked=""/><div class="controls bullet"><span class="by">mrkpdl</span><span>|</span><a href="#42866072">prev</a><span>|</span><a href="#42868651">next</a><span>|</span><label class="collapse" for="c-42871905">[-]</label><label class="expand" for="c-42871905">[4 more]</label></div><br/><div class="children"><div class="content">The cat is out of the bag. This is the landscape now, r1 was made in a post-o1 world. Now other models can distill r1 and so on.<p>I don’t buy the argument that distilling from o1 undermines deep seek’s claims around expense at all. Just as open AI used the tools ‘available to them’ to train their models (eg everyone else’ data), r1 is using today’s tools.<p>Does open AI really have a moral or ethical high ground here?</div><br/><div id="42876125" class="c"><input type="checkbox" id="c-42876125" checked=""/><div class="controls bullet"><span class="by">jamil7</span><span>|</span><a href="#42871905">parent</a><span>|</span><a href="#42875727">next</a><span>|</span><label class="collapse" for="c-42876125">[-]</label><label class="expand" for="c-42876125">[1 more]</label></div><br/><div class="children"><div class="content">Agree 100%, this was also bound to happen eventually, OpenAI could have just remained more &quot;open&quot; from the beginning and embraced the inevitable commoditization of these models. What did delaying this buy them?</div><br/></div></div><div id="42872353" class="c"><input type="checkbox" id="c-42872353" checked=""/><div class="controls bullet"><span class="by">ijidak</span><span>|</span><a href="#42871905">parent</a><span>|</span><a href="#42875727">prev</a><span>|</span><a href="#42868651">next</a><span>|</span><label class="collapse" for="c-42872353">[-]</label><label class="expand" for="c-42872353">[1 more]</label></div><br/><div class="children"><div class="content">Plus, it suggests OpenAI never had much of a moat.<p>Even if they win the legal case, it means weights can be inferred and improved upon simply by using the output that is also your core value add (e.g. the very output you need to sell to the world).<p>Their moat is about as strong as KFC&#x27;s eleven herbs and spices. Maybe less...</div><br/></div></div></div></div><div id="42868651" class="c"><input type="checkbox" id="c-42868651" checked=""/><div class="controls bullet"><span class="by">blast</span><span>|</span><a href="#42871905">prev</a><span>|</span><a href="#42866118">next</a><span>|</span><label class="collapse" for="c-42868651">[-]</label><label class="expand" for="c-42868651">[57 more]</label></div><br/><div class="children"><div class="content">Everyone is responding to the intellectual property issue, but isn&#x27;t that the less interesting point?<p>If Deepseek trained off OpenAI, then it wasn&#x27;t trained from scratch for &quot;pennies on the dollar&quot; and isn&#x27;t the Sputnik-like technical breakthrough that we&#x27;ve been hearing so much about. That&#x27;s the news here. Or rather, the potential news, since we don&#x27;t know if it&#x27;s true yet.</div><br/><div id="42869791" class="c"><input type="checkbox" id="c-42869791" checked=""/><div class="controls bullet"><span class="by">alecco</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42868817">next</a><span>|</span><label class="collapse" for="c-42869791">[-]</label><label class="expand" for="c-42869791">[8 more]</label></div><br/><div class="children"><div class="content">Even if all that about training is true, the bigger cost is inference and Deepseek is 100x cheaper. That destroys OpenAI&#x2F;Anthropic&#x27;s value proposition of having a unique secret sauce so users are quickly fleeing to cheaper alternatives.<p>Google Deepmind&#x27;s recent Gemini 2.0 Flash Thinking is also priced at the new Deepseek level. It&#x27;s pretty good (unlike previous Gemini models).<p>[0] <a href="https:&#x2F;&#x2F;x.com&#x2F;deedydas&#x2F;status&#x2F;1883355957838897409" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;deedydas&#x2F;status&#x2F;1883355957838897409</a><p>[1] <a href="https:&#x2F;&#x2F;x.com&#x2F;raveeshbhalla&#x2F;status&#x2F;1883380722645512275" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;raveeshbhalla&#x2F;status&#x2F;1883380722645512275</a></div><br/><div id="42875108" class="c"><input type="checkbox" id="c-42875108" checked=""/><div class="controls bullet"><span class="by">nightpool</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869791">parent</a><span>|</span><a href="#42872028">next</a><span>|</span><label class="collapse" for="c-42875108">[-]</label><label class="expand" for="c-42875108">[3 more]</label></div><br/><div class="children"><div class="content">I mean, Deepseek is currently charging 100x less. That doesn&#x27;t tell us much about how cheaper it is to run inference on.</div><br/><div id="42875416" class="c"><input type="checkbox" id="c-42875416" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42875108">parent</a><span>|</span><a href="#42872028">next</a><span>|</span><label class="collapse" for="c-42875416">[-]</label><label class="expand" for="c-42875416">[2 more]</label></div><br/><div class="children"><div class="content">More like OpenAI is currently charging more. Since R1 is open source &#x2F; open weight we can actually run it on our own hardware and see what kinda compute it requires.<p>What is definitely true is that there are already other providers offering DeepSeek R1 (e.g. on OpenRouter[1]) for $7&#x2F;m-in and $7&#x2F;m-out. Meanwhile OpenAI is charging $15&#x2F;m-in and $60&#x2F;m-out. So already you&#x27;re seeing at least 5x cheaper inference with R1 vs O1 with a bunch of confounding factors. But it is hard to say anything truly concrete about efficiency  OpenAI does not disclose the actual compute required to run inference for O1.<p>[1] <a href="https:&#x2F;&#x2F;openrouter.ai&#x2F;deepseek&#x2F;deepseek-r1" rel="nofollow">https:&#x2F;&#x2F;openrouter.ai&#x2F;deepseek&#x2F;deepseek-r1</a></div><br/><div id="42876005" class="c"><input type="checkbox" id="c-42876005" checked=""/><div class="controls bullet"><span class="by">alecco</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42875416">parent</a><span>|</span><a href="#42872028">next</a><span>|</span><label class="collapse" for="c-42876005">[-]</label><label class="expand" for="c-42876005">[1 more]</label></div><br/><div class="children"><div class="content">And those 3rd party Deepseek inference prices are without low level optimized code, AFAIK.</div><br/></div></div></div></div></div></div><div id="42872028" class="c"><input type="checkbox" id="c-42872028" checked=""/><div class="controls bullet"><span class="by">blast</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869791">parent</a><span>|</span><a href="#42875108">prev</a><span>|</span><a href="#42868817">next</a><span>|</span><label class="collapse" for="c-42872028">[-]</label><label class="expand" for="c-42872028">[4 more]</label></div><br/><div class="children"><div class="content">&gt; the bigger cost is inference<p>I didn&#x27;t know that. Is this always the case?</div><br/><div id="42873761" class="c"><input type="checkbox" id="c-42873761" checked=""/><div class="controls bullet"><span class="by">fcantournet</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42872028">parent</a><span>|</span><a href="#42868817">next</a><span>|</span><label class="collapse" for="c-42873761">[-]</label><label class="expand" for="c-42873761">[3 more]</label></div><br/><div class="children"><div class="content">Well in the first years of AI no, it wasn&#x27;t because nobody was using it.
But at some point if you want to make money you have to provide a service to users, ideally hundreds of millions of users.<p>So you can think of training as CI+TEST_ENV and inference as the cost of running your PROD deployments.<p>Generally in traditional IT infra PROD &gt;&gt; CI+TEST_ENV (10-100 to 1)<p>The ratio might be quite different for LLM, but still any SUCCESSFUL model will have inference &gt; training at some point in time.</div><br/><div id="42874047" class="c"><input type="checkbox" id="c-42874047" checked=""/><div class="controls bullet"><span class="by">sfilmeyer</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42873761">parent</a><span>|</span><a href="#42868817">next</a><span>|</span><label class="collapse" for="c-42874047">[-]</label><label class="expand" for="c-42874047">[2 more]</label></div><br/><div class="children"><div class="content">&gt;The ratio might be quite different for LLM, but still any SUCCESSFUL model will have inference &gt; training at some point in time.<p>I think you&#x27;re making assumptions here that don&#x27;t necessarily have to be universally true for all successful models. Even without getting into particularly pathological cases, some models can be successful and profitable while only having a few customers. If you build a model that is very valuable to investment banks, to professional basketball teams, or some other much more limited group than consumers writ large, you might get paid handsomely for a limited amount of inference but still spend a lot on training.</div><br/><div id="42875394" class="c"><input type="checkbox" id="c-42875394" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42874047">parent</a><span>|</span><a href="#42868817">next</a><span>|</span><label class="collapse" for="c-42875394">[-]</label><label class="expand" for="c-42875394">[1 more]</label></div><br/><div class="children"><div class="content">if there is so much value for a small group, it is likely those are not simple inferences but of the new expensive kind with very long CoT chains and reasoning. So not cheap and it is exactly this trend towards inference time compute that make inference &gt; training from a total resources needed pov.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42868817" class="c"><input type="checkbox" id="c-42868817" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42869791">prev</a><span>|</span><a href="#42875516">next</a><span>|</span><label class="collapse" for="c-42868817">[-]</label><label class="expand" for="c-42868817">[35 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not correct. First of all, training off of data generated by another AI is generally a bad idea because you&#x27;ll end up with a strictly less accurate model (usually). But secondly, and more to your point, even if you were to use training data from another model, YOU STILL NEED TO DO ALL THE TRAINING.<p>Using data from another model won&#x27;t save you any training time.</div><br/><div id="42869137" class="c"><input type="checkbox" id="c-42869137" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868817">parent</a><span>|</span><a href="#42868941">next</a><span>|</span><label class="collapse" for="c-42869137">[-]</label><label class="expand" for="c-42869137">[14 more]</label></div><br/><div class="children"><div class="content">&gt; training off of data generated by another AI is generally a bad idea<p>It&#x27;s...not, and its repeatedly been proven in practice that this is an invalid generalization because it is missing necessary qualifications, and its funny that this myth keeps persisting.<p>It&#x27;s probably a bad idea to use <i>uncurated</i> output from another AI to train a model if you are trying to make a better model rather than a distillation of the first model, and its definitely (and, ISTR, the actual research result from which the false generalization has developed) a bad idea to iteratively fine-tune a model on <i>its own</i> unfiltered output, but there has been lots of success using AI models to generate data which is curated and used to train other models, which can be much more efficient that trying to <i>create</i> new material without AI once you&#x27;ve gotten to the point where you&#x27;ve already hoovered up all the readily-accessible low hanging fruit of premade content relevant to your training goal.</div><br/><div id="42869350" class="c"><input type="checkbox" id="c-42869350" checked=""/><div class="controls bullet"><span class="by">LPisGood</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869137">parent</a><span>|</span><a href="#42874681">next</a><span>|</span><label class="collapse" for="c-42869350">[-]</label><label class="expand" for="c-42869350">[12 more]</label></div><br/><div class="children"><div class="content">It is, of course not going to produce a “child” model that more accurately predicts the underlying true distribution that the “parent” model was trying to. That is, it will not add anything new.<p>This is immediately obvious if you look at it through a statistical learning lens and not the mysticism crystal ball that many view NN’s through.</div><br/><div id="42874576" class="c"><input type="checkbox" id="c-42874576" checked=""/><div class="controls bullet"><span class="by">highfrequency</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869350">parent</a><span>|</span><a href="#42869967">next</a><span>|</span><label class="collapse" for="c-42874576">[-]</label><label class="expand" for="c-42874576">[1 more]</label></div><br/><div class="children"><div class="content">While that is theoretically true, it misses everything interesting (kind of like the No Free Lunch Theorem, or the VC dimension for neural nets). The key is that the parent model may have been trained on a dubious objective like predicting the next word of randomly sampled internet text - not because this is the objective we want, but because this is the only way to get a trillion training points.<p>Given this, there’s no reason why it could not be trivial to produce a child model from (filtered) parent output that exceeds the child model on a different, more meaningful objective like being a useful chatbot. There&#x27;s no reason why this would have to be limited to domains with verifiable answers either.</div><br/></div></div><div id="42869967" class="c"><input type="checkbox" id="c-42869967" checked=""/><div class="controls bullet"><span class="by">acgourley</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869350">parent</a><span>|</span><a href="#42874576">prev</a><span>|</span><a href="#42869868">next</a><span>|</span><label class="collapse" for="c-42869967">[-]</label><label class="expand" for="c-42869967">[4 more]</label></div><br/><div class="children"><div class="content">This is not obvious to me! For example, if you locked me in a room with no information inputs, over time I may still become more intelligent by your measures. Through play and reflection I can prune, reconcile and generate. I need compute to do this, but not necessarily more knowledge.</div><br/><div id="42870821" class="c"><input type="checkbox" id="c-42870821" checked=""/><div class="controls bullet"><span class="by">sudosysgen</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869967">parent</a><span>|</span><a href="#42869868">next</a><span>|</span><label class="collapse" for="c-42870821">[-]</label><label class="expand" for="c-42870821">[3 more]</label></div><br/><div class="children"><div class="content">Again, this isn&#x27;t how distillation work. Your task as the distillation model is to copy mistakes, and you will be penalized by pruning reconciling and generating.<p>&quot;Play and reflection&quot; is something else, which isn&#x27;t distillation.</div><br/><div id="42873334" class="c"><input type="checkbox" id="c-42873334" checked=""/><div class="controls bullet"><span class="by">soerxpso</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42870821">parent</a><span>|</span><a href="#42869868">next</a><span>|</span><label class="collapse" for="c-42873334">[-]</label><label class="expand" for="c-42873334">[2 more]</label></div><br/><div class="children"><div class="content">The initial claim was that distillation can never be used to create a model B that&#x27;s smarter than model A, because B only has access to A&#x27;s knowledge. The argument you&#x27;re responding to was that play and reflection can result in improvements without any additional knowledge, so it is possible for distillation to work as a starting point to create a model B that is smarter than model A, with no new data except model A&#x27;s outputs and then model B&#x27;s outputs. This refutes the initial claim. It is not important for distillation <i>alone</i> to be enough, if it can be made to be enough with a few extra steps afterward.</div><br/><div id="42873790" class="c"><input type="checkbox" id="c-42873790" checked=""/><div class="controls bullet"><span class="by">pockmarked19</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42873334">parent</a><span>|</span><a href="#42869868">next</a><span>|</span><label class="collapse" for="c-42873790">[-]</label><label class="expand" for="c-42873790">[1 more]</label></div><br/><div class="children"><div class="content">You’ve subtly confused “less accurate” and “smarter” in your argument. In other words you’ve replaced the benchmark of representing the base data with the benchmark of reasoning score.<p>Then, you’ve asserted that was the original claim.<p>Sneaky! But that’s how “arguments” on HN are “won”.</div><br/></div></div></div></div></div></div></div></div><div id="42869868" class="c"><input type="checkbox" id="c-42869868" checked=""/><div class="controls bullet"><span class="by">mattnewton</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869350">parent</a><span>|</span><a href="#42869967">prev</a><span>|</span><a href="#42870849">next</a><span>|</span><label class="collapse" for="c-42869868">[-]</label><label class="expand" for="c-42869868">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are no longer trying to just reproduce the distribution of online text as a whole to push the state of the art, they are focused on a different distribution of “high quality” - whatever that means in your domain. So it is possible that this process matches a “better” distribution for some tasks by removing erroneous information or sampling “better” outputs more frequently.</div><br/></div></div><div id="42870849" class="c"><input type="checkbox" id="c-42870849" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869350">parent</a><span>|</span><a href="#42869868">prev</a><span>|</span><a href="#42869888">next</a><span>|</span><label class="collapse" for="c-42870849">[-]</label><label class="expand" for="c-42870849">[1 more]</label></div><br/><div class="children"><div class="content">The latest models create information from base models by randomly creating candidate responses then pruning the bad ones using an evaluation function. The good responses improve the model.<p>It is not distillation. It&#x27;s like how you can arrive at new knowledge by reflecting on existing knowledge.</div><br/></div></div><div id="42869888" class="c"><input type="checkbox" id="c-42869888" checked=""/><div class="controls bullet"><span class="by">kybernetikos</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869350">parent</a><span>|</span><a href="#42870849">prev</a><span>|</span><a href="#42869895">next</a><span>|</span><label class="collapse" for="c-42869888">[-]</label><label class="expand" for="c-42869888">[1 more]</label></div><br/><div class="children"><div class="content">Fine tuning an llm on the output of another llm is exactly how deepseek made its progress. The way they got around the problem you describe is by doing this in a domain that can be relatively easily checked for correctness, so suggested training data for fine tuning could be automatically filtered out if it was wrong.</div><br/></div></div><div id="42869895" class="c"><input type="checkbox" id="c-42869895" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869350">parent</a><span>|</span><a href="#42869888">prev</a><span>|</span><a href="#42869777">next</a><span>|</span><label class="collapse" for="c-42869895">[-]</label><label class="expand" for="c-42869895">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It is, of course not going to produce a “child” model that more accurately predicts the underlying true distribution that the “parent” model was trying to. That is, it will not add anything new.<p>Unfiltered? Sure. With human curation of the generated data it certainly can. (Even automated curation can do this, though its more obvious that human curation can.)<p>I mean, I can randomly developed fact claims about addition, and if I curate which ones go into a training set, train a model that reflects addition of integers much more accurately than the random process which generated the pre-curation input data.<p>Without curation, as I already said, the best you get is a distillation of the source model, which is highly improbable to be more accurate.</div><br/></div></div><div id="42869777" class="c"><input type="checkbox" id="c-42869777" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869350">parent</a><span>|</span><a href="#42869895">prev</a><span>|</span><a href="#42870005">next</a><span>|</span><label class="collapse" for="c-42869777">[-]</label><label class="expand" for="c-42869777">[1 more]</label></div><br/><div class="children"><div class="content">No no no you don’t understand, the models will magically overcome issues and somehow become 100x and do real AGI! Any day now! It’ll work because LLM’s are basically magic!<p>Also, can I have some money to build more data centres pls?</div><br/></div></div><div id="42870005" class="c"><input type="checkbox" id="c-42870005" checked=""/><div class="controls bullet"><span class="by">Jerrrry</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869350">parent</a><span>|</span><a href="#42869777">prev</a><span>|</span><a href="#42874681">next</a><span>|</span><label class="collapse" for="c-42870005">[-]</label><label class="expand" for="c-42870005">[1 more]</label></div><br/><div class="children"><div class="content">No one knows if the pigeon-hole principle applies absolutely exclusive to the ability to generalize outside of a training set.<p>That is the existential, $1T question.</div><br/></div></div></div></div><div id="42874681" class="c"><input type="checkbox" id="c-42874681" checked=""/><div class="controls bullet"><span class="by">gitaarik</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869137">parent</a><span>|</span><a href="#42869350">prev</a><span>|</span><a href="#42868941">next</a><span>|</span><label class="collapse" for="c-42874681">[-]</label><label class="expand" for="c-42874681">[1 more]</label></div><br/><div class="children"><div class="content">So 1 + 1 = 3?</div><br/></div></div></div></div><div id="42868941" class="c"><input type="checkbox" id="c-42868941" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868817">parent</a><span>|</span><a href="#42869137">prev</a><span>|</span><a href="#42868960">next</a><span>|</span><label class="collapse" for="c-42868941">[-]</label><label class="expand" for="c-42868941">[6 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re missing the point being made here, IMHO: using an advanced model to build <i>high quality</i> training data (whatever that means for a given training paradigm) absolutely would increase the efficiency of the process. Remember that they&#x27;re not fighting over sounding human, they&#x27;re fighting over deliberative reasoning capabilities, something that&#x27;s relatively rare in online discourse.<p>Re: &quot;generally a bad idea&quot;, I&#x27;d just highlight &quot;generally&quot; ;) Clearly it worked in this case!</div><br/><div id="42869054" class="c"><input type="checkbox" id="c-42869054" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868941">parent</a><span>|</span><a href="#42868960">next</a><span>|</span><label class="collapse" for="c-42869054">[-]</label><label class="expand" for="c-42869054">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s trivial to build synthetic reasoning datasets, likely even in natural languages. This is a well established technique that works (e.g. see Microsoft Phi, among others).<p>I said generally because there are things like adversarial training that use a ruleset to help generate correct datasets that work well. Outside of techniques like that it&#x27;s not just a rule of thumb, it&#x27;s <i>always</i> true that training on the output of another model will result in a worse model.<p><a href="https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;ai-generated-data-can-poison-future-ai-models&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;ai-generated-data...</a></div><br/><div id="42869940" class="c"><input type="checkbox" id="c-42869940" checked=""/><div class="controls bullet"><span class="by">numba888</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869054">parent</a><span>|</span><a href="#42868960">next</a><span>|</span><label class="collapse" for="c-42869940">[-]</label><label class="expand" for="c-42869940">[4 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s always true that training on the output of another model will result in a worse model.<p>Not convincing.<p>You can imagine model doing some primitive thinking and coming to conclusion. Then you can train another model on summaries. If everything goes well it will be coming to conclusions quicker. That&#x27;s at least. Or it may be able solve more complex problems with the same amount of &#x27;thinking&#x27;. It will be self-propelled evolution.<p>Another option is to use one model to produce &#x27;thinking&#x27; part from known outputs. Then train another to reproduce thinking to get the right output, unknown to it initially. Using humans to create such dataset would be slow and very expensive.<p>PS: if it was impossible humans would be still living on the trees.</div><br/><div id="42871250" class="c"><input type="checkbox" id="c-42871250" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869940">parent</a><span>|</span><a href="#42876122">next</a><span>|</span><label class="collapse" for="c-42871250">[-]</label><label class="expand" for="c-42871250">[2 more]</label></div><br/><div class="children"><div class="content">Humans don&#x27;t improve by &quot;thinking.&quot; They improve my natural selection against a fitness function. If that fitness function is &quot;doing better at math&quot; then over a long time perhaps humans will get better at math.<p>These models don&#x27;t evolve like they, there is not a random process of architectural evolution. Nor is there a fitness function anything like &quot;get better at math.&quot;<p>A system like AlphaZero works because it has a rules to use as an oracle: the game rules. The game rules provide the new training information needed drive the process. Each game played produces new <i>correct</i> training data.<p>These LLMs have no such oracle. Their fitness function is and remains: predict the next word, followed by: produce text that makes a human happy. Note that it&#x27;s not &quot;produce text that makes ChatGPT happy.&quot;</div><br/><div id="42875531" class="c"><input type="checkbox" id="c-42875531" checked=""/><div class="controls bullet"><span class="by">numba888</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42871250">parent</a><span>|</span><a href="#42876122">next</a><span>|</span><label class="collapse" for="c-42875531">[-]</label><label class="expand" for="c-42875531">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s more complicated than this. I mean what you get is defined by what you put in. At first is was random or selected internet garbage + books + docs. I.e. not designed for training. Than was tuning. Now we can use trained model to generate the data designed for training. With specific qualities, in this case reasoning. And train next model. Just intuitively it can be smaller and better at what we trained it for. I showed two options how data can be generated, there are others of course.<p>As for humans, assuming genetically they have the same intellectual abilities, you can see the difference in development of different groups. It&#x27;s mostly defined by training the better next generation. Schools are exactly for this.</div><br/></div></div></div></div><div id="42876122" class="c"><input type="checkbox" id="c-42876122" checked=""/><div class="controls bullet"><span class="by">DonHopkins</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869940">parent</a><span>|</span><a href="#42871250">prev</a><span>|</span><a href="#42868960">next</a><span>|</span><label class="collapse" for="c-42876122">[-]</label><label class="expand" for="c-42876122">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re the sociopath who just confidently tried to blame the air crash on DEI and spewed baseless conspiracy theories about who was to blame, while the bodies are still being recovered from the frozen river. What a disgusting comment. There is absolutely no thought going on in your close-minded bigoted head, and I&#x27;m not at all interested in your uneducated opinions about AI, since you haven&#x27;t even achieved natural intelligence, empathy, or humanity.</div><br/></div></div></div></div></div></div></div></div><div id="42868960" class="c"><input type="checkbox" id="c-42868960" checked=""/><div class="controls bullet"><span class="by">smitelli</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868817">parent</a><span>|</span><a href="#42868941">prev</a><span>|</span><a href="#42868912">next</a><span>|</span><label class="collapse" for="c-42868960">[-]</label><label class="expand" for="c-42868960">[3 more]</label></div><br/><div class="children"><div class="content">&gt; training off of data generated by another AI is generally a bad idea<p>Ah. So if I understand this... once the internet becomes completely overrun with AI-generated articles of no particular substance or importance, we should not bulk-scrape that internet again to train the subsequent generation of models.<p>I look forward to that day.</div><br/><div id="42869335" class="c"><input type="checkbox" id="c-42869335" checked=""/><div class="controls bullet"><span class="by">bangaladore</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868960">parent</a><span>|</span><a href="#42871261">next</a><span>|</span><label class="collapse" for="c-42869335">[-]</label><label class="expand" for="c-42869335">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s already happened. Its well established now that the internet is tainted. After essentially ChatGPT&#x27;s public release, a non-insignificant amount of internet content is not written by humans.</div><br/></div></div><div id="42871261" class="c"><input type="checkbox" id="c-42871261" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868960">parent</a><span>|</span><a href="#42869335">prev</a><span>|</span><a href="#42868912">next</a><span>|</span><label class="collapse" for="c-42871261">[-]</label><label class="expand" for="c-42871261">[1 more]</label></div><br/><div class="children"><div class="content">Yes, this is a real and serious concern that AI researchers have.</div><br/></div></div></div></div><div id="42868912" class="c"><input type="checkbox" id="c-42868912" checked=""/><div class="controls bullet"><span class="by">fumeux_fume</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868817">parent</a><span>|</span><a href="#42868960">prev</a><span>|</span><a href="#42869006">next</a><span>|</span><label class="collapse" for="c-42868912">[-]</label><label class="expand" for="c-42868912">[5 more]</label></div><br/><div class="children"><div class="content">I think the point is that if R1 isn&#x27;t possible without access to OpenAI (at low, subsidized costs) then this isn&#x27;t really a breakthrough as much as a hack to clone an existing model.</div><br/><div id="42868959" class="c"><input type="checkbox" id="c-42868959" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868912">parent</a><span>|</span><a href="#42868988">next</a><span>|</span><label class="collapse" for="c-42868959">[-]</label><label class="expand" for="c-42868959">[3 more]</label></div><br/><div class="children"><div class="content">The training techniques are a breakthrough no matter what data is used. It&#x27;s not up for debate, it&#x27;s an empirical question with a concrete answer. They can and did train orders of magnitude faster.</div><br/><div id="42869252" class="c"><input type="checkbox" id="c-42869252" checked=""/><div class="controls bullet"><span class="by">blast</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868959">parent</a><span>|</span><a href="#42868988">next</a><span>|</span><label class="collapse" for="c-42869252">[-]</label><label class="expand" for="c-42869252">[2 more]</label></div><br/><div class="children"><div class="content">Not arguing with your point about training efficiency, but the degree to which R1 is a technical breakthrough changes if they were calling an outside API to get the answers,  no?<p>It seems like the difference between someone doing a better writeup of (say) Wiles&#x27;s proof vs. proving Fermat&#x27;s Last Theorem independently.</div><br/><div id="42870476" class="c"><input type="checkbox" id="c-42870476" checked=""/><div class="controls bullet"><span class="by">pests</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869252">parent</a><span>|</span><a href="#42868988">next</a><span>|</span><label class="collapse" for="c-42870476">[-]</label><label class="expand" for="c-42870476">[1 more]</label></div><br/><div class="children"><div class="content">That outside API used to be humans, doing the work manually. Now we have ways to speed that up.</div><br/></div></div></div></div></div></div><div id="42868988" class="c"><input type="checkbox" id="c-42868988" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868912">parent</a><span>|</span><a href="#42868959">prev</a><span>|</span><a href="#42869006">next</a><span>|</span><label class="collapse" for="c-42868988">[-]</label><label class="expand" for="c-42868988">[1 more]</label></div><br/><div class="children"><div class="content">R1 is--as far as we know from good ol&#x27; ClosedAI--far more efficient. Even if it were a &quot;clone&quot;, A) that would be a terribly impressive achievement on its own that Anthropic and Google would be mighty jealous of, and B) it&#x27;s at the very least a distillation of O1&#x27;s reasoning capabilities into a more svelte form.</div><br/></div></div></div></div><div id="42869006" class="c"><input type="checkbox" id="c-42869006" checked=""/><div class="controls bullet"><span class="by">athrowaway3z</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868817">parent</a><span>|</span><a href="#42868912">prev</a><span>|</span><a href="#42875520">next</a><span>|</span><label class="collapse" for="c-42869006">[-]</label><label class="expand" for="c-42869006">[1 more]</label></div><br/><div class="children"><div class="content">Thats not right either.<p>It proofs we _can_ optimize our training data.<p>Just like humans have been genetically stable for a long time, the quality &amp; structure of information available to a child today vs that of 2000 years ago makes them more skilled at certain tasks. Math being a good example.</div><br/></div></div><div id="42875520" class="c"><input type="checkbox" id="c-42875520" checked=""/><div class="controls bullet"><span class="by">jjallen</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868817">parent</a><span>|</span><a href="#42869006">prev</a><span>|</span><a href="#42870355">next</a><span>|</span><label class="collapse" for="c-42875520">[-]</label><label class="expand" for="c-42875520">[1 more]</label></div><br/><div class="children"><div class="content">The DS R1 Model is slightly better though. So how does your statement square with that?</div><br/></div></div><div id="42870355" class="c"><input type="checkbox" id="c-42870355" checked=""/><div class="controls bullet"><span class="by">Voloskaya</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868817">parent</a><span>|</span><a href="#42875520">prev</a><span>|</span><a href="#42869076">next</a><span>|</span><label class="collapse" for="c-42870355">[-]</label><label class="expand" for="c-42870355">[3 more]</label></div><br/><div class="children"><div class="content">&gt; First of all, training off of data generated by another AI is generally a bad idea because you&#x27;ll end up with a strictly less accurate model (usually).<p>That is not true at all.<p>We have known how to solve this for at least 2 years now.<p>All the latest state of the art models depend heavily on training on synthetic data.</div><br/><div id="42873203" class="c"><input type="checkbox" id="c-42873203" checked=""/><div class="controls bullet"><span class="by">bjourne</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42870355">parent</a><span>|</span><a href="#42869076">next</a><span>|</span><label class="collapse" for="c-42873203">[-]</label><label class="expand" for="c-42873203">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-024-07566-y" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41586-024-07566-y</a></div><br/><div id="42873528" class="c"><input type="checkbox" id="c-42873528" checked=""/><div class="controls bullet"><span class="by">Voloskaya</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42873203">parent</a><span>|</span><a href="#42869076">next</a><span>|</span><label class="collapse" for="c-42873528">[-]</label><label class="expand" for="c-42873528">[1 more]</label></div><br/><div class="children"><div class="content">Key point from your linked paper:<p>&gt; We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models<p>No one is training on indiscriminate synthetic data. It&#x27;s very much discriminated, but still synthetic.</div><br/></div></div></div></div></div></div></div></div><div id="42875516" class="c"><input type="checkbox" id="c-42875516" checked=""/><div class="controls bullet"><span class="by">jjallen</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42868817">prev</a><span>|</span><a href="#42868786">next</a><span>|</span><label class="collapse" for="c-42875516">[-]</label><label class="expand" for="c-42875516">[1 more]</label></div><br/><div class="children"><div class="content">That may be true. But an even more interesting point may be that you don’t have to train a huge model ever again? Or at least not to train a new slightly improved model because now we have open weights of an excellent large model and a way to train smaller ones.</div><br/></div></div><div id="42868786" class="c"><input type="checkbox" id="c-42868786" checked=""/><div class="controls bullet"><span class="by">jondwillis</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42875516">prev</a><span>|</span><a href="#42869320">next</a><span>|</span><label class="collapse" for="c-42868786">[-]</label><label class="expand" for="c-42868786">[1 more]</label></div><br/><div class="children"><div class="content">But it does mean moat is even less defensible for companies whose fortunes are tied to their foundation models having some performance edge, and a shift in the kinds of hardware used for inference (smaller, closer to the edge.)</div><br/></div></div><div id="42869320" class="c"><input type="checkbox" id="c-42869320" checked=""/><div class="controls bullet"><span class="by">bangaladore</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42868786">prev</a><span>|</span><a href="#42869043">next</a><span>|</span><label class="collapse" for="c-42869320">[-]</label><label class="expand" for="c-42869320">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s only true if you assume that O1 synthetic data sets are much better than any other (comparably sized) opensource model.<p>It&#x27;s not apparently obvious to me that that is the case.<p>Ie. do you need a SOTA model to produce a new SOTA model?</div><br/></div></div><div id="42869043" class="c"><input type="checkbox" id="c-42869043" checked=""/><div class="controls bullet"><span class="by">philistine</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42869320">prev</a><span>|</span><a href="#42869614">next</a><span>|</span><label class="collapse" for="c-42869043">[-]</label><label class="expand" for="c-42869043">[1 more]</label></div><br/><div class="children"><div class="content">There’s a question of scale here: was it trained on 1000 outputs or 5 million?</div><br/></div></div><div id="42869614" class="c"><input type="checkbox" id="c-42869614" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42869043">prev</a><span>|</span><a href="#42869147">next</a><span>|</span><label class="collapse" for="c-42869614">[-]</label><label class="expand" for="c-42869614">[4 more]</label></div><br/><div class="children"><div class="content"><i>If Deepseek trained off OpenAI, then it wasn&#x27;t trained from scratch for &quot;pennies on the dollar&quot;</i><p>If OpenAI trained on the intellectual property of others, maybe it wasn&#x27;t the creativity breakthrough people claim?<p>Oppositely<p>If you say ChatGPT was trained on &quot;whatever data was available&quot;, and you say Deepseek was trained  &quot;whatever data was available&quot;, then they sound pretty equivalent.<p>All the rough consensus language output of humanity is now roughly on the Internet. The various LLMs have roughly distilled that and the results are naturally going to be tighter and tighter. It&#x27;s not surprising that companies are going to get better and better at solving the same problem. The situation of DeepSeek isn&#x27;t so much that promises future achievements but that it shows that OpenAI&#x27;s string of announcements are incremental progress that aren&#x27;t going to be reaching the AGI that Altman now often harps on.</div><br/><div id="42871521" class="c"><input type="checkbox" id="c-42871521" checked=""/><div class="controls bullet"><span class="by">el_cujo</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42869614">parent</a><span>|</span><a href="#42869147">next</a><span>|</span><label class="collapse" for="c-42871521">[-]</label><label class="expand" for="c-42871521">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not an OpenAI apologist and don&#x27;t like what they&#x27;ve done with other people&#x27;s intellectual property but I think that&#x27;s kind of a false equivalency. OpenAI&#x27;s GPT 3.5&#x2F;4 was a big leap forward in the technology in terms of functionality. DeepSeek-r1 isn&#x27;t really a huge step forward in output, it&#x27;s mostly comparable to existing models, one thing that is really cool about it is it being able to be trained from scratch quickly and cheaply. This is completely undercut if it was trained off of OpenAI&#x27;s data. I don&#x27;t care about adjudicating which one is a bigger thief, but it&#x27;s notable if one of the biggest breakthroughs about DeepSeek-r1 is pretty much a lie. And it&#x27;s still really cool that it&#x27;s open source and can be run locally, it&#x27;ll have that over OpenAI whether or not the training claims are a lie&#x2F;misleading</div><br/><div id="42871645" class="c"><input type="checkbox" id="c-42871645" checked=""/><div class="controls bullet"><span class="by">pertymcpert</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42871521">parent</a><span>|</span><a href="#42873377">next</a><span>|</span><label class="collapse" for="c-42871645">[-]</label><label class="expand" for="c-42871645">[1 more]</label></div><br/><div class="children"><div class="content">Not just the training cost, the inference cost is a fraction of o1.</div><br/></div></div><div id="42873377" class="c"><input type="checkbox" id="c-42873377" checked=""/><div class="controls bullet"><span class="by">buzzerbetrayed</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42871521">parent</a><span>|</span><a href="#42871645">prev</a><span>|</span><a href="#42869147">next</a><span>|</span><label class="collapse" for="c-42873377">[-]</label><label class="expand" for="c-42873377">[1 more]</label></div><br/><div class="children"><div class="content">How is it a “lie” for DeepSeek to train their data from ChatGPT but not if they train their data from all of Twitter and Reddit? Either way the training is 100x cheaper.</div><br/></div></div></div></div></div></div><div id="42868841" class="c"><input type="checkbox" id="c-42868841" checked=""/><div class="controls bullet"><span class="by">fumeux_fume</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42869147">prev</a><span>|</span><a href="#42870271">next</a><span>|</span><label class="collapse" for="c-42868841">[-]</label><label class="expand" for="c-42868841">[2 more]</label></div><br/><div class="children"><div class="content">This has been in the back of my head since the news broke. Has anyone built their own R1 from scratch and validated it?</div><br/><div id="42869713" class="c"><input type="checkbox" id="c-42869713" checked=""/><div class="controls bullet"><span class="by">RevEng</span><span>|</span><a href="#42868651">root</a><span>|</span><a href="#42868841">parent</a><span>|</span><a href="#42870271">next</a><span>|</span><label class="collapse" for="c-42869713">[-]</label><label class="expand" for="c-42869713">[1 more]</label></div><br/><div class="children"><div class="content">In the last few days? No, that would be impossible; no one has the resources to train a base model that quickly. But there are definitely a lot of people working on it.</div><br/></div></div></div></div><div id="42870271" class="c"><input type="checkbox" id="c-42870271" checked=""/><div class="controls bullet"><span class="by">FooBarWidget</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42868841">prev</a><span>|</span><a href="#42872653">next</a><span>|</span><label class="collapse" for="c-42870271">[-]</label><label class="expand" for="c-42870271">[1 more]</label></div><br/><div class="children"><div class="content">Have people on HN never heard of public ChatGPT conversations data sets? They&#x27;ve been mentioned multiple times in past HN conversations and I thought it&#x27;d be common knowledge here by now. Pretty much all open source models have been training on them for the past 2 years, it&#x27;s common practice by now. And haven&#x27;t people been having conversations about &quot;synthetic data&quot; for a pretty long time by now? Why is all of this suddenly an issue in the context of DeepSeek? Nobody made a fuss about this before.<p>And just because a model trains on <i>some</i> ChatGPT data, doesn&#x27;t mean that that data is the majority. It&#x27;s just another dataset.</div><br/></div></div><div id="42872653" class="c"><input type="checkbox" id="c-42872653" checked=""/><div class="controls bullet"><span class="by">ohhhhhhhhhk</span><span>|</span><a href="#42868651">parent</a><span>|</span><a href="#42870271">prev</a><span>|</span><a href="#42866118">next</a><span>|</span><label class="collapse" for="c-42872653">[-]</label><label class="expand" for="c-42872653">[1 more]</label></div><br/><div class="children"><div class="content">Funny how the first principles people now want to claim the opposite of what they’ve been crowing about for decades since techbros climbed their way out of their billion dollar one hit wonders. Boo fucking hoo.</div><br/></div></div></div></div><div id="42866118" class="c"><input type="checkbox" id="c-42866118" checked=""/><div class="controls bullet"><span class="by">ok123456</span><span>|</span><a href="#42868651">prev</a><span>|</span><a href="#42866806">next</a><span>|</span><label class="collapse" for="c-42866118">[-]</label><label class="expand" for="c-42866118">[5 more]</label></div><br/><div class="children"><div class="content">OpenAI&#x27;s models were trained on ebooks from a private ebook torrent tracker leeched en-mass during a free leech event by people who hated private torrent trackers and wanted to destroy their &quot;economy.&quot;<p>The books were all in epub format, converted, cleaned to plain text, and hosted on a public data hoarder site.</div><br/><div id="42873290" class="c"><input type="checkbox" id="c-42873290" checked=""/><div class="controls bullet"><span class="by">harry8</span><span>|</span><a href="#42866118">parent</a><span>|</span><a href="#42866806">next</a><span>|</span><label class="collapse" for="c-42873290">[-]</label><label class="expand" for="c-42873290">[4 more]</label></div><br/><div class="children"><div class="content">Have you got some support for this claim?<p>There&#x27;s a lot of wild claims about, so while this is plausible it would be great if there were some evidence backing it.</div><br/><div id="42876040" class="c"><input type="checkbox" id="c-42876040" checked=""/><div class="controls bullet"><span class="by">OsrsNeedsf2P</span><span>|</span><a href="#42866118">root</a><span>|</span><a href="#42873290">parent</a><span>|</span><a href="#42873383">next</a><span>|</span><label class="collapse" for="c-42876040">[-]</label><label class="expand" for="c-42876040">[1 more]</label></div><br/><div class="children"><div class="content">He could be confusing it with Llama: <a href="https:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;new-documents-unredacted-meta-copyright-ai-lawsuit&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;new-documents-unredacted-meta-co...</a></div><br/></div></div><div id="42873383" class="c"><input type="checkbox" id="c-42873383" checked=""/><div class="controls bullet"><span class="by">naet</span><span>|</span><a href="#42866118">root</a><span>|</span><a href="#42873290">parent</a><span>|</span><a href="#42876040">prev</a><span>|</span><a href="#42866806">next</a><span>|</span><label class="collapse" for="c-42873383">[-]</label><label class="expand" for="c-42873383">[2 more]</label></div><br/><div class="children"><div class="content">NYT claims that OpenAI trained on their material.  They argue for copyright violation, although I think another argument might be breach of TOS in scraping the material from their website or archive.<p>The complaint filing has some references to some of the other training material used by OpenAI, but I didn&#x27;t dig deeply in to what all of it was:<p><a href="https:&#x2F;&#x2F;nytco-assets.nytimes.com&#x2F;2023&#x2F;12&#x2F;NYT_Complaint_Dec2023.pdf" rel="nofollow">https:&#x2F;&#x2F;nytco-assets.nytimes.com&#x2F;2023&#x2F;12&#x2F;NYT_Complaint_Dec20...</a></div><br/><div id="42873453" class="c"><input type="checkbox" id="c-42873453" checked=""/><div class="controls bullet"><span class="by">throwaway314155</span><span>|</span><a href="#42866118">root</a><span>|</span><a href="#42873383">parent</a><span>|</span><a href="#42866806">next</a><span>|</span><label class="collapse" for="c-42873453">[-]</label><label class="expand" for="c-42873453">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s that got to do with this books claim?</div><br/></div></div></div></div></div></div></div></div><div id="42866806" class="c"><input type="checkbox" id="c-42866806" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#42866118">prev</a><span>|</span><a href="#42866480">next</a><span>|</span><label class="collapse" for="c-42866806">[-]</label><label class="expand" for="c-42866806">[29 more]</label></div><br/><div class="children"><div class="content">All the top level comments are basking in the irony of it, which is fair enough. But I think this changes the Deepseek narrative a bit. If they just benefited from repurposing OpenAI data, that&#x27;s different than having achieved an engineering breakthrough, which may suggest OpenAI&#x27;s results were hard earned after all.</div><br/><div id="42868421" class="c"><input type="checkbox" id="c-42868421" checked=""/><div class="controls bullet"><span class="by">tasuki</span><span>|</span><a href="#42866806">parent</a><span>|</span><a href="#42870093">next</a><span>|</span><label class="collapse" for="c-42868421">[-]</label><label class="expand" for="c-42868421">[8 more]</label></div><br/><div class="children"><div class="content">I understand they just used the API to talk to the OpenAI models. That... seems pretty innocent? Probably they even paid for it? OpenAI is selling API access, someone decided to buy it. Good for OpenAI!<p>I understand ToS violations can lead to a ban. OpenAI is free to ban DeepSeek from using their APIs.</div><br/><div id="42870425" class="c"><input type="checkbox" id="c-42870425" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42868421">parent</a><span>|</span><a href="#42868963">next</a><span>|</span><label class="collapse" for="c-42870425">[-]</label><label class="expand" for="c-42870425">[5 more]</label></div><br/><div class="children"><div class="content">Sure, but I&#x27;m not interested in innocence. They can be as innocent or guilty as they want. But it means they didn&#x27;t, via engineering wherewithal, reproduce the OpenAI capabilities from scratch. And originally that was supposed to be one of the stunning and impressive (if true) implications of the whole Deepseek news cycle.</div><br/><div id="42871591" class="c"><input type="checkbox" id="c-42871591" checked=""/><div class="controls bullet"><span class="by">tasuki</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42870425">parent</a><span>|</span><a href="#42875757">next</a><span>|</span><label class="collapse" for="c-42871591">[-]</label><label class="expand" for="c-42871591">[2 more]</label></div><br/><div class="children"><div class="content">Nothing is <i>ever</i> done &quot;from scratch&quot;. To create a sandwich, you first have to create the universe.<p>Yes, there is the question how much ChatGPT data DeepSeek has ingested. Certainly not zero! But if DeepSeek has achieved iterative self-improvement, that&#x27;d be huge too!</div><br/><div id="42873105" class="c"><input type="checkbox" id="c-42873105" checked=""/><div class="controls bullet"><span class="by">danparsonson</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42871591">parent</a><span>|</span><a href="#42875757">next</a><span>|</span><label class="collapse" for="c-42873105">[-]</label><label class="expand" for="c-42873105">[1 more]</label></div><br/><div class="children"><div class="content">&quot;From scratch&quot; has a specific definition here though - it means &#x27;from the same or broadly the same corpus of data that OpenAI started with&#x27;. The implication was that DeepSeek had created something broadly equivalent to ChatGPT on their own and for much less cost; deriving it from an existing model is a different claim. It&#x27;s a little like claiming you invented a car when actually you took an existing car and tuned and remodelled it - the end result may be impressive and useful and better than the original, but it&#x27;s not really a new invention.</div><br/></div></div></div></div><div id="42875757" class="c"><input type="checkbox" id="c-42875757" checked=""/><div class="controls bullet"><span class="by">tw1984</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42870425">parent</a><span>|</span><a href="#42871591">prev</a><span>|</span><a href="#42871530">next</a><span>|</span><label class="collapse" for="c-42875757">[-]</label><label class="expand" for="c-42875757">[1 more]</label></div><br/><div class="children"><div class="content">&gt; reproduce the OpenAI capabilities from scratch<p>who cares. even if the claim is true, does that make the open source model less attractive?<p>in fact, it implies that there is no moat in this game. openai can no longer maintain its stupid valuation, as other companies can just scrape its output and build better models at much lower costs.<p>everything points to the exact same end result - DeepSeek democratized AI, OpenAI&#x27;s old business model is dead.</div><br/></div></div><div id="42871530" class="c"><input type="checkbox" id="c-42871530" checked=""/><div class="controls bullet"><span class="by">freehorse</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42870425">parent</a><span>|</span><a href="#42875757">prev</a><span>|</span><a href="#42868963">next</a><span>|</span><label class="collapse" for="c-42871530">[-]</label><label class="expand" for="c-42871530">[1 more]</label></div><br/><div class="children"><div class="content">It is not as if they are not open about how they did it. People are actually working on reproducing their results as they describe in the papers. Somebody has already reproduced the r1-zero rl training process on a smaller model (linked in some comment here).<p>Even if o1 specifically was used (which is in itself doubtful), it does not mean that this was the main reason that r1 succeeded&#x2F;it could not have happened without it. The o1 outputs hides the CoT part, which is the most important here. Also we are in 2025, scratch does not exist anymore. Creating better technology building upon previous (widely available) technology has never been a controversial issue.</div><br/></div></div></div></div><div id="42868963" class="c"><input type="checkbox" id="c-42868963" checked=""/><div class="controls bullet"><span class="by">Mengkudulangsat</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42868421">parent</a><span>|</span><a href="#42870425">prev</a><span>|</span><a href="#42870577">next</a><span>|</span><label class="collapse" for="c-42868963">[-]</label><label class="expand" for="c-42868963">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s how I understand it too.<p>If your own API can leak your secret sauce without any malicious penetration, well, that&#x27;s on you.</div><br/></div></div><div id="42870577" class="c"><input type="checkbox" id="c-42870577" checked=""/><div class="controls bullet"><span class="by">rubslopes</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42868421">parent</a><span>|</span><a href="#42868963">prev</a><span>|</span><a href="#42870093">next</a><span>|</span><label class="collapse" for="c-42870577">[-]</label><label class="expand" for="c-42870577">[1 more]</label></div><br/><div class="children"><div class="content">Additionally, I was under the impression that all those Chinese models were being trained using data from OpenAI and Anthropic. Were there not some reports that Qwen models referred to themselves as Claude?</div><br/></div></div></div></div><div id="42870093" class="c"><input type="checkbox" id="c-42870093" checked=""/><div class="controls bullet"><span class="by">JTyQZSnP3cQGa8B</span><span>|</span><a href="#42866806">parent</a><span>|</span><a href="#42868421">prev</a><span>|</span><a href="#42868480">next</a><span>|</span><label class="collapse" for="c-42870093">[-]</label><label class="expand" for="c-42870093">[4 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI&#x27;s results were hard earned after all<p>DDOSing web sites and grabbing content without anyone&#x27;s consent is not hard earned at all. They did spent billions on their thing, but nothing was earned as they could never do that legally.</div><br/><div id="42870500" class="c"><input type="checkbox" id="c-42870500" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42870093">parent</a><span>|</span><a href="#42870358">next</a><span>|</span><label class="collapse" for="c-42870500">[-]</label><label class="expand" for="c-42870500">[2 more]</label></div><br/><div class="children"><div class="content">I understand the temptation to go there, but I think it misses the point. I have no qualms at all with the idea that the sum total of intelligence distributed across the internet was siphoned away from creators and piped through an engine that now cynically seeks to replace them. Believe me, I will grab my pitchfork and march side by side with you.<p>But let&#x27;s keep the eye on the ball for a second. None of that changes the fact that what <i>was</i> built was a capability to reflect that knowledge in dynamic and deep ways in conversation, as well as image and audio recognition.<p>And did Deepseek also build that? From scratch? Because they might not have.</div><br/><div id="42874040" class="c"><input type="checkbox" id="c-42874040" checked=""/><div class="controls bullet"><span class="by">rakejake</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42870500">parent</a><span>|</span><a href="#42870358">next</a><span>|</span><label class="collapse" for="c-42874040">[-]</label><label class="expand" for="c-42874040">[1 more]</label></div><br/><div class="children"><div class="content">Look at it this way. Even OpenAI uses their own models&#x27; output to train subsequent models. They do pay for a lot of manual annotations but also use a lot of machine generated data because it is cheaper and good enough, especially from the bigger models.<p>So say DS had simply published a paper outlining the RL technique they used, and one of Meta, Google or even OpenAI themselves had used it to train a new model, don&#x27;t you think they&#x27;d have shouted off the rooftops about a new breakthrough? The fact that the provenance of the data is from a rival&#x27;s model does not negate the value of the research IMHO.</div><br/></div></div></div></div><div id="42870358" class="c"><input type="checkbox" id="c-42870358" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42870093">parent</a><span>|</span><a href="#42870500">prev</a><span>|</span><a href="#42868480">next</a><span>|</span><label class="collapse" for="c-42870358">[-]</label><label class="expand" for="c-42870358">[1 more]</label></div><br/><div class="children"><div class="content">More like hard bought and hard stolen.</div><br/></div></div></div></div><div id="42868480" class="c"><input type="checkbox" id="c-42868480" checked=""/><div class="controls bullet"><span class="by">the_duke</span><span>|</span><a href="#42866806">parent</a><span>|</span><a href="#42870093">prev</a><span>|</span><a href="#42873431">next</a><span>|</span><label class="collapse" for="c-42868480">[-]</label><label class="expand" for="c-42868480">[3 more]</label></div><br/><div class="children"><div class="content">These aren&#x27;t mutually exclusive.<p>It&#x27;s been known for a while that competitors used OpenAI to improve their models, that&#x27;s why they changed the TOS to forbid it.<p>That doesn&#x27;t mean the deep seek technical achievements are less valid.</div><br/><div id="42870744" class="c"><input type="checkbox" id="c-42870744" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42868480">parent</a><span>|</span><a href="#42873431">next</a><span>|</span><label class="collapse" for="c-42870744">[-]</label><label class="expand" for="c-42870744">[2 more]</label></div><br/><div class="children"><div class="content">&gt;That doesn&#x27;t mean the deep seek technical achievements are less valid.<p>Well, that&#x27;s literally exactly what it would mean. If DeepSeek relied on OpenAI’s API, their main achievement is in efficiency and cost reduction as opposed to fundamental AI breakthroughs.</div><br/><div id="42872110" class="c"><input type="checkbox" id="c-42872110" checked=""/><div class="controls bullet"><span class="by">obmelvin</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42870744">parent</a><span>|</span><a href="#42873431">next</a><span>|</span><label class="collapse" for="c-42872110">[-]</label><label class="expand" for="c-42872110">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. They accomplished a lot with distillation and optimization - but there&#x27;s little reason to believe you don&#x27;t also need foundational models to keep advancing. Otherwise won&#x27;t they run into issues training on more synthetic data?<p>In a way this is something most companies have been doing with their smaller models, DeepSeek just supposedly* did it better.</div><br/></div></div></div></div></div></div><div id="42873431" class="c"><input type="checkbox" id="c-42873431" checked=""/><div class="controls bullet"><span class="by">soerxpso</span><span>|</span><a href="#42866806">parent</a><span>|</span><a href="#42868480">prev</a><span>|</span><a href="#42869266">next</a><span>|</span><label class="collapse" for="c-42873431">[-]</label><label class="expand" for="c-42873431">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If they just benefited from repurposing OpenAI data, that&#x27;s different than having achieved an engineering breakthrough<p>One way or another, they were able to create something that has WAY cheaper inference costs than o1 at the same level of intelligence. I was paying Anthropic $15&#x2F;1M tokens to make myself 10x faster at writing software, which was coming out to $10&#x2F;day. O1 is $60&#x2F;1M tokens, which for my level of usage would mean that it costs as much as a whole junior software engineer. DeepSeek is able to do it for $2.50&#x2F;1M tokens.<p>Either OpenAI was taking a profit margin that would make the US Healthcare industry weep, or DeepSeek made an engineering breakthrough that increases inference efficiency by orders of magnitude.</div><br/></div></div><div id="42869266" class="c"><input type="checkbox" id="c-42869266" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#42866806">parent</a><span>|</span><a href="#42873431">prev</a><span>|</span><a href="#42868324">next</a><span>|</span><label class="collapse" for="c-42869266">[-]</label><label class="expand" for="c-42869266">[5 more]</label></div><br/><div class="children"><div class="content">I really don&#x27;t see a correlation here to be honest.<p>Eventually all future AIs will be produced with synthetic input, the amount of (quality) data we humans can produce is quite limited.<p>The fact that the input of one AI has been used in the training of another one seems irrelevant.</div><br/><div id="42870807" class="c"><input type="checkbox" id="c-42870807" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42869266">parent</a><span>|</span><a href="#42868324">next</a><span>|</span><label class="collapse" for="c-42870807">[-]</label><label class="expand" for="c-42870807">[4 more]</label></div><br/><div class="children"><div class="content">The issue isn’t just that AI trained on AI is inevitable it&#x27;s <i>whose</i> AI is being used as the base layer. Right now, OpenAI’s models are at the top of that hierarchy. If Deepseek depended on them, it means OpenAI is still the upstream bottleneck, not easily replaced.<p>The deeper question is whether Deepseek has achieved real autonomy or if it’s just a derivative work. If the latter, then OpenAI still holds the keys to future advances. If Deepseek truly found a way to be independent while achieving similar performance, then OpenAI has a problem.<p>The details of how they trained matter more than the inevitability of synthetic data down the line.</div><br/><div id="42871058" class="c"><input type="checkbox" id="c-42871058" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42870807">parent</a><span>|</span><a href="#42868324">next</a><span>|</span><label class="collapse" for="c-42871058">[-]</label><label class="expand" for="c-42871058">[3 more]</label></div><br/><div class="children"><div class="content">&gt; then OpenAI still holds the keys to future advances<p>Point is, those future advances are worthless. Eventually anybody will be able to feed each other&#x27;s data for the training.<p>There&#x27;s no moat here. LLMs are commodities.</div><br/><div id="42871166" class="c"><input type="checkbox" id="c-42871166" checked=""/><div class="controls bullet"><span class="by">glenstein</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42871058">parent</a><span>|</span><a href="#42868324">next</a><span>|</span><label class="collapse" for="c-42871166">[-]</label><label class="expand" for="c-42871166">[2 more]</label></div><br/><div class="children"><div class="content">If LLMs were already pure commodities, OpenAI wouldn&#x27;t be able to charge a premium, and DeepSeek wouldn’t have needed to distill their model from OpenAI in the first place. The fact that they did proves there’s still a moat—just maybe not as wide as OpenAI hoped.</div><br/></div></div></div></div></div></div></div></div><div id="42868324" class="c"><input type="checkbox" id="c-42868324" checked=""/><div class="controls bullet"><span class="by">plantwallshoe</span><span>|</span><a href="#42866806">parent</a><span>|</span><a href="#42869266">prev</a><span>|</span><a href="#42868099">next</a><span>|</span><label class="collapse" for="c-42868324">[-]</label><label class="expand" for="c-42868324">[3 more]</label></div><br/><div class="children"><div class="content">Yeah what happens when we remove all financial incentive to fund groundbreaking science?<p>It’s the same problem with pharmaceuticals and generics. It’s great when the price of drugs is low, but without perverse financial incentives no company is going to burn billions of dollars in a risky search for new medicines.</div><br/><div id="42869213" class="c"><input type="checkbox" id="c-42869213" checked=""/><div class="controls bullet"><span class="by">amarcheschi</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42868324">parent</a><span>|</span><a href="#42870025">next</a><span>|</span><label class="collapse" for="c-42869213">[-]</label><label class="expand" for="c-42869213">[1 more]</label></div><br/><div class="children"><div class="content">In this case, these cures (llms) are medicines in search for a disease to cure. I got Ai shoved everywhere, where I just want it to aid in my coding. Literally, that&#x27;s it. They&#x27;re also good at summarizing emails and similar things, but I know nobody who does that. I wouldn&#x27;t trust an Ai reading and possibly hallucinate emails</div><br/></div></div><div id="42870025" class="c"><input type="checkbox" id="c-42870025" checked=""/><div class="controls bullet"><span class="by">jjcob</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42868324">parent</a><span>|</span><a href="#42869213">prev</a><span>|</span><a href="#42868099">next</a><span>|</span><label class="collapse" for="c-42870025">[-]</label><label class="expand" for="c-42870025">[1 more]</label></div><br/><div class="children"><div class="content">Then we just have to fund research by giving grants to universities and research teams. Oh wait a sec: That&#x27;s already what pretty much every government in the world is doing anyway!</div><br/></div></div></div></div><div id="42868099" class="c"><input type="checkbox" id="c-42868099" checked=""/><div class="controls bullet"><span class="by">nprateem</span><span>|</span><a href="#42866806">parent</a><span>|</span><a href="#42868324">prev</a><span>|</span><a href="#42866480">next</a><span>|</span><label class="collapse" for="c-42868099">[-]</label><label class="expand" for="c-42868099">[4 more]</label></div><br/><div class="children"><div class="content">Of course. How else would Americans justify their superiority (and therefore valuations) if a load of <i>foreigners</i> for Christ&#x27;s sake could just out innovate them?<p>They <i>had</i> to be cheating.</div><br/><div id="42869034" class="c"><input type="checkbox" id="c-42869034" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42868099">parent</a><span>|</span><a href="#42866480">next</a><span>|</span><label class="collapse" for="c-42869034">[-]</label><label class="expand" for="c-42869034">[3 more]</label></div><br/><div class="children"><div class="content">Please don&#x27;t take HN threads into nationalistic flamewar. It&#x27;s not what this site is for, and destroys what it is for.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a><p>p.s. yes, that goes both ways - that is, if people are slamming a different country from an opposite direction, we say the same thing (provided we see the post in the first place)</div><br/><div id="42869440" class="c"><input type="checkbox" id="c-42869440" checked=""/><div class="controls bullet"><span class="by">LPisGood</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42869034">parent</a><span>|</span><a href="#42866480">next</a><span>|</span><label class="collapse" for="c-42869440">[-]</label><label class="expand" for="c-42869440">[2 more]</label></div><br/><div class="children"><div class="content">I see where you’re coming from but that comment didn’t strike me as particularly inflammatory.</div><br/><div id="42870346" class="c"><input type="checkbox" id="c-42870346" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42866806">root</a><span>|</span><a href="#42869440">parent</a><span>|</span><a href="#42866480">next</a><span>|</span><label class="collapse" for="c-42870346">[-]</label><label class="expand" for="c-42870346">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m likely more sensitive to the fire potential on account of being conditioned by the job.<p>Part of it is the form of the comment, btw - that one was entirely a sequence of indignation tropes.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42866480" class="c"><input type="checkbox" id="c-42866480" checked=""/><div class="controls bullet"><span class="by">daft_pink</span><span>|</span><a href="#42866806">prev</a><span>|</span><a href="#42876115">next</a><span>|</span><label class="collapse" for="c-42866480">[-]</label><label class="expand" for="c-42866480">[34 more]</label></div><br/><div class="children"><div class="content">This reminds me of the railroads, where once railroads were invented, there was a huge investment boom of eveyrone trying to make money of the railroads, but the competition brought the costs down where the railroads weren’t the people who generally made the money and got the benefit, but the consumers and regular businesses did and competition caused many to fail.<p>AI is probably similar where the Moore’s law and advancement will eventually allow people to run open models locally and bring down the cost of operation.  Competiition will make it hard for all but one or two players to survive and Nvidia, OpenAI, Deepseek, etc most investments in AI by these large companies will fail to generate substantial wealth but maybe earn some sort of return or maybe not.</div><br/><div id="42867065" class="c"><input type="checkbox" id="c-42867065" checked=""/><div class="controls bullet"><span class="by">floatrock</span><span>|</span><a href="#42866480">parent</a><span>|</span><a href="#42869274">next</a><span>|</span><label class="collapse" for="c-42867065">[-]</label><label class="expand" for="c-42867065">[19 more]</label></div><br/><div class="children"><div class="content">The railroads drama ended when JP Morgan (the person, not yet the entity) brought all the railroad bosses together, said &quot;you all answer to me because I represent your investors &#x2F; shareholders&quot;, and forced a wave of consolidation and syndicates because competition was bad for business.<p>Then all the farmers in the midwest went broke not because they couldn&#x27;t get their goods to market, but because JP Morgan&#x27;s consolidated syndicates ate all their margin hauling their goods to market.<p>Consolidation and monopoly over your competition is always the end goal.</div><br/><div id="42868303" class="c"><input type="checkbox" id="c-42868303" checked=""/><div class="controls bullet"><span class="by">DrScientist</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867065">parent</a><span>|</span><a href="#42873041">next</a><span>|</span><label class="collapse" for="c-42868303">[-]</label><label class="expand" for="c-42868303">[13 more]</label></div><br/><div class="children"><div class="content">&gt; Consolidation and monopoly over your competition is always the end goal.<p>Surely that&#x27;s only possible when you have a large barrier to entry?<p>What&#x27;s going to be that barrier in this case - cos it turns out not to be neither training costs&#x2F;hardware or secret expertise.</div><br/><div id="42870151" class="c"><input type="checkbox" id="c-42870151" checked=""/><div class="controls bullet"><span class="by">_DeadFred_</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42868303">parent</a><span>|</span><a href="#42869136">next</a><span>|</span><label class="collapse" for="c-42870151">[-]</label><label class="expand" for="c-42870151">[3 more]</label></div><br/><div class="children"><div class="content">Government regulation.<p>&#x27;Can&#x27;t have your data going to China&#x27;<p>&#x27;Can&#x27;t allow companies that do censorship aligned with foreign nations&#x27;<p>&#x27;This company violated our laws and used an American company&#x27;s tech for their training unfairly&#x27;<p>And the government choosing winners.<p>&#x27;The government in announcing 500 billion going to these chosen winners, anyone else take the hint, give up, you won&#x27;t get government contracts but will get pressure&#x27;.<p>Good thing nobody is making these sorts of arguments today.</div><br/><div id="42870670" class="c"><input type="checkbox" id="c-42870670" checked=""/><div class="controls bullet"><span class="by">astrange</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42870151">parent</a><span>|</span><a href="#42869136">next</a><span>|</span><label class="collapse" for="c-42870670">[-]</label><label class="expand" for="c-42870670">[2 more]</label></div><br/><div class="children"><div class="content">The government isn&#x27;t giving 500 billion to anyone. They just let Trump announce a private deal he has no involvement.</div><br/><div id="42872982" class="c"><input type="checkbox" id="c-42872982" checked=""/><div class="controls bullet"><span class="by">_DeadFred_</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42870670">parent</a><span>|</span><a href="#42869136">next</a><span>|</span><label class="collapse" for="c-42872982">[-]</label><label class="expand" for="c-42872982">[1 more]</label></div><br/><div class="children"><div class="content">Correct, as I stated the government is just giving their &#x27;blessing&#x27;.</div><br/></div></div></div></div></div></div><div id="42869136" class="c"><input type="checkbox" id="c-42869136" checked=""/><div class="controls bullet"><span class="by">floatrock</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42868303">parent</a><span>|</span><a href="#42870151">prev</a><span>|</span><a href="#42869106">next</a><span>|</span><label class="collapse" for="c-42869136">[-]</label><label class="expand" for="c-42869136">[4 more]</label></div><br/><div class="children"><div class="content">You figure that out and the VC&#x27;s will be shovelling money into your face.<p>I suspect the &quot;it ain&#x27;t training costs&#x2F;hardware&quot; bit is a bit exagerated since it ignores all the prior work that DeepSeek was built on top of.<p>But, if all else fails, there&#x27;s always the tried-and-true approaches: regulatory capture, industry entrenchment, use your VC bucks to be the last one who can wait out the costs the incumbents <i>do</i> face before they fold, etc.</div><br/><div id="42869641" class="c"><input type="checkbox" id="c-42869641" checked=""/><div class="controls bullet"><span class="by">jaredklewis</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42869136">parent</a><span>|</span><a href="#42869106">next</a><span>|</span><label class="collapse" for="c-42869641">[-]</label><label class="expand" for="c-42869641">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I suspect the &quot;it ain&#x27;t training costs&#x2F;hardware&quot; bit is a bit exagerated since it ignores all the prior work that DeepSeek was built on top of.<p>How does it ignore it? The success of Deepseek proves that training costs&#x2F;hardware are definitely NOT a barrier to entry that protects OpenAI from competition. If anyone can train their model with ChatGPT for a fraction of the cost it took to train ChatGPT and get similar results, then how is that a barrier?</div><br/><div id="42871087" class="c"><input type="checkbox" id="c-42871087" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42869641">parent</a><span>|</span><a href="#42869106">next</a><span>|</span><label class="collapse" for="c-42871087">[-]</label><label class="expand" for="c-42871087">[2 more]</label></div><br/><div class="children"><div class="content">Can <i>anyone</i> do that though? You need the tokens and the pipelines to feed them to the matmul mincers. Quoting only dollar equivalent of GPU time is disingenuous at best.<p>That’s not to say they lie about everything, obviously the thing works amazingly well. The cost is understated by 10x or more, which is still not bad at all I guess? But not mind blowing.</div><br/><div id="42875863" class="c"><input type="checkbox" id="c-42875863" checked=""/><div class="controls bullet"><span class="by">maigret</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42871087">parent</a><span>|</span><a href="#42869106">next</a><span>|</span><label class="collapse" for="c-42875863">[-]</label><label class="expand" for="c-42875863">[1 more]</label></div><br/><div class="children"><div class="content">Even if that&#x27;s 10x, that&#x27;s easy to counter. $50M can be invested by almost anyone. There are thousands of entities (incl. governments, even regional ones) who could easily bring such capital.</div><br/></div></div></div></div></div></div></div></div><div id="42869106" class="c"><input type="checkbox" id="c-42869106" checked=""/><div class="controls bullet"><span class="by">tdb7893</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42868303">parent</a><span>|</span><a href="#42869136">prev</a><span>|</span><a href="#42869284">next</a><span>|</span><label class="collapse" for="c-42869106">[-]</label><label class="expand" for="c-42869106">[3 more]</label></div><br/><div class="children"><div class="content">So I&#x27;m not an expert in this but even with DeepSeek supposedly reducing training costs isn&#x27;t the estimate still in the millions (and that&#x27;s presumably not counting a lot of costs)? And that wouldn&#x27;t be counting a bunch of other barriers for actually building the business since training a model is only one part, the barrier to entry still seems very high.<p>Also barriers to entry aren&#x27;t the only way to get a consolidated market anyway.</div><br/><div id="42869493" class="c"><input type="checkbox" id="c-42869493" checked=""/><div class="controls bullet"><span class="by">layer8</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42869106">parent</a><span>|</span><a href="#42869284">next</a><span>|</span><label class="collapse" for="c-42869493">[-]</label><label class="expand" for="c-42869493">[2 more]</label></div><br/><div class="children"><div class="content">About your first point, IMO the usefulness of AI will remain relatively limited as long as we don’t have continuously learning AI. And once we have that, the disparity between training and inference may effectively disappear. Whether that means that such AI will become more accessible&#x2F;affordable or less is a different question.</div><br/><div id="42873054" class="c"><input type="checkbox" id="c-42873054" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42869493">parent</a><span>|</span><a href="#42869284">next</a><span>|</span><label class="collapse" for="c-42873054">[-]</label><label class="expand" for="c-42873054">[1 more]</label></div><br/><div class="children"><div class="content">We have that now, DeepSeek just proved it.</div><br/></div></div></div></div></div></div><div id="42869284" class="c"><input type="checkbox" id="c-42869284" checked=""/><div class="controls bullet"><span class="by">antisthenes</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42868303">parent</a><span>|</span><a href="#42869106">prev</a><span>|</span><a href="#42869059">next</a><span>|</span><label class="collapse" for="c-42869284">[-]</label><label class="expand" for="c-42869284">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Surely that&#x27;s only possible when you have a large barrier to entry?<p>As you grow bigger, you create barriers to entry where none existed before, whether intentionally or unintentionally.</div><br/></div></div><div id="42869059" class="c"><input type="checkbox" id="c-42869059" checked=""/><div class="controls bullet"><span class="by">yoyohello13</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42868303">parent</a><span>|</span><a href="#42869284">prev</a><span>|</span><a href="#42873041">next</a><span>|</span><label class="collapse" for="c-42869059">[-]</label><label class="expand" for="c-42869059">[1 more]</label></div><br/><div class="children"><div class="content">The large syndicate will create the barriers. Either via laws, or if that fails violence.</div><br/></div></div></div></div><div id="42873041" class="c"><input type="checkbox" id="c-42873041" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867065">parent</a><span>|</span><a href="#42868303">prev</a><span>|</span><a href="#42870668">next</a><span>|</span><label class="collapse" for="c-42873041">[-]</label><label class="expand" for="c-42873041">[1 more]</label></div><br/><div class="children"><div class="content">This is why we saw the market correction, because the AI hegemony has been cracked.</div><br/></div></div><div id="42870668" class="c"><input type="checkbox" id="c-42870668" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867065">parent</a><span>|</span><a href="#42873041">prev</a><span>|</span><a href="#42869081">next</a><span>|</span><label class="collapse" for="c-42870668">[-]</label><label class="expand" for="c-42870668">[1 more]</label></div><br/><div class="children"><div class="content">This moment was also historically significant because it demonstrated how financial power (Morgan) could control industrial power (the railroads).  A pattern that some say became increasingly important in American capitalism.</div><br/></div></div><div id="42869081" class="c"><input type="checkbox" id="c-42869081" checked=""/><div class="controls bullet"><span class="by">mrdevlar</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867065">parent</a><span>|</span><a href="#42870668">prev</a><span>|</span><a href="#42869598">next</a><span>|</span><label class="collapse" for="c-42869081">[-]</label><label class="expand" for="c-42869081">[2 more]</label></div><br/><div class="children"><div class="content">Which is the exact goal of the current wave of Tech oligarchy also.</div><br/></div></div><div id="42869598" class="c"><input type="checkbox" id="c-42869598" checked=""/><div class="controls bullet"><span class="by">jonstewart</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867065">parent</a><span>|</span><a href="#42869081">prev</a><span>|</span><a href="#42869274">next</a><span>|</span><label class="collapse" for="c-42869598">[-]</label><label class="expand" for="c-42869598">[1 more]</label></div><br/><div class="children"><div class="content">I just read _The Great River_ by Boyce Upholt, a history of the Mississippi river and human management thereof. It was funny how the railroads were used as a bogeyman to justify continued building of locks, dams, and other control structures on the Mississippi and its tributaries, long after shipping commodities down river had been supplanted by the railroads.</div><br/></div></div></div></div><div id="42869274" class="c"><input type="checkbox" id="c-42869274" checked=""/><div class="controls bullet"><span class="by">rgbrgb</span><span>|</span><a href="#42866480">parent</a><span>|</span><a href="#42867065">prev</a><span>|</span><a href="#42867020">next</a><span>|</span><label class="collapse" for="c-42869274">[-]</label><label class="expand" for="c-42869274">[1 more]</label></div><br/><div class="children"><div class="content">I think that&#x27;s a very possible outcome. A lot of people investing in AI are thinking there&#x27;s a google moment coming where one monopoly will reign supreme. Google has strong network effects around user data AND economies of scale. Right now, AI is 1-player with much weaker network effects. The user data moat goes away once the model trains itself effectively and the economies of scale advantage goes away with smart small models that can be efficiently hosted by mortals&#x2F;hobbyists. The DeepSeek result points to both of those happening in the near future. Interesting times.</div><br/></div></div><div id="42867020" class="c"><input type="checkbox" id="c-42867020" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#42866480">parent</a><span>|</span><a href="#42869274">prev</a><span>|</span><a href="#42870916">next</a><span>|</span><label class="collapse" for="c-42867020">[-]</label><label class="expand" for="c-42867020">[9 more]</label></div><br/><div class="children"><div class="content">For the curious, it was vertical integration in the railroad-oil&#x2F;-coal industry which is where the money was made.<p>The problem for AI is the hardware is commodified and offers no natural monopoly, so there isn&#x27;t really anything obvious to vertically integrate-towards-monopoly.</div><br/><div id="42867064" class="c"><input type="checkbox" id="c-42867064" checked=""/><div class="controls bullet"><span class="by">fullshark</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867020">parent</a><span>|</span><a href="#42870916">next</a><span>|</span><label class="collapse" for="c-42867064">[-]</label><label class="expand" for="c-42867064">[8 more]</label></div><br/><div class="children"><div class="content">Aren’t we approaching a scenario where the software is commodified (or at least “good enough” software) and the hardware isn’t (NVIDIA GPUs have defined advantages)</div><br/><div id="42867200" class="c"><input type="checkbox" id="c-42867200" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867064">parent</a><span>|</span><a href="#42867648">next</a><span>|</span><label class="collapse" for="c-42867200">[-]</label><label class="expand" for="c-42867200">[4 more]</label></div><br/><div class="children"><div class="content">I think the lesson of DeepSeek is &#x27;no&#x27; -- that by software innovation (ie., dropping below CUDA to programming the GPU directly, working at 8bit, etc.) you can trivialise the hardware requirement.<p>However I think the reality is that there&#x27;s only so much coal to be mined, as far as LLM training goes. When we&#x27;re at &quot;very dimishing returns&quot; SoC&#x2F;Apple&#x2F;TSMC-CPU innovations will deliver cheap inference. We only really need a M4 Ultra with 1TB RAM to hollow-out the hardware-inference-supplier market.<p>Very easy to imagine a future where Apple releases a &quot;Apple Intelligence Mac Studio&quot; with the specs for many businesses to run arbitrary models.</div><br/><div id="42868106" class="c"><input type="checkbox" id="c-42868106" checked=""/><div class="controls bullet"><span class="by">daft_pink</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867200">parent</a><span>|</span><a href="#42867648">next</a><span>|</span><label class="collapse" for="c-42868106">[-]</label><label class="expand" for="c-42868106">[3 more]</label></div><br/><div class="children"><div class="content">I really hope that apple realizes soon there is a market for Mac Pro&#x2F;Mac Studio with a RAM in the TBs for AI Workloads under $10k and a bunch of GPU cores.</div><br/><div id="42869472" class="c"><input type="checkbox" id="c-42869472" checked=""/><div class="controls bullet"><span class="by">jppope</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42868106">parent</a><span>|</span><a href="#42867648">next</a><span>|</span><label class="collapse" for="c-42869472">[-]</label><label class="expand" for="c-42869472">[2 more]</label></div><br/><div class="children"><div class="content">there was a company that recently built a desktop GPU for that exact thing. I&#x27;ll see if I can find it</div><br/><div id="42869753" class="c"><input type="checkbox" id="c-42869753" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42869472">parent</a><span>|</span><a href="#42867648">next</a><span>|</span><label class="collapse" for="c-42869753">[-]</label><label class="expand" for="c-42869753">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;cerebras.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;cerebras.ai&#x2F;</a> ?</div><br/></div></div></div></div></div></div></div></div><div id="42867648" class="c"><input type="checkbox" id="c-42867648" checked=""/><div class="controls bullet"><span class="by">duped</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867064">parent</a><span>|</span><a href="#42867200">prev</a><span>|</span><a href="#42870916">next</a><span>|</span><label class="collapse" for="c-42867648">[-]</label><label class="expand" for="c-42867648">[3 more]</label></div><br/><div class="children"><div class="content">Compute is literally being sold as a commodity today, software is not.</div><br/><div id="42871109" class="c"><input type="checkbox" id="c-42871109" checked=""/><div class="controls bullet"><span class="by">phkahler</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42867648">parent</a><span>|</span><a href="#42870916">next</a><span>|</span><label class="collapse" for="c-42871109">[-]</label><label class="expand" for="c-42871109">[2 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; Compute is literally being sold as a commodity today, software is not.<p>The marginal cost of software is zero. You need some kind of perceived advantage to get people to pay for it. This isn&#x27;t hard, as most people will pay a bit for big-name vs &quot;free&quot;. That could change as more open source apps become popular by being awesome.</div><br/><div id="42875482" class="c"><input type="checkbox" id="c-42875482" checked=""/><div class="controls bullet"><span class="by">duped</span><span>|</span><a href="#42866480">root</a><span>|</span><a href="#42871109">parent</a><span>|</span><a href="#42870916">next</a><span>|</span><label class="collapse" for="c-42875482">[-]</label><label class="expand" for="c-42875482">[1 more]</label></div><br/><div class="children"><div class="content">Marginal cost has nothing to do with it - you can buy and sell compute like you could corn and beef at scale. You can&#x27;t buy and sell software like that. In fact I&#x27;m surprised we don&#x27;t have futures markets for things like compute and object storage.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42870916" class="c"><input type="checkbox" id="c-42870916" checked=""/><div class="controls bullet"><span class="by">yonran</span><span>|</span><a href="#42866480">parent</a><span>|</span><a href="#42867020">prev</a><span>|</span><a href="#42869195">next</a><span>|</span><label class="collapse" for="c-42870916">[-]</label><label class="expand" for="c-42870916">[1 more]</label></div><br/><div class="children"><div class="content">I think a better analogy than railroads (which own the land that the track sits on and often valuable land around the station) is airlines, which don’t own land. I recall a relevant Warren Buffett letter that warned about investing hundreds of millions of dollars into capital with no moat:<p>&gt; Similarly, business growth, per se, tells us little about value.  It&#x27;s true that growth often has a positive impact on value, sometimes one of spectacular proportions.  But such an effect is far from certain. For example, investors have regularly poured  money into the domestic airline business to finance profitless (or worse) growth.  For these investors, it would have been far better  if Orville had failed to get off the ground at Kitty Hawk: The more the industry has grown, the worse the disaster for owners.<p><a href="https:&#x2F;&#x2F;www.berkshirehathaway.com&#x2F;letters&#x2F;1992.html" rel="nofollow">https:&#x2F;&#x2F;www.berkshirehathaway.com&#x2F;letters&#x2F;1992.html</a></div><br/></div></div><div id="42869195" class="c"><input type="checkbox" id="c-42869195" checked=""/><div class="controls bullet"><span class="by">UncleOxidant</span><span>|</span><a href="#42866480">parent</a><span>|</span><a href="#42870916">prev</a><span>|</span><a href="#42869395">next</a><span>|</span><label class="collapse" for="c-42869195">[-]</label><label class="expand" for="c-42869195">[1 more]</label></div><br/><div class="children"><div class="content">&gt; where the Moore’s law and advancement will eventually allow people to run open models locally<p>Probably won&#x27;t be Moore&#x27;s law (which is kind of slowing down) so much as architectural improvements (both on the compute side and the model side - you could say that R1 represents an architectural improvement of efficiency on the model side).</div><br/></div></div><div id="42869395" class="c"><input type="checkbox" id="c-42869395" checked=""/><div class="controls bullet"><span class="by">lastofthemojito</span><span>|</span><a href="#42866480">parent</a><span>|</span><a href="#42869195">prev</a><span>|</span><a href="#42869518">next</a><span>|</span><label class="collapse" for="c-42869395">[-]</label><label class="expand" for="c-42869395">[1 more]</label></div><br/><div class="children"><div class="content">I saw a thought-provoking post that similarly compared LLM makers to the airlines: <a href="https:&#x2F;&#x2F;calpaterson.com&#x2F;porter.html" rel="nofollow">https:&#x2F;&#x2F;calpaterson.com&#x2F;porter.html</a></div><br/></div></div><div id="42869518" class="c"><input type="checkbox" id="c-42869518" checked=""/><div class="controls bullet"><span class="by">taco_emoji</span><span>|</span><a href="#42866480">parent</a><span>|</span><a href="#42869395">prev</a><span>|</span><a href="#42876115">next</a><span>|</span><label class="collapse" for="c-42869518">[-]</label><label class="expand" for="c-42869518">[1 more]</label></div><br/><div class="children"><div class="content">Main difference is that railroads are actually useful</div><br/></div></div></div></div><div id="42876115" class="c"><input type="checkbox" id="c-42876115" checked=""/><div class="controls bullet"><span class="by">oysmal</span><span>|</span><a href="#42866480">prev</a><span>|</span><a href="#42867655">next</a><span>|</span><label class="collapse" for="c-42876115">[-]</label><label class="expand" for="c-42876115">[1 more]</label></div><br/><div class="children"><div class="content">Given that the training approach was open sourced, their claim can be independently verified. Huggingface is currently doing that with Open R1, so hopefully we will get a concrete answer to whether these accusations are merited or not.</div><br/></div></div><div id="42867655" class="c"><input type="checkbox" id="c-42867655" checked=""/><div class="controls bullet"><span class="by">wanderingmoose</span><span>|</span><a href="#42876115">prev</a><span>|</span><a href="#42876044">next</a><span>|</span><label class="collapse" for="c-42867655">[-]</label><label class="expand" for="c-42867655">[9 more]</label></div><br/><div class="children"><div class="content">There is a lot of discussion here about IP theft. Honest question, from deepseek&#x27;s point of view as a company under a different set of laws than US&#x2F;Western -- was there IP theft?<p>A company like OpenAI can put whatever licensing they want in place. But that only matters if they can enforce it. The question is, can they enforce it against deepseek? Did deepseek do something illegal under the laws of their originating country?<p>I&#x27;ve had some limited exposure to media related licensing when releasing content in China and what is allowed is very different than what is permitted in the US.<p>The interesting part which points to innovation moving outside of the US is US companies are beholden to strict IP laws while many places in the world don&#x27;t have such restrictions and will be able to utilize more data more easily.</div><br/><div id="42870243" class="c"><input type="checkbox" id="c-42870243" checked=""/><div class="controls bullet"><span class="by">fulafel</span><span>|</span><a href="#42867655">parent</a><span>|</span><a href="#42867831">next</a><span>|</span><label class="collapse" for="c-42870243">[-]</label><label class="expand" for="c-42870243">[1 more]</label></div><br/><div class="children"><div class="content">What law would be broken here? Seems that copyright wouldn&#x27;t apply unless they somehow snatched the OpenAI models verbatim.</div><br/></div></div><div id="42867831" class="c"><input type="checkbox" id="c-42867831" checked=""/><div class="controls bullet"><span class="by">thiago_fm</span><span>|</span><a href="#42867655">parent</a><span>|</span><a href="#42870243">prev</a><span>|</span><a href="#42876044">next</a><span>|</span><label class="collapse" for="c-42867831">[-]</label><label class="expand" for="c-42867831">[7 more]</label></div><br/><div class="children"><div class="content">The most interesting part is that China has been ahead of the US in AI for many years, just not in LLMs.<p>You need to visit mainland China and see how AI applications are everywhere, from transport to goods shipping.<p>I&#x27;m not surprised at all. I hope this in the end makes the US kill its strict IP laws, which is the problem.<p>If the US doesn&#x27;t, China will always have a huge edge on it, no matter how much NVidia hardware the US has.<p>And you know what, Huawei is already making inference hardware... it won&#x27;t take them long to finally copy the TSMC tech and flip the situation upside down.<p>When China can make the equivalent of H100s, it will be hilarious because they will sell for $10 in Aliexpress :-)</div><br/><div id="42868946" class="c"><input type="checkbox" id="c-42868946" checked=""/><div class="controls bullet"><span class="by">twobitshifter</span><span>|</span><a href="#42867655">root</a><span>|</span><a href="#42867831">parent</a><span>|</span><a href="#42870024">next</a><span>|</span><label class="collapse" for="c-42868946">[-]</label><label class="expand" for="c-42868946">[5 more]</label></div><br/><div class="children"><div class="content">You don’t even need to visit china, just read the latest research papers and look at the authors. China has more researchers in AI than the West and that’s a proven way to build an advantage.</div><br/><div id="42872241" class="c"><input type="checkbox" id="c-42872241" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#42867655">root</a><span>|</span><a href="#42868946">parent</a><span>|</span><a href="#42870024">next</a><span>|</span><label class="collapse" for="c-42872241">[-]</label><label class="expand" for="c-42872241">[4 more]</label></div><br/><div class="children"><div class="content">It is also funny in a different way. Many people don&#x27;t realise that they live in some sort of bubble. Many people in &quot;The West&quot; think that they are still the center of the world in everything, while this might not be so correct anymore.<p>In the U.S. there is 350 million people and EU has 520 million people (excluding Russia and Turkey).<p>China alone has 1.4 billion people.<p>Since there is a language barrier and China isolates themselves pretty well from the internet, we forget that there is a huge society with high focus on science. And most of our tech products are coming from there.</div><br/><div id="42875981" class="c"><input type="checkbox" id="c-42875981" checked=""/><div class="controls bullet"><span class="by">mordae</span><span>|</span><a href="#42867655">root</a><span>|</span><a href="#42872241">parent</a><span>|</span><a href="#42874514">next</a><span>|</span><label class="collapse" for="c-42875981">[-]</label><label class="expand" for="c-42875981">[1 more]</label></div><br/><div class="children"><div class="content">Not just that. They have 19% of people with tertiary education.<p>So about as many as US has adults.</div><br/></div></div><div id="42874514" class="c"><input type="checkbox" id="c-42874514" checked=""/><div class="controls bullet"><span class="by">realusername</span><span>|</span><a href="#42867655">root</a><span>|</span><a href="#42872241">parent</a><span>|</span><a href="#42875981">prev</a><span>|</span><a href="#42870024">next</a><span>|</span><label class="collapse" for="c-42874514">[-]</label><label class="expand" for="c-42874514">[2 more]</label></div><br/><div class="children"><div class="content">&gt; China alone has 1.4 billion people.<p>There&#x27;s some clues that their population count isn&#x27;t accurate and would be closer to 1.2 billion in reality, not that it changes the conclusion.</div><br/><div id="42875291" class="c"><input type="checkbox" id="c-42875291" checked=""/><div class="controls bullet"><span class="by">new_user_final</span><span>|</span><a href="#42867655">root</a><span>|</span><a href="#42874514">parent</a><span>|</span><a href="#42870024">next</a><span>|</span><label class="collapse" for="c-42875291">[-]</label><label class="expand" for="c-42875291">[1 more]</label></div><br/><div class="children"><div class="content">More accurately more than 1 Billion. So, US population is their rounding error.</div><br/></div></div></div></div></div></div></div></div><div id="42870024" class="c"><input type="checkbox" id="c-42870024" checked=""/><div class="controls bullet"><span class="by">nostradumbasp</span><span>|</span><a href="#42867655">root</a><span>|</span><a href="#42867831">parent</a><span>|</span><a href="#42868946">prev</a><span>|</span><a href="#42876044">next</a><span>|</span><label class="collapse" for="c-42870024">[-]</label><label class="expand" for="c-42870024">[1 more]</label></div><br/><div class="children"><div class="content">Maybe not $10 unless they are loss-leading to dominance. Well they actually could very well do exactly that... Hm, yea, good points. I would expect at least an order or two of magnitude higher to prevent an inferno.<p>Lets be fair though. Replicating TSMC isn&#x27;t something that could happen quickly. Then again, who knows how far along they already are...</div><br/></div></div></div></div></div></div><div id="42876044" class="c"><input type="checkbox" id="c-42876044" checked=""/><div class="controls bullet"><span class="by">thih9</span><span>|</span><a href="#42867655">prev</a><span>|</span><a href="#42866391">next</a><span>|</span><label class="collapse" for="c-42876044">[-]</label><label class="expand" for="c-42876044">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t mind and I believe that a company with &quot;open&quot; in its name shouldn&#x27;t mind either.<p>I hope this is actually true and OpenAI loses its close to monopoly status. Having a for profit entity safeguarding a popular resource like this sounds miserable for everyone else.<p>At the moment AI looks like typical VC scheme: build something off someone else&#x27;s work, sell it at cost at first, shove it down everyone&#x27;s throats and when it&#x27;s too late, hike the prices. I don&#x27;t like that.</div><br/></div></div><div id="42866391" class="c"><input type="checkbox" id="c-42866391" checked=""/><div class="controls bullet"><span class="by">me551ah</span><span>|</span><a href="#42876044">prev</a><span>|</span><a href="#42866049">next</a><span>|</span><label class="collapse" for="c-42866391">[-]</label><label class="expand" for="c-42866391">[2 more]</label></div><br/><div class="children"><div class="content">OpenAI is going after a company that open sourced their model, by distilling from their non-open AI?<p>OpenAI talks a lot about the principles of being Open, while still keeping their models closed and not fostering the open source community or sharing their research. Now when a company distills their models using perfectly allowed methods on the public internet, OpenAI wants to shut them down too?<p>High time OpenAI changes their name to ClosedAI</div><br/><div id="42870334" class="c"><input type="checkbox" id="c-42870334" checked=""/><div class="controls bullet"><span class="by">alexathrowawa9</span><span>|</span><a href="#42866391">parent</a><span>|</span><a href="#42866049">next</a><span>|</span><label class="collapse" for="c-42870334">[-]</label><label class="expand" for="c-42870334">[1 more]</label></div><br/><div class="children"><div class="content">The name OpenAI gets more ridiculous by the day<p>Would not be surprised if they do a rebrand eventually</div><br/></div></div></div></div><div id="42866049" class="c"><input type="checkbox" id="c-42866049" checked=""/><div class="controls bullet"><span class="by">readyplayernull</span><span>|</span><a href="#42866391">prev</a><span>|</span><a href="#42874022">next</a><span>|</span><label class="collapse" for="c-42866049">[-]</label><label class="expand" for="c-42866049">[1 more]</label></div><br/><div class="children"><div class="content">Do you remember when Microsoft was caught scrapping data from Google:<p><a href="https:&#x2F;&#x2F;www.wired.com&#x2F;2011&#x2F;02&#x2F;bing-copies-google&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.wired.com&#x2F;2011&#x2F;02&#x2F;bing-copies-google&#x2F;</a><p>They don&#x27;t care, T&amp;C and copyright is void unless it affects them, others can go kick rocks. Not surprising they  and OpenAI will do a legal battle over this.</div><br/></div></div><div id="42874022" class="c"><input type="checkbox" id="c-42874022" checked=""/><div class="controls bullet"><span class="by">TylerJaacks</span><span>|</span><a href="#42866049">prev</a><span>|</span><a href="#42866034">next</a><span>|</span><label class="collapse" for="c-42874022">[-]</label><label class="expand" for="c-42874022">[1 more]</label></div><br/><div class="children"><div class="content">Cry me a fucking river OpenAI, as if your business model isn&#x27;t entirely based on this exact same thing.</div><br/></div></div><div id="42866034" class="c"><input type="checkbox" id="c-42866034" checked=""/><div class="controls bullet"><span class="by">Ciantic</span><span>|</span><a href="#42874022">prev</a><span>|</span><a href="#42873796">next</a><span>|</span><label class="collapse" for="c-42866034">[-]</label><label class="expand" for="c-42866034">[12 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not being sarcastic, but we may soon have to torrent DeepSeek&#x27;s model. OpenAI has a lot of clout in the US and could get DeepSeek banned in western countries for copyright.</div><br/><div id="42867527" class="c"><input type="checkbox" id="c-42867527" checked=""/><div class="controls bullet"><span class="by">timeon</span><span>|</span><a href="#42866034">parent</a><span>|</span><a href="#42870180">next</a><span>|</span><label class="collapse" for="c-42867527">[-]</label><label class="expand" for="c-42867527">[7 more]</label></div><br/><div class="children"><div class="content">&gt; US and could get DeepSeek banned in western countries for copyright<p>If US is going to proceed with trade war on EU, as it was planning anyway, then DeepSeek will be banned only in US. Seems like term &quot;western countries&quot; is slowly eroding.</div><br/><div id="42869033" class="c"><input type="checkbox" id="c-42869033" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#42866034">root</a><span>|</span><a href="#42867527">parent</a><span>|</span><a href="#42870180">next</a><span>|</span><label class="collapse" for="c-42869033">[-]</label><label class="expand" for="c-42869033">[6 more]</label></div><br/><div class="children"><div class="content">Great point. Plus, the revival of serious talk of the Monroe Doctrine (!!!) in the U.S. government lends a possibly completely-new meaning to &quot;western countries&quot; -- i.e. the Americas...</div><br/><div id="42869300" class="c"><input type="checkbox" id="c-42869300" checked=""/><div class="controls bullet"><span class="by">surgical_fire</span><span>|</span><a href="#42866034">root</a><span>|</span><a href="#42869033">parent</a><span>|</span><a href="#42870177">next</a><span>|</span><label class="collapse" for="c-42869300">[-]</label><label class="expand" for="c-42869300">[3 more]</label></div><br/><div class="children"><div class="content">Except the US has only contempt for anything south of Texas. Perhaps &quot;western countries&quot; will be reduced to US and Canada.<p>Many countries in Latin America have better relations and more robust trade partnerships with China.<p>As for the EU, I think it will be great for it to shed its reliance on the US, and act more independently from it.</div><br/><div id="42869477" class="c"><input type="checkbox" id="c-42869477" checked=""/><div class="controls bullet"><span class="by">ta1243</span><span>|</span><a href="#42866034">root</a><span>|</span><a href="#42869300">parent</a><span>|</span><a href="#42870177">next</a><span>|</span><label class="collapse" for="c-42869477">[-]</label><label class="expand" for="c-42869477">[2 more]</label></div><br/><div class="children"><div class="content">The US is talking about annexing Canada, so &quot;western countries&quot; means the USA, which if continuing down this path long enough will become a pariah</div><br/><div id="42876016" class="c"><input type="checkbox" id="c-42876016" checked=""/><div class="controls bullet"><span class="by">mordae</span><span>|</span><a href="#42866034">root</a><span>|</span><a href="#42869477">parent</a><span>|</span><a href="#42870177">next</a><span>|</span><label class="collapse" for="c-42876016">[-]</label><label class="expand" for="c-42876016">[1 more]</label></div><br/><div class="children"><div class="content">This always reminds me of the Fallout opening video.</div><br/></div></div></div></div></div></div><div id="42870177" class="c"><input type="checkbox" id="c-42870177" checked=""/><div class="controls bullet"><span class="by">marcosdumay</span><span>|</span><a href="#42866034">root</a><span>|</span><a href="#42869033">parent</a><span>|</span><a href="#42869300">prev</a><span>|</span><a href="#42870180">next</a><span>|</span><label class="collapse" for="c-42870177">[-]</label><label class="expand" for="c-42870177">[2 more]</label></div><br/><div class="children"><div class="content">Only if they do it by force.<p>Trump has already managed to completely destroy the US reputation within basically the entire continent¹. And he seems intent on creating a commercial war against all the countries here too.<p>1 - Do not capture and torture random people on the street if you want to maintain some goodwill. Even if you have reasons to capture them.</div><br/><div id="42872607" class="c"><input type="checkbox" id="c-42872607" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#42866034">root</a><span>|</span><a href="#42870177">parent</a><span>|</span><a href="#42870180">next</a><span>|</span><label class="collapse" for="c-42872607">[-]</label><label class="expand" for="c-42872607">[1 more]</label></div><br/><div class="children"><div class="content">Yeah... I don&#x27;t think goodwill was ever a very central part of the Monroe doctrine. Its imperial expansionism, plain n&#x27; simple. Embargo + pressure who you can, depose any governments that resist, threaten the rest into silent compliance.<p>Scary times.</div><br/></div></div></div></div></div></div></div></div><div id="42870180" class="c"><input type="checkbox" id="c-42870180" checked=""/><div class="controls bullet"><span class="by">aerhardt</span><span>|</span><a href="#42866034">parent</a><span>|</span><a href="#42867527">prev</a><span>|</span><a href="#42866394">next</a><span>|</span><label class="collapse" for="c-42870180">[-]</label><label class="expand" for="c-42870180">[2 more]</label></div><br/><div class="children"><div class="content">Unfathomable to me that they&#x27;d make themselves look so foolish by trying to ban a piece of software.</div><br/><div id="42874528" class="c"><input type="checkbox" id="c-42874528" checked=""/><div class="controls bullet"><span class="by">forgotoldacc</span><span>|</span><a href="#42866034">root</a><span>|</span><a href="#42870180">parent</a><span>|</span><a href="#42866394">next</a><span>|</span><label class="collapse" for="c-42874528">[-]</label><label class="expand" for="c-42874528">[1 more]</label></div><br/><div class="children"><div class="content">It wouldn&#x27;t be foolish. The US has an active cult of personality, and whatever the leader says, half the country believes it unquestioningly. If OpenAI is said to be protecting America and DeepSeek is doing terrible, terrible things to the children (many smart people are saying it), there&#x27;ll be an overnight pivot to half the country screaming for it to be banned and harassing anyone who says otherwise.<p>Who cares if some people think you look foolish when you have a locked down 500 billion dollar investment guarantee?</div><br/></div></div></div></div><div id="42866394" class="c"><input type="checkbox" id="c-42866394" checked=""/><div class="controls bullet"><span class="by">alchemist1e9</span><span>|</span><a href="#42866034">parent</a><span>|</span><a href="#42870180">prev</a><span>|</span><a href="#42871084">next</a><span>|</span><label class="collapse" for="c-42866394">[-]</label><label class="expand" for="c-42866394">[1 more]</label></div><br/><div class="children"><div class="content">I think most likely all sorts of data and models need to have a decentralized LLM data archive via torrents etc.<p>It’s not limited to the models themselves but also OpenAI will probably work towards shutting down access to training data sets also.<p>imho it’s probably an emergency all hand on deck problem.</div><br/></div></div><div id="42871084" class="c"><input type="checkbox" id="c-42871084" checked=""/><div class="controls bullet"><span class="by">sergiotapia</span><span>|</span><a href="#42866034">parent</a><span>|</span><a href="#42866394">prev</a><span>|</span><a href="#42873796">next</a><span>|</span><label class="collapse" for="c-42871084">[-]</label><label class="expand" for="c-42871084">[1 more]</label></div><br/><div class="children"><div class="content">that would be suicide - that company only exists because they stole content for every single person, website and media company on the planet.</div><br/></div></div></div></div><div id="42873796" class="c"><input type="checkbox" id="c-42873796" checked=""/><div class="controls bullet"><span class="by">karim79</span><span>|</span><a href="#42866034">prev</a><span>|</span><a href="#42869325">next</a><span>|</span><label class="collapse" for="c-42873796">[-]</label><label class="expand" for="c-42873796">[1 more]</label></div><br/><div class="children"><div class="content">Oh God. I know exactly how this feels. A few years ago I made a bread hydration and conversion calculator for a friend, and put it up on JSFiddle. My friend, at the time, was an apprentice baker.<p>Just weeks later, I discovered that others were pulling off similar calculations! They were making great bread with ease and not having to resort to notebooks and calculators! The horror! I can&#x27;t believe that said close friend of mine would actually share those highly hydraty mathematical formulas with other humans without first requesting my consent &lt;&#x2F;sarc&gt;.<p>Could it be, that this stuff just ends up in the dumpster of &quot;sorry you can&#x27;t patent math&quot; or the like?</div><br/></div></div><div id="42869325" class="c"><input type="checkbox" id="c-42869325" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42873796">prev</a><span>|</span><a href="#42876029">next</a><span>|</span><label class="collapse" for="c-42869325">[-]</label><label class="expand" for="c-42869325">[1 more]</label></div><br/><div class="children"><div class="content">Hey, OpenAI, so, you know that legal theory that is the entire basis of your argument that any of your products are legal? &quot;Training AI on proprietary data is a use that doesn&#x27;t require permission from the owner of the data&quot;?<p>You might want to consider how it applies to this situation.</div><br/></div></div><div id="42876029" class="c"><input type="checkbox" id="c-42876029" checked=""/><div class="controls bullet"><span class="by">krystofee</span><span>|</span><a href="#42869325">prev</a><span>|</span><a href="#42874205">next</a><span>|</span><label class="collapse" for="c-42876029">[-]</label><label class="expand" for="c-42876029">[1 more]</label></div><br/><div class="children"><div class="content">I dont know if point of this is just to derail public attention to narative “hey, chinese stole our model, thats not fair, we need computee”, when the deepseek has clearly done some exceptional technical breakthrough on R1 and v3 models. Which even if you stole data from OpenAi is its thing.</div><br/></div></div><div id="42874205" class="c"><input type="checkbox" id="c-42874205" checked=""/><div class="controls bullet"><span class="by">olalonde</span><span>|</span><a href="#42876029">prev</a><span>|</span><a href="#42866113">next</a><span>|</span><label class="collapse" for="c-42874205">[-]</label><label class="expand" for="c-42874205">[1 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s true, how is it problematic? It seems aligned with their mission:<p>&gt; We will attempt to directly build safe and beneficial AGI, but will also consider our <i>mission fulfilled if our work aids others to achieve this outcome</i>.<p>&gt; We will <i>actively cooperate</i> with other research and policy institutions; we seek to create a global community working together to address AGI’s global challenges.<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;charter&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;charter&#x2F;</a><p>&#x2F;s, we all know what their true mission is...</div><br/></div></div><div id="42866113" class="c"><input type="checkbox" id="c-42866113" checked=""/><div class="controls bullet"><span class="by">mhitza</span><span>|</span><a href="#42874205">prev</a><span>|</span><a href="#42873080">next</a><span>|</span><label class="collapse" for="c-42866113">[-]</label><label class="expand" for="c-42866113">[3 more]</label></div><br/><div class="children"><div class="content">This is funny because its.<p>1. Something I&#x27;d expect to happen.<p>2. Lived through a similar scenario in 2010 or so.<p>Early in my professional career I&#x27;ve worked for a media company that was scraping other sites (think Craigslist but for our local market) to republish the content on our competing website. I wasn&#x27;t working on that specific project, but I did work on an integration on my teams project where the scraping team could post jobs on our platform directly. When others started scraping &quot;our content&quot; there were a couple of urgent all hands on deck meetings scheduled, with a high level of disbelief.</div><br/><div id="42868032" class="c"><input type="checkbox" id="c-42868032" checked=""/><div class="controls bullet"><span class="by">spyckie2</span><span>|</span><a href="#42866113">parent</a><span>|</span><a href="#42867578">next</a><span>|</span><label class="collapse" for="c-42868032">[-]</label><label class="expand" for="c-42868032">[1 more]</label></div><br/><div class="children"><div class="content">Classic.</div><br/></div></div><div id="42867578" class="c"><input type="checkbox" id="c-42867578" checked=""/><div class="controls bullet"><span class="by">kigiri</span><span>|</span><a href="#42866113">parent</a><span>|</span><a href="#42868032">prev</a><span>|</span><a href="#42873080">next</a><span>|</span><label class="collapse" for="c-42867578">[-]</label><label class="expand" for="c-42867578">[1 more]</label></div><br/><div class="children"><div class="content">Nice one, thank you for sharing !</div><br/></div></div></div></div><div id="42873080" class="c"><input type="checkbox" id="c-42873080" checked=""/><div class="controls bullet"><span class="by">esskay</span><span>|</span><a href="#42866113">prev</a><span>|</span><a href="#42875001">next</a><span>|</span><label class="collapse" for="c-42873080">[-]</label><label class="expand" for="c-42873080">[3 more]</label></div><br/><div class="children"><div class="content">Hard to really have any sympathy for OpenAI&#x27;s position when they&#x27;re actively stealing content, ignoring requests to stop then spending huge amounts to get around sites running ai poisoning scripts, making it clear they&#x27;ll still take your content regardless of if you consent to it.</div><br/><div id="42873183" class="c"><input type="checkbox" id="c-42873183" checked=""/><div class="controls bullet"><span class="by">michaelmarkell</span><span>|</span><a href="#42873080">parent</a><span>|</span><a href="#42875001">next</a><span>|</span><label class="collapse" for="c-42873183">[-]</label><label class="expand" for="c-42873183">[2 more]</label></div><br/><div class="children"><div class="content">Can someone with more expertise help me understand what I&#x27;m looking at here? <a href="https:&#x2F;&#x2F;crt.sh&#x2F;?id=10106356492" rel="nofollow">https:&#x2F;&#x2F;crt.sh&#x2F;?id=10106356492</a><p>It looks like Deepseek had a subdomain called &quot;openai-us1.deepseek.com&quot;. What is a legitimate use-case for hosting an openai proxy(?) on your subdomain like this?<p>Not implying anything&#x27;s off here, but it&#x27;s interesting to me that this OpenAI entity is one of the few subdomains they have on their site</div><br/><div id="42875674" class="c"><input type="checkbox" id="c-42875674" checked=""/><div class="controls bullet"><span class="by">gkbrk</span><span>|</span><a href="#42873080">root</a><span>|</span><a href="#42873183">parent</a><span>|</span><a href="#42875001">next</a><span>|</span><label class="collapse" for="c-42875674">[-]</label><label class="expand" for="c-42875674">[1 more]</label></div><br/><div class="children"><div class="content">Could just be an OpenAI-compatible endpoint too. A lot of LLM tools use OpenAI compatible APIs, just like a lot of Object Storage tools use S3 compatible APIs.</div><br/></div></div></div></div></div></div><div id="42875001" class="c"><input type="checkbox" id="c-42875001" checked=""/><div class="controls bullet"><span class="by">emsign</span><span>|</span><a href="#42873080">prev</a><span>|</span><a href="#42865858">next</a><span>|</span><label class="collapse" for="c-42875001">[-]</label><label class="expand" for="c-42875001">[1 more]</label></div><br/><div class="children"><div class="content">&quot;yOu ShOuLdN&#x27;t TaKe OtHeR pEoPlE&#x27;s DaTa!1!1&quot; are they mental? How can people at OpenAI lack be so self-righteous and unaware? Is thia arrogance or a mental illness?</div><br/></div></div><div id="42865858" class="c"><input type="checkbox" id="c-42865858" checked=""/><div class="controls bullet"><span class="by">sho_hn</span><span>|</span><a href="#42875001">prev</a><span>|</span><a href="#42875340">next</a><span>|</span><label class="collapse" for="c-42865858">[-]</label><label class="expand" for="c-42865858">[13 more]</label></div><br/><div class="children"><div class="content">While I&#x27;m as amused as everyone else  - I think it&#x27;s technically accurate to point out that the &quot;we trained it for $6 mio&quot; narrative is contingent on the done investment by others.</div><br/><div id="42866274" class="c"><input type="checkbox" id="c-42866274" checked=""/><div class="controls bullet"><span class="by">Palmik</span><span>|</span><a href="#42865858">parent</a><span>|</span><a href="#42866445">next</a><span>|</span><label class="collapse" for="c-42866274">[-]</label><label class="expand" for="c-42866274">[1 more]</label></div><br/><div class="children"><div class="content">When I use NVIDIA GPUs to train a model, I do not consider the R&amp;D cost to develop all of those GPUs as part of my costs.<p>When I use an API to generate some data, I do not consider the R&amp;D cost to develop the API as part of my costs.</div><br/></div></div><div id="42866445" class="c"><input type="checkbox" id="c-42866445" checked=""/><div class="controls bullet"><span class="by">kobalsky</span><span>|</span><a href="#42865858">parent</a><span>|</span><a href="#42866274">prev</a><span>|</span><a href="#42865901">next</a><span>|</span><label class="collapse" for="c-42866445">[-]</label><label class="expand" for="c-42866445">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI has been in a war-room for days searching for a match in the data, and they just came out with this without providing proof.<p>My cynical opinion is that the traning corpus has some small amount of data generated by OpenAI, which is probably impossible to avoid at this point, and they are hanging on that thread for dear life.</div><br/></div></div><div id="42865901" class="c"><input type="checkbox" id="c-42865901" checked=""/><div class="controls bullet"><span class="by">bbqfog</span><span>|</span><a href="#42865858">parent</a><span>|</span><a href="#42866445">prev</a><span>|</span><a href="#42870839">next</a><span>|</span><label class="collapse" for="c-42865901">[-]</label><label class="expand" for="c-42865901">[8 more]</label></div><br/><div class="children"><div class="content">OpenAI&#x27;s models were also trained on billions of dollars of &quot;free&quot; labor that produced the content that it was trained on.</div><br/><div id="42865967" class="c"><input type="checkbox" id="c-42865967" checked=""/><div class="controls bullet"><span class="by">sho_hn</span><span>|</span><a href="#42865858">root</a><span>|</span><a href="#42865901">parent</a><span>|</span><a href="#42870839">next</a><span>|</span><label class="collapse" for="c-42865967">[-]</label><label class="expand" for="c-42865967">[7 more]</label></div><br/><div class="children"><div class="content">Oh, absolutely. I&#x27;m not defending OpenAI, I just care about accurate reporting. Even on HN - even in this thread - you see people who came away with the conclusion that DeepSeek did something while &quot;cutting cost by 27x&quot;.<p>But that&#x27;s a bit like saying that by painting a a bare wall green you have demonstrated that you can build green walls 27x cheaper, ignoring the cost of building the wall in the first place.<p>Smarter reporting and discourse would explain how this iterative process actually works and who is building on who and how, not frame it as two competing from-scratch clean room efforts. It&#x27;d help clear up expectations of what&#x27;s coming next.<p>It&#x27;s a bit similar to how many are saying DeepSeek have demonstrated independence from nVidia, when part of the clever thing they did was figure out how to make the intentionally gimped H800s work for their training runs by doing low-level optimizations that are <i>more</i> nVidia-specific, etc.<p>Rarely have I seen a highly technical topic see produce more uninformed snap takes than this week.</div><br/><div id="42866355" class="c"><input type="checkbox" id="c-42866355" checked=""/><div class="controls bullet"><span class="by">Palmik</span><span>|</span><a href="#42865858">root</a><span>|</span><a href="#42865967">parent</a><span>|</span><a href="#42871700">next</a><span>|</span><label class="collapse" for="c-42866355">[-]</label><label class="expand" for="c-42866355">[2 more]</label></div><br/><div class="children"><div class="content">You are underselling or not understanding the breakthrough. They trained 600B model on 15T tokens for &lt;$6&#x2F;m. Regardless of the provenance of the tokens, this in itself is impressive.<p>Not to mention post-training. Their novel GRPO technique used for preference optimization &#x2F; alignment is also much more efficient than PPO.</div><br/><div id="42867110" class="c"><input type="checkbox" id="c-42867110" checked=""/><div class="controls bullet"><span class="by">sho_hn</span><span>|</span><a href="#42865858">root</a><span>|</span><a href="#42866355">parent</a><span>|</span><a href="#42871700">next</a><span>|</span><label class="collapse" for="c-42867110">[-]</label><label class="expand" for="c-42867110">[1 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s call it underselling. :-) Mostly because I&#x27;m not sure anyone&#x27;s independently done the math and we just have a single statement from the CEO. I do appreciate the algorithmic improvements, and the excellent attention-to-performance-in-detail stuff in their implementation (careful treatment of precision, etc.), making the H800s useful, etc. I agree there&#x27;s a lot there.</div><br/></div></div></div></div><div id="42871700" class="c"><input type="checkbox" id="c-42871700" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#42865858">root</a><span>|</span><a href="#42865967">parent</a><span>|</span><a href="#42866355">prev</a><span>|</span><a href="#42866109">next</a><span>|</span><label class="collapse" for="c-42871700">[-]</label><label class="expand" for="c-42871700">[1 more]</label></div><br/><div class="children"><div class="content">&gt; that&#x27;s a bit like saying that by painting a a bare wall green you have demonstrated that you can build green walls 27x cheaper, ignoring the cost of building the wall in the first place<p>That&#x27;s a funny analogy, but in reality DeepSeek did reinforcement learning to generate chain of thought, which was used in the end to finetune LLMs. The RL model was called DeepSeek-R1-Zero, while the SFT model is DeepSeek-R1.<p>They might have boostrapped the Zero model with some demonstrations.<p>&gt; DeepSeek-R1-Zero struggles with challenges like poor readability, and language mixing. To make reasoning processes more readable and share them with the open community, we explore DeepSeek-R1, a method that utilizes RL with human-friendly cold-start data.<p>&gt; Unlike DeepSeek-R1-Zero, to prevent the early unstable cold start phase of RL training from the base model, for DeepSeek-R1 we construct and collect a small amount of long CoT data to fine-tune the model as the initial RL actor. To collect such data, we have explored several approaches: using few-shot prompting with a long CoT as an example, directly prompting models to generate detailed answers with reflection and verification, gathering DeepSeek-R1Zero outputs in a readable format, and refining the results through post-processing by human annotators.</div><br/></div></div><div id="42866109" class="c"><input type="checkbox" id="c-42866109" checked=""/><div class="controls bullet"><span class="by">bbqfog</span><span>|</span><a href="#42865858">root</a><span>|</span><a href="#42865967">parent</a><span>|</span><a href="#42871700">prev</a><span>|</span><a href="#42870839">next</a><span>|</span><label class="collapse" for="c-42866109">[-]</label><label class="expand" for="c-42866109">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t agree. Walls are physical items so your example is true, but models are data. Anyone can train off of these models, that&#x27;s the current environment we exist in. Just like OpenAI trained on data that has since been locked up in a lot of cases. In 2025 training models like Deepseek is indeed 27x cheaper, that includes both their innovations and the existence of new &quot;raw material&quot; to do such a thing.</div><br/><div id="42866165" class="c"><input type="checkbox" id="c-42866165" checked=""/><div class="controls bullet"><span class="by">sho_hn</span><span>|</span><a href="#42865858">root</a><span>|</span><a href="#42866109">parent</a><span>|</span><a href="#42870839">next</a><span>|</span><label class="collapse" for="c-42866165">[-]</label><label class="expand" for="c-42866165">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think we disagree at all, actually!<p>What I&#x27;m saying is that in the media it&#x27;s being portrayed as if DeepSeek did <i>the same thing OpenAI did</i> 27x cheaper, and the outsized market reaction is in large parts a response to that narrative. While the reality is more that being a fast-follower is cheaper (and the concrete reason is e.g. being able to source training data from prior LLMs synthetically, among other things), which shouldn&#x27;t have surprised anyone and is just how technology in general trends.<p>The achievement of DeepSeek is putting together a competent team that excels at end-to-end implementation, which is no small feat and is promising wrt&#x2F; their future efforts.</div><br/><div id="42867329" class="c"><input type="checkbox" id="c-42867329" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#42865858">root</a><span>|</span><a href="#42866165">parent</a><span>|</span><a href="#42870839">next</a><span>|</span><label class="collapse" for="c-42867329">[-]</label><label class="expand" for="c-42867329">[1 more]</label></div><br/><div class="children"><div class="content">How much money a third company would need to spend to achieve what OpenAI achieved to compete with them, 5billion or 6million?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42870839" class="c"><input type="checkbox" id="c-42870839" checked=""/><div class="controls bullet"><span class="by">freehorse</span><span>|</span><a href="#42865858">parent</a><span>|</span><a href="#42865901">prev</a><span>|</span><a href="#42870417">next</a><span>|</span><label class="collapse" for="c-42870839">[-]</label><label class="expand" for="c-42870839">[1 more]</label></div><br/><div class="children"><div class="content">That is the case anyway for training any llm. It is contingent on the work done by all those who produced the data.</div><br/></div></div><div id="42870417" class="c"><input type="checkbox" id="c-42870417" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#42865858">parent</a><span>|</span><a href="#42870839">prev</a><span>|</span><a href="#42875340">next</a><span>|</span><label class="collapse" for="c-42870417">[-]</label><label class="expand" for="c-42870417">[1 more]</label></div><br/><div class="children"><div class="content">The opposite, is claiming that OpenAI could have now built better performing, cheaper to run model (when compared to what they published) training it at 1% cost on output of their previous models. ... But they chose not to do it.</div><br/></div></div></div></div><div id="42875340" class="c"><input type="checkbox" id="c-42875340" checked=""/><div class="controls bullet"><span class="by">bicepjai</span><span>|</span><a href="#42865858">prev</a><span>|</span><a href="#42865775">next</a><span>|</span><label class="collapse" for="c-42875340">[-]</label><label class="expand" for="c-42875340">[2 more]</label></div><br/><div class="children"><div class="content">Reading this post, I can’t help but wonder if people realize the irony in what they’re saying.
1. “The issue is when you [take it out of the platform and] are doing it to create your own model for your own purposes,”
2. “There’s a technique in AI called distillation . . . when one model learns from another model [and] kind of sucks the knowledge out of the parent model,”</div><br/><div id="42875429" class="c"><input type="checkbox" id="c-42875429" checked=""/><div class="controls bullet"><span class="by">palisade</span><span>|</span><a href="#42875340">parent</a><span>|</span><a href="#42865775">next</a><span>|</span><label class="collapse" for="c-42875429">[-]</label><label class="expand" for="c-42875429">[1 more]</label></div><br/><div class="children"><div class="content">Is this really the point OpenAI wants to start debating? When OpenAI steals everyone&#x27;s data, it is fine. Right? But, let us pull the ladder up after that.</div><br/></div></div></div></div><div id="42865775" class="c"><input type="checkbox" id="c-42865775" checked=""/><div class="controls bullet"><span class="by">1970-01-01</span><span>|</span><a href="#42875340">prev</a><span>|</span><a href="#42874572">next</a><span>|</span><label class="collapse" for="c-42865775">[-]</label><label class="expand" for="c-42865775">[5 more]</label></div><br/><div class="children"><div class="content">DeepSeek have more integrity than &#x27;Open&#x27;AI by not even pretending to care about that.</div><br/><div id="42868496" class="c"><input type="checkbox" id="c-42868496" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#42865775">parent</a><span>|</span><a href="#42874572">next</a><span>|</span><label class="collapse" for="c-42868496">[-]</label><label class="expand" for="c-42868496">[4 more]</label></div><br/><div class="children"><div class="content">And seem to be more actively fulfilling the mission that &#x27;Open&#x27;AI pretends to strive for.</div><br/><div id="42871180" class="c"><input type="checkbox" id="c-42871180" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#42865775">root</a><span>|</span><a href="#42868496">parent</a><span>|</span><a href="#42874572">next</a><span>|</span><label class="collapse" for="c-42871180">[-]</label><label class="expand" for="c-42871180">[3 more]</label></div><br/><div class="children"><div class="content">Exactly, they <i>actually</i> opened up the model and research, which the &quot;Open&quot; company didn&#x27;t, and merely adjusted some of their pricing tiers to try to combat commercially (but not without mumbling something like &quot;yeah, we totally had these ideas too&quot;). Now every single Meta, OpenAI etc engineer is trying to copy DeepSeek&#x27;s innovations, and their first act is to... complain about copyright infringement, of all things?! What an absolute clown party, how can these people take themselves seriously, do they just have zero comprehension of what hypocrisy is or what&#x27;s going on here...<p>I can scarcely process all the levels of irony involved, the irony-o-meter is pegged and I can&#x27;t get the good one from the safe because I&#x27;m incapacitated from laughter.</div><br/><div id="42872455" class="c"><input type="checkbox" id="c-42872455" checked=""/><div class="controls bullet"><span class="by">tim333</span><span>|</span><a href="#42865775">root</a><span>|</span><a href="#42871180">parent</a><span>|</span><a href="#42874572">next</a><span>|</span><label class="collapse" for="c-42872455">[-]</label><label class="expand" for="c-42872455">[2 more]</label></div><br/><div class="children"><div class="content">Altman was in a bit of a tricky position in that he figured OpenAI would need a lot of money for compute to be able to compete but it was hard to get that while remaining open. DeepSeek benefit from being funded from their own hedge fund. I wonder if part of their strategy is crack AI and then have it trade the markets?</div><br/><div id="42875317" class="c"><input type="checkbox" id="c-42875317" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#42865775">root</a><span>|</span><a href="#42872455">parent</a><span>|</span><a href="#42874572">next</a><span>|</span><label class="collapse" for="c-42875317">[-]</label><label class="expand" for="c-42875317">[1 more]</label></div><br/><div class="children"><div class="content">The last (only?) language model OpenAI released openly was GPT-2, and even for that the instruction weighted model was never released. This was in 2019. The large Microsoft deal was done in 2023.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42874572" class="c"><input type="checkbox" id="c-42874572" checked=""/><div class="controls bullet"><span class="by">kamranjon</span><span>|</span><a href="#42865775">prev</a><span>|</span><a href="#42867511">next</a><span>|</span><label class="collapse" for="c-42874572">[-]</label><label class="expand" for="c-42874572">[1 more]</label></div><br/><div class="children"><div class="content">I was just wondering if this is even feasible?<p>The amount of iterations of training that would be needed for DeepSeek to actually learn anything from OpenAI would seem to be an insane amount of requests from a non-local AI, which you’d think would be immediately obvious to OpenAI just by looking at suspicious requests?<p>Am I correct in this assumption or am I missing something? Is it even realistic that something like this is possible without a local model?</div><br/></div></div><div id="42867511" class="c"><input type="checkbox" id="c-42867511" checked=""/><div class="controls bullet"><span class="by">concerndc1tizen</span><span>|</span><a href="#42874572">prev</a><span>|</span><a href="#42870451">next</a><span>|</span><label class="collapse" for="c-42867511">[-]</label><label class="expand" for="c-42867511">[1 more]</label></div><br/><div class="children"><div class="content">Is OpenAI claiming copyright ownership over the generated synthetic data?<p>That would be a dangerous precedent to establish.<p>If it&#x27;s a terms of service violation, I guess they&#x27;re within their rights to terminate service, but what other recourse do they have?<p>Other than that, perhaps this is just rhetoric aimed at introducing restrictions in the US, to prevent access to foreign AI, to establish a national monopoly?</div><br/></div></div><div id="42870451" class="c"><input type="checkbox" id="c-42870451" checked=""/><div class="controls bullet"><span class="by">divbzero</span><span>|</span><a href="#42867511">prev</a><span>|</span><a href="#42866229">next</a><span>|</span><label class="collapse" for="c-42870451">[-]</label><label class="expand" for="c-42870451">[1 more]</label></div><br/><div class="children"><div class="content">I was wondering if this might be the case, similar to how Bing’s initial training included Google’s search results [1]. I’d be curious to see more details of OpenAI’s evidence.<p>It is, of course, quite ironic for OpenAI to indiscriminately scrape the entire web and then complain about being scraped themselves.<p>[1]: <a href="https:&#x2F;&#x2F;searchengineland.com&#x2F;google-bing-is-cheating-copying-our-search-results-62914" rel="nofollow">https:&#x2F;&#x2F;searchengineland.com&#x2F;google-bing-is-cheating-copying...</a></div><br/></div></div><div id="42866229" class="c"><input type="checkbox" id="c-42866229" checked=""/><div class="controls bullet"><span class="by">thorum</span><span>|</span><a href="#42870451">prev</a><span>|</span><a href="#42873648">next</a><span>|</span><label class="collapse" for="c-42866229">[-]</label><label class="expand" for="c-42866229">[15 more]</label></div><br/><div class="children"><div class="content">&gt; “It is (relatively) easy to copy something that you know works,” Altman tweeted. “It is extremely hard to do something new, risky, and difficult when you don’t know if it will work.”<p>The humor&#x2F;hypocrisy of the situation aside, it does seem to be true that OpenAI is consistently the one coming up with new ideas first (GPT 4, o1, 4o-style multimodality, voice chat, DALL-E, …) and then other companies reproduce their work, and get more credit because they actually publish the research.<p>Unfortunately for them it’s challenging to profit in the long term from being first in this space and the time it takes for each new idea to be reproduced is getting shorter.</div><br/><div id="42869592" class="c"><input type="checkbox" id="c-42869592" checked=""/><div class="controls bullet"><span class="by">Hatchback7599</span><span>|</span><a href="#42866229">parent</a><span>|</span><a href="#42870812">next</a><span>|</span><label class="collapse" for="c-42869592">[-]</label><label class="expand" for="c-42869592">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of the Bill Gates quote when Steve Jobs accused him of stealing the ideas of Windows from Mac:<p>Well, Steve... I think it’s more like we both had this rich neighbor named Xerox and I broke into his house to steal the TV set and found out that you had already stolen it.<p>Xerox could be seen as Google, whose researchers produced the landmark Attention Is All You Need paper, and the general public, who provided all of the training data to make these models possible.</div><br/></div></div><div id="42870812" class="c"><input type="checkbox" id="c-42870812" checked=""/><div class="controls bullet"><span class="by">rndphs</span><span>|</span><a href="#42866229">parent</a><span>|</span><a href="#42869592">prev</a><span>|</span><a href="#42866492">next</a><span>|</span><label class="collapse" for="c-42870812">[-]</label><label class="expand" for="c-42870812">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI is consistently the one coming up with new ideas first (GPT 4, o1, 4o-style multimodality, voice chat, DALL-E, …)<p>As far as I can tell o1 was based on Q-star, which could likely be Quiet-STaR, a CoT RL technique developed at Stanford that OpenAI may have learned about before it got published. Presumably that&#x27;s why they never used the Q-Star name even though it had garnered mystique and would have been good for building hype. This is just speculation, but since OpenAI haven&#x27;t published their technique then we can&#x27;t know if it really was their innovation.</div><br/></div></div><div id="42866492" class="c"><input type="checkbox" id="c-42866492" checked=""/><div class="controls bullet"><span class="by">turtlesdown11</span><span>|</span><a href="#42866229">parent</a><span>|</span><a href="#42870812">prev</a><span>|</span><a href="#42869306">next</a><span>|</span><label class="collapse" for="c-42866492">[-]</label><label class="expand" for="c-42866492">[3 more]</label></div><br/><div class="children"><div class="content">&gt; other companies reproduce their work, and get more credit because they actually publish the research.<p>I don&#x27;t understand, you mean OpenAI isn&#x27;t releasing open models and openly publishing their research?</div><br/><div id="42870465" class="c"><input type="checkbox" id="c-42870465" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#42866229">root</a><span>|</span><a href="#42866492">parent</a><span>|</span><a href="#42869306">next</a><span>|</span><label class="collapse" for="c-42870465">[-]</label><label class="expand" for="c-42870465">[2 more]</label></div><br/><div class="children"><div class="content">Are you being sarcastic (honestly, it&#x27;s hard to tell after reading as many uninformed takes in the past week as I have).<p>No, they aren&#x27;t (other than whisper).<p>Their &quot;papers&quot; are closer to marketing materials. Very intentionally leaving out tons of technical information.</div><br/><div id="42871099" class="c"><input type="checkbox" id="c-42871099" checked=""/><div class="controls bullet"><span class="by">KolmogorovComp</span><span>|</span><a href="#42866229">root</a><span>|</span><a href="#42870465">parent</a><span>|</span><a href="#42869306">next</a><span>|</span><label class="collapse" for="c-42871099">[-]</label><label class="expand" for="c-42871099">[1 more]</label></div><br/><div class="children"><div class="content">They are being sarcastic.</div><br/></div></div></div></div></div></div><div id="42869306" class="c"><input type="checkbox" id="c-42869306" checked=""/><div class="controls bullet"><span class="by">weego</span><span>|</span><a href="#42866229">parent</a><span>|</span><a href="#42866492">prev</a><span>|</span><a href="#42870333">next</a><span>|</span><label class="collapse" for="c-42869306">[-]</label><label class="expand" for="c-42869306">[2 more]</label></div><br/><div class="children"><div class="content">Boy who stole test papers complains about child copying his answers.</div><br/><div id="42869818" class="c"><input type="checkbox" id="c-42869818" checked=""/><div class="controls bullet"><span class="by">FridgeSeal</span><span>|</span><a href="#42866229">root</a><span>|</span><a href="#42869306">parent</a><span>|</span><a href="#42870333">next</a><span>|</span><label class="collapse" for="c-42869818">[-]</label><label class="expand" for="c-42869818">[1 more]</label></div><br/><div class="children"><div class="content">No you don’t understand, AI is “dangerous” and only him and his uber rich billionaire mates should get to control it!</div><br/></div></div></div></div><div id="42870333" class="c"><input type="checkbox" id="c-42870333" checked=""/><div class="controls bullet"><span class="by">namuol</span><span>|</span><a href="#42866229">parent</a><span>|</span><a href="#42869306">prev</a><span>|</span><a href="#42866537">next</a><span>|</span><label class="collapse" for="c-42870333">[-]</label><label class="expand" for="c-42870333">[1 more]</label></div><br/><div class="children"><div class="content">The eye-watering funding numbers proposed by Altman in the past and more recently with “Stargate” suggests a publicly-funded research pivot is not out of the question. Could see a big defense department grant being given. Sigh.</div><br/></div></div><div id="42866537" class="c"><input type="checkbox" id="c-42866537" checked=""/><div class="controls bullet"><span class="by">actuallyalys</span><span>|</span><a href="#42866229">parent</a><span>|</span><a href="#42870333">prev</a><span>|</span><a href="#42869307">next</a><span>|</span><label class="collapse" for="c-42866537">[-]</label><label class="expand" for="c-42866537">[1 more]</label></div><br/><div class="children"><div class="content">There’s some truth in that, but isn’t making a radically cheaper version also a new idea that deepseek didn’t know whether it would work? I mean, there was already research into distillation, but there was already research into some of (most of?) OpenAI’s ideas.</div><br/></div></div><div id="42869307" class="c"><input type="checkbox" id="c-42869307" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#42866229">parent</a><span>|</span><a href="#42866537">prev</a><span>|</span><a href="#42869504">next</a><span>|</span><label class="collapse" for="c-42869307">[-]</label><label class="expand" for="c-42869307">[2 more]</label></div><br/><div class="children"><div class="content"><i>The humor&#x2F;hypocrisy of the situation aside, it does seem to be true that OpenAI is consistently the one coming up with new ideas first (GPT 4, o1, 4o-style multimodality, voice chat, DALL-E, …) and then other companies reproduce their work, and get more credit because they actually publish the research</i><p>I claim one just can&#x27;t put the humor&#x2F;hypocrisy aside that easily.<p>What OpenAI did with the release of ChatGPT is productize research that was open and ongoing with Deepmind and other leading at least as much. And everything after that was an extension of the basic approach - improved, expanded but ultimately the same sort of beast. One might even say the situation of OpenAI to DeepMind was like Apple to Xerox. Productizing is nothing to sneeze at - it requires creativity and work to productize basic research. But naturally get end-users who consider the productizers the &quot;fountain heads&quot;, who overestimate the productizers because products are all they see.</div><br/><div id="42871443" class="c"><input type="checkbox" id="c-42871443" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#42866229">root</a><span>|</span><a href="#42869307">parent</a><span>|</span><a href="#42869504">next</a><span>|</span><label class="collapse" for="c-42871443">[-]</label><label class="expand" for="c-42871443">[1 more]</label></div><br/><div class="children"><div class="content">They RLHF&#x27;d first no?</div><br/></div></div></div></div><div id="42869504" class="c"><input type="checkbox" id="c-42869504" checked=""/><div class="controls bullet"><span class="by">mistercheph</span><span>|</span><a href="#42866229">parent</a><span>|</span><a href="#42869307">prev</a><span>|</span><a href="#42866399">next</a><span>|</span><label class="collapse" for="c-42869504">[-]</label><label class="expand" for="c-42869504">[1 more]</label></div><br/><div class="children"><div class="content">Not really, they just put their eye to where everyone knows the ball is going and publish fake &#x2F; cherrypicked results and then pretend like they got there first (o1, gpt voice, sora)</div><br/></div></div><div id="42866399" class="c"><input type="checkbox" id="c-42866399" checked=""/><div class="controls bullet"><span class="by">spencerflem</span><span>|</span><a href="#42866229">parent</a><span>|</span><a href="#42869504">prev</a><span>|</span><a href="#42873648">next</a><span>|</span><label class="collapse" for="c-42866399">[-]</label><label class="expand" for="c-42866399">[2 more]</label></div><br/><div class="children"><div class="content">Fortunately, OpenAI doesn&#x27;t need to make money because they are a nonprofit dedicated to the safe and transparent advancement of AI for all of humanity</div><br/><div id="42867097" class="c"><input type="checkbox" id="c-42867097" checked=""/><div class="controls bullet"><span class="by">mjburgess</span><span>|</span><a href="#42866229">root</a><span>|</span><a href="#42866399">parent</a><span>|</span><a href="#42873648">next</a><span>|</span><label class="collapse" for="c-42867097">[-]</label><label class="expand" for="c-42867097">[1 more]</label></div><br/><div class="children"><div class="content">...somewhere a yacht salesman cried out in terror</div><br/></div></div></div></div></div></div><div id="42873648" class="c"><input type="checkbox" id="c-42873648" checked=""/><div class="controls bullet"><span class="by">alasr</span><span>|</span><a href="#42866229">prev</a><span>|</span><label class="collapse" for="c-42873648">[-]</label><label class="expand" for="c-42873648">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI says it has evidence DeepSeek used its model to train competitor.<p>&gt; The San Francisco-based ChatGPT maker told the Financial Times it had seen some evidence of “distillation”, which it suspects to be from DeepSeek.<p>&gt; ...<p>&gt; OpenAI declined to comment further or provide details of its evidence. Its terms of service state users cannot “copy” any of its services or “use output to develop models that compete with OpenAI”.<p>OAI share the evidence with the public; or, accept the possibility that your <i>case</i> is not as strong as you&#x27;re claiming here.</div><br/></div></div></div></div></div></div></div></body></html>