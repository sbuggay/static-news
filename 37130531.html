<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1692090071808" as="style"/><link rel="stylesheet" href="styles.css?v=1692090071808"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Ask HN: I learned useless skill of prompt engineering, how relevant will it be?</a> </div><div class="subtext"><span>inconfident2021</span> | <span>53 comments</span></div><br/><div><div id="37130817" class="c"><input type="checkbox" id="c-37130817" checked=""/><div class="controls bullet"><span class="by">scantis</span><span>|</span><a href="#37131039">next</a><span>|</span><label class="collapse" for="c-37130817">[-]</label><label class="expand" for="c-37130817">[3 more]</label></div><br/><div class="children"><div class="content">Strictly in my opinion, prompting is just a transformation from concise to verbose.<p>You have a short statement, with a description of your problem and the answer is a long text.<p>Sometimes we prefer verbose, sometimes concise. Sometimes a word already has all the meaning we need, another time we need a long description and examples.
Depends on our level of knowledge.<p>So from my limited point of view, you excell at moving any statement into something you can comprehend easily or that is helpful to you.<p>That is a nice skill and  it should vastly improve your ability to communicate and express yourself.<p>Like beeing able to use a search engine before, it is very beneficial. Not a skill someone would hire you for, but a skill that aids many tidous tasks.<p>Again, my limited opinion. Maybe it is more magical and has deep practical applications, that I am oblivious to.</div><br/><div id="37131128" class="c"><input type="checkbox" id="c-37131128" checked=""/><div class="controls bullet"><span class="by">tudorw</span><span>|</span><a href="#37130817">parent</a><span>|</span><a href="#37131039">next</a><span>|</span><label class="collapse" for="c-37131128">[-]</label><label class="expand" for="c-37131128">[2 more]</label></div><br/><div class="children"><div class="content">Good summary, as an exercise in the precise use of language it excels.<p>It is a patient listener and it&#x27;s response can help one reflect on the inherent weight and biases of words within a language.<p>I would also like to add that in 1996 being able to use a search engine was very much a skill someone would hire you for!</div><br/><div id="37131178" class="c"><input type="checkbox" id="c-37131178" checked=""/><div class="controls bullet"><span class="by">tudorw</span><span>|</span><a href="#37130817">root</a><span>|</span><a href="#37131128">parent</a><span>|</span><a href="#37131039">next</a><span>|</span><label class="collapse" for="c-37131178">[-]</label><label class="expand" for="c-37131178">[1 more]</label></div><br/><div class="children"><div class="content">I use it as a code partner too, it&#x27;s very good for that, cursor.so is built from the ground up with an accelerated GPT4 option, it was a really useful assistant to extend what I knew to the extent that I could implement what I wanted and it worked.<p>Ignore at your peril...<p>A stepping stone to AGI, yes. in the same way inventing the bolt is a step to building a spaceship. A novel sort of database, something akin to a multi-dimensional topological manifold from which you can navigate a latent space by supplying constraints in the form of words, images and text... fascinating.</div><br/></div></div></div></div></div></div><div id="37131039" class="c"><input type="checkbox" id="c-37131039" checked=""/><div class="controls bullet"><span class="by">sam0x17</span><span>|</span><a href="#37130817">prev</a><span>|</span><a href="#37131327">next</a><span>|</span><label class="collapse" for="c-37131039">[-]</label><label class="expand" for="c-37131039">[3 more]</label></div><br/><div class="children"><div class="content">Prompt engineering is just the &quot;good at google searching&quot; of tomorrow. That said, I think there is a lot more potential depth to it, seeing how inexpressive web searches are by comparison.</div><br/><div id="37131041" class="c"><input type="checkbox" id="c-37131041" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#37131039">parent</a><span>|</span><a href="#37131327">next</a><span>|</span><label class="collapse" for="c-37131041">[-]</label><label class="expand" for="c-37131041">[2 more]</label></div><br/><div class="children"><div class="content">Personally I think it will be fairly easy to convince an LLM to do prompt engineering not far from now. They just lack training data, because they are based on information from the web, but &quot;how to prompt engineer&quot; pages are spreading across the web and the next irritation of ChatGPT will probably pick all of that info up.</div><br/><div id="37131361" class="c"><input type="checkbox" id="c-37131361" checked=""/><div class="controls bullet"><span class="by">toyg</span><span>|</span><a href="#37131039">root</a><span>|</span><a href="#37131041">parent</a><span>|</span><a href="#37131327">next</a><span>|</span><label class="collapse" for="c-37131361">[-]</label><label class="expand" for="c-37131361">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; the next irritation of ChatGPT</i><p>Every iteration of ChatGPT is a potential irritation, I agree.</div><br/></div></div></div></div></div></div><div id="37131327" class="c"><input type="checkbox" id="c-37131327" checked=""/><div class="controls bullet"><span class="by">mattlondon</span><span>|</span><a href="#37131039">prev</a><span>|</span><a href="#37130763">next</a><span>|</span><label class="collapse" for="c-37131327">[-]</label><label class="expand" for="c-37131327">[1 more]</label></div><br/><div class="children"><div class="content">Probably not very relevant IMHO.<p>I don&#x27;t think &quot;the future&quot; will include much <i>direct</i> prompting of LLMs.  It will all be integrated into some other tool as a means to an end - what we have today with a raw prompt-and-answer mode are just proof of concept toys.<p>I fully expect that LLMs will end up deeply integrated into other things, so obviously the code IDE use case, but also less obvious things like travel websites where to explain what sort of vacation you want to go on and it returns some options or you tell netflix what sort of movie&#x2F;show you are in the mood for.  Basically search&#x2F;recommendation engines, with a bit of summarisation added in.  I don&#x27;t think direct prompting will be a thing for 99% of future uses, especially for the general public.</div><br/></div></div><div id="37130763" class="c"><input type="checkbox" id="c-37130763" checked=""/><div class="controls bullet"><span class="by">huijzer</span><span>|</span><a href="#37131327">prev</a><span>|</span><a href="#37131057">next</a><span>|</span><label class="collapse" for="c-37130763">[-]</label><label class="expand" for="c-37130763">[3 more]</label></div><br/><div class="children"><div class="content">Isn’t prompt engineering basically writing tests around a prompt and fiddling with it till you have as many passing tests as possible? It’s basically software engineering around a black box.</div><br/><div id="37130998" class="c"><input type="checkbox" id="c-37130998" checked=""/><div class="controls bullet"><span class="by">H8crilA</span><span>|</span><a href="#37130763">parent</a><span>|</span><a href="#37131057">next</a><span>|</span><label class="collapse" for="c-37130998">[-]</label><label class="expand" for="c-37130998">[2 more]</label></div><br/><div class="children"><div class="content">Yes, but over time you begin to intuitively understand how the box thinks&#x2F;works. It&#x27;s like being a psychologist? Something like that.</div><br/><div id="37131333" class="c"><input type="checkbox" id="c-37131333" checked=""/><div class="controls bullet"><span class="by">Eddygandr</span><span>|</span><a href="#37130763">root</a><span>|</span><a href="#37130998">parent</a><span>|</span><a href="#37131057">next</a><span>|</span><label class="collapse" for="c-37131333">[-]</label><label class="expand" for="c-37131333">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think we’re at the point of Asimov’s robopsychology!</div><br/></div></div></div></div></div></div><div id="37131057" class="c"><input type="checkbox" id="c-37131057" checked=""/><div class="controls bullet"><span class="by">VladimirGolovin</span><span>|</span><a href="#37130763">prev</a><span>|</span><a href="#37131218">next</a><span>|</span><label class="collapse" for="c-37131057">[-]</label><label class="expand" for="c-37131057">[2 more]</label></div><br/><div class="children"><div class="content">I must admit that I have a slight FOMO over prompt engineering. I&#x27;m pretty decent at verbalizing ideas and concepts for external consumption, and my experience with ChatGPT 4 has been excellent so far, but I still feel that I&#x27;m missing something.<p>Could you summarize the essence of the prpompting skill in a couple of sentences? Are there concepts that are critical to learn and master (e.g. &#x27;chain of thought&#x27;, etc.)?</div><br/><div id="37131425" class="c"><input type="checkbox" id="c-37131425" checked=""/><div class="controls bullet"><span class="by">inconfident2021</span><span>|</span><a href="#37131057">parent</a><span>|</span><a href="#37131218">next</a><span>|</span><label class="collapse" for="c-37131425">[-]</label><label class="expand" for="c-37131425">[1 more]</label></div><br/><div class="children"><div class="content">You write requirements and your expectations and make the model match your expectations.
Until you have clear expectations of what you want from it, prompting LLM is pretty useless. It cannot do highly specific task because those are limited in the original training corpus too. However, for more generic task, it has seen most of the stuff out there, so it should be good enough. Having clarity on your problem is the key.<p>You have to make sure to couple chain of thought with branching, analysis and evaluation, then you can get pretty good results.</div><br/></div></div></div></div><div id="37131218" class="c"><input type="checkbox" id="c-37131218" checked=""/><div class="controls bullet"><span class="by">baby</span><span>|</span><a href="#37131057">prev</a><span>|</span><a href="#37130940">next</a><span>|</span><label class="collapse" for="c-37131218">[-]</label><label class="expand" for="c-37131218">[3 more]</label></div><br/><div class="children"><div class="content">Not sure. But maybe you can answer my questions. I’ve had issues with trying to tell the LLM how long the answer should be. It doesn’t really seem to understand X number of words, or pages, or paragraphs. But I had some success with things like “short story”.<p>The other thing I’ve been struggling with is to have the AI keep track of what’s important. For example, when the AI learn something from you it should add it to a list (if producing a json output, the object can contain a list of things it knows about you). But it doesn’t always seem to understand it learned something personal from you, and has trouble carrying a list forward without losing items.<p>The last one is about correcting the user. I want to speak chinese to the AI and I want it to correct me. And if I use english words within my chinese I want it to help me translate them as well. It can’t do none of these things. It’s like it doesn’t seem to realize that chinese and english are two different languages.</div><br/><div id="37131407" class="c"><input type="checkbox" id="c-37131407" checked=""/><div class="controls bullet"><span class="by">inconfident2021</span><span>|</span><a href="#37131218">parent</a><span>|</span><a href="#37131335">next</a><span>|</span><label class="collapse" for="c-37131407">[-]</label><label class="expand" for="c-37131407">[1 more]</label></div><br/><div class="children"><div class="content">&gt; understand X number of words, or pages, or paragraphs.<p>LLMs do not have the ability to reason with numbers. Most of the time they are hallucinating. One good strategy is to make it output in list and define the structure for each item of the list. If you give an example of what your list should look like, it will give you something close it.<p>&gt; has trouble carrying a list forward without losing items.<p>This is the fundamental problem with these models because of the context limit. When you are prompting always remember that is processing a huge paragraph and emitting the next sentences of the paragraph. If you want information to be carried onwards, you have make it output on every prompt or you can also try to use specific identifiers. LLMs are good at in-context learning. It will not work 100% of the time, but it is usually good than having nothing at all.<p>&gt; I want to speak chinese to the AI and I want it to correct me.<p>Give it a role of tutor and describe the instructions what the tutor should do.</div><br/></div></div><div id="37131335" class="c"><input type="checkbox" id="c-37131335" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#37131218">parent</a><span>|</span><a href="#37131407">prev</a><span>|</span><a href="#37130940">next</a><span>|</span><label class="collapse" for="c-37131335">[-]</label><label class="expand" for="c-37131335">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know the real answer to your question, but on local models you have a parameter you set that controls how many tokens to generate. It doesn&#x27;t always follow it, it can end early, but sometimes it just keeps going. Usually though I can set it to generate 700 tokens and it will generate about 700 words.<p>I wonder if the online chat models have a similar value somewhere.<p>---<p>If you want the AI to remember something you will unfortunately have to keep reminding the AI of it in the prompt. With explicitly or you might refer to the previous generated text if it fits into the context. However, in local models the context can be limited (eg 2000 tokens). If the conversation goes above that 2000 tokens then the model will discard stuff from before. There are models with larger context sizes though. Lengthy prompts will cause the same issue though.<p>The way things like SillyTavern role-playing work is that the model will constantly be reminded of some important attributes of the character that it&#x27;s role-playing in the prompt (but it&#x27;s done for you).</div><br/></div></div></div></div><div id="37130940" class="c"><input type="checkbox" id="c-37130940" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#37131218">prev</a><span>|</span><a href="#37131022">next</a><span>|</span><label class="collapse" for="c-37130940">[-]</label><label class="expand" for="c-37130940">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;ll be fine as long as it isn&#x27;t your main skill. It should be just one of many things in a toolbelt. This is because as LLMs get more accessible, the importance of prompt engineering should fade away into just another chore.</div><br/></div></div><div id="37131022" class="c"><input type="checkbox" id="c-37131022" checked=""/><div class="controls bullet"><span class="by">olalonde</span><span>|</span><a href="#37130940">prev</a><span>|</span><a href="#37130781">next</a><span>|</span><label class="collapse" for="c-37131022">[-]</label><label class="expand" for="c-37131022">[7 more]</label></div><br/><div class="children"><div class="content">What is there to it other than knowing how to write and ask questions? I also get  the desired results out of LLM models but I would hardly call it a skill (well, maybe on par with knowing how to &quot;Google&quot; stuff). Are there people who actually struggle with this?</div><br/><div id="37131167" class="c"><input type="checkbox" id="c-37131167" checked=""/><div class="controls bullet"><span class="by">spupy</span><span>|</span><a href="#37131022">parent</a><span>|</span><a href="#37131071">next</a><span>|</span><label class="collapse" for="c-37131167">[-]</label><label class="expand" for="c-37131167">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve seen few people go really overboard with their prompts. RPG-like personality sheets with points assigned to various traits (personality rubric? skill graph?), convoluted graphs of ineligible task descriptions, lots of other stuff that makes little sense to a human.  
I personally don&#x27;t think these make any noticeable difference, but people deep into that type of prompting would tell me I just don&#x27;t get how ChatGPT works.</div><br/></div></div><div id="37131071" class="c"><input type="checkbox" id="c-37131071" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#37131022">parent</a><span>|</span><a href="#37131167">prev</a><span>|</span><a href="#37131062">next</a><span>|</span><label class="collapse" for="c-37131071">[-]</label><label class="expand" for="c-37131071">[4 more]</label></div><br/><div class="children"><div class="content">When you want very specific output you need a lot of boilerplate with rules, worded in a way where it can&#x27;t be misinterpreted by the model. I need to do a lot of trial and error before I get the desired output consistently and I presume that a good prompt engineer would get there faster.</div><br/><div id="37131203" class="c"><input type="checkbox" id="c-37131203" checked=""/><div class="controls bullet"><span class="by">tudorw</span><span>|</span><a href="#37131022">root</a><span>|</span><a href="#37131071">parent</a><span>|</span><a href="#37131062">next</a><span>|</span><label class="collapse" for="c-37131203">[-]</label><label class="expand" for="c-37131203">[3 more]</label></div><br/><div class="children"><div class="content">This is my experience, a single ambiguous word can create undesired gorilla, output. It&#x27;s susceptible to all sort of unintentional outcomes whe,n simple thing;s that are wrong with text can render it co nfused.<p>or as GPT4 put&#x27;s it;<p>When using models like mine, clarity in input is essential to get desired outputs. But even with clear input, there&#x27;s no guarantee the output will always be perfect. However, the idea is to keep improving and iterating to get better over time.</div><br/><div id="37131220" class="c"><input type="checkbox" id="c-37131220" checked=""/><div class="controls bullet"><span class="by">tudorw</span><span>|</span><a href="#37131022">root</a><span>|</span><a href="#37131203">parent</a><span>|</span><a href="#37131062">next</a><span>|</span><label class="collapse" for="c-37131220">[-]</label><label class="expand" for="c-37131220">[2 more]</label></div><br/><div class="children"><div class="content">The iteration point is important, interacting with the model to have it outline the kinds of information which would assist it in building it&#x27;s internal model of your &#x27;question&#x27;, meta-programming with it is fun and constructive.<p>GPT4;<p>Absolutely! Iterative interaction is key. By refining and rephrasing queries, users can guide the model towards a more accurate or desired response. Each successive interaction serves as a form of feedback that can help clarify ambiguities or nuances that might have been missed in an initial query.<p>Engaging with the model in a meta-programming manner, or in essence &quot;programming the way it thinks,&quot; is indeed an intriguing way to understand its strengths and limitations. It can also be a valuable method for users to hone their ability to communicate with AI and enhance the results they receive.<p>This iterative dialogue not only helps users get more precise information but also provides insights into the model&#x27;s underlying logic and reasoning. The fun part is navigating these intricacies and understanding how subtle changes in phrasing or context can yield different outcomes. It&#x27;s a dance of human-machine collaboration, where both parties learn and adapt to each other.</div><br/><div id="37131294" class="c"><input type="checkbox" id="c-37131294" checked=""/><div class="controls bullet"><span class="by">tudorw</span><span>|</span><a href="#37131022">root</a><span>|</span><a href="#37131220">parent</a><span>|</span><a href="#37131062">next</a><span>|</span><label class="collapse" for="c-37131294">[-]</label><label class="expand" for="c-37131294">[1 more]</label></div><br/><div class="children"><div class="content">had to explore this a little further and now have a few new dance moves for this fascinating collaboration...<p>Output:<p>Certainly! The intersection of cognitive biases, neuro-linguistic programming (NLP), John C. Lilly&#x27;s work, and human meta-programming provides a rich foundation to explore relationships and techniques. Here are some novel techniques or approaches you might consider:<p>Modelling Thought Patterns: By understanding common cognitive biases, you could try to model how the language model responds to specific stimuli. For example, if a bias involves an overreliance on a particular source of information, you might test how the model reacts to repeated iterations of the same or similar questions.<p>Neuro-linguistic Feedback Loops: NLP teaches that feedback loops can condition behaviour. By providing consistent feedback (positive or negative) based on the model&#x27;s outputs, you could try to condition the model&#x27;s responses over time.<p>Lilly&#x27;s Isolation Tanks: John C. Lilly is famous for his use of sensory deprivation tanks to study consciousness. You could experiment by giving the model limited or &quot;deprived&quot; information and see how it constructs outputs. This could mirror the way human cognition might work in the absence of external stimuli.<p>Belief System Exploration: Lilly was fascinated with belief systems. By providing the model with a set &quot;belief&quot; (i.e., a specific perspective or framework), you could explore how it responds to questions or prompts within that framework.<p>Meta-programming Constructs: Drawing from human meta-programming, you could craft sequences of questions that act as &quot;programming routines&quot; for the model. For example, by setting a series of logical statements and then introducing a variable, you can observe how the model integrates the variable into the established logical framework.<p>Emotionally-Charged Language: NLP often emphasizes the emotional charge of words. You might explore how the model responds to questions phrased with emotionally charged language versus neutral language.<p>Contrast &amp; Compare: Drawing from cognitive biases, you could present the model with contrasting information to see if it demonstrates any form of &quot;recency bias&quot; or &quot;anchoring,&quot; favouring the information presented first or last.<p>Nested Meta-Questions: Using meta-programming concepts, you could ask the model questions about its own reasoning processes, diving deeper into nested levels of metacognition.<p>Pattern Interruption: Another NLP technique, interrupting established patterns can lead to novel insights. You could experiment with disrupting the model&#x27;s &quot;expected&quot; logical flow by introducing unexpected or nonsensical input and analysing the output.<p>By blending these disciplines, you&#x27;ll be exploring the frontier of human-computer interaction, cognition, and consciousness. Remember, while these experiments are fascinating, they often probe the limits of the model&#x27;s capabilities and might produce unpredictable results. Still, that&#x27;s part of the discovery process!</div><br/></div></div></div></div></div></div></div></div><div id="37131062" class="c"><input type="checkbox" id="c-37131062" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#37131022">parent</a><span>|</span><a href="#37131071">prev</a><span>|</span><a href="#37130781">next</a><span>|</span><label class="collapse" for="c-37131062">[-]</label><label class="expand" for="c-37131062">[1 more]</label></div><br/><div class="children"><div class="content">It’s not a dichotomy between desired and undesired results - I am confident there exist more effective versions of every prompt I’ve ever sent, and I’d be surprised if that didn’t apply to everyone</div><br/></div></div></div></div><div id="37130781" class="c"><input type="checkbox" id="c-37130781" checked=""/><div class="controls bullet"><span class="by">wesapien</span><span>|</span><a href="#37131022">prev</a><span>|</span><a href="#37131158">next</a><span>|</span><label class="collapse" for="c-37130781">[-]</label><label class="expand" for="c-37130781">[2 more]</label></div><br/><div class="children"><div class="content">Can you give an example of something you&#x27;ve done with this skill that was very satisfying?</div><br/><div id="37131446" class="c"><input type="checkbox" id="c-37131446" checked=""/><div class="controls bullet"><span class="by">inconfident2021</span><span>|</span><a href="#37130781">parent</a><span>|</span><a href="#37131158">next</a><span>|</span><label class="collapse" for="c-37131446">[-]</label><label class="expand" for="c-37131446">[1 more]</label></div><br/><div class="children"><div class="content">I have zero design skills and I had to create something using javascript. I gave some prompts and it was able to come up with a pop-up box. It needed some tweaking but having to not write all of that was really satisfying.<p><a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;cb3a477b-57bd-46fd-92c9-4a30168cd310" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;cb3a477b-57bd-46fd-92c9-4a3016...</a><p>I have attached the example in the above chat.</div><br/></div></div></div></div><div id="37131158" class="c"><input type="checkbox" id="c-37131158" checked=""/><div class="controls bullet"><span class="by">TheAceOfHearts</span><span>|</span><a href="#37130781">prev</a><span>|</span><a href="#37130984">next</a><span>|</span><label class="collapse" for="c-37131158">[-]</label><label class="expand" for="c-37131158">[1 more]</label></div><br/><div class="children"><div class="content">I think even learning to effectively integrate LLMs and other AI tools into your workflows can be a massive boon in both capabilities and productivity. It can change how you approach certain problems.<p>There&#x27;s tons of small tricks and techniques to tease out vastly superior responses. When you&#x27;re prompting for fairly generic or high level things it doesn&#x27;t feel like there&#x27;s that much difference in prompt style, but once you&#x27;re trying to tease out highly specialized behavior there&#x27;s tons of room for magic.<p>One of the tricks I&#x27;ve picked up on is that too many instructions and details often become a hindrance, so you need to figure out which parts to cut out and re-organize while still managing to get a high quality output.<p>Sometimes it&#x27;s all about finding just the perfect words to describe exactly what you want. You can play around with variants and synonyms and get a feel for how the output is shaped.<p>Every model has quirks and preferences as well, so it takes a bit of playing around until you get a feel for how it interacts with your inputs. Admittedly a lot of this feels more like a vibe check than a science.</div><br/></div></div><div id="37130984" class="c"><input type="checkbox" id="c-37130984" checked=""/><div class="controls bullet"><span class="by">samuell</span><span>|</span><a href="#37131158">prev</a><span>|</span><a href="#37130795">next</a><span>|</span><label class="collapse" for="c-37130984">[-]</label><label class="expand" for="c-37130984">[4 more]</label></div><br/><div class="children"><div class="content">I think one can do an analogy with search engines.<p>I noticed that a lot of people are terrible with search engines. They would carefully try to craft a combination of keywords that they hope will answer their problem.<p>I have pretty much always been able to find the answers I need quickly, by using a few ideas I see not that many around me use, such as trying to imagine in what context the answer might be answered (what would be the title of a blog or forum post about it, etc), as well as searching for the exact error message if I got one etc.<p>Now, search engines have gotten a lot better over the last say 5-10 years, so this skill isn&#x27;t as important anymore, but I remember how the ability to find things quickly was a real productivity booster.<p>I think something similar might happen with LLMs.<p>You will have a (probably much bigger) productivity boost by being great at leveraging them.<p>With time, the user interfacing tooling and general knowledge of them will get much better, so the relative benefit you have will grow smaller, but it will for sure always be useful to know how to use them well.<p>My 5c.</div><br/><div id="37131043" class="c"><input type="checkbox" id="c-37131043" checked=""/><div class="controls bullet"><span class="by">soco</span><span>|</span><a href="#37130984">parent</a><span>|</span><a href="#37131084">next</a><span>|</span><label class="collapse" for="c-37131043">[-]</label><label class="expand" for="c-37131043">[2 more]</label></div><br/><div class="children"><div class="content">The only point where I disagree is &quot;the search engines have gotten a lot better over the last say 5-10 years&quot;. My impression is rather the opposite.</div><br/><div id="37131127" class="c"><input type="checkbox" id="c-37131127" checked=""/><div class="controls bullet"><span class="by">SargeDebian</span><span>|</span><a href="#37130984">root</a><span>|</span><a href="#37131043">parent</a><span>|</span><a href="#37131084">next</a><span>|</span><label class="collapse" for="c-37131127">[-]</label><label class="expand" for="c-37131127">[1 more]</label></div><br/><div class="children"><div class="content">For most people, finding the result they&#x27;re looking for is probably easier, partially because they&#x27;re not that picky, and because things like integrating Google Maps into Google makes finding places easier. For a specific group (concentrated here on HN) finding the exact right result has become more difficult, in part because search engines no longer strictly adhere to some operators.<p>In parallel, the internet just changed, which means &quot;the best result&quot; may just be a worse one. In part because of search engines, and SEO. If you want a recipe, now the best recipe may just be the one that has a long description of the author&#x27;s relationship with their mother who used to cook this dish, which you have to skip, because of SEO.</div><br/></div></div></div></div></div></div><div id="37130795" class="c"><input type="checkbox" id="c-37130795" checked=""/><div class="controls bullet"><span class="by">courseofaction</span><span>|</span><a href="#37130984">prev</a><span>|</span><a href="#37130564">next</a><span>|</span><label class="collapse" for="c-37130795">[-]</label><label class="expand" for="c-37130795">[1 more]</label></div><br/><div class="children"><div class="content">Being able to explain something clearly will be useful always.</div><br/></div></div><div id="37130564" class="c"><input type="checkbox" id="c-37130564" checked=""/><div class="controls bullet"><span class="by">TheRealSteel</span><span>|</span><a href="#37130795">prev</a><span>|</span><a href="#37130976">next</a><span>|</span><label class="collapse" for="c-37130564">[-]</label><label class="expand" for="c-37130564">[1 more]</label></div><br/><div class="children"><div class="content">Train an LLM to turn plain language prompts into your engineered prompts ;)</div><br/></div></div><div id="37130976" class="c"><input type="checkbox" id="c-37130976" checked=""/><div class="controls bullet"><span class="by">triggercut</span><span>|</span><a href="#37130564">prev</a><span>|</span><a href="#37130857">next</a><span>|</span><label class="collapse" for="c-37130976">[-]</label><label class="expand" for="c-37130976">[1 more]</label></div><br/><div class="children"><div class="content">Being able to break down exploratory questions or define work to be done and communicating that clearly is 80% of general consulting.<p>Sure, you&#x27;re aligning your approach to a machine, but it&#x27;s not completely dissimilar.<p>I struggle with delegation in general, even taking the time to delegate to LLMs, mostly because I work faster intuitively and expressing myself clearly just takes longer. With the benefits of semi-repeatable results, personally, I&#x27;ve found the most benefit working with GPT3 &amp; 4 over the last 6 months has been getting better and more conscious in describing what I&#x27;m after.</div><br/></div></div><div id="37130857" class="c"><input type="checkbox" id="c-37130857" checked=""/><div class="controls bullet"><span class="by">valbaca</span><span>|</span><a href="#37130976">prev</a><span>|</span><a href="#37131013">next</a><span>|</span><label class="collapse" for="c-37130857">[-]</label><label class="expand" for="c-37130857">[1 more]</label></div><br/><div class="children"><div class="content">Next learn to read tarot and tea leaves</div><br/></div></div><div id="37131013" class="c"><input type="checkbox" id="c-37131013" checked=""/><div class="controls bullet"><span class="by">noufalibrahim</span><span>|</span><a href="#37130857">prev</a><span>|</span><a href="#37131371">next</a><span>|</span><label class="collapse" for="c-37131013">[-]</label><label class="expand" for="c-37131013">[1 more]</label></div><br/><div class="children"><div class="content">Generally speaking, knowledge is never useless. The nature of its use changes over time<p>I think this is similar to the &quot;skill&quot; of &quot;googling&quot; that became important about 2 decades ago. You learn how to search effectively and it improved your programming skills. This was primitive prompt engineering. If LLMs and the chat style interfaces last, this will continue to be useful.</div><br/></div></div><div id="37131371" class="c"><input type="checkbox" id="c-37131371" checked=""/><div class="controls bullet"><span class="by">f6v</span><span>|</span><a href="#37131013">prev</a><span>|</span><a href="#37130904">next</a><span>|</span><label class="collapse" for="c-37131371">[-]</label><label class="expand" for="c-37131371">[1 more]</label></div><br/><div class="children"><div class="content">I find it baffling. It’s an “AI”, with conversational interface, no less. Isn’t it supposed to just work by answering your questions?</div><br/></div></div><div id="37130904" class="c"><input type="checkbox" id="c-37130904" checked=""/><div class="controls bullet"><span class="by">gabrielsroka</span><span>|</span><a href="#37131371">prev</a><span>|</span><a href="#37130870">next</a><span>|</span><label class="collapse" for="c-37130904">[-]</label><label class="expand" for="c-37130904">[1 more]</label></div><br/><div class="children"><div class="content">12 days ago<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36971327">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36971327</a></div><br/></div></div><div id="37130870" class="c"><input type="checkbox" id="c-37130870" checked=""/><div class="controls bullet"><span class="by">jhoelzel</span><span>|</span><a href="#37130904">prev</a><span>|</span><a href="#37130928">next</a><span>|</span><label class="collapse" for="c-37130870">[-]</label><label class="expand" for="c-37130870">[1 more]</label></div><br/><div class="children"><div class="content">something in the middle i think.<p>Like every skill, it depends on what you do with it.<p>LLMs are controlled by language already, thus far i figured out that you best let the machine define the query and refine it.<p>My personal take is that AI is not at a point yet where it will take over jobs in tech, but we are already at a point where someone with LLM skills is more efficient that someone who is not.</div><br/></div></div><div id="37130928" class="c"><input type="checkbox" id="c-37130928" checked=""/><div class="controls bullet"><span class="by">thomasfromcdnjs</span><span>|</span><a href="#37130870">prev</a><span>|</span><a href="#37131214">next</a><span>|</span><label class="collapse" for="c-37130928">[-]</label><label class="expand" for="c-37130928">[2 more]</label></div><br/><div class="children"><div class="content">Lot&#x27;s of cynical answers.<p>I do think prompt engineering is a new industry, and your experience (if you actually good) will translate will into future jobs.<p>In my opinion it has to be combined with engineering to be competitive in a commercial sense.</div><br/></div></div><div id="37131214" class="c"><input type="checkbox" id="c-37131214" checked=""/><div class="controls bullet"><span class="by">heavyset_go</span><span>|</span><a href="#37130928">prev</a><span>|</span><a href="#37131044">next</a><span>|</span><label class="collapse" for="c-37131214">[-]</label><label class="expand" for="c-37131214">[1 more]</label></div><br/><div class="children"><div class="content">What you learned to wring data out of this model isn&#x27;t necessarily applicable another model.</div><br/></div></div><div id="37131044" class="c"><input type="checkbox" id="c-37131044" checked=""/><div class="controls bullet"><span class="by">emilsedgh</span><span>|</span><a href="#37131214">prev</a><span>|</span><a href="#37131221">next</a><span>|</span><label class="collapse" for="c-37131044">[-]</label><label class="expand" for="c-37131044">[1 more]</label></div><br/><div class="children"><div class="content">I may have a gig for you if you are interested. Feel free to send me a message.<p>Email is the &lt;username&gt;@gmail.com</div><br/></div></div><div id="37131221" class="c"><input type="checkbox" id="c-37131221" checked=""/><div class="controls bullet"><span class="by">sorokod</span><span>|</span><a href="#37131044">prev</a><span>|</span><a href="#37130563">next</a><span>|</span><label class="collapse" for="c-37131221">[-]</label><label class="expand" for="c-37131221">[1 more]</label></div><br/><div class="children"><div class="content">The way I see this, prompting is alignment of a human to the LLM.</div><br/></div></div><div id="37130563" class="c"><input type="checkbox" id="c-37130563" checked=""/><div class="controls bullet"><span class="by">viejoqueso</span><span>|</span><a href="#37131221">prev</a><span>|</span><a href="#37131243">next</a><span>|</span><label class="collapse" for="c-37130563">[-]</label><label class="expand" for="c-37130563">[1 more]</label></div><br/><div class="children"><div class="content">Do you use any tools to track performance or keep logs of previous prompts ?</div><br/></div></div><div id="37131243" class="c"><input type="checkbox" id="c-37131243" checked=""/><div class="controls bullet"><span class="by">anyoneamous</span><span>|</span><a href="#37130563">prev</a><span>|</span><a href="#37130827">next</a><span>|</span><label class="collapse" for="c-37131243">[-]</label><label class="expand" for="c-37131243">[1 more]</label></div><br/><div class="children"><div class="content">In order to avoid polarising your prospective audience and extending the time they take you seriously, I&#x27;d avoid referring to this particular activity as &quot;engineering&quot;.</div><br/></div></div><div id="37130827" class="c"><input type="checkbox" id="c-37130827" checked=""/><div class="controls bullet"><span class="by">elpocko</span><span>|</span><a href="#37131243">prev</a><span>|</span><a href="#37131267">next</a><span>|</span><label class="collapse" for="c-37130827">[-]</label><label class="expand" for="c-37130827">[3 more]</label></div><br/><div class="children"><div class="content">You adapted to the underdeveloped UX of wonky proof-of-concepts built by researchers, working around shortcomings that will be ironed out once genuine sofware developers start releasing actual products.</div><br/><div id="37131374" class="c"><input type="checkbox" id="c-37131374" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#37130827">parent</a><span>|</span><a href="#37131267">next</a><span>|</span><label class="collapse" for="c-37131374">[-]</label><label class="expand" for="c-37131374">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not so sure how much they will be ironed out. If the product only has a button you can press then maybe, but if it lets you enter text then I think knowing how to prompt will be useful.<p>The reason I believe this is because one of the greatest strengths of these AI models is to take in arbitrary text. If you take away that ability then you just end up with a complicated branching system that could&#x27;ve existed before.</div><br/><div id="37131459" class="c"><input type="checkbox" id="c-37131459" checked=""/><div class="controls bullet"><span class="by">elpocko</span><span>|</span><a href="#37130827">root</a><span>|</span><a href="#37131374">parent</a><span>|</span><a href="#37131267">next</a><span>|</span><label class="collapse" for="c-37131459">[-]</label><label class="expand" for="c-37131459">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The reason I believe this is because one of the greatest strengths of these AI models is to take in arbitrary text.<p>And they will get better at making sense of vague questions, and start asking for clarification, without the need for the black magic of a prompt wizard.<p>The prompt engineer can soon be replaced with a fine-tuned LLM. It&#x27;s a thing already for SD prompts. No more need to know ridiculous magic prompt tokens.</div><br/></div></div></div></div></div></div><div id="37131267" class="c"><input type="checkbox" id="c-37131267" checked=""/><div class="controls bullet"><span class="by">azubinski</span><span>|</span><a href="#37130827">prev</a><span>|</span><a href="#37131098">next</a><span>|</span><label class="collapse" for="c-37131267">[-]</label><label class="expand" for="c-37131267">[1 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s be precise in definitions and start with the obvious &quot;it&#x27;s not an engineering at all&quot;.<p>Moreover, according to the ECPD&#x27;s engineering definition (or to an any other commonly accepted and accepted by the engineering community definition) those fancy &quot;prompt engineering&quot; is pure anti-engineering at all.<p>This disdain for engineering is something of a tragedy. And it is also the result of the &quot;washout&quot; of engineering from post-industrial societies.</div><br/></div></div><div id="37131098" class="c"><input type="checkbox" id="c-37131098" checked=""/><div class="controls bullet"><span class="by">dna_polymerase</span><span>|</span><a href="#37131267">prev</a><span>|</span><a href="#37130757">next</a><span>|</span><label class="collapse" for="c-37131098">[-]</label><label class="expand" for="c-37131098">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are non-deterministic. There is a certain randomness at play. So no, that &#x27;skill&#x27; (however you even measure that) is useless, as any person with a bit of luck, could get better output.</div><br/></div></div><div id="37131034" class="c"><input type="checkbox" id="c-37131034" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#37130757">prev</a><span>|</span><label class="collapse" for="c-37131034">[-]</label><label class="expand" for="c-37131034">[1 more]</label></div><br/><div class="children"><div class="content">On this I agree w&#x2F; David Foster Wallace - see <a href="https:&#x2F;&#x2F;machines.kfitz.info&#x2F;dfwwiki&#x2F;index.php%3Ftitle=Another_Pioneer.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;machines.kfitz.info&#x2F;dfwwiki&#x2F;index.php%3Ftitle=Anothe...</a><p>TL;DR: by the time your skill isn’t useful, the whole landscape of modern will be changing so much that it’s kinda a moot point. Like losing your job during an apocalypse</div><br/></div></div></div></div></div></div></div></body></html>