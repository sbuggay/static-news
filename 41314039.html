<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1724317256078" as="style"/><link rel="stylesheet" href="styles.css?v=1724317256078"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="http://cantrip.org/sortfast.html">Do low-level optimizations matter? Faster quicksort with cmov (2020)</a> <span class="domain">(<a href="http://cantrip.org">cantrip.org</a>)</span></div><div class="subtext"><span>fanf2</span> | <span>45 comments</span></div><br/><div><div id="41317192" class="c"><input type="checkbox" id="c-41317192" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#41315534">next</a><span>|</span><label class="collapse" for="c-41317192">[-]</label><label class="expand" for="c-41317192">[1 more]</label></div><br/><div class="children"><div class="content">A correction to the history mentioned in the article: CMOV has not been added by AMD around 2000.<p>CMOV has been added by Intel in 1995, to Pentium Pro. It was the most important addition to the x86 ISA added by Pentium Pro. So CMOV was supported by Pentium Pro and its successors, like Pentium 2 or Pentium III, but it was not supported by Pentium, Pentium with MMX or AMD K6 CPUs. AMD has added CMOV starting with Athlon, in 1999.<p>Pentium Pro was the first Intel CPU with out-of-order execution and it did much more speculative execution than its predecessors. Therefore it had the need for CMOV to limit the performance loss caused by branch mispredictions.</div><br/></div></div><div id="41315534" class="c"><input type="checkbox" id="c-41315534" checked=""/><div class="controls bullet"><span class="by">dgl</span><span>|</span><a href="#41317192">prev</a><span>|</span><a href="#41314797">next</a><span>|</span><label class="collapse" for="c-41315534">[-]</label><label class="expand" for="c-41315534">[10 more]</label></div><br/><div class="children"><div class="content">The most important bit of this is in the conclusion:<p><pre><code>  Before we conclude anything, we should remind ourselves of its limitations. The tests run were on completely random data. Truly random data seldom occurs in real life.
</code></pre>
Linus famously ranted about CMOV in <a href="https:&#x2F;&#x2F;yarchive.net&#x2F;comp&#x2F;linux&#x2F;cmov.html" rel="nofollow">https:&#x2F;&#x2F;yarchive.net&#x2F;comp&#x2F;linux&#x2F;cmov.html</a> (2007, so potentially more modern architectures are better at some of this) and he says:<p><pre><code>  if you KNOW the branch is totally unpredictable, cmov is often good for
  performance. But a compiler almost never knows that.
</code></pre>
As usual with optimizations like this you have to benchmark and even then if your sample isn&#x27;t representative it might not mean much.</div><br/><div id="41318148" class="c"><input type="checkbox" id="c-41318148" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#41315534">parent</a><span>|</span><a href="#41316411">next</a><span>|</span><label class="collapse" for="c-41318148">[-]</label><label class="expand" for="c-41318148">[1 more]</label></div><br/><div class="children"><div class="content">Linus was specifically ranting about compilers inserting CMOV. These days it is actually a pain to get GCC or clang to generate a CMOV when you specifically want it.<p>Also, CMOV did indeed get significantly better.</div><br/></div></div><div id="41316411" class="c"><input type="checkbox" id="c-41316411" checked=""/><div class="controls bullet"><span class="by">tialaramex</span><span>|</span><a href="#41315534">parent</a><span>|</span><a href="#41318148">prev</a><span>|</span><a href="#41316991">next</a><span>|</span><label class="collapse" for="c-41316411">[-]</label><label class="expand" for="c-41316411">[1 more]</label></div><br/><div class="children"><div class="content">You can see how dramatically the actual data changes sort performance in e.g. this (summary of the current unstable sort in Rust, ipnsort)<p><a href="https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;blob&#x2F;main&#x2F;writeup&#x2F;ipnsort_introduction&#x2F;text.md#robust">https:&#x2F;&#x2F;github.com&#x2F;Voultapher&#x2F;sort-research-rs&#x2F;blob&#x2F;main&#x2F;wri...</a><p>Notice how random_s95 is <i>worse</i> (not by much, but it&#x27;s there) than fully random. random_s95 is 95% sorted data, but 5% unsorted, simulating a common &quot;sort, do stuff, append, repeat&quot; pattern we see in a lot of software.<p>In contrast the sorted cases are almost instant, and random_d20 (only 20 distinct values, chosen at random, but as a result the sorted output needs much fewer comparions) is very fast.</div><br/></div></div><div id="41316991" class="c"><input type="checkbox" id="c-41316991" checked=""/><div class="controls bullet"><span class="by">jnordwick</span><span>|</span><a href="#41315534">parent</a><span>|</span><a href="#41316411">prev</a><span>|</span><a href="#41314797">next</a><span>|</span><label class="collapse" for="c-41316991">[-]</label><label class="expand" for="c-41316991">[7 more]</label></div><br/><div class="children"><div class="content">When Linus made that comment cmov was like a 6 cycle latency. For the last decade it has been 1 cycle, and I don&#x27;t think there is any scenario where cmov is now slower than a branch.</div><br/><div id="41317236" class="c"><input type="checkbox" id="c-41317236" checked=""/><div class="controls bullet"><span class="by">haberman</span><span>|</span><a href="#41315534">root</a><span>|</span><a href="#41316991">parent</a><span>|</span><a href="#41317904">next</a><span>|</span><label class="collapse" for="c-41317236">[-]</label><label class="expand" for="c-41317236">[4 more]</label></div><br/><div class="children"><div class="content">The problem is not the 1 cycle latency, but the data dependency on both values.  A correctly-predicted branch cuts the dependency on the value that is not used.<p>I&#x27;ve definitely measured scenarios where cmov&#x2F;branchless is slower than a branch for a given algorithm.  Especially if the branchless version is doing a bit more work to avoid the branch.</div><br/><div id="41317702" class="c"><input type="checkbox" id="c-41317702" checked=""/><div class="controls bullet"><span class="by">unnah</span><span>|</span><a href="#41315534">root</a><span>|</span><a href="#41317236">parent</a><span>|</span><a href="#41317904">next</a><span>|</span><label class="collapse" for="c-41317702">[-]</label><label class="expand" for="c-41317702">[3 more]</label></div><br/><div class="children"><div class="content">Good point. It makes me wonder if modern out-of-order processors can skip performing unused computations altogether, if their result registers are overwritten by other data later (in program order).</div><br/><div id="41318159" class="c"><input type="checkbox" id="c-41318159" checked=""/><div class="controls bullet"><span class="by">gpderetta</span><span>|</span><a href="#41315534">root</a><span>|</span><a href="#41317702">parent</a><span>|</span><a href="#41318109">next</a><span>|</span><label class="collapse" for="c-41318159">[-]</label><label class="expand" for="c-41318159">[1 more]</label></div><br/><div class="children"><div class="content">CPUs could in theory speculate CMOV, reintroducing prediction when predictable. But after Spectre, IIRC Intel now guarantees that CMOV is never speculated.</div><br/></div></div><div id="41318109" class="c"><input type="checkbox" id="c-41318109" checked=""/><div class="controls bullet"><span class="by">ants_a</span><span>|</span><a href="#41315534">root</a><span>|</span><a href="#41317702">parent</a><span>|</span><a href="#41318159">prev</a><span>|</span><a href="#41317904">next</a><span>|</span><label class="collapse" for="c-41318109">[-]</label><label class="expand" for="c-41318109">[1 more]</label></div><br/><div class="children"><div class="content">No, and it feels unlikely that they will either.</div><br/></div></div></div></div></div></div><div id="41317904" class="c"><input type="checkbox" id="c-41317904" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#41315534">root</a><span>|</span><a href="#41316991">parent</a><span>|</span><a href="#41317236">prev</a><span>|</span><a href="#41317828">next</a><span>|</span><label class="collapse" for="c-41317904">[-]</label><label class="expand" for="c-41317904">[1 more]</label></div><br/><div class="children"><div class="content">a cmov-based approach is necessarily slower than a branch-based approach that was correctly predicted, since cmov requires computing both branches then selecting the result at the end.</div><br/></div></div><div id="41317828" class="c"><input type="checkbox" id="c-41317828" checked=""/><div class="controls bullet"><span class="by">clausecker</span><span>|</span><a href="#41315534">root</a><span>|</span><a href="#41316991">parent</a><span>|</span><a href="#41317904">prev</a><span>|</span><a href="#41314797">next</a><span>|</span><label class="collapse" for="c-41317828">[-]</label><label class="expand" for="c-41317828">[1 more]</label></div><br/><div class="children"><div class="content">Are you sure?  I recall cmov always having single cycle latency.</div><br/></div></div></div></div></div></div><div id="41314797" class="c"><input type="checkbox" id="c-41314797" checked=""/><div class="controls bullet"><span class="by">kimixa</span><span>|</span><a href="#41315534">prev</a><span>|</span><a href="#41316993">next</a><span>|</span><label class="collapse" for="c-41314797">[-]</label><label class="expand" for="c-41314797">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Back in 2000, AMD included cmov in its 64-bit x86 ISA extensions. Then, Intel had to adopt them when Itanium flopped.<p>Wasn&#x27;t &quot;cmov&quot; one of the things added for the pentium pro? So it wasn&#x27;t instruction compatible - hence the &quot;i686&quot; prefix to a lot of compiler triples?</div><br/><div id="41315585" class="c"><input type="checkbox" id="c-41315585" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#41314797">parent</a><span>|</span><a href="#41315047">next</a><span>|</span><label class="collapse" for="c-41315585">[-]</label><label class="expand" for="c-41315585">[3 more]</label></div><br/><div class="children"><div class="content">Intel was so embarrassed by the failure of itanium they invented a Time Machine and went back and added the instruction to a 1995 CPU. Deceptive and anti-competitive!</div><br/><div id="41316458" class="c"><input type="checkbox" id="c-41316458" checked=""/><div class="controls bullet"><span class="by">basementcat</span><span>|</span><a href="#41314797">root</a><span>|</span><a href="#41315585">parent</a><span>|</span><a href="#41315047">next</a><span>|</span><label class="collapse" for="c-41316458">[-]</label><label class="expand" for="c-41316458">[2 more]</label></div><br/><div class="children"><div class="content">Intel failed to predict the timeline branch in which i686 arch had cmov so they had to roll back and replay it.</div><br/><div id="41317156" class="c"><input type="checkbox" id="c-41317156" checked=""/><div class="controls bullet"><span class="by">winternewt</span><span>|</span><a href="#41314797">root</a><span>|</span><a href="#41316458">parent</a><span>|</span><a href="#41315047">next</a><span>|</span><label class="collapse" for="c-41317156">[-]</label><label class="expand" for="c-41317156">[1 more]</label></div><br/><div class="children"><div class="content">Also known as Speculative CPU manufacturing</div><br/></div></div></div></div></div></div><div id="41315047" class="c"><input type="checkbox" id="c-41315047" checked=""/><div class="controls bullet"><span class="by">pbsd</span><span>|</span><a href="#41314797">parent</a><span>|</span><a href="#41315585">prev</a><span>|</span><a href="#41316993">next</a><span>|</span><label class="collapse" for="c-41315047">[-]</label><label class="expand" for="c-41315047">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that is correct.</div><br/></div></div></div></div><div id="41316993" class="c"><input type="checkbox" id="c-41316993" checked=""/><div class="controls bullet"><span class="by">orlp</span><span>|</span><a href="#41314797">prev</a><span>|</span><a href="#41314540">next</a><span>|</span><label class="collapse" for="c-41316993">[-]</label><label class="expand" for="c-41316993">[2 more]</label></div><br/><div class="children"><div class="content">Rather than std::swap_if which is rather niche, I would prefer to see std::select(cond, if_true, if_false), with the guarantee that unlike the ternary operator it eagerly evaluates both arguments and selects between them branchlessly if possible.<p>Something similar is coming to Rust as well: <a href="https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;nightly&#x2F;core&#x2F;intrinsics&#x2F;fn.select_unpredictable.html" rel="nofollow">https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;nightly&#x2F;core&#x2F;intrinsics&#x2F;fn.select_...</a></div><br/><div id="41317342" class="c"><input type="checkbox" id="c-41317342" checked=""/><div class="controls bullet"><span class="by">account42</span><span>|</span><a href="#41316993">parent</a><span>|</span><a href="#41314540">next</a><span>|</span><label class="collapse" for="c-41317342">[-]</label><label class="expand" for="c-41317342">[1 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t the sensible lower level primitive be Clang&#x27;s __builtin_unpredictable? If you standardize that then a librry can easily build your select function on top of it. I guess GCC&#x27;s __builtin_expect_with_probability with probabilily 0.5 should have the same meaning.</div><br/></div></div></div></div><div id="41314540" class="c"><input type="checkbox" id="c-41314540" checked=""/><div class="controls bullet"><span class="by">karmakaze</span><span>|</span><a href="#41316993">prev</a><span>|</span><a href="#41314607">next</a><span>|</span><label class="collapse" for="c-41314540">[-]</label><label class="expand" for="c-41314540">[13 more]</label></div><br/><div class="children"><div class="content">I would expect eliminating branches in a busy inner loop to matter.<p>The interesting part is how that was done:<p>&gt; A New Primitive, swap_if<p>&gt; How can we use this method in our sort? First, let us make a swap_if:<p><pre><code>  inline bool swap_if(bool c, int&amp; a, int&amp; b) {
    int ta = a, mask = -c;  &#x2F;&#x2F; false -&gt; 0, true -&gt; 111..111
    a = (b &amp; mask) | (ta &amp; ~mask);
    b = (ta &amp; mask) | (b &amp; ~mask);
    return c;
  }
</code></pre>
&gt; In our partition function, then, we can transform<p><pre><code>    if (*right &lt;= pivot) {
      int tmp = *left; *left = *right, *right = tmp;
      ++left;
    }
</code></pre>
&gt; into just<p><pre><code>    left += swap_if(*right &lt;= pivot, *left, *right);</code></pre></div><br/><div id="41315116" class="c"><input type="checkbox" id="c-41315116" checked=""/><div class="controls bullet"><span class="by">kevinventullo</span><span>|</span><a href="#41314540">parent</a><span>|</span><a href="#41315049">next</a><span>|</span><label class="collapse" for="c-41315116">[-]</label><label class="expand" for="c-41315116">[4 more]</label></div><br/><div class="children"><div class="content">There’s a well-known in-place implementation of swap of the form:<p><pre><code>  a ^= b
  b ^= a
  a ^= b
</code></pre>
(Here ^ denotes bitwise XOR)<p>Allowing for the mask, one could do an in-place version of swap_if via<p><pre><code>  a ^= (b &amp; mask)
  b ^= (a &amp; mask)
  a ^= (b &amp; mask)
</code></pre>
The in-place version of swap is generally discouraged because compilers are smart (<a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;36906&#x2F;what-is-the-fastest-way-to-swap-values-in-c" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;36906&#x2F;what-is-the-fastes...</a>) but I do wonder whether the masking in swap_if obscures intent to the compiler enough to close the gap.<p>Assuming the mask is passed in, Godbolt puts OP’s swap_if at 26 instructions, versus the above swap_if at 17 instructions: <a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;Wedco5hPv" rel="nofollow">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;Wedco5hPv</a></div><br/><div id="41317941" class="c"><input type="checkbox" id="c-41317941" checked=""/><div class="controls bullet"><span class="by">Someone</span><span>|</span><a href="#41314540">root</a><span>|</span><a href="#41315116">parent</a><span>|</span><a href="#41315810">next</a><span>|</span><label class="collapse" for="c-41317941">[-]</label><label class="expand" for="c-41317941">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The in-place version of swap is generally discouraged because compilers are smart<p>Isn’t that more because CPUs slow down when there are dependencies between instructions?<p>Compilers could (and may even do) fairly easily detect that pattern (like they do with some versions of <i>popcnt</i>. See for example <a href="https:&#x2F;&#x2F;langdev.stackexchange.com&#x2F;questions&#x2F;3942&#x2F;what-are-the-ways-compilers-recognize-complex-patterns" rel="nofollow">https:&#x2F;&#x2F;langdev.stackexchange.com&#x2F;questions&#x2F;3942&#x2F;what-are-th...</a>, discussed here in <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40987123">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=40987123</a>) and compile it to whatever is fastest on the target CPU&#x2F;in the given context (in some contexts, it can be compiled to nothing, just changing the mapping between local variables and the registers they’re stored in)</div><br/></div></div><div id="41315810" class="c"><input type="checkbox" id="c-41315810" checked=""/><div class="controls bullet"><span class="by">ack_complete</span><span>|</span><a href="#41314540">root</a><span>|</span><a href="#41315116">parent</a><span>|</span><a href="#41317941">prev</a><span>|</span><a href="#41315049">next</a><span>|</span><label class="collapse" for="c-41315810">[-]</label><label class="expand" for="c-41315810">[2 more]</label></div><br/><div class="children"><div class="content">You have the optimizer disabled and the functions are no-ops. Additionally, masking that way makes the XOR no longer a no-op, so only one masking operation is necessary -- but it seems that GCC already knows this trick:<p><a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;qxMvcbrc8" rel="nofollow">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;qxMvcbrc8</a></div><br/><div id="41316401" class="c"><input type="checkbox" id="c-41316401" checked=""/><div class="controls bullet"><span class="by">kevinventullo</span><span>|</span><a href="#41314540">root</a><span>|</span><a href="#41315810">parent</a><span>|</span><a href="#41315049">next</a><span>|</span><label class="collapse" for="c-41316401">[-]</label><label class="expand" for="c-41316401">[1 more]</label></div><br/><div class="children"><div class="content">Oof, thank you for the correction.</div><br/></div></div></div></div></div></div><div id="41315049" class="c"><input type="checkbox" id="c-41315049" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#41314540">parent</a><span>|</span><a href="#41315116">prev</a><span>|</span><a href="#41315304">next</a><span>|</span><label class="collapse" for="c-41315049">[-]</label><label class="expand" for="c-41315049">[4 more]</label></div><br/><div class="children"><div class="content">Will we see x86 or similar CPUs replace hot instruction blocks with current-processor-specific optimized code during runtime, similar to how certain JIT VMs do?<p>What I mean is, say you have a similar simple &quot;x = (cond) ? a : b;&quot; which the compiler has not translated to a CMOV.<p>If this is in a hot loop then the CPU could, in theory, notice that &quot;it&#x27;s just doing a conditional move, I can do the CMOV faster&quot; and then translate those code bytes at that memory location to a CMOV instead (ie during decoding or something like that).<p>Not worth the complexity? I imagine it would slow down the decoder or wherever they insert this replacement logic. Or am I hopelessly out of date and they&#x27;re already doing this?</div><br/><div id="41315148" class="c"><input type="checkbox" id="c-41315148" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#41314540">root</a><span>|</span><a href="#41315049">parent</a><span>|</span><a href="#41315179">next</a><span>|</span><label class="collapse" for="c-41315148">[-]</label><label class="expand" for="c-41315148">[1 more]</label></div><br/><div class="children"><div class="content">I think it could only do that in spans of code where interrupts are disabled and purely between values already in registers.  CPU state feels like it&#x27;s in your control,  but it&#x27;s not at all in your control,  and even if it was,  multiple processes might exist and memory is never in your control.</div><br/></div></div><div id="41315179" class="c"><input type="checkbox" id="c-41315179" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#41314540">root</a><span>|</span><a href="#41315049">parent</a><span>|</span><a href="#41315148">prev</a><span>|</span><a href="#41316887">next</a><span>|</span><label class="collapse" for="c-41315179">[-]</label><label class="expand" for="c-41315179">[1 more]</label></div><br/><div class="children"><div class="content">Whether to use a branch or a conditional move isn’t really dependent on what the source is doing but how likely the branch is and its dependencies. Simplifying a bit, an explicit cmov is basically telling the computer that the condition is not easy to predict and to not bother. Modern processors will typically do the same analysis themselves and perform similarly on a branch with a slight overhead.</div><br/></div></div><div id="41316887" class="c"><input type="checkbox" id="c-41316887" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#41314540">root</a><span>|</span><a href="#41315049">parent</a><span>|</span><a href="#41315179">prev</a><span>|</span><a href="#41315304">next</a><span>|</span><label class="collapse" for="c-41316887">[-]</label><label class="expand" for="c-41316887">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Will we see x86 or similar CPUs replace hot instruction blocks with current-processor-specific optimized code during runtime, similar to how certain JIT VMs do?<p>Wasn&#x27;t that one of Transmeta&#x27;s things?</div><br/></div></div></div></div><div id="41315304" class="c"><input type="checkbox" id="c-41315304" checked=""/><div class="controls bullet"><span class="by">a_e_k</span><span>|</span><a href="#41314540">parent</a><span>|</span><a href="#41315049">prev</a><span>|</span><a href="#41314607">next</a><span>|</span><label class="collapse" for="c-41315304">[-]</label><label class="expand" for="c-41315304">[4 more]</label></div><br/><div class="children"><div class="content">This sort of use of turning conditionals into bitmasks and then shuffling masked values around was fairly common back in the day when writing code for SSE intrinsics.<p>You wouldn&#x27;t want to have to check each lane individually since that would spoil the point of using SSE.  So you&#x27;d write masking ops like this and keep things parallel, tThen judiciously use any() and all() type intrinsics to check whether the lanes could agree to skip certain blocks conditionally.<p>(This was before ISPC and before autovectorization to handle it for you.)</div><br/><div id="41316371" class="c"><input type="checkbox" id="c-41316371" checked=""/><div class="controls bullet"><span class="by">djmips</span><span>|</span><a href="#41314540">root</a><span>|</span><a href="#41315304">parent</a><span>|</span><a href="#41314607">next</a><span>|</span><label class="collapse" for="c-41316371">[-]</label><label class="expand" for="c-41316371">[3 more]</label></div><br/><div class="children"><div class="content">Does ISPC + auto vectorization truly remove the need to attend to these details in the most optimized code?</div><br/><div id="41317222" class="c"><input type="checkbox" id="c-41317222" checked=""/><div class="controls bullet"><span class="by">a_e_k</span><span>|</span><a href="#41314540">root</a><span>|</span><a href="#41316371">parent</a><span>|</span><a href="#41314607">next</a><span>|</span><label class="collapse" for="c-41317222">[-]</label><label class="expand" for="c-41317222">[2 more]</label></div><br/><div class="children"><div class="content">They can, yes.<p>For example, here&#x27;s a simple Compiler Explorer link with a simple loop conditionally copying from one of two values:<p><a href="https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;TbeK99sx1" rel="nofollow">https:&#x2F;&#x2F;godbolt.org&#x2F;z&#x2F;TbeK99sx1</a>.<p>If you look at the assembly code produced, you&#x27;ll see in lines 9-11, it&#x27;s doing a similar thing as the swap_if() function: ANDing one value with the mask, ANDing the other with the negation of the mask, and then ORing them together.  And it produced that automatically from the ternary in the loop.<p>They can also do things like automatically generate epilogues with a serial loop to handle the leftover items if the loop count isn&#x27;t an even multiple of the SIMD width.  That&#x27;s something else that I remember writing by hand before autovectorizers.<p>That said, coaxing an autovectorizer to actually vectorize a loop can be an art in itself.  They&#x27;re notoriously finicky.  My favorite used to be the one in the old (&quot;classic&quot;) ICC compiler where you use compiler flags to get a nice optimization report which would explain exactly why it chose what it did for each loop.  You could also set #pragma&#x27;s which would noisily warn or error out if the associated loop failed to vectorize for some reason.<p>(And of course, a lot of this stuff you might just use GPU compute for now.)</div><br/><div id="41317945" class="c"><input type="checkbox" id="c-41317945" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#41314540">root</a><span>|</span><a href="#41317222">parent</a><span>|</span><a href="#41314607">next</a><span>|</span><label class="collapse" for="c-41317945">[-]</label><label class="expand" for="c-41317945">[1 more]</label></div><br/><div class="children"><div class="content">normally there is an instruction for this called blend (since SSE4.1).<p>There shouldn&#x27;t be a need to do any bitwise magic.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41314607" class="c"><input type="checkbox" id="c-41314607" checked=""/><div class="controls bullet"><span class="by">memset</span><span>|</span><a href="#41314540">prev</a><span>|</span><a href="#41316098">next</a><span>|</span><label class="collapse" for="c-41314607">[-]</label><label class="expand" for="c-41314607">[6 more]</label></div><br/><div class="children"><div class="content">Fascinating! How does one learn to write C code that will make use of specific asm instructions?<p>SIMDjson is another example that comes to mind. The conceit of C is that you do t have control over the underlying machine instructions without inlining it yourself. So how do people write C code with cpu optimizations like this?</div><br/><div id="41314682" class="c"><input type="checkbox" id="c-41314682" checked=""/><div class="controls bullet"><span class="by">addaon</span><span>|</span><a href="#41314607">parent</a><span>|</span><a href="#41314755">next</a><span>|</span><label class="collapse" for="c-41314682">[-]</label><label class="expand" for="c-41314682">[3 more]</label></div><br/><div class="children"><div class="content">There are three approaches:<p>1) Use intrinsics, if your platform provides intrinsics for the instructions you want to use.<p>2) Use inline assembly (which I suppose doesn&#x27;t technically count as writing C code, but is very much part of the story).<p>3) Write C code carefully against a chosen compiler with chosen optimization flags, and inspect the assembly. Especially for small chunks of code, a tool like godbolt.org is indispensable. Basically, you&#x27;re writing the assembly you want the compiler to generate (either explicitly, or just in your head), then writing C code that seems likely to generate that sequence of instructions, then tweaking the code until the output you want is generated. If this is a super important optimization, it&#x27;s also reasonable to add a build step that inspects the generated assembly and fails the build if it doesn&#x27;t match the desired pattern; but in that case, writing inline assembly is usually easier.</div><br/><div id="41314846" class="c"><input type="checkbox" id="c-41314846" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#41314607">root</a><span>|</span><a href="#41314682">parent</a><span>|</span><a href="#41314755">next</a><span>|</span><label class="collapse" for="c-41314846">[-]</label><label class="expand" for="c-41314846">[2 more]</label></div><br/><div class="children"><div class="content">Option 4 is sometimes compiler annotations like __builtin_expect_with_probability which you could use to assign a branch a value of 50% which should coerce it to pick cmov (same risk as 3 though in that you need to inspect compiler output).</div><br/><div id="41315058" class="c"><input type="checkbox" id="c-41315058" checked=""/><div class="controls bullet"><span class="by">addaon</span><span>|</span><a href="#41314607">root</a><span>|</span><a href="#41314846">parent</a><span>|</span><a href="#41314755">next</a><span>|</span><label class="collapse" for="c-41315058">[-]</label><label class="expand" for="c-41315058">[1 more]</label></div><br/><div class="children"><div class="content">Yep, there&#x27;s an entire book to be written on techniques that you can use to express your understanding of code to the compiler so that the compiler&#x27;s chosen implementation of it matches yours. Plenty of __builtins and __attributes__, and even just the ordering of if&#x2F;else statements, grouping statements into local scopes with {}, using or not using a temporary variable...</div><br/></div></div></div></div></div></div><div id="41314755" class="c"><input type="checkbox" id="c-41314755" checked=""/><div class="controls bullet"><span class="by">adelpozo</span><span>|</span><a href="#41314607">parent</a><span>|</span><a href="#41314682">prev</a><span>|</span><a href="#41314672">next</a><span>|</span><label class="collapse" for="c-41314755">[-]</label><label class="expand" for="c-41314755">[1 more]</label></div><br/><div class="children"><div class="content">I would say it is a moving target if the goal is to write C code that compiles to a seemingly magical cpu instruction. As other have pointed out, learning assembly and compiler explorer are useful things.<p>As a way to show the wonderful complexities of compilers check the TOC of <a href="https:&#x2F;&#x2F;shop.elsevier.com&#x2F;books&#x2F;optimizing-compilers-for-modern-architectures&#x2F;allen&#x2F;978-0-08-051324-9" rel="nofollow">https:&#x2F;&#x2F;shop.elsevier.com&#x2F;books&#x2F;optimizing-compilers-for-mod...</a></div><br/></div></div><div id="41314672" class="c"><input type="checkbox" id="c-41314672" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#41314607">parent</a><span>|</span><a href="#41314755">prev</a><span>|</span><a href="#41316098">next</a><span>|</span><label class="collapse" for="c-41314672">[-]</label><label class="expand" for="c-41314672">[1 more]</label></div><br/><div class="children"><div class="content">Use inline assembly or intrinsics. Read the code of stuff that does these things.<p>Resources sufficient for implementing simdjson or similar vectorized parsers: <a href="https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;docs&#x2F;intrinsics-guide&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;docs&#x2F;intrinsics-guid...</a> <a href="https:&#x2F;&#x2F;lemire.me&#x2F;blog&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lemire.me&#x2F;blog&#x2F;</a> <a href="http:&#x2F;&#x2F;0x80.pl&#x2F;articles&#x2F;" rel="nofollow">http:&#x2F;&#x2F;0x80.pl&#x2F;articles&#x2F;</a></div><br/></div></div></div></div><div id="41316098" class="c"><input type="checkbox" id="c-41316098" checked=""/><div class="controls bullet"><span class="by">xiaodai</span><span>|</span><a href="#41314607">prev</a><span>|</span><a href="#41315722">next</a><span>|</span><label class="collapse" for="c-41316098">[-]</label><label class="expand" for="c-41316098">[2 more]</label></div><br/><div class="children"><div class="content">The radix sort implementation is not optimal. Instead of sorting 1 digit at a time, it should be sorting 11 digits at a time to saturate the cache lines.<p>So the baseline radix sort can be even faster.</div><br/><div id="41316691" class="c"><input type="checkbox" id="c-41316691" checked=""/><div class="controls bullet"><span class="by">djmips</span><span>|</span><a href="#41316098">parent</a><span>|</span><a href="#41315722">next</a><span>|</span><label class="collapse" for="c-41316691">[-]</label><label class="expand" for="c-41316691">[1 more]</label></div><br/><div class="children"><div class="content">From the article - &quot;This radix sort would be easy to make even faster. Instead, let us make one that is slower&quot;<p>The radix sort was used to provide an estimate for how much better the quicksort could improve.</div><br/></div></div></div></div><div id="41315722" class="c"><input type="checkbox" id="c-41315722" checked=""/><div class="controls bullet"><span class="by">pcwalton</span><span>|</span><a href="#41316098">prev</a><span>|</span><a href="#41317633">next</a><span>|</span><label class="collapse" for="c-41315722">[-]</label><label class="expand" for="c-41315722">[2 more]</label></div><br/><div class="children"><div class="content">Note that random data is not a common case for sorting algorithms. It&#x27;d be interesting to see how the numbers change on partially-, mostly-, and fully-sorted data.</div><br/><div id="41315922" class="c"><input type="checkbox" id="c-41315922" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#41315722">parent</a><span>|</span><a href="#41317633">next</a><span>|</span><label class="collapse" for="c-41315922">[-]</label><label class="expand" for="c-41315922">[1 more]</label></div><br/><div class="children"><div class="content">the article does mention this:<p>&gt; <i>What can we conclude from this discovery? Before we conclude anything, we should remind ourselves of its limitations. The tests run were on completely random data. Truly random data seldom occurs in real life. </i><p>it&#x27;s true that it&#x27;s not a common case, but it&#x27;s probably the simplest objectively justifiable case; any particular case of the others requires more elaborate justification for privileging it.  why 90% sorted instead of 80%, say?  or why do we give 20% weighting to the randomized-data case and 80% weighting to the 90%-sorted case, rather than some other weighting?<p>and it does at least guarantee exploration of a good part of the algorithm&#x27;s behavior space.  i mean, bogosort is optimal on fully-sorted data, right?  as long as you do the check for sortedness before the random shuffle instead of after it<p>it&#x27;s important that your sort not <i>explode</i> on mostly-sorted or mostly-reverse-sorted data (myers&#x27;s &#x27;bog-standard quicksort&#x27; uses the last element as the pivot and consequently goes quadratic), but beyond that, the particular weighting of relative importance to assign to random input vs. 99% sorted vs. 90% sorted vs. 90% reverse sorted—that requires some application-specific justification<p>aside from the ones you mentioned, another interesting case is a large array of records that all have equal keys.  median-of-three quicksort or random-pivot quicksort does fine on mostly- or fully-sorted data, but still sucks when everything is equal!</div><br/></div></div></div></div><div id="41317633" class="c"><input type="checkbox" id="c-41317633" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#41315722">prev</a><span>|</span><a href="#41314483">next</a><span>|</span><label class="collapse" for="c-41317633">[-]</label><label class="expand" for="c-41317633">[1 more]</label></div><br/><div class="children"><div class="content">Heh, nice!  This article reminded me of a great talk I recently noticed:<p>Rethinking Binary Search: Improving on a Classic with AI Assistance: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=FAGf5Xr8HZU" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=FAGf5Xr8HZU</a><p>The gist is rather simple: Assuming that a substiantial amount of your searches results in <i>no result</i>, you can bias the binary search to jump farther then just half, improving runtime noticeably.</div><br/></div></div><div id="41314483" class="c"><input type="checkbox" id="c-41314483" checked=""/><div class="controls bullet"><span class="by">mbroncano</span><span>|</span><a href="#41317633">prev</a><span>|</span><a href="#41314930">next</a><span>|</span><label class="collapse" for="c-41314483">[-]</label><label class="expand" for="c-41314483">[1 more]</label></div><br/><div class="children"><div class="content">(2020)</div><br/></div></div></div></div></div></div></div></body></html>