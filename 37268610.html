<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1693040458787" as="style"/><link rel="stylesheet" href="styles.css?v=1693040458787"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="http://karpathy.github.io/2022/03/14/lecun1989/">Deep Neural Nets: 33 years ago and 33 years from now (2022)</a> <span class="domain">(<a href="http://karpathy.github.io">karpathy.github.io</a>)</span></div><div class="subtext"><span>gsky</span> | <span>26 comments</span></div><br/><div><div id="37270484" class="c"><input type="checkbox" id="c-37270484" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#37268776">next</a><span>|</span><label class="collapse" for="c-37270484">[-]</label><label class="expand" for="c-37270484">[3 more]</label></div><br/><div class="children"><div class="content">Something else I find exciting, starting with one of the reflections-<p>The original training took 3 days on a Sun 4&#x2F;260 workstation; I can&#x27;t find specifics but I believe that era of early SPARC workstations would likely pull about 200 watts in total (the CPU wasn&#x27;t super high powered but the whole system, running with the disks and the monitor etc would pull about that).<p>So 200 watts * 72 hours = 14400 watt-hours of energy.<p>Karpathy trained the equivalent on a Macbook, not even fully utilized, in 90 seconds.  Likely something around 20 watts * 0.025 hours = 0.5 watt-hours.<p>An energy efficiency improvement of nearly 30000x.</div><br/><div id="37270524" class="c"><input type="checkbox" id="c-37270524" checked=""/><div class="controls bullet"><span class="by">fouronnes3</span><span>|</span><a href="#37270484">parent</a><span>|</span><a href="#37270820">next</a><span>|</span><label class="collapse" for="c-37270524">[-]</label><label class="expand" for="c-37270524">[1 more]</label></div><br/><div class="children"><div class="content">This is very interesting, because I&#x27;ve always thought that all NN performance should be measured in a unit with  energy in the denominator.</div><br/></div></div><div id="37270820" class="c"><input type="checkbox" id="c-37270820" checked=""/><div class="controls bullet"><span class="by">Aardwolf</span><span>|</span><a href="#37270484">parent</a><span>|</span><a href="#37270524">prev</a><span>|</span><a href="#37268776">next</a><span>|</span><label class="collapse" for="c-37270820">[-]</label><label class="expand" for="c-37270820">[1 more]</label></div><br/><div class="children"><div class="content">30k doesn&#x27;t even sound like that much to me given Moore&#x27;s law. I&#x27;d expect more improvement since 1989. Supercomputer performance increased more than a million since then</div><br/></div></div></div></div><div id="37268776" class="c"><input type="checkbox" id="c-37268776" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#37270484">prev</a><span>|</span><a href="#37270805">next</a><span>|</span><label class="collapse" for="c-37268776">[-]</label><label class="expand" for="c-37268776">[7 more]</label></div><br/><div class="children"><div class="content">This was really good. The only thing I didn&#x27;t see explicitly discussed, although I guess it&#x27;s obvious, is that what&#x27;s different 33 years later is the inputs the models operate on. The &#x27;89 sota model used 16x16 greyscale images, today we have single digit megapixel color images, in 30 years, a desktop will be able to train Clip in 90 seconds, but what will the sota models be trained on?</div><br/><div id="37270790" class="c"><input type="checkbox" id="c-37270790" checked=""/><div class="controls bullet"><span class="by">ramblerman</span><span>|</span><a href="#37268776">parent</a><span>|</span><a href="#37269717">next</a><span>|</span><label class="collapse" for="c-37270790">[-]</label><label class="expand" for="c-37270790">[1 more]</label></div><br/><div class="children"><div class="content">Millions of hours of data captured by headsets like the vision pro?<p>Not sure all the things it captures, but a model could be trained on the combination of audio&#x2F;video&#x2F;spatial&#x2F;iris&#x2F;what have you...</div><br/></div></div><div id="37269717" class="c"><input type="checkbox" id="c-37269717" checked=""/><div class="controls bullet"><span class="by">retrac</span><span>|</span><a href="#37268776">parent</a><span>|</span><a href="#37270790">prev</a><span>|</span><a href="#37270805">next</a><span>|</span><label class="collapse" for="c-37269717">[-]</label><label class="expand" for="c-37269717">[5 more]</label></div><br/><div class="children"><div class="content">Human behaviour in a way far more general than which token we might next type.  To mimick humans as closely as might be possible with the basic deep learning method, train something that can predict human behaviour in general.  Training would require billions to quadrillions of hours of video and audio and probably many other inputs, from many different people, engaged in the full variety of human activity.</div><br/><div id="37269995" class="c"><input type="checkbox" id="c-37269995" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#37268776">root</a><span>|</span><a href="#37269717">parent</a><span>|</span><a href="#37270805">next</a><span>|</span><label class="collapse" for="c-37269995">[-]</label><label class="expand" for="c-37269995">[4 more]</label></div><br/><div class="children"><div class="content">Why? An adult by 25 only has 146k hours of video experience “training,” most of it repeated, derivative, and unproductive. And their encoded genes can be observed in their genome, so don’t need to be retrained by millions of years of evolution.</div><br/><div id="37270346" class="c"><input type="checkbox" id="c-37270346" checked=""/><div class="controls bullet"><span class="by">thaw13579</span><span>|</span><a href="#37268776">root</a><span>|</span><a href="#37269995">parent</a><span>|</span><a href="#37270268">next</a><span>|</span><label class="collapse" for="c-37270346">[-]</label><label class="expand" for="c-37270346">[1 more]</label></div><br/><div class="children"><div class="content">Much of that time also includes physical interaction with the world, which makes it far more valuable because it can improve performance in a focused way.</div><br/></div></div><div id="37270268" class="c"><input type="checkbox" id="c-37270268" checked=""/><div class="controls bullet"><span class="by">alanbernstein</span><span>|</span><a href="#37268776">root</a><span>|</span><a href="#37269995">parent</a><span>|</span><a href="#37270346">prev</a><span>|</span><a href="#37270094">next</a><span>|</span><label class="collapse" for="c-37270268">[-]</label><label class="expand" for="c-37270268">[1 more]</label></div><br/><div class="children"><div class="content">How better to learn to do menial physical tasks like house cleaning, and produce picking?</div><br/></div></div></div></div></div></div></div></div><div id="37268912" class="c"><input type="checkbox" id="c-37268912" checked=""/><div class="controls bullet"><span class="by">alexmuro</span><span>|</span><a href="#37270805">prev</a><span>|</span><a href="#37270025">next</a><span>|</span><label class="collapse" for="c-37268912">[-]</label><label class="expand" for="c-37268912">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s crazy how little has changed and how much had changed. I remember what a revelation &quot;the unreasonable effectiveness of RNNs&quot; was when I was read it and it feels like we live in a different world.</div><br/><div id="37269188" class="c"><input type="checkbox" id="c-37269188" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#37268912">parent</a><span>|</span><a href="#37270025">next</a><span>|</span><label class="collapse" for="c-37269188">[-]</label><label class="expand" for="c-37269188">[1 more]</label></div><br/><div class="children"><div class="content">I think we could collectively more constructive and sober conversation if we kept that 2015 bit of work as a sort of baseline.<p>The new stuff is better, by a lot, and with implications more to come.<p>But those of us paying attention then had a frame of reference where “so much better it’s crazy” still stops short of “it’s out of control”.<p>It’s a lot better.</div><br/></div></div></div></div><div id="37270025" class="c"><input type="checkbox" id="c-37270025" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#37268912">prev</a><span>|</span><a href="#37269125">next</a><span>|</span><label class="collapse" for="c-37270025">[-]</label><label class="expand" for="c-37270025">[2 more]</label></div><br/><div class="children"><div class="content">The most fundamental change is the difference in <i>what</i> models are being trained on.<p>Little images of characters is a trivia type problem, very different from training on the linguistic and visual communication of essentially the whole human race.<p>Another 33 years of expanded computing resources won’t be training models to mimic the behavior and knowledge of humanity.<p>That problem (<i>us!</i>) will have been reduced to a toy problem long before then.</div><br/><div id="37270794" class="c"><input type="checkbox" id="c-37270794" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#37270025">parent</a><span>|</span><a href="#37269125">next</a><span>|</span><label class="collapse" for="c-37270794">[-]</label><label class="expand" for="c-37270794">[1 more]</label></div><br/><div class="children"><div class="content">I think AI models will evolve by generating synthetic data, filtering and improving it, and then retraining. Possibly  with external systems in the loop - code execution, search, human, simulation or robot. Quality won&#x27;t degrade because there will be a lot of effort put into data filtering and diversity. We can always improve on a model by giving it more time.<p>Model architecture doesn&#x27;t matter compared to the dataset. Any model from a class can learn the same skills from the same data, but change the data and they all change their abilities - the intelligence is in the data.<p>The future is data engineering, not model architecturing.
Human culture, by analogy, evolves faster  than human biology. The data is evolving faster than the model. And we are seeing a drastic reduction in novel architectures in AI, diverse datasets applied to the same transformer models in recent years. Even among the transformers, very few variants are largely used, thousands of them abandoned.<p>I like to think of it as language evolution by memetics being the real engine behind intelligence. We and AI are riding the language exponential together.</div><br/></div></div></div></div><div id="37269125" class="c"><input type="checkbox" id="c-37269125" checked=""/><div class="controls bullet"><span class="by">bilsbie</span><span>|</span><a href="#37270025">prev</a><span>|</span><a href="#37269060">next</a><span>|</span><label class="collapse" for="c-37269125">[-]</label><label class="expand" for="c-37269125">[2 more]</label></div><br/><div class="children"><div class="content">It’s interesting in that time we almost completely lost interest in neural networks and then came back around to them.</div><br/><div id="37270373" class="c"><input type="checkbox" id="c-37270373" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#37269125">parent</a><span>|</span><a href="#37269060">next</a><span>|</span><label class="collapse" for="c-37270373">[-]</label><label class="expand" for="c-37270373">[1 more]</label></div><br/><div class="children"><div class="content">I had to retake my AI class at university several times because I just didn’t agree on the “AI is symbolic search” aspect.<p>Now though, I’m sure people are taking LLMs and putting them together to do forward and backward chaining.</div><br/></div></div></div></div><div id="37269060" class="c"><input type="checkbox" id="c-37269060" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#37269125">prev</a><span>|</span><a href="#37270191">next</a><span>|</span><label class="collapse" for="c-37269060">[-]</label><label class="expand" for="c-37269060">[1 more]</label></div><br/><div class="children"><div class="content">Related:<p><i>Deep Neural Nets: 33 years ago and 33 years from now</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30673821">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30673821</a> - March 2022 (5 comments)</div><br/></div></div><div id="37270191" class="c"><input type="checkbox" id="c-37270191" checked=""/><div class="controls bullet"><span class="by">fnord77</span><span>|</span><a href="#37269060">prev</a><span>|</span><a href="#37269653">next</a><span>|</span><label class="collapse" for="c-37270191">[-]</label><label class="expand" for="c-37270191">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Our datasets and models today [2055] look like a joke. Both are somewhere around 10,000,000X larger.<p>will there really be 10 million times 400 million images floating around then?</div><br/><div id="37270799" class="c"><input type="checkbox" id="c-37270799" checked=""/><div class="controls bullet"><span class="by">ramblerman</span><span>|</span><a href="#37270191">parent</a><span>|</span><a href="#37270376">next</a><span>|</span><label class="collapse" for="c-37270799">[-]</label><label class="expand" for="c-37270799">[1 more]</label></div><br/><div class="children"><div class="content">I think you are limiting yourself by thinking of the dataset of the future as just being more and bigger images.<p>Perhaps it will be trained on whole videos, or a combination of different inputs from agents that move about in the real world &#x2F; or a video game.</div><br/></div></div><div id="37270376" class="c"><input type="checkbox" id="c-37270376" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#37270191">parent</a><span>|</span><a href="#37270799">prev</a><span>|</span><a href="#37269653">next</a><span>|</span><label class="collapse" for="c-37270376">[-]</label><label class="expand" for="c-37270376">[4 more]</label></div><br/><div class="children"><div class="content">Generate as many as you need.</div><br/><div id="37270716" class="c"><input type="checkbox" id="c-37270716" checked=""/><div class="controls bullet"><span class="by">alpaca128</span><span>|</span><a href="#37270191">root</a><span>|</span><a href="#37270376">parent</a><span>|</span><a href="#37270379">next</a><span>|</span><label class="collapse" for="c-37270716">[-]</label><label class="expand" for="c-37270716">[2 more]</label></div><br/><div class="children"><div class="content">Training models from generated content degrades them over time.</div><br/><div id="37270867" class="c"><input type="checkbox" id="c-37270867" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#37270191">root</a><span>|</span><a href="#37270716">parent</a><span>|</span><a href="#37270379">next</a><span>|</span><label class="collapse" for="c-37270867">[-]</label><label class="expand" for="c-37270867">[1 more]</label></div><br/><div class="children"><div class="content">Yet science fiction pushes civilization towards novelty</div><br/></div></div></div></div><div id="37270379" class="c"><input type="checkbox" id="c-37270379" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#37270191">root</a><span>|</span><a href="#37270376">parent</a><span>|</span><a href="#37270716">prev</a><span>|</span><a href="#37269653">next</a><span>|</span><label class="collapse" for="c-37270379">[-]</label><label class="expand" for="c-37270379">[1 more]</label></div><br/><div class="children"><div class="content">Oh, also curious… today, how many individual image frames from video are there just from Tesla vehicles?</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>