<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1727341275470" as="style"/><link rel="stylesheet" href="styles.css?v=1727341275470"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/miramurati/status/1839025700009030027">Mira Murati leaves OpenAI</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>brianjking</span> | <span>365 comments</span></div><br/><div><div id="41651210" class="c"><input type="checkbox" id="c-41651210" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#41652023">next</a><span>|</span><label class="collapse" for="c-41651210">[-]</label><label class="expand" for="c-41651210">[237 more]</label></div><br/><div class="children"><div class="content">It is hard for me to square &quot;This company is a few short years away from building world-changing AGI&quot; and &quot;I&#x27;m stepping away to do my own thing&quot;. Maybe I&#x27;m just bad at putting myself in someone else&#x27;s shoes, but I feel like if I had spent years working towards a vision of AGI, and thought that success was finally just around the corner, it&#x27;d be very difficult to walk away.</div><br/><div id="41651562" class="c"><input type="checkbox" id="c-41651562" checked=""/><div class="controls bullet"><span class="by">lacker</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651350">next</a><span>|</span><label class="collapse" for="c-41651562">[-]</label><label class="expand" for="c-41651562">[47 more]</label></div><br/><div class="children"><div class="content">It&#x27;s easy to have missed this part of the story in all the chaos, but from the NYTimes in March:<p><i>Ms. Murati wrote a private memo to Mr. Altman raising questions about his management and also shared her concerns with the board. That move helped to propel the board’s decision to force him out.</i><p><a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;03&#x2F;07&#x2F;technology&#x2F;openai-executives-role-in-sam-altman-ouster.html" rel="nofollow">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;03&#x2F;07&#x2F;technology&#x2F;openai-executi...</a><p>It should be no surprise if Sam Altman wants executives who opposed his leadership, like Mira and Ilya, out of the company. When you&#x27;re firing a high-level executive in a polite way, it&#x27;s common to let them announce their own departure and frame it the way they want.</div><br/><div id="41651724" class="c"><input type="checkbox" id="c-41651724" checked=""/><div class="controls bullet"><span class="by">startupsfail</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651562">parent</a><span>|</span><a href="#41652213">next</a><span>|</span><label class="collapse" for="c-41651724">[-]</label><label class="expand" for="c-41651724">[38 more]</label></div><br/><div class="children"><div class="content">Greg Brockman, OpenAI President and co-founder is also on extended leave of absence.<p>And John Schulman, and Peter Deng are out already. Yet the company is still shipping, like no other. Recent multimodal integrations and benchmarks of o1 are outstanding.</div><br/><div id="41651928" class="c"><input type="checkbox" id="c-41651928" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651724">parent</a><span>|</span><a href="#41652669">next</a><span>|</span><label class="collapse" for="c-41651928">[-]</label><label class="expand" for="c-41651928">[5 more]</label></div><br/><div class="children"><div class="content">&gt;  Yet the company is still shipping, like no other<p>If executives &#x2F; high level architects &#x2F; researchers are working on this quarter&#x27;s features something is very wrong. The higher you get the more ahead you need to be working, C-level departures should only have an impact about a year down the line, at a company of this size.</div><br/><div id="41653636" class="c"><input type="checkbox" id="c-41653636" checked=""/><div class="controls bullet"><span class="by">mise_en_place</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651928">parent</a><span>|</span><a href="#41651964">next</a><span>|</span><label class="collapse" for="c-41653636">[-]</label><label class="expand" for="c-41653636">[2 more]</label></div><br/><div class="children"><div class="content">Funny, at every corporation I&#x27;ve worked for, every department was still working on <i>last</i> quarter&#x27;s features. FAANG included.</div><br/><div id="41653927" class="c"><input type="checkbox" id="c-41653927" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653636">parent</a><span>|</span><a href="#41651964">next</a><span>|</span><label class="collapse" for="c-41653927">[-]</label><label class="expand" for="c-41653927">[1 more]</label></div><br/><div class="children"><div class="content">That’s exactly what they were saying. The department are operating behind the executives.</div><br/></div></div></div></div><div id="41651964" class="c"><input type="checkbox" id="c-41651964" checked=""/><div class="controls bullet"><span class="by">ttcbj</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651928">parent</a><span>|</span><a href="#41653636">prev</a><span>|</span><a href="#41653076">next</a><span>|</span><label class="collapse" for="c-41651964">[-]</label><label class="expand" for="c-41651964">[1 more]</label></div><br/><div class="children"><div class="content">This is a good point.  I had not thought of it this way before.</div><br/></div></div><div id="41653076" class="c"><input type="checkbox" id="c-41653076" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651928">parent</a><span>|</span><a href="#41651964">prev</a><span>|</span><a href="#41652669">next</a><span>|</span><label class="collapse" for="c-41653076">[-]</label><label class="expand" for="c-41653076">[1 more]</label></div><br/><div class="children"><div class="content">You may find that this is true in many companies.</div><br/></div></div></div></div><div id="41652669" class="c"><input type="checkbox" id="c-41652669" checked=""/><div class="controls bullet"><span class="by">ac29</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651724">parent</a><span>|</span><a href="#41651928">prev</a><span>|</span><a href="#41654525">next</a><span>|</span><label class="collapse" for="c-41652669">[-]</label><label class="expand" for="c-41652669">[4 more]</label></div><br/><div class="children"><div class="content">&gt; the company is still shipping, like no other<p>Meta, Anthropic, Google, and others all are shipping state of the art models.<p>I&#x27;m not trying to be dismissive of OpenAI&#x27;s work, but they are absolutely not the only company shipping very large foundation models.</div><br/><div id="41654023" class="c"><input type="checkbox" id="c-41654023" checked=""/><div class="controls bullet"><span class="by">g8oz</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652669">parent</a><span>|</span><a href="#41652880">next</a><span>|</span><label class="collapse" for="c-41654023">[-]</label><label class="expand" for="c-41654023">[1 more]</label></div><br/><div class="children"><div class="content">Indeed Anthropic is just as good, if not better in my sample size of one. Which is great because OpenAI as an org gives shady vibes - maybe it&#x27;s just Altman, but he is running the show.</div><br/></div></div><div id="41652880" class="c"><input type="checkbox" id="c-41652880" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652669">parent</a><span>|</span><a href="#41654023">prev</a><span>|</span><a href="#41654525">next</a><span>|</span><label class="collapse" for="c-41652880">[-]</label><label class="expand" for="c-41652880">[2 more]</label></div><br/><div class="children"><div class="content">Perhaps you havent tried o1-preview or advanced voice if you call all the rest SOTA.</div><br/><div id="41653092" class="c"><input type="checkbox" id="c-41653092" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652880">parent</a><span>|</span><a href="#41654525">next</a><span>|</span><label class="collapse" for="c-41653092">[-]</label><label class="expand" for="c-41653092">[1 more]</label></div><br/><div class="children"><div class="content">If only they’d release the advanced voice thing as an API. Their TTS is already pretty good, but ai wouldn’t say no to an improvement.</div><br/></div></div></div></div></div></div><div id="41654525" class="c"><input type="checkbox" id="c-41654525" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651724">parent</a><span>|</span><a href="#41652669">prev</a><span>|</span><a href="#41653808">next</a><span>|</span><label class="collapse" for="c-41654525">[-]</label><label class="expand" for="c-41654525">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Yet the company is still shipping, like no other.<p>I don&#x27;t see it for OpenAI, I do see it for the competition. They have shipped incremental improvements, however, they are watering down their current models (my guess is they are trying to save on compute?). Copilot has turned into garbage and for coding related stuff, Claude is now better than gpt-4.<p>Honestly, their outlook is bleak.</div><br/><div id="41655570" class="c"><input type="checkbox" id="c-41655570" checked=""/><div class="controls bullet"><span class="by">benterix</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41654525">parent</a><span>|</span><a href="#41653808">next</a><span>|</span><label class="collapse" for="c-41655570">[-]</label><label class="expand" for="c-41655570">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I have the same feeling. It seems like operating GPT-4 is too expensive, so they decided to call it &quot;legacy&quot; and get rid of it soon, and instead focus on cheaper&#x2F;faster 4o, and also chain its prompts to call it a new model.<p>I understand why they are doing it, but honestly if they cancel GPT-4, many people will just cancel their subscription.</div><br/></div></div></div></div><div id="41653808" class="c"><input type="checkbox" id="c-41653808" checked=""/><div class="controls bullet"><span class="by">moondistance</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651724">parent</a><span>|</span><a href="#41654525">prev</a><span>|</span><a href="#41653236">next</a><span>|</span><label class="collapse" for="c-41653808">[-]</label><label class="expand" for="c-41653808">[1 more]</label></div><br/><div class="children"><div class="content">VP Research Barret Zoph and Chief Research Officer Bob McGrew also announced their departures this evening.</div><br/></div></div><div id="41653236" class="c"><input type="checkbox" id="c-41653236" checked=""/><div class="controls bullet"><span class="by">RobertDeNiro</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651724">parent</a><span>|</span><a href="#41653808">prev</a><span>|</span><a href="#41653860">next</a><span>|</span><label class="collapse" for="c-41653236">[-]</label><label class="expand" for="c-41653236">[3 more]</label></div><br/><div class="children"><div class="content">Greg’s wife is pretty sick. For all we know this is unrelated to the drama.</div><br/><div id="41653960" class="c"><input type="checkbox" id="c-41653960" checked=""/><div class="controls bullet"><span class="by">theGnuMe</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653236">parent</a><span>|</span><a href="#41653860">next</a><span>|</span><label class="collapse" for="c-41653960">[-]</label><label class="expand" for="c-41653960">[2 more]</label></div><br/><div class="children"><div class="content">Sorry to hear that, all the best wishes to them.</div><br/><div id="41655400" class="c"><input type="checkbox" id="c-41655400" checked=""/><div class="controls bullet"><span class="by">imdsm</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653960">parent</a><span>|</span><a href="#41653860">next</a><span>|</span><label class="collapse" for="c-41655400">[-]</label><label class="expand" for="c-41655400">[1 more]</label></div><br/><div class="children"><div class="content">Context (I think): <a href="https:&#x2F;&#x2F;x.com&#x2F;gdb&#x2F;status&#x2F;1744446603962765669" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;gdb&#x2F;status&#x2F;1744446603962765669</a><p>Big fan of Greg, and I think the motivation behind AGI is sound here. Even what we have now is a fantastic tool, if people decide to use it.</div><br/></div></div></div></div></div></div><div id="41653860" class="c"><input type="checkbox" id="c-41653860" checked=""/><div class="controls bullet"><span class="by">vicentwu</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651724">parent</a><span>|</span><a href="#41653236">prev</a><span>|</span><a href="#41653937">next</a><span>|</span><label class="collapse" for="c-41653860">[-]</label><label class="expand" for="c-41653860">[1 more]</label></div><br/><div class="children"><div class="content">Past efforts leds to today&#x27;s products. We need to wait to see the real imapct on the ability to ship.</div><br/></div></div><div id="41653937" class="c"><input type="checkbox" id="c-41653937" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651724">parent</a><span>|</span><a href="#41653860">prev</a><span>|</span><a href="#41655144">next</a><span>|</span><label class="collapse" for="c-41653937">[-]</label><label class="expand" for="c-41653937">[6 more]</label></div><br/><div class="children"><div class="content">&gt; like no other<p>Really? Anthropic seems to be popping off right now.<p>Kagi isn’t exactly in the AI space, but they ship features pretty frequently.<p>OpenAI is shipping incremental improvements to its chatgpt product.</div><br/><div id="41654016" class="c"><input type="checkbox" id="c-41654016" checked=""/><div class="controls bullet"><span class="by">jjtheblunt</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653937">parent</a><span>|</span><a href="#41655144">next</a><span>|</span><label class="collapse" for="c-41654016">[-]</label><label class="expand" for="c-41654016">[5 more]</label></div><br/><div class="children"><div class="content">&quot;popping off&quot; means what?</div><br/><div id="41654712" class="c"><input type="checkbox" id="c-41654712" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41654016">parent</a><span>|</span><a href="#41655493">next</a><span>|</span><label class="collapse" for="c-41654712">[-]</label><label class="expand" for="c-41654712">[3 more]</label></div><br/><div class="children"><div class="content">Modern colloquialism generally meaning Moving&#x2F;advancing&#x2F;growing&#x2F;gaining popularity very fast</div><br/><div id="41655136" class="c"><input type="checkbox" id="c-41655136" checked=""/><div class="controls bullet"><span class="by">elbear</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41654712">parent</a><span>|</span><a href="#41655493">next</a><span>|</span><label class="collapse" for="c-41655136">[-]</label><label class="expand" for="c-41655136">[2 more]</label></div><br/><div class="children"><div class="content">Are they? In my recent experience, ChatGPT seems to have gotten better than Claude again. Plus their free limit is more strict, so this experience is on the free account.</div><br/><div id="41655307" class="c"><input type="checkbox" id="c-41655307" checked=""/><div class="controls bullet"><span class="by">0xKromo</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41655136">parent</a><span>|</span><a href="#41655493">next</a><span>|</span><label class="collapse" for="c-41655307">[-]</label><label class="expand" for="c-41655307">[1 more]</label></div><br/><div class="children"><div class="content">Its just tribalism. People tend to find a team to root for when there is a competition. Which one is better is subjective at this point imo.</div><br/></div></div></div></div></div></div><div id="41655493" class="c"><input type="checkbox" id="c-41655493" checked=""/><div class="controls bullet"><span class="by">jpeg-irl</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41654016">parent</a><span>|</span><a href="#41654712">prev</a><span>|</span><a href="#41655144">next</a><span>|</span><label class="collapse" for="c-41655493">[-]</label><label class="expand" for="c-41655493">[1 more]</label></div><br/><div class="children"><div class="content">The features shipped by Anthropic in the past month are far more practical and provide clear value for builders than o1&#x27;s chain of thought improvements.<p>- Prompt Cache, 90% savings on large system prompts for 5 mins of calls. This is amazing<p>- Contexual RAG, while not ground breaking idea, is important thinking and method for better vector retrieval</div><br/></div></div></div></div></div></div><div id="41655144" class="c"><input type="checkbox" id="c-41655144" checked=""/><div class="controls bullet"><span class="by">mistercheph</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651724">parent</a><span>|</span><a href="#41653937">prev</a><span>|</span><a href="#41651855">next</a><span>|</span><label class="collapse" for="c-41655144">[-]</label><label class="expand" for="c-41655144">[1 more]</label></div><br/><div class="children"><div class="content">In my humble opinion you&#x27;re wrong, Sora and 4o voice are months old and no signs they&#x27;re not vaporware, and they still haven&#x27;t shipped a text model on par with 3.5 sonnet!</div><br/></div></div><div id="41651844" class="c"><input type="checkbox" id="c-41651844" checked=""/><div class="controls bullet"><span class="by">fairity</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651724">parent</a><span>|</span><a href="#41651960">prev</a><span>|</span><a href="#41652213">next</a><span>|</span><label class="collapse" for="c-41651844">[-]</label><label class="expand" for="c-41651844">[3 more]</label></div><br/><div class="children"><div class="content">Quite interesting that this comment is downvoted when the content is factually correct and pertinent.<p>It&#x27;s a very relevant fact that Greg Brockman recently left on his own volition.<p>Greg was aligned with Sam during the coup.  So, the fact that Greg left lends more credence to the idea that Murati is leaving on her own volition.</div><br/><div id="41652020" class="c"><input type="checkbox" id="c-41652020" checked=""/><div class="controls bullet"><span class="by">frakkingcylons</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651844">parent</a><span>|</span><a href="#41652677">next</a><span>|</span><label class="collapse" for="c-41652020">[-]</label><label class="expand" for="c-41652020">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a very relevant fact that Greg Brockman recently left on his own volition.<p>Except that isn’t true. He has not resigned from OpenAI. He’s on extended leave until the end of the year.<p>That could become an official resignation later, and I agree that that seems more likely than not. But stating that he’s left for good as of right now is misleading.</div><br/></div></div><div id="41652677" class="c"><input type="checkbox" id="c-41652677" checked=""/><div class="controls bullet"><span class="by">meiraleal</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651844">parent</a><span>|</span><a href="#41652020">prev</a><span>|</span><a href="#41652213">next</a><span>|</span><label class="collapse" for="c-41652677">[-]</label><label class="expand" for="c-41652677">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Quite interesting that this comment is downvoted when the content is factually correct and pertinent.<p>&gt;&gt; Yet the company is still shipping, like no other.<p>this is factually wrong. Just today Meta (which I despise) shipped more than openAI in a long time.</div><br/></div></div></div></div></div></div><div id="41652213" class="c"><input type="checkbox" id="c-41652213" checked=""/><div class="controls bullet"><span class="by">SkyMarshal</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651562">parent</a><span>|</span><a href="#41651724">prev</a><span>|</span><a href="#41653334">next</a><span>|</span><label class="collapse" for="c-41652213">[-]</label><label class="expand" for="c-41652213">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; When you&#x27;re firing a high-level executive in a polite way, it&#x27;s common to let them announce their own departure and frame it the way they want.</i><p>You also give them some distance in time from the drama so the two appear unconnected under cursory inspection.</div><br/></div></div><div id="41653334" class="c"><input type="checkbox" id="c-41653334" checked=""/><div class="controls bullet"><span class="by">SadTrombone</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651562">parent</a><span>|</span><a href="#41652213">prev</a><span>|</span><a href="#41651931">next</a><span>|</span><label class="collapse" for="c-41653334">[-]</label><label class="expand" for="c-41653334">[5 more]</label></div><br/><div class="children"><div class="content">To be fair she was also one of the employees who signed the letter to the board demanding that Altman be reinstated or she would leave the company.</div><br/><div id="41654136" class="c"><input type="checkbox" id="c-41654136" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653334">parent</a><span>|</span><a href="#41653350">next</a><span>|</span><label class="collapse" for="c-41654136">[-]</label><label class="expand" for="c-41654136">[2 more]</label></div><br/><div class="children"><div class="content">Does that actually mean anything? Didn&#x27;t 95% of the company sign that letter, and soon afterwards many employees stated that they felt pressured by a vocal minority of peers and supervisors to sign the letter? E.g. if most executives on her level already signed the letter, it would have been political suicide not to sign it</div><br/><div id="41655744" class="c"><input type="checkbox" id="c-41655744" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41654136">parent</a><span>|</span><a href="#41653350">next</a><span>|</span><label class="collapse" for="c-41655744">[-]</label><label class="expand" for="c-41655744">[1 more]</label></div><br/><div class="children"><div class="content">She was second-in-command of the company. Who else is there on her level to pressure her to sign such a thing, besides Sam himself?</div><br/></div></div></div></div><div id="41653350" class="c"><input type="checkbox" id="c-41653350" checked=""/><div class="controls bullet"><span class="by">bradleyjg</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653334">parent</a><span>|</span><a href="#41654136">prev</a><span>|</span><a href="#41651931">next</a><span>|</span><label class="collapse" for="c-41653350">[-]</label><label class="expand" for="c-41653350">[2 more]</label></div><br/><div class="children"><div class="content">Isn’t that even worse? You write to the board, they take action on your complaints, and then you change your mind?</div><br/><div id="41653513" class="c"><input type="checkbox" id="c-41653513" checked=""/><div class="controls bullet"><span class="by">barkingcat</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653350">parent</a><span>|</span><a href="#41651931">next</a><span>|</span><label class="collapse" for="c-41653513">[-]</label><label class="expand" for="c-41653513">[1 more]</label></div><br/><div class="children"><div class="content">It means when she was opting for the reinstating of Altman, she didn&#x27;t have all the information needed to make a decsion<p>Now that she&#x27;s seen exactly what prompted the previous board to fire Altman, she fires herself because she understands their decision now.</div><br/></div></div></div></div></div></div><div id="41653409" class="c"><input type="checkbox" id="c-41653409" checked=""/><div class="controls bullet"><span class="by">mempko</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651562">parent</a><span>|</span><a href="#41651931">prev</a><span>|</span><a href="#41651350">next</a><span>|</span><label class="collapse" for="c-41653409">[-]</label><label class="expand" for="c-41653409">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, Sam Altman wants group think, no opposition, no diversity of thought. That&#x27;s what petty dictators demand. This spells the end of OpenAI IMO. Huge amount of money will keep it going until it doesn&#x27;t</div><br/></div></div></div></div><div id="41651350" class="c"><input type="checkbox" id="c-41651350" checked=""/><div class="controls bullet"><span class="by">aresant</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651562">prev</a><span>|</span><a href="#41651317">next</a><span>|</span><label class="collapse" for="c-41651350">[-]</label><label class="expand" for="c-41651350">[58 more]</label></div><br/><div class="children"><div class="content">I think the much more likely scenario than product roadmap concerns is that Murati (and Ilya for that matter) took their shot to remove Sam, lost, and in an effort to collectively retain billion$ of enterprise value have been playing nice, but were never seriously going to work together again after the failed coup.</div><br/><div id="41651716" class="c"><input type="checkbox" id="c-41651716" checked=""/><div class="controls bullet"><span class="by">deepGem</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651350">parent</a><span>|</span><a href="#41651702">next</a><span>|</span><label class="collapse" for="c-41651716">[-]</label><label class="expand" for="c-41651716">[21 more]</label></div><br/><div class="children"><div class="content">Why is it so hard to just accept this and be transparent about motives ? It&#x27;s fair to say &#x27;we were not aligned with Sam, we tried an ouster, didn&#x27;t pan out so the best thing for us to do is to leave and let Sam pursue his path&quot;, which the entirely company has vouched for.<p>Instead, you get to see grey area after grey area.</div><br/><div id="41651941" class="c"><input type="checkbox" id="c-41651941" checked=""/><div class="controls bullet"><span class="by">jjulius</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651716">parent</a><span>|</span><a href="#41654935">next</a><span>|</span><label class="collapse" for="c-41651941">[-]</label><label class="expand" for="c-41651941">[9 more]</label></div><br/><div class="children"><div class="content">Because, for some weird reason, our culture has collectively decided that, even if most of us are capable of reading between the lines to understand what&#x27;s <i>really</i> being said or is happening, it&#x27;s often wrong and bad to be honest and transparent, and we should put the most positive spin possible on it. It&#x27;s everywhere, especially in professional and political environments.</div><br/><div id="41655822" class="c"><input type="checkbox" id="c-41655822" checked=""/><div class="controls bullet"><span class="by">bergen</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651941">parent</a><span>|</span><a href="#41653108">next</a><span>|</span><label class="collapse" for="c-41655822">[-]</label><label class="expand" for="c-41655822">[1 more]</label></div><br/><div class="children"><div class="content">This is not a culture thing imo, being honest and transparent makes you vulnerable to exploits, which is often a bad thing for the ones being honest and transparent in a high competition area.</div><br/></div></div><div id="41653108" class="c"><input type="checkbox" id="c-41653108" checked=""/><div class="controls bullet"><span class="by">discordance</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651941">parent</a><span>|</span><a href="#41655822">prev</a><span>|</span><a href="#41654609">next</a><span>|</span><label class="collapse" for="c-41653108">[-]</label><label class="expand" for="c-41653108">[2 more]</label></div><br/><div class="children"><div class="content">For a counter example of what open and transparent communincation from a C-level tech person could look like, have a read of what the SpaCy founder blogged about a few months ago:<p><a href="https:&#x2F;&#x2F;honnibal.dev&#x2F;blog&#x2F;back-to-our-roots" rel="nofollow">https:&#x2F;&#x2F;honnibal.dev&#x2F;blog&#x2F;back-to-our-roots</a></div><br/><div id="41655409" class="c"><input type="checkbox" id="c-41655409" checked=""/><div class="controls bullet"><span class="by">vincnetas</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653108">parent</a><span>|</span><a href="#41654609">next</a><span>|</span><label class="collapse" for="c-41655409">[-]</label><label class="expand" for="c-41655409">[1 more]</label></div><br/><div class="children"><div class="content">Stakes are orders of magnitude lower in spaCy case compared to OpenAI (for announcer and for people around them). It&#x27;s easier to just be yourself when you&#x27;re back on square one.</div><br/></div></div></div></div><div id="41654609" class="c"><input type="checkbox" id="c-41654609" checked=""/><div class="controls bullet"><span class="by">lotsofpulp</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651941">parent</a><span>|</span><a href="#41653108">prev</a><span>|</span><a href="#41651975">next</a><span>|</span><label class="collapse" for="c-41654609">[-]</label><label class="expand" for="c-41654609">[1 more]</label></div><br/><div class="children"><div class="content">It is human nature to use plausible deniability to play politics and fool one’s self or others.  You will get better results in negotiations if you allow the opposing party to maintain face (i.e. ego).<p>See flirting as a more basic example.</div><br/></div></div><div id="41651975" class="c"><input type="checkbox" id="c-41651975" checked=""/><div class="controls bullet"><span class="by">FactKnower69</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651941">parent</a><span>|</span><a href="#41654609">prev</a><span>|</span><a href="#41655006">next</a><span>|</span><label class="collapse" for="c-41651975">[-]</label><label class="expand" for="c-41651975">[3 more]</label></div><br/><div class="children"><div class="content">McKinsey MBA brain rot seeping into all levels of culture</div><br/><div id="41652643" class="c"><input type="checkbox" id="c-41652643" checked=""/><div class="controls bullet"><span class="by">cedws</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651975">parent</a><span>|</span><a href="#41655006">next</a><span>|</span><label class="collapse" for="c-41652643">[-]</label><label class="expand" for="c-41652643">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s giving too much credit to McKinsey. I&#x27;d argue it&#x27;s systemic brainrot. Never admit mistakes, never express yourself, never be honest. Just make up as much bullshit as possible on the fly, say whatever you have to pacify people. Even just say bullshit 24&#x2F;7.<p>Not to dunk on Mira Murati, because this note is pretty cookie cutter, but it exemplifies this perfectly. It says nothing about her motivations for resigning. It bends over backwards to kiss the asses of the people she&#x27;s leaving behind. It could ultimately be condensed into two words: &quot;I&#x27;ve resigned.&quot;</div><br/><div id="41654894" class="c"><input type="checkbox" id="c-41654894" checked=""/><div class="controls bullet"><span class="by">Earw0rm</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652643">parent</a><span>|</span><a href="#41655006">next</a><span>|</span><label class="collapse" for="c-41654894">[-]</label><label class="expand" for="c-41654894">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a management culture which is almost colonial in nature, and seeks to differentiate itself from a &quot;labor class&quot; which is already highly educated.<p>Never spook the horses. Never show the team, or the public, what&#x27;s going on behind the curtain.. or even that there is anything going on. At all time present the appearance of a swan gliding serenely across a lake.<p>Because if you show humanity, those other humans might cotton on to the fact that you&#x27;re not much different to them, and have done little to earn or justify your position of authority.<p>And that wouldn&#x27;t do at all.</div><br/></div></div></div></div></div></div><div id="41655006" class="c"><input type="checkbox" id="c-41655006" checked=""/><div class="controls bullet"><span class="by">kyawzazaw</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651941">parent</a><span>|</span><a href="#41651975">prev</a><span>|</span><a href="#41654935">next</a><span>|</span><label class="collapse" for="c-41655006">[-]</label><label class="expand" for="c-41655006">[1 more]</label></div><br/><div class="children"><div class="content">not for two sigma</div><br/></div></div></div></div><div id="41654935" class="c"><input type="checkbox" id="c-41654935" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651716">parent</a><span>|</span><a href="#41651941">prev</a><span>|</span><a href="#41651782">next</a><span>|</span><label class="collapse" for="c-41654935">[-]</label><label class="expand" for="c-41654935">[1 more]</label></div><br/><div class="children"><div class="content">People, including East Asians, frequently claim &quot;face&quot; is an East Asian cultural concept despite the fact that it is omnipresent in all cultures. It doesn&#x27;t matter if outsiders have figured out what&#x27;s actually going on. The only thing that matters is saving face.</div><br/></div></div><div id="41651782" class="c"><input type="checkbox" id="c-41651782" checked=""/><div class="controls bullet"><span class="by">startupsfail</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651716">parent</a><span>|</span><a href="#41654935">prev</a><span>|</span><a href="#41651750">next</a><span>|</span><label class="collapse" for="c-41651782">[-]</label><label class="expand" for="c-41651782">[1 more]</label></div><br/><div class="children"><div class="content">“the entire company has vouched for” is inconsistent with what we see now.  Low&#x2F;mid ranking employees were obviously tweeting in alignment with their management and by request.</div><br/></div></div><div id="41651750" class="c"><input type="checkbox" id="c-41651750" checked=""/><div class="controls bullet"><span class="by">widowlark</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651716">parent</a><span>|</span><a href="#41651782">prev</a><span>|</span><a href="#41651774">next</a><span>|</span><label class="collapse" for="c-41651750">[-]</label><label class="expand" for="c-41651750">[1 more]</label></div><br/><div class="children"><div class="content">id imagine that level of honesty could still lead to billions lost in shareholder value - thus the grey area. Market obfuscation is a real thing.</div><br/></div></div><div id="41651774" class="c"><input type="checkbox" id="c-41651774" checked=""/><div class="controls bullet"><span class="by">stagger87</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651716">parent</a><span>|</span><a href="#41651750">prev</a><span>|</span><a href="#41655079">next</a><span>|</span><label class="collapse" for="c-41651774">[-]</label><label class="expand" for="c-41651774">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s in nobodies best interest to do this especially when there is so much money at play.</div><br/><div id="41651921" class="c"><input type="checkbox" id="c-41651921" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651774">parent</a><span>|</span><a href="#41655079">next</a><span>|</span><label class="collapse" for="c-41651921">[-]</label><label class="expand" for="c-41651921">[2 more]</label></div><br/><div class="children"><div class="content">A bit ironic for a non-profit</div><br/><div id="41652498" class="c"><input type="checkbox" id="c-41652498" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651921">parent</a><span>|</span><a href="#41655079">next</a><span>|</span><label class="collapse" for="c-41652498">[-]</label><label class="expand" for="c-41652498">[1 more]</label></div><br/><div class="children"><div class="content">As I understand they are going to be stop being non-profit soonish now?</div><br/></div></div></div></div></div></div><div id="41655079" class="c"><input type="checkbox" id="c-41655079" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651716">parent</a><span>|</span><a href="#41651774">prev</a><span>|</span><a href="#41651935">next</a><span>|</span><label class="collapse" for="c-41655079">[-]</label><label class="expand" for="c-41655079">[1 more]</label></div><br/><div class="children"><div class="content">We lie about our successes why would we not lie about our failures?</div><br/></div></div><div id="41652486" class="c"><input type="checkbox" id="c-41652486" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651716">parent</a><span>|</span><a href="#41651935">prev</a><span>|</span><a href="#41651702">next</a><span>|</span><label class="collapse" for="c-41652486">[-]</label><label class="expand" for="c-41652486">[3 more]</label></div><br/><div class="children"><div class="content">Because if you are a high level executive and you are transparent on those things, and if it backfires, it will backfire hard for your future opportunities, since all the companies will view you as a potential liability. So it is always safer and wiser option to not say anything in case of any risk of it backfiring. So you do the polite PR messaging every single time. There&#x27;s nothing to be gained on the individual level of being transparent, only to be risked.</div><br/><div id="41652828" class="c"><input type="checkbox" id="c-41652828" checked=""/><div class="controls bullet"><span class="by">deepGem</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652486">parent</a><span>|</span><a href="#41651702">next</a><span>|</span><label class="collapse" for="c-41652828">[-]</label><label class="expand" for="c-41652828">[2 more]</label></div><br/><div class="children"><div class="content">I doubt someone with Mira or Ilya’s calibre have to worry about future opportunities. They can very well craft their own opportunities.<p>Saying I was wrong should not be this complicated, or saying we failed.<p>I do however agree that there is nothing to be gained and everything to be risked. So why do it.</div><br/><div id="41653158" class="c"><input type="checkbox" id="c-41653158" checked=""/><div class="controls bullet"><span class="by">dh2022</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652828">parent</a><span>|</span><a href="#41651702">next</a><span>|</span><label class="collapse" for="c-41653158">[-]</label><label class="expand" for="c-41653158">[1 more]</label></div><br/><div class="children"><div class="content">Their (Ilya and Mira) perspective on anything is so far remote from your (and my) perspectives that trying to understand their personal feelings behind their resignation is an enterprise doomed to failure.</div><br/></div></div></div></div></div></div></div></div><div id="41651702" class="c"><input type="checkbox" id="c-41651702" checked=""/><div class="controls bullet"><span class="by">bookofjoe</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651350">parent</a><span>|</span><a href="#41651716">prev</a><span>|</span><a href="#41651481">next</a><span>|</span><label class="collapse" for="c-41651702">[-]</label><label class="expand" for="c-41651702">[9 more]</label></div><br/><div class="children"><div class="content">&quot;When you strike at a king, you must kill him.&quot; — Emerson</div><br/><div id="41651918" class="c"><input type="checkbox" id="c-41651918" checked=""/><div class="controls bullet"><span class="by">sllewe</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651702">parent</a><span>|</span><a href="#41653585">next</a><span>|</span><label class="collapse" for="c-41651918">[-]</label><label class="expand" for="c-41651918">[6 more]</label></div><br/><div class="children"><div class="content">or an alternate - &quot;Come at the king - you best not miss&quot; -- Omar Little.</div><br/><div id="41653582" class="c"><input type="checkbox" id="c-41653582" checked=""/><div class="controls bullet"><span class="by">timy2shoes</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651918">parent</a><span>|</span><a href="#41653537">next</a><span>|</span><label class="collapse" for="c-41653582">[-]</label><label class="expand" for="c-41653582">[3 more]</label></div><br/><div class="children"><div class="content">“the King stay the King.” —- D’Angelo Barksdale</div><br/><div id="41654592" class="c"><input type="checkbox" id="c-41654592" checked=""/><div class="controls bullet"><span class="by">sirspacey</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653582">parent</a><span>|</span><a href="#41653537">next</a><span>|</span><label class="collapse" for="c-41654592">[-]</label><label class="expand" for="c-41654592">[2 more]</label></div><br/><div class="children"><div class="content">“Original King Julius is on the line.” - Sacha Baron Cohen</div><br/><div id="41654964" class="c"><input type="checkbox" id="c-41654964" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41654592">parent</a><span>|</span><a href="#41653537">next</a><span>|</span><label class="collapse" for="c-41654964">[-]</label><label class="expand" for="c-41654964">[1 more]</label></div><br/><div class="children"><div class="content">King <i>Julien</i></div><br/></div></div></div></div></div></div><div id="41653537" class="c"><input type="checkbox" id="c-41653537" checked=""/><div class="controls bullet"><span class="by">macintux</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651918">parent</a><span>|</span><a href="#41653582">prev</a><span>|</span><a href="#41652227">next</a><span>|</span><label class="collapse" for="c-41653537">[-]</label><label class="expand" for="c-41653537">[1 more]</label></div><br/><div class="children"><div class="content">“How do you shoot the devil in the back? What if you miss?”</div><br/></div></div><div id="41652227" class="c"><input type="checkbox" id="c-41652227" checked=""/><div class="controls bullet"><span class="by">ionwake</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651918">parent</a><span>|</span><a href="#41653537">prev</a><span>|</span><a href="#41653585">next</a><span>|</span><label class="collapse" for="c-41652227">[-]</label><label class="expand" for="c-41652227">[1 more]</label></div><br/><div class="children"><div class="content">the real OG comment here</div><br/></div></div></div></div><div id="41653585" class="c"><input type="checkbox" id="c-41653585" checked=""/><div class="controls bullet"><span class="by">ropable</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651702">parent</a><span>|</span><a href="#41651918">prev</a><span>|</span><a href="#41651807">next</a><span>|</span><label class="collapse" for="c-41653585">[-]</label><label class="expand" for="c-41653585">[1 more]</label></div><br/><div class="children"><div class="content">&quot;When you play the game of thrones, you win or you die.&quot; - Cersei Lannister</div><br/></div></div><div id="41651807" class="c"><input type="checkbox" id="c-41651807" checked=""/><div class="controls bullet"><span class="by">dangitman</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651702">parent</a><span>|</span><a href="#41653585">prev</a><span>|</span><a href="#41651481">next</a><span>|</span><label class="collapse" for="c-41651807">[-]</label><label class="expand" for="c-41651807">[1 more]</label></div><br/><div class="children"><div class="content">&quot;You come at the king, you best not miss.&quot; - Omar</div><br/></div></div></div></div><div id="41651481" class="c"><input type="checkbox" id="c-41651481" checked=""/><div class="controls bullet"><span class="by">bg24</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651350">parent</a><span>|</span><a href="#41651702">prev</a><span>|</span><a href="#41651415">next</a><span>|</span><label class="collapse" for="c-41651481">[-]</label><label class="expand" for="c-41651481">[1 more]</label></div><br/><div class="children"><div class="content">This is the likely scenario. Every conflict at exec level comes with a &quot;messaging&quot; aspect, with there being a comms team, and board to manage that part.</div><br/></div></div><div id="41651415" class="c"><input type="checkbox" id="c-41651415" checked=""/><div class="controls bullet"><span class="by">amenhotep</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651350">parent</a><span>|</span><a href="#41651481">prev</a><span>|</span><a href="#41651545">next</a><span>|</span><label class="collapse" for="c-41651415">[-]</label><label class="expand" for="c-41651415">[8 more]</label></div><br/><div class="children"><div class="content">Failed coup? Altman managed to usurp the board&#x27;s power, seems pretty successful to me</div><br/><div id="41651521" class="c"><input type="checkbox" id="c-41651521" checked=""/><div class="controls bullet"><span class="by">xwowsersx</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651415">parent</a><span>|</span><a href="#41651446">next</a><span>|</span><label class="collapse" for="c-41651521">[-]</label><label class="expand" for="c-41651521">[5 more]</label></div><br/><div class="children"><div class="content">I think OP means the failed coup in which they attempted to oust Altman?</div><br/><div id="41651735" class="c"><input type="checkbox" id="c-41651735" checked=""/><div class="controls bullet"><span class="by">jordanb</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651521">parent</a><span>|</span><a href="#41651446">next</a><span>|</span><label class="collapse" for="c-41651735">[-]</label><label class="expand" for="c-41651735">[4 more]</label></div><br/><div class="children"><div class="content">Yeah the GP&#x27;s point is the board was acting within its purview by dismissing the CEO. The coup was the successful counter-campaign against the board by Altman and the investors.</div><br/><div id="41652005" class="c"><input type="checkbox" id="c-41652005" checked=""/><div class="controls bullet"><span class="by">jeremyjh</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651735">parent</a><span>|</span><a href="#41651951">next</a><span>|</span><label class="collapse" for="c-41652005">[-]</label><label class="expand" for="c-41652005">[1 more]</label></div><br/><div class="children"><div class="content">The successful coup was led by Satya Nadella.</div><br/></div></div><div id="41651951" class="c"><input type="checkbox" id="c-41651951" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651735">parent</a><span>|</span><a href="#41652005">prev</a><span>|</span><a href="#41651446">next</a><span>|</span><label class="collapse" for="c-41651951">[-]</label><label class="expand" for="c-41651951">[2 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s be honest: in large part by Microsoft.</div><br/><div id="41653225" class="c"><input type="checkbox" id="c-41653225" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651951">parent</a><span>|</span><a href="#41651446">next</a><span>|</span><label class="collapse" for="c-41653225">[-]</label><label class="expand" for="c-41653225">[1 more]</label></div><br/><div class="children"><div class="content">Does it matter? The board made a decision and the CEO reversed it. There is no clearer example of a corporate coup.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41651545" class="c"><input type="checkbox" id="c-41651545" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651350">parent</a><span>|</span><a href="#41651415">prev</a><span>|</span><a href="#41652187">next</a><span>|</span><label class="collapse" for="c-41651545">[-]</label><label class="expand" for="c-41651545">[1 more]</label></div><br/><div class="children"><div class="content">&gt;but were never seriously going to work together again after the failed coup.<p>Just to clear one thing up, the designated function of a board of directors is to appoint or replace the executive of an organisation, and openAI in particular is structured such that the non-profit part of the organisation controls the LLC.<p>The coup was the executive, together with the investors, effectively turning that on its head by force.</div><br/></div></div><div id="41651688" class="c"><input type="checkbox" id="c-41651688" checked=""/><div class="controls bullet"><span class="by">nopromisessir</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651350">parent</a><span>|</span><a href="#41655829">prev</a><span>|</span><a href="#41651317">next</a><span>|</span><label class="collapse" for="c-41651688">[-]</label><label class="expand" for="c-41651688">[15 more]</label></div><br/><div class="children"><div class="content">Highly speculative.<p>Also highly cynical.<p>Some folks are professional and mature. In the best organisations, the management team sets the highest possible standard, in terms of tone and culture. If done well, this tends to trickle down to all areas of the organization.<p>Another speculation would be that she&#x27;s resigning for complicated reasons which are personal. I&#x27;ve had to do the same in my past. The real pro&#x27;s give the benefit of the doubt.</div><br/><div id="41651772" class="c"><input type="checkbox" id="c-41651772" checked=""/><div class="controls bullet"><span class="by">itsoktocry</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651688">parent</a><span>|</span><a href="#41651739">next</a><span>|</span><label class="collapse" for="c-41651772">[-]</label><label class="expand" for="c-41651772">[4 more]</label></div><br/><div class="children"><div class="content">What leads you to believe that OpenAI is one of the best managed organizations?</div><br/><div id="41651862" class="c"><input type="checkbox" id="c-41651862" checked=""/><div class="controls bullet"><span class="by">nopromisessir</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651772">parent</a><span>|</span><a href="#41651739">next</a><span>|</span><label class="collapse" for="c-41651862">[-]</label><label class="expand" for="c-41651862">[3 more]</label></div><br/><div class="children"><div class="content">Many hours of interviews.<p>Organizational performance metrics.<p>Frequency of scientific breakthroughs.<p>Frequency and quality of product updates.<p>History of consistently setting the state of the art in artificial intelligence.<p>Demonstrated ability to attract world class talent.<p>Released the fastest growing software product in the history of humanity.</div><br/><div id="41651930" class="c"><input type="checkbox" id="c-41651930" checked=""/><div class="controls bullet"><span class="by">kranke155</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651862">parent</a><span>|</span><a href="#41651739">next</a><span>|</span><label class="collapse" for="c-41651930">[-]</label><label class="expand" for="c-41651930">[2 more]</label></div><br/><div class="children"><div class="content">We have to see if they’ll keep executing in a year, considering the losses in staff and the non technical CEO.</div><br/><div id="41653449" class="c"><input type="checkbox" id="c-41653449" checked=""/><div class="controls bullet"><span class="by">nopromisessir</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651930">parent</a><span>|</span><a href="#41651739">next</a><span>|</span><label class="collapse" for="c-41653449">[-]</label><label class="expand" for="c-41653449">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get this.<p>I could write paragraphs...<p>Why the rain clouds?</div><br/></div></div></div></div></div></div></div></div><div id="41651739" class="c"><input type="checkbox" id="c-41651739" checked=""/><div class="controls bullet"><span class="by">dfgtyu65r</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651688">parent</a><span>|</span><a href="#41651772">prev</a><span>|</span><a href="#41651747">next</a><span>|</span><label class="collapse" for="c-41651739">[-]</label><label class="expand" for="c-41651739">[6 more]</label></div><br/><div class="children"><div class="content">This feels naive, especially given what we now know about Open AI.</div><br/><div id="41651954" class="c"><input type="checkbox" id="c-41651954" checked=""/><div class="controls bullet"><span class="by">nopromisessir</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651739">parent</a><span>|</span><a href="#41651747">next</a><span>|</span><label class="collapse" for="c-41651954">[-]</label><label class="expand" for="c-41651954">[5 more]</label></div><br/><div class="children"><div class="content">If you care to detail supporting evidence, I&#x27;d be keen to see.<p>Please no speculative pieces, rumor nor hearsay.</div><br/><div id="41652033" class="c"><input type="checkbox" id="c-41652033" checked=""/><div class="controls bullet"><span class="by">apwell23</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651954">parent</a><span>|</span><a href="#41651747">next</a><span>|</span><label class="collapse" for="c-41652033">[-]</label><label class="expand" for="c-41652033">[4 more]</label></div><br/><div class="children"><div class="content">Well why was sam altman fired. it was never revealed.<p>CEOs get fired all the time and company puts out a statement.<p>I&#x27;ve never seen &quot;we won&#x27;t tell you why we fired our CEO&quot; anywhere.<p>now he is back making totally ridiculous statments like 
&#x27;AI is going to solve all of physics&#x27; or that &#x27;AI is going to clone my brain by 2027&#x27;<p>This is a strange company.</div><br/><div id="41652103" class="c"><input type="checkbox" id="c-41652103" checked=""/><div class="controls bullet"><span class="by">alephnerd</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652033">parent</a><span>|</span><a href="#41651747">next</a><span>|</span><label class="collapse" for="c-41652103">[-]</label><label class="expand" for="c-41652103">[3 more]</label></div><br/><div class="children"><div class="content">&gt; This is a strange company.<p>Because the old guard wanted it to remain a cliquey non-profit filled to the brim with EA, AI Alignment, and OpenPhilanthropy types, but the current OpenAI is now an enterprise company.<p>This is just Sam Altman cleaning house after the attempted corporate coup a year ago.</div><br/><div id="41653301" class="c"><input type="checkbox" id="c-41653301" checked=""/><div class="controls bullet"><span class="by">llamaimperative</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652103">parent</a><span>|</span><a href="#41653321">next</a><span>|</span><label class="collapse" for="c-41653301">[-]</label><label class="expand" for="c-41653301">[1 more]</label></div><br/><div class="children"><div class="content">When the board fires the CEO and the CEO reverses the decision, <i>that</i> is the coup.<p>The board’s only reason to exist is effectively to fire the CEO.</div><br/></div></div><div id="41653321" class="c"><input type="checkbox" id="c-41653321" checked=""/><div class="controls bullet"><span class="by">apwell23</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652103">parent</a><span>|</span><a href="#41653301">prev</a><span>|</span><a href="#41651747">next</a><span>|</span><label class="collapse" for="c-41653321">[-]</label><label class="expand" for="c-41653321">[1 more]</label></div><br/><div class="children"><div class="content">I think thats some rumors that they spread to make this look like a &quot;conflict of philosophy&quot; type bs.<p>There are some juicy rumors about what actually happened too. much more belivable lol .</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41651747" class="c"><input type="checkbox" id="c-41651747" checked=""/><div class="controls bullet"><span class="by">sverhagen</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651688">parent</a><span>|</span><a href="#41651739">prev</a><span>|</span><a href="#41651317">next</a><span>|</span><label class="collapse" for="c-41651747">[-]</label><label class="expand" for="c-41651747">[4 more]</label></div><br/><div class="children"><div class="content">Did you also try to oust the CEO of a multi-billion dollar juggernaut?</div><br/><div id="41651895" class="c"><input type="checkbox" id="c-41651895" checked=""/><div class="controls bullet"><span class="by">nopromisessir</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651747">parent</a><span>|</span><a href="#41651317">next</a><span>|</span><label class="collapse" for="c-41651895">[-]</label><label class="expand" for="c-41651895">[3 more]</label></div><br/><div class="children"><div class="content">Sure didn&#x27;t.<p>Neither did she though... To my knowledge.<p>Can you provide any evidence that she tried to do that? I would ask that it be non-speculative in nature please.</div><br/><div id="41652038" class="c"><input type="checkbox" id="c-41652038" checked=""/><div class="controls bullet"><span class="by">alephnerd</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651895">parent</a><span>|</span><a href="#41651317">next</a><span>|</span><label class="collapse" for="c-41652038">[-]</label><label class="expand" for="c-41652038">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;17&#x2F;technology&#x2F;openai-sam-altman-ousted.html" rel="nofollow">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;17&#x2F;technology&#x2F;openai-sam-alt...</a></div><br/><div id="41653430" class="c"><input type="checkbox" id="c-41653430" checked=""/><div class="controls bullet"><span class="by">nopromisessir</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652038">parent</a><span>|</span><a href="#41651317">next</a><span>|</span><label class="collapse" for="c-41653430">[-]</label><label class="expand" for="c-41653430">[1 more]</label></div><br/><div class="children"><div class="content">Below are exerts from the article you link. I&#x27;d suggest a more careful read through. Unless out of hand, you give zero credibility to first hand accounts given to the NYT by both Mirati and Sustkever...<p>This piece is built on conjecture from a source whose identify is withheld. The sources version of events is openly refuted by the parties in question. Offering it as evidence that Mirati intentionally made political moves in order to get Altman ousted is an indefensible position.<p>&#x27;Mr. Sutskever’s lawyer, Alex Weingarten, said claims that he had approached the board were “categorically false.”&#x27;<p>&#x27;Marc H. Axelbaum, a lawyer for Ms. Murati, said in a statement: “The claims that she approached the board in an effort to get Mr. Altman fired last year or supported the board’s actions are flat wrong. She was perplexed at the board’s decision then, but is not surprised that some former board members are now attempting to shift the blame to her.”
In a message to OpenAI employees after publication of this article, Ms. Murati said she and Mr. Altman “have a strong and productive partnership and I have not been shy about sharing feedback with him directly.”<p>She added that she did not reach out to the board but “when individual board members reached out directly to me for feedback about Sam, I provided it — all feedback Sam already knew,” and that did not mean she was “responsible for or supported the old board’s actions.”&#x27;<p>This part of NYT piece is supported by evidence:<p>&#x27;Ms. Murati wrote a private memo to Mr. Altman raising questions about his management and also shared her concerns with the board. That move helped to propel the board’s decision to force him out.&#x27;<p>INTENT matters. Mirati says the board asked for her concerns about Altmans. She provided it and had already brought it to Altmans attention... in writing. Her actions demonstrate transparency and professionalism.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41651317" class="c"><input type="checkbox" id="c-41651317" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651350">prev</a><span>|</span><a href="#41653521">next</a><span>|</span><label class="collapse" for="c-41651317">[-]</label><label class="expand" for="c-41651317">[30 more]</label></div><br/><div class="children"><div class="content">&gt; It is hard for me to square &quot;This company is a few short years away from building world-changing AGI&quot;<p>Altmans quote was that &quot;it&#x27;s possible that we will have superintelligence in a few thousand days&quot;, which sounds a lot more optimistic on the surface than it actually is. A few thousand days could be interpreted as 10 years or more, and by adding the &quot;possibly&quot; qualifier he didn&#x27;t even really commit to that prediction.<p>It&#x27;s hype with no substance, but vaguely gesturing that something earth-shattering is coming does serve to convince investors to keep dumping endless $billions into his unprofitable company, without risking the reputational damage of missing a deadline since he never actually gave one. Just keep signing those 9 digit checks and we&#x27;ll totally build AGI... eventually. Honest.</div><br/><div id="41651635" class="c"><input type="checkbox" id="c-41651635" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651317">parent</a><span>|</span><a href="#41652990">next</a><span>|</span><label class="collapse" for="c-41651635">[-]</label><label class="expand" for="c-41651635">[7 more]</label></div><br/><div class="children"><div class="content">Between 1 and 10 thousands of days, so 3 to 27 years.<p>A range I&#x27;d agree with; for me, &quot;pessimism&quot; is the shortest part of that range, but even then you have to be very confident the specific metaphorical horse you&#x27;re betting on is going to be both victorious in its own right and not, because there&#x27;s no suitable existing metaphor, secretly an ICBM wearing a patomime costume.</div><br/><div id="41653332" class="c"><input type="checkbox" id="c-41653332" checked=""/><div class="controls bullet"><span class="by">dimitri-vs</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651635">parent</a><span>|</span><a href="#41651875">next</a><span>|</span><label class="collapse" for="c-41653332">[-]</label><label class="expand" for="c-41653332">[1 more]</label></div><br/><div class="children"><div class="content">Just in time for them to figure out fusion to power all the GPUs.<p>But really. o1 has been very whelming, nothing like the step up from 3.5 to 4. Still prefer sonnet3.5 and opus.</div><br/></div></div><div id="41651875" class="c"><input type="checkbox" id="c-41651875" checked=""/><div class="controls bullet"><span class="by">zooq_ai</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651635">parent</a><span>|</span><a href="#41653332">prev</a><span>|</span><a href="#41652990">next</a><span>|</span><label class="collapse" for="c-41651875">[-]</label><label class="expand" for="c-41651875">[5 more]</label></div><br/><div class="children"><div class="content">1 you use 1<p>2 (or even 3) you use &quot;a couple&quot;<p>A few is almost always &gt; 3 and one could argue that upper limit 15<p>So, 10 years to 50 years</div><br/><div id="41654545" class="c"><input type="checkbox" id="c-41654545" checked=""/><div class="controls bullet"><span class="by">usaar333</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651875">parent</a><span>|</span><a href="#41652143">next</a><span>|</span><label class="collapse" for="c-41654545">[-]</label><label class="expand" for="c-41654545">[1 more]</label></div><br/><div class="children"><div class="content">few is not &gt; 3.  Literally it&#x27;s just &gt;= 2, though I think &gt;= 3 is the common definition.<p>15 is too high to be a &quot;few&quot; except in contexts of a few out of tens of thousands of items.<p>Realistically I interpret this as 3-7 thousands of days (8 to 19 years), which is largely consensus prediction range anyway.</div><br/></div></div><div id="41652143" class="c"><input type="checkbox" id="c-41652143" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651875">parent</a><span>|</span><a href="#41654545">prev</a><span>|</span><a href="#41652398">next</a><span>|</span><label class="collapse" for="c-41652143">[-]</label><label class="expand" for="c-41652143">[2 more]</label></div><br/><div class="children"><div class="content">Personally speaking, above 10 thousand I&#x27;d switch to saying &quot;a few tens of thousands&quot;.<p>But the mere fact you say 15 is arguable does indeed broaden the range, just as me saying 1 broadens it in the opposite extent.</div><br/></div></div><div id="41652398" class="c"><input type="checkbox" id="c-41652398" checked=""/><div class="controls bullet"><span class="by">fvv</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651875">parent</a><span>|</span><a href="#41652143">prev</a><span>|</span><a href="#41652990">next</a><span>|</span><label class="collapse" for="c-41652398">[-]</label><label class="expand" for="c-41652398">[1 more]</label></div><br/><div class="children"><div class="content">You imply that he knows exactly when which imo is not and could even be next year for what we knows.. Who know every paper yet to be published??</div><br/></div></div></div></div></div></div><div id="41652990" class="c"><input type="checkbox" id="c-41652990" checked=""/><div class="controls bullet"><span class="by">015a</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651317">parent</a><span>|</span><a href="#41651635">prev</a><span>|</span><a href="#41651400">next</a><span>|</span><label class="collapse" for="c-41652990">[-]</label><label class="expand" for="c-41652990">[3 more]</label></div><br/><div class="children"><div class="content">Because as we all know: Full Self Driving is just six months away.</div><br/><div id="41653090" class="c"><input type="checkbox" id="c-41653090" checked=""/><div class="controls bullet"><span class="by">squarefoot</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652990">parent</a><span>|</span><a href="#41651400">next</a><span>|</span><label class="collapse" for="c-41653090">[-]</label><label class="expand" for="c-41653090">[2 more]</label></div><br/><div class="children"><div class="content">Thanks, now I cannot unthink of this vision: developers activate the first ASI, and after 3 minutes it spits out full code and plans for a working Full Self Driving car prototype:)</div><br/><div id="41655094" class="c"><input type="checkbox" id="c-41655094" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653090">parent</a><span>|</span><a href="#41651400">next</a><span>|</span><label class="collapse" for="c-41655094">[-]</label><label class="expand" for="c-41655094">[1 more]</label></div><br/><div class="children"><div class="content">I thought super-intelligence was to say self driving would be fully operational <i>next year</i> for 10 consecutive years?</div><br/></div></div></div></div></div></div><div id="41651400" class="c"><input type="checkbox" id="c-41651400" checked=""/><div class="controls bullet"><span class="by">z7</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651317">parent</a><span>|</span><a href="#41652990">prev</a><span>|</span><a href="#41652057">next</a><span>|</span><label class="collapse" for="c-41651400">[-]</label><label class="expand" for="c-41651400">[10 more]</label></div><br/><div class="children"><div class="content">&gt;Altmans quote was that AGI &quot;could be just a few thousand days away&quot; which sounds a lot more optimistic on the surface than it actually is.<p>I think he was referring to ASI, not AGI.</div><br/><div id="41651517" class="c"><input type="checkbox" id="c-41651517" checked=""/><div class="controls bullet"><span class="by">umeshunni</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651400">parent</a><span>|</span><a href="#41652636">next</a><span>|</span><label class="collapse" for="c-41651517">[-]</label><label class="expand" for="c-41651517">[7 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t ASI &gt; AGI?</div><br/><div id="41651737" class="c"><input type="checkbox" id="c-41651737" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651517">parent</a><span>|</span><a href="#41651661">next</a><span>|</span><label class="collapse" for="c-41651737">[-]</label><label class="expand" for="c-41651737">[2 more]</label></div><br/><div class="children"><div class="content">Both are poorly defined.<p>By all the standards I had growing up, ChatGPT is already AGI. It&#x27;s almost certainly not as economically transformative as it needs to be to meet OpenAI&#x27;s stated definition.<p>OTOH that may be due to limited availability rather than limited quality: if all the 20 USD&#x2F;month for Plus gets spent on electricity to run the servers, at $0.10&#x2F;kWh, that&#x27;s about 274 W average consumption. Scaled up to the world population, that&#x27;s approximately the entire global electricity supply. Which is kinda why there&#x27;s also all the stories about AI data centres getting dedicated power plants.</div><br/><div id="41652224" class="c"><input type="checkbox" id="c-41652224" checked=""/><div class="controls bullet"><span class="by">Spivak</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651737">parent</a><span>|</span><a href="#41651661">next</a><span>|</span><label class="collapse" for="c-41652224">[-]</label><label class="expand" for="c-41652224">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t know why you&#x27;re being downvoted, these models meet the definition of AGI. It just looks different than perhaps we expected.<p>We made a thing that exhibits the emergent property of intelligence. A level
of intelligence that trades blows with humans. The fact that our brains do lots of other things to make us into self-contained autonomous beings is cool and maybe answers some questions about what being sentient means but memory and self-learning aren&#x27;t the same thing as intelligence.<p>I think it&#x27;s cool that we got there before simulating an already existing brain and that intelligence can exist separate from consciousness.</div><br/></div></div></div></div><div id="41651661" class="c"><input type="checkbox" id="c-41651661" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651517">parent</a><span>|</span><a href="#41651737">prev</a><span>|</span><a href="#41652636">next</a><span>|</span><label class="collapse" for="c-41651661">[-]</label><label class="expand" for="c-41651661">[4 more]</label></div><br/><div class="children"><div class="content">Is the S here referring to Sentient or Specialised?</div><br/><div id="41652626" class="c"><input type="checkbox" id="c-41652626" checked=""/><div class="controls bullet"><span class="by">jrflowers</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651661">parent</a><span>|</span><a href="#41651780">next</a><span>|</span><label class="collapse" for="c-41652626">[-]</label><label class="expand" for="c-41652626">[1 more]</label></div><br/><div class="children"><div class="content">Scottish.</div><br/></div></div><div id="41651780" class="c"><input type="checkbox" id="c-41651780" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651661">parent</a><span>|</span><a href="#41652626">prev</a><span>|</span><a href="#41651717">next</a><span>|</span><label class="collapse" for="c-41651780">[-]</label><label class="expand" for="c-41651780">[1 more]</label></div><br/><div class="children"><div class="content">Super(human).<p>Old-school AI was already specialised. Nobody can agree what &quot;sentient&quot; is, and if sentience includes a capacity to feel emotions&#x2F;qualia etc. then we&#x27;d only willingly choose that over non-sentient for brain uploading not &quot;mere&quot; assistants.</div><br/></div></div><div id="41651717" class="c"><input type="checkbox" id="c-41651717" checked=""/><div class="controls bullet"><span class="by">romanhn</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651661">parent</a><span>|</span><a href="#41651780">prev</a><span>|</span><a href="#41652636">next</a><span>|</span><label class="collapse" for="c-41651717">[-]</label><label class="expand" for="c-41651717">[1 more]</label></div><br/><div class="children"><div class="content">Super, whatever that means</div><br/></div></div></div></div></div></div><div id="41652636" class="c"><input type="checkbox" id="c-41652636" checked=""/><div class="controls bullet"><span class="by">bottlepalm</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651400">parent</a><span>|</span><a href="#41651517">prev</a><span>|</span><a href="#41652057">next</a><span>|</span><label class="collapse" for="c-41652636">[-]</label><label class="expand" for="c-41652636">[2 more]</label></div><br/><div class="children"><div class="content">Given that ChatGPT is already smarter and faster than humans in many different metrics. Once the other metrics catch up with humans it will still be better than humans in the existing metrics. Therefore there will be no AGI, only ASI.</div><br/><div id="41652740" class="c"><input type="checkbox" id="c-41652740" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652636">parent</a><span>|</span><a href="#41652057">next</a><span>|</span><label class="collapse" for="c-41652740">[-]</label><label class="expand" for="c-41652740">[1 more]</label></div><br/><div class="children"><div class="content">My fridge is already smarter and faster than humans in many different metrics.<p>Has been this way since calculation machines were invented hundreds of years ago.</div><br/></div></div></div></div></div></div><div id="41652057" class="c"><input type="checkbox" id="c-41652057" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651317">parent</a><span>|</span><a href="#41651400">prev</a><span>|</span><a href="#41652182">next</a><span>|</span><label class="collapse" for="c-41652057">[-]</label><label class="expand" for="c-41652057">[6 more]</label></div><br/><div class="children"><div class="content">OpenAI is a Microsoft play to get into power generation business, specifically nuclear, which is a pet interest of Bill Gates for many years.<p>There, that&#x27;s my conspiracy theory quota for 2024 in one comment.</div><br/><div id="41654831" class="c"><input type="checkbox" id="c-41654831" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652057">parent</a><span>|</span><a href="#41654940">prev</a><span>|</span><a href="#41653287">next</a><span>|</span><label class="collapse" for="c-41654831">[-]</label><label class="expand" for="c-41654831">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s kinda cool as a conspiracy theory. It&#x27;s just reasonable enough if you don&#x27;t know any of the specifics. And the incentives mostly make sense, if you don&#x27;t look too closely.</div><br/></div></div><div id="41653287" class="c"><input type="checkbox" id="c-41653287" checked=""/><div class="controls bullet"><span class="by">kolbe</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652057">parent</a><span>|</span><a href="#41654831">prev</a><span>|</span><a href="#41652182">next</a><span>|</span><label class="collapse" for="c-41653287">[-]</label><label class="expand" for="c-41653287">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think Gates has much influence on Microsoft these days.</div><br/><div id="41653373" class="c"><input type="checkbox" id="c-41653373" checked=""/><div class="controls bullet"><span class="by">basementcat</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653287">parent</a><span>|</span><a href="#41652182">next</a><span>|</span><label class="collapse" for="c-41653373">[-]</label><label class="expand" for="c-41653373">[2 more]</label></div><br/><div class="children"><div class="content">He controls approximately 1% of the voting shares of MSFT.</div><br/><div id="41653411" class="c"><input type="checkbox" id="c-41653411" checked=""/><div class="controls bullet"><span class="by">kolbe</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653373">parent</a><span>|</span><a href="#41652182">next</a><span>|</span><label class="collapse" for="c-41653411">[-]</label><label class="expand" for="c-41653411">[1 more]</label></div><br/><div class="children"><div class="content">And I would argue his &quot;soft power&quot; is greatly diminished as well</div><br/></div></div></div></div></div></div></div></div><div id="41652182" class="c"><input type="checkbox" id="c-41652182" checked=""/><div class="controls bullet"><span class="by">petre</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651317">parent</a><span>|</span><a href="#41652057">prev</a><span>|</span><a href="#41653998">next</a><span>|</span><label class="collapse" for="c-41652182">[-]</label><label class="expand" for="c-41652182">[2 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s possible that we will have superintelligence in a few thousand days<p>Sure, a few thousand days and a few trillion $ away. We&#x27;ll also have full self driving next month. This is just like the fusion is the energy of the future joke: it&#x27;s 30 years away and it will always be.</div><br/><div id="41652448" class="c"><input type="checkbox" id="c-41652448" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652182">parent</a><span>|</span><a href="#41653998">next</a><span>|</span><label class="collapse" for="c-41652448">[-]</label><label class="expand" for="c-41652448">[1 more]</label></div><br/><div class="children"><div class="content">Now it’s 20 years away! It took 50 years for it to go from 30 to 20 years away. So maybe, in another 50 years it will be 10 years away?</div><br/></div></div></div></div><div id="41653998" class="c"><input type="checkbox" id="c-41653998" checked=""/><div class="controls bullet"><span class="by">theGnuMe</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651317">parent</a><span>|</span><a href="#41652182">prev</a><span>|</span><a href="#41653521">next</a><span>|</span><label class="collapse" for="c-41653998">[-]</label><label class="expand" for="c-41653998">[1 more]</label></div><br/><div class="children"><div class="content">To paraphrase a notable example:  We will have full self driving capability next year..</div><br/></div></div></div></div><div id="41653521" class="c"><input type="checkbox" id="c-41653521" checked=""/><div class="controls bullet"><span class="by">blihp</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651317">prev</a><span>|</span><a href="#41651524">next</a><span>|</span><label class="collapse" for="c-41653521">[-]</label><label class="expand" for="c-41653521">[2 more]</label></div><br/><div class="children"><div class="content">This was the company that made all sorts of noise about how they couldn&#x27;t release GPT-2 to the public because it was too dangerous[1].  While there are many very useful applications being developed, OpenAI&#x27;s main deliverable appears to be hype that I suspect when it&#x27;s all said and done they will fail to deliver on.  I think the main thing they are doing quite successfully is cashing in on the hype before people figure it out.<p>[1] <a href="https:&#x2F;&#x2F;slate.com&#x2F;technology&#x2F;2019&#x2F;02&#x2F;openai-gpt2-text-generating-algorithm-ai-dangerous.html" rel="nofollow">https:&#x2F;&#x2F;slate.com&#x2F;technology&#x2F;2019&#x2F;02&#x2F;openai-gpt2-text-genera...</a></div><br/><div id="41653576" class="c"><input type="checkbox" id="c-41653576" checked=""/><div class="controls bullet"><span class="by">johnfn</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653521">parent</a><span>|</span><a href="#41651524">next</a><span>|</span><label class="collapse" for="c-41653576">[-]</label><label class="expand" for="c-41653576">[1 more]</label></div><br/><div class="children"><div class="content">GPT-2 and descendants have polluted the internet with AI spam. I don&#x27;t think that this is too unreasonable of a claim.</div><br/></div></div></div></div><div id="41651524" class="c"><input type="checkbox" id="c-41651524" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41653521">prev</a><span>|</span><a href="#41651461">next</a><span>|</span><label class="collapse" for="c-41651524">[-]</label><label class="expand" for="c-41651524">[3 more]</label></div><br/><div class="children"><div class="content">Regardless of where AI currently is and where it is going, you don&#x27;t simply quit as CTO of the company that is leading the space <i>by far</i> in terms of technology, products, funding, revenue, popularity, adoption and just about everything else. She was fired, plain and simple.</div><br/><div id="41651933" class="c"><input type="checkbox" id="c-41651933" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651524">parent</a><span>|</span><a href="#41654839">next</a><span>|</span><label class="collapse" for="c-41651933">[-]</label><label class="expand" for="c-41651933">[1 more]</label></div><br/><div class="children"><div class="content">You can leave and be happy with 30M+ USD in stocks and prospects of easy to find a job also.</div><br/></div></div><div id="41654839" class="c"><input type="checkbox" id="c-41654839" checked=""/><div class="controls bullet"><span class="by">piuantiderp</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651524">parent</a><span>|</span><a href="#41651933">prev</a><span>|</span><a href="#41651461">next</a><span>|</span><label class="collapse" for="c-41654839">[-]</label><label class="expand" for="c-41654839">[1 more]</label></div><br/><div class="children"><div class="content">Or you are disgusted and leave. Are there things more important than money? You&#x27;d certainly be certain the OpenAI founders sold themselves as, not&#x27;in&#x27;it&#x27;for&#x27;the money.</div><br/></div></div></div></div><div id="41651461" class="c"><input type="checkbox" id="c-41651461" checked=""/><div class="controls bullet"><span class="by">f0e4c2f7</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651524">prev</a><span>|</span><a href="#41651267">next</a><span>|</span><label class="collapse" for="c-41651461">[-]</label><label class="expand" for="c-41651461">[2 more]</label></div><br/><div class="children"><div class="content">There is one clear answer in my opinion:<p>There is a secondary market for OpenAI stock.<p>It&#x27;s not a public market so nobody knows how much you&#x27;re making if you sell, but if you look at current valuations it must be a lot.<p>In that context, it would be quite hard not to leave and sell or stay and sell. What if oai loses the lead? What if open source wins? Keeping the stock seems like the actual hard thing to me and I expect to see many others leave (like early googlers or Facebook employees)<p>Sure it&#x27;s worth more if you hang on to it, but many think &quot;how many hundreds of M&#x27;s do I actually need? Better to derisk and sell&quot;</div><br/><div id="41651672" class="c"><input type="checkbox" id="c-41651672" checked=""/><div class="controls bullet"><span class="by">chatcode</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651461">parent</a><span>|</span><a href="#41651267">next</a><span>|</span><label class="collapse" for="c-41651672">[-]</label><label class="expand" for="c-41651672">[1 more]</label></div><br/><div class="children"><div class="content">What would you do if<p>a) you had more money than you&#x27;ll ever need in your lifetime<p>b) you think AI abundance is just around the corner, likely making everything cheaper<p>c) you realize you still only have a finite time left on this planet<p>d) you have non-AGI dreams of your own that you&#x27;d like to work on<p>e) you can get funding for anything you want, based on your name alone<p>Do you keep working at OpenAI?</div><br/></div></div></div></div><div id="41651267" class="c"><input type="checkbox" id="c-41651267" checked=""/><div class="controls bullet"><span class="by">orionsbelt</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651461">prev</a><span>|</span><a href="#41651797">next</a><span>|</span><label class="collapse" for="c-41651267">[-]</label><label class="expand" for="c-41651267">[13 more]</label></div><br/><div class="children"><div class="content">Maybe she thinks the _world_ is a few short years away from building world-changing AGI, not just limited to OpenAI, and she wants to compete and do her own thing (and easily raise $1B like Ilya).</div><br/><div id="41651367" class="c"><input type="checkbox" id="c-41651367" checked=""/><div class="controls bullet"><span class="by">xur17</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651267">parent</a><span>|</span><a href="#41651893">next</a><span>|</span><label class="collapse" for="c-41651367">[-]</label><label class="expand" for="c-41651367">[6 more]</label></div><br/><div class="children"><div class="content">Which is arguably a good thing (having AGI spread amongst multiple entities rather than one leader).</div><br/><div id="41651452" class="c"><input type="checkbox" id="c-41651452" checked=""/><div class="controls bullet"><span class="by">tomrod</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651367">parent</a><span>|</span><a href="#41652137">next</a><span>|</span><label class="collapse" for="c-41651452">[-]</label><label class="expand" for="c-41651452">[2 more]</label></div><br/><div class="children"><div class="content">The show Person of Interest comes to mind.</div><br/><div id="41651701" class="c"><input type="checkbox" id="c-41651701" checked=""/><div class="controls bullet"><span class="by">tempodox</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651452">parent</a><span>|</span><a href="#41652137">next</a><span>|</span><label class="collapse" for="c-41651701">[-]</label><label class="expand" for="c-41651701">[1 more]</label></div><br/><div class="children"><div class="content">Samaritan will take us by the hand and lead us safely through this brave new world.</div><br/></div></div></div></div><div id="41652137" class="c"><input type="checkbox" id="c-41652137" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651367">parent</a><span>|</span><a href="#41651452">prev</a><span>|</span><a href="#41651893">next</a><span>|</span><label class="collapse" for="c-41652137">[-]</label><label class="expand" for="c-41652137">[3 more]</label></div><br/><div class="children"><div class="content">How is that good? An arms race increases the pressure to go fast and disregard alignment safety, non proliferation is essential.</div><br/><div id="41654999" class="c"><input type="checkbox" id="c-41654999" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652137">parent</a><span>|</span><a href="#41652468">next</a><span>|</span><label class="collapse" for="c-41654999">[-]</label><label class="expand" for="c-41654999">[1 more]</label></div><br/><div class="children"><div class="content">Probably off-topic for this thread but my own rather fatalist view is alignment&#x2F;safety is a waste of effort if AGI will happen. True AGI will be able to self-modify at a pace beyond human comprehension, and won&#x27;t be obligated to comply with whatever values we&#x27;ve set for it. If it can be reined in with human-set rules like a magical spell, then it is not AGI. If humans have free will, then AGI will have it too. Humans frequently go rogue and reject value systems that took decades to be baked into them. There is no reason to believe AGI won&#x27;t do the same.</div><br/></div></div><div id="41652468" class="c"><input type="checkbox" id="c-41652468" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652137">parent</a><span>|</span><a href="#41654999">prev</a><span>|</span><a href="#41651893">next</a><span>|</span><label class="collapse" for="c-41652468">[-]</label><label class="expand" for="c-41652468">[1 more]</label></div><br/><div class="children"><div class="content">I think that train left some time ago.</div><br/></div></div></div></div></div></div><div id="41651893" class="c"><input type="checkbox" id="c-41651893" checked=""/><div class="controls bullet"><span class="by">zooq_ai</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651267">parent</a><span>|</span><a href="#41651367">prev</a><span>|</span><a href="#41651797">next</a><span>|</span><label class="collapse" for="c-41651893">[-]</label><label class="expand" for="c-41651893">[6 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t imagine investor pouring money on her. She has zero credibility both hardcore STEM like Ilya or a visionary like Jobs&#x2F;Musk</div><br/><div id="41652624" class="c"><input type="checkbox" id="c-41652624" checked=""/><div class="controls bullet"><span class="by">phatfish</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651893">parent</a><span>|</span><a href="#41652628">next</a><span>|</span><label class="collapse" for="c-41652624">[-]</label><label class="expand" for="c-41652624">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Credibility&quot; has nothing to do with how much money rich people are willing to give you.</div><br/></div></div><div id="41652628" class="c"><input type="checkbox" id="c-41652628" checked=""/><div class="controls bullet"><span class="by">KoftaBob</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651893">parent</a><span>|</span><a href="#41652624">prev</a><span>|</span><a href="#41651797">next</a><span>|</span><label class="collapse" for="c-41652628">[-]</label><label class="expand" for="c-41652628">[4 more]</label></div><br/><div class="children"><div class="content">She was the CTO, how does she not have STEM credibility?</div><br/><div id="41652876" class="c"><input type="checkbox" id="c-41652876" checked=""/><div class="controls bullet"><span class="by">peanuty1</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652628">parent</a><span>|</span><a href="#41653733">next</a><span>|</span><label class="collapse" for="c-41652876">[-]</label><label class="expand" for="c-41652876">[1 more]</label></div><br/><div class="children"><div class="content">Has she published a single AI research paper?</div><br/></div></div><div id="41653733" class="c"><input type="checkbox" id="c-41653733" checked=""/><div class="controls bullet"><span class="by">zooq_ai</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652628">parent</a><span>|</span><a href="#41652876">prev</a><span>|</span><a href="#41651797">next</a><span>|</span><label class="collapse" for="c-41653733">[-]</label><label class="expand" for="c-41653733">[2 more]</label></div><br/><div class="children"><div class="content">Sometimes with good looks and charm, you can fall up.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mira_Murati" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mira_Murati</a><p>Point me to a single credential where you feel confident of putting your money on her?</div><br/><div id="41654957" class="c"><input type="checkbox" id="c-41654957" checked=""/><div class="controls bullet"><span class="by">csomar</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653733">parent</a><span>|</span><a href="#41651797">next</a><span>|</span><label class="collapse" for="c-41654957">[-]</label><label class="expand" for="c-41654957">[1 more]</label></div><br/><div class="children"><div class="content">She studied math early on, so she&#x27;s definitively technical. She is the CTO, so she kinda needs to balance the managerial while having enough understanding of the underlying technical.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41651797" class="c"><input type="checkbox" id="c-41651797" checked=""/><div class="controls bullet"><span class="by">shmatt</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651267">prev</a><span>|</span><a href="#41655666">next</a><span>|</span><label class="collapse" for="c-41651797">[-]</label><label class="expand" for="c-41651797">[29 more]</label></div><br/><div class="children"><div class="content">I feel like this is stating the obvious - but i guess not to many - but a probabilistic syllable generator is not intelligence, it does not understand us, it cannot reason, it can only generate the next syllable<p>It makes us feel understood in the same ways John Edward used to in daytime tv, its all about how language makes us feel<p>true AGI...unfortunately we&#x27;re not even close</div><br/><div id="41653131" class="c"><input type="checkbox" id="c-41653131" checked=""/><div class="controls bullet"><span class="by">lumenwrites</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651797">parent</a><span>|</span><a href="#41653390">next</a><span>|</span><label class="collapse" for="c-41653131">[-]</label><label class="expand" for="c-41653131">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Intelligence&quot; is a poorly defined term prone to arguments about semantics and goalpost shifting.<p>I think it&#x27;s more productive to think about AI in terms of &quot;effectiveness&quot; or &quot;capability&quot;. If you ask it, &quot;what is the capital of France?&quot;, and it replies &quot;Paris&quot; - it doesn&#x27;t matter whether it is intelligent or not, it is effective&#x2F;capable at identifying the capital of France.<p>Same goes for producing an image, writing SQL code that works, automating some % of intellectual labor, giving medical advice, solving an equation, piloting a drone, building and managing a profitable company. It is capable of various things to various degrees. If these capabilities are enough to make money, create risks, change the world in some significant way - that is the part that matters.<p>Whether we call it &quot;intelligence&quot; or &quot;probabilistically generaring syllables&quot; is not important.</div><br/></div></div><div id="41653390" class="c"><input type="checkbox" id="c-41653390" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651797">parent</a><span>|</span><a href="#41653131">prev</a><span>|</span><a href="#41652195">next</a><span>|</span><label class="collapse" for="c-41653390">[-]</label><label class="expand" for="c-41653390">[3 more]</label></div><br/><div class="children"><div class="content">it can actually solve problems though, its not just an illusion of intelligence if it does the stuff we considered mere years ago sufficient to be intelligent. But you and others keep moving the goalposts as benchmarks saturate, perhaps due to a misplaced pride in the specialness of human intelligence.<p>I understand the fear, but the knee jerk response “its just predicting the next token thus could never be intelligent” makes you look more like a stochastic parrot than these models are.</div><br/><div id="41655089" class="c"><input type="checkbox" id="c-41655089" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653390">parent</a><span>|</span><a href="#41654222">next</a><span>|</span><label class="collapse" for="c-41655089">[-]</label><label class="expand" for="c-41655089">[1 more]</label></div><br/><div class="children"><div class="content">It solves problems because it was trained with the solutions to these problems that have been written down a thousand times before. A lot of people don&#x27;t even consider the ability to solve problems to be a reliable indicator of human intelligence, see the constantly evolving discourse regarding standardized tests.<p>Attempts at autonomous AI agents are still failing spectacularly because the models don&#x27;t actually have any thought or memory. Context is provided to them via prefixing the prompt with all previous prompts which obviously causes significant info loss after a few interaction loops. The level of intellectual complexity at play here is on par with nematodes in a lab (which btw still can&#x27;t be digitally emulated after decades of research). This isn&#x27;t a diss on all the smart people working in AI today, bc I&#x27;m not talking about the quality of any specific model available today.</div><br/></div></div><div id="41654222" class="c"><input type="checkbox" id="c-41654222" checked=""/><div class="controls bullet"><span class="by">caconym_</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653390">parent</a><span>|</span><a href="#41655089">prev</a><span>|</span><a href="#41652195">next</a><span>|</span><label class="collapse" for="c-41654222">[-]</label><label class="expand" for="c-41654222">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;goalposts&quot; are &quot;moving&quot; because now (unlike &quot;mere years ago&quot;) we have real AI systems that are at least good enough to be seriously compared with human intelligence. We aren&#x27;t vaguely speculating about what such an AI system <i>might</i> be like^[1]; we have the real thing now, and we can test its capabilities and see what it <i>is</i> like, what it&#x27;s good at, and what it&#x27;s not so good at.<p>I think your use of the &quot;goalposts&quot; metaphor is telling. You see this as a team sport; you see yourself on the offensive, or the defensive, or whatever. Neither is conducive to a balanced, objective view of reality. Modern LLMs are shockingly &quot;smart&quot; in many ways, but if you think they&#x27;re general intelligence in the same way humans have general intelligence (even disregarding agency, learning, etc.), that&#x27;s a you problem.<p>^[1] I feel the implicit suggestion that there was some sort of broad consensus on this in the before-times is revisionism.</div><br/></div></div></div></div><div id="41652195" class="c"><input type="checkbox" id="c-41652195" checked=""/><div class="controls bullet"><span class="by">svara</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651797">parent</a><span>|</span><a href="#41653390">prev</a><span>|</span><a href="#41652152">next</a><span>|</span><label class="collapse" for="c-41652195">[-]</label><label class="expand" for="c-41652195">[6 more]</label></div><br/><div class="children"><div class="content">I truly think you haven&#x27;t really thought this through.<p>There&#x27;s a huge amount of circuitry between the input and the output of the model. How do you know what it does or doesn&#x27;t do?<p>Humans brains &quot;just&quot; output the next couple milliseconds of muscle activation, given sensory input and internal state.<p>Edit: Interestingly, this is getting downvotes even though 1) my last sentence is a precise and accurate statement of the state of the art in neuroscience and 2) it is completely isomorphic to what the parent post presented as an argument against current models being AGI.<p>To clarify, I don&#x27;t believe we&#x27;re very close to AGI, but parent&#x27;s argument is just confused.</div><br/><div id="41653048" class="c"><input type="checkbox" id="c-41653048" checked=""/><div class="controls bullet"><span class="by">015a</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652195">parent</a><span>|</span><a href="#41653819">next</a><span>|</span><label class="collapse" for="c-41653048">[-]</label><label class="expand" for="c-41653048">[3 more]</label></div><br/><div class="children"><div class="content">Did you seriously just use the word &quot;isomorphic&quot;? No wonder people believe AI is the next crypto.</div><br/><div id="41655765" class="c"><input type="checkbox" id="c-41655765" checked=""/><div class="controls bullet"><span class="by">edouard-harris</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653048">parent</a><span>|</span><a href="#41655214">next</a><span>|</span><label class="collapse" for="c-41655765">[-]</label><label class="expand" for="c-41655765">[1 more]</label></div><br/><div class="children"><div class="content">In what way was their usage incorrect? They simply said that the brain just predicts next-actions, in response to a statement that an LLM predicts next-tokens. You can believe or disbelieve either of those statements individually, but the claims are isomorphic in the sense that they have the same structure.</div><br/></div></div><div id="41655214" class="c"><input type="checkbox" id="c-41655214" checked=""/><div class="controls bullet"><span class="by">svara</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653048">parent</a><span>|</span><a href="#41655765">prev</a><span>|</span><a href="#41653819">next</a><span>|</span><label class="collapse" for="c-41655214">[-]</label><label class="expand" for="c-41655214">[1 more]</label></div><br/><div class="children"><div class="content">Well, AI clearly is the next crypto, haha.<p>Apologies for the wording but I think you got it and the point stands.<p>I&#x27;m not a native speaker and mostly use English in a professional science related setting, that&#x27;s why I sound like that sometimes.<p>isomorphic - being of identical or similar form, shape, or structure (m-w). Here metaphorically applied to the structure of an argument.</div><br/></div></div></div></div><div id="41653819" class="c"><input type="checkbox" id="c-41653819" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652195">parent</a><span>|</span><a href="#41653048">prev</a><span>|</span><a href="#41652152">next</a><span>|</span><label class="collapse" for="c-41653819">[-]</label><label class="expand" for="c-41653819">[2 more]</label></div><br/><div class="children"><div class="content">&gt; There&#x27;s a huge amount of circuitry between the input and the output of the model<p>Yeah - but it&#x27;s just a stack of transformer layers. No looping, no memory, no self-modification (learning). Also, no magic.</div><br/><div id="41655209" class="c"><input type="checkbox" id="c-41655209" checked=""/><div class="controls bullet"><span class="by">svara</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653819">parent</a><span>|</span><a href="#41652152">next</a><span>|</span><label class="collapse" for="c-41655209">[-]</label><label class="expand" for="c-41655209">[1 more]</label></div><br/><div class="children"><div class="content">No looping, but you can unroll loops to a fixed depth and apply the model iteratively. There obviously is memory and learning.<p>Neuroscience hasn&#x27;t found the magic dust in our brains yet, either. ;)</div><br/></div></div></div></div></div></div><div id="41652152" class="c"><input type="checkbox" id="c-41652152" checked=""/><div class="controls bullet"><span class="by">HeatrayEnjoyer</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651797">parent</a><span>|</span><a href="#41652195">prev</a><span>|</span><a href="#41652197">next</a><span>|</span><label class="collapse" for="c-41652152">[-]</label><label class="expand" for="c-41652152">[1 more]</label></div><br/><div class="children"><div class="content">This overplayed knee jerk response is so dull.</div><br/></div></div><div id="41652197" class="c"><input type="checkbox" id="c-41652197" checked=""/><div class="controls bullet"><span class="by">ttul</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651797">parent</a><span>|</span><a href="#41652152">prev</a><span>|</span><a href="#41651873">next</a><span>|</span><label class="collapse" for="c-41652197">[-]</label><label class="expand" for="c-41652197">[7 more]</label></div><br/><div class="children"><div class="content">While it&#x27;s true that language models are fundamentally based on statistical patterns in language, characterizing them as mere &quot;probabilistic syllable generators&quot; significantly understates their capabilities and functional intelligence.<p>These models can engage in multistep logical reasoning, solve complex problems, and generate novel ideas - going far beyond simply predicting the next syllable. They can follow intricate chains of thought and arrive at non-obvious conclusions. And OpenAI has now showed us that fine-tuning a model specifically to plan step by step dramatically improves its ability to solve problems that were previously the domain of human experts.<p>Although there is no definitive evidence that state-of-the-art language models have a comprehensive &quot;world model&quot; in the way humans do, several studies and observations suggest that large language models (LLMs) may possess some elements or precursors of a world model.<p>For example, Tegmark and Gurnee [1] found that LLMs learn linear representations of space and time across multiple scales. These representations appear to be robust to prompting variations and unified across different entity types. This suggests that modern LLMs may learn rich spatiotemporal representations of the real world, which could be considered basic ingredients of a world model.<p>And even if we look at much smaller models like Stable Diffusion XL, it&#x27;s clear that they encode a rich understanding of optics [2] within just a few billion parameters (3.5 billion to be precise). Generative video models like OpenAI&#x27;s Sora clearly have a world model as they are able to simulate gravity, collisions between objects, and other concepts necessary to render a coherent scene.<p>As for AGI, the consensus on Metaculus is that it will arrive in 2023. But consider that before GPT-4 arrived, the consensus was that full AGI was not coming until 2041 [3]. The consensus for the arrival date of &quot;weakly general&quot; AGI is 2027 [4] (i.e AGI that doesn&#x27;t have a robotic physical world component). The best tool for achieving AGI is the transformer and its derivatives; its scaling keeps going with no end in sight.<p>Citations:<p>[1] <a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;language-models-represent-space-and-time" rel="nofollow">https:&#x2F;&#x2F;paperswithcode.com&#x2F;paper&#x2F;language-models-represent-s...</a><p>[2] <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;StableDiffusion&#x2F;comments&#x2F;15he3f4&#x2F;elven_rings_sdxl_10_offset_lora&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;StableDiffusion&#x2F;comments&#x2F;15he3f4&#x2F;el...</a><p>[3] <a href="https:&#x2F;&#x2F;www.metaculus.com&#x2F;questions&#x2F;5121&#x2F;date-of-artificial-general-intelligence&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.metaculus.com&#x2F;questions&#x2F;5121&#x2F;date-of-artificial-...</a><p>[4] <a href="https:&#x2F;&#x2F;www.metaculus.com&#x2F;questions&#x2F;3479&#x2F;date-weakly-general-ai-is-publicly-known&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.metaculus.com&#x2F;questions&#x2F;3479&#x2F;date-weakly-general...</a></div><br/><div id="41653124" class="c"><input type="checkbox" id="c-41653124" checked=""/><div class="controls bullet"><span class="by">PollardsRho</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652197">parent</a><span>|</span><a href="#41652464">next</a><span>|</span><label class="collapse" for="c-41653124">[-]</label><label class="expand" for="c-41653124">[2 more]</label></div><br/><div class="children"><div class="content">&gt; its scaling keeps going with no end in sight.<p>Not only are we within eyesight of the end, we&#x27;re more or less there. o1 isn&#x27;t just scaling up parameter count 10x again and making GPT-5, because that&#x27;s not really an effective approach at this point in the exponential curve of parameter count and model performance.<p>I agree with the broader point: I&#x27;m not sure it isn&#x27;t consistent with current neuroscience that our brains aren&#x27;t doing anything more than predicting next inputs in a broadly similar way, and any categorical distinction between AI and human intelligence seems quite challenging.<p>I disagree that we can draw a line from scaling current transformer models to AGI, however. A model that is great for communicating with people in natural language may not be the best for deep reasoning, abstraction, unified creative visions over long-form generations, motor control, planning, etc. The history of computer science is littered with simple extrapolations from existing technology that completely missed the need for a paradigm shift.</div><br/><div id="41653861" class="c"><input type="checkbox" id="c-41653861" checked=""/><div class="controls bullet"><span class="by">versteegen</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653124">parent</a><span>|</span><a href="#41652464">next</a><span>|</span><label class="collapse" for="c-41653861">[-]</label><label class="expand" for="c-41653861">[1 more]</label></div><br/><div class="children"><div class="content">The fact that OpenAI created and released o1 doesn&#x27;t mean they won&#x27;t also scale models upwards or don&#x27;t think it&#x27;s their best hope. There&#x27;s been plenty said implying that they are.<p>I definitely agree that AGI isn&#x27;t just a matter of scaling transformers, and also as you say that they &quot;may not be the best&quot; for such tasks. (Vanilla transformers are extremely inefficient.) But the really important point is that transformers <i>can</i> do things such as abstract, reason, form world models and theories of minds, etc, <i>to a significant degree</i> (a much greater degree than virtually anyone would have predicted 5-10 years ago), all learnt <i>automatically</i>. It shows these problems are actually tractable for connectionist machine learning, without a paradigm shift as you and many others allege. That is the part I disagree with. But more breakthroughs needed.</div><br/></div></div></div></div><div id="41652464" class="c"><input type="checkbox" id="c-41652464" checked=""/><div class="controls bullet"><span class="by">iLoveOncall</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652197">parent</a><span>|</span><a href="#41653124">prev</a><span>|</span><a href="#41651873">next</a><span>|</span><label class="collapse" for="c-41652464">[-]</label><label class="expand" for="c-41652464">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Generative video models like OpenAI&#x27;s Sora clearly have a world model as they are able to simulate gravity, collisions between objects, and other concepts necessary to render a coherent scene.<p>I won&#x27;t expand on the rest, but this is simply nonsensical.<p>The fact that Sora generates output that matches its training data doesn&#x27;t show that it has a concept of gravity, collision between object, or anything else. It has a &quot;world model&quot; the same way a photocopier has a &quot;document model&quot;.</div><br/><div id="41652650" class="c"><input type="checkbox" id="c-41652650" checked=""/><div class="controls bullet"><span class="by">svara</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652464">parent</a><span>|</span><a href="#41651873">next</a><span>|</span><label class="collapse" for="c-41652650">[-]</label><label class="expand" for="c-41652650">[3 more]</label></div><br/><div class="children"><div class="content">My suspicion is that you&#x27;re leaving some important parts in your logic unstated. Such as belief in a magical property within humans of &quot;understanding&quot;, which you don&#x27;t define.<p>The ability of video models to generate novel video consistent with physical reality shows that they have extracted important invariants - physical law - out of the data.<p>It&#x27;s probably better not to muddle the discussion with ill defined terms such as &quot;intelligence&quot; or &quot;understanding&quot;.<p>I have my own beef with the AGI is nigh crowd, but this criticism amounts to word play.</div><br/><div id="41652881" class="c"><input type="checkbox" id="c-41652881" checked=""/><div class="controls bullet"><span class="by">phatfish</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652650">parent</a><span>|</span><a href="#41653370">next</a><span>|</span><label class="collapse" for="c-41652881">[-]</label><label class="expand" for="c-41652881">[1 more]</label></div><br/><div class="children"><div class="content">It feels like if these image and video generation models were really resolving some fundamental laws from the training data they should at least be able to re-create an image at a different angle.</div><br/></div></div><div id="41653370" class="c"><input type="checkbox" id="c-41653370" checked=""/><div class="controls bullet"><span class="by">some1else</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652650">parent</a><span>|</span><a href="#41652881">prev</a><span>|</span><a href="#41651873">next</a><span>|</span><label class="collapse" for="c-41653370">[-]</label><label class="expand" for="c-41653370">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Allegory of the cave&quot; comes to mind, when trying to describe the understanding that&#x27;s missing from diffusion models. I think a super-model with such qualifications would require a number of ControlNets in a non-visual domains to be able to encode understanding of the underlying physics. Diffusion models can render permutations of whatever they&#x27;ve seen fairly well without that, though.</div><br/></div></div></div></div></div></div></div></div><div id="41651873" class="c"><input type="checkbox" id="c-41651873" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651797">parent</a><span>|</span><a href="#41652197">prev</a><span>|</span><a href="#41652235">next</a><span>|</span><label class="collapse" for="c-41651873">[-]</label><label class="expand" for="c-41651873">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not saying you&#x27;re wrong but you could use this reductive rhetorical strategy to dismiss any AI algorithm. &quot;It&#x27;s just X&quot; is frankly shallow criticism.</div><br/><div id="41651942" class="c"><input type="checkbox" id="c-41651942" checked=""/><div class="controls bullet"><span class="by">timr</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651873">parent</a><span>|</span><a href="#41651937">next</a><span>|</span><label class="collapse" for="c-41651942">[-]</label><label class="expand" for="c-41651942">[4 more]</label></div><br/><div class="children"><div class="content">And you can dismiss any argument with your response.<p>&quot;Your argument is just a reductive rhetorical strategy.&quot;</div><br/><div id="41652615" class="c"><input type="checkbox" id="c-41652615" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651942">parent</a><span>|</span><a href="#41651937">next</a><span>|</span><label class="collapse" for="c-41652615">[-]</label><label class="expand" for="c-41652615">[3 more]</label></div><br/><div class="children"><div class="content">Sure if you ignore context.<p>&quot;a probabilistic syllable generator is not intelligence, it does not understand us, it cannot reason&quot; is a strong statement and I highly doubt it&#x27;s backed by any sort of substance other than &quot;feelz&quot;.</div><br/><div id="41653296" class="c"><input type="checkbox" id="c-41653296" checked=""/><div class="controls bullet"><span class="by">timr</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652615">parent</a><span>|</span><a href="#41651937">next</a><span>|</span><label class="collapse" for="c-41653296">[-]</label><label class="expand" for="c-41653296">[2 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t ignore any more context than you did, but just I want to acknowledge the irony that &quot;context&quot; (specifically, here, any sort of memory that isn&#x27;t in the text context window) is <i>exactly</i> what is lacking with these models.<p>For example, even the dumbest dog has a memory, a strikingly advanced concept model of the world [1], a persistent state beyond the last conversation history, and an ability to reason (that doesn&#x27;t require re-running the same conversation sixteen bajillion times in a row). Transformer models do not. It&#x27;s really cool that they can input and barf out realistic-sounding text, but let&#x27;s keep in mind the obvious truths about what they are doing.<p>[1] &quot;I like food. Something that smells like food is in the square thing on the floor. Maybe if I tip it over food will come out, and I will find food. Oh no, the person looked at me strangely when I got close to the square thing! I am in trouble! I will have to do it when they&#x27;re not looking.&quot;</div><br/><div id="41653516" class="c"><input type="checkbox" id="c-41653516" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653296">parent</a><span>|</span><a href="#41651937">next</a><span>|</span><label class="collapse" for="c-41653516">[-]</label><label class="expand" for="c-41653516">[1 more]</label></div><br/><div class="children"><div class="content">&gt; that doesn&#x27;t require re-running the same conversation sixteen bajillion times in a row<p>Lets assume the dog visual systems run at 60 frames per second. If it takes 1 second to flip a bowl of food over then that&#x27;s 60 datapoints of cause-effect data that the dog&#x27;s brain learned from.<p>Assuming it&#x27;s the same for humans, lets say I go on a trip to the grocery store for 1 hour. That&#x27;s 216,000 data points from one trip. Not to mention auditory data, touch, smell, and even taste.<p>&gt; ability to reason [...] Transformer models do not<p>Can you tell me what reasoning is? Why can&#x27;t transformers reason? Note I said <i>transformers</i> not <i>llm&#x27;s</i>. You could make a reasonable (hah) case that current LLMs cannot reason (or at least very well) but why are transformers as an architecture doomed?<p>What about chain of thought? Some have made the claim that chain of thought adds recurrence to transformer models. That&#x27;s a pretty big shift, but you&#x27;ve already decided transformers are a dead end so no chance of that making a difference right?</div><br/></div></div></div></div></div></div></div></div><div id="41651937" class="c"><input type="checkbox" id="c-41651937" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651873">parent</a><span>|</span><a href="#41651942">prev</a><span>|</span><a href="#41651904">next</a><span>|</span><label class="collapse" for="c-41651937">[-]</label><label class="expand" for="c-41651937">[1 more]</label></div><br/><div class="children"><div class="content">&gt; to dismiss any AI algorithm<p>Or even human intelligence</div><br/></div></div><div id="41651904" class="c"><input type="checkbox" id="c-41651904" checked=""/><div class="controls bullet"><span class="by">iLoveOncall</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651873">parent</a><span>|</span><a href="#41651937">prev</a><span>|</span><a href="#41652235">next</a><span>|</span><label class="collapse" for="c-41651904">[-]</label><label class="expand" for="c-41651904">[3 more]</label></div><br/><div class="children"><div class="content">And there&#x27;s nothing wrong about that: the fact that _artificial intelligence_ will never lead to general intelligence isn&#x27;t exactly a hot take.</div><br/><div id="41652663" class="c"><input type="checkbox" id="c-41652663" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651904">parent</a><span>|</span><a href="#41652632">next</a><span>|</span><label class="collapse" for="c-41652663">[-]</label><label class="expand" for="c-41652663">[1 more]</label></div><br/><div class="children"><div class="content">It’s almost trolling at this point, though.</div><br/></div></div><div id="41652632" class="c"><input type="checkbox" id="c-41652632" checked=""/><div class="controls bullet"><span class="by">CooCooCaCha</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651904">parent</a><span>|</span><a href="#41652663">prev</a><span>|</span><a href="#41652235">next</a><span>|</span><label class="collapse" for="c-41652632">[-]</label><label class="expand" for="c-41652632">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s both a very general and very bold claim. I don&#x27;t think it&#x27;s unreasonable to say that&#x27;s too strong of a claim given how we don&#x27;t know what is possible yet and there&#x27;s frankly no good reason to completely dismiss the idea of artificial general intelligence.</div><br/></div></div></div></div></div></div><div id="41652235" class="c"><input type="checkbox" id="c-41652235" checked=""/><div class="controls bullet"><span class="by">Erem</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651797">parent</a><span>|</span><a href="#41651873">prev</a><span>|</span><a href="#41655666">next</a><span>|</span><label class="collapse" for="c-41652235">[-]</label><label class="expand" for="c-41652235">[1 more]</label></div><br/><div class="children"><div class="content">The only useful way to define an AGI is based on its capabilities, not its implementation details.<p>Based on capabilities alone, current LLMs demonstrate many of the capabilities practitioners ten years ago would have tossed into the AGI bucket.<p>What are some top capabilities (meaning inputs and outputs) you think are missing on the path between what we have now and AGI?</div><br/></div></div></div></div><div id="41655666" class="c"><input type="checkbox" id="c-41655666" checked=""/><div class="controls bullet"><span class="by">TrackerFF</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651797">prev</a><span>|</span><a href="#41652007">next</a><span>|</span><label class="collapse" for="c-41655666">[-]</label><label class="expand" for="c-41655666">[1 more]</label></div><br/><div class="children"><div class="content">Nothing difficult about it.<p>1) She has a very good big picture view of the market. She has probably identified some very specific problems that need to be solved, or at least knows where the demand lies.<p>2) She has the senior exec OpenAI pedigree, which makes raising funds almost trivial.<p>3) She can probably make as much, if not more, by branching out on her own - while having more control, and working on more interesting stuff.</div><br/></div></div><div id="41652007" class="c"><input type="checkbox" id="c-41652007" checked=""/><div class="controls bullet"><span class="by">apwell23</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41655666">prev</a><span>|</span><a href="#41651598">next</a><span>|</span><label class="collapse" for="c-41652007">[-]</label><label class="expand" for="c-41652007">[7 more]</label></div><br/><div class="children"><div class="content">Her rise didn&#x27;t make sense to me. Product manager at tesla to CTO at openAI with no technical background and a deleted profile ?<p>This is a very strange company to say the least.</div><br/><div id="41652655" class="c"><input type="checkbox" id="c-41652655" checked=""/><div class="controls bullet"><span class="by">nebula8804</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652007">parent</a><span>|</span><a href="#41652885">next</a><span>|</span><label class="collapse" for="c-41652655">[-]</label><label class="expand" for="c-41652655">[3 more]</label></div><br/><div class="children"><div class="content">&gt;Product manager at tesla to CTO at openAI with no technical background and a deleted profile ?<p>Doesn&#x27;t she have a dual bachelors in Mathematics and Mechanical Engineering?</div><br/><div id="41653325" class="c"><input type="checkbox" id="c-41653325" checked=""/><div class="controls bullet"><span class="by">apwell23</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652655">parent</a><span>|</span><a href="#41652885">next</a><span>|</span><label class="collapse" for="c-41653325">[-]</label><label class="expand" for="c-41653325">[2 more]</label></div><br/><div class="children"><div class="content">Thats what is needed to get a job as a product manager these days?</div><br/><div id="41653784" class="c"><input type="checkbox" id="c-41653784" checked=""/><div class="controls bullet"><span class="by">nebula8804</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653325">parent</a><span>|</span><a href="#41652885">next</a><span>|</span><label class="collapse" for="c-41653784">[-]</label><label class="expand" for="c-41653784">[1 more]</label></div><br/><div class="children"><div class="content">Well that and years of experience leading projects. Wasn&#x27;t she head of the Model X program at Tesla?<p>But my point is that she does have a technical background.</div><br/></div></div></div></div></div></div><div id="41652885" class="c"><input type="checkbox" id="c-41652885" checked=""/><div class="controls bullet"><span class="by">fzzzy</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652007">parent</a><span>|</span><a href="#41652655">prev</a><span>|</span><a href="#41652080">next</a><span>|</span><label class="collapse" for="c-41652885">[-]</label><label class="expand" for="c-41652885">[1 more]</label></div><br/><div class="children"><div class="content">You have to remember that OpenAI&#x27;s mission was considered absolute batshit insane back then.</div><br/></div></div><div id="41652080" class="c"><input type="checkbox" id="c-41652080" checked=""/><div class="controls bullet"><span class="by">alephnerd</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652007">parent</a><span>|</span><a href="#41652885">prev</a><span>|</span><a href="#41651598">next</a><span>|</span><label class="collapse" for="c-41652080">[-]</label><label class="expand" for="c-41652080">[2 more]</label></div><br/><div class="children"><div class="content">A significant portion of the old guard at OpenAI was part of the Effective Altruism, AI Alignment, and Open Philanthropy movement.<p>Most hiring in the foundational AI&#x2F;model space is very nepotistic and biased towards people in that clique.<p>Also, Elon Musk used to be the primary patron for OpenAI before losing interest during the AI Winter in the late 2010s.</div><br/><div id="41653025" class="c"><input type="checkbox" id="c-41653025" checked=""/><div class="controls bullet"><span class="by">comp_throw7</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652080">parent</a><span>|</span><a href="#41651598">next</a><span>|</span><label class="collapse" for="c-41653025">[-]</label><label class="expand" for="c-41653025">[1 more]</label></div><br/><div class="children"><div class="content">Which has zero explanatory power w.r.t. Murati, since she&#x27;s not part of that crowd at all.  But her previously working at an Elon company seems like a plausible route, if she did in fact join before he left OpenAI (since he left in Feb 2018).</div><br/></div></div></div></div></div></div><div id="41651598" class="c"><input type="checkbox" id="c-41651598" checked=""/><div class="controls bullet"><span class="by">ren_engineer</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41652007">prev</a><span>|</span><a href="#41651450">next</a><span>|</span><label class="collapse" for="c-41651598">[-]</label><label class="expand" for="c-41651598">[2 more]</label></div><br/><div class="children"><div class="content">most of the people seem to be leaving due to the direction where Altman is taking OpenAI. It went from a charity to him seemingly doing everything possible to monetize it for himself both directly and indirectly by him trying to raise funds for AI adjacent traditionally structured companies he controlled<p>probably not coincidence that she resigned at almost the same time the rumors about OpenAI completely removing the non-profit board are getting confirmed - <a href="https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;artificial-intelligence&#x2F;openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;artificial-intelligence&#x2F;o...</a></div><br/><div id="41652029" class="c"><input type="checkbox" id="c-41652029" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651598">parent</a><span>|</span><a href="#41651450">next</a><span>|</span><label class="collapse" for="c-41652029">[-]</label><label class="expand" for="c-41652029">[1 more]</label></div><br/><div class="children"><div class="content">Afaik, he&#x27;s exceedingly driven to do that, because if they run out of money Microsoft gets to pick the carcass clean.</div><br/></div></div></div></div><div id="41651450" class="c"><input type="checkbox" id="c-41651450" checked=""/><div class="controls bullet"><span class="by">tomrod</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651598">prev</a><span>|</span><a href="#41651729">next</a><span>|</span><label class="collapse" for="c-41651450">[-]</label><label class="expand" for="c-41651450">[29 more]</label></div><br/><div class="children"><div class="content">My take is that Altman recognizes LLM winter is coming and is trying to entrench.</div><br/><div id="41651625" class="c"><input type="checkbox" id="c-41651625" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651450">parent</a><span>|</span><a href="#41654855">next</a><span>|</span><label class="collapse" for="c-41651625">[-]</label><label class="expand" for="c-41651625">[20 more]</label></div><br/><div class="children"><div class="content">I don’t think we’re gonna see a winter. LLMs are here to stay. Natural language interfaces are great. Embeddings are incredibly useful.<p>They just won’t be the hottest thing since smartphones.</div><br/><div id="41652199" class="c"><input type="checkbox" id="c-41652199" checked=""/><div class="controls bullet"><span class="by">Yizahi</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651625">parent</a><span>|</span><a href="#41653067">next</a><span>|</span><label class="collapse" for="c-41652199">[-]</label><label class="expand" for="c-41652199">[1 more]</label></div><br/><div class="children"><div class="content">LLMs as programs are here to stay. The issue is with expenses&#x2F;revenue ratio all these LLM corpos have. According to Sequoia analyst (so not some anon on a forum) there is a giant money hole in that industry, and &quot;giant&quot; doesn&#x27;t even begins to describe it (iirc it was 600bln this summer). That whole industry will definitely see winter soon, even if all things Altman says would be true.</div><br/></div></div><div id="41653067" class="c"><input type="checkbox" id="c-41653067" checked=""/><div class="controls bullet"><span class="by">015a</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651625">parent</a><span>|</span><a href="#41652199">prev</a><span>|</span><a href="#41651789">next</a><span>|</span><label class="collapse" for="c-41653067">[-]</label><label class="expand" for="c-41653067">[1 more]</label></div><br/><div class="children"><div class="content">You just described what literally anyone who says &quot;AI Winter&quot; means; the technology doesn&#x27;t go away, companies still deploy it and evolve it, customers still pay for it, it just stops being so attractive to massive funding and we see fewer foundational breakthroughs.</div><br/></div></div><div id="41651789" class="c"><input type="checkbox" id="c-41651789" checked=""/><div class="controls bullet"><span class="by">xtracto</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651625">parent</a><span>|</span><a href="#41653067">prev</a><span>|</span><a href="#41651685">next</a><span>|</span><label class="collapse" for="c-41651789">[-]</label><label class="expand" for="c-41651789">[7 more]</label></div><br/><div class="children"><div class="content">I just made a (IMHO) cool test with OpenAI&#x2F;Linux&#x2F;TCL-TK:<p>&quot;write a TCL&#x2F;tk script file that is a &quot;frontend&quot; to the ls command:  It should provide checkboxes and dropdowns for the different options available in bash ls and a button &quot;RUN&quot; to run the configured ls command.  The output of the ls command should be displayed in a Text box inside the interface. The script must be runnable using tclsh&quot;<p>It didn&#x27;t get it right the first time (for some reason wants to put a `mainloop` instruction)  but after several corrections I got an ugly but pretty functional UI.<p>Imagine a Linux Distro that uses some kind of LLM generated interfaces to make its power more accessible. Maybe even &quot;self healing&quot;.<p>LLMs don&#x27;t stop amazing me personally.</div><br/><div id="41652013" class="c"><input type="checkbox" id="c-41652013" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651789">parent</a><span>|</span><a href="#41653911">next</a><span>|</span><label class="collapse" for="c-41652013">[-]</label><label class="expand" for="c-41652013">[4 more]</label></div><br/><div class="children"><div class="content">The issue (and I think what&#x27;s behind the thinking of AI skeptics) is previous experience with the sharp edge of the Pareto principle.<p>Current LLMs being 80% to being 100% useful doesn&#x27;t mean there&#x27;s only 20% effort left.<p>It means we got the lowest-hanging 80% of utility.<p>Bridging that last 20% is going to take a ton of work. Indeed, maybe 4x the effort that getting this far required.<p>And people also overestimate the utility of a solution that&#x27;s randomly wrong. It&#x27;s exceedingly difficult to build reliable systems when you&#x27;re stacking a 5% wrong solution on another 5% wrong solution on another 5% wrong solution...</div><br/><div id="41652580" class="c"><input type="checkbox" id="c-41652580" checked=""/><div class="controls bullet"><span class="by">nebula8804</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652013">parent</a><span>|</span><a href="#41653911">next</a><span>|</span><label class="collapse" for="c-41652580">[-]</label><label class="expand" for="c-41652580">[3 more]</label></div><br/><div class="children"><div class="content">Thank You! You have explained the exact issue I (and probably many others) are seeing trying to adopt AI for work. It is because of this I don&#x27;t worry about AI taking our jobs for now. You still need somewhat foundational knowledge in whatever you are trying to do in order to get that remaining 20%. Sometimes this means pushing back against the AI&#x27;s solution, other times it means reframing the question, and other times its just giving up and doing the work yourself. I keep seeing all these impressive toy demos and my experience (Angular and Flask dev) seem to indicate that it is not going to replace any subject matter expert anytime soon. (And I am referring to all the three major AI players as I regularly and religiously test all their releases).<p>&gt;And people also overestimate the utility of a solution that&#x27;s randomly wrong. It&#x27;s exceedingly difficult to build reliable systems when you&#x27;re stacking a 5% wrong solution on another 5% wrong solution on another 5% wrong solution...<p>I call this the merry go round of hell mixed with a cruel hall of mirrors. LLM spits out a solution with some errors, you tell it to fix the errors, it produces other errors or totally forgets important context from one prompt ago. You then fix those issues, it then introduces other issues or messes up the original fix. Rinse and repeat. God help you if you don&#x27;t actually know what you are doing, you&#x27;ll be trapped in that hall of mirrors for all of eternity slowly losing your sanity.</div><br/><div id="41654031" class="c"><input type="checkbox" id="c-41654031" checked=""/><div class="controls bullet"><span class="by">theGnuMe</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652580">parent</a><span>|</span><a href="#41653911">next</a><span>|</span><label class="collapse" for="c-41654031">[-]</label><label class="expand" for="c-41654031">[2 more]</label></div><br/><div class="children"><div class="content">and here we are arguing for internet points.</div><br/><div id="41654381" class="c"><input type="checkbox" id="c-41654381" checked=""/><div class="controls bullet"><span class="by">tomrod</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41654031">parent</a><span>|</span><a href="#41653911">next</a><span>|</span><label class="collapse" for="c-41654381">[-]</label><label class="expand" for="c-41654381">[1 more]</label></div><br/><div class="children"><div class="content">Much more meaningful to this existentialist.</div><br/></div></div></div></div></div></div></div></div><div id="41653911" class="c"><input type="checkbox" id="c-41653911" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651789">parent</a><span>|</span><a href="#41652013">prev</a><span>|</span><a href="#41652054">next</a><span>|</span><label class="collapse" for="c-41653911">[-]</label><label class="expand" for="c-41653911">[1 more]</label></div><br/><div class="children"><div class="content">It can work with things of very limited scope, like that you describe.<p>I wrote some data visualizations with Claude and aider.<p>For anything that someone would actually pay for (expecting the robustness of paid-for software) I don’t think we’re there.<p>The devil is in the details, after all. And detail is what you lose when running reality through a statistical model.</div><br/></div></div><div id="41652054" class="c"><input type="checkbox" id="c-41652054" checked=""/><div class="controls bullet"><span class="by">therouwboat</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651789">parent</a><span>|</span><a href="#41653911">prev</a><span>|</span><a href="#41651685">next</a><span>|</span><label class="collapse" for="c-41652054">[-]</label><label class="expand" for="c-41652054">[1 more]</label></div><br/><div class="children"><div class="content">Why make tool when you can just ask AI to give you filelist or files that you need?</div><br/></div></div></div></div><div id="41651685" class="c"><input type="checkbox" id="c-41651685" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651625">parent</a><span>|</span><a href="#41651789">prev</a><span>|</span><a href="#41651671">next</a><span>|</span><label class="collapse" for="c-41651685">[-]</label><label class="expand" for="c-41651685">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re useful in some situations, but extremely expensive to operate. It&#x27;s unclear if they&#x27;ll be profitable in the near future. OpenAI seems to be claiming they need an extra $XXX billion in investment before they can...?</div><br/></div></div><div id="41651671" class="c"><input type="checkbox" id="c-41651671" checked=""/><div class="controls bullet"><span class="by">eastbound</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651625">parent</a><span>|</span><a href="#41651685">prev</a><span>|</span><a href="#41654855">next</a><span>|</span><label class="collapse" for="c-41651671">[-]</label><label class="expand" for="c-41651671">[9 more]</label></div><br/><div class="children"><div class="content">It’s a glorified grammar corrector?</div><br/><div id="41651795" class="c"><input type="checkbox" id="c-41651795" checked=""/><div class="controls bullet"><span class="by">stocknoob</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651671">parent</a><span>|</span><a href="#41651857">next</a><span>|</span><label class="collapse" for="c-41651795">[-]</label><label class="expand" for="c-41651795">[2 more]</label></div><br/><div class="children"><div class="content">TIL Math Olympiad problems are simple grammar exercises.</div><br/><div id="41653885" class="c"><input type="checkbox" id="c-41653885" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651795">parent</a><span>|</span><a href="#41651857">next</a><span>|</span><label class="collapse" for="c-41653885">[-]</label><label class="expand" for="c-41653885">[1 more]</label></div><br/><div class="children"><div class="content">They do way more than correcting grammar, but tbf, they did make something like 10,000 submissions to the math Olympiad to get that score.<p>It’s not like it’ll do it consistently.<p>Just a marketing stunt.</div><br/></div></div></div></div><div id="41651857" class="c"><input type="checkbox" id="c-41651857" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651671">parent</a><span>|</span><a href="#41651795">prev</a><span>|</span><a href="#41651738">next</a><span>|</span><label class="collapse" for="c-41651857">[-]</label><label class="expand" for="c-41651857">[1 more]</label></div><br/><div class="children"><div class="content">If you consider responding to this:<p>&quot;oi i need lik a scrip or somfing 2 take pic of me screen evry sec for min, mac&quot;<p>with an actual (and usually functional) script to be &quot;glorified grammar corrector&quot;, then sure.</div><br/></div></div><div id="41651738" class="c"><input type="checkbox" id="c-41651738" checked=""/><div class="controls bullet"><span class="by">CharlieDigital</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651671">parent</a><span>|</span><a href="#41651857">prev</a><span>|</span><a href="#41654855">next</a><span>|</span><label class="collapse" for="c-41651738">[-]</label><label class="expand" for="c-41651738">[5 more]</label></div><br/><div class="children"><div class="content">Not really.<p>I think actually the best use case for LLMs is &quot;explainer&quot;.<p>When combined with RAG, it&#x27;s fantastic at taking a complex corpus of information and distilling it down into more digestible summaries.</div><br/><div id="41652101" class="c"><input type="checkbox" id="c-41652101" checked=""/><div class="controls bullet"><span class="by">bot347851834</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651738">parent</a><span>|</span><a href="#41654855">next</a><span>|</span><label class="collapse" for="c-41652101">[-]</label><label class="expand" for="c-41652101">[4 more]</label></div><br/><div class="children"><div class="content">Can you share an example of a use case you have in mind of this &quot;explainer + RAG&quot; combo you just described?<p>I think that RAG and RAG-based tooling around LLMs is gonna be the clear way forward for most companies with a properly constructed knowledge base but I wonder what you mean by &quot;explainer&quot;?.<p>Are you talking about asking an LLM something like &quot;in which way did the teams working on project X deal with Y problem?&quot; and then having it breaking it down for you? Or is there something more to it?</div><br/><div id="41652644" class="c"><input type="checkbox" id="c-41652644" checked=""/><div class="controls bullet"><span class="by">nebula8804</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652101">parent</a><span>|</span><a href="#41653271">next</a><span>|</span><label class="collapse" for="c-41652644">[-]</label><label class="expand" for="c-41652644">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not the OP but I got some fun ones that I think are what you are asking? I would also love to hear others interesting ideas&#x2F;findings.<p>1. I got this medical provider that has a webapp that downloads graphql data(basically json) to the frontend and shows <i>some</i> of the data to the template as a result while hiding the rest. Furthermore, I see that they hide even more info after I pay the bill. I download all the data, combine it with other historical data that I have downloaded and dumped it into the LLM. It spits out interesting insights about my health history, ways in which I have been unusually charged by my insurance, and the speed at which the company operates based on all the historical data showing time between appointment and the bill adjusted for the time of year. It then formats everything into an open format that is easy for me to self host. (HTML + JS tables). Its a tiny way to wrestle back control from the company until they wise up.<p>2. Companies are increasingly allowing customers to receive a &quot;backup&quot; of all the data they have on them(Thanks EU and California). For example Burger King&#x2F;Wendys allow this. What do they give you when you request data? A zip file filled with just a bunch of crud from their internal system. No worries: Dump it into the LLM and it tells you everything that the company knows about you in an easy to understand format (Bullet points in this case). You know when the company managed to track you, how much they &quot;remember&quot;, how much money they got out of you, your behaviors, etc.</div><br/></div></div><div id="41653271" class="c"><input type="checkbox" id="c-41653271" checked=""/><div class="controls bullet"><span class="by">CharlieDigital</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652101">parent</a><span>|</span><a href="#41652644">prev</a><span>|</span><a href="#41654855">next</a><span>|</span><label class="collapse" for="c-41653271">[-]</label><label class="expand" for="c-41653271">[2 more]</label></div><br/><div class="children"><div class="content">If you go to <a href="https:&#x2F;&#x2F;clinicaltrials.gov&#x2F;" rel="nofollow">https:&#x2F;&#x2F;clinicaltrials.gov&#x2F;</a>, you can see almost every clinical trial that&#x27;s registered in the US.<p>Some trials have their protocols published.<p>Here&#x27;s an example trial: <a href="https:&#x2F;&#x2F;clinicaltrials.gov&#x2F;study&#x2F;NCT06613256" rel="nofollow">https:&#x2F;&#x2F;clinicaltrials.gov&#x2F;study&#x2F;NCT06613256</a><p>And here&#x27;s the protocol: <a href="https:&#x2F;&#x2F;cdn.clinicaltrials.gov&#x2F;large-docs&#x2F;56&#x2F;NCT06613256&#x2F;Prot_000.pdf" rel="nofollow">https:&#x2F;&#x2F;cdn.clinicaltrials.gov&#x2F;large-docs&#x2F;56&#x2F;NCT06613256&#x2F;Pro...</a> It&#x27;s actually relatively short at 33 pages.  Some larger trials (especially oncology trials) can have protocols that are 200 pages long.<p>One of the big challenges with clinical trials is making this information more accessible to both patients (for informed consent) and the trial site staff (to avoid making mistakes, helping answer patient questions, even asking the right questions when negotiating the contract with a sponsor).<p>The gist of it here is exactly like you said: RAG to pull back the relevant chunks of a complex document like this and then LLM to explain and summarize the information in those chunks that makes it easier to digest.  That response can be tuned to the level of the reader by adding simple phrases like &quot;explain it to me at a high school level&quot;.</div><br/><div id="41654191" class="c"><input type="checkbox" id="c-41654191" checked=""/><div class="controls bullet"><span class="by">theGnuMe</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41653271">parent</a><span>|</span><a href="#41654855">next</a><span>|</span><label class="collapse" for="c-41654191">[-]</label><label class="expand" for="c-41654191">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s your experience with clinical trials?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41654855" class="c"><input type="checkbox" id="c-41654855" checked=""/><div class="controls bullet"><span class="by">piuantiderp</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651450">parent</a><span>|</span><a href="#41651625">prev</a><span>|</span><a href="#41651622">next</a><span>|</span><label class="collapse" for="c-41654855">[-]</label><label class="expand" for="c-41654855">[1 more]</label></div><br/><div class="children"><div class="content">A cash out</div><br/></div></div><div id="41651622" class="c"><input type="checkbox" id="c-41651622" checked=""/><div class="controls bullet"><span class="by">chinathrow</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651450">parent</a><span>|</span><a href="#41654855">prev</a><span>|</span><a href="#41651729">next</a><span>|</span><label class="collapse" for="c-41651622">[-]</label><label class="expand" for="c-41651622">[7 more]</label></div><br/><div class="children"><div class="content">Looking at ChatGPT or Claude coding output, it&#x27;s already here.</div><br/><div id="41651817" class="c"><input type="checkbox" id="c-41651817" checked=""/><div class="controls bullet"><span class="by">criticalfault</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651622">parent</a><span>|</span><a href="#41651729">next</a><span>|</span><label class="collapse" for="c-41651817">[-]</label><label class="expand" for="c-41651817">[6 more]</label></div><br/><div class="children"><div class="content">Bad?<p>I just tried Gemini and it was useless.</div><br/><div id="41652302" class="c"><input type="checkbox" id="c-41652302" checked=""/><div class="controls bullet"><span class="by">mnk47</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651817">parent</a><span>|</span><a href="#41652875">next</a><span>|</span><label class="collapse" for="c-41652302">[-]</label><label class="expand" for="c-41652302">[3 more]</label></div><br/><div class="children"><div class="content">Starting to wonder why this is so common in LLM discussions at HN.<p>Someone says &quot;X is the model that really impressive. Y is good too.&quot;<p>Then someone responds &quot;What?! I just used Z and it was terrible!&quot;<p>I see this at least once in practically every AI thread</div><br/><div id="41655330" class="c"><input type="checkbox" id="c-41655330" checked=""/><div class="controls bullet"><span class="by">rpmisms</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652302">parent</a><span>|</span><a href="#41654388">next</a><span>|</span><label class="collapse" for="c-41655330">[-]</label><label class="expand" for="c-41655330">[1 more]</label></div><br/><div class="children"><div class="content">It depends on what you&#x27;re writing. GPT-4 can pump out average React all day long. It&#x27;s next to useless with Laravel.</div><br/></div></div><div id="41654388" class="c"><input type="checkbox" id="c-41654388" checked=""/><div class="controls bullet"><span class="by">tomrod</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41652302">parent</a><span>|</span><a href="#41655330">prev</a><span>|</span><a href="#41652875">next</a><span>|</span><label class="collapse" for="c-41654388">[-]</label><label class="expand" for="c-41654388">[1 more]</label></div><br/><div class="children"><div class="content">Humans understand mean but struggle with variance.</div><br/></div></div></div></div><div id="41652875" class="c"><input type="checkbox" id="c-41652875" checked=""/><div class="controls bullet"><span class="by">fzzzy</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651817">parent</a><span>|</span><a href="#41652302">prev</a><span>|</span><a href="#41652252">next</a><span>|</span><label class="collapse" for="c-41652875">[-]</label><label class="expand" for="c-41652875">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re the one that chose to try Gemini for some reason.</div><br/></div></div><div id="41652252" class="c"><input type="checkbox" id="c-41652252" checked=""/><div class="controls bullet"><span class="by">andrewinardeer</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651817">parent</a><span>|</span><a href="#41652875">prev</a><span>|</span><a href="#41651729">next</a><span>|</span><label class="collapse" for="c-41652252">[-]</label><label class="expand" for="c-41652252">[1 more]</label></div><br/><div class="children"><div class="content">Google ought to hang its head in utter disgrace over the putrid swill they have the audacity to peddle under the Gemini label.<p>Their laughably overzealous nanny-state censorship, paired with a model so appallingly inept it would embarrass a chatbot from the 90s, makes it nothing short of highway robbery that this digital dumpster fire is permitted to masquerade as a product fit for public consumption.<p>The sheer gall of Google to foist this steaming pile of silicon refuse onto unsuspecting users borders on fraudulent.</div><br/></div></div></div></div></div></div></div></div><div id="41651729" class="c"><input type="checkbox" id="c-41651729" checked=""/><div class="controls bullet"><span class="by">elAhmo</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651450">prev</a><span>|</span><a href="#41651516">next</a><span>|</span><label class="collapse" for="c-41651729">[-]</label><label class="expand" for="c-41651729">[1 more]</label></div><br/><div class="children"><div class="content">It would be definitely difficult thing to walk away.<p>This is just one more in a series of massive red flags around this company, from the insanely convoluted governance scheme, over the board drama, to many executives and key people leaving afterwards. It feels like Sam is doing the cleanup and anyone who opposes him has no place at OpenAI.<p>This, coming around the time where there are rumors of possible change to the corporate structure to be more friendly to investors, is an interesting timing.</div><br/></div></div><div id="41651516" class="c"><input type="checkbox" id="c-41651516" checked=""/><div class="controls bullet"><span class="by">Apocryphon</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651729">prev</a><span>|</span><a href="#41654776">next</a><span>|</span><label class="collapse" for="c-41651516">[-]</label><label class="expand" for="c-41651516">[6 more]</label></div><br/><div class="children"><div class="content">What if she believes AGI is imminent and is relocating to a remote location to build a Faraday-shielded survival bunker.</div><br/><div id="41651811" class="c"><input type="checkbox" id="c-41651811" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651516">parent</a><span>|</span><a href="#41651561">next</a><span>|</span><label class="collapse" for="c-41651811">[-]</label><label class="expand" for="c-41651811">[3 more]</label></div><br/><div class="children"><div class="content">Then she hasn&#x27;t ((read or watched) and (found plausible)) any of the speculative fiction about how that&#x27;s not enough to keep you safe.</div><br/><div id="41651908" class="c"><input type="checkbox" id="c-41651908" checked=""/><div class="controls bullet"><span class="by">Apocryphon</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651811">parent</a><span>|</span><a href="#41651561">next</a><span>|</span><label class="collapse" for="c-41651908">[-]</label><label class="expand" for="c-41651908">[2 more]</label></div><br/><div class="children"><div class="content">No one knows how deep the bunker goes</div><br/><div id="41652102" class="c"><input type="checkbox" id="c-41652102" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651908">parent</a><span>|</span><a href="#41651561">next</a><span>|</span><label class="collapse" for="c-41652102">[-]</label><label class="expand" for="c-41652102">[1 more]</label></div><br/><div class="children"><div class="content">We can be reasonably confident of which side of the Mohorovičić discontinuity it may be, as existing tools would be necessary to create it in the first place.</div><br/></div></div></div></div></div></div><div id="41651561" class="c"><input type="checkbox" id="c-41651561" checked=""/><div class="controls bullet"><span class="by">wantsanagent</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651516">parent</a><span>|</span><a href="#41651811">prev</a><span>|</span><a href="#41654776">next</a><span>|</span><label class="collapse" for="c-41651561">[-]</label><label class="expand" for="c-41651561">[2 more]</label></div><br/><div class="children"><div class="content">This is now my head-canon.</div><br/><div id="41651730" class="c"><input type="checkbox" id="c-41651730" checked=""/><div class="controls bullet"><span class="by">tempodox</span><span>|</span><a href="#41651210">root</a><span>|</span><a href="#41651561">parent</a><span>|</span><a href="#41654776">next</a><span>|</span><label class="collapse" for="c-41651730">[-]</label><label class="expand" for="c-41651730">[1 more]</label></div><br/><div class="children"><div class="content">Laputan machine!</div><br/></div></div></div></div></div></div><div id="41654776" class="c"><input type="checkbox" id="c-41654776" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651516">prev</a><span>|</span><a href="#41653272">next</a><span>|</span><label class="collapse" for="c-41654776">[-]</label><label class="expand" for="c-41654776">[1 more]</label></div><br/><div class="children"><div class="content">Another theory: it’s possibly related to a change of heart at OpenAI to become a for-profit company. It is rumoured Altman’s gunning for a 7% stake in the for-profit entity. That would be very substantial at a $150B valuation.<p>Squeezing out senior execs could be a way for him to maximize his claim on the stake. Notwithstanding, the execs may have disagreed with the shift in culture.</div><br/></div></div><div id="41653272" class="c"><input type="checkbox" id="c-41653272" checked=""/><div class="controls bullet"><span class="by">hatthew</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41654776">prev</a><span>|</span><a href="#41653703">next</a><span>|</span><label class="collapse" for="c-41653272">[-]</label><label class="expand" for="c-41653272">[1 more]</label></div><br/><div class="children"><div class="content">Could also be that she just got tired of the day to day responsibilities. Maybe she realized she that she hasn&#x27;t been able to spend more than 5 minutes with her kids&#x2F;nieces&#x2F;nephews last week. Maybe she was going to murder someone if she had to sit through another day with 10 hours of meetings.<p>I don&#x27;t know her personal life or her feelings, but it doesn&#x27;t seem like a stretch to imagine that she was just <i>done</i>.</div><br/></div></div><div id="41651801" class="c"><input type="checkbox" id="c-41651801" checked=""/><div class="controls bullet"><span class="by">insane_dreamer</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41653703">prev</a><span>|</span><a href="#41653041">next</a><span>|</span><label class="collapse" for="c-41651801">[-]</label><label class="expand" for="c-41651801">[1 more]</label></div><br/><div class="children"><div class="content">What top executives write in these farewell letters often has little to do with their actual reasons for leaving.</div><br/></div></div><div id="41653041" class="c"><input type="checkbox" id="c-41653041" checked=""/><div class="controls bullet"><span class="by">mmaunder</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41651801">prev</a><span>|</span><a href="#41654348">next</a><span>|</span><label class="collapse" for="c-41653041">[-]</label><label class="expand" for="c-41653041">[1 more]</label></div><br/><div class="children"><div class="content">I think they have an innovation problem. There are a few signals wrt the o1 release that indicate this. Not really a new model but an old model with CoT. And the missing system prompt - because they&#x27;re using it internally now. Also seeing 500 errors from their REST endpoints intermittently.</div><br/></div></div><div id="41654348" class="c"><input type="checkbox" id="c-41654348" checked=""/><div class="controls bullet"><span class="by">mvkel</span><span>|</span><a href="#41651210">parent</a><span>|</span><a href="#41653041">prev</a><span>|</span><a href="#41652023">next</a><span>|</span><label class="collapse" for="c-41654348">[-]</label><label class="expand" for="c-41654348">[1 more]</label></div><br/><div class="children"><div class="content">A couple of the original inventors of the transformer left Google to start crypto companies.</div><br/></div></div></div></div><div id="41652023" class="c"><input type="checkbox" id="c-41652023" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#41651210">prev</a><span>|</span><a href="#41653326">next</a><span>|</span><label class="collapse" for="c-41652023">[-]</label><label class="expand" for="c-41652023">[14 more]</label></div><br/><div class="children"><div class="content">I will never understand why people still take statements like these at face value. These aren&#x27;t her personal thoughts and feelings. The letter was carefully crafted by OpenAI&#x27;s PR team under strict direction from Sam and the board. Whatever the real story is is sitting under many layers of NDAs and threats of clawing back&#x2F;diluting her shares, and we will not know it for a long time. What I can say for certain is no executive in her position ever willingly resigns to pursue different passions&#x2F;spend more time with their family&#x2F;enjoy retirement or whatever else.</div><br/><div id="41655022" class="c"><input type="checkbox" id="c-41655022" checked=""/><div class="controls bullet"><span class="by">h4ny</span><span>|</span><a href="#41652023">parent</a><span>|</span><a href="#41653186">next</a><span>|</span><label class="collapse" for="c-41655022">[-]</label><label class="expand" for="c-41655022">[1 more]</label></div><br/><div class="children"><div class="content">It sounds like you probably are already aware, but perhaps most people don&#x27;t take statements like those at face value but we have all been conditioned to &quot;shut up and move on&quot;, by people who appear to be able to hold our careers hostage if we displease them.</div><br/></div></div><div id="41653186" class="c"><input type="checkbox" id="c-41653186" checked=""/><div class="controls bullet"><span class="by">mayneack</span><span>|</span><a href="#41652023">parent</a><span>|</span><a href="#41655022">prev</a><span>|</span><a href="#41652177">next</a><span>|</span><label class="collapse" for="c-41653186">[-]</label><label class="expand" for="c-41653186">[1 more]</label></div><br/><div class="children"><div class="content">I mostly agree that &quot;willingly resigns to pursue other passions&quot; is unlikely however &quot;quit in frustration over $working_conditions&quot; is completely plausible. Those could be anything from disagreeing with some strategy or thinking your boss is too much of a jerk to work with over your alternative options.</div><br/></div></div><div id="41652177" class="c"><input type="checkbox" id="c-41652177" checked=""/><div class="controls bullet"><span class="by">davesque</span><span>|</span><a href="#41652023">parent</a><span>|</span><a href="#41653186">prev</a><span>|</span><a href="#41653571">next</a><span>|</span><label class="collapse" for="c-41652177">[-]</label><label class="expand" for="c-41652177">[4 more]</label></div><br/><div class="children"><div class="content">&gt; no executive in her position ever willingly resigns to pursue different passions&#x2F;spend more time with their family&#x2F;enjoy retirement or whatever else<p>Especially when they enjoy a position like hers at the most important technology company in a generation.</div><br/><div id="41653479" class="c"><input type="checkbox" id="c-41653479" checked=""/><div class="controls bullet"><span class="by">norir</span><span>|</span><a href="#41652023">root</a><span>|</span><a href="#41652177">parent</a><span>|</span><a href="#41653571">next</a><span>|</span><label class="collapse" for="c-41653479">[-]</label><label class="expand" for="c-41653479">[3 more]</label></div><br/><div class="children"><div class="content">Time will tell about openai&#x27;s true import. Right now, the jury is very much out. Even in the llm space, it is not clear that openai will be the ultimate victor. Especially if they keep hemorrhaging talent.</div><br/><div id="41653989" class="c"><input type="checkbox" id="c-41653989" checked=""/><div class="controls bullet"><span class="by">salomonk_mur</span><span>|</span><a href="#41652023">root</a><span>|</span><a href="#41653479">parent</a><span>|</span><a href="#41653571">next</a><span>|</span><label class="collapse" for="c-41653989">[-]</label><label class="expand" for="c-41653989">[2 more]</label></div><br/><div class="children"><div class="content">Still, certainly the most visible.</div><br/><div id="41654279" class="c"><input type="checkbox" id="c-41654279" checked=""/><div class="controls bullet"><span class="by">cleandreams</span><span>|</span><a href="#41652023">root</a><span>|</span><a href="#41653989">parent</a><span>|</span><a href="#41653571">next</a><span>|</span><label class="collapse" for="c-41654279">[-]</label><label class="expand" for="c-41654279">[1 more]</label></div><br/><div class="children"><div class="content">They also get the most revenue and users.</div><br/></div></div></div></div></div></div></div></div><div id="41653571" class="c"><input type="checkbox" id="c-41653571" checked=""/><div class="controls bullet"><span class="by">dougb5</span><span>|</span><a href="#41652023">parent</a><span>|</span><a href="#41652177">prev</a><span>|</span><a href="#41655453">next</a><span>|</span><label class="collapse" for="c-41653571">[-]</label><label class="expand" for="c-41653571">[1 more]</label></div><br/><div class="children"><div class="content">There may be a story, and I&#x27;m sure she worded the message carefully, but I don&#x27;t see any reason to doubt she worded it herself.  &quot;Create the time and space to do my own exploration&quot; is beautiful compared to the usual.  To me means she is confident enough in her ability to do good in the world that the corporate identity she&#x27;s now tethered to is insignificant by comparison.</div><br/></div></div><div id="41655453" class="c"><input type="checkbox" id="c-41655453" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#41652023">parent</a><span>|</span><a href="#41653571">prev</a><span>|</span><a href="#41652131">next</a><span>|</span><label class="collapse" for="c-41655453">[-]</label><label class="expand" for="c-41655453">[1 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t such a statement rather be written by her own lawyers and trusted advisors?<p>Either way, it&#x27;s meaningless prose.</div><br/></div></div><div id="41652131" class="c"><input type="checkbox" id="c-41652131" checked=""/><div class="controls bullet"><span class="by">tasuki</span><span>|</span><a href="#41652023">parent</a><span>|</span><a href="#41655453">prev</a><span>|</span><a href="#41652932">next</a><span>|</span><label class="collapse" for="c-41652131">[-]</label><label class="expand" for="c-41652131">[4 more]</label></div><br/><div class="children"><div class="content">&gt; What I can say for certain is no executive in her position ever willingly resigns to pursue different passions&#x2F;spend more time with their family&#x2F;enjoy retirement or whatever else.<p>Do you think that&#x27;s because executives are so exceedingly ambitious, or because pursuing different passions is for some reason less attractive?</div><br/><div id="41652552" class="c"><input type="checkbox" id="c-41652552" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41652023">root</a><span>|</span><a href="#41652131">parent</a><span>|</span><a href="#41652372">next</a><span>|</span><label class="collapse" for="c-41652552">[-]</label><label class="expand" for="c-41652552">[2 more]</label></div><br/><div class="children"><div class="content">I would say that reaching this type of position requires exceeding amount of ambition, drive and craving in the first place, and all and any steps during the process of getting there solidify that by giving the dopamine hits to be addicted to such success, so it is not a case where you can just stop and decide &quot;I&#x27;ll chill now&quot;.</div><br/><div id="41654247" class="c"><input type="checkbox" id="c-41654247" checked=""/><div class="controls bullet"><span class="by">theGnuMe</span><span>|</span><a href="#41652023">root</a><span>|</span><a href="#41652552">parent</a><span>|</span><a href="#41652372">next</a><span>|</span><label class="collapse" for="c-41654247">[-]</label><label class="expand" for="c-41654247">[1 more]</label></div><br/><div class="children"><div class="content">Dopamine hits... I wonder if this explains why the OpenAI folks tweet a lot...
It&#x27;s kind of weird right, to tweet a lot?<p>But all these tweets from lower level execs as well.<p>I mean I love Machine Learning twitter hot takes because it exposes me to interesting ideas (and maybe that is why people tweet) but it seems more about status seeking&#x2F;marketing than anything else.  And really as I learn more, you see that the literature is iterating&#x2F;optimizing the current fashion.<p>But maybe no weirder than commenting here I guess though.. maybe this is weird.  
Have we all collectively asked ourselves, why do we comment here?  It&#x27;s gotta be
the dopamine.</div><br/></div></div></div></div><div id="41652372" class="c"><input type="checkbox" id="c-41652372" checked=""/><div class="controls bullet"><span class="by">paulcole</span><span>|</span><a href="#41652023">root</a><span>|</span><a href="#41652131">parent</a><span>|</span><a href="#41652552">prev</a><span>|</span><a href="#41652932">next</a><span>|</span><label class="collapse" for="c-41652372">[-]</label><label class="expand" for="c-41652372">[1 more]</label></div><br/><div class="children"><div class="content">It’s because they can’t imagine themselves doing it so they imagine that everyone must be like that. It’s part hubris and part lack of creativity&#x2F;empathy.<p>Think about if you’ve ever known someone you’ve been envious of for whatever reason who did something that just perplexed you. “They dumped their gorgeous partner, how could they do that?” “They quit a dream job, how could they do that?” “They moved out of that awesome apartment, how could they do that?” “They dropped out of that elite school, how could they do that?”<p>Very easily actually.<p>You’re seeing only part of the picture. Beautiful people are just as annoying as everybody else. Every dream job has a part that sucks.<p>If you can’t imagine that, you’re not trying hard enough.<p>You can see this in action in a lot of ways. One good one is the Ultimatum Game:<p><a href="https:&#x2F;&#x2F;www.core-econ.org&#x2F;the-economy&#x2F;microeconomics&#x2F;04-strategic-interactions-11-ultimatum-game.html" rel="nofollow">https:&#x2F;&#x2F;www.core-econ.org&#x2F;the-economy&#x2F;microeconomics&#x2F;04-stra...</a><p>Most people will end up thinking that they have an ironclad logical strategy but if you ask them about it, it’ll end up that their strategy is treating the other player as a carbon copy of themselves.</div><br/></div></div></div></div><div id="41652932" class="c"><input type="checkbox" id="c-41652932" checked=""/><div class="controls bullet"><span class="by">baxtr</span><span>|</span><a href="#41652023">parent</a><span>|</span><a href="#41652131">prev</a><span>|</span><a href="#41653326">next</a><span>|</span><label class="collapse" for="c-41652932">[-]</label><label class="expand" for="c-41652932">[1 more]</label></div><br/><div class="children"><div class="content">It was probably crafted with ChatGPT?</div><br/></div></div></div></div><div id="41653326" class="c"><input type="checkbox" id="c-41653326" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#41652023">prev</a><span>|</span><a href="#41651601">next</a><span>|</span><label class="collapse" for="c-41653326">[-]</label><label class="expand" for="c-41653326">[8 more]</label></div><br/><div class="children"><div class="content">Similar to when Andrei Karpathy left Tesla. Tesla was on the verge of &#x27;solving FSD&#x27; and unlocking trillions of $ of revenue (and mind you, this was already 3 years after the CEO said that they will have 1 million robotaxis on the road by the year&#x27;s end).<p>Guess what ? Tesla is still on the verge of &#x27;solving FSD&#x27;. And most probably it will be in the same place for the next 10 years.<p>The writing is on the wall for OpenAI.</div><br/><div id="41655914" class="c"><input type="checkbox" id="c-41655914" checked=""/><div class="controls bullet"><span class="by">yas_hmaheshwari</span><span>|</span><a href="#41653326">parent</a><span>|</span><a href="#41654449">next</a><span>|</span><label class="collapse" for="c-41655914">[-]</label><label class="expand" for="c-41655914">[1 more]</label></div><br/><div class="children"><div class="content">The original saying of &quot;fake it till you make it&quot; has been changed to &quot;say it till you make it&quot; :-)</div><br/></div></div><div id="41654449" class="c"><input type="checkbox" id="c-41654449" checked=""/><div class="controls bullet"><span class="by">vagab0nd</span><span>|</span><a href="#41653326">parent</a><span>|</span><a href="#41655914">prev</a><span>|</span><a href="#41651601">next</a><span>|</span><label class="collapse" for="c-41654449">[-]</label><label class="expand" for="c-41654449">[6 more]</label></div><br/><div class="children"><div class="content">I follow the latest updates to FSD and it&#x27;s clear to me that they are getting closer to robotaxis really fast.</div><br/><div id="41654530" class="c"><input type="checkbox" id="c-41654530" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#41653326">root</a><span>|</span><a href="#41654449">parent</a><span>|</span><a href="#41655112">next</a><span>|</span><label class="collapse" for="c-41654530">[-]</label><label class="expand" for="c-41654530">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what was said years ago.</div><br/></div></div><div id="41655112" class="c"><input type="checkbox" id="c-41655112" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#41653326">root</a><span>|</span><a href="#41654449">parent</a><span>|</span><a href="#41654530">prev</a><span>|</span><a href="#41654847">next</a><span>|</span><label class="collapse" for="c-41655112">[-]</label><label class="expand" for="c-41655112">[2 more]</label></div><br/><div class="children"><div class="content">FSD isn&#x27;t getting &quot;solved&quot; without outlawing human drivers, period. Otherwise you are trying to solve a non-deterministic system with deterministic software under a 0% error tolerance rate. Even without human drivers you still have to deal with all the non-vehicle entities that pop onto the road from time to time. Jaywalkers alone is almost as complex to deal with as human drivers.</div><br/><div id="41655926" class="c"><input type="checkbox" id="c-41655926" checked=""/><div class="controls bullet"><span class="by">WFHRenaissance</span><span>|</span><a href="#41653326">root</a><span>|</span><a href="#41655112">parent</a><span>|</span><a href="#41654847">next</a><span>|</span><label class="collapse" for="c-41655926">[-]</label><label class="expand" for="c-41655926">[1 more]</label></div><br/><div class="children"><div class="content">LOL this is BS. We have plenty of deterministic software being used to solve non-deterministic systems already. I agree that 0% error rate will require the removal of all human drivers from the system, but 0.0001% error rate will be seen as accepted risk.</div><br/></div></div></div></div><div id="41655043" class="c"><input type="checkbox" id="c-41655043" checked=""/><div class="controls bullet"><span class="by">TheAlchemist</span><span>|</span><a href="#41653326">root</a><span>|</span><a href="#41654449">parent</a><span>|</span><a href="#41654847">prev</a><span>|</span><a href="#41651601">next</a><span>|</span><label class="collapse" for="c-41655043">[-]</label><label class="expand" for="c-41655043">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I follow it too. There is progress for sure, one have to wonder if the CEO was very consciously lying 5, 8 years ago when he said they are less than 1 year away from robotaxis, given how shitty the system was.<p>They are on a path of linear improvement. They would need to go on a path of exponential improvement to have any hope of a working robotaxi in the next 2 years.<p>That&#x27;s not happening at all.</div><br/></div></div></div></div></div></div><div id="41651601" class="c"><input type="checkbox" id="c-41651601" checked=""/><div class="controls bullet"><span class="by">ruddct</span><span>|</span><a href="#41653326">prev</a><span>|</span><a href="#41653251">next</a><span>|</span><label class="collapse" for="c-41651601">[-]</label><label class="expand" for="c-41651601">[15 more]</label></div><br/><div class="children"><div class="content">Related (possibly): OpenAI to remove non-profit control and give Sam Altman equity<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41651548">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41651548</a></div><br/><div id="41651946" class="c"><input type="checkbox" id="c-41651946" checked=""/><div class="controls bullet"><span class="by">Recursing</span><span>|</span><a href="#41651601">parent</a><span>|</span><a href="#41655290">next</a><span>|</span><label class="collapse" for="c-41651946">[-]</label><label class="expand" for="c-41651946">[8 more]</label></div><br/><div class="children"><div class="content">Interesting that gwern predicted this as well yesterday<p>&gt; Translation for the rest of us: &quot;we need to fully privatize the OA subsidiary and turn it into a B-corp which can raise a lot more capital over the next decade, in order to achieve the goals of the nonprofit, because the chief threat is not anything like existential risk from autonomous agents in the next few years or arms races, but inadequate commercialization due to fundraising constraints&quot;.<p>&gt; It&#x27;s about laying the groundwork for the privatization and establishing rhetorical grounds for how the privatization of OA is consistent with the OA nonprofit&#x27;s legally-required mission and fiduciary duties. Altman is not writing to anyone here, he is, among others, writing to the OA nonprofit board and to the judge next year.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41629493">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41629493</a></div><br/><div id="41654236" class="c"><input type="checkbox" id="c-41654236" checked=""/><div class="controls bullet"><span class="by">usaar333</span><span>|</span><a href="#41651601">root</a><span>|</span><a href="#41651946">parent</a><span>|</span><a href="#41652025">next</a><span>|</span><label class="collapse" for="c-41654236">[-]</label><label class="expand" for="c-41654236">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not a novel prediction.  There were news reports nearly 2 weeks ago about this: <a href="https:&#x2F;&#x2F;fortune.com&#x2F;2024&#x2F;09&#x2F;13&#x2F;sam-altman-openai-non-profit-structure-change-next-year&#x2F;" rel="nofollow">https:&#x2F;&#x2F;fortune.com&#x2F;2024&#x2F;09&#x2F;13&#x2F;sam-altman-openai-non-profit-...</a><p>Gwern&#x27;s more novel prediction track record is calling everyone leaving from OpenAI (Mira was not expected) and general bullishness on scaling years ago. His post from 2 years ago (<a href="https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;mlscaling&#x2F;comments&#x2F;uznkhw&#x2F;gpt3_2nd_anniversary&#x2F;iab8vy2&#x2F;" rel="nofollow">https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;mlscaling&#x2F;comments&#x2F;uznkhw&#x2F;gpt3_2nd_...</a>) is mostly correct, though incorrectly believed large companies would not deploy user-facing LLMs (granted I think much of this is reasonably obvious?).  And Gato2 seems to have never happened.<p>His overall predictions? I can find his prediction book which he heavily used in 2010 (<a href="https:&#x2F;&#x2F;predictionbook.com&#x2F;users&#x2F;gwern&#x2F;page&#x2F;2?filter=judged&amp;tags=);" rel="nofollow">https:&#x2F;&#x2F;predictionbook.com&#x2F;users&#x2F;gwern&#x2F;page&#x2F;2?filter=judged&amp;...</a> Brier score of 0.16 is quite good, but this isn&#x27;t superforecaster level (there&#x27;s people with Brier scores below 0.1 on that site).<p>Overall, I see no reason to believe Gwern&#x27;s numbers over say the consensus prediction at metaculus, even though yes, I do love reading his analysis.</div><br/></div></div><div id="41652025" class="c"><input type="checkbox" id="c-41652025" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#41651601">root</a><span>|</span><a href="#41651946">parent</a><span>|</span><a href="#41654236">prev</a><span>|</span><a href="#41655290">next</a><span>|</span><label class="collapse" for="c-41652025">[-]</label><label class="expand" for="c-41652025">[6 more]</label></div><br/><div class="children"><div class="content">With multiple correct predictions, do you think the rest of HN will start to listen to Gwern’s beliefs about OpenAI &#x2F; AGI problems?<p>Probably not.</div><br/><div id="41652938" class="c"><input type="checkbox" id="c-41652938" checked=""/><div class="controls bullet"><span class="by">baxtr</span><span>|</span><a href="#41651601">root</a><span>|</span><a href="#41652025">parent</a><span>|</span><a href="#41655290">next</a><span>|</span><label class="collapse" for="c-41652938">[-]</label><label class="expand" for="c-41652938">[5 more]</label></div><br/><div class="children"><div class="content">I’m not aware of those beliefs. Could you provide a link to an article&#x2F; comment?</div><br/><div id="41653050" class="c"><input type="checkbox" id="c-41653050" checked=""/><div class="controls bullet"><span class="by">comp_throw7</span><span>|</span><a href="#41651601">root</a><span>|</span><a href="#41652938">parent</a><span>|</span><a href="#41653206">next</a><span>|</span><label class="collapse" for="c-41653050">[-]</label><label class="expand" for="c-41653050">[2 more]</label></div><br/><div class="children"><div class="content">This is somewhat high context, but as a random example: <a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;jtoPawEhLNXNxvgTT&#x2F;bing-chat-is-blatantly-aggressively-misaligned#ckwcde6QBaNw7yxCt" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;jtoPawEhLNXNxvgTT&#x2F;bing-chat-...</a></div><br/><div id="41655381" class="c"><input type="checkbox" id="c-41655381" checked=""/><div class="controls bullet"><span class="by">baxtr</span><span>|</span><a href="#41651601">root</a><span>|</span><a href="#41653050">parent</a><span>|</span><a href="#41653206">next</a><span>|</span><label class="collapse" for="c-41655381">[-]</label><label class="expand" for="c-41655381">[1 more]</label></div><br/><div class="children"><div class="content">So is he predicting that AGI is around the corner?</div><br/></div></div></div></div><div id="41653206" class="c"><input type="checkbox" id="c-41653206" checked=""/><div class="controls bullet"><span class="by">reducesuffering</span><span>|</span><a href="#41651601">root</a><span>|</span><a href="#41652938">parent</a><span>|</span><a href="#41653050">prev</a><span>|</span><a href="#41655290">next</a><span>|</span><label class="collapse" for="c-41653206">[-]</label><label class="expand" for="c-41653206">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;gwern.net&#x2F;fiction&#x2F;clippy" rel="nofollow">https:&#x2F;&#x2F;gwern.net&#x2F;fiction&#x2F;clippy</a><p>TL;DR spoiler from someone else is: <a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;a5e9arCnbDac9Doig&#x2F;it-looks-like-you-re-trying-to-take-over-the-world#QDKsFyDtkQRpi8jMe" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;a5e9arCnbDac9Doig&#x2F;it-looks-l...</a></div><br/><div id="41653395" class="c"><input type="checkbox" id="c-41653395" checked=""/><div class="controls bullet"><span class="by">andy_ppp</span><span>|</span><a href="#41651601">root</a><span>|</span><a href="#41653206">parent</a><span>|</span><a href="#41655290">next</a><span>|</span><label class="collapse" for="c-41653395">[-]</label><label class="expand" for="c-41653395">[1 more]</label></div><br/><div class="children"><div class="content">Are we sure it’s safe to suggest plans like this for the AI &#x2F;s</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41655290" class="c"><input type="checkbox" id="c-41655290" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#41651601">parent</a><span>|</span><a href="#41651946">prev</a><span>|</span><a href="#41653110">next</a><span>|</span><label class="collapse" for="c-41655290">[-]</label><label class="expand" for="c-41655290">[1 more]</label></div><br/><div class="children"><div class="content">Sensible move since most of the competition is operating under a more normal corporate model. I think the non profit thing at this point might be considered a failed experiment.<p>It didn&#x27;t really contain progress or experimentation. Lots of people are at this point using open source models independently from OpenAI. And a lot of those models aren&#x27;t that far behind qualitatively from what OpenAI is doing. And several of their competitors are starting to compete at the same level; mostly under normal corporate governance.<p>So, OpenAI adjusting to that isn&#x27;t that strange. It&#x27;s also going to be interesting to see where the people that are leaving OpenAI are going to end up. My prediction is that they will mostly end up in a variety of AI startups with traditional VC funding and usual corporate legal entities. And mostly not running or setting up their own foundations.</div><br/></div></div><div id="41653110" class="c"><input type="checkbox" id="c-41653110" checked=""/><div class="controls bullet"><span class="by">booleanbetrayal</span><span>|</span><a href="#41651601">parent</a><span>|</span><a href="#41655290">prev</a><span>|</span><a href="#41652491">next</a><span>|</span><label class="collapse" for="c-41653110">[-]</label><label class="expand" for="c-41653110">[2 more]</label></div><br/><div class="children"><div class="content">I would find it hard to believe this isn&#x27;t the critical factor in her departure. Surprising that the linked thread isn&#x27;t getting any traction. Or not?</div><br/><div id="41653781" class="c"><input type="checkbox" id="c-41653781" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41651601">root</a><span>|</span><a href="#41653110">parent</a><span>|</span><a href="#41652491">next</a><span>|</span><label class="collapse" for="c-41653781">[-]</label><label class="expand" for="c-41653781">[1 more]</label></div><br/><div class="children"><div class="content">146 points and never hit the front page even once. There&#x27;s definitely algorithmic shenanigans going on.<p><a href="https:&#x2F;&#x2F;hnrankings.info&#x2F;41651548&#x2F;" rel="nofollow">https:&#x2F;&#x2F;hnrankings.info&#x2F;41651548&#x2F;</a></div><br/></div></div></div></div><div id="41652491" class="c"><input type="checkbox" id="c-41652491" checked=""/><div class="controls bullet"><span class="by">teamonkey</span><span>|</span><a href="#41651601">parent</a><span>|</span><a href="#41653110">prev</a><span>|</span><a href="#41652412">next</a><span>|</span><label class="collapse" for="c-41652491">[-]</label><label class="expand" for="c-41652491">[2 more]</label></div><br/><div class="children"><div class="content">That post seems to be in free-fall for some reason</div><br/></div></div><div id="41652412" class="c"><input type="checkbox" id="c-41652412" checked=""/><div class="controls bullet"><span class="by">johnneville</span><span>|</span><a href="#41651601">parent</a><span>|</span><a href="#41652491">prev</a><span>|</span><a href="#41653251">next</a><span>|</span><label class="collapse" for="c-41652412">[-]</label><label class="expand" for="c-41652412">[1 more]</label></div><br/><div class="children"><div class="content">maybe they offered her little to no equity</div><br/></div></div></div></div><div id="41653251" class="c"><input type="checkbox" id="c-41653251" checked=""/><div class="controls bullet"><span class="by">bansheeps</span><span>|</span><a href="#41651601">prev</a><span>|</span><a href="#41651463">next</a><span>|</span><label class="collapse" for="c-41653251">[-]</label><label class="expand" for="c-41653251">[4 more]</label></div><br/><div class="children"><div class="content">Update: Looks like Barret Zoph, GPT-4&#x27;s post training (co-)lead is also leaving: <a href="https:&#x2F;&#x2F;x.com&#x2F;barret_zoph&#x2F;status&#x2F;1839095143397515452" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;barret_zoph&#x2F;status&#x2F;1839095143397515452</a></div><br/><div id="41655933" class="c"><input type="checkbox" id="c-41655933" checked=""/><div class="controls bullet"><span class="by">yas_hmaheshwari</span><span>|</span><a href="#41653251">parent</a><span>|</span><a href="#41653506">next</a><span>|</span><label class="collapse" for="c-41655933">[-]</label><label class="expand" for="c-41655933">[1 more]</label></div><br/><div class="children"><div class="content">Whoa!  This definitely looks much more troubling for the company now.  Can&#x27;t decide it is because AGI is coming very soon OR AGI is very far away</div><br/></div></div><div id="41653506" class="c"><input type="checkbox" id="c-41653506" checked=""/><div class="controls bullet"><span class="by">thundergolfer</span><span>|</span><a href="#41653251">parent</a><span>|</span><a href="#41655933">prev</a><span>|</span><a href="#41651463">next</a><span>|</span><label class="collapse" for="c-41653506">[-]</label><label class="expand" for="c-41653506">[2 more]</label></div><br/><div class="children"><div class="content">And now Bob McGrew, Chief of Research</div><br/><div id="41653692" class="c"><input type="checkbox" id="c-41653692" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41653251">root</a><span>|</span><a href="#41653506">parent</a><span>|</span><a href="#41651463">next</a><span>|</span><label class="collapse" for="c-41653692">[-]</label><label class="expand" for="c-41653692">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI is restructuring to be a for profit. Looks like that&#x27;s coming with a bunch of turnover.<p>I&#x27;m not sure why the HN algorithm never let it hit the front page, but there&#x27;s discussion here:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41651548">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41651548</a></div><br/></div></div></div></div></div></div><div id="41651463" class="c"><input type="checkbox" id="c-41651463" checked=""/><div class="controls bullet"><span class="by">keeptrying</span><span>|</span><a href="#41653251">prev</a><span>|</span><a href="#41651412">next</a><span>|</span><label class="collapse" for="c-41651463">[-]</label><label class="expand" for="c-41651463">[18 more]</label></div><br/><div class="children"><div class="content">If OpenAI is the foremost in solving the AGI - possibly the biggest invention of mankind - it&#x27;s a little weird that everyone&#x27;s dropping out.<p>Does it not look like that no one wants to work with Sam in the long run?</div><br/><div id="41651775" class="c"><input type="checkbox" id="c-41651775" checked=""/><div class="controls bullet"><span class="by">lionkor</span><span>|</span><a href="#41651463">parent</a><span>|</span><a href="#41652516">next</a><span>|</span><label class="collapse" for="c-41651775">[-]</label><label class="expand" for="c-41651775">[1 more]</label></div><br/><div class="children"><div class="content">Maybe its marketing and LLMs are the peak of what they are capable of.</div><br/></div></div><div id="41652516" class="c"><input type="checkbox" id="c-41652516" checked=""/><div class="controls bullet"><span class="by">onlyrealcuzzo</span><span>|</span><a href="#41651463">parent</a><span>|</span><a href="#41651775">prev</a><span>|</span><a href="#41651475">next</a><span>|</span><label class="collapse" for="c-41652516">[-]</label><label class="expand" for="c-41652516">[2 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t (dyst)OpenAI have a clause that you can&#x27;t say anything bad about the company after leaving?<p>I&#x27;m not convinced these board members are able to say what they want when leaving.</div><br/></div></div><div id="41651475" class="c"><input type="checkbox" id="c-41651475" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#41651463">parent</a><span>|</span><a href="#41652516">prev</a><span>|</span><a href="#41653111">next</a><span>|</span><label class="collapse" for="c-41651475">[-]</label><label class="expand" for="c-41651475">[1 more]</label></div><br/><div class="children"><div class="content">Or is it Sam who doesn&#x27;t want to work with them?</div><br/></div></div><div id="41653111" class="c"><input type="checkbox" id="c-41653111" checked=""/><div class="controls bullet"><span class="by">vl</span><span>|</span><a href="#41651463">parent</a><span>|</span><a href="#41651475">prev</a><span>|</span><a href="#41651836">next</a><span>|</span><label class="collapse" for="c-41653111">[-]</label><label class="expand" for="c-41653111">[1 more]</label></div><br/><div class="children"><div class="content">But it makes perfect sense to drop out and enjoy last couple years of pre-AGI bliss.<p>Advances in AI even without AGI will lead to unemployment, recession, collapse of our economic structure, and then our social structure. Whatever is on the other side is not pretty.<p>If you are on the forefront, know it’s coming imminently, and made your money, it makes perfect sense to leave and enjoy money and leisures money allows while money still worth something.</div><br/></div></div><div id="41651826" class="c"><input type="checkbox" id="c-41651826" checked=""/><div class="controls bullet"><span class="by">uhtred</span><span>|</span><a href="#41651463">parent</a><span>|</span><a href="#41651836">prev</a><span>|</span><a href="#41651769">next</a><span>|</span><label class="collapse" for="c-41651826">[-]</label><label class="expand" for="c-41651826">[7 more]</label></div><br/><div class="children"><div class="content">Artificial General Intelligence requires a bit more than parsing and predicting text I reckon.</div><br/><div id="41652035" class="c"><input type="checkbox" id="c-41652035" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651463">root</a><span>|</span><a href="#41651826">parent</a><span>|</span><a href="#41651912">next</a><span>|</span><label class="collapse" for="c-41652035">[-]</label><label class="expand" for="c-41652035">[3 more]</label></div><br/><div class="children"><div class="content">Yes, and transformer models can do more than text.<p>There&#x27;s almost certainly better options out there given it looks like we don&#x27;t need so many examples to learn from, though I&#x27;m not at all clear if we need those better ways or if we can get by without due to the abundance of training data.</div><br/><div id="41655731" class="c"><input type="checkbox" id="c-41655731" checked=""/><div class="controls bullet"><span class="by">rocqua</span><span>|</span><a href="#41651463">root</a><span>|</span><a href="#41652035">parent</a><span>|</span><a href="#41651912">next</a><span>|</span><label class="collapse" for="c-41655731">[-]</label><label class="expand" for="c-41655731">[2 more]</label></div><br/><div class="children"><div class="content">If you come up with a new system, you&#x27;re going to want to integrate AI into the system, presuming AI gets a bit better.<p>If AI can only learn after people have used the system for a year, then your system will just get ignored. After all, it lacks AI. And hence it will never get enough training data to get AI integration.<p>Learning needs to get faster. Otherwise, we will be stuck with the tools that already exist. New tools won&#x27;t just need to be possible to train humans on, but also to train AIs on.<p>Edit: a great example here is the Tamarin protocol prover. It would be great, and feasible, to get AI assistance to write these proofs. But there aren&#x27;t enough proofs out there to train on.</div><br/><div id="41656068" class="c"><input type="checkbox" id="c-41656068" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651463">root</a><span>|</span><a href="#41655731">parent</a><span>|</span><a href="#41651912">next</a><span>|</span><label class="collapse" for="c-41656068">[-]</label><label class="expand" for="c-41656068">[1 more]</label></div><br/><div class="children"><div class="content">If the user manual fits into the context window, existing LLMs can already do an OK-but-not-great job. Not previously heard of Tamarin, quick google suggests that&#x27;s a domain where the standard is theoretically &quot;you need to make zero errors&quot; but in practice is &quot;be better than your opponent because neither of you is close to perfect&quot;? In either case, have you tried giving the entire manual to the LLM context window?<p>If the new system can be interacted with in a non-destructive manner at low cost and with useful responses, then existing AI can self-generate the training data.<p>If it merely takes a year, businesses will rush to get that training data even if they need to pay humans for a bit: Cars are an example of &quot;real data is expensive or destructive&quot;, it&#x27;s clearly taking a lot more than a year to get there, and there&#x27;s a lot of investment in just that.<p>Pay 10,000 people USD 100,000 each for a year, that billion dollar investment then gets reduced to 2.4 million&#x2F;year in ChatGPT Plus subscription fees or whatever. Plenty of investors will take that deal… if you can actually be sure it will work.</div><br/></div></div></div></div></div></div><div id="41651912" class="c"><input type="checkbox" id="c-41651912" checked=""/><div class="controls bullet"><span class="by">stathibus</span><span>|</span><a href="#41651463">root</a><span>|</span><a href="#41651826">parent</a><span>|</span><a href="#41652035">prev</a><span>|</span><a href="#41651769">next</a><span>|</span><label class="collapse" for="c-41651912">[-]</label><label class="expand" for="c-41651912">[3 more]</label></div><br/><div class="children"><div class="content">at the very least you could say &quot;parsing and predicting text, images, and audio&quot;. and you would be correct - physical embodiment and spatial reasoning are missing.</div><br/><div id="41656079" class="c"><input type="checkbox" id="c-41656079" checked=""/><div class="controls bullet"><span class="by">Yizahi</span><span>|</span><a href="#41651463">root</a><span>|</span><a href="#41651912">parent</a><span>|</span><a href="#41652051">next</a><span>|</span><label class="collapse" for="c-41656079">[-]</label><label class="expand" for="c-41656079">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s all just text though, both images and audio are presented to LLM as a text, the training data is a text and all it does is append small bits of text to a larger text iteratively. So parent poster was correct.</div><br/></div></div><div id="41652051" class="c"><input type="checkbox" id="c-41652051" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41651463">root</a><span>|</span><a href="#41651912">parent</a><span>|</span><a href="#41656079">prev</a><span>|</span><a href="#41651769">next</a><span>|</span><label class="collapse" for="c-41652051">[-]</label><label class="expand" for="c-41652051">[1 more]</label></div><br/><div class="children"><div class="content">Just spatial resoning, people have already demonstrated it controlling robots.</div><br/></div></div></div></div></div></div><div id="41651769" class="c"><input type="checkbox" id="c-41651769" checked=""/><div class="controls bullet"><span class="by">ilrwbwrkhv</span><span>|</span><a href="#41651463">parent</a><span>|</span><a href="#41651826">prev</a><span>|</span><a href="#41651412">next</a><span>|</span><label class="collapse" for="c-41651769">[-]</label><label class="expand" for="c-41651769">[4 more]</label></div><br/><div class="children"><div class="content">Open AI fired her. She didn&#x27;t drop out.</div><br/><div id="41655958" class="c"><input type="checkbox" id="c-41655958" checked=""/><div class="controls bullet"><span class="by">_giorgio_</span><span>|</span><a href="#41651463">root</a><span>|</span><a href="#41651769">parent</a><span>|</span><a href="#41653241">next</a><span>|</span><label class="collapse" for="c-41655958">[-]</label><label class="expand" for="c-41655958">[1 more]</label></div><br/><div class="children"><div class="content">Yes. All the conspirators are out now.<p><a href="https:&#x2F;&#x2F;nypost.com&#x2F;2024&#x2F;03&#x2F;08&#x2F;business&#x2F;openai-chief-technology-officer-mira-murati-complained-about-sam-altman&#x2F;" rel="nofollow">https:&#x2F;&#x2F;nypost.com&#x2F;2024&#x2F;03&#x2F;08&#x2F;business&#x2F;openai-chief-technolo...</a></div><br/></div></div><div id="41653241" class="c"><input type="checkbox" id="c-41653241" checked=""/><div class="controls bullet"><span class="by">keeptrying</span><span>|</span><a href="#41651463">root</a><span>|</span><a href="#41651769">parent</a><span>|</span><a href="#41655958">prev</a><span>|</span><a href="#41651412">next</a><span>|</span><label class="collapse" for="c-41653241">[-]</label><label class="expand" for="c-41653241">[2 more]</label></div><br/><div class="children"><div class="content">Do you have any proof even circumstantial?</div><br/><div id="41655961" class="c"><input type="checkbox" id="c-41655961" checked=""/><div class="controls bullet"><span class="by">_giorgio_</span><span>|</span><a href="#41651463">root</a><span>|</span><a href="#41653241">parent</a><span>|</span><a href="#41651412">next</a><span>|</span><label class="collapse" for="c-41655961">[-]</label><label class="expand" for="c-41655961">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;nypost.com&#x2F;2024&#x2F;03&#x2F;08&#x2F;business&#x2F;openai-chief-technology-officer-mira-murati-complained-about-sam-altman&#x2F;" rel="nofollow">https:&#x2F;&#x2F;nypost.com&#x2F;2024&#x2F;03&#x2F;08&#x2F;business&#x2F;openai-chief-technolo...</a></div><br/></div></div></div></div></div></div></div></div><div id="41651412" class="c"><input type="checkbox" id="c-41651412" checked=""/><div class="controls bullet"><span class="by">codingwagie</span><span>|</span><a href="#41651463">prev</a><span>|</span><a href="#41651512">next</a><span>|</span><label class="collapse" for="c-41651412">[-]</label><label class="expand" for="c-41651412">[25 more]</label></div><br/><div class="children"><div class="content">My bet is all of these people can raise 20-100M for their own startups. And they are already rich enough to retire. OpenAI is going corporate</div><br/><div id="41651505" class="c"><input type="checkbox" id="c-41651505" checked=""/><div class="controls bullet"><span class="by">keeptrying</span><span>|</span><a href="#41651412">parent</a><span>|</span><a href="#41651512">next</a><span>|</span><label class="collapse" for="c-41651505">[-]</label><label class="expand" for="c-41651505">[24 more]</label></div><br/><div class="children"><div class="content">If you keep working past $10M net worth (as all these people undoubtedly are) its usually always for legacy.<p>I actually think Sam&#x27;s vision probably scares them.</div><br/><div id="41653293" class="c"><input type="checkbox" id="c-41653293" checked=""/><div class="controls bullet"><span class="by">patcon</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651505">parent</a><span>|</span><a href="#41651649">next</a><span>|</span><label class="collapse" for="c-41653293">[-]</label><label class="expand" for="c-41653293">[1 more]</label></div><br/><div class="children"><div class="content">When enough ppl visibly leave and have real concerns, they can be in touch in exile, and all break NDA in synchrony.<p>If the stakes are as high as some believe, I presume ppl don&#x27;t actually care about getting sued when they believe they&#x27;re helping humanity avert existential crisis.</div><br/></div></div><div id="41651649" class="c"><input type="checkbox" id="c-41651649" checked=""/><div class="controls bullet"><span class="by">brigadier132</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651505">parent</a><span>|</span><a href="#41653293">prev</a><span>|</span><a href="#41651647">next</a><span>|</span><label class="collapse" for="c-41651649">[-]</label><label class="expand" for="c-41651649">[5 more]</label></div><br/><div class="children"><div class="content">&gt; its usually always for legacy<p>Legacy is the dumbest reason to work and does not explain the motivation of the vast majority of people that are wealthy.<p>edit: The vast majority of people with more than $10million are completely unknown so the idea that they care about legacy is stupid.</div><br/><div id="41651972" class="c"><input type="checkbox" id="c-41651972" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651649">parent</a><span>|</span><a href="#41651647">next</a><span>|</span><label class="collapse" for="c-41651972">[-]</label><label class="expand" for="c-41651972">[4 more]</label></div><br/><div class="children"><div class="content">What do you think their motivations might be?</div><br/><div id="41652589" class="c"><input type="checkbox" id="c-41652589" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651972">parent</a><span>|</span><a href="#41652531">next</a><span>|</span><label class="collapse" for="c-41652589">[-]</label><label class="expand" for="c-41652589">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also addiction to success. If you don&#x27;t keep getting the success in magnitudes you did before, you will get bored and depressed, so you have to keep going and get it since your brain is wired to seek for that. Your brain and emotions are calibrated to what you got before, it&#x27;s kind of like drugs.<p>If you don&#x27;t have the 10M you won&#x27;t understand, you would think that &quot;oh my if only I had the 10M I would just chill&quot;, but it never works like that. Human appetite is infinite.<p>The more highs you get from success, the more you expect from the future achievements to get that same feeling, and if you don&#x27;t get any you will feel terrible. That&#x27;s it.</div><br/></div></div><div id="41652531" class="c"><input type="checkbox" id="c-41652531" checked=""/><div class="controls bullet"><span class="by">mr90210</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651972">parent</a><span>|</span><a href="#41652589">prev</a><span>|</span><a href="#41652600">next</a><span>|</span><label class="collapse" for="c-41652531">[-]</label><label class="expand" for="c-41652531">[1 more]</label></div><br/><div class="children"><div class="content">Speaking for myself, I&#x27;d keep working even if I had 100M. As long as I am healthy, I plan to continue on being productive towards something I find interesting.</div><br/></div></div></div></div></div></div><div id="41651647" class="c"><input type="checkbox" id="c-41651647" checked=""/><div class="controls bullet"><span class="by">hiddencost</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651505">parent</a><span>|</span><a href="#41651649">prev</a><span>|</span><a href="#41651512">next</a><span>|</span><label class="collapse" for="c-41651647">[-]</label><label class="expand" for="c-41651647">[17 more]</label></div><br/><div class="children"><div class="content">$10M doesn&#x27;t go as far as you&#x27;d think in the Bay Area or NYC.</div><br/><div id="41651713" class="c"><input type="checkbox" id="c-41651713" checked=""/><div class="controls bullet"><span class="by">_se</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651647">parent</a><span>|</span><a href="#41655124">next</a><span>|</span><label class="collapse" for="c-41651713">[-]</label><label class="expand" for="c-41651713">[10 more]</label></div><br/><div class="children"><div class="content">$10M is never work again money literally anywhere in the world. Don&#x27;t kid yourself. Buy a $3.5M house outright and then collect $250k per year risk free after taxes. You&#x27;re doing whatever you want and still saving money.</div><br/><div id="41652616" class="c"><input type="checkbox" id="c-41652616" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651713">parent</a><span>|</span><a href="#41653473">next</a><span>|</span><label class="collapse" for="c-41652616">[-]</label><label class="expand" for="c-41652616">[2 more]</label></div><br/><div class="children"><div class="content">The problem is if you are the type of person able to get to $10M, you&#x27;ll probably want more, since the motivation that got you there in the first place will keep you unsatisfied with anything less. You&#x27;ll constantly crave for more in terms of magnitudes.</div><br/><div id="41653252" class="c"><input type="checkbox" id="c-41653252" checked=""/><div class="controls bullet"><span class="by">keeptrying</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41652616">parent</a><span>|</span><a href="#41653473">next</a><span>|</span><label class="collapse" for="c-41653252">[-]</label><label class="expand" for="c-41653252">[1 more]</label></div><br/><div class="children"><div class="content">No. Know lots of people in this bucket.<p>Of course there are some who want $100M.<p>But most are really happy that they most likely don’t ever have to do anything they don’t like.</div><br/></div></div></div></div><div id="41653473" class="c"><input type="checkbox" id="c-41653473" checked=""/><div class="controls bullet"><span class="by">vl</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651713">parent</a><span>|</span><a href="#41652616">prev</a><span>|</span><a href="#41653382">next</a><span>|</span><label class="collapse" for="c-41653473">[-]</label><label class="expand" for="c-41653473">[3 more]</label></div><br/><div class="children"><div class="content">With 3.5M house just taxes, utilities and maintenance cost will ruin your remaining 7.5.</div><br/><div id="41654250" class="c"><input type="checkbox" id="c-41654250" checked=""/><div class="controls bullet"><span class="by">mindslight</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41653473">parent</a><span>|</span><a href="#41653382">next</a><span>|</span><label class="collapse" for="c-41654250">[-]</label><label class="expand" for="c-41654250">[2 more]</label></div><br/><div class="children"><div class="content">The neat part is that for a 3.5M house in the Bay area, the only maintenance required is changing the rain fly every year and the ground pad every couple.</div><br/><div id="41655844" class="c"><input type="checkbox" id="c-41655844" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41654250">parent</a><span>|</span><a href="#41653382">next</a><span>|</span><label class="collapse" for="c-41655844">[-]</label><label class="expand" for="c-41655844">[1 more]</label></div><br/><div class="children"><div class="content">And who is going to fix your shower when it leaks, and install solar panels, or redo your kitchen because your parents are living with you now and can&#x27;t bear to leave their traditional cooking behind?</div><br/></div></div></div></div></div></div><div id="41653382" class="c"><input type="checkbox" id="c-41653382" checked=""/><div class="controls bullet"><span class="by">kolbe</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651713">parent</a><span>|</span><a href="#41653473">prev</a><span>|</span><a href="#41655124">next</a><span>|</span><label class="collapse" for="c-41653382">[-]</label><label class="expand" for="c-41653382">[4 more]</label></div><br/><div class="children"><div class="content">Assuming they&#x27;re 40, how far do you think $250k will go 20-30-40 years from now? It&#x27;s not a stretch to think dollars could be devalued by 90%, possibly even worthless, within 30 years.</div><br/><div id="41653474" class="c"><input type="checkbox" id="c-41653474" checked=""/><div class="controls bullet"><span class="by">user90131313</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41653382">parent</a><span>|</span><a href="#41654152">next</a><span>|</span><label class="collapse" for="c-41653474">[-]</label><label class="expand" for="c-41653474">[2 more]</label></div><br/><div class="children"><div class="content">If portfolio is diversified enough it can be enough for decades? If dollar goes down some other things will go up. gold, Bitcoin etc.</div><br/><div id="41654513" class="c"><input type="checkbox" id="c-41654513" checked=""/><div class="controls bullet"><span class="by">kolbe</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41653474">parent</a><span>|</span><a href="#41654152">next</a><span>|</span><label class="collapse" for="c-41654513">[-]</label><label class="expand" for="c-41654513">[1 more]</label></div><br/><div class="children"><div class="content">The original comment was premised on them being income-generating assets, which gold and btc are not</div><br/></div></div></div></div><div id="41654152" class="c"><input type="checkbox" id="c-41654152" checked=""/><div class="controls bullet"><span class="by">chairmansteve</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41653382">parent</a><span>|</span><a href="#41653474">prev</a><span>|</span><a href="#41655124">next</a><span>|</span><label class="collapse" for="c-41654152">[-]</label><label class="expand" for="c-41654152">[1 more]</label></div><br/><div class="children"><div class="content">They obviously don&#x27;t keep it dollars. Diversify into equities, property etc.</div><br/></div></div></div></div></div></div><div id="41655124" class="c"><input type="checkbox" id="c-41655124" checked=""/><div class="controls bullet"><span class="by">ssnistfajen</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651647">parent</a><span>|</span><a href="#41651713">prev</a><span>|</span><a href="#41651969">next</a><span>|</span><label class="collapse" for="c-41655124">[-]</label><label class="expand" for="c-41655124">[1 more]</label></div><br/><div class="children"><div class="content">Only if you have runaway expenditures due to the lack of self-control and discipline.</div><br/></div></div><div id="41651969" class="c"><input type="checkbox" id="c-41651969" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651647">parent</a><span>|</span><a href="#41655124">prev</a><span>|</span><a href="#41652066">next</a><span>|</span><label class="collapse" for="c-41651969">[-]</label><label class="expand" for="c-41651969">[1 more]</label></div><br/><div class="children"><div class="content">Which is why smart retirees don&#x27;t fucking live there.</div><br/></div></div><div id="41652066" class="c"><input type="checkbox" id="c-41652066" checked=""/><div class="controls bullet"><span class="by">FactKnower69</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651647">parent</a><span>|</span><a href="#41651969">prev</a><span>|</span><a href="#41651770">next</a><span>|</span><label class="collapse" for="c-41652066">[-]</label><label class="expand" for="c-41652066">[1 more]</label></div><br/><div class="children"><div class="content">hilarious logical end progression of all those idiotic articles about $600k dual income households in the bay living &quot;paycheck to paycheck&quot;</div><br/></div></div><div id="41651770" class="c"><input type="checkbox" id="c-41651770" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651647">parent</a><span>|</span><a href="#41652066">prev</a><span>|</span><a href="#41651703">next</a><span>|</span><label class="collapse" for="c-41651770">[-]</label><label class="expand" for="c-41651770">[2 more]</label></div><br/><div class="children"><div class="content">Maybe it doesn&#x27;t if you think you&#x27;re just going to live off $10M in your checking account... but that&#x27;s generally not how that works.</div><br/><div id="41651866" class="c"><input type="checkbox" id="c-41651866" checked=""/><div class="controls bullet"><span class="by">fldskfjdslkfj</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651770">parent</a><span>|</span><a href="#41651703">next</a><span>|</span><label class="collapse" for="c-41651866">[-]</label><label class="expand" for="c-41651866">[1 more]</label></div><br/><div class="children"><div class="content">at 5% rate that&#x27;s a cushy 500k a year.</div><br/></div></div></div></div><div id="41651703" class="c"><input type="checkbox" id="c-41651703" checked=""/><div class="controls bullet"><span class="by">ForHackernews</span><span>|</span><a href="#41651412">root</a><span>|</span><a href="#41651647">parent</a><span>|</span><a href="#41651770">prev</a><span>|</span><a href="#41651512">next</a><span>|</span><label class="collapse" for="c-41651703">[-]</label><label class="expand" for="c-41651703">[1 more]</label></div><br/><div class="children"><div class="content">...the only two places on Earth.</div><br/></div></div></div></div></div></div></div></div><div id="41651512" class="c"><input type="checkbox" id="c-41651512" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#41651412">prev</a><span>|</span><a href="#41651889">next</a><span>|</span><label class="collapse" for="c-41651512">[-]</label><label class="expand" for="c-41651512">[5 more]</label></div><br/><div class="children"><div class="content">I am glad most people do not talk in real life using the same style this message was written in.</div><br/><div id="41651614" class="c"><input type="checkbox" id="c-41651614" checked=""/><div class="controls bullet"><span class="by">antoineMoPa</span><span>|</span><a href="#41651512">parent</a><span>|</span><a href="#41651889">next</a><span>|</span><label class="collapse" for="c-41651614">[-]</label><label class="expand" for="c-41651614">[4 more]</label></div><br/><div class="children"><div class="content">To me, this looks like something chatgpt would write.</div><br/><div id="41655974" class="c"><input type="checkbox" id="c-41655974" checked=""/><div class="controls bullet"><span class="by">betimsl</span><span>|</span><a href="#41651512">root</a><span>|</span><a href="#41651614">parent</a><span>|</span><a href="#41652918">next</a><span>|</span><label class="collapse" for="c-41655974">[-]</label><label class="expand" for="c-41655974">[1 more]</label></div><br/><div class="children"><div class="content">As an albanian, I can confirm she wrote it herself (obviously with the help of ChatGPT) -- no finesse and other writing elements.</div><br/></div></div><div id="41652918" class="c"><input type="checkbox" id="c-41652918" checked=""/><div class="controls bullet"><span class="by">latexr</span><span>|</span><a href="#41651512">root</a><span>|</span><a href="#41651614">parent</a><span>|</span><a href="#41655974">prev</a><span>|</span><a href="#41651980">next</a><span>|</span><label class="collapse" for="c-41652918">[-]</label><label class="expand" for="c-41652918">[1 more]</label></div><br/><div class="children"><div class="content">I am surprised I had to scroll down this far to find someone making this point. In addition to being the obvious joke in this situation, the message was so dull, generic, and “this incredible journey” that I instinctively began to read diagonally before finishing the second paragraph.</div><br/></div></div><div id="41651980" class="c"><input type="checkbox" id="c-41651980" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#41651512">root</a><span>|</span><a href="#41651614">parent</a><span>|</span><a href="#41652918">prev</a><span>|</span><a href="#41651889">next</a><span>|</span><label class="collapse" for="c-41651980">[-]</label><label class="expand" for="c-41651980">[1 more]</label></div><br/><div class="children"><div class="content">Or, like, any PR person from the past... forever.</div><br/></div></div></div></div></div></div><div id="41651889" class="c"><input type="checkbox" id="c-41651889" checked=""/><div class="controls bullet"><span class="by">neom</span><span>|</span><a href="#41651512">prev</a><span>|</span><a href="#41655371">next</a><span>|</span><label class="collapse" for="c-41651889">[-]</label><label class="expand" for="c-41651889">[2 more]</label></div><br/><div class="children"><div class="content">Lots of speculation in the comments. Who knows, but if it was me, I wouldn&#x27;t be keeping all my eggs in the OpenAI basket, 6 years and well vested with a long run of AI companies you could go to? I&#x27;d start buying a few more lottery tickets personally (especially at 35).</div><br/><div id="41652355" class="c"><input type="checkbox" id="c-41652355" checked=""/><div class="controls bullet"><span class="by">joshdavham</span><span>|</span><a href="#41651889">parent</a><span>|</span><a href="#41655371">next</a><span>|</span><label class="collapse" for="c-41652355">[-]</label><label class="expand" for="c-41652355">[1 more]</label></div><br/><div class="children"><div class="content">That was actually my first thought as well. If you’ve got your vesting and don’t wanna work in a large company setting anymore, why not go do something else?</div><br/></div></div></div></div><div id="41653005" class="c"><input type="checkbox" id="c-41653005" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41653789">prev</a><span>|</span><a href="#41654105">next</a><span>|</span><label class="collapse" for="c-41653005">[-]</label><label class="expand" for="c-41653005">[5 more]</label></div><br/><div class="children"><div class="content">&gt; we fundamentally changed how AI systems learn and reason through complex problems<p>I&#x27;m not an AI researcher, have they done this? The commentary I&#x27;ve seen on o1 is basically that they incorporated techniques that were already being used.<p>I&#x27;d also be curious to learn: what fundamental contributions to research has OpenAI made?<p>The ChatGPT that was released in 2022 was based on Google&#x27;s research, and IMO the internal Google chatbot from 2021 was better than the first ChatGPT.<p>I know they employ a lot of AI scientists who have previously published milestone work, and I&#x27;ve read at least one OpenAI paper. But I&#x27;m genuinely unaware of what fundamental breakthroughs they&#x27;ve made as a company.<p>I&#x27;m willing to believe they&#x27;ve done important work, and I&#x27;m seriously asking for pointers to some of it. What I know of them is mainly that they&#x27;ve been first to market with existing tech, possibly training on more data.</div><br/><div id="41653239" class="c"><input type="checkbox" id="c-41653239" checked=""/><div class="controls bullet"><span class="by">danpalmer</span><span>|</span><a href="#41653005">parent</a><span>|</span><a href="#41653152">next</a><span>|</span><label class="collapse" for="c-41653239">[-]</label><label class="expand" for="c-41653239">[2 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s inarguable that OpenAI have at least at times over the last 3 years been well ahead of other companies. Whether that&#x27;s true now is open to debate, but it has been true.<p>This suggests they have either: made substantial breakthroughs, that are <i>not open</i>, or that the better abilities of OpenAI products are due to non-substantial tweaks (more training, better prompting, etc).<p>I&#x27;m not sure either of these options is great for the original mission of OpenAI, although given their direction to &quot;Closed-AI&quot; I guess the former would be better for them.</div><br/><div id="41653542" class="c"><input type="checkbox" id="c-41653542" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41653005">root</a><span>|</span><a href="#41653239">parent</a><span>|</span><a href="#41653152">next</a><span>|</span><label class="collapse" for="c-41653542">[-]</label><label class="expand" for="c-41653542">[1 more]</label></div><br/><div class="children"><div class="content">I left pretty soon after a Google engineer decided the internal chat bot was sentient but before ChatGPT 3.5 came out. So I missed the entire period where Google was trying to catch up.<p>But it seemed to me before I left that they were struggling to productize the bot and keep it from saying things that damage the brand. That&#x27;s definitely something OpenAI figured out first.<p>I got the feeling that maybe Microsoft&#x27;s Tay experience cast a large shadow on Google&#x27;s willingness to take its chat bot public.</div><br/></div></div></div></div><div id="41653152" class="c"><input type="checkbox" id="c-41653152" checked=""/><div class="controls bullet"><span class="by">incognition</span><span>|</span><a href="#41653005">parent</a><span>|</span><a href="#41653239">prev</a><span>|</span><a href="#41654105">next</a><span>|</span><label class="collapse" for="c-41653152">[-]</label><label class="expand" for="c-41653152">[2 more]</label></div><br/><div class="children"><div class="content">Ilya was the Google researcher..</div><br/><div id="41653420" class="c"><input type="checkbox" id="c-41653420" checked=""/><div class="controls bullet"><span class="by">ants_everywhere</span><span>|</span><a href="#41653005">root</a><span>|</span><a href="#41653152">parent</a><span>|</span><a href="#41654105">next</a><span>|</span><label class="collapse" for="c-41653420">[-]</label><label class="expand" for="c-41653420">[1 more]</label></div><br/><div class="children"><div class="content">Wasn&#x27;t he at OpenAI when transformers and Google&#x27;s pretrained transformer BERT came out?</div><br/></div></div></div></div></div></div><div id="41654105" class="c"><input type="checkbox" id="c-41654105" checked=""/><div class="controls bullet"><span class="by">k1rd</span><span>|</span><a href="#41653005">prev</a><span>|</span><a href="#41652508">next</a><span>|</span><label class="collapse" for="c-41654105">[-]</label><label class="expand" for="c-41654105">[1 more]</label></div><br/><div class="children"><div class="content">If you leave him on an island of cannibals...
He will be the only one left.</div><br/></div></div><div id="41652508" class="c"><input type="checkbox" id="c-41652508" checked=""/><div class="controls bullet"><span class="by">w10-1</span><span>|</span><a href="#41654105">prev</a><span>|</span><a href="#41655894">next</a><span>|</span><label class="collapse" for="c-41652508">[-]</label><label class="expand" for="c-41652508">[1 more]</label></div><br/><div class="children"><div class="content">The disparity between size of the promise and the ambiguity of the business model creates both necessity and advantage for executives to leverage external forces to shape company direction.  Everyone in the C-suite would be seeking a foothold, but it&#x27;s unlikely any CTO or technologist would be the real nexus for partner and now investor relations.  So while there might be circumstances, history, and personalities involved, OpenAI&#x27;s current situation basically dictates this.<p>With luck, Mr. Altman&#x27;s overtures to bring in middle east investors will get locals on board; either way, it&#x27;s fair to say he&#x27;ll own whatever OpenAI becomes, whether he&#x27;s an owner or not.  And if he loses control in the current scrum, I suspect his replacement would be much worse (giving him yet another advantage).<p>Best wishes to all.</div><br/></div></div><div id="41655894" class="c"><input type="checkbox" id="c-41655894" checked=""/><div class="controls bullet"><span class="by">betimsl</span><span>|</span><a href="#41652508">prev</a><span>|</span><a href="#41651275">next</a><span>|</span><label class="collapse" for="c-41655894">[-]</label><label class="expand" for="c-41655894">[1 more]</label></div><br/><div class="children"><div class="content">a-few-moments-later.jpeg:
- She and the prime minister of Albania on the same photo</div><br/></div></div><div id="41651275" class="c"><input type="checkbox" id="c-41651275" checked=""/><div class="controls bullet"><span class="by">aresant</span><span>|</span><a href="#41655894">prev</a><span>|</span><a href="#41652409">next</a><span>|</span><label class="collapse" for="c-41651275">[-]</label><label class="expand" for="c-41651275">[4 more]</label></div><br/><div class="children"><div class="content">It is unsuprising that Murati is leaving, she was reported to be one of the principal advocates for pushing Sam out (1)<p>Of course everybody was quick to play nice once OpenAI insiders got the reality check from Satya that he&#x27;d just crush them by building an internal competing group, cut funding, and instantly destroy lots of paper millionaires.<p>I&#x27;d imagine that Mira and others had 6 - 12 month agreeements in place to let the dust settle and finish their latest round of funding without further drama<p>The OpenAI soap opera is going to be a great book or movie someday<p>(1) <a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;03&#x2F;07&#x2F;technology&#x2F;openai-executives-role-in-sam-altman-ouster.html" rel="nofollow">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;03&#x2F;07&#x2F;technology&#x2F;openai-executi...</a>?</div><br/><div id="41651965" class="c"><input type="checkbox" id="c-41651965" checked=""/><div class="controls bullet"><span class="by">mcast</span><span>|</span><a href="#41651275">parent</a><span>|</span><a href="#41652409">next</a><span>|</span><label class="collapse" for="c-41651965">[-]</label><label class="expand" for="c-41651965">[3 more]</label></div><br/><div class="children"><div class="content">Trent Reznor and David Fincher need to team up again to make a movie about this.</div><br/><div id="41655532" class="c"><input type="checkbox" id="c-41655532" checked=""/><div class="controls bullet"><span class="by">ackbar03</span><span>|</span><a href="#41651275">root</a><span>|</span><a href="#41651965">parent</a><span>|</span><a href="#41652442">next</a><span>|</span><label class="collapse" for="c-41655532">[-]</label><label class="expand" for="c-41655532">[1 more]</label></div><br/><div class="children"><div class="content">real question is did Michael Lewis happen to be hanging around the OpenAI water-coolers again when all this happened</div><br/></div></div><div id="41652442" class="c"><input type="checkbox" id="c-41652442" checked=""/><div class="controls bullet"><span class="by">fb03</span><span>|</span><a href="#41651275">root</a><span>|</span><a href="#41651965">parent</a><span>|</span><a href="#41655532">prev</a><span>|</span><a href="#41652409">next</a><span>|</span><label class="collapse" for="c-41652442">[-]</label><label class="expand" for="c-41652442">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d not complain if William Gibson got into the project as well.</div><br/></div></div></div></div></div></div><div id="41652409" class="c"><input type="checkbox" id="c-41652409" checked=""/><div class="controls bullet"><span class="by">charlie0</span><span>|</span><a href="#41651275">prev</a><span>|</span><a href="#41653706">next</a><span>|</span><label class="collapse" for="c-41652409">[-]</label><label class="expand" for="c-41652409">[2 more]</label></div><br/><div class="children"><div class="content">Will probably start her own company and raise a billy like her old pal Iyla. I wouldn&#x27;t blame her, there&#x27;s been so many articles that technical people should just start their own company instead of being CTO.</div><br/><div id="41655498" class="c"><input type="checkbox" id="c-41655498" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#41652409">parent</a><span>|</span><a href="#41653706">next</a><span>|</span><label class="collapse" for="c-41655498">[-]</label><label class="expand" for="c-41655498">[1 more]</label></div><br/><div class="children"><div class="content">Now I’m curious. Can you share some example articles please?</div><br/></div></div></div></div><div id="41653706" class="c"><input type="checkbox" id="c-41653706" checked=""/><div class="controls bullet"><span class="by">xyst</span><span>|</span><a href="#41652409">prev</a><span>|</span><a href="#41653752">next</a><span>|</span><label class="collapse" for="c-41653706">[-]</label><label class="expand" for="c-41653706">[1 more]</label></div><br/><div class="children"><div class="content">Company is circling the drain. Sam Altman must be a real nightmare to work with.</div><br/></div></div><div id="41653752" class="c"><input type="checkbox" id="c-41653752" checked=""/><div class="controls bullet"><span class="by">lossolo</span><span>|</span><a href="#41653706">prev</a><span>|</span><a href="#41651997">next</a><span>|</span><label class="collapse" for="c-41653752">[-]</label><label class="expand" for="c-41653752">[1 more]</label></div><br/><div class="children"><div class="content">Bob McGrew, head of research just quit too.<p>&quot;I just shared this with OpenAI&quot;<p><a href="https:&#x2F;&#x2F;x.com&#x2F;bobmcgrewai&#x2F;status&#x2F;1839099787423134051" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;bobmcgrewai&#x2F;status&#x2F;1839099787423134051</a><p>Barret Zoph, VP Research (Post-Training)<p>&quot;I posted this note to OpenAI.&quot;<p><a href="https:&#x2F;&#x2F;x.com&#x2F;barret_zoph&#x2F;status&#x2F;1839095143397515452" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;barret_zoph&#x2F;status&#x2F;1839095143397515452</a><p>All used the same template.</div><br/></div></div><div id="41651899" class="c"><input type="checkbox" id="c-41651899" checked=""/><div class="controls bullet"><span class="by">carimura</span><span>|</span><a href="#41651997">prev</a><span>|</span><a href="#41653371">next</a><span>|</span><label class="collapse" for="c-41651899">[-]</label><label class="expand" for="c-41651899">[1 more]</label></div><br/><div class="children"><div class="content">Once someone is independently wealthy, personal priorities change. I guarantee she&#x27;ll crop up again as founder CEO&#x2F;CTO where she calls the shots and gets the chance (even if slim) to turn millions into billions.</div><br/></div></div><div id="41653371" class="c"><input type="checkbox" id="c-41653371" checked=""/><div class="controls bullet"><span class="by">JCM9</span><span>|</span><a href="#41651899">prev</a><span>|</span><a href="#41651629">next</a><span>|</span><label class="collapse" for="c-41653371">[-]</label><label class="expand" for="c-41653371">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI is shifting from “we did some really cool stuff” phase into the reality of needing to run a company, getting revenue, etc phase. Not common for folks to want to move on and go find the next cool thing. AGI is not around the corner. Building a company is a very different thing than building cool stuff and OpenAI is now in building a company mode.</div><br/></div></div><div id="41651629" class="c"><input type="checkbox" id="c-41651629" checked=""/><div class="controls bullet"><span class="by">textlapse</span><span>|</span><a href="#41653371">prev</a><span>|</span><a href="#41651796">next</a><span>|</span><label class="collapse" for="c-41651629">[-]</label><label class="expand" for="c-41651629">[1 more]</label></div><br/><div class="children"><div class="content">Maybe OpenAI is trying to enter a new enterprise phase past its startup era?<p>They have hired CTO like figures from ex MSFt and so on … which would mean a natural exit for the startup era folks that we have seen recently?<p>Every company wants to sell itself as some grandiose savior initially ‘organize the world’s information and make it universally accessible’, ‘solve AGI’ but I guess the investors and the top level people in reality are motivated by dollar signs and ads and enterprise and so on.<p>Not that that’s a bad thing but really it’s a Potemkin village though…</div><br/></div></div><div id="41651796" class="c"><input type="checkbox" id="c-41651796" checked=""/><div class="controls bullet"><span class="by">simbas</span><span>|</span><a href="#41651629">prev</a><span>|</span><a href="#41651364">next</a><span>|</span><label class="collapse" for="c-41651796">[-]</label><label class="expand" for="c-41651796">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;x.com&#x2F;miramurati&#x2F;status&#x2F;1726542556203483392" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;miramurati&#x2F;status&#x2F;1726542556203483392</a></div><br/></div></div><div id="41651364" class="c"><input type="checkbox" id="c-41651364" checked=""/><div class="controls bullet"><span class="by">alexmolas</span><span>|</span><a href="#41651796">prev</a><span>|</span><a href="#41651386">next</a><span>|</span><label class="collapse" for="c-41651364">[-]</label><label class="expand" for="c-41651364">[2 more]</label></div><br/><div class="children"><div class="content">They can&#x27;t spend more than 6 months without a drama...</div><br/><div id="41652998" class="c"><input type="checkbox" id="c-41652998" checked=""/><div class="controls bullet"><span class="by">jonny_eh</span><span>|</span><a href="#41651364">parent</a><span>|</span><a href="#41651386">next</a><span>|</span><label class="collapse" for="c-41652998">[-]</label><label class="expand" for="c-41652998">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the same drama, spread out over time.</div><br/></div></div></div></div><div id="41651386" class="c"><input type="checkbox" id="c-41651386" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#41651364">prev</a><span>|</span><a href="#41653810">next</a><span>|</span><label class="collapse" for="c-41651386">[-]</label><label class="expand" for="c-41651386">[1 more]</label></div><br/><div class="children"><div class="content">They will all be replaced by ASIs soon, so it doesn&#x27;t matter who s coming and going</div><br/></div></div><div id="41653810" class="c"><input type="checkbox" id="c-41653810" checked=""/><div class="controls bullet"><span class="by">lsh123</span><span>|</span><a href="#41651386">prev</a><span>|</span><a href="#41653363">next</a><span>|</span><label class="collapse" for="c-41653810">[-]</label><label class="expand" for="c-41653810">[1 more]</label></div><br/><div class="children"><div class="content">Treason doth never prosper, what’s the reason?
For if it prosper, none dare call it Treason.</div><br/></div></div><div id="41653363" class="c"><input type="checkbox" id="c-41653363" checked=""/><div class="controls bullet"><span class="by">JCM9</span><span>|</span><a href="#41653810">prev</a><span>|</span><a href="#41651764">next</a><span>|</span><label class="collapse" for="c-41653363">[-]</label><label class="expand" for="c-41653363">[1 more]</label></div><br/><div class="children"><div class="content">They set out to do some cool stuff. They did. Company is now in the reality of they need to run a business and make revenue&#x2F;profit which is, honestly, a lot less fun than when you were in “let’s change the world and do cool stuff” phase. AGI is much further away than thought. Was a good run and time to do something else and let others now do the “run a company” phase. Seems like nothing more to it than that and seems fair to me.</div><br/></div></div><div id="41651764" class="c"><input type="checkbox" id="c-41651764" checked=""/><div class="controls bullet"><span class="by">isodev</span><span>|</span><a href="#41653363">prev</a><span>|</span><a href="#41651279">next</a><span>|</span><label class="collapse" for="c-41651764">[-]</label><label class="expand" for="c-41651764">[3 more]</label></div><br/><div class="children"><div class="content">Can someone share a non twitter link? For those of us who can’t access it.</div><br/><div id="41651988" class="c"><input type="checkbox" id="c-41651988" checked=""/><div class="controls bullet"><span class="by">hoherd</span><span>|</span><a href="#41651764">parent</a><span>|</span><a href="#41651279">next</a><span>|</span><label class="collapse" for="c-41651988">[-]</label><label class="expand" for="c-41651988">[2 more]</label></div><br/><div class="children"><div class="content">I actually had the same thought because I DNS block xitter.<p>Somebody else archived it before me: <a href="https:&#x2F;&#x2F;archive.li&#x2F;0Mea1" rel="nofollow">https:&#x2F;&#x2F;archive.li&#x2F;0Mea1</a></div><br/><div id="41654629" class="c"><input type="checkbox" id="c-41654629" checked=""/><div class="controls bullet"><span class="by">isodev</span><span>|</span><a href="#41651764">root</a><span>|</span><a href="#41651988">parent</a><span>|</span><a href="#41651279">next</a><span>|</span><label class="collapse" for="c-41654629">[-]</label><label class="expand" for="c-41654629">[1 more]</label></div><br/><div class="children"><div class="content">Thank you!</div><br/></div></div></div></div></div></div><div id="41651279" class="c"><input type="checkbox" id="c-41651279" checked=""/><div class="controls bullet"><span class="by">throwaway314155</span><span>|</span><a href="#41651764">prev</a><span>|</span><label class="collapse" for="c-41651279">[-]</label><label class="expand" for="c-41651279">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve forgotten, did she play a role in the attempted Sam Altman ouster?</div><br/><div id="41651500" class="c"><input type="checkbox" id="c-41651500" checked=""/><div class="controls bullet"><span class="by">paxys</span><span>|</span><a href="#41651279">parent</a><span>|</span><a href="#41653214">next</a><span>|</span><label class="collapse" for="c-41651500">[-]</label><label class="expand" for="c-41651500">[1 more]</label></div><br/><div class="children"><div class="content">She was picked by the board to replace Sam in the interim after his ouster, so we can draw some conclusions from that.</div><br/></div></div><div id="41653214" class="c"><input type="checkbox" id="c-41653214" checked=""/><div class="controls bullet"><span class="by">015a</span><span>|</span><a href="#41651279">parent</a><span>|</span><a href="#41651500">prev</a><span>|</span><a href="#41651307">next</a><span>|</span><label class="collapse" for="c-41653214">[-]</label><label class="expand" for="c-41653214">[1 more]</label></div><br/><div class="children"><div class="content">Well, she accepted the role of interim CEO for a bit, and then flip-flopped to supporting getting Sam back when it became obvious that the employees were fully hypnotized by Sam&#x27;s reality distortion field.</div><br/></div></div><div id="41651320" class="c"><input type="checkbox" id="c-41651320" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#41651279">parent</a><span>|</span><a href="#41651307">prev</a><span>|</span><label class="collapse" for="c-41651320">[-]</label><label class="expand" for="c-41651320">[1 more]</label></div><br/><div class="children"><div class="content">She wasn’t on the board right? So if she did play a role, it wasn’t through a vote I’d guess.</div><br/></div></div></div></div></div></div></div></div></div></body></html>