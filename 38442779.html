<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701162059392" as="style"/><link rel="stylesheet" href="styles.css?v=1701162059392"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2311.01906">Simplifying Transformer Blocks</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>georgehill</span> | <span>12 comments</span></div><br/><div><div id="38443539" class="c"><input type="checkbox" id="c-38443539" checked=""/><div class="controls bullet"><span class="by">low_tech_love</span><span>|</span><a href="#38443677">next</a><span>|</span><label class="collapse" for="c-38443539">[-]</label><label class="expand" for="c-38443539">[4 more]</label></div><br/><div class="children"><div class="content">“This complexity leads to brittle architectures, where seemingly minor changes can significantly reduce training speed, or render models untrainable.”<p>I am by no means an expert and I can’t verify the authors’ claims about reduced speed and untrainability, but this reflects an impression I’ve been having on the papers I read and review. The field of ML research is moving so fast that people don’t even take time anymore to explain the design decisions behind their architectures. It’s basically “we got nice results, and here is the architecture of the model” (proceeds to show a figure with a hundred coloured blocks connected together in some seemingly random complex way).<p>It used to be that such a thing would get backlash from reviewers, and they would require you to actually justify the design. I don’t see that anymore. The problem with this for me is that we fail to build a nice, crisp understanding of the effects of each design decision in the final outcomes, which hurts the actual “science” of it. It also opens up the field for bogus and unreproducible claims.<p>But at least other people are picking up on the thread and doing that in follow-up papers, which is good.</div><br/><div id="38443671" class="c"><input type="checkbox" id="c-38443671" checked=""/><div class="controls bullet"><span class="by">loveparade</span><span>|</span><a href="#38443539">parent</a><span>|</span><a href="#38443583">next</a><span>|</span><label class="collapse" for="c-38443671">[-]</label><label class="expand" for="c-38443671">[1 more]</label></div><br/><div class="children"><div class="content">It has always been like this in DL research. Also, providing justification doesn&#x27;t necessarily help, because they are usually just guesses. The problem goes deeper than this. It&#x27;s easy, and common, to make up justifications after the fact. You can try a bunch of random stuff, some thing randomly works, and then you make up an explanation for why it works that sounds plausible, but in reality is nothing more than a fictional narrative to convince reviewers (and possibly yourself). The underlying problem here are the incentives of the academic system. Reviewers reward good narratives and stories. Also, in DL especially, it&#x27;s quite difficult to perform ablation studies or get statistical significance numbers due experiments taking a long time to run.<p>I hate to say it, because that&#x27;s not how science should work, but with the flood of papers, looking at <i>who</i> wrote a paper is probably one of the more reliable indicators of quality. The reason is that people with a reputation are putting their reputation at stake when publishing something. Publishing BS would reflect badly on them, so they tend to go through more quality control. An unknown researcher at an unknown lab has nothing to lose by flooding arxiv with BS papers, which on the surface are indistinguishable from high quality work.</div><br/></div></div><div id="38443583" class="c"><input type="checkbox" id="c-38443583" checked=""/><div class="controls bullet"><span class="by">sytelus</span><span>|</span><a href="#38443539">parent</a><span>|</span><a href="#38443671">prev</a><span>|</span><a href="#38443724">next</a><span>|</span><label class="collapse" for="c-38443583">[-]</label><label class="expand" for="c-38443583">[1 more]</label></div><br/><div class="children"><div class="content">There are rarely any design &quot;decisions&quot;. Typically, you throw many things at wall and something sticks which becomes paper. Transformer paper has approximately zero &quot;design decisions&quot; apart from attention block. I can imagine they just tried out various combinations, kept adding projections and went with what worked the best.</div><br/></div></div><div id="38443724" class="c"><input type="checkbox" id="c-38443724" checked=""/><div class="controls bullet"><span class="by">lossolo</span><span>|</span><a href="#38443539">parent</a><span>|</span><a href="#38443583">prev</a><span>|</span><a href="#38443677">next</a><span>|</span><label class="collapse" for="c-38443724">[-]</label><label class="expand" for="c-38443724">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The field of ML research is moving so fast that people don’t even take time anymore to explain the design decisions behind their architectures<p>Often, they don&#x27;t fully understand why certain methods work, they simply experiment and observe the outcomes. This sentiment is echoed by one of the authors of the Transformer paper in another publication[1], where he states:<p>&quot;We offer no explanation as to why these architectures seem to work; we attribute their success, as with all else, to divine benevolence.&quot;<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2002.05202.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2002.05202.pdf</a></div><br/></div></div></div></div><div id="38443677" class="c"><input type="checkbox" id="c-38443677" checked=""/><div class="controls bullet"><span class="by">Bayes7</span><span>|</span><a href="#38443539">prev</a><span>|</span><a href="#38443735">next</a><span>|</span><label class="collapse" for="c-38443677">[-]</label><label class="expand" for="c-38443677">[1 more]</label></div><br/><div class="children"><div class="content">&quot;[...] modern neural network (NN) architectures have complex designs with many components [...]&quot;<p>I find the Transformer architecture actually very simple compared to previous models like LSTMs or other recurrent models. You could argue that their vision counterparts like ViT are conceptually maybe even simpler than ConvNets?<p>Also, can someone explain why they are so keen to remove the skip connections? At least when it comes to coding, nothing is simpler than adding a skip connection and computationally the effect should be marginal?</div><br/></div></div><div id="38443735" class="c"><input type="checkbox" id="c-38443735" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#38443677">prev</a><span>|</span><a href="#38443204">next</a><span>|</span><label class="collapse" for="c-38443735">[-]</label><label class="expand" for="c-38443735">[2 more]</label></div><br/><div class="children"><div class="content">This is a nice start, but what would really help is for someone who understands the GPU programming model in-depth to give this a shot, with the goal of reducing DRAM bandwidth and fitting the layers exactly onto a GPU&#x27;s memory hierarchy (cache levels, local memory and registers). Basically, sizes of a target HW platform&#x27;s memories should be hyper-parameters of the architecture.</div><br/><div id="38443801" class="c"><input type="checkbox" id="c-38443801" checked=""/><div class="controls bullet"><span class="by">machinekob</span><span>|</span><a href="#38443735">parent</a><span>|</span><a href="#38443204">next</a><span>|</span><label class="collapse" for="c-38443801">[-]</label><label class="expand" for="c-38443801">[1 more]</label></div><br/><div class="children"><div class="content">Indeed it could be a target, but newer and newer co-processor for pure MatMul or even NPU are created and Cache&#x2F;Register are changing fast from one architecture to another so it still wouldnt be optimal for most users.</div><br/></div></div></div></div><div id="38443204" class="c"><input type="checkbox" id="c-38443204" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#38443735">prev</a><span>|</span><a href="#38443429">next</a><span>|</span><label class="collapse" for="c-38443204">[-]</label><label class="expand" for="c-38443204">[1 more]</label></div><br/><div class="children"><div class="content">&quot;While we have demonstrated the efficacy of our simplifications
across architectures, datasets, and tasks, the models we have considered (100-300M parameters) are small relative to the largest transformers.&quot;<p>University researchers without a big lab&#x27;s backing cannot try out such experiments on really large models.</div><br/></div></div><div id="38443429" class="c"><input type="checkbox" id="c-38443429" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#38443204">prev</a><span>|</span><a href="#38443475">next</a><span>|</span><label class="collapse" for="c-38443429">[-]</label><label class="expand" for="c-38443429">[1 more]</label></div><br/><div class="children"><div class="content">Not sure if I read it correctly, but it seems like the skip connections are kinda still present in the skipless block because they added I after the softmax and v= the previous hidden state. Still a cool paper if they really managed to get rid of those projections without degrading the quality.</div><br/></div></div><div id="38443475" class="c"><input type="checkbox" id="c-38443475" checked=""/><div class="controls bullet"><span class="by">samus</span><span>|</span><a href="#38443429">prev</a><span>|</span><label class="collapse" for="c-38443475">[-]</label><label class="expand" for="c-38443475">[2 more]</label></div><br/><div class="children"><div class="content">I love reading about papers like these. They raise hopes that novel model architectures might reduce the need for computational resources to train powerful models, which would help lower the barrier of entry.</div><br/><div id="38443536" class="c"><input type="checkbox" id="c-38443536" checked=""/><div class="controls bullet"><span class="by">heyitsguay</span><span>|</span><a href="#38443475">parent</a><span>|</span><label class="collapse" for="c-38443536">[-]</label><label class="expand" for="c-38443536">[1 more]</label></div><br/><div class="children"><div class="content">If you read &quot;Attention Is All You Need&quot;, you&#x27;ll see that was actually the motive behind the original Transformer too! Bit of a Jevon&#x27;s paradox situation.</div><br/></div></div></div></div></div></div></div></div></div></body></html>