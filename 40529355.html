<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1717146073707" as="style"/><link rel="stylesheet" href="styles.css?v=1717146073707"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://spectrum.ieee.org/1-bit-llm">“Imprecise” language models are smaller, speedier, and nearly as accurate</a> <span class="domain">(<a href="https://spectrum.ieee.org">spectrum.ieee.org</a>)</span></div><div class="subtext"><span>jnord</span> | <span>50 comments</span></div><br/><div><div id="40531638" class="c"><input type="checkbox" id="c-40531638" checked=""/><div class="controls bullet"><span class="by">mlsu</span><span>|</span><a href="#40532159">next</a><span>|</span><label class="collapse" for="c-40531638">[-]</label><label class="expand" for="c-40531638">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t believe that quantization comes for free. Someone made the observation that llama3 models quantize &quot;worse&quot; than llama2 models do -- they suffer in quality from quantization far more.<p>My intuition is that a model which is undertrained suffers less from quantization, because the training process has not utilized each weight to its full potential. One of the key findings with llama, and why it punches above its weight for its size, is that they trained it for longer on a much larger dataset then was &quot;optimal&quot; according to the literature up to that point.<p>Putting two and two together, it seems that:<p>small model, lots of data, long training &gt; large model + quantization<p>That basically, quantization is a lossy shortcut to the tail of training long. Amount and quality of data is, as always, the most important part about all of this.</div><br/><div id="40531940" class="c"><input type="checkbox" id="c-40531940" checked=""/><div class="controls bullet"><span class="by">kir-gadjello</span><span>|</span><a href="#40531638">parent</a><span>|</span><a href="#40532159">next</a><span>|</span><label class="collapse" for="c-40531940">[-]</label><label class="expand" for="c-40531940">[2 more]</label></div><br/><div class="children"><div class="content">While llama3-8b might be slightly more brittle under quantization, llama3-70b really surprised myself and others[1] in how well it performs even in the 2..3 bits per parameter regime. It requires one of the most advanced quantization methods (IQ2_XS specifically) to work, but the reward is a SoTA LLM that fits on one 4090 GPU with 8K context (KV-cache uncompressed btw) and allows for advanced usecases such as powering the agent engine I&#x27;m working on: <a href="https:&#x2F;&#x2F;github.com&#x2F;kir-gadjello&#x2F;picoagent-rnd">https:&#x2F;&#x2F;github.com&#x2F;kir-gadjello&#x2F;picoagent-rnd</a><p>For me it completely replaced strong models such as Mixtral-8x7B and DeepSeek-Coder-Instruct-33B.<p>1. <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1cst400&#x2F;result_llama_3_mmlu_score_vs_quantization_for&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1cst400&#x2F;result_...</a></div><br/><div id="40532196" class="c"><input type="checkbox" id="c-40532196" checked=""/><div class="controls bullet"><span class="by">d13</span><span>|</span><a href="#40531638">root</a><span>|</span><a href="#40531940">parent</a><span>|</span><a href="#40532159">next</a><span>|</span><label class="collapse" for="c-40532196">[-]</label><label class="expand" for="c-40532196">[1 more]</label></div><br/><div class="children"><div class="content">How does it compare against unequalised Llama 3 8B at 16fp? I’ve been using that locally and it’s almost replaced GPT4 for me. Runs in about 14GB of VRAM.</div><br/></div></div></div></div></div></div><div id="40532159" class="c"><input type="checkbox" id="c-40532159" checked=""/><div class="controls bullet"><span class="by">13alvone</span><span>|</span><a href="#40531638">prev</a><span>|</span><a href="#40530838">next</a><span>|</span><label class="collapse" for="c-40532159">[-]</label><label class="expand" for="c-40532159">[8 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been thinking about how far we&#x27;ve come with large language models (LLMs) and the challenge of making them almost perfect. It feels a lot like trying to get a spaceship to travel at the speed of light.<p>We’ve made impressive progress, getting these models to be quite accurate. But pushing from 90% to 99.9999999% accuracy? That takes an insane amount of data and computing power. It&#x27;s like needing exponentially more energy as you get closer to light speed.<p>And just like we can’t actually reach the speed of light, there might be a practical limit to how accurate LLMs can get. Language is incredibly complex and full of ambiguities. The closer we aim for perfection, the harder it becomes. Each tiny improvement requires significantly more resources, and the gains become marginal.<p>To get LLMs to near-perfect accuracy, we&#x27;d need an infinite amount of data and computing power, which isn&#x27;t feasible. So while LLMs are amazing and have come a long way, getting them to be nearly perfect is probably impossible—like reaching the speed of light.<p>Regardless I hope to appreciate the progress we&#x27;ve made but also be realistic about the challenges ahead. What do you think? Is this a fair analogy?</div><br/><div id="40532802" class="c"><input type="checkbox" id="c-40532802" checked=""/><div class="controls bullet"><span class="by">kreyenborgi</span><span>|</span><a href="#40532159">parent</a><span>|</span><a href="#40532756">next</a><span>|</span><label class="collapse" for="c-40532802">[-]</label><label class="expand" for="c-40532802">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Data&quot; isn&#x27;t an inexhaustible resource, and also isn&#x27;t fungible in the way energy is. Of the thousands of languages in the world, a fair chunk don&#x27;t even have writing systems, and some have very few speakers left. Many are lost forever. Now ask the best llm trained on &quot;all the data&quot; to translate some fragment of some isolate language not in its training set and not very related to existing languages. You can&#x27;t improve on that task by adding more sentences in English or by combining with learning on other modalities.</div><br/></div></div><div id="40532756" class="c"><input type="checkbox" id="c-40532756" checked=""/><div class="controls bullet"><span class="by">wruza</span><span>|</span><a href="#40532159">parent</a><span>|</span><a href="#40532802">prev</a><span>|</span><a href="#40532242">next</a><span>|</span><label class="collapse" for="c-40532756">[-]</label><label class="expand" for="c-40532756">[1 more]</label></div><br/><div class="children"><div class="content">There’s also a rumor that models these days employ a large “safety” parachute behind their engines all the time. Some of these get so big that models become dumber right before your eyes.</div><br/></div></div><div id="40532242" class="c"><input type="checkbox" id="c-40532242" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#40532159">parent</a><span>|</span><a href="#40532756">prev</a><span>|</span><a href="#40532181">next</a><span>|</span><label class="collapse" for="c-40532242">[-]</label><label class="expand" for="c-40532242">[1 more]</label></div><br/><div class="children"><div class="content">But it still might be worth it. A 90% accurate model will only successfully complete a task consisting of 10 subtasks 0.9^10 = 35%of the time, while a 99% will do so 90% of the time making the former useless, but the latter quite useful.</div><br/></div></div><div id="40532181" class="c"><input type="checkbox" id="c-40532181" checked=""/><div class="controls bullet"><span class="by">jjayj</span><span>|</span><a href="#40532159">parent</a><span>|</span><a href="#40532242">prev</a><span>|</span><a href="#40530838">next</a><span>|</span><label class="collapse" for="c-40532181">[-]</label><label class="expand" for="c-40532181">[4 more]</label></div><br/><div class="children"><div class="content">I think I agree with your analogy, but would say 99% rather than 99.99999%.<p>Beyond that, I&#x27;m not entirely sure what a &quot;perfect&quot; LLM would even be defined as.</div><br/><div id="40532190" class="c"><input type="checkbox" id="c-40532190" checked=""/><div class="controls bullet"><span class="by">13alvone</span><span>|</span><a href="#40532159">root</a><span>|</span><a href="#40532181">parent</a><span>|</span><a href="#40530838">next</a><span>|</span><label class="collapse" for="c-40532190">[-]</label><label class="expand" for="c-40532190">[3 more]</label></div><br/><div class="children"><div class="content">That makes sense, and just harder and harder to get more accurate. Same as humans I supposed :)</div><br/><div id="40532239" class="c"><input type="checkbox" id="c-40532239" checked=""/><div class="controls bullet"><span class="by">jjayj</span><span>|</span><a href="#40532159">root</a><span>|</span><a href="#40532190">parent</a><span>|</span><a href="#40530838">next</a><span>|</span><label class="collapse" for="c-40532239">[-]</label><label class="expand" for="c-40532239">[2 more]</label></div><br/><div class="children"><div class="content">Past 99%, what does &quot;more accurate&quot; mean? I think it will vary from person to person and use case to use case, which is why I personally don&#x27;t foresee a world where an LLM or any form of AI&#x2F;ML is ever perfectly accurate.<p>I&#x27;m struggling to think of any medium that has ever reached 100% accuracy, so to target that for an ML algorithm seems foolhardy</div><br/><div id="40532311" class="c"><input type="checkbox" id="c-40532311" checked=""/><div class="controls bullet"><span class="by">13alvone</span><span>|</span><a href="#40532159">root</a><span>|</span><a href="#40532239">parent</a><span>|</span><a href="#40530838">next</a><span>|</span><label class="collapse" for="c-40532311">[-]</label><label class="expand" for="c-40532311">[1 more]</label></div><br/><div class="children"><div class="content">I agree with this. Because it does seem that if it&#x27;s based on NOT 100% accurate information in terms of training, it can never return 100% accurate results. Which I guess, as humans, we don&#x27;t either, but as a committee, one MAY argue we could. I&#x27;m torn lol.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40530838" class="c"><input type="checkbox" id="c-40530838" checked=""/><div class="controls bullet"><span class="by">jandrese</span><span>|</span><a href="#40532159">prev</a><span>|</span><a href="#40531154">next</a><span>|</span><label class="collapse" for="c-40530838">[-]</label><label class="expand" for="c-40530838">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m starting to feel like the Thinking Machines CM-1 was 40 years ahead of its time.</div><br/><div id="40530943" class="c"><input type="checkbox" id="c-40530943" checked=""/><div class="controls bullet"><span class="by">chuckadams</span><span>|</span><a href="#40530838">parent</a><span>|</span><a href="#40531154">next</a><span>|</span><label class="collapse" for="c-40530943">[-]</label><label class="expand" for="c-40530943">[2 more]</label></div><br/><div class="children"><div class="content">It had the most wonderful blinkenlights too! :)</div><br/><div id="40531142" class="c"><input type="checkbox" id="c-40531142" checked=""/><div class="controls bullet"><span class="by">deepfriedchokes</span><span>|</span><a href="#40530838">root</a><span>|</span><a href="#40530943">parent</a><span>|</span><a href="#40531154">next</a><span>|</span><label class="collapse" for="c-40531142">[-]</label><label class="expand" for="c-40531142">[1 more]</label></div><br/><div class="children"><div class="content">One of my favorites, CM-1 t-shirt:<p><a href="https:&#x2F;&#x2F;www.tamikothiel.com&#x2F;cm&#x2F;cm-tshirt.html" rel="nofollow">https:&#x2F;&#x2F;www.tamikothiel.com&#x2F;cm&#x2F;cm-tshirt.html</a></div><br/></div></div></div></div></div></div><div id="40531154" class="c"><input type="checkbox" id="c-40531154" checked=""/><div class="controls bullet"><span class="by">brcmthrowaway</span><span>|</span><a href="#40530838">prev</a><span>|</span><a href="#40531577">next</a><span>|</span><label class="collapse" for="c-40531154">[-]</label><label class="expand" for="c-40531154">[3 more]</label></div><br/><div class="children"><div class="content">Are there any 1-bit LLMs available on GitHub?</div><br/><div id="40531399" class="c"><input type="checkbox" id="c-40531399" checked=""/><div class="controls bullet"><span class="by">lhl</span><span>|</span><a href="#40531154">parent</a><span>|</span><a href="#40531292">next</a><span>|</span><label class="collapse" for="c-40531399">[-]</label><label class="expand" for="c-40531399">[1 more]</label></div><br/><div class="children"><div class="content">BitNet Implementations:<p>* <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;1bitLLM&#x2F;bitnet_b1_58-large" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;1bitLLM&#x2F;bitnet_b1_58-large</a><p>* <a href="https:&#x2F;&#x2F;github.com&#x2F;Oxen-AI&#x2F;BitNet-1.58-Instruct">https:&#x2F;&#x2F;github.com&#x2F;Oxen-AI&#x2F;BitNet-1.58-Instruct</a><p>* <a href="https:&#x2F;&#x2F;github.com&#x2F;nkotak&#x2F;1.58BitNet">https:&#x2F;&#x2F;github.com&#x2F;nkotak&#x2F;1.58BitNet</a><p>See some followups that has some training advice: <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;unilm&#x2F;tree&#x2F;master&#x2F;bitnet">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;unilm&#x2F;tree&#x2F;master&#x2F;bitnet</a></div><br/></div></div><div id="40531292" class="c"><input type="checkbox" id="c-40531292" checked=""/><div class="controls bullet"><span class="by">hughesjj</span><span>|</span><a href="#40531154">parent</a><span>|</span><a href="#40531399">prev</a><span>|</span><a href="#40531577">next</a><span>|</span><label class="collapse" for="c-40531292">[-]</label><label class="expand" for="c-40531292">[1 more]</label></div><br/><div class="children"><div class="content">Heck they have some zero bit llm&#x27;s<p><a href="https:&#x2F;&#x2F;github.com&#x2F;kelseyhightower&#x2F;nocode">https:&#x2F;&#x2F;github.com&#x2F;kelseyhightower&#x2F;nocode</a></div><br/></div></div></div></div><div id="40531577" class="c"><input type="checkbox" id="c-40531577" checked=""/><div class="controls bullet"><span class="by">WiSaGaN</span><span>|</span><a href="#40531154">prev</a><span>|</span><a href="#40530984">next</a><span>|</span><label class="collapse" for="c-40531577">[-]</label><label class="expand" for="c-40531577">[3 more]</label></div><br/><div class="children"><div class="content">This seems saying that the 1bit model is a bit better than GPTQ Q2. However, I find there are few situations where you would want to use GPTQ Q2 in the first places. You would want to run the F16 version if you want quality, and if you want to have a sweet spot, you usually find something like Q5_K_M of the biggest model you can run.</div><br/><div id="40531914" class="c"><input type="checkbox" id="c-40531914" checked=""/><div class="controls bullet"><span class="by">qeternity</span><span>|</span><a href="#40531577">parent</a><span>|</span><a href="#40530984">next</a><span>|</span><label class="collapse" for="c-40531914">[-]</label><label class="expand" for="c-40531914">[2 more]</label></div><br/><div class="children"><div class="content">Nobody is running llama.cpp in production…</div><br/><div id="40532119" class="c"><input type="checkbox" id="c-40532119" checked=""/><div class="controls bullet"><span class="by">luke-stanley</span><span>|</span><a href="#40531577">root</a><span>|</span><a href="#40531914">parent</a><span>|</span><a href="#40530984">next</a><span>|</span><label class="collapse" for="c-40532119">[-]</label><label class="expand" for="c-40532119">[1 more]</label></div><br/><div class="children"><div class="content">What do you mean? What makes you think that?</div><br/></div></div></div></div></div></div><div id="40530984" class="c"><input type="checkbox" id="c-40530984" checked=""/><div class="controls bullet"><span class="by">aussieguy1234</span><span>|</span><a href="#40531577">prev</a><span>|</span><a href="#40531107">next</a><span>|</span><label class="collapse" for="c-40530984">[-]</label><label class="expand" for="c-40530984">[5 more]</label></div><br/><div class="children"><div class="content">When it needs to do more precise numerical calculations, perhaps, like a human, it could just use a calculator?</div><br/><div id="40531045" class="c"><input type="checkbox" id="c-40531045" checked=""/><div class="controls bullet"><span class="by">kromem</span><span>|</span><a href="#40530984">parent</a><span>|</span><a href="#40531107">next</a><span>|</span><label class="collapse" for="c-40531045">[-]</label><label class="expand" for="c-40531045">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not really a concern.<p>If you have a trillion parameter 8-bit fp network or a trillion parameter 1.5-bit ternary network, based on the scaling in Microsoft&#x27;s paper the latter will actually perform better.<p>A lot of the current thinking is that the nodes themselves act as superpositions for a virtualized network in a multidimensional vector space, so precision is fairly arbitrary for the base nodes and it may be that constraining the individual node values actually allows for a less fuzzy virtualized network by the end of the training.<p>You could still have a very precise &#x27;calculator&#x27; feature in the virtual space no matter the underlying parameter precision, and because each parameter is being informed by overlapping virtual features, may even have less unexpected errors and issues with lower precision nodes.</div><br/><div id="40531545" class="c"><input type="checkbox" id="c-40531545" checked=""/><div class="controls bullet"><span class="by">xwolfi</span><span>|</span><a href="#40530984">root</a><span>|</span><a href="#40531045">parent</a><span>|</span><a href="#40531107">next</a><span>|</span><label class="collapse" for="c-40531545">[-]</label><label class="expand" for="c-40531545">[3 more]</label></div><br/><div class="children"><div class="content">Yup, your response makes me think they should just use a calculator, like everyone.</div><br/><div id="40532086" class="c"><input type="checkbox" id="c-40532086" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#40530984">root</a><span>|</span><a href="#40531545">parent</a><span>|</span><a href="#40531107">next</a><span>|</span><label class="collapse" for="c-40532086">[-]</label><label class="expand" for="c-40532086">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know what you mean. They already use the GPU as a calculator.</div><br/><div id="40532487" class="c"><input type="checkbox" id="c-40532487" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#40530984">root</a><span>|</span><a href="#40532086">parent</a><span>|</span><a href="#40531107">next</a><span>|</span><label class="collapse" for="c-40532487">[-]</label><label class="expand" for="c-40532487">[1 more]</label></div><br/><div class="children"><div class="content">I believe you four are talking about different things; the models are executed on very good &quot;calculators&quot; (if you want to call the GPUs that), but themselves are not very good at being used <i>as</i> calculators.<p>LLMs are sufficiently good hammers that people see everything as a nail, then talk about how bad they are at driving screws.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40531107" class="c"><input type="checkbox" id="c-40531107" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#40530984">prev</a><span>|</span><a href="#40531333">next</a><span>|</span><label class="collapse" for="c-40531107">[-]</label><label class="expand" for="c-40531107">[2 more]</label></div><br/><div class="children"><div class="content">Easier just to deploy more renewable energy</div><br/><div id="40531119" class="c"><input type="checkbox" id="c-40531119" checked=""/><div class="controls bullet"><span class="by">adtac</span><span>|</span><a href="#40531107">parent</a><span>|</span><a href="#40531333">next</a><span>|</span><label class="collapse" for="c-40531119">[-]</label><label class="expand" for="c-40531119">[1 more]</label></div><br/><div class="children"><div class="content">Like often, both will probably happen</div><br/></div></div></div></div><div id="40531333" class="c"><input type="checkbox" id="c-40531333" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#40531107">prev</a><span>|</span><a href="#40531534">next</a><span>|</span><label class="collapse" for="c-40531333">[-]</label><label class="expand" for="c-40531333">[10 more]</label></div><br/><div class="children"><div class="content">Quantization is never free, and you can rest assured that even the &quot;good&quot; quants of the best models are highly crippled compared to their unquantized versions.<p>The &quot;nearly as accurate&quot; is only on their contrived benchmarks. I&#x27;ve never met a quantized model that actually behaved &quot;98%&quot; as good as the unquantized model, and I do LLM work daily and have since well before the ChatGPT era.</div><br/><div id="40531378" class="c"><input type="checkbox" id="c-40531378" checked=""/><div class="controls bullet"><span class="by">rockskon</span><span>|</span><a href="#40531333">parent</a><span>|</span><a href="#40531534">next</a><span>|</span><label class="collapse" for="c-40531378">[-]</label><label class="expand" for="c-40531378">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never met an LLM that consistently behaved well at all. Quantized or unquantized.<p>Honestly it feels like the bulk of the industry is acting out one big LARP where they&#x27;re always right around the corner from developing AGI and doing something big and amazing and....it just never materializes. Obnoxious AI agents, worthless AI-generated websites crowding out useful resources, unreliable AI search results.<p>The AI industry has done very well for itself selling hype.  Now it needs actual good products.</div><br/><div id="40531430" class="c"><input type="checkbox" id="c-40531430" checked=""/><div class="controls bullet"><span class="by">hn_throwaway_99</span><span>|</span><a href="#40531333">root</a><span>|</span><a href="#40531378">parent</a><span>|</span><a href="#40531688">next</a><span>|</span><label class="collapse" for="c-40531430">[-]</label><label class="expand" for="c-40531430">[5 more]</label></div><br/><div class="children"><div class="content">This makes 0 sense to me. I get <i>tons</i> of real world value and productivity benefits from AI, most specifically ChatGPT and cursor.sh.<p>I don&#x27;t disagree that there is a ton of hype, a lot of it unwarranted, and I cringe when I see tons of companies trying to &quot;throw AI against the wall and see if it sticks&quot; (I personally nominate LinkedIn&#x27;s AI blurbs on their feed as &quot;most useless and annoying use of AI&quot;). But still, I&#x27;m blown away with how much value I get from AI. It makes me a bit sad that so many of us have become so jaded that they see it as &quot;one big LARP&quot;.</div><br/><div id="40532425" class="c"><input type="checkbox" id="c-40532425" checked=""/><div class="controls bullet"><span class="by">rockskon</span><span>|</span><a href="#40531333">root</a><span>|</span><a href="#40531430">parent</a><span>|</span><a href="#40532093">next</a><span>|</span><label class="collapse" for="c-40532425">[-]</label><label class="expand" for="c-40532425">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the thing -<p>I can&#x27;t trust ChatGPT.<p>If I am searching for something I don&#x27;t know the answer to and don&#x27;t have the luxury of trial-and-error for the information I&#x27;m given, I can&#x27;t rely on an unreliable agent like ChatGPT (or literally any LLM for that matter).<p>ChatGPT could be giving me a correct answer.  Or it could be blowing smoke up my ass.<p>I don&#x27;t know which it is when I&#x27;m seeing an answer from ChatGPT!<p>And that&#x27;s the problem.</div><br/><div id="40532698" class="c"><input type="checkbox" id="c-40532698" checked=""/><div class="controls bullet"><span class="by">tasuki</span><span>|</span><a href="#40531333">root</a><span>|</span><a href="#40532425">parent</a><span>|</span><a href="#40532093">next</a><span>|</span><label class="collapse" for="c-40532698">[-]</label><label class="expand" for="c-40532698">[2 more]</label></div><br/><div class="children"><div class="content">Ask questions where you can verify whether the answer is correct. Then it becomes a very useful tool.</div><br/><div id="40532762" class="c"><input type="checkbox" id="c-40532762" checked=""/><div class="controls bullet"><span class="by">rockskon</span><span>|</span><a href="#40531333">root</a><span>|</span><a href="#40532698">parent</a><span>|</span><a href="#40532093">next</a><span>|</span><label class="collapse" for="c-40532762">[-]</label><label class="expand" for="c-40532762">[1 more]</label></div><br/><div class="children"><div class="content">Only if the trial-and-error process has no meaningful consequences for failure.</div><br/></div></div></div></div></div></div><div id="40532093" class="c"><input type="checkbox" id="c-40532093" checked=""/><div class="controls bullet"><span class="by">Capricorn2481</span><span>|</span><a href="#40531333">root</a><span>|</span><a href="#40531430">parent</a><span>|</span><a href="#40532425">prev</a><span>|</span><a href="#40531688">next</a><span>|</span><label class="collapse" for="c-40532093">[-]</label><label class="expand" for="c-40532093">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s dismissive to call it jaded. I don&#x27;t think you, me, or the people you&#x27;re talking about are intellectually different. We just don&#x27;t like what AI makes even if we think it&#x27;s impressive.</div><br/></div></div></div></div><div id="40531688" class="c"><input type="checkbox" id="c-40531688" checked=""/><div class="controls bullet"><span class="by">throw46365</span><span>|</span><a href="#40531333">root</a><span>|</span><a href="#40531378">parent</a><span>|</span><a href="#40531430">prev</a><span>|</span><a href="#40532209">next</a><span>|</span><label class="collapse" for="c-40531688">[-]</label><label class="expand" for="c-40531688">[1 more]</label></div><br/><div class="children"><div class="content">I had that feeling the other day, reading quotes from that OpenAI executive:<p><a href="https:&#x2F;&#x2F;archive.is&#x2F;LpDuJ" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;LpDuJ</a><p><i>She said the executives told the board they &quot;didn&#x27;t think he was the right person to lead the company to AGI…”</i><p>The way I read it, it sort of sounded like you could substitute “AGI” with “Shangri-La”.<p>It’s always going to be just down the road, but <i>they</i> are sort of emotionally convinced that is where they are headed.</div><br/></div></div><div id="40532209" class="c"><input type="checkbox" id="c-40532209" checked=""/><div class="controls bullet"><span class="by">umanwizard</span><span>|</span><a href="#40531333">root</a><span>|</span><a href="#40531378">parent</a><span>|</span><a href="#40531688">prev</a><span>|</span><a href="#40531668">next</a><span>|</span><label class="collapse" for="c-40532209">[-]</label><label class="expand" for="c-40532209">[1 more]</label></div><br/><div class="children"><div class="content">I’m blown away when people say stuff like this. GPT-4 makes me substantially more productive almost every day. It’s like we live in a different reality.</div><br/></div></div><div id="40531668" class="c"><input type="checkbox" id="c-40531668" checked=""/><div class="controls bullet"><span class="by">devbent</span><span>|</span><a href="#40531333">root</a><span>|</span><a href="#40531378">parent</a><span>|</span><a href="#40532209">prev</a><span>|</span><a href="#40531534">next</a><span>|</span><label class="collapse" for="c-40531668">[-]</label><label class="expand" for="c-40531668">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Now it needs actual good products.<p>I asked chatgpt for recommended food pairings for a soup I made today. It did a great job.<p>Chatgpt also helped me debug a home automation issue I&#x27;d been having for over a year with some smart lights.<p>I find uses for chatgpt every day.</div><br/></div></div></div></div></div></div><div id="40531534" class="c"><input type="checkbox" id="c-40531534" checked=""/><div class="controls bullet"><span class="by">light_hue_1</span><span>|</span><a href="#40531333">prev</a><span>|</span><a href="#40531692">next</a><span>|</span><label class="collapse" for="c-40531534">[-]</label><label class="expand" for="c-40531534">[2 more]</label></div><br/><div class="children"><div class="content">The performance loss from BiLLM is disastrous. It&#x27;s basically useless. No one would ever want to use the resulting models. They hide their main results in the appendix: Table 8. page 15. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.04291" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.04291</a><p>I won&#x27;t go over the entire table in detail, but PIQA, BoolQ, HellaSwag, and WinoGrande should in the mid-to-high 70s for LLaMa2-7B. They drop that to 58, 62, 32, and 51. There are 700M parameter models that perform much better.<p>What they should have reported is effective number of parameters. Does LLaMa2-7B with their quantization method outperform a model that has amount of computation but uses that compute with say.. 16-bit quantization? If the answer is no, and it seems like it very clearly is, then the method is wholly worthless. Just use a smaller model to begin with.<p>The BitNet paper is better. But for some reason they only consider very small models. It&#x27;s the obvious question and in their FAQ they don&#x27;t provide a solid answer to it. Despite having all of the compute resources of MS. They could have easily run this experiment in the past year; I&#x27;m suspicious.</div><br/><div id="40532131" class="c"><input type="checkbox" id="c-40532131" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#40531534">parent</a><span>|</span><a href="#40531692">next</a><span>|</span><label class="collapse" for="c-40532131">[-]</label><label class="expand" for="c-40532131">[1 more]</label></div><br/><div class="children"><div class="content">BiLLM is about post training quantization and BitNet trains models from scratch. You do realize that one of those is going to give significantly worse results and the other is going to be significantly more expensive, well into the millions of dollars?</div><br/></div></div></div></div><div id="40531692" class="c"><input type="checkbox" id="c-40531692" checked=""/><div class="controls bullet"><span class="by">roschdal</span><span>|</span><a href="#40531534">prev</a><span>|</span><a href="#40530837">next</a><span>|</span><label class="collapse" for="c-40531692">[-]</label><label class="expand" for="c-40531692">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Nearly accurate&quot; as in &quot;incorrect&quot;</div><br/><div id="40531816" class="c"><input type="checkbox" id="c-40531816" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#40531692">parent</a><span>|</span><a href="#40530837">next</a><span>|</span><label class="collapse" for="c-40531816">[-]</label><label class="expand" for="c-40531816">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t worry, the LLMs were only &quot;fairly accurate&quot; (as in &quot;incorrect&quot;) to begin with.</div><br/></div></div></div></div><div id="40530837" class="c"><input type="checkbox" id="c-40530837" checked=""/><div class="controls bullet"><span class="by">hiddencost</span><span>|</span><a href="#40531692">prev</a><span>|</span><label class="collapse" for="c-40530837">[-]</label><label class="expand" for="c-40530837">[8 more]</label></div><br/><div class="children"><div class="content">Nope nope nope.<p>Any time we find more efficiency, we can trade it for more quality by doing more compute. We&#x27;ll always use as much compute as we can afford, until we stop getting quality gains that are worth the added cost.</div><br/><div id="40531237" class="c"><input type="checkbox" id="c-40531237" checked=""/><div class="controls bullet"><span class="by">kazinator</span><span>|</span><a href="#40530837">parent</a><span>|</span><a href="#40531129">next</a><span>|</span><label class="collapse" for="c-40531237">[-]</label><label class="expand" for="c-40531237">[1 more]</label></div><br/><div class="children"><div class="content">Cost is basically time here. &quot;How much compute we can afford&quot; is really &quot;how long we are willing to wait for the result&quot;.</div><br/></div></div><div id="40531129" class="c"><input type="checkbox" id="c-40531129" checked=""/><div class="controls bullet"><span class="by">shikon7</span><span>|</span><a href="#40530837">parent</a><span>|</span><a href="#40531237">prev</a><span>|</span><a href="#40530911">next</a><span>|</span><label class="collapse" for="c-40531129">[-]</label><label class="expand" for="c-40531129">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it seems the more efficient use we have for compute, the more valuable compute is to us, and the more compute we will be able to afford.</div><br/></div></div><div id="40530911" class="c"><input type="checkbox" id="c-40530911" checked=""/><div class="controls bullet"><span class="by">XorNot</span><span>|</span><a href="#40530837">parent</a><span>|</span><a href="#40531129">prev</a><span>|</span><label class="collapse" for="c-40530911">[-]</label><label class="expand" for="c-40530911">[5 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this article just about an optimization though, sans the title?<p>I don&#x27;t much care for all the &quot;oh but the energy usage&quot; claims in most tech things: it&#x27;s all electricity, and it&#x27;s all fungible. It usually seems to roll out as a proxy for &quot;I don&#x27;t like this thing&quot;.<p>Like even with cryptocurrency, there were a lot of people mistaking the issue of scalability - namely that &quot;as a store of value&quot; crypto would consume incredible amounts of other resources (and a lot of people got stuck trying to figure out how somehow &quot;a hash&quot; could be reclaimed for useful resources) to do less then alternatives, with &quot;the energy usage itself is the problem&quot;.<p>Finding optimizations for LLMs is good because it means we can build cheaper LLMs, which means we can build larger LLMs then we otherwise could for some given constraint, which means we can miniaturize (or in this case specialize) more capable hardware. The thing which really matter is, can the energy usage be meaningfully limited to a sensible scaling factor given the capability that makes them useful?<p>Because environmentally, I can install solar panels to do zero-carbon training (and if LLMs are as valuable as they&#x27;re currently being priced, this is a no-brainer - if people aren&#x27;t lying about solar being &quot;cheaper then fossil fuels&quot;).</div><br/><div id="40531082" class="c"><input type="checkbox" id="c-40531082" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#40530837">root</a><span>|</span><a href="#40530911">parent</a><span>|</span><a href="#40530934">next</a><span>|</span><label class="collapse" for="c-40531082">[-]</label><label class="expand" for="c-40531082">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Like even with cryptocurrency, there were a lot of people mistaking the issue of scalability - namely that &quot;as a store of value&quot; crypto would consume incredible amounts of other resources (and a lot of people got stuck trying to figure out how somehow &quot;a hash&quot; could be reclaimed for useful resources) to do less then alternatives, with &quot;the energy usage itself is the problem&quot;.<p>To be fair, technology-wise they mostly solved this problem via proof-of-stake.<p>From an individual point of view you still expense enormous resources as a miner &#x2F; validator in a proof-of-stake system.  It&#x27;s just that now the resources come in the form of lost opportunity costs for your staked tokens (eg staked Ethereum).<p>But from aggregated perspective of society, staked Ethereum is essentially free.<p>That has some parallels to how acquiring regular money, like USD, is something individuals spend a lot of effort on.  But for the whole of society, printing USD is essentially free.<p>&gt; Because environmentally, I can install solar panels to do zero-carbon training (and if LLMs are as valuable as they&#x27;re currently being priced, this is a no-brainer - if people aren&#x27;t lying about solar being &quot;cheaper then fossil fuels&quot;).<p>There&#x27;s still opportunity costs for that energy.  Unless you have truly stranded electricity that couldn&#x27;t be used for anything else.<p>&gt; Finding optimizations for LLMs is good because it means we can build cheaper LLMs, which means we can build larger LLMs then we otherwise could for some given constraint, which means we can miniaturize (or in this case specialize) more capable hardware. The thing which really matter is, can the energy usage be meaningfully limited to a sensible scaling factor given the capability that makes them useful?<p>I agree with that paragraph.  It&#x27;s all about trade-offs.  If we can shift the efficiency frontier, that&#x27;s good.  Then people can decide whether they want cheaper models at the same performance, or pay the same energy-price for better models, or a combination thereof.  Or pay more energy for even better model</div><br/></div></div><div id="40530934" class="c"><input type="checkbox" id="c-40530934" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#40530837">root</a><span>|</span><a href="#40530911">parent</a><span>|</span><a href="#40531082">prev</a><span>|</span><a href="#40531068">next</a><span>|</span><label class="collapse" for="c-40530934">[-]</label><label class="expand" for="c-40530934">[2 more]</label></div><br/><div class="children"><div class="content">It’s good that we can build cheaper LLMs, but the problem companies guzzling energy for LLM training won’t use less energy, they’ll just have better models</div><br/><div id="40531540" class="c"><input type="checkbox" id="c-40531540" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#40530837">root</a><span>|</span><a href="#40530934">parent</a><span>|</span><a href="#40531068">next</a><span>|</span><label class="collapse" for="c-40531540">[-]</label><label class="expand" for="c-40531540">[1 more]</label></div><br/><div class="children"><div class="content">That energy is still on the order of a household’s yearly electricity, not that of Argentina as cryptos were, and that’s just for training.<p>Inferring is much cheaper and arguably provides quite a lot of value (even though I also think it is overhyped), for very little energy consumption, probably more is lost due to inefficiency for any physical product.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>