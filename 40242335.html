<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1714726863964" as="style"/><link rel="stylesheet" href="styles.css?v=1714726863964"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.mattcutts.com/blog/google-synonyms/">Google&#x27;s Synonym Extraction Methods (2010)</a> <span class="domain">(<a href="https://www.mattcutts.com">www.mattcutts.com</a>)</span></div><div class="subtext"><span>bms2297</span> | <span>30 comments</span></div><br/><div><div id="40242336" class="c"><input type="checkbox" id="c-40242336" checked=""/><div class="controls bullet"><span class="by">bms2297</span><span>|</span><a href="#40242519">next</a><span>|</span><label class="collapse" for="c-40242336">[-]</label><label class="expand" for="c-40242336">[19 more]</label></div><br/><div class="children"><div class="content">One of the most important components of Pre-2010 Google&#x27;s search system was its synonym discovery mechanism. Simply put, queries would be &quot;expanded&quot; with synonyms. Google automatically generated synonym choices that took into account the context of surrounding words, with the understanding that synonyms are highly context dependent. Steven Baker, John Lamping, and a couple of others were key engineers of the system.<p>Does anyone with a NLP background care to take some guesses on how the synonym extraction methodology worked? My only piece of information is that it likely used the query log itself to do so.</div><br/><div id="40242904" class="c"><input type="checkbox" id="c-40242904" checked=""/><div class="controls bullet"><span class="by">evmar</span><span>|</span><a href="#40242336">parent</a><span>|</span><a href="#40242676">next</a><span>|</span><label class="collapse" for="c-40242904">[-]</label><label class="expand" for="c-40242904">[8 more]</label></div><br/><div class="children"><div class="content">I was on the team too, with less impact than the names you mentioned.  The team filed a number of patents that describe parts of how it worked.  You can query a patent search engine with terms like [baker synonyms].  Looking now I think Steve was on most of the patents and you can also gather adjacent coauthor names from there.<p>[I am not a fan of patents, but to the extent they have any positives they in principle serve to share knowledge about how inventions work.  Also I am not a lawyer but I think patents last 20 years from filing date and these were filed ~20 years ago maybe?]</div><br/><div id="40242993" class="c"><input type="checkbox" id="c-40242993" checked=""/><div class="controls bullet"><span class="by">robrenaud</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40242904">parent</a><span>|</span><a href="#40244768">next</a><span>|</span><label class="collapse" for="c-40242993">[-]</label><label class="expand" for="c-40242993">[6 more]</label></div><br/><div class="children"><div class="content">I got a couple patents while at Google. I sent a nice readable 4 page design doc that I wrote to a patent lawyer, and I got back 40 pages of nonsense that I basically didn&#x27;t understand.<p>I wish there was some kind of readability requirement for patents , if they are to continue to exist.</div><br/><div id="40243266" class="c"><input type="checkbox" id="c-40243266" checked=""/><div class="controls bullet"><span class="by">bruckie</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40242993">parent</a><span>|</span><a href="#40243672">next</a><span>|</span><label class="collapse" for="c-40243266">[-]</label><label class="expand" for="c-40243266">[4 more]</label></div><br/><div class="children"><div class="content">Ha, I had the exact same experience. The lawyers sent me what they wrote for me to verify that they didn&#x27;t mess anything up, and it almost seemed like they had based the patent on an entirely different document than the one I wrote up for the invention disclosure—not because they actually messed it up, but because patentese is almost as far from regular English as any foreign language.</div><br/><div id="40243304" class="c"><input type="checkbox" id="c-40243304" checked=""/><div class="controls bullet"><span class="by">neodypsis</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40243266">parent</a><span>|</span><a href="#40243672">next</a><span>|</span><label class="collapse" for="c-40243304">[-]</label><label class="expand" for="c-40243304">[3 more]</label></div><br/><div class="children"><div class="content">Someone should finetune an LLM to create a &quot;patentese&quot; assistant writer.</div><br/><div id="40243464" class="c"><input type="checkbox" id="c-40243464" checked=""/><div class="controls bullet"><span class="by">gregw134</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40243304">parent</a><span>|</span><a href="#40243672">next</a><span>|</span><label class="collapse" for="c-40243464">[-]</label><label class="expand" for="c-40243464">[2 more]</label></div><br/><div class="children"><div class="content">Please no</div><br/><div id="40243667" class="c"><input type="checkbox" id="c-40243667" checked=""/><div class="controls bullet"><span class="by">ajb</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40243464">parent</a><span>|</span><a href="#40243672">next</a><span>|</span><label class="collapse" for="c-40243667">[-]</label><label class="expand" for="c-40243667">[1 more]</label></div><br/><div class="children"><div class="content">The reverse would be good though</div><br/></div></div></div></div></div></div></div></div><div id="40243672" class="c"><input type="checkbox" id="c-40243672" checked=""/><div class="controls bullet"><span class="by">ajb</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40242993">parent</a><span>|</span><a href="#40243266">prev</a><span>|</span><a href="#40244768">next</a><span>|</span><label class="collapse" for="c-40243672">[-]</label><label class="expand" for="c-40243672">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, factor of 10 expansion was my experience as well.</div><br/></div></div></div></div><div id="40244768" class="c"><input type="checkbox" id="c-40244768" checked=""/><div class="controls bullet"><span class="by">bms2297</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40242904">parent</a><span>|</span><a href="#40242993">prev</a><span>|</span><a href="#40242676">next</a><span>|</span><label class="collapse" for="c-40244768">[-]</label><label class="expand" for="c-40244768">[1 more]</label></div><br/><div class="children"><div class="content">Very cool that you worked on it! I&#x27;ve found most, I think, of the patents. They are.... as has been hinted at in this thread, very difficult to parse through and (imo) don&#x27;t actually reveal much, though I may just lack the expertise! That&#x27;s why I was hoping to get some NLP folks to speculate!<p>Your point on dates is something I did want to call out - I wouldn&#x27;t be asking this if it wasn&#x27;t ancient history. I have no interest in doing anything sinister. Just trying to explore a fun part of Internet history. Any shot I could shoot you an email to chat?</div><br/></div></div></div></div><div id="40242676" class="c"><input type="checkbox" id="c-40242676" checked=""/><div class="controls bullet"><span class="by">jjtheblunt</span><span>|</span><a href="#40242336">parent</a><span>|</span><a href="#40242904">prev</a><span>|</span><a href="#40243402">next</a><span>|</span><label class="collapse" for="c-40242676">[-]</label><label class="expand" for="c-40242676">[3 more]</label></div><br/><div class="children"><div class="content">Around 2001 i was using Wordnet to do the same in Motorola Labs days.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;WordNet" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;WordNet</a></div><br/><div id="40242801" class="c"><input type="checkbox" id="c-40242801" checked=""/><div class="controls bullet"><span class="by">mcculley</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40242676">parent</a><span>|</span><a href="#40243402">next</a><span>|</span><label class="collapse" for="c-40242801">[-]</label><label class="expand" for="c-40242801">[2 more]</label></div><br/><div class="children"><div class="content">Wordnet is insufficient for disambiguation, right? That’s why you need the query log.</div><br/><div id="40243174" class="c"><input type="checkbox" id="c-40243174" checked=""/><div class="controls bullet"><span class="by">jjtheblunt</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40242801">parent</a><span>|</span><a href="#40243402">next</a><span>|</span><label class="collapse" for="c-40243174">[-]</label><label class="expand" for="c-40243174">[1 more]</label></div><br/><div class="children"><div class="content">That would be great.</div><br/></div></div></div></div></div></div><div id="40243402" class="c"><input type="checkbox" id="c-40243402" checked=""/><div class="controls bullet"><span class="by">cdavid</span><span>|</span><a href="#40242336">parent</a><span>|</span><a href="#40242676">prev</a><span>|</span><a href="#40244051">next</a><span>|</span><label class="collapse" for="c-40243402">[-]</label><label class="expand" for="c-40243402">[2 more]</label></div><br/><div class="children"><div class="content">If you have access to the query log, aka &quot;who makes which query in what context&quot;), you can use see which queries are &quot;close&quot; to others in context.<p>For example, with session, you can detect manual query rewriting, and use this as a signal to see which queries are close to others in the time context. You can do various fancy things from just that.<p>Nowadays, a simple way to start would be to use SOTA LLMs to generate synonyms offline, and use this for query expansion at query time. At least in a context where queries are small, that should give decent results. This has however diminishing returns because of cost (the more synonyms the more expensive querying the index), and also you lose precision with diminishing returns on increased recall.<p>Ofc, for complex search like google, I am sure it is much more complicated</div><br/><div id="40244798" class="c"><input type="checkbox" id="c-40244798" checked=""/><div class="controls bullet"><span class="by">bms2297</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40243402">parent</a><span>|</span><a href="#40244051">next</a><span>|</span><label class="collapse" for="c-40244798">[-]</label><label class="expand" for="c-40244798">[1 more]</label></div><br/><div class="children"><div class="content">Re: LLMs, I was trying to better understand how pre-LLM search worked, hence the interest in the topic.<p>Any chance you have any open source links that discuss how you practically operate a system based on the concept you describe (manual query rewrite w&#x2F;i a session as your data set)? Perhaps it&#x27;s obvious to an NLP person how to reduce that &quot;idea&quot; to practice, but it is not to me!<p>You&#x27;re definitely right about the idea though - a former Search engineer obliquely mentioned that this sort of session based manual query rewriting was very core to how the synonym system worked.</div><br/></div></div></div></div><div id="40244051" class="c"><input type="checkbox" id="c-40244051" checked=""/><div class="controls bullet"><span class="by">bpiche</span><span>|</span><a href="#40242336">parent</a><span>|</span><a href="#40243402">prev</a><span>|</span><a href="#40242843">next</a><span>|</span><label class="collapse" for="c-40244051">[-]</label><label class="expand" for="c-40244051">[2 more]</label></div><br/><div class="children"><div class="content">Maybe pointwise mutual information (pmi)</div><br/><div id="40244838" class="c"><input type="checkbox" id="c-40244838" checked=""/><div class="controls bullet"><span class="by">bms2297</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40244051">parent</a><span>|</span><a href="#40242843">next</a><span>|</span><label class="collapse" for="c-40244838">[-]</label><label class="expand" for="c-40244838">[1 more]</label></div><br/><div class="children"><div class="content">Say more!? :)</div><br/></div></div></div></div><div id="40242843" class="c"><input type="checkbox" id="c-40242843" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#40242336">parent</a><span>|</span><a href="#40244051">prev</a><span>|</span><a href="#40242519">next</a><span>|</span><label class="collapse" for="c-40242843">[-]</label><label class="expand" for="c-40242843">[3 more]</label></div><br/><div class="children"><div class="content">Also under-rated feature of 2010-era search was Matt Cutts, author of the article.  He was an outlier at Google in that he did real community engagement as well as anti-spam, which is a huge contrast to today’s Google and how the internet has reacted to present-day SEO.<p>While the Matt Cuts era search tech is interesting, it’s crucial to keep in mind that the <i>dataset</i> was very different then too as a result of Matt Cutts’ own attitude towards spam and SEO.<p>Back in 2010 LDA was big and Google had used probabilistic networks e.g. Rephil &#x2F; large noisy-OR networks as models<p><a href="https:&#x2F;&#x2F;uh.edu&#x2F;nsm&#x2F;computer-science&#x2F;events&#x2F;seminars&#x2F;2016&#x2F;1104-howes.php" rel="nofollow">https:&#x2F;&#x2F;uh.edu&#x2F;nsm&#x2F;computer-science&#x2F;events&#x2F;seminars&#x2F;2016&#x2F;110...</a><p>Would the same things work today given how SEO spam and Google ads work? The same models are probably useful but it’s the noise and the long tail of the data that makes the problem hard.</div><br/><div id="40244154" class="c"><input type="checkbox" id="c-40244154" checked=""/><div class="controls bullet"><span class="by">bpiche</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40242843">parent</a><span>|</span><a href="#40242519">next</a><span>|</span><label class="collapse" for="c-40244154">[-]</label><label class="expand" for="c-40244154">[2 more]</label></div><br/><div class="children"><div class="content">I was a fan of LDA but would not agree that it is &#x27;probably useful&#x27; today. It&#x27;s an unsupervised clustering algorithm based on Gibbs sampling. Like k-means, it&#x27;s gonna return a few buckets that will have to be reviewed by a human for data exploration. In this case instead of neatly labeled buckets, these are unlabeled distributions of distributions (lists of single word tokens). If you do some kind of multiword tokenization preprocessing, it&#x27;ll return a few lists of words and multiword tokens for each document. How is this useful to an end user? Even internally, they&#x27;re not useful embeddings&#x2F;vectorizations. Would love to hear some contrary opinions</div><br/><div id="40245102" class="c"><input type="checkbox" id="c-40245102" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#40242336">root</a><span>|</span><a href="#40244154">parent</a><span>|</span><a href="#40242519">next</a><span>|</span><label class="collapse" for="c-40245102">[-]</label><label class="expand" for="c-40245102">[1 more]</label></div><br/><div class="children"><div class="content">In many applications like especially Google&#x27;s display ad targeting market, the &quot;accuracy&quot; of the clusters isn&#x27;t so import as the lift in key metrics (e.g. click rates or revenue) and the overall efficiency of the method.  Indeed the clustering algo might get things &quot;dead wrong&quot; but somehow surface something that causes clicks and revenue to increase.  LDA offered much improvement over e.g. TF-IDF models, just as t-SNE improved on LDA, and now LLM embeddings are on average better and potentially cheap to compute.<p>LDA could be useful if your success metric is perplexity; k-means is useful if vector distance is very meaningful for your problem.  Also well-studied algorithms are generally useful for initial studies in a new, unknown dataset.  As always with ML, the dataset and setting are just as important as the model and algorithm.</div><br/></div></div></div></div></div></div></div></div><div id="40242519" class="c"><input type="checkbox" id="c-40242519" checked=""/><div class="controls bullet"><span class="by">mmastrac</span><span>|</span><a href="#40242336">prev</a><span>|</span><a href="#40243105">next</a><span>|</span><label class="collapse" for="c-40242519">[-]</label><label class="expand" for="c-40242519">[2 more]</label></div><br/><div class="children"><div class="content">Given this was published in 2010, and <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Word2vec" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Word2vec</a> was  published in 2013, perhaps this was an early precursor?<p>From the article linked from this blog post: &quot;Enabling computers to understand language remains one of the hardest problems in artificial intelligence.&quot;</div><br/><div id="40243743" class="c"><input type="checkbox" id="c-40243743" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#40242519">parent</a><span>|</span><a href="#40243105">next</a><span>|</span><label class="collapse" for="c-40243743">[-]</label><label class="expand" for="c-40243743">[1 more]</label></div><br/><div class="children"><div class="content">I worked for this task for a year and it doesn&#x27;t work very well because in embedding space relatedness, synonymy and antonymy are mixed up and require pairwise thresholding. You can probably get to 90% but not 99% this way. Better use a crossentropy approach.<p>In modern RAG applications we return top-k results for this reason - it can&#x27;t simply give the correct snippet in one result, leaving the hard part to the LLM to make sense what is useful and what is not.</div><br/></div></div></div></div><div id="40243105" class="c"><input type="checkbox" id="c-40243105" checked=""/><div class="controls bullet"><span class="by">fuzzy_biscuit</span><span>|</span><a href="#40242519">prev</a><span>|</span><a href="#40242448">next</a><span>|</span><label class="collapse" for="c-40243105">[-]</label><label class="expand" for="c-40243105">[1 more]</label></div><br/><div class="children"><div class="content">Oh man, I miss the days when Matt Cutts was the de facto search liaison at Google. When I was doing an agency SEO, I read his posts and followed him with fervor.</div><br/></div></div><div id="40242448" class="c"><input type="checkbox" id="c-40242448" checked=""/><div class="controls bullet"><span class="by">e____g</span><span>|</span><a href="#40243105">prev</a><span>|</span><a href="#40242744">next</a><span>|</span><label class="collapse" for="c-40242448">[-]</label><label class="expand" for="c-40242448">[1 more]</label></div><br/><div class="children"><div class="content">(2010)</div><br/></div></div><div id="40242685" class="c"><input type="checkbox" id="c-40242685" checked=""/><div class="controls bullet"><span class="by">dkjaudyeqooe</span><span>|</span><a href="#40242744">prev</a><span>|</span><a href="#40242743">next</a><span>|</span><label class="collapse" for="c-40242685">[-]</label><label class="expand" for="c-40242685">[4 more]</label></div><br/><div class="children"><div class="content">&gt; A lot of people seem to think that Google only does simple-minded matching of the users’ keywords with words that we indexed<p>Oh what a dream if that were true! Instead, every year, the &#x27;synonyms&#x27; get broader and broader. To me it looks like they&#x27;re using synonyms of synonyms (of synonyms).<p>One thing is surely true: Google abhors a vacuum, they will show you results, no matter how tenuously connected to your query.</div><br/><div id="40242961" class="c"><input type="checkbox" id="c-40242961" checked=""/><div class="controls bullet"><span class="by">Calavar</span><span>|</span><a href="#40242685">parent</a><span>|</span><a href="#40242743">next</a><span>|</span><label class="collapse" for="c-40242961">[-]</label><label class="expand" for="c-40242961">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Oh what a dream if that were true! Instead, every year, the &#x27;synonyms&#x27; get broader and broader. To me it looks like they&#x27;re using synonyms of synonyms (of synonyms).<p>Forget about synonyms of synonyms - I&#x27;ve seen antonyms  bolded as matches in google search results. I have to imagine I&#x27;m not the only one.</div><br/><div id="40243107" class="c"><input type="checkbox" id="c-40243107" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#40242685">root</a><span>|</span><a href="#40242961">parent</a><span>|</span><a href="#40242743">next</a><span>|</span><label class="collapse" for="c-40243107">[-]</label><label class="expand" for="c-40243107">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve also seen a few cases where it decided to cross out the word &quot;not&quot;, basically inverting all the results.</div><br/><div id="40243273" class="c"><input type="checkbox" id="c-40243273" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#40242685">root</a><span>|</span><a href="#40243107">parent</a><span>|</span><a href="#40242743">next</a><span>|</span><label class="collapse" for="c-40243273">[-]</label><label class="expand" for="c-40243273">[1 more]</label></div><br/><div class="children"><div class="content">Google has slashed one term in my two word query. The results of this 50% query reduction, predictably, were complete trash.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>