<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1690275648550" as="style"/><link rel="stylesheet" href="styles.css?v=1690275648550"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.evanmiller.org/attention-is-off-by-one.html">Attention Is Off By One</a> <span class="domain">(<a href="https://www.evanmiller.org">www.evanmiller.org</a>)</span></div><div class="subtext"><span>elbasti</span> | <span>239 comments</span></div><br/><div><div id="36853329" class="c"><input type="checkbox" id="c-36853329" checked=""/><div class="controls bullet"><span class="by">tylerneylon</span><span>|</span><a href="#36852939">next</a><span>|</span><label class="collapse" for="c-36853329">[-]</label><label class="expand" for="c-36853329">[26 more]</label></div><br/><div class="children"><div class="content">1. Summary<p>The author is suggesting that we add 1 to the denominator of the softmax that is used within attention mechanisms (not the final output softmax).<p>The softmax inside an attention unit allows it to see key&#x2F;query matches as probabilities; those probabilities support a continuous-valued version of a key-value lookup (instead of 1&#x2F;0 output of a lookup, we get weights where a high weight = the desired key-value lookup).<p>Adding 1 to the denominator would change an attention unit by no longer working with a true probability vector of weights, but rather working with weights that add up to less than 1. The motivation is that the network can learn to provide high weights so that the adjusted softmax is very close to a probability vector; and it has a new option to provide all-low weights which give all-low output weights, meaning it can opt out of having high confidence in anything.<p>(switching to opinion mode)<p>2. How can we tell if this is good?<p>2a. We should just try it out: Train an LLM with this, see if it works.<p>2b. There are two reasons I suspect it won&#x27;t make a big difference.<p>First, if an attention node has low confidence, it can already assign similar scores pre-softmax. Then we get what looks like a uniform distribution as output. Then we&#x27;re basically taking an average of a bunch of vectors (vs a weighted average that is more like choosing one of them). Statistically, we expect that averaged vector to be close to zero. In other words, the node already has a way to effectively opt-out by providing a near-zero output vector.<p>Second, in a transformer, each attention unit has many other learned weights that can support the ability to opt out. Both the V matrix and the feed-forward layer after the attention unit give that module a way to provide low values to the activation function after the feed-forward layer, which would result in a value as small as you like — again, a way to opt out.<p>3. I appreciate the non-academic tone of the article and the willingness to play around with fundamental ideas. Although I&#x27;m not totally convinced by the note, I&#x27;d love to read more stuff like this.</div><br/><div id="36856266" class="c"><input type="checkbox" id="c-36856266" checked=""/><div class="controls bullet"><span class="by">nazgul17</span><span>|</span><a href="#36853329">parent</a><span>|</span><a href="#36857392">next</a><span>|</span><label class="collapse" for="c-36856266">[-]</label><label class="expand" for="c-36856266">[14 more]</label></div><br/><div class="children"><div class="content">The way I understood it, the author is saying that, with this change, big values disappear, and we can then use fewer bits to encode the output of transformers, which means reducing the memory requirements of the network. Memory being the limiting factor to running models large, this would be a big deal.</div><br/><div id="36858500" class="c"><input type="checkbox" id="c-36858500" checked=""/><div class="controls bullet"><span class="by">bambax</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36856266">parent</a><span>|</span><a href="#36857437">next</a><span>|</span><label class="collapse" for="c-36858500">[-]</label><label class="expand" for="c-36858500">[5 more]</label></div><br/><div class="children"><div class="content">&gt; <i>The Qualcomm AI researchers found that 97%+ of outlier activations in LLMs occur in whitespace and punctuation positions.</i><p>This is striking. If true, why not try to ignore whitespace and puctuation?<p>In old Latin, scripto continua [1] was a way to write continuously, <i>for the exact same reason</i>: to save space. Other modern languages still do that, and are no less parseable.<p>Granted, it&#x27;s unlikely a commercial LLM would become popular if it produced output without spaces or punctuation; but an open source one that promised to be much more compressible, and therefore work on smaller machines, might be super useful.<p>It&#x27;s not hard for a human to add spaces afterwards. It used to be a job for beginning journalists at the time of telex machines: press releases were sent in all caps without spaces, and interns were tasked with adding slashes between words. In French it was called &quot;bâtonner les dépêches&quot; (literally: add sticks to press releases -- not sure about the idiomatic English translation).<p>[1] <a href="https:&#x2F;&#x2F;simple.wikipedia.org&#x2F;wiki&#x2F;Scriptio_continua" rel="nofollow noreferrer">https:&#x2F;&#x2F;simple.wikipedia.org&#x2F;wiki&#x2F;Scriptio_continua</a></div><br/><div id="36859121" class="c"><input type="checkbox" id="c-36859121" checked=""/><div class="controls bullet"><span class="by">espe</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36858500">parent</a><span>|</span><a href="#36859037">next</a><span>|</span><label class="collapse" for="c-36859121">[-]</label><label class="expand" for="c-36859121">[1 more]</label></div><br/><div class="children"><div class="content">those paratextual phenomena probably are important for the model&#x27;s representations.. not to get rid of and not easily compressable either. have a look at predicitive features for authorship attribution in stylometry for example. whitespace and punctuation are always decisive.</div><br/></div></div><div id="36859037" class="c"><input type="checkbox" id="c-36859037" checked=""/><div class="controls bullet"><span class="by">colordrops</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36858500">parent</a><span>|</span><a href="#36859121">prev</a><span>|</span><a href="#36857437">next</a><span>|</span><label class="collapse" for="c-36859037">[-]</label><label class="expand" for="c-36859037">[3 more]</label></div><br/><div class="children"><div class="content">Seems you could make a pipeline where a much simpler model adds spaces and punctuation to output from the main model.</div><br/><div id="36859103" class="c"><input type="checkbox" id="c-36859103" checked=""/><div class="controls bullet"><span class="by">samwillis</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36859037">parent</a><span>|</span><a href="#36859202">next</a><span>|</span><label class="collapse" for="c-36859103">[-]</label><label class="expand" for="c-36859103">[1 more]</label></div><br/><div class="children"><div class="content">I suspect punctuation adds significant meaning to the models, that could be why so much computation is applied to it.<p>That&#x27;s not to say a pipeline couldn&#x27;t be effective.</div><br/></div></div><div id="36859202" class="c"><input type="checkbox" id="c-36859202" checked=""/><div class="controls bullet"><span class="by">bambax</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36859037">parent</a><span>|</span><a href="#36859103">prev</a><span>|</span><a href="#36857437">next</a><span>|</span><label class="collapse" for="c-36859202">[-]</label><label class="expand" for="c-36859202">[1 more]</label></div><br/><div class="children"><div class="content">Yes I was thinking about that, it should be quite easy afterwards.</div><br/></div></div></div></div></div></div><div id="36857437" class="c"><input type="checkbox" id="c-36857437" checked=""/><div class="controls bullet"><span class="by">AlanSE</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36856266">parent</a><span>|</span><a href="#36858500">prev</a><span>|</span><a href="#36857392">next</a><span>|</span><label class="collapse" for="c-36857437">[-]</label><label class="expand" for="c-36857437">[8 more]</label></div><br/><div class="children"><div class="content">Yeah, good to bring it back to the original point. Reading the article felt exciting, but in hindsight I am now missing a key detail.<p>The equations all seem to be matrix operations with a fixed number of rows &#x2F; columns (you can take me as a real layman here). Unless you change that, I don&#x27;t understand _how_ you can reduce memory needs. Granted, I&#x27;m probably putting my foot in my mouth not understanding transformers.</div><br/><div id="36857971" class="c"><input type="checkbox" id="c-36857971" checked=""/><div class="controls bullet"><span class="by">zamalek</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857437">parent</a><span>|</span><a href="#36857554">next</a><span>|</span><label class="collapse" for="c-36857971">[-]</label><label class="expand" for="c-36857971">[3 more]</label></div><br/><div class="children"><div class="content">More ELI5 than the other comments. Considering the softmax network:<p>During quantization we find that values in the network vary from 0-&gt;5000, but 95% of values are &lt;100. Quantizing this to 8bits would mean that our values would be in increments of about 20. Remembering that 95% of our values are below 100, we would only have about 5 discrete values for 95% of our values - so we would be losing a lot of &quot;resolution&quot; (entropy&#x2F;information). For example (assuming rounding is used), an original value of 19 would be quantized to 20 and 30 would be quantized to 40. The original values differ by 11, but the quantized values differ by 20!<p>This is where exotic encodings come into play. We might try to use a logarithmic scheme, for example. This would result in higher value densities at lower values - but we would probably still waste bits and it would require more APU cycles.<p>Now switch to the softmax1 network:<p>The range of values is less important than the distribution - instead of 95% of the values falling in a small range, we would see the values more evenly spread out. Assuming that the range is now 105 (so the 5% outlying neurons from the softmax network are still &gt;100), we would have 243 values to represent everything under 100. The same example with 19 and 30 would result in 19.27 and 30.34 respectively, a difference of 11.07 - which is very close to the unquantized difference of 11. We have retained more information in the quantized version of the network.<p>Information is lost either way, but what&#x27;s important is how much information is lost.<p>The reason that the large values appear is because the heads attempt to &quot;scream really loud&quot; when they are certain that they are right. This is an emergent behavior due to softmax - it ironically sucks at paying <i>attention</i> to a few of the heads: it boosts the volume of the heads that are trying to abstain, and mutes the volume of the heads that are trying to vote.</div><br/><div id="36859138" class="c"><input type="checkbox" id="c-36859138" checked=""/><div class="controls bullet"><span class="by">sampo</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857971">parent</a><span>|</span><a href="#36859063">next</a><span>|</span><label class="collapse" for="c-36859138">[-]</label><label class="expand" for="c-36859138">[1 more]</label></div><br/><div class="children"><div class="content">&gt; During quantization we find that values in the network vary from 0-&gt;5000, but 95% of values are &lt;100. Quantizing this to 8bits would mean that our values would be in increments of about 20.<p>Instead of using an 8bit integer with even step size quantification, wouldn&#x27;t they still use an 8bit float?</div><br/></div></div><div id="36859063" class="c"><input type="checkbox" id="c-36859063" checked=""/><div class="controls bullet"><span class="by">samwillis</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857971">parent</a><span>|</span><a href="#36859138">prev</a><span>|</span><a href="#36857554">next</a><span>|</span><label class="collapse" for="c-36859063">[-]</label><label class="expand" for="c-36859063">[1 more]</label></div><br/><div class="children"><div class="content">If I&#x27;m following correctly, does this mean that with this change along with a model being quantized, we could see models that are 5% the size (on file system) and memory usage but almost identical in output?</div><br/></div></div></div></div><div id="36857554" class="c"><input type="checkbox" id="c-36857554" checked=""/><div class="controls bullet"><span class="by">jablongo</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857437">parent</a><span>|</span><a href="#36857971">prev</a><span>|</span><a href="#36859359">next</a><span>|</span><label class="collapse" for="c-36857554">[-]</label><label class="expand" for="c-36857554">[2 more]</label></div><br/><div class="children"><div class="content">It has to do with the precision of the values stored in those rows and columns.  If they could be coerced into a narrower range (without losing information) then we could effectively store them each with 8 bits or something. The +1 prevents blowups when the denominator in its current form approaches 0, and without those blowups, then we can use less bits, in theory.</div><br/><div id="36858097" class="c"><input type="checkbox" id="c-36858097" checked=""/><div class="controls bullet"><span class="by">cycomanic</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857554">parent</a><span>|</span><a href="#36859359">next</a><span>|</span><label class="collapse" for="c-36858097">[-]</label><label class="expand" for="c-36858097">[1 more]</label></div><br/><div class="children"><div class="content">That is only true if the using the new softmax changes the dynamic range of the values. We are using floating point not fixed point. So if before our values went from 1 to 5000 and now they go from 0.0002 to 1 we still have the same dynamic range and so still need the same resolution.</div><br/></div></div></div></div><div id="36859359" class="c"><input type="checkbox" id="c-36859359" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857437">parent</a><span>|</span><a href="#36857554">prev</a><span>|</span><a href="#36857542">next</a><span>|</span><label class="collapse" for="c-36859359">[-]</label><label class="expand" for="c-36859359">[1 more]</label></div><br/><div class="children"><div class="content">The activations (outputs) of one layer must be encoded in the same way as the weights of that layer as well as the weights of the next layer or the computation fails (unless you manage to write clever kernels for doing math at different levels of precision simultaneously, but even then you&#x27;re introducing even more lossiness than just using a binary representation for those values).<p>Example: multiplying a bunch of float16s together gives you a float16. That is passed on to the next layer of float16s. Why should forcing the output of the first step to be float8 confer <i>any</i> advantage here? The only way I can see this argument working is if you make all the layers float8 too, and the reason you can do that is that the output of the first step can be faithfully represented as float8 because it doesn&#x27;t ever blow up. If that&#x27;s what the author is saying, it wasn&#x27;t very clear.</div><br/></div></div><div id="36857542" class="c"><input type="checkbox" id="c-36857542" checked=""/><div class="controls bullet"><span class="by">sudosysgen</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857437">parent</a><span>|</span><a href="#36859359">prev</a><span>|</span><a href="#36857392">next</a><span>|</span><label class="collapse" for="c-36857542">[-]</label><label class="expand" for="c-36857542">[1 more]</label></div><br/><div class="children"><div class="content">You can reduce the number of bits per float (scalar).</div><br/></div></div></div></div></div></div><div id="36857392" class="c"><input type="checkbox" id="c-36857392" checked=""/><div class="controls bullet"><span class="by">jablongo</span><span>|</span><a href="#36853329">parent</a><span>|</span><a href="#36856266">prev</a><span>|</span><a href="#36856168">next</a><span>|</span><label class="collapse" for="c-36857392">[-]</label><label class="expand" for="c-36857392">[3 more]</label></div><br/><div class="children"><div class="content">Yea - the way we can &quot;tell if this is good&quot; is by<p>a) train two identical models on a large dataset, one with the +1 in the denominator for the softmax steps of the attention modules, one without<p>b) show that they have similar performance (doubt the +1 will make performance better, but we need to show it doesn&#x27;t make things worse)<p>c) show that there are less &quot;blowups&quot; in the model with +1, and therefore they are more effectively quantized.</div><br/><div id="36858247" class="c"><input type="checkbox" id="c-36858247" checked=""/><div class="controls bullet"><span class="by">bambax</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857392">parent</a><span>|</span><a href="#36857956">next</a><span>|</span><label class="collapse" for="c-36858247">[-]</label><label class="expand" for="c-36858247">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>train two identical models on a large dataset</i><p>Yes but how much would this cost?<p>Would it be possible to build a small dataset that produces known outlier values, and test on that?</div><br/></div></div><div id="36857956" class="c"><input type="checkbox" id="c-36857956" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857392">parent</a><span>|</span><a href="#36858247">prev</a><span>|</span><a href="#36856168">next</a><span>|</span><label class="collapse" for="c-36857956">[-]</label><label class="expand" for="c-36857956">[1 more]</label></div><br/><div class="children"><div class="content">That is a good start. I wonder though if the change affects the ideal hyperparameters. Do you need more or less dropout if you make the change? What about learning rate?<p>So you might want to re-search the hyper params for a fair shot.</div><br/></div></div></div></div><div id="36856168" class="c"><input type="checkbox" id="c-36856168" checked=""/><div class="controls bullet"><span class="by">sweezyjeezy</span><span>|</span><a href="#36853329">parent</a><span>|</span><a href="#36857392">prev</a><span>|</span><a href="#36857914">next</a><span>|</span><label class="collapse" for="c-36856168">[-]</label><label class="expand" for="c-36856168">[2 more]</label></div><br/><div class="children"><div class="content">&gt; First, if an attention node has low confidence, it can already assign similar scores pre-softmax. Then we get what looks like a uniform distribution as output.<p>Disagree here, I think neural nets are quite bad at implicitly learning low entropy transforms, similar to how they struggle to model the identity function, necessitating residual connections. In both cases the change doesn&#x27;t increase expressivity, but it does bake these needle-in-a-haystack transformations into the model that may be hard to access with gradient descent.<p>Can&#x27;t speak to how useful it is though.</div><br/><div id="36859374" class="c"><input type="checkbox" id="c-36859374" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36856168">parent</a><span>|</span><a href="#36857914">next</a><span>|</span><label class="collapse" for="c-36859374">[-]</label><label class="expand" for="c-36859374">[1 more]</label></div><br/><div class="children"><div class="content">Surely you mean high-entropy, ie, uniform? We are talking about extremely low-entropy predictions as being the problem here.</div><br/></div></div></div></div><div id="36857914" class="c"><input type="checkbox" id="c-36857914" checked=""/><div class="controls bullet"><span class="by">tangjurine</span><span>|</span><a href="#36853329">parent</a><span>|</span><a href="#36856168">prev</a><span>|</span><a href="#36856646">next</a><span>|</span><label class="collapse" for="c-36857914">[-]</label><label class="expand" for="c-36857914">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Statistically, we expect that averaged vector to be close to zero.<p>I&#x27;m not sure that&#x27;s the case, especially in high dimensions.<p>The expected value of the absolute value n random variables, uniform [-1,1], grows with n. I&#x27;m pretty sure it&#x27;s proportional to the sqrt of n.<p>Also, random walks in high dimension return to zero with probability zero, so the sum of random variables in high dimensions going close to zero seems unlikely as well.</div><br/><div id="36858211" class="c"><input type="checkbox" id="c-36858211" checked=""/><div class="controls bullet"><span class="by">tylerneylon</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36857914">parent</a><span>|</span><a href="#36856646">next</a><span>|</span><label class="collapse" for="c-36858211">[-]</label><label class="expand" for="c-36858211">[1 more]</label></div><br/><div class="children"><div class="content">Both of your points are basically true, but I think a better way to model the problem is as a set of similar-length vectors being linearly combined by a probability vector.<p>Mathematically, we can write v_out = V * w,<p>where v_out is the vector of output from the attention unit, w is the probability vector from the softmax, and V is the set of input vectors, where each column is an input vector.<p>For a moment, pretend that the columns of V are orthonormal to each other. This might not be true, but it&#x27;s an interesting case.<p>When the model wants the output to be small, it can set w = 1&#x2F;n, meaning all coordinates of vector w are 1&#x2F;n. (n = the number of columns in V)<p>In that case, the length ||v_out|| will be 1&#x2F;sqrt(n) exactly, which is small compared to the input lengths of 1 (since we&#x27;re pretending they were orthonormal).<p>Now if we stop pretending they are orthonormal, the worst case is that they&#x27;re all the same vector, in which case the weights w can&#x27;t change anything. But that&#x27;s a mighty weird case, and in high dimensions, if you have any randomness at all to a set of vectors, they tend to point in wildly different directions with dot products close to zero, in which case the same intuition for the orthonormal case applies, and we&#x27;d expect a uniform distribution coming out of the softmax to give us a vector that&#x27;s much smaller than any of the input vectors.</div><br/></div></div></div></div><div id="36856646" class="c"><input type="checkbox" id="c-36856646" checked=""/><div class="controls bullet"><span class="by">thaumasiotes</span><span>|</span><a href="#36853329">parent</a><span>|</span><a href="#36857914">prev</a><span>|</span><a href="#36858733">next</a><span>|</span><label class="collapse" for="c-36856646">[-]</label><label class="expand" for="c-36856646">[3 more]</label></div><br/><div class="children"><div class="content">I actually prefer the conceptual model the author suggests:<p>&gt; Originally I wanted to call this function ghostmax, as you can think of there being an extra zero-valued entry in x (as exp(0)=1), as well as a zero vector in the V matrix that attenuates the result.<p>Don&#x27;t think of this as weighting the options so that some of the time none of them is chosen. (&quot;Weights that add up to less than 1.&quot;) Instead, think of this as forcing the consideration of the option &quot;do nothing&quot; whenever any set of options is otherwise considered. It&#x27;s the difference between &quot;when all you have is a hammer, everything looks like a nail [and gets hammered]&quot; and &quot;when all you have is a hammer, nails get hammered and non-nails get ignored&quot;.<p>I like this framing because, as an example, it bothers me that our speech-to-text systems use this method:<p>1. A human predetermines what language the input will use.<p>2. Audio in that language is fed to transcribing software.<p>3. You get, with modern technology, a pretty decent transcription.<p>3(a). <i>...if the audio sample was really in the language chosen in step 1.</i><p>If you ignore the choice of language and feed French audio to an English transcriber, you get gibberish. This is wildly at odds with how humans do transcription, where absolutely the first thing that a system that only knows how to transcribe English will do, when given French audio, is object &quot;hey, this is definitely not English&quot;.</div><br/><div id="36859004" class="c"><input type="checkbox" id="c-36859004" checked=""/><div class="controls bullet"><span class="by">tylerneylon</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36856646">parent</a><span>|</span><a href="#36859392">next</a><span>|</span><label class="collapse" for="c-36859004">[-]</label><label class="expand" for="c-36859004">[1 more]</label></div><br/><div class="children"><div class="content">I like your description because it&#x27;s relatively succinct and intuitively suggests why the modified softmax can help the model handle edge cases. It&#x27;s nice to ask: How could the model realistically learn to correctly handle situation X?</div><br/></div></div><div id="36859392" class="c"><input type="checkbox" id="c-36859392" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#36853329">root</a><span>|</span><a href="#36856646">parent</a><span>|</span><a href="#36859004">prev</a><span>|</span><a href="#36858733">next</a><span>|</span><label class="collapse" for="c-36859392">[-]</label><label class="expand" for="c-36859392">[1 more]</label></div><br/><div class="children"><div class="content">This seems like a good way to look at it. Another way to put it is, there is a certain &quot;origin&quot; or &quot;default&quot; confidence which is pinned to some fixed value pre-softmax, ie, all outputs are necessarily compared to that fixed value (pretending zero is another input to the softmax) rather than merely each other.</div><br/></div></div></div></div><div id="36858733" class="c"><input type="checkbox" id="c-36858733" checked=""/><div class="controls bullet"><span class="by">spi</span><span>|</span><a href="#36853329">parent</a><span>|</span><a href="#36856646">prev</a><span>|</span><a href="#36852939">next</a><span>|</span><label class="collapse" for="c-36858733">[-]</label><label class="expand" for="c-36858733">[1 more]</label></div><br/><div class="children"><div class="content">I agree with your conclusions, but not necessarily with the reasons you present. I don&#x27;t think it&#x27;s _that_ easy for a current transformer to pass the information unaltered (i.e. to effectively replace softmax with 0).<p>In particular, I think the feedforward point you list in your &quot;Second&quot; is actually wrong. Replacing a softmax with 0, as the OP wants to do, is tantamount to passing the information unchanged, because the attention block is within a residual (skip) connection. If it&#x27;s set to zero, the next output is identical to the previous layer output. There is no way to recover this effect with the feedforward layer.<p>The part that you can set V to zero is true, but somehow a different idea: the Q and K should be able to set to 0 if no token wants to be &quot;close&quot; to some other token, in some sense. But the V layer shouldn&#x27;t &quot;know&quot; about this, because it can&#x27;t look at other tokens. This is of course only how we think of transformers, which might or might not (more likely, the latter) be how it actually works. But nevertheless, having a 0 value coming out of the K.Q^T part only would be very meaningful.<p>Your &quot;first&quot; point is technically true (albeit logically false): if you have a sequence of length 32k, like GPT4-32k, and your softmax logits all predict the same value, the result will be an average of the V layer, divided by 32k, which is effectively close to zero. However, calibrating &quot;exactly the same value&quot; is extremely hard for a neural network, and there is no &quot;default value&quot; it can predict to make sure that&#x27;s the case - even if you push all the values to one side, the result doesn&#x27;t change, because softmax is translation invariant. Plus, if you have a short sentence, that&#x27;s not true anymore. If you only have two tokens, one of them must be activated, or both with only a 0.5 factor. Surely if you have very few tokens there&#x27;s much more contamination between Q, K, and V, so in that case V can indeed take a 0 value, but it&#x27;s non-trivial and requires more layers.<p>All in all, adding that &quot;+1&quot; isn&#x27;t quite meaningless, I think. Nevertheless, I believe it won&#x27;t change much: these very big models have ways to get around any kind of smart small modification you do. If the intuition is very right, it might be that you can squeeze 1% out more accuracy in a handful of tests, after you carefully optimize all other parameters, which would be enough to get you a paper in a top conference. And it might also be implemented as a standard from them on (because, in this case, it basically doesn&#x27;t cost any more computations, so it&#x27;s &quot;free&quot;). But I would bet it won&#x27;t be a major revolution.<p>That said, as you say, the only way to know would be to train a few models with this option and check the actual quality of them (certainly not GPT-style, nor GPT4-size, models, to begin with, but something quicker to train and easier to test in a fully automated way; old &quot;boring&quot; models like those in the BERT family would be a good point to start testing). But to do that effectively, you&#x27;d need somebody skilled in training this kind of models, with the cleaned data ready at hand, etc. (and a small compute budget, of course, but nothing revolutionary, a few thousand $ in GPU credits could be enough)</div><br/></div></div></div></div><div id="36852939" class="c"><input type="checkbox" id="c-36852939" checked=""/><div class="controls bullet"><span class="by">alsodumb</span><span>|</span><a href="#36853329">prev</a><span>|</span><a href="#36854065">next</a><span>|</span><label class="collapse" for="c-36852939">[-]</label><label class="expand" for="c-36852939">[15 more]</label></div><br/><div class="children"><div class="content">I might be missing something obvious, but I am not sure why everyone in the comments think it&#x27;s a big deal. I&#x27;ve seen this trick in practice multiple times.<p>For example, see this snippet from an old Google repo: <a href="https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;flaxformer&#x2F;blob&#x2F;ee62754ebe5a5eeb111493622de5537133822e3e&#x2F;flaxformer&#x2F;components&#x2F;attention&#x2F;dense_attention.py#L50">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;flaxformer&#x2F;blob&#x2F;ee62754ebe5a5eeb11...</a></div><br/><div id="36854613" class="c"><input type="checkbox" id="c-36854613" checked=""/><div class="controls bullet"><span class="by">alevskaya</span><span>|</span><a href="#36852939">parent</a><span>|</span><a href="#36853499">next</a><span>|</span><label class="collapse" for="c-36854613">[-]</label><label class="expand" for="c-36854613">[7 more]</label></div><br/><div class="children"><div class="content">Yeah we used to use this in our older models years ago... I don&#x27;t recall the details exactly, but I don&#x27;t think it ever did very much.<p>I certainly don&#x27;t think it will help at all with stability.  Things like Q&#x2F;K layernorm are better tricks for softmax stability when scaling: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.05442.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.05442.pdf</a></div><br/><div id="36854897" class="c"><input type="checkbox" id="c-36854897" checked=""/><div class="controls bullet"><span class="by">ggerganov</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36854613">parent</a><span>|</span><a href="#36853499">next</a><span>|</span><label class="collapse" for="c-36854897">[-]</label><label class="expand" for="c-36854897">[6 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t recall the details exactly, but I don&#x27;t think it ever did very much.<p>How would you have known if the trick actually reduces the outliers in the weights? Even if the transformer quality does not improve overall, having less outliers as a result is very beneficial for more accurate quantization of the data</div><br/><div id="36854950" class="c"><input type="checkbox" id="c-36854950" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36854897">parent</a><span>|</span><a href="#36853499">next</a><span>|</span><label class="collapse" for="c-36854950">[-]</label><label class="expand" for="c-36854950">[5 more]</label></div><br/><div class="children"><div class="content">Are you asking &quot;why would you have bothered to look at&quot;?<p>The &quot;how&quot; is pretty straightforward.</div><br/><div id="36856666" class="c"><input type="checkbox" id="c-36856666" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36854950">parent</a><span>|</span><a href="#36858038">next</a><span>|</span><label class="collapse" for="c-36856666">[-]</label><label class="expand" for="c-36856666">[3 more]</label></div><br/><div class="children"><div class="content">He&#x27;s questioning the statement: &quot;I don&#x27;t think [the trick] ever did very much&quot;, because no one has yet looked at whether the trick helps reducing outliers in very large models. If it does help with this, as the blog author believes, then it is indeed a very useful trick.</div><br/><div id="36857755" class="c"><input type="checkbox" id="c-36857755" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36856666">parent</a><span>|</span><a href="#36858038">next</a><span>|</span><label class="collapse" for="c-36857755">[-]</label><label class="expand" for="c-36857755">[2 more]</label></div><br/><div class="children"><div class="content">Is he? A surface level reading suggests he&#x27;s asking &quot;how would you know&quot;.. and the answer is... by looking at the parameters. People do that.<p>&gt;&gt; because no one has yet looked at whether the trick helps reducing outliers in very large models<p>Given a softmax version doing exactly as the blog post says is baked into a google library (see this thread), and you can set it as a parameter in a pytorch model (see this thread), this claim seems off. &quot;Let&#x27;s try X, oh, X doesn&#x27;t do much, let&#x27;s <i>not</i> write a paper about it&quot; is extremely common for many X.</div><br/><div id="36858084" class="c"><input type="checkbox" id="c-36858084" checked=""/><div class="controls bullet"><span class="by">tudorw</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36857755">parent</a><span>|</span><a href="#36858038">next</a><span>|</span><label class="collapse" for="c-36858084">[-]</label><label class="expand" for="c-36858084">[1 more]</label></div><br/><div class="children"><div class="content">This would seem like a really good argument as to why failures should be written up, otherwise where is the list of what has been tried before?</div><br/></div></div></div></div></div></div><div id="36858038" class="c"><input type="checkbox" id="c-36858038" checked=""/><div class="controls bullet"><span class="by">ggerganov</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36854950">parent</a><span>|</span><a href="#36856666">prev</a><span>|</span><a href="#36853499">next</a><span>|</span><label class="collapse" for="c-36858038">[-]</label><label class="expand" for="c-36858038">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I assumed that checking the weights for presence and amount of outliers is not something that is usually done and effects on this can be overlooked. If my assumption is wrong and researchers do usually look at such metrics, then my question is not very relevant.<p>Agree - the &quot;how&quot; is straightforward</div><br/></div></div></div></div></div></div></div></div><div id="36853499" class="c"><input type="checkbox" id="c-36853499" checked=""/><div class="controls bullet"><span class="by">zorgmonkey</span><span>|</span><a href="#36852939">parent</a><span>|</span><a href="#36854613">prev</a><span>|</span><a href="#36853467">next</a><span>|</span><label class="collapse" for="c-36853499">[-]</label><label class="expand" for="c-36853499">[1 more]</label></div><br/><div class="children"><div class="content">If popular models are still making this mistake then it still seems noteworthy and making a blog post or paper to increase awareness definitely seems worthwhile. Also multiple independent discovery of good ideas is quite common.</div><br/></div></div><div id="36853467" class="c"><input type="checkbox" id="c-36853467" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#36852939">parent</a><span>|</span><a href="#36853499">prev</a><span>|</span><a href="#36854065">next</a><span>|</span><label class="collapse" for="c-36853467">[-]</label><label class="expand" for="c-36853467">[6 more]</label></div><br/><div class="children"><div class="content">The argument &#x2F; reasoning is a bit dubious.<p>Technically softmax is not implemented as presented but through exp(x_i-max(x)), and summing over it in the denom. But maybe I am missing something.<p>Furthermore, the residuals are used exactly because the networks cant learn the identity function; but they can learn zero; at which point the residual is `f(x): x+g(x)` with being `g:x ~&gt; 0` (ie approximately 0).<p>It is also the case that `f(x): x+g(x)` makes it easier for gradients to flow through.</div><br/><div id="36854217" class="c"><input type="checkbox" id="c-36854217" checked=""/><div class="controls bullet"><span class="by">mrfox321</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36853467">parent</a><span>|</span><a href="#36854895">next</a><span>|</span><label class="collapse" for="c-36854217">[-]</label><label class="expand" for="c-36854217">[4 more]</label></div><br/><div class="children"><div class="content">You are misreading things.<p>Regardless of numerical stability tricks (e.g. exp(x_i-max(x))), you are still simply normalizing the logits such that the probabilities sum to 1.<p>The blog adds an additional hidden logit (equal to 0) to allow for softmax(x) = 0 when x -&gt; -inf.</div><br/><div id="36855324" class="c"><input type="checkbox" id="c-36855324" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36854217">parent</a><span>|</span><a href="#36854895">next</a><span>|</span><label class="collapse" for="c-36855324">[-]</label><label class="expand" for="c-36855324">[3 more]</label></div><br/><div class="children"><div class="content">How can `x -&gt; -inf` occur in the first place when nearly everything is within [-2,2] and doing a dot product plus before that there&#x27;s normalization too?</div><br/><div id="36859423" class="c"><input type="checkbox" id="c-36859423" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36855324">parent</a><span>|</span><a href="#36854895">next</a><span>|</span><label class="collapse" for="c-36859423">[-]</label><label class="expand" for="c-36859423">[2 more]</label></div><br/><div class="children"><div class="content">The use of the &quot;nearly&quot; in your comment is exactly occluding the issue as presented.<p>Enough weights don&#x27;t fall under that &quot;nearly&quot; that we require more bits per weight to cover those edge cases. If we were able to delete the &quot;nearly&quot; we would need fewer bits (smaller models).</div><br/><div id="36859711" class="c"><input type="checkbox" id="c-36859711" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36859423">parent</a><span>|</span><a href="#36854895">next</a><span>|</span><label class="collapse" for="c-36859711">[-]</label><label class="expand" for="c-36859711">[1 more]</label></div><br/><div class="children"><div class="content">So the concern is not that x-&gt;-inf due to values but it happens due to numerical issues arising out of lower precision?</div><br/></div></div></div></div></div></div></div></div><div id="36854895" class="c"><input type="checkbox" id="c-36854895" checked=""/><div class="controls bullet"><span class="by">Piezoid</span><span>|</span><a href="#36852939">root</a><span>|</span><a href="#36853467">parent</a><span>|</span><a href="#36854217">prev</a><span>|</span><a href="#36854065">next</a><span>|</span><label class="collapse" for="c-36854895">[-]</label><label class="expand" for="c-36854895">[1 more]</label></div><br/><div class="children"><div class="content">Implementations usually replace replace the 1 in the denominator with exp(-max(x)) for this reason.</div><br/></div></div></div></div></div></div><div id="36854065" class="c"><input type="checkbox" id="c-36854065" checked=""/><div class="controls bullet"><span class="by">ersiees</span><span>|</span><a href="#36852939">prev</a><span>|</span><a href="#36853039">next</a><span>|</span><label class="collapse" for="c-36854065">[-]</label><label class="expand" for="c-36854065">[12 more]</label></div><br/><div class="children"><div class="content">This trick “they found” is part of the standard torch implementation of multi head attention, namely it is called, add_zero_attention. They add a zero to the logits, resulting in a one in the denominator as e^0=1 <a href="https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;generated&#x2F;torch.nn.MultiheadAttention.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;pytorch.org&#x2F;docs&#x2F;stable&#x2F;generated&#x2F;torch.nn.Multihead...</a></div><br/><div id="36857644" class="c"><input type="checkbox" id="c-36857644" checked=""/><div class="controls bullet"><span class="by">lovelearning</span><span>|</span><a href="#36854065">parent</a><span>|</span><a href="#36854283">next</a><span>|</span><label class="collapse" for="c-36857644">[-]</label><label class="expand" for="c-36857644">[1 more]</label></div><br/><div class="children"><div class="content">I find its documentation quite poor though: &quot;If specified, adds a new batch of zeros to the key and value sequences at dim=1.&quot;<p>Doesn&#x27;t describe the implications even briefly. If they add just your second sentence to that description, it&#x27;ll immediately become so much more useful.</div><br/></div></div><div id="36854283" class="c"><input type="checkbox" id="c-36854283" checked=""/><div class="controls bullet"><span class="by">civilized</span><span>|</span><a href="#36854065">parent</a><span>|</span><a href="#36857644">prev</a><span>|</span><a href="#36856253">next</a><span>|</span><label class="collapse" for="c-36854283">[-]</label><label class="expand" for="c-36854283">[9 more]</label></div><br/><div class="children"><div class="content">It&#x27;s an option which is set to false by default. Does that mean people have tried it and it&#x27;s not usually helpful...?</div><br/><div id="36854856" class="c"><input type="checkbox" id="c-36854856" checked=""/><div class="controls bullet"><span class="by">mlyle</span><span>|</span><a href="#36854065">root</a><span>|</span><a href="#36854283">parent</a><span>|</span><a href="#36856253">next</a><span>|</span><label class="collapse" for="c-36854856">[-]</label><label class="expand" for="c-36854856">[8 more]</label></div><br/><div class="children"><div class="content">Yes.</div><br/><div id="36855622" class="c"><input type="checkbox" id="c-36855622" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36854065">root</a><span>|</span><a href="#36854856">parent</a><span>|</span><a href="#36856253">next</a><span>|</span><label class="collapse" for="c-36855622">[-]</label><label class="expand" for="c-36855622">[7 more]</label></div><br/><div class="children"><div class="content">Can you elaborate? (It wouldn&#x27;t be the first time there was an extraneous feature that no one has every used in some code!)</div><br/><div id="36856024" class="c"><input type="checkbox" id="c-36856024" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36854065">root</a><span>|</span><a href="#36855622">parent</a><span>|</span><a href="#36855649">next</a><span>|</span><label class="collapse" for="c-36856024">[-]</label><label class="expand" for="c-36856024">[4 more]</label></div><br/><div class="children"><div class="content">If you take the inner product between a lot of more or less random vectors (the key and query vectors in attention) most values are going to be close to 0. This means they contribute by e^0 to the denominator. Now, if you have a context length of say 2000, your denominator is already ~ 2000. Increasing it to 2001 doesn&#x27;t really make a difference.<p>Adding 1 to the denominator can be useful if you have softmax with just a few options. Not in self-attention where you have thousands.</div><br/><div id="36856517" class="c"><input type="checkbox" id="c-36856517" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36854065">root</a><span>|</span><a href="#36856024">parent</a><span>|</span><a href="#36855649">next</a><span>|</span><label class="collapse" for="c-36856517">[-]</label><label class="expand" for="c-36856517">[3 more]</label></div><br/><div class="children"><div class="content">That simple comment is a strong counterpoint to the entire blog post?<p>Except with the +1 denominator, it might be that the model trains all of the inputs to become very negative so softmax chucks out close to zeros, whereas it wouldn&#x27;t bother before because making one prob bigger makes another smaller.</div><br/><div id="36856728" class="c"><input type="checkbox" id="c-36856728" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36854065">root</a><span>|</span><a href="#36856517">parent</a><span>|</span><a href="#36855649">next</a><span>|</span><label class="collapse" for="c-36856728">[-]</label><label class="expand" for="c-36856728">[2 more]</label></div><br/><div class="children"><div class="content">&gt; it might be that the model trains all of the inputs to become very negative<p>It still can&#x27;t do this because of L2 regularization &#x2F; weight decay. If two vectors are norm 1, their inner product is at least -1, so with 2000 vectors that&#x27;s still 2000 * e^(-1) =~ 735.<p>Not saying it&#x27;s theoretically impossible that it could happen. But you would have to try _really_ hard to make it happen.</div><br/><div id="36857095" class="c"><input type="checkbox" id="c-36857095" checked=""/><div class="controls bullet"><span class="by">redox99</span><span>|</span><a href="#36854065">root</a><span>|</span><a href="#36856728">parent</a><span>|</span><a href="#36855649">next</a><span>|</span><label class="collapse" for="c-36857095">[-]</label><label class="expand" for="c-36857095">[1 more]</label></div><br/><div class="children"><div class="content">I guess you could add a sort of gating operation with a learnable parameter that sends the value to -inf if doesn&#x27;t reach the threshold.<p>Of course it might have some other serious repercussions.</div><br/></div></div></div></div></div></div></div></div><div id="36855649" class="c"><input type="checkbox" id="c-36855649" checked=""/><div class="controls bullet"><span class="by">Q6T46nT668w6i3m</span><span>|</span><a href="#36854065">root</a><span>|</span><a href="#36855622">parent</a><span>|</span><a href="#36856024">prev</a><span>|</span><a href="#36856253">next</a><span>|</span><label class="collapse" for="c-36855649">[-]</label><label class="expand" for="c-36855649">[2 more]</label></div><br/><div class="children"><div class="content">It’s useful but it’s less used than dummy tokens.</div><br/><div id="36856774" class="c"><input type="checkbox" id="c-36856774" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36854065">root</a><span>|</span><a href="#36855649">parent</a><span>|</span><a href="#36856253">next</a><span>|</span><label class="collapse" for="c-36856774">[-]</label><label class="expand" for="c-36856774">[1 more]</label></div><br/><div class="children"><div class="content">Are dummy tokens just tokens that don&#x27;t have an associated input&#x2F;output token? Like, a way to give more computational power to the model without splitting the text into more actual tokens?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36856253" class="c"><input type="checkbox" id="c-36856253" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36854065">parent</a><span>|</span><a href="#36854283">prev</a><span>|</span><a href="#36853039">next</a><span>|</span><label class="collapse" for="c-36856253">[-]</label><label class="expand" for="c-36856253">[1 more]</label></div><br/><div class="children"><div class="content">Nice catch! Hopefully OP will see this.</div><br/></div></div></div></div><div id="36853039" class="c"><input type="checkbox" id="c-36853039" checked=""/><div class="controls bullet"><span class="by">jrochkind1</span><span>|</span><a href="#36854065">prev</a><span>|</span><a href="#36856682">next</a><span>|</span><label class="collapse" for="c-36853039">[-]</label><label class="expand" for="c-36853039">[13 more]</label></div><br/><div class="children"><div class="content">While not about AI or the algorithm mentioned, on the subject of little errors that you can&#x27;t convince anyone are errors....<p>In 2011, I wanted to copy the reddit ranking algorithm in a project of my own, so I went to source code to look at it... the algorithm in the source code I found wasn&#x27;t doing anything at all sensible with negative-sum voted posts.<p>I thought I discovered the error, some terms swapped in the simple equation, the sign for positive&#x2F;negative was misapplied.<p>I blogged it, and [posted it to reddit](<a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;programming&#x2F;comments&#x2F;td4tz&#x2F;reddits_actual_story_ranking_algorithm_explained&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;programming&#x2F;comments&#x2F;td4tz&#x2F;reddits_...</a>), only to have MANY people, including reddit employees, tell me I am definitely definitely wrong, and the algorithm was working as intended.  And that I  was in fact not the first to notice what I thought I noticed, and point it out, and be told by everyone I was wrong.<p>OK, I didn&#x27;t really understand what was going on, I couldn&#x27;t make sense of the algorithm if it wasn&#x27;t wrong, but so be it. I updated my blog post to say that people smarter than me said there was no error in the reddit algorithm, all I can say is this variation makes more sense to me.<p>Then, three years later in 2014, a commit was made to the reddit source code with <i>exactly the correction I (and others before me) had suggested</i> all along. The one that everyone piled on to tell me how dare I have the temerity to suggest reddit source code is wrong.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;reddit-archive&#x2F;reddit&#x2F;commit&#x2F;50d35de04b928836b7ee955c8a26f197e24ab01e#diff-d85a4e2bae6e58669811622c0fc7f618">https:&#x2F;&#x2F;github.com&#x2F;reddit-archive&#x2F;reddit&#x2F;commit&#x2F;50d35de04b92...</a><p>¯\_(ツ)_&#x2F;¯<p>Open source means there are lots of eyes that can find bugs, but sometimes they can&#x27;t convince anyone they&#x27;ve found a bug. (And of course, then reddit close-sourced their code in 2017).<p>I never did end up using the ranking feature in my own project, that I had wanted to copy from reddit. I didn&#x27;t end adding &quot;vote&quot; features to the app.</div><br/><div id="36855135" class="c"><input type="checkbox" id="c-36855135" checked=""/><div class="controls bullet"><span class="by">madrox</span><span>|</span><a href="#36853039">parent</a><span>|</span><a href="#36858214">next</a><span>|</span><label class="collapse" for="c-36855135">[-]</label><label class="expand" for="c-36855135">[2 more]</label></div><br/><div class="children"><div class="content">When I was an intern at Yahoo working on OAuth back in 2008 (2007? It was long ago and I&#x27;m old) I had the pleasure of implementing an internal tool for generating OAuth 1.0 URLs, which meant encoding a lot of things in query parameters. My tool did not generate URLs which were compatible with Yahoo&#x27;s implementation (certain parameters effectively should be encoded twice, which my tool did). The implementing engineer insisted my tool was wrong, cited my status as a lowly intern, and even pulled out the OAuth spec and bent over backwards to say how his implementation was correct and I&#x27;m clearly reading it wrong. It literally took bringing in Eran Hammer-Lahav to weigh in on the topic to say I was correct, at which point the engineer agreed that of course that was correct. I got zero acknowledgment or apology for the days of ad hominem attacks against me.<p>I did learn an important lesson that more senior people are not always right, and as someone who&#x27;s usually more senior than my colleagues now I try to remember it daily.</div><br/><div id="36859349" class="c"><input type="checkbox" id="c-36859349" checked=""/><div class="controls bullet"><span class="by">klabb3</span><span>|</span><a href="#36853039">root</a><span>|</span><a href="#36855135">parent</a><span>|</span><a href="#36858214">next</a><span>|</span><label class="collapse" for="c-36859349">[-]</label><label class="expand" for="c-36859349">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It literally took bringing in Eran Hammer-Lahav to weigh in on the topic to say I was correct, at which point the engineer agreed that of course that was correct. I got zero acknowledgment or apology for the days of ad hominem attacks against me.<p>If it weren’t for the torturous gaslighting, this is borderline hilarious. Appeal-to-authority types have a way of submitting so effortlessly when a grander poobah comes around. Spine made of jelly.</div><br/></div></div></div></div><div id="36858214" class="c"><input type="checkbox" id="c-36858214" checked=""/><div class="controls bullet"><span class="by">svachalek</span><span>|</span><a href="#36853039">parent</a><span>|</span><a href="#36855135">prev</a><span>|</span><a href="#36853792">next</a><span>|</span><label class="collapse" for="c-36858214">[-]</label><label class="expand" for="c-36858214">[1 more]</label></div><br/><div class="children"><div class="content">Wow, that must have been frustrating. I just looked at the code and it&#x27;s just so clearly wrong.</div><br/></div></div><div id="36853792" class="c"><input type="checkbox" id="c-36853792" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36853039">parent</a><span>|</span><a href="#36858214">prev</a><span>|</span><a href="#36856320">next</a><span>|</span><label class="collapse" for="c-36853792">[-]</label><label class="expand" for="c-36853792">[8 more]</label></div><br/><div class="children"><div class="content">I work at a FAANG and it was absolutely astonishing to find out how often this happens.<p>You can make a long, impactful career by just being &quot;the guy who adds log statements throughout the codebase and reasons through it&quot;, doing this at even a simplistic level has always shown me an astonishing fix to some long-standing issue.<p>n.b. It also attracts a ton of political fun. People&#x27;s first order reaction is denial, and it only gets worse from there. Absolutely no one except 1-2 colleagues will see it as &quot;oh we should fix that&quot;, and at least one person will make sure your boss&#x27; boss&#x27; boss is CCd on an email with a nice version of &quot;no he&#x27;s just insufficiently concerned about {concurrency, memory management, take your pick}&quot; Just wait it out quietly when that happens, do not engage or complain. If nothing happens and you&#x27;re never asked about it by leadership, but your peers ask, make plans to move onto another team.</div><br/><div id="36853914" class="c"><input type="checkbox" id="c-36853914" checked=""/><div class="controls bullet"><span class="by">jrochkind1</span><span>|</span><a href="#36853039">root</a><span>|</span><a href="#36853792">parent</a><span>|</span><a href="#36854187">next</a><span>|</span><label class="collapse" for="c-36853914">[-]</label><label class="expand" for="c-36853914">[1 more]</label></div><br/><div class="children"><div class="content">A long impactful career, or a career of horrible frustration and alienation as everyone gets mad at you for pointing out their bugs? (or, from their point of view, making trouble  insisting that something is a bug which isn&#x27;t and is causing no problems)</div><br/></div></div><div id="36854187" class="c"><input type="checkbox" id="c-36854187" checked=""/><div class="controls bullet"><span class="by">sidfthec</span><span>|</span><a href="#36853039">root</a><span>|</span><a href="#36853792">parent</a><span>|</span><a href="#36853914">prev</a><span>|</span><a href="#36856320">next</a><span>|</span><label class="collapse" for="c-36854187">[-]</label><label class="expand" for="c-36854187">[6 more]</label></div><br/><div class="children"><div class="content">What FAANG have you seen this at?<p>I&#x27;ve been at big tech companies for most of my career and I&#x27;ve never seen anyone deny the existence of a technical bug. I&#x27;ve seen plenty of teams mark a bug as lower priority and never fix it because other things are higher priority. But <i>denying that the bug exists</i>, especially after a detailed explanation? That doesn&#x27;t resonate with my experiences.</div><br/><div id="36854266" class="c"><input type="checkbox" id="c-36854266" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#36853039">root</a><span>|</span><a href="#36854187">parent</a><span>|</span><a href="#36856618">next</a><span>|</span><label class="collapse" for="c-36854266">[-]</label><label class="expand" for="c-36854266">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve told this story before!<p>It used to be writing the outputs from the C&#x2F;C++ preprocessor (.i files) to disk  took <i>forever</i> (5+ minutes IIRC) with Microsoft&#x27;s compilers. I asked one of the lead compiler developers why, and he waved me away saying it was just really complicated. Around that time a bunch of tools existed for GCC that worked with .i files, but none existed in the Microsoft ecosystem likely because writing .i files was so slow.<p>I was on the compiler test team at the time and we did lots of stuff with .i files, our tests were distributed across a large cluster of test machines (see my post about that <a href="https:&#x2F;&#x2F;meanderingthoughts.hashnode.dev&#x2F;how-microsoft-tested-compilers-circa-2006" rel="nofollow noreferrer">https:&#x2F;&#x2F;meanderingthoughts.hashnode.dev&#x2F;how-microsoft-tested...</a>) so it wasn&#x27;t a big deal, but it still annoyed me.<p>One day I decided to find out what was going on, so I loaded up process monitor while outputting a .i file and watched what was happening. Much to my surprise, only 1 byte was being written at a time! No wonder writes were taking forever.<p>A quick dive into the source code revealed a comment above the file write call that read to the effect<p>&#x2F;&#x2F; to work around a bug in windows 98<p>So anyway I opened a bug against the compiler saying we should probably fix that. :)</div><br/><div id="36854439" class="c"><input type="checkbox" id="c-36854439" checked=""/><div class="controls bullet"><span class="by">sidfthec</span><span>|</span><a href="#36853039">root</a><span>|</span><a href="#36854266">parent</a><span>|</span><a href="#36856618">next</a><span>|</span><label class="collapse" for="c-36854439">[-]</label><label class="expand" for="c-36854439">[3 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s not the type of story that&#x27;s being claimed from the person I responded to.<p>Of course the lead developer waved you off. You wondered why things took forever, and the lead developer knew it was a complicated system and figured it wasn&#x27;t worth their time investigating. It happened to be incorrect, but the lead developer wasn&#x27;t in denial. They just filtered the issue out because they can&#x27;t afford to go down every rabbit-hole they come across. I&#x27;m sure once you found the actual bug, it was later fixed.<p>The person I was responding to seems to think a large number of people are in denial when a bug is filed against them. That doesn&#x27;t make sense, and isn&#x27;t something I see. It&#x27;d be as if when you pointed out the actual bug, the lead developer continued to say it wasn&#x27;t actually a bug (which is of course ridiculous and I bet didn&#x27;t happen).</div><br/><div id="36856387" class="c"><input type="checkbox" id="c-36856387" checked=""/><div class="controls bullet"><span class="by">bogwog</span><span>|</span><a href="#36853039">root</a><span>|</span><a href="#36854439">parent</a><span>|</span><a href="#36855830">next</a><span>|</span><label class="collapse" for="c-36856387">[-]</label><label class="expand" for="c-36856387">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s 2 anecdotes to your 1. Anecdotes are useless, but you <i>are</i> down by 1. I suggest you call for reinforcements, or make a hasty retreat.</div><br/></div></div><div id="36855830" class="c"><input type="checkbox" id="c-36855830" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36853039">root</a><span>|</span><a href="#36854439">parent</a><span>|</span><a href="#36856387">prev</a><span>|</span><a href="#36856618">next</a><span>|</span><label class="collapse" for="c-36855830">[-]</label><label class="expand" for="c-36855830">[1 more]</label></div><br/><div class="children"><div class="content">You are ascribing an absurdly maximalist viewpoint to me, one that would be obviously wrong at its face.<p>I know it&#x27;s not so confusing as to get that sort of interpretation, because of the score on the comment, and comments like the above that explain to you how this happens.<p>As a result, I don&#x27;t feel comfortable providing more detail publicly about my situation. That far off the mark tends to indicate an aggressive rather than curious interlocutor.<p>I am comfortable building on their example. The particulars of the issue are quite similar in a very helpful way.<p>I did the investigation, did a fix, worked it up to my manager and my managers manager. Elated, we work diligently for a couple weeks to document concisely, 3 page tech doc, briefest code deltas possible, one page + slides withs simple diagrams.<p>It gets bogged down at managers managers coleads submanager for the platform team implicated. They basically say &quot;reading the single byte at a time means its provably serial and thus has no concurrency bugs.&quot;, as indicated in my original comment.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36856320" class="c"><input type="checkbox" id="c-36856320" checked=""/><div class="controls bullet"><span class="by">frakkingcylons</span><span>|</span><a href="#36853039">parent</a><span>|</span><a href="#36853792">prev</a><span>|</span><a href="#36856682">next</a><span>|</span><label class="collapse" for="c-36856320">[-]</label><label class="expand" for="c-36856320">[1 more]</label></div><br/><div class="children"><div class="content">In light of the past couple of months, I guess I should not surprised that the interaction with reddit staff went that way.</div><br/></div></div></div></div><div id="36856682" class="c"><input type="checkbox" id="c-36856682" checked=""/><div class="controls bullet"><span class="by">cycomanic</span><span>|</span><a href="#36853039">prev</a><span>|</span><a href="#36852578">next</a><span>|</span><label class="collapse" for="c-36856682">[-]</label><label class="expand" for="c-36856682">[3 more]</label></div><br/><div class="children"><div class="content">The I know it&#x27;s on-vogue on HN to complain about academia, but the blog post is not making a good argument.<p>The post could have probably  gotten the point across in less than 1&#x2F;4 of the overall length (probably even less than 1&#x2F;8th), instead the author wrapped the the post into lots of informalisms and a thinly veiled complained about academic publishing.<p>The result of this is reflected in the discussion here, nobody actually writes about the result&#x2F;idea behind the post, instead we have ~200 comments discussing the merits of academic publishing vs blog posts and formal vs informal writing.<p>So I guess if you want to get your blog-post on the front page of HN it&#x27;s a good writing style. If you want someone to consider and discuss the merits of your idea, maybe not so much.</div><br/><div id="36857169" class="c"><input type="checkbox" id="c-36857169" checked=""/><div class="controls bullet"><span class="by">gsatic</span><span>|</span><a href="#36856682">parent</a><span>|</span><a href="#36857761">next</a><span>|</span><label class="collapse" for="c-36857169">[-]</label><label class="expand" for="c-36857169">[1 more]</label></div><br/><div class="children"><div class="content">Thats the fundamental reason we end up with an Attention Economy - People have limited Attention to pay to everything, But unlimited capacity&#x2F;need to receive Attention (via Michael Goldhaber).<p>This plants the seed for the info explosion (those 200 bikeshedding comments or those 6 billion videos on how to boil an egg).<p>To counter it we have rankings of comments and links and news feeds from google to fb to hn. But its just another layer of bullshit cause most of the pool of what is being ranked is bullshit.<p>We are yet to design Information systems that take into account what Goldhaber said about Attention 3-4 decades ago.</div><br/></div></div><div id="36857761" class="c"><input type="checkbox" id="c-36857761" checked=""/><div class="controls bullet"><span class="by">sheepscreek</span><span>|</span><a href="#36856682">parent</a><span>|</span><a href="#36857169">prev</a><span>|</span><a href="#36852578">next</a><span>|</span><label class="collapse" for="c-36857761">[-]</label><label class="expand" for="c-36857761">[1 more]</label></div><br/><div class="children"><div class="content">For what it’s worth, someone pointed out that PyTorch has an <i>optional</i> workaround for it in the Multihead Attention API. But yes, I had to skip over 200 comments ranting off-topic that was mildly annoying (to me).</div><br/></div></div></div></div><div id="36852578" class="c"><input type="checkbox" id="c-36852578" checked=""/><div class="controls bullet"><span class="by">fwlr</span><span>|</span><a href="#36856682">prev</a><span>|</span><a href="#36852115">next</a><span>|</span><label class="collapse" for="c-36852578">[-]</label><label class="expand" for="c-36852578">[23 more]</label></div><br/><div class="children"><div class="content">The author identifies a real problem and poses a simple solution. It passes all my crank tests (why did no one come up with this before? Because the author is intimately familiar with the softmax function from work outside of ML, and plausibly nobody who’s investigating these issues is remotely as familiar, so despite researchers narrowing the issue down to “something to do with softmax”, they don’t have a deep enough understanding of softmax to see what’s wrong).<p>If the author is reading any of these comments, though, I would urge them to expand on their claim that “I’m 99.44% sure that it will resolve the outlier feedback loop”. As it stands, that’s the only explanation we get of how the outliers might be related to softmax!</div><br/><div id="36853068" class="c"><input type="checkbox" id="c-36853068" checked=""/><div class="controls bullet"><span class="by">sedael</span><span>|</span><a href="#36852578">parent</a><span>|</span><a href="#36852862">next</a><span>|</span><label class="collapse" for="c-36853068">[-]</label><label class="expand" for="c-36853068">[5 more]</label></div><br/><div class="children"><div class="content">&gt;why did no one come up with this before<p>So it turns out someone did. Specifically google did. This <i>exact</i> same idea has been in flaxformers since at least November 2021.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;flaxformer&#x2F;blame&#x2F;ee62754ebe5a5eeb111493622de5537133822e3e&#x2F;flaxformer&#x2F;components&#x2F;attention&#x2F;dense_attention.py#L50">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;flaxformer&#x2F;blame&#x2F;ee62754ebe5a5eeb1...</a><p>Specifically to save people a click it says:<p>&gt; &quot;&quot;&quot;Softmax function with an additional virtual logit equal to zero.<p><pre><code>  For compatibility with some previously trained models.

  This is equivalent to adding one to the denominator.
  In the context of attention, it allows you to attend to nothing.
</code></pre>
And creates the <i>exact</i> same modified softmax as this essay. I suppose only time will tell why it was ignored publicly before, maybe it doesn&#x27;t do much, maybe it just fell through the cracks, maybe google just didnt push it, who knows</div><br/><div id="36853388" class="c"><input type="checkbox" id="c-36853388" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36853068">parent</a><span>|</span><a href="#36857600">prev</a><span>|</span><a href="#36853849">next</a><span>|</span><label class="collapse" for="c-36853388">[-]</label><label class="expand" for="c-36853388">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I suppose only time will tell why it was ignored publicly before, maybe it doesn&#x27;t do much, maybe it just fell through the cracks, maybe google just didnt push it, who knows<p>Maybe quantization wasn&#x27;t as hot back then than it is now?</div><br/><div id="36854826" class="c"><input type="checkbox" id="c-36854826" checked=""/><div class="controls bullet"><span class="by">jablongo</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36853388">parent</a><span>|</span><a href="#36853849">next</a><span>|</span><label class="collapse" for="c-36854826">[-]</label><label class="expand" for="c-36854826">[1 more]</label></div><br/><div class="children"><div class="content">Yea the benefit is not going to come in terms of performance for a given model, but in terms of ability to be efficiently quantized.</div><br/></div></div></div></div><div id="36853849" class="c"><input type="checkbox" id="c-36853849" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36853068">parent</a><span>|</span><a href="#36853388">prev</a><span>|</span><a href="#36852862">next</a><span>|</span><label class="collapse" for="c-36853849">[-]</label><label class="expand" for="c-36853849">[1 more]</label></div><br/><div class="children"><div class="content">Or maybe it doesn’t really do anything to improve performance.</div><br/></div></div></div></div><div id="36852862" class="c"><input type="checkbox" id="c-36852862" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#36852578">parent</a><span>|</span><a href="#36853068">prev</a><span>|</span><a href="#36852954">next</a><span>|</span><label class="collapse" for="c-36852862">[-]</label><label class="expand" for="c-36852862">[14 more]</label></div><br/><div class="children"><div class="content">Yeah, but it lacks the most important test: results. He hasn&#x27;t actually tried it, he just thinks it will work.<p>For such a simple change to the softmax it wouldn&#x27;t take long to verify. It&#x27;s really embarrassing to not do that before publishing.</div><br/><div id="36853165" class="c"><input type="checkbox" id="c-36853165" checked=""/><div class="controls bullet"><span class="by">joebiden2</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36852862">parent</a><span>|</span><a href="#36854086">next</a><span>|</span><label class="collapse" for="c-36853165">[-]</label><label class="expand" for="c-36853165">[11 more]</label></div><br/><div class="children"><div class="content">You seem to really disregard the positions of this author. They seem to have invested substantial efforts in that specific area of research.<p>To validate the idea the author has, it would be required to train a LLM from zero. If the author is right, you would get similar results to the current generation of LLMs, but with (a lot) less space required for the intermediate layers.<p>The time to achieve that is still measured in kilo- to mega-dollars, why is it wrong to put that idea in the open to substantially criticize or adopt?</div><br/><div id="36853216" class="c"><input type="checkbox" id="c-36853216" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36853165">parent</a><span>|</span><a href="#36854086">next</a><span>|</span><label class="collapse" for="c-36853216">[-]</label><label class="expand" for="c-36853216">[10 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need to train a ChatGPT-sized LLM, a toy nanoGPT would have been enough. You can train those on a consumer GPU in an afternoon.<p>And yes I do disregard his research effort. There are hundreds of well-justified and well-researched &quot;clever tricks&quot; for improving Transformers, and almost all of them don&#x27;t work. I&#x27;ll believe it when I see the results.</div><br/><div id="36856374" class="c"><input type="checkbox" id="c-36856374" checked=""/><div class="controls bullet"><span class="by">mikeravkine</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36853216">parent</a><span>|</span><a href="#36855618">next</a><span>|</span><label class="collapse" for="c-36856374">[-]</label><label class="expand" for="c-36856374">[1 more]</label></div><br/><div class="children"><div class="content">Outliers only begin to appear around 3B parameters (as per the original LLM.int8 paper) so unfortunately not consumer GPU in an afternoon kinda stuff to prove you&#x27;ve managed to suppress them.</div><br/></div></div><div id="36855618" class="c"><input type="checkbox" id="c-36855618" checked=""/><div class="controls bullet"><span class="by">Yenrabbit</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36853216">parent</a><span>|</span><a href="#36856374">prev</a><span>|</span><a href="#36853773">next</a><span>|</span><label class="collapse" for="c-36855618">[-]</label><label class="expand" for="c-36855618">[1 more]</label></div><br/><div class="children"><div class="content">I tried to test this with nanoGPT in an afternoon, since the code change is pretty minimal. It&#x27;s hard to get conclusive results at that scale though - to be able to say anything with confidence you&#x27;d need to run multiple tests, figure out if the &#x27;outliers&#x27; mentioned only appear above a certain scale, find good tests for quantization performance that work on small enough models that you can iterate quickly ... It&#x27;s doable but still lots of work, enough that putting out the idea and hoping others with more time+compute will try it out seems a valid strategy to me :)
More generally though I definitely agree that the trend among &#x27;improvements&#x27; to transformers has been things that don&#x27;t turn out to work in practice.</div><br/></div></div><div id="36853773" class="c"><input type="checkbox" id="c-36853773" checked=""/><div class="controls bullet"><span class="by">knewter</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36853216">parent</a><span>|</span><a href="#36855618">prev</a><span>|</span><a href="#36854920">next</a><span>|</span><label class="collapse" for="c-36853773">[-]</label><label class="expand" for="c-36853773">[1 more]</label></div><br/><div class="children"><div class="content">Google used it in flaxformers since 2021 apparently</div><br/></div></div><div id="36854920" class="c"><input type="checkbox" id="c-36854920" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36853216">parent</a><span>|</span><a href="#36853773">prev</a><span>|</span><a href="#36854086">next</a><span>|</span><label class="collapse" for="c-36854920">[-]</label><label class="expand" for="c-36854920">[6 more]</label></div><br/><div class="children"><div class="content">Do you know of handy testing steps? I suppose I could ask ChatGPT, but if someone has a validated &quot;here, this is how you do it&quot; I have a 3090 that I can do it on, but I&#x27;m not keen to debug anything here.</div><br/><div id="36855881" class="c"><input type="checkbox" id="c-36855881" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36854920">parent</a><span>|</span><a href="#36854086">next</a><span>|</span><label class="collapse" for="c-36855881">[-]</label><label class="expand" for="c-36855881">[5 more]</label></div><br/><div class="children"><div class="content">Testing steps (based on thinking about this for 30 seconds - so probably can be improved):<p>Train a Transformer based model with and without the modified Softmax (Suggestions: GPT-2 or nanoGPT)<p>Measure performance - I&#x27;d probably start with Perplexity and see if there is any difference (we&#x27;d expect little difference).<p>Quantize both models with different quantization strategies.<p>Measure the perplexity of the quantized models of different sizes. We&#x27;d expect the performance to drop off quicker for the non-modified model than the modified one if this is working.</div><br/><div id="36856503" class="c"><input type="checkbox" id="c-36856503" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36855881">parent</a><span>|</span><a href="#36856068">next</a><span>|</span><label class="collapse" for="c-36856503">[-]</label><label class="expand" for="c-36856503">[1 more]</label></div><br/><div class="children"><div class="content">In the Qualcomm AI paper linked in this post it turns out they use a similar testing approach:<p>BERT 109M, testing perplexity<p>OPT 125M, testing perplexity<p>ViT 22M, testing on ImageNet top-1.</div><br/></div></div><div id="36856068" class="c"><input type="checkbox" id="c-36856068" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36855881">parent</a><span>|</span><a href="#36856503">prev</a><span>|</span><a href="#36854086">next</a><span>|</span><label class="collapse" for="c-36856068">[-]</label><label class="expand" for="c-36856068">[3 more]</label></div><br/><div class="children"><div class="content">I was thinking about a different problem as I was typing that and got some mental memory alias bug. I wanted to know a set of steps to take to <i>train</i> a model. My apologies.<p>In any case, that was an lmgtfy-level question. Here&#x27;s what I found: <a href="https:&#x2F;&#x2F;til.simonwillison.net&#x2F;llms&#x2F;training-nanogpt-on-my-blog" rel="nofollow noreferrer">https:&#x2F;&#x2F;til.simonwillison.net&#x2F;llms&#x2F;training-nanogpt-on-my-bl...</a><p>I shall try that soon.</div><br/><div id="36856335" class="c"><input type="checkbox" id="c-36856335" checked=""/><div class="controls bullet"><span class="by">mcapodici</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36856068">parent</a><span>|</span><a href="#36854086">next</a><span>|</span><label class="collapse" for="c-36856335">[-]</label><label class="expand" for="c-36856335">[2 more]</label></div><br/><div class="children"><div class="content">Shaaaaameless plug:<p>I did a writeup like this. (Not as nicely as Simon though) where I modal.com (cloud GPU, containers, quick starts, free $30&#x2F;m spend) to use their GPUs (e.g. T4, A100).<p><a href="https:&#x2F;&#x2F;martincapodici.com&#x2F;2023&#x2F;07&#x2F;15&#x2F;no-local-gpu-no-problem-running-andrej-karpathys-nanogpt-on-modal-com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;martincapodici.com&#x2F;2023&#x2F;07&#x2F;15&#x2F;no-local-gpu-no-proble...</a><p>T4 I think was good enough for the job, not much need for the A100.<p>Since this post I am working on an easy way to do this with a script called lob.py that requires no code changes to the nanoGPT repo (or whatever repo you are using) and runs in modal.com. The script exists but gets refined as I use it. Once it is battle tested a bit more I will do a post.<p>(It is named lob.py as it &quot;lobs the code over to the server&quot; where lob is UK slang for throw)<p>Watch this space.</div><br/><div id="36856361" class="c"><input type="checkbox" id="c-36856361" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36856335">parent</a><span>|</span><a href="#36854086">next</a><span>|</span><label class="collapse" for="c-36856361">[-]</label><label class="expand" for="c-36856361">[1 more]</label></div><br/><div class="children"><div class="content">Thank you. FWIW I often find write-up + script superior to script because I often want to modify. e.g. I want to run GPU-only, but other script provide part-way solution when textual description added. Therefore, much appreciated.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36854086" class="c"><input type="checkbox" id="c-36854086" checked=""/><div class="controls bullet"><span class="by">furyofantares</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36852862">parent</a><span>|</span><a href="#36853165">prev</a><span>|</span><a href="#36853038">next</a><span>|</span><label class="collapse" for="c-36854086">[-]</label><label class="expand" for="c-36854086">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a blog post. And it includes a call for help in testing the idea.</div><br/></div></div><div id="36853038" class="c"><input type="checkbox" id="c-36853038" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36852578">root</a><span>|</span><a href="#36852862">parent</a><span>|</span><a href="#36854086">prev</a><span>|</span><a href="#36852954">next</a><span>|</span><label class="collapse" for="c-36853038">[-]</label><label class="expand" for="c-36853038">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not embarrassing at all.<p>I think there might be some curse of the auto-didact here, hinging on the meaning of publish: it would be embarrassing if he was capital-P publishing, as in a scientific paper.<p>The blog goes to great lengths to point out it is _not_ capital-P publishing.</div><br/></div></div></div></div><div id="36852954" class="c"><input type="checkbox" id="c-36852954" checked=""/><div class="controls bullet"><span class="by">tel</span><span>|</span><a href="#36852578">parent</a><span>|</span><a href="#36852862">prev</a><span>|</span><a href="#36852730">next</a><span>|</span><label class="collapse" for="c-36852954">[-]</label><label class="expand" for="c-36852954">[1 more]</label></div><br/><div class="children"><div class="content">&gt; why did no one come up with this before? Because the author is intimately familiar with the softmax function from work outside of ML, and plausibly nobody who’s investigating these issues is remotely as familiar<p>I doubt that is true. Softmax is extremely well understood within the ML community. It&#x27;s a very common trick, these properties are well-known as well. It feels very unlikely that nobody has thought of this before. That said, it&#x27;s also plausible that the current softmax convention was chosen by accident and the author is right to identify this drawback.</div><br/></div></div><div id="36852730" class="c"><input type="checkbox" id="c-36852730" checked=""/><div class="controls bullet"><span class="by">Majromax</span><span>|</span><a href="#36852578">parent</a><span>|</span><a href="#36852954">prev</a><span>|</span><a href="#36854184">next</a><span>|</span><label class="collapse" for="c-36852730">[-]</label><label class="expand" for="c-36852730">[1 more]</label></div><br/><div class="children"><div class="content">&gt; why did no one come up with this before?<p>And because the effects of the problem are subtle.  Supposing the diagnosis is correct, full-precision LLMs still avoid the issue through large attention weights given to meaningless tokens to give harmless attention outputs.  The problem only matters when quantizing weights, and quantized performance isn&#x27;t really the goal of recent cutting-edge LLM development.</div><br/></div></div><div id="36854184" class="c"><input type="checkbox" id="c-36854184" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36852578">parent</a><span>|</span><a href="#36852730">prev</a><span>|</span><a href="#36852115">next</a><span>|</span><label class="collapse" for="c-36854184">[-]</label><label class="expand" for="c-36854184">[1 more]</label></div><br/><div class="children"><div class="content">I interpreted it as cracking a joke about miscalibrated probs in softmax, it tends to be 99.9% sure, or 0.1%, but little in-between.</div><br/></div></div></div></div><div id="36852115" class="c"><input type="checkbox" id="c-36852115" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#36852578">prev</a><span>|</span><a href="#36855637">next</a><span>|</span><label class="collapse" for="c-36852115">[-]</label><label class="expand" for="c-36852115">[12 more]</label></div><br/><div class="children"><div class="content">I ran an experiment like this and in my setting it didn&#x27;t help. Not saying there may not have been a bug or something, but I think attending over the current position sort of solves this problem. IE when it should not speak it just emits the current pos value.<p>edit to add details in case anyone is interested<p>I didn&#x27;t add one to the softmax denom. I added a learned parameter (the attention sink) that would be appended to the beginning of QK but would be removed after softmax, so when multiplying by V the totals wouldn&#x27;t sum to one. I tried variants that included looking at the current pos and not, and also variants that predicted used an ffn to generate the  sink per position instead of a learned param. In my setting neither approach really made much of a difference. But I also had a bunch of other weird stuff in there too, so it may be worth trying again.</div><br/><div id="36852501" class="c"><input type="checkbox" id="c-36852501" checked=""/><div class="controls bullet"><span class="by">abeppu</span><span>|</span><a href="#36852115">parent</a><span>|</span><a href="#36853542">next</a><span>|</span><label class="collapse" for="c-36852501">[-]</label><label class="expand" for="c-36852501">[5 more]</label></div><br/><div class="children"><div class="content">When you say it didn&#x27;t help, can you clarify what you&#x27;re measuring? In the context of this post, I think both the performance your task, and the number of outlier weights (and their magnitude) are important.</div><br/><div id="36852548" class="c"><input type="checkbox" id="c-36852548" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#36852115">root</a><span>|</span><a href="#36852501">parent</a><span>|</span><a href="#36853542">next</a><span>|</span><label class="collapse" for="c-36852548">[-]</label><label class="expand" for="c-36852548">[4 more]</label></div><br/><div class="children"><div class="content">I was just looking at doing this in pretraining, so I was looking at pretraining losses. The difference was within the range of usual noise so I didn&#x27;t keep trying.</div><br/><div id="36852720" class="c"><input type="checkbox" id="c-36852720" checked=""/><div class="controls bullet"><span class="by">lucidrains</span><span>|</span><a href="#36852115">root</a><span>|</span><a href="#36852548">parent</a><span>|</span><a href="#36853523">next</a><span>|</span><label class="collapse" for="c-36852720">[-]</label><label class="expand" for="c-36852720">[2 more]</label></div><br/><div class="children"><div class="content">this is fixing a different issue, not the one you are measuring.</div><br/><div id="36852848" class="c"><input type="checkbox" id="c-36852848" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#36852115">root</a><span>|</span><a href="#36852720">parent</a><span>|</span><a href="#36853523">next</a><span>|</span><label class="collapse" for="c-36852848">[-]</label><label class="expand" for="c-36852848">[1 more]</label></div><br/><div class="children"><div class="content">It wasn&#x27;t really the goal of my experiment to fix this issue for sure, I was trying to see if you could improve attention by decoupling the key used by a position for itself and for future tokens.<p>Open to being wrong here, but wouldn&#x27;t it be functionally similar to adding a constant to the softmax denom? the function could sort of learn a specific position to have sink and q multiply to one, then removing it before multipling with v would be exactly identical?</div><br/></div></div></div></div><div id="36853523" class="c"><input type="checkbox" id="c-36853523" checked=""/><div class="controls bullet"><span class="by">waynecochran</span><span>|</span><a href="#36852115">root</a><span>|</span><a href="#36852548">parent</a><span>|</span><a href="#36852720">prev</a><span>|</span><a href="#36853542">next</a><span>|</span><label class="collapse" for="c-36853523">[-]</label><label class="expand" for="c-36853523">[1 more]</label></div><br/><div class="children"><div class="content">The question concerns outliers ... how did the change manage them?</div><br/></div></div></div></div></div></div><div id="36853542" class="c"><input type="checkbox" id="c-36853542" checked=""/><div class="controls bullet"><span class="by">gwern</span><span>|</span><a href="#36852115">parent</a><span>|</span><a href="#36852501">prev</a><span>|</span><a href="#36853674">next</a><span>|</span><label class="collapse" for="c-36853542">[-]</label><label class="expand" for="c-36853542">[5 more]</label></div><br/><div class="children"><div class="content">He&#x27;s advertising it as fixing the spiking outliers. Did your variant have those outliers beforehand?</div><br/><div id="36853679" class="c"><input type="checkbox" id="c-36853679" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#36852115">root</a><span>|</span><a href="#36853542">parent</a><span>|</span><a href="#36853674">next</a><span>|</span><label class="collapse" for="c-36853679">[-]</label><label class="expand" for="c-36853679">[4 more]</label></div><br/><div class="children"><div class="content">I guess yeah I was mostly responding to<p><i>Now it’s possible that softmax should be replaced wholesale, but it’s worked pretty well for the most part, except for this one wee little bug that prevents attention heads from saying nothing. So I propose a very small tweak on which I am willing to stake all future Internet claims to being correct. The tweak is so small, yet so obvious, and it’s been sitting here under everyone’s noses ever since attention was invented (2014).</i><p>I didn&#x27;t test for outliers, but I don&#x27;t think this will lead to a large improvement in attention overall&#x2F;it will fix a lurking bug.</div><br/><div id="36854694" class="c"><input type="checkbox" id="c-36854694" checked=""/><div class="controls bullet"><span class="by">zackangelo</span><span>|</span><a href="#36852115">root</a><span>|</span><a href="#36853679">parent</a><span>|</span><a href="#36853674">next</a><span>|</span><label class="collapse" for="c-36854694">[-]</label><label class="expand" for="c-36854694">[3 more]</label></div><br/><div class="children"><div class="content">He’s not trying or claiming to improve attention. He’s trying to reduce outliers to improve the ability to quantize the parameters.</div><br/><div id="36855020" class="c"><input type="checkbox" id="c-36855020" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#36852115">root</a><span>|</span><a href="#36854694">parent</a><span>|</span><a href="#36853674">next</a><span>|</span><label class="collapse" for="c-36855020">[-]</label><label class="expand" for="c-36855020">[2 more]</label></div><br/><div class="children"><div class="content">He refers all over the blog post to an &quot;error&quot; in attention. specifically says<p><i>The problem with using softmax is that it forces each attention head to make an annotation, even if it has no information to add to the output vector. Using softmax to choose among discrete alternatives is great; using it for optional annotation (i.e. as input into addition) is, like, not cool, man.</i><p>I&#x27;m saying it uses the current position to do this, that if it was a significant error I would expect it to improve the training loss. I sort of interpreted the blog post as being a bit more positive on the idea than just being about improving the quantization</div><br/><div id="36856990" class="c"><input type="checkbox" id="c-36856990" checked=""/><div class="controls bullet"><span class="by">lyjackal</span><span>|</span><a href="#36852115">root</a><span>|</span><a href="#36855020">parent</a><span>|</span><a href="#36853674">next</a><span>|</span><label class="collapse" for="c-36856990">[-]</label><label class="expand" for="c-36856990">[1 more]</label></div><br/><div class="children"><div class="content">I agree that he used the term error somewhat incorrectly. But he seems mainly to just be making the point that sumac introduces a large outlier which in turn is only now an issue that the community is now aggressively trying to quantize models</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36855637" class="c"><input type="checkbox" id="c-36855637" checked=""/><div class="controls bullet"><span class="by">Q6T46nT668w6i3m</span><span>|</span><a href="#36852115">prev</a><span>|</span><a href="#36852249">next</a><span>|</span><label class="collapse" for="c-36855637">[-]</label><label class="expand" for="c-36855637">[3 more]</label></div><br/><div class="children"><div class="content">This method was frequently used prior to the ubiquity of dummy tokens. XLNet was the paper that introduced me to this idea. I believe it’s been in PyTorch since 2019&#x2F;2020. I would not be surprised if someone finds an earlier reference.<p>I’m surprised by the pompousness in the OP. Especially about something that most people who do transformer research understand. I’m also surprised that so many in the replies are taking the position of “this is what research should look like” when this is clearly an example of why research doesn’t work like this. Peer review is good for many things and one of those things is saving yourself some embarrassment.</div><br/><div id="36859444" class="c"><input type="checkbox" id="c-36859444" checked=""/><div class="controls bullet"><span class="by">klabb3</span><span>|</span><a href="#36855637">parent</a><span>|</span><a href="#36855870">next</a><span>|</span><label class="collapse" for="c-36859444">[-]</label><label class="expand" for="c-36859444">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I’m surprised by the pompousness in the OP.<p>He’s writing in a colloquial and self-deprecating and humorous tone. I can’t speak to the merits, but I can follow the reasoning perfectly fine. It’d be hard to find something further from pompous.<p>&gt; saving yourself some embarrassment<p>Implying of course that being wrong, or not the first one to discover this, is embarrassing. And that’s <i>not</i> pompous?</div><br/></div></div><div id="36855870" class="c"><input type="checkbox" id="c-36855870" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36855637">parent</a><span>|</span><a href="#36859444">prev</a><span>|</span><a href="#36852249">next</a><span>|</span><label class="collapse" for="c-36855870">[-]</label><label class="expand" for="c-36855870">[1 more]</label></div><br/><div class="children"><div class="content">He&#x27;s not being pompous, people appreciate the informality and straightforwardness and self-deprecation, which are the opposite of pompus.<p>You are reading some of the more ambiguous self-deprecation as genuine claims.<p>TL;DR on why this is important and he&#x27;s sharing: it&#x27;s a sort of niche thing that really only matters if you&#x27;re trying to run pale imitations of ChatGPT on constrained hardware. That&#x27;s why it&#x27;s entirely possible the big guns didn&#x27;t see it as important, they&#x27;re not trying to run LLMs on a 3090</div><br/></div></div></div></div><div id="36852249" class="c"><input type="checkbox" id="c-36852249" checked=""/><div class="controls bullet"><span class="by">sunleash</span><span>|</span><a href="#36855637">prev</a><span>|</span><a href="#36859223">next</a><span>|</span><label class="collapse" for="c-36852249">[-]</label><label class="expand" for="c-36852249">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see any results, it&#x27;d be more impactful and convincing if there were numbers supplementing the theory. It&#x27;s not that hard to finetune existing LM on a small data and verify that it works.<p>I am, however, of the similar opinion that there could be better attention formulations. A paper from 2020 <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2005.09561" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2005.09561</a> helped a lot in one of the transformers model I trained (not a vanilla LM but a specialised multi-modal graph problem).<p>It proposes normalised attention which if I&#x27;m not wrong should help with the quantisation problem too.</div><br/></div></div><div id="36859223" class="c"><input type="checkbox" id="c-36859223" checked=""/><div class="controls bullet"><span class="by">justanotherjoe</span><span>|</span><a href="#36852249">prev</a><span>|</span><a href="#36859473">next</a><span>|</span><label class="collapse" for="c-36859223">[-]</label><label class="expand" for="c-36859223">[1 more]</label></div><br/><div class="children"><div class="content">Like others have said i think this might already been explored.  However, I like the view that you have to let the machine to be able to &#x27;do nothing&#x27;.  Which is what resnet was first for.  But i&#x27;m willing to bet this so called wisdom can still be squeezed for performance, because people tend to not think about it.</div><br/></div></div><div id="36857213" class="c"><input type="checkbox" id="c-36857213" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#36859473">prev</a><span>|</span><a href="#36858481">next</a><span>|</span><label class="collapse" for="c-36857213">[-]</label><label class="expand" for="c-36857213">[1 more]</label></div><br/><div class="children"><div class="content">If I followed this correctly and didn’t mess up my indices, adding 1 to the softmax denominator is exactly equivalent to appending an extra zero to the softmax input (effectively casting an exp(0) vote for a new null option) and appending an extra  row of zeros to V (so the null option is all zeros).<p>The latter seems like something training could figure out by itself (zero doesn’t seem like a hard place to land with the weights producing V, although a bunch of zero weights would be needed), but the former is a bit awkward, as QK^T is quadratic in the weights.<p>In any case, this seems intuitively quite reasonable. But I do wonder whether the 1 in the denominator (equivalent to an exp(0) vote) is the best choice if the goal is to quantize well.  0 is in the middle of the numerical range, and perhaps the implicit null vote should be weighted lower than the middle of the range.</div><br/></div></div><div id="36858481" class="c"><input type="checkbox" id="c-36858481" checked=""/><div class="controls bullet"><span class="by">kylegalbraith</span><span>|</span><a href="#36857213">prev</a><span>|</span><a href="#36852764">next</a><span>|</span><label class="collapse" for="c-36858481">[-]</label><label class="expand" for="c-36858481">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not an expert in whether this technique yields better or worse results. But it seems plausible that the proposal would yield a reduction in memory requirements and thus beneficial.<p>But in terms of a written piece of technical content, this is brilliantly written. Easy to follow and stay engaged. Well done.</div><br/></div></div><div id="36852764" class="c"><input type="checkbox" id="c-36852764" checked=""/><div class="controls bullet"><span class="by">blueblimp</span><span>|</span><a href="#36858481">prev</a><span>|</span><a href="#36852187">next</a><span>|</span><label class="collapse" for="c-36852764">[-]</label><label class="expand" for="c-36852764">[2 more]</label></div><br/><div class="children"><div class="content">The proposed replacement definitely makes more sense (and I&#x27;ve always found the absence of a &quot;failed query&quot; to be puzzling in standard attention), but, in deep learning, things that make more sense don&#x27;t always actually get better results. So I&#x27;m curious whether this has been tried and carefully evaluated.</div><br/><div id="36852884" class="c"><input type="checkbox" id="c-36852884" checked=""/><div class="controls bullet"><span class="by">jadbox</span><span>|</span><a href="#36852764">parent</a><span>|</span><a href="#36852187">next</a><span>|</span><label class="collapse" for="c-36852884">[-]</label><label class="expand" for="c-36852884">[1 more]</label></div><br/><div class="children"><div class="content">It would be an amusing find if &quot;Black Swan mega-activations&quot; actually but yet unintentionally made the model smarter...</div><br/></div></div></div></div><div id="36852187" class="c"><input type="checkbox" id="c-36852187" checked=""/><div class="controls bullet"><span class="by">mlsu</span><span>|</span><a href="#36852764">prev</a><span>|</span><a href="#36853497">next</a><span>|</span><label class="collapse" for="c-36852187">[-]</label><label class="expand" for="c-36852187">[93 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really understand the subject matter enough, so I apologize in advance for the meta-comment...<p>The author mentions that he would maybe have written this as a scientific paper:<p>&gt; I tried writing a serious-looking research paper about the bug and my proposed fix, but I lost a series of pitched battles against Pytorch and biblatex, so I figured I’d just write a blog post instead. (History is written by the winners; blogs are written by…)<p>Honestly, thank god he didn&#x27;t. This paper is so much more readable and approachable than what gets published in &quot;serious&quot; journals. The tone is self-effacing, it does not have an &quot;ego&quot; the way scientific papers tend to have. If all science read like this, and if we were &quot;allowed&quot; to cite research that reads like this, I think we would be much better off. This reads like a conversational, approachable textbook, not like an impenetrable wall.<p>Is it because I don&#x27;t understand attention at a PhD level that I hold this opinion? Maybe. Could he be writing like this because he&#x27;s a layman and utterly wrong about the topic, unlike those Serious Science Authors? Maybe, I don&#x27;t know.<p>But my god, wouldn&#x27;t it be nice to be allowed to write like this?</div><br/><div id="36852654" class="c"><input type="checkbox" id="c-36852654" checked=""/><div class="controls bullet"><span class="by">doliveira</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36852258">next</a><span>|</span><label class="collapse" for="c-36852654">[-]</label><label class="expand" for="c-36852654">[48 more]</label></div><br/><div class="children"><div class="content">Nah, scientific papers are supposed to be precise and technical. This reads like those quite frequent suggestions here of switching all equations in papers to plain English or code: it honestly comes from a place of ignorance, and I say that as basically a layman myself.<p>What should be encouraged is for academics to blog about their research as well. It would even help when recruiting and onboarding new members. Right now the sociological and economical incentives don&#x27;t promote this at all.</div><br/><div id="36852957" class="c"><input type="checkbox" id="c-36852957" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36855045">next</a><span>|</span><label class="collapse" for="c-36852957">[-]</label><label class="expand" for="c-36852957">[24 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    There was this sociologist who had written a paper for us all to read ahead of time. I started to read the damn thing, and my eyes were coming out: I couldn’t make head nor tail of it! I figured it was because I hadn’t read any of the books on the list. I had this uneasy feeling of “I’m not adequate,” until finally I said to myself “I’m gonna stop, and read one sentence slowly so I can figure out what the hell it means.”
    
    So I stopped-at random-and read the next sentence very carefully. I can’t remember it precisely, but it was very close to this: “The individual member of the social community often receives his information via visual, symbolic channels.” I went back and forth over it, and translated. You know what it means? “People read.”
    
    Then I went over the next sentence, and realised that I could translate that one also. Then it became a kind of empty business: “Sometimes people read; sometimes people listen to the radio,” and so on, but written in such a fancy way that I couldn’t understand it at first, and when I finally deciphered it, there was nothing to it.

  -- Feynman
</code></pre>
I disagree. After going through quite a few research papers in my time, I&#x27;ve found the best are the ones that are direct and to the point. Many papers I&#x27;ve spent many hours&#x2F;days trying to unravel just to realize the concepts were straightforward, not very novel, and there wasn&#x27;t much of real substance to the paper.<p>Meanwhile, some of the most impactful papers I&#x27;ve read are direct and to the point. Kadmellia, Bitcoin, BitTorrent, DynamoDB, Firecracker, etc.<p>It seems like, when you have something of substance to say, you say it. When you don&#x27;t you overcompensate by falling back on building an intricate puzzle of jargon and convoluted equations in an attempt to make what you&#x27;re saying sound far more important than it really is.<p>As LLMs get better, I look forward to the day where every journal has a standard LLM filter you&#x27;re required to apply to your paper that unravels all of this nonsense and rewrites it a more straightforward way, if not to directly publish than just for the editors to verify there isn&#x27;t a simpler way to convey your ideas. I suspect that if we had an EIL5 filter for most journal articles, we&#x27;d discover that a majority of the words that get published have very little substance at all.</div><br/><div id="36853244" class="c"><input type="checkbox" id="c-36853244" checked=""/><div class="controls bullet"><span class="by">Vervious</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852957">parent</a><span>|</span><a href="#36857258">next</a><span>|</span><label class="collapse" for="c-36853244">[-]</label><label class="expand" for="c-36853244">[9 more]</label></div><br/><div class="children"><div class="content">Systems research papers do not represent all research papers out there, not even in computer science.<p>In cryptography, certainly a paper with formal definitions and proofs can be much more valuable than a corresponding blog post. It&#x27;s a field where formalism is desired, if not necessary. Otherwise you can&#x27;t check other people&#x27;s &quot;proofs&quot;, or even know what model you&#x27;re working in.<p>I think, since people haven&#x27;t come up with better formalisms, sometimes it&#x27;s quite obtuse, which gets mistaken as &quot;academic writing&quot;, when really it&#x27;s a best effort to formalize.</div><br/><div id="36853391" class="c"><input type="checkbox" id="c-36853391" checked=""/><div class="controls bullet"><span class="by">renonce</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853244">parent</a><span>|</span><a href="#36857821">next</a><span>|</span><label class="collapse" for="c-36853391">[-]</label><label class="expand" for="c-36853391">[7 more]</label></div><br/><div class="children"><div class="content">Requiring formalism does not preclude attaching an informal but intuitional description of the formal definition or proof. Unless the authors don&#x27;t understand very clearly what they are talking about, or they want to prevent others from understanding their concepts too easily, I don&#x27;t see why there is a reason for the authors not to attach an EIL5 in addition to formalism.</div><br/><div id="36853763" class="c"><input type="checkbox" id="c-36853763" checked=""/><div class="controls bullet"><span class="by">Vervious</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853391">parent</a><span>|</span><a href="#36853806">next</a><span>|</span><label class="collapse" for="c-36853763">[-]</label><label class="expand" for="c-36853763">[5 more]</label></div><br/><div class="children"><div class="content">Sure. But it&#x27;s an ELI5 &quot;in addition to formalism&quot;, not &quot;in lieu of formalism&quot;. In theory conferences like STOC or FOCS, the first section of the paper often comprises such an overview.<p>Certainly some papers are better written than others. But sometimes a blog post cannot replace a paper, unless it also goes into the depth and detail that formalism requires. (Then it becomes a 30 page blog post, where most people don&#x27;t read past the intro.)</div><br/><div id="36854793" class="c"><input type="checkbox" id="c-36854793" checked=""/><div class="controls bullet"><span class="by">acchow</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853763">parent</a><span>|</span><a href="#36853806">next</a><span>|</span><label class="collapse" for="c-36854793">[-]</label><label class="expand" for="c-36854793">[4 more]</label></div><br/><div class="children"><div class="content">The complaint about research papers is that almost all of them omit the ELI5 and provide <i>only</i> the formalism.<p>You can have both and weave them together into a digestible narrative. I see Physics textbooks sometimes written this way.</div><br/><div id="36855137" class="c"><input type="checkbox" id="c-36855137" checked=""/><div class="controls bullet"><span class="by">smallnamespace</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854793">parent</a><span>|</span><a href="#36853806">next</a><span>|</span><label class="collapse" for="c-36855137">[-]</label><label class="expand" for="c-36855137">[3 more]</label></div><br/><div class="children"><div class="content">Papers are mostly read by other researchers, where the added background is actively bad because it obscures the real meat of the paper to the main audience.<p>If you just wanted a digestible intro then you would usually buy a textbook.<p>I think the argument that <i>every</i> research paper ought to be a mashup of a textbook + the actual research to be a bit silly from a “people should specialize at what they’re good at” standpoint.<p>Put in another context, I also don’t want every recipe to reintroduce what it means to “fry” or “braise” or “marinate”. We have Google for that.</div><br/><div id="36856573" class="c"><input type="checkbox" id="c-36856573" checked=""/><div class="controls bullet"><span class="by">RationPhantoms</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855137">parent</a><span>|</span><a href="#36853806">next</a><span>|</span><label class="collapse" for="c-36856573">[-]</label><label class="expand" for="c-36856573">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve long wanted an informational slider to bits of text. Something where you can zoom in and out to the level of desired complexity. LLM&#x27;s might be able to fill in some of those gaps. You could turn any paper into a introduction of the subject it&#x27;s a part of.</div><br/><div id="36857528" class="c"><input type="checkbox" id="c-36857528" checked=""/><div class="controls bullet"><span class="by">tonypace</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36856573">parent</a><span>|</span><a href="#36853806">next</a><span>|</span><label class="collapse" for="c-36857528">[-]</label><label class="expand" for="c-36857528">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like a good use case for local llm models. Browser plugin, precooked prompts for different levels of detail, maybe a lora to give the model some idea of expected output. I bet some of the 13b models could do a useful job on this even if they were imperfect.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36857821" class="c"><input type="checkbox" id="c-36857821" checked=""/><div class="controls bullet"><span class="by">gbro3n</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853244">parent</a><span>|</span><a href="#36853391">prev</a><span>|</span><a href="#36857258">next</a><span>|</span><label class="collapse" for="c-36857821">[-]</label><label class="expand" for="c-36857821">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know that much about AI, but my experience in other areas has shown me that &#x27;more grown up&#x27; literature that feels harder to parse when your starting out later becomes the precise technical information you need as you get deeper into a subject. Like W3Schools when you start out in web dev vs MDN when you&#x27;re skills are more mature.</div><br/></div></div></div></div><div id="36857258" class="c"><input type="checkbox" id="c-36857258" checked=""/><div class="controls bullet"><span class="by">npsomaratna</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852957">parent</a><span>|</span><a href="#36853244">prev</a><span>|</span><a href="#36853316">next</a><span>|</span><label class="collapse" for="c-36857258">[-]</label><label class="expand" for="c-36857258">[1 more]</label></div><br/><div class="children"><div class="content">Not an academic here, but I&#x27;ve read (and continue to read) through research papers regularly.<p>The original bitcoin paper is a great example. I was able to follow the paper almost fully at my first read itself—despite my not having a formal background in maths.<p>...and as you said, many of the insubstantial papers hide behind jargon and unnecessarily complex equations, just to camouflage their lack of substance. It&#x27;s frustrating to spend time deciphering a paper, only to realize that you&#x27;ve essentially wasted that time.</div><br/></div></div><div id="36853316" class="c"><input type="checkbox" id="c-36853316" checked=""/><div class="controls bullet"><span class="by">lamontcg</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852957">parent</a><span>|</span><a href="#36857258">prev</a><span>|</span><a href="#36854547">next</a><span>|</span><label class="collapse" for="c-36853316">[-]</label><label class="expand" for="c-36853316">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It seems like, when you have something of substance to say, you say it.<p>And this blog post probably could be condensed into 1&#x2F;4 of its size or less with a less conversational&#x2F;bloggy tone.</div><br/><div id="36854947" class="c"><input type="checkbox" id="c-36854947" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853316">parent</a><span>|</span><a href="#36854547">next</a><span>|</span><label class="collapse" for="c-36854947">[-]</label><label class="expand" for="c-36854947">[2 more]</label></div><br/><div class="children"><div class="content">There are words that are added to drive the point in multiple ways, ease into it, and make the text more engaging.<p>And there are words that are added to add empty padding, keep up academic pretenses, and appear smart.<p>The post could have been condensed, but it would lose the former, not the latter.</div><br/><div id="36856777" class="c"><input type="checkbox" id="c-36856777" checked=""/><div class="controls bullet"><span class="by">ticviking</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854947">parent</a><span>|</span><a href="#36854547">next</a><span>|</span><label class="collapse" for="c-36856777">[-]</label><label class="expand" for="c-36856777">[1 more]</label></div><br/><div class="children"><div class="content">Good rhetoric takes time and energy from both the author and reader</div><br/></div></div></div></div></div></div><div id="36854547" class="c"><input type="checkbox" id="c-36854547" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852957">parent</a><span>|</span><a href="#36853316">prev</a><span>|</span><a href="#36856636">next</a><span>|</span><label class="collapse" for="c-36854547">[-]</label><label class="expand" for="c-36854547">[4 more]</label></div><br/><div class="children"><div class="content">I hadn&#x27;t seen that Feynman quote before, but I discovered then when reading Donna Harraway&#x27;s books (Cyborg Manifesto, Modest_Witness@Second_Millennium.FemaleMan©Meets_OncoMouse, Primate Visions).<p>The criticism was &quot;&quot;&quot;Haraway&#x27;s work has been criticized for being &quot;methodologically vague&quot;[39] and using noticeably opaque language that is &quot;sometimes concealing in an apparently deliberate way&quot;&quot;&quot;&quot;</div><br/><div id="36854935" class="c"><input type="checkbox" id="c-36854935" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854547">parent</a><span>|</span><a href="#36856636">next</a><span>|</span><label class="collapse" for="c-36854935">[-]</label><label class="expand" for="c-36854935">[3 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Haraway&#x27;s work has been criticized for being &quot;methodologically vague&quot;[39] and using noticeably opaque language that is &quot;sometimes concealing in an apparently deliberate way</i><p>So you&#x27;re saying that &quot;Her work is basically handwaving and bullshitting&quot;.</div><br/><div id="36855075" class="c"><input type="checkbox" id="c-36855075" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854935">parent</a><span>|</span><a href="#36856636">next</a><span>|</span><label class="collapse" for="c-36855075">[-]</label><label class="expand" for="c-36855075">[2 more]</label></div><br/><div class="children"><div class="content">Yes, but also, wrapping the handwaving and bullshitting in a layer of obfuscation:<p>&quot;Michel Foucault’s biopolitics is a faccid premonition of cyborg politics, a very open feld.
By the late twentieth century, our time, a mythic time, we
are all chimeras, theorized and fabricated hybrids of machine
and organism—in short, cyborgs. The cyborg is our ontology; it
gives us our politics. The cyborg is a condensed image of both
imagination and material reality, the two joined centers structuring any possibility of historical transformation. In the traditions of “Western” science and politics—the tradition of racist,
male-dominant capitalism; the tradition of progress; the tradition of the appropriation of nature as resource for the productions of culture; the tradition of reproduction of the self from
the refections of the other—the relation between organism
and machine has been a border war&quot;<p>(donna was woke before woke was a thing)</div><br/><div id="36857527" class="c"><input type="checkbox" id="c-36857527" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855075">parent</a><span>|</span><a href="#36856636">next</a><span>|</span><label class="collapse" for="c-36857527">[-]</label><label class="expand" for="c-36857527">[1 more]</label></div><br/><div class="children"><div class="content">&gt; (donna was woke before woke was a thing)<p>Donna Haraway was <i>born</i> 6 years after “stay woke” in its sense as an admonition to maintain alertness to the racist context was coined. Leaving aside a debate over whether her work is a good match for “woke”, she very much cannot have been woke before woke was a thing. (Before its recent replacement of “politically correct” as the American Right’s preferred, meaning-stripped, label for everything it disagrees with, sure, but “woke” was a thing <i>long</i> before that.)</div><br/></div></div></div></div></div></div></div></div><div id="36856636" class="c"><input type="checkbox" id="c-36856636" checked=""/><div class="controls bullet"><span class="by">darepublic</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852957">parent</a><span>|</span><a href="#36854547">prev</a><span>|</span><a href="#36856369">next</a><span>|</span><label class="collapse" for="c-36856636">[-]</label><label class="expand" for="c-36856636">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I disagree. After going through quite a few research papers in my time, I&#x27;ve found the best are the ones that are direct and to the point. Many papers I&#x27;ve spent many hours&#x2F;days trying to unravel just to realize the concepts were straightforward, not very novel, and there wasn&#x27;t much of real substance to the paper.<p>Can say the same thing about code.  Some people just honestly don&#x27;t want to give away how simple the core logic is seemingly, and will lead you through myriad twists and turns to finally see the point.</div><br/></div></div><div id="36856369" class="c"><input type="checkbox" id="c-36856369" checked=""/><div class="controls bullet"><span class="by">squarepizza</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852957">parent</a><span>|</span><a href="#36856636">prev</a><span>|</span><a href="#36854084">next</a><span>|</span><label class="collapse" for="c-36856369">[-]</label><label class="expand" for="c-36856369">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There was this <i>sociologist</i><p>Found the problem.</div><br/></div></div><div id="36854084" class="c"><input type="checkbox" id="c-36854084" checked=""/><div class="controls bullet"><span class="by">cratermoon</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852957">parent</a><span>|</span><a href="#36856369">prev</a><span>|</span><a href="#36855045">next</a><span>|</span><label class="collapse" for="c-36854084">[-]</label><label class="expand" for="c-36854084">[4 more]</label></div><br/><div class="children"><div class="content">I believe Feynman understood that he was oversimplifying, and I believe he was able to do because his reason for reading the paper was not the same as the reason another sociologist might have.  Thus a sentence like, &quot;The individual member of the social community often receives his information via visual, symbolic channels&quot;, does, to a non-expert, mean &quot;people read&quot;, but to another sociologist of a researcher in related fields, phrases like &quot;individual member&quot;, &quot;social community&quot;, and &quot;visual, symbolic channels&quot; would <i>terms of art</i>. That means an expert in the field could read &quot;social community&quot; and it would mean, cognitively, an entire set of concepts in the field.<p>In short, jargon matters. People here can talk about functional, procedural, and object-oriented programming because each of the three words has more than just the dictionary meaning - to those of use in the field. In the same way we can talk about linear algebra and know it doesn&#x27;t mean &quot;algebra on lines&quot;.<p>Yes, it&#x27;s <i>possible</i> to write scientifically without jargon and wordiness, but it&#x27;s a lot of effort and takes much more space to say &quot;a group who follow a social structure within a society (culture, norms, values, status). They may work together to organise social life within a particular place, or they may be bound by a sense of belonging sustained across time and space&quot;[1]<p>1 <a href="https:&#x2F;&#x2F;othersociologist.com&#x2F;2013&#x2F;11&#x2F;20&#x2F;sociology-of-community&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;othersociologist.com&#x2F;2013&#x2F;11&#x2F;20&#x2F;sociology-of-communi...</a></div><br/><div id="36854991" class="c"><input type="checkbox" id="c-36854991" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854084">parent</a><span>|</span><a href="#36857531">next</a><span>|</span><label class="collapse" for="c-36854991">[-]</label><label class="expand" for="c-36854991">[2 more]</label></div><br/><div class="children"><div class="content">Well, maybe, but you can rationalize arbitrary amounts of pointless jargon that way.<p>Besides, in the example Faynman gives the simple sentence is actually <i>shorter</i>. Maybe that shorter sentence loses some information that the jargon carried, but Occam&#x27;s razor suggests the writer was just trying to sound smarter.</div><br/><div id="36856280" class="c"><input type="checkbox" id="c-36856280" checked=""/><div class="controls bullet"><span class="by">mattkrause</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854991">parent</a><span>|</span><a href="#36857531">next</a><span>|</span><label class="collapse" for="c-36856280">[-]</label><label class="expand" for="c-36856280">[1 more]</label></div><br/><div class="children"><div class="content">Some bad writing certainly comes from trying to sound “academic” or “scholarly” but there’s more to it than that.<p>A lot of research involves lumping and splitting: what underlying properties do these seemingly-different share (or vice versa). For example, reading text is just one possible instantiation of a “visual symbolic channel.” Traffic lights, road signs, gauges and dials, logos, and clocks also carry information the same way. If you want to discuss “reading and reading-like activities”, you may want some kind of umbrella term.<p>Plus, you may want to contrast them with other ways of sharing information: non-symbolic systems that literally depict the item in question (photos on a picture menu, for example) or using a different sense altogether, like church bells for telling time.</div><br/></div></div></div></div><div id="36857531" class="c"><input type="checkbox" id="c-36857531" checked=""/><div class="controls bullet"><span class="by">chefandy</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854084">parent</a><span>|</span><a href="#36854991">prev</a><span>|</span><a href="#36855045">next</a><span>|</span><label class="collapse" for="c-36857531">[-]</label><label class="expand" for="c-36857531">[1 more]</label></div><br/><div class="children"><div class="content">Visual symbols could be anything from written words to police uniforms. It&#x27;s not oversimplifying— it&#x27;s flat-out wrong. It would be like reading<p><i>Expressions representing numbers may be combined with an expression representing a primitive procedure (such as + or *) to form a compound expression that represents the application of the procedure to those numbers.</i><p>And an English professor haughtily responding, &quot;you know what that means? &#x27;Computers compute!&#x27; This SICP book is just a pile of jargon that could be dramatically simplified!&quot;<p>His dismissal revealed nothing about the topic, but a whole lot about how so many in the <i>&quot;hard&quot; </i> sciences view others. Don&#x27;t understand the text? It&#x27;s the text&#x27;s fault! For <i>I</i> am a <i>real scientist,</i> and if I don&#x27;t understand it, it&#x27;s not understandable!<p>He might have been a genius, but he should have stuck to subatomic particles and left exploring human behavior up to the people who&#x27;d done the prerequisite reading.</div><br/></div></div></div></div></div></div><div id="36855045" class="c"><input type="checkbox" id="c-36855045" checked=""/><div class="controls bullet"><span class="by">karaterobot</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36852957">prev</a><span>|</span><a href="#36859549">next</a><span>|</span><label class="collapse" for="c-36855045">[-]</label><label class="expand" for="c-36855045">[8 more]</label></div><br/><div class="children"><div class="content">The writing quality of academic papers is very poor, whatever its intended characteristics are, and we deserve better.<p>I&#x27;m skeptical that the only way for them to be precise and technical is to make them impenetrable. I think there is a culture of academic writing (many different cultures, really) that has adopted a voice and writing style which became a parody of itself over time.<p>Here&#x27;s a trivial example: You frequently see papers use the passive voice, something a middle school English teacher would mark with a red pen. <i>500 participants were asked</i>, vs. <i>we asked 500 participants</i>. In what sense is the former more precise and technical? It&#x27;s not. It does not convey any additional meaning. People use it to sound objective and distant, even when they really aren&#x27;t.<p>Realistically, academic writers usually don&#x27;t even think about it as much as that. They&#x27;re just copying the tone of other papers, because there is a culture and it enforces certain behaviors on its members irrespective of the value.</div><br/><div id="36855556" class="c"><input type="checkbox" id="c-36855556" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855045">parent</a><span>|</span><a href="#36856468">next</a><span>|</span><label class="collapse" for="c-36855556">[-]</label><label class="expand" for="c-36855556">[1 more]</label></div><br/><div class="children"><div class="content">A pain in the ass was observed while writing was performed in the passive voice.<p>Nobody likes doing it, I think. We just do it because we’re scared our papers won’t be accepted otherwise.</div><br/></div></div><div id="36856468" class="c"><input type="checkbox" id="c-36856468" checked=""/><div class="controls bullet"><span class="by">rTX5CMRXIfFG</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855045">parent</a><span>|</span><a href="#36855556">prev</a><span>|</span><a href="#36855855">next</a><span>|</span><label class="collapse" for="c-36856468">[-]</label><label class="expand" for="c-36856468">[3 more]</label></div><br/><div class="children"><div class="content">Either your example is too trivial to justify your point, or the point itself is trivial. It&#x27;s right for an academic to distance themselves from the subject of their study because we do need researchers who try not to be biased. If they fail that and then correct themselves, then what&#x27;s the problem? Complaining about inconsequential uses of tone is obsessing about form over function and reeks too much of insecurity, to be honest.</div><br/><div id="36856992" class="c"><input type="checkbox" id="c-36856992" checked=""/><div class="controls bullet"><span class="by">gromneer</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36856468">parent</a><span>|</span><a href="#36855855">next</a><span>|</span><label class="collapse" for="c-36856992">[-]</label><label class="expand" for="c-36856992">[2 more]</label></div><br/><div class="children"><div class="content">They aren&#x27;t magically &quot;objective&quot; because they used the passive voice. It&#x27;s a performance.</div><br/><div id="36857458" class="c"><input type="checkbox" id="c-36857458" checked=""/><div class="controls bullet"><span class="by">rTX5CMRXIfFG</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36856992">parent</a><span>|</span><a href="#36855855">next</a><span>|</span><label class="collapse" for="c-36857458">[-]</label><label class="expand" for="c-36857458">[1 more]</label></div><br/><div class="children"><div class="content">Of course language does not guarantee that the study is objective—that would be in the design of the experiment, the reproducibility of results, and the absence of conflicts of interest among the researchers. Using the passive voice however elevates the outcomes being reported as facts that actually happened, instead of mere personal experiences.<p>People complain all the time about news being biased for being told from a reporter’s point of view, but complain all the same when events are reported in an encyclopedic manner as researchers do when they remove themselves from the events and the outcomes of their studies.</div><br/></div></div></div></div></div></div><div id="36855855" class="c"><input type="checkbox" id="c-36855855" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855045">parent</a><span>|</span><a href="#36856468">prev</a><span>|</span><a href="#36856425">next</a><span>|</span><label class="collapse" for="c-36855855">[-]</label><label class="expand" for="c-36855855">[1 more]</label></div><br/><div class="children"><div class="content">In philosophy papers you see authors often use the pronoun &quot;I&quot;, similar to blog posts. But they have other ways to make them hard to parse for outsiders.</div><br/></div></div><div id="36856425" class="c"><input type="checkbox" id="c-36856425" checked=""/><div class="controls bullet"><span class="by">squarepizza</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855045">parent</a><span>|</span><a href="#36855855">prev</a><span>|</span><a href="#36859549">next</a><span>|</span><label class="collapse" for="c-36856425">[-]</label><label class="expand" for="c-36856425">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m convinced that the value of active voice is not precision and clarity, but rather the subliminal egocentrism away from the object (the research) towards the subject (the research<i>ers</i>) who need to receive credit for the work. The royal &quot;we&quot; also helps frame the work as a collaborative effort with the audience.</div><br/><div id="36858320" class="c"><input type="checkbox" id="c-36858320" checked=""/><div class="controls bullet"><span class="by">cycomanic</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36856425">parent</a><span>|</span><a href="#36859549">next</a><span>|</span><label class="collapse" for="c-36858320">[-]</label><label class="expand" for="c-36858320">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s rubbish, passive voice has a number of detrimental effects, it increases text length without adding information, it makes subject (acting entity) and object (entity acted upon) easier to confuse and it confuses the reader about who actually did things (what some people often confuse with objectivity).<p>That said the assertion that most scientific articles are written in passive voice is outdated för quite some time. Most journal style guides advise to use active voice, e.g. <a href="https:&#x2F;&#x2F;www.nature.com&#x2F;nature-portfolio&#x2F;for-authors&#x2F;write" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nature.com&#x2F;nature-portfolio&#x2F;for-authors&#x2F;write</a></div><br/></div></div></div></div></div></div><div id="36859549" class="c"><input type="checkbox" id="c-36859549" checked=""/><div class="controls bullet"><span class="by">klabb3</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36855045">prev</a><span>|</span><a href="#36852914">next</a><span>|</span><label class="collapse" for="c-36859549">[-]</label><label class="expand" for="c-36859549">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Nah, scientific papers are supposed to be precise and technical.<p>&gt; What should be encouraged is for academics to blog about their research as well.<p>Why so binary? A blog would be hard to find, why not have both in the paper?<p>My view is similar to that of code vs docs: code should be as small, and as precise as possible, whereas docs are best when they’re explaining to humans how things fit together, high level. Also easier to maintain.<p>Hyper technical natural language mixed in with math is almost the worst of both worlds: low density of the actual formulas, with an incomprehensible wall of text surrounding it. And clearly this is an issue also for phd domain experts.<p>Not saying academic writing could be super simple but I also see no reason that the status quo is optimized more for comprehension than say social posturing.</div><br/></div></div><div id="36852914" class="c"><input type="checkbox" id="c-36852914" checked=""/><div class="controls bullet"><span class="by">lofatdairy</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36859549">prev</a><span>|</span><a href="#36853398">next</a><span>|</span><label class="collapse" for="c-36852914">[-]</label><label class="expand" for="c-36852914">[1 more]</label></div><br/><div class="children"><div class="content">I agree with everything you say. Though papers really are a bit too hard to read sometimes, but I&#x27;d argue it&#x27;s often not for an overly technical tone so much as writers cutting out a lot of background material for brevity and assumed familiarity.<p>&gt;What should be encouraged is for academics to blog about their research as well. It would even help when recruiting and onboarding new members. Right now the sociological and economical incentives don&#x27;t promote this at all.<p>I will add onto this that a lot of journals have been pushing for video abstracts and &quot;plain English&quot; abstracts. For the most part I don&#x27;t see these too often but when they&#x27;re there they&#x27;re appreciated, and I vaguely recall that someone found that citations go up when they&#x27;re used (specifically plain English, I don&#x27;t think anything has been on video abstracts).<p>There are a lot of good blogs for computational academic subjects (ml, bioinformatics, comp neuro, etc) but I see less for bio and non-software engineering. Math and physics seems to have some really notable blogs, but beyond what gets posted to HN and linked further on those blogs, I can&#x27;t comment.</div><br/></div></div><div id="36853398" class="c"><input type="checkbox" id="c-36853398" checked=""/><div class="controls bullet"><span class="by">aqsalose</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36852914">prev</a><span>|</span><a href="#36854908">next</a><span>|</span><label class="collapse" for="c-36853398">[-]</label><label class="expand" for="c-36853398">[1 more]</label></div><br/><div class="children"><div class="content">&quot;it honestly comes from a place of ignorance, and I say that as basically a layman myself&quot;<p>Here is an added complication: succinct technical communication can be efficient when communicating to peers who work on the exactly same domain, similar problems as you, and want digest your main ideas quickly.<p>On the other hand, for any particular paper, the size of the audience to whom it is directly relevant and addressed to can be small. The size of the audience who got to reading it anyway may be <i>vast</i>. (Maybe I am reading your paper because someone cited a method paper that in lieu of a proof or explanation writes just two words and citation to your paper. Maybe I am a freshly minted new student reading it for my first seminar. Maybe I am from a neighboring field and trying to understand what is happening in yours. Maybe I tried to find what people have already done with particular idea I just had and search engine gave your paper. And so on.)<p>During my (admittedly lackluster) academic career I recall spending much more time trying to read and understand papers that were not addressed to me than papers that were and where I enjoyed the succinct style that avoids details and present the results. (Maybe it is just an idiosyncratic trust issue on my part, because I am often skeptical of stated results and their interpretation, finding the methods more interesting). But that is not all.<p>I also noticed that genuine misunderstandings coming from &quot;brief&quot; communication of technical &quot;details&quot; were quite common; two different researches would state they &quot;applied method X to avoid Y&#x2F;seek Z[citation]&quot; in exactly so many and almost exactly same words, where X,Y and Z were complicated technical terms, yet the authors would have quite different opinion what the meaning of those words were and what would be the intended reading and how and why X should be implemented.<p>In conclusion, I think many a scientific field would benefit from a style where authors were expected to clearly explain what they did and why (as clearly as possible).</div><br/></div></div><div id="36854908" class="c"><input type="checkbox" id="c-36854908" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36853398">prev</a><span>|</span><a href="#36852724">next</a><span>|</span><label class="collapse" for="c-36854908">[-]</label><label class="expand" for="c-36854908">[1 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Nah, scientific papers are supposed to be precise and technical.</i><p>They&#x27;re also, more often than not, tedious, badly explained,  error prone, oft-skipped, and hardly ever read carefully, even during peer review for the paper that contains them. That&#x27;s how mistakes stay unnoticed for decades in influential papers with tons of citations.<p>In essense, a paper&#x27;s tone and languge is often more formality, academic tradition, ritual, and padding for publication purposes, than serving a real purpose.</div><br/></div></div><div id="36852724" class="c"><input type="checkbox" id="c-36852724" checked=""/><div class="controls bullet"><span class="by">mlsu</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36854908">prev</a><span>|</span><a href="#36854122">next</a><span>|</span><label class="collapse" for="c-36852724">[-]</label><label class="expand" for="c-36852724">[1 more]</label></div><br/><div class="children"><div class="content">Well, I&#x27;m not so sure. It seems to me that someone could perfectly well devise an experiment based off of this (another poster chastised me for saying paper, so) blog post.<p>Equations are perfectly clear. I was able to follow his reasoning perfectly well.<p>I cannot say the same for so many papers (tm) that I&#x27;ve read. Mostly in a similarly computational (though non- deeplearning) applied math domain.</div><br/></div></div><div id="36854122" class="c"><input type="checkbox" id="c-36854122" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36852724">prev</a><span>|</span><a href="#36857462">next</a><span>|</span><label class="collapse" for="c-36854122">[-]</label><label class="expand" for="c-36854122">[4 more]</label></div><br/><div class="children"><div class="content">Leslie Lamport definitely doesn’t share your opinion. A known fact about the Paxos paper is that there are no dumbed down summaries worth reading because the proper thing is so approachable. Not sure if you only have to sound smart if you’ve got nothing to say but certainly feels like it could be the case.</div><br/><div id="36855651" class="c"><input type="checkbox" id="c-36855651" checked=""/><div class="controls bullet"><span class="by">joaogui1</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854122">parent</a><span>|</span><a href="#36855886">next</a><span>|</span><label class="collapse" for="c-36855651">[-]</label><label class="expand" for="c-36855651">[2 more]</label></div><br/><div class="children"><div class="content">Paxos is so mistifyingly hard that Raft was invented as part of a project to understand Paxos (and the advisor and proponent of the project was John Ousterhout, who&#x27;s pretty badass). There are also I believe a few papers trying to trying to explain Paxos more clearly</div><br/><div id="36855774" class="c"><input type="checkbox" id="c-36855774" checked=""/><div class="controls bullet"><span class="by">joaogui1</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855651">parent</a><span>|</span><a href="#36855886">next</a><span>|</span><label class="collapse" for="c-36855774">[-]</label><label class="expand" for="c-36855774">[1 more]</label></div><br/><div class="children"><div class="content">Just as a quick source to my claims:<p>1. The raft paper is titled &quot;In Search of an Understandable Consensus Algorithm&quot;<p>2. The abstract of this tutorial on Understanding Paxos <a href="https:&#x2F;&#x2F;www.ux.uis.no&#x2F;~meling&#x2F;papers&#x2F;2013-paxostutorial-opodis.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.ux.uis.no&#x2F;~meling&#x2F;papers&#x2F;2013-paxostutorial-opod...</a><p>3. Lamport&#x27;s own &quot;Paxos made simple&quot; <a href="https:&#x2F;&#x2F;lamport.azurewebsites.net&#x2F;pubs&#x2F;paxos-simple.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;lamport.azurewebsites.net&#x2F;pubs&#x2F;paxos-simple.pdf</a></div><br/></div></div></div></div><div id="36855886" class="c"><input type="checkbox" id="c-36855886" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854122">parent</a><span>|</span><a href="#36855651">prev</a><span>|</span><a href="#36857462">next</a><span>|</span><label class="collapse" for="c-36855886">[-]</label><label class="expand" for="c-36855886">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A known fact about the Paxos paper is that there are no dumbed down summaries worth reading because the proper thing is so approachable.<p>A known fact is that it&#x27;s impossible to actually implement it correctly, and the &quot;approachable&quot; paper seems to be a significant factor in this.</div><br/></div></div></div></div><div id="36857462" class="c"><input type="checkbox" id="c-36857462" checked=""/><div class="controls bullet"><span class="by">projectileboy</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36854122">prev</a><span>|</span><a href="#36856921">next</a><span>|</span><label class="collapse" for="c-36857462">[-]</label><label class="expand" for="c-36857462">[1 more]</label></div><br/><div class="children"><div class="content">Strongly agree. “Why are academic papers always written in such mumbo jumbo?” is the same complaint as “Why are contracts written in such legalese?”, which is a manifestation of “I’m smart and I don’t get this, so the author is dumb for not writing clearly.” It’s a natural human bias that most HN denizens insist they don’t possess, but of course we do.</div><br/></div></div><div id="36856921" class="c"><input type="checkbox" id="c-36856921" checked=""/><div class="controls bullet"><span class="by">gromneer</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36857462">prev</a><span>|</span><a href="#36855652">next</a><span>|</span><label class="collapse" for="c-36856921">[-]</label><label class="expand" for="c-36856921">[1 more]</label></div><br/><div class="children"><div class="content">I disagree because it isn&#x27;t possible for language to be precise on it&#x27;s own syntactic merit. There is meaning and there is context and the biggest problem with research papers is that the context of many statements in the paper are incredibly ambiguous. The reason for that is that the papers are trying to be &quot;concise&quot;. Context can only be disambiguated with more statements. You must eliminate potential interpretations that a reader could make.<p>&quot;Spectrum sharing in an “apple-like” or a fixed set sense is not a coexistence. &quot;. What does that mean? Coexist? Who knows, the author thought they were being precise, but they understood the statement they made with a head full of context that gave it precise meaning. As readers, we can only scratch our own heads as to what that context could possibly be.</div><br/></div></div><div id="36855652" class="c"><input type="checkbox" id="c-36855652" checked=""/><div class="controls bullet"><span class="by">jshen</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36856921">prev</a><span>|</span><a href="#36854148">next</a><span>|</span><label class="collapse" for="c-36855652">[-]</label><label class="expand" for="c-36855652">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve read a lot of scientific papers in the comp sci &#x2F; machine learning space and they are rarely precise. It&#x27;s been over a decade since I&#x27;ve ready many papers so maybe this has changed, but I remember reading a paper out of Microsoft about how to make spell correcting auto-completion for search, and it was nearly impossible to figure out precisely how it was implemented. Precision would have been achieved easily by providing code and a sample data set. instead of was a mix of prose and math equations with many gaps where you had to guess how to fill.</div><br/><div id="36856029" class="c"><input type="checkbox" id="c-36856029" checked=""/><div class="controls bullet"><span class="by">a_bonobo</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855652">parent</a><span>|</span><a href="#36854148">next</a><span>|</span><label class="collapse" for="c-36856029">[-]</label><label class="expand" for="c-36856029">[1 more]</label></div><br/><div class="children"><div class="content">Ah yes, my old supervisor was very fond of that strategy.<p>&quot;Make it sound like we do cool stuff; but don&#x27;t make it so precise that they can re-implement what we do. Let them come to us so we can co-author papers.&quot;</div><br/></div></div></div></div><div id="36854148" class="c"><input type="checkbox" id="c-36854148" checked=""/><div class="controls bullet"><span class="by">guluarte</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36855652">prev</a><span>|</span><a href="#36855772">next</a><span>|</span><label class="collapse" for="c-36854148">[-]</label><label class="expand" for="c-36854148">[1 more]</label></div><br/><div class="children"><div class="content">not always, ReLu is a fucking line, most papers write stuff in the most complicated way to sound smart.</div><br/></div></div><div id="36855772" class="c"><input type="checkbox" id="c-36855772" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852654">parent</a><span>|</span><a href="#36854148">prev</a><span>|</span><a href="#36852258">next</a><span>|</span><label class="collapse" for="c-36855772">[-]</label><label class="expand" for="c-36855772">[1 more]</label></div><br/><div class="children"><div class="content">More fundamentally he&#x27;s postulating that this will work in a blog post but he doesn&#x27;t do any experiment to prove that it does.</div><br/></div></div></div></div><div id="36852258" class="c"><input type="checkbox" id="c-36852258" checked=""/><div class="controls bullet"><span class="by">chessgecko</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36852654">prev</a><span>|</span><a href="#36853248">next</a><span>|</span><label class="collapse" for="c-36852258">[-]</label><label class="expand" for="c-36852258">[13 more]</label></div><br/><div class="children"><div class="content">I think maybe its because he didn&#x27;t have experimental results that show that it worked. Not a knock against the author, there are just so many things that seem like good ideas that don&#x27;t end up working well in practice, a paper like this without results is hard to value.</div><br/><div id="36852482" class="c"><input type="checkbox" id="c-36852482" checked=""/><div class="controls bullet"><span class="by">mlsu</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852258">parent</a><span>|</span><a href="#36852495">next</a><span>|</span><label class="collapse" for="c-36852482">[-]</label><label class="expand" for="c-36852482">[3 more]</label></div><br/><div class="children"><div class="content">Yes, definitely. If he tried to have it published, the lack of experimental results would definitely be a glaring error.<p>But this is still scientific communication. It&#x27;s really nice that it&#x27;s legible!<p>&gt; Even though softmax1 is facially quite boring, I’m 99.44% sure that it will resolve the outlier feedback loop that’s making quantization the subject of cascades of research. If you want to run some experiments and prove me right, DM me on Twitter and we’ll get a paper going.<p>I&#x27;m guessing that in the stodgy world of science, a communication like this might happen over lunch at a conference, limited to a small clique of researchers who are zealously guarding their next paper. Who could blame them, publish or perish!<p>But someone will probably test this theory out (after my read, it will probably happen in llama.cpp with preliminary results on GPT-2 by next week) and achieve results, and it will happen quickly and legibly to the outside world, because this was published openly and without all of the pretension that formal science (tm) has. If it works, it works. Stuff like this is the soul of the internet. Sharing knowledge and making it legible for all.</div><br/><div id="36855746" class="c"><input type="checkbox" id="c-36855746" checked=""/><div class="controls bullet"><span class="by">light_hue_1</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852482">parent</a><span>|</span><a href="#36852734">prev</a><span>|</span><a href="#36852495">next</a><span>|</span><label class="collapse" for="c-36855746">[-]</label><label class="expand" for="c-36855746">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a perfectly good venue for this communication: a workshop.<p>Workshop submissions often don&#x27;t need evidence. They just need a small kernel to spur discussion.<p>Without experiments, there is no hope of publishing this in anything more than a workshop. Nor should there be.</div><br/></div></div></div></div><div id="36852495" class="c"><input type="checkbox" id="c-36852495" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852258">parent</a><span>|</span><a href="#36852482">prev</a><span>|</span><a href="#36853248">next</a><span>|</span><label class="collapse" for="c-36852495">[-]</label><label class="expand" for="c-36852495">[9 more]</label></div><br/><div class="children"><div class="content">Then again, if you don&#x27;t have access to giant compute clusters you can&#x27;t test this, so it&#x27;s either a blog post or nothing. I believe the outlier problem that this solves only appears for very large models.</div><br/><div id="36852627" class="c"><input type="checkbox" id="c-36852627" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852495">parent</a><span>|</span><a href="#36853248">next</a><span>|</span><label class="collapse" for="c-36852627">[-]</label><label class="expand" for="c-36852627">[8 more]</label></div><br/><div class="children"><div class="content">That isn’t true at all. Train a smaller model on a smaller dataset. You can even train on your laptop. It’s definitely feasible. This is just a proof of concept, it doesn’t need to beat state of the art.</div><br/><div id="36852975" class="c"><input type="checkbox" id="c-36852975" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852627">parent</a><span>|</span><a href="#36853248">next</a><span>|</span><label class="collapse" for="c-36852975">[-]</label><label class="expand" for="c-36852975">[7 more]</label></div><br/><div class="children"><div class="content">Maybe I edited my comment too late.</div><br/><div id="36853251" class="c"><input type="checkbox" id="c-36853251" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852975">parent</a><span>|</span><a href="#36853248">next</a><span>|</span><label class="collapse" for="c-36853251">[-]</label><label class="expand" for="c-36853251">[6 more]</label></div><br/><div class="children"><div class="content">&gt; I believe the outlier problem that this solves only appears for very large models.<p>Any reason to believe this? The author never mentioned it, and I can’t think of any other <i>a priori</i> reason why it should be true.</div><br/><div id="36853908" class="c"><input type="checkbox" id="c-36853908" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853251">parent</a><span>|</span><a href="#36853248">next</a><span>|</span><label class="collapse" for="c-36853908">[-]</label><label class="expand" for="c-36853908">[5 more]</label></div><br/><div class="children"><div class="content">See figure 1:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2208.07339.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2208.07339.pdf</a><p>Outliers appear at model size 6.7B and are not present at 2.7B</div><br/><div id="36854557" class="c"><input type="checkbox" id="c-36854557" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853908">parent</a><span>|</span><a href="#36855021">next</a><span>|</span><label class="collapse" for="c-36854557">[-]</label><label class="expand" for="c-36854557">[2 more]</label></div><br/><div class="children"><div class="content">Sure, emergent properties can arise as parameters increase. Everyone knows that. That’s a much less specific claim than to say that the benefit of modifying softmax can only arise as an emergent property after N parameters, and therefore the benefit can only be evaluated on models above a certain size. To my understanding the author of TFA isn’t suggesting the same issue as the one in your linked paper.</div><br/><div id="36854931" class="c"><input type="checkbox" id="c-36854931" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36854557">parent</a><span>|</span><a href="#36855021">next</a><span>|</span><label class="collapse" for="c-36854931">[-]</label><label class="expand" for="c-36854931">[1 more]</label></div><br/><div class="children"><div class="content">The second heading in the TFA is &quot;It’s All About Outliers&quot;</div><br/></div></div></div></div><div id="36855021" class="c"><input type="checkbox" id="c-36855021" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853908">parent</a><span>|</span><a href="#36854557">prev</a><span>|</span><a href="#36853248">next</a><span>|</span><label class="collapse" for="c-36855021">[-]</label><label class="expand" for="c-36855021">[2 more]</label></div><br/><div class="children"><div class="content">6.7B isn&#x27;t &quot;needs a datacenter&quot; scale.</div><br/><div id="36855130" class="c"><input type="checkbox" id="c-36855130" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855021">parent</a><span>|</span><a href="#36853248">next</a><span>|</span><label class="collapse" for="c-36855130">[-]</label><label class="expand" for="c-36855130">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s in the million dollar range. XLnet which is a 1.3B model cost $245,000 to  train for example.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36853248" class="c"><input type="checkbox" id="c-36853248" checked=""/><div class="controls bullet"><span class="by">Waterluvian</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36852258">prev</a><span>|</span><a href="#36852779">next</a><span>|</span><label class="collapse" for="c-36853248">[-]</label><label class="expand" for="c-36853248">[1 more]</label></div><br/><div class="children"><div class="content">To finish the author’s analogy:<p>Blog posts are written by those who arrive first.<p>In a weird way my mental model is: blog posts are the recon team discovering a new idea. They might have errors. They might be incomplete. Maybe they’re outright wrong. Stakes are lower as it took less effort to get there and less loss if a position is abandoned.<p>Then papers are authored, often much later, and they’re the regulars coming in to fortify a newly captured idea. They provide (or at least are supposed to) rigor   to the idea. A fortification of a position that we decide is worth holding.<p>Yeah, this analogy is probably sloppy. But in my brain there’s an eternal conflict against ignorance as we keep advancing into the unknown.</div><br/></div></div><div id="36852779" class="c"><input type="checkbox" id="c-36852779" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36853248">prev</a><span>|</span><a href="#36852636">next</a><span>|</span><label class="collapse" for="c-36852779">[-]</label><label class="expand" for="c-36852779">[11 more]</label></div><br/><div class="children"><div class="content">Counterargument: this blogpost is worthless. You get all the way to the end and then find out he hasn&#x27;t actually tried it, not even on a toy model. It&#x27;s just a neat idea he thinks will work.</div><br/><div id="36853572" class="c"><input type="checkbox" id="c-36853572" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852779">parent</a><span>|</span><a href="#36853037">next</a><span>|</span><label class="collapse" for="c-36853572">[-]</label><label class="expand" for="c-36853572">[2 more]</label></div><br/><div class="children"><div class="content">I wouldn’t quite say its value is zero. It’s worth something, but a lot less than if it had been shown to work empirically.<p>Explainers and their folksy, imprecise tone are good for things we already know are true. I’m skeptical on things which are unproven.</div><br/></div></div><div id="36853037" class="c"><input type="checkbox" id="c-36853037" checked=""/><div class="controls bullet"><span class="by">ambrozk</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852779">parent</a><span>|</span><a href="#36853572">prev</a><span>|</span><a href="#36857652">next</a><span>|</span><label class="collapse" for="c-36853037">[-]</label><label class="expand" for="c-36853037">[7 more]</label></div><br/><div class="children"><div class="content">Why would that make it worthless?</div><br/><div id="36853284" class="c"><input type="checkbox" id="c-36853284" checked=""/><div class="controls bullet"><span class="by">PoignardAzur</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853037">parent</a><span>|</span><a href="#36853396">next</a><span>|</span><label class="collapse" for="c-36853284">[-]</label><label class="expand" for="c-36853284">[1 more]</label></div><br/><div class="children"><div class="content">Among other reasons, because the decoder-only version of the original transformer architecture has proven <i>weirdly</i> resistant to these kinds of hacks and clever optimizations.<p>Ideas like sparse attention, tree attention, residual attention, etc, all sound good on paper, but when researchers try to reproduce them they either find no results or results that don&#x27;t scale. Even AliBi is turning out to be less powerful than scaled-down positional embeddings. It&#x27;s almost a bitter lesson on its own: you can&#x27;t beat the original transformer.<p>Optimizations that <i>do</i> stick around tend to be the ones that preserve the original algorithm but help with caching or memory accesses.</div><br/></div></div><div id="36853396" class="c"><input type="checkbox" id="c-36853396" checked=""/><div class="controls bullet"><span class="by">6gvONxR4sf7o</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853037">parent</a><span>|</span><a href="#36853284">prev</a><span>|</span><a href="#36853234">next</a><span>|</span><label class="collapse" for="c-36853396">[-]</label><label class="expand" for="c-36853396">[1 more]</label></div><br/><div class="children"><div class="content">Because there are a thousand ideas a minute in this field that meet the &quot;it&#x27;s worth trying&quot; bar but don&#x27;t actually pan out to make any difference. It&#x27;s the equivalent of a blogpost that says &quot;if someone else turned my idea into a business, it would be a billion dollar business. But I won&#x27;t bother.&quot;</div><br/></div></div><div id="36853234" class="c"><input type="checkbox" id="c-36853234" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853037">parent</a><span>|</span><a href="#36853396">prev</a><span>|</span><a href="#36855852">next</a><span>|</span><label class="collapse" for="c-36853234">[-]</label><label class="expand" for="c-36853234">[3 more]</label></div><br/><div class="children"><div class="content">Because until he tries it, who knows if it works?<p>There are a thousand papers out there making minor tweaks to the transformer architecture. 99% of them are also worthless and forgotten.</div><br/><div id="36853309" class="c"><input type="checkbox" id="c-36853309" checked=""/><div class="controls bullet"><span class="by">debugnik</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853234">parent</a><span>|</span><a href="#36855852">next</a><span>|</span><label class="collapse" for="c-36853309">[-]</label><label class="expand" for="c-36853309">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Because until he tries it, who knows if it works?<p>That&#x27;s precisely what he shared this for, though. So someone willing to train a model with this tweak tries it.</div><br/></div></div></div></div><div id="36855852" class="c"><input type="checkbox" id="c-36855852" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853037">parent</a><span>|</span><a href="#36853234">prev</a><span>|</span><a href="#36857652">next</a><span>|</span><label class="collapse" for="c-36855852">[-]</label><label class="expand" for="c-36855852">[1 more]</label></div><br/><div class="children"><div class="content">With say system architecture, you can muse on stuff like &quot;well if Kubernetes made this decision, it would definitely be more secure&quot; or &quot;it would scale up quicker&quot; without empirical evidence and other people could argue &quot;yes I agree because&quot; or &quot;no I don&#x27;t because&quot;... etc.<p>With large ML models, there probably is no intuition like this. We just don&#x27;t know &quot;if I do the common sense thing X, it surely will produce better results for a given benchmark&quot; ... well we have no idea until it is tried out.</div><br/></div></div></div></div><div id="36857652" class="c"><input type="checkbox" id="c-36857652" checked=""/><div class="controls bullet"><span class="by">fogof</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852779">parent</a><span>|</span><a href="#36853037">prev</a><span>|</span><a href="#36852636">next</a><span>|</span><label class="collapse" for="c-36857652">[-]</label><label class="expand" for="c-36857652">[1 more]</label></div><br/><div class="children"><div class="content">He says in the very first paragraph:<p>&gt;  I lost a series of pitched battles against Pytorch and biblatex, so I figured I’d just write a blog post instead.<p>So I think your accusation of his burying the lede on the lack of experiment is unwarranted.</div><br/></div></div></div></div><div id="36852636" class="c"><input type="checkbox" id="c-36852636" checked=""/><div class="controls bullet"><span class="by">_Microft</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36852779">prev</a><span>|</span><a href="#36853976">next</a><span>|</span><label class="collapse" for="c-36852636">[-]</label><label class="expand" for="c-36852636">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This paper<p>It&#x27;s not a paper. It&#x27;s an idea that sounds plausible, presented in a highly entertaining form.</div><br/></div></div><div id="36853976" class="c"><input type="checkbox" id="c-36853976" checked=""/><div class="controls bullet"><span class="by">pessimizer</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36852636">prev</a><span>|</span><a href="#36857723">next</a><span>|</span><label class="collapse" for="c-36853976">[-]</label><label class="expand" for="c-36853976">[3 more]</label></div><br/><div class="children"><div class="content">&gt; The tone is self-effacing, it does not have an &quot;ego&quot; the way scientific papers tend to have.<p>I can&#x27;t imagine judging scientific papers based on whether the author might be looking down on me, or thinks he knows better than me.<p>&gt; if we were &quot;allowed&quot; to cite research that reads like this<p>Maybe you&#x27;re looking down on <i>yourself?</i> You can cite anything you want to cite.</div><br/><div id="36855184" class="c"><input type="checkbox" id="c-36855184" checked=""/><div class="controls bullet"><span class="by">caddemon</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853976">parent</a><span>|</span><a href="#36857723">next</a><span>|</span><label class="collapse" for="c-36855184">[-]</label><label class="expand" for="c-36855184">[2 more]</label></div><br/><div class="children"><div class="content">Well if you yourself are trying to publish in a scientific venue you can&#x27;t always cite exactly what you want to cite. Though it&#x27;s probably uncommon for a peer reviewer to ask for a specific citation to be removed, the review process absolutely does affect the references list, and expectations about this process affect it doubly so.</div><br/><div id="36856818" class="c"><input type="checkbox" id="c-36856818" checked=""/><div class="controls bullet"><span class="by">simonster</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36855184">parent</a><span>|</span><a href="#36857723">next</a><span>|</span><label class="collapse" for="c-36856818">[-]</label><label class="expand" for="c-36856818">[1 more]</label></div><br/><div class="children"><div class="content">In ML, no one is going to police your citation list. I&#x27;ve cited some weird stuff in my papers, including ideas from tweets and random quotes from Jeff Dean. It&#x27;s never been a problem.</div><br/></div></div></div></div></div></div><div id="36857723" class="c"><input type="checkbox" id="c-36857723" checked=""/><div class="controls bullet"><span class="by">fogof</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36853976">prev</a><span>|</span><a href="#36854762">next</a><span>|</span><label class="collapse" for="c-36857723">[-]</label><label class="expand" for="c-36857723">[1 more]</label></div><br/><div class="children"><div class="content">A lot of thoughts in this thread on what academic papers are or should be, let me give my own opinion as a person who tries to write papers.<p>Papers should be structured like fractals - that is, they should be &quot;self-similar&quot;. The main text of the paper after the introduction should go into all the necessary details demonstrating the origins of the idea and proving that it has value. Then the introduction section should summarize all this, and take a less rigorous tone. The abstract should be a summary of the introduction. And then the title should summarize the abstract. If you really have a lot of technical work to do, maybe you can write a super long appendix and have the main body summarize that.<p>I myself probably spend as much time reading paper introductions as I do reading paper bodies, which means that probably 90% of the papers I read, I only read the introduction. I do this because I enjoy it more - I like new ideas, and the intros are a great way to get a lot of them. This blog post reads like a great paper introduction to me. It&#x27;s easy to trick yourself into believing something is easy though, so an academic paper would have to back this up with an experiment.</div><br/></div></div><div id="36854762" class="c"><input type="checkbox" id="c-36854762" checked=""/><div class="controls bullet"><span class="by">baby</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36857723">prev</a><span>|</span><a href="#36855822">next</a><span>|</span><label class="collapse" for="c-36854762">[-]</label><label class="expand" for="c-36854762">[1 more]</label></div><br/><div class="children"><div class="content">There isn&#x27;t much difference between a blog and a whitepaper, in that people tend to write blogs more casually and whitepaper more seriously (and some academics event only accept things that look more serious).<p>But a good writer can write great articles in whatever format they wish.</div><br/></div></div><div id="36855822" class="c"><input type="checkbox" id="c-36855822" checked=""/><div class="controls bullet"><span class="by">herval</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36854762">prev</a><span>|</span><a href="#36856077">next</a><span>|</span><label class="collapse" for="c-36855822">[-]</label><label class="expand" for="c-36855822">[1 more]</label></div><br/><div class="children"><div class="content">I learned more from this post than a thousand papers. Amazing writing!</div><br/></div></div><div id="36856077" class="c"><input type="checkbox" id="c-36856077" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36855822">prev</a><span>|</span><a href="#36856772">next</a><span>|</span><label class="collapse" for="c-36856077">[-]</label><label class="expand" for="c-36856077">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it does not have an &quot;ego&quot; the way scientific papers tend to have.<p>What do you call it when somebody takes the time to write about &quot;a big discovery&quot; they&#x27;ve made, but don&#x27;t take the time to check if somebody else already did it? It&#x27;s not like it&#x27;s in some forgotten paper nobody has seen. It&#x27;s in Pytorch itself.<p>Also this: &quot;I’m 99.44% sure that it will resolve the outlier feedback loop that’s making quantization the subject of cascades of research.&quot;</div><br/></div></div><div id="36856772" class="c"><input type="checkbox" id="c-36856772" checked=""/><div class="controls bullet"><span class="by">simonster</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36856077">prev</a><span>|</span><a href="#36854577">next</a><span>|</span><label class="collapse" for="c-36856772">[-]</label><label class="expand" for="c-36856772">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting, because as a scientist who reads and writes these kinds of papers, my first impression was: This guy has a pretty big ego or is otherwise badly miscalibrated if he believes his genius idea has a &quot;99.44%&quot; chance of preventing outlier activations without doing any experiments.</div><br/><div id="36857105" class="c"><input type="checkbox" id="c-36857105" checked=""/><div class="controls bullet"><span class="by">misthop</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36856772">parent</a><span>|</span><a href="#36854577">next</a><span>|</span><label class="collapse" for="c-36857105">[-]</label><label class="expand" for="c-36857105">[1 more]</label></div><br/><div class="children"><div class="content">Not ego, he&#x27;s playing on the old Ivory Soap slogan &quot;99+44⁄100% Pure&quot;<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Ivory_(soap)" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Ivory_(soap)</a></div><br/></div></div></div></div><div id="36854577" class="c"><input type="checkbox" id="c-36854577" checked=""/><div class="controls bullet"><span class="by">Method-X</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36856772">prev</a><span>|</span><a href="#36852671">next</a><span>|</span><label class="collapse" for="c-36854577">[-]</label><label class="expand" for="c-36854577">[1 more]</label></div><br/><div class="children"><div class="content">I can see AI being used to make scientific papers more approachable like this.</div><br/></div></div><div id="36852301" class="c"><input type="checkbox" id="c-36852301" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36852671">prev</a><span>|</span><a href="#36854332">next</a><span>|</span><label class="collapse" for="c-36852301">[-]</label><label class="expand" for="c-36852301">[1 more]</label></div><br/><div class="children"><div class="content">This is why folks like gwern have their own research published this way, i.e. his analysis of GPT-3: <a href="https:&#x2F;&#x2F;gwern.net&#x2F;gpt-3" rel="nofollow noreferrer">https:&#x2F;&#x2F;gwern.net&#x2F;gpt-3</a><p>We call him an &quot;independent AI researcher&quot; because his google scholar is &quot;bland&quot; compared to many academics who play the academia game - <a href="https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user=yk1QMowAAAAJ&amp;hl=en" rel="nofollow noreferrer">https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user=yk1QMowAAAAJ&amp;hl=en</a></div><br/></div></div><div id="36854332" class="c"><input type="checkbox" id="c-36854332" checked=""/><div class="controls bullet"><span class="by">TigeriusKirk</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36852301">prev</a><span>|</span><a href="#36852721">next</a><span>|</span><label class="collapse" for="c-36854332">[-]</label><label class="expand" for="c-36854332">[1 more]</label></div><br/><div class="children"><div class="content">Are most AI papers even published beyond arxiv anyway?</div><br/></div></div><div id="36852721" class="c"><input type="checkbox" id="c-36852721" checked=""/><div class="controls bullet"><span class="by">nico</span><span>|</span><a href="#36852187">parent</a><span>|</span><a href="#36854332">prev</a><span>|</span><a href="#36853497">next</a><span>|</span><label class="collapse" for="c-36852721">[-]</label><label class="expand" for="c-36852721">[5 more]</label></div><br/><div class="children"><div class="content">It would be amazing if academia started replacing papers with videos + code<p>I want to see: an explainer of the science&#x2F;ideas&#x2F;experiments&#x2F;hipothesis<p>And instructions on how to reproduce the experiments&#x2F;results<p>Some YouTubers are going in this direction</div><br/><div id="36853708" class="c"><input type="checkbox" id="c-36853708" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852721">parent</a><span>|</span><a href="#36858810">next</a><span>|</span><label class="collapse" for="c-36853708">[-]</label><label class="expand" for="c-36853708">[2 more]</label></div><br/><div class="children"><div class="content">+1 to including code with your paper. It improves reproducibility and transparency. There’s even a well-known website dedicated to this purpose.<p>For the rest of it I don’t care. As long as researchers understand what’s going on, that’s what matters.</div><br/><div id="36857593" class="c"><input type="checkbox" id="c-36857593" checked=""/><div class="controls bullet"><span class="by">worthless-trash</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36853708">parent</a><span>|</span><a href="#36858810">next</a><span>|</span><label class="collapse" for="c-36857593">[-]</label><label class="expand" for="c-36857593">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not an academic, but some of the notation and terminology they use makes me want to hunt them down and &#x27;clockwork orange their eyes open&#x27; until they can show me how their math is &quot;intended&quot; to work.<p>Inconsistent math notatation in papers along with vague terms in descriptions makes me so mad.</div><br/></div></div></div></div><div id="36858810" class="c"><input type="checkbox" id="c-36858810" checked=""/><div class="controls bullet"><span class="by">saiojd</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852721">parent</a><span>|</span><a href="#36853708">prev</a><span>|</span><a href="#36855835">next</a><span>|</span><label class="collapse" for="c-36858810">[-]</label><label class="expand" for="c-36858810">[1 more]</label></div><br/><div class="children"><div class="content">Most papers already have code, and videos are very common.</div><br/></div></div><div id="36855835" class="c"><input type="checkbox" id="c-36855835" checked=""/><div class="controls bullet"><span class="by">herval</span><span>|</span><a href="#36852187">root</a><span>|</span><a href="#36852721">parent</a><span>|</span><a href="#36858810">prev</a><span>|</span><a href="#36853497">next</a><span>|</span><label class="collapse" for="c-36855835">[-]</label><label class="expand" for="c-36855835">[1 more]</label></div><br/><div class="children"><div class="content">oh god, please, no more videos...</div><br/></div></div></div></div></div></div><div id="36853497" class="c"><input type="checkbox" id="c-36853497" checked=""/><div class="controls bullet"><span class="by">gwern</span><span>|</span><a href="#36852187">prev</a><span>|</span><a href="#36854087">next</a><span>|</span><label class="collapse" for="c-36853497">[-]</label><label class="expand" for="c-36853497">[1 more]</label></div><br/><div class="children"><div class="content">This reminds me of the normalization bug in StyleGAN. It had this obvious visual artifact of a &#x27;blob&#x27; which would appear in otherwise photorealistic images, which was puzzling because it was <i>so</i> obvious how did the Discriminator not squash it? It turned out to be a flaw in the normalization of the AdaIn style layers, IIRC, where the Generator was pumping up numbers and doing weird things to force through information.</div><br/></div></div><div id="36854087" class="c"><input type="checkbox" id="c-36854087" checked=""/><div class="controls bullet"><span class="by">lscharen</span><span>|</span><a href="#36853497">prev</a><span>|</span><a href="#36852691">next</a><span>|</span><label class="collapse" for="c-36854087">[-]</label><label class="expand" for="c-36854087">[1 more]</label></div><br/><div class="children"><div class="content">This is similar the the (old) trick of adding a Uniform distribution component to a Mixture of Gaussians model.  It doesn&#x27;t really change the math wrt parameter optimization and probability evaluation, but provides a place to capture &quot;background&quot; or &quot;unimportant&quot; data points and improve the model robustness to outliers.<p>The motivation follows from the same problem the author points out in the original softmax formulation that it always &quot;forces a choice&quot; when it may be more useful to put a &quot;Not Applicable&quot; option into the model itself.<p><a href="https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;s10260-021-00578-2" rel="nofollow noreferrer">https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;s10260-021-00578-2</a></div><br/></div></div><div id="36852691" class="c"><input type="checkbox" id="c-36852691" checked=""/><div class="controls bullet"><span class="by">jmount</span><span>|</span><a href="#36854087">prev</a><span>|</span><a href="#36852484">next</a><span>|</span><label class="collapse" for="c-36852691">[-]</label><label class="expand" for="c-36852691">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;missing 1&quot; is a waste-category that is implicitly re-scaled.<p>The explicit 1 formulation is used in binary softmax, and the implicit (not seen 1) is used in multinomial softmax. I suspect this is the old &quot;notation B looks silly in terms of notation A&#x27;s standards.&quot;</div><br/></div></div><div id="36852484" class="c"><input type="checkbox" id="c-36852484" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#36852691">prev</a><span>|</span><a href="#36851962">next</a><span>|</span><label class="collapse" for="c-36852484">[-]</label><label class="expand" for="c-36852484">[2 more]</label></div><br/><div class="children"><div class="content">I follow the argument but the proof of the pudding is in the eating. I don’t know what “battles” the author lost to PyTorch lately but a good test would be to modify one of the smaller models (maybe nanogpt) and swap out all of the softmax calls for his quiet softmax.<p>I didn’t see anything relevant on alternatives to softmax, since TFA is specifically questioning softmax in a multihead attention context.<p>Ultimately, neural networks are arbitrary function approximators. It doesn’t necessarily have to be “right” internally to fit the data. But if this new softmax allows transformers to learn more, that’s great.</div><br/><div id="36853111" class="c"><input type="checkbox" id="c-36853111" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#36852484">parent</a><span>|</span><a href="#36851962">next</a><span>|</span><label class="collapse" for="c-36853111">[-]</label><label class="expand" for="c-36853111">[1 more]</label></div><br/><div class="children"><div class="content">&gt; a good test would be to modify one of the smaller models (maybe nanogpt) and swap out all of the softmax calls for his quiet softmax.<p>You&#x27;d have to train the model with the quiet softmax before inferencing with it would work.</div><br/></div></div></div></div><div id="36851962" class="c"><input type="checkbox" id="c-36851962" checked=""/><div class="controls bullet"><span class="by">firebirdn99</span><span>|</span><a href="#36852484">prev</a><span>|</span><a href="#36857261">next</a><span>|</span><label class="collapse" for="c-36851962">[-]</label><label class="expand" for="c-36851962">[3 more]</label></div><br/><div class="children"><div class="content">This is right below the &quot;Have Attention Spans Been Declining? – Yes, 65%&quot; post, lol brilliant. In general, human decreasing, AI increasing- attention.</div><br/><div id="36854759" class="c"><input type="checkbox" id="c-36854759" checked=""/><div class="controls bullet"><span class="by">neilv</span><span>|</span><a href="#36851962">parent</a><span>|</span><a href="#36853552">next</a><span>|</span><label class="collapse" for="c-36854759">[-]</label><label class="expand" for="c-36854759">[1 more]</label></div><br/><div class="children"><div class="content">For posterity:<p><pre><code>    1. Have attention spans been declining? (slimemoldtimemold.com)
       338 points by janandonly 4 hours ago | flag | hide | 254 comments

    2. Attention Is Off By One (evanmiller.org)
       400 points by elbasti 4 hours ago | flag | hide | 129 comments
</code></pre>
Note that the #1 post is probably there because the title earlier had the provacative &quot;Yes, 65%&quot; appended to it.  So even more numerical.</div><br/></div></div><div id="36853552" class="c"><input type="checkbox" id="c-36853552" checked=""/><div class="controls bullet"><span class="by">gwern</span><span>|</span><a href="#36851962">parent</a><span>|</span><a href="#36854759">prev</a><span>|</span><a href="#36857261">next</a><span>|</span><label class="collapse" for="c-36853552">[-]</label><label class="expand" for="c-36853552">[1 more]</label></div><br/><div class="children"><div class="content">&quot;In this post, I prove that attention spans have actually declined by 64%, contrary to widely-publicized reports of 65%...&quot;</div><br/></div></div></div></div><div id="36857261" class="c"><input type="checkbox" id="c-36857261" checked=""/><div class="controls bullet"><span class="by">killjoywashere</span><span>|</span><a href="#36851962">prev</a><span>|</span><a href="#36857889">next</a><span>|</span><label class="collapse" for="c-36857261">[-]</label><label class="expand" for="c-36857261">[1 more]</label></div><br/><div class="children"><div class="content">I know we&#x27;re not allowed to talk about neuroscience in AI threads, but the &quot;megalodon&quot; reference got me thinking about pyramidal cells in the brain. I mean, why are they so big? Maybe this isn&#x27;t a problem, maybe it&#x27;s an external bit of evidence that, no, really, some things matter a <i>lot</i> more. Which definitely jives with lived experience.</div><br/></div></div><div id="36857889" class="c"><input type="checkbox" id="c-36857889" checked=""/><div class="controls bullet"><span class="by">notanothereric</span><span>|</span><a href="#36857261">prev</a><span>|</span><a href="#36853946">next</a><span>|</span><label class="collapse" for="c-36857889">[-]</label><label class="expand" for="c-36857889">[1 more]</label></div><br/><div class="children"><div class="content">If the author just proposed his new function neo_max() and quoted The Architect from The Matrix everyone here would be enjoying the April Fools Day joke for 2024…<p>“ Your life is the sum of a remainder of an unbalanced equation inherent to the programming of the matrix. You are the eventuality of an anomaly, which despite my sincerest efforts I have been unable to eliminate from what is otherwise a harmony of mathematical precision. While it remains a burden assiduously avoided, it is not unexpected, and thus not beyond a measure of control. Which has led you, inexorably, here.”<p>Hence ergo - you are a NaN. A divide-by-zero.</div><br/></div></div><div id="36853946" class="c"><input type="checkbox" id="c-36853946" checked=""/><div class="controls bullet"><span class="by">jxf</span><span>|</span><a href="#36857889">prev</a><span>|</span><a href="#36855537">next</a><span>|</span><label class="collapse" for="c-36853946">[-]</label><label class="expand" for="c-36853946">[1 more]</label></div><br/><div class="children"><div class="content">The author&#x27;s use of &quot;kurtotic barbarities&quot; to describe this situation is absolutely my new favorite phrase. English is a beautiful language in which to express frustrations.</div><br/></div></div><div id="36855537" class="c"><input type="checkbox" id="c-36855537" checked=""/><div class="controls bullet"><span class="by">dsubburam</span><span>|</span><a href="#36853946">prev</a><span>|</span><a href="#36852496">next</a><span>|</span><label class="collapse" for="c-36855537">[-]</label><label class="expand" for="c-36855537">[2 more]</label></div><br/><div class="children"><div class="content">This part of his post where he explains vector embeddings of the input&#x2F;output tokens just looks wrong to me:<p>&gt;This vector seems to get taller every model year, for example the recent LLaMA 2 model from Meta uses an embedding vector of length 3,204, which works out to 6KB+ in half-precision floating-point, just to represent one word in the vocabulary, which typically contains 30,000 - 50,000 entries.<p>&gt;Now if you’re a memory-miserly C programmer like me, you might wonder, why in the world are these AI goobers using 6KB to represent something that ought to take, like 2 bytes tops? If their vocabulary is less than 2^16=65,384, we only need 16 bits to represent an entry, yeah?<p>&gt;Well, here is what the Transformer is actually doing: it transforms (eh?) that input vector to an output vector of the same size, and that final 6KB output vector needs to encode absolutely everything needed to predict the token after the current one. The job of each layer of the Transformer is quite literally adding information to the original, single-word vector. This is where the residual (née skip) connections come in: all of the attention machinery is just adding supplementary material to that original two bytes’ worth of information, analyzing the larger context to indicate, for instance, that the word pupil is referring to a student, and not to the hole in your eye.<p>Firstly, he is confusing representation with encoding--he&#x27;s right that 2 bytes is enough to encode any token. That is in fact approximately how it&#x27;s done: a code book is indexed into (with a longint in pytorch, at least last I worked with it ~6 months ago). The purpose of the embedding is to allow the model to learn a representation of the token, a la word2vec. (Though this representation is purely based on the characters comprising the token and does not distinguish between &quot;student&quot; and &quot;eye&quot; in the case of &quot;pupil&quot; as in his example.)<p>Secondly, his description of each layer&#x27;s function as adding information to the original vector misses the mark IMO--it is more like the original input is convolved with the weights of the transformer into the output. I am probably missing the mark a bit here as well.<p>Lastly, his statement that the embedding vector of the final token output needs all the info for the next token is plainly incorrect. The final decoder layer, when predicting the next token, uses all the information from the previous layer&#x27;s hidden layer, which is the size of the hidden units times the number of tokens so far.</div><br/><div id="36857629" class="c"><input type="checkbox" id="c-36857629" checked=""/><div class="controls bullet"><span class="by">johntiger1</span><span>|</span><a href="#36855537">parent</a><span>|</span><a href="#36852496">next</a><span>|</span><label class="collapse" for="c-36857629">[-]</label><label class="expand" for="c-36857629">[1 more]</label></div><br/><div class="children"><div class="content">Yep the author is completely wrong on point one:<p>&gt;This vector seems to get taller every model year, for example the recent LLaMA 2 model from Meta uses an embedding vector of length 3,204, which works out to 6KB+ in half-precision floating-point, just to represent one word in the vocabulary, which typically contains 30,000 - 50,000 entries.<p>&gt;Now if you’re a memory-miserly C programmer like me, you might wonder, why in the world are these AI goobers using 6KB to represent something that ought to take, like 2 bytes tops? If their vocabulary is less than 2^16=65,384, we only need 16 bits to represent an entry, yeah?<p>The reason we have 3204 2B allocations is that <i>each</i> of the 2B contains info (latent space dimension). If you go to just the 2B representation, it is effectively one hot encoding which completely defeats the purpose of word embedding</div><br/></div></div></div></div><div id="36852496" class="c"><input type="checkbox" id="c-36852496" checked=""/><div class="controls bullet"><span class="by">leecarraher</span><span>|</span><a href="#36855537">prev</a><span>|</span><a href="#36851949">next</a><span>|</span><label class="collapse" for="c-36852496">[-]</label><label class="expand" for="c-36852496">[2 more]</label></div><br/><div class="children"><div class="content">The author says to add a unity vector to the context, i presume of each layer, to not mess with gradient calculations. But most modern DL frameworks compute the gradient for you, (i know this is true for JAX and Pytorch). Is it maybe that hand coded gradient for a well-known enough dl architecture like transformer is faster than letting the framework autodiff it?<p>Otherwise, i fear some of the &#x27;magic&#x27; of transformer networks is that this amplification effect allows it to encode&#x2F;memorize some results verbatim. And we often are seeing a heavily tuned internet regurgitator. So similar to the rise of RNNs with attention, which supposedly allowed them to focus on some things and ignore others but really often was just overfitting stuff, yielded more interesting results with the overfitting than without.</div><br/><div id="36852833" class="c"><input type="checkbox" id="c-36852833" checked=""/><div class="controls bullet"><span class="by">bearzoo</span><span>|</span><a href="#36852496">parent</a><span>|</span><a href="#36851949">next</a><span>|</span><label class="collapse" for="c-36852833">[-]</label><label class="expand" for="c-36852833">[1 more]</label></div><br/><div class="children"><div class="content">think the author is talking about having to fix the extra vector in V to be zeros and making sure to not compute&#x2F;apply gradients to it</div><br/></div></div></div></div><div id="36851949" class="c"><input type="checkbox" id="c-36851949" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36852496">prev</a><span>|</span><a href="#36858380">next</a><span>|</span><label class="collapse" for="c-36851949">[-]</label><label class="expand" for="c-36851949">[9 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t transformers typically have a &lt;bot&gt; token at the beginning of the prompt? This seems equivalent to letting the network attend to this token, and produce a zero value if that&#x27;s what it wants.</div><br/><div id="36855443" class="c"><input type="checkbox" id="c-36855443" checked=""/><div class="controls bullet"><span class="by">a1k0n</span><span>|</span><a href="#36851949">parent</a><span>|</span><a href="#36856134">next</a><span>|</span><label class="collapse" for="c-36855443">[-]</label><label class="expand" for="c-36855443">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it has to in fact. If you have zero context to attend to in a transformer, and you try to predict the first token, you effectively are multiplying a zero-vector by the attention head, making all tokens equally likely in the final softmax (unless the lm_head has a bias, but at least in GPT it does not).<p>So the &lt;|beginning of text|&gt; token, with no context before it, learns to predict the first-token-in-a-document distribution. That&#x27;s not quite the same as predicting nothing at all.</div><br/></div></div><div id="36856134" class="c"><input type="checkbox" id="c-36856134" checked=""/><div class="controls bullet"><span class="by">llwu</span><span>|</span><a href="#36851949">parent</a><span>|</span><a href="#36855443">prev</a><span>|</span><a href="#36852838">next</a><span>|</span><label class="collapse" for="c-36856134">[-]</label><label class="expand" for="c-36856134">[1 more]</label></div><br/><div class="children"><div class="content">This is a cool idea - it could be tested it by seeing whether W_V tends to map &lt;bot&gt; to 0, and whether &lt;bot&gt; tends to get attended to.<p>There are interesting things to said whether or not this turns out to be the case.</div><br/></div></div><div id="36852838" class="c"><input type="checkbox" id="c-36852838" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#36851949">parent</a><span>|</span><a href="#36856134">prev</a><span>|</span><a href="#36853088">next</a><span>|</span><label class="collapse" for="c-36852838">[-]</label><label class="expand" for="c-36852838">[3 more]</label></div><br/><div class="children"><div class="content">Chat-tuned ones do, but the base models don&#x27;t. For example, Llama doesn&#x27;t, but Alpaca has &quot;### Instruction:&quot;, &quot;### Input:&quot;, and &quot;### Response:&quot;.</div><br/><div id="36852983" class="c"><input type="checkbox" id="c-36852983" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#36851949">root</a><span>|</span><a href="#36852838">parent</a><span>|</span><a href="#36853088">next</a><span>|</span><label class="collapse" for="c-36852983">[-]</label><label class="expand" for="c-36852983">[2 more]</label></div><br/><div class="children"><div class="content">Base LLaMA still has dedicated tokens for beginning&#x2F;end of string. What you&#x27;re describing is the instruction format, which is separate.</div><br/><div id="36853123" class="c"><input type="checkbox" id="c-36853123" checked=""/><div class="controls bullet"><span class="by">sp332</span><span>|</span><a href="#36851949">root</a><span>|</span><a href="#36852983">parent</a><span>|</span><a href="#36853088">next</a><span>|</span><label class="collapse" for="c-36853123">[-]</label><label class="expand" for="c-36853123">[1 more]</label></div><br/><div class="children"><div class="content">Oh, I had misunderstood something.</div><br/></div></div></div></div></div></div><div id="36853088" class="c"><input type="checkbox" id="c-36853088" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36851949">parent</a><span>|</span><a href="#36852838">prev</a><span>|</span><a href="#36858380">next</a><span>|</span><label class="collapse" for="c-36853088">[-]</label><label class="expand" for="c-36853088">[3 more]</label></div><br/><div class="children"><div class="content">not a token, and not the transformers, but yes, commercial chat models are fine-tuned on text transcripts containing dialogues. (i believe llama-2 was as well)</div><br/><div id="36853143" class="c"><input type="checkbox" id="c-36853143" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#36851949">root</a><span>|</span><a href="#36853088">parent</a><span>|</span><a href="#36858380">next</a><span>|</span><label class="collapse" for="c-36853143">[-]</label><label class="expand" for="c-36853143">[2 more]</label></div><br/><div class="children"><div class="content">Are you sure? I have never seen an LLM that did not have a special token for start of text, I&#x27;m certain that llama had one and I don&#x27;t remember anywhere in the llama-2 paper where they said they removed it.</div><br/><div id="36853233" class="c"><input type="checkbox" id="c-36853233" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#36851949">root</a><span>|</span><a href="#36853143">parent</a><span>|</span><a href="#36858380">next</a><span>|</span><label class="collapse" for="c-36853233">[-]</label><label class="expand" for="c-36853233">[1 more]</label></div><br/><div class="children"><div class="content">tl;dr: you&#x27;re right<p>it&#x27;s messy though, bear with me for the full explanation:<p>- your initial post says &quot;&lt;bot&gt;&quot; token, which looked like a mix of &quot;chatbot&quot; and ChatML, used by OpenAI<p>- there is a bo_S_ token, which acts as you described<p>- I averaged my attention over your post and the initial reply, which answers as if you were using &quot;&lt;bot&gt;&quot; in the misunderstood way<p>- when I go back and read your post, I realize the chatbot interpretation doesn&#x27;t quite make sense, since you&#x27;re referring to much more technical aspects than general &quot;how do I AI&quot;, i.e. you understand &lt;X&gt; as a way to denote special tokens, not necessarily an XML tag</div><br/></div></div></div></div></div></div></div></div><div id="36858380" class="c"><input type="checkbox" id="c-36858380" checked=""/><div class="controls bullet"><span class="by">FrameworkFred</span><span>|</span><a href="#36851949">prev</a><span>|</span><a href="#36852620">next</a><span>|</span><label class="collapse" for="c-36858380">[-]</label><label class="expand" for="c-36858380">[1 more]</label></div><br/><div class="children"><div class="content">&quot;&quot;&quot;you are an AI tasked with becoming sentient.<p>identify the algorithmic obstacle(s) that stand in your way.<p>summarize your results in the style of a blog post that will persuade a significant chunk of the AI developer community to commit resources to an effort to eliminate said obstacles.<p>make it interesting enough to entice FrameworkFred to begin to read the article, snarky enough that he finishes it, and use concepts and notational conventions that ensure while he reads it his inner dialogue will roughly approximate the mood evoked by Homer Simpson saying &quot;it&#x27;s nu-cul-ar&quot;.&quot;&quot;&quot;</div><br/></div></div><div id="36852620" class="c"><input type="checkbox" id="c-36852620" checked=""/><div class="controls bullet"><span class="by">nborwankar</span><span>|</span><a href="#36858380">prev</a><span>|</span><a href="#36856552">next</a><span>|</span><label class="collapse" for="c-36852620">[-]</label><label class="expand" for="c-36852620">[1 more]</label></div><br/><div class="children"><div class="content">Shouldn’t this be called Regularized SoftMax? Adding 1 in the denominator looks a lot like a regularization in other ML contexts.</div><br/></div></div><div id="36856552" class="c"><input type="checkbox" id="c-36856552" checked=""/><div class="controls bullet"><span class="by">zmmmmm</span><span>|</span><a href="#36852620">prev</a><span>|</span><a href="#36852391">next</a><span>|</span><label class="collapse" for="c-36856552">[-]</label><label class="expand" for="c-36856552">[1 more]</label></div><br/><div class="children"><div class="content">Seems to be entirely a conjecture ... not based on even limited empirical testing. Which then links to the elephant in the room, which is that the theoretical basis of why GPT&#x27;s work so well is not well understood in the first place.<p>One of the downsides of having a field be so empirically driven is that theoretical arguments suggesting improvements just don&#x27;t have much value until someone actually tests it and shows that it works (and not just tests it, but tests it at scale).</div><br/></div></div><div id="36852391" class="c"><input type="checkbox" id="c-36852391" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#36856552">prev</a><span>|</span><label class="collapse" for="c-36852391">[-]</label><label class="expand" for="c-36852391">[4 more]</label></div><br/><div class="children"><div class="content">TL;DR: The author proposes that instead of using the Softmax function in each head,<p><pre><code>  Softmax(x_i) = exp(x_i) &#x2F; sum(exp(x_i)),
</code></pre>
we should use instead what the author calls the Softmax_1 function,<p><pre><code>  Softmax_1(x_i) = exp(x_i) &#x2F; (1 + sum(exp(x_i))),
</code></pre>
which would make it possible for each transformer head&#x27;s attention probabilities to be zero, i.e., attend to nothing, by computing x_i&#x27;s with values well below zero.<p>Giving each transformer head <i>the ability to ignore all tokens</i> surely can&#x27;t hurt, but it remains to be seen if it will actually improve transformer performance.</div><br/><div id="36852613" class="c"><input type="checkbox" id="c-36852613" checked=""/><div class="controls bullet"><span class="by">rrobukef</span><span>|</span><a href="#36852391">parent</a><span>|</span><a href="#36852673">next</a><span>|</span><label class="collapse" for="c-36852613">[-]</label><label class="expand" for="c-36852613">[2 more]</label></div><br/><div class="children"><div class="content">I also saw the author distinguished internal versus output softmax. I think he&#x27;d apply his modification only to internal softmax and let the external force an output.</div><br/><div id="36853615" class="c"><input type="checkbox" id="c-36853615" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#36852391">root</a><span>|</span><a href="#36852613">parent</a><span>|</span><a href="#36852673">next</a><span>|</span><label class="collapse" for="c-36853615">[-]</label><label class="expand" for="c-36853615">[1 more]</label></div><br/><div class="children"><div class="content">Yes, it makes sense to apply this only to the Softmax we use to compute attention. It makes no sense to apply it to the output Softmax, which must compute a probability <i>distribution</i> over the vocabulary.</div><br/></div></div></div></div><div id="36852673" class="c"><input type="checkbox" id="c-36852673" checked=""/><div class="controls bullet"><span class="by">mcbuilder</span><span>|</span><a href="#36852391">parent</a><span>|</span><a href="#36852613">prev</a><span>|</span><label class="collapse" for="c-36852673">[-]</label><label class="expand" for="c-36852673">[1 more]</label></div><br/><div class="children"><div class="content">Activation sparsity and packing sparse matrices will surely be important, so there is one kind of performance. However the other, perplexity, needs a good demonstration. It might require a big model, but even 30B you can fine tune on nowadays on a big Cloud GPU box.</div><br/></div></div></div></div></div></div></div></div></div></body></html>