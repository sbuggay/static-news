<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735635663378" as="style"/><link rel="stylesheet" href="styles.css?v=1735635663378"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://bellard.org/ts_sms/">Short Message Compression Using LLMs</a> <span class="domain">(<a href="https://bellard.org">bellard.org</a>)</span></div><div class="subtext"><span>chunkles</span> | <span>102 comments</span></div><br/><div><div id="42550929" class="c"><input type="checkbox" id="c-42550929" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42557419">next</a><span>|</span><label class="collapse" for="c-42550929">[-]</label><label class="expand" for="c-42550929">[32 more]</label></div><br/><div class="children"><div class="content">The way this works is awesome. If I understand correctly, it&#x27;s like that, given (part of) a sentence, the next token really in the sequence will be one predicted by the model among the top scoring ones, so most next tokens can be mapped to very low numbers (0 if the actual next token it&#x27;s the best token in the LLM prediction, 1 if it is the second best, ...). This small numbers can be encoded very efficiently using trivial old techniques. And boom: done.<p>So for instance:<p>&gt; In my pasta I put a lot of [cheese]<p>LLM top N tokens for &quot;In my pasta I put a lot of&quot; will be [0:tomato, 1:cheese, 2:oil]<p>The real next token is &quot;cheese&quot; so I&#x27;ll store &quot;1&quot;.<p>Well, this is neat, but also very computationally expensive :D So for my small ESP32 LoRa devices I used this: <a href="https:&#x2F;&#x2F;github.com&#x2F;antirez&#x2F;smaz2">https:&#x2F;&#x2F;github.com&#x2F;antirez&#x2F;smaz2</a>
And so forth.</div><br/><div id="42552286" class="c"><input type="checkbox" id="c-42552286" checked=""/><div class="controls bullet"><span class="by">gliptic</span><span>|</span><a href="#42550929">parent</a><span>|</span><a href="#42552081">next</a><span>|</span><label class="collapse" for="c-42552286">[-]</label><label class="expand" for="c-42552286">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;m pretty sure it doesn&#x27;t use ranking. That leaves a lot of performance on the table. Instead you would use the actual predicted token probabilities and arithmetic coding.</div><br/><div id="42552425" class="c"><input type="checkbox" id="c-42552425" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552286">parent</a><span>|</span><a href="#42552081">next</a><span>|</span><label class="collapse" for="c-42552425">[-]</label><label class="expand" for="c-42552425">[8 more]</label></div><br/><div class="children"><div class="content">I supposed it used arithmetic coding with the ranking bacause they have a distribution easy to exploit: zero more likely, one a bit less and so forth. What&#x27;s your guess? Unfortunately Bellard is as smart as hermetic. We are here guessing what should be a README file.</div><br/><div id="42552481" class="c"><input type="checkbox" id="c-42552481" checked=""/><div class="controls bullet"><span class="by">gliptic</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552425">parent</a><span>|</span><a href="#42556106">next</a><span>|</span><label class="collapse" for="c-42552481">[-]</label><label class="expand" for="c-42552481">[2 more]</label></div><br/><div class="children"><div class="content">The model gives you a probability distribution over the tokens. You could use that directly with arithmetic coding, but there are ways to convert that to a distribution over e.g. the next byte instead which would improve efficiency further by removing the redundancy in alternative token encodings. ts_zip does this, and README says this works similar to ts_zip.<p>EDIT: Hm, or maybe ts_zip uses just the token probabilities directly. I thought it was slightly more efficient about it.<p>&quot;The language model predicts the probabilities of the next token. An arithmetic coder then encodes the next token according to the probabilities.&quot;</div><br/><div id="42552568" class="c"><input type="checkbox" id="c-42552568" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552481">parent</a><span>|</span><a href="#42556106">next</a><span>|</span><label class="collapse" for="c-42552568">[-]</label><label class="expand" for="c-42552568">[1 more]</label></div><br/><div class="children"><div class="content">Oh, that makes sense! So they use the probability of the next token itself. Thanks for clarifying. Also clever trick about the multiple potential tokens to represent the same text.</div><br/></div></div></div></div><div id="42556106" class="c"><input type="checkbox" id="c-42556106" checked=""/><div class="controls bullet"><span class="by">bravura</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552425">parent</a><span>|</span><a href="#42552481">prev</a><span>|</span><a href="#42552652">next</a><span>|</span><label class="collapse" for="c-42556106">[-]</label><label class="expand" for="c-42556106">[1 more]</label></div><br/><div class="children"><div class="content">antirez, it&#x27;s probably identical to the approach in this paper: 
Li et al 2024, &quot;Evaluating Large Language Models for Generalization and Robustness via Data Compression&quot; (<a href="https:&#x2F;&#x2F;ar5iv.labs.arxiv.org&#x2F;html&#x2F;&#x2F;2402.00861" rel="nofollow">https:&#x2F;&#x2F;ar5iv.labs.arxiv.org&#x2F;html&#x2F;&#x2F;2402.00861</a>).<p>There&#x27;s a pretty straight line from assigning probabilities (to a sequence of tokens) to arithmetic compression as an optimal compression algorithm for that distribution.</div><br/></div></div><div id="42552652" class="c"><input type="checkbox" id="c-42552652" checked=""/><div class="controls bullet"><span class="by">gus_massa</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552425">parent</a><span>|</span><a href="#42556106">prev</a><span>|</span><a href="#42552081">next</a><span>|</span><label class="collapse" for="c-42552652">[-]</label><label class="expand" for="c-42552652">[4 more]</label></div><br/><div class="children"><div class="content">If you are going to zip the resulting file, it may be useful to have a lot of 0s.<p>If you are going to send the result as is,
 Huffman coding (with some escape for unusal words(?)) will be better. I think even better than the other method that forgets the probabilities and then tries to compresd it.</div><br/><div id="42552678" class="c"><input type="checkbox" id="c-42552678" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552652">parent</a><span>|</span><a href="#42552081">next</a><span>|</span><label class="collapse" for="c-42552678">[-]</label><label class="expand" for="c-42552678">[3 more]</label></div><br/><div class="children"><div class="content">Just to clarify: even storing ranking, here would likely produce good results, but not as good as storing the probability, since it exploits better the ability of arithmetic coding to store this fractional intervals. But here the fundamental trick is that the LLM can compress the &quot;next in sequence&quot; information in a distribution that is much better to compress than the initial data itself.</div><br/><div id="42552753" class="c"><input type="checkbox" id="c-42552753" checked=""/><div class="controls bullet"><span class="by">gliptic</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552678">parent</a><span>|</span><a href="#42552081">next</a><span>|</span><label class="collapse" for="c-42552753">[-]</label><label class="expand" for="c-42552753">[2 more]</label></div><br/><div class="children"><div class="content">This is especially true for instance when you have two or more tokens that are about equally likely, or one token that is virtually certain, which ranking would obscure.</div><br/><div id="42553396" class="c"><input type="checkbox" id="c-42553396" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552753">parent</a><span>|</span><a href="#42552081">next</a><span>|</span><label class="collapse" for="c-42553396">[-]</label><label class="expand" for="c-42553396">[1 more]</label></div><br/><div class="children"><div class="content">Indeed.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42552081" class="c"><input type="checkbox" id="c-42552081" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42550929">parent</a><span>|</span><a href="#42552286">prev</a><span>|</span><a href="#42551933">next</a><span>|</span><label class="collapse" for="c-42552081">[-]</label><label class="expand" for="c-42552081">[2 more]</label></div><br/><div class="children"><div class="content">This is very similar to how many compression schemes work. Look up Huffman coding to begin with.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Huffman_coding" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Huffman_coding</a></div><br/><div id="42552236" class="c"><input type="checkbox" id="c-42552236" checked=""/><div class="controls bullet"><span class="by">nzach</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552081">parent</a><span>|</span><a href="#42551933">next</a><span>|</span><label class="collapse" for="c-42552236">[-]</label><label class="expand" for="c-42552236">[1 more]</label></div><br/><div class="children"><div class="content">For anyone interested in this topic, Primeagen has a pretty great video on how he used several encoding schemes to save bandwidth in one of his projects.<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3f9tbqSIm-E" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3f9tbqSIm-E</a></div><br/></div></div></div></div><div id="42551933" class="c"><input type="checkbox" id="c-42551933" checked=""/><div class="controls bullet"><span class="by">ai-christianson</span><span>|</span><a href="#42550929">parent</a><span>|</span><a href="#42552081">prev</a><span>|</span><a href="#42554201">next</a><span>|</span><label class="collapse" for="c-42551933">[-]</label><label class="expand" for="c-42551933">[3 more]</label></div><br/><div class="children"><div class="content">Seems like an ideal compression method for LoRa&#x2F;Meshtastic-style communication. An LLM wouldn&#x27;t run on an ESP32, but there are several that could run on a raspberry pi.<p>It&#x27;s not just natural language that could be compressed this way, either. Code (HTML, JS, etc) could be compressed with the same technique&#x2F;models. I bet that the same general idea could work for image compression as well, using an image&#x2F;diffusion model (or perhaps a multimodal model for everything.)<p>This could lead to an entire internet of content using just a few bits.</div><br/><div id="42556815" class="c"><input type="checkbox" id="c-42556815" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42551933">parent</a><span>|</span><a href="#42555431">next</a><span>|</span><label class="collapse" for="c-42556815">[-]</label><label class="expand" for="c-42556815">[1 more]</label></div><br/><div class="children"><div class="content">The key insight is that the larger the shared context between parties, the more efficient communication can be, as communication tends towards a purely relational construct. The limit of this is two parties that both share the exact same context and inputs, the inputs should produce the same hidden state within both parties and communication is not even necessary because both parties have the same knowledge and state.<p>That&#x27;s not new to anyone familiar with compression or information theory, but the novelty here is the LLM itself. It&#x27;s absolutely plausible that, given an already highly compressed relationally-encoded context like a trained LLM, very few bits could be communicated to communicate very abstract and complex ideas, letting the LLM recontextualize information which has been compressed across several semantic and contextual layers, effectively leveraging a complete (but lossy) history of human knowledge against every single bit of information communicated.</div><br/></div></div><div id="42555431" class="c"><input type="checkbox" id="c-42555431" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42551933">parent</a><span>|</span><a href="#42556815">prev</a><span>|</span><a href="#42554201">next</a><span>|</span><label class="collapse" for="c-42555431">[-]</label><label class="expand" for="c-42555431">[1 more]</label></div><br/><div class="children"><div class="content">LORA is also pretty slow,  like the &#x27;long fast&#x27; mode that most meshtastic users use is about a kilobit per second... and presumably a small percentage of the traffic at any time is traffic in channels that you&#x27;re monitoring.<p>Probably decoding few tokens per second is fast enough to deliver more goodput than the existing uncompressed usage.</div><br/></div></div></div></div><div id="42551388" class="c"><input type="checkbox" id="c-42551388" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42550929">parent</a><span>|</span><a href="#42554201">prev</a><span>|</span><a href="#42556517">next</a><span>|</span><label class="collapse" for="c-42551388">[-]</label><label class="expand" for="c-42551388">[14 more]</label></div><br/><div class="children"><div class="content">It&#x27;d be a fun experiment to try making it lossy.<p>You could adjust tokens towards what&#x27;s more statistically probable, and therefore more compressible (in your example, it&#x27;d be picking tomato instead of cheese)</div><br/><div id="42552409" class="c"><input type="checkbox" id="c-42552409" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42551388">parent</a><span>|</span><a href="#42551465">next</a><span>|</span><label class="collapse" for="c-42552409">[-]</label><label class="expand" for="c-42552409">[8 more]</label></div><br/><div class="children"><div class="content">I could see that as a plot point in a science fiction story: Intergalactic telegrams are prohibitively expensive, so before sending one you&#x27;re offered various variants of your text that amount to the same thing but save data due to using more generic (per zeitgeist) language :)<p>Compare also with commercial code [1], a close historical analog, albeit with handcrafted, as opposed to ML-derived, compression tables. (There was a single code point for &quot;twins, born alive and well, one boy and one girl&quot;, for example! [2])<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Commercial_code_(communications)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Commercial_code_(communication...</a><p>[2] <a href="https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;unicodeuniversa00unkngoog&#x2F;" rel="nofollow">https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;unicodeuniversa00unkngoog&#x2F;</a></div><br/><div id="42552687" class="c"><input type="checkbox" id="c-42552687" checked=""/><div class="controls bullet"><span class="by">duskwuff</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552409">parent</a><span>|</span><a href="#42551465">next</a><span>|</span><label class="collapse" for="c-42552687">[-]</label><label class="expand" for="c-42552687">[7 more]</label></div><br/><div class="children"><div class="content">Comes up as a minor plot point in Vernor Vinge&#x27;s <i>The Blabber</i> (1988):<p>&gt; “And from your standpoint, Hamid, there’s one big drawback. The mean bandwidth of this thing [<i>an ansible, more or less</i>] is just under six bits per minute.”<p>&gt; “Huh? Ten seconds to send a single bit?”<p>&gt; “Yup. Skandr left three protocols at the Lothlrimarre end: ASCII, a Hamming map to a subset of English, and an AI scheme that guesses what you’d say if you used more bits. The first is Skandr’s idea of a joke, and I wouldn’t trust the third more than wishful thinking.”<p>(Good advice at the end there.)</div><br/><div id="42554159" class="c"><input type="checkbox" id="c-42554159" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42552687">parent</a><span>|</span><a href="#42551465">next</a><span>|</span><label class="collapse" for="c-42554159">[-]</label><label class="expand" for="c-42554159">[6 more]</label></div><br/><div class="children"><div class="content">A bit of an aside- in one of the sequels to A Fire Upon the Deep, somebody has to interpret some very lossy audio and video into the most likely explanation, but they are stuck with a stupider than usual AI and it misinterprets the results (it&#x27;s implied if they had their full AI it would have gotten the interpretation correct even with the ambiguity).  This episode in the book completely changed how I think about imputation under uncertainty.  Often, I don&#x27;t want a single high confidence prediction, I want a probability distribution of the most likely predictions, rank ordered.</div><br/><div id="42554379" class="c"><input type="checkbox" id="c-42554379" checked=""/><div class="controls bullet"><span class="by">wat10000</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42554159">parent</a><span>|</span><a href="#42551465">next</a><span>|</span><label class="collapse" for="c-42554379">[-]</label><label class="expand" for="c-42554379">[5 more]</label></div><br/><div class="children"><div class="content"><i>Fire</i> has evocations, which are videos compressed down to something like just a description, then rendered at the receiving end in a way that hopefully has some resemblance to the original.<p>One viewer stumbles onto a key insight about the struggle taking place, but they only have evocations so they’re not sure. And they sound like a total kook so everyone ignores them.</div><br/><div id="42556161" class="c"><input type="checkbox" id="c-42556161" checked=""/><div class="controls bullet"><span class="by">askvictor</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42554379">parent</a><span>|</span><a href="#42554893">next</a><span>|</span><label class="collapse" for="c-42556161">[-]</label><label class="expand" for="c-42556161">[2 more]</label></div><br/><div class="children"><div class="content">I shudder to think how current LLMs would go with this. I guess we can currently do this easily for still images and audio. Kind of reminds me of Translation Party.</div><br/><div id="42556198" class="c"><input type="checkbox" id="c-42556198" checked=""/><div class="controls bullet"><span class="by">duskwuff</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42556161">parent</a><span>|</span><a href="#42554893">next</a><span>|</span><label class="collapse" for="c-42556198">[-]</label><label class="expand" for="c-42556198">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Hexapodia is the key insight.&quot;</div><br/></div></div></div></div><div id="42554893" class="c"><input type="checkbox" id="c-42554893" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42554379">parent</a><span>|</span><a href="#42556161">prev</a><span>|</span><a href="#42551465">next</a><span>|</span><label class="collapse" for="c-42554893">[-]</label><label class="expand" for="c-42554893">[2 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t find an exact reference and I don&#x27;t want to spoil too much, I think this was in Children of the Sky, at some point one of the wolf creatures is imprisoned and somebody uses the ship&#x27;s reduced AI to spy on them.</div><br/><div id="42556028" class="c"><input type="checkbox" id="c-42556028" checked=""/><div class="controls bullet"><span class="by">abecedarius</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42554893">parent</a><span>|</span><a href="#42551465">next</a><span>|</span><label class="collapse" for="c-42556028">[-]</label><label class="expand" for="c-42556028">[1 more]</label></div><br/><div class="children"><div class="content">Slight correction: the person with the spy system didn&#x27;t believe its reports in the end -- the doubt&#x2F;dismissal problem came before sharing with others, as I remember it. Agreed this was in Children of the Sky.<p>(aFutD also had a case of high-stakes suspicion of highly compressed messages during Zone turbulence, as I think the GP meant.)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42551465" class="c"><input type="checkbox" id="c-42551465" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42551388">parent</a><span>|</span><a href="#42552409">prev</a><span>|</span><a href="#42556517">next</a><span>|</span><label class="collapse" for="c-42551465">[-]</label><label class="expand" for="c-42551465">[5 more]</label></div><br/><div class="children"><div class="content">Yep. For lossy what could work even better is an encoder-decoder model, so that it is possible to just save the embedding, and later the embedding will be turned back into the meaning.</div><br/><div id="42551516" class="c"><input type="checkbox" id="c-42551516" checked=""/><div class="controls bullet"><span class="by">srush</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42551465">parent</a><span>|</span><a href="#42556517">next</a><span>|</span><label class="collapse" for="c-42551516">[-]</label><label class="expand" for="c-42551516">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve tried to build sort of model several times, but could never get it to work. The challenge is that small perturbations in encoder space lead to removing semantically important details (e.g. dates). You really want these to mess up syntax instead to get something more analogous to a lossy video encoder.</div><br/><div id="42551573" class="c"><input type="checkbox" id="c-42551573" checked=""/><div class="controls bullet"><span class="by">antirez</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42551516">parent</a><span>|</span><a href="#42555503">next</a><span>|</span><label class="collapse" for="c-42551573">[-]</label><label class="expand" for="c-42551573">[2 more]</label></div><br/><div class="children"><div class="content">Yep, makes sense... Something like 20 years ago I experimented with encoder&#x2F;decoder models for lossy images compression and it worked very well, but it&#x27;s a completely different domain indeed, where there aren&#x27;t single local concentration of entropy that messes with the whole result.</div><br/><div id="42557424" class="c"><input type="checkbox" id="c-42557424" checked=""/><div class="controls bullet"><span class="by">mikaraento</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42551573">parent</a><span>|</span><a href="#42555503">next</a><span>|</span><label class="collapse" for="c-42557424">[-]</label><label class="expand" for="c-42557424">[1 more]</label></div><br/><div class="children"><div class="content">I guess text in images would be similar, and is indeed where image generation models struggle to get the details right.<p>E.g., making a greeting card with somebody&#x27;s name spelled correctly.</div><br/></div></div></div></div><div id="42555503" class="c"><input type="checkbox" id="c-42555503" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#42550929">root</a><span>|</span><a href="#42551516">parent</a><span>|</span><a href="#42551573">prev</a><span>|</span><a href="#42556517">next</a><span>|</span><label class="collapse" for="c-42555503">[-]</label><label class="expand" for="c-42555503">[1 more]</label></div><br/><div class="children"><div class="content">I built a lossy text compressor in the days before LLMs.<p>I used a word embedding to convert the text to a space where similar tokens had similar semantic meaning, then I modified an ordinary LZ encoder to choose cheaper tokens if they were &#x27;close enough&#x27; according to some tunable loss parameter.<p>It &quot;worked&quot;, but was better at producing amusing outputs than any other purpose. Perhaps you wouldn&#x27;t have considered that working!<p>In terms of a modern implementation using an LLM, I would think that I could improve the retention of details like that by adapting the loss parameter based on the flatness of the model. E.g. for a date the model may be confident that the figures are numbers but pretty uniform among the numbers.  Though I bet those details you want to preserve have a lot of the document&#x27;s actual entropy.</div><br/></div></div></div></div></div></div></div></div><div id="42556517" class="c"><input type="checkbox" id="c-42556517" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#42550929">parent</a><span>|</span><a href="#42551388">prev</a><span>|</span><a href="#42553248">next</a><span>|</span><label class="collapse" for="c-42556517">[-]</label><label class="expand" for="c-42556517">[1 more]</label></div><br/><div class="children"><div class="content"><i>very computationally expensive</i><p>The same goes for all the other higher-order probability models, which are used in what is currently the best known compression algorithm:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;PAQ" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;PAQ</a><p>LLMs are just another way to do the probability modeling.</div><br/></div></div></div></div><div id="42557419" class="c"><input type="checkbox" id="c-42557419" checked=""/><div class="controls bullet"><span class="by">the5avage</span><span>|</span><a href="#42550929">prev</a><span>|</span><a href="#42556581">next</a><span>|</span><label class="collapse" for="c-42557419">[-]</label><label class="expand" for="c-42557419">[1 more]</label></div><br/><div class="children"><div class="content">Is there a paper explaining it in more detail? I also saw on his website he has a similar algorithm for audio compression...</div><br/></div></div><div id="42556581" class="c"><input type="checkbox" id="c-42556581" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#42557419">prev</a><span>|</span><a href="#42550868">next</a><span>|</span><label class="collapse" for="c-42556581">[-]</label><label class="expand" for="c-42556581">[3 more]</label></div><br/><div class="children"><div class="content">The download is 153MB, compressed... didn&#x27;t even bother to wait for it to finish once I saw the size.<p>The brotli comparison is IMHO slightly misleading. Yes, it &quot;embeds a dictionary to optimize the compression of small messages&quot;, but that dictionary is a few orders of magnitude smaller than the embedded &quot;dictionary&quot; which is the LLM in ts_sms.<p>There&#x27;s a reason the Hutter Prize (and the demoscene) counts the <i>whole</i> data necessary to reproduce its output.  In other words, ts_sms took around 18 bytes + ~152MB while brotli took around 70 bytes + ~128KB (approximately size of its dictionary and decompressor.)</div><br/><div id="42556695" class="c"><input type="checkbox" id="c-42556695" checked=""/><div class="controls bullet"><span class="by">theamk</span><span>|</span><a href="#42556581">parent</a><span>|</span><a href="#42556647">next</a><span>|</span><label class="collapse" for="c-42556695">[-]</label><label class="expand" for="c-42556695">[1 more]</label></div><br/><div class="children"><div class="content">Life is more than that competitions?<p>For example, antirez mentioned LoRa in the earlier thread - that&#x27;s a cheap, license-free radio, which achieves a large range at the expense of low rate (250 bit&#x2F;sec). That&#x27;s 30 bytes&#x2F;second, not including framing overhead and retransmission.<p>If you wanted to build a communication system out of those, this compression method would be great. You&#x27;d have LORA device that connects to a regular cell phone and provides connectivity, and all the compression&#x2F;decompression and UI happens on the cell phone. 150MB is nothing for modern phones, but you&#x27;d see a real improvement in message speed.</div><br/></div></div><div id="42556647" class="c"><input type="checkbox" id="c-42556647" checked=""/><div class="controls bullet"><span class="by">f33d5173</span><span>|</span><a href="#42556581">parent</a><span>|</span><a href="#42556695">prev</a><span>|</span><a href="#42550868">next</a><span>|</span><label class="collapse" for="c-42556647">[-]</label><label class="expand" for="c-42556647">[1 more]</label></div><br/><div class="children"><div class="content">You can compress arbitrarily many messages with it, and the dictionary remains 153MB. Why it&#x27;s worth pointing out that brotli already uses a dictionary is that otherwise it would be generating the dictionary as it compressed, meaning that short messages would be pessimized. So brotli is in some sense the state of the art for short messages.</div><br/></div></div></div></div><div id="42550868" class="c"><input type="checkbox" id="c-42550868" checked=""/><div class="controls bullet"><span class="by">kianN</span><span>|</span><a href="#42556581">prev</a><span>|</span><a href="#42551407">next</a><span>|</span><label class="collapse" for="c-42550868">[-]</label><label class="expand" for="c-42550868">[4 more]</label></div><br/><div class="children"><div class="content">For those wondering how it works:<p>&gt; The language model predicts the probabilities of the next token. An arithmetic coder then encodes the next token according to the probabilities. [1]<p>It’s also mentioned that the model is configured to be deterministic, which is how I would guess the decompression is able to map a set of token likelihoods to the original token?<p>[1] <a href="https:&#x2F;&#x2F;bellard.org&#x2F;ts_zip&#x2F;" rel="nofollow">https:&#x2F;&#x2F;bellard.org&#x2F;ts_zip&#x2F;</a></div><br/><div id="42552999" class="c"><input type="checkbox" id="c-42552999" checked=""/><div class="controls bullet"><span class="by">kvemkon</span><span>|</span><a href="#42550868">parent</a><span>|</span><a href="#42552701">next</a><span>|</span><label class="collapse" for="c-42552999">[-]</label><label class="expand" for="c-42552999">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ts_zip<p>Discussed (once more) in a neighbor thread: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42549083">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42549083</a></div><br/></div></div><div id="42552701" class="c"><input type="checkbox" id="c-42552701" checked=""/><div class="controls bullet"><span class="by">cyptus</span><span>|</span><a href="#42550868">parent</a><span>|</span><a href="#42552999">prev</a><span>|</span><a href="#42551407">next</a><span>|</span><label class="collapse" for="c-42552701">[-]</label><label class="expand" for="c-42552701">[2 more]</label></div><br/><div class="children"><div class="content">isn’t a LLM itself basically a compression of the texts from the internet? you can download the model and decompress the (larger) content with compute power (lossy)</div><br/><div id="42553144" class="c"><input type="checkbox" id="c-42553144" checked=""/><div class="controls bullet"><span class="by">kianN</span><span>|</span><a href="#42550868">root</a><span>|</span><a href="#42552701">parent</a><span>|</span><a href="#42551407">next</a><span>|</span><label class="collapse" for="c-42553144">[-]</label><label class="expand" for="c-42553144">[1 more]</label></div><br/><div class="children"><div class="content">Yeah that’s exactly how I think of llms in my head: lossy compression that interpolates in order to fill in gaps. Hallucination is simply interpolation error. Which is guaranteed in lossy compression.</div><br/></div></div></div></div></div></div><div id="42551407" class="c"><input type="checkbox" id="c-42551407" checked=""/><div class="controls bullet"><span class="by">tshaddox</span><span>|</span><a href="#42550868">prev</a><span>|</span><a href="#42550949">next</a><span>|</span><label class="collapse" for="c-42551407">[-]</label><label class="expand" for="c-42551407">[13 more]</label></div><br/><div class="children"><div class="content">This is obviously relevant to the Hutter Prize, which is intended to incentivize AI research by awarding cash to people who can losslessly compress a large English text corpus:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hutter_Prize" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hutter_Prize</a><p>From a cursory web search it doesn&#x27;t appear that LLMs have been useful for this particular challenge, presumably because the challenge imposes rather strict size, CPU, and memory constraints.</div><br/><div id="42552698" class="c"><input type="checkbox" id="c-42552698" checked=""/><div class="controls bullet"><span class="by">willvarfar</span><span>|</span><a href="#42551407">parent</a><span>|</span><a href="#42551552">next</a><span>|</span><label class="collapse" for="c-42552698">[-]</label><label class="expand" for="c-42552698">[3 more]</label></div><br/><div class="children"><div class="content">This compressor is by a certain Fabrice Bellard, an overactive overachiving powerhouse of a programmer who happens to be leading the Large Text Compression Benchmark <a href="https:&#x2F;&#x2F;www.mattmahoney.net&#x2F;dc&#x2F;text.html" rel="nofollow">https:&#x2F;&#x2F;www.mattmahoney.net&#x2F;dc&#x2F;text.html</a>, which is maintained by Matt Mahoney who happens to run the Hutter Prize :)<p>Fabrice also makes some programs you might use, like FFMEG and QEMU<p><a href="https:&#x2F;&#x2F;bellard.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;bellard.org&#x2F;</a></div><br/><div id="42554032" class="c"><input type="checkbox" id="c-42554032" checked=""/><div class="controls bullet"><span class="by">TacticalCoder</span><span>|</span><a href="#42551407">root</a><span>|</span><a href="#42552698">parent</a><span>|</span><a href="#42553259">next</a><span>|</span><label class="collapse" for="c-42554032">[-]</label><label class="expand" for="c-42554032">[1 more]</label></div><br/><div class="children"><div class="content">&gt; FFMEG<p>For those unaware, it&#x27;s a typo. willvarfar meant FFMPEG.</div><br/></div></div><div id="42553259" class="c"><input type="checkbox" id="c-42553259" checked=""/><div class="controls bullet"><span class="by">berbec</span><span>|</span><a href="#42551407">root</a><span>|</span><a href="#42552698">parent</a><span>|</span><a href="#42554032">prev</a><span>|</span><a href="#42551552">next</a><span>|</span><label class="collapse" for="c-42553259">[-]</label><label class="expand" for="c-42553259">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Fabrice also makes some programs you might use, like FFMEG and QEMU<p>This would be the one sentence that wouldn&#x27;t cause me to look down on somoene, if used as a third-person humble-brag.</div><br/></div></div></div></div><div id="42551552" class="c"><input type="checkbox" id="c-42551552" checked=""/><div class="controls bullet"><span class="by">evertedsphere</span><span>|</span><a href="#42551407">parent</a><span>|</span><a href="#42552698">prev</a><span>|</span><a href="#42551458">next</a><span>|</span><label class="collapse" for="c-42551552">[-]</label><label class="expand" for="c-42551552">[3 more]</label></div><br/><div class="children"><div class="content">it&#x27;s simpler: the hutter prize imposes a 110M constraint on the sum of the sizes of your program (including any data it needs to run) and the compressed data<p>llms are generally large</div><br/><div id="42552732" class="c"><input type="checkbox" id="c-42552732" checked=""/><div class="controls bullet"><span class="by">gliptic</span><span>|</span><a href="#42551407">root</a><span>|</span><a href="#42551552">parent</a><span>|</span><a href="#42552282">next</a><span>|</span><label class="collapse" for="c-42552732">[-]</label><label class="expand" for="c-42552732">[1 more]</label></div><br/><div class="children"><div class="content">This could be circumvented by _training_ the LLM on the fly on the previously observed file data. This is what Bellard&#x27;s other NN compressor, nncp, does [1], which is currently #1 on Mahoney&#x27;s benchmark [2]. Unfortunately this is too slow, especially running on the CPU as Hutter&#x27;s challenge stipulates IIRC.<p>[1] <a href="https:&#x2F;&#x2F;bellard.org&#x2F;nncp&#x2F;" rel="nofollow">https:&#x2F;&#x2F;bellard.org&#x2F;nncp&#x2F;</a><p>[2] <a href="http:&#x2F;&#x2F;mattmahoney.net&#x2F;dc&#x2F;text.html" rel="nofollow">http:&#x2F;&#x2F;mattmahoney.net&#x2F;dc&#x2F;text.html</a></div><br/></div></div></div></div><div id="42551458" class="c"><input type="checkbox" id="c-42551458" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42551407">parent</a><span>|</span><a href="#42551552">prev</a><span>|</span><a href="#42550949">next</a><span>|</span><label class="collapse" for="c-42551458">[-]</label><label class="expand" for="c-42551458">[6 more]</label></div><br/><div class="children"><div class="content">More because lossy compression is what&#x27;s been analogized to intelligence and this prize is doing a sleight of hand to insert lossless compression as if that doesn&#x27;t make a difference. That&#x27;s more why LLMs aren&#x27;t really all that useful.</div><br/><div id="42552101" class="c"><input type="checkbox" id="c-42552101" checked=""/><div class="controls bullet"><span class="by">tshaddox</span><span>|</span><a href="#42551407">root</a><span>|</span><a href="#42551458">parent</a><span>|</span><a href="#42550949">next</a><span>|</span><label class="collapse" for="c-42552101">[-]</label><label class="expand" for="c-42552101">[5 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t call that a sleight of hand. Surely better lossy compression can be trivially used to implement better lossless compression, and the latter is just much easier to quantify for a benchmark.</div><br/><div id="42552355" class="c"><input type="checkbox" id="c-42552355" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42551407">root</a><span>|</span><a href="#42552101">parent</a><span>|</span><a href="#42550949">next</a><span>|</span><label class="collapse" for="c-42552355">[-]</label><label class="expand" for="c-42552355">[4 more]</label></div><br/><div class="children"><div class="content">Not a single lossless compression technique I’m aware of starts of in lossy compression.<p>They have different goals and utilize completely different techniques.<p>At most lossy techniques leverage lossless techniques (eg to compress non-perceptual binary headers) not the other way round.</div><br/><div id="42552606" class="c"><input type="checkbox" id="c-42552606" checked=""/><div class="controls bullet"><span class="by">leijurv</span><span>|</span><a href="#42551407">root</a><span>|</span><a href="#42552355">parent</a><span>|</span><a href="#42550949">next</a><span>|</span><label class="collapse" for="c-42552606">[-]</label><label class="expand" for="c-42552606">[3 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s the submission that won the Hutter Prize in 2021: <a href="https:&#x2F;&#x2F;github.com&#x2F;amargaritov&#x2F;starlit">https:&#x2F;&#x2F;github.com&#x2F;amargaritov&#x2F;starlit</a> It uses a LSTM to predict the next token lossily, then uses <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Arithmetic_coding" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Arithmetic_coding</a> to convert that to lossless compression. Lossless compression can definitely leverage a lossy compressor, such as via arithmetic coding. Also see: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Context-adaptive_binary_arithmetic_coding" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Context-adaptive_binary_arithm...</a> which has a simple &quot;Example&quot; section - imagine if the top prediction made by your neural network was correct, you emit &quot;0&quot;, if the 2nd was correct, you emit &quot;10&quot;, if the 3rd, &quot;110&quot;, if the 4th, &quot;1110&quot;. As you can see, this is lossless, but the fundamental prediction is lossy, and the better that prediction is, the better the compression. (In actuality, you wouldn&#x27;t waste your 1 bits like this, you&#x27;d use arithmetic coding instead).</div><br/><div id="42552733" class="c"><input type="checkbox" id="c-42552733" checked=""/><div class="controls bullet"><span class="by">willvarfar</span><span>|</span><a href="#42551407">root</a><span>|</span><a href="#42552606">parent</a><span>|</span><a href="#42553586">next</a><span>|</span><label class="collapse" for="c-42552733">[-]</label><label class="expand" for="c-42552733">[1 more]</label></div><br/><div class="children"><div class="content">Yes, one way to think about arithmetic compression is encoding the difference between the prediction and reality.<p>This isn&#x27;t normally what people mean by lossy compression, though.  In lossy compression (e.g. mainstream media compression like JPEG) you work out what the user doesn&#x27;t value and throw it away.</div><br/></div></div><div id="42553586" class="c"><input type="checkbox" id="c-42553586" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#42551407">root</a><span>|</span><a href="#42552606">parent</a><span>|</span><a href="#42552733">prev</a><span>|</span><a href="#42550949">next</a><span>|</span><label class="collapse" for="c-42553586">[-]</label><label class="expand" for="c-42553586">[1 more]</label></div><br/><div class="children"><div class="content">This is standard lossless compression. None of the concepts particular to lossy compression (like rate-distortion theory) are used.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42550949" class="c"><input type="checkbox" id="c-42550949" checked=""/><div class="controls bullet"><span class="by">giovannibonetti</span><span>|</span><a href="#42551407">prev</a><span>|</span><a href="#42556734">next</a><span>|</span><label class="collapse" for="c-42550949">[-]</label><label class="expand" for="c-42550949">[8 more]</label></div><br/><div class="children"><div class="content">Regarding lossless text compression, does anyone know how a simple way to compress repetitive JSON(B) data in a regular Postgres table? Ideally I would use columnar compression [1], but I&#x27;m limited to the extensions supported by Google Cloud SQL [2].<p>Since my JSON(B) data is fairly repetitive, my bet would be to store some sort of JSON schema in a parent table. I&#x27;m storing the response body from a API call to a third-party API, so normalizing it by hand is probably out of the question.<p>I wonder if Avro can be helpful for storing the JSON schema. Even if I had to create custom PL&#x2F;SQL functions for my top 10 JSON schemas it would be ok, since the data is growing very quickly and I imagine it could be compressed at least 10x compared to regular JSON or JSONB columns.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;citusdata&#x2F;citus?tab=readme-ov-file#creating-tables-with-columnar-storage">https:&#x2F;&#x2F;github.com&#x2F;citusdata&#x2F;citus?tab=readme-ov-file#creati...</a>
[2] <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;sql&#x2F;docs&#x2F;postgres&#x2F;extensions" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;sql&#x2F;docs&#x2F;postgres&#x2F;extensions</a></div><br/><div id="42557187" class="c"><input type="checkbox" id="c-42557187" checked=""/><div class="controls bullet"><span class="by">Too</span><span>|</span><a href="#42550949">parent</a><span>|</span><a href="#42551197">next</a><span>|</span><label class="collapse" for="c-42557187">[-]</label><label class="expand" for="c-42557187">[1 more]</label></div><br/><div class="children"><div class="content">Two similar approaches using the fact that large portions of the text in a record is static.<p>Using CLP: <a href="https:&#x2F;&#x2F;www.uber.com&#x2F;blog&#x2F;reducing-logging-cost-by-two-orders-of-magnitude-using-clp&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.uber.com&#x2F;blog&#x2F;reducing-logging-cost-by-two-order...</a><p><a href="https:&#x2F;&#x2F;messagetemplates.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;messagetemplates.org&#x2F;</a><p>Rewrite the log to extract and group by common identifiers:<p><a href="https:&#x2F;&#x2F;bit.kevinslin.com&#x2F;p&#x2F;lossless-log-aggregation" rel="nofollow">https:&#x2F;&#x2F;bit.kevinslin.com&#x2F;p&#x2F;lossless-log-aggregation</a></div><br/></div></div><div id="42551197" class="c"><input type="checkbox" id="c-42551197" checked=""/><div class="controls bullet"><span class="by">maccard</span><span>|</span><a href="#42550949">parent</a><span>|</span><a href="#42557187">prev</a><span>|</span><a href="#42552270">next</a><span>|</span><label class="collapse" for="c-42551197">[-]</label><label class="expand" for="c-42551197">[1 more]</label></div><br/><div class="children"><div class="content">I ended up with a similar problem. We replaced the data with a simple binary serialization format, gzip’ed that, and then base64 encoded the gzipped data. It’s far from perfect but it was 250x saving in our case making it go from “stupidly large” to “we don’t care” with an hours work.</div><br/></div></div><div id="42552270" class="c"><input type="checkbox" id="c-42552270" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#42550949">parent</a><span>|</span><a href="#42551197">prev</a><span>|</span><a href="#42551896">next</a><span>|</span><label class="collapse" for="c-42552270">[-]</label><label class="expand" for="c-42552270">[1 more]</label></div><br/><div class="children"><div class="content">For compressing short (&lt;100 bytes), repetitive strings, you could potentially train a zstd dictionary on your dataset, and then use that same dictionary for all rows. Of course, you’d want to disable several zstd defaults, like outputting the zstd header, since every single byte counts for short string compression.</div><br/></div></div><div id="42551896" class="c"><input type="checkbox" id="c-42551896" checked=""/><div class="controls bullet"><span class="by">ianburrell</span><span>|</span><a href="#42550949">parent</a><span>|</span><a href="#42552270">prev</a><span>|</span><a href="#42551084">next</a><span>|</span><label class="collapse" for="c-42551896">[-]</label><label class="expand" for="c-42551896">[1 more]</label></div><br/><div class="children"><div class="content">Postgres supports toast (long record) compression. It seems to support enabling on columns. It looks like it supports LZ4 and Zstd now. Zstd has better compression at expense of more time.</div><br/></div></div><div id="42551084" class="c"><input type="checkbox" id="c-42551084" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#42550949">parent</a><span>|</span><a href="#42551896">prev</a><span>|</span><a href="#42551056">next</a><span>|</span><label class="collapse" for="c-42551084">[-]</label><label class="expand" for="c-42551084">[1 more]</label></div><br/><div class="children"><div class="content">TOAST compression is likely your best option for that data. You may need to lower the data size threshold for toast for that column.</div><br/></div></div><div id="42551056" class="c"><input type="checkbox" id="c-42551056" checked=""/><div class="controls bullet"><span class="by">brody_hamer</span><span>|</span><a href="#42550949">parent</a><span>|</span><a href="#42551084">prev</a><span>|</span><a href="#42556734">next</a><span>|</span><label class="collapse" for="c-42551056">[-]</label><label class="expand" for="c-42551056">[2 more]</label></div><br/><div class="children"><div class="content">I haven’t played around with it too much myself, but I remember reading that gzip (or at least python’s compatible zlib library) supports a “seed dictionary” of expected fragments”.<p>I gather that you’d supply the same “seed” during both compression and decompression, and this would reduce the amount of information embedded into the compressed result.</div><br/><div id="42556554" class="c"><input type="checkbox" id="c-42556554" checked=""/><div class="controls bullet"><span class="by">duskwuff</span><span>|</span><a href="#42550949">root</a><span>|</span><a href="#42551056">parent</a><span>|</span><a href="#42556734">next</a><span>|</span><label class="collapse" for="c-42556554">[-]</label><label class="expand" for="c-42556554">[1 more]</label></div><br/><div class="children"><div class="content">Many other compression libraries, like zstd, support functionality along those lines. For that matter, brotli&#x27;s big party trick is having a built-in dictionary, tuned for web content.<p>It&#x27;s easy to implement in LZ-style compressors - it amounts to injecting the dictionary as context, as if it had been previously output by the decompressor. (There&#x27;s a striking parallel to how LLM prompting works.)</div><br/></div></div></div></div></div></div><div id="42556734" class="c"><input type="checkbox" id="c-42556734" checked=""/><div class="controls bullet"><span class="by">SeptiumMMX</span><span>|</span><a href="#42550949">prev</a><span>|</span><a href="#42555062">next</a><span>|</span><label class="collapse" for="c-42556734">[-]</label><label class="expand" for="c-42556734">[1 more]</label></div><br/><div class="children"><div class="content">The practical use for this could be satellite messaging (e.g. InReach) where a message is limited to ~160 characters, and costs about a dollar per message.</div><br/></div></div><div id="42555062" class="c"><input type="checkbox" id="c-42555062" checked=""/><div class="controls bullet"><span class="by">tdiff</span><span>|</span><a href="#42556734">prev</a><span>|</span><a href="#42551590">next</a><span>|</span><label class="collapse" for="c-42555062">[-]</label><label class="expand" for="c-42555062">[1 more]</label></div><br/><div class="children"><div class="content">How is llm here better than Markov chains created from a corpus of English text? I guess similar idea must have been explored million times in traditional compression studies.</div><br/></div></div><div id="42551590" class="c"><input type="checkbox" id="c-42551590" checked=""/><div class="controls bullet"><span class="by">mNovak</span><span>|</span><a href="#42555062">prev</a><span>|</span><a href="#42551104">next</a><span>|</span><label class="collapse" for="c-42551590">[-]</label><label class="expand" for="c-42551590">[3 more]</label></div><br/><div class="children"><div class="content">I recall someone using one of the image generation models for pretty impressive (lossy) compression as well -- I wonder if AI data compression&#x2F;inflation will be a viable concept in the future; the cost of inference right now is high, but it feels similar to the way cryptographic functions were more expensive before they got universal hardware acceleration.</div><br/><div id="42551655" class="c"><input type="checkbox" id="c-42551655" checked=""/><div class="controls bullet"><span class="by">hangonhn</span><span>|</span><a href="#42551590">parent</a><span>|</span><a href="#42551104">next</a><span>|</span><label class="collapse" for="c-42551655">[-]</label><label class="expand" for="c-42551655">[2 more]</label></div><br/><div class="children"><div class="content">At a startup where I worked many years ago, they trained a model to take the image and screen size as the input and it would output the JPG compression level to use so that the image appears the same to people. It worked exceedingly well that a major software company offered to acquire the startup just for that. Alas, the founders were too ambitious&#x2F;greedy and said no. It all burned down.</div><br/><div id="42553175" class="c"><input type="checkbox" id="c-42553175" checked=""/><div class="controls bullet"><span class="by">kevmo314</span><span>|</span><a href="#42551590">root</a><span>|</span><a href="#42551655">parent</a><span>|</span><a href="#42551104">next</a><span>|</span><label class="collapse" for="c-42553175">[-]</label><label class="expand" for="c-42553175">[1 more]</label></div><br/><div class="children"><div class="content">That seems like a fun project to replicate independently. You didn&#x27;t want to rebuild it?</div><br/></div></div></div></div></div></div><div id="42551104" class="c"><input type="checkbox" id="c-42551104" checked=""/><div class="controls bullet"><span class="by">stabbles</span><span>|</span><a href="#42551590">prev</a><span>|</span><a href="#42550887">next</a><span>|</span><label class="collapse" for="c-42551104">[-]</label><label class="expand" for="c-42551104">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a bit confusing to show the output as multibyte utf-8 characters and compare that to a base64 string</div><br/><div id="42551121" class="c"><input type="checkbox" id="c-42551121" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42551104">parent</a><span>|</span><a href="#42550887">next</a><span>|</span><label class="collapse" for="c-42551121">[-]</label><label class="expand" for="c-42551121">[2 more]</label></div><br/><div class="children"><div class="content">The comparison example uses base64 too</div><br/><div id="42551152" class="c"><input type="checkbox" id="c-42551152" checked=""/><div class="controls bullet"><span class="by">stabbles</span><span>|</span><a href="#42551104">root</a><span>|</span><a href="#42551121">parent</a><span>|</span><a href="#42550887">next</a><span>|</span><label class="collapse" for="c-42551152">[-]</label><label class="expand" for="c-42551152">[1 more]</label></div><br/><div class="children"><div class="content">Ah, my mistake. I thought that was meant to show a dictionary and brotli encoded string separately.</div><br/></div></div></div></div></div></div><div id="42550887" class="c"><input type="checkbox" id="c-42550887" checked=""/><div class="controls bullet"><span class="by">max_</span><span>|</span><a href="#42551104">prev</a><span>|</span><a href="#42553621">next</a><span>|</span><label class="collapse" for="c-42550887">[-]</label><label class="expand" for="c-42550887">[3 more]</label></div><br/><div class="children"><div class="content">Does this guy (Fabrice Bellard) have a podcast interview anyone would recommend?</div><br/><div id="42552155" class="c"><input type="checkbox" id="c-42552155" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#42550887">parent</a><span>|</span><a href="#42553621">next</a><span>|</span><label class="collapse" for="c-42552155">[-]</label><label class="expand" for="c-42552155">[2 more]</label></div><br/><div class="children"><div class="content">AFAIK, he doesn&#x27;t do videos or interviews.  His web presence is pretty sparse.  I remember trying to dig something up last year and coming up blank.  Totally respect that, but a bummer for folks hoping to get a peek inside his mind.<p>If nothing else, I hope he finds time to write his thoughts into a book at some point.</div><br/><div id="42552263" class="c"><input type="checkbox" id="c-42552263" checked=""/><div class="controls bullet"><span class="by">usr1106</span><span>|</span><a href="#42550887">root</a><span>|</span><a href="#42552155">parent</a><span>|</span><a href="#42553621">next</a><span>|</span><label class="collapse" for="c-42552263">[-]</label><label class="expand" for="c-42552263">[1 more]</label></div><br/><div class="children"><div class="content">He seems to spend all time to write truly amazing software.</div><br/></div></div></div></div></div></div><div id="42553621" class="c"><input type="checkbox" id="c-42553621" checked=""/><div class="controls bullet"><span class="by">j_juggernaut</span><span>|</span><a href="#42550887">prev</a><span>|</span><a href="#42552197">next</a><span>|</span><label class="collapse" for="c-42553621">[-]</label><label class="expand" for="c-42553621">[1 more]</label></div><br/><div class="children"><div class="content">Made a quick and dirt streamlit app to play around encrypt decrypt
<a href="https:&#x2F;&#x2F;llmencryptdecrypt-euyfofcjh8bf2utuha2zox.streamlit.app&#x2F;" rel="nofollow">https:&#x2F;&#x2F;llmencryptdecrypt-euyfofcjh8bf2utuha2zox.streamlit.a...</a></div><br/></div></div><div id="42552197" class="c"><input type="checkbox" id="c-42552197" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42553621">prev</a><span>|</span><a href="#42552242">next</a><span>|</span><label class="collapse" for="c-42552197">[-]</label><label class="expand" for="c-42552197">[1 more]</label></div><br/><div class="children"><div class="content">Impressive!<p>I wonder if this is at all similar to what Apple uses for their satellite iMessage&#x2F;SMS service, as that&#x27;s a domain where it&#x27;s probably worth spending significant compute on both sides to shave off even a single byte to transmit.</div><br/></div></div><div id="42552242" class="c"><input type="checkbox" id="c-42552242" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#42552197">prev</a><span>|</span><a href="#42551114">next</a><span>|</span><label class="collapse" for="c-42552242">[-]</label><label class="expand" for="c-42552242">[2 more]</label></div><br/><div class="children"><div class="content">What is this encoding scheme that produces Chinese characters from binary data? E.g. from the first example:<p>&gt; <i>뮭䅰㼦覞㻪紹陠聚牊</i><p>I&#x27;ve never seen that before. The base64 below it, in contrast, is quite familiar.</div><br/><div id="42552253" class="c"><input type="checkbox" id="c-42552253" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42552242">parent</a><span>|</span><a href="#42551114">next</a><span>|</span><label class="collapse" for="c-42552253">[-]</label><label class="expand" for="c-42552253">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a family of encodings optimized for fitting the most information possible into an Unicode string of a given length, e.g. for gimmicks like fitting the most possible binary data into tweets.<p>For example: <a href="https:&#x2F;&#x2F;github.com&#x2F;qntm&#x2F;base65536">https:&#x2F;&#x2F;github.com&#x2F;qntm&#x2F;base65536</a><p>For short messages in the mobile phone (i.e. GSM&#x2F;3GPP) sense, which was my first association for &quot;short message compression&quot;, it doubt that it works better than just sending binary messages with the appropriate header, but if that&#x27;s not an option, it might just beat a custom alphabet based on the 7-bit GSM charset [1] (since that allows 100% of possible 7-bit characters to be used, whereas UTF-16 probably has at least some reserved codepoints that might be causing problems).<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;GSM_03.38" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;GSM_03.38</a></div><br/></div></div></div></div><div id="42551114" class="c"><input type="checkbox" id="c-42551114" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42552242">prev</a><span>|</span><a href="#42553163">next</a><span>|</span><label class="collapse" for="c-42551114">[-]</label><label class="expand" for="c-42551114">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the throughput like, for both compression and decompression?</div><br/></div></div><div id="42550964" class="c"><input type="checkbox" id="c-42550964" checked=""/><div class="controls bullet"><span class="by">yalok</span><span>|</span><a href="#42553163">prev</a><span>|</span><a href="#42552556">next</a><span>|</span><label class="collapse" for="c-42550964">[-]</label><label class="expand" for="c-42550964">[2 more]</label></div><br/><div class="children"><div class="content">What’s the size of the model used here?</div><br/><div id="42551070" class="c"><input type="checkbox" id="c-42551070" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#42550964">parent</a><span>|</span><a href="#42552556">next</a><span>|</span><label class="collapse" for="c-42551070">[-]</label><label class="expand" for="c-42551070">[1 more]</label></div><br/><div class="children"><div class="content">The model used is RWKV 169M v4.</div><br/></div></div></div></div><div id="42552556" class="c"><input type="checkbox" id="c-42552556" checked=""/><div class="controls bullet"><span class="by">slater</span><span>|</span><a href="#42550964">prev</a><span>|</span><a href="#42554467">next</a><span>|</span><label class="collapse" for="c-42552556">[-]</label><label class="expand" for="c-42552556">[2 more]</label></div><br/><div class="children"><div class="content">i always wondered if e.g. telcos had special short codes for stuff people often send, like at xmas many people write &quot;merry christmas&quot; in an SMS, and the telco just sends out &quot;[code:mx]&quot; to all recipient phones, to save on bandwidth and disk space?</div><br/><div id="42556604" class="c"><input type="checkbox" id="c-42556604" checked=""/><div class="controls bullet"><span class="by">qingcharles</span><span>|</span><a href="#42552556">parent</a><span>|</span><a href="#42554467">next</a><span>|</span><label class="collapse" for="c-42556604">[-]</label><label class="expand" for="c-42556604">[1 more]</label></div><br/><div class="children"><div class="content">No, the systems are not that sophisticated, from having worked on them in the past.</div><br/></div></div></div></div><div id="42554467" class="c"><input type="checkbox" id="c-42554467" checked=""/><div class="controls bullet"><span class="by">jonplackett</span><span>|</span><a href="#42552556">prev</a><span>|</span><a href="#42550994">next</a><span>|</span><label class="collapse" for="c-42554467">[-]</label><label class="expand" for="c-42554467">[1 more]</label></div><br/><div class="children"><div class="content">Would this also work for video encoding using something like Sora?<p>Get Sora to guess the next frame and then correct any parts that are wrong?<p>I mean, it would be an absolutely insane waste of power, but maybe one day it’ll make sense!</div><br/></div></div><div id="42550994" class="c"><input type="checkbox" id="c-42550994" checked=""/><div class="controls bullet"><span class="by">deadbabe</span><span>|</span><a href="#42554467">prev</a><span>|</span><a href="#42552281">next</a><span>|</span><label class="collapse" for="c-42550994">[-]</label><label class="expand" for="c-42550994">[9 more]</label></div><br/><div class="children"><div class="content">Could this become an attack vector somehow? The greatest minds could probably find a way to get a malicious payload decompressed into the output.</div><br/><div id="42551105" class="c"><input type="checkbox" id="c-42551105" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42550994">parent</a><span>|</span><a href="#42553669">next</a><span>|</span><label class="collapse" for="c-42551105">[-]</label><label class="expand" for="c-42551105">[7 more]</label></div><br/><div class="children"><div class="content">It&#x27;s lossless, at worst you&#x27;d make the compression ratio worse for certain inputs.</div><br/><div id="42551208" class="c"><input type="checkbox" id="c-42551208" checked=""/><div class="controls bullet"><span class="by">deadbabe</span><span>|</span><a href="#42550994">root</a><span>|</span><a href="#42551105">parent</a><span>|</span><a href="#42553669">next</a><span>|</span><label class="collapse" for="c-42551208">[-]</label><label class="expand" for="c-42551208">[6 more]</label></div><br/><div class="children"><div class="content">With LLM based compression, could we get something like the opposite of lossless, like hallucinatory? All the original content, plus more?</div><br/><div id="42551979" class="c"><input type="checkbox" id="c-42551979" checked=""/><div class="controls bullet"><span class="by">ychen306</span><span>|</span><a href="#42550994">root</a><span>|</span><a href="#42551208">parent</a><span>|</span><a href="#42551359">next</a><span>|</span><label class="collapse" for="c-42551979">[-]</label><label class="expand" for="c-42551979">[1 more]</label></div><br/><div class="children"><div class="content">How this works is the LLM predicts the probability of the next token and then an arithmetic coder turns that probability distribution into bits. So it will never hallucinate. In the worst case, when the LLM makes an outrageous prediction, you just use more bits, but it doesn&#x27;t affect correctness.</div><br/></div></div><div id="42551359" class="c"><input type="checkbox" id="c-42551359" checked=""/><div class="controls bullet"><span class="by">tshaddox</span><span>|</span><a href="#42550994">root</a><span>|</span><a href="#42551208">parent</a><span>|</span><a href="#42551979">prev</a><span>|</span><a href="#42551312">next</a><span>|</span><label class="collapse" for="c-42551359">[-]</label><label class="expand" for="c-42551359">[1 more]</label></div><br/><div class="children"><div class="content">Presuming the software is implemented correctly, that can&#x27;t happen (per the definition of &quot;lossless&quot;). I can imagine this happening with a careless implementation, e.g. if circumstances conspire to allow a slightly different version or configuration of the LLM to be used across compression and decompression.</div><br/></div></div><div id="42551312" class="c"><input type="checkbox" id="c-42551312" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42550994">root</a><span>|</span><a href="#42551208">parent</a><span>|</span><a href="#42551359">prev</a><span>|</span><a href="#42551422">next</a><span>|</span><label class="collapse" for="c-42551312">[-]</label><label class="expand" for="c-42551312">[1 more]</label></div><br/><div class="children"><div class="content">Not if the compression scheme is lossless, which it is here, per my previous comment.</div><br/></div></div><div id="42551422" class="c"><input type="checkbox" id="c-42551422" checked=""/><div class="controls bullet"><span class="by">semiquaver</span><span>|</span><a href="#42550994">root</a><span>|</span><a href="#42551208">parent</a><span>|</span><a href="#42551312">prev</a><span>|</span><a href="#42553669">next</a><span>|</span><label class="collapse" for="c-42551422">[-]</label><label class="expand" for="c-42551422">[2 more]</label></div><br/><div class="children"><div class="content">LLMs are deterministic at zero temperature.</div><br/><div id="42557359" class="c"><input type="checkbox" id="c-42557359" checked=""/><div class="controls bullet"><span class="by">gloflo</span><span>|</span><a href="#42550994">root</a><span>|</span><a href="#42551422">parent</a><span>|</span><a href="#42553669">next</a><span>|</span><label class="collapse" for="c-42557359">[-]</label><label class="expand" for="c-42557359">[1 more]</label></div><br/><div class="children"><div class="content">Deterministically lossy&#x2F;hallucinatory.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42552281" class="c"><input type="checkbox" id="c-42552281" checked=""/><div class="controls bullet"><span class="by">mlok</span><span>|</span><a href="#42550994">prev</a><span>|</span><a href="#42552466">next</a><span>|</span><label class="collapse" for="c-42552281">[-]</label><label class="expand" for="c-42552281">[5 more]</label></div><br/><div class="children"><div class="content">LLMs, and now this, make me think of the (non-existant) &quot;Sloot Digital Coding System&quot; that could be viewed as a form of &quot;compression&quot;.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Sloot_Digital_Coding_System" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Sloot_Digital_Coding_System</a></div><br/><div id="42552381" class="c"><input type="checkbox" id="c-42552381" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#42552281">parent</a><span>|</span><a href="#42552466">next</a><span>|</span><label class="collapse" for="c-42552381">[-]</label><label class="expand" for="c-42552381">[4 more]</label></div><br/><div class="children"><div class="content">I view it as a form of fraud. There&#x27;s no way that worked or could have worked.</div><br/><div id="42555488" class="c"><input type="checkbox" id="c-42555488" checked=""/><div class="controls bullet"><span class="by">perching_aix</span><span>|</span><a href="#42552281">root</a><span>|</span><a href="#42552381">parent</a><span>|</span><a href="#42554217">next</a><span>|</span><label class="collapse" for="c-42555488">[-]</label><label class="expand" for="c-42555488">[1 more]</label></div><br/><div class="children"><div class="content">I thought I had come up with something with a similar performance once. Then a couple hours later I realized that I just (still) suck at combinatorics :)</div><br/></div></div><div id="42554217" class="c"><input type="checkbox" id="c-42554217" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#42552281">root</a><span>|</span><a href="#42552381">parent</a><span>|</span><a href="#42555488">prev</a><span>|</span><a href="#42552623">next</a><span>|</span><label class="collapse" for="c-42554217">[-]</label><label class="expand" for="c-42554217">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps not literally, but you can easily imagine training an embedding on a large amount of existing video, and then delivering somebody &quot;the point in space that decodes to the video with the least residual compared to the original&quot;.<p>Conceptually, most modern movies are just linear combinations of basis tropes (tvtropes.org).</div><br/></div></div><div id="42552623" class="c"><input type="checkbox" id="c-42552623" checked=""/><div class="controls bullet"><span class="by">mlok</span><span>|</span><a href="#42552281">root</a><span>|</span><a href="#42552381">parent</a><span>|</span><a href="#42554217">prev</a><span>|</span><a href="#42552466">next</a><span>|</span><label class="collapse" for="c-42552623">[-]</label><label class="expand" for="c-42552623">[1 more]</label></div><br/><div class="children"><div class="content">Yes that is why I specified it was non-existent. But the idea behind it is in the same vein somehow. Maybe what Sloot envisioned was something similar to LLMs.</div><br/></div></div></div></div></div></div><div id="42552124" class="c"><input type="checkbox" id="c-42552124" checked=""/><div class="controls bullet"><span class="by">RandomThoughts3</span><span>|</span><a href="#42552466">prev</a><span>|</span><label class="collapse" for="c-42552124">[-]</label><label class="expand" for="c-42552124">[3 more]</label></div><br/><div class="children"><div class="content">It’s a very clever idea.<p>I could see it becoming very useful if on device LLM becomes a thing. That might allow storing a lot of original sources for not much additional data. We might be able to get an on device chat bot sending you to a copy of Wikipedia&#x2F;reference material all stored on device and working fully offline.</div><br/><div id="42553606" class="c"><input type="checkbox" id="c-42553606" checked=""/><div class="controls bullet"><span class="by">zamadatix</span><span>|</span><a href="#42552124">parent</a><span>|</span><a href="#42552343">next</a><span>|</span><label class="collapse" for="c-42553606">[-]</label><label class="expand" for="c-42553606">[1 more]</label></div><br/><div class="children"><div class="content">If mobile phone conversations over the last 2 decades have taught me anything it&#x27;s that people talk about anything but battery life and ultimately the crowd ends up doing &quot;whatever means I don&#x27;t have to put it on the charger twice a day&quot;. Especially when the base iPhone SE already has enough storage to fit more text than one could read in their life anyways.</div><br/></div></div><div id="42552343" class="c"><input type="checkbox" id="c-42552343" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42552124">parent</a><span>|</span><a href="#42553606">prev</a><span>|</span><label class="collapse" for="c-42552343">[-]</label><label class="expand" for="c-42552343">[1 more]</label></div><br/><div class="children"><div class="content">If you like that idea, give Kiwix a try! Best ~60 GB I have stored on my phone :) And it comes in handy more often than initially expected.</div><br/></div></div></div></div></div></div></div></div></div></body></html>