<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1729933251992" as="style"/><link rel="stylesheet" href="styles.css?v=1729933251992"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://estuary.dev/streaming-joins-are-hard/">Streaming joins are hard</a> <span class="domain">(<a href="https://estuary.dev">estuary.dev</a>)</span></div><div class="subtext"><span>danthelion</span> | <span>38 comments</span></div><br/><div><div id="41950029" class="c"><input type="checkbox" id="c-41950029" checked=""/><div class="controls bullet"><span class="by">ryzhyk</span><span>|</span><a href="#41949582">next</a><span>|</span><label class="collapse" for="c-41950029">[-]</label><label class="expand" for="c-41950029">[10 more]</label></div><br/><div class="children"><div class="content">The correct way to think about the problem is in terms of evaluating joins (or any other queries) over changing datasets.  And for that you need an engine designed for *incremental* processing from the ground up: algorithms, data structures, the storage layer, and of course the underlying theory.  If you don&#x27;t have such an engine, you&#x27;re doomed to build layer of hacks, and still fail to do it well.<p>We&#x27;ve been building such an engine at Feldera (<a href="https:&#x2F;&#x2F;www.feldera.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.feldera.com&#x2F;</a>), and it can compute joins, aggregates, window queries, and much more fully incrementally.  All you have to do is write your queries in SQL, attach your data sources (stream or batch), and watch results get incrementally updated in real-time.</div><br/><div id="41951735" class="c"><input type="checkbox" id="c-41951735" checked=""/><div class="controls bullet"><span class="by">majormajor</span><span>|</span><a href="#41950029">parent</a><span>|</span><a href="#41951697">next</a><span>|</span><label class="collapse" for="c-41951735">[-]</label><label class="expand" for="c-41951735">[1 more]</label></div><br/><div class="children"><div class="content">Does this offer any non-SQL programmatic interfaces or ways to do Complex Event Processing (e.g. <a href="https:&#x2F;&#x2F;www.databricks.com&#x2F;glossary&#x2F;complex-event-processing" rel="nofollow">https:&#x2F;&#x2F;www.databricks.com&#x2F;glossary&#x2F;complex-event-processing</a> )? A lot of those scenarios would be tough to express in SQL.</div><br/></div></div><div id="41950081" class="c"><input type="checkbox" id="c-41950081" checked=""/><div class="controls bullet"><span class="by">d0mine</span><span>|</span><a href="#41950029">parent</a><span>|</span><a href="#41951697">prev</a><span>|</span><a href="#41951542">next</a><span>|</span><label class="collapse" for="c-41950081">[-]</label><label class="expand" for="c-41950081">[6 more]</label></div><br/><div class="children"><div class="content">Is it related to Differential Dataflow &#x2F; timely dataflow <a href="https:&#x2F;&#x2F;github.com&#x2F;TimelyDataflow&#x2F;differential-dataflow">https:&#x2F;&#x2F;github.com&#x2F;TimelyDataflow&#x2F;differential-dataflow</a></div><br/><div id="41950153" class="c"><input type="checkbox" id="c-41950153" checked=""/><div class="controls bullet"><span class="by">ryzhyk</span><span>|</span><a href="#41950029">root</a><span>|</span><a href="#41950081">parent</a><span>|</span><a href="#41951542">next</a><span>|</span><label class="collapse" for="c-41950153">[-]</label><label class="expand" for="c-41950153">[5 more]</label></div><br/><div class="children"><div class="content">We have our own formal model called DBSP: <a href="https:&#x2F;&#x2F;docs.feldera.com&#x2F;papers" rel="nofollow">https:&#x2F;&#x2F;docs.feldera.com&#x2F;papers</a><p>It is indeed inspired by timely&#x2F;differential, but is not exactly comparable to it. One nice property of DBSP is that the theory is very modular and allows adding new incremental operators with strong correctness guarantees, kind of LEGO brick for incremental computation. For example we have a fully incremental implementation of rolling aggregates (<a href="https:&#x2F;&#x2F;www.feldera.com&#x2F;blog&#x2F;rolling-aggregates" rel="nofollow">https:&#x2F;&#x2F;www.feldera.com&#x2F;blog&#x2F;rolling-aggregates</a>), which I don&#x27;t think any other system can do today.</div><br/><div id="41952718" class="c"><input type="checkbox" id="c-41952718" checked=""/><div class="controls bullet"><span class="by">anonymoushn</span><span>|</span><a href="#41950029">root</a><span>|</span><a href="#41950153">parent</a><span>|</span><a href="#41950926">next</a><span>|</span><label class="collapse" for="c-41952718">[-]</label><label class="expand" for="c-41952718">[1 more]</label></div><br/><div class="children"><div class="content">Fast rolling aggregates are swell. I meet a lot of people who are building trading systems and want this sort of thing, but it usually isn&#x27;t a great choice because the perfectly rectangular kernel probably isn&#x27;t the best possible version of the feature and because arbitrary kernels can be well approximated using a state of constant size rather than a large buffer storing a sliding window.</div><br/></div></div><div id="41950926" class="c"><input type="checkbox" id="c-41950926" checked=""/><div class="controls bullet"><span class="by">incr_me</span><span>|</span><a href="#41950029">root</a><span>|</span><a href="#41950153">parent</a><span>|</span><a href="#41952718">prev</a><span>|</span><a href="#41951542">next</a><span>|</span><label class="collapse" for="c-41950926">[-]</label><label class="expand" for="c-41950926">[3 more]</label></div><br/><div class="children"><div class="content">Are you aware of any efforts to apply DBSP&#x27;s theory to a general programming language&#x2F;environment? From my perspective, DDlog was the most inspiring project in the field of incremental computation, but it seems like all of these projects just lead to implementations of streaming databases or other similar commercial products that fit into Data™ pipelines (no offense). Incremental computation pops up everywhere, from databases to business logic to UI rendering and video game graphics, and I have this hunch that if the problem could be solved at a fundamental level and in an accessible way, we could have revolutionary gains for programmers and programs.</div><br/><div id="41951320" class="c"><input type="checkbox" id="c-41951320" checked=""/><div class="controls bullet"><span class="by">ryzhyk</span><span>|</span><a href="#41950029">root</a><span>|</span><a href="#41950926">parent</a><span>|</span><a href="#41951542">next</a><span>|</span><label class="collapse" for="c-41951320">[-]</label><label class="expand" for="c-41951320">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for the kind words about DDlog :)<p>The reason DBSP and Differential Dataflow work so well is because they are specialized to relational computations. Relational operators have nice properties that allow evaluating them incrementally.  Incremental evaluation for a general purpose language like Rust is a much, much harder problem.<p>FWIW, DBSP is available as a Rust crate (<a href="https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;dbsp" rel="nofollow">https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;dbsp</a>), so you can use it as an embedded incremental compute engine inside your program.</div><br/><div id="41953061" class="c"><input type="checkbox" id="c-41953061" checked=""/><div class="controls bullet"><span class="by">incr_me</span><span>|</span><a href="#41950029">root</a><span>|</span><a href="#41951320">parent</a><span>|</span><a href="#41951542">next</a><span>|</span><label class="collapse" for="c-41953061">[-]</label><label class="expand" for="c-41953061">[1 more]</label></div><br/><div class="children"><div class="content">Indeed. I&#x27;ve experimented a bit with abusing DD&#x2F;DBSP for my purposes by modeling various kinds of data structures in terms of Z-sets, but these efforts have not yielded very impressive results. :)<p>For how elegant DBSP is I still found the paper a tough nut to crack, and it really is one of the more accessible theoretical contributions in the space, at least from this grubby programmer&#x27;s perspective... I hope to devote some time to study and play around more, but in the meantime I&#x27;m rooting for you!</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41951542" class="c"><input type="checkbox" id="c-41951542" checked=""/><div class="controls bullet"><span class="by">qazxcvbnm</span><span>|</span><a href="#41950029">parent</a><span>|</span><a href="#41950081">prev</a><span>|</span><a href="#41949582">next</a><span>|</span><label class="collapse" for="c-41951542">[-]</label><label class="expand" for="c-41951542">[1 more]</label></div><br/><div class="children"><div class="content">Hi, I’ve read the DBSP paper and it’s a really well-thought out framework; all the magic seemed so simple with the way the paper laid things out. However, the paper dealt with abelian Z-sets only, and mentioned that in your implementation, you also handle the non-abelian aspect of ordering. I was wondering if you guys have published about how did you that?</div><br/></div></div></div></div><div id="41949582" class="c"><input type="checkbox" id="c-41949582" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41950029">prev</a><span>|</span><a href="#41949643">next</a><span>|</span><label class="collapse" for="c-41949582">[-]</label><label class="expand" for="c-41949582">[14 more]</label></div><br/><div class="children"><div class="content">Can someone explain what the use case is for streaming joins in the first place?<p>I&#x27;ve written my fair share of joins in SQL. They&#x27;re indispensable.<p>But I&#x27;ve never come across a situation where I needed to join data from two streams in real time as they&#x27;re both coming in. I&#x27;m not sure I even understand what that&#x27;s supposed to mean conceptually.<p>It&#x27;s easy enough to dump streams into a database and query the database but clearly this isn&#x27;t about that.<p>So what&#x27;s the use case for joins on raw stream data?</div><br/><div id="41949906" class="c"><input type="checkbox" id="c-41949906" checked=""/><div class="controls bullet"><span class="by">GeneralMayhem</span><span>|</span><a href="#41949582">parent</a><span>|</span><a href="#41949710">next</a><span>|</span><label class="collapse" for="c-41949906">[-]</label><label class="expand" for="c-41949906">[4 more]</label></div><br/><div class="children"><div class="content">Event correlations are a typical one. Think about ad tech: you want every click event to be hydrated with information about the impression or query that led to it. Both of those are high-volume log streams.<p>You want to end up with the results of:<p>```
select * from clicks left join impressions on (clicks.impression_id=impressions.id)
```<p>but you want to see incremental results - for instance, because you want to feed the joined rows into a streaming aggregator to keep counts as up to date as possible.</div><br/><div id="41950220" class="c"><input type="checkbox" id="c-41950220" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41949582">root</a><span>|</span><a href="#41949906">parent</a><span>|</span><a href="#41949710">next</a><span>|</span><label class="collapse" for="c-41950220">[-]</label><label class="expand" for="c-41950220">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s helpful, thanks.<p>I was definitely under the impression that ad impressions and clicks would be written to databases immediately and queried from there.<p>I&#x27;m still having a hard time imagining in what case you&#x27;d need a &quot;live&quot; aggregating display that needed to join data from multiple streams, rather than just accumulating from individual streams, but I guess I can imagine that there are circumstances where that would be desired.<p>Thanks!</div><br/><div id="41951154" class="c"><input type="checkbox" id="c-41951154" checked=""/><div class="controls bullet"><span class="by">zbentley</span><span>|</span><a href="#41949582">root</a><span>|</span><a href="#41950220">parent</a><span>|</span><a href="#41950436">next</a><span>|</span><label class="collapse" for="c-41951154">[-]</label><label class="expand" for="c-41951154">[1 more]</label></div><br/><div class="children"><div class="content">Live-updated aggregates are quite common in this area. Consider metered billing (&quot;discontinue this ad after it has been served&#x2F;clicked&#x2F;rendered X times&quot;), reactive segmentation (&quot;the owner of a store has decided to offer a discount to anyone that viewed but did not purchase products X, Y, and Z within a 10 minute period&quot;), or intrusion detection (&quot;if the same sequence of routes is accessed quickly in rapid succession across the webserver fleet, regardless of source IP or UA, send an alert&quot;).<p>In a very large number of cases, those streams of data are too large to query effectively (read: cheaply or with low enough latency to satisfy people interested in up-to-date results) at rest. With 100ks or millions of events&#x2F;second, the &quot;store then query&quot; approach loses fidelity and affordability fast.</div><br/></div></div><div id="41950436" class="c"><input type="checkbox" id="c-41950436" checked=""/><div class="controls bullet"><span class="by">jrockway</span><span>|</span><a href="#41949582">root</a><span>|</span><a href="#41950220">parent</a><span>|</span><a href="#41951154">prev</a><span>|</span><a href="#41949710">next</a><span>|</span><label class="collapse" for="c-41950436">[-]</label><label class="expand" for="c-41950436">[1 more]</label></div><br/><div class="children"><div class="content">I think it can be challenging to get that much data to a single database.  For example, you probably don&#x27;t want to send every &quot;someone moused over this ad&quot; event in Japan to a datacenter in us-east-1.  But if you do the aggregation and storage close to the user, you can emit summaries to that central server, backing some web page where you can see your &quot;a 39-year-old white male moused over this ad&quot; count go up in real time.<p>How important ads are is debatable, but if you&#x27;re an ad company and this is what your customers want, it&#x27;s an implementation that you might come up with because of the engineering practicality.</div><br/></div></div></div></div></div></div><div id="41949710" class="c"><input type="checkbox" id="c-41949710" checked=""/><div class="controls bullet"><span class="by">BeefWellington</span><span>|</span><a href="#41949582">parent</a><span>|</span><a href="#41949906">prev</a><span>|</span><a href="#41951015">next</a><span>|</span><label class="collapse" for="c-41949710">[-]</label><label class="expand" for="c-41949710">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll use a contrived example here to explain what the value of streaming the data itself is.<p>Let&#x27;s say you run a large installation that has a variety of very important gauges and sensors. Due to the size and complexity of this installation, these gauges and sensors need to be fed back to a console somewhere so that an overseer role of sorts can get that big picture view to ensure the installation is functioning fully healthy.<p>For that scenario, if you look at your data in the sense of a typical RDBMS &#x2F; Data Warehouse, you would probably want to save as much over the wire traffic as possible to ensure there&#x27;s no delays in getting the sensor information fed into the system reliably on time. So you trim down things to just a station ID and some readings coming into your &quot;fact&quot; table (it could be more transactionally modeled but mostly it&#x27;ll fit the same bill).<p>Basically the streaming is useful so that in near-realtime you can live scroll the recordset as data comes in. Your SQL query becomes more of an infinite Cursor.<p>Older ways of doing this did exist on SQL databases just fine; typically you&#x27;d have some kind of record marker, whether it was ROWID, DateTime, etc., and you&#x27;d just reissue an identical query to get the newer records. That introduces some overhead though, and the streaming approach kind of minimizes&#x2F;eliminates that.</div><br/><div id="41950147" class="c"><input type="checkbox" id="c-41950147" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#41949582">root</a><span>|</span><a href="#41949710">parent</a><span>|</span><a href="#41949897">next</a><span>|</span><label class="collapse" for="c-41950147">[-]</label><label class="expand" for="c-41950147">[2 more]</label></div><br/><div class="children"><div class="content">I definitely understand the value of streaming. Your gauges example is great.<p>What I don&#x27;t understand is streaming joins. None of your gauge values need to join to anything.<p>And if they did -- if something needed to join ID values to display names, presumably those would sit in a database, not a different stream?</div><br/><div id="41951726" class="c"><input type="checkbox" id="c-41951726" checked=""/><div class="controls bullet"><span class="by">majormajor</span><span>|</span><a href="#41949582">root</a><span>|</span><a href="#41950147">parent</a><span>|</span><a href="#41949897">next</a><span>|</span><label class="collapse" for="c-41951726">[-]</label><label class="expand" for="c-41951726">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And if they did -- if something needed to join ID values to display names, presumably those would sit in a database, not a different stream?<p>At a high level the push-instead-of-pull benefit here is &quot;you don&#x27;t have to query the ID values to get the display names every time&quot; which will reduce your latency. (You can cache but then you might get into invalidation issues and start thinking &quot;why not just send the updates directly to my cache instead&quot;)<p>There&#x27;s also a less cacheable version where both sides are updating more frequently and you have logic like &quot;if X=1 and Y=2 do Z.&quot;<p>For small enough batches streaming and micro-batching do often end up very similar.</div><br/></div></div></div></div><div id="41949897" class="c"><input type="checkbox" id="c-41949897" checked=""/><div class="controls bullet"><span class="by">hotstickyballs</span><span>|</span><a href="#41949582">root</a><span>|</span><a href="#41949710">parent</a><span>|</span><a href="#41950147">prev</a><span>|</span><a href="#41951015">next</a><span>|</span><label class="collapse" for="c-41949897">[-]</label><label class="expand" for="c-41949897">[1 more]</label></div><br/><div class="children"><div class="content">Should’ve just cached the output of group bys.</div><br/></div></div></div></div><div id="41951015" class="c"><input type="checkbox" id="c-41951015" checked=""/><div class="controls bullet"><span class="by">matlin</span><span>|</span><a href="#41949582">parent</a><span>|</span><a href="#41949710">prev</a><span>|</span><a href="#41949744">next</a><span>|</span><label class="collapse" for="c-41951015">[-]</label><label class="expand" for="c-41951015">[1 more]</label></div><br/><div class="children"><div class="content">We apply incremental, streamable &quot;joins&quot; (relational queries) for real-time syncing between application client and server. I think much of the initial research in this space was around data pipelines but the killer app (no pun intended) is actually in app development</div><br/></div></div><div id="41949744" class="c"><input type="checkbox" id="c-41949744" checked=""/><div class="controls bullet"><span class="by">closeparen</span><span>|</span><a href="#41949582">parent</a><span>|</span><a href="#41951015">prev</a><span>|</span><a href="#41950109">next</a><span>|</span><label class="collapse" for="c-41949744">[-]</label><label class="expand" for="c-41949744">[1 more]</label></div><br/><div class="children"><div class="content">Anything you can do with stateful streaming technology, you can do with a database and a message handler. It’s just a question of programming model and scaling characteristics. You typically get an in-process embedded DB per shard, with an API that makes it seem closer to managing state in memory.</div><br/></div></div><div id="41950109" class="c"><input type="checkbox" id="c-41950109" checked=""/><div class="controls bullet"><span class="by">ryzhyk</span><span>|</span><a href="#41949582">parent</a><span>|</span><a href="#41949744">prev</a><span>|</span><a href="#41949898">next</a><span>|</span><label class="collapse" for="c-41950109">[-]</label><label class="expand" for="c-41950109">[1 more]</label></div><br/><div class="children"><div class="content">The computational complexity of running an analytical query on a database is, at best, O(N), where N is the size of the database. The computational complexity of evaluating queries incrementally over streaming data with a well-designed query engine is O(delta), where delta is the size of the *new* data.  If your use case is well served by a database (i.e., can tolerate the latency), then you&#x27;re certainly better off relying on the more mature technology. But if you need to do some heavy-weight queries and get fresh results in real-time, no DB I can think of can pull that off (including &quot;real-time&quot; databases).</div><br/></div></div><div id="41949898" class="c"><input type="checkbox" id="c-41949898" checked=""/><div class="controls bullet"><span class="by">tshaddox</span><span>|</span><a href="#41949582">parent</a><span>|</span><a href="#41950109">prev</a><span>|</span><a href="#41951993">next</a><span>|</span><label class="collapse" for="c-41949898">[-]</label><label class="expand" for="c-41949898">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t the use case just any time you want a client to essentially subscribe to an SQL query and receive message every time the result of that SQL query changes?</div><br/></div></div><div id="41951993" class="c"><input type="checkbox" id="c-41951993" checked=""/><div class="controls bullet"><span class="by">fnordpiglet</span><span>|</span><a href="#41949582">parent</a><span>|</span><a href="#41949898">prev</a><span>|</span><a href="#41949643">next</a><span>|</span><label class="collapse" for="c-41951993">[-]</label><label class="expand" for="c-41951993">[1 more]</label></div><br/><div class="children"><div class="content">This is extremely common in trading systems where real time data is joined against reference data and grouped, etc for a variety of purposes including consumption by algorithms and display.</div><br/></div></div></div></div><div id="41949643" class="c"><input type="checkbox" id="c-41949643" checked=""/><div class="controls bullet"><span class="by">10000truths</span><span>|</span><a href="#41949582">prev</a><span>|</span><a href="#41949268">next</a><span>|</span><label class="collapse" for="c-41949643">[-]</label><label class="expand" for="c-41949643">[1 more]</label></div><br/><div class="children"><div class="content">Streams are <i>conceptually</i> infinite, yes, but many streaming use cases are dealing with a finite amount of data that&#x27;s larger than memory but fits on disk. In those cases, you can typically get away with materializing your inputs to a temporary file in order to implement joins, sorts, percentile aggregations, etc.</div><br/></div></div><div id="41949268" class="c"><input type="checkbox" id="c-41949268" checked=""/><div class="controls bullet"><span class="by">fifilura</span><span>|</span><a href="#41949643">prev</a><span>|</span><a href="#41949952">next</a><span>|</span><label class="collapse" for="c-41949268">[-]</label><label class="expand" for="c-41949268">[1 more]</label></div><br/><div class="children"><div class="content">A couple of years ago Materialize had all the buzz, not sure what is the difference.<p><a href="https:&#x2F;&#x2F;materialize.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;materialize.com&#x2F;</a></div><br/></div></div><div id="41949952" class="c"><input type="checkbox" id="c-41949952" checked=""/><div class="controls bullet"><span class="by">tombert</span><span>|</span><a href="#41949268">prev</a><span>|</span><a href="#41949876">next</a><span>|</span><label class="collapse" for="c-41949952">[-]</label><label class="expand" for="c-41949952">[1 more]</label></div><br/><div class="children"><div class="content">A large part of my job in the last few months has been in the form figuring out how to optimize joins in Kafka Streams.<p>Kafka Streams, by default, uses either RocksDB or an in-memory system for the join buffer, which is fine but completely devours your RAM, and so I have been writing something more tuned for our work that actually uses Postgres as the state store.<p>It works, but optimizing JOINs is almost as much of an art as it is a science. Trying to optimize caches and predict stuff so you can minimize the cost of latency ends up being a lot of “guess and check” work, particularly if you want to keep memory usage reasonable.</div><br/></div></div><div id="41949876" class="c"><input type="checkbox" id="c-41949876" checked=""/><div class="controls bullet"><span class="by">mattxxx</span><span>|</span><a href="#41949952">prev</a><span>|</span><a href="#41949135">next</a><span>|</span><label class="collapse" for="c-41949876">[-]</label><label class="expand" for="c-41949876">[1 more]</label></div><br/><div class="children"><div class="content">JOINs are just hard <i>period</i>. When you&#x27;re operating at a large scale, you need to be thinking about exactly <i>how</i> to partition + index your data for the types of queries that you want to write with JOINs.<p>Streaming joins are <i>so hard</i>, that they&#x27;re an anti pattern. If you&#x27;re using external storage to make it work, then your architecture has probably gone really wrong or you&#x27;re using streams for something that you shouldn&#x27;t.</div><br/></div></div><div id="41949135" class="c"><input type="checkbox" id="c-41949135" checked=""/><div class="controls bullet"><span class="by">jdelman</span><span>|</span><a href="#41949876">prev</a><span>|</span><a href="#41949368">next</a><span>|</span><label class="collapse" for="c-41949135">[-]</label><label class="expand" for="c-41949135">[3 more]</label></div><br/><div class="children"><div class="content">The ability to express joins in terms of SQL with Estuary is pretty cool. Flink can do a lot of what is described in this post, but you have to set up a lot of intermediate structures, write a lot of Java&#x2F;Scala, and store your state as protos to support backwards compatibility. Abstracting all of that away would be a huge time saver, but I imagine not having fine grained control over the results and join methods could be frustrating.</div><br/><div id="41949156" class="c"><input type="checkbox" id="c-41949156" checked=""/><div class="controls bullet"><span class="by">fiddlerwoaroof</span><span>|</span><a href="#41949135">parent</a><span>|</span><a href="#41949261">next</a><span>|</span><label class="collapse" for="c-41949156">[-]</label><label class="expand" for="c-41949156">[1 more]</label></div><br/><div class="children"><div class="content">Flink does have a SQL join now that you can make work.  Streaming joins remain a hard problem, though and, imo, SQL doesn’t map nicely onto streaming systems.</div><br/></div></div></div></div><div id="41949368" class="c"><input type="checkbox" id="c-41949368" checked=""/><div class="controls bullet"><span class="by">neeleshs</span><span>|</span><a href="#41949135">prev</a><span>|</span><a href="#41950865">next</a><span>|</span><label class="collapse" for="c-41949368">[-]</label><label class="expand" for="c-41949368">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Unlike batch tables, streams are infinite. You can&#x27;t &quot;just wait&quot; for all the rows to arrive before performing a join.&quot;<p>I view batch tables as simply a given state of some set of streams at a point in time. Running the same query against &quot;batch&quot; tables at different points in time yields different results (assuming the table is churning over time).</div><br/><div id="41950215" class="c"><input type="checkbox" id="c-41950215" checked=""/><div class="controls bullet"><span class="by">lsuresh</span><span>|</span><a href="#41949368">parent</a><span>|</span><a href="#41950865">next</a><span>|</span><label class="collapse" for="c-41950215">[-]</label><label class="expand" for="c-41950215">[1 more]</label></div><br/><div class="children"><div class="content">Your mental model is spot on and described quite well here: <a href="https:&#x2F;&#x2F;current.confluent.io&#x2F;2024-sessions&#x2F;streaming-queries-without-compromise" rel="nofollow">https:&#x2F;&#x2F;current.confluent.io&#x2F;2024-sessions&#x2F;streaming-queries...</a></div><br/></div></div></div></div><div id="41950865" class="c"><input type="checkbox" id="c-41950865" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#41949368">prev</a><span>|</span><a href="#41949755">next</a><span>|</span><label class="collapse" for="c-41950865">[-]</label><label class="expand" for="c-41950865">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Streaming data isn&#x27;t static like tables in databases—it&#x27;s unbounded, constantly updating, and poses significant challenges in managing state.<p>I don&#x27;t really see the difference between tables &amp; streams. Data in tables changes over time too. You can model a stream as a table with any degree of fidelity you desire. In fact, I believe this could be considered a common approach for implementing streaming abstractions.</div><br/><div id="41950955" class="c"><input type="checkbox" id="c-41950955" checked=""/><div class="controls bullet"><span class="by">pgwhalen</span><span>|</span><a href="#41950865">parent</a><span>|</span><a href="#41949755">next</a><span>|</span><label class="collapse" for="c-41950955">[-]</label><label class="expand" for="c-41950955">[1 more]</label></div><br/><div class="children"><div class="content">When one queries a table though, it&#x27;s only query at one point in time.  Querying a stream implies that your result set is a stream as well, which introduces a whole separate set of complexities to worry about both as an implementor of the query engine and a client.</div><br/></div></div></div></div><div id="41949755" class="c"><input type="checkbox" id="c-41949755" checked=""/><div class="controls bullet"><span class="by">hamandcheese</span><span>|</span><a href="#41950865">prev</a><span>|</span><label class="collapse" for="c-41949755">[-]</label><label class="expand" for="c-41949755">[2 more]</label></div><br/><div class="children"><div class="content">It seems intuitive to me that a correct streaming join is impossible without an infinite buffer and strong guarantees on how events are ordered. The number of real world systems offering both of those guarantees is zero. Anyone espousing streaming joins as a general solution should be avoided at all costs, particularly if they have a title that contains &quot;architect&quot; or &quot;enterprise&quot; (god forbid both in the same title).<p>At best, it is a trick to be applied in very specific circumstances.</div><br/><div id="41950005" class="c"><input type="checkbox" id="c-41950005" checked=""/><div class="controls bullet"><span class="by">ryzhyk</span><span>|</span><a href="#41949755">parent</a><span>|</span><label class="collapse" for="c-41950005">[-]</label><label class="expand" for="c-41950005">[1 more]</label></div><br/><div class="children"><div class="content">A streaming join indeed requires an unbounded buffer in the most general case when inputs keep growing and any input record on one side of the join can match any record on the other side. However, it does not require inputs to be ordered. An incremental query engine such as Feldera or Materialize can handle out-of-order data and offer strong consistency guarantees (disclaimer: I am a developer of Feldera).  In practice, unbounded buffers can often be avoided as well. This may require a specialized join such as as-of join (<a href="https:&#x2F;&#x2F;www.feldera.com&#x2F;blog&#x2F;asof-join" rel="nofollow">https:&#x2F;&#x2F;www.feldera.com&#x2F;blog&#x2F;asof-join</a>) and some GC machinery.</div><br/></div></div></div></div></div></div></div></div></div></body></html>