<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1729414851290" as="style"/><link rel="stylesheet" href="styles.css?v=1729414851290"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/norvig/pytudes/blob/main/ipynb/Triplets.ipynb">The Languages of English, Math, and Programming</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>stereoabuse</span> | <span>13 comments</span></div><br/><div><div id="41892687" class="c"><input type="checkbox" id="c-41892687" checked=""/><div class="controls bullet"><span class="by">nick0garvey</span><span>|</span><a href="#41892497">next</a><span>|</span><label class="collapse" for="c-41892687">[-]</label><label class="expand" for="c-41892687">[4 more]</label></div><br/><div class="children"><div class="content">I took a Udacity class by Norvig [1] and my abilities as a programmer clearly were improved afterward.<p>His code here demonstrates why. It is both shorter and much easier to understand than anything the LLMs generated. It is not always as efficient as the LLMs (who often skip the third loop by calculating the last factor), but it is definitely the code I would prefer to work with in most situations.<p>[1] <a href="https:&#x2F;&#x2F;www.udacity.com&#x2F;course&#x2F;design-of-computer-programs--cs212" rel="nofollow">https:&#x2F;&#x2F;www.udacity.com&#x2F;course&#x2F;design-of-computer-programs--...</a></div><br/><div id="41892999" class="c"><input type="checkbox" id="c-41892999" checked=""/><div class="controls bullet"><span class="by">upghost</span><span>|</span><a href="#41892687">parent</a><span>|</span><a href="#41893592">next</a><span>|</span><label class="collapse" for="c-41892999">[-]</label><label class="expand" for="c-41892999">[2 more]</label></div><br/><div class="children"><div class="content">Single handedly most important class in my career back in the day. It took me 3 months to really grok and generalize the Qpig algorithm, even my professors couldn&#x27;t explain it.<p>It&#x27;s amazing how he never used the words &quot;AI&quot; once in this course despite the fact that it is a straight up AI course.<p>I revisit the course notes at least once a year and I still walk away with something new every time.</div><br/><div id="41893895" class="c"><input type="checkbox" id="c-41893895" checked=""/><div class="controls bullet"><span class="by">JohnKemeny</span><span>|</span><a href="#41892687">root</a><span>|</span><a href="#41892999">parent</a><span>|</span><a href="#41893592">next</a><span>|</span><label class="collapse" for="c-41893895">[-]</label><label class="expand" for="c-41893895">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the Qpig algorithm?</div><br/></div></div></div></div><div id="41893592" class="c"><input type="checkbox" id="c-41893592" checked=""/><div class="controls bullet"><span class="by">l33t7332273</span><span>|</span><a href="#41892687">parent</a><span>|</span><a href="#41892999">prev</a><span>|</span><a href="#41892497">next</a><span>|</span><label class="collapse" for="c-41893592">[-]</label><label class="expand" for="c-41893592">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It is both shorter and much easier to understand than anything the LLMs generated.<p>I think this makes sense. LLMs are trained on average code on average. This means they produce average code, on average.</div><br/></div></div></div></div><div id="41892497" class="c"><input type="checkbox" id="c-41892497" checked=""/><div class="controls bullet"><span class="by">earslap</span><span>|</span><a href="#41892687">prev</a><span>|</span><a href="#41892867">next</a><span>|</span><label class="collapse" for="c-41892497">[-]</label><label class="expand" for="c-41892497">[1 more]</label></div><br/><div class="children"><div class="content">It is more obvious when taken to extreme: With the current feedforward transformer architectures, there is a fixed amount of compute per token. Imagine asking a very hard question with a yes&#x2F;no answer to an LLM. There are infinite number of cases where the compute available to the calculation of the next token is not enough to definitively solve that problem, even given &quot;perfect&quot; training.<p>You can increase the compute for allowing more tokens for it to use as a &quot;scratch pad&quot; so the total compute available will be num_tokens * ops_per_token but there still are infinite amount of problems you can ask that will not be computable within that constraint.<p>But, you can offload computation by asking for the description of the computation, instead of asking for the LLM to compute it. I&#x27;m no mathematician but I would not be surprised to learn that the above limit applies here as well in some sense (maybe there are solutions to problems that can&#x27;t be represented in a reasonable number of symbols given our constraints - Kolmogorov Complexity and all that), but still for most practical (and beyond) purposes this is a huge improvement and should be enough for most things we care about. Just letting the system describe the computation steps to solve a problem and executing that computation separately offline (then feeding it back if necessary) is a necessary component if we want to do more useful things.</div><br/></div></div><div id="41892867" class="c"><input type="checkbox" id="c-41892867" checked=""/><div class="controls bullet"><span class="by">ryandv</span><span>|</span><a href="#41892497">prev</a><span>|</span><a href="#41892749">next</a><span>|</span><label class="collapse" for="c-41892867">[-]</label><label class="expand" for="c-41892867">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s worth noting that math and programming do not appear to be considered &quot;languages&quot; by much of the academic and&#x2F;or neuroscientific literature; see [0] on the front page right now and my comments regarding the same [1].<p>[0] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41868884">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41868884</a><p>[1] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41892701">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41892701</a></div><br/></div></div><div id="41892749" class="c"><input type="checkbox" id="c-41892749" checked=""/><div class="controls bullet"><span class="by">segmondy</span><span>|</span><a href="#41892867">prev</a><span>|</span><a href="#41892652">next</a><span>|</span><label class="collapse" for="c-41892749">[-]</label><label class="expand" for="c-41892749">[1 more]</label></div><br/><div class="children"><div class="content">Tried these with some local models and these are the ones that generated the program one shot, a few of them also generated the results correctly one shot.<p>llama3.1-70b, llama3.1-405b, deepseekcoder2.5, gemma-27b, mistral-large, qwen2.5-72b.  <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;segmond&#x2F;8992a8ec5976ff6533d797caafe151fa" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;segmond&#x2F;8992a8ec5976ff6533d797caafe1...</a><p>I like how the solution sort of varies across most, tho mistral and qwen look really similar.</div><br/></div></div><div id="41892652" class="c"><input type="checkbox" id="c-41892652" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#41892749">prev</a><span>|</span><a href="#41892312">next</a><span>|</span><label class="collapse" for="c-41892652">[-]</label><label class="expand" for="c-41892652">[1 more]</label></div><br/><div class="children"><div class="content">Gut feel: doing this in two steps (1. write an algorithm for and 2. write code for)  or even chain-of-thought prompting might yield better results.</div><br/></div></div><div id="41892312" class="c"><input type="checkbox" id="c-41892312" checked=""/><div class="controls bullet"><span class="by">owenpalmer</span><span>|</span><a href="#41892652">prev</a><span>|</span><a href="#41892506">next</a><span>|</span><label class="collapse" for="c-41892312">[-]</label><label class="expand" for="c-41892312">[3 more]</label></div><br/><div class="children"><div class="content">A formal notation for reasoning could possibly solve some reasoning issues for LLMs. Perhaps something like Lojban or symbolic logic. We don&#x27;t have a lot of data for it, but it might be possible to synthetically generate it.<p>On a dark note, I wonder if increasing AI reasoning capability could have dangerous results. Currently, LLMs are relatively empathetic, and seem to factor the complex human experience into it&#x27;s responses. Would making LLMs more logical, cold, and calculating result in them stepping on things which humans care about?</div><br/><div id="41892996" class="c"><input type="checkbox" id="c-41892996" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#41892312">parent</a><span>|</span><a href="#41892705">next</a><span>|</span><label class="collapse" for="c-41892996">[-]</label><label class="expand" for="c-41892996">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A formal notation for reasoning could possibly solve some reasoning issues for LLMs. Perhaps something like Lojban or symbolic logic. We don&#x27;t have a lot of data for it, but it might be possible to synthetically generate it.<p>There&#x27;s definitely anecdata supporting this. For some time chatgpt was better on a lot of arithmetic&#x2F;logic type tasks if you asked it to generate a python program to do x than if you just asked it to do x for example.  I haven&#x27;t tested this specifically on the latest generation but my feeling is it has caught up a lot.</div><br/></div></div><div id="41892705" class="c"><input type="checkbox" id="c-41892705" checked=""/><div class="controls bullet"><span class="by">Jianghong94</span><span>|</span><a href="#41892312">parent</a><span>|</span><a href="#41892996">prev</a><span>|</span><a href="#41892506">next</a><span>|</span><label class="collapse" for="c-41892705">[-]</label><label class="expand" for="c-41892705">[1 more]</label></div><br/><div class="children"><div class="content">Due to the extreme data quantity requirement for pre-training, LLM effectively locks your reasoning language into the lowest common denominator, aka Python. Sure, people (maybe very smart) can come up with reasonable, effective, efficient notation; the problem is to train the model to use it properly.</div><br/></div></div></div></div><div id="41892506" class="c"><input type="checkbox" id="c-41892506" checked=""/><div class="controls bullet"><span class="by">downboots</span><span>|</span><a href="#41892312">prev</a><span>|</span><label class="collapse" for="c-41892506">[-]</label><label class="expand" for="c-41892506">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The language that a problem-solver uses matters!<p>Because the &quot;intelligence&quot; is borrowed from language (lower entropy)</div><br/></div></div></div></div></div></div></div></body></html>