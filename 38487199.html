<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701507667135" as="style"/><link rel="stylesheet" href="styles.css?v=1701507667135"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/unslothai/unsloth">Show HN: 80% faster, 50% less memory, 0% loss of accuracy Llama finetuning</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>danielhanchen</span> | <span>96 comments</span></div><br/><div><div id="38494191" class="c"><input type="checkbox" id="c-38494191" checked=""/><div class="controls bullet"><span class="by">apsec112</span><span>|</span><a href="#38496601">next</a><span>|</span><label class="collapse" for="c-38494191">[-]</label><label class="expand" for="c-38494191">[27 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t run the code, but... how is this even possible? I&#x27;ve done PyTorch profiling on QLoRA Llama-2-70B fine tunes, and the runtime is dominated by the large matrix multiplies in the MLP layers, plus a bit for attention. Under the hood, this repo calls the same torch.matmul() for MLP and flash_attn_func() for attention as HuggingFace does. So how can it be that much faster? They have a few Triton kernels, but there appears to be no Triton on MLP or attention and that&#x27;s most of the bottleneck.</div><br/><div id="38495137" class="c"><input type="checkbox" id="c-38495137" checked=""/><div class="controls bullet"><span class="by">WhitneyLand</span><span>|</span><a href="#38494191">parent</a><span>|</span><a href="#38494478">next</a><span>|</span><label class="collapse" for="c-38495137">[-]</label><label class="expand" for="c-38495137">[4 more]</label></div><br/><div class="children"><div class="content">They say it’s due a custom optimized version of autograd which is sort of a key calculus component. They also mention simple things like function inlining or memory optimizations. It seems plausible these things could be optimized.<p>Whatever advantage they have I don’t see how they would be able to to keep it for long as part of their closed source “pro” version.<p>If it’s low hanging fruit the open source equivalents are bound to snipe them before long.</div><br/><div id="38495290" class="c"><input type="checkbox" id="c-38495290" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495137">parent</a><span>|</span><a href="#38494478">next</a><span>|</span><label class="collapse" for="c-38495290">[-]</label><label class="expand" for="c-38495290">[3 more]</label></div><br/><div class="children"><div class="content">There&#x27;s more as well!! I agree hypothetically in a few years people will catch up - we&#x27;re well aware of that! But we made this into a startup, and so this was just one product we were releasing! We&#x27;re going to be making many AI products in the coming weeks!</div><br/><div id="38495498" class="c"><input type="checkbox" id="c-38495498" checked=""/><div class="controls bullet"><span class="by">WhitneyLand</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495290">parent</a><span>|</span><a href="#38494478">next</a><span>|</span><label class="collapse" for="c-38495498">[-]</label><label class="expand" for="c-38495498">[2 more]</label></div><br/><div class="children"><div class="content">That sounds really great, we need all the advancement we can get in this field.<p>Best of luck and all success to you!</div><br/><div id="38495518" class="c"><input type="checkbox" id="c-38495518" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495498">parent</a><span>|</span><a href="#38494478">next</a><span>|</span><label class="collapse" for="c-38495518">[-]</label><label class="expand" for="c-38495518">[1 more]</label></div><br/><div class="children"><div class="content">Thanks a bunch!! Super appreciate it!</div><br/></div></div></div></div></div></div></div></div><div id="38494478" class="c"><input type="checkbox" id="c-38494478" checked=""/><div class="controls bullet"><span class="by">TheGeminon</span><span>|</span><a href="#38494191">parent</a><span>|</span><a href="#38495137">prev</a><span>|</span><a href="#38495528">next</a><span>|</span><label class="collapse" for="c-38494478">[-]</label><label class="expand" for="c-38494478">[13 more]</label></div><br/><div class="children"><div class="content">There is a more detailed explanation at <a href="https:&#x2F;&#x2F;unsloth.ai&#x2F;introducing" rel="nofollow noreferrer">https:&#x2F;&#x2F;unsloth.ai&#x2F;introducing</a></div><br/><div id="38494553" class="c"><input type="checkbox" id="c-38494553" checked=""/><div class="controls bullet"><span class="by">apsec112</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38494478">parent</a><span>|</span><a href="#38495528">next</a><span>|</span><label class="collapse" for="c-38494553">[-]</label><label class="expand" for="c-38494553">[12 more]</label></div><br/><div class="children"><div class="content">That... doesn&#x27;t really explain how they can get such a high number? Standard FLOP efficiency on fine-tuning big models is like 30-40%. How can you get 750%?</div><br/><div id="38495080" class="c"><input type="checkbox" id="c-38495080" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38494553">parent</a><span>|</span><a href="#38495528">next</a><span>|</span><label class="collapse" for="c-38495080">[-]</label><label class="expand" for="c-38495080">[11 more]</label></div><br/><div class="children"><div class="content">Hey! Great question! That&#x27;s what I&#x27;m confused about as well!<p>So in GPUs the goal is to saturate the GPU with matrix multiplies instead of data movement. I&#x27;ll write a more detailed blog but approximately:<p>1. Flash Attention v2 reduces the time taken by 17% or so<p>2. RoPE Triton kernels: -7.1%<p>3. RMS Layernorm in Triton: -3.1%<p>4. Cross Entropy in Triton: -1%<p>5. Manual autograd for MLP: -4%<p>6. Manual QKV autograd: -2%<p>7. Manual O autograd: -2%<p>8. Smart cache evictions and reduced data duplications etc: -30%<p>9. And other tricks in the Max and Pro versions makes it 30x faster<p>You can see it&#x27;s just tricks in each step, which accumulate together to make to go faster.<p>I&#x27;ll write up a blog post to detail it all in the future!!!</div><br/><div id="38495796" class="c"><input type="checkbox" id="c-38495796" checked=""/><div class="controls bullet"><span class="by">demosthanos</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495080">parent</a><span>|</span><a href="#38495925">next</a><span>|</span><label class="collapse" for="c-38495796">[-]</label><label class="expand" for="c-38495796">[9 more]</label></div><br/><div class="children"><div class="content">&gt; And other tricks in the Max and Pro versions makes it 30x faster<p>This feels like the collecting underpants meme. Phase 1: Get to the same performance as other methods. Phase 2: ???. Phase 3: Now you&#x27;re at 750%!<p>You may or may not actually have succeeded at what you claim to, but you&#x27;re not being very persuasive. I realize that you&#x27;re trying to turn these tricks into a profit and revealing them would destroy that possibility, but you&#x27;re going to have a really hard time persuading people to pay for a product that does something that enormous teams of PhDs at BigTech haven&#x27;t been able to pull off on the basis of &quot;trust me&quot;.</div><br/><div id="38495926" class="c"><input type="checkbox" id="c-38495926" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495796">parent</a><span>|</span><a href="#38495925">next</a><span>|</span><label class="collapse" for="c-38495926">[-]</label><label class="expand" for="c-38495926">[8 more]</label></div><br/><div class="children"><div class="content">I agree fully - what do you suggest then? OSS the entire code base and using AGPL3? I tried that with <a href="https:&#x2F;&#x2F;github.com&#x2F;danielhanchen&#x2F;hyperlearn">https:&#x2F;&#x2F;github.com&#x2F;danielhanchen&#x2F;hyperlearn</a> to no avail - we couldn&#x27;t even monetize it at all, so I just OSSed everything.<p>I listed all the research articles and methods in Hyperlearn which in the end were gobbled up by other packages.<p>We still have to cover life expenses and stuff sadly as a startup.<p>Do you have any suggestions how we could go about this? We thought maybe an actual training &#x2F; inference platform, and not even OSSing any code, but we decided against this, so we OSSed some code.<p>Any suggestions are welcome!</div><br/><div id="38497061" class="c"><input type="checkbox" id="c-38497061" checked=""/><div class="controls bullet"><span class="by">welzel</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495926">parent</a><span>|</span><a href="#38496046">next</a><span>|</span><label class="collapse" for="c-38497061">[-]</label><label class="expand" for="c-38497061">[1 more]</label></div><br/><div class="children"><div class="content">Finding a OOS business model is non-trivial.<p>Maybe you should talk to <a href="https:&#x2F;&#x2F;goodsnooze.gumroad.com&#x2F;l&#x2F;macwhisper" rel="nofollow noreferrer">https:&#x2F;&#x2F;goodsnooze.gumroad.com&#x2F;l&#x2F;macwhisper</a> to get some inspiration?<p>People are paying for convenience.<p>as for the technology itself: the B2B market is super-super early and i understand everybody is in goldrush mode, however 98% of all startups will not survive the next 3-5 years.<p>From the demand site: Companies are still sleeping, you can see very very very few  proof of concept implementation, but basically nothing goes to production.<p>The rate of innovation is extremely high with LLM, making it a bad investment for a company.<p>My idea: OSS everything, become an expert in the field, learn how to sell, survive from consulting services. Don´t build products, do paid projects instead.<p>Focus all your energy to understand customer needs and building your target audience.<p>Be ready when the time is right to build a startup around LLM.<p>Don´t waste time building technology, develop your business instead.</div><br/></div></div><div id="38496046" class="c"><input type="checkbox" id="c-38496046" checked=""/><div class="controls bullet"><span class="by">wsxiaoys</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495926">parent</a><span>|</span><a href="#38497061">prev</a><span>|</span><a href="#38496792">next</a><span>|</span><label class="collapse" for="c-38496046">[-]</label><label class="expand" for="c-38496046">[4 more]</label></div><br/><div class="children"><div class="content">Wow, this is a great topic. I don&#x27;t really have specific suggestions, but I&#x27;d like to contribute some thoughts on the matter.<p>Monetizing anything isn&#x27;t inherently problematic; the challenge lies in defining what should be paid for and what should be offered for free.<p>In the realm of open-source products and SaaS, the common practice is to provide free self-hosting options while charging for cloud hosting or enterprise-specific features, such as access control and authentication integrations.<p>However, the landscape becomes significantly more challenging for LLMOps (assuming you are still focusing on training as a major aspect of your business, which can be categorized as LLMOps).<p>Historically, there haven&#x27;t been many success stories in this area (with exceptions 
 like wand.ai, which focusing on tracking experiments). I believe this difficulty arises from the largely ad-hoc nature of training and fine-tuning processes, making standardization a challenge, coupled with the infrequency of these tasks.<p>That being said, training&#x2F;finetuning is a valuable technique. However, transforming it into a company that offers products is really challenging. Successful examples in this realm typically depend heavily on solution customization or consulting-oriented business models.</div><br/><div id="38496145" class="c"><input type="checkbox" id="c-38496145" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38496046">parent</a><span>|</span><a href="#38496792">next</a><span>|</span><label class="collapse" for="c-38496145">[-]</label><label class="expand" for="c-38496145">[3 more]</label></div><br/><div class="children"><div class="content">Thanks for the points!
I agree monetization in the LLM Ops space is hard and complex.
Agreed fully on customizing solutions or consulting.<p>Yep self hosting solutions like Redhat, or DBs like MongoDB or Gitlab&#x27;s dashboard style approach could work - the issue is now as you mentioned we offer training and finetuning.<p>We do plan to offer inference as well, plus the data gathering process, and the final prompt engineering side - but we thought why not have a shot?<p>It&#x27;s possible best to make a training and inference platform - maybe some sort of personal ChatGPT training for the public - everyone can train their own personal ChatGPT not via ChatGPT&#x27;s in context learning or RAG, but coupled with actual fast 30x finetuning, a personal bot can truly be possible.<p>Thaks for the suggestions!</div><br/><div id="38496470" class="c"><input type="checkbox" id="c-38496470" checked=""/><div class="controls bullet"><span class="by">_boffin_</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38496145">parent</a><span>|</span><a href="#38496792">next</a><span>|</span><label class="collapse" for="c-38496470">[-]</label><label class="expand" for="c-38496470">[2 more]</label></div><br/><div class="children"><div class="content">You have companies that are spending good money on fine-tuning and will start spending money on fine-tuning. It seems like it would almost be easier to just go directly to these companies by looking at their blog posts--they&#x27;re telling you that they&#x27;re doing it in some way or another. I know Plaid and friends are doing it.<p>It&#x27;s costing them x. you can shave y off. you can get improvements to market faster and cheaper.</div><br/><div id="38496711" class="c"><input type="checkbox" id="c-38496711" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38496470">parent</a><span>|</span><a href="#38496792">next</a><span>|</span><label class="collapse" for="c-38496711">[-]</label><label class="expand" for="c-38496711">[1 more]</label></div><br/><div class="children"><div class="content">Interesting points! I shall try this with my bro!!<p>I was thinking along the lines of say the cost of A100s or H100s * electricity cost and engineering costs then how much we save, and some discounting factor.</div><br/></div></div></div></div></div></div></div></div><div id="38496792" class="c"><input type="checkbox" id="c-38496792" checked=""/><div class="controls bullet"><span class="by">mdekkers</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495926">parent</a><span>|</span><a href="#38496046">prev</a><span>|</span><a href="#38495925">next</a><span>|</span><label class="collapse" for="c-38496792">[-]</label><label class="expand" for="c-38496792">[2 more]</label></div><br/><div class="children"><div class="content">You don’t need to explain every detail of how you do what you do, your product should speak for itself - outcomes count. If you go to a restaurant, you don’t demand to stand in the kitchen and inspect each ingredient and process, right?<p>I appreciate this probably isn’t a popular HN opinion, but as you say, you need to make a living. If you have produced something novel that is working, put the gaspedal down and monetise the absolute living daylights out of it as long as you can. Because that is what everyone with _money_ is doing. You don’t see OpenAI opening all their research and tricks now, do you?<p>Do your thing, buddy, and make your money. All the best with your startup, and don’t get distracted by the people clamouring for your recipes.</div><br/><div id="38496870" class="c"><input type="checkbox" id="c-38496870" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38496792">parent</a><span>|</span><a href="#38495925">next</a><span>|</span><label class="collapse" for="c-38496870">[-]</label><label class="expand" for="c-38496870">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! That&#x27;s what I was trying to convery just I couldn&#x27;t say it like that! :)<p>Sadly OpenAI did in fact open source everything, but now revenue is king - I&#x27;m sure they will open source stuff in the future once the time is right.<p>But thanks a lot - it means a lot - highly appreciate it!!!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38495528" class="c"><input type="checkbox" id="c-38495528" checked=""/><div class="controls bullet"><span class="by">bradfox2</span><span>|</span><a href="#38494191">parent</a><span>|</span><a href="#38494478">prev</a><span>|</span><a href="#38496601">next</a><span>|</span><label class="collapse" for="c-38495528">[-]</label><label class="expand" for="c-38495528">[9 more]</label></div><br/><div class="children"><div class="content">These are significant claims locked behind a paid &#x27;pro&#x27; version.  Red flags.</div><br/><div id="38495550" class="c"><input type="checkbox" id="c-38495550" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495528">parent</a><span>|</span><a href="#38496527">next</a><span>|</span><label class="collapse" for="c-38495550">[-]</label><label class="expand" for="c-38495550">[7 more]</label></div><br/><div class="children"><div class="content">Sorry about that - I&#x27;m super new to pricing and stuff so it might seem off since I&#x27;m literally making the plans with my bro as we go along.<p>If you don&#x27;t believe the timings, I was the author of Hyperlearn <a href="https:&#x2F;&#x2F;github.com&#x2F;danielhanchen&#x2F;hyperlearn">https:&#x2F;&#x2F;github.com&#x2F;danielhanchen&#x2F;hyperlearn</a> which makes ML faster - I also listed the papers which cite the algos.<p>I also used to work at NVIDIA making TSNE 2000x faster on GPUs and some other algos like Randomized SVD, sparse matrix multiplies etc.<p>If you have any suggestions on a more appropriate pricing strategy - I&#x27;m all ears!!<p>I really don&#x27;t know much about pricing and the open core model, so I&#x27;m making stuff up literally.</div><br/><div id="38496370" class="c"><input type="checkbox" id="c-38496370" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495550">parent</a><span>|</span><a href="#38495711">next</a><span>|</span><label class="collapse" for="c-38496370">[-]</label><label class="expand" for="c-38496370">[2 more]</label></div><br/><div class="children"><div class="content">Pro says single GPU some places and multi-GPU others. I really hope it is multi-GPU because basically every enthusiast making finetunes is using 2-4 3090s locally or renting 8x GPU boxes on Vast for finetuning. If multi-GPU is enterprise only you will miss out on basically the largest customer segment as far as I can tell.</div><br/><div id="38496426" class="c"><input type="checkbox" id="c-38496426" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38496370">parent</a><span>|</span><a href="#38495711">next</a><span>|</span><label class="collapse" for="c-38496426">[-]</label><label class="expand" for="c-38496426">[1 more]</label></div><br/><div class="children"><div class="content">Apologies on the confusion - I&#x27;m still trying to flesh stuff out on the differentating factors with my bro - I&#x27;ll update it once we&#x27;re fully sure - sorry again!</div><br/></div></div></div></div><div id="38495711" class="c"><input type="checkbox" id="c-38495711" checked=""/><div class="controls bullet"><span class="by">bradfox2</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495550">parent</a><span>|</span><a href="#38496370">prev</a><span>|</span><a href="#38496757">next</a><span>|</span><label class="collapse" for="c-38495711">[-]</label><label class="expand" for="c-38495711">[2 more]</label></div><br/><div class="children"><div class="content">Are the 30x claims comparing full update training vs qlora&#x2F;4bit weights?</div><br/><div id="38495908" class="c"><input type="checkbox" id="c-38495908" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495711">parent</a><span>|</span><a href="#38496757">next</a><span>|</span><label class="collapse" for="c-38495908">[-]</label><label class="expand" for="c-38495908">[1 more]</label></div><br/><div class="children"><div class="content">Sorry about the confusion - the 30X is comparing QLora with QLora - all benchmarking is QLoRa bsz=2, ga=4</div><br/></div></div></div></div><div id="38496757" class="c"><input type="checkbox" id="c-38496757" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38495550">parent</a><span>|</span><a href="#38495711">prev</a><span>|</span><a href="#38496527">next</a><span>|</span><label class="collapse" for="c-38496757">[-]</label><label class="expand" for="c-38496757">[2 more]</label></div><br/><div class="children"><div class="content">If this is all legit, you’re best trying to get an in somehow with a16z. They’re throwing money left and right at people doing this kind of stuff.</div><br/><div id="38496776" class="c"><input type="checkbox" id="c-38496776" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494191">root</a><span>|</span><a href="#38496757">parent</a><span>|</span><a href="#38496527">next</a><span>|</span><label class="collapse" for="c-38496776">[-]</label><label class="expand" for="c-38496776">[1 more]</label></div><br/><div class="children"><div class="content">Oh my A16z? Do you have any contacts? :))<p>But for now - our goal is somehow to get revenue ourselves via some cool AI products, and trying to shrink the expenses to 0 (like via our fast training methods)</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38496601" class="c"><input type="checkbox" id="c-38496601" checked=""/><div class="controls bullet"><span class="by">neilmovva</span><span>|</span><a href="#38494191">prev</a><span>|</span><a href="#38493724">next</a><span>|</span><label class="collapse" for="c-38496601">[-]</label><label class="expand" for="c-38496601">[3 more]</label></div><br/><div class="children"><div class="content">promising results, excited to try it out!<p>question on the perf benchmarks: why do all the results with 2 GPUs &amp; DDP take longer than the single GPU case? 
Both benchmarks do the same amount of work, one training epoch, so this <i>negative</i> scaling is surprising.</div><br/><div id="38496734" class="c"><input type="checkbox" id="c-38496734" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38496601">parent</a><span>|</span><a href="#38493724">next</a><span>|</span><label class="collapse" for="c-38496734">[-]</label><label class="expand" for="c-38496734">[2 more]</label></div><br/><div class="children"><div class="content">So there&#x27;s 2 main reasons:<p>1. DDP itself has an overhead since it has to synchronize gradients at each training step since GPU0 and GPU1 has to give gradients to GPU0.<p>2. Huggingface seems to not be optimized well for DDP mainly due to inefficient data movement - we fixed that - interestingly - even on 1 GPU it&#x27;s faster.</div><br/><div id="38497114" class="c"><input type="checkbox" id="c-38497114" checked=""/><div class="controls bullet"><span class="by">neilmovva</span><span>|</span><a href="#38496601">root</a><span>|</span><a href="#38496734">parent</a><span>|</span><a href="#38493724">next</a><span>|</span><label class="collapse" for="c-38497114">[-]</label><label class="expand" for="c-38497114">[1 more]</label></div><br/><div class="children"><div class="content">I agree that synchronization causes overhead, so 2x GPUs won&#x27;t achieve the ideal 0.5x total runtime. But here, taking your Alpaca benchmark as an example, we are seeing 2x GPUs get 3.6x runtime with Huggingface, or 1.15x with Unsloth Max.<p>In other words, every benchmark, in either HF or Unsloth, is slower in absolute terms when going from 1 to 2 GPUs. That makes me think something is wrong with the test.<p>Could you share your benchmark code?</div><br/></div></div></div></div></div></div><div id="38493724" class="c"><input type="checkbox" id="c-38493724" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#38496601">prev</a><span>|</span><a href="#38494918">next</a><span>|</span><label class="collapse" for="c-38493724">[-]</label><label class="expand" for="c-38493724">[9 more]</label></div><br/><div class="children"><div class="content">It&#x27;d be great to have a chronicle of all these efforts. I lost track of the variations quite a long time ago.<p>It&#x27;d be quite a lift unless we&#x27;re just willing to just accept the self reported metrics as golden. And even then, they&#x27;re always qualified by hardware and usage scope. Making it good enough to be useful is the hard part. CI&#x2F;CD pipeline with a bunch of machine configurations and benchmarks along with a reasonable way to communicate them...<p>If anyone&#x27;s up for it you&#x27;d legitimately become indispensable.</div><br/><div id="38495031" class="c"><input type="checkbox" id="c-38495031" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38493724">parent</a><span>|</span><a href="#38495393">next</a><span>|</span><label class="collapse" for="c-38495031">[-]</label><label class="expand" for="c-38495031">[7 more]</label></div><br/><div class="children"><div class="content">Hey there! Yes that&#x27;s exactly what I thought! I was writing up a blog post at <a href="https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;1AOuhMVILE06mD-Go7-RuN47Dg35t1wuK?usp=sharing" rel="nofollow noreferrer">https:&#x2F;&#x2F;colab.research.google.com&#x2F;drive&#x2F;1AOuhMVILE06mD-Go7-R...</a> which step by step shows every change I did plus gave timings &#x2F; mem savings.<p>I&#x27;ll post it once its completed if you&#x27;re interested!</div><br/><div id="38495215" class="c"><input type="checkbox" id="c-38495215" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#38493724">root</a><span>|</span><a href="#38495031">parent</a><span>|</span><a href="#38495393">next</a><span>|</span><label class="collapse" for="c-38495215">[-]</label><label class="expand" for="c-38495215">[6 more]</label></div><br/><div class="children"><div class="content">Thanks. There&#x27;s been a few substantial and laudable efforts which are much appreciated but what I&#x27;m suggesting is an actual continuous infrastructure, like how those benchmarking sites have software for people to run on their machines that phone home so that people who make new benchmarks or new variations can submit them and refine the results.<p>For instance, are any of your prompting tests in say, Korean? What about winograd schema challenges in languages other than English? Japanese for instance, comes with its own unique set of context ambiguities that do not appear in English. I&#x27;m sure dozens of languages are similar. It&#x27;d be nice to have user contributable tests to cover the breadth of use cases here.<p>A great optimization that moves a score let&#x27;s say from 95% -&gt; 5% on &quot;winograd-persian&quot; may be fine or may be a show stopper, depends on what you care about.<p>That&#x27;s why it&#x27;s gotta be normalized, future-proof, and crowdsourced.</div><br/><div id="38495224" class="c"><input type="checkbox" id="c-38495224" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38493724">root</a><span>|</span><a href="#38495215">parent</a><span>|</span><a href="#38495393">next</a><span>|</span><label class="collapse" for="c-38495224">[-]</label><label class="expand" for="c-38495224">[5 more]</label></div><br/><div class="children"><div class="content">Ohhh interesting! So like ML Perf or Faster CPython <a href="https:&#x2F;&#x2F;github.com&#x2F;faster-cpython&#x2F;benchmarking-public">https:&#x2F;&#x2F;github.com&#x2F;faster-cpython&#x2F;benchmarking-public</a>?</div><br/><div id="38495338" class="c"><input type="checkbox" id="c-38495338" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#38493724">root</a><span>|</span><a href="#38495224">parent</a><span>|</span><a href="#38495393">next</a><span>|</span><label class="collapse" for="c-38495338">[-]</label><label class="expand" for="c-38495338">[4 more]</label></div><br/><div class="children"><div class="content">Sure. This thing I propose might already exist in a nascent form.<p>I haven&#x27;t checked in a few months and the way things are moving now...</div><br/><div id="38495412" class="c"><input type="checkbox" id="c-38495412" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38493724">root</a><span>|</span><a href="#38495338">parent</a><span>|</span><a href="#38495393">next</a><span>|</span><label class="collapse" for="c-38495412">[-]</label><label class="expand" for="c-38495412">[3 more]</label></div><br/><div class="children"><div class="content">Interesting!! I&#x27;ll talk with my brother about this - sounds very cool!</div><br/><div id="38496985" class="c"><input type="checkbox" id="c-38496985" checked=""/><div class="controls bullet"><span class="by">ptd</span><span>|</span><a href="#38493724">root</a><span>|</span><a href="#38495412">parent</a><span>|</span><a href="#38495393">next</a><span>|</span><label class="collapse" for="c-38496985">[-]</label><label class="expand" for="c-38496985">[2 more]</label></div><br/><div class="children"><div class="content">Hey Daniel, I would love to help out on this. I&#x27;m learning about LLMs and this benchmarking project sounds like a fun way to further my knowledge and skills. I sent you a message on LinkedIn.<p>Cheers!</div><br/><div id="38497078" class="c"><input type="checkbox" id="c-38497078" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38493724">root</a><span>|</span><a href="#38496985">parent</a><span>|</span><a href="#38495393">next</a><span>|</span><label class="collapse" for="c-38497078">[-]</label><label class="expand" for="c-38497078">[1 more]</label></div><br/><div class="children"><div class="content">Cool lets chat on Linkedin! :)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38494918" class="c"><input type="checkbox" id="c-38494918" checked=""/><div class="controls bullet"><span class="by">graphe</span><span>|</span><a href="#38493724">prev</a><span>|</span><a href="#38495534">next</a><span>|</span><label class="collapse" for="c-38494918">[-]</label><label class="expand" for="c-38494918">[2 more]</label></div><br/><div class="children"><div class="content">Somewhat related: is it worth it to use a P100 or P40? I was gonna get one but seems like pascal isn&#x27;t being supported by more and more projects.</div><br/><div id="38495254" class="c"><input type="checkbox" id="c-38495254" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494918">parent</a><span>|</span><a href="#38495534">next</a><span>|</span><label class="collapse" for="c-38495254">[-]</label><label class="expand" for="c-38495254">[1 more]</label></div><br/><div class="children"><div class="content">P100 - oh my so Xformers for Flash Attention I think does support it, but Triton supports Compute Capability 7.0+, whilst a P100 is 6.0 :(<p>So technically the code can run, but I&#x27;ll have to edit it to remove the Triton changes.</div><br/></div></div></div></div><div id="38495534" class="c"><input type="checkbox" id="c-38495534" checked=""/><div class="controls bullet"><span class="by">0x6c6f6c</span><span>|</span><a href="#38494918">prev</a><span>|</span><a href="#38496663">next</a><span>|</span><label class="collapse" for="c-38495534">[-]</label><label class="expand" for="c-38495534">[4 more]</label></div><br/><div class="children"><div class="content">I see this mentions 2018+ GPUs, but I&#x27;m curious why this wouldn&#x27;t work on say a 1080Ti. My cursory look at the hardware specs shows this has support for CUDA8+ and this states 7.5<p>Would someone be able to tell me more about this?</div><br/><div id="38495936" class="c"><input type="checkbox" id="c-38495936" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495534">parent</a><span>|</span><a href="#38495770">next</a><span>|</span><label class="collapse" for="c-38495936">[-]</label><label class="expand" for="c-38495936">[2 more]</label></div><br/><div class="children"><div class="content">Sorry about 1080 Ti - sadly Triton and Xformers support Cuda 7.0, so unless if OpenAI and Meta makes it support Cuda 6.0, we sadly don&#x27;t support it.<p>The main reason is because from Turing, Tensor Cores got provided, and so the matrix matmuls are all different in Tensor Cores</div><br/><div id="38497147" class="c"><input type="checkbox" id="c-38497147" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#38495534">root</a><span>|</span><a href="#38495936">parent</a><span>|</span><a href="#38495770">next</a><span>|</span><label class="collapse" for="c-38497147">[-]</label><label class="expand" for="c-38497147">[1 more]</label></div><br/><div class="children"><div class="content">Any source recommendations on howto find out the minimum hw requirementsto train LLM with Xbit and YB parameters?</div><br/></div></div></div></div><div id="38495770" class="c"><input type="checkbox" id="c-38495770" checked=""/><div class="controls bullet"><span class="by">zargon</span><span>|</span><a href="#38495534">parent</a><span>|</span><a href="#38495936">prev</a><span>|</span><a href="#38496663">next</a><span>|</span><label class="collapse" for="c-38495770">[-]</label><label class="expand" for="c-38495770">[1 more]</label></div><br/><div class="children"><div class="content">1080 Ti has CUDA capability version 6.1.</div><br/></div></div></div></div><div id="38496663" class="c"><input type="checkbox" id="c-38496663" checked=""/><div class="controls bullet"><span class="by">aerioux</span><span>|</span><a href="#38495534">prev</a><span>|</span><a href="#38494555">next</a><span>|</span><label class="collapse" for="c-38496663">[-]</label><label class="expand" for="c-38496663">[2 more]</label></div><br/><div class="children"><div class="content">If this technology is generalizable to more LLM architectures, y&#x27;all can start messaging venture capitalists with a demo and they can help on the rest (pricing models, customers, etc).</div><br/><div id="38496742" class="c"><input type="checkbox" id="c-38496742" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38496663">parent</a><span>|</span><a href="#38494555">next</a><span>|</span><label class="collapse" for="c-38496742">[-]</label><label class="expand" for="c-38496742">[1 more]</label></div><br/><div class="children"><div class="content">Working on making it work on all archs!!
Probably some sort of automatic dispatcher and automatic autograd engine!</div><br/></div></div></div></div><div id="38494555" class="c"><input type="checkbox" id="c-38494555" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#38496663">prev</a><span>|</span><a href="#38495386">next</a><span>|</span><label class="collapse" for="c-38494555">[-]</label><label class="expand" for="c-38494555">[6 more]</label></div><br/><div class="children"><div class="content">There are a number of papers on optimizing xor chains for cauchy reed Solomon computation, it sounds like a superficially similar problem?</div><br/><div id="38495128" class="c"><input type="checkbox" id="c-38495128" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494555">parent</a><span>|</span><a href="#38495386">next</a><span>|</span><label class="collapse" for="c-38495128">[-]</label><label class="expand" for="c-38495128">[5 more]</label></div><br/><div class="children"><div class="content">Hey! Oh noo we don&#x27;t do any XOR chain optimizations or Cauchy Reed Solomon computations - I had to wikipedia it and learn about them - mroe reading to do!<p>It&#x27;s mainly trying to reduce data movement, maximize FLOP utilization via matrix multiplies, and reducing FLOPs via manually deriving backpropagation equations + more!</div><br/><div id="38496049" class="c"><input type="checkbox" id="c-38496049" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#38494555">root</a><span>|</span><a href="#38495128">parent</a><span>|</span><a href="#38495386">next</a><span>|</span><label class="collapse" for="c-38496049">[-]</label><label class="expand" for="c-38496049">[4 more]</label></div><br/><div class="children"><div class="content">I realize they&#x27;re different, but it seems like there are some similarities. In both, you have some chain of operations you need to do, and you want to minimize their cost and optimize for cache benefits etc.,<p>This is a pretty good overview paper: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2108.02692.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2108.02692.pdf</a> (they claim to be better than the rest -- I haven&#x27;t evaluated their claims in practice yet)<p>The techniques are mostly about ordering and common subexpression elimination for XOR operations and choosing &quot;better&quot; matrices to do the computation with. CRS codes can be used with many different matrices, but it turns out some are better than others for effiency (XOR operations are encoded by 1s in the CRS matrix, so if you choose a CRS matrix with fewer of them while meeting the requirements, you can do less operations and get the same results).</div><br/><div id="38496151" class="c"><input type="checkbox" id="c-38496151" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494555">root</a><span>|</span><a href="#38496049">parent</a><span>|</span><a href="#38495386">next</a><span>|</span><label class="collapse" for="c-38496151">[-]</label><label class="expand" for="c-38496151">[3 more]</label></div><br/><div class="children"><div class="content">OHHH yes yes - sorry you&#x27;re correct - apologies I&#x27;m not too familiar with this - thanks for the paper I&#x27;ll read it through!!<p>Yep so the OSS version does have the reordering of operations - I&#x27;ll write a blog post about it in the coming days!! We also have other tricks up our sleeve to make it go even faster!!</div><br/><div id="38496903" class="c"><input type="checkbox" id="c-38496903" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#38494555">root</a><span>|</span><a href="#38496151">parent</a><span>|</span><a href="#38495386">next</a><span>|</span><label class="collapse" for="c-38496903">[-]</label><label class="expand" for="c-38496903">[2 more]</label></div><br/><div class="children"><div class="content">Ah actually, <a href="https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;fast19-zhou.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;fast19-zhou.pdf</a> is probably a better reference (it includes the discussion of &quot;bitmatrix normalization&quot;, the mentioned process of reducing the number of xors necessary, aside from scheduling and common subexpression elimination).<p>Hope it&#x27;s potentially helpful :)</div><br/><div id="38497042" class="c"><input type="checkbox" id="c-38497042" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494555">root</a><span>|</span><a href="#38496903">parent</a><span>|</span><a href="#38495386">next</a><span>|</span><label class="collapse" for="c-38497042">[-]</label><label class="expand" for="c-38497042">[1 more]</label></div><br/><div class="children"><div class="content">OOOOO thankss!! 100% I&#x27;m reading this - thanks a bunch for the references! Highly appreciate it!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38495386" class="c"><input type="checkbox" id="c-38495386" checked=""/><div class="controls bullet"><span class="by">gentleman11</span><span>|</span><a href="#38494555">prev</a><span>|</span><a href="#38495049">next</a><span>|</span><label class="collapse" for="c-38495386">[-]</label><label class="expand" for="c-38495386">[4 more]</label></div><br/><div class="children"><div class="content">Isnt llama proprietary? Why not dine tune one of the truly open models instead?</div><br/><div id="38495421" class="c"><input type="checkbox" id="c-38495421" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495386">parent</a><span>|</span><a href="#38496066">next</a><span>|</span><label class="collapse" for="c-38495421">[-]</label><label class="expand" for="c-38495421">[1 more]</label></div><br/><div class="children"><div class="content">Llama is generally OSS, except for some gating to large companies - but as a first try I made it work for Llama since the architecture is replicated in other models like Mistral or Yi.</div><br/></div></div><div id="38496066" class="c"><input type="checkbox" id="c-38496066" checked=""/><div class="controls bullet"><span class="by">selfhoster11</span><span>|</span><a href="#38495386">parent</a><span>|</span><a href="#38495421">prev</a><span>|</span><a href="#38495049">next</a><span>|</span><label class="collapse" for="c-38496066">[-]</label><label class="expand" for="c-38496066">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a tremendous open source ecosystem in place for Llama already. This is a huge deal for beginners and model integrators alike.<p>Not to mention that other than beyond 7B models, your options drastically taper off. Mistral and most open base model projects only have models available up to 7 billion parameters or so, which is quite tiny if you are used to the relative ease of using un-finetuned GPT-4 to carry out your tasks of choice.<p>So what options are there? Falcon 40B and MPT-30B - sure, the weights license is all right, but many in the community have reservations about those models&#x27; underperformance, as you can get much more bang for your buck with newer models, in an equal number of weights in a newer base model. Subjectively speaking, it could be a waste of time.<p>Falcon 180B and Yi 34B weights are both issued under non-free licenses, just like Llama 2.<p>Is Llama 2 proprietary? For the vast majority of people, for the vast majority of purposes, no. I&#x27;m not a lawyer, but I think that Meta would be quite unlikely to do more than cut off your HuggingFace access to the repo where new models will be distributed.</div><br/><div id="38496107" class="c"><input type="checkbox" id="c-38496107" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495386">root</a><span>|</span><a href="#38496066">parent</a><span>|</span><a href="#38495049">next</a><span>|</span><label class="collapse" for="c-38496107">[-]</label><label class="expand" for="c-38496107">[1 more]</label></div><br/><div class="children"><div class="content">Thanks to Meta for open sourcing Llama!!! Ye sadly the HFF leaderboard doesn&#x27;t have a high opinion for Falcon. MPT&#x27;s long context via Alibi did work, just less so when compared to RoPE scaling.<p>All thanks to Llama - the LLM community is now vibrant and alive!</div><br/></div></div></div></div></div></div><div id="38495049" class="c"><input type="checkbox" id="c-38495049" checked=""/><div class="controls bullet"><span class="by">xrd</span><span>|</span><a href="#38495386">prev</a><span>|</span><a href="#38494949">next</a><span>|</span><label class="collapse" for="c-38495049">[-]</label><label class="expand" for="c-38495049">[4 more]</label></div><br/><div class="children"><div class="content">OK, this is my favorite .ai domain. And, the logo snaps!</div><br/><div id="38495100" class="c"><input type="checkbox" id="c-38495100" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495049">parent</a><span>|</span><a href="#38494949">next</a><span>|</span><label class="collapse" for="c-38495100">[-]</label><label class="expand" for="c-38495100">[3 more]</label></div><br/><div class="children"><div class="content">Thanks!! My brother came up with the name!! &quot;Un-sloth&quot; where sloth is the slow cute animal, and it also means lazy and slow, and &quot;un&quot; reverses it!</div><br/><div id="38495259" class="c"><input type="checkbox" id="c-38495259" checked=""/><div class="controls bullet"><span class="by">juunpp</span><span>|</span><a href="#38495049">root</a><span>|</span><a href="#38495100">parent</a><span>|</span><a href="#38494949">next</a><span>|</span><label class="collapse" for="c-38495259">[-]</label><label class="expand" for="c-38495259">[2 more]</label></div><br/><div class="children"><div class="content">SSL_ERROR_NO_CYPHER_OVERLAP when checking your site.</div><br/><div id="38495300" class="c"><input type="checkbox" id="c-38495300" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495049">root</a><span>|</span><a href="#38495259">parent</a><span>|</span><a href="#38494949">next</a><span>|</span><label class="collapse" for="c-38495300">[-]</label><label class="expand" for="c-38495300">[1 more]</label></div><br/><div class="children"><div class="content">Do you mean <a href="http:&#x2F;&#x2F;www.unsloth.ai&#x2F;" rel="nofollow noreferrer">http:&#x2F;&#x2F;www.unsloth.ai&#x2F;</a> doesn&#x27;t work? My brother is working on it as we speak!<p>Edit: it seems like <a href="http:&#x2F;&#x2F;unsloth.ai" rel="nofollow noreferrer">http:&#x2F;&#x2F;unsloth.ai</a> works - we&#x27;re talking with our web hosting people to fix it</div><br/></div></div></div></div></div></div></div></div><div id="38494949" class="c"><input type="checkbox" id="c-38494949" checked=""/><div class="controls bullet"><span class="by">TuringNYC</span><span>|</span><a href="#38495049">prev</a><span>|</span><a href="#38495505">next</a><span>|</span><label class="collapse" for="c-38494949">[-]</label><label class="expand" for="c-38494949">[2 more]</label></div><br/><div class="children"><div class="content">wow i wish i could do this with all my M1 pro max neural cores</div><br/><div id="38495106" class="c"><input type="checkbox" id="c-38495106" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38494949">parent</a><span>|</span><a href="#38495505">next</a><span>|</span><label class="collapse" for="c-38495106">[-]</label><label class="expand" for="c-38495106">[1 more]</label></div><br/><div class="children"><div class="content">M1 support is probably coming in the future if there is enough support - could you make an Issue at <a href="https:&#x2F;&#x2F;github.com&#x2F;unslothai&#x2F;unsloth">https:&#x2F;&#x2F;github.com&#x2F;unslothai&#x2F;unsloth</a> - that would be much appreciated!<p>I think there are a few Redditors from &#x2F;r&#x2F;localllama who also requested this, but for now first priority is getting Mistral support!!</div><br/></div></div></div></div><div id="38495505" class="c"><input type="checkbox" id="c-38495505" checked=""/><div class="controls bullet"><span class="by">yunohn</span><span>|</span><a href="#38494949">prev</a><span>|</span><a href="#38495915">next</a><span>|</span><label class="collapse" for="c-38495505">[-]</label><label class="expand" for="c-38495505">[4 more]</label></div><br/><div class="children"><div class="content">This seems very interesting, but I’m very confused why you have gated the &#x2F;max&#x2F;imum speedup version for enterprise-only? It would make more sense to have only the Free and Paid plans differing in performance, and Enterprise getting support&#x2F;etc.</div><br/><div id="38495526" class="c"><input type="checkbox" id="c-38495526" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495505">parent</a><span>|</span><a href="#38495915">next</a><span>|</span><label class="collapse" for="c-38495526">[-]</label><label class="expand" for="c-38495526">[3 more]</label></div><br/><div class="children"><div class="content">Good point - we thought about this - we&#x27;re still figuring out the pricing as we go along - so all suggestions are welcome!<p>I&#x27;m all very new to this, so I&#x27;m literally making stuff as I go along!!<p>Apologies!</div><br/><div id="38495582" class="c"><input type="checkbox" id="c-38495582" checked=""/><div class="controls bullet"><span class="by">yunohn</span><span>|</span><a href="#38495505">root</a><span>|</span><a href="#38495526">parent</a><span>|</span><a href="#38495915">next</a><span>|</span><label class="collapse" for="c-38495582">[-]</label><label class="expand" for="c-38495582">[2 more]</label></div><br/><div class="children"><div class="content">No worries, just my 2c!<p>Given the current state of AI performance, I’d imagine that those without 100s of GPUs but looking to maximise the performance of what they do have, would be a great demographic for the Paid plan.</div><br/><div id="38495939" class="c"><input type="checkbox" id="c-38495939" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495505">root</a><span>|</span><a href="#38495582">parent</a><span>|</span><a href="#38495915">next</a><span>|</span><label class="collapse" for="c-38495939">[-]</label><label class="expand" for="c-38495939">[1 more]</label></div><br/><div class="children"><div class="content">Interesting! I did have some chats from interested people who have say 2 or 4 or 8 GPUs who are willing to somehow buy the Pro plan - the issue is now how do we price it, do we make a training platform? etc</div><br/></div></div></div></div></div></div></div></div><div id="38495915" class="c"><input type="checkbox" id="c-38495915" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#38495505">prev</a><span>|</span><a href="#38496944">next</a><span>|</span><label class="collapse" for="c-38495915">[-]</label><label class="expand" for="c-38495915">[21 more]</label></div><br/><div class="children"><div class="content">What is the motivation behind open sourcing code at all if you&#x27;re not going to open source it all? I don&#x27;t mean this to be an asshole, as I truly want to understand the motivation.</div><br/><div id="38496044" class="c"><input type="checkbox" id="c-38496044" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">parent</a><span>|</span><a href="#38496045">next</a><span>|</span><label class="collapse" for="c-38496044">[-]</label><label class="expand" for="c-38496044">[13 more]</label></div><br/><div class="children"><div class="content">Good point - the main issue is we encountered this exact issue with our old package Hyperlearn (<a href="https:&#x2F;&#x2F;github.com&#x2F;danielhanchen&#x2F;hyperlearn">https:&#x2F;&#x2F;github.com&#x2F;danielhanchen&#x2F;hyperlearn</a>).<p>I OSSed all the code to the community - I&#x27;m actually an extremely open person and I love contributing to the OSS community.<p>The issue was the package got gobbled up by other startups and big tech companies with no credit - I didn&#x27;t want any cash from it, but it stung and hurt really bad hearing other startups and companies claim it was them who made it faster, whilst it was actually my work. It hurt really bad - as an OSS person, I  don&#x27;t want money, but just some recognition for the work.<p>I also used to accept and help everyone with coding up their startup&#x27;s software, but I never got paid or even any thanks - sadly I didn&#x27;t expect the world to be such a hostile place.<p>So after a sad awakening, I decided with my brother instead of OSSing everything, we would first OSS something which is still very good - 5X faster training is already very reasonable.<p>I&#x27;m all open to other suggestions on how we should approach this though! There are no evil intentions - in fact I insisted we OSS EVERYTHING even the 30x faster algos, but after a level headed discussion with my brother - we still have to pay life expenses no?<p>If you have other ways we can go about this - I&#x27;m all ears!! We&#x27;re literally making stuff up as we go along!</div><br/><div id="38496933" class="c"><input type="checkbox" id="c-38496933" checked=""/><div class="controls bullet"><span class="by">nikolayasdf123</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496044">parent</a><span>|</span><a href="#38496636">next</a><span>|</span><label class="collapse" for="c-38496933">[-]</label><label class="expand" for="c-38496933">[2 more]</label></div><br/><div class="children"><div class="content">&gt; gobbled up by other startups and big tech companies with no credit<p>true. saw this myself too for my projects. big tech &#x2F; startups would use your project internally and give you nothing back. sadly happens often.</div><br/><div id="38497051" class="c"><input type="checkbox" id="c-38497051" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496933">parent</a><span>|</span><a href="#38496636">next</a><span>|</span><label class="collapse" for="c-38497051">[-]</label><label class="expand" for="c-38497051">[1 more]</label></div><br/><div class="children"><div class="content">:( Very sad</div><br/></div></div></div></div><div id="38496636" class="c"><input type="checkbox" id="c-38496636" checked=""/><div class="controls bullet"><span class="by">squigz</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496044">parent</a><span>|</span><a href="#38496933">prev</a><span>|</span><a href="#38496057">next</a><span>|</span><label class="collapse" for="c-38496636">[-]</label><label class="expand" for="c-38496636">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for your response, and for open sourcing things at all :)<p>&gt; The issue was the package got gobbled up by other startups and big tech companies with no credit<p>I understand that this is frustrating, but are you open sourcing things for recognition? The fact is companies are going to use 100s of open source packages and aren&#x27;t going to credit them all, or even any.<p>At any rate, I appreciate how difficult your position must be, and wish you luck.</div><br/><div id="38496785" class="c"><input type="checkbox" id="c-38496785" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496636">parent</a><span>|</span><a href="#38496057">next</a><span>|</span><label class="collapse" for="c-38496785">[-]</label><label class="expand" for="c-38496785">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! :)<p>I agree, but generally as a researcher &#x2F; OSS even a nice citation is nice :) There are some cool people who do just that, but some do not.<p>But thanks once again!</div><br/></div></div></div></div><div id="38496057" class="c"><input type="checkbox" id="c-38496057" checked=""/><div class="controls bullet"><span class="by">kristopolous</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496044">parent</a><span>|</span><a href="#38496636">prev</a><span>|</span><a href="#38496045">next</a><span>|</span><label class="collapse" for="c-38496057">[-]</label><label class="expand" for="c-38496057">[8 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a variety of licenses some of which protect you from this problem. Maybe those would be appropriate?</div><br/><div id="38496072" class="c"><input type="checkbox" id="c-38496072" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496057">parent</a><span>|</span><a href="#38496045">next</a><span>|</span><label class="collapse" for="c-38496072">[-]</label><label class="expand" for="c-38496072">[7 more]</label></div><br/><div class="children"><div class="content">Sadly I&#x27;ve tried GPL3 for Hyperlearn and AGPL3 - those licenses only work for UI or Database based OSS - eg MongoDB, Gitlab etc.<p>I still haven&#x27;t figured out how to open source algorithms which don&#x27;t have an UI or database - maybe a training or inference platform?<p>But if we made a training &#x2F; inference platform, then there won&#x27;t be any OSS code.<p>We&#x27;re currently stuck in the middle - do you have any suggestions on this?</div><br/><div id="38496178" class="c"><input type="checkbox" id="c-38496178" checked=""/><div class="controls bullet"><span class="by">Jayakumark</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496072">parent</a><span>|</span><a href="#38496188">next</a><span>|</span><label class="collapse" for="c-38496178">[-]</label><label class="expand" for="c-38496178">[2 more]</label></div><br/><div class="children"><div class="content">Sell binaries without code for individuals&#x2F;enterprises who can train on private data , Get some GPUs and sell training platforms similar to together.ai for enterprises with data privacy guarantee. just make it super simple , give a google like sheet to fill or dump a folder with text files and you can use ml to make it in structured format. User gives<p>Input - &gt; excel, txt etc<p>Select model base -&gt; mystal, llama2<p>output --&gt; fine trained model.<p>Give a fixed cost based on data you got .. say it will take $50 to train on this ? for 25 hours of GPU with your markup.<p>User Pays the bill and get PEFT llama model out.<p>The big problem i see in Finetuning for GPU Poor is no one gives an estimate on how much it will cost for your data on a given model.<p>have a calculator for x words or Bytes and y epochs, here is the cost we are estimating..<p>Once you make your $x million in terms of 50x your pay for the time you invested, you can open source it, but we are greedy when it comes to money.. so opensource model at your will. In the mean time hope no one catches your technique.</div><br/><div id="38496285" class="c"><input type="checkbox" id="c-38496285" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496178">parent</a><span>|</span><a href="#38496188">next</a><span>|</span><label class="collapse" for="c-38496285">[-]</label><label class="expand" for="c-38496285">[1 more]</label></div><br/><div class="children"><div class="content">Ye a training platform!<p>Ye for hobbyists - it&#x27;s hard to price.<p>But I agree some sort of platform for training could in theory work</div><br/></div></div></div></div><div id="38496188" class="c"><input type="checkbox" id="c-38496188" checked=""/><div class="controls bullet"><span class="by">Zuiii</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496072">parent</a><span>|</span><a href="#38496178">prev</a><span>|</span><a href="#38496045">next</a><span>|</span><label class="collapse" for="c-38496188">[-]</label><label class="expand" for="c-38496188">[4 more]</label></div><br/><div class="children"><div class="content">&gt; I still haven&#x27;t figured out how to open source algorithms<p>You&#x27;re not supposed to be able to restrict algorithms (i.e. math), and copyright (e.g. open source licenses) is definitely not the right tool. If you want to do it anyway, You&#x27;ll have better chances by abusing the patent system.</div><br/><div id="38496290" class="c"><input type="checkbox" id="c-38496290" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496188">parent</a><span>|</span><a href="#38496045">next</a><span>|</span><label class="collapse" for="c-38496290">[-]</label><label class="expand" for="c-38496290">[3 more]</label></div><br/><div class="children"><div class="content">Hmmm patents - doesn&#x27;t that also showcase everything in the open though?</div><br/><div id="38496330" class="c"><input type="checkbox" id="c-38496330" checked=""/><div class="controls bullet"><span class="by">Zuiii</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496290">parent</a><span>|</span><a href="#38496045">next</a><span>|</span><label class="collapse" for="c-38496330">[-]</label><label class="expand" for="c-38496330">[2 more]</label></div><br/><div class="children"><div class="content">Yes, but that&#x27;s the only way I know of to legally stop others from making money off &quot;ideas&quot;. Copyright isn&#x27;t a good tool for this as oracle recently found out.</div><br/><div id="38496431" class="c"><input type="checkbox" id="c-38496431" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496330">parent</a><span>|</span><a href="#38496045">next</a><span>|</span><label class="collapse" for="c-38496431">[-]</label><label class="expand" for="c-38496431">[1 more]</label></div><br/><div class="children"><div class="content">Good point! I&#x27;ll have a chat with my bro - but thanks for your suggestions - highly appreciate it!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38495928" class="c"><input type="checkbox" id="c-38495928" checked=""/><div class="controls bullet"><span class="by">sbierwagen</span><span>|</span><a href="#38495915">parent</a><span>|</span><a href="#38496045">prev</a><span>|</span><a href="#38495961">next</a><span>|</span><label class="collapse" for="c-38495928">[-]</label><label class="expand" for="c-38495928">[2 more]</label></div><br/><div class="children"><div class="content">Shareware. See the open source preview, pay a million dollars for the full version.</div><br/><div id="38496080" class="c"><input type="checkbox" id="c-38496080" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38495928">parent</a><span>|</span><a href="#38495961">next</a><span>|</span><label class="collapse" for="c-38496080">[-]</label><label class="expand" for="c-38496080">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t characterize it exactly as &quot;shareware&quot;, since the OSS version is fully functional, trains 5x faster on a single GPU.<p>The paid version just makes it train 30x faster on multi GPU platforms - it&#x27;s more of an open core approach.</div><br/></div></div></div></div><div id="38495961" class="c"><input type="checkbox" id="c-38495961" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38495915">parent</a><span>|</span><a href="#38495928">prev</a><span>|</span><a href="#38496944">next</a><span>|</span><label class="collapse" for="c-38495961">[-]</label><label class="expand" for="c-38495961">[4 more]</label></div><br/><div class="children"><div class="content">This is, I believe, part of the Y Combinator playbook. You want to get as much growth as possible using any means you can think of then flip the pricing (or tracking) on as soon as it peaks. Alternatively you can sell your company or go public.<p>The company here does seem less sinister however - don&#x27;t think they&#x27;ve accepted VC investment yet? Could be wrong.</div><br/><div id="38496060" class="c"><input type="checkbox" id="c-38496060" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38495961">parent</a><span>|</span><a href="#38496944">next</a><span>|</span><label class="collapse" for="c-38496060">[-]</label><label class="expand" for="c-38496060">[3 more]</label></div><br/><div class="children"><div class="content">No we don&#x27;t have any funding! I&#x27;m grateful to my family to supporting us till now.<p>We&#x27;re open to VC investment now, except we truly believe in bootstrapping it - we have tonnes of other products in the pipeline like a Recession predictor, a Data Science Consultant, our own trained chatbot via DPO and our fully cleaned datasets and more!</div><br/><div id="38496380" class="c"><input type="checkbox" id="c-38496380" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496060">parent</a><span>|</span><a href="#38496944">next</a><span>|</span><label class="collapse" for="c-38496380">[-]</label><label class="expand" for="c-38496380">[2 more]</label></div><br/><div class="children"><div class="content">Refreshing to see, especially on this forum! Best of luck.</div><br/><div id="38496432" class="c"><input type="checkbox" id="c-38496432" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38495915">root</a><span>|</span><a href="#38496380">parent</a><span>|</span><a href="#38496944">next</a><span>|</span><label class="collapse" for="c-38496432">[-]</label><label class="expand" for="c-38496432">[1 more]</label></div><br/><div class="children"><div class="content">:) Thanks!</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38496944" class="c"><input type="checkbox" id="c-38496944" checked=""/><div class="controls bullet"><span class="by">nikolayasdf123</span><span>|</span><a href="#38495915">prev</a><span>|</span><a href="#38487200">next</a><span>|</span><label class="collapse" for="c-38496944">[-]</label><label class="expand" for="c-38496944">[3 more]</label></div><br/><div class="children"><div class="content">monetising software tooling and libraries is notoriously hard. and amount of heat you getting here is huge. hope you find a way!</div><br/><div id="38497033" class="c"><input type="checkbox" id="c-38497033" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#38496944">parent</a><span>|</span><a href="#38497123">next</a><span>|</span><label class="collapse" for="c-38497033">[-]</label><label class="expand" for="c-38497033">[1 more]</label></div><br/><div class="children"><div class="content">Thanks!! I agree fully - I&#x27;m still trying to work it out with my brother on how we can effectively monetize it - probably products is the way to go like how OpenAI does it?<p>But thanks a lot again!</div><br/></div></div></div></div></div></div></div></div></div></body></html>