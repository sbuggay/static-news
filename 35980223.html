<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1684400451676" as="style"/><link rel="stylesheet" href="styles.css?v=1684400451676"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/nickm980/smallville">Show HN: Smallville – Create generative agents for simulations and games</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>nm980</span> | <span>22 comments</span></div><br/><div><div id="35981723" class="c"><input type="checkbox" id="c-35981723" checked=""/><div class="controls bullet"><span class="by">philipov</span><span>|</span><a href="#35981714">next</a><span>|</span><label class="collapse" for="c-35981723">[-]</label><label class="expand" for="c-35981723">[12 more]</label></div><br/><div class="children"><div class="content">Uh... is there some way to use this without connecting to a server? Like, for a game that can be played offline?<p>Finding a way to make the machine learning piece a completely self-contained library that can be shipped at scale to run on individual computers is the big hurdle to making AI like this practical for games. If I have to rely on your service staying up for my game to work, that&#x27;s an unacceptable supply chain risk.</div><br/><div id="35982213" class="c"><input type="checkbox" id="c-35982213" checked=""/><div class="controls bullet"><span class="by">AgentK20</span><span>|</span><a href="#35981723">parent</a><span>|</span><a href="#35982593">next</a><span>|</span><label class="collapse" for="c-35982213">[-]</label><label class="expand" for="c-35982213">[8 more]</label></div><br/><div class="children"><div class="content">EDIT: Actually there&#x27;s apparently been a lot of progress recently that I hadn&#x27;t kept up with; see the replies to this comment.<p>Original message: From a quick peek at the source, this depends on the ChatGPT API for the underlying LLM. It could probably be modified to use a local copy of an LLM, but most models I&#x27;ve seen are 300GB+ and require significant computational resources to operate (think several $15k NVIDIA A100 compute nodes). There&#x27;s a lot of effort being put in by the open source community to minimize these models and run them on commodity hardware, but as of yet the quality of the responses from the model are correlated with how large (and therefore how much compute) the model has. Give it a year or two and it&#x27;ll probably be more reasonable to integrate a local LLM for gaming purposes.</div><br/><div id="35982427" class="c"><input type="checkbox" id="c-35982427" checked=""/><div class="controls bullet"><span class="by">theaiquestion</span><span>|</span><a href="#35981723">root</a><span>|</span><a href="#35982213">parent</a><span>|</span><a href="#35982593">next</a><span>|</span><label class="collapse" for="c-35982427">[-]</label><label class="expand" for="c-35982427">[7 more]</label></div><br/><div class="children"><div class="content">&gt; most models I&#x27;ve seen are 300GB+ and require significant computational resources to operate (think several $15k NVIDIA A100 compute nodes).<p>What? Where have you been the last 3 months?<p>&gt; the quality of the responses from the model are correlated with how large (and therefore how much compute) the model has<p>There&#x27;s a lot more to this including the model structure, training methods, number of training tokens, quality of training data, etc.<p>I&#x27;m not at all saying that Vicuna&#x2F;Alpaca&#x2F;SuperCOT&#x2F;Other llama based models are as good as GPT3.5 - but they should be capable of this, they still create coherent answers.<p>You need preferably 24GB of vram, but you can get away with less, or you can use system memory (although that&#x27;ll be slow).<p>There is a openai api proxy that might let this work without too much work actually<p>EDIT: It actually says in the readme they plan to support StableLM which is interesting because at least at the moment that&#x27;s not a well performing model<p>EDIT 2: You should try the replit2.8B model - This is surprisingly good at programming - <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;replit&#x2F;replit-code-v1-3b-demo" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;replit&#x2F;replit-code-v1-3b-demo</a></div><br/><div id="35982504" class="c"><input type="checkbox" id="c-35982504" checked=""/><div class="controls bullet"><span class="by">inhumantsar</span><span>|</span><a href="#35981723">root</a><span>|</span><a href="#35982427">parent</a><span>|</span><a href="#35982738">next</a><span>|</span><label class="collapse" for="c-35982504">[-]</label><label class="expand" for="c-35982504">[2 more]</label></div><br/><div class="children"><div class="content">Even if you&#x27;re a more lightweight model, it&#x27;s still not very practical to require a dedicated 24GB GPU for every active gamer, whether local or cloud hosted.<p>For all intents and purposes, it&#x27;s as much of a non-starter in a production game as the multiple A100 scenario.<p>Of course that isn&#x27;t going to remain the case for long as the recent advancements in optimization make their way into live systems, but still.</div><br/><div id="35982577" class="c"><input type="checkbox" id="c-35982577" checked=""/><div class="controls bullet"><span class="by">theaiquestion</span><span>|</span><a href="#35981723">root</a><span>|</span><a href="#35982504">parent</a><span>|</span><a href="#35982738">next</a><span>|</span><label class="collapse" for="c-35982577">[-]</label><label class="expand" for="c-35982577">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s still not very practical to require a dedicated 24GB GPU<p>totally agreed, you could get away with 12GB too which is in the midrange.<p>That said yeah it&#x27;s still not something you could make a game with yet, I&#x27;m just pointing out 300GB+ of VRAM isn&#x27;t the bar for entry here, it is reachable for medium-high end consumers but that&#x27;s not really including the games resources either, and most gamers aren&#x27;t medium-high end so...</div><br/></div></div></div></div><div id="35982738" class="c"><input type="checkbox" id="c-35982738" checked=""/><div class="controls bullet"><span class="by">nm980</span><span>|</span><a href="#35981723">root</a><span>|</span><a href="#35982427">parent</a><span>|</span><a href="#35982504">prev</a><span>|</span><a href="#35982477">next</a><span>|</span><label class="collapse" for="c-35982738">[-]</label><label class="expand" for="c-35982738">[3 more]</label></div><br/><div class="children"><div class="content">&gt; EDIT: It actually says in the readme they plan to support StableLM which is interesting because at least at the moment that&#x27;s not a well performing model<p>I chose StableLM because that&#x27;s the only other model I knew of besides ChatGPT. I&#x27;m open to adding support for other models after I fix some bugs first.</div><br/><div id="35983114" class="c"><input type="checkbox" id="c-35983114" checked=""/><div class="controls bullet"><span class="by">theaiquestion</span><span>|</span><a href="#35981723">root</a><span>|</span><a href="#35982738">parent</a><span>|</span><a href="#35982477">next</a><span>|</span><label class="collapse" for="c-35983114">[-]</label><label class="expand" for="c-35983114">[2 more]</label></div><br/><div class="children"><div class="content">You might consider supporting ooba&#x27;s api which would give you a lot of support for different things really quickly.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F;</a></div><br/><div id="35983708" class="c"><input type="checkbox" id="c-35983708" checked=""/><div class="controls bullet"><span class="by">nullsense</span><span>|</span><a href="#35981723">root</a><span>|</span><a href="#35983114">parent</a><span>|</span><a href="#35982477">next</a><span>|</span><label class="collapse" for="c-35983708">[-]</label><label class="expand" for="c-35983708">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I second this. I use this frequently and lots of models downloaded that I test out with it. I&#x27;m keen to see a more API led approach.</div><br/></div></div></div></div></div></div><div id="35982477" class="c"><input type="checkbox" id="c-35982477" checked=""/><div class="controls bullet"><span class="by">AgentK20</span><span>|</span><a href="#35981723">root</a><span>|</span><a href="#35982427">parent</a><span>|</span><a href="#35982738">prev</a><span>|</span><a href="#35982593">next</a><span>|</span><label class="collapse" for="c-35982477">[-]</label><label class="expand" for="c-35982477">[1 more]</label></div><br/><div class="children"><div class="content">Oh, fair enough. I hadn&#x27;t been keeping up too much but hadn&#x27;t realized they had progressed that far. I&#x27;ll have to do some tinkering this evening.</div><br/></div></div></div></div></div></div><div id="35982593" class="c"><input type="checkbox" id="c-35982593" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#35981723">parent</a><span>|</span><a href="#35982213">prev</a><span>|</span><a href="#35984220">next</a><span>|</span><label class="collapse" for="c-35982593">[-]</label><label class="expand" for="c-35982593">[1 more]</label></div><br/><div class="children"><div class="content">7B parameter models are more than enough for this and run faster than talking pace on even a low end CPU.<p>Even a finetuned 3B model would be excellent for generative agents and only use about 2GB of RAM to at high speeds on even a single core CPU.</div><br/></div></div><div id="35984220" class="c"><input type="checkbox" id="c-35984220" checked=""/><div class="controls bullet"><span class="by">woah</span><span>|</span><a href="#35981723">parent</a><span>|</span><a href="#35982593">prev</a><span>|</span><a href="#35981714">next</a><span>|</span><label class="collapse" for="c-35984220">[-]</label><label class="expand" for="c-35984220">[2 more]</label></div><br/><div class="children"><div class="content">Dunno. I only ever play games that require an internet connection. I doubt this is an issue for most players.</div><br/><div id="35985347" class="c"><input type="checkbox" id="c-35985347" checked=""/><div class="controls bullet"><span class="by">ehnto</span><span>|</span><a href="#35981723">root</a><span>|</span><a href="#35984220">parent</a><span>|</span><a href="#35981714">next</a><span>|</span><label class="collapse" for="c-35985347">[-]</label><label class="expand" for="c-35985347">[1 more]</label></div><br/><div class="children"><div class="content">Games are increasingly moments in time, moments where all the services are working, and other people are playing. Get it while it&#x27;s hot or you&#x27;ll be playing a dead world.<p>Do I think that&#x27;s good? Absolutely not, I think it&#x27;s terrible. But the commentor I&#x27;m replying to is right, &quot;most players&quot; won&#x27;t care at all, else we wouldn&#x27;t be in this position.</div><br/></div></div></div></div></div></div><div id="35981714" class="c"><input type="checkbox" id="c-35981714" checked=""/><div class="controls bullet"><span class="by">green_man_lives</span><span>|</span><a href="#35981723">prev</a><span>|</span><a href="#35983748">next</a><span>|</span><label class="collapse" for="c-35981714">[-]</label><label class="expand" for="c-35981714">[3 more]</label></div><br/><div class="children"><div class="content">This is so cool! I have been wanting to see something like this for a few years now. I tried making a demo of something similar (but much more primitive) in Unity back in 2021, but small transformers weren&#x27;t good enough at the time.<p>Is there any way to protect against prompt injection here? Looking at the architecture I am thinking it would be possible for users to tell an agent what to do directly by tricking them.<p>This isn&#x27;t really a criticism, I think it&#x27;s actually a cool feature. It might be a fun premise of a game where you know you are in a simulation and can manipulate the NPCs around you.</div><br/><div id="35985127" class="c"><input type="checkbox" id="c-35985127" checked=""/><div class="controls bullet"><span class="by">nullsense</span><span>|</span><a href="#35981714">parent</a><span>|</span><a href="#35983748">next</a><span>|</span><label class="collapse" for="c-35985127">[-]</label><label class="expand" for="c-35985127">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Is there any way to protect against prompt injection here? Looking at the architecture I am thinking it would be possible for users to tell an agent what to do directly by tricking them.<p>Not a solved problem in humans either. I remember watching a documentary on North Korea recently where they covered how his brother got murdered at an airport in Singapore by a woman who had been conned for months into believing she was starring in a reality TV show playing pranks on people.<p>As generality increases to Infinity I&#x27;m not sure there&#x27;s actually a way to solve this particular problem. It might just be a failure of imagination on my part.</div><br/><div id="35985322" class="c"><input type="checkbox" id="c-35985322" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#35981714">root</a><span>|</span><a href="#35985127">parent</a><span>|</span><a href="#35983748">next</a><span>|</span><label class="collapse" for="c-35985322">[-]</label><label class="expand" for="c-35985322">[1 more]</label></div><br/><div class="children"><div class="content">Please tell me the name of this documentary. That sounds insane!</div><br/></div></div></div></div></div></div><div id="35983748" class="c"><input type="checkbox" id="c-35983748" checked=""/><div class="controls bullet"><span class="by">troymc</span><span>|</span><a href="#35981714">prev</a><span>|</span><a href="#35981908">next</a><span>|</span><label class="collapse" for="c-35983748">[-]</label><label class="expand" for="c-35983748">[1 more]</label></div><br/><div class="children"><div class="content">Once your NPCs get good enough, you could connect them to the real world (via APIs) so they could do goal-oriented sensing and actuation there too. I&#x27;m fairly sure it would be wonderful for all involved.</div><br/></div></div><div id="35981908" class="c"><input type="checkbox" id="c-35981908" checked=""/><div class="controls bullet"><span class="by">YesBox</span><span>|</span><a href="#35983748">prev</a><span>|</span><a href="#35984818">next</a><span>|</span><label class="collapse" for="c-35981908">[-]</label><label class="expand" for="c-35981908">[2 more]</label></div><br/><div class="children"><div class="content">Pretty neat. I&#x27;m creating an isometric, pixel art city builder game, though I imagine this wont scale to 10K or 100K units?</div><br/><div id="35985436" class="c"><input type="checkbox" id="c-35985436" checked=""/><div class="controls bullet"><span class="by">kleene_op</span><span>|</span><a href="#35981908">parent</a><span>|</span><a href="#35984818">next</a><span>|</span><label class="collapse" for="c-35985436">[-]</label><label class="expand" for="c-35985436">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m interested in this as well.<p>I would like to know if the part of the LLM that stores the experience of interacting with the player is separate from the base model, and if so how heavy that specific part is?<p>Are we talking Mb or Gb?</div><br/></div></div></div></div><div id="35984818" class="c"><input type="checkbox" id="c-35984818" checked=""/><div class="controls bullet"><span class="by">pharmakom</span><span>|</span><a href="#35981908">prev</a><span>|</span><a href="#35983715">next</a><span>|</span><label class="collapse" for="c-35984818">[-]</label><label class="expand" for="c-35984818">[1 more]</label></div><br/><div class="children"><div class="content">can you link to the code where the prompts are generated?</div><br/></div></div><div id="35983715" class="c"><input type="checkbox" id="c-35983715" checked=""/><div class="controls bullet"><span class="by">nullsense</span><span>|</span><a href="#35984818">prev</a><span>|</span><a href="#35980224">next</a><span>|</span><label class="collapse" for="c-35983715">[-]</label><label class="expand" for="c-35983715">[1 more]</label></div><br/><div class="children"><div class="content">Neat. Will have to have a play with this on the weekend.</div><br/></div></div></div></div></div></div></div></body></html>