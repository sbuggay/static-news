<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1722697058039" as="style"/><link rel="stylesheet" href="styles.css?v=1722697058039"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://aiola.com/blog/introducing-whisper-medusa/">AiOla open-sources ultra-fast ‘multi-head’ speech recognition model</a> <span class="domain">(<a href="https://aiola.com">aiola.com</a>)</span></div><div class="subtext"><span>cheptsov</span> | <span>12 comments</span></div><br/><div><div id="41146858" class="c"><input type="checkbox" id="c-41146858" checked=""/><div class="controls bullet"><span class="by">phkahler</span><span>|</span><a href="#41146754">next</a><span>|</span><label class="collapse" for="c-41146858">[-]</label><label class="expand" for="c-41146858">[1 more]</label></div><br/><div class="children"><div class="content">IIRC Whisper works on wave files. Can this do real time low latency continuous ASR?</div><br/></div></div><div id="41146754" class="c"><input type="checkbox" id="c-41146754" checked=""/><div class="controls bullet"><span class="by">BetterWhisper</span><span>|</span><a href="#41146858">prev</a><span>|</span><a href="#41145596">next</a><span>|</span><label class="collapse" for="c-41146754">[-]</label><label class="expand" for="c-41146754">[1 more]</label></div><br/><div class="children"><div class="content">Does it do speaker recognition&#x2F; diarization? Can&#x27;t see it from the repo readme</div><br/></div></div><div id="41145596" class="c"><input type="checkbox" id="c-41145596" checked=""/><div class="controls bullet"><span class="by">gronky_</span><span>|</span><a href="#41146754">prev</a><span>|</span><a href="#41145683">next</a><span>|</span><label class="collapse" for="c-41145596">[-]</label><label class="expand" for="c-41145596">[1 more]</label></div><br/><div class="children"><div class="content">GH repo: <a href="https:&#x2F;&#x2F;github.com&#x2F;aiola-lab&#x2F;whisper-medusa">https:&#x2F;&#x2F;github.com&#x2F;aiola-lab&#x2F;whisper-medusa</a></div><br/></div></div><div id="41145683" class="c"><input type="checkbox" id="c-41145683" checked=""/><div class="controls bullet"><span class="by">Doohickey-d</span><span>|</span><a href="#41145596">prev</a><span>|</span><a href="#41145691">next</a><span>|</span><label class="collapse" for="c-41145683">[-]</label><label class="expand" for="c-41145683">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious which of the Whisper derivatives is actually the fastest ?<p>Since faster-whisper claims 4x speedup over base Whisper, and I&#x27;ve found WhisperX to be faster still (for longer audio where it can do batch inference), at least on consumer GPUs.<p>So with AiOla saying &quot;50% speedup&quot;, is that actually noteworthy?</div><br/><div id="41145815" class="c"><input type="checkbox" id="c-41145815" checked=""/><div class="controls bullet"><span class="by">gronky_</span><span>|</span><a href="#41145683">parent</a><span>|</span><a href="#41146170">next</a><span>|</span><label class="collapse" for="c-41145815">[-]</label><label class="expand" for="c-41145815">[2 more]</label></div><br/><div class="children"><div class="content">From my understanding faster-whisper optimizes the inference without changing the model itself. Here they seem to be changing the model architecture but not applying other optimizations.<p>50% on its own doesn’t make this the current best choice for production. But I imagine this could become the new base model that all of the inference optimizations are applied to.<p>Wonder if it’s plug and play or if faster-whisper and others would need to reimplement from scratch?</div><br/><div id="41146013" class="c"><input type="checkbox" id="c-41146013" checked=""/><div class="controls bullet"><span class="by">dloss</span><span>|</span><a href="#41145683">root</a><span>|</span><a href="#41145815">parent</a><span>|</span><a href="#41146170">next</a><span>|</span><label class="collapse" for="c-41146013">[-]</label><label class="expand" for="c-41146013">[1 more]</label></div><br/><div class="children"><div class="content">Is this even faster?  <a href="https:&#x2F;&#x2F;github.com&#x2F;Vaibhavs10&#x2F;insanely-fast-whisper">https:&#x2F;&#x2F;github.com&#x2F;Vaibhavs10&#x2F;insanely-fast-whisper</a><p>If so, is the quality still acceptable?</div><br/></div></div></div></div><div id="41146170" class="c"><input type="checkbox" id="c-41146170" checked=""/><div class="controls bullet"><span class="by">tomp</span><span>|</span><a href="#41145683">parent</a><span>|</span><a href="#41145815">prev</a><span>|</span><a href="#41145691">next</a><span>|</span><label class="collapse" for="c-41146170">[-]</label><label class="expand" for="c-41146170">[1 more]</label></div><br/><div class="children"><div class="content">Depends what you mean by “fast”.<p>I’ve tested WhisperLive, it’s basically real-time (i.e. low <i>latency</i>).</div><br/></div></div></div></div><div id="41145691" class="c"><input type="checkbox" id="c-41145691" checked=""/><div class="controls bullet"><span class="by">qwertox</span><span>|</span><a href="#41145683">prev</a><span>|</span><label class="collapse" for="c-41145691">[-]</label><label class="expand" for="c-41145691">[4 more]</label></div><br/><div class="children"><div class="content">Nothing of interest here, it&#x27;s an ad.<p>If you&#x27;re interested, you might as well check out Gladia, at least they have a pricing section and allow you to use it as a developer, unlike just asking you to &quot;Request a Demo&quot;.<p>And while a sibling comment links to the GitHub repository, their entire website does not contain such a link.<p>---<p>Edit: My bad, for some reason I first checked the website instead of the blog post. Looks much more interesting now.</div><br/><div id="41145741" class="c"><input type="checkbox" id="c-41145741" checked=""/><div class="controls bullet"><span class="by">cheptsov</span><span>|</span><a href="#41145691">parent</a><span>|</span><a href="#41145874">next</a><span>|</span><label class="collapse" for="c-41145741">[-]</label><label class="expand" for="c-41145741">[2 more]</label></div><br/><div class="children"><div class="content">They have shared the link to GitHub [1], HuggingFace repo [2], and the paper [3]:<p>1. <a href="https:&#x2F;&#x2F;github.com&#x2F;aiola-lab&#x2F;whisper-medusa">https:&#x2F;&#x2F;github.com&#x2F;aiola-lab&#x2F;whisper-medusa</a><p>2. <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;aiola&#x2F;whisper-medusa-v1" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;aiola&#x2F;whisper-medusa-v1</a><p>3. <a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;method&#x2F;multi-head-attention" rel="nofollow">https:&#x2F;&#x2F;paperswithcode.com&#x2F;method&#x2F;multi-head-attention</a></div><br/><div id="41145813" class="c"><input type="checkbox" id="c-41145813" checked=""/><div class="controls bullet"><span class="by">nmstoker</span><span>|</span><a href="#41145691">root</a><span>|</span><a href="#41145741">parent</a><span>|</span><a href="#41145874">next</a><span>|</span><label class="collapse" for="c-41145813">[-]</label><label class="expand" for="c-41145813">[1 more]</label></div><br/><div class="children"><div class="content">Looks like they left out all training code, presumably for commercial reasons (but it only just came out so it&#x27;s conceivable they are just cleaning up that side of the code but I doubt it). Totally their call, given they&#x27;ve put the effort in, just a shame.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>