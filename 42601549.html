<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1736154058433" as="style"/><link rel="stylesheet" href="styles.css?v=1736154058433"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://altayakkus.substack.com/p/you-wouldnt-download-an-ai">Extracting AI models from mobile apps</a> <span class="domain">(<a href="https://altayakkus.substack.com">altayakkus.substack.com</a>)</span></div><div class="subtext"><span>smoser</span> | <span>196 comments</span></div><br/><div><div id="42603346" class="c"><input type="checkbox" id="c-42603346" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#42602864">next</a><span>|</span><label class="collapse" for="c-42603346">[-]</label><label class="expand" for="c-42603346">[9 more]</label></div><br/><div class="children"><div class="content">This is cool, but only the first part in extracting a ML model for usage. The second part is reverse engineering the tokenizer and input transformations that are needed to before passing the data to the model, and outputting a human readable format.</div><br/><div id="42605304" class="c"><input type="checkbox" id="c-42605304" checked=""/><div class="controls bullet"><span class="by">mentalgear</span><span>|</span><a href="#42603346">parent</a><span>|</span><a href="#42605061">next</a><span>|</span><label class="collapse" for="c-42605304">[-]</label><label class="expand" for="c-42605304">[3 more]</label></div><br/><div class="children"><div class="content">Would be interesting if someone could detail the approach to decode the pre-post processing steps before it enters the model, and how to find the correct input encoding.</div><br/><div id="42606240" class="c"><input type="checkbox" id="c-42606240" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42603346">root</a><span>|</span><a href="#42605304">parent</a><span>|</span><a href="#42605061">next</a><span>|</span><label class="collapse" for="c-42606240">[-]</label><label class="expand" for="c-42606240">[2 more]</label></div><br/><div class="children"><div class="content">Boils down to &quot;use Frida to find the arguments to the TensorFlow call beyond the model file&quot;<p>Key here is, a binary model is just a bag-of-floats with primitively typed inputs and outputs.<p>It&#x27;s ~impossible to write up more than what&#x27;s here because either:<p>A) you understand reverse engineering and model basics, and thus the current content is clear you&#x27;d use Frida to figure out how the arguments are passed to TensorFlow<p>or<p>B) you don&#x27;t understand this is a binary reverse engineering problem, even when shown Frida. If more content was provided, you&#x27;d see it as specific to a particular problem. Which it has to be. You&#x27;d also need a walkthrough by hand about batching, tokenization, so on and so forth, too much for a write up, and it&#x27;d be too confusing to follow for another model.<p>TL;Dr a request for more content is asking for a reverse engineering article to give you a full education on modal inference</div><br/></div></div></div></div><div id="42605061" class="c"><input type="checkbox" id="c-42605061" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42603346">parent</a><span>|</span><a href="#42605304">prev</a><span>|</span><a href="#42605241">next</a><span>|</span><label class="collapse" for="c-42605061">[-]</label><label class="expand" for="c-42605061">[3 more]</label></div><br/><div class="children"><div class="content">This is a good comment, but only in the sense it documents a model file doesn&#x27;t run the model by itself.<p>An analogous situation is seeing a blog that purports to &quot;show you code&quot;, and the code returns an object, and commenting &quot;This is cool, but doesn&#x27;t show you how to turn a function return value into a human readable format&quot; More noise, than signal.<p>The techniques in the article are trivially understood to also apply to discovering the input tokenization format, and Netron shows you the types of inputs and outputs.<p>Thanks for the article OP, really fascinating.</div><br/><div id="42605618" class="c"><input type="checkbox" id="c-42605618" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#42603346">root</a><span>|</span><a href="#42605061">parent</a><span>|</span><a href="#42605241">next</a><span>|</span><label class="collapse" for="c-42605618">[-]</label><label class="expand" for="c-42605618">[2 more]</label></div><br/><div class="children"><div class="content">Just having the shape of the input and output are not sufficient, the image (in this example) needs to be normalized. It&#x27;s presumably not difficult to find the exact numbers, but it is a source of errors when reverse engineering a ML model.</div><br/><div id="42606244" class="c"><input type="checkbox" id="c-42606244" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42603346">root</a><span>|</span><a href="#42605618">parent</a><span>|</span><a href="#42605241">next</a><span>|</span><label class="collapse" for="c-42606244">[-]</label><label class="expand" for="c-42606244">[1 more]</label></div><br/><div class="children"><div class="content">Right, you get it: it&#x27;s a Frida problem.</div><br/></div></div></div></div></div></div><div id="42605241" class="c"><input type="checkbox" id="c-42605241" checked=""/><div class="controls bullet"><span class="by">rob_c</span><span>|</span><a href="#42603346">parent</a><span>|</span><a href="#42605061">prev</a><span>|</span><a href="#42602864">next</a><span>|</span><label class="collapse" for="c-42605241">[-]</label><label class="expand" for="c-42605241">[2 more]</label></div><br/><div class="children"><div class="content">If you can&#x27;t fix this with a little help from chatgpt or Google you shouldn&#x27;t be building the models frankly let alone mucking with other people&#x27;s...</div><br/></div></div></div></div><div id="42602864" class="c"><input type="checkbox" id="c-42602864" checked=""/><div class="controls bullet"><span class="by">nthingtohide</span><span>|</span><a href="#42603346">prev</a><span>|</span><a href="#42604566">next</a><span>|</span><label class="collapse" for="c-42602864">[-]</label><label class="expand" for="c-42602864">[5 more]</label></div><br/><div class="children"><div class="content">One thing I noticed in Gboard is it uses homeomorphic encryption to do federated learning of common words used amongst public to do encrypted suggestions.<p>E.g. there are two common spelling of bizarre which are popular on Gboard : bizzare and bizarre.<p>Can something similar help in model encryption?</div><br/><div id="42605216" class="c"><input type="checkbox" id="c-42605216" checked=""/><div class="controls bullet"><span class="by">antman</span><span>|</span><a href="#42602864">parent</a><span>|</span><a href="#42605254">next</a><span>|</span><label class="collapse" for="c-42605216">[-]</label><label class="expand" for="c-42605216">[1 more]</label></div><br/><div class="children"><div class="content">Had to look it up, this seems to be the paper <a href="https:&#x2F;&#x2F;research.google&#x2F;pubs&#x2F;federated-learning-for-mobile-keyboard-prediction-2&#x2F;" rel="nofollow">https:&#x2F;&#x2F;research.google&#x2F;pubs&#x2F;federated-learning-for-mobile-k...</a></div><br/></div></div><div id="42605254" class="c"><input type="checkbox" id="c-42605254" checked=""/><div class="controls bullet"><span class="by">umeshunni</span><span>|</span><a href="#42602864">parent</a><span>|</span><a href="#42605216">prev</a><span>|</span><a href="#42605517">next</a><span>|</span><label class="collapse" for="c-42605254">[-]</label><label class="expand" for="c-42605254">[2 more]</label></div><br/><div class="children"><div class="content">Homomorphic, not homeomorphic</div><br/><div id="42607226" class="c"><input type="checkbox" id="c-42607226" checked=""/><div class="controls bullet"><span class="by">hyperbovine</span><span>|</span><a href="#42602864">root</a><span>|</span><a href="#42605254">parent</a><span>|</span><a href="#42605517">next</a><span>|</span><label class="collapse" for="c-42607226">[-]</label><label class="expand" for="c-42607226">[1 more]</label></div><br/><div class="children"><div class="content">`enc(coffee cup) == enc(donut)` would be an interesting guarantee.</div><br/></div></div></div></div><div id="42605517" class="c"><input type="checkbox" id="c-42605517" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42602864">parent</a><span>|</span><a href="#42605254">prev</a><span>|</span><a href="#42604566">next</a><span>|</span><label class="collapse" for="c-42605517">[-]</label><label class="expand" for="c-42605517">[1 more]</label></div><br/><div class="children"><div class="content">In theory yes, in practice right now no. Homomorphic encryption is too computationally expensive.</div><br/></div></div></div></div><div id="42604566" class="c"><input type="checkbox" id="c-42604566" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#42602864">prev</a><span>|</span><a href="#42602057">next</a><span>|</span><label class="collapse" for="c-42604566">[-]</label><label class="expand" for="c-42604566">[3 more]</label></div><br/><div class="children"><div class="content">I’m a huge fan of ML on device. It’s a big improvement in privacy for the user. That said, there’s always a chance for the user to extract your model, so on-device models will need to be fairly generic.</div><br/><div id="42606467" class="c"><input type="checkbox" id="c-42606467" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#42604566">parent</a><span>|</span><a href="#42602057">next</a><span>|</span><label class="collapse" for="c-42606467">[-]</label><label class="expand" for="c-42606467">[2 more]</label></div><br/><div class="children"><div class="content">Maybe someday we will build a society where standing on the shoulders of giants is encouraged, even when they haven&#x27;t been dead for 100 years yet.</div><br/><div id="42606531" class="c"><input type="checkbox" id="c-42606531" checked=""/><div class="controls bullet"><span class="by">andrewfromx</span><span>|</span><a href="#42604566">root</a><span>|</span><a href="#42606467">parent</a><span>|</span><a href="#42602057">next</a><span>|</span><label class="collapse" for="c-42606531">[-]</label><label class="expand" for="c-42606531">[1 more]</label></div><br/><div class="children"><div class="content">this would be yellow in <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Spiral_Dynamics" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Spiral_Dynamics</a> but we are still a mix of orange and green.</div><br/></div></div></div></div></div></div><div id="42602057" class="c"><input type="checkbox" id="c-42602057" checked=""/><div class="controls bullet"><span class="by">JTyQZSnP3cQGa8B</span><span>|</span><a href="#42604566">prev</a><span>|</span><a href="#42603051">next</a><span>|</span><label class="collapse" for="c-42602057">[-]</label><label class="expand" for="c-42602057">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Keep in mind that AI models [...] are considered intellectual property<p>Is it ironic or missing a &#x2F;s? I can&#x27;t really tell here.</div><br/><div id="42602430" class="c"><input type="checkbox" id="c-42602430" checked=""/><div class="controls bullet"><span class="by">SunlitCat</span><span>|</span><a href="#42602057">parent</a><span>|</span><a href="#42602082">next</a><span>|</span><label class="collapse" for="c-42602430">[-]</label><label class="expand" for="c-42602430">[2 more]</label></div><br/><div class="children"><div class="content">To be honest, that was my first thought on reading that headline as well. Given that especially those large companies (but who knows how smaller ones got their training data) got a huge amount of backlash for their unprecedented collection of data all over the web and not just there but everywhere else, it&#x27;s kinda ironic to talk about intellectual property.<p>If you use one of those AI model as a basis for your AI model the real danger could be that the owners of the originating data are going after you at some point as well.</div><br/><div id="42602861" class="c"><input type="checkbox" id="c-42602861" checked=""/><div class="controls bullet"><span class="by">ToucanLoucan</span><span>|</span><a href="#42602057">root</a><span>|</span><a href="#42602430">parent</a><span>|</span><a href="#42602082">next</a><span>|</span><label class="collapse" for="c-42602861">[-]</label><label class="expand" for="c-42602861">[1 more]</label></div><br/><div class="children"><div class="content">Standard corporate hypocrisy. &quot;Rules for thee, not for me.&quot;<p>If you actually expected anything to be open about OpenAI&#x27;s products, please get in touch, I have an incredible business opportunity for you in the form of a bridge in New York.</div><br/></div></div></div></div><div id="42602082" class="c"><input type="checkbox" id="c-42602082" checked=""/><div class="controls bullet"><span class="by">Freak_NL</span><span>|</span><a href="#42602057">parent</a><span>|</span><a href="#42602430">prev</a><span>|</span><a href="#42606251">next</a><span>|</span><label class="collapse" for="c-42602082">[-]</label><label class="expand" for="c-42602082">[1 more]</label></div><br/><div class="children"><div class="content">Standard disclaimer. Like inserting a bunch of &#x27;hypothetically&#x27; in a comment telling one where to find some piece of abandoned media where using an unsanctioned channel would entail infringing upon someone&#x27;s intellectual property.</div><br/></div></div><div id="42606251" class="c"><input type="checkbox" id="c-42606251" checked=""/><div class="controls bullet"><span class="by">GuB-42</span><span>|</span><a href="#42602057">parent</a><span>|</span><a href="#42602082">prev</a><span>|</span><a href="#42603467">next</a><span>|</span><label class="collapse" for="c-42606251">[-]</label><label class="expand" for="c-42606251">[1 more]</label></div><br/><div class="children"><div class="content">For now, it is better to assume it is the truth.<p>The simple fact that models are released under license, which may or may not be free, imply that it is intellectual property. You can&#x27;t license something that is not intellectual property.<p>It is a standard disclaimer, if you disagree, talk to your lawyer. The legal situation of AI models is such a mess that I am not even sure that a non-specialist professional will be of great help, let alone random people on the internet.</div><br/></div></div><div id="42603467" class="c"><input type="checkbox" id="c-42603467" checked=""/><div class="controls bullet"><span class="by">npteljes</span><span>|</span><a href="#42602057">parent</a><span>|</span><a href="#42606251">prev</a><span>|</span><a href="#42603051">next</a><span>|</span><label class="collapse" for="c-42603467">[-]</label><label class="expand" for="c-42603467">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s both. It&#x27;s<p>1. the current, unproven-in-court legal understanding,
2. standard disclaimer to cover OP&#x27;s ass
3. tongue-in-cheek reference to the prevalent argument that training AI on data, and then offering it via AI is being a parasite on that original data</div><br/></div></div></div></div><div id="42603051" class="c"><input type="checkbox" id="c-42603051" checked=""/><div class="controls bullet"><span class="by">avg_dev</span><span>|</span><a href="#42602057">prev</a><span>|</span><a href="#42602876">next</a><span>|</span><label class="collapse" for="c-42603051">[-]</label><label class="expand" for="c-42603051">[2 more]</label></div><br/><div class="children"><div class="content">pretty cool; that frida tool seems really nice. <a href="https:&#x2F;&#x2F;frida.re&#x2F;docs&#x2F;home&#x2F;" rel="nofollow">https:&#x2F;&#x2F;frida.re&#x2F;docs&#x2F;home&#x2F;</a><p>(and a bunch of people seem to be interested in the &quot;IP&quot; note, but I took as, just trying to not get run into legal trouble for advertising &quot;here&#x27;s how you can &#x27;steal&#x27; models!&quot;)</div><br/><div id="42605063" class="c"><input type="checkbox" id="c-42605063" checked=""/><div class="controls bullet"><span class="by">frogsRnice</span><span>|</span><a href="#42603051">parent</a><span>|</span><a href="#42602876">next</a><span>|</span><label class="collapse" for="c-42605063">[-]</label><label class="expand" for="c-42605063">[1 more]</label></div><br/><div class="children"><div class="content">frida is an amazing tool - it has empowered me to do things that would have otherwise took weeks or even months. This video is a little old, but the creator is also cracked <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=CLpW1tZCblo" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=CLpW1tZCblo</a><p>It&#x27;s supposed to be &quot;free-IDA&quot; and the work put in by the developers and maintainers is truly phenomenal.<p>EDIT: This isn&#x27;t really an attack imo. If you are going to take &quot;secrets&quot; and shove it into a mobile app, they can&#x27;t really be considered secret. I suppose it&#x27;s a tradeoff - if you want to do this kind of thing client-side - the secret sauce isn&#x27;t so secret.</div><br/></div></div></div></div><div id="42602876" class="c"><input type="checkbox" id="c-42602876" checked=""/><div class="controls bullet"><span class="by">boothby</span><span>|</span><a href="#42603051">prev</a><span>|</span><a href="#42603684">next</a><span>|</span><label class="collapse" for="c-42602876">[-]</label><label class="expand" for="c-42602876">[9 more]</label></div><br/><div class="children"><div class="content">If I understand the position of major players in this field, downloading models in bulk and training a ML model on that corpus shouldn&#x27;t violate anybody&#x27;s IP.</div><br/><div id="42602952" class="c"><input type="checkbox" id="c-42602952" checked=""/><div class="controls bullet"><span class="by">zitterbewegung</span><span>|</span><a href="#42602876">parent</a><span>|</span><a href="#42603684">next</a><span>|</span><label class="collapse" for="c-42602952">[-]</label><label class="expand" for="c-42602952">[8 more]</label></div><br/><div class="children"><div class="content">IANAL But, this is not true it would be a piece of the software. If there is a copyright on the app itself it would extend to the model. Even models have licenses for example LLAMA is release under this license [1]<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;meta-llama&#x2F;llama&#x2F;blob&#x2F;main&#x2F;LICENSE">https:&#x2F;&#x2F;github.com&#x2F;meta-llama&#x2F;llama&#x2F;blob&#x2F;main&#x2F;LICENSE</a></div><br/><div id="42603363" class="c"><input type="checkbox" id="c-42603363" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42602876">root</a><span>|</span><a href="#42602952">parent</a><span>|</span><a href="#42603315">next</a><span>|</span><label class="collapse" for="c-42603363">[-]</label><label class="expand" for="c-42603363">[1 more]</label></div><br/><div class="children"><div class="content">The fact that models creators <i>assert</i> that they are protectrd by copyright and offer licenses does not mean:<p>(1) That they are actually protected by copyright in the first place, or<p>(2) That the particular act described does not fall into an exception to copyright like fair use, exactly as many model creators assert that the exact same act done with the materials models are trained on does, rendering the restrictions of the license offered moot for that purpose.</div><br/></div></div><div id="42603315" class="c"><input type="checkbox" id="c-42603315" checked=""/><div class="controls bullet"><span class="by">boothby</span><span>|</span><a href="#42602876">root</a><span>|</span><a href="#42602952">parent</a><span>|</span><a href="#42603363">prev</a><span>|</span><a href="#42602996">next</a><span>|</span><label class="collapse" for="c-42603315">[-]</label><label class="expand" for="c-42603315">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are trained on works -- software, graphics and text -- covered by my copyright.  What&#x27;s the difference?</div><br/></div></div><div id="42602996" class="c"><input type="checkbox" id="c-42602996" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#42602876">root</a><span>|</span><a href="#42602952">parent</a><span>|</span><a href="#42603315">prev</a><span>|</span><a href="#42603003">next</a><span>|</span><label class="collapse" for="c-42602996">[-]</label><label class="expand" for="c-42602996">[3 more]</label></div><br/><div class="children"><div class="content">If I understand the position of major players in this field, copyright itself is optional (for them at least).</div><br/><div id="42603476" class="c"><input type="checkbox" id="c-42603476" checked=""/><div class="controls bullet"><span class="by">zitterbewegung</span><span>|</span><a href="#42602876">root</a><span>|</span><a href="#42602996">parent</a><span>|</span><a href="#42603411">next</a><span>|</span><label class="collapse" for="c-42603476">[-]</label><label class="expand" for="c-42603476">[1 more]</label></div><br/><div class="children"><div class="content">True, I think there has to be a case that sets precedent for this issue.</div><br/></div></div><div id="42603411" class="c"><input type="checkbox" id="c-42603411" checked=""/><div class="controls bullet"><span class="by">rusk</span><span>|</span><a href="#42602876">root</a><span>|</span><a href="#42602996">parent</a><span>|</span><a href="#42603476">prev</a><span>|</span><a href="#42603003">next</a><span>|</span><label class="collapse" for="c-42603411">[-]</label><label class="expand" for="c-42603411">[1 more]</label></div><br/><div class="children"><div class="content">They claim “safe harbour” - if nobody complains it’s fair game</div><br/></div></div></div></div><div id="42603003" class="c"><input type="checkbox" id="c-42603003" checked=""/><div class="controls bullet"><span class="by">Drakim</span><span>|</span><a href="#42602876">root</a><span>|</span><a href="#42602952">parent</a><span>|</span><a href="#42602996">prev</a><span>|</span><a href="#42604854">next</a><span>|</span><label class="collapse" for="c-42603003">[-]</label><label class="expand" for="c-42603003">[1 more]</label></div><br/><div class="children"><div class="content">Is there a material difference between the copyright laws for software and the copyright laws for images and text?</div><br/></div></div><div id="42604854" class="c"><input type="checkbox" id="c-42604854" checked=""/><div class="controls bullet"><span class="by">_DeadFred_</span><span>|</span><a href="#42602876">root</a><span>|</span><a href="#42602952">parent</a><span>|</span><a href="#42603003">prev</a><span>|</span><a href="#42603684">next</a><span>|</span><label class="collapse" for="c-42604854">[-]</label><label class="expand" for="c-42604854">[1 more]</label></div><br/><div class="children"><div class="content">Yeah no.<p>An example for legal reference might be convolution reverb. Basically it&#x27;s a way to record what a fancy reverb machines does (using copyrighted complex math algorithms) and cheaply recreate the reverb on my computer. It seems like companies can do this as long as they distribute protected reverbs separately from the commercial application. So Liquidsonics (<a href="https:&#x2F;&#x2F;www.liquidsonics.com&#x2F;software&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.liquidsonics.com&#x2F;software&#x2F;</a>) sells reverb software but puts for free download the &#x27;protected&#x27; convolution reverbs specifically the Bricasti ones in dispute (<a href="https:&#x2F;&#x2F;www.liquidsonics.com&#x2F;fusion-ir&#x2F;reverberate-3&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.liquidsonics.com&#x2F;fusion-ir&#x2F;reverberate-3&#x2F;</a>)<p>Also, while a SQL server can be copyright protected, a SQL database is not given copyright protection&#x2F;ownership to the SQL server software creators by extension of that.</div><br/></div></div></div></div></div></div><div id="42603684" class="c"><input type="checkbox" id="c-42603684" checked=""/><div class="controls bullet"><span class="by">1vuio0pswjnm7</span><span>|</span><a href="#42602876">prev</a><span>|</span><a href="#42604455">next</a><span>|</span><label class="collapse" for="c-42603684">[-]</label><label class="expand" for="c-42603684">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Keep in mind that AI models, like most things, are considered intellectual property. Before using or modifying any extracted models, you need the explicit permission of their owner.&quot;<p>If weights and biases contained in &quot;AI models&quot; are prorietary, then for one model owner to detect infingement by another model owner, it may be necessary to download and extract.</div><br/></div></div><div id="42604455" class="c"><input type="checkbox" id="c-42604455" checked=""/><div class="controls bullet"><span class="by">Fragoel2</span><span>|</span><a href="#42603684">prev</a><span>|</span><a href="#42603251">next</a><span>|</span><label class="collapse" for="c-42604455">[-]</label><label class="expand" for="c-42604455">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s an interesting research paper from a few years ago that extracted models from Android apps on a large scale: <a href="https:&#x2F;&#x2F;impillar.github.io&#x2F;files&#x2F;ccs2022advdroid.pdf" rel="nofollow">https:&#x2F;&#x2F;impillar.github.io&#x2F;files&#x2F;ccs2022advdroid.pdf</a></div><br/></div></div><div id="42605317" class="c"><input type="checkbox" id="c-42605317" checked=""/><div class="controls bullet"><span class="by">amolgupta</span><span>|</span><a href="#42603251">prev</a><span>|</span><a href="#42602046">next</a><span>|</span><label class="collapse" for="c-42605317">[-]</label><label class="expand" for="c-42605317">[3 more]</label></div><br/><div class="children"><div class="content">For app developers considering tflite, a safer way would be to host the models on firebase and delete them when their job is done. It comes with other features like versioning for model updates, A&#x2F;B tests, lower apk size etc.
<a href="https:&#x2F;&#x2F;firebase.google.com&#x2F;docs&#x2F;ml&#x2F;manage-hosted-models" rel="nofollow">https:&#x2F;&#x2F;firebase.google.com&#x2F;docs&#x2F;ml&#x2F;manage-hosted-models</a></div><br/><div id="42605853" class="c"><input type="checkbox" id="c-42605853" checked=""/><div class="controls bullet"><span class="by">hn8726</span><span>|</span><a href="#42605317">parent</a><span>|</span><a href="#42606206">next</a><span>|</span><label class="collapse" for="c-42605853">[-]</label><label class="expand" for="c-42605853">[1 more]</label></div><br/><div class="children"><div class="content">That wouldn&#x27;t help against the technique explained in the article, would it? Since the model makes it way into the device, it can be intercepted in a similar fashion.<p>I&#x27;m not quite sure I understand the firebase feature btw. From the docs, it&#x27;s pretty much file storage with a dedicated API? I suppose you can use those models for inference in the cloud, but still, the storage API seems redundant.</div><br/></div></div><div id="42606206" class="c"><input type="checkbox" id="c-42606206" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42605317">parent</a><span>|</span><a href="#42605853">prev</a><span>|</span><a href="#42602046">next</a><span>|</span><label class="collapse" for="c-42606206">[-]</label><label class="expand" for="c-42606206">[1 more]</label></div><br/><div class="children"><div class="content">In addition to the sibling comment this would require repeatedly re-downloading models when you want to use them, which sucks.</div><br/></div></div></div></div><div id="42602046" class="c"><input type="checkbox" id="c-42602046" checked=""/><div class="controls bullet"><span class="by">do_not_redeem</span><span>|</span><a href="#42605317">prev</a><span>|</span><a href="#42605056">next</a><span>|</span><label class="collapse" for="c-42602046">[-]</label><label class="expand" for="c-42602046">[4 more]</label></div><br/><div class="children"><div class="content">Can anyone explain that resize_to_320.tflite file? Surely they aren&#x27;t using an AI model to resize images? Right?</div><br/><div id="42602134" class="c"><input type="checkbox" id="c-42602134" checked=""/><div class="controls bullet"><span class="by">smitop</span><span>|</span><a href="#42602046">parent</a><span>|</span><a href="#42602679">next</a><span>|</span><label class="collapse" for="c-42602134">[-]</label><label class="expand" for="c-42602134">[2 more]</label></div><br/><div class="children"><div class="content">tflite files can contain a ResizeOp that resizes the image: <a href="https:&#x2F;&#x2F;ai.google.dev&#x2F;edge&#x2F;api&#x2F;tflite&#x2F;java&#x2F;org&#x2F;tensorflow&#x2F;lite&#x2F;support&#x2F;image&#x2F;ops&#x2F;ResizeOp" rel="nofollow">https:&#x2F;&#x2F;ai.google.dev&#x2F;edge&#x2F;api&#x2F;tflite&#x2F;java&#x2F;org&#x2F;tensorflow&#x2F;li...</a><p>The file is only 7.7kb, so it couldn&#x27;t contain many weights anyways.</div><br/><div id="42604110" class="c"><input type="checkbox" id="c-42604110" checked=""/><div class="controls bullet"><span class="by">raydiak</span><span>|</span><a href="#42602046">root</a><span>|</span><a href="#42602134">parent</a><span>|</span><a href="#42602679">next</a><span>|</span><label class="collapse" for="c-42604110">[-]</label><label class="expand" for="c-42604110">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. Put another way, tensorflow is not an AI. You can build an AI in tensorflow. You can also resize images in tensorflow (using the traditional algorithms, not AI). I am not an expert, but as I understand, it is common for vision models to require a fixed resolution input, and it is common for that resolution to be quite low due to resource constraints.</div><br/></div></div></div></div><div id="42602679" class="c"><input type="checkbox" id="c-42602679" checked=""/><div class="controls bullet"><span class="by">koe123</span><span>|</span><a href="#42602046">parent</a><span>|</span><a href="#42602134">prev</a><span>|</span><a href="#42605056">next</a><span>|</span><label class="collapse" for="c-42602679">[-]</label><label class="expand" for="c-42602679">[1 more]</label></div><br/><div class="children"><div class="content">Probably not what your alluding to but AI upscaling of images is definitely a thing</div><br/></div></div></div></div><div id="42605056" class="c"><input type="checkbox" id="c-42605056" checked=""/><div class="controls bullet"><span class="by">Ekaros</span><span>|</span><a href="#42602046">prev</a><span>|</span><a href="#42602689">next</a><span>|</span><label class="collapse" for="c-42605056">[-]</label><label class="expand" for="c-42605056">[4 more]</label></div><br/><div class="children"><div class="content">Can you launder AI model by feeding it to some other model or training process? After all that is how it was originally created. So it cannot be any less legal...</div><br/><div id="42605119" class="c"><input type="checkbox" id="c-42605119" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#42605056">parent</a><span>|</span><a href="#42602689">next</a><span>|</span><label class="collapse" for="c-42605119">[-]</label><label class="expand" for="c-42605119">[3 more]</label></div><br/><div class="children"><div class="content">There are a family of techniques, often called something like “distillation”. There are also various synthetic training data strategies, it’s a very active area of research.<p>As for the copyright treatment? As far as I know it’s a bit up in the air at the moment. I suspect that the major frontier vendors would mostly contend that training data is fair use but weights are copyrighted. But that’s because they’re bad people.</div><br/><div id="42605185" class="c"><input type="checkbox" id="c-42605185" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#42605056">root</a><span>|</span><a href="#42605119">parent</a><span>|</span><a href="#42602689">next</a><span>|</span><label class="collapse" for="c-42605185">[-]</label><label class="expand" for="c-42605185">[2 more]</label></div><br/><div class="children"><div class="content">The weights are my training data. I scraped them from the internet</div><br/><div id="42607857" class="c"><input type="checkbox" id="c-42607857" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#42605056">root</a><span>|</span><a href="#42605185">parent</a><span>|</span><a href="#42602689">next</a><span>|</span><label class="collapse" for="c-42607857">[-]</label><label class="expand" for="c-42607857">[1 more]</label></div><br/><div class="children"><div class="content">That sentiment is ethically sound and logically robust and directionally consistent with any uniform application of the law as written.<p>But there is a group of people, growing daily in influence, who utterly reject such principles as either worthy or useful. This group of people is defined by the ego necessary to conclude that when the stakes are this high, the decisions should be made by them, that the ends justify the means on arbitrary antisocial behavior (c.f. the behavior of their scrapers) as long as this quasi-religious orgasm of singularity is steered by the firm hand that is willing and able to see it through.<p>That doesn’t distress me: L Ron Hubbard has that.<p>It distresses me that HN as a community refuses to stand up to these people.</div><br/></div></div></div></div></div></div></div></div><div id="42602689" class="c"><input type="checkbox" id="c-42602689" checked=""/><div class="controls bullet"><span class="by">jonpo</span><span>|</span><a href="#42605056">prev</a><span>|</span><a href="#42603178">next</a><span>|</span><label class="collapse" for="c-42602689">[-]</label><label class="expand" for="c-42602689">[25 more]</label></div><br/><div class="children"><div class="content">Well done you seem to have liberated an open model trained on open data for blind and visually impaired people.<p>Paper: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.03738" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2204.03738</a><p>Code: <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;banknote-net">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;banknote-net</a>
Training data: <a href="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;microsoft&#x2F;banknote-net&#x2F;refs&#x2F;heads&#x2F;main&#x2F;data&#x2F;banknote_net.csv" rel="nofollow">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;microsoft&#x2F;banknote-net&#x2F;ref...</a><p>model: <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;banknote-net&#x2F;blob&#x2F;main&#x2F;models&#x2F;banknote_net_encoder.h5">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;banknote-net&#x2F;blob&#x2F;main&#x2F;models&#x2F;b...</a><p>Kinda easier to download it straight from github.<p>Its licenced under MIT and CDLA-Permissive-2.0 licenses.<p>But lets not let that get in the way of hating on AI shall we?</div><br/><div id="42605011" class="c"><input type="checkbox" id="c-42605011" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42602689">parent</a><span>|</span><a href="#42604992">next</a><span>|</span><label class="collapse" for="c-42605011">[-]</label><label class="expand" for="c-42605011">[4 more]</label></div><br/><div class="children"><div class="content">&gt; But lets not let that get in the way of hating on AI shall we?<p>Can you please edit this kind of thing out of your HN comments? 
(This is in the site guidelines: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a>.)<p>It leads to a downward spiral, as one can see in the progression to <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42604422">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42604422</a> and <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42604728">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42604728</a>. That&#x27;s what we&#x27;re trying to avoid here.<p>Your post is informative and would be just fine without the last sentence (well, plus the snarky first two words).</div><br/><div id="42605438" class="c"><input type="checkbox" id="c-42605438" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#42602689">root</a><span>|</span><a href="#42605011">parent</a><span>|</span><a href="#42605527">next</a><span>|</span><label class="collapse" for="c-42605438">[-]</label><label class="expand" for="c-42605438">[2 more]</label></div><br/><div class="children"><div class="content">Can you clarify this a bit.   I presume you are talking about the tone more than the implied statement.<p>If the last sentence were explicit rather than implied, for instance<p><i>This article seems to be serving the growing prejudice against AI</i><p>Is that better?  It is still likely to be controversial and the accuracy debatable, but it is at least sincere and could be the start of a reasonable conversation, provided the responders behave accordingly.<p>I would like people to talk about controversial things here if they do so in a considerate manner.<p>I&#x27;d also like to personally acknowledge how much work you do to defuse situations on HN. You represent an excellent example of how to behave. Even when the people you are talking to assume bad faith you hold your composure.</div><br/><div id="42607003" class="c"><input type="checkbox" id="c-42607003" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42602689">root</a><span>|</span><a href="#42605438">parent</a><span>|</span><a href="#42605527">next</a><span>|</span><label class="collapse" for="c-42607003">[-]</label><label class="expand" for="c-42607003">[1 more]</label></div><br/><div class="children"><div class="content">Sure, that would be better. It isn&#x27;t snarky, and it makes fewer uncharitable assumptions.</div><br/></div></div></div></div><div id="42605527" class="c"><input type="checkbox" id="c-42605527" checked=""/><div class="controls bullet"><span class="by">jonpo</span><span>|</span><a href="#42602689">root</a><span>|</span><a href="#42605011">parent</a><span>|</span><a href="#42605438">prev</a><span>|</span><a href="#42604992">next</a><span>|</span><label class="collapse" for="c-42605527">[-]</label><label class="expand" for="c-42605527">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t seem to be able to edit it, apologies I will try not to let this type of thing get to me in future.<p>I would also like to point out that this is a fine tuned classifier vision model based on mobilenetv2 and not an LLM.</div><br/></div></div></div></div><div id="42604992" class="c"><input type="checkbox" id="c-42604992" checked=""/><div class="controls bullet"><span class="by">DoctorOetker</span><span>|</span><a href="#42602689">parent</a><span>|</span><a href="#42605011">prev</a><span>|</span><a href="#42604167">next</a><span>|</span><label class="collapse" for="c-42604992">[-]</label><label class="expand" for="c-42604992">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t you think its intentional, so as not to demonstrate the technique on potentially copyrighted data?</div><br/></div></div><div id="42604167" class="c"><input type="checkbox" id="c-42604167" checked=""/><div class="controls bullet"><span class="by">llama_drama</span><span>|</span><a href="#42602689">parent</a><span>|</span><a href="#42604992">prev</a><span>|</span><a href="#42605284">next</a><span>|</span><label class="collapse" for="c-42604167">[-]</label><label class="expand" for="c-42604167">[1 more]</label></div><br/><div class="children"><div class="content">If this is exactly the same model then what&#x27;s the point of encrypting it?</div><br/></div></div><div id="42605284" class="c"><input type="checkbox" id="c-42605284" checked=""/><div class="controls bullet"><span class="by">rob_c</span><span>|</span><a href="#42602689">parent</a><span>|</span><a href="#42604167">prev</a><span>|</span><a href="#42604422">next</a><span>|</span><label class="collapse" for="c-42605284">[-]</label><label class="expand" for="c-42605284">[1 more]</label></div><br/><div class="children"><div class="content">... Because if he did this with a model that&#x27;s not open that&#x27;s sure going to keep everyone happy and not result in lawsuit(s)...<p>The same method&#x2F;strategy applies to closed tools and models too, although you should probably be careful if you&#x27;ve handed over a credit card for a decryption key to a service and try this ;)</div><br/></div></div></div></div><div id="42603178" class="c"><input type="checkbox" id="c-42603178" checked=""/><div class="controls bullet"><span class="by">Polizeiposaune</span><span>|</span><a href="#42602689">prev</a><span>|</span><a href="#42603993">next</a><span>|</span><label class="collapse" for="c-42603178">[-]</label><label class="expand" for="c-42603178">[60 more]</label></div><br/><div class="children"><div class="content">You wouldn&#x27;t train a LLM on a corpus containing copyrighted works without ensuring you had the necessary rights to the works, would you?</div><br/><div id="42604510" class="c"><input type="checkbox" id="c-42604510" checked=""/><div class="controls bullet"><span class="by">Workaccount2</span><span>|</span><a href="#42603178">parent</a><span>|</span><a href="#42604049">next</a><span>|</span><label class="collapse" for="c-42604510">[-]</label><label class="expand" for="c-42604510">[13 more]</label></div><br/><div class="children"><div class="content">LLMs are not massive archives of data. They are a tiny fraction of a fraction of a percent of the size of their training set.<p>And before you knee-jerk &quot;it&#x27;s a compression algo!&quot;, I invite you to archive all your data with an LLMs &quot;compression algo&quot;.</div><br/><div id="42604549" class="c"><input type="checkbox" id="c-42604549" checked=""/><div class="controls bullet"><span class="by">BobbyTables2</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604510">parent</a><span>|</span><a href="#42604546">next</a><span>|</span><label class="collapse" for="c-42604549">[-]</label><label class="expand" for="c-42604549">[4 more]</label></div><br/><div class="children"><div class="content">Copying a single sentence verbatim from a 1000 page book is still plagiarism.<p>And is technically copyright infringement outside fair use exceptions.</div><br/><div id="42604582" class="c"><input type="checkbox" id="c-42604582" checked=""/><div class="controls bullet"><span class="by">concerndc1tizen</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604549">parent</a><span>|</span><a href="#42604546">next</a><span>|</span><label class="collapse" for="c-42604582">[-]</label><label class="expand" for="c-42604582">[3 more]</label></div><br/><div class="children"><div class="content">And similarly, translating those sentences into data points is still a derivative work, like transcribing music and then making a new recording is still derivative.</div><br/><div id="42604691" class="c"><input type="checkbox" id="c-42604691" checked=""/><div class="controls bullet"><span class="by">jpollock</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604582">parent</a><span>|</span><a href="#42604546">next</a><span>|</span><label class="collapse" for="c-42604691">[-]</label><label class="expand" for="c-42604691">[2 more]</label></div><br/><div class="children"><div class="content">derivative works still tend to be copyright violations.</div><br/><div id="42604767" class="c"><input type="checkbox" id="c-42604767" checked=""/><div class="controls bullet"><span class="by">concerndc1tizen</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604691">parent</a><span>|</span><a href="#42604546">next</a><span>|</span><label class="collapse" for="c-42604767">[-]</label><label class="expand" for="c-42604767">[1 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s what I&#x27;m saying. An LLM washing machine doesn&#x27;t get rid of the copyright.</div><br/></div></div></div></div></div></div></div></div><div id="42604546" class="c"><input type="checkbox" id="c-42604546" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604510">parent</a><span>|</span><a href="#42604549">prev</a><span>|</span><a href="#42604690">next</a><span>|</span><label class="collapse" for="c-42604546">[-]</label><label class="expand" for="c-42604546">[6 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t matter. It&#x27;s still a derived work.</div><br/><div id="42604671" class="c"><input type="checkbox" id="c-42604671" checked=""/><div class="controls bullet"><span class="by">baxtr</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604546">parent</a><span>|</span><a href="#42604690">next</a><span>|</span><label class="collapse" for="c-42604671">[-]</label><label class="expand" for="c-42604671">[5 more]</label></div><br/><div class="children"><div class="content">Well what isn’t in this world?<p>Would Einstein would have been possible without Newton?</div><br/><div id="42604897" class="c"><input type="checkbox" id="c-42604897" checked=""/><div class="controls bullet"><span class="by">thedailymail</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604671">parent</a><span>|</span><a href="#42604690">next</a><span>|</span><label class="collapse" for="c-42604897">[-]</label><label class="expand" for="c-42604897">[4 more]</label></div><br/><div class="children"><div class="content">Newton was public domain by Einstein&#x27;s time.</div><br/><div id="42605524" class="c"><input type="checkbox" id="c-42605524" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604897">parent</a><span>|</span><a href="#42604690">next</a><span>|</span><label class="collapse" for="c-42605524">[-]</label><label class="expand" for="c-42605524">[3 more]</label></div><br/><div class="children"><div class="content">Indeed. Copyright was introduced in 1710, Principia was published in 1687.</div><br/><div id="42605600" class="c"><input type="checkbox" id="c-42605600" checked=""/><div class="controls bullet"><span class="by">yieldcrv</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42605524">parent</a><span>|</span><a href="#42604690">next</a><span>|</span><label class="collapse" for="c-42605600">[-]</label><label class="expand" for="c-42605600">[2 more]</label></div><br/><div class="children"><div class="content">and even with our current copyright laws providing for long dated protection, it would have still been in public domain</div><br/><div id="42605653" class="c"><input type="checkbox" id="c-42605653" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42605600">parent</a><span>|</span><a href="#42604690">next</a><span>|</span><label class="collapse" for="c-42605653">[-]</label><label class="expand" for="c-42605653">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s hard to say what the current laws actually imply. Steamboat Willie was originally meant to be in the public domain in 1955. Got there in 2024.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42604690" class="c"><input type="checkbox" id="c-42604690" checked=""/><div class="controls bullet"><span class="by">timewizard</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604510">parent</a><span>|</span><a href="#42604546">prev</a><span>|</span><a href="#42604049">next</a><span>|</span><label class="collapse" for="c-42604690">[-]</label><label class="expand" for="c-42604690">[2 more]</label></div><br/><div class="children"><div class="content">&gt; LLMs are not massive archives of data.<p>Neither am I,  yet,  I am still capable of reproducing copyrighted works to a level that most would describe as illegal.<p>&gt; And before you knee-jerk &quot;it&#x27;s a compression algo!&quot;<p>It&#x27;s literally a fundamental part of the technology so I can&#x27;t see how you call it a &quot;knee jerk.&quot;  It&#x27;s lossy compression,  the same way a JPEG might be,  and simply recompressing your picture to a lower resolution does not at all obviate your copyright.<p>&gt; I invite you to archive all your data with an LLMs &quot;compression algo&quot;.<p>As long as we agree it is _my data_ and not yours.</div><br/><div id="42604938" class="c"><input type="checkbox" id="c-42604938" checked=""/><div class="controls bullet"><span class="by">Isamu</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604690">parent</a><span>|</span><a href="#42604049">next</a><span>|</span><label class="collapse" for="c-42604938">[-]</label><label class="expand" for="c-42604938">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s lossy compression, the same way a JPEG might be<p>Compression yes, but this is co-mingling as well. The entire corpus is compressed together, which identifies common patterns, and in the model they are essentially now overlapping.<p>The original document is represented statistically in the final model, but you’ve lost the ability to extract it closely. Instead you gain the ability to generate something statistically similar to a large number of original documents that are related or are structurally similar.<p>I’m just commenting, not disputing any argument about fair use.</div><br/></div></div></div></div></div></div><div id="42604049" class="c"><input type="checkbox" id="c-42604049" checked=""/><div class="controls bullet"><span class="by">tomjen3</span><span>|</span><a href="#42603178">parent</a><span>|</span><a href="#42604510">prev</a><span>|</span><a href="#42603560">next</a><span>|</span><label class="collapse" for="c-42604049">[-]</label><label class="expand" for="c-42604049">[3 more]</label></div><br/><div class="children"><div class="content">You wouldn&#x27;t read a book and teach others its lessons without a derived license, would you?</div><br/><div id="42604175" class="c"><input type="checkbox" id="c-42604175" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604049">parent</a><span>|</span><a href="#42604107">next</a><span>|</span><label class="collapse" for="c-42604175">[-]</label><label class="expand" for="c-42604175">[1 more]</label></div><br/><div class="children"><div class="content">When I was at school, we were sometimes all sat down in front of a TV to watch some movie on VHS tape (it was the 90s).<p>At the start of the tape, there was a copyright notice forbidding the VHS tape from being played at, amongst other places, schools.<p>Copyright rules are a strange thing.</div><br/></div></div><div id="42604107" class="c"><input type="checkbox" id="c-42604107" checked=""/><div class="controls bullet"><span class="by">dijksterhuis</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604049">parent</a><span>|</span><a href="#42604175">prev</a><span>|</span><a href="#42603560">next</a><span>|</span><label class="collapse" for="c-42604107">[-]</label><label class="expand" for="c-42604107">[1 more]</label></div><br/><div class="children"><div class="content">copyright refers to the act of copying the material at hand (including distribution, reproduction, performance) etc.<p>as an example: saying “i really like james holden’s inheritors album for the rough and dissonant sounds” isn’t covered by copyright.<p>if i reproduced it verbatim using my mouth, or created a derived work which is noticeably similar to the original, that’s a different question though.<p>in your example, a derivative work example could be akin to only quoting from the book for the audience and modifying a word of each quote.<p>“derived” works are always a grey area, especially around generative machine learning right now.</div><br/></div></div></div></div><div id="42603560" class="c"><input type="checkbox" id="c-42603560" checked=""/><div class="controls bullet"><span class="by">yieldcrv</span><span>|</span><a href="#42603178">parent</a><span>|</span><a href="#42604049">prev</a><span>|</span><a href="#42603466">next</a><span>|</span><label class="collapse" for="c-42603560">[-]</label><label class="expand" for="c-42603560">[1 more]</label></div><br/><div class="children"><div class="content">and therefore everyone has the necessary rights to read works, the necessary rights to critique of the works including for commercial purposes, and the necessary rights to derivative works including for commercial purposes</div><br/></div></div><div id="42603466" class="c"><input type="checkbox" id="c-42603466" checked=""/><div class="controls bullet"><span class="by">sharkest</span><span>|</span><a href="#42603178">parent</a><span>|</span><a href="#42603560">prev</a><span>|</span><a href="#42604202">next</a><span>|</span><label class="collapse" for="c-42603466">[-]</label><label class="expand" for="c-42603466">[2 more]</label></div><br/><div class="children"><div class="content">Would.</div><br/></div></div><div id="42604202" class="c"><input type="checkbox" id="c-42604202" checked=""/><div class="controls bullet"><span class="by">philwelch</span><span>|</span><a href="#42603178">parent</a><span>|</span><a href="#42603466">prev</a><span>|</span><a href="#42603486">next</a><span>|</span><label class="collapse" for="c-42604202">[-]</label><label class="expand" for="c-42604202">[27 more]</label></div><br/><div class="children"><div class="content">You’re applying a double standard to LLM’s and human creators. Any human writer or artist or filmmaker or musician will be influenced by other people’s works, even while those works are still under copyright.</div><br/><div id="42604288" class="c"><input type="checkbox" id="c-42604288" checked=""/><div class="controls bullet"><span class="by">dijksterhuis</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604202">parent</a><span>|</span><a href="#42604273">next</a><span>|</span><label class="collapse" for="c-42604288">[-]</label><label class="expand" for="c-42604288">[5 more]</label></div><br/><div class="children"><div class="content">as a human being, and one that does music stuff, i don’t download terabytes of other peoples works from the internet directly into my brain. i don’t have verbatim reproductions of people’s work sitting around on a hard disk in my stomach&#x2F;lungs&#x2F;head&#x2F;feet.<p>LLMs are not humans. They’re essentially a probabilistic compression algorithm (encode data into model weights&#x2F;decode with prompt to retrieve data).</div><br/><div id="42604461" class="c"><input type="checkbox" id="c-42604461" checked=""/><div class="controls bullet"><span class="by">philwelch</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604288">parent</a><span>|</span><a href="#42604273">next</a><span>|</span><label class="collapse" for="c-42604461">[-]</label><label class="expand" for="c-42604461">[4 more]</label></div><br/><div class="children"><div class="content">Do you ever listen to music? Is your music ever influenced by the music that you listen to? How do you imagine that works, in an information-theoretical sense, that fundamentally differs from an LLM?<p>Depending on how much music you&#x27;ve listened to, you very well may have &quot;downloaded terabytes&quot; of it into your brain. Your argument is specious.</div><br/><div id="42605388" class="c"><input type="checkbox" id="c-42605388" checked=""/><div class="controls bullet"><span class="by">cmiles74</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604461">parent</a><span>|</span><a href="#42604688">next</a><span>|</span><label class="collapse" for="c-42605388">[-]</label><label class="expand" for="c-42605388">[2 more]</label></div><br/><div class="children"><div class="content">Information on how large language models are trained is not hard to come by, there are numerous articles that cover this material. Even a brief skimming of this material will make it clear that the training of large language models is materially different in almost every way from how human beings &quot;learn&quot; and build knowledge. There are still many open questions around the process of how humans collect, store, retrieve and synthesize information.<p>There is little mystery to how large language models function and it&#x27;s clear that their output is parroting back portions of their training data, the quality of output degrades greatly when novel input is provided. Is  your argument that people fundamentally function in the same way? That would be a bold and novel assertion!</div><br/><div id="42608628" class="c"><input type="checkbox" id="c-42608628" checked=""/><div class="controls bullet"><span class="by">philwelch</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42605388">parent</a><span>|</span><a href="#42604688">next</a><span>|</span><label class="collapse" for="c-42608628">[-]</label><label class="expand" for="c-42608628">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There is little mystery to how large language models function and it&#x27;s clear that their output is parroting back portions of their training data<p>If this were true, then you would be able to identify the specific work being &quot;parroted&quot; and you&#x27;d have a case for copyright infringement regardless of whether it was produced by an LLM at all. This isn&#x27;t how LLMs work though. For instance, if an LLM&#x27;s training data includes the complete works of a given author and then you prompt the LLM to write a story in the style of that author, it will actually write an original story instead of reproducing one of the stories in its training corpus. It won&#x27;t be particularly good but it will be an original work.<p>It also isn&#x27;t obvious whether or not, or to what degree, LLM training works differently from human learning. You yourself acknowledged that there are &quot;many open questions&quot; about how human learning works, so how can you be so confident that it&#x27;s fundamentally different? It doesn&#x27;t matter anyway because you can still apply the exact same standards to LLM output to judge whether it infringes copyright that you would to something that was produced by a human being.</div><br/></div></div></div></div><div id="42604688" class="c"><input type="checkbox" id="c-42604688" checked=""/><div class="controls bullet"><span class="by">dijksterhuis</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604461">parent</a><span>|</span><a href="#42605388">prev</a><span>|</span><a href="#42604273">next</a><span>|</span><label class="collapse" for="c-42604688">[-]</label><label class="expand" for="c-42604688">[1 more]</label></div><br/><div class="children"><div class="content">i do listen to music.<p>i listen to it on apple music.<p>i pay money to apple for this.<p>some of that money that i pay to apple goes to the rights holders of that music for the copying and performance of their work through my speakers.<p>that’s a pretty big difference to how most LLMs are trained right there! i actually pay original creators some money.<p>-<p>i am a human being. you cannot reduce me down to some easy information theory.<p>an LLM is a tool. an algorithm. with the same random seed etc etc it will get the same results. it is not human.<p>you put me in the same room as yesterday i’ll behave completely differently.<p>-<p>i have listened to way more than terabytes of music in my life. doesn’t mean i have the ability to regurgitate any of it verbatim though. i’m crap at that stuff.<p>LLMs seem to be really good at it though.</div><br/></div></div></div></div></div></div><div id="42604273" class="c"><input type="checkbox" id="c-42604273" checked=""/><div class="controls bullet"><span class="by">cmiles74</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604202">parent</a><span>|</span><a href="#42604288">prev</a><span>|</span><a href="#42604706">next</a><span>|</span><label class="collapse" for="c-42604273">[-]</label><label class="expand" for="c-42604273">[18 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see how this is a double standard. Comparing a person interacting with their culture is not comparable in any way. IMHO, it&#x27;s kind of a wacky argument to make.</div><br/><div id="42604302" class="c"><input type="checkbox" id="c-42604302" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604273">parent</a><span>|</span><a href="#42605330">next</a><span>|</span><label class="collapse" for="c-42604302">[-]</label><label class="expand" for="c-42604302">[16 more]</label></div><br/><div class="children"><div class="content">Can you elaborate on how it&#x27;s not comparable? It seems obvious to me that it is -- they both learn and then create -- so what&#x27;s the difference?<p>If I can hire an employee who draws on knowledge they learned from copyrighted textbooks, why can&#x27;t I hire an AI which draws on knowledge it learned from copyrighted textbooks? What makes that argument &quot;wacky&quot; in your eyes?</div><br/><div id="42604329" class="c"><input type="checkbox" id="c-42604329" checked=""/><div class="controls bullet"><span class="by">tekno45</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604302">parent</a><span>|</span><a href="#42604744">next</a><span>|</span><label class="collapse" for="c-42604329">[-]</label><label class="expand" for="c-42604329">[11 more]</label></div><br/><div class="children"><div class="content">you&#x27;re asking why you have to treat people differently than you treat tools and machines.</div><br/><div id="42604363" class="c"><input type="checkbox" id="c-42604363" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604329">parent</a><span>|</span><a href="#42604744">next</a><span>|</span><label class="collapse" for="c-42604363">[-]</label><label class="expand" for="c-42604363">[10 more]</label></div><br/><div class="children"><div class="content">Well obviously not in general. But when it comes to copyright law specifically, yes absolutely. That is the question I&#x27;m asking.</div><br/><div id="42605333" class="c"><input type="checkbox" id="c-42605333" checked=""/><div class="controls bullet"><span class="by">cmiles74</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604363">parent</a><span>|</span><a href="#42604497">next</a><span>|</span><label class="collapse" for="c-42605333">[-]</label><label class="expand" for="c-42605333">[1 more]</label></div><br/><div class="children"><div class="content">It has never been argued that copyright law should apply to information the people learn, whether that be from reading books or newspapers, watching television or appreciating art like paintings or photographs.<p>Unlike a person, an large language model is product built by a company and sold by a company. While I am not a lawyer, I believe much of the copyright arguments around LLM training revolve around the idea that copyrighted content should be licensed by the company training the LLM. In much the same way that people are not allowed to scrape the content of the New York Time website and then pass it off as their own content, so should OpenAI be barred from scraping the New York Times website to train ChatGPT and then sell the service without providing some dollars back to the New York Times.</div><br/></div></div><div id="42604497" class="c"><input type="checkbox" id="c-42604497" checked=""/><div class="controls bullet"><span class="by">salawat</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604363">parent</a><span>|</span><a href="#42605333">prev</a><span>|</span><a href="#42604744">next</a><span>|</span><label class="collapse" for="c-42604497">[-]</label><label class="expand" for="c-42604497">[8 more]</label></div><br/><div class="children"><div class="content">You&#x27;re not going to get an answer you find agreeable, because you&#x27;re hoping for an answer that allows you to continue to treat the tool as chattel, without conferring to it the excess baggage of being an individuated entity&#x2F;laborer.<p>You&#x27;re either going to get: it&#x27;s a technological, infinitely scalable process, and the training data should be considered what it is, which is intellectual property that should be being licensed before being used.<p>...or... It actually is the same as human learning, and it&#x27;s time we started loading these things up with other baggage to be attached to persons if we&#x27;re going to accept it&#x27;s possible for a machine to learn like a human.<p>There isn&#x27;t a reasonable middle ground due to the magnitude of social disruption a chattel quasi-human technological human replacement would cause.</div><br/><div id="42608766" class="c"><input type="checkbox" id="c-42608766" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604497">parent</a><span>|</span><a href="#42604733">next</a><span>|</span><label class="collapse" for="c-42608766">[-]</label><label class="expand" for="c-42608766">[1 more]</label></div><br/><div class="children"><div class="content">Hi.  I like this post.  There are some careful thoughts here.<p>Can you help me to understand the term &quot;chattel&quot; as you used it?  I never heard the term before I read your post, and I needed to Google for it: &lt;&lt;<p>(in general use) a personal possession.<p>(in law) an item of property other than freehold land, including tangible goods ( chattels personal ) and leasehold interests ( chattels real ).
&gt;&gt;</div><br/></div></div><div id="42604733" class="c"><input type="checkbox" id="c-42604733" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604497">parent</a><span>|</span><a href="#42608766">prev</a><span>|</span><a href="#42604605">next</a><span>|</span><label class="collapse" for="c-42604733">[-]</label><label class="expand" for="c-42604733">[1 more]</label></div><br/><div class="children"><div class="content">Aren&#x27;t animals a current example of a middle ground?  They are incapable of authoring copyrightable works under current US law.</div><br/></div></div><div id="42604605" class="c"><input type="checkbox" id="c-42604605" checked=""/><div class="controls bullet"><span class="by">philwelch</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604497">parent</a><span>|</span><a href="#42604733">prev</a><span>|</span><a href="#42604744">next</a><span>|</span><label class="collapse" for="c-42604605">[-]</label><label class="expand" for="c-42604605">[5 more]</label></div><br/><div class="children"><div class="content">No, you’re missing the point of copyright. The point of copyright is to protect an exclusive right to copy, not the right to produce original works influenced by previous works. If an LLM produces original works that are influenced by the training data, that is not a violation of copyright. If it reproduces the training data verbatim, it is.</div><br/><div id="42608795" class="c"><input type="checkbox" id="c-42608795" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604605">parent</a><span>|</span><a href="#42604749">next</a><span>|</span><label class="collapse" for="c-42608795">[-]</label><label class="expand" for="c-42608795">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; The point of copyright is to protect an exclusive right to copy, not the right to produce original works influenced by previous works.
</code></pre>
As I understand, the definition of &quot;the right to produce original works influenced by previous works&quot; has been a <i>slowly</i> moving target in my lifetime.  Think about the effects of the album Paul&#x27;s Boutique by Beastie Boys.  They went wild with sampling and paid very little (zero?) to license those samples.  Then, there were a bunch of court cases in the US that decided that future samplers needed to license the samples from the original authors.  However, the ability to create legal, derivative works is usually carefully defined in copyright law.  Can you comment on this matter vis-a-via LLMs?<p><pre><code>    &gt; If an LLM produces original works that are influenced by the training data, that is not a violation of copyright.
</code></pre>
I&#x27;m pretty sure if an LLM creates Paul&#x27;s Boutique 2.0 in 2025 using incredible number of samples, then someone cannot sell it (or use it in a YouTube video) without first licensing those samples.  I doubt very much someone could just &quot;hide behind&quot; an LLM and claim, &quot;Oh, it is original, but derivative, work, created by an LLM.&quot;  I doubt courts would allow that.</div><br/></div></div><div id="42604749" class="c"><input type="checkbox" id="c-42604749" checked=""/><div class="controls bullet"><span class="by">dijksterhuis</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604605">parent</a><span>|</span><a href="#42608795">prev</a><span>|</span><a href="#42607711">next</a><span>|</span><label class="collapse" for="c-42604749">[-]</label><label class="expand" for="c-42604749">[2 more]</label></div><br/><div class="children"><div class="content">i weirdly agree with you, but also want to point out that “influenced by the training data” is doing some very heavy lifting there.<p>exactly how the new work is created is important when it comes to derivative works.<p>does it use a copy of the original work to create it, or a vague idea&#x2F;memory of the original work’s composition?<p>when i make music it’s usually vague memories. i’d argue that LLMs have an encoded representation of the original work in their weights (along with all the other stuff).<p>but that’s the legal grey area bit. is the “mush” of model weights an encoded representation of works, or vague memories?</div><br/><div id="42604932" class="c"><input type="checkbox" id="c-42604932" checked=""/><div class="controls bullet"><span class="by">philwelch</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604749">parent</a><span>|</span><a href="#42607711">next</a><span>|</span><label class="collapse" for="c-42604932">[-]</label><label class="expand" for="c-42604932">[1 more]</label></div><br/><div class="children"><div class="content">I don’t really think it matters because you can just compare the output to the input and apply the same standard, treating the process between the two as a black box.</div><br/></div></div></div></div><div id="42607711" class="c"><input type="checkbox" id="c-42607711" checked=""/><div class="controls bullet"><span class="by">yencabulator</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604605">parent</a><span>|</span><a href="#42604749">prev</a><span>|</span><a href="#42604744">next</a><span>|</span><label class="collapse" for="c-42607711">[-]</label><label class="expand" for="c-42607711">[1 more]</label></div><br/><div class="children"><div class="content">Also, even if an LLM generates an original work, the weights it used may still be a derived work.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42604744" class="c"><input type="checkbox" id="c-42604744" checked=""/><div class="controls bullet"><span class="by">_DeadFred_</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604302">parent</a><span>|</span><a href="#42604329">prev</a><span>|</span><a href="#42605307">next</a><span>|</span><label class="collapse" for="c-42604744">[-]</label><label class="expand" for="c-42604744">[1 more]</label></div><br/><div class="children"><div class="content">One is a collection of highly dithered data generated by machines paid for by a business in order to financially gain from the copyrighted works in order to replace any future need for copyrighted text books.<p>The other is a person learning from a copyrighted textbook in the legally protected manner, and whom and use the textbook was written for.</div><br/></div></div><div id="42605307" class="c"><input type="checkbox" id="c-42605307" checked=""/><div class="controls bullet"><span class="by">cmiles74</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604302">parent</a><span>|</span><a href="#42604744">prev</a><span>|</span><a href="#42604915">next</a><span>|</span><label class="collapse" for="c-42605307">[-]</label><label class="expand" for="c-42605307">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this question really makes any sense... In my opinion, it&#x27;s kind of mish-mashing several things together.<p>&quot;Can you elaborate on how it&#x27;s not comparable?&quot;<p>The process of individual people interacting with their culture is a vastly different process than that used to train large language models. In what ways to you think these processes have anything in common?<p>&quot;It seems obvious to me that it is -- they both learn and then create -- so what&#x27;s the difference?&quot;<p>This doesn&#x27;t seem obvious to me (obviously)! Maybe you can argue that an LLM &quot;learns&quot; during training, but that ceases once training is complete. For sure, there are work-arounds that meet certain goals (RAG, fine-tuning); maybe your already vague definition of &quot;learning&quot; could be stretched to include these? Still, comparing this to how people learn is pretty far-fetched. AFAICT, there&#x27;s no literature supporting the view that there&#x27;s any commonality here; if you have some I would be very interested to read it. :-)<p>Do they both create? I suspect not; an LLM is parroting back data from it&#x27;s training set. We&#x27;ve seen many studies showing that tested LLMs perform poorly on novel problem sets. This article was posted just this week:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42565606">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42565606</a><p>The court is still out on the copyright issue, for the perspective of US law we&#x27;ll have to wait on this one. Still, it&#x27;s clear that an LLM can&#x27;t &quot;create&quot; in any meaningful way.<p>And so on and so forth. How is hiring an employee at all similar to subscribing to an OpenAI ChatGPT plan? Wacky indeed!</div><br/></div></div><div id="42604915" class="c"><input type="checkbox" id="c-42604915" checked=""/><div class="controls bullet"><span class="by">homarp</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604302">parent</a><span>|</span><a href="#42605307">prev</a><span>|</span><a href="#42604860">next</a><span>|</span><label class="collapse" for="c-42604915">[-]</label><label class="expand" for="c-42604915">[1 more]</label></div><br/><div class="children"><div class="content">most probably your employee actually &#x27;paid&#x27; for their textbook.</div><br/></div></div><div id="42604860" class="c"><input type="checkbox" id="c-42604860" checked=""/><div class="controls bullet"><span class="by">groby_b</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604302">parent</a><span>|</span><a href="#42604915">prev</a><span>|</span><a href="#42605330">next</a><span>|</span><label class="collapse" for="c-42604860">[-]</label><label class="expand" for="c-42604860">[1 more]</label></div><br/><div class="children"><div class="content">Unless you are making an argument for personhood, one is a machine, the other is a human. Different standards apply, end of discussion.</div><br/></div></div></div></div><div id="42605330" class="c"><input type="checkbox" id="c-42605330" checked=""/><div class="controls bullet"><span class="by">rob_c</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604273">parent</a><span>|</span><a href="#42604302">prev</a><span>|</span><a href="#42604706">next</a><span>|</span><label class="collapse" for="c-42605330">[-]</label><label class="expand" for="c-42605330">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a little simplistic. You&#x27;re almost trying to say blank and white sands gray can&#x27;t be compared which is a bit weird.<p>Strangely like the situation itself.<p>The question is just looked to how can we guarantee a model is influenced rather than memorising an input?<p>And then is a human who is influenced simply relying on a faulty or less than perfect memory?</div><br/></div></div></div></div><div id="42604706" class="c"><input type="checkbox" id="c-42604706" checked=""/><div class="controls bullet"><span class="by">_DeadFred_</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604202">parent</a><span>|</span><a href="#42604273">prev</a><span>|</span><a href="#42603486">next</a><span>|</span><label class="collapse" for="c-42604706">[-]</label><label class="expand" for="c-42604706">[3 more]</label></div><br/><div class="children"><div class="content">Human creators don&#x27;t store that &#x27;influence&#x27; in a digital machine accessible format generated directly from the copyrighted content though.<p>Although with the &#x27;good new everyone, we built the torment nexus&#x27; trajectory of AI my guess is at this point AI companies would just incorporate actual human brains instead of digital storage if that was the requirement.</div><br/><div id="42604841" class="c"><input type="checkbox" id="c-42604841" checked=""/><div class="controls bullet"><span class="by">galangalalgol</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604706">parent</a><span>|</span><a href="#42604995">next</a><span>|</span><label class="collapse" for="c-42604841">[-]</label><label class="expand" for="c-42604841">[1 more]</label></div><br/><div class="children"><div class="content">Does that imply that if we invent brain upload technology, that my weights have every conflicting license and patent for everything I can quote or create? I don&#x27;t like that precedent. I have complete rights over my noggin&#x27;s contents. If I do quote a NYT article in it&#x27;s entirely, <i>that</i> vould be infringement, but not copying my brain itself.</div><br/></div></div><div id="42604995" class="c"><input type="checkbox" id="c-42604995" checked=""/><div class="controls bullet"><span class="by">philwelch</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604706">parent</a><span>|</span><a href="#42604841">prev</a><span>|</span><a href="#42603486">next</a><span>|</span><label class="collapse" for="c-42604995">[-]</label><label class="expand" for="c-42604995">[1 more]</label></div><br/><div class="children"><div class="content">Your argument boils down to “we don’t know how brains work”, and it is a non-sequitur. It isn’t a violation of copyright law to create original works under the creative influence of works still under copyright.</div><br/></div></div></div></div></div></div><div id="42603486" class="c"><input type="checkbox" id="c-42603486" checked=""/><div class="controls bullet"><span class="by">deadbabe</span><span>|</span><a href="#42603178">parent</a><span>|</span><a href="#42604202">prev</a><span>|</span><a href="#42603993">next</a><span>|</span><label class="collapse" for="c-42603486">[-]</label><label class="expand" for="c-42603486">[13 more]</label></div><br/><div class="children"><div class="content">Fair use.</div><br/><div id="42604242" class="c"><input type="checkbox" id="c-42604242" checked=""/><div class="controls bullet"><span class="by">dijksterhuis</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42603486">parent</a><span>|</span><a href="#42604045">next</a><span>|</span><label class="collapse" for="c-42604242">[-]</label><label class="expand" for="c-42604242">[1 more]</label></div><br/><div class="children"><div class="content">*only available in the USA, terms and conditions apply.<p>most other places use fair dealing which is more restrictive <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Fair_dealing" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Fair_dealing</a></div><br/></div></div><div id="42604045" class="c"><input type="checkbox" id="c-42604045" checked=""/><div class="controls bullet"><span class="by">griomnib</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42603486">parent</a><span>|</span><a href="#42604242">prev</a><span>|</span><a href="#42604325">next</a><span>|</span><label class="collapse" for="c-42604045">[-]</label><label class="expand" for="c-42604045">[1 more]</label></div><br/><div class="children"><div class="content">Easy to claim, harder to justify once you start charging money for your subsequent creation.<p>Unless all LLM are a ruthless parody of human intelligence, which they may be, the legal issues will continue.</div><br/></div></div><div id="42604325" class="c"><input type="checkbox" id="c-42604325" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42603486">parent</a><span>|</span><a href="#42604045">prev</a><span>|</span><a href="#42603993">next</a><span>|</span><label class="collapse" for="c-42604325">[-]</label><label class="expand" for="c-42604325">[10 more]</label></div><br/><div class="children"><div class="content">The moment you earn money from it, that&#x27;s not fair use anymore. When I last checked, unlimited access to said models were not free, plus it&#x27;s not &quot;research&quot; anymore.<p>- Addenda -<p>For the interested parties, the law states the following [0].<p>Notwithstanding the provisions of sections 17 U.S.C. § 106 and 17 U.S.C. § 106A, the fair use of a copyrighted work, including such use by reproduction in copies or phonorecords or by any other means specified by that section, for purposes such as criticism, comment, news reporting, teaching (including multiple copies for classroom use), scholarship, or research, is not an infringement of copyright. In determining whether the use made of a work in any particular case is a fair use the factors to be considered shall include:<p><pre><code>    1. the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes;
    2. the nature of the copyrighted work;
    3. the amount and substantiality of the portion used in relation to the copyrighted work as a whole; and
    4. the effect of the use upon the potential market for or value of the copyrighted work.

</code></pre>
The fact that a work is unpublished shall not itself bar a finding of fair use if such finding is made upon consideration of all the above factors<p>So, if you say that these factors can be flexed depending on the defendant, and can be just waved away to protect the wealthy, then it becomes <i>something else</i>, but given these factors, and how damaging this &quot;fair use&quot; is, I can certainly say that training AI models with copyrighted corpus is not fair use in any way.<p>Of course at the end of the day, IANAL &amp; IANAJ. However, my moral compass directly bars use of copyrighted corpus in publicly accessible, for profit models which undermine many people of their livelihoods.<p>From my perspective, people can whitewash AI training as they see fit to sleep sound at night, but this doesn&#x27;t change anything from my PoV.<p>[0]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fair_use#U.S._fair_use_factors" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fair_use#U.S._fair_use_factors</a></div><br/><div id="42604437" class="c"><input type="checkbox" id="c-42604437" checked=""/><div class="controls bullet"><span class="by">FloorEgg</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604325">parent</a><span>|</span><a href="#42604387">next</a><span>|</span><label class="collapse" for="c-42604437">[-]</label><label class="expand" for="c-42604437">[3 more]</label></div><br/><div class="children"><div class="content">I really don&#x27;t think it&#x27;s that simple. I can read books and then earn money from applying what I learned in them. I can also study art and then make original art in the same or similar styles. If a person was doing this there would be no one claiming copyright infringement. The only difference is it&#x27;s a machine doing it and not a person.<p>The nature of copyright and plagiarism boils down to paraphrasing, and so long as LLMs sufficiently paraphrase the content it&#x27;s an open question whether it&#x27;s copyright infringement and requires new law&#x2F;precedent.<p>So the fact they are earning money is a red herring unless they are reproducing the exact same content without paraphrasing (with exception to commentary). E.g. they can quote part of a work while commenting on it.<p>Where they have gotten into trouble with e.g. NYT afaik is when the LLM reproduced a whole article word for word. I think they have all tried hard to prevent the LLM from ever doing that to avoid that legal risk.</div><br/><div id="42604724" class="c"><input type="checkbox" id="c-42604724" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604437">parent</a><span>|</span><a href="#42604387">next</a><span>|</span><label class="collapse" for="c-42604724">[-]</label><label class="expand" for="c-42604724">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I can read books and then earn money from applying what I learned in them.<p>How many books can you read, understand and memorize in T time, and how many books an AI can ingest in the T time?<p>If we&#x27;re down to paraphrasing, watch this video [1], and think again.<p>Many models, given that you ask the correct questions, reproduce their training set with great accuracy, and this is only prevented with monkey patching, IIUC.<p>So, it&#x27;s still a big mess, even if we don&#x27;t add copyrighted corpus to the mix. Oh, BTW, datasets like &quot;The Stack&quot; are not clean as they claim. I have seen at least two non-permissively licensed code repositories inside that dataset.<p>[1]: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;LrkAORPiaEA" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;LrkAORPiaEA</a></div><br/><div id="42605856" class="c"><input type="checkbox" id="c-42605856" checked=""/><div class="controls bullet"><span class="by">FloorEgg</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604724">parent</a><span>|</span><a href="#42604387">next</a><span>|</span><label class="collapse" for="c-42605856">[-]</label><label class="expand" for="c-42605856">[1 more]</label></div><br/><div class="children"><div class="content">I agree it&#x27;s a big mess, that was kind of my point.<p>I am curious about the video, but am not compelled to spend 24 min watching it when you haven&#x27;t summarized its thesis for me. The title of the video makes it seem adjacent at best to the points I was making. (Some automated flagging system =&#x2F;= actual law)</div><br/></div></div></div></div></div></div><div id="42604387" class="c"><input type="checkbox" id="c-42604387" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604325">parent</a><span>|</span><a href="#42604437">prev</a><span>|</span><a href="#42604384">next</a><span>|</span><label class="collapse" for="c-42604387">[-]</label><label class="expand" for="c-42604387">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Making money&quot; does not immediately invalidate fair use, but it does wave a big red flag in the courts&#x27; faces.</div><br/><div id="42604742" class="c"><input type="checkbox" id="c-42604742" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604387">parent</a><span>|</span><a href="#42604384">next</a><span>|</span><label class="collapse" for="c-42604742">[-]</label><label class="expand" for="c-42604742">[2 more]</label></div><br/><div class="children"><div class="content">So you say that, every law is a suggestion depending who&#x27;s being tried?</div><br/><div id="42604933" class="c"><input type="checkbox" id="c-42604933" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604742">parent</a><span>|</span><a href="#42604384">next</a><span>|</span><label class="collapse" for="c-42604933">[-]</label><label class="expand" for="c-42604933">[1 more]</label></div><br/><div class="children"><div class="content">Er, what? I&#x27;m speaking directly from the law, 17 U.S.C. § 107. It&#x27;s deliberately written in terms of &quot;factors to consider&quot;, rather than absolutes.<p>&gt; In determining whether the use made of a work in any particular case is a fair use the factors to be considered shall include:<p>&gt; *       the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes;<p>&gt; *       the nature of the copyrighted work;<p>&gt; *       the amount and substantiality of the portion used in relation to the copyrighted work as a whole; and<p>&gt; *       the effect of the use upon the potential market for or value of the copyrighted work.</div><br/></div></div></div></div></div></div><div id="42604384" class="c"><input type="checkbox" id="c-42604384" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604325">parent</a><span>|</span><a href="#42604387">prev</a><span>|</span><a href="#42603993">next</a><span>|</span><label class="collapse" for="c-42604384">[-]</label><label class="expand" for="c-42604384">[3 more]</label></div><br/><div class="children"><div class="content">You can absolutely monetize works altered under fair use.</div><br/><div id="42604730" class="c"><input type="checkbox" id="c-42604730" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604384">parent</a><span>|</span><a href="#42603993">next</a><span>|</span><label class="collapse" for="c-42604730">[-]</label><label class="expand" for="c-42604730">[2 more]</label></div><br/><div class="children"><div class="content">Any examples sans current AI models? I have not seen any, or failed to find any, to precise.</div><br/><div id="42605448" class="c"><input type="checkbox" id="c-42605448" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#42603178">root</a><span>|</span><a href="#42604730">parent</a><span>|</span><a href="#42603993">next</a><span>|</span><label class="collapse" for="c-42605448">[-]</label><label class="expand" for="c-42605448">[1 more]</label></div><br/><div class="children"><div class="content">Basically any YouTube video that shows another YouTube video, song, movie, etc. as part of something else (eg a voiceover.)</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42603993" class="c"><input type="checkbox" id="c-42603993" checked=""/><div class="controls bullet"><span class="by">kittikitti</span><span>|</span><a href="#42603178">prev</a><span>|</span><a href="#42602063">next</a><span>|</span><label class="collapse" for="c-42603993">[-]</label><label class="expand" for="c-42603993">[1 more]</label></div><br/><div class="children"><div class="content">This was a great article and I really appreciate it!</div><br/></div></div><div id="42602063" class="c"><input type="checkbox" id="c-42602063" checked=""/><div class="controls bullet"><span class="by">wat10000</span><span>|</span><a href="#42603993">prev</a><span>|</span><a href="#42604251">next</a><span>|</span><label class="collapse" for="c-42602063">[-]</label><label class="expand" for="c-42602063">[58 more]</label></div><br/><div class="children"><div class="content">“ Keep in mind that AI models, like most things, are considered intellectual property. Before using or modifying any extracted models, you need the explicit permission of their owner.”<p>That’s not true, is it? It would be a copyright violation to distribute an extracted model, but you can do what you want with it yourself.</div><br/><div id="42602255" class="c"><input type="checkbox" id="c-42602255" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#42602063">parent</a><span>|</span><a href="#42602192">next</a><span>|</span><label class="collapse" for="c-42602255">[-]</label><label class="expand" for="c-42602255">[30 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not even sure if event the first part is true.  Has it been determined if AI models are intellectual property?  Machine generated content may not be copyrightable.  It isn&#x27;t just the output of generative AI that falls under this,  the models themselves are.<p>Can you copyright a set of coefficients for a formula?  In the sense of a JPEG it would be considered that the image being reproduced is the thing that has the copyright.  Being the first to run the calculations that produces a compressed version of that data should not grant you any special rights to that compressed form.<p>An AI model is just a form of that writ large.   When the models generalize and create new content, it seems hard to see how that either the output or the model that generated it could be considered someone&#x27;s property.<p>People possess models,   I&#x27;m not sure if they own them.<p>There are however billions of dollars at play here and enough money can buy you whichever legal opinion you want.</div><br/><div id="42603624" class="c"><input type="checkbox" id="c-42603624" checked=""/><div class="controls bullet"><span class="by">cle</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602255">parent</a><span>|</span><a href="#42602790">next</a><span>|</span><label class="collapse" for="c-42603624">[-]</label><label class="expand" for="c-42603624">[1 more]</label></div><br/><div class="children"><div class="content">I think you have to distinguish between a model, its implementation, and its weights&#x2F;parameters. AFAIU:<p>- Models are processes&#x2F;concepts, thus not copyrightable, but <i>are</i> subject to trade secret law, contract and license restrictions, patents, etc.<p>- Concrete implementations may be copyrighted like any code.<p>- Parameters are &quot;facts&quot;, thus not copyrightable, but are similarly subject to trade secret and contract law.<p>IANAL, not legal advice, yadda yadda yadda.</div><br/></div></div><div id="42602790" class="c"><input type="checkbox" id="c-42602790" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602255">parent</a><span>|</span><a href="#42603624">prev</a><span>|</span><a href="#42603448">next</a><span>|</span><label class="collapse" for="c-42602790">[-]</label><label class="expand" for="c-42602790">[20 more]</label></div><br/><div class="children"><div class="content">&gt; AI models are intellectual property<p>If companies train on data they don&#x27;t own and expect to own their model weights, that&#x27;s hypocritical.<p>Model weights shouldn&#x27;t be copyrightable if the training data was pilfered.<p>But this hasn&#x27;t been tested because models are locked away in data centers as trade secrets. There&#x27;s no opportunity to observe or copy them outside of using their outputs as synthetic data.<p>On that subject, training on model outputs should be fair use, and an area we should use legislation to defend access to (similar to web scraping provisions).</div><br/><div id="42603307" class="c"><input type="checkbox" id="c-42603307" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602790">parent</a><span>|</span><a href="#42603376">next</a><span>|</span><label class="collapse" for="c-42603307">[-]</label><label class="expand" for="c-42603307">[9 more]</label></div><br/><div class="children"><div class="content">&gt; If companies train on data they don&#x27;t own and expect to own their model weights, that&#x27;s hypocritical.<p>Its not hypocritical to follow a line of legal analysis whoch holds that copying material in the course of training AI  on it is outside the scope of copyright protection (as, e.g., fair use in the US), but that the model weights resulting from the training are protected by copyright.<p>It maybe wrong, and it may 
be convenient for the interests of the firms involved, but it is not self-inconsistent in the way required for it to be hypocrisy.</div><br/><div id="42603545" class="c"><input type="checkbox" id="c-42603545" checked=""/><div class="controls bullet"><span class="by">Mordisquitos</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603307">parent</a><span>|</span><a href="#42604820">next</a><span>|</span><label class="collapse" for="c-42603545">[-]</label><label class="expand" for="c-42603545">[5 more]</label></div><br/><div class="children"><div class="content">If the resulting AI models are protected by copyright that invalidates the claim that AI models being trained on copyrighted materials is fair-use analogous to human beings becoming educated by exposure to copyrighted materials.<p>Educated human beings are not protected by copyright, hence neither should trained AI models. Conversely, if a copyrightable work is produced based on work which itself is copyrighted, the resulting work needs the consent of the original authors of the prior work.<p>AI models can&#x27;t have their ©ake and eat it.</div><br/><div id="42608183" class="c"><input type="checkbox" id="c-42608183" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603545">parent</a><span>|</span><a href="#42604622">next</a><span>|</span><label class="collapse" for="c-42608183">[-]</label><label class="expand" for="c-42608183">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If the resulting AI models are protected by copyright that invalidates the claim that AI models being trained on copyrighted materials is fair-use analogous to human beings becoming educated by exposure to copyrighted materials.<p>No one training (foundation) models makes that fair use argument by analogy, they make arguments that addresses the specific statutory and case law criteria for fair use (abd frequently focus on the transformative character of the use); its true that the analogy to a learning human argument is frequently made in internet fora by AI enthusiasts who aren&#x27;t the people training models on vaat scraped datasets. That argument is bunk for a number of reasons, but most critically the fact that a human learning from material <i>isn’t fair use</i>, because a human brain isn’t treated as a fixed medium, so learning in a human brain isn’t legally a copy or derivative work that would violate copyright without the fair use exception, so it&#x27;s not a use to which fair use analysis even applies, so you can&#x27;t argue anything is fair use by analogy to that. But its moot to any argument for hypocrisy by the big model makers, because they aren’t using that argument to start with.</div><br/></div></div><div id="42604622" class="c"><input type="checkbox" id="c-42604622" checked=""/><div class="controls bullet"><span class="by">drdeca</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603545">parent</a><span>|</span><a href="#42608183">prev</a><span>|</span><a href="#42604820">next</a><span>|</span><label class="collapse" for="c-42604622">[-]</label><label class="expand" for="c-42604622">[3 more]</label></div><br/><div class="children"><div class="content">If I take 1000 books and count the distributions of the lengths of the words, and the covariance between the lengths of one word and the next word for each book, and how much this covariance matrix tends to vary across the different books, and other things like this, and publish these summaries, it seems fairly clear to me that this should count as fair use.<p>(Such a model&#x2F;statistical-summary, along with a dictionary, could be used to generate nonsensical texts which have similar patterns in terms of just word lengths.)<p>Should the resulting work be protected by copyright? I’m not entirely sure…<p>I guess one thing is, the specific numbers I obtain by doing this are not a consequence of any creative decision making on my part, which I think in some jurisdictions (I don’t remember which) plays a role in whether a work is copyrightable (I will use “copyrightable” as an abbreviation for “protected by copyright”. I don’t mean to imply a requirement that someone specifically registers for copyright.). (Iirc this makes it so phone books are copyrightable in some jurisdictions but not others?)<p>The particular choice of statistical analysis does seem like it may involve creative decision making, but that would just be about like, what analysis I describe, and how the numbers I publish are to be interpreted, not what the numbers are? (Analogous to the source code of an ML model, not the parameters.)<p>Here is another question: suppose there is a method of producing a data artifact which would be genuinely (and economically) useful, and which does not rely on taking in any copyrighted input, but requires a large (expensive) amount of compute to produce, and which also uses a lot of randomness so that the result would be different each time it was done (but suppose also that there isn’t much point doing it multiple times at the same scale, as having two of this kind of data artifact wouldn’t be much more valuable than having one).<p>Should such data artifacts be protected by copyright or something like it?<p>Well, if copyright requires creative human decision making, then they wouldn’t be.<p>It seems like it would make sense to want it to be economically incentivized to create such data artifacts of higher sizes (to a point of course. Only as much as is justified by the value that is produced by them being available.) .<p>If such data artifacts can always be distributed without restriction, then ones that are publicly available would be public goods, and I guess only ones that are trade secrets would be private goods? It seems to me like having some mechanism to incentivize their creation and being-eventually-freely-distributed would be beneficial?<p>But maybe copyright isn’t the best way to do that? Idk.</div><br/><div id="42604799" class="c"><input type="checkbox" id="c-42604799" checked=""/><div class="controls bullet"><span class="by">_DeadFred_</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42604622">parent</a><span>|</span><a href="#42604909">next</a><span>|</span><label class="collapse" for="c-42604799">[-]</label><label class="expand" for="c-42604799">[1 more]</label></div><br/><div class="children"><div class="content">&#x27;Should the resulting work be protected by copyright? I’m not entirely sure…&#x27;<p>This has already been settled hasn&#x27;t it? Don&#x27;t companies have to introduce &#x27;flaws&#x27; in order for data sets to be &#x27;protected&#x27;? Just compiled lists of facts can&#x27;t be protected. Which is why things like election result companies having to rely on NDAs and not copyright protections to protect their services on election night.</div><br/></div></div><div id="42604909" class="c"><input type="checkbox" id="c-42604909" checked=""/><div class="controls bullet"><span class="by">Mordisquitos</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42604622">parent</a><span>|</span><a href="#42604799">prev</a><span>|</span><a href="#42604820">next</a><span>|</span><label class="collapse" for="c-42604909">[-]</label><label class="expand" for="c-42604909">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>suppose there is a method of producing a data artifact which would be genuinely (and economically) useful, and which does not rely on taking in any copyrighted input, [...] It seems like it would make sense to want it to be economically incentivized to create such data artifacts of higher sizes [...] But maybe copyright isn’t the best way to do that? Idk.</i><p>Exactly. It would be patents, not copyright.</div><br/></div></div></div></div></div></div><div id="42604820" class="c"><input type="checkbox" id="c-42604820" checked=""/><div class="controls bullet"><span class="by">OkayPhysicist</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603307">parent</a><span>|</span><a href="#42603545">prev</a><span>|</span><a href="#42604282">next</a><span>|</span><label class="collapse" for="c-42604820">[-]</label><label class="expand" for="c-42604820">[2 more]</label></div><br/><div class="children"><div class="content">The model weights are the result of an automated process, by definition, and thus not protected by copyright.<p>In my unusually well-informed on copyright but not a lawyer opinion, without any new legislation on the subject, I suspect that the most likely scenario for intellectual property rights surrounding AI is that using other people&#x27;s works for training probably falls under fair use, since it&#x27;s extremely transformative (an AI that makes text and a textual work are very different things) and it&#x27;s extremely difficult to argue that the AI, as it exists today, directly impacts the value of the original work.<p>The list of what traing data to use  is probably protected by copyright if hand-picked, otherwise just whatever web-crawler they wrote to gather it.<p>The AI models, as in, the inference and training applications are protected by copyright, like any other application.<p>The architecture of a particular AI model can be protected by patents.<p>The weights, as the result of an automated process, are probably not protected by copyright.</div><br/><div id="42608207" class="c"><input type="checkbox" id="c-42608207" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42604820">parent</a><span>|</span><a href="#42604282">next</a><span>|</span><label class="collapse" for="c-42608207">[-]</label><label class="expand" for="c-42608207">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The model weights are the result of an automated process, by definition, and thus not protected by copyright.<p>Object code is the result of an automated process and is covered by the copyright on the source code.<p>Compilations are covered by  copyright separate from that of the individual works, and it is arguable that a training set would be covered by a compilation copyright, and the result of applying an automated training processs to it would remain covered by that copyright.</div><br/></div></div></div></div><div id="42604282" class="c"><input type="checkbox" id="c-42604282" checked=""/><div class="controls bullet"><span class="by">tjr</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603307">parent</a><span>|</span><a href="#42604820">prev</a><span>|</span><a href="#42603376">next</a><span>|</span><label class="collapse" for="c-42604282">[-]</label><label class="expand" for="c-42604282">[1 more]</label></div><br/><div class="children"><div class="content">I think it is fair to say that existing copyright law was not written to handle all of this. It was written for people who created works, and for other people who were using those works.<p>To substitute either party with a computer system and assume that the existing law still makes sense may be assuming too much.</div><br/></div></div></div></div><div id="42603376" class="c"><input type="checkbox" id="c-42603376" checked=""/><div class="controls bullet"><span class="by">rsynnott</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602790">parent</a><span>|</span><a href="#42603307">prev</a><span>|</span><a href="#42603081">next</a><span>|</span><label class="collapse" for="c-42603376">[-]</label><label class="expand" for="c-42603376">[1 more]</label></div><br/><div class="children"><div class="content">There are certainly publicly available weights with restrictive licenses (eg some of the StableDiffusion stuff). I’d agree that it’d seem fairly perverse to say “our process for making this by slurping in a ton of copyright content was not copyright theft, but your use of it outside our restrictive license is”, but then I’m not a lawyer.</div><br/></div></div><div id="42603081" class="c"><input type="checkbox" id="c-42603081" checked=""/><div class="controls bullet"><span class="by">ANewFormation</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602790">parent</a><span>|</span><a href="#42603376">prev</a><span>|</span><a href="#42603636">next</a><span>|</span><label class="collapse" for="c-42603081">[-]</label><label class="expand" for="c-42603081">[8 more]</label></div><br/><div class="children"><div class="content">Now that you mention it, I&#x27;m quite surprised that none of the typical fanatical IP lawsuiters had sued arguing (reasonably I think) that the output of the LLMs is strongly suggestive that they have been trained on copyrighted materials. Get the lawsuit to discovery, and those data centers become fair game.<p>Perhaps &#x27;strongly suggestive&#x27; isn&#x27;t enough.</div><br/><div id="42603148" class="c"><input type="checkbox" id="c-42603148" checked=""/><div class="controls bullet"><span class="by">Onawa</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603081">parent</a><span>|</span><a href="#42603326">next</a><span>|</span><label class="collapse" for="c-42603148">[-]</label><label class="expand" for="c-42603148">[1 more]</label></div><br/><div class="children"><div class="content">Wasn&#x27;t that the goal of both the New York Times lawsuit and other class action lawsuits from authors?<p><a href="https:&#x2F;&#x2F;harvardlawreview.org&#x2F;blog&#x2F;2024&#x2F;04&#x2F;nyt-v-openai-the-timess-about-face&#x2F;" rel="nofollow">https:&#x2F;&#x2F;harvardlawreview.org&#x2F;blog&#x2F;2024&#x2F;04&#x2F;nyt-v-openai-the-t...</a><p><a href="https:&#x2F;&#x2F;www.publishersweekly.com&#x2F;pw&#x2F;by-topic&#x2F;industry-news&#x2F;publisher-news&#x2F;article&#x2F;95768-authors-sue-ai-firm-anthropic-for-copyright-infringement.html" rel="nofollow">https:&#x2F;&#x2F;www.publishersweekly.com&#x2F;pw&#x2F;by-topic&#x2F;industry-news&#x2F;p...</a></div><br/></div></div><div id="42603326" class="c"><input type="checkbox" id="c-42603326" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603081">parent</a><span>|</span><a href="#42603148">prev</a><span>|</span><a href="#42603248">next</a><span>|</span><label class="collapse" for="c-42603326">[-]</label><label class="expand" for="c-42603326">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Now that you mention it, I&#x27;m quite surprised that none of the typical fanatical IP lawsuiters had sued arguing (reasonably I think) that the output of the LLMs is strongly suggestive that they have been trained on copyrighted materials. Get the lawsuit to discovery, and those data centers become fair game.<p>No, there have been lawsuits, and the data centers have not been fair game because whether or not the models were trained on copyright-protected works is not generally in dispute. Discovery only applies to evidence relevant to facts in dispute.</div><br/></div></div><div id="42603248" class="c"><input type="checkbox" id="c-42603248" checked=""/><div class="controls bullet"><span class="by">cabalamat</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603081">parent</a><span>|</span><a href="#42603326">prev</a><span>|</span><a href="#42603636">next</a><span>|</span><label class="collapse" for="c-42603248">[-]</label><label class="expand" for="c-42603248">[5 more]</label></div><br/><div class="children"><div class="content">&gt; strongly suggestive that they have been trained on copyrighted materials<p>Given that everything -- including this comment -- is copyrighted unless it is (1) old or (2) deliberately put into the public domain, this is almost certainly true.</div><br/><div id="42603380" class="c"><input type="checkbox" id="c-42603380" checked=""/><div class="controls bullet"><span class="by">rusk</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603248">parent</a><span>|</span><a href="#42603636">next</a><span>|</span><label class="collapse" for="c-42603380">[-]</label><label class="expand" for="c-42603380">[4 more]</label></div><br/><div class="children"><div class="content">Isn’t this comment in the public domain? I presume that’s what I’m doing when I’m posting on a forum. If somebody copied and pasted something I wrote on here could I in theory use copyright law to restrict distribution? I think the law would say I published it on a public forum and thus it is in the public domain.</div><br/><div id="42603478" class="c"><input type="checkbox" id="c-42603478" checked=""/><div class="controls bullet"><span class="by">taormina</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603380">parent</a><span>|</span><a href="#42603665">next</a><span>|</span><label class="collapse" for="c-42603478">[-]</label><label class="expand" for="c-42603478">[2 more]</label></div><br/><div class="children"><div class="content">Why would it be in the public domain? Anything you create, under US copyright law, is the opposite of being in the public domain, it&#x27;s yours. According to the legalese of YC, you are granting YC and YC alone a license to use the UGC you submitted to their website, but if anything, the YC agreement DEMANDS that you own the copyright to the comment you are posting.<p>&gt; User Content Transmitted Through the Site: With respect to the content or other materials you upload through the Site or share with other users or recipients (collectively, “User Content”), you represent and warrant that you own all right, title and interest in and to such User Content, including, without limitation, all copyrights and rights of publicity contained therein. By uploading any User Content you hereby grant and will grant Y Combinator and its affiliated companies a nonexclusive, worldwide, royalty free, fully paid up, transferable, sublicensable, perpetual, irrevocable license to copy, display, upload, perform, distribute, store, modify and otherwise use your User Content for any Y Combinator-related purpose in any form, medium or technology now known or later developed. However, please review the Privacy Policy located here for more information on how we treat information included in applications submitted to us.<p>&gt; You acknowledge and agree that any questions, comments, suggestions, ideas, feedback or other information about the Site (“Submissions”) provided by you to Y Combinator are non-confidential and Y Combinator will be entitled to the unrestricted use and dissemination of these Submissions for any purpose, without acknowledgment or compensation to you.</div><br/><div id="42603719" class="c"><input type="checkbox" id="c-42603719" checked=""/><div class="controls bullet"><span class="by">ANewFormation</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603478">parent</a><span>|</span><a href="#42603665">next</a><span>|</span><label class="collapse" for="c-42603719">[-]</label><label class="expand" for="c-42603719">[1 more]</label></div><br/><div class="children"><div class="content">Another example of this is people putting code, intended to be shared, up on e.g. Github without a licence.<p>Many people seem to think that no licence = public domain, but it&#x27;s still under strong copyright protection. This is the point of things like the Unlicense license.</div><br/></div></div></div></div><div id="42603665" class="c"><input type="checkbox" id="c-42603665" checked=""/><div class="controls bullet"><span class="by">graemep</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603380">parent</a><span>|</span><a href="#42603478">prev</a><span>|</span><a href="#42603636">next</a><span>|</span><label class="collapse" for="c-42603665">[-]</label><label class="expand" for="c-42603665">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If somebody copied and pasted something I wrote on here could I in theory use copyright law to restrict distribution?<p>Yes you could, unless you agreed to forum terms that said otherwise, fair use aside. Its the same in most jurisdictions</div><br/></div></div></div></div></div></div></div></div><div id="42603636" class="c"><input type="checkbox" id="c-42603636" checked=""/><div class="controls bullet"><span class="by">mikewarot</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602790">parent</a><span>|</span><a href="#42603081">prev</a><span>|</span><a href="#42603448">next</a><span>|</span><label class="collapse" for="c-42603636">[-]</label><label class="expand" for="c-42603636">[1 more]</label></div><br/><div class="children"><div class="content">&gt;models are locked away in data centers as trade secrets<p>The architecture and the weights in a model are the secret process used to make a commercially valuable output. It makes the most sense to treat them as a trade secret, in a court of law.</div><br/></div></div></div></div><div id="42603448" class="c"><input type="checkbox" id="c-42603448" checked=""/><div class="controls bullet"><span class="by">nullc</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602255">parent</a><span>|</span><a href="#42602790">prev</a><span>|</span><a href="#42603369">next</a><span>|</span><label class="collapse" for="c-42603448">[-]</label><label class="expand" for="c-42603448">[1 more]</label></div><br/><div class="children"><div class="content">The weights are a product of a mechanical process, 5 years ago it would be generally uncontroversial that they would be not subject to copyright in the US... but &#x27;industry&#x27; has done a tremendous job of spreading confusion.</div><br/></div></div><div id="42603369" class="c"><input type="checkbox" id="c-42603369" checked=""/><div class="controls bullet"><span class="by">baryphonic</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602255">parent</a><span>|</span><a href="#42603448">prev</a><span>|</span><a href="#42602860">next</a><span>|</span><label class="collapse" for="c-42603369">[-]</label><label class="expand" for="c-42603369">[3 more]</label></div><br/><div class="children"><div class="content">Going a step further, weights, i.e. coefficients, aren&#x27;t produced by a person at all – they&#x27;re produced by machine algorithms. Because a human did not create the weights, the weights have no author. Thus they are ineligible for copyright in the first place and are in the public domain. Whether the model architecture is copyrightable is more of an open question, but I think a solid argument could be that the model architecture is simply a mathematical expression – albeit a complex one –, though Python or other source code is almost certainly copyrighted. But I imagine clean-room methods could avoid problems there, and with much less effort than most software.<p>IANAL, but I have serious doubts about the applicability of current copyright law to existing AI models. I imagine the courts will decide the same.</div><br/><div id="42603653" class="c"><input type="checkbox" id="c-42603653" checked=""/><div class="controls bullet"><span class="by">jonpo</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603369">parent</a><span>|</span><a href="#42602860">next</a><span>|</span><label class="collapse" for="c-42603653">[-]</label><label class="expand" for="c-42603653">[2 more]</label></div><br/><div class="children"><div class="content">You can say the same about compiled executable code though.</div><br/><div id="42604172" class="c"><input type="checkbox" id="c-42604172" checked=""/><div class="controls bullet"><span class="by">baryphonic</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603653">parent</a><span>|</span><a href="#42602860">next</a><span>|</span><label class="collapse" for="c-42604172">[-]</label><label class="expand" for="c-42604172">[1 more]</label></div><br/><div class="children"><div class="content">Each compiled executable has a one-to-one relation with its source code, which has an author (except for LLM code and&#x2F;or infinite monkeys). Thus compiled executables are derivative works.<p>There is an argument also that LLMs are derivative works of the training data, which I&#x27;m somewhat sympathetic to, though clearly there&#x27;s a difference and lots of ambiguity about which contributions to which weights correspond to any particular source work.<p>Again IANAL, and this is my opinion based on reading the law &amp; precedents. Consult a real copyright attorney for real advice.</div><br/></div></div></div></div></div></div><div id="42602860" class="c"><input type="checkbox" id="c-42602860" checked=""/><div class="controls bullet"><span class="by">slowmovintarget</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602255">parent</a><span>|</span><a href="#42603369">prev</a><span>|</span><a href="#42602192">next</a><span>|</span><label class="collapse" for="c-42602860">[-]</label><label class="expand" for="c-42602860">[4 more]</label></div><br/><div class="children"><div class="content">Datasets want to be free.</div><br/><div id="42603118" class="c"><input type="checkbox" id="c-42603118" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602860">parent</a><span>|</span><a href="#42603714">prev</a><span>|</span><a href="#42602192">next</a><span>|</span><label class="collapse" for="c-42603118">[-]</label><label class="expand" for="c-42603118">[2 more]</label></div><br/><div class="children"><div class="content">Just ask the owner of the data for their consent before adding to a dataset which wants to be free.</div><br/><div id="42603759" class="c"><input type="checkbox" id="c-42603759" checked=""/><div class="controls bullet"><span class="by">cle</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603118">parent</a><span>|</span><a href="#42602192">next</a><span>|</span><label class="collapse" for="c-42603759">[-]</label><label class="expand" for="c-42603759">[1 more]</label></div><br/><div class="children"><div class="content">The main disagreement is who the &quot;owner&quot; is in the first place.</div><br/></div></div></div></div></div></div></div></div><div id="42602192" class="c"><input type="checkbox" id="c-42602192" checked=""/><div class="controls bullet"><span class="by">jdietrich</span><span>|</span><a href="#42602063">parent</a><span>|</span><a href="#42602255">prev</a><span>|</span><a href="#42603233">next</a><span>|</span><label class="collapse" for="c-42602192">[-]</label><label class="expand" for="c-42602192">[21 more]</label></div><br/><div class="children"><div class="content">Circumventing a copy-prevention system without a valid exemption is a crime, even if you don&#x27;t make unlawful copies. Copyright covers the right to make copies, not the right to distribute; &quot;doing what you want with it yourself&quot; may or may not be covered by fair use. Whether or not model weights are copyrightable remains an open question.<p><a href="https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;17&#x2F;1201" rel="nofollow">https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;17&#x2F;1201</a></div><br/><div id="42602822" class="c"><input type="checkbox" id="c-42602822" checked=""/><div class="controls bullet"><span class="by">nadermx</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602192">parent</a><span>|</span><a href="#42602236">next</a><span>|</span><label class="collapse" for="c-42602822">[-]</label><label class="expand" for="c-42602822">[2 more]</label></div><br/><div class="children"><div class="content">Actually, in terms of copyright control &quot;The Federal Circuit went on to clarify the nature of the DMCA&#x27;s anti-circumvention provisions. The DMCA established causes of action for liability and did not establish a property right. Therefore, circumvention is not infringement in itself.&quot;[1]<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Chamberlain_Group,_Inc._v._Skylink_Technologies,_Inc" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Chamberlain_Group,_Inc._v._S...</a></div><br/><div id="42603330" class="c"><input type="checkbox" id="c-42603330" checked=""/><div class="controls bullet"><span class="by">bitwize</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602822">parent</a><span>|</span><a href="#42602236">next</a><span>|</span><label class="collapse" for="c-42603330">[-]</label><label class="expand" for="c-42603330">[1 more]</label></div><br/><div class="children"><div class="content">Circumvention is not infringement, but the DMCA makes it a separate crime punishable by up to 5 years in prison.</div><br/></div></div></div></div><div id="42602236" class="c"><input type="checkbox" id="c-42602236" checked=""/><div class="controls bullet"><span class="by">mcny</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602192">parent</a><span>|</span><a href="#42602822">prev</a><span>|</span><a href="#42602439">next</a><span>|</span><label class="collapse" for="c-42602236">[-]</label><label class="expand" for="c-42602236">[5 more]</label></div><br/><div class="children"><div class="content">&gt;Circumventing a copy-prevention system without a valid exemption is a crime, even if you don&#x27;t make unlawful copies. Copyright covers the right to make copies, not the right to distribute; &quot;doing what you want with it yourself&quot; may or may not be covered by fair use. Whether or not model weights are copyrightable remains an open question.<p>If that is the law, it is a defect that we need to fix. 
Laws do not come down from heaven in the form of commandments. 
We, humans, write laws. 
If there is a defect in the laws, we should fix it.<p>If this is the law, time shifting and format shifting is unlawful as well which to me is unacceptable.<p>Disclaimer: As usual, I anal.</div><br/><div id="42602813" class="c"><input type="checkbox" id="c-42602813" checked=""/><div class="controls bullet"><span class="by">dialup_sounds</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602236">parent</a><span>|</span><a href="#42602439">next</a><span>|</span><label class="collapse" for="c-42602813">[-]</label><label class="expand" for="c-42602813">[4 more]</label></div><br/><div class="children"><div class="content">Time shifting is protected by 40 years of judicial precedent establishing it as fair use.</div><br/><div id="42602848" class="c"><input type="checkbox" id="c-42602848" checked=""/><div class="controls bullet"><span class="by">nadermx</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602813">parent</a><span>|</span><a href="#42602439">next</a><span>|</span><label class="collapse" for="c-42602848">[-]</label><label class="expand" for="c-42602848">[3 more]</label></div><br/><div class="children"><div class="content">This is being tested in the courts currently, <a href="https:&#x2F;&#x2F;torrentfreak.com&#x2F;appeals-court-hears-riaa-and-yout-in-high-stakes-streamripper-case-240209&#x2F;" rel="nofollow">https:&#x2F;&#x2F;torrentfreak.com&#x2F;appeals-court-hears-riaa-and-yout-i...</a></div><br/><div id="42603831" class="c"><input type="checkbox" id="c-42603831" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602848">parent</a><span>|</span><a href="#42604568">next</a><span>|</span><label class="collapse" for="c-42603831">[-]</label><label class="expand" for="c-42603831">[1 more]</label></div><br/><div class="children"><div class="content">DMCA 1201 is written so broadly that <i>any</i> feature of a product or service can be construed to prevent copying, and thus gain 1201 protection.<p>I don&#x27;t think YouTube intended regular uploads to have DRM, if only because they support Creative Commons metadata on uploads, and Creative Commons specifically forbids the use of technical protection measures on CC-licensed content[0]. On a less moralistic note, applying encryption to all YouTube videos would be prohibitively expensive because DRM vendors charge $$$ for the tech.<p>But the RIAA wants DRM because, well, they don&#x27;t want people taking what they have rightfully stolen. So YouTube engineered a weak form of URL obfuscation that would only stop very basic scrapers[1]. DMCA 1201 doesn&#x27;t care about encryption or obfuscation, though. What it does care about is if something was <i>intended</i> to stop copying, and if so, if the defendant&#x27;s product was designed to defeat that thing.<p>There&#x27;s an interesting wrinkle in DMCA 1201 in that merely being able to defeat DRM does not make something illegal. Defeating DRM has to be the tool&#x27;s <i>only function</i>[2], or you have to advertise the tool as being able to defeat DRM[3], in order to actually violate DMCA 1201. DRM vendors <i>usually</i> resort to encryption, because it makes the circumvention tools specialized enough that they have no other purpose and thus fall afoul of DMCA 1201. But there&#x27;s nothing stopping you from using really basic schemes (ROT-13 your DVDs!) and still getting to sue for 1201.<p>Going back to the AI ripping question, this blog post is probably not in and of itself a circumvention tool[4], but anyone implementing it is very much making circumvention tools, which are illegal to distribute. Circumvention itself is also illegal, but only when there&#x27;s an underlying copyright infringement. i.e. you can&#x27;t just encrypt something that&#x27;s public domain or uncopyrightable and sue anyone who decrypts it.<p>So the next question is: is AI copyrightable? And can you sue for 1201 circumvention for something that is fundamentally composed of someone else&#x27;s copyrighted work that you don&#x27;t own and haven&#x27;t licensed?<p>[0] Additionally, there is a very large repository of CC-BY music from Kevin MacLeod that is used all over YouTube that would have to be removed or relicensed if the RIAA were to prevail on this case.<p>I have no idea if Kevin actually intends to enforce the no-DRM clause in this way, though. Kevin actually has a fairly loose interpretation of CC-BY. For example, <i>nobody</i> attributes his music correctly, either the way the license requires, or with Kevin&#x27;s (legally insufficient) recommended attribution strings. He does sell commercial (non-attribution) licenses but I&#x27;ve yet to hear of any enforcement actions from him.<p>[1] To be clear, without DRM encryption, <i>any</i> video can be ripped by hooking standard HTML5 video APIs using an extension.<p>[2] Things with &quot;limited commercial purposes&quot; beyond breaking DRM may also be construed as circumvention tools under DMCA 1201.<p>[3] My favorite example: someone tried selling a VGA-to-composite adapter as a way to copy movies off Netflix. That is illegal under DMCA 1201.<p>[4] To be clear, this is NOT settled law, this is &quot;get sued and find out if the Supreme Court likes you that day&quot; law.</div><br/></div></div><div id="42604568" class="c"><input type="checkbox" id="c-42604568" checked=""/><div class="controls bullet"><span class="by">dialup_sounds</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602848">parent</a><span>|</span><a href="#42603831">prev</a><span>|</span><a href="#42602439">next</a><span>|</span><label class="collapse" for="c-42604568">[-]</label><label class="expand" for="c-42604568">[1 more]</label></div><br/><div class="children"><div class="content">Not really. The fair use status of time shifting isn&#x27;t in question there by either party.</div><br/></div></div></div></div></div></div></div></div><div id="42602439" class="c"><input type="checkbox" id="c-42602439" checked=""/><div class="controls bullet"><span class="by">rpdillon</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602192">parent</a><span>|</span><a href="#42602236">prev</a><span>|</span><a href="#42604089">next</a><span>|</span><label class="collapse" for="c-42602439">[-]</label><label class="expand" for="c-42602439">[10 more]</label></div><br/><div class="children"><div class="content">Your comment confused me, but I&#x27;m very interested in what you&#x27;re getting at.<p>&gt; Circumventing a copy-prevention system without a valid exemption is a crime, even if you don&#x27;t make unlawful copies.<p>Yep, this is the DMCA section 1201. Late &#x27;90s law in the US.<p>&gt; Copyright covers the right to make copies, not the right to distribute<p>This is where I got confused. Copyright covers four rights: copying, distribution, creation of derivative works, and public performance.  So I&#x27;m not sure what you were getting at with the copy&#x2F;distribute dichotomy.<p>But here&#x27;s a question I&#x27;m curious about: Can DMCA apply to a copy-protection mechanism that&#x27;s being applied to non-copyrightable work?  Based on my reading of <a href="https:&#x2F;&#x2F;www.copyright.gov&#x2F;dmca&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.copyright.gov&#x2F;dmca&#x2F;</a>:<p>&gt; First, it prohibits circumventing technological protection measures (or TPMs) used by copyright owners to control access to their works.<p>That&#x27;s not the letter of the law, but an overview, but it does seem to suggest you can&#x27;t bring a DMCA 1201 claim against someone circumventing copy-protection for uncopyrightable works.<p>&gt; Whether or not model weights are copyrightable remains an open question.<p>And this is where the interaction with the wording of 1201 gets interesting, in my (non-professional) opinion!</div><br/><div id="42602937" class="c"><input type="checkbox" id="c-42602937" checked=""/><div class="controls bullet"><span class="by">lcnPylGDnU4H9OF</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602439">parent</a><span>|</span><a href="#42604089">next</a><span>|</span><label class="collapse" for="c-42602937">[-]</label><label class="expand" for="c-42602937">[9 more]</label></div><br/><div class="children"><div class="content">Here is the relevant text in the law:<p>&gt; No person shall circumvent a technological measure that effectively controls access to a work protected under this title.<p>The inclusion of “work protected under this title” makes it clear in the law, though I doubt a judge would rule otherwise without that line. (Otherwise, I’d wonder if I could claim damages that Google et al. are violating the technological measures I’ve put in place to protect the specificity of my interests, because it wouldn’t matter that such is not protected by copyright law.)<p>Also not an attorney, for what it’s worth.</div><br/><div id="42603044" class="c"><input type="checkbox" id="c-42603044" checked=""/><div class="controls bullet"><span class="by">roywiggins</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602937">parent</a><span>|</span><a href="#42604089">next</a><span>|</span><label class="collapse" for="c-42603044">[-]</label><label class="expand" for="c-42603044">[8 more]</label></div><br/><div class="children"><div class="content">It seems clear from this definition especially:<p>&gt; (A) to “circumvent a technological measure” means to descramble a scrambled work, to decrypt an encrypted work, or otherwise to avoid, bypass, remove, deactivate, or impair a technological measure, <i>without the authority of the copyright owner</i><p>In this case there <i>is</i> no copyright owner.</div><br/><div id="42603077" class="c"><input type="checkbox" id="c-42603077" checked=""/><div class="controls bullet"><span class="by">lcnPylGDnU4H9OF</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603044">parent</a><span>|</span><a href="#42604089">next</a><span>|</span><label class="collapse" for="c-42603077">[-]</label><label class="expand" for="c-42603077">[7 more]</label></div><br/><div class="children"><div class="content">Right, that’s what I was getting at with my parenthetical. Obviously the work has to have an owned copyright in order to be protected by copyright law.</div><br/><div id="42603090" class="c"><input type="checkbox" id="c-42603090" checked=""/><div class="controls bullet"><span class="by">roywiggins</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603077">parent</a><span>|</span><a href="#42603396">next</a><span>|</span><label class="collapse" for="c-42603090">[-]</label><label class="expand" for="c-42603090">[1 more]</label></div><br/><div class="children"><div class="content">sorry, yes, reread your comment and dirty-edited mine</div><br/></div></div><div id="42603396" class="c"><input type="checkbox" id="c-42603396" checked=""/><div class="controls bullet"><span class="by">rusk</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603077">parent</a><span>|</span><a href="#42603090">prev</a><span>|</span><a href="#42604089">next</a><span>|</span><label class="collapse" for="c-42603396">[-]</label><label class="expand" for="c-42603396">[5 more]</label></div><br/><div class="children"><div class="content">This is interesting. I wonder could you use it as a basis for “legally” circumventing a technology by applying it to non-copyrighted works.</div><br/><div id="42603683" class="c"><input type="checkbox" id="c-42603683" checked=""/><div class="controls bullet"><span class="by">lcnPylGDnU4H9OF</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603396">parent</a><span>|</span><a href="#42604089">next</a><span>|</span><label class="collapse" for="c-42603683">[-]</label><label class="expand" for="c-42603683">[4 more]</label></div><br/><div class="children"><div class="content">If you mean that you might be able to decrypt a copyrighted work because you used that same encryption method on a non-copyrighted work, then definitely not. The work under protection will be considered. (Otherwise, I am unsure what you meant.)</div><br/><div id="42603818" class="c"><input type="checkbox" id="c-42603818" checked=""/><div class="controls bullet"><span class="by">rusk</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603683">parent</a><span>|</span><a href="#42604089">next</a><span>|</span><label class="collapse" for="c-42603818">[-]</label><label class="expand" for="c-42603818">[3 more]</label></div><br/><div class="children"><div class="content">From what I recall, it was the actual protection method that was protected by DMCA - when DVD protection was cracked it was forbidden to distribute a particular section of code so they just printed it on a Tee-shirt to troll the powers that be.</div><br/><div id="42605218" class="c"><input type="checkbox" id="c-42605218" checked=""/><div class="controls bullet"><span class="by">lcnPylGDnU4H9OF</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603818">parent</a><span>|</span><a href="#42604975">next</a><span>|</span><label class="collapse" for="c-42605218">[-]</label><label class="expand" for="c-42605218">[1 more]</label></div><br/><div class="children"><div class="content">Presuming you are referring to this: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AACS_encryption_key_controversy" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AACS_encryption_key_controvers...</a><p>&gt; Outside the Internet and the mass media, the key has appeared in or on T-shirts, poetry, songs and music videos, illustrations and other graphic artworks, tattoos and body art, and comic strips.<p>Using the encryption key to decrypt the data on a DVD is illegal “circumvention” per DMCA 1201, if it’s done without authorization from the copyright owner of the data on the DVD. If it were really illegal to simply publish the key on a website, then printing it on clothing that they sold instead would not be a viable loophole.<p>I’m glad it is still referred to as a controversy that they were issuing cease and desist letters for publishing information when the actual crime they had in mind, which was not alleged in the letters, is using the information to decrypt a DVD.</div><br/></div></div><div id="42604975" class="c"><input type="checkbox" id="c-42604975" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42603818">parent</a><span>|</span><a href="#42605218">prev</a><span>|</span><a href="#42604089">next</a><span>|</span><label class="collapse" for="c-42604975">[-]</label><label class="expand" for="c-42604975">[1 more]</label></div><br/><div class="children"><div class="content">Better yet just print the colors that represent the number, see <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Illegal_number" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Illegal_number</a><p>But then again, knowing the number is a far cry from using that number to circumvent DRM</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="42604089" class="c"><input type="checkbox" id="c-42604089" checked=""/><div class="controls bullet"><span class="by">larodi</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602192">parent</a><span>|</span><a href="#42602439">prev</a><span>|</span><a href="#42603489">next</a><span>|</span><label class="collapse" for="c-42604089">[-]</label><label class="expand" for="c-42604089">[1 more]</label></div><br/><div class="children"><div class="content">just imagine, like just for a second how it becomes illegal to train anything that does not then afterwards produce, if publicly used or distributed, a copyright token which is both in the training set - to mark it - and in the produce - to recognize it.<p>so this is where it all goes in several years, if i were the gov.</div><br/></div></div><div id="42603470" class="c"><input type="checkbox" id="c-42603470" checked=""/><div class="controls bullet"><span class="by">BadHumans</span><span>|</span><a href="#42602063">root</a><span>|</span><a href="#42602192">parent</a><span>|</span><a href="#42603489">prev</a><span>|</span><a href="#42603233">next</a><span>|</span><label class="collapse" for="c-42603470">[-]</label><label class="expand" for="c-42603470">[1 more]</label></div><br/><div class="children"><div class="content">Is using millions of copyrighted works to train your AI a valid exemption? Asking for a few billionaire friends.</div><br/></div></div></div></div><div id="42603233" class="c"><input type="checkbox" id="c-42603233" checked=""/><div class="controls bullet"><span class="by">dragonwriter</span><span>|</span><a href="#42602063">parent</a><span>|</span><a href="#42602192">prev</a><span>|</span><a href="#42602686">next</a><span>|</span><label class="collapse" for="c-42603233">[-]</label><label class="expand" for="c-42603233">[1 more]</label></div><br/><div class="children"><div class="content">No, copyright violation occurs at the first unauthorized copying or creation of a derivative work or exercise of any of the other exclusive rights of the copyright holder (that does not fall into an exception like that for fair use.) That distribution is required for a copyright violation is a persistent myth. Distribution is a means by which a violation becomes more likely to be detected and also more likely to involve significant liability for damages.<p>(OTOH, whether models, as the output of a mechanical process,  are subject to copyright is a matter of some debate. The firms training models tend to treat the models as if they were protected by copyright but also tend to treat the source works as if copying for the purpose of training AI were within a copyright exception; why each of those positions is in their interest is obvious, but neither is well-established.)</div><br/></div></div><div id="42602686" class="c"><input type="checkbox" id="c-42602686" checked=""/><div class="controls bullet"><span class="by">rileymat2</span><span>|</span><a href="#42602063">parent</a><span>|</span><a href="#42603233">prev</a><span>|</span><a href="#42602750">next</a><span>|</span><label class="collapse" for="c-42602686">[-]</label><label class="expand" for="c-42602686">[1 more]</label></div><br/><div class="children"><div class="content">I doubt the models are copyrighted, arn’t works created by machine not eligible?  Or you get into cases autogenerating and claiming ownership of all possible musical note combinations.</div><br/></div></div><div id="42602750" class="c"><input type="checkbox" id="c-42602750" checked=""/><div class="controls bullet"><span class="by">hnlmorg</span><span>|</span><a href="#42602063">parent</a><span>|</span><a href="#42602686">prev</a><span>|</span><a href="#42602166">next</a><span>|</span><label class="collapse" for="c-42602750">[-]</label><label class="expand" for="c-42602750">[2 more]</label></div><br/><div class="children"><div class="content">It’s hard to say because as far as I know this stuff hasn’t been definitively tested on any courts that I know of. Europe not America.<p>AI models are generally regarded as a company’s asset (like a customer database would also be), and rightly so given the cost required to generate one. But that’s a different matter entirely to copyright.</div><br/></div></div><div id="42602166" class="c"><input type="checkbox" id="c-42602166" checked=""/><div class="controls bullet"><span class="by">wslh</span><span>|</span><a href="#42602063">parent</a><span>|</span><a href="#42602750">prev</a><span>|</span><a href="#42604061">next</a><span>|</span><label class="collapse" for="c-42602166">[-]</label><label class="expand" for="c-42602166">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s also worth noting that there is still no legal clarity on these issues, even if a license claims to provide specific permissions.<p>Additionally, the debate around the sources companies use to train their models remains unresolved, raising ethical and legal questions about data ownership and consent.</div><br/></div></div><div id="42604061" class="c"><input type="checkbox" id="c-42604061" checked=""/><div class="controls bullet"><span class="by">larodi</span><span>|</span><a href="#42602063">parent</a><span>|</span><a href="#42602166">prev</a><span>|</span><a href="#42604251">next</a><span>|</span><label class="collapse" for="c-42604061">[-]</label><label class="expand" for="c-42604061">[1 more]</label></div><br/><div class="children"><div class="content">its insane to state it tbh</div><br/></div></div></div></div><div id="42602494" class="c"><input type="checkbox" id="c-42602494" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#42605221">prev</a><span>|</span><label class="collapse" for="c-42602494">[-]</label><label class="expand" for="c-42602494">[1 more]</label></div><br/><div class="children"><div class="content">&gt; hoarding data<p>Laundering IP. FTFY.</div><br/></div></div></div></div></div></div></div></body></html>