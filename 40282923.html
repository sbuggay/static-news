<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1715158874819" as="style"/><link rel="stylesheet" href="styles.css?v=1715158874819"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/lilipads/gradient_descent_viz">Gradient descent visualization</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>weinzierl</span> | <span>32 comments</span></div><br/><div><div id="40290512" class="c"><input type="checkbox" id="c-40290512" checked=""/><div class="controls bullet"><span class="by">levocardia</span><span>|</span><a href="#40288072">next</a><span>|</span><label class="collapse" for="c-40290512">[-]</label><label class="expand" for="c-40290512">[14 more]</label></div><br/><div class="children"><div class="content">These are nice animations. However I&#x27;ve always hesitated to get too enamored with these simple 2D visualizations of gradient descent, because one of the strange takeaways from deep learning is that behavior in high dimensions is very different from behavior in low dimensions.<p>In a 2D problem with many local minima, like the &quot;eggholder functions&quot; [1], gradient descent will be hopeless. But neural net optimization in high dimensions really is a similar situation with many local minima, except gradient descent does great.<p>Gradient descent in high dimensions also seems to have the ability to &quot;step over&quot; areas of high loss, which you can see by looking at the loss of a linear interpolation between weights at successive steps of gradient descent. This, again, seems like extremely strange behavior with no low-dimensional analogue.<p>[1] <a href="https:&#x2F;&#x2F;www.sfu.ca&#x2F;~ssurjano&#x2F;egg.html" rel="nofollow">https:&#x2F;&#x2F;www.sfu.ca&#x2F;~ssurjano&#x2F;egg.html</a></div><br/><div id="40291622" class="c"><input type="checkbox" id="c-40291622" checked=""/><div class="controls bullet"><span class="by">huevosabio</span><span>|</span><a href="#40290512">parent</a><span>|</span><a href="#40295418">next</a><span>|</span><label class="collapse" for="c-40291622">[-]</label><label class="expand" for="c-40291622">[2 more]</label></div><br/><div class="children"><div class="content">My understanding of this phenomenon in DL is that its not due to anything intrinsic to gradient descent, the same principles and understanding apply.<p>Rather, it is that with very large dimensionality the probability that you spuriously get all derivatives to be zero is vanishingly small. That is, local minima are less likely because you need a lot of dimensions to agree that df(x_i)&#x2F;dx_i = 0.<p>I may be wrong though!</div><br/><div id="40292095" class="c"><input type="checkbox" id="c-40292095" checked=""/><div class="controls bullet"><span class="by">dxbydt</span><span>|</span><a href="#40290512">root</a><span>|</span><a href="#40291622">parent</a><span>|</span><a href="#40295418">next</a><span>|</span><label class="collapse" for="c-40292095">[-]</label><label class="expand" for="c-40292095">[1 more]</label></div><br/><div class="children"><div class="content">if the probability that you get a derivative close to 0 is small, say only 10%, then you need just 3 dimensions to get that multiplicative probability equal to a tenth of a percent. 3 is hardly “very large dimensionality”<p>you can assign different numbers, but still you will find you don’t need more than say 10 dimensions for this effect to happen.</div><br/></div></div></div></div><div id="40295418" class="c"><input type="checkbox" id="c-40295418" checked=""/><div class="controls bullet"><span class="by">Grimblewald</span><span>|</span><a href="#40290512">parent</a><span>|</span><a href="#40291622">prev</a><span>|</span><a href="#40295491">next</a><span>|</span><label class="collapse" for="c-40295418">[-]</label><label class="expand" for="c-40295418">[1 more]</label></div><br/><div class="children"><div class="content">Not super strange if you think of it going the other way. Think of a saddle like construct, in one dimension you get stuck easily, in another tgere is a way forward where over time the other previously &#x27;stuck&#x27; dimension is freed up again. In higher dimensions you have a much higher chance of havibg such alternative pathways. During training this looks lime breif plateaus in loss reduction followed by a sudden rapid decrease again. Sorry for typos, bumpy train, fix one get another, will try edit later.</div><br/></div></div><div id="40295491" class="c"><input type="checkbox" id="c-40295491" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40290512">parent</a><span>|</span><a href="#40295418">prev</a><span>|</span><a href="#40290748">next</a><span>|</span><label class="collapse" for="c-40295491">[-]</label><label class="expand" for="c-40295491">[1 more]</label></div><br/><div class="children"><div class="content">&gt;behavior in high dimensions is very different from behavior in low dimensions<p>Keeping that in mind it is still useful. Maybe one useful addition would be to reduce dimensionality to show that if we pick some dimensions we don&#x27;t have a local minimum, hence we don&#x27;t have a local minimum in the larger dimension we started with.</div><br/></div></div><div id="40290748" class="c"><input type="checkbox" id="c-40290748" checked=""/><div class="controls bullet"><span class="by">cafaxo</span><span>|</span><a href="#40290512">parent</a><span>|</span><a href="#40295491">prev</a><span>|</span><a href="#40294530">next</a><span>|</span><label class="collapse" for="c-40290748">[-]</label><label class="expand" for="c-40290748">[7 more]</label></div><br/><div class="children"><div class="content">Does gradient descent really do well for deep learning when the gradient is computed with respect to the whole dataset? I assumed that the noise in SGD played an important role for escaping local minima.</div><br/><div id="40291797" class="c"><input type="checkbox" id="c-40291797" checked=""/><div class="controls bullet"><span class="by">cameldrv</span><span>|</span><a href="#40290512">root</a><span>|</span><a href="#40290748">parent</a><span>|</span><a href="#40294530">next</a><span>|</span><label class="collapse" for="c-40291797">[-]</label><label class="expand" for="c-40291797">[6 more]</label></div><br/><div class="children"><div class="content">There aren&#x27;t really local minima in most deep networks.  When you get into millions&#x2F;billions of parameters, there will essentially always be some directions that point downwards.  You have to get really really close to the true minimum for there to be no direction to go that improves the loss.<p>Incidentally this same phenomenon is IMO how evolution is able to build things like the eye.  Naively you&#x27;d think that since you need so many parts arranged so well, it&#x27;s impossible to find a step by step path where fitness goes up at every step, i.e. if you just have a retina with no lens or vice-versa, it doesn&#x27;t work.  However, due to the high dimensionality of DNA, there is essentially guaranteed to be a path with monotonically increasing fitness just because there are so many different possible paths from A to B in the high dimensional space that at least one is bound to work.<p>Now this isn&#x27;t strictly true for every high dimensional system.  You need to have a degree of symmetry or redundancy in the encoding for it to work.  For example, in convolutional neural networks, you see this phenomenon where some filters get &quot;stuck&quot; in training, and those are local minima for that subspace.  What happens though is that if one filter gets stuck, the network will just use another one that had a better initialization.  This is why pruning works, lottery tickets, etc.  Things like residual connections enhance this effect since you can even be stuck in a whole layer and the training process can just bypass it.<p>You see the same thing with life, where you could put a sequence for the same protein in different parts of the genome and it could still be produced, regardless of the position.  There are also many different ways to encode the exact same protein, and many different possible proteins that will have the same shape in the critical areas.  Life finds a way.</div><br/><div id="40293122" class="c"><input type="checkbox" id="c-40293122" checked=""/><div class="controls bullet"><span class="by">whatever1</span><span>|</span><a href="#40290512">root</a><span>|</span><a href="#40291797">parent</a><span>|</span><a href="#40292034">next</a><span>|</span><label class="collapse" for="c-40293122">[-]</label><label class="expand" for="c-40293122">[3 more]</label></div><br/><div class="children"><div class="content">If that was the case we would be finding globally optimal solutions for complicated non-convex optimization problems.<p>The reality is different, you need to really explore the space to find the truly global optimal solution.<p>A better explanation is that for ml you don&#x27;t want a globally optimal solution that overindexes on your training set. You want a suboptimal solution that might also fit an unseen data set.</div><br/><div id="40293655" class="c"><input type="checkbox" id="c-40293655" checked=""/><div class="controls bullet"><span class="by">blt</span><span>|</span><a href="#40290512">root</a><span>|</span><a href="#40293122">parent</a><span>|</span><a href="#40292034">next</a><span>|</span><label class="collapse" for="c-40293655">[-]</label><label class="expand" for="c-40293655">[2 more]</label></div><br/><div class="children"><div class="content">That is what people thought until around 2018, but it was wrong. It turns out that deep learning optimization problems have many global optima. In fact, when the #parameters exceeds the #data, SGD reliably finds parameters that interpolate the training data with 0 loss. Surprisingly, most of these generalize well and overfitting is not a big problem.<p>In other words, deep learning is a very special nonconvex optimization problem. A lot of our old intuition about optimization for ML is invalid in the overparameterized regime.</div><br/><div id="40293972" class="c"><input type="checkbox" id="c-40293972" checked=""/><div class="controls bullet"><span class="by">patrick451</span><span>|</span><a href="#40290512">root</a><span>|</span><a href="#40293655">parent</a><span>|</span><a href="#40292034">next</a><span>|</span><label class="collapse" for="c-40293972">[-]</label><label class="expand" for="c-40293972">[1 more]</label></div><br/><div class="children"><div class="content">I have read this in several places and want to learn more. Do you have a reference handy?</div><br/></div></div></div></div></div></div><div id="40292034" class="c"><input type="checkbox" id="c-40292034" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#40290512">root</a><span>|</span><a href="#40291797">parent</a><span>|</span><a href="#40293122">prev</a><span>|</span><a href="#40294530">next</a><span>|</span><label class="collapse" for="c-40292034">[-]</label><label class="expand" for="c-40292034">[2 more]</label></div><br/><div class="children"><div class="content">&gt; There aren&#x27;t really local minima in most deep networks.<p>How so?<p>If there are no local minima other than the global one there are convex optimization methods that are far faster than SGD or Adam. The only reason these methods exist is because deep networks is a non-convex optimization problem.</div><br/><div id="40292280" class="c"><input type="checkbox" id="c-40292280" checked=""/><div class="controls bullet"><span class="by">aaplok</span><span>|</span><a href="#40290512">root</a><span>|</span><a href="#40292034">parent</a><span>|</span><a href="#40294530">next</a><span>|</span><label class="collapse" for="c-40292280">[-]</label><label class="expand" for="c-40292280">[1 more]</label></div><br/><div class="children"><div class="content">There are many nonconvex functions where every local minimum is global, and even many nonconvex functions with a unique local minimum (which is de facto global). Convex methods can fail on those.<p>The reason why GD and friends are a good choice in deep learning is that computing the gradient is cheap (and approximating it even more so). Every descent method relies on solving a subproblem of sorts, typically projecting the current iterate on a sublevel set of an approximation of the function, for some definition of projection. With GD, it&#x27;s as cheap as it gets, just subtract a shrinked version of the gradient. Subproblems in other algorithms are a lot more expensive computationally, particularly at high dimensions. So more efficient as in requiring fewer function evaluations, yes, but at the cost of doing a lot more work at each step.</div><br/></div></div></div></div></div></div></div></div><div id="40294530" class="c"><input type="checkbox" id="c-40294530" checked=""/><div class="controls bullet"><span class="by">epipolar</span><span>|</span><a href="#40290512">parent</a><span>|</span><a href="#40290748">prev</a><span>|</span><a href="#40293568">next</a><span>|</span><label class="collapse" for="c-40294530">[-]</label><label class="expand" for="c-40294530">[1 more]</label></div><br/><div class="children"><div class="content">Might I suggest an insightful seminar for anyone curious about why gradient descent is even tractable in such high dimensions:<p>Stanford Seminar - A Picture of the Prediction Space of Deep Networks by  Pratik Chadhari:<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;ZD2cL-QoI5g?si=hVFU5_4CeoLYtyuB" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;ZD2cL-QoI5g?si=hVFU5_4CeoLYtyuB</a></div><br/></div></div><div id="40293568" class="c"><input type="checkbox" id="c-40293568" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#40290512">parent</a><span>|</span><a href="#40294530">prev</a><span>|</span><a href="#40288072">next</a><span>|</span><label class="collapse" for="c-40293568">[-]</label><label class="expand" for="c-40293568">[1 more]</label></div><br/><div class="children"><div class="content">Behavior in high dimensions is even weirder than you might think, because you&#x27;re nearly always close to a saddle point. There&#x27;s way more saddle points than minima or maxima (consider modeling the sign of eigenvalues for the Jacobian as a binomial distribution -- how likely is it they&#x27;re all positive or all negative?).<p>However usually only a relatively small subset of dimensions are important (read: represent a stable optimum), see the &#x27;lottery ticket&#x27; hypothesis for more.<p>What&#x27;s also weird is that &quot;convergence&quot; in these cases isn&#x27;t really convergence, it&#x27;s just slowly floating between saddle points as you begin to overfit. Hence early stopping.<p>&gt; Gradient descent in high dimensions also seems to have the ability to &quot;step over&quot; areas of high loss<p>This has much less to do with gradients per se and way more to do with step size. It&#x27;s an artifact of discretization, not of the algorithm per se.</div><br/></div></div></div></div><div id="40288072" class="c"><input type="checkbox" id="c-40288072" checked=""/><div class="controls bullet"><span class="by">albertzeyer</span><span>|</span><a href="#40290512">prev</a><span>|</span><a href="#40285011">next</a><span>|</span><label class="collapse" for="c-40288072">[-]</label><label class="expand" for="c-40288072">[10 more]</label></div><br/><div class="children"><div class="content">Note that such a 2D parameter space gives often the wrong intuition when thinking about applying gradient descent on high-dimensional parameter space.<p>Also, mini-batch stochastic gradient descent behaves more stochastic than just gradient descent.</div><br/><div id="40288278" class="c"><input type="checkbox" id="c-40288278" checked=""/><div class="controls bullet"><span class="by">GrantMoyer</span><span>|</span><a href="#40288072">parent</a><span>|</span><a href="#40288981">next</a><span>|</span><label class="collapse" for="c-40288278">[-]</label><label class="expand" for="c-40288278">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, but I still think this is a useful tool for building intuition about a subset of problems gradient descent faces. The animation in the readme is similar to what I picture in my head for local minima for instance.</div><br/></div></div><div id="40288981" class="c"><input type="checkbox" id="c-40288981" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#40288072">parent</a><span>|</span><a href="#40288278">prev</a><span>|</span><a href="#40289621">next</a><span>|</span><label class="collapse" for="c-40288981">[-]</label><label class="expand" for="c-40288981">[3 more]</label></div><br/><div class="children"><div class="content">&gt;gives often the wrong intuition when thinking about applying gradient descent on high-dimensional parameter space<p>Can you give some examples?</div><br/><div id="40291311" class="c"><input type="checkbox" id="c-40291311" checked=""/><div class="controls bullet"><span class="by">euW3EeBe</span><span>|</span><a href="#40288072">root</a><span>|</span><a href="#40288981">parent</a><span>|</span><a href="#40295453">next</a><span>|</span><label class="collapse" for="c-40291311">[-]</label><label class="expand" for="c-40291311">[1 more]</label></div><br/><div class="children"><div class="content">Not an expert in this field, but I&#x27;m guessing this is related to unintuitive nature of geometry in high-dimensional spaces.<p>One rough example I can think of is the fact that the number of ways to move away from the origin increases exponentially (or even faster?) as the dimensionality goes up. There is _way_ more volume away from the origin than near it, I&#x27;ve seen this explained as something like &quot;most of the volume of a high-dimensional orange is in the peel&quot;. One result of this is the fact that samples of a standard gaussian end up forming a &quot;shell&quot; as opposed to a &quot;ball&quot; that you would expect (this phenomenon is called the concentration of measure in general).<p>Also, very roughly, high-dimensional objects have lots of corners, and these corners are also very sharp. I would guess that gradient descent would get stuck in these corners and have a hard time getting out.<p>Some links related to this:<p>- Spikey Spheres: <a href="http:&#x2F;&#x2F;www.penzba.co.uk&#x2F;cgi-bin&#x2F;PvsNP.py?SpikeySpheres#HN2" rel="nofollow">http:&#x2F;&#x2F;www.penzba.co.uk&#x2F;cgi-bin&#x2F;PvsNP.py?SpikeySpheres#HN2</a><p>- Thinking outside the 10-dimensional box - 3blue1brown: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=zwAD6dRSVyI" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=zwAD6dRSVyI</a><p>- This is a fairly long talk about HMC, but it does talk about some problems that come up when sampling high-dimensional distributions: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=pHsuIaPbNbY" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=pHsuIaPbNbY</a></div><br/></div></div><div id="40295453" class="c"><input type="checkbox" id="c-40295453" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#40288072">root</a><span>|</span><a href="#40288981">parent</a><span>|</span><a href="#40291311">prev</a><span>|</span><a href="#40289621">next</a><span>|</span><label class="collapse" for="c-40295453">[-]</label><label class="expand" for="c-40295453">[1 more]</label></div><br/><div class="children"><div class="content">Probably there are very few local minimums since the chances of all local derivatives to be 0 decrease with the number of dimensions.</div><br/></div></div></div></div><div id="40289621" class="c"><input type="checkbox" id="c-40289621" checked=""/><div class="controls bullet"><span class="by">dukeofdoom</span><span>|</span><a href="#40288072">parent</a><span>|</span><a href="#40288981">prev</a><span>|</span><a href="#40285011">next</a><span>|</span><label class="collapse" for="c-40289621">[-]</label><label class="expand" for="c-40289621">[5 more]</label></div><br/><div class="children"><div class="content">I vaguely remember something like this explained in one of my math classes 
(calculus or linear equations). Not sure if the math teacher was referring the same problem:<p>If you were walking down a mountain following an algorithm that told you just to keep going down. You might get stuck in a local minimum. Since you might reach a valley. Sometimes you need to go up to get out of the valley to keep going down.</div><br/><div id="40289750" class="c"><input type="checkbox" id="c-40289750" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#40288072">root</a><span>|</span><a href="#40289621">parent</a><span>|</span><a href="#40289652">next</a><span>|</span><label class="collapse" for="c-40289750">[-]</label><label class="expand" for="c-40289750">[3 more]</label></div><br/><div class="children"><div class="content">In very high dimensional spaces (like trying to optimize a neural network with billions of parameters), to be &quot;in a valley&quot;, you must be in a valley with respect to every one of the billions of dimensions. It turns out that in many practical settings, loss landscapes are pretty well-behaved in this regard, and you can almost always find some direction to continue going downward in that lets you go around the next hill rather than over it.<p>This 2015 paper has some good examples (although it does sort of sweep some issues under the rug): <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1412.6544" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1412.6544</a></div><br/><div id="40293661" class="c"><input type="checkbox" id="c-40293661" checked=""/><div class="controls bullet"><span class="by">jonathan_landy</span><span>|</span><a href="#40288072">root</a><span>|</span><a href="#40289750">parent</a><span>|</span><a href="#40289652">next</a><span>|</span><label class="collapse" for="c-40293661">[-]</label><label class="expand" for="c-40293661">[2 more]</label></div><br/><div class="children"><div class="content">Is the claim that there aren’t local many local minima for high dimensional problems eg in neural network loss functions?</div><br/><div id="40294100" class="c"><input type="checkbox" id="c-40294100" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#40288072">root</a><span>|</span><a href="#40293661">parent</a><span>|</span><a href="#40289652">next</a><span>|</span><label class="collapse" for="c-40294100">[-]</label><label class="expand" for="c-40294100">[1 more]</label></div><br/><div class="children"><div class="content">Yes. To be more specific, it&#x27;s that nearly all points where the derivative is zero are saddle points rather than minima. Note that some portion of this nice behavior seems to be due to design choices in modern architectures, like residual connections, rather than being a general fact about all high dimensional problems.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1712.09913" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1712.09913</a> This paper has some nice visualizations.</div><br/></div></div></div></div></div></div><div id="40289652" class="c"><input type="checkbox" id="c-40289652" checked=""/><div class="controls bullet"><span class="by">Feathercrown</span><span>|</span><a href="#40288072">root</a><span>|</span><a href="#40289621">parent</a><span>|</span><a href="#40289750">prev</a><span>|</span><a href="#40285011">next</a><span>|</span><label class="collapse" for="c-40289652">[-]</label><label class="expand" for="c-40289652">[1 more]</label></div><br/><div class="children"><div class="content">When I took an ML class we solved that with a temperature parameter, to allow random deviations out of a local minimum. I wonder if there are novel methods now or if they&#x27;re just improved versions of temperature?</div><br/></div></div></div></div></div></div><div id="40285011" class="c"><input type="checkbox" id="c-40285011" checked=""/><div class="controls bullet"><span class="by">DrNosferatu</span><span>|</span><a href="#40288072">prev</a><span>|</span><a href="#40289264">next</a><span>|</span><label class="collapse" for="c-40285011">[-]</label><label class="expand" for="c-40285011">[1 more]</label></div><br/><div class="children"><div class="content">Looks great!<p>Killer feature: allow arbitrary surfaces to be used (choice of 2D projection if in higher dimensions). And integrate in Python to allow use in production! Allow arbitrary zoom and level of detail of surface.</div><br/></div></div><div id="40289264" class="c"><input type="checkbox" id="c-40289264" checked=""/><div class="controls bullet"><span class="by">GistNoesis</span><span>|</span><a href="#40285011">prev</a><span>|</span><a href="#40291333">next</a><span>|</span><label class="collapse" for="c-40289264">[-]</label><label class="expand" for="c-40289264">[1 more]</label></div><br/><div class="children"><div class="content">Here is a project I created for myself (some time ago) to help visualize the gradient as a vector field.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;GistNoesis&#x2F;VisualizeGradient">https:&#x2F;&#x2F;github.com&#x2F;GistNoesis&#x2F;VisualizeGradient</a><p>Probably best used as a support material with someone teaching along the way the right mental picture one should have.<p>A great exercise is to have the student (or yourself) draw this visualization with pen and paper, (both in 2d and 3d), for various functions. And you can make the connection to the usual &quot;tangent&quot; on the curve of a derivative.</div><br/></div></div><div id="40291333" class="c"><input type="checkbox" id="c-40291333" checked=""/><div class="controls bullet"><span class="by">j_bum</span><span>|</span><a href="#40289264">prev</a><span>|</span><a href="#40292621">next</a><span>|</span><label class="collapse" for="c-40291333">[-]</label><label class="expand" for="c-40291333">[1 more]</label></div><br/><div class="children"><div class="content">I love creating things to solidify my intuition about topics. When I learned about gradient descent, I saw this repo and was inspired to create my own toy Python package for visualizing gradient descent.<p>My package, which uses PyVista for visualization:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;JacobBumgarner&#x2F;grad-descent-visualizer">https:&#x2F;&#x2F;github.com&#x2F;JacobBumgarner&#x2F;grad-descent-visualizer</a></div><br/></div></div><div id="40292621" class="c"><input type="checkbox" id="c-40292621" checked=""/><div class="controls bullet"><span class="by">umvi</span><span>|</span><a href="#40291333">prev</a><span>|</span><a href="#40290317">next</a><span>|</span><label class="collapse" for="c-40292621">[-]</label><label class="expand" for="c-40292621">[1 more]</label></div><br/><div class="children"><div class="content">I thought gradient descent always followed the steepest slope, this looks like a physics simulation where marbles are rolling down hills. In mathematical gradient descent do you really oscillate around the minimum like a marble rocking back and forth in a pit?<p>Edit: Oh, I see. The animations are &quot;momentum&quot; gradient descent</div><br/></div></div><div id="40290317" class="c"><input type="checkbox" id="c-40290317" checked=""/><div class="controls bullet"><span class="by">can16358p</span><span>|</span><a href="#40292621">prev</a><span>|</span><a href="#40289020">next</a><span>|</span><label class="collapse" for="c-40290317">[-]</label><label class="expand" for="c-40290317">[1 more]</label></div><br/><div class="children"><div class="content">As a extremely visual thinker&#x2F;learner, thank you for creating this!<p>Many things that were too abstract on paper and formulas are MUCH easier to understand this way.</div><br/></div></div><div id="40289020" class="c"><input type="checkbox" id="c-40289020" checked=""/><div class="controls bullet"><span class="by">alok-g</span><span>|</span><a href="#40290317">prev</a><span>|</span><label class="collapse" for="c-40289020">[-]</label><label class="expand" for="c-40289020">[2 more]</label></div><br/><div class="children"><div class="content">This is great!<p>Which open source license is this under?  (Absence of license by default implies &#x27;copyrighted&#x27;, which in this case could be in conflict with the Qt open source license.  Note:  I am not a lawyer.)</div><br/></div></div></div></div></div></div></div></body></html>