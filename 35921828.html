<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1683968448910" as="style"/><link rel="stylesheet" href="styles.css?v=1683968448910"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.koehntopp.info/2023/05/12/50-years-in-filesystems-1994.html">The SGI XFS Filesystem</a> <span class="domain">(<a href="https://blog.koehntopp.info">blog.koehntopp.info</a>)</span></div><div class="subtext"><span>ecliptik</span> | <span>10 comments</span></div><br/><div><div id="35923232" class="c"><input type="checkbox" id="c-35923232" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#35922794">next</a><span>|</span><label class="collapse" for="c-35923232">[-]</label><label class="expand" for="c-35923232">[1 more]</label></div><br/><div class="children"><div class="content">One thing I have long been suspicious of, but never swept out the parameter space to know for sure, is how one should set sunit, swidth, agcount or agsize to exploit the parallelism of an SSD and modern CPU. Used to be that sunit, swidth, and agsize were critical for RAIDs because getting them wrong would mean weird stripe misalignment, and if you did not set agsize all of your metadata load would be on a subset of the array. These days an SSD has way more natural parallelism than any RAID ever had, and we have more CPU cores than ever. Are we supposed to be setting sunit, swidth, and agsize? Or does the flash translation mean it doesn&#x27;t matter? And how best to mkfs.xfs when your SSD offers LBA sizes other than 512?</div><br/></div></div><div id="35922794" class="c"><input type="checkbox" id="c-35922794" checked=""/><div class="controls bullet"><span class="by">DiabloD3</span><span>|</span><a href="#35923232">prev</a><span>|</span><a href="#35923217">next</a><span>|</span><label class="collapse" for="c-35922794">[-]</label><label class="expand" for="c-35922794">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a fan of XFS. I&#x27;ve used it for over a decade for all systems that don&#x27;t need ZFS.<p>In fact, due to the lifespan of the headless box under my desk (ie, predates bootable ZFS root partitions under Linux), its root partition is still XFS, while the actual real storage is ZFS managed</div><br/></div></div><div id="35923217" class="c"><input type="checkbox" id="c-35923217" checked=""/><div class="controls bullet"><span class="by">wazoox</span><span>|</span><a href="#35922794">prev</a><span>|</span><a href="#35922740">next</a><span>|</span><label class="collapse" for="c-35923217">[-]</label><label class="expand" for="c-35923217">[1 more]</label></div><br/><div class="children"><div class="content">XFS is incredibly robust. I manage many petabytes of XFS machines. Some have XFS volumes in the 2 PiB range. And it&#x27;s also extremely fast. And I remember when I created my first folder with several billion files and it just worked :)</div><br/></div></div><div id="35922740" class="c"><input type="checkbox" id="c-35922740" checked=""/><div class="controls bullet"><span class="by">miohtama</span><span>|</span><a href="#35923217">prev</a><span>|</span><a href="#35922877">next</a><span>|</span><label class="collapse" for="c-35922740">[-]</label><label class="expand" for="c-35922740">[1 more]</label></div><br/><div class="children"><div class="content">Does XFS offer benefits or tradeoffs of ZFS&#x2F;ext4&#x2F;others today?<p>I have been using it with Linux since early 2000. But I am not sure how the file-system development has been lately e.g. with the SSD revolution.</div><br/></div></div><div id="35922877" class="c"><input type="checkbox" id="c-35922877" checked=""/><div class="controls bullet"><span class="by">bombcar</span><span>|</span><a href="#35922740">prev</a><span>|</span><a href="#35924258">next</a><span>|</span><label class="collapse" for="c-35922877">[-]</label><label class="expand" for="c-35922877">[1 more]</label></div><br/><div class="children"><div class="content">XFS was the first time I felt i had a “real” file system on Linux, ext2 being long in the fsck and reiserfs doing strange things with tail packing.</div><br/></div></div><div id="35924258" class="c"><input type="checkbox" id="c-35924258" checked=""/><div class="controls bullet"><span class="by">donatj</span><span>|</span><a href="#35922877">prev</a><span>|</span><a href="#35924116">next</a><span>|</span><label class="collapse" for="c-35924258">[-]</label><label class="expand" for="c-35924258">[1 more]</label></div><br/><div class="children"><div class="content">We use XFS for an internal queue because it handles large numbers of files (millions - billions) better than basically anything else we&#x27;ve tried.</div><br/></div></div><div id="35924116" class="c"><input type="checkbox" id="c-35924116" checked=""/><div class="controls bullet"><span class="by">codetrotter</span><span>|</span><a href="#35924258">prev</a><span>|</span><a href="#35924010">next</a><span>|</span><label class="collapse" for="c-35924116">[-]</label><label class="expand" for="c-35924116">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is part 3 of a series. The first part is “1974 ”. The second part is “1984 ”.<p>&gt; In 1994, the paper Scalability in the XFS File System saw publication. Computers got faster since 1984, and so did storages.<p>Crossing my fingers that either 2004 or 2014 will be about ZFS.<p>In 2013, OpenZFS was founded to coordinate the development of open source ZFS.</div><br/></div></div><div id="35924010" class="c"><input type="checkbox" id="c-35924010" checked=""/><div class="controls bullet"><span class="by">Paul-Craft</span><span>|</span><a href="#35924116">prev</a><span>|</span><a href="#35924279">next</a><span>|</span><label class="collapse" for="c-35924010">[-]</label><label class="expand" for="c-35924010">[1 more]</label></div><br/><div class="children"><div class="content">While we&#x27;re on filesystems, what would be the better choice for a home NAS array with, say, 10-20 individual drives and, say, ~2-300 TB raw storage: ZFS or btrfs?  Let&#x27;s assume that all drives in the array are connected via a common SAS or SATA 3 backplane and that the array is on a local network with at least 1Gbps speed.<p>Is there any other fs that would even merit consideration at this point?<p>How does the inclusion of SSDs as cache drives for the array modify this?<p>Does any of this change if we specify 10Gbps LAN?</div><br/></div></div><div id="35924279" class="c"><input type="checkbox" id="c-35924279" checked=""/><div class="controls bullet"><span class="by">johnea</span><span>|</span><a href="#35924010">prev</a><span>|</span><label class="collapse" for="c-35924279">[-]</label><label class="expand" for="c-35924279">[1 more]</label></div><br/><div class="children"><div class="content">Bloatware since 1994...</div><br/></div></div></div></div></div></div></div></body></html>