<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1729242071367" as="style"/><link rel="stylesheet" href="styles.css?v=1729242071367"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/google-deepmind/searchless_chess">Grandmaster-level chess without search</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>lawrenceyan</span> | <span>79 comments</span></div><br/><div><div id="41874291" class="c"><input type="checkbox" id="c-41874291" checked=""/><div class="controls bullet"><span class="by">tzs</span><span>|</span><a href="#41873501">next</a><span>|</span><label class="collapse" for="c-41874291">[-]</label><label class="expand" for="c-41874291">[23 more]</label></div><br/><div class="children"><div class="content">OT: what&#x27;s the state of the art in non-GM level computer chess?<p>Say I want to play chess with an opponent that is at about the same skill level as me, or perhaps I want to play with an opponent about 100 rating points above me for training.<p>Most engines let you dumb them down by cutting search depth, but that usually doesn&#x27;t work well. Sure, you end up beating them about half the time if you cut the search down enough but it generally feels like they were still outplaying you for much of the game and you won because they made one or two blunders.<p>What I want is a computer opponent that plays at a level of my choosing but plays a game that feels like that of a typical human player of that level.<p>Are there such engines?</div><br/><div id="41874461" class="c"><input type="checkbox" id="c-41874461" checked=""/><div class="controls bullet"><span class="by">rococode</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41875558">next</a><span>|</span><label class="collapse" for="c-41874461">[-]</label><label class="expand" for="c-41874461">[2 more]</label></div><br/><div class="children"><div class="content">Maia does this reasonably well! You can play against it on Lichess. I have gotten a few &quot;feels like a human&quot; moments when playing against it - for example, getting it to fall into a trap that could trick a human but would easily be seen by a traditional search algorithm. It&#x27;s not adjustable but there are a few different versions with different ratings (although it&#x27;s not a very wide range).<p><a href="https:&#x2F;&#x2F;www.maiachess.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.maiachess.com&#x2F;</a><p><a href="https:&#x2F;&#x2F;lichess.org&#x2F;@&#x2F;maia1" rel="nofollow">https:&#x2F;&#x2F;lichess.org&#x2F;@&#x2F;maia1</a></div><br/><div id="41875507" class="c"><input type="checkbox" id="c-41875507" checked=""/><div class="controls bullet"><span class="by">plaguuuuuu</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41874461">parent</a><span>|</span><a href="#41875558">next</a><span>|</span><label class="collapse" for="c-41875507">[-]</label><label class="expand" for="c-41875507">[1 more]</label></div><br/><div class="children"><div class="content">Piggy-backing off this - does anyone know of a quick way to evaluate the maia weights from python or js for a single board state? I&#x27;m trying to hack something together with my own search func intended for human play and I can&#x27;t quite figure it out from the cpp in Lc0.</div><br/></div></div></div></div><div id="41875558" class="c"><input type="checkbox" id="c-41875558" checked=""/><div class="controls bullet"><span class="by">salamo</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41874461">prev</a><span>|</span><a href="#41877326">next</a><span>|</span><label class="collapse" for="c-41875558">[-]</label><label class="expand" for="c-41875558">[3 more]</label></div><br/><div class="children"><div class="content">I built something like this. It works as long as you&#x27;re not too high-rated: chessmate.ai. Once players get higher rated it is more difficult to predict their moves because you need to model their search process, not just their intuitive move choice. It&#x27;s also possible to train on one player&#x27;s games only so that it is more personalized.<p>It uses a similar approach to Maia but with a different neural network, so it had a bit better move matching performance. And on top of that it has an expectation maximization algorithm so that the bot will try to exploit your mistakes.</div><br/><div id="41876397" class="c"><input type="checkbox" id="c-41876397" checked=""/><div class="controls bullet"><span class="by">primitivesuave</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41875558">parent</a><span>|</span><a href="#41877326">next</a><span>|</span><label class="collapse" for="c-41876397">[-]</label><label class="expand" for="c-41876397">[2 more]</label></div><br/><div class="children"><div class="content">Really nice work! The tabs other than &quot;play&quot; don&#x27;t seem to be working, but I was able to try some novelty openings and it certainly felt like it was responding with human moves. It would be great to have the ability to go back&#x2F;forth moves to try out different variations.<p>I&#x27;m curious how you combined Stockfish with your own model - but no worries if you&#x27;re keeping the secret sauce a secret. All the best to you in building out this app!</div><br/><div id="41877072" class="c"><input type="checkbox" id="c-41877072" checked=""/><div class="controls bullet"><span class="by">salamo</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41876397">parent</a><span>|</span><a href="#41877326">next</a><span>|</span><label class="collapse" for="c-41877072">[-]</label><label class="expand" for="c-41877072">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m happy you enjoyed it! There are definitely a few rough edges, yes.<p>Since the whole thing is executed in the browser (including the model) there aren&#x27;t a ton of secrets for me to keep. Essentially it is expectation maximization: the bot tries to find the move with the highest value. What is &quot;value&quot;? Essentially, it is the dot product between the probability distribution coming out of the model and the centipawn evaluations from Stockfish.<p>In other words if the model thinks you will blunder with high probability, it will try to steer you towards making that mistake.</div><br/></div></div></div></div></div></div><div id="41877326" class="c"><input type="checkbox" id="c-41877326" checked=""/><div class="controls bullet"><span class="by">netdevnet</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41875558">prev</a><span>|</span><a href="#41875964">next</a><span>|</span><label class="collapse" for="c-41877326">[-]</label><label class="expand" for="c-41877326">[1 more]</label></div><br/><div class="children"><div class="content">How would you even go about making a model that can simulate a human chess skillset (saying levels implies that chess skillset is a scalar value while it is more reasonable to think of it as a tree of skills where your abilities might be higher or lower depend ending on the specific skill branch)</div><br/></div></div><div id="41875964" class="c"><input type="checkbox" id="c-41875964" checked=""/><div class="controls bullet"><span class="by">WhitneyLand</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41877326">prev</a><span>|</span><a href="#41876292">next</a><span>|</span><label class="collapse" for="c-41875964">[-]</label><label class="expand" for="c-41875964">[3 more]</label></div><br/><div class="children"><div class="content">What’s your rating, have you tried gpt4o?<p>It’s supposedly good up to about 1300, but aside from that the ability to prompt can make the style of play somewhat tunable for ex aggressive, defensive, etc.</div><br/><div id="41876164" class="c"><input type="checkbox" id="c-41876164" checked=""/><div class="controls bullet"><span class="by">anamexis</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41875964">parent</a><span>|</span><a href="#41876292">next</a><span>|</span><label class="collapse" for="c-41876164">[-]</label><label class="expand" for="c-41876164">[2 more]</label></div><br/><div class="children"><div class="content">Do you know if there are any interfaces to play against got4o? Or is it just typing in algebraic moves back and forth?</div><br/><div id="41876271" class="c"><input type="checkbox" id="c-41876271" checked=""/><div class="controls bullet"><span class="by">stackghost</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41876164">parent</a><span>|</span><a href="#41876292">next</a><span>|</span><label class="collapse" for="c-41876271">[-]</label><label class="expand" for="c-41876271">[1 more]</label></div><br/><div class="children"><div class="content">It prints an ASCII board, and then yes, you type algebraic moves back and forth and it updates the board for you each turn.</div><br/></div></div></div></div></div></div><div id="41876292" class="c"><input type="checkbox" id="c-41876292" checked=""/><div class="controls bullet"><span class="by">LanceH</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41875964">prev</a><span>|</span><a href="#41876599">next</a><span>|</span><label class="collapse" for="c-41876292">[-]</label><label class="expand" for="c-41876292">[1 more]</label></div><br/><div class="children"><div class="content">A long time ago I had the Fritz engine from chessbase.  It had a sparring feature where if you maintained good play it would give up a tactical puzzle in the middle of the game.  It could either warn you or not.  If you didn&#x27;t play solidly enough, you would just lose.<p>As far as I can tell, they got rid of this feature.  It was the only computer opponent that felt real.  Like it made a human mistake when put under pressure, rather than just playing like a computer and randomly deciding to play stupid.</div><br/></div></div><div id="41876599" class="c"><input type="checkbox" id="c-41876599" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41876292">prev</a><span>|</span><a href="#41874316">next</a><span>|</span><label class="collapse" for="c-41876599">[-]</label><label class="expand" for="c-41876599">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if loweing the &#x27;temperature&#x27; level (how rigid they select the max value completion) on these types of models would achieve this? Might be tricky to tune as the outcome is likely non=linear</div><br/></div></div><div id="41874316" class="c"><input type="checkbox" id="c-41874316" checked=""/><div class="controls bullet"><span class="by">rtlaker</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41876599">prev</a><span>|</span><a href="#41875838">next</a><span>|</span><label class="collapse" for="c-41874316">[-]</label><label class="expand" for="c-41874316">[1 more]</label></div><br/><div class="children"><div class="content">No, not with adjustable rating. The best human-like engine is fairymax, but its Elo is estimated between 1700-2000.</div><br/></div></div><div id="41875838" class="c"><input type="checkbox" id="c-41875838" checked=""/><div class="controls bullet"><span class="by">Scene_Cast2</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41874316">prev</a><span>|</span><a href="#41875345">next</a><span>|</span><label class="collapse" for="c-41875838">[-]</label><label class="expand" for="c-41875838">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m currently trying to build one, fwiw.</div><br/><div id="41876114" class="c"><input type="checkbox" id="c-41876114" checked=""/><div class="controls bullet"><span class="by">andrelaszlo</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41875838">parent</a><span>|</span><a href="#41875345">next</a><span>|</span><label class="collapse" for="c-41876114">[-]</label><label class="expand" for="c-41876114">[1 more]</label></div><br/><div class="children"><div class="content">Cool! I&#x27;ve been wondering for s while if it wouldn&#x27;t be possible to use lichess games for various ratings to make typical mistakes.<p>I&#x27;m also curious about if it would be possible to mimic certain playing styles. Two beginners can have the same rating but one might lose because they have a weak opening, and the other one because they mess upo the end game, for example.<p>Random mistakes doesn&#x27;t mimic human play very well.</div><br/></div></div></div></div><div id="41875345" class="c"><input type="checkbox" id="c-41875345" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41875838">prev</a><span>|</span><a href="#41874396">next</a><span>|</span><label class="collapse" for="c-41875345">[-]</label><label class="expand" for="c-41875345">[1 more]</label></div><br/><div class="children"><div class="content">GPT-3.5-turbo-instruct has a peak Elo of around 1800 (but of course can be prompted to play with less skill) and is as human like as you&#x27;ll get at that level.</div><br/></div></div><div id="41874396" class="c"><input type="checkbox" id="c-41874396" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#41874291">parent</a><span>|</span><a href="#41875345">prev</a><span>|</span><a href="#41873501">next</a><span>|</span><label class="collapse" for="c-41874396">[-]</label><label class="expand" for="c-41874396">[7 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t seem that difficult to pull off - take one of the existing engines, get the top y moves, choose randomly. For each level down increase y by 1.</div><br/><div id="41874486" class="c"><input type="checkbox" id="c-41874486" checked=""/><div class="controls bullet"><span class="by">ajkjk</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41874396">parent</a><span>|</span><a href="#41874442">next</a><span>|</span><label class="collapse" for="c-41874486">[-]</label><label class="expand" for="c-41874486">[1 more]</label></div><br/><div class="children"><div class="content">No, it doesn&#x27;t work at all. Human mistakes are not at all like computer mistakes. Like -- blundering a piece in a 1-2 move combination will straight up never show up in the stockfish move tree, no matter what you set `y` to.</div><br/></div></div><div id="41874442" class="c"><input type="checkbox" id="c-41874442" checked=""/><div class="controls bullet"><span class="by">agubelu</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41874396">parent</a><span>|</span><a href="#41874486">prev</a><span>|</span><a href="#41874463">next</a><span>|</span><label class="collapse" for="c-41874442">[-]</label><label class="expand" for="c-41874442">[2 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t work that way. There are many positions with lots of moves that are reasonable, but many others with only 1-2 sensible moves. It would make lots of obvious blunders that an amateur human would never make.</div><br/><div id="41874482" class="c"><input type="checkbox" id="c-41874482" checked=""/><div class="controls bullet"><span class="by">chmod775</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41874442">parent</a><span>|</span><a href="#41874463">next</a><span>|</span><label class="collapse" for="c-41874482">[-]</label><label class="expand" for="c-41874482">[1 more]</label></div><br/><div class="children"><div class="content">Also attention. Lower level human players are more likely to make a move close to their own&#x2F;their opponent&#x27;s recent move. They&#x27;re focused on one area of the board.<p>Basic computer opponents on the other hand can make moves all over the place. They look at the board state holistically. This can be very frustrating to play against as a human who has enough problems just thinking their way through some subset of the board, but is thrown off by the computer again and again.<p>It&#x27;s not that bad in chess at least (compared to Go), but still something worth to keep in mind if you&#x27;re trying to make an AI that is fun to play against as an amateur.</div><br/></div></div></div></div><div id="41874463" class="c"><input type="checkbox" id="c-41874463" checked=""/><div class="controls bullet"><span class="by">dullcrisp</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41874396">parent</a><span>|</span><a href="#41874442">prev</a><span>|</span><a href="#41874480">next</a><span>|</span><label class="collapse" for="c-41874463">[-]</label><label class="expand" for="c-41874463">[1 more]</label></div><br/><div class="children"><div class="content">Seems this might still have the problem of moves being either extremely good or extremely bad depending on how many good moves are found, rather than playing at a consistent level. Or for example in a degenerate case where there are only two moves and one leads to mate, the computer will be picking randomly.</div><br/></div></div><div id="41874480" class="c"><input type="checkbox" id="c-41874480" checked=""/><div class="controls bullet"><span class="by">bobmcnamara</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41874396">parent</a><span>|</span><a href="#41874463">prev</a><span>|</span><a href="#41873501">next</a><span>|</span><label class="collapse" for="c-41874480">[-]</label><label class="expand" for="c-41874480">[2 more]</label></div><br/><div class="children"><div class="content">Your engine would only mate once it had y options to mate.</div><br/><div id="41874704" class="c"><input type="checkbox" id="c-41874704" checked=""/><div class="controls bullet"><span class="by">dullcrisp</span><span>|</span><a href="#41874291">root</a><span>|</span><a href="#41874480">parent</a><span>|</span><a href="#41873501">next</a><span>|</span><label class="collapse" for="c-41874704">[-]</label><label class="expand" for="c-41874704">[1 more]</label></div><br/><div class="children"><div class="content">Or y chances. They did say it’d pick randomly. Still not great though, if a bit less funny.</div><br/></div></div></div></div></div></div></div></div><div id="41873501" class="c"><input type="checkbox" id="c-41873501" checked=""/><div class="controls bullet"><span class="by">hlfshell</span><span>|</span><a href="#41874291">prev</a><span>|</span><a href="#41875854">next</a><span>|</span><label class="collapse" for="c-41873501">[-]</label><label class="expand" for="c-41873501">[4 more]</label></div><br/><div class="children"><div class="content">I did a talk about this! (And also wrote up about my talk here[1]). This paper is a great example of both knowledge distillation. It&#x27;s less of a paper about chess and more about how complicated non linear search functions - complete with whatever tuning experts can prepare - can be distilled into a (quasi-linear, if it&#x27;s a standardized input like chess) transformer model.<p>[1]: <a href="https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;deepmind-grandmaster-chess-without-search&#x2F;" rel="nofollow">https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;deepmind-grandmaster-chess-without...</a></div><br/><div id="41874003" class="c"><input type="checkbox" id="c-41874003" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#41873501">parent</a><span>|</span><a href="#41875854">next</a><span>|</span><label class="collapse" for="c-41874003">[-]</label><label class="expand" for="c-41874003">[3 more]</label></div><br/><div class="children"><div class="content">I think the vs. humans result should be taken with a huge grain of salt. These are blitz games, and their engine’s elo was far higher against humans than against other bots. So it’s likely that time was a factor, where humans are likely to flag (run out of time) or blunder in low time situations.<p>It’s still very cool that they could learn a very good eval function that doesn’t require search. I would’ve liked the authors to throw out the games where the Stockfish fallback kicked in though. Even for a human, mate in 2 vs mate in 10 is the difference between a win and a draw&#x2F;loss on time.<p>I also would’ve liked to see a head to head with limited search depth Stockfish. That would tell us approximately how much of the search tree their eval function distilled.</div><br/><div id="41874038" class="c"><input type="checkbox" id="c-41874038" checked=""/><div class="controls bullet"><span class="by">hlfshell</span><span>|</span><a href="#41873501">root</a><span>|</span><a href="#41874003">parent</a><span>|</span><a href="#41875854">next</a><span>|</span><label class="collapse" for="c-41874038">[-]</label><label class="expand" for="c-41874038">[2 more]</label></div><br/><div class="children"><div class="content">The reason the time (blitz) games make sense is because the distilled functionality is of a 50ms Stockfish eval function. The engine likely would perform worse as only the human would benefit from the additional time.<p>As for limited search tree I like the idea! I think it&#x27;s tough to measure, since the time it takes to perform search across various depths vary wildly based on the complexity of the position. I feel like you would have to compile a dataset of specific positions identified to require significant depth of search to find a &quot;good&quot; move.</div><br/><div id="41874149" class="c"><input type="checkbox" id="c-41874149" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#41873501">root</a><span>|</span><a href="#41874038">parent</a><span>|</span><a href="#41875854">next</a><span>|</span><label class="collapse" for="c-41874149">[-]</label><label class="expand" for="c-41874149">[1 more]</label></div><br/><div class="children"><div class="content">My point is that if the computer never flags it will have an inherent advantage in low time controls. If not, why not just test it in hyperbullet games? Games where humans flag in a drawn or winning position need to be excluded, otherwise it’s unclear what this is even measuring.<p>And limited depth games would not have been difficult to run. You can run a limited search Stockfish on a laptop using the UCI protocol: <a href="https:&#x2F;&#x2F;github.com&#x2F;official-stockfish&#x2F;Stockfish&#x2F;wiki&#x2F;UCI-%26-Commands">https:&#x2F;&#x2F;github.com&#x2F;official-stockfish&#x2F;Stockfish&#x2F;wiki&#x2F;UCI-%26...</a></div><br/></div></div></div></div></div></div></div></div><div id="41875854" class="c"><input type="checkbox" id="c-41875854" checked=""/><div class="controls bullet"><span class="by">Scene_Cast2</span><span>|</span><a href="#41873501">prev</a><span>|</span><a href="#41877343">next</a><span>|</span><label class="collapse" for="c-41875854">[-]</label><label class="expand" for="c-41875854">[1 more]</label></div><br/><div class="children"><div class="content">If anyone is looking to get into chess neural nets, I <i>highly</i> recommend this repo -  <a href="https:&#x2F;&#x2F;github.com&#x2F;sgrvinod&#x2F;chess-transformers">https:&#x2F;&#x2F;github.com&#x2F;sgrvinod&#x2F;chess-transformers</a><p>It uses paradigmatic PyTorch with easy to read code, and the architecture is similar to the current best performing chess neural nets.</div><br/></div></div><div id="41877343" class="c"><input type="checkbox" id="c-41877343" checked=""/><div class="controls bullet"><span class="by">chvid</span><span>|</span><a href="#41875854">prev</a><span>|</span><a href="#41874706">next</a><span>|</span><label class="collapse" for="c-41877343">[-]</label><label class="expand" for="c-41877343">[2 more]</label></div><br/><div class="children"><div class="content">But the gigantic synthetic dataset that is used for training is created with plenty of traditional search. So it is all a bit silly but I guess cool none the less ...</div><br/><div id="41877359" class="c"><input type="checkbox" id="c-41877359" checked=""/><div class="controls bullet"><span class="by">chvid</span><span>|</span><a href="#41877343">parent</a><span>|</span><a href="#41874706">next</a><span>|</span><label class="collapse" for="c-41877359">[-]</label><label class="expand" for="c-41877359">[1 more]</label></div><br/><div class="children"><div class="content">If anything it demonstrates the limits of NN. A human brain can learn based on far fewer examples.</div><br/></div></div></div></div><div id="41874706" class="c"><input type="checkbox" id="c-41874706" checked=""/><div class="controls bullet"><span class="by">osti</span><span>|</span><a href="#41877343">prev</a><span>|</span><a href="#41876458">next</a><span>|</span><label class="collapse" for="c-41874706">[-]</label><label class="expand" for="c-41874706">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;lczero.org&#x2F;blog&#x2F;2024&#x2F;02&#x2F;how-well-do-lc0-networks-compare-to-the-greatest-transformer-network-from-deepmind&#x2F;" rel="nofollow">https:&#x2F;&#x2F;lczero.org&#x2F;blog&#x2F;2024&#x2F;02&#x2F;how-well-do-lc0-networks-com...</a><p>The best neural network chess engine&#x27;s authors wrote about this deepminds publication.</div><br/></div></div><div id="41876458" class="c"><input type="checkbox" id="c-41876458" checked=""/><div class="controls bullet"><span class="by">barelyusable</span><span>|</span><a href="#41874706">prev</a><span>|</span><a href="#41875035">next</a><span>|</span><label class="collapse" for="c-41876458">[-]</label><label class="expand" for="c-41876458">[2 more]</label></div><br/><div class="children"><div class="content">What are some of the go-to books&#x2F;articles for computer chess? I like the game and have a decent understanding of basics, so studying algorithms based on the game would be a good opportunity for me to learn conventional algos, but also RL&#x2F;ML&#x2F;MCTS etc. Also I wonder what is the go-to codebase these days?</div><br/><div id="41877236" class="c"><input type="checkbox" id="c-41877236" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#41876458">parent</a><span>|</span><a href="#41875035">next</a><span>|</span><label class="collapse" for="c-41877236">[-]</label><label class="expand" for="c-41877236">[1 more]</label></div><br/><div class="children"><div class="content">Stockfish and Leela are the two best engines and they’re both on GitHub. Although I will say they are hyperoptimized to win.<p>You can also ask any noob questions on their Discords.</div><br/></div></div></div></div><div id="41875035" class="c"><input type="checkbox" id="c-41875035" checked=""/><div class="controls bullet"><span class="by">jackmalpo</span><span>|</span><a href="#41876458">prev</a><span>|</span><a href="#41875758">next</a><span>|</span><label class="collapse" for="c-41875035">[-]</label><label class="expand" for="c-41875035">[2 more]</label></div><br/><div class="children"><div class="content">what i would love is an engine that thinks more like a human. presumably since this uses stockfish annotated games, it basically ends up thinking like a computer. thinking like a human would be awesome for game reviews to walk through things to note in different positions (tuned to my elo).</div><br/><div id="41875976" class="c"><input type="checkbox" id="c-41875976" checked=""/><div class="controls bullet"><span class="by">levocardia</span><span>|</span><a href="#41875035">parent</a><span>|</span><a href="#41875758">next</a><span>|</span><label class="collapse" for="c-41875976">[-]</label><label class="expand" for="c-41875976">[1 more]</label></div><br/><div class="children"><div class="content">Or a model whose performance is measured via its efficiency of learning--in other words, how many games does it need to play to learn to play at X level? The reason Magnus Carlsen is impressive is because he&#x27;s reached his ability level in chess under enormous time and computation constraints, compared to a computer. His efficiency of learning is extraordinary compared to that of any chess engine.</div><br/></div></div></div></div><div id="41875758" class="c"><input type="checkbox" id="c-41875758" checked=""/><div class="controls bullet"><span class="by">squidgedcricket</span><span>|</span><a href="#41875035">prev</a><span>|</span><a href="#41875257">next</a><span>|</span><label class="collapse" for="c-41875758">[-]</label><label class="expand" for="c-41875758">[7 more]</label></div><br/><div class="children"><div class="content">Would it be feasible to create a complete lookup table of &#x27;best&#x27; moves for all given board configurations?  I&#x27;m not sure how to determine the total number of configurations.  Not the same as a tablebase, just a single next move rather than sequence to checkmate.<p>It wouldn&#x27;t be competitive against top tier players and AI, but I wouldn&#x27;t be surprised if it could beat me.  &#x27;Instantly&#x27; knowing the next move would be a cool trick.</div><br/><div id="41875833" class="c"><input type="checkbox" id="c-41875833" checked=""/><div class="controls bullet"><span class="by">jeremyjh</span><span>|</span><a href="#41875758">parent</a><span>|</span><a href="#41876086">next</a><span>|</span><label class="collapse" for="c-41875833">[-]</label><label class="expand" for="c-41875833">[2 more]</label></div><br/><div class="children"><div class="content">There are more possible chess games than there are atoms in the universe. It can&#x27;t be solved by brute force.</div><br/><div id="41875944" class="c"><input type="checkbox" id="c-41875944" checked=""/><div class="controls bullet"><span class="by">squidgedcricket</span><span>|</span><a href="#41875758">root</a><span>|</span><a href="#41875833">parent</a><span>|</span><a href="#41876086">next</a><span>|</span><label class="collapse" for="c-41875944">[-]</label><label class="expand" for="c-41875944">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a lot of chess configs, but there&#x27;s a LOT of atoms in the observable universe. I suspect there&#x27;s a few in the unobservable universe too.<p>Chess configs = 4.8 x 10^44, Atoms &gt; 10^70<p><a href="https:&#x2F;&#x2F;tromp.github.io&#x2F;chess&#x2F;chess.html" rel="nofollow">https:&#x2F;&#x2F;tromp.github.io&#x2F;chess&#x2F;chess.html</a>
<a href="https:&#x2F;&#x2F;physics.stackexchange.com&#x2F;questions&#x2F;47941&#x2F;dumbed-down-explanation-how-scientists-know-the-number-of-atoms-in-the-universe" rel="nofollow">https:&#x2F;&#x2F;physics.stackexchange.com&#x2F;questions&#x2F;47941&#x2F;dumbed-dow...</a><p>You might be able to pull off a low-resolution lookup table. Take some big but manageable number N (e.g 10^10) and calculate the maximally even distribution of those points over the total space of chessboard configurations. Then make a lookup table for those configs. In play, for configs not in the table, interpolate between nearest points in the table.</div><br/></div></div></div></div><div id="41876086" class="c"><input type="checkbox" id="c-41876086" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#41875758">parent</a><span>|</span><a href="#41875833">prev</a><span>|</span><a href="#41875783">next</a><span>|</span><label class="collapse" for="c-41876086">[-]</label><label class="expand" for="c-41876086">[1 more]</label></div><br/><div class="children"><div class="content">That is basically what a neural network based chess engine is. The function the neural network is encoding is logically equivalent to &quot;probability this move is the best for this board state&quot;.<p>The resolution isn&#x27;t great, and adding search to that can be used to develop an implicit measure of how accurate the function is (ie, probability the move suggested in a position remains unchanged after searching the move tree for better alternatives).</div><br/></div></div><div id="41875783" class="c"><input type="checkbox" id="c-41875783" checked=""/><div class="controls bullet"><span class="by">k2xl</span><span>|</span><a href="#41875758">parent</a><span>|</span><a href="#41876086">prev</a><span>|</span><a href="#41875257">next</a><span>|</span><label class="collapse" for="c-41875783">[-]</label><label class="expand" for="c-41875783">[3 more]</label></div><br/><div class="children"><div class="content">The amount of data that would be required for a lookup table for all best moves for every board configuration would be infeasible.<p>They have managed to create one for 7 pieces. Last update on trying to get to 8 piece database: <a href="https:&#x2F;&#x2F;www.chess.com&#x2F;blog&#x2F;Rocky64&#x2F;eight-piece-tablebases-a-progress-update-and-some-results" rel="nofollow">https:&#x2F;&#x2F;www.chess.com&#x2F;blog&#x2F;Rocky64&#x2F;eight-piece-tablebases-a-...</a></div><br/><div id="41875862" class="c"><input type="checkbox" id="c-41875862" checked=""/><div class="controls bullet"><span class="by">squidgedcricket</span><span>|</span><a href="#41875758">root</a><span>|</span><a href="#41875783">parent</a><span>|</span><a href="#41876145">next</a><span>|</span><label class="collapse" for="c-41875862">[-]</label><label class="expand" for="c-41875862">[1 more]</label></div><br/><div class="children"><div class="content">Yup, and it looks like a complete tablebase from the start of the game won&#x27;t ever be feasible.<p>&gt; From May to August 2018 Bojun Guo generated 7-piece tables. The 7-piece tablebase contains 423,836,835,667,331 unique legal positions in about 18 Terabytes.</div><br/></div></div><div id="41876145" class="c"><input type="checkbox" id="c-41876145" checked=""/><div class="controls bullet"><span class="by">andrelaszlo</span><span>|</span><a href="#41875758">root</a><span>|</span><a href="#41875783">parent</a><span>|</span><a href="#41875862">prev</a><span>|</span><a href="#41875257">next</a><span>|</span><label class="collapse" for="c-41876145">[-]</label><label class="expand" for="c-41876145">[1 more]</label></div><br/><div class="children"><div class="content">Almost halfway there ;)</div><br/></div></div></div></div></div></div><div id="41875257" class="c"><input type="checkbox" id="c-41875257" checked=""/><div class="controls bullet"><span class="by">RayVR</span><span>|</span><a href="#41875758">prev</a><span>|</span><a href="#41876043">next</a><span>|</span><label class="collapse" for="c-41875257">[-]</label><label class="expand" for="c-41875257">[4 more]</label></div><br/><div class="children"><div class="content">I forget the rough adjustment factors, but it is worth noting that lichess Elo is not the same as chess.com or FIDE. I think lichess is typically ~300 points above chess.com.<p>This implies the model is around 2500 blitz vs humans. As blitz elo are often much higher than in classical time controls, 2500 elo on chess.com places it firmly in the &#x27;good but not great&#x27; level.<p>I am very curious to know whether the model suffers from the same eval problems vs the well known &quot;anti-bot&quot; openings that stockfish is susceptible to at limited search depths.</div><br/><div id="41875357" class="c"><input type="checkbox" id="c-41875357" checked=""/><div class="controls bullet"><span class="by">gpm</span><span>|</span><a href="#41875257">parent</a><span>|</span><a href="#41875461">next</a><span>|</span><label class="collapse" for="c-41875357">[-]</label><label class="expand" for="c-41875357">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I think lichess is typically ~300 points above chess.com.<p>Yeah, no. They are two different rating systems (not ELO incidentally) with different curves, there isn&#x27;t a fixed difference you can apply. At the high end of the scale lichess ratings are below, not above, chess.com ratings. E.g. Magnus Carlsen is 3131 blitz on lichess [0], 3294 blitz on chess.com [1].<p>This website [2] tries to translate between the sites, and figures that a 2925 lichess blitz rating (the closet on the website to the one reported in the paper of 2895) translates to 3000 chess.com.<p>[0] Multiple accounts but this is the one I found with the most blitz games: <a href="https:&#x2F;&#x2F;lichess.org&#x2F;@&#x2F;DrNykterstein&#x2F;perf&#x2F;blitz" rel="nofollow">https:&#x2F;&#x2F;lichess.org&#x2F;@&#x2F;DrNykterstein&#x2F;perf&#x2F;blitz</a><p>[1] <a href="https:&#x2F;&#x2F;www.chess.com&#x2F;member&#x2F;magnuscarlsen" rel="nofollow">https:&#x2F;&#x2F;www.chess.com&#x2F;member&#x2F;magnuscarlsen</a><p>[2] <a href="https:&#x2F;&#x2F;chessgoals.com&#x2F;rating-comparison&#x2F;#lichesschesscom" rel="nofollow">https:&#x2F;&#x2F;chessgoals.com&#x2F;rating-comparison&#x2F;#lichesschesscom</a></div><br/><div id="41876798" class="c"><input type="checkbox" id="c-41876798" checked=""/><div class="controls bullet"><span class="by">jdck1326</span><span>|</span><a href="#41875257">root</a><span>|</span><a href="#41875357">parent</a><span>|</span><a href="#41875461">next</a><span>|</span><label class="collapse" for="c-41876798">[-]</label><label class="expand" for="c-41876798">[1 more]</label></div><br/><div class="children"><div class="content">Elo. Not acronym, named for its inventor Arpad Emmerich Elo<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Elo_rating_system" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Elo_rating_system</a></div><br/></div></div></div></div></div></div><div id="41876043" class="c"><input type="checkbox" id="c-41876043" checked=""/><div class="controls bullet"><span class="by">sourcepluck</span><span>|</span><a href="#41875257">prev</a><span>|</span><a href="#41876476">next</a><span>|</span><label class="collapse" for="c-41876043">[-]</label><label class="expand" for="c-41876043">[2 more]</label></div><br/><div class="children"><div class="content">I believe GM and chess author (and all-round lovely fellow) Matthew Sadler rigged up Leela Zero to effectively play off intuition and do very little or no search for training games. He could usually beat it, but not always. Think it might have been in The Silicon Road to Chess Improvement.</div><br/><div id="41877553" class="c"><input type="checkbox" id="c-41877553" checked=""/><div class="controls bullet"><span class="by">Davidzheng</span><span>|</span><a href="#41876043">parent</a><span>|</span><a href="#41876476">next</a><span>|</span><label class="collapse" for="c-41877553">[-]</label><label class="expand" for="c-41877553">[1 more]</label></div><br/><div class="children"><div class="content">I mean for lczero you can just set the max depth at 1 ply for example</div><br/></div></div></div></div><div id="41876476" class="c"><input type="checkbox" id="c-41876476" checked=""/><div class="controls bullet"><span class="by">dougSF70</span><span>|</span><a href="#41876043">prev</a><span>|</span><a href="#41875628">next</a><span>|</span><label class="collapse" for="c-41876476">[-]</label><label class="expand" for="c-41876476">[1 more]</label></div><br/><div class="children"><div class="content">Slightly off topic but I built <a href="https:&#x2F;&#x2F;chessladders.com" rel="nofollow">https:&#x2F;&#x2F;chessladders.com</a></div><br/></div></div><div id="41875628" class="c"><input type="checkbox" id="c-41875628" checked=""/><div class="controls bullet"><span class="by">rawsh</span><span>|</span><a href="#41876476">prev</a><span>|</span><a href="#41876628">next</a><span>|</span><label class="collapse" for="c-41875628">[-]</label><label class="expand" for="c-41875628">[1 more]</label></div><br/><div class="children"><div class="content">You can actually get solid performance with pretrained chat models: <a href="https:&#x2F;&#x2F;raw.sh&#x2F;posts&#x2F;chess_puzzles" rel="nofollow">https:&#x2F;&#x2F;raw.sh&#x2F;posts&#x2F;chess_puzzles</a><p>On lichess puzzles gpt4o with the compiled prompt is around 70%, I think the 270M transformer is around 95%</div><br/></div></div><div id="41876628" class="c"><input type="checkbox" id="c-41876628" checked=""/><div class="controls bullet"><span class="by">BoardsOfCanada</span><span>|</span><a href="#41875628">prev</a><span>|</span><a href="#41873998">next</a><span>|</span><label class="collapse" for="c-41876628">[-]</label><label class="expand" for="c-41876628">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s somewhat telling that they chose Stockfish as the oracle and not AlphaZero.</div><br/></div></div><div id="41873998" class="c"><input type="checkbox" id="c-41873998" checked=""/><div class="controls bullet"><span class="by">ChrisArchitect</span><span>|</span><a href="#41876628">prev</a><span>|</span><a href="#41875226">next</a><span>|</span><label class="collapse" for="c-41873998">[-]</label><label class="expand" for="c-41873998">[1 more]</label></div><br/><div class="children"><div class="content">Associated discussion on the paper:<p><i>Grandmaster-Level Chess Without Search</i><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39301944">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39301944</a></div><br/></div></div><div id="41875226" class="c"><input type="checkbox" id="c-41875226" checked=""/><div class="controls bullet"><span class="by">imranhou</span><span>|</span><a href="#41873998">prev</a><span>|</span><a href="#41873554">next</a><span>|</span><label class="collapse" for="c-41875226">[-]</label><label class="expand" for="c-41875226">[2 more]</label></div><br/><div class="children"><div class="content">From the page: &quot;We also show that our model outperforms AlphaZero&#x27;s policy and value networks (without MCTS) and GPT-3.5-turbo-instruct.&quot;<p>Why compare this to GPT-3.5-turbo-instruct? Is that near SOTA in this space?</div><br/><div id="41875394" class="c"><input type="checkbox" id="c-41875394" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#41875226">parent</a><span>|</span><a href="#41873554">next</a><span>|</span><label class="collapse" for="c-41875394">[-]</label><label class="expand" for="c-41875394">[1 more]</label></div><br/><div class="children"><div class="content">As far as anyone knows, 3.5-turbo-instruct is the best chess playing (certainly it was at the time of the paper) LLM. About 1800 Elo and &lt; 0.1% Illegal move rate. It&#x27;s unclear why it was so much better than 4 (lack of RLHF?, Data?) and I don&#x27;t know if anyone has bothered to test 4o similarly but it was pretty big news online at the time.</div><br/></div></div></div></div><div id="41873554" class="c"><input type="checkbox" id="c-41873554" checked=""/><div class="controls bullet"><span class="by">joelthelion</span><span>|</span><a href="#41875226">prev</a><span>|</span><a href="#41873648">next</a><span>|</span><label class="collapse" for="c-41873554">[-]</label><label class="expand" for="c-41873554">[17 more]</label></div><br/><div class="children"><div class="content">I wonder if you could creatively combine this model with search algorithms to advance the state of the art in computer chess? I wouldn&#x27;t be surprised to see such a bot pop up on tcec in a couple years.</div><br/><div id="41873900" class="c"><input type="checkbox" id="c-41873900" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#41873554">parent</a><span>|</span><a href="#41873666">next</a><span>|</span><label class="collapse" for="c-41873900">[-]</label><label class="expand" for="c-41873900">[4 more]</label></div><br/><div class="children"><div class="content">The advantage of this flavor of engine is that it might make parallel position evaluation extremely efficient. Calculate 1024 leaf positions and batch them to the model, take the top 10% and explore their sub-trees either via further GPU batching or minimax eval.<p>NNUE already tries to distill a subtree eval into a neural net, but it’s optimized for CPU rather than GPU.</div><br/><div id="41875457" class="c"><input type="checkbox" id="c-41875457" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873900">parent</a><span>|</span><a href="#41873666">next</a><span>|</span><label class="collapse" for="c-41875457">[-]</label><label class="expand" for="c-41875457">[3 more]</label></div><br/><div class="children"><div class="content">As a game player I want to play an opponent that behaves like a human. Otherwise I’m always looking for the flaw in the design that I can exploit, which wins me the game but is less fun.<p>What you’re discussing sounds like intuition with checking, which is pretty close to how humans with a moderate degree of skill behave. I haven’t known enough Chess or Go masters to have any claim on how <i>they</i> think. But most of us don’t want an opponent at that level and if we did, we would certainly find a human, or just play against ourselves.</div><br/><div id="41875947" class="c"><input type="checkbox" id="c-41875947" checked=""/><div class="controls bullet"><span class="by">salamo</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41875457">parent</a><span>|</span><a href="#41873666">next</a><span>|</span><label class="collapse" for="c-41875947">[-]</label><label class="expand" for="c-41875947">[2 more]</label></div><br/><div class="children"><div class="content">The issue is that humans and computers don&#x27;t evaluate board positions in the same way. A computer will analyze every possible move, and then every possible response to each of those moves, etc. Human grandmasters will typically only analyze a handful of candidate moves, and a few possible replies to those moves. This means human search is much narrower and shallower.<p>If you want a computer that plays like a human, you will probably need to imitate the way that a human thinks about the game. This means for example thinking about the interactions between pieces and the flow of the game rather than stateless evaluations.</div><br/><div id="41876175" class="c"><input type="checkbox" id="c-41876175" checked=""/><div class="controls bullet"><span class="by">hinkley</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41875947">parent</a><span>|</span><a href="#41873666">next</a><span>|</span><label class="collapse" for="c-41876175">[-]</label><label class="expand" for="c-41876175">[1 more]</label></div><br/><div class="children"><div class="content">Grandparent was suggesting the hybrid approach where you select a handful of good candidate positions and then explore them (DFS) as far as possible. Which is pretty much how humans work.</div><br/></div></div></div></div></div></div></div></div><div id="41873666" class="c"><input type="checkbox" id="c-41873666" checked=""/><div class="controls bullet"><span class="by">alfalfasprout</span><span>|</span><a href="#41873554">parent</a><span>|</span><a href="#41873900">prev</a><span>|</span><a href="#41873648">next</a><span>|</span><label class="collapse" for="c-41873666">[-]</label><label class="expand" for="c-41873666">[12 more]</label></div><br/><div class="children"><div class="content">The thing is classical chess (unlike eg; go) is essentially &quot;solved&quot; when run on computers capable of extreme depth. Modern chess engines play essentially flawlessly.</div><br/><div id="41873728" class="c"><input type="checkbox" id="c-41873728" checked=""/><div class="controls bullet"><span class="by">KK7NIL</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873666">parent</a><span>|</span><a href="#41873853">next</a><span>|</span><label class="collapse" for="c-41873728">[-]</label><label class="expand" for="c-41873728">[3 more]</label></div><br/><div class="children"><div class="content">The developers of stockfish and lc0 (and the many weaker engines around) would disagree, we&#x27;ve seen their strength improve considerably over the last few years.<p>Currently there&#x27;s a very interesting war between small neural networks on the CPU with high search depth alpha-beta pruning (stockfish NNUE) and big neural networks on a GPU with Monte Carlo search and lower depth (lc0).<p>So, while machines beating humans is &quot;solved&quot;, chess is very far from solved (just ask the guys who have actually solved chess endgames with 8 or less pieces).</div><br/><div id="41873849" class="c"><input type="checkbox" id="c-41873849" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873728">parent</a><span>|</span><a href="#41873853">next</a><span>|</span><label class="collapse" for="c-41873849">[-]</label><label class="expand" for="c-41873849">[2 more]</label></div><br/><div class="children"><div class="content">Stockfish and lc0 would always draw if they are not put in unbalanced starting positions, the starting position will be swapped in the next game to make it fair.</div><br/><div id="41874064" class="c"><input type="checkbox" id="c-41874064" checked=""/><div class="controls bullet"><span class="by">KK7NIL</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873849">parent</a><span>|</span><a href="#41873853">next</a><span>|</span><label class="collapse" for="c-41874064">[-]</label><label class="expand" for="c-41874064">[1 more]</label></div><br/><div class="children"><div class="content">In classical controls (what TCEC mainly uses), yes. 
They can play pretty exciting bullet chess without a forced opening though.</div><br/></div></div></div></div></div></div><div id="41873853" class="c"><input type="checkbox" id="c-41873853" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873666">parent</a><span>|</span><a href="#41873728">prev</a><span>|</span><a href="#41873731">next</a><span>|</span><label class="collapse" for="c-41873853">[-]</label><label class="expand" for="c-41873853">[1 more]</label></div><br/><div class="children"><div class="content">Chess is not “solved”. Solved doesn’t mean computers can beat humans, it means for any chess board position we can tell whether white wins, black wins, or the game is drawn with perfect play. We would know if the starting position was drawn, for example.<p>No computers now or in the foreseeable future will be capable of solving chess. It has an average branching factor over 30 and games can be over 100 moves.</div><br/></div></div><div id="41873731" class="c"><input type="checkbox" id="c-41873731" checked=""/><div class="controls bullet"><span class="by">solveit</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873666">parent</a><span>|</span><a href="#41873853">prev</a><span>|</span><a href="#41873911">next</a><span>|</span><label class="collapse" for="c-41873731">[-]</label><label class="expand" for="c-41873731">[5 more]</label></div><br/><div class="children"><div class="content">We really have no way to know this. But I would be very surprised if modern chess engines didn&#x27;t regularly blunder into losing (from the perspective of a hypothetical 32-piece tablebase) positions, and very very surprised if modern chess engines perfectly converted tablebase-winning positions.</div><br/><div id="41874074" class="c"><input type="checkbox" id="c-41874074" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873731">parent</a><span>|</span><a href="#41874713">next</a><span>|</span><label class="collapse" for="c-41874074">[-]</label><label class="expand" for="c-41874074">[2 more]</label></div><br/><div class="children"><div class="content">The fact that TCEC games aren’t all draws suggests that computers aren’t perfect. Stockfish loses to Leela sometimes for example.</div><br/><div id="41874621" class="c"><input type="checkbox" id="c-41874621" checked=""/><div class="controls bullet"><span class="by">grumpopotamus</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41874074">parent</a><span>|</span><a href="#41874713">next</a><span>|</span><label class="collapse" for="c-41874621">[-]</label><label class="expand" for="c-41874621">[1 more]</label></div><br/><div class="children"><div class="content">Tcec games are deliberately played from imbalanced opening positions. The draw rate would be much higher for the top participants if this wasn&#x27;t forced. However, I agree that engines are not perfect. I have heard this claim many times before a new engine came along that showed just how beatable the state of the art engines still were at the time.</div><br/></div></div></div></div><div id="41874713" class="c"><input type="checkbox" id="c-41874713" checked=""/><div class="controls bullet"><span class="by">KK7NIL</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873731">parent</a><span>|</span><a href="#41874074">prev</a><span>|</span><a href="#41873753">next</a><span>|</span><label class="collapse" for="c-41874713">[-]</label><label class="expand" for="c-41874713">[1 more]</label></div><br/><div class="children"><div class="content">We do know this, there are many positions (primarily sharp middle game one&#x27;s) where SF&#x2F;lc0 will significantly change their evaluation as they go deeper. 
This problem gets better the more time they spend on one position but it&#x27;s an inevitable consequence of the horizon effect and it&#x27;s why (except for 8 pieces or less), chess is far from solved.</div><br/></div></div><div id="41873753" class="c"><input type="checkbox" id="c-41873753" checked=""/><div class="controls bullet"><span class="by">__s</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873731">parent</a><span>|</span><a href="#41874713">prev</a><span>|</span><a href="#41873911">next</a><span>|</span><label class="collapse" for="c-41873753">[-]</label><label class="expand" for="c-41873753">[1 more]</label></div><br/><div class="children"><div class="content">not only blunder into losing positions, but also blunder from winning positions into draws<p>even in human chess people sometimes mistaken draw frequency to reflect both sides playing optimally, but there are many games where a winning advantage slips away into a draw</div><br/></div></div></div></div><div id="41873911" class="c"><input type="checkbox" id="c-41873911" checked=""/><div class="controls bullet"><span class="by">primitivesuave</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873666">parent</a><span>|</span><a href="#41873731">prev</a><span>|</span><a href="#41873743">next</a><span>|</span><label class="collapse" for="c-41873911">[-]</label><label class="expand" for="c-41873911">[1 more]</label></div><br/><div class="children"><div class="content">This is accurate for endgames only. In complicated positions, there is still room for improvement - the recent game of lc0 vs stockfish where lc0 forced a draw against an impending checkmate is a good example. There is currently no way for a chess engine searching a massive game tree can see how an innocuous pawn move enables a forced stalemate 40 moves down the line.</div><br/></div></div><div id="41873743" class="c"><input type="checkbox" id="c-41873743" checked=""/><div class="controls bullet"><span class="by">__s</span><span>|</span><a href="#41873554">root</a><span>|</span><a href="#41873666">parent</a><span>|</span><a href="#41873911">prev</a><span>|</span><a href="#41873648">next</a><span>|</span><label class="collapse" for="c-41873743">[-]</label><label class="expand" for="c-41873743">[1 more]</label></div><br/><div class="children"><div class="content">compared to humans yes, but between themselves in TCEC progress continues. TCEC has AIs play both sides of random openings, rather than stick to playing chess&#x27;s initial position. The same happens for checkers amongst humans, where opening positions are randomized</div><br/></div></div></div></div></div></div><div id="41873648" class="c"><input type="checkbox" id="c-41873648" checked=""/><div class="controls bullet"><span class="by">dgraph_advocate</span><span>|</span><a href="#41873554">prev</a><span>|</span><a href="#41874924">next</a><span>|</span><label class="collapse" for="c-41873648">[-]</label><label class="expand" for="c-41873648">[1 more]</label></div><br/><div class="children"><div class="content">This is missing a makefile to automate the manual installation steps</div><br/></div></div><div id="41874924" class="c"><input type="checkbox" id="c-41874924" checked=""/><div class="controls bullet"><span class="by">YeGoblynQueenne</span><span>|</span><a href="#41873648">prev</a><span>|</span><a href="#41876623">next</a><span>|</span><label class="collapse" for="c-41874924">[-]</label><label class="expand" for="c-41874924">[1 more]</label></div><br/><div class="children"><div class="content">Excellent work but I suggest a slightly different title:<p>&quot;What would Stockfish Do?&quot;<p>A more appropriate title; because Stockfish is a search-base system and DeepMind&#x27;s approach wouldn&#x27;t work without it.<p>Oh, btw, this is (yet another) a Neurosymbolic system of the &quot;compiling system 2 to system 1&quot; type.</div><br/></div></div><div id="41876623" class="c"><input type="checkbox" id="c-41876623" checked=""/><div class="controls bullet"><span class="by">xiaodai</span><span>|</span><a href="#41874924">prev</a><span>|</span><a href="#41876994">next</a><span>|</span><label class="collapse" for="c-41876623">[-]</label><label class="expand" for="c-41876623">[1 more]</label></div><br/><div class="children"><div class="content">this paper is so dumb. so you modeled the output of stockfish? stockfish does use simulation or selfplay or search. so you&#x27;ve outsourced search and dont do it yourself so you can claim to be &quot;without search&quot;</div><br/></div></div><div id="41876994" class="c"><input type="checkbox" id="c-41876994" checked=""/><div class="controls bullet"><span class="by">bicsi</span><span>|</span><a href="#41876623">prev</a><span>|</span><label class="collapse" for="c-41876994">[-]</label><label class="expand" for="c-41876994">[4 more]</label></div><br/><div class="children"><div class="content">They built a dumber clone of Stockfish, and they call it ‘zero’ for some reason. What is the meaning behind ‘zero’ anyways? It used to refer to zero-shot, but now it seems like it’s just a marketing term.</div><br/><div id="41877219" class="c"><input type="checkbox" id="c-41877219" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#41876994">parent</a><span>|</span><a href="#41877013">next</a><span>|</span><label class="collapse" for="c-41877219">[-]</label><label class="expand" for="c-41877219">[1 more]</label></div><br/><div class="children"><div class="content">I assume you’re referring to AlphaZero and Leela Chess Zero.<p>AlphaZero was the successor to AlphaGo. AZ was notable because unlike AG, it used zero human games to learn to play: it just played games against itself. Typically in “supervised” machine learning you take human data and train a model to imitate it. AZ used zero human data to learn.<p>Leela Chess Zero started out as an open source copy of AZ but it’s probably better than AZ now.</div><br/></div></div><div id="41877013" class="c"><input type="checkbox" id="c-41877013" checked=""/><div class="controls bullet"><span class="by">ralegh</span><span>|</span><a href="#41876994">parent</a><span>|</span><a href="#41877219">prev</a><span>|</span><a href="#41877220">next</a><span>|</span><label class="collapse" for="c-41877013">[-]</label><label class="expand" for="c-41877013">[1 more]</label></div><br/><div class="children"><div class="content">I assume it&#x27;s &#x27;zero&#x27; turns lookahead&#x2F;search, i.e. only look at the current board state.</div><br/></div></div><div id="41877220" class="c"><input type="checkbox" id="c-41877220" checked=""/><div class="controls bullet"><span class="by">pertymcpert</span><span>|</span><a href="#41876994">parent</a><span>|</span><a href="#41877013">prev</a><span>|</span><label class="collapse" for="c-41877220">[-]</label><label class="expand" for="c-41877220">[1 more]</label></div><br/><div class="children"><div class="content">Zero doesn&#x27;t mean zero shot learning. It was coined by Deepmind for AlphaGo Zero where they used zero human input into the training data. It was trained entirely by playing against itself.</div><br/></div></div></div></div></div></div></div></div></div></body></html>