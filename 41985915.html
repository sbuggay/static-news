<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1730278864118" as="style"/><link rel="stylesheet" href="styles.css?v=1730278864118"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.bloomberg.com/news/articles/2024-10-29/microsoft-s-github-unit-cuts-ai-deals-with-google-anthropic">GitHub cuts AI deals with Google, Anthropic</a> <span class="domain">(<a href="https://www.bloomberg.com">www.bloomberg.com</a>)</span></div><div class="subtext"><span>jbredeche</span> | <span>374 comments</span></div><br/><div><div id="41986040" class="c"><input type="checkbox" id="c-41986040" checked=""/><div class="controls bullet"><span class="by">altbdoor</span><span>|</span><a href="#41993059">next</a><span>|</span><label class="collapse" for="c-41986040">[-]</label><label class="expand" for="c-41986040">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.is&#x2F;Il4QM" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;Il4QM</a></div><br/></div></div><div id="41993059" class="c"><input type="checkbox" id="c-41993059" checked=""/><div class="controls bullet"><span class="by">davidthewatson</span><span>|</span><a href="#41986040">prev</a><span>|</span><a href="#41988665">next</a><span>|</span><label class="collapse" for="c-41993059">[-]</label><label class="expand" for="c-41993059">[1 more]</label></div><br/><div class="children"><div class="content">Solving complex challenges from code to testing of complex systems full-stop is a page from Buchanan and Pirolli, combined:<p><a href="https:&#x2F;&#x2F;web.mit.edu&#x2F;jrankin&#x2F;www&#x2F;engin_as_lib_art&#x2F;Design_thinking.pdf" rel="nofollow">https:&#x2F;&#x2F;web.mit.edu&#x2F;jrankin&#x2F;www&#x2F;engin_as_lib_art&#x2F;Design_thin...</a><p><a href="https:&#x2F;&#x2F;www.efsa.europa.eu&#x2F;sites&#x2F;default&#x2F;files&#x2F;event&#x2F;180918-conference&#x2F;presentations&#x2F;20-3_07_Pirolli.pdf" rel="nofollow">https:&#x2F;&#x2F;www.efsa.europa.eu&#x2F;sites&#x2F;default&#x2F;files&#x2F;event&#x2F;180918-...</a><p>That is, a combination of wicked problems and human-computer sensemaking requiring iteration. Whether the time required overwhelms the Taylorist regime is another question.</div><br/></div></div><div id="41988665" class="c"><input type="checkbox" id="c-41988665" checked=""/><div class="controls bullet"><span class="by">thih9</span><span>|</span><a href="#41993059">prev</a><span>|</span><a href="#41991122">next</a><span>|</span><label class="collapse" for="c-41988665">[-]</label><label class="expand" for="c-41988665">[189 more]</label></div><br/><div class="children"><div class="content">I use cursor and its tab completion; while what it can do is mind blowing, in practice I’m not noticing a productivity boost.<p>I find that ai can help significantly with doing plumbing, but it has no problems with connecting the pipes wrong. I need to double and triple check the updated code - or fix the resulting errors when I don’t do that. So: boilerplate and outer app layers, yes; architecture and core libraries, no.<p>Curious, is that a property of all ai assisted tools for now? Or would copilot, perhaps with its new models, offer a different experience?</div><br/><div id="41989760" class="c"><input type="checkbox" id="c-41989760" checked=""/><div class="controls bullet"><span class="by">ianbutler</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41989002">next</a><span>|</span><label class="collapse" for="c-41989760">[-]</label><label class="expand" for="c-41989760">[116 more]</label></div><br/><div class="children"><div class="content">I&#x27;m actually very curious why AI use is such a bi-modal experience. I&#x27;ve used AI to move multi thousand line codebases between languages. I&#x27;ve created new apps from scratch with it.<p>My theory is the willingness to baby sit and the modality. I&#x27;m perfectly fine telling the tool I use its errors and working side by side with it like it was another person. At the end of the day it can belt out lines of code faster than I, or any human, can and I can review code very quickly so the overall productivity boost has been great.<p>It does fundamentally alter my workflow. I&#x27;m very hands off keyboard when I&#x27;m working with AI in a way that is much more like working with someone or coaching someone to make something instead of doing the making myself. Which I&#x27;m fine with but recognize many developers aren&#x27;t.<p>I use AI autocomplete 0% of the time as I found that workflow was not as effective as me just writing code, but most of my most successful work using AI is a chat dialogue where I&#x27;m letting it build large swaths of the project a file or parts of a file at a time, with me reviewing and coaching.</div><br/><div id="41989925" class="c"><input type="checkbox" id="c-41989925" checked=""/><div class="controls bullet"><span class="by">0xFACEFEED</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41992525">next</a><span>|</span><label class="collapse" for="c-41989925">[-]</label><label class="expand" for="c-41989925">[85 more]</label></div><br/><div class="children"><div class="content">As a programmer of over 20 years - this is terrifying.<p>I&#x27;m willing to accept that I just have &quot;get off my lawn&quot; syndrome or something.<p>But the idea of letting an LLM write&#x2F;move large swaths of code seems so incredibly irresponsible. Whenever I sit down to write some code, be it a large implementation or a small function, I think about what other people (or future versions of myself) will struggle with when interacting with the code. Is it clear and concise? Is it too clever? Is it too easy to write a subtle bug when making changes? Have I made it totally clear that X is relying on Y dangerous behavior by adding a comment or intentionally making it visible in some other way?<p>It goes the other way too. If I know someone well (or their style) then it makes evaluating their code easier. The more time I spend in a codebase the better idea I have of what the writer was trying to do. I remember spending a lot of time reading the early Redis codebase and got a pretty good sense of how Salvatore thinks. Or altering my approaches to code reviews depending on which coworker was submitting it. These weren&#x27;t things I were doing out of desire but because all non-trivial code has so much subtlety; it&#x27;s just the nature of the beast.<p>So the thought of opening up a codebase that was cobbled together by an AI is just scary to me. Subtle bugs and errors would be equally distributed across the whole thing instead of where the writer was less competent (as is often the case). The whole thing just sounds like a gargantuan mess.<p>Change my mind.</div><br/><div id="41990274" class="c"><input type="checkbox" id="c-41990274" checked=""/><div class="controls bullet"><span class="by">hansonkd</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41992643">next</a><span>|</span><label class="collapse" for="c-41990274">[-]</label><label class="expand" for="c-41990274">[21 more]</label></div><br/><div class="children"><div class="content">&gt; The more time I spend in a codebase the better idea I have of what the writer was trying to do.<p>This whole thing of using LLMs to Code reminds me a bit of when Google Translate came out and became popular, right around the time I started studying Russian.<p>Yes, copying and pasting a block of Russian text produced a block of english text that you could get a general idea of what was happening. But translating from english to russian rarely worked well enough to fool the professor because of all the idioms, style, etc. Russian has a lot of ways you can write &quot;compactly&quot; with fewer words than english and have a much more precise meaning of the sentence. (I always likened russian to type-safe haskell and english to dynamic python)<p>If you actually understood Russian and read the text, you could uncover much deeper and subtle meaning and connections that get lost in translation.<p>If you went to russia today you could get around with google translate and people would understand you. But you aren&#x27;t going to be having anything other than surface level requests and responses.<p>Coding with LLMs reminds me a lot of this. Yes, they produce something that the computer understands and runs, but the meaning and intention of what you wanted to communicate gets lost through this translation layer.<p>Coding is even worse because i feel like the intention of coding should never to be to belt out as many lines as possible. Coding has powerful abstractions that you can use to minimize the lines you write and crystalize meaning and intent.</div><br/><div id="41992805" class="c"><input type="checkbox" id="c-41992805" checked=""/><div class="controls bullet"><span class="by">azangru</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990274">parent</a><span>|</span><a href="#41990593">next</a><span>|</span><label class="collapse" for="c-41992805">[-]</label><label class="expand" for="c-41992805">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Russian has a lot of ways you can write &quot;compactly&quot; with fewer words than english and have a much more precise meaning of the sentence. (I always likened russian to type-safe haskell and english to dynamic python)<p>Funny; my experience has been completely the opposite. I&#x27;ve always envied the English language for how compactly and precisely it can express meaning compared to Russian, both because of an immensely rich vocabulary, and because of the very flexible grammar.<p>I suspect this difference in perception may be due to comparing original texts, especially ones produced by excellent writers or ones that have been polished by generations that use them, to translations, which are almost invariably stylistically inferior to the original: less creative, less playful, less punchy, less succinct. So, if you translate a good Russian writer who is a master of his craft into English, you may feel the inadequacy of the language. Likewise, whenever I try to read translations of English prose into Russian, it reads clumsy and depressingly weak.</div><br/><div id="41993024" class="c"><input type="checkbox" id="c-41993024" checked=""/><div class="controls bullet"><span class="by">pastage</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992805">parent</a><span>|</span><a href="#41990593">next</a><span>|</span><label class="collapse" for="c-41993024">[-]</label><label class="expand" for="c-41993024">[1 more]</label></div><br/><div class="children"><div class="content">Translating is an interpretation of the original text. A translated book can be better than the original. But you often need mastery of the language you translate to.</div><br/></div></div></div></div><div id="41990593" class="c"><input type="checkbox" id="c-41990593" checked=""/><div class="controls bullet"><span class="by">balder1991</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990274">parent</a><span>|</span><a href="#41992805">prev</a><span>|</span><a href="#41992513">next</a><span>|</span><label class="collapse" for="c-41990593">[-]</label><label class="expand" for="c-41990593">[8 more]</label></div><br/><div class="children"><div class="content">&gt; the intention of coding should never to be to belt out as many lines as possible<p>That’s such an underrated statement. Especially when you consider the amount of code as a liability that you’ll have to take care later.</div><br/><div id="41991531" class="c"><input type="checkbox" id="c-41991531" checked=""/><div class="controls bullet"><span class="by">abadpoli</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990593">parent</a><span>|</span><a href="#41990945">next</a><span>|</span><label class="collapse" for="c-41991531">[-]</label><label class="expand" for="c-41991531">[4 more]</label></div><br/><div class="children"><div class="content">This presumes that it will be real humans that have to “take care” of the code later.<p>A lot of the people that are hawking AI, especially in management, are chasing a future where there are no humans, because AI writes the code and maintains the code, no pesky expensive humans needed. And AI won’t object to things like bad code style or low quality code.</div><br/><div id="41992153" class="c"><input type="checkbox" id="c-41992153" checked=""/><div class="controls bullet"><span class="by">tivert</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991531">parent</a><span>|</span><a href="#41992519">next</a><span>|</span><label class="collapse" for="c-41992153">[-]</label><label class="expand" for="c-41992153">[1 more]</label></div><br/><div class="children"><div class="content">Well that will work great if you let the AI decide if the code is working or not.<p>User: This is calculating the result wrong.<p>AI: CLOSED WONTFIX: WORKING AS DESIGNED.</div><br/></div></div><div id="41992519" class="c"><input type="checkbox" id="c-41992519" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991531">parent</a><span>|</span><a href="#41992153">prev</a><span>|</span><a href="#41992200">next</a><span>|</span><label class="collapse" for="c-41992519">[-]</label><label class="expand" for="c-41992519">[1 more]</label></div><br/><div class="children"><div class="content">&gt;AI writes the code<p>AI will never write proper code unless guided by someone who knows how to properly code and how to properly translate business needs into code.</div><br/></div></div><div id="41992200" class="c"><input type="checkbox" id="c-41992200" checked=""/><div class="controls bullet"><span class="by">jkestner</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991531">parent</a><span>|</span><a href="#41992519">prev</a><span>|</span><a href="#41990945">next</a><span>|</span><label class="collapse" for="c-41992200">[-]</label><label class="expand" for="c-41992200">[1 more]</label></div><br/><div class="children"><div class="content">All you got to do is write the unit tests and let the AI evolve the code, right??</div><br/></div></div></div></div><div id="41990945" class="c"><input type="checkbox" id="c-41990945" checked=""/><div class="controls bullet"><span class="by">mreid</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990593">parent</a><span>|</span><a href="#41991531">prev</a><span>|</span><a href="#41991874">next</a><span>|</span><label class="collapse" for="c-41990945">[-]</label><label class="expand" for="c-41990945">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve heard a similar sentiment: &quot;It&#x27;s not lines of code written, it&#x27;s lines of code spent.&quot;<p>It also reminds me of this analogy for data, especially sensitive data: &quot;it&#x27;s not oil, it&#x27;s nuclear waste.&quot;</div><br/></div></div><div id="41991874" class="c"><input type="checkbox" id="c-41991874" checked=""/><div class="controls bullet"><span class="by">grbsh</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990593">parent</a><span>|</span><a href="#41990945">prev</a><span>|</span><a href="#41992513">next</a><span>|</span><label class="collapse" for="c-41991874">[-]</label><label class="expand" for="c-41991874">[2 more]</label></div><br/><div class="children"><div class="content">I think this is a bit short sighted, but I’m not sure how short. I suspect in the future, code will be something in between what it is today, and a build artifact. Do you have to maintain bytecode?</div><br/><div id="41992178" class="c"><input type="checkbox" id="c-41992178" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991874">parent</a><span>|</span><a href="#41992513">next</a><span>|</span><label class="collapse" for="c-41992178">[-]</label><label class="expand" for="c-41992178">[1 more]</label></div><br/><div class="children"><div class="content">People working on VMs have to maintain compatibility with old bytecode and evolve the bytecode format forward, does that count?</div><br/></div></div></div></div></div></div><div id="41992513" class="c"><input type="checkbox" id="c-41992513" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990274">parent</a><span>|</span><a href="#41990593">prev</a><span>|</span><a href="#41992848">next</a><span>|</span><label class="collapse" for="c-41992513">[-]</label><label class="expand" for="c-41992513">[1 more]</label></div><br/><div class="children"><div class="content">Coding isn&#x27;t the hard part. The hard part is translating the business needs in code.<p>You can tell a junior programmer &quot;Make a DB with tables book, author, has Written, customer, stock, hasBought, with the following rules between them. Write a repository, for that DB. Use repository in BooksService and BasketService. Use those services in Books controller and Basket controller.&quot; and he will do a fine job.<p>Ask the junior to write an API for a book store and he will have a harder time.</div><br/></div></div><div id="41992848" class="c"><input type="checkbox" id="c-41992848" checked=""/><div class="controls bullet"><span class="by">Etherlord87</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990274">parent</a><span>|</span><a href="#41992513">prev</a><span>|</span><a href="#41991514">next</a><span>|</span><label class="collapse" for="c-41992848">[-]</label><label class="expand" for="c-41992848">[1 more]</label></div><br/><div class="children"><div class="content">I think translating to russian wasn&#x27;t worse than translating to English because &quot;russian is more compact&quot;.<p>Probably it was worse, because people in charge in Google speak English. It was embarrassing to watch Google conferences where they proposed Google Translate to translate professional products. It&#x27;s similarly embarrassing watching people proposing chatGPT lightly, because they lack the ability, or probably just don&#x27;t care to, analyze the problem thoroughly.</div><br/></div></div><div id="41991514" class="c"><input type="checkbox" id="c-41991514" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990274">parent</a><span>|</span><a href="#41992848">prev</a><span>|</span><a href="#41991219">next</a><span>|</span><label class="collapse" for="c-41991514">[-]</label><label class="expand" for="c-41991514">[7 more]</label></div><br/><div class="children"><div class="content">I had the opposite experience lately:<p>I was helping translate some UI text for a website from English to German, my mother tongue.  I found that usually the machine came up with better translations than me.</div><br/><div id="41992303" class="c"><input type="checkbox" id="c-41992303" checked=""/><div class="controls bullet"><span class="by">patrickk</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991514">parent</a><span>|</span><a href="#41991982">next</a><span>|</span><label class="collapse" for="c-41992303">[-]</label><label class="expand" for="c-41992303">[3 more]</label></div><br/><div class="children"><div class="content">English and German are EU languages. Russian is not.<p>The EU maintains a large translation service to translate most EU official texts into all EU languages. So Google Translate is using that to train on. Google gets a free gift from a multinational bureaucracy and gets to look like a smart company in the process.<p>This is also why English-Mandarin is often poorly translated, in my opinion.</div><br/><div id="41992675" class="c"><input type="checkbox" id="c-41992675" checked=""/><div class="controls bullet"><span class="by">arthur_sav</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992303">parent</a><span>|</span><a href="#41992646">next</a><span>|</span><label class="collapse" for="c-41992675">[-]</label><label class="expand" for="c-41992675">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t that mean it&#x27;s just inevitable what will happen.<p>The question is not longer IF machines are capable, the question is WHEN. And the when is no longer decades away.</div><br/></div></div><div id="41992646" class="c"><input type="checkbox" id="c-41992646" checked=""/><div class="controls bullet"><span class="by">71bw</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992303">parent</a><span>|</span><a href="#41992675">prev</a><span>|</span><a href="#41991982">next</a><span>|</span><label class="collapse" for="c-41992646">[-]</label><label class="expand" for="c-41992646">[1 more]</label></div><br/><div class="children"><div class="content">&gt;This is also why English-Mandarin is often poorly translated, in my opinion.<p>Shockingly, this is something that Yandex Translate absolutely excels at.</div><br/></div></div></div></div><div id="41991982" class="c"><input type="checkbox" id="c-41991982" checked=""/><div class="controls bullet"><span class="by">amake</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991514">parent</a><span>|</span><a href="#41992303">prev</a><span>|</span><a href="#41991219">next</a><span>|</span><label class="collapse" for="c-41991982">[-]</label><label class="expand" for="c-41991982">[3 more]</label></div><br/><div class="children"><div class="content">Perhaps you are not a translator. Translating is a skill that is more than simply being bilingual.</div><br/><div id="41992080" class="c"><input type="checkbox" id="c-41992080" checked=""/><div class="controls bullet"><span class="by">tkgally</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991982">parent</a><span>|</span><a href="#41991219">next</a><span>|</span><label class="collapse" for="c-41992080">[-]</label><label class="expand" for="c-41992080">[2 more]</label></div><br/><div class="children"><div class="content">I am a professional translator, and I have been using LLMs to speed up and, yes, improve my translations for a year and a half.<p>When properly prompted, the LLMs produce reasonably accurate and natural translations, but sometimes there are mistakes (often the result of ambiguities in the source text) or the sentences don’t flow together as smoothly as I would like. So I check and polish the translations sentence by sentence. While I’m doing that, I sometimes encounter a word or phrase that just doesn’t sound right to me but that I can’t think how to fix. In those cases, I give the LLMs the original and draft translation and ask for ten variations of the problematic sentence. Most of the suggestions wouldn’t work well, but there are usually two or three that I like and that are better than what I could come up with on my own.<p>Lately I have also been using LLMs as editors: I feed one the entire source text and the draft translation, and I ask for suggestions for corrections and improvements to the translation. I adopt the suggestions I like, and then I run the revised translation through another LLM with the same prompt. After five or six iterations, I do a final read-through of the translation to make sure everything is okay.<p>My guess is that using LLMs like this cuts my total translation time by close to half while raising the quality of the finished product by some significant but difficult-to-quantify amount.<p>This process became feasible only after ChatGPT, Claude, and Gemini got longer context windows. Each new model release has performed better than the previous one, too. I’ve also tried open-weight models, but they were significantly worse for Japanese to English, the direction I translate.<p>Although I am not a software developer, I’ve been following the debates on HN about whether or not LLMs are useful as coding assistants with much interest. My guess is that the disagreements are due partly to the different work situations of the people on both sides of the issue. But I also wonder if some of those who reject AI assistance just haven’t been able to find a suitable interactive workflow for using it.</div><br/><div id="41992554" class="c"><input type="checkbox" id="c-41992554" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992080">parent</a><span>|</span><a href="#41991219">next</a><span>|</span><label class="collapse" for="c-41992554">[-]</label><label class="expand" for="c-41992554">[1 more]</label></div><br/><div class="children"><div class="content">&gt; While I’m doing that, I sometimes encounter a word or phrase that just doesn’t sound right to me but that I can’t think how to fix. In those cases, I give the LLMs the original and draft translation and ask for ten variations of the problematic sentence. Most of the suggestions wouldn’t work well, but there are usually two or three that I like and that are better than what I could come up with on my own.<p>Yes, coming up with variations that work better (and hit the right connotations) is what I used the machine for, too.</div><br/></div></div></div></div></div></div></div></div><div id="41991219" class="c"><input type="checkbox" id="c-41991219" checked=""/><div class="controls bullet"><span class="by">atrettel</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990274">parent</a><span>|</span><a href="#41991514">prev</a><span>|</span><a href="#41992643">next</a><span>|</span><label class="collapse" for="c-41991219">[-]</label><label class="expand" for="c-41991219">[1 more]</label></div><br/><div class="children"><div class="content">This is a great analogy.  I find myself thinking that by abstracting the entire design process when coding something using generative AI tools, you tend to lose track of fine details by only concentrating on the overall function.<p>Maybe the code works, but does it integrate well with the rest of the codebase?  Do the data structures that it created follow the overall design principles for your application?  For example, does it make the right tradeoffs between time and space complexity for this application?  For certain applications, memory may be an issue and while code the may work, it uses too much memory to be useful in practice.<p>These are the kind of problems that I think about, and it aligns with your analogy.  There is in fact something &quot;lost through this translation layer&quot;.</div><br/></div></div></div></div><div id="41992643" class="c"><input type="checkbox" id="c-41992643" checked=""/><div class="controls bullet"><span class="by">KronisLV</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41990274">prev</a><span>|</span><a href="#41991479">next</a><span>|</span><label class="collapse" for="c-41992643">[-]</label><label class="expand" for="c-41992643">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I think about what other people (or future versions of myself) will struggle with when interacting with the code.<p>This feels like the sign of a good developer!<p>On the other hand, sometimes you just need executable line noise that gets the job done by Thursday so you can ship it and think about refactoring later.<p>As far as AI code goes, more often than not, it will read as something very generic, which is not necessarily a bad thing. When opening yet another Java CRUD project, I’d be more happy to see someone copy and pasting working code from tutorials or resources online (while it still works correctly), as opposed to seeing people develop bespoke systems on top of what a framework provides for every project.</div><br/><div id="41992859" class="c"><input type="checkbox" id="c-41992859" checked=""/><div class="controls bullet"><span class="by">Etherlord87</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992643">parent</a><span>|</span><a href="#41991479">next</a><span>|</span><label class="collapse" for="c-41992859">[-]</label><label class="expand" for="c-41992859">[1 more]</label></div><br/><div class="children"><div class="content">&gt; On the other hand, sometimes you just need executable line noise that gets the job done by Thursday so you can ship it and think about refactoring later.<p>This is a problem too. ChatGPT enables you to write bad code.<p>It&#x27;s like Adobe Flash: flash using websites didn&#x27;t have to be slow, but it was easy to make a slow website with it.</div><br/></div></div></div></div><div id="41991479" class="c"><input type="checkbox" id="c-41991479" checked=""/><div class="controls bullet"><span class="by">dools</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41992643">prev</a><span>|</span><a href="#41990206">next</a><span>|</span><label class="collapse" for="c-41991479">[-]</label><label class="expand" for="c-41991479">[4 more]</label></div><br/><div class="children"><div class="content">&gt; But the idea of letting an LLM write&#x2F;move large swaths of code seems so incredibly irresponsible<p>I heard a similar thing from a dude when I said I use it for bash scripts instead of copying and pasting things off StackOverflow.<p>He was a bit &quot;get off my lawny&quot; about the idea of running any code you didn&#x27;t write, especially bash scripts in a terminal.<p>It is obviously the case that I didn&#x27;t write most of the code in the world by a very large margin, but even not taking it to extremes if I&#x27;m working on a team and people are writing code how is it any different? Everyone makes mistakes, I make mistakes.<p>I think it&#x27;s a bad idea to run things that you don&#x27;t at least understand what it&#x27;s going to do but the speed with which ChatGPT can produce, for example, gcloud shell commands to manage resources is lightning fast (all of which is very readable, just takes a while if you want to look it up and compose the commands yourself).<p>If your quality control method is &quot;making sure there are no mistakes&quot; then it&#x27;s already broken regardless of where the code comes from. Me reviewing AI code is no different from me reviewing anyone else&#x27;s code.<p>Me testing AI code using unit or integration tests is no different from testing anyone else&#x27;s code, or my own code for that matter.</div><br/><div id="41991750" class="c"><input type="checkbox" id="c-41991750" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991479">parent</a><span>|</span><a href="#41991775">next</a><span>|</span><label class="collapse" for="c-41991750">[-]</label><label class="expand" for="c-41991750">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Me reviewing AI code is no different from me reviewing anyone else&#x27;s code.<p>I take your point, and on the whole I agree with your post, but this point is fundamentally _not_ correct, in that if I have a question about someone else&#x27;s code I can ask them about their intention, state-of-mind, and understanding at the time they wrote it, and (subjectively, sure; but I think this is a reasonable claim) can _usually_ detect pretty well if they are bullshitting me when they respond. Asking AI for explanations tends to lead to extremely convincing and confident false justifications rather than an admission of error or doubt.<p>However:<p>&gt; Me testing AI code using unit or integration tests is no different from testing anyone else&#x27;s code, or my own code for that matter.<p>This is totally fair</div><br/><div id="41992236" class="c"><input type="checkbox" id="c-41992236" checked=""/><div class="controls bullet"><span class="by">mikeshi42</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991750">parent</a><span>|</span><a href="#41991775">next</a><span>|</span><label class="collapse" for="c-41992236">[-]</label><label class="expand" for="c-41992236">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m assuming by bullshitting you mean differentiating between LLM hallucinations and a human with low confidence in their code.<p>I&#x27;ve found that LLMs do sometimes acknowledge hallucinations. But really the check is much easier than a PR&#x2F;questioning an author - just run the code given by the copilot and check that it works, just as if you typed it yourself.</div><br/></div></div></div></div><div id="41991775" class="c"><input type="checkbox" id="c-41991775" checked=""/><div class="controls bullet"><span class="by">AdieuToLogic</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991479">parent</a><span>|</span><a href="#41991750">prev</a><span>|</span><a href="#41990206">next</a><span>|</span><label class="collapse" for="c-41991775">[-]</label><label class="expand" for="c-41991775">[1 more]</label></div><br/><div class="children"><div class="content">Multiple times in my s&#x2F;w development career, I&#x27;ve had supervisors ask me why I am not typing code throughout the work day.<p>My response each time was along the lines of:<p><pre><code>  When I write code, it is to reify the part of a solution which
  I understand.  This includes writing tests to certify same.

  There is no reason to do so before then.</code></pre></div><br/></div></div></div></div><div id="41990206" class="c"><input type="checkbox" id="c-41990206" checked=""/><div class="controls bullet"><span class="by">sbarre</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41991479">prev</a><span>|</span><a href="#41990841">next</a><span>|</span><label class="collapse" for="c-41990206">[-]</label><label class="expand" for="c-41990206">[8 more]</label></div><br/><div class="children"><div class="content">I think it depends on the stakes of what you&#x27;re building.<p>A lot of the concerns you describe make me think you work in a larger company or team and so both the organizational stakes (maintenance, future changes, tech debt, other people taking it over) and the functional stakes (bug free, performant, secure, etc) are high?<p>If the person you&#x27;re responding to is cranking out a personal SaaS project or something they won&#x27;t ever want to maintain much, then they can do different math on risks.<p>And probably also the language you&#x27;re using, and the actual code itself.<p>Porting a multi-thousand line web SaaS product in Typescript that&#x27;s just CRUD operations and cranking out web views?  Sure why not.<p>Porting a multi-thousand line game codebase that&#x27;s performance-critical and written in C++?  Probably not.<p>That said, I am super fascinated by the approach of &quot;let the LLM write the code and coach it when it gets it wrong&quot; and I feel like I want to try that..  But probably not on a work project, and maybe just on a personal project.</div><br/><div id="41990498" class="c"><input type="checkbox" id="c-41990498" checked=""/><div class="controls bullet"><span class="by">tetha</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990206">parent</a><span>|</span><a href="#41991206">next</a><span>|</span><label class="collapse" for="c-41990498">[-]</label><label class="expand" for="c-41990498">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Porting a multi-thousand line web SaaS product in Typescript that&#x27;s just CRUD operations and cranking out web views? Sure why not.
&gt;
&gt; Porting a multi-thousand line game codebase that&#x27;s performance-critical and written in C++? Probably not.<p>From my own experience:<p>I really enjoy CoPilot to support me writing a terraform provider. I think this works well because we have hundreds of existing terraform providers with the same boilerplate and the same REST-handling already. Here, the LLM can crank out oodles and oodles of identical boilerplate that&#x27;s easy to review and deal with. Huge productivity boost. Maybe we should have better frameworks and languages for this, but alas...<p>I&#x27;ve also tried using CoPilot on a personal Godot project. I turned it off after a day, because it was so distracting with nonsense. Thinking about it along these lines, I would not be surprised if this occurred because the high-level code of games (think what AAA games do in Lua, and well what Godot does in GDScript) tends to be small-volume and rather erratic within there. Here there is no real pattern to follow.<p>This could also be a cause for the huge difference in LLM productivity boosts people report. If you need Spring Boot code to put query params into an ORM and turn that into JSON, it can probably do that. If you need embedded C code for an obscure micro controller.. yeah, good luck.</div><br/><div id="41990537" class="c"><input type="checkbox" id="c-41990537" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990498">parent</a><span>|</span><a href="#41991206">next</a><span>|</span><label class="collapse" for="c-41990537">[-]</label><label class="expand" for="c-41990537">[2 more]</label></div><br/><div class="children"><div class="content">&gt; If you need embedded C code for an obscure micro controller.. yeah, good luck.<p>... or even information in the embedded world. LLMs need to generate something, o they&#x27;ll generate code even when the answer is &quot;no dude, your chip doesn&#x27;t support that&quot;.</div><br/><div id="41991753" class="c"><input type="checkbox" id="c-41991753" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990537">parent</a><span>|</span><a href="#41991206">next</a><span>|</span><label class="collapse" for="c-41991753">[-]</label><label class="expand" for="c-41991753">[1 more]</label></div><br/><div class="children"><div class="content">&gt; they&#x27;ll generate code even when the answer is &quot;no dude, your chip doesn&#x27;t support that&quot;.<p>This is precisely the problem. As I point out elsewhere[0], reviewing AI-generated code is _not_ the same thing as reviewing code written by someone else, because you can ask a human author what they were thinking and get a moderately-honest response; whereas an AI will confidently and convincingly lie to you.<p>[0] <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41991750">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41991750</a></div><br/></div></div></div></div></div></div><div id="41991206" class="c"><input type="checkbox" id="c-41991206" checked=""/><div class="controls bullet"><span class="by">ehnto</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990206">parent</a><span>|</span><a href="#41990498">prev</a><span>|</span><a href="#41990320">next</a><span>|</span><label class="collapse" for="c-41991206">[-]</label><label class="expand" for="c-41991206">[2 more]</label></div><br/><div class="children"><div class="content">I am quite interested in how LLMs would handle game development. Coming to game development from a long career in boutique applications and also enterprise software, game development is a whole different level of &quot;boutique&quot;.<p>I think both because of the coupled, convoluted complexity of much game logic, and because there are fewer open source examples of novel game code available to train on, they may struggle to be as useful.</div><br/><div id="41992250" class="c"><input type="checkbox" id="c-41992250" checked=""/><div class="controls bullet"><span class="by">Tiktaalik</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991206">parent</a><span>|</span><a href="#41990320">next</a><span>|</span><label class="collapse" for="c-41992250">[-]</label><label class="expand" for="c-41992250">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I think the lack of game code available to train on could be a problem. There&#x27;s a fair amount of &quot;black art&quot; type problems in games too that a LLM may struggle with just because there&#x27;s not a lot to go on.<p>Additionally the problems of custom engines and game specific patterns.<p>That being said there&#x27;s parts of games with boilerplate code like any application. In a past game as I was finishing it up some of this AI stuff was first becoming useable and I experimented with generating some boilerplate classes with high level descriptions of what I wanted and it did a pretty decent job.<p>I think some of the most significant productivity gains for games is going to be less on the code side and more in the technical art space.</div><br/></div></div></div></div><div id="41990320" class="c"><input type="checkbox" id="c-41990320" checked=""/><div class="controls bullet"><span class="by">0xFACEFEED</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990206">parent</a><span>|</span><a href="#41991206">prev</a><span>|</span><a href="#41990841">next</a><span>|</span><label class="collapse" for="c-41990320">[-]</label><label class="expand" for="c-41990320">[2 more]</label></div><br/><div class="children"><div class="content">&gt; A lot of the concerns you describe make me think you work in a larger company or team and so both the organizational stakes (maintenance, future changes, tech debt, other people taking it over) and the functional stakes (bug free, performant, secure, etc) are high?<p>The most financially rewarding project I worked on started out as an early stage startup with small ambitions. It ended up growing and succeeding far beyond expectations.<p>It was a small codebase but the stakes were still very high. We were all pretty experienced going into it so we each had preferences for which footguns to avoid. For example we shied away from ORMs because they&#x27;re the kind of dependency that could get you stuck in mud. Pick a &quot;bad&quot; ORM, spend months piling code on top of it, and then find out that you&#x27;re spending more time fighting it than being productive. But now you don&#x27;t have the time to untangle yourself from that dependency. Worst of all, at least in our experience, it&#x27;s impossible to really predict how likely you are to get &quot;stuck&quot; this way with a large dependency. So the judgement call was to avoid major dependencies like this unless we absolutely had to.<p>I attribute the success of our project to literally thousands of minor and major decisions like that one.<p>To me almost all software is high stakes. Unless it&#x27;s so trivial that nothing about it matters at all; but that&#x27;s not what these AI tools are marketing toward, are they?<p>Something might start out as a small useful library and grow into a dependency that hundreds of thousands of people use.<p>So that&#x27;s why it terrifies me. I&#x27;m terrified of one day joining a team or wanting to contribute to an OSS project - only to be faced with thousands of lines of nonsensical autogenerated LLM code. If nothing else it takes all the joy out of programming computers (although I think there&#x27;s a more existential risk here). If it was a team I&#x27;d probably just quit on the spot but I have that luxury and probably would have caught it during due diligence. If it&#x27;s an OSS project I&#x27;d nope out and not contribute.</div><br/><div id="41991083" class="c"><input type="checkbox" id="c-41991083" checked=""/><div class="controls bullet"><span class="by">mistrial9</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990320">parent</a><span>|</span><a href="#41990841">next</a><span>|</span><label class="collapse" for="c-41991083">[-]</label><label class="expand" for="c-41991083">[1 more]</label></div><br/><div class="children"><div class="content">adding here due to some resonance with the point of view.. this exchange lacks crucial axes.. what kind of programming ?<p>I assume the parent-post is saying &quot;I ported thousands of lines of &lt;some C family executing on a server&gt; to &lt;python on standard cloud environments&gt;.  I could be very wrong but that is my guess. Like any data-driven software machinery, there is massive inherent bias and extra resources for &lt;current in-demand thing&gt; in this guess-case it is python that runs on a standard cloud environment with the loaders and credentials parts too perhaps.<p>Those who learned programming in the theoretic ways know that many, many software systems are possible in various compute contexts. And those working on hardware teams know that there are a lot of kinds of computing hardware. And to add another off-the-cuff idea, so much web interface ala 2004 code to bring to newer, cleaner setups.<p>I am not &lt;emotional state descriptor&gt; about this sea change in code generation, but actually code generation is not at all new. It is the blatent stealing and LICENSE washing of a generation of OSS that gets me, actually. Those code generation machines are repeating their inputs.  No authors agreed and no one asked them, either.</div><br/></div></div></div></div></div></div><div id="41990841" class="c"><input type="checkbox" id="c-41990841" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41990206">prev</a><span>|</span><a href="#41992445">next</a><span>|</span><label class="collapse" for="c-41990841">[-]</label><label class="expand" for="c-41990841">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But the idea of letting an LLM write&#x2F;move large swaths of code seems so incredibly irresponsible.<p>I do think it is kind of crazy based on what I&#x27;ve seen. I&#x27;m convinced LLM is a game changer but I couldn&#x27;t believe how stupid it can be.  Take the following example, which is a spelling and grammar checker that I wrote:<p><a href="https:&#x2F;&#x2F;app.gitsense.com&#x2F;?doc=f7419bfb27c8968bae&amp;samples=5" rel="nofollow">https:&#x2F;&#x2F;app.gitsense.com&#x2F;?doc=f7419bfb27c8968bae&amp;samples=5</a><p>If you click on the sentence, you can see that Claude-3.5 and GPT-4o cannot tell that GitHub is spelled correctly most of the time. It was this example that made me realize how dangerous LLM can be. The sentence is short but Claude-3.5 and GPT-4o just can&#x27;t process it properly.<p>Having a LLM rewrite large swaths of code is crazy but I believe with proper tooling to verify and challenge changes, we can mitigate the risk.<p>I&#x27;m just speculating, but I believe GitHub has come to the same conclusion that I have, which is, all models can be stupid, but it is unlikely that all will be stupid at the same time.</div><br/></div></div><div id="41992445" class="c"><input type="checkbox" id="c-41992445" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41990841">prev</a><span>|</span><a href="#41990262">next</a><span>|</span><label class="collapse" for="c-41992445">[-]</label><label class="expand" for="c-41992445">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Whenever I sit down to write some code, be it a large implementation or a small function, I think about what other people (or future versions of myself) will struggle with when interacting with the code. Is it clear and concise? Is it too clever? Is it too easy to write a subtle bug when making changes? Have I made it totally clear that X is relying on Y dangerous behavior by adding a comment or intentionally making it visible in some other way?<p>Over 20 years of experience, too, but I quit doing that for work. Nobody really really cares, all they care is about time to market and having features they&#x27;ve sold yesterday to customers being done today.<p>As long as I follow some mental models and some rules, the code is reasonably well written and there is no need to procrastinate and think too much.<p>When I write code for myself, or I am contributing to a small project with a small number of contributors, then things change. If I can afford and I like it I am not only willing to assure things are carefully thought out, but also I am willing to experiment and test until I am sure that I use the best variant I can come up with. Like going from 99% to 99.9%, even if it wouldn&#x27;t matter in practice. Just for fun.<p>As a manager, I wouldn&#x27;t ask people to write perfect code, nor I would like them to ship buggy code very fast, but ship reasonably good code as fast as they can write reasonable good code.</div><br/></div></div><div id="41990262" class="c"><input type="checkbox" id="c-41990262" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41992445">prev</a><span>|</span><a href="#41990413">next</a><span>|</span><label class="collapse" for="c-41990262">[-]</label><label class="expand" for="c-41990262">[11 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll take a stab at changing your mind.<p>AIs are not able to write Redis. That&#x27;s not their job. AIs should not write complex high performance code that millions of users rely on. If the code does something valuable for a large number of people you can afford humans to write it.<p>AIs should write low value code that just repeats what&#x27;s been done before but with some variations. Generic parts of CRUD apps, some fraction of typical frontends, common CI setups.
That&#x27;s what they&#x27;re good at because they&#x27;ve seen it a million times already. That category constitutes most code written.<p>This relieves human developers of ballpark 20% of their workload and that&#x27;s already worth a lot of money.</div><br/><div id="41992550" class="c"><input type="checkbox" id="c-41992550" checked=""/><div class="controls bullet"><span class="by">takeda</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990262">parent</a><span>|</span><a href="#41990835">next</a><span>|</span><label class="collapse" for="c-41992550">[-]</label><label class="expand" for="c-41992550">[1 more]</label></div><br/><div class="children"><div class="content">So maybe that&#x27;s the issue I&#x27;m having.<p>I spent may entire career trying to eliminate such code as much as I can, so then having copilot write code that I have to fix on almost every step. I frequently have to look for subtle issues and few times they sneaked through, when it produces correct code it frequently is often more verbose than my code.</div><br/></div></div><div id="41990835" class="c"><input type="checkbox" id="c-41990835" checked=""/><div class="controls bullet"><span class="by">photonthug</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990262">parent</a><span>|</span><a href="#41992550">prev</a><span>|</span><a href="#41992578">next</a><span>|</span><label class="collapse" for="c-41990835">[-]</label><label class="expand" for="c-41990835">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ll take a stab at changing your mind.<p>Not the parent but this doesn’t seem mind changing, because what you describe is the normal&#x2F;boring route to slightly better productivity using new tools without the breathless hype. And the 20% increase you mention of course depends a lot on what you’re doing, so for many types of work you’d be much closer to zero.<p>I’m curious about the claims of “power users” that are talking very excitedly about a brave new world.  Are they fooling themselves, or trying to fool others, or working at jobs where 90% of their work is boilerplate drudgery, or what exactly?  Inevitably it’s all of the above.. and some small percentage of real power users that could probably teach the rest of us cool stuff about their unique workflows.  Not sure how to find the signal in all the noise though.<p>So personally, if I were to write “change my mind”, what I’d really mean is something like “convince me there are real power users already out there in the wild, using tools that are open to the public today”.<p>GP mentioned machine assisted translation of a huge code base being almost completely hands-off.  If that were true and as easy as advertised then one might expect, for example, that it were trivial to just rewrite media wiki or Wordpress in rails or Django with a few people in a week.  This is on the easier side of what I’d <i>confidently</i> label as a game-changingly huge productivity boost btw, and is a soft problem chosen because of the availability of existing code examples, mere translation over original work, etc.  Not sure we’re there yet.</div><br/></div></div><div id="41992578" class="c"><input type="checkbox" id="c-41992578" checked=""/><div class="controls bullet"><span class="by">hitradostava</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990262">parent</a><span>|</span><a href="#41990835">prev</a><span>|</span><a href="#41990449">next</a><span>|</span><label class="collapse" for="c-41992578">[-]</label><label class="expand" for="c-41992578">[1 more]</label></div><br/><div class="children"><div class="content">In a couple of years time I don&#x27;t see why AI based tooling couldn&#x27;t write Redis? Would you get a complete Redis produced with a single prompt? Of course not. but if extreme speed is what you want to optimize for, then the tooling needs to be given the right feedback loop to optimize for that.<p>I think the question to ask is what do I do as a software engineer that couldn&#x27;t be done by an AI based tool in a few years time? The answer is scary, but exciting.</div><br/></div></div><div id="41990449" class="c"><input type="checkbox" id="c-41990449" checked=""/><div class="controls bullet"><span class="by">0xFACEFEED</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990262">parent</a><span>|</span><a href="#41992578">prev</a><span>|</span><a href="#41990977">next</a><span>|</span><label class="collapse" for="c-41990449">[-]</label><label class="expand" for="c-41990449">[5 more]</label></div><br/><div class="children"><div class="content">I can definitely see the value in letting AI generate low stakes code. I&#x27;m a daily CoPilot user and, while I don&#x27;t let it generate implementations, the suggestions it gives for boilerplate-y things is top notch. Love it as a tool.<p>My major issue with your position is that, at least in my experience, good software is the sum of even the seemingly low risk parts. When I think of real world software that people rely on (the only type I care about in this context) then it&#x27;s hard to point a finger at some part of it and go &quot;eh, this part doesn&#x27;t matter&quot;. It all matters.<p>The alternative, I fear, is 90% of the software we use exhibiting subtle goofy behavior and just being overall unpleasant to use.<p>I guess an analogy for my concern is what it would look like if 60% of every film was AI generated using the models we have today. Some might argue that 60% of all films are low stakes scenes with simple exposition or whatever. And then remaining 40% are the climax or other important moments. But many people believe that 100% of the film matters - even the opening credits.<p>And even if none of that were an issue: in my experience it&#x27;s very difficult to assess what part of an application will&#x2F;won&#x27;t be low&#x2F;high stakes. Imagine being a tech startup that needs to pivot your focus toward the low stakes part of the application that the LLM wrote.</div><br/><div id="41990741" class="c"><input type="checkbox" id="c-41990741" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990449">parent</a><span>|</span><a href="#41991550">next</a><span>|</span><label class="collapse" for="c-41990741">[-]</label><label class="expand" for="c-41990741">[2 more]</label></div><br/><div class="children"><div class="content">I think your concept of ‘what the AI wrote’ is too large. There is zero chance my one line copilot or three line cursor tab completions are going to have an effect on the overall quality of my codebase.<p>What it is useful for is doing exactly the things I already know need to happen, but don’t want to spend the effort to write out (at least, not having to do it is great).<p>Since my brain and focus aren’t killed by writing crud, I get to spend that on more useful stuff. If it doesn’t make me more effective, at least it makes my job more enjoyable.</div><br/><div id="41991047" class="c"><input type="checkbox" id="c-41991047" checked=""/><div class="controls bullet"><span class="by">0xFACEFEED</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990741">parent</a><span>|</span><a href="#41991550">next</a><span>|</span><label class="collapse" for="c-41991047">[-]</label><label class="expand" for="c-41991047">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m with you. I use Copilot every day in the way you&#x27;re describing and I love it. The person I was responding to is claiming to code &quot;hands off&quot; and let the AI write the majority of the software.</div><br/></div></div></div></div><div id="41991550" class="c"><input type="checkbox" id="c-41991550" checked=""/><div class="controls bullet"><span class="by">SoftTalker</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990449">parent</a><span>|</span><a href="#41990741">prev</a><span>|</span><a href="#41990977">next</a><span>|</span><label class="collapse" for="c-41991550">[-]</label><label class="expand" for="c-41991550">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The alternative, I fear, is 90% of the software we use exhibiting subtle goofy behavior and just being overall unpleasant to use.<p>This sounds like most software honestly.</div><br/><div id="41992044" class="c"><input type="checkbox" id="c-41992044" checked=""/><div class="controls bullet"><span class="by">0xFACEFEED</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991550">parent</a><span>|</span><a href="#41990977">next</a><span>|</span><label class="collapse" for="c-41992044">[-]</label><label class="expand" for="c-41992044">[1 more]</label></div><br/><div class="children"><div class="content">And that&#x27;s what LLMs are trained on.<p>Hahaha</div><br/></div></div></div></div></div></div><div id="41990977" class="c"><input type="checkbox" id="c-41990977" checked=""/><div class="controls bullet"><span class="by">skywhopper</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990262">parent</a><span>|</span><a href="#41990449">prev</a><span>|</span><a href="#41990413">next</a><span>|</span><label class="collapse" for="c-41990977">[-]</label><label class="expand" for="c-41990977">[2 more]</label></div><br/><div class="children"><div class="content">I have to disagree. If there’s that much boilerplate floating around then the tooling should be improved. Pasting over inefficiency with sloppier inefficiency is just a pure waste.</div><br/><div id="41992306" class="c"><input type="checkbox" id="c-41992306" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990977">parent</a><span>|</span><a href="#41990413">next</a><span>|</span><label class="collapse" for="c-41992306">[-]</label><label class="expand" for="c-41992306">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not boilerplate, it&#x27;s just uncomplicated but necessary specifications.<p>AI is the improved tooling.</div><br/></div></div></div></div></div></div><div id="41990413" class="c"><input type="checkbox" id="c-41990413" checked=""/><div class="controls bullet"><span class="by">mithametacs</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41990262">prev</a><span>|</span><a href="#41992458">next</a><span>|</span><label class="collapse" for="c-41990413">[-]</label><label class="expand" for="c-41990413">[4 more]</label></div><br/><div class="children"><div class="content">You still use type systems, tests, and code review.<p>For a lot of use cases it&#x27;s powerful.<p>If you ask it to build out a brand new system with a complex algorithm or to perform a more complex refactoring, it&#x27;ll be more work correcting it than doing it yourself.<p>But that malformed JSON document with the weird missing quotation marks (so the usual formatters break), and spaces before commas, and the indentation is wild...  Give it to an LLM.<p>Or when you&#x27;re writing content impls for a game based on a list of text descriptions, copy the text into a block comment.  Then impl 1 example.  Then just sit back and press tab and watch your profits.</div><br/><div id="41990806" class="c"><input type="checkbox" id="c-41990806" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990413">parent</a><span>|</span><a href="#41992458">next</a><span>|</span><label class="collapse" for="c-41990806">[-]</label><label class="expand" for="c-41990806">[3 more]</label></div><br/><div class="children"><div class="content">The (mostly useless boilerplate “I’m basically just testing my  mocks”) tests are being written by AI too these days.<p>Which is mildly annoying as a lot of those tests are basically just noise rather than useful tools. Humans have the same problem, but current models are especially prone to it from what I’ve observed<p>And not enough devs are babysitting the AI to make sure the test cases are useful, even if they’re doing so for the original code it produced</div><br/><div id="41991106" class="c"><input type="checkbox" id="c-41991106" checked=""/><div class="controls bullet"><span class="by">chillfox</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990806">parent</a><span>|</span><a href="#41992458">next</a><span>|</span><label class="collapse" for="c-41991106">[-]</label><label class="expand" for="c-41991106">[2 more]</label></div><br/><div class="children"><div class="content">There are very few tutorials on how to do testing and I don&#x27;t think I have ever seen one that was great. Compared to general coding stuff where there&#x27;s great tutorials available for all the most common things.<p>So I think quality testing is just not in the training data at anywhere close to the quantity needed.</div><br/><div id="41992775" class="c"><input type="checkbox" id="c-41992775" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991106">parent</a><span>|</span><a href="#41992458">next</a><span>|</span><label class="collapse" for="c-41992775">[-]</label><label class="expand" for="c-41992775">[1 more]</label></div><br/><div class="children"><div class="content">Testing well is both an art and a science, and I mean, just look at the dev community on the topic, some are religious about TDD, some say unit tests only, some say the whole range to e2e etc. etc. hard to have good training data when there is no definition of what is &quot;right&quot; in the first place!</div><br/></div></div></div></div></div></div></div></div><div id="41992458" class="c"><input type="checkbox" id="c-41992458" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41990413">prev</a><span>|</span><a href="#41991702">next</a><span>|</span><label class="collapse" for="c-41992458">[-]</label><label class="expand" for="c-41992458">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Change my mind.<p>Nobody pays for splendid code that isn&#x27;t in production. They will gladly pay for buggy code that is in production and solves their needs as long as the marketing team does a good job.</div><br/></div></div><div id="41991702" class="c"><input type="checkbox" id="c-41991702" checked=""/><div class="controls bullet"><span class="by">AdieuToLogic</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41992458">prev</a><span>|</span><a href="#41990208">next</a><span>|</span><label class="collapse" for="c-41991702">[-]</label><label class="expand" for="c-41991702">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Whenever I sit down to write some code, be it a large implementation or a small function, I think about what other people (or future versions of myself) will struggle with when interacting with the code. Is it clear and concise? Is it too clever? Is it too easy to write a subtle bug when making changes? Have I made it totally clear that X is relying on Y dangerous behavior by adding a comment or intentionally making it visible in some other way?<p>&gt; It goes the other way too. If I know someone well (or their style) then it makes evaluating their code easier. The more time I spend in a codebase the better idea I have of what the writer was trying to do.<p>What I believe you are describing is a general definition of &quot;understanding&quot;, which I am sure you are aware.  And given your 20+ year experience, your summary of:<p>&gt; So the thought of opening up a codebase that was cobbled together by an AI is just scary to me. Subtle bugs and errors would be equally distributed across the whole thing instead of where the writer was less competent (as is often the case).<p>Is not only entirely understandable (pardon the pun), but to be expected as algorithms employed lack the crucial bit which you identify - understanding.<p>&gt; The whole thing just sounds like a gargantuan mess.<p>As it does to most whom envision having to live with artifacts produced by a statistical predictive text algorithm.<p>&gt; Change my mind.<p>One cannot because understanding, as people know it, is intrinsic to each person by definition.  It exists as a concept within the person whom possesses it and is defined entirely by said person.</div><br/></div></div><div id="41990208" class="c"><input type="checkbox" id="c-41990208" checked=""/><div class="controls bullet"><span class="by">ianbutler</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41991702">prev</a><span>|</span><a href="#41991453">next</a><span>|</span><label class="collapse" for="c-41990208">[-]</label><label class="expand" for="c-41990208">[2 more]</label></div><br/><div class="children"><div class="content">I have 10 years professional experience and I&#x27;ve been writing code for 20 years, really with this workflow I just read and review significantly more code and I coach it when it structures or styles something in a way I don&#x27;t like.<p>I&#x27;m fully in control and nothing gets committed I haven&#x27;t read its an extension of me at that point.<p>Edit: I think the issues you&#x27;ve mentioned typically apply to people too and the answer is largely the same. Talk, coach, put hard fixes in like linting and review approvals.</div><br/><div id="41990751" class="c"><input type="checkbox" id="c-41990751" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990208">parent</a><span>|</span><a href="#41991453">next</a><span>|</span><label class="collapse" for="c-41990751">[-]</label><label class="expand" for="c-41990751">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Talk, coach, put hard fixes in like linting and review approvals.<p>And sometimes, when all that doesn’t work? Just do it yourself :)</div><br/></div></div></div></div><div id="41991453" class="c"><input type="checkbox" id="c-41991453" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41990208">prev</a><span>|</span><a href="#41991450">next</a><span>|</span><label class="collapse" for="c-41991453">[-]</label><label class="expand" for="c-41991453">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Change my mind.<p>Unit, integration, e2e, types and linters would catch most of the things you mention.<p>Not every software is mission critical, often the most important thing is to go as fast and possible and iterate very quickly. Good enough is better than very good in many cases.</div><br/><div id="41991494" class="c"><input type="checkbox" id="c-41991494" checked=""/><div class="controls bullet"><span class="by">almostdeadguy</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991453">parent</a><span>|</span><a href="#41991450">next</a><span>|</span><label class="collapse" for="c-41991494">[-]</label><label class="expand" for="c-41991494">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Unit, integration, e2e, types and linters would catch most of the things you mention.<p>Who’s writing those?</div><br/><div id="41992790" class="c"><input type="checkbox" id="c-41992790" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991494">parent</a><span>|</span><a href="#41991450">next</a><span>|</span><label class="collapse" for="c-41992790">[-]</label><label class="expand" for="c-41992790">[1 more]</label></div><br/><div class="children"><div class="content">Lots of people. For certain types of software (ISO) they are required.<p>But I&#x27;m in the boat (and also experienced many times first hand) all those tests you write will by definition, never test against that first production bug you get :)</div><br/></div></div></div></div></div></div><div id="41991450" class="c"><input type="checkbox" id="c-41991450" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41991453">prev</a><span>|</span><a href="#41991672">next</a><span>|</span><label class="collapse" for="c-41991450">[-]</label><label class="expand" for="c-41991450">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But the idea of letting an LLM write&#x2F;move large swaths of code seems so incredibly irresponsible.<p>Why?  Presumably you let your coworkers move code around, too, and then you review it?  (And vice versa.)</div><br/></div></div><div id="41991672" class="c"><input type="checkbox" id="c-41991672" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41991450">prev</a><span>|</span><a href="#41991332">next</a><span>|</span><label class="collapse" for="c-41991672">[-]</label><label class="expand" for="c-41991672">[4 more]</label></div><br/><div class="children"><div class="content">&gt; But the idea of letting an LLM write&#x2F;move large swaths of code seems so incredibly irresponsible.<p>I think this is where the bimodality comes from. When someone says &quot;I used AI to refactor 3000 loc&quot; some take it to mean they used AI in small steps as an accellerator, and others take it to mean a direct copy&#x2F;paste, fix compile errors and move on.<p>Treat AI like a mid level engineer that you are pair programming with, who can type insanely fast. Move in small steps. Read through it&#x27;s code after each small iteration. Ask it to fix things (or fix them yourself if quick and easy). Brainstorm ideas with it etc etc.</div><br/><div id="41991854" class="c"><input type="checkbox" id="c-41991854" checked=""/><div class="controls bullet"><span class="by">nwienert</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991672">parent</a><span>|</span><a href="#41991332">next</a><span>|</span><label class="collapse" for="c-41991854">[-]</label><label class="expand" for="c-41991854">[3 more]</label></div><br/><div class="children"><div class="content">It’s really far from mid level. It’s a weird mix of expert at things it trained on, and complete misleading idiot at anything outside.<p>For a bash script or the first steps of something simple it’s great.<p>For anything complex at all it’s worse than nothing.</div><br/><div id="41992569" class="c"><input type="checkbox" id="c-41992569" checked=""/><div class="controls bullet"><span class="by">anonzzzies</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991854">parent</a><span>|</span><a href="#41991937">next</a><span>|</span><label class="collapse" for="c-41992569">[-]</label><label class="expand" for="c-41992569">[1 more]</label></div><br/><div class="children"><div class="content">Works well for us nonetheless, also on more complex things. It&#x27;s not worse than most (including seniors) humans I worked with in the past 40 years, but it is faster and cheaper. On HN it is sometimes forgotten that by far most programmers do not like it; they need money. If you see what comes out of them, you have to puke; yet it&#x27;s running billion$ businesses and works surprisingly well considering the bad code quality.</div><br/></div></div><div id="41991937" class="c"><input type="checkbox" id="c-41991937" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991854">parent</a><span>|</span><a href="#41992569">prev</a><span>|</span><a href="#41991332">next</a><span>|</span><label class="collapse" for="c-41991937">[-]</label><label class="expand" for="c-41991937">[1 more]</label></div><br/><div class="children"><div class="content">For anything complex, move in small steps.<p>For anything truly novel, or on a codebase with a very bespoke in house architecture or DSL, yeah you won&#x27;t get much out of it.</div><br/></div></div></div></div></div></div><div id="41991332" class="c"><input type="checkbox" id="c-41991332" checked=""/><div class="controls bullet"><span class="by">OJFord</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41991672">prev</a><span>|</span><a href="#41991144">next</a><span>|</span><label class="collapse" for="c-41991332">[-]</label><label class="expand" for="c-41991332">[1 more]</label></div><br/><div class="children"><div class="content">&gt; As a programmer of over 20 years - this is terrifying.
&gt;
&gt; I&#x27;m willing to accept that I just have &quot;get off my lawn&quot; syndrome or something.
&gt;
&gt; But the idea of letting an LLM write&#x2F;move large swaths of code seems so incredibly irresponsible.<p>My first thought was that I disagree (though I don&#x27;t use or like this in-IDE AI stuff) because version control. But then the way people use (or can&#x27;t use) SVC &#x27;terrifies&#x27; me anyway, so maybe I agree? It would be fine correctly handled, but it won&#x27;t be, sort of thing.</div><br/></div></div><div id="41991144" class="c"><input type="checkbox" id="c-41991144" checked=""/><div class="controls bullet"><span class="by">outside1234</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41991332">prev</a><span>|</span><a href="#41991386">next</a><span>|</span><label class="collapse" for="c-41991144">[-]</label><label class="expand" for="c-41991144">[1 more]</label></div><br/><div class="children"><div class="content">The saying &quot;You can delegate tasks but not responsibility&quot; comes to mind.<p>You are still responsible for the code AI is writing.  It is just that writing code with AI is more like reviewing a PR now.</div><br/></div></div><div id="41991386" class="c"><input type="checkbox" id="c-41991386" checked=""/><div class="controls bullet"><span class="by">com2kid</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41991144">prev</a><span>|</span><a href="#41990003">next</a><span>|</span><label class="collapse" for="c-41991386">[-]</label><label class="expand" for="c-41991386">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But the idea of letting an LLM write&#x2F;move large swaths of code seems so incredibly irresponsible.<p>People felt the same about compilers for a long time. And justifiably so, the idea that compilers are reliable is quite a new one, finding compilers bugs used to be pretty common. (Those experimenting with newer languages still get to enjoy the fun of this!)<p>How about other code generation tools? Presumably you don&#x27;t take much umbrage with schema generators? Or code generators that take a scheme and output library code (OpenAPI, Protocol buffers, or even COM)? Those can easily take a few dozen lines of input and output many thousands of LoC, and because they are part of an automated pipeline, even if you do want to fix the code up, any fixes you make will be destroyed on the next pipeline run!<p>But there is also a LOT of boring boilerplate code that can be automated.<p>For example, the necessary code to create a new server, attach a JSON schema to a POST endpoint, validate a bearer token, and enable a given CORS config is pretty cut and dry.<p>If I am ramping up on a new backend framework, I can either spend hours learning the above and then copy and paste it forever more into each new project I start up, or I can use an AI to crap the code out for me.<p>(Actually once I was setting up a new server and I decided to not just copy and paste and to do it myself, I flipped the order of two `use` directives and it cost me at least 4 hours to figure out WTF was wrong....)<p>&gt; As a programmer of over 20 years<p>I&#x27;m almost up there, and my view is that I have two modes of working:<p>1. Super low level, where my intimate knowledge of algorithms, the language and framework I&#x27;m using, of CPU and memory constraints, all come together to let me write code that is damn near magical.<p>2. Super high level, where I am architecting a solution using design patterns and the individual pieces of code are functionally <i>very</i> simple, and it is how they are connected together that really matters.<p>For #1, eh, for some popular problems AI can help (popular optimizations on Stack Overflow).<p>For #2, AI is the most useful, because I have already broken the problem down into individual bite size testable nuggets. I can have the AI write a lot of the boilerplate, and then integrate the code within the larger, human architected, system.<p>&gt; So the thought of opening up a codebase that was cobbled together by an AI is just scary to me.<p>The AI didn&#x27;t cobble together the system. The AI did stuff like &quot;go through this array and check the ID field of each object and if more than 3 of them are null log an error, increment the ExcessNullsEncountered metric counter, and return an HTTP 400 error to the caller&quot;<p>Edit: This just happened<p>I am writing a small Canvas game renderer, and I am having an issue with text above a character&#x27;s head renders off the canvas. So I had Cursor fix the function up to move text under a character if it would have been rendered above the canvas area.<p>I was able to write the instructions out to Cursor faster than I could have found a pencil and paper to sketch out what I needed to do.</div><br/></div></div><div id="41990003" class="c"><input type="checkbox" id="c-41990003" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989925">parent</a><span>|</span><a href="#41991386">prev</a><span>|</span><a href="#41992525">next</a><span>|</span><label class="collapse" for="c-41990003">[-]</label><label class="expand" for="c-41990003">[17 more]</label></div><br/><div class="children"><div class="content">You. Can. Write. Tests.</div><br/><div id="41990160" class="c"><input type="checkbox" id="c-41990160" checked=""/><div class="controls bullet"><span class="by">0xFACEFEED</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990003">parent</a><span>|</span><a href="#41990157">next</a><span>|</span><label class="collapse" for="c-41990160">[-]</label><label class="expand" for="c-41990160">[9 more]</label></div><br/><div class="children"><div class="content">How do tests account for cases where I&#x27;m looking at a 100 line function that could have easily been written in 20 lines with just as much, if not more, clarity?<p>It reminds me of a time (long ago) when the trend&#x2F;fad was building applications visually. You would drag and drop UI elements and define logic using GUIs. Behind the scenes the IDE would generate code that linked everything together. One of the selling points was that underneath the hood it&#x27;s just code so if someone didn&#x27;t have access to the IDE (or whatever) then they could just open the source and make edits themselves.<p>It obviously didn&#x27;t work out. But not because of the scope&#x2F;scale (something AI code generation solves) but because, it turns out, writing maintainable secure software takes a lot of careful thought.<p>I&#x27;m not talking about asking an AI to vomit out a CRUD UI. For that I&#x27;m sure it&#x27;s well suited and the risk is pretty low. But as soon as you introduce domain specific logic or non-trivial things connected to the real world - it requires thought. Often times you need to spend more time thinking about the problem than writing the code.<p>I just don&#x27;t see how &quot;guidance&quot; of an LLM gets anywhere near writing good software outside of trivial stuff.</div><br/><div id="41990767" class="c"><input type="checkbox" id="c-41990767" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990160">parent</a><span>|</span><a href="#41991022">next</a><span>|</span><label class="collapse" for="c-41990767">[-]</label><label class="expand" for="c-41990767">[1 more]</label></div><br/><div class="children"><div class="content">&gt; How do tests account for cases where I&#x27;m looking at a 100 line function that could have easily been written in 20 lines with just as much, if not more, clarity?<p>That’s not a failure of the AI writing that 100 line monstrosity, it’s a failure of you deciding to actually use the thing.<p>If you know what 20 lines are necessary and the AI doesn’t output that, why would you use it?</div><br/></div></div><div id="41991022" class="c"><input type="checkbox" id="c-41991022" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990160">parent</a><span>|</span><a href="#41990767">prev</a><span>|</span><a href="#41992324">next</a><span>|</span><label class="collapse" for="c-41991022">[-]</label><label class="expand" for="c-41991022">[5 more]</label></div><br/><div class="children"><div class="content">&gt; How do tests account for cases where I&#x27;m looking at a 100 line function that could have easily been written in 20 lines with just as much, if not more, clarity?<p>If the function is fast to evaluate and you have thorough coverage by tests, you couod iterate on an LLMs that aims to compress it down to a simpler &#x2F; shorter version that behaves identical to the original function. Of course brevity for the sake of brevity can lead to less code that is not always more clear or simpler to understand than the original —LLMs are very good at mimicing code style, so show them a lot of your own code and ask them to mimic it and you may be surprized.</div><br/><div id="41991538" class="c"><input type="checkbox" id="c-41991538" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991022">parent</a><span>|</span><a href="#41992324">next</a><span>|</span><label class="collapse" for="c-41991538">[-]</label><label class="expand" for="c-41991538">[4 more]</label></div><br/><div class="children"><div class="content">Finally found a comment down here that I like. I&#x27;m also with the notion of tests and also iterating until you get to a solution you like. I also don&#x27;t see anything particularly &quot;terrifying&quot; that many other comments suggest.<p>At the end of the day, we&#x27;re engineers that write complex symbols on a 2d canvas, for something that is (ultimately, even if the code being written is machine to machine or something) used for some human purpose.<p>Now, if those complex symbols are readable, fully covered in tests, and meets requirements &#x2F; specifications, I don&#x27;t see why I should care if a human, an AI, or a monkey generated those symbols. If it meets the spec, it meets the spec.<p>Seems like most people in these threads are making arguments against others who are describing usage of these tools in a grossly incorrect manner from the get go.<p>I&#x27;ve said it before in other AI threads that I think (at least half?) of the noise and disagreement around AI generated code is like a bunch of people trying to use a hammer when they needed a screwdriver and then complaining that the hammer didnt work like a screwdriver!!! I just don&#x27;t get it. When you&#x27;re dealing with complex systems, i.e, reality, these tools (or any tool for that matter) will never work like a magic wand.</div><br/><div id="41991769" class="c"><input type="checkbox" id="c-41991769" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991538">parent</a><span>|</span><a href="#41992332">next</a><span>|</span><label class="collapse" for="c-41991769">[-]</label><label class="expand" for="c-41991769">[2 more]</label></div><br/><div class="children"><div class="content">&gt; a bunch of people trying to use a hammer when they needed a screwdriver and then complaining that the hammer didnt work like a screwdriver<p>When it&#x27;s being sold as a screwdriver, that&#x27;s hardly their fault.</div><br/><div id="41992800" class="c"><input type="checkbox" id="c-41992800" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991769">parent</a><span>|</span><a href="#41992332">next</a><span>|</span><label class="collapse" for="c-41992800">[-]</label><label class="expand" for="c-41992800">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll give you that! Too much of this stuff is sold as the &quot;magic wand&quot; solution... I guess marketing for many products has been like that for a long time...</div><br/></div></div></div></div><div id="41992332" class="c"><input type="checkbox" id="c-41992332" checked=""/><div class="controls bullet"><span class="by">nprateem</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991538">parent</a><span>|</span><a href="#41991769">prev</a><span>|</span><a href="#41992324">next</a><span>|</span><label class="collapse" for="c-41992332">[-]</label><label class="expand" for="c-41992332">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure people who are &quot;terrified&quot; either haven&#x27;t really tried AI or are so attached to their intellect their egos won&#x27;t allow them to admit that there&#x27;s little value now in a lot of the stuff they&#x27;ve memorised over the last few years.<p>I think this egoic threat is the biggest influence on this kind of thinking tbh.</div><br/></div></div></div></div></div></div><div id="41992324" class="c"><input type="checkbox" id="c-41992324" checked=""/><div class="controls bullet"><span class="by">nprateem</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990160">parent</a><span>|</span><a href="#41991022">prev</a><span>|</span><a href="#41990512">next</a><span>|</span><label class="collapse" for="c-41992324">[-]</label><label class="expand" for="c-41992324">[1 more]</label></div><br/><div class="children"><div class="content">Sure but you go fast on the simple parts it&#x27;s good at and slow on the novel&#x2F;critical part. It&#x27;s not that hard to understand. You don&#x27;t drive at top speed everywhere either. You go slower depending on the context.<p>The real problem with AI coding is not knowing in advance the cases where it&#x27;s going to spin its wheels and go in a cycle of stupid answers. I lose 20 minutes at a time that way because it seems like it needs just one more prompt, but in the end I have to step in, either with code or telling it specifically where the bug is.</div><br/></div></div></div></div><div id="41990157" class="c"><input type="checkbox" id="c-41990157" checked=""/><div class="controls bullet"><span class="by">hakunin</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990003">parent</a><span>|</span><a href="#41990160">prev</a><span>|</span><a href="#41990127">next</a><span>|</span><label class="collapse" for="c-41990157">[-]</label><label class="expand" for="c-41990157">[1 more]</label></div><br/><div class="children"><div class="content">How do you write a test for code clarity &#x2F; readability &#x2F; maintainability?</div><br/></div></div><div id="41990127" class="c"><input type="checkbox" id="c-41990127" checked=""/><div class="controls bullet"><span class="by">lanternfish</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990003">parent</a><span>|</span><a href="#41990157">prev</a><span>|</span><a href="#41990118">next</a><span>|</span><label class="collapse" for="c-41990127">[-]</label><label class="expand" for="c-41990127">[1 more]</label></div><br/><div class="children"><div class="content">Tests aren&#x27;t a full solution for all the considerations of the above post.</div><br/></div></div><div id="41990118" class="c"><input type="checkbox" id="c-41990118" checked=""/><div class="controls bullet"><span class="by">ok_dad</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990003">parent</a><span>|</span><a href="#41990127">prev</a><span>|</span><a href="#41990559">next</a><span>|</span><label class="collapse" for="c-41990118">[-]</label><label class="expand" for="c-41990118">[1 more]</label></div><br/><div class="children"><div class="content">Tests haven’t saved us so far, humans have been writing tests that passed for software with bugs for decades.</div><br/></div></div><div id="41990559" class="c"><input type="checkbox" id="c-41990559" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990003">parent</a><span>|</span><a href="#41990118">prev</a><span>|</span><a href="#41990129">next</a><span>|</span><label class="collapse" for="c-41990559">[-]</label><label class="expand" for="c-41990559">[1 more]</label></div><br/><div class="children"><div class="content">More importantly, you can read diffs.<p>Depending on whether I&#x27;m using LLMs from my Emacs or via a tool like Aider, I either review and manually merge offered modifications as diffs (in editor), or review the automatically generated commits (Aider). Either way, I end up reading a lot of diffs and massaging the LLM output on the fly, and <i>nothing that I haven&#x27;t reviewed gets pushed to upstream</i>.<p>I mean, people aren&#x27;t seriously pushing unreviewed LLM-generated code to production? Current models aren&#x27;t good enough for that.</div><br/></div></div><div id="41990129" class="c"><input type="checkbox" id="c-41990129" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990003">parent</a><span>|</span><a href="#41990559">prev</a><span>|</span><a href="#41991509">next</a><span>|</span><label class="collapse" for="c-41990129">[-]</label><label class="expand" for="c-41990129">[1 more]</label></div><br/><div class="children"><div class="content">Just let the LLM do that too.</div><br/></div></div><div id="41991509" class="c"><input type="checkbox" id="c-41991509" checked=""/><div class="controls bullet"><span class="by">fzeroracer</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990003">parent</a><span>|</span><a href="#41990129">prev</a><span>|</span><a href="#41990135">next</a><span>|</span><label class="collapse" for="c-41991509">[-]</label><label class="expand" for="c-41991509">[1 more]</label></div><br/><div class="children"><div class="content">The most common failure of TDD is that assuming just bolting on more tests will fix the problem of a poorly designed codebase.</div><br/></div></div><div id="41990135" class="c"><input type="checkbox" id="c-41990135" checked=""/><div class="controls bullet"><span class="by">the_real_cher</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990003">parent</a><span>|</span><a href="#41991509">prev</a><span>|</span><a href="#41992525">next</a><span>|</span><label class="collapse" for="c-41990135">[-]</label><label class="expand" for="c-41990135">[1 more]</label></div><br/><div class="children"><div class="content">Even better you can let the AI write tests.</div><br/></div></div></div></div></div></div><div id="41992525" class="c"><input type="checkbox" id="c-41992525" checked=""/><div class="controls bullet"><span class="by">hitradostava</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41989925">prev</a><span>|</span><a href="#41991048">next</a><span>|</span><label class="collapse" for="c-41992525">[-]</label><label class="expand" for="c-41992525">[3 more]</label></div><br/><div class="children"><div class="content">I agree with you and its confusing to me. I do think there is a lot of emotion at play here - rather than cold rationality.<p>Using LLM based tools effectively requires a change in workflow that a lot of people aren&#x27;t ready to try. Everyone can share their anecdote of how an LLM has produced stupid or buggy code, but there is way too much focus on what we are now, rather than the direction of travel.<p>I think existing models are already sufficient, its just we need to improve the feedback loop. A lot of the corrections &#x2F; direction I make to LLM produced code could 100% be done by a better LLM agent. In the next year I can imagine tooling that:
 - lets me interact fully via voice
 - a separate &quot;architecture&quot; agent ensures that any produced code is in line with the patterns in a particular repo
 - compile and runtime errors are automatically fed back in and automatically fixed
 - a refactoring workflow mode, where the aim is to first get tests written, then get the code working, and then get the code efficient, clean and with repo patterns<p>I&#x27;m excited by this direction of travel, but I do think it will fundamentally change software engineering in a way that is scary.</div><br/><div id="41992542" class="c"><input type="checkbox" id="c-41992542" checked=""/><div class="controls bullet"><span class="by">RheingoldRiver</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992525">parent</a><span>|</span><a href="#41991048">next</a><span>|</span><label class="collapse" for="c-41992542">[-]</label><label class="expand" for="c-41992542">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Using LLM based tools effectively requires a change in workflow that a lot of people aren&#x27;t ready to try<p>This is a REALLY good summary of it I think. If you lose your patience with people, you&#x27;ll lose your patience with AI tooling, because AI interaction is fundamentally so similar to interacting with other people</div><br/><div id="41992594" class="c"><input type="checkbox" id="c-41992594" checked=""/><div class="controls bullet"><span class="by">hitradostava</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992542">parent</a><span>|</span><a href="#41991048">next</a><span>|</span><label class="collapse" for="c-41992594">[-]</label><label class="expand" for="c-41992594">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, and LLM based tools can be very frustrating right now - but if you view the tooling as a very fast junior developer with very broad but shallow knowledge then you can develop a workflow which for many (but not all) tasks is much much faster writing code by hand.</div><br/></div></div></div></div></div></div><div id="41991048" class="c"><input type="checkbox" id="c-41991048" checked=""/><div class="controls bullet"><span class="by">foobiekr</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41992525">prev</a><span>|</span><a href="#41989857">next</a><span>|</span><label class="collapse" for="c-41991048">[-]</label><label class="expand" for="c-41991048">[2 more]</label></div><br/><div class="children"><div class="content">The most likely explanation is that the code you are writing has low information density and is stringing things together the same way many existing apps have already done.<p>That isn’t a judgement but trying to use the ai code completion tools for complex systems tasks is almost always a disaster.</div><br/><div id="41992821" class="c"><input type="checkbox" id="c-41992821" checked=""/><div class="controls bullet"><span class="by">fullstackchris</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991048">parent</a><span>|</span><a href="#41989857">next</a><span>|</span><label class="collapse" for="c-41992821">[-]</label><label class="expand" for="c-41992821">[1 more]</label></div><br/><div class="children"><div class="content">Not sure what you mean by &quot;complex systems tasks&quot; but most of the leading models have helped me with writing concurrent go code just fine. Not sure if that counts as &quot;complex&quot; enough. However this was prompting, not completion. Obviously I expect something like copilot to pick the normie non-concurrent implementation</div><br/></div></div></div></div><div id="41989857" class="c"><input type="checkbox" id="c-41989857" checked=""/><div class="controls bullet"><span class="by">__float</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41991048">prev</a><span>|</span><a href="#41992392">next</a><span>|</span><label class="collapse" for="c-41989857">[-]</label><label class="expand" for="c-41989857">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure how many people are like me, but my attempts to use Copilot have largely been the context of writing code as usual, occasionally getting end-of-line or handful-of-lines completions from it.
I suspect there&#x27;s probably a bigger shift needed, but I haven&#x27;t seen anyone (besides AI &quot;influencers&quot; I don&#x27;t trust..?) showing what their day-to-day workflows look like.<p>Is there a Vimcasts equivalent for learning the AI editor tips and tricks?</div><br/><div id="41990233" class="c"><input type="checkbox" id="c-41990233" checked=""/><div class="controls bullet"><span class="by">sbarre</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989857">parent</a><span>|</span><a href="#41990358">next</a><span>|</span><label class="collapse" for="c-41990233">[-]</label><label class="expand" for="c-41990233">[1 more]</label></div><br/><div class="children"><div class="content">Have you tried the chat mode?<p>The autocomplete is somewhere between annoying and underwhelming for me, but the chat is super useful.  Being able to just describe what you&#x27;re thinking or what you&#x27;re trying to do and having a bespoke code sample just show up (based on the code in your editor) that you can then either copy&#x2F;paste in, cherry-pick from or just get inspired by, has been a great productivity booster..<p>Treat it like a pair programmer or a rubber duck and you might have a better experience. I did!</div><br/></div></div><div id="41990358" class="c"><input type="checkbox" id="c-41990358" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989857">parent</a><span>|</span><a href="#41990233">prev</a><span>|</span><a href="#41992392">next</a><span>|</span><label class="collapse" for="c-41990358">[-]</label><label class="expand" for="c-41990358">[1 more]</label></div><br/><div class="children"><div class="content">Yeah using a chat interface</div><br/></div></div></div></div><div id="41992392" class="c"><input type="checkbox" id="c-41992392" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41989857">prev</a><span>|</span><a href="#41992311">next</a><span>|</span><label class="collapse" for="c-41992392">[-]</label><label class="expand" for="c-41992392">[1 more]</label></div><br/><div class="children"><div class="content">&gt;My theory is the willingness to baby sit and the modality. I&#x27;m perfectly fine telling the tool I use its errors and working side by side with it like it was another person.<p>In my experience, baby sitting the AI takes to much time and effort. I&#x27;d rather do it myself and use AI for tasks I don&#x27;t have to babysit.</div><br/></div></div><div id="41992311" class="c"><input type="checkbox" id="c-41992311" checked=""/><div class="controls bullet"><span class="by">zkry</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41992392">prev</a><span>|</span><a href="#41990455">next</a><span>|</span><label class="collapse" for="c-41992311">[-]</label><label class="expand" for="c-41992311">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious coming from the other end. I guess I can totally understand certain use cases where I&#x27;m generating fairly simple, self contained code in a language I&#x27;m unfamiliar with being good.<p>But surely you must have experienced something where you&#x27;re literally fighting with the model, where it continuously repeats its mistakes, and fixing a mistake in one place, breaks something else, and you can&#x27;t seem to escape this loop. You then get desperate, invoking magic phrases like &quot;you think through your problems step by step&quot;, or &quot;you are a senior developer&quot;, only for it to loose the entire thread of the conversation.<p>Then the worst part is when you finally give up, your mental state of the problem is no better than when you first started off.</div><br/><div id="41992564" class="c"><input type="checkbox" id="c-41992564" checked=""/><div class="controls bullet"><span class="by">Vegenoid</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992311">parent</a><span>|</span><a href="#41990455">next</a><span>|</span><label class="collapse" for="c-41992564">[-]</label><label class="expand" for="c-41992564">[1 more]</label></div><br/><div class="children"><div class="content">This is my experience. I’d love to see some full streams of people building whole useful apps from scratch with an LLM, does anyone have any good examples?</div><br/></div></div></div></div><div id="41990455" class="c"><input type="checkbox" id="c-41990455" checked=""/><div class="controls bullet"><span class="by">2024user</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41992311">prev</a><span>|</span><a href="#41991446">next</a><span>|</span><label class="collapse" for="c-41990455">[-]</label><label class="expand" for="c-41990455">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re doing something that appears in it&#x27;s training model a lot, like building a twitter clone, then it is great. If you&#x27;re using something brand new like react router 7 then it makes mistakes</div><br/></div></div><div id="41991446" class="c"><input type="checkbox" id="c-41991446" checked=""/><div class="controls bullet"><span class="by">dools</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41990455">prev</a><span>|</span><a href="#41992416">next</a><span>|</span><label class="collapse" for="c-41991446">[-]</label><label class="expand" for="c-41991446">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m actually very curious why AI use is such a bi-modal experience<p>I think it&#x27;s just that it&#x27;s better at some things than others. Lucky for people who happen to be working in python&#x2F;node&#x2F;php&#x2F;bash&#x2F;sql&#x2F;java probably unlucky for people writing Go and Rust (I&#x27;m hypothesising because I don&#x27;t know Go or Rust nor have I ever used them but when the AI doesn&#x27;t know something it REALLY doesn&#x27;t know it, like it goes from being insanely useful to utterly useless).<p>&gt; I use AI autocomplete 0% of the time as I found that workflow was not as effective as me just writing code, but most of my most successful work using AI is a chat dialogue where I&#x27;m letting it build large swaths of the project a file or parts of a file at a time, with me reviewing and coaching.<p>Me too, the way I use it is more like pair programming.</div><br/></div></div><div id="41992416" class="c"><input type="checkbox" id="c-41992416" checked=""/><div class="controls bullet"><span class="by">Myrmornis</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41991446">prev</a><span>|</span><a href="#41989876">next</a><span>|</span><label class="collapse" for="c-41992416">[-]</label><label class="expand" for="c-41992416">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s bimodal because there&#x27;s a roughly bimodal distribution of high level attitudes among programmers. There&#x27;s one clump that are willing to be humble and interact with the AI in a thoughtful, careful manner, acknowledging that it might be smarter than them (e.g. see Terry Tao&#x27;s comments regarding mathematics usage about how in order to get good results he takes care with what he puts in (and imagine what &quot;care&quot; means for a professional mathematician!)) and there&#x27;s another clump who aren&#x27;t.</div><br/></div></div><div id="41989876" class="c"><input type="checkbox" id="c-41989876" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41992416">prev</a><span>|</span><a href="#41991533">next</a><span>|</span><label class="collapse" for="c-41989876">[-]</label><label class="expand" for="c-41989876">[1 more]</label></div><br/><div class="children"><div class="content">I guess for me it actually takes longer to review code than to write it. So maybe that’s some of the difference.</div><br/></div></div><div id="41991533" class="c"><input type="checkbox" id="c-41991533" checked=""/><div class="controls bullet"><span class="by">Bjartr</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41989876">prev</a><span>|</span><a href="#41992146">next</a><span>|</span><label class="collapse" for="c-41991533">[-]</label><label class="expand" for="c-41991533">[2 more]</label></div><br/><div class="children"><div class="content">Interesting that you find the conversational approach effective. For me, I&#x27;d say 9 out of 10 code conversations get stuck in a loop with me telling the AI the next suggested iteration didn&#x27;t actually change anything or changed it back to something that was already broken. Do you not experience that so often, of do you have a way to escape that?</div><br/><div id="41991618" class="c"><input type="checkbox" id="c-41991618" checked=""/><div class="controls bullet"><span class="by">bequanna</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991533">parent</a><span>|</span><a href="#41992146">next</a><span>|</span><label class="collapse" for="c-41991618">[-]</label><label class="expand" for="c-41991618">[1 more]</label></div><br/><div class="children"><div class="content">I encounter that issue when the chat becomes too long.<p>Starting a new chat with context and asking your question again typically works for me.</div><br/></div></div></div></div><div id="41992146" class="c"><input type="checkbox" id="c-41992146" checked=""/><div class="controls bullet"><span class="by">tivert</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41991533">prev</a><span>|</span><a href="#41991778">next</a><span>|</span><label class="collapse" for="c-41992146">[-]</label><label class="expand" for="c-41992146">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ...and I can review code very quickly so the overall productivity boost has been great.<p>Color me skeptical. After a certain point, greater speed is achieved by sacrificing accuracy and comprehension. So, &quot;I can review code very quickly&quot; starts to sound like &quot;I don&#x27;t read, I skim.&quot;<p>IMHO, reviewing code is one of the parts of the job that sucks, so I see &quot;AI&quot; as a wonderful technology to improve our lives by replacing fun with chores.</div><br/></div></div><div id="41991778" class="c"><input type="checkbox" id="c-41991778" checked=""/><div class="controls bullet"><span class="by">andsoitis</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41992146">prev</a><span>|</span><a href="#41990076">next</a><span>|</span><label class="collapse" for="c-41991778">[-]</label><label class="expand" for="c-41991778">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m perfectly fine telling the tool I use its errors and working side by side with it like it was another person.<p>This is key. Traditional computing systems are deterministic machines, but AI is a probabilistic machine. So the way you interact and the range, precision, and perspective of the output stretches over a different problem&#x2F;solution space.</div><br/></div></div><div id="41990076" class="c"><input type="checkbox" id="c-41990076" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41991778">prev</a><span>|</span><a href="#41991615">next</a><span>|</span><label class="collapse" for="c-41990076">[-]</label><label class="expand" for="c-41990076">[1 more]</label></div><br/><div class="children"><div class="content">My theory is grammatical correctness and specificity. I see a lot of people prompt like this:<p>&quot;use python to write me a prog that does some dice rolls and makes a graph&quot;<p>Vs<p>&quot;Create a Python program that generates random numbers to simulate a series of dice rolls. Export a graph of the results in PNG format.&quot;<p>Information theory requires that you provide enough actual information. There is a minimum amount of work to supply the input. Otherwise, the gaps will get filled in with noise, working, what you want, or not.<p>For example, maybe someday you could say &quot;write me an OS&quot; and it would work. However, to get exactly what you want, you still have to specify it. You can only compress so far.</div><br/></div></div><div id="41991615" class="c"><input type="checkbox" id="c-41991615" checked=""/><div class="controls bullet"><span class="by">apwell23</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41990076">prev</a><span>|</span><a href="#41990049">next</a><span>|</span><label class="collapse" for="c-41991615">[-]</label><label class="expand" for="c-41991615">[1 more]</label></div><br/><div class="children"><div class="content">&gt; move multi thousand line codebases between languages<p>i am more curious about why someone do would this</div><br/></div></div><div id="41990049" class="c"><input type="checkbox" id="c-41990049" checked=""/><div class="controls bullet"><span class="by">rqmedes</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41991615">prev</a><span>|</span><a href="#41990486">next</a><span>|</span><label class="collapse" for="c-41990049">[-]</label><label class="expand" for="c-41990049">[1 more]</label></div><br/><div class="children"><div class="content">I agree. I am in a very senior role and find that working  with AI the same way you do I  am many times more productive. Months of work becomes days or even hours of work</div><br/></div></div><div id="41990486" class="c"><input type="checkbox" id="c-41990486" checked=""/><div class="controls bullet"><span class="by">xk_id</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989760">parent</a><span>|</span><a href="#41990049">prev</a><span>|</span><a href="#41989002">next</a><span>|</span><label class="collapse" for="c-41990486">[-]</label><label class="expand" for="c-41990486">[8 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m actually very curious why AI use is such a bi-modal experience.<p>My conspiracy theory is that the positive experiences are exaggerated and come from investors in the Nvidia stock.</div><br/><div id="41992041" class="c"><input type="checkbox" id="c-41992041" checked=""/><div class="controls bullet"><span class="by">eyegor</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990486">parent</a><span>|</span><a href="#41990629">next</a><span>|</span><label class="collapse" for="c-41992041">[-]</label><label class="expand" for="c-41992041">[2 more]</label></div><br/><div class="children"><div class="content">Have you tried using chatgpt&#x2F;etc as a starting point when you&#x27;re unfamiliar with something? That&#x27;s where it really excels for me, I can go crazy fast from 0 to ~30 (if we call 60 mvp). For example, the other day I was trying to stream some pcm audio using webaudio and it spit out a mostly functional prototype for me in a few minutes of trying. For me to read through msdn and get to that point would&#x27;ve taken an hour or two, and going from the crappy prototype as a starting point to read up on webaudio let me get an mvp in ~15 mins. I rarely touch frontend web code so for me these tools are super helpful.<p>On the other hand, I find it just wastes my time in more typical tasks like implementing business logic in a familiar language cause it makes up stdlib apis too often.</div><br/><div id="41992125" class="c"><input type="checkbox" id="c-41992125" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992041">parent</a><span>|</span><a href="#41990629">next</a><span>|</span><label class="collapse" for="c-41992125">[-]</label><label class="expand" for="c-41992125">[1 more]</label></div><br/><div class="children"><div class="content">This is about the only use case I found it helpful for - saving me time in research, not in coding.<p>I needed to compare compression ratios of a certain text in a language, and it actually came up with something nice and almost workable.  It didn&#x27;t compile but I forgot why now, I just remember it needing a small tweak.  That saved me having to track down the libraries, their APIs, etc.<p>However, when it comes to actually doing data structures or logic, I find it quicker to just do it myself than to type out what I want to do, and double check its work.</div><br/></div></div></div></div><div id="41990629" class="c"><input type="checkbox" id="c-41990629" checked=""/><div class="controls bullet"><span class="by">Nullabillity</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990486">parent</a><span>|</span><a href="#41992041">prev</a><span>|</span><a href="#41989002">next</a><span>|</span><label class="collapse" for="c-41990629">[-]</label><label class="expand" for="c-41990629">[5 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a very important caveat. In our modern economy it&#x27;s difficult to <i>not</i> be a shill in some way, shape, or form, even if you don&#x27;t quite realize it consciously. It&#x27;s honestly one of the most depressing things about the stock market.</div><br/><div id="41991400" class="c"><input type="checkbox" id="c-41991400" checked=""/><div class="controls bullet"><span class="by">malux85</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990629">parent</a><span>|</span><a href="#41990732">next</a><span>|</span><label class="collapse" for="c-41991400">[-]</label><label class="expand" for="c-41991400">[3 more]</label></div><br/><div class="children"><div class="content">Theres a big difference between being a happy customer and being a shill.</div><br/><div id="41991490" class="c"><input type="checkbox" id="c-41991490" checked=""/><div class="controls bullet"><span class="by">Nullabillity</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991400">parent</a><span>|</span><a href="#41990732">next</a><span>|</span><label class="collapse" for="c-41991490">[-]</label><label class="expand" for="c-41991490">[2 more]</label></div><br/><div class="children"><div class="content">Holding stock is not being a &quot;happy customer&quot;. I may be happy with the headset that I bought, but the difference is that I don&#x27;t make money if you buy an identical one.</div><br/><div id="41991602" class="c"><input type="checkbox" id="c-41991602" checked=""/><div class="controls bullet"><span class="by">malux85</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991490">parent</a><span>|</span><a href="#41990732">next</a><span>|</span><label class="collapse" for="c-41991602">[-]</label><label class="expand" for="c-41991602">[1 more]</label></div><br/><div class="children"><div class="content">I wasnt talking about holding stock, I was responding to this comment you said:<p>&gt; In our modern economy it&#x27;s difficult to not be a shill in some way, shape, or form, even if you don&#x27;t quite realize it consciously.<p>Oxford dictionary defines a shill as
&quot;an accomplice of a confidence trickster or swindler who poses as a genuine customer to entice or encourage others.&quot;<p>So the difference between someone shilling and being a satisfied customer is an intent to decieve. How is it &quot;difficult to not pose as a genuine customer to entice or encourage others&quot; ?</div><br/></div></div></div></div></div></div><div id="41990732" class="c"><input type="checkbox" id="c-41990732" checked=""/><div class="controls bullet"><span class="by">xk_id</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990629">parent</a><span>|</span><a href="#41991400">prev</a><span>|</span><a href="#41989002">next</a><span>|</span><label class="collapse" for="c-41990732">[-]</label><label class="expand" for="c-41990732">[1 more]</label></div><br/><div class="children"><div class="content">I credit my past interest in cryptocurrencies for educating me about the essence of the stock market in its purest form. And in fact there are painful parallels with the AI bubble.</div><br/></div></div></div></div></div></div></div></div><div id="41989002" class="c"><input type="checkbox" id="c-41989002" checked=""/><div class="controls bullet"><span class="by">bob1029</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41989760">prev</a><span>|</span><a href="#41989683">next</a><span>|</span><label class="collapse" for="c-41989002">[-]</label><label class="expand" for="c-41989002">[37 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the subtle errors that are really difficult to navigate. I got burned for about 40 hours on a conditional being backward in the middle of an otherwise flawless method.<p>The apparent speed up is mostly a deception. It definitely helps with rough outlines and approaches. But, the faster you go, the less you will notice the fine details, and the more assumptions you will accumulate before realizing the fundamental error.<p>I&#x27;d rather find out I was wrong within the same day. I&#x27;d probably have written some unit tests and played around with that function a lot more if I had handcrafted it.</div><br/><div id="41989332" class="c"><input type="checkbox" id="c-41989332" checked=""/><div class="controls bullet"><span class="by">tanseydavid</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989002">parent</a><span>|</span><a href="#41989898">next</a><span>|</span><label class="collapse" for="c-41989332">[-]</label><label class="expand" for="c-41989332">[8 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; The apparent speed up is mostly a deception.<p>When I am able ask a very simple question of an LLM which then prevents me having to context-switch to answer the same simple question myself; this is a big time saver for me but hard-to-quantify.<p>Anything that reduces my cognitive load when the pressure is on is a blessing on some level.</div><br/><div id="41989402" class="c"><input type="checkbox" id="c-41989402" checked=""/><div class="controls bullet"><span class="by">oogetyboogety</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989332">parent</a><span>|</span><a href="#41989964">next</a><span>|</span><label class="collapse" for="c-41989402">[-]</label><label class="expand" for="c-41989402">[6 more]</label></div><br/><div class="children"><div class="content">This might be the measurable &quot;some&quot;  non deceptive time saving, whereas most of it is still deceptive in terms of time saved</div><br/><div id="41989832" class="c"><input type="checkbox" id="c-41989832" checked=""/><div class="controls bullet"><span class="by">0xFACEFEED</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989402">parent</a><span>|</span><a href="#41989746">next</a><span>|</span><label class="collapse" for="c-41989832">[-]</label><label class="expand" for="c-41989832">[1 more]</label></div><br/><div class="children"><div class="content">You could make the same argument for any non-AI driven productivity tool&#x2F;technique. If we can&#x27;t trust the user to determine what is and is not time-saving then time-saving isn&#x27;t a useful thing to discuss outside of an academic setting.<p>My issue with most AI discussions is they seem to completely change the dimensions we use to evaluate basic things. I believe if we replaced &quot;AI&quot; with &quot;new useful tool&quot; then people would be much more eager to adopt it.<p>What clicked for me is when I started treating it more like a tool and less like some sort of nebulous pandora&#x27;s box.<p>Now to me it&#x27;s no different than auto completing code, fuzzy finding files, regular expressions, garbage collection, unit testing, UI frameworks, design patterns, etc. It&#x27;s just a tool. It has weaknesses and it has strengths. Use it for the strengths and account for the weaknesses.<p>Like any tool it can be destructive in the hands of an inexperienced person or a person who&#x27;s asking it to do too much. But in the hands of someone who knows what they&#x27;re doing and knows what they want out of it - it&#x27;s so freakin&#x27; awesome.<p>Sorry for the digression. All that to say that if someone believes it&#x27;s a productivity boost for them then I don&#x27;t think they&#x27;re being misled.</div><br/></div></div><div id="41989746" class="c"><input type="checkbox" id="c-41989746" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989402">parent</a><span>|</span><a href="#41989832">prev</a><span>|</span><a href="#41989964">next</a><span>|</span><label class="collapse" for="c-41989746">[-]</label><label class="expand" for="c-41989746">[4 more]</label></div><br/><div class="children"><div class="content">Except actual studies objectively show efficiency gains, more with junior devs, which make sense. So no, it&#x27;s not a &quot;deception&quot; but it is often overstated in popular media.</div><br/><div id="41989866" class="c"><input type="checkbox" id="c-41989866" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989746">parent</a><span>|</span><a href="#41989964">next</a><span>|</span><label class="collapse" for="c-41989866">[-]</label><label class="expand" for="c-41989866">[3 more]</label></div><br/><div class="children"><div class="content">Studies have limitations, in particular they test artificial and narrowly-scoped problems that are quite different from real world work.</div><br/><div id="41990615" class="c"><input type="checkbox" id="c-41990615" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989866">parent</a><span>|</span><a href="#41990009">next</a><span>|</span><label class="collapse" for="c-41990615">[-]</label><label class="expand" for="c-41990615">[1 more]</label></div><br/><div class="children"><div class="content">And anecdotes are useless. If you want to show me improved studies justifying your claim great, but no I don&#x27;t value random anecdotes. There are countless conflicting anecdotes (including my own).</div><br/></div></div><div id="41990009" class="c"><input type="checkbox" id="c-41990009" checked=""/><div class="controls bullet"><span class="by">rqmedes</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989866">parent</a><span>|</span><a href="#41990615">prev</a><span>|</span><a href="#41989964">next</a><span>|</span><label class="collapse" for="c-41990009">[-]</label><label class="expand" for="c-41990009">[1 more]</label></div><br/><div class="children"><div class="content">I find the opposite, the more senior the more value they offer as you know how to ask the right questions, how to vary the questions and try different tact’s and also observe errors or mistakes</div><br/></div></div></div></div></div></div></div></div><div id="41989964" class="c"><input type="checkbox" id="c-41989964" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989332">parent</a><span>|</span><a href="#41989402">prev</a><span>|</span><a href="#41989898">next</a><span>|</span><label class="collapse" for="c-41989964">[-]</label><label class="expand" for="c-41989964">[1 more]</label></div><br/><div class="children"><div class="content">Cognitive load is something people always leave out. I can fuckin code drunk with these things. Or just increase stamina to push farther than I would writing every single line.</div><br/></div></div></div></div><div id="41989898" class="c"><input type="checkbox" id="c-41989898" checked=""/><div class="controls bullet"><span class="by">pawelduda</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989002">parent</a><span>|</span><a href="#41989332">prev</a><span>|</span><a href="#41989207">next</a><span>|</span><label class="collapse" for="c-41989898">[-]</label><label class="expand" for="c-41989898">[1 more]</label></div><br/><div class="children"><div class="content">Exactly, 1 step forward, 1 step backward. Avoiding edge cases is something that can&#x27;t be glossed over, and for that I need to carefully review the code. Since I&#x27;m accountable for it, and can&#x27;t skip this part anyway, I&#x27;d rather review my own than some chatbot&#x27;s.</div><br/></div></div><div id="41989207" class="c"><input type="checkbox" id="c-41989207" checked=""/><div class="controls bullet"><span class="by">enneff</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989002">parent</a><span>|</span><a href="#41989898">prev</a><span>|</span><a href="#41989730">next</a><span>|</span><label class="collapse" for="c-41989207">[-]</label><label class="expand" for="c-41989207">[12 more]</label></div><br/><div class="children"><div class="content">That’s the thing, isn’t it? The craft of programming in the small is one of being intimate with the details, thinking things through conscientiously. LLMs don’t do that.</div><br/><div id="41989920" class="c"><input type="checkbox" id="c-41989920" checked=""/><div class="controls bullet"><span class="by">__MatrixMan__</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989207">parent</a><span>|</span><a href="#41989336">next</a><span>|</span><label class="collapse" for="c-41989920">[-]</label><label class="expand" for="c-41989920">[3 more]</label></div><br/><div class="children"><div class="content">I find that it depends very heavily on what you&#x27;re up to.  When I ask it to write nix code it&#x27;ll just flat out forget how the syntax works half way though.  But if I want it to troubleshoot an emacs config or wield matplotlib it&#x27;s downright wizardly, often including the kind of thing that does indicate an intimacy with the details.  I get distracted because I&#x27;m then asking it:<p>&gt; I un-did your change which made no sense to me and now everything is broken, why is what you did necessary?<p>I think we just have to ask ourselves what we want it to be good at, and then be diligent about generating decades worth of high quality training material in that domain.  At some point, it&#x27;ll start getting the details right.</div><br/><div id="41991220" class="c"><input type="checkbox" id="c-41991220" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989920">parent</a><span>|</span><a href="#41989336">next</a><span>|</span><label class="collapse" for="c-41991220">[-]</label><label class="expand" for="c-41991220">[2 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t work in the tech industry, because almost nothing is decades old, for obvious reasons.</div><br/><div id="41992070" class="c"><input type="checkbox" id="c-41992070" checked=""/><div class="controls bullet"><span class="by">__MatrixMan__</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991220">parent</a><span>|</span><a href="#41989336">next</a><span>|</span><label class="collapse" for="c-41992070">[-]</label><label class="expand" for="c-41992070">[1 more]</label></div><br/><div class="children"><div class="content">What languages&#x2F;toolkits are you working with that are less than 10 years old?<p>Anyhow, it seems to me like it <i>is</i> working.  It&#x27;s just working <i>better</i> for the really old stuff because:<p>- there has been more time for training data to accumulate<p>- some of it predates the trend of monetizing data, so there was less hoarding and more sharing<p>It may be that the hard slow way is the only way to get good results.  If the modern trends re: products don&#x27;t have the longevity&#x2F;community to benefit from it, maybe we should fix <i>that</i>.</div><br/></div></div></div></div></div></div><div id="41989336" class="c"><input type="checkbox" id="c-41989336" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989207">parent</a><span>|</span><a href="#41989920">prev</a><span>|</span><a href="#41989730">next</a><span>|</span><label class="collapse" for="c-41989336">[-]</label><label class="expand" for="c-41989336">[8 more]</label></div><br/><div class="children"><div class="content">Perhaps it should be prompted to then?<p>Ask it to review its own code for any problems?<p>Also identify typical and corner cases and generate tests?<p>Question marks here because I have not used the tool.<p>The size &amp; depth of each accepted code step is still up to the developer slash prompter</div><br/><div id="41989487" class="c"><input type="checkbox" id="c-41989487" checked=""/><div class="controls bullet"><span class="by">nrclark</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989336">parent</a><span>|</span><a href="#41989629">next</a><span>|</span><label class="collapse" for="c-41989487">[-]</label><label class="expand" for="c-41989487">[2 more]</label></div><br/><div class="children"><div class="content">I use Chatgpt for coding &#x2F; API questions pretty frequently. It&#x27;s bad at writing code with any kind of non-trivial design complexity.<p>There have been a bunch of times where I&#x27;ve asked it to write me a snippet of code, and it cheerfully gave me back something that doesn&#x27;t work for one reason or another. Hallucinated methods are common. Then I ask it to check its code, and it&#x27;ll find the error and give me back code with a different error. I&#x27;ll repeat the process a few times before it eventually gets back to code that resembles its first attempt. Then I&#x27;ll give up and write it myself.<p>As an example of a task that it failed to do: I asked it to write me an example Python function that runs a subprocess, prints its stdout transparently (so that I can use it for running interactive applications), but also records the process&#x27;s stdout so that I can use it later. I wanted something that used non-blocking I&#x2F;O methods, so that I didn&#x27;t have to explicitly poll every N milliseconds or something.</div><br/><div id="41989980" class="c"><input type="checkbox" id="c-41989980" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989487">parent</a><span>|</span><a href="#41989629">next</a><span>|</span><label class="collapse" for="c-41989980">[-]</label><label class="expand" for="c-41989980">[1 more]</label></div><br/><div class="children"><div class="content">Honestly I find that when GPT starts to lose the plot it&#x27;s a good time to refactor and then keep on moving. &quot;Break this into separate headers or modules and give me some YAML like markup with function names, return type, etc for each file.&quot; Or just use stubs instead of dumping every line of code in.</div><br/></div></div></div></div><div id="41989629" class="c"><input type="checkbox" id="c-41989629" checked=""/><div class="controls bullet"><span class="by">tomrod</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989336">parent</a><span>|</span><a href="#41989487">prev</a><span>|</span><a href="#41989949">next</a><span>|</span><label class="collapse" for="c-41989629">[-]</label><label class="expand" for="c-41989629">[4 more]</label></div><br/><div class="children"><div class="content">How long are you willing to iterate to get things right?</div><br/><div id="41989990" class="c"><input type="checkbox" id="c-41989990" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989629">parent</a><span>|</span><a href="#41989949">next</a><span>|</span><label class="collapse" for="c-41989990">[-]</label><label class="expand" for="c-41989990">[3 more]</label></div><br/><div class="children"><div class="content">If it takes almost no cognitive energy, quite a while. Even if it&#x27;s a little slower than what I can do, I don&#x27;t care because I didn&#x27;t have to focus deeply on it and have plenty of energy left to keep on pushing.</div><br/><div id="41990930" class="c"><input type="checkbox" id="c-41990930" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989990">parent</a><span>|</span><a href="#41991555">next</a><span>|</span><label class="collapse" for="c-41990930">[-]</label><label class="expand" for="c-41990930">[1 more]</label></div><br/><div class="children"><div class="content">As my mother used to say, &quot;I love work. I could watch it all day!&quot;<p>I can see where you are coming from.<p>Maintaining a better creative + technical balance, instead of see-sawing. More continuous conscious planning, less drilling.<p>Plus the unwavering tireless help of these AI&#x27;s seems psychologically conducive to maintaining one&#x27;s own motivation. Even if I end up designing an elaborate garden estate or a simpler better six-axis camera stabilizer&#x2F;tracker, or refactoring how I think of primes before attempting a theorem, ... when that was not my agenda for the day. Or any day.</div><br/></div></div><div id="41991555" class="c"><input type="checkbox" id="c-41991555" checked=""/><div class="controls bullet"><span class="by">Bjartr</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989990">parent</a><span>|</span><a href="#41990930">prev</a><span>|</span><a href="#41989949">next</a><span>|</span><label class="collapse" for="c-41991555">[-]</label><label class="expand" for="c-41991555">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m constantly having to go back and tell the AI about every mistake it makes and remind it not to reintroduce mistakes that were previously fixed. &quot;no cognitive energy&quot; is definitely not how I would describe that experience.</div><br/></div></div></div></div></div></div><div id="41989949" class="c"><input type="checkbox" id="c-41989949" checked=""/><div class="controls bullet"><span class="by">EVa5I7bHFq9mnYK</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989336">parent</a><span>|</span><a href="#41989629">prev</a><span>|</span><a href="#41989730">next</a><span>|</span><label class="collapse" for="c-41989949">[-]</label><label class="expand" for="c-41989949">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s presumably what o1-preview does? Iterates and checks the result. It takes much longer, but does indeed write slightly better code.</div><br/></div></div></div></div></div></div><div id="41989730" class="c"><input type="checkbox" id="c-41989730" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989002">parent</a><span>|</span><a href="#41989207">prev</a><span>|</span><a href="#41990748">next</a><span>|</span><label class="collapse" for="c-41989730">[-]</label><label class="expand" for="c-41989730">[11 more]</label></div><br/><div class="children"><div class="content">Why aren&#x27;t you writing unit tests just because AI wrote the function? Unit tests should be written regardless of the skill of the developer. Ironically, unit tests are also one area where AI really does help move faster.<p>High level design, rough outlines and approaches, is the worst place to use AI. The other place AI is pretty good is surfacing api call or function calls you might not know about if you&#x27;re new to the language. Basically, it can save you a lot of time by avoiding the need for tons of internet searching in some cases.</div><br/><div id="41992617" class="c"><input type="checkbox" id="c-41992617" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989730">parent</a><span>|</span><a href="#41989844">next</a><span>|</span><label class="collapse" for="c-41992617">[-]</label><label class="expand" for="c-41992617">[1 more]</label></div><br/><div class="children"><div class="content">I am kind of starting to doubt about the utility of unit tests. From a theoretical perspective I see the point in writing unit tests. But in practice I rarely seen them being useful. Guy A writes poor logic and sets in stone that poor logic by writing an unit test. Manual testing discovers a bug so guy B has to modify that poor logic and the unit test.<p>I&#x27;d rather see the need for integration tests and end to end tests. I want to test business logic not assert that 2 + 2 = 4.</div><br/></div></div><div id="41989844" class="c"><input type="checkbox" id="c-41989844" checked=""/><div class="controls bullet"><span class="by">chairhairair</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989730">parent</a><span>|</span><a href="#41992617">prev</a><span>|</span><a href="#41990748">next</a><span>|</span><label class="collapse" for="c-41989844">[-]</label><label class="expand" for="c-41989844">[9 more]</label></div><br/><div class="children"><div class="content">I have completely the opposite perspective.<p>Unit tests actually need to be correct, down to individual characters. Same goes with API calls. The API needs to actually exist.<p>Contrast that with &quot;high level design, rough outlines&quot;. Those can be quite vague and hand-wavy. That&#x27;s where these fuzzy LLMs shine.<p>That said, these LLM-based systems are great at writing &quot;change detection&quot; unit tests that offer ~zero value (or negative).</div><br/><div id="41990448" class="c"><input type="checkbox" id="c-41990448" checked=""/><div class="controls bullet"><span class="by">tensor</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989844">parent</a><span>|</span><a href="#41989939">next</a><span>|</span><label class="collapse" for="c-41990448">[-]</label><label class="expand" for="c-41990448">[6 more]</label></div><br/><div class="children"><div class="content">The fact that you think &quot;change detection&quot; tests offer zero value speaks volumes. Those may well be the most important use of unit tests. Getting the function correct in the first place isn&#x27;t that hard for a senior developer, which is often why it&#x27;s tempting to skip unit tests. But then you go refactor something and oops you broke it without realizing it, some boring obvious edge case, or the like.<p>These tests are also very time consuming to write, with lots of boilerplate that AI is very good at writing.</div><br/><div id="41992633" class="c"><input type="checkbox" id="c-41992633" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990448">parent</a><span>|</span><a href="#41992644">next</a><span>|</span><label class="collapse" for="c-41992633">[-]</label><label class="expand" for="c-41992633">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The fact that you think &quot;change detection&quot; tests offer zero value speaks volumes.<p>But code should change. What shouldn&#x27;t change, if business rules don&#x27;t change, is APIs and contracts. And for that we have integration tests and end to end tests.</div><br/></div></div><div id="41992644" class="c"><input type="checkbox" id="c-41992644" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990448">parent</a><span>|</span><a href="#41992633">prev</a><span>|</span><a href="#41990807">next</a><span>|</span><label class="collapse" for="c-41992644">[-]</label><label class="expand" for="c-41992644">[1 more]</label></div><br/><div class="children"><div class="content">&gt;But then you go refactor something and oops you broke it without realizing it, some boring obvious edge case, or the like<p>I will start to care when integration tests are failing, because that is an actual bug. Then I will fix the bug and move over.</div><br/></div></div><div id="41990807" class="c"><input type="checkbox" id="c-41990807" checked=""/><div class="controls bullet"><span class="by">chairhairair</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990448">parent</a><span>|</span><a href="#41992644">prev</a><span>|</span><a href="#41990618">next</a><span>|</span><label class="collapse" for="c-41990807">[-]</label><label class="expand" for="c-41990807">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;testing.googleblog.com&#x2F;2015&#x2F;01&#x2F;testing-on-toilet-change-detector-tests.html" rel="nofollow">https:&#x2F;&#x2F;testing.googleblog.com&#x2F;2015&#x2F;01&#x2F;testing-on-toilet-cha...</a><p>&quot;speaks volumes&quot; lol</div><br/></div></div><div id="41990618" class="c"><input type="checkbox" id="c-41990618" checked=""/><div class="controls bullet"><span class="by">mattmanser</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990448">parent</a><span>|</span><a href="#41990807">prev</a><span>|</span><a href="#41989939">next</a><span>|</span><label class="collapse" for="c-41990618">[-]</label><label class="expand" for="c-41990618">[2 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;ve misunderstood what he meant by change detection (not GP, could be wrong).<p>Hard to describe, easy to spot.<p>Some people write tests that are tightly coupled to their particular implementation.<p>They might have tons of setup code in each test. So refactoring means each test needs extensive rewrites.<p>Or there will be loads of asserts that have little to do with the actual thing being tested.<p>These tests usually have negative value as your only real option as another developer is to simply delete them all and start again.<p>That&#x27;s what I would interpret the GP as meaning when they use the phrase &quot;change detection&quot; tests.</div><br/><div id="41992661" class="c"><input type="checkbox" id="c-41992661" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990618">parent</a><span>|</span><a href="#41989939">next</a><span>|</span><label class="collapse" for="c-41992661">[-]</label><label class="expand" for="c-41992661">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Some people write tests that are tightly coupled to their particular implementation.<p>That is not due to people choice but due to what actual code being tested does.<p>I think integration tests and end to end tests are much better.</div><br/></div></div></div></div></div></div><div id="41989939" class="c"><input type="checkbox" id="c-41989939" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989844">parent</a><span>|</span><a href="#41990448">prev</a><span>|</span><a href="#41990748">next</a><span>|</span><label class="collapse" for="c-41989939">[-]</label><label class="expand" for="c-41989939">[2 more]</label></div><br/><div class="children"><div class="content">&gt; That said, these LLM-based systems are great at writing &quot;change detection&quot; unit tests that offer ~zero value (or negative).<p>That’s not at all true in my experience. With minimal guidance they put out pretty sensible tests.</div><br/><div id="41990501" class="c"><input type="checkbox" id="c-41990501" checked=""/><div class="controls bullet"><span class="by">filoleg</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989939">parent</a><span>|</span><a href="#41990748">next</a><span>|</span><label class="collapse" for="c-41990501">[-]</label><label class="expand" for="c-41990501">[1 more]</label></div><br/><div class="children"><div class="content">&gt; With minimal guidance[, LLM-based systems] put out pretty sensible tests.<p>Yes and no. They get out all the initial annoying boilerplate of writing tests out of the way, and the tests end up being mostly decent on the surface, but I have to manually tweak the behavior and write most of the important parts myself, especially for non-trivial tricky scenarios.<p>However, I am not saying this as a point against LLMs. The fact that they are able to get a good chunk of the boring boilerplate parts of writing unit tests out of the way and let me focus on the actual logic of individual tests has been noticeably helpful to me, personally.<p>I only use LLMs for the very first initial phase of writing unit tests, with most of the work still being done by me. But that initial phase is the most annoying and boring part of the process for me. So even if I still spend 90% of the time writing code manually, I still am very glad for being able to get that initial boring part out of the way quickly, without wasting my mental effort cycles on it.</div><br/></div></div></div></div></div></div></div></div><div id="41990748" class="c"><input type="checkbox" id="c-41990748" checked=""/><div class="controls bullet"><span class="by">hackable_sand</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989002">parent</a><span>|</span><a href="#41989730">prev</a><span>|</span><a href="#41989683">next</a><span>|</span><label class="collapse" for="c-41990748">[-]</label><label class="expand" for="c-41990748">[4 more]</label></div><br/><div class="children"><div class="content">I would love to find out<p>where programmers are learning this idea:<p>that writing code fast is ideal.<p>If it takes 30 years to write one loc, it takes 30 years.<p>Ideally, it takes 30 years to write zero lines of code.</div><br/><div id="41992584" class="c"><input type="checkbox" id="c-41992584" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990748">parent</a><span>|</span><a href="#41991428">next</a><span>|</span><label class="collapse" for="c-41992584">[-]</label><label class="expand" for="c-41992584">[1 more]</label></div><br/><div class="children"><div class="content">&gt;where programmers are learning this idea:<p>&gt;that writing code fast is ideal.<p>At places that pay them.</div><br/></div></div><div id="41991428" class="c"><input type="checkbox" id="c-41991428" checked=""/><div class="controls bullet"><span class="by">gitaarik</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990748">parent</a><span>|</span><a href="#41992584">prev</a><span>|</span><a href="#41989683">next</a><span>|</span><label class="collapse" for="c-41991428">[-]</label><label class="expand" for="c-41991428">[2 more]</label></div><br/><div class="children"><div class="content">The best programmers are no programmers!</div><br/><div id="41992043" class="c"><input type="checkbox" id="c-41992043" checked=""/><div class="controls bullet"><span class="by">hackable_sand</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991428">parent</a><span>|</span><a href="#41989683">next</a><span>|</span><label class="collapse" for="c-41992043">[-]</label><label class="expand" for="c-41992043">[1 more]</label></div><br/><div class="children"><div class="content">Alternatively,<p>more logic does not validate the truth.</div><br/></div></div></div></div></div></div></div></div><div id="41989683" class="c"><input type="checkbox" id="c-41989683" checked=""/><div class="controls bullet"><span class="by">miki123211</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41989002">prev</a><span>|</span><a href="#41992313">next</a><span>|</span><label class="collapse" for="c-41989683">[-]</label><label class="expand" for="c-41989683">[4 more]</label></div><br/><div class="children"><div class="content">For now, I mostly use AI as a &quot;faster typist&quot;.<p>If it wants to complete what I wanted to type anyway, or something extremely similar, I just press tab, otherwise I type my own code.<p>I&#x27;d say about 70% of individual lines are obvious enough if you have the surrounding context that this works pretty well in practice. This number is somewhat lower in normal code and higher in unit tests.<p>Another use case is writing one-off scripts that aren&#x27;t connected to any codebase in particular. If you&#x27;re doing a lot of work with data, this comes in very handy.<p>Something like &quot;here&#x27;s the header of a CSV file&quot;, pass each row through model x, only pass these three fields, the model will give you annotations, put these back in the csv and save, show progress, save every n rows in case of crashes, when the output file exists, skip already processed rows.&quot;<p>I&#x27;m not (yet) convinced by AI writing entire features, I tried that a few times and it was very inconsistent with the surrounding codebase. Managing which parts of the codebase to put in its context is definitely an art though.<p>It&#x27;s worth keeping in mind that this is the worst AI we&#x27;ll ever have, so this will probably get better soon.</div><br/><div id="41992700" class="c"><input type="checkbox" id="c-41992700" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989683">parent</a><span>|</span><a href="#41990162">next</a><span>|</span><label class="collapse" for="c-41992700">[-]</label><label class="expand" for="c-41992700">[1 more]</label></div><br/><div class="children"><div class="content">Yes, for simple boring tasks like converting a JSON to C# classes, it does wonders.<p>For everything clever it kind of needs baby sitting which doesn&#x27;t make it faster than writing the code myself.<p>Even for the glorified use case of writing unit tests it sucks unless the code is very simple with few dependencies.</div><br/></div></div><div id="41990162" class="c"><input type="checkbox" id="c-41990162" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989683">parent</a><span>|</span><a href="#41992700">prev</a><span>|</span><a href="#41989881">next</a><span>|</span><label class="collapse" for="c-41990162">[-]</label><label class="expand" for="c-41990162">[1 more]</label></div><br/><div class="children"><div class="content">Reminds me of how I use the satnav when driving.<p>I don&#x27;t close my eyes and do whatever it tells me to do. If I think I know better I don&#x27;t &quot;turn right at the next set of lights&quot; I just drive on as I would have before GPS and eventually realise that I went the wrong way or the satnav realises there was a perfectly valid 2nd&#x2F;3rd&#x2F;4th path to get to where I wanted to go.</div><br/></div></div><div id="41989881" class="c"><input type="checkbox" id="c-41989881" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989683">parent</a><span>|</span><a href="#41990162">prev</a><span>|</span><a href="#41992313">next</a><span>|</span><label class="collapse" for="c-41989881">[-]</label><label class="expand" for="c-41989881">[1 more]</label></div><br/><div class="children"><div class="content">One off scripts do work very well.</div><br/></div></div></div></div><div id="41992313" class="c"><input type="checkbox" id="c-41992313" checked=""/><div class="controls bullet"><span class="by">chilldsgn</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41989683">prev</a><span>|</span><a href="#41988885">next</a><span>|</span><label class="collapse" for="c-41992313">[-]</label><label class="expand" for="c-41992313">[1 more]</label></div><br/><div class="children"><div class="content">I used Jetbrains&#x27; AI Assistant for a while and I made the mistake of trusting some of its code, which introduced bugs and slowed me down to double-check a lot of the boilerplate I had it write for me.<p>Really not worth it for me at this point.<p>I must add that I found Anthropic&#x27;s Claude quite useful (Sonnet 3.5) when I had to work on a legacy code base using Adobe ColdFusion (*vomit). I knew nothing of Coldfusion or the awful code base, and it helped me figure out a lot of things about Coldfusion without having to spend too much energy on learning and generating code for a framework I will never again use. I still had to make some updates to the code, but it was less cognitive effort that having to read docs and spend time Googling.</div><br/></div></div><div id="41988885" class="c"><input type="checkbox" id="c-41988885" checked=""/><div class="controls bullet"><span class="by">SparkyMcUnicorn</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41992313">prev</a><span>|</span><a href="#41990245">next</a><span>|</span><label class="collapse" for="c-41988885">[-]</label><label class="expand" for="c-41988885">[3 more]</label></div><br/><div class="children"><div class="content">I haven&#x27;t used Cursor, but I use Aider with Sonnet 3.5 and also use Copilot for &quot;autocomplete&quot;.<p>I&#x27;d highly recommend reading through Aider&#x27;s docs[0], because I think it&#x27;s relevant for any AI tool you use. A lot of people harp on prompting, and while a good prompt is important I often see developers making other mistakes like not providing context that&#x27;s good, correct, or even too much[1].<p>When I find models are going on the wrong path with something, or &quot;connecting the pipes wrong&quot;, I often add code comments that provide additional clarity. Not only does this help future me&#x2F;devs, but the more I steer AI towards correct results, the fewer problems models seem to have going forward.<p>Everybody seems to be having wildly different experiences using AI for coding assistance, but I&#x27;ve personally found it to be a big productivity boost.<p>[0] <a href="https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;usage&#x2F;tips.html" rel="nofollow">https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;usage&#x2F;tips.html</a><p>[1] <a href="https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;troubleshooting&#x2F;edit-errors.html#reduce-distractions" rel="nofollow">https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;troubleshooting&#x2F;edit-errors.html#red...</a></div><br/><div id="41989125" class="c"><input type="checkbox" id="c-41989125" checked=""/><div class="controls bullet"><span class="by">realce</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41988885">parent</a><span>|</span><a href="#41990245">next</a><span>|</span><label class="collapse" for="c-41989125">[-]</label><label class="expand" for="c-41989125">[2 more]</label></div><br/><div class="children"><div class="content">Totally agree that heavy commenting is the best convention for helping the assistant help you best.  I try to comment in a way that makes a file or function into a &quot;story&quot; or kind of a single narrative.</div><br/><div id="41989376" class="c"><input type="checkbox" id="c-41989376" checked=""/><div class="controls bullet"><span class="by">jascha_eng</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989125">parent</a><span>|</span><a href="#41990245">next</a><span>|</span><label class="collapse" for="c-41989376">[-]</label><label class="expand" for="c-41989376">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s super interesting, I&#x27;ve been removing a lot of the redundant comments from the AI results. But adding new more explanatory ones that make it easier for both AI and humans to understand the code base makes a lot of sense in my head.<p>I was big on writing code to be easy to read for humans, but it being easy to read for AI hasn&#x27;t been a large concern of mine.</div><br/></div></div></div></div></div></div><div id="41990245" class="c"><input type="checkbox" id="c-41990245" checked=""/><div class="controls bullet"><span class="by">Yodel0914</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41988885">prev</a><span>|</span><a href="#41992436">next</a><span>|</span><label class="collapse" for="c-41990245">[-]</label><label class="expand" for="c-41990245">[4 more]</label></div><br/><div class="children"><div class="content">I find chatgpt incredibly useful for writing scripts against well-known APIs, or for a &quot;better stackoverflow&quot;. Things like &quot;how do I use a cursor in sql&quot; or &quot;in a devops yaml pipeline, I want to trigger another pipeline. How do I do that?&quot;.<p>But working on our actual codebase with copilot in the IDE (Rider, in my case) is a net negative. It usually does OK when it&#x27;s suggesting the completion of a single line, but when it decides to generate a whole block it invariably misunderstands the point of the code. I could imagine that getting better if I wrote more descriptive method names or comments, but the killer for me is that it just makes up methods and method signatures, even for objects that are part of publicly documented frameworks&#x2F;APIs.</div><br/><div id="41992716" class="c"><input type="checkbox" id="c-41992716" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990245">parent</a><span>|</span><a href="#41990431">next</a><span>|</span><label class="collapse" for="c-41992716">[-]</label><label class="expand" for="c-41992716">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&quot;better stackoverflow&quot;<p>I had asked hard questions on SO that only a human with experience can answer. And I found answers on SO that only a human with experience can answer.</div><br/></div></div><div id="41990431" class="c"><input type="checkbox" id="c-41990431" checked=""/><div class="controls bullet"><span class="by">jmpeax</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990245">parent</a><span>|</span><a href="#41992716">prev</a><span>|</span><a href="#41991495">next</a><span>|</span><label class="collapse" for="c-41990431">[-]</label><label class="expand" for="c-41990431">[1 more]</label></div><br/><div class="children"><div class="content">Same here. If you need to lookup how to do something in an api I find it much faster to use chatgpt than to try to search through the janky official docs or in some github examples folder. Chatgpt is basically documentation search 2.0.</div><br/></div></div><div id="41991495" class="c"><input type="checkbox" id="c-41991495" checked=""/><div class="controls bullet"><span class="by">deepfriedbits</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41990245">parent</a><span>|</span><a href="#41990431">prev</a><span>|</span><a href="#41992436">next</a><span>|</span><label class="collapse" for="c-41991495">[-]</label><label class="expand" for="c-41991495">[1 more]</label></div><br/><div class="children"><div class="content">I love your framing of it as a &quot;better stackoverflow.&quot; That&#x27;s so true. However, I feel like some of our complaints about accuracy and hidden bugs are temporary pain (12-36) months before the tools truly become mind-blowing productivity multipliers.</div><br/></div></div></div></div><div id="41992436" class="c"><input type="checkbox" id="c-41992436" checked=""/><div class="controls bullet"><span class="by">chrisandchris</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41990245">prev</a><span>|</span><a href="#41989698">next</a><span>|</span><label class="collapse" for="c-41992436">[-]</label><label class="expand" for="c-41992436">[1 more]</label></div><br/><div class="children"><div class="content">Similar experience. I used Gitlab Duo and now the JetBrains AI assistant (the small one which does inly inline).<p>What I notice is that line-completion is quite good if you read the produced code in prosa. But most of the times the internals are different, and so the completed line is still useless.<p>E.g. assume an Enum Completion with values InlineCompletion, FullLine, NoCompletion.<p>If i write<p>&gt; if (currentMode == Compl<p>It will happily suggest<p>&gt; if (currentMode == Completion.FullLineCompletion) {<p>while not realizing that this enum values does not exist.</div><br/></div></div><div id="41989698" class="c"><input type="checkbox" id="c-41989698" checked=""/><div class="controls bullet"><span class="by">pnathan</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41992436">prev</a><span>|</span><a href="#41992420">next</a><span>|</span><label class="collapse" for="c-41989698">[-]</label><label class="expand" for="c-41989698">[1 more]</label></div><br/><div class="children"><div class="content">In general I do not find AI a net positive. Other tools seem to do at least as well in general.<p>it can be used if you want the reliability of a random forum poster. which... sure. knock yourself out. sometimes there&#x27;s gems in that dirt.<p>I&#x27;m getting _very_ bearish on using LLMs for things that aren&#x27;t pattern recognition.</div><br/></div></div><div id="41992420" class="c"><input type="checkbox" id="c-41992420" checked=""/><div class="controls bullet"><span class="by">resonious</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41989698">prev</a><span>|</span><a href="#41992384">next</a><span>|</span><label class="collapse" for="c-41992420">[-]</label><label class="expand" for="c-41992420">[1 more]</label></div><br/><div class="children"><div class="content">I had the same experience with Copilot and stopped using it. Been somewhat tempted to try Cursor thinking maybe it&#x27;s gotten better but this comment is suggesting that maybe it&#x27;s not.<p>I get the best use out of straight up ChatGPT. It&#x27;s like a cheatsheet for everything.</div><br/></div></div><div id="41992384" class="c"><input type="checkbox" id="c-41992384" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41992420">prev</a><span>|</span><a href="#41992191">next</a><span>|</span><label class="collapse" for="c-41992384">[-]</label><label class="expand" for="c-41992384">[1 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t use it but I&#x27;ve seen videos where people used Cline with Claude to modify the source and afterwards, have Cline run the app collect the errors and fix them.<p>The examples were small and trivial, though. I am not sure how that would work in large and complex code bases.</div><br/></div></div><div id="41992191" class="c"><input type="checkbox" id="c-41992191" checked=""/><div class="controls bullet"><span class="by">willtemperley</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41992384">prev</a><span>|</span><a href="#41989100">next</a><span>|</span><label class="collapse" for="c-41992191">[-]</label><label class="expand" for="c-41992191">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve found explaining boilerplate code to Claude or ChatGPT has been very worthwhile, the boring code gets written and the prompt is the documentation.<p>OTOH tab completion in Intellij and Xcode has been useful occasionally, usually distracting and sometimes annoying. A way to fast toggle this would be good, but when I know what I want to code, good old code completion works nicely thanks.</div><br/></div></div><div id="41989100" class="c"><input type="checkbox" id="c-41989100" checked=""/><div class="controls bullet"><span class="by">knallfrosch</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41992191">prev</a><span>|</span><a href="#41991154">next</a><span>|</span><label class="collapse" for="c-41989100">[-]</label><label class="expand" for="c-41989100">[1 more]</label></div><br/><div class="children"><div class="content">I use it for an unfamiliar programming language and it&#x27;s very nice. You can also ask it to explain badly documented code.</div><br/></div></div><div id="41991154" class="c"><input type="checkbox" id="c-41991154" checked=""/><div class="controls bullet"><span class="by">grensley</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41989100">prev</a><span>|</span><a href="#41988764">next</a><span>|</span><label class="collapse" for="c-41991154">[-]</label><label class="expand" for="c-41991154">[1 more]</label></div><br/><div class="children"><div class="content">I think there&#x27;s a number of factors that make it work as well as it does for me:<p>- Mostly writing React<p>- Not using any obscure or new libraries<p>- Naming things well<p>- Keeping logic simple<p>- Leaving a comment at the point where I&#x27;m about to make a shift from what the common logic would be<p>- Getting a feel for when it&#x27;s going to be able to correctly guess or not (and not even reading it if I think it&#x27;s going to be wrong)<p>- Trusting short blocks more than long ones</div><br/></div></div><div id="41988764" class="c"><input type="checkbox" id="c-41988764" checked=""/><div class="controls bullet"><span class="by">MangoCoffee</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41991154">prev</a><span>|</span><a href="#41989552">next</a><span>|</span><label class="collapse" for="c-41988764">[-]</label><label class="expand" for="c-41988764">[8 more]</label></div><br/><div class="children"><div class="content">Time will tell. As a GitHub Copilot user, I still review the code.<p>SpaceX&#x27;s advancements are impressive, from rocket blow up to successfully catching the Starship booster.<p>Who knows what AI will be capable of in 5-10 years? Perhaps it will revolutionize code assistance or even replace developers</div><br/><div id="41988950" class="c"><input type="checkbox" id="c-41988950" checked=""/><div class="controls bullet"><span class="by">outworlder</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41988764">parent</a><span>|</span><a href="#41988966">next</a><span>|</span><label class="collapse" for="c-41988950">[-]</label><label class="expand" for="c-41988950">[2 more]</label></div><br/><div class="children"><div class="content">&gt; SpaceX&#x27;s advancements are impressive, from rocket blow up to successfully catching the Starship booster.<p>That felt like it was LLM generated since that doesn&#x27;t have anything to do with the subject being discussed. Not only it&#x27;s on a different industry but it&#x27;s a completely different set of problems. We know what&#x27;s involved in catching a rocket. It&#x27;s a massive engineering challenge yes, but we all know it can be done(whether or not it makes sense or is economically viable are different issues).<p>Even going to the Moon – which was a massive project and took massive focus from an entire country to do – was a matter of developing the equipment, procedures, calculations (and yes, some software). We knew back then it could be done, and roughly how.<p>Artificial intelligence? We don&#x27;t know enough about &quot;intelligence&quot;. There isn&#x27;t even a target to reach right now. If we said &quot;resources aren&#x27;t a problem, let&#x27;s build AI&quot;, there isn&#x27;t a single person on this planet that can tell you how to build such an AI or even which technologies need to be developed.<p>More to the point, current LLMs are able to probabilistically generate data based on prompts. That&#x27;s pretty much it. They don&#x27;t &quot;know&quot; anything about what they are generating, they can&#x27;t reason about it. In order for &quot;AI&quot; to replace developers entirely, we need other big advancements in the field, which may or may not come.</div><br/><div id="41989463" class="c"><input type="checkbox" id="c-41989463" checked=""/><div class="controls bullet"><span class="by">dspillett</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41988950">parent</a><span>|</span><a href="#41988966">next</a><span>|</span><label class="collapse" for="c-41989463">[-]</label><label class="expand" for="c-41989463">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Artificial intelligence? We don&#x27;t know enough about &quot;intelligence&quot;.</i><p>The problem I have with this objection is that it, like many discussions, conflates LLMs (glorified predictive text) and other technologies currently being referred to as AI, with AGI.<p>Most of these technologies should still be called machine learning as they aren&#x27;t really doing anything intelligent in the sense of general intelligence. As you say yourself: they don&#x27;t know anything. And by inference, they aren&#x27;t <i>reasoning</i> about anything.<p>Boilerplate code for common problems, and some not so common ones, which is what LLMs are getting pretty OK at and might in the coming years be very good at, <i>is</i> a definable problem that we understand quite well. And much as we like to think of ourselves as &quot;computer scientists&quot;, the vast majority of what we do boils down to boilerplate code using common primitives, that are remarkably similar across many problem domains that might on first look appear to be quite different, because many of the same primitives and compound structures are used. The bits that require actual intelligence are often quite small (this is how <i>I</i> survive as a dev!), or are away from the development coalface (for instance: discovering and defining the problems before we can solve them, or describing the problem &amp; solution such that someone or an &quot;AI&quot; can do the legwork).<p><i>&gt; we need other big advancements in the field, which may or may not come.</i><p>I&#x27;m waiting for an LLM being guided to create a better LLM, and eventually down that chain a real AGI popping into existence, much like the infinite improbability drive being created by clever use of a late version finite improbability generator. This is (hopefully) many years (in fact I&#x27;m hoping for at least a couple of decades so I can be safely retired or nearly there!) from happening, but it feels like such things are just over the next deep valley of disillusionment.</div><br/></div></div></div></div><div id="41988966" class="c"><input type="checkbox" id="c-41988966" checked=""/><div class="controls bullet"><span class="by">olivermuty</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41988764">parent</a><span>|</span><a href="#41988950">prev</a><span>|</span><a href="#41990363">next</a><span>|</span><label class="collapse" for="c-41988966">[-]</label><label class="expand" for="c-41988966">[4 more]</label></div><br/><div class="children"><div class="content">Except cursor is the fireworks based on black powder here. It will look good, but as a technology to get you to the moon it seems to look like a dead end. NOTHING (of serious science) seems to indicate LLMs being anything but a dead end with the current hardware capabilites.<p>So then I ask: What, in qualitative terms, makes you think AI in the current form will be capable of this in 5 or 10 years? Other than seeing the middle of what seems to be an S-curve and going «ooooh shiny exponential!»</div><br/><div id="41989019" class="c"><input type="checkbox" id="c-41989019" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41988966">parent</a><span>|</span><a href="#41989471">next</a><span>|</span><label class="collapse" for="c-41989019">[-]</label><label class="expand" for="c-41989019">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>NOTHING (of serious science) seems to indicate LLMs being anything but a dead end with the current hardware capabilites.</i><p>In the same sense that black powder sucks as a rocket propellant - but it&#x27;s enough to demonstrate that iterating on the same architecture and using better fuels <i>will</i> get you to the Moon eventually. LLMs of today are starting points, and many ideas for architectural improvements are being explored, and nothing in serious science suggests <i>that</i> will be a dead end any time soon.</div><br/><div id="41989896" class="c"><input type="checkbox" id="c-41989896" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41989019">parent</a><span>|</span><a href="#41989471">next</a><span>|</span><label class="collapse" for="c-41989896">[-]</label><label class="expand" for="c-41989896">[1 more]</label></div><br/><div class="children"><div class="content">It’s easy to say with hindsight but if all you have is black powder I don’t think it’s obvious those better fuels even exist.</div><br/></div></div></div></div><div id="41989471" class="c"><input type="checkbox" id="c-41989471" checked=""/><div class="controls bullet"><span class="by">dbmikus</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41988966">parent</a><span>|</span><a href="#41989019">prev</a><span>|</span><a href="#41990363">next</a><span>|</span><label class="collapse" for="c-41989471">[-]</label><label class="expand" for="c-41989471">[1 more]</label></div><br/><div class="children"><div class="content">If you look at LLM performance on benchmarks, they keep getting better at a fast rate.[1]<p>We also now have models of various sizes trained in general matters, and those can now be tuned or fine-tuned to specific domains. The advances in multi-modal AI are also happening very quickly as well. Model specialization, model reflection (chain of thought, OpenAI&#x27;s new O1 model, etc.) are also undergoing rapid experimentation.<p>Two demonstrable things that LLMs don&#x27;t do well currently, are (1) generalize quickly to out-of-distribution examples, (2) catch logic mistakes in questions that look very similar to training data, but are modified. This video talks about both of these things.[2]<p>I think I-JEPA is a pretty interesting line of work towards solving these problems. I also think that multi-modal AI pushes in a similar direction. We need AI to learn abstractions that are more decoupled from the source format, and we need AI that can reflect and modify its plans and update itself in real time.<p>All these lines of research and development are more-or-less underway. I think 5-10 years is reasonable for  another big advancement in AI capability. We&#x27;ve shown that applying data at scale to simple models works, and now we can experiment with other representations of that data (ie other models or ways to combine LLM inferences).<p>[1]: <a href="https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;3-5-models-and-computer-use" rel="nofollow">https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;3-5-models-and-computer-use</a>
[2]: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=s7_NlkBwdj8" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=s7_NlkBwdj8</a></div><br/></div></div></div></div><div id="41990363" class="c"><input type="checkbox" id="c-41990363" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41988764">parent</a><span>|</span><a href="#41988966">prev</a><span>|</span><a href="#41989552">next</a><span>|</span><label class="collapse" for="c-41990363">[-]</label><label class="expand" for="c-41990363">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  or even replace developers<p>I don&#x27;t think there will be a &#x27;replace developers, but other work remains extant&#x27; moment - not at least for very long at all.</div><br/></div></div></div></div><div id="41989552" class="c"><input type="checkbox" id="c-41989552" checked=""/><div class="controls bullet"><span class="by">fullstackwife</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41988764">prev</a><span>|</span><a href="#41992292">next</a><span>|</span><label class="collapse" for="c-41989552">[-]</label><label class="expand" for="c-41989552">[1 more]</label></div><br/><div class="children"><div class="content">One of the reasons for that may be the price: large code changes with multi turn conversation can eat up a lot of tokens, while those tools charge you a flat price per month. Probably many hacks are done under the hood to keep *their* costs low, and the user experiences this as lower quality responses.<p>Still the &quot;architecture and core libraries&quot; is rather corner case, something at the bottom of their current sales funnel.<p>also: do you really want to get equivalent of 1 FTE work for 20 USD per month?:)</div><br/></div></div><div id="41992292" class="c"><input type="checkbox" id="c-41992292" checked=""/><div class="controls bullet"><span class="by">faangguyindia</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41989552">prev</a><span>|</span><a href="#41991120">next</a><span>|</span><label class="collapse" for="c-41992292">[-]</label><label class="expand" for="c-41992292">[1 more]</label></div><br/><div class="children"><div class="content">Zed AI is much better than cursor I&#x27;ve found.</div><br/></div></div><div id="41991120" class="c"><input type="checkbox" id="c-41991120" checked=""/><div class="controls bullet"><span class="by">breckenedge</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41992292">prev</a><span>|</span><a href="#41989614">next</a><span>|</span><label class="collapse" for="c-41991120">[-]</label><label class="expand" for="c-41991120">[2 more]</label></div><br/><div class="children"><div class="content">Tab complete is just one of their proprietary models. I find chat-mode more helpful for refactoring and multi-file updates, even more when I specify the exact files to include.</div><br/><div id="41992764" class="c"><input type="checkbox" id="c-41992764" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41991120">parent</a><span>|</span><a href="#41989614">next</a><span>|</span><label class="collapse" for="c-41992764">[-]</label><label class="expand" for="c-41992764">[1 more]</label></div><br/><div class="children"><div class="content">I think SuperMaven has tab complete and let&#x27;s you chose the model.</div><br/></div></div></div></div><div id="41989614" class="c"><input type="checkbox" id="c-41989614" checked=""/><div class="controls bullet"><span class="by">tomrod</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41991120">prev</a><span>|</span><a href="#41989972">next</a><span>|</span><label class="collapse" for="c-41989614">[-]</label><label class="expand" for="c-41989614">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love an autoselected LLM that is fine-tuned to the syntax I&#x27;m actively using -- Cursor has a bit of a head start, but where Github and others can take it could be mindblowing (Cursor&#x27;s moat is a decent VS Code extension -- I&#x27;m not sure it&#x27;s a deep moat though).</div><br/></div></div><div id="41989972" class="c"><input type="checkbox" id="c-41989972" checked=""/><div class="controls bullet"><span class="by">Aeolun</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41989614">prev</a><span>|</span><a href="#41992327">next</a><span>|</span><label class="collapse" for="c-41989972">[-]</label><label class="expand" for="c-41989972">[1 more]</label></div><br/><div class="children"><div class="content">&gt; in practice I’m not noticing a productivity boost<p>I am. Can suddenly do in a weekend what would have taken a week.</div><br/></div></div><div id="41992327" class="c"><input type="checkbox" id="c-41992327" checked=""/><div class="controls bullet"><span class="by">nsonha</span><span>|</span><a href="#41988665">parent</a><span>|</span><a href="#41989972">prev</a><span>|</span><a href="#41991122">next</a><span>|</span><label class="collapse" for="c-41992327">[-]</label><label class="expand" for="c-41992327">[2 more]</label></div><br/><div class="children"><div class="content">&gt; cursor and its tab completion<p>If this is how you use Cursor then you dont need Cursor. Autocomplete has existed even before AI, but Cursor&#x27;s selling point is in multi-files editing and a sensible workflow that let users iterate through diffs in the UI.<p>I have never used AI to generate code, only to edit. I can see it useful in both, and we should look at all usecases of AI instead of looking at it as glorified autocomplete.</div><br/><div id="41992779" class="c"><input type="checkbox" id="c-41992779" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41988665">root</a><span>|</span><a href="#41992327">parent</a><span>|</span><a href="#41991122">next</a><span>|</span><label class="collapse" for="c-41992779">[-]</label><label class="expand" for="c-41992779">[1 more]</label></div><br/><div class="children"><div class="content">&gt;If this is how you use Cursor then you dont need Cursor.<p>I&#x27;ve tried Cursor yesterday only to realise it can&#x27;t run and debug C# projects.</div><br/></div></div></div></div></div></div><div id="41991122" class="c"><input type="checkbox" id="c-41991122" checked=""/><div class="controls bullet"><span class="by">AIorNot</span><span>|</span><a href="#41988665">prev</a><span>|</span><a href="#41992022">next</a><span>|</span><label class="collapse" for="c-41991122">[-]</label><label class="expand" for="c-41991122">[17 more]</label></div><br/><div class="children"><div class="content">Reviewing these conversations is like listening to horse and buggy manufacturers pooh-poohing automobiles:<p>1. they will scare the horses. a good team of horses is no match for funky &#x27;automobile&#x27;<p>2. how will they be able to deal with our muddy, messy roads<p>3. their engines are unreliable and prone to breaking down 
stranding you in the middle and having to do it yourself..<p>4. their drivers cant handle the speed, too many miles driven means unsafe driving.. we should stick to horses they are manageable.<p>Meanwhile I&#x27;m watching a community of mostly young people building and using tools like copilot, cursor, replit, jacob etc and wiring up LLMs into increasingly more complex workflows.<p>this is snapshot of the current state, not a reflection of the future-  Give it 10 years</div><br/><div id="41991636" class="c"><input type="checkbox" id="c-41991636" checked=""/><div class="controls bullet"><span class="by">fumeux_fume</span><span>|</span><a href="#41991122">parent</a><span>|</span><a href="#41991577">next</a><span>|</span><label class="collapse" for="c-41991636">[-]</label><label class="expand" for="c-41991636">[4 more]</label></div><br/><div class="children"><div class="content">Reading this comment is like listening to Tesla in 2014 tell me about how their cars will be driving themselves. Give it 10 years.</div><br/><div id="41992990" class="c"><input type="checkbox" id="c-41992990" checked=""/><div class="controls bullet"><span class="by">hmottestad</span><span>|</span><a href="#41991122">root</a><span>|</span><a href="#41991636">parent</a><span>|</span><a href="#41993026">next</a><span>|</span><label class="collapse" for="c-41992990">[-]</label><label class="expand" for="c-41992990">[1 more]</label></div><br/><div class="children"><div class="content">Tesla might not have managed to do it, but Waymo had over 7.1 million miles driven by their driverless cars by 2023: <a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;12&#x2F;20&#x2F;24006712&#x2F;waymo-driverless-million-mile-safety-compare-human" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;12&#x2F;20&#x2F;24006712&#x2F;waymo-driverles...</a><p>I&#x27;m still waiting for the future where a robot maid does my dishes, hangs my clothes, tidies and vacuums my apartment while I&#x27;m working on my piano skills. But at least I now have a robot vacuum with a camera that avoids whatever toys I forgot to pick up.</div><br/></div></div><div id="41993026" class="c"><input type="checkbox" id="c-41993026" checked=""/><div class="controls bullet"><span class="by">luckydata</span><span>|</span><a href="#41991122">root</a><span>|</span><a href="#41991636">parent</a><span>|</span><a href="#41992990">prev</a><span>|</span><a href="#41992300">next</a><span>|</span><label class="collapse" for="c-41993026">[-]</label><label class="expand" for="c-41993026">[1 more]</label></div><br/><div class="children"><div class="content">It might not be perfect yet but my huble Model 3 drove me to a doctor appointment all by itself from my driveway last week. I would say it&#x27;s pretty damn impressive the kind of progress they were able to make.</div><br/></div></div><div id="41992300" class="c"><input type="checkbox" id="c-41992300" checked=""/><div class="controls bullet"><span class="by">chii</span><span>|</span><a href="#41991122">root</a><span>|</span><a href="#41991636">parent</a><span>|</span><a href="#41993026">prev</a><span>|</span><a href="#41991577">next</a><span>|</span><label class="collapse" for="c-41992300">[-]</label><label class="expand" for="c-41992300">[1 more]</label></div><br/><div class="children"><div class="content">humans greatly over estimate trends short-term, and greatly under estimate it long-term .</div><br/></div></div></div></div><div id="41991577" class="c"><input type="checkbox" id="c-41991577" checked=""/><div class="controls bullet"><span class="by">hhdhdbdb</span><span>|</span><a href="#41991122">parent</a><span>|</span><a href="#41991636">prev</a><span>|</span><a href="#41991909">next</a><span>|</span><label class="collapse" for="c-41991577">[-]</label><label class="expand" for="c-41991577">[2 more]</label></div><br/><div class="children"><div class="content">I dont see a young&#x2F;old divide when it comes to AI. Altough there is a young&#x2F;old divide in familial responsibilies and willingness to be a chip on the VC&#x27;s roulette table.</div><br/><div id="41992033" class="c"><input type="checkbox" id="c-41992033" checked=""/><div class="controls bullet"><span class="by">frank_nitti</span><span>|</span><a href="#41991122">root</a><span>|</span><a href="#41991577">parent</a><span>|</span><a href="#41991909">next</a><span>|</span><label class="collapse" for="c-41992033">[-]</label><label class="expand" for="c-41992033">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely true. The oldest devs I work with are some of the most enthusiastic about using LLM chat to develop. Among the younger devs, they all seem to use it but the amount that can actually produce working code are few.<p>Now I get a lot of calls from team asking for help fixing some  code they got from an AI.. Overall it is improving the code quality from the group, I no longer have to instruct people on basics to set up their approach&#x2F;solution. Will admit there is a little difficulty dealing with pushback on my guidance because e.g. “well chatgpt said I should use this library” when the core SDK already supports something more recent than the AI was trained on</div><br/></div></div></div></div><div id="41991909" class="c"><input type="checkbox" id="c-41991909" checked=""/><div class="controls bullet"><span class="by">FrequentLurker</span><span>|</span><a href="#41991122">parent</a><span>|</span><a href="#41991577">prev</a><span>|</span><a href="#41991569">next</a><span>|</span><label class="collapse" for="c-41991909">[-]</label><label class="expand" for="c-41991909">[1 more]</label></div><br/><div class="children"><div class="content">Except the automobile in this case only reaches the destination correctly sometimes. They are less likely to reach the destination as the path becomes longer or more complex.</div><br/></div></div><div id="41991569" class="c"><input type="checkbox" id="c-41991569" checked=""/><div class="controls bullet"><span class="by">enumjorge</span><span>|</span><a href="#41991122">parent</a><span>|</span><a href="#41991909">prev</a><span>|</span><a href="#41991898">next</a><span>|</span><label class="collapse" for="c-41991569">[-]</label><label class="expand" for="c-41991569">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure why people can&#x27;t be humble enough to accept that we don&#x27;t really know what the future will hold. Just because people have underestimated some new technology in the past doesn&#x27;t mean that will continue to be true for all new technologies.<p>The fact that LLMs currently do not really understand the answers they&#x27;re giving you is a pretty significant limitation they have. It doesn&#x27;t make them useless, but it means they&#x27;re not as useful at a lot of tasks that people think they can handle. And that limitation is also fundamental to how LLMs work. Can that be overcome? Maybe. There&#x27;s certainly a ton of money behind it and a lot of smart people are working on it. But is it guaranteed?<p>Perhaps I&#x27;m wrong and we already know that it&#x27;s simply a matter of time. I&#x27;d love to read an technical explanation for why that is, but I mostly see people rolling their eyes at us mere mortals who don&#x27;t see how this will obviously change everything as if we&#x27;re too small minded to understand what&#x27;s going on.<p>To be extra clear, I&#x27;m not saying LLMs won&#x27;t be a technological innovation as seismic as the invention of the car. My confusion is why for some there doesn&#x27;t seem to be room for doubt.</div><br/><div id="41993033" class="c"><input type="checkbox" id="c-41993033" checked=""/><div class="controls bullet"><span class="by">luckydata</span><span>|</span><a href="#41991122">root</a><span>|</span><a href="#41991569">parent</a><span>|</span><a href="#41991898">next</a><span>|</span><label class="collapse" for="c-41993033">[-]</label><label class="expand" for="c-41993033">[1 more]</label></div><br/><div class="children"><div class="content">in the current state they are already plenty useful, I don&#x27;t think it&#x27;s worth proving mathematically that something can work 100% of the times when 80% is good enough.</div><br/></div></div></div></div><div id="41991898" class="c"><input type="checkbox" id="c-41991898" checked=""/><div class="controls bullet"><span class="by">hakunin</span><span>|</span><a href="#41991122">parent</a><span>|</span><a href="#41991569">prev</a><span>|</span><a href="#41991248">next</a><span>|</span><label class="collapse" for="c-41991898">[-]</label><label class="expand" for="c-41991898">[1 more]</label></div><br/><div class="children"><div class="content">Prospective and retrospective analysis are fundamentally different. It’s easy to point to successes and failures of the past, but that’s not how we predict the concrete future potential of one specific thing.</div><br/></div></div><div id="41991248" class="c"><input type="checkbox" id="c-41991248" checked=""/><div class="controls bullet"><span class="by">crop_rotation</span><span>|</span><a href="#41991122">parent</a><span>|</span><a href="#41991898">prev</a><span>|</span><a href="#41991606">next</a><span>|</span><label class="collapse" for="c-41991248">[-]</label><label class="expand" for="c-41991248">[2 more]</label></div><br/><div class="children"><div class="content">It is hard to understand some phenomena if it stands to reduce your income. Even if the LLMs don&#x27;t improve one bit from here and current state is froze, they are still too good and will be everywhere before we can finish talking of horses and automobiles.</div><br/><div id="41991608" class="c"><input type="checkbox" id="c-41991608" checked=""/><div class="controls bullet"><span class="by">hhdhdbdb</span><span>|</span><a href="#41991122">root</a><span>|</span><a href="#41991248">parent</a><span>|</span><a href="#41991606">next</a><span>|</span><label class="collapse" for="c-41991608">[-]</label><label class="expand" for="c-41991608">[1 more]</label></div><br/><div class="children"><div class="content">LLMs make my job as a software engineer even more secure. Most of what I do is social and&#x2F;or understand what is going on. LLMs are a tool to reduce mental load when in VSCode on some tasks. They are like the pilot&#x27;s autopilot.<p>LLM takes my job then we have reached the singularity. Jobs wont matter anymore at that point.</div><br/></div></div></div></div><div id="41991606" class="c"><input type="checkbox" id="c-41991606" checked=""/><div class="controls bullet"><span class="by">ENGNR</span><span>|</span><a href="#41991122">parent</a><span>|</span><a href="#41991248">prev</a><span>|</span><a href="#41991336">next</a><span>|</span><label class="collapse" for="c-41991606">[-]</label><label class="expand" for="c-41991606">[1 more]</label></div><br/><div class="children"><div class="content">I think a lot of the criticism is constructive. Many of the limitations won’t just magically go away - we’ll have to build tooling and processes and adjust our way of thinking to get there. Most devs will jump across to anything useful the second it’s ready, I would think</div><br/></div></div><div id="41991336" class="c"><input type="checkbox" id="c-41991336" checked=""/><div class="controls bullet"><span class="by">wruza</span><span>|</span><a href="#41991122">parent</a><span>|</span><a href="#41991606">prev</a><span>|</span><a href="#41992477">next</a><span>|</span><label class="collapse" for="c-41991336">[-]</label><label class="expand" for="c-41991336">[1 more]</label></div><br/><div class="children"><div class="content">A reminder that we basically <i>built cities</i> around the cars, cause they still need fuel, break and drown in the mud.<p>What is your similar plan for LLMs?<p>Analogies always end somewhere, I’m just curious where yours does.</div><br/></div></div><div id="41992477" class="c"><input type="checkbox" id="c-41992477" checked=""/><div class="controls bullet"><span class="by">globular-toast</span><span>|</span><a href="#41991122">parent</a><span>|</span><a href="#41991336">prev</a><span>|</span><a href="#41992022">next</a><span>|</span><label class="collapse" for="c-41992477">[-]</label><label class="expand" for="c-41992477">[2 more]</label></div><br/><div class="children"><div class="content">The funny thing about this comment is there&#x27;s an increasing number of people beginning to think automobiles <i>were</i> a mistake. They pollute, they&#x27;re unhealthy, dangerous, cause congestion, but we&#x27;ve built our lives around them and basically addicted to them.<p>LLMs piece together language based on other language they&#x27;ve seen. It&#x27;s not intelligent, it&#x27;s just a language tool. Currently we have no idea what will happen once there are no more human inputs to train the LLMs. We might end up wishing we didn&#x27;t build our whole lives around LLMs.</div><br/><div id="41992908" class="c"><input type="checkbox" id="c-41992908" checked=""/><div class="controls bullet"><span class="by">GreenWatermelon</span><span>|</span><a href="#41991122">root</a><span>|</span><a href="#41992477">parent</a><span>|</span><a href="#41992022">next</a><span>|</span><label class="collapse" for="c-41992908">[-]</label><label class="expand" for="c-41992908">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. Cars are horrible, they made everything worse for everyone except the few people with money to buy a car.<p>Cars produce toxic fumes, air pollution, noise pollution with their engine noises and horns, light pollution with their headlights pointed directly into my fucking eye, consume incredible amounts  of resources to function, consume a fuckton of resources for road maintainability waste millions of man-hours in soul-crushing traffic jams, all that for them to be slower than me on my fucking bike inside the city.<p>Yeah the horse and buggy manufacturers were right, cars were a mistake. We just doubled down on that mistake.</div><br/></div></div></div></div></div></div><div id="41992022" class="c"><input type="checkbox" id="c-41992022" checked=""/><div class="controls bullet"><span class="by">hi_hi</span><span>|</span><a href="#41991122">prev</a><span>|</span><a href="#41986044">next</a><span>|</span><label class="collapse" for="c-41992022">[-]</label><label class="expand" for="c-41992022">[5 more]</label></div><br/><div class="children"><div class="content">Every single one of these discussion, at some point, devolves to some version of<p>- &lt;LLM Y&gt; is by far the best. In my extensive usage it is consistently outperforms &lt;LLM X&gt; by at least 2x. The difference is night and day.<p>Then the immediate child reply:<p>- What!? You must be holding it wrong. The complete inverse is true for me.<p>I don&#x27;t know what to make of this contradiction. We&#x27;re all using the same 2 things right? How can opinions vary by such a large amount. It makes me not trust any opinion on any other subject (which admittedly is not a bad default state, but who has time to form their own opinions on everything).</div><br/><div id="41992909" class="c"><input type="checkbox" id="c-41992909" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#41992022">parent</a><span>|</span><a href="#41992037">next</a><span>|</span><label class="collapse" for="c-41992909">[-]</label><label class="expand" for="c-41992909">[1 more]</label></div><br/><div class="children"><div class="content">Most of the LLM quality discussions have a shelf life measured in weeks. The companies involved are leap frogging each other with model updates and tweaks every few weeks.<p>Try it yourself. I&#x27;m getting a lot of value out of just using chat gpt for coding. It&#x27;s not without flaws. But I can get it to do a lot of routine stuff quite quickly. What I like about the desktop client is that a prompt is just one alt+space away. I usually just copy paste whatever I&#x27;m working on and then ask it to do stuff to it.<p>There&#x27;s some art to the prompting and you usually have to nudge it to not be lazy and do the whole thing you asked for. It seems engineers on the other side are working really hard to minimize token usage.<p>I find it&#x27;s increasingly the UX that&#x27;s holding me back, not the model quality. Context windows are now big enough to hold a lot of stuff. But how do you get everything in there that matters? Manually copy pasting together stuff is tedious. I actually wrote a script (well, with some llm help) that flattens things in my repository into a file that I then simply attach to a conversation. Works surprisingly well.</div><br/></div></div><div id="41992037" class="c"><input type="checkbox" id="c-41992037" checked=""/><div class="controls bullet"><span class="by">slimsag</span><span>|</span><a href="#41992022">parent</a><span>|</span><a href="#41992909">prev</a><span>|</span><a href="#41992156">next</a><span>|</span><label class="collapse" for="c-41992037">[-]</label><label class="expand" for="c-41992037">[1 more]</label></div><br/><div class="children"><div class="content">Lots of possibilities here.<p>People are learning to prompt LLMs in ways that produce better results for their LLM of choice, so switching to another one they find their approach no longer works as well.<p>Or.. LLMs have different personalities in terms of output; some being more or less direct&#x2F;polite than others, or sounding more or less confident; and that is causing people to perceive a difference that in terms of factual answers may not be different.<p>Or just personal preference masquerading as intelligence - a classic among software engineers.</div><br/></div></div><div id="41992156" class="c"><input type="checkbox" id="c-41992156" checked=""/><div class="controls bullet"><span class="by">psyklic</span><span>|</span><a href="#41992022">parent</a><span>|</span><a href="#41992037">prev</a><span>|</span><a href="#41992461">next</a><span>|</span><label class="collapse" for="c-41992156">[-]</label><label class="expand" for="c-41992156">[1 more]</label></div><br/><div class="children"><div class="content">Same reason as programming language flamewars. Coders assume their individual experience holds for every domain. Yet LLMs are good for some things, bad at others.</div><br/></div></div><div id="41992461" class="c"><input type="checkbox" id="c-41992461" checked=""/><div class="controls bullet"><span class="by">ffsm8</span><span>|</span><a href="#41992022">parent</a><span>|</span><a href="#41992156">prev</a><span>|</span><a href="#41986044">next</a><span>|</span><label class="collapse" for="c-41992461">[-]</label><label class="expand" for="c-41992461">[1 more]</label></div><br/><div class="children"><div class="content">Ever heard of astroturfing?</div><br/></div></div></div></div><div id="41986044" class="c"><input type="checkbox" id="c-41986044" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#41992022">prev</a><span>|</span><a href="#41986126">next</a><span>|</span><label class="collapse" for="c-41986044">[-]</label><label class="expand" for="c-41986044">[71 more]</label></div><br/><div class="children"><div class="content">This is pretty exciting. I&#x27;m a copilot user at work, but also have access to Claude. I&#x27;m more inclined to use Claude for difficult coding problems or to review my work as I&#x27;ve just grown more confident in its abilities over the last several months.</div><br/><div id="41987016" class="c"><input type="checkbox" id="c-41987016" checked=""/><div class="controls bullet"><span class="by">pseudosavant</span><span>|</span><a href="#41986044">parent</a><span>|</span><a href="#41986084">next</a><span>|</span><label class="collapse" for="c-41987016">[-]</label><label class="expand" for="c-41987016">[16 more]</label></div><br/><div class="children"><div class="content">I use both Claude and ChatGPT&#x2F;GPT-4o a lot. Claude, the model, definitely is &#x27;better&#x27; than GPT-4o. But OpenAI provides a much more capable app in ChatGPT and an easier development platform.<p>I would absolutely choose to use Claude as my model with ChatGPT if that happened (yes, I know it won&#x27;t). ChatGPT as an app is just so far ahead: code interpreter, web search&#x2F;fetch, fluid voice interaction, Custom GPTs, image generation, and memory. It isn&#x27;t close. But Claude absolutely produces better code, only being beaten by ChatGPT because it can fetch data from the web to RAG enhance its knowledge of things like APIs.<p>Claude&#x27;s implementation of artifacts is very good though, and I&#x27;m sure that is what lead OpenAI to push out their buggy canvas feature.</div><br/><div id="41988029" class="c"><input type="checkbox" id="c-41988029" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987016">parent</a><span>|</span><a href="#41987972">next</a><span>|</span><label class="collapse" for="c-41988029">[-]</label><label class="expand" for="c-41988029">[4 more]</label></div><br/><div class="children"><div class="content">It’s all a dice game with these things, you have to watch them closely or they start running you (with bad outcomes). Disclaimers aside:<p>Sonnet is better in the small, by a lot. It’s sharply up from idk, three months ago or something when it was still an attractive nuisance. It still tops out at “Best SO Answer”, but it hits that like 90%+. If it involves more than copy paste, sorry folks, it’s still just really fucking good copy paste.<p>But for sheer “doesn’t stutter every interaction at the worst moment”? You’ve got to hand it to the ops people: 4o can give you second best in industrial quantity on demand. I’m finding that if AI is good enough, then OpenAI is good enough.</div><br/><div id="41988230" class="c"><input type="checkbox" id="c-41988230" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988029">parent</a><span>|</span><a href="#41987972">next</a><span>|</span><label class="collapse" for="c-41988230">[-]</label><label class="expand" for="c-41988230">[3 more]</label></div><br/><div class="children"><div class="content">&gt;If it involves more than copy paste, sorry folks, it’s still just really fucking good copy paste.<p>Are you sure you&#x27;re using Claude 3.5 Sonnet? In my experience it&#x27;s absolutely capable of writing entire small applications based off a detailed spec I give it, which don&#x27;t exist on GitHub or Stack Overflow. It makes some mistakes, especially for underspecified things, but generally it can fix them with further prompting.</div><br/><div id="41989809" class="c"><input type="checkbox" id="c-41989809" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988230">parent</a><span>|</span><a href="#41987972">next</a><span>|</span><label class="collapse" for="c-41989809">[-]</label><label class="expand" for="c-41989809">[2 more]</label></div><br/><div class="children"><div class="content">I’m quite sure what model revision their API quotes, though serious users rapidly discover that like any distributed system, it has a rhythm to it.<p>And I’m not sure we disagree.<p>Vercel demo but Pets <i>is</i> copy paste.</div><br/><div id="41989817" class="c"><input type="checkbox" id="c-41989817" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41989809">parent</a><span>|</span><a href="#41987972">next</a><span>|</span><label class="collapse" for="c-41989817">[-]</label><label class="expand" for="c-41989817">[1 more]</label></div><br/><div class="children"><div class="content">We have entered the era of generic fashionable CRUD framework demo Too Cheap To Hawk.</div><br/></div></div></div></div></div></div></div></div><div id="41987972" class="c"><input type="checkbox" id="c-41987972" checked=""/><div class="controls bullet"><span class="by">tanelpoder</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987016">parent</a><span>|</span><a href="#41988029">prev</a><span>|</span><a href="#41988444">next</a><span>|</span><label class="collapse" for="c-41987972">[-]</label><label class="expand" for="c-41987972">[7 more]</label></div><br/><div class="children"><div class="content">Are there any good 3rd-party native frontend apps for Claude (on MacOS)? I mean something like ChatGPTs app, not an editor. I guess one option would be to just run Claude iPad app on MacOS.</div><br/><div id="41988647" class="c"><input type="checkbox" id="c-41988647" checked=""/><div class="controls bullet"><span class="by">Liquix</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987972">parent</a><span>|</span><a href="#41988036">next</a><span>|</span><label class="collapse" for="c-41988647">[-]</label><label class="expand" for="c-41988647">[1 more]</label></div><br/><div class="children"><div class="content">Jan [0] is MacOS native, open source, similar feel to the ChatGPT frontend, very polished, and offers Anthropic integration (all Claude models).<p>It also features one-click installation, OpenAI integration, a hub for downloading and running local models, a spec-compatible API server, global &quot;quick answer&quot; shortcut, and more. Really can&#x27;t recommend it enough!<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;janhq&#x2F;jan">https:&#x2F;&#x2F;github.com&#x2F;janhq&#x2F;jan</a></div><br/></div></div><div id="41988036" class="c"><input type="checkbox" id="c-41988036" checked=""/><div class="controls bullet"><span class="by">mike_hearn</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987972">parent</a><span>|</span><a href="#41988647">prev</a><span>|</span><a href="#41989058">next</a><span>|</span><label class="collapse" for="c-41988036">[-]</label><label class="expand" for="c-41988036">[1 more]</label></div><br/><div class="children"><div class="content">You can use <a href="https:&#x2F;&#x2F;recurse.chat&#x2F;" rel="nofollow">https:&#x2F;&#x2F;recurse.chat&#x2F;</a> if you have an Apple silicon Mac.</div><br/></div></div><div id="41989058" class="c"><input type="checkbox" id="c-41989058" checked=""/><div class="controls bullet"><span class="by">octohub</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987972">parent</a><span>|</span><a href="#41988036">prev</a><span>|</span><a href="#41988393">next</a><span>|</span><label class="collapse" for="c-41989058">[-]</label><label class="expand" for="c-41989058">[1 more]</label></div><br/><div class="children"><div class="content">Msty [0] is a really good app - you can use both local or online models and has web search, attachments, RAG, split chats, etc., built-in.<p>[0] <a href="https:&#x2F;&#x2F;msty.app" rel="nofollow">https:&#x2F;&#x2F;msty.app</a></div><br/></div></div><div id="41988393" class="c"><input type="checkbox" id="c-41988393" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987972">parent</a><span>|</span><a href="#41989058">prev</a><span>|</span><a href="#41988795">next</a><span>|</span><label class="collapse" for="c-41988393">[-]</label><label class="expand" for="c-41988393">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re willing to settle for a client-side only web frontend (i.e. talks directly with APIs of the models you use), TypingMind would work. It&#x27;s paid, but it&#x27;s good (see [0]), and I guess you could always go for the self-hosted version and wrap it in an Electron app - it&#x27;s what most &quot;native&quot; apps are these days anyway (and LLM frontends in particular).<p>--<p>[0] - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41988306">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41988306</a></div><br/></div></div><div id="41988795" class="c"><input type="checkbox" id="c-41988795" checked=""/><div class="controls bullet"><span class="by">jawon</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987972">parent</a><span>|</span><a href="#41988393">prev</a><span>|</span><a href="#41988342">next</a><span>|</span><label class="collapse" for="c-41988795">[-]</label><label class="expand" for="c-41988795">[1 more]</label></div><br/><div class="children"><div class="content">I like msty.app. Parallel prompting across multiple commercial and local models plus branching dialogs. Doesn’t do artifacts, etc, though.</div><br/></div></div><div id="41988342" class="c"><input type="checkbox" id="c-41988342" checked=""/><div class="controls bullet"><span class="by">greenavocado</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987972">parent</a><span>|</span><a href="#41988795">prev</a><span>|</span><a href="#41988444">next</a><span>|</span><label class="collapse" for="c-41988342">[-]</label><label class="expand" for="c-41988342">[1 more]</label></div><br/><div class="children"><div class="content">Open-WebUI doesn&#x27;t support Claude natively (only through a series of hacks) but it is absolutely &quot;THE&quot; go-to for a ChatGPT Pro like experience (it is slightly better).<p><a href="https:&#x2F;&#x2F;github.com&#x2F;open-webui&#x2F;open-webui">https:&#x2F;&#x2F;github.com&#x2F;open-webui&#x2F;open-webui</a></div><br/></div></div></div></div><div id="41988444" class="c"><input type="checkbox" id="c-41988444" checked=""/><div class="controls bullet"><span class="by">coryfklein</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987016">parent</a><span>|</span><a href="#41987972">prev</a><span>|</span><a href="#41988177">next</a><span>|</span><label class="collapse" for="c-41988444">[-]</label><label class="expand" for="c-41988444">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But OpenAI provides a much more capable app in ChatGPT and an easier development platform<p>Which app are you talking about here?</div><br/></div></div><div id="41988177" class="c"><input type="checkbox" id="c-41988177" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987016">parent</a><span>|</span><a href="#41988444">prev</a><span>|</span><a href="#41988306">next</a><span>|</span><label class="collapse" for="c-41988177">[-]</label><label class="expand" for="c-41988177">[1 more]</label></div><br/><div class="children"><div class="content">FWIW, I was able to get a decent way into making my own client for ChatGPT by asking  the free 3.5 version to do JS for me* before it was made redundant by the real app, so this shouldn&#x27;t be too hard if you want a specific experience&#x2F;workflow?<p>* I&#x27;m iOS by experience; my main professional JS experience was something like a year before jQuery came out, so I kinda need an LLM to catch me up for anything HTML<p>Also, I wanted HTML rather than native for this.</div><br/></div></div><div id="41988306" class="c"><input type="checkbox" id="c-41988306" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987016">parent</a><span>|</span><a href="#41988177">prev</a><span>|</span><a href="#41988211">next</a><span>|</span><label class="collapse" for="c-41988306">[-]</label><label class="expand" for="c-41988306">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>ChatGPT as an app is just so far ahead: code interpreter, web search&#x2F;fetch, fluid voice interaction, Custom GPTs, image generation, and memory. It isn&#x27;t close.</i><p>Funny thing, TypingMind was ahead of them for over a year, implementing those features on top of the API, without trying to mix business model with engineering[0]. It&#x27;s only recently that ChatGPT webapp got more polished and streamlined, but TypingMind&#x27;s been giving you all those features for <i>every</i> LLM that can handle it. So, if you&#x27;re looking for ChatGPT-level frontend to Anthropic models, this is it.<p>ChatGPT shines on mobile[1] and I still keep my subscription for that reason. On desktop, I stick to TypingMind and being able to run the same plugins on GPT-4o and Claude 3.5 Sonnet, and if I need a new tool, I can make myself one in five minutes with passing knowledge of JavaScript[2]; no need to subscribe to some Gee Pee Tee.<p>Now, I know I sound like a shill, I&#x27;m not. I&#x27;m just a satisfied user with no affiliation to the app or the guy that made it. It&#x27;s just that TypingMind did the <i>bloodingly stupid obvious</i> thing to do with the API and tool support (even before the latter was released), and continues to do the <i>obvious things</i> with it, and I&#x27;m completely confused as to why others don&#x27;t, or why people find &quot;GPTs&quot; novel. They&#x27;re not. They&#x27;re a simple idea, wrapped in tons of marketing bullshit that makes it less useful and delayed its release by half a year.<p>--<p>[0] - &quot;GPTs&quot;, seriously. That&#x27;s not a feature, that&#x27;s just system prompt and model config, put in an opaque box and distributed on a <i>marketplace</i> for no good reason.<p>[1] - Voice story has been better for a while, but that&#x27;s a matter of integration - OpenAI putting together their own LLM and (unreleased) voice model in a mobile app, in a manner hardly possible with the API their offered, vs. TypingMind being a webapp that uses third party TTS and STT models via &quot;bring your own API key&quot; approach.<p>[2] - I made <a href="https:&#x2F;&#x2F;docs.typingmind.com&#x2F;plugins&#x2F;plugins-examples#db32cc67d4ed476f93bab6818f9865c8" rel="nofollow">https:&#x2F;&#x2F;docs.typingmind.com&#x2F;plugins&#x2F;plugins-examples#db32cc6...</a> long before you could do that stuff with ChatGPT app. It&#x27;s literally as easy as it can possibly be: <a href="https:&#x2F;&#x2F;git.sr.ht&#x2F;~temporal&#x2F;typingmind-plugins&#x2F;tree" rel="nofollow">https:&#x2F;&#x2F;git.sr.ht&#x2F;~temporal&#x2F;typingmind-plugins&#x2F;tree</a>. In particular, this one is more representative - <a href="https:&#x2F;&#x2F;git.sr.ht&#x2F;~temporal&#x2F;typingmind-plugins&#x2F;tree&#x2F;master&#x2F;item&#x2F;activities-boredapi" rel="nofollow">https:&#x2F;&#x2F;git.sr.ht&#x2F;~temporal&#x2F;typingmind-plugins&#x2F;tree&#x2F;master&#x2F;i...</a> - PlantUML one is also less than 10 lines of code, but on top of 1.5k lines of DEFLATE implementation in JS I plain copy-pasted from the interwebz because I cannot into JS modules.</div><br/></div></div><div id="41988211" class="c"><input type="checkbox" id="c-41988211" checked=""/><div class="controls bullet"><span class="by">mattwad</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987016">parent</a><span>|</span><a href="#41988306">prev</a><span>|</span><a href="#41986084">next</a><span>|</span><label class="collapse" for="c-41988211">[-]</label><label class="expand" for="c-41988211">[1 more]</label></div><br/><div class="children"><div class="content">Have you tried using Cursor with Claude embedded? I can&#x27;t go back to anything else, it&#x27;s very nice having the AI embedded in the IDE and it just knows all the files i am working with. Cursor can use GPT-4o too if you want</div><br/></div></div></div></div><div id="41986084" class="c"><input type="checkbox" id="c-41986084" checked=""/><div class="controls bullet"><span class="by">ganoushoreilly</span><span>|</span><a href="#41986044">parent</a><span>|</span><a href="#41987016">prev</a><span>|</span><a href="#41986594">next</a><span>|</span><label class="collapse" for="c-41986084">[-]</label><label class="expand" for="c-41986084">[29 more]</label></div><br/><div class="children"><div class="content">I too use Claude more frequently than OpenAi GPT4o. I think this is a two fold move for MS and I like it. Claude being more accurate &#x2F; efficient for me says it&#x27;s likely they see the same thing, win number 1. The second is with all the OpenAI drama MS has started to distance themselves over a souring relationship (allegedly). If so, this could be a smart move away tactfully.<p>Either way, Claude is great so this is a net win for everyone.</div><br/><div id="41986292" class="c"><input type="checkbox" id="c-41986292" checked=""/><div class="controls bullet"><span class="by">thelittleone</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986084">parent</a><span>|</span><a href="#41988496">next</a><span>|</span><label class="collapse" for="c-41986292">[-]</label><label class="expand" for="c-41986292">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m the same, but had a lot of issues getting structured output from Anthropic. Ended up always writing response processors. Frustrated by how fragile that was, decided to try OpenAI structured outputs and it just worked and since they also have prompt caching now, it worked out very well for my use case.<p>Anthropic&#x27;s seems to have addressed the issue using pydantic but I haven&#x27;t had a chance to test it yet.<p>I pretty much use Anthropic for everything else.</div><br/></div></div><div id="41988496" class="c"><input type="checkbox" id="c-41988496" checked=""/><div class="controls bullet"><span class="by">JacobThreeThree</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986084">parent</a><span>|</span><a href="#41986292">prev</a><span>|</span><a href="#41986272">next</a><span>|</span><label class="collapse" for="c-41988496">[-]</label><label class="expand" for="c-41988496">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The second is with all the OpenAI drama MS has started to distance themselves over a souring relationship (allegedly). If so, this could be a smart move away tactfully.<p>I agree, this was a tactical move designed to give them leverage over OpenAI.</div><br/></div></div><div id="41986272" class="c"><input type="checkbox" id="c-41986272" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986084">parent</a><span>|</span><a href="#41988496">prev</a><span>|</span><a href="#41986382">next</a><span>|</span><label class="collapse" for="c-41986272">[-]</label><label class="expand" for="c-41986272">[25 more]</label></div><br/><div class="children"><div class="content">Yeah, Claude consistently impresses me.<p>A commenter on another thread mentioned it but it’s very similar to how search felt in the early 2000s. I ask it a question and get my answer.<p>Sometimes it’s a little (or a lot) wrong or outdated, but at least I get something to tinker with.</div><br/><div id="41987474" class="c"><input type="checkbox" id="c-41987474" checked=""/><div class="controls bullet"><span class="by">imiric</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986272">parent</a><span>|</span><a href="#41986685">next</a><span>|</span><label class="collapse" for="c-41987474">[-]</label><label class="expand" for="c-41987474">[12 more]</label></div><br/><div class="children"><div class="content">I recently tried to ask these tools for help with using a popular library, and both GPT-4o and Claude 3.5 Sonnet gave highly misleading and unusable suggestions. They consistently hallucinated APIs that didn&#x27;t exist, and would repeat the same wrong answers, ignoring my previous instructions. I spent upwards of 30 minutes repeating &quot;now I get this error&quot; to try to coax them in the right direction, but always ending up in a loop that got me nowhere. Some of the errors were really basic too, like referencing a variable that was never declared, etc. Finally, Claude made a tangential suggestion that made me look into using a different approach, but it was still faster to look into the official documentation than to keep asking it questions. GPT-4o was noticeably worse, and I quickly abandoned it.<p>If this is the state of the art of coding LLMs, I really don&#x27;t see why I should waste my time evaluating their confident sounding, but wrong, answers. It doesn&#x27;t seem like much has improved in the past year or so, and at this point this seems like an inherent limitation of the architecture.</div><br/><div id="41988960" class="c"><input type="checkbox" id="c-41988960" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987474">parent</a><span>|</span><a href="#41988083">next</a><span>|</span><label class="collapse" for="c-41988960">[-]</label><label class="expand" for="c-41988960">[4 more]</label></div><br/><div class="children"><div class="content">FWIW I almost never ask it to write code for me. I did once to write a matplotlib script and it gave me a similar headache.<p>I ask it questions mostly about libraries I’m using (usually that have poor documentation) and how to integrate it with other libraries.<p>I found out about Yjs by asking about different operational transform patterns.<p>Got some context on the prosemirror plugin by pasting the entire provider class into Claude and asking questions.<p>It wasn’t always exactly correct, but it was correct enough that it made the process of learning prosemirror, yjs, and how they interact pretty nice.<p>The “complete” examples it kept spitting out were totally wrong, but the information it gave me was not.</div><br/><div id="41989688" class="c"><input type="checkbox" id="c-41989688" checked=""/><div class="controls bullet"><span class="by">imiric</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988960">parent</a><span>|</span><a href="#41988083">next</a><span>|</span><label class="collapse" for="c-41989688">[-]</label><label class="expand" for="c-41989688">[3 more]</label></div><br/><div class="children"><div class="content">To be clear, I didn&#x27;t ask it to write something complex. The prompt was &quot;how do I do X with library Y?&quot;, with a bit more detail. The library is fairly popular and in a mainstream language.<p>I had a suspicion that what I was trying to do was simply not possible with that library, but since LLMs are incapable of saying &quot;that&#x27;s not possible&quot; or &quot;I don&#x27;t know&quot;, they will rephrase your prompt and hallucinate whatever might plausibly make sense. They have no way to gauge whether what they&#x27;re outputting is actually correct.<p>So I can imagine that you sometimes might get something useful from this, but if you want a specific answer about something, you will always have to double-check their work. In the specific case of programming, this could be improved with a simple engineering task: integrate the output with a real programming environment, and evaluate the result of actually running the code. I think there are coding assistant services that do this already, but frankly, I was expecting more from simple chat services.</div><br/><div id="41991006" class="c"><input type="checkbox" id="c-41991006" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41989688">parent</a><span>|</span><a href="#41988083">next</a><span>|</span><label class="collapse" for="c-41991006">[-]</label><label class="expand" for="c-41991006">[2 more]</label></div><br/><div class="children"><div class="content">&gt; if you want a specific answer about something<p>Specific is the specific thing that statistical models are not good at :(<p>&gt; how do I do X with library Y?<p>Recent research and anecdotal experience has shown that LLMs perform quite poorly with short prompts. Attention just has more data to work with when there are more tokens. Try extending that question like “I am using this programming language and am trying to do this task with this library. How do I do this thing with this other library”<p>I realize prompt engineering like this is fuzzy and “magic,” but short prompts have a consistent lower performance.<p>&gt; In the specific case of programming, this could be improved with a simple engineering task: integrate the output with a real programming environment, and evaluate the result of actually running the code.<p>Not as simple as you’d think. You’re letting something run arbitrary code.<p>Tho you should give aider.chat a try if you want to test out that workflow. I found it very very slow.</div><br/><div id="41992491" class="c"><input type="checkbox" id="c-41992491" checked=""/><div class="controls bullet"><span class="by">imiric</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41991006">parent</a><span>|</span><a href="#41988083">next</a><span>|</span><label class="collapse" for="c-41992491">[-]</label><label class="expand" for="c-41992491">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Recent research and anecdotal experience has shown that LLMs perform quite poorly with short prompts.<p>I&#x27;m aware of that. The actual prompt was more elaborate. I was just mentioning the gist of it here.<p>Besides, you would think that after 30 minutes of prompting and corrections it would arrive at the correct answer. I&#x27;m aware that subsequent output is based on the session history, but I would also expect this to be less of an issue if the human response was negative. It just seems like sloppy engineering otherwise.<p>&gt; Specific is the specific thing that statistical models are not good at<p>Some models are good at needle-in-a-haystack problems. If the information exists, they&#x27;re able to find it. What I don&#x27;t need is for it to hallucinate wrong answers if the information doesn&#x27;t exist.<p>This is a core problem of this tech, but I also expected it to improve over time.<p>&gt; Tho you should give aider.chat a try<p>Thanks, I&#x27;ll do that eventually. If it&#x27;s slow, it can get faster. I&#x27;d rather the tool be slow but give correct answers, than it slowing me down by wasting my time error correcting it.<p>Thankfully, these approaches can work for programming tasks. There is not much that can be done to verify the output of any other subject.</div><br/></div></div></div></div></div></div></div></div><div id="41988083" class="c"><input type="checkbox" id="c-41988083" checked=""/><div class="controls bullet"><span class="by">geodel</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987474">parent</a><span>|</span><a href="#41988960">prev</a><span>|</span><a href="#41988582">next</a><span>|</span><label class="collapse" for="c-41988083">[-]</label><label class="expand" for="c-41988083">[6 more]</label></div><br/><div class="children"><div class="content">Well it is volume business. &lt;1% of advanced skill developers will find AI helper useless but for 99% of IT CRUD peddlers these tools are quite sufficient. All in all if employers cut down 15-20% of net development costs by reducing head counts, it will be very worthwhile for companies.</div><br/><div id="41988694" class="c"><input type="checkbox" id="c-41988694" checked=""/><div class="controls bullet"><span class="by">WgaqPdNr7PGLGVW</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988083">parent</a><span>|</span><a href="#41989745">next</a><span>|</span><label class="collapse" for="c-41988694">[-]</label><label class="expand" for="c-41988694">[4 more]</label></div><br/><div class="children"><div class="content">I suspect it will go a different direction.<p>Codebases are exploding in size. Feature development has slowed down.<p>What might have been a carefully designed 100kloc codebase in 2018 is now a 500kloc ball of mud in 2024.<p>Companies need many more developers to complete a decent sized feature than they needed in 2018.</div><br/><div id="41991193" class="c"><input type="checkbox" id="c-41991193" checked=""/><div class="controls bullet"><span class="by">geodel</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988694">parent</a><span>|</span><a href="#41989075">next</a><span>|</span><label class="collapse" for="c-41991193">[-]</label><label class="expand" for="c-41991193">[1 more]</label></div><br/><div class="children"><div class="content">Agree. But we are already in that loop. A 50KLOC properly written &quot;Monolith, hence outdated&quot; app is now 30 micro services of 20KLOC surface + 100KLOC of submerged in terms of <i>convenience</i> libraries with kubernetes, grafana, datadog, servicemesh and so on. From what I am seeing companies are increasingly using off the shelf components so KLOC will keep rising but developer count would not.</div><br/></div></div><div id="41989075" class="c"><input type="checkbox" id="c-41989075" checked=""/><div class="controls bullet"><span class="by">outworlder</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988694">parent</a><span>|</span><a href="#41991193">prev</a><span>|</span><a href="#41989745">next</a><span>|</span><label class="collapse" for="c-41989075">[-]</label><label class="expand" for="c-41989075">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s worse than that. Now the balls of mud are distributed. We get incredibly complex interactions between services which need a lot of infrastructure to enable them, that requires more observability, which requires more infrastructure...</div><br/><div id="41991583" class="c"><input type="checkbox" id="c-41991583" checked=""/><div class="controls bullet"><span class="by">WgaqPdNr7PGLGVW</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41989075">parent</a><span>|</span><a href="#41989745">next</a><span>|</span><label class="collapse" for="c-41991583">[-]</label><label class="expand" for="c-41991583">[1 more]</label></div><br/><div class="children"><div class="content">Yeah. You can fit a lot of business logic into a 100kloc monolith written by skilled developers.<p>Once you start shifting it to micro services the business logic gets spread out and duplicated.<p>At the same time each micro-service now has its own code to handle rest, graphql, grpc endpoints.<p>And each downstream call needs error handling and retry logic.<p>And of course now you need distributed tracing.<p>And of course now your auth becomes much more complex.<p>And of course now each service might be called multiple times for the one request - better make them idempotent.<p>And each service will drift in terms of underlying libraries.<p>And so on.<p>Now we have been adding in LLM solutions so there is no consistency in any of the above services.<p>Each dev rather than look at the existing approaches instead asks Claude and it provides a slightly different way each time - often pulling in additional libraries we have to support.<p>These days I see so much bad code like a single microservice with 3 different approaches to making a http request.</div><br/></div></div></div></div></div></div><div id="41989745" class="c"><input type="checkbox" id="c-41989745" checked=""/><div class="controls bullet"><span class="by">imiric</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988083">parent</a><span>|</span><a href="#41988694">prev</a><span>|</span><a href="#41988582">next</a><span>|</span><label class="collapse" for="c-41989745">[-]</label><label class="expand" for="c-41989745">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but my specific question was fairly trivial, using a mainstream language and a popular library. Most of my work qualifies as CRUD peddling. And yet these tools are still wasting my time.<p>Maybe I&#x27;ll have better luck next time, or maybe I need to improve my prompting skills, or use a different model, etc. I was just expecting more from state of the art LLMs in 2024.</div><br/></div></div></div></div><div id="41988582" class="c"><input type="checkbox" id="c-41988582" checked=""/><div class="controls bullet"><span class="by">WgaqPdNr7PGLGVW</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987474">parent</a><span>|</span><a href="#41988083">prev</a><span>|</span><a href="#41986685">next</a><span>|</span><label class="collapse" for="c-41988582">[-]</label><label class="expand" for="c-41988582">[1 more]</label></div><br/><div class="children"><div class="content">Yeah there is a big disconnect between the devs caught up in the hype and the devs who aren&#x27;t.<p>A lot of the devs in my office using Claude&#x2F;gpt are convinced they are so much more productive but they aren&#x27;t actually producing features or bug fixes any faster.<p>I think they are just excited about a novel new way to write code.</div><br/></div></div></div></div><div id="41986685" class="c"><input type="checkbox" id="c-41986685" checked=""/><div class="controls bullet"><span class="by">gonab</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986272">parent</a><span>|</span><a href="#41987474">prev</a><span>|</span><a href="#41986382">next</a><span>|</span><label class="collapse" for="c-41986685">[-]</label><label class="expand" for="c-41986685">[12 more]</label></div><br/><div class="children"><div class="content">Conversely I feel that the experience of searching has been degraded by a lot since 2016&#x2F;17. My these is that, at this time, online spam increased by an order of magnitude</div><br/><div id="41987394" class="c"><input type="checkbox" id="c-41987394" checked=""/><div class="controls bullet"><span class="by">state_less</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986685">parent</a><span>|</span><a href="#41987336">next</a><span>|</span><label class="collapse" for="c-41987394">[-]</label><label class="expand" for="c-41987394">[4 more]</label></div><br/><div class="children"><div class="content">Old style Google search is dead, folks just haven’t closed the casket yet.  My index queries are down ~90%.  In the future, we’ll look back at LLMs as a major turning point in how people retrieve and consume information.</div><br/><div id="41988069" class="c"><input type="checkbox" id="c-41988069" checked=""/><div class="controls bullet"><span class="by">darepublic</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987394">parent</a><span>|</span><a href="#41991284">next</a><span>|</span><label class="collapse" for="c-41988069">[-]</label><label class="expand" for="c-41988069">[2 more]</label></div><br/><div class="children"><div class="content">I still prefer it over using llm.  And I would be doubtful that llm search has major benefits over Google search imo</div><br/><div id="41988221" class="c"><input type="checkbox" id="c-41988221" checked=""/><div class="controls bullet"><span class="by">ben_w</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988069">parent</a><span>|</span><a href="#41991284">next</a><span>|</span><label class="collapse" for="c-41988221">[-]</label><label class="expand" for="c-41988221">[1 more]</label></div><br/><div class="children"><div class="content">Depends what you want it for.<p>Right now, I find each tool better at different things.<p>If I can only describe what I want but don&#x27;t know key words, LLM are the only solution.<p>If I need citations, LLMs suck.</div><br/></div></div></div></div><div id="41991284" class="c"><input type="checkbox" id="c-41991284" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987394">parent</a><span>|</span><a href="#41988069">prev</a><span>|</span><a href="#41987336">next</a><span>|</span><label class="collapse" for="c-41991284">[-]</label><label class="expand" for="c-41991284">[1 more]</label></div><br/><div class="children"><div class="content">Abstractive vs. extractive search.</div><br/></div></div></div></div><div id="41987336" class="c"><input type="checkbox" id="c-41987336" checked=""/><div class="controls bullet"><span class="by">dageshi</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986685">parent</a><span>|</span><a href="#41987394">prev</a><span>|</span><a href="#41986985">next</a><span>|</span><label class="collapse" for="c-41987336">[-]</label><label class="expand" for="c-41987336">[3 more]</label></div><br/><div class="children"><div class="content">I think it was the switch from desktop search traffic being dominant to mobile traffic being dominant, that switch happened around the end of 2016.<p>Google used to prioritise big comprehensive articles on subjects for desktop users but mobile users just wanted quick answers, so that&#x27;s what google prioritised as they became the biggest users.<p>But also, per your point, I think those smaller simpler less comprehensive posts are easier to fake&#x2F;spam than the larger more compreshensible posts that came before.</div><br/><div id="41988880" class="c"><input type="checkbox" id="c-41988880" checked=""/><div class="controls bullet"><span class="by">zeknife</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987336">parent</a><span>|</span><a href="#41986985">next</a><span>|</span><label class="collapse" for="c-41988880">[-]</label><label class="expand" for="c-41988880">[2 more]</label></div><br/><div class="children"><div class="content">Ironically, I almost never see quick answers in the top results, mostly it&#x27;s dragged out pages of paragraph after paragraph with ads inbetween.</div><br/><div id="41989014" class="c"><input type="checkbox" id="c-41989014" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988880">parent</a><span>|</span><a href="#41986985">next</a><span>|</span><label class="collapse" for="c-41989014">[-]</label><label class="expand" for="c-41989014">[1 more]</label></div><br/><div class="children"><div class="content">Guess who sells the ads…</div><br/></div></div></div></div></div></div><div id="41986985" class="c"><input type="checkbox" id="c-41986985" checked=""/><div class="controls bullet"><span class="by">bobthepanda</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986685">parent</a><span>|</span><a href="#41987336">prev</a><span>|</span><a href="#41989989">next</a><span>|</span><label class="collapse" for="c-41986985">[-]</label><label class="expand" for="c-41986985">[1 more]</label></div><br/><div class="children"><div class="content">Winning the war against spam is an arms race. Spam hasn’t spent years targeting AI search yet.</div><br/></div></div><div id="41989989" class="c"><input type="checkbox" id="c-41989989" checked=""/><div class="controls bullet"><span class="by">EVa5I7bHFq9mnYK</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986685">parent</a><span>|</span><a href="#41986985">prev</a><span>|</span><a href="#41992373">next</a><span>|</span><label class="collapse" for="c-41989989">[-]</label><label class="expand" for="c-41989989">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s getting ridiculous. Half of the time now when I ask AI to search some information for me, it finds and summarizes some very long article obviously written by AI, and lacking any useful information.</div><br/></div></div><div id="41992373" class="c"><input type="checkbox" id="c-41992373" checked=""/><div class="controls bullet"><span class="by">th0ma5</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986685">parent</a><span>|</span><a href="#41989989">prev</a><span>|</span><a href="#41986798">next</a><span>|</span><label class="collapse" for="c-41992373">[-]</label><label class="expand" for="c-41992373">[1 more]</label></div><br/><div class="children"><div class="content">Queries were rewritten with BERT starting even before then so it&#x27;s still the same generative model problem.</div><br/></div></div><div id="41986798" class="c"><input type="checkbox" id="c-41986798" checked=""/><div class="controls bullet"><span class="by">TeaBrain</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986685">parent</a><span>|</span><a href="#41992373">prev</a><span>|</span><a href="#41986382">next</a><span>|</span><label class="collapse" for="c-41986798">[-]</label><label class="expand" for="c-41986798">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think this is necessarily converse to what they said.</div><br/></div></div></div></div></div></div></div></div><div id="41986594" class="c"><input type="checkbox" id="c-41986594" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#41986044">parent</a><span>|</span><a href="#41986084">prev</a><span>|</span><a href="#41988088">next</a><span>|</span><label class="collapse" for="c-41986594">[-]</label><label class="expand" for="c-41986594">[23 more]</label></div><br/><div class="children"><div class="content">The speed with which AI models are improving blows my mind. Humans quickly normalize technological progress, but it&#x27;s staggering to reflect on our progress over just these <i>two years</i>.</div><br/><div id="41986928" class="c"><input type="checkbox" id="c-41986928" checked=""/><div class="controls bullet"><span class="by">campbel</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986594">parent</a><span>|</span><a href="#41987954">next</a><span>|</span><label class="collapse" for="c-41986928">[-]</label><label class="expand" for="c-41986928">[2 more]</label></div><br/><div class="children"><div class="content">Yes! I&#x27;m much more inclined to write one-off scripts for short manual tasks as I can usually get AI to get something useful very fast. For example, last week I worked with Claude to write a script to get a sense of how many PRs my company had that included comprehensive testing. This was borderline best done as a manual task previously, now I just ask Claude to write a short bash script that uses the GitHub CLI to do it and I&#x27;ve got a repeatable reliable process for pulling this information.</div><br/><div id="41987562" class="c"><input type="checkbox" id="c-41987562" checked=""/><div class="controls bullet"><span class="by">unshavedyak</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986928">parent</a><span>|</span><a href="#41987954">next</a><span>|</span><label class="collapse" for="c-41987562">[-]</label><label class="expand" for="c-41987562">[1 more]</label></div><br/><div class="children"><div class="content">I rarely use LLMs for tasks but i love it for exploring spaces i would otherwise just ignore. Like writing some random bash script isn&#x27;t difficult at all, but it&#x27;s also so fiddly that i just don&#x27;t care to do it. It&#x27;s nice to just throw a bot at it and come back later. Loosely speaking.<p>Still i find very little use from LLMs in this front, but they do come in handy randomly.</div><br/></div></div></div></div><div id="41987954" class="c"><input type="checkbox" id="c-41987954" checked=""/><div class="controls bullet"><span class="by">ffujdefvjg</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986594">parent</a><span>|</span><a href="#41986928">prev</a><span>|</span><a href="#41987542">next</a><span>|</span><label class="collapse" for="c-41987954">[-]</label><label class="expand" for="c-41987954">[5 more]</label></div><br/><div class="children"><div class="content">Lots of progress, but I feel like we&#x27;ve been seeing diminishing returns. I can&#x27;t help but feel like recent improvements are just refinements and not real advances. The interest in AI may drive investment and research in better models that are game-changers, but we aren&#x27;t there yet.</div><br/><div id="41988118" class="c"><input type="checkbox" id="c-41988118" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987954">parent</a><span>|</span><a href="#41988059">next</a><span>|</span><label class="collapse" for="c-41988118">[-]</label><label class="expand" for="c-41988118">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re proving GP&#x27;s point about normalization of progress. It&#x27;s been two years. We&#x27;re still during the first iteration of applications of this new tech, advancements didn&#x27;t have time yet to start compounding. This is barely getting started.</div><br/></div></div><div id="41988059" class="c"><input type="checkbox" id="c-41988059" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987954">parent</a><span>|</span><a href="#41988118">prev</a><span>|</span><a href="#41987542">next</a><span>|</span><label class="collapse" for="c-41988059">[-]</label><label class="expand" for="c-41988059">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know about you, but o1-preview&#x2F;o1-mini has been able to solve many moderately challenging programming tasks that would&#x27;ve taken me 30 mins to an hour. No other models earlier could&#x27;ve done that.</div><br/><div id="41988174" class="c"><input type="checkbox" id="c-41988174" checked=""/><div class="controls bullet"><span class="by">ffujdefvjg</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988059">parent</a><span>|</span><a href="#41987542">next</a><span>|</span><label class="collapse" for="c-41988174">[-]</label><label class="expand" for="c-41988174">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s an improvement but...I&#x27;ve asked it to do some really simple tasks and it&#x27;ll occasionally do them in the most roundabout way you could imagine. Like, let&#x27;s source a bash file that creates and reads a state file to do something for which the functionality was already built-in. Say I&#x27;m a little skeptical of this solution and plug it into a new o1-preview prompt to double check the solution, and it starts by critiquing the bash script and error handling instead of seeing that the functionality is baked in and it&#x27;s plainly documented. Other errors have been more subtle.<p>When it works, it&#x27;s pretty good, and sometimes great. But when failure modes look like the above I&#x27;m very wary of accepting its output.</div><br/><div id="41990126" class="c"><input type="checkbox" id="c-41990126" checked=""/><div class="controls bullet"><span class="by">warkdarrior</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988174">parent</a><span>|</span><a href="#41987542">next</a><span>|</span><label class="collapse" for="c-41990126">[-]</label><label class="expand" for="c-41990126">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve asked it to do some really simple tasks and it&#x27;ll occasionally do them in the most roundabout way you could imagine.<p>But it still does the tasks you asked for, so that&#x27;s the part that really matters.</div><br/></div></div></div></div></div></div></div></div><div id="41987542" class="c"><input type="checkbox" id="c-41987542" checked=""/><div class="controls bullet"><span class="by">unshavedyak</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41986594">parent</a><span>|</span><a href="#41987954">prev</a><span>|</span><a href="#41988088">next</a><span>|</span><label class="collapse" for="c-41987542">[-]</label><label class="expand" for="c-41987542">[15 more]</label></div><br/><div class="children"><div class="content">I wonder how long people will still protest in these threads that &quot;It doesn&#x27;t know anything! It&#x27;s just an autocomplete parrot!&quot;<p>Because.. yea, it is. However.. it keeps expanding, it keeps getting more useful. Yea people and especially companies are using it for things which it has no business being involved in.. and despite that it keeps growing, it keeps progressing.<p>I do find the &quot;stochastic parrot&quot; comments slowly dwindle in number and volume with each significant release, though.<p>Still, i find it weirdly interesting to see a bunch of people be both right and &quot;wrong&quot; at the same time. They&#x27;re completely right, and yet it&#x27;s like they&#x27;re also being proven wrong in the ways that matter.<p>Very weird space we&#x27;re living in.</div><br/><div id="41988159" class="c"><input type="checkbox" id="c-41988159" checked=""/><div class="controls bullet"><span class="by">wavemode</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987542">parent</a><span>|</span><a href="#41987804">next</a><span>|</span><label class="collapse" for="c-41988159">[-]</label><label class="expand" for="c-41988159">[4 more]</label></div><br/><div class="children"><div class="content">You&#x27;re conflating three different things.<p>There&#x27;s the question, &quot;is an LLM just autocomplete&quot;? The answer to that question is obviously no, but the question is also a strawman - people who actually use LLM&#x27;s regularly do recognize that there is more to their capabilities than randomized pattern matching.<p>Separately, there&#x27;s the question of &quot;will LLM&#x27;s become AGI and&#x2F;or become super intelligent.&quot; Most people recognize that LLM&#x27;s are not currently super intelligent, and that there currently isn&#x27;t a clear path toward making them so. Still, many people seem to feel that we&#x27;re on the verge of progress here, and feel very strongly that anyone who disagrees is an AI &quot;doomer&quot;.<p>Then there&#x27;s the question of &quot;are we in an AI bubble&quot;? This is more a matter of debate. Some would argue that if LLM reasoning capabilities plateau, people will stop investing in the technology. I actually don&#x27;t agree with that view - I think there is a lot of economic value still yet to be realized in AI advancements - I don&#x27;t think we&#x27;re on the verge of some sort of AI winter, even if LLM&#x27;s never become super intelligent.</div><br/><div id="41989089" class="c"><input type="checkbox" id="c-41989089" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988159">parent</a><span>|</span><a href="#41987804">next</a><span>|</span><label class="collapse" for="c-41989089">[-]</label><label class="expand" for="c-41989089">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Most people recognize that LLM&#x27;s are not currently super intelligent,<p>I think calling it intelligent is being extremely generous. Take a look at the following example which is a spelling and grammar checker that I wrote:<p><a href="https:&#x2F;&#x2F;app.gitsense.com&#x2F;?doc=f7419bfb27c89&amp;temperature=0.50&amp;samples=5" rel="nofollow">https:&#x2F;&#x2F;app.gitsense.com&#x2F;?doc=f7419bfb27c89&amp;temperature=0.50...</a><p>When the temperature is 0.5, both Claude 3.5 and GPT-4o can&#x27;t properly recognize that GitHub is capitalized.  You can see the responses by clicking in the sentence.  Each model was asked to validate the sentence 5 times.<p>If the temperature is set to 0.0, most models will get it right (most of the time), but Claude 3.5 still can&#x27;t see the sentence in front of it.<p><a href="https:&#x2F;&#x2F;app.gitsense.com&#x2F;?doc=f7419bfb27c89&amp;temperature=0.00&amp;samples=5" rel="nofollow">https:&#x2F;&#x2F;app.gitsense.com&#x2F;?doc=f7419bfb27c89&amp;temperature=0.00...</a><p>Right now, LLM is an insanely useful and powerful next word predictor, but I wouldn&#x27;t call it intelligent.</div><br/><div id="41989690" class="c"><input type="checkbox" id="c-41989690" checked=""/><div class="controls bullet"><span class="by">digging</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41989089">parent</a><span>|</span><a href="#41987804">next</a><span>|</span><label class="collapse" for="c-41989690">[-]</label><label class="expand" for="c-41989690">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I think calling it intelligent is being extremely generous ... can&#x27;t properly recognize that GitHub is capitalized.<p>Wouldn&#x27;t this make chimpanzees and ravens and dolphins unintelligent too? You&#x27;re asking it to do a task that&#x27;s (mostly) easy <i>for humans</i>. It&#x27;s not a human though. It&#x27;s an alien intelligence which &quot;thinks&quot; in our language, but not in the same way we do.<p>If they could, specialized AI might think we&#x27;re unintelligent based on how often we fail, even with advanced tools, pattern matching tasks that are trivial for them. Would you say they&#x27;re right to feel that way?</div><br/><div id="41989868" class="c"><input type="checkbox" id="c-41989868" checked=""/><div class="controls bullet"><span class="by">sdesol</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41989690">parent</a><span>|</span><a href="#41987804">next</a><span>|</span><label class="collapse" for="c-41989868">[-]</label><label class="expand" for="c-41989868">[1 more]</label></div><br/><div class="children"><div class="content">Animals are capable of learning. LLMs can not. LLM uses weights that are defined during the training process to decide what to do next. LLM cannot self evaluate based on what it has said. You have to create a new message for it to create a new probability path.<p>Animals have the ability to learn and grow by themselves. LLMs are not intelligent and I don&#x27;t see how they can be since they just follow the most likely path with randomness (temperature) sprinkled in.</div><br/></div></div></div></div></div></div></div></div><div id="41987804" class="c"><input type="checkbox" id="c-41987804" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987542">parent</a><span>|</span><a href="#41988159">prev</a><span>|</span><a href="#41988852">next</a><span>|</span><label class="collapse" for="c-41987804">[-]</label><label class="expand" for="c-41987804">[9 more]</label></div><br/><div class="children"><div class="content">The &quot;statistical parrot&quot; parrots have been demonstrably wrong for years (see e.g. LeCun et al[1]). It&#x27;s just harder to ignore reality with hundreds of millions of people now using incredible new AI tools. We&#x27;re approaching &quot;don&#x27;t believe your lying eyes&quot; territory. Deniers will continue pretending that LLMs are just an NFT-level fad or bubble or whatever. The AI revolution will continue to pass them by. More&#x27;s the pity.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2110.09485" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2110.09485</a></div><br/><div id="41989155" class="c"><input type="checkbox" id="c-41989155" checked=""/><div class="controls bullet"><span class="by">outworlder</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987804">parent</a><span>|</span><a href="#41988089">next</a><span>|</span><label class="collapse" for="c-41989155">[-]</label><label class="expand" for="c-41989155">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Deniers will continue pretending that LLMs are just an NFT-level fad or bubble or whatever. The AI revolution will continue to pass them by. More&#x27;s the pity.<p>You should re-read that very slowly and carefully and really think about it. Calling anyone that&#x27;s skeptical a &#x27;denier&#x27; is a red flag.<p>We have been through these AI cycles before. In every case, the tools were impressive for their time. Their limitations were always brushed aside and we would get a hype cycle. There was nothing wrong with the technology, but humans always like to try to extrapolate their capabilities and we usually get that wrong. When hype caught up to reality, investments dried up and nobody wanted to touch &quot;AI&quot; for a while.<p>Rinse, repeat.<p>LLMs are again impressive, for our time. When the dust settles, we&#x27;ll get some useful tools but I&#x27;m pretty sure we will experience another – severe – AI winter.<p>If we had some optimistic but also realistic discussions on their limitations, I&#x27;d be less skeptical. As it is, we are talking about &#x27;revolution&#x27;, and developers being out of jobs, and superintelligence and whatnot. That&#x27;s <i>not</i> the level the technology is at today and it is not clear we are going to do anything else other than get stuck in a local maxima.</div><br/></div></div><div id="41988089" class="c"><input type="checkbox" id="c-41988089" checked=""/><div class="controls bullet"><span class="by">mensetmanusman</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987804">parent</a><span>|</span><a href="#41989155">prev</a><span>|</span><a href="#41988759">next</a><span>|</span><label class="collapse" for="c-41988089">[-]</label><label class="expand" for="c-41988089">[6 more]</label></div><br/><div class="children"><div class="content">A trillion dimensional stochastic parrot is still a stochastic parrot.<p>If these systems showed understanding we would notice.<p>No one is denying that this form of intelligence is useful.</div><br/><div id="41988264" class="c"><input type="checkbox" id="c-41988264" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988089">parent</a><span>|</span><a href="#41988341">next</a><span>|</span><label class="collapse" for="c-41988264">[-]</label><label class="expand" for="c-41988264">[4 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know how you can say they lack understanding of the world when in pretty much any standardised test designed to measure human intelligence they perform better than the average human. They only thing that don&#x27;t understand is touch because they&#x27;re not trained on that, but they can already understand audio and video.</div><br/><div id="41988968" class="c"><input type="checkbox" id="c-41988968" checked=""/><div class="controls bullet"><span class="by">zeknife</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988264">parent</a><span>|</span><a href="#41989956">next</a><span>|</span><label class="collapse" for="c-41988968">[-]</label><label class="expand" for="c-41988968">[2 more]</label></div><br/><div class="children"><div class="content">You said it, those tests are designed to measure human intelligence, because we know that there is a correspondence between test results and other, more general tasks - in humans. We do not know that such a correspondence exists with language models. I would actually argue that they demonstrably do not, since even an LLM that passes every IQ test you put in front of it can still trip up on trivial exceptions that wouldn&#x27;t fool a child.</div><br/><div id="41991361" class="c"><input type="checkbox" id="c-41991361" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988968">parent</a><span>|</span><a href="#41989956">next</a><span>|</span><label class="collapse" for="c-41991361">[-]</label><label class="expand" for="c-41991361">[1 more]</label></div><br/><div class="children"><div class="content">So they fail in their own way? They&#x27;re not humans; that&#x27;s to be expected.</div><br/></div></div></div></div><div id="41989956" class="c"><input type="checkbox" id="c-41989956" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988264">parent</a><span>|</span><a href="#41988968">prev</a><span>|</span><a href="#41988341">next</a><span>|</span><label class="collapse" for="c-41989956">[-]</label><label class="expand" for="c-41989956">[1 more]</label></div><br/><div class="children"><div class="content">An answer key would outperform the average human but it isn’t intelligent. Tests designed for humans are not appropriate to judge non humans.</div><br/></div></div></div></div><div id="41988341" class="c"><input type="checkbox" id="c-41988341" checked=""/><div class="controls bullet"><span class="by">devmor</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41988089">parent</a><span>|</span><a href="#41988264">prev</a><span>|</span><a href="#41988759">next</a><span>|</span><label class="collapse" for="c-41988341">[-]</label><label class="expand" for="c-41988341">[1 more]</label></div><br/><div class="children"><div class="content">No you don’t understand, if i put a billion billion trillion monkeys on typewriters, they’re actually now one super intelligent monkey because they’re useful now!<p>We just need more monkeys and it will be the same as a human brain.</div><br/></div></div></div></div><div id="41988759" class="c"><input type="checkbox" id="c-41988759" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987804">parent</a><span>|</span><a href="#41988089">prev</a><span>|</span><a href="#41988852">next</a><span>|</span><label class="collapse" for="c-41988759">[-]</label><label class="expand" for="c-41988759">[1 more]</label></div><br/><div class="children"><div class="content">What does the mass of users change about what it is?
How many of these check the results for hallucinations and how many don’t because I part of AI?<p>More than once these tools fail at tasks a fifth grader could understand</div><br/></div></div></div></div><div id="41988852" class="c"><input type="checkbox" id="c-41988852" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#41986044">root</a><span>|</span><a href="#41987542">parent</a><span>|</span><a href="#41987804">prev</a><span>|</span><a href="#41988088">next</a><span>|</span><label class="collapse" for="c-41988852">[-]</label><label class="expand" for="c-41988852">[1 more]</label></div><br/><div class="children"><div class="content">Are you confusing frequency of use with usefulness?<p>If these tools boost tue productivity where is the output spike of all the companies, the spike in revenue and profits?<p>How often do we lose the benefit auto text generation to the loop of
That’s wrong
Oh yes of course, here is the correct version
Nope, still wrong
Prompt editing?</div><br/></div></div></div></div></div></div><div id="41988088" class="c"><input type="checkbox" id="c-41988088" checked=""/><div class="controls bullet"><span class="by">mtkd</span><span>|</span><a href="#41986044">parent</a><span>|</span><a href="#41986594">prev</a><span>|</span><a href="#41987367">next</a><span>|</span><label class="collapse" for="c-41988088">[-]</label><label class="expand" for="c-41988088">[1 more]</label></div><br/><div class="children"><div class="content">One service is not really enough -- you need a few to triangulate more often than not, especially when it comes to code using latest versions of public APIs<p>Phind is useful as you can switch between them -- but only get a handful of o1 and Opus a day which I burn through quick at moment on deeper things -- Phind-405b and 3.5 Sonnet are decent for general use</div><br/></div></div><div id="41987367" class="c"><input type="checkbox" id="c-41987367" checked=""/><div class="controls bullet"><span class="by">szundi</span><span>|</span><a href="#41986044">parent</a><span>|</span><a href="#41988088">prev</a><span>|</span><a href="#41986126">next</a><span>|</span><label class="collapse" for="c-41987367">[-]</label><label class="expand" for="c-41987367">[1 more]</label></div><br/><div class="children"><div class="content">Switch to Cursor with Claude backend and 5x immediately</div><br/></div></div></div></div><div id="41986126" class="c"><input type="checkbox" id="c-41986126" checked=""/><div class="controls bullet"><span class="by">thenobsta</span><span>|</span><a href="#41986044">prev</a><span>|</span><a href="#41992551">next</a><span>|</span><label class="collapse" for="c-41986126">[-]</label><label class="expand" for="c-41986126">[8 more]</label></div><br/><div class="children"><div class="content">I wonder what the rationale for this was internally. More OpenAI issues? competitiveness with Cursor? It seems good for the user to increase competition across LLM providers.<p>Also ambiguous title. I thought GitHub canceled deals they had in the work. The article is clearly about making a deal, but it&#x27;s unclear from the article&#x27;s title.</div><br/><div id="41986530" class="c"><input type="checkbox" id="c-41986530" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#41986126">parent</a><span>|</span><a href="#41990457">next</a><span>|</span><label class="collapse" for="c-41986530">[-]</label><label class="expand" for="c-41986530">[3 more]</label></div><br/><div class="children"><div class="content">Could be a fight against Llama, which excludes MS and Google in its open license (though I think has done separate pay deals with one or both of them).  Meta are notably absent from this announcement.</div><br/><div id="41992407" class="c"><input type="checkbox" id="c-41992407" checked=""/><div class="controls bullet"><span class="by">Idiot211</span><span>|</span><a href="#41986126">root</a><span>|</span><a href="#41986530">parent</a><span>|</span><a href="#41987999">next</a><span>|</span><label class="collapse" for="c-41992407">[-]</label><label class="expand" for="c-41992407">[1 more]</label></div><br/><div class="children"><div class="content">I was at the keynote, Llama was featured in the Copilot models section and called out specifically, as was Mistral.<p>I assume they just aren&#x27;t at the point where they have the ability or want to host the compute to offer up Llama as an option as opposed to OpenAI, Anthropic and Google who are all offering the model as a service.</div><br/></div></div><div id="41987999" class="c"><input type="checkbox" id="c-41987999" checked=""/><div class="controls bullet"><span class="by">szundi</span><span>|</span><a href="#41986126">root</a><span>|</span><a href="#41986530">parent</a><span>|</span><a href="#41992407">prev</a><span>|</span><a href="#41990457">next</a><span>|</span><label class="collapse" for="c-41987999">[-]</label><label class="expand" for="c-41987999">[1 more]</label></div><br/><div class="children"><div class="content">Try to fight the free good-enough haha. At least that’s the plan of Meta, who does not benefit as much selling this than using this</div><br/></div></div></div></div><div id="41990457" class="c"><input type="checkbox" id="c-41990457" checked=""/><div class="controls bullet"><span class="by">gavin_gee</span><span>|</span><a href="#41986126">parent</a><span>|</span><a href="#41986530">prev</a><span>|</span><a href="#41986199">next</a><span>|</span><label class="collapse" for="c-41990457">[-]</label><label class="expand" for="c-41990457">[2 more]</label></div><br/><div class="children"><div class="content">cursor is kicking vscode&#x27;s butt because it has multi models. also MS is hedging bets against OpenAI. that relationship is not easy</div><br/><div id="41991997" class="c"><input type="checkbox" id="c-41991997" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#41986126">root</a><span>|</span><a href="#41990457">parent</a><span>|</span><a href="#41986199">next</a><span>|</span><label class="collapse" for="c-41991997">[-]</label><label class="expand" for="c-41991997">[1 more]</label></div><br/><div class="children"><div class="content">Or, anti trust fears.</div><br/></div></div></div></div><div id="41992362" class="c"><input type="checkbox" id="c-41992362" checked=""/><div class="controls bullet"><span class="by">nprateem</span><span>|</span><a href="#41986126">parent</a><span>|</span><a href="#41986199">prev</a><span>|</span><a href="#41992551">next</a><span>|</span><label class="collapse" for="c-41992362">[-]</label><label class="expand" for="c-41992362">[1 more]</label></div><br/><div class="children"><div class="content">Claude is good, openai shit?</div><br/></div></div></div></div><div id="41992551" class="c"><input type="checkbox" id="c-41992551" checked=""/><div class="controls bullet"><span class="by">DeathArrow</span><span>|</span><a href="#41986126">prev</a><span>|</span><a href="#41992980">next</a><span>|</span><label class="collapse" for="c-41992551">[-]</label><label class="expand" for="c-41992551">[2 more]</label></div><br/><div class="children"><div class="content">For all those believers in the power of AI who tested it in modifying their front-ends and writing a Python script, I have a test: ask AI to write an operating system kernel or a database. Of course, something simple.<p>I never seen AI being used in writing system software. Perhaps there is a reason behind it?</div><br/><div id="41992595" class="c"><input type="checkbox" id="c-41992595" checked=""/><div class="controls bullet"><span class="by">uberswe</span><span>|</span><a href="#41992551">parent</a><span>|</span><a href="#41992980">next</a><span>|</span><label class="collapse" for="c-41992595">[-]</label><label class="expand" for="c-41992595">[1 more]</label></div><br/><div class="children"><div class="content">From experience no AI solution is consistently making fault free code of any kind when you need more than a snippet.<p>Personally I have been making Velocity Proxy plugins for Minecraft where ChatGPT generates the bulk of the plugin and I fix all the incorrect imports, this is Java. My latest project was a whitelist plugin that uses Discord roles to allow&#x2F;deny players to join.</div><br/></div></div></div></div><div id="41992980" class="c"><input type="checkbox" id="c-41992980" checked=""/><div class="controls bullet"><span class="by">anshumankmr</span><span>|</span><a href="#41992551">prev</a><span>|</span><a href="#41992257">next</a><span>|</span><label class="collapse" for="c-41992980">[-]</label><label class="expand" for="c-41992980">[1 more]</label></div><br/><div class="children"><div class="content">What about Open AI or since they are both under the same org, it is sort of understood Open AI can scrape it.</div><br/></div></div><div id="41992257" class="c"><input type="checkbox" id="c-41992257" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#41992980">prev</a><span>|</span><a href="#41990458">next</a><span>|</span><label class="collapse" for="c-41992257">[-]</label><label class="expand" for="c-41992257">[1 more]</label></div><br/><div class="children"><div class="content">Wait, does this provide UNLIMITED completions via Claude 3.5 Sonnet for a single $10&#x2F;month subscription?<p>Compared to Cursor&#x27;s 500 monthly completions for $20, and Claude&#x27;s web access for $20, this seems like a bargain.</div><br/></div></div><div id="41990458" class="c"><input type="checkbox" id="c-41990458" checked=""/><div class="controls bullet"><span class="by">javaunsafe2019</span><span>|</span><a href="#41992257">prev</a><span>|</span><a href="#41990670">next</a><span>|</span><label class="collapse" for="c-41990458">[-]</label><label class="expand" for="c-41990458">[8 more]</label></div><br/><div class="children"><div class="content">I don’t know how people can claim such huge success using copilot and such. I also own a subscription and tried to use it for coding but all task from spring boot authentication configuration to aws policies and lambdas it failed horribly.<p>Writing the code myself using proper documentation was the only option.<p>I wonder if false information is written here in the comments section for certain reasons …</div><br/><div id="41992459" class="c"><input type="checkbox" id="c-41992459" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#41990458">parent</a><span>|</span><a href="#41990470">next</a><span>|</span><label class="collapse" for="c-41992459">[-]</label><label class="expand" for="c-41992459">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a completely new skill that you need to learn. My productivity gains are substantial but it comes from experience building multiple applications using LLMs. I feel I learn something new every day and the tooling just gets better and better.<p>&gt; I wonder if false information is written here in the comments section for certain reasons …<p>I find it perplexing that you resort to this instead of other plausible explanations.</div><br/></div></div><div id="41990470" class="c"><input type="checkbox" id="c-41990470" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#41990458">parent</a><span>|</span><a href="#41992459">prev</a><span>|</span><a href="#41991537">next</a><span>|</span><label class="collapse" for="c-41990470">[-]</label><label class="expand" for="c-41990470">[4 more]</label></div><br/><div class="children"><div class="content">You need to spend time learning how to use it. This is difficult because there&#x27;s no manual, and there&#x27;s a widespread implication that it should just magically work well without you having to invest any effort in it.<p>If you can figure out HOW to invest that effort it becomes really valuable.<p>I wish I had good resources I could link you to here but I don&#x27;t, which is a big part of the problem here.</div><br/><div id="41990696" class="c"><input type="checkbox" id="c-41990696" checked=""/><div class="controls bullet"><span class="by">scott01</span><span>|</span><a href="#41990458">root</a><span>|</span><a href="#41990470">parent</a><span>|</span><a href="#41991537">next</a><span>|</span><label class="collapse" for="c-41990696">[-]</label><label class="expand" for="c-41990696">[3 more]</label></div><br/><div class="children"><div class="content">You sound like you’ve had success using this tech for work. Can you tell more about your personal experience, please? I’ve tried ChatGPT a few times a year ago or so, but it was extremely frustrating, and I gave up.</div><br/><div id="41991500" class="c"><input type="checkbox" id="c-41991500" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#41990458">root</a><span>|</span><a href="#41990696">parent</a><span>|</span><a href="#41991537">next</a><span>|</span><label class="collapse" for="c-41991500">[-]</label><label class="expand" for="c-41991500">[2 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s my &quot;How I use LLMs and ChatGPT&quot; series: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;series&#x2F;using-llms&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;series&#x2F;using-llms&#x2F;</a><p>Also relevant is my ai-assisted-programming tag: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;ai-assisted-programming&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;tags&#x2F;ai-assisted-programming&#x2F;</a></div><br/><div id="41992383" class="c"><input type="checkbox" id="c-41992383" checked=""/><div class="controls bullet"><span class="by">th0ma5</span><span>|</span><a href="#41990458">root</a><span>|</span><a href="#41991500">parent</a><span>|</span><a href="#41991537">next</a><span>|</span><label class="collapse" for="c-41992383">[-]</label><label class="expand" for="c-41992383">[1 more]</label></div><br/><div class="children"><div class="content">These examples are not much different than tutorial regurgitation imo. I would not pass this off as solving the problems that programmers have in practice, imo.</div><br/></div></div></div></div></div></div></div></div><div id="41991537" class="c"><input type="checkbox" id="c-41991537" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#41990458">parent</a><span>|</span><a href="#41990470">prev</a><span>|</span><a href="#41992547">next</a><span>|</span><label class="collapse" for="c-41991537">[-]</label><label class="expand" for="c-41991537">[1 more]</label></div><br/><div class="children"><div class="content">Maybe you should set the right expectations to find the right use.<p>There&#x27;s plenty of copilot and cursor users out there, and developers are really not the kind of crowd that likes to pay for development tools.</div><br/></div></div><div id="41992547" class="c"><input type="checkbox" id="c-41992547" checked=""/><div class="controls bullet"><span class="by">globular-toast</span><span>|</span><a href="#41990458">parent</a><span>|</span><a href="#41991537">prev</a><span>|</span><a href="#41990670">next</a><span>|</span><label class="collapse" for="c-41992547">[-]</label><label class="expand" for="c-41992547">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately I think it really depends what people are doing. Some people have an utterly trivial problem domain and their job is to translate fairly low level demands into code. We used to call these code monkeys. The term has fallen out of favour but they still exist. Others have a very difficult problem domain, very high level, complex problems, and spend most of their time reasoning with how to manage that inherent complexity in a functioning software system. In these discussions it&#x27;s impossible to tell who is who.</div><br/></div></div></div></div><div id="41990670" class="c"><input type="checkbox" id="c-41990670" checked=""/><div class="controls bullet"><span class="by">CephalopodMD</span><span>|</span><a href="#41990458">prev</a><span>|</span><a href="#41987030">next</a><span>|</span><label class="collapse" for="c-41990670">[-]</label><label class="expand" for="c-41990670">[5 more]</label></div><br/><div class="children"><div class="content">I usually feel like i can confidently express a change I want in code faster and better than I can explain what I want an AI to do in English. Like if I have a good prompt, these tools work okay, but getting that prompt almost as hard as just writing the code itself often. Do others feel the same struggle?</div><br/><div id="41992599" class="c"><input type="checkbox" id="c-41992599" checked=""/><div class="controls bullet"><span class="by">Kiro</span><span>|</span><a href="#41990670">parent</a><span>|</span><a href="#41991003">next</a><span>|</span><label class="collapse" for="c-41992599">[-]</label><label class="expand" for="c-41992599">[1 more]</label></div><br/><div class="children"><div class="content">You learn how to effectively prompt it in a way where the AI can fill in the blanks. Sometimes the prompt is just a couple of words because I know that the AI will interpolate the rest by the context (getting the context right is crucial). However, even when I need to be verbose and have to spend a few minutes on a prompt it gives me code that would have taken half a day to write manually. You also need to learn how and when to split work into chunks. It&#x27;s much less intuitive than one would think and is completely different than how you would split it for a human. You get to &quot;know&quot; the AI and what it needs in order to succeed with a task.<p>LLMs have other problems though. The biggest problem for me is that it feels like I lose control of the codebase. I don&#x27;t have the same mental mapping of the code.</div><br/></div></div><div id="41991003" class="c"><input type="checkbox" id="c-41991003" checked=""/><div class="controls bullet"><span class="by">neodymiumphish</span><span>|</span><a href="#41990670">parent</a><span>|</span><a href="#41992599">prev</a><span>|</span><a href="#41987030">next</a><span>|</span><label class="collapse" for="c-41991003">[-]</label><label class="expand" for="c-41991003">[3 more]</label></div><br/><div class="children"><div class="content">I’m positive my experience pales in comparison to yours, as I don’t actually code anything beyond the occasional single use script, but YES! I hate trying to explain the exact SQL result I’m looking for or some text modification I need to be able to throw together a CTE since I have read-only access and can’t even build a temp table.</div><br/><div id="41991626" class="c"><input type="checkbox" id="c-41991626" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#41990670">root</a><span>|</span><a href="#41991003">parent</a><span>|</span><a href="#41992141">prev</a><span>|</span><a href="#41987030">next</a><span>|</span><label class="collapse" for="c-41991626">[-]</label><label class="expand" for="c-41991626">[1 more]</label></div><br/><div class="children"><div class="content">GPT-4o usually does well with SQL. Did a query right first time using cte’s, array functions, table created on the fly in the query, etc.<p>SQL syntax is fiddly so it’s nice to have a robot do it.</div><br/></div></div></div></div></div></div><div id="41987030" class="c"><input type="checkbox" id="c-41987030" checked=""/><div class="controls bullet"><span class="by">dgellow</span><span>|</span><a href="#41990670">prev</a><span>|</span><a href="#41986223">next</a><span>|</span><label class="collapse" for="c-41987030">[-]</label><label class="expand" for="c-41987030">[4 more]</label></div><br/><div class="children"><div class="content">I’ve been using Cody from Sourcegraph to have access to other models, if copilot offers something similar I guess I will switch back to it. I find copilot autocomplete to be more often on point than Cody, but the chat experience with Cody + Sonnet 3.5 is way ahead in may experience</div><br/><div id="41987426" class="c"><input type="checkbox" id="c-41987426" checked=""/><div class="controls bullet"><span class="by">sqs</span><span>|</span><a href="#41987030">parent</a><span>|</span><a href="#41991294">next</a><span>|</span><label class="collapse" for="c-41987426">[-]</label><label class="expand" for="c-41987426">[2 more]</label></div><br/><div class="children"><div class="content">Context is a huge part of the chat experience in Cody, and we&#x27;re working hard to stay ahead there as well with things like OpenCtx (<a href="https:&#x2F;&#x2F;openctx.org" rel="nofollow">https:&#x2F;&#x2F;openctx.org</a>) and more code context based on the code graph (defs&#x2F;refs&#x2F;etc.). All this competition is good for everyone. :)</div><br/><div id="41991646" class="c"><input type="checkbox" id="c-41991646" checked=""/><div class="controls bullet"><span class="by">dgellow</span><span>|</span><a href="#41987030">root</a><span>|</span><a href="#41987426">parent</a><span>|</span><a href="#41991294">next</a><span>|</span><label class="collapse" for="c-41991646">[-]</label><label class="expand" for="c-41991646">[1 more]</label></div><br/><div class="children"><div class="content">Your vscode and rider integrations are fantastic, love the different ways to add context to the chat</div><br/></div></div></div></div><div id="41991294" class="c"><input type="checkbox" id="c-41991294" checked=""/><div class="controls bullet"><span class="by">metadaemon</span><span>|</span><a href="#41987030">parent</a><span>|</span><a href="#41987426">prev</a><span>|</span><a href="#41986223">next</a><span>|</span><label class="collapse" for="c-41991294">[-]</label><label class="expand" for="c-41991294">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a hypocrite because I&#x27;m now currently paying for Cody due to their integration with the new OpenAI o1-preview model. I find this model to be mind blowing and it&#x27;s made me actually focus on the more mundane tasks that come with the job.</div><br/></div></div></div></div><div id="41986223" class="c"><input type="checkbox" id="c-41986223" checked=""/><div class="controls bullet"><span class="by">JimDabell</span><span>|</span><a href="#41987030">prev</a><span>|</span><a href="#41988750">next</a><span>|</span><label class="collapse" for="c-41986223">[-]</label><label class="expand" for="c-41986223">[9 more]</label></div><br/><div class="children"><div class="content">Anthropic’s article: <a href="https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;github-copilot" rel="nofollow">https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;github-copilot</a><p>GitHub’s article: <a href="https:&#x2F;&#x2F;github.blog&#x2F;news-insights&#x2F;product-news&#x2F;bringing-developer-choice-to-copilot&#x2F;" rel="nofollow">https:&#x2F;&#x2F;github.blog&#x2F;news-insights&#x2F;product-news&#x2F;bringing-deve...</a><p>Google Cloud’s article: <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;ai-machine-learning&#x2F;gemini-models-on-github-copilot" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;ai-machine-learning&#x2F;g...</a><p>Weird that it wasn’t published on the official Gemini news site here: <a href="https:&#x2F;&#x2F;blog.google&#x2F;products&#x2F;gemini&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.google&#x2F;products&#x2F;gemini&#x2F;</a><p>Edit: GitHub Copilot is now also available in Xcode: <a href="https:&#x2F;&#x2F;github.blog&#x2F;changelog&#x2F;2024-10-29-github-copilot-code-completion-in-xcode-is-now-available-in-public-preview&#x2F;" rel="nofollow">https:&#x2F;&#x2F;github.blog&#x2F;changelog&#x2F;2024-10-29-github-copilot-code...</a><p>Discussion here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41987404">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41987404</a></div><br/><div id="41986688" class="c"><input type="checkbox" id="c-41986688" checked=""/><div class="controls bullet"><span class="by">vault</span><span>|</span><a href="#41986223">parent</a><span>|</span><a href="#41986765">next</a><span>|</span><label class="collapse" for="c-41986688">[-]</label><label class="expand" for="c-41986688">[3 more]</label></div><br/><div class="children"><div class="content">I wonder if behind the choice of calling the human user &quot;mona&quot; there&#x27;s an Italian XD<p><a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;z01xgfl.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;z01xgfl.png</a></div><br/><div id="41986763" class="c"><input type="checkbox" id="c-41986763" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#41986223">root</a><span>|</span><a href="#41986688">parent</a><span>|</span><a href="#41986765">next</a><span>|</span><label class="collapse" for="c-41986763">[-]</label><label class="expand" for="c-41986763">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s Mona Lisa the Octocat: <a href="https:&#x2F;&#x2F;github.com&#x2F;monatheoctocat">https:&#x2F;&#x2F;github.com&#x2F;monatheoctocat</a></div><br/><div id="41988519" class="c"><input type="checkbox" id="c-41988519" checked=""/><div class="controls bullet"><span class="by">lelandfe</span><span>|</span><a href="#41986223">root</a><span>|</span><a href="#41986763">parent</a><span>|</span><a href="#41986765">next</a><span>|</span><label class="collapse" for="c-41988519">[-]</label><label class="expand" for="c-41988519">[1 more]</label></div><br/><div class="children"><div class="content">Hah, TIL. <a href="https:&#x2F;&#x2F;cameronmcefee.com&#x2F;work&#x2F;the-octocat&#x2F;" rel="nofollow">https:&#x2F;&#x2F;cameronmcefee.com&#x2F;work&#x2F;the-octocat&#x2F;</a></div><br/></div></div></div></div></div></div><div id="41986765" class="c"><input type="checkbox" id="c-41986765" checked=""/><div class="controls bullet"><span class="by">patates</span><span>|</span><a href="#41986223">parent</a><span>|</span><a href="#41986688">prev</a><span>|</span><a href="#41987202">next</a><span>|</span><label class="collapse" for="c-41986765">[-]</label><label class="expand" for="c-41986765">[4 more]</label></div><br/><div class="children"><div class="content">Google Cloud&#x27;s article is from tomorrow?<p><a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;ai-machine-learning&#x2F;gemini-models-on-github-copilot" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;ai-machine-learning&#x2F;g...</a><p><a href="https:&#x2F;&#x2F;i.postimg.cc&#x2F;RVWSfpvs&#x2F;grafik.png" rel="nofollow">https:&#x2F;&#x2F;i.postimg.cc&#x2F;RVWSfpvs&#x2F;grafik.png</a></div><br/><div id="41987017" class="c"><input type="checkbox" id="c-41987017" checked=""/><div class="controls bullet"><span class="by">JimDabell</span><span>|</span><a href="#41986223">root</a><span>|</span><a href="#41986765">parent</a><span>|</span><a href="#41986807">next</a><span>|</span><label class="collapse" for="c-41987017">[-]</label><label class="expand" for="c-41987017">[2 more]</label></div><br/><div class="children"><div class="content">It’s October 30th in several parts of the world already. It’s after midnight everywhere GMT+7 onwards.</div><br/><div id="41989627" class="c"><input type="checkbox" id="c-41989627" checked=""/><div class="controls bullet"><span class="by">patates</span><span>|</span><a href="#41986223">root</a><span>|</span><a href="#41987017">parent</a><span>|</span><a href="#41986807">next</a><span>|</span><label class="collapse" for="c-41989627">[-]</label><label class="expand" for="c-41989627">[1 more]</label></div><br/><div class="children"><div class="content">Obviously! However, Google being an American company, that was surprising. I&#x27;m in Europe and am used to seeing newest posts &quot;from yesterday&quot; when they are from the USA. This one is weird.</div><br/></div></div></div></div><div id="41986807" class="c"><input type="checkbox" id="c-41986807" checked=""/><div class="controls bullet"><span class="by">cortesoft</span><span>|</span><a href="#41986223">root</a><span>|</span><a href="#41986765">parent</a><span>|</span><a href="#41987017">prev</a><span>|</span><a href="#41987202">next</a><span>|</span><label class="collapse" for="c-41986807">[-]</label><label class="expand" for="c-41986807">[1 more]</label></div><br/><div class="children"><div class="content">It says the 29th now</div><br/></div></div></div></div></div></div><div id="41988750" class="c"><input type="checkbox" id="c-41988750" checked=""/><div class="controls bullet"><span class="by">ed_elliott_asc</span><span>|</span><a href="#41986223">prev</a><span>|</span><a href="#41990325">next</a><span>|</span><label class="collapse" for="c-41988750">[-]</label><label class="expand" for="c-41988750">[1 more]</label></div><br/><div class="children"><div class="content">I am excited about this as I use Claude for coding but what I really like about copilot is if you have a list of something random like:<p>&#x2F;* Col1 varchar not null,
Col2 int null,
Col3 int not nul*&#x2F;<p>Then start doing something else like:<p>| column | type |
|—-| —-|
| Col1 | varchar |<p>Then copilot is very good at guessing the rest of the table.<p>(This isn’t just sql to markdown it works whenever you want to repeat something using parts of another list somewhere in the same doc)<p>I hope they continues as this has been a game changer for me as it is so quick, really great.</div><br/></div></div><div id="41990325" class="c"><input type="checkbox" id="c-41990325" checked=""/><div class="controls bullet"><span class="by">jmpeax</span><span>|</span><a href="#41988750">prev</a><span>|</span><a href="#41986134">next</a><span>|</span><label class="collapse" for="c-41990325">[-]</label><label class="expand" for="c-41990325">[4 more]</label></div><br/><div class="children"><div class="content">So &quot;cut a deal&quot; means to <i>make</i> a deal rather than <i>sever</i> a deal?</div><br/><div id="41990368" class="c"><input type="checkbox" id="c-41990368" checked=""/><div class="controls bullet"><span class="by">heavyset_go</span><span>|</span><a href="#41990325">parent</a><span>|</span><a href="#41990391">next</a><span>|</span><label class="collapse" for="c-41990368">[-]</label><label class="expand" for="c-41990368">[1 more]</label></div><br/><div class="children"><div class="content">It does, and it was unclear to me, as well. It&#x27;s a poor title IMO</div><br/></div></div><div id="41990391" class="c"><input type="checkbox" id="c-41990391" checked=""/><div class="controls bullet"><span class="by">yowmamasita</span><span>|</span><a href="#41990325">parent</a><span>|</span><a href="#41990368">prev</a><span>|</span><a href="#41991792">next</a><span>|</span><label class="collapse" for="c-41990391">[-]</label><label class="expand" for="c-41990391">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;@IsmoComedian&#x2F;videos" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;@IsmoComedian&#x2F;videos</a> you&#x27;ll like him</div><br/></div></div><div id="41991792" class="c"><input type="checkbox" id="c-41991792" checked=""/><div class="controls bullet"><span class="by">Nition</span><span>|</span><a href="#41990325">parent</a><span>|</span><a href="#41990391">prev</a><span>|</span><a href="#41986134">next</a><span>|</span><label class="collapse" for="c-41991792">[-]</label><label class="expand" for="c-41991792">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a similar problem with the word &quot;cleave&quot; which can mean both cut apart or stick together.</div><br/></div></div></div></div><div id="41986134" class="c"><input type="checkbox" id="c-41986134" checked=""/><div class="controls bullet"><span class="by">jddj</span><span>|</span><a href="#41990325">prev</a><span>|</span><a href="#41989799">next</a><span>|</span><label class="collapse" for="c-41986134">[-]</label><label class="expand" for="c-41986134">[3 more]</label></div><br/><div class="children"><div class="content">Sensible.<p>Big part of competitors&#x27; (eg. Aider, Cursor, I imagine also jetbrains) advantage was not being tied to one model as the landscape changed.<p>After large MS OpenAI investment they could just as easily have put blinders on and doubled down.</div><br/><div id="41986249" class="c"><input type="checkbox" id="c-41986249" checked=""/><div class="controls bullet"><span class="by">kyawzazaw</span><span>|</span><a href="#41986134">parent</a><span>|</span><a href="#41989799">next</a><span>|</span><label class="collapse" for="c-41986249">[-]</label><label class="expand" for="c-41986249">[2 more]</label></div><br/><div class="children"><div class="content">Jetbrains is doing its own LLM</div><br/><div id="41986663" class="c"><input type="checkbox" id="c-41986663" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#41986134">root</a><span>|</span><a href="#41986249">parent</a><span>|</span><a href="#41989799">next</a><span>|</span><label class="collapse" for="c-41986663">[-]</label><label class="expand" for="c-41986663">[1 more]</label></div><br/><div class="children"><div class="content">Cursor is too! Mixing and matching specialized &amp; flagship models is the way forward.</div><br/></div></div></div></div></div></div><div id="41989799" class="c"><input type="checkbox" id="c-41989799" checked=""/><div class="controls bullet"><span class="by">lifeisstillgood</span><span>|</span><a href="#41986134">prev</a><span>|</span><a href="#41986316">next</a><span>|</span><label class="collapse" for="c-41989799">[-]</label><label class="expand" for="c-41989799">[1 more]</label></div><br/><div class="children"><div class="content">I still think it’s worth emphasising  - LLMs represent a massive capital absorber.  Taking gobs of funding into your company is how you grow, how your options become more valuable, how your employees stay with you.  If that treadmill were to break bad things happen.<p>Search has been stuttering for a while - Google’s growth and investment has been flattening - at some point they absorbed all the worlds stored information.<p>OpenAI showed the new growth - we need billions of dollars to build and the run the LLMs (at a loss one assumes) - the treadmill can keep going</div><br/></div></div><div id="41986316" class="c"><input type="checkbox" id="c-41986316" checked=""/><div class="controls bullet"><span class="by">gdiamos</span><span>|</span><a href="#41989799">prev</a><span>|</span><a href="#41988254">next</a><span>|</span><label class="collapse" for="c-41986316">[-]</label><label class="expand" for="c-41986316">[7 more]</label></div><br/><div class="children"><div class="content">Github was an early OpenAI design partner.  OpenAI developed a custom LLM for them.<p>It&#x27;s so interesting that even after that early mover advantage they have to go back to the foundation model providers.<p>Does this mean that future tech companies have no choice but to do this?</div><br/><div id="41987068" class="c"><input type="checkbox" id="c-41987068" checked=""/><div class="controls bullet"><span class="by">gk1</span><span>|</span><a href="#41986316">parent</a><span>|</span><a href="#41986897">next</a><span>|</span><label class="collapse" for="c-41987068">[-]</label><label class="expand" for="c-41987068">[2 more]</label></div><br/><div class="children"><div class="content">It may not be a model quality issue. It may be that GitHub wants to sell a lot more of Copilot, including to companies who refuse to use anything from OpenAI. Now GitHub can say &quot;Oh that&#x27;s fine, we have these two other lovely providers to choose from.&quot;<p>Also, after Anthropic and Google sold massive amounts of pre-paid usage credits to companies, those companies want to draw down that usage and get their money&#x27;s worth. GitHub might allow them to do that through Copilot, and therefore get their business.</div><br/><div id="41987913" class="c"><input type="checkbox" id="c-41987913" checked=""/><div class="controls bullet"><span class="by">manquer</span><span>|</span><a href="#41986316">root</a><span>|</span><a href="#41987068">parent</a><span>|</span><a href="#41986897">next</a><span>|</span><label class="collapse" for="c-41987913">[-]</label><label class="expand" for="c-41987913">[1 more]</label></div><br/><div class="children"><div class="content">I think that the credit scenario is more true for OpenAI than others . Existing Azure commits can be used to buy OpenAI via the marketplace. It will never be as simple for any non Azure partner (Only Github is tying up with Anthropic here not Azure)<p>GitHub doesn’t even support using those azure managed APIs for copilot today, it is just a license you can buy currently and add to a user license. The best you can do is pay for copilot with existing azure commits .<p>This seems about not being left behind as other models outpace what copilot can do with their custom OpenAI model that doesn’t seem to getting updated .</div><br/></div></div></div></div><div id="41986897" class="c"><input type="checkbox" id="c-41986897" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#41986316">parent</a><span>|</span><a href="#41987068">prev</a><span>|</span><a href="#41986576">next</a><span>|</span><label class="collapse" for="c-41986897">[-]</label><label class="expand" for="c-41986897">[3 more]</label></div><br/><div class="children"><div class="content">Yes, because transfer learning works. A specialized model for X will be subsumed by a general model for X&#x2F;Y&#x2F;Z as it becomes better at Y&#x2F;Z. This is why models which learn other languages become better at English.<p>Custom models still have use cases, e.g. situations requiring cheaper or faster inference. But ultimately The Bitter Lesson holds -- your specialized thing will always be overtaken by throwing more compute at a general thing. We&#x27;ll be following around foundation models for the foreseeable future, with distilled offshoots bubbling up&#x2F;dying along the way.</div><br/><div id="41987040" class="c"><input type="checkbox" id="c-41987040" checked=""/><div class="controls bullet"><span class="by">kingkongjaffa</span><span>|</span><a href="#41986316">root</a><span>|</span><a href="#41986897">parent</a><span>|</span><a href="#41986576">next</a><span>|</span><label class="collapse" for="c-41987040">[-]</label><label class="expand" for="c-41987040">[2 more]</label></div><br/><div class="children"><div class="content">&gt; This is why models which learn other languages become better at English.<p>Do you have a source for that, I&#x27;d love to learn more!</div><br/><div id="41987591" class="c"><input type="checkbox" id="c-41987591" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#41986316">root</a><span>|</span><a href="#41987040">parent</a><span>|</span><a href="#41986576">next</a><span>|</span><label class="collapse" for="c-41987591">[-]</label><label class="expand" for="c-41987591">[1 more]</label></div><br/><div class="children"><div class="content"><i>Evaluating cross-lingual transfer learning approaches in multilingual conversational agent models</i>[1]<p><i>Cross-lingual transfer learning for multilingual voice agents</i>[2]<p><i>Large Language Models Are Cross-Lingual Knowledge-Free Reasoners</i>[3]<p><i>An Empirical Study of Cross-Lingual Transfer Learning in Programming Languages</i>[4]<p>That should get you started on transfer learning re. languages, but you&#x27;ll have more fun personally picking interesting papers over reading a random yahoo&#x27;s choices. The fire hose of papers is nuts, so you&#x27;ll never be left wanting.<p>[1] <a href="https:&#x2F;&#x2F;www.amazon.science&#x2F;publications&#x2F;evaluating-cross-lingual-transfer-learning-approaches-in-multilingual-conversational-agent-models" rel="nofollow">https:&#x2F;&#x2F;www.amazon.science&#x2F;publications&#x2F;evaluating-cross-lin...</a><p>[2] <a href="https:&#x2F;&#x2F;www.amazon.science&#x2F;blog&#x2F;cross-lingual-transfer-learning-for-multilingual-voice-agents" rel="nofollow">https:&#x2F;&#x2F;www.amazon.science&#x2F;blog&#x2F;cross-lingual-transfer-learn...</a><p>[3] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2406.16655v1" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2406.16655v1</a><p>[4] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.16937v2" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.16937v2</a></div><br/></div></div></div></div></div></div><div id="41986576" class="c"><input type="checkbox" id="c-41986576" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#41986316">parent</a><span>|</span><a href="#41986897">prev</a><span>|</span><a href="#41988254">next</a><span>|</span><label class="collapse" for="c-41986576">[-]</label><label class="expand" for="c-41986576">[1 more]</label></div><br/><div class="children"><div class="content">I see no reason why GitHub wouldn’t use fine tuned models from google or anthropic.<p>I think their version of gpt-3.5 was a fine tune as well. I doubt they had a whole model from scratch made just for them.</div><br/></div></div></div></div><div id="41988254" class="c"><input type="checkbox" id="c-41988254" checked=""/><div class="controls bullet"><span class="by">Fairburn</span><span>|</span><a href="#41986316">prev</a><span>|</span><a href="#41991987">next</a><span>|</span><label class="collapse" for="c-41988254">[-]</label><label class="expand" for="c-41988254">[1 more]</label></div><br/><div class="children"><div class="content">1 point by Fairburn 0 minutes ago | prev | next | edit | delete [–]<p>I have no doubts that Claude is serviceable from a coders perspective. But for me, as a paid user, I became tired of being told that I have to slow down and then be cut off while actively working on a product. When Anthropic addresses this, Ill add it back to my tools.</div><br/></div></div><div id="41991987" class="c"><input type="checkbox" id="c-41991987" checked=""/><div class="controls bullet"><span class="by">intrepidsoldier</span><span>|</span><a href="#41988254">prev</a><span>|</span><a href="#41986547">next</a><span>|</span><label class="collapse" for="c-41991987">[-]</label><label class="expand" for="c-41991987">[1 more]</label></div><br/><div class="children"><div class="content">Can it help you work in large messy codebases or is it good only to &quot;build tic tac toe games in 5 mins&quot;?</div><br/></div></div><div id="41986547" class="c"><input type="checkbox" id="c-41986547" checked=""/><div class="controls bullet"><span class="by">xyst</span><span>|</span><a href="#41991987">prev</a><span>|</span><a href="#41986846">next</a><span>|</span><label class="collapse" for="c-41986547">[-]</label><label class="expand" for="c-41986547">[6 more]</label></div><br/><div class="children"><div class="content">Got to cut deals before the AI bust pops, VC money and interest vanishes and interest rates go up.<p>Also diversifying is always a good option. Even if one cash cow gets nuked from orbit, you have 2 other companies to latch onto</div><br/><div id="41987022" class="c"><input type="checkbox" id="c-41987022" checked=""/><div class="controls bullet"><span class="by">kingkongjaffa</span><span>|</span><a href="#41986547">parent</a><span>|</span><a href="#41986846">next</a><span>|</span><label class="collapse" for="c-41987022">[-]</label><label class="expand" for="c-41987022">[5 more]</label></div><br/><div class="children"><div class="content">&gt; interest rates go up<p>This is kind of a cynical tech startup take:<p>- ragging on VC&#x27;s
- calling something a bubble<p>Interest rates are on their way back down btw.<p><a href="https:&#x2F;&#x2F;www.federalreserve.gov&#x2F;newsevents&#x2F;pressreleases&#x2F;monetary20240918a.htm" rel="nofollow">https:&#x2F;&#x2F;www.federalreserve.gov&#x2F;newsevents&#x2F;pressreleases&#x2F;mone...</a><p><a href="https:&#x2F;&#x2F;www.reuters.com&#x2F;world&#x2F;uk&#x2F;bank-england-cut-bank-rate-475-nov-7-say-all-72-economists-polled-2024-10-28&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reuters.com&#x2F;world&#x2F;uk&#x2F;bank-england-cut-bank-rate-...</a><p>Funding has looked to be running out a few times for OpenAI specifically, but most frontier model development is reasonably well funded still.</div><br/><div id="41987082" class="c"><input type="checkbox" id="c-41987082" checked=""/><div class="controls bullet"><span class="by">njtransit</span><span>|</span><a href="#41986547">root</a><span>|</span><a href="#41987022">parent</a><span>|</span><a href="#41990282">next</a><span>|</span><label class="collapse" for="c-41987082">[-]</label><label class="expand" for="c-41987082">[3 more]</label></div><br/><div class="children"><div class="content">If interest rates are on their way down, why has the 10Y treasury yield increased 50 points over the last month? <a href="https:&#x2F;&#x2F;www.cnbc.com&#x2F;quotes&#x2F;US10Y" rel="nofollow">https:&#x2F;&#x2F;www.cnbc.com&#x2F;quotes&#x2F;US10Y</a></div><br/><div id="41990173" class="c"><input type="checkbox" id="c-41990173" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#41986547">root</a><span>|</span><a href="#41987082">parent</a><span>|</span><a href="#41990213">next</a><span>|</span><label class="collapse" for="c-41990173">[-]</label><label class="expand" for="c-41990173">[1 more]</label></div><br/><div class="children"><div class="content">Because they previously decreased more under the expectation of another half point cut by the fed. Stronger economic indicators have cut the expectation for steep rate cuts so treasuries are declining.</div><br/></div></div><div id="41990213" class="c"><input type="checkbox" id="c-41990213" checked=""/><div class="controls bullet"><span class="by">warkdarrior</span><span>|</span><a href="#41986547">root</a><span>|</span><a href="#41987082">parent</a><span>|</span><a href="#41990173">prev</a><span>|</span><a href="#41990282">next</a><span>|</span><label class="collapse" for="c-41990213">[-]</label><label class="expand" for="c-41990213">[1 more]</label></div><br/><div class="children"><div class="content">It also dropped 40 points over the last six months.</div><br/></div></div></div></div><div id="41990282" class="c"><input type="checkbox" id="c-41990282" checked=""/><div class="controls bullet"><span class="by">FactKnower69</span><span>|</span><a href="#41986547">root</a><span>|</span><a href="#41987022">parent</a><span>|</span><a href="#41987082">prev</a><span>|</span><a href="#41986846">next</a><span>|</span><label class="collapse" for="c-41990282">[-]</label><label class="expand" for="c-41990282">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Interest rates are on their way back down btw.<p>completely wrong, where have you been the past month? 10Y t-notes are actually UP after the fed&#x27;s hysterical 50 basis point cut lol</div><br/></div></div></div></div></div></div><div id="41986846" class="c"><input type="checkbox" id="c-41986846" checked=""/><div class="controls bullet"><span class="by">sprkv5</span><span>|</span><a href="#41986547">prev</a><span>|</span><a href="#41986168">next</a><span>|</span><label class="collapse" for="c-41986846">[-]</label><label class="expand" for="c-41986846">[7 more]</label></div><br/><div class="children"><div class="content">One of the reasons that comes to my mind is - it could have been problematic look for only Microsoft (Copilot) to have access to GitHub for training AI models - à la monopolizing a data treasure trove. With anti-competitive legislation catching up to Google to open up its Play Store, this could have been one of key reasons why this deal came about.</div><br/><div id="41987036" class="c"><input type="checkbox" id="c-41987036" checked=""/><div class="controls bullet"><span class="by">poincaredisk</span><span>|</span><a href="#41986846">parent</a><span>|</span><a href="#41986168">next</a><span>|</span><label class="collapse" for="c-41987036">[-]</label><label class="expand" for="c-41987036">[6 more]</label></div><br/><div class="children"><div class="content">Copilot can choke on my AGPL code on GitHub, that was used for training their proprietary models. I&#x27;m still salty about this, sadly looks like the world has largely moved on.</div><br/><div id="41987266" class="c"><input type="checkbox" id="c-41987266" checked=""/><div class="controls bullet"><span class="by">sprkv5</span><span>|</span><a href="#41986846">root</a><span>|</span><a href="#41987036">parent</a><span>|</span><a href="#41987248">next</a><span>|</span><label class="collapse" for="c-41987266">[-]</label><label class="expand" for="c-41987266">[2 more]</label></div><br/><div class="children"><div class="content">Yet Google and Anthropic wanted in on the huge data that GitHub has to offer. It seems the world has not moved on just yet.</div><br/><div id="41988339" class="c"><input type="checkbox" id="c-41988339" checked=""/><div class="controls bullet"><span class="by">nonfamous</span><span>|</span><a href="#41986846">root</a><span>|</span><a href="#41987266">parent</a><span>|</span><a href="#41987248">next</a><span>|</span><label class="collapse" for="c-41988339">[-]</label><label class="expand" for="c-41988339">[1 more]</label></div><br/><div class="children"><div class="content">The Claude terms of service [1] apparently preclude Anthropic or AWS using GitHub user data for training:<p>GitHub Copilot uses Claude 3.5 Sonnet hosted on Amazon Web Services. When using Claude 3.5 Sonnet, prompts and metadata are sent to Amazon&#x27;s Bedrock service, which makes the following data commitments: Amazon Bedrock doesn&#x27;t store or log your prompts and completions. Amazon Bedrock doesn&#x27;t use your prompts and completions to train any AWS models and doesn&#x27;t distribute them to third parties.<p>[1] <a href="https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;copilot&#x2F;using-github-copilot&#x2F;using-claude-sonnet-in-github-copilot" rel="nofollow">https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;copilot&#x2F;using-github-copilot&#x2F;usin...</a></div><br/></div></div></div></div><div id="41987248" class="c"><input type="checkbox" id="c-41987248" checked=""/><div class="controls bullet"><span class="by">azemetre</span><span>|</span><a href="#41986846">root</a><span>|</span><a href="#41987036">parent</a><span>|</span><a href="#41987266">prev</a><span>|</span><a href="#41986168">next</a><span>|</span><label class="collapse" for="c-41987248">[-]</label><label class="expand" for="c-41987248">[3 more]</label></div><br/><div class="children"><div class="content">It really feels like a digital form of colonialism; they come in take everything, completely disregard the rules, ignore intellectual copyright laws (while you still have to obey them), but when you speak out against this suddenly you are a luddite that doesn&#x27;t care about human progress.</div><br/><div id="41988621" class="c"><input type="checkbox" id="c-41988621" checked=""/><div class="controls bullet"><span class="by">mnau</span><span>|</span><a href="#41986846">root</a><span>|</span><a href="#41987248">parent</a><span>|</span><a href="#41989153">next</a><span>|</span><label class="collapse" for="c-41988621">[-]</label><label class="expand" for="c-41988621">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s especially distasteful when we consider lawsuits like Epic vs Silicon Knights. <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Silicon_Knights" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Silicon_Knights</a><p>&gt; Silicon Knights had &quot;deliberately and repeatedly copied thousands of lines of Epic Games&#x27; copyrighted code, and then attempted to conceal its wrongdoing by removing Epic Games&#x27; copyright notices and by disguising Epic Games&#x27; copyrighted code as Silicon Knights&#x27; own<p>&gt; Epic Games prevailed against Silicon Knights&#x27; lawsuit, and won its counter-suit for $4.45 million on grounds of copyright infringement,<p>&gt; following the loss of the court case, Silicon Knights filed for bankruptcy</div><br/></div></div><div id="41989153" class="c"><input type="checkbox" id="c-41989153" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#41986846">root</a><span>|</span><a href="#41987248">parent</a><span>|</span><a href="#41988621">prev</a><span>|</span><a href="#41986168">next</a><span>|</span><label class="collapse" for="c-41989153">[-]</label><label class="expand" for="c-41989153">[1 more]</label></div><br/><div class="children"><div class="content">If it doesn&#x27;t work, oh well, you&#x27;ll get VC money for something else.<p>If it works, the lawyers will figure it out.</div><br/></div></div></div></div></div></div></div></div><div id="41986168" class="c"><input type="checkbox" id="c-41986168" checked=""/><div class="controls bullet"><span class="by">neevans</span><span>|</span><a href="#41986846">prev</a><span>|</span><a href="#41986100">next</a><span>|</span><label class="collapse" for="c-41986168">[-]</label><label class="expand" for="c-41986168">[1 more]</label></div><br/><div class="children"><div class="content">Actually excited 2M context window will be useful in this case</div><br/></div></div><div id="41986100" class="c"><input type="checkbox" id="c-41986100" checked=""/><div class="controls bullet"><span class="by">thecopy</span><span>|</span><a href="#41986168">prev</a><span>|</span><a href="#41989158">next</a><span>|</span><label class="collapse" for="c-41986100">[-]</label><label class="expand" for="c-41986100">[8 more]</label></div><br/><div class="children"><div class="content">Great news! This can only mean better suggestions.<p>I expected little from Copilot, but now i find it indispensible. It is such a productivity multiplier.</div><br/><div id="41986483" class="c"><input type="checkbox" id="c-41986483" checked=""/><div class="controls bullet"><span class="by">otteromkram</span><span>|</span><a href="#41986100">parent</a><span>|</span><a href="#41989158">next</a><span>|</span><label class="collapse" for="c-41986483">[-]</label><label class="expand" for="c-41986483">[7 more]</label></div><br/><div class="children"><div class="content">I removed it from windows and I&#x27;m still very productive. Probably moreso, since I don&#x27;t have to make constant corrections.<p>To each their own.</div><br/><div id="41986950" class="c"><input type="checkbox" id="c-41986950" checked=""/><div class="controls bullet"><span class="by">Tiberium</span><span>|</span><a href="#41986100">root</a><span>|</span><a href="#41986483">parent</a><span>|</span><a href="#41989158">next</a><span>|</span><label class="collapse" for="c-41986950">[-]</label><label class="expand" for="c-41986950">[6 more]</label></div><br/><div class="children"><div class="content">GitHub Copilot and Microsoft Copilot are different products</div><br/><div id="41987630" class="c"><input type="checkbox" id="c-41987630" checked=""/><div class="controls bullet"><span class="by">ipaddr</span><span>|</span><a href="#41986100">root</a><span>|</span><a href="#41986950">parent</a><span>|</span><a href="#41988208">next</a><span>|</span><label class="collapse" for="c-41987630">[-]</label><label class="expand" for="c-41987630">[1 more]</label></div><br/><div class="children"><div class="content">Their branding is confusing</div><br/></div></div><div id="41988208" class="c"><input type="checkbox" id="c-41988208" checked=""/><div class="controls bullet"><span class="by">hbn</span><span>|</span><a href="#41986100">root</a><span>|</span><a href="#41986950">parent</a><span>|</span><a href="#41987630">prev</a><span>|</span><a href="#41987448">next</a><span>|</span><label class="collapse" for="c-41988208">[-]</label><label class="expand" for="c-41988208">[1 more]</label></div><br/><div class="children"><div class="content">Is Microsoft Copilot even a single product? It seems to me they just shove AI in random places throughout their products and call it Copilot. Which would make Github Copilot essentially another one of these places the branding shows up (even if it started there)</div><br/></div></div><div id="41987448" class="c"><input type="checkbox" id="c-41987448" checked=""/><div class="controls bullet"><span class="by">doublerabbit</span><span>|</span><a href="#41986100">root</a><span>|</span><a href="#41986950">parent</a><span>|</span><a href="#41988208">prev</a><span>|</span><a href="#41989158">next</a><span>|</span><label class="collapse" for="c-41987448">[-]</label><label class="expand" for="c-41987448">[3 more]</label></div><br/><div class="children"><div class="content">Same difference. They both are glorified liberians.</div><br/><div id="41987735" class="c"><input type="checkbox" id="c-41987735" checked=""/><div class="controls bullet"><span class="by">TimeBearingDown</span><span>|</span><a href="#41986100">root</a><span>|</span><a href="#41987448">parent</a><span>|</span><a href="#41989158">next</a><span>|</span><label class="collapse" for="c-41987735">[-]</label><label class="expand" for="c-41987735">[2 more]</label></div><br/><div class="children"><div class="content">Liberians seem quite useful, then! I’ve never been to Africa myself.</div><br/><div id="41989335" class="c"><input type="checkbox" id="c-41989335" checked=""/><div class="controls bullet"><span class="by">timeon</span><span>|</span><a href="#41986100">root</a><span>|</span><a href="#41987735">parent</a><span>|</span><a href="#41989158">next</a><span>|</span><label class="collapse" for="c-41989335">[-]</label><label class="expand" for="c-41989335">[1 more]</label></div><br/><div class="children"><div class="content">Just don&#x27;t lick your fingers.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="41989158" class="c"><input type="checkbox" id="c-41989158" checked=""/><div class="controls bullet"><span class="by">richardw</span><span>|</span><a href="#41986100">prev</a><span>|</span><a href="#41991254">next</a><span>|</span><label class="collapse" for="c-41989158">[-]</label><label class="expand" for="c-41989158">[1 more]</label></div><br/><div class="children"><div class="content">This kind of thing is why I think Sam is often misjudged. You can’t fuck around in such a competitive market. If you go in all kumbaya you’ll get crushed by market forces. It’s rare for company&#x2F;founder ideals to survive the market indefinitely. I think he’s iterated fast and the job is still very hard.</div><br/></div></div><div id="41991254" class="c"><input type="checkbox" id="c-41991254" checked=""/><div class="controls bullet"><span class="by">albert_e</span><span>|</span><a href="#41989158">prev</a><span>|</span><a href="#41986392">next</a><span>|</span><label class="collapse" for="c-41991254">[-]</label><label class="expand" for="c-41991254">[2 more]</label></div><br/><div class="children"><div class="content">Interestingly GitHub (a Microsoft entity) will use Amazon Bedrock to run Claude Sonnet.<p>&gt; Claude 3.5 Sonnet runs on GitHub Copilot via Amazon Bedrock, leveraging Bedrock’s cross-region inference to further enhance reliability.<p>[1] <a href="https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;github-copilot" rel="nofollow">https:&#x2F;&#x2F;www.anthropic.com&#x2F;news&#x2F;github-copilot</a></div><br/><div id="41992342" class="c"><input type="checkbox" id="c-41992342" checked=""/><div class="controls bullet"><span class="by">Squarex</span><span>|</span><a href="#41991254">parent</a><span>|</span><a href="#41986392">next</a><span>|</span><label class="collapse" for="c-41992342">[-]</label><label class="expand" for="c-41992342">[1 more]</label></div><br/><div class="children"><div class="content">They probably need enterprise level support for regional regulations like gdpr. Especially for their enterprise customers.</div><br/></div></div></div></div><div id="41986392" class="c"><input type="checkbox" id="c-41986392" checked=""/><div class="controls bullet"><span class="by">mmiyer</span><span>|</span><a href="#41991254">prev</a><span>|</span><a href="#41991194">next</a><span>|</span><label class="collapse" for="c-41986392">[-]</label><label class="expand" for="c-41986392">[1 more]</label></div><br/><div class="children"><div class="content">Seems to be part of Microsoft’s hedging of its OpenAI bet, ever since Sam Altman’s ousting: <a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;10&#x2F;17&#x2F;technology&#x2F;microsoft-openai-partnership-deal.html" rel="nofollow">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2024&#x2F;10&#x2F;17&#x2F;technology&#x2F;microsoft-open...</a></div><br/></div></div><div id="41991194" class="c"><input type="checkbox" id="c-41991194" checked=""/><div class="controls bullet"><span class="by">pyeri</span><span>|</span><a href="#41986392">prev</a><span>|</span><a href="#41989485">next</a><span>|</span><label class="collapse" for="c-41991194">[-]</label><label class="expand" for="c-41991194">[3 more]</label></div><br/><div class="children"><div class="content">Call me eccentric but the only true or utilitarian use case I&#x27;ve found for AI so far is chatgpt. Rest all appear to be shiny toys just trying to bask in the AI glory but none solve any real human problem?</div><br/><div id="41991199" class="c"><input type="checkbox" id="c-41991199" checked=""/><div class="controls bullet"><span class="by">akmittal</span><span>|</span><a href="#41991194">parent</a><span>|</span><a href="#41992585">next</a><span>|</span><label class="collapse" for="c-41991199">[-]</label><label class="expand" for="c-41991199">[1 more]</label></div><br/><div class="children"><div class="content">ChatGPT is just good at marketing and they were the first one with good model. Claude is equally good or better</div><br/></div></div><div id="41992585" class="c"><input type="checkbox" id="c-41992585" checked=""/><div class="controls bullet"><span class="by">globular-toast</span><span>|</span><a href="#41991194">parent</a><span>|</span><a href="#41991199">prev</a><span>|</span><a href="#41989485">next</a><span>|</span><label class="collapse" for="c-41992585">[-]</label><label class="expand" for="c-41992585">[1 more]</label></div><br/><div class="children"><div class="content">Even ChatGPT is rubbish. Try to figure out something you couldn&#x27;t find in a book and it will end up contradicting itself before long. If it gets it right that just means you could have found it in a book. I&#x27;ve been immersed in the internet my whole life and I still think books are the best source of knowledge. Curation and editing are what we need more of.</div><br/></div></div></div></div><div id="41989485" class="c"><input type="checkbox" id="c-41989485" checked=""/><div class="controls bullet"><span class="by">pavelboyko</span><span>|</span><a href="#41991194">prev</a><span>|</span><label class="collapse" for="c-41989485">[-]</label><label class="expand" for="c-41989485">[4 more]</label></div><br/><div class="children"><div class="content">I mentored junior SWE and CS students for years, and now using Claude as a coding assistant feels very similar. Yesterday, it suggested implementing a JSON parser from scratch in C to avoid a dependency -- and, unsurprisingly, the code didn’t work. Two main differences stand out: 1) the LLM doesn’t learn from corrections (at least not directly), and 2) the feedback loop is seconds instead of days. This speed is so convenient that it makes hiring junior SWEs seem almost pointless, though I sometimes wonder where we’ll find mid-level and senior developers tomorrow if we stop hiring juniors today.</div><br/><div id="41989653" class="c"><input type="checkbox" id="c-41989653" checked=""/><div class="controls bullet"><span class="by">al_borland</span><span>|</span><a href="#41989485">parent</a><span>|</span><a href="#41989553">next</a><span>|</span><label class="collapse" for="c-41989653">[-]</label><label class="expand" for="c-41989653">[1 more]</label></div><br/><div class="children"><div class="content">Does speed matter when it&#x27;s not getting better and learning from corrections? I think I&#x27;d rather give someone a problem and have them come back with something that works in a couple days (answering a question here or there), rather than spend my time doing it myself because I&#x27;m getting fast, but wrong, results that aren&#x27;t improving from the AI.<p>&gt; though I sometimes wonder where we’ll find mid-level and senior developers tomorrow if we stop hiring juniors today.<p>This is also a key point. While there is a lot of short term thinking these days, since people don&#x27;t stick with companies like they used to. As a person who has been with my company for close to 20 years, making sure things can still run once you leave is important from a business perspective.<p>Training isn&#x27;t about today, it&#x27;s about tomorrow. I&#x27;ve trained a lot of people, and doing it myself would always be faster in the moment. But it&#x27;s about making the team better and making sure more people have more skill, to reduce single points of failure and ensure business continuity over the long-term. Not all of it pays off, but when it does, it pays off big.</div><br/></div></div><div id="41989553" class="c"><input type="checkbox" id="c-41989553" checked=""/><div class="controls bullet"><span class="by">hypeatei</span><span>|</span><a href="#41989485">parent</a><span>|</span><a href="#41989653">prev</a><span>|</span><a href="#41989615">next</a><span>|</span><label class="collapse" for="c-41989553">[-]</label><label class="expand" for="c-41989553">[1 more]</label></div><br/><div class="children"><div class="content">Years of experience doesn&#x27;t correlate to a good developer either. I&#x27;ve seen senior devs using AI to solve impossible problems, for example asking it how to store an API key client side without leaking it...</div><br/></div></div></div></div></div></div></div></div></div></body></html>