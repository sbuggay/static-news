<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1721206870077" as="style"/><link rel="stylesheet" href="styles.css?v=1721206870077"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://docs.scale-lang.com/">Run CUDA, unmodified, on AMD GPUs</a> <span class="domain">(<a href="https://docs.scale-lang.com">docs.scale-lang.com</a>)</span></div><div class="subtext"><span>Straw</span> | <span>351 comments</span></div><br/><div><div id="40970717" class="c"><input type="checkbox" id="c-40970717" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#40970852">next</a><span>|</span><label class="collapse" for="c-40970717">[-]</label><label class="expand" for="c-40970717">[186 more]</label></div><br/><div class="children"><div class="content">A lot of people think AMD should support these translation layers but I think it&#x27;s a bad idea. CUDA is not designed to be vendor agnostic and Nvidia can make things arbitrarily difficult both technically and legally. For example I think it would be against the license agreement of cuDNN or cuBLAS to run them on this. So those and other Nvidia libraries would become part of the API boundary that AMD would need to reimplement and support.<p>Chasing bug-for-bug compatibility is a fool&#x27;s errand. The important users of CUDA are open source. AMD can implement support directly in the upstream projects like pytorch or llama.cpp. And once support is there it can be maintained by the community.</div><br/><div id="40971093" class="c"><input type="checkbox" id="c-40971093" checked=""/><div class="controls bullet"><span class="by">eslaught</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40971026">next</a><span>|</span><label class="collapse" for="c-40971093">[-]</label><label class="expand" for="c-40971093">[66 more]</label></div><br/><div class="children"><div class="content">Are you aware of HIP? It&#x27;s officially supported and, for code that avoids obscure features of CUDA like inline PTX, it&#x27;s pretty much a find-and-replace to get a working build:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;ROCm&#x2F;HIP">https:&#x2F;&#x2F;github.com&#x2F;ROCm&#x2F;HIP</a><p>Don&#x27;t believe me? Include this at the top of your CUDA code, build with hipcc, and see what happens:<p><a href="https:&#x2F;&#x2F;gitlab.com&#x2F;StanfordLegion&#x2F;legion&#x2F;-&#x2F;blob&#x2F;master&#x2F;runtime&#x2F;hip_cuda_compat&#x2F;hip_cuda.h" rel="nofollow">https:&#x2F;&#x2F;gitlab.com&#x2F;StanfordLegion&#x2F;legion&#x2F;-&#x2F;blob&#x2F;master&#x2F;runti...</a><p>It&#x27;s incomplete because I&#x27;m lazy but you can see most things are just a single #ifdef away in the implementation.</div><br/><div id="40971168" class="c"><input type="checkbox" id="c-40971168" checked=""/><div class="controls bullet"><span class="by">currymj</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971093">parent</a><span>|</span><a href="#40971932">next</a><span>|</span><label class="collapse" for="c-40971168">[-]</label><label class="expand" for="c-40971168">[55 more]</label></div><br/><div class="children"><div class="content">if you&#x27;re talking about building anything, that is already too hard for ML researchers.<p>you have to be able to pip install something and just have it work, reasonably fast, without crashing, and also it has to not interfere with 100 other weird poorly maintained ML library dependencies.</div><br/><div id="40971813" class="c"><input type="checkbox" id="c-40971813" checked=""/><div class="controls bullet"><span class="by">eslaught</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971168">parent</a><span>|</span><a href="#40972814">next</a><span>|</span><label class="collapse" for="c-40971813">[-]</label><label class="expand" for="c-40971813">[2 more]</label></div><br/><div class="children"><div class="content">If your point is that HIP is not a zero-effort porting solution, that is correct. HIP is a <i>low</i>-effort solution, not a zero effort solution. It targets users who already use and know CUDA, and minimizes the changes that are required from pre-existing CUDA code.<p>In the case of these abstraction layers, then it would be the responsibility of the abstraction maintainers (or AMD) to port them. Obviously, someone who does not even use CUDA would not use HIP either.<p>To be honest, I have a hard time believing that a truly zero-effort solution exists. Especially one that gets high performance. Once you start talking about the full stack, there are too many potholes and sharp edges to believe that it will really work. So I am highly skeptical of original article. Not that I wouldn&#x27;t want to be proved wrong. But what they&#x27;re claiming to do is a big lift, even taking HIP as a starting point.<p>The easiest, fastest (for end users), highest-performance solution for ML will come when the ecosystem integrates it natively. HIP would be a way to get there faster, but it will take nonzero effort from CUDA-proficient engineers to get there.</div><br/><div id="40977136" class="c"><input type="checkbox" id="c-40977136" checked=""/><div class="controls bullet"><span class="by">currymj</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971813">parent</a><span>|</span><a href="#40972814">next</a><span>|</span><label class="collapse" for="c-40977136">[-]</label><label class="expand" for="c-40977136">[1 more]</label></div><br/><div class="children"><div class="content">I agree completely with your last point.<p>As other commenters have pointed out, this is probably a good solution for HPC jobs where everyone is using C++ or Fortran anyway and you frequently write your own CUDA kernels.<p>From time to time I run into a decision maker who understandably wants to believe that AMD cards are now &quot;ready&quot; to be used for deep learning, and points to things like the fact that HIP mostly works pretty well. I was kind of reacting against that.</div><br/></div></div></div></div><div id="40972814" class="c"><input type="checkbox" id="c-40972814" checked=""/><div class="controls bullet"><span class="by">elashri</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971168">parent</a><span>|</span><a href="#40971813">prev</a><span>|</span><a href="#40971362">next</a><span>|</span><label class="collapse" for="c-40972814">[-]</label><label class="expand" for="c-40972814">[1 more]</label></div><br/><div class="children"><div class="content">As someone doing a lot of work with CUDA in a big research organization, there are few of us. If you are working with CUDA, then you are not from the type of people who wait to have something that just works like you describe. CUDA itself is a battle with poorly documented stuff.</div><br/></div></div><div id="40971362" class="c"><input type="checkbox" id="c-40971362" checked=""/><div class="controls bullet"><span class="by">bootsmann</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971168">parent</a><span>|</span><a href="#40972814">prev</a><span>|</span><a href="#40972288">next</a><span>|</span><label class="collapse" for="c-40971362">[-]</label><label class="expand" for="c-40971362">[43 more]</label></div><br/><div class="children"><div class="content">Don’t most orgs that are deep enough to run custom cuda kernels have dedicated engineers for this stuff. I can’t imagine a person who can write raw cuda not being able to handle things more difficult than pip install.</div><br/><div id="40971697" class="c"><input type="checkbox" id="c-40971697" checked=""/><div class="controls bullet"><span class="by">gaogao</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971362">parent</a><span>|</span><a href="#40976395">next</a><span>|</span><label class="collapse" for="c-40971697">[-]</label><label class="expand" for="c-40971697">[41 more]</label></div><br/><div class="children"><div class="content">Engineers who are really, really good at CUDA are worth their weight in gold, so there&#x27;s more projects for them than they have time. Worth their weight in gold isn&#x27;t figurative here – the one I know has a ski house more expensive than 180 lbs of gold (~$5,320,814).</div><br/><div id="40973513" class="c"><input type="checkbox" id="c-40973513" checked=""/><div class="controls bullet"><span class="by">Willish42</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971697">parent</a><span>|</span><a href="#40983131">next</a><span>|</span><label class="collapse" for="c-40973513">[-]</label><label class="expand" for="c-40973513">[9 more]</label></div><br/><div class="children"><div class="content">The fact that &quot;worth their weight in cold&quot; typically means in the single-digit millions is <i>fascinating</i> to me (though I doubt I&#x27;ll be able to get there myself, maybe someday). I looked it up though and I think this is undercounting the current value of gold per ounce&#x2F;lb&#x2F;etc.<p>5320814 &#x2F; 180 &#x2F; 16 = ~1847.5<p>Per <a href="https:&#x2F;&#x2F;www.apmex.com&#x2F;gold-price" rel="nofollow">https:&#x2F;&#x2F;www.apmex.com&#x2F;gold-price</a> and <a href="https:&#x2F;&#x2F;goldprice.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;goldprice.org&#x2F;</a>, current value is north of $2400 &#x2F; oz. It was around $1800 in 2020. That growth for _gold_ of all things  (up 71% in the last 5 years) is crazy to me.<p>It&#x27;s worth noting that anyone with a ski house that expensive probably has a net worth well over twice the price of that ski house. I guess it&#x27;s time to start learning CUDA!</div><br/><div id="40974500" class="c"><input type="checkbox" id="c-40974500" checked=""/><div class="controls bullet"><span class="by">atwrk</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973513">parent</a><span>|</span><a href="#40973588">next</a><span>|</span><label class="collapse" for="c-40974500">[-]</label><label class="expand" for="c-40974500">[4 more]</label></div><br/><div class="children"><div class="content"><i>&gt; That growth for _gold_ of all things (up 71% in the last 5 years) is crazy to me.</i><p>For comparison: S&amp;P500 grew about the same during that period (more than 100% from Jan 2019, about 70 from Dec 2019), so the higher price of gold did not outperform the growth of the general (financial) economy.</div><br/><div id="40975942" class="c"><input type="checkbox" id="c-40975942" checked=""/><div class="controls bullet"><span class="by">dash2</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974500">parent</a><span>|</span><a href="#40973588">next</a><span>|</span><label class="collapse" for="c-40975942">[-]</label><label class="expand" for="c-40975942">[3 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s still surprising performance, because the S&amp;P generates income and pays dividends. Its increase reflects (at least, is supposed to!) expectations of future higher income. Gold doesn&#x27;t even bear interest....</div><br/><div id="40983509" class="c"><input type="checkbox" id="c-40983509" checked=""/><div class="controls bullet"><span class="by">t-3</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40975942">parent</a><span>|</span><a href="#40982467">next</a><span>|</span><label class="collapse" for="c-40983509">[-]</label><label class="expand" for="c-40983509">[1 more]</label></div><br/><div class="children"><div class="content">Gold is commonly seen as a hedge against inflation and a decently stable non-currency store of value. With many countries having&#x2F;being perceived to have high inflation during this time, the price of gold is bound to rise as well. Pretty much any economic or sociopolitical tremor will bounce up the price of the gold at least temporarily.</div><br/></div></div><div id="40982467" class="c"><input type="checkbox" id="c-40982467" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40975942">parent</a><span>|</span><a href="#40983509">prev</a><span>|</span><a href="#40973588">next</a><span>|</span><label class="collapse" for="c-40982467">[-]</label><label class="expand" for="c-40982467">[1 more]</label></div><br/><div class="children"><div class="content">The S&amp;P doesn&#x27;t really pay much in the way of dividends does it? Last time I checked it was order-of-magnitude 1% which is a bit of a joke figure.<p>Anyway, there isn&#x27;t a lot of evidence that the value of gold is going up. It seems to just be keeping pace with the M2. Both doubled-and-a-bit since 2010 (working in USD).</div><br/></div></div></div></div></div></div><div id="40973588" class="c"><input type="checkbox" id="c-40973588" checked=""/><div class="controls bullet"><span class="by">boulos</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973513">parent</a><span>|</span><a href="#40974500">prev</a><span>|</span><a href="#40975210">next</a><span>|</span><label class="collapse" for="c-40973588">[-]</label><label class="expand" for="c-40973588">[3 more]</label></div><br/><div class="children"><div class="content">Note: gold uses <i>troy</i> ounces, so adjust by ~10%. It&#x27;s easier to just use grams or kilograms :).</div><br/><div id="40978267" class="c"><input type="checkbox" id="c-40978267" checked=""/><div class="controls bullet"><span class="by">Willish42</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973588">parent</a><span>|</span><a href="#40975210">next</a><span>|</span><label class="collapse" for="c-40978267">[-]</label><label class="expand" for="c-40978267">[2 more]</label></div><br/><div class="children"><div class="content">Thanks, I&#x27;m a bit new to this entire concept. Do <i>troy</i> lbs also exist, or is that just a term when measuring ounces?</div><br/><div id="40982833" class="c"><input type="checkbox" id="c-40982833" checked=""/><div class="controls bullet"><span class="by">someguydave</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40978267">parent</a><span>|</span><a href="#40975210">next</a><span>|</span><label class="collapse" for="c-40982833">[-]</label><label class="expand" for="c-40982833">[1 more]</label></div><br/><div class="children"><div class="content">yes, there are troy pounds, they are 12 troy ounces (not 16 ounces, like normal (avoirdupois) pounds)<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Troy_weight" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Troy_weight</a><p>180 avoirdupois pounds is 2,625 ounces troy.  The gold price is around $2470&#x2F;ounce troy today, so $2470*2625 ~= $6.483 million</div><br/></div></div></div></div></div></div></div></div><div id="40983131" class="c"><input type="checkbox" id="c-40983131" checked=""/><div class="controls bullet"><span class="by">radarsat1</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971697">parent</a><span>|</span><a href="#40973513">prev</a><span>|</span><a href="#40971801">next</a><span>|</span><label class="collapse" for="c-40983131">[-]</label><label class="expand" for="c-40983131">[2 more]</label></div><br/><div class="children"><div class="content">Selection bias. I&#x27;m sure there are lots of people who are really good at CUDA and don&#x27;t have those kind of assets. Not everyone knows how to sell their skills.</div><br/><div id="40983324" class="c"><input type="checkbox" id="c-40983324" checked=""/><div class="controls bullet"><span class="by">smallnamespace</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40983131">parent</a><span>|</span><a href="#40971801">next</a><span>|</span><label class="collapse" for="c-40983324">[-]</label><label class="expand" for="c-40983324">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately it&#x27;s also hard to buy (find) people who don&#x27;t know how to sell.</div><br/></div></div></div></div><div id="40971801" class="c"><input type="checkbox" id="c-40971801" checked=""/><div class="controls bullet"><span class="by">bbkane</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971697">parent</a><span>|</span><a href="#40983131">prev</a><span>|</span><a href="#40971879">next</a><span>|</span><label class="collapse" for="c-40971801">[-]</label><label class="expand" for="c-40971801">[21 more]</label></div><br/><div class="children"><div class="content">Would you (or your friend) be able to drop any good CUDA learning resources? I&#x27;d like to be worth my weight in gold...</div><br/><div id="40974120" class="c"><input type="checkbox" id="c-40974120" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971801">parent</a><span>|</span><a href="#40974471">next</a><span>|</span><label class="collapse" for="c-40974120">[-]</label><label class="expand" for="c-40974120">[19 more]</label></div><br/><div class="children"><div class="content">A working knowledge of C++, plus a bit of online reading about CUDA and the NVidia GPU architecture, plus studying the LCZero chess engine source code (the CUDA neural net part, I mean) seems like enough to get started.  I did that and felt like I could contribute to that code, at least at a newbie level, given the hardware and build tools.  At least in the pre-NNUE era, the code was pretty readable.  I didn&#x27;t pursue it though.<p>Of course becoming &quot;really good&quot; is a lot different and like anything else, it presumably takes a lot of callused fingertips (from typing) to get there.</div><br/><div id="40980694" class="c"><input type="checkbox" id="c-40980694" checked=""/><div class="controls bullet"><span class="by">suresk</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974120">parent</a><span>|</span><a href="#40974438">next</a><span>|</span><label class="collapse" for="c-40980694">[-]</label><label class="expand" for="c-40980694">[1 more]</label></div><br/><div class="children"><div class="content">Having dabbled in CUDA, but not worked on it professionally, it feels like a lot of the complexity isn&#x27;t really in CUDA&#x2F;C++, but in the algorithms you have to come up with to really take advantage of the hardware.<p>Optimizing something for SIMD execution isn&#x27;t often straightforward and it isn&#x27;t something a lot of developers encounter outside a few small areas. There are also a lot of hardware architecture considerations you have to work with (memory transfer speed is a big one) to even come close to saturating the compute units.</div><br/></div></div><div id="40974438" class="c"><input type="checkbox" id="c-40974438" checked=""/><div class="controls bullet"><span class="by">mosselman</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974120">parent</a><span>|</span><a href="#40980694">prev</a><span>|</span><a href="#40978172">next</a><span>|</span><label class="collapse" for="c-40974438">[-]</label><label class="expand" for="c-40974438">[9 more]</label></div><br/><div class="children"><div class="content">The real challenge is probably getting your hands on a 4090 for a price you can pay before you are worth your weight in gold. Because an arm and a limb in gold is quite a lot.</div><br/><div id="40974751" class="c"><input type="checkbox" id="c-40974751" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974438">parent</a><span>|</span><a href="#40976373">next</a><span>|</span><label class="collapse" for="c-40974751">[-]</label><label class="expand" for="c-40974751">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t really need a 4090.  An older board is plenty.  The software is basically the same.   I fooled around with what I think was a 1080 on Paperspace for something like 50 cents an hour, but it was mostly with some Pytorch models rather than CUDA directly.</div><br/></div></div><div id="40976373" class="c"><input type="checkbox" id="c-40976373" checked=""/><div class="controls bullet"><span class="by">ahepp</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974438">parent</a><span>|</span><a href="#40974751">prev</a><span>|</span><a href="#40978172">next</a><span>|</span><label class="collapse" for="c-40976373">[-]</label><label class="expand" for="c-40976373">[7 more]</label></div><br/><div class="children"><div class="content">I was looking into this recently and it seems like the cheapest AWS instance with a CUDA GPU is something on the order of $1&#x2F;hr. It looks like an H100 instance might be $15&#x2F;hr (although I’m not sure if I’m looking at a monthly price).<p>So yeah it’s not ideal if you’re on a budget, but it seems like there are some solutions that don’t involve massive capex.</div><br/><div id="40976564" class="c"><input type="checkbox" id="c-40976564" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40976373">parent</a><span>|</span><a href="#40978172">next</a><span>|</span><label class="collapse" for="c-40976564">[-]</label><label class="expand" for="c-40976564">[6 more]</label></div><br/><div class="children"><div class="content">Look on vast.ai instead of AWS, you can rent machines with older GPU&#x27;s dirt cheap.  I don&#x27;t see how they even cover the electricity bills.  A 4090 machine starts at about $.25&#x2F;hour though I didn&#x27;t examine the configuration.<p>A new 4090 costs around $1800 (<a href="https:&#x2F;&#x2F;www.centralcomputer.com&#x2F;asus-tuf-rtx4090-o24g-gaming-asus-tuf-gaming-geforce-rtx-4090-oc-edition-graphics-card-24gb-gddr6x-pci-express-4-0.html" rel="nofollow">https:&#x2F;&#x2F;www.centralcomputer.com&#x2F;asus-tuf-rtx4090-o24g-gaming...</a>) and that&#x27;s probably affordable to AWS users.  I see a 2080Ti on Craigslist for $300 (<a href="https:&#x2F;&#x2F;sfbay.craigslist.org&#x2F;scz&#x2F;sop&#x2F;d&#x2F;aptos-nvidia-geforce-rtx-2080-ti-11gb&#x2F;7764007550.html" rel="nofollow">https:&#x2F;&#x2F;sfbay.craigslist.org&#x2F;scz&#x2F;sop&#x2F;d&#x2F;aptos-nvidia-geforce-...</a>) though used GPU&#x27;s are possibly thrashed by bitcoin mining.  I don&#x27;t have a suitable host machine, unfortunately.</div><br/><div id="40977903" class="c"><input type="checkbox" id="c-40977903" checked=""/><div class="controls bullet"><span class="by">dotancohen</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40976564">parent</a><span>|</span><a href="#40978051">next</a><span>|</span><label class="collapse" for="c-40977903">[-]</label><label class="expand" for="c-40977903">[4 more]</label></div><br/><div class="children"><div class="content">Thrashed? What type of damage could a mostly-solid state device suffer? Fan problems? Worn PCi connectors? Deteriorating Arctic Ice from repeated heat cycling?</div><br/><div id="40980184" class="c"><input type="checkbox" id="c-40980184" checked=""/><div class="controls bullet"><span class="by">mschuster91</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40977903">parent</a><span>|</span><a href="#40979688">next</a><span>|</span><label class="collapse" for="c-40980184">[-]</label><label class="expand" for="c-40980184">[1 more]</label></div><br/><div class="children"><div class="content">Heat. A lot of components - and not just in computers but <i>everything</i> hardware - are spec&#x27;d for something called &quot;duty cycles&quot;, basically how long a thing is active in a specific time frame.<p>Gaming cards&#x2F;rigs, which many of the early miners were based on, rarely run at 100% all the time, the workload is burst-y (and distributed amongst different areas of the system). In comparison, a miner runs at 100% all the time.<p>On top of that, for silicon there is an effect called electromigration [1], where the literal movement of electrons erodes the material over time - made worse by ever shrinking feature sizes as well as, again, the chips being used in exactly the same way all the time.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Electromigration" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Electromigration</a></div><br/></div></div><div id="40979688" class="c"><input type="checkbox" id="c-40979688" checked=""/><div class="controls bullet"><span class="by">ssl-3</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40977903">parent</a><span>|</span><a href="#40980184">prev</a><span>|</span><a href="#40978051">next</a><span>|</span><label class="collapse" for="c-40979688">[-]</label><label class="expand" for="c-40979688">[2 more]</label></div><br/><div class="children"><div class="content">Nope, none of those.<p>When people were mining Ethereum (which was the last craze that GPUs were capable of playing in -- BTC has been off the GPU radar for a long time), profitable mining was fairly kind to cards compared to gaming.<p>Folks wanted their hardware to produce as much as possible, for as little as possible, before it became outdated.<p>The load was constant, so heat cycles weren&#x27;t really a thing.<p>That heat was minimized; cards were clocked (and voltages tweaked) to optimize the ratio of crypto output to Watts input.  For Ethereum, this meant undervolting and underclocking the GPU -- which are kind to it.<p>Fan speeds were kept both moderate and tightly controlled; too fast, and it would cost more (the fans themselves cost money to run, and money to replace).  Too slow, and potential output was left on the table.<p>For Ethereum, RAM got hit hard.  But RAM doesn&#x27;t necessarily care about that; DRAM in general is more or less just an array of solid-state capacitors.  And people needed that RAM to work reliably -- it&#x27;s NFG to spend money producing bad blocks.<p>Power supplies tended to be stable,  because good, cheap, stable, high-current, and stupidly-efficient are qualities that go hand-in-hand thanks to HP server PSUs being cheap like chips.<p>There were exceptions, of course: Some people did not mine smartly.<p>---<p>But this is broadly very different from how gamers treat hardware, wherein: Heat cycles are real, over clocking everything to eek out an extra few FPS is real, pushing things a bit too far and producing glitches can be tolerated sometimes, fan speeds are whatever, and power supplies are picked based on what they <i>look like</i> instead of an actual price&#x2F;performance comparison.<p>A card that was used for mining is not implicitly worse in any way than one that was used for gaming.  Purchasing either thing involves non-zero risk.</div><br/><div id="40981199" class="c"><input type="checkbox" id="c-40981199" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40979688">parent</a><span>|</span><a href="#40978051">next</a><span>|</span><label class="collapse" for="c-40981199">[-]</label><label class="expand" for="c-40981199">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; That heat was minimized; cards were clocked (and voltages tweaked) to optimize the ratio of crypto output to Watts input. For Ethereum, this meant undervolting and underclocking the GPU -- which are kind to it.<p>&gt; Fan speeds were kept both moderate and tightly controlled; too fast, and it would cost more (the fans themselves cost money to run, and money to replace). Too slow, and potential output was left on the table.</i><p>In the ideal case, this is spot on.  Annoyingly however, this hinges on the assumption of an awful lot of competence from top to bottom.<p>If I&#x27;ve learned anything in my considerable career, it&#x27;s that reality is typically one of the first things tossed when situations and goals become complex.<p>The few successful crypto miners <i>maybe did some</i> of the optimizations you mention.  The odds aren&#x27;t good enough for me to want to purchase a Craigslist or FB marketplace card for only a 30% discount.<p>I do genuinely admire your idealism, though.</div><br/></div></div></div></div></div></div><div id="40978051" class="c"><input type="checkbox" id="c-40978051" checked=""/><div class="controls bullet"><span class="by">SonOfLilit</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40976564">parent</a><span>|</span><a href="#40977903">prev</a><span>|</span><a href="#40978172">next</a><span>|</span><label class="collapse" for="c-40978051">[-]</label><label class="expand" for="c-40978051">[1 more]</label></div><br/><div class="children"><div class="content">replying to sibling @dotancohen, they melt, and they suffer from thermal expansion and compression</div><br/></div></div></div></div></div></div></div></div><div id="40978172" class="c"><input type="checkbox" id="c-40978172" checked=""/><div class="controls bullet"><span class="by">robotnikman</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974120">parent</a><span>|</span><a href="#40974438">prev</a><span>|</span><a href="#40974365">next</a><span>|</span><label class="collapse" for="c-40978172">[-]</label><label class="expand" for="c-40978172">[1 more]</label></div><br/><div class="children"><div class="content">Are there any certifications or other ways to prove your knowledge to employers in order to get your foot in the door?</div><br/></div></div><div id="40974365" class="c"><input type="checkbox" id="c-40974365" checked=""/><div class="controls bullet"><span class="by">8n4vidtmkvmk</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974120">parent</a><span>|</span><a href="#40978172">prev</a><span>|</span><a href="#40974471">next</a><span>|</span><label class="collapse" for="c-40974365">[-]</label><label class="expand" for="c-40974365">[7 more]</label></div><br/><div class="children"><div class="content">Does this pay more than $500k&#x2F;yr? I already know C++, could be tempted to learn CUDA.</div><br/><div id="40974736" class="c"><input type="checkbox" id="c-40974736" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974365">parent</a><span>|</span><a href="#40974471">next</a><span>|</span><label class="collapse" for="c-40974736">[-]</label><label class="expand" for="c-40974736">[6 more]</label></div><br/><div class="children"><div class="content">I kinda doubt it.  Nobody paid me to do that though.  I was just interested in LCZero.  To get that $500k&#x2F;year, I think you need up to date ML understanding and not just CUDA.  CUDA is just another programming language while ML is a big area of active research.  You could watch some of the fast.ai ML videos and then enter some Kaggle competitions if you want to go that route.</div><br/><div id="40975960" class="c"><input type="checkbox" id="c-40975960" checked=""/><div class="controls bullet"><span class="by">almostgotcaught</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974736">parent</a><span>|</span><a href="#40974471">next</a><span>|</span><label class="collapse" for="c-40975960">[-]</label><label class="expand" for="c-40975960">[5 more]</label></div><br/><div class="children"><div class="content">You&#x27;re wrong. The people building the models don&#x27;t write CUDA kernels. The people optimizing the models write CUDA kernels. And you don&#x27;t need to know a bunch of ML bs to optimize kernels. Source: I optimize GPU kernels. I don&#x27;t make 500k but I&#x27;m not that far from.</div><br/><div id="40977230" class="c"><input type="checkbox" id="c-40977230" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40975960">parent</a><span>|</span><a href="#40976079">next</a><span>|</span><label class="collapse" for="c-40977230">[-]</label><label class="expand" for="c-40977230">[3 more]</label></div><br/><div class="children"><div class="content">How much performance difference is there between writing a kernel in a high level language&#x2F;framework like PyTorch (torch.compile) or Triton, and hand optimizing? Are you writing kernels in PTX?<p>What&#x27;s your opinion on the future of writing optimized GPU code&#x2F;kernels - how long before compilers are as good or better than (most) humans writing hand-optimized PTX?</div><br/><div id="40980251" class="c"><input type="checkbox" id="c-40980251" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40977230">parent</a><span>|</span><a href="#40980994">prev</a><span>|</span><a href="#40976079">next</a><span>|</span><label class="collapse" for="c-40980251">[-]</label><label class="expand" for="c-40980251">[1 more]</label></div><br/><div class="children"><div class="content">The CUDA version of LCZero was around 2x or 3x faster than the Tensorflow(?) version iirc.</div><br/></div></div></div></div><div id="40976079" class="c"><input type="checkbox" id="c-40976079" checked=""/><div class="controls bullet"><span class="by">throwaway81523</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40975960">parent</a><span>|</span><a href="#40977230">prev</a><span>|</span><a href="#40974471">next</a><span>|</span><label class="collapse" for="c-40976079">[-]</label><label class="expand" for="c-40976079">[1 more]</label></div><br/><div class="children"><div class="content">Heh I&#x27;m in the wrong business then.  Interesting.  Used to be that game programmers spent lots of time optimizing non-ML CUDA code.  They didn&#x27;t make anything like 500k at that time.  I wonder what the ML industry has done to game development, or for that matter to scientific programming.  Wow.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40971879" class="c"><input type="checkbox" id="c-40971879" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971697">parent</a><span>|</span><a href="#40971801">prev</a><span>|</span><a href="#40974461">next</a><span>|</span><label class="collapse" for="c-40971879">[-]</label><label class="expand" for="c-40971879">[3 more]</label></div><br/><div class="children"><div class="content">That’s pretty funny. Good test of value across the millennia. I wonder if the best aqueduct engineers during the peak of Ancient Rome’s power had villas worth their body weight in gold.</div><br/><div id="40972375" class="c"><input type="checkbox" id="c-40972375" checked=""/><div class="controls bullet"><span class="by">Winse</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971879">parent</a><span>|</span><a href="#40974461">next</a><span>|</span><label class="collapse" for="c-40972375">[-]</label><label class="expand" for="c-40972375">[2 more]</label></div><br/><div class="children"><div class="content">Lol. For once being overweight may come with some advantages here.</div><br/><div id="40973967" class="c"><input type="checkbox" id="c-40973967" checked=""/><div class="controls bullet"><span class="by">necovek</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972375">parent</a><span>|</span><a href="#40974461">next</a><span>|</span><label class="collapse" for="c-40973967">[-]</label><label class="expand" for="c-40973967">[1 more]</label></div><br/><div class="children"><div class="content">Or disadvantages: you may be as rich as your skinny neighbour, but they are the only ones worth their weight in gold ;)</div><br/></div></div></div></div></div></div><div id="40974461" class="c"><input type="checkbox" id="c-40974461" checked=""/><div class="controls bullet"><span class="by">iftheshoefitss</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971697">parent</a><span>|</span><a href="#40971879">prev</a><span>|</span><a href="#40975197">next</a><span>|</span><label class="collapse" for="c-40974461">[-]</label><label class="expand" for="c-40974461">[2 more]</label></div><br/><div class="children"><div class="content">What do people study to figure out CUDA? I’m studying to get me GED and hope to go to school one day</div><br/><div id="40978905" class="c"><input type="checkbox" id="c-40978905" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974461">parent</a><span>|</span><a href="#40975197">next</a><span>|</span><label class="collapse" for="c-40978905">[-]</label><label class="expand" for="c-40978905">[1 more]</label></div><br/><div class="children"><div class="content">Computer science. This is a grad level topic probably.<p>Nvidia literally wrote most of the textbooks in this field and you’d probably be taught using one of these anyway:<p><a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;cuda-books-archive" rel="nofollow">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;cuda-books-archive</a><p>“GPGPU Gems” is another “cookbook” sort of textbook that might be helpful starting out but you’ll want a good understanding of the SIMT model etc.</div><br/></div></div></div></div><div id="40975197" class="c"><input type="checkbox" id="c-40975197" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971697">parent</a><span>|</span><a href="#40974461">prev</a><span>|</span><a href="#40976870">next</a><span>|</span><label class="collapse" for="c-40975197">[-]</label><label class="expand" for="c-40975197">[2 more]</label></div><br/><div class="children"><div class="content">Just wait until someone trains an ML model that can translate any CUDA code into something more portable like HIP.<p>GP says it is just some #ifdefs in most cases, so an LLM should be able to do it, right?</div><br/><div id="40976621" class="c"><input type="checkbox" id="c-40976621" checked=""/><div class="controls bullet"><span class="by">FuriouslyAdrift</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40975197">parent</a><span>|</span><a href="#40976870">next</a><span>|</span><label class="collapse" for="c-40976621">[-]</label><label class="expand" for="c-40976621">[1 more]</label></div><br/><div class="children"><div class="content">OpenAI Triton? Pytorch 2.0 already uses it.<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;triton&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;index&#x2F;triton&#x2F;</a></div><br/></div></div></div></div></div></div><div id="40976395" class="c"><input type="checkbox" id="c-40976395" checked=""/><div class="controls bullet"><span class="by">phkahler</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971362">parent</a><span>|</span><a href="#40971697">prev</a><span>|</span><a href="#40972288">next</a><span>|</span><label class="collapse" for="c-40976395">[-]</label><label class="expand" for="c-40976395">[1 more]</label></div><br/><div class="children"><div class="content">&gt;&gt; Don’t most orgs that are deep enough to run custom cuda kernels have dedicated engineers for this stuff. I can’t imagine a person who can write raw cuda not being able to handle things more difficult than pip install.<p>This seems to be fairly common problem with software. The people who create software regularly deal with complex tool chains, dependency management, configuration files, and so on. As a result they think that if a solutions &quot;exists&quot; everything is fine. Need to edit a config file for your particular setup? No problem. The thing is, <i>I</i> have been programming stuff for decades and I really <i>hate</i> having to do that stuff and will avoid tools that make me do it. I have my own problems to solve, and don&#x27;t want to deal with figuring out tools no matter how &quot;simple&quot; the author thinks that is to do.<p>A huge part of the reason commercial software exists today is probably because open source projects don&#x27;t take things to this extreme. I look at some things that qualify as products and think they&#x27;re really simplistic, but they take care of some minutia that regular people are will to pay so they don&#x27;t have to learn or deal with it. The same can be true for developers and ML researchers or whatever.</div><br/></div></div></div></div><div id="40972288" class="c"><input type="checkbox" id="c-40972288" checked=""/><div class="controls bullet"><span class="by">ezekiel68</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971168">parent</a><span>|</span><a href="#40971362">prev</a><span>|</span><a href="#40971390">next</a><span>|</span><label class="collapse" for="c-40972288">[-]</label><label class="expand" for="c-40972288">[5 more]</label></div><br/><div class="children"><div class="content">&gt; if you&#x27;re talking about building anything, that is already too hard for ML researchers.<p>I don&#x27;t think so.  I agree it is too hard for the ML researches at the companies which will have their rear ends handed to them by the other companies whose ML researchers can be bothered to follow a blog post and prompt ChatGPT to resolve error messages.</div><br/><div id="40977091" class="c"><input type="checkbox" id="c-40977091" checked=""/><div class="controls bullet"><span class="by">currymj</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972288">parent</a><span>|</span><a href="#40972780">next</a><span>|</span><label class="collapse" for="c-40977091">[-]</label><label class="expand" for="c-40977091">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not really talking about companies here for the most part, I&#x27;m talking about academic ML researchers (or industry researchers whose role is primarily academic-style research). In companies there is more incentive for good software engineering practices.<p>I&#x27;m also speaking from personal experience: I once had to hand-write my own CUDA kernels (on official NVIDIA cards, not even this weird translation layer): it was useful and I figured it out, but everything was constantly breaking at first.<p>It was a drag on productivity and more importantly, it made it too difficult for other people to run my code (which means they are less likely to cite my work).</div><br/></div></div><div id="40972780" class="c"><input type="checkbox" id="c-40972780" checked=""/><div class="controls bullet"><span class="by">jokethrowaway</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972288">parent</a><span>|</span><a href="#40977091">prev</a><span>|</span><a href="#40971390">next</a><span>|</span><label class="collapse" for="c-40972780">[-]</label><label class="expand" for="c-40972780">[3 more]</label></div><br/><div class="children"><div class="content">a lot of ML researchers stay pretty high level and reinstall conda when things stop working<p>and rightly so, they have more complicated issues to tackle<p>It&#x27;s on developers to provide better infrastructure and solve these challenges</div><br/><div id="40973611" class="c"><input type="checkbox" id="c-40973611" checked=""/><div class="controls bullet"><span class="by">LtWorf</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972780">parent</a><span>|</span><a href="#40971390">next</a><span>|</span><label class="collapse" for="c-40973611">[-]</label><label class="expand" for="c-40973611">[2 more]</label></div><br/><div class="children"><div class="content">Not rightly. It&#x27;d be faster on the long term to address the issues.</div><br/><div id="40973940" class="c"><input type="checkbox" id="c-40973940" checked=""/><div class="controls bullet"><span class="by">bayindirh</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973611">parent</a><span>|</span><a href="#40971390">next</a><span>|</span><label class="collapse" for="c-40973940">[-]</label><label class="expand" for="c-40973940">[1 more]</label></div><br/><div class="children"><div class="content">Currently nobody think that long term. They just reinstall, that’s it.</div><br/></div></div></div></div></div></div></div></div><div id="40971390" class="c"><input type="checkbox" id="c-40971390" checked=""/><div class="controls bullet"><span class="by">jchw</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971168">parent</a><span>|</span><a href="#40972288">prev</a><span>|</span><a href="#40971468">next</a><span>|</span><label class="collapse" for="c-40971390">[-]</label><label class="expand" for="c-40971390">[1 more]</label></div><br/><div class="children"><div class="content">The target audience of interoperability technology is whoever is building, though. Ideally, interoperability technology can help software that supports only NVIDIA GPUs today go on to quickly add baseline support for Intel and AMD GPUs tomorrow.<p>(and for one data point, I believe Blender is actively using HIP for AMD GPU support in Cycles.)</div><br/></div></div><div id="40971468" class="c"><input type="checkbox" id="c-40971468" checked=""/><div class="controls bullet"><span class="by">Agingcoder</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971168">parent</a><span>|</span><a href="#40971390">prev</a><span>|</span><a href="#40973033">next</a><span>|</span><label class="collapse" for="c-40971468">[-]</label><label class="expand" for="c-40971468">[1 more]</label></div><br/><div class="children"><div class="content">Their target is hpc users, not ml researchers. I can understand why this would be valuable to this particular crowd.</div><br/></div></div><div id="40973033" class="c"><input type="checkbox" id="c-40973033" checked=""/><div class="controls bullet"><span class="by">klik99</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971168">parent</a><span>|</span><a href="#40971468">prev</a><span>|</span><a href="#40971932">next</a><span>|</span><label class="collapse" for="c-40973033">[-]</label><label class="expand" for="c-40973033">[1 more]</label></div><br/><div class="children"><div class="content">God this explains so much about my last month, working with tensorflow lite and libtorch in C++</div><br/></div></div></div></div><div id="40971932" class="c"><input type="checkbox" id="c-40971932" checked=""/><div class="controls bullet"><span class="by">SushiHippie</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971093">parent</a><span>|</span><a href="#40971168">prev</a><span>|</span><a href="#40972158">next</a><span>|</span><label class="collapse" for="c-40971932">[-]</label><label class="expand" for="c-40971932">[3 more]</label></div><br/><div class="children"><div class="content">AMD has hipify for this, which converts cuda code to hip.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;ROCm&#x2F;HIPIFY">https:&#x2F;&#x2F;github.com&#x2F;ROCm&#x2F;HIPIFY</a></div><br/><div id="40979387" class="c"><input type="checkbox" id="c-40979387" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971932">parent</a><span>|</span><a href="#40972158">next</a><span>|</span><label class="collapse" for="c-40979387">[-]</label><label class="expand" for="c-40979387">[2 more]</label></div><br/><div class="children"><div class="content">There is more glaring issue, ROCm doesn&#x27;t even work well on most AMD devices nowadays, and hip performance wise deterioriates on the same hardware compared to ROCm.</div><br/><div id="40980679" class="c"><input type="checkbox" id="c-40980679" checked=""/><div class="controls bullet"><span class="by">boroboro4</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40979387">parent</a><span>|</span><a href="#40972158">next</a><span>|</span><label class="collapse" for="c-40980679">[-]</label><label class="expand" for="c-40980679">[1 more]</label></div><br/><div class="children"><div class="content">It supports all of current datacenter GPUs.<p>If you want to write very efficient CUDA kernel for modern datacenter NVIDIA GPU (read H100), you need to write it with having hardware in mind (and preferably in hands, H100 and RTX 4090 behave <i>very</i> differently in practice). So I don&#x27;t think the difference between AMD and NVIDIA is as big as everyone perceives.</div><br/></div></div></div></div></div></div><div id="40972158" class="c"><input type="checkbox" id="c-40972158" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971093">parent</a><span>|</span><a href="#40971932">prev</a><span>|</span><a href="#40973799">next</a><span>|</span><label class="collapse" for="c-40972158">[-]</label><label class="expand" for="c-40972158">[6 more]</label></div><br/><div class="children"><div class="content">Inline PTX is hardly an obscure feature. It&#x27;s pretty widely used in practice, at least in the AI space.</div><br/><div id="40972750" class="c"><input type="checkbox" id="c-40972750" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972158">parent</a><span>|</span><a href="#40973799">next</a><span>|</span><label class="collapse" for="c-40972750">[-]</label><label class="expand" for="c-40972750">[5 more]</label></div><br/><div class="children"><div class="content">Yeah, a lot of the newer accelerators are not even available without using inline PTX assembly. Even the ones that are have weird shapes that are not amenable to high-performance work.</div><br/><div id="40976859" class="c"><input type="checkbox" id="c-40976859" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972750">parent</a><span>|</span><a href="#40973799">next</a><span>|</span><label class="collapse" for="c-40976859">[-]</label><label class="expand" for="c-40976859">[4 more]</label></div><br/><div class="children"><div class="content">Are you saying that the latest NVIDIA nvcc doesn&#x27;t support the latest NVIDIA devices?</div><br/><div id="40977266" class="c"><input type="checkbox" id="c-40977266" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40976859">parent</a><span>|</span><a href="#40973799">next</a><span>|</span><label class="collapse" for="c-40977266">[-]</label><label class="expand" for="c-40977266">[3 more]</label></div><br/><div class="children"><div class="content">For any compiler, &quot;supporting&quot; a certain CPU or GPU only means that they can generate correct translated code with that CPU or GPU as the execution target.<p>It does not mean that the compiler is able to generate code that has optimal performance, when that can be achieved by using certain instructions without a direct equivalent in a high-level language.<p>No compiler that supports the Intel-AMD ISA knows how to use all the instructions available in this ISA.</div><br/><div id="40977394" class="c"><input type="checkbox" id="c-40977394" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40977266">parent</a><span>|</span><a href="#40973799">next</a><span>|</span><label class="collapse" for="c-40977394">[-]</label><label class="expand" for="c-40977394">[2 more]</label></div><br/><div class="children"><div class="content">Sure, but I&#x27;m not sure if that is what the parent poster was saying (that nvcc generates poor quality PTX for newer devices).<p>It&#x27;s been a while since I looked at CUDA, but it used to be that NVIDIA were continually extending cuDNN to add support for kernels needed by SOTA models, and I assume these kernels were all hand optimized.<p>I&#x27;m curious what kind of models people are writing where not only is there is no optimized cuDNN support, but also solutions like Triton or torch.compile, and even hand optimized CUDA C kernels are too slow. Are hand written PTX kernels really that common ?</div><br/><div id="40983468" class="c"><input type="checkbox" id="c-40983468" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40977394">parent</a><span>|</span><a href="#40973799">next</a><span>|</span><label class="collapse" for="c-40983468">[-]</label><label class="expand" for="c-40983468">[1 more]</label></div><br/><div class="children"><div class="content">Yes. Take a look at, say, CUTLASS: you&#x27;ll see that they use PTX instructions because there are no intrinsics, much less automatic compiler lowering, for the accelerators they target.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40973799" class="c"><input type="checkbox" id="c-40973799" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971093">parent</a><span>|</span><a href="#40972158">prev</a><span>|</span><a href="#40971026">next</a><span>|</span><label class="collapse" for="c-40973799">[-]</label><label class="expand" for="c-40973799">[1 more]</label></div><br/><div class="children"><div class="content">How does it run CUDA Fortran?</div><br/></div></div></div></div><div id="40971026" class="c"><input type="checkbox" id="c-40971026" checked=""/><div class="controls bullet"><span class="by">blitzar</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40971093">prev</a><span>|</span><a href="#40970930">next</a><span>|</span><label class="collapse" for="c-40971026">[-]</label><label class="expand" for="c-40971026">[43 more]</label></div><br/><div class="children"><div class="content">It would be good if AMD did something, anything.<p>Support this, reimplement that, support upstream efforts, dont really care. Any of those would cost a couple of million and be worth a trillion dollars to AMD shareholders.</div><br/><div id="40972439" class="c"><input type="checkbox" id="c-40972439" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971026">parent</a><span>|</span><a href="#40971676">next</a><span>|</span><label class="collapse" for="c-40972439">[-]</label><label class="expand" for="c-40972439">[23 more]</label></div><br/><div class="children"><div class="content">Is it weird how the comments here are blaming AMD and not Nvidia? Sure, the obvious argument is that Nvidia has no practical motivation to build an open platform. But there are counterexamples that suggest otherwise (Android). And there is a compelling argument that long term, their proprietary firmware layer will become an insufficient moat to their hardware dominance.<p>Who’s the root cause? The company with the dominant platform that refuses to open it up, or the competitor who can’t catch up because they’re running so far behind? Even if AMD made their own version of CUDA that was better in every way, it still wouldn’t gain adoption because CUDA has become the standard. No matter what they do, they’ll need to have a compatibility layer. And in that case maybe it makes sense for them to invest in the  best one that emerges from the community.</div><br/><div id="40972728" class="c"><input type="checkbox" id="c-40972728" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972439">parent</a><span>|</span><a href="#40973572">next</a><span>|</span><label class="collapse" for="c-40972728">[-]</label><label class="expand" for="c-40972728">[8 more]</label></div><br/><div class="children"><div class="content">&gt; Is it weird how the comments here are blaming AMD and not Nvidia?<p>Nvidia has put in the legwork and are reaping the rewards. They&#x27;ve worked closely with the people who are actually using their stuff, funding development and giving loads of support to researchers, teachers and so on, for probably a decade now. Why should they give all that away?<p>&gt; But there are counterexamples that suggest otherwise (Android).<p>How is Android a counterexample? Google makes no money off of it, nor does anyone else. Google keeps Android open so that Apple can&#x27;t move everyone onto their ad platform, so it&#x27;s worth it for them as a strategic move, but Nvidia has no such motive.<p>&gt; Even if AMD made their own version of CUDA that was better in every way, it still wouldn’t gain adoption because CUDA has become the standard.<p>Maybe. But again, that&#x27;s because NVidia has been putting in the work to make something better for a decade or more. The best time for AMD to start actually trying was 10 years ago; the second-best time is today.</div><br/><div id="40977404" class="c"><input type="checkbox" id="c-40977404" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972728">parent</a><span>|</span><a href="#40973572">next</a><span>|</span><label class="collapse" for="c-40977404">[-]</label><label class="expand" for="c-40977404">[7 more]</label></div><br/><div class="children"><div class="content">&gt; Google makes no money off of it, nor does anyone else<p>Google makes no money off of Android? That seems like a really weird claim to make. Do you really think Google would be anywhere near as valuable of a company if iOS had all of the market share that the data vacuum that is Android has? I can&#x27;t imagine that being the case.<p>Google makes a boatload off of Android, just like AMD would if they supported open GPGPU efforts aggressively.</div><br/><div id="40979131" class="c"><input type="checkbox" id="c-40979131" checked=""/><div class="controls bullet"><span class="by">rjurney</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40977404">parent</a><span>|</span><a href="#40978424">next</a><span>|</span><label class="collapse" for="c-40979131">[-]</label><label class="expand" for="c-40979131">[5 more]</label></div><br/><div class="children"><div class="content">Android is a complement to Google&#x27;s business, which is when open source works. What would be the complement worth $1 Trillion to NVIDIA to build a truly open platform? There isn&#x27;t one. That was his point.</div><br/><div id="40980017" class="c"><input type="checkbox" id="c-40980017" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40979131">parent</a><span>|</span><a href="#40978424">next</a><span>|</span><label class="collapse" for="c-40980017">[-]</label><label class="expand" for="c-40980017">[4 more]</label></div><br/><div class="children"><div class="content">There’s an entire derivative industry of GPUs, namely GenAI and LLM providers, that could be the “complement” to an open GPU platform. The exact design and interface between such a complement and platform is yet undefined, but I’m sure there are creative approaches to this problem.</div><br/><div id="40980260" class="c"><input type="checkbox" id="c-40980260" checked=""/><div class="controls bullet"><span class="by">rjurney</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40980017">parent</a><span>|</span><a href="#40978424">next</a><span>|</span><label class="collapse" for="c-40980260">[-]</label><label class="expand" for="c-40980260">[3 more]</label></div><br/><div class="children"><div class="content">And NVIDIA is playing in that game too. Why would they not play in higher level services as well? They already publish the source to their entire software stack. A comparison to Android is completely useless. Google is a multi-sided platform that does lots of things for free for some people (web users, Android users) so it can charge other people for their data (ad buyers). That isn&#x27;t the chip business whatsoever. The original comment only makes sense if you know nothing about their respective business models.</div><br/><div id="40980698" class="c"><input type="checkbox" id="c-40980698" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40980260">parent</a><span>|</span><a href="#40978424">next</a><span>|</span><label class="collapse" for="c-40980698">[-]</label><label class="expand" for="c-40980698">[2 more]</label></div><br/><div class="children"><div class="content">Yes, so when the ground inevitably shifts below their feet (it might happen years from now, but it <i>will</i> happen – open platforms always emerge and eventually proliferate), wouldn’t it be better for them to own that platform?<p>On the other hand, they could always wait for the most viable threat to emerge and then pay a few billion dollars to acquire it and own its direction. Google didn’t invent Android, after all…<p>&gt; Google is a multi-sided platform that does lots of things for free for some people… That isn&#x27;t the chip business whatsoever.<p>This is a reductionist differentiation that overlooks the similarities between the platforms of “mobile” and “GPU” (and also mischaracterizes the business model of Google, who does in fact make money directly from Android sales, and even moved all the way down the stack to selling hardware). In fact there is even a potentially direct analogy between the two platforms: LLM is the top of the stack with GPU on the bottom, just like Advertising is the top of the stack with Mobile on the bottom.<p>Yes, Google’s top level money printer is advertising, and everything they do (including Android) is about controlling the maximum number of layers below that money printer. But that doesn’t mean there is no benefit to Nvidia doing the same. They might approach it differently, since they currently own the bottom layer whereas Google started from the top layer. But the end result of controlling the whole stack will lead to the same benefits.<p>And you even admit in your comment that Nvidia is investing in these higher levels. My argument is that they are jeopardizing the longevity of these high-level investments due to their reluctance to invest in an open platform at the bottom layer (not even the bottom, but one level above their hardware). This will leave them vulnerable to encroachment by a player that comes from a higher level, like OpenAI for example, who gets to define the open platform before Nvidia ever has a chance to own it.</div><br/><div id="40981466" class="c"><input type="checkbox" id="c-40981466" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40980698">parent</a><span>|</span><a href="#40978424">next</a><span>|</span><label class="collapse" for="c-40981466">[-]</label><label class="expand" for="c-40981466">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it might happen years from now, but it will happen – open platforms always emerge and eventually proliferate<p>30 years ago people were making the same argument that MS should have kept DirectX open or else they were going to lose to OpenGL. Look how that&#x27;s worked out for them.<p>&gt; Google, who does in fact make money directly from Android sales<p>They don&#x27;t though. They have some amount of revenue from it, but it&#x27;s a loss-making operation.<p>&gt; In fact there is even a potentially direct analogy between the two platforms: LLM is the top of the stack with GPU on the bottom, just like Advertising is the top of the stack with Mobile on the bottom.<p>But which layer is the differentiator, and which layer is just commodity? Google gives away Android because it isn&#x27;t better than iOS and isn&#x27;t trying to be; &quot;good enough&quot; is fine for their business (if anything, being open is a way to stay relevant where they would otherwise fall behind). They don&#x27;t give away the ad-tech, nor would they open up e.g. Maps data where they have a competitive advantage.<p>NVidia has no reason to open up CUDA; they have nothing to gain and a lot to lose by doing so. They make a lot of their money from hardware sales which they would open up to cannibalisation, and CUDA is already the industry standard that everyone builds on and stays compatible with. If there was ever a real competitive threat then that might change, but AMD has a long way to go to get there.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40978424" class="c"><input type="checkbox" id="c-40978424" checked=""/><div class="controls bullet"><span class="by">michaelt</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40977404">parent</a><span>|</span><a href="#40979131">prev</a><span>|</span><a href="#40973572">next</a><span>|</span><label class="collapse" for="c-40978424">[-]</label><label class="expand" for="c-40978424">[1 more]</label></div><br/><div class="children"><div class="content">Google gave away the software platform - Android - to hardware vendors for free, vendors compete making the hardware into cheap, low-margin commodity items, and google makes boatloads of money from ads, tracking and the app store.<p>nvidia <i>could</i> give away the software platform - CUDA - to hardware vendors for free, making the hardware into cheap, low-margin commodity items. But how would they make boatloads of money when there&#x27;s nowhere to put ads, tracking or an app store?</div><br/></div></div></div></div></div></div><div id="40973572" class="c"><input type="checkbox" id="c-40973572" checked=""/><div class="controls bullet"><span class="by">nemothekid</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972439">parent</a><span>|</span><a href="#40972728">prev</a><span>|</span><a href="#40973816">next</a><span>|</span><label class="collapse" for="c-40973572">[-]</label><label class="expand" for="c-40973572">[1 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Is it weird how the comments here are blaming AMD and not Nvidia?</i><p>It&#x27;s not. Even as it is, I do not trust HIP or RocM to be a viable alternative to Cuda. George Hotz did plenty of work trying to port various ML architectures to AMD and was met with countless driver bugs. The problem isn&#x27;t nvidia won&#x27;t build an open platform - the problem is AMD won&#x27;t invest in a competitive platform. 99% of ML engineers do not write CUDA. For the vast majority of workloads, there are probably 20 engineers at Meta who write the Cuda backend for Pytorch that every other engineer uses. Meta could hire another 20 engineers to support whatever AMD has (they did, and it&#x27;s not as robust as CUDA).<p>Even if CUDA was open - do you expect nvidia to also write drivers for AMD? I don&#x27;t believe 3rd parties will get anywhere writing &quot;compatibility layers&quot; because AMD&#x27;s own GPU aren&#x27;t optimized or tested for CUDA-like workloads.</div><br/></div></div><div id="40973816" class="c"><input type="checkbox" id="c-40973816" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972439">parent</a><span>|</span><a href="#40973572">prev</a><span>|</span><a href="#40972796">next</a><span>|</span><label class="collapse" for="c-40973816">[-]</label><label class="expand" for="c-40973816">[1 more]</label></div><br/><div class="children"><div class="content">Khrons, AMD and Intel have had 15 years to make something out of OpenCL that could rival CUDA.<p>Instead they managed 15 years of disappointment, in a standard stuck in C99, that adopted C++ and a polyglot bytecode too late to matter, never produced an ecosystem of IDE tooling and GPU libraries.<p>Naturally CUDA became the standard, when NVIDIA provided what the GPU community cared about.</div><br/></div></div><div id="40972796" class="c"><input type="checkbox" id="c-40972796" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972439">parent</a><span>|</span><a href="#40973816">prev</a><span>|</span><a href="#40975615">next</a><span>|</span><label class="collapse" for="c-40972796">[-]</label><label class="expand" for="c-40972796">[9 more]</label></div><br/><div class="children"><div class="content">&gt; Is it weird how the comments here are blaming AMD and not Nvidia?<p>Not even a little bit. It simply isn&#x27;t Nvidia&#x27;s job to provide competitive alternatives to Nvidia. Competing is something AMD must take responsibility for.<p>The only reason CUDA is such a big talking point is because AMD tripped over their own feet supporting accelerated BLAS on AMD GPUs. Realistically it probably is hard to implement (AMD have a lot of competent people on staff) but Nvidia hasn&#x27;t done anything unfair apart from execute so well that they make all the alternatives look bad.</div><br/><div id="40973208" class="c"><input type="checkbox" id="c-40973208" checked=""/><div class="controls bullet"><span class="by">jkmcf</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972796">parent</a><span>|</span><a href="#40975615">next</a><span>|</span><label class="collapse" for="c-40973208">[-]</label><label class="expand" for="c-40973208">[8 more]</label></div><br/><div class="children"><div class="content">I agree with you, but replace NVIDIA with Apple. What would the EU say?</div><br/><div id="40973620" class="c"><input type="checkbox" id="c-40973620" checked=""/><div class="controls bullet"><span class="by">LtWorf</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973208">parent</a><span>|</span><a href="#40975615">next</a><span>|</span><label class="collapse" for="c-40973620">[-]</label><label class="expand" for="c-40973620">[7 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think nvidia bans anyone from running code on their devices.</div><br/><div id="40977469" class="c"><input type="checkbox" id="c-40977469" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973620">parent</a><span>|</span><a href="#40974044">next</a><span>|</span><label class="collapse" for="c-40977469">[-]</label><label class="expand" for="c-40977469">[3 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.pcgamer.com&#x2F;nvidia-officially-confirms-hash-rate-limiter-for-graphics-cards-shipping-from-mid-may&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.pcgamer.com&#x2F;nvidia-officially-confirms-hash-rate...</a><p>Also: look into why the Nouveau driver performance is limited.</div><br/><div id="40978985" class="c"><input type="checkbox" id="c-40978985" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40977469">parent</a><span>|</span><a href="#40974044">next</a><span>|</span><label class="collapse" for="c-40978985">[-]</label><label class="expand" for="c-40978985">[2 more]</label></div><br/><div class="children"><div class="content">so terrible that vendors can enforce these proprietary licenses on software they paid to develop &#x2F;s</div><br/><div id="40979409" class="c"><input type="checkbox" id="c-40979409" checked=""/><div class="controls bullet"><span class="by">Zambyte</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40978985">parent</a><span>|</span><a href="#40974044">next</a><span>|</span><label class="collapse" for="c-40979409">[-]</label><label class="expand" for="c-40979409">[1 more]</label></div><br/><div class="children"><div class="content">Huh? Why the sarcasm? You think it&#x27;s a good thing that someone besides the person who owns the hardware has the final say on what the hardware is allowed to be used for?</div><br/></div></div></div></div></div></div><div id="40974044" class="c"><input type="checkbox" id="c-40974044" checked=""/><div class="controls bullet"><span class="by">padthai</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973620">parent</a><span>|</span><a href="#40977469">prev</a><span>|</span><a href="#40975615">next</a><span>|</span><label class="collapse" for="c-40974044">[-]</label><label class="expand" for="c-40974044">[3 more]</label></div><br/><div class="children"><div class="content">They do from time to time: <a href="https:&#x2F;&#x2F;wirelesswire.jp&#x2F;2017&#x2F;12&#x2F;62708&#x2F;" rel="nofollow">https:&#x2F;&#x2F;wirelesswire.jp&#x2F;2017&#x2F;12&#x2F;62708&#x2F;</a></div><br/><div id="40976691" class="c"><input type="checkbox" id="c-40976691" checked=""/><div class="controls bullet"><span class="by">kbolino</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974044">parent</a><span>|</span><a href="#40975615">next</a><span>|</span><label class="collapse" for="c-40976691">[-]</label><label class="expand" for="c-40976691">[2 more]</label></div><br/><div class="children"><div class="content">This seems to be more about certain devices (consumer-grade GPUs) in certain settings (data centers), though I do question how enforceable it actually is. My guess is that it can only apply when you try to get discounts from bulk-ordering GPUs.<p>Also, was there any followup to this story? It seems a bit unnecessary because nVidia has already neutered consumer cards for many&#x2F;most data center purposes by not using ECC and by providing so few FP64 units that double precision FLOPS is barely better than CPU SIMD.</div><br/><div id="40979003" class="c"><input type="checkbox" id="c-40979003" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40976691">parent</a><span>|</span><a href="#40975615">next</a><span>|</span><label class="collapse" for="c-40979003">[-]</label><label class="expand" for="c-40979003">[1 more]</label></div><br/><div class="children"><div class="content">it’s also not really a thing anymore because of the open kernel driver… at that point it’s just MIT licensed.<p>of course people continued to melt down about that for some reason too, in the customary “nothing is ever libre enough!” circular firing squad. Just like streamline etc.<p>There’s a really shitty strain of fanboy thought that wants libre software to be actively worsened (even stonewalled by the kernel team if necessary) so that they can continue to argue against nvidia as a bad actor that doesn’t play nicely with open source. You saw it with all these things but especially with the open kernel driver, people were really happy it didn’t get upstreamed. Shitty behavior all around.<p>You see it every time someone quotes Linus Torvalds on the issue. Some slight from 2006 is more important than users having good, open drivers upstreamed. Some petty brand preferences are legitimately far important than working with and bringing that vendor into the fold long-term, <i>for a large number of people</i>. Most of whom don’t even consider themselves fanboys! They just say all the things a fanboy would say, and act all the ways a fanboy would act…</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40975615" class="c"><input type="checkbox" id="c-40975615" checked=""/><div class="controls bullet"><span class="by">whywhywhywhy</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972439">parent</a><span>|</span><a href="#40972796">prev</a><span>|</span><a href="#40977699">next</a><span>|</span><label class="collapse" for="c-40975615">[-]</label><label class="expand" for="c-40975615">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Is it weird how the comments here are blaming AMD and not Nvidia?<p>Because it IS AMD&#x2F;Apple&#x2F;etcs fault for the position they&#x27;re in right now. CUDA showed where the world was heading and where the gains in compute would be made well over a decade ago now.<p>They even had OpenCL, didn&#x27;t put the right amount of effort into it, all the talent found CUDA easier to work with so built there. Then what did AMD, Apple do? Double down and try and make something better and compete? Nah they fragmented and went their own way, AMD with what feels like a fraction of the effort even Apple put in.<p>From the actions of the other teams in the game it&#x27;s not hard to imagine a world without CUDA being a world where this tech is running at a fraction of it&#x27;s potential.</div><br/></div></div><div id="40977699" class="c"><input type="checkbox" id="c-40977699" checked=""/><div class="controls bullet"><span class="by">cogman10</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972439">parent</a><span>|</span><a href="#40975615">prev</a><span>|</span><a href="#40975683">next</a><span>|</span><label class="collapse" for="c-40977699">[-]</label><label class="expand" for="c-40977699">[1 more]</label></div><br/><div class="children"><div class="content">Funnily, who I blame the most for there not being real competition to CUDA is apple.  As of late, Apple has been really pushing for vender lock in APIs rather than adopting open standards.  The end result is you can get AMD and Intel onboard with some standard which is ultimately torpedoed by apple.  (See apple departing from and rejecting everything that comes from the khronos group).<p>With the number of devs that use Apple silicon now-a-days, I have to think that their support for khronos initiatives like SYCL and OpenCL would have significantly accelerated progress and adoption in both.<p>We need an open standard that isn&#x27;t just AMD specific to be successful in toppling CUDA.</div><br/></div></div><div id="40975683" class="c"><input type="checkbox" id="c-40975683" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972439">parent</a><span>|</span><a href="#40977699">prev</a><span>|</span><a href="#40971676">next</a><span>|</span><label class="collapse" for="c-40975683">[-]</label><label class="expand" for="c-40975683">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s always been on the straggler to catch up by cheating. That&#x27;s just how the world works - even in open source. If AMD supported CUDA, it would have a bigger market share. That&#x27;s a fact. Nvidia doesn&#x27;t want that. That&#x27;s a fact. But when Reddit started, it just scraped feeds from Digg, and when Facebook started, it let you link your MySpace credentials and scraped your MySpace account. Adversarial interoperability is nothing new.</div><br/></div></div></div></div><div id="40971676" class="c"><input type="checkbox" id="c-40971676" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971026">parent</a><span>|</span><a href="#40972439">prev</a><span>|</span><a href="#40971502">next</a><span>|</span><label class="collapse" for="c-40971676">[-]</label><label class="expand" for="c-40971676">[16 more]</label></div><br/><div class="children"><div class="content">ROCm counts as &quot;something&quot;</div><br/><div id="40971906" class="c"><input type="checkbox" id="c-40971906" checked=""/><div class="controls bullet"><span class="by">curt15</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971676">parent</a><span>|</span><a href="#40971502">next</a><span>|</span><label class="collapse" for="c-40971906">[-]</label><label class="expand" for="c-40971906">[15 more]</label></div><br/><div class="children"><div class="content">Pretty much any modern NVIDIA GPU supports CUDA. You don&#x27;t have to buy a datacenter-class unit to get your feet wet with CUDA programming. ROCm will count as &quot;something&quot; when the same is true for AMD GPUs.</div><br/><div id="40972293" class="c"><input type="checkbox" id="c-40972293" checked=""/><div class="controls bullet"><span class="by">jacoblambda</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971906">parent</a><span>|</span><a href="#40972033">next</a><span>|</span><label class="collapse" for="c-40972293">[-]</label><label class="expand" for="c-40972293">[2 more]</label></div><br/><div class="children"><div class="content">ROCm supports current gen consumer gpus officially and a decent chunk of recent gen consumer gpus unofficially. Not all of them of course but a decent chunk.<p>It&#x27;s not ideal but I&#x27;m pretty sure CUDA didn&#x27;t support everything from day 1. And ROCm is part of AMD&#x27;s vendor part of the Windows AI stack so from upcoming gen on out basically anything that outputs video should support ROCm.</div><br/><div id="40974121" class="c"><input type="checkbox" id="c-40974121" checked=""/><div class="controls bullet"><span class="by">ChoGGi</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972293">parent</a><span>|</span><a href="#40972033">next</a><span>|</span><label class="collapse" for="c-40974121">[-]</label><label class="expand" for="c-40974121">[1 more]</label></div><br/><div class="children"><div class="content">No, but CUDA at least supported the 8800 gt on release [1]. ROCm didn&#x27;t support any consumer cards on release, looks like they didn&#x27;t support any till last year? [2]<p>[1]<a href="https:&#x2F;&#x2F;www.gamesindustry.biz&#x2F;nvidia-unveils-cuda-the-gpu-computing-revolution-begins" rel="nofollow">https:&#x2F;&#x2F;www.gamesindustry.biz&#x2F;nvidia-unveils-cuda-the-gpu-co...</a><p>[2]<a href="https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;amd-rocm-comes-to-windows-on-consumer-gpus" rel="nofollow">https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;amd-rocm-comes-to-windows-...</a></div><br/></div></div></div></div><div id="40972033" class="c"><input type="checkbox" id="c-40972033" checked=""/><div class="controls bullet"><span class="by">muxr</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971906">parent</a><span>|</span><a href="#40972293">prev</a><span>|</span><a href="#40972591">next</a><span>|</span><label class="collapse" for="c-40972033">[-]</label><label class="expand" for="c-40972033">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think AMD needs to support 5+ year old GPUs personally. And all the recent generations are already practically supported.<p>AMD only claims support for a select few GPUs, but in my testing I find all the GPUs work fine if the architecture is supported. I&#x27;ve tested rx6600, rx6700xt for example and even though they aren&#x27;t officially supported, they work fine on ROCm.</div><br/><div id="40973186" class="c"><input type="checkbox" id="c-40973186" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972033">parent</a><span>|</span><a href="#40974529">next</a><span>|</span><label class="collapse" for="c-40973186">[-]</label><label class="expand" for="c-40973186">[1 more]</label></div><br/><div class="children"><div class="content">&gt; 5+ year old GPUs<p>AMD had a big architecture switchover <i>exactly</i> 5 years ago, and the full launch wasn&#x27;t over until 4.5 years ago.  I think that generation <i>should</i> have full support.  Especially because it&#x27;s not like they&#x27;re cutting support now.  They didn&#x27;t support it at launch, and they didn&#x27;t support it after 1, 2, 3, 4 years either.<p>The other way to look at things, I&#x27;d say that for a mid to high tier GPU to be obsolete based on performance, the replacement model needs to be over twice as fast.  7700XT is just over 50% faster than 5700XT.</div><br/></div></div><div id="40974529" class="c"><input type="checkbox" id="c-40974529" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972033">parent</a><span>|</span><a href="#40973186">prev</a><span>|</span><a href="#40972591">next</a><span>|</span><label class="collapse" for="c-40974529">[-]</label><label class="expand" for="c-40974529">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m on a 5+ year old GPU, because I don&#x27;t trust AMD to offer a compelling GPU that actually works. An RX 7 570 is good enough for the little gaming I do. It mostly acts as an oversized iGPU that has good Linux drivers, but since AMD is not supporting ROCm on this GPU, there is no need to hurry on upgrading to a better GPU or to get my feet wet on running things locally on the GPU like Stable Diffusion, LLMs, etc.</div><br/></div></div></div></div><div id="40972591" class="c"><input type="checkbox" id="c-40972591" checked=""/><div class="controls bullet"><span class="by">squidgyhead</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971906">parent</a><span>|</span><a href="#40972033">prev</a><span>|</span><a href="#40978725">next</a><span>|</span><label class="collapse" for="c-40972591">[-]</label><label class="expand" for="c-40972591">[7 more]</label></div><br/><div class="children"><div class="content">Here is the support list:<p><a href="https:&#x2F;&#x2F;rocm.docs.amd.com&#x2F;projects&#x2F;install-on-linux&#x2F;en&#x2F;latest&#x2F;reference&#x2F;system-requirements.html" rel="nofollow">https:&#x2F;&#x2F;rocm.docs.amd.com&#x2F;projects&#x2F;install-on-linux&#x2F;en&#x2F;lates...</a></div><br/><div id="40972822" class="c"><input type="checkbox" id="c-40972822" checked=""/><div class="controls bullet"><span class="by">mappu</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972591">parent</a><span>|</span><a href="#40978725">next</a><span>|</span><label class="collapse" for="c-40972822">[-]</label><label class="expand" for="c-40972822">[6 more]</label></div><br/><div class="children"><div class="content">AMD&#x27;s definition of &quot;support&quot; I think is different than what people expect, and pretty misleading - ROCm itself will run on almost anything, back as far as the RX 400&#x2F;500 series:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ROCm#:~:text=GCN%205%20%2D%20Vega).-,Consumer%2Dgrade%20GPUs,-%5Bedit%5D" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ROCm#:~:text=GCN%205%20%2D%20V...</a><p>Stable Diffusion ran fine for me on RX 570 and RX 6600XT with nothing but distro packages.</div><br/><div id="40978762" class="c"><input type="checkbox" id="c-40978762" checked=""/><div class="controls bullet"><span class="by">slavik81</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972822">parent</a><span>|</span><a href="#40974728">next</a><span>|</span><label class="collapse" for="c-40978762">[-]</label><label class="expand" for="c-40978762">[1 more]</label></div><br/><div class="children"><div class="content">There are out-of-bounds writes in the BLAS libraries for gfx803 GPUs (such as the RX 570). That hardware might work fine for your use case, but there&#x27;s a lot of failures in the test suites.<p>I agree that the official support list is very conservative, but I wouldn&#x27;t recommend pre-Vega GPUs for use with ROCm. Stick to gfx900 and newer, if you can.</div><br/></div></div><div id="40974728" class="c"><input type="checkbox" id="c-40974728" checked=""/><div class="controls bullet"><span class="by">Nab443</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972822">parent</a><span>|</span><a href="#40978762">prev</a><span>|</span><a href="#40974541">next</a><span>|</span><label class="collapse" for="c-40974728">[-]</label><label class="expand" for="c-40974728">[3 more]</label></div><br/><div class="children"><div class="content">The last time I checked, I was stuck with a pretty old kernel if I wanted to have the last version of ROCm available for my rx470. It&#x27;s compatible at some point in time, but not kept compatible with recent kernels.</div><br/><div id="40980763" class="c"><input type="checkbox" id="c-40980763" checked=""/><div class="controls bullet"><span class="by">mappu</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974728">parent</a><span>|</span><a href="#40978938">prev</a><span>|</span><a href="#40974541">next</a><span>|</span><label class="collapse" for="c-40980763">[-]</label><label class="expand" for="c-40980763">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the responsibility of your distro to ship things that work together,</div><br/></div></div></div></div><div id="40974541" class="c"><input type="checkbox" id="c-40974541" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972822">parent</a><span>|</span><a href="#40974728">prev</a><span>|</span><a href="#40978725">next</a><span>|</span><label class="collapse" for="c-40974541">[-]</label><label class="expand" for="c-40974541">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t buy it. Even running things like llama.cpp on my RX 570 via Vulkan crashes the entire system.</div><br/></div></div></div></div></div></div><div id="40978725" class="c"><input type="checkbox" id="c-40978725" checked=""/><div class="controls bullet"><span class="by">slashdave</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971906">parent</a><span>|</span><a href="#40972591">prev</a><span>|</span><a href="#40977586">next</a><span>|</span><label class="collapse" for="c-40978725">[-]</label><label class="expand" for="c-40978725">[1 more]</label></div><br/><div class="children"><div class="content">AMD should focus their efforts on competitive hardware offerings, because that is where the need and the money is. Sorry, I don&#x27;t think the hobbyist should be a priority.</div><br/></div></div><div id="40977586" class="c"><input type="checkbox" id="c-40977586" checked=""/><div class="controls bullet"><span class="by">bavell</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971906">parent</a><span>|</span><a href="#40978725">prev</a><span>|</span><a href="#40971502">next</a><span>|</span><label class="collapse" for="c-40977586">[-]</label><label class="expand" for="c-40977586">[1 more]</label></div><br/><div class="children"><div class="content">Huh? I&#x27;ve been running ROCm for SD and LLMs for over a year and a half on my puny consumer 6750X - not even latest gen.</div><br/></div></div></div></div></div></div><div id="40971502" class="c"><input type="checkbox" id="c-40971502" checked=""/><div class="controls bullet"><span class="by">oezi</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971026">parent</a><span>|</span><a href="#40971676">prev</a><span>|</span><a href="#40970930">next</a><span>|</span><label class="collapse" for="c-40971502">[-]</label><label class="expand" for="c-40971502">[3 more]</label></div><br/><div class="children"><div class="content">A couple of million doesn&#x27;t get you anything in corporate land</div><br/><div id="40971900" class="c"><input type="checkbox" id="c-40971900" checked=""/><div class="controls bullet"><span class="by">spacebanana7</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971502">parent</a><span>|</span><a href="#40970930">next</a><span>|</span><label class="collapse" for="c-40971900">[-]</label><label class="expand" for="c-40971900">[2 more]</label></div><br/><div class="children"><div class="content">A couple dozen billion for a 10% chance of becoming NVIDIA competitive is worth it, looking at the stock prices.</div><br/><div id="40979588" class="c"><input type="checkbox" id="c-40979588" checked=""/><div class="controls bullet"><span class="by">oezi</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971900">parent</a><span>|</span><a href="#40970930">next</a><span>|</span><label class="collapse" for="c-40979588">[-]</label><label class="expand" for="c-40979588">[1 more]</label></div><br/><div class="children"><div class="content">Billions. Now we are talking.</div><br/></div></div></div></div></div></div></div></div><div id="40970930" class="c"><input type="checkbox" id="c-40970930" checked=""/><div class="controls bullet"><span class="by">fngjdflmdflg</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40971026">prev</a><span>|</span><a href="#40973277">next</a><span>|</span><label class="collapse" for="c-40970930">[-]</label><label class="expand" for="c-40970930">[6 more]</label></div><br/><div class="children"><div class="content">&gt;Nvidia can make things arbitrarily difficult both technically and legally.<p>I disagree. AMD can simply not implement those APIs, similar to how game emulators implement the most used APIs first and sometimes never bother implementing obscure ones. It would only matter that NVIDIA added eg. patented APIs to CUDA if those APIs were useful. In which case AMD should have a way to do them anyway. Unless NVIDIA comes up with a new patented API which is both useful and impossible to implement in any other way, which would be bad for AMD in any event. On the other hand, if AMD start supporting CUDA and people start using AMD cards, then developers will be hesitant to use APIs that only work on NVIDIA  cards. Right now they are losing billions of dollars on this. Then again they barely seem capable of supporting RocM on their cards, much less CUDA.<p>You have a fair point in terms of cuDNN and cuBLAS but I don&#x27;t know that that kind of ToS is actually binding.</div><br/><div id="40972385" class="c"><input type="checkbox" id="c-40972385" checked=""/><div class="controls bullet"><span class="by">selimnairb</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40970930">parent</a><span>|</span><a href="#40973277">next</a><span>|</span><label class="collapse" for="c-40972385">[-]</label><label class="expand" for="c-40972385">[5 more]</label></div><br/><div class="children"><div class="content">Patented API? I thought Google v. Oracle settled this? Making an implementation of an API spec is fair use, is it not?</div><br/><div id="40972915" class="c"><input type="checkbox" id="c-40972915" checked=""/><div class="controls bullet"><span class="by">fngjdflmdflg</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972385">parent</a><span>|</span><a href="#40973277">next</a><span>|</span><label class="collapse" for="c-40972915">[-]</label><label class="expand" for="c-40972915">[4 more]</label></div><br/><div class="children"><div class="content">My understanding is that Google v. Oracle only applies to copyright.</div><br/><div id="40973424" class="c"><input type="checkbox" id="c-40973424" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972915">parent</a><span>|</span><a href="#40973277">next</a><span>|</span><label class="collapse" for="c-40973424">[-]</label><label class="expand" for="c-40973424">[3 more]</label></div><br/><div class="children"><div class="content">Well you can&#x27;t patent an API so....</div><br/><div id="40973833" class="c"><input type="checkbox" id="c-40973833" checked=""/><div class="controls bullet"><span class="by">fngjdflmdflg</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973424">parent</a><span>|</span><a href="#40973277">next</a><span>|</span><label class="collapse" for="c-40973833">[-]</label><label class="expand" for="c-40973833">[2 more]</label></div><br/><div class="children"><div class="content">You can patent the implementation. You can&#x27;t patent the API name DecodeH265Video() but you can still sue someone for implementing that function correctly.</div><br/><div id="40979595" class="c"><input type="checkbox" id="c-40979595" checked=""/><div class="controls bullet"><span class="by">anticensor</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973833">parent</a><span>|</span><a href="#40973277">next</a><span>|</span><label class="collapse" for="c-40979595">[-]</label><label class="expand" for="c-40979595">[1 more]</label></div><br/><div class="children"><div class="content">If there is only one way to solve a problem, there is nothing to invent, just discover, and discoveries are decidedly not patentable.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40973277" class="c"><input type="checkbox" id="c-40973277" checked=""/><div class="controls bullet"><span class="by">apatheticonion</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40970930">prev</a><span>|</span><a href="#40971064">next</a><span>|</span><label class="collapse" for="c-40973277">[-]</label><label class="expand" for="c-40973277">[14 more]</label></div><br/><div class="children"><div class="content">Agreed. Rather than making CUDA the standard; AMD should push&#x2F;drive an open standard that can be run on any hardware.<p>We have seen this succeed multiple times: FreeSync vs GSync, DLSS vs FSR, (not AMD but) Vulkan vs DirectX &amp; Metal.<p>All of the big tech companies are obsessed with ring-fencing developers behind the thin veil of &quot;innovation&quot; - where really it&#x27;s just good for business (I swear it should be regulated because it&#x27;s really bad for consumers).<p>A CUDA translation layer is okay for now but it does risk CUDA becoming the standard API. Personally, I am comfortable with waiting on an open standard to take over - ROCm has serviced my needs pretty well so far.<p>Just wish GPU sharing with VMs was as easy as CPU sharing.</div><br/><div id="40975795" class="c"><input type="checkbox" id="c-40975795" checked=""/><div class="controls bullet"><span class="by">naasking</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973277">parent</a><span>|</span><a href="#40974144">next</a><span>|</span><label class="collapse" for="c-40975795">[-]</label><label class="expand" for="c-40975795">[1 more]</label></div><br/><div class="children"><div class="content">&gt; AMD should push&#x2F;drive an open standard that can be run on any hardware.<p>AMD has always been notoriously bad at the software side, and they frequently abandon their projects when they&#x27;re almost usable, so I won&#x27;t hold my breath.</div><br/></div></div><div id="40974144" class="c"><input type="checkbox" id="c-40974144" checked=""/><div class="controls bullet"><span class="by">ChoGGi</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973277">parent</a><span>|</span><a href="#40975795">prev</a><span>|</span><a href="#40973322">next</a><span>|</span><label class="collapse" for="c-40974144">[-]</label><label class="expand" for="c-40974144">[1 more]</label></div><br/><div class="children"><div class="content">&quot;We have seen this succeed multiple times: FreeSync vs GSync, DLSS vs FSR, (not AMD but) Vulkan vs DirectX &amp; Metal.&quot;<p>I&#x27;ll definitely agree with you on Sync and Vulkan, but dlss and xess are both better than fsr.<p><a href="https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=el70HE6rXV4" rel="nofollow">https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=el70HE6rXV4</a></div><br/></div></div><div id="40973322" class="c"><input type="checkbox" id="c-40973322" checked=""/><div class="controls bullet"><span class="by">amy-petrik-214</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973277">parent</a><span>|</span><a href="#40974144">prev</a><span>|</span><a href="#40973840">next</a><span>|</span><label class="collapse" for="c-40973322">[-]</label><label class="expand" for="c-40973322">[4 more]</label></div><br/><div class="children"><div class="content">we actually also saw this historically with openGL. 
openGL comes from an ancient company whispered about by the elderly programmers (30 + year old) known as SGI.  Originally it was CLOSED SOURCE and SGI called it &quot;SGI-GL&quot; for a computer codename IRIS which was cool looking with bright popping color plastic and faux granite keyboard.  Good guy SGI open sourced SGI-GL to become what we called &quot;openGL&quot; (get it, now it&#x27;s open), and then it stuck.<p>That&#x27;s all to say NVIDIA <i>could</i> pull a SGI and open their stuff, but they&#x27;re going more sony style and trying to monopolize.  Oh, and SGI also wrote another ancient lore library known as &quot;STL&quot; or the &quot;SGI Template Library&quot; which is like the original boost template metaprogramming granddaddy</div><br/><div id="40974046" class="c"><input type="checkbox" id="c-40974046" checked=""/><div class="controls bullet"><span class="by">usr1106</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973322">parent</a><span>|</span><a href="#40973841">next</a><span>|</span><label class="collapse" for="c-40974046">[-]</label><label class="expand" for="c-40974046">[2 more]</label></div><br/><div class="children"><div class="content">Nice story, but is it correct? Wikipedia says STL was first implemented by HP and later by the same authors at SGI.</div><br/><div id="40977354" class="c"><input type="checkbox" id="c-40977354" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974046">parent</a><span>|</span><a href="#40973841">next</a><span>|</span><label class="collapse" for="c-40977354">[-]</label><label class="expand" for="c-40977354">[1 more]</label></div><br/><div class="children"><div class="content">STL started even earlier, obviously without using the name &quot;STL&quot;, as a library of generic algorithms for the programming language Ada (David R. Musser &amp; Alexander A. Stepanov, 1987).</div><br/></div></div></div></div><div id="40973841" class="c"><input type="checkbox" id="c-40973841" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973322">parent</a><span>|</span><a href="#40974046">prev</a><span>|</span><a href="#40973840">next</a><span>|</span><label class="collapse" for="c-40973841">[-]</label><label class="expand" for="c-40973841">[1 more]</label></div><br/><div class="children"><div class="content">Also the XFS file system.</div><br/></div></div></div></div><div id="40973840" class="c"><input type="checkbox" id="c-40973840" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973277">parent</a><span>|</span><a href="#40973322">prev</a><span>|</span><a href="#40974470">next</a><span>|</span><label class="collapse" for="c-40973840">[-]</label><label class="expand" for="c-40973840">[4 more]</label></div><br/><div class="children"><div class="content">Vulkan only matters on Android (from version 10 onwards) and GNU&#x2F;Linux.<p>Zero impact on Switch, Playstation, XBox, Windows, macOS, iOS, iPadOS, Vision OS.</div><br/><div id="40974148" class="c"><input type="checkbox" id="c-40974148" checked=""/><div class="controls bullet"><span class="by">ChoGGi</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973840">parent</a><span>|</span><a href="#40974470">next</a><span>|</span><label class="collapse" for="c-40974148">[-]</label><label class="expand" for="c-40974148">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Windows&quot;<p>dxvk-gplasync is a game changer for dx9-11 shader stutter.</div><br/><div id="40974531" class="c"><input type="checkbox" id="c-40974531" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974148">parent</a><span>|</span><a href="#40974470">next</a><span>|</span><label class="collapse" for="c-40974531">[-]</label><label class="expand" for="c-40974531">[2 more]</label></div><br/><div class="children"><div class="content">Sure, for the 2% folks that enjoy Windows games, written againt DirectX, on Linux Steam Store.<p>Which Android Studios can&#x27;t even be bothered to target with their NDK engines, based on GL ES, Vulkan.</div><br/><div id="40976462" class="c"><input type="checkbox" id="c-40976462" checked=""/><div class="controls bullet"><span class="by">ChoGGi</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974531">parent</a><span>|</span><a href="#40974470">next</a><span>|</span><label class="collapse" for="c-40976462">[-]</label><label class="expand" for="c-40976462">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m on windows 11, if I see not dx12 in my afterburner overlay, I use it.<p>Even if there&#x27;s no shader stutter, Vulkan tends to use less juice than DX.</div><br/></div></div></div></div></div></div></div></div><div id="40974470" class="c"><input type="checkbox" id="c-40974470" checked=""/><div class="controls bullet"><span class="by">gjulianm</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973277">parent</a><span>|</span><a href="#40973840">prev</a><span>|</span><a href="#40975455">next</a><span>|</span><label class="collapse" for="c-40974470">[-]</label><label class="expand" for="c-40974470">[1 more]</label></div><br/><div class="children"><div class="content">OpenCL was released in 2009. AMD has had plenty of time to push and drive that standard. But OpenCL had a worse experience than CUDA, and AMD wasn&#x27;t up to the task in terms of hardware, so it made no real sense to go for OpenCL.</div><br/></div></div><div id="40975455" class="c"><input type="checkbox" id="c-40975455" checked=""/><div class="controls bullet"><span class="by">consf</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973277">parent</a><span>|</span><a href="#40974470">prev</a><span>|</span><a href="#40974553">next</a><span>|</span><label class="collapse" for="c-40975455">[-]</label><label class="expand" for="c-40975455">[1 more]</label></div><br/><div class="children"><div class="content">A strategic and forward-thinking approach</div><br/></div></div><div id="40974553" class="c"><input type="checkbox" id="c-40974553" checked=""/><div class="controls bullet"><span class="by">imtringued</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973277">parent</a><span>|</span><a href="#40975455">prev</a><span>|</span><a href="#40971064">next</a><span>|</span><label class="collapse" for="c-40974553">[-]</label><label class="expand" for="c-40974553">[1 more]</label></div><br/><div class="children"><div class="content">AMD shouldn&#x27;t push on anything. They have the wrong incentives. They should just make sure that software runs on their GPUs and nothing else.<p>Karol Herbst is working on Rusticl, which is mesa&#x27;s latest OpenCL implementation and will pave the way for other things such as SYCL.</div><br/></div></div></div></div><div id="40971064" class="c"><input type="checkbox" id="c-40971064" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40973277">prev</a><span>|</span><a href="#40971843">next</a><span>|</span><label class="collapse" for="c-40971064">[-]</label><label class="expand" for="c-40971064">[21 more]</label></div><br/><div class="children"><div class="content">&gt; Nvidia can make things arbitrarily difficult both technically and legally<p>Pretty sure APIs are not copyrightable, e.g. <a href="https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;supremecourt&#x2F;text&#x2F;18-956" rel="nofollow">https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;supremecourt&#x2F;text&#x2F;18-956</a><p>&gt; against the license agreement of cuDNN or cuBLAS to run them on this<p>They don’t run either of them, they instead implement an equivalent API on top of something else. Here’s a quote: “Open-source wrapper libraries providing the &quot;CUDA-X&quot; APIs by delegating to the corresponding ROCm libraries. This is how libraries such as cuBLAS and cuSOLVER are handled.”</div><br/><div id="40971185" class="c"><input type="checkbox" id="c-40971185" checked=""/><div class="controls bullet"><span class="by">dralley</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971064">parent</a><span>|</span><a href="#40975398">next</a><span>|</span><label class="collapse" for="c-40971185">[-]</label><label class="expand" for="c-40971185">[19 more]</label></div><br/><div class="children"><div class="content">I believe it was decided that they are copyrightable but that using them for compatibility purposes is fair use.</div><br/><div id="40971330" class="c"><input type="checkbox" id="c-40971330" checked=""/><div class="controls bullet"><span class="by">kbolino</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971185">parent</a><span>|</span><a href="#40975398">next</a><span>|</span><label class="collapse" for="c-40971330">[-]</label><label class="expand" for="c-40971330">[18 more]</label></div><br/><div class="children"><div class="content">No, it&#x27;s stranger than that: SCOTUS did not rule on copyrightability of APIs at all, but simply ruled that even <i>if</i> they are copyrightable, what Google did (completely reimplement Sun&#x2F;Oracle&#x27;s public API) was still fair use.</div><br/><div id="40971417" class="c"><input type="checkbox" id="c-40971417" checked=""/><div class="controls bullet"><span class="by">mrandish</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971330">parent</a><span>|</span><a href="#40972240">next</a><span>|</span><label class="collapse" for="c-40971417">[-]</label><label class="expand" for="c-40971417">[10 more]</label></div><br/><div class="children"><div class="content">It would have been nice to get a clear SCOTUS precedent on this. On the other hand, I also value a SCOTUS which rules minimally and narrowly by default (I also appreciate SCOTUS&#x27; return to stricter constitutional grounding in the past decade).</div><br/><div id="40971779" class="c"><input type="checkbox" id="c-40971779" checked=""/><div class="controls bullet"><span class="by">hobs</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971417">parent</a><span>|</span><a href="#40972240">next</a><span>|</span><label class="collapse" for="c-40971779">[-]</label><label class="expand" for="c-40971779">[9 more]</label></div><br/><div class="children"><div class="content">Incredibly loud laughing from the lawyers whose study of law is being thrown around willy nilly because of all the unprecedented joke decisions they are making right now.</div><br/><div id="40971834" class="c"><input type="checkbox" id="c-40971834" checked=""/><div class="controls bullet"><span class="by">kbolino</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971779">parent</a><span>|</span><a href="#40972240">next</a><span>|</span><label class="collapse" for="c-40971834">[-]</label><label class="expand" for="c-40971834">[8 more]</label></div><br/><div class="children"><div class="content">We are stuck between a rock and a hard place politically. The real decisions should be coming from Congress not the courts. However, Congress is too disorganized and disconnected to answer the important questions, leaving the courts to either muddle along or else become semi-dictatorial. In most countries, this would cause a constitutional crisis, but the modern U.S. system seems to be a little too resilient to such otherwise concerning signals.</div><br/><div id="40972159" class="c"><input type="checkbox" id="c-40972159" checked=""/><div class="controls bullet"><span class="by">hobs</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971834">parent</a><span>|</span><a href="#40972240">next</a><span>|</span><label class="collapse" for="c-40972159">[-]</label><label class="expand" for="c-40972159">[7 more]</label></div><br/><div class="children"><div class="content">We&#x27;re far past a constitutional crisis, and the courts taking power nobody wanted to give to them (who wasn&#x27;t interested in a unitary executive at least) isn&#x27;t a good solution.</div><br/><div id="40972259" class="c"><input type="checkbox" id="c-40972259" checked=""/><div class="controls bullet"><span class="by">kbolino</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972159">parent</a><span>|</span><a href="#40972240">next</a><span>|</span><label class="collapse" for="c-40972259">[-]</label><label class="expand" for="c-40972259">[6 more]</label></div><br/><div class="children"><div class="content">What constitutional crisis has occurred that hasn&#x27;t been resolved?<p>Constitutional crises involve fundamental breaks in the working of government that bring two or more of its elements into direct conflict that can&#x27;t be reconciled through the normal means. The last of these by my accounting was over desegregation, which was resolved with the President ordering the Army to force the recalcitrant states to comply. Before that was a showdown between the New Deal Congress and the Supreme Court, which the former won by credibly threatening to pack the latter (which is IMO a much less severe crisis but still more substantial than anything happening today). However, that was almost a century ago, and Congress has not been that coherent lately.</div><br/><div id="40972792" class="c"><input type="checkbox" id="c-40972792" checked=""/><div class="controls bullet"><span class="by">ted_dunning</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972259">parent</a><span>|</span><a href="#40972240">next</a><span>|</span><label class="collapse" for="c-40972792">[-]</label><label class="expand" for="c-40972792">[5 more]</label></div><br/><div class="children"><div class="content">I would think the latest one where SCOTUS ruled that the president was a king except in matters where the SCOTUS decides they aren&#x27;t counts as a constitutional crisis.</div><br/><div id="40972988" class="c"><input type="checkbox" id="c-40972988" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972792">parent</a><span>|</span><a href="#40972240">next</a><span>|</span><label class="collapse" for="c-40972988">[-]</label><label class="expand" for="c-40972988">[4 more]</label></div><br/><div class="children"><div class="content">Constitutional crises are not a matter of opinion but of occurrence, arising from an <i>actual power conflict</i> between arms of the government that is caused by a conflicted reading of the constitutional text. Basically, if the system just ticks on, it&#x27;s not a constitutional crisis.<p>If &quot;I think this is a very bad decision&quot; was cause for a constitutional crisis, any state with more than three digit population would be in constitutional crisis perpetually.</div><br/><div id="40973543" class="c"><input type="checkbox" id="c-40973543" checked=""/><div class="controls bullet"><span class="by">jolux</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972988">parent</a><span>|</span><a href="#40972240">next</a><span>|</span><label class="collapse" for="c-40973543">[-]</label><label class="expand" for="c-40973543">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Constitutional crises are not a matter of opinion but of occurrence, arising from an actual power conflict between arms of the government that is caused by a conflicted reading of the constitutional text. Basically, if the system just ticks on, it&#x27;s not a constitutional crisis.<p>This happened as recently as 2021-01-06; strong evidence that the military subverted the president to call the National Guard into Washington DC and secure the electoral count.</div><br/><div id="40976107" class="c"><input type="checkbox" id="c-40976107" checked=""/><div class="controls bullet"><span class="by">kbolino</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973543">parent</a><span>|</span><a href="#40973875">next</a><span>|</span><label class="collapse" for="c-40976107">[-]</label><label class="expand" for="c-40976107">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s close. Both the excessively long lame duck period (2 months for Congress and 2.5 months for the President) and disunity between the President and the rest of the executive branch have also been fodder for crises in the past (Marbury v Madison, Andrew Johnson&#x27;s impeachment).</div><br/></div></div><div id="40973875" class="c"><input type="checkbox" id="c-40973875" checked=""/><div class="controls bullet"><span class="by">hnfong</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973543">parent</a><span>|</span><a href="#40976107">prev</a><span>|</span><a href="#40972240">next</a><span>|</span><label class="collapse" for="c-40973875">[-]</label><label class="expand" for="c-40973875">[1 more]</label></div><br/><div class="children"><div class="content">If Trump didn&#x27;t back down it could have definitely been a constitutional crisis.<p>I&#x27;d say it was narrowly averted though.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40972240" class="c"><input type="checkbox" id="c-40972240" checked=""/><div class="controls bullet"><span class="by">not2b</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971330">parent</a><span>|</span><a href="#40971417">prev</a><span>|</span><a href="#40971883">next</a><span>|</span><label class="collapse" for="c-40972240">[-]</label><label class="expand" for="c-40972240">[6 more]</label></div><br/><div class="children"><div class="content">That is how the SC used to work: they would decide cases on the narrowest possible grounds. If they don&#x27;t have to decide a tough question, but they can finesse it with something simpler, good enough. More recently they have been willing to tear up decades of established law on a regular basis.</div><br/><div id="40973852" class="c"><input type="checkbox" id="c-40973852" checked=""/><div class="controls bullet"><span class="by">hnfong</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972240">parent</a><span>|</span><a href="#40971883">next</a><span>|</span><label class="collapse" for="c-40973852">[-]</label><label class="expand" for="c-40973852">[5 more]</label></div><br/><div class="children"><div class="content">&quot;Used to work&quot;... this was 2021.<p>And generally courts&#x2F;judges just choose the scope of their legal opinions based on how far reaching they want the legal principles to apply.<p>IMHO, copyright-ability of APIs is so far away from their political agenda that they probably just decided to leave the issue on a cliffhanger...</div><br/><div id="40976096" class="c"><input type="checkbox" id="c-40976096" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40973852">parent</a><span>|</span><a href="#40971883">next</a><span>|</span><label class="collapse" for="c-40976096">[-]</label><label class="expand" for="c-40976096">[4 more]</label></div><br/><div class="children"><div class="content">Yes, &quot;used to&quot;. Now, in 2024, the same supreme court has decided that presidents have immunity in all official acts, from stealing documents, up to and including assassination attempts on their opponents. This is a radical shift in how the court operates.</div><br/><div id="40976156" class="c"><input type="checkbox" id="c-40976156" checked=""/><div class="controls bullet"><span class="by">kbolino</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40976096">parent</a><span>|</span><a href="#40976330">next</a><span>|</span><label class="collapse" for="c-40976156">[-]</label><label class="expand" for="c-40976156">[2 more]</label></div><br/><div class="children"><div class="content">This &quot;opponent assassination&quot; hypothetical gets bandied about a lot but I have not seen any evidence that any court considers that to be an &quot;official act&quot;. Official acts are constrained to legitimate exercises of constitutional authority and are not merely anything a President (or especially, an ex-President) does.</div><br/><div id="40979348" class="c"><input type="checkbox" id="c-40979348" checked=""/><div class="controls bullet"><span class="by">not2b</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40976156">parent</a><span>|</span><a href="#40976330">next</a><span>|</span><label class="collapse" for="c-40979348">[-]</label><label class="expand" for="c-40979348">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s specifically mentioned in the dissents.</div><br/></div></div></div></div><div id="40976330" class="c"><input type="checkbox" id="c-40976330" checked=""/><div class="controls bullet"><span class="by">jpadkins</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40976096">parent</a><span>|</span><a href="#40976156">prev</a><span>|</span><a href="#40971883">next</a><span>|</span><label class="collapse" for="c-40976330">[-]</label><label class="expand" for="c-40976330">[1 more]</label></div><br/><div class="children"><div class="content">the only thing radical is the opinions of people you are listening to if you believe SCOTUS enabled legally sanctioned assassinations.  It was political hyperbole based on nothing, and it worked (with you).  Think for yourself.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40975398" class="c"><input type="checkbox" id="c-40975398" checked=""/><div class="controls bullet"><span class="by">consf</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971064">parent</a><span>|</span><a href="#40971185">prev</a><span>|</span><a href="#40971843">next</a><span>|</span><label class="collapse" for="c-40975398">[-]</label><label class="expand" for="c-40975398">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re correct! Fair Use Doctrine</div><br/></div></div></div></div><div id="40971843" class="c"><input type="checkbox" id="c-40971843" checked=""/><div class="controls bullet"><span class="by">Wowfunhappy</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40971064">prev</a><span>|</span><a href="#40972924">next</a><span>|</span><label class="collapse" for="c-40971843">[-]</label><label class="expand" for="c-40971843">[3 more]</label></div><br/><div class="children"><div class="content">&gt;  CUDA is not designed to be vendor agnostic and Nvidia can make things arbitrarily difficult [...] technically.<p>(Let&#x27;s put the legal questions aside for a moment.)<p>nVidia changes GPU architectures every generation &#x2F; few generations, right? How does CUDA work across those—and how can it have forwards compatibility in the future—if it&#x27;s not designed to be technologically agnostic?</div><br/><div id="40972759" class="c"><input type="checkbox" id="c-40972759" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971843">parent</a><span>|</span><a href="#40971853">next</a><span>|</span><label class="collapse" for="c-40972759">[-]</label><label class="expand" for="c-40972759">[1 more]</label></div><br/><div class="children"><div class="content">PTX is meant to be portable across GPU microarchitectures. That said, Nvidia owns the entire spec, so they can just keep adding new instructions that their GPUs now support but AMD GPUs don&#x27;t.</div><br/></div></div><div id="40971853" class="c"><input type="checkbox" id="c-40971853" checked=""/><div class="controls bullet"><span class="by">andy_ppp</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971843">parent</a><span>|</span><a href="#40972759">prev</a><span>|</span><a href="#40972924">next</a><span>|</span><label class="collapse" for="c-40971853">[-]</label><label class="expand" for="c-40971853">[1 more]</label></div><br/><div class="children"><div class="content">One way is to make sure the hardware team does certain things to support easy transition to new architectures, we have seen this with Apple Silicon for example!</div><br/></div></div></div></div><div id="40972924" class="c"><input type="checkbox" id="c-40972924" checked=""/><div class="controls bullet"><span class="by">rjurney</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40971843">prev</a><span>|</span><a href="#40973558">next</a><span>|</span><label class="collapse" for="c-40972924">[-]</label><label class="expand" for="c-40972924">[3 more]</label></div><br/><div class="children"><div class="content">Not having a layer like this has left AMD completely out of the AI game that has made NVDA the world&#x27;s most valuable company.</div><br/><div id="40979340" class="c"><input type="checkbox" id="c-40979340" checked=""/><div class="controls bullet"><span class="by">HarHarVeryFunny</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972924">parent</a><span>|</span><a href="#40974162">next</a><span>|</span><label class="collapse" for="c-40979340">[-]</label><label class="expand" for="c-40979340">[1 more]</label></div><br/><div class="children"><div class="content">Well, they kinda have it with their hipify tool, although this is for porting CUDA code to AMD&#x27;s HIP which supports both AMD and NVIDIA. This supports CUDA C code and libraries with AMD equivalents like cuDNN, cuBLAS, cuRAND, but doesn&#x27;t support porting of CUDA C inline PTX assembler. AMD have their own inline GCN assembler, but seem to discourage it&#x27;s use.<p>There are also versions of PyTorch, TensorFlow and JAX with AMD support.<p>PyTorch&#x27;s torch.compile can generate Triton (OpenAI&#x27;s GPU compiler) kernels, with Triton also supporting AMD.</div><br/></div></div><div id="40974162" class="c"><input type="checkbox" id="c-40974162" checked=""/><div class="controls bullet"><span class="by">ChoGGi</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972924">parent</a><span>|</span><a href="#40979340">prev</a><span>|</span><a href="#40973558">next</a><span>|</span><label class="collapse" for="c-40974162">[-]</label><label class="expand" for="c-40974162">[1 more]</label></div><br/><div class="children"><div class="content">Self-inflicted wounds hurt the most.</div><br/></div></div></div></div><div id="40973558" class="c"><input type="checkbox" id="c-40973558" checked=""/><div class="controls bullet"><span class="by">magic_hamster</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40972924">prev</a><span>|</span><a href="#40975362">next</a><span>|</span><label class="collapse" for="c-40973558">[-]</label><label class="expand" for="c-40973558">[1 more]</label></div><br/><div class="children"><div class="content">CUDA is the juice that built Nvidia in the AI space and allowed them to charge crazy money for their hardware. To be able to run CUDA on cost effective AMD hardware can be a big leap forward, allow more people to research, and break away from Nvidia&#x27;s stranglehold over VRAM. Nvidia will never open source their own platform unless their hand is forced. I think we all should support this endeavor and contribute where possible.</div><br/></div></div><div id="40975362" class="c"><input type="checkbox" id="c-40975362" checked=""/><div class="controls bullet"><span class="by">raxxorraxor</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40973558">prev</a><span>|</span><a href="#40971067">next</a><span>|</span><label class="collapse" for="c-40975362">[-]</label><label class="expand" for="c-40975362">[2 more]</label></div><br/><div class="children"><div class="content">I really hope they will do what you suggested. With some innovative product placement, GPUs with a lot of memory for example, they could dethrone nvidia if it doesn&#x27;t change strategy.<p>That said, easier said than done. You need very specialized developers to build a CUDA equivalent and have people start using it. AMD could do it with a more open development process leveraging the open source community. I believe this will happen at some point anyway by AMD or someone else. The market just gets more attractive by the day and at some point the high entry barrier will not matter much.<p>So why should AMD skimp on their ambitions here? This would be a most sensible investment, few risks and high gains if successful.</div><br/><div id="40975387" class="c"><input type="checkbox" id="c-40975387" checked=""/><div class="controls bullet"><span class="by">consf</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40975362">parent</a><span>|</span><a href="#40971067">next</a><span>|</span><label class="collapse" for="c-40975387">[-]</label><label class="expand" for="c-40975387">[1 more]</label></div><br/><div class="children"><div class="content">This expanding market provides AMD with a lucrative opportunity indeed</div><br/></div></div></div></div><div id="40971067" class="c"><input type="checkbox" id="c-40971067" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40975362">prev</a><span>|</span><a href="#40974953">next</a><span>|</span><label class="collapse" for="c-40971067">[-]</label><label class="expand" for="c-40971067">[8 more]</label></div><br/><div class="children"><div class="content">Like supporting x86 was a bad idea as well?</div><br/><div id="40971373" class="c"><input type="checkbox" id="c-40971373" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971067">parent</a><span>|</span><a href="#40971091">next</a><span>|</span><label class="collapse" for="c-40971373">[-]</label><label class="expand" for="c-40971373">[2 more]</label></div><br/><div class="children"><div class="content">Before starting, AMD signed an agreement with Intel that gave them an explicit license to x86. And x86 was a whole lot smaller and simpler back then in <i>1982</i>. A completely different and incomparable situation.</div><br/><div id="40971626" class="c"><input type="checkbox" id="c-40971626" checked=""/><div class="controls bullet"><span class="by">nostrademons</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971373">parent</a><span>|</span><a href="#40971091">next</a><span>|</span><label class="collapse" for="c-40971626">[-]</label><label class="expand" for="c-40971626">[1 more]</label></div><br/><div class="children"><div class="content">Technically it was after starting - AMD was founded in 1969 as a second-sourcer for Fairchild and National Semiconductor, and had reverse-engineered the 8080 by 1975 and acquired a formal license to it by 1976.<p>The 1982 deal you speak of was actually pretty interesting: as a condition of the x86&#x27;s use in the IBM PC, IBM requested a second source for x86 chips.  AMD was that source, and so they cross-licensed the x86 in 1982 to allow the IBM PC project to proceed forward.  This makes the Intel&#x2F;AMD deal even more important for both companies: <i>the PC market would never have developed</i> without the cross-licensing, which would&#x27;ve been bad for all companies involved.  This gave Intel an ongoing stake in AMD&#x27;s success at least until the PC market consolidated on the x86 standard.</div><br/></div></div></div></div><div id="40971091" class="c"><input type="checkbox" id="c-40971091" checked=""/><div class="controls bullet"><span class="by">karolist</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971067">parent</a><span>|</span><a href="#40971373">prev</a><span>|</span><a href="#40974953">next</a><span>|</span><label class="collapse" for="c-40971091">[-]</label><label class="expand" for="c-40971091">[5 more]</label></div><br/><div class="children"><div class="content">Was there a large entity steering x86 spec alone with a huge feature lead against their competition, free to steer the spec in any ways they choose? Also, hardware is not opensource software, you get big players onboard and they will be able to implement the spec they want every gen, software has more moving parts and unaligned parties involved.</div><br/><div id="40971173" class="c"><input type="checkbox" id="c-40971173" checked=""/><div class="controls bullet"><span class="by">cherryteastain</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971091">parent</a><span>|</span><a href="#40974953">next</a><span>|</span><label class="collapse" for="c-40971173">[-]</label><label class="expand" for="c-40971173">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Was there a large entity steering x86 spec alone with a huge feature lead against their competition, free to steer the spec in any ways they choose?<p>Ever heard of Intel?</div><br/><div id="40971263" class="c"><input type="checkbox" id="c-40971263" checked=""/><div class="controls bullet"><span class="by">karolist</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971173">parent</a><span>|</span><a href="#40974953">next</a><span>|</span><label class="collapse" for="c-40971263">[-]</label><label class="expand" for="c-40971263">[3 more]</label></div><br/><div class="children"><div class="content">I had&#x27;t considered that angle. Is your point that Intel was the creator of x86, but software chose to support it, then AMD had nothing else but to play catch up in x86 support to be part of the software target market? If so and factual (I&#x27;ve no idea), fair point, I didn&#x27;t know.</div><br/><div id="40972204" class="c"><input type="checkbox" id="c-40972204" checked=""/><div class="controls bullet"><span class="by">marshray</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971263">parent</a><span>|</span><a href="#40974953">next</a><span>|</span><label class="collapse" for="c-40972204">[-]</label><label class="expand" for="c-40972204">[2 more]</label></div><br/><div class="children"><div class="content">It was exactly the same instruction set.<p>C compilers didn&#x27;t offer an &quot;AMD&quot; CPU target* until AMD came out with the &quot;AMD64&quot; instruction set. Today we call this &quot;x86_64&quot; or &quot;x64&quot;.<p>* Feel free to point out some custom multimedia vector extensions for Athlons or something, but the point remains.</div><br/><div id="40975716" class="c"><input type="checkbox" id="c-40975716" checked=""/><div class="controls bullet"><span class="by">gmokki</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972204">parent</a><span>|</span><a href="#40974953">next</a><span>|</span><label class="collapse" for="c-40975716">[-]</label><label class="expand" for="c-40975716">[1 more]</label></div><br/><div class="children"><div class="content">And Intel named its licenced implementation of AMD64 as IA-32e, just to make it clear to everyone that it is based on Intel architecture 32bit version with an extension.
Luckily they dropped that name few years later</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40974953" class="c"><input type="checkbox" id="c-40974953" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40971067">prev</a><span>|</span><a href="#40971265">next</a><span>|</span><label class="collapse" for="c-40974953">[-]</label><label class="expand" for="c-40974953">[1 more]</label></div><br/><div class="children"><div class="content">That is why an open standard should be made so it isn&#x27;t locked to a particular piece of hardware and then allow modular support for different hardware to interface with supported drivers.</div><br/></div></div><div id="40971265" class="c"><input type="checkbox" id="c-40971265" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40974953">prev</a><span>|</span><a href="#40971792">next</a><span>|</span><label class="collapse" for="c-40971265">[-]</label><label class="expand" for="c-40971265">[5 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t cuDNN a much better case for reimplementing than CUDA? It has much more choice in how things actually happen and cuDNN itself chooses different implementations at runtime + does fusing. It seems way more generic and the reimplementation would allow using the best AMD-targeted kernel rather than one the original has.</div><br/><div id="40971531" class="c"><input type="checkbox" id="c-40971531" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971265">parent</a><span>|</span><a href="#40971792">next</a><span>|</span><label class="collapse" for="c-40971531">[-]</label><label class="expand" for="c-40971531">[4 more]</label></div><br/><div class="children"><div class="content">AMD have &quot;MIOpen&quot; which is <i>basically</i> cuDNN-for-AMD. Ish.</div><br/><div id="40974035" class="c"><input type="checkbox" id="c-40974035" checked=""/><div class="controls bullet"><span class="by">mmis1000</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971531">parent</a><span>|</span><a href="#40971792">next</a><span>|</span><label class="collapse" for="c-40974035">[-]</label><label class="expand" for="c-40974035">[3 more]</label></div><br/><div class="children"><div class="content">And that thing is left for unreleased on windows for almost a whole year for unknown reason. Even though there is activity on github and build fix frequently. There is just no .exe or .msi for you to download. In fact, the rocm for linux is on major 6 release (which includes miopen). But somehow windows is still on major 5 (don&#x27;t have miopen) for almost a whole year.<p>It almost make me wonder. Is there a shady trade somewhere to ask amd never release sdk for Windows to hike the price of nvidia card higher? Why they keep developing these without release it at all?</div><br/><div id="40983662" class="c"><input type="checkbox" id="c-40983662" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974035">parent</a><span>|</span><a href="#40981312">next</a><span>|</span><label class="collapse" for="c-40983662">[-]</label><label class="expand" for="c-40983662">[1 more]</label></div><br/><div class="children"><div class="content">Since they cancelled the work on zluda and absolutely fail to do anything about other options, I really believe there&#x27;s some &quot;don&#x27;t do it or you&#x27;ll get sued to hell and back&quot; agreement. They can&#x27;t be so dumb they just miss it by accident.</div><br/></div></div><div id="40981312" class="c"><input type="checkbox" id="c-40981312" checked=""/><div class="controls bullet"><span class="by">flamedoge</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40974035">parent</a><span>|</span><a href="#40983662">prev</a><span>|</span><a href="#40971792">next</a><span>|</span><label class="collapse" for="c-40981312">[-]</label><label class="expand" for="c-40981312">[1 more]</label></div><br/><div class="children"><div class="content">probably because their focus is on data centers that mostly run linux</div><br/></div></div></div></div></div></div></div></div><div id="40971792" class="c"><input type="checkbox" id="c-40971792" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40971265">prev</a><span>|</span><a href="#40971021">next</a><span>|</span><label class="collapse" for="c-40971792">[-]</label><label class="expand" for="c-40971792">[1 more]</label></div><br/><div class="children"><div class="content">Given AMDs prior lack of interest I&#x27;ll take whatever options there are. My daily driver has a Vega 10 GPU and it&#x27;s been quite frustrating not to be able to easily leverage it for doing basic ML tasks, to the point that I&#x27;ve been looking at buying an external nvidia GPU instead just to try out some of the popular Python libraries.</div><br/></div></div><div id="40971021" class="c"><input type="checkbox" id="c-40971021" checked=""/><div class="controls bullet"><span class="by">dietr1ch</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40971792">prev</a><span>|</span><a href="#40970736">next</a><span>|</span><label class="collapse" for="c-40971021">[-]</label><label class="expand" for="c-40971021">[5 more]</label></div><br/><div class="children"><div class="content">How&#x27;s this situation different than the one around Java, Sun&#x2F;Oracle and Google?</div><br/><div id="40971255" class="c"><input type="checkbox" id="c-40971255" checked=""/><div class="controls bullet"><span class="by">dboreham</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971021">parent</a><span>|</span><a href="#40970736">next</a><span>|</span><label class="collapse" for="c-40971255">[-]</label><label class="expand" for="c-40971255">[4 more]</label></div><br/><div class="children"><div class="content">The judge might not be a coder next time.</div><br/><div id="40971287" class="c"><input type="checkbox" id="c-40971287" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971255">parent</a><span>|</span><a href="#40970736">next</a><span>|</span><label class="collapse" for="c-40971287">[-]</label><label class="expand" for="c-40971287">[3 more]</label></div><br/><div class="children"><div class="content">The US law is highly dependent on precedents. The Google-Oracle case has set one fortunately, so anything following it won&#x27;t start from scratch. Fortunately we may not need a closer judge.</div><br/><div id="40971560" class="c"><input type="checkbox" id="c-40971560" checked=""/><div class="controls bullet"><span class="by">jjk166</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971287">parent</a><span>|</span><a href="#40971569">next</a><span>|</span><label class="collapse" for="c-40971560">[-]</label><label class="expand" for="c-40971560">[1 more]</label></div><br/><div class="children"><div class="content">Google-Oracle side stepped the issue of API copyrightability by saying Google&#x27;s particular implementation would fall under fair use. Whether APIs are copyrightable remains an open question.</div><br/></div></div><div id="40971569" class="c"><input type="checkbox" id="c-40971569" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40971287">parent</a><span>|</span><a href="#40971560">prev</a><span>|</span><a href="#40970736">next</a><span>|</span><label class="collapse" for="c-40971569">[-]</label><label class="expand" for="c-40971569">[1 more]</label></div><br/><div class="children"><div class="content">Until you get an activist court</div><br/></div></div></div></div></div></div></div></div><div id="40970736" class="c"><input type="checkbox" id="c-40970736" checked=""/><div class="controls bullet"><span class="by">DeepYogurt</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40971021">prev</a><span>|</span><a href="#40975373">next</a><span>|</span><label class="collapse" for="c-40970736">[-]</label><label class="expand" for="c-40970736">[1 more]</label></div><br/><div class="children"><div class="content">Ya, honestly better to leave that to third parties who can dedicate themselves to it and maybe offer support or whatever. Let AMD work on good first party support first.</div><br/></div></div><div id="40975373" class="c"><input type="checkbox" id="c-40975373" checked=""/><div class="controls bullet"><span class="by">consf</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40970736">prev</a><span>|</span><a href="#40972936">next</a><span>|</span><label class="collapse" for="c-40975373">[-]</label><label class="expand" for="c-40975373">[1 more]</label></div><br/><div class="children"><div class="content">The legal, technical and strategic challenges make it a less attractive option</div><br/></div></div><div id="40972936" class="c"><input type="checkbox" id="c-40972936" checked=""/><div class="controls bullet"><span class="by">neutrinobro</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40975373">prev</a><span>|</span><a href="#40973043">next</a><span>|</span><label class="collapse" for="c-40972936">[-]</label><label class="expand" for="c-40972936">[1 more]</label></div><br/><div class="children"><div class="content"><i>Cries in OpenCL</i></div><br/></div></div><div id="40972040" class="c"><input type="checkbox" id="c-40972040" checked=""/><div class="controls bullet"><span class="by">koolala</span><span>|</span><a href="#40970717">parent</a><span>|</span><a href="#40973043">prev</a><span>|</span><a href="#40970852">next</a><span>|</span><label class="collapse" for="c-40972040">[-]</label><label class="expand" for="c-40972040">[2 more]</label></div><br/><div class="children"><div class="content">CUDA v1...CUDA v2... CUDA v... CUDA isnt commonly assosiated with a version number...</div><br/><div id="40972107" class="c"><input type="checkbox" id="c-40972107" checked=""/><div class="controls bullet"><span class="by">Uehreka</span><span>|</span><a href="#40970717">root</a><span>|</span><a href="#40972040">parent</a><span>|</span><a href="#40970852">next</a><span>|</span><label class="collapse" for="c-40972107">[-]</label><label class="expand" for="c-40972107">[1 more]</label></div><br/><div class="children"><div class="content">…yes it is? <a href="https:&#x2F;&#x2F;developer.nvidia.com&#x2F;cuda-toolkit-archive" rel="nofollow">https:&#x2F;&#x2F;developer.nvidia.com&#x2F;cuda-toolkit-archive</a></div><br/></div></div></div></div></div></div><div id="40970852" class="c"><input type="checkbox" id="c-40970852" checked=""/><div class="controls bullet"><span class="by">ladberg</span><span>|</span><a href="#40970717">prev</a><span>|</span><a href="#40970701">next</a><span>|</span><label class="collapse" for="c-40970852">[-]</label><label class="expand" for="c-40970852">[18 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t really see how any code that depends heavily on the underlying hardware can &quot;just work&quot; on AMD. Most serious CUDA code is aware of register file and shared memory sizes, wgmma instructions, optimal tensor core memory &amp; register layouts, tensor memory accelerator instructions, etc...<p>Presumably that stuff doesn&#x27;t &quot;just work&quot; but they don&#x27;t want to mention it?</div><br/><div id="40971164" class="c"><input type="checkbox" id="c-40971164" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40970852">parent</a><span>|</span><a href="#40974308">next</a><span>|</span><label class="collapse" for="c-40971164">[-]</label><label class="expand" for="c-40971164">[14 more]</label></div><br/><div class="children"><div class="content">Sort of<p>A lot of our hw-aware bits are parameterized where we fill in constants based on the available hw
. Doable to port, same as we do whenever new Nvidia architectures come out.<p>But yeah, we have tricky bits that inline PTX, and.. that will be more annoying to redo.</div><br/><div id="40971264" class="c"><input type="checkbox" id="c-40971264" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40971164">parent</a><span>|</span><a href="#40974308">next</a><span>|</span><label class="collapse" for="c-40971264">[-]</label><label class="expand" for="c-40971264">[13 more]</label></div><br/><div class="children"><div class="content">&gt; SCALE accepts CUDA programs as-is. [...] This is true even if your program uses inline PTX asm</div><br/><div id="40971299" class="c"><input type="checkbox" id="c-40971299" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40971264">parent</a><span>|</span><a href="#40974308">next</a><span>|</span><label class="collapse" for="c-40971299">[-]</label><label class="expand" for="c-40971299">[12 more]</label></div><br/><div class="children"><div class="content">Oh that will be interesting to understand, as PTX gets to more about trickier hw-arch-specific phenomena that diff brands disagree on, like memory models. Neat!</div><br/><div id="40971352" class="c"><input type="checkbox" id="c-40971352" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40971299">parent</a><span>|</span><a href="#40974308">next</a><span>|</span><label class="collapse" for="c-40971352">[-]</label><label class="expand" for="c-40971352">[11 more]</label></div><br/><div class="children"><div class="content">Looks like the PTX translation is via another project ZLUDA, though how they bridge the differences in memory&#x2F;consistency&#x2F;etc models safely remains unclear to me...</div><br/><div id="40971561" class="c"><input type="checkbox" id="c-40971561" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40971352">parent</a><span>|</span><a href="#40974308">next</a><span>|</span><label class="collapse" for="c-40971561">[-]</label><label class="expand" for="c-40971561">[10 more]</label></div><br/><div class="children"><div class="content">Hi! Spectral engineer here!<p>SCALE does not use any part of ZLUDA. We have modified the clang frontend to convert inline PTX asm block to LLVM IR.<p>To put in a less compiler-engineer-ey way: for any given block of PTX, there exists a hypothetical sequence of C++&#x2F;CUDA code you could have written to achieve the same effect, but on AMD (perhaps using funky __builtin_... functions if the code includes shuffles&#x2F;ballots&#x2F;other-weird-gpu-stuff). Our compiler effectively converts the PTX into that hypothetical C++.<p>Regarding memory consistency etc.: NVIDIA document the &quot;CUDA memory consistency model&quot; extremely thoroughly, and likewise, the consistency guarantees for PTX. It is therefore sufficient to ensure that we use operations at least as synchronising as those called for in the documented semantics of the language (be it CUDA or PTX, for each operation).<p>Differing consistency _between architectures_ is the AMDGPU backend&#x27;s problem.</div><br/><div id="40972769" class="c"><input type="checkbox" id="c-40972769" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40971561">parent</a><span>|</span><a href="#40972050">next</a><span>|</span><label class="collapse" for="c-40972769">[-]</label><label class="expand" for="c-40972769">[5 more]</label></div><br/><div class="children"><div class="content">Ah I was reading the &#x27;deeper dive&#x27; section on my phone and missed it was a comparison, not a warning, thank you<p>I&#x27;m curious how something like this example would translate:<p>===<p>Mapping lower-level ptx patterns to higher-level AMD constructs like __ballot, and knowing it&#x27;s safe<p>```<p><pre><code>  #ifdef INLINEPTX
  inline uint ptx_thread_vote(float rSq, float rCritSq) {
      uint result = 0;
      asm(&quot;{\n\t&quot;
           &quot;.reg .pred cond, out;\n\t&quot;
           &quot;setp.ge.f32 cond, %1, %2;\n\t&quot;
           &quot;vote.sync.all.pred out, cond, 0xffffffff;\n\t&quot;
           &quot;selp.u32 %0, 1, 0, out;\n\t&quot;
           &quot;}\n\t&quot;
           : &quot;=r&quot;(result)
           : &quot;f&quot;(rSq), &quot;f&quot;(rCritSq));
      return result;
  }
  #endif
</code></pre>
```<p>===<p>Again, I&#x27;m guessing there might be an equiv simpler program involving AMD&#x27;s __ballot, but I&#x27;m unsure of the true equivalence wrt safety, and it seems like a tricky rewrite as it needs to (afaict) decompile to recover the higher-level abstraction. Normally it&#x27;s easier to compile down or sideways (translate), and it&#x27;s not clear to me these primitives are 1:1 for safely doing so.<p>===<p>FWIW, this is all pretty cool. We stay away from PTX -- most of our app code is higher-level, whether RAPIDS (GPU dataframes, GPU ML, etc libs), minimal cuda, and minimal opencl, with only small traces of inline ptx. So more realistically, if we had the motivation, we&#x27;d likely explore just #ifdef&#x27;ing it with something predictable.</div><br/><div id="40973008" class="c"><input type="checkbox" id="c-40973008" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40972769">parent</a><span>|</span><a href="#40972050">next</a><span>|</span><label class="collapse" for="c-40973008">[-]</label><label class="expand" for="c-40973008">[4 more]</label></div><br/><div class="children"><div class="content">I compiled your function with SCALE for gfx1030:<p><pre><code>        .p2align        2                               ; -- Begin function _Z15ptx_thread_voteff
        .type   _Z15ptx_thread_voteff,@function
  _Z15ptx_thread_voteff:                  ; @_Z15ptx_thread_voteff
  ; %bb.0:                                ; %entry
        s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
        s_waitcnt_vscnt null, 0x0
        v_cmp_ge_f32_e32 vcc_lo, v0, v1
        s_cmp_eq_u32 vcc_lo, -1
        s_cselect_b32 s4, -1, 0
        v_cndmask_b32_e64 v0, 0, 1, s4
        s_setpc_b64 s[30:31]
  .Lfunc_end1:
        .size   _Z15ptx_thread_voteff, .Lfunc_end1-_Z15ptx_thread_voteff
                                        ; -- End function


</code></pre>
What were the safety concerns you had? This code seems to be something like `return __all_sync(rSq &gt;= rCritSq) ? 1 : 0`, right?</div><br/><div id="40973129" class="c"><input type="checkbox" id="c-40973129" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40973008">parent</a><span>|</span><a href="#40972050">next</a><span>|</span><label class="collapse" for="c-40973129">[-]</label><label class="expand" for="c-40973129">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s supposed to be waiting for all threads to vote<p>I&#x27;m not familiar with AMD enough to know if additional synchronization is needed. ChatGPT recommended adding  barriers beyond what that gave, but again, I&#x27;m not familiar with AMD commands.</div><br/><div id="40973196" class="c"><input type="checkbox" id="c-40973196" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40973129">parent</a><span>|</span><a href="#40972050">next</a><span>|</span><label class="collapse" for="c-40973196">[-]</label><label class="expand" for="c-40973196">[2 more]</label></div><br/><div class="children"><div class="content">Indeed, no extra synchronisation is needed here due to the nature of the hardware (threads in a warp can&#x27;t get out of sync with each other).<p>Even on NVIDIA, you could&#x27;ve written this without the asm a discussed above!</div><br/><div id="40973825" class="c"><input type="checkbox" id="c-40973825" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40973196">parent</a><span>|</span><a href="#40972050">next</a><span>|</span><label class="collapse" for="c-40973825">[-]</label><label class="expand" for="c-40973825">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I think, after this snippet was written, cuda added __all_sync as an intrinsic. The divergent code before this was plain-ish cuda, and this snippet ensures they wait on the comparison vote before recurring.<p>So in the AMD version, the compiler correctly realized the synchronization was on the comparison, so adds the AMD version right before it. That seems like a straightforward transform here.<p>It&#x27;d be interesting to understand the comparison of what Nvidia primitives map vs what doesn&#x27;t. The above is a fairly simple barrier. We avoided PTX as much as we could and wrote it as simply as we could, I&#x27;d expect most of our PTX to port for similar reasons. The story is a bit diff for libraries we call. E.g., cudf probably has little compute-tier ptx directly, but will call nvidia libs, and use weird IO bits like cufile &#x2F; gpu direct storage.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40972050" class="c"><input type="checkbox" id="c-40972050" checked=""/><div class="controls bullet"><span class="by">ladberg</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40971561">parent</a><span>|</span><a href="#40972769">prev</a><span>|</span><a href="#40974308">next</a><span>|</span><label class="collapse" for="c-40972050">[-]</label><label class="expand" for="c-40972050">[4 more]</label></div><br/><div class="children"><div class="content">Just to check here, if you&#x27;re given something like the following PTX:<p><pre><code>  wgmma.mma_async.sync.aligned.m64n256k16.f32.bf16.bf16
</code></pre>
Do you reverse it back into C++ that does the corresponding FMAs manually instead of using tensor hardware? Or are you able to convert it into a series of __builtin_amdgcn_mfma_CDFmt_MxNxKABFmt instructions that emulate the same behavior?</div><br/><div id="40972578" class="c"><input type="checkbox" id="c-40972578" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40972050">parent</a><span>|</span><a href="#40974308">next</a><span>|</span><label class="collapse" for="c-40972578">[-]</label><label class="expand" for="c-40972578">[3 more]</label></div><br/><div class="children"><div class="content">Rather awkwardly, you&#x27;ve asked about an instruction that isn&#x27;t currently implemented. :D Support for wmma and friends is in development.<p>But in general the answer to your question is yes: we use AMD-specific builtins where available&#x2F;efficient to make things work. Otherwise many things would be unrepresentble, not just slow!</div><br/><div id="40972768" class="c"><input type="checkbox" id="c-40972768" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40972578">parent</a><span>|</span><a href="#40974308">next</a><span>|</span><label class="collapse" for="c-40972768">[-]</label><label class="expand" for="c-40972768">[2 more]</label></div><br/><div class="children"><div class="content">What do you do when a builtin doesn&#x27;t exist?</div><br/><div id="40973020" class="c"><input type="checkbox" id="c-40973020" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40972768">parent</a><span>|</span><a href="#40974308">next</a><span>|</span><label class="collapse" for="c-40973020">[-]</label><label class="expand" for="c-40973020">[1 more]</label></div><br/><div class="children"><div class="content">Add one: it&#x27;s trivial to add a compiler builtin to carry the instruction from the frontend to the backend if an instruction exists and the backend knows about it.<p>If there&#x27;s no instruction, either, you can write a C++ function to replicate the behaviour and codegen a call to it. Since the PTX blocks are expanded during initial IR generation, it all inlines nicely by the end. Of course, such software emulation is potentially suboptimal (depends on the situation).</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40974308" class="c"><input type="checkbox" id="c-40974308" checked=""/><div class="controls bullet"><span class="by">Moldoteck</span><span>|</span><a href="#40970852">parent</a><span>|</span><a href="#40971164">prev</a><span>|</span><a href="#40975471">next</a><span>|</span><label class="collapse" for="c-40974308">[-]</label><label class="expand" for="c-40974308">[2 more]</label></div><br/><div class="children"><div class="content">it&#x27;s a speculation, but I think it&#x27;s similar with processors = nobody guarantees the code will run the way you set it up. You may want to use some specific register but if the processor will think it has another register that can fulfill the task, it&#x27;ll use that but tell you that your code is executed as expected. Maybe the internal gpu processor of amd can sufficiently simulate the behavior of nvidia hardware so that higher abstractions will be unaware that something different is happening under the hood</div><br/><div id="40981447" class="c"><input type="checkbox" id="c-40981447" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40970852">root</a><span>|</span><a href="#40974308">parent</a><span>|</span><a href="#40975471">next</a><span>|</span><label class="collapse" for="c-40981447">[-]</label><label class="expand" for="c-40981447">[1 more]</label></div><br/><div class="children"><div class="content">Prettymuch. Compilers can do a lot more than people give them credit for. At least AMD document their hardware so it is <i>actually possible to know</i> low-level details. PTX can obfuscate that surprisingly badly for nvidia targets.</div><br/></div></div></div></div><div id="40975471" class="c"><input type="checkbox" id="c-40975471" checked=""/><div class="controls bullet"><span class="by">consf</span><span>|</span><a href="#40970852">parent</a><span>|</span><a href="#40974308">prev</a><span>|</span><a href="#40970701">next</a><span>|</span><label class="collapse" for="c-40975471">[-]</label><label class="expand" for="c-40975471">[1 more]</label></div><br/><div class="children"><div class="content">It involves significant challenges</div><br/></div></div></div></div><div id="40970701" class="c"><input type="checkbox" id="c-40970701" checked=""/><div class="controls bullet"><span class="by">acheong08</span><span>|</span><a href="#40970852">prev</a><span>|</span><a href="#40970890">next</a><span>|</span><label class="collapse" for="c-40970701">[-]</label><label class="expand" for="c-40970701">[46 more]</label></div><br/><div class="children"><div class="content">Impressive if true. Unfortunately not open source and scarce on exact details on how it works<p>Edit: not sure why I just sort of expect projects to be open source or at least source available these days.</div><br/><div id="40971275" class="c"><input type="checkbox" id="c-40971275" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#40970701">parent</a><span>|</span><a href="#40970955">next</a><span>|</span><label class="collapse" for="c-40971275">[-]</label><label class="expand" for="c-40971275">[22 more]</label></div><br/><div class="children"><div class="content">Makes sense to expect this kind of thing to be open source. The whole point of providing improved compatibility is to make people’s lives easier, and open source is usually an important feature to ensure wide compatibility. It also means projects can live on after the creators move to other things, people can submit patches for important features or bug fixes, and generally makes the system much more useful.</div><br/><div id="40971615" class="c"><input type="checkbox" id="c-40971615" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971275">parent</a><span>|</span><a href="#40979898">next</a><span>|</span><label class="collapse" for="c-40971615">[-]</label><label class="expand" for="c-40971615">[20 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t find it wrong for someone to attempt to make money back on their time and experience of doing the work. I don&#x27;t mind people that offer that back as open source either. However, I do have a problem of people expecting everything to be open&#x2F;free, especially those that then go on a crusade chastising those that do try to make money.</div><br/><div id="40971951" class="c"><input type="checkbox" id="c-40971951" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971615">parent</a><span>|</span><a href="#40979898">next</a><span>|</span><label class="collapse" for="c-40971951">[-]</label><label class="expand" for="c-40971951">[19 more]</label></div><br/><div class="children"><div class="content">I&#x27;m really trying to keep this about the engineering features of a system rather than moral judgments. Open source systems are simply more flexible and adaptable than proprietary systems, which have their own benefits. In today&#x27;s world, the engineering value of open source systems is becoming so important that people are looking for other ways to provide for the developers creating these systems. It can be surprising when a project creator builds something in an area that is usually all open source, but they choose a proprietary path. Just look at the problems created by NVIDIA for their use of proprietary software in CUDA and their GPUs. This software is an attempt to fix issues created by proprietary software with another piece of proprietary software, which is if nothing else an interesting decision.</div><br/><div id="40972196" class="c"><input type="checkbox" id="c-40972196" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971951">parent</a><span>|</span><a href="#40979898">next</a><span>|</span><label class="collapse" for="c-40972196">[-]</label><label class="expand" for="c-40972196">[18 more]</label></div><br/><div class="children"><div class="content">UNIX wasn&#x27;t free. Windows wasn&#x27;t free. It wasn&#x27;t until some knucklehead came along and did something abnormal and gave away their thing. Bakers don&#x27;t give away their goods. Mechanics don&#x27;t typically repair things for free. Builders don&#x27;t build things for free. Gas stations don&#x27;t give away gas.<p>Why do we think all software should be free, and then think that those that don&#x27;t give it away are the abnormal ones?</div><br/><div id="40972674" class="c"><input type="checkbox" id="c-40972674" checked=""/><div class="controls bullet"><span class="by">dTal</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972196">parent</a><span>|</span><a href="#40972456">next</a><span>|</span><label class="collapse" for="c-40972674">[-]</label><label class="expand" for="c-40972674">[8 more]</label></div><br/><div class="children"><div class="content">Because software is information. It is closer to a scientific paper than a loaf of bread, and I do expect those to be free. I do not expect scientists to <i>work</i> for free, but the marginal cost of copying their output is 0 and the social benefit is huge.<p>Free software, like open science, clearly has something going for it pragmatically. The developer hours put into it have paid for themselves magnitudes of times over. Megacorps hire people to work on free software. If you can&#x27;t see the value, that&#x27;s a you problem.</div><br/><div id="40974543" class="c"><input type="checkbox" id="c-40974543" checked=""/><div class="controls bullet"><span class="by">voidUpdate</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972674">parent</a><span>|</span><a href="#40973737">next</a><span>|</span><label class="collapse" for="c-40974543">[-]</label><label class="expand" for="c-40974543">[5 more]</label></div><br/><div class="children"><div class="content">If all software was free and made no money, how could developers pay their bills?</div><br/><div id="40974859" class="c"><input type="checkbox" id="c-40974859" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40974543">parent</a><span>|</span><a href="#40975562">next</a><span>|</span><label class="collapse" for="c-40974859">[-]</label><label class="expand" for="c-40974859">[1 more]</label></div><br/><div class="children"><div class="content">Free software is so important to society that I believe the most reasonable solution is to provide for all people without their need to work for survival. Automate as much as possible such that work is not compulsory, and enough people simply want something to do (and possibly additional pay depending on how the system is arranged) that everything that needs to get done by people does get done.<p>For now that is fiction, but so is &quot;if all software was free&quot;. I do think though that both would lead to a faster rate of innovation in society versus one where critical information is withheld from society to pay someone&#x27;s rent and food bills.</div><br/></div></div><div id="40975562" class="c"><input type="checkbox" id="c-40975562" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40974543">parent</a><span>|</span><a href="#40974859">prev</a><span>|</span><a href="#40973737">next</a><span>|</span><label class="collapse" for="c-40975562">[-]</label><label class="expand" for="c-40975562">[3 more]</label></div><br/><div class="children"><div class="content">Most software is free and makes no money - and that has always been the case. There are some very popular and widely-used non-free systems, but most software isn&#x27;t that, and its developers still pay the bills.<p>This is somewhat analogous to music or books&#x2F;literature. Most composers and performers and authors make no money from people copying and sharing their works. Some pay the bills working professionally for entities who want their product enough to pay for it; some do other things in life. Some indeed give up their work on music because they can&#x27;t afford to not do more gainful work. And still,  neither music nor books go away as copying them gets closer to being free.</div><br/><div id="40975619" class="c"><input type="checkbox" id="c-40975619" checked=""/><div class="controls bullet"><span class="by">voidUpdate</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40975562">parent</a><span>|</span><a href="#40973737">next</a><span>|</span><label class="collapse" for="c-40975619">[-]</label><label class="expand" for="c-40975619">[2 more]</label></div><br/><div class="children"><div class="content">If my current employer can&#x27;t make any money from the code we write, then it would collapse faster than a soufflé taken out of the oven too early, and I would be out of a job</div><br/><div id="40979490" class="c"><input type="checkbox" id="c-40979490" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40975619">parent</a><span>|</span><a href="#40973737">next</a><span>|</span><label class="collapse" for="c-40979490">[-]</label><label class="expand" for="c-40979490">[1 more]</label></div><br/><div class="children"><div class="content">That does not contradict my point... also, there are other ways to make money from writing code than forcing people to pay for copies of that code.</div><br/></div></div></div></div></div></div></div></div><div id="40973737" class="c"><input type="checkbox" id="c-40973737" checked=""/><div class="controls bullet"><span class="by">acuozzo</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972674">parent</a><span>|</span><a href="#40974543">prev</a><span>|</span><a href="#40972456">next</a><span>|</span><label class="collapse" for="c-40973737">[-]</label><label class="expand" for="c-40973737">[2 more]</label></div><br/><div class="children"><div class="content">&gt; the social benefit is huge<p>It will be interesting to see if this is the case in the long run, assuming &quot;huge&quot; has a positive connotation in your post, of course.<p>If AGI comes to pass and it winds up being a net negative for humanity, then the ethics of any practice which involves freely distributing information that can be endlessly copied for very little cost must be reevaluated.</div><br/><div id="40974862" class="c"><input type="checkbox" id="c-40974862" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40973737">parent</a><span>|</span><a href="#40972456">next</a><span>|</span><label class="collapse" for="c-40974862">[-]</label><label class="expand" for="c-40974862">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If AGI comes to pass<p>Increasingly, I am not putting much weight in any predictions about whether this will happen in the way we think it will, or what it could possibly mean. We might as well be talking about the rapture.</div><br/></div></div></div></div></div></div><div id="40972456" class="c"><input type="checkbox" id="c-40972456" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972196">parent</a><span>|</span><a href="#40972674">prev</a><span>|</span><a href="#40972657">next</a><span>|</span><label class="collapse" for="c-40972456">[-]</label><label class="expand" for="c-40972456">[7 more]</label></div><br/><div class="children"><div class="content">&gt; Why do we think all software should be free<p>Why do people return Windows laptops when they have to pay for a Windows License Activation? Because every single OEM pays for it; you don&#x27;t <i>expect</i> to buy Windows because it is a failed B2C business model. Nobody wants it. Same goes for proprietary UNIX, and people <i>wish</i> it was the case for Nvidia drivers. I own CUDA hardware and lament the fact that cross-industry GPGPU died so FAANG could sell licensed AI SDKs. The only thing stopping AI from being &quot;free&quot; is the limitations OEMs impose on their hardware.<p>&gt; that those that don&#x27;t give it away are the abnormal ones?<p>They are. Admit it; the internet is the new normal, if your software isn&#x27;t as &quot;free&quot; as opening a website, you&#x27;re weird. If I have to pay to access your little forum, I won&#x27;t use it. If I have to buy your app to see what it&#x27;s like, I&#x27;ll never know what you&#x27;re offering. Part of what makes Nvidia&#x27;s business model so successful is that they <i>do</i> &quot;give away&quot; CUDA to anyone that owns their hardware. There is no developer fee or mandatory licensing cost, it is plug-and-play with the hardware. Same goes for OpenAI, they&#x27;d have never succeeded if you had to buy &quot;the ChatGPT App&quot; from your App Store.</div><br/><div id="40972605" class="c"><input type="checkbox" id="c-40972605" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972456">parent</a><span>|</span><a href="#40972657">next</a><span>|</span><label class="collapse" for="c-40972605">[-]</label><label class="expand" for="c-40972605">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Why do people return Windows laptops when they have to pay for a Windows License Activation?<p>The internet echo chamber strikes again. Exactly how many people are actually doing this? Not many, and those that are all hangout together. The rest of the world just blindly goes about their day using Windows while surfing the web using Chrome. Sometimes, it&#x27;s a good thing to get outside your bubble. It&#x27;s a big world out there, and not everybody sees the world as you do</div><br/><div id="40972733" class="c"><input type="checkbox" id="c-40972733" checked=""/><div class="controls bullet"><span class="by">talldayo</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972605">parent</a><span>|</span><a href="#40972657">next</a><span>|</span><label class="collapse" for="c-40972733">[-]</label><label class="expand" for="c-40972733">[5 more]</label></div><br/><div class="children"><div class="content">&gt; The rest of the world just blindly goes about their day using Windows while surfing the web using Chrome.<p>Paying for Windows? I think you missed my point. If your computer doesn&#x27;t ship with an OS, paid or otherwise, people think it&#x27;s a glitch. The average consumer will sooner return their laptop before they buy a license of Windows, create an Install Media from their old device and flash the new hardware with a purchased license. They&#x27;ll get a Chromebook instead, people don&#x27;t <i>buy</i> Windows today.<p>The internet has conditioned the majority of modern technology users to reject and habitually avoid non-free experiences. Ad-enabled free platforms and their pervasive success is all the evidence you need. Commercial software as it existed 20 or 30 years ago is a dead business. Free reigns supreme.</div><br/><div id="40973353" class="c"><input type="checkbox" id="c-40973353" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972733">parent</a><span>|</span><a href="#40974311">next</a><span>|</span><label class="collapse" for="c-40973353">[-]</label><label class="expand" for="c-40973353">[3 more]</label></div><br/><div class="children"><div class="content">Who&#x2F;where&#x2F;how does someone buy a laptop without an OS? I&#x27;m just not able to follow down this hypothetical path that you are insisting on blazing</div><br/><div id="40974118" class="c"><input type="checkbox" id="c-40974118" checked=""/><div class="controls bullet"><span class="by">hamilyon2</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40973353">parent</a><span>|</span><a href="#40974311">next</a><span>|</span><label class="collapse" for="c-40974118">[-]</label><label class="expand" for="c-40974118">[2 more]</label></div><br/><div class="children"><div class="content">That is kind of his point. You don&#x27;t, Windows is bundled with laptop. It is not that I agree with his points. Windows for example isn&#x27;t open source in remotest sense</div><br/><div id="40976511" class="c"><input type="checkbox" id="c-40976511" checked=""/><div class="controls bullet"><span class="by">dylan604</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40974118">parent</a><span>|</span><a href="#40974311">next</a><span>|</span><label class="collapse" for="c-40976511">[-]</label><label class="expand" for="c-40976511">[1 more]</label></div><br/><div class="children"><div class="content">Dell offers laptops with a version of Linux preinstalled and supports them. System76, Lenovo, Purism as well to name a few. Apple also sells laptops without Windows on them. There are actually quite a few options that do this. If you don&#x27;t want Windows, we have options now. Yes, historically, it was Windows or Apple&#x27;s OS, but that&#x27;s no longer true and not recognizing that just makes you look like you&#x27;re pushing a false narrative on the situation for what purpose only you know.</div><br/></div></div></div></div></div></div><div id="40974311" class="c"><input type="checkbox" id="c-40974311" checked=""/><div class="controls bullet"><span class="by">alt227</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972733">parent</a><span>|</span><a href="#40973353">prev</a><span>|</span><a href="#40972657">next</a><span>|</span><label class="collapse" for="c-40974311">[-]</label><label class="expand" for="c-40974311">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Commercial software as it existed 20 or 30 years ago is a dead business. Free reigns supreme.<p>What nonsense. Go into any business and you will find every single piece of software they use is bought and paid for with bells on. The &#x27;Free World&#x27; you speak of is only there to get you, an individual, used to using the software so that businesses are made to purchase it. In the old days we called this &#x27;demo&#x27; or &#x27;shareware&#x27;. Now its &#x27;free&#x27; or &#x27;personal&#x27; tier subscription.<p>Go and ask any designer if their copy of Adobe Creative Cloud, 3d studio Max, or AutoCAD is free. Any office worker if Micsrosoft Office(including Teams and Sharedpoint etc) or even google docs for business. Majority of developers are running paid versions of Jetbrains. Running an online shop? Chances are you are paying for shopify software, or something like Zoho to manage your customers and orders.<p>&#x27;Free&#x27; as you put it is very much only in the online individual consumer world, a very small part of the software world.<p>The commercial software market is more alive and expensive than it has ever been.</div><br/></div></div></div></div></div></div></div></div><div id="40972657" class="c"><input type="checkbox" id="c-40972657" checked=""/><div class="controls bullet"><span class="by">TaylorAlexander</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972196">parent</a><span>|</span><a href="#40972456">prev</a><span>|</span><a href="#40974264">next</a><span>|</span><label class="collapse" for="c-40972657">[-]</label><label class="expand" for="c-40972657">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Bakers don&#x27;t give away their goods. Mechanics don&#x27;t typically repair things for free. Builders don&#x27;t build things for free. Gas stations don&#x27;t give away gas.<p>These all have the property which is that they are scarce physical goods or services. Software is not scarce (though of course the labor to create it is), so this is a really bad comparison.<p>And again I did not say it should or should not be free, I said there are engineering benefits to open source software and more and more people recognize those benefits and choose to make things free because they see the value and are willing to recognize the tradeoffs. I never said what &quot;should&quot; be done. &quot;Should&quot; is kind of a nonsense term when used in this way as it hides a lot of assumptions, so I generally do not use it, and notably did not use it in my comment. I want to point out the peculiarity in your rather strong response to a word and concept I never used. I think you are having an argument with imagined people, not a discussion with me.<p>And for what it is worth, I am a robotics engineer and I am designing a completely open source solar powered farming robot designed to be made in a small shop in any city in the world (see my profile), funded by a wealthy robotics entrepreneur who recognizes the value in making this technology available to people all over the world.<p>So I am one of those engineers making this choice, and not someone just asking for things without doing the same of my work. Everything I produce is open source, including person projects and even my personal writing.</div><br/></div></div><div id="40974264" class="c"><input type="checkbox" id="c-40974264" checked=""/><div class="controls bullet"><span class="by">napoleongl</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972196">parent</a><span>|</span><a href="#40972657">prev</a><span>|</span><a href="#40979898">next</a><span>|</span><label class="collapse" for="c-40974264">[-]</label><label class="expand" for="c-40974264">[1 more]</label></div><br/><div class="children"><div class="content">Otoh recepies and drawings are commonly available for free. So if you can support yourself the cake and engine repair is free. But if you need support then you can get someone to bake or build for you.</div><br/></div></div></div></div></div></div></div></div><div id="40979898" class="c"><input type="checkbox" id="c-40979898" checked=""/><div class="controls bullet"><span class="by">nicce</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971275">parent</a><span>|</span><a href="#40971615">prev</a><span>|</span><a href="#40970955">next</a><span>|</span><label class="collapse" for="c-40979898">[-]</label><label class="expand" for="c-40979898">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Makes sense to expect this kind of thing to be open source. The whole point of providing improved compatibility is to make people’s lives easier, and open source is usually an important feature to ensure wide compatibility. It also means projects can live on after the creator<p>AMD just bought company working with similar things for more than 600m.</div><br/></div></div></div></div><div id="40970955" class="c"><input type="checkbox" id="c-40970955" checked=""/><div class="controls bullet"><span class="by">tempaccount420</span><span>|</span><a href="#40970701">parent</a><span>|</span><a href="#40971275">prev</a><span>|</span><a href="#40971037">next</a><span>|</span><label class="collapse" for="c-40970955">[-]</label><label class="expand" for="c-40970955">[1 more]</label></div><br/><div class="children"><div class="content">They might be hoping to be acquired by AMD</div><br/></div></div><div id="40971037" class="c"><input type="checkbox" id="c-40971037" checked=""/><div class="controls bullet"><span class="by">msond</span><span>|</span><a href="#40970701">parent</a><span>|</span><a href="#40970955">prev</a><span>|</span><a href="#40971555">next</a><span>|</span><label class="collapse" for="c-40971037">[-]</label><label class="expand" for="c-40971037">[9 more]</label></div><br/><div class="children"><div class="content">We&#x27;re going to be publishing more details on later blog posts and documentation about how this works and how we&#x27;ve built it.<p>Yes, we&#x27;re not open source, however our license is very permissive. It&#x27;s both in the software distribution and viewable online at <a href="https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;licensing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;licensing&#x2F;</a></div><br/><div id="40971530" class="c"><input type="checkbox" id="c-40971530" checked=""/><div class="controls bullet"><span class="by">breck</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971037">parent</a><span>|</span><a href="#40971555">next</a><span>|</span><label class="collapse" for="c-40971530">[-]</label><label class="expand" for="c-40971530">[8 more]</label></div><br/><div class="children"><div class="content">How about trying _Early_ Source?<p>It&#x27;s open source with a long delay, but paying users get the latest updates.<p>Make the git repo from &quot;today - N years&quot; open source, where N is something like 1 or 2.<p>That way, students can learn on old versions, and when they grow into professionals they can pay for access to the cutting Edge builds.<p>Win win win win<p>( <a href="https:&#x2F;&#x2F;breckyunits.com&#x2F;earlySource.html" rel="nofollow">https:&#x2F;&#x2F;breckyunits.com&#x2F;earlySource.html</a>)</div><br/><div id="40971828" class="c"><input type="checkbox" id="c-40971828" checked=""/><div class="controls bullet"><span class="by">msond</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971530">parent</a><span>|</span><a href="#40971555">next</a><span>|</span><label class="collapse" for="c-40971828">[-]</label><label class="expand" for="c-40971828">[7 more]</label></div><br/><div class="children"><div class="content">We&#x27;re still thinking about our approach but this is a nice suggestion, thank you.<p>I&#x27;m curious, for what reasons are you interested in the source code yourself?</div><br/><div id="40971916" class="c"><input type="checkbox" id="c-40971916" checked=""/><div class="controls bullet"><span class="by">mindcrime</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971828">parent</a><span>|</span><a href="#40971959">next</a><span>|</span><label class="collapse" for="c-40971916">[-]</label><label class="expand" for="c-40971916">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not the person you replied to, and I can&#x27;t speak for them. But I can say that for myself, and a not small number of other people, it&#x27;s an ideological issue. I simply do not use software that isn&#x27;t F&#x2F;OSS - to the greatest extent that that is possible. For me, I might use a VERY small amount of non F&#x2F;OSS stuff, but it&#x27;s very hard to get me to adopt something new if it isn&#x27;t.<p>Now should you make business decisions based on that? Probably not. But while I don&#x27;t claim to be a representative sample, I am pretty sure the number of people who share my beliefs in this regard is substantially &quot;non zero&quot;. <i>shrug</i></div><br/></div></div><div id="40971959" class="c"><input type="checkbox" id="c-40971959" checked=""/><div class="controls bullet"><span class="by">atq2119</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971828">parent</a><span>|</span><a href="#40971916">prev</a><span>|</span><a href="#40972368">next</a><span>|</span><label class="collapse" for="c-40971959">[-]</label><label class="expand" for="c-40971959">[1 more]</label></div><br/><div class="children"><div class="content">Not GP, but a guaranteed source availability means users can fix issues themselves in the future if the original provider goes belly-up.</div><br/></div></div><div id="40972368" class="c"><input type="checkbox" id="c-40972368" checked=""/><div class="controls bullet"><span class="by">idonotknowwhy</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971828">parent</a><span>|</span><a href="#40971959">prev</a><span>|</span><a href="#40971991">next</a><span>|</span><label class="collapse" for="c-40972368">[-]</label><label class="expand" for="c-40972368">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a big fan of opensource for most things but if what you&#x27;ve got actually works, you could probably earn big money selling it. The biggest companies in the world are building &#x2F; using this sort of thing.<p>Imagine the shift of capital if for example, Intel GPUS suddenly had the same ML software compatibility as Nvidia</div><br/></div></div><div id="40971991" class="c"><input type="checkbox" id="c-40971991" checked=""/><div class="controls bullet"><span class="by">breck</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971828">parent</a><span>|</span><a href="#40972368">prev</a><span>|</span><a href="#40971555">next</a><span>|</span><label class="collapse" for="c-40971991">[-]</label><label class="expand" for="c-40971991">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m curious, for what reasons are you interested in the source code yourself?<p>I am the founder&#x2F;editor of PLDB. So I try to do my best to help people &quot;build the next great programming language&quot;.<p>We clone the git repos of over 1,000 compilers and interpreters and use cloc to determine what languages the people who are building languages are using. The people who build languages obviously are the experts, so how they go so goes the world.<p>We call this measurement &quot;Foundation Score&quot;. A Foundation Score of 100 means 100 other languages uses this language somehow in their primary implementation.<p>It is utterly dominated by open source languages, and the disparity is only getting more extreme.<p>You can see for yourself here:<p><a href="https:&#x2F;&#x2F;pldb.io&#x2F;lists&#x2F;explorer.html#columns=rank~name~id~appeared~tags~creators~foundationScore~isOpenSource" rel="nofollow">https:&#x2F;&#x2F;pldb.io&#x2F;lists&#x2F;explorer.html#columns=rank~name~id~app...</a><p>Some that might have become irrelevant have gained a second wind after going open source.<p>But some keep falling further behind.<p>I look at Mathematica, a very powerful and amazing language, and it makes me sad to see so few other language designers using it, and the reason is because its closed source. So they are not doing so hot, and that&#x27;s a language from one of our world&#x27;s smartest and most prolific thinkers that&#x27;s been around for decades.<p>I don&#x27;t see a way for a new language to catch on nowadays that is not open source.</div><br/><div id="40972366" class="c"><input type="checkbox" id="c-40972366" checked=""/><div class="controls bullet"><span class="by">msond</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971991">parent</a><span>|</span><a href="#40971555">next</a><span>|</span><label class="collapse" for="c-40972366">[-]</label><label class="expand" for="c-40972366">[2 more]</label></div><br/><div class="children"><div class="content">Very interesting, thank you for sharing!<p>We do believe in open source software and we do want to move the GPGPU market away from fully closed languages. The future is open for discussion but regardless, the status-quo at the moment is a proprietary and dominant implementation which only supports a single vendor.<p>&gt; I don&#x27;t see a way for a new language to catch on nowadays that is not open source.<p>I do note that CUDA is itself closed source -- while there&#x27;s an open source implementation in the LLVM project, it is not as bleeding edge as NVIDIA&#x27;s own.</div><br/><div id="40972624" class="c"><input type="checkbox" id="c-40972624" checked=""/><div class="controls bullet"><span class="by">breck</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972366">parent</a><span>|</span><a href="#40971555">next</a><span>|</span><label class="collapse" for="c-40972624">[-]</label><label class="expand" for="c-40972624">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I do note that CUDA is itself closed source<p>And this is a good point. However, it also has a 17 year head start, and many of those years were spent developing before people realized what a huge market there was.<p>All it will take is one committed genius to create an open source alternative to CUDA to dethrone it.<p>But they would have to have some Mojo (hint hint) to pull that off.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40971555" class="c"><input type="checkbox" id="c-40971555" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#40970701">parent</a><span>|</span><a href="#40971037">prev</a><span>|</span><a href="#40970958">next</a><span>|</span><label class="collapse" for="c-40971555">[-]</label><label class="expand" for="c-40971555">[11 more]</label></div><br/><div class="children"><div class="content">Also, can I even buy an AMD GPU? I don&#x27;t see a &quot;buy now&quot; button or a PCIe version anywhere here<p><a href="https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;products&#x2F;accelerators&#x2F;instinct&#x2F;mi300&#x2F;mi300x.html" rel="nofollow">https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;products&#x2F;accelerators&#x2F;instinct&#x2F;mi300&#x2F;...</a><p>Another big AMD fuckup in my opinion. Nobody is going to drop millions on these things without being able to test them out first.<p>First rule of sales: If you have something for sale, take my money.</div><br/><div id="40972012" class="c"><input type="checkbox" id="c-40972012" checked=""/><div class="controls bullet"><span class="by">nwiswell</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40971555">parent</a><span>|</span><a href="#40970958">next</a><span>|</span><label class="collapse" for="c-40972012">[-]</label><label class="expand" for="c-40972012">[10 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t see a &quot;buy now&quot; button or a PCIe version anywhere here<p>&quot;Buy now&quot; buttons and online shopping carts are not generally how organizations looking to spend serious money on AI buy their hardware.<p>They have a long list of server hardware partners, and odds are you&#x27;d already have an existing relationship with one or more of them, and they&#x27;d provide a quote.<p>They even go one step further and show off some of their partners&#x27; solutions:<p><a href="https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;graphics&#x2F;servers-instinct-deep-learning" rel="nofollow">https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;graphics&#x2F;servers-instinct-deep-learni...</a><p>FWIW I believe Supermicro and Exxact actually do have web-based shopping carts these days, so maybe you could skip the quotation and buy directly if you were so motivated? Seems kind of weird at this price point.<p><a href="https:&#x2F;&#x2F;www.exxactcorp.com&#x2F;Exxact-TS4-185328443-E185328443" rel="nofollow">https:&#x2F;&#x2F;www.exxactcorp.com&#x2F;Exxact-TS4-185328443-E185328443</a></div><br/><div id="40972189" class="c"><input type="checkbox" id="c-40972189" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972012">parent</a><span>|</span><a href="#40970958">next</a><span>|</span><label class="collapse" for="c-40972189">[-]</label><label class="expand" for="c-40972189">[9 more]</label></div><br/><div class="children"><div class="content">... and that&#x27;s why AMD is losing.<p>They could break the trend and offer a &quot;buy now&quot; button instead of offering quotes and coffee chats. It&#x27;s very likely that will kickstart the software snowball with early adopters.<p>Nobody is going to drop millions on an unproven platform.<p>&gt; Seems kind of weird at this price point.<p>Yeah that $234K server is too much for people to do a trial. It has 8xMI300X GPUs along with a bunch of other shit.<p>Give me a single MI300X GPU in PCIe form factor for $20K and I&#x27;d very seriously consider. I&#x27;m sure there are many people who would help adapt the ecosystem if they were truly available.</div><br/><div id="40973977" class="c"><input type="checkbox" id="c-40973977" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972189">parent</a><span>|</span><a href="#40972475">next</a><span>|</span><label class="collapse" for="c-40973977">[-]</label><label class="expand" for="c-40973977">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Give me a single MI300X GPU in PCIe form factor for $20K and I&#x27;d very seriously consider. I&#x27;m sure there are many people who would help adapt the ecosystem if they were truly available.</i><p>I know this isn&#x27;t what you&#x27;re looking for entirely, but my business, Hot Aisle, is working on making MI300x available for rental. Our pricing isn&#x27;t too crazy given that the GPU has 192GB and one week minimum isn&#x27;t too bad. We will add on-demand hourly pricing as soon as we technically can.<p>I&#x27;m also pushing hard on Dell and AMD to pre-purchase developer credits on our hardware, that we can then give away to people who want to &quot;kick the tires&quot;.<p><a href="https:&#x2F;&#x2F;hotaisle.xyz&#x2F;pricing&#x2F;" rel="nofollow">https:&#x2F;&#x2F;hotaisle.xyz&#x2F;pricing&#x2F;</a></div><br/></div></div><div id="40972475" class="c"><input type="checkbox" id="c-40972475" checked=""/><div class="controls bullet"><span class="by">nwiswell</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972189">parent</a><span>|</span><a href="#40973977">prev</a><span>|</span><a href="#40970958">next</a><span>|</span><label class="collapse" for="c-40972475">[-]</label><label class="expand" for="c-40972475">[7 more]</label></div><br/><div class="children"><div class="content">Why would you be looking to dip your toe into the AMD ecosystem for the first time using an MI300X? It doesn&#x27;t make any sense. It&#x27;s not entry level hardware.</div><br/><div id="40972484" class="c"><input type="checkbox" id="c-40972484" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972475">parent</a><span>|</span><a href="#40970958">next</a><span>|</span><label class="collapse" for="c-40972484">[-]</label><label class="expand" for="c-40972484">[6 more]</label></div><br/><div class="children"><div class="content">To help fix the ecosystem. It&#x27;s way more affordable than Nvidia.<p>I&#x27;m not looking for entry level hardware.</div><br/><div id="40972502" class="c"><input type="checkbox" id="c-40972502" checked=""/><div class="controls bullet"><span class="by">nwiswell</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972484">parent</a><span>|</span><a href="#40970958">next</a><span>|</span><label class="collapse" for="c-40972502">[-]</label><label class="expand" for="c-40972502">[5 more]</label></div><br/><div class="children"><div class="content">Yes, that&#x27;s why you&#x27;d choose AMD, I&#x27;m saying that you don&#x27;t enter the ecosystem for the first time by purchasing the absolute cutting edge hardware.<p>As far as I&#x27;m aware you can&#x27;t simply buy an Nvidia B200 PCIe card over the counter, either.</div><br/><div id="40972551" class="c"><input type="checkbox" id="c-40972551" checked=""/><div class="controls bullet"><span class="by">dheera</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972502">parent</a><span>|</span><a href="#40970958">next</a><span>|</span><label class="collapse" for="c-40972551">[-]</label><label class="expand" for="c-40972551">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not looking to enter the ecosystem, I&#x27;m already deep in it and want to fix the AMD problem so that I can build big projects around it and undercut everyone who&#x27;s using Nvidia.<p>You can purchase H100 and A100 PCIe cards over the counter. They&#x27;re great for compiling CUDA code, testing code before you launch a multi-node job into a cluster, and for running evaluations.<p>AMD has nothing of the sort, and it&#x27;s hurting them.<p>I cannot blow 250K on an SMCI server, nor do I have the electricity setup for it. I <i>can</i> blow 20K on a PCIe GPU and start contributing to the ecosystem, or maybe prove out an idea on one GPU before trying to raise millions from a VC to build a more cost-effective datacenter that actually works.</div><br/><div id="40972580" class="c"><input type="checkbox" id="c-40972580" checked=""/><div class="controls bullet"><span class="by">nwiswell</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972551">parent</a><span>|</span><a href="#40973696">next</a><span>|</span><label class="collapse" for="c-40972580">[-]</label><label class="expand" for="c-40972580">[1 more]</label></div><br/><div class="children"><div class="content">&gt; AMD has nothing of the sort, and it&#x27;s hurting them.<p>What are you talking about? Have you looked?<p><a href="https:&#x2F;&#x2F;www.dell.com&#x2F;en-us&#x2F;shop&#x2F;amd-mi210-300w-pcie-64gb-passive-double-wide-full-height-gpu-customer-install&#x2F;apd&#x2F;490-bhur&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.dell.com&#x2F;en-us&#x2F;shop&#x2F;amd-mi210-300w-pcie-64gb-pas...</a><p><a href="https:&#x2F;&#x2F;www.bitworks.io&#x2F;product&#x2F;amd-instinct-mi210-64gb-hbm2e-graphics-card-2x-slot-pcie-passive-cooling&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.bitworks.io&#x2F;product&#x2F;amd-instinct-mi210-64gb-hbm2...</a></div><br/></div></div><div id="40973696" class="c"><input type="checkbox" id="c-40973696" checked=""/><div class="controls bullet"><span class="by">shaklee3</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40972551">parent</a><span>|</span><a href="#40972580">prev</a><span>|</span><a href="#40970958">next</a><span>|</span><label class="collapse" for="c-40973696">[-]</label><label class="expand" for="c-40973696">[2 more]</label></div><br/><div class="children"><div class="content">A 20k GPU will be passively cooled and you&#x27;ll need a real server for that. Even the old MI210 another poster sent is passive.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="40970958" class="c"><input type="checkbox" id="c-40970958" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#40970701">parent</a><span>|</span><a href="#40971555">prev</a><span>|</span><a href="#40970890">next</a><span>|</span><label class="collapse" for="c-40970958">[-]</label><label class="expand" for="c-40970958">[2 more]</label></div><br/><div class="children"><div class="content">They&#x27;re using Docusaurus[1] for their website, which is most commonly used with open source projects.<p><a href="https:&#x2F;&#x2F;docusaurus.io&#x2F;docs" rel="nofollow">https:&#x2F;&#x2F;docusaurus.io&#x2F;docs</a></div><br/><div id="40971016" class="c"><input type="checkbox" id="c-40971016" checked=""/><div class="controls bullet"><span class="by">msond</span><span>|</span><a href="#40970701">root</a><span>|</span><a href="#40970958">parent</a><span>|</span><a href="#40970890">next</a><span>|</span><label class="collapse" for="c-40971016">[-]</label><label class="expand" for="c-40971016">[1 more]</label></div><br/><div class="children"><div class="content">Actually, we use mkdocs and the excellent material for mkdocs theme: <a href="https:&#x2F;&#x2F;squidfunk.github.io&#x2F;mkdocs-material&#x2F;" rel="nofollow">https:&#x2F;&#x2F;squidfunk.github.io&#x2F;mkdocs-material&#x2F;</a></div><br/></div></div></div></div></div></div><div id="40970890" class="c"><input type="checkbox" id="c-40970890" checked=""/><div class="controls bullet"><span class="by">resters</span><span>|</span><a href="#40970701">prev</a><span>|</span><a href="#40970716">next</a><span>|</span><label class="collapse" for="c-40970890">[-]</label><label class="expand" for="c-40970890">[21 more]</label></div><br/><div class="children"><div class="content">The main cause of Nvidia&#x27;s crazy valuation is AMD&#x27;s unwillingness to invest in making its GPUs as useful as Nvidia&#x27;s for ML.<p>Maybe AMD fears antitrust action, or maybe there is something about its underlying hardware approach that would limit competitiveness, but the company seems to have left billions of dollars on the table during the crypto mining GPU demand spike and now during the AI boom demand spike.</div><br/><div id="40971118" class="c"><input type="checkbox" id="c-40971118" checked=""/><div class="controls bullet"><span class="by">karolist</span><span>|</span><a href="#40970890">parent</a><span>|</span><a href="#40979656">next</a><span>|</span><label class="collapse" for="c-40971118">[-]</label><label class="expand" for="c-40971118">[9 more]</label></div><br/><div class="children"><div class="content">I think this could be cultural differences, AMD&#x27;s software department is underfunded and doing poorly for a long time now.<p>* <a href="https:&#x2F;&#x2F;www.levels.fyi&#x2F;companies&#x2F;amd&#x2F;salaries&#x2F;software-engineer?country=254" rel="nofollow">https:&#x2F;&#x2F;www.levels.fyi&#x2F;companies&#x2F;amd&#x2F;salaries&#x2F;software-engin...</a><p>* <a href="https:&#x2F;&#x2F;www.levels.fyi&#x2F;companies&#x2F;nvidia&#x2F;salaries&#x2F;software-engineer?country=254" rel="nofollow">https:&#x2F;&#x2F;www.levels.fyi&#x2F;companies&#x2F;nvidia&#x2F;salaries&#x2F;software-en...</a><p>And it&#x27;s probably better now. Nvidia was paying much more long before, also their stock growing attracts even more talent.</div><br/><div id="40971146" class="c"><input type="checkbox" id="c-40971146" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40971118">parent</a><span>|</span><a href="#40973012">next</a><span>|</span><label class="collapse" for="c-40971146">[-]</label><label class="expand" for="c-40971146">[7 more]</label></div><br/><div class="children"><div class="content">&gt; I think this could be cultural differences, AMD&#x27;s software department is underfunded and doing poorly for a long time now.<p>Rumor is that ML engineers (that AMD really needs) are expensive; and AMD doesn&#x27;t want to give them more money than the rest of the SWEs they have (for pissing off the existing SWEs). So AMD is caught in a bind: can&#x27;t pay to get top MLE talent and can&#x27;t just sit by and watch NVDA eat its lunch.</div><br/><div id="40972587" class="c"><input type="checkbox" id="c-40972587" checked=""/><div class="controls bullet"><span class="by">xboxnolifes</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40971146">parent</a><span>|</span><a href="#40971288">next</a><span>|</span><label class="collapse" for="c-40972587">[-]</label><label class="expand" for="c-40972587">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So AMD is caught in a bind: can&#x27;t pay to get top MLE talent and can&#x27;t just sit by and watch NVDA eat its lunch.<p>This isn&#x27;t being caught in a bind. This is, if true, just making a poor decision. Nothing is <i>really</i> preventing them from paying more for specialized work.</div><br/></div></div><div id="40971288" class="c"><input type="checkbox" id="c-40971288" checked=""/><div class="controls bullet"><span class="by">karolist</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40971146">parent</a><span>|</span><a href="#40972587">prev</a><span>|</span><a href="#40971205">next</a><span>|</span><label class="collapse" for="c-40971288">[-]</label><label class="expand" for="c-40971288">[3 more]</label></div><br/><div class="children"><div class="content">I find this strange to believe. Every big company has levels, unless your existing L7+ IC is below market, you can just pull L7+ salaried ML engineers with some secret signing bonus like literally everyone else.</div><br/><div id="40971955" class="c"><input type="checkbox" id="c-40971955" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40971288">parent</a><span>|</span><a href="#40971205">next</a><span>|</span><label class="collapse" for="c-40971955">[-]</label><label class="expand" for="c-40971955">[2 more]</label></div><br/><div class="children"><div class="content">The dirty secret in the tech industry is that most people at AMD or Intel or IBM and historically Nvidia&#x2F;Oracle (this changed post 2022), were the 2nd-3rd tier tech companies. Staffed heavily by the rejects of the FAANG, they were still happy to have their 100-200K in their MCOL areas, but no free food and a much more boring work culture. Intel&#x27;s &quot;great place to work&quot; corporate propaganda was known as &quot;great place to leetcode&quot; while I worked there, as Intel was always seen as a stepping stone before you &quot;made it&quot; in a FAANG.<p>Culturally, none of these companies were happy to pay anyone except the tip, top &quot;distinguished&quot; engineers more than 300K. AMD seems to be stuck in this mentality, just as IBM is.</div><br/><div id="40977010" class="c"><input type="checkbox" id="c-40977010" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40971955">parent</a><span>|</span><a href="#40971205">next</a><span>|</span><label class="collapse" for="c-40977010">[-]</label><label class="expand" for="c-40977010">[1 more]</label></div><br/><div class="children"><div class="content">&gt; AMD seems to be stuck in this mentality, just as IBM is.<p>And that&#x27;s why creative destruction is essential for technological progress. It&#x27;s common for organizations to get stuck in stable-but-suboptimal social equilibria: everyone knows there&#x27;s a problem but nobody can fix it. The only way out is to make a new organization and let the old one die.</div><br/></div></div></div></div></div></div><div id="40971205" class="c"><input type="checkbox" id="c-40971205" checked=""/><div class="controls bullet"><span class="by">mepian</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40971146">parent</a><span>|</span><a href="#40971288">prev</a><span>|</span><a href="#40972504">next</a><span>|</span><label class="collapse" for="c-40971205">[-]</label><label class="expand" for="c-40971205">[1 more]</label></div><br/><div class="children"><div class="content">AMD recently acquired Silo AI.</div><br/></div></div></div></div><div id="40973012" class="c"><input type="checkbox" id="c-40973012" checked=""/><div class="controls bullet"><span class="by">DaoVeles</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40971118">parent</a><span>|</span><a href="#40971146">prev</a><span>|</span><a href="#40979656">next</a><span>|</span><label class="collapse" for="c-40973012">[-]</label><label class="expand" for="c-40973012">[1 more]</label></div><br/><div class="children"><div class="content">So nothing has changed since the era of ATI.</div><br/></div></div></div></div><div id="40979656" class="c"><input type="checkbox" id="c-40979656" checked=""/><div class="controls bullet"><span class="by">anticensor</span><span>|</span><a href="#40970890">parent</a><span>|</span><a href="#40971118">prev</a><span>|</span><a href="#40971144">next</a><span>|</span><label class="collapse" for="c-40979656">[-]</label><label class="expand" for="c-40979656">[1 more]</label></div><br/><div class="children"><div class="content">AMD fears anti-collusion action, remember, CEOs of the two are just barely far enough of kinship to not be automatically considered colluding with each other.</div><br/></div></div><div id="40971144" class="c"><input type="checkbox" id="c-40971144" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#40970890">parent</a><span>|</span><a href="#40979656">prev</a><span>|</span><a href="#40972164">next</a><span>|</span><label class="collapse" for="c-40971144">[-]</label><label class="expand" for="c-40971144">[2 more]</label></div><br/><div class="children"><div class="content">There are stories from credible sources that AMD software engineers had to buy AMD GPUs with their own money to use in CI machines.</div><br/></div></div><div id="40972164" class="c"><input type="checkbox" id="c-40972164" checked=""/><div class="controls bullet"><span class="by">ClassyJacket</span><span>|</span><a href="#40970890">parent</a><span>|</span><a href="#40971144">prev</a><span>|</span><a href="#40972828">next</a><span>|</span><label class="collapse" for="c-40972164">[-]</label><label class="expand" for="c-40972164">[6 more]</label></div><br/><div class="children"><div class="content">I like to watch YouTube retrospectives on old failed tech companies - LGR has some good ones.<p>When I think of AMD ignoring machine learning, I can&#x27;t help imagine a future YouTuber&#x27;s voiceover explaining how this caused their downfall.<p>There&#x27;s a tendency sometimes to think &quot;they know what they&#x27;re doing, they must have good reasons&quot;. And sometimes that&#x27;s right, and sometimes that&#x27;s wrong. Perhaps there&#x27;s some great technical, legal, or economic reason I&#x27;m just not aware of. But when you actually look into these things, it&#x27;s surprising how often the answer is indeed just shortsightedness.<p>They could end up like BlackBerry, Blockbuster, Nokia, and Kodak. I guess it&#x27;s not quite as severe, since they will still have a market in games and therefore may well continue to exist, but it will still be looked back on as a colossal mistake.<p>Same with Toyota ignoring electric cars.<p>I&#x27;m not an investor, but I still have stakes in the sense that Nvidia has no significant competition in the machine learning space, and that sucks. GPU prices are sky high and there&#x27;s nobody else to turn to if there&#x27;s something about Nvidia you just don&#x27;t like or if they decide to screw us.</div><br/><div id="40977032" class="c"><input type="checkbox" id="c-40977032" checked=""/><div class="controls bullet"><span class="by">hedora</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40972164">parent</a><span>|</span><a href="#40979090">next</a><span>|</span><label class="collapse" for="c-40977032">[-]</label><label class="expand" for="c-40977032">[1 more]</label></div><br/><div class="children"><div class="content">In fairness to AMD, they bet on crypto, and nvidia bet on AI.  Crypto was the right short term bet.<p>Also, ignoring is a strong word:  I’m staring at a little &lt;&lt; $1000, silent 53 watt mini-PC with an AMD SoC.  It has an NPU comparable to an M1.  In a few months, with the ryzen 9000 series, NPUs for devices of its class will bump from 16 tops to 50 tops.<p>I’m pretty sure the linux taint bit is off, and everything just worked out of the box.</div><br/></div></div><div id="40979090" class="c"><input type="checkbox" id="c-40979090" checked=""/><div class="controls bullet"><span class="by">daedrdev</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40972164">parent</a><span>|</span><a href="#40977032">prev</a><span>|</span><a href="#40976078">next</a><span>|</span><label class="collapse" for="c-40979090">[-]</label><label class="expand" for="c-40979090">[1 more]</label></div><br/><div class="children"><div class="content">Toyota is extremely strong in the hybrid car market, and with ravenous competition for electric cars and slowing demand Toyota may have made the right decision after all</div><br/></div></div><div id="40976078" class="c"><input type="checkbox" id="c-40976078" checked=""/><div class="controls bullet"><span class="by">robertlagrant</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40972164">parent</a><span>|</span><a href="#40979090">prev</a><span>|</span><a href="#40976232">next</a><span>|</span><label class="collapse" for="c-40976078">[-]</label><label class="expand" for="c-40976078">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also just the idea of endeavour - Nvidia tried something, and it worked. Businesses (or rather their shareholders) take risks with their capital sometimes, and it doesn&#x27;t always work. But in this case it did.</div><br/><div id="40980978" class="c"><input type="checkbox" id="c-40980978" checked=""/><div class="controls bullet"><span class="by">robocat</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40976078">parent</a><span>|</span><a href="#40976232">next</a><span>|</span><label class="collapse" for="c-40980978">[-]</label><label class="expand" for="c-40980978">[1 more]</label></div><br/><div class="children"><div class="content">And NVidea has a reputation for going all-in on certain market decisions. That is hard to compete against when the bet works.</div><br/></div></div></div></div><div id="40976232" class="c"><input type="checkbox" id="c-40976232" checked=""/><div class="controls bullet"><span class="by">_boffin_</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40972164">parent</a><span>|</span><a href="#40976078">prev</a><span>|</span><a href="#40972828">next</a><span>|</span><label class="collapse" for="c-40976232">[-]</label><label class="expand" for="c-40976232">[1 more]</label></div><br/><div class="children"><div class="content">If you haven’t heard of this book, you might like it. Dealers of lightening</div><br/></div></div></div></div><div id="40972828" class="c"><input type="checkbox" id="c-40972828" checked=""/><div class="controls bullet"><span class="by">gukov</span><span>|</span><a href="#40970890">parent</a><span>|</span><a href="#40972164">prev</a><span>|</span><a href="#40970716">next</a><span>|</span><label class="collapse" for="c-40972828">[-]</label><label class="expand" for="c-40972828">[2 more]</label></div><br/><div class="children"><div class="content">The companies&#x27; CEO&#x27;s are related. My conspiracy theory is that they don&#x27;t want to step on each other&#x27;s toes. Not sure if that works with fiduciary duty, though.</div><br/><div id="40974399" class="c"><input type="checkbox" id="c-40974399" checked=""/><div class="controls bullet"><span class="by">arendtio</span><span>|</span><a href="#40970890">root</a><span>|</span><a href="#40972828">parent</a><span>|</span><a href="#40970716">next</a><span>|</span><label class="collapse" for="c-40974399">[-]</label><label class="expand" for="c-40974399">[1 more]</label></div><br/><div class="children"><div class="content">I searched for it and found this (in case someone else might want to read it):<p><a href="https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;jensen-huang-and-lisa-su-family-tree-shows-how-closely-they-are-related" rel="nofollow">https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;jensen-huang-and-lisa-su-f...</a></div><br/></div></div></div></div></div></div><div id="40970716" class="c"><input type="checkbox" id="c-40970716" checked=""/><div class="controls bullet"><span class="by">Straw</span><span>|</span><a href="#40970890">prev</a><span>|</span><a href="#40970704">next</a><span>|</span><label class="collapse" for="c-40970716">[-]</label><label class="expand" for="c-40970716">[1 more]</label></div><br/><div class="children"><div class="content">I worked for spectral compute a few years ago. Very smart and capable technical team.<p>At the time, not only did they target AMD (with less compatibility than they have now), but also outperformed the default LLVM ptx backend, and even NVCC, when compiling for Nvidia GPUs!</div><br/></div></div><div id="40970704" class="c"><input type="checkbox" id="c-40970704" checked=""/><div class="controls bullet"><span class="by">juujian</span><span>|</span><a href="#40970716">prev</a><span>|</span><a href="#40983368">next</a><span>|</span><label class="collapse" for="c-40970704">[-]</label><label class="expand" for="c-40970704">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand how AMD has messed up so badly that I feel like celebrating a project like this. Features of my laptop are just physically there but not usable, particularly in Linux. So frustrating.</div><br/><div id="40971670" class="c"><input type="checkbox" id="c-40971670" checked=""/><div class="controls bullet"><span class="by">jeroenhd</span><span>|</span><a href="#40970704">parent</a><span>|</span><a href="#40971212">next</a><span>|</span><label class="collapse" for="c-40971670">[-]</label><label class="expand" for="c-40971670">[2 more]</label></div><br/><div class="children"><div class="content">AMD hardware works fine, the problem is that the major research projects everyone copies are all developed specifically for Nvidia.<p>Now AMD is spinning up CUDA compatibility layer after CUDA compatibility layer. It&#x27;s like trying to beat Windows by building another ReactOS&#x2F;Wine. It&#x27;s an approach doomed to fail unless AMD somehow manages to gain vastly more resources than the competition.<p>Apple&#x27;s NPU may not be very powerful, but many models have been altered specifically to run on them, making their NPUs vastly more useful than most equivalently powerful iGPUs. AMD doesn&#x27;t have that just yet, they&#x27;re always catching up.<p>It&#x27;ll be interesting to see what Qualcomm will do to get developers to make use of their NPUs on the new laptop chips.</div><br/><div id="40971902" class="c"><input type="checkbox" id="c-40971902" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40970704">root</a><span>|</span><a href="#40971670">parent</a><span>|</span><a href="#40971212">next</a><span>|</span><label class="collapse" for="c-40971902">[-]</label><label class="expand" for="c-40971902">[1 more]</label></div><br/><div class="children"><div class="content">Interesting analogy. The last few programs from the windows world I tried to run were flawless under wine and abjectly failed under windows 11.</div><br/></div></div></div></div><div id="40971212" class="c"><input type="checkbox" id="c-40971212" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#40970704">parent</a><span>|</span><a href="#40971670">prev</a><span>|</span><a href="#40970830">next</a><span>|</span><label class="collapse" for="c-40971212">[-]</label><label class="expand" for="c-40971212">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know if I would call it a mess up. AMD still has massive market in server chips, and their ARM stuff is on the horizon. We all assume that graphics cards are the way forward for ML, which may not be the case in the future.<p>Nvidia were just ahead in this particular category due to CUDA, so AMD may have just let them run with it for now.</div><br/></div></div><div id="40970830" class="c"><input type="checkbox" id="c-40970830" checked=""/><div class="controls bullet"><span class="by">djbusby</span><span>|</span><a href="#40970704">parent</a><span>|</span><a href="#40971212">prev</a><span>|</span><a href="#40983368">next</a><span>|</span><label class="collapse" for="c-40970830">[-]</label><label class="expand" for="c-40970830">[1 more]</label></div><br/><div class="children"><div class="content">Same boat, AMD CPU but nothing else. I feel like a moderate improvement of their FOSS support, drivers would open new hardware revenue - to say nothing about the AI channel.</div><br/></div></div></div></div><div id="40983368" class="c"><input type="checkbox" id="c-40983368" checked=""/><div class="controls bullet"><span class="by">qeternity</span><span>|</span><a href="#40970704">prev</a><span>|</span><a href="#40971094">next</a><span>|</span><label class="collapse" for="c-40983368">[-]</label><label class="expand" for="c-40983368">[1 more]</label></div><br/><div class="children"><div class="content">The future is inference. Many inference stacks already support AMD although the kernels are less optimized. This will of course change over time, but if AMD can crack the inference demand, it will put NVDA under huge pressure.</div><br/></div></div><div id="40971094" class="c"><input type="checkbox" id="c-40971094" checked=""/><div class="controls bullet"><span class="by">ashvardanian</span><span>|</span><a href="#40983368">prev</a><span>|</span><a href="#40972749">next</a><span>|</span><label class="collapse" for="c-40971094">[-]</label><label class="expand" for="c-40971094">[5 more]</label></div><br/><div class="children"><div class="content">It’s great that there is a page about current limitations [1], but I am afraid that what most people describe as “CUDA” is a small subset of the real CUDA functionality. Would be great to have a comparison table for advanced features like warp shuffles, atomics, DPX, TMA, MMA, etc. Ideally a table, mapping every PTX instruction to a direct RDNA counterpart or a list of instructions used to emulate it.<p>[1]: <a href="https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;manual&#x2F;differences&#x2F;" rel="nofollow">https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;manual&#x2F;differences&#x2F;</a></div><br/><div id="40971652" class="c"><input type="checkbox" id="c-40971652" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40971094">parent</a><span>|</span><a href="#40972749">next</a><span>|</span><label class="collapse" for="c-40971652">[-]</label><label class="expand" for="c-40971652">[4 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right that most people only use a small subset of cuda: we prioritied support for features based on what was needed for various open-source projects, as a way to try to capture the most common things first.<p>A complete API comparison table is coming soon, I belive. :D<p>In a nutshell:
- DPX: Yes.
- Shuffles: Yes. Including the PTX versions, with all their weird&#x2F;wacky&#x2F;insane arguments.
- Atomics: yes, except the 128-bit atomics nvidia added very recently.
- MMA: in development, though of course we can&#x27;t fix the fact that nvidia&#x27;s hardware in this area is just <i>better</i> than AMD&#x27;s, so don&#x27;t expect performance to be as good in all cases.
- TMA: On the same branch as MMA, though it&#x27;ll just be using AMD&#x27;s async copy instructions.<p>&gt; mapping every PTX instruction to a direct RDNA counterpart or a list of instructions used to emulate it.<p>We plan to publish a compatibility table of which instructons are supported, but a list of the instructions used to produce each PTX instruction is not in general meaningful. The inline PTX handler works by converting the PTX block to LLVM IR at the start of compilation (at the same time the rest of your code gets turned into IR), so it then &quot;compiles forward&quot; with the rest of the program. As a result, the actual instructions chosen vary on a csae-by-case basis due to the whims of the optimiser. This design in principle produces better performance than a hypothetical solution that turned PTX asm into AMD asm, because it conveniently eliminates the optimisation barrier an asm block typically represents. Care, of course, is taken to handle the wacky memory consistency concerns that this implies!<p>We&#x27;re documenting which ones are expected to perform worse than on NVIDIA, though!</div><br/><div id="40972826" class="c"><input type="checkbox" id="c-40972826" checked=""/><div class="controls bullet"><span class="by">ashvardanian</span><span>|</span><a href="#40971094">root</a><span>|</span><a href="#40971652">parent</a><span>|</span><a href="#40976255">next</a><span>|</span><label class="collapse" for="c-40972826">[-]</label><label class="expand" for="c-40972826">[1 more]</label></div><br/><div class="children"><div class="content">Have you seen anyone productively using TMA on Nvidia or async instructions on AMD? I’m currently looking at a 60% throughput degradation for 2D inputs on H100: <a href="https:&#x2F;&#x2F;github.com&#x2F;ashvardanian&#x2F;scaling-democracy&#x2F;blob&#x2F;a8092613fac1ae107e6a956c5c41ad4994a51735&#x2F;scaling_democracy.cu#L266">https:&#x2F;&#x2F;github.com&#x2F;ashvardanian&#x2F;scaling-democracy&#x2F;blob&#x2F;a8092...</a></div><br/></div></div><div id="40976255" class="c"><input type="checkbox" id="c-40976255" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#40971094">root</a><span>|</span><a href="#40971652">parent</a><span>|</span><a href="#40972826">prev</a><span>|</span><a href="#40972749">next</a><span>|</span><label class="collapse" for="c-40976255">[-]</label><label class="expand" for="c-40976255">[2 more]</label></div><br/><div class="children"><div class="content">&gt; You&#x27;re right that most people only use a small subset of cuda<p>This is true first and foremost for the host-side API. From my StackOverflow and NVIDIA forums experience - I&#x27;m often the first and only person to ask about any number of nooks and crannies of the CUDA Driver API, with issues which nobody seems to have stumbled onto before; or at least - not stumbled and wrote anything in public about it.</div><br/><div id="40979236" class="c"><input type="checkbox" id="c-40979236" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40971094">root</a><span>|</span><a href="#40976255">parent</a><span>|</span><a href="#40972749">next</a><span>|</span><label class="collapse" for="c-40979236">[-]</label><label class="expand" for="c-40979236">[1 more]</label></div><br/><div class="children"><div class="content">Oh yes, we found all kinds of bugs in Nvidia&#x27;s cuda implementation during this project :D.<p>There&#x27;s a bunch of pretty obscure functions in the device side apis too: some esoteric math functions, old simd &quot;intrinsics&quot; that are mostly irrelevant with modern compilers, etc.</div><br/></div></div></div></div></div></div></div></div><div id="40972749" class="c"><input type="checkbox" id="c-40972749" checked=""/><div class="controls bullet"><span class="by">spfd</span><span>|</span><a href="#40971094">prev</a><span>|</span><a href="#40970777">next</a><span>|</span><label class="collapse" for="c-40972749">[-]</label><label class="expand" for="c-40972749">[5 more]</label></div><br/><div class="children"><div class="content">Very impressive!<p>But I can&#x27;t help but think if something like this can be done to this extend, I wonder what went wrong&#x2F;why it&#x27;s a struggle for OpenCL to unify the two fragmentized communities. While this is very practical and has a significant impact for people who develop GPGPU&#x2F;AI applications, for the heterogeneous computing community as a whole, relying on&#x2F;promoting a proprietary interface&#x2F;API&#x2F;language to become THE interface to work with different GPUs sounds like bad news.<p>Can someone educate me on why OpenCL seems to be out of scene in the comments&#x2F;any of the recent discussions related to this topic?</div><br/><div id="40977463" class="c"><input type="checkbox" id="c-40977463" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40972749">parent</a><span>|</span><a href="#40979076">next</a><span>|</span><label class="collapse" for="c-40977463">[-]</label><label class="expand" for="c-40977463">[2 more]</label></div><br/><div class="children"><div class="content">Opencl gives you the subset of capability that a lot of different companies were confident they could implement. That subset turns out to be intensely annoying to program in - it&#x27;s just the compiler saying no over and over again.<p>Or you can compile as freestanding c++ with clang extensions and it works much like a CPU does. Or you can compile as cuda or openmp and most stuff you write actually turns into code, not a semantic error.<p>Currently cuda holds lead position but it should lose that place because it&#x27;s horrible to work in (and to a lesser extent because more than one company knows how to make a GPU). Openmp is an interesting alternative - need to be a little careful to get fast code out but lots of things work somewhat intuitively.<p>Personally, I think raw C++ is going to win out and the many heterogeneous languages will ultimately be dropped as basically a bad idea. But time will tell. Opencl looks very DoA.</div><br/></div></div><div id="40979076" class="c"><input type="checkbox" id="c-40979076" checked=""/><div class="controls bullet"><span class="by">mschuetz</span><span>|</span><a href="#40972749">parent</a><span>|</span><a href="#40977463">prev</a><span>|</span><a href="#40973782">next</a><span>|</span><label class="collapse" for="c-40979076">[-]</label><label class="expand" for="c-40979076">[1 more]</label></div><br/><div class="children"><div class="content">OpenCL isn&#x27;t nice to use and lacks tons of quality of life features. I wouldn&#x27;t use it, even if it was double as fast as CUDA.</div><br/></div></div><div id="40973782" class="c"><input type="checkbox" id="c-40973782" checked=""/><div class="controls bullet"><span class="by">vedranm</span><span>|</span><a href="#40972749">parent</a><span>|</span><a href="#40979076">prev</a><span>|</span><a href="#40970777">next</a><span>|</span><label class="collapse" for="c-40973782">[-]</label><label class="expand" for="c-40973782">[1 more]</label></div><br/><div class="children"><div class="content">If you are going the &quot;open standard&quot; route, SYCL is much more modern than OpenCL and also nicer to work with.</div><br/></div></div></div></div><div id="40970777" class="c"><input type="checkbox" id="c-40970777" checked=""/><div class="controls bullet"><span class="by">joe_the_user</span><span>|</span><a href="#40972749">prev</a><span>|</span><a href="#40970710">next</a><span>|</span><label class="collapse" for="c-40970777">[-]</label><label class="expand" for="c-40970777">[1 more]</label></div><br/><div class="children"><div class="content">This sounds fabulous. I look forward to AMD being drawn kicking and screaming into direct competition with Nvidia.</div><br/></div></div><div id="40970710" class="c"><input type="checkbox" id="c-40970710" checked=""/><div class="controls bullet"><span class="by">deliveryboyman</span><span>|</span><a href="#40970777">prev</a><span>|</span><a href="#40981027">next</a><span>|</span><label class="collapse" for="c-40970710">[-]</label><label class="expand" for="c-40970710">[1 more]</label></div><br/><div class="children"><div class="content">Would like to see benchmarks for the applications in the test suite.<p>E.g., how does Cycles compare on AMD vs Nvidia?</div><br/></div></div><div id="40981027" class="c"><input type="checkbox" id="c-40981027" checked=""/><div class="controls bullet"><span class="by">lukan</span><span>|</span><a href="#40970710">prev</a><span>|</span><a href="#40971034">next</a><span>|</span><label class="collapse" for="c-40981027">[-]</label><label class="expand" for="c-40981027">[1 more]</label></div><br/><div class="children"><div class="content">Ok, so I just stumbled on the problem, that I tried out openwhisper (from OpenAI), but on my CPU, because of no CUDA and workarounds seem hacky. So the headline sounds good!<p>But can this help me directly? Or would OpenAI have to use this tool for me to benefit?<p>It is not immediately clear to me (but I am a beginner in this space).</div><br/></div></div><div id="40971034" class="c"><input type="checkbox" id="c-40971034" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40981027">prev</a><span>|</span><a href="#40981211">next</a><span>|</span><label class="collapse" for="c-40971034">[-]</label><label class="expand" for="c-40971034">[8 more]</label></div><br/><div class="children"><div class="content">This is technically feasible so might be the real thing. Parsing inline ptx and mapping that onto amdgpu would be a huge pain.<p>Working from cuda source that doesn&#x27;t use inline ptx to target amdgpu is roughly regex find and replace to get hip, which has implemented pretty much the same functionality.<p>Some of the details would be dubious, e.g. the atomic models probably don&#x27;t match, and volta has a different instruction pointer model, but it could all be done correctly.<p>Amd won&#x27;t do this. Cuda isn&#x27;t a very nice thing in general and the legal team would have kittens. But other people totally could.</div><br/><div id="40971597" class="c"><input type="checkbox" id="c-40971597" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40971034">parent</a><span>|</span><a href="#40981211">next</a><span>|</span><label class="collapse" for="c-40971597">[-]</label><label class="expand" for="c-40971597">[7 more]</label></div><br/><div class="children"><div class="content">[I work on SCALE]<p>Mapping inline ptx to AMD machine code would indeed <i>suck</i>. Converting it to LLVM IR right at the start of compilation (when the initial IR is being generated) is much simpler, since it then gets &quot;compiled forward&quot; with the rest of the code. It&#x27;s as if you wrote C++&#x2F;intrinsics&#x2F;whatever instead.<p>Note that nvcc accepts a different dialect of C++ from clang (and hence hipcc), so there is in fact more that separates CUDA from hip (at the language level) than just find&#x2F;replace. We discuss this a little in [the manual](<a href="https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;manual&#x2F;dialects&#x2F;" rel="nofollow">https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;manual&#x2F;dialects&#x2F;</a>)<p>Handling differences between the atomic models is, indeed, &quot;fun&quot;. But since CUDA is a programming language with documented semantics for its memory consistency (and so is PTX) it is entirely possible to arrange for the compiler to &quot;play by NVIDIA&#x27;s rules&quot;.</div><br/><div id="40971725" class="c"><input type="checkbox" id="c-40971725" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40971034">root</a><span>|</span><a href="#40971597">parent</a><span>|</span><a href="#40981211">next</a><span>|</span><label class="collapse" for="c-40971725">[-]</label><label class="expand" for="c-40971725">[6 more]</label></div><br/><div class="children"><div class="content">Huh. Inline assembly is strongly associated in my mind with writing things that can&#x27;t be represented in LLVM IR, but in the specific case of PTX - you can only write things that ptxas understands, and that probably rules out wide classes of horrendous behaviour. Raw bytes being used for instructions and for data, ad hoc  self modifying code and so forth.<p>I believe nvcc is roughly an antique clang build hacked out of all recognition. I remember it rejecting templates with &#x27;I&#x27; as the type name and working when changing to &#x27;T&#x27;, nonsense like that. The HIP language probably corresponds pretty closely to clang&#x27;s cuda implementation in terms of semantics (a lot of the control flow in clang treats them identically), but I don&#x27;t believe an exact match to nvcc was considered particularly necessary for the clang -x cuda work.<p>The ptx to llvm IR approach is clever. I think upstream would be game for that, feel free to tag me on reviews if you want to get that divergence out of your local codebase.</div><br/><div id="40973040" class="c"><input type="checkbox" id="c-40973040" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40971034">root</a><span>|</span><a href="#40971725">parent</a><span>|</span><a href="#40972813">next</a><span>|</span><label class="collapse" for="c-40973040">[-]</label><label class="expand" for="c-40973040">[2 more]</label></div><br/><div class="children"><div class="content">I certainly would not attempt this feat with x86 `asm` blocks :D. PTX is indeed very pedestrian: it&#x27;s more like IR than machine code, really. All the usual &quot;machine-level craziness&quot; that would otherwise make this impossible is just unrepresentable in PTX (though you do run into cases of &quot;oopsie, AMD don&#x27;t have hardware for this so we have to do something insane&quot;).</div><br/><div id="40976862" class="c"><input type="checkbox" id="c-40976862" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40971034">root</a><span>|</span><a href="#40973040">parent</a><span>|</span><a href="#40972813">next</a><span>|</span><label class="collapse" for="c-40976862">[-]</label><label class="expand" for="c-40976862">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a beautiful answer to a deeply annoying language feature. I absolutely love it. Yes, inline asm containing PTX definitely should be burned off at the compiler front end, regardless of whether it ultimately codegens as PTX or something else.<p>I&#x27;m spawned a thread on the llvm board asking if anyone else wants that as a feature <a href="https:&#x2F;&#x2F;discourse.llvm.org&#x2F;t&#x2F;fexpand-inline-ptx-as-a-feature&#x2F;80169" rel="nofollow">https:&#x2F;&#x2F;discourse.llvm.org&#x2F;t&#x2F;fexpand-inline-ptx-as-a-feature...</a> in the upstream. That doesn&#x27;t feel great - you&#x27;ve done something clever in a proprietary compiler and I&#x27;m suggesting upstream reimplement it - so I hope that doesn&#x27;t cause you any distress. AMD is relatively unlikely to greenlight me writing it so it&#x27;s <i>probably</i> just more marketing unless other people are keen to parse asm in string literals.</div><br/></div></div></div></div><div id="40972813" class="c"><input type="checkbox" id="c-40972813" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40971034">root</a><span>|</span><a href="#40971725">parent</a><span>|</span><a href="#40973040">prev</a><span>|</span><a href="#40981211">next</a><span>|</span><label class="collapse" for="c-40972813">[-]</label><label class="expand" for="c-40972813">[3 more]</label></div><br/><div class="children"><div class="content">nvcc is nowhere near that bad these days, it supports most C++ code directly (for example, I&#x27;ve written kernels that include headers like &lt;span&gt; or &lt;algorithm&gt; and they work just fine).</div><br/><div id="40973029" class="c"><input type="checkbox" id="c-40973029" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40971034">root</a><span>|</span><a href="#40972813">parent</a><span>|</span><a href="#40981211">next</a><span>|</span><label class="collapse" for="c-40973029">[-]</label><label class="expand" for="c-40973029">[2 more]</label></div><br/><div class="children"><div class="content">NVCC is doing much better than before in terms of &quot;broken C++&quot;. There was indeed a time when lots of modern C++ just <i>didn&#x27;t work</i>.<p>Nowadays the issues are more subtle and nasty. Subtle differences in overload resolution. Subtle differences in lambda handling. Enough to break code in &quot;spicy&quot; ways when you try to port it over.</div><br/><div id="40983462" class="c"><input type="checkbox" id="c-40983462" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#40971034">root</a><span>|</span><a href="#40973029">parent</a><span>|</span><a href="#40981211">next</a><span>|</span><label class="collapse" for="c-40983462">[-]</label><label class="expand" for="c-40983462">[1 more]</label></div><br/><div class="children"><div class="content">What do you think the source of this is? My understanding was that Nvidia is basically adopting the clang frontend wholesale now so I&#x27;m curious where it differs.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="40981211" class="c"><input type="checkbox" id="c-40981211" checked=""/><div class="controls bullet"><span class="by">omneity</span><span>|</span><a href="#40971034">prev</a><span>|</span><a href="#40970698">next</a><span>|</span><label class="collapse" for="c-40981211">[-]</label><label class="expand" for="c-40981211">[1 more]</label></div><br/><div class="children"><div class="content">Wondering if there&#x27;s an ongoing effort to do the same with MPS&#x2F;Metal as a backend. If anything given how many developers are on macs I think it could get immense traction.</div><br/></div></div><div id="40970698" class="c"><input type="checkbox" id="c-40970698" checked=""/><div class="controls bullet"><span class="by">adzm</span><span>|</span><a href="#40981211">prev</a><span>|</span><a href="#40976074">next</a><span>|</span><label class="collapse" for="c-40970698">[-]</label><label class="expand" for="c-40970698">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to see some benchmarks but this is something the market has been yearning for.</div><br/><div id="40970783" class="c"><input type="checkbox" id="c-40970783" checked=""/><div class="controls bullet"><span class="by">msond</span><span>|</span><a href="#40970698">parent</a><span>|</span><a href="#40976074">next</a><span>|</span><label class="collapse" for="c-40970783">[-]</label><label class="expand" for="c-40970783">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re putting together benchmarks to publish at a later time, and we&#x27;ve asked some independent third parties to work on their own additionally.</div><br/></div></div></div></div><div id="40976074" class="c"><input type="checkbox" id="c-40976074" checked=""/><div class="controls bullet"><span class="by">stuaxo</span><span>|</span><a href="#40970698">prev</a><span>|</span><a href="#40973794">next</a><span>|</span><label class="collapse" for="c-40976074">[-]</label><label class="expand" for="c-40976074">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the licensing, will I be able run this as a hobbyist for free software?</div><br/></div></div><div id="40973794" class="c"><input type="checkbox" id="c-40973794" checked=""/><div class="controls bullet"><span class="by">pjmlp</span><span>|</span><a href="#40976074">prev</a><span>|</span><a href="#40972543">next</a><span>|</span><label class="collapse" for="c-40973794">[-]</label><label class="expand" for="c-40973794">[6 more]</label></div><br/><div class="children"><div class="content">This targets CUDA C++, not CUDA the NVIDIA infrastructure for C, C++, Fortran, and anything else targeting PTX.</div><br/><div id="40975752" class="c"><input type="checkbox" id="c-40975752" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40973794">parent</a><span>|</span><a href="#40972543">next</a><span>|</span><label class="collapse" for="c-40975752">[-]</label><label class="expand" for="c-40975752">[5 more]</label></div><br/><div class="children"><div class="content">The CUDA C APIs are supported as much in C as in C++ using SCALE!<p>Cuda-fortran is not currently supported by scale since we haven&#x27;t seen much use of it &quot;in the wild&quot; to push it up our priority list.</div><br/><div id="40978442" class="c"><input type="checkbox" id="c-40978442" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#40973794">root</a><span>|</span><a href="#40975752">parent</a><span>|</span><a href="#40972543">next</a><span>|</span><label class="collapse" for="c-40978442">[-]</label><label class="expand" for="c-40978442">[4 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t matter though. NVIDIA distributes tons of libraries built atop CUDA that you cannot distribute or use on AMD chips legally. Cutlass, CuBLAS, NCCL, etc.</div><br/><div id="40979214" class="c"><input type="checkbox" id="c-40979214" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40973794">root</a><span>|</span><a href="#40978442">parent</a><span>|</span><a href="#40978619">next</a><span>|</span><label class="collapse" for="c-40979214">[-]</label><label class="expand" for="c-40979214">[2 more]</label></div><br/><div class="children"><div class="content">SCALE doesn&#x27;t use cuBlas and friends. For those APIs, it uses either its own implementations of the functions, or delegates to an existing AMD library (such as rocblas).<p>It wouldn&#x27;t even be technically possible for SCALE to distribute and use cuBlas, since the source code is not available. I suppose maybe you could do distribute cuBlas and run it through ZLUDA, but that would likely become legally troublesome.</div><br/><div id="40981120" class="c"><input type="checkbox" id="c-40981120" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#40973794">root</a><span>|</span><a href="#40979214">parent</a><span>|</span><a href="#40978619">next</a><span>|</span><label class="collapse" for="c-40981120">[-]</label><label class="expand" for="c-40981120">[1 more]</label></div><br/><div class="children"><div class="content">&gt; SCALE doesn&#x27;t use cuBlas and friends. For those APIs, it uses either its own implementations of the functions, or delegates to an existing AMD library (such as rocblas).<p>And this is the problem. I guarantee you NVIDIA has more engineers working on cuBLAS et al than AMD does.<p>The NVIDIA moat is not CUDA the language or CUDA the library. It&#x27;s CUDA the ecosystem. That means things like all the high performance libraries; all the high performance libraries with clustering support (does AMD even have a clustering solution like NVLink -- everyone forgets that NVIDIA also does high speed networking); all the high perf appliances (everyone also forgets that NVIDIA sells entire systems, not GPUS); all the high perf servers (Triton inference server, etc). We can go on.<p>I commend the project volunteers for what they&#x27;ve done, but I would recommend getting VC money and competing directly with NVIDIA.</div><br/></div></div></div></div><div id="40978619" class="c"><input type="checkbox" id="c-40978619" checked=""/><div class="controls bullet"><span class="by">tama_sala</span><span>|</span><a href="#40973794">root</a><span>|</span><a href="#40978442">parent</a><span>|</span><a href="#40979214">prev</a><span>|</span><a href="#40972543">next</a><span>|</span><label class="collapse" for="c-40978619">[-]</label><label class="expand" for="c-40978619">[1 more]</label></div><br/><div class="children"><div class="content">Correct, which one of the main moats Nvidia has when it comes to training</div><br/></div></div></div></div></div></div></div></div><div id="40972543" class="c"><input type="checkbox" id="c-40972543" checked=""/><div class="controls bullet"><span class="by">nabogh</span><span>|</span><a href="#40973794">prev</a><span>|</span><a href="#40978713">next</a><span>|</span><label class="collapse" for="c-40972543">[-]</label><label class="expand" for="c-40972543">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve written a bit of CUDA before. If I want to go pretty bare-bones, what&#x27;s the equivalent setup for writing code for my AMD card?</div><br/><div id="40980952" class="c"><input type="checkbox" id="c-40980952" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40972543">parent</a><span>|</span><a href="#40978713">next</a><span>|</span><label class="collapse" for="c-40980952">[-]</label><label class="expand" for="c-40980952">[1 more]</label></div><br/><div class="children"><div class="content">HIP works very similarly. Install rocm from your Linux distribution or from amd&#x27;s repo, or build it from github.com&#x2F;rocm. Has the nice feature of being pure userspace if you use the driver version that&#x27;s already in your kernel.<p>How turn-key &#x2F; happy an experience that is depends on how closely your system correlates with one of the documented&#x2F;tested distro versions and what GPU you have. If it&#x27;s one that doesn&#x27;t have binary versions of rocblas etc in the binary blob, either build rocm from source or don&#x27;t bother with rocblas.</div><br/></div></div></div></div><div id="40978713" class="c"><input type="checkbox" id="c-40978713" checked=""/><div class="controls bullet"><span class="by">tallmed</span><span>|</span><a href="#40972543">prev</a><span>|</span><a href="#40973836">next</a><span>|</span><label class="collapse" for="c-40978713">[-]</label><label class="expand" for="c-40978713">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if this thing has anything common with zluda, its permissively licensed after all.</div><br/></div></div><div id="40973836" class="c"><input type="checkbox" id="c-40973836" checked=""/><div class="controls bullet"><span class="by">uptownfunk</span><span>|</span><a href="#40978713">prev</a><span>|</span><a href="#40970849">next</a><span>|</span><label class="collapse" for="c-40973836">[-]</label><label class="expand" for="c-40973836">[2 more]</label></div><br/><div class="children"><div class="content">Very clearly the business motive make sense, go after nvidia gpu monopoly. Can someone help a lay person understand the pitfalls here that prevent this from being an intelligent venture?</div><br/><div id="40980966" class="c"><input type="checkbox" id="c-40980966" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40973836">parent</a><span>|</span><a href="#40970849">next</a><span>|</span><label class="collapse" for="c-40980966">[-]</label><label class="expand" for="c-40980966">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s technically non-trivial and deeply irritating to implement in places as people expect bugward compatibility with cuda.<p>Also nvidia might savage you with lawyers for threatening their revenue stream. Big companies can kill small ones by strangling them in the courts then paying the fine when they lose a decade later.</div><br/></div></div></div></div><div id="40970849" class="c"><input type="checkbox" id="c-40970849" checked=""/><div class="controls bullet"><span class="by">sakras</span><span>|</span><a href="#40973836">prev</a><span>|</span><a href="#40973439">next</a><span>|</span><label class="collapse" for="c-40970849">[-]</label><label class="expand" for="c-40970849">[3 more]</label></div><br/><div class="children"><div class="content">One question I always have about these sorts of translation layers is how they deal with the different warp sizes. I&#x27;d imagine a lot of CUDA code relies on 32-wide warps, while as far as I know AMD tends to have 64-wide warps. Is there some sort of emulation that needs to happen?</div><br/><div id="40971075" class="c"><input type="checkbox" id="c-40971075" checked=""/><div class="controls bullet"><span class="by">msond</span><span>|</span><a href="#40970849">parent</a><span>|</span><a href="#40970959">next</a><span>|</span><label class="collapse" for="c-40971075">[-]</label><label class="expand" for="c-40971075">[1 more]</label></div><br/><div class="children"><div class="content">SCALE is not a &quot;translation layer&quot;, it&#x27;s a full source-to-target compiler from CUDA-like C++ code to AMD GPUs.<p>See this part of the documentation for more details regarding warp sizes: <a href="https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;manual&#x2F;language-extensions&#x2F;#improved-support-for-non-32-warpsize" rel="nofollow">https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;manual&#x2F;language-extensions&#x2F;#impr...</a></div><br/></div></div><div id="40970959" class="c"><input type="checkbox" id="c-40970959" checked=""/><div class="controls bullet"><span class="by">mpreda</span><span>|</span><a href="#40970849">parent</a><span>|</span><a href="#40971075">prev</a><span>|</span><a href="#40973439">next</a><span>|</span><label class="collapse" for="c-40970959">[-]</label><label class="expand" for="c-40970959">[1 more]</label></div><br/><div class="children"><div class="content">The older AMD <i>GCN</i> had 64-wide wavefront, but the newer AMD GPUs &quot;RDNA&quot; support both 64 and 32 wavefront, and this is configurable at runtime. It appears the narrower wavefronts are better suited for games in general.<p>Not sure what is the situation with &quot;CDNA&quot;, which is the compute-oriented evolution of &quot;GCN&quot;, i.e. whether CDNA is 64-wavefront only or dual like RNDA.</div><br/></div></div></div></div><div id="40973439" class="c"><input type="checkbox" id="c-40973439" checked=""/><div class="controls bullet"><span class="by">ekelsen</span><span>|</span><a href="#40970849">prev</a><span>|</span><a href="#40970718">next</a><span>|</span><label class="collapse" for="c-40973439">[-]</label><label class="expand" for="c-40973439">[1 more]</label></div><br/><div class="children"><div class="content">A major component of many CUDA programs these days involves NCCL and high bandwidth intra-node communication.<p>Does NCCL just work? If not, what would be involved in getting it to work?</div><br/></div></div><div id="40970718" class="c"><input type="checkbox" id="c-40970718" checked=""/><div class="controls bullet"><span class="by">jarbus</span><span>|</span><a href="#40973439">prev</a><span>|</span><a href="#40971332">next</a><span>|</span><label class="collapse" for="c-40970718">[-]</label><label class="expand" for="c-40970718">[9 more]</label></div><br/><div class="children"><div class="content">Really, really, <i>really</i> curious as to how they managed to pull this off, if their project works as well as they claim it does. If stuff as complex as paged&#x2F;flash attention can &quot;just work&quot;, this is really cool.</div><br/><div id="40970745" class="c"><input type="checkbox" id="c-40970745" checked=""/><div class="controls bullet"><span class="by">Straw</span><span>|</span><a href="#40970718">parent</a><span>|</span><a href="#40971133">next</a><span>|</span><label class="collapse" for="c-40970745">[-]</label><label class="expand" for="c-40970745">[4 more]</label></div><br/><div class="children"><div class="content">My understanding from chatting with them is that tensor core operations aren&#x27;t supported yet, so FlashAttention likely won&#x27;t work. I think its on their to-do list though!<p>Nvidia actually has more and more capable matrix multiplication units, so even with a translation layer I wouldn&#x27;t expect the same performance until AMD produces better ML cards.<p>Additionally, these kernels usually have high sensitivity to cache and smem sizes, so they might need to be retuned.</div><br/><div id="40971980" class="c"><input type="checkbox" id="c-40971980" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#40970718">root</a><span>|</span><a href="#40970745">parent</a><span>|</span><a href="#40971133">next</a><span>|</span><label class="collapse" for="c-40971980">[-]</label><label class="expand" for="c-40971980">[3 more]</label></div><br/><div class="children"><div class="content">So the only part that anyone actually cares about, as usual, is not supported. Same story as it was in 2012 with AMD vs Nvidia (and likely much before that too!). The more things change, the more they stay the same.</div><br/><div id="40972556" class="c"><input type="checkbox" id="c-40972556" checked=""/><div class="controls bullet"><span class="by">Straw</span><span>|</span><a href="#40970718">root</a><span>|</span><a href="#40971980">parent</a><span>|</span><a href="#40971133">next</a><span>|</span><label class="collapse" for="c-40972556">[-]</label><label class="expand" for="c-40972556">[2 more]</label></div><br/><div class="children"><div class="content">People did GPGPU computing long before GPUs. Simply look at the list of tested, supported projects on their docs page!</div><br/><div id="40978469" class="c"><input type="checkbox" id="c-40978469" checked=""/><div class="controls bullet"><span class="by">Straw</span><span>|</span><a href="#40970718">root</a><span>|</span><a href="#40972556">parent</a><span>|</span><a href="#40971133">next</a><span>|</span><label class="collapse" for="c-40978469">[-]</label><label class="expand" for="c-40978469">[1 more]</label></div><br/><div class="children"><div class="content">[EDIT] long before deep learning!</div><br/></div></div></div></div></div></div></div></div><div id="40971133" class="c"><input type="checkbox" id="c-40971133" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40970718">parent</a><span>|</span><a href="#40970745">prev</a><span>|</span><a href="#40971332">next</a><span>|</span><label class="collapse" for="c-40971133">[-]</label><label class="expand" for="c-40971133">[4 more]</label></div><br/><div class="children"><div class="content">Cuda is a programming language. You implement it like any other. The docs are a bit sparse but not awful. Targeting amdgpu is probably about as difficult as targeting x64, mostly changes the compiler runtime.<p>The online ptx implementation is notable for being even more annoying to deal with than the cuda, but it&#x27;s just bytes in &#x2F; different bytes out. No magic.</div><br/><div id="40971688" class="c"><input type="checkbox" id="c-40971688" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40970718">root</a><span>|</span><a href="#40971133">parent</a><span>|</span><a href="#40971332">next</a><span>|</span><label class="collapse" for="c-40971688">[-]</label><label class="expand" for="c-40971688">[3 more]</label></div><br/><div class="children"><div class="content">[I work on SCALE]<p>CUDA has a couple of extra problems beyond just any other programming language:<p>- CUDA is more than a language: it&#x27;s a giant library (for both CPU and GPU) for interacting with the GPU, and for writing the GPU code. This needed reimplementing. At least for the device-side stuff we can implement it <i>in CUDA</i>, so when we add support for other GPU vendors the code can (mostly) just be recompiled and work there :D.
- CUDA (the language) is not actually specified. It is, informally, &quot;whatever nvcc does&quot;. This differs significantly from what Clang&#x27;s CUDA support does (which is ultimately what the HIP compiler is derived from).<p>PTX is indeed vastly annoying.</div><br/><div id="40971868" class="c"><input type="checkbox" id="c-40971868" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40970718">root</a><span>|</span><a href="#40971688">parent</a><span>|</span><a href="#40971332">next</a><span>|</span><label class="collapse" for="c-40971868">[-]</label><label class="expand" for="c-40971868">[2 more]</label></div><br/><div class="children"><div class="content">The openmp device runtime library was originally written in cuda. I ported that to hip for amdgpu, discovered the upstream hip compiler wasn&#x27;t quite as solid as advertised, then ported it to openmp with some compiler intrinsics. The languages are all essentially C++ syntax with some spurious noise obfuscating llvm IR. The libc effort has gone with freestanding c++ based on that experience and and we&#x27;ve now mostly fixed the ways that goes wrong.<p>You might also find raw c++ for device libraries saner to deal with than cuda. In particular you don&#x27;t need to jury rig the thing to not spuriously embed the GPU code in x64 elf objects and&#x2F;or pull the binaries apart. Though if you&#x27;re feeding the same device libraries to nvcc with #ifdef around the divergence your hands are tied.</div><br/><div id="40972165" class="c"><input type="checkbox" id="c-40972165" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40970718">root</a><span>|</span><a href="#40971868">parent</a><span>|</span><a href="#40971332">next</a><span>|</span><label class="collapse" for="c-40972165">[-]</label><label class="expand" for="c-40972165">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You might also find raw c++ for device libraries saner to deal with than cuda.<p>Actually, we just compile all the device libraries to LLVM bitcode and be done with it. Then we can write them using all the clang-dialect, not-nvcc-emulating, C++23 we feel like, and it&#x27;ll still work when someone imports them into their c++98 CUDA project from hell. :D</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40971332" class="c"><input type="checkbox" id="c-40971332" checked=""/><div class="controls bullet"><span class="by">qwerty456127</span><span>|</span><a href="#40970718">prev</a><span>|</span><a href="#40970686">next</a><span>|</span><label class="collapse" for="c-40971332">[-]</label><label class="expand" for="c-40971332">[3 more]</label></div><br/><div class="children"><div class="content">&gt; gfx1030, gfx1100, gfx1010, gfx1101, gfx900...<p>How do I find out which do I have?</div><br/><div id="40971659" class="c"><input type="checkbox" id="c-40971659" checked=""/><div class="controls bullet"><span class="by">ckitching</span><span>|</span><a href="#40971332">parent</a><span>|</span><a href="#40980529">next</a><span>|</span><label class="collapse" for="c-40971659">[-]</label><label class="expand" for="c-40971659">[1 more]</label></div><br/><div class="children"><div class="content">Like this:<p><a href="https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;manual&#x2F;how-to-use&#x2F;#identifying-gpu-target" rel="nofollow">https:&#x2F;&#x2F;docs.scale-lang.com&#x2F;manual&#x2F;how-to-use&#x2F;#identifying-g...</a></div><br/></div></div><div id="40980529" class="c"><input type="checkbox" id="c-40980529" checked=""/><div class="controls bullet"><span class="by">systemBuilder</span><span>|</span><a href="#40971332">parent</a><span>|</span><a href="#40971659">prev</a><span>|</span><a href="#40970686">next</a><span>|</span><label class="collapse" for="c-40980529">[-]</label><label class="expand" for="c-40980529">[1 more]</label></div><br/><div class="children"><div class="content">gfx1101 : <a href="https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-navi-32.g1000" rel="nofollow">https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-navi-32.g1000</a><p>gfx1100 : <a href="https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-navi-31.g998" rel="nofollow">https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-navi-31.g998</a><p>gfx1030 : <a href="https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-navi-21.g923" rel="nofollow">https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-navi-21.g923</a><p>gfx1010 : <a href="https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-navi-10.g861" rel="nofollow">https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-navi-10.g861</a><p>gfx900 : <a href="https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-vega-10.g800" rel="nofollow">https:&#x2F;&#x2F;www.techpowerup.com&#x2F;gpu-specs&#x2F;amd-vega-10.g800</a></div><br/></div></div></div></div><div id="40970686" class="c"><input type="checkbox" id="c-40970686" checked=""/><div class="controls bullet"><span class="by">arjvik</span><span>|</span><a href="#40971332">prev</a><span>|</span><a href="#40981749">next</a><span>|</span><label class="collapse" for="c-40970686">[-]</label><label class="expand" for="c-40970686">[3 more]</label></div><br/><div class="children"><div class="content">Who is this Spectral Compute, and where can we see more about them?</div><br/><div id="40970751" class="c"><input type="checkbox" id="c-40970751" checked=""/><div class="controls bullet"><span class="by">msond</span><span>|</span><a href="#40970686">parent</a><span>|</span><a href="#40981749">next</a><span>|</span><label class="collapse" for="c-40970751">[-]</label><label class="expand" for="c-40970751">[2 more]</label></div><br/><div class="children"><div class="content">You can learn more about us on <a href="https:&#x2F;&#x2F;spectralcompute.co.uk" rel="nofollow">https:&#x2F;&#x2F;spectralcompute.co.uk</a></div><br/><div id="40971098" class="c"><input type="checkbox" id="c-40971098" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40970686">root</a><span>|</span><a href="#40970751">parent</a><span>|</span><a href="#40981749">next</a><span>|</span><label class="collapse" for="c-40971098">[-]</label><label class="expand" for="c-40971098">[1 more]</label></div><br/><div class="children"><div class="content">The branch free regex engine is an interesting idea. I would have said that can&#x27;t be implemented in finite code.<p>Compile to DFA by repeatedly differentiating then unroll the machine? You&#x27;d still have back edges for the repeating sections.</div><br/></div></div></div></div></div></div><div id="40981749" class="c"><input type="checkbox" id="c-40981749" checked=""/><div class="controls bullet"><span class="by">seanp2k2</span><span>|</span><a href="#40970686">prev</a><span>|</span><a href="#40970692">next</a><span>|</span><label class="collapse" for="c-40981749">[-]</label><label class="expand" for="c-40981749">[1 more]</label></div><br/><div class="children"><div class="content">This is the way.</div><br/></div></div><div id="40970692" class="c"><input type="checkbox" id="c-40970692" checked=""/><div class="controls bullet"><span class="by">pixelpoet</span><span>|</span><a href="#40981749">prev</a><span>|</span><a href="#40970885">next</a><span>|</span><label class="collapse" for="c-40970692">[-]</label><label class="expand" for="c-40970692">[12 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this a bit legally dubious, like zluda?</div><br/><div id="40970761" class="c"><input type="checkbox" id="c-40970761" checked=""/><div class="controls bullet"><span class="by">janice1999</span><span>|</span><a href="#40970692">parent</a><span>|</span><a href="#40970885">next</a><span>|</span><label class="collapse" for="c-40970761">[-]</label><label class="expand" for="c-40970761">[11 more]</label></div><br/><div class="children"><div class="content">It&#x27;s advertised as a &quot;clean room&quot; re-implementation. What part would be illegal?</div><br/><div id="40970875" class="c"><input type="checkbox" id="c-40970875" checked=""/><div class="controls bullet"><span class="by">ekelsen</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40970761">parent</a><span>|</span><a href="#40970889">next</a><span>|</span><label class="collapse" for="c-40970875">[-]</label><label class="expand" for="c-40970875">[6 more]</label></div><br/><div class="children"><div class="content">If they had to reverse engineer any compiled code to do this, I think that would be against licenses they had to agree to?<p>At least grounds for suing and starting an extensive discovery process and possibly a costly injunction...</div><br/><div id="40971058" class="c"><input type="checkbox" id="c-40971058" checked=""/><div class="controls bullet"><span class="by">msond</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40970875">parent</a><span>|</span><a href="#40971143">next</a><span>|</span><label class="collapse" for="c-40971058">[-]</label><label class="expand" for="c-40971058">[1 more]</label></div><br/><div class="children"><div class="content">We have not reverse engineered any compiled code in the process of developing SCALE.<p>It was clean-room implemented purely from the API surface and by trial-and-error with open CUDA code.</div><br/></div></div><div id="40971143" class="c"><input type="checkbox" id="c-40971143" checked=""/><div class="controls bullet"><span class="by">RockRobotRock</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40970875">parent</a><span>|</span><a href="#40971058">prev</a><span>|</span><a href="#40970889">next</a><span>|</span><label class="collapse" for="c-40971143">[-]</label><label class="expand" for="c-40971143">[4 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that exactly what a &quot;clean room&quot; approach avoids?</div><br/><div id="40971469" class="c"><input type="checkbox" id="c-40971469" checked=""/><div class="controls bullet"><span class="by">ekelsen</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40971143">parent</a><span>|</span><a href="#40970889">next</a><span>|</span><label class="collapse" for="c-40971469">[-]</label><label class="expand" for="c-40971469">[3 more]</label></div><br/><div class="children"><div class="content">oh definitely. But if I was NVIDIA I&#x27;d want to verify that in court after discovery rather than relying on their claim on a website.</div><br/><div id="40972309" class="c"><input type="checkbox" id="c-40972309" checked=""/><div class="controls bullet"><span class="by">RockRobotRock</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40971469">parent</a><span>|</span><a href="#40970889">next</a><span>|</span><label class="collapse" for="c-40972309">[-]</label><label class="expand" for="c-40972309">[2 more]</label></div><br/><div class="children"><div class="content">good point</div><br/><div id="40973413" class="c"><input type="checkbox" id="c-40973413" checked=""/><div class="controls bullet"><span class="by">ekelsen</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40972309">parent</a><span>|</span><a href="#40970889">next</a><span>|</span><label class="collapse" for="c-40973413">[-]</label><label class="expand" for="c-40973413">[1 more]</label></div><br/><div class="children"><div class="content">FWIW, I think this is really great work and I wish only the best for scale.  Super impressed.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40970889" class="c"><input type="checkbox" id="c-40970889" checked=""/><div class="controls bullet"><span class="by">Keyframe</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40970761">parent</a><span>|</span><a href="#40970875">prev</a><span>|</span><a href="#40970885">next</a><span>|</span><label class="collapse" for="c-40970889">[-]</label><label class="expand" for="c-40970889">[4 more]</label></div><br/><div class="children"><div class="content">Can&#x27;t run useful shit on it: <a href="https:&#x2F;&#x2F;docs.nvidia.com&#x2F;deeplearning&#x2F;cudnn&#x2F;latest&#x2F;reference&#x2F;eula.html" rel="nofollow">https:&#x2F;&#x2F;docs.nvidia.com&#x2F;deeplearning&#x2F;cudnn&#x2F;latest&#x2F;reference&#x2F;...</a><p>Namely:<p>&quot;4.1 License Scope. The SDK is licensed for you to develop applications only for use in systems with NVIDIA GPUs.&quot;</div><br/><div id="40971253" class="c"><input type="checkbox" id="c-40971253" checked=""/><div class="controls bullet"><span class="by">mkl</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40970889">parent</a><span>|</span><a href="#40972258">next</a><span>|</span><label class="collapse" for="c-40971253">[-]</label><label class="expand" for="c-40971253">[2 more]</label></div><br/><div class="children"><div class="content">So add a cheap NVidia card alongside grunty AMD ones, and check for its existence.  It doesn&#x27;t seem to say it needs to run on NVidia GPUs.</div><br/><div id="40971397" class="c"><input type="checkbox" id="c-40971397" checked=""/><div class="controls bullet"><span class="by">Keyframe</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40971253">parent</a><span>|</span><a href="#40972258">next</a><span>|</span><label class="collapse" for="c-40971397">[-]</label><label class="expand" for="c-40971397">[1 more]</label></div><br/><div class="children"><div class="content">Heh, true. On the other hand, I bet companies are eager to challenge the wrath of a $3T company for a promise of &quot;maybe it&#x27;ll work, not all of it but at least it&#x27;ll run worse, at least for now&quot;.</div><br/></div></div></div></div><div id="40972258" class="c"><input type="checkbox" id="c-40972258" checked=""/><div class="controls bullet"><span class="by">JonChesterfield</span><span>|</span><a href="#40970692">root</a><span>|</span><a href="#40970889">parent</a><span>|</span><a href="#40971253">prev</a><span>|</span><a href="#40970885">next</a><span>|</span><label class="collapse" for="c-40972258">[-]</label><label class="expand" for="c-40972258">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think the terms of the Nvidia SDK can restrict running software without said SDK. Nvidia&#x27;s libraries don&#x27;t seem to be involved here. Their hardware isn&#x27;t involved either. It&#x27;s just some ascii in a bunch of text files being hacked around with before running on someone else&#x27;s hardware.</div><br/></div></div></div></div></div></div></div></div><div id="40970885" class="c"><input type="checkbox" id="c-40970885" checked=""/><div class="controls bullet"><span class="by">shmerl</span><span>|</span><a href="#40970692">prev</a><span>|</span><a href="#40970683">next</a><span>|</span><label class="collapse" for="c-40970885">[-]</label><label class="expand" for="c-40970885">[2 more]</label></div><br/><div class="children"><div class="content">Compiler isn&#x27;t open source? That feels like DOA in this day and age. There is ZLUDA already which is open.<p>If they plan to open it up, it can be something useful to add to options of breaking CUDA lock-in.</div><br/><div id="40971602" class="c"><input type="checkbox" id="c-40971602" checked=""/><div class="controls bullet"><span class="by">uyzstvqs</span><span>|</span><a href="#40970885">parent</a><span>|</span><a href="#40970683">next</a><span>|</span><label class="collapse" for="c-40971602">[-]</label><label class="expand" for="c-40971602">[1 more]</label></div><br/><div class="children"><div class="content">ZLUDA is pretty good, except that it lacks cuDNN which makes most PyTorch projects just not work. Not sure if this project does cover that? That could be a game changer, otherwise yeah ZLUDA is the better open-source option.</div><br/></div></div></div></div><div id="40970683" class="c"><input type="checkbox" id="c-40970683" checked=""/><div class="controls bullet"><span class="by">dagmx</span><span>|</span><a href="#40970885">prev</a><span>|</span><a href="#40972920">next</a><span>|</span><label class="collapse" for="c-40970683">[-]</label><label class="expand" for="c-40970683">[1 more]</label></div><br/><div class="children"><div class="content">Has anyone tried this and knows how well it works? It definitely sounds very compelling</div><br/></div></div><div id="40972920" class="c"><input type="checkbox" id="c-40972920" checked=""/><div class="controls bullet"><span class="by">rjurney</span><span>|</span><a href="#40970683">prev</a><span>|</span><label class="collapse" for="c-40972920">[-]</label><label class="expand" for="c-40972920">[1 more]</label></div><br/><div class="children"><div class="content">If it&#x27;s efficient, this is very good for competition.</div><br/></div></div></div></div></div></div></div></body></html>