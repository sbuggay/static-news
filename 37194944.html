<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1692522055730" as="style"/><link rel="stylesheet" href="styles.css?v=1692522055730"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://drops.dagstuhl.de/opus/volltexte/2023/18524/pdf/OASIcs-SLATE-2023-10.pdf">Large Language Models: Compilers for the 4th Gen of Programming Languages? [pdf]</a> <span class="domain">(<a href="https://drops.dagstuhl.de">drops.dagstuhl.de</a>)</span></div><div class="subtext"><span>luu</span> | <span>12 comments</span></div><br/><div><div id="37197306" class="c"><input type="checkbox" id="c-37197306" checked=""/><div class="controls bullet"><span class="by">Smaug123</span><span>|</span><a href="#37195286">next</a><span>|</span><label class="collapse" for="c-37197306">[-]</label><label class="expand" for="c-37197306">[1 more]</label></div><br/><div class="children"><div class="content"><i>twitch</i> I thought the Queen was greedy and had very little patience - why are we traversing the input list twice in both generated responses?</div><br/></div></div><div id="37195286" class="c"><input type="checkbox" id="c-37195286" checked=""/><div class="controls bullet"><span class="by">PaulHoule</span><span>|</span><a href="#37197306">prev</a><span>|</span><a href="#37196413">next</a><span>|</span><label class="collapse" for="c-37195286">[-]</label><label class="expand" for="c-37195286">[3 more]</label></div><br/><div class="children"><div class="content">What is it with rude and ignorant people who recycle version numbers?  There was Web 3.0<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Semantic_Web" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Semantic_Web</a><p>and the blockheads totally ignored it.  (e.g. I had a Web 3.0 site a decade before they did!)<p>Similarly there was a lot of talk about 4GL in the 1980s<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fourth-generation_programming_language" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fourth-generation_programming_...</a><p>some of which was related to the same symbolic A.I. ideas that were influential to the semantic web.</div><br/><div id="37196235" class="c"><input type="checkbox" id="c-37196235" checked=""/><div class="controls bullet"><span class="by">linguae</span><span>|</span><a href="#37195286">parent</a><span>|</span><a href="#37196413">next</a><span>|</span><label class="collapse" for="c-37196235">[-]</label><label class="expand" for="c-37196235">[2 more]</label></div><br/><div class="children"><div class="content">I think a major part of it is a lack of knowledge of history among many people in computer science and software engineering, even researchers.  Alan Kay, the creator of the Smalltalk programming language and one of my personal heroes, has lamented many times over the years that a &quot;pop culture&quot; has developed in the software engineering and computer science world.  This culture is focused on the present and often disregards the past.  It&#x27;s more than the overloading of terminology like &quot;Web 3.0&quot; and &quot;fourth-generation programming languages.&quot;  It&#x27;s an overall attitude that focuses solely on the fad du jour and lacks a deeper understanding of computing.<p>I&#x27;ve noticed a lack of knowledge of computing history among many people who work in computing professions.  Personally I think all undergraduate students of computer science and related disciplines would benefit immensely from a one-semester history of computing course.  They&#x27;d start by learning about early analog computing devices before learning about two very crucial developments in the 1930&#x27;s and 1940&#x27;s: (1) the invention of early digital computers such as the ENIAC, and (2) meta-mathematics and how that led to Godel&#x27;s incompleteness theorem, the lambda calculus, Turing machines, and other fundamental concepts that underpin theoretical computer science.  Then they&#x27;d learn about the rise of the computer industry, the history of software, the history of high-level programming languages, the history of AI, advances in computer architecture, the birth of the Internet, the GUI, the World Wide Web, social networking, and modern topics such as deep neural networks and large language models.  It would be a lot of ground to cover and it would be impossible to cover everything in just a single course, but the goal of such a course is for practitioners in computer science and software engineering to have a basic understanding of the history of their profession and why things are the way that they are today.<p>I also believe that those fortunate enough to work in or visit Silicon Valley should make a visit to the Computer History Museum in Mountain View to get a taste of how far computing has come in just a relatively short amount of time compared to all of human history.</div><br/><div id="37196770" class="c"><input type="checkbox" id="c-37196770" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#37195286">root</a><span>|</span><a href="#37196235">parent</a><span>|</span><a href="#37196413">next</a><span>|</span><label class="collapse" for="c-37196770">[-]</label><label class="expand" for="c-37196770">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I also believe that those fortunate enough to work in or visit Silicon Valley should make a visit to the Computer History Museum in Mountain View to get a taste of how far computing has come in just a relatively short amount of time compared to all of human history.<p>Got to second this. That museum was the highlight of my visit, and I still remember everything in detail.</div><br/></div></div></div></div></div></div><div id="37196413" class="c"><input type="checkbox" id="c-37196413" checked=""/><div class="controls bullet"><span class="by">ixaxaar</span><span>|</span><a href="#37195286">prev</a><span>|</span><a href="#37196264">next</a><span>|</span><label class="collapse" for="c-37196413">[-]</label><label class="expand" for="c-37196413">[1 more]</label></div><br/><div class="children"><div class="content">I am not so sure if the determinism offered by programming languages is more meant for a human requirement or not - if it is, making programming languages more &quot;natural&quot; will actually backfire because a human ultimately needs to read it and understand.<p>Code is meant to be mostly read not written. And no, LLM explanations are shit useless, a language model simply cannot handhold a human to make them understand logic line by line, you NEED to read it, and hence code has to be &quot;readable&quot;, which to an engineer means &quot;precise&quot;.</div><br/></div></div><div id="37196264" class="c"><input type="checkbox" id="c-37196264" checked=""/><div class="controls bullet"><span class="by">isaiahg</span><span>|</span><a href="#37196413">prev</a><span>|</span><a href="#37196554">next</a><span>|</span><label class="collapse" for="c-37196264">[-]</label><label class="expand" for="c-37196264">[1 more]</label></div><br/><div class="children"><div class="content">This is something I’ve been thinking about for some time, a new type of programming that uses an ai model for parsing. It’s a interesting thought that can lead down many rabbit holes. You could have AI interpret a lot of expressiveness into a language while having an optimizing AI turn whatever crazy thing we come up with into fast code.<p>For any prospective language designers out there. Please don’t make human based language programming a thing again. That’s an idea that should stay in the waste bin. A language that describes programs shouldn’t be ambiguous. I also wouldn’t trust any AI—no matter how smart—to create code I’d be happy with, unless I could go into very specific detail.<p>No limits on structure serialization though. Make that a one liner please</div><br/></div></div><div id="37196554" class="c"><input type="checkbox" id="c-37196554" checked=""/><div class="controls bullet"><span class="by">canvascritic</span><span>|</span><a href="#37196264">prev</a><span>|</span><a href="#37196718">next</a><span>|</span><label class="collapse" for="c-37196554">[-]</label><label class="expand" for="c-37196554">[1 more]</label></div><br/><div class="children"><div class="content">Haha I love this, great read. The concept of llms serving as a fourth generation compiler is not really novel. I think we saw Databricks in here talking about LLMs as the new compiler and Python as the new bytecode. Anyway if we&#x27;re to follow this line of thought, it might not be long before large language models begin interfacing directly with machine hardware, bypassing the need for languages like python and java altogether. Like what purpose would they serve? This could streamline computational processes, reducing overheads and inefficiencies.<p>As the distance between the llm and hardware closes, human interaction with these systems might evolve to use even higher-level languages, further abstracting us from the underlying mechanics. it&#x27;s conceivable that, in the hopefully distant future our interaction could advance to direct neural or brain interfaces, where our thoughts translate into commands without the need for any traditional &quot;coding&quot; at all. Instead the spec becomes the software. These are damn exciting times</div><br/></div></div><div id="37196718" class="c"><input type="checkbox" id="c-37196718" checked=""/><div class="controls bullet"><span class="by">richardjam73</span><span>|</span><a href="#37196554">prev</a><span>|</span><a href="#37196405">next</a><span>|</span><label class="collapse" for="c-37196718">[-]</label><label class="expand" for="c-37196718">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that their usage of 4th Generation Programming Languages is incorrect. The paper shows cleary that they understand the generations. The conclusion reads more like LLMs can translate from an human prompt to a 3GL such as python. The prompt is not quite human language but is rather a specific form of writing designed to get the output needed from the LLM, in this way it is a 4GL and the LLM is the compiler.</div><br/></div></div><div id="37196405" class="c"><input type="checkbox" id="c-37196405" checked=""/><div class="controls bullet"><span class="by">random3</span><span>|</span><a href="#37196718">prev</a><span>|</span><label class="collapse" for="c-37196405">[-]</label><label class="expand" for="c-37196405">[3 more]</label></div><br/><div class="children"><div class="content">Oh, so this isn&#x27;t about these 4GLs <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fourth-generation_programming_language" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fourth-generation_programming_...</a><p>This said, I&#x27;m not sure why we&#x27;d call natural language 4th gen it&#x27;s very much the first gen.</div><br/><div id="37196890" class="c"><input type="checkbox" id="c-37196890" checked=""/><div class="controls bullet"><span class="by">lifthrasiir</span><span>|</span><a href="#37196405">parent</a><span>|</span><label class="collapse" for="c-37196890">[-]</label><label class="expand" for="c-37196890">[2 more]</label></div><br/><div class="children"><div class="content">The original concepts of 4GL and 5GL are long gone [1], and I do think it is reasonable to reuse the 4GL label for other possibilities.<p>[1] In the sense that those labels do not describe the actual &quot;generation&quot;. There still exist visual programming (4GL) and constraint and logic programming (5GL), but they are no longer considered to delieve the goal of 4GL and 5GL by its own, and thus have failed to generate enough interest to be considered a &quot;generation&quot;.</div><br/><div id="37197212" class="c"><input type="checkbox" id="c-37197212" checked=""/><div class="controls bullet"><span class="by">mitjam</span><span>|</span><a href="#37196405">root</a><span>|</span><a href="#37196890">parent</a><span>|</span><label class="collapse" for="c-37197212">[-]</label><label class="expand" for="c-37197212">[1 more]</label></div><br/><div class="children"><div class="content">I think 4gl is alive and delivering on its goal of manipulating and analyzing a lot of data with few statements, for example in the form of SQL, R, Pandas, Mathematica, Wolfram Alpha, Power Query, and many more. Nobody calls it that way, anymore, however.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>