<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1698224463499" as="style"/><link rel="stylesheet" href="styles.css?v=1698224463499"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://simonwillison.net/2023/Oct/23/embeddings/">Embeddings: What they are and why they matter</a> <span class="domain">(<a href="https://simonwillison.net">simonwillison.net</a>)</span></div><div class="subtext"><span>simonw</span> | <span>45 comments</span></div><br/><div><div id="38008786" class="c"><input type="checkbox" id="c-38008786" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38010616">next</a><span>|</span><label class="collapse" for="c-38008786">[-]</label><label class="expand" for="c-38008786">[5 more]</label></div><br/><div class="children"><div class="content">Since publishing this I&#x27;ve found a few additional resources that are really useful for understanding embeddings at a lower level (my article is deliberately very high level and focuses mainly on their applications).<p>Cohere&#x27;s Text Embeddings Visually Explained: <a href="https:&#x2F;&#x2F;txt.cohere.com&#x2F;text-embeddings&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;txt.cohere.com&#x2F;text-embeddings&#x2F;</a><p>The Tensorflow Embedding Projector tool: <a href="https:&#x2F;&#x2F;projector.tensorflow.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;projector.tensorflow.org&#x2F;</a><p>What are embeddings? by Vicki Boykis is worth checking out as well: <a href="https:&#x2F;&#x2F;vickiboykis.com&#x2F;what_are_embeddings&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;vickiboykis.com&#x2F;what_are_embeddings&#x2F;</a><p>Actually I&#x27;ll add those as &quot;further reading&quot; at the bottom of the page.</div><br/><div id="38009473" class="c"><input type="checkbox" id="c-38009473" checked=""/><div class="controls bullet"><span class="by">ColinEberhardt</span><span>|</span><a href="#38008786">parent</a><span>|</span><a href="#38010256">next</a><span>|</span><label class="collapse" for="c-38009473">[-]</label><label class="expand" for="c-38009473">[1 more]</label></div><br/><div class="children"><div class="content">I had exactly the same idea a while back:<p><a href="https:&#x2F;&#x2F;blog.scottlogic.com&#x2F;2022&#x2F;02&#x2F;23&#x2F;word-embedding-recommendations.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.scottlogic.com&#x2F;2022&#x2F;02&#x2F;23&#x2F;word-embedding-recomm...</a><p>Using embeddings I increased engagement with related articles.<p>Personally I think embeddings are a powerful tool that are somewhat overlooked. They can be used to navigate between documents (and excerpts) based on similarities - or conversely find unique content.<p>All without worrying about hallucinations. In other words, they are quite ‘safe’</div><br/></div></div><div id="38010256" class="c"><input type="checkbox" id="c-38010256" checked=""/><div class="controls bullet"><span class="by">hhthrowaway1230</span><span>|</span><a href="#38008786">parent</a><span>|</span><a href="#38009473">prev</a><span>|</span><a href="#38009200">next</a><span>|</span><label class="collapse" for="c-38010256">[-]</label><label class="expand" for="c-38010256">[1 more]</label></div><br/><div class="children"><div class="content">simon, the way you write makes it so accessible for people that have limited experience with ai, ml or llms. thank you!<p>maybe it is also interesting to tell how some embeddings are established i.e via training and cutting of the classification layer or with things things like efficientnet</div><br/></div></div><div id="38009200" class="c"><input type="checkbox" id="c-38009200" checked=""/><div class="controls bullet"><span class="by">forgingahead</span><span>|</span><a href="#38008786">parent</a><span>|</span><a href="#38010256">prev</a><span>|</span><a href="#38010616">next</a><span>|</span><label class="collapse" for="c-38009200">[-]</label><label class="expand" for="c-38009200">[2 more]</label></div><br/><div class="children"><div class="content">Simon, just wanted to say thanks for all the great content and writings you&#x27;ve been putting out - it&#x27;s been super helpful to help digest a lot of the fast developments in this space. Always looking forward to the next one!</div><br/><div id="38009257" class="c"><input type="checkbox" id="c-38009257" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38008786">root</a><span>|</span><a href="#38009200">parent</a><span>|</span><a href="#38010616">next</a><span>|</span><label class="collapse" for="c-38009257">[-]</label><label class="expand" for="c-38009257">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for saying that!</div><br/></div></div></div></div></div></div><div id="38010616" class="c"><input type="checkbox" id="c-38010616" checked=""/><div class="controls bullet"><span class="by">wolfgangK</span><span>|</span><a href="#38008786">prev</a><span>|</span><a href="#38009896">next</a><span>|</span><label class="collapse" for="c-38010616">[-]</label><label class="expand" for="c-38010616">[2 more]</label></div><br/><div class="children"><div class="content">About words embeddings, the №1 example is the famous King - Man + Women = Queen
This works nicely in the vector space but fails to make a visual impression when projected on 2 dimensions. Neither with ACP, nor MDS ot t-SNE in my experience :
<a href="https:&#x2F;&#x2F;bhugueney.gitlab.io&#x2F;test-notebooks-org-publish&#x2F;jupyterlite&#x2F;lab&#x2F;?path=custom%2FWords-Embeddings.ipynb" rel="nofollow noreferrer">https:&#x2F;&#x2F;bhugueney.gitlab.io&#x2F;test-notebooks-org-publish&#x2F;jupyt...</a><p>(← JupyterLite Notebook doing words embedding in the browser : don&#x27;t try to run this on a smartphone !)<p>Does anyone know how to nicely visualize the poster child of words embeddings ?</div><br/><div id="38010694" class="c"><input type="checkbox" id="c-38010694" checked=""/><div class="controls bullet"><span class="by">lindenr</span><span>|</span><a href="#38010616">parent</a><span>|</span><a href="#38009896">next</a><span>|</span><label class="collapse" for="c-38010694">[-]</label><label class="expand" for="c-38010694">[1 more]</label></div><br/><div class="children"><div class="content">If I understand you right - you could visualize in 2d space: &quot;king&quot; at origin, X-axis is &quot;king&quot;-&quot;man&quot;, Y-axis is &quot;king&quot;-&quot;woman&quot; (or gram-schmidt if you really want orthogonal).<p>In 3d you can go one further and have the Z-axis be &quot;king&quot;-&quot;queen&quot; (or gram-schmidt again). The orthogonalized versions have the advantage that they give a closer notion of distance to what the underlying model sees. In the 2d case you will get exact distances except that it won&#x27;t show how far off &quot;queen&quot; you are when you compute &quot;king&quot;-&quot;man&quot;+&quot;woman&quot;. In the 3d case it should give exact distances.<p>Edit to add: With the 2d version you can maybe do some more stuff. IIRC &quot;queen&quot; is chosen as it&#x27;s the word with the closest embedding to X=&quot;king&quot;-&quot;man&quot;+&quot;woman&quot;. You can put the next few closest words on the 2d chart as well, each labeled with the orthogonal distance from the 2d plane. So then &quot;queen&quot; should be the word with the smallest (squared distance from X) + (squared orthogonal distance from plane), which you might be able to eyeball.</div><br/></div></div></div></div><div id="38009896" class="c"><input type="checkbox" id="c-38009896" checked=""/><div class="controls bullet"><span class="by">abricq</span><span>|</span><a href="#38010616">prev</a><span>|</span><a href="#38010488">next</a><span>|</span><label class="collapse" for="c-38009896">[-]</label><label class="expand" for="c-38009896">[1 more]</label></div><br/><div class="children"><div class="content">Not quite the same application, but in computer vision and visual SLAM algorithms (to construct a map of your surrounding using a camera) embeddings have become a de-facto method to perform place-recognition ! And it&#x27;s very similar to this article. It is called &quot;bag-of-word place recognition&quot; and it really became the standard, used by absolutely every open-source library nowadays.<p>The core idea is that each image is passed through a feature-extractor-descriptor pipeline and is &#x27;embedded&#x27; in a vector containing the N top features. While the camera moves, a database of images (called keyframes) is created (images are stored as much-lower dimensional vectors). Again while the camera moves, all images are used to query the database, something like cosine-similarity is used to retrieve the best match from the vector database. If a match happened, a stereo-constraints can be computed betweeen the query image and the match, and the software is able to update the map.<p>[1] is the original paper and here&#x27;s the most famous implementation: <a href="https:&#x2F;&#x2F;github.com&#x2F;dorian3d&#x2F;DBoW2">https:&#x2F;&#x2F;github.com&#x2F;dorian3d&#x2F;DBoW2</a><p>[1]: <a href="https:&#x2F;&#x2F;www.google.com&#x2F;search?client=firefox-b-d&amp;q=Bags+of+Binary+Words+for+Fast+Place+Recognition+in+Image+Sequences" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.google.com&#x2F;search?client=firefox-b-d&amp;q=Bags+of+B...</a></div><br/></div></div><div id="38010488" class="c"><input type="checkbox" id="c-38010488" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38009896">prev</a><span>|</span><a href="#38009308">next</a><span>|</span><label class="collapse" for="c-38010488">[-]</label><label class="expand" for="c-38010488">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m trying to understand the clustering code but not doing too well.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm-cluster&#x2F;blob&#x2F;main&#x2F;llm_cluster.py#L72">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm-cluster&#x2F;blob&#x2F;main&#x2F;llm_cluster....</a><p>So does this take each row from the DB, convert to a numpy array (?), then uses an existing model called MiniBatchKMeans (?) to go over that array and generate a bunch of labels.  Then add it to a dictionary and print to console.</div><br/></div></div><div id="38009308" class="c"><input type="checkbox" id="c-38009308" checked=""/><div class="controls bullet"><span class="by">Ozzie_osman</span><span>|</span><a href="#38010488">prev</a><span>|</span><a href="#38009039">next</a><span>|</span><label class="collapse" for="c-38009308">[-]</label><label class="expand" for="c-38009308">[2 more]</label></div><br/><div class="children"><div class="content">Having played around with embeddings and built a few production use-cases with them.. They are awesome and enable a lot of cool applications. But, if you&#x27;re building in a particular domain, you&#x27;ll hit limits with any off-the-shelf embeddings model. One way to think about this is that the off-the-shelf embedding models have a lot of dimensions, but some of those dimensions may and some may not that matter for your application (classification, content similarity, clustering, etc). In other words, a vector may be close to another vector in dimensions you don&#x27;t care about.<p>I look forward to seeing better tooling and literature around fine-tuning embedding models.</div><br/><div id="38010728" class="c"><input type="checkbox" id="c-38010728" checked=""/><div class="controls bullet"><span class="by">eldenring</span><span>|</span><a href="#38009308">parent</a><span>|</span><a href="#38009039">next</a><span>|</span><label class="collapse" for="c-38010728">[-]</label><label class="expand" for="c-38010728">[1 more]</label></div><br/><div class="children"><div class="content">Fine-tuning an entire language model to solve this problem is like using a sledgehammer on a nail. We have had tools for this for years, for example just label some data and train an SVM on your embedding space for classification.</div><br/></div></div></div></div><div id="38009039" class="c"><input type="checkbox" id="c-38009039" checked=""/><div class="controls bullet"><span class="by">quartz</span><span>|</span><a href="#38009308">prev</a><span>|</span><a href="#38010587">next</a><span>|</span><label class="collapse" for="c-38009039">[-]</label><label class="expand" for="c-38009039">[1 more]</label></div><br/><div class="children"><div class="content">This is a great zero to one reference.<p>I built my own note taking ios app a little while back and adding embeddings to my existing fulltext search functionality was 1) surprisingly easy and 2) way more powerful than I initially expected.<p>I knew it would work for things like if I search for &quot;dog&quot; I&#x27;ll also get notes that say &quot;canine&quot;, but I didn&#x27;t originally realize until I played around with it that if I search for something like &quot;pets I might like&quot; I&#x27;ll get all kinds of notes I&#x27;ve taken regarding various animals with positive sentiment.<p>It was the first big aha moment for me.<p>At the time I found Supabase&#x27;s PR for their DocsGPT really helpful for example code: <a href="https:&#x2F;&#x2F;github.com&#x2F;supabase&#x2F;supabase&#x2F;pull&#x2F;12056">https:&#x2F;&#x2F;github.com&#x2F;supabase&#x2F;supabase&#x2F;pull&#x2F;12056</a></div><br/></div></div><div id="38010587" class="c"><input type="checkbox" id="c-38010587" checked=""/><div class="controls bullet"><span class="by">FL33TW00D</span><span>|</span><a href="#38009039">prev</a><span>|</span><a href="#37988568">next</a><span>|</span><label class="collapse" for="c-38010587">[-]</label><label class="expand" for="c-38010587">[1 more]</label></div><br/><div class="children"><div class="content">How can I possibly know which models have gamed the MTEB benchmark and which haven&#x27;t?<p>It&#x27;s very hard to know which embedding models are objectively good now that everyone is gaming the benchmark.</div><br/></div></div><div id="37988568" class="c"><input type="checkbox" id="c-37988568" checked=""/><div class="controls bullet"><span class="by">lordgrenville</span><span>|</span><a href="#38010587">prev</a><span>|</span><a href="#38009553">next</a><span>|</span><label class="collapse" for="c-37988568">[-]</label><label class="expand" for="c-37988568">[4 more]</label></div><br/><div class="children"><div class="content">&gt; dot_product = sum(x * y for x, y in zip(a, b))<p>Wait, why would you do this and not use vectorised numpy operations?<p>&gt; I actually got ChatGPT to write all of my different versions of cosine similarity<p>Ah...</div><br/><div id="37989799" class="c"><input type="checkbox" id="c-37989799" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37988568">parent</a><span>|</span><a href="#38009553">next</a><span>|</span><label class="collapse" for="c-37989799">[-]</label><label class="expand" for="c-37989799">[3 more]</label></div><br/><div class="children"><div class="content">Two reasons. First, when I&#x27;m trying to explain stuff to people I find numpy syntax gets in the way.<p>And second, numpy isn&#x27;t the lightest dependency. I use it when I need the performance but I don&#x27;t like to default to it.</div><br/><div id="37990650" class="c"><input type="checkbox" id="c-37990650" checked=""/><div class="controls bullet"><span class="by">lordgrenville</span><span>|</span><a href="#37988568">root</a><span>|</span><a href="#37989799">parent</a><span>|</span><a href="#38010289">next</a><span>|</span><label class="collapse" for="c-37990650">[-]</label><label class="expand" for="c-37990650">[1 more]</label></div><br/><div class="children"><div class="content">Makes sense. And sorry for the snark - I enjoyed the post, and generally enjoy your writing as well.</div><br/></div></div><div id="38010289" class="c"><input type="checkbox" id="c-38010289" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#37988568">root</a><span>|</span><a href="#37989799">parent</a><span>|</span><a href="#37990650">prev</a><span>|</span><a href="#38009553">next</a><span>|</span><label class="collapse" for="c-38010289">[-]</label><label class="expand" for="c-38010289">[1 more]</label></div><br/><div class="children"><div class="content">I disagree that your version is more readable. If you don’t know linear algebra, the code is inscrutable, and if you do, dot(x,y)&#x2F;norm(x)&#x2F;norm(y) is about as close to the math as you can get.</div><br/></div></div></div></div></div></div><div id="38009553" class="c"><input type="checkbox" id="c-38009553" checked=""/><div class="controls bullet"><span class="by">26fingies</span><span>|</span><a href="#37988568">prev</a><span>|</span><a href="#38010358">next</a><span>|</span><label class="collapse" for="c-38009553">[-]</label><label class="expand" for="c-38009553">[3 more]</label></div><br/><div class="children"><div class="content">Admittedly i more or less skimmed and plan on going back over this tomorrow, but I dont see how these vectors are actually created. I get that I could use your llm tool or whatever, but that seems unsatisfactory. How is the sausage made? (or if thats explained can someone point me at the right place to look?)</div><br/><div id="38009634" class="c"><input type="checkbox" id="c-38009634" checked=""/><div class="controls bullet"><span class="by">n2d4</span><span>|</span><a href="#38009553">parent</a><span>|</span><a href="#38009721">next</a><span>|</span><label class="collapse" for="c-38009634">[-]</label><label class="expand" for="c-38009634">[1 more]</label></div><br/><div class="children"><div class="content">In essence, an embedding vector is (lossy) compression. Any compression could in theory be used to make such vectors, for example people have tried using gzip embeddings.<p>Now on how to get a compression vector from an LLM, simplified: Most ML models are built from different layers, executed one after another. Some of the layers are bigger, some are smaller, but each has a defined in- and output. If a layer&#x27;s input size is smaller than model&#x27;s input size, that must mean (lossy) compression must have happened to get there. So, you just evaluate the LLM on whatever you want to embed, and take the activation at the smallest layer input, and that&#x27;s your embedding vector.<p>Not <i>every</i> compression vector makes for good semantic embeddings (which requires that two similar phrases are next to each other in the embedding space), but because of how ML models work, this tends to be the case empirically.</div><br/></div></div><div id="38009721" class="c"><input type="checkbox" id="c-38009721" checked=""/><div class="controls bullet"><span class="by">lelanthran</span><span>|</span><a href="#38009553">parent</a><span>|</span><a href="#38009634">prev</a><span>|</span><a href="#38010358">next</a><span>|</span><label class="collapse" for="c-38009721">[-]</label><label class="expand" for="c-38009721">[1 more]</label></div><br/><div class="children"><div class="content">I second this question. Not that the article wasn&#x27;t helpful, but I think of it as a good start - now how do I generate that array of floats?</div><br/></div></div></div></div><div id="38010358" class="c"><input type="checkbox" id="c-38010358" checked=""/><div class="controls bullet"><span class="by">tudorw</span><span>|</span><a href="#38009553">prev</a><span>|</span><a href="#38009852">next</a><span>|</span><label class="collapse" for="c-38010358">[-]</label><label class="expand" for="c-38010358">[1 more]</label></div><br/><div class="children"><div class="content">Has anyone used PHATE for visualising?<p>&quot;PHATE is a dimensionality reduction and visualization tool designed to preserve both local and global data structure.&quot;</div><br/></div></div><div id="38009852" class="c"><input type="checkbox" id="c-38009852" checked=""/><div class="controls bullet"><span class="by">heisenburgzero</span><span>|</span><a href="#38010358">prev</a><span>|</span><a href="#38009615">next</a><span>|</span><label class="collapse" for="c-38009852">[-]</label><label class="expand" for="c-38009852">[4 more]</label></div><br/><div class="children"><div class="content">Why does the embeddings have linear properties such that you can use functions like cosine similarity to compare? It seems that after the signal going through so many non-linear activation layers, the linear properties should have been broken down &#x2F; no guarantees.<p>I wasn&#x27;t able to find a good answer online.</div><br/><div id="38010250" class="c"><input type="checkbox" id="c-38010250" checked=""/><div class="controls bullet"><span class="by">montebicyclelo</span><span>|</span><a href="#38009852">parent</a><span>|</span><a href="#38010318">next</a><span>|</span><label class="collapse" for="c-38010250">[-]</label><label class="expand" for="c-38010250">[1 more]</label></div><br/><div class="children"><div class="content">LLM vectors do have decent linear properties already. But for document embedding purposes they are often further trained for retrieval via cosine similarity, which enhances this, e.g. see table 1 in [1], avg retrieval performancs using BERT goes up from 54 to 76 after fine-tuning for embeddings.<p>[1] <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1908.10084.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1908.10084.pdf</a></div><br/></div></div><div id="38010318" class="c"><input type="checkbox" id="c-38010318" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#38009852">parent</a><span>|</span><a href="#38010250">prev</a><span>|</span><a href="#38010144">next</a><span>|</span><label class="collapse" for="c-38010318">[-]</label><label class="expand" for="c-38010318">[1 more]</label></div><br/><div class="children"><div class="content">The cosine similarity is not inherently better suited for linear properties whatever that means, it’s just the cosine of the angle between two vectors. If the vectors are unit length, then it’s just the projection of one to the other.</div><br/></div></div><div id="38010144" class="c"><input type="checkbox" id="c-38010144" checked=""/><div class="controls bullet"><span class="by">blackbear_</span><span>|</span><a href="#38009852">parent</a><span>|</span><a href="#38010318">prev</a><span>|</span><a href="#38009615">next</a><span>|</span><label class="collapse" for="c-38010144">[-]</label><label class="expand" for="c-38010144">[1 more]</label></div><br/><div class="children"><div class="content">Because neural networks use dot products, which are just un-normalized cosine similarities, as the main way to compare and transform embeddings in their hidden layers. Therefore, it makes sense that the most important signals in the data arranged in latent space such that they are amenable to manipulations based on dot products</div><br/></div></div></div></div><div id="38009615" class="c"><input type="checkbox" id="c-38009615" checked=""/><div class="controls bullet"><span class="by">pseudosavant</span><span>|</span><a href="#38009852">prev</a><span>|</span><a href="#38010025">next</a><span>|</span><label class="collapse" for="c-38009615">[-]</label><label class="expand" for="c-38009615">[1 more]</label></div><br/><div class="children"><div class="content">This is the most interesting thing I&#x27;ve read about in &quot;AI&quot; in quite a few months. I always wondered what embedding models were when I&#x27;d see lists, or curious why everyone is talking about vector DBs.<p>This is immediately making me think about how I could apply this to a long running side project I have. It might make it practical to do useful clustering of user&#x27;s data if every document has an embedding.</div><br/></div></div><div id="38010025" class="c"><input type="checkbox" id="c-38010025" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38009615">prev</a><span>|</span><a href="#38009720">next</a><span>|</span><label class="collapse" for="c-38010025">[-]</label><label class="expand" for="c-38010025">[3 more]</label></div><br/><div class="children"><div class="content">Is there a ready made search framework commercially speaking like an aws service or of the shelf database, for sites that will take all your articles and for a given article find all similar ones?</div><br/><div id="38010142" class="c"><input type="checkbox" id="c-38010142" checked=""/><div class="controls bullet"><span class="by">m3at</span><span>|</span><a href="#38010025">parent</a><span>|</span><a href="#38009720">next</a><span>|</span><label class="collapse" for="c-38010142">[-]</label><label class="expand" for="c-38010142">[2 more]</label></div><br/><div class="children"><div class="content">Depends what you mean by taking all your articles. If it&#x27;s scraping no, but if you provide text content and urls as key&#x2F;values pairs yes.<p>SageMaker and VertexAI are the AI services of AWS and GCP respectively, and they both offer embedding generation and vector databases (the two key pieces necessary for embedding search).<p>There are a bunch of smaller companies offering vector search as a service too, example pinecone to name just one: <a href="https:&#x2F;&#x2F;www.pinecone.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.pinecone.io&#x2F;</a></div><br/><div id="38010381" class="c"><input type="checkbox" id="c-38010381" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#38010025">root</a><span>|</span><a href="#38010142">parent</a><span>|</span><a href="#38009720">next</a><span>|</span><label class="collapse" for="c-38010381">[-]</label><label class="expand" for="c-38010381">[1 more]</label></div><br/><div class="children"><div class="content">Thanks, will have a look. Yeah in this case I&#x27;d want to provide the text content.<p>I also just found pgvector which seems like it could help? It has a similarity search.</div><br/></div></div></div></div></div></div><div id="38009720" class="c"><input type="checkbox" id="c-38009720" checked=""/><div class="controls bullet"><span class="by">benreesman</span><span>|</span><a href="#38010025">prev</a><span>|</span><a href="#37987675">next</a><span>|</span><label class="collapse" for="c-38009720">[-]</label><label class="expand" for="c-38009720">[1 more]</label></div><br/><div class="children"><div class="content">Great article! I can’t remember the YouTuber’s name or what to search for, but one of the Pinecone people has great videos at an introductory-to-intermediate level that is both really accessible and well motivated by examples.<p>Anyone remember?</div><br/></div></div><div id="37987675" class="c"><input type="checkbox" id="c-37987675" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38009720">prev</a><span>|</span><a href="#38008856">next</a><span>|</span><label class="collapse" for="c-37987675">[-]</label><label class="expand" for="c-37987675">[4 more]</label></div><br/><div class="children"><div class="content">If you&#x27;ve been wondering why there&#x27;s so much hype around vector databases at the moment this article should help explain that too - embeddings and vector databases both occupy the same space.</div><br/><div id="38008723" class="c"><input type="checkbox" id="c-38008723" checked=""/><div class="controls bullet"><span class="by">williamcotton</span><span>|</span><a href="#37987675">parent</a><span>|</span><a href="#38009535">next</a><span>|</span><label class="collapse" for="c-38008723">[-]</label><label class="expand" for="c-38008723">[1 more]</label></div><br/><div class="children"><div class="content">The same… vector space?<p>I’ll show myself out…</div><br/></div></div><div id="38009535" class="c"><input type="checkbox" id="c-38009535" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#37987675">parent</a><span>|</span><a href="#38008723">prev</a><span>|</span><a href="#38008856">next</a><span>|</span><label class="collapse" for="c-38009535">[-]</label><label class="expand" for="c-38009535">[2 more]</label></div><br/><div class="children"><div class="content">Is it because with transformers and LLMs the embeddings are more powerful than they have been before (they can seem to understand more)?</div><br/><div id="38010606" class="c"><input type="checkbox" id="c-38010606" checked=""/><div class="controls bullet"><span class="by">jaggederest</span><span>|</span><a href="#37987675">root</a><span>|</span><a href="#38009535">parent</a><span>|</span><a href="#38008856">next</a><span>|</span><label class="collapse" for="c-38010606">[-]</label><label class="expand" for="c-38010606">[1 more]</label></div><br/><div class="children"><div class="content">Broadly, as I understand it, the way the embeddings are generated &quot;needs&quot; LLMs to produce the superior results you&#x27;d see with e.g. OpenAI&#x27;s text-embedding-ada-002 - we&#x27;ve been working with vectors at least as long as I&#x27;ve been programming, but until recently they didn&#x27;t <i>mean</i> anything particular. LLMs let the vectors have semantic meaning and relate similar conceptual text, instead of (as in the article) using gzip to generate vectors where the similarity is entirely textual, i.e. similar words and passages and characters, even if they have different meanings.<p>So ultimately they&#x27;re not at all new (embedding data into a hamming space to compare it to other data), but the underlying meaning is much more useful in a world where you can peek into the internal state of a LLM to generate them.</div><br/></div></div></div></div></div></div><div id="38008856" class="c"><input type="checkbox" id="c-38008856" checked=""/><div class="controls bullet"><span class="by">zachthewf</span><span>|</span><a href="#37987675">prev</a><span>|</span><a href="#38008937">next</a><span>|</span><label class="collapse" for="c-38008856">[-]</label><label class="expand" for="c-38008856">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious to know more about your experience with ImageBind, and what applications for multimodal embeddings are most exciting to you.</div><br/><div id="38008878" class="c"><input type="checkbox" id="c-38008878" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38008856">parent</a><span>|</span><a href="#38008937">next</a><span>|</span><label class="collapse" for="c-38008878">[-]</label><label class="expand" for="c-38008878">[1 more]</label></div><br/><div class="children"><div class="content">So far I&#x27;ve only just played with it - I don&#x27;t even fully understand what some of those file formats are!<p>I got it to compare an image to an audio file which was pretty neat. I need to dig in more and see what kind of useful things I can use it for.</div><br/></div></div></div></div><div id="38008937" class="c"><input type="checkbox" id="c-38008937" checked=""/><div class="controls bullet"><span class="by">tayo42</span><span>|</span><a href="#38008856">prev</a><span>|</span><label class="collapse" for="c-38008937">[-]</label><label class="expand" for="c-38008937">[8 more]</label></div><br/><div class="children"><div class="content">Ive been playing with embeddings lately for document search based off queries&#x2F;questions. this makes it seem like they work great, but it hasn&#x27;t been very smooth for me.<p>I kept running into people recommending against using them for long documents? Is openai better then the models sentenance-transformers uses? I found some recommendations to average together the embeddings of parts. I guess its cutting edge-ish still, a lot still feels like you can have a cool demo quickly, but something reliable and accurate is a lot of work?</div><br/><div id="38008948" class="c"><input type="checkbox" id="c-38008948" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#38008937">parent</a><span>|</span><a href="#38009732">next</a><span>|</span><label class="collapse" for="c-38008948">[-]</label><label class="expand" for="c-38008948">[5 more]</label></div><br/><div class="children"><div class="content">OpenAI&#x27;s embedding model works up to 8,000 tokens. The sentence-transformers ones are mostly smaller than that, though there&#x27;s a new model that just came out that can handle 8,000: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;jinaai&#x2F;jina-embeddings-v2-base-en" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;jinaai&#x2F;jina-embeddings-v2-base-en</a><p>People tend to &quot;chunk&quot; larger documents - the chunking strategy that&#x27;s best is very dependent on what you are using the embeddings for. I&#x27;ve found it frustratingly hard to find really good guidance as to chunking strategies.<p>I&#x27;ve had good results for Q&amp;A chunking my blog content up into paragraph sized chunks, as described here: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Oct&#x2F;23&#x2F;embeddings&#x2F;#answering-questions-with-retrieval-augmented-generation" rel="nofollow noreferrer">https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Oct&#x2F;23&#x2F;embeddings&#x2F;#answering-...</a> - but I&#x27;m not ready to say that&#x27;s a universally good practice.</div><br/><div id="38009263" class="c"><input type="checkbox" id="c-38009263" checked=""/><div class="controls bullet"><span class="by">llmllmllm</span><span>|</span><a href="#38008937">root</a><span>|</span><a href="#38008948">parent</a><span>|</span><a href="#38009179">next</a><span>|</span><label class="collapse" for="c-38009263">[-]</label><label class="expand" for="c-38009263">[1 more]</label></div><br/><div class="children"><div class="content">I have found success with chunking with 100 tokens, preceeded by the last 10 tokens of the previous chunk, and the first 10 tokens of the next chunk, 120 tokens total. I generate an embedding for each, then compare that to embedding(s) derived from the input query.<p>How to generate embeddings from the input query well is where one&#x27;s focus should be IMO. An example: &quot;don&#x27;t mention x&quot; being turned into filtering out &#x2F; de-emphasizing chunks that align with the embedding for x.<p>I&#x27;ve been using these techniques along with pgvector and OpenAI&#x27;s embeddings for <a href="https:&#x2F;&#x2F;flowch.ai" rel="nofollow noreferrer">https:&#x2F;&#x2F;flowch.ai</a> and it works really well. A user uploads a document or uses the Chrome Extension on a webpage and FlowChai chunks up the content, generates embeddings, builds up a RAG context and then produces a report based on the user&#x27;s prompt.<p>I hope that helps show a real world example. You&#x27;re welcome to play with FlowChai for free to see how it works in practice at the application level.</div><br/></div></div><div id="38009179" class="c"><input type="checkbox" id="c-38009179" checked=""/><div class="controls bullet"><span class="by">CityOfThrowaway</span><span>|</span><a href="#38008937">root</a><span>|</span><a href="#38008948">parent</a><span>|</span><a href="#38009263">prev</a><span>|</span><a href="#38009732">next</a><span>|</span><label class="collapse" for="c-38009179">[-]</label><label class="expand" for="c-38009179">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m also curious about how to think about chunking for Doc-to-Doc similarity.<p>Say I have an input document that I want to use as my search query and a database of potential results documents.<p>It&#x27;s not clear to me that I should simply embed both the input document and each of the results documents. If the documents contain a variety of ideas, I&#x27;d be nervous they wind getting embedded into some generic space.<p>But I don&#x27;t have any good ideas as to what type of chunk-match-and-aggregate strategy might work well here.<p>Would love ideas from folks that have done stuff like this!</div><br/><div id="38009340" class="c"><input type="checkbox" id="c-38009340" checked=""/><div class="controls bullet"><span class="by">Swizec</span><span>|</span><a href="#38008937">root</a><span>|</span><a href="#38009179">parent</a><span>|</span><a href="#38009249">prev</a><span>|</span><a href="#38009732">next</a><span>|</span><label class="collapse" for="c-38009340">[-]</label><label class="expand" for="c-38009340">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If the documents contain a variety of ideas<p>I&#x27;ve found chunking by sub-headings works really well.<p>But here&#x27;s a dirty secret I&#x27;ve learned as a writer: Your document can only ever contain 1 idea. That&#x27;s the most that human readers can manage.</div><br/></div></div></div></div></div></div><div id="38009732" class="c"><input type="checkbox" id="c-38009732" checked=""/><div class="controls bullet"><span class="by">jn2clark</span><span>|</span><a href="#38008937">parent</a><span>|</span><a href="#38008948">prev</a><span>|</span><a href="#38009662">next</a><span>|</span><label class="collapse" for="c-38009732">[-]</label><label class="expand" for="c-38009732">[1 more]</label></div><br/><div class="children"><div class="content">Try this <a href="https:&#x2F;&#x2F;github.com&#x2F;marqo-ai&#x2F;marqo">https:&#x2F;&#x2F;github.com&#x2F;marqo-ai&#x2F;marqo</a> which handles all the chunking for you (and is configurable). Also handles chunking of images in an analogous way. This enables highlighting in longer docs and also for images in a single retrieval step.</div><br/></div></div><div id="38009662" class="c"><input type="checkbox" id="c-38009662" checked=""/><div class="controls bullet"><span class="by">freediver</span><span>|</span><a href="#38008937">parent</a><span>|</span><a href="#38009732">prev</a><span>|</span><label class="collapse" for="c-38009662">[-]</label><label class="expand" for="c-38009662">[1 more]</label></div><br/><div class="children"><div class="content">If you are looking for lightweight, low- latency, fully local, end-to-end solution (chunking, embedding, storage and vector search), try vectordb [1]<p>Just spent a day updating it with latest benchmarks for text embedding models.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;kagisearch&#x2F;vectordb">https:&#x2F;&#x2F;github.com&#x2F;kagisearch&#x2F;vectordb</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>