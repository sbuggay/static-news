<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1694163660314" as="style"/><link rel="stylesheet" href="styles.css?v=1694163660314"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.lancedb.com/llms-rag-the-missing-storage-layer-for-ai-28ded35fa984">LLMs, RAG, and the missing storage layer for AI</a> <span class="domain">(<a href="https://blog.lancedb.com">blog.lancedb.com</a>)</span></div><div class="subtext"><span>yurisagalov</span> | <span>39 comments</span></div><br/><div><div id="37430866" class="c"><input type="checkbox" id="c-37430866" checked=""/><div class="controls bullet"><span class="by">ianpurton</span><span>|</span><a href="#37428429">next</a><span>|</span><label class="collapse" for="c-37430866">[-]</label><label class="expand" for="c-37430866">[2 more]</label></div><br/><div class="children"><div class="content">As an architect working on LLM applications I have these criteria for a database.<p>- Full SQL support<p>- Has good tooling around migrations (i.e. dbmate)<p>- Good support for running in Kubernetes or in the cloud<p>- Well understood by operations i.e. backups and scaling<p>- Supports vectors and similarity search.<p>- Well supported client libraries<p>So basically Postgres and PgVector.</div><br/><div id="37431072" class="c"><input type="checkbox" id="c-37431072" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#37430866">parent</a><span>|</span><a href="#37428429">next</a><span>|</span><label class="collapse" for="c-37431072">[-]</label><label class="expand" for="c-37431072">[1 more]</label></div><br/><div class="children"><div class="content">Exactly.  The whole point about databases is you don&#x27;t need &quot;a database for AI&quot; you need a database, ideally with an extension to add additional AI functionality (ie postgres and pgvector).  Trying to take a special store you invent for AI and retrofit all the desirable things you need to make it work properly in the context of a real application you&#x27;re just going to end up with a mess.<p>As a thought-experiment for people who don&#x27;t understand why you need (for example) regular relational columns alongside vector storage, consider how you would implement RAG for a set of documents where not everyone has permission to view every document.  In the pgvector case it&#x27;s easy - I can add one or more label columns and then when I do my search query filter to only include labels that user has permission to view.  Then my vector similarity results will definitely not include anything that violates my access control. Trivial with something like pgvector - basically impossible (afaics) with special-purpose vector stores.<p>Or think about ranking.  Say you want to do RAG over a space where you want to prioritise the most recent results, not just pure similarity. Or prioritise on a set of other features somehow (source credibility whatever). Easy to do if you have relational columns, no bueno if you just have a vector store.<p>And that&#x27;s not to mention the obvious things around ACID, availability, recovery, replication, etc.</div><br/></div></div></div></div><div id="37428429" class="c"><input type="checkbox" id="c-37428429" checked=""/><div class="controls bullet"><span class="by">panarky</span><span>|</span><a href="#37430866">prev</a><span>|</span><a href="#37429697">next</a><span>|</span><label class="collapse" for="c-37428429">[-]</label><label class="expand" for="c-37428429">[21 more]</label></div><br/><div class="children"><div class="content">The first unstated assumption is that similar vectors are relevant documents, and for many use cases that&#x27;s just not true. Cosine similarity != relevance. So if your pipeline pulls 2 or 4 or 12 document chunks into the LLM&#x27;s context, and half or more of them aren&#x27;t relevant, does this make the LLM&#x27;s response more or less relevant?<p>The second unstated assumption is that the vector index can accurately identify the top K vectors by cosine similarity, and that&#x27;s not true either. If you retrieve the top K vectors according to the vector index (instead of computing all the pairwise similarities in advance), that set of 10 vectors will be missing documents that have a higher cosine similarity than that of the K&#x27;th vector retrieved.<p>All of this means you&#x27;ll need to retrieve a multiple of K vectors, figure out some way to re-rank them to exclude the irrelevant ones, and have your own ground truth to measure the index&#x27;s precision and recall.</div><br/><div id="37428804" class="c"><input type="checkbox" id="c-37428804" checked=""/><div class="controls bullet"><span class="by">brigadier132</span><span>|</span><a href="#37428429">parent</a><span>|</span><a href="#37428797">next</a><span>|</span><label class="collapse" for="c-37428804">[-]</label><label class="expand" for="c-37428804">[11 more]</label></div><br/><div class="children"><div class="content">The vectors are literally constructed so that cosine similarity <i>is</i> semantic similarity.<p>&gt; second unstated assumption is that the vector index can accurately identify the top K vectors by cosine similarity, and that&#x27;s not true either<p>Its not unstated, its called ANN for a reason</div><br/><div id="37431090" class="c"><input type="checkbox" id="c-37431090" checked=""/><div class="controls bullet"><span class="by">godelski</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37428804">parent</a><span>|</span><a href="#37429003">next</a><span>|</span><label class="collapse" for="c-37431090">[-]</label><label class="expand" for="c-37431090">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  The vectors are literally constructed so that cosine similarity is semantic similarity.<p>Are they? A learned embedding doesn&#x27;t guarantee this and a positional embedding certainly doesn&#x27;t. Our latent embeddings don&#x27;t either unless you are inferring this through the dot product in the attention mechanism. But that too is learned. There are no guarantees that the similarities that they learn are the same things we consider as similarities. High dimensional space is really weird.<p>And while we&#x27;re at it, we should mention that methods like t-SNE and UMAP are clustering algorithms not dimensional reduction. Just because they can find ways to cluster the data in a lower dimensional projection (epic mapping) doesn&#x27;t mean that they are similar in the higher dimensional space. It all depends on the ability to unknot in the higher dimensional space.<p>It is extremely important to do what the OP is doing and consider the assumptions of the model, data, and measurements. Good results do not necessarily mean good methods. I like to say that you don&#x27;t need to know math to make a good model, but you do need to know math to know why your model is wrong. Your comment just comes off as dismissive rather than actually countering the claims. There&#x27;s plenty more assumptions than OP listed too. But their assumptions don&#x27;t mean the model won&#x27;t work, it just means what constraints the model is working under. We want to understand the constraints&#x2F;assumptions if we want to make better models. Large models have advantages because they can have larger latent spaces and that gives them a lot of freedom to unknot data and move them around as they please. But that doesn&#x27;t mean the methods are efficient.</div><br/></div></div><div id="37429003" class="c"><input type="checkbox" id="c-37429003" checked=""/><div class="controls bullet"><span class="by">spott</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37428804">parent</a><span>|</span><a href="#37431090">prev</a><span>|</span><a href="#37429968">next</a><span>|</span><label class="collapse" for="c-37429003">[-]</label><label class="expand" for="c-37429003">[6 more]</label></div><br/><div class="children"><div class="content">To be fair… semantic similarity isn’t the same as relevance either.<p>They are related, and we frequently assume they are close enough that it doesn’t matter, but they are different.</div><br/><div id="37430574" class="c"><input type="checkbox" id="c-37430574" checked=""/><div class="controls bullet"><span class="by">petra</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37429003">parent</a><span>|</span><a href="#37429143">next</a><span>|</span><label class="collapse" for="c-37430574">[-]</label><label class="expand" for="c-37430574">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s interesting.<p>Are there any good sources to learn more about that?</div><br/></div></div><div id="37429143" class="c"><input type="checkbox" id="c-37429143" checked=""/><div class="controls bullet"><span class="by">brigadier132</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37429003">parent</a><span>|</span><a href="#37430574">prev</a><span>|</span><a href="#37429968">next</a><span>|</span><label class="collapse" for="c-37429143">[-]</label><label class="expand" for="c-37429143">[4 more]</label></div><br/><div class="children"><div class="content">I disagree, the embeddings are what are used by the llms themselves to produce relevant output and the output is relevant ergo the embeddings do produce relevant output via similarity search</div><br/><div id="37429542" class="c"><input type="checkbox" id="c-37429542" checked=""/><div class="controls bullet"><span class="by">spott</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37429143">parent</a><span>|</span><a href="#37429262">next</a><span>|</span><label class="collapse" for="c-37429542">[-]</label><label class="expand" for="c-37429542">[2 more]</label></div><br/><div class="children"><div class="content">You probably aren’t using an LLM for your text embeddings for document retrieval (they don’t perform as well as specialist embedding models[0]), and even if they did, you have an embedding about a bare document, without any context of what you are trying to get out of it.  If you were to add your context in and then get an embedding, you would get a different answer.  As your query gets specific, irrelevant aspects of the embedding space can overwhelm the similarity function, leading to irrelevant answers that are still semantically similar.<p>[0] <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;mteb&#x2F;leaderboard</a></div><br/><div id="37430716" class="c"><input type="checkbox" id="c-37430716" checked=""/><div class="controls bullet"><span class="by">regularfry</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37429542">parent</a><span>|</span><a href="#37429262">next</a><span>|</span><label class="collapse" for="c-37430716">[-]</label><label class="expand" for="c-37430716">[1 more]</label></div><br/><div class="children"><div class="content">The recent SILO-LM paper has a slightly different approach: rather than using input embeddings and prompting the LLM with documents, it searches the database according to the LLM&#x27;s <i>output</i> embedding and uses KNN search to skew the output embedding vector before token generation. Done that way round, using LLM embeddings outperforms RAG, allegedly.<p>They did it with a custom language model.  I really want to give this a try with llama2 embeddings but haven&#x27;t had the bandwidth yet (and llama2&#x27;s embedding vectors are inconveniently huge, but that&#x27;s a different problem).</div><br/></div></div></div></div><div id="37429262" class="c"><input type="checkbox" id="c-37429262" checked=""/><div class="controls bullet"><span class="by">viscanti</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37429143">parent</a><span>|</span><a href="#37429542">prev</a><span>|</span><a href="#37429968">next</a><span>|</span><label class="collapse" for="c-37429262">[-]</label><label class="expand" for="c-37429262">[1 more]</label></div><br/><div class="children"><div class="content">Not if you&#x27;re using ANN. In some cases that will be very similar to exhaustive search but in other cases you&#x27;ll get results that you don&#x27;t want. You also need embeddings that distribute things mostly evenly across the embedding space (not all will).</div><br/></div></div></div></div></div></div><div id="37429968" class="c"><input type="checkbox" id="c-37429968" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37428804">parent</a><span>|</span><a href="#37429003">prev</a><span>|</span><a href="#37428797">next</a><span>|</span><label class="collapse" for="c-37429968">[-]</label><label class="expand" for="c-37429968">[3 more]</label></div><br/><div class="children"><div class="content">This is kind of a moot argument, semantic similarity is higher dimensionality than cosine similarity can capture.<p>If I&#x27;m using vectors for question&#x2F;answer, then:<p>&quot;What is a cat&quot;<p>and<p>&quot;What is a dog&quot;<p>Should be more dissimilar than the documents answering either.<p>If I&#x27;m using it for FAQ filtering then they should be more similar.</div><br/><div id="37430627" class="c"><input type="checkbox" id="c-37430627" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37429968">parent</a><span>|</span><a href="#37428797">next</a><span>|</span><label class="collapse" for="c-37430627">[-]</label><label class="expand" for="c-37430627">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had decent results using a doc2query style approach:<p><pre><code>    1. Ask an LLM to return a list of questions answered by the document
    2. Store the embeddings of the questions along with a document ID
    3. On user query, get the embedding of the user query
    4. KNN cosine similarity search the user embedding vs. the corpus of question embeddings
    5. Return the highest ranked documents
</code></pre>
You can tweak this approach depending on your use case, so that in step 1 you generate embeddings that are more similar to the types of things you want returned in step 5. If you want the answer to &quot;What is a cat&quot; to be similar to &quot;What is a dog,&quot; you&#x27;d prompt&#x2F;finetune the LLM in step 1 to generate broad questions that would encompass both; if you want them to be very different, you&#x27;d do the opposite and avoid generalities.</div><br/><div id="37431186" class="c"><input type="checkbox" id="c-37431186" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37430627">parent</a><span>|</span><a href="#37428797">next</a><span>|</span><label class="collapse" for="c-37431186">[-]</label><label class="expand" for="c-37431186">[1 more]</label></div><br/><div class="children"><div class="content">You just reinvented a 2 year old technique with a more expensive pipeline and missed performance gains (from the cross-encoder step):<p><a href="https:&#x2F;&#x2F;www.sbert.net&#x2F;examples&#x2F;domain_adaptation&#x2F;README.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sbert.net&#x2F;examples&#x2F;domain_adaptation&#x2F;README.html</a>
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.07577" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.07577</a></div><br/></div></div></div></div></div></div></div></div><div id="37428797" class="c"><input type="checkbox" id="c-37428797" checked=""/><div class="controls bullet"><span class="by">Jimmc414</span><span>|</span><a href="#37428429">parent</a><span>|</span><a href="#37428804">prev</a><span>|</span><a href="#37428581">next</a><span>|</span><label class="collapse" for="c-37428797">[-]</label><label class="expand" for="c-37428797">[6 more]</label></div><br/><div class="children"><div class="content">Switching to Word2Vec embeddings led to a substantial improvement in my cosine similarity evaluations for text similarity, but granted I was looking for actual similarity, not relevance.  I tried many different methods and had lots of mediocre results initially.<p>code:
<a href="https:&#x2F;&#x2F;github.com&#x2F;jimmc414&#x2F;document_intelligence&#x2F;blob&#x2F;main&#x2F;text_similarity.py">https:&#x2F;&#x2F;github.com&#x2F;jimmc414&#x2F;document_intelligence&#x2F;blob&#x2F;main&#x2F;...</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;jimmc414&#x2F;document_intelligence">https:&#x2F;&#x2F;github.com&#x2F;jimmc414&#x2F;document_intelligence</a></div><br/><div id="37429678" class="c"><input type="checkbox" id="c-37429678" checked=""/><div class="controls bullet"><span class="by">Nowado</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37428797">parent</a><span>|</span><a href="#37430076">next</a><span>|</span><label class="collapse" for="c-37429678">[-]</label><label class="expand" for="c-37429678">[2 more]</label></div><br/><div class="children"><div class="content">Interesting, do you happen to have some quantitative results on this&#x2F;additional insights&#x2F;etc?<p>I&#x27;ve interpreted transformer vector similarity as &#x27;likelihood to be followed by the same thing&#x27; which is <i>close</i> to word2vec&#x27;s &#x27;sum of likelihoods of all words to be replaced by the other set&#x27; (kinda), but also very different in some contexts.</div><br/><div id="37429978" class="c"><input type="checkbox" id="c-37429978" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37429678">parent</a><span>|</span><a href="#37430076">next</a><span>|</span><label class="collapse" for="c-37429978">[-]</label><label class="expand" for="c-37429978">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no simplified definition like that, vectors can even capture logical properties, it&#x27;s all down to what the model was tuned for: <a href="https:&#x2F;&#x2F;www.sbert.net&#x2F;examples&#x2F;training&#x2F;nli&#x2F;README.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sbert.net&#x2F;examples&#x2F;training&#x2F;nli&#x2F;README.html</a></div><br/></div></div></div></div><div id="37430076" class="c"><input type="checkbox" id="c-37430076" checked=""/><div class="controls bullet"><span class="by">sandGorgon</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37428797">parent</a><span>|</span><a href="#37429678">prev</a><span>|</span><a href="#37428935">next</a><span>|</span><label class="collapse" for="c-37430076">[-]</label><label class="expand" for="c-37430076">[1 more]</label></div><br/><div class="children"><div class="content">this is very interesting. you had better results here than the openai ada02 and other embeddings like bge ?</div><br/></div></div><div id="37428935" class="c"><input type="checkbox" id="c-37428935" checked=""/><div class="controls bullet"><span class="by">bugglebeetle</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37428797">parent</a><span>|</span><a href="#37430076">prev</a><span>|</span><a href="#37428581">next</a><span>|</span><label class="collapse" for="c-37428935">[-]</label><label class="expand" for="c-37428935">[2 more]</label></div><br/><div class="children"><div class="content">As opposed to sentencebert or what?</div><br/><div id="37428966" class="c"><input type="checkbox" id="c-37428966" checked=""/><div class="controls bullet"><span class="by">Jimmc414</span><span>|</span><a href="#37428429">root</a><span>|</span><a href="#37428935">parent</a><span>|</span><a href="#37428581">next</a><span>|</span><label class="collapse" for="c-37428966">[-]</label><label class="expand" for="c-37428966">[1 more]</label></div><br/><div class="children"><div class="content">DistilBERT and RoBERTa</div><br/></div></div></div></div></div></div><div id="37428581" class="c"><input type="checkbox" id="c-37428581" checked=""/><div class="controls bullet"><span class="by">NhanH</span><span>|</span><a href="#37428429">parent</a><span>|</span><a href="#37428797">prev</a><span>|</span><a href="#37430189">next</a><span>|</span><label class="collapse" for="c-37428581">[-]</label><label class="expand" for="c-37428581">[1 more]</label></div><br/><div class="children"><div class="content">Could you please explain a bit on your 2nd paragraph. I couldn’t quite understand either the problem statement nor the reasoning itself.</div><br/></div></div><div id="37430189" class="c"><input type="checkbox" id="c-37430189" checked=""/><div class="controls bullet"><span class="by">saliagato</span><span>|</span><a href="#37428429">parent</a><span>|</span><a href="#37428581">prev</a><span>|</span><a href="#37430219">next</a><span>|</span><label class="collapse" for="c-37430189">[-]</label><label class="expand" for="c-37430189">[1 more]</label></div><br/><div class="children"><div class="content">Azure Cognitive Search takes care of all of this combining semantic search with other layers of traditional search methods</div><br/></div></div><div id="37430219" class="c"><input type="checkbox" id="c-37430219" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#37428429">parent</a><span>|</span><a href="#37430189">prev</a><span>|</span><a href="#37429697">next</a><span>|</span><label class="collapse" for="c-37430219">[-]</label><label class="expand" for="c-37430219">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Cosine similarity != relevance&quot;  In all ML search products, there&#x27;s a tradeoff between precision and recall, and moreover there&#x27;s almost never any &quot;gold&quot; data that ensures the &quot;correctness&quot; of surfaced results.  I mean, Bing and Google have both invested millions of dollars in labeling web pages and even evaluating search results, but those labels can become useless as your set of documents change.<p>Cosine similar is a useful compromise and yes a lot of authors take this for granted.  At the end of the day, an LLM product probably won&#x27;t be evaluated on accuracy but rather &quot;lift&quot; over an alternative.  And the evaluation will be in units of user happiness.<p>&gt; All of this means you&#x27;ll need to retrieve a multiple of K vectors, figure out some way to re-rank them to exclude the irrelevant ones, and have your own ground truth to measure the index&#x27;s precision and recall.<p>This is usually a Series E problem, not a Series A problem.</div><br/></div></div></div></div><div id="37429697" class="c"><input type="checkbox" id="c-37429697" checked=""/><div class="controls bullet"><span class="by">freedmand</span><span>|</span><a href="#37428429">prev</a><span>|</span><a href="#37424754">next</a><span>|</span><label class="collapse" for="c-37429697">[-]</label><label class="expand" for="c-37429697">[6 more]</label></div><br/><div class="children"><div class="content">I don’t fully understand the fascination with retrieval augmented generation. The retrieval part is already really good and computationally inexpensive — why not just pass the semantic search results to the user in a pleasant interface and allow them to synthesize their own response? Reading a generated paragraph that obscures the full sourcing seems like a practice that’s been popularized to justify using the shiny new tech, but is the generated part what users actually want? (Not to mention there is no bulletproof way to prevent hallucinations, lies, and prompt injection even with retrieval context.)</div><br/><div id="37430152" class="c"><input type="checkbox" id="c-37430152" checked=""/><div class="controls bullet"><span class="by">sdenton4</span><span>|</span><a href="#37429697">parent</a><span>|</span><a href="#37430874">next</a><span>|</span><label class="collapse" for="c-37430152">[-]</label><label class="expand" for="c-37430152">[1 more]</label></div><br/><div class="children"><div class="content">On the modeling side, it&#x27;s compelling to separate the memory from the linguistic skills. Vector search is hella fast and can be very good. So you can off load the memorization part of the problem, and let the language model focus on the language. This should allow better performance with much smaller models.</div><br/></div></div><div id="37430874" class="c"><input type="checkbox" id="c-37430874" checked=""/><div class="controls bullet"><span class="by">nottheengineer</span><span>|</span><a href="#37429697">parent</a><span>|</span><a href="#37430152">prev</a><span>|</span><a href="#37430017">next</a><span>|</span><label class="collapse" for="c-37430874">[-]</label><label class="expand" for="c-37430874">[1 more]</label></div><br/><div class="children"><div class="content">I really like using LLMs to learn stuff because they can explain anything at the exact level I need. Hallucination is a big problem with that and RAG pretty much solves it. If I give chatGPT a good stackoverflow post and tell it to dumb it down for me, it does very well. RAG just automates that process with the added benefit of not letting the LLM decide which information to retrieve, which should greatly reduce the chance of accidentally biasing the model with your prompt.</div><br/></div></div><div id="37430017" class="c"><input type="checkbox" id="c-37430017" checked=""/><div class="controls bullet"><span class="by">matchagaucho</span><span>|</span><a href="#37429697">parent</a><span>|</span><a href="#37430874">prev</a><span>|</span><a href="#37430373">next</a><span>|</span><label class="collapse" for="c-37430017">[-]</label><label class="expand" for="c-37430017">[1 more]</label></div><br/><div class="children"><div class="content">In a strict &quot;one question &#x2F; one response&quot; search, raw semantic search results are a great solution. And consumes far fewer tokens.<p>In conversational AI, providing search results appended to a long-memory context produces &quot;human-like&quot; results.</div><br/></div></div><div id="37430373" class="c"><input type="checkbox" id="c-37430373" checked=""/><div class="controls bullet"><span class="by">zawaideh</span><span>|</span><a href="#37429697">parent</a><span>|</span><a href="#37430017">prev</a><span>|</span><a href="#37429957">next</a><span>|</span><label class="collapse" for="c-37430373">[-]</label><label class="expand" for="c-37430373">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes what I want is to ask Google&#x2F;Alexa&#x2F;Siri a question and get a summary response along with the source. I think that would be a good application of the above.<p>Less so IMO when I’m on my phone or in front of the computer.</div><br/></div></div></div></div><div id="37424754" class="c"><input type="checkbox" id="c-37424754" checked=""/><div class="controls bullet"><span class="by">jamesblonde</span><span>|</span><a href="#37429697">prev</a><span>|</span><a href="#37427043">next</a><span>|</span><label class="collapse" for="c-37424754">[-]</label><label class="expand" for="c-37424754">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not clear to me that only a vector DB should be used for RAG.
Vector DBs give you stochastic responses.<p>For customer chatbots, it seems that structured data - from an operational database or a feature store adds more value. If the user asks about an order they made or a product they have a question about, you use the user-id (when logged in) to retrieve all info about what the user bought recently - the LLM will figure out what the prompt is referring to.<p>Reference:<p><a href="https:&#x2F;&#x2F;www.hopsworks.ai&#x2F;dictionary&#x2F;retrieval-augmented-llm" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.hopsworks.ai&#x2F;dictionary&#x2F;retrieval-augmented-llm</a></div><br/><div id="37428648" class="c"><input type="checkbox" id="c-37428648" checked=""/><div class="controls bullet"><span class="by">jarulraj</span><span>|</span><a href="#37424754">parent</a><span>|</span><a href="#37427043">next</a><span>|</span><label class="collapse" for="c-37428648">[-]</label><label class="expand" for="c-37428648">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing that observation on customer chatbots.<p>1. Will that query look like this:<p><pre><code>  SELECT LLM(&quot;{user_question}&quot;, order_info)  
  FROM postgres_data.order_table  
  WHERE user_id = “101”;
</code></pre>
2. How will a feature store, like Hopsworks, help in this app?<p>Shameless self-plug: We are building EvaDB [1], a query engine for shipping fast AI-powered apps with SQL. Would love to exchange notes on such apps if you&#x27;re up for it!<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;georgia-tech-db&#x2F;evadb">https:&#x2F;&#x2F;github.com&#x2F;georgia-tech-db&#x2F;evadb</a></div><br/><div id="37429702" class="c"><input type="checkbox" id="c-37429702" checked=""/><div class="controls bullet"><span class="by">jamesblonde</span><span>|</span><a href="#37424754">root</a><span>|</span><a href="#37428648">parent</a><span>|</span><a href="#37427043">next</a><span>|</span><label class="collapse" for="c-37429702">[-]</label><label class="expand" for="c-37429702">[1 more]</label></div><br/><div class="children"><div class="content">Why would your projection be this - SELECT LLM(&quot;{user_question}&quot;, ?<p>You can train a small llm on your private data to map the user question to tables in your db.<p>Then Just select with a limit ( or time bounded).
The feature store is just another operational store that could have relevant data for the query.</div><br/></div></div></div></div></div></div><div id="37427043" class="c"><input type="checkbox" id="c-37427043" checked=""/><div class="controls bullet"><span class="by">Charon77</span><span>|</span><a href="#37424754">prev</a><span>|</span><a href="#37428896">next</a><span>|</span><label class="collapse" for="c-37427043">[-]</label><label class="expand" for="c-37427043">[2 more]</label></div><br/><div class="children"><div class="content">A lot of things mentioned are too handwaved and not explained well.<p>It&#x27;s not explained how vector DB is going to help while incumbents like chatgpt4 can already call functions and do API calls.<p>It doesn&#x27;t make AI less black box, it&#x27;s irrelevant and not explained..<p>There&#x27;s already existing ways to fine tune models without expensive hardwares such as using LoRA to inject small layers with customized training data, which trains in fractions of the time and resource needed to retrain the model</div><br/><div id="37428949" class="c"><input type="checkbox" id="c-37428949" checked=""/><div class="controls bullet"><span class="by">antupis</span><span>|</span><a href="#37427043">parent</a><span>|</span><a href="#37428896">next</a><span>|</span><label class="collapse" for="c-37428949">[-]</label><label class="expand" for="c-37428949">[1 more]</label></div><br/><div class="children"><div class="content">There is lots of things like which you don’t want leak eg customer specific data. For those cases vectors are great.</div><br/></div></div></div></div><div id="37428896" class="c"><input type="checkbox" id="c-37428896" checked=""/><div class="controls bullet"><span class="by">juxtaposicion</span><span>|</span><a href="#37427043">prev</a><span>|</span><a href="#37430698">next</a><span>|</span><label class="collapse" for="c-37428896">[-]</label><label class="expand" for="c-37428896">[1 more]</label></div><br/><div class="children"><div class="content">We use Lance extensively at my startup. This blog post (previously on HN) details nicely why: <a href="https:&#x2F;&#x2F;thedataquarry.com&#x2F;posts&#x2F;vector-db-4&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;thedataquarry.com&#x2F;posts&#x2F;vector-db-4&#x2F;</a> but essentially it’s because Lance is a “just a file” in the same way SQLite is a “just a file” which makes it embedded and serverless and straightforward to use locally or in a deployment.</div><br/></div></div><div id="37430698" class="c"><input type="checkbox" id="c-37430698" checked=""/><div class="controls bullet"><span class="by">Binarybuilder</span><span>|</span><a href="#37428896">prev</a><span>|</span><a href="#37430296">next</a><span>|</span><label class="collapse" for="c-37430698">[-]</label><label class="expand" for="c-37430698">[1 more]</label></div><br/><div class="children"><div class="content">I smell self promotion</div><br/></div></div><div id="37430296" class="c"><input type="checkbox" id="c-37430296" checked=""/><div class="controls bullet"><span class="by">dr_dshiv</span><span>|</span><a href="#37430698">prev</a><span>|</span><a href="#37428611">next</a><span>|</span><label class="collapse" for="c-37430296">[-]</label><label class="expand" for="c-37430296">[1 more]</label></div><br/><div class="children"><div class="content">404</div><br/></div></div><div id="37428611" class="c"><input type="checkbox" id="c-37428611" checked=""/><div class="controls bullet"><span class="by">eth0pal</span><span>|</span><a href="#37430296">prev</a><span>|</span><label class="collapse" for="c-37428611">[-]</label><label class="expand" for="c-37428611">[1 more]</label></div><br/><div class="children"><div class="content">Shameless self promotion</div><br/></div></div></div></div></div></div></div></body></html>