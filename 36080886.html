<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1685091693682" as="style"/><link rel="stylesheet" href="styles.css?v=1685091693682"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2305.12544">A PhD student&#x27;s perspective on research in NLP in the era of LLMs</a>Â <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>morgangiraud</span> | <span>8 comments</span></div><br/><div><div id="36081062" class="c"><input type="checkbox" id="c-36081062" checked=""/><div class="controls bullet"><span class="by">rhdunn</span><span>|</span><a href="#36081377">next</a><span>|</span><label class="collapse" for="c-36081062">[-]</label><label class="expand" for="c-36081062">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been interested in NLP for tagging stories based on topics and themes (detectives, werewolves, murder mystery, etc.), so need accurate disambiguation of parts of speech and ways of detecting uses of metaphore, similies, etc. to describe those. I also want to be able to assess how much of the text is about a given topic, so that if I&#x27;m interested in reading a detective story from e.g. the Project Gutenberg collection, I don&#x27;t want it to pick up a story where a detective is only mentioned in one paragraph.<p>I&#x27;ve looked at several existing NLP frameworks (Open NLP, Stanford NLP) and none of them are accurate enough -- they fail on things like adjectives and old english second person pronouns. This makes them practically unusable for proper sense diambiguation, lemma and part of speech based rules, etc.<p>The Open NLP tokenizer is also terrible at tokenizing title abbreviations (&quot;Dr&quot;, etc.) and things like the use of &quot;--&quot; to delimit text, which is frequently found various Project Gutenberg texts. You can train the Open NLP tokenizer, but it works on what it has seen, so you need to give it every variation of &quot;(Mr|Mrs|Miss|Ms|Rev|Dr|...). [A-Z]&quot; for it to tokenize those titles; the same for other tokens.</div><br/><div id="36081162" class="c"><input type="checkbox" id="c-36081162" checked=""/><div class="controls bullet"><span class="by">viksit</span><span>|</span><a href="#36081062">parent</a><span>|</span><a href="#36081377">next</a><span>|</span><label class="collapse" for="c-36081162">[-]</label><label class="expand" for="c-36081162">[4 more]</label></div><br/><div class="children"><div class="content">at this point the gpt api will do all of that for you! or you can use the embeddings api and build your own systems.</div><br/><div id="36081187" class="c"><input type="checkbox" id="c-36081187" checked=""/><div class="controls bullet"><span class="by">rhdunn</span><span>|</span><a href="#36081062">root</a><span>|</span><a href="#36081162">parent</a><span>|</span><a href="#36081377">next</a><span>|</span><label class="collapse" for="c-36081187">[-]</label><label class="expand" for="c-36081187">[3 more]</label></div><br/><div class="children"><div class="content">The problem with GPT and other LLMs is that they don&#x27;t tokenize words at a word or morpheme level, it&#x27;s just blocks of up to 4 characters, so you get tokens like `!&quot;` instead of two separate tokens. -- That makes it harder to write custom tools on top of, unlike e.g. the output&#x2F;model of things like the universaldependencies project.</div><br/><div id="36081392" class="c"><input type="checkbox" id="c-36081392" checked=""/><div class="controls bullet"><span class="by">DougBTX</span><span>|</span><a href="#36081062">root</a><span>|</span><a href="#36081187">parent</a><span>|</span><a href="#36081338">next</a><span>|</span><label class="collapse" for="c-36081392">[-]</label><label class="expand" for="c-36081392">[1 more]</label></div><br/><div class="children"><div class="content">Do you strictly need that level of tokenisation precision to meet your high-level goals?</div><br/></div></div><div id="36081338" class="c"><input type="checkbox" id="c-36081338" checked=""/><div class="controls bullet"><span class="by">viksit</span><span>|</span><a href="#36081062">root</a><span>|</span><a href="#36081187">parent</a><span>|</span><a href="#36081392">prev</a><span>|</span><a href="#36081377">next</a><span>|</span><label class="collapse" for="c-36081338">[-]</label><label class="expand" for="c-36081338">[1 more]</label></div><br/><div class="children"><div class="content">perhaps a spacy pipeline using gpt and huggingface?</div><br/></div></div></div></div></div></div></div></div><div id="36081377" class="c"><input type="checkbox" id="c-36081377" checked=""/><div class="controls bullet"><span class="by">totorovirus</span><span>|</span><a href="#36081062">prev</a><span>|</span><a href="#36081488">next</a><span>|</span><label class="collapse" for="c-36081377">[-]</label><label class="expand" for="c-36081377">[1 more]</label></div><br/><div class="children"><div class="content">well I see topics like NLP in ethics, healthcare, etc, which I think is a sign they don&#x27;t have much to do here.</div><br/></div></div></div></div></div></div></div></body></html>