<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1699952460992" as="style"/><link rel="stylesheet" href="styles.css?v=1699952460992"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://jxnl.github.io/instructor/blog/2023/11/05/chain-of-density/">Smarter summaries with finetuning GPT-3.5 and chain of density</a> <span class="domain">(<a href="https://jxnl.github.io">jxnl.github.io</a>)</span></div><div class="subtext"><span>ivanleomk</span> | <span>38 comments</span></div><br/><div><div id="38254065" class="c"><input type="checkbox" id="c-38254065" checked=""/><div class="controls bullet"><span class="by">tobbe2064</span><span>|</span><a href="#38256987">next</a><span>|</span><label class="collapse" for="c-38254065">[-]</label><label class="expand" for="c-38254065">[7 more]</label></div><br/><div class="children"><div class="content">Am i reading it right that the fine tune a model using 20 examples and 5 epochs? That seems really weird for me</div><br/><div id="38255304" class="c"><input type="checkbox" id="c-38255304" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#38254065">parent</a><span>|</span><a href="#38256943">next</a><span>|</span><label class="collapse" for="c-38255304">[-]</label><label class="expand" for="c-38255304">[3 more]</label></div><br/><div class="children"><div class="content">LLMs are few shots learners, that&#x27;s why many people put examples into prompt, this is the next step.</div><br/><div id="38256484" class="c"><input type="checkbox" id="c-38256484" checked=""/><div class="controls bullet"><span class="by">ed</span><span>|</span><a href="#38254065">root</a><span>|</span><a href="#38255304">parent</a><span>|</span><a href="#38256943">next</a><span>|</span><label class="collapse" for="c-38256484">[-]</label><label class="expand" for="c-38256484">[2 more]</label></div><br/><div class="children"><div class="content">I don’t believe few shot performance dictates how quickly you can fine-tune.<p>Most fine tunes will have much larger datasets (I am under the impression you want 10’s of thousands of examples for most runs).<p>So I’m similarly impressed 20 examples would make such a big difference.<p>But also note entity density decreases as example count increases. This is counterintuitive — maybe something else is going on here?</div><br/><div id="38257586" class="c"><input type="checkbox" id="c-38257586" checked=""/><div class="controls bullet"><span class="by">jxnlco</span><span>|</span><a href="#38254065">root</a><span>|</span><a href="#38256484">parent</a><span>|</span><a href="#38256943">next</a><span>|</span><label class="collapse" for="c-38257586">[-]</label><label class="expand" for="c-38257586">[1 more]</label></div><br/><div class="children"><div class="content">usually higher parameter models do better with less training data,
seperate from few shot learners, but related in other ways.</div><br/></div></div></div></div></div></div><div id="38254510" class="c"><input type="checkbox" id="c-38254510" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#38254065">parent</a><span>|</span><a href="#38256943">prev</a><span>|</span><a href="#38256987">next</a><span>|</span><label class="collapse" for="c-38254510">[-]</label><label class="expand" for="c-38254510">[2 more]</label></div><br/><div class="children"><div class="content">Can&#x27;t overfit when your learning rate is zero! <i>insert smart thinking meme</i></div><br/></div></div></div></div><div id="38256987" class="c"><input type="checkbox" id="c-38256987" checked=""/><div class="controls bullet"><span class="by">miket</span><span>|</span><a href="#38254065">prev</a><span>|</span><a href="#38253037">next</a><span>|</span><label class="collapse" for="c-38256987">[-]</label><label class="expand" for="c-38256987">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a good way to identify how entity-dense your text is: <a href="https:&#x2F;&#x2F;demo.nl.diffbot.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;demo.nl.diffbot.com&#x2F;</a></div><br/></div></div><div id="38253037" class="c"><input type="checkbox" id="c-38253037" checked=""/><div class="controls bullet"><span class="by">esafak</span><span>|</span><a href="#38256987">prev</a><span>|</span><a href="#38252436">next</a><span>|</span><label class="collapse" for="c-38253037">[-]</label><label class="expand" for="c-38253037">[3 more]</label></div><br/><div class="children"><div class="content">Those repeated calls sound like a good way to rack up a bill and incur a high latency.</div><br/><div id="38253077" class="c"><input type="checkbox" id="c-38253077" checked=""/><div class="controls bullet"><span class="by">jxnlco</span><span>|</span><a href="#38253037">parent</a><span>|</span><a href="#38253201">next</a><span>|</span><label class="collapse" for="c-38253077">[-]</label><label class="expand" for="c-38253077">[1 more]</label></div><br/><div class="children"><div class="content">right which is why finetuning on the last one is a great save but preserves quality</div><br/></div></div></div></div><div id="38252436" class="c"><input type="checkbox" id="c-38252436" checked=""/><div class="controls bullet"><span class="by">huac</span><span>|</span><a href="#38253037">prev</a><span>|</span><a href="#38252781">next</a><span>|</span><label class="collapse" for="c-38252436">[-]</label><label class="expand" for="c-38252436">[3 more]</label></div><br/><div class="children"><div class="content">nice work! generating good example data is the most important part of finetuning.<p>imo summarization is also a fairly simple task -- I wouldn&#x27;t be surprised if a fine-tuned open source model (eg llama 13 &#x2F; mistral 7) would get to similar performance.</div><br/><div id="38253660" class="c"><input type="checkbox" id="c-38253660" checked=""/><div class="controls bullet"><span class="by">robbomacrae</span><span>|</span><a href="#38252436">parent</a><span>|</span><a href="#38252744">next</a><span>|</span><label class="collapse" for="c-38253660">[-]</label><label class="expand" for="c-38253660">[1 more]</label></div><br/><div class="children"><div class="content">I find that bart large 410m [0] parameters does a fine job at summarizing. In Summer AI I alternate between using a copy of that bart large getting hyper-trained on feedback and Chat GPT 3.3 and honestly I don&#x27;t have a preference between the results.<p>However, thanks to this article I might revisit the summarization techniques used a try a fine tuned 3.5.<p>It would be great to see these techniques compared to Chat GPT 4 Turbo.<p>[0]: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;facebook&#x2F;bart-large-cnn" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;facebook&#x2F;bart-large-cnn</a></div><br/></div></div><div id="38252744" class="c"><input type="checkbox" id="c-38252744" checked=""/><div class="controls bullet"><span class="by">jxnlco</span><span>|</span><a href="#38252436">parent</a><span>|</span><a href="#38253660">prev</a><span>|</span><a href="#38252781">next</a><span>|</span><label class="collapse" for="c-38252744">[-]</label><label class="expand" for="c-38252744">[1 more]</label></div><br/><div class="children"><div class="content">for sure! the one thing i was surprised by was how little data gpt3.5 needed, could love for a company to try how the scaling laws work for those smaller models.</div><br/></div></div></div></div><div id="38252781" class="c"><input type="checkbox" id="c-38252781" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#38252436">prev</a><span>|</span><a href="#38253724">next</a><span>|</span><label class="collapse" for="c-38252781">[-]</label><label class="expand" for="c-38252781">[4 more]</label></div><br/><div class="children"><div class="content">One of the fun parts of AI is finding out that abstractive summarization is &quot;easy&quot;, but extractive summarization (which is what humans do far more often in practice) is still very hard. Partly because most datasets assume sentence level extractive summarization, which is often not how humans summarize documents.<p>There&#x27;s still tons of very low hanging fruit in the summarization work. I&#x27;m not aware of significant followup work to pointer networks besides pointer-generator networks, which these days are considered old news. Pointer based architectures are the ideal system for word level extractive summarizers, yet the very best extractive summarization systems today are usually nothing more than sentence selectors using some kinds of embeddings and cosine similarity.<p>Happy to see such success with abstractive summaries, but the kind that myself and most other humans are interested in is still far from solved.</div><br/><div id="38259138" class="c"><input type="checkbox" id="c-38259138" checked=""/><div class="controls bullet"><span class="by">jimmySixDOF</span><span>|</span><a href="#38252781">parent</a><span>|</span><a href="#38252937">next</a><span>|</span><label class="collapse" for="c-38259138">[-]</label><label class="expand" for="c-38259138">[1 more]</label></div><br/><div class="children"><div class="content">Yes and then within that there are variations on a large text with chapters without chapters, conversational&#x2F;meeting records from whisper, etc etc and they each need a different approach to the problem.</div><br/></div></div><div id="38252937" class="c"><input type="checkbox" id="c-38252937" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#38252781">parent</a><span>|</span><a href="#38259138">prev</a><span>|</span><a href="#38253724">next</a><span>|</span><label class="collapse" for="c-38252937">[-]</label><label class="expand" for="c-38252937">[2 more]</label></div><br/><div class="children"><div class="content">Could you point me to more reading on extractive summarisation? A lot of what I see feels out of date compared to what should be possible now with LLMs.</div><br/><div id="38256806" class="c"><input type="checkbox" id="c-38256806" checked=""/><div class="controls bullet"><span class="by">axpy906</span><span>|</span><a href="#38252781">root</a><span>|</span><a href="#38252937">parent</a><span>|</span><a href="#38253724">next</a><span>|</span><label class="collapse" for="c-38256806">[-]</label><label class="expand" for="c-38256806">[1 more]</label></div><br/><div class="children"><div class="content">You don’t need an LLM for extractive summarization.
It’s pulling out the most meaningful sentences from the article. Not sure what the parent meant.</div><br/></div></div></div></div></div></div><div id="38253724" class="c"><input type="checkbox" id="c-38253724" checked=""/><div class="controls bullet"><span class="by">sandGorgon</span><span>|</span><a href="#38252781">prev</a><span>|</span><a href="#38252728">next</a><span>|</span><label class="collapse" for="c-38253724">[-]</label><label class="expand" for="c-38253724">[8 more]</label></div><br/><div class="children"><div class="content">has anyone finetuned gpt 3.5 or llama, etc using their private data ? what is the best practice to generate training data.<p>one way i have heard is to send a chunk of data to gpt4 and ask for questions to be generated. unsure of other ways.
what has worked well ?</div><br/><div id="38253761" class="c"><input type="checkbox" id="c-38253761" checked=""/><div class="controls bullet"><span class="by">vjb2tq4dws</span><span>|</span><a href="#38253724">parent</a><span>|</span><a href="#38253848">next</a><span>|</span><label class="collapse" for="c-38253761">[-]</label><label class="expand" for="c-38253761">[6 more]</label></div><br/><div class="children"><div class="content">here is an example on how to generate synthetic data that you can adapt for your case <a href="https:&#x2F;&#x2F;dzlab.github.io&#x2F;2023&#x2F;09&#x2F;22&#x2F;palm-synthetic-data&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;dzlab.github.io&#x2F;2023&#x2F;09&#x2F;22&#x2F;palm-synthetic-data&#x2F;</a></div><br/><div id="38254568" class="c"><input type="checkbox" id="c-38254568" checked=""/><div class="controls bullet"><span class="by">just_boost_it</span><span>|</span><a href="#38253724">root</a><span>|</span><a href="#38253761">parent</a><span>|</span><a href="#38253848">next</a><span>|</span><label class="collapse" for="c-38254568">[-]</label><label class="expand" for="c-38254568">[5 more]</label></div><br/><div class="children"><div class="content">Is this proven to work? ML models are usually trained to learn a model of the environment by giving them environment data. I would have expected feeding it model outputs just trains it to learn a model of the model creating the data.<p>Without seeing some kind of demonstration otherwise, my feeling is that it would be like regressing stock price on inflation, then trying to generate more data using the regression model and random inflation numbers. All you&#x27;d learn is the model that you put in to generate the data.</div><br/><div id="38255137" class="c"><input type="checkbox" id="c-38255137" checked=""/><div class="controls bullet"><span class="by">valine</span><span>|</span><a href="#38253724">root</a><span>|</span><a href="#38254568">parent</a><span>|</span><a href="#38253848">next</a><span>|</span><label class="collapse" for="c-38255137">[-]</label><label class="expand" for="c-38255137">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;d think of it less like teaching the model something new, and more like enforcing a behavior the model can already output. Any decent raw model can output function names and parameters with prompt engineering. To do function calling, you need the model to output function names reliably for a wide variety of prompts. That&#x27;s where the fine-tuning comes in.</div><br/><div id="38255365" class="c"><input type="checkbox" id="c-38255365" checked=""/><div class="controls bullet"><span class="by">just_boost_it</span><span>|</span><a href="#38253724">root</a><span>|</span><a href="#38255137">parent</a><span>|</span><a href="#38253848">next</a><span>|</span><label class="collapse" for="c-38255365">[-]</label><label class="expand" for="c-38255365">[3 more]</label></div><br/><div class="children"><div class="content">I could very easily believe that if I saw proof, but it just feels a bit wrong to train a model on model outputs.<p>Even in the main article here, the model did better with fewer fine tuned examples. To us, the auto-generated examples might look different enough and might look good enough, but they were all generated algorithmically. Feeding more examples in might easily be leading it to focus on some artifact of the embeddings or generating model that we just don&#x27;t perceive.</div><br/><div id="38255644" class="c"><input type="checkbox" id="c-38255644" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38253724">root</a><span>|</span><a href="#38255365">parent</a><span>|</span><a href="#38257597">next</a><span>|</span><label class="collapse" for="c-38255644">[-]</label><label class="expand" for="c-38255644">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it just feels a bit wrong to train a model on model outputs<p>If you have a small student model and a large teacher it makes sense, the student is better off after this distillation.<p>If you have a way to filter out low quality synthetic examples then it would be useful to generate a bunch more and take the best.<p>If your LLM is an agent, then it can generate feedback signals from the environment. Even a human-AI chat is a form of environment for the model. Every human response can be evaluated as positive or negative reward.<p>More fundamentally, organic datasets are very unbalanced, LLMs need more complex reasoning chains than what is usually available. There are some exceptions - in scientific papers, manuals and code you get very complex reasoning chains. But not in general. This issue can be fixed with synthetic data.<p>And even in principle, if you have a model at level N and want to make a dataset at level N+1, then you need to boost your model. You can give it more tokens, more attempts or more tools.</div><br/></div></div><div id="38257597" class="c"><input type="checkbox" id="c-38257597" checked=""/><div class="controls bullet"><span class="by">jxnlco</span><span>|</span><a href="#38253724">root</a><span>|</span><a href="#38255365">parent</a><span>|</span><a href="#38255644">prev</a><span>|</span><a href="#38253848">next</a><span>|</span><label class="collapse" for="c-38257597">[-]</label><label class="expand" for="c-38257597">[1 more]</label></div><br/><div class="children"><div class="content">theres a whole literature on distilation and student teacher networks</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38253848" class="c"><input type="checkbox" id="c-38253848" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#38253724">parent</a><span>|</span><a href="#38253761">prev</a><span>|</span><a href="#38252728">next</a><span>|</span><label class="collapse" for="c-38253848">[-]</label><label class="expand" for="c-38253848">[1 more]</label></div><br/><div class="children"><div class="content">If its a small amount of data, it seems RAG pieplines are better.
is all I think I know.</div><br/></div></div></div></div><div id="38252728" class="c"><input type="checkbox" id="c-38252728" checked=""/><div class="controls bullet"><span class="by">themonk911</span><span>|</span><a href="#38253724">prev</a><span>|</span><a href="#38253666">next</a><span>|</span><label class="collapse" for="c-38252728">[-]</label><label class="expand" for="c-38252728">[5 more]</label></div><br/><div class="children"><div class="content">Gotta admit I spent some time thinking this was a new technique called &#x27;chain of <i>destiny</i>&#x27; and was reading through the article trying to work out what kind of fate-based prompt engineering was happening.</div><br/><div id="38253612" class="c"><input type="checkbox" id="c-38253612" checked=""/><div class="controls bullet"><span class="by">mpalmer</span><span>|</span><a href="#38252728">parent</a><span>|</span><a href="#38254860">next</a><span>|</span><label class="collapse" for="c-38253612">[-]</label><label class="expand" for="c-38253612">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=jGxuWWGo8AY&amp;t=9">https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=jGxuWWGo8AY&amp;t=9</a></div><br/></div></div><div id="38254860" class="c"><input type="checkbox" id="c-38254860" checked=""/><div class="controls bullet"><span class="by">rzzzt</span><span>|</span><a href="#38252728">parent</a><span>|</span><a href="#38253612">prev</a><span>|</span><a href="#38252853">next</a><span>|</span><label class="collapse" for="c-38254860">[-]</label><label class="expand" for="c-38254860">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a forgotten Wolfenstein sequel!</div><br/></div></div><div id="38252853" class="c"><input type="checkbox" id="c-38252853" checked=""/><div class="controls bullet"><span class="by">intelVISA</span><span>|</span><a href="#38252728">parent</a><span>|</span><a href="#38254860">prev</a><span>|</span><a href="#38252943">next</a><span>|</span><label class="collapse" for="c-38252853">[-]</label><label class="expand" for="c-38252853">[1 more]</label></div><br/><div class="children"><div class="content">Did the exact same thing :)</div><br/></div></div></div></div><div id="38253666" class="c"><input type="checkbox" id="c-38253666" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#38252728">prev</a><span>|</span><a href="#38252936">next</a><span>|</span><label class="collapse" for="c-38253666">[-]</label><label class="expand" for="c-38253666">[5 more]</label></div><br/><div class="children"><div class="content">Minor correction: the article describes Chain of Density as &quot;First introduced by Salesforce&#x27;s AI Research wing&quot; -- however the 1st author (who is a PhD student) and senior author are both at Columbia; only one of the 5 authors is at Salesforce.</div><br/><div id="38253747" class="c"><input type="checkbox" id="c-38253747" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#38253666">parent</a><span>|</span><a href="#38254700">next</a><span>|</span><label class="collapse" for="c-38253747">[-]</label><label class="expand" for="c-38253747">[2 more]</label></div><br/><div class="children"><div class="content">prepared to see all these companies &quot;invent&quot; these techniques. fwiw people believe OpenAI &quot;invented&quot; chatgpt, whereas the inventors of the transformer model individually worked at competing companies during the research (Google Brain) and presently founded competing companies now.</div><br/><div id="38253834" class="c"><input type="checkbox" id="c-38253834" checked=""/><div class="controls bullet"><span class="by">vinni2</span><span>|</span><a href="#38253666">root</a><span>|</span><a href="#38253747">parent</a><span>|</span><a href="#38254700">next</a><span>|</span><label class="collapse" for="c-38253834">[-]</label><label class="expand" for="c-38253834">[1 more]</label></div><br/><div class="children"><div class="content">The novelty of chatgpt was instruction tuning of transformers using reinforcement learning with human feedback and finding right dataset as well as annotations for it. before this transformers were good for some tasks but not so good for generating text. Even though OpenAI didn’t invent transformers they did invent the technique needed to make chatgpt possible.</div><br/></div></div></div></div><div id="38254700" class="c"><input type="checkbox" id="c-38254700" checked=""/><div class="controls bullet"><span class="by">jxnlco</span><span>|</span><a href="#38253666">parent</a><span>|</span><a href="#38253747">prev</a><span>|</span><a href="#38256364">next</a><span>|</span><label class="collapse" for="c-38254700">[-]</label><label class="expand" for="c-38254700">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll fix this now!</div><br/></div></div></div></div></div></div></div></div></div></body></html>