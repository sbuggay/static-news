<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1695200461593" as="style"/><link rel="stylesheet" href="styles.css?v=1695200461593"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://vishnumenon.com/lightrail/2023/09/17/AI-Interfaces.html">What will LLM-powered software look like in the medium-term future?</a> <span class="domain">(<a href="https://vishnumenon.com">vishnumenon.com</a>)</span></div><div class="subtext"><span>vishnumenon</span> | <span>15 comments</span></div><br/><div><div id="37581946" class="c"><input type="checkbox" id="c-37581946" checked=""/><div class="controls bullet"><span class="by">liampulles</span><span>|</span><a href="#37581444">next</a><span>|</span><label class="collapse" for="c-37581946">[-]</label><label class="expand" for="c-37581946">[1 more]</label></div><br/><div class="children"><div class="content">My prediction is that LLMs are going to be used almost exclusively for views over commands. They are simply too unpredictable.<p>I&#x27;m more optimistic than the author about how useful LLMs may be for chat based interfaces - I don&#x27;t think it is appreciated in tech how many people are (still) computer illiterate in the world, and natural language can be a big improvement in usability for the kinds of usecases these users need.</div><br/></div></div><div id="37581444" class="c"><input type="checkbox" id="c-37581444" checked=""/><div class="controls bullet"><span class="by">jaynetics</span><span>|</span><a href="#37581946">prev</a><span>|</span><a href="#37581482">next</a><span>|</span><label class="collapse" for="c-37581444">[-]</label><label class="expand" for="c-37581444">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Even if an LLM could provide me with a recipe that perfectly suits what I’m looking for, I wouldn’t want to give up the experience of using a recipe search engine and browsing through a large collection of recipes. Even if an LLM could provide me with restaurant recommendations based on my preferences, I’d still seek out a map-based UX for exploring the variety present in my vicinity. The desire to replace all UX with LLMs seems like a desire to replace all serendipity with efficiency, and I think (or hope) that such a transition is much more appealing in theory than it would be in practice.<p>I guess the question is: how much of our web or software use is leisurely browsing (reading news or HN would be other likely candidates for this category) and how much is more task-like, e.g. send a message to some friends, add a note to a specific list, order some groceries?<p>We might also want to consider how much of a role such private use of software plays in shaping UX trends. If business software (sheets, Photoshop, CAD etc.) can be sped up with chat input, it will be, and people will be expected to use the quickest UI.<p>This is not to say that browsing will disappear, but I can totally see it being relegated to a second class UI in the long run, even in applications where it&#x27;s currently the obvious choice, just because our default UX expectations will be different.</div><br/></div></div><div id="37581482" class="c"><input type="checkbox" id="c-37581482" checked=""/><div class="controls bullet"><span class="by">ilaksh</span><span>|</span><a href="#37581444">prev</a><span>|</span><a href="#37581786">next</a><span>|</span><label class="collapse" for="c-37581482">[-]</label><label class="expand" for="c-37581482">[4 more]</label></div><br/><div class="children"><div class="content">All of this makes sense.<p>I would like to add my own prediction for 2027. I believe in the next 4 years, much more comfortable and capable mixed reality glasses and goggles may be somewhat common. Also AI generation and streaming of realistic avatars will have advanced. Quite possibly this will use low-latency Wifi to stream from a PC.<p>So if you want, you will be able to have a fairly realistic representation of the AI as a synthetic person in the room with you when you put the MR device on. It will have eye contact and seem quite similar to a real person (if you want). You will be able to just talk to it.<p>Another thing that might become popular could be larger 3d monitors. The type that have some stereoscopic effect tuned to your exact position. So your AI helper might just live in a virtual window or doorway or something like that.<p>You can actually already build something a bit like this, at least in 2d, without really inventing anything complex. You would use things like a HeyGen or D-ID API and maybe Eleven Labs or something. You won&#x27;t get eye contact or a realistic 3d avatar that seems to be sitting on your couch, and there will be pauses waiting for it to respond. But theoretically, fast-forwarding several years, those things are not at all insurmountable.</div><br/><div id="37581645" class="c"><input type="checkbox" id="c-37581645" checked=""/><div class="controls bullet"><span class="by">badcppdev</span><span>|</span><a href="#37581482">parent</a><span>|</span><a href="#37581760">next</a><span>|</span><label class="collapse" for="c-37581645">[-]</label><label class="expand" for="c-37581645">[2 more]</label></div><br/><div class="children"><div class="content">When we can interact by talking to a 2D cartoon in a Zoom call then I guess we&#x27;ll be X% towards your 2027 vision.</div><br/><div id="37581867" class="c"><input type="checkbox" id="c-37581867" checked=""/><div class="controls bullet"><span class="by">pomtato</span><span>|</span><a href="#37581482">root</a><span>|</span><a href="#37581645">parent</a><span>|</span><a href="#37581760">next</a><span>|</span><label class="collapse" for="c-37581867">[-]</label><label class="expand" for="c-37581867">[1 more]</label></div><br/><div class="children"><div class="content">You can already do that with praktika.ai , they&#x27;re in ed-tech and got ai avatars of sorts that you can &quot;video-call&quot; to :D</div><br/></div></div></div></div><div id="37581760" class="c"><input type="checkbox" id="c-37581760" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#37581482">parent</a><span>|</span><a href="#37581645">prev</a><span>|</span><a href="#37581786">next</a><span>|</span><label class="collapse" for="c-37581760">[-]</label><label class="expand" for="c-37581760">[1 more]</label></div><br/><div class="children"><div class="content">2037 maybe, but four years isn&#x27;t very long.</div><br/></div></div></div></div><div id="37581786" class="c"><input type="checkbox" id="c-37581786" checked=""/><div class="controls bullet"><span class="by">sgt101</span><span>|</span><a href="#37581482">prev</a><span>|</span><a href="#37581393">next</a><span>|</span><label class="collapse" for="c-37581786">[-]</label><label class="expand" for="c-37581786">[1 more]</label></div><br/><div class="children"><div class="content">9&#x2F;10 requests for a simple sql query get a working query.<p>This isn&#x27;t enough to enable a useful interface.<p>It takes a lot of scaffolding to get an llm powered interface to actually work.</div><br/></div></div><div id="37581393" class="c"><input type="checkbox" id="c-37581393" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#37581786">prev</a><span>|</span><a href="#37581939">next</a><span>|</span><label class="collapse" for="c-37581393">[-]</label><label class="expand" for="c-37581393">[1 more]</label></div><br/><div class="children"><div class="content">A lot of this seems like a nerd’s fantasy. I share these fantasies &#x2F; desires, but I don’t think its a sober, realistic take on what’s most likely.<p>&gt; Even if an LLM could provide me with a recipe that perfectly suits what I’m looking for, I wouldn’t want to give up the experience of using a recipe search engine and browsing through a large collection of recipes.<p>Me too, but allrecipes.com has already switched from “search for what you want” to “we’ll tell you what you want”. This is a UX pattern that I hate but has proven a winner across many apps lately - e.g. TikTok. Streaming music still allows you to  build playlists of specific songs, but auto-built radio stations are filled with a suspicious amount of whatever the major labels are pushing this quarter. Netflix&#x2F;etc has shockingly fuzzy search which largely pushes whatever they want you to watch rather than what you’re searching for. YouTube is mostly also push rather than pull today.<p>I expect everything to continue moving that direction, against the wishes of the power users. The majority of users seem to go for the simpler UX, even if they sometimes complain about quality.<p>&gt; In an ideal world, I’d like to have the underlying model be a swappable implementation detail. Llama 2 and similar developments make me optimistic.<p>This is a pipe dream. LLMs may be hot-swappable by developers but for 99% of apps + OSes this wont be a user-configurable thing.</div><br/></div></div><div id="37581939" class="c"><input type="checkbox" id="c-37581939" checked=""/><div class="controls bullet"><span class="by">geuis</span><span>|</span><a href="#37581393">prev</a><span>|</span><a href="#37581991">next</a><span>|</span><label class="collapse" for="c-37581939">[-]</label><label class="expand" for="c-37581939">[1 more]</label></div><br/><div class="children"><div class="content">Ok. I appreciate they didn&#x27;t use Medium as a blog post. There&#x27;s a lot of good engineering knowledge currently locked behind the Medium &quot;sign in&quot; interface. It&#x27;s dumb and stupid.<p>But just to voice an opinion, please kill the lengthy paragraph levels of fluff in blog posts. I don&#x27;t want to say my opinion is influenced by shitty blog recipes and research papers, but it is. So stop it.<p>Just say what you need to say in bullet points at the beginning and fill in the details further on.</div><br/></div></div><div id="37581991" class="c"><input type="checkbox" id="c-37581991" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#37581939">prev</a><span>|</span><a href="#37581422">next</a><span>|</span><label class="collapse" for="c-37581991">[-]</label><label class="expand" for="c-37581991">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I don’t believe that natural language is an adequate medium for conveying instructions with the precision required for many applications. Moreover, the “inefficiency” involved in carrying out many digital tasks “manually” is a core driver of the joy that comes with using computers (for me and, I assume, for at least some subset of others). Even if an LLM could provide me with a recipe that perfectly suits what I’m looking for, I wouldn’t want to give up the experience of using a recipe search engine and browsing through a large collection of recipes.<p>But searching for places to eat and recipes to make is very much <i>not</i> a precise search.<p>IMO the reason <i>chat</i> and not <i>input text and get an answer</i> is so powerful is that it allows messy search with iterative refinement - just like talking to an expert. Just &quot;chat input, result given&quot; doesn&#x27;t have that.<p>I want to tell a recipe search I&#x27;m after a healthy light thing as it&#x27;s hot. I want to get back options and then say &quot;I don&#x27;t really like cucumber though&quot; and have it get rid of cucumber heavy recipes but leave in some salads and say &quot;look this recipe has cucumber in but it&#x27;ll be fine without it&quot;. Or &quot;you asked for a chicken recipe but here&#x27;s one with pork that should sub in just fine&quot;.<p>For restaurants I want to get back some options and tell it &quot;that&#x27;s too expensive, this is a quick thing&quot; and get back more hole-in-the-wall things. Tell it &quot;Hmm, something spicy sounds good but I&#x27;ve been to those Indian restaurants before, I&#x27;m after something new&quot; and get a recommendation for the Ethiopian place in town.<p>&gt; The current state of having a chat-ish UX that’s specific to each tool or website (e.g. a Documentation Chat on a library documentation page, a VSCode extension, a Google Bard integration, a really-badly-implemented chatbot in my banking app, etc.) doesn’t make any single one of those experiences more enjoyable, effective, or entertaining;<p>Coding chat in my editor absolutely makes coding more effective. I want heavy integration around how it edits text, not a general chat widget.<p>&gt; The idealized role of persistence in LLM UX is also fairly obvious: it’s easy to imagine an LLM-powered experience that remembers and “understands” all my previous interactions with it, and uses that information to better help me with whatever my current task is<p>I sort of agree, but I absolutely detest hidden state about me. I <i>should not</i> alter my behaviour just because I&#x27;m worried about how that&#x27;ll impact things. You see this regularly, I may avoid some weird youtube video (e.g. to see a weird flat earth take) because I don&#x27;t really want the hassle of having loads of weird conspiracy stuff promoted or having to manually remove it from some list.<p>Having said that, recipe search that remembers I hate cucumbers is great.<p>I wonder if manually curated context will in general be better? Or maybe just for me.<p>&gt; I’m interacting with UXes that can remember and utilize my previously expressed preferences, desires, goals, and information, using that underlying memory across different use cases seems like low-hanging fruit for drastically reducing friction.<p>The tricky part here is I switch contexts and don&#x27;t want them bleeding into each other. My preferences for interaction around my kids and while at work are very different.<p>&gt; A small-scale and developer-centric example: I use GitHub Copilot in VSCode, and I was recently implementing a library with documentation that featured LLM-powered Q&amp;A, and it felt bizarre to have two LLM-mediated experiences open that each had exactly half the info needed to solve my problem.<p>I think here a split between <i>data sources</i> and <i>frontends</i> is key. This interaction is awkward, and should be combined (copilot should be able to reach out to that documentation).<p>&gt; locally runnable and open models are no match for GPT-4 (etc.),<p>It&#x27;s going to be more efficient to move compute to central places, the less they&#x27;re used per person the more efficient it will be to have one central location process everyones things. A short taxi ride per week is cheaper than owning a car. However as uses grow (e.g. proactive llms), will this shift the equation towards locally runnable ones? A few queries a day and you&#x27;re obviously better off not buying a h100. Constantly running things all day and if prices fall maybe that&#x27;ll change.</div><br/></div></div><div id="37581422" class="c"><input type="checkbox" id="c-37581422" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#37581991">prev</a><span>|</span><a href="#37581800">next</a><span>|</span><label class="collapse" for="c-37581422">[-]</label><label class="expand" for="c-37581422">[1 more]</label></div><br/><div class="children"><div class="content">Some nice ideas here. I think some of these could see realisation, depending very much on how accessible those LLMs become.<p>At the moment I&#x27;m sure there are only a couple of user interfaces that people know and will resist l reuse. After all they&#x27;ll want to take very little risk and use what they&#x27;ve seen works in other places. The full screen ChatGPT style page, or those annoying chatbot pop-ups that sit in the bottom right hand corner of sites I don&#x27;t care about. Something to keep an eye on and see what emerges.</div><br/></div></div><div id="37581800" class="c"><input type="checkbox" id="c-37581800" checked=""/><div class="controls bullet"><span class="by">avindroth</span><span>|</span><a href="#37581422">prev</a><span>|</span><a href="#37581329">next</a><span>|</span><label class="collapse" for="c-37581800">[-]</label><label class="expand" for="c-37581800">[1 more]</label></div><br/><div class="children"><div class="content">This space is surprisingly under-explored. Any idea in this space is basically new.</div><br/></div></div><div id="37581329" class="c"><input type="checkbox" id="c-37581329" checked=""/><div class="controls bullet"><span class="by">isoprophlex</span><span>|</span><a href="#37581800">prev</a><span>|</span><a href="#37581425">next</a><span>|</span><label class="collapse" for="c-37581329">[-]</label><label class="expand" for="c-37581329">[1 more]</label></div><br/><div class="children"><div class="content">Loving the ideas here. I&#x27;m especially fond of the machine-to-machine idea, the concept of a locally running LLM that knows about you, and a remote LLM in an app or whatever, interacting with eachother to create a highly individualized UX.<p>Seems like a perfect blend of keeping the core personality of the LLM trained on your data local, while still allowing permissioned access.</div><br/></div></div><div id="37581425" class="c"><input type="checkbox" id="c-37581425" checked=""/><div class="controls bullet"><span class="by">Traubenfuchs</span><span>|</span><a href="#37581329">prev</a><span>|</span><label class="collapse" for="c-37581425">[-]</label><label class="expand" for="c-37581425">[1 more]</label></div><br/><div class="children"><div class="content">I feel like us not being in that future right now means we won‘t get there so fast.<p>What‘s missing to get all of this now? What recolutionary research, product development that hasn‘t happened yet will happen in the coming year?<p>To me it looks like LLM tech is stagnating, after the hype peak we are close to the trough of disillusionment.</div><br/></div></div></div></div></div></div></div></body></html>