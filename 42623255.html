<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1736586060714" as="style"/><link rel="stylesheet" href="styles.css?v=1736586060714"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://harimus.github.io//2024/05/31/motortask.html">Common misconceptions about the complexity in robotics vs. AI (2024)</a> <span class="domain">(<a href="https://harimus.github.io">harimus.github.io</a>)</span></div><div class="subtext"><span>wallflower</span> | <span>34 comments</span></div><br/><div><div id="42663308" class="c"><input type="checkbox" id="c-42663308" checked=""/><div class="controls bullet"><span class="by">no_op</span><span>|</span><a href="#42662951">next</a><span>|</span><label class="collapse" for="c-42663308">[-]</label><label class="expand" for="c-42663308">[3 more]</label></div><br/><div class="children"><div class="content">I think Moravec&#x27;s Paradox is often misapplied when considering LLMs vs. robotics. It&#x27;s true that formal reasoning over unambiguous problem representations is easy and computationally cheap. Lisp machines were already doing this sort of thing in the &#x27;70s. But the kind of commonsense reasoning over ambiguous natural language that LLMs can do is <i>not</i> easy or computationally cheap. Many early AI researchers thought it would be — that it would just require a bit of elaboration on the formal reasoning stuff — but this was totally wrong.<p>So, it doesn&#x27;t make sense to say that what LLMs do is Moravec-easy, and therefore can&#x27;t be extrapolated to predict near-term progress on Moravec-hard problems like robotics. What LLMs do is, in fact, Moravec-hard. And we should expect that if we&#x27;ve got enough compute to make major progress on one Moravec-hard problem, there&#x27;s a good chance we&#x27;re closing in on having enough to make major progress on others.</div><br/><div id="42664433" class="c"><input type="checkbox" id="c-42664433" checked=""/><div class="controls bullet"><span class="by">lsy</span><span>|</span><a href="#42663308">parent</a><span>|</span><a href="#42664277">next</a><span>|</span><label class="collapse" for="c-42664433">[-]</label><label class="expand" for="c-42664433">[1 more]</label></div><br/><div class="children"><div class="content">Leaving aside the lack of consensus around whether LLMs actually succeed in commonsense reasoning, this seems a little bit like saying “Actually, the first 90% of our project took an enormous amount of time, so it must be ‘Pareto-hard’. And thus the last 10% is well within reach!” That is, that Pareto and Moravec were in fact just wrong, and thing A and thing B are equivalently hard.<p>Keeping the paradox would more logically bring you to the conclusion that LLMs’ massive computational needs and limited capacities imply a commensurately greater, mind-bogglingly large computational requirement for physical aptitude.</div><br/></div></div><div id="42664277" class="c"><input type="checkbox" id="c-42664277" checked=""/><div class="controls bullet"><span class="by">bjornsing</span><span>|</span><a href="#42663308">parent</a><span>|</span><a href="#42664433">prev</a><span>|</span><a href="#42662951">next</a><span>|</span><label class="collapse" for="c-42664277">[-]</label><label class="expand" for="c-42664277">[1 more]</label></div><br/><div class="children"><div class="content">Good points. Came here to say pretty much the same.<p>Moravec&#x27;s Paradox is certainly interesting and correct if you limit its scope (as you say). But it feels intuitively wrong to me to make any claims about the relative computational demands of sensi-motor control and abstract thinking before we’ve really solved either problem.<p>Looking e.g. at the recent progress in solving ARC-AGI my impression is that abstract thought could have incredible computational demands. IIRC they had to throw approximately $10k of compute at o3 before it reached human performance. Now compare how cognitively challenging ARC-AGI is to e.g. designing or reorganizing a Tesla gigafactory.<p>With that said I do agree that our culture tends to value simple office work over skillful practical work. Hopefully the progress in AI&#x2F;ML will soon correct that wrong.</div><br/></div></div></div></div><div id="42662951" class="c"><input type="checkbox" id="c-42662951" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#42663308">prev</a><span>|</span><a href="#42663824">next</a><span>|</span><label class="collapse" for="c-42662951">[-]</label><label class="expand" for="c-42662951">[13 more]</label></div><br/><div class="children"><div class="content">&gt; Moravec’s paradox is the observation by artificial intelligence and robotics researchers that, contrary to traditional assumptions, reasoning requires very little computation, but sensorimotor and perception skills require enormous computational resources. The principle was articulated by Hans Moravec, Rodney Brooks, Marvin Minsky, and others in the 1980s.<p>I have a name for it now!<p>I&#x27;ve said over and over that there are only two really hard problems in robotics: Perception and funding.  A perfectly perceived system and world can be trivially planned for and (at least proprio-)controlled. Imagine having a perfect intuition about other actors such that you know their paths (in self driving cars), or your map is a perfect voxel + trajectory + classification. How divine!<p>It&#x27;s limited information and difficulties in reducing signal to concise representation that always get ya. This is why the perfect lab demos always fail - there&#x27;s a corner case not in your training data, or the sensor stuttered or became misaligned, or etc etc.</div><br/><div id="42663482" class="c"><input type="checkbox" id="c-42663482" checked=""/><div class="controls bullet"><span class="by">bobsomers</span><span>|</span><a href="#42662951">parent</a><span>|</span><a href="#42662986">next</a><span>|</span><label class="collapse" for="c-42663482">[-]</label><label class="expand" for="c-42663482">[3 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;ve said over and over that there are only two really hard problems in robotics: Perception and funding. A perfectly perceived system and world can be trivially planned for and (at least proprio-)controlled.<p>Funding for sure. :)<p>But as for perception, the inverse is also true. If I have an perfect planning&#x2F;prediction system, I can throw the grungiest, worst perception data into it and it will still plan successfully despite tons of uncertainty.<p>And therein lies the real challenge of robotics: It&#x27;s fundamentally a systems engineering problem. You will never have perfect perception or a perfect planner. So, can you make a perception system that is <i>good enough</i> that, when coupled with your planning system which is <i>good enough</i>, you are able to solve enough problems with enough 9s to make it successful.<p>The most commercially successful robots I&#x27;ve seen have had some of the smartest systems engineering behind them, such that entire classes of failures were eliminated by being smarter about what you <i>actually need to do to solve the problem</i> and aggressively avoid solving subproblems that aren&#x27;t absolutely necessary. Only then do you really have a hope of getting good enough at that focused domain to ship something before the money runs out. :)</div><br/><div id="42663556" class="c"><input type="checkbox" id="c-42663556" checked=""/><div class="controls bullet"><span class="by">portaouflop</span><span>|</span><a href="#42662951">root</a><span>|</span><a href="#42663482">parent</a><span>|</span><a href="#42662986">next</a><span>|</span><label class="collapse" for="c-42663556">[-]</label><label class="expand" for="c-42663556">[2 more]</label></div><br/><div class="children"><div class="content">&gt; being smarter about what you actually need to do to solve the problem and aggressively avoid solving subproblems that aren&#x27;t absolutely necessary<p>I feel like this is true for every engineering discipline or maybe even every field that needs to operate in the real world</div><br/><div id="42664214" class="c"><input type="checkbox" id="c-42664214" checked=""/><div class="controls bullet"><span class="by">vrighter</span><span>|</span><a href="#42662951">root</a><span>|</span><a href="#42663556">parent</a><span>|</span><a href="#42662986">next</a><span>|</span><label class="collapse" for="c-42664214">[-]</label><label class="expand" for="c-42664214">[1 more]</label></div><br/><div class="children"><div class="content">except software, of course. Nowadays it seems that software is all about creating problems to create solutions for.</div><br/></div></div></div></div></div></div><div id="42662986" class="c"><input type="checkbox" id="c-42662986" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#42662951">parent</a><span>|</span><a href="#42663482">prev</a><span>|</span><a href="#42663262">next</a><span>|</span><label class="collapse" for="c-42662986">[-]</label><label class="expand" for="c-42662986">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Moravec hypothesized around his paradox, that the reason for the paradox [that things we perceive as easy b&#x2F;c we dont think about them are actually hard] could be due to the sensor &amp; motor portion of the human brain having had billions of years of experience and natural selection to fine-tune it, while abstract thoughts have had maybe 100 thousand years or less<p>Another gem!</div><br/><div id="42664070" class="c"><input type="checkbox" id="c-42664070" checked=""/><div class="controls bullet"><span class="by">topherclay</span><span>|</span><a href="#42662951">root</a><span>|</span><a href="#42662986">parent</a><span>|</span><a href="#42663110">next</a><span>|</span><label class="collapse" for="c-42664070">[-]</label><label class="expand" for="c-42664070">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ...the sensor &amp; motor portion of the human brain having had billions of years of experience.<p>It doesn&#x27;t really change the significance of the quote, but I can&#x27;t help but point out that we didn&#x27;t even have nerve cells more than 0.6 billion of years ago.</div><br/></div></div><div id="42663110" class="c"><input type="checkbox" id="c-42663110" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#42662951">root</a><span>|</span><a href="#42662986">parent</a><span>|</span><a href="#42664070">prev</a><span>|</span><a href="#42663262">next</a><span>|</span><label class="collapse" for="c-42663110">[-]</label><label class="expand" for="c-42663110">[3 more]</label></div><br/><div class="children"><div class="content">Or it could be a parallel vs serial compute thing.<p>Perception tasks involve relatively simple operations across very large amounts of data, which is very easy if you have a lot of parallel processors.<p>Abstract thought is mostly a serial task, applying very complex operations to a small amount of data. Many abstract tasks like evaluating logical expressions cannot be done in parallel - they are in the complexity class P-complete.<p>Your brain is mostly a parallel processor (80 billion neurons operating asynchronously), so logical reasoning is hard and perception is easy. Your CPU is mostly a serial processor, so logical reasoning is easy and perception is hard.</div><br/><div id="42663433" class="c"><input type="checkbox" id="c-42663433" checked=""/><div class="controls bullet"><span class="by">cratermoon</span><span>|</span><a href="#42662951">root</a><span>|</span><a href="#42663110">parent</a><span>|</span><a href="#42663262">next</a><span>|</span><label class="collapse" for="c-42663433">[-]</label><label class="expand" for="c-42663433">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Perception tasks involve relatively simple operations across very large amounts of data, which is very easy if you have a lot of parallel processors.<p>Yes, relatively simple.
Wait, isn&#x27;t that exactly what the article explained was completely wrong-headed?</div><br/><div id="42664342" class="c"><input type="checkbox" id="c-42664342" checked=""/><div class="controls bullet"><span class="by">burnished</span><span>|</span><a href="#42662951">root</a><span>|</span><a href="#42663433">parent</a><span>|</span><a href="#42663262">next</a><span>|</span><label class="collapse" for="c-42664342">[-]</label><label class="expand" for="c-42664342">[1 more]</label></div><br/><div class="children"><div class="content">No. The article is talking about things we think of as being easy because they are easy for a human to perform but that are actually very difficult to formalize&#x2F;reproduce artificially.<p>The person you are responding to is instead comparing differences in biological systems and mechanical systems.</div><br/></div></div></div></div></div></div></div></div><div id="42663262" class="c"><input type="checkbox" id="c-42663262" checked=""/><div class="controls bullet"><span class="by">lang4d</span><span>|</span><a href="#42662951">parent</a><span>|</span><a href="#42662986">prev</a><span>|</span><a href="#42664112">next</a><span>|</span><label class="collapse" for="c-42663262">[-]</label><label class="expand" for="c-42663262">[1 more]</label></div><br/><div class="children"><div class="content">Maybe just semantics, but I think I would call that prediction. Even if you have perfect perception (measuring the current state of the world perfectly), it&#x27;s nontrivial to predict the future paths of other actors. The prediction problem requires intuition about what the other actors are thinking, how their plans influence each other, and how your plan influences them.</div><br/></div></div><div id="42664112" class="c"><input type="checkbox" id="c-42664112" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#42662951">parent</a><span>|</span><a href="#42663262">prev</a><span>|</span><a href="#42663952">next</a><span>|</span><label class="collapse" for="c-42664112">[-]</label><label class="expand" for="c-42664112">[2 more]</label></div><br/><div class="children"><div class="content">Yeah the fun way Moravec&#x27;s paradox was explained to me [1] is that you can now easily get a computer to solve simultaneous differential equations governing all the axes of motion of a robot arm but getting it to pick one screw out of a box of screws is an unsolved research problem.<p>[1] by a disillusioned computer vision phd that left the field in the 1990s.</div><br/><div id="42664262" class="c"><input type="checkbox" id="c-42664262" checked=""/><div class="controls bullet"><span class="by">wrp</span><span>|</span><a href="#42662951">root</a><span>|</span><a href="#42664112">parent</a><span>|</span><a href="#42663952">next</a><span>|</span><label class="collapse" for="c-42664262">[-]</label><label class="expand" for="c-42664262">[1 more]</label></div><br/><div class="children"><div class="content">Selective attention was one of the main factors in Hubert Dreyfus&#x27; explanation of &quot;what computers can&#x27;t do.&quot; He had a special term for it, which I can&#x27;t remember off-hand.</div><br/></div></div></div></div><div id="42663952" class="c"><input type="checkbox" id="c-42663952" checked=""/><div class="controls bullet"><span class="by">exe34</span><span>|</span><a href="#42662951">parent</a><span>|</span><a href="#42664112">prev</a><span>|</span><a href="#42663824">next</a><span>|</span><label class="collapse" for="c-42663952">[-]</label><label class="expand" for="c-42663952">[1 more]</label></div><br/><div class="children"><div class="content">&quot;the sensor stuttered or became misaligned, or etc etc.&quot;<p>if your eyes suddenly crossed, you&#x27;d probably fall over too!</div><br/></div></div></div></div><div id="42663824" class="c"><input type="checkbox" id="c-42663824" checked=""/><div class="controls bullet"><span class="by">jonas21</span><span>|</span><a href="#42662951">prev</a><span>|</span><a href="#42664312">next</a><span>|</span><label class="collapse" for="c-42663824">[-]</label><label class="expand" for="c-42663824">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s worth noting that modern multimodal models are not confused by the cat image. For example, Claude 3.5 Sonnet says:<p>&gt; <i>This image shows two cats cuddling or sleeping together on what appears to be a blue fabric surface, possibly a blanket or bedspread. One cat appears to be black while the other is white with pink ears. They&#x27;re lying close together, suggesting they&#x27;re comfortable with each other. The composition is quite sweet and peaceful, capturing a tender moment between these feline companions.</i></div><br/><div id="42664387" class="c"><input type="checkbox" id="c-42664387" checked=""/><div class="controls bullet"><span class="by">throw310822</span><span>|</span><a href="#42663824">parent</a><span>|</span><a href="#42664312">next</a><span>|</span><label class="collapse" for="c-42664387">[-]</label><label class="expand" for="c-42664387">[2 more]</label></div><br/><div class="children"><div class="content">Also Claude, when given the entire picture:<p>&quot;This is a humorous post showcasing an AI image recognition system making an amusing mistake. The neural network (named &quot;neural net guesses memes&quot;) attempted to classify an image with 99.52% confidence that it shows a skunk. However, the image actually shows two cats lying together - one black and one white - whose coloring and positioning resembles the distinctive black and white pattern of a skunk.<p>The humor comes from the fact that while the AI was very confident (99.52%) in its prediction, it was completely wrong...&quot;<p>The progress we made in barely ten years is astounding.</div><br/><div id="42664430" class="c"><input type="checkbox" id="c-42664430" checked=""/><div class="controls bullet"><span class="by">timomaxgalvin</span><span>|</span><a href="#42663824">root</a><span>|</span><a href="#42664387">parent</a><span>|</span><a href="#42664312">next</a><span>|</span><label class="collapse" for="c-42664430">[-]</label><label class="expand" for="c-42664430">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s easy to make something work when the example goes from being out of the training data to into the training data.</div><br/></div></div></div></div></div></div><div id="42664312" class="c"><input type="checkbox" id="c-42664312" checked=""/><div class="controls bullet"><span class="by">bjornsing</span><span>|</span><a href="#42663824">prev</a><span>|</span><a href="#42663261">next</a><span>|</span><label class="collapse" for="c-42664312">[-]</label><label class="expand" for="c-42664312">[1 more]</label></div><br/><div class="children"><div class="content">I’m surprised this doesn’t place more emphasis on self-supervised learning through exploration. Is human-labeled datasets really the SOTA approach for robotics?</div><br/></div></div><div id="42663261" class="c"><input type="checkbox" id="c-42663261" checked=""/><div class="controls bullet"><span class="by">jes5199</span><span>|</span><a href="#42664312">prev</a><span>|</span><a href="#42663056">next</a><span>|</span><label class="collapse" for="c-42663261">[-]</label><label class="expand" for="c-42663261">[4 more]</label></div><br/><div class="children"><div class="content">I would love to see some numbers. How many orders of magnitude more complicated do we think embodiment is, compared to conversation? How much data do we need compared to what we’ve already collected?</div><br/><div id="42664435" class="c"><input type="checkbox" id="c-42664435" checked=""/><div class="controls bullet"><span class="by">timomaxgalvin</span><span>|</span><a href="#42663261">parent</a><span>|</span><a href="#42664352">next</a><span>|</span><label class="collapse" for="c-42664435">[-]</label><label class="expand" for="c-42664435">[1 more]</label></div><br/><div class="children"><div class="content">I feel more tired after driving all day than reading all day.</div><br/></div></div><div id="42664352" class="c"><input type="checkbox" id="c-42664352" checked=""/><div class="controls bullet"><span class="by">rstuart4133</span><span>|</span><a href="#42663261">parent</a><span>|</span><a href="#42664435">prev</a><span>|</span><a href="#42663773">next</a><span>|</span><label class="collapse" for="c-42664352">[-]</label><label class="expand" for="c-42664352">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Hardness&quot; is a difficult quantity to define if you venture beyond &quot;humans have been trying to build systems to do this for a while, and haven&#x27;t succeeded&quot;.<p>Insects have succeed in build precision systems that combine vision, smell, touch and a few other senses.  I doubt finding a juicy spider, immobilising it, is that much more difficult that finding a door knob and turning it, or folding a T-Shirt.  Yet insects accomplish it with I suspect far less compute than modern LLM&#x27;s.  So it&#x27;s not &quot;hard&quot; in the sense of requiring huge compute resources, and certainly not a lot of power.<p>So it&#x27;s probably not that hard in the sense that it&#x27;s well within the capabilities of the hardware we have now.  The issue is more that we don&#x27;t have a clue how to do it.</div><br/></div></div><div id="42663773" class="c"><input type="checkbox" id="c-42663773" checked=""/><div class="controls bullet"><span class="by">FloorEgg</span><span>|</span><a href="#42663261">parent</a><span>|</span><a href="#42664352">prev</a><span>|</span><a href="#42663056">next</a><span>|</span><label class="collapse" for="c-42663773">[-]</label><label class="expand" for="c-42663773">[1 more]</label></div><br/><div class="children"><div class="content">If nature computed both through evolution, then maybe it&#x27;s approximately the same ratio. So roughly the time it took to evolve embodiment, and roughly the time it took to evolve from grunts to advanced language.<p>If we start from when we think multicellular life first evolved (~2b years), or maybe the Cambrian explosion (~500m years), and until modern humans (~300k years). Then compare that to the time between first modern humans now now.<p>It seems like maybe 3-4 orders of magnitude harder.<p>My intuition after reading the articles is that there needs to be way more sensors all throughout the robot, probably with lots of redundancies, and then lots of modern LLM sized models all dedicated to specific joints and functions and capable of cascading judgement between each other, similar to how our nervous system works.</div><br/></div></div></div></div><div id="42663056" class="c"><input type="checkbox" id="c-42663056" checked=""/><div class="controls bullet"><span class="by">Legend2440</span><span>|</span><a href="#42663261">prev</a><span>|</span><a href="#42662987">next</a><span>|</span><label class="collapse" for="c-42663056">[-]</label><label class="expand" for="c-42663056">[3 more]</label></div><br/><div class="children"><div class="content">Honestly I&#x27;m tired of people who are more focused on &#x27;debunking the hype&#x27; than figuring out how to make things work.<p>Yes, robotics is hard, and it&#x27;s still hard despite big breakthroughs in other parts of AI like computer vision and NLP. But deep learning is still the most promising avenue for general-purpose robots, and it&#x27;s hard to imagine a way to handle the open-ended complexity of the real world <i>other</i> than learning.<p>Just let them cook.</div><br/><div id="42663799" class="c"><input type="checkbox" id="c-42663799" checked=""/><div class="controls bullet"><span class="by">FloorEgg</span><span>|</span><a href="#42663056">parent</a><span>|</span><a href="#42663454">next</a><span>|</span><label class="collapse" for="c-42663799">[-]</label><label class="expand" for="c-42663799">[1 more]</label></div><br/><div class="children"><div class="content">As someone on the sidelines of robotics who generally feels everything getting disrupted and at the precipice of major change, it&#x27;s really helpful to have a clearer understanding of the actual challenge and how close we are to solving it. Anything that helps me make more accurate predictions will help me make better decisions about what problems I should be trying to solve and what skills I should be trying to develop.</div><br/></div></div><div id="42663454" class="c"><input type="checkbox" id="c-42663454" checked=""/><div class="controls bullet"><span class="by">mitthrowaway2</span><span>|</span><a href="#42663056">parent</a><span>|</span><a href="#42663799">prev</a><span>|</span><a href="#42662987">next</a><span>|</span><label class="collapse" for="c-42663454">[-]</label><label class="expand" for="c-42663454">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>If you want a more technical, serious (better) post with a solution oriented point to make, I’ll refer you to Eric Jang’s post [1]</i><p>[1] <a href="https:&#x2F;&#x2F;evjang.com&#x2F;2022&#x2F;07&#x2F;23&#x2F;robotics-generative.html" rel="nofollow">https:&#x2F;&#x2F;evjang.com&#x2F;2022&#x2F;07&#x2F;23&#x2F;robotics-generative.html</a></div><br/></div></div></div></div><div id="42662987" class="c"><input type="checkbox" id="c-42662987" checked=""/><div class="controls bullet"><span class="by">catgary</span><span>|</span><a href="#42663056">prev</a><span>|</span><a href="#42663741">next</a><span>|</span><label class="collapse" for="c-42662987">[-]</label><label class="expand" for="c-42662987">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, this was my general impression after a brief, disastrous stretch in robotics after my PhD. Hell, I work in animation now, which is a way easier problem since there are no physical constraints, and we still can’t solve a lot of the problems the OP brings up.<p>Even stuff like using video misses the point, because so much of our experience is via touch.</div><br/></div></div><div id="42663741" class="c"><input type="checkbox" id="c-42663741" checked=""/><div class="controls bullet"><span class="by">jillesvangurp</span><span>|</span><a href="#42662987">prev</a><span>|</span><a href="#42663226">next</a><span>|</span><label class="collapse" for="c-42663741">[-]</label><label class="expand" for="c-42663741">[1 more]</label></div><br/><div class="children"><div class="content">Yesterday, I was watching some of the youtube videos on the website of a robotics company <a href="https:&#x2F;&#x2F;www.figure.ai" rel="nofollow">https:&#x2F;&#x2F;www.figure.ai</a> that challenges some of the points in this article a bit.<p>They have a nice robot prototype that (assuming these demos aren&#x27;t faked) does fairly complicated things. And one of the key features they show case is using OpenAI&#x27;s AI for the human computer interaction and reasoning.<p>While these things seem a bit slow, they do get things done. They have a cool demo of the a human interacting with one of the prototypes to ask it what it thinks needs to be done and then asking it do these things. That show cases reasoning, planning, and machine vision. Which are exactly topics that all the big LLM companies are working on.<p>They appear to be using an agentic approach similar to how LLMs are currently being integrated into other software products. Honestly, it doesn&#x27;t even look like they are doing much that isn&#x27;t part of OpenAI&#x27;s APIs. Which is impressive. I saw speech capabilities, reasoning, visual inputs, function calls, etc. in action. Including the dreaded &quot;thinking&quot; pause where the Robot waits a few seconds for the remote GPUs to do their thing.<p>This is not about fine motor control but about replacing humans controlling robots with LLMs controlling robots and getting similarly good&#x2F;ok results. As the article argues, the hardware is actually not perfect but good enough for a lot of tasks if it is controlled by a human. The hardware in this video is nothing special. Multiple companies have similar or better prototypes. Dexterity and balance are alright but probably not best in class. Best in class hardware is not the point of these demos.<p>Dexterity and real time feedback is less important than the reasoning and classification capabilities people have. The latency just means things go a bit slower. Watching these things shuffle around like an old person that needs to go to the bath room is a bit painful. But getting from A to B seems like a solved problem. A 2 or 3x speedup would be nice. 10x would be impressively fast. 100x would be scary and intimidating to have near you. I don&#x27;t think that&#x27;s going to be a challenge long term. Making LLMs faster is an easier problem than making them smarter.<p>Putting a coffee cup in a coffee machine (one of the demo videos) and then learning to fix it when it misaligns seems like an impressive capability. It compensates for precision and speed with adaptability and reasoning: analyze the camera input, correctly analyze the situation, problem and challenge come up with a plan to perform the task, execute the plan, re-evaluate, adapt, fix. It&#x27;s a bit clumsy but the end result is coffee. Good demo and I can see how you might make it do all sorts of things that are vaguely useful that way.<p>The key point here is that knowing that the thing in front of the robot is a coffee cup and a coffee machine and identifying how those things fit together and in what context that is required are all things that LLMs can do.<p>Better feedback loops and hardware will make this faster, and less tedious to watch. Faster LLMs will help with that too. And better LLMs will result in less mistakes, better plans, etc. It seems both capabilities are improving at an enormously fast pace right now.<p>And a fine point with human intelligence is that we divide and conquer. Juggling is a lot harder when you start thinking about it. The thinking parts of your brain interferes with the lower level neural circuits involved with juggling. You&#x27;ll drop the balls. The whole point with juggling is that you need to act faster than you can think. Like LLMs, we&#x27;re too slow. But we can still learn to juggle. Juggling robots are going to be a thing.</div><br/></div></div><div id="42663226" class="c"><input type="checkbox" id="c-42663226" checked=""/><div class="controls bullet"><span class="by">cratermoon</span><span>|</span><a href="#42663741">prev</a><span>|</span><label class="collapse" for="c-42663226">[-]</label><label class="expand" for="c-42663226">[4 more]</label></div><br/><div class="children"><div class="content">It might be nice if the author qualified &quot;most of the freely available data on the internet&quot; with &quot;whether or not it was copyrighted&quot; or something to acknowledge the widespread theft of the works of millions.</div><br/><div id="42663846" class="c"><input type="checkbox" id="c-42663846" checked=""/><div class="controls bullet"><span class="by">danielbln</span><span>|</span><a href="#42663226">parent</a><span>|</span><a href="#42664328">prev</a><span>|</span><label class="collapse" for="c-42663846">[-]</label><label class="expand" for="c-42663846">[2 more]</label></div><br/><div class="children"><div class="content">Theft is the wrong term, it implies that the original is no longer available. It&#x27;s copyright infringement at best, and possibly fair use depending on jurisdiction. It wasn&#x27;t theft when the RIAA went on a lawsuit spree against mp3 copying, and it isn&#x27;t theft now.</div><br/><div id="42664355" class="c"><input type="checkbox" id="c-42664355" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#42663226">root</a><span>|</span><a href="#42663846">parent</a><span>|</span><label class="collapse" for="c-42664355">[-]</label><label class="expand" for="c-42664355">[1 more]</label></div><br/><div class="children"><div class="content">Related: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=IeTybKL1pM4" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=IeTybKL1pM4</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>