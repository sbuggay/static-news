<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1694854877741" as="style"/><link rel="stylesheet" href="styles.css?v=1694854877741"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.wired.com/story/welfare-state-algorithms/">The Suspicion Machine</a> <span class="domain">(<a href="https://www.wired.com">www.wired.com</a>)</span></div><div class="subtext"><span>dthal</span> | <span>21 comments</span></div><br/><div><div id="37533047" class="c"><input type="checkbox" id="c-37533047" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#37533057">next</a><span>|</span><label class="collapse" for="c-37533047">[-]</label><label class="expand" for="c-37533047">[2 more]</label></div><br/><div class="children"><div class="content">The algorithm described in this article seems very bad.  But I would argue that ML risk scores can, in principle, be better than human judgment.<p>Humans seem more subject to bias than algorithms are.  Algorithms only look at data, but humans are additionally vulnerable to stereotypes and prejudices from society.<p>Furthermore, using an algorithm gives voters an opportunity to have a debate regarding how best to approach a problem like welfare fraud.<p>Human judgment relies on bureaucrats who are often biased and unaccountable.  It&#x27;s infeasible for voters to audit every decision made by a human bureaucrat.  Replacing the bureaucrat with an algorithm and inviting voters to audit the algorithm seems a heck of a lot more feasible.<p>I give the city of Rotterdam a lot of credit for the level of transparency they demonstrated in this article.  If they want to be successful with algorithmic risk scores, I think they should increase the level of transparency even further.  Run an open contest to develop algorithms for spotting welfare fraud.  Give citizens or representatives information about the performance characteristics of various algorithms, and let them vote for the algorithm they want.<p>In the same way politicians periodically come up for re-election, algorithms should periodically come up for re-election too.  Inform voters how the current algorithm has been performing, and give them the option to switch to something different.</div><br/><div id="37533113" class="c"><input type="checkbox" id="c-37533113" checked=""/><div class="controls bullet"><span class="by">tagyro</span><span>|</span><a href="#37533047">parent</a><span>|</span><a href="#37533057">next</a><span>|</span><label class="collapse" for="c-37533113">[-]</label><label class="expand" for="c-37533113">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Humans seem more subject to bias than algorithms are.<p>One might think that, but algorithms are built by humans, so they (algorithms) automatically have the same biases as the humans that built them.</div><br/></div></div></div></div><div id="37533057" class="c"><input type="checkbox" id="c-37533057" checked=""/><div class="controls bullet"><span class="by">0wis</span><span>|</span><a href="#37533047">prev</a><span>|</span><a href="#37532073">next</a><span>|</span><label class="collapse" for="c-37533057">[-]</label><label class="expand" for="c-37533057">[1 more]</label></div><br/><div class="children"><div class="content">I am not sure the data model is the problem here.
I feel like the journalist tried really hard to make a case against scoring (which I do not like either), but overlooked the fact that the whole system in which its embedded is bad.
The case should not be on the technology but on its usage.<p>It’s already looking like a bad journalism piece in the first part :<p>” Being flagged for investigation can ruin someone’s life, and the opacity of the system makes it nearly impossible to challenge being selected for an investigation, let alone stop one that’s already underway. One mother put under investigation in Rotterdam faced a raid from fraud controllers who rifled through her laundry, counted toothbrushes, and asked intimate questions about her life in front of her children.”<p>Here the problem is not the algorithm, its the investigators.<p>Another ethical problem for me : the system of flagging in whole relied partly on anonymous tips from neighbors. I am not an expert but I feel more at ease about a system that rely on a selection algorithm + randomness than delation.<p>I think the problem was the processes around the algorithm not its existence itself.
The journalist seems to assume during the whole piece that the algorithm will become the main&#x2F;only way to identify fraudsters. If its the case, it’s terribly wrong because how are you training your algorithm then ?<p>Most of the time, the piece try to put the reader in an emotional state of fear and anger and is not at all doing any analysis, while faking it using a lot of numbers and graphs.<p>Sorry for the long rant but I  am surprised that this came from Wired which I consider quite good on tech topics, and that its on HN 2nd page.<p>I am against government scoring and algorithms for legal &#x2F; police cases precisely because it can be badly used by powerful people.<p>Am I the only one to feel that its not a good article ?</div><br/></div></div><div id="37532073" class="c"><input type="checkbox" id="c-37532073" checked=""/><div class="controls bullet"><span class="by">rnk</span><span>|</span><a href="#37533057">prev</a><span>|</span><a href="#37532793">next</a><span>|</span><label class="collapse" for="c-37532073">[-]</label><label class="expand" for="c-37532073">[8 more]</label></div><br/><div class="children"><div class="content">This is a real problem. These algorithms are a way for us in the west to experience social credit type scores like we read about from China. I&#x27;m sure there&#x27;s someone here who was unfortunate to have a name that overlapped in some way with an identified &quot;terrorist&quot;. Don&#x27;t forget that when you buy an airplane ticket, there&#x27;s that always slightly worrisome option to &quot;add your special id number if you are incorrectly listed as a terrorist&quot;, whatever they call that. The inability to sue to identify the problem or correct it is a real loss of autonomy and freedom. I&#x27;ve always wondered what the impact would be if I ran into that. And also how come the &#x27;terrorist&#x27; can&#x27;t just find out someone&#x27;s excuse-me number? I put terrorist in quotes not because there aren&#x27;t any real terrorists, but because it is such a fraught identification, subjective, there must be mistakes.</div><br/><div id="37532986" class="c"><input type="checkbox" id="c-37532986" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#37532073">parent</a><span>|</span><a href="#37532449">next</a><span>|</span><label class="collapse" for="c-37532986">[-]</label><label class="expand" for="c-37532986">[1 more]</label></div><br/><div class="children"><div class="content">&gt;The inability to sue to identify the problem or correct it is a real loss of autonomy and freedom.<p>It&#x27;s unclear if &quot;inability to sue&quot; applies in this case.  For example:<p>&gt;Discriminating against people based on their gender and ethnic background is illegal in the Netherlands, but converting that information into data points to be fed into an algorithm may not be. This gray area, in part the result of broad legal leeway granted in the name of fighting welfare fraud, lets officials process and profile welfare recipients based on sensitive characteristics in ways that would otherwise be illegal. Dutch courts are currently reviewing the issue.</div><br/></div></div><div id="37532449" class="c"><input type="checkbox" id="c-37532449" checked=""/><div class="controls bullet"><span class="by">Biologist123</span><span>|</span><a href="#37532073">parent</a><span>|</span><a href="#37532986">prev</a><span>|</span><a href="#37532793">next</a><span>|</span><label class="collapse" for="c-37532449">[-]</label><label class="expand" for="c-37532449">[6 more]</label></div><br/><div class="children"><div class="content">In the west, I sometimes wonder if we already have a scoring system which ensures only good citizens can access housing, food and the rest.<p>It’s called “money”, which together with credit scoring functions to make sure you abide by the rules society sets: no pay, no play.</div><br/><div id="37532801" class="c"><input type="checkbox" id="c-37532801" checked=""/><div class="controls bullet"><span class="by">lozenge</span><span>|</span><a href="#37532073">root</a><span>|</span><a href="#37532449">parent</a><span>|</span><a href="#37532519">next</a><span>|</span><label class="collapse" for="c-37532801">[-]</label><label class="expand" for="c-37532801">[2 more]</label></div><br/><div class="children"><div class="content">Money in the US traces back to redlining, racist deeds, racist lending criteria, white areas enforced with mob violence etc. Money is just the modern legal way of carrying over past discrimination.</div><br/><div id="37532904" class="c"><input type="checkbox" id="c-37532904" checked=""/><div class="controls bullet"><span class="by">RandomLensman</span><span>|</span><a href="#37532073">root</a><span>|</span><a href="#37532801">parent</a><span>|</span><a href="#37532519">next</a><span>|</span><label class="collapse" for="c-37532904">[-]</label><label class="expand" for="c-37532904">[1 more]</label></div><br/><div class="children"><div class="content">Interesting that money in the US should have a very different origin - how did that happen?</div><br/></div></div></div></div><div id="37532519" class="c"><input type="checkbox" id="c-37532519" checked=""/><div class="controls bullet"><span class="by">safety1st</span><span>|</span><a href="#37532073">root</a><span>|</span><a href="#37532449">parent</a><span>|</span><a href="#37532801">prev</a><span>|</span><a href="#37532793">next</a><span>|</span><label class="collapse" for="c-37532519">[-]</label><label class="expand" for="c-37532519">[3 more]</label></div><br/><div class="children"><div class="content">This is like equating dick pic spam with sexual abuse, yes the first one is problematic, but no it is not equal to the second, in fact it&#x27;s a disservice to victims of genuine abuse to equate them.<p>I can get money from almost anybody who&#x27;s willing to give it to me for any reason, the government&#x27;s influence and visibility into this are limited. I can earn money in some other currency&#x2F;jurisdiction and convert it, too. Agree the US credit bureaus are problematic (they are not a &quot;Western&quot; thing, they&#x27;re an American thing), but they&#x27;re nothing like the social credit score.<p>With China&#x27;s social credit score there&#x27;s one number in a database which the government can adjust as they see fit, if they decide to penalize you, you&#x27;re no longer able to participate in a vast array of social services and functions. It is total control and you become a pariah overnight.<p>This comment was whataboutism, I guess. <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Whataboutism" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Whataboutism</a></div><br/><div id="37532586" class="c"><input type="checkbox" id="c-37532586" checked=""/><div class="controls bullet"><span class="by">Biologist123</span><span>|</span><a href="#37532073">root</a><span>|</span><a href="#37532519">parent</a><span>|</span><a href="#37532569">next</a><span>|</span><label class="collapse" for="c-37532586">[-]</label><label class="expand" for="c-37532586">[1 more]</label></div><br/><div class="children"><div class="content">Your analogy is a bit of an odd one, as unsolicited dick pics are undoubtedly a form of sexual abuse.</div><br/></div></div><div id="37532569" class="c"><input type="checkbox" id="c-37532569" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#37532073">root</a><span>|</span><a href="#37532519">parent</a><span>|</span><a href="#37532586">prev</a><span>|</span><a href="#37532793">next</a><span>|</span><label class="collapse" for="c-37532569">[-]</label><label class="expand" for="c-37532569">[1 more]</label></div><br/><div class="children"><div class="content">&gt; With China&#x27;s social credit score there&#x27;s one number in a database<p>Isn&#x27;t the consensus that this doesn&#x27;t actually exist, though?<p>It&#x27;s one of those very well talked about things that in reality just... isn&#x27;t... there.</div><br/></div></div></div></div></div></div></div></div><div id="37532793" class="c"><input type="checkbox" id="c-37532793" checked=""/><div class="controls bullet"><span class="by">lozenge</span><span>|</span><a href="#37532073">prev</a><span>|</span><a href="#37532800">next</a><span>|</span><label class="collapse" for="c-37532793">[-]</label><label class="expand" for="c-37532793">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t the Dutch language requirement, which is codified as an eligibility criteria, already intended to create an underclass of residents?<p>I think it is morally justifiable as a residency requirement, but not justifiable to let people live there without being able to receive government support.<p>I think it&#x27;s a situation where the government want to be racist or at least xenophobic, the citizens agree, but the law prevents them. Accenture was drafted in to get around the law.</div><br/><div id="37532960" class="c"><input type="checkbox" id="c-37532960" checked=""/><div class="controls bullet"><span class="by">0xDEAFBEAD</span><span>|</span><a href="#37532793">parent</a><span>|</span><a href="#37532800">next</a><span>|</span><label class="collapse" for="c-37532960">[-]</label><label class="expand" for="c-37532960">[1 more]</label></div><br/><div class="children"><div class="content">&gt;I think it is morally justifiable as a residency requirement, but not justifiable to let people live there without being able to receive government support.<p>Given the choice between accepting a small number of immigrants <i>with</i> government support, or a large number of immigrants <i>without</i> government support, the second option seems more humane to me.<p>By choosing the first option, you are effectively creating a privileged class based on whatever criteria your country uses to accept immigrants. The underclass might be out of your sight, but it still exists.<p>As long as you are using some criteria to accept immigrants, &quot;willing to work without government support&quot; (at least until they become fluent in the local language) seems like a perfectly reasonable criterion to me.  And it is a criterion that gives your nation the capacity to accept a larger number of migrants without breaking the budget -- thereby helping more people from developing countries improve their economic situation.</div><br/></div></div></div></div><div id="37532800" class="c"><input type="checkbox" id="c-37532800" checked=""/><div class="controls bullet"><span class="by">croes</span><span>|</span><a href="#37532793">prev</a><span>|</span><a href="#37532054">next</a><span>|</span><label class="collapse" for="c-37532800">[-]</label><label class="expand" for="c-37532800">[1 more]</label></div><br/><div class="children"><div class="content">Seems like it uses a simple equation:<p>Poor = suspicious</div><br/></div></div><div id="37532054" class="c"><input type="checkbox" id="c-37532054" checked=""/><div class="controls bullet"><span class="by">friend_and_foe</span><span>|</span><a href="#37532800">prev</a><span>|</span><a href="#37532249">next</a><span>|</span><label class="collapse" for="c-37532054">[-]</label><label class="expand" for="c-37532054">[5 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;archive.ph&#x2F;9Ibjn" rel="nofollow noreferrer">https:&#x2F;&#x2F;archive.ph&#x2F;9Ibjn</a></div><br/><div id="37532284" class="c"><input type="checkbox" id="c-37532284" checked=""/><div class="controls bullet"><span class="by">CommitSyn</span><span>|</span><a href="#37532054">parent</a><span>|</span><a href="#37532249">next</a><span>|</span><label class="collapse" for="c-37532284">[-]</label><label class="expand" for="c-37532284">[4 more]</label></div><br/><div class="children"><div class="content">I desperately want to read this article. Anyone else getting &#x2F;constant&#x2F; cloudflare CAPTCHAS while trying to access archive.ph? Android with mobile Firefox or chrome, first with wifi then mobile then VPN. No matter what I can&#x27;t access it and it won&#x27;t stop showing the &quot;are you a human?&quot; check page, even after trying the CAPTCHA the first time it stops showing.<p>Must be a cloudflare outage?</div><br/><div id="37532527" class="c"><input type="checkbox" id="c-37532527" checked=""/><div class="controls bullet"><span class="by">ImAnAmateur</span><span>|</span><a href="#37532054">root</a><span>|</span><a href="#37532284">parent</a><span>|</span><a href="#37532344">next</a><span>|</span><label class="collapse" for="c-37532527">[-]</label><label class="expand" for="c-37532527">[1 more]</label></div><br/><div class="children"><div class="content">Have you tried reading the linked article? It&#x27;s not behind a pay wall. It works for me even with javascript on.<p>IMO, ghe article is only good for better understanding the abysmal failure of the Rotterdam, Netherlands 2017-2021 government benefits random audit program. The authors allege that they contacted other cities that set up something similar but don&#x27;t name any. Related reading: <a href="https:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;welfare-algorithms-discrimination&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;welfare-algorithms-discriminatio...</a></div><br/></div></div><div id="37532344" class="c"><input type="checkbox" id="c-37532344" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#37532054">root</a><span>|</span><a href="#37532284">parent</a><span>|</span><a href="#37532527">prev</a><span>|</span><a href="#37532783">next</a><span>|</span><label class="collapse" for="c-37532344">[-]</label><label class="expand" for="c-37532344">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t need to read the article, it seems like you understand the problem :)</div><br/></div></div><div id="37532783" class="c"><input type="checkbox" id="c-37532783" checked=""/><div class="controls bullet"><span class="by">thedailymail</span><span>|</span><a href="#37532054">root</a><span>|</span><a href="#37532284">parent</a><span>|</span><a href="#37532344">prev</a><span>|</span><a href="#37532249">next</a><span>|</span><label class="collapse" for="c-37532783">[-]</label><label class="expand" for="c-37532783">[1 more]</label></div><br/><div class="children"><div class="content">If you are using Cloudflare 1.1.1.1, try switching it off or using another DNS resolver. There are reported issues with archive.md blocking access from 1.1.1.1</div><br/></div></div></div></div></div></div><div id="37532249" class="c"><input type="checkbox" id="c-37532249" checked=""/><div class="controls bullet"><span class="by">nicbou</span><span>|</span><a href="#37532054">prev</a><span>|</span><label class="collapse" for="c-37532249">[-]</label><label class="expand" for="c-37532249">[1 more]</label></div><br/><div class="children"><div class="content">This terrifies me.<p>Algorithms give the rank and file the option to defer all accountability to a machine. The algorithms make mistakes. No one gets blamed or fired for trusting it in the first place.</div><br/></div></div></div></div></div></div></div></body></html>