<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1736931675383" as="style"/><link rel="stylesheet" href="styles.css?v=1736931675383"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://modal.com/gpu-glossary/readme">The Missing Nvidia GPU Glossary</a> <span class="domain">(<a href="https://modal.com">modal.com</a>)</span></div><div class="subtext"><span>birdculture</span> | <span>63 comments</span></div><br/><div><div id="42702202" class="c"><input type="checkbox" id="c-42702202" checked=""/><div class="controls bullet"><span class="by">jms55</span><span>|</span><a href="#42703563">next</a><span>|</span><label class="collapse" for="c-42702202">[-]</label><label class="expand" for="c-42702202">[19 more]</label></div><br/><div class="children"><div class="content">The weird part of the programming model is that threadblocks don&#x27;t map 1:1 to warps or SMs. A single threadblock executes on a single SM, but each SM has multiple warps, and the threadblock could be the size of a single warp, or larger than the combined thread count of all warps in the SM.<p>So, how large do you make your threadblocks to get optimal SM&#x2F;warp scheduling? Well it &quot;depends&quot; based on resource usage, divergence, etc. Basically run it, profile, switch the threadblock size, profile again, etc. Repeat on every GPU&#x2F;platform (if you&#x27;re programming for multiple GPU platforms and not just CUDA, like games do). It&#x27;s a huge pain, and very sensitive to code changes.<p>People new to GPU programming ask me &quot;how big do I make the threadblock size?&quot; and I tell them go with 64 or 128 to start, and then profile and adjust as needed.<p>Two articles on the AMD side of things:<p><a href="https:&#x2F;&#x2F;gpuopen.com&#x2F;learn&#x2F;occupancy-explained" rel="nofollow">https:&#x2F;&#x2F;gpuopen.com&#x2F;learn&#x2F;occupancy-explained</a><p><a href="https:&#x2F;&#x2F;gpuopen.com&#x2F;learn&#x2F;optimizing-gpu-occupancy-resource-usage-large-thread-groups" rel="nofollow">https:&#x2F;&#x2F;gpuopen.com&#x2F;learn&#x2F;optimizing-gpu-occupancy-resource-...</a></div><br/><div id="42702716" class="c"><input type="checkbox" id="c-42702716" checked=""/><div class="controls bullet"><span class="by">bassp</span><span>|</span><a href="#42702202">parent</a><span>|</span><a href="#42703875">next</a><span>|</span><label class="collapse" for="c-42702716">[-]</label><label class="expand" for="c-42702716">[8 more]</label></div><br/><div class="children"><div class="content">I was taught that you want, usually, more threads per block than each SM can execute, because SMs context switch between threads (fancy hardware multi threading!) on memory read stalls to achieve super high throughput.<p>There are, ofc, other concerns like register pressure that could affect the calculus, but if an SM is waiting on a memory read to proceed and doesn’t have any other threads available to run, you’re probably leaving perf on the table (iirc).</div><br/><div id="42703528" class="c"><input type="checkbox" id="c-42703528" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42702716">parent</a><span>|</span><a href="#42704845">next</a><span>|</span><label class="collapse" for="c-42703528">[-]</label><label class="expand" for="c-42703528">[5 more]</label></div><br/><div class="children"><div class="content">Pretty sure CUDA will limit your thread count to hardware constraints? You can’t just request a million threads.</div><br/><div id="42703582" class="c"><input type="checkbox" id="c-42703582" checked=""/><div class="controls bullet"><span class="by">bassp</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42703528">parent</a><span>|</span><a href="#42703621">next</a><span>|</span><label class="collapse" for="c-42703582">[-]</label><label class="expand" for="c-42703582">[2 more]</label></div><br/><div class="children"><div class="content">You can request up to 1024-2048 threads per block depending on the gpu; each SM can execute between 32 and 128 threads at a time! So you can have a lot more threads assigned to an SM than the SM can run at once</div><br/><div id="42707310" class="c"><input type="checkbox" id="c-42707310" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42703582">parent</a><span>|</span><a href="#42703621">next</a><span>|</span><label class="collapse" for="c-42707310">[-]</label><label class="expand" for="c-42707310">[1 more]</label></div><br/><div class="children"><div class="content">Right, ok. So you mean a handful of warps and not like a plethora of them for no reason.</div><br/></div></div></div></div><div id="42703621" class="c"><input type="checkbox" id="c-42703621" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42703528">parent</a><span>|</span><a href="#42703582">prev</a><span>|</span><a href="#42704845">next</a><span>|</span><label class="collapse" for="c-42703621">[-]</label><label class="expand" for="c-42703621">[2 more]</label></div><br/><div class="children"><div class="content">Thread counts per block are limited to 1024 (unless I’ve missed and change and wikipedia is wrong), but total threads per kernel is 1024<i>(2^32-1)</i>65535*65535 ~= 2^74 threads<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thread_block_(CUDA_programming)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thread_block_(CUDA_programming...</a></div><br/><div id="42707329" class="c"><input type="checkbox" id="c-42707329" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42703621">parent</a><span>|</span><a href="#42704845">next</a><span>|</span><label class="collapse" for="c-42707329">[-]</label><label class="expand" for="c-42707329">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I’m talking about the limit per-block.</div><br/></div></div></div></div></div></div><div id="42704845" class="c"><input type="checkbox" id="c-42704845" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42702716">parent</a><span>|</span><a href="#42703528">prev</a><span>|</span><a href="#42703875">next</a><span>|</span><label class="collapse" for="c-42704845">[-]</label><label class="expand" for="c-42704845">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I was taught that you want, usually, more threads per block
&gt; than each SM can execute, because SMs context switch between
&gt; threads (fancy hardware multi threading!) on memory read 
&gt; stalls to achieve super high throughput.<p>You were taught wrong...<p>First, &quot;execution&quot; on an SM is a complex pipelined thing, like on a CPU core (except without branching). If you mean instruction issues, an SM can up to issue up to 4 instructions, one for each of 4 warps per cycle (on NVIDIA hardware for the last 10 years). But - there is no such thing as an SM &quot;context switch between threads&quot;.<p>Sometimes, more than 4<i>32 = 128 threads is a good idea. Sometimes, it&#x27;s a bad idea. This depends on things like:<p></i> Amount of shared memory used per warp<p>* Makeup of the instructions to be executed<p>* Register pressure, like you mentioned (because once you exceed 256 threads per block, the number of registers available per thread starts to decrease).</div><br/><div id="42705866" class="c"><input type="checkbox" id="c-42705866" checked=""/><div class="controls bullet"><span class="by">bassp</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42704845">parent</a><span>|</span><a href="#42703875">next</a><span>|</span><label class="collapse" for="c-42705866">[-]</label><label class="expand" for="c-42705866">[1 more]</label></div><br/><div class="children"><div class="content">Sorry if I was sloppy with my wording, instruction issuance is what I meant :)<p>I thought that warps weren&#x27;t issued instructions unless they were ready to execute (ie had all the data they needed to execute the next instruction), and that therefore it was a best practice, in most (not all) cases to have more threads per block than the SM can execute at once so that the warp scheduler can issue instructions to one warp while another waits on a memory read. Is that not true?</div><br/></div></div></div></div></div></div><div id="42703875" class="c"><input type="checkbox" id="c-42703875" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42702202">parent</a><span>|</span><a href="#42702716">prev</a><span>|</span><a href="#42702224">next</a><span>|</span><label class="collapse" for="c-42703875">[-]</label><label class="expand" for="c-42703875">[1 more]</label></div><br/><div class="children"><div class="content">100% -- there&#x27;s basically no substitue for benchmarking! I find the empiricism kind of comforting, coming from a research science background.<p>IIUC, even CuBLAS basically just uses a bunch of heuristics that are mostly derived from benchmarking to decide with kernels to use.</div><br/></div></div><div id="42702224" class="c"><input type="checkbox" id="c-42702224" checked=""/><div class="controls bullet"><span class="by">EarlKing</span><span>|</span><a href="#42702202">parent</a><span>|</span><a href="#42703875">prev</a><span>|</span><a href="#42704786">next</a><span>|</span><label class="collapse" for="c-42702224">[-]</label><label class="expand" for="c-42702224">[8 more]</label></div><br/><div class="children"><div class="content">Sounds like the sort of thing that would lend itself to runtime optimization.</div><br/><div id="42702318" class="c"><input type="checkbox" id="c-42702318" checked=""/><div class="controls bullet"><span class="by">jms55</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42702224">parent</a><span>|</span><a href="#42704640">next</a><span>|</span><label class="collapse" for="c-42702318">[-]</label><label class="expand" for="c-42702318">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not too informed on the details, but iirc drivers _do_ try and optimize shaders in the background, and then when ready swaps in a better version. But I doubt it does stuff like change threadgroup size, the programmer might assume a certain size and their shader would be broken if changed. Also drivers doing background work means unpredictable performance and stuttering, which developers really don&#x27;t like.<p>Someone correct me if I&#x27;m wrong, maybe drivers don&#x27;t do this anymore.</div><br/><div id="42703243" class="c"><input type="checkbox" id="c-42703243" checked=""/><div class="controls bullet"><span class="by">EarlKing</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42702318">parent</a><span>|</span><a href="#42704640">next</a><span>|</span><label class="collapse" for="c-42703243">[-]</label><label class="expand" for="c-42703243">[3 more]</label></div><br/><div class="children"><div class="content">Well, if the user isn&#x27;t going to be sharing the GPU with another task then you could push things back to install-time. In other words: At install time you conduct a benchmark on the relevant shaders, rewrite as necessary, recompile, and save the results accordingly. Now the user has a version of your shaders optimized to their particular configuration. Since installation times are already somewhat lengthy anyway you can be reasonably certain that no one is going to miss an extra minute or two needed to conduct benchmarks, especially if it results in installing optimized code.</div><br/><div id="42703982" class="c"><input type="checkbox" id="c-42703982" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42703243">parent</a><span>|</span><a href="#42703538">next</a><span>|</span><label class="collapse" for="c-42703982">[-]</label><label class="expand" for="c-42703982">[1 more]</label></div><br/><div class="children"><div class="content">Coming from the neural network world, rather than the shader world, but: I&#x27;d say you&#x27;re absolutely right!<p>Right now NNs and their workloads are changing quickly enough that people tend to prefer runtime optimization (like the dynamic&#x2F;JIT compilation provided by Torch&#x27;s compiler), but when you&#x27;re confident you understand the workload and have the know-how, you can do static compilation (e.g. with ONNX, TensorRT).<p>I work on a serverless infrastructure product that gets used for NN inference on GPUs, so we&#x27;re very interested in ways to amortize as much of that compilation and configuration work as possible. Maybe someday we&#x27;ll even have something like what Redshift has in their query engine -- pre-compiled binaries cached across users.</div><br/></div></div><div id="42703538" class="c"><input type="checkbox" id="c-42703538" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42703243">parent</a><span>|</span><a href="#42703982">prev</a><span>|</span><a href="#42704640">next</a><span>|</span><label class="collapse" for="c-42703538">[-]</label><label class="expand" for="c-42703538">[1 more]</label></div><br/><div class="children"><div class="content">This is how autotuning often works yes</div><br/></div></div></div></div></div></div><div id="42704640" class="c"><input type="checkbox" id="c-42704640" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42702224">parent</a><span>|</span><a href="#42702318">prev</a><span>|</span><a href="#42704786">next</a><span>|</span><label class="collapse" for="c-42704640">[-]</label><label class="expand" for="c-42704640">[3 more]</label></div><br/><div class="children"><div class="content">But which programming languages are most amenable to automatic runtime optimization?<p>Should we go back to FORTRAN?</div><br/><div id="42707510" class="c"><input type="checkbox" id="c-42707510" checked=""/><div class="controls bullet"><span class="by">morphle</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42704640">parent</a><span>|</span><a href="#42706446">next</a><span>|</span><label class="collapse" for="c-42707510">[-]</label><label class="expand" for="c-42707510">[1 more]</label></div><br/><div class="children"><div class="content">Squeak Smalltalk has several automatic runtime optimizations and compilers like JIT, parallel load balancing compiler [1], adaptive compiler [2] and a metacircular simulator and byte code virtual machine written in itself that allows you to do runtime optimisations on GPUs. The byte codes are of course replaced with the native GPU instructions at runtime.<p>There are dozens of scientific papers and active research is still being done [1].<p>I&#x27;ve worked on automatic parallel runtime optimizations and adaptive compilers since 1981. We make reconfigurable hardware (chips and wafers) that also optimises at runtime.<p>Truffle&#x2F;GraalVM is very rigid and overly complicated [6].<p>With a meta compiler like Ometa or Ohm we can give any programming language the runtime adaptive compilation for GPUs [3][4].<p>I&#x27;m currently adapting my adaptive compiler to Apple Silicon M4 GPU and neural engine to unlock the trillions of operations per second these chips can do.<p>I can adapt them to more NVIDIA GPUs with the information of the website in the title. Thank you very much charles_irl! I would love to be able to save the whole website in a single PDF.<p>I can optimise your GPU software a lot with my adaptive compilers. It will cost less than 100K in labour to speed up your GPU code by a factor 4-8 at least, sometimes I see 30-50 times speedup.<p>[1] <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wDhnjEQyuDk" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wDhnjEQyuDk</a><p>[2] <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=CfYnzVxdwZE" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=CfYnzVxdwZE</a><p>[3] <a href="https:&#x2F;&#x2F;tinlizzie.org&#x2F;~ohshima&#x2F;shadama2&#x2F;" rel="nofollow">https:&#x2F;&#x2F;tinlizzie.org&#x2F;~ohshima&#x2F;shadama2&#x2F;</a><p>[4] <a href="https:&#x2F;&#x2F;github.com&#x2F;yoshikiohshima&#x2F;Shadama">https:&#x2F;&#x2F;github.com&#x2F;yoshikiohshima&#x2F;Shadama</a><p>[5] <a href="http:&#x2F;&#x2F;www.tinlizzie.org&#x2F;ometa&#x2F;" rel="nofollow">http:&#x2F;&#x2F;www.tinlizzie.org&#x2F;ometa&#x2F;</a><p>[6] <a href="https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;grcuda">https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;grcuda</a></div><br/></div></div><div id="42706446" class="c"><input type="checkbox" id="c-42706446" checked=""/><div class="controls bullet"><span class="by">EarlKing</span><span>|</span><a href="#42702202">root</a><span>|</span><a href="#42704640">parent</a><span>|</span><a href="#42707510">prev</a><span>|</span><a href="#42704786">next</a><span>|</span><label class="collapse" for="c-42706446">[-]</label><label class="expand" for="c-42706446">[1 more]</label></div><br/><div class="children"><div class="content">The sad answer is... probably none of them. Runtime optimization has always been one of those things that sends most programmers running away screaming, and those who make languages never seem to come from the ranks of those who understand the clear utility of it.</div><br/></div></div></div></div></div></div><div id="42704786" class="c"><input type="checkbox" id="c-42704786" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#42702202">parent</a><span>|</span><a href="#42702224">prev</a><span>|</span><a href="#42703563">next</a><span>|</span><label class="collapse" for="c-42704786">[-]</label><label class="expand" for="c-42704786">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a huge pain, and very sensitive to code changes.<p>Optimization is very often like that. Making things generic, uniform and simple typically has a performance penalty - and you use your GPU because you care about that stuff.</div><br/></div></div></div></div><div id="42703563" class="c"><input type="checkbox" id="c-42703563" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42702202">prev</a><span>|</span><a href="#42708230">next</a><span>|</span><label class="collapse" for="c-42703563">[-]</label><label class="expand" for="c-42703563">[2 more]</label></div><br/><div class="children"><div class="content">It would be nice if this also included terms that are often used by Nvidia that apparently come from computer architecture (?) but are basically foreign to software engineers, like “scoreboard” or “math pipe”.</div><br/><div id="42703701" class="c"><input type="checkbox" id="c-42703701" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42703563">parent</a><span>|</span><a href="#42708230">next</a><span>|</span><label class="collapse" for="c-42703701">[-]</label><label class="expand" for="c-42703701">[1 more]</label></div><br/><div class="children"><div class="content">Great idea! We&#x27;ll add some of those in the next round.</div><br/></div></div></div></div><div id="42708230" class="c"><input type="checkbox" id="c-42708230" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#42703563">prev</a><span>|</span><a href="#42702216">next</a><span>|</span><label class="collapse" for="c-42708230">[-]</label><label class="expand" for="c-42708230">[1 more]</label></div><br/><div class="children"><div class="content">Really great work, suggest for a next post: the VRAM requirements estimation calculation for running models locally. Especially with different architecture and different Quants, it gets always confusing and even online calculators give different answer. I never found a really good deep dive on this yet.</div><br/></div></div><div id="42702216" class="c"><input type="checkbox" id="c-42702216" checked=""/><div class="controls bullet"><span class="by">EarlKing</span><span>|</span><a href="#42708230">prev</a><span>|</span><a href="#42705347">next</a><span>|</span><label class="collapse" for="c-42702216">[-]</label><label class="expand" for="c-42702216">[5 more]</label></div><br/><div class="children"><div class="content">FINALLY. Nvidia&#x27;s always been pretty craptacular when it comes to their documentation. It&#x27;s really hard to read unless you already know their internal names for, well, just about everything.</div><br/><div id="42703107" class="c"><input type="checkbox" id="c-42703107" checked=""/><div class="controls bullet"><span class="by">let_me_post_0</span><span>|</span><a href="#42702216">parent</a><span>|</span><a href="#42705347">next</a><span>|</span><label class="collapse" for="c-42703107">[-]</label><label class="expand" for="c-42703107">[4 more]</label></div><br/><div class="children"><div class="content">Nvidia isn&#x27;t very big on opensource either. Most CUDA libraries are still closed source. I think this might eventually be their downfall, because people want to know what they are working with. For example with PyTorch, I can profile the library against my use case and then decide to modify the official library to get some bespoke optimization. With CUDA, if I need to do that, I need to start from scratch and guess as to whether the library from the api already has such optimizations.</div><br/><div id="42704904" class="c"><input type="checkbox" id="c-42704904" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#42702216">root</a><span>|</span><a href="#42703107">parent</a><span>|</span><a href="#42705347">next</a><span>|</span><label class="collapse" for="c-42704904">[-]</label><label class="expand" for="c-42704904">[3 more]</label></div><br/><div class="children"><div class="content">NVIDIA does have a bunch of FOSS libraries - like CUB and Thrust (now part of CCCL). But - they tend to suffer from &quot;not invented here&quot; syndrome [1] ; so they seem to avoid collaboration on FOSS they don&#x27;t manage&#x2F;control by themselves.<p>I have a bit of a chip on my shoulder here, since I&#x27;ve been trying to pitch my Modern C++ API wrappers to them for years, and even though I&#x27;ve gotten some appreciative comments from individuals, they have shown zero interest.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;eyalroz&#x2F;cuda-api-wrappers&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;eyalroz&#x2F;cuda-api-wrappers&#x2F;</a><p>There is also their driver, which is supposedly &quot;open source&quot;, but actually none of the logic is exposed to you. Their runtime library is closed too, their management utility (nvidia-smi), their LLVM-based compiler, their profilers, their OpenCL stack :-(<p>I must say they do have relatively extensive documentation, even if it doesn&#x27;t cover everything.<p>[1] - <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Not_invented_here" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Not_invented_here</a></div><br/><div id="42706603" class="c"><input type="checkbox" id="c-42706603" checked=""/><div class="controls bullet"><span class="by">TerraHertz</span><span>|</span><a href="#42702216">root</a><span>|</span><a href="#42704904">parent</a><span>|</span><a href="#42705347">next</a><span>|</span><label class="collapse" for="c-42706603">[-]</label><label class="expand" for="c-42706603">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a deeper reason. Remember 3Dfx? They made the entire source code for their  3D hardware available to developers, all in C and a tiny bit of assembler. It could be easily ported to non-Wintel platforms. (I know, because I did port it to a MIPS  based platform that had zero operating system. It was a poker machine.)<p>Then 3Dfx was smashed from the inside and bought out by nVidia. Source code to 3D accellerator hardware drivers never to be seen again.<p>Why? Because if just anybody could port 3D graphics hardware and drivers to any custom hardware and OS platform, then Microsoft, Apple, etc would rapidly be killed by something with a MUCH better GUI (3D) appearing on the market.<p>The powers that be do NOT want capable, unchained computing systems to upset their carefully constructed &#x27;enslavement via enshitification&#x27; schemes.</div><br/><div id="42706785" class="c"><input type="checkbox" id="c-42706785" checked=""/><div class="controls bullet"><span class="by">ryao</span><span>|</span><a href="#42702216">root</a><span>|</span><a href="#42706603">parent</a><span>|</span><a href="#42705347">next</a><span>|</span><label class="collapse" for="c-42706785">[-]</label><label class="expand" for="c-42706785">[1 more]</label></div><br/><div class="children"><div class="content">Some of it is open source:<p><a href="https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;open-gpu-kernel-modules">https:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;open-gpu-kernel-modules</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="42705347" class="c"><input type="checkbox" id="c-42705347" checked=""/><div class="controls bullet"><span class="by">krackers</span><span>|</span><a href="#42702216">prev</a><span>|</span><a href="#42676996">next</a><span>|</span><label class="collapse" for="c-42705347">[-]</label><label class="expand" for="c-42705347">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a wonderful correspondence between GPU and more conventional SIMD vector terms in the P&amp;H comp arch book. Slide 13 of <a href="https:&#x2F;&#x2F;cse.buffalo.edu&#x2F;~rsridhar&#x2F;cse490-590&#x2F;lec&#x2F;Chapter04.pdf" rel="nofollow">https:&#x2F;&#x2F;cse.buffalo.edu&#x2F;~rsridhar&#x2F;cse490-590&#x2F;lec&#x2F;Chapter04.p...</a></div><br/></div></div><div id="42676996" class="c"><input type="checkbox" id="c-42676996" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42705347">prev</a><span>|</span><a href="#42708675">next</a><span>|</span><label class="collapse" for="c-42676996">[-]</label><label class="expand" for="c-42676996">[12 more]</label></div><br/><div class="children"><div class="content">Oh hey, I wrote this!<p>Thanks for sharing it.</div><br/><div id="42702432" class="c"><input type="checkbox" id="c-42702432" checked=""/><div class="controls bullet"><span class="by">ks2048</span><span>|</span><a href="#42676996">parent</a><span>|</span><a href="#42706226">next</a><span>|</span><label class="collapse" for="c-42702432">[-]</label><label class="expand" for="c-42702432">[3 more]</label></div><br/><div class="children"><div class="content">Looks nice. I&#x27;m not sure if this is the place for it, but what I am always searching for is a very concise table of the different GPUs available with approximate compute power and costs. Lists such as wikipedia [1] are way to complicated.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_Nvidia_graphics_processing_units" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_Nvidia_graphics_proces...</a></div><br/><div id="42703842" class="c"><input type="checkbox" id="c-42703842" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42676996">root</a><span>|</span><a href="#42702432">parent</a><span>|</span><a href="#42706226">next</a><span>|</span><label class="collapse" for="c-42703842">[-]</label><label class="expand" for="c-42703842">[2 more]</label></div><br/><div class="children"><div class="content">Yeah, there&#x27;s a tension between showing enough information to be useful for driving decisions and hiding enough information.<p>For example, &quot;compute capability&quot; sounds like it&#x27;d be what you need, but it&#x27;s actually more of a software versioning index :(<p>Was thinking of splitting the difference by collecting up the quoted arithmetic (FLOP&#x2F;s) and memory bandwidths from the manufacturer datasheets. But there&#x27;s caveats there too, e.g. the dreaded &quot;With sparsity&quot; asterisk on the Tensor Core FLOP&#x2F;s of recent generations.</div><br/><div id="42703937" class="c"><input type="checkbox" id="c-42703937" checked=""/><div class="controls bullet"><span class="by">shihab</span><span>|</span><a href="#42676996">root</a><span>|</span><a href="#42703842">parent</a><span>|</span><a href="#42706226">next</a><span>|</span><label class="collapse" for="c-42703937">[-]</label><label class="expand" for="c-42703937">[1 more]</label></div><br/><div class="children"><div class="content">I was looking for a simple table recently- outlining say how the shared memory or total register size&#x2F;SM varies between generations (Something like that Wiki table). It was surprisingly hard to find those info.</div><br/></div></div></div></div></div></div><div id="42706226" class="c"><input type="checkbox" id="c-42706226" checked=""/><div class="controls bullet"><span class="by">alberth</span><span>|</span><a href="#42676996">parent</a><span>|</span><a href="#42702432">prev</a><span>|</span><a href="#42678674">next</a><span>|</span><label class="collapse" for="c-42706226">[-]</label><label class="expand" for="c-42706226">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for this.<p>Any chance you could just make it a single long webpage (as opposed to making me click through one page at a time)?<p>For some reason on my iPad the links don’t always work the first time I click them.</div><br/></div></div><div id="42678674" class="c"><input type="checkbox" id="c-42678674" checked=""/><div class="controls bullet"><span class="by">petermcneeley</span><span>|</span><a href="#42676996">parent</a><span>|</span><a href="#42706226">prev</a><span>|</span><a href="#42702427">next</a><span>|</span><label class="collapse" for="c-42678674">[-]</label><label class="expand" for="c-42678674">[3 more]</label></div><br/><div class="children"><div class="content">Great work. Nice aesthetic.<p>&quot;These groups of threads, known as warps , are switched out on a per clock cycle basis — roughly one nanosecond. CPU thread context switches, on the other hand, take few hundred to a few thousand clock cycles&quot;<p>I would note that intels SMT does do something very similar (2 hw threads). Other like the xeon phi would round robin 4 threads on a single core.</div><br/><div id="42702443" class="c"><input type="checkbox" id="c-42702443" checked=""/><div class="controls bullet"><span class="by">zeusk</span><span>|</span><a href="#42676996">root</a><span>|</span><a href="#42678674">parent</a><span>|</span><a href="#42703744">next</a><span>|</span><label class="collapse" for="c-42702443">[-]</label><label class="expand" for="c-42702443">[1 more]</label></div><br/><div class="children"><div class="content">SMT isn&#x27;t that really is it?<p>SMT allows for concurrent execution of both threads (thus independent front-end for fetch, decode especially) and certain core resources are statically partitioned unlike a warp being scheduled on SM.<p>I&#x27;m not a graphics expert but warps seem closer to run-time&#x2F;dynamic VLIW than SMT.</div><br/></div></div><div id="42703744" class="c"><input type="checkbox" id="c-42703744" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42676996">root</a><span>|</span><a href="#42678674">parent</a><span>|</span><a href="#42702443">prev</a><span>|</span><a href="#42702427">next</a><span>|</span><label class="collapse" for="c-42703744">[-]</label><label class="expand" for="c-42703744">[1 more]</label></div><br/><div class="children"><div class="content">Thanks!<p>&gt; intels SMT does do something very similar (2 hw threads)<p>Yeah that&#x27;s a good point. One thing I learned from looking at both hardware stacks more closely was that they aren&#x27;t as different as they seem at first -- lots of the same ideas or techniques get are used, but in different ways.</div><br/></div></div></div></div><div id="42702427" class="c"><input type="checkbox" id="c-42702427" checked=""/><div class="controls bullet"><span class="by">byteknight</span><span>|</span><a href="#42676996">parent</a><span>|</span><a href="#42678674">prev</a><span>|</span><a href="#42705733">next</a><span>|</span><label class="collapse" for="c-42702427">[-]</label><label class="expand" for="c-42702427">[2 more]</label></div><br/><div class="children"><div class="content">I absolutely love the look. Is it a template or custom?</div><br/><div id="42703764" class="c"><input type="checkbox" id="c-42703764" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42676996">root</a><span>|</span><a href="#42702427">parent</a><span>|</span><a href="#42705733">next</a><span>|</span><label class="collapse" for="c-42703764">[-]</label><label class="expand" for="c-42703764">[1 more]</label></div><br/><div class="children"><div class="content">Custom! Took inspiration from lynx, lotus, and other classic terminal programs.</div><br/></div></div></div></div><div id="42705733" class="c"><input type="checkbox" id="c-42705733" checked=""/><div class="controls bullet"><span class="by">MostlyAmiable</span><span>|</span><a href="#42676996">parent</a><span>|</span><a href="#42702427">prev</a><span>|</span><a href="#42706482">next</a><span>|</span><label class="collapse" for="c-42705733">[-]</label><label class="expand" for="c-42705733">[1 more]</label></div><br/><div class="children"><div class="content">What was your method for drawing&#x2F;generating the SM diagram?</div><br/></div></div><div id="42706482" class="c"><input type="checkbox" id="c-42706482" checked=""/><div class="controls bullet"><span class="by">TerraHertz</span><span>|</span><a href="#42676996">parent</a><span>|</span><a href="#42705733">prev</a><span>|</span><a href="#42708675">next</a><span>|</span><label class="collapse" for="c-42706482">[-]</label><label class="expand" for="c-42706482">[1 more]</label></div><br/><div class="children"><div class="content">Thanks!
As an old (retired) programmer I was hoping a good intro to GPUs would turn up.
Now, I don&#x27;t suppose you could add &#x27;ink on paper&#x27; to the color options? Gray on light gray, with medium gray highlighting, is hard on old eyes. While I never want to see P7 phosphor green again.
And I suppose a zipfile of the whole thing, for local reading and archive, would be out of the question?</div><br/></div></div></div></div><div id="42708675" class="c"><input type="checkbox" id="c-42708675" checked=""/><div class="controls bullet"><span class="by">pythops</span><span>|</span><a href="#42676996">prev</a><span>|</span><a href="#42703356">next</a><span>|</span><label class="collapse" for="c-42708675">[-]</label><label class="expand" for="c-42708675">[1 more]</label></div><br/><div class="children"><div class="content">Awesome &lt;3</div><br/></div></div><div id="42703356" class="c"><input type="checkbox" id="c-42703356" checked=""/><div class="controls bullet"><span class="by">joshdavham</span><span>|</span><a href="#42708675">prev</a><span>|</span><a href="#42707473">next</a><span>|</span><label class="collapse" for="c-42703356">[-]</label><label class="expand" for="c-42703356">[2 more]</label></div><br/><div class="children"><div class="content">Incredible work, thank you so much! This will hopefully break down more barriers to entry for newcomers wanting to work with GPUs!</div><br/><div id="42703923" class="c"><input type="checkbox" id="c-42703923" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42703356">parent</a><span>|</span><a href="#42707473">next</a><span>|</span><label class="collapse" for="c-42703923">[-]</label><label class="expand" for="c-42703923">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the kind words! I still feel like one of those newcomers myself :)<p>Now that so many more people are running workloads, including critical ones, on GPUs, it feels much more important that a base level of knowledge and intuition is broadly disseminated -- kinda like how most engineers basically grok database index management, even if they couldn&#x27;t write a high-performance B+ tree from scratch. Hope this document helps that along!</div><br/></div></div></div></div><div id="42707473" class="c"><input type="checkbox" id="c-42707473" checked=""/><div class="controls bullet"><span class="by">JeremyMorgan</span><span>|</span><a href="#42703356">prev</a><span>|</span><a href="#42677177">next</a><span>|</span><label class="collapse" for="c-42707473">[-]</label><label class="expand" for="c-42707473">[1 more]</label></div><br/><div class="children"><div class="content">This is incredible. I&#x27;m gonna spend some time here.<p>And I love the design&#x2F;UI.</div><br/></div></div><div id="42677177" class="c"><input type="checkbox" id="c-42677177" checked=""/><div class="controls bullet"><span class="by">K0IN</span><span>|</span><a href="#42707473">prev</a><span>|</span><a href="#42704562">next</a><span>|</span><label class="collapse" for="c-42677177">[-]</label><label class="expand" for="c-42677177">[9 more]</label></div><br/><div class="children"><div class="content">Is there a plain text &#x2F; markdown &#x2F; html version?</div><br/><div id="42677561" class="c"><input type="checkbox" id="c-42677561" checked=""/><div class="controls bullet"><span class="by">aithrowawaycomm</span><span>|</span><a href="#42677177">parent</a><span>|</span><a href="#42678379">next</a><span>|</span><label class="collapse" for="c-42677561">[-]</label><label class="expand" for="c-42677561">[4 more]</label></div><br/><div class="children"><div class="content">I would also like to see a PDF that has all the text in one place, presented linearly. This looks like a very worthwhile read, but waiting a few seconds for two paragraphs to load is a very frustrating user experience.</div><br/><div id="42703805" class="c"><input type="checkbox" id="c-42703805" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42677177">root</a><span>|</span><a href="#42677561">parent</a><span>|</span><a href="#42678379">next</a><span>|</span><label class="collapse" for="c-42703805">[-]</label><label class="expand" for="c-42703805">[3 more]</label></div><br/><div class="children"><div class="content">A few seconds is way longer than we intended! When I click around all pages after the first load in milliseconds.<p>Do you have any script blockers, browser cache settings, or extensions that might mess with navigation?<p>&gt; would also like to see a PDF that has all the text in one place, presented linearly<p>Yeah, good idea! I think a PDF with links so that it&#x27;s still easy to cross-reference terms would get the best of both worlds.</div><br/><div id="42704887" class="c"><input type="checkbox" id="c-42704887" checked=""/><div class="controls bullet"><span class="by">aithrowawaycomm</span><span>|</span><a href="#42677177">root</a><span>|</span><a href="#42703805">parent</a><span>|</span><a href="#42704776">next</a><span>|</span><label class="collapse" for="c-42704887">[-]</label><label class="expand" for="c-42704887">[1 more]</label></div><br/><div class="children"><div class="content">I am using Safari on iOS - I disabled private relay and tested again, still seems oddly slow. No extensions; the settings to periodically delete cookies and block popups are enabled, don&#x27;t see why those would affect this. Maybe it&#x27;s just HN traffic, thousands of people flipping through the first dozen or so pages.<p>Edit: I just checked again and it didn&#x27;t load at all... I also see this is on the front page again, at 5:30pm Eastern US time :) Probably HN hug of death.</div><br/></div></div><div id="42704776" class="c"><input type="checkbox" id="c-42704776" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#42677177">root</a><span>|</span><a href="#42703805">parent</a><span>|</span><a href="#42704887">prev</a><span>|</span><a href="#42678379">next</a><span>|</span><label class="collapse" for="c-42704776">[-]</label><label class="expand" for="c-42704776">[1 more]</label></div><br/><div class="children"><div class="content">book time book time</div><br/></div></div></div></div></div></div><div id="42678379" class="c"><input type="checkbox" id="c-42678379" checked=""/><div class="controls bullet"><span class="by">htk</span><span>|</span><a href="#42677177">parent</a><span>|</span><a href="#42677561">prev</a><span>|</span><a href="#42704562">next</a><span>|</span><label class="collapse" for="c-42678379">[-]</label><label class="expand" for="c-42678379">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m with you. The theme is cool for a brief blog post, but anything longer and I want out of the AS400 terminal.</div><br/><div id="42702439" class="c"><input type="checkbox" id="c-42702439" checked=""/><div class="controls bullet"><span class="by">ks2048</span><span>|</span><a href="#42677177">root</a><span>|</span><a href="#42678379">parent</a><span>|</span><a href="#42704562">next</a><span>|</span><label class="collapse" for="c-42702439">[-]</label><label class="expand" for="c-42702439">[3 more]</label></div><br/><div class="children"><div class="content">I found it much better by clicking &quot;light&quot; at the top to change theme.</div><br/><div id="42703064" class="c"><input type="checkbox" id="c-42703064" checked=""/><div class="controls bullet"><span class="by">mandevil</span><span>|</span><a href="#42677177">root</a><span>|</span><a href="#42702439">parent</a><span>|</span><a href="#42704562">next</a><span>|</span><label class="collapse" for="c-42703064">[-]</label><label class="expand" for="c-42703064">[2 more]</label></div><br/><div class="children"><div class="content">Found it more readable, yeah, but all of the captions on the diagrams- identifying block types by color- no longer made any sense.</div><br/><div id="42703773" class="c"><input type="checkbox" id="c-42703773" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42677177">root</a><span>|</span><a href="#42703064">parent</a><span>|</span><a href="#42704562">next</a><span>|</span><label class="collapse" for="c-42703773">[-]</label><label class="expand" for="c-42703773">[1 more]</label></div><br/><div class="children"><div class="content">Good callout! I&#x27;ll work on the captions.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42704562" class="c"><input type="checkbox" id="c-42704562" checked=""/><div class="controls bullet"><span class="by">germanjoey</span><span>|</span><a href="#42677177">prev</a><span>|</span><a href="#42703501">next</a><span>|</span><label class="collapse" for="c-42704562">[-]</label><label class="expand" for="c-42704562">[1 more]</label></div><br/><div class="children"><div class="content">This is really incredible, thank you!</div><br/></div></div><div id="42703501" class="c"><input type="checkbox" id="c-42703501" checked=""/><div class="controls bullet"><span class="by">weltensturm</span><span>|</span><a href="#42704562">prev</a><span>|</span><a href="#42704917">next</a><span>|</span><label class="collapse" for="c-42703501">[-]</label><label class="expand" for="c-42703501">[3 more]</label></div><br/><div class="children"><div class="content">that&#x27;s pretty</div><br/><div id="42703993" class="c"><input type="checkbox" id="c-42703993" checked=""/><div class="controls bullet"><span class="by">charles_irl</span><span>|</span><a href="#42703501">parent</a><span>|</span><a href="#42704917">next</a><span>|</span><label class="collapse" for="c-42703993">[-]</label><label class="expand" for="c-42703993">[2 more]</label></div><br/><div class="children"><div class="content">Thanks! We think that just because something is deeply technical doesn&#x27;t mean it has to be ugly.</div><br/><div id="42708141" class="c"><input type="checkbox" id="c-42708141" checked=""/><div class="controls bullet"><span class="by">ttwwmm</span><span>|</span><a href="#42703501">root</a><span>|</span><a href="#42703993">parent</a><span>|</span><a href="#42704917">next</a><span>|</span><label class="collapse" for="c-42708141">[-]</label><label class="expand" for="c-42708141">[1 more]</label></div><br/><div class="children"><div class="content">Did you really have to hijack the up and down keys? I can&#x27;t scroll.</div><br/></div></div></div></div></div></div><div id="42704917" class="c"><input type="checkbox" id="c-42704917" checked=""/><div class="controls bullet"><span class="by">einpoklum</span><span>|</span><a href="#42703501">prev</a><span>|</span><a href="#42704205">next</a><span>|</span><label class="collapse" for="c-42704917">[-]</label><label class="expand" for="c-42704917">[1 more]</label></div><br/><div class="children"><div class="content">This has been submitted, like, five times already over the past 5 weeks:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;from?site=modal.com">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;from?site=modal.com</a></div><br/></div></div><div id="42704205" class="c"><input type="checkbox" id="c-42704205" checked=""/><div class="controls bullet"><span class="by">richwater</span><span>|</span><a href="#42704917">prev</a><span>|</span><a href="#42703931">next</a><span>|</span><label class="collapse" for="c-42704205">[-]</label><label class="expand" for="c-42704205">[3 more]</label></div><br/><div class="children"><div class="content">content is cool; usability and design of the website is awful (although charming)</div><br/><div id="42704468" class="c"><input type="checkbox" id="c-42704468" checked=""/><div class="controls bullet"><span class="by">yshklarov</span><span>|</span><a href="#42704205">parent</a><span>|</span><a href="#42703931">next</a><span>|</span><label class="collapse" for="c-42704468">[-]</label><label class="expand" for="c-42704468">[2 more]</label></div><br/><div class="children"><div class="content">Not at all -- the usability and design are fantastic! (On desktop, at least.)<p>What, specifially, do you find awful here?</div><br/><div id="42708137" class="c"><input type="checkbox" id="c-42708137" checked=""/><div class="controls bullet"><span class="by">ttwwmm</span><span>|</span><a href="#42704205">root</a><span>|</span><a href="#42704468">parent</a><span>|</span><a href="#42703931">next</a><span>|</span><label class="collapse" for="c-42708137">[-]</label><label class="expand" for="c-42708137">[1 more]</label></div><br/><div class="children"><div class="content">Try scrolling with the arrow keys.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>