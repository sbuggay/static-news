<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1733043654022" as="style"/><link rel="stylesheet" href="styles.css?v=1733043654022"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/JeffDean/status/1858540085794451906">Jeff Dean Responds to EDA Industry about AlphaChip</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>nsoonhui</span> | <span>91 comments</span></div><br/><div><div id="42287145" class="c"><input type="checkbox" id="c-42287145" checked=""/><div class="controls bullet"><span class="by">oesa</span><span>|</span><a href="#42285810">next</a><span>|</span><label class="collapse" for="c-42287145">[-]</label><label class="expand" for="c-42287145">[2 more]</label></div><br/><div class="children"><div class="content">In the tweet Jeff Dean says that Cheng at al. failed to follow the steps required to replicate the work of the Google researchers.<p>Specifically:<p>&gt; In particular the authors did no pre-training (despite pre-training being mentioned 37 times in our Nature article), robbing our learning-based method of its ability to learn from other chip designs<p>But in the Circuit Training Google repo[1] they specifically say:<p>&gt; Our results training from scratch are comparable or better than the reported results in the paper (on page 22) which used fine-tuning from a pre-trained model.<p>I may be misunderstanding something here, but which one is it? Did they mess up when they did not pre-train or they followed the &quot;steps&quot; described in the original repo and tried to get a fair reproduction?<p>Also, the UCSD group had to reverse-engineer several steps to reproduce the results so it seems like the paper&#x27;s results weren&#x27;t reproducible by themselves.<p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;google-research&#x2F;circuit_training&#x2F;blob&#x2F;main&#x2F;docs&#x2F;ARIANE.md#results">https:&#x2F;&#x2F;github.com&#x2F;google-research&#x2F;circuit_training&#x2F;blob&#x2F;mai...</a></div><br/></div></div><div id="42285810" class="c"><input type="checkbox" id="c-42285810" checked=""/><div class="controls bullet"><span class="by">vighneshiyer</span><span>|</span><a href="#42287145">prev</a><span>|</span><a href="#42286615">next</a><span>|</span><label class="collapse" for="c-42285810">[-]</label><label class="expand" for="c-42285810">[12 more]</label></div><br/><div class="children"><div class="content">I have published an addendum to an article I wrote about AlphaChip (<a href="https:&#x2F;&#x2F;vighneshiyer.com&#x2F;misc&#x2F;ml-for-placement&#x2F;" rel="nofollow">https:&#x2F;&#x2F;vighneshiyer.com&#x2F;misc&#x2F;ml-for-placement&#x2F;</a>) at the very bottom that addresses this rebuttal from Google and the AlphaChip algorithm in general.<p>In short, I think the Nature authors have made some reasonable criticisms regarding the training methodology employed by the ISPD authors, but the extreme compute cost and runtime of AlphaChip still makes it non-competitive with commercial autofloorplanners and AutoDMP. Regardless, I think the ISPD authors owe the Nature authors an even more rigorous study that addresses all their criticisms. Even if they just try to evaluate the pre-trained checkpoint that Google published, that would be a useful piece of data to add to the debate.</div><br/><div id="42286713" class="c"><input type="checkbox" id="c-42286713" checked=""/><div class="controls bullet"><span class="by">nemonemo</span><span>|</span><a href="#42285810">parent</a><span>|</span><a href="#42286298">next</a><span>|</span><label class="collapse" for="c-42286713">[-]</label><label class="expand" for="c-42286713">[6 more]</label></div><br/><div class="children"><div class="content">In the conclusion of the article, you said: &quot;While I concede that there are things the ISPD authors could have done better, their conclusion is still sound. The Nature authors do not address the fact that CMP and AutoDMP outperform CT with far less runtime and compute requirements.&quot;<p>One key argument in the rebuttal against the ISPD article is that the resources used in their comparison were significantly smaller. To me, this point alone seems sufficient to question the validity of the ISPD work&#x27;s conclusions. What are your thoughts on this?<p>Additionally, I noticed that the neutral tone of this comment is quite a departure from the strongly critical tone of your article toward the AlphaChip work (words like &quot;arrogance&quot;, &quot;disdain&quot;, &quot;hyperbole&quot;, &quot;belittling&quot;, &quot;hostile&quot; for AlphaChip authors, as opposed to &quot;excellent&quot; for a Synopsys VP.) Could you share where this difference in tone originates?</div><br/><div id="42286814" class="c"><input type="checkbox" id="c-42286814" checked=""/><div class="controls bullet"><span class="by">vighneshiyer</span><span>|</span><a href="#42285810">root</a><span>|</span><a href="#42286713">parent</a><span>|</span><a href="#42286298">next</a><span>|</span><label class="collapse" for="c-42286814">[-]</label><label class="expand" for="c-42286814">[5 more]</label></div><br/><div class="children"><div class="content">&gt; One key argument in the rebuttal against the ISPD article is that the resources used in their comparison were significantly smaller. To me, this point alone seems sufficient to question the validity of the ISPD work&#x27;s conclusions. What are your thoughts on this?<p>I believe this is a fair criticism, and it could be a reason why the ISPD Tensorboard shows divergence during training for some RTL designs. The ISPD authors provide their own justification for their substitution of training time for compute resources in page 11 of their paper (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.11014" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2302.11014</a>).<p>I do not think it changes the ISPD work&#x27;s conclusions however since they demonstrate that CMP and AutoDMP outperform CT wrt QoR and runtime even though they use much fewer compute resources. If more compute resources are used and CT becomes competitive wrt QoR, then it will still lag behind in runtime. Furthermore, Google has not produced evidence that AlphaChip, with their substantial compute resources, outperforms commercial placers (or even AutoDMP). In the recent rebuttal from Google (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2411.10053" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2411.10053</a>), the only claim on page 8 says Google VLSI engineers preferred RL over humans and commercial placers on a blind study conducted in 2020. Commercial mixed placers, if configured correctly, have become very good over the past 4 years, so perhaps another blind study is warranted.<p>&gt; Additionally, I noticed that the neutral tone of this comment is quite a departure from the strongly critical tone of your article<p>I will openly admit my bias is against the AlphaChip work. I referred to the Nature authors as &#x27;arrogant&#x27; and &#x27;disdainful&#x27; with respect to their statement that EDA CAD engineers are just being bitter ML-haters when they criticize the AlphaChip work. I referred to Jeff Dean as &#x27;belittling&#x27; and &#x27;hostile&#x27; and using &#x27;hyperbole&#x27; with respect to his statements against Igor Markov, which I think is unbecoming of him. I referred to Shankar as &#x27;excellent&#x27; with respect to his shrewd business acumen.</div><br/><div id="42287031" class="c"><input type="checkbox" id="c-42287031" checked=""/><div class="controls bullet"><span class="by">nemonemo</span><span>|</span><a href="#42285810">root</a><span>|</span><a href="#42286814">parent</a><span>|</span><a href="#42286855">next</a><span>|</span><label class="collapse" for="c-42287031">[-]</label><label class="expand" for="c-42287031">[2 more]</label></div><br/><div class="children"><div class="content">Thank you for your thoughtful response. Acknowledging potential biases openly in a public forum is never easy, and in my view, it adds credibility to your words compared to leaving such matters as implicit insinuations.<p>That said, on page 8, the paper says that &#x27;standard licensing agreements with commercial vendors prohibit public comparison with their offerings.&#x27; Given this inherent limitation, what alternative approach could have been taken to enable a more meaningful comparison between CT and CMP?</div><br/><div id="42287148" class="c"><input type="checkbox" id="c-42287148" checked=""/><div class="controls bullet"><span class="by">vighneshiyer</span><span>|</span><a href="#42285810">root</a><span>|</span><a href="#42287031">parent</a><span>|</span><a href="#42286855">next</a><span>|</span><label class="collapse" for="c-42287148">[-]</label><label class="expand" for="c-42287148">[1 more]</label></div><br/><div class="children"><div class="content">So I&#x27;m not sure what Google is referring to here. As you can see in the ISPD paper (<a href="https:&#x2F;&#x2F;vlsicad.ucsd.edu&#x2F;Publications&#x2F;Conferences&#x2F;396&#x2F;c396.pdf" rel="nofollow">https:&#x2F;&#x2F;vlsicad.ucsd.edu&#x2F;Publications&#x2F;Conferences&#x2F;396&#x2F;c396.p...</a>) on page 5, they openly compare Cadence CMP with AutoDMP and other algorithims quantitatively. The only obfuscation is with the proprietary GF12 technology, where they can&#x27;t provide absolute numbers, but only relative ones. Comparison against commercial tools is actually a common practice in academic EDA CAD papers, although usually the exact tool vendor is obfuscated. CAD tool vendors have actually gotten more permissive about sharing tool data and scripts in public over the past few years. However, PDKs have always been under NDAs and are still very restrictive.<p>Perhaps the Cadence license agreement signed by a corporation is different than the one signed by a university. In such a case, they could partner with a university. But I doubt their license agreement prevents any public comparison. For example, see the AutoDMP paper from NVIDIA (<a href="https:&#x2F;&#x2F;d1qx31qr3h6wln.cloudfront.net&#x2F;publications&#x2F;AutoDMP.pdf" rel="nofollow">https:&#x2F;&#x2F;d1qx31qr3h6wln.cloudfront.net&#x2F;publications&#x2F;AutoDMP.p...</a>) where on page 7 they openly benchmark their tool against Cadence Innovus. My suspicion is they wish to keep details about the TPU blocks they evaluated under tight wraps.</div><br/></div></div></div></div><div id="42286855" class="c"><input type="checkbox" id="c-42286855" checked=""/><div class="controls bullet"><span class="by">make3</span><span>|</span><a href="#42285810">root</a><span>|</span><a href="#42286814">parent</a><span>|</span><a href="#42287031">prev</a><span>|</span><a href="#42286298">next</a><span>|</span><label class="collapse" for="c-42286855">[-]</label><label class="expand" for="c-42286855">[2 more]</label></div><br/><div class="children"><div class="content">We care about the field advancing, not the feelings of a few sadly low EQ researchers. The approach is either better or it&#x27;s not.</div><br/><div id="42286938" class="c"><input type="checkbox" id="c-42286938" checked=""/><div class="controls bullet"><span class="by">BoingBoomTschak</span><span>|</span><a href="#42285810">root</a><span>|</span><a href="#42286855">parent</a><span>|</span><a href="#42286298">next</a><span>|</span><label class="collapse" for="c-42286938">[-]</label><label class="expand" for="c-42286938">[1 more]</label></div><br/><div class="children"><div class="content">&gt; EQ<p>Using a fantasy concept invented by a science journalist doesn&#x27;t help your posts, you know. Protip: it&#x27;s just empathy + regular intelligence.</div><br/></div></div></div></div></div></div></div></div><div id="42286298" class="c"><input type="checkbox" id="c-42286298" checked=""/><div class="controls bullet"><span class="by">wholehog</span><span>|</span><a href="#42285810">parent</a><span>|</span><a href="#42286713">prev</a><span>|</span><a href="#42286615">next</a><span>|</span><label class="collapse" for="c-42286298">[-]</label><label class="expand" for="c-42286298">[5 more]</label></div><br/><div class="children"><div class="content">We&#x27;re talking 16 GPUs for ~6 hrs for inference, and 48 hrs for pre-training. This is not an exorbitant amount of compute.<p>A GPU costs $1-2&#x2F;hr on the cloud market. So, ~$100-200 for inference, and ~$800-1600 for pre-training, which amortizes across chips. Cloud prices are an upper bound -- most CS labs will have way more than this available on premises.<p>In an industry context, these costs are completely dwarfed by the rest of the chip design process. (For context, the licensing costs alone for most commercial EDA software are in the millions of dollars.)</div><br/><div id="42286702" class="c"><input type="checkbox" id="c-42286702" checked=""/><div class="controls bullet"><span class="by">vighneshiyer</span><span>|</span><a href="#42285810">root</a><span>|</span><a href="#42286298">parent</a><span>|</span><a href="#42286366">next</a><span>|</span><label class="collapse" for="c-42286702">[-]</label><label class="expand" for="c-42286702">[1 more]</label></div><br/><div class="children"><div class="content">You are correct. For commercial use, the GPUs used for training and fine-tuning aren&#x27;t a problem financially. However, if we wanted to rigorously benchmark AlphaChip against simulated annealing or other floorplanning algorithms, we have to afford the same compute and runtime budget to each algorithm. With 16 GPUs running for 6 hours, you could explore a huge placement space using any algorithm, and it isn&#x27;t clear if RL will outperform the other ones. Furthermore, the runtime of AlphaChip as shown in the Nature paper and ISPD was still significantly greater than Cadence&#x27;s concurrent macro placer (even after pre-training, RL requires several hours of fine-tuning on the target problem instance). Arguably, the runtime could go down with more GPUs, but at this point, it is unclear how much value is coming from the policy network &#x2F; problem embedding vs the ability to explore many potential placements.</div><br/></div></div><div id="42286366" class="c"><input type="checkbox" id="c-42286366" checked=""/><div class="controls bullet"><span class="by">bushbaba</span><span>|</span><a href="#42285810">root</a><span>|</span><a href="#42286298">parent</a><span>|</span><a href="#42286702">prev</a><span>|</span><a href="#42286615">next</a><span>|</span><label class="collapse" for="c-42286366">[-]</label><label class="expand" for="c-42286366">[3 more]</label></div><br/><div class="children"><div class="content">h100 GPU instances are multiple orders of magnitude more expensive.</div><br/><div id="42286413" class="c"><input type="checkbox" id="c-42286413" checked=""/><div class="controls bullet"><span class="by">radq</span><span>|</span><a href="#42285810">root</a><span>|</span><a href="#42286366">parent</a><span>|</span><a href="#42286696">next</a><span>|</span><label class="collapse" for="c-42286413">[-]</label><label class="expand" for="c-42286413">[1 more]</label></div><br/><div class="children"><div class="content">Not true, H100s cost $2-3&#x2F;GPU&#x2F;hr on the open market.</div><br/></div></div><div id="42286696" class="c"><input type="checkbox" id="c-42286696" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#42285810">root</a><span>|</span><a href="#42286366">parent</a><span>|</span><a href="#42286413">prev</a><span>|</span><a href="#42286615">next</a><span>|</span><label class="collapse" for="c-42286696">[-]</label><label class="expand" for="c-42286696">[1 more]</label></div><br/><div class="children"><div class="content">H100 GPUs are more or less similar in price&#x2F;performance. It is 2-3x more expensive per hour for 2-3x higher performance.</div><br/></div></div></div></div></div></div></div></div><div id="42286615" class="c"><input type="checkbox" id="c-42286615" checked=""/><div class="controls bullet"><span class="by">_cs2017_</span><span>|</span><a href="#42285810">prev</a><span>|</span><a href="#42285420">next</a><span>|</span><label class="collapse" for="c-42286615">[-]</label><label class="expand" for="c-42286615">[2 more]</label></div><br/><div class="children"><div class="content">Curious why there&#x27;s so much emotion and unpleasantness in this dispute? How did it evolve from the boring academic argument about benchmarks, significance, etc to a battle of personal attacks?</div><br/><div id="42286805" class="c"><input type="checkbox" id="c-42286805" checked=""/><div class="controls bullet"><span class="by">boredatoms</span><span>|</span><a href="#42286615">parent</a><span>|</span><a href="#42285420">next</a><span>|</span><label class="collapse" for="c-42286805">[-]</label><label class="expand" for="c-42286805">[1 more]</label></div><br/><div class="children"><div class="content">A lot of people work on non-AI implementations</div><br/></div></div></div></div><div id="42285420" class="c"><input type="checkbox" id="c-42285420" checked=""/><div class="controls bullet"><span class="by">nsoonhui</span><span>|</span><a href="#42286615">prev</a><span>|</span><a href="#42286311">next</a><span>|</span><label class="collapse" for="c-42285420">[-]</label><label class="expand" for="c-42285420">[1 more]</label></div><br/><div class="children"><div class="content">The context of Jeff Dean&#x27;s response:<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41673769">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41673769</a><p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41673808">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=41673808</a></div><br/></div></div><div id="42286311" class="c"><input type="checkbox" id="c-42286311" checked=""/><div class="controls bullet"><span class="by">wholehog</span><span>|</span><a href="#42285420">prev</a><span>|</span><a href="#42286858">next</a><span>|</span><label class="collapse" for="c-42286311">[-]</label><label class="expand" for="c-42286311">[2 more]</label></div><br/><div class="children"><div class="content">The paper: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2411.10053" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2411.10053</a></div><br/></div></div><div id="42286858" class="c"><input type="checkbox" id="c-42286858" checked=""/><div class="controls bullet"><span class="by">rowanG077</span><span>|</span><a href="#42286311">prev</a><span>|</span><a href="#42285441">next</a><span>|</span><label class="collapse" for="c-42286858">[-]</label><label class="expand" for="c-42286858">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t get. Why isn&#x27;t the model open if it works? If it isn&#x27;t this is just a fart in the wind. If it is the findings should be straightforward to replicate.</div><br/></div></div><div id="42285441" class="c"><input type="checkbox" id="c-42285441" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#42286858">prev</a><span>|</span><a href="#42285972">next</a><span>|</span><label class="collapse" for="c-42285441">[-]</label><label class="expand" for="c-42285441">[25 more]</label></div><br/><div class="children"><div class="content">The fact that the EDA companies are garbage in no way mitigates the fact that Google continues to peddle unsubstantiated snake oil.<p>This is easy to debunk from the Google side: release a tool.  If you don&#x27;t want to release a tool, then it&#x27;s unsubstantiated and you don&#x27;t get to publish.  Simple.<p>That having been said:<p>1) None of these &quot;AI&quot; tools have yet demonstrated the ability to classify &quot;This is datapath&quot;, &quot;This is array logic&quot;, &quot;This is random logic&quot;.  This is the <i>BIG</i> win.  And it won&#x27;t just be a couple of percentage points in area or a couple of days saved when it works--it will be 25%+ in area and months in time.<p>2) Saving a couple of percentage points in random logic isn&#x27;t impressive.  If I have the compute power to run EDA tools with a couple of different random seeds, at least one run will likely be a couple percentage points better.<p>3) I really don&#x27;t understand why they don&#x27;t do stuff on analog&#x2F;RF.  The patterns are smaller and much better matches to the kind of reinforcement learning that current &quot;AI&quot; is suited for.<p>I put this snake oil in the same category as &quot;financial advice&quot;--if it worked, they wouldn&#x27;t be sharing it and would simply be printing money by taking advantage of it.</div><br/><div id="42285601" class="c"><input type="checkbox" id="c-42285601" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#42285441">parent</a><span>|</span><a href="#42285623">next</a><span>|</span><label class="collapse" for="c-42285601">[-]</label><label class="expand" for="c-42285601">[10 more]</label></div><br/><div class="children"><div class="content">&gt; Google continues to peddle unsubstantiated snake oil<p>I read your comment, but I&#x27;m not following -- or maybe I disagree with it -- I&#x27;m not sure yet.<p>&quot;Snake oil&quot; is an emotionally loaded term that raises the temperature of the conversation. That usually makes having a conversation harder.<p>From my point of view, AlphaGo, AlphaZero, AlphaFold were significant achievements. Agree? Are you claiming that AlphaChip is not? Are you claiming they are perpetrating some kind of deception or exaggeration? Your numbered points seem like valid criticisms (I haven&#x27;t evaluated them closely), but even if true, I don&#x27;t see how they support your &quot;snake oil&quot; claim.</div><br/><div id="42285665" class="c"><input type="checkbox" id="c-42285665" checked=""/><div class="controls bullet"><span class="by">11101010001100</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42285601">parent</a><span>|</span><a href="#42285649">next</a><span>|</span><label class="collapse" for="c-42285665">[-]</label><label class="expand" for="c-42285665">[2 more]</label></div><br/><div class="children"><div class="content">Their material discovery paper turned out to have negligible significance.</div><br/><div id="42285801" class="c"><input type="checkbox" id="c-42285801" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42285665">parent</a><span>|</span><a href="#42285649">next</a><span>|</span><label class="collapse" for="c-42285801">[-]</label><label class="expand" for="c-42285801">[1 more]</label></div><br/><div class="children"><div class="content">If so, does this qualify as “snake oil”? What do you mean? Snake oil requires exaggeration and deception. Fair?<p>If a paper &#x2F; experiment is done with intellectual honesty, great! If it doesn’t make a big splash, fine.</div><br/></div></div></div></div><div id="42285649" class="c"><input type="checkbox" id="c-42285649" checked=""/><div class="controls bullet"><span class="by">griomnib</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42285601">parent</a><span>|</span><a href="#42285665">prev</a><span>|</span><a href="#42285824">next</a><span>|</span><label class="collapse" for="c-42285649">[-]</label><label class="expand" for="c-42285649">[6 more]</label></div><br/><div class="children"><div class="content">They have literally been caught faking AI demos, they brought distrust on themselves.</div><br/><div id="42285754" class="c"><input type="checkbox" id="c-42285754" checked=""/><div class="controls bullet"><span class="by">rajup</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42285649">parent</a><span>|</span><a href="#42285824">next</a><span>|</span><label class="collapse" for="c-42285754">[-]</label><label class="expand" for="c-42285754">[5 more]</label></div><br/><div class="children"><div class="content">Really not sure how you’re conflating product demos which are known to be pie in the sky across the industry (not just Google) with peer reviewed research published in journals. Super basic distinction imho.</div><br/><div id="42286280" class="c"><input type="checkbox" id="c-42286280" checked=""/><div class="controls bullet"><span class="by">stackghost</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42285754">parent</a><span>|</span><a href="#42285824">next</a><span>|</span><label class="collapse" for="c-42286280">[-]</label><label class="expand" for="c-42286280">[4 more]</label></div><br/><div class="children"><div class="content">&gt;peer reviewed research published in journals<p>Peer review doesn&#x27;t mean as much as Elsevier would like you to believe.  Plenty of peer-reviewed research is absolute trash.</div><br/><div id="42286689" class="c"><input type="checkbox" id="c-42286689" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42286280">parent</a><span>|</span><a href="#42285824">next</a><span>|</span><label class="collapse" for="c-42286689">[-]</label><label class="expand" for="c-42286689">[3 more]</label></div><br/><div class="children"><div class="content">All of the highest impact papers authored by DeepMind and Google Brain have appeared in Nature, which is the gold standard for peer-reviewed natural science research.  What exactly are you trying to claim about Google&#x27;s peer-reviewed papers?</div><br/><div id="42286837" class="c"><input type="checkbox" id="c-42286837" checked=""/><div class="controls bullet"><span class="by">stackghost</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42286689">parent</a><span>|</span><a href="#42287149">next</a><span>|</span><label class="collapse" for="c-42286837">[-]</label><label class="expand" for="c-42286837">[1 more]</label></div><br/><div class="children"><div class="content">Nature is just as susceptible to the perverse incentives at play in the academic publishing market as anyone else, and has had their share of controversies over the years including having to retract papers after they were found to be bogus.<p>In and of itself, &quot;Being published in a peer reviewed journal&quot; does not place the contents of a paper beyond reproach or criticism.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42285824" class="c"><input type="checkbox" id="c-42285824" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42285601">parent</a><span>|</span><a href="#42285649">prev</a><span>|</span><a href="#42285623">next</a><span>|</span><label class="collapse" for="c-42285824">[-]</label><label class="expand" for="c-42285824">[1 more]</label></div><br/><div class="children"><div class="content">&gt; From my point of view, AlphaGo, AlphaZero, AlphaFold were significant achievements.<p>These things you mentioned had obvious benchmarks that were <i>easily</i> surpassed by the appropriate &quot;AI&quot;.  The evidence that they were better wasn&#x27;t just significant, it was <i>obvious</i>.<p>This leaves the fact that with what appears to be maximal cooking of the books, the only thing AlphaChip seems to be able to beat is human, manual placement and not anything algorithmic--even from many, many generations ago.<p>Trying to pass that off as a significant &quot;advance&quot; in a &quot;scientific publication&quot; borders on scientific fraud and should <i>definitely</i> be called out.<p>The problem here is that I am certain that this is wired to the career trajectories of &quot;Very Important People(tm)&quot; and the fact that it essentially failed miserably is simply not politically allowed.<p>If they want to lie, they can do that in press releases.  If they want published in something reputable, they should have to be able to provide proper evidence for replication.<p>And, if they can&#x27;t do that, well, that&#x27;s an answer itself, no?</div><br/></div></div></div></div><div id="42285623" class="c"><input type="checkbox" id="c-42285623" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#42285441">parent</a><span>|</span><a href="#42285601">prev</a><span>|</span><a href="#42286676">next</a><span>|</span><label class="collapse" for="c-42285623">[-]</label><label class="expand" for="c-42285623">[1 more]</label></div><br/><div class="children"><div class="content">&gt; if it worked, they wouldn&#x27;t be sharing it and would simply be printing money by taking advantage of it.<p>Sure, there are some techniques in financial markets that are only valuable when they are not widely known. But claiming this pattern applies universally is incorrect.<p>Publishing a technique doesn&#x27;t prove it doesn&#x27;t work. (Stating it this way makes it fairly obvious.)<p>DeepMind, like many AI research labs, publish important and useful research. One might ask &quot;is a lab leaving money off the table by publishing?&quot;. Perhaps a better question is &quot;What &#x27;game&#x27; is the lab playing and over what time scale?&quot;.</div><br/></div></div><div id="42286676" class="c"><input type="checkbox" id="c-42286676" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#42285441">parent</a><span>|</span><a href="#42285623">prev</a><span>|</span><a href="#42285479">next</a><span>|</span><label class="collapse" for="c-42286676">[-]</label><label class="expand" for="c-42286676">[4 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; EDA companies are garbage
</code></pre>
I don&#x27;t understand this comment.  Can you please explain?  Are they unethical?  Or do they write poor software?</div><br/><div id="42286705" class="c"><input type="checkbox" id="c-42286705" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42286676">parent</a><span>|</span><a href="#42285479">next</a><span>|</span><label class="collapse" for="c-42286705">[-]</label><label class="expand" for="c-42286705">[3 more]</label></div><br/><div class="children"><div class="content">Yes and yes.<p>EDA companies are gatekeeping monopolies.  They absolutely abuse their monopoly position to extract huge chunks of money out of companies, and are pretty much single-handedly responsible for the fact that the hardware startup ecosystem is moribund compared to that of the software startup ecosystem.<p>They have been horrible liars about performance and benchmarketing for decades.  They dragged their feet miserably over releasing Linux versions of their software because they were extracting money based upon number of CPU licenses (everything was on Sparc which was vastly inferior).  Their software hasn&#x27;t really improved all that much over decades--mostly they benefited from Moore&#x27;s Law.  They have made a point of stifling attempts at interoperability and open data exchange.  They have bought lots of competitors mostly to just shut them down.  I can go on and on.<p>The EDA companies aren&#x27;t quite Oracle--but they&#x27;re not far off.<p>This is one of the reasons why Google is getting pounded over this--maybe even unfairly.  People in the field are <i>super</i> sensitive about bullshit claims from EDA vendors--we&#x27;ve heard them <i>all</i> and been on the receiving end of the stick <i>far</i> too many times.</div><br/><div id="42286930" class="c"><input type="checkbox" id="c-42286930" checked=""/><div class="controls bullet"><span class="by">alexey-salmin</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42286705">parent</a><span>|</span><a href="#42285479">next</a><span>|</span><label class="collapse" for="c-42286930">[-]</label><label class="expand" for="c-42286930">[2 more]</label></div><br/><div class="children"><div class="content">&gt; pretty much single-handedly responsible for the fact that the hardware startup ecosystem is moribund compared to that of the software startup ecosystem.<p>This was the case before EDA companies even appeared. Hardware is hard because it&#x27;s manufacturing. You can&#x27;t &quot;iterate quickly&quot;, every iteration costs millions of dollars and so does every mistake.</div><br/><div id="42287136" class="c"><input type="checkbox" id="c-42287136" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42286930">parent</a><span>|</span><a href="#42285479">next</a><span>|</span><label class="collapse" for="c-42287136">[-]</label><label class="expand" for="c-42287136">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Hardware is hard because it&#x27;s manufacturing. You can&#x27;t &quot;iterate quickly&quot;, every iteration costs millions of dollars and so does every mistake.<p>This is true for injection molding and yet we do that all the time in small businesses.<p>A mask set for an older technology can be in the range of $50K-$100K.  That&#x27;s right about the same price as injection molds.<p>The main difference is that Solidworks is about $25K while Cadence, et al, is about a megabuck.</div><br/></div></div></div></div></div></div></div></div><div id="42285479" class="c"><input type="checkbox" id="c-42285479" checked=""/><div class="controls bullet"><span class="by">joshuamorton</span><span>|</span><a href="#42285441">parent</a><span>|</span><a href="#42286676">prev</a><span>|</span><a href="#42286755">next</a><span>|</span><label class="collapse" for="c-42285479">[-]</label><label class="expand" for="c-42285479">[5 more]</label></div><br/><div class="children"><div class="content">As someone who has no skin in the game and is only loosely following this, there is a tool: <a href="https:&#x2F;&#x2F;github.com&#x2F;google-research&#x2F;circuit_training">https:&#x2F;&#x2F;github.com&#x2F;google-research&#x2F;circuit_training</a>, the detractors claim to not be able to reproduce Google&#x27;s results (what Dean is commenting on) with it, Google and 1-2 other companies claim to be using it internally to success (e.g. see the end of this article: <a href="https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;how-alphachip-transformed-computer-chip-design&#x2F;" rel="nofollow">https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;how-alphachip-transfor...</a>).</div><br/><div id="42285780" class="c"><input type="checkbox" id="c-42285780" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42285479">parent</a><span>|</span><a href="#42286755">next</a><span>|</span><label class="collapse" for="c-42285780">[-]</label><label class="expand" for="c-42285780">[4 more]</label></div><br/><div class="children"><div class="content">There are benchmarks in this space.  You can also bring your chip designs into the open and show what happens with different tools.  You can run the algorithm on the placed designs that you sponsor for open source VLSI to show how much better they are.<p>None of this has been done.  This is <i>table stakes</i> if you want to talk about your EDA algorithm advancement.  If this weren&#x27;t coming out of Google, everybody would laugh it out of the room (see what happened to a similar publication with similar claims from a Chinese source--everybody dismissed it out of hand--rightfully so even though that paper was <i>MUCH</i> better than anything Google has promulgated).<p>Extraordinary claims require extraordinary evidence.  Nothing about AlphaChip even reaches <i>ordinary</i> evidence.<p>If they hadn&#x27;t gotten a publication in Nature for effectively a failure, this would be <i>way</i> less contentious.</div><br/><div id="42286701" class="c"><input type="checkbox" id="c-42286701" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42285780">parent</a><span>|</span><a href="#42286755">next</a><span>|</span><label class="collapse" for="c-42286701">[-]</label><label class="expand" for="c-42286701">[3 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; Nothing about AlphaChip even reaches ordinary evidence.
</code></pre>
You reply is wildly confident and dismissive.  If correct, why did Nature choose to publish?</div><br/><div id="42286880" class="c"><input type="checkbox" id="c-42286880" checked=""/><div class="controls bullet"><span class="by">rowanG077</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42286701">parent</a><span>|</span><a href="#42287160">next</a><span>|</span><label class="collapse" for="c-42286880">[-]</label><label class="expand" for="c-42286880">[1 more]</label></div><br/><div class="children"><div class="content">Can you stop with this pure appeal to authority. Publishing in nature is not proof it works. It&#x27;s only proof the paper has packaged the claim it works semi well.</div><br/></div></div></div></div></div></div></div></div><div id="42286755" class="c"><input type="checkbox" id="c-42286755" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#42285441">parent</a><span>|</span><a href="#42285479">prev</a><span>|</span><a href="#42286517">next</a><span>|</span><label class="collapse" for="c-42286755">[-]</label><label class="expand" for="c-42286755">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; if it worked, they wouldn&#x27;t be sharing it and would simply be printing money by taking advantage of it.</i><p>This is a fallacious argument. A better chip design process does not eliminate all other risks like product-market fit or the upfront cost of making masks or chronic mismanagement.</div><br/></div></div><div id="42286517" class="c"><input type="checkbox" id="c-42286517" checked=""/><div class="controls bullet"><span class="by">lobochrome</span><span>|</span><a href="#42285441">parent</a><span>|</span><a href="#42286755">prev</a><span>|</span><a href="#42286598">next</a><span>|</span><label class="collapse" for="c-42286517">[-]</label><label class="expand" for="c-42286517">[2 more]</label></div><br/><div class="children"><div class="content">Agreed, in particular on #2<p>Given infinite time and compute - maybe the approach is significantly better. But that’s just not practical. So unless you see dramatic shifts - no one is going to throw away proven results on your new approach because of the TTM penalty if it goes wrong.<p>The EDA industry is (has to be) ultra conservative.</div><br/><div id="42286706" class="c"><input type="checkbox" id="c-42286706" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#42285441">root</a><span>|</span><a href="#42286517">parent</a><span>|</span><a href="#42286598">next</a><span>|</span><label class="collapse" for="c-42286706">[-]</label><label class="expand" for="c-42286706">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; The EDA industry is (has to be) ultra conservative.
</code></pre>
What is special about EDA that requires it to be more conservative?</div><br/></div></div></div></div><div id="42286598" class="c"><input type="checkbox" id="c-42286598" checked=""/><div class="controls bullet"><span class="by">raverbashing</span><span>|</span><a href="#42285441">parent</a><span>|</span><a href="#42286517">prev</a><span>|</span><a href="#42285972">next</a><span>|</span><label class="collapse" for="c-42286598">[-]</label><label class="expand" for="c-42286598">[1 more]</label></div><br/><div class="children"><div class="content">Honestly this does not compute<p>&gt; None of these &quot;AI&quot; tools have yet demonstrated the ability to classify &quot;This is datapath&quot;, &quot;This is array logic&quot;, &quot;This is random logic&quot;.<p>Sounds like a good objective, one that could be added to training parameters. Or maybe it isn&#x27;t needed (AI can &#x27;understand&#x27; some concepts without explicitly tagging)<p>&gt; If I have the compute power to run EDA tools with a couple of different random seeds, at least one run will likely be a couple percentage points better.<p>Then do it?! How long does it actually take to run? I know EDA tools creators are bad at some kinds of code optimization (and yes, it&#x27;s hard) but let&#x27;s say for a company like Intel, if it takes 10 days to rerun a chip to get 1% better, that sounds like a worthy tradeoff.<p>&gt; I put this snake oil in the same category as &quot;financial advice&quot;--if it worked, they wouldn&#x27;t be sharing it and would simply be printing money by taking advantage of it.<p>Yeah I don&#x27;t think you understood the problem here. Good financial advice is about balancing risks and returns.</div><br/></div></div></div></div><div id="42285972" class="c"><input type="checkbox" id="c-42285972" checked=""/><div class="controls bullet"><span class="by">AtlasBarfed</span><span>|</span><a href="#42285441">prev</a><span>|</span><a href="#42287141">next</a><span>|</span><label class="collapse" for="c-42285972">[-]</label><label class="expand" for="c-42285972">[6 more]</label></div><br/><div class="children"><div class="content">How the hell would you verify an AI-generated silicon design?<p>Like, for a CPU, you want to be sure it behaves properly for the given inputs. Anyone remember that floating point error in, was it Pentium IIs or Pentium IIIs?<p>I mean, I guess if the chip is designed for AI, and AIs are inherently nonguaranteed output&#x2F;responses, then the AI chip design being nonguaranteed isn&#x27;t any difference in nonguarantees.<p>Unless it is...</div><br/><div id="42286195" class="c"><input type="checkbox" id="c-42286195" checked=""/><div class="controls bullet"><span class="by">quadrature</span><span>|</span><a href="#42285972">parent</a><span>|</span><a href="#42286050">next</a><span>|</span><label class="collapse" for="c-42286195">[-]</label><label class="expand" for="c-42286195">[2 more]</label></div><br/><div class="children"><div class="content">&gt; How the hell would you verify an AI-generated silicon design?<p>I think you&#x27;re asking a different question, but in the context of the OP researchers are exploring AI for solving deterministic but intractable problems in the field of chip design and not generating designs end to end.<p>Here&#x27;s an excerpt from the paper.<p>&quot;The objective is to place
a netlist graph of macros (e.g., SRAMs) and standard cells
(logic gates, such as NAND, NOR, and XOR) onto a chip
canvas, such that power, performance, and area (PPA) are
optimized, while adhering to constraints on placement density and routing congestion (described in Sections 3.3.6
and 3.3.5). Despite decades of research on this problem,
it is still necessary for human experts to iterate for weeks
with the existing placement tools, in order to produce solutions that meet multi-faceted design criteria.&quot;<p>The hope is that Reinforcement Learning can find solutions to such complex optimization problems.</div><br/><div id="42286668" class="c"><input type="checkbox" id="c-42286668" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#42285972">root</a><span>|</span><a href="#42286195">parent</a><span>|</span><a href="#42286050">next</a><span>|</span><label class="collapse" for="c-42286668">[-]</label><label class="expand" for="c-42286668">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>    &gt; Despite decades of research on this problem, it is still necessary for human experts to iterate for weeks with the existing placement tools, in order to produce solutions that meet multi-faceted design criteria.
</code></pre>
Ironically, this sounds a lot like building a bot to play StarCraft, which is exactly what AlphaStar did.  I had no idea that EDA layout is still so difficult and manual in 2024.  This seems like a very worth area of research.<p>I am not an expert in AI&#x2F;ML, but is the ultimate goal: Train on as many open source circuit designs as possible to build a base, then try to solve IC layouts problems via reinforcement learning, similar to AlphaStar.  Finally, use the trained model to do inference during IC layout?</div><br/></div></div></div></div><div id="42286050" class="c"><input type="checkbox" id="c-42286050" checked=""/><div class="controls bullet"><span class="by">lisper</span><span>|</span><a href="#42285972">parent</a><span>|</span><a href="#42286195">prev</a><span>|</span><a href="#42286426">next</a><span>|</span><label class="collapse" for="c-42286050">[-]</label><label class="expand" for="c-42286050">[1 more]</label></div><br/><div class="children"><div class="content">&gt; How the hell would you verify an AI-generated silicon design?<p>The same way you verify a human-generated one.<p>&gt; Anyone remember that floating point error in, was it Pentium IIs or Pentium IIIs?<p>That was 1994.  The industry has come a long way in the intervening 30 years.</div><br/></div></div><div id="42286426" class="c"><input type="checkbox" id="c-42286426" checked=""/><div class="controls bullet"><span class="by">asveikau</span><span>|</span><a href="#42285972">parent</a><span>|</span><a href="#42286050">prev</a><span>|</span><a href="#42286065">next</a><span>|</span><label class="collapse" for="c-42286426">[-]</label><label class="expand" for="c-42286426">[1 more]</label></div><br/><div class="children"><div class="content">The famous FPU issue that I can think of was the original Pentium.</div><br/></div></div><div id="42286065" class="c"><input type="checkbox" id="c-42286065" checked=""/><div class="controls bullet"><span class="by">gwervc</span><span>|</span><a href="#42285972">parent</a><span>|</span><a href="#42286426">prev</a><span>|</span><a href="#42287141">next</a><span>|</span><label class="collapse" for="c-42286065">[-]</label><label class="expand" for="c-42286065">[1 more]</label></div><br/><div class="children"><div class="content">A well working CPU is probably beside the point. What&#x27;s important now is for researchers to publish papers using or speaking about AI. Then executives and managers to deploy AI in their companies. Then selling AI PC (somehow, we are already at this step). Whatever the results are. Customers issues will be solved by using more AI (think chatbots) until morale improves.</div><br/></div></div></div></div><div id="42285403" class="c"><input type="checkbox" id="c-42285403" checked=""/><div class="controls bullet"><span class="by">twothreeone</span><span>|</span><a href="#42287141">prev</a><span>|</span><label class="collapse" for="c-42285403">[-]</label><label class="expand" for="c-42285403">[38 more]</label></div><br/><div class="children"><div class="content">I get why Jeff would be pressed to comment on this, given he&#x27;s credited on basically all of &quot;Google Brain&quot; research output. But saying &quot;they couldn&#x27;t replicate it because they&#x27;re idiots, therefore it&#x27;s replicable&quot; is not a rebuttal, just bullying. Sounds like the critics struck a nerve and there&#x27;s no good way for him to refute the replication problem his research apparently exhibits.</div><br/><div id="42285469" class="c"><input type="checkbox" id="c-42285469" checked=""/><div class="controls bullet"><span class="by">danpalmer</span><span>|</span><a href="#42285403">parent</a><span>|</span><a href="#42285454">next</a><span>|</span><label class="collapse" for="c-42285469">[-]</label><label class="expand" for="c-42285469">[12 more]</label></div><br/><div class="children"><div class="content">&gt; But saying &quot;they couldn&#x27;t replicate it because they&#x27;re idiots, therefore it&#x27;s replicable&quot; is not a rebuttal, just bullying<p>That&#x27;s not an argument made in the linked tweet. His claim is &quot;they couldn&#x27;t replicate it because they didn&#x27;t follow the steps&quot;, which seems like a very reasonable claim, regardless of the motivation behind making it.</div><br/><div id="42285503" class="c"><input type="checkbox" id="c-42285503" checked=""/><div class="controls bullet"><span class="by">bayarearefugee</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285469">parent</a><span>|</span><a href="#42285454">next</a><span>|</span><label class="collapse" for="c-42285503">[-]</label><label class="expand" for="c-42285503">[11 more]</label></div><br/><div class="children"><div class="content">At the end of the day my question is simply why does anyone care about the drama over this one way or another?<p>Either the research is as much of a breakthrough as is claimed and Google is about to pull way ahead of all these other &quot;idiots&quot; who can&#x27;t replicate their method even when it is described to them in detail, or the research is flawed and overblown and not as effective as claimed.  This seems like exactly the sort of question the market will quickly decide over the next couple of years and not worth arguing over.<p>Why do a non-zero amount of people have seemingly religious beliefs about this topic on one side or the other?</div><br/><div id="42285574" class="c"><input type="checkbox" id="c-42285574" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285503">parent</a><span>|</span><a href="#42286665">next</a><span>|</span><label class="collapse" for="c-42285574">[-]</label><label class="expand" for="c-42285574">[2 more]</label></div><br/><div class="children"><div class="content">The reason Jeff Dean cares is that his team&#x27;s improvement compared to standard EDA tools was marginal at best and may have overfitted to a certain class of chips. Thus, he is defending his research because it is not widely accepted. Open source code has been out for years and in that time the EDA companies have largely done their own ML-based approaches that do not match his. He attributes this not to failings in his own research but to the detractors at these companies not giving it a fair chance.<p>The guys at EDA companies care because Google&#x27;s result makes them look like idiots when you take the paper at face value, and does advance the state of the art a bit. They have been working hard for marginal improvements, and that some team of ML people can come in and make a big splash with something like this is offensive to them. Furthermore, the result is not that impressive and does not generalize enough to be useful to them (and competent teams at these companies absolutely have checked).<p>The fact that the result is so minor <i>is the reason</i> that this is so contentious.</div><br/><div id="42286270" class="c"><input type="checkbox" id="c-42286270" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285574">parent</a><span>|</span><a href="#42286665">next</a><span>|</span><label class="collapse" for="c-42286270">[-]</label><label class="expand" for="c-42286270">[1 more]</label></div><br/><div class="children"><div class="content">The result is minor AND Google spent a (relative) lot of money to achieve it (especially in the eyes of the new CFO).  Jeff Dean is desperately trying to save the prestige of the research (in a very insular, Google-y way) because he wants to save the 2017-era economically-not-viable blue sky culture where Tensorflow &amp; the TPU flourished and the transformer was born.  But the reality is that Google’s core businesses are under attack (anti-trust, Jedi Blue etc), the TPU now has zero chance versus NVidia, and Google is literally no longer growing ads.  His financing is about to pop in the next 1-2 years.<p><a href="https:&#x2F;&#x2F;sparktoro.com&#x2F;blog&#x2F;is-google-losing-search-market-share&#x2F;" rel="nofollow">https:&#x2F;&#x2F;sparktoro.com&#x2F;blog&#x2F;is-google-losing-search-market-sh...</a></div><br/></div></div></div></div><div id="42286665" class="c"><input type="checkbox" id="c-42286665" checked=""/><div class="controls bullet"><span class="by">joatmon-snoo</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285503">parent</a><span>|</span><a href="#42285574">prev</a><span>|</span><a href="#42286720">next</a><span>|</span><label class="collapse" for="c-42286665">[-]</label><label class="expand" for="c-42286665">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This seems like exactly the sort of question the market will quickly decide over the next couple of years and not worth arguing over.<p>Discussions like this are _how_ the market decides whether or not this achievement is real or not.</div><br/></div></div><div id="42286720" class="c"><input type="checkbox" id="c-42286720" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285503">parent</a><span>|</span><a href="#42286665">prev</a><span>|</span><a href="#42285525">next</a><span>|</span><label class="collapse" for="c-42286720">[-]</label><label class="expand" for="c-42286720">[1 more]</label></div><br/><div class="children"><div class="content">One constant that I see on HN: they love drama and love to tear down a winner, presumably  over jealousy.</div><br/></div></div><div id="42285525" class="c"><input type="checkbox" id="c-42285525" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285503">parent</a><span>|</span><a href="#42286720">prev</a><span>|</span><a href="#42285948">next</a><span>|</span><label class="collapse" for="c-42285525">[-]</label><label class="expand" for="c-42285525">[1 more]</label></div><br/><div class="children"><div class="content">&gt; why does anyone care<p>n.b. you&#x27;re on a social news site<p>&gt; pull way ahead of all these other &quot;idiots&quot;<p>Pulling way ahead sounds sufficient, not necessary. Can we prove it&#x27;s not the case? Let&#x27;s say someone says that&#x27;s why Gemini inference is so cheap. Can we show that&#x27;s wrong?<p>&gt; &quot;idiots&quot;<p>?</div><br/></div></div><div id="42285948" class="c"><input type="checkbox" id="c-42285948" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285503">parent</a><span>|</span><a href="#42285525">prev</a><span>|</span><a href="#42285454">next</a><span>|</span><label class="collapse" for="c-42285948">[-]</label><label class="expand" for="c-42285948">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Why do a non-zero amount of people have seemingly religious beliefs about this topic on one side or the other?<p>Because lots of engineers are being told by managers &quot;Why aren&#x27;t we using that tool?&quot; and a bunch of engineers are stuck saying &quot;Because it doesn&#x27;t actually work.&quot; aka &quot;Google is lying through their teeth.&quot; to which the response is &quot;Oh, so you know better than Google?&quot; to which the reponse is &quot;Yeah, actually, I fucking do.  Now piss off and let me finish timing closure this goddamn block that is already 6 weeks late.&quot;<p>Now can you understand why this is a bit contentious?<p>Marketing &quot;exaggerations&quot; from authority can cause <i>huge</i> amounts of grief.<p>In my little corner of the world, I had to sit and defend against the lies that a startup with famous designers were putting out about power consumption while we were designing similar chips in the space.  I had to go toe to toe with Senior VPs over it and I had to stand my ground and defend my team who analyzed things dead on.  All this occurred in spite of the fact that they had no silicon.  In addition, I <i>knew</i> the famous designers involved would happily lie straight to your face having worked with them before and having been lied straight to my face and having had to clean up the mess when they left the company.<p>To be fair, it is also the only time I have had a Senior VP remember the kerfuffle and <i>apologize</i> when said startup finally delivered silicon and not only were the real numbers not what they claimed they weren&#x27;t even close to the ones we were getting.</div><br/><div id="42286285" class="c"><input type="checkbox" id="c-42286285" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285948">parent</a><span>|</span><a href="#42285454">next</a><span>|</span><label class="collapse" for="c-42286285">[-]</label><label class="expand" for="c-42286285">[4 more]</label></div><br/><div class="children"><div class="content">And do you believe that that is what&#x27;s happening in this case?<p>If you have personal experience with Jeff Dean et al that you&#x27;re willing to share, I&#x27;d be interested in hearing about it.<p>From where I&#x27;m sitting it looks like, &quot;Google spent a fortune on deep learning, and got a small but real win. People who don&#x27;t like Google failed to follow Google&#x27;s recipe and got a large and easily replicated loss.&quot;<p>It&#x27;s not even clear that Google&#x27;s approach is feasible right now for companies not named Google. It is not clear that it works on other classes of chip. It is not clear that the technique will grow beyond what Google already got. It is really not clear that anyone should be jumping on this.<p>But there is a world of difference between that, and concluding that Google is lying.</div><br/><div id="42286673" class="c"><input type="checkbox" id="c-42286673" checked=""/><div class="controls bullet"><span class="by">bsder</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42286285">parent</a><span>|</span><a href="#42287169">next</a><span>|</span><label class="collapse" for="c-42286673">[-]</label><label class="expand" for="c-42286673">[2 more]</label></div><br/><div class="children"><div class="content">&gt; From where I&#x27;m sitting it looks like, &quot;Google spent a fortune on deep learning, and got a small but real win. People who don&#x27;t like Google failed to follow Google&#x27;s recipe and got a large and easily replicated loss.&quot;<p>From where I&#x27;m sitting it looks like Google cooked the books maximally, barely beat humans let alone state of the art algorithms, published a crappy article in Nature because it would never have passed editorial muster at something like DAC or an IEEE journal and now have to browbeat other people who are calling them out on it.<p>And that&#x27;s the <i>best</i> interpretation we can cough up.<p>I&#x27;ll go further, we don&#x27;t even have any raw data that says that they actually did beat the humans.  Some of the humans I know who run P&amp;R are <i>REALLY</i> good at what they do.  The data could be <i>completely made up</i>.  Given how much scientific fraud has come out lately, I&#x27;m amazed at the number of people defending Google on this.<p>Where I&#x27;m from, we call what Google is doing both &quot;lying&quot; and &quot;bullying&quot;.<p>Look, Google can <i>easily</i> defuse this in all manner of ways.  Publish their raw data.  Run things on testbenches and benchmarks that the EDA tools vendors have been running on for years.  Run things on the open source VLSI designs that they sponsored.<p>What I suspect happened is that Google&#x27;s AI group has gotten used to being able to make hyperbolic marketing claims which are difficult to verify.  They then poked at place and route, failed, and published an article anyway because someone&#x27;s promotion is tied to this.  They expected that everybody would swallow their glop just like every other time, be mostly ignored and the people involved can get their promotions and move on.<p>Unfortunately, Google is shoveling bullshit around something that has objective answers; real money is at stake; and they&#x27;re getting rightfully excoriated for it.<p>Whoops.</div><br/><div id="42286726" class="c"><input type="checkbox" id="c-42286726" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42286673">parent</a><span>|</span><a href="#42287169">next</a><span>|</span><label class="collapse" for="c-42286726">[-]</label><label class="expand" for="c-42286726">[1 more]</label></div><br/><div class="children"><div class="content">Look, either the follow-up article did pretraining or not. Jeff Dean is claiming that the importance of pretraining was mentioned 37 times and the follow-up didn&#x27;t do it. That sounds easy to verify.<p>Likewise the importance of spending 20x as much money on the training portion seems easy to verify, and significant.<p>That they would fail to properly test against industry standard workbenches seems reasonable to me. This is a bunch of ML specialists who know nothing about chip design. Their background is beating everyone at Go and setting a new state of the art for protein folding, and not chip design. If you dismiss those particular past accomplishments as hyperbolic marketing, that&#x27;s your decision. But you aren&#x27;t going to find a lot of people in these parts who agree with you.<p>If you think that those were real, but that a bunch of more recent accomplishments are BS, I haven&#x27;t been following closely enough to have an opinion. The stuff that crossed my radar since AlphaFold is mostly done at places like OpenAI, and not Google.<p>Regardless, the truth will out. And what Google is claiming for itself here really isn&#x27;t all that impressive.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42285454" class="c"><input type="checkbox" id="c-42285454" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#42285403">parent</a><span>|</span><a href="#42285469">prev</a><span>|</span><a href="#42285768">next</a><span>|</span><label class="collapse" for="c-42285454">[-]</label><label class="expand" for="c-42285454">[11 more]</label></div><br/><div class="children"><div class="content">&gt; they couldn&#x27;t replicate it because they&#x27;re idiots<p>If they did not follow the steps to replicate (pre-training, using less compute, etc.) and then failed, so what&#x27;s wrong with calling out the flaws in their attempted &quot;replication&quot;?</div><br/><div id="42285496" class="c"><input type="checkbox" id="c-42285496" checked=""/><div class="controls bullet"><span class="by">twothreeone</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285454">parent</a><span>|</span><a href="#42285768">next</a><span>|</span><label class="collapse" for="c-42285496">[-]</label><label class="expand" for="c-42285496">[10 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not a value judgement, just doesn&#x27;t help his case at all. He&#x27;d need to counter the  replication problem, but apparently that&#x27;s not an option. Instead, he&#x27;s making people who were unable to replicate it look bad, which actually strengthens their criticism.</div><br/><div id="42285543" class="c"><input type="checkbox" id="c-42285543" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285496">parent</a><span>|</span><a href="#42285552">next</a><span>|</span><label class="collapse" for="c-42285543">[-]</label><label class="expand" for="c-42285543">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know how you rebut a flawed paper without making its authors look bad? That would be a general-purpose argument against criticizing papers.<p>Actually, people <i>should</i> criticize flawed papers. That&#x27;s how science works! When you publish scientific papers, you should expect criticism if there&#x27;s something that doesn&#x27;t look right.<p>The only way to avoid that is to get critical feedback <i>before</i> publishing the paper, and it&#x27;s not always possible, so then the scientific debate happens in public.</div><br/><div id="42285614" class="c"><input type="checkbox" id="c-42285614" checked=""/><div class="controls bullet"><span class="by">twothreeone</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285543">parent</a><span>|</span><a href="#42285552">next</a><span>|</span><label class="collapse" for="c-42285614">[-]</label><label class="expand" for="c-42285614">[2 more]</label></div><br/><div class="children"><div class="content">The situation here is different though.. If I&#x27;m making an existence claim by demonstrating a constructive argument and then being criticized for it, the most effective response to that critique would be a second, alternative construction, not attacking the critic&#x27;s argument. After all, I&#x27;m the one claiming existence.. the burden of proof is on me, not my critics.</div><br/><div id="42285704" class="c"><input type="checkbox" id="c-42285704" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285614">parent</a><span>|</span><a href="#42285552">next</a><span>|</span><label class="collapse" for="c-42285704">[-]</label><label class="expand" for="c-42285704">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know which argument is more constructive, though? Both teams reported what they did. They got different results. Figuring out why is the next step, and pointing out that they did different things seems useful.<p>Though, the broader question is how useful the results of the original paper are to other people who might do the same thing.</div><br/></div></div></div></div></div></div><div id="42285552" class="c"><input type="checkbox" id="c-42285552" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285496">parent</a><span>|</span><a href="#42285543">prev</a><span>|</span><a href="#42285990">next</a><span>|</span><label class="collapse" for="c-42285552">[-]</label><label class="expand" for="c-42285552">[5 more]</label></div><br/><div class="children"><div class="content">&gt; But saying &quot;they couldn&#x27;t replicate it because they&#x27;re idiots, therefore it&#x27;s replicable&quot; is not a rebuttal, just bullying.<p>&gt; It&#x27;s not a value judgement, just doesn&#x27;t help his case at all.<p>Calling it &quot;bullying&quot; looks like a value judgment to me. Am I missing something?<p>To me, Dean&#x27;s response is quite sensible, particularly given his claims the other papers made serious mistakes and have potential conflicts of interest.</div><br/><div id="42285653" class="c"><input type="checkbox" id="c-42285653" checked=""/><div class="controls bullet"><span class="by">twothreeone</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285552">parent</a><span>|</span><a href="#42285990">next</a><span>|</span><label class="collapse" for="c-42285653">[-]</label><label class="expand" for="c-42285653">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not saying &quot;Bullying is bad and bullies are bad people&quot;, that would be a value judgement. I&#x27;m saying bullying is the strictly worse strategy for strengthening his paper&#x27;s claims in this scenario. The better strategy would be to foster an environment in which people can easily replicate your claims.</div><br/><div id="42285715" class="c"><input type="checkbox" id="c-42285715" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285653">parent</a><span>|</span><a href="#42285765">next</a><span>|</span><label class="collapse" for="c-42285715">[-]</label><label class="expand" for="c-42285715">[1 more]</label></div><br/><div class="children"><div class="content">I think for most people the word “bullying” has a value judgment built-in.</div><br/></div></div><div id="42285765" class="c"><input type="checkbox" id="c-42285765" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285653">parent</a><span>|</span><a href="#42285715">prev</a><span>|</span><a href="#42285742">next</a><span>|</span><label class="collapse" for="c-42285765">[-]</label><label class="expand" for="c-42285765">[1 more]</label></div><br/><div class="children"><div class="content">Are you suggesting Dean take a different approach in his response? Are you saying it was already too late given the environment? (I’m also not sure I know what you mean by environment here.)</div><br/></div></div><div id="42285742" class="c"><input type="checkbox" id="c-42285742" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285653">parent</a><span>|</span><a href="#42285765">prev</a><span>|</span><a href="#42285990">next</a><span>|</span><label class="collapse" for="c-42285742">[-]</label><label class="expand" for="c-42285742">[1 more]</label></div><br/><div class="children"><div class="content">In a perfect world, making a paper easier to replicate has advantages, sure. (But it also has costs.)<p>Second, even a healthy environment can be undermined by lack of skills or resources, intellectual dishonesty, or conflicts of interest.</div><br/></div></div></div></div></div></div><div id="42285990" class="c"><input type="checkbox" id="c-42285990" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285496">parent</a><span>|</span><a href="#42285552">prev</a><span>|</span><a href="#42285768">next</a><span>|</span><label class="collapse" for="c-42285990">[-]</label><label class="expand" for="c-42285990">[1 more]</label></div><br/><div class="children"><div class="content">they have open source code.</div><br/></div></div></div></div></div></div><div id="42285768" class="c"><input type="checkbox" id="c-42285768" checked=""/><div class="controls bullet"><span class="by">johnfn</span><span>|</span><a href="#42285403">parent</a><span>|</span><a href="#42285454">prev</a><span>|</span><a href="#42285482">next</a><span>|</span><label class="collapse" for="c-42285768">[-]</label><label class="expand" for="c-42285768">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;they couldn&#x27;t replicate it because they&#x27;re idiots, therefore it&#x27;s replicable&quot;<p>Where does it say that? Dean outlines explicit steps that the authors missed in the tweet.</div><br/></div></div><div id="42285482" class="c"><input type="checkbox" id="c-42285482" checked=""/><div class="controls bullet"><span class="by">jsnell</span><span>|</span><a href="#42285403">parent</a><span>|</span><a href="#42285768">prev</a><span>|</span><a href="#42286212">next</a><span>|</span><label class="collapse" for="c-42285482">[-]</label><label class="expand" for="c-42285482">[7 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a good thing that he didn&#x27;t say that, then.<p>The tweet just says that the reproduction attempt didn&#x27;t didn&#x27;t actually follow the original methodology. There is no claim that the authors of the replication attempt were &quot;idiots&quot; or anything similar, you just made that up. The obviously fallacious logic in &quot;they couldn&#x27;t replicate it ..., therefore it&#x27;s replicable&quot; is also a total fabrication on your part.</div><br/><div id="42285577" class="c"><input type="checkbox" id="c-42285577" checked=""/><div class="controls bullet"><span class="by">twothreeone</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285482">parent</a><span>|</span><a href="#42286212">next</a><span>|</span><label class="collapse" for="c-42285577">[-]</label><label class="expand" for="c-42285577">[6 more]</label></div><br/><div class="children"><div class="content">A Google Nature Paper has not been replicated for over 3 years, but I&#x27;m the one fabricating stuff :D<p>Making a novel claim implies its *_claimed_ replicability.<p>&quot;You did not follow the steps&quot; is calling them idiots.<p>The only inference I made is that he&#x27;s pressed to comment. He could have said nothing.. instead he&#x27;s lashing out publicly, because other people were unable to replicate it. If there&#x27;s no problem replicating the work, why hasn&#x27;t that happend? Any other author would be worried if a publication about their work were saying &quot;it&#x27;s not replicable&quot; and trying their best to help replicate it.. but somehow that doesn&#x27;t apply to him.</div><br/><div id="42285638" class="c"><input type="checkbox" id="c-42285638" checked=""/><div class="controls bullet"><span class="by">griomnib</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285577">parent</a><span>|</span><a href="#42286212">next</a><span>|</span><label class="collapse" for="c-42285638">[-]</label><label class="expand" for="c-42285638">[5 more]</label></div><br/><div class="children"><div class="content">“You can only validate my results if you have an entire Google data center worth of compute available. Since you don’t, you can’t question us.”</div><br/><div id="42285685" class="c"><input type="checkbox" id="c-42285685" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285638">parent</a><span>|</span><a href="#42286212">next</a><span>|</span><label class="collapse" for="c-42285685">[-]</label><label class="expand" for="c-42285685">[4 more]</label></div><br/><div class="children"><div class="content">We&#x27;re actually talking about the difference between Cheng using 8 GPUs and 2 CPUs while Google used 16 GPUs and 40 CPUs. These are under-your-desk levels of resources. Cheng et al authors are all affiliated with UCSD which owns the Expanse supercomputer which is orders of magnitude larger than what you would need to reproduce the original work. Cheng et al does not explain why they used fewer resources.</div><br/><div id="42285696" class="c"><input type="checkbox" id="c-42285696" checked=""/><div class="controls bullet"><span class="by">griomnib</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285685">parent</a><span>|</span><a href="#42286212">next</a><span>|</span><label class="collapse" for="c-42285696">[-]</label><label class="expand" for="c-42285696">[3 more]</label></div><br/><div class="children"><div class="content">That’s a fair complaint then.</div><br/><div id="42286299" class="c"><input type="checkbox" id="c-42286299" checked=""/><div class="controls bullet"><span class="by">phonon</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285696">parent</a><span>|</span><a href="#42286212">next</a><span>|</span><label class="collapse" for="c-42286299">[-]</label><label class="expand" for="c-42286299">[2 more]</label></div><br/><div class="children"><div class="content">No it&#x27;s not. They ran it longer instead.</div><br/><div id="42286900" class="c"><input type="checkbox" id="c-42286900" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42286299">parent</a><span>|</span><a href="#42286212">next</a><span>|</span><label class="collapse" for="c-42286900">[-]</label><label class="expand" for="c-42286900">[1 more]</label></div><br/><div class="children"><div class="content">The 2022 paper pretty explicitly says that runtime is not a substitute. They say their best result &quot;can only be achieved in our 8-GPU setup&quot;.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="42286212" class="c"><input type="checkbox" id="c-42286212" checked=""/><div class="controls bullet"><span class="by">MicolashKyoka</span><span>|</span><a href="#42285403">parent</a><span>|</span><a href="#42285482">prev</a><span>|</span><a href="#42285569">next</a><span>|</span><label class="collapse" for="c-42286212">[-]</label><label class="expand" for="c-42286212">[1 more]</label></div><br/><div class="children"><div class="content">if they are idiots and couldn&#x27;t replicate it, it&#x27;s worth saying it. better that than sugarcoating idiocy until it harms future research.</div><br/></div></div><div id="42285569" class="c"><input type="checkbox" id="c-42285569" checked=""/><div class="controls bullet"><span class="by">make3</span><span>|</span><a href="#42285403">parent</a><span>|</span><a href="#42286212">prev</a><span>|</span><a href="#42285773">next</a><span>|</span><label class="collapse" for="c-42285569">[-]</label><label class="expand" for="c-42285569">[1 more]</label></div><br/><div class="children"><div class="content">&quot;they couldn&#x27;t replicate it because they&#x27;re idiots, therefore it&#x27;s replicable&quot;
That&#x27;s literally not what he says though. He says, &quot;they didn&#x27;t replicate it so their conclusions are invalid&quot;, which is a completely different thing than what you&#x27;re accusing him of, and is valid.</div><br/></div></div><div id="42285773" class="c"><input type="checkbox" id="c-42285773" checked=""/><div class="controls bullet"><span class="by">iamnotafraid</span><span>|</span><a href="#42285403">parent</a><span>|</span><a href="#42285569">prev</a><span>|</span><a href="#42285628">next</a><span>|</span><label class="collapse" for="c-42285773">[-]</label><label class="expand" for="c-42285773">[1 more]</label></div><br/><div class="children"><div class="content">Interesting point, I give u this</div><br/></div></div><div id="42285628" class="c"><input type="checkbox" id="c-42285628" checked=""/><div class="controls bullet"><span class="by">griomnib</span><span>|</span><a href="#42285403">parent</a><span>|</span><a href="#42285773">prev</a><span>|</span><label class="collapse" for="c-42285628">[-]</label><label class="expand" for="c-42285628">[3 more]</label></div><br/><div class="children"><div class="content">I love how he’s claiming bias due to his critic’s employer. As though working for <i>Google</i> has no conflicts?  A company that is desperately hyping each and every “me too” AI development to juice the stock price?<p>Jeff drank so much kool aid he forget what water is.</div><br/><div id="42285645" class="c"><input type="checkbox" id="c-42285645" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285628">parent</a><span>|</span><label class="collapse" for="c-42285645">[-]</label><label class="expand" for="c-42285645">[2 more]</label></div><br/><div class="children"><div class="content">He&#x27;s criticizing Markov for not disclosing the conflict, not for the conflict itself. Hiding your affiliation in a scientific publication is far outside the norms of science, and they should be criticized for that. The publication we are discussing — &quot;That Chip Has Sailed&quot; — dismisses Markov in a few paragraph and spends the bulk its arguments on Cheng.</div><br/><div id="42285655" class="c"><input type="checkbox" id="c-42285655" checked=""/><div class="controls bullet"><span class="by">griomnib</span><span>|</span><a href="#42285403">root</a><span>|</span><a href="#42285645">parent</a><span>|</span><label class="collapse" for="c-42285655">[-]</label><label class="expand" for="c-42285655">[1 more]</label></div><br/><div class="children"><div class="content">I know the norms of science, I also know norms of present day Google.  Nobody from Google should have the gall to accuse others of anything.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>