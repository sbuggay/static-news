<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1702026058725" as="style"/><link rel="stylesheet" href="styles.css?v=1702026058725"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://tomhazledine.com/llm-related-posts/">Show HN: My related-posts finder script (with LLM and GPT4 enhancement)</a>Â <span class="domain">(<a href="https://tomhazledine.com">tomhazledine.com</a>)</span></div><div class="subtext"><span>tomhazledine</span> | <span>5 comments</span></div><br/><div><div id="38566537" class="c"><input type="checkbox" id="c-38566537" checked=""/><div class="controls bullet"><span class="by">pabe</span><span>|</span><a href="#38563881">next</a><span>|</span><label class="collapse" for="c-38566537">[-]</label><label class="expand" for="c-38566537">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for contributing your work as OSS and writing a comprehensive blog post about it :)<p>I like the simplicity of your approach without vector DB etc. In case you want to add one, Typesense seems to be a good OSS fit.</div><br/></div></div><div id="38563881" class="c"><input type="checkbox" id="c-38563881" checked=""/><div class="controls bullet"><span class="by">TOMDM</span><span>|</span><a href="#38566537">prev</a><span>|</span><label class="collapse" for="c-38563881">[-]</label><label class="expand" for="c-38563881">[3 more]</label></div><br/><div class="children"><div class="content">Really neat, thank you for posting!<p>How did you end up handling the case where posts are longer than the context window for the embedding API?</div><br/><div id="38565405" class="c"><input type="checkbox" id="c-38565405" checked=""/><div class="controls bullet"><span class="by">seanhunter</span><span>|</span><a href="#38563881">parent</a><span>|</span><a href="#38564671">next</a><span>|</span><label class="collapse" for="c-38565405">[-]</label><label class="expand" for="c-38565405">[1 more]</label></div><br/><div class="children"><div class="content">This comment is similar to the comment I wanted to make because I also thought it was pretty nifty.<p>Joking aside this is pretty cool.  One thing about the whole embeddings&#x2F;cosine similarity thing for people who are struggling with understanding it.<p>Computers are good at doing lots of sums. Embeddings turn a problem that seems to be about something else[1] into a problem involving lots of sums by turning that something else into numbers.<p>So when we turn some text into embeddings (numbers), what do those numbers mean? You could imagine a space with a lot of dimensions - the author is using openai embeddings so it&#x27;s like a thousand dimensions or something - and every point in that space is some embedding, which is actually a numerical representation of the meaning of some text.[2] So things with similar meaning have embeddings which are close to one another in this space. How do you decide what &quot;close&quot; is?<p>Well one easy way is cosine similarity.  Since these are vectors imagine two arrows coming from the origin. To make things simpler imagine it in the two-dimensional plane rather than 1000 dimensions which owuld make your brain leak out of your ears.  So you have two arrows going from the origin to some two points.  What you want is the length of the line from the tip of one arrow to the tip of the other arrow. For people who struggle to remember their trig, this distance is given by c^2 = a^2 + b^2 - 2ab cos theta.  It just so happens that if you take the dot product of two vectors and divide by the product of their norms you get the cosine of the angle between them (cos theta). That&#x27;s why it&#x27;s called cosine similarity even though you don&#x27;t see a cosine in the formula.[3]<p>[1] language usually in the case of LLMs, but embeddings aren&#x27;t only about text.<p>[2] this is why searching embeddings is called semantic search.<p>[3] The term cosine distance is often used loosely for this although I believe it&#x27;s actually technically not a distance because it doesn&#x27;t obey certain properties that are necessary for something to be a distance.</div><br/></div></div><div id="38564671" class="c"><input type="checkbox" id="c-38564671" checked=""/><div class="controls bullet"><span class="by">thomasfromcdnjs</span><span>|</span><a href="#38563881">parent</a><span>|</span><a href="#38565405">prev</a><span>|</span><label class="collapse" for="c-38564671">[-]</label><label class="expand" for="c-38564671">[1 more]</label></div><br/><div class="children"><div class="content">Piggy backing this comment to simply also express how cool of an idea it is.</div><br/></div></div></div></div></div></div></div></div></div></body></html>