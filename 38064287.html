<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1698656467606" as="style"/><link rel="stylesheet" href="styles.css?v=1698656467606"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.nature.com/articles/s41583-023-00756-z">How deep is the brain? The shallow brain hypothesis</a> <span class="domain">(<a href="https://www.nature.com">www.nature.com</a>)</span></div><div class="subtext"><span>vapemaster</span> | <span>89 comments</span></div><br/><div><div id="38064742" class="c"><input type="checkbox" id="c-38064742" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#38066660">next</a><span>|</span><label class="collapse" for="c-38064742">[-]</label><label class="expand" for="c-38064742">[53 more]</label></div><br/><div class="children"><div class="content">If I had a nickel for every time some neurologist tried to compare brains to neural networks. It&#x27;s a surefire way to tell someone is either desperate for grant money or has been smoking crack. (previously: comparing brains and &quot;electronic computers&quot;)<p>Their entire article hinges on the complaint &quot;brain seems shallow and neural networks are deep, ergo neural networks are doing it wrong.&quot;<p>Neurologists seem to have a really hard time comprehending that researchers working on neural networks aren&#x27;t as clueless about computers as neurology is about the brain. They also <i>vastly</i> overestimate how much engineers working on neural networks even care about how biological brains work.<p>Virtually every attempt at making neural networks mimic biological neurons has been a miserable failure. Neural networks, despite their name, don&#x27;t work anything like biological neurons and their development is guided by a combination of<p>A) practical experimentation and refinement, and<p>B) real, actual understanding about how they work.<p>The concept of resnets didn&#x27;t come from biology. It came from observations about the flow of gradients between nodes in the computational graph. The concept of CNNs didn&#x27;t come from biology, it came from old knowledge of convolutional filters. The current form and function of neural networks is grounded in repeated practical experimentation, not an attempt to mimic the slabs of meat that we place on pedestals. Neural networks are deep because it turns out hierarchical feature detectors work really well, and it doesn&#x27;t really matter if the brain doesn&#x27;t do things that way.<p>And then you have the nitwits searching the brain for transformer networks. Might as well look for mercury delay line memory while you&#x27;re at it. Quantum entanglement too.</div><br/><div id="38064876" class="c"><input type="checkbox" id="c-38064876" checked=""/><div class="controls bullet"><span class="by">robbrown451</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064935">next</a><span>|</span><label class="collapse" for="c-38064876">[-]</label><label class="expand" for="c-38064876">[20 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t agree with the dismissiveness of this comment, and frankly I find its tone out of line and not with the spirit of Hacker News.<p>There are insights that can come from studying the brain, that do indeed apply. Some researchers may not glean anything from such studies, and some may. I have no doubt that as neural networks get more an more powerful, we will continue to find more ways they are similar to the brain, and apply things we&#x27;ve learned about the brain to them.<p>I certainly prefer to see people making comparisons of neural networks to the brain, that the old &quot;it&#x27;s just a glorified autocomplete&quot; and the like.<p>Relax.</div><br/><div id="38065546" class="c"><input type="checkbox" id="c-38065546" checked=""/><div class="controls bullet"><span class="by">ramraj07</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064876">parent</a><span>|</span><a href="#38065366">next</a><span>|</span><label class="collapse" for="c-38065546">[-]</label><label class="expand" for="c-38065546">[6 more]</label></div><br/><div class="children"><div class="content">No one disagrees we might be able to discern insights if we understand how our brain is wired. The problem is the current state of neuroscience is so flawed in its approach it’s not looking like they’re of any use. They don’t even understand how a 900 neuron worms system works but are more than happy to tap half a billion dollars from unsuspecting politicians saying they’ll map the human connectome. Go read the brain initiative proposal [1] to see how out of touch with reality the scientists in this field are. I agree with OP that sharp criticism of the entire field is fully warranted.<p>1. <a href="https:&#x2F;&#x2F;braininitiative.nih.gov&#x2F;sites&#x2F;default&#x2F;files&#x2F;documents&#x2F;brain_2.0_06062019-final_rev_10302019_508c.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;braininitiative.nih.gov&#x2F;sites&#x2F;default&#x2F;files&#x2F;document...</a></div><br/><div id="38065706" class="c"><input type="checkbox" id="c-38065706" checked=""/><div class="controls bullet"><span class="by">andbberger</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065546">parent</a><span>|</span><a href="#38065366">next</a><span>|</span><label class="collapse" for="c-38065706">[-]</label><label class="expand" for="c-38065706">[5 more]</label></div><br/><div class="children"><div class="content">what are you talking about is this konrad kording&#x27;s shitposting alt??? this reeks of naivety<p>I certainly have many critiques of methods used in neuroscience rn (as a working neuroscientist) but to reduce those to the conclusion that the entire project of neuroscience is hopeless is absurd. We understand certain things quite well actually, and it&#x27;s not at all obvious what &quot;understanding&quot; at a larger scale would look like. It is very possible that the brain is irreducibly complex, and that the model you would need to construct to describe it would itself be so complex as to be useless in providing insight. Considering that the brain is by far the most complex object in the universe I think we&#x27;re doing pretty well.<p>Furthermore, there are quite a lot of disagreements about the utility of connectomics. Outside of the extremists (Sebastian Seung and his ilk) no one thinks that connectomics is going to be the key that brings earth shattering insight. It&#x27;s just another tool. There is a complete connectome for part of the drosophila brain already (privately funded btw),  which is in daily use in many fly labs. It tells you what other neurons are connected to. Incredibly useful. Not earth shattering.<p>also you might want to measure the neuroscience funding you deem wasteful up against the tens of billions NASA is spending to send humans (and not robots) back to the moon for &quot;the spirit of adventure&quot;. cold war&#x27;s over. robots will do just fine for the moon.</div><br/><div id="38066057" class="c"><input type="checkbox" id="c-38066057" checked=""/><div class="controls bullet"><span class="by">ramraj07</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065706">parent</a><span>|</span><a href="#38065946">next</a><span>|</span><label class="collapse" for="c-38066057">[-]</label><label class="expand" for="c-38066057">[2 more]</label></div><br/><div class="children"><div class="content">Can you please elaborate what great strides the field of neuroscience has made in the past 30 years?<p>From where I stand I can’t see anyone giving a clear explanation of anything our brain does or does not do in a disease. The only novel treatment that has come out seems to have been stick a rod into the brain and zap it and it just magically cures a lot of diseases we still don’t understand even a bit.<p>This is not even starting to discuss what little we have learned about how brains algorithms work. I’m still waiting to understand why pyramidal neurons were somehow groundbreaking. We found some neuron that fires when you walk to a place, why wouldn’t we find one?<p>And what are you saying about the fly connectome again? Do we have exact names for every neuron in the fly brain and its verified connectome for every neuron?<p>Last I checked the worm connectome has been available in intricate detail for decades and the scientists still haven’t had any proper decoding of the algorithms in that system. In fact I know every lab trying to figure that out now, I wrote proposals in the topic myself. Everyone else has apparently decided it’s not sexy enough to work with worms so they have just leaped to more complex systems with no basic understanding. I’m not the only one saying this. Sydney Brenner said as much in an editorial. But the field was too busy doing I don’t know what to listen.<p>Sydney, B. &amp; Sejnowski, T. J. Understanding the human brain. Science 334, 567 (2011).<p>I remember sauntering to the occasional neuroscience talk during my ut southwestern PhD and occasionally hearing some professor brag about how the majority of one of their PhD’s jobs was to segmenting a single neuron in the thousand EM images or something. Surely that’s a sign this field needs revision?</div><br/><div id="38066227" class="c"><input type="checkbox" id="c-38066227" checked=""/><div class="controls bullet"><span class="by">andbberger</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38066057">parent</a><span>|</span><a href="#38065946">next</a><span>|</span><label class="collapse" for="c-38066227">[-]</label><label class="expand" for="c-38066227">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And what are you saying about the fly connectome again? Do we have exact names for every neuron in the fly brain and its verified connectome for every neuron?<p>onus isn&#x27;t on me to justify the existence of an entire field to you. the claim that neuroscience has not made great strides in the last 30 years is an extraordinary one, and that&#x27;s all on you. but it especially doesn&#x27;t help your case that if you had googled &quot;fly connectome &quot; you would have seen that the first result is a complete connectome of a larvae and the third result is the tour de force from Janelia that produced an adult connectome. With names and verified connections. there is even a wikipedia article for the drosophila connectome!<p>&gt; I remember sauntering to the occasional neuroscience talk during my ut southwestern PhD and occasionally hearing some professor brag about how the majority of one of their PhD’s jobs was to segmenting a single neuron in the thousand EM images or something. Surely that’s a sign this field needs revision?<p>and if you had gone on to actually read the hemibrain connectome paper you would have gained some appreciation for the gargantuan achievement that it was. it took hundreds of person years to generate ground truth segmenting neurons by hand, to develop the ML techniques required to automatically segment the rest (extremely difficult problem) and to then validate the automatic segmentations. not to mention the insane effort it was to acquire a half petabyte EM image of a single fly at sub-synaptic resolution in the first place.<p>I gotta hand it to you though, the position of naivety you&#x27;ve delivered your middlebrow dismissal from is truly impressive in magnitude.</div><br/></div></div></div></div><div id="38065946" class="c"><input type="checkbox" id="c-38065946" checked=""/><div class="controls bullet"><span class="by">civilitty</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065706">parent</a><span>|</span><a href="#38066057">prev</a><span>|</span><a href="#38065827">next</a><span>|</span><label class="collapse" for="c-38065946">[-]</label><label class="expand" for="c-38065946">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. Reading the GP’s comment it feels like it’s from bizzaro world. It’s the computer scientists who have been claiming that neural networks resemble the human brain - they even fucking named them <i>neural</i> networks for christ’s sake! That could be excused as naive hubris in the 1980s, it’s utter delusion now.<p>A surface review of neuroplasticity literature alone should free anyone of the illusion that “neural networks” have even a passing resemblance to biological neurons, something covered in neuroscience 101 and is widely internalized by its practitioners. The BS grant writing and PR scientists have to participate in is hardly reflect of state of the art science itself.<p>The irony is that machine learning methods are a perfect fit for neuroscience and biology in general which generates reams of data that is largely so multidimensional that manual analysis is intractable. What we’re seeing now is the crest of the academic hype cycle which - if the history of bioinformatics is anything to go by - means that ML will take years if not decades for the field to understand and filly utilize.</div><br/></div></div><div id="38065827" class="c"><input type="checkbox" id="c-38065827" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065706">parent</a><span>|</span><a href="#38065946">prev</a><span>|</span><a href="#38065366">next</a><span>|</span><label class="collapse" for="c-38065827">[-]</label><label class="expand" for="c-38065827">[1 more]</label></div><br/><div class="children"><div class="content">As another working neuroscientist, thank you. And cheers.</div><br/></div></div></div></div></div></div><div id="38065366" class="c"><input type="checkbox" id="c-38065366" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064876">parent</a><span>|</span><a href="#38065546">prev</a><span>|</span><a href="#38065176">next</a><span>|</span><label class="collapse" for="c-38065366">[-]</label><label class="expand" for="c-38065366">[10 more]</label></div><br/><div class="children"><div class="content">No I think these comments are quite necessary.  People need to stop making these comparisons because they have absolutely no grounding in how brains actually work. There are bad ideas that should be dismissed.</div><br/><div id="38065551" class="c"><input type="checkbox" id="c-38065551" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065366">parent</a><span>|</span><a href="#38065550">next</a><span>|</span><label class="collapse" for="c-38065551">[-]</label><label class="expand" for="c-38065551">[5 more]</label></div><br/><div class="children"><div class="content">Neural networks are absolutely based on a very simplified model of how brains work. Specific NN architectures are in turn based on specific parts of the brain (e.g. Convolution Neural Networks are based on the visual cortices of cats&#x2F;frogs).</div><br/><div id="38065748" class="c"><input type="checkbox" id="c-38065748" checked=""/><div class="controls bullet"><span class="by">andbberger</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065551">parent</a><span>|</span><a href="#38065550">next</a><span>|</span><label class="collapse" for="c-38065748">[-]</label><label class="expand" for="c-38065748">[4 more]</label></div><br/><div class="children"><div class="content">nah, they&#x27;re arbitrary function approximators that caught a lucky break. CNNs rose to prominence because natural scene statistics are translation invariant and convolutions can be efficiently computed on GPUs. and now that we have whole warehouses of GPUs, the current mood in DL is to stop building the symmetries of your dataset into the model (which is insane btw) and use brute force.<p>the tenuous connection DL once had to neuroscience (perceptrons) is a distant memory</div><br/><div id="38065823" class="c"><input type="checkbox" id="c-38065823" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065748">parent</a><span>|</span><a href="#38065550">next</a><span>|</span><label class="collapse" for="c-38065823">[-]</label><label class="expand" for="c-38065823">[3 more]</label></div><br/><div class="children"><div class="content">A fabricated re-telling of the past, given that we didn&#x27;t start using GPUs for this type of compute until the turn of the millenium.</div><br/><div id="38065863" class="c"><input type="checkbox" id="c-38065863" checked=""/><div class="controls bullet"><span class="by">andbberger</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065823">parent</a><span>|</span><a href="#38065550">next</a><span>|</span><label class="collapse" for="c-38065863">[-]</label><label class="expand" for="c-38065863">[2 more]</label></div><br/><div class="children"><div class="content">AlexNet was the turning point for DL.</div><br/><div id="38066067" class="c"><input type="checkbox" id="c-38066067" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065863">parent</a><span>|</span><a href="#38065550">next</a><span>|</span><label class="collapse" for="c-38066067">[-]</label><label class="expand" for="c-38066067">[1 more]</label></div><br/><div class="children"><div class="content">Why do you say that? Deep Learning was accelerating well before that (I would argue it has been accelerating for its entire existence).<p>AlexNet was a state-of-the-art image recognition net for a (relatively) brief amount of time. It wasn&#x27;t the first CNN to use GPU acceleration, and it was quickly eclipsed in terms of ImageNet performance.<p>Regardless, I think bringing up AlexNet kinda invalidates your initial point. Although yes, it turns out that the two were  a great match, CNNs and modern GPUs were clearly developed independently of each other, as evidenced by the many, many iterations of both before they were combined.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38065550" class="c"><input type="checkbox" id="c-38065550" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065366">parent</a><span>|</span><a href="#38065551">prev</a><span>|</span><a href="#38065426">next</a><span>|</span><label class="collapse" for="c-38065550">[-]</label><label class="expand" for="c-38065550">[3 more]</label></div><br/><div class="children"><div class="content">Artificial neural networks are the closest working model of a brain we have today.<p>Lots of graph nodes, with weighted connections,  performing distributed computation (mainly hierarchical pattern matching), learning from data by gradually updating weights, using selective attention (and&#x2F;or recurrence, and&#x2F;or convolutional filters).<p>Which of the above is not happening in our brains? Which of the above is not biologically inspired?<p>In fact this description equally applies to both a brain and GPT4.</div><br/><div id="38065580" class="c"><input type="checkbox" id="c-38065580" checked=""/><div class="controls bullet"><span class="by">aeternum</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065550">parent</a><span>|</span><a href="#38065426">next</a><span>|</span><label class="collapse" for="c-38065580">[-]</label><label class="expand" for="c-38065580">[2 more]</label></div><br/><div class="children"><div class="content">Many organisms have just a handful of neurons yet exhibit complex behavior that would be impossible given the weighted connections model.  Not to mention single-celled organisms that exhibit ability to navigate.<p>The model can be the closest working model but that doesn&#x27;t mean it is complete.  It&#x27;s very likely that cells can store memories&#x2F;information independent from weights.</div><br/><div id="38065676" class="c"><input type="checkbox" id="c-38065676" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065580">parent</a><span>|</span><a href="#38065426">next</a><span>|</span><label class="collapse" for="c-38065676">[-]</label><label class="expand" for="c-38065676">[1 more]</label></div><br/><div class="children"><div class="content">We can’t do that not because our mathematical neurons are too simple. We can’t do that because we don’t know the algorithms those biological neurons are running.<p>Do you see the difference?</div><br/></div></div></div></div></div></div><div id="38065426" class="c"><input type="checkbox" id="c-38065426" checked=""/><div class="controls bullet"><span class="by">robbrown451</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065366">parent</a><span>|</span><a href="#38065550">prev</a><span>|</span><a href="#38065176">next</a><span>|</span><label class="collapse" for="c-38065426">[-]</label><label class="expand" for="c-38065426">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re saying the study has no grounding in how brains work? I&#x27;d think a more reasonable conclusion would be that the neuroscientists involved have no grounding in how artificial neural networks work.<p>It seems the whole point is to bring in additional details of how brains work, that the think may be relevant to artificial NNs.</div><br/></div></div></div></div><div id="38065176" class="c"><input type="checkbox" id="c-38065176" checked=""/><div class="controls bullet"><span class="by">krainboltgreene</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064876">parent</a><span>|</span><a href="#38065366">prev</a><span>|</span><a href="#38064935">next</a><span>|</span><label class="collapse" for="c-38065176">[-]</label><label class="expand" for="c-38065176">[3 more]</label></div><br/><div class="children"><div class="content">What does this comment add to the discussion?</div><br/><div id="38065249" class="c"><input type="checkbox" id="c-38065249" checked=""/><div class="controls bullet"><span class="by">robbrown451</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065176">parent</a><span>|</span><a href="#38064935">next</a><span>|</span><label class="collapse" for="c-38065249">[-]</label><label class="expand" for="c-38065249">[2 more]</label></div><br/><div class="children"><div class="content">I dunno. My comment complained about the parent comment not adding positively to the discussion. And gave at least a bit of support for that complaint.<p>Would you have preferred I emulate your style, and complain while providing no support for my complaint?<p>Ok.</div><br/><div id="38066360" class="c"><input type="checkbox" id="c-38066360" checked=""/><div class="controls bullet"><span class="by">krainboltgreene</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065249">parent</a><span>|</span><a href="#38064935">next</a><span>|</span><label class="collapse" for="c-38066360">[-]</label><label class="expand" for="c-38066360">[1 more]</label></div><br/><div class="children"><div class="content">Being positive is not a requirement of commenting on HN, but you should comment with something that is substantive, so yes I do think you shouldn&#x27;t have commented at all. Tone policing is cringe.</div><br/></div></div></div></div></div></div></div></div><div id="38064935" class="c"><input type="checkbox" id="c-38064935" checked=""/><div class="controls bullet"><span class="by">jacobsimon</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064876">prev</a><span>|</span><a href="#38064948">next</a><span>|</span><label class="collapse" for="c-38064935">[-]</label><label class="expand" for="c-38064935">[8 more]</label></div><br/><div class="children"><div class="content">This is a really weird take. There is such a long history of shared insights between biology and neural network research, and to say they’re unrelated or can’t take inspiration from one another is bizarre.<p>&gt; The concept of CNNs didn&#x27;t come from biology<p>I just opened a survey paper on CNNs and literally the first sentence of the paper reads:<p>&gt; “Convolutional Neural Network (CNN) is a well-known deep learning architecture inspired by the natural visual perception mechanism of the living creatures. In 1959, Hubel &amp; Wiesel [1] found that cells in animal visual cortex are responsible for detecting light in receptive fields. Inspired by this discovery…”<p>Source: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1512.07108.pdf%C3%A3%E2%82%AC%E2%80%9A" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1512.07108.pdf%C3%A3%E2%82%AC%E2%80%9A</a></div><br/><div id="38064983" class="c"><input type="checkbox" id="c-38064983" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064935">parent</a><span>|</span><a href="#38064948">next</a><span>|</span><label class="collapse" for="c-38064983">[-]</label><label class="expand" for="c-38064983">[7 more]</label></div><br/><div class="children"><div class="content">That&#x27;s later backfill, a retroactive change to give a manufactured &quot;biological&quot; origin story. Whether they&#x27;re real or not, researchers <i>love</i> a good &quot;we took this from nature, isn&#x27;t nature wonderful!&quot; explanation.<p>The C in CNN isn&#x27;t &quot;Convolution&quot; for no reason. It came from work with convolutional filters (yay Sobel kernels!) which at it&#x27;s height became filter banks and gabor filters and so on before neural networks pretty much killed off handcrafted feature development. Every explanation of how CNNs work still falls back to the original convolutional kernel intuition.</div><br/><div id="38066076" class="c"><input type="checkbox" id="c-38066076" checked=""/><div class="controls bullet"><span class="by">rerdavies</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064983">parent</a><span>|</span><a href="#38065130">next</a><span>|</span><label class="collapse" for="c-38066076">[-]</label><label class="expand" for="c-38066076">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The C in CNN isn&#x27;t &quot;Convolution&quot; for no reason.<p>The first N in CNN is &quot;Neural&quot; for a reason.</div><br/></div></div><div id="38065130" class="c"><input type="checkbox" id="c-38065130" checked=""/><div class="controls bullet"><span class="by">dartos</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064983">parent</a><span>|</span><a href="#38066076">prev</a><span>|</span><a href="#38064948">next</a><span>|</span><label class="collapse" for="c-38065130">[-]</label><label class="expand" for="c-38065130">[5 more]</label></div><br/><div class="children"><div class="content">You can use that argument for anything you disagree with.
Do you have a source or anything?</div><br/><div id="38065188" class="c"><input type="checkbox" id="c-38065188" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065130">parent</a><span>|</span><a href="#38064948">next</a><span>|</span><label class="collapse" for="c-38065188">[-]</label><label class="expand" for="c-38065188">[4 more]</label></div><br/><div class="children"><div class="content">Have a read through the first paper describing a convolutional neural network, from 1998: <a href="http:&#x2F;&#x2F;yann.lecun.com&#x2F;exdb&#x2F;publis&#x2F;pdf&#x2F;lecun-01a.pdf" rel="nofollow noreferrer">http:&#x2F;&#x2F;yann.lecun.com&#x2F;exdb&#x2F;publis&#x2F;pdf&#x2F;lecun-01a.pdf</a><p>There&#x27;s absolutely no mention of biological inspiration whatsoever. At the same time, one can point to a long and rich history of convolutional filters being used in signal processing. And then there&#x27;s the name, <i>Convolutional</i> Neural Network. The entire concept of a CNN is framed as a series of learned filters.</div><br/><div id="38065498" class="c"><input type="checkbox" id="c-38065498" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065188">parent</a><span>|</span><a href="#38065416">next</a><span>|</span><label class="collapse" for="c-38065498">[-]</label><label class="expand" for="c-38065498">[1 more]</label></div><br/><div class="children"><div class="content">That is definitely not the first paper describing a CNN. That is not even the first paper by Le Cun describing CNNs (he was already on them as early as 1989[1]).<p>Regardless, Le Cun is not the first to describe CNNs, merely one of the first to use them for OCR (specifically for hand-written text).<p>The first neural network arch to use convolutions instead of matmuls was this[2], from the year of our lord 1988. This in turn is based on Fukushima&#x27;s &quot;neocognitron&quot;[3] (1980), which is based on the visual cortex of felines (from work done by Hubel and Wiesel in the 50s&#x2F;60s).<p>I guess it is not super surprising you might be confused – Le Cun seems a bit more reticent than average to cite the work he&#x27;s building on top of, and when he does it is frequently in reference to his own prior work. So if that is where you&#x27;re getting your picture of artificial neural network history, your skewed perception makes sense.<p>[1] <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;abstract&#x2F;document&#x2F;41400" rel="nofollow noreferrer">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;abstract&#x2F;document&#x2F;41400</a><p>[2] <a href="https:&#x2F;&#x2F;proceedings.neurips.cc&#x2F;paper&#x2F;1987&#x2F;file&#x2F;98f13708210194c475687be6106a3b84-Paper.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;proceedings.neurips.cc&#x2F;paper&#x2F;1987&#x2F;file&#x2F;98f1370821019...</a><p>[3] <a href="https:&#x2F;&#x2F;www.cs.princeton.edu&#x2F;courses&#x2F;archive&#x2F;spr08&#x2F;cos598B&#x2F;Readings&#x2F;Fukushima1980.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.cs.princeton.edu&#x2F;courses&#x2F;archive&#x2F;spr08&#x2F;cos598B&#x2F;R...</a></div><br/></div></div><div id="38065416" class="c"><input type="checkbox" id="c-38065416" checked=""/><div class="controls bullet"><span class="by">jacobsimon</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065188">parent</a><span>|</span><a href="#38065498">prev</a><span>|</span><a href="#38065323">next</a><span>|</span><label class="collapse" for="c-38065416">[-]</label><label class="expand" for="c-38065416">[1 more]</label></div><br/><div class="children"><div class="content">Surely you are trolling me now. There is a very clear biological inspiration mentioned in this paper: they literally define a CNN as having “receptive fields” and then they cite the same Hubel &amp; Wiesel research mentioned before multiple times. LeCun mentions their research in papers even earlier in the 80s as well, during which they were awarded the Nobel prize for their research on the visual system. Of course there is also a lot of computational and mathematical research that was ongoing simultaneously, but to say that there is “no inspiration whatsoever” is pretty far from the truth.</div><br/></div></div><div id="38065323" class="c"><input type="checkbox" id="c-38065323" checked=""/><div class="controls bullet"><span class="by">readthenotes1</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065188">parent</a><span>|</span><a href="#38065416">prev</a><span>|</span><a href="#38064948">next</a><span>|</span><label class="collapse" for="c-38065323">[-]</label><label class="expand" for="c-38065323">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s funny. I had a book on &quot;neural nets&quot; in the 1980s, and it mentioned the analog to brain neurons.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38064948" class="c"><input type="checkbox" id="c-38064948" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064935">prev</a><span>|</span><a href="#38064974">next</a><span>|</span><label class="collapse" for="c-38064948">[-]</label><label class="expand" for="c-38064948">[1 more]</label></div><br/><div class="children"><div class="content">While I agree with this emotional post there is one nuance. Neural networks aren&#x27;t intelligent, brain is. And that&#x27;s where we want to be. Checking gradients and studying filters can get us only this far. So, using brain as inspiration looks like a good option. There are other, but nobody knows where next breakthrough will be. Like nobody knew five years back that transformers are so powerful. My guess next step to AGI will be a complex modular multi-modal system. With hierarchy, workers and controllers, complex signals.. Sound familiar? Brain is sort of it. This is need for embodied AI, obviously. But, interesting thing, it&#x27;s needed even for body-less AGI too. I.e. AGI is not a big calculator (!), it&#x27;s more like real-time system. One reason is that full search is impossible. So, in many cases requests will be like &#x27;give the best answer you can find in 4 seconds&#x27;. &#x27;and keep looking&#x27;. So far we have only real-time dumb robots and NN big calculators. And brains, of course.</div><br/></div></div><div id="38064974" class="c"><input type="checkbox" id="c-38064974" checked=""/><div class="controls bullet"><span class="by">dilawar</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064948">prev</a><span>|</span><a href="#38064900">next</a><span>|</span><label class="collapse" for="c-38064974">[-]</label><label class="expand" for="c-38064974">[2 more]</label></div><br/><div class="children"><div class="content">&gt; previously: comparing brains and &quot;electronic computers&quot;)<p>Before that: comparing brain with hydraulic machines. There has been tendency to compare brain with most complex machine known to us at that particular time.<p>&quot;Descartes was impressed by the hydraulic figures in the royal gardens, and developed a hydraulic theory of the action of the brain. We have since had telephone theories, electrical field theories, and now theories based on computing machines… . We are more likely to find out how the brain works by studying the brain itself, and the phenomenon of behavior, than by indulging in far-fetched physical analogies.&quot; -- Karl Lashley 1951</div><br/><div id="38065500" class="c"><input type="checkbox" id="c-38065500" checked=""/><div class="controls bullet"><span class="by">spindle</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064974">parent</a><span>|</span><a href="#38064900">next</a><span>|</span><label class="collapse" for="c-38065500">[-]</label><label class="expand" for="c-38065500">[1 more]</label></div><br/><div class="children"><div class="content">And also comparing brains to clockwork.</div><br/></div></div></div></div><div id="38064900" class="c"><input type="checkbox" id="c-38064900" checked=""/><div class="controls bullet"><span class="by">crustacean111</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064974">prev</a><span>|</span><a href="#38065633">next</a><span>|</span><label class="collapse" for="c-38064900">[-]</label><label class="expand" for="c-38064900">[5 more]</label></div><br/><div class="children"><div class="content">CNNs actually are biologically inspired. The receptive field in a CNN mimics the way that cortical neurons only respond to stimuli in a restricted region of the visual field. Different cortical neurons have receptive fields that partially overlap to cover the whole visual field [1].<p>[1] - <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Convolutional_neural_network" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Convolutional_neural_network</a></div><br/><div id="38064943" class="c"><input type="checkbox" id="c-38064943" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064900">parent</a><span>|</span><a href="#38065501">next</a><span>|</span><label class="collapse" for="c-38064943">[-]</label><label class="expand" for="c-38064943">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re going to have to dig deeper. The concept of a receptive field goes all the way back to convolutional filters.<p>It&#x27;s not surprising that we found out later the brain also uses such a fundamental element of signal theory.</div><br/><div id="38065338" class="c"><input type="checkbox" id="c-38065338" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064943">parent</a><span>|</span><a href="#38065501">next</a><span>|</span><label class="collapse" for="c-38065338">[-]</label><label class="expand" for="c-38065338">[1 more]</label></div><br/><div class="children"><div class="content">Oh good. So you do admit that there are useful parallels between signal processing, statistical processing, and the brain.</div><br/></div></div></div></div><div id="38065501" class="c"><input type="checkbox" id="c-38065501" checked=""/><div class="controls bullet"><span class="by">vkou</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38064900">parent</a><span>|</span><a href="#38064943">prev</a><span>|</span><a href="#38065633">next</a><span>|</span><label class="collapse" for="c-38065501">[-]</label><label class="expand" for="c-38065501">[2 more]</label></div><br/><div class="children"><div class="content">Sure, and airplanes are inspired by birds. That doesn&#x27;t mean that detailed studies of the Boeing 747 are going to unlock a lot of hitherto unknown mysteries of heron behaviour.</div><br/><div id="38066276" class="c"><input type="checkbox" id="c-38066276" checked=""/><div class="controls bullet"><span class="by">jacobsimon</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065501">parent</a><span>|</span><a href="#38065633">next</a><span>|</span><label class="collapse" for="c-38066276">[-]</label><label class="expand" for="c-38066276">[1 more]</label></div><br/><div class="children"><div class="content">I mean, I know you’re just providing an analogy, but people are still studying the physics of bird flight and we’re nowhere close to building machines yet that can maneuver the way birds can. <a href="https:&#x2F;&#x2F;www.quantamagazine.org&#x2F;geometric-analysis-reveals-how-birds-mastered-flight-20220803&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.quantamagazine.org&#x2F;geometric-analysis-reveals-ho...</a></div><br/></div></div></div></div></div></div><div id="38065633" class="c"><input type="checkbox" id="c-38065633" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064900">prev</a><span>|</span><a href="#38066580">next</a><span>|</span><label class="collapse" for="c-38065633">[-]</label><label class="expand" for="c-38065633">[1 more]</label></div><br/><div class="children"><div class="content">Dude. What holy and special work do you do? There&#x27;s nothing dumb or dull in searching for analogous structure between two effective machines, neither of which we understand.</div><br/></div></div><div id="38066580" class="c"><input type="checkbox" id="c-38066580" checked=""/><div class="controls bullet"><span class="by">radarsat1</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38065633">prev</a><span>|</span><a href="#38064880">next</a><span>|</span><label class="collapse" for="c-38066580">[-]</label><label class="expand" for="c-38066580">[1 more]</label></div><br/><div class="children"><div class="content">&gt; every time some neurologist tried to compare brains to neural networks<p>Value of this comment aside, it kind of makes me chuckle how casually it (and other comments in this thread) just drops the word &quot;artificial&quot; from neural networks here, specifically when comparing with neurology. The irony is funny. Like, somehow we&#x27;ve forgotten why we call them that in the first place, exactly when talking about the thing that inspired the approach.</div><br/></div></div><div id="38064880" class="c"><input type="checkbox" id="c-38064880" checked=""/><div class="controls bullet"><span class="by">mrstone</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38066580">prev</a><span>|</span><a href="#38065056">next</a><span>|</span><label class="collapse" for="c-38064880">[-]</label><label class="expand" for="c-38064880">[1 more]</label></div><br/><div class="children"><div class="content">A neurologist is a medical doctor. Neuroscientists are the PhDs who do the actual research.</div><br/></div></div><div id="38065056" class="c"><input type="checkbox" id="c-38065056" checked=""/><div class="controls bullet"><span class="by">wslh</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064880">prev</a><span>|</span><a href="#38065919">next</a><span>|</span><label class="collapse" for="c-38065056">[-]</label><label class="expand" for="c-38065056">[1 more]</label></div><br/><div class="children"><div class="content">Only an observer of the topic but I think it is good to review Koch&#x27;s book about the real complexity of a single neuron [1].<p>[1] <a href="https:&#x2F;&#x2F;www.amazon.com&#x2F;Biophysics-Computation-Information-Computational-Neuroscience&#x2F;dp&#x2F;0195181999&#x2F;ref=sr_1_1?keywords=Biophysics+of+Computation%3A+Information+Processing+in+Single+Neurons&amp;qid=1561229482&amp;s=books&amp;sr=1-1" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.amazon.com&#x2F;Biophysics-Computation-Information-Co...</a></div><br/></div></div><div id="38065919" class="c"><input type="checkbox" id="c-38065919" checked=""/><div class="controls bullet"><span class="by">hliyan</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38065056">prev</a><span>|</span><a href="#38064859">next</a><span>|</span><label class="collapse" for="c-38065919">[-]</label><label class="expand" for="c-38065919">[1 more]</label></div><br/><div class="children"><div class="content">&quot;brain seems shallow and neural networks are deep, ergo neural networks are doing it wrong&quot;<p>Please don&#x27;t claim things the author didn&#x27;t. What I read was &quot;ergo (artificial) neural networks may be missing a trick&quot;</div><br/></div></div><div id="38064825" class="c"><input type="checkbox" id="c-38064825" checked=""/><div class="controls bullet"><span class="by">b33j0r</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064859">prev</a><span>|</span><a href="#38065279">next</a><span>|</span><label class="collapse" for="c-38064825">[-]</label><label class="expand" for="c-38064825">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, but I do also think that order emerged from chaos. It’s an easy claim when order is defined by itself!<p>But in reality, we’re equipped exactly to exist, and we still wonder why in a backwards way, even with education (guilty!)<p>AI is the task of playing God like toddlers at recess, and LLMs the tower of babel. I still wanna play, it’s fun</div><br/></div></div><div id="38065279" class="c"><input type="checkbox" id="c-38065279" checked=""/><div class="controls bullet"><span class="by">bjourne</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064825">prev</a><span>|</span><a href="#38065372">next</a><span>|</span><label class="collapse" for="c-38065279">[-]</label><label class="expand" for="c-38065279">[2 more]</label></div><br/><div class="children"><div class="content">First, I wonder how you got access to the article? It is behind a
paywall and not yet uploaded to the sites I usually find paywalled
articles on.<p>Second, there is no need to <i>compare</i> brains to neural networks
because brains <i>are</i> neural networks. Neurons form vertices and axons
edges connecting the aforementioned. What you are perhaps thinking of
are <i>artificial</i> neural networks - most of which are very dissimilar
to brains. But even then you are wrong. Artificial Izhikevich and
Hodgkin-Huxley neural networks attempts to closely mimic the behavior
of real neurons.<p>While deep, hierarchical artificial neural networks have been more
successful than biologically plausible ones, that may be because the
technology isn&#x27;t ready yet. After all, the perceptron was invented in
the 1950&#x27;s but didn&#x27;t become prominent until the 2010&#x27;s (or
so). Perhaps we need new memories that better map to (real) neural
network topologies, or perhaps 3d chips that can pack transistors in
the same way brains pack neurons.</div><br/><div id="38066979" class="c"><input type="checkbox" id="c-38066979" checked=""/><div class="controls bullet"><span class="by">mjan22640</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065279">parent</a><span>|</span><a href="#38065372">next</a><span>|</span><label class="collapse" for="c-38066979">[-]</label><label class="expand" for="c-38066979">[1 more]</label></div><br/><div class="children"><div class="content">A neuron is analogous to a 3d integrated circuit rather to a transistor. A molecule acts like a transistor <a href="https:&#x2F;&#x2F;medium.com&#x2F;the-physics-arxiv-blog&#x2F;the-origin-of-life-and-the-hidden-role-of-quantum-criticality-ca4707924552" rel="nofollow noreferrer">https:&#x2F;&#x2F;medium.com&#x2F;the-physics-arxiv-blog&#x2F;the-origin-of-life...</a><p>Changes in mechanical pressure, electric field, other molecules attachment, photon absorption, can control the conductivity.<p>Organic semiconductors designed to fit like lego bricks to naturally build the desired structure are IMHO the way to go to produce 3d circuits, rather than layered silicone litography.</div><br/></div></div></div></div><div id="38065372" class="c"><input type="checkbox" id="c-38065372" checked=""/><div class="controls bullet"><span class="by">andromaton</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38065279">prev</a><span>|</span><a href="#38066049">next</a><span>|</span><label class="collapse" for="c-38065372">[-]</label><label class="expand" for="c-38065372">[1 more]</label></div><br/><div class="children"><div class="content">Books and articles I was reading in the 80s (eg Minsky and Papert, Byte magazine) were referring to Rosenblatt and retinas.</div><br/></div></div><div id="38064872" class="c"><input type="checkbox" id="c-38064872" checked=""/><div class="controls bullet"><span class="by">peyton</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38066049">prev</a><span>|</span><a href="#38066519">next</a><span>|</span><label class="collapse" for="c-38064872">[-]</label><label class="expand" for="c-38064872">[1 more]</label></div><br/><div class="children"><div class="content">I dunno, failure seems okay. Wouldn’t expect a better paradigm to beat SOTA at first. It’s totally plausible that neurons use eg. transposons in a way we don’t yet have the instrument resolution to characterize, which would suggest that you don’t need 1000 layers, but a lookup table or something.</div><br/></div></div><div id="38066519" class="c"><input type="checkbox" id="c-38066519" checked=""/><div class="controls bullet"><span class="by">nathias</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38064872">prev</a><span>|</span><a href="#38065277">next</a><span>|</span><label class="collapse" for="c-38066519">[-]</label><label class="expand" for="c-38066519">[1 more]</label></div><br/><div class="children"><div class="content">Metaphores and analogies are important tools of thinking, even in science, some bear fruits some lead to errors, but we can&#x27;t know in advance.</div><br/></div></div><div id="38065277" class="c"><input type="checkbox" id="c-38065277" checked=""/><div class="controls bullet"><span class="by">SubiculumCode</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38066519">prev</a><span>|</span><a href="#38065345">next</a><span>|</span><label class="collapse" for="c-38065277">[-]</label><label class="expand" for="c-38065277">[2 more]</label></div><br/><div class="children"><div class="content">If you read this article, I think most would understand that it is primarily aimed at other neuroscientists, and only using ML structures an an analogy only, and I think a somewhat useful one to boot. The real point of the article was to propose a general hierarchy for how information flows in the brain, to emphasize the importance of subcortical brain even in higher order cognition, and proposes how simultaneous processing of multiple levels of representation can inform action and thought.<p>As a developmental neuroscientist, I found the article insightful and thought provoking. Further, it is quite consistent with major hypotheses in psychology, how the hippocampus works (a subcortical structure) and combines information into memories: See fuzzy trace theory [1], for example.<p>Your dismissive tone is unappreciated, ill-informed, and crass.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fuzzy-trace_theory" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fuzzy-trace_theory</a></div><br/><div id="38065476" class="c"><input type="checkbox" id="c-38065476" checked=""/><div class="controls bullet"><span class="by">visitor4711</span><span>|</span><a href="#38064742">root</a><span>|</span><a href="#38065277">parent</a><span>|</span><a href="#38065345">next</a><span>|</span><label class="collapse" for="c-38065476">[-]</label><label class="expand" for="c-38065476">[1 more]</label></div><br/><div class="children"><div class="content">fully agree</div><br/></div></div></div></div><div id="38065345" class="c"><input type="checkbox" id="c-38065345" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38064742">parent</a><span>|</span><a href="#38065277">prev</a><span>|</span><a href="#38066660">next</a><span>|</span><label class="collapse" for="c-38065345">[-]</label><label class="expand" for="c-38065345">[1 more]</label></div><br/><div class="children"><div class="content">As a biomedical engineer who went into software, thank you for this comment lol. So tired of rehashing this.</div><br/></div></div></div></div><div id="38066150" class="c"><input type="checkbox" id="c-38066150" checked=""/><div class="controls bullet"><span class="by">MagicMoonlight</span><span>|</span><a href="#38066660">prev</a><span>|</span><a href="#38064683">next</a><span>|</span><label class="collapse" for="c-38066150">[-]</label><label class="expand" for="c-38066150">[3 more]</label></div><br/><div class="children"><div class="content">If it was shallow then it wouldn’t take 25 years for a human brain to fully train. The fact that some parts of it need that much data mean they must be way up the hierarchy.</div><br/><div id="38066868" class="c"><input type="checkbox" id="c-38066868" checked=""/><div class="controls bullet"><span class="by">GranularRecipe</span><span>|</span><a href="#38066150">parent</a><span>|</span><a href="#38064683">next</a><span>|</span><label class="collapse" for="c-38066868">[-]</label><label class="expand" for="c-38066868">[2 more]</label></div><br/><div class="children"><div class="content">The reason for deep learning is that shallow networks are very hard (or impossible) to train. In that sense, long time of training is evidence for shallow networks.</div><br/><div id="38066949" class="c"><input type="checkbox" id="c-38066949" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#38066150">root</a><span>|</span><a href="#38066868">parent</a><span>|</span><a href="#38064683">next</a><span>|</span><label class="collapse" for="c-38066949">[-]</label><label class="expand" for="c-38066949">[1 more]</label></div><br/><div class="children"><div class="content">No it&#x27;s because shallow networks can&#x27;t express complex functions. If you think about it the shallowest network is pretty much a lookup table. They can <i>theoretically</i> model any function, but the number of parameters needed means in practice they can&#x27;t. Deep networks can learn much more complex functions for the same number of parameters.</div><br/></div></div></div></div></div></div><div id="38064683" class="c"><input type="checkbox" id="c-38064683" checked=""/><div class="controls bullet"><span class="by">sheeshkebab</span><span>|</span><a href="#38066150">prev</a><span>|</span><a href="#38065882">next</a><span>|</span><label class="collapse" for="c-38064683">[-]</label><label class="expand" for="c-38064683">[23 more]</label></div><br/><div class="children"><div class="content">It’s indeed odd that current dnn’s require massive amount of energy to retrain and lack any kind of practical continuous adaptation and learning.</div><br/><div id="38064733" class="c"><input type="checkbox" id="c-38064733" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38064683">parent</a><span>|</span><a href="#38064761">next</a><span>|</span><label class="collapse" for="c-38064733">[-]</label><label class="expand" for="c-38064733">[9 more]</label></div><br/><div class="children"><div class="content">With computer-based intelligence we have the overhead of computing every bit though (probably) inefficient silicon and direct electric currents. The brain leverages the properties of chemicals, though millions of years of evolution.</div><br/><div id="38064790" class="c"><input type="checkbox" id="c-38064790" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064733">parent</a><span>|</span><a href="#38064761">next</a><span>|</span><label class="collapse" for="c-38064790">[-]</label><label class="expand" for="c-38064790">[8 more]</label></div><br/><div class="children"><div class="content">The brain isn&#x27;t a faster computer.<p>An infinitely-fast computer wouldn&#x27;t meaningfully change the &quot;expensive training vs fast, static inference&quot; workflow that neural networks have always been developed around (except in the most brute force-y &quot;retrain on the entire world, every single nanosecond&quot; sense).</div><br/><div id="38065027" class="c"><input type="checkbox" id="c-38065027" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064790">parent</a><span>|</span><a href="#38065637">next</a><span>|</span><label class="collapse" for="c-38065027">[-]</label><label class="expand" for="c-38065027">[6 more]</label></div><br/><div class="children"><div class="content">I think we agree? I am talking to the efficiency of the brain. Not processing speed. Efficiency of the brain to do things advantageous to the selfish genes I guess.<p>The brain is supremely efficient at what the brain has evolved to do. It is almost tautological! Because if it wasn&#x27;t, it wouldn&#x27;t have evolved to that.<p>Silicon comes from an alien land, and is emulating. Even with the best algorithms there has to be a limit on how efficient a computer-based intelligence can be without changing how the chips work.<p>You could spin it around and say, well computers are better at many things than humans, and there is no way you could get a biological brain to be as good for the same amount of power (e.g. a raspberry pi can do calculations our brain couldn&#x27;t possibly do).</div><br/><div id="38065155" class="c"><input type="checkbox" id="c-38065155" checked=""/><div class="controls bullet"><span class="by">DiggyJohnson</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38065027">parent</a><span>|</span><a href="#38065762">next</a><span>|</span><label class="collapse" for="c-38065155">[-]</label><label class="expand" for="c-38065155">[1 more]</label></div><br/><div class="children"><div class="content">Really well said, I think this is an excellent way to frame the dichotomy (comparison?).<p>Much of these threads make the binary mistake: can these systems be compared, or are they fundamentally different? A bit of both, almost certainly.</div><br/></div></div><div id="38065762" class="c"><input type="checkbox" id="c-38065762" checked=""/><div class="controls bullet"><span class="by">cortesoft</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38065027">parent</a><span>|</span><a href="#38065155">prev</a><span>|</span><a href="#38067008">next</a><span>|</span><label class="collapse" for="c-38065762">[-]</label><label class="expand" for="c-38065762">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The brain is supremely efficient at what the brain has evolved to do. It is almost tautological! Because if it wasn&#x27;t, it wouldn&#x27;t have evolved to that.<p>Not really, evolution doesn&#x27;t guarantee the brain will be supremely efficient. It just guarantees that it will be efficient ENOUGH.</div><br/></div></div><div id="38067008" class="c"><input type="checkbox" id="c-38067008" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38065027">parent</a><span>|</span><a href="#38065762">prev</a><span>|</span><a href="#38065538">next</a><span>|</span><label class="collapse" for="c-38067008">[-]</label><label class="expand" for="c-38067008">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re talking about something orthogonal, how efficient it is.  He&#x27;s talking about something different:<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Catastrophic_interference" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Catastrophic_interference</a><p>Which practically requires full retraining at every step to integrate new knowledge.  I think we have some partial solutions like learning to select between finetunings, but not if the task needs to crosscut between them.<p>The human brain doesn&#x27;t seem to suffer with catastrophic interference to nearly the same degree, independent of its computational efficiency, though there are possibly related things like developmental stages that if they are delayed may never be able to take place.</div><br/></div></div><div id="38065538" class="c"><input type="checkbox" id="c-38065538" checked=""/><div class="controls bullet"><span class="by">PaulDavisThe1st</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38065027">parent</a><span>|</span><a href="#38067008">prev</a><span>|</span><a href="#38065637">next</a><span>|</span><label class="collapse" for="c-38065538">[-]</label><label class="expand" for="c-38065538">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The brain is supremely efficient at what the brain has evolved to do. It is almost tautological! Because if it wasn&#x27;t, it wouldn&#x27;t have evolved to that.<p>This echoes an extremely naive view of evolution.<p>There are many phenotypes in the living world which have evolved but for which there is no reason to believe that the phenotype is either (a) supremely efficient and&#x2F;or (b) under selection pressure (the two are obviously related).<p>Evolution has no tautology. Brains do not evolve to be supremely efficient, just like humans do not evolve to be supremely efficient.<p>What exists today is that which has survived, for whatever reason. It&#x27;s not even possible to say something as apparently simplistic as &quot;the only purpose evolution respects is leaving behind more copies&quot; because that ignores (a) group selection (b) changing ecosystems that favor plasticity in the long run.</div><br/><div id="38066406" class="c"><input type="checkbox" id="c-38066406" checked=""/><div class="controls bullet"><span class="by">cycomanic</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38065538">parent</a><span>|</span><a href="#38065637">next</a><span>|</span><label class="collapse" for="c-38066406">[-]</label><label class="expand" for="c-38066406">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There are many phenotypes in the living world which have evolved but for which there is no reason to believe that the phenotype is either (a) supremely efficient and&#x2F;or (b) under selection pressure (the two are obviously related).<p>&gt; Evolution has no tautology. Brains do not evolve to be supremely efficient, just like humans do not evolve to be supremely efficient.<p>&gt; What exists today is that which has survived, for whatever reason. It&#x27;s not even possible to say something as apparently simplistic as &quot;the only purpose evolution respects is leaving behind more copies&quot; because that ignores (a) group selection (b) changing ecosystems that favor plasticity in the long run.<p>A primary example of this are our legs, they would be much more efficient if the knees pointed backwards. They are not the most efficient design, but simply good enough.</div><br/></div></div></div></div></div></div><div id="38065637" class="c"><input type="checkbox" id="c-38065637" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064790">parent</a><span>|</span><a href="#38065027">prev</a><span>|</span><a href="#38064761">next</a><span>|</span><label class="collapse" for="c-38065637">[-]</label><label class="expand" for="c-38065637">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s an apples-to-oranges comparison. They&#x27;re both fruit that grow on trees, but that&#x27;s where the similarities end.<p>The primary difference, and likely the reason that brains are unreasonably effective, is the specifics of the architecture and internal representations (in the rigorous, information-theoretic sense) of its computational systems. It&#x27;s not quite analog but it uses analog means. It&#x27;s not quite digital but it does process via abstractions.<p>You can still reasonably call the brain a &quot;computer&quot; if you decide it can shed the laden history of that word and its close association with binary operations using transistors. You can do so because it uses internal structures to process inputs and emit outputs. But like I said above, it requires a generalized interpretation of the word to start to understand where and how the two fields of study may be unified.</div><br/></div></div></div></div></div></div><div id="38064761" class="c"><input type="checkbox" id="c-38064761" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#38064683">parent</a><span>|</span><a href="#38064733">prev</a><span>|</span><a href="#38064811">next</a><span>|</span><label class="collapse" for="c-38064761">[-]</label><label class="expand" for="c-38064761">[6 more]</label></div><br/><div class="children"><div class="content">Yes, it&#x27;s odd that sled dogs make terrible housepets. &#x2F;s<p>Neural networks fundamentally aren&#x27;t <i>designed</i> to be otherwise. The workflow that has guided their entire development for over a decade is based around expensive training and static inference.</div><br/><div id="38064799" class="c"><input type="checkbox" id="c-38064799" checked=""/><div class="controls bullet"><span class="by">sheeshkebab</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064761">parent</a><span>|</span><a href="#38064811">next</a><span>|</span><label class="collapse" for="c-38064799">[-]</label><label class="expand" for="c-38064799">[5 more]</label></div><br/><div class="children"><div class="content">Why then all the talk about AGI when fundamentals don’t even allow for it to emerge.</div><br/><div id="38064838" class="c"><input type="checkbox" id="c-38064838" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064799">parent</a><span>|</span><a href="#38064904">next</a><span>|</span><label class="collapse" for="c-38064838">[-]</label><label class="expand" for="c-38064838">[1 more]</label></div><br/><div class="children"><div class="content">Because drumming up talk about AGI is a really great way to get funding for your startup. The tech industry sustains itself on hype.</div><br/></div></div><div id="38064904" class="c"><input type="checkbox" id="c-38064904" checked=""/><div class="controls bullet"><span class="by">FeepingCreature</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064799">parent</a><span>|</span><a href="#38064838">prev</a><span>|</span><a href="#38064811">next</a><span>|</span><label class="collapse" for="c-38064904">[-]</label><label class="expand" for="c-38064904">[3 more]</label></div><br/><div class="children"><div class="content">First make it work; then make it efficient.</div><br/><div id="38064915" class="c"><input type="checkbox" id="c-38064915" checked=""/><div class="controls bullet"><span class="by">jakobson14</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064904">parent</a><span>|</span><a href="#38064811">next</a><span>|</span><label class="collapse" for="c-38064915">[-]</label><label class="expand" for="c-38064915">[2 more]</label></div><br/><div class="children"><div class="content">Your scientists were so preoccupied with whether or not they should that they didn&#x27;t stop to think if they could.</div><br/><div id="38065099" class="c"><input type="checkbox" id="c-38065099" checked=""/><div class="controls bullet"><span class="by">drdeca</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064915">parent</a><span>|</span><a href="#38064811">next</a><span>|</span><label class="collapse" for="c-38065099">[-]</label><label class="expand" for="c-38065099">[1 more]</label></div><br/><div class="children"><div class="content">... seems potentially  better than the other way around?  
Well, I suppose it depends.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38064811" class="c"><input type="checkbox" id="c-38064811" checked=""/><div class="controls bullet"><span class="by">4death4</span><span>|</span><a href="#38064683">parent</a><span>|</span><a href="#38064761">prev</a><span>|</span><a href="#38066112">next</a><span>|</span><label class="collapse" for="c-38064811">[-]</label><label class="expand" for="c-38064811">[6 more]</label></div><br/><div class="children"><div class="content">When you say “massive amount of energy” are you comparing the energy requirements to a single human or to the billions of years of solar and geothermal energy that went into producing the human species?</div><br/><div id="38064951" class="c"><input type="checkbox" id="c-38064951" checked=""/><div class="controls bullet"><span class="by">edmundsauto</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064811">parent</a><span>|</span><a href="#38064914">next</a><span>|</span><label class="collapse" for="c-38064951">[-]</label><label class="expand" for="c-38064951">[2 more]</label></div><br/><div class="children"><div class="content">I don’t think this is an apt comparison, but I do think the amount of energy it takes to grow a human into brain maturity in adulthood is an interesting one. Brains + bodies over a 20 year development cycle is still probably much less than training even a low quality Llm.</div><br/><div id="38065235" class="c"><input type="checkbox" id="c-38065235" checked=""/><div class="controls bullet"><span class="by">4death4</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064951">parent</a><span>|</span><a href="#38064914">next</a><span>|</span><label class="collapse" for="c-38065235">[-]</label><label class="expand" for="c-38065235">[1 more]</label></div><br/><div class="children"><div class="content">Let’s say a human needs an average of 2000 calories a day. A calorie is roughly equivalent to 1 Watt hour, so over 20 years, it takes about 15 MWh to sustain a human.<p>Let’s say a single A100 has a peak power draw of 250W, and you need 100 to train an LLM. So each hour of training consumes 25,000 Wh of energy. 15 MWh &#x2F; 25,000 W = 600 hours, or 25 days, which is probably pretty close to the true training time.<p>So the numbers are actually pretty close. But a human brain doesn’t start out as a set of random weights like an LLM. The human brain has predefined structure that’s the result of an extremely long evolutionary process.</div><br/></div></div></div></div><div id="38064914" class="c"><input type="checkbox" id="c-38064914" checked=""/><div class="controls bullet"><span class="by">Affric</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064811">parent</a><span>|</span><a href="#38064951">prev</a><span>|</span><a href="#38066112">next</a><span>|</span><label class="collapse" for="c-38064914">[-]</label><label class="expand" for="c-38064914">[3 more]</label></div><br/><div class="children"><div class="content">By that token the amount of energy for neural networks will be bound to some extent by the development of the biosphere and the creators of neural networks.</div><br/><div id="38065599" class="c"><input type="checkbox" id="c-38065599" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#38064683">root</a><span>|</span><a href="#38064914">parent</a><span>|</span><a href="#38064976">next</a><span>|</span><label class="collapse" for="c-38065599">[-]</label><label class="expand" for="c-38065599">[1 more]</label></div><br/><div class="children"><div class="content">Not really? The point is that most artificial neural networks are started from basically zero (random noisy weights), where as a human neural network is jump-started with an overall neural structure that has been shaped by millions of years of evolution. Sure, it&#x27;s not fair to compare the overall energy required to get there, but the point is just that a biological neural network starts with a huge headstart that is frequently forgotten when talking about efficiency.</div><br/></div></div></div></div></div></div><div id="38066112" class="c"><input type="checkbox" id="c-38066112" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#38064683">parent</a><span>|</span><a href="#38064811">prev</a><span>|</span><a href="#38065882">next</a><span>|</span><label class="collapse" for="c-38066112">[-]</label><label class="expand" for="c-38066112">[1 more]</label></div><br/><div class="children"><div class="content">In-comtext learning exists though.</div><br/></div></div></div></div><div id="38065882" class="c"><input type="checkbox" id="c-38065882" checked=""/><div class="controls bullet"><span class="by">hliyan</span><span>|</span><a href="#38064683">prev</a><span>|</span><a href="#38065583">next</a><span>|</span><label class="collapse" for="c-38065882">[-]</label><label class="expand" for="c-38065882">[2 more]</label></div><br/><div class="children"><div class="content">&quot;brain seems shallow and neural networks are deep, ergo neural networks are doing it wrong&quot;<p>Please don&#x27;t claim things the author didn&#x27;t. What I read was &quot;ergo (artificial) neural networks may be missing a trick&quot;</div><br/><div id="38065926" class="c"><input type="checkbox" id="c-38065926" checked=""/><div class="controls bullet"><span class="by">hliyan</span><span>|</span><a href="#38065882">parent</a><span>|</span><a href="#38065583">next</a><span>|</span><label class="collapse" for="c-38065926">[-]</label><label class="expand" for="c-38065926">[1 more]</label></div><br/><div class="children"><div class="content">Ignore. Reposted this under correct parent comment</div><br/></div></div></div></div><div id="38065583" class="c"><input type="checkbox" id="c-38065583" checked=""/><div class="controls bullet"><span class="by">beaugunderson</span><span>|</span><a href="#38065882">prev</a><span>|</span><a href="#38065928">next</a><span>|</span><label class="collapse" for="c-38065583">[-]</label><label class="expand" for="c-38065583">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;anonymfile.com&#x2F;dR8a&#x2F;s41583-023-00756-z.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;anonymfile.com&#x2F;dR8a&#x2F;s41583-023-00756-z.pdf</a></div><br/></div></div><div id="38065928" class="c"><input type="checkbox" id="c-38065928" checked=""/><div class="controls bullet"><span class="by">phlogisticfugu</span><span>|</span><a href="#38065583">prev</a><span>|</span><a href="#38066504">next</a><span>|</span><label class="collapse" for="c-38065928">[-]</label><label class="expand" for="c-38065928">[1 more]</label></div><br/><div class="children"><div class="content">deep learning models have already been permitting &quot;shallow signals&quot; for a while.  see &quot;skip connections&quot;<p><a href="https:&#x2F;&#x2F;theaisummer.com&#x2F;skip-connections&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;theaisummer.com&#x2F;skip-connections&#x2F;</a></div><br/></div></div><div id="38066504" class="c"><input type="checkbox" id="c-38066504" checked=""/><div class="controls bullet"><span class="by">Simon_ORourke</span><span>|</span><a href="#38065928">prev</a><span>|</span><a href="#38066088">next</a><span>|</span><label class="collapse" for="c-38066504">[-]</label><label class="expand" for="c-38066504">[1 more]</label></div><br/><div class="children"><div class="content">Judging by some of the levels of driving around these parts, the brain may be very shallow indeed.</div><br/></div></div><div id="38066088" class="c"><input type="checkbox" id="c-38066088" checked=""/><div class="controls bullet"><span class="by">low_tech_punk</span><span>|</span><a href="#38066504">prev</a><span>|</span><a href="#38065187">next</a><span>|</span><label class="collapse" for="c-38066088">[-]</label><label class="expand" for="c-38066088">[1 more]</label></div><br/><div class="children"><div class="content">Replay of Jeff Hawkins group’s A Thousand Brains theory?</div><br/></div></div><div id="38065187" class="c"><input type="checkbox" id="c-38065187" checked=""/><div class="controls bullet"><span class="by">Salgat</span><span>|</span><a href="#38066088">prev</a><span>|</span><label class="collapse" for="c-38065187">[-]</label><label class="expand" for="c-38065187">[2 more]</label></div><br/><div class="children"><div class="content">The brain communicates with itself, so deep layers are equivalent to sections of the brain talking to each other. The only relevance white matter depth has is with regard to how it&#x27;s trained, and since it doesn&#x27;t use gradient descent, it&#x27;s irrelevant to neural networks in that regard.</div><br/><div id="38065608" class="c"><input type="checkbox" id="c-38065608" checked=""/><div class="controls bullet"><span class="by">blovescoffee</span><span>|</span><a href="#38065187">parent</a><span>|</span><label class="collapse" for="c-38065608">[-]</label><label class="expand" for="c-38065608">[1 more]</label></div><br/><div class="children"><div class="content">Intercommunication does not equal layer depth.</div><br/></div></div></div></div></div></div></div></div></div></body></html>