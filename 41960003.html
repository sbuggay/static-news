<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1730451665107" as="style"/><link rel="stylesheet" href="styles.css?v=1730451665107"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Tell HN: Robots.txt pitfalls – what I learned the hard way</a> </div><div class="subtext"><span>pyeri</span> | <span>33 comments</span></div><br/><div><div id="42010174" class="c"><input type="checkbox" id="c-42010174" checked=""/><div class="controls bullet"><span class="by">andrethegiant</span><span>|</span><a href="#41960195">next</a><span>|</span><label class="collapse" for="c-42010174">[-]</label><label class="expand" for="c-42010174">[4 more]</label></div><br/><div class="children"><div class="content">&gt; there&#x27;s typically a 5-7 day gap between updating the robots.txt file and crawlers processing it<p>You could try moving your favicon to another dir, or root dir, for the time being, and update your HTML to match. That way it would be allowed according to the version that Google still has cached. Also, I think browsers look for a favicon at &#x2F;favicon.ico regardless, so it might be worth making a copy there too.</div><br/><div id="42011292" class="c"><input type="checkbox" id="c-42011292" checked=""/><div class="controls bullet"><span class="by">throwaway2016a</span><span>|</span><a href="#42010174">parent</a><span>|</span><a href="#42011152">next</a><span>|</span><label class="collapse" for="c-42011292">[-]</label><label class="expand" for="c-42011292">[2 more]</label></div><br/><div class="children"><div class="content">&#x2F;favicon.ico is the default and it will be loaded if your page does not specify a different path in the metadata but in my experience most clients respect the metadata and won&#x27;t try to fetch the default path until after the &lt;head&gt; section of the page loads for HTML content.<p>But non-HTML content has no choice but to use the default so it&#x27;s generally a good idea to make sure the default path resolves.</div><br/><div id="42013675" class="c"><input type="checkbox" id="c-42013675" checked=""/><div class="controls bullet"><span class="by">andrewxdiamond</span><span>|</span><a href="#42010174">root</a><span>|</span><a href="#42011292">parent</a><span>|</span><a href="#42011152">next</a><span>|</span><label class="collapse" for="c-42013675">[-]</label><label class="expand" for="c-42013675">[1 more]</label></div><br/><div class="children"><div class="content">&gt; won&#x27;t try to fetch the default path until after the &lt;head&gt; section of the page loads for HTML content<p>That&#x27;s a really interesting optimization. How did you discover this? Reading source?</div><br/></div></div></div></div><div id="42011152" class="c"><input type="checkbox" id="c-42011152" checked=""/><div class="controls bullet"><span class="by">ms7892</span><span>|</span><a href="#42010174">parent</a><span>|</span><a href="#42011292">prev</a><span>|</span><a href="#41960195">next</a><span>|</span><label class="collapse" for="c-42011152">[-]</label><label class="expand" for="c-42011152">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing, I wasn’t knowing that browsers look for a favicon at &#x2F;favicon.ico. Thanks again.</div><br/></div></div></div></div><div id="41960195" class="c"><input type="checkbox" id="c-41960195" checked=""/><div class="controls bullet"><span class="by">dazc</span><span>|</span><a href="#42010174">prev</a><span>|</span><a href="#42011060">next</a><span>|</span><label class="collapse" for="c-41960195">[-]</label><label class="expand" for="c-41960195">[3 more]</label></div><br/><div class="children"><div class="content">USE X-Robots-Tag: noindex to prevent files being indexed and let google determine how they crawl your site for themselves.<p>A nightmare scenario can result, otherwise, where you have content indexed but don&#x27;t allow googlebot to crawl it. This does not end well.<p><a href="https:&#x2F;&#x2F;developers.google.com&#x2F;search&#x2F;docs&#x2F;crawling-indexing&#x2F;block-indexing" rel="nofollow">https:&#x2F;&#x2F;developers.google.com&#x2F;search&#x2F;docs&#x2F;crawling-indexing&#x2F;...</a></div><br/><div id="42011609" class="c"><input type="checkbox" id="c-42011609" checked=""/><div class="controls bullet"><span class="by">csiegert</span><span>|</span><a href="#41960195">parent</a><span>|</span><a href="#42011060">next</a><span>|</span><label class="collapse" for="c-42011609">[-]</label><label class="expand" for="c-42011609">[2 more]</label></div><br/><div class="children"><div class="content">I’ve got two questions:<p>1. What does it look like for a page to be indexed when googlebot is not allowed to crawl it? What is shown in search results (since googlebot has not seen its content)?<p>2. The linked page says to avoid Disallow in robots.txt and to rely on the noindex tag. But how can I prevent googlebot from crawling all user profiles to avoid database hits, bandwidth, etc. without an entry in robots.txt? With noindex, googlebot must visit each user profile page to see that it is not supposed to be indexed.</div><br/><div id="42012147" class="c"><input type="checkbox" id="c-42012147" checked=""/><div class="controls bullet"><span class="by">seanwilson</span><span>|</span><a href="#41960195">root</a><span>|</span><a href="#42011609">parent</a><span>|</span><a href="#42011060">next</a><span>|</span><label class="collapse" for="c-42012147">[-]</label><label class="expand" for="c-42012147">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;developers.google.com&#x2F;search&#x2F;docs&#x2F;crawling-indexing&#x2F;block-indexing" rel="nofollow">https:&#x2F;&#x2F;developers.google.com&#x2F;search&#x2F;docs&#x2F;crawling-indexing&#x2F;...</a><p><pre><code>   &quot;Important: For the noindex rule to be effective, the page or resource must not be blocked by a robots.txt file, and it has to be otherwise accessible to the crawler. If the page is blocked by a robots.txt file or the crawler can&#x27;t access the page, the crawler will never see the noindex rule, and the page can still appear in search results, for example if other pages link to it.&quot;
</code></pre>
It&#x27;s counterintuitive but if you want a page to never appear on Google search, you need to flag it as noindex, and not block it via robots.txt.<p>&gt; 1. What does it look like for a page to be indexed when googlebot is not allowed to crawl it? What is shown in search results (since googlebot has not seen its content)?<p>It&#x27;ll usually list the URL with a description like &quot;No information is available for this page&quot;. This can happen for example if the page has a lot of backlinks, it&#x27;s blocked via robots.txt, and it&#x27;s missing the noindex flag.</div><br/></div></div></div></div></div></div><div id="42011060" class="c"><input type="checkbox" id="c-42011060" checked=""/><div class="controls bullet"><span class="by">hk1337</span><span>|</span><a href="#41960195">prev</a><span>|</span><a href="#42010412">next</a><span>|</span><label class="collapse" for="c-42011060">[-]</label><label class="expand" for="c-42011060">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s good information but...<p>1. Why is your favicon in the uploads directory? Usually, those would be at the root of your site or in an image directory?<p>2. Why is there an uploads directory for a static site hosted on GitHub? I don&#x27;t believe that is useful on GitHub, is it? You cannot have visitors upload files to it, right?</div><br/><div id="42011737" class="c"><input type="checkbox" id="c-42011737" checked=""/><div class="controls bullet"><span class="by">gwd</span><span>|</span><a href="#42011060">parent</a><span>|</span><a href="#42010412">next</a><span>|</span><label class="collapse" for="c-42011737">[-]</label><label class="expand" for="c-42011737">[1 more]</label></div><br/><div class="children"><div class="content">Speaking for myself:<p>1. I want nginx to serve static files, and everything else to be reverse proxied to the webapp<p>2. The configuration file that allows &#x2F;favicon.ico (and others) to be a file but &#x2F; and other paths to be passed to the webapp is kind of ugly.  Here&#x27;s mine:<p><pre><code>    location ~* ^&#x2F;(favicon.ico|apple-touch-icon.png)$ {
        root $icons_path;
    }
</code></pre>
In my own case I&#x27;ve so far decided to accept the ugly config file, but as you can see, I haven&#x27;t gotten around to adding even a robots.txt or any of the other files the modern web ecosystem expects; and adding them involves adding them one-by-one.  I can see why someone would say, &quot;Why make an ugly hack of an nginx config, when I can just define the favicon location in the metadata to a path easily configured to be files-only?&quot;</div><br/></div></div></div></div><div id="42010412" class="c"><input type="checkbox" id="c-42010412" checked=""/><div class="controls bullet"><span class="by">seanwilson</span><span>|</span><a href="#42011060">prev</a><span>|</span><a href="#42015150">next</a><span>|</span><label class="collapse" for="c-42010412">[-]</label><label class="expand" for="c-42010412">[3 more]</label></div><br/><div class="children"><div class="content">How big is your site? Crawl budget is likely only relevant for huge sites, not personal blogs.</div><br/><div id="42011580" class="c"><input type="checkbox" id="c-42011580" checked=""/><div class="controls bullet"><span class="by">moribunda</span><span>|</span><a href="#42010412">parent</a><span>|</span><a href="#42014192">next</a><span>|</span><label class="collapse" for="c-42011580">[-]</label><label class="expand" for="c-42011580">[1 more]</label></div><br/><div class="children"><div class="content">Exactly - this SEOveroptimisation</div><br/></div></div><div id="42014192" class="c"><input type="checkbox" id="c-42014192" checked=""/><div class="controls bullet"><span class="by">ccgreg</span><span>|</span><a href="#42010412">parent</a><span>|</span><a href="#42011580">prev</a><span>|</span><a href="#42015150">next</a><span>|</span><label class="collapse" for="c-42014192">[-]</label><label class="expand" for="c-42014192">[1 more]</label></div><br/><div class="children"><div class="content">Crawl budget is relevant to every site in Common Crawl.</div><br/></div></div></div></div><div id="42011491" class="c"><input type="checkbox" id="c-42011491" checked=""/><div class="controls bullet"><span class="by">xnx</span><span>|</span><a href="#42015150">prev</a><span>|</span><a href="#42012741">next</a><span>|</span><label class="collapse" for="c-42011491">[-]</label><label class="expand" for="c-42011491">[4 more]</label></div><br/><div class="children"><div class="content">The best SEO advice is to not focus on SEO and make a site that people will like.</div><br/><div id="42012417" class="c"><input type="checkbox" id="c-42012417" checked=""/><div class="controls bullet"><span class="by">dewey</span><span>|</span><a href="#42011491">parent</a><span>|</span><a href="#42013146">next</a><span>|</span><label class="collapse" for="c-42012417">[-]</label><label class="expand" for="c-42012417">[2 more]</label></div><br/><div class="children"><div class="content">Technical SEO still is a very valid optimization. Making sure you have all the relevant tags, a good structure, fast loading pages etc.</div><br/><div id="42013910" class="c"><input type="checkbox" id="c-42013910" checked=""/><div class="controls bullet"><span class="by">fhdsgbbcaA</span><span>|</span><a href="#42011491">root</a><span>|</span><a href="#42012417">parent</a><span>|</span><a href="#42013146">next</a><span>|</span><label class="collapse" for="c-42013910">[-]</label><label class="expand" for="c-42013910">[1 more]</label></div><br/><div class="children"><div class="content">Just focus on accessibility and standards.</div><br/></div></div></div></div><div id="42013146" class="c"><input type="checkbox" id="c-42013146" checked=""/><div class="controls bullet"><span class="by">Retr0id</span><span>|</span><a href="#42011491">parent</a><span>|</span><a href="#42012417">prev</a><span>|</span><a href="#42012741">next</a><span>|</span><label class="collapse" for="c-42013146">[-]</label><label class="expand" for="c-42013146">[1 more]</label></div><br/><div class="children"><div class="content">Thinking about SEO too hard sucks, but having a site that nobody can find (even when they already know about it and are specifically trying to find it again!) sucks even more.</div><br/></div></div></div></div><div id="42012741" class="c"><input type="checkbox" id="c-42012741" checked=""/><div class="controls bullet"><span class="by">liendolucas</span><span>|</span><a href="#42011491">prev</a><span>|</span><a href="#42012175">next</a><span>|</span><label class="collapse" for="c-42012741">[-]</label><label class="expand" for="c-42012741">[5 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a complete ignorant when it comes to SEOs so what are the consequences of not having a robots.txt nor a sitemap.xml at all? Will that be detrimental in a big way?</div><br/><div id="42014620" class="c"><input type="checkbox" id="c-42014620" checked=""/><div class="controls bullet"><span class="by">12thhandyman</span><span>|</span><a href="#42012741">parent</a><span>|</span><a href="#42013951">next</a><span>|</span><label class="collapse" for="c-42014620">[-]</label><label class="expand" for="c-42014620">[1 more]</label></div><br/><div class="children"><div class="content">There are many metrics and facets of a website considered for SEO, with varying weights. The absence of either a robots.txt or sitemap.xml has a non-negligible but relatively minor weight compared to some other metrics.
The files should be present and accurate when optimizing for seo. Ruby on Rails for example creates an empty robots.txt file with new projects, it does not create any sitemap.xml however.</div><br/></div></div><div id="42013951" class="c"><input type="checkbox" id="c-42013951" checked=""/><div class="controls bullet"><span class="by">jamesfinlayson</span><span>|</span><a href="#42012741">parent</a><span>|</span><a href="#42014620">prev</a><span>|</span><a href="#42013532">next</a><span>|</span><label class="collapse" for="c-42013951">[-]</label><label class="expand" for="c-42013951">[1 more]</label></div><br/><div class="children"><div class="content">My understanding is that a lack of robots.txt should be fine and the lack of a sitemap.xml shouldn&#x27;t be too troublesome as long as there is something linking to your site and all pages are linked from somewhere on your site (the sitemap helps search engines find all the links in one place but you have a nav bar or an article list that should work similarly, but you can give a suggestion to search engines about how often they should recrawl in your sitemap, which I don&#x27;t believe you can influence any other way).</div><br/></div></div><div id="42013532" class="c"><input type="checkbox" id="c-42013532" checked=""/><div class="controls bullet"><span class="by">shikshake</span><span>|</span><a href="#42012741">parent</a><span>|</span><a href="#42013951">prev</a><span>|</span><a href="#42013706">next</a><span>|</span><label class="collapse" for="c-42013532">[-]</label><label class="expand" for="c-42013532">[1 more]</label></div><br/><div class="children"><div class="content">I’m also ignorant of this, and to add a question on top of yours:  is it worth worrying about robots.txt for personal portfolio websites built from scratch?</div><br/></div></div><div id="42013706" class="c"><input type="checkbox" id="c-42013706" checked=""/><div class="controls bullet"><span class="by">Brajeshwar</span><span>|</span><a href="#42012741">parent</a><span>|</span><a href="#42013532">prev</a><span>|</span><a href="#42012175">next</a><span>|</span><label class="collapse" for="c-42013706">[-]</label><label class="expand" for="c-42013706">[1 more]</label></div><br/><div class="children"><div class="content">Nope! A site without robots.txt is defaulted to saying, please do the default — crawl my site in its entirety.</div><br/></div></div></div></div><div id="42012175" class="c"><input type="checkbox" id="c-42012175" checked=""/><div class="controls bullet"><span class="by">maciekpaprocki</span><span>|</span><a href="#42012741">prev</a><span>|</span><a href="#42011697">next</a><span>|</span><label class="collapse" for="c-42012175">[-]</label><label class="expand" for="c-42012175">[1 more]</label></div><br/><div class="children"><div class="content">You dont want to exclude your images. That can very much affect your results as it will remove you from image tab, but also content of articles that contain them might be affected.</div><br/></div></div><div id="42011697" class="c"><input type="checkbox" id="c-42011697" checked=""/><div class="controls bullet"><span class="by">tiffanyh</span><span>|</span><a href="#42012175">prev</a><span>|</span><a href="#42012432">next</a><span>|</span><label class="collapse" for="c-42011697">[-]</label><label class="expand" for="c-42011697">[6 more]</label></div><br/><div class="children"><div class="content">Does anyone have suggestions on what a proper robots.txt would be?<p>How about:<p><pre><code>  User-agent: *
  Allow: &#x2F;
  Sitemap: https:&#x2F;&#x2F;example.com&#x2F;sitemap.xml</code></pre></div><br/><div id="42012549" class="c"><input type="checkbox" id="c-42012549" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#42011697">parent</a><span>|</span><a href="#42011966">next</a><span>|</span><label class="collapse" for="c-42012549">[-]</label><label class="expand" for="c-42012549">[3 more]</label></div><br/><div class="children"><div class="content">The recommendation is to use an empty &quot;Disallow:&quot; rule rather than a catch all &quot;Allow:&quot; rule.<p>Otherwise that is the canonical minimal example.</div><br/><div id="42012744" class="c"><input type="checkbox" id="c-42012744" checked=""/><div class="controls bullet"><span class="by">tiffanyh</span><span>|</span><a href="#42011697">root</a><span>|</span><a href="#42012549">parent</a><span>|</span><a href="#42011966">next</a><span>|</span><label class="collapse" for="c-42012744">[-]</label><label class="expand" for="c-42012744">[2 more]</label></div><br/><div class="children"><div class="content">Like this?<p><pre><code>  User-agent: *
  Disallow: 
  Sitemap: https:&#x2F;&#x2F;example.com&#x2F;sitemap.xml</code></pre></div><br/><div id="42013444" class="c"><input type="checkbox" id="c-42013444" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#42011697">root</a><span>|</span><a href="#42012744">parent</a><span>|</span><a href="#42011966">next</a><span>|</span><label class="collapse" for="c-42013444">[-]</label><label class="expand" for="c-42013444">[1 more]</label></div><br/><div class="children"><div class="content">Precisely.</div><br/></div></div></div></div></div></div><div id="42011966" class="c"><input type="checkbox" id="c-42011966" checked=""/><div class="controls bullet"><span class="by">bragr</span><span>|</span><a href="#42011697">parent</a><span>|</span><a href="#42012549">prev</a><span>|</span><a href="#42012196">next</a><span>|</span><label class="collapse" for="c-42011966">[-]</label><label class="expand" for="c-42011966">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a valid robots.txt, but &quot;proper&quot; is entirely dependent on what you want to achieve. If you aren&#x27;t looking to treat different bots differently, and are looking allow all of your site to be indexed, then that is exactly what you want.</div><br/></div></div></div></div><div id="42012432" class="c"><input type="checkbox" id="c-42012432" checked=""/><div class="controls bullet"><span class="by">dewey</span><span>|</span><a href="#42011697">prev</a><span>|</span><a href="#42013609">next</a><span>|</span><label class="collapse" for="c-42012432">[-]</label><label class="expand" for="c-42012432">[1 more]</label></div><br/><div class="children"><div class="content">If you don’t have millions of pages the crawl budget limitations most likely will have zero impact.<p>Make sure your basic technical SEO factors are all good. Search console is looking good and then don’t continue to worry unless you are a huge site that’s living off SEO traffic.</div><br/></div></div><div id="42013609" class="c"><input type="checkbox" id="c-42013609" checked=""/><div class="controls bullet"><span class="by">Theodores</span><span>|</span><a href="#42012432">prev</a><span>|</span><a href="#42012899">next</a><span>|</span><label class="collapse" for="c-42013609">[-]</label><label class="expand" for="c-42013609">[1 more]</label></div><br/><div class="children"><div class="content">I thought that Google Search Console had tools to test robots.txt and sitemap.xml files, but it has been a while since I have needed to do that.<p>For those wondering why favicon is in a directory, nowadays there are half a dozen different favicon files for different devices in different situations and there are online tools such as The Real Favicon Generator that will take a source image and make the variants for you. These come with a code snippet for head and the option to use a sub directory so that you don&#x27;t clutter the root.<p>Maybe they should offer a robots.txt snippet too.<p>Fun fact, for a single page, you can base64 encode the favicon and shove it in the page, thereby not needing a separate file. Why would you want to do that? If you base64 encode all the images and add the scripts and stylesheets in, then you can have a HTML page that you don&#x27;t have to upload, you can email it to someone. This is useful if wanting to share a design mockup.</div><br/></div></div></div></div></div></div></div></body></html>