<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1690794075142" as="style"/><link rel="stylesheet" href="styles.css?v=1690794075142"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://sfcompute.org/">Show HN: San Francisco Compute – 512 H100s at &lt;$2/hr for research and startups</a> <span class="domain">(<a href="https://sfcompute.org">sfcompute.org</a>)</span></div><div class="subtext"><span>flaque</span> | <span>161 comments</span></div><br/><div><div id="36934431" class="c"><input type="checkbox" id="c-36934431" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36936414">next</a><span>|</span><label class="collapse" for="c-36934431">[-]</label><label class="expand" for="c-36934431">[43 more]</label></div><br/><div class="children"><div class="content">I hope you succeed. TPU research cloud (TRC) tried this in 2019. It was how I got my start.<p>In 2023 you can barely get a single TPU for more than an hour. Back then you could get literally hundreds, with an s.<p>I believed in TRC. I thought they’d solve it by scaling, and building a whole continent of TPUs. But in the end, TPU time was cut short in favor of internal researchers — some researchers being more equal than others. And how could it be any other way? If I made a proposal today to get these H100s to train GPT to play chess, people would laugh. The world is different now.<p>Your project has a youthful optimism that I hope you won’t lose as you go. And in fact it might be the way to win in the long run. So whenever someone comes knocking, begging for a tiny slice of your H100s for their harebrained idea, I hope you’ll humor them. It’s the only reason I was able to become anybody.</div><br/><div id="36935095" class="c"><input type="checkbox" id="c-36935095" checked=""/><div class="controls bullet"><span class="by">flaque</span><span>|</span><a href="#36934431">parent</a><span>|</span><a href="#36937037">next</a><span>|</span><label class="collapse" for="c-36935095">[-]</label><label class="expand" for="c-36935095">[13 more]</label></div><br/><div class="children"><div class="content">&gt; Your project has a youthful optimism that I hope you won’t lose as you go. And in fact it might be the way to win in the long run.<p>This is the nicest thing anyone has said to us about this. We&#x27;re gonna frame this and hang it out on our wall.<p>&gt; So whenever someone comes knocking, begging for a tiny slice of your H100s for their harebrained idea, I hope you’ll humor them.<p>Absolutely! :D</div><br/><div id="36935423" class="c"><input type="checkbox" id="c-36935423" checked=""/><div class="controls bullet"><span class="by">camhart</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36935095">parent</a><span>|</span><a href="#36937037">next</a><span>|</span><label class="collapse" for="c-36935423">[-]</label><label class="expand" for="c-36935423">[12 more]</label></div><br/><div class="children"><div class="content">Optimism is (almost) always required in order to accomplish anything of significance.  Those who lose it, aren&#x27;t living up to their potential.<p>I&#x27;m not encouraging the false belief that everything you do will work out.  Instead I&#x27;m encouraging the realization that the greatest accomplishments almost always feel like long shots, and require significant amounts of optimism.  Fear and pessimism, while helpful in appropriate doses, will limit you greatly in life if you let them rule you too significantly.<p>When I look back on my life, the greatest accomplishments I&#x27;ve achieved are ones where I was naive yet optimistic going into it.  This was a good thing, because I would have been too scared to try had I really known the challenges that lay ahead.</div><br/><div id="36936311" class="c"><input type="checkbox" id="c-36936311" checked=""/><div class="controls bullet"><span class="by">Frost1x</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36935423">parent</a><span>|</span><a href="#36936610">next</a><span>|</span><label class="collapse" for="c-36936311">[-]</label><label class="expand" for="c-36936311">[9 more]</label></div><br/><div class="children"><div class="content">&gt;Optimism is (almost) always required in order to accomplish anything of significance. Those who lose it, aren&#x27;t living up to their potential.<p>I argue that realism trumps optimism. It&#x27;s perfectly normal in a realist farming to see something difficult, acknowledge the high risk and failure potential, and still pursue something with intent to succeed.<p>I&#x27;ve personally grown tired of over optimism everywhere because it creates unrealistic situations and passes consequences of failure in an inequitable way. The &quot;visionary&quot; is rewarded when the rare successes occur, while everyone else suffers the consequences for most failures. No contingency plans for failure, no discussion of failure, and so on. Optimism just takes any idea, pursues it and consequences be someone else&#x27;s problem and be damned.<p>Pessimism isn&#x27;t much better, you essentially think everything is too risky or unlikely to succeed so you never do anything. You live in a state of inaction because any level of risk or uncertainty is too much.<p>To me, realism is much better. You acknowledge the challenge. You acknowledge the risk. You make sure everyone involved understands it, but you still charge forward knowing you might succeed. Some think if you&#x27;re not naively optimistic (what most people in my experience refer to as &quot;optimism&quot;) you don&#x27;t create enough pressure. I think that&#x27;s non-sense.</div><br/><div id="36937666" class="c"><input type="checkbox" id="c-36937666" checked=""/><div class="controls bullet"><span class="by">OrsonSmelles</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36936311">parent</a><span>|</span><a href="#36937452">next</a><span>|</span><label class="collapse" for="c-36937666">[-]</label><label class="expand" for="c-36937666">[1 more]</label></div><br/><div class="children"><div class="content">While I&#x27;ve said something like this comment scores of times in my life, and it&#x27;s definitely a necessary corrective for a lot of optimists who don&#x27;t think too hard about how they think, I don&#x27;t think it&#x27;s a useful place to stop. It&#x27;s not hard to get unanimous agreement with &quot;be a realist!&quot; because it&#x27;s framed so the alternative is irrationality&#x2F;delusion. But even among people who agree that the goal should be to reason under uncertainty and assess risks clearly, there will be a spectrum of risk tolerance, and I don&#x27;t think it&#x27;s the worst thing ever to describe that as &quot;optimism&quot; vs. &quot;pessimism&quot;! (I fully acknowledge this isn&#x27;t the dominant usage, but I think some spaces lean this way)<p>In this context, I tend to read the parent claim as something like, &quot;great success requires willingness to sometimes take worse-than-even odds or pursue modestly-negative-EV opportunities&quot;. I&#x27;m not sure I agree with the strongest version of that, but I think it&#x27;s likely that the space of risky paths to great achievement is richer than that of cautious ones.</div><br/></div></div><div id="36937452" class="c"><input type="checkbox" id="c-36937452" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36936311">parent</a><span>|</span><a href="#36937666">prev</a><span>|</span><a href="#36936875">next</a><span>|</span><label class="collapse" for="c-36937452">[-]</label><label class="expand" for="c-36937452">[2 more]</label></div><br/><div class="children"><div class="content">If everyone were a realist, we wouldn&#x27;t have half the advances we do. Because what can be &quot;real&quot; is proven wrong through innovation, after all isn&#x27;t that disruption? :)<p>Sam Altman talks about this quite frequently, that it&#x27;s not intelligence or luck necessary for an enduring innovation. It is persistence in the face of inevitability, and a high tolerance for being proven wrong and still persisting</div><br/><div id="36937722" class="c"><input type="checkbox" id="c-36937722" checked=""/><div class="controls bullet"><span class="by">OO000oo</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937452">parent</a><span>|</span><a href="#36936875">next</a><span>|</span><label class="collapse" for="c-36937722">[-]</label><label class="expand" for="c-36937722">[1 more]</label></div><br/><div class="children"><div class="content">Everybody knows socialism is impossible though. Can&#x27;t work, not worth trying, don&#x27;t even think about it.</div><br/></div></div></div></div><div id="36936875" class="c"><input type="checkbox" id="c-36936875" checked=""/><div class="controls bullet"><span class="by">rileyphone</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36936311">parent</a><span>|</span><a href="#36937452">prev</a><span>|</span><a href="#36937011">next</a><span>|</span><label class="collapse" for="c-36936875">[-]</label><label class="expand" for="c-36936875">[2 more]</label></div><br/><div class="children"><div class="content">You can be a realist visionary.</div><br/><div id="36937470" class="c"><input type="checkbox" id="c-36937470" checked=""/><div class="controls bullet"><span class="by">Frost1x</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36936875">parent</a><span>|</span><a href="#36937011">next</a><span>|</span><label class="collapse" for="c-36937470">[-]</label><label class="expand" for="c-36937470">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely, which is what I advocate for.</div><br/></div></div></div></div><div id="36937011" class="c"><input type="checkbox" id="c-36937011" checked=""/><div class="controls bullet"><span class="by">hgsgm</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36936311">parent</a><span>|</span><a href="#36936875">prev</a><span>|</span><a href="#36936610">next</a><span>|</span><label class="collapse" for="c-36937011">[-]</label><label class="expand" for="c-36937011">[3 more]</label></div><br/><div class="children"><div class="content">Realism doesn&#x27;t work in business. Business success requires 10 people to try for 1 person to succeed. If those 10 people were realists, they wouldn&#x27;t try.</div><br/><div id="36937569" class="c"><input type="checkbox" id="c-36937569" checked=""/><div class="controls bullet"><span class="by">worldsayshi</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937011">parent</a><span>|</span><a href="#36936610">next</a><span>|</span><label class="collapse" for="c-36937569">[-]</label><label class="expand" for="c-36937569">[2 more]</label></div><br/><div class="children"><div class="content">Depends how much that one person wins and how much the others lose.</div><br/></div></div></div></div></div></div><div id="36936610" class="c"><input type="checkbox" id="c-36936610" checked=""/><div class="controls bullet"><span class="by">dhash</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36935423">parent</a><span>|</span><a href="#36936311">prev</a><span>|</span><a href="#36937441">next</a><span>|</span><label class="collapse" for="c-36936610">[-]</label><label class="expand" for="c-36936610">[1 more]</label></div><br/><div class="children"><div class="content">YC startup founder here,<p>Mostly agree, except the market is not an optimistic place — it’s the market.<p>There are a multitude of reasons you lose your optimism, mostly because people take it away — your  optimism is their money</div><br/></div></div><div id="36937441" class="c"><input type="checkbox" id="c-36937441" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36935423">parent</a><span>|</span><a href="#36936610">prev</a><span>|</span><a href="#36937037">next</a><span>|</span><label class="collapse" for="c-36937441">[-]</label><label class="expand" for="c-36937441">[1 more]</label></div><br/><div class="children"><div class="content">What a beautiful and articulate thought. thank you</div><br/></div></div></div></div></div></div><div id="36937037" class="c"><input type="checkbox" id="c-36937037" checked=""/><div class="controls bullet"><span class="by">zak</span><span>|</span><a href="#36934431">parent</a><span>|</span><a href="#36935095">prev</a><span>|</span><a href="#36939997">next</a><span>|</span><label class="collapse" for="c-36937037">[-]</label><label class="expand" for="c-36937037">[14 more]</label></div><br/><div class="children"><div class="content">Actually, the TPU Research Cloud program is still going strong! We&#x27;ve expanded the compute pool significantly to include Cloud TPU v4 Pod slices, and larger projects still use hundreds of chips at a time. (TRC capacity has not been reclaimed for internal use.)<p>Check out this list of recent TRC-supported publications: <a href="https:&#x2F;&#x2F;sites.research.google&#x2F;trc&#x2F;publications&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;sites.research.google&#x2F;trc&#x2F;publications&#x2F;</a><p>Demand for Cloud TPUs is definitely intense, so if you&#x27;re using preemptible capacity, you&#x27;re probably seeing more frequent interruptions, but reserved capacity is also available. Hope you email the TRC support team to say hello!</div><br/><div id="36937244" class="c"><input type="checkbox" id="c-36937244" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937037">parent</a><span>|</span><a href="#36938275">next</a><span>|</span><label class="collapse" for="c-36937244">[-]</label><label class="expand" for="c-36937244">[11 more]</label></div><br/><div class="children"><div class="content">Zak, I love you buddy, but you should have some of your researchers try to use the TRC program. They should pretend to be a nobody (like I was in 2019) and try to do any research with the resources they’re granted. I guarantee you those researchers will all tell you “we can’t start any training runs anymore because the TPUs die after 45 minutes.”<p>This may feel like an anime betrayal, since you basically launched my career as a scientist. But it’s important for hobbyists and tinkerers to be able to participate in the AI ecosystem, especially today. And TRC just does not support them anymore. I tried, many times, over the last year and a half.<p>You don’t need to take my word for it. Here’s some unfiltered DMs on the subject:  <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;6vqvzXs" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;6vqvzXs</a><p>Notice how their optimism dries up, and not because I was telling them how bad TRC has become. It’s because their TPUs kept dying.<p>I held out hope for so long. I thought it was temporary. It ain’t temporary, Zak. And I vividly remember when it happened. Some smart person in google proposed a new allocation algorithm back near the end of 2021, and poof, overnight our ability to make TPUs went from dozens to a handful. It was quite literally overnight; we had monitoring graphs that flatlined. I can probably still dig them up.<p>I’ve wanted to email you privately about this, but given that I am a small fish in a pond that’s grown exponentially bigger, I don’t think it would’ve made a difference. The difference is in your last paragraph: you allocate reserved instances to those who deserve it, and leave everybody else to fight over 45 minutes of TPU time when it takes 25 minutes just to create and fill your TPU with your research data.<p>Your non-preemptible TPUs are frankly a lie. I didn’t want to drop the L word, but a TPUv3 in euw4a will literally delete itself — aka preempt — after no more than a couple hours. I tested this over many months. That was some time ago, so maybe things have changed, but I wouldn’t bet on it.<p>There’s some serious “left hand doesn’t know that right hand detached from its body and migrated south for the winter” energy in the TRC program. I don’t know where it embedded itself, but if you want to elevate any other engineers from software devs to researchers, I urge you to make some big changes.<p>One last thing. The support staff of TRC is phenomenal. Jonathan Colton has worked more miracles than I can count, along with the rest of his crew. Ultimately he had to send me an email like “by the way, TRC doesn’t delete TPUs. This distinction probably won’t be too relevant, but I wanted to let you know” (paraphrasing). Translation: you took the power away from the people who knew where to put it (Jonathan) and gave it to some really important researchers, probably in Brain or some other division of Google. And the rest is history. So I don’t want to hear that one of the changes is “ok, we’ve punished the support staff” - as far as I can tell, they’ve moved mountains with whatever tools they had available, and I definitely wouldn’t have been able to do any better in their shoes.<p>Also, hello. Thanks for launching my career. Sorry that I had to leave this here, but my duty is to the open source community. The good news is that you can still recover, if only you’d revert this silly “we’ll slip you some reserved TPUs that don’t kamikaze themselves after 45 minutes if you ask in just the right way” stuff. That wasn’t how the program was in 2019, and I guarantee that I couldn’t have done the work I did then under the current conditions.</div><br/><div id="36937557" class="c"><input type="checkbox" id="c-36937557" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937244">parent</a><span>|</span><a href="#36937636">next</a><span>|</span><label class="collapse" for="c-36937557">[-]</label><label class="expand" for="c-36937557">[7 more]</label></div><br/><div class="children"><div class="content">&gt; You don’t need to take my word for it. Here’s some unfiltered DMs on the subject: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;6vqvzXs" rel="nofollow noreferrer">https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;6vqvzXs</a><p>&gt; Notice how their optimism dries up, and not because I was telling them how bad TRC has become. It’s because their TPUs kept dying.<p>Unless I&#x27;m misreading this they sound pretty happy and you sound pessimistic? Their last substantial comment was &quot;I&#x27;m sure Zak could hook you up with something better&quot;?</div><br/><div id="36937683" class="c"><input type="checkbox" id="c-36937683" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937557">parent</a><span>|</span><a href="#36937636">next</a><span>|</span><label class="collapse" for="c-36937683">[-]</label><label class="expand" for="c-36937683">[6 more]</label></div><br/><div class="children"><div class="content">TRC is supposed to be the “something better”. This insider TPU stuff is for the birds. If TRC can only offer 4 hours with no preemptions, that’s fine, but they need to be up front about that. Saying that TPUs preempt every 24 hours and then killing them off after 45 minutes is… not very productive.<p>As for their comments, the third screenshot is the key; they’re agreeing that the situation is bad. They’re a friend, and they’re a little indirect with the way they phrase things. (If you’ve ever had a friend who really doesn’t want to be wrong, you know what I mean; they kind of say things in a circular way in order to agree without agreeing. After awhile it’s pretty cute and endearing though.)<p>I was particularly pessimistic in those DMs because it came a couple months after I thought I’d give TRC one last try, back in January, which was roughly a year after I’d started my “ok, I’m losing hope, but I’ll wait and see” journey. In the meantime I kept cheerleading TRC and driving people to their signup page. But after the TPUs all died in less than two hours yet again, that was that.<p>I have a really high tolerance for faulty equipment. This is free compute; me complaining is just ungrateful. But I saw what things were like in 2019. “Different” would be the understatement of the century. If my baby wasn’t being incubated in the NICU today, I’d show the charts where our usage went from thousands of cores down to almost zero, and not for lack of trying.<p>It also would’ve been fine to say “sorry, this is unsustainable, the new limits are one tpu per person per project” and then give me a rock solid tpu. We had those in 2021. One of our TPUv3s stayed online for so long that I started to host my blog on it just to show people that TPUs were good for more than AI; the uptime was measured in months. Then poof, now you can barely fire one up.</div><br/><div id="36938206" class="c"><input type="checkbox" id="c-36938206" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937683">parent</a><span>|</span><a href="#36938390">next</a><span>|</span><label class="collapse" for="c-36938206">[-]</label><label class="expand" for="c-36938206">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have a qualified opinion on the subject of TPU availability.<p>I&#x27;m just pointing out that your summary of the DMs (&quot;Notice how their optimism dries up, and not because I was telling them how bad TRC has become. It’s because their TPUs kept dying&quot;) is the opposite of what the DMs show.</div><br/></div></div><div id="36938390" class="c"><input type="checkbox" id="c-36938390" checked=""/><div class="controls bullet"><span class="by">zak</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937683">parent</a><span>|</span><a href="#36938206">prev</a><span>|</span><a href="#36938902">next</a><span>|</span><label class="collapse" for="c-36938390">[-]</label><label class="expand" for="c-36938390">[1 more]</label></div><br/><div class="children"><div class="content">As mentioned in another comment, it sounds like you&#x27;re using preemptible TRC TPU quota. If you use on-demand TRC TPU quota instead, that should improve your uptime substantially.</div><br/></div></div><div id="36938902" class="c"><input type="checkbox" id="c-36938902" checked=""/><div class="controls bullet"><span class="by">KirillPanov</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937683">parent</a><span>|</span><a href="#36938390">prev</a><span>|</span><a href="#36937636">next</a><span>|</span><label class="collapse" for="c-36938902">[-]</label><label class="expand" for="c-36938902">[3 more]</label></div><br/><div class="children"><div class="content">This is totally fascinating.<p>Frankly, it sounds to me like they&#x27;re having severe yield+reliability problems with the TPUv4s that aren&#x27;t getting caught by wafer-level testing, and have binned the flakiest ones for use by outsiders.<p>A lot of yield issues show up as spontaneous resets&#x2F;crashes.</div><br/><div id="36938929" class="c"><input type="checkbox" id="c-36938929" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36938902">parent</a><span>|</span><a href="#36937636">next</a><span>|</span><label class="collapse" for="c-36938929">[-]</label><label class="expand" for="c-36938929">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s more likely Google preempting researcher who are on a preemptable research grant, and it is happening a lot more often because there are more paying customers.</div><br/><div id="36939048" class="c"><input type="checkbox" id="c-36939048" checked=""/><div class="controls bullet"><span class="by">KirillPanov</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36938929">parent</a><span>|</span><a href="#36937636">next</a><span>|</span><label class="collapse" for="c-36939048">[-]</label><label class="expand" for="c-36939048">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Preemptable money&quot; sounds like the kind of bullshit I would use to cover up failed chips.  And yes, I am a VLSI engineer.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36937636" class="c"><input type="checkbox" id="c-36937636" checked=""/><div class="controls bullet"><span class="by">zak</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937244">parent</a><span>|</span><a href="#36937557">prev</a><span>|</span><a href="#36938275">next</a><span>|</span><label class="collapse" for="c-36937636">[-]</label><label class="expand" for="c-36937636">[3 more]</label></div><br/><div class="children"><div class="content">A few quick comments:<p>&gt; But it’s important for hobbyists and tinkerers to be able to participate in the AI ecosystem<p>Totally agree! This was a big part of my original motivation for creating the TPU Research Cloud program. People sometimes assume that e.g. an academic affiliation is required to participate, but that isn&#x27;t true; we want the program to be as open as possible. We should find a better way to highlight the work of TRC tinkerers - for now, the GitHub and Hugging Face search buttons near the top of <a href="https:&#x2F;&#x2F;sites.research.google&#x2F;trc&#x2F;publications&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;sites.research.google&#x2F;trc&#x2F;publications&#x2F;</a> provide some raw pointers.<p>I&#x27;m sorry to hear that you&#x27;ve personally had a hard time getting TPU v3 capacity in europe-west4-a. In general, TRC TPU availability varies by region and by hardware generation, and we&#x27;ve experimented with different ways of prioritizing projects. It&#x27;s possible that something was misconfigured on our end if your TPU lifetimes were so short. Could you email Jonathan the name of the project(s) you were using and any other data you still have handy so we can figure out what was going wrong?<p>Also, thanks for the kind words for Jonathan and the rest of the TRC team. They haven&#x27;t lost any power or control, and they are allocating a lot more Cloud TPU capacity than ever. However, now that everyone wants to train LLMs, diffusion models, and other exciting new things, demand for TPU compute is way up, so juggling all of the inbound TRC requests is definitely more challenging than it used to be.</div><br/><div id="36937723" class="c"><input type="checkbox" id="c-36937723" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937636">parent</a><span>|</span><a href="#36938275">next</a><span>|</span><label class="collapse" for="c-36937723">[-]</label><label class="expand" for="c-36937723">[2 more]</label></div><br/><div class="children"><div class="content">It’s not euw4a. It’s everywhere. The allocation algorithm across the board kills off TPUs after no more than a couple hours. usc1f, usc1a, usc1c, euw4a; it makes no difference.<p>It would be funny if someone set gpt-2-15b-poetry (our project) in some special way to prevent us from making TPUs that ever last more than a few hours, but from what I’ve heard from other people, this isn’t the case. That’s what I mean about the left hand doesn’t know what’s going on with the right hand. It’s not a misconfiguration. Again, pretend to be some random person who just wants to apply for TPU access, fill out your form, then try to do research with the TPUs that are available to you. You’ll have a rough time, but it’ll also cure this misconception that it’s a special case or was just me.<p>Again, no need to take my word for it; here’s an organic comment from someone who was rolling their eyes whenever I was cheerleading TRC, because their experience was so bad: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36936782">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36936782</a><p>I think that the experience is probably great for researchers who get special approval. And that’s fine, if that’s how the program is designed to be. But at least tell people that they shouldn’t expect more than an hour or two of TPU time.</div><br/><div id="36938345" class="c"><input type="checkbox" id="c-36938345" checked=""/><div class="controls bullet"><span class="by">zak</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937723">parent</a><span>|</span><a href="#36938275">next</a><span>|</span><label class="collapse" for="c-36938345">[-]</label><label class="expand" for="c-36938345">[1 more]</label></div><br/><div class="children"><div class="content">It sounds like you&#x27;re primarily using preemptible TPU quota, which doesn&#x27;t come with any availability or uptime expectations at all.<p>By default, the TRC program grants both on-demand quota and preemptible quota. If you are able to create a TPU VM with your on-demand quota, it should last quite a bit longer than a few hours. (There are situations in which on-demand TRC TPU VMs can be interrupted, but these ought to be rare.) If your on-demand TPU VMs are being interrupted frequently, please email TRC support and provide the names of the TPU hosts that were interrupted so folks can try to help.<p>When there is very high demand for Cloud TPUs, it&#x27;s certainly possible for preemptible TPU VMs to be interrupted frequently. It would be an interesting engineering project to make a very robust training system that could make progress even with low TPU VM uptime, and I hope someone does it! Until then, though, you should have a better experience with on-demand resources when you&#x27;re able to create them. Reserved capacity is even better since it provides an expectation of both availability and uptime.</div><br/></div></div></div></div></div></div></div></div><div id="36938275" class="c"><input type="checkbox" id="c-36938275" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937037">parent</a><span>|</span><a href="#36937244">prev</a><span>|</span><a href="#36939997">next</a><span>|</span><label class="collapse" for="c-36938275">[-]</label><label class="expand" for="c-36938275">[2 more]</label></div><br/><div class="children"><div class="content">Main problem with the TPU Research Cloud is you get dragged down a LOT by the buggy TPU API-- not just the Google Cloud API being awful but the Tensorflow&#x2F;Jax&#x2F;Pytorch support also being awful too.  You also basically must use Google Cloud Storage, which is also slow and can be really expensive getting anything into &#x2F; out-of.<p>The Googlers maintaining the TPU Github repo also just basically don&#x27;t care about your PR unless it&#x27;s somehow gonna help them in their own perf review.<p>In contrast with a GPU-based grid, you can not only run the latest &amp; greatest out-of-the-box but also do a lot of local testing that saves tons of time.<p>Finally, the OP here appears to be offering real customer engagement, which is totally absent from my own GCloud experiences across several companies.</div><br/><div id="36938435" class="c"><input type="checkbox" id="c-36938435" checked=""/><div class="controls bullet"><span class="by">zak</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36938275">parent</a><span>|</span><a href="#36939997">next</a><span>|</span><label class="collapse" for="c-36938435">[-]</label><label class="expand" for="c-36938435">[1 more]</label></div><br/><div class="children"><div class="content">Could you share a few technical details about the issues you&#x27;ve encountered with TF &#x2F; JAX &#x2F; PyTorch on Cloud TPUs? The overall Cloud TPU user experience improved a whole lot when we enabled direct access to TPU VMs, and I believe the newer JAX and PyTorch integrations are improving very rapidly. I&#x27;d love to know which issues are currently causing the most friction.</div><br/></div></div></div></div></div></div><div id="36939997" class="c"><input type="checkbox" id="c-36939997" checked=""/><div class="controls bullet"><span class="by">nwoli</span><span>|</span><a href="#36934431">parent</a><span>|</span><a href="#36937037">prev</a><span>|</span><a href="#36934741">next</a><span>|</span><label class="collapse" for="c-36939997">[-]</label><label class="expand" for="c-36939997">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In 2023 you can barely get a single TPU for more than an hour<p>Oh come on, colab gives TPU access in the free tier for a whole half day. No need to exaggerate the shortage</div><br/></div></div><div id="36934741" class="c"><input type="checkbox" id="c-36934741" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#36934431">parent</a><span>|</span><a href="#36939997">prev</a><span>|</span><a href="#36937003">next</a><span>|</span><label class="collapse" for="c-36934741">[-]</label><label class="expand" for="c-36934741">[1 more]</label></div><br/><div class="children"><div class="content">What Shawn says is absolutely right. The race right now is way too hot for this stuff. A single customer will eat up 512 gpus for 3 years.</div><br/></div></div><div id="36937003" class="c"><input type="checkbox" id="c-36937003" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#36934431">parent</a><span>|</span><a href="#36934741">prev</a><span>|</span><a href="#36936782">next</a><span>|</span><label class="collapse" for="c-36937003">[-]</label><label class="expand" for="c-36937003">[1 more]</label></div><br/><div class="children"><div class="content">My experience has been different. Considering how easy the application is I think they&#x27;re still being fairly generous as I&#x27;ve been offered multiple v3-8s and v3-32s x 30days as well as pre-emptible v3-64s x 28 days for a few different projects within the last 6 months.<p>Are you affiliated with an academic institution? Otherwise I&#x27;m not sure why they&#x27;re been more generous with me, my projects have been mildly interesting at best.<p>They&#x27;re certainly a lot stingier with larger pods than they used to be though.</div><br/></div></div><div id="36936782" class="c"><input type="checkbox" id="c-36936782" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#36934431">parent</a><span>|</span><a href="#36937003">prev</a><span>|</span><a href="#36934865">next</a><span>|</span><label class="collapse" for="c-36936782">[-]</label><label class="expand" for="c-36936782">[1 more]</label></div><br/><div class="children"><div class="content">Wow! I never thought you’d see the light. All I ever see from your posts is praise for TRC. As someone who got started way later on, I had infinitely more success with a gaming GPU I owned myself. Obviously not really comparable, but TRC was very very difficult to work with. I think I only ever had access to a TPUv3 once and that wasn’t nearly enough time to learn the ropes.<p>My understanding was that this situation changed drastically depending on what sort of email you had or how popular your Twitter handle was.</div><br/></div></div><div id="36934865" class="c"><input type="checkbox" id="c-36934865" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#36934431">parent</a><span>|</span><a href="#36936782">prev</a><span>|</span><a href="#36936414">next</a><span>|</span><label class="collapse" for="c-36934865">[-]</label><label class="expand" for="c-36934865">[11 more]</label></div><br/><div class="children"><div class="content">&gt; In 2023 you can barely get a single TPU for more than an hour.<p>Um. Can&#x27;t you order them from coral.ai and put them in an NVMe slot? Or are the cloud TPUs more powerful?</div><br/><div id="36934907" class="c"><input type="checkbox" id="c-36934907" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36934865">parent</a><span>|</span><a href="#36936414">next</a><span>|</span><label class="collapse" for="c-36934907">[-]</label><label class="expand" for="c-36934907">[10 more]</label></div><br/><div class="children"><div class="content">TPU pod is not sold by google, edge tpu is different</div><br/><div id="36934921" class="c"><input type="checkbox" id="c-36934921" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36934907">parent</a><span>|</span><a href="#36936414">next</a><span>|</span><label class="collapse" for="c-36934921">[-]</label><label class="expand" for="c-36934921">[9 more]</label></div><br/><div class="children"><div class="content">So the cloud TPUs are more powerful...? Or what are you saying?</div><br/><div id="36934939" class="c"><input type="checkbox" id="c-36934939" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36934921">parent</a><span>|</span><a href="#36937891">next</a><span>|</span><label class="collapse" for="c-36934939">[-]</label><label class="expand" for="c-36934939">[4 more]</label></div><br/><div class="children"><div class="content">Yeah, it’s a silly branding thing.<p>One TPU (not even a pod, just a regular old TPUv2) has 96 CPU cores with 1.4TB of RAM, and that’s not even counting their hardware acceleration. I’d love to buy one.</div><br/><div id="36936962" class="c"><input type="checkbox" id="c-36936962" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36934939">parent</a><span>|</span><a href="#36937891">next</a><span>|</span><label class="collapse" for="c-36936962">[-]</label><label class="expand" for="c-36936962">[3 more]</label></div><br/><div class="children"><div class="content">Huh, this doesn&#x27;t seem right. Based on #s you seem to be referring to pods but even then I&#x27;m not familiar with such a configuration existing.<p>A single TPUv2 chip has 1 core and 8gb of memory. A single device comes in the v2-8 configuration with 8 cores and 64gb of memory.<p>Pod variants come in v2-32 to v2-512 configurations.</div><br/><div id="36937866" class="c"><input type="checkbox" id="c-36937866" checked=""/><div class="controls bullet"><span class="by">simonster</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36936962">parent</a><span>|</span><a href="#36937891">next</a><span>|</span><label class="collapse" for="c-36937866">[-]</label><label class="expand" for="c-36937866">[2 more]</label></div><br/><div class="children"><div class="content">A single TPUv2 host has 8 TPU cores with 64GB of total HBM (8GB per core), but like GPUs, TPUs can&#x27;t directly access a network, so the host also needs CPUs and standard RAM to send data to them. They are fast, and the host has to be fast enough to keep them fed with data, so the host is pretty beefy. But FWIW, a TPUv2 host has somewhere around 330GB of RAM, not 1.4TB.</div><br/><div id="36938860" class="c"><input type="checkbox" id="c-36938860" checked=""/><div class="controls bullet"><span class="by">haldujai</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937866">parent</a><span>|</span><a href="#36937891">next</a><span>|</span><label class="collapse" for="c-36938860">[-]</label><label class="expand" for="c-36938860">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for clarifying, I misinterpreted the commenter as referring to the accelerator as the conversation was about TPU availability for purchase.<p>I know just enough about the architecture to facilitate using TPUs for research training runs but I&#x27;m not sure what&#x27;s so special about the host?<p>Sure it&#x27;s beefy but there are much beefier servers readily available.</div><br/></div></div></div></div></div></div></div></div><div id="36937891" class="c"><input type="checkbox" id="c-36937891" checked=""/><div class="controls bullet"><span class="by">dgacmu</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36934921">parent</a><span>|</span><a href="#36934939">prev</a><span>|</span><a href="#36937828">next</a><span>|</span><label class="collapse" for="c-36937891">[-]</label><label class="expand" for="c-36937891">[2 more]</label></div><br/><div class="children"><div class="content">Edge TPUs are low cost, low power inference devices the size of a dime. I have a hundred of them sitting in a closet. (Alas. Anyone want to buy 100 coral minis? :-)<p>The TPUs you rent that are being discussed here are capable of training, consume hundreds of watts and have a heatsink bigger than your fist and really spectacular network links. They&#x27;re analogous to Nvidia&#x27;s highest end GPUs from a &quot;what can you do with them&quot; perspective.<p>Both are custom chips for deep learning but they&#x27;re completely different beasts.</div><br/><div id="36937932" class="c"><input type="checkbox" id="c-36937932" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36937891">parent</a><span>|</span><a href="#36937828">next</a><span>|</span><label class="collapse" for="c-36937932">[-]</label><label class="expand" for="c-36937932">[1 more]</label></div><br/><div class="children"><div class="content">Can I hook a microphone up to a Coral Mini and run Whisper? I&#x27;d love to have a home assistant that wasn&#x27;t on the cloud.<p>As for the rest of them, list them on Amazon and let them do the fulfillment. That $10k of hardware isn&#x27;t going to sell itself from your closet. (Yet. LLMs are making great strides.)</div><br/></div></div></div></div><div id="36937828" class="c"><input type="checkbox" id="c-36937828" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36934921">parent</a><span>|</span><a href="#36937891">prev</a><span>|</span><a href="#36934925">next</a><span>|</span><label class="collapse" for="c-36937828">[-]</label><label class="expand" for="c-36937828">[1 more]</label></div><br/><div class="children"><div class="content">They are entirely different chips - like an order of magnitude in terms if transistor count and die size.</div><br/></div></div><div id="36934925" class="c"><input type="checkbox" id="c-36934925" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#36934431">root</a><span>|</span><a href="#36934921">parent</a><span>|</span><a href="#36937828">prev</a><span>|</span><a href="#36936414">next</a><span>|</span><label class="collapse" for="c-36934925">[-]</label><label class="expand" for="c-36934925">[1 more]</label></div><br/><div class="children"><div class="content">yes</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36936414" class="c"><input type="checkbox" id="c-36936414" checked=""/><div class="controls bullet"><span class="by">whack</span><span>|</span><a href="#36934431">prev</a><span>|</span><a href="#36939384">next</a><span>|</span><label class="collapse" for="c-36936414">[-]</label><label class="expand" for="c-36936414">[13 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Rather than each of K startups individually buying clusters of N gpus, together we buy a cluster with NK gpus... Then we set up a job scheduler to allocate compute</i><p>In theory, this sounds almost identical to the business model behind AWS, Azure, and other cloud providers. &quot;Instead of everyone buying a fixed amount of hardware for individual use, we&#x27;ll buy a massive pool of hardware that people can time-share.&quot; Outside of cloud providers having to mark up prices to give themselves a net-margin, is there something else they are failing to do, hence creating the need for these projects?</div><br/><div id="36937749" class="c"><input type="checkbox" id="c-36937749" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36936414">parent</a><span>|</span><a href="#36937020">next</a><span>|</span><label class="collapse" for="c-36937749">[-]</label><label class="expand" for="c-36937749">[3 more]</label></div><br/><div class="children"><div class="content">Couple things, mostly pricing and availability:<p>1) Margins. Public cloud investors expect a certain margin profile. They can’t compete with Lambda&#x2F;Fluidstack’s margins.<p>2) To an extent also big clouds have worse networking for LLM training. I believe only Azure has infiniband. Oracle is 3200 Gbps but not infiniband, same for AWS I believe. GCP not sure but their A100 networking speeds were only 100 Gbps I believe rather than 1600. Whereas lambda, fluidstack and coreweave all have ib.<p>3) Availability. Nvidia isn’t giving big clouds the allocation they want.</div><br/><div id="36939068" class="c"><input type="checkbox" id="c-36939068" checked=""/><div class="controls bullet"><span class="by">TylerE</span><span>|</span><a href="#36936414">root</a><span>|</span><a href="#36937749">parent</a><span>|</span><a href="#36939413">next</a><span>|</span><label class="collapse" for="c-36939068">[-]</label><label class="expand" for="c-36939068">[1 more]</label></div><br/><div class="children"><div class="content">Low margins and “will this thing still be around in 2 years” are negatively correlated.<p>Where’s the capital for upgrades, repairs, and replacements coming from?</div><br/></div></div><div id="36939413" class="c"><input type="checkbox" id="c-36939413" checked=""/><div class="controls bullet"><span class="by">bravura</span><span>|</span><a href="#36936414">root</a><span>|</span><a href="#36937749">parent</a><span>|</span><a href="#36939068">prev</a><span>|</span><a href="#36937020">next</a><span>|</span><label class="collapse" for="c-36939413">[-]</label><label class="expand" for="c-36939413">[1 more]</label></div><br/><div class="children"><div class="content">What is your differentiator from Lambda? That you are smaller and in a single DC?<p>Sincere question.</div><br/></div></div></div></div><div id="36937020" class="c"><input type="checkbox" id="c-36937020" checked=""/><div class="controls bullet"><span class="by">aabhay</span><span>|</span><a href="#36936414">parent</a><span>|</span><a href="#36937749">prev</a><span>|</span><a href="#36936524">next</a><span>|</span><label class="collapse" for="c-36937020">[-]</label><label class="expand" for="c-36937020">[2 more]</label></div><br/><div class="children"><div class="content">They are working on this. All the major clouds have initiatives to do short term requests&#x2F;reservations. It’s just not a feature that has ever been of much use pre-GenAI. How often do you need to request 1000 CPU nodes for 48 hours in a single zone?<p>Secondly, there is a fundamental question of resource sharing here. Even with this project by Evan and AI Grant (the second such cluster created by AI Grant btw), the question will arise — if one team has enough money to provision the entire cluster forever, why not do it? What are the exact parameters of fair use? In networking, we have algorithms around bandwidth sharing (TCP Fairness, etc.) that encode sharing mechanisms but they don’t work for these kinds of chunky workloads either.<p>But over the next few months, AWS and others are working to release queueing services that let you temporarily provision a chunk of compute, probably with upfront payment, and at a high expense (perhaps above the on demand rate).</div><br/><div id="36937289" class="c"><input type="checkbox" id="c-36937289" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#36936414">root</a><span>|</span><a href="#36937020">parent</a><span>|</span><a href="#36936524">next</a><span>|</span><label class="collapse" for="c-36937289">[-]</label><label class="expand" for="c-36937289">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It’s just not a feature that has ever been of much use pre-GenAI. How often do you need to request 1000 CPU nodes for 48 hours in a single zone?<p>I would srgue this has always been a common case for cloud GPU compute</div><br/></div></div></div></div><div id="36936524" class="c"><input type="checkbox" id="c-36936524" checked=""/><div class="controls bullet"><span class="by">abraae</span><span>|</span><a href="#36936414">parent</a><span>|</span><a href="#36937020">prev</a><span>|</span><a href="#36939384">next</a><span>|</span><label class="collapse" for="c-36936524">[-]</label><label class="expand" for="c-36936524">[7 more]</label></div><br/><div class="children"><div class="content">AWS and Azure would slit their own throats before they created a way for their customers to pool instances to save money.<p>They want to do that themselves, and keep the customer relationship and the profits, instead of giving them to a middleman or the customer.</div><br/><div id="36936767" class="c"><input type="checkbox" id="c-36936767" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#36936414">root</a><span>|</span><a href="#36936524">parent</a><span>|</span><a href="#36937606">next</a><span>|</span><label class="collapse" for="c-36936767">[-]</label><label class="expand" for="c-36936767">[5 more]</label></div><br/><div class="children"><div class="content">It’s just corporate profits combined with market forces, not a some sort of malicious conspiracy.<p>You can rent a 2-socket AMD server with 120 available cores and RDMA for something like 50c to $2 per hour. That’s just barely above the cost of the electricity and cooling!<p>What do you want, free compute just handed to you out of the goodness of their hearts?<p>There is incredible demand for high-end GPUs right now, and market prices reflect that.</div><br/><div id="36936932" class="c"><input type="checkbox" id="c-36936932" checked=""/><div class="controls bullet"><span class="by">abraae</span><span>|</span><a href="#36936414">root</a><span>|</span><a href="#36936767">parent</a><span>|</span><a href="#36937180">next</a><span>|</span><label class="collapse" for="c-36936932">[-]</label><label class="expand" for="c-36936932">[1 more]</label></div><br/><div class="children"><div class="content">You mentioned malicious conspiracy, not me.<p>It&#x27;s just business and I&#x27;d do the same if I was in charge of AWS.</div><br/></div></div><div id="36937180" class="c"><input type="checkbox" id="c-36937180" checked=""/><div class="controls bullet"><span class="by">mikeravkine</span><span>|</span><a href="#36936414">root</a><span>|</span><a href="#36936767">parent</a><span>|</span><a href="#36936932">prev</a><span>|</span><a href="#36937232">next</a><span>|</span><label class="collapse" for="c-36937180">[-]</label><label class="expand" for="c-36937180">[1 more]</label></div><br/><div class="children"><div class="content">Sorry where are these .50c many core servers you speak of exactly?</div><br/></div></div><div id="36937232" class="c"><input type="checkbox" id="c-36937232" checked=""/><div class="controls bullet"><span class="by">megakwood</span><span>|</span><a href="#36936414">root</a><span>|</span><a href="#36936767">parent</a><span>|</span><a href="#36937180">prev</a><span>|</span><a href="#36937522">next</a><span>|</span><label class="collapse" for="c-36937232">[-]</label><label class="expand" for="c-36937232">[1 more]</label></div><br/><div class="children"><div class="content">Where can you get 120 cores for $2&#x2F;hr?</div><br/></div></div><div id="36937522" class="c"><input type="checkbox" id="c-36937522" checked=""/><div class="controls bullet"><span class="by">alex_lav</span><span>|</span><a href="#36936414">root</a><span>|</span><a href="#36936767">parent</a><span>|</span><a href="#36937232">prev</a><span>|</span><a href="#36937606">next</a><span>|</span><label class="collapse" for="c-36937522">[-]</label><label class="expand" for="c-36937522">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You can rent a 2-socket AMD server with 120 available cores and RDMA for something like 50c to $2 per hour.<p>Source required</div><br/></div></div></div></div><div id="36937606" class="c"><input type="checkbox" id="c-36937606" checked=""/><div class="controls bullet"><span class="by">asdfaoeu</span><span>|</span><a href="#36936414">root</a><span>|</span><a href="#36936524">parent</a><span>|</span><a href="#36936767">prev</a><span>|</span><a href="#36939384">next</a><span>|</span><label class="collapse" for="c-36937606">[-]</label><label class="expand" for="c-36937606">[1 more]</label></div><br/><div class="children"><div class="content">AWS and Azure both charge by the hour anyway so it wouldn&#x27;t but if you wanted you could use Reserved instances and just have their accounts in the same organisation.<p>A large part of the profit comes from the upfront risk of buying machines. With this you are just absorbing that risk which may be better if the startup expects to last.</div><br/></div></div></div></div></div></div><div id="36939384" class="c"><input type="checkbox" id="c-36939384" checked=""/><div class="controls bullet"><span class="by">wodenokoto</span><span>|</span><a href="#36936414">prev</a><span>|</span><a href="#36936436">next</a><span>|</span><label class="collapse" for="c-36939384">[-]</label><label class="expand" for="c-36939384">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s just that no cloud provider in the world will give you $100k of compute for just a couple weeks<p>I&#x27;ve never had to buy very large compute, but I thought that was the whole point of the cloud</div><br/></div></div><div id="36936436" class="c"><input type="checkbox" id="c-36936436" checked=""/><div class="controls bullet"><span class="by">bnr4u</span><span>|</span><a href="#36939384">prev</a><span>|</span><a href="#36937802">next</a><span>|</span><label class="collapse" for="c-36936436">[-]</label><label class="expand" for="c-36936436">[6 more]</label></div><br/><div class="children"><div class="content">Having hosted infrastructure in CA at multiple colos. I would advise you to host it elsewhere if you can, cost of power, other infrastructure is much higher in CA than AZ or NV.</div><br/><div id="36937145" class="c"><input type="checkbox" id="c-36937145" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#36936436">parent</a><span>|</span><a href="#36937802">next</a><span>|</span><label class="collapse" for="c-36937145">[-]</label><label class="expand" for="c-36937145">[5 more]</label></div><br/><div class="children"><div class="content">Power seems like a very small amount of cost of compute when it comes to GPU’s.</div><br/><div id="36937429" class="c"><input type="checkbox" id="c-36937429" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#36936436">root</a><span>|</span><a href="#36937145">parent</a><span>|</span><a href="#36937432">next</a><span>|</span><label class="collapse" for="c-36937429">[-]</label><label class="expand" for="c-36937429">[3 more]</label></div><br/><div class="children"><div class="content">FWIW I tired to look up some numbers, i found California &quot;industrial&quot; electricity at $0.18&#x2F;Kwh <a href="https:&#x2F;&#x2F;www.eia.gov&#x2F;electricity&#x2F;monthly&#x2F;epm_table_grapher.php?t=epmt_5_6_a" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.eia.gov&#x2F;electricity&#x2F;monthly&#x2F;epm_table_grapher.ph...</a> and H100s using 300-700w <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;h100&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;h100&#x2F;</a> which implies a worst case marginal cost of .18*.7 = $.126 &#x2F; gpu &#x2F; hour. Looks like Montana is cheapest at ~$.05 &#x2F; kwh which would bring that down to $.035. So there may be about a $0.09 California premium (vs the absolute cheapest possibility), which as you say is a small amount of the total cost, but could be material for large workloads.</div><br/><div id="36937702" class="c"><input type="checkbox" id="c-36937702" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#36936436">root</a><span>|</span><a href="#36937429">parent</a><span>|</span><a href="#36937432">next</a><span>|</span><label class="collapse" for="c-36937702">[-]</label><label class="expand" for="c-36937702">[2 more]</label></div><br/><div class="children"><div class="content">Retail residential power in the city of Santa Clara is $0.15&#x2F;KwH, I&#x27;m sure commercial could be less.  Especially if you throw some solar panels on the roof.<p>The most expensive part would be the land, but honestly there is some pretty cheap land outside the cities.</div><br/><div id="36939177" class="c"><input type="checkbox" id="c-36939177" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36936436">root</a><span>|</span><a href="#36937702">parent</a><span>|</span><a href="#36937432">next</a><span>|</span><label class="collapse" for="c-36939177">[-]</label><label class="expand" for="c-36939177">[1 more]</label></div><br/><div class="children"><div class="content">For reference, I&#x27;m in SF and paid PGE $0.50938&#x2F;KWh during peak hours, residential, last bill.</div><br/></div></div></div></div></div></div><div id="36937432" class="c"><input type="checkbox" id="c-36937432" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#36936436">root</a><span>|</span><a href="#36937145">parent</a><span>|</span><a href="#36937429">prev</a><span>|</span><a href="#36937802">next</a><span>|</span><label class="collapse" for="c-36937432">[-]</label><label class="expand" for="c-36937432">[1 more]</label></div><br/><div class="children"><div class="content">over regulation and taxes</div><br/></div></div></div></div></div></div><div id="36937802" class="c"><input type="checkbox" id="c-36937802" checked=""/><div class="controls bullet"><span class="by">dudus</span><span>|</span><a href="#36936436">prev</a><span>|</span><a href="#36934602">next</a><span>|</span><label class="collapse" for="c-36937802">[-]</label><label class="expand" for="c-36937802">[2 more]</label></div><br/><div class="children"><div class="content">I know AWS&#x2F;GCP&#x2F;Azure have overhead and I understand why so many companies choose to go bare metal on their ops. I personally rarely think it&#x27;s worth the time and effort, but I get that with scale saving can be substantial.<p>But for AI training? If the public cloud isn&#x27;t competitive even for bursty AI training, their margins are much higher than I anticipated.<p>OP mentions 10-20x cost reduction? Compared to what? AWS?</div><br/><div id="36940030" class="c"><input type="checkbox" id="c-36940030" checked=""/><div class="controls bullet"><span class="by">jerjerjer</span><span>|</span><a href="#36937802">parent</a><span>|</span><a href="#36934602">next</a><span>|</span><label class="collapse" for="c-36940030">[-]</label><label class="expand" for="c-36940030">[1 more]</label></div><br/><div class="children"><div class="content">AWS offers p5.48xlarge which is 8xH100 for $98.32, so 12.29$ per hour per H100 - ~6x the price.</div><br/></div></div></div></div><div id="36934602" class="c"><input type="checkbox" id="c-36934602" checked=""/><div class="controls bullet"><span class="by">williamstein</span><span>|</span><a href="#36937802">prev</a><span>|</span><a href="#36934798">next</a><span>|</span><label class="collapse" for="c-36934602">[-]</label><label class="expand" for="c-36934602">[16 more]</label></div><br/><div class="children"><div class="content">How does this compare to <a href="https:&#x2F;&#x2F;lambdalabs.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;lambdalabs.com&#x2F;</a>
?</div><br/><div id="36935032" class="c"><input type="checkbox" id="c-36935032" checked=""/><div class="controls bullet"><span class="by">flaque</span><span>|</span><a href="#36934602">parent</a><span>|</span><a href="#36935023">next</a><span>|</span><label class="collapse" for="c-36935032">[-]</label><label class="expand" for="c-36935032">[10 more]</label></div><br/><div class="children"><div class="content">Ah, we&#x27;re running a medium amount of compute at zero-margin. The point is not to go sell the Fortune 500, but to make sure a grad student can spend a $50k grant.<p>Right now, it&#x27;s pretty easy to get a few A&#x2F;H100s (Lambda is great for this), but very hard to get more than 24 at a reasonable price ($~2 an hour). One often needs to put up a 6+ month commitment, even when they may only want to run their H100s for an 8 hour training run.<p>It&#x27;s the right business decision for GPU brokers to do long term reservations and so on, and we might do so too if we were in their shoes. But we&#x27;re not in their shoes and have a very different goal: arm the rebels! Let someone who isn&#x27;t BigCorp train a model!</div><br/><div id="36935507" class="c"><input type="checkbox" id="c-36935507" checked=""/><div class="controls bullet"><span class="by">trostaft</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36935032">parent</a><span>|</span><a href="#36936192">next</a><span>|</span><label class="collapse" for="c-36935507">[-]</label><label class="expand" for="c-36935507">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but to make sure a grad student can spend a $50k grant.<p>As a graduate student, thank you. Thankfully, my workloads aren&#x27;t LLM crazy so I can get by on my old NVIDIA consumer hardware, but I have coworkers struggling to get reasonable prices&#x2F;time for larger scale hardware.</div><br/></div></div><div id="36936192" class="c"><input type="checkbox" id="c-36936192" checked=""/><div class="controls bullet"><span class="by">narrator</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36935032">parent</a><span>|</span><a href="#36935507">prev</a><span>|</span><a href="#36937199">next</a><span>|</span><label class="collapse" for="c-36936192">[-]</label><label class="expand" for="c-36936192">[6 more]</label></div><br/><div class="children"><div class="content">So what happens when some big bucks VC backed closed source LLM company buys all your compute inventory for the next 5 years?  This is not that unlikely.  Lambda Labs a little while back was completely sold out of all compute inventory.</div><br/><div id="36936484" class="c"><input type="checkbox" id="c-36936484" checked=""/><div class="controls bullet"><span class="by">xeromal</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36936192">parent</a><span>|</span><a href="#36938477">next</a><span>|</span><label class="collapse" for="c-36936484">[-]</label><label class="expand" for="c-36936484">[4 more]</label></div><br/><div class="children"><div class="content">I assume it&#x27;s up to them to say no. They did say they&#x27;re not in it to make bookoo bucks</div><br/><div id="36936558" class="c"><input type="checkbox" id="c-36936558" checked=""/><div class="controls bullet"><span class="by">agajews</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36936484">parent</a><span>|</span><a href="#36940088">next</a><span>|</span><label class="collapse" for="c-36936558">[-]</label><label class="expand" for="c-36936558">[2 more]</label></div><br/><div class="children"><div class="content">Yeah we aren’t going to let anyone book the whole thing for years. If we ever have to make the choice, we’ll choose the startups over the big companies.</div><br/><div id="36937097" class="c"><input type="checkbox" id="c-36937097" checked=""/><div class="controls bullet"><span class="by">flaque</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36936558">parent</a><span>|</span><a href="#36940088">next</a><span>|</span><label class="collapse" for="c-36937097">[-]</label><label class="expand" for="c-36937097">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, if someone doesn&#x27;t care about the cost and wants to buy whole cluster, they might be better off using an existing provider.</div><br/></div></div></div></div><div id="36940088" class="c"><input type="checkbox" id="c-36940088" checked=""/><div class="controls bullet"><span class="by">stavros</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36936484">parent</a><span>|</span><a href="#36936558">prev</a><span>|</span><a href="#36938477">next</a><span>|</span><label class="collapse" for="c-36940088">[-]</label><label class="expand" for="c-36940088">[1 more]</label></div><br/><div class="children"><div class="content">I must say, this is the worst I&#x27;ve seen &quot;beaucoup&quot; spelled.</div><br/></div></div></div></div><div id="36938477" class="c"><input type="checkbox" id="c-36938477" checked=""/><div class="controls bullet"><span class="by">gnopgnip</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36936192">parent</a><span>|</span><a href="#36936484">prev</a><span>|</span><a href="#36937199">next</a><span>|</span><label class="collapse" for="c-36938477">[-]</label><label class="expand" for="c-36938477">[1 more]</label></div><br/><div class="children"><div class="content">Presumably them buy more gpus</div><br/></div></div></div></div><div id="36937199" class="c"><input type="checkbox" id="c-36937199" checked=""/><div class="controls bullet"><span class="by">ec109685</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36935032">parent</a><span>|</span><a href="#36936192">prev</a><span>|</span><a href="#36935634">next</a><span>|</span><label class="collapse" for="c-36937199">[-]</label><label class="expand" for="c-36937199">[1 more]</label></div><br/><div class="children"><div class="content">How can you allow people to get big chunks of GPU’s without a lot of expensive slack in the system?</div><br/></div></div><div id="36935634" class="c"><input type="checkbox" id="c-36935634" checked=""/><div class="controls bullet"><span class="by">lulunananaluna</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36935032">parent</a><span>|</span><a href="#36937199">prev</a><span>|</span><a href="#36935023">next</a><span>|</span><label class="collapse" for="c-36935634">[-]</label><label class="expand" for="c-36935634">[1 more]</label></div><br/><div class="children"><div class="content">This is great. Thank you very much for your work.</div><br/></div></div></div></div><div id="36935023" class="c"><input type="checkbox" id="c-36935023" checked=""/><div class="controls bullet"><span class="by">wongarsu</span><span>|</span><a href="#36934602">parent</a><span>|</span><a href="#36935032">prev</a><span>|</span><a href="#36934984">next</a><span>|</span><label class="collapse" for="c-36935023">[-]</label><label class="expand" for="c-36935023">[2 more]</label></div><br/><div class="children"><div class="content">Very similar price, but from what I gather very different model. One important difference might be if you regularly run short-ish training runs over many GPUs. Lambdalabs might not have 256 instances to give you right now. With OP you are basically buying the right to put jobs in the job queue for their 512 GPU cluster, so running a job that needs 256 GPUs isn&#x27;t an issue (though you might wait behind someone running a 512 GPU job).<p>No idea how capacity at lambdalabs actually looks like though. Does anyone have insight how easy it is to spin up more than 2-3 instances up there?</div><br/><div id="36935181" class="c"><input type="checkbox" id="c-36935181" checked=""/><div class="controls bullet"><span class="by">agajews</span><span>|</span><a href="#36934602">root</a><span>|</span><a href="#36935023">parent</a><span>|</span><a href="#36934984">next</a><span>|</span><label class="collapse" for="c-36935181">[-]</label><label class="expand" for="c-36935181">[1 more]</label></div><br/><div class="children"><div class="content">Yeah it’s pretty hard to find a big block of GPUs that you can use for a short time, esp if you need infiniband for multinode training. Lambda I think needs a min reservation of 6-12 months if you want IB.</div><br/></div></div></div></div><div id="36934984" class="c"><input type="checkbox" id="c-36934984" checked=""/><div class="controls bullet"><span class="by">jorlow</span><span>|</span><a href="#36934602">parent</a><span>|</span><a href="#36935023">prev</a><span>|</span><a href="#36936351">next</a><span>|</span><label class="collapse" for="c-36934984">[-]</label><label class="expand" for="c-36934984">[1 more]</label></div><br/><div class="children"><div class="content">You can usually only get a few h100s at a time unless you&#x27;re committed to reserved instances (for a longer time period)</div><br/></div></div><div id="36936351" class="c"><input type="checkbox" id="c-36936351" checked=""/><div class="controls bullet"><span class="by">ivalm</span><span>|</span><a href="#36934602">parent</a><span>|</span><a href="#36934984">prev</a><span>|</span><a href="#36935053">next</a><span>|</span><label class="collapse" for="c-36936351">[-]</label><label class="expand" for="c-36936351">[1 more]</label></div><br/><div class="children"><div class="content">No real way to get a big block without commitment. Iirc smallest h100 commitment is 64gpus for 3 years (about $3M usd).</div><br/></div></div><div id="36935053" class="c"><input type="checkbox" id="c-36935053" checked=""/><div class="controls bullet"><span class="by">theptip</span><span>|</span><a href="#36934602">parent</a><span>|</span><a href="#36936351">prev</a><span>|</span><a href="#36934798">next</a><span>|</span><label class="collapse" for="c-36935053">[-]</label><label class="expand" for="c-36935053">[1 more]</label></div><br/><div class="children"><div class="content">My question too. At $2&#x2F;hr for H100 that seems more flexible? But I haven’t tried to get 10k GPU-hours on any of these services, maybe that is where the bottleneck is.</div><br/></div></div></div></div><div id="36934798" class="c"><input type="checkbox" id="c-36934798" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#36934602">prev</a><span>|</span><a href="#36936226">next</a><span>|</span><label class="collapse" for="c-36934798">[-]</label><label class="expand" for="c-36934798">[8 more]</label></div><br/><div class="children"><div class="content">I am super interested in AI on a personal level and have been involved for a number of years.<p>I have never seen a GPU crunch quite like it is right now. To anyone who is interested in hobbyist ML, I highly highly recommend using vast.ai</div><br/><div id="36936413" class="c"><input type="checkbox" id="c-36936413" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36934798">parent</a><span>|</span><a href="#36937779">next</a><span>|</span><label class="collapse" for="c-36936413">[-]</label><label class="expand" for="c-36936413">[4 more]</label></div><br/><div class="children"><div class="content">Depends on what you class as hobbyist but I am running 
a T4 for a few minutes to get acquainted with tools and concepts 
and I found modal.com really good for this. They resell AWS and GCP at the moment.
They also have A100 but T4 is all I need for now.</div><br/><div id="36936802" class="c"><input type="checkbox" id="c-36936802" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#36934798">root</a><span>|</span><a href="#36936413">parent</a><span>|</span><a href="#36937779">next</a><span>|</span><label class="collapse" for="c-36936802">[-]</label><label class="expand" for="c-36936802">[3 more]</label></div><br/><div class="children"><div class="content">Significantly more expensive than equivalent 3090 configuration if you can do model parallelism</div><br/><div id="36936850" class="c"><input type="checkbox" id="c-36936850" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36934798">root</a><span>|</span><a href="#36936802">parent</a><span>|</span><a href="#36937779">next</a><span>|</span><label class="collapse" for="c-36936850">[-]</label><label class="expand" for="c-36936850">[2 more]</label></div><br/><div class="children"><div class="content">What do you mean by this? I use less than the $30&#x2F;m free included usage.<p>I am guessing you mean at some point just buy your own 3090 as it will be cheaper than paying a cloud per second for a server-grade Nvidia setup.</div><br/><div id="36936880" class="c"><input type="checkbox" id="c-36936880" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#36934798">root</a><span>|</span><a href="#36936850">parent</a><span>|</span><a href="#36937779">next</a><span>|</span><label class="collapse" for="c-36936880">[-]</label><label class="expand" for="c-36936880">[1 more]</label></div><br/><div class="children"><div class="content">I think this is more applicable for training usecases. If you can get by with less than $30&#x2F;mo in aws compute (quite expensive) then it likely does not make a didference.<p>What I mean is that you can rent out 4 3090 GPUs for much cheaper than renting an A100 on aws because you are not paying Nvidia&#x27;s &quot;cloud tax&quot; on flops&#x2F;$</div><br/></div></div></div></div></div></div></div></div><div id="36937779" class="c"><input type="checkbox" id="c-36937779" checked=""/><div class="controls bullet"><span class="by">tikkun</span><span>|</span><a href="#36934798">parent</a><span>|</span><a href="#36936413">prev</a><span>|</span><a href="#36935919">next</a><span>|</span><label class="collapse" for="c-36937779">[-]</label><label class="expand" for="c-36937779">[1 more]</label></div><br/><div class="children"><div class="content">Additional clouds:<p>For H100s and A100s - lambda, fluidstack, runpod. Also coreweave and crusoe and oblivus and latitude<p>For non a&#x2F;h100s: vast, Tensordock, also runpod here too</div><br/></div></div><div id="36935919" class="c"><input type="checkbox" id="c-36935919" checked=""/><div class="controls bullet"><span class="by">williamstein</span><span>|</span><a href="#36934798">parent</a><span>|</span><a href="#36937779">prev</a><span>|</span><a href="#36936226">next</a><span>|</span><label class="collapse" for="c-36935919">[-]</label><label class="expand" for="c-36935919">[2 more]</label></div><br/><div class="children"><div class="content">Many thanks for posting about vast.ai, which I had never heard of!  It&#x27;s a sort of &quot;gig economy&#x2F;marketplace&quot; for GPU&#x27;s. The first machine I tried just now worked fine, had 512GB of RAM, 256 AMC CPUs, an A100 GPU, and I got about 4 minutes for $0.05 (which they provided for free).</div><br/><div id="36936857" class="c"><input type="checkbox" id="c-36936857" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#36934798">root</a><span>|</span><a href="#36935919">parent</a><span>|</span><a href="#36936226">next</a><span>|</span><label class="collapse" for="c-36936857">[-]</label><label class="expand" for="c-36936857">[1 more]</label></div><br/><div class="children"><div class="content">The only caveat is it is not really appropriate for private usecases.<p>Also, many of the available options clearly are recycled crypto mining rigs which have somewhat odd configurations (poor gpu bandwidth, low cpu ram).</div><br/></div></div></div></div></div></div><div id="36936226" class="c"><input type="checkbox" id="c-36936226" checked=""/><div class="controls bullet"><span class="by">kaycebasques</span><span>|</span><a href="#36934798">prev</a><span>|</span><a href="#36935638">next</a><span>|</span><label class="collapse" for="c-36936226">[-]</label><label class="expand" for="c-36936226">[3 more]</label></div><br/><div class="children"><div class="content">Hi, SF lover [1] here. Anything interesting to note about your name? Will your hardware actually be based in SF? Any plans to start meetups or bring customers together for socializing or anything like that?<p>[1] We have not gone the way of the Xerces blue [2] yet... we still exist!<p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Xerces_blue" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Xerces_blue</a></div><br/><div id="36936770" class="c"><input type="checkbox" id="c-36936770" checked=""/><div class="controls bullet"><span class="by">agajews</span><span>|</span><a href="#36936226">parent</a><span>|</span><a href="#36936783">next</a><span>|</span><label class="collapse" for="c-36936770">[-]</label><label class="expand" for="c-36936770">[1 more]</label></div><br/><div class="children"><div class="content">Ah the hardware isn’t gonna be in SF (not the cheapest datacenter space)<p>But I do think a lot of our customers will be out here —- SF is still probably the best place to do startups. We just have so many more people doing hard technical stuff here. Literally every single place I’ve lived in SF there’s been another startup living upstairs or downstairs<p>Good idea to host some in person events!</div><br/></div></div></div></div><div id="36935638" class="c"><input type="checkbox" id="c-36935638" checked=""/><div class="controls bullet"><span class="by">nilsbunger</span><span>|</span><a href="#36936226">prev</a><span>|</span><a href="#36935246">next</a><span>|</span><label class="collapse" for="c-36935638">[-]</label><label class="expand" for="c-36935638">[14 more]</label></div><br/><div class="children"><div class="content">I love the idea of community assets. could it be the start of a GPU co-op?</div><br/><div id="36935758" class="c"><input type="checkbox" id="c-36935758" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36935638">parent</a><span>|</span><a href="#36935688">next</a><span>|</span><label class="collapse" for="c-36935758">[-]</label><label class="expand" for="c-36935758">[9 more]</label></div><br/><div class="children"><div class="content">For consumer-grade cards, that&#x27;s already here.<p>Make money off your GPU with vast.AI<p><a href="https:&#x2F;&#x2F;cloud.vast.ai&#x2F;host&#x2F;setup" rel="nofollow noreferrer">https:&#x2F;&#x2F;cloud.vast.ai&#x2F;host&#x2F;setup</a></div><br/><div id="36935986" class="c"><input type="checkbox" id="c-36935986" checked=""/><div class="controls bullet"><span class="by">mdaniel</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36935758">parent</a><span>|</span><a href="#36936022">next</a><span>|</span><label class="collapse" for="c-36935986">[-]</label><label class="expand" for="c-36935986">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Requirements<p>&gt; Ubuntu 18.04 or newer (required)<p>&gt; Dedicated machines only - the machine shouldn&#x27;t be doing other stuff while rented<p>well that&#x27;s certainly not what I expected. ctrl-f &quot;virtual&quot; gives nothing, so it seems they really mean &quot;take over your machine&quot;<p>&gt; Note: you may need to install python2.7 to run the install script.<p>what kind of nonsense is this? Did they write the script in 2001 and just abandon it?</div><br/><div id="36936171" class="c"><input type="checkbox" id="c-36936171" checked=""/><div class="controls bullet"><span class="by">mschuster91</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36935986">parent</a><span>|</span><a href="#36936535">next</a><span>|</span><label class="collapse" for="c-36936171">[-]</label><label class="expand" for="c-36936171">[3 more]</label></div><br/><div class="children"><div class="content">&gt; what kind of nonsense is this? Did they write the script in 2001 and just abandon it?<p>Anything AI&#x2F;ML is a hot mess of cobbled-together bits and pieces of Python barely holding together. I recently read somewhere that there should be a new specialization of &quot;ML DevOps Engineer&quot;... and hell I&#x27;m supporting that.</div><br/><div id="36936575" class="c"><input type="checkbox" id="c-36936575" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36936171">parent</a><span>|</span><a href="#36937483">next</a><span>|</span><label class="collapse" for="c-36936575">[-]</label><label class="expand" for="c-36936575">[1 more]</label></div><br/><div class="children"><div class="content"><i>there should be a new specialization of &quot;ML DevOps Engineer&quot;</i><p>Do you mean MLOps? Nothing new about it. We have two full-time MLOps engineers at our startup.</div><br/></div></div><div id="36937483" class="c"><input type="checkbox" id="c-36937483" checked=""/><div class="controls bullet"><span class="by">ethbr0</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36936171">parent</a><span>|</span><a href="#36936575">prev</a><span>|</span><a href="#36936535">next</a><span>|</span><label class="collapse" for="c-36937483">[-]</label><label class="expand" for="c-36937483">[1 more]</label></div><br/><div class="children"><div class="content">Python is awesome because they built what people wanted.<p>Python is terrible because they built what people wanted.</div><br/></div></div></div></div><div id="36936535" class="c"><input type="checkbox" id="c-36936535" checked=""/><div class="controls bullet"><span class="by">williamstein</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36935986">parent</a><span>|</span><a href="#36936171">prev</a><span>|</span><a href="#36936022">next</a><span>|</span><label class="collapse" for="c-36936535">[-]</label><label class="expand" for="c-36936535">[2 more]</label></div><br/><div class="children"><div class="content">I just skimmed their FAQ at <a href="https:&#x2F;&#x2F;vast.ai&#x2F;faq" rel="nofollow noreferrer">https:&#x2F;&#x2F;vast.ai&#x2F;faq</a>, and it seems like it could use an update.  E.g., it says &quot;Initially we are supporting Ubuntu Linux, more specifically Ubuntu 16.04 LTS.&quot;.  That version of Ubuntu has been end-of-life&#x27;d for several years, and when I just tried vast.ai out, it seemed to be using Ubuntu 20.04.  There were also a couple of words with letters missing (probably trivial typos) that could be found with a spell checker. The questions in their FAQ are really interesting though, in terms of highlighting what users care about (e.g., there&#x27;s a lot devoted to &quot;how do I use vast.ai + google colab together&quot;?).    I also wonder when vast.ai started?  Sometimes you can get insight from a company blog page, but the vast.ai blog seems to start in Feb 2023: <a href="https:&#x2F;&#x2F;vast.ai&#x2F;blog" rel="nofollow noreferrer">https:&#x2F;&#x2F;vast.ai&#x2F;blog</a>   .  There&#x27;s a bunch of &quot;personal experiences&quot; with vast.ai from 3 years ago in this discussion though: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;MachineLearning&#x2F;comments&#x2F;hv49pd&#x2F;d_consumer_gpu_cloud_rental_vastai&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;MachineLearning&#x2F;comments&#x2F;hv49pd&#x2F;d_c...</a><p>A comment in that discussion mentions yet another competitor in this space that I&#x27;ve never heard of: <a href="https:&#x2F;&#x2F;www.qblocks.cloud&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.qblocks.cloud&#x2F;</a> -- I just tried Q blocks out and the new user experience wasn&#x27;t as good for me as with vast.ai: you have to put in $10 money to try it, instead of getting to try it initially for free; there is a manual approval process before you can try data center class GPUs; you only see that your instance is in Norway (say) after you try to start it, not before; it seems like there&#x27;s no ssh access, and they only provide Jupyter to connect; neither pytorch nor tensorflow seemed to be installed.  They could probably update their pages too, e.g., <a href="https:&#x2F;&#x2F;www.qblocks.cloud&#x2F;vision" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.qblocks.cloud&#x2F;vision</a> is all about crypto mining and smartphones, which feels a bit dated... :-)</div><br/><div id="36937400" class="c"><input type="checkbox" id="c-36937400" checked=""/><div class="controls bullet"><span class="by">mikeravkine</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36936535">parent</a><span>|</span><a href="#36936022">next</a><span>|</span><label class="collapse" for="c-36937400">[-]</label><label class="expand" for="c-36937400">[1 more]</label></div><br/><div class="children"><div class="content">TensorDock Marketplace is another option: <a href="https:&#x2F;&#x2F;marketplace.tensordock.com&#x2F;order_list" rel="nofollow noreferrer">https:&#x2F;&#x2F;marketplace.tensordock.com&#x2F;order_list</a><p>It&#x27;s unique in that you can set your own prices, it&#x27;s a true spot marketplace.. I&#x27;ve grabbed 2x3090 for $0.02&#x2F;hr before.<p>Probably no good for training (can be interrupted any time with zero warning ssh just drops and that&#x27;s it) but for my inference usecases it lets me spot heavy compute for pennies.</div><br/></div></div></div></div></div></div><div id="36936022" class="c"><input type="checkbox" id="c-36936022" checked=""/><div class="controls bullet"><span class="by">lgats</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36935758">parent</a><span>|</span><a href="#36935986">prev</a><span>|</span><a href="#36935826">next</a><span>|</span><label class="collapse" for="c-36936022">[-]</label><label class="expand" for="c-36936022">[1 more]</label></div><br/><div class="children"><div class="content">check here to see the current bid prices &#x2F; gpu setups
<a href="https:&#x2F;&#x2F;cloud.vast.ai&#x2F;create&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;cloud.vast.ai&#x2F;create&#x2F;</a></div><br/></div></div><div id="36935826" class="c"><input type="checkbox" id="c-36935826" checked=""/><div class="controls bullet"><span class="by">PartiallyTyped</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36935758">parent</a><span>|</span><a href="#36936022">prev</a><span>|</span><a href="#36935688">next</a><span>|</span><label class="collapse" for="c-36935826">[-]</label><label class="expand" for="c-36935826">[1 more]</label></div><br/><div class="children"><div class="content">My computer is sitting mostly idle at home, thanks for this.</div><br/></div></div></div></div><div id="36935688" class="c"><input type="checkbox" id="c-36935688" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#36935638">parent</a><span>|</span><a href="#36935758">prev</a><span>|</span><a href="#36935246">next</a><span>|</span><label class="collapse" for="c-36935688">[-]</label><label class="expand" for="c-36935688">[4 more]</label></div><br/><div class="children"><div class="content">Serious Q, as I dont know Twitters internal infra at all... but with a shrinking in revenue from ads, or maybe less engagement by users, and the influx of Threads - maybe twitter can use from slices of its infra (even if its rack space, VMs, Containers, connectivity, who knows what, to support startups such as this?<p>Basically twitter devolves into the Colos of the late 90s :-)<p>-<p>For those who didnt notice, it was tongue in cheek.</div><br/><div id="36935721" class="c"><input type="checkbox" id="c-36935721" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36935688">parent</a><span>|</span><a href="#36936712">next</a><span>|</span><label class="collapse" for="c-36935721">[-]</label><label class="expand" for="c-36935721">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve generally tried to give Twitter the benefit of the doubt but I would never trust them as an infrastructure provider in their current incarnation. Reliability and consistency have been so far from their focus.</div><br/></div></div><div id="36936712" class="c"><input type="checkbox" id="c-36936712" checked=""/><div class="controls bullet"><span class="by">mike_d</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36935688">parent</a><span>|</span><a href="#36935721">prev</a><span>|</span><a href="#36935786">next</a><span>|</span><label class="collapse" for="c-36936712">[-]</label><label class="expand" for="c-36936712">[1 more]</label></div><br/><div class="children"><div class="content">Generally when you just stop paying your bills the datacenter holds your hardware and eventually auctions it off to cover some of your debt. I seriously doubt Twitter has any access to the two of three datacenters Elon decided to not pay for.</div><br/></div></div><div id="36935786" class="c"><input type="checkbox" id="c-36935786" checked=""/><div class="controls bullet"><span class="by">aionaiodfgnio</span><span>|</span><a href="#36935638">root</a><span>|</span><a href="#36935688">parent</a><span>|</span><a href="#36936712">prev</a><span>|</span><a href="#36935246">next</a><span>|</span><label class="collapse" for="c-36935786">[-]</label><label class="expand" for="c-36935786">[1 more]</label></div><br/><div class="children"><div class="content">Would you really trust a company that doesn&#x27;t pay its rent to run your infrastructure?</div><br/></div></div></div></div></div></div><div id="36935246" class="c"><input type="checkbox" id="c-36935246" checked=""/><div class="controls bullet"><span class="by">moneycantbuy</span><span>|</span><a href="#36935638">prev</a><span>|</span><a href="#36936846">next</a><span>|</span><label class="collapse" for="c-36935246">[-]</label><label class="expand" for="c-36935246">[14 more]</label></div><br/><div class="children"><div class="content">How did you get the money to buy 512 H100s?</div><br/><div id="36935490" class="c"><input type="checkbox" id="c-36935490" checked=""/><div class="controls bullet"><span class="by">taminka</span><span>|</span><a href="#36935246">parent</a><span>|</span><a href="#36937024">next</a><span>|</span><label class="collapse" for="c-36935490">[-]</label><label class="expand" for="c-36935490">[6 more]</label></div><br/><div class="children"><div class="content">ask no questions hear no lies</div><br/><div id="36935538" class="c"><input type="checkbox" id="c-36935538" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#36935246">root</a><span>|</span><a href="#36935490">parent</a><span>|</span><a href="#36937024">next</a><span>|</span><label class="collapse" for="c-36935538">[-]</label><label class="expand" for="c-36935538">[5 more]</label></div><br/><div class="children"><div class="content">EDIT: They seem to be in a raising fund &#x2F; debt stage. Great initiative</div><br/><div id="36935580" class="c"><input type="checkbox" id="c-36935580" checked=""/><div class="controls bullet"><span class="by">williamstein</span><span>|</span><a href="#36935246">root</a><span>|</span><a href="#36935538">parent</a><span>|</span><a href="#36936112">next</a><span>|</span><label class="collapse" for="c-36935580">[-]</label><label class="expand" for="c-36935580">[2 more]</label></div><br/><div class="children"><div class="content">Their announcement says &quot;We can probably get a good deal from a bank [...]&quot;, so maybe they don&#x27;t just have 20M USD sitting around.</div><br/><div id="36935595" class="c"><input type="checkbox" id="c-36935595" checked=""/><div class="controls bullet"><span class="by">rvnx</span><span>|</span><a href="#36935246">root</a><span>|</span><a href="#36935580">parent</a><span>|</span><a href="#36936112">next</a><span>|</span><label class="collapse" for="c-36935595">[-]</label><label class="expand" for="c-36935595">[1 more]</label></div><br/><div class="children"><div class="content">Well, this pushes me even further in the direction that they are actually good guys that need support, and that they are trying to bring a good deal on the table :)</div><br/></div></div></div></div><div id="36936112" class="c"><input type="checkbox" id="c-36936112" checked=""/><div class="controls bullet"><span class="by">herval</span><span>|</span><a href="#36935246">root</a><span>|</span><a href="#36935538">parent</a><span>|</span><a href="#36935580">prev</a><span>|</span><a href="#36935712">next</a><span>|</span><label class="collapse" for="c-36936112">[-]</label><label class="expand" for="c-36936112">[1 more]</label></div><br/><div class="children"><div class="content">unrelated to this specific initiative, but - I keep seeing a lot of announcements of huge VC rounds around what&#x27;s effectively datacenters for GPUs. Curious about the math behind that - I feel like those things get obsolete so fast, it&#x27;s almost like the whole scooter rental thing, where the unit economics doesn&#x27;t add up.<p>Anyone have an insight?</div><br/></div></div></div></div></div></div><div id="36935570" class="c"><input type="checkbox" id="c-36935570" checked=""/><div class="controls bullet"><span class="by">humanistbot</span><span>|</span><a href="#36935246">parent</a><span>|</span><a href="#36937024">prev</a><span>|</span><a href="#36936846">next</a><span>|</span><label class="collapse" for="c-36935570">[-]</label><label class="expand" for="c-36935570">[6 more]</label></div><br/><div class="children"><div class="content">From sentence one of the post, it clearly states that they are VC funders who are doing this for a round of startups they just funded, and they&#x27;re looking for others to be a part of it.</div><br/><div id="36935589" class="c"><input type="checkbox" id="c-36935589" checked=""/><div class="controls bullet"><span class="by">flaque</span><span>|</span><a href="#36935246">root</a><span>|</span><a href="#36935570">parent</a><span>|</span><a href="#36936846">next</a><span>|</span><label class="collapse" for="c-36935589">[-]</label><label class="expand" for="c-36935589">[5 more]</label></div><br/><div class="children"><div class="content">Oh no, definitely not. We just got a loan.<p>Neither Alex or I are currently VCs, and this has no affiliation with any venture fund.<p>We want to be a customer of the sf compute group too!</div><br/><div id="36937394" class="c"><input type="checkbox" id="c-36937394" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#36935246">root</a><span>|</span><a href="#36935589">parent</a><span>|</span><a href="#36936640">next</a><span>|</span><label class="collapse" for="c-36937394">[-]</label><label class="expand" for="c-36937394">[2 more]</label></div><br/><div class="children"><div class="content">How’d you get this loan? Is it from a benevolent individual who just wants to make something happen?<p>If not and you got the loan from a bank, super curious how you were able to get the bank to trust that renting out the GPUs would cover the loan or if some other reasoning convinced them. Assuming you aren’t trying to turn this into a big business, that knowledge might help a lot of other players run similar programs and further democratize SOA GPU access.</div><br/><div id="36937717" class="c"><input type="checkbox" id="c-36937717" checked=""/><div class="controls bullet"><span class="by">xwdv</span><span>|</span><a href="#36935246">root</a><span>|</span><a href="#36937394">parent</a><span>|</span><a href="#36936640">next</a><span>|</span><label class="collapse" for="c-36937717">[-]</label><label class="expand" for="c-36937717">[1 more]</label></div><br/><div class="children"><div class="content">I’m fairly certain this loan is either a private individual or a HELOC or something. No way is a bank just going to loan out a bunch of money to some startup like this.</div><br/></div></div></div></div><div id="36936640" class="c"><input type="checkbox" id="c-36936640" checked=""/><div class="controls bullet"><span class="by">xwdv</span><span>|</span><a href="#36935246">root</a><span>|</span><a href="#36935589">parent</a><span>|</span><a href="#36937394">prev</a><span>|</span><a href="#36936846">next</a><span>|</span><label class="collapse" for="c-36936640">[-]</label><label class="expand" for="c-36936640">[2 more]</label></div><br/><div class="children"><div class="content">I’m curious, how are those loans guaranteed?</div><br/><div id="36937031" class="c"><input type="checkbox" id="c-36937031" checked=""/><div class="controls bullet"><span class="by">turbobooster</span><span>|</span><a href="#36935246">root</a><span>|</span><a href="#36936640">parent</a><span>|</span><a href="#36936846">next</a><span>|</span><label class="collapse" for="c-36937031">[-]</label><label class="expand" for="c-36937031">[1 more]</label></div><br/><div class="children"><div class="content">The only guarantee is them not paying it back</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36936846" class="c"><input type="checkbox" id="c-36936846" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#36935246">prev</a><span>|</span><a href="#36938635">next</a><span>|</span><label class="collapse" for="c-36936846">[-]</label><label class="expand" for="c-36936846">[2 more]</label></div><br/><div class="children"><div class="content">Noob Thought: So this would be a blue print on how a mid tier universities with older large compute cluster ops could do things in 2023 to support large LLM research?<p>Perhaps its also a way for freshly applying grad students to look at a university looking to do research in LLMs that requires scale...</div><br/><div id="36936894" class="c"><input type="checkbox" id="c-36936894" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#36936846">parent</a><span>|</span><a href="#36938635">next</a><span>|</span><label class="collapse" for="c-36936894">[-]</label><label class="expand" for="c-36936894">[1 more]</label></div><br/><div class="children"><div class="content">Like to clarify, a new grad students could look at the current group and ask &quot;Hey I know you are working on LLMs, but how many $$ of your grant are dedicated to how many TPU hours per grad student?&quot;</div><br/></div></div></div></div><div id="36938635" class="c"><input type="checkbox" id="c-36938635" checked=""/><div class="controls bullet"><span class="by">netcraft</span><span>|</span><a href="#36936846">prev</a><span>|</span><a href="#36934749">next</a><span>|</span><label class="collapse" for="c-36938635">[-]</label><label class="expand" for="c-36938635">[2 more]</label></div><br/><div class="children"><div class="content">Honest question I don’t know how to consider: are we further along or behind with AI given crypto’s use of GPUs? Has the same cards bought for mining furthered AI, or maybe that demand lead to more research into GPUs and what they can do - or would we be further along if we weren’t wasting these cards on mining?</div><br/><div id="36938710" class="c"><input type="checkbox" id="c-36938710" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36938635">parent</a><span>|</span><a href="#36934749">next</a><span>|</span><label class="collapse" for="c-36938710">[-]</label><label class="expand" for="c-36938710">[1 more]</label></div><br/><div class="children"><div class="content">Ethereum&#x27;s (thrice delayed) move to PoS put a glut of GPUs on the market, just in time for the AI boom to swallow them back up, so I think it ended up okay. NVDA certainly had a great few days in the market thanks to AI though.</div><br/></div></div></div></div><div id="36934749" class="c"><input type="checkbox" id="c-36934749" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#36938635">prev</a><span>|</span><a href="#36935641">next</a><span>|</span><label class="collapse" for="c-36934749">[-]</label><label class="expand" for="c-36934749">[12 more]</label></div><br/><div class="children"><div class="content">554 5.7.1 &lt;evan@sfcompute.org&gt;: Relay access denied<p>554 5.7.1 &lt;alex@sfcompute.org&gt;: Relay access denied</div><br/><div id="36934956" class="c"><input type="checkbox" id="c-36934956" checked=""/><div class="controls bullet"><span class="by">flaque</span><span>|</span><a href="#36934749">parent</a><span>|</span><a href="#36935641">next</a><span>|</span><label class="collapse" for="c-36934956">[-]</label><label class="expand" for="c-36934956">[11 more]</label></div><br/><div class="children"><div class="content">!!!!!! fixing this. For the moment, evan at roomservice dot dev</div><br/><div id="36935471" class="c"><input type="checkbox" id="c-36935471" checked=""/><div class="controls bullet"><span class="by">ranting-moth</span><span>|</span><a href="#36934749">root</a><span>|</span><a href="#36934956">parent</a><span>|</span><a href="#36934992">next</a><span>|</span><label class="collapse" for="c-36935471">[-]</label><label class="expand" for="c-36935471">[1 more]</label></div><br/><div class="children"><div class="content">Ah, putting out flames live on HN. Back in the day it was on IRC or just on the phone with the customer. I miss those times.</div><br/></div></div><div id="36934992" class="c"><input type="checkbox" id="c-36934992" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36934749">root</a><span>|</span><a href="#36934956">parent</a><span>|</span><a href="#36935471">prev</a><span>|</span><a href="#36934968">next</a><span>|</span><label class="collapse" for="c-36934992">[-]</label><label class="expand" for="c-36934992">[7 more]</label></div><br/><div class="children"><div class="content">fwiw, <a href="https:&#x2F;&#x2F;roomservice.dev&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;roomservice.dev&#x2F;</a> is currently a 404</div><br/><div id="36935086" class="c"><input type="checkbox" id="c-36935086" checked=""/><div class="controls bullet"><span class="by">flaque</span><span>|</span><a href="#36934749">root</a><span>|</span><a href="#36934992">parent</a><span>|</span><a href="#36935221">next</a><span>|</span><label class="collapse" for="c-36935086">[-]</label><label class="expand" for="c-36935086">[3 more]</label></div><br/><div class="children"><div class="content">Ah yeah, that&#x27;s normal! Was from my old CRDT company, and works as a good emergency email while we debug our DNS.</div><br/><div id="36935424" class="c"><input type="checkbox" id="c-36935424" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36934749">root</a><span>|</span><a href="#36935086">parent</a><span>|</span><a href="#36935359">next</a><span>|</span><label class="collapse" for="c-36935424">[-]</label><label class="expand" for="c-36935424">[1 more]</label></div><br/><div class="children"><div class="content">I assume it was a Take3 reference. I wanted to point it out, in case it was supposed to return more than a 404.</div><br/></div></div></div></div><div id="36935221" class="c"><input type="checkbox" id="c-36935221" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#36934749">root</a><span>|</span><a href="#36934992">parent</a><span>|</span><a href="#36935086">prev</a><span>|</span><a href="#36934968">next</a><span>|</span><label class="collapse" for="c-36935221">[-]</label><label class="expand" for="c-36935221">[3 more]</label></div><br/><div class="children"><div class="content">http != smtp<p><pre><code>  roomservice.dev. 60 IN MX 5 alt1.aspmx.l.google.com.
  roomservice.dev. 60 IN MX 5 alt2.aspmx.l.google.com.
  roomservice.dev. 60 IN MX 1 aspmx.l.google.com.
  roomservice.dev. 60 IN MX 10 alt3.aspmx.l.google.com.
  roomservice.dev. 60 IN MX 10 alt4.aspmx.l.google.com.
  roomservice.dev. 60 IN MX 15 4ig53n4pw7p3cuxm7n7xi7dpuyq6722aipexvhkngzbd2e4mudmq.mx-verification.google.com.</code></pre></div><br/><div id="36935797" class="c"><input type="checkbox" id="c-36935797" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36934749">root</a><span>|</span><a href="#36935221">parent</a><span>|</span><a href="#36935346">prev</a><span>|</span><a href="#36934968">next</a><span>|</span><label class="collapse" for="c-36935797">[-]</label><label class="expand" for="c-36935797">[1 more]</label></div><br/><div class="children"><div class="content">I know the difference between an email and a web page, tyvm.</div><br/></div></div></div></div></div></div><div id="36935316" class="c"><input type="checkbox" id="c-36935316" checked=""/><div class="controls bullet"><span class="by">latchkey</span><span>|</span><a href="#36934749">root</a><span>|</span><a href="#36934956">parent</a><span>|</span><a href="#36934968">prev</a><span>|</span><a href="#36935641">next</a><span>|</span><label class="collapse" for="c-36935316">[-]</label><label class="expand" for="c-36935316">[1 more]</label></div><br/><div class="children"><div class="content">done</div><br/></div></div></div></div></div></div><div id="36935641" class="c"><input type="checkbox" id="c-36935641" checked=""/><div class="controls bullet"><span class="by">sashank_1509</span><span>|</span><a href="#36934749">prev</a><span>|</span><a href="#36938214">next</a><span>|</span><label class="collapse" for="c-36935641">[-]</label><label class="expand" for="c-36935641">[4 more]</label></div><br/><div class="children"><div class="content">Correct me if I’m wrong but doesn’t Lambda Labs already provide them at 1.89$? What’s the point if you’re starting out not the cheapest</div><br/><div id="36936517" class="c"><input type="checkbox" id="c-36936517" checked=""/><div class="controls bullet"><span class="by">agajews</span><span>|</span><a href="#36935641">parent</a><span>|</span><a href="#36935670">next</a><span>|</span><label class="collapse" for="c-36936517">[-]</label><label class="expand" for="c-36936517">[1 more]</label></div><br/><div class="children"><div class="content">Ah that’s only if you pay for 3 years of compute upfront. Most startups, especially the small ones, really can’t afford that</div><br/></div></div><div id="36935670" class="c"><input type="checkbox" id="c-36935670" checked=""/><div class="controls bullet"><span class="by">davidmurphy</span><span>|</span><a href="#36935641">parent</a><span>|</span><a href="#36936517">prev</a><span>|</span><a href="#36938214">next</a><span>|</span><label class="collapse" for="c-36935670">[-]</label><label class="expand" for="c-36935670">[2 more]</label></div><br/><div class="children"><div class="content">Looks like their site is quoting a rate of $1.99 now
<a href="https:&#x2F;&#x2F;lambdalabs.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;lambdalabs.com&#x2F;</a></div><br/><div id="36935745" class="c"><input type="checkbox" id="c-36935745" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#36935641">root</a><span>|</span><a href="#36935670">parent</a><span>|</span><a href="#36938214">next</a><span>|</span><label class="collapse" for="c-36935745">[-]</label><label class="expand" for="c-36935745">[1 more]</label></div><br/><div class="children"><div class="content">See this post above: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36935032">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36935032</a><p>Price and market depth are very different things</div><br/></div></div></div></div></div></div><div id="36938214" class="c"><input type="checkbox" id="c-36938214" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#36935641">prev</a><span>|</span><a href="#36937786">next</a><span>|</span><label class="collapse" for="c-36938214">[-]</label><label class="expand" for="c-36938214">[1 more]</label></div><br/><div class="children"><div class="content">Will it be a Slurm cluster, or what kind of scheduler is SFC planning to use?</div><br/></div></div><div id="36937786" class="c"><input type="checkbox" id="c-36937786" checked=""/><div class="controls bullet"><span class="by">mackid</span><span>|</span><a href="#36938214">prev</a><span>|</span><a href="#36938376">next</a><span>|</span><label class="collapse" for="c-36937786">[-]</label><label class="expand" for="c-36937786">[2 more]</label></div><br/><div class="children"><div class="content">Nat Friedman and Daniel Gross setup  a 2,512 H100 cluster [1] for their startups, with a very similar “shared” model.  Might be interesting to connect with them.<p>[1] <a href="https:&#x2F;&#x2F;andromedacluster.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;andromedacluster.com&#x2F;</a></div><br/><div id="36938551" class="c"><input type="checkbox" id="c-36938551" checked=""/><div class="controls bullet"><span class="by">flaque</span><span>|</span><a href="#36937786">parent</a><span>|</span><a href="#36938376">next</a><span>|</span><label class="collapse" for="c-36938551">[-]</label><label class="expand" for="c-36938551">[1 more]</label></div><br/><div class="children"><div class="content">Nat &amp; Daniel’s cluster is great, and we fully recommend startups seek out this option as well. Nat &amp; Daniel are some of the best investors one can have</div><br/></div></div></div></div><div id="36938376" class="c"><input type="checkbox" id="c-36938376" checked=""/><div class="controls bullet"><span class="by">rushingcreek</span><span>|</span><a href="#36937786">prev</a><span>|</span><a href="#36935640">next</a><span>|</span><label class="collapse" for="c-36938376">[-]</label><label class="expand" for="c-36938376">[1 more]</label></div><br/><div class="children"><div class="content">I love this. Us at Phind.com would love to be a part of this.</div><br/></div></div><div id="36935640" class="c"><input type="checkbox" id="c-36935640" checked=""/><div class="controls bullet"><span class="by">ucarion</span><span>|</span><a href="#36938376">prev</a><span>|</span><a href="#36939621">next</a><span>|</span><label class="collapse" for="c-36935640">[-]</label><label class="expand" for="c-36935640">[1 more]</label></div><br/><div class="children"><div class="content">Wishing y&#x27;all the best of luck. This would be huge for a lot of folks.</div><br/></div></div><div id="36939621" class="c"><input type="checkbox" id="c-36939621" checked=""/><div class="controls bullet"><span class="by">jeepers6</span><span>|</span><a href="#36935640">prev</a><span>|</span><a href="#36937182">next</a><span>|</span><label class="collapse" for="c-36939621">[-]</label><label class="expand" for="c-36939621">[1 more]</label></div><br/><div class="children"><div class="content">Please take this question without prejudice.<p>Is it accurate to say you’re willing to go into ~20,000,000 USD debt to sell discounted computer-as-a-service to researchers&#x2F;startups, but unwilling to go into debt to sponsor the undergraduate degrees of ~100-500 students at top-tier schools? (40k - 200k USD per degree)<p>Or, you know, build and fund a small public school&#x2F;library or two for ~5 years?</div><br/></div></div><div id="36937182" class="c"><input type="checkbox" id="c-36937182" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#36939621">prev</a><span>|</span><a href="#36935706">next</a><span>|</span><label class="collapse" for="c-36937182">[-]</label><label class="expand" for="c-36937182">[4 more]</label></div><br/><div class="children"><div class="content">The billion dollar question is:<p>Who is funding this?<p>Cause if it’s VC then it’s going to have the same fate as everything else after 5-7 years.<p>I hope y’all have as innovative of a business model. You’ll need it if you want to do what you’re doing now for more than a few years</div><br/><div id="36937312" class="c"><input type="checkbox" id="c-36937312" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36937182">parent</a><span>|</span><a href="#36935706">next</a><span>|</span><label class="collapse" for="c-36937312">[-]</label><label class="expand" for="c-36937312">[3 more]</label></div><br/><div class="children"><div class="content">What&#x27;s wrong with doing something profitable for a few years? H100&#x27;s in a couple of years will be like having a cluster of K80&#x27;s today.<p>Not everything has grow to have the appetite of Galactus and swallow a whole planet. Making single digit millions of dollars over a couple of years is still worthwhile, especially if it helps others and moves humanity forwards.<p>This project isn&#x27;t ever going to want to try and compete with AWS, so no, it&#x27;s not a billion dollar question. $20 Million, yeah.</div><br/><div id="36937436" class="c"><input type="checkbox" id="c-36937436" checked=""/><div class="controls bullet"><span class="by">constantly</span><span>|</span><a href="#36937182">root</a><span>|</span><a href="#36937312">parent</a><span>|</span><a href="#36937490">next</a><span>|</span><label class="collapse" for="c-36937436">[-]</label><label class="expand" for="c-36937436">[1 more]</label></div><br/><div class="children"><div class="content">You’re completely right in everything you say about growing sustainably and making some money over time. But if this project is VC that all goes out the window and it won’t be profitable unless it massively galactus scales to compete with AWS in 5-7 years, and will fail after that almost certainly, like the vast, vast majority of VC projects.</div><br/></div></div><div id="36937490" class="c"><input type="checkbox" id="c-36937490" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#36937182">root</a><span>|</span><a href="#36937312">parent</a><span>|</span><a href="#36937436">prev</a><span>|</span><a href="#36935706">next</a><span>|</span><label class="collapse" for="c-36937490">[-]</label><label class="expand" for="c-36937490">[1 more]</label></div><br/><div class="children"><div class="content">Hey I agree!<p>That’s why I’m asking because a “bootstrapped” company like you describe has a future…<p>One backed by VC doesn’t<p>I mean they may have a future but not like you describe</div><br/></div></div></div></div></div></div><div id="36935706" class="c"><input type="checkbox" id="c-36935706" checked=""/><div class="controls bullet"><span class="by">resonance1994</span><span>|</span><a href="#36937182">prev</a><span>|</span><a href="#36935524">next</a><span>|</span><label class="collapse" for="c-36935706">[-]</label><label class="expand" for="c-36935706">[1 more]</label></div><br/><div class="children"><div class="content">Just curious, do you guys use renewable energy to power your cluster?</div><br/></div></div><div id="36935524" class="c"><input type="checkbox" id="c-36935524" checked=""/><div class="controls bullet"><span class="by">29athrowaway</span><span>|</span><a href="#36935706">prev</a><span>|</span><a href="#36934838">next</a><span>|</span><label class="collapse" for="c-36935524">[-]</label><label class="expand" for="c-36935524">[4 more]</label></div><br/><div class="children"><div class="content">During a gold rush, sell shovels.<p>When was the last time you spoke to a chatbot?</div><br/><div id="36935723" class="c"><input type="checkbox" id="c-36935723" checked=""/><div class="controls bullet"><span class="by">netsec_burn</span><span>|</span><a href="#36935524">parent</a><span>|</span><a href="#36935782">next</a><span>|</span><label class="collapse" for="c-36935723">[-]</label><label class="expand" for="c-36935723">[1 more]</label></div><br/><div class="children"><div class="content">For me, today and almost every day since the beginning of this year. Not sure if that saying applies here.</div><br/></div></div><div id="36935782" class="c"><input type="checkbox" id="c-36935782" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#36935524">parent</a><span>|</span><a href="#36935723">prev</a><span>|</span><a href="#36935649">next</a><span>|</span><label class="collapse" for="c-36935782">[-]</label><label class="expand" for="c-36935782">[1 more]</label></div><br/><div class="children"><div class="content">Chatbot in the sense I think you mean is a horrible application. Millions of people are using large language models daily though.</div><br/></div></div><div id="36935649" class="c"><input type="checkbox" id="c-36935649" checked=""/><div class="controls bullet"><span class="by">lulunananaluna</span><span>|</span><a href="#36935524">parent</a><span>|</span><a href="#36935782">prev</a><span>|</span><a href="#36934838">next</a><span>|</span><label class="collapse" for="c-36935649">[-]</label><label class="expand" for="c-36935649">[1 more]</label></div><br/><div class="children"><div class="content">Downvoted by others, yet very true. This is a valid business model, nothing to be ashamed about it.</div><br/></div></div></div></div><div id="36934838" class="c"><input type="checkbox" id="c-36934838" checked=""/><div class="controls bullet"><span class="by">rsync</span><span>|</span><a href="#36935524">prev</a><span>|</span><a href="#36934352">next</a><span>|</span><label class="collapse" for="c-36934838">[-]</label><label class="expand" for="c-36934838">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Once the cluster is online ...&quot;<p>Where will the cluster be hosted ?<p>May I suggest that you get your IP transit from he.net ?</div><br/><div id="36935551" class="c"><input type="checkbox" id="c-36935551" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#36934838">parent</a><span>|</span><a href="#36934903">next</a><span>|</span><label class="collapse" for="c-36935551">[-]</label><label class="expand" for="c-36935551">[2 more]</label></div><br/><div class="children"><div class="content">Not to mention, San Francisco is not known for having cheap real estate, nor is it known for having cheap electricity. My last (residential) bill to PGE, I paid $0.50938&#x2F;KWh at peak.</div><br/><div id="36935692" class="c"><input type="checkbox" id="c-36935692" checked=""/><div class="controls bullet"><span class="by">vladgur</span><span>|</span><a href="#36934838">root</a><span>|</span><a href="#36935551">parent</a><span>|</span><a href="#36934903">next</a><span>|</span><label class="collapse" for="c-36935692">[-]</label><label class="expand" for="c-36935692">[1 more]</label></div><br/><div class="children"><div class="content">While business rates may be different, California cannot be a sensible place to host power-hungry infrastructure - our electrical rates are easily 5-8 times of other locations within the US</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>