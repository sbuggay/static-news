<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1732611672515" as="style"/><link rel="stylesheet" href="styles.css?v=1732611672515"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://aws.amazon.com/about-aws/whats-new/2024/11/amazon-s3-functionality-conditional-writes/">Amazon S3 Adds Put-If-Match (Compare-and-Swap)</a>Â <span class="domain">(<a href="https://aws.amazon.com">aws.amazon.com</a>)</span></div><div class="subtext"><span>Sirupsen</span> | <span>109 comments</span></div><br/><div><div id="42243447" class="c"><input type="checkbox" id="c-42243447" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#42241487">next</a><span>|</span><label class="collapse" for="c-42243447">[-]</label><label class="expand" for="c-42243447">[3 more]</label></div><br/><div class="children"><div class="content">Ah so its not only me that uses AWS primitives for hackily implementing all sorts of synchronization primitives.<p>My other favorite pattern is implementing a pool of workers by quering ec2 instances with a certain tag in a stopped state and starting them.
Starting the instance can succeed only once - that means I managed to snatch the machine. If it fails, I try again, grabbing another one.<p>This is one of those things that I never advertised out of professional shame, but it works, its bulletproof and dead simple and does not require additional infra to work.</div><br/><div id="42243588" class="c"><input type="checkbox" id="c-42243588" checked=""/><div class="controls bullet"><span class="by">_zoltan_</span><span>|</span><a href="#42243447">parent</a><span>|</span><a href="#42241487">next</a><span>|</span><label class="collapse" for="c-42243588">[-]</label><label class="expand" for="c-42243588">[2 more]</label></div><br/><div class="children"><div class="content">this actually sounds interesting. do you precreate the workers beforehand and then just keep them in a stopped state?</div><br/><div id="42243615" class="c"><input type="checkbox" id="c-42243615" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#42243447">root</a><span>|</span><a href="#42243588">parent</a><span>|</span><a href="#42241487">next</a><span>|</span><label class="collapse" for="c-42243615">[-]</label><label class="expand" for="c-42243615">[1 more]</label></div><br/><div class="children"><div class="content">yeah. one of the goals was startup time, so It made sense to precreate them. In practice we never ran out of free machines (and if we did, I have a cdk script to make more), and inifnite scaling is a pain in the butt anyways due to having to manage subnets etc.<p>Cost-wise we&#x27;re only paying for the EBS volumes for the stopped instances which are like 4GB each, so they cost practically nothing, we spend less than a dollar per month for the whole bunch.</div><br/></div></div></div></div></div></div><div id="42241487" class="c"><input type="checkbox" id="c-42241487" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#42243447">prev</a><span>|</span><a href="#42241528">next</a><span>|</span><label class="collapse" for="c-42241487">[-]</label><label class="expand" for="c-42241487">[26 more]</label></div><br/><div class="children"><div class="content">It&#x27;s also possible to enforce the use of conditional writes: <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;about-aws&#x2F;whats-new&#x2F;2024&#x2F;11&#x2F;amazon-s3-enforcement-conditional-write-operations-general-purpose-buckets&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;about-aws&#x2F;whats-new&#x2F;2024&#x2F;11&#x2F;amazon-s3...</a><p>My biggest wishlist item for S3 is the ability to enforce that an object is named with a name that matches its hash. (With a modern hash considered secure, not MD5 or SHA1, though it isn&#x27;t supported for those either.) That would make it much easier to build content-addressible storage.</div><br/><div id="42243234" class="c"><input type="checkbox" id="c-42243234" checked=""/><div class="controls bullet"><span class="by">josnyder</span><span>|</span><a href="#42241487">parent</a><span>|</span><a href="#42242293">next</a><span>|</span><label class="collapse" for="c-42243234">[-]</label><label class="expand" for="c-42243234">[1 more]</label></div><br/><div class="children"><div class="content">While it can&#x27;t be done server-side, this can be done straightforwardly in a signer service, and the signer doesn&#x27;t need to interact with the payloads being uploaded. In other words, a tiny signer can act as a control plane for massive quantities of uploaded data.<p>The client sends the request headers (including the x-amz-content-sha256 header) to the signer, and the signer responds with a valid S3 PUT request (minus body). The client takes the signer&#x27;s response, appends its chosen request payload, and uploads it to S3. With such a system, you can implement a signer in a lambda function, and the lambda function enforces the content-addressed invariant.<p>Unfortunately it doesn&#x27;t work natively with multipart: while SigV4+S3 enables you to enforce the SHA256 of each individual part, you can&#x27;t enforce the SHA256 of the entire object. If you really want, you can invent your own tree hashing format atop SHA256, and enforce content-addressability on that.<p>I have a blog post [1] that goes into more depth on signers in general.<p>[1] <a href="https:&#x2F;&#x2F;josnyder.com&#x2F;blog&#x2F;2024&#x2F;patterns_in_s3_data_access.html" rel="nofollow">https:&#x2F;&#x2F;josnyder.com&#x2F;blog&#x2F;2024&#x2F;patterns_in_s3_data_access.ht...</a></div><br/></div></div><div id="42242293" class="c"><input type="checkbox" id="c-42242293" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#42241487">parent</a><span>|</span><a href="#42243234">prev</a><span>|</span><a href="#42241838">next</a><span>|</span><label class="collapse" for="c-42242293">[-]</label><label class="expand" for="c-42242293">[4 more]</label></div><br/><div class="children"><div class="content">S3 has supported SHA-256 as a checksum algo since 2022. You can calculate the hash locally and then specify that hash in the PutObject call. S3 will calculate the hash and compare it with the hash in the PutObject call and reject the Put if they differ. The hash and algo are then stored in the object&#x27;s metadata. You simply also use the SHA-256 hash as the key for the object.<p><a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;aws&#x2F;new-additional-checksum-algorithms-for-amazon-s3&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;aws&#x2F;new-additional-checksum-alg...</a></div><br/><div id="42242522" class="c"><input type="checkbox" id="c-42242522" checked=""/><div class="controls bullet"><span class="by">thayne</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42242293">parent</a><span>|</span><a href="#42241838">next</a><span>|</span><label class="collapse" for="c-42242522">[-]</label><label class="expand" for="c-42242522">[3 more]</label></div><br/><div class="children"><div class="content">Unfortunately, for a multi-part upload it isn&#x27;t a hash of the total object, it is a hash of the hashes for each part, which is a lot less useful. Especially if you don&#x27;t know how the file was partititioned during upload.<p>And even if it was for the whole file, it isn&#x27;t used for the ETag, so, so it can&#x27;t be used for conditional PUTs.<p>I had a use case where this looked really promising, then I ran into the multipart upload limitations, and ended up using my own custom metadata for the sha256sum.</div><br/><div id="42243392" class="c"><input type="checkbox" id="c-42243392" checked=""/><div class="controls bullet"><span class="by">vdm</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42242522">parent</a><span>|</span><a href="#42243213">next</a><span>|</span><label class="collapse" for="c-42243392">[-]</label><label class="expand" for="c-42243392">[1 more]</label></div><br/><div class="children"><div class="content">Ways to control etag&#x2F;Additional Checksums without configuring clients:<p>CopyObject writes a single part object and can read from a  multipart object, as long as the parts total less than the 5 gibibyte limit for a single part.<p>For future writes, s3:ObjectCreated:CompleteMultipartUpload event can trigger CopyObject, else defrag to policy size parts. Boto copy() with multipart_chunksize configured is the most convenient implementation, other SDKs lack an equivalent.<p>For past writes, existing multipart objects can be selected from inventory filtering ETag column length greater than 32 characters. Dividing object size by part size might hint if part size is policy.</div><br/></div></div><div id="42243213" class="c"><input type="checkbox" id="c-42243213" checked=""/><div class="controls bullet"><span class="by">vdm</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42242522">parent</a><span>|</span><a href="#42243392">prev</a><span>|</span><a href="#42241838">next</a><span>|</span><label class="collapse" for="c-42243213">[-]</label><label class="expand" for="c-42243213">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t the SDKs take care of computing the multi-part checksum during upload?<p>&gt; To create a trailing checksum when using an AWS SDK, populate the ChecksumAlgorithm parameter with your preferred algorithm. The SDK uses that algorithm to calculate the checksum for your object (or object parts) and automatically appends it to the end of your upload request. This behavior saves you time because Amazon S3 performs both the verification and upload of your data in a single pass. <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;checking-object-integrity.html#trailing-checksums" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;userguide&#x2F;checki...</a></div><br/></div></div></div></div></div></div><div id="42241838" class="c"><input type="checkbox" id="c-42241838" checked=""/><div class="controls bullet"><span class="by">texthompson</span><span>|</span><a href="#42241487">parent</a><span>|</span><a href="#42242293">prev</a><span>|</span><a href="#42241630">next</a><span>|</span><label class="collapse" for="c-42241838">[-]</label><label class="expand" for="c-42241838">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s interesting. Would you want it to be something like a bucket setting, like &quot;any time an object is uploaded, don&#x27;t let an object write complete unless S3 verifies that a pre-defined hash function (like SHA256) is called to verify that the object&#x27;s name matches the object&#x27;s contents?&quot;</div><br/><div id="42242030" class="c"><input type="checkbox" id="c-42242030" checked=""/><div class="controls bullet"><span class="by">BikiniPrince</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241838">parent</a><span>|</span><a href="#42241630">next</a><span>|</span><label class="collapse" for="c-42242030">[-]</label><label class="expand" for="c-42242030">[1 more]</label></div><br/><div class="children"><div class="content">You can already put with a sha256 hash. If it fails it just returns an error.</div><br/></div></div></div></div><div id="42241630" class="c"><input type="checkbox" id="c-42241630" checked=""/><div class="controls bullet"><span class="by">cmeacham98</span><span>|</span><a href="#42241487">parent</a><span>|</span><a href="#42241838">prev</a><span>|</span><a href="#42241750">next</a><span>|</span><label class="collapse" for="c-42241630">[-]</label><label class="expand" for="c-42241630">[6 more]</label></div><br/><div class="children"><div class="content">Is there any reason you can&#x27;t enforce that restriction on your side? Or are you saying you want S3 to automatically set the name for you based on the hash?</div><br/><div id="42241747" class="c"><input type="checkbox" id="c-42241747" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241630">parent</a><span>|</span><a href="#42241750">next</a><span>|</span><label class="collapse" for="c-42241747">[-]</label><label class="expand" for="c-42241747">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Is there any reason you can&#x27;t enforce that restriction on your side?<p>I&#x27;d like to set IAM permissions for a role, so that that role can add objects to the content-addressible store, but only if their name matches the hash of their content.<p>&gt; Or are you saying you want S3 to automatically set the name for you based on the hash?<p>I&#x27;m happy to name the files myself, if I can get S3 to enforce that. But sure, if it were easier, I&#x27;d be thrilled to have S3 name the files by hash, and&#x2F;or support retrieving files by hash.</div><br/><div id="42241927" class="c"><input type="checkbox" id="c-42241927" checked=""/><div class="controls bullet"><span class="by">mdavidn</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241747">parent</a><span>|</span><a href="#42241750">next</a><span>|</span><label class="collapse" for="c-42241927">[-]</label><label class="expand" for="c-42241927">[4 more]</label></div><br/><div class="children"><div class="content">I think you can presign PutObject calls that validate a particular SHA-256 checksum. An API endpoint, e.g. in a Lambda, can effectively enforce this rule. It unfortunately wonât work on multipart uploads except on individual parts.</div><br/><div id="42243393" class="c"><input type="checkbox" id="c-42243393" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241927">parent</a><span>|</span><a href="#42242300">next</a><span>|</span><label class="collapse" for="c-42243393">[-]</label><label class="expand" for="c-42243393">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately, last I checked, the list of headers you&#x27;re allowed to enforce for pre-signing does not include the hash.</div><br/></div></div><div id="42242300" class="c"><input type="checkbox" id="c-42242300" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241927">parent</a><span>|</span><a href="#42243393">prev</a><span>|</span><a href="#42242564">next</a><span>|</span><label class="collapse" for="c-42242300">[-]</label><label class="expand" for="c-42242300">[1 more]</label></div><br/><div class="children"><div class="content">The hash of multipart uploads is simply the hash of all the part hashes. I&#x27;ve been able to replicate it.</div><br/></div></div><div id="42242564" class="c"><input type="checkbox" id="c-42242564" checked=""/><div class="controls bullet"><span class="by">thayne</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241927">parent</a><span>|</span><a href="#42242300">prev</a><span>|</span><a href="#42241750">next</a><span>|</span><label class="collapse" for="c-42242564">[-]</label><label class="expand" for="c-42242564">[1 more]</label></div><br/><div class="children"><div class="content">But in order to do that you need to already know the contents of the file.<p>I suppose you could have some API to request a signed url for a certain hash, but that starts getting complicated, especially if you need support for multi-part uploads, which you probably do.</div><br/></div></div></div></div></div></div></div></div><div id="42241750" class="c"><input type="checkbox" id="c-42241750" checked=""/><div class="controls bullet"><span class="by">anotheraccount9</span><span>|</span><a href="#42241487">parent</a><span>|</span><a href="#42241630">prev</a><span>|</span><a href="#42241624">next</a><span>|</span><label class="collapse" for="c-42241750">[-]</label><label class="expand" for="c-42241750">[1 more]</label></div><br/><div class="children"><div class="content">Could you use a meta field from the object and save the hash in it, running a compare from it?</div><br/></div></div><div id="42241624" class="c"><input type="checkbox" id="c-42241624" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#42241487">parent</a><span>|</span><a href="#42241750">prev</a><span>|</span><a href="#42241528">next</a><span>|</span><label class="collapse" for="c-42241624">[-]</label><label class="expand" for="c-42241624">[11 more]</label></div><br/><div class="children"><div class="content">That will probably never happen because of the fundamental nature of blob storage.<p>Individual objects are split into multiple blocks, each of which can be stored independently on different underlying servers. Each can see its own block, but not any other block.<p>Calculating a hash like SHA256 would require a sequential scan through all blocks. This <i>could</i> be done with a minimum of network traffic if instead of streaming the bytes to a central server to hash, the <i>hash state</i> is forwarded from block server to block server in sequence. Still though, it would be a very slow serial operation that could be fairly chatty too if there are many tiny blocks.<p>What <i>could</i> work would be to use a Merkle tree hash construction where some of subdivision boundaries match the block sizes.</div><br/><div id="42241854" class="c"><input type="checkbox" id="c-42241854" checked=""/><div class="controls bullet"><span class="by">texthompson</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241624">parent</a><span>|</span><a href="#42241693">next</a><span>|</span><label class="collapse" for="c-42241854">[-]</label><label class="expand" for="c-42241854">[6 more]</label></div><br/><div class="children"><div class="content">Why would you PUT an object, then download it again to a central server in the first place? If a service is accepting an upload of the bytes, it is already doing a pass over all the bytes anyway. It doesn&#x27;t seem like a ton of overhead to calculate SHA256 in the 4092-byte chunks as the upload progresses. I suspect that sort of calculation would happen anyways.</div><br/><div id="42241955" class="c"><input type="checkbox" id="c-42241955" checked=""/><div class="controls bullet"><span class="by">willglynn</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241854">parent</a><span>|</span><a href="#42241936">next</a><span>|</span><label class="collapse" for="c-42241955">[-]</label><label class="expand" for="c-42241955">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right, and in fact S3 does this with the `ETag:` headerâ¦ in the simple case.<p>S3 also supports more complicated cases where the entire object may not be visible to any single component while it is being written, and in those cases, `ETag:` works differently.<p>&gt; * Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS Management Console, and are encrypted by SSE-S3 or plaintext, have ETags that are an MD5 digest of their object data.<p>&gt; * Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS Management Console, and are encrypted by SSE-C or SSE-KMS, have ETags that are not an MD5 digest of their object data.<p>&gt; * If an object is created by either the Multipart Upload or Part Copy operation, the ETag is not an MD5 digest, regardless of the method of encryption. If an object is larger than 16 MB, the AWS Management Console will upload or copy that object as a Multipart Upload, and therefore the ETag will not be an MD5 digest.<p><a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;API&#x2F;API_Object.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;API&#x2F;API_Object.h...</a></div><br/></div></div><div id="42241936" class="c"><input type="checkbox" id="c-42241936" checked=""/><div class="controls bullet"><span class="by">danielheath</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241854">parent</a><span>|</span><a href="#42241955">prev</a><span>|</span><a href="#42241693">next</a><span>|</span><label class="collapse" for="c-42241936">[-]</label><label class="expand" for="c-42241936">[4 more]</label></div><br/><div class="children"><div class="content">S3 supports multipart uploads which donât necessarily send all the parts to the same server.</div><br/><div id="42241974" class="c"><input type="checkbox" id="c-42241974" checked=""/><div class="controls bullet"><span class="by">texthompson</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241936">parent</a><span>|</span><a href="#42241693">next</a><span>|</span><label class="collapse" for="c-42241974">[-]</label><label class="expand" for="c-42241974">[3 more]</label></div><br/><div class="children"><div class="content">Why does it matter where the bytes are stored at rest? Isn&#x27;t everything you need for SHA-256 just the results of the SHA-256 algorithm on every 4096-byte block? I think you could just calculate that as the data is streamed in.</div><br/><div id="42243763" class="c"><input type="checkbox" id="c-42243763" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241974">parent</a><span>|</span><a href="#42242181">next</a><span>|</span><label class="collapse" for="c-42243763">[-]</label><label class="expand" for="c-42243763">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Isn&#x27;t everything you need for SHA-256 just the results of the SHA-256 algorithm on every 4096-byte block?<p>No, you need the hash of the previous block before you can start processing the next block.</div><br/></div></div><div id="42242181" class="c"><input type="checkbox" id="c-42242181" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241974">parent</a><span>|</span><a href="#42243763">prev</a><span>|</span><a href="#42241693">next</a><span>|</span><label class="collapse" for="c-42242181">[-]</label><label class="expand" for="c-42242181">[1 more]</label></div><br/><div class="children"><div class="content">The data is not necessarily &quot;streamed&quot; in! That&#x27;s a significant design feature to allow <i>parallel</i> uploads of a single object using many parts (&quot;blocks&quot;). See: <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;API&#x2F;API_CreateMultipartUpload.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AmazonS3&#x2F;latest&#x2F;API&#x2F;API_CreateMu...</a></div><br/></div></div></div></div></div></div></div></div><div id="42241693" class="c"><input type="checkbox" id="c-42241693" checked=""/><div class="controls bullet"><span class="by">losteric</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241624">parent</a><span>|</span><a href="#42241854">prev</a><span>|</span><a href="#42242059">next</a><span>|</span><label class="collapse" for="c-42241693">[-]</label><label class="expand" for="c-42241693">[2 more]</label></div><br/><div class="children"><div class="content">Why does the architect of blob storage matter? The hash can be calculated as data streams in for the first write, before data gets dispersed into multiple physically stored blocks.</div><br/><div id="42241901" class="c"><input type="checkbox" id="c-42241901" checked=""/><div class="controls bullet"><span class="by">willglynn</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241693">parent</a><span>|</span><a href="#42242059">next</a><span>|</span><label class="collapse" for="c-42241901">[-]</label><label class="expand" for="c-42241901">[1 more]</label></div><br/><div class="children"><div class="content">It is common to use multipart uploads for large objects, since this both increases throughput and decreases latency. Individual part uploads can happen in parallel and complete in any sequence. There&#x27;s no architectural requirement that an entire object pass through a single system on either S3&#x27;s side or on the client&#x27;s side.</div><br/></div></div></div></div><div id="42242059" class="c"><input type="checkbox" id="c-42242059" checked=""/><div class="controls bullet"><span class="by">flakes</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241624">parent</a><span>|</span><a href="#42241693">prev</a><span>|</span><a href="#42242044">next</a><span>|</span><label class="collapse" for="c-42242059">[-]</label><label class="expand" for="c-42242059">[1 more]</label></div><br/><div class="children"><div class="content">You have just re-invented IPFS! <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;InterPlanetary_File_System" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;InterPlanetary_File_System</a></div><br/></div></div><div id="42242044" class="c"><input type="checkbox" id="c-42242044" checked=""/><div class="controls bullet"><span class="by">Salgat</span><span>|</span><a href="#42241487">root</a><span>|</span><a href="#42241624">parent</a><span>|</span><a href="#42242059">prev</a><span>|</span><a href="#42241528">next</a><span>|</span><label class="collapse" for="c-42242044">[-]</label><label class="expand" for="c-42242044">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t that the point of the metadata? Calculate the hash ahead of time and store it in the metadata as part of the atomic commit for the blob (at least for S3).</div><br/></div></div></div></div></div></div><div id="42241528" class="c"><input type="checkbox" id="c-42241528" checked=""/><div class="controls bullet"><span class="by">Sirupsen</span><span>|</span><a href="#42241487">prev</a><span>|</span><a href="#42241036">next</a><span>|</span><label class="collapse" for="c-42241528">[-]</label><label class="expand" for="c-42241528">[9 more]</label></div><br/><div class="children"><div class="content">To avoid any dependencies other than object storage, we&#x27;ve been making use of this in our database (turbopuffer.com) for consensus and concurrency control since day one.  Been waiting for this since the day we launched on Google Cloud Storage ~1 year ago. Our bet that S3 would get it in a reasonable time-frame worked out!<p><a href="https:&#x2F;&#x2F;turbopuffer.com&#x2F;blog&#x2F;turbopuffer" rel="nofollow">https:&#x2F;&#x2F;turbopuffer.com&#x2F;blog&#x2F;turbopuffer</a></div><br/><div id="42243418" class="c"><input type="checkbox" id="c-42243418" checked=""/><div class="controls bullet"><span class="by">CobrastanJorji</span><span>|</span><a href="#42241528">parent</a><span>|</span><a href="#42242120">next</a><span>|</span><label class="collapse" for="c-42243418">[-]</label><label class="expand" for="c-42243418">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m glad that bet worked out for you, but what made you think one year ago that S3 would introduce it soon that was untrue for the previous 15 years?</div><br/></div></div><div id="42242120" class="c"><input type="checkbox" id="c-42242120" checked=""/><div class="controls bullet"><span class="by">amazingamazing</span><span>|</span><a href="#42241528">parent</a><span>|</span><a href="#42243418">prev</a><span>|</span><a href="#42241036">next</a><span>|</span><label class="collapse" for="c-42242120">[-]</label><label class="expand" for="c-42242120">[7 more]</label></div><br/><div class="children"><div class="content">Interesting that whatâs basically an ad is the top comment - itâs not like this is open source or anything - canât even use it immediately (you have to apply for access). Totally proprietary. At least elasticsearch is APGL, saying nothing of open search which also supports use of S3</div><br/><div id="42242372" class="c"><input type="checkbox" id="c-42242372" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#42241528">root</a><span>|</span><a href="#42242120">parent</a><span>|</span><a href="#42243005">next</a><span>|</span><label class="collapse" for="c-42242372">[-]</label><label class="expand" for="c-42242372">[3 more]</label></div><br/><div class="children"><div class="content">Someone made an informed technical bet that worked out. Sounds like HN material to me. (Also, is it really a useful ad if you can&#x27;t easily use the product?)</div><br/><div id="42242384" class="c"><input type="checkbox" id="c-42242384" checked=""/><div class="controls bullet"><span class="by">amazingamazing</span><span>|</span><a href="#42241528">root</a><span>|</span><a href="#42242372">parent</a><span>|</span><a href="#42243005">next</a><span>|</span><label class="collapse" for="c-42242384">[-]</label><label class="expand" for="c-42242384">[2 more]</label></div><br/><div class="children"><div class="content">Worked out how? Thereâs no implementation. Itâs just conjecture.</div><br/><div id="42242443" class="c"><input type="checkbox" id="c-42242443" checked=""/><div class="controls bullet"><span class="by">hedora</span><span>|</span><a href="#42241528">root</a><span>|</span><a href="#42242384">parent</a><span>|</span><a href="#42243005">next</a><span>|</span><label class="collapse" for="c-42242443">[-]</label><label class="expand" for="c-42242443">[1 more]</label></div><br/><div class="children"><div class="content">Pretty much all other S3 implementations (including open source ones) support this or equivalent primitives, so this is great for interoperability with existing implementations.</div><br/></div></div></div></div></div></div><div id="42243005" class="c"><input type="checkbox" id="c-42243005" checked=""/><div class="controls bullet"><span class="by">ramraj07</span><span>|</span><a href="#42241528">root</a><span>|</span><a href="#42242120">parent</a><span>|</span><a href="#42242372">prev</a><span>|</span><a href="#42242717">next</a><span>|</span><label class="collapse" for="c-42243005">[-]</label><label class="expand" for="c-42243005">[1 more]</label></div><br/><div class="children"><div class="content">No one owes anyone open source. If they can make the business case work or if it works in their favor, sure.</div><br/></div></div><div id="42242717" class="c"><input type="checkbox" id="c-42242717" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#42241528">root</a><span>|</span><a href="#42242120">parent</a><span>|</span><a href="#42243005">prev</a><span>|</span><a href="#42241036">next</a><span>|</span><label class="collapse" for="c-42242717">[-]</label><label class="expand" for="c-42242717">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;slatedb&#x2F;slatedb">https:&#x2F;&#x2F;github.com&#x2F;slatedb&#x2F;slatedb</a> will, I expect, use this at some point. Object backed DB, which is open source.</div><br/><div id="42243076" class="c"><input type="checkbox" id="c-42243076" checked=""/><div class="controls bullet"><span class="by">benesch</span><span>|</span><a href="#42241528">root</a><span>|</span><a href="#42242717">parent</a><span>|</span><a href="#42241036">next</a><span>|</span><label class="collapse" for="c-42243076">[-]</label><label class="expand" for="c-42243076">[1 more]</label></div><br/><div class="children"><div class="content">Yes! Iâm actively working on it, in fact. Weâre waiting on the next release of the Rust `object_store` crate, which will bring support for S3âs native conditional puts.<p>If you want to follow along: <a href="https:&#x2F;&#x2F;github.com&#x2F;slatedb&#x2F;slatedb&#x2F;issues&#x2F;164">https:&#x2F;&#x2F;github.com&#x2F;slatedb&#x2F;slatedb&#x2F;issues&#x2F;164</a></div><br/></div></div></div></div></div></div></div></div><div id="42241036" class="c"><input type="checkbox" id="c-42241036" checked=""/><div class="controls bullet"><span class="by">1a527dd5</span><span>|</span><a href="#42241528">prev</a><span>|</span><a href="#42240969">next</a><span>|</span><label class="collapse" for="c-42241036">[-]</label><label class="expand" for="c-42241036">[12 more]</label></div><br/><div class="children"><div class="content">Be still my beating heart. I have lived to see this day.<p>Genuinely, we&#x27;ve wanted this for ages and we got half way there with strong consistency.</div><br/><div id="42241188" class="c"><input type="checkbox" id="c-42241188" checked=""/><div class="controls bullet"><span class="by">ncruces</span><span>|</span><a href="#42241036">parent</a><span>|</span><a href="#42241305">next</a><span>|</span><label class="collapse" for="c-42241188">[-]</label><label class="expand" for="c-42241188">[1 more]</label></div><br/><div class="children"><div class="content">Might finally be possible to do this on S3:
<a href="https:&#x2F;&#x2F;pkg.go.dev&#x2F;github.com&#x2F;ncruces&#x2F;go-gcp&#x2F;gmutex" rel="nofollow">https:&#x2F;&#x2F;pkg.go.dev&#x2F;github.com&#x2F;ncruces&#x2F;go-gcp&#x2F;gmutex</a></div><br/></div></div><div id="42241305" class="c"><input type="checkbox" id="c-42241305" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#42241036">parent</a><span>|</span><a href="#42241188">prev</a><span>|</span><a href="#42240969">next</a><span>|</span><label class="collapse" for="c-42241305">[-]</label><label class="expand" for="c-42241305">[10 more]</label></div><br/><div class="children"><div class="content">So....given CAP, which one did they give up</div><br/><div id="42241792" class="c"><input type="checkbox" id="c-42241792" checked=""/><div class="controls bullet"><span class="by">the_arun</span><span>|</span><a href="#42241036">root</a><span>|</span><a href="#42241305">parent</a><span>|</span><a href="#42241494">next</a><span>|</span><label class="collapse" for="c-42241792">[-]</label><label class="expand" for="c-42241792">[1 more]</label></div><br/><div class="children"><div class="content">I thought they have implemented Optimistic locking now to coordinate concurrent writes. How does it change anything in CAP?</div><br/></div></div><div id="42241494" class="c"><input type="checkbox" id="c-42241494" checked=""/><div class="controls bullet"><span class="by">moralestapia</span><span>|</span><a href="#42241036">root</a><span>|</span><a href="#42241305">parent</a><span>|</span><a href="#42241792">prev</a><span>|</span><a href="#42241338">next</a><span>|</span><label class="collapse" for="c-42241494">[-]</label><label class="expand" for="c-42241494">[1 more]</label></div><br/><div class="children"><div class="content">A tiny bit of availability, unnoticeable at web scale.</div><br/></div></div><div id="42241338" class="c"><input type="checkbox" id="c-42241338" checked=""/><div class="controls bullet"><span class="by">johnrob</span><span>|</span><a href="#42241036">root</a><span>|</span><a href="#42241305">parent</a><span>|</span><a href="#42241494">prev</a><span>|</span><a href="#42240969">next</a><span>|</span><label class="collapse" for="c-42241338">[-]</label><label class="expand" for="c-42241338">[7 more]</label></div><br/><div class="children"><div class="content">Iâd wager that the algorithm is slightly eager to throw a consistency error if itâs unable to verify across partitions.  Since the caller is naturally ready for this error, itâs likely not a problem.  So in short itâs the P :)</div><br/><div id="42241363" class="c"><input type="checkbox" id="c-42241363" checked=""/><div class="controls bullet"><span class="by">alanyilunli</span><span>|</span><a href="#42241036">root</a><span>|</span><a href="#42241338">parent</a><span>|</span><a href="#42241751">next</a><span>|</span><label class="collapse" for="c-42241363">[-]</label><label class="expand" for="c-42241363">[5 more]</label></div><br/><div class="children"><div class="content">Shouldn&#x27;t that be the A then? Since the network partition is still there but availability is non-guaranteed.</div><br/><div id="42241505" class="c"><input type="checkbox" id="c-42241505" checked=""/><div class="controls bullet"><span class="by">johnrob</span><span>|</span><a href="#42241036">root</a><span>|</span><a href="#42241363">parent</a><span>|</span><a href="#42241751">next</a><span>|</span><label class="collapse" for="c-42241505">[-]</label><label class="expand" for="c-42241505">[4 more]</label></div><br/><div class="children"><div class="content">Yes, definitely.  Good point (I was knee jerk assuming the A is always chosen and the real âchoiceâ is between C and P).</div><br/><div id="42241886" class="c"><input type="checkbox" id="c-42241886" checked=""/><div class="controls bullet"><span class="by">btown</span><span>|</span><a href="#42241036">root</a><span>|</span><a href="#42241505">parent</a><span>|</span><a href="#42241772">next</a><span>|</span><label class="collapse" for="c-42241886">[-]</label><label class="expand" for="c-42241886">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;tqdev.com&#x2F;2024-the-p-in-cap-is-for-performance" rel="nofollow">https:&#x2F;&#x2F;tqdev.com&#x2F;2024-the-p-in-cap-is-for-performance</a> is a really interesting take on this as a response to <a href="https:&#x2F;&#x2F;blog.dtornow.com&#x2F;the-cap-theorem.-the-bad-the-bad-the-ugly&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.dtornow.com&#x2F;the-cap-theorem.-the-bad-the-bad-th...</a> - essentially, the only way to get CA is if you&#x27;re willing to say that every request will succeed eventually, but it might take an unbounded amount of time for partitions to heal, and you have to be willing to wait indefinitely for that to happen. Which can indeed make sense for asynchronous messaging, but not for real-time applications as we think about them in the modern day. In practice, if you&#x27;re talking about CAP for high-performance systems, you&#x27;re choosing either CP or AP.</div><br/></div></div><div id="42241772" class="c"><input type="checkbox" id="c-42241772" checked=""/><div class="controls bullet"><span class="by">rhaen</span><span>|</span><a href="#42241036">root</a><span>|</span><a href="#42241505">parent</a><span>|</span><a href="#42241886">prev</a><span>|</span><a href="#42241751">next</a><span>|</span><label class="collapse" for="c-42241772">[-]</label><label class="expand" for="c-42241772">[2 more]</label></div><br/><div class="children"><div class="content">Well, P isn&#x27;t really much of a choice, I don&#x27;t think you can opt out of acts of god.</div><br/><div id="42241869" class="c"><input type="checkbox" id="c-42241869" checked=""/><div class="controls bullet"><span class="by">fwip</span><span>|</span><a href="#42241036">root</a><span>|</span><a href="#42241772">parent</a><span>|</span><a href="#42241751">next</a><span>|</span><label class="collapse" for="c-42241869">[-]</label><label class="expand" for="c-42241869">[1 more]</label></div><br/><div class="children"><div class="content">You can design to minimize P, though. For instance, if you have all the services running on the same physical box, and make people enter the room to use it instead of over the Internet, &quot;partition&quot; becomes much less likely. (This example is a bit silly.)<p>But you&#x27;re right, if you take a broad view of P, the choice is really between consistency and availability.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="42240969" class="c"><input type="checkbox" id="c-42240969" checked=""/><div class="controls bullet"><span class="by">koolba</span><span>|</span><a href="#42241036">prev</a><span>|</span><a href="#42241531">next</a><span>|</span><label class="collapse" for="c-42240969">[-]</label><label class="expand" for="c-42240969">[2 more]</label></div><br/><div class="children"><div class="content">This combined with the read-after-write consistency guarantee is a perfect building block (pun intended) for incremental append only storage atop an object store. It solves the biggest problem with coordinating multiple writers to a WAL.</div><br/><div id="42240996" class="c"><input type="checkbox" id="c-42240996" checked=""/><div class="controls bullet"><span class="by">IgorPartola</span><span>|</span><a href="#42240969">parent</a><span>|</span><a href="#42241531">next</a><span>|</span><label class="collapse" for="c-42240996">[-]</label><label class="expand" for="c-42240996">[1 more]</label></div><br/><div class="children"><div class="content">Rename for objects and âdirectoriesâ also. Atomic.</div><br/></div></div></div></div><div id="42241531" class="c"><input type="checkbox" id="c-42241531" checked=""/><div class="controls bullet"><span class="by">CubsFan1060</span><span>|</span><a href="#42240969">prev</a><span>|</span><a href="#42242399">next</a><span>|</span><label class="collapse" for="c-42241531">[-]</label><label class="expand" for="c-42241531">[12 more]</label></div><br/><div class="children"><div class="content">I feel dumb for asking this, but can someone explain why this is such a big deal?  Iâm not quite sure I am grokking it yet.</div><br/><div id="42241577" class="c"><input type="checkbox" id="c-42241577" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42241531">parent</a><span>|</span><a href="#42243437">next</a><span>|</span><label class="collapse" for="c-42241577">[-]</label><label class="expand" for="c-42241577">[1 more]</label></div><br/><div class="children"><div class="content">If my memory of parallel algorithms class serves me right, you can build any synchronization algorithm on top of compare-and-swap as an atomic primitive.<p>As a (horribly inefficient, in case of non-trivial write contention) toy example, you could use S3 as a lock-free concurrent SQLite storage backend: Reads work as expected by fetching the entire database and satisfying the operation locally; writes work like this:<p>- Download the current database copy<p>- Perform your write locally<p>- Upload it back using &quot;Put-If-Match&quot; and the pre-edit copy as the matched object.<p>- If you get success, consider the transaction successful.<p>- If you get failure, go back to step 1 and try again.</div><br/></div></div><div id="42243437" class="c"><input type="checkbox" id="c-42243437" checked=""/><div class="controls bullet"><span class="by">CobrastanJorji</span><span>|</span><a href="#42241531">parent</a><span>|</span><a href="#42241577">prev</a><span>|</span><a href="#42241551">next</a><span>|</span><label class="collapse" for="c-42243437">[-]</label><label class="expand" for="c-42243437">[1 more]</label></div><br/><div class="children"><div class="content">It is often very important to know, when you write an object, what the previous state was. Say you sold plushies and you had 100 plushies in a warehouse. You create a file &quot;remainingPlushies.txt&quot; that stores &quot;100&quot;. If somebody buys a plushie, you read the file, and if it&#x27;s bigger than 0, you subtract 1, write the new version of the file, and okay the sale.<p>Without conditional writes, two instances of your application might both read &quot;100&quot;, both subtract 1, and both write &quot;99&quot;. If they checked the file afterward, both would think everything was fine. But things aren&#x27;t find because you&#x27;ve actually sold two.<p>The other cloud storage providers have had these sorts of conditional write features since basically forever, and it&#x27;s always been really weird that S3 has lacked them.</div><br/></div></div><div id="42241551" class="c"><input type="checkbox" id="c-42241551" checked=""/><div class="controls bullet"><span class="by">Sirupsen</span><span>|</span><a href="#42241531">parent</a><span>|</span><a href="#42243437">prev</a><span>|</span><a href="#42242041">next</a><span>|</span><label class="collapse" for="c-42241551">[-]</label><label class="expand" for="c-42241551">[6 more]</label></div><br/><div class="children"><div class="content">The short of it is that building a database on top of object storage has generally required a complicated, distributed system for consensus&#x2F;metadata. CAS makes it possible to build these big data systems without any other dependencies. This is a win for simplicity and reliability.</div><br/><div id="42241563" class="c"><input type="checkbox" id="c-42241563" checked=""/><div class="controls bullet"><span class="by">CubsFan1060</span><span>|</span><a href="#42241531">root</a><span>|</span><a href="#42241551">parent</a><span>|</span><a href="#42242041">next</a><span>|</span><label class="collapse" for="c-42241563">[-]</label><label class="expand" for="c-42241563">[5 more]</label></div><br/><div class="children"><div class="content">Thanks!   Do they mention when the comparison is done?  Is it before, after, or during an upload? (For instance, if I have a 4tb file in a multi part upload, would I only know it would fail as soon as the whole file is uploaded?)</div><br/><div id="42242060" class="c"><input type="checkbox" id="c-42242060" checked=""/><div class="controls bullet"><span class="by">timmg</span><span>|</span><a href="#42241531">root</a><span>|</span><a href="#42241563">parent</a><span>|</span><a href="#42241715">next</a><span>|</span><label class="collapse" for="c-42242060">[-]</label><label class="expand" for="c-42242060">[1 more]</label></div><br/><div class="children"><div class="content">(I assume) it will fail if the eTag doesn&#x27;t match -- the instance it got the header.<p>The main point of it is: I have an object that I want to mutate.  I <i>think</i> I have the latest version in memory.  So I update in memory and upload it to S3 <i>with the eTag of the version I have</i> and tell it to only commit <i>if that is the latest version</i>.  If it &quot;fails&quot;, I re-download the object, re-apply the mutation, and try again.</div><br/></div></div><div id="42241715" class="c"><input type="checkbox" id="c-42241715" checked=""/><div class="controls bullet"><span class="by">poincaredisk</span><span>|</span><a href="#42241531">root</a><span>|</span><a href="#42241563">parent</a><span>|</span><a href="#42242060">prev</a><span>|</span><a href="#42242041">next</a><span>|</span><label class="collapse" for="c-42241715">[-]</label><label class="expand" for="c-42241715">[3 more]</label></div><br/><div class="children"><div class="content">I imagine, for it to make sense, that the comparison is done at the last possible moment, before atomically swapping the file contents.</div><br/><div id="42242141" class="c"><input type="checkbox" id="c-42242141" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42241531">root</a><span>|</span><a href="#42241715">parent</a><span>|</span><a href="#42241982">next</a><span>|</span><label class="collapse" for="c-42242141">[-]</label><label class="expand" for="c-42242141">[1 more]</label></div><br/><div class="children"><div class="content">Practically, they could do both: Do an early reject of a given POST in case the ETag does not match, but re-validate this just before swapping out the objects (and committing to considering the given request as the successful one globally).<p>That said, I&#x27;m not sure if common HTTP libraries look at response headers before they&#x27;re done posting a response body, or if that&#x27;s even allowed&#x2F;possible in HTTP? It seems feasible at a first glance with chunked encoding, at least.<p>Edit: Upon looking a bit, it seems that informational response codes, e.g. 100 (Continue) in combination with Expect 100-continue in the requests, could enable just that and avoid an extra GET with If-Match.</div><br/></div></div><div id="42241982" class="c"><input type="checkbox" id="c-42241982" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#42241531">root</a><span>|</span><a href="#42241715">parent</a><span>|</span><a href="#42242141">prev</a><span>|</span><a href="#42242041">next</a><span>|</span><label class="collapse" for="c-42241982">[-]</label><label class="expand" for="c-42241982">[1 more]</label></div><br/><div class="children"><div class="content">I can imagine it might be useful to make this a choice for databases with high frequency small swaps and occasional large ones.<p>1) default, load-compare-&amp;-swap for small fast load&#x2F;swaps.<p>2) optional, compare-load-&amp;-swap to allow a large load to pass its compare, and cut in front of all the fast small swap that would otherwise create an un-hittable moving target during its long loads for its own compare.<p>3) If the load itself was stable relative to the compare, then it could be pre-loaded and swapped into a holding location, followed by as many fast compare-&amp;-swaps as needed to get it into the right location.</div><br/></div></div></div></div></div></div></div></div><div id="42242041" class="c"><input type="checkbox" id="c-42242041" checked=""/><div class="controls bullet"><span class="by">jayd16</span><span>|</span><a href="#42241531">parent</a><span>|</span><a href="#42241551">prev</a><span>|</span><a href="#42241537">next</a><span>|</span><label class="collapse" for="c-42242041">[-]</label><label class="expand" for="c-42242041">[2 more]</label></div><br/><div class="children"><div class="content">When you upload a change you can know you&#x27;re not clobbering changes you never saw.</div><br/><div id="42243012" class="c"><input type="checkbox" id="c-42243012" checked=""/><div class="controls bullet"><span class="by">ramraj07</span><span>|</span><a href="#42241531">root</a><span>|</span><a href="#42242041">parent</a><span>|</span><a href="#42241537">next</a><span>|</span><label class="collapse" for="c-42243012">[-]</label><label class="expand" for="c-42243012">[1 more]</label></div><br/><div class="children"><div class="content">Brilliant single line that is better than every other description above. Kudos.</div><br/></div></div></div></div></div></div><div id="42242399" class="c"><input type="checkbox" id="c-42242399" checked=""/><div class="controls bullet"><span class="by">maglite77</span><span>|</span><a href="#42241531">prev</a><span>|</span><a href="#42241308">next</a><span>|</span><label class="collapse" for="c-42242399">[-]</label><label class="expand" for="c-42242399">[2 more]</label></div><br/><div class="children"><div class="content">Noting that Azure Blob storage supports e-tag &#x2F; optimistic controls as well (via If-Match conditions)[1], how does this differ? Or is it the same feature?<p>[1]: <a href="https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;azure&#x2F;storage&#x2F;blobs&#x2F;concurrency-manage" rel="nofollow">https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;azure&#x2F;storage&#x2F;blobs&#x2F;concur...</a></div><br/><div id="42242409" class="c"><input type="checkbox" id="c-42242409" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42242399">parent</a><span>|</span><a href="#42241308">next</a><span>|</span><label class="collapse" for="c-42242409">[-]</label><label class="expand" for="c-42242409">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the same feature. Google Cloud Storage has it too: <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;storage&#x2F;docs&#x2F;request-preconditions#precondition_criteria" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;storage&#x2F;docs&#x2F;request-preconditions#...</a></div><br/></div></div></div></div><div id="42241308" class="c"><input type="checkbox" id="c-42241308" checked=""/><div class="controls bullet"><span class="by">offmycloud</span><span>|</span><a href="#42242399">prev</a><span>|</span><a href="#42242292">next</a><span>|</span><label class="collapse" for="c-42241308">[-]</label><label class="expand" for="c-42241308">[7 more]</label></div><br/><div class="children"><div class="content">If the default ETag algorithm for non-encrypted, non-multipart uploads in AWS is a plain MD5 hash, is this subject to failure for object data with MD5 collisions?<p>I&#x27;m thinking of a situation in which an application assumes that different (possibly adversarial) user-provided data will always generate a different ETag.</div><br/><div id="42243448" class="c"><input type="checkbox" id="c-42243448" checked=""/><div class="controls bullet"><span class="by">CobrastanJorji</span><span>|</span><a href="#42241308">parent</a><span>|</span><a href="#42241391">next</a><span>|</span><label class="collapse" for="c-42243448">[-]</label><label class="expand" for="c-42243448">[1 more]</label></div><br/><div class="children"><div class="content">With Google Cloud Storage, you can solve this by conditionally writing based on the &quot;generation number&quot; of the object, which always increases with each new write, so you can know whether the object has been overwritten regardless of its contents. I think Azure also has an equivalent.</div><br/></div></div><div id="42241391" class="c"><input type="checkbox" id="c-42241391" checked=""/><div class="controls bullet"><span class="by">revnode</span><span>|</span><a href="#42241308">parent</a><span>|</span><a href="#42243448">prev</a><span>|</span><a href="#42241417">next</a><span>|</span><label class="collapse" for="c-42241391">[-]</label><label class="expand" for="c-42241391">[2 more]</label></div><br/><div class="children"><div class="content">MD5 hash collisions are unlikely to happen at random. The defect was that you can make it happen purposefully, making it useless for security.</div><br/><div id="42241928" class="c"><input type="checkbox" id="c-42241928" checked=""/><div class="controls bullet"><span class="by">aphantastic</span><span>|</span><a href="#42241308">root</a><span>|</span><a href="#42241391">parent</a><span>|</span><a href="#42241417">next</a><span>|</span><label class="collapse" for="c-42241928">[-]</label><label class="expand" for="c-42241928">[1 more]</label></div><br/><div class="children"><div class="content">Sure, but theoretically you could have a system where a distributed log of user generated content is built via this CAS&#x2F;&#x2F;MD5 primitive. A malicious actor could craft the data such that entries are dropped.</div><br/></div></div></div></div><div id="42242333" class="c"><input type="checkbox" id="c-42242333" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#42241308">parent</a><span>|</span><a href="#42242010">prev</a><span>|</span><a href="#42242292">next</a><span>|</span><label class="collapse" for="c-42242333">[-]</label><label class="expand" for="c-42242333">[1 more]</label></div><br/><div class="children"><div class="content">The default Etag is used to detect bit errors and and MD5 is fine for that. S3 does support using SHA256 instead.</div><br/></div></div></div></div><div id="42242292" class="c"><input type="checkbox" id="c-42242292" checked=""/><div class="controls bullet"><span class="by">amazingamazing</span><span>|</span><a href="#42241308">prev</a><span>|</span><a href="#42243537">next</a><span>|</span><label class="collapse" for="c-42242292">[-]</label><label class="expand" for="c-42242292">[2 more]</label></div><br/><div class="children"><div class="content">Ironically with this and lambda you could make a serverless sqlite by mapping pages to objects, using http range reads to read the db and lambda to translate queries to the writes in the appropriate pages via cas. Prior to this it would require a server to handle concurrent writers, making the whole thing a nonstarter for âserverlessâ.<p>Too bad performance would be terrible without a caching layer (ebs).</div><br/><div id="42242312" class="c"><input type="checkbox" id="c-42242312" checked=""/><div class="controls bullet"><span class="by">captn3m0</span><span>|</span><a href="#42242292">parent</a><span>|</span><a href="#42243537">next</a><span>|</span><label class="collapse" for="c-42242312">[-]</label><label class="expand" for="c-42242312">[1 more]</label></div><br/><div class="children"><div class="content">For read heavy workloads, you could cache the results at cloudfront. Maybe we will someday see Wordpress-on-Lambda-to-Sqlite-over-S3.</div><br/></div></div></div></div><div id="42243537" class="c"><input type="checkbox" id="c-42243537" checked=""/><div class="controls bullet"><span class="by">anonymousDan</span><span>|</span><a href="#42242292">prev</a><span>|</span><a href="#42241812">next</a><span>|</span><label class="collapse" for="c-42243537">[-]</label><label class="expand" for="c-42243537">[1 more]</label></div><br/><div class="children"><div class="content">Would be interesting to understand how they&#x27;ve implemented it and they whether there is any perf impact on other API calls.</div><br/></div></div><div id="42241812" class="c"><input type="checkbox" id="c-42241812" checked=""/><div class="controls bullet"><span class="by">ipython</span><span>|</span><a href="#42243537">prev</a><span>|</span><a href="#42242329">next</a><span>|</span><label class="collapse" for="c-42241812">[-]</label><label class="expand" for="c-42241812">[1 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t wait to see what abomination Cory Quinn can come up with now given this new primitive! (see previous work abusing Route53 as a database: <a href="https:&#x2F;&#x2F;www.lastweekinaws.com&#x2F;blog&#x2F;route-53-amazons-premier-database&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.lastweekinaws.com&#x2F;blog&#x2F;route-53-amazons-premier-...</a>)</div><br/></div></div><div id="42242329" class="c"><input type="checkbox" id="c-42242329" checked=""/><div class="controls bullet"><span class="by">m_d_</span><span>|</span><a href="#42241812">prev</a><span>|</span><a href="#42242938">next</a><span>|</span><label class="collapse" for="c-42242329">[-]</label><label class="expand" for="c-42242329">[1 more]</label></div><br/><div class="children"><div class="content">s3fs&#x27;s <a href="https:&#x2F;&#x2F;github.com&#x2F;fsspec&#x2F;s3fs&#x2F;pull&#x2F;917">https:&#x2F;&#x2F;github.com&#x2F;fsspec&#x2F;s3fs&#x2F;pull&#x2F;917</a> was in response to the IfNoneMatch feature from the summer. How would people imagine this new feature being surfaced in a filesystem abstraction?</div><br/></div></div><div id="42242938" class="c"><input type="checkbox" id="c-42242938" checked=""/><div class="controls bullet"><span class="by">vytautask</span><span>|</span><a href="#42242329">prev</a><span>|</span><a href="#42241017">next</a><span>|</span><label class="collapse" for="c-42242938">[-]</label><label class="expand" for="c-42242938">[2 more]</label></div><br/><div class="children"><div class="content">An open-source implementation of Amazon S3 - MinIO has had it for almost two years (relevant post: <a href="https:&#x2F;&#x2F;blog.min.io&#x2F;leading-the-way-minios-conditional-write-feature-for-modern-data-workloads&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.min.io&#x2F;leading-the-way-minios-conditional-write...</a>). Strangely, Amazon is catching up just now.</div><br/><div id="42243073" class="c"><input type="checkbox" id="c-42243073" checked=""/><div class="controls bullet"><span class="by">topspin</span><span>|</span><a href="#42242938">parent</a><span>|</span><a href="#42241017">next</a><span>|</span><label class="collapse" for="c-42243073">[-]</label><label class="expand" for="c-42243073">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not &quot;strange&quot; to me.  Object storage has been a long time coming, and it&#x27;s still being figured out: the entirely typical process of discovering useful and feasible primitives that expand applicability to more sophisticated problems.  This is obviously going occur first in smaller and&#x2F;or younger, more agile implementations, whereas AWS has the problem of implementing this at pretty much the largest conceivable scale with zero risk.  The lag is, therefore, entirely unsurprising.</div><br/></div></div></div></div><div id="42241017" class="c"><input type="checkbox" id="c-42241017" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#42242938">prev</a><span>|</span><a href="#42243278">next</a><span>|</span><label class="collapse" for="c-42241017">[-]</label><label class="expand" for="c-42241017">[7 more]</label></div><br/><div class="children"><div class="content">Finally. GCP has had this for a long time. Years ago I was surprised S3 didnât.</div><br/><div id="42241173" class="c"><input type="checkbox" id="c-42241173" checked=""/><div class="controls bullet"><span class="by">ncruces</span><span>|</span><a href="#42241017">parent</a><span>|</span><a href="#42241735">next</a><span>|</span><label class="collapse" for="c-42241173">[-]</label><label class="expand" for="c-42241173">[1 more]</label></div><br/><div class="children"><div class="content">GCS is just missing x-amz-copy-source-range in my book.<p>Can we have this Google?<p>â¦<p>Please?</div><br/></div></div><div id="42241735" class="c"><input type="checkbox" id="c-42241735" checked=""/><div class="controls bullet"><span class="by">mannyv</span><span>|</span><a href="#42241017">parent</a><span>|</span><a href="#42241173">prev</a><span>|</span><a href="#42243278">next</a><span>|</span><label class="collapse" for="c-42241735">[-]</label><label class="expand" for="c-42241735">[5 more]</label></div><br/><div class="children"><div class="content">GCP still doesn&#x27;t have triggers out of beta last time i checked (which was a while ago).</div><br/><div id="42243476" class="c"><input type="checkbox" id="c-42243476" checked=""/><div class="controls bullet"><span class="by">BrandonY</span><span>|</span><a href="#42241017">root</a><span>|</span><a href="#42241735">parent</a><span>|</span><a href="#42241748">next</a><span>|</span><label class="collapse" for="c-42243476">[-]</label><label class="expand" for="c-42243476">[1 more]</label></div><br/><div class="children"><div class="content">We do have Cloud Run Functions that trigger on Cloud Storage events, as well as Cloud Pub&#x2F;Sub notifications for the same. Is there a specific bit of functionality you&#x27;re looking for?</div><br/></div></div><div id="42241748" class="c"><input type="checkbox" id="c-42241748" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#42241017">root</a><span>|</span><a href="#42241735">parent</a><span>|</span><a href="#42243476">prev</a><span>|</span><a href="#42243278">next</a><span>|</span><label class="collapse" for="c-42241748">[-]</label><label class="expand" for="c-42241748">[3 more]</label></div><br/><div class="children"><div class="content">Gmail was in beta for five years, I don&#x27;t think that label really means anything.</div><br/><div id="42242341" class="c"><input type="checkbox" id="c-42242341" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#42241017">root</a><span>|</span><a href="#42241748">parent</a><span>|</span><a href="#42243278">next</a><span>|</span><label class="collapse" for="c-42242341">[-]</label><label class="expand" for="c-42242341">[2 more]</label></div><br/><div class="children"><div class="content">It means that Google doesn&#x27;t want to offer an SLA</div><br/><div id="42242652" class="c"><input type="checkbox" id="c-42242652" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#42241017">root</a><span>|</span><a href="#42242341">parent</a><span>|</span><a href="#42243278">next</a><span>|</span><label class="collapse" for="c-42242652">[-]</label><label class="expand" for="c-42242652">[1 more]</label></div><br/><div class="children"><div class="content">Not that it matters. It just changes the volume and timing of &quot;I believe I did bob&quot;</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42243278" class="c"><input type="checkbox" id="c-42243278" checked=""/><div class="controls bullet"><span class="by">lttlrck</span><span>|</span><a href="#42241017">prev</a><span>|</span><a href="#42241933">next</a><span>|</span><label class="collapse" for="c-42243278">[-]</label><label class="expand" for="c-42243278">[1 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this compare-and-set rather than compare-and-swap?</div><br/></div></div><div id="42241933" class="c"><input type="checkbox" id="c-42241933" checked=""/><div class="controls bullet"><span class="by">stevefan1999</span><span>|</span><a href="#42243278">prev</a><span>|</span><a href="#42241652">next</a><span>|</span><label class="collapse" for="c-42241933">[-]</label><label class="expand" for="c-42241933">[3 more]</label></div><br/><div class="children"><div class="content">So...are we closer to getting to use S3 as a...you guessed it...a database? With CAS, we are probably able to get a basic level of atomicity, and S3 itself is pretty durable, now we have to deal with consistency and isolation...although S3 branded itself as &quot;eventually consistent&quot;...</div><br/><div id="42241951" class="c"><input type="checkbox" id="c-42241951" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#42241933">parent</a><span>|</span><a href="#42242195">next</a><span>|</span><label class="collapse" for="c-42241951">[-]</label><label class="expand" for="c-42241951">[1 more]</label></div><br/><div class="children"><div class="content">People who want all those features use something like Delta Lake on top of object storage.</div><br/></div></div><div id="42242195" class="c"><input type="checkbox" id="c-42242195" checked=""/><div class="controls bullet"><span class="by">User23</span><span>|</span><a href="#42241933">parent</a><span>|</span><a href="#42241951">prev</a><span>|</span><a href="#42241652">next</a><span>|</span><label class="collapse" for="c-42242195">[-]</label><label class="expand" for="c-42242195">[1 more]</label></div><br/><div class="children"><div class="content">There was a great deal of interest in gossip protocols, eventual consistency, and such at Amazon in the mid oughts. So much so that they hired a certain Cornell professor along with the better part of his grad students to build out those technologies.</div><br/></div></div></div></div><div id="42241652" class="c"><input type="checkbox" id="c-42241652" checked=""/><div class="controls bullet"><span class="by">wanderingmind</span><span>|</span><a href="#42241933">prev</a><span>|</span><a href="#42241335">next</a><span>|</span><label class="collapse" for="c-42241652">[-]</label><label class="expand" for="c-42241652">[1 more]</label></div><br/><div class="children"><div class="content">Does this mean, in theory we will be able to manage multiple concurrent writes&#x2F;updates to s3 without having to use new solutions like Regatta[1] that was recently launched?<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42174204">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42174204</a></div><br/></div></div><div id="42241335" class="c"><input type="checkbox" id="c-42241335" checked=""/><div class="controls bullet"><span class="by">gravitronic</span><span>|</span><a href="#42241652">prev</a><span>|</span><a href="#42241781">next</a><span>|</span><label class="collapse" for="c-42241335">[-]</label><label class="expand" for="c-42241335">[1 more]</label></div><br/><div class="children"><div class="content">First thing I thought when I saw the headline was &quot;oh!  I should tell Sirupsen&quot;</div><br/></div></div><div id="42241781" class="c"><input type="checkbox" id="c-42241781" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#42241335">prev</a><span>|</span><a href="#42241692">next</a><span>|</span><label class="collapse" for="c-42241781">[-]</label><label class="expand" for="c-42241781">[1 more]</label></div><br/><div class="children"><div class="content">I implemented that extension in R2 at launch IIRC. Thanks for catching up &amp; helping move distributed storage applications a meaningful step forward. Intended sincerely. I&#x27;m sure adding this was non-trivial for a complex legacy codebase like that.</div><br/></div></div><div id="42241692" class="c"><input type="checkbox" id="c-42241692" checked=""/><div class="controls bullet"><span class="by">dvektor</span><span>|</span><a href="#42241781">prev</a><span>|</span><a href="#42242567">next</a><span>|</span><label class="collapse" for="c-42241692">[-]</label><label class="expand" for="c-42241692">[1 more]</label></div><br/><div class="children"><div class="content">[rejected]
error: failed to push some refs to remote repository<p>Finally we can have this with s3 :)</div><br/></div></div><div id="42242567" class="c"><input type="checkbox" id="c-42242567" checked=""/><div class="controls bullet"><span class="by">paulsutter</span><span>|</span><a href="#42241692">prev</a><span>|</span><a href="#42241601">next</a><span>|</span><label class="collapse" for="c-42242567">[-]</label><label class="expand" for="c-42242567">[1 more]</label></div><br/><div class="children"><div class="content">Whatâs amazing is that it took them so long to add these functions</div><br/></div></div><div id="42241601" class="c"><input type="checkbox" id="c-42241601" checked=""/><div class="controls bullet"><span class="by">rrr_oh_man</span><span>|</span><a href="#42242567">prev</a><span>|</span><a href="#42241325">next</a><span>|</span><label class="collapse" for="c-42241601">[-]</label><label class="expand" for="c-42241601">[2 more]</label></div><br/><div class="children"><div class="content">Could anybody explain for the uninitiated?</div><br/><div id="42241619" class="c"><input type="checkbox" id="c-42241619" checked=""/><div class="controls bullet"><span class="by">msoad</span><span>|</span><a href="#42241601">parent</a><span>|</span><a href="#42241325">next</a><span>|</span><label class="collapse" for="c-42241619">[-]</label><label class="expand" for="c-42241619">[1 more]</label></div><br/><div class="children"><div class="content">It ensures that when you try to upload (or âputâ) a new version of a file, the operation only succeeds if the file on the server still has the exact version (ETag) you specify. If someone else has updated the file in the meantime, your upload is blocked to prevent overwriting their changes.<p>This is especially useful in scenarios where multiple users or processes are working on the same data, as it helps maintain consistency and avoids accidental overwrites.<p>This is using the same mechanism as HTTP&#x27;s `If-None-Match` header so it&#x27;s easier to implement&#x2F;learn</div><br/></div></div></div></div><div id="42241325" class="c"><input type="checkbox" id="c-42241325" checked=""/><div class="controls bullet"><span class="by">tonymet</span><span>|</span><a href="#42241601">prev</a><span>|</span><a href="#42242587">next</a><span>|</span><label class="collapse" for="c-42241325">[-]</label><label class="expand" for="c-42241325">[3 more]</label></div><br/><div class="children"><div class="content">good example of how a simple feature on the surface (a header comparison) requires tremendous complexity and capacity on the backend.</div><br/><div id="42241351" class="c"><input type="checkbox" id="c-42241351" checked=""/><div class="controls bullet"><span class="by">akira2501</span><span>|</span><a href="#42241325">parent</a><span>|</span><a href="#42242587">next</a><span>|</span><label class="collapse" for="c-42241351">[-]</label><label class="expand" for="c-42241351">[2 more]</label></div><br/><div class="children"><div class="content">S3 is rated as &quot;durable&quot; as opposed to &quot;best effort.&quot;  It has lots of interesting guarantees as a result.</div><br/><div id="42242328" class="c"><input type="checkbox" id="c-42242328" checked=""/><div class="controls bullet"><span class="by">tonymet</span><span>|</span><a href="#42241325">root</a><span>|</span><a href="#42241351">parent</a><span>|</span><a href="#42242587">next</a><span>|</span><label class="collapse" for="c-42242328">[-]</label><label class="expand" for="c-42242328">[1 more]</label></div><br/><div class="children"><div class="content">Also they are faithful to their consistency commitments</div><br/></div></div></div></div></div></div><div id="42242587" class="c"><input type="checkbox" id="c-42242587" checked=""/><div class="controls bullet"><span class="by">thayne</span><span>|</span><a href="#42241325">prev</a><span>|</span><a href="#42242572">next</a><span>|</span><label class="collapse" for="c-42242587">[-]</label><label class="expand" for="c-42242587">[1 more]</label></div><br/><div class="children"><div class="content">Now if only you had more control over the ETag, so you could use a sha256 of the  total file (even for multi-part uploads), or a version counter, or a global counter from an external system, or a logical hash of the content as opposed to a hash of the bytes.</div><br/></div></div><div id="42242572" class="c"><input type="checkbox" id="c-42242572" checked=""/><div class="controls bullet"><span class="by">serbrech</span><span>|</span><a href="#42242587">prev</a><span>|</span><a href="#42242339">next</a><span>|</span><label class="collapse" for="c-42242572">[-]</label><label class="expand" for="c-42242572">[1 more]</label></div><br/><div class="children"><div class="content">Why is standard etag support making the frontpage?</div><br/></div></div><div id="42242339" class="c"><input type="checkbox" id="c-42242339" checked=""/><div class="controls bullet"><span class="by">grahamj</span><span>|</span><a href="#42242572">prev</a><span>|</span><a href="#42240935">next</a><span>|</span><label class="collapse" for="c-42242339">[-]</label><label class="expand" for="c-42242339">[1 more]</label></div><br/><div class="children"><div class="content">bender_neat.gif</div><br/></div></div></div></div></div></div></div></body></html>