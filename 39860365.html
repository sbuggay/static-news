<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1711702870159" as="style"/><link rel="stylesheet" href="styles.css?v=1711702870159"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/mratsim/Arraymancer">Arraymancer – Deep Learning Nim Library</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>archargelod</span> | <span>12 comments</span></div><br/><div><div id="39861382" class="c"><input type="checkbox" id="c-39861382" checked=""/><div class="controls bullet"><span class="by">angusturner</span><span>|</span><a href="#39861480">next</a><span>|</span><label class="collapse" for="c-39861382">[-]</label><label class="expand" for="c-39861382">[2 more]</label></div><br/><div class="children"><div class="content">I would love for a non-python based deep learning framework to gain traction.<p>My initial impression though is that the scope is very broad. Trying to be both sci-kit learn and numpy and torch seems like a recipe for doing none of these things very well.<p>Its interesting to contrast this with the visions&#x2F;aspirations of other new-ish deep learning frameworks. Starting with my favorite, Jax offers &quot;composable function transformations + autodiff&quot;. Obviously there is still a tonne of work to do this well, support multiple accelerators etc. etc. But notably I think they made the right call to leave high level abstractions (like fully-fledged NN libraries or optimisation libraries) out of the Jax core. It does what it says on the box. And it does it really really well.<p>TinyGrad seems like another interesting case study, in the sense that it is aggressively pushing to reduce complexity and LOC while still providing the relevant abstractions to do ML on multiple accelerators. It is quite young still, and I have my doubts about how much traction it will gain. Still a cool project though, and I like to see people pushing in this direction.<p>PyTorch obviously still has a tonne of mind-share (and I love it), but it is interesting to see the complexity of that project grow beyond what it is arguably necessary. (e.g. having a &quot;MultiHeadAttention&quot; implementation in PyTorch is a mistake in my opinion).</div><br/><div id="39861724" class="c"><input type="checkbox" id="c-39861724" checked=""/><div class="controls bullet"><span class="by">ezquerra</span><span>|</span><a href="#39861382">parent</a><span>|</span><a href="#39861480">next</a><span>|</span><label class="collapse" for="c-39861724">[-]</label><label class="expand" for="c-39861724">[1 more]</label></div><br/><div class="children"><div class="content">I am one of the Arraymancer contributors. I believe that what mratsim (Arraymancer’s creator) has done is pretty amazing but I agree that the scope is a quite ambitious. There’s been some talk about separating the deep learning bits into its own library (which I expect would be done in a backwards compatible way). Recently we worked on adding FFT support but instead of adding it to Arraymancer it was added to “impulse” (<a href="https:&#x2F;&#x2F;github.com&#x2F;SciNim&#x2F;impulse">https:&#x2F;&#x2F;github.com&#x2F;SciNim&#x2F;impulse</a>) which is a separate, signal processing focused library. There is also Vindaar’s datamancer (a pandas like dataframe library) and ggplotnim (a plotting library inspired by R’s ggplot). The combination of all of these libraries makes nim a very compelling language for signal processing, data science and ML.<p>Personally I’d like Arraymancer to be a great tensor library (basically a very good and ideally faster alternative to numpy and base Matlab). Frankly I think that it’s nearly there already. I’ve been using Arraymancer to port a 5G physical layer simulator from Matlab to nim and it’s been a joy. It’s not perfect by any means but it’s already very good. And given how fast nim’s scientific ecosystem keeps improving it will only get much better.</div><br/></div></div></div></div><div id="39861480" class="c"><input type="checkbox" id="c-39861480" checked=""/><div class="controls bullet"><span class="by">CornCobs</span><span>|</span><a href="#39861382">prev</a><span>|</span><a href="#39861657">next</a><span>|</span><label class="collapse" for="c-39861480">[-]</label><label class="expand" for="c-39861480">[3 more]</label></div><br/><div class="children"><div class="content">What syntax of nim&#x27;s is the network: ... Used to declaratively construct the neural networks? Is it a macro? Looks really neat!</div><br/><div id="39861563" class="c"><input type="checkbox" id="c-39861563" checked=""/><div class="controls bullet"><span class="by">warangal</span><span>|</span><a href="#39861480">parent</a><span>|</span><a href="#39861559">next</a><span>|</span><label class="collapse" for="c-39861563">[-]</label><label class="expand" for="c-39861563">[1 more]</label></div><br/><div class="children"><div class="content">It is a small DSL written using macros at <a href="https:&#x2F;&#x2F;github.com&#x2F;mratsim&#x2F;Arraymancer&#x2F;blob&#x2F;master&#x2F;src&#x2F;arraymancer&#x2F;nn&#x2F;nn_dsl.nim">https:&#x2F;&#x2F;github.com&#x2F;mratsim&#x2F;Arraymancer&#x2F;blob&#x2F;master&#x2F;src&#x2F;array...</a>.<p>Nim has pretty great meta-programming capabilities and arraymancer employs some cool features like emitting cuda-kernels on the fly using standard templates depending on backend !</div><br/></div></div><div id="39861559" class="c"><input type="checkbox" id="c-39861559" checked=""/><div class="controls bullet"><span class="by">supakeen</span><span>|</span><a href="#39861480">parent</a><span>|</span><a href="#39861563">prev</a><span>|</span><a href="#39861657">next</a><span>|</span><label class="collapse" for="c-39861559">[-]</label><label class="expand" for="c-39861559">[1 more]</label></div><br/><div class="children"><div class="content">Yes, Nim macros can fiddle with the AST: <a href="https:&#x2F;&#x2F;nim-lang.org&#x2F;docs&#x2F;macros.html" rel="nofollow">https:&#x2F;&#x2F;nim-lang.org&#x2F;docs&#x2F;macros.html</a><p>You can also see another (I think) neat example in `npeg`: <a href="https:&#x2F;&#x2F;github.com&#x2F;zevv&#x2F;npeg?tab=readme-ov-file#quickstart">https:&#x2F;&#x2F;github.com&#x2F;zevv&#x2F;npeg?tab=readme-ov-file#quickstart</a></div><br/></div></div></div></div><div id="39861657" class="c"><input type="checkbox" id="c-39861657" checked=""/><div class="controls bullet"><span class="by">wodenokoto</span><span>|</span><a href="#39861480">prev</a><span>|</span><a href="#39861581">next</a><span>|</span><label class="collapse" for="c-39861657">[-]</label><label class="expand" for="c-39861657">[3 more]</label></div><br/><div class="children"><div class="content">Having grown up with JavaScript Python and R, I’m kinda looking towards learning a compiled language.<p>I’ve given a bit of thought to Rust since it’s polars native and I want to move away from pandas.<p>Is nim a good place to go?</div><br/><div id="39861687" class="c"><input type="checkbox" id="c-39861687" checked=""/><div class="controls bullet"><span class="by">FireInsight</span><span>|</span><a href="#39861657">parent</a><span>|</span><a href="#39861742">next</a><span>|</span><label class="collapse" for="c-39861687">[-]</label><label class="expand" for="c-39861687">[1 more]</label></div><br/><div class="children"><div class="content">Nim as a language is a good place to go. The ecosystem is another story entirely. I suggest you search for the kinds of libraries you&#x27;d need and check their maintenance status, maybe do some example project to get a feel for the compiler and `nimble`.</div><br/></div></div><div id="39861742" class="c"><input type="checkbox" id="c-39861742" checked=""/><div class="controls bullet"><span class="by">ezquerra</span><span>|</span><a href="#39861657">parent</a><span>|</span><a href="#39861687">prev</a><span>|</span><a href="#39861581">next</a><span>|</span><label class="collapse" for="c-39861742">[-]</label><label class="expand" for="c-39861742">[1 more]</label></div><br/><div class="children"><div class="content">Definitely. Nim is a great language and coming from Python it might be the easiest compiled language for you to get into.</div><br/></div></div></div></div><div id="39861581" class="c"><input type="checkbox" id="c-39861581" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#39861657">prev</a><span>|</span><label class="collapse" for="c-39861581">[-]</label><label class="expand" for="c-39861581">[3 more]</label></div><br/><div class="children"><div class="content">Interesting that it &quot;Supports tensors of up to 6 dimensions&quot;. Is it difficult to support an arbitrary number of dimensions, e.g. does Nim lack variadic generics?</div><br/><div id="39861624" class="c"><input type="checkbox" id="c-39861624" checked=""/><div class="controls bullet"><span class="by">mratsim</span><span>|</span><a href="#39861581">parent</a><span>|</span><a href="#39861621">next</a><span>|</span><label class="collapse" for="c-39861624">[-]</label><label class="expand" for="c-39861624">[1 more]</label></div><br/><div class="children"><div class="content">Author here,<p>Nim supports variadic generic, it&#x27;s an arbitrary limitation so that shape and stride small vectors that describe a tebsor can be stack-allocated and fit in a cacheline.<p>Also at the time, Nim default heap allocator was not compatible with OpenMP.<p>Edit: it can be configured via a compile-time flag to 8 or 10 or anything: <a href="https:&#x2F;&#x2F;github.com&#x2F;mratsim&#x2F;Arraymancer&#x2F;blob&#x2F;master&#x2F;src%2Farraymancer%2Flaser%2Fdynamic_stack_arrays.nim#L6">https:&#x2F;&#x2F;github.com&#x2F;mratsim&#x2F;Arraymancer&#x2F;blob&#x2F;master&#x2F;src%2Farr...</a></div><br/></div></div><div id="39861621" class="c"><input type="checkbox" id="c-39861621" checked=""/><div class="controls bullet"><span class="by">ElegantBeef</span><span>|</span><a href="#39861581">parent</a><span>|</span><a href="#39861624">prev</a><span>|</span><label class="collapse" for="c-39861621">[-]</label><label class="expand" for="c-39861621">[1 more]</label></div><br/><div class="children"><div class="content">It does not formally have variadics, but since it has tuples you can have pretend variadic generics.</div><br/></div></div></div></div></div></div></div></div></div></body></html>