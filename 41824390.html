<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1728810068115" as="style"/><link rel="stylesheet" href="styles.css?v=1728810068115"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://replicate.com/blog/flux-is-fast-and-open-source">FLUX is fast and it&#x27;s open source</a> <span class="domain">(<a href="https://replicate.com">replicate.com</a>)</span></div><div class="subtext"><span>smusamashah</span> | <span>66 comments</span></div><br/><div><div id="41824956" class="c"><input type="checkbox" id="c-41824956" checked=""/><div class="controls bullet"><span class="by">sorenjan</span><span>|</span><a href="#41825795">next</a><span>|</span><label class="collapse" for="c-41824956">[-]</label><label class="expand" for="c-41824956">[12 more]</label></div><br/><div class="children"><div class="content">Text to image models feels inefficient to me. I wonder if it would be possible and better to do it in separate steps, like text to scene graph, scene graph to semantically segmented image, segmented image to final image. That way each step could be trained separately and be modular, and the image would be easier to edit instead of completely replace it with the output of a new prompt. That way it should be much easier to generate stuff like &quot;object x next to object y, with the text foo on it&quot;, and the art style or level of realism would depend on the final rendering model which would be separate from the prompt adherence.<p>Kind of like those video2video (or img2img on each frame I guess) models where they enhance the image outputs from video games:<p><a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2021&#x2F;5&#x2F;12&#x2F;22432945&#x2F;intel-gta-v-realistic-machine-learning-cityscapes-dataset" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2021&#x2F;5&#x2F;12&#x2F;22432945&#x2F;intel-gta-v-real...</a>
<a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;aivideo&#x2F;comments&#x2F;1fx6zdr&#x2F;gta_iv_with_a_photorealistic_filter_with_runway&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;aivideo&#x2F;comments&#x2F;1fx6zdr&#x2F;gta_iv_wit...</a></div><br/><div id="41825674" class="c"><input type="checkbox" id="c-41825674" checked=""/><div class="controls bullet"><span class="by">kqr</span><span>|</span><a href="#41824956">parent</a><span>|</span><a href="#41825012">next</a><span>|</span><label class="collapse" for="c-41825674">[-]</label><label class="expand" for="c-41825674">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this essemtially the approach to image recognition etc. that failed for ages until we brute forced it with bigger and deeper matrices?<p>It seems sensible to extract features and reason about things the way a human would, but it turns out its easier to scale pattern matching purely done by computer.</div><br/><div id="41825750" class="c"><input type="checkbox" id="c-41825750" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#41824956">root</a><span>|</span><a href="#41825674">parent</a><span>|</span><a href="#41825012">next</a><span>|</span><label class="collapse" for="c-41825750">[-]</label><label class="expand" for="c-41825750">[2 more]</label></div><br/><div class="children"><div class="content">This is Sutton&#x27;s <i>Bitter Lesson</i>:<p><a href="https:&#x2F;&#x2F;www.cs.utexas.edu&#x2F;~eunsol&#x2F;courses&#x2F;data&#x2F;bitter_lesson.pdf" rel="nofollow">https:&#x2F;&#x2F;www.cs.utexas.edu&#x2F;~eunsol&#x2F;courses&#x2F;data&#x2F;bitter_lesson...</a></div><br/><div id="41826187" class="c"><input type="checkbox" id="c-41826187" checked=""/><div class="controls bullet"><span class="by">selvan</span><span>|</span><a href="#41824956">root</a><span>|</span><a href="#41825750">parent</a><span>|</span><a href="#41825012">next</a><span>|</span><label class="collapse" for="c-41826187">[-]</label><label class="expand" for="c-41826187">[1 more]</label></div><br/><div class="children"><div class="content">From the PDF - &quot;One thing that should be learned from the bitter lesson is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are &quot;search&quot; and &quot;learning&quot;.<p>The second general point to be learned from the bitter lesson is that the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries. All these are part of the arbitrary, intrinsically-complex, outside world. They are not what should be built in, as their complexity is endless; instead we should build in only the meta-methods that can find and capture this arbitrary complexity. Essential to these methods is that they can find good approximations, but the search for them should be by our methods, not by us. We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.&quot;</div><br/></div></div></div></div></div></div><div id="41825012" class="c"><input type="checkbox" id="c-41825012" checked=""/><div class="controls bullet"><span class="by">spencerchubb</span><span>|</span><a href="#41824956">parent</a><span>|</span><a href="#41825674">prev</a><span>|</span><a href="#41825203">next</a><span>|</span><label class="collapse" for="c-41825012">[-]</label><label class="expand" for="c-41825012">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s essentially what diffusion does, except it doesn&#x27;t have clear boundaries between &quot;scene graph&quot; and &quot;full image&quot;. It starts out noisy and adds more detail gradually</div><br/><div id="41825655" class="c"><input type="checkbox" id="c-41825655" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#41824956">root</a><span>|</span><a href="#41825012">parent</a><span>|</span><a href="#41825203">next</a><span>|</span><label class="collapse" for="c-41825655">[-]</label><label class="expand" for="c-41825655">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s true, the inefficiency is from using pixel-to-pixel attention at each stage. It the beginning low resolution would be enough, even at the end high resolution is only needed at the pixel&#x27;s neighborhood</div><br/></div></div></div></div><div id="41825203" class="c"><input type="checkbox" id="c-41825203" checked=""/><div class="controls bullet"><span class="by">ZoomZoomZoom</span><span>|</span><a href="#41824956">parent</a><span>|</span><a href="#41825012">prev</a><span>|</span><a href="#41825912">next</a><span>|</span><label class="collapse" for="c-41825203">[-]</label><label class="expand" for="c-41825203">[3 more]</label></div><br/><div class="children"><div class="content">The issue with this is there&#x27;s a false assumption that an image is a collection of objects. It&#x27;s not (necessarily).<p>I want a picture of frozen cyan peach fuzz.</div><br/><div id="41825301" class="c"><input type="checkbox" id="c-41825301" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#41824956">root</a><span>|</span><a href="#41825203">parent</a><span>|</span><a href="#41825912">next</a><span>|</span><label class="collapse" for="c-41825301">[-]</label><label class="expand" for="c-41825301">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;imgur.com&#x2F;ayAWSKr" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;ayAWSKr</a><p>Prompt: frozen cyan peach fuzz, with default settings on a first generation SD model.<p>People _seriously_ do not understand how good these tools have been for nearly two years already.</div><br/><div id="41825767" class="c"><input type="checkbox" id="c-41825767" checked=""/><div class="controls bullet"><span class="by">thomashop</span><span>|</span><a href="#41824956">root</a><span>|</span><a href="#41825301">parent</a><span>|</span><a href="#41825912">next</a><span>|</span><label class="collapse" for="c-41825767">[-]</label><label class="expand" for="c-41825767">[1 more]</label></div><br/><div class="children"><div class="content">You can do this dynamically with Pollinations URLs too:<p><a href="https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;frozen_cyan_peach_fuzz?seed=1" rel="nofollow">https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;frozen_cyan_peach_fuzz?seed=1</a><p><a href="https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;frozen_cyan_peach_fuzz?seed=2" rel="nofollow">https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;frozen_cyan_peach_fuzz?seed=2</a><p><a href="https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;frozen_cyan_peach_fuzz?seed=3" rel="nofollow">https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;frozen_cyan_peach_fuzz?seed=3</a><p>Disclaimer: I&#x27;m behind Pollinations.AI</div><br/></div></div></div></div></div></div><div id="41825912" class="c"><input type="checkbox" id="c-41825912" checked=""/><div class="controls bullet"><span class="by">seydor</span><span>|</span><a href="#41824956">parent</a><span>|</span><a href="#41825203">prev</a><span>|</span><a href="#41825735">next</a><span>|</span><label class="collapse" for="c-41825912">[-]</label><label class="expand" for="c-41825912">[1 more]</label></div><br/><div class="children"><div class="content">Neural networks will gradually be compressed to their minimum optimal size (once we know how to do that)</div><br/></div></div><div id="41825735" class="c"><input type="checkbox" id="c-41825735" checked=""/><div class="controls bullet"><span class="by">teh_infallible</span><span>|</span><a href="#41824956">parent</a><span>|</span><a href="#41825912">prev</a><span>|</span><a href="#41825226">next</a><span>|</span><label class="collapse" for="c-41825735">[-]</label><label class="expand" for="c-41825735">[1 more]</label></div><br/><div class="children"><div class="content">I am hoping that AI art tends towards a modular approach, where generating a character, setting, style, and camera movement each happens in its own step. It doesn’t make sense to describe everything at once and hope you like what you get.</div><br/></div></div></div></div><div id="41825795" class="c"><input type="checkbox" id="c-41825795" checked=""/><div class="controls bullet"><span class="by">thomashop</span><span>|</span><a href="#41824956">prev</a><span>|</span><a href="#41825741">next</a><span>|</span><label class="collapse" for="c-41825795">[-]</label><label class="expand" for="c-41825795">[2 more]</label></div><br/><div class="children"><div class="content">If you want to play with FLUX.schnell easily, type the prompt into a Pollinations URL:<p><a href="https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;a_donkey_holding_a_sign_with_flux_is_fast_and_its_open_source_written" rel="nofollow">https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;a_donkey_holding_a_sign_with_flux_...</a><p><a href="https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;a_donkey_holding_a_sign_with_flux_is_fast_and_its_open_source_written?seed=2" rel="nofollow">https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;a_donkey_holding_a_sign_with_flux_...</a><p><a href="https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;Minimalist%20and%20conceptual%20artwork%20depicting%20the%20difference%20between%20traditional%20programming%20and%20deep%20learning.%20On%20one%20side,%20a%20linear,%20step-by-step%20flowchart%20represents%20traditional%20programming.%20On%20the%20other%20side,%20an%20interconnected%20web%20of%20nodes%20represents%20deep%20learning.%20The%20image%20uses%20a%20retrofuturistic%20style%20with%20a%20Soviet%20realist%20influence,%20emphasizing%20the%20contrast%20between%20rigid%20structure%20and%20organic%20complexity.?width=1024&amp;height=576&amp;seed=1234&amp;nologo=true" rel="nofollow">https:&#x2F;&#x2F;pollinations.ai&#x2F;p&#x2F;Minimalist%20and%20conceptual%20ar...</a><p>It&#x27;s incredible how fast it is. We generate 8000 images every 30 minutes for our users using only three L40S GPUs. Disclaimer: I&#x27;m behind Pollinations</div><br/><div id="41826198" class="c"><input type="checkbox" id="c-41826198" checked=""/><div class="controls bullet"><span class="by">peterpans01</span><span>|</span><a href="#41825795">parent</a><span>|</span><a href="#41825741">next</a><span>|</span><label class="collapse" for="c-41826198">[-]</label><label class="expand" for="c-41826198">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;only&quot; word sounds quite expensive for most of us.</div><br/></div></div></div></div><div id="41825741" class="c"><input type="checkbox" id="c-41825741" checked=""/><div class="controls bullet"><span class="by">trickstra</span><span>|</span><a href="#41825795">prev</a><span>|</span><a href="#41825261">next</a><span>|</span><label class="collapse" for="c-41825741">[-]</label><label class="expand" for="c-41825741">[2 more]</label></div><br/><div class="children"><div class="content">Non-commercial is not open-source, because if the original copyright holder stops maintaining it, nobody else can continue (or has to work like a slave for free). Open-source is about what happens if the original author stops working on it. Open-source gives everyone the license to continue developing it, which obviously means also the ability to get paid. Don&#x27;t call it open-source if this aspect is missing.<p>Only the FLUX.1 [schnell] is open-source (Apache2), FLUX.1 [dev] is non-commercial.</div><br/><div id="41826085" class="c"><input type="checkbox" id="c-41826085" checked=""/><div class="controls bullet"><span class="by">starfezzy</span><span>|</span><a href="#41825741">parent</a><span>|</span><a href="#41825261">next</a><span>|</span><label class="collapse" for="c-41826085">[-]</label><label class="expand" for="c-41826085">[1 more]</label></div><br/><div class="children"><div class="content">Doesn’t open source mean the source is viewable&#x2F;inspectable? I don’t know any closed source apps that let you view the source.</div><br/></div></div></div></div><div id="41825261" class="c"><input type="checkbox" id="c-41825261" checked=""/><div class="controls bullet"><span class="by">jsemrau</span><span>|</span><a href="#41825741">prev</a><span>|</span><a href="#41824946">next</a><span>|</span><label class="collapse" for="c-41825261">[-]</label><label class="expand" for="c-41825261">[9 more]</label></div><br/><div class="children"><div class="content">My favorite thing to do with Flux is create images with a white background for my substack[1] because the text following is amazing and I can communicate something visually through the artwork as well.<p>[1]<a href="https:&#x2F;&#x2F;substackcdn.com&#x2F;image&#x2F;fetch&#x2F;w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep&#x2F;https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4dd8e1ab-ae2a-4cf0-818b-3794d9cc8ad4_1344x768.png" rel="nofollow">https:&#x2F;&#x2F;substackcdn.com&#x2F;image&#x2F;fetch&#x2F;w_1456,c_limit,f_webp,q_...</a></div><br/><div id="41825495" class="c"><input type="checkbox" id="c-41825495" checked=""/><div class="controls bullet"><span class="by">ruthmarx</span><span>|</span><a href="#41825261">parent</a><span>|</span><a href="#41824946">next</a><span>|</span><label class="collapse" for="c-41825495">[-]</label><label class="expand" for="c-41825495">[8 more]</label></div><br/><div class="children"><div class="content">That example you gave is a good reason why artists get pissed off IMO. The LLM is clearly aping some artists specific style, and now missing out on paid work as a result.<p>Not sure I have an opinion on that, technology marches on etc, but it is interesting.</div><br/><div id="41825686" class="c"><input type="checkbox" id="c-41825686" checked=""/><div class="controls bullet"><span class="by">jsemrau</span><span>|</span><a href="#41825261">root</a><span>|</span><a href="#41825495">parent</a><span>|</span><a href="#41825859">next</a><span>|</span><label class="collapse" for="c-41825686">[-]</label><label class="expand" for="c-41825686">[6 more]</label></div><br/><div class="children"><div class="content">I understand your point, but in 0% of all cases would I hire an artist to create imagery for my personal blog. Therefore, I would think that market doesn&#x27;t exist.</div><br/><div id="41826284" class="c"><input type="checkbox" id="c-41826284" checked=""/><div class="controls bullet"><span class="by">earthnail</span><span>|</span><a href="#41825261">root</a><span>|</span><a href="#41825686">parent</a><span>|</span><a href="#41825839">next</a><span>|</span><label class="collapse" for="c-41826284">[-]</label><label class="expand" for="c-41826284">[1 more]</label></div><br/><div class="children"><div class="content">However, the blogs or newspapers or print outlets that used to hire them hired them because you couldn’t- it was a differentiator.<p>That differentiator is gone, and as such won’t pay for it anymore. They’ll just use the same AI as you.<p>This destroys the existing market of the artist.<p>To be clear, my comment isn’t meant as a judgment, just as market analysis.</div><br/></div></div><div id="41825839" class="c"><input type="checkbox" id="c-41825839" checked=""/><div class="controls bullet"><span class="by">ruthmarx</span><span>|</span><a href="#41825261">root</a><span>|</span><a href="#41825686">parent</a><span>|</span><a href="#41826284">prev</a><span>|</span><a href="#41825859">next</a><span>|</span><label class="collapse" for="c-41825839">[-]</label><label class="expand" for="c-41825839">[4 more]</label></div><br/><div class="children"><div class="content">Yeah, I get that completely, I&#x27;m the same way. I just think it&#x27;s interesting. It&#x27;s kind of the same argument as piracy, since most people wouldn&#x27;t pay for what they download if it wasn&#x27;t free.</div><br/><div id="41826043" class="c"><input type="checkbox" id="c-41826043" checked=""/><div class="controls bullet"><span class="by">ilkke</span><span>|</span><a href="#41825261">root</a><span>|</span><a href="#41825839">parent</a><span>|</span><a href="#41825928">next</a><span>|</span><label class="collapse" for="c-41826043">[-]</label><label class="expand" for="c-41826043">[2 more]</label></div><br/><div class="children"><div class="content">What is different in this case is that large companies are very likely looking to replace artists with ai, which is a huge potential impact.
Piracy never had such risks</div><br/><div id="41826239" class="c"><input type="checkbox" id="c-41826239" checked=""/><div class="controls bullet"><span class="by">jsemrau</span><span>|</span><a href="#41825261">root</a><span>|</span><a href="#41826043">parent</a><span>|</span><a href="#41825928">next</a><span>|</span><label class="collapse" for="c-41826239">[-]</label><label class="expand" for="c-41826239">[1 more]</label></div><br/><div class="children"><div class="content">I think this will only happen if you could selectively replace parts within an image selectively and reliably. There are still major problems even in Photoshops genaI application. For example, it is not possible select the head of a person on a picture and then type &quot;smile&quot; to make the face smile. We might get there eventually.</div><br/></div></div></div></div><div id="41825928" class="c"><input type="checkbox" id="c-41825928" checked=""/><div class="controls bullet"><span class="by">jsemrau</span><span>|</span><a href="#41825261">root</a><span>|</span><a href="#41825839">parent</a><span>|</span><a href="#41826043">prev</a><span>|</span><a href="#41825859">next</a><span>|</span><label class="collapse" for="c-41825928">[-]</label><label class="expand" for="c-41825928">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d rather think it&#x27;s the same argument as open-source and public domain. Currently, I am researching an agent that ReAct&#x27;s through a game of TicTacToe. I am using a derivative of the open-source transformer&#x27;s prompt</div><br/></div></div></div></div></div></div><div id="41825859" class="c"><input type="checkbox" id="c-41825859" checked=""/><div class="controls bullet"><span class="by">pajeets</span><span>|</span><a href="#41825261">root</a><span>|</span><a href="#41825495">parent</a><span>|</span><a href="#41825686">prev</a><span>|</span><a href="#41824946">next</a><span>|</span><label class="collapse" for="c-41825859">[-]</label><label class="expand" for="c-41825859">[1 more]</label></div><br/><div class="children"><div class="content">Dont care about artists opinion on rest of using AI tools instead of not paying them because I couldnt and wouldnt so theres no demand in the first place.<p>All I wanna know is the prompt that was used to generate the art speaking of which i wanna know how to create cartoony images like that OP</div><br/></div></div></div></div></div></div><div id="41824946" class="c"><input type="checkbox" id="c-41824946" checked=""/><div class="controls bullet"><span class="by">vunderba</span><span>|</span><a href="#41825261">prev</a><span>|</span><a href="#41825799">next</a><span>|</span><label class="collapse" for="c-41824946">[-]</label><label class="expand" for="c-41824946">[4 more]</label></div><br/><div class="children"><div class="content">Flux is the leading contender for a locally hosted generative systems in terms of prompt adherence, but the omnipresent shallow depth of field is irritatingly hard to get rid of.</div><br/><div id="41825290" class="c"><input type="checkbox" id="c-41825290" checked=""/><div class="controls bullet"><span class="by">cranium</span><span>|</span><a href="#41824946">parent</a><span>|</span><a href="#41825799">next</a><span>|</span><label class="collapse" for="c-41825290">[-]</label><label class="expand" for="c-41825290">[3 more]</label></div><br/><div class="children"><div class="content">I guess it&#x27;s optimized for artsy images?</div><br/><div id="41825659" class="c"><input type="checkbox" id="c-41825659" checked=""/><div class="controls bullet"><span class="by">AuryGlenz</span><span>|</span><a href="#41824946">root</a><span>|</span><a href="#41825290">parent</a><span>|</span><a href="#41825305">next</a><span>|</span><label class="collapse" for="c-41825659">[-]</label><label class="expand" for="c-41825659">[1 more]</label></div><br/><div class="children"><div class="content">They almost certainly did DPO it, so that would have an effect. It was also probably just trained more on professional photography than cell phone pics.<p>I’ve found it odd how there’s a segment of the population that hates a shallow depth of field now, as they’re so used to their phone pictures. I got in an argument on Reddit (sigh) with someone who insisted that the somewhat shallow depth of field that SDXL liked to do by default was “fake.”<p>As in, he was only ever exposed to it through portrait mode and the like on phones and didn’t comprehend that larger sensors simply looked like that. The images he was posting that looked “fake” to him looked to be about a 50mm lens at f&#x2F;4 on a full frame camera at a normal portrait distance, so nothing super shallow either.</div><br/></div></div><div id="41825305" class="c"><input type="checkbox" id="c-41825305" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#41824946">root</a><span>|</span><a href="#41825290">parent</a><span>|</span><a href="#41825659">prev</a><span>|</span><a href="#41825799">next</a><span>|</span><label class="collapse" for="c-41825305">[-]</label><label class="expand" for="c-41825305">[1 more]</label></div><br/><div class="children"><div class="content">Give it another month and it will be porn, just like sdxl.</div><br/></div></div></div></div></div></div><div id="41825799" class="c"><input type="checkbox" id="c-41825799" checked=""/><div class="controls bullet"><span class="by">112233</span><span>|</span><a href="#41824946">prev</a><span>|</span><a href="#41824926">next</a><span>|</span><label class="collapse" for="c-41825799">[-]</label><label class="expand" for="c-41825799">[5 more]</label></div><br/><div class="children"><div class="content">Does someone know what FLUX 1.1 has been trained on?
I generated almost hundred images on the pro model using &quot;camera filename + simple word&quot; two word prompts, and it all looks like photos from someones phone. Like, unless it has text I would not even stop to consider any of these images AI. They sometimes look cropped. A lot of food pictures, messy tables and appartments etc.<p>Did they scrape public facebook posts? Snapchat? Vkontakte? Buy private images from onedrive&#x2F;dropbox? If I put as the second word a female name, it almost always triggers nsfw filter. So I assume images in the training set are quite private.<p>See for yourself (autoplay music warning):<p>people: <a href="https:&#x2F;&#x2F;vm.tiktok.com&#x2F;ZGdeXEhMg&#x2F;" rel="nofollow">https:&#x2F;&#x2F;vm.tiktok.com&#x2F;ZGdeXEhMg&#x2F;</a><p>food and stuff: <a href="https:&#x2F;&#x2F;vm.tiktok.com&#x2F;ZGdeXEBDK&#x2F;" rel="nofollow">https:&#x2F;&#x2F;vm.tiktok.com&#x2F;ZGdeXEBDK&#x2F;</a><p>signs: <a href="https:&#x2F;&#x2F;vm.tiktok.com&#x2F;ZGdeXoAgy&#x2F;" rel="nofollow">https:&#x2F;&#x2F;vm.tiktok.com&#x2F;ZGdeXoAgy&#x2F;</a><p>[edit]
Looking at these images feels uneasy, like I am looking at someones private photos. There is not enough &quot;guidance&quot; in a prompt like &quot;IMG00012.JPG forbid&quot; to account for these images, so it must all come from the training data.<p>I do not believe FLUX 1.1 pro has radically different training set than these previous open models, even if it is more prone to such generation.<p>It feels really off, so, again, is there any info on training data used for these models?</div><br/><div id="41825937" class="c"><input type="checkbox" id="c-41825937" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#41825799">parent</a><span>|</span><a href="#41825941">next</a><span>|</span><label class="collapse" for="c-41825937">[-]</label><label class="expand" for="c-41825937">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just flux, you can do the same with other models including Stable Diffusion.<p>These two reddit threads [1][2] explore this convention a bit.<p><pre><code>    DSC_0001-9999.JPG - Nikon Default
    DSCF0001-9999.JPG - Fujifilm Default
    IMG_0001-9999.JPG - Generic Image
    P0001-9999.JPG - Panasonic Default
    CIMG0001-9999.JPG - Casio Default
    PICT0001-9999.JPG - Sony Default
    Photo_0001-9999.JPG - Android Photo
    VID_0001-9999.mp4 - Generic Video
    
    Edit: Also created a version for 3D Software Filenames (all of them tested, only a few had some effects)
    
    Autodesk Filmbox (FBX): my_model0001-9999.fbx
    Stereolithography (STL): Model0001-9999.stl
    3ds Max: 3ds_Scene0001-9999.max
    Cinema 4D: Project0001-9999.c4d
    Maya (ASCII): Animation0001-9999.ma
    SketchUp: SketchUp0001-9999.skp

</code></pre>
[1]: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;StableDiffusion&#x2F;comments&#x2F;1fxkt3p&#x2F;common_camera_and_smartphone_file_naming_formats&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;StableDiffusion&#x2F;comments&#x2F;1fxkt3p&#x2F;co...</a><p>[2]: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;StableDiffusion&#x2F;comments&#x2F;1fxdm1n&#x2F;i_tested_the_use_of_a_random_filename_1234jpg_to&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;StableDiffusion&#x2F;comments&#x2F;1fxdm1n&#x2F;i_...</a></div><br/><div id="41826091" class="c"><input type="checkbox" id="c-41826091" checked=""/><div class="controls bullet"><span class="by">112233</span><span>|</span><a href="#41825799">root</a><span>|</span><a href="#41825937">parent</a><span>|</span><a href="#41825947">next</a><span>|</span><label class="collapse" for="c-41826091">[-]</label><label class="expand" for="c-41826091">[1 more]</label></div><br/><div class="children"><div class="content">Thank you, this is good and horrific to know. The hair of my hair are standing on their end.<p>Of all the models exibiting this behaviour, has anyone published, what are the training data sources? Like, honest list, not the PR-boilerplate.</div><br/></div></div><div id="41825947" class="c"><input type="checkbox" id="c-41825947" checked=""/><div class="controls bullet"><span class="by">pajeets</span><span>|</span><a href="#41825799">root</a><span>|</span><a href="#41825937">parent</a><span>|</span><a href="#41826091">prev</a><span>|</span><a href="#41825941">next</a><span>|</span><label class="collapse" for="c-41825947">[-]</label><label class="expand" for="c-41825947">[1 more]</label></div><br/><div class="children"><div class="content">wow this is wild!<p><a href="https:&#x2F;&#x2F;i.postimg.cc&#x2F;vT6SV7pq&#x2F;replicate-prediction-6ap8z1jv59rm40cjgk9t90zb80.webp" rel="nofollow">https:&#x2F;&#x2F;i.postimg.cc&#x2F;vT6SV7pq&#x2F;replicate-prediction-6ap8z1jv5...</a><p><a href="https:&#x2F;&#x2F;i.postimg.cc&#x2F;vZzMTM71&#x2F;replicate-prediction-7r4b4p6sj9rm60cjgkavj1en0g.webp" rel="nofollow">https:&#x2F;&#x2F;i.postimg.cc&#x2F;vZzMTM71&#x2F;replicate-prediction-7r4b4p6sj...</a><p><a href="https:&#x2F;&#x2F;i.postimg.cc&#x2F;rs6wM5LJ&#x2F;replicate-prediction-d8s4c93v51rm60cjgkd996qxpw.webp" rel="nofollow">https:&#x2F;&#x2F;i.postimg.cc&#x2F;rs6wM5LJ&#x2F;replicate-prediction-d8s4c93v5...</a><p>I DEMAND TO KNOW HOW RUN LOCAL SAAR</div><br/></div></div></div></div><div id="41825941" class="c"><input type="checkbox" id="c-41825941" checked=""/><div class="controls bullet"><span class="by">pajeets</span><span>|</span><a href="#41825799">parent</a><span>|</span><a href="#41825937">prev</a><span>|</span><a href="#41824926">next</a><span>|</span><label class="collapse" for="c-41825941">[-]</label><label class="expand" for="c-41825941">[1 more]</label></div><br/><div class="children"><div class="content">I experienced the same thing, it was so weird i got good results in the beginning and then it &quot;craps out&quot;<p>dont know why all the critical comments about flux are being downvoted or flag sure is weird</div><br/></div></div></div></div><div id="41824926" class="c"><input type="checkbox" id="c-41824926" checked=""/><div class="controls bullet"><span class="by">CosmicShadow</span><span>|</span><a href="#41825799">prev</a><span>|</span><a href="#41824848">next</a><span>|</span><label class="collapse" for="c-41824926">[-]</label><label class="expand" for="c-41824926">[5 more]</label></div><br/><div class="children"><div class="content">I just cancelled my Midjourney subscription, it feels like it&#x27;s fallen too far behind for the stuff I&#x27;d like to do. Spent a lot of time considering using Replicate as well as Ideogram.</div><br/><div id="41825308" class="c"><input type="checkbox" id="c-41825308" checked=""/><div class="controls bullet"><span class="by">simonjgreen</span><span>|</span><a href="#41824926">parent</a><span>|</span><a href="#41825886">next</a><span>|</span><label class="collapse" for="c-41825308">[-]</label><label class="expand" for="c-41825308">[1 more]</label></div><br/><div class="children"><div class="content">I have been questioning the value beyond novelty as well recently. I’m curious if you replaced it with another tool or simply don’t derive value from those things?</div><br/></div></div><div id="41825886" class="c"><input type="checkbox" id="c-41825886" checked=""/><div class="controls bullet"><span class="by">pajeets</span><span>|</span><a href="#41824926">parent</a><span>|</span><a href="#41825308">prev</a><span>|</span><a href="#41824848">next</a><span>|</span><label class="collapse" for="c-41825886">[-]</label><label class="expand" for="c-41825886">[3 more]</label></div><br/><div class="children"><div class="content">never used midjourney because it had that signature look and bad with hands, feet, letters<p>crazy not even a year has past since Emad&#x27;s downfall a <i>local open source</i> and superior model drops<p>which just shows how little moat these companies have and are just lighting cash on fire which we benefit from</div><br/><div id="41826288" class="c"><input type="checkbox" id="c-41826288" checked=""/><div class="controls bullet"><span class="by">aqme28</span><span>|</span><a href="#41824926">root</a><span>|</span><a href="#41825886">parent</a><span>|</span><a href="#41826211">next</a><span>|</span><label class="collapse" for="c-41826288">[-]</label><label class="expand" for="c-41826288">[1 more]</label></div><br/><div class="children"><div class="content">Flux has a signature look too, it’s just a different one.</div><br/></div></div><div id="41826211" class="c"><input type="checkbox" id="c-41826211" checked=""/><div class="controls bullet"><span class="by">keiferski</span><span>|</span><a href="#41824926">root</a><span>|</span><a href="#41825886">parent</a><span>|</span><a href="#41826288">prev</a><span>|</span><a href="#41824848">next</a><span>|</span><label class="collapse" for="c-41826211">[-]</label><label class="expand" for="c-41826211">[1 more]</label></div><br/><div class="children"><div class="content">It’s very easy to turn off the default Midjourney look.</div><br/></div></div></div></div></div></div><div id="41824848" class="c"><input type="checkbox" id="c-41824848" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#41824926">prev</a><span>|</span><a href="#41824862">next</a><span>|</span><label class="collapse" for="c-41824848">[-]</label><label class="expand" for="c-41824848">[5 more]</label></div><br/><div class="children"><div class="content">&gt; We added a new synchronous HTTP API that makes all image models much faster on Replicate.<p>ooh why is synchronous fast? i click thru to <a href="https:&#x2F;&#x2F;replicate.com&#x2F;changelog&#x2F;2024-10-09-synchronous-api">https:&#x2F;&#x2F;replicate.com&#x2F;changelog&#x2F;2024-10-09-synchronous-api</a><p>&gt; Our client libraries and API are now much faster at running models, particularly if a file is being returned.<p>... thanks?<p>just sharing my frustration as a developer. try to explain things a little better if you&#x27;d like it to stick&#x2F;for us to become your advocates.</div><br/><div id="41824899" class="c"><input type="checkbox" id="c-41824899" checked=""/><div class="controls bullet"><span class="by">weird-eye-issue</span><span>|</span><a href="#41824848">parent</a><span>|</span><a href="#41824862">next</a><span>|</span><label class="collapse" for="c-41824899">[-]</label><label class="expand" for="c-41824899">[4 more]</label></div><br/><div class="children"><div class="content">I mean it literally explains why in the second paragraph. It returns the actual file data in the response rather than a URL where you have to make a second request to get the file data</div><br/><div id="41825356" class="c"><input type="checkbox" id="c-41825356" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#41824848">root</a><span>|</span><a href="#41824899">parent</a><span>|</span><a href="#41824862">next</a><span>|</span><label class="collapse" for="c-41825356">[-]</label><label class="expand" for="c-41825356">[3 more]</label></div><br/><div class="children"><div class="content">thats not &quot;making the image models much faster&quot;, thats just making getting the image back slightly faster</div><br/><div id="41825709" class="c"><input type="checkbox" id="c-41825709" checked=""/><div class="controls bullet"><span class="by">popalchemist</span><span>|</span><a href="#41824848">root</a><span>|</span><a href="#41825356">parent</a><span>|</span><a href="#41824862">next</a><span>|</span><label class="collapse" for="c-41825709">[-]</label><label class="expand" for="c-41825709">[2 more]</label></div><br/><div class="children"><div class="content">The &quot;making the image models much faster&quot; part is model optimizations that are also explained in the post.</div><br/><div id="41825828" class="c"><input type="checkbox" id="c-41825828" checked=""/><div class="controls bullet"><span class="by">ErikBjare</span><span>|</span><a href="#41824848">root</a><span>|</span><a href="#41825709">parent</a><span>|</span><a href="#41824862">next</a><span>|</span><label class="collapse" for="c-41825828">[-]</label><label class="expand" for="c-41825828">[1 more]</label></div><br/><div class="children"><div class="content">Where? I don&#x27;t see any explanation of model optimizations in the linked post.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="41824862" class="c"><input type="checkbox" id="c-41824862" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#41824848">prev</a><span>|</span><a href="#41825008">next</a><span>|</span><label class="collapse" for="c-41824862">[-]</label><label class="expand" for="c-41824862">[2 more]</label></div><br/><div class="children"><div class="content">this comparison for the quantization effect is very nice <a href="https:&#x2F;&#x2F;flux-quality-comparison.vercel.app&#x2F;" rel="nofollow">https:&#x2F;&#x2F;flux-quality-comparison.vercel.app&#x2F;</a><p>however i do have to ask.. ~2x faster for fp16-&gt;fp8 is expected right? its still not as good as the &quot;realtime&quot; or &quot;lightning&quot; options that basically have to be 5-10x faster. whats the ideal product usecase for just ~2x faster?</div><br/><div id="41825657" class="c"><input type="checkbox" id="c-41825657" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#41824862">parent</a><span>|</span><a href="#41825008">next</a><span>|</span><label class="collapse" for="c-41825657">[-]</label><label class="expand" for="c-41825657">[1 more]</label></div><br/><div class="children"><div class="content">Funny, sometime I like the fast one better.</div><br/></div></div></div></div><div id="41825008" class="c"><input type="checkbox" id="c-41825008" checked=""/><div class="controls bullet"><span class="by">dvrp</span><span>|</span><a href="#41824862">prev</a><span>|</span><a href="#41824873">next</a><span>|</span><label class="collapse" for="c-41825008">[-]</label><label class="expand" for="c-41825008">[1 more]</label></div><br/><div class="children"><div class="content">i think we (krea) are faster at the time of writing this comment (but i’ll have to double-check on our infra)</div><br/></div></div><div id="41824873" class="c"><input type="checkbox" id="c-41824873" checked=""/><div class="controls bullet"><span class="by">LeicaLatte</span><span>|</span><a href="#41825008">prev</a><span>|</span><a href="#41824725">next</a><span>|</span><label class="collapse" for="c-41824873">[-]</label><label class="expand" for="c-41824873">[1 more]</label></div><br/><div class="children"><div class="content">Flux is awesome and improving all the time.</div><br/></div></div><div id="41824725" class="c"><input type="checkbox" id="c-41824725" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41824873">prev</a><span>|</span><a href="#41825141">next</a><span>|</span><label class="collapse" for="c-41824725">[-]</label><label class="expand" for="c-41824725">[15 more]</label></div><br/><div class="children"><div class="content">I know naming things is hard, but...<p><a href="https:&#x2F;&#x2F;justgetflux.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;justgetflux.com&#x2F;</a><p><a href="https:&#x2F;&#x2F;flux11pro.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;flux11pro.com&#x2F;</a> (Maybe the same thing? Unclear.)<p><a href="https:&#x2F;&#x2F;github.com&#x2F;flux-framework&#x2F;flux-core">https:&#x2F;&#x2F;github.com&#x2F;flux-framework&#x2F;flux-core</a><p><a href="https:&#x2F;&#x2F;github.com&#x2F;facebookarchive&#x2F;flux&#x2F;tree&#x2F;main">https:&#x2F;&#x2F;github.com&#x2F;facebookarchive&#x2F;flux&#x2F;tree&#x2F;main</a> (apparently archived now, but this was the first thing I thought of)<p><a href="https:&#x2F;&#x2F;www.flux.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.flux.ai&#x2F;</a><p><a href="https:&#x2F;&#x2F;fluxcd.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;fluxcd.io&#x2F;</a><p><a href="https:&#x2F;&#x2F;runonflux.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;runonflux.io&#x2F;</a><p><a href="https:&#x2F;&#x2F;fluxml.ai&#x2F;" rel="nofollow">https:&#x2F;&#x2F;fluxml.ai&#x2F;</a></div><br/><div id="41824870" class="c"><input type="checkbox" id="c-41824870" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#41824725">parent</a><span>|</span><a href="#41824732">next</a><span>|</span><label class="collapse" for="c-41824870">[-]</label><label class="expand" for="c-41824870">[2 more]</label></div><br/><div class="children"><div class="content">&quot;<i>Please don&#x27;t complain about tangential annoyances—e.g. article or website formats, name collisions, or back-button breakage. They&#x27;re too common to be interesting.</i>&quot;<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a></div><br/><div id="41824886" class="c"><input type="checkbox" id="c-41824886" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41824725">root</a><span>|</span><a href="#41824870">parent</a><span>|</span><a href="#41824732">next</a><span>|</span><label class="collapse" for="c-41824886">[-]</label><label class="expand" for="c-41824886">[1 more]</label></div><br/><div class="children"><div class="content">I just posted a reply to another person quoting this guideline:<p>&gt; In general I think that&#x27;s true and agree that minor name collision commentary is uninteresting, but in this case we&#x27;re talking about 11 collisions (and counting) in tech alone, 3 of those in AI&#x2F;ML and 1 of those specifically in image generation.<p>&gt; When it&#x27;s that bad I think that the frequency of collisions for this name is an interesting topic in its own right.<p>I&#x27;ll respect your judgement on this and not push it further, but this is my thought process here.</div><br/></div></div></div></div><div id="41824732" class="c"><input type="checkbox" id="c-41824732" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#41824725">parent</a><span>|</span><a href="#41824870">prev</a><span>|</span><a href="#41824889">next</a><span>|</span><label class="collapse" for="c-41824732">[-]</label><label class="expand" for="c-41824732">[3 more]</label></div><br/><div class="children"><div class="content">Well, the word refers to &quot;continuous change&quot;, so I guess it&#x27;s pretty appropriate.</div><br/><div id="41824824" class="c"><input type="checkbox" id="c-41824824" checked=""/><div class="controls bullet"><span class="by">achrono</span><span>|</span><a href="#41824725">root</a><span>|</span><a href="#41824732">parent</a><span>|</span><a href="#41824734">next</a><span>|</span><label class="collapse" for="c-41824824">[-]</label><label class="expand" for="c-41824824">[1 more]</label></div><br/><div class="children"><div class="content">this name flux</div><br/></div></div></div></div><div id="41824889" class="c"><input type="checkbox" id="c-41824889" checked=""/><div class="controls bullet"><span class="by">dig1</span><span>|</span><a href="#41824725">parent</a><span>|</span><a href="#41824732">prev</a><span>|</span><a href="#41824782">next</a><span>|</span><label class="collapse" for="c-41824889">[-]</label><label class="expand" for="c-41824889">[1 more]</label></div><br/><div class="children"><div class="content">Also <a href="https:&#x2F;&#x2F;github.com&#x2F;influxdata&#x2F;flux">https:&#x2F;&#x2F;github.com&#x2F;influxdata&#x2F;flux</a> - &quot;a lightweight scripting language for querying databases and working with data&quot;</div><br/></div></div><div id="41824782" class="c"><input type="checkbox" id="c-41824782" checked=""/><div class="controls bullet"><span class="by">Conscat</span><span>|</span><a href="#41824725">parent</a><span>|</span><a href="#41824889">prev</a><span>|</span><a href="#41824815">next</a><span>|</span><label class="collapse" for="c-41824782">[-]</label><label class="expand" for="c-41824782">[2 more]</label></div><br/><div class="children"><div class="content">The first thing that comes to mind when I think &quot;flux&quot; is none of the above too . There&#x27;s an extremely cool alternative iterator library for C++20 by Tristan Brindle named flux.</div><br/><div id="41824874" class="c"><input type="checkbox" id="c-41824874" checked=""/><div class="controls bullet"><span class="by">bigiain</span><span>|</span><a href="#41824725">root</a><span>|</span><a href="#41824782">parent</a><span>|</span><a href="#41824815">next</a><span>|</span><label class="collapse" for="c-41824874">[-]</label><label class="expand" for="c-41824874">[1 more]</label></div><br/><div class="children"><div class="content">&#x2F;me glances across my desk to see my soldering station...</div><br/></div></div></div></div><div id="41824815" class="c"><input type="checkbox" id="c-41824815" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#41824725">parent</a><span>|</span><a href="#41824782">prev</a><span>|</span><a href="#41824829">next</a><span>|</span><label class="collapse" for="c-41824815">[-]</label><label class="expand" for="c-41824815">[1 more]</label></div><br/><div class="children"><div class="content">And then you can branch out of AI - <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Flux_Foundation" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Flux_Foundation</a> works on public art.</div><br/></div></div><div id="41824829" class="c"><input type="checkbox" id="c-41824829" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#41824725">parent</a><span>|</span><a href="#41824815">prev</a><span>|</span><a href="#41824851">next</a><span>|</span><label class="collapse" for="c-41824829">[-]</label><label class="expand" for="c-41824829">[1 more]</label></div><br/><div class="children"><div class="content">there are just some names that technology brothers gravitate to like moths to a flame. Orion, Voltron, Galactus...</div><br/></div></div><div id="41824851" class="c"><input type="checkbox" id="c-41824851" checked=""/><div class="controls bullet"><span class="by">worstspotgain</span><span>|</span><a href="#41824725">parent</a><span>|</span><a href="#41824829">prev</a><span>|</span><a href="#41824804">next</a><span>|</span><label class="collapse" for="c-41824851">[-]</label><label class="expand" for="c-41824851">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;podcasts.apple.com&#x2F;us&#x2F;podcast&#x2F;what-the-flux&#x2F;id1493896209" rel="nofollow">https:&#x2F;&#x2F;podcasts.apple.com&#x2F;us&#x2F;podcast&#x2F;what-the-flux&#x2F;id149389...</a></div><br/></div></div><div id="41824804" class="c"><input type="checkbox" id="c-41824804" checked=""/><div class="controls bullet"><span class="by">artificialLimbs</span><span>|</span><a href="#41824725">parent</a><span>|</span><a href="#41824851">prev</a><span>|</span><a href="#41824849">next</a><span>|</span><label class="collapse" for="c-41824804">[-]</label><label class="expand" for="c-41824804">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t forget Caleb Porzio&#x27;s new Laravel UI kit.<p><a href="https:&#x2F;&#x2F;fluxui.dev&#x2F;" rel="nofollow">https:&#x2F;&#x2F;fluxui.dev&#x2F;</a></div><br/></div></div><div id="41824849" class="c"><input type="checkbox" id="c-41824849" checked=""/><div class="controls bullet"><span class="by">Vt71fcAqt7</span><span>|</span><a href="#41824725">parent</a><span>|</span><a href="#41824804">prev</a><span>|</span><a href="#41825141">next</a><span>|</span><label class="collapse" for="c-41824849">[-]</label><label class="expand" for="c-41824849">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Please don&#x27;t complain about tangential annoyances—e.g. article or website formats, name collisions, or back-button breakage. They&#x27;re too common to be interesting.</div><br/><div id="41824871" class="c"><input type="checkbox" id="c-41824871" checked=""/><div class="controls bullet"><span class="by">lolinder</span><span>|</span><a href="#41824725">root</a><span>|</span><a href="#41824849">parent</a><span>|</span><a href="#41825141">next</a><span>|</span><label class="collapse" for="c-41824871">[-]</label><label class="expand" for="c-41824871">[1 more]</label></div><br/><div class="children"><div class="content">In general I think that&#x27;s true and agree that minor name collision commentary is uninteresting, but in this case we&#x27;re talking about 11 collisions (and counting) in tech alone, 3 of those in AI&#x2F;ML and 1 of <i>those</i> specifically in image generation.<p>When it&#x27;s that bad I think that the frequency of collisions for this name is an interesting topic in its own right.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>