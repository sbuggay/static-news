<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1692090071808" as="style"/><link rel="stylesheet" href="styles.css?v=1692090071808"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/normal-computing/outlines">Show HN: LLMs can generate valid JSON 100% of the time</a>Â <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>remilouf</span> | <span>155 comments</span></div><br/><div><div id="37131269" class="c"><input type="checkbox" id="c-37131269" checked=""/><div class="controls bullet"><span class="by">hansvm</span><span>|</span><a href="#37126594">next</a><span>|</span><label class="collapse" for="c-37131269">[-]</label><label class="expand" for="c-37131269">[2 more]</label></div><br/><div class="children"><div class="content">A major part of the power of an LLM is the calibrated probability distribution in its responses, and this technique probably throws that ability away. Why is it good enough?<p>As a brief example, suppose the only possible LLM outputs were &quot;hello world&quot;, &quot;food&quot;, &quot;hello&quot;, and &quot;good day&quot; (and that they&#x27;re all equally probable with no prompting). Suppose your grammar requires a space in the output somewhere and has no other constraints. If you sampled LLM outputs till something passed the grammer you&#x27;d receive &quot;hello world&quot; and &quot;good day&quot; with equal probability. If you apply the website&#x27;s technique you&#x27;ll receive &quot;hello world&quot; twice as frequently as &quot;good day&quot;.<p>The core problem is that an answer prefix might have been extremely unlikely to yield a valid response, but the technique (probably -- assuming it succeeds -- my example assumed retries would eventually succeed) constructs a valid response from it regardless. Assuming enough independence in the right places everything is fine and dandy still, but correlated errors compound quickly in autoregressive models.<p>As a brief JSON-specific question, is an LLM more or less likely to make factual errors (hallucinations, truncated strings, missing main characters, ...) when it produces a response failing to adhere to a schema? If factual error rate relates nontrivially to schema error rate then this path is more perilous than it seems. Given the outsized impact certain words or schmooshed together word-phrases seem to have on LLM output, I&#x27;d be surprised if details like schema adherence didn&#x27;t bleed into other characteristics of the output.</div><br/><div id="37131508" class="c"><input type="checkbox" id="c-37131508" checked=""/><div class="controls bullet"><span class="by">druskacik</span><span>|</span><a href="#37131269">parent</a><span>|</span><a href="#37126594">next</a><span>|</span><label class="collapse" for="c-37131508">[-]</label><label class="expand" for="c-37131508">[1 more]</label></div><br/><div class="children"><div class="content">In this case (multiple choice generation), if one of the possible outputs does no match the regex, you can just exclude it from generation.<p>I am trying to think of an example where <i>&quot;answer prefix might have been extremely unlikely to yield a valid response, but the technique ( ... ) constructs a valid response from it regardless&quot;</i>, which might really cause a problem. But to no luck. Anyone has any idea? This could potentially be an interesting research question.</div><br/></div></div></div></div><div id="37126594" class="c"><input type="checkbox" id="c-37126594" checked=""/><div class="controls bullet"><span class="by">activatedgeek</span><span>|</span><a href="#37131269">prev</a><span>|</span><a href="#37125563">next</a><span>|</span><label class="collapse" for="c-37126594">[-]</label><label class="expand" for="c-37126594">[18 more]</label></div><br/><div class="children"><div class="content">Mechanistically, I think this library takes the simple idea of masking part of the vocabulary space and steps in time efficiently. Great!<p>I am curious, however, for the ones who have played around with such libraries wrapping base LLMs with output structure: do base models like Llama2 work very well?
My experience says &quot;hell no!&quot; and you do need a fair bit of instruction-tuning for specific use cases to actually get things to work.<p>And even then, it seems very counter-intuitive to me that given an instruction-tuned model, post-hoc masking of the state-space during generation then amounts to just changing the generation distribution, and potentially detrimental to instruction-tuning?</div><br/><div id="37129917" class="c"><input type="checkbox" id="c-37129917" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37126594">parent</a><span>|</span><a href="#37127252">next</a><span>|</span><label class="collapse" for="c-37129917">[-]</label><label class="expand" for="c-37129917">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m quite impressed with Llama 2 13B - the more time I spend with it the more I think it might be genuinely useful for more than just playing around with local LLMs.<p>I&#x27;m using the MLC version (since that works with a GPU on my M2 Mac) via my <a href="https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm-mlc">https:&#x2F;&#x2F;github.com&#x2F;simonw&#x2F;llm-mlc</a> plugin.</div><br/><div id="37130282" class="c"><input type="checkbox" id="c-37130282" checked=""/><div class="controls bullet"><span class="by">moneywoes</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37129917">parent</a><span>|</span><a href="#37127252">next</a><span>|</span><label class="collapse" for="c-37130282">[-]</label><label class="expand" for="c-37130282">[3 more]</label></div><br/><div class="children"><div class="content">What are your use cases</div><br/><div id="37130638" class="c"><input type="checkbox" id="c-37130638" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37130282">parent</a><span>|</span><a href="#37130992">next</a><span>|</span><label class="collapse" for="c-37130638">[-]</label><label class="expand" for="c-37130638">[1 more]</label></div><br/><div class="children"><div class="content">The thing I really want to get working is retrieval augmented generation - so effectively answering questions based on a blob of context that I pass in, and being able to do good-enough summarization.<p>I haven&#x27;t quite proved this to myself yet but I think it&#x27;s going to work pretty well.</div><br/></div></div><div id="37130992" class="c"><input type="checkbox" id="c-37130992" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37130282">parent</a><span>|</span><a href="#37130638">prev</a><span>|</span><a href="#37127252">next</a><span>|</span><label class="collapse" for="c-37130992">[-]</label><label class="expand" for="c-37130992">[1 more]</label></div><br/><div class="children"><div class="content">Not simonw, but I&#x27;ve been using Llama2-13B for search re-ranking very successfully.</div><br/></div></div></div></div></div></div><div id="37127252" class="c"><input type="checkbox" id="c-37127252" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#37126594">parent</a><span>|</span><a href="#37129917">prev</a><span>|</span><a href="#37130885">next</a><span>|</span><label class="collapse" for="c-37127252">[-]</label><label class="expand" for="c-37127252">[3 more]</label></div><br/><div class="children"><div class="content">&gt; <i>...given an instruction-tuned model, post-hoc masking of the state-space during generation then amounts to just changing the generation distribution...</i><p>Isn&#x27;t that what we did with test driven development?<p>The primary difference was our generator functions were human instead of LLM. Why not cut out the middle-human?</div><br/><div id="37129924" class="c"><input type="checkbox" id="c-37129924" checked=""/><div class="controls bullet"><span class="by">spockz</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37127252">parent</a><span>|</span><a href="#37128647">next</a><span>|</span><label class="collapse" for="c-37129924">[-]</label><label class="expand" for="c-37129924">[1 more]</label></div><br/><div class="children"><div class="content">Yes. And if that human was smart and knowledgable they would use property based testing to automatically generate test inputs. Most libraries make it trivial to do for custom data types and can even reduce the failing test case to a minimal size input. I have been using this since 2008 and it was around before that.</div><br/></div></div><div id="37128647" class="c"><input type="checkbox" id="c-37128647" checked=""/><div class="controls bullet"><span class="by">activatedgeek</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37127252">parent</a><span>|</span><a href="#37129924">prev</a><span>|</span><a href="#37130885">next</a><span>|</span><label class="collapse" for="c-37128647">[-]</label><label class="expand" for="c-37128647">[1 more]</label></div><br/><div class="children"><div class="content">I think what I am saying is tangential to TDD. I am not really even concerned about the ability of LLM to function as desired, and its verification.<p>I was rather concerned about a broader fundamental question - how does post-hoc guided generation interfere with the potential benefits of instruction-tuning?</div><br/></div></div></div></div><div id="37130885" class="c"><input type="checkbox" id="c-37130885" checked=""/><div class="controls bullet"><span class="by">LakshyAAAgrawal</span><span>|</span><a href="#37126594">parent</a><span>|</span><a href="#37127252">prev</a><span>|</span><a href="#37127435">next</a><span>|</span><label class="collapse" for="c-37130885">[-]</label><label class="expand" for="c-37130885">[2 more]</label></div><br/><div class="children"><div class="content">In our experience, at least for code generation, the experience has been that base models can be improved significantly by guiding token level generation.<p>In our paper titled &quot;Guiding Language Models of Code with Global Context using Monitors&quot; (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.10763" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.10763</a>), we propose Monitor Guided Decoding, which interfaces LLMs to static analysis, and guides the model to generate type-consistent code. Without any kind of fine-tuning, we show that using static analysis to guide token level generation at specific points leads to significantly improved quality of generated code, both in terms of compilability and match with ground truth. Even very small models (1.1B) are able to generate more compilable code than much larger models (175B) while also improving on match with ground truth.</div><br/><div id="37131227" class="c"><input type="checkbox" id="c-37131227" checked=""/><div class="controls bullet"><span class="by">Roark66</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37130885">parent</a><span>|</span><a href="#37127435">next</a><span>|</span><label class="collapse" for="c-37131227">[-]</label><label class="expand" for="c-37131227">[1 more]</label></div><br/><div class="children"><div class="content">It is an interesting paper. Any idea when the code&#x2F;data will be released? It appears it has been almost 2 months since the paper was submitted, but the link given leads to a random bing page :-(</div><br/></div></div></div></div><div id="37127435" class="c"><input type="checkbox" id="c-37127435" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#37126594">parent</a><span>|</span><a href="#37130885">prev</a><span>|</span><a href="#37126811">next</a><span>|</span><label class="collapse" for="c-37127435">[-]</label><label class="expand" for="c-37127435">[1 more]</label></div><br/><div class="children"><div class="content">&gt;you do need a fair bit of instruction-tuning for specific use cases to actually get things to work.<p>The instruction tuning part is &quot;trivial&quot;...it&#x27;s the dealing with edge cases part that gets me.<p>With classic code edge cases are well insignificant edge cases. With LLM you never know what will make it go off on a tangent &amp; the parsing code needs to deal with that chaos.<p>Or put differently the % of cases that are edge cases seems to have gone up dramatically</div><br/></div></div><div id="37126811" class="c"><input type="checkbox" id="c-37126811" checked=""/><div class="controls bullet"><span class="by">make3</span><span>|</span><a href="#37126594">parent</a><span>|</span><a href="#37127435">prev</a><span>|</span><a href="#37125563">next</a><span>|</span><label class="collapse" for="c-37126811">[-]</label><label class="expand" for="c-37126811">[7 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure of why you would want to use raw llama-2 though when there is a million super strong instruction fine-tuned versions of llama-2 on HF hub that would do the job a million times better? Like Stability-AI&#x27;s Beluga-2. See <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;HuggingFaceH4&#x2F;open_llm_leaderboard" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;HuggingFaceH4&#x2F;open_llm_leaderb...</a><p>About your second point, the goal is that the model can only generate JSON (for example), which can 100% be done by constraining which output token can and cannot be used.</div><br/><div id="37126938" class="c"><input type="checkbox" id="c-37126938" checked=""/><div class="controls bullet"><span class="by">nabakin</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37126811">parent</a><span>|</span><a href="#37128670">next</a><span>|</span><label class="collapse" for="c-37126938">[-]</label><label class="expand" for="c-37126938">[5 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t rely too much on automated benchmarks for LLMs. They are often gamed, made to overfit, and result in worse performance in the general case.<p>Human evaluation is the gold standard and the Llama 2 paper gave significant evidence that Llama 2 70b chat is on-par, if not, better than ChatGPT for that metric so I tend to stick to it unless there is good reason not to.</div><br/><div id="37127260" class="c"><input type="checkbox" id="c-37127260" checked=""/><div class="controls bullet"><span class="by">huevosabio</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37126938">parent</a><span>|</span><a href="#37128670">next</a><span>|</span><label class="collapse" for="c-37127260">[-]</label><label class="expand" for="c-37127260">[4 more]</label></div><br/><div class="children"><div class="content">The problem with Llama 2 chat versions is that they have been RLHF-ed to death. You can&#x27;t ask questions without getting a sermon of how your question may be inappropriate for this or that reason.<p>I think it&#x27;s worse on the smaller models, but still present in the 70B one.</div><br/><div id="37128412" class="c"><input type="checkbox" id="c-37128412" checked=""/><div class="controls bullet"><span class="by">dceddia</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37127260">parent</a><span>|</span><a href="#37130081">next</a><span>|</span><label class="collapse" for="c-37128412">[-]</label><label class="expand" for="c-37128412">[2 more]</label></div><br/><div class="children"><div class="content">Apologies if youâd already seen this and were only trying to make a point, but you might like this article from a week or 2 ago that talks about how to run Llama 2 âuncensoredâ locally, and it seems to do a decent job of mitigating the sermons!<p>Article: <a href="https:&#x2F;&#x2F;ollama.ai&#x2F;blog&#x2F;run-llama2-uncensored-locally" rel="nofollow noreferrer">https:&#x2F;&#x2F;ollama.ai&#x2F;blog&#x2F;run-llama2-uncensored-locally</a><p>Discussion: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36973584">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36973584</a></div><br/><div id="37129595" class="c"><input type="checkbox" id="c-37129595" checked=""/><div class="controls bullet"><span class="by">superkuh</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37128412">parent</a><span>|</span><a href="#37130081">next</a><span>|</span><label class="collapse" for="c-37129595">[-]</label><label class="expand" for="c-37129595">[1 more]</label></div><br/><div class="children"><div class="content">When you encounter &quot;uncensored&quot; in a llama model (1 or 2) what that means in that context is that the fine-tuning datasets used have had all refusals to respond removed. There&#x27;s no way to uncensor the pre-trained model itself and fine-tuning only changes the style of the output.</div><br/></div></div></div></div><div id="37130081" class="c"><input type="checkbox" id="c-37130081" checked=""/><div class="controls bullet"><span class="by">nabakin</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37127260">parent</a><span>|</span><a href="#37128412">prev</a><span>|</span><a href="#37128670">next</a><span>|</span><label class="collapse" for="c-37130081">[-]</label><label class="expand" for="c-37130081">[1 more]</label></div><br/><div class="children"><div class="content">For sure, that&#x27;s a good reason for using the uncensored fine-tuned versions. There are other good reasons too like expanded context size, codegen, and story writing&#x2F;rp. Just be careful of extraordinary benchmarks.<p>Btw, have you tried changing the default Llama 2 chat prompt? Meta tried to fine-tune it so that if you remove the safety part from the prompt, safety won&#x27;t be applied[1]. Not sure how well it works myself, but worth a shot I guess<p>[1] can be found in the Llama 2 paper</div><br/></div></div></div></div></div></div><div id="37128670" class="c"><input type="checkbox" id="c-37128670" checked=""/><div class="controls bullet"><span class="by">activatedgeek</span><span>|</span><a href="#37126594">root</a><span>|</span><a href="#37126811">parent</a><span>|</span><a href="#37126938">prev</a><span>|</span><a href="#37125563">next</a><span>|</span><label class="collapse" for="c-37128670">[-]</label><label class="expand" for="c-37128670">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I&#x27;m not sure of why you would want to use raw llama-2<p>Sure. My concern was not specific to llama-2, and was only using it as a placeholder example of a decent pre-trained base model. Replace it with your favorite base model, which you want to use for guided generation. My question is more fundamental - how does post-hoc guided generation interfere with the potential benefits of instruction-tuning?<p>&gt; About your second point, the goal is that the model can only generate JSON (for example), which can 100% be done by constraining which output token can and cannot be used.<p>Mechanistically, yes. I am not arguing that. The whole point is to generate JSON that is &quot;useful&quot;.</div><br/></div></div></div></div></div></div><div id="37125563" class="c"><input type="checkbox" id="c-37125563" checked=""/><div class="controls bullet"><span class="by">panarky</span><span>|</span><a href="#37126594">prev</a><span>|</span><a href="#37125690">next</a><span>|</span><label class="collapse" for="c-37125563">[-]</label><label class="expand" for="c-37125563">[29 more]</label></div><br/><div class="children"><div class="content">I can make GPT4 return valid JSON simply by providing examples in the system message. This works nine times out of ten.<p>But it&#x27;s still probabilistic, and nine times out of ten isn&#x27;t good enough.<p>Occasionally it will hallucinate responses like this:<p>{&quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot; for i in range(n)}<p>Re-prompting with the parsing error message is usually enough to get it on the second try.<p>But escaping double-quotes and newline characters is less reliable. Even after giving it multiple examples, it correctly escapes only about half the time.<p>Re-prompting for escaping errors still yields a ~50% success rate.</div><br/><div id="37127042" class="c"><input type="checkbox" id="c-37127042" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37126587">next</a><span>|</span><label class="collapse" for="c-37127042">[-]</label><label class="expand" for="c-37127042">[1 more]</label></div><br/><div class="children"><div class="content">That re-prompting on error trick is what this new Microsoft library does, too: <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;TypeChat">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;TypeChat</a><p>Here&#x27;s their prompt for that: <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;TypeChat&#x2F;blob&#x2F;c45460f4030938da39629d882c3e0e2c718f8680&#x2F;src&#x2F;program.ts#L212-L216">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;TypeChat&#x2F;blob&#x2F;c45460f4030938da3...</a><p>I think the approach using grammars (seen here, but also in things like <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773</a> ) is a much more elegant solution.</div><br/></div></div><div id="37126587" class="c"><input type="checkbox" id="c-37126587" checked=""/><div class="controls bullet"><span class="by">padolsey</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37127042">prev</a><span>|</span><a href="#37127224">next</a><span>|</span><label class="collapse" for="c-37126587">[-]</label><label class="expand" for="c-37126587">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had more luck with getting it to output XML as (1) You can imbue XML with actual language&#x2F;meaning (which LLMs adore) and (2) parsers can be made to be more forgiving. I get why people want to make JSON, but to me it&#x27;s a bit like trying to get a cat to swim - you might eventually succeed, but it&#x27;s not their natural inclination.</div><br/><div id="37130347" class="c"><input type="checkbox" id="c-37130347" checked=""/><div class="controls bullet"><span class="by">prempv</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37126587">parent</a><span>|</span><a href="#37127071">next</a><span>|</span><label class="collapse" for="c-37130347">[-]</label><label class="expand" for="c-37130347">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had the same experience as well. I suspect if it&#x27;s due to large presence of HTML in the training data as part of codebases and online content</div><br/></div></div><div id="37127071" class="c"><input type="checkbox" id="c-37127071" checked=""/><div class="controls bullet"><span class="by">gowld</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37126587">parent</a><span>|</span><a href="#37130347">prev</a><span>|</span><a href="#37127224">next</a><span>|</span><label class="collapse" for="c-37127071">[-]</label><label class="expand" for="c-37127071">[4 more]</label></div><br/><div class="children"><div class="content">How do you imbue XML with meaning?</div><br/><div id="37127102" class="c"><input type="checkbox" id="c-37127102" checked=""/><div class="controls bullet"><span class="by">padolsey</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37127071">parent</a><span>|</span><a href="#37127224">next</a><span>|</span><label class="collapse" for="c-37127102">[-]</label><label class="expand" for="c-37127102">[3 more]</label></div><br/><div class="children"><div class="content">XML Elements themselves: their naming, their attributes, comments, indentation. There&#x27;s more opportunity at every level of the hierarchy to demarkate and establish meaning. Having closing-tags as well, I&#x27;ve found, is a massive boon; LLMs can better understand what &quot;finishing&quot; looks like if its delimited in a semantic way - with a name.</div><br/><div id="37129798" class="c"><input type="checkbox" id="c-37129798" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37127102">parent</a><span>|</span><a href="#37127224">next</a><span>|</span><label class="collapse" for="c-37129798">[-]</label><label class="expand" for="c-37129798">[2 more]</label></div><br/><div class="children"><div class="content">Same works for JSON. Naming JSON keys works for adjusting what the output is nicely, and you can comment in your definitions (by defining them in a JSON Schema, or inserting placeholder text like `&quot;someKeyWithClarifyingDetails&quot;: &lt;some detailed instruction&gt;`)<p>I&#x27;m actually partial to CSV these days though, it can really cut down on response times just not needing to return all the extra tokens for JSON&#x2F;XML delimiters</div><br/><div id="37131298" class="c"><input type="checkbox" id="c-37131298" checked=""/><div class="controls bullet"><span class="by">padolsey</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37129798">parent</a><span>|</span><a href="#37127224">next</a><span>|</span><label class="collapse" for="c-37131298">[-]</label><label class="expand" for="c-37131298">[1 more]</label></div><br/><div class="children"><div class="content">Ostenibly yeh JSON should be able to encapsulate mose of that semantic stuff but having replaced an XML schema in the system prompt with gpt&#x27;s function-calling API I&#x27;ve been very umimpressed. It feels much less capable. I would have to provide a lot more clarifying prompts to make it more capable. I think I will, for now, bias to using schemas that are closest to prose.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37127224" class="c"><input type="checkbox" id="c-37127224" checked=""/><div class="controls bullet"><span class="by">caesil</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37126587">prev</a><span>|</span><a href="#37130792">next</a><span>|</span><label class="collapse" for="c-37127224">[-]</label><label class="expand" for="c-37127224">[6 more]</label></div><br/><div class="children"><div class="content">With ChatGPT function calling I get valid JSON 100% of the time from GPT-4 unless I have made some error in prompting.<p>The chief error is not providing escape hatches. LLMs look for a right answer. If you are feeding it some texts and asking it to return structured data about the texts, but then one of the texts is blank, it will be difficult to determine a right answer, so you get hallucinations. The solution is an escape hatch where one of the arguments is a `textIsMissing` boolean or something.<p>As long as you&#x27;ve accounted for these failure modes, it works flawlessly.</div><br/><div id="37128092" class="c"><input type="checkbox" id="c-37128092" checked=""/><div class="controls bullet"><span class="by">reissbaker</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37127224">parent</a><span>|</span><a href="#37129136">next</a><span>|</span><label class="collapse" for="c-37128092">[-]</label><label class="expand" for="c-37128092">[2 more]</label></div><br/><div class="children"><div class="content">GPT-4 is amazing, but the upside of smaller models is much lower cost. I get basically 100% accuracy on JSON modeling with GPT-4 with function calling too, but I will say that gpt-3.5-turbo with function calling is somewhat less accurate â it usually generates valid JSON in terms of JSON.parse not exploding, but not necessarily JSON following the schema I passed in (although it&#x27;s surprisingly good, maybe ~90% accurate?). I use 3.5-turbo a decent amount in API calls because it&#x27;s just a lot cheaper, and performs well enough even if it&#x27;s not gpt-4 level.<p>I haven&#x27;t gotten a chance to earnestly use the smaller Llama models yet in more than small prototypes (although I&#x27;m building a 4090-based system to learn more about finetuning them), but the little amount of experimenting I&#x27;ve done with them makes me think they need a decent amount of help with generating consistently-valid JSON matching some schema out of the box. This is a pretty neat tool to use for them, since it doesn&#x27;t require finetuning runs, it just masks logits.</div><br/><div id="37129813" class="c"><input type="checkbox" id="c-37129813" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37128092">parent</a><span>|</span><a href="#37129136">next</a><span>|</span><label class="collapse" for="c-37129813">[-]</label><label class="expand" for="c-37129813">[1 more]</label></div><br/><div class="children"><div class="content">claude-1.2-instant came out last week and is doing extremely well at following schemas.<p>I&#x27;d say it&#x27;s reached 3.5 turbo with the format following skills of GPT-4, which is powerful once you give it chain-of-thought</div><br/></div></div></div></div><div id="37129136" class="c"><input type="checkbox" id="c-37129136" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37127224">parent</a><span>|</span><a href="#37128092">prev</a><span>|</span><a href="#37130792">next</a><span>|</span><label class="collapse" for="c-37129136">[-]</label><label class="expand" for="c-37129136">[3 more]</label></div><br/><div class="children"><div class="content">The premise of function calling is great, but in my experience (at least on GPT-3.5, haven&#x27;t tried it with GPT-4 yet) it seems to generate wildly different, and less useful results, for the same prompt.</div><br/><div id="37130658" class="c"><input type="checkbox" id="c-37130658" checked=""/><div class="controls bullet"><span class="by">ipaddr</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37129136">parent</a><span>|</span><a href="#37130792">next</a><span>|</span><label class="collapse" for="c-37130658">[-]</label><label class="expand" for="c-37130658">[2 more]</label></div><br/><div class="children"><div class="content">You can change the randomness value to 0 and get the same output each time for the same text</div><br/><div id="37130695" class="c"><input type="checkbox" id="c-37130695" checked=""/><div class="controls bullet"><span class="by">selcuka</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37130658">parent</a><span>|</span><a href="#37130792">next</a><span>|</span><label class="collapse" for="c-37130695">[-]</label><label class="expand" for="c-37130695">[1 more]</label></div><br/><div class="children"><div class="content">I should probably re-test it, but I think it wasn&#x27;t the temperature. The results were unusually useless.</div><br/></div></div></div></div></div></div></div></div><div id="37130792" class="c"><input type="checkbox" id="c-37130792" checked=""/><div class="controls bullet"><span class="by">karmasimida</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37127224">prev</a><span>|</span><a href="#37127035">next</a><span>|</span><label class="collapse" for="c-37130792">[-]</label><label class="expand" for="c-37130792">[1 more]</label></div><br/><div class="children"><div class="content">I see grammar constrained generation for 2 major advantages:<p>1. It consumes fewer tokens, no need to add too many examples into the prompt.<p>2. It suffers less from the forgetting issue.<p>Another minor advantage is you can control precisely where your desired output to begin with.<p>But overall, those are nice perks not too substantial IMO.</div><br/></div></div><div id="37127035" class="c"><input type="checkbox" id="c-37127035" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37130792">prev</a><span>|</span><a href="#37126717">next</a><span>|</span><label class="collapse" for="c-37127035">[-]</label><label class="expand" for="c-37127035">[1 more]</label></div><br/><div class="children"><div class="content">What about reprompting with a different temperature value?<p>If this works, how to select the optimal value? Maybe you can train a model that can excel at the task of querying gpt4 for valid jsons</div><br/></div></div><div id="37126717" class="c"><input type="checkbox" id="c-37126717" checked=""/><div class="controls bullet"><span class="by">MuffinFlavored</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37127035">prev</a><span>|</span><a href="#37129631">next</a><span>|</span><label class="collapse" for="c-37126717">[-]</label><label class="expand" for="c-37126717">[5 more]</label></div><br/><div class="children"><div class="content">I wonder if the next iteration of OpenAI features is something like:<p>right now you can inject prompts that the LLM takes into consideration before the output<p>I wonder if you can make it have a &quot;post&quot; generation function that says like &quot;keep re-trying in a loop (aka hallucinating with randomness) until the output message passes XYZ format&#x2F;checks&#x2F;scoring&quot;</div><br/><div id="37127056" class="c"><input type="checkbox" id="c-37127056" checked=""/><div class="controls bullet"><span class="by">padjo</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37126717">parent</a><span>|</span><a href="#37130648">next</a><span>|</span><label class="collapse" for="c-37127056">[-]</label><label class="expand" for="c-37127056">[3 more]</label></div><br/><div class="children"><div class="content">Itâs starting to feel like LLMs are to âclassicalâ software engineering what quantum physics was to classical physics</div><br/><div id="37128809" class="c"><input type="checkbox" id="c-37128809" checked=""/><div class="controls bullet"><span class="by">catlifeonmars</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37127056">parent</a><span>|</span><a href="#37130648">next</a><span>|</span><label class="collapse" for="c-37128809">[-]</label><label class="expand" for="c-37128809">[2 more]</label></div><br/><div class="children"><div class="content">How so? Iâm not quite following the analogy.</div><br/><div id="37129265" class="c"><input type="checkbox" id="c-37129265" checked=""/><div class="controls bullet"><span class="by">antonvs</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37128809">parent</a><span>|</span><a href="#37130648">next</a><span>|</span><label class="collapse" for="c-37129265">[-]</label><label class="expand" for="c-37129265">[1 more]</label></div><br/><div class="children"><div class="content">Just guessing what was meant, but quantum physics in some sense tries all possible paths before an outcome is selected.<p>The problem with that is that without a quantum computer, or without some sort of filtering,  that process can take up to infinite time.</div><br/></div></div></div></div></div></div><div id="37130648" class="c"><input type="checkbox" id="c-37130648" checked=""/><div class="controls bullet"><span class="by">kristjansson</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37126717">parent</a><span>|</span><a href="#37127056">prev</a><span>|</span><a href="#37129631">next</a><span>|</span><label class="collapse" for="c-37130648">[-]</label><label class="expand" for="c-37130648">[1 more]</label></div><br/><div class="children"><div class="content">Why wait for OpenAI?</div><br/></div></div></div></div><div id="37129631" class="c"><input type="checkbox" id="c-37129631" checked=""/><div class="controls bullet"><span class="by">andreygrehov</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37126717">prev</a><span>|</span><a href="#37126963">next</a><span>|</span><label class="collapse" for="c-37129631">[-]</label><label class="expand" for="c-37129631">[3 more]</label></div><br/><div class="children"><div class="content">Meh... I asked GPT4 to return a sample PHP code inside of a random JSON. It failed the JSON linter from the very first try. I actually couldn&#x27;t pass the validation despite many retries, eg follow up corrections. Not a single time it generated a 100% valid JSON, I eventually gave up.</div><br/><div id="37130717" class="c"><input type="checkbox" id="c-37130717" checked=""/><div class="controls bullet"><span class="by">ipaddr</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37129631">parent</a><span>|</span><a href="#37131505">next</a><span>|</span><label class="collapse" for="c-37130717">[-]</label><label class="expand" for="c-37130717">[1 more]</label></div><br/><div class="children"><div class="content">This worked with chatGPT:
create a sample hello world in php<p>store that code in a json[object<p>code:
{
  &quot;php_code&quot;: &quot;&lt;?php echo &#x27;Hello, World!&#x27;; ?&gt;&quot;
}</div><br/></div></div><div id="37131505" class="c"><input type="checkbox" id="c-37131505" checked=""/><div class="controls bullet"><span class="by">adamrezich</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37129631">parent</a><span>|</span><a href="#37130717">prev</a><span>|</span><a href="#37126963">next</a><span>|</span><label class="collapse" for="c-37131505">[-]</label><label class="expand" for="c-37131505">[1 more]</label></div><br/><div class="children"><div class="content">if you think that&#x27;s bad, try to get it to generate Inform 7 gamesâInform&#x27;s natural-English-ish syntax completely throws all LLMs for a loop, consistently. it generates code that looks <i>possibly</i> correct (to an Inform newbie at least), but fails to compile far more often than not. I find this super interesting.</div><br/></div></div></div></div><div id="37126963" class="c"><input type="checkbox" id="c-37126963" checked=""/><div class="controls bullet"><span class="by">phillipcarter</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37129631">prev</a><span>|</span><a href="#37126751">next</a><span>|</span><label class="collapse" for="c-37126963">[-]</label><label class="expand" for="c-37126963">[1 more]</label></div><br/><div class="children"><div class="content">This is what we do, but for GPT-3.5. And it doesn&#x27;t need to be system messages either. We even have it emitting <i>only</i> JSON in a specific structure (except for when it fails to produce an output altogether). This is without the function calling model.</div><br/></div></div><div id="37126751" class="c"><input type="checkbox" id="c-37126751" checked=""/><div class="controls bullet"><span class="by">thumbsup-_-</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37126963">prev</a><span>|</span><a href="#37126896">next</a><span>|</span><label class="collapse" for="c-37126751">[-]</label><label class="expand" for="c-37126751">[1 more]</label></div><br/><div class="children"><div class="content">Yeah same thing. I have done the same with GPT-3.5. Simply ask it to output using provided schema only and give a few examples. Always outputs in provided json format</div><br/></div></div><div id="37126896" class="c"><input type="checkbox" id="c-37126896" checked=""/><div class="controls bullet"><span class="by">orasis</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37126751">prev</a><span>|</span><a href="#37125700">next</a><span>|</span><label class="collapse" for="c-37126896">[-]</label><label class="expand" for="c-37126896">[2 more]</label></div><br/><div class="children"><div class="content">What about using ChatGPTâs new function calling mechanism?</div><br/><div id="37126984" class="c"><input type="checkbox" id="c-37126984" checked=""/><div class="controls bullet"><span class="by">superasn</span><span>|</span><a href="#37125563">root</a><span>|</span><a href="#37126896">parent</a><span>|</span><a href="#37125700">next</a><span>|</span><label class="collapse" for="c-37126984">[-]</label><label class="expand" for="c-37126984">[1 more]</label></div><br/><div class="children"><div class="content">That returns broken JSON a lot of the times too</div><br/></div></div></div></div><div id="37125700" class="c"><input type="checkbox" id="c-37125700" checked=""/><div class="controls bullet"><span class="by">keiferwiseman</span><span>|</span><a href="#37125563">parent</a><span>|</span><a href="#37126896">prev</a><span>|</span><a href="#37125690">next</a><span>|</span><label class="collapse" for="c-37125700">[-]</label><label class="expand" for="c-37125700">[1 more]</label></div><br/><div class="children"><div class="content">It took some iterations but I&#x27;ve managed to get the OpenAI API to give me valid JSON 100% of the time now(based on my testing). I think I put in the prompt to never use newlines because it was causing issues lol.</div><br/></div></div></div></div><div id="37125690" class="c"><input type="checkbox" id="c-37125690" checked=""/><div class="controls bullet"><span class="by">xigency</span><span>|</span><a href="#37125563">prev</a><span>|</span><a href="#37131359">next</a><span>|</span><label class="collapse" for="c-37125690">[-]</label><label class="expand" for="c-37125690">[6 more]</label></div><br/><div class="children"><div class="content">Thanks for building this. The mechanics are such an obvious idea that it&#x27;s astounding that the first-party platforms haven&#x27;t done this yet. I would be interested to see how this could be used for other tasks outside of JSON that require structured input.</div><br/><div id="37126190" class="c"><input type="checkbox" id="c-37126190" checked=""/><div class="controls bullet"><span class="by">umvi</span><span>|</span><a href="#37125690">parent</a><span>|</span><a href="#37125712">next</a><span>|</span><label class="collapse" for="c-37126190">[-]</label><label class="expand" for="c-37126190">[2 more]</label></div><br/><div class="children"><div class="content">&gt; it&#x27;s astounding that the first-party platforms haven&#x27;t done this yet<p>I was under the impression LLM tech is currently in a breakneck arms race and that things are dramatically changing every few months. It could simply just be a consequence of limited developer resources. It would be &quot;astounding&quot; if decade-old tech were missing such a fundamental feature, but for AI tech in arms-race mode it seems reasonable that they are still missing QoL features.</div><br/><div id="37127553" class="c"><input type="checkbox" id="c-37127553" checked=""/><div class="controls bullet"><span class="by">winwang</span><span>|</span><a href="#37125690">root</a><span>|</span><a href="#37126190">parent</a><span>|</span><a href="#37125712">next</a><span>|</span><label class="collapse" for="c-37127553">[-]</label><label class="expand" for="c-37127553">[1 more]</label></div><br/><div class="children"><div class="content">I think they meant that you&#x27;d expect simpler&#x2F;more obvious ideas to be implemented first.</div><br/></div></div></div></div><div id="37125712" class="c"><input type="checkbox" id="c-37125712" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125690">parent</a><span>|</span><a href="#37126190">prev</a><span>|</span><a href="#37126851">next</a><span>|</span><label class="collapse" for="c-37125712">[-]</label><label class="expand" for="c-37125712">[2 more]</label></div><br/><div class="children"><div class="content">Thanks! We have extended the approach to grammar-based sampling. We describe the approach in the paper linked above. The following PR is relevant: <a href="https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;178">https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;178</a></div><br/><div id="37126971" class="c"><input type="checkbox" id="c-37126971" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#37125690">root</a><span>|</span><a href="#37125712">parent</a><span>|</span><a href="#37126851">next</a><span>|</span><label class="collapse" for="c-37126971">[-]</label><label class="expand" for="c-37126971">[1 more]</label></div><br/><div class="children"><div class="content">Could this same approach be applied at training?    If the guidance does a lot of the syntactical heavy lifting, would that create the opportunity for a model to use the weights for something else.  Essentially not bothering to reduce the error of things that the guidance will stomp on anyway.</div><br/></div></div></div></div><div id="37126851" class="c"><input type="checkbox" id="c-37126851" checked=""/><div class="controls bullet"><span class="by">LakshyAAAgrawal</span><span>|</span><a href="#37125690">parent</a><span>|</span><a href="#37125712">prev</a><span>|</span><a href="#37131359">next</a><span>|</span><label class="collapse" for="c-37126851">[-]</label><label class="expand" for="c-37126851">[1 more]</label></div><br/><div class="children"><div class="content">Hi, the paper at <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.10763" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.10763</a> titled &quot;Guiding Language Models of Code with Global Context using Monitors&quot; shows how to have the language models generate code without hallucinated dereferences.</div><br/></div></div></div></div><div id="37131359" class="c"><input type="checkbox" id="c-37131359" checked=""/><div class="controls bullet"><span class="by">cztomsik</span><span>|</span><a href="#37125690">prev</a><span>|</span><a href="#37125738">next</a><span>|</span><label class="collapse" for="c-37131359">[-]</label><label class="expand" for="c-37131359">[1 more]</label></div><br/><div class="children"><div class="content">FYI llama.cpp can do that for a &quot;while&quot; <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773</a><p>Somebody is also working on a whisper.cpp version, which is maybe even more interesting because if you have grammar you can speak not only JSON but also a code (or anything)</div><br/></div></div><div id="37125738" class="c"><input type="checkbox" id="c-37125738" checked=""/><div class="controls bullet"><span class="by">J_Shelby_J</span><span>|</span><a href="#37131359">prev</a><span>|</span><a href="#37125368">next</a><span>|</span><label class="collapse" for="c-37125738">[-]</label><label class="expand" for="c-37125738">[12 more]</label></div><br/><div class="children"><div class="content">So to explain this another way:<p>After each token generated by the LLM you update the logit bias âmaskâ to only allow the next token to be a valid json token?<p>Very slick!</div><br/><div id="37126564" class="c"><input type="checkbox" id="c-37126564" checked=""/><div class="controls bullet"><span class="by">dontreact</span><span>|</span><a href="#37125738">parent</a><span>|</span><a href="#37125761">next</a><span>|</span><label class="collapse" for="c-37126564">[-]</label><label class="expand" for="c-37126564">[6 more]</label></div><br/><div class="children"><div class="content">You would also need to keep generating until the whole string is valid. And what if it gets caught in a loop?<p>Not sure how this can really guarantee 100%</div><br/><div id="37126770" class="c"><input type="checkbox" id="c-37126770" checked=""/><div class="controls bullet"><span class="by">orlp</span><span>|</span><a href="#37125738">root</a><span>|</span><a href="#37126564">parent</a><span>|</span><a href="#37130514">next</a><span>|</span><label class="collapse" for="c-37126770">[-]</label><label class="expand" for="c-37126770">[4 more]</label></div><br/><div class="children"><div class="content">&gt; And what if it gets caught in a loop? Not sure how this can really guarantee 100%<p>It&#x27;s not great but after some timeout you can just set the mask to only include closing brackets.</div><br/><div id="37126859" class="c"><input type="checkbox" id="c-37126859" checked=""/><div class="controls bullet"><span class="by">aassddffasdf</span><span>|</span><a href="#37125738">root</a><span>|</span><a href="#37126770">parent</a><span>|</span><a href="#37130514">next</a><span>|</span><label class="collapse" for="c-37126859">[-]</label><label class="expand" for="c-37126859">[3 more]</label></div><br/><div class="children"><div class="content">You would still have to ensure balancing somehow. Both &quot;]&quot; and &quot;}&quot; are valid &quot;closing brackets&quot; and the correct one to choose is context-dependent.</div><br/><div id="37127915" class="c"><input type="checkbox" id="c-37127915" checked=""/><div class="controls bullet"><span class="by">gyy52380</span><span>|</span><a href="#37125738">root</a><span>|</span><a href="#37126859">parent</a><span>|</span><a href="#37130514">next</a><span>|</span><label class="collapse" for="c-37127915">[-]</label><label class="expand" for="c-37127915">[2 more]</label></div><br/><div class="children"><div class="content">You can determine which brackets you need in which order by parsing the incomplete json which was generated so far.</div><br/><div id="37128278" class="c"><input type="checkbox" id="c-37128278" checked=""/><div class="controls bullet"><span class="by">dontreact</span><span>|</span><a href="#37125738">root</a><span>|</span><a href="#37127915">parent</a><span>|</span><a href="#37130514">next</a><span>|</span><label class="collapse" for="c-37128278">[-]</label><label class="expand" for="c-37128278">[1 more]</label></div><br/><div class="children"><div class="content">That won&#x27;t do it, also need to close other stuf<p>{&quot;this&quot;: &quot;is valid json so farrrrrrrrrrrrrr<p>But yeah the general idea makes sense. Once you hit a timeout, change the mask to things that will close existing open things in a valid manner (}, ), ], &quot;)</div><br/></div></div></div></div></div></div></div></div><div id="37130514" class="c"><input type="checkbox" id="c-37130514" checked=""/><div class="controls bullet"><span class="by">kristjansson</span><span>|</span><a href="#37125738">root</a><span>|</span><a href="#37126564">parent</a><span>|</span><a href="#37126770">prev</a><span>|</span><a href="#37125761">next</a><span>|</span><label class="collapse" for="c-37130514">[-]</label><label class="expand" for="c-37130514">[1 more]</label></div><br/><div class="children"><div class="content">Same problem with normal sampling - if it doesn&#x27;t pick the &lt;end&gt; token, you&#x27;re stuck generating until you hit some stopping heuristic (max tokens, timeout, etc.)</div><br/></div></div></div></div><div id="37125761" class="c"><input type="checkbox" id="c-37125761" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125738">parent</a><span>|</span><a href="#37126564">prev</a><span>|</span><a href="#37129380">next</a><span>|</span><label class="collapse" for="c-37125761">[-]</label><label class="expand" for="c-37125761">[2 more]</label></div><br/><div class="children"><div class="content">Indeed. And we&#x27;re able to update the mask with a dictionary lookup instead of looping over the entire vocabulary (slow!).</div><br/></div></div><div id="37129380" class="c"><input type="checkbox" id="c-37129380" checked=""/><div class="controls bullet"><span class="by">bmc7505</span><span>|</span><a href="#37125738">parent</a><span>|</span><a href="#37125761">prev</a><span>|</span><a href="#37126305">next</a><span>|</span><label class="collapse" for="c-37129380">[-]</label><label class="expand" for="c-37129380">[1 more]</label></div><br/><div class="children"><div class="content">You also need some kind of beam search or rejection sampling since JSON tokens to not exactly correspond to logits.<p>edit: They describe this more carefully in the paper.</div><br/></div></div><div id="37126305" class="c"><input type="checkbox" id="c-37126305" checked=""/><div class="controls bullet"><span class="by">behnamoh</span><span>|</span><a href="#37125738">parent</a><span>|</span><a href="#37129380">prev</a><span>|</span><a href="#37125368">next</a><span>|</span><label class="collapse" for="c-37126305">[-]</label><label class="expand" for="c-37126305">[2 more]</label></div><br/><div class="children"><div class="content">Itâs actually a very old trick. Lots of libraries do this. idk whatâs the big deal about this one.</div><br/><div id="37126345" class="c"><input type="checkbox" id="c-37126345" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125738">root</a><span>|</span><a href="#37126305">parent</a><span>|</span><a href="#37125368">next</a><span>|</span><label class="collapse" for="c-37126345">[-]</label><label class="expand" for="c-37126345">[1 more]</label></div><br/><div class="children"><div class="content">Perhaps I didnât explain clearly enough in the original post?</div><br/></div></div></div></div></div></div><div id="37125368" class="c"><input type="checkbox" id="c-37125368" checked=""/><div class="controls bullet"><span class="by">sneedchucker</span><span>|</span><a href="#37125738">prev</a><span>|</span><a href="#37128463">next</a><span>|</span><label class="collapse" for="c-37125368">[-]</label><label class="expand" for="c-37125368">[5 more]</label></div><br/><div class="children"><div class="content">Relevant; LLama.cpp implemented grammar-based sampling last month.<p><a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36819906">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36819906</a>
<a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773</a></div><br/><div id="37125691" class="c"><input type="checkbox" id="c-37125691" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125368">parent</a><span>|</span><a href="#37128086">next</a><span>|</span><label class="collapse" for="c-37125691">[-]</label><label class="expand" for="c-37125691">[3 more]</label></div><br/><div class="children"><div class="content">We can extend our approach to grammar-based sampling, as explained in the paper linked above. Relevant PR: <a href="https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;178">https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;178</a><p>Our method is much more efficient. llama.cpp loops over the entire vocabulary (~50k tokens) <i>at each step</i> to generate the mask. We generate an index at initialization, and building the masks at each step only requires a dictionary lookup (trade speed for memory). Sampling is just as fast as standard sampling.</div><br/><div id="37126045" class="c"><input type="checkbox" id="c-37126045" checked=""/><div class="controls bullet"><span class="by">popinman322</span><span>|</span><a href="#37125368">root</a><span>|</span><a href="#37125691">parent</a><span>|</span><a href="#37127072">next</a><span>|</span><label class="collapse" for="c-37126045">[-]</label><label class="expand" for="c-37126045">[1 more]</label></div><br/><div class="children"><div class="content">It should hopefully be a quick change to llama.cpp to add a mask per grammar state to bring it in line with your generation method; I don&#x27;t think the two are incompatible, thankfully.<p>I do wonder how much you win here by masking the tokens? You still need to iterate along the output vector to apply the mask. Masking on the accelerator still requires filtering on the CPU side? Compared to running the language model, the cost of iterating over the edges in the grammar seems small.</div><br/></div></div><div id="37127072" class="c"><input type="checkbox" id="c-37127072" checked=""/><div class="controls bullet"><span class="by">burke</span><span>|</span><a href="#37125368">root</a><span>|</span><a href="#37125691">parent</a><span>|</span><a href="#37126045">prev</a><span>|</span><a href="#37128086">next</a><span>|</span><label class="collapse" for="c-37127072">[-]</label><label class="expand" for="c-37127072">[1 more]</label></div><br/><div class="children"><div class="content">Yes! This is closer to the approach I took in my port of llama.cpp&#x27;s grammar support to PyTorch: <a href="https:&#x2F;&#x2F;github.com&#x2F;Shopify&#x2F;torch-grammar&#x2F;blob&#x2F;main&#x2F;torch_grammar&#x2F;grammar_sampler.py#L203-L212">https:&#x2F;&#x2F;github.com&#x2F;Shopify&#x2F;torch-grammar&#x2F;blob&#x2F;main&#x2F;torch_gra...</a> ... it generates a tensor mapping each PDA stack to a map of which tokens are acceptable from that state. It seems like a much better way to do it than looping over the sampled tokens on each turn.</div><br/></div></div></div></div><div id="37128086" class="c"><input type="checkbox" id="c-37128086" checked=""/><div class="controls bullet"><span class="by">btwillard</span><span>|</span><a href="#37125368">parent</a><span>|</span><a href="#37125691">prev</a><span>|</span><a href="#37128463">next</a><span>|</span><label class="collapse" for="c-37128086">[-]</label><label class="expand" for="c-37128086">[1 more]</label></div><br/><div class="children"><div class="content">We also had an implementation of grammar-driven guidance around the same time: <a href="https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;131">https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;131</a>.  I imagine many others did as well, given all the papers we found on the subject.  The point of this and our ongoing work is the availability of very low cost guidance, which was implemented a while ago for the regex case and expanded upon with JSON.</div><br/></div></div></div></div><div id="37128463" class="c"><input type="checkbox" id="c-37128463" checked=""/><div class="controls bullet"><span class="by">Scaevolus</span><span>|</span><a href="#37125368">prev</a><span>|</span><a href="#37126503">next</a><span>|</span><label class="collapse" for="c-37128463">[-]</label><label class="expand" for="c-37128463">[1 more]</label></div><br/><div class="children"><div class="content">Are there temperature or sampling parameters for generate.regex? I&#x27;m poking around trying to generate password mnemonics (<a href="https:&#x2F;&#x2F;rmmh.github.io&#x2F;abbrase&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;rmmh.github.io&#x2F;abbrase&#x2F;</a>), and it really doesn&#x27;t like actually giving me proper words:<p><pre><code>    &gt;&gt; model = models.transformers(&quot;gpt2-medium&quot;)
    &gt;&gt; generate.regex(model, r&quot;Rea[a-z&#x27;]{,10} lik[a-z&#x27;]{,10} acr[a-z&#x27;]{,10} ene[a-z&#x27;]{,10} sta[a-z&#x27;]{,10}\.&quot;, max_tokens=30)(&quot;A memorable phrase is:&quot;)
    &#x27;Rearmingandme like acrowetteanda eneatubootank stackfishkies.&#x27;</code></pre></div><br/></div></div><div id="37126503" class="c"><input type="checkbox" id="c-37126503" checked=""/><div class="controls bullet"><span class="by">Q6T46nT668w6i3m</span><span>|</span><a href="#37128463">prev</a><span>|</span><a href="#37126385">next</a><span>|</span><label class="collapse" for="c-37126503">[-]</label><label class="expand" for="c-37126503">[2 more]</label></div><br/><div class="children"><div class="content">Is this Brandon Willard the breakdancer from Detroit Brandon Willard?<p>Edit: It is! <a href="https:&#x2F;&#x2F;brandonwillard.github.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;brandonwillard.github.io&#x2F;</a></div><br/><div id="37126535" class="c"><input type="checkbox" id="c-37126535" checked=""/><div class="controls bullet"><span class="by">btwillard</span><span>|</span><a href="#37126503">parent</a><span>|</span><a href="#37126385">next</a><span>|</span><label class="collapse" for="c-37126535">[-]</label><label class="expand" for="c-37126535">[1 more]</label></div><br/><div class="children"><div class="content">Ha, yeah, in a distant, but really fun, past!</div><br/></div></div></div></div><div id="37126385" class="c"><input type="checkbox" id="c-37126385" checked=""/><div class="controls bullet"><span class="by">aduffy</span><span>|</span><a href="#37126503">prev</a><span>|</span><a href="#37125916">next</a><span>|</span><label class="collapse" for="c-37126385">[-]</label><label class="expand" for="c-37126385">[1 more]</label></div><br/><div class="children"><div class="content">This is exciting, we built a similar tool[1] recently specifically targeted at constraining llama output to match a TypeScript interface.<p>I firmly believe that output format guarantees are going to be important for real (non-toy) decades for LLMs<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;discussions&#x2F;2494">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;discussions&#x2F;2494</a></div><br/></div></div><div id="37125916" class="c"><input type="checkbox" id="c-37125916" checked=""/><div class="controls bullet"><span class="by">Scene_Cast2</span><span>|</span><a href="#37126385">prev</a><span>|</span><a href="#37127863">next</a><span>|</span><label class="collapse" for="c-37125916">[-]</label><label class="expand" for="c-37125916">[7 more]</label></div><br/><div class="children"><div class="content">One potential drawback I can see is if the viable tokens are far down the list of predictions. In that case, filtering down to just those tokens is a distribution shift with resulting output being less stable &#x2F; less sensible.</div><br/><div id="37126159" class="c"><input type="checkbox" id="c-37126159" checked=""/><div class="controls bullet"><span class="by">Scarblac</span><span>|</span><a href="#37125916">parent</a><span>|</span><a href="#37128536">next</a><span>|</span><label class="collapse" for="c-37126159">[-]</label><label class="expand" for="c-37126159">[3 more]</label></div><br/><div class="children"><div class="content">It can&#x27;t be less sensible JSON than syntactically  invalid JSON. All the tokens higher on the list are syntax errors.</div><br/><div id="37126796" class="c"><input type="checkbox" id="c-37126796" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#37125916">root</a><span>|</span><a href="#37126159">parent</a><span>|</span><a href="#37126786">next</a><span>|</span><label class="collapse" for="c-37126796">[-]</label><label class="expand" for="c-37126796">[1 more]</label></div><br/><div class="children"><div class="content">It seems unlikely for JSON, but this might indicate that the model has somehow painted itself into a corner and the best thing to do is backtrack?<p>Regenerating the entire response could be seen as an extreme form of backtracking.</div><br/></div></div><div id="37126786" class="c"><input type="checkbox" id="c-37126786" checked=""/><div class="controls bullet"><span class="by">haswell</span><span>|</span><a href="#37125916">root</a><span>|</span><a href="#37126159">parent</a><span>|</span><a href="#37126796">prev</a><span>|</span><a href="#37128536">next</a><span>|</span><label class="collapse" for="c-37126786">[-]</label><label class="expand" for="c-37126786">[1 more]</label></div><br/><div class="children"><div class="content">That depends highly on the values contained within the JSON. Syntactically correct is only useful if the rest of the content is useful.</div><br/></div></div></div></div><div id="37128536" class="c"><input type="checkbox" id="c-37128536" checked=""/><div class="controls bullet"><span class="by">pshc</span><span>|</span><a href="#37125916">parent</a><span>|</span><a href="#37126159">prev</a><span>|</span><a href="#37126033">next</a><span>|</span><label class="collapse" for="c-37128536">[-]</label><label class="expand" for="c-37128536">[2 more]</label></div><br/><div class="children"><div class="content">Exactly my concern. If the model isn&#x27;t sure-footed about the path forward, it seems prudent to take that fact as information and adjust the initial conditions, rather than forcing the model into a potentially hallucinatory idea-space.</div><br/><div id="37130051" class="c"><input type="checkbox" id="c-37130051" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#37125916">root</a><span>|</span><a href="#37128536">parent</a><span>|</span><a href="#37126033">next</a><span>|</span><label class="collapse" for="c-37130051">[-]</label><label class="expand" for="c-37130051">[1 more]</label></div><br/><div class="children"><div class="content">What are characteristics of a &quot;hallucinatory idea-space&quot;? If you&#x27;re enforcing the model outputting a closing bracket instead of a random string of numbers, that seems like a win for JSON formatting.</div><br/></div></div></div></div><div id="37126033" class="c"><input type="checkbox" id="c-37126033" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125916">parent</a><span>|</span><a href="#37128536">prev</a><span>|</span><a href="#37127863">next</a><span>|</span><label class="collapse" for="c-37126033">[-]</label><label class="expand" for="c-37126033">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, this remains an empirical question.</div><br/></div></div></div></div><div id="37127863" class="c"><input type="checkbox" id="c-37127863" checked=""/><div class="controls bullet"><span class="by">anotherpaulg</span><span>|</span><a href="#37125916">prev</a><span>|</span><a href="#37125432">next</a><span>|</span><label class="collapse" for="c-37127863">[-]</label><label class="expand" for="c-37127863">[5 more]</label></div><br/><div class="children"><div class="content">For complex tasks like coding, my experience is that asking for a complex output format hurts performance on the underlying task. This showed up clearly in code editing benchmarks of GPT-3.5 and GPT-4:<p><a href="https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;benchmarks.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;aider.chat&#x2F;docs&#x2F;benchmarks.html</a><p>Iâm curious if you have measured whether the âconstrained generationâ that youâre doing suffers from similar downsides?</div><br/><div id="37128315" class="c"><input type="checkbox" id="c-37128315" checked=""/><div class="controls bullet"><span class="by">darkteflon</span><span>|</span><a href="#37127863">parent</a><span>|</span><a href="#37128117">next</a><span>|</span><label class="collapse" for="c-37128315">[-]</label><label class="expand" for="c-37128315">[1 more]</label></div><br/><div class="children"><div class="content">Weâve seen this too. We run them as two separate stages - âreasonâ, log the intermediate output, then parse.</div><br/></div></div><div id="37128117" class="c"><input type="checkbox" id="c-37128117" checked=""/><div class="controls bullet"><span class="by">infecto</span><span>|</span><a href="#37127863">parent</a><span>|</span><a href="#37128315">prev</a><span>|</span><a href="#37125432">next</a><span>|</span><label class="collapse" for="c-37128117">[-]</label><label class="expand" for="c-37128117">[3 more]</label></div><br/><div class="children"><div class="content">100% have observed the same over many tests. No loss in fidelity when responding in spoken language style of formatting but using json is disastrous.</div><br/><div id="37131068" class="c"><input type="checkbox" id="c-37131068" checked=""/><div class="controls bullet"><span class="by">speedgoose</span><span>|</span><a href="#37127863">root</a><span>|</span><a href="#37128117">parent</a><span>|</span><a href="#37128531">next</a><span>|</span><label class="collapse" for="c-37131068">[-]</label><label class="expand" for="c-37131068">[1 more]</label></div><br/><div class="children"><div class="content">While not ideal, could a workaround be to ask in spoken language first, and then ask to format it in JSON?</div><br/></div></div><div id="37128531" class="c"><input type="checkbox" id="c-37128531" checked=""/><div class="controls bullet"><span class="by">nouri</span><span>|</span><a href="#37127863">root</a><span>|</span><a href="#37128117">parent</a><span>|</span><a href="#37131068">prev</a><span>|</span><a href="#37125432">next</a><span>|</span><label class="collapse" for="c-37128531">[-]</label><label class="expand" for="c-37128531">[1 more]</label></div><br/><div class="children"><div class="content">Using OpenAI Function Calls or asking for JSON in the prompt?</div><br/></div></div></div></div></div></div><div id="37125432" class="c"><input type="checkbox" id="c-37125432" checked=""/><div class="controls bullet"><span class="by">Deukhoofd</span><span>|</span><a href="#37127863">prev</a><span>|</span><a href="#37127145">next</a><span>|</span><label class="collapse" for="c-37125432">[-]</label><label class="expand" for="c-37125432">[7 more]</label></div><br/><div class="children"><div class="content">Looks interesting! How would you say it compares to Microsoft&#x27;s TypeChat (beyond the obvious Python&#x2F;TypeScript difference)?<p><a href="https:&#x2F;&#x2F;microsoft.github.io&#x2F;TypeChat&#x2F;blog&#x2F;introducing-typechat&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;microsoft.github.io&#x2F;TypeChat&#x2F;blog&#x2F;introducing-typech...</a></div><br/><div id="37125470" class="c"><input type="checkbox" id="c-37125470" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125432">parent</a><span>|</span><a href="#37126002">next</a><span>|</span><label class="collapse" for="c-37125470">[-]</label><label class="expand" for="c-37125470">[4 more]</label></div><br/><div class="children"><div class="content">Thanks for bringing this library to my attention! From my understanding, TypeChat proceeds by (1) generating (2) attempting validation (3) if it fails, call the LLM again to fix the output (4) etc.<p>Our method on the other <i>guarantees</i> that the output will follow the specs of the JSON schema. No need to call the LLM several times.</div><br/><div id="37125589" class="c"><input type="checkbox" id="c-37125589" checked=""/><div class="controls bullet"><span class="by">1wheel</span><span>|</span><a href="#37125432">root</a><span>|</span><a href="#37125470">parent</a><span>|</span><a href="#37126002">next</a><span>|</span><label class="collapse" for="c-37125589">[-]</label><label class="expand" for="c-37125589">[3 more]</label></div><br/><div class="children"><div class="content">There&#x27;s also <a href="https:&#x2F;&#x2F;lmql.ai&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;lmql.ai&#x2F;</a></div><br/><div id="37125746" class="c"><input type="checkbox" id="c-37125746" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125432">root</a><span>|</span><a href="#37125589">parent</a><span>|</span><a href="#37126002">next</a><span>|</span><label class="collapse" for="c-37125746">[-]</label><label class="expand" for="c-37125746">[2 more]</label></div><br/><div class="children"><div class="content">LQML (and guidance <a href="https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance">https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance</a>) are much more inefficient. They loop over the entire vocabulary at each step, we only do it once at initialization.</div><br/><div id="37130030" class="c"><input type="checkbox" id="c-37130030" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#37125432">root</a><span>|</span><a href="#37125746">parent</a><span>|</span><a href="#37126002">next</a><span>|</span><label class="collapse" for="c-37130030">[-]</label><label class="expand" for="c-37130030">[1 more]</label></div><br/><div class="children"><div class="content">Does looping over the vocabulary add much overhead to the tok&#x2F;s? I imagine they&#x27;re just checking if the input is in a set, and usually there&#x27;s only ~30k tokens. That&#x27;s somewhat intensive, but inference on the neural net feels like it&#x27;d take longer.</div><br/></div></div></div></div></div></div></div></div><div id="37126002" class="c"><input type="checkbox" id="c-37126002" checked=""/><div class="controls bullet"><span class="by">2bitencryption</span><span>|</span><a href="#37125432">parent</a><span>|</span><a href="#37125470">prev</a><span>|</span><a href="#37127145">next</a><span>|</span><label class="collapse" for="c-37126002">[-]</label><label class="expand" for="c-37126002">[2 more]</label></div><br/><div class="children"><div class="content">TypeChat: let&#x27;s try really hard to try to convince the model to make the highest-scoring tokens follow the grammar we want.<p>Guidance (and this project?): Let&#x27;s not even bother with trying to convince the model; instead, we&#x27;ll only sample from the set of tokens that are guaranteed to be correct for the grammar we want to emit.</div><br/><div id="37126094" class="c"><input type="checkbox" id="c-37126094" checked=""/><div class="controls bullet"><span class="by">btwillard</span><span>|</span><a href="#37125432">root</a><span>|</span><a href="#37126002">parent</a><span>|</span><a href="#37127145">next</a><span>|</span><label class="collapse" for="c-37126094">[-]</label><label class="expand" for="c-37126094">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, and our addition to all that is to almost completely remove the cost of determining the next valid tokens on each step.</div><br/></div></div></div></div></div></div><div id="37127145" class="c"><input type="checkbox" id="c-37127145" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37125432">prev</a><span>|</span><a href="#37125896">next</a><span>|</span><label class="collapse" for="c-37127145">[-]</label><label class="expand" for="c-37127145">[6 more]</label></div><br/><div class="children"><div class="content">I really hope OpenAI add something like this to their endpoints soon.<p>Being able to pass up some kind of grammar (a regular expression, or a JSON schema, or some other format) and have this trick run during their token sampling process to ensure the output was compliant would be incredibly useful.</div><br/><div id="37127292" class="c"><input type="checkbox" id="c-37127292" checked=""/><div class="controls bullet"><span class="by">joshuanapoli</span><span>|</span><a href="#37127145">parent</a><span>|</span><a href="#37127320">next</a><span>|</span><label class="collapse" for="c-37127292">[-]</label><label class="expand" for="c-37127292">[4 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t the Function Calling feature meant for this purpose? It guides the LLM to output according to the given schema. The name of the feature is a little misleading.<p><a href="https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;gpt&#x2F;function-calling" rel="nofollow noreferrer">https:&#x2F;&#x2F;platform.openai.com&#x2F;docs&#x2F;guides&#x2F;gpt&#x2F;function-calling</a></div><br/><div id="37127322" class="c"><input type="checkbox" id="c-37127322" checked=""/><div class="controls bullet"><span class="by">tornato7</span><span>|</span><a href="#37127145">root</a><span>|</span><a href="#37127292">parent</a><span>|</span><a href="#37127376">next</a><span>|</span><label class="collapse" for="c-37127322">[-]</label><label class="expand" for="c-37127322">[1 more]</label></div><br/><div class="children"><div class="content">Function Calling is fine-tuned to a certain output format, but it very often strays from that format. My function-calling-handling code has a mess of edge case handlers that catch when GPT-4 is calling functions incorrectly.</div><br/></div></div><div id="37127376" class="c"><input type="checkbox" id="c-37127376" checked=""/><div class="controls bullet"><span class="by">M4v3R</span><span>|</span><a href="#37127145">root</a><span>|</span><a href="#37127292">parent</a><span>|</span><a href="#37127322">prev</a><span>|</span><a href="#37127359">next</a><span>|</span><label class="collapse" for="c-37127376">[-]</label><label class="expand" for="c-37127376">[1 more]</label></div><br/><div class="children"><div class="content">Itâs not though, they even say it in their docs that sending a schema does not guarantee that the model will actually adhere to the scheme or even produce valid JSON</div><br/></div></div><div id="37127359" class="c"><input type="checkbox" id="c-37127359" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37127145">root</a><span>|</span><a href="#37127292">parent</a><span>|</span><a href="#37127376">prev</a><span>|</span><a href="#37127320">next</a><span>|</span><label class="collapse" for="c-37127359">[-]</label><label class="expand" for="c-37127359">[1 more]</label></div><br/><div class="children"><div class="content">Surprisingly the function calling mechanism doesn&#x27;t appear to use this trick - apparently it&#x27;s still possible to get the wrong JSON structure back from it occasionally.</div><br/></div></div></div></div><div id="37127320" class="c"><input type="checkbox" id="c-37127320" checked=""/><div class="controls bullet"><span class="by">potatoman22</span><span>|</span><a href="#37127145">parent</a><span>|</span><a href="#37127292">prev</a><span>|</span><a href="#37125896">next</a><span>|</span><label class="collapse" for="c-37127320">[-]</label><label class="expand" for="c-37127320">[1 more]</label></div><br/><div class="children"><div class="content">They recently added logit biases, so that&#x27;s a start.</div><br/></div></div></div></div><div id="37125896" class="c"><input type="checkbox" id="c-37125896" checked=""/><div class="controls bullet"><span class="by">Ilasky</span><span>|</span><a href="#37127145">prev</a><span>|</span><a href="#37127402">next</a><span>|</span><label class="collapse" for="c-37125896">[-]</label><label class="expand" for="c-37125896">[6 more]</label></div><br/><div class="children"><div class="content">OpenAI has this capability built in with functions[0], I believe! Building my own project[1] I have implemented functions in combination with guidance[2] and havenât had a hiccup yet! I have a JSON parser function there, just in case, but it seems to be working reliably.<p>Hereâs a bit more of a description of using the functions API for JSON returns: <a href="https:&#x2F;&#x2F;yonom.substack.com&#x2F;p&#x2F;native-json-output-from-gpt-4" rel="nofollow noreferrer">https:&#x2F;&#x2F;yonom.substack.com&#x2F;p&#x2F;native-json-output-from-gpt-4</a><p>[0] <a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;function-calling-and-other-api-updates" rel="nofollow noreferrer">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;function-calling-and-other-api-updat...</a><p>[1] <a href="https:&#x2F;&#x2F;resgen.app" rel="nofollow noreferrer">https:&#x2F;&#x2F;resgen.app</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance">https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance</a></div><br/><div id="37125951" class="c"><input type="checkbox" id="c-37125951" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#37125896">parent</a><span>|</span><a href="#37126772">next</a><span>|</span><label class="collapse" for="c-37125951">[-]</label><label class="expand" for="c-37125951">[4 more]</label></div><br/><div class="children"><div class="content">&gt;OpenAI has this capability built in with functions<p>From OpenAI&#x27;s docs:<p>&gt; note: the model may generate invalid JSON<p>I would guess they <i>don&#x27;t</i> use your method - and perhaps they should!</div><br/><div id="37126079" class="c"><input type="checkbox" id="c-37126079" checked=""/><div class="controls bullet"><span class="by">Ilasky</span><span>|</span><a href="#37125896">root</a><span>|</span><a href="#37125951">parent</a><span>|</span><a href="#37126772">next</a><span>|</span><label class="collapse" for="c-37126079">[-]</label><label class="expand" for="c-37126079">[3 more]</label></div><br/><div class="children"><div class="content">Good catch! It really is a combination of guidance guaranteeing JSON output and OpenAI getting it right a good majority of the time[0]. But yeah, I can see how it can be frustrating that the JSON output is not guaranteed by the docs.<p>[0] &gt;&gt;99% in my experience</div><br/><div id="37126116" class="c"><input type="checkbox" id="c-37126116" checked=""/><div class="controls bullet"><span class="by">Ilasky</span><span>|</span><a href="#37125896">root</a><span>|</span><a href="#37126079">parent</a><span>|</span><a href="#37126772">next</a><span>|</span><label class="collapse" for="c-37126116">[-]</label><label class="expand" for="c-37126116">[2 more]</label></div><br/><div class="children"><div class="content">That said, I am definitely going to look into this library and compare its results to guidance, since they claim it blows it out of the water (which is very enticing!)</div><br/><div id="37126313" class="c"><input type="checkbox" id="c-37126313" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125896">root</a><span>|</span><a href="#37126116">parent</a><span>|</span><a href="#37126772">next</a><span>|</span><label class="collapse" for="c-37126313">[-]</label><label class="expand" for="c-37126313">[1 more]</label></div><br/><div class="children"><div class="content">Figure 2 in our paper (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09702" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09702</a>) shows the difference for a single regex.</div><br/></div></div></div></div></div></div></div></div><div id="37126772" class="c"><input type="checkbox" id="c-37126772" checked=""/><div class="controls bullet"><span class="by">thomasfromcdnjs</span><span>|</span><a href="#37125896">parent</a><span>|</span><a href="#37125951">prev</a><span>|</span><a href="#37127402">next</a><span>|</span><label class="collapse" for="c-37126772">[-]</label><label class="expand" for="c-37126772">[1 more]</label></div><br/><div class="children"><div class="content">I do the same, just tell Openai to call a parser at the end and wahal.</div><br/></div></div></div></div><div id="37127402" class="c"><input type="checkbox" id="c-37127402" checked=""/><div class="controls bullet"><span class="by">dvt</span><span>|</span><a href="#37125896">prev</a><span>|</span><a href="#37125950">next</a><span>|</span><label class="collapse" for="c-37127402">[-]</label><label class="expand" for="c-37127402">[3 more]</label></div><br/><div class="children"><div class="content">I may get heavily downvoted for my criticism here, but here we go again: yet another &quot;innovation&quot; that&#x27;s fueled by the stupid money poured into AI startups in the past 2 years. Imagine thinking that adding regex on top of an LLM is worth $8.5M[1]. At least Llama&#x27;s grammar-based sampling[2] is a <i>bit</i> more interesting but still essentially putting lipstick on a pig.<p>How is telling the language model &quot;no, not like that, give me another token&quot; at every step of token inference getting so many people ecstatic? The paper is basically undergrad-level excitement about something not even remotely interesting. Congratulations, you reinvented Markov chains (oh, sorry, &quot;state machines&quot;) on top of LLMs.<p>I mean <i>of course</i> you can guarantee grammar and schema well-formedness as, duh, you have what essentially amounts to a post-processing step. Maybe I&#x27;m the idiot here, is anyone actually using any of these tools in production?<p>[1] <a href="https:&#x2F;&#x2F;www.benzinga.com&#x2F;pressreleases&#x2F;23&#x2F;06&#x2F;n32834246&#x2F;normal-computing-raises-8-5m-in-seed-funding-to-enable-ai-solutions-for-critical-enterprise-and-go" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.benzinga.com&#x2F;pressreleases&#x2F;23&#x2F;06&#x2F;n32834246&#x2F;norma...</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773&#x2F;files">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;1773&#x2F;files</a></div><br/><div id="37130754" class="c"><input type="checkbox" id="c-37130754" checked=""/><div class="controls bullet"><span class="by">kristjansson</span><span>|</span><a href="#37127402">parent</a><span>|</span><a href="#37130670">next</a><span>|</span><label class="collapse" for="c-37130754">[-]</label><label class="expand" for="c-37130754">[1 more]</label></div><br/><div class="children"><div class="content">I think you might be over-simplifying.  This (and llama.cpp&#x27;s grammar-based sampling, which this is moving towards[1]) doesn&#x27;t say &quot;no, not like that, give me another token&quot;. It excludes impossible tokens at each step, but otherwise samples like normal.<p>Is this a revolutionary trick? Not really, since llama.cpp and guidance, and probably others have already done it.  But it&#x27;s a good trick, and hopefully one of many to justify the valuation :).<p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;178">https:&#x2F;&#x2F;github.com&#x2F;normal-computing&#x2F;outlines&#x2F;pull&#x2F;178</a></div><br/></div></div><div id="37130670" class="c"><input type="checkbox" id="c-37130670" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#37127402">parent</a><span>|</span><a href="#37130754">prev</a><span>|</span><a href="#37125950">next</a><span>|</span><label class="collapse" for="c-37130670">[-]</label><label class="expand" for="c-37130670">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Imagine thinking that adding regex on top of an LLM is worth $8.5M<p>you should be downvoted for being this reductionist and uncharitable. this is a side project of a larger company effort.</div><br/></div></div></div></div><div id="37125950" class="c"><input type="checkbox" id="c-37125950" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#37127402">prev</a><span>|</span><a href="#37129978">next</a><span>|</span><label class="collapse" for="c-37125950">[-]</label><label class="expand" for="c-37125950">[15 more]</label></div><br/><div class="children"><div class="content">OK, you get syntactically valid JSON, but does it contain the correct info? This is effectively a polisher, like spell check, which gives the output superficially correct form but doesn&#x27;t understand the content. Right?</div><br/><div id="37126253" class="c"><input type="checkbox" id="c-37126253" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#37125950">parent</a><span>|</span><a href="#37127237">next</a><span>|</span><label class="collapse" for="c-37126253">[-]</label><label class="expand" for="c-37126253">[10 more]</label></div><br/><div class="children"><div class="content">This analogy falls apart because the spellchecker is separate from the author, and doesnât know what the author intended.<p>Here, the LLM is still dictating the token probabilities, so the content will be as correct as the LLM can make it, given the constraints. AIUI, the sampler is just choosing tokens on a combination of probability and syntactic correctness, instead of strictly on probability.<p>If the LLM is forced to provide a numeric temperature for Seattle, and the input doesnât contain that data, then obviously the LLM will be forced by the sampler to provide a random answer if the sampler will accept nothing else, much like a human who is forced to mark âtrueâ&#x2F;âfalseâ on an online form, with no option to reject the question and explain that the question isnât even a true&#x2F;false question.<p>I donât know about this specific implementation, but it seems important to design systems like this to always âacceptâ (sample for) an error response from the LLM so that it can hopefully reject invalid requests.<p>But, yes, all the usual caveats about LLMs apply. It canât provide correct answers to things it doesnât know. Forcing it to respond with the answer to the life, the universe, and everything is not going to provide a meaningful response. Even things it âknowsâ, it can still get wrong sometimes.</div><br/><div id="37126961" class="c"><input type="checkbox" id="c-37126961" checked=""/><div class="controls bullet"><span class="by">anticrymactic</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37126253">parent</a><span>|</span><a href="#37126823">next</a><span>|</span><label class="collapse" for="c-37126961">[-]</label><label class="expand" for="c-37126961">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m stupid with LLMs, but would it be possible to have this output with gpt4&#x27;s intelligence, or would it have to be specifically trained?</div><br/><div id="37126995" class="c"><input type="checkbox" id="c-37126995" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37126961">parent</a><span>|</span><a href="#37126823">next</a><span>|</span><label class="collapse" for="c-37126995">[-]</label><label class="expand" for="c-37126995">[1 more]</label></div><br/><div class="children"><div class="content">Itâs something OpenAI should really implement themselves. Implementing it from the client side will mean sending the same request over and over until you get a syntactically correct answer, which is going to be much slower and likely to cost a lot. The server can guide the generation, but the client can (currently) only hint at what it wants. ChatGPT4 is fairly good at following schemas, and thatâs what OpenAI currently relies on, but they make no guarantees.<p>It likely wouldnât require additional training. Itâs a change to the way the server uses the model, not a change to the model itselfâ¦ but we donât know ChatGPT4âs true architecture because OpenAI wonât publish anything about it, so itâs hard to say for sure.</div><br/></div></div></div></div><div id="37126823" class="c"><input type="checkbox" id="c-37126823" checked=""/><div class="controls bullet"><span class="by">chipsrafferty</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37126253">parent</a><span>|</span><a href="#37126961">prev</a><span>|</span><a href="#37127237">next</a><span>|</span><label class="collapse" for="c-37126823">[-]</label><label class="expand" for="c-37126823">[7 more]</label></div><br/><div class="children"><div class="content">Why isn&#x27;t it possible to design LLMs that say &quot;I don&#x27;t know&quot;?</div><br/><div id="37126848" class="c"><input type="checkbox" id="c-37126848" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37126823">parent</a><span>|</span><a href="#37127109">next</a><span>|</span><label class="collapse" for="c-37126848">[-]</label><label class="expand" for="c-37126848">[1 more]</label></div><br/><div class="children"><div class="content">It <i>is</i> possibleâ¦ ChatGPT4 says that all the time. Itâs just not <i>guaranteed</i> that an LLM will recognize that it doesnât know a particular answer every time. I had even already mentioned in the comment youâre replying to that you should leave room in the sampler to <i>allow</i> the LLM to provide error responses. I never said it wasnât possible.<p>Not to anthropomorphize LLMs too much, but humans will also sometimes respond confidently with a wrong answer too. Both LLMs and humans will sometimes say the wrong thing when they donât actually know an answer, but sometimes (hopefully most of the time) they will instead say that they donât know the answer.<p>Contrary to another response here, I do not believe it&#x27;s a good mental model to say that LLMs only respond &quot;I don&#x27;t know&quot; only when they have specifically memorized that they don&#x27;t know a fact. When you&#x27;re dealing with tens or hundreds of billions of parameters, the &quot;why&quot; is often elusive and complicated. It&#x27;s also probabilistic; it may respond that it doesn&#x27;t know one time, but the next time, it may unfortunately claim to know an answer it doesn&#x27;t know -- which is a form of hallucination. If it was just about memorization, then it wouldn&#x27;t be probabilistic. Reducing hallucinations is one of the major goals of LLM research today, and ChatGPT4 performs much better in this area than ChatGPT3.5 did.<p>Here is a quick example of ChatGPT4 saying it doesnât know: <a href="https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;7b72b109-fb84-4988-891b-f2eecc4ce582" rel="nofollow noreferrer">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;7b72b109-fb84-4988-891b-f2eecc...</a><p>I&#x27;m sure no one at OpenAI specifically trained ChatGPT4 to recognize a question about the Stanley Cup and respond that it doesn&#x27;t know the answer, but it still said that it didn&#x27;t know. It <i>absolutely did not</i> start a sentence with &quot;the winner of the 2023 Stanley Cup was...&quot; and then wander its way into a bad answer. That&#x27;s <i>not</i> a good representation of how this stuff works, even though it does sample one token at a time.</div><br/></div></div><div id="37127109" class="c"><input type="checkbox" id="c-37127109" checked=""/><div class="controls bullet"><span class="by">skybrian</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37126823">parent</a><span>|</span><a href="#37126848">prev</a><span>|</span><a href="#37127329">next</a><span>|</span><label class="collapse" for="c-37127109">[-]</label><label class="expand" for="c-37127109">[1 more]</label></div><br/><div class="children"><div class="content">They do, but it&#x27;s a form of imitation, not actually knowing what they don&#x27;t know.<p>Ask an LLM to imitate a confident physicist and it will try, regardless of how much physics it knows.<p>Or if you tell ChatGPT that it&#x27;s wrong multiple times, it may learn the pattern and assume it&#x27;s always wrong, resulting in a downward spiral. (This can happen when using Code Interpreter and it makes several failed attempts to correct a mistake.)<p>The difficult research problem is training it to have an accurate model of what it knows.</div><br/></div></div><div id="37127329" class="c"><input type="checkbox" id="c-37127329" checked=""/><div class="controls bullet"><span class="by">Lerc</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37126823">parent</a><span>|</span><a href="#37127109">prev</a><span>|</span><a href="#37128704">next</a><span>|</span><label class="collapse" for="c-37127329">[-]</label><label class="expand" for="c-37127329">[2 more]</label></div><br/><div class="children"><div class="content">They can say I don&#x27;t know when they contain the fact that they don&#x27;t know something.   For instance saying &quot;I don&#x27;t know&quot; could be a response to&quot;What is the meaning of life&quot;<p>On the other hand if you ask a LLM how to do something about fish maintenance that it does not know how to do, it might produce an answer like &quot;Sure, first take your fish and &quot; at which point all of the options for the next word are all over the place because there isn&#x27;t the information available to guide the choice.   The sentence started as if it knew the answer because there was no information to say that it didn&#x27;t.  By the time the absence of information has an impact, the LLM is already committed to the sentence where it is confidently giving you an answer.</div><br/></div></div><div id="37128704" class="c"><input type="checkbox" id="c-37128704" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37126823">parent</a><span>|</span><a href="#37127329">prev</a><span>|</span><a href="#37128389">next</a><span>|</span><label class="collapse" for="c-37128704">[-]</label><label class="expand" for="c-37128704">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Why isn&#x27;t it possible to design LLMs that say &quot;I don&#x27;t know&quot;?<p>You have to have an understanding of âIâ before you can make that judgement.</div><br/></div></div><div id="37128389" class="c"><input type="checkbox" id="c-37128389" checked=""/><div class="controls bullet"><span class="by">bestcoder69</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37126823">parent</a><span>|</span><a href="#37128704">prev</a><span>|</span><a href="#37127237">next</a><span>|</span><label class="collapse" for="c-37128389">[-]</label><label class="expand" for="c-37128389">[1 more]</label></div><br/><div class="children"><div class="content">text-davinci-002 used to make me so mad with how often itâd do that</div><br/></div></div></div></div></div></div><div id="37127237" class="c"><input type="checkbox" id="c-37127237" checked=""/><div class="controls bullet"><span class="by">burke</span><span>|</span><a href="#37125950">parent</a><span>|</span><a href="#37126253">prev</a><span>|</span><a href="#37126482">next</a><span>|</span><label class="collapse" for="c-37127237">[-]</label><label class="expand" for="c-37127237">[2 more]</label></div><br/><div class="children"><div class="content">You can go pretty deep once you get context free grammars. For example, I&#x27;m using torch-grammar (but outlines should be able to do the same thing once CFG support is merged) to not just restrict the format of a generation to a DSL&#x27;s syntax, but to restrict the keys it updates to valid keys in a known set.<p>e.g.:<p><pre><code>    int_key ::= DQUO (&quot;f&quot; (&quot;e&quot; (&quot;atured-&quot; (&quot;b&quot; (&quot;log.&quot; (&quot;p&quot; (&quot;ost_limit&quot; | &quot;a&quot; ...
</code></pre>
Obviously, yeah, it doesn&#x27;t &quot;understand&quot; the content, but that&#x27;s what the LLM is for. It&#x27;s remarkable how plausible the generations you can get out of random noise are with a sufficiently-restrictive grammar. Bolting that onto a well-trained LLM is pretty powerful.</div><br/><div id="37127315" class="c"><input type="checkbox" id="c-37127315" checked=""/><div class="controls bullet"><span class="by">btwillard</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37127237">parent</a><span>|</span><a href="#37126482">next</a><span>|</span><label class="collapse" for="c-37127315">[-]</label><label class="expand" for="c-37127315">[1 more]</label></div><br/><div class="children"><div class="content">FYI: We&#x27;ve had grammar constraints available in Outlines for a while, but not using the FSM and indexing approach that makes the regex case so fast.  My open PR only adds that.</div><br/></div></div></div></div><div id="37126482" class="c"><input type="checkbox" id="c-37126482" checked=""/><div class="controls bullet"><span class="by">empath-nirvana</span><span>|</span><a href="#37125950">parent</a><span>|</span><a href="#37127237">prev</a><span>|</span><a href="#37129978">next</a><span>|</span><label class="collapse" for="c-37126482">[-]</label><label class="expand" for="c-37126482">[2 more]</label></div><br/><div class="children"><div class="content">This isn&#x27;t really an interesting question is it?  Everyone knows that chatgpt is not an oracle.  It doesn&#x27;t need to output the correct information 100% of the time.</div><br/><div id="37129946" class="c"><input type="checkbox" id="c-37129946" checked=""/><div class="controls bullet"><span class="by">offmycloud</span><span>|</span><a href="#37125950">root</a><span>|</span><a href="#37126482">parent</a><span>|</span><a href="#37129978">next</a><span>|</span><label class="collapse" for="c-37129946">[-]</label><label class="expand" for="c-37129946">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that everyone, or even a majority of people understand this.  That&#x27;s certainly not how AI is being marketed to the general public.  The concern here is that syntactic correctness might be mistaken for factual accuracy.</div><br/></div></div></div></div></div></div><div id="37129978" class="c"><input type="checkbox" id="c-37129978" checked=""/><div class="controls bullet"><span class="by">Ycros</span><span>|</span><a href="#37125950">prev</a><span>|</span><a href="#37127577">next</a><span>|</span><label class="collapse" for="c-37129978">[-]</label><label class="expand" for="c-37129978">[1 more]</label></div><br/><div class="children"><div class="content">Having played around with this sort of thing in the llama.cpp ecosystem when they added it a few weeks ago, I will say that it also helps if your models a) are tuned to output json and b) you prompt them to do so. Anything you can do to help the output fit the grammar helps.</div><br/></div></div><div id="37127577" class="c"><input type="checkbox" id="c-37127577" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#37129978">prev</a><span>|</span><a href="#37130978">next</a><span>|</span><label class="collapse" for="c-37127577">[-]</label><label class="expand" for="c-37127577">[7 more]</label></div><br/><div class="children"><div class="content">As a more general comment, the repo README provides examples that all use gpt2. It would be nice to see at least one example that invokes llama2, since I feel like that would make sure the reader knows that this library can use models that are more modern and interesting.</div><br/><div id="37127605" class="c"><input type="checkbox" id="c-37127605" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#37127577">parent</a><span>|</span><a href="#37130678">next</a><span>|</span><label class="collapse" for="c-37127605">[-]</label><label class="expand" for="c-37127605">[4 more]</label></div><br/><div class="children"><div class="content">Inclined to disagree - gpt2 is far more likely to produce gibberish. So if you can force specific outputs on that then it is a good demo that higher quality models will be even better</div><br/><div id="37127628" class="c"><input type="checkbox" id="c-37127628" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#37127577">root</a><span>|</span><a href="#37127605">parent</a><span>|</span><a href="#37130678">next</a><span>|</span><label class="collapse" for="c-37127628">[-]</label><label class="expand" for="c-37127628">[3 more]</label></div><br/><div class="children"><div class="content">Maybe... but then if I want to use something better, I have to figure out how by myself. I said &quot;at least one example&quot;, not &quot;please change <i>all</i> the examples to llama2.&quot; I agree with your general point. It would be nice if there were an example of how to use a better model.<p>Models often have different shapes and requirements, so is it really as simple as changing the string &quot;gpt2&quot; to &quot;llama2-13B-Chat&quot; and it will magically work? If so, that&#x27;s great, and I wish that was made clear. Unfortunately, that hasn&#x27;t always been my experience with other libraries.</div><br/><div id="37127709" class="c"><input type="checkbox" id="c-37127709" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37127577">root</a><span>|</span><a href="#37127628">parent</a><span>|</span><a href="#37130678">next</a><span>|</span><label class="collapse" for="c-37127709">[-]</label><label class="expand" for="c-37127709">[2 more]</label></div><br/><div class="children"><div class="content">Agree, working on a Colab with a &quot;better&quot; model as we speak.</div><br/><div id="37128624" class="c"><input type="checkbox" id="c-37128624" checked=""/><div class="controls bullet"><span class="by">dvasdekis</span><span>|</span><a href="#37127577">root</a><span>|</span><a href="#37127709">parent</a><span>|</span><a href="#37130678">next</a><span>|</span><label class="collapse" for="c-37128624">[-]</label><label class="expand" for="c-37128624">[1 more]</label></div><br/><div class="children"><div class="content">Wonderful, thank you!</div><br/></div></div></div></div></div></div></div></div><div id="37130678" class="c"><input type="checkbox" id="c-37130678" checked=""/><div class="controls bullet"><span class="by">swyx</span><span>|</span><a href="#37127577">parent</a><span>|</span><a href="#37127605">prev</a><span>|</span><a href="#37130978">next</a><span>|</span><label class="collapse" for="c-37130678">[-]</label><label class="expand" for="c-37130678">[2 more]</label></div><br/><div class="children"><div class="content">it would also be nice to see one example that uses gpt4.</div><br/><div id="37130764" class="c"><input type="checkbox" id="c-37130764" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#37127577">root</a><span>|</span><a href="#37130678">parent</a><span>|</span><a href="#37130978">next</a><span>|</span><label class="collapse" for="c-37130764">[-]</label><label class="expand" for="c-37130764">[1 more]</label></div><br/><div class="children"><div class="content">Given how this works, I donât think that is possible unless OpenAI implements it themselves.</div><br/></div></div></div></div></div></div><div id="37130978" class="c"><input type="checkbox" id="c-37130978" checked=""/><div class="controls bullet"><span class="by">kristjansson</span><span>|</span><a href="#37127577">prev</a><span>|</span><a href="#37128280">next</a><span>|</span><label class="collapse" for="c-37130978">[-]</label><label class="expand" for="c-37130978">[3 more]</label></div><br/><div class="children"><div class="content">It does seem inapt to claim this âeliminatesâ hallucinations in your blog post. Sort of like unnamed FP languages claiming to eliminate bugs.<p>Both eliminate a subclass of failures, but donât preclude failure categorically.</div><br/><div id="37131147" class="c"><input type="checkbox" id="c-37131147" checked=""/><div class="controls bullet"><span class="by">TeeWEE</span><span>|</span><a href="#37130978">parent</a><span>|</span><a href="#37128280">next</a><span>|</span><label class="collapse" for="c-37131147">[-]</label><label class="expand" for="c-37131147">[2 more]</label></div><br/><div class="children"><div class="content">As it describes it does eliminate non JSON outputs by masking the tokens while the LLM is generating. Its quite smart if you ask me.</div><br/><div id="37131207" class="c"><input type="checkbox" id="c-37131207" checked=""/><div class="controls bullet"><span class="by">kristjansson</span><span>|</span><a href="#37130978">root</a><span>|</span><a href="#37131147">parent</a><span>|</span><a href="#37128280">next</a><span>|</span><label class="collapse" for="c-37131207">[-]</label><label class="expand" for="c-37131207">[1 more]</label></div><br/><div class="children"><div class="content">Itâs very clever. I wouldnât want it to be oversold.</div><br/></div></div></div></div></div></div><div id="37128280" class="c"><input type="checkbox" id="c-37128280" checked=""/><div class="controls bullet"><span class="by">itissid</span><span>|</span><a href="#37130978">prev</a><span>|</span><a href="#37130977">next</a><span>|</span><label class="collapse" for="c-37128280">[-]</label><label class="expand" for="c-37128280">[1 more]</label></div><br/><div class="children"><div class="content">I have noob thought on the potential of these in Formal path planning. 
Specifically given a set of functions that basically map {State -&gt; Actions} given preconditions, transition functions (heavily paraphrasing STRIPS[1]) can a correct and optionally &quot;realistic&quot; plan be generated[2]? I am quite interested in this. It seems clear that the issue is that there is no &quot;guidance&quot; like DFA on what is the correct next symbol for a Plan, but perhaps the AI can generate some kind of a probability or order on what is the best step and one can go from there...<p>Are you guys thinking about this direction?<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stanford_Research_Institute_Problem_Solver#Complexity" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stanford_Research_Institute_Pr...</a><p>[2] Formal Planning decision problem(plan exists) given STRIPS spec is at least NP-Complete[1]. There are several mathematical, logical and statistical &quot;tricks&quot;(e.g. [3]) that are used to bring down the complexity and try find a plan using heuristics(thinking MDPs, POMDPs here). This is not new, everyone in LLM research knows this.<p>[3] &quot;Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning&quot;: <a href="https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S0004370299000521?ref=pdf_download" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S000437029...</a></div><br/></div></div><div id="37130977" class="c"><input type="checkbox" id="c-37130977" checked=""/><div class="controls bullet"><span class="by">calderwoodra</span><span>|</span><a href="#37128280">prev</a><span>|</span><a href="#37125801">next</a><span>|</span><label class="collapse" for="c-37130977">[-]</label><label class="expand" for="c-37130977">[1 more]</label></div><br/><div class="children"><div class="content">Have you found a solution to output exceeding the context window? That&#x27;s been our only issue with generating json output.</div><br/></div></div><div id="37125801" class="c"><input type="checkbox" id="c-37125801" checked=""/><div class="controls bullet"><span class="by">thatcherthorn</span><span>|</span><a href="#37130977">prev</a><span>|</span><a href="#37129776">next</a><span>|</span><label class="collapse" for="c-37125801">[-]</label><label class="expand" for="c-37125801">[3 more]</label></div><br/><div class="children"><div class="content">This is awesome. I have a vision to build self-managed software. This will be a great tool.</div><br/><div id="37125814" class="c"><input type="checkbox" id="c-37125814" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125801">parent</a><span>|</span><a href="#37125847">next</a><span>|</span><label class="collapse" for="c-37125814">[-]</label><label class="expand" for="c-37125814">[1 more]</label></div><br/><div class="children"><div class="content">Thank you! Hope this helps and opens many applications :)</div><br/></div></div><div id="37125847" class="c"><input type="checkbox" id="c-37125847" checked=""/><div class="controls bullet"><span class="by">malux85</span><span>|</span><a href="#37125801">parent</a><span>|</span><a href="#37125814">prev</a><span>|</span><a href="#37129776">next</a><span>|</span><label class="collapse" for="c-37125847">[-]</label><label class="expand" for="c-37125847">[1 more]</label></div><br/><div class="children"><div class="content">This is really great too, I am building self-generating experiments and molecular simulations with <a href="https:&#x2F;&#x2F;atomictessellator.com" rel="nofollow noreferrer">https:&#x2F;&#x2F;atomictessellator.com</a> and I am going to try out this framework after work</div><br/></div></div></div></div><div id="37129776" class="c"><input type="checkbox" id="c-37129776" checked=""/><div class="controls bullet"><span class="by">dsrtslnd23</span><span>|</span><a href="#37125801">prev</a><span>|</span><a href="#37127284">next</a><span>|</span><label class="collapse" for="c-37129776">[-]</label><label class="expand" for="c-37129776">[1 more]</label></div><br/><div class="children"><div class="content">It says &quot;Outlines ã° is compatible with all models.&quot;.
But does this actually work with gpt3.5-turbo or gpt4?
I was using guidance before and you only get value when using davinci due to the constraints of chat api based models.</div><br/></div></div><div id="37127284" class="c"><input type="checkbox" id="c-37127284" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#37129776">prev</a><span>|</span><a href="#37130851">next</a><span>|</span><label class="collapse" for="c-37127284">[-]</label><label class="expand" for="c-37127284">[1 more]</label></div><br/><div class="children"><div class="content">Enforcing JSON schema, regex and grammars is very useful. But how can we enforce decoding spans from a document? decoded text should be copied from a list of spans in the input document. It would be useful for extractive tasks.</div><br/></div></div><div id="37130851" class="c"><input type="checkbox" id="c-37130851" checked=""/><div class="controls bullet"><span class="by">aiunboxed</span><span>|</span><a href="#37127284">prev</a><span>|</span><a href="#37128607">next</a><span>|</span><label class="collapse" for="c-37130851">[-]</label><label class="expand" for="c-37130851">[1 more]</label></div><br/><div class="children"><div class="content">Open AI has released this as a feature, is this news ? what am i missing ?</div><br/></div></div><div id="37128607" class="c"><input type="checkbox" id="c-37128607" checked=""/><div class="controls bullet"><span class="by">jmcminis</span><span>|</span><a href="#37130851">prev</a><span>|</span><a href="#37126329">next</a><span>|</span><label class="collapse" for="c-37128607">[-]</label><label class="expand" for="c-37128607">[1 more]</label></div><br/><div class="children"><div class="content">Are there edge cases here due to context length?<p>1. I have a json schema with required fields. I complete the json, but do not include the required fields.<p>2. I run out of token from the model before I finish the json object because I&#x27;m in the middle of some deep, nested structure.<p>These seem solvable, just edge cases to control for by either reserving tokens, randomly generating required tokens until completing the json, or something more sophisticated.</div><br/></div></div><div id="37126329" class="c"><input type="checkbox" id="c-37126329" checked=""/><div class="controls bullet"><span class="by">leetharris</span><span>|</span><a href="#37128607">prev</a><span>|</span><a href="#37125493">next</a><span>|</span><label class="collapse" for="c-37126329">[-]</label><label class="expand" for="c-37126329">[5 more]</label></div><br/><div class="children"><div class="content">How does this compare in terms of latency, cost, and effectiveness to jsonformer? <a href="https:&#x2F;&#x2F;github.com&#x2F;1rgs&#x2F;jsonformer">https:&#x2F;&#x2F;github.com&#x2F;1rgs&#x2F;jsonformer</a></div><br/><div id="37126388" class="c"><input type="checkbox" id="c-37126388" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37126329">parent</a><span>|</span><a href="#37126352">next</a><span>|</span><label class="collapse" for="c-37126388">[-]</label><label class="expand" for="c-37126388">[3 more]</label></div><br/><div class="children"><div class="content">Figure 2 in our paper (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09702" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.09702</a>) shows the difference between guidance and outlines to generate a sequence that is valid to a regex. Jsonformer uses the same technique as guidance. Extrapolate this to several fields.<p>Note that we still need to manage the KV cache in outlines. Itâs a small interface change that will be made this week hopefully, but weâve been focusing on constrained generation so far.</div><br/><div id="37126669" class="c"><input type="checkbox" id="c-37126669" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#37126329">root</a><span>|</span><a href="#37126388">parent</a><span>|</span><a href="#37126352">next</a><span>|</span><label class="collapse" for="c-37126669">[-]</label><label class="expand" for="c-37126669">[2 more]</label></div><br/><div class="children"><div class="content">Sad to see that my related work on token-level constrained text generation is not cited in the paper: <a href="https:&#x2F;&#x2F;github.com&#x2F;Hellisotherpeople&#x2F;Constrained-Text-Generation-Studio">https:&#x2F;&#x2F;github.com&#x2F;Hellisotherpeople&#x2F;Constrained-Text-Genera...</a><p><a href="https:&#x2F;&#x2F;aclanthology.org&#x2F;2022.cai-1.2&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;aclanthology.org&#x2F;2022.cai-1.2&#x2F;</a></div><br/><div id="37126743" class="c"><input type="checkbox" id="c-37126743" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37126329">root</a><span>|</span><a href="#37126669">parent</a><span>|</span><a href="#37126352">next</a><span>|</span><label class="collapse" for="c-37126743">[-]</label><label class="expand" for="c-37126743">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re unfortunately only human and didn&#x27;t catch every single paper on the topic while writing the draft. Thanks for bringing it to our attention.</div><br/></div></div></div></div></div></div><div id="37126352" class="c"><input type="checkbox" id="c-37126352" checked=""/><div class="controls bullet"><span class="by">bhickey</span><span>|</span><a href="#37126329">parent</a><span>|</span><a href="#37126388">prev</a><span>|</span><a href="#37125493">next</a><span>|</span><label class="collapse" for="c-37126352">[-]</label><label class="expand" for="c-37126352">[1 more]</label></div><br/><div class="children"><div class="content">jsonformer uses a template rather than a DFA. The logit masking seems to be identical, though.</div><br/></div></div></div></div><div id="37125493" class="c"><input type="checkbox" id="c-37125493" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#37126329">prev</a><span>|</span><a href="#37128672">next</a><span>|</span><label class="collapse" for="c-37125493">[-]</label><label class="expand" for="c-37125493">[2 more]</label></div><br/><div class="children"><div class="content">That looks intriguing. Managing that interface has proven challenging - especially on data cleaning tasks where the model ends up talking rather than doing. Bit more guiderails would be helpful on that</div><br/><div id="37125528" class="c"><input type="checkbox" id="c-37125528" checked=""/><div class="controls bullet"><span class="by">remilouf</span><span>|</span><a href="#37125493">parent</a><span>|</span><a href="#37128672">next</a><span>|</span><label class="collapse" for="c-37125528">[-]</label><label class="expand" for="c-37125528">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what we noticed as well, and we were not satisfied with the `guardrails` approach of just rejecting invalid outputs. The method makes the interface robust.</div><br/></div></div></div></div><div id="37128672" class="c"><input type="checkbox" id="c-37128672" checked=""/><div class="controls bullet"><span class="by">sandkoan</span><span>|</span><a href="#37125493">prev</a><span>|</span><label class="collapse" for="c-37128672">[-]</label><label class="expand" for="c-37128672">[1 more]</label></div><br/><div class="children"><div class="content">This is what we did at Trex (<a href="https:&#x2F;&#x2F;github.com&#x2F;automorphic-ai&#x2F;trex">https:&#x2F;&#x2F;github.com&#x2F;automorphic-ai&#x2F;trex</a>). The tricky part is doing it quickly and efficiently.</div><br/></div></div></div></div></div></div></div></body></html>