<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1718269274765" as="style"/><link rel="stylesheet" href="styles.css?v=1718269274765"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://engineering.fb.com/2024/06/12/data-infrastructure/training-large-language-models-at-scale-meta/">How Meta trains large language models at scale</a> <span class="domain">(<a href="https://engineering.fb.com">engineering.fb.com</a>)</span></div><div class="subtext"><span>mfiguiere</span> | <span>124 comments</span></div><br/><div><div id="40665413" class="c"><input type="checkbox" id="c-40665413" checked=""/><div class="controls bullet"><span class="by">samspenc</span><span>|</span><a href="#40665558">next</a><span>|</span><label class="collapse" for="c-40665413">[-]</label><label class="expand" for="c-40665413">[8 more]</label></div><br/><div class="children"><div class="content">OK this was a bit funny:<p><pre><code>  Top HW failure modes: 
  * GPU falling off the bus
</code></pre>
I honestly thought &quot;do they mean GPUs falling off a bus entering the data center&quot; and then realized its actually the connectivity, as they mention in the next line<p><pre><code>  GPUs falling off: In this case, GPUs are not detected by the host on PCIe.</code></pre></div><br/><div id="40666375" class="c"><input type="checkbox" id="c-40666375" checked=""/><div class="controls bullet"><span class="by">martin-adams</span><span>|</span><a href="#40665413">parent</a><span>|</span><a href="#40666407">next</a><span>|</span><label class="collapse" for="c-40666375">[-]</label><label class="expand" for="c-40666375">[2 more]</label></div><br/><div class="children"><div class="content">A GPU falling off the bus would be one mega flop</div><br/><div id="40666430" class="c"><input type="checkbox" id="c-40666430" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40665413">root</a><span>|</span><a href="#40666375">parent</a><span>|</span><a href="#40666407">next</a><span>|</span><label class="collapse" for="c-40666430">[-]</label><label class="expand" for="c-40666430">[1 more]</label></div><br/><div class="children"><div class="content">The audience in the back goes <i>clap clap clap</i>, <i>chapeau bas</i>.</div><br/></div></div></div></div><div id="40666407" class="c"><input type="checkbox" id="c-40666407" checked=""/><div class="controls bullet"><span class="by">m463</span><span>|</span><a href="#40665413">parent</a><span>|</span><a href="#40666375">prev</a><span>|</span><a href="#40666129">next</a><span>|</span><label class="collapse" for="c-40666407">[-]</label><label class="expand" for="c-40666407">[1 more]</label></div><br/><div class="children"><div class="content">Actually, they &quot;fell&quot; off the truck:<p><a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2021&#x2F;11&#x2F;6&#x2F;22767046&#x2F;someone-stole-shipment-evga-rtx-graphics-cards" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2021&#x2F;11&#x2F;6&#x2F;22767046&#x2F;someone-stole-sh...</a></div><br/></div></div><div id="40666129" class="c"><input type="checkbox" id="c-40666129" checked=""/><div class="controls bullet"><span class="by">ChuckMcM</span><span>|</span><a href="#40665413">parent</a><span>|</span><a href="#40666407">prev</a><span>|</span><a href="#40666824">next</a><span>|</span><label class="collapse" for="c-40666129">[-]</label><label class="expand" for="c-40666129">[1 more]</label></div><br/><div class="children"><div class="content">The bits on the bus go round and round!<p>There is a lot of interesting yet unpublished work on &#x27;data center&#x27; scale compute complexes. It was a rabbit hole I fell into several times while at Google.</div><br/></div></div><div id="40666824" class="c"><input type="checkbox" id="c-40666824" checked=""/><div class="controls bullet"><span class="by">whazor</span><span>|</span><a href="#40665413">parent</a><span>|</span><a href="#40666129">prev</a><span>|</span><a href="#40665625">next</a><span>|</span><label class="collapse" for="c-40666824">[-]</label><label class="expand" for="c-40666824">[1 more]</label></div><br/><div class="children"><div class="content">I was imagining that some sys admin has to walk to the server, take out the GPU, blow against the PCI-E pins like a game cartridge, and put it back to try again.</div><br/></div></div><div id="40665625" class="c"><input type="checkbox" id="c-40665625" checked=""/><div class="controls bullet"><span class="by">cachvico</span><span>|</span><a href="#40665413">parent</a><span>|</span><a href="#40666824">prev</a><span>|</span><a href="#40665558">next</a><span>|</span><label class="collapse" for="c-40665625">[-]</label><label class="expand" for="c-40665625">[2 more]</label></div><br/><div class="children"><div class="content">Brings a whole new meaning to bus factor</div><br/><div id="40666094" class="c"><input type="checkbox" id="c-40666094" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#40665413">root</a><span>|</span><a href="#40665625">parent</a><span>|</span><a href="#40665558">next</a><span>|</span><label class="collapse" for="c-40666094">[-]</label><label class="expand" for="c-40666094">[1 more]</label></div><br/><div class="children"><div class="content">I’ve never met a GPU that could survive getting hit by a bus.</div><br/></div></div></div></div></div></div><div id="40665558" class="c"><input type="checkbox" id="c-40665558" checked=""/><div class="controls bullet"><span class="by">dudus</span><span>|</span><a href="#40665413">prev</a><span>|</span><a href="#40665659">next</a><span>|</span><label class="collapse" for="c-40665558">[-]</label><label class="expand" for="c-40665558">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Since we did not have time to change the cooling infrastructure, we had to remain in an air-cooled environment. The mechanical and thermal designs had to change to accommodate this, and that triggered a validation cycle to support a large-scale deployment.<p>&gt; All of these hardware-related changes were challenging because we had to find a solution that fit within the existing resource constraints, with a very small degree of freedom to change and meet a tight schedule.<p>Seems like the time constraints put into the team impacted the overall quality of the model.</div><br/></div></div><div id="40665659" class="c"><input type="checkbox" id="c-40665659" checked=""/><div class="controls bullet"><span class="by">Oras</span><span>|</span><a href="#40665558">prev</a><span>|</span><a href="#40665530">next</a><span>|</span><label class="collapse" for="c-40665659">[-]</label><label class="expand" for="c-40665659">[4 more]</label></div><br/><div class="children"><div class="content">Would be nice to read how do they collect&#x2F;prepare data for training.<p>Which data sources? How much of Meta users data (fb, instagram… etc). How do they sanitize PII?</div><br/><div id="40666422" class="c"><input type="checkbox" id="c-40666422" checked=""/><div class="controls bullet"><span class="by">OsrsNeedsf2P</span><span>|</span><a href="#40665659">parent</a><span>|</span><a href="#40667357">next</a><span>|</span><label class="collapse" for="c-40666422">[-]</label><label class="expand" for="c-40666422">[2 more]</label></div><br/><div class="children"><div class="content">&gt; How do they sanitize PII?<p>I can&#x27;t comment on how things like faces get used, but in my experience, PII at Meta is inaccessible by default.<p>Unless you&#x27;re impersonating a user on the platform (to access what PII they can see), you have to request special access for logs or database columns that contain so much as user IDs, otherwise the data simply won&#x27;t show up when you query for it. This is baked into the infrastructure layer, so I doubt the GenAI teams are using something else.</div><br/><div id="40667079" class="c"><input type="checkbox" id="c-40667079" checked=""/><div class="controls bullet"><span class="by">actionfromafar</span><span>|</span><a href="#40665659">root</a><span>|</span><a href="#40666422">parent</a><span>|</span><a href="#40667357">next</a><span>|</span><label class="collapse" for="c-40667079">[-]</label><label class="expand" for="c-40667079">[1 more]</label></div><br/><div class="children"><div class="content">For a convenient definition of PII. Isn’t everything a user does in aggregate PII?</div><br/></div></div></div></div><div id="40667357" class="c"><input type="checkbox" id="c-40667357" checked=""/><div class="controls bullet"><span class="by">discobot</span><span>|</span><a href="#40665659">parent</a><span>|</span><a href="#40666422">prev</a><span>|</span><a href="#40665530">next</a><span>|</span><label class="collapse" for="c-40667357">[-]</label><label class="expand" for="c-40667357">[1 more]</label></div><br/><div class="children"><div class="content">They explicitly train models only on public datasets</div><br/></div></div></div></div><div id="40665530" class="c"><input type="checkbox" id="c-40665530" checked=""/><div class="controls bullet"><span class="by">yosito</span><span>|</span><a href="#40665659">prev</a><span>|</span><a href="#40666350">next</a><span>|</span><label class="collapse" for="c-40665530">[-]</label><label class="expand" for="c-40665530">[2 more]</label></div><br/><div class="children"><div class="content">I wish that instead of just training another stupid LLM, Meta would use it to improve their search and help me find the content I&#x27;m actually interested in.</div><br/><div id="40666359" class="c"><input type="checkbox" id="c-40666359" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40665530">parent</a><span>|</span><a href="#40666350">next</a><span>|</span><label class="collapse" for="c-40666359">[-]</label><label class="expand" for="c-40666359">[1 more]</label></div><br/><div class="children"><div class="content">Their revenue depends on it being hard (but not impossible) for you to find the content you&#x27;re actually interested in. Would be nice if it didn&#x27;t, but in this reality, money on the Internet is made by wasting users&#x27; lives. That is what attention economy is about.</div><br/></div></div></div></div><div id="40666350" class="c"><input type="checkbox" id="c-40666350" checked=""/><div class="controls bullet"><span class="by">lokimedes</span><span>|</span><a href="#40665530">prev</a><span>|</span><a href="#40664978">next</a><span>|</span><label class="collapse" for="c-40666350">[-]</label><label class="expand" for="c-40666350">[2 more]</label></div><br/><div class="children"><div class="content">Yikes, the little Infiniband+A100 cluster I installed for my previous company seemed useful at the time (12 GPUs) and that was at a cost of around $300k. With LLMs it feels like game over for non-cloud applications if you are not a mega-corp.</div><br/><div id="40666445" class="c"><input type="checkbox" id="c-40666445" checked=""/><div class="controls bullet"><span class="by">lannisterstark</span><span>|</span><a href="#40666350">parent</a><span>|</span><a href="#40664978">next</a><span>|</span><label class="collapse" for="c-40666445">[-]</label><label class="expand" for="c-40666445">[1 more]</label></div><br/><div class="children"><div class="content">Well, yes, but Not all models need to be &quot;super large.&quot; Smaller models, specialized in specific tasks, working together - and then reporting to a slightly larger model is the way to go.<p>Think of everything being connected to a &quot;Home Computer&quot; in those &quot;Future House of 2020&quot; videos that were out there in 70s or what not.<p>Another example (very rough) would be something like &quot;Weather data gets to a small model via an API, model looks at it, updates the home dashboard, also sees if there&#x27;s any alerts, if so, adds x or y to home dashboard appropriately as to what it thinks best.&quot;<p>We can probably achieve the latter example today. (without any significant &#x27;coding&#x27; on anyone&#x27;s part except the API owner)</div><br/></div></div></div></div><div id="40664978" class="c"><input type="checkbox" id="c-40664978" checked=""/><div class="controls bullet"><span class="by">mike_d</span><span>|</span><a href="#40666350">prev</a><span>|</span><a href="#40665450">next</a><span>|</span><label class="collapse" for="c-40664978">[-]</label><label class="expand" for="c-40664978">[75 more]</label></div><br/><div class="children"><div class="content">Posts like this underscore why the smart money is betting on Google as the long term AI winner. Meta, Microsoft, OpenAI, etc. are trying to address problems with consumer video cards and spending billions to try and out bid each other to win Nvidia&#x27;s favor - while Google is on their 6th generation of custom silicon.<p>Literally the only thing that can stop Google now is the fact they keep bringing Microsoft and Oracle flunkies into leadership positions.</div><br/><div id="40665112" class="c"><input type="checkbox" id="c-40665112" checked=""/><div class="controls bullet"><span class="by">throwaway_ab</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665177">next</a><span>|</span><label class="collapse" for="c-40665112">[-]</label><label class="expand" for="c-40665112">[36 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s likely Nvidia&#x27;s GPU&#x27;s, many of which are $50,000+ for a single unit, far surpass Google&#x27;s custom silicon otherwise why wouldn&#x27;t Google be selling shovels like Nvidia?<p>If Google had a better chip, or even a chip that was close, they would sell it to anyone and everyone.<p>From a quick search I can see Google&#x27;s custom chips are 15x to 30x slower to train AI compared to Nvidia&#x27;s current latest gen AI specific GPU&#x27;s.</div><br/><div id="40665297" class="c"><input type="checkbox" id="c-40665297" checked=""/><div class="controls bullet"><span class="by">aseipp</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665112">parent</a><span>|</span><a href="#40665929">next</a><span>|</span><label class="collapse" for="c-40665297">[-]</label><label class="expand" for="c-40665297">[1 more]</label></div><br/><div class="children"><div class="content">Nvidia has decades of experience selling hardware to people with all the pains that entails, support, sales channels, customer acquisition, software, it&#x27;s something you don&#x27;t just do overnight, and it does cost money. Google&#x27;s TPUs get some of their cost efficiency from not supporting COTS use cases and the overhead of selling to people, and the total wall clock time has to also include the total operational costs, which dominate at their size (e.g. if it&#x27;s 30x slower but 1&#x2F;50th the TCO then it&#x27;s a win. I don&#x27;t know how TPUv5 stacks up against the B200). It&#x27;s not as simple as &quot;just put it on a shelf and sell it and make a gajillion dollars like nvidia&quot;</div><br/></div></div><div id="40665929" class="c"><input type="checkbox" id="c-40665929" checked=""/><div class="controls bullet"><span class="by">EvgeniyZh</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665112">parent</a><span>|</span><a href="#40665297">prev</a><span>|</span><a href="#40665474">next</a><span>|</span><label class="collapse" for="c-40665929">[-]</label><label class="expand" for="c-40665929">[1 more]</label></div><br/><div class="children"><div class="content">TPU v5p is ~2 times slower than H100 at larg(ish)-scale training (order of 10k chips) [1]. And they already have v6 [2]. I think it&#x27;s safe to say that they are fairly close to Nvidia in terms of performance.<p>[1] <a href="https:&#x2F;&#x2F;mlcommons.org&#x2F;benchmarks&#x2F;training&#x2F;" rel="nofollow">https:&#x2F;&#x2F;mlcommons.org&#x2F;benchmarks&#x2F;training&#x2F;</a><p>[2] <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;compute&#x2F;introducing-trillium-6th-gen-tpus" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;compute&#x2F;introducing-t...</a></div><br/></div></div><div id="40665474" class="c"><input type="checkbox" id="c-40665474" checked=""/><div class="controls bullet"><span class="by">bluedino</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665112">parent</a><span>|</span><a href="#40665929">prev</a><span>|</span><a href="#40665962">next</a><span>|</span><label class="collapse" for="c-40665474">[-]</label><label class="expand" for="c-40665474">[12 more]</label></div><br/><div class="children"><div class="content">We have almost 400 H100&#x27;s sitting idle. I wonder how many other companies are buying millions of dollars worth of these chips with the hopes of them being used, but aren&#x27;t being utilized?</div><br/><div id="40665835" class="c"><input type="checkbox" id="c-40665835" checked=""/><div class="controls bullet"><span class="by">jonathanlei</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665474">parent</a><span>|</span><a href="#40666545">next</a><span>|</span><label class="collapse" for="c-40665835">[-]</label><label class="expand" for="c-40665835">[2 more]</label></div><br/><div class="children"><div class="content">Hello! If you&#x27;re interested in monetizing those GPUs, I&#x27;d be happy to rent them (all 400!) and offer those to customers of the cloud I work at :)<p>jonathan [at] tensordock.com</div><br/><div id="40665973" class="c"><input type="checkbox" id="c-40665973" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665835">parent</a><span>|</span><a href="#40666545">next</a><span>|</span><label class="collapse" for="c-40665973">[-]</label><label class="expand" for="c-40665973">[1 more]</label></div><br/><div class="children"><div class="content">If you want 512 H100s connected with infiniband: <a href="https:&#x2F;&#x2F;lambdalabs.com&#x2F;service&#x2F;gpu-cloud&#x2F;1-click-clusters" rel="nofollow">https:&#x2F;&#x2F;lambdalabs.com&#x2F;service&#x2F;gpu-cloud&#x2F;1-click-clusters</a></div><br/></div></div></div></div><div id="40666545" class="c"><input type="checkbox" id="c-40666545" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665474">parent</a><span>|</span><a href="#40665835">prev</a><span>|</span><a href="#40665750">next</a><span>|</span><label class="collapse" for="c-40666545">[-]</label><label class="expand" for="c-40666545">[1 more]</label></div><br/><div class="children"><div class="content">So you&#x27;re saying, H100s are the corporate equivalent of Raspberry Pis now? Bought to not miss out, then left to gather dust in a drawer?</div><br/></div></div><div id="40665750" class="c"><input type="checkbox" id="c-40665750" checked=""/><div class="controls bullet"><span class="by">radq</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665474">parent</a><span>|</span><a href="#40666545">prev</a><span>|</span><a href="#40665827">next</a><span>|</span><label class="collapse" for="c-40665750">[-]</label><label class="expand" for="c-40665750">[1 more]</label></div><br/><div class="children"><div class="content">Have you considered sponsoring an open-source project? ;)</div><br/></div></div><div id="40665581" class="c"><input type="checkbox" id="c-40665581" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665474">parent</a><span>|</span><a href="#40665827">prev</a><span>|</span><a href="#40665494">next</a><span>|</span><label class="collapse" for="c-40665581">[-]</label><label class="expand" for="c-40665581">[1 more]</label></div><br/><div class="children"><div class="content">the world would love to buy time on your idle H100&#x27;s if you&#x27;re selling.</div><br/></div></div><div id="40665494" class="c"><input type="checkbox" id="c-40665494" checked=""/><div class="controls bullet"><span class="by">irjustin</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665474">parent</a><span>|</span><a href="#40665581">prev</a><span>|</span><a href="#40665553">next</a><span>|</span><label class="collapse" for="c-40665494">[-]</label><label class="expand" for="c-40665494">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s insane and incredible all at the same time.</div><br/></div></div><div id="40665553" class="c"><input type="checkbox" id="c-40665553" checked=""/><div class="controls bullet"><span class="by">gfosco</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665474">parent</a><span>|</span><a href="#40665494">prev</a><span>|</span><a href="#40666115">next</a><span>|</span><label class="collapse" for="c-40665553">[-]</label><label class="expand" for="c-40665553">[1 more]</label></div><br/><div class="children"><div class="content">Looking to get rid of a few?....</div><br/></div></div><div id="40666115" class="c"><input type="checkbox" id="c-40666115" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665474">parent</a><span>|</span><a href="#40665553">prev</a><span>|</span><a href="#40665526">next</a><span>|</span><label class="collapse" for="c-40666115">[-]</label><label class="expand" for="c-40666115">[1 more]</label></div><br/><div class="children"><div class="content">I know of many important projects that need GPUs right now and aren’t getting any. You could help motivate the ponydiffusion folks to actually try finetuning of SD3!</div><br/></div></div><div id="40665526" class="c"><input type="checkbox" id="c-40665526" checked=""/><div class="controls bullet"><span class="by">newswasboring</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665474">parent</a><span>|</span><a href="#40666115">prev</a><span>|</span><a href="#40665647">next</a><span>|</span><label class="collapse" for="c-40665526">[-]</label><label class="expand" for="c-40665526">[1 more]</label></div><br/><div class="children"><div class="content">Wow, that&#x27;s a lot of money in inventory. What was the original thought process? Just fomo?</div><br/></div></div><div id="40665647" class="c"><input type="checkbox" id="c-40665647" checked=""/><div class="controls bullet"><span class="by">giancarlostoro</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665474">parent</a><span>|</span><a href="#40665526">prev</a><span>|</span><a href="#40665962">next</a><span>|</span><label class="collapse" for="c-40665647">[-]</label><label class="expand" for="c-40665647">[1 more]</label></div><br/><div class="children"><div class="content">Probably could profit selling them second hand honestly.</div><br/></div></div></div></div><div id="40665962" class="c"><input type="checkbox" id="c-40665962" checked=""/><div class="controls bullet"><span class="by">vineyardmike</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665112">parent</a><span>|</span><a href="#40665474">prev</a><span>|</span><a href="#40667201">next</a><span>|</span><label class="collapse" for="c-40665962">[-]</label><label class="expand" for="c-40665962">[4 more]</label></div><br/><div class="children"><div class="content">&gt; why wouldn&#x27;t Google be selling shovels<p>They do sell them - but through their struggling cloud business. Either way, Nvidia&#x27;s margin is google&#x27;s opportunity to lower costs.<p>&gt; I can see Google&#x27;s custom chips are 15x to 30x slower to train AI<p>TPUs are designed for inference not training - they&#x27;re betting that they can <i>serve</i> models to the world at a lower cost structure than their competition. The compute required for inference to serve their billions of customers is far greater than training costs for models - even LLMs. They&#x27;ve been running model inference as a part of production traffic for <i>years</i>.</div><br/><div id="40666205" class="c"><input type="checkbox" id="c-40666205" checked=""/><div class="controls bullet"><span class="by">uluyol</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665962">parent</a><span>|</span><a href="#40666197">next</a><span>|</span><label class="collapse" for="c-40666205">[-]</label><label class="expand" for="c-40666205">[1 more]</label></div><br/><div class="children"><div class="content">Google most certainly uses TPUs for training.</div><br/></div></div><div id="40666197" class="c"><input type="checkbox" id="c-40666197" checked=""/><div class="controls bullet"><span class="by">refulgentis</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665962">parent</a><span>|</span><a href="#40666205">prev</a><span>|</span><a href="#40667201">next</a><span>|</span><label class="collapse" for="c-40666197">[-]</label><label class="expand" for="c-40666197">[2 more]</label></div><br/><div class="children"><div class="content">This breaks my brain, because I know Google trains it models on TPUs and they&#x27;re seen as faster, and if they&#x27;re better at inference, and can train, then why is Nvidia in a unique position? My understanding was always it&#x27;s as simple as it required esoteric tooling</div><br/><div id="40666236" class="c"><input type="checkbox" id="c-40666236" checked=""/><div class="controls bullet"><span class="by">smueller1234</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40666197">parent</a><span>|</span><a href="#40667201">next</a><span>|</span><label class="collapse" for="c-40666236">[-]</label><label class="expand" for="c-40666236">[1 more]</label></div><br/><div class="children"><div class="content">Multiple types of TPUs.<p>(I work for Google, but the above is public information.)</div><br/></div></div></div></div></div></div><div id="40667201" class="c"><input type="checkbox" id="c-40667201" checked=""/><div class="controls bullet"><span class="by">xipix</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665112">parent</a><span>|</span><a href="#40665962">prev</a><span>|</span><a href="#40666537">next</a><span>|</span><label class="collapse" for="c-40667201">[-]</label><label class="expand" for="c-40667201">[1 more]</label></div><br/><div class="children"><div class="content">Intel, AMD and others also have chips for training that perform close to or sometimes better than Nvidia&#x27;s. These are already in the market. Two problems: the CUDA moat, and, &quot;noone gets fired for buying green&quot;.</div><br/></div></div><div id="40666537" class="c"><input type="checkbox" id="c-40666537" checked=""/><div class="controls bullet"><span class="by">girvo</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665112">parent</a><span>|</span><a href="#40667201">prev</a><span>|</span><a href="#40665149">next</a><span>|</span><label class="collapse" for="c-40666537">[-]</label><label class="expand" for="c-40666537">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If Google had a better chip, or even a chip that was close, they would sell it to anyone and everyone.<p>While I do not actually think Google&#x27;s chips <i>are</i> better or close to being better, I don&#x27;t think this actually holds?<p>If the upside of &lt;better chip&gt; is effectively unbounded, it would outweigh the short term benefit of selling them to others, I would think. At least for a company like Google.</div><br/></div></div><div id="40665149" class="c"><input type="checkbox" id="c-40665149" checked=""/><div class="controls bullet"><span class="by">candiddevmike</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665112">parent</a><span>|</span><a href="#40666537">prev</a><span>|</span><a href="#40667271">next</a><span>|</span><label class="collapse" for="c-40665149">[-]</label><label class="expand" for="c-40665149">[14 more]</label></div><br/><div class="children"><div class="content">They do sell shovels, you can get Google TPUs on Google Cloud.</div><br/><div id="40665206" class="c"><input type="checkbox" id="c-40665206" checked=""/><div class="controls bullet"><span class="by">matt-p</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665149">parent</a><span>|</span><a href="#40665220">next</a><span>|</span><label class="collapse" for="c-40665206">[-]</label><label class="expand" for="c-40665206">[9 more]</label></div><br/><div class="children"><div class="content">Exactly and they are still about 1&#x2F;18ths as good at training llms as a H100.<p>Maybe they are less than 1&#x2F;18ths the cost, so google technically have a marginally better unit cost but i doubt it when you consider the R&amp;D cost. They are less bad at inference, but still much worse than even an A100.</div><br/><div id="40665680" class="c"><input type="checkbox" id="c-40665680" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665206">parent</a><span>|</span><a href="#40665274">next</a><span>|</span><label class="collapse" for="c-40665680">[-]</label><label class="expand" for="c-40665680">[1 more]</label></div><br/><div class="children"><div class="content">Given that Google invented Transformer architecture (and Google AI continues to do foundational R&amp;D on ML architecture) — and that Google&#x27;s TPUs don&#x27;t even support the most common ML standards, but require their own training and inference frameworks — I would assume that &quot;the point&quot; of TPUs <i>from Google&#x27;s perspective</i>, has less to do with running LLMs, and more to do with running weird experimental custom model architectures that don&#x27;t even exist as journal papers yet.<p>I would bet money that TPUs are at least better at <i>doing AI research</i> than anything Nvidia will sell you. That alone might be enough for Google to keep getting some new ones fabbed each year. The TPUs you can rent on Google Cloud might very well just be hardware requisitioned by the AI team, for the AI team, that they aren&#x27;t always using to capacity, and so is &quot;earning out&quot; its CapEx through public rentals.<p>TPUs are <i>maybe</i> also better at other things Google does internally, too. Running inference on YouTube&#x27;s audio+video-input timecoded-captions-output model, say.</div><br/></div></div><div id="40665274" class="c"><input type="checkbox" id="c-40665274" checked=""/><div class="controls bullet"><span class="by">blharr</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665206">parent</a><span>|</span><a href="#40665680">prev</a><span>|</span><a href="#40665267">next</a><span>|</span><label class="collapse" for="c-40665274">[-]</label><label class="expand" for="c-40665274">[2 more]</label></div><br/><div class="children"><div class="content">Also energy cost. 18 chips vs 1, it&#x27;s probably costing a lot more to run 18</div><br/><div id="40665304" class="c"><input type="checkbox" id="c-40665304" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665274">parent</a><span>|</span><a href="#40665267">next</a><span>|</span><label class="collapse" for="c-40665304">[-]</label><label class="expand" for="c-40665304">[1 more]</label></div><br/><div class="children"><div class="content">Google claims the opposite in &quot;TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings
&quot; <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.01433" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.01433</a><p>Despite various details I don&#x27;t think that this is an area where Facebook is very different from Google. Both have terrifying amounts of datacenter to play with. Both have long experience making reliable products out of unreliable subsystems. Both have innovative orchestration and storage stacks. Meta hasn&#x27;t published much or anything about things like reconfigurable optical switches, but that doesn&#x27;t mean they don&#x27;t have such a thing.</div><br/></div></div></div></div><div id="40665267" class="c"><input type="checkbox" id="c-40665267" checked=""/><div class="controls bullet"><span class="by">jeffbee</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665206">parent</a><span>|</span><a href="#40665274">prev</a><span>|</span><a href="#40665220">next</a><span>|</span><label class="collapse" for="c-40665267">[-]</label><label class="expand" for="c-40665267">[5 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see how you can evaluate better and worse for training without doing so on cost basis. If it costs less and eventually finishes then it&#x27;s better.</div><br/><div id="40665594" class="c"><input type="checkbox" id="c-40665594" checked=""/><div class="controls bullet"><span class="by">tmostak</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665267">parent</a><span>|</span><a href="#40665627">next</a><span>|</span><label class="collapse" for="c-40665594">[-]</label><label class="expand" for="c-40665594">[3 more]</label></div><br/><div class="children"><div class="content">This assumes that you can linearly scale up the number of TPUs to get equal performance to Nvidia cards for less cost. Like most things distributed, this is unlikely to be the case.</div><br/><div id="40666571" class="c"><input type="checkbox" id="c-40666571" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665594">parent</a><span>|</span><a href="#40665627">next</a><span>|</span><label class="collapse" for="c-40666571">[-]</label><label class="expand" for="c-40666571">[2 more]</label></div><br/><div class="children"><div class="content">This is absolutely the case, TPUs scale very well: <a href="https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;maxtext">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;maxtext</a> .</div><br/><div id="40666728" class="c"><input type="checkbox" id="c-40666728" checked=""/><div class="controls bullet"><span class="by">pama</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40666571">parent</a><span>|</span><a href="#40665627">next</a><span>|</span><label class="collapse" for="c-40666728">[-]</label><label class="expand" for="c-40666728">[1 more]</label></div><br/><div class="children"><div class="content">The repo mentiones a Karpathy tweet from Jan 2023. Andrej has recently created llm.c and the same model trained about 32x faster on the same NVidia hardware mentioned in the tweet.  I dont think the perfomance estimate that the repo used (based on that early tweet) was accurate for the performance of the NVidia hardware itself.</div><br/></div></div></div></div></div></div><div id="40665627" class="c"><input type="checkbox" id="c-40665627" checked=""/><div class="controls bullet"><span class="by">fbdab103</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665267">parent</a><span>|</span><a href="#40665594">prev</a><span>|</span><a href="#40665220">next</a><span>|</span><label class="collapse" for="c-40665627">[-]</label><label class="expand" for="c-40665627">[1 more]</label></div><br/><div class="children"><div class="content">Time is money. You might be a lab with long queues to train, leaving expensive staff twiddling their thumbs.</div><br/></div></div></div></div></div></div><div id="40665220" class="c"><input type="checkbox" id="c-40665220" checked=""/><div class="controls bullet"><span class="by">throwaway_ab</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665149">parent</a><span>|</span><a href="#40665206">prev</a><span>|</span><a href="#40667271">next</a><span>|</span><label class="collapse" for="c-40665220">[-]</label><label class="expand" for="c-40665220">[4 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t that be renting a shovel vs selling a shovel?</div><br/><div id="40665226" class="c"><input type="checkbox" id="c-40665226" checked=""/><div class="controls bullet"><span class="by">candiddevmike</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665220">parent</a><span>|</span><a href="#40667271">next</a><span>|</span><label class="collapse" for="c-40665226">[-]</label><label class="expand" for="c-40665226">[3 more]</label></div><br/><div class="children"><div class="content">NVIDIA sells subscriptions...</div><br/><div id="40667397" class="c"><input type="checkbox" id="c-40667397" checked=""/><div class="controls bullet"><span class="by">kkielhofner</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665226">parent</a><span>|</span><a href="#40665283">next</a><span>|</span><label class="collapse" for="c-40667397">[-]</label><label class="expand" for="c-40667397">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure why you&#x27;re getting downvoted. It&#x27;s very clear that Nvidia is moving towards directly offering cloud services[0].<p>[0] - <a href="https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;dgx-cloud&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;data-center&#x2F;dgx-cloud&#x2F;</a></div><br/></div></div><div id="40665283" class="c"><input type="checkbox" id="c-40665283" checked=""/><div class="controls bullet"><span class="by">throwaway_ab</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665226">parent</a><span>|</span><a href="#40667397">prev</a><span>|</span><a href="#40667271">next</a><span>|</span><label class="collapse" for="c-40665283">[-]</label><label class="expand" for="c-40665283">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m only aware of Nvidia AI Enterprise and that isn&#x27;t required to run the GPU.<p>I think it&#x27;s aimed at medium to large corporations.<p>Massive corporations such as Meta and OpenAI would build their own cloud and not rely on this.<p>The GPU really is a shovel, and can be used without any subscription.<p>Don&#x27;t get me wrong, I want there to be competition with Nvidia, I want more access for open source and small players to run and train AI on competitive hardware at our own sites.<p>But no one is competing, no one has any idea what they&#x27;re doing. Nvidia has no competition whatsoever, no one is even close.<p>This lets Nvidia get away with adding more vram onto an AI specific GPU and increase the price by 10x.<p>This lets Nvidia remove NVLink from current gen consumer cards like the 4090.<p>This lets Nvidia use their driver licence to prevent cloud platforms from offering consumers cards as a choice in datacenters.<p>If Nvidia had a shred of competition things would be much better.</div><br/></div></div></div></div></div></div></div></div><div id="40667271" class="c"><input type="checkbox" id="c-40667271" checked=""/><div class="controls bullet"><span class="by">megablast</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665112">parent</a><span>|</span><a href="#40665149">prev</a><span>|</span><a href="#40665177">next</a><span>|</span><label class="collapse" for="c-40667271">[-]</label><label class="expand" for="c-40667271">[1 more]</label></div><br/><div class="children"><div class="content">Is that why apple sell there chips to everyone??</div><br/></div></div></div></div><div id="40665177" class="c"><input type="checkbox" id="c-40665177" checked=""/><div class="controls bullet"><span class="by">matt-p</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665112">prev</a><span>|</span><a href="#40665143">next</a><span>|</span><label class="collapse" for="c-40665177">[-]</label><label class="expand" for="c-40665177">[3 more]</label></div><br/><div class="children"><div class="content">Can&#x27;t agree. This is like saying $popularApp will fail because they buy expensive hosting at AWS.<p>Rubbish they will fail because the product didn&#x27;t fit the market, if they&#x27;re successful they&#x27;ll have money to buy servers and colo then drive down cost. If they succeed it will be in large part due to the fact they spent thier capital and more importantly time on code&#x2F;engineers rather than servers.<p>Right now companies are searching for a use of AI that will add hundreds of billions to thier market cap. Once they find that they can make TPUs, right now only one thing matters; getting there first.</div><br/><div id="40666260" class="c"><input type="checkbox" id="c-40666260" checked=""/><div class="controls bullet"><span class="by">mike_d</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665177">parent</a><span>|</span><a href="#40665584">next</a><span>|</span><label class="collapse" for="c-40666260">[-]</label><label class="expand" for="c-40666260">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is like saying $popularApp will fail because they buy expensive hosting at AWS.<p>For any given mobile app startup, AWS is effectively infinite. The more money you throw at it the more doodads you get back. Nvidia&#x27;s supply chain is not infinite and is the bottle neck for all the non-Google players to fight over.</div><br/></div></div></div></div><div id="40665143" class="c"><input type="checkbox" id="c-40665143" checked=""/><div class="controls bullet"><span class="by">tw04</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665177">prev</a><span>|</span><a href="#40665029">next</a><span>|</span><label class="collapse" for="c-40665143">[-]</label><label class="expand" for="c-40665143">[8 more]</label></div><br/><div class="children"><div class="content">Except Microsoft is making their own chips as well?<p><a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;11&#x2F;15&#x2F;23960345&#x2F;microsoft-cpu-gpu-ai-chips-azure-maia-cobalt-specifications-cloud-infrastructure" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;11&#x2F;15&#x2F;23960345&#x2F;microsoft-cpu-g...</a></div><br/><div id="40665222" class="c"><input type="checkbox" id="c-40665222" checked=""/><div class="controls bullet"><span class="by">jauer</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665143">parent</a><span>|</span><a href="#40665029">next</a><span>|</span><label class="collapse" for="c-40665222">[-]</label><label class="expand" for="c-40665222">[7 more]</label></div><br/><div class="children"><div class="content">and so is Meta: <a href="https:&#x2F;&#x2F;ai.meta.com&#x2F;blog&#x2F;next-generation-meta-training-inference-accelerator-AI-MTIA&#x2F;" rel="nofollow">https:&#x2F;&#x2F;ai.meta.com&#x2F;blog&#x2F;next-generation-meta-training-infer...</a></div><br/><div id="40665301" class="c"><input type="checkbox" id="c-40665301" checked=""/><div class="controls bullet"><span class="by">boringg</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665222">parent</a><span>|</span><a href="#40665029">next</a><span>|</span><label class="collapse" for="c-40665301">[-]</label><label class="expand" for="c-40665301">[6 more]</label></div><br/><div class="children"><div class="content">Ever since Apple did it everyone has leaped on board.  Let&#x27;s see how things pan out for everyone...</div><br/><div id="40665509" class="c"><input type="checkbox" id="c-40665509" checked=""/><div class="controls bullet"><span class="by">1024core</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665301">parent</a><span>|</span><a href="#40665354">next</a><span>|</span><label class="collapse" for="c-40665509">[-]</label><label class="expand" for="c-40665509">[3 more]</label></div><br/><div class="children"><div class="content">Google introduced their first TPU in 2015...? Long before Apple taped out their first silicon.</div><br/><div id="40665563" class="c"><input type="checkbox" id="c-40665563" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665509">parent</a><span>|</span><a href="#40665946">next</a><span>|</span><label class="collapse" for="c-40665563">[-]</label><label class="expand" for="c-40665563">[1 more]</label></div><br/><div class="children"><div class="content">if we&#x27;re talking custom silicon, Google acquired Motorola in 2011, and Apple acquired PA semi in 2008.<p>The idea is obvious to everybody in the industry, it&#x27;s a question of money and motivation.</div><br/></div></div><div id="40665946" class="c"><input type="checkbox" id="c-40665946" checked=""/><div class="controls bullet"><span class="by">mamp</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665509">parent</a><span>|</span><a href="#40665563">prev</a><span>|</span><a href="#40665354">next</a><span>|</span><label class="collapse" for="c-40665946">[-]</label><label class="expand" for="c-40665946">[1 more]</label></div><br/><div class="children"><div class="content">Apple’s first in-house designed chip was the A4 in 2010.</div><br/></div></div></div></div><div id="40665354" class="c"><input type="checkbox" id="c-40665354" checked=""/><div class="controls bullet"><span class="by">jacurtis</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665301">parent</a><span>|</span><a href="#40665509">prev</a><span>|</span><a href="#40665029">next</a><span>|</span><label class="collapse" for="c-40665354">[-]</label><label class="expand" for="c-40665354">[2 more]</label></div><br/><div class="children"><div class="content">And that&#x27;s why $ARM is a good buy. Selling swords and steel to all these armies as they go to war.</div><br/><div id="40665899" class="c"><input type="checkbox" id="c-40665899" checked=""/><div class="controls bullet"><span class="by">silisili</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665354">parent</a><span>|</span><a href="#40665029">next</a><span>|</span><label class="collapse" for="c-40665899">[-]</label><label class="expand" for="c-40665899">[1 more]</label></div><br/><div class="children"><div class="content">ARM is just collecting royalties in this space.  Their reference designs aren&#x27;t exactly competitive.<p>I&#x27;m not saying it&#x27;s a bad buy, either, but if and when they turn the screws, there will be a mass exodus.  Solid long term play perhaps, but not going to see Nvidia like price action.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="40665029" class="c"><input type="checkbox" id="c-40665029" checked=""/><div class="controls bullet"><span class="by">hooloovoo_zoo</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665143">prev</a><span>|</span><a href="#40665674">next</a><span>|</span><label class="collapse" for="c-40665029">[-]</label><label class="expand" for="c-40665029">[1 more]</label></div><br/><div class="children"><div class="content">Google has been working on TPUs and Tensorflow for a decade with pretty mixed success; I don&#x27;t think it&#x27;s clear that they&#x27;re going to win.</div><br/></div></div><div id="40665674" class="c"><input type="checkbox" id="c-40665674" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665029">prev</a><span>|</span><a href="#40665516">next</a><span>|</span><label class="collapse" for="c-40665674">[-]</label><label class="expand" for="c-40665674">[1 more]</label></div><br/><div class="children"><div class="content">^ How to compact as many mistakes as possible in one single comment.<p>1. Google&#x27;s stock didn&#x27;t siginificantly outperformed Meta, Microsoft, etc, in thet past two years.<p>2. Meta and Microsoft are trying to make their own chips as well.<p>3. They&#x27;re not using &quot;consumer video cards&quot; to train AI. I don&#x27;t even know if you can call these beasts video cards any more. H100 doesn&#x27;t have HDMI port.</div><br/></div></div><div id="40665516" class="c"><input type="checkbox" id="c-40665516" checked=""/><div class="controls bullet"><span class="by">zmmmmm</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665674">prev</a><span>|</span><a href="#40665399">next</a><span>|</span><label class="collapse" for="c-40665516">[-]</label><label class="expand" for="c-40665516">[1 more]</label></div><br/><div class="children"><div class="content">Custom silicon is fantastic when things have stabilised and you know exactly want you want. But things are still evolving fast in real time and in that environment, whoever can move fastest to be ultra flexible and deploy the latest architecture as soon as possible is the winner. I think in a nutshell, that is the story of Nvidia&#x27;s success here : they created a GPGPU platform with just the right level of abstraction to capture the market for AI research.</div><br/></div></div><div id="40665399" class="c"><input type="checkbox" id="c-40665399" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665516">prev</a><span>|</span><a href="#40665469">next</a><span>|</span><label class="collapse" for="c-40665399">[-]</label><label class="expand" for="c-40665399">[1 more]</label></div><br/><div class="children"><div class="content">I would call it &quot;stupid&quot; money. This isn&#x27;t a commodity business. Value of the final product is orthogonal to amount invested in compute. If Google is 10% slower or its product is 10% worse, it can lose all the value. This is like valuing a software company higher because its devs are using cheap PC desktops instead of Mac.</div><br/></div></div><div id="40665469" class="c"><input type="checkbox" id="c-40665469" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665399">prev</a><span>|</span><a href="#40665016">next</a><span>|</span><label class="collapse" for="c-40665469">[-]</label><label class="expand" for="c-40665469">[1 more]</label></div><br/><div class="children"><div class="content">That’s how all huge tech companies become dinosaurs though. Upper management that is already stupidly wealthy (and therefore unmotivated) have the funding and patience to hire geniuses to build incredible machines and then constantly tie their shoelaces together while asking them to sprint. Examples include Microsoft and Oracle as you said, and before them IBM, AT$T, TIBCO, Marvell, Motorola, I could go on for a while…</div><br/></div></div><div id="40665016" class="c"><input type="checkbox" id="c-40665016" checked=""/><div class="controls bullet"><span class="by">zdyn5</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665469">prev</a><span>|</span><a href="#40665944">next</a><span>|</span><label class="collapse" for="c-40665016">[-]</label><label class="expand" for="c-40665016">[5 more]</label></div><br/><div class="children"><div class="content">H100s are far from consumer video cards</div><br/><div id="40665164" class="c"><input type="checkbox" id="c-40665164" checked=""/><div class="controls bullet"><span class="by">stygiansonic</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665016">parent</a><span>|</span><a href="#40665944">next</a><span>|</span><label class="collapse" for="c-40665164">[-]</label><label class="expand" for="c-40665164">[4 more]</label></div><br/><div class="children"><div class="content">Yeah, ops comment makes it seem like they are building racks of RTX 4090s, when this isn’t remotely true. Tensor Core performance is far different on the data center class devices vs consumer ones.</div><br/><div id="40666288" class="c"><input type="checkbox" id="c-40666288" checked=""/><div class="controls bullet"><span class="by">mike_d</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665164">parent</a><span>|</span><a href="#40665944">next</a><span>|</span><label class="collapse" for="c-40666288">[-]</label><label class="expand" for="c-40666288">[3 more]</label></div><br/><div class="children"><div class="content">They are building racks of 4090s. Nobody can get H100s in any reasonable volume.<p>Hell, Microsoft is renting GPUs from Oracle Cloud to get enough capacity to run Bing.</div><br/><div id="40666569" class="c"><input type="checkbox" id="c-40666569" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40666288">parent</a><span>|</span><a href="#40667326">next</a><span>|</span><label class="collapse" for="c-40666569">[-]</label><label class="expand" for="c-40666569">[1 more]</label></div><br/><div class="children"><div class="content">There are apparently some 400 of H100s sitting idle somewhere upthread. Yes, I&#x27;m having hard time imagining how&#x27;s that possible too.</div><br/></div></div><div id="40667326" class="c"><input type="checkbox" id="c-40667326" checked=""/><div class="controls bullet"><span class="by">kkielhofner</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40666288">parent</a><span>|</span><a href="#40666569">prev</a><span>|</span><a href="#40665944">next</a><span>|</span><label class="collapse" for="c-40667326">[-]</label><label class="expand" for="c-40667326">[1 more]</label></div><br/><div class="children"><div class="content">Who is &quot;they&quot;?<p>RTX 4090s are terrible for this task. Off the top of my head:<p>- VRAM (obviously). Isn&#x27;t that where the racks come in? Not really. Nvidia famously removed something as basic as NVLink between two cards from the 3090 to the 4090. When it comes to bandwidth between cards (crucial) even 16 lanes of PCIe 4 isn&#x27;t fast enough. When you start talking about &quot;racks&quot; unless you&#x27;re running on server grade CPUs (contributing to cost vs power vs density vs perf) you&#x27;re not going to have nearly enough PCIe lanes to get very far. Even P2P over PCIe requires a hack geohot developed[0] and needless to say that&#x27;s umm, less than confidence inspiring for what you would lay out ($$$) in terms of hardware, space, cooling, and power. The lack of ECC is a real issue as well.<p>- Form factor. Remember PCIe lanes, etc? The RTX 4090 is a ~three slot beast when using air cooling and needless to say rigging up something like the dual slot water cooled 4090s I have at scale is another challenge altogether... How are people going to wire this up? What do the enclosures&#x2F;racks&#x2F;etc look like? This isn&#x27;t like crypto mining where cheap 1x PCIe risers can be used without dramatically limiting performance to the point of useless.<p>- Performance. As grandparent comment noted 4090s are not designed for this workload. In typical usage for training I see them as 10-20% faster than an RTX 3090 at much higher cost. Compared to my H100 with SXM4 it&#x27;s ridiculously slow.<p>- Market segmentation. Nvidia really knows what they&#x27;re doing here... There are all kinds of limitations you run into with how the hardware is designed (like Tensor Core performance for inference especially).<p>- Issues at scale. Look at the Meta post - their biggest issues are things that are dramatically worse with consumer cards like the RTX 4090, especially when you&#x27;re running with some kind of goofy PCIe cabling issue (like risers).<p>- Power. No matter what power limiting you employ an RTX 4090 is pretty bad for power&#x2F;performance ratio. The card isn&#x27;t fundamentally designed for these tasks - it&#x27;s designed to run screaming for a few hours a day so gamers can push as many FPS at high res as possible. Training, inference, etc is a different beast and the performance vs power ratio for these tasks is terrible compared to A&#x2F;H100. Now lets talk about the physical cabling, PSU, etc issues. Yes miners had hacks for this as well but it&#x27;s yet another issue.<p>- Fan design. There isn&#x27;t a single &quot;blower&quot; style RTX 4090 on the market. There was a dual-slot RTX 3090 at one point (I have a bunch of them) but Nvidia made Gigabyte pull them from the market because people were using them for this. Figuring out some kind of air-cooling setup with the fan and cooling design of the available RTX 4090 cards sounds like a complete nightmare...<p>- Licensing issues. Again, laying out the $$$ for this with a deployment that almost certainly violates the Nvidia EULA is a risky investment.<p>Three RTX 4090s (at 9 slots) to get &quot;only&quot; 72GB of VRAM, talking over PCIe, using 48 PCIe lanes, multi-node over sloooow ethernet (hitting CPU - slower and yet more power), using what likely ends up at ~900 watts (power limited) for significantly reduced throughput and less VRAM is ridiculous. Scaling the kind of ethernet you need for this (100 gig) comes at a very high per-port cost and due to all of these issues the performance would still be terrible.<p>I&#x27;m all for creativity but deploying &quot;racks&quot; of 4090s for AI tasks is (frankly) flat-out stupid.<p>[0] - <a href="https:&#x2F;&#x2F;github.com&#x2F;tinygrad&#x2F;open-gpu-kernel-modules">https:&#x2F;&#x2F;github.com&#x2F;tinygrad&#x2F;open-gpu-kernel-modules</a></div><br/></div></div></div></div></div></div></div></div><div id="40665944" class="c"><input type="checkbox" id="c-40665944" checked=""/><div class="controls bullet"><span class="by">guardiang</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665016">prev</a><span>|</span><a href="#40666360">next</a><span>|</span><label class="collapse" for="c-40665944">[-]</label><label class="expand" for="c-40665944">[1 more]</label></div><br/><div class="children"><div class="content">Google is old like MetLife, relative to each&#x27;s respective industry. Both are carrying too much baggage and are top heavy. As a result, I personally don&#x27;t think Google will be able to keep pace with OpenAI in the long run.</div><br/></div></div><div id="40666360" class="c"><input type="checkbox" id="c-40666360" checked=""/><div class="controls bullet"><span class="by">jatins</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665944">prev</a><span>|</span><a href="#40665122">next</a><span>|</span><label class="collapse" for="c-40666360">[-]</label><label class="expand" for="c-40666360">[1 more]</label></div><br/><div class="children"><div class="content">this was the same argument that was presented a decade ago on why Google was supposed to win the cloud because their internal infra was miles ahead of Amazon and Microsoft.<p>Yet here we are. Will the consumer video cards get cheaper and better faster or will Google&#x27;s directors&#x27; infighting stop first?</div><br/></div></div><div id="40665122" class="c"><input type="checkbox" id="c-40665122" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40666360">prev</a><span>|</span><a href="#40665193">next</a><span>|</span><label class="collapse" for="c-40665122">[-]</label><label class="expand" for="c-40665122">[5 more]</label></div><br/><div class="children"><div class="content">The only thing that can stop Google is Google.  Somehow every bet that isn&#x27;t Search doesn&#x27;t pan out.  And inexplicably, they&#x27;re working hard to kill Search now.  As a shareholder, I hope they succeed.  But I am more pessimistic about it than you.</div><br/><div id="40665705" class="c"><input type="checkbox" id="c-40665705" checked=""/><div class="controls bullet"><span class="by">yellow_postit</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665122">parent</a><span>|</span><a href="#40665250">next</a><span>|</span><label class="collapse" for="c-40665705">[-]</label><label class="expand" for="c-40665705">[2 more]</label></div><br/><div class="children"><div class="content">And they missed multiple waves of effectively building on their own in house research.</div><br/></div></div></div></div><div id="40665193" class="c"><input type="checkbox" id="c-40665193" checked=""/><div class="controls bullet"><span class="by">throwaway920102</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665122">prev</a><span>|</span><a href="#40665068">next</a><span>|</span><label class="collapse" for="c-40665193">[-]</label><label class="expand" for="c-40665193">[1 more]</label></div><br/><div class="children"><div class="content">What can stop Google is building the wrong thing, or being so scared to launch anything that they smother their own fledgling products before they are born or before they can mature. Their product and finance and accounting teams should be tossed.</div><br/></div></div><div id="40665068" class="c"><input type="checkbox" id="c-40665068" checked=""/><div class="controls bullet"><span class="by">ai4ever</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665193">prev</a><span>|</span><a href="#40665233">next</a><span>|</span><label class="collapse" for="c-40665068">[-]</label><label class="expand" for="c-40665068">[1 more]</label></div><br/><div class="children"><div class="content">here is an older take on this same topic..<p><a href="https:&#x2F;&#x2F;www.yitay.net&#x2F;blog&#x2F;training-great-llms-entirely-from-ground-zero-in-the-wilderness" rel="nofollow">https:&#x2F;&#x2F;www.yitay.net&#x2F;blog&#x2F;training-great-llms-entirely-from...</a><p>GPU vs TPU, and good software managing large clusters of them  across all sorts of failure.<p>the funny bit from the above article is the incident when someone forgot about a training job at google, and month later had the model fully trained without an alert of any kind. &quot;outrageously good infra&quot;</div><br/></div></div><div id="40665233" class="c"><input type="checkbox" id="c-40665233" checked=""/><div class="controls bullet"><span class="by">r_hanz</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665068">prev</a><span>|</span><a href="#40665042">next</a><span>|</span><label class="collapse" for="c-40665233">[-]</label><label class="expand" for="c-40665233">[2 more]</label></div><br/><div class="children"><div class="content">Much the same way you can have all the best gear and still fail - Google’s primary strength seems to be the DeepMind group. I’m not affiliated with Google, but IMHO the reason they will slowly die is because their engineering culture has taken a backseat due to their broken hiring practices.<p>Bad hiring practices aren’t exclusive to them, but from all accounts it seems like their internal focus is on optimizing ad revenue over everything else. I could be wrong or misinformed, but it seems to me like they are playing the finite game in the AI space (DeepMind group aside) while FAIR are playing the infinite game.<p>*meanwhile MSFT are simply trying to buy their way to relevance (e.g. OpenAI investments, etc) and carve out future revenues (Recall) and Jobs-less Apple is building their trademark walled-garden (AppleIntelligence?). Although the use of unified memory in Apple silicon poses some interesting possibilities for enabling the use of sizable models on consumer hardware.<p>Overall it seems like “big-tech” is by-and-large uninspired and asleep at the wheel save specific teams like those led by Lecun, Hassabis, etc. not sure where that leaves OpenAI now that Karpathy is gone.</div><br/><div id="40665771" class="c"><input type="checkbox" id="c-40665771" checked=""/><div class="controls bullet"><span class="by">VirusNewbie</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665233">parent</a><span>|</span><a href="#40665042">next</a><span>|</span><label class="collapse" for="c-40665771">[-]</label><label class="expand" for="c-40665771">[1 more]</label></div><br/><div class="children"><div class="content">&gt;ecause their engineering culture has taken a backseat due to their broken hiring practices.<p>What company do you think has better hiring practices, and subsequently a higher talent pool?  Meta is pretty similar to Google&#x27;s (though with an emphasis on speed over creativity).  Microsoft is certainly worse at hiring than the two aforementioned...</div><br/></div></div></div></div><div id="40665042" class="c"><input type="checkbox" id="c-40665042" checked=""/><div class="controls bullet"><span class="by">rapsey</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665233">prev</a><span>|</span><a href="#40665536">next</a><span>|</span><label class="collapse" for="c-40665042">[-]</label><label class="expand" for="c-40665042">[2 more]</label></div><br/><div class="children"><div class="content">Their work on folding and ai could very well be a business worth in the hundreds of billions and they know it as well as many other bets.<p>Wheres others are playing the llm race to the bottom.</div><br/><div id="40665556" class="c"><input type="checkbox" id="c-40665556" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#40664978">root</a><span>|</span><a href="#40665042">parent</a><span>|</span><a href="#40665536">next</a><span>|</span><label class="collapse" for="c-40665556">[-]</label><label class="expand" for="c-40665556">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Their work on folding and ai could very well be a business worth in the hundreds of billions and they know it as well as many other bets.<p>And we&#x27;ll be writing case studies of how they squandered billions of R&amp;D to help found other companies (kinda like Xerox Parc)<p>Almost every interesting paper after transformers has had it&#x27;s authors leave to commercialize their own companies.</div><br/></div></div></div></div><div id="40665536" class="c"><input type="checkbox" id="c-40665536" checked=""/><div class="controls bullet"><span class="by">htrp</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665042">prev</a><span>|</span><a href="#40665096">next</a><span>|</span><label class="collapse" for="c-40665536">[-]</label><label class="expand" for="c-40665536">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Literally the only thing that can stop Google now is the fact they keep bringing Microsoft and Oracle flunkies into leadership positions.<p>You mean the thing that&#x27;s already stopped them? 
If they had seriously invested into the TPU ecosystem in 2015, they would already have &quot;won&quot; AI.</div><br/></div></div><div id="40666645" class="c"><input type="checkbox" id="c-40666645" checked=""/><div class="controls bullet"><span class="by">checkyoursudo</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40665096">prev</a><span>|</span><a href="#40665427">next</a><span>|</span><label class="collapse" for="c-40666645">[-]</label><label class="expand" for="c-40666645">[1 more]</label></div><br/><div class="children"><div class="content">What would any company as &quot;the long term AI winner&quot; look like? What would it mean to be the winner in this context?</div><br/></div></div><div id="40665427" class="c"><input type="checkbox" id="c-40665427" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#40664978">parent</a><span>|</span><a href="#40666645">prev</a><span>|</span><a href="#40665450">next</a><span>|</span><label class="collapse" for="c-40665427">[-]</label><label class="expand" for="c-40665427">[1 more]</label></div><br/><div class="children"><div class="content">I wish I had your faith in Google’s ability to refrain from kneecapping their own perfectly fine product.</div><br/></div></div></div></div><div id="40665450" class="c"><input type="checkbox" id="c-40665450" checked=""/><div class="controls bullet"><span class="by">xvector</span><span>|</span><a href="#40664978">prev</a><span>|</span><a href="#40666657">next</a><span>|</span><label class="collapse" for="c-40665450">[-]</label><label class="expand" for="c-40665450">[3 more]</label></div><br/><div class="children"><div class="content">&gt; So we decided to build both: two 24k clusters, one with RoCE and another with InfiniBand. Our intent was to build and learn from the operational experience.<p>I love how they built two completely insane clusters just to learn. That&#x27;s badass.</div><br/><div id="40666719" class="c"><input type="checkbox" id="c-40666719" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#40665450">parent</a><span>|</span><a href="#40665471">next</a><span>|</span><label class="collapse" for="c-40666719">[-]</label><label class="expand" for="c-40666719">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not just to learn; an RoCE ethernet cluster with Aristas is way cheaper to build and maintain than a fancy InfiniBand cluster with Mellanox&#x2F;NVidia networking, so proving that the former is good enough at scale will eventually save Meta a huge amount of money. InfiniBand cards are much more expensive than ethernet because there&#x27;s few vendors, that have a quasi-monopoloy, and because overall far fewer of them are produced so there&#x27;s less economy of scale.</div><br/></div></div><div id="40665471" class="c"><input type="checkbox" id="c-40665471" checked=""/><div class="controls bullet"><span class="by">riku_iki</span><span>|</span><a href="#40665450">parent</a><span>|</span><a href="#40666719">prev</a><span>|</span><a href="#40666657">next</a><span>|</span><label class="collapse" for="c-40665471">[-]</label><label class="expand" for="c-40665471">[1 more]</label></div><br/><div class="children"><div class="content">More like Mark gave them 100k GPUs, and they are not sure what exactly to do with them..</div><br/></div></div></div></div><div id="40666657" class="c"><input type="checkbox" id="c-40666657" checked=""/><div class="controls bullet"><span class="by">radarsat1</span><span>|</span><a href="#40665450">prev</a><span>|</span><a href="#40665353">next</a><span>|</span><label class="collapse" for="c-40666657">[-]</label><label class="expand" for="c-40666657">[1 more]</label></div><br/><div class="children"><div class="content">Frustratingly little information. For example, I&#x27;m exceedingly curious how they deal with scheduling jobs on such a huge array of machines. The article:<p>&gt; Efficient scheduling helps ensure that our resources are used optimally. This involves sophisticated algorithms that can allocate resources based on the needs of different jobs and dynamic scheduling to adapt to changing workloads.<p>Wow thanks for that, captain obvious. So how do you do it?</div><br/></div></div><div id="40665353" class="c"><input type="checkbox" id="c-40665353" checked=""/><div class="controls bullet"><span class="by">kdot</span><span>|</span><a href="#40666657">prev</a><span>|</span><a href="#40664976">next</a><span>|</span><label class="collapse" for="c-40665353">[-]</label><label class="expand" for="c-40665353">[8 more]</label></div><br/><div class="children"><div class="content">How will Meta leverage LLMs at scale to drive revenue? It&#x27;s not clear.</div><br/><div id="40665609" class="c"><input type="checkbox" id="c-40665609" checked=""/><div class="controls bullet"><span class="by">threeseed</span><span>|</span><a href="#40665353">parent</a><span>|</span><a href="#40666060">next</a><span>|</span><label class="collapse" for="c-40665609">[-]</label><label class="expand" for="c-40665609">[1 more]</label></div><br/><div class="children"><div class="content">I still believe that a VR future is coming once the technology commoditises i.e. costs come down 10x and we have 3090 level GPUs in the headset. At that point we will have photo-realistic experiences like concerts etc that anyone can afford.<p>And at that point having a lot of LLM based avatars that can help &quot;fill in the space&quot; will be valuable.</div><br/></div></div><div id="40666060" class="c"><input type="checkbox" id="c-40666060" checked=""/><div class="controls bullet"><span class="by">sangnoir</span><span>|</span><a href="#40665353">parent</a><span>|</span><a href="#40665609">prev</a><span>|</span><a href="#40666449">next</a><span>|</span><label class="collapse" for="c-40666060">[-]</label><label class="expand" for="c-40666060">[2 more]</label></div><br/><div class="children"><div class="content">If only Meta had a way to monetize engagement with generative AI content in a way that scales with quantity of generated content.</div><br/><div id="40666280" class="c"><input type="checkbox" id="c-40666280" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#40665353">root</a><span>|</span><a href="#40666060">parent</a><span>|</span><a href="#40666449">next</a><span>|</span><label class="collapse" for="c-40666280">[-]</label><label class="expand" for="c-40666280">[1 more]</label></div><br/><div class="children"><div class="content">Revolutionary!</div><br/></div></div></div></div><div id="40666449" class="c"><input type="checkbox" id="c-40666449" checked=""/><div class="controls bullet"><span class="by">OsrsNeedsf2P</span><span>|</span><a href="#40665353">parent</a><span>|</span><a href="#40666060">prev</a><span>|</span><a href="#40665521">next</a><span>|</span><label class="collapse" for="c-40666449">[-]</label><label class="expand" for="c-40666449">[1 more]</label></div><br/><div class="children"><div class="content">LLMs aren&#x27;t a monetizable product themselves. For the foreseeable future, that will always be ads. LLMs (and VR) are just big bets on getting ahead of future technology.</div><br/></div></div><div id="40665521" class="c"><input type="checkbox" id="c-40665521" checked=""/><div class="controls bullet"><span class="by">dweekly</span><span>|</span><a href="#40665353">parent</a><span>|</span><a href="#40666449">prev</a><span>|</span><a href="#40666470">next</a><span>|</span><label class="collapse" for="c-40665521">[-]</label><label class="expand" for="c-40665521">[1 more]</label></div><br/><div class="children"><div class="content">Ask the AI to come up with a business model.</div><br/></div></div><div id="40666470" class="c"><input type="checkbox" id="c-40666470" checked=""/><div class="controls bullet"><span class="by">HDThoreaun</span><span>|</span><a href="#40665353">parent</a><span>|</span><a href="#40665521">prev</a><span>|</span><a href="#40664976">next</a><span>|</span><label class="collapse" for="c-40666470">[-]</label><label class="expand" for="c-40666470">[2 more]</label></div><br/><div class="children"><div class="content">I think the nearish term plan is chatbot customer assistants on whatsapp. Doesnt seem like theyre that close to releasing them but who knows</div><br/><div id="40667169" class="c"><input type="checkbox" id="c-40667169" checked=""/><div class="controls bullet"><span class="by">altdataseller</span><span>|</span><a href="#40665353">root</a><span>|</span><a href="#40666470">parent</a><span>|</span><a href="#40664976">next</a><span>|</span><label class="collapse" for="c-40667169">[-]</label><label class="expand" for="c-40667169">[1 more]</label></div><br/><div class="children"><div class="content">At the end of the day, everything eventually comes down to chatbots</div><br/></div></div></div></div></div></div><div id="40664976" class="c"><input type="checkbox" id="c-40664976" checked=""/><div class="controls bullet"><span class="by">whalesalad</span><span>|</span><a href="#40665353">prev</a><span>|</span><a href="#40665237">next</a><span>|</span><label class="collapse" for="c-40664976">[-]</label><label class="expand" for="c-40664976">[3 more]</label></div><br/><div class="children"><div class="content">interesting that their domain is still engineering.fb.com</div><br/><div id="40665397" class="c"><input type="checkbox" id="c-40665397" checked=""/><div class="controls bullet"><span class="by">samspenc</span><span>|</span><a href="#40664976">parent</a><span>|</span><a href="#40665237">next</a><span>|</span><label class="collapse" for="c-40665397">[-]</label><label class="expand" for="c-40665397">[2 more]</label></div><br/><div class="children"><div class="content">I think fb.com is their internal domain and they never really bothered to change it, I think employees used to have a @fb.com e-mail, at least this was true a few years ago, not sure if that has changed.</div><br/><div id="40665480" class="c"><input type="checkbox" id="c-40665480" checked=""/><div class="controls bullet"><span class="by">dnissley</span><span>|</span><a href="#40664976">root</a><span>|</span><a href="#40665397">parent</a><span>|</span><a href="#40665237">next</a><span>|</span><label class="collapse" for="c-40665480">[-]</label><label class="expand" for="c-40665480">[1 more]</label></div><br/><div class="children"><div class="content">Emails switched to @meta.com in 2022.</div><br/></div></div></div></div></div></div><div id="40664941" class="c"><input type="checkbox" id="c-40664941" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#40665237">prev</a><span>|</span><a href="#40665435">next</a><span>|</span><label class="collapse" for="c-40664941">[-]</label><label class="expand" for="c-40664941">[2 more]</label></div><br/><div class="children"><div class="content">Random q, I wonder if gloo is used in these systems? <a href="https:&#x2F;&#x2F;github.com&#x2F;facebookincubator&#x2F;gloo">https:&#x2F;&#x2F;github.com&#x2F;facebookincubator&#x2F;gloo</a><p>RDMA and GPUDirect capable. Coordinates over MPI or (hi)redia.</div><br/><div id="40665305" class="c"><input type="checkbox" id="c-40665305" checked=""/><div class="controls bullet"><span class="by">runeblaze</span><span>|</span><a href="#40664941">parent</a><span>|</span><a href="#40665435">next</a><span>|</span><label class="collapse" for="c-40665305">[-]</label><label class="expand" for="c-40665305">[1 more]</label></div><br/><div class="children"><div class="content">̶I̶I̶R̶C̶ ̶g̶l̶o̶o̶ ̶i̶s̶ ̶C̶P̶U̶ ̶t̶e̶n̶s̶o̶r̶s̶ ̶o̶n̶l̶y̶ ̶s̶o̶ ̶l̶i̶k̶e̶l̶y̶ ̶n̶o̶t̶<p>Edit: I had a brain freeze or something... gloo is not CPU only but for whatever reason I don&#x27;t see it outside of CPU-comms</div><br/></div></div></div></div><div id="40665435" class="c"><input type="checkbox" id="c-40665435" checked=""/><div class="controls bullet"><span class="by">idkdotcom</span><span>|</span><a href="#40664941">prev</a><span>|</span><a href="#40665161">next</a><span>|</span><label class="collapse" for="c-40665435">[-]</label><label class="expand" for="c-40665435">[3 more]</label></div><br/><div class="children"><div class="content">These seem classic challenges with running distributed systems loads that are not specific to training LLMs.<p>Anyone of the super computers listed here <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;TOP500" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;TOP500</a> suffers from the same issues.<p>Think about it. While the national labs use these systems to model serious stuff -such as climate or nuclear weapons- Meta uses them to train LLMs. What a joke, honestly!</div><br/><div id="40666572" class="c"><input type="checkbox" id="c-40666572" checked=""/><div class="controls bullet"><span class="by">whiplash451</span><span>|</span><a href="#40665435">parent</a><span>|</span><a href="#40665161">next</a><span>|</span><label class="collapse" for="c-40666572">[-]</label><label class="expand" for="c-40666572">[2 more]</label></div><br/><div class="children"><div class="content">A lot of serious things look like a toy or a joke at first.</div><br/></div></div></div></div><div id="40665611" class="c"><input type="checkbox" id="c-40665611" checked=""/><div class="controls bullet"><span class="by">koolala</span><span>|</span><a href="#40665018">prev</a><span>|</span><label class="collapse" for="c-40665611">[-]</label><label class="expand" for="c-40665611">[1 more]</label></div><br/><div class="children"><div class="content">what a title...</div><br/></div></div></div></div></div></div></div></body></html>