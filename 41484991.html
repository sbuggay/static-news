<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1725872472874" as="style"/><link rel="stylesheet" href="styles.css?v=1725872472874"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://dl.acm.org/doi/10.1145/3589334.3645323">QUIC is not quick enough over fast internet</a> <span class="domain">(<a href="https://dl.acm.org">dl.acm.org</a>)</span></div><div class="subtext"><span>Shank</span> | <span>128 comments</span></div><br/><div><div id="41485526" class="c"><input type="checkbox" id="c-41485526" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41486655">next</a><span>|</span><label class="collapse" for="c-41485526">[-]</label><label class="expand" for="c-41485526">[31 more]</label></div><br/><div class="children"><div class="content">There are a number of concrete problems:<p>- syscall interfaces are a mess, the primitive APIs are too slow for regular sized packets (~1500 bytes), the overhead is too high. GSO helps but it’s a horrible API, and it’s been buggy even lately due to complexity and poor code standards.<p>- the syscall costs got even higher with spectre mitigation - and this story likely isn’t over. We need a replacement for the BSD sockets &#x2F; POSIX APIs they’re terrible this decade. Yes, uring is fancy, but there’s a tutorial level API middle ground possible that should be safe and 10x less overhead without resorting to uring level complexity.<p>- system udp buffers are far too small by default - they’re much much smaller than their tcp siblings, essentially no one but experts have been using them, and experts just retune stuff.<p>- udp stack optimizations are possible (such as possible route lookup reuse without connect(2)), gso demonstrates this, though as noted above gso is highly fallible, quite expensive itself, and the design is wholly unnecessarily intricate for what we need, particularly as we want to do this safely from unprivileged userspace.<p>- several optimizations currently available only work at low&#x2F;mid-scale, such as connect binding to (potentially) avoid route lookups &#x2F; GSO only being applicable on a socket without high peer-competition (competing peers result in short offload chains due to single-peer constraints, eroding the overhead wins).<p>Despite all this, you can implement GSO and get substantial performance improvements, we (tailscale) have on Linux. There will be a need at some point for platforms to increase platform side buffer sizes for lower end systems, high load&#x2F;concurrency, bdp and so on, but buffers and congestion control are a high complex and sometimes quite sensitive topic - nonetheless, when you have many applications doing this (presumed future state), there will be a need.</div><br/><div id="41485597" class="c"><input type="checkbox" id="c-41485597" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41485526">parent</a><span>|</span><a href="#41486408">next</a><span>|</span><label class="collapse" for="c-41485597">[-]</label><label class="expand" for="c-41485597">[16 more]</label></div><br/><div class="children"><div class="content">&gt; Yes, uring is fancy, but there’s a tutorial level API middle ground possible that should be safe and 10x less overhead without resorting to uring level complexity.<p>I don&#x27;t think io_uring is as complex as its reputation suggests. I don&#x27;t think we need a substantially simpler <i>low-level</i> API; I think we need more high-level APIs built on top of io_uring. (That will also help with portability: we need APIs that can be most efficiently implemented atop io_uring but that work on non-Linux systems.)</div><br/><div id="41485621" class="c"><input type="checkbox" id="c-41485621" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485597">parent</a><span>|</span><a href="#41485673">next</a><span>|</span><label class="collapse" for="c-41485621">[-]</label><label class="expand" for="c-41485621">[14 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t think io_uring is as complex as its reputation suggests.<p>uring is extremely problematic to integrate into many common application &#x2F; language runtimes and it has been demonstrably difficult to integrate into linux safely and correctly as well, with a continual stream of bugs, security and policy control issues.<p>in principle a shared memory queue is a reasonable basis for improving the IO cost between applications and IO stacks such as the network or filesystem stacks, but this isn&#x27;t easy to do well, cf. uring bugs and binder bugs.</div><br/><div id="41486280" class="c"><input type="checkbox" id="c-41486280" checked=""/><div class="controls bullet"><span class="by">arghwhat</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485621">parent</a><span>|</span><a href="#41485662">next</a><span>|</span><label class="collapse" for="c-41486280">[-]</label><label class="expand" for="c-41486280">[3 more]</label></div><br/><div class="children"><div class="content">Two things:<p>One, uring is not extremely problematic to integrate, as it can be chained into a conventional event loop if you want to, or can even be fit into a conventionally blocking design to get localized syscall benefits. That is, you do not need to convert to a fully uring event loop design, even if that would be superior - and it can usually be kept entirely within a (slightly modified) event loop abstraction. The reason it has not yet been implemented is just priority - most stuff <i>isn&#x27;t</i> bottlenecked on IOPS.<p>Two, yes you could have e middle-ground. I assume the syscall overhead you call out is the need to send UDP packets one at a time through sendmsg&#x2F;sendto, rather than doing one big write for several packets worth of data on TCP. An API that allowed you to provide a chain of messages, like sendmsg takes an iovec for data, is possible. But it&#x27;s also possible to do this already as a tiny blocking wrapper around io_uring, saving you new syscalls.</div><br/><div id="41486528" class="c"><input type="checkbox" id="c-41486528" checked=""/><div class="controls bullet"><span class="by">Veserv</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41486280">parent</a><span>|</span><a href="#41485662">next</a><span>|</span><label class="collapse" for="c-41486528">[-]</label><label class="expand" for="c-41486528">[2 more]</label></div><br/><div class="children"><div class="content">The system call to send multiple UDP packets in a single call has existed since Linux 3.0 over a decade ago[1]: sendmmsg().<p>[1] <a href="https:&#x2F;&#x2F;man7.org&#x2F;linux&#x2F;man-pages&#x2F;man2&#x2F;sendmmsg.2.html" rel="nofollow">https:&#x2F;&#x2F;man7.org&#x2F;linux&#x2F;man-pages&#x2F;man2&#x2F;sendmmsg.2.html</a></div><br/><div id="41486549" class="c"><input type="checkbox" id="c-41486549" checked=""/><div class="controls bullet"><span class="by">arghwhat</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41486528">parent</a><span>|</span><a href="#41485662">next</a><span>|</span><label class="collapse" for="c-41486549">[-]</label><label class="expand" for="c-41486549">[1 more]</label></div><br/><div class="children"><div class="content">Ah nice, in that case OP&#x27;s point about syscall overhead is entirely moot. :)<p>That should really be in the `SEE ALSO` of `man 3 sendmsg`...</div><br/></div></div></div></div></div></div><div id="41485662" class="c"><input type="checkbox" id="c-41485662" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485621">parent</a><span>|</span><a href="#41486280">prev</a><span>|</span><a href="#41485685">next</a><span>|</span><label class="collapse" for="c-41485662">[-]</label><label class="expand" for="c-41485662">[8 more]</label></div><br/><div class="children"><div class="content">&gt; with a continual stream of bugs, security and policy control issues<p>This has not been true for a long time. There was an early design mistake that made it quite prone to these, but that mistake has been fixed. Unfortunately, the reputational damage will stick around for a while.</div><br/><div id="41485683" class="c"><input type="checkbox" id="c-41485683" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485662">parent</a><span>|</span><a href="#41485685">next</a><span>|</span><label class="collapse" for="c-41485683">[-]</label><label class="expand" for="c-41485683">[7 more]</label></div><br/><div class="children"><div class="content">13 CVEs so far this year afaik</div><br/><div id="41485707" class="c"><input type="checkbox" id="c-41485707" checked=""/><div class="controls bullet"><span class="by">bonzini</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485683">parent</a><span>|</span><a href="#41485685">next</a><span>|</span><label class="collapse" for="c-41485707">[-]</label><label class="expand" for="c-41485707">[6 more]</label></div><br/><div class="children"><div class="content">CVE numbers from the Linux CNA are bollocks.</div><br/><div id="41485721" class="c"><input type="checkbox" id="c-41485721" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485707">parent</a><span>|</span><a href="#41485780">next</a><span>|</span><label class="collapse" for="c-41485721">[-]</label><label class="expand" for="c-41485721">[4 more]</label></div><br/><div class="children"><div class="content">This conversation would be a good one to point them to to show that their policy is not just harmless point-proving, but in fact does cause harm.<p>For context, to the best of my knowledge the current approach of the Linux CNA is, in keeping with long-standing Linux security policy of &quot;every single fix <i>might</i> be a security fix&quot;, to assign CVEs regardless of whether something has any security impact or not.</div><br/><div id="41486444" class="c"><input type="checkbox" id="c-41486444" checked=""/><div class="controls bullet"><span class="by">kuschku</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485721">parent</a><span>|</span><a href="#41485801">next</a><span>|</span><label class="collapse" for="c-41486444">[-]</label><label class="expand" for="c-41486444">[1 more]</label></div><br/><div class="children"><div class="content">CVE assignment != security issue<p>CVE numbers are just a way to ensure everyone is talking about the same bug. Not every security issue has a CVE, not every CVE is a security issue.<p>Often, a regular bug turns out years later to have been a security issue, or a security issue turns out to have no security impact at all.<p>If you want a central authority to tell you what to think, just use CVSS instead of the binary &quot;does it have a CVE&quot; metric.</div><br/></div></div><div id="41485801" class="c"><input type="checkbox" id="c-41485801" checked=""/><div class="controls bullet"><span class="by">di4na</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485721">parent</a><span>|</span><a href="#41486444">prev</a><span>|</span><a href="#41485780">next</a><span>|</span><label class="collapse" for="c-41485801">[-]</label><label class="expand" for="c-41485801">[2 more]</label></div><br/><div class="children"><div class="content">I would not call it harm. The use of uring in higher level languages is definitely prone to errors, bugs and security problems</div><br/><div id="41485864" class="c"><input type="checkbox" id="c-41485864" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485801">parent</a><span>|</span><a href="#41485780">next</a><span>|</span><label class="collapse" for="c-41485864">[-]</label><label class="expand" for="c-41485864">[1 more]</label></div><br/><div class="children"><div class="content">See the context I added to that comment; this is not about security issues, it&#x27;s about the Linux CNA&#x27;s absurd approach to CVE assignment for things that aren&#x27;t CVEs.</div><br/></div></div></div></div></div></div><div id="41485780" class="c"><input type="checkbox" id="c-41485780" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485707">parent</a><span>|</span><a href="#41485721">prev</a><span>|</span><a href="#41485685">next</a><span>|</span><label class="collapse" for="c-41485780">[-]</label><label class="expand" for="c-41485780">[1 more]</label></div><br/><div class="children"><div class="content">this is a bit of a distraction, sure the leaks and some of the deadlocks are fairly uninteresting, but the toctou, overflows, uid race&#x2F;confusion and so on are real issues that shouldn&#x27;t be dismissed as if they don&#x27;t exist.</div><br/></div></div></div></div></div></div></div></div><div id="41485685" class="c"><input type="checkbox" id="c-41485685" checked=""/><div class="controls bullet"><span class="by">jeffparsons</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485621">parent</a><span>|</span><a href="#41485662">prev</a><span>|</span><a href="#41485673">next</a><span>|</span><label class="collapse" for="c-41485685">[-]</label><label class="expand" for="c-41485685">[2 more]</label></div><br/><div class="children"><div class="content">I find this surprising, given that my initial response to reading the iouring design was:<p>1. This is pretty clean and straightforward.
2. This is obviously what we need to decouple a bunch of things without the previous downsides.<p>What has made it so hard to integrate it into common language runtimes? Do you have examples of where there&#x27;s been an irreconcilable &quot;impedance mismatch&quot;?</div><br/><div id="41485755" class="c"><input type="checkbox" id="c-41485755" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485685">parent</a><span>|</span><a href="#41485673">next</a><span>|</span><label class="collapse" for="c-41485755">[-]</label><label class="expand" for="c-41485755">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;github.com&#x2F;tailscale&#x2F;tailscale&#x2F;pull&#x2F;2370">https:&#x2F;&#x2F;github.com&#x2F;tailscale&#x2F;tailscale&#x2F;pull&#x2F;2370</a> was a practical drive toward this, will not proceed on this path.<p>much more approachable, boats has written about challenges integrating in rust: <a href="https:&#x2F;&#x2F;without.boats&#x2F;tags&#x2F;io-uring&#x2F;" rel="nofollow">https:&#x2F;&#x2F;without.boats&#x2F;tags&#x2F;io-uring&#x2F;</a><p>in the most general form: you need a fairly &quot;loose&quot; memory model to integrate the &quot;best&quot; (performance wise) parts, and the &quot;best&quot; (ease of use&#x2F;forward looking safety) way to integrate requires C library linkage. This is troublesome in most GC languages, and many managed runtimes. There&#x27;s also the issue that uring being non-portable means that the things it suggests you must do (such as say pinning a buffer pool and making APIs like read not immediate caller allocates) requires a substantially separate API for this platform than for others, or at least substantial reworks over all the existing POSIX modeled APIs - thus back to what I said originally, we need a replacement for POSIX &amp; BSD here, broadly applied.</div><br/></div></div></div></div></div></div><div id="41485673" class="c"><input type="checkbox" id="c-41485673" checked=""/><div class="controls bullet"><span class="by">lukeh</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485597">parent</a><span>|</span><a href="#41485621">prev</a><span>|</span><a href="#41486408">next</a><span>|</span><label class="collapse" for="c-41485673">[-]</label><label class="expand" for="c-41485673">[1 more]</label></div><br/><div class="children"><div class="content">async&#x2F;await io_uwring wrappers for languages such as Swift [1] and Rust [2] [3] can improve usability considerably. I&#x27;m not super familiar with the Rust wrappers but, I&#x27;ve been using IORingSwift for socket, file and serial I&#x2F;O for some time now.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;PADL&#x2F;IORingSwift">https:&#x2F;&#x2F;github.com&#x2F;PADL&#x2F;IORingSwift</a>
[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;bytedance&#x2F;monoio">https:&#x2F;&#x2F;github.com&#x2F;bytedance&#x2F;monoio</a>
[3] <a href="https:&#x2F;&#x2F;github.com&#x2F;tokio-rs&#x2F;tokio-uring">https:&#x2F;&#x2F;github.com&#x2F;tokio-rs&#x2F;tokio-uring</a></div><br/></div></div></div></div><div id="41486408" class="c"><input type="checkbox" id="c-41486408" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41485526">parent</a><span>|</span><a href="#41485597">prev</a><span>|</span><a href="#41485529">next</a><span>|</span><label class="collapse" for="c-41486408">[-]</label><label class="expand" for="c-41486408">[2 more]</label></div><br/><div class="children"><div class="content">Seems to me that the real problem is the 1500 byte MTU that hasn&#x27;t increased in practice in over <i>40 years</i>.</div><br/><div id="41486433" class="c"><input type="checkbox" id="c-41486433" checked=""/><div class="controls bullet"><span class="by">asmor</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41486408">parent</a><span>|</span><a href="#41485529">next</a><span>|</span><label class="collapse" for="c-41486433">[-]</label><label class="expand" for="c-41486433">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s on the list that right after we all migrate to IPv6.</div><br/></div></div></div></div><div id="41485529" class="c"><input type="checkbox" id="c-41485529" checked=""/><div class="controls bullet"><span class="by">SomaticPirate</span><span>|</span><a href="#41485526">parent</a><span>|</span><a href="#41486408">prev</a><span>|</span><a href="#41485580">next</a><span>|</span><label class="collapse" for="c-41485529">[-]</label><label class="expand" for="c-41485529">[8 more]</label></div><br/><div class="children"><div class="content">What is GSO?</div><br/><div id="41486607" class="c"><input type="checkbox" id="c-41486607" checked=""/><div class="controls bullet"><span class="by">USiBqidmOOkAqRb</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485529">parent</a><span>|</span><a href="#41485562">next</a><span>|</span><label class="collapse" for="c-41486607">[-]</label><label class="expand" for="c-41486607">[1 more]</label></div><br/><div class="children"><div class="content">Shipping? Government services online? Piedmont airport? Alcoholics anonymous? Obviously not.<p><i>Please</i> introduce your initialisms, if it&#x27;s not guaranteed that first result in a search will be correct.</div><br/></div></div><div id="41485562" class="c"><input type="checkbox" id="c-41485562" checked=""/><div class="controls bullet"><span class="by">jesperwe</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485529">parent</a><span>|</span><a href="#41486607">prev</a><span>|</span><a href="#41485556">next</a><span>|</span><label class="collapse" for="c-41485562">[-]</label><label class="expand" for="c-41485562">[2 more]</label></div><br/><div class="children"><div class="content">Generic Segmentation Offload<p>&quot;GSO gains performance by enabling upper layer applications to process a smaller number of large packets (e.g. MTU size of 64KB), instead of processing higher numbers of small packets (e.g. MTU size of 1500B), thus reducing per-packet overhead.&quot;</div><br/><div id="41486540" class="c"><input type="checkbox" id="c-41486540" checked=""/><div class="controls bullet"><span class="by">underdeserver</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485562">parent</a><span>|</span><a href="#41485556">next</a><span>|</span><label class="collapse" for="c-41486540">[-]</label><label class="expand" for="c-41486540">[1 more]</label></div><br/><div class="children"><div class="content">This is more the result.<p>Generally today an Ethernet frame, which is the basic atomic unit of information over the wire, is limited to 1500 bytes (the MTU, or Maximum Transmission Unit).<p>If you want to send more - the IP layer allows for 64k bytes per IP packet - you need to split the IP packet into multiple (64k &#x2F; 1500 plus some header overhead) frames. This is called segmentation.<p>Before GSO the kernel would do that which takes buffering and CPU time to assemble the frame headers. GSO moves this to the ethernet hardware, which is essentially doing the same thing only hardware accelerated and without taking up a CPU core.</div><br/></div></div></div></div><div id="41485556" class="c"><input type="checkbox" id="c-41485556" checked=""/><div class="controls bullet"><span class="by">throwaway8481</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485529">parent</a><span>|</span><a href="#41485562">prev</a><span>|</span><a href="#41485557">next</a><span>|</span><label class="collapse" for="c-41485556">[-]</label><label class="expand" for="c-41485556">[1 more]</label></div><br/><div class="children"><div class="content">Generic Segmentation Offload<p><a href="https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;latest&#x2F;networking&#x2F;segmentation-offloads.html" rel="nofollow">https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;latest&#x2F;networking&#x2F;segmentati...</a></div><br/></div></div><div id="41485557" class="c"><input type="checkbox" id="c-41485557" checked=""/><div class="controls bullet"><span class="by">chaboud</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485529">parent</a><span>|</span><a href="#41485556">prev</a><span>|</span><a href="#41485555">next</a><span>|</span><label class="collapse" for="c-41485557">[-]</label><label class="expand" for="c-41485557">[2 more]</label></div><br/><div class="children"><div class="content">Likely Generic Segmentation Offload (if memory serves), which is a generalization of TCP segmentation offload.<p>Basically (hyper simple), the kernel can lump stuff together when working with the network interface, which cuts down on ultra slow hardware interactions.</div><br/><div id="41485576" class="c"><input type="checkbox" id="c-41485576" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485557">parent</a><span>|</span><a href="#41485555">next</a><span>|</span><label class="collapse" for="c-41485576">[-]</label><label class="expand" for="c-41485576">[1 more]</label></div><br/><div class="children"><div class="content">it was originally for the hardware, but it&#x27;s also valuable on the software side as the cost of syscalls is far too high for packet sized transactions</div><br/></div></div></div></div><div id="41485555" class="c"><input type="checkbox" id="c-41485555" checked=""/><div class="controls bullet"><span class="by">thorncorona</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485529">parent</a><span>|</span><a href="#41485557">prev</a><span>|</span><a href="#41485580">next</a><span>|</span><label class="collapse" for="c-41485555">[-]</label><label class="expand" for="c-41485555">[1 more]</label></div><br/><div class="children"><div class="content">presumably generic segmentation offloading</div><br/></div></div></div></div><div id="41485580" class="c"><input type="checkbox" id="c-41485580" checked=""/><div class="controls bullet"><span class="by">cookiengineer</span><span>|</span><a href="#41485526">parent</a><span>|</span><a href="#41485529">prev</a><span>|</span><a href="#41485992">next</a><span>|</span><label class="collapse" for="c-41485580">[-]</label><label class="expand" for="c-41485580">[3 more]</label></div><br/><div class="children"><div class="content">Say what you want but I bet we&#x27;ll see lots of eBPF modules being loaded in the future for the very reason you&#x27;re describing. An ebpf quic module? Why not!<p>And that scares me, because there&#x27;s not a single tool that has this on its radar for malware detection&#x2F;prevention.</div><br/><div id="41485605" class="c"><input type="checkbox" id="c-41485605" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485580">parent</a><span>|</span><a href="#41485992">next</a><span>|</span><label class="collapse" for="c-41485605">[-]</label><label class="expand" for="c-41485605">[2 more]</label></div><br/><div class="children"><div class="content">we can consider ebpf &quot;a solution&quot; when there&#x27;s even a remote chance you&#x27;ll be able to do it from an unentitled ios app. somewhat hyperbole, but the point is, this problem is a problem for userspace client applications, and bpf isn&#x27;t a particularly &quot;good&quot; solution for servers either, it&#x27;s high cost of authorship for a problem that is easily solvable with a better API to the network stack.</div><br/><div id="41486604" class="c"><input type="checkbox" id="c-41486604" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#41485526">root</a><span>|</span><a href="#41485605">parent</a><span>|</span><a href="#41485992">next</a><span>|</span><label class="collapse" for="c-41486604">[-]</label><label class="expand" for="c-41486604">[1 more]</label></div><br/><div class="children"><div class="content">ebpf is linux technology, you will never be able to do it from iOS.</div><br/></div></div></div></div></div></div><div id="41485992" class="c"><input type="checkbox" id="c-41485992" checked=""/><div class="controls bullet"><span class="by">quotemstr</span><span>|</span><a href="#41485526">parent</a><span>|</span><a href="#41485580">prev</a><span>|</span><a href="#41486655">next</a><span>|</span><label class="collapse" for="c-41485992">[-]</label><label class="expand" for="c-41485992">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Yes, uring is fancy, but there’s a tutorial level API middle ground possible that should be safe and 10x less overhead without resorting to uring level complexity.<p>And the kernel has no business providing this middle-layer API. Why should it? Let people grab whatever they need from the ecosystem. Networking should be like Vulkan: it should have a high-performance, flexible API at the systems level with being &quot;easy to use&quot; a non-goal --- and higher-level facilities on top.</div><br/></div></div></div></div><div id="41486655" class="c"><input type="checkbox" id="c-41486655" checked=""/><div class="controls bullet"><span class="by">crashingintoyou</span><span>|</span><a href="#41485526">prev</a><span>|</span><a href="#41485054">next</a><span>|</span><label class="collapse" for="c-41486655">[-]</label><label class="expand" for="c-41486655">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t have access to the published version but draft at <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.09423" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.09423</a> mentions ping RTT at 0.23ms.<p>As someone frequently at 150ms+ latency for a lot of websites (and semi-frequently 300ms+ for non-geo-distributed websites), in practice with the latency QUIC is easily the best for throughput, HTTP&#x2F;1.1 with a decent number of parallel connections is a not-that-distant second, and in a remote third is HTTP&#x2F;2 due to head-of-line-blocking issues if&#x2F;when a packet goes missing.</div><br/></div></div><div id="41485054" class="c"><input type="checkbox" id="c-41485054" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41486655">prev</a><span>|</span><a href="#41485176">next</a><span>|</span><label class="collapse" for="c-41485054">[-]</label><label class="expand" for="c-41485054">[25 more]</label></div><br/><div class="children"><div class="content">In the early days of QUIC, many people pointed out that the UDP stack has had far far less optimization put into it than the TCP stack. Sure enough, some of the issues identified here arise because the UDP stack isn&#x27;t doing things that it <i>could</i> do but that nobody has been motivated to make it do, such as UDP generic receive offload. Papers like this are very likely to lead to optimizations both obvious and subtle.</div><br/><div id="41485162" class="c"><input type="checkbox" id="c-41485162" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#41485054">parent</a><span>|</span><a href="#41485236">next</a><span>|</span><label class="collapse" for="c-41485162">[-]</label><label class="expand" for="c-41485162">[19 more]</label></div><br/><div class="children"><div class="content">What is UDP offload going to <i>do</i>? UDP barely does anything but queue and copy.<p>Linux scheduling from packet-received to thread has control is not real-time, and if the CPUs are busy, may be rather slow. That&#x27;s probably part of the bottleneck.<p>The embarrassing thing is that QUIC, even in Google&#x27;s own benchmarks, only improved performance by about 10%. The added complexity probably isn&#x27;t worth the trouble. However, it gave Google control of more of the stack, which may have been the real motivation.</div><br/><div id="41485342" class="c"><input type="checkbox" id="c-41485342" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485162">parent</a><span>|</span><a href="#41485543">next</a><span>|</span><label class="collapse" for="c-41485342">[-]</label><label class="expand" for="c-41485342">[10 more]</label></div><br/><div class="children"><div class="content">Last I looked (several months ago), Linux&#x27;s UDP stack did not seemed well tuned in its memory management accounting.<p>For background, the mental model of what receiving network data looks like in userspace is almost completely backwards compared to how general-purpose kernel network receive actually works.  User code thinks it allocates a buffer (per-socket or perhaps a fancier io_uring scheme), then receives packets into that buffer, then processes them.<p>The kernel is the other way around.  The kernel allocates buffers and feeds pointers to those buffers to the NIC.  The NIC receives packets and DMAs them into the buffers, then tells the kernel.  But the NIC and the kernel have <i>absolutely no concept</i> of which socket those buffers belong to until <i>after</i> they are DMAed into the buffers.  So the kernel cannot possibly map received packets to the actual recipient&#x27;s memory.  So instead, after identifying who owns a received packet, the kernel retroactively charges the recipient for the memory.  This happens on a per-packet basis, it involves per-socket <i>and</i> cgroup accounting, and there is no support for having a socket &quot;pre-allocate&quot; this memory in advance of receiving a packet.  So the accounting is gnarly, involves atomic operations, and seems quite unlikely to win any speed awards.  On a very cursory inspection, the TCP code seemed better tuned, and it possibly also won by generally handling more bytes per operation.<p>Keep in mind that the kernel <i>can&#x27;t</i> copy data to application memory synchronously -- the application memory might be paged out when a packet shows up.  So instead the whole charging dance above happens immediately when a packet is received, and the data is copied later on.<p>For quite a long time, I&#x27;ve thought it would be nifty if there was a NIC that kept received data in its own RAM and then allowed it to be efficiently DMAed to application memory when the application was ready for it.  In essence, a lot of the accounting and memory management logic could move out of the kernel into the NIC.  I&#x27;m not aware of anyone doing this.</div><br/><div id="41485525" class="c"><input type="checkbox" id="c-41485525" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485342">parent</a><span>|</span><a href="#41485565">next</a><span>|</span><label class="collapse" for="c-41485525">[-]</label><label class="expand" for="c-41485525">[3 more]</label></div><br/><div class="children"><div class="content">&gt; For quite a long time, I&#x27;ve thought it would be nifty if there was a NIC that kept received data in its own RAM and then allowed it to be efficiently DMAed to application memory when the application was ready for it.<p>I wonder if we could do a more advanced version of receive-packet steering that sufficiently identifies packets as <i>definitely</i> for a given process and DMAs them directly to that process&#x27;s pre-provided buffers for later notification? In particular, can we offload enough information to a smart NIC that it can identify where something should be DMAed to?</div><br/><div id="41486626" class="c"><input type="checkbox" id="c-41486626" checked=""/><div class="controls bullet"><span class="by">mgaunard</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485525">parent</a><span>|</span><a href="#41485767">next</a><span>|</span><label class="collapse" for="c-41486626">[-]</label><label class="expand" for="c-41486626">[1 more]</label></div><br/><div class="children"><div class="content">Most advanced NICs support flow steering, which makes the NIC write to different buffers depending on the target port.<p>In practice though, you only have a limited amount of these buffers, and it causes complications if multiple processes need to consume the same multicast.</div><br/></div></div><div id="41485767" class="c"><input type="checkbox" id="c-41485767" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485525">parent</a><span>|</span><a href="#41486626">prev</a><span>|</span><a href="#41485565">next</a><span>|</span><label class="collapse" for="c-41485767">[-]</label><label class="expand" for="c-41485767">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think the result would be compatible with the socket or io_uring API, but maybe io_uring could be extended a bit.  Basically the kernel would opportunistically program a “flow director” or similar rule to send packets to special rx queue, and that queue would point to (pinned) application memory.  Getting this to be compatible with iptables&#x2F;nftables would be a mess or maybe entirely impossible.<p>I’ve never seen the accelerated steering stuff work well in practice, sadly. The code is messy, the diagnostics are basically nonexistent, and it’s not clear to me that many drivers support it well.</div><br/></div></div></div></div><div id="41485565" class="c"><input type="checkbox" id="c-41485565" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485342">parent</a><span>|</span><a href="#41485525">prev</a><span>|</span><a href="#41485355">next</a><span>|</span><label class="collapse" for="c-41485565">[-]</label><label class="expand" for="c-41485565">[3 more]</label></div><br/><div class="children"><div class="content">Presuming that this is a server that has One (public) Job, couldn&#x27;t you:<p>1. dedicate a NIC to the application;<p>2. and have the userland app open a packet socket against the NIC, to drink from its firehose through MMIO against the kernel&#x27;s own NIC DMA buffer;<p>...all without involving the kernel TCP&#x2F;IP (or in this case, UDP&#x2F;IP) stack, and any of the accounting logic squirreled away in there?<p>(You <i>can</i> also throw in a BPF filter here, to drop everything except UDP packets with the expected specified ip:port — but if you&#x27;re already doing more packet validation at the app level, you may as well just take the whole firehose of packets and validate them for being targeted at the app at the same time that they&#x27;re validated for their L7 structure.)</div><br/><div id="41486546" class="c"><input type="checkbox" id="c-41486546" checked=""/><div class="controls bullet"><span class="by">SSLy</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485565">parent</a><span>|</span><a href="#41485746">next</a><span>|</span><label class="collapse" for="c-41486546">[-]</label><label class="expand" for="c-41486546">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>1. dedicate a NIC to the application;</i><p>you need to respond to ICMPs which have different proto&#x2F;header number than UDP or TCP.</div><br/></div></div><div id="41485746" class="c"><input type="checkbox" id="c-41485746" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485565">parent</a><span>|</span><a href="#41486546">prev</a><span>|</span><a href="#41485355">next</a><span>|</span><label class="collapse" for="c-41485746">[-]</label><label class="expand" for="c-41485746">[1 more]</label></div><br/><div class="children"><div class="content">I think DPDK does something like this. The NIC is programmed to aim the packets in question at a specific hardware receive queue, and that queue is entirely owned by a userspace program.<p>A lot of high end NICs support moderately complex receive queue selection rules.</div><br/></div></div></div></div><div id="41485355" class="c"><input type="checkbox" id="c-41485355" checked=""/><div class="controls bullet"><span class="by">fragmede</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485342">parent</a><span>|</span><a href="#41485565">prev</a><span>|</span><a href="#41485543">next</a><span>|</span><label class="collapse" for="c-41485355">[-]</label><label class="expand" for="c-41485355">[3 more]</label></div><br/><div class="children"><div class="content">RDMA is common for high performance applications but it doesn&#x27;t work over the Internet.</div><br/><div id="41485445" class="c"><input type="checkbox" id="c-41485445" checked=""/><div class="controls bullet"><span class="by">Danieru</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485355">parent</a><span>|</span><a href="#41485482">next</a><span>|</span><label class="collapse" for="c-41485445">[-]</label><label class="expand" for="c-41485445">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a good thing the NIC is connected over pcie then.</div><br/></div></div><div id="41485482" class="c"><input type="checkbox" id="c-41485482" checked=""/><div class="controls bullet"><span class="by">shaklee3</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485355">parent</a><span>|</span><a href="#41485445">prev</a><span>|</span><a href="#41485543">next</a><span>|</span><label class="collapse" for="c-41485482">[-]</label><label class="expand" for="c-41485482">[1 more]</label></div><br/><div class="children"><div class="content">You can do GPUdirect over the Internet without RDMA though.</div><br/></div></div></div></div></div></div><div id="41485543" class="c"><input type="checkbox" id="c-41485543" checked=""/><div class="controls bullet"><span class="by">raggi</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485162">parent</a><span>|</span><a href="#41485342">prev</a><span>|</span><a href="#41485341">next</a><span>|</span><label class="collapse" for="c-41485543">[-]</label><label class="expand" for="c-41485543">[1 more]</label></div><br/><div class="children"><div class="content">UDP offload gets you implicitly today:<p>- 64 packets per syscall, which is enough data to amortize the syscall overhead - a single packet is not.<p>- UDP offload optionally lets you defer checksum computation, often offloading it to hardware.<p>- UDP offload lets you skip&#x2F;reuse route lookups for subsequent packets in a bundle.<p>What UDP offload is no good for though, is large scale servers - the current APIs only work when the incoming packet chains neatly organize into batches per peer socket. If you have many thousands of active sockets you’ll stop having full bundles and the overhead starts sneaking back in. As I said in another thread, we really need a replacement for the BSD APIs here, they just don’t scale for modern hardware constraints and software needs - much too expensive per packet.</div><br/></div></div><div id="41485341" class="c"><input type="checkbox" id="c-41485341" checked=""/><div class="controls bullet"><span class="by">infogulch</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485162">parent</a><span>|</span><a href="#41485543">prev</a><span>|</span><a href="#41485297">next</a><span>|</span><label class="collapse" for="c-41485341">[-]</label><label class="expand" for="c-41485341">[3 more]</label></div><br/><div class="children"><div class="content">In my head the main benefit of QUIC was always multipath, aka the ability to switch interfaces on demand without losing the connection. There&#x27;s MPTCP but who knows how viable it is.</div><br/><div id="41486500" class="c"><input type="checkbox" id="c-41486500" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485341">parent</a><span>|</span><a href="#41485688">next</a><span>|</span><label class="collapse" for="c-41486500">[-]</label><label class="expand" for="c-41486500">[1 more]</label></div><br/><div class="children"><div class="content">Is that actually implemented and working in practice? My connection still hangs whenever my wifi goes out of range...</div><br/></div></div><div id="41485688" class="c"><input type="checkbox" id="c-41485688" checked=""/><div class="controls bullet"><span class="by">rocqua</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485341">parent</a><span>|</span><a href="#41486500">prev</a><span>|</span><a href="#41485297">next</a><span>|</span><label class="collapse" for="c-41485688">[-]</label><label class="expand" for="c-41485688">[1 more]</label></div><br/><div class="children"><div class="content">Mptcp sees use in the Telco space, so they probably know.</div><br/></div></div></div></div><div id="41485297" class="c"><input type="checkbox" id="c-41485297" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485162">parent</a><span>|</span><a href="#41485341">prev</a><span>|</span><a href="#41485359">next</a><span>|</span><label class="collapse" for="c-41485297">[-]</label><label class="expand" for="c-41485297">[1 more]</label></div><br/><div class="children"><div class="content">Among other things, GRO (receive offloading) means you can get more data off of the network card in fewer operations.<p>Linux has receive packet steering, which can help with getting packets from the network card to the right CPU and the right userspace thread without moving from one CPU&#x27;s cache to another.</div><br/></div></div><div id="41485359" class="c"><input type="checkbox" id="c-41485359" checked=""/><div class="controls bullet"><span class="by">apitman</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485162">parent</a><span>|</span><a href="#41485297">prev</a><span>|</span><a href="#41485604">next</a><span>|</span><label class="collapse" for="c-41485359">[-]</label><label class="expand" for="c-41485359">[1 more]</label></div><br/><div class="children"><div class="content">Ditching head of line blocking is potentially a big win, but I really wish it wouldn&#x27;t have come with so much complexity.</div><br/></div></div><div id="41485604" class="c"><input type="checkbox" id="c-41485604" checked=""/><div class="controls bullet"><span class="by">10000truths</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485162">parent</a><span>|</span><a href="#41485359">prev</a><span>|</span><a href="#41485254">next</a><span>|</span><label class="collapse" for="c-41485604">[-]</label><label class="expand" for="c-41485604">[1 more]</label></div><br/><div class="children"><div class="content">Bulk throughout isn&#x27;t on par with TLS mainly because NICs with dedicated hardware for QUIC offload aren&#x27;t commercially available (yet). Latency is undoubtedly better - the 1-RTT QUIC handshake substantially reduces time-to-first-byte compared to TLS.</div><br/></div></div><div id="41485254" class="c"><input type="checkbox" id="c-41485254" checked=""/><div class="controls bullet"><span class="by">Vecr</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485162">parent</a><span>|</span><a href="#41485604">prev</a><span>|</span><a href="#41485236">next</a><span>|</span><label class="collapse" for="c-41485254">[-]</label><label class="expand" for="c-41485254">[1 more]</label></div><br/><div class="children"><div class="content">I think one of the original drivers was the ability to quickly tweak parameters, after Linux rejected what I think was userspace adjustment of window sizing to be more aggressive than the default.<p>The Linux maintainers didn&#x27;t want to be responsible for congestion collapse, but UDP lets you spray packets from userspace, so Google went with that.</div><br/></div></div></div></div><div id="41485236" class="c"><input type="checkbox" id="c-41485236" checked=""/><div class="controls bullet"><span class="by">RachelF</span><span>|</span><a href="#41485054">parent</a><span>|</span><a href="#41485162">prev</a><span>|</span><a href="#41486439">next</a><span>|</span><label class="collapse" for="c-41485236">[-]</label><label class="expand" for="c-41485236">[4 more]</label></div><br/><div class="children"><div class="content">Also bear in mind that many of today&#x27;s network cards have processors in them that handle much of the TCP&#x2F;IP overhead.</div><br/><div id="41485458" class="c"><input type="checkbox" id="c-41485458" checked=""/><div class="controls bullet"><span class="by">kccqzy</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485236">parent</a><span>|</span><a href="#41486439">next</a><span>|</span><label class="collapse" for="c-41485458">[-]</label><label class="expand" for="c-41485458">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s mostly still for the data center. Which end-user network cards that I can buy can do TCP offloading?</div><br/><div id="41485514" class="c"><input type="checkbox" id="c-41485514" checked=""/><div class="controls bullet"><span class="by">phil21</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485458">parent</a><span>|</span><a href="#41485517">next</a><span>|</span><label class="collapse" for="c-41485514">[-]</label><label class="expand" for="c-41485514">[1 more]</label></div><br/><div class="children"><div class="content">Unless I’m missing something here, pretty much any Intel nic released in the past decade should support tcp offload.  I imagine the same is true for Broadcom and other vendors as well, but I don’t have something handy to check.</div><br/></div></div><div id="41485517" class="c"><input type="checkbox" id="c-41485517" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41485054">root</a><span>|</span><a href="#41485458">parent</a><span>|</span><a href="#41485514">prev</a><span>|</span><a href="#41486439">next</a><span>|</span><label class="collapse" for="c-41485517">[-]</label><label class="expand" for="c-41485517">[1 more]</label></div><br/><div class="children"><div class="content">Some wifi cards offload a surprising amount in order to do wake-on-wireless, but that&#x27;s not for performance.</div><br/></div></div></div></div></div></div><div id="41486439" class="c"><input type="checkbox" id="c-41486439" checked=""/><div class="controls bullet"><span class="by">nextaccountic</span><span>|</span><a href="#41485054">parent</a><span>|</span><a href="#41485236">prev</a><span>|</span><a href="#41485176">next</a><span>|</span><label class="collapse" for="c-41486439">[-]</label><label class="expand" for="c-41486439">[1 more]</label></div><br/><div class="children"><div class="content">Do you mean that under the same workload, TCP will perform better?</div><br/></div></div></div></div><div id="41485176" class="c"><input type="checkbox" id="c-41485176" checked=""/><div class="controls bullet"><span class="by">sbstp</span><span>|</span><a href="#41485054">prev</a><span>|</span><a href="#41485200">next</a><span>|</span><label class="collapse" for="c-41485176">[-]</label><label class="expand" for="c-41485176">[6 more]</label></div><br/><div class="children"><div class="content">Even HTTP&#x2F;2 seems to have been rushed[1]. Chrome has removed support for server push. Maybe more thought should be put into these protocols instead of just rebranding whatever Google is trying to impose on us.<p>[1] <a href="https:&#x2F;&#x2F;varnish-cache.org&#x2F;docs&#x2F;trunk&#x2F;phk&#x2F;h2againagainagain.html" rel="nofollow">https:&#x2F;&#x2F;varnish-cache.org&#x2F;docs&#x2F;trunk&#x2F;phk&#x2F;h2againagainagain.h...</a></div><br/><div id="41486184" class="c"><input type="checkbox" id="c-41486184" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#41485176">parent</a><span>|</span><a href="#41485255">next</a><span>|</span><label class="collapse" for="c-41486184">[-]</label><label class="expand" for="c-41486184">[1 more]</label></div><br/><div class="children"><div class="content">HTTP2 was a prototype that was designed by people who either assumed that mobile internet would get better much quicker than it did, or who didn&#x27;t understand what packet loss did to throughput.<p>I suspect part of the problem is that some of the rush is that people at major companies will get a promotion if they do &quot;high impact&quot; work out in the open.<p>HTTP&#x2F;2 &quot;solves head of line blocking&quot; which is doesn&#x27;t. It exchanged an HTTP SSL blocking issues with TCP on the real internet issue. This was predicted at the time.<p>The other issue is that instead of keeping it a simple protocol, the temptation to add complexity to aid a specific use case gets too much. (It&#x27;s human nature I don&#x27;t blame them)</div><br/></div></div><div id="41485255" class="c"><input type="checkbox" id="c-41485255" checked=""/><div class="controls bullet"><span class="by">surajrmal</span><span>|</span><a href="#41485176">parent</a><span>|</span><a href="#41486184">prev</a><span>|</span><a href="#41485881">next</a><span>|</span><label class="collapse" for="c-41485255">[-]</label><label class="expand" for="c-41485255">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s okay to make mistakes, that&#x27;s how you learn and improve. Being conservative has drawbacks of its own. Id argue we need more parties involved earlier in the process rather than just time.</div><br/><div id="41485459" class="c"><input type="checkbox" id="c-41485459" checked=""/><div class="controls bullet"><span class="by">zdragnar</span><span>|</span><a href="#41485176">root</a><span>|</span><a href="#41485255">parent</a><span>|</span><a href="#41485881">next</a><span>|</span><label class="collapse" for="c-41485459">[-]</label><label class="expand" for="c-41485459">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a weird balancing act. On the other hand, waiting for everyone to agree on everything means that the spec will take a decade or two for everyone to come together, and then all the additional time for everyone to actively support it.<p>AJAX is a decent example. Microsoft&#x27;s Outlook Web Access team implemented XMLHTTP as an activex thing for IE 5 and soon the rest of the vendors adopted it as a standard thing as XmlHttpRequest objects.<p>In fact, I suspect the list of things that exist in browsers because one vendor thought it was a good idea and everyone hopped on board is far, far longer than those designed by committee. Often times, the initially released version is not exactly the same that everyone standardized on, but they all get to build on the real-world consequences of it.<p>I happen to like the TC39 process <a href="https:&#x2F;&#x2F;tc39.es&#x2F;process-document&#x2F;" rel="nofollow">https:&#x2F;&#x2F;tc39.es&#x2F;process-document&#x2F;</a> which requires two live implementations with use in the wild for something to get into the final stage and become an official part of the specification. It is obviously harder for something like a network stack than a JavaScript engine to get real world use and feedback, but it has helped to keep a lot of the crazier vendor specific features at bay.</div><br/></div></div></div></div><div id="41485881" class="c"><input type="checkbox" id="c-41485881" checked=""/><div class="controls bullet"><span class="by">est</span><span>|</span><a href="#41485176">parent</a><span>|</span><a href="#41485255">prev</a><span>|</span><a href="#41485295">next</a><span>|</span><label class="collapse" for="c-41485881">[-]</label><label class="expand" for="c-41485881">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t blame Google, all major version changes are very brave, I praised them. The problem is lack of non-google protocols for competition.</div><br/></div></div></div></div><div id="41485200" class="c"><input type="checkbox" id="c-41485200" checked=""/><div class="controls bullet"><span class="by">botanical</span><span>|</span><a href="#41485176">prev</a><span>|</span><a href="#41485037">next</a><span>|</span><label class="collapse" for="c-41485200">[-]</label><label class="expand" for="c-41485200">[8 more]</label></div><br/><div class="children"><div class="content">&gt; we identify the root cause to be high receiver-side processing overhead<p>I find this to be the issue when it comes to Google, and I bet it was known before hand; pushing processing to the user. For example, the AV1 video codec was deployed when no consumer had HW decoding capabilities. It saved them on space at the expense of increased CPU usage for the end-user.<p>I don&#x27;t know what the motive was there; it would still show that they are carbon-neutral while billions are busy processing the data.</div><br/><div id="41485400" class="c"><input type="checkbox" id="c-41485400" checked=""/><div class="controls bullet"><span class="by">anfilt</span><span>|</span><a href="#41485200">parent</a><span>|</span><a href="#41485477">next</a><span>|</span><label class="collapse" for="c-41485400">[-]</label><label class="expand" for="c-41485400">[1 more]</label></div><br/><div class="children"><div class="content">Well I will say if your running servers hit billions of times per day. Offloading processing to the client when safe to do so starts make sense financially. Google does not have to pay for your CPU or storage usage ect...<p>Also I will say if said overhead is not too much it&#x27;s not that bad of a thing.</div><br/></div></div><div id="41485477" class="c"><input type="checkbox" id="c-41485477" checked=""/><div class="controls bullet"><span class="by">danpalmer</span><span>|</span><a href="#41485200">parent</a><span>|</span><a href="#41485400">prev</a><span>|</span><a href="#41485435">next</a><span>|</span><label class="collapse" for="c-41485477">[-]</label><label class="expand" for="c-41485477">[3 more]</label></div><br/><div class="children"><div class="content">&gt; the AV1 video codec was deployed when no consumer had HW decoding capabilities<p>This was a bug. An improved software decoder was deployed for Android and for buggy reasons the YouTube app used it instead of a hardware accelerated implementation. It was fixed.<p>Having worked on a similar space (compression formats for app downloads) I can assure you that all factors are accounted for with decisions like this, we were profiling device thermals for different compression formats. Setting aside bugs, the teams behind things like this are taking wide-reaching views of the ecosystem when making these decisions, and at scale, client concerns almost always outweigh server concerns.</div><br/><div id="41485663" class="c"><input type="checkbox" id="c-41485663" checked=""/><div class="controls bullet"><span class="by">watermelon0</span><span>|</span><a href="#41485200">root</a><span>|</span><a href="#41485477">parent</a><span>|</span><a href="#41486156">next</a><span>|</span><label class="collapse" for="c-41485663">[-]</label><label class="expand" for="c-41485663">[1 more]</label></div><br/><div class="children"><div class="content">YouTube had the same issue with VP9 on laptops, where you had to use an extension to force H264, to avoid quickly draining the battery.</div><br/></div></div><div id="41486156" class="c"><input type="checkbox" id="c-41486156" checked=""/><div class="controls bullet"><span class="by">toastal</span><span>|</span><a href="#41485200">root</a><span>|</span><a href="#41485477">parent</a><span>|</span><a href="#41485663">prev</a><span>|</span><a href="#41485435">next</a><span>|</span><label class="collapse" for="c-41486156">[-]</label><label class="expand" for="c-41486156">[1 more]</label></div><br/><div class="children"><div class="content">If only they would give us JXL on Android</div><br/></div></div></div></div><div id="41485435" class="c"><input type="checkbox" id="c-41485435" checked=""/><div class="controls bullet"><span class="by">kccqzy</span><span>|</span><a href="#41485200">parent</a><span>|</span><a href="#41485477">prev</a><span>|</span><a href="#41485037">next</a><span>|</span><label class="collapse" for="c-41485435">[-]</label><label class="expand" for="c-41485435">[3 more]</label></div><br/><div class="children"><div class="content">This is indeed an issue but it&#x27;s widespread and everyone does it, including Google. Things like servers no longer generating actual dynamic HTML, replaced with servers simply serving pure data like JSON and expecting the client to render it into the DOM. It&#x27;s not just Google that doesn&#x27;t care, but the majority of web developers also don&#x27;t care.</div><br/><div id="41485603" class="c"><input type="checkbox" id="c-41485603" checked=""/><div class="controls bullet"><span class="by">SquareWheel</span><span>|</span><a href="#41485200">root</a><span>|</span><a href="#41485435">parent</a><span>|</span><a href="#41485037">next</a><span>|</span><label class="collapse" for="c-41485603">[-]</label><label class="expand" for="c-41485603">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s clearly advantages to writing a web app as an SPA, otherwise web devs wouldn&#x27;t do it.  The idea that web devs &quot;don&#x27;t care&quot; (about what exactly?) really doesn&#x27;t make any sense.<p>Moving interactions to JSON in many cases is just a better experience.  If you click a Like button on Facebook, which is the better outcome: To see a little animation where the button updates, or for the page to reload with a flash of white, throw away the comment you were part-way through writing, and then scroll you back to the top of the page?<p>There&#x27;s a reason XMLHttpRequest took the world by storm.  More than that, jQuery is still used on more than 80% of websites due in large part to its legacy of making this process easier and cross-browser.</div><br/><div id="41486105" class="c"><input type="checkbox" id="c-41486105" checked=""/><div class="controls bullet"><span class="by">tock</span><span>|</span><a href="#41485200">root</a><span>|</span><a href="#41485603">parent</a><span>|</span><a href="#41485037">next</a><span>|</span><label class="collapse" for="c-41486105">[-]</label><label class="expand" for="c-41486105">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think Facebook is the best example given the sheer number of loading skeletons I see on their page.</div><br/></div></div></div></div></div></div></div></div><div id="41485037" class="c"><input type="checkbox" id="c-41485037" checked=""/><div class="controls bullet"><span class="by">JoshTriplett</span><span>|</span><a href="#41485200">prev</a><span>|</span><a href="#41485909">next</a><span>|</span><label class="collapse" for="c-41485037">[-]</label><label class="expand" for="c-41485037">[1 more]</label></div><br/><div class="children"><div class="content">Seems to be available on arXiv: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.09423" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.09423</a></div><br/></div></div><div id="41485909" class="c"><input type="checkbox" id="c-41485909" checked=""/><div class="controls bullet"><span class="by">AlphaCharlie</span><span>|</span><a href="#41485037">prev</a><span>|</span><a href="#41485390">next</a><span>|</span><label class="collapse" for="c-41485909">[-]</label><label class="expand" for="c-41485909">[1 more]</label></div><br/><div class="children"><div class="content">Free PDF file of the research: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.09423" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.09423</a></div><br/></div></div><div id="41485390" class="c"><input type="checkbox" id="c-41485390" checked=""/><div class="controls bullet"><span class="by">apitman</span><span>|</span><a href="#41485909">prev</a><span>|</span><a href="#41486396">next</a><span>|</span><label class="collapse" for="c-41485390">[-]</label><label class="expand" for="c-41485390">[6 more]</label></div><br/><div class="children"><div class="content">Currently chewing my way laboriously through RFC9000. Definitely concerned by how complex it is. The high level ideas of QUIC seem fairly straight forward, but the spec feels full of edge cases you must account for. Maybe there&#x27;s no other way, but it makes me uncomfortable.<p>I don&#x27;t mind too much as long as they never try to take HTTP&#x2F;1.1 from me.</div><br/><div id="41485460" class="c"><input type="checkbox" id="c-41485460" checked=""/><div class="controls bullet"><span class="by">ironmagma</span><span>|</span><a href="#41485390">parent</a><span>|</span><a href="#41486381">next</a><span>|</span><label class="collapse" for="c-41485460">[-]</label><label class="expand" for="c-41485460">[4 more]</label></div><br/><div class="children"><div class="content">Considering they can’t really even make IPv6 happen, that seems like a likely scenario.</div><br/><div id="41485889" class="c"><input type="checkbox" id="c-41485889" checked=""/><div class="controls bullet"><span class="by">BartjeD</span><span>|</span><a href="#41485390">root</a><span>|</span><a href="#41485460">parent</a><span>|</span><a href="#41486381">next</a><span>|</span><label class="collapse" for="c-41485889">[-]</label><label class="expand" for="c-41485889">[3 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.google.com&#x2F;intl&#x2F;en&#x2F;ipv6&#x2F;statistics.html" rel="nofollow">https:&#x2F;&#x2F;www.google.com&#x2F;intl&#x2F;en&#x2F;ipv6&#x2F;statistics.html</a><p>I think it&#x27;s just your little corner of the woods that isn&#x27;t adopting it. Over here the trend is very clearly to move away from IPv4, except for legacy reasons.</div><br/><div id="41486070" class="c"><input type="checkbox" id="c-41486070" checked=""/><div class="controls bullet"><span class="by">apitman</span><span>|</span><a href="#41485390">root</a><span>|</span><a href="#41485889">parent</a><span>|</span><a href="#41486381">next</a><span>|</span><label class="collapse" for="c-41486070">[-]</label><label class="expand" for="c-41486070">[2 more]</label></div><br/><div class="children"><div class="content">The important milestone is when it&#x27;s safe to turn IPv4 off. And that&#x27;s not going to happen as long as any country hasn&#x27;t fully adopted it, and I don&#x27;t think that&#x27;s ever going to happen. For better or worse NAT handles outgoing connections and SNI routing handles incoming connections for most use cases. Self-hosting is the most broken but IMO that&#x27;s better handled with tunneling anyway so you don&#x27;t expose your home IP.</div><br/><div id="41486376" class="c"><input type="checkbox" id="c-41486376" checked=""/><div class="controls bullet"><span class="by">jeroenhd</span><span>|</span><a href="#41485390">root</a><span>|</span><a href="#41486070">parent</a><span>|</span><a href="#41486381">next</a><span>|</span><label class="collapse" for="c-41486376">[-]</label><label class="expand" for="c-41486376">[1 more]</label></div><br/><div class="children"><div class="content">IPv4 doesn&#x27;t need to be off. Hacks and workarounds like DS-Lite can stay with us forever, just like hacks and workarounds like NAT and ALGs will.</div><br/></div></div></div></div></div></div></div></div><div id="41486381" class="c"><input type="checkbox" id="c-41486381" checked=""/><div class="controls bullet"><span class="by">jakeogh</span><span>|</span><a href="#41485390">parent</a><span>|</span><a href="#41485460">prev</a><span>|</span><a href="#41486396">next</a><span>|</span><label class="collapse" for="c-41486381">[-]</label><label class="expand" for="c-41486381">[1 more]</label></div><br/><div class="children"><div class="content">I think keeping HTTP&#x2F;1.1 is almost as important as not dropping IPV4 (there are good reasons to not being able to tag everything; it&#x27;s harder to block a country than a user.) For similar reasons we should keep old protocols.<p>On a positive note, AFAICT 90%(??) of QUIC implementations ignored the proposed the spin bit: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20990754">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20990754</a></div><br/></div></div></div></div><div id="41486396" class="c"><input type="checkbox" id="c-41486396" checked=""/><div class="controls bullet"><span class="by">wseqyrku</span><span>|</span><a href="#41485390">prev</a><span>|</span><a href="#41485036">next</a><span>|</span><label class="collapse" for="c-41486396">[-]</label><label class="expand" for="c-41486396">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a work in progress for kernel support: <a href="https:&#x2F;&#x2F;github.com&#x2F;lxin&#x2F;quic">https:&#x2F;&#x2F;github.com&#x2F;lxin&#x2F;quic</a></div><br/></div></div><div id="41485036" class="c"><input type="checkbox" id="c-41485036" checked=""/><div class="controls bullet"><span class="by">jacob019</span><span>|</span><a href="#41486396">prev</a><span>|</span><a href="#41485058">next</a><span>|</span><label class="collapse" for="c-41485036">[-]</label><label class="expand" for="c-41485036">[19 more]</label></div><br/><div class="children"><div class="content">Maybe moving the connection protocol into userspace isn&#x27;t such a great plan.</div><br/><div id="41486036" class="c"><input type="checkbox" id="c-41486036" checked=""/><div class="controls bullet"><span class="by">mrweasel</span><span>|</span><a href="#41485036">parent</a><span>|</span><a href="#41485060">next</a><span>|</span><label class="collapse" for="c-41486036">[-]</label><label class="expand" for="c-41486036">[2 more]</label></div><br/><div class="children"><div class="content">Maybe moving the entire application to the browser&#x2F;cloud wasn&#x27;t the best idea for a large number of use cases?<p>Video streaming, sure, but we&#x27;re already able to stream 4K video over a 25Mbit line. With modern internet connections being 200Mbit to 1Gbit, I don&#x27;t see that we need the bandwidth in private homes. Maybe for video conferencing in large companies, but that also doesn&#x27;t need to be 4K.<p>The underlying internet protocols are old, so there&#x27;s no harm in assessing if they&#x27;ve outlived their usefulness. However, we should also consider in web applications and &quot;always connected&quot; is truly the best solution for our day to day application needs.</div><br/><div id="41486589" class="c"><input type="checkbox" id="c-41486589" checked=""/><div class="controls bullet"><span class="by">kuschku</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41486036">parent</a><span>|</span><a href="#41485060">next</a><span>|</span><label class="collapse" for="c-41486589">[-]</label><label class="expand" for="c-41486589">[1 more]</label></div><br/><div class="children"><div class="content">&gt; With modern internet connections being 200Mbit to 1Gbit, I don&#x27;t see that we need the bandwidth in private homes<p>Private connections tend to be asymmetrical. In some cases, e.g. old DOCSIS versions, that used to be due to technical necessity.<p>Private connections tend to be unstable, the bandwidth fluctuates quite a bit. Depending on country, the actually guaranteed bandwidth is somewhere between half of what&#x27;s on the sticker, to nothing at all.<p>Private connections are usually used by families, with multiple people using it at the same time. In recent years, you might have 3+ family members in a video call at the same time.<p>So if you&#x27;re paying for a 1000&#x2F;50 line (as is common with DOCSIS deployments), what you&#x27;re actually getting is usually a 400&#x2F;20 line that sometimes achieves more. And those 20Mbps upload are now split between multiple people.<p>At the same time, you&#x27;re absolutely right – Gigabit is enough for most people. Download speeds are enough for quite a while. We should instead be increasing upload speeds and deploying FTTH and IPv6 everywhere to reduce the latency.</div><br/></div></div></div></div><div id="41485060" class="c"><input type="checkbox" id="c-41485060" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#41485036">parent</a><span>|</span><a href="#41486036">prev</a><span>|</span><a href="#41485408">next</a><span>|</span><label class="collapse" for="c-41485060">[-]</label><label class="expand" for="c-41485060">[8 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have access to the article, but they&#x27;re saying the issue is due to client side ack processing. I suspect they&#x27;re testing at bandwidths far beyond what&#x27;s normal for consumer applications.</div><br/><div id="41485114" class="c"><input type="checkbox" id="c-41485114" checked=""/><div class="controls bullet"><span class="by">dartharva</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485060">parent</a><span>|</span><a href="#41485130">next</a><span>|</span><label class="collapse" for="c-41485114">[-]</label><label class="expand" for="c-41485114">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s available on arxiv and nope, they are testing mostly for regular 4G&#x2F;5G speeds.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.09423" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.09423</a></div><br/><div id="41485223" class="c"><input type="checkbox" id="c-41485223" checked=""/><div class="controls bullet"><span class="by">DannyBee</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485114">parent</a><span>|</span><a href="#41485130">next</a><span>|</span><label class="collapse" for="c-41485223">[-]</label><label class="expand" for="c-41485223">[5 more]</label></div><br/><div class="children"><div class="content">4g tops out at 1gbps only when one person is on the network.
5g tops out at ~10gbps (some 20gbps i guess) only when one person is on the network.<p>They are testing at 1gbps.<p>This is not regular 4g speed for sure, and it&#x27;s a rare 5g speed.
regular 5g speed is (in the US) 40-50mbps, so, 20x slower than they are testing.</div><br/><div id="41485988" class="c"><input type="checkbox" id="c-41485988" checked=""/><div class="controls bullet"><span class="by">vrighter</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485223">parent</a><span>|</span><a href="#41485377">next</a><span>|</span><label class="collapse" for="c-41485988">[-]</label><label class="expand" for="c-41485988">[1 more]</label></div><br/><div class="children"><div class="content">Gigabit fiber internet is quite cheap and increasingly available (I&#x27;m not from the US). I don&#x27;t just use the internet over a 4&#x2F;5g connection. This definitely affects more people than you think.</div><br/></div></div><div id="41485377" class="c"><input type="checkbox" id="c-41485377" checked=""/><div class="controls bullet"><span class="by">izend</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485223">parent</a><span>|</span><a href="#41485988">prev</a><span>|</span><a href="#41485317">next</a><span>|</span><label class="collapse" for="c-41485377">[-]</label><label class="expand" for="c-41485377">[1 more]</label></div><br/><div class="children"><div class="content">What about 1gbps fiber at home, it is becoming common in Canada.  I have 1gbps up&#x2F;down.</div><br/></div></div><div id="41485317" class="c"><input type="checkbox" id="c-41485317" checked=""/><div class="controls bullet"><span class="by">dartharva</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485223">parent</a><span>|</span><a href="#41485377">prev</a><span>|</span><a href="#41486270">next</a><span>|</span><label class="collapse" for="c-41485317">[-]</label><label class="expand" for="c-41485317">[1 more]</label></div><br/><div class="children"><div class="content">Still won&#x27;t be beyond normal consumer applications&#x27; capacity, right?</div><br/></div></div><div id="41486270" class="c"><input type="checkbox" id="c-41486270" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485223">parent</a><span>|</span><a href="#41485317">prev</a><span>|</span><a href="#41485130">next</a><span>|</span><label class="collapse" for="c-41486270">[-]</label><label class="expand" for="c-41486270">[1 more]</label></div><br/><div class="children"><div class="content">Http1.1 has been around for 28 years. At the time, gigabit ethernet was _expensive_. 9600baud on mobile was rare.<p>and yet http1.1 runs on gigabit networks pretty well.</div><br/></div></div></div></div></div></div><div id="41485130" class="c"><input type="checkbox" id="c-41485130" checked=""/><div class="controls bullet"><span class="by">spacebacon</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485060">parent</a><span>|</span><a href="#41485114">prev</a><span>|</span><a href="#41485408">next</a><span>|</span><label class="collapse" for="c-41485130">[-]</label><label class="expand" for="c-41485130">[1 more]</label></div><br/><div class="children"><div class="content">See arXiv link in comments.</div><br/></div></div></div></div><div id="41485408" class="c"><input type="checkbox" id="c-41485408" checked=""/><div class="controls bullet"><span class="by">kccqzy</span><span>|</span><a href="#41485036">parent</a><span>|</span><a href="#41485060">prev</a><span>|</span><a href="#41485178">next</a><span>|</span><label class="collapse" for="c-41485408">[-]</label><label class="expand" for="c-41485408">[2 more]</label></div><br/><div class="children"><div class="content">The flexibility and ease of changing a userspace protocol IMO far outweighs anything else. If the performance problem described in this article (which I don&#x27;t have access to) is in userspace QUIC code, it can be fixed and deployed very quickly. If similar performance issue were to be found in TCP, expect to wait multiple years.</div><br/><div id="41486002" class="c"><input type="checkbox" id="c-41486002" checked=""/><div class="controls bullet"><span class="by">vrighter</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485408">parent</a><span>|</span><a href="#41485178">next</a><span>|</span><label class="collapse" for="c-41486002">[-]</label><label class="expand" for="c-41486002">[1 more]</label></div><br/><div class="children"><div class="content">Well, the problem is probably that it is in userspace in the first place.</div><br/></div></div></div></div><div id="41485178" class="c"><input type="checkbox" id="c-41485178" checked=""/><div class="controls bullet"><span class="by">01HNNWZ0MV43FF</span><span>|</span><a href="#41485036">parent</a><span>|</span><a href="#41485408">prev</a><span>|</span><a href="#41485198">next</a><span>|</span><label class="collapse" for="c-41485178">[-]</label><label class="expand" for="c-41485178">[5 more]</label></div><br/><div class="children"><div class="content">Does QUIC mandate that, or is that just the stepping stone until the chicken-and-egg problem is solved and we get kernel support?</div><br/><div id="41485500" class="c"><input type="checkbox" id="c-41485500" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485178">parent</a><span>|</span><a href="#41485416">next</a><span>|</span><label class="collapse" for="c-41485500">[-]</label><label class="expand" for="c-41485500">[2 more]</label></div><br/><div class="children"><div class="content">No, but it depends on how QUIC works, how Ethernet hardware works, and how much you actually want to offload to the NIC. For example, QUIC has TLS encryption built-in, so anything that&#x27;s encrypted can&#x27;t be offloaded. And I don&#x27;t think most people want to hand all their TLS keys to their NIC[0].<p>At the very least you probably would have to assign QUIC its own transport, rather than using UDP as &quot;we have raw sockets at home&quot;. Problem is, only TCP and UDP reliably traverse the Internet[1]. <i>Everything</i> in the middle is sniffing traffic, messing with options, etc. In fact, Google rejected an alternate transport protocol called SCTP (which does all the stream multiplexing over a single connection that QUIC does) specifically because, among other things, SCTP&#x27;s a transport protocol and middleboxes choke on it.<p>[0] I am aware that &quot;SSL accelerators&quot; used to do exactly this, but in modern times we have perfectly good crypto accelerators right in our CPU cores.<p>[1] ICMP sometimes traverses the internet, it&#x27;s how ping works, but a lot of firewalls blackhole ICMP. Or at least they did before IPv6 made it practically mandatory to forward ICMP packets.</div><br/><div id="41485766" class="c"><input type="checkbox" id="c-41485766" checked=""/><div class="controls bullet"><span class="by">_flux</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485500">parent</a><span>|</span><a href="#41485416">next</a><span>|</span><label class="collapse" for="c-41485766">[-]</label><label class="expand" for="c-41485766">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think passing just the session keys to NIC would sound so perilous, though.</div><br/></div></div></div></div><div id="41485416" class="c"><input type="checkbox" id="c-41485416" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485178">parent</a><span>|</span><a href="#41485500">prev</a><span>|</span><a href="#41485206">next</a><span>|</span><label class="collapse" for="c-41485416">[-]</label><label class="expand" for="c-41485416">[1 more]</label></div><br/><div class="children"><div class="content">As others in the thread summarized the paper as saying the issue is ack offload. That has nothing to do with whether the stack is in kernel space or user space. Indeed there’s some concern about this inevitable scenario because the kernel is so slow moving, updates take much longer to propagate to applications needing them without a middle ground whereas as user space stacks they can update as the endpoint applications need them to.</div><br/></div></div><div id="41485206" class="c"><input type="checkbox" id="c-41485206" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#41485036">root</a><span>|</span><a href="#41485178">parent</a><span>|</span><a href="#41485416">prev</a><span>|</span><a href="#41485198">next</a><span>|</span><label class="collapse" for="c-41485206">[-]</label><label class="expand" for="c-41485206">[1 more]</label></div><br/><div class="children"><div class="content">On mobile the plan is to never use kernel support so that apps can have the latest QUIC on old kernels.</div><br/></div></div></div></div></div></div><div id="41485058" class="c"><input type="checkbox" id="c-41485058" checked=""/><div class="controls bullet"><span class="by">mholt</span><span>|</span><a href="#41485036">prev</a><span>|</span><a href="#41485469">next</a><span>|</span><label class="collapse" for="c-41485058">[-]</label><label class="expand" for="c-41485058">[10 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have access to the paper but based on the abstract and a quick scan of the presentation, I can confirm that I have seen results like this in Caddy, which enables HTTP&#x2F;3 out of the box.<p>HTTP&#x2F;3 implementations vary widely at the moment, and will likely take another decade to optimize to homogeneity. But even then, QUIC requires a <i>lot</i> of state management that TCP doesn&#x27;t have to worry about (even in the kernel). There&#x27;s a ton of processing involved with every UDP packet, and small MTUs, still engrained into many middle boxes and even end-user machines these days, don&#x27;t make it any better.<p>So, yeah, as I felt about QUIC ... oh, about 6 years ago or so... HTTP&#x2F;2 is actually really quite good enough for most use cases. The far reaches of the world and those without fast connections will benefit, but the majority of global transmissions will likely be best served with HTTP&#x2F;2.<p>Intuitively, I consider each HTTP major version an increased order of magnitude in complexity. From 1 to 2 the main complexities are binary (that&#x27;s debatable, since it&#x27;s technically simpler from an encoding standpoint), compression, and streams; then with HTTP&#x2F;3 there&#x27;s _so, so much_ it does to make it work. It _can_ be faster -- that&#x27;s proven -- but only when networks are slow.<p>TCP congestion control is its own worst enemy, but when networks aren&#x27;t congested (and with the right algorithm)... guess what. It&#x27;s fast! And the in-order packet transmissions (head-of-line blocking) makes endpoint code so much simpler and faster. It&#x27;s no wonder TCP is faster these days when networks are fast.<p>I think servers should offer HTTP&#x2F;3 but clients should be choosy when to use it, for the sake of their own experience&#x2F;performance.</div><br/><div id="41486452" class="c"><input type="checkbox" id="c-41486452" checked=""/><div class="controls bullet"><span class="by">geocar</span><span>|</span><a href="#41485058">parent</a><span>|</span><a href="#41485159">next</a><span>|</span><label class="collapse" for="c-41486452">[-]</label><label class="expand" for="c-41486452">[1 more]</label></div><br/><div class="children"><div class="content">I turned off HTTP2 and HTTP3 a few months ago.<p>I see a few million daily page views: Memory usage has been down, latency has been down, network accounting (bandwidth) is about the same. Revenue (ads) is up.<p>&gt; It _can_ be faster -- that&#x27;s proven -- but only when networks are slow.<p>It can be faster in a situation that doesn&#x27;t exist.<p>It sounds charitable to say something like &quot;when networks are slow&quot; -- but because everyone has had a slow network experience, they are going to think that QUIC would help them out, but <i>real world slow network problems</i> don&#x27;t look like the ones that QUIC solves.<p>In the real world, QUIC wastes memory and money and increases latency on the <i>average case</i>. Maybe some Google engineers can come up with a clever heuristic involving TCP options or the RTT information to &quot;switch on QUIC selectively&quot; but honestly I wish they wouldn&#x27;t bother, simply because I don&#x27;t want to waste my time benchmarking another half-baked google fart.</div><br/></div></div><div id="41485159" class="c"><input type="checkbox" id="c-41485159" checked=""/><div class="controls bullet"><span class="by">altairprime</span><span>|</span><a href="#41485058">parent</a><span>|</span><a href="#41486452">prev</a><span>|</span><a href="#41485168">next</a><span>|</span><label class="collapse" for="c-41485159">[-]</label><label class="expand" for="c-41485159">[3 more]</label></div><br/><div class="children"><div class="content">The performance gap is shown to be due to hardware offloading, not due to congestion control, in the arxiv paper above.</div><br/><div id="41485290" class="c"><input type="checkbox" id="c-41485290" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#41485058">root</a><span>|</span><a href="#41485159">parent</a><span>|</span><a href="#41485168">next</a><span>|</span><label class="collapse" for="c-41485290">[-]</label><label class="expand" for="c-41485290">[2 more]</label></div><br/><div class="children"><div class="content">And because Quic is encrypted at a fundamental level, offload likely means needing to share keys with the network card which is a trust concern.</div><br/><div id="41485679" class="c"><input type="checkbox" id="c-41485679" checked=""/><div class="controls bullet"><span class="by">10000truths</span><span>|</span><a href="#41485058">root</a><span>|</span><a href="#41485290">parent</a><span>|</span><a href="#41485168">next</a><span>|</span><label class="collapse" for="c-41485679">[-]</label><label class="expand" for="c-41485679">[1 more]</label></div><br/><div class="children"><div class="content">This is already how TLS offload is implemented for NICs that support it. The handshake isn&#x27;t offloaded, only the data path. So essentially, the application performs the handshake, then it calls setsockopt to convert the TCP socket to a kTLS socket, then it passes the shared key, IV, etc. to the kTLS socket, and the OS&#x27;s network stack passes those parameters to the NIC. From there, the NIC only handles the bulk encryption&#x2F;decryption and record encapsulation&#x2F;decapsulation. This approach keeps the drivers&#x27; offload implementations simple, while still allowing the application&#x2F;OS to manage the session state.</div><br/></div></div></div></div></div></div><div id="41485168" class="c"><input type="checkbox" id="c-41485168" checked=""/><div class="controls bullet"><span class="by">truetraveller</span><span>|</span><a href="#41485058">parent</a><span>|</span><a href="#41485159">prev</a><span>|</span><a href="#41485150">next</a><span>|</span><label class="collapse" for="c-41485168">[-]</label><label class="expand" for="c-41485168">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;d say Http1.1 is good enough for most people, especially with persistent connections.  Http2 is an exponential leap in complexity, and burdensome&#x2F;error-prone for clients to implement.</div><br/><div id="41485185" class="c"><input type="checkbox" id="c-41485185" checked=""/><div class="controls bullet"><span class="by">01HNNWZ0MV43FF</span><span>|</span><a href="#41485058">root</a><span>|</span><a href="#41485168">parent</a><span>|</span><a href="#41485374">next</a><span>|</span><label class="collapse" for="c-41485185">[-]</label><label class="expand" for="c-41485185">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I imagine 1 + 3 being popular. 1.1 is so simple to implement and WebTransport &#x2F; QUIC is basically a teeny VPN connection.</div><br/></div></div><div id="41485374" class="c"><input type="checkbox" id="c-41485374" checked=""/><div class="controls bullet"><span class="by">apitman</span><span>|</span><a href="#41485058">root</a><span>|</span><a href="#41485168">parent</a><span>|</span><a href="#41485185">prev</a><span>|</span><a href="#41485150">next</a><span>|</span><label class="collapse" for="c-41485374">[-]</label><label class="expand" for="c-41485374">[1 more]</label></div><br/><div class="children"><div class="content">The day they come for HTTP&#x2F;1.1 is the day I die on a hill.</div><br/></div></div></div></div><div id="41485304" class="c"><input type="checkbox" id="c-41485304" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41485058">parent</a><span>|</span><a href="#41485150">prev</a><span>|</span><a href="#41485469">next</a><span>|</span><label class="collapse" for="c-41485304">[-]</label><label class="expand" for="c-41485304">[1 more]</label></div><br/><div class="children"><div class="content">Agreed on this.</div><br/></div></div></div></div><div id="41485469" class="c"><input type="checkbox" id="c-41485469" checked=""/><div class="controls bullet"><span class="by">jauntywundrkind</span><span>|</span><a href="#41485058">prev</a><span>|</span><a href="#41485602">next</a><span>|</span><label class="collapse" for="c-41485469">[-]</label><label class="expand" for="c-41485469">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if these results reproduce on Windows. Is there any TCP offload or GSO there? If not maybe the results wouldn&#x27;t vary?</div><br/></div></div><div id="41485602" class="c"><input type="checkbox" id="c-41485602" checked=""/><div class="controls bullet"><span class="by">latentpot</span><span>|</span><a href="#41485469">prev</a><span>|</span><a href="#41486151">next</a><span>|</span><label class="collapse" for="c-41485602">[-]</label><label class="expand" for="c-41485602">[4 more]</label></div><br/><div class="children"><div class="content">QUIC is the standard problem across n number of clients who choose Zscaler and similar content inspection tools. You can block it at the policy level but you also need to have it disabled at the browser level. Which sometimes magically turns on again and leads to a flurry of tickets for &#x27;slow internet&#x27;, &#x27;Google search not working&#x27; etcetera.</div><br/><div id="41485687" class="c"><input type="checkbox" id="c-41485687" checked=""/><div class="controls bullet"><span class="by">watermelon0</span><span>|</span><a href="#41485602">parent</a><span>|</span><a href="#41485947">next</a><span>|</span><label class="collapse" for="c-41485687">[-]</label><label class="expand" for="c-41485687">[1 more]</label></div><br/><div class="children"><div class="content">Wouldn&#x27;t the issue in this case be with Zscaler, and not with QUIC?</div><br/></div></div><div id="41485947" class="c"><input type="checkbox" id="c-41485947" checked=""/><div class="controls bullet"><span class="by">chgs</span><span>|</span><a href="#41485602">parent</a><span>|</span><a href="#41485687">prev</a><span>|</span><a href="#41486151">next</a><span>|</span><label class="collapse" for="c-41485947">[-]</label><label class="expand" for="c-41485947">[2 more]</label></div><br/><div class="children"><div class="content">The problem here is choosing software like zscaler</div><br/><div id="41486563" class="c"><input type="checkbox" id="c-41486563" checked=""/><div class="controls bullet"><span class="by">mcosta</span><span>|</span><a href="#41485602">root</a><span>|</span><a href="#41485947">parent</a><span>|</span><a href="#41486151">next</a><span>|</span><label class="collapse" for="c-41486563">[-]</label><label class="expand" for="c-41486563">[1 more]</label></div><br/><div class="children"><div class="content">Zscaler is not chosen, it is imposed by the corporation</div><br/></div></div></div></div></div></div><div id="41486151" class="c"><input type="checkbox" id="c-41486151" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#41485602">prev</a><span>|</span><a href="#41485062">next</a><span>|</span><label class="collapse" for="c-41486151">[-]</label><label class="expand" for="c-41486151">[3 more]</label></div><br/><div class="children"><div class="content">I wonder if the trick might be to repurpose technology from server hardware: partition the physical NIC into virtual PCI-e devices with distinct addresses, and map to user-space processes instead of virtual machines.<p>So in essence, each browser tab or even each listening UDP socket could have a distinct IPv6 address dedicated to it, with packets delivered into a ring buffer in user-mode. This is so similar to what goes on with hypervisors now that existing hardware designs might even be able to handle it already.<p>Just an idle thought...</div><br/><div id="41486618" class="c"><input type="checkbox" id="c-41486618" checked=""/><div class="controls bullet"><span class="by">jeroenhd</span><span>|</span><a href="#41486151">parent</a><span>|</span><a href="#41486210">next</a><span>|</span><label class="collapse" for="c-41486618">[-]</label><label class="expand" for="c-41486618">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve often pondered if it was possible to assign every application&#x2F;tab&#x2F;domain&#x2F;origin a different IPv6 address to exchange data with, to make tracking people just a tad harder, but also to simplify per-process firewall rules. With the bare minimum, a &#x2F;64, you could easily host billions of addresses per device without running out.<p>I think there may be a limit to how many IP addresses NICs (and maybe drivers) can track at once, though.<p>What I don&#x27;t really get is why QUIC had to be invented when multi-stream protocols like SCTP already exist. SCTP brings the reliability of TCP with the multi-stream system that makes QUIC good for websites. Piping TLS over it is a bit of a pain (you don&#x27;t want a separate handshake per stream), but surely there could be techniques to make it less painful (leveraging 0-RTT? Using session resumptions with tickets from the first connected stream?).</div><br/></div></div><div id="41486210" class="c"><input type="checkbox" id="c-41486210" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#41486151">parent</a><span>|</span><a href="#41486618">prev</a><span>|</span><a href="#41485062">next</a><span>|</span><label class="collapse" for="c-41486210">[-]</label><label class="expand" for="c-41486210">[1 more]</label></div><br/><div class="children"><div class="content">Or just have multiple TCP streams. Super simple, low cost, uses all the optimisations we have already.<p>when the latency&#x2F;packet drop is low, prune the connections and you get monster speed.<p>When the latency&#x2F;loss is high, grow the number of concurrent connections to overcome slow start.<p>Doesn&#x27;t give you QUIC like multipath though.</div><br/></div></div></div></div><div id="41485296" class="c"><input type="checkbox" id="c-41485296" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41485062">prev</a><span>|</span><label class="collapse" for="c-41485296">[-]</label><label class="expand" for="c-41485296">[9 more]</label></div><br/><div class="children"><div class="content">Maybe I&#x27;m the only person who thinks that trying to make existing internet protocols faster is wasted energy. But who am I to say anything.</div><br/><div id="41486538" class="c"><input type="checkbox" id="c-41486538" checked=""/><div class="controls bullet"><span class="by">foul</span><span>|</span><a href="#41485296">parent</a><span>|</span><a href="#41485919">next</a><span>|</span><label class="collapse" for="c-41486538">[-]</label><label class="expand" for="c-41486538">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s wasted energy when they aren&#x27;t used at their full capacity.<p>I think that GoogleHTTP has real-world uses for bad connectivity or in datacenters where they can fine-tune their data throughput (and buy crazy good NICs), but it seems that to use it for replacing TCP (which seems to be confirmed as very good when receiver and sender aren&#x27;t controlled by the same party) the world needs a hardware overhaul or something.</div><br/></div></div><div id="41485919" class="c"><input type="checkbox" id="c-41485919" checked=""/><div class="controls bullet"><span class="by">cheema33</span><span>|</span><a href="#41485296">parent</a><span>|</span><a href="#41486538">prev</a><span>|</span><label class="collapse" for="c-41485919">[-]</label><label class="expand" for="c-41485919">[7 more]</label></div><br/><div class="children"><div class="content">&gt; Maybe I&#x27;m the only person who thinks that trying to make existing internet protocols faster is wasted energy. But who am I to say anything.<p>If you have a valid argument to support your claim, why not present it?</div><br/><div id="41486018" class="c"><input type="checkbox" id="c-41486018" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41485296">root</a><span>|</span><a href="#41485919">parent</a><span>|</span><label class="collapse" for="c-41486018">[-]</label><label class="expand" for="c-41486018">[6 more]</label></div><br/><div class="children"><div class="content">They are already expected standards so when you create optimizations you&#x27;re building on functions that need to be supported additionally on top of them. This leads to incompatibility and sometimes often worse performance as what is being experienced here with QUIC.<p>You can read more about such things from, The Evolution of the Internet Congestion Control. <a href="https:&#x2F;&#x2F;groups.csail.mit.edu&#x2F;ana&#x2F;Publications&#x2F;The_Evolution_of_Internet_Congestion_Bauer_Clark_Lehr_TPRC_2009.pdf" rel="nofollow">https:&#x2F;&#x2F;groups.csail.mit.edu&#x2F;ana&#x2F;Publications&#x2F;The_Evolution_...</a><p>A good solution is to create a newer protocol when the limits of an existing protcol are exceeded. No one thought of needing HTTPS long ago and now we have 443 for HTTP security. If we need something to be faster and it has already achieved an arbitrary limit for the sake of backward compatibility it would be better to introduce a new protocol.<p>I dislike the idea that we&#x27;re turning into another Reddit where we are pointing fingers at people for updoots. If you dislike my opinion please present one equal to where that can be challenged.</div><br/><div id="41486181" class="c"><input type="checkbox" id="c-41486181" checked=""/><div class="controls bullet"><span class="by">paulgb</span><span>|</span><a href="#41485296">root</a><span>|</span><a href="#41486018">parent</a><span>|</span><a href="#41486174">next</a><span>|</span><label class="collapse" for="c-41486181">[-]</label><label class="expand" for="c-41486181">[3 more]</label></div><br/><div class="children"><div class="content">&gt; A good solution is to create a newer protocol when the limits of an existing protcol are exceeded.<p>It’s not clear to me how this is different to what’s happening. Is your objection that they did it on top of UDP instead of inventing a new transport layer?</div><br/><div id="41486323" class="c"><input type="checkbox" id="c-41486323" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41485296">root</a><span>|</span><a href="#41486181">parent</a><span>|</span><a href="#41486174">next</a><span>|</span><label class="collapse" for="c-41486323">[-]</label><label class="expand" for="c-41486323">[2 more]</label></div><br/><div class="children"><div class="content">No, actually what I mean was that QUIC being a protocol on UDP was intended to take advantage of the speed of UDP to do things faster that some TCP protocols did. While the merit is there the optimizations done on TCP itself has drastically improved the performance of TCP based protocols. UDP is still exceptional but it is like using a crowbar to open bottle. Not exactly the tool intended for the purpose.<p>Creating a new protocol starting from scratch would be better effort spent. A QUICv2 is on the way. <a href="https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;rfc9369&#x2F;" rel="nofollow">https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;rfc9369&#x2F;</a><p>I don&#x27;t think it addresses the problems with QUICv1 in terms of lightweight performance and bandwidth which the post claims QUIC lacks.</div><br/><div id="41486600" class="c"><input type="checkbox" id="c-41486600" checked=""/><div class="controls bullet"><span class="by">Veserv</span><span>|</span><a href="#41485296">root</a><span>|</span><a href="#41486323">parent</a><span>|</span><a href="#41486174">next</a><span>|</span><label class="collapse" for="c-41486600">[-]</label><label class="expand" for="c-41486600">[1 more]</label></div><br/><div class="children"><div class="content">QUICv2 is not really a new standard. It explicitly exists merely to intentionally rearrange some fields to prevent standard hardcoding&#x2F;ossification and exercise the version negotiation logic of implementations. It says so right in the abstract:<p>“Its purpose is to combat various ossification vectors and exercise the version negotiation framework.”</div><br/></div></div></div></div></div></div><div id="41486174" class="c"><input type="checkbox" id="c-41486174" checked=""/><div class="controls bullet"><span class="by">likis</span><span>|</span><a href="#41485296">root</a><span>|</span><a href="#41486018">parent</a><span>|</span><a href="#41486181">prev</a><span>|</span><label class="collapse" for="c-41486174">[-]</label><label class="expand" for="c-41486174">[2 more]</label></div><br/><div class="children"><div class="content">You posted your opinion without any kind of accompanying argument, and it was also quite unclear what you meant. Whining about being a target and being downvoted is not really going to help your case.<p>I initially understood your first post as: &quot;Let&#x27;s not try to make the internet faster&quot;<p>With this reply, you are clarifying your initial post that was very unclear.
Now I understand it as:<p>&quot;Let&#x27;s not try to make existing protocols faster, let&#x27;s make new protocols instead&quot;</div><br/><div id="41486366" class="c"><input type="checkbox" id="c-41486366" checked=""/><div class="controls bullet"><span class="by">Sparkyte</span><span>|</span><a href="#41485296">root</a><span>|</span><a href="#41486174">parent</a><span>|</span><label class="collapse" for="c-41486366">[-]</label><label class="expand" for="c-41486366">[1 more]</label></div><br/><div class="children"><div class="content">More that if a protocol has met it&#x27;s limit and you are at a dead end it is better to build a new one from the ground up. Making the internet faster is great but you eventually hit a wall. You need to be creative and come up with better solutions.<p>In fact our modern network infrastructure returns on designs intended for limited network performance. Our networks are fiber and 5g which are roughly 170,000 times faster and wider since the initial inception of the internet.<p>Time for a QUICv2<p><a href="https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;rfc9369&#x2F;" rel="nofollow">https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;rfc9369&#x2F;</a><p>But I don&#x27;t think it addresses the disparity between it and lightweight protocols as networks get faster.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>