<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1733734861769" as="style"/><link rel="stylesheet" href="styles.css?v=1733734861769"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://alok.github.io/2024/09/28/discontinuous-derivative/">Derivative at a Discontinuity</a> <span class="domain">(<a href="https://alok.github.io">alok.github.io</a>)</span></div><div class="subtext"><span>yuppiemephisto</span> | <span>34 comments</span></div><br/><div><div id="42362120" class="c"><input type="checkbox" id="c-42362120" checked=""/><div class="controls bullet"><span class="by">mturmon</span><span>|</span><a href="#42362949">next</a><span>|</span><label class="collapse" for="c-42362120">[-]</label><label class="expand" for="c-42362120">[3 more]</label></div><br/><div class="children"><div class="content">I really appreciated this piece. Thank you to OP for writing and submitting it.<p>The thing that piqued my interest was the side remark that the Dirac delta is a “distribution“, and that this is an unfortunate name clash with the same concept in probability (measure theory).<p>My training (in EE) used both Dirac delta “functions” (in signal processing) and distributions in the sense of measure theory (in estimation theory). Really two separate forks of coursework.<p>I had always thought that the use of delta functions in convolution integrals (signal processing) was ultimately justified by measure theory — the same machinery as I learned (with some effort) when I took measure theoretic probability.<p>But, as flagged by the OP, that is not the case! Mind blown.<p>Some of this is the result of the way these concepts are taught. There is some hand waving both in signal processing, and in estimation theory, when these difficult functions and integrals come up.<p>I’m not aware of signal processing courses (probably graduate level) in which convolution against delta “functions” uses the distribution concept. There are indeed words to the effect of either,<p>- Dirac delta is not a function, but think of it as a limit of increasingly-concentrated Gaussians;<p>- use of Dirac delta is ok, because we don’t need to represent it directly, only the result of an inner product against a smooth function (i.e., a convolution)<p>But these excuses are not rigorously justified, even at the graduate level, in my experience.<p>*<p>Separately from that, I wonder if OP has ever seen the book Radically Elementary Probability Theory, by Edward Nelson (<a href="https:&#x2F;&#x2F;web.math.princeton.edu&#x2F;~nelson&#x2F;books&#x2F;rept.pdf" rel="nofollow">https:&#x2F;&#x2F;web.math.princeton.edu&#x2F;~nelson&#x2F;books&#x2F;rept.pdf</a>). It uses nonstandard analysis to get around a lot of the (elegant) fussiness of measure theory.<p>The preface alone is fun to read.</div><br/><div id="42362837" class="c"><input type="checkbox" id="c-42362837" checked=""/><div class="controls bullet"><span class="by">creata</span><span>|</span><a href="#42362120">parent</a><span>|</span><a href="#42362949">next</a><span>|</span><label class="collapse" for="c-42362837">[-]</label><label class="expand" for="c-42362837">[2 more]</label></div><br/><div class="children"><div class="content">&gt; But these excuses are not rigorously justified, even at the graduate level, in my experience.<p>Imo, the informal use is already pretty close to the formal definition. Formally, a distribution is <i>defined</i> purely by its inner products against certain smooth functions (usually the ones with compact support) which is what the OP alluded to when he said:<p>&gt; The formal definition of a generalized function is: an element of the continuous dual space of a space of smooth functions.<p>That &quot;element of the continuous dual space&quot; is just a function that takes in a smooth function with compact support f, and returns what we take to be the inner product of f with our generalized function.<p>So (again, imo) &quot;we don’t need to represent it directly, only the result of an inner product against a smooth function&quot; isn&#x27;t <i>that</i> distant to the formal definition.</div><br/><div id="42363594" class="c"><input type="checkbox" id="c-42363594" checked=""/><div class="controls bullet"><span class="by">mturmon</span><span>|</span><a href="#42362120">root</a><span>|</span><a href="#42362837">parent</a><span>|</span><a href="#42362949">next</a><span>|</span><label class="collapse" for="c-42363594">[-]</label><label class="expand" for="c-42363594">[1 more]</label></div><br/><div class="children"><div class="content">I hear you, and I admit I&#x27;m drawing a fuzzy line (is the conventional approach “rigorous”).<p>Here are two “test functions”-<p>- we learned much about impulse responses, and sometimes considered responses to dipoles, etc. However, if I read the Wikipedia article correctly (it’s not great…), the theory implies that a distribution (in the technical sense) has derivatives of any order. I’m not sure I really knew that I could count on that. A rigorous treatment would have given me that assurance.<p>- if I understand correctly, the concept of introducing an impulse to a system that has an identity impulse response, which implies an inner product of delta with itself, is not well-defined. Again, I’m not sure if we covered that concept. (Admittedly, it’s been a long time.)</div><br/></div></div></div></div></div></div><div id="42362949" class="c"><input type="checkbox" id="c-42362949" checked=""/><div class="controls bullet"><span class="by">tzs</span><span>|</span><a href="#42362120">prev</a><span>|</span><a href="#42322495">next</a><span>|</span><label class="collapse" for="c-42362949">[-]</label><label class="expand" for="c-42362949">[1 more]</label></div><br/><div class="children"><div class="content">Differentiation turns out to be a deeper subject than most people expect even if you just stick to the ordinary real numbers rather than venturing into things like hyperreals.<p>I once saw in an elementary calculus book a note after the proof of a theorem about differentiation that the converse of the theorem was also true but needed more advanced techniques than were covered in the book.<p>I checked the advanced calculus and real analysis books I had and they didn&#x27;t have the proof.<p>I then did some searching and found mention of a book titled &quot;Differentiation&quot; (or something similar) and found a site that had scans for the first chapter of that book. It proved the theorem on something like page 6 and I couldn&#x27;t understand it at all. Starting from the beginning I think I got through maybe a page or two before it got to my deep with my mere bachelor&#x27;s degree in mathematics level of preparation.<p>I kind of wish I&#x27;d bought a copy of that book. I&#x27;ve never since been able to find it. I&#x27;ve found other books with the same or similar title but they weren&#x27;t it.</div><br/></div></div><div id="42322495" class="c"><input type="checkbox" id="c-42322495" checked=""/><div class="controls bullet"><span class="by">dhosek</span><span>|</span><a href="#42362949">prev</a><span>|</span><a href="#42322361">next</a><span>|</span><label class="collapse" for="c-42322495">[-]</label><label class="expand" for="c-42322495">[15 more]</label></div><br/><div class="children"><div class="content">One minor nit: A function can be differentiable at <i>a</i> and discontinuous at <i>a</i> even with the standard definition of the derivative. A trivial example would be the function <i>f</i>(<i>x</i>) = (<i>x</i>²-1)&#x2F;(<i>x</i>-1) which is undefined at <i>x</i>=1, but <i>f</i>&#x27;(1)=1 (in fact derivatives have exactly this sort of discontinuity in them which is why they’re defined via limits). In complex analysis, this sort of “hole” in the function is called a removable singularity¹ which is one of three types of singularities that show up in complex functions.<p>⸻<p>1. Yes, this is mathematically the reason why black holes are referred to as singularities.</div><br/><div id="42323025" class="c"><input type="checkbox" id="c-42323025" checked=""/><div class="controls bullet"><span class="by">bikenaga</span><span>|</span><a href="#42322495">parent</a><span>|</span><a href="#42362371">next</a><span>|</span><label class="collapse" for="c-42323025">[-]</label><label class="expand" for="c-42323025">[11 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not understanding what you&#x27;re saying. The standard definition of the derivative of f at c is<p>f&#x27;(c) = lim_{h → 0} (f(c + h) - f(c))&#x2F;h<p>The definition would not make sense if f wasn&#x27;t defined at c (note the &quot;f(c)&quot; in the numerator). For instance, it can&#x27;t be applied to your f(x) = (x² - 1)&#x2F;(x - 1) at x = 1, because f(1) is not defined.<p>And it&#x27;s a standard result (even stated in Calc 1 classes) that if a function is differentiable at a point, then it&#x27;s continuous there. For example:<p>5.2 Theorem. Let f be defined on [a, b]. If f is differentiable at a point x ∈ [a, b], then f is continuous at x.<p>(Walter Rudin, &quot;Principles of Mathematical Analysis&quot;, 3rd edition, p. 104)<p>Or:<p>Theorem 2.1 If f is differentiable at x = a, then f is continuous at x = a.<p>(Robert Smith and Roland Minton, &quot;Calculus -Early Transcendentals&quot;, 4th edition, p. 140)<p>It&#x27;s true that your f(x) = (x² - 1)&#x2F;(x - 1) has a removable discontinuity at x = 1, since if we define g(x) = f(x) for x ≠ 1 and g(1) = 2, then g is continuous. Was this what you meant?</div><br/><div id="42323316" class="c"><input type="checkbox" id="c-42323316" checked=""/><div class="controls bullet"><span class="by">terminalbraid</span><span>|</span><a href="#42322495">root</a><span>|</span><a href="#42323025">parent</a><span>|</span><a href="#42323904">next</a><span>|</span><label class="collapse" for="c-42323316">[-]</label><label class="expand" for="c-42323316">[1 more]</label></div><br/><div class="children"><div class="content">This is correct.  You cannot have a discontinuity with any accepted definition of a derivative (and your definition is explicit about this:  the value f(c) must exist).   Just allowing the limits on both sides to be equal already has a mathematical definition which is that of a functional limit, the function in this case being (f(x) - flim(c))&#x2F; (x-c) where flim(c) is the value of a (different) functional limit of f(x): x-&gt;c (as f(c) doesn&#x27;t exist).<p>and yes, by defining a new function with that hole explicitly filled in with a defined value to make it continuous is the typical prescription.  It does <i>not</i> imply the derivative exists for the other function as the other post posits.</div><br/></div></div><div id="42323904" class="c"><input type="checkbox" id="c-42323904" checked=""/><div class="controls bullet"><span class="by">dwattttt</span><span>|</span><a href="#42322495">root</a><span>|</span><a href="#42323025">parent</a><span>|</span><a href="#42323316">prev</a><span>|</span><a href="#42331537">next</a><span>|</span><label class="collapse" for="c-42323904">[-]</label><label class="expand" for="c-42323904">[3 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Classification_of_discontinuities" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Classification_of_discontinu...</a> is responsive and quite accessible. It notes that there doesn&#x27;t have to be an undefined point for a function to be discontinuous (and that terminology often conflates the two), and matches what I recall of determining that if the limit of the derivative from both sides of the discontinuity exists and is equal, the derivative exists.</div><br/><div id="42324218" class="c"><input type="checkbox" id="c-42324218" checked=""/><div class="controls bullet"><span class="by">bikenaga</span><span>|</span><a href="#42322495">root</a><span>|</span><a href="#42323904">parent</a><span>|</span><a href="#42331537">next</a><span>|</span><label class="collapse" for="c-42324218">[-]</label><label class="expand" for="c-42324218">[2 more]</label></div><br/><div class="children"><div class="content">&gt; ... there doesn&#x27;t have to be an undefined point for a function to be discontinuous.<p>That&#x27;s right. In the example f(x) = (x² - 1)&#x2F;(x - 1) for x ≠ 1, if we further define f(1) = 0, the function is now defined at x = 1, but discontinuous there.<p>&gt; ... if the limit of the derivative from both sides of the discontinuity exists and is equal, the derivative exists.<p>(You probably mean &quot;both sides of the point&quot;, since if there&#x27;s a discontinuity there the derivative can&#x27;t exist.) Your point that, if the left and right-hand  limits both exist and are equal, then the derivative exists (and equals their common value) is true for all limits.<p>Also, there&#x27;s a difference between the use of the word &quot;continuous&quot; in calc courses and in topology. In calc courses where functions tend to take real numbers to real numbers, a function may be said to be &quot;not continuous&quot; at a point where it isn&#x27;t defined. So f(x) = 1&#x2F;(x - 2) is &quot;not continuous at 2&quot;. But in topology, you only consider continuity for points in the domain of the function. So since the (natural) domain of f(x) = 1&#x2F;(x - 2) is x ≠ 2, the function is continuous everywhere (that it&#x27;s defined).</div><br/><div id="42325431" class="c"><input type="checkbox" id="c-42325431" checked=""/><div class="controls bullet"><span class="by">dwattttt</span><span>|</span><a href="#42322495">root</a><span>|</span><a href="#42324218">parent</a><span>|</span><a href="#42331537">next</a><span>|</span><label class="collapse" for="c-42325431">[-]</label><label class="expand" for="c-42325431">[1 more]</label></div><br/><div class="children"><div class="content">I was actually aiming for the situation where a function is defined on all reals but still discontinuous (e.g. the piecewise function in the wiki article for the removable discontinuity). So there&#x27;s a discontinuity (x=1), however the function is defined everywhere.</div><br/></div></div></div></div></div></div><div id="42331537" class="c"><input type="checkbox" id="c-42331537" checked=""/><div class="controls bullet"><span class="by">smokedetector1</span><span>|</span><a href="#42322495">root</a><span>|</span><a href="#42323025">parent</a><span>|</span><a href="#42323904">prev</a><span>|</span><a href="#42362371">next</a><span>|</span><label class="collapse" for="c-42331537">[-]</label><label class="expand" for="c-42331537">[6 more]</label></div><br/><div class="children"><div class="content">The standard definition of a derivative c involves the assumption that f is defined at c.<p>However, you could also (probably) define the derivative as lim_{h-&gt;0} (f(c+h) - f(c-h))&#x2F;2h, so without needing f(c) to be defined. But that&#x27;s not standard.</div><br/><div id="42361884" class="c"><input type="checkbox" id="c-42361884" checked=""/><div class="controls bullet"><span class="by">JadeNB</span><span>|</span><a href="#42322495">root</a><span>|</span><a href="#42331537">parent</a><span>|</span><a href="#42361881">prev</a><span>|</span><a href="#42362371">next</a><span>|</span><label class="collapse" for="c-42361884">[-]</label><label class="expand" for="c-42361884">[4 more]</label></div><br/><div class="children"><div class="content">&gt; However, you could also (probably) define the derivative as lim_{h-&gt;0} (f(c+h) - f(c-h))&#x2F;2h, so without needing f(c) to be defined. But that&#x27;s not standard.<p>Although this gives the right answer whenever f is differentiable at c, it can wrongly think that a function is differentiable when it isn&#x27;t, as for the absolute-value function at c = 0.</div><br/><div id="42362891" class="c"><input type="checkbox" id="c-42362891" checked=""/><div class="controls bullet"><span class="by">smokedetector1</span><span>|</span><a href="#42322495">root</a><span>|</span><a href="#42361884">parent</a><span>|</span><a href="#42362371">next</a><span>|</span><label class="collapse" for="c-42362891">[-]</label><label class="expand" for="c-42362891">[3 more]</label></div><br/><div class="children"><div class="content">Good point. So this is probably one of the reasons why the version I stated isn&#x27;t used.</div><br/><div id="42363132" class="c"><input type="checkbox" id="c-42363132" checked=""/><div class="controls bullet"><span class="by">JadeNB</span><span>|</span><a href="#42322495">root</a><span>|</span><a href="#42362891">parent</a><span>|</span><a href="#42362371">next</a><span>|</span><label class="collapse" for="c-42363132">[-]</label><label class="expand" for="c-42363132">[2 more]</label></div><br/><div class="children"><div class="content">It is used, just with the caveat in mind that it may exist when the derivative doesn&#x27;t.  It is usually called the symmetric derivative (<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Symmetric_derivative" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Symmetric_derivative</a>).</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42362371" class="c"><input type="checkbox" id="c-42362371" checked=""/><div class="controls bullet"><span class="by">Tainnor</span><span>|</span><a href="#42322495">parent</a><span>|</span><a href="#42323025">prev</a><span>|</span><a href="#42322854">next</a><span>|</span><label class="collapse" for="c-42362371">[-]</label><label class="expand" for="c-42362371">[1 more]</label></div><br/><div class="children"><div class="content">&gt; this sort of “hole” in the function is called a removable singularity<p>It&#x27;s called &quot;removable&quot; because it can be removed by a continuous extension - the original function itself is still formally discontinuous (of course, one would often &quot;morally&quot; treat these as the same function, but strictly speaking they&#x27;re not). An important theorem in complex analysis is that any continuous extension at a single point is automatically a holomorphic (= complex differentiable) extension too.</div><br/></div></div><div id="42322854" class="c"><input type="checkbox" id="c-42322854" checked=""/><div class="controls bullet"><span class="by">dawnofdusk</span><span>|</span><a href="#42322495">parent</a><span>|</span><a href="#42362371">prev</a><span>|</span><a href="#42327390">next</a><span>|</span><label class="collapse" for="c-42322854">[-]</label><label class="expand" for="c-42322854">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it makes sense to allow derivatives of a function f to have a larger domain than the domain of f.<p>&gt;which is why they’re defined via limits<p>They&#x27;re defined via studying f(x+h) - f(x) with a limit h -&gt; 0. But, your example is taking two limits, h-&gt;0 and x-&gt;1, simultaneously. This is not the same thing.</div><br/></div></div><div id="42327390" class="c"><input type="checkbox" id="c-42327390" checked=""/><div class="controls bullet"><span class="by">vouaobrasil</span><span>|</span><a href="#42322495">parent</a><span>|</span><a href="#42322854">prev</a><span>|</span><a href="#42322361">next</a><span>|</span><label class="collapse" for="c-42327390">[-]</label><label class="expand" for="c-42327390">[1 more]</label></div><br/><div class="children"><div class="content">You are wrong. In order for you to make sense of what you are saying, you first must REDEFINE f(x) to be f(x) = (x^2 - 1)(x - 1) when x != 1 and define f(1) = 2. Of course, then f will be continuous at x = 1 also.<p>A function is continuous at x = a if it is differentiable at x = a.<p>You do understand the concept, but your precision in the definitions is lacking.</div><br/></div></div></div></div><div id="42322361" class="c"><input type="checkbox" id="c-42322361" checked=""/><div class="controls bullet"><span class="by">ogogmad</span><span>|</span><a href="#42322495">prev</a><span>|</span><a href="#42323132">next</a><span>|</span><label class="collapse" for="c-42322361">[-]</label><label class="expand" for="c-42322361">[5 more]</label></div><br/><div class="children"><div class="content">I think you can get a generalisation of autodiff using this idea of &quot;nonstandard real numbers&quot;: You just need a computable field with infinitesimals in it. The Levi-Civita field looks especially convenient because it&#x27;s real-closed. You might be able to get an auto-limit algorithm from it by evaluating a program infinitely close to a limit. I&#x27;m not sure if there&#x27;s a problem with numerical stability when something like division by infinitesimals gets done. Does this have something to do with how Mathematica and other CASes take limits of algebraic expressions?<p>-----<p>Concerning the Dirac delta example: I think this is probably a pleasant way of using a sequence of better and better approximations to the Dirac delta. Terry Tao has some nice blog posts where he shows that a lot of NSA can be translated into sequences, either in a high-powered way using ultrafilters, or in an elementary way using passage to convergent subsequences where necessary.<p>An interesting question is: What does distribution theory really accomplish? Why is it useful? I have an idea myself but I think it&#x27;s an interesting question.</div><br/><div id="42337164" class="c"><input type="checkbox" id="c-42337164" checked=""/><div class="controls bullet"><span class="by">srean</span><span>|</span><a href="#42322361">parent</a><span>|</span><a href="#42326261">next</a><span>|</span><label class="collapse" for="c-42337164">[-]</label><label class="expand" for="c-42337164">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think this is probably a pleasant way of using a sequence of better and better approximations to the Dirac delta.<p>That can give wrong answers because derivative of the limit is not always the limit of the derivative.<p>When modeling phenomena with Dirac delta, I think the question becomes do I really need a discontinuity to have a useful model or can I get away with smoothening the discontinuity out.</div><br/></div></div><div id="42326261" class="c"><input type="checkbox" id="c-42326261" checked=""/><div class="controls bullet"><span class="by">srean</span><span>|</span><a href="#42322361">parent</a><span>|</span><a href="#42337164">prev</a><span>|</span><a href="#42323132">next</a><span>|</span><label class="collapse" for="c-42326261">[-]</label><label class="expand" for="c-42326261">[3 more]</label></div><br/><div class="children"><div class="content">Thanks a bunch for pointing me towards Levi-Civita field. Where can I learn more ? Any pedagogic text ?</div><br/><div id="42336509" class="c"><input type="checkbox" id="c-42336509" checked=""/><div class="controls bullet"><span class="by">yuppiemephisto</span><span>|</span><a href="#42322361">root</a><span>|</span><a href="#42326261">parent</a><span>|</span><a href="#42323132">next</a><span>|</span><label class="collapse" for="c-42336509">[-]</label><label class="expand" for="c-42336509">[2 more]</label></div><br/><div class="children"><div class="content">See my code at the end. The Wikipedia article is pretty good too. I can send you more if you like.</div><br/><div id="42337137" class="c"><input type="checkbox" id="c-42337137" checked=""/><div class="controls bullet"><span class="by">srean</span><span>|</span><a href="#42322361">root</a><span>|</span><a href="#42336509">parent</a><span>|</span><a href="#42323132">next</a><span>|</span><label class="collapse" for="c-42337137">[-]</label><label class="expand" for="c-42337137">[1 more]</label></div><br/><div class="children"><div class="content">Found it, thanks.</div><br/></div></div></div></div></div></div></div></div><div id="42323132" class="c"><input type="checkbox" id="c-42323132" checked=""/><div class="controls bullet"><span class="by">plus</span><span>|</span><a href="#42322361">prev</a><span>|</span><a href="#42322644">next</a><span>|</span><label class="collapse" for="c-42323132">[-]</label><label class="expand" for="c-42323132">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve personally always thought of the Dirac delta function as being the limit of a Gaussian with variance approaching 0. From this perspective, the Heaviside step function is a limit of the error function. I feel the error function and logistic function approaches <i>should</i> be equivalent, though I haven&#x27;t worked through to math to show it rigorously.</div><br/><div id="42336526" class="c"><input type="checkbox" id="c-42336526" checked=""/><div class="controls bullet"><span class="by">yuppiemephisto</span><span>|</span><a href="#42323132">parent</a><span>|</span><a href="#42322644">next</a><span>|</span><label class="collapse" for="c-42336526">[-]</label><label class="expand" for="c-42336526">[1 more]</label></div><br/><div class="children"><div class="content">All these would be infinitely close in the nonstandard characterization. I just picked logistic because it was easy and step is discontinuous so it shows off the approach’s power. If I started with delta instead I would have done Gaussian and integrated that and ended up with erf.</div><br/></div></div></div></div><div id="42322644" class="c"><input type="checkbox" id="c-42322644" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#42323132">prev</a><span>|</span><a href="#42362989">next</a><span>|</span><label class="collapse" for="c-42322644">[-]</label><label class="expand" for="c-42322644">[4 more]</label></div><br/><div class="children"><div class="content">Hm. Back when I was working on game physics engines this might have been useful.<p>In impulse&#x2F;constraint mechanics, when two objects collide, their momentum changes in zero time. An impulse is an infinite force applied over zero time with finite energy transfer. You have to integrate over that to get the new velocity. This is done as a special case. It is messy for multi-body collisions, and is hard to make work with a friction model. This is why large objects in video games bounce like small ones, changing direction in zero time.<p>I wonder if nonstandard analysis might help.</div><br/><div id="42322679" class="c"><input type="checkbox" id="c-42322679" checked=""/><div class="controls bullet"><span class="by">ogogmad</span><span>|</span><a href="#42322644">parent</a><span>|</span><a href="#42362289">next</a><span>|</span><label class="collapse" for="c-42322679">[-]</label><label class="expand" for="c-42322679">[1 more]</label></div><br/><div class="children"><div class="content">The following is just my opinion:<p>Integration can be done with its own special arithmetic: Interval arithmetic. I base this suggestion on the fact that this is apparently the only way of automatically getting error bounds on integrals. It&#x27;s cool that it works.<p>NSA does not work with a computable field so it&#x27;s not directly useful. But at the end of the article, there&#x27;s a link to some code that uses the Levi-Civita field, which is a &quot;nice&quot; approximation to NSA because it&#x27;s computable and still real-closed. You might be able to do an &quot;auto-limit&quot; using it, in a kind of generalisation of automatic differentiation. This might for instance turn one numerical algorithm, like Householder QR, into another one, like Gaussian elimination, by taking an appropriate limit.<p>I don&#x27;t know if these two things interact well in practice: Levi-Civita for algebraic limits and interval arithmetic for integrals. They might! This might suggest rather provocatively that integration is only clumsily interpreted as a limit of some function. Finally tbh, I&#x27;m not sure if this is the best solution to the friction&#x2F;collision detection problem you&#x27;re describing.</div><br/></div></div><div id="42362289" class="c"><input type="checkbox" id="c-42362289" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#42322644">parent</a><span>|</span><a href="#42322679">prev</a><span>|</span><a href="#42329179">next</a><span>|</span><label class="collapse" for="c-42362289">[-]</label><label class="expand" for="c-42362289">[1 more]</label></div><br/><div class="children"><div class="content">Making it work in finite but short time should fix that. A large object generally can deform a larger distance. This makes all collisions inelastic, with large ones being different than small ones.<p>If you can get realistic billiards breaks, you&#x27;re on the right track.</div><br/></div></div><div id="42329179" class="c"><input type="checkbox" id="c-42329179" checked=""/><div class="controls bullet"><span class="by">lupire</span><span>|</span><a href="#42322644">parent</a><span>|</span><a href="#42362289">prev</a><span>|</span><a href="#42362989">next</a><span>|</span><label class="collapse" for="c-42329179">[-]</label><label class="expand" for="c-42329179">[1 more]</label></div><br/><div class="children"><div class="content">Nonstandard analysis is the mathematical description of your special case. Same thing.</div><br/></div></div></div></div><div id="42362989" class="c"><input type="checkbox" id="c-42362989" checked=""/><div class="controls bullet"><span class="by">chii</span><span>|</span><a href="#42322644">prev</a><span>|</span><a href="#42362636">next</a><span>|</span><label class="collapse" for="c-42362989">[-]</label><label class="expand" for="c-42362989">[1 more]</label></div><br/><div class="children"><div class="content">Wow, it never occurred to me that the step function and the dirac delta are related in this way! but now that i see it, it&#x27;s obvious!<p>I&#x27;ve never learnt this level of maths formally, but it&#x27;s been an interest of mine on and off. And this post explained it very well, and pretty understandably for the laymen.</div><br/></div></div><div id="42362636" class="c"><input type="checkbox" id="c-42362636" checked=""/><div class="controls bullet"><span class="by">shwouchk</span><span>|</span><a href="#42362989">prev</a><span>|</span><a href="#42363730">next</a><span>|</span><label class="collapse" for="c-42362636">[-]</label><label class="expand" for="c-42362636">[1 more]</label></div><br/><div class="children"><div class="content">It is an interesting piece but to claim that no heavy machinery is used is a bit disingenuous at best. You have defined some purely algebraic operation “differentiation”. This operation involves a choice of infinitesimal. Is it trivial to show that the definition is independent of infinitesimal? especially if we are deriving at a hyperreal point? I doubt it and likely you would need to do more complicated set theoretic limits rather analytic limits. How do you calculate the integral of this function? Or even define it? Or rather functions, since it’s an infinite family of logistic functions? To even properly define this space you need to go quite heavily into set theory and i doubt many would find it simpler, even than working with distributions</div><br/></div></div><div id="42363730" class="c"><input type="checkbox" id="c-42363730" checked=""/><div class="controls bullet"><span class="by">thaumasiotes</span><span>|</span><a href="#42362636">prev</a><span>|</span><label class="collapse" for="c-42363730">[-]</label><label class="expand" for="c-42363730">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The Number of Pieces an Integral is Cut Into<p>&gt; You’re probably familiar with the idea that each piece has infinitesimal width, but what about the question of ‘how MANY pieces are there?’. The answer to that is a hypernatural number. Let’s call it N again.<p>Is that right? I thought there was an important theorem specifying that no matter the infinitesimal width of an integral slice, the total area will be in the neighborhood of (= infinitely close to) the same real number, which is the value of the integral. That&#x27;s why we don&#x27;t have to specify the value of dx when integrating over dx... right?</div><br/></div></div></div></div></div></div></div></body></html>