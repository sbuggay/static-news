<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1711270853153" as="style"/><link rel="stylesheet" href="styles.css?v=1711270853153"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://newsroom.ucla.edu/releases/speaking-without-vocal-cords-ucla-engineering-wearable-tech">Speaking without vocal cords, thanks to a new AI-assisted wearable device</a> <span class="domain">(<a href="https://newsroom.ucla.edu">newsroom.ucla.edu</a>)</span></div><div class="subtext"><span>geox</span> | <span>8 comments</span></div><br/><div><div id="39805720" class="c"><input type="checkbox" id="c-39805720" checked=""/><div class="controls bullet"><span class="by">tbenst</span><span>|</span><a href="#39805404">next</a><span>|</span><label class="collapse" for="c-39805720">[-]</label><label class="expand" for="c-39805720">[1 more]</label></div><br/><div class="children"><div class="content">This is a super cool device. Note that the decoding is highly limited: they decode into one of five different sentences. This is easier than five words for example as there is more information to distinguish.<p>Unfortunately the media is blowing this way of out proportion as the larynx alone does not contain sufficient information to decode silent speech.<p>If you also sense the lips, tongue articulators, and jaw, then general English decoding becomes possible with high accuracy (eg see our recent work here: <a href="https:&#x2F;&#x2F;x.com&#x2F;tbenst&#x2F;status&#x2F;1767952614157848859" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;tbenst&#x2F;status&#x2F;1767952614157848859</a>). It’s not in the preprint but I’ve done experiments with only the larynx recorded and performance is pretty abysmal on even a 10 word vocabulary—-hence why they did a five sentence task.</div><br/></div></div><div id="39805404" class="c"><input type="checkbox" id="c-39805404" checked=""/><div class="controls bullet"><span class="by">zharknado</span><span>|</span><a href="#39805720">prev</a><span>|</span><a href="#39805305">next</a><span>|</span><label class="collapse" for="c-39805404">[-]</label><label class="expand" for="c-39805404">[1 more]</label></div><br/><div class="children"><div class="content">Very cool! This is an insanely impressive sensor, but the proposed application is still in dream phase.<p>&gt; Going forward, the research team plans to continue enlarging the vocabulary of the device through machine learning and to test it in people with speech disorders.<p>They haven’t tried giving it to a person with a voice disorder. So it just might not work in that application at all. That will likely depend on the degree to which laryngeal muscles are implicated in a given person’s disorder.<p>That’s certainly a valid starting place for research purposes, but it’s very early days.<p>And I imagine you’ll need some very interesting cabling attached to a somewhat beefy device to actually run live inference from this data, plus to drive the speech synthesis.</div><br/></div></div><div id="39805305" class="c"><input type="checkbox" id="c-39805305" checked=""/><div class="controls bullet"><span class="by">khimaros</span><span>|</span><a href="#39805404">prev</a><span>|</span><a href="#39805414">next</a><span>|</span><label class="collapse" for="c-39805305">[-]</label><label class="expand" for="c-39805305">[4 more]</label></div><br/><div class="children"><div class="content">i&#x27;m really excited to see progress being made in this space. subvocal speech recognition seems to be an underfunded area of research.<p>my sense is that it has the potential to make hands free interaction with our devices in public spaces less obnoxious and, consequently, more socially acceptable.<p>however, i notice that the article doesn&#x27;t mention anything about dictionary size, which is a very important consideration for a tool of this kind.</div><br/><div id="39805410" class="c"><input type="checkbox" id="c-39805410" checked=""/><div class="controls bullet"><span class="by">dontreact</span><span>|</span><a href="#39805305">parent</a><span>|</span><a href="#39805353">next</a><span>|</span><label class="collapse" for="c-39805410">[-]</label><label class="expand" for="c-39805410">[1 more]</label></div><br/><div class="children"><div class="content">While subvocal is cool and would allow for speech in more places, something that’s earlier on the tech tree and that I would like to see is just robust lipreading.<p>I already am comfortable talking to my phone quietly using my AirPods while looking at my screen, but it seems like in loud public places the accuracy becomes unusable. I imagine it could be easily recovered by the additional signal of lipreading.</div><br/></div></div><div id="39805353" class="c"><input type="checkbox" id="c-39805353" checked=""/><div class="controls bullet"><span class="by">thorum</span><span>|</span><a href="#39805305">parent</a><span>|</span><a href="#39805410">prev</a><span>|</span><a href="#39805349">next</a><span>|</span><label class="collapse" for="c-39805353">[-]</label><label class="expand" for="c-39805353">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The research team demonstrated the system’s accuracy by having the participants pronounce five sentences — both aloud and voicelessly — including “Hi, Rachel, how are you doing today?” and “I love you!” (…) Going forward, the research team plans to continue enlarging the vocabulary of the device through machine learning and to test it in people with speech disorders.<p>It&#x27;s a proof of concept at this stage but very cool.</div><br/></div></div><div id="39805349" class="c"><input type="checkbox" id="c-39805349" checked=""/><div class="controls bullet"><span class="by">graphe</span><span>|</span><a href="#39805305">parent</a><span>|</span><a href="#39805353">prev</a><span>|</span><a href="#39805414">next</a><span>|</span><label class="collapse" for="c-39805349">[-]</label><label class="expand" for="c-39805349">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Basic_english" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Basic_english</a> this communicates English efficiently with 850 words. I don&#x27;t think it&#x27;s basic English is any good but I can see them making simplified English the lingua franca to boost &#x27;literacy rates&#x27; in the future.</div><br/></div></div></div></div><div id="39805414" class="c"><input type="checkbox" id="c-39805414" checked=""/><div class="controls bullet"><span class="by">anonylizard</span><span>|</span><a href="#39805305">prev</a><span>|</span><label class="collapse" for="c-39805414">[-]</label><label class="expand" for="c-39805414">[1 more]</label></div><br/><div class="children"><div class="content">This seems only useful to people who once had a voice, then lost their voice. Because only this way, would they have a unified mapping of voice cord movements to actual voices. Deaf and mutes can&#x27;t really use this.<p>It also basically mandates a patch to your throat, because no way of detecting vibrations otherwise.<p>I wonder if there are visual based ways, like sign-&gt;text, expression-&gt;text, that would benefit from the larger developments in LLMs. Like an LLM that has access to your conversation history, so when you give your smartphone camera a hand sign and a smile, it can guess and output an entire intended speech.</div><br/></div></div></div></div></div></div></div></body></html>