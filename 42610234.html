<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1736240477098" as="style"/><link rel="stylesheet" href="styles.css?v=1736240477098"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://wiredream.com/llm-optimizing-digit-diff/">LLMs and Code Optimization</a>Â <span class="domain">(<a href="https://wiredream.com">wiredream.com</a>)</span></div><div class="subtext"><span>dgacmu</span> | <span>9 comments</span></div><br/><div><div id="42618457" class="c"><input type="checkbox" id="c-42618457" checked=""/><div class="controls bullet"><span class="by">emeryberger</span><span>|</span><a href="#42619295">next</a><span>|</span><label class="collapse" for="c-42618457">[-]</label><label class="expand" for="c-42618457">[3 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  One major limitation the LLM has is that it can&#x27;t run a profiler on the code, 
  but we can. (This would be a fun thing to do in the future - feed the output
  of perf to the LLM and say &#x27;now optimize&#x27;).
</code></pre>
This has been a feature of the Scalene Python profiler (<a href="https:&#x2F;&#x2F;github.com&#x2F;plasma-umass&#x2F;scalene">https:&#x2F;&#x2F;github.com&#x2F;plasma-umass&#x2F;scalene</a>) for some time (at this point, about 1.5 years) - bring your own API key for OpenAI &#x2F; Azure &#x2F; Bedrock, also works with Ollama. Optimizing Python code to use NumPy or other similar native libraries can easily yield multiple order of magnitude improvements in real-world settings. We tried it on several of the success stories of Scalene (before the integration with LLMs); see <a href="https:&#x2F;&#x2F;github.com&#x2F;plasma-umass&#x2F;scalene&#x2F;issues&#x2F;58">https:&#x2F;&#x2F;github.com&#x2F;plasma-umass&#x2F;scalene&#x2F;issues&#x2F;58</a> - and found that it often automatically yielded the same or better optimizations - see <a href="https:&#x2F;&#x2F;github.com&#x2F;plasma-umass&#x2F;scalene&#x2F;issues&#x2F;554">https:&#x2F;&#x2F;github.com&#x2F;plasma-umass&#x2F;scalene&#x2F;issues&#x2F;554</a>. (Full disclosure: I am one of the principal designers of Scalene.)</div><br/><div id="42619679" class="c"><input type="checkbox" id="c-42619679" checked=""/><div class="controls bullet"><span class="by">jmathai</span><span>|</span><a href="#42618457">parent</a><span>|</span><a href="#42618496">next</a><span>|</span><label class="collapse" for="c-42619679">[-]</label><label class="expand" for="c-42619679">[1 more]</label></div><br/><div class="children"><div class="content">This same approach can work for eliminating errors in LLM generated code. We&#x27;ve had good luck doing it with Lattice [1] going from 5% to 90% success rate of creating a fully functional application.<p>I&#x27;m drafting a blog post that talks about how but for now the documentation will have to do.<p>[1] <a href="https:&#x2F;&#x2F;withlattice.com&#x2F;documentation" rel="nofollow">https:&#x2F;&#x2F;withlattice.com&#x2F;documentation</a></div><br/></div></div></div></div><div id="42619295" class="c"><input type="checkbox" id="c-42619295" checked=""/><div class="controls bullet"><span class="by">joshka</span><span>|</span><a href="#42618457">prev</a><span>|</span><a href="#42619344">next</a><span>|</span><label class="collapse" for="c-42619295">[-]</label><label class="expand" for="c-42619295">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I think it&#x27;s revealing how limited the LLMs were in algorithmically optimizing this problem vs approaches like &quot;add some parallelism&quot; or &quot;use numpy&quot;, for which they were quite decent in Python and somewhat less decent in Rust. It&#x27;s surprising to me that unless I prompted it overly-specifically, GPT 4o didn&#x27;t suggest using a faster rand implementation, as that was a pretty effective, easy step.<p>As a human performing optimization one of the steps might be to generate a list of candidate optimizations. After that you might explore each idea in parallel. By using the LLM iteratively, you&#x27;re side stepping that approach and constraining the LLM to instead picking a certain optimization first and then build on that. So one cure might be to adjust your prompt and iteration strategy to take into account that there are multiple candidate solutions rather than just one. This leads to more of an agentic &#x2F; chain approach than a completions approach to the task though.<p>The other missing part of this is that each time you optimize the code (even if it&#x27;s a failure), you learn something more about the optimization. Again this context seems missing when the LLM looks at the code (unless that history is provided in CoPilot completions automatically - it probably depends on what approach you&#x27;re taking there).<p>I wonder if there are any AI tools out there doing context + planning + history + RAG + test + evaluation + tool use + feedback approaches. I&#x27;ve seen various tools do 2-3 of those. It&#x27;s not a stretch to think that we might eventually see tools that start to emulate more of the developer inner loops.</div><br/><div id="42619661" class="c"><input type="checkbox" id="c-42619661" checked=""/><div class="controls bullet"><span class="by">kiratp</span><span>|</span><a href="#42619295">parent</a><span>|</span><a href="#42619344">next</a><span>|</span><label class="collapse" for="c-42619661">[-]</label><label class="expand" for="c-42619661">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder if there are any AI tools out there doing context + planning + history + RAG + test + evaluation + tool use + feedback approaches. I&#x27;ve seen various tools do 2-3 of those. It&#x27;s not a stretch to think that we might eventually see tools that start to emulate more of the developer inner loops.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;cline&#x2F;cline">https:&#x2F;&#x2F;github.com&#x2F;cline&#x2F;cline</a></div><br/></div></div></div></div><div id="42619344" class="c"><input type="checkbox" id="c-42619344" checked=""/><div class="controls bullet"><span class="by">mkagenius</span><span>|</span><a href="#42619295">prev</a><span>|</span><label class="collapse" for="c-42619344">[-]</label><label class="expand" for="c-42619344">[3 more]</label></div><br/><div class="children"><div class="content">I think there is a much simpler explanation behind this: training data.<p>Llms have had truck load of training on normal code than a super optimized ones.<p>That&#x27;s why you will see it struggle with nginx configs. And on newer technology where there is less amount of data available.</div><br/><div id="42619781" class="c"><input type="checkbox" id="c-42619781" checked=""/><div class="controls bullet"><span class="by">jasfi</span><span>|</span><a href="#42619344">parent</a><span>|</span><a href="#42619619">next</a><span>|</span><label class="collapse" for="c-42619781">[-]</label><label class="expand" for="c-42619781">[1 more]</label></div><br/><div class="children"><div class="content">Refining and adding to the text and code they train on is a major area of focus at the moment. Things will definitely get better, but it will take time.</div><br/></div></div><div id="42619619" class="c"><input type="checkbox" id="c-42619619" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#42619344">parent</a><span>|</span><a href="#42619781">prev</a><span>|</span><label class="collapse" for="c-42619619">[-]</label><label class="expand" for="c-42619619">[1 more]</label></div><br/><div class="children"><div class="content">If they trained an LLM on demoscene entries, maybe the results could be better, but I doubt by much.</div><br/></div></div></div></div></div></div></div></div></div></body></html>