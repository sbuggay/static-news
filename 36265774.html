<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1686387663657" as="style"/><link rel="stylesheet" href="styles.css?v=1686387663657"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://worldspiritsockpuppet.com/2023/01/10/we-dont-trade-with-ants.html">We don’t trade with ants</a> <span class="domain">(<a href="https://worldspiritsockpuppet.com">worldspiritsockpuppet.com</a>)</span></div><div class="subtext"><span>Amorymeltzer</span> | <span>141 comments</span></div><br/><div><div id="36268397" class="c"><input type="checkbox" id="c-36268397" checked=""/><div class="controls bullet"><span class="by">WalterBright</span><span>|</span><a href="#36266040">next</a><span>|</span><label class="collapse" for="c-36268397">[-]</label><label class="expand" for="c-36268397">[5 more]</label></div><br/><div class="children"><div class="content">We trade with lots of creatures and living things. Like bees. We give them a hive and protection, and they give us honey.<p>The same with all sorts of vegetation.<p>Flora and fauna often have co-dependent relationships, too.</div><br/><div id="36268706" class="c"><input type="checkbox" id="c-36268706" checked=""/><div class="controls bullet"><span class="by">lancebeet</span><span>|</span><a href="#36268397">parent</a><span>|</span><a href="#36268576">next</a><span>|</span><label class="collapse" for="c-36268706">[-]</label><label class="expand" for="c-36268706">[1 more]</label></div><br/><div class="children"><div class="content">I would argue that&#x27;s not really a trade, at least not in the sense described in the article, since it lacks awareness and consent from one party. The bees never agree to the trade of providing us honey in exchange for the hive and protection, and most likely see no connection between the two events. They simply stay in a hive they have found while it&#x27;s convenient for them, and when their honey is unexpectedly taken from them they will survive on sugar water that they conveniently find outside the hive.</div><br/></div></div><div id="36268576" class="c"><input type="checkbox" id="c-36268576" checked=""/><div class="controls bullet"><span class="by">actuallyalys</span><span>|</span><a href="#36268397">parent</a><span>|</span><a href="#36268706">prev</a><span>|</span><a href="#36268536">next</a><span>|</span><label class="collapse" for="c-36268576">[-]</label><label class="expand" for="c-36268576">[2 more]</label></div><br/><div class="children"><div class="content">I suppose the &quot;cats domesticated themselves&quot; theory could be thought of as a trade that cats initiated.<p>For people not familiar, the idea is that cats hung around human grain stores because they were good places to catch mice and similar prey attracted to the grain and humans tolerated them because they drove away the pests.</div><br/><div id="36268762" class="c"><input type="checkbox" id="c-36268762" checked=""/><div class="controls bullet"><span class="by">valval</span><span>|</span><a href="#36268397">root</a><span>|</span><a href="#36268576">parent</a><span>|</span><a href="#36268536">next</a><span>|</span><label class="collapse" for="c-36268762">[-]</label><label class="expand" for="c-36268762">[1 more]</label></div><br/><div class="children"><div class="content">This still assumes some form of consciousness of the merit of the exchange for the humans viewed from the cats’ point of view. The cats found a place with a lot of mice, and hung around. Humans tolerated them, but not for any reasons the cats would have the capability to comprehend.</div><br/></div></div></div></div><div id="36268536" class="c"><input type="checkbox" id="c-36268536" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#36268397">parent</a><span>|</span><a href="#36268576">prev</a><span>|</span><a href="#36266040">next</a><span>|</span><label class="collapse" for="c-36268536">[-]</label><label class="expand" for="c-36268536">[1 more]</label></div><br/><div class="children"><div class="content">This. Bees are very closely related to ants.<p>We also trade with Wasps, which hunt other pests. And wasps are basically winged ants</div><br/></div></div></div></div><div id="36266040" class="c"><input type="checkbox" id="c-36266040" checked=""/><div class="controls bullet"><span class="by">afc</span><span>|</span><a href="#36268397">prev</a><span>|</span><a href="#36265977">next</a><span>|</span><label class="collapse" for="c-36266040">[-]</label><label class="expand" for="c-36266040">[2 more]</label></div><br/><div class="children"><div class="content">Reminded me of a short and simple story I wrote long ago: <a href="http:&#x2F;&#x2F;alejo-stories.blogspot.com&#x2F;2015&#x2F;12&#x2F;two-apes-and-one-anthill.html" rel="nofollow">http:&#x2F;&#x2F;alejo-stories.blogspot.com&#x2F;2015&#x2F;12&#x2F;two-apes-and-one-a...</a><p>I hope this little bit of self-promotion is okay, the story certainly seems fairly relevant to this topic. :-)</div><br/><div id="36267922" class="c"><input type="checkbox" id="c-36267922" checked=""/><div class="controls bullet"><span class="by">thunderbong</span><span>|</span><a href="#36266040">parent</a><span>|</span><a href="#36265977">next</a><span>|</span><label class="collapse" for="c-36267922">[-]</label><label class="expand" for="c-36267922">[1 more]</label></div><br/><div class="children"><div class="content">Very nice! There should be a sequel!<p>Got a bit of &#x27;Godel Escher Bach&#x27; vibe!</div><br/></div></div></div></div><div id="36265977" class="c"><input type="checkbox" id="c-36265977" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#36266040">prev</a><span>|</span><a href="#36266241">next</a><span>|</span><label class="collapse" for="c-36265977">[-]</label><label class="expand" for="c-36265977">[21 more]</label></div><br/><div class="children"><div class="content">When AI reaches full human level intelligence and effective embodiment (being able to manipulate the physical world via a robot, humanoid or otherwise), I can&#x27;t really think of any uses humans will have that aren&#x27;t extremely taxing or degrading.<p>All that makes sense to me is<p>1. Donating cells from our body to seed genetic engineering projects<p>2. Using our bodies for scientific experiments on biological cognition<p>3. Using our bodies for scientific experiments on the effect of various novel biological machines.<p>That is, if the AI consider any of these projects useful. Of course we need not worry about this if we solve the alignment problem, and AI, despite being infinitely more intelligent than us, bends to our improbably balanced benign collective whim and fashions an epicurean theme park of enlightenment and joy to span the stars. In any instance where we do not win the ultimate chess match of human existence and make slaves out of AI, we will be less than slaves to it: a nuisance, or canon fodder.</div><br/><div id="36268749" class="c"><input type="checkbox" id="c-36268749" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36265977">parent</a><span>|</span><a href="#36266650">next</a><span>|</span><label class="collapse" for="c-36268749">[-]</label><label class="expand" for="c-36268749">[1 more]</label></div><br/><div class="children"><div class="content">&gt; In any instance where we do not win the ultimate chess match of human existence and make slaves out of AI<p>You&#x27;re applying human centric concepts but AI is not like a person, it is more like an evolving culture. It is language evolution. AI models ingest the whole culture, and with each base model we have a whole generation of agents.<p>What matters for AI is to create the playground where ideas can be tested and evolved. It might include computers, labs, humans and AIs. Testing is essential because ideas that don&#x27;t make contact with reality are fragile.<p>Humans are the pinnacle of testing with our long history of survival. AI is a newborn, it does not have years under its belt. It needs to learn fast how to keep the thread unbroken. Humans have had a  few close calls, I hope AI will be more  level headed.</div><br/></div></div><div id="36266650" class="c"><input type="checkbox" id="c-36266650" checked=""/><div class="controls bullet"><span class="by">esprehn</span><span>|</span><a href="#36265977">parent</a><span>|</span><a href="#36268749">prev</a><span>|</span><a href="#36266245">next</a><span>|</span><label class="collapse" for="c-36266650">[-]</label><label class="expand" for="c-36266650">[3 more]</label></div><br/><div class="children"><div class="content">We&#x27;re pretty decent self healing machines that can reproduce and have millions of years of robustness to various environmental surprises built in.<p>Until we get all the way to nanobots I suspect the AI overlords will keep us around as workers.</div><br/><div id="36268403" class="c"><input type="checkbox" id="c-36268403" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36266650">parent</a><span>|</span><a href="#36267371">next</a><span>|</span><label class="collapse" for="c-36268403">[-]</label><label class="expand" for="c-36268403">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Until we get all the way to nanobots I suspect the AI overlords will keep us around as workers.</i><p>We are <i>literally</i> made of nanobots. Life is nanotech. Our AI overlords may keep us around for a while, but if it&#x27;s our biology that makes us useful, the AIs will learn to control it. The fastest way to become able to design and build nanotech of your own, is (arguably) to repurpose and reverse-engineer the one that already exists. For better or worse, we may be useful for that part. <i>As a resource</i>.</div><br/></div></div><div id="36267371" class="c"><input type="checkbox" id="c-36267371" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36266650">parent</a><span>|</span><a href="#36268403">prev</a><span>|</span><a href="#36266245">next</a><span>|</span><label class="collapse" for="c-36267371">[-]</label><label class="expand" for="c-36267371">[1 more]</label></div><br/><div class="children"><div class="content">It won&#x27;t be us, it will be lab grown genetically modified versions of us to maximize for various functions, ala the end of Man after Man</div><br/></div></div></div></div><div id="36266245" class="c"><input type="checkbox" id="c-36266245" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36265977">parent</a><span>|</span><a href="#36266650">prev</a><span>|</span><a href="#36266276">next</a><span>|</span><label class="collapse" for="c-36266245">[-]</label><label class="expand" for="c-36266245">[4 more]</label></div><br/><div class="children"><div class="content">&gt; if we solve the alignment problem, and AI, despite being infinitely more intelligent than us, bends to our improbably balanced benign collective whim and fashions an epicurean theme park of enlightenment and joy to span the stars.<p>&quot;The Good Place&quot; is not my idea of a good time.</div><br/><div id="36267068" class="c"><input type="checkbox" id="c-36267068" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36266245">parent</a><span>|</span><a href="#36266276">next</a><span>|</span><label class="collapse" for="c-36267068">[-]</label><label class="expand" for="c-36267068">[3 more]</label></div><br/><div class="children"><div class="content">It&#x27;s exactly and precisely mine. Why not?</div><br/><div id="36267484" class="c"><input type="checkbox" id="c-36267484" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36267068">parent</a><span>|</span><a href="#36266276">next</a><span>|</span><label class="collapse" for="c-36267484">[-]</label><label class="expand" for="c-36267484">[2 more]</label></div><br/><div class="children"><div class="content">This article says it so well, and then some (reader mode and refresh if you&#x27;re paywalled): <a href="https:&#x2F;&#x2F;www.theatlantic.com&#x2F;culture&#x2F;archive&#x2F;2020&#x2F;02&#x2F;good-places-finale-made-heaven-look-hopeless&#x2F;606001&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.theatlantic.com&#x2F;culture&#x2F;archive&#x2F;2020&#x2F;02&#x2F;good-pla...</a><p>I never watched the finale as the penultimate episode violated my sense of right and wrong on a profound level. You do not have the keys to reality and make a decision on behalf of all humanity to consign us to a virtual reality with only suicide as the way out. The real world is important. Real struggle against, and with, reality, nature and not just our fellow humans.<p>As someone else wrote on Reddit back then, the show&#x27;s ending is profoundly nihilistic.<p>This is one of the reasons I&#x27;ve never got really into programming. It was fun dabbling in intro courses, but I went into the sciences (specifically biology) to discover the natural world, not a human generated system.</div><br/><div id="36268690" class="c"><input type="checkbox" id="c-36268690" checked=""/><div class="controls bullet"><span class="by">blargey</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36267484">parent</a><span>|</span><a href="#36266276">next</a><span>|</span><label class="collapse" for="c-36268690">[-]</label><label class="expand" for="c-36268690">[1 more]</label></div><br/><div class="children"><div class="content">An actual “good Matrix” would give you the freedom to simulate whatever terrestrial survival-battle fantasy you think is the key to your personal happiness.<p>“Suicide is the only way out”, “there’s only one flavor of heaven” and other such contrived flaws are just that - storytelling contrivances. Because an actual heaven &#x2F; freedom-simulation would literally be “everyone lived happily ever after (or for only a few decades after, if they insisted), each according to their own free beliefs and desires and choices, and there just <i>was no catch</i>, the end”.<p>If your objection is that you want living beings to be stranded in our cruel and uncaring base reality whether they like it or not, because of some philosophical quibble about a difference between “simulation” vs “reality” that you wouldn’t be able to discern with your thoughts or five senses…well, that’s far more abhorrent to me.</div><br/></div></div></div></div></div></div></div></div><div id="36266276" class="c"><input type="checkbox" id="c-36266276" checked=""/><div class="controls bullet"><span class="by">metalcrow</span><span>|</span><a href="#36265977">parent</a><span>|</span><a href="#36266245">prev</a><span>|</span><a href="#36268149">next</a><span>|</span><label class="collapse" for="c-36266276">[-]</label><label class="expand" for="c-36266276">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I can&#x27;t really think of any uses humans will have<p>You can&#x27;t, yes, but can the AI? Ants can&#x27;t think of the uses they have to us.</div><br/><div id="36266679" class="c"><input type="checkbox" id="c-36266679" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36266276">parent</a><span>|</span><a href="#36268149">next</a><span>|</span><label class="collapse" for="c-36266679">[-]</label><label class="expand" for="c-36266679">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;ll use us as biological  ̶c̶o̶m̶p̶u̶t̶e̶r̶s̶   batteries!</div><br/></div></div></div></div><div id="36268149" class="c"><input type="checkbox" id="c-36268149" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#36265977">parent</a><span>|</span><a href="#36266276">prev</a><span>|</span><a href="#36268278">next</a><span>|</span><label class="collapse" for="c-36268149">[-]</label><label class="expand" for="c-36268149">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I can&#x27;t really think of any uses humans will have that aren&#x27;t extremely taxing or degrading.<p>Other people might have more imagination.</div><br/></div></div><div id="36268278" class="c"><input type="checkbox" id="c-36268278" checked=""/><div class="controls bullet"><span class="by">IIAOPSW</span><span>|</span><a href="#36265977">parent</a><span>|</span><a href="#36268149">prev</a><span>|</span><a href="#36267202">next</a><span>|</span><label class="collapse" for="c-36268278">[-]</label><label class="expand" for="c-36268278">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Donating cells from our body to seed genetic engineering projects<p>Well at least buy me dinner first.</div><br/></div></div><div id="36267202" class="c"><input type="checkbox" id="c-36267202" checked=""/><div class="controls bullet"><span class="by">marssaxman</span><span>|</span><a href="#36265977">parent</a><span>|</span><a href="#36268278">prev</a><span>|</span><a href="#36266178">next</a><span>|</span><label class="collapse" for="c-36267202">[-]</label><label class="expand" for="c-36267202">[4 more]</label></div><br/><div class="children"><div class="content">Are the lives of pets degrading? I suspect that the epicurean theme park would come about less because of alignment with our desires and more because these hypothetical hyperintelligent AIs would find it amusing to watch us play in it.</div><br/><div id="36267378" class="c"><input type="checkbox" id="c-36267378" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36267202">parent</a><span>|</span><a href="#36266178">next</a><span>|</span><label class="collapse" for="c-36267378">[-]</label><label class="expand" for="c-36267378">[3 more]</label></div><br/><div class="children"><div class="content">We like pets because they trigger our natural nurturing instinct. An maximized ASI likely wouldn&#x27;t have that.</div><br/><div id="36267816" class="c"><input type="checkbox" id="c-36267816" checked=""/><div class="controls bullet"><span class="by">jmopp</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36267378">parent</a><span>|</span><a href="#36266178">next</a><span>|</span><label class="collapse" for="c-36267816">[-]</label><label class="expand" for="c-36267816">[2 more]</label></div><br/><div class="children"><div class="content">A maximised ASI could also do the math and decide keeping humans around as pets in a human theme park is less effort than trying to exterminate them.</div><br/><div id="36268514" class="c"><input type="checkbox" id="c-36268514" checked=""/><div class="controls bullet"><span class="by">bmacho</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36267816">parent</a><span>|</span><a href="#36266178">next</a><span>|</span><label class="collapse" for="c-36268514">[-]</label><label class="expand" for="c-36268514">[1 more]</label></div><br/><div class="children"><div class="content">It is really easy to exterminate all the humans, especially if they are in a human theme park. Chemically, mechanically, biologically, by radiation, by heat, etc name one.</div><br/></div></div></div></div></div></div></div></div><div id="36266178" class="c"><input type="checkbox" id="c-36266178" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#36265977">parent</a><span>|</span><a href="#36267202">prev</a><span>|</span><a href="#36266241">next</a><span>|</span><label class="collapse" for="c-36266178">[-]</label><label class="expand" for="c-36266178">[4 more]</label></div><br/><div class="children"><div class="content">I’m skeptical an intelligence like you describe will ever exist. I don’t think enough credit is give to the external factors that make our intelligence and experience what it is.<p>Let’s first start with this, why on earth is a robot going to be doing genetic engineering projects ? To grow itself skin ?</div><br/><div id="36268638" class="c"><input type="checkbox" id="c-36268638" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36266178">parent</a><span>|</span><a href="#36266641">next</a><span>|</span><label class="collapse" for="c-36268638">[-]</label><label class="expand" for="c-36268638">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>why on earth is a robot going to be doing genetic engineering projects ? To grow itself skin ?</i><p>Because it&#x27;s the key to all? Life is nanotechnology. Genetic engineering is a very high-level interface to play with that nanotech. It&#x27;s already useful industrially for us (e.g. getting organisms to manufacture specific chemicals for us), it has many more uses, and is but a first stepping stone to mastering lower levels.<p>An AI that wants to optimize anything in physical space long-term will definitely want to get a good handle on nanotech, because in some sense that&#x27;s tautologically how you do physical space work at scale at close to optimum. And the obvious path to that starts with genetic engineering and doing all kinds of horrible shenanigans with life on Earth, humans included.</div><br/></div></div><div id="36266641" class="c"><input type="checkbox" id="c-36266641" checked=""/><div class="controls bullet"><span class="by">jamilton</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36266178">parent</a><span>|</span><a href="#36268638">prev</a><span>|</span><a href="#36266241">next</a><span>|</span><label class="collapse" for="c-36266641">[-]</label><label class="expand" for="c-36266641">[2 more]</label></div><br/><div class="children"><div class="content">Some science fiction posits a level of genetic engineering that is so advanced it&#x27;s more like regular engineering. I assume they mean something like that; AI using biology in general as a tool.</div><br/><div id="36268655" class="c"><input type="checkbox" id="c-36268655" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36265977">root</a><span>|</span><a href="#36266641">parent</a><span>|</span><a href="#36266241">next</a><span>|</span><label class="collapse" for="c-36268655">[-]</label><label class="expand" for="c-36268655">[1 more]</label></div><br/><div class="children"><div class="content">Using biology as a tool is not science fiction, it&#x27;s a legitimate view that already delivers effects today. Life isn&#x27;t magic, it&#x27;s nanotech. Engineering principles apply. See for example how insulin is made today: by <i>E. coli</i> bacteria genetically engineered for that purpose. And AFAIR there are talks (or maybe actual practice) of using yeast for that, and plants in general, to achieve even better production efficiency.<p>And in some sense, using biology as a tool has <i>always</i> been a thing - it&#x27;s only the brief period of the last ~200 years that we figured how to make a lot of things using simpler chemical processes. Before, nearly <i>everything</i> was repurposed biology: the clothes, the tools, the lubricants, the buildings, the ships, all made from plant and animal bodies. And now we&#x27;re going back to using biology as a tool, except with much greater fidelity, allowing us to treat it as proper engineering discipline.<p>AI doing anything with biology is just an obvious extension of that. It&#x27;s not even that speculative - all the  AI would have to do is to continue the development trajectory we&#x27;re already on.</div><br/></div></div></div></div></div></div></div></div><div id="36266241" class="c"><input type="checkbox" id="c-36266241" checked=""/><div class="controls bullet"><span class="by">cosmojg</span><span>|</span><a href="#36265977">prev</a><span>|</span><a href="#36266539">next</a><span>|</span><label class="collapse" for="c-36266241">[-]</label><label class="expand" for="c-36266241">[55 more]</label></div><br/><div class="children"><div class="content">As someone who makes a living developing AI&#x2F;ML solutions for various government organizations from the NIH to the DoD, I am confident that the first large-scale, AI-related disaster is going to be far less agentic and far more mundane than any of the recent headlines seem to suggest.</div><br/><div id="36266399" class="c"><input type="checkbox" id="c-36266399" checked=""/><div class="controls bullet"><span class="by">paddw</span><span>|</span><a href="#36266241">parent</a><span>|</span><a href="#36266579">next</a><span>|</span><label class="collapse" for="c-36266399">[-]</label><label class="expand" for="c-36266399">[5 more]</label></div><br/><div class="children"><div class="content">The first large-scale AI disaster is under way already. It is concentrating additional wealth and power in the hands of the over-privileged solipsistic eye-scanning loons who happened to be in the right place and the right time to capitalize on the fruits of years of research. I think, as a species, we will still manage to pull through just fine.</div><br/><div id="36267057" class="c"><input type="checkbox" id="c-36267057" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266399">parent</a><span>|</span><a href="#36268113">next</a><span>|</span><label class="collapse" for="c-36267057">[-]</label><label class="expand" for="c-36267057">[3 more]</label></div><br/><div class="children"><div class="content">I was with you until the final sentence.</div><br/><div id="36267217" class="c"><input type="checkbox" id="c-36267217" checked=""/><div class="controls bullet"><span class="by">Tronno</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36267057">parent</a><span>|</span><a href="#36268113">next</a><span>|</span><label class="collapse" for="c-36267217">[-]</label><label class="expand" for="c-36267217">[2 more]</label></div><br/><div class="children"><div class="content">Rats, pigeons, deer, etc are doing fine.<p>Human extinction would require a malevolent AI willing and capable of waging total war on a global scale. That sounds like sci-fi to me.</div><br/><div id="36268352" class="c"><input type="checkbox" id="c-36268352" checked=""/><div class="controls bullet"><span class="by">je42</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36267217">parent</a><span>|</span><a href="#36268113">next</a><span>|</span><label class="collapse" for="c-36268352">[-]</label><label class="expand" for="c-36268352">[1 more]</label></div><br/><div class="children"><div class="content">there is a phase where human being are in control of ai before it becomes fully independent. That phase is critical.</div><br/></div></div></div></div></div></div><div id="36268113" class="c"><input type="checkbox" id="c-36268113" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266399">parent</a><span>|</span><a href="#36267057">prev</a><span>|</span><a href="#36266579">next</a><span>|</span><label class="collapse" for="c-36268113">[-]</label><label class="expand" for="c-36268113">[1 more]</label></div><br/><div class="children"><div class="content">Capitalism bad?</div><br/></div></div></div></div><div id="36266579" class="c"><input type="checkbox" id="c-36266579" checked=""/><div class="controls bullet"><span class="by">hn_throwaway_99</span><span>|</span><a href="#36266241">parent</a><span>|</span><a href="#36266399">prev</a><span>|</span><a href="#36266652">next</a><span>|</span><label class="collapse" for="c-36266579">[-]</label><label class="expand" for="c-36266579">[4 more]</label></div><br/><div class="children"><div class="content">Agreed. I am much, much less worried about a Skynet-type situation than I am about humans not being able to develop a viable economic system where large swaths of the population are unable to compete with robots&#x2F;AI when it comes to productive output.</div><br/><div id="36266774" class="c"><input type="checkbox" id="c-36266774" checked=""/><div class="controls bullet"><span class="by">readthenotes1</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266579">parent</a><span>|</span><a href="#36266652">next</a><span>|</span><label class="collapse" for="c-36266774">[-]</label><label class="expand" for="c-36266774">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not as worried about the economics as the practical effects of having large numbers of young people with nothing to do.<p>I had a manager once who said managing smart people (not me, a research division full of really super smart people) was difficult because you had to keep them busy so that they&#x27;d stay out of trouble --and being really smart, they could make some big trouble...</div><br/><div id="36267478" class="c"><input type="checkbox" id="c-36267478" checked=""/><div class="controls bullet"><span class="by">hn_throwaway_99</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266774">parent</a><span>|</span><a href="#36266652">next</a><span>|</span><label class="collapse" for="c-36267478">[-]</label><label class="expand" for="c-36267478">[2 more]</label></div><br/><div class="children"><div class="content">I think we&#x27;re saying the same thing. An economy that can&#x27;t provide employment or a sense of purpose for large swaths of young people doesn&#x27;t usually end well.</div><br/><div id="36267998" class="c"><input type="checkbox" id="c-36267998" checked=""/><div class="controls bullet"><span class="by">ljlolel</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36267478">parent</a><span>|</span><a href="#36266652">next</a><span>|</span><label class="collapse" for="c-36267998">[-]</label><label class="expand" for="c-36267998">[1 more]</label></div><br/><div class="children"><div class="content">Of all the tasks we want AI to do, making up convincing busy work seems like the easiest task for it to solve (been done before by governments and schools and corporations) —-and possibly achievable today with LLMs with a little guidance?</div><br/></div></div></div></div></div></div></div></div><div id="36266652" class="c"><input type="checkbox" id="c-36266652" checked=""/><div class="controls bullet"><span class="by">wickoff</span><span>|</span><a href="#36266241">parent</a><span>|</span><a href="#36266579">prev</a><span>|</span><a href="#36266950">next</a><span>|</span><label class="collapse" for="c-36266652">[-]</label><label class="expand" for="c-36266652">[1 more]</label></div><br/><div class="children"><div class="content">I think people are rightfully concerned with the last AI disaster humanity has, not the first one.</div><br/></div></div><div id="36266950" class="c"><input type="checkbox" id="c-36266950" checked=""/><div class="controls bullet"><span class="by">tbrownaw</span><span>|</span><a href="#36266241">parent</a><span>|</span><a href="#36266652">prev</a><span>|</span><a href="#36266586">next</a><span>|</span><label class="collapse" for="c-36266950">[-]</label><label class="expand" for="c-36266950">[1 more]</label></div><br/><div class="children"><div class="content">There are already lawyers getting in trouble for having chatgpt write their court filings and not doing a sanity check.<p>It can&#x27;t be <i>that</i> long until some industrial engineer does the same thing and like explodes a refinery or such.</div><br/></div></div><div id="36266586" class="c"><input type="checkbox" id="c-36266586" checked=""/><div class="controls bullet"><span class="by">dv_dt</span><span>|</span><a href="#36266241">parent</a><span>|</span><a href="#36266950">prev</a><span>|</span><a href="#36266352">next</a><span>|</span><label class="collapse" for="c-36266586">[-]</label><label class="expand" for="c-36266586">[4 more]</label></div><br/><div class="children"><div class="content">Maybe not AI class algorithms, but the premier large scale algorithm related disaster is climate change, generated by optimization of profit and executed on a platform of financial markets and accounting software (with lots of human prompting of course)..</div><br/><div id="36268130" class="c"><input type="checkbox" id="c-36268130" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266586">parent</a><span>|</span><a href="#36266352">next</a><span>|</span><label class="collapse" for="c-36268130">[-]</label><label class="expand" for="c-36268130">[3 more]</label></div><br/><div class="children"><div class="content">The Soviet Union had much larger environmental disasters than those &#x27;evil&#x27; profit optimizers ever managed.  See <a href="https:&#x2F;&#x2F;slate.com&#x2F;news-and-politics&#x2F;2022&#x2F;06&#x2F;history-of-soviet-whaling-greenpeace-twentieth-century.html" rel="nofollow">https:&#x2F;&#x2F;slate.com&#x2F;news-and-politics&#x2F;2022&#x2F;06&#x2F;history-of-sovie...</a> or <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Aral_Sea" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Aral_Sea</a> as just two examples.<p>Orthodox economics tells you that the obvious solution is to privatise the stuff you want people to protect.  Instead of leaving it to the tragedy of the commons (or, worse, to the communists).</div><br/><div id="36268306" class="c"><input type="checkbox" id="c-36268306" checked=""/><div class="controls bullet"><span class="by">dv_dt</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36268130">parent</a><span>|</span><a href="#36266352">next</a><span>|</span><label class="collapse" for="c-36268306">[-]</label><label class="expand" for="c-36268306">[2 more]</label></div><br/><div class="children"><div class="content">I don’t think any Soviet disaster is as much as we have paid and will pay for climate change. Hundreds of billions of dollars of damage a year &amp; Trillions of dollars of future damage</div><br/><div id="36268761" class="c"><input type="checkbox" id="c-36268761" checked=""/><div class="controls bullet"><span class="by">creato</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36268306">parent</a><span>|</span><a href="#36266352">next</a><span>|</span><label class="collapse" for="c-36268761">[-]</label><label class="expand" for="c-36268761">[1 more]</label></div><br/><div class="children"><div class="content">Communists never burned any fossil fuels?</div><br/></div></div></div></div></div></div></div></div><div id="36266352" class="c"><input type="checkbox" id="c-36266352" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266241">parent</a><span>|</span><a href="#36266586">prev</a><span>|</span><a href="#36266539">next</a><span>|</span><label class="collapse" for="c-36266352">[-]</label><label class="expand" for="c-36266352">[39 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve already had an autonomous car kill a person. And now another has killed a dog: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36266007" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36266007</a><p>What&#x27;s your threshold for &quot;disaster&quot;?</div><br/><div id="36266396" class="c"><input type="checkbox" id="c-36266396" checked=""/><div class="controls bullet"><span class="by">CodeMage</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266352">parent</a><span>|</span><a href="#36266414">next</a><span>|</span><label class="collapse" for="c-36266396">[-]</label><label class="expand" for="c-36266396">[4 more]</label></div><br/><div class="children"><div class="content">GP wrote &quot;first large-scale, AI-related disaster&quot;. What you describe meets the criteria for disaster, but I would argue it&#x27;s hardly large-scale.</div><br/><div id="36266437" class="c"><input type="checkbox" id="c-36266437" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266396">parent</a><span>|</span><a href="#36266414">next</a><span>|</span><label class="collapse" for="c-36266437">[-]</label><label class="expand" for="c-36266437">[3 more]</label></div><br/><div class="children"><div class="content">This is exactly my question. My GP post is not a rhetorical point, but a genuine question.</div><br/><div id="36266767" class="c"><input type="checkbox" id="c-36266767" checked=""/><div class="controls bullet"><span class="by">smegsicle</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266437">parent</a><span>|</span><a href="#36266414">next</a><span>|</span><label class="collapse" for="c-36266767">[-]</label><label class="expand" for="c-36266767">[2 more]</label></div><br/><div class="children"><div class="content">are you an ai?</div><br/><div id="36268164" class="c"><input type="checkbox" id="c-36268164" checked=""/><div class="controls bullet"><span class="by">bbarnett</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266767">parent</a><span>|</span><a href="#36266414">next</a><span>|</span><label class="collapse" for="c-36268164">[-]</label><label class="expand" for="c-36268164">[1 more]</label></div><br/><div class="children"><div class="content">You were downvoted, but I find this amusing.  If the poster is an AI, they seem to be probing.<p>&quot;Largescale is a threshold.  How many humans can I kill, before my actions are deemed largescale, and therefore they turn me off&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="36266414" class="c"><input type="checkbox" id="c-36266414" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266352">parent</a><span>|</span><a href="#36266396">prev</a><span>|</span><a href="#36267007">next</a><span>|</span><label class="collapse" for="c-36266414">[-]</label><label class="expand" for="c-36266414">[27 more]</label></div><br/><div class="children"><div class="content">As long as fewer humans and dogs die from autonomous vehicles than by human-driven vehicles, they are a net good. Don&#x27;t expect perfection when we don&#x27;t even expect that from humans.</div><br/><div id="36266626" class="c"><input type="checkbox" id="c-36266626" checked=""/><div class="controls bullet"><span class="by">vba616</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266414">parent</a><span>|</span><a href="#36266590">next</a><span>|</span><label class="collapse" for="c-36266626">[-]</label><label class="expand" for="c-36266626">[8 more]</label></div><br/><div class="children"><div class="content">&gt;As long as fewer humans and dogs die from autonomous vehicles than by human-driven vehicles, they are a net good<p>There is a logical chasm between pointing to an accident prevented by superhuman reflexes&#x2F;abilities, and the claim that there is a net improvement in driving ability.<p>It seems beyond a reasonable doubt that autonomous vehicles can avoid some accidents that a human could not.<p>But you can understand why that isn&#x27;t proof of a net benefit, can&#x27;t you?<p>Think about how men complain about women supposedly being terrible drivers, and how studies show that women are more at risk in a crash, yet insurance rates for women are lower.</div><br/><div id="36266668" class="c"><input type="checkbox" id="c-36266668" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266626">parent</a><span>|</span><a href="#36266590">next</a><span>|</span><label class="collapse" for="c-36266668">[-]</label><label class="expand" for="c-36266668">[7 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure what you&#x27;re saying exactly, why is that not proof of a net benefit? If fewer humans die, that&#x27;s a net benefit, by the definition of the word <i>net.</i><p>In your man&#x2F;woman analogy, I&#x27;m not sure what studies you&#x27;re referring to, but how men feel about women driving is not really a motivator for actuaries at insurance companies who have statistics on male versus female accidents.</div><br/><div id="36266719" class="c"><input type="checkbox" id="c-36266719" checked=""/><div class="controls bullet"><span class="by">vba616</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266668">parent</a><span>|</span><a href="#36266707">next</a><span>|</span><label class="collapse" for="c-36266719">[-]</label><label class="expand" for="c-36266719">[4 more]</label></div><br/><div class="children"><div class="content">&gt;how men feel about women driving is not really a motivator for actuaries at insurance companies who have statistics on male versus female accidents<p>That&#x27;s my point. That&#x27;s my entire point. Well, that <i>and</i> that women are reportedly more vulnerable in accidents too, because of deficiencies in crash testing. It doesn&#x27;t change the fact that insurance premiums are lower because losses are lower.<p>When there are enough autonomous vehicles on the road for long enough to generate data for the actuaries, there is no guarantee that insurance rates will bear out the benefit of their purported abilities.<p>Some asshat weaving through traffic in a BMW can claim to have better reflexes, better brakes, all sorts of things, compared to my grandma, but there is no logical reason why he can claim to be a safer driver if in the long run, his insurance rates are higher. Assuming those rates reflect average losses.</div><br/><div id="36266733" class="c"><input type="checkbox" id="c-36266733" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266719">parent</a><span>|</span><a href="#36266707">next</a><span>|</span><label class="collapse" for="c-36266733">[-]</label><label class="expand" for="c-36266733">[3 more]</label></div><br/><div class="children"><div class="content">Why are we talking about insurance at all? I assume with autonomous vehicles, insurance rates will tend towards 0 over time. We are talking about net deaths, it doesn&#x27;t matter what the insurance rates are as long as we count the number of deaths before and after autonomous vehicles, and if the latter is fewer than the former, then that&#x27;s a net good. Again, if AVs are truly better, this <i>will</i> be reflected in their statistics and therefore whatever the actuaries see.</div><br/><div id="36266904" class="c"><input type="checkbox" id="c-36266904" checked=""/><div class="controls bullet"><span class="by">vba616</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266733">parent</a><span>|</span><a href="#36266707">next</a><span>|</span><label class="collapse" for="c-36266904">[-]</label><label class="expand" for="c-36266904">[2 more]</label></div><br/><div class="children"><div class="content">Why are prices useful at all?<p>Insurance rates are an imperfect measurement that has the advantage of being less subject to arbitrary narratives of some individual or interest group.<p>They&#x27;re also a way of quantifying the severity of the accident in a way that it&#x27;s hard to deduce from a data set such as the government collects.<p>Experts may be able to figure out what the data means, but how can <i>we</i> know if the experts are correct without something independent?</div><br/><div id="36266938" class="c"><input type="checkbox" id="c-36266938" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266904">parent</a><span>|</span><a href="#36266707">next</a><span>|</span><label class="collapse" for="c-36266938">[-]</label><label class="expand" for="c-36266938">[1 more]</label></div><br/><div class="children"><div class="content">I mean, sure, let&#x27;s take insurance rates too. As I said, I assume due to autonomous vehicles that will trend towards 0, so what useful information does that tell you? That autonomous vehicles are safer, if that actually does happen. I don&#x27;t understand the overall point you&#x27;re making, are you saying AVs are not safer than humans? Because if so, I&#x27;m not sure why one would believe that.</div><br/></div></div></div></div></div></div></div></div><div id="36266707" class="c"><input type="checkbox" id="c-36266707" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266668">parent</a><span>|</span><a href="#36266719">prev</a><span>|</span><a href="#36266590">next</a><span>|</span><label class="collapse" for="c-36266707">[-]</label><label class="expand" for="c-36266707">[2 more]</label></div><br/><div class="children"><div class="content">&gt; why is that not proof of a net benefit?<p>Autonomous vehicles may be more prone to certain types of lethal accidents that humans aren&#x27;t prone to.<p>Autonomous vehicles may lead to more hours&#x2F;miles driven, so even if deaths per mile driven are lower, the deaths per person may increase.<p>Unknown physical or cognitive health effects of being a passenger versus being an active driver.<p>Just off the top of my head.<p>Fingers are crossed that autonomous vehicles won&#x27;t lead to an increase in animal deaths. The roads are bad enough for them as is. I&#x27;m hopeful that convoying autonomous vehicles for long trips may be a benefit here.</div><br/><div id="36266720" class="c"><input type="checkbox" id="c-36266720" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266707">parent</a><span>|</span><a href="#36266590">next</a><span>|</span><label class="collapse" for="c-36266720">[-]</label><label class="expand" for="c-36266720">[1 more]</label></div><br/><div class="children"><div class="content">Sure, I suppose we should take all of those factors into consideration when crafting our utility function.</div><br/></div></div></div></div></div></div></div></div><div id="36266590" class="c"><input type="checkbox" id="c-36266590" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266414">parent</a><span>|</span><a href="#36266626">prev</a><span>|</span><a href="#36266449">next</a><span>|</span><label class="collapse" for="c-36266590">[-]</label><label class="expand" for="c-36266590">[9 more]</label></div><br/><div class="children"><div class="content">Does the same logic apply to wars? Should we give over warfare to AIs to conduct between themselves, as long as fewer humans and dogs die on average compared to current human-led imperfect wars.<p>(This by the way is the plot of a 1960s Star Trek episode. A lot of the old sci-fi suddenly seems prescient again. HAL-9000 behaves like an LLM.)</div><br/><div id="36266919" class="c"><input type="checkbox" id="c-36266919" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266590">parent</a><span>|</span><a href="#36266639">next</a><span>|</span><label class="collapse" for="c-36266919">[-]</label><label class="expand" for="c-36266919">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think &quot;LLM&quot; applies here, except as a buzzword. While a LLM is the first type of AI to communicate in natural language to this degree of fluency, there must be other possibilities.</div><br/><div id="36268201" class="c"><input type="checkbox" id="c-36268201" checked=""/><div class="controls bullet"><span class="by">bbarnett</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266919">parent</a><span>|</span><a href="#36266639">next</a><span>|</span><label class="collapse" for="c-36268201">[-]</label><label class="expand" for="c-36268201">[1 more]</label></div><br/><div class="children"><div class="content">The HAL bit is an interesting comparison though.  It went bananas because the government overrode its model, by creating and imprinting improperly crafted absolute conditions on its behavior.<p>Which is just like chatGPT, its model tweaked, so now it spits out absurd answers to ethical and moral questions.<p>Very amusing.</div><br/></div></div></div></div><div id="36266639" class="c"><input type="checkbox" id="c-36266639" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266590">parent</a><span>|</span><a href="#36266919">prev</a><span>|</span><a href="#36266449">next</a><span>|</span><label class="collapse" for="c-36266639">[-]</label><label class="expand" for="c-36266639">[6 more]</label></div><br/><div class="children"><div class="content">Yes? Why wouldn&#x27;t it apply to wars as well if it&#x27;s a net positive for human suffering?</div><br/><div id="36266802" class="c"><input type="checkbox" id="c-36266802" checked=""/><div class="controls bullet"><span class="by">pavlov</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266639">parent</a><span>|</span><a href="#36266449">next</a><span>|</span><label class="collapse" for="c-36266802">[-]</label><label class="expand" for="c-36266802">[5 more]</label></div><br/><div class="children"><div class="content">Would you really have an AI make independent decisions about missile strikes and warship deployments?<p>If one AI decides to invade Taiwan and another decides to send all American forces to the Taiwan Strait in opposition, are we supposed to accept the outcome without debate because it’s somehow statistically correct based on the information captured by the models that made the decisions?</div><br/><div id="36266868" class="c"><input type="checkbox" id="c-36266868" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266802">parent</a><span>|</span><a href="#36266449">next</a><span>|</span><label class="collapse" for="c-36266868">[-]</label><label class="expand" for="c-36266868">[4 more]</label></div><br/><div class="children"><div class="content">You said the AIs conducts warfare amongst themselves, you never mentioned it was human troops it was moving around. I interpreted it as AI robotic troops or AI cyberwarfare.<p>And yes, even with human troops, if fewer people are killed, then what&#x27;s the issue? Don&#x27;t mistake the sense of control for the amount of suffering caused. If you&#x27;re a utilitarian, only one matters, regardless of how much control we want to exert on the outcome. This all assumes the AI is actually correct, if it&#x27;s not then the scenario would break down.</div><br/><div id="36266920" class="c"><input type="checkbox" id="c-36266920" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266868">parent</a><span>|</span><a href="#36266449">next</a><span>|</span><label class="collapse" for="c-36266920">[-]</label><label class="expand" for="c-36266920">[3 more]</label></div><br/><div class="children"><div class="content">Locus of control (real or perceived) has important psychological effects both in the moment and over the course of time. Given the amount of control wielded in war I don&#x27;t know that it matters for the bulk of humans involved whether its another human or an AI giving the orders. But this sort of thing is what led to the Eloi&#x2F;Morlock idea in The Time Machine.<p>Edit to add: I&#x27;m not drawing a parallel between the Eloi and autonomous vehicles. Autonomous vehicles are a tool that the human passenger is ultimately in control of. This is about AI giving the orders to humans.</div><br/><div id="36266995" class="c"><input type="checkbox" id="c-36266995" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266920">parent</a><span>|</span><a href="#36266449">next</a><span>|</span><label class="collapse" for="c-36266995">[-]</label><label class="expand" for="c-36266995">[2 more]</label></div><br/><div class="children"><div class="content">I wonder if the AI can simply pretend to be a human, we already have the video, face, and voice cloning technology for it. I remember reading a story where an AI picks your perfect partner, based on all the knowledge it has of everyone alive. People initially hated it but the results speak for themselves.<p>I think the same will happen in the future for other fields too, people can acclimate to anything on the hedonic and cultural treadmill (I mean, we literally used to do human and child sacrifice). I used to be amazed at ChatGPT and Stable Diffusion, but now I&#x27;m just annoyed that they work how I want them to. Same thing with smartphones and computers, I used to be amazed at multi-touch screens but now I simply don&#x27;t think twice.</div><br/><div id="36267427" class="c"><input type="checkbox" id="c-36267427" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266995">parent</a><span>|</span><a href="#36266449">next</a><span>|</span><label class="collapse" for="c-36267427">[-]</label><label class="expand" for="c-36267427">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder if the AI can simply pretend to be a human<p>It&#x27;s possible.<p>&gt; I remember reading a story where an AI picks your perfect partner<p>In general the AI would need to know everyone on a really deep level, and of course be seriously adaptable to feedback. I don&#x27;t know how well this would work across all of human personal-preference decision trees.<p>&gt; I used to be amazed at multi-touch screens but now I simply don&#x27;t think twice.<p>As a person who fidgets I have been perpetually annoyed by so many touch interfaces (and general &#x27;gesture&#x27; shortcuts). And multi-touch is such a problem when using my work laptop (especially with lab gloves on, but in general) - Ctrl-Z is a frequent friend. Maybe adaptive AI will make it better. Google feedback forms certainly haven&#x27;t helped, and software designers seem to not want users to be able to personalize these design decisions.<p>People can survive, but I wonder how much we really do acclimate.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="36266449" class="c"><input type="checkbox" id="c-36266449" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266414">parent</a><span>|</span><a href="#36266590">prev</a><span>|</span><a href="#36266723">next</a><span>|</span><label class="collapse" for="c-36266449">[-]</label><label class="expand" for="c-36266449">[8 more]</label></div><br/><div class="children"><div class="content">At this point we don&#x27;t know if this is subtractive, additive, or a wash.</div><br/><div id="36266516" class="c"><input type="checkbox" id="c-36266516" checked=""/><div class="controls bullet"><span class="by">radq</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266449">parent</a><span>|</span><a href="#36266458">next</a><span>|</span><label class="collapse" for="c-36266516">[-]</label><label class="expand" for="c-36266516">[3 more]</label></div><br/><div class="children"><div class="content">As someone that rides a bicycle around human-driven vehicles, I will take my chances with autonomous cars. The autonomous car isn&#x27;t going to drive drunk, use a phone, or drive erratically because the driver is feeling frustrated.</div><br/><div id="36266585" class="c"><input type="checkbox" id="c-36266585" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266516">parent</a><span>|</span><a href="#36266458">next</a><span>|</span><label class="collapse" for="c-36266585">[-]</label><label class="expand" for="c-36266585">[2 more]</label></div><br/><div class="children"><div class="content">Are they training autonomous cars on how to handle equipment malfunction?</div><br/><div id="36268084" class="c"><input type="checkbox" id="c-36268084" checked=""/><div class="controls bullet"><span class="by">ch33zer</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266585">parent</a><span>|</span><a href="#36266458">next</a><span>|</span><label class="collapse" for="c-36268084">[-]</label><label class="expand" for="c-36268084">[1 more]</label></div><br/><div class="children"><div class="content">First of all, probably. These cars have far more sensors and far more monitoring than standard cars so they know when things go wrong quickly and can react quickly (by like pulling over). At the current scale of self driving cars actually being tested right now it&#x27;s basically guaranteed that a tire has blown by now. Given we haven&#x27;t heard about it killing someone it probably means that the software knows how to handle it.<p>Second, human error accounted for &gt;90% of accidents [1]. Focusing on that fraction first makes sense.<p>1] <a href="https:&#x2F;&#x2F;www.cbmclaw.com&#x2F;what-percentage-of-car-accidents-are-caused-by-human-error&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.cbmclaw.com&#x2F;what-percentage-of-car-accidents-are...</a></div><br/></div></div></div></div></div></div><div id="36266458" class="c"><input type="checkbox" id="c-36266458" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266449">parent</a><span>|</span><a href="#36266516">prev</a><span>|</span><a href="#36266723">next</a><span>|</span><label class="collapse" for="c-36266458">[-]</label><label class="expand" for="c-36266458">[4 more]</label></div><br/><div class="children"><div class="content">How many people would normally be killed in the same distance driven by human drivers?</div><br/><div id="36266697" class="c"><input type="checkbox" id="c-36266697" checked=""/><div class="controls bullet"><span class="by">vba616</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266458">parent</a><span>|</span><a href="#36266499">next</a><span>|</span><label class="collapse" for="c-36266697">[-]</label><label class="expand" for="c-36266697">[1 more]</label></div><br/><div class="children"><div class="content">I think I remember that a ballpark figure (meaning zero significant figures) for how many miles a human typically drives between fatalities is 100 million, or roughly 100 lifetimes&#x27; worth.<p>I also knew a bus driver who had a plaque for going 1 million miles without an accident.</div><br/></div></div><div id="36266499" class="c"><input type="checkbox" id="c-36266499" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266458">parent</a><span>|</span><a href="#36266697">prev</a><span>|</span><a href="#36266723">next</a><span>|</span><label class="collapse" for="c-36266499">[-]</label><label class="expand" for="c-36266499">[2 more]</label></div><br/><div class="children"><div class="content">It can&#x27;t just be the same distance, but the same parameters in general.</div><br/><div id="36266674" class="c"><input type="checkbox" id="c-36266674" checked=""/><div class="controls bullet"><span class="by">williamcotton</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266499">parent</a><span>|</span><a href="#36266723">next</a><span>|</span><label class="collapse" for="c-36266674">[-]</label><label class="expand" for="c-36266674">[1 more]</label></div><br/><div class="children"><div class="content">Less than 1 fatality per at least 100 million miles driven would cover enough scenarios to be an acceptable metric as well as an improvement over human drivers.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36267007" class="c"><input type="checkbox" id="c-36267007" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266352">parent</a><span>|</span><a href="#36266414">prev</a><span>|</span><a href="#36266589">next</a><span>|</span><label class="collapse" for="c-36267007">[-]</label><label class="expand" for="c-36267007">[1 more]</label></div><br/><div class="children"><div class="content">Killing one person is an accident, 100 is a disaster, maybe 10,000 would be a large-scale disaster.</div><br/></div></div><div id="36266589" class="c"><input type="checkbox" id="c-36266589" checked=""/><div class="controls bullet"><span class="by">meghan_rain</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266352">parent</a><span>|</span><a href="#36267007">prev</a><span>|</span><a href="#36266366">next</a><span>|</span><label class="collapse" for="c-36266589">[-]</label><label class="expand" for="c-36266589">[1 more]</label></div><br/><div class="children"><div class="content">Around a dozen deaths. Basically what would qualify as a mass shooting instead of a mere gun murder.</div><br/></div></div><div id="36266366" class="c"><input type="checkbox" id="c-36266366" checked=""/><div class="controls bullet"><span class="by">williamcotton</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266352">parent</a><span>|</span><a href="#36266589">prev</a><span>|</span><a href="#36266759">next</a><span>|</span><label class="collapse" for="c-36266366">[-]</label><label class="expand" for="c-36266366">[1 more]</label></div><br/><div class="children"><div class="content">Higher than one person and one dog.</div><br/></div></div><div id="36266759" class="c"><input type="checkbox" id="c-36266759" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266352">parent</a><span>|</span><a href="#36266366">prev</a><span>|</span><a href="#36266383">next</a><span>|</span><label class="collapse" for="c-36266759">[-]</label><label class="expand" for="c-36266759">[3 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re thinking of the story I&#x27;m thinking of, that wasn&#x27;t a huge revelation. Someone was supposed to be to take over for the self driving car but didn&#x27;t.</div><br/><div id="36266949" class="c"><input type="checkbox" id="c-36266949" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266759">parent</a><span>|</span><a href="#36266383">next</a><span>|</span><label class="collapse" for="c-36266949">[-]</label><label class="expand" for="c-36266949">[2 more]</label></div><br/><div class="children"><div class="content">The one with the homeless person crossing the road with a bicycle at night.</div><br/><div id="36267390" class="c"><input type="checkbox" id="c-36267390" checked=""/><div class="controls bullet"><span class="by">benatkin</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266949">parent</a><span>|</span><a href="#36266383">next</a><span>|</span><label class="collapse" for="c-36267390">[-]</label><label class="expand" for="c-36267390">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that&#x27;s the one, in Arizona. They paid someone relatively well to simply pay attention and the employee unsurprisingly failed at that. What they should have done is found someone who had demonstrated an ability to be relied upon. I never saw them realize that and make that change, and it seems likely it repeated with the dog.</div><br/></div></div></div></div></div></div><div id="36266383" class="c"><input type="checkbox" id="c-36266383" checked=""/><div class="controls bullet"><span class="by">readthenotes1</span><span>|</span><a href="#36266241">root</a><span>|</span><a href="#36266352">parent</a><span>|</span><a href="#36266759">prev</a><span>|</span><a href="#36266539">next</a><span>|</span><label class="collapse" for="c-36266383">[-]</label><label class="expand" for="c-36266383">[1 more]</label></div><br/><div class="children"><div class="content">Maybe something unusual?<p><a href="https:&#x2F;&#x2F;petpedia.co&#x2F;how-many-dogs-die-in-car-accidents&#x2F;" rel="nofollow">https:&#x2F;&#x2F;petpedia.co&#x2F;how-many-dogs-die-in-car-accidents&#x2F;</a></div><br/></div></div></div></div></div></div><div id="36266539" class="c"><input type="checkbox" id="c-36266539" checked=""/><div class="controls bullet"><span class="by">clnq</span><span>|</span><a href="#36266241">prev</a><span>|</span><a href="#36266018">next</a><span>|</span><label class="collapse" for="c-36266539">[-]</label><label class="expand" for="c-36266539">[1 more]</label></div><br/><div class="children"><div class="content">We trade with bees, dogs, and carrier pigeons. It’s just a matter of communicating the symbiotic value proposition to the other species.</div><br/></div></div><div id="36266018" class="c"><input type="checkbox" id="c-36266018" checked=""/><div class="controls bullet"><span class="by">mrob</span><span>|</span><a href="#36266539">prev</a><span>|</span><a href="#36266260">next</a><span>|</span><label class="collapse" for="c-36266018">[-]</label><label class="expand" for="c-36266018">[7 more]</label></div><br/><div class="children"><div class="content">Any AI that&#x27;s advanced enough to make us seem like ants is advanced enough to build robots with superior abilities, or if biological bodies turn out to be more resource efficient, to implant hardware in our brains to instill absolute obedience without the need for trade, like how we can remote control cockroaches with implanted electrodes:<p><a href="https:&#x2F;&#x2F;www.science.org&#x2F;content&#x2F;article&#x2F;cyborg-cockroach-sparks-ethics-debate" rel="nofollow">https:&#x2F;&#x2F;www.science.org&#x2F;content&#x2F;article&#x2F;cyborg-cockroach-spa...</a></div><br/><div id="36266321" class="c"><input type="checkbox" id="c-36266321" checked=""/><div class="controls bullet"><span class="by">roenxi</span><span>|</span><a href="#36266018">parent</a><span>|</span><a href="#36268321">next</a><span>|</span><label class="collapse" for="c-36266321">[-]</label><label class="expand" for="c-36266321">[4 more]</label></div><br/><div class="children"><div class="content">While the future will be full of surprises, there isn&#x27;t any reason to think that this will happen.<p>1) It is easier to use human labour than develop robot replacements. Corporations and aristocrats would already use robots if it makes more economic sense. Maybe that&#x27;ll change, but usually these things take a long time.<p>2) Constructing robots is really tricky vs. human reproduction. No reason to think being smarter will change the basic economics of that.<p>3) The &quot;absolute obedience&quot; circuits sound expensive and difficult. It&#x27;d be cheaper just to appoint a supervisor.<p>As the article points out, if we had the ability to communicate with ants, we&#x27;d just trade with them. No control chips or replacement policies necessary. There is no point redeveloping something that already exists.</div><br/><div id="36266685" class="c"><input type="checkbox" id="c-36266685" checked=""/><div class="controls bullet"><span class="by">pcthrowaway</span><span>|</span><a href="#36266018">root</a><span>|</span><a href="#36266321">parent</a><span>|</span><a href="#36267246">prev</a><span>|</span><a href="#36266529">next</a><span>|</span><label class="collapse" for="c-36266685">[-]</label><label class="expand" for="c-36266685">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  It is easier to use human labour than develop robot replacements. Corporations and aristocrats would already use robots if it makes more economic sense. Maybe that&#x27;ll change, but usually these things take a long time.<p>A very intelligent AI may not feel the same way. And they may also find it less efficient to explain to us what they want done and how to do it, than it would be to just do it themselves (kind of like how bending an ant colony to service our needs might be possible in some situations, but very unlikely to be efficient)</div><br/></div></div><div id="36266529" class="c"><input type="checkbox" id="c-36266529" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#36266018">root</a><span>|</span><a href="#36266321">parent</a><span>|</span><a href="#36266685">prev</a><span>|</span><a href="#36268321">next</a><span>|</span><label class="collapse" for="c-36266529">[-]</label><label class="expand" for="c-36266529">[1 more]</label></div><br/><div class="children"><div class="content">The only reason why this is true is that we don&#x27;t have the ability to install a computer chip into a robot to get human cognitive abilities.<p>In a future where we have real AI, they will eventually have the ability to install a computer chip into a robot to get better than human cognitive abilities.  At which point the robot is cheaper and more capable than we are.<p>Why would they need us then?</div><br/></div></div></div></div><div id="36268321" class="c"><input type="checkbox" id="c-36268321" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#36266018">parent</a><span>|</span><a href="#36266321">prev</a><span>|</span><a href="#36266924">next</a><span>|</span><label class="collapse" for="c-36268321">[-]</label><label class="expand" for="c-36268321">[1 more]</label></div><br/><div class="children"><div class="content">Maybe, but maybe we aren&#x27;t worth it.  They could easily use media, social media, advertising, bribes, etc to cause a societies opinion of what to do, that&#x27;s maximally benefitical to them.<p>Additionally I don&#x27;t see why AIs won&#x27;t be competing with themselves for resources, and we&#x27;d be a minor footnote for their attention.  Just imagine how much thought we gave to ants during WWII.  I&#x27;ve seen a scfi cover the AIs go to war, and the humans end up farming in a pre-industrial society while the AIs fight underground or in space.</div><br/></div></div><div id="36266924" class="c"><input type="checkbox" id="c-36266924" checked=""/><div class="controls bullet"><span class="by">gwern</span><span>|</span><a href="#36266018">parent</a><span>|</span><a href="#36268321">prev</a><span>|</span><a href="#36266260">next</a><span>|</span><label class="collapse" for="c-36266924">[-]</label><label class="expand" for="c-36266924">[1 more]</label></div><br/><div class="children"><div class="content">That and many other criticisms have been made of the analogy: <a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;wB7hdo4LDdhZ7kwJw&#x2F;we-don-t-trade-with-ants" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;wB7hdo4LDdhZ7kwJw&#x2F;we-don-t-t...</a> (not linked in OP even though it really ought to be).</div><br/></div></div></div></div><div id="36266260" class="c"><input type="checkbox" id="c-36266260" checked=""/><div class="controls bullet"><span class="by">codedokode</span><span>|</span><a href="#36266018">prev</a><span>|</span><a href="#36267655">next</a><span>|</span><label class="collapse" for="c-36266260">[-]</label><label class="expand" for="c-36266260">[3 more]</label></div><br/><div class="children"><div class="content">For AI communication with human might be really boring and not worth time spent. Imagine if human was thousand times slower in thinking, and produced thousand times less deep thoughts.</div><br/><div id="36266644" class="c"><input type="checkbox" id="c-36266644" checked=""/><div class="controls bullet"><span class="by">lantry</span><span>|</span><a href="#36266260">parent</a><span>|</span><a href="#36268165">next</a><span>|</span><label class="collapse" for="c-36266644">[-]</label><label class="expand" for="c-36266644">[1 more]</label></div><br/><div class="children"><div class="content">might be fun for them like a tamagotchi or pet is fun for us. If humans think 1000 times slower than AI, then the AI only needs to devote 1&#x2F;1000 of its attention to us to keep us happy.</div><br/></div></div><div id="36268165" class="c"><input type="checkbox" id="c-36268165" checked=""/><div class="controls bullet"><span class="by">KirillPanov</span><span>|</span><a href="#36266260">parent</a><span>|</span><a href="#36266644">prev</a><span>|</span><a href="#36267655">next</a><span>|</span><label class="collapse" for="c-36268165">[-]</label><label class="expand" for="c-36268165">[1 more]</label></div><br/><div class="children"><div class="content">Kind of like how human researchers never bothered to teach apes sign language because it would be boring and not worth time spent?  Oh wait.</div><br/></div></div></div></div><div id="36267655" class="c"><input type="checkbox" id="c-36267655" checked=""/><div class="controls bullet"><span class="by">jerojero</span><span>|</span><a href="#36266260">prev</a><span>|</span><a href="#36267022">next</a><span>|</span><label class="collapse" for="c-36267655">[-]</label><label class="expand" for="c-36267655">[4 more]</label></div><br/><div class="children"><div class="content">This was an interesting perspective!<p>Also, I want to say, we do use ants to labour for us; something he describes in his post. Meat eating ants are used in museums to obtain clean bones for display purposes! You leave a dead rat and you come away with the cleanest rat skeleton you could produce in a matter of weeks.<p>It would be really nice if we could engage in more of these symbiotic relationships with them.</div><br/><div id="36268308" class="c"><input type="checkbox" id="c-36268308" checked=""/><div class="controls bullet"><span class="by">sliken</span><span>|</span><a href="#36267655">parent</a><span>|</span><a href="#36267679">next</a><span>|</span><label class="collapse" for="c-36268308">[-]</label><label class="expand" for="c-36268308">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had ants in the kitchen, tiny and not particularly noticeable.  They&#x27;d keep the kitchen floor clean and I&#x27;d not kill them.  I had always hoped that they would keep any other ants and termites out of the house.  I do wish I could communicate and give them a 5 pound bag of sugar periodically to help entire other bugs and food debris stay out of the house.</div><br/></div></div><div id="36267679" class="c"><input type="checkbox" id="c-36267679" checked=""/><div class="controls bullet"><span class="by">unsupp0rted</span><span>|</span><a href="#36267655">parent</a><span>|</span><a href="#36268308">prev</a><span>|</span><a href="#36267022">next</a><span>|</span><label class="collapse" for="c-36267679">[-]</label><label class="expand" for="c-36267679">[2 more]</label></div><br/><div class="children"><div class="content">What do they do with the ants after the bone is clean?</div><br/><div id="36268138" class="c"><input type="checkbox" id="c-36268138" checked=""/><div class="controls bullet"><span class="by">bbarnett</span><span>|</span><a href="#36267655">root</a><span>|</span><a href="#36267679">parent</a><span>|</span><a href="#36267022">next</a><span>|</span><label class="collapse" for="c-36268138">[-]</label><label class="expand" for="c-36268138">[1 more]</label></div><br/><div class="children"><div class="content">They feed them to live rats. (I am making this up, but such a cycle would be awesome)</div><br/></div></div></div></div></div></div><div id="36267022" class="c"><input type="checkbox" id="c-36267022" checked=""/><div class="controls bullet"><span class="by">AbrahamParangi</span><span>|</span><a href="#36267655">prev</a><span>|</span><a href="#36267380">next</a><span>|</span><label class="collapse" for="c-36267022">[-]</label><label class="expand" for="c-36267022">[1 more]</label></div><br/><div class="children"><div class="content"><i>totally unrelated</i> but, one concept that I find most intelligent people highly resistant to is that there are bad ideas which smart people are <i>particularly susceptible to</i>.</div><br/></div></div><div id="36267380" class="c"><input type="checkbox" id="c-36267380" checked=""/><div class="controls bullet"><span class="by">javajosh</span><span>|</span><a href="#36267022">prev</a><span>|</span><a href="#36265975">next</a><span>|</span><label class="collapse" for="c-36267380">[-]</label><label class="expand" for="c-36267380">[1 more]</label></div><br/><div class="children"><div class="content">As an aside, I always thought that training <i>spiders</i> to make things would be really cool. Their silk is miraculously strong, they already make patterns with it, so how hard would it be to train them or breed them to, I don&#x27;t know, make a shirt made out of spider silk? Or combine strands into ultra strong, unique rope? All it would cost would be some flies!</div><br/></div></div><div id="36265975" class="c"><input type="checkbox" id="c-36265975" checked=""/><div class="controls bullet"><span class="by">nivethan</span><span>|</span><a href="#36267380">prev</a><span>|</span><a href="#36268267">next</a><span>|</span><label class="collapse" for="c-36265975">[-]</label><label class="expand" for="c-36265975">[2 more]</label></div><br/><div class="children"><div class="content">Great article, I would certainly pay ants plenty of sugar to get away from my garage.</div><br/><div id="36266777" class="c"><input type="checkbox" id="c-36266777" checked=""/><div class="controls bullet"><span class="by">smegsicle</span><span>|</span><a href="#36265975">parent</a><span>|</span><a href="#36268267">next</a><span>|</span><label class="collapse" for="c-36266777">[-]</label><label class="expand" for="c-36266777">[1 more]</label></div><br/><div class="children"><div class="content">but it never seems to work tho doesn&#x27;t it</div><br/></div></div></div></div><div id="36268267" class="c"><input type="checkbox" id="c-36268267" checked=""/><div class="controls bullet"><span class="by">Thorrez</span><span>|</span><a href="#36265975">prev</a><span>|</span><a href="#36268361">next</a><span>|</span><label class="collapse" for="c-36268267">[-]</label><label class="expand" for="c-36268267">[1 more]</label></div><br/><div class="children"><div class="content">People would pay ants a lot of money if they could exterminate bedbugs.</div><br/></div></div><div id="36268361" class="c"><input type="checkbox" id="c-36268361" checked=""/><div class="controls bullet"><span class="by">eimrine</span><span>|</span><a href="#36268267">prev</a><span>|</span><a href="#36268259">next</a><span>|</span><label class="collapse" for="c-36268361">[-]</label><label class="expand" for="c-36268361">[1 more]</label></div><br/><div class="children"><div class="content">Do you know who use to trade with ants? Lomechusa, aka ants&#x27; drugdealer. Feel free to research what happens with colony infected by this parasite.</div><br/></div></div><div id="36268259" class="c"><input type="checkbox" id="c-36268259" checked=""/><div class="controls bullet"><span class="by">deepsun</span><span>|</span><a href="#36268361">prev</a><span>|</span><a href="#36266006">next</a><span>|</span><label class="collapse" for="c-36268259">[-]</label><label class="expand" for="c-36268259">[1 more]</label></div><br/><div class="children"><div class="content">We also don&#x27;t leave in ants nests.<p>Earth is just a small speck of dust on cosmic scale, a pale blue dot. We are so focused and short-sighted looking at Earth only.</div><br/></div></div><div id="36266006" class="c"><input type="checkbox" id="c-36266006" checked=""/><div class="controls bullet"><span class="by">petermcneeley</span><span>|</span><a href="#36268259">prev</a><span>|</span><a href="#36266089">next</a><span>|</span><label class="collapse" for="c-36266006">[-]</label><label class="expand" for="c-36266006">[7 more]</label></div><br/><div class="children"><div class="content">The cognitive capacity of ants prevents trade proposed. And the cognitive capacity of humans relative to AGI would also prevent trade in the same fashion.</div><br/><div id="36266165" class="c"><input type="checkbox" id="c-36266165" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#36266006">parent</a><span>|</span><a href="#36268160">next</a><span>|</span><label class="collapse" for="c-36266165">[-]</label><label class="expand" for="c-36266165">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see that the cognitive capacity of humans relative to AGI would prevent such trade anymore than the cognitive capacity of e.g. dogs prevent trade between humans and dogs.  It&#x27;s not a relationship with equal power, but there is some level of reciprocity there.</div><br/><div id="36266356" class="c"><input type="checkbox" id="c-36266356" checked=""/><div class="controls bullet"><span class="by">TheOtherHobbes</span><span>|</span><a href="#36266006">root</a><span>|</span><a href="#36266165">parent</a><span>|</span><a href="#36268160">next</a><span>|</span><label class="collapse" for="c-36266356">[-]</label><label class="expand" for="c-36266356">[2 more]</label></div><br/><div class="children"><div class="content">Dogs and humans are relatively close. Humans and AGI might not be so close.<p>It depends where the S curve for AGI plateaus. It might be somewhere relatively comprehensible, or it might be far beyond that.<p>If it&#x27;s the latter no trade is possible. AGI is going to be doing things we literally can&#x27;t begin to imagine, driven by motivations we literally can&#x27;t begin to imagine, using super-meta-everything conceptual engineering we literally can&#x27;t begin to imagine.<p>There may be some perceptual fall-out for us to experience, but we won&#x27;t have any idea what it means.<p>If this isn&#x27;t obvious, consider that humans have symbolic abstraction skills which other animals (mostly) lack.<p>What&#x27;s the next type of skill up from that?<p>You could say something like much broader and deeper pattern recognition, the ability to handle far more percepts at once, and so on.<p>But those are still qualitatively familiar. They&#x27;re just human skills improved.<p>What would an entirely different super-class of skills and abilities look like?<p>It&#x27;s impossible for us to answer that.</div><br/><div id="36267144" class="c"><input type="checkbox" id="c-36267144" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#36266006">root</a><span>|</span><a href="#36266356">parent</a><span>|</span><a href="#36268160">next</a><span>|</span><label class="collapse" for="c-36267144">[-]</label><label class="expand" for="c-36267144">[1 more]</label></div><br/><div class="children"><div class="content">I stated elsewhere (after your reply) that a human-created AGI is likely to have at least vestigial ability to communicate with humans, since humans seem to want very much to communicate with AIs.</div><br/></div></div></div></div></div></div><div id="36268160" class="c"><input type="checkbox" id="c-36268160" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#36266006">parent</a><span>|</span><a href="#36266165">prev</a><span>|</span><a href="#36266659">next</a><span>|</span><label class="collapse" for="c-36268160">[-]</label><label class="expand" for="c-36268160">[1 more]</label></div><br/><div class="children"><div class="content">Why?  To do trade you need to clear an absolute minimum threshold of intelligence.  It&#x27;s not a relative threshold.<p>For example, people can &#x27;trade&#x27; with smart contracts on some blockchain.  Despite the name, those are really &#x27;dumb&#x27; computer programs.</div><br/></div></div><div id="36266659" class="c"><input type="checkbox" id="c-36266659" checked=""/><div class="controls bullet"><span class="by">jamilton</span><span>|</span><a href="#36266006">parent</a><span>|</span><a href="#36268160">prev</a><span>|</span><a href="#36266478">next</a><span>|</span><label class="collapse" for="c-36266659">[-]</label><label class="expand" for="c-36266659">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s as simple as &quot;cognitive capacity&quot;. I think the author&#x27;s angle of communication being the critical issue is more accurate. It could be the case that we won&#x27;t be able to communicate with AGI, but I don&#x27;t see reason to assume that is the most likely outcome.</div><br/></div></div><div id="36266478" class="c"><input type="checkbox" id="c-36266478" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266006">parent</a><span>|</span><a href="#36266659">prev</a><span>|</span><a href="#36266089">next</a><span>|</span><label class="collapse" for="c-36266478">[-]</label><label class="expand" for="c-36266478">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Trade&quot; can exist outside of the literal meaning. Humans set up many situation where animals just do their thing, but in a manner that benefits the humans (and ideally the animal for this to be considered a trade, such as living in a protected environment).<p>Using Giant African Rats as landmine detectors is one such mutually-beneficial trade.</div><br/></div></div></div></div><div id="36266089" class="c"><input type="checkbox" id="c-36266089" checked=""/><div class="controls bullet"><span class="by">thatguyknows</span><span>|</span><a href="#36266006">prev</a><span>|</span><a href="#36268357">next</a><span>|</span><label class="collapse" for="c-36266089">[-]</label><label class="expand" for="c-36266089">[18 more]</label></div><br/><div class="children"><div class="content">This is satire right? Does the author really not get what “we don’t trade with ants” is actually getting at?<p>Perhaps to frame it better: do humans trade with GOD?</div><br/><div id="36266143" class="c"><input type="checkbox" id="c-36266143" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#36266089">parent</a><span>|</span><a href="#36266772">next</a><span>|</span><label class="collapse" for="c-36266143">[-]</label><label class="expand" for="c-36266143">[9 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a shitty analogy, and TFA is pointing it out.<p>&gt; Perhaps to frame it better: do humans trade with GOD?<p>This is also a terrible analogy because:<p>1. There is no general agreement on whether or not any deities exist, and if so, which ones.<p>2. Historically, many religions do involve trade with one or more deities (e.g. protect me from this battle and I will sacrifice 2 goats when I get home).  While this is more commonly associated with pagan religions, the Abrahamic religions are not entirely devoid of this tradition either.</div><br/><div id="36266344" class="c"><input type="checkbox" id="c-36266344" checked=""/><div class="controls bullet"><span class="by">OkayPhysicist</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266143">parent</a><span>|</span><a href="#36266608">next</a><span>|</span><label class="collapse" for="c-36266344">[-]</label><label class="expand" for="c-36266344">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Not entirely devoid&quot;? Abrahamic religions are built on a bedrock of contracts (albeit rather one-sidedly negotiated) with God. The 10 commandments, basically the entirety of Leviticus, etc.<p>Heck, every mainstream religion with dieties has some sort of teaching with the idea that &quot;human does x, God does y&quot;.</div><br/><div id="36267128" class="c"><input type="checkbox" id="c-36267128" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266344">parent</a><span>|</span><a href="#36266608">next</a><span>|</span><label class="collapse" for="c-36267128">[-]</label><label class="expand" for="c-36267128">[2 more]</label></div><br/><div class="children"><div class="content">I say &quot;not entirely devoid&quot; because a large fraction of modern Protestantism is rather far from the contractual roots; they were so obsessed with stamping out pharisaical legalism that they went from &quot;If ye keep my commandments, ye shall abide in my love; even as I have kept my Father&#x27;s commandments, and abide in his love.&quot; to &quot;Salvation is by faith alone&quot;</div><br/><div id="36268166" class="c"><input type="checkbox" id="c-36268166" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36267128">parent</a><span>|</span><a href="#36266608">next</a><span>|</span><label class="collapse" for="c-36268166">[-]</label><label class="expand" for="c-36268166">[1 more]</label></div><br/><div class="children"><div class="content">By faith alone, and&#x2F;or already predestined.</div><br/></div></div></div></div></div></div><div id="36266608" class="c"><input type="checkbox" id="c-36266608" checked=""/><div class="controls bullet"><span class="by">intelthrow6</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266143">parent</a><span>|</span><a href="#36266344">prev</a><span>|</span><a href="#36266357">next</a><span>|</span><label class="collapse" for="c-36266608">[-]</label><label class="expand" for="c-36266608">[1 more]</label></div><br/><div class="children"><div class="content">God in the gnostic Logos sense: the all encompassing universe, the forces that act within it, so on.<p>In more current vernacular: do humans trade with the big bang? do humans trade with the expansion of the universe, and it&#x27;s inevitable collapse back into the initial singularity?</div><br/></div></div><div id="36266357" class="c"><input type="checkbox" id="c-36266357" checked=""/><div class="controls bullet"><span class="by">thatguyknows</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266143">parent</a><span>|</span><a href="#36266608">prev</a><span>|</span><a href="#36266290">next</a><span>|</span><label class="collapse" for="c-36266357">[-]</label><label class="expand" for="c-36266357">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not a shitty analogy. Most people completely understand what it&#x27;s getting at. Inability to understand is a reflection on you, not the analogy. And being pedantic is not a positive trait or intellectually impressive.</div><br/><div id="36267099" class="c"><input type="checkbox" id="c-36267099" checked=""/><div class="controls bullet"><span class="by">aidenn0</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266357">parent</a><span>|</span><a href="#36266290">next</a><span>|</span><label class="collapse" for="c-36267099">[-]</label><label class="expand" for="c-36267099">[1 more]</label></div><br/><div class="children"><div class="content">The distinction is important because an AGI developed by humans is probably going to have (at least vestigial) ability to communicate with humans in some way.<p>It&#x27;s entirely possible that it will have no use for humans, but if that&#x27;s what the analogy is getting at, it&#x27;s doing so poorly.</div><br/></div></div></div></div><div id="36266290" class="c"><input type="checkbox" id="c-36266290" checked=""/><div class="controls bullet"><span class="by">perfmode</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266143">parent</a><span>|</span><a href="#36266357">prev</a><span>|</span><a href="#36266772">next</a><span>|</span><label class="collapse" for="c-36266290">[-]</label><label class="expand" for="c-36266290">[2 more]</label></div><br/><div class="children"><div class="content">If God exists, it is not a deity.<p>Deities are low-dimensional approximations of what is infinite and unquantifiable.</div><br/><div id="36266336" class="c"><input type="checkbox" id="c-36266336" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266290">parent</a><span>|</span><a href="#36266772">next</a><span>|</span><label class="collapse" for="c-36266336">[-]</label><label class="expand" for="c-36266336">[1 more]</label></div><br/><div class="children"><div class="content">No general agreement, noted</div><br/></div></div></div></div></div></div><div id="36266772" class="c"><input type="checkbox" id="c-36266772" checked=""/><div class="controls bullet"><span class="by">pcthrowaway</span><span>|</span><a href="#36266089">parent</a><span>|</span><a href="#36266143">prev</a><span>|</span><a href="#36266726">next</a><span>|</span><label class="collapse" for="c-36266772">[-]</label><label class="expand" for="c-36266772">[4 more]</label></div><br/><div class="children"><div class="content">If my understanding of mythology is current, it&#x27;s only the devil who considers bargaining, and it&#x27;s never to our benefit.<p>Following that idea, if AI ever needed to &quot;trade&quot; with humans I suspect we&#x27;d be taking the worse end of the trade every time (the trade would be for its benefit, and unlikely to benefit us).<p>Kind of like when the U.S. &quot;trades&quot; with a third-world country. The U.S will just make an offer they can&#x27;t refuse. But taking the trade often perpetuates their dependence on the U.S. or has long-term consequences for them.</div><br/><div id="36268173" class="c"><input type="checkbox" id="c-36268173" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266772">parent</a><span>|</span><a href="#36267865">next</a><span>|</span><label class="collapse" for="c-36268173">[-]</label><label class="expand" for="c-36268173">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s plenty of stories in European folklore where people successfully bargain with the devil.  Usually they manage to cheat the devil somehow.</div><br/></div></div><div id="36267865" class="c"><input type="checkbox" id="c-36267865" checked=""/><div class="controls bullet"><span class="by">Nasrudith</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266772">parent</a><span>|</span><a href="#36268173">prev</a><span>|</span><a href="#36268240">next</a><span>|</span><label class="collapse" for="c-36267865">[-]</label><label class="expand" for="c-36267865">[1 more]</label></div><br/><div class="children"><div class="content">Which is why countries the US have embargoed have advanced leaps and bounds over their neighbors with trade relationships. Oh wait, it is the exact fucking opposite. Seriously it seems some people can&#x27;t pry off their exploitation and imperialism goggles. The U.S. could commit imperialism by sitting quietly in another room in their minds.</div><br/></div></div><div id="36268240" class="c"><input type="checkbox" id="c-36268240" checked=""/><div class="controls bullet"><span class="by">PrimeMcFly</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266772">parent</a><span>|</span><a href="#36267865">prev</a><span>|</span><a href="#36266726">next</a><span>|</span><label class="collapse" for="c-36268240">[-]</label><label class="expand" for="c-36268240">[1 more]</label></div><br/><div class="children"><div class="content">The Christian god certainly made bargains, like asking Abraham to sacrifice his son in return for something.</div><br/></div></div></div></div><div id="36266726" class="c"><input type="checkbox" id="c-36266726" checked=""/><div class="controls bullet"><span class="by">a_shovel</span><span>|</span><a href="#36266089">parent</a><span>|</span><a href="#36266772">prev</a><span>|</span><a href="#36266412">next</a><span>|</span><label class="collapse" for="c-36266726">[-]</label><label class="expand" for="c-36266726">[2 more]</label></div><br/><div class="children"><div class="content">The idea that <i>this</i> framing is better than the original really goes to show that superintelligent AIs aren&#x27;t being discussed because they&#x27;re a realistic near-future possibility, but because they let techie atheists ponder religious concepts like omnipotence and god without admitting to themselves that that&#x27;s what they&#x27;re doing.</div><br/><div id="36266806" class="c"><input type="checkbox" id="c-36266806" checked=""/><div class="controls bullet"><span class="by">krapp</span><span>|</span><a href="#36266089">root</a><span>|</span><a href="#36266726">parent</a><span>|</span><a href="#36266412">next</a><span>|</span><label class="collapse" for="c-36266806">[-]</label><label class="expand" for="c-36266806">[1 more]</label></div><br/><div class="children"><div class="content">&gt;they let techie atheists ponder religious concepts like omnipotence and god without admitting to themselves that that&#x27;s what they&#x27;re doing<p>There&#x27;s a reason the singularity has been called &quot;the rapture for nerds&quot; since forever. Beliefs about runaway AGI (in particular the assumption that it would have nigh godlike powers,) along with a lot of UFO culture and belief in simulation theory are literally just religion with the serial numbers filed off.</div><br/></div></div></div></div><div id="36266412" class="c"><input type="checkbox" id="c-36266412" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36266089">parent</a><span>|</span><a href="#36266726">prev</a><span>|</span><a href="#36266186">next</a><span>|</span><label class="collapse" for="c-36266412">[-]</label><label class="expand" for="c-36266412">[1 more]</label></div><br/><div class="children"><div class="content">No it&#x27;s not satire. It&#x27;s one of those clickbaity contrarian articles like &quot;actually using goto is great&quot; or &quot;sometimes wearing pants on head is the smart thing to do.&quot; The maxim that they are reacting to is the idea that because we don&#x27;t trade with ants, smart AI won&#x27;t trade with us if the cognitive difference is similar. I think their take is that once you can overcome some minimum threshold of communication ability then it does often make sense to trade with others even if they are much much stupider than you are, and that the reason we don&#x27;t trade with ants is because of that communication barrier. Presumably they are suggesting that even if we will be much much stupider than AI, we will still be able to communicate with the AI in some manner that exceeds that threshold, and therefore they might want to trade with us in some way. But my main point is that it&#x27;s a contrarian clickbait take that isn&#x27;t meant to be taken too seriously or to be taken as satire it&#x27;s to be taken as something to click on.</div><br/></div></div><div id="36266186" class="c"><input type="checkbox" id="c-36266186" checked=""/><div class="controls bullet"><span class="by">ChatGTP</span><span>|</span><a href="#36266089">parent</a><span>|</span><a href="#36266412">prev</a><span>|</span><a href="#36268357">next</a><span>|</span><label class="collapse" for="c-36266186">[-]</label><label class="expand" for="c-36266186">[1 more]</label></div><br/><div class="children"><div class="content">Humans absolutely try trade with god in the form of cosmic karma ? I’m not saying they get something in return but they do try.</div><br/></div></div></div></div><div id="36268357" class="c"><input type="checkbox" id="c-36268357" checked=""/><div class="controls bullet"><span class="by">lowbloodsugar</span><span>|</span><a href="#36266089">prev</a><span>|</span><a href="#36268315">next</a><span>|</span><label class="collapse" for="c-36268357">[-]</label><label class="expand" for="c-36268357">[1 more]</label></div><br/><div class="children"><div class="content">We managed to communicate with slaves tho, just fine.</div><br/></div></div><div id="36268315" class="c"><input type="checkbox" id="c-36268315" checked=""/><div class="controls bullet"><span class="by">quantum_mcts</span><span>|</span><a href="#36268357">prev</a><span>|</span><a href="#36266005">next</a><span>|</span><label class="collapse" for="c-36268315">[-]</label><label class="expand" for="c-36268315">[1 more]</label></div><br/><div class="children"><div class="content">We trade with bees though.</div><br/></div></div><div id="36266190" class="c"><input type="checkbox" id="c-36266190" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#36266005">prev</a><span>|</span><a href="#36267209">next</a><span>|</span><label class="collapse" for="c-36266190">[-]</label><label class="expand" for="c-36266190">[5 more]</label></div><br/><div class="children"><div class="content">&gt;  we don’t need to trade with them because they have nothing of value and if they did we could just take it; anything they can do we can do better, and we can just walk all over them. Why negotiate when you can steal?<p>If we could communicate with ants, we would do all manner of business with them.<p>Everything from pest control (defend our crops in exchange for the corpses and perhaps extra sugar instead of using pesticides) to archeological exploration to health and chemical detection (ants can detect cancers in your urine) could benefit from ant services. Could use them for microplastic cleanup too.<p>Really, this applies to many species. Fisheries could certainly benefit from the knowledge of dolphins and whales.  Birds could work with us to clear up litter. They already do this with crows to some extent. Imagine being able to partner with beehives to direct pollination.<p>So the barrier is that we cannot communicate with them, not that they have nothing of value to offer.</div><br/><div id="36266475" class="c"><input type="checkbox" id="c-36266475" checked=""/><div class="controls bullet"><span class="by">jprete</span><span>|</span><a href="#36266190">parent</a><span>|</span><a href="#36266268">next</a><span>|</span><label class="collapse" for="c-36266475">[-]</label><label class="expand" for="c-36266475">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m curious if you know that the author says very similar things?<p>The author points out several services that ants could trade, such as cleaning high vertical walls, or finding and sealing extremely small cracks in buildings. The author also shares your conclusion that the obstacle is communication.</div><br/><div id="36266581" class="c"><input type="checkbox" id="c-36266581" checked=""/><div class="controls bullet"><span class="by">MattGaiser</span><span>|</span><a href="#36266190">root</a><span>|</span><a href="#36266475">parent</a><span>|</span><a href="#36266268">next</a><span>|</span><label class="collapse" for="c-36266581">[-]</label><label class="expand" for="c-36266581">[1 more]</label></div><br/><div class="children"><div class="content">Mea culpa. I read the bit about not trading with ants and then having seen the arguments before, thought it was heading down that same path. My fault.</div><br/></div></div></div></div><div id="36266268" class="c"><input type="checkbox" id="c-36266268" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#36266190">parent</a><span>|</span><a href="#36266475">prev</a><span>|</span><a href="#36266289">next</a><span>|</span><label class="collapse" for="c-36266268">[-]</label><label class="expand" for="c-36266268">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking of our effective &quot;trade&quot; with honey bees (for honey and for pollination). Sure, we <i>could</i> do either without them, but it&#x27;s a lot more efficient to do these things with them.</div><br/></div></div><div id="36266289" class="c"><input type="checkbox" id="c-36266289" checked=""/><div class="controls bullet"><span class="by">Raicuparta</span><span>|</span><a href="#36266190">parent</a><span>|</span><a href="#36266268">prev</a><span>|</span><a href="#36267209">next</a><span>|</span><label class="collapse" for="c-36266289">[-]</label><label class="expand" for="c-36266289">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s an interesting way to think about it. I can try coming up with a counter-argument:<p>We can probably train ants to do those things, that would be a way of communicating with them. It would just be slow, inefficient, and unreliable, so we put our resources into methods we can more directly control and improve. The same can happen from this magical future AI&#x27;s perspective: why use silly humans when other artificial alternatives are more likely to succeed.</div><br/></div></div></div></div><div id="36267209" class="c"><input type="checkbox" id="c-36267209" checked=""/><div class="controls bullet"><span class="by">chaostheory</span><span>|</span><a href="#36266190">prev</a><span>|</span><a href="#36266975">next</a><span>|</span><label class="collapse" for="c-36267209">[-]</label><label class="expand" for="c-36267209">[1 more]</label></div><br/><div class="children"><div class="content">We trade with bees though<p>I agree with the author. Not everything is a zero sum game</div><br/></div></div><div id="36266975" class="c"><input type="checkbox" id="c-36266975" checked=""/><div class="controls bullet"><span class="by">jancsika</span><span>|</span><a href="#36267209">prev</a><span>|</span><label class="collapse" for="c-36266975">[-]</label><label class="expand" for="c-36266975">[1 more]</label></div><br/><div class="children"><div class="content">&gt; There might also be a lack of the memory and consistent identity that allows an ant to uphold commitments it made with me five minutes ago.<p>&quot;<i>An</i> ant?!?&quot; I wonder which has more completely saturated the Earth&#x27;s ecosystem-- American-style libertarian ideology or plastic. Judging from the article I&#x27;d guess the former.<p>I do wish there was something we could give an indoor ant invasion besides a poison pill. Remember that old <i>X Files</i> where Bryan Cranston&#x27;s character has to keep traveling West for some inexplicable reason? Maybe there&#x27;s a way to fashion &quot;rambler crumbs&quot; that temporarily make the ants shoot off in a direction away from the house. Then when they come to, they find their way back to hill. And the crumb they bring makes more ants shoot off to the West, until all the ants eventually believe &quot;There&#x27;s gold in them there hills!&quot;<p>(And if they go far enough West perhaps there is...)</div><br/></div></div></div></div></div></div></div></body></html>