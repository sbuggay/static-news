<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1693386064689" as="style"/><link rel="stylesheet" href="styles.css?v=1693386064689"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.servethehome.com/intel-shows-8-core-528-thread-processor-with-silicon-photonics/">Intel shows 8 core 528 thread processor with silicon photonics</a> <span class="domain">(<a href="https://www.servethehome.com">www.servethehome.com</a>)</span></div><div class="subtext"><span>NavinF</span> | <span>134 comments</span></div><br/><div><div id="37316146" class="c"><input type="checkbox" id="c-37316146" checked=""/><div class="controls bullet"><span class="by">rbanffy</span><span>|</span><a href="#37318974">next</a><span>|</span><label class="collapse" for="c-37316146">[-]</label><label class="expand" for="c-37316146">[28 more]</label></div><br/><div class="children"><div class="content">66 threads per core looks more like a barrel processor than anything else. We shouldn’t expect those threads to be very fast, but we can assume that, if the processor has enough work, it should be able to be doing something useful most of the time (rather than waiting for memory).</div><br/><div id="37317741" class="c"><input type="checkbox" id="c-37317741" checked=""/><div class="controls bullet"><span class="by">jandrewrogers</span><span>|</span><a href="#37316146">parent</a><span>|</span><a href="#37318495">next</a><span>|</span><label class="collapse" for="c-37317741">[-]</label><label class="expand" for="c-37317741">[11 more]</label></div><br/><div class="children"><div class="content">I don’t know if Intel has the appetite to attempt another barrel processor.<p>The primary weakness of barrel processors is human; only a handful of people grok how to design codes that really exploit their potential. They look deceptively familiar at a code level, because normal code will run okay, but won’t perform well unless you do things that look extremely odd to someone that has only written code for CPUs. It is a weird type of architecture to design data structures and algorithms for and there isn’t a lot of literature on algorithm design for barrel processors.<p>I love barrel processors and have designed codes for a few different such architectures, starting with the old Tera systems, and became quite good at it. In the hands of someone that knows what they are doing I believe they can be more computationally efficient than just about any other architecture given a similar silicon budget for general purpose computing. However, the reality is that writing efficient code for a barrel processor requires carrying a much more complex model in your head than the equivalent code on a CPU; the economics favors architectures like CPUs where an average engineer can deliver adequate efficiency. At this point, I’ve given up on the idea that I’ll ever see a mainstream barrel processor, despite their strengths from a pure computational efficiency standpoint.</div><br/><div id="37319170" class="c"><input type="checkbox" id="c-37319170" checked=""/><div class="controls bullet"><span class="by">yvdriess</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317741">parent</a><span>|</span><a href="#37318336">next</a><span>|</span><label class="collapse" for="c-37319170">[-]</label><label class="expand" for="c-37319170">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s two single threaded cores, but the eight multithreaded cores are indeed Tera-style barrel processors. The Tera paper is even cited directly in the PIUMA white paper: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2010.06277" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2010.06277</a></div><br/></div></div><div id="37318336" class="c"><input type="checkbox" id="c-37318336" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317741">parent</a><span>|</span><a href="#37319170">prev</a><span>|</span><a href="#37317819">next</a><span>|</span><label class="collapse" for="c-37318336">[-]</label><label class="expand" for="c-37318336">[2 more]</label></div><br/><div class="children"><div class="content">What are the kinds of challenges to write things efficiently?<p>From skimming Wikipedia, it looks like a big challenge is cache pollution. Is it possible that the hit to cache locality is what inhibits uptake? After all, most threads in the OS are sitting idle doing nothing, which means you’re penalized for any “hot code” that’s largely serial (ie typically you have a small number of “hot” applications unless your problem is embarrassingly parallel)</div><br/><div id="37319274" class="c"><input type="checkbox" id="c-37319274" checked=""/><div class="controls bullet"><span class="by">yvdriess</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37318336">parent</a><span>|</span><a href="#37317819">next</a><span>|</span><label class="collapse" for="c-37319274">[-]</label><label class="expand" for="c-37319274">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  What are the kinds of challenges to write things efficiently?<p>The challenge is mostly that you have to create enough fine-grained parallelism and that per thread performance is relatively low. Amdahl&#x27;s law is in full effect here, a sequential part is going to bite you hard. That&#x27;s why each die on this chip has two sequential-performance cores.<p>The graph problems this processor is designed to handle have plenty of parallelism and most of the time those threads will be waiting for (uncached) 8B DRAM accesses.<p>&gt; From skimming Wikipedia, it looks like a big challenge is cache pollution<p>This processor has tiny caches and the programmer decides which accesses are cached. In practice, you cache the thread&#x27;s stack and do all the large graph accesses un-cached, letting the barrel processor hide the latency. There are very fast scratchpads on this thing for when you do need to exploit locality.</div><br/></div></div></div></div><div id="37317819" class="c"><input type="checkbox" id="c-37317819" checked=""/><div class="controls bullet"><span class="by">sbierwagen</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317741">parent</a><span>|</span><a href="#37318336">prev</a><span>|</span><a href="#37318955">next</a><span>|</span><label class="collapse" for="c-37317819">[-]</label><label class="expand" for="c-37317819">[6 more]</label></div><br/><div class="children"><div class="content">If Intel was very bullish on AI, they might be tempted to design arbitrarily complicated architectures and just trust that GPT-6 will be able to write code for it.<p>This was a bet that completely failed for Itanium, but maybe this time...</div><br/><div id="37318754" class="c"><input type="checkbox" id="c-37318754" checked=""/><div class="controls bullet"><span class="by">sph</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317819">parent</a><span>|</span><a href="#37318869">next</a><span>|</span><label class="collapse" for="c-37318754">[-]</label><label class="expand" for="c-37318754">[1 more]</label></div><br/><div class="children"><div class="content">Is GPT-6 the proverbial magic wand that makes all your dreams come true? Because you just hand waved away all the complexity just by name dropping it. Let&#x27;s get back to Earth for one second...</div><br/></div></div><div id="37318869" class="c"><input type="checkbox" id="c-37318869" checked=""/><div class="controls bullet"><span class="by">JW_00000</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317819">parent</a><span>|</span><a href="#37318754">prev</a><span>|</span><a href="#37318241">next</a><span>|</span><label class="collapse" for="c-37318869">[-]</label><label class="expand" for="c-37318869">[2 more]</label></div><br/><div class="children"><div class="content">How could GPT-(arbitrarily large number) learn to write code for an architecture for which there is no training data?</div><br/><div id="37318962" class="c"><input type="checkbox" id="c-37318962" checked=""/><div class="controls bullet"><span class="by">317070</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37318869">parent</a><span>|</span><a href="#37318241">next</a><span>|</span><label class="collapse" for="c-37318962">[-]</label><label class="expand" for="c-37318962">[1 more]</label></div><br/><div class="children"><div class="content">From reading the documentation in the context.</div><br/></div></div></div></div><div id="37318241" class="c"><input type="checkbox" id="c-37318241" checked=""/><div class="controls bullet"><span class="by">sfn42</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317819">parent</a><span>|</span><a href="#37318869">prev</a><span>|</span><a href="#37318593">next</a><span>|</span><label class="collapse" for="c-37318241">[-]</label><label class="expand" for="c-37318241">[1 more]</label></div><br/><div class="children"><div class="content">I doubt Intel leadership is that naive.</div><br/></div></div><div id="37318593" class="c"><input type="checkbox" id="c-37318593" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317819">parent</a><span>|</span><a href="#37318241">prev</a><span>|</span><a href="#37318955">next</a><span>|</span><label class="collapse" for="c-37318593">[-]</label><label class="expand" for="c-37318593">[1 more]</label></div><br/><div class="children"><div class="content">They probably aren&#x27;t <i>insanely</i> bullish. GPT is a revolution but it&#x27;s a revolution because it can do &quot;easy&quot; general tasks for the first time, which makes it the first actually useful general purpose AI.<p>But it still can&#x27;t really design things. It&#x27;s probably about as far away from being able to design a complex CPU architecture as GPT-4 is from Eliza.</div><br/></div></div></div></div><div id="37318955" class="c"><input type="checkbox" id="c-37318955" checked=""/><div class="controls bullet"><span class="by">jeffreygoesto</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317741">parent</a><span>|</span><a href="#37317819">prev</a><span>|</span><a href="#37318495">next</a><span>|</span><label class="collapse" for="c-37318955">[-]</label><label class="expand" for="c-37318955">[1 more]</label></div><br/><div class="children"><div class="content">Would you call that &quot;general purpose&quot; still? If the code needs to be so special to leverage the benefits of that design?</div><br/></div></div></div></div><div id="37318495" class="c"><input type="checkbox" id="c-37318495" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#37316146">parent</a><span>|</span><a href="#37317741">prev</a><span>|</span><a href="#37316266">next</a><span>|</span><label class="collapse" for="c-37318495">[-]</label><label class="expand" for="c-37318495">[6 more]</label></div><br/><div class="children"><div class="content">64 of the 66 treads are slow threads where each group of 16 threads shares one set of execution units and all 64 threads share a scratchpad memory and the caches.<p>This part of each core is very similar to the existing GPUs.<p>What is different in this experimental Intel CPU and unlike in any previous GPU or CPU, is that each core, besides the GPU-like part, also includes 2 very fast threads, with out-of-order execution and a much higher clock frequency than the slow threads. Each of the 2 fast threads has its own non-shared execution units.<p>Separately, the 2 fast threads and the 64 slow threads are very similar with older CPUs or GPUs, but their combination into a single core with shared scratchpad memory and cache memories is novel.</div><br/><div id="37319213" class="c"><input type="checkbox" id="c-37319213" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37318495">parent</a><span>|</span><a href="#37319143">next</a><span>|</span><label class="collapse" for="c-37319213">[-]</label><label class="expand" for="c-37319213">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Separately, the 2 fast threads and the 64 slow threads are very similar with older CPUs or GPUs, but their combination into a single core with shared scratchpad memory and cache memories is novel.<p>Getting some Cell[1] vibes from that, except in reverse I guess.<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cell_(processor)" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cell_(processor)</a></div><br/></div></div><div id="37319143" class="c"><input type="checkbox" id="c-37319143" checked=""/><div class="controls bullet"><span class="by">voxadam</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37318495">parent</a><span>|</span><a href="#37319213">prev</a><span>|</span><a href="#37318973">next</a><span>|</span><label class="collapse" for="c-37319143">[-]</label><label class="expand" for="c-37319143">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m far from a CPU or architecture expert but the way you describe it this CPU reminds me a bit of the Cell from IBM, Sony, and Toshiba. Though, I don&#x27;t remember if the SPEs had any sort of shared memory in the Cell.</div><br/></div></div><div id="37318973" class="c"><input type="checkbox" id="c-37318973" checked=""/><div class="controls bullet"><span class="by">tgv</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37318495">parent</a><span>|</span><a href="#37319143">prev</a><span>|</span><a href="#37316266">next</a><span>|</span><label class="collapse" for="c-37318973">[-]</label><label class="expand" for="c-37318973">[3 more]</label></div><br/><div class="children"><div class="content">So this is a processor where you would have 97% of the threads doing some I&#x2F;O like task? But that can&#x27;t be disk I&#x2F;O, so that would leave networking?</div><br/><div id="37319283" class="c"><input type="checkbox" id="c-37319283" checked=""/><div class="controls bullet"><span class="by">yvdriess</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37318973">parent</a><span>|</span><a href="#37319052">next</a><span>|</span><label class="collapse" for="c-37319283">[-]</label><label class="expand" for="c-37319283">[1 more]</label></div><br/><div class="children"><div class="content">DRAM is the new I&#x2F;O. So yes, this is designed to handle 97% of the threads doing constant bad-locality DRAM accesses.</div><br/></div></div><div id="37319052" class="c"><input type="checkbox" id="c-37319052" checked=""/><div class="controls bullet"><span class="by">dan-robertson</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37318973">parent</a><span>|</span><a href="#37319283">prev</a><span>|</span><a href="#37316266">next</a><span>|</span><label class="collapse" for="c-37319052">[-]</label><label class="expand" for="c-37319052">[1 more]</label></div><br/><div class="children"><div class="content">I think generally the threads are spending a lot of time waiting on memory. It can take &gt;100 cycles to get something from ram so you could have all your threads try to read a pointer and still have computation to spare until the first read comes back from memory.<p>It could be that eg 97% of your threads are looking things up in big hashtables (eg computing a big join for a database query) or binary-searching big arrays, rather than ‘some I&#x2F;O task’</div><br/></div></div></div></div></div></div><div id="37316266" class="c"><input type="checkbox" id="c-37316266" checked=""/><div class="controls bullet"><span class="by">twoodfin</span><span>|</span><a href="#37316146">parent</a><span>|</span><a href="#37318495">prev</a><span>|</span><a href="#37319028">next</a><span>|</span><label class="collapse" for="c-37316266">[-]</label><label class="expand" for="c-37316266">[3 more]</label></div><br/><div class="children"><div class="content">Reminds me of Tera, the original SMT. 128 threads per core in 
1990!<p><a href="https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&amp;type=pdf&amp;doi=108b3a24274af0aab079bd94ab7c1ee6543563d4" rel="nofollow noreferrer">https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&amp;type=pdf&amp;d...</a><p>(I’d put up money that the DARPA project that funded this work is from the same lineage of TLA interest that got Tera enough money to buy Cray!)</div><br/><div id="37319306" class="c"><input type="checkbox" id="c-37319306" checked=""/><div class="controls bullet"><span class="by">yvdriess</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37316266">parent</a><span>|</span><a href="#37316926">next</a><span>|</span><label class="collapse" for="c-37319306">[-]</label><label class="expand" for="c-37319306">[1 more]</label></div><br/><div class="children"><div class="content">Their multithreaded cores are similar design, yes. It does not do XMT&#x27;s in-hardware full&#x2F;empty bit memory access system though.</div><br/></div></div></div></div><div id="37319028" class="c"><input type="checkbox" id="c-37319028" checked=""/><div class="controls bullet"><span class="by">mjan22640</span><span>|</span><a href="#37316146">parent</a><span>|</span><a href="#37316266">prev</a><span>|</span><a href="#37317918">next</a><span>|</span><label class="collapse" for="c-37319028">[-]</label><label class="expand" for="c-37319028">[1 more]</label></div><br/><div class="children"><div class="content">To me it looks like the opposite, the processor being very fast, and exporting itself as 66 threads to not spend virtually all its time waiting for external circuits.</div><br/></div></div><div id="37317918" class="c"><input type="checkbox" id="c-37317918" checked=""/><div class="controls bullet"><span class="by">userbinator</span><span>|</span><a href="#37316146">parent</a><span>|</span><a href="#37319028">prev</a><span>|</span><a href="#37316289">next</a><span>|</span><label class="collapse" for="c-37317918">[-]</label><label class="expand" for="c-37317918">[2 more]</label></div><br/><div class="children"><div class="content">How useful would it be as a GPU?</div><br/><div id="37318173" class="c"><input type="checkbox" id="c-37318173" checked=""/><div class="controls bullet"><span class="by">zoenolan</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317918">parent</a><span>|</span><a href="#37316289">next</a><span>|</span><label class="collapse" for="c-37318173">[-]</label><label class="expand" for="c-37318173">[1 more]</label></div><br/><div class="children"><div class="content">These particular chips. They seem more targeted at HPC work (and price point).<p>This sort of architecture. I wouldn&#x27;t be surprised if current GPU were doing something similar.<p>If you think about executing a shader program. You typically are running that same code over a bunch of data. You can map that to multiple threads.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thread_block_(CUDA_programming)" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thread_block_(CUDA_programming...</a><p><a href="https:&#x2F;&#x2F;yosefk.com&#x2F;blog&#x2F;simd-simt-smt-parallelism-in-nvidia-gpus.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;yosefk.com&#x2F;blog&#x2F;simd-simt-smt-parallelism-in-nvidia-...</a></div><br/></div></div></div></div><div id="37317723" class="c"><input type="checkbox" id="c-37317723" checked=""/><div class="controls bullet"><span class="by">lynx23</span><span>|</span><a href="#37316146">parent</a><span>|</span><a href="#37316289">prev</a><span>|</span><a href="#37318974">next</a><span>|</span><label class="collapse" for="c-37317723">[-]</label><label class="expand" for="c-37317723">[2 more]</label></div><br/><div class="children"><div class="content">Feels a bit like async on the programming language side.  Just replace &quot;waiting for memory&quot; with &quot;waiting for IO&quot; and you&#x27;re almost there.</div><br/><div id="37318463" class="c"><input type="checkbox" id="c-37318463" checked=""/><div class="controls bullet"><span class="by">mananaysiempre</span><span>|</span><a href="#37316146">root</a><span>|</span><a href="#37317723">parent</a><span>|</span><a href="#37318974">next</a><span>|</span><label class="collapse" for="c-37318463">[-]</label><label class="expand" for="c-37318463">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Just replace &quot;waiting for memory&quot; with &quot;waiting for IO&quot; and you&#x27;re almost there.<p>You can <i>see</i> the latter in your code, you can’t—on a modern superscalar—see the former. Is the proposed architecture any different?</div><br/></div></div></div></div></div></div><div id="37318974" class="c"><input type="checkbox" id="c-37318974" checked=""/><div class="controls bullet"><span class="by">dschuetz</span><span>|</span><a href="#37316146">prev</a><span>|</span><a href="#37317165">next</a><span>|</span><label class="collapse" for="c-37318974">[-]</label><label class="expand" for="c-37318974">[1 more]</label></div><br/><div class="children"><div class="content">This seems more like a proof-of-concept CPU rather than a marketable product, highly specialized, problems and workloads that it solves yet to be found.<p>I anticipate that photonics will be introduced to general-purpose computing in the years to come, even if only to get a handle on the rising excess heat problems. Most notable is the 10 -&gt; 7 nm process.</div><br/></div></div><div id="37317165" class="c"><input type="checkbox" id="c-37317165" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#37318974">prev</a><span>|</span><a href="#37316163">next</a><span>|</span><label class="collapse" for="c-37317165">[-]</label><label class="expand" for="c-37317165">[8 more]</label></div><br/><div class="children"><div class="content">Marvell made an SMT8 ARM CPU with &quot;768 Threads Per Node&quot;<p><a href="https:&#x2F;&#x2F;www.servethehome.com&#x2F;marvell-thunderx3-arm-server-cpu-with-768-threads-in-2020&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.servethehome.com&#x2F;marvell-thunderx3-arm-server-cp...</a><p>IIRC it was targeted at database workloads, and the pitch was the same: if the core is usually twiddling its thumbs waiting on RAM, it might as well work on another thread in the meantime.<p>And I guess IBM and Zen4C kinda fufill this demand, but more SMT16 cloud instances explicity targeted at these low IPC loads would be neat.</div><br/><div id="37317659" class="c"><input type="checkbox" id="c-37317659" checked=""/><div class="controls bullet"><span class="by">paulmd</span><span>|</span><a href="#37317165">parent</a><span>|</span><a href="#37317191">next</a><span>|</span><label class="collapse" for="c-37317659">[-]</label><label class="expand" for="c-37317659">[1 more]</label></div><br/><div class="children"><div class="content">Niagara (Ultrasparc T1&#x2F;T2) did the same thing.  CMT8&#x2F;SMT8 seems to be a sweet spot for these kinds of barrel processor-esque designs.</div><br/></div></div><div id="37317191" class="c"><input type="checkbox" id="c-37317191" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#37317165">parent</a><span>|</span><a href="#37317659">prev</a><span>|</span><a href="#37318891">next</a><span>|</span><label class="collapse" for="c-37317191">[-]</label><label class="expand" for="c-37317191">[5 more]</label></div><br/><div class="children"><div class="content">I never read or heard someone say “mind as well..” is that common where you’re from? I’ve only ever heard “might as well…”<p>Interesting thank you!</div><br/><div id="37317283" class="c"><input type="checkbox" id="c-37317283" checked=""/><div class="controls bullet"><span class="by">carbotaniuman</span><span>|</span><a href="#37317165">root</a><span>|</span><a href="#37317191">parent</a><span>|</span><a href="#37317355">next</a><span>|</span><label class="collapse" for="c-37317283">[-]</label><label class="expand" for="c-37317283">[3 more]</label></div><br/><div class="children"><div class="content">Feels like a typo I think, it doesn&#x27;t seem to be a thing from a Google search.</div><br/><div id="37318087" class="c"><input type="checkbox" id="c-37318087" checked=""/><div class="controls bullet"><span class="by">pyinstallwoes</span><span>|</span><a href="#37317165">root</a><span>|</span><a href="#37317283">parent</a><span>|</span><a href="#37317355">next</a><span>|</span><label class="collapse" for="c-37318087">[-]</label><label class="expand" for="c-37318087">[2 more]</label></div><br/><div class="children"><div class="content">It reminds me of the difference I saw in Europe when signs posted may say “mind your step” instead of “watch your step”</div><br/><div id="37318223" class="c"><input type="checkbox" id="c-37318223" checked=""/><div class="controls bullet"><span class="by">galaxyLogic</span><span>|</span><a href="#37317165">root</a><span>|</span><a href="#37318087">parent</a><span>|</span><a href="#37317355">next</a><span>|</span><label class="collapse" for="c-37318223">[-]</label><label class="expand" for="c-37318223">[1 more]</label></div><br/><div class="children"><div class="content">Right, the London subway (used to) have an announcement on every stop:  &quot;Mind the Gap&quot;. It is weird and wonderful.</div><br/></div></div></div></div></div></div><div id="37317355" class="c"><input type="checkbox" id="c-37317355" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#37317165">root</a><span>|</span><a href="#37317191">parent</a><span>|</span><a href="#37317283">prev</a><span>|</span><a href="#37318891">next</a><span>|</span><label class="collapse" for="c-37317355">[-]</label><label class="expand" for="c-37317355">[1 more]</label></div><br/><div class="children"><div class="content">Yep, typo. It is late...</div><br/></div></div></div></div></div></div><div id="37316163" class="c"><input type="checkbox" id="c-37316163" checked=""/><div class="controls bullet"><span class="by">ggm</span><span>|</span><a href="#37317165">prev</a><span>|</span><a href="#37316136">next</a><span>|</span><label class="collapse" for="c-37316163">[-]</label><label class="expand" for="c-37316163">[2 more]</label></div><br/><div class="children"><div class="content">They seem to be suggesting if you amortize the die cost and speed consequences of electrical to optical, you can then get pretty much distance-independent speeds (obviously not, but lets limit ourselves to the distance of chip carriers inside a single chassis) interconnect at good rates in optical, with low interference and free routing within the bend radius of the light guides.<p>Maybe I misread it. Maybe the optical component is for something else like die stacking so you get grids of chips on a super carrier, with optical interconnect.</div><br/><div id="37317082" class="c"><input type="checkbox" id="c-37317082" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#37316163">parent</a><span>|</span><a href="#37316136">next</a><span>|</span><label class="collapse" for="c-37317082">[-]</label><label class="expand" for="c-37317082">[1 more]</label></div><br/><div class="children"><div class="content">They had voxels in 1997 when i was there.... the goal was stacking layers and using voxels in the vertical stack</div><br/></div></div></div></div><div id="37316136" class="c"><input type="checkbox" id="c-37316136" checked=""/><div class="controls bullet"><span class="by">froogle</span><span>|</span><a href="#37316163">prev</a><span>|</span><a href="#37317051">next</a><span>|</span><label class="collapse" for="c-37316136">[-]</label><label class="expand" for="c-37316136">[41 more]</label></div><br/><div class="children"><div class="content">&gt; Here is the actual die photograph and confirmation that this is being done on TSMC 7nm.<p>Yikes, Intel. Has to be a pretty low moment as a chipmaker to have to use your competitor&#x27;s fabs for something like this.</div><br/><div id="37316158" class="c"><input type="checkbox" id="c-37316158" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#37316136">parent</a><span>|</span><a href="#37316493">next</a><span>|</span><label class="collapse" for="c-37316158">[-]</label><label class="expand" for="c-37316158">[30 more]</label></div><br/><div class="children"><div class="content">Intel has a prototype 1.8nm node which Nvidia already tested and spoken well of.<p>But yes, the 10nm node has been a disaster for Intel and set the company back 5&#x2F;10 years on the chip making business.</div><br/><div id="37316174" class="c"><input type="checkbox" id="c-37316174" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316158">parent</a><span>|</span><a href="#37316493">next</a><span>|</span><label class="collapse" for="c-37316174">[-]</label><label class="expand" for="c-37316174">[29 more]</label></div><br/><div class="children"><div class="content">If not for Intel&#x27;s 10nm debacle, Apple probably wouldn&#x27;t have left. All of Apple&#x27;s early-2010s hardware designs were predicated on Intel&#x27;s three-years-out promises of thermal+power efficiency for 10nm, that just never materialized.</div><br/><div id="37316806" class="c"><input type="checkbox" id="c-37316806" checked=""/><div class="controls bullet"><span class="by">Tsarbomb</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316174">parent</a><span>|</span><a href="#37317443">next</a><span>|</span><label class="collapse" for="c-37316806">[-]</label><label class="expand" for="c-37316806">[11 more]</label></div><br/><div class="children"><div class="content">I hard disagree. The chassis and cooler designs of the old intel based macs sandbagged the performance a great deal. They were already building a narrative to their investors and consumers that a jump to in house chip design was necessary. You can see this sandbagging in the old intel chassis Apple Silicon MBP where their performance is markedly worse than the ones in the newer chassis.</div><br/><div id="37316988" class="c"><input type="checkbox" id="c-37316988" checked=""/><div class="controls bullet"><span class="by">acdha</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316806">parent</a><span>|</span><a href="#37317674">next</a><span>|</span><label class="collapse" for="c-37316988">[-]</label><label class="expand" for="c-37316988">[1 more]</label></div><br/><div class="children"><div class="content">That doesn’t make sense: everyone else got hit by Intel’s failure to deliver, too. Even if you assume Apple had some 4-D chess plan where making their own products worse was needed to justify a huge gamble, it’s not like Dell or HP were in on it. Slapping a monster heat sink and fan on can help with performance but then you’re paying with weight, battery life, and purchase price.<p>I think a more parsimonious explanation is the accepted one: Intel was floundering for ages, Apple’s phone CPUs were booming, and a company which had suffered a lot due to supplier issues in the PowerPC era decided that they couldn’t afford to let another company have that much control over their product line. It wasn’t just things like the CPUs failing further behind but also the various chipset restrictions and inability to customize things. Apple puts a ton of hardware in to support things like security or various popular tasks (image &amp; video processing, ML, etc.) and now that’s an internal conversation, and the net result is cheaper, cooler, and a unique selling point for them.</div><br/></div></div><div id="37317674" class="c"><input type="checkbox" id="c-37317674" checked=""/><div class="controls bullet"><span class="by">Aurornis</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316806">parent</a><span>|</span><a href="#37316988">prev</a><span>|</span><a href="#37318504">next</a><span>|</span><label class="collapse" for="c-37317674">[-]</label><label class="expand" for="c-37317674">[8 more]</label></div><br/><div class="children"><div class="content">I doubt it was intentional, but you&#x27;re very right that the old laptops had terrible thermal design.<p>Under load, my M1 laptop can pull similar wattage to my old Intel MacBook Pro while staying virtually silent. Meanwhile the old Intel MacBook Pro sounds like a jet engine.</div><br/><div id="37317807" class="c"><input type="checkbox" id="c-37317807" checked=""/><div class="controls bullet"><span class="by">eyegor</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37317674">parent</a><span>|</span><a href="#37318577">next</a><span>|</span><label class="collapse" for="c-37317807">[-]</label><label class="expand" for="c-37317807">[3 more]</label></div><br/><div class="children"><div class="content">The m1&#x2F;m2 chips are generally stupid effecient compared to Intel chips (or even amd&#x2F;arm&#x2F;etc)... Are you sure the power draw is comparable? Apple is quite well known for kneecapping hardware with terrible thermal solutions and I don&#x27;t think there are any breakthroughs in the modern chassis.<p>I couldn&#x27;t find good data on the older mbpros, but the m1 max mbpro used 1&#x2F;3 the power vs an 11th gen Intel laptop to get almost identical scores in cinebench r23.<p><a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;17024&#x2F;apple-m1-max-performance-review&#x2F;3" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;17024&#x2F;apple-m1-max-performanc...</a></div><br/><div id="37318402" class="c"><input type="checkbox" id="c-37318402" checked=""/><div class="controls bullet"><span class="by">dijit</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37317807">parent</a><span>|</span><a href="#37318034">next</a><span>|</span><label class="collapse" for="c-37318402">[-]</label><label class="expand" for="c-37318402">[1 more]</label></div><br/><div class="children"><div class="content">the whole premise of this thread is that this reputation isnt fully justified, and thats one I agree with.<p>Intel for the last 10 years has been saying “if your CPU isn&#x27;t 100c then theres performance on the table”.<p>They also drastically underplayed TDP compared to, say, AMD, by taking the average TDP with frequency scaling taken into consideration.<p>I can <i>easily</i> see Intel marketing to Apple that their CPUs would be fine with 10w of cooling with Intel knowing that that they wont perform as well, and Apple thinking that there will be a generational improvement on thermal efficiency.</div><br/></div></div></div></div><div id="37318577" class="c"><input type="checkbox" id="c-37318577" checked=""/><div class="controls bullet"><span class="by">senttoschool</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37317674">parent</a><span>|</span><a href="#37317807">prev</a><span>|</span><a href="#37318504">next</a><span>|</span><label class="collapse" for="c-37318577">[-]</label><label class="expand" for="c-37318577">[4 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Under load, my M1 laptop can pull similar wattage to my old Intel MacBook Pro while staying virtually silent. Meanwhile the old Intel MacBook Pro sounds like a jet engine.</i><p>On a 15&#x2F;16&quot; Intel MBP, the CPU alone can draw up to 100w. No Apple Silicon except an M Ultra can draw that much power.<p>There is no chance your M1 laptop can draw even close to it. M1 maxes out at around 10w. M1 Max maxes out at around 40w.</div><br/><div id="37319172" class="c"><input type="checkbox" id="c-37319172" checked=""/><div class="controls bullet"><span class="by">dijit</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37318577">parent</a><span>|</span><a href="#37318504">next</a><span>|</span><label class="collapse" for="c-37319172">[-]</label><label class="expand" for="c-37319172">[3 more]</label></div><br/><div class="children"><div class="content">Where do you get the info about power draw?<p>Intel doesn&#x27;t publish anything except TDP.<p>Being generous and saying TDP is actually the consumption; most Intel Mac&#x27;s actually shipping with &quot;configurable power down&quot; specced chips ranging from 23W (like the i5 5257U) to 47W (like the i7 4870HQ); (NOTE: newer chips like the i9 9980HK actually have a <i>lower</i> TDP at 45w)<p>of course TDP isn&#x27;t actually a measure of power consumption, but M2 Max has a TDP of 79W which is considerably more than the &quot;high end&quot; Intel CPU&#x27;s; at least in terms of what Intel markets.</div><br/><div id="37319182" class="c"><input type="checkbox" id="c-37319182" checked=""/><div class="controls bullet"><span class="by">senttoschool</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37319172">parent</a><span>|</span><a href="#37318504">next</a><span>|</span><label class="collapse" for="c-37319182">[-]</label><label class="expand" for="c-37319182">[2 more]</label></div><br/><div class="children"><div class="content">Check here: <a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;17024&#x2F;apple-m1-max-performance-review&#x2F;3" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;17024&#x2F;apple-m1-max-performanc...</a><p>Keep in mind that Intel might ship a 23w chip but laptop makers can choose to boost it to whatever it wants. For example, a 23w Intel chip is often boosted to 35w+ because laptop makers want to win benchmarks. In addition, Intel&#x27;s TDP is quite useless because they added PL1 and PL2 boosts.</div><br/><div id="37319205" class="c"><input type="checkbox" id="c-37319205" checked=""/><div class="controls bullet"><span class="by">dijit</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37319182">parent</a><span>|</span><a href="#37318504">next</a><span>|</span><label class="collapse" for="c-37319205">[-]</label><label class="expand" for="c-37319205">[1 more]</label></div><br/><div class="children"><div class="content">Apple always shipped their chips with &quot;configurable power down&quot; when it was available, which isn&#x27;t available on higher specced chips like the i7&#x2F;i9 - though they didn&#x27;t disable boost clocks as far as I know.<p>The major pains for Apple was when the thermal situation was so bad that CPUs were performing below <i>base</i> clock. -- at that point i7&#x27;s were outperforming i9&#x27;s because they were underclocking themselves due to thermal exhaustion; which feels too weird to be true.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37318504" class="c"><input type="checkbox" id="c-37318504" checked=""/><div class="controls bullet"><span class="by">lostlogin</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316806">parent</a><span>|</span><a href="#37317674">prev</a><span>|</span><a href="#37317443">next</a><span>|</span><label class="collapse" for="c-37318504">[-]</label><label class="expand" for="c-37318504">[1 more]</label></div><br/><div class="children"><div class="content">&gt; You can see this sandbagging in the old intel chassis Apple Silicon MBP where their performance is markedly worse than the ones in the newer chassis.<p>And you can compare both of those and Intels newer chips to Apples ARM offerings.</div><br/></div></div></div></div><div id="37317443" class="c"><input type="checkbox" id="c-37317443" checked=""/><div class="controls bullet"><span class="by">kalleboo</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316174">parent</a><span>|</span><a href="#37316806">prev</a><span>|</span><a href="#37316508">next</a><span>|</span><label class="collapse" for="c-37317443">[-]</label><label class="expand" for="c-37317443">[1 more]</label></div><br/><div class="children"><div class="content">I dunno, they could have gone to AMD who is on TSMC and have lots of design wins in other proprietary machines where the manufacturer has a lot of say in tweaking the chip (=game consoles).<p>I think Apple really wanted to unify the Mac and iOS platforms and it would have happened regardless.</div><br/></div></div><div id="37316508" class="c"><input type="checkbox" id="c-37316508" checked=""/><div class="controls bullet"><span class="by">1over137</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316174">parent</a><span>|</span><a href="#37317443">prev</a><span>|</span><a href="#37316384">next</a><span>|</span><label class="collapse" for="c-37316508">[-]</label><label class="expand" for="c-37316508">[11 more]</label></div><br/><div class="children"><div class="content">&gt;If not for Intel&#x27;s 10nm debacle, Apple probably wouldn&#x27;t have left<p>I doubt it. Apple loves doing full vertical stack as much as possible.</div><br/><div id="37316667" class="c"><input type="checkbox" id="c-37316667" checked=""/><div class="controls bullet"><span class="by">JimmyAustin</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316508">parent</a><span>|</span><a href="#37316384">next</a><span>|</span><label class="collapse" for="c-37316667">[-]</label><label class="expand" for="c-37316667">[10 more]</label></div><br/><div class="children"><div class="content">Apple left for TSMC, not to do in-house chip fabrication.</div><br/><div id="37316748" class="c"><input type="checkbox" id="c-37316748" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316667">parent</a><span>|</span><a href="#37316713">next</a><span>|</span><label class="collapse" for="c-37316748">[-]</label><label class="expand" for="c-37316748">[6 more]</label></div><br/><div class="children"><div class="content">Apple had been doing their own mobile processors for a decade. It was matter of time before they vertically integrated the desktop. They definitely did not leave Intel over the process tech.</div><br/><div id="37316826" class="c"><input type="checkbox" id="c-37316826" checked=""/><div class="controls bullet"><span class="by">monocasa</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316748">parent</a><span>|</span><a href="#37316713">next</a><span>|</span><label class="collapse" for="c-37316826">[-]</label><label class="expand" for="c-37316826">[5 more]</label></div><br/><div class="children"><div class="content">Apple has been investing directly in mobile processors since they bought a stake in ARM for the Newton.  Then later they heavily invested in PortalPlayer, the designer of the iPod SoCs.<p>Their strategy for desktop and mobile processors has been different since the 90s and they only consolidated because it made sense to ditch their partners in the desktop space.</div><br/><div id="37317252" class="c"><input type="checkbox" id="c-37317252" checked=""/><div class="controls bullet"><span class="by">throwawaylinux</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316826">parent</a><span>|</span><a href="#37316968">next</a><span>|</span><label class="collapse" for="c-37317252">[-]</label><label class="expand" for="c-37317252">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Apple has been investing directly in mobile processors since they bought a stake in ARM for the Newton. Then later they heavily invested in PortalPlayer, the designer of the iPod SoCs.<p>Not this heavily. They bought an entire CPU design and implementation team (PA Semi).</div><br/><div id="37317304" class="c"><input type="checkbox" id="c-37317304" checked=""/><div class="controls bullet"><span class="by">monocasa</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37317252">parent</a><span>|</span><a href="#37316968">next</a><span>|</span><label class="collapse" for="c-37317304">[-]</label><label class="expand" for="c-37317304">[2 more]</label></div><br/><div class="children"><div class="content">I mean, they purchased 47% of ARM in the 90s.  That&#x27;s while defining the mobile space in the first place, and it being much more of a gamble than now.  Heavy first line investment to create mobile niches has empirically been their strategy for decades.</div><br/><div id="37317376" class="c"><input type="checkbox" id="c-37317376" checked=""/><div class="controls bullet"><span class="by">throwawaylinux</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37317304">parent</a><span>|</span><a href="#37316968">next</a><span>|</span><label class="collapse" for="c-37317376">[-]</label><label class="expand" for="c-37317376">[1 more]</label></div><br/><div class="children"><div class="content">Apple invested in them for a chip for Newton, not for the ARM architecture in particular. Apple was creating their own PowerPC architcture around this time, and they sold their share of ARM when they gave up on Newton.<p>The PA Semi purchase and redirection of their team from PowerPC to ARM was completely different and obviously signaled they were all in on ARM, like their earlier ARM&#x2F;Newton stuff did not.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37316777" class="c"><input type="checkbox" id="c-37316777" checked=""/><div class="controls bullet"><span class="by">throwaway58480</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316667">parent</a><span>|</span><a href="#37316713">prev</a><span>|</span><a href="#37316384">next</a><span>|</span><label class="collapse" for="c-37316777">[-]</label><label class="expand" for="c-37316777">[2 more]</label></div><br/><div class="children"><div class="content">Apple didn&#x27;t, the Mac business unit did. And it makes sense to consolidate on the investment in chips for phones and tablets.</div><br/><div id="37317120" class="c"><input type="checkbox" id="c-37317120" checked=""/><div class="controls bullet"><span class="by">docfort</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316777">parent</a><span>|</span><a href="#37316384">next</a><span>|</span><label class="collapse" for="c-37317120">[-]</label><label class="expand" for="c-37317120">[1 more]</label></div><br/><div class="children"><div class="content">Apple famously doesn’t do business units. It’s all in on functional organization.</div><br/></div></div></div></div></div></div></div></div><div id="37316384" class="c"><input type="checkbox" id="c-37316384" checked=""/><div class="controls bullet"><span class="by">hypercube33</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316174">parent</a><span>|</span><a href="#37316508">prev</a><span>|</span><a href="#37318132">next</a><span>|</span><label class="collapse" for="c-37316384">[-]</label><label class="expand" for="c-37316384">[4 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s not forget Intel had issues with atom soc chips dying like crazy due to power-on-hours in things like Cisco routers, Nas and other devices around this era too. I think that had a big ripple effect on them to play a cog in their machine around 2018 or so.<p>Yes 10nm+++++ was a big problem, too.<p>Apple was also busy going independent and I think their path is to merge iOS with MacOX someday here so it makes sense to dump x86 in favor of higher control and profit margins.</div><br/><div id="37316908" class="c"><input type="checkbox" id="c-37316908" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316384">parent</a><span>|</span><a href="#37318139">next</a><span>|</span><label class="collapse" for="c-37316908">[-]</label><label class="expand" for="c-37316908">[2 more]</label></div><br/><div class="children"><div class="content">Right. It made no sense for Apple to have complete control over most of their devices, with custom innovations moving between them, and still remain dependent on Intel for one class of devices.<p>Intel downsides for Apple:<p>1. No reliable control of schedule, specs, CPU, GPU, DPU core counts, high&#x2F;low power core ratios, energy envelopes.<p>2. No ability to embed special Apple designed blocks (Secure Enclave, Video processing, whatever, ...)<p>3. Intel still hasn&#x27;t moved to on-chip RAM, shared across all core-types. (As far as I know?)<p>4. The need to negotiate Intel chip supplies, complicated by Intel&#x27;s plans for other partner&#x27;s needs.<p>5. An inability to differentiate Mac&#x27;s basic computing capabilities from every other PC that continues to use Intel.<p>6. Intel requiring Apple to support a second instruction architecture, and a more complex stack of software development tools.<p>Apple solved 1000 problems when they ditched Intel.</div><br/></div></div><div id="37318139" class="c"><input type="checkbox" id="c-37318139" checked=""/><div class="controls bullet"><span class="by">RF_Savage</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316384">parent</a><span>|</span><a href="#37316908">prev</a><span>|</span><a href="#37318132">next</a><span>|</span><label class="collapse" for="c-37318139">[-]</label><label class="expand" for="c-37318139">[1 more]</label></div><br/><div class="children"><div class="content">Yep. Got hit twice by that.   
Enough power on hours on those Atoms = some clock buffer dies and now your device no longer boots.</div><br/></div></div></div></div><div id="37318132" class="c"><input type="checkbox" id="c-37318132" checked=""/><div class="controls bullet"><span class="by">yread</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316174">parent</a><span>|</span><a href="#37316384">prev</a><span>|</span><a href="#37316493">next</a><span>|</span><label class="collapse" for="c-37318132">[-]</label><label class="expand" for="c-37318132">[1 more]</label></div><br/><div class="children"><div class="content">Apple switching to ARM also cost some time. It took like 2 years before you could run Docker on M1. Lots of people delayed their purchases until their apps could run</div><br/></div></div></div></div></div></div><div id="37316493" class="c"><input type="checkbox" id="c-37316493" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#37316136">parent</a><span>|</span><a href="#37316158">prev</a><span>|</span><a href="#37317257">next</a><span>|</span><label class="collapse" for="c-37316493">[-]</label><label class="expand" for="c-37316493">[2 more]</label></div><br/><div class="children"><div class="content">TSMC processes are easier to use and there&#x27;s a whole IP ecosystem around them that doesn&#x27;t exist for Intel&#x27;s in-house processes. I can easily imagine a research project preferring to use TSMC.</div><br/><div id="37316809" class="c"><input type="checkbox" id="c-37316809" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316493">parent</a><span>|</span><a href="#37317257">next</a><span>|</span><label class="collapse" for="c-37316809">[-]</label><label class="expand" for="c-37316809">[1 more]</label></div><br/><div class="children"><div class="content">Many intel products that aren&#x27;t strategically tied to their process nodes use TSMC for this reason. You can buy a lot of stuff off-the-shelf and integration is a lot quicker.</div><br/></div></div></div></div><div id="37317257" class="c"><input type="checkbox" id="c-37317257" checked=""/><div class="controls bullet"><span class="by">georgeburdell</span><span>|</span><a href="#37316136">parent</a><span>|</span><a href="#37316493">prev</a><span>|</span><a href="#37316321">next</a><span>|</span><label class="collapse" for="c-37317257">[-]</label><label class="expand" for="c-37317257">[1 more]</label></div><br/><div class="children"><div class="content">Pretty much everything that isn&#x27;t a logic CPU is a 2nd class citizen at Intel fabs.  It explains why a lot of oddball stuff like this is TSMC.  Example: Silicon Photonics itself is being done in Albuquerque, which was a dead&#x2F;dying site.</div><br/></div></div><div id="37316321" class="c"><input type="checkbox" id="c-37316321" checked=""/><div class="controls bullet"><span class="by">tgtweak</span><span>|</span><a href="#37316136">parent</a><span>|</span><a href="#37317257">prev</a><span>|</span><a href="#37317131">next</a><span>|</span><label class="collapse" for="c-37316321">[-]</label><label class="expand" for="c-37316321">[5 more]</label></div><br/><div class="children"><div class="content">nvidia and amd have already signed contracts to use Intel&#x27;s fab service (angstrom-class) so it&#x27;s not unfathomable to consider.  AMD did the same when they dropped global foundries and it could be argued that this was the main reason for their jump ahead vs intel.<p>They&#x27;re all using ASML lithography machines anyway, so who&#x27;s feeding the wafers into the machine is kind of inconsequential.</div><br/><div id="37316627" class="c"><input type="checkbox" id="c-37316627" checked=""/><div class="controls bullet"><span class="by">sevenlake</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316321">parent</a><span>|</span><a href="#37316497">next</a><span>|</span><label class="collapse" for="c-37316627">[-]</label><label class="expand" for="c-37316627">[1 more]</label></div><br/><div class="children"><div class="content">&quot; amd have already signed contracts to use Intel&#x27;s fab service&quot;<p>Source requested, I follow this news closely and have not seen anything that AMD is using Intel&#x27;s fab.<p>Nvidia praised their test chip and that indicates they <i>might</i> use Intel&#x27;s fab. They have not definitively announced that either (<a href="https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;nvidia-ceo-intel-test-chip-results-for-next-gen-process-look-good" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;nvidia-ceo-intel-test-chip...</a>)<p>Amazon was using Intel Foundry for <i>packaging</i>, not fabrication. And Qualcomm was considering 20A (<a href="https:&#x2F;&#x2F;www.pcgamer.com&#x2F;intel-announces-first-foundry-customers&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.pcgamer.com&#x2F;intel-announces-first-foundry-custom...</a>) in 2021, but there was a rumor earlier this year that Qualcomm might not use it after all (<a href="https:&#x2F;&#x2F;www.notebookcheck.net&#x2F;Qualcomm-reportedly-ditches-Intel-20A-in-favour-of-TSMC-and-Samsung.739789.0.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.notebookcheck.net&#x2F;Qualcomm-reportedly-ditches-In...</a>)</div><br/></div></div><div id="37316497" class="c"><input type="checkbox" id="c-37316497" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316321">parent</a><span>|</span><a href="#37316627">prev</a><span>|</span><a href="#37317136">next</a><span>|</span><label class="collapse" for="c-37316497">[-]</label><label class="expand" for="c-37316497">[1 more]</label></div><br/><div class="children"><div class="content"><i>who&#x27;s feeding the wafers into the machine is kind of inconsequential</i><p>If that was true Intel wouldn&#x27;t be years behind.</div><br/></div></div><div id="37317136" class="c"><input type="checkbox" id="c-37317136" checked=""/><div class="controls bullet"><span class="by">tambourine_man</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37316321">parent</a><span>|</span><a href="#37316497">prev</a><span>|</span><a href="#37316628">next</a><span>|</span><label class="collapse" for="c-37317136">[-]</label><label class="expand" for="c-37317136">[1 more]</label></div><br/><div class="children"><div class="content">That’s a colossal overstatement. I suggest you checkout Asianometry on YouTube.<p>TSMC is in a unique position in the market and its integration with ASML is one of the chapters in this novel.</div><br/></div></div></div></div><div id="37317131" class="c"><input type="checkbox" id="c-37317131" checked=""/><div class="controls bullet"><span class="by">renewiltord</span><span>|</span><a href="#37316136">parent</a><span>|</span><a href="#37316321">prev</a><span>|</span><a href="#37317051">next</a><span>|</span><label class="collapse" for="c-37317131">[-]</label><label class="expand" for="c-37317131">[2 more]</label></div><br/><div class="children"><div class="content">They&#x27;ve used them for maybe 15 years for their non-PC processors, guys.<p>If you search Google with the time filter between 2001 and 2010 you&#x27;ll find news on it.<p>There must be some reason HN users don&#x27;t know very much about semiconductors. Probably principally a software audience? Probably the highest confidence:commentary_quality ratio on this site.</div><br/><div id="37318039" class="c"><input type="checkbox" id="c-37318039" checked=""/><div class="controls bullet"><span class="by">ethbr1</span><span>|</span><a href="#37316136">root</a><span>|</span><a href="#37317131">parent</a><span>|</span><a href="#37317051">next</a><span>|</span><label class="collapse" for="c-37318039">[-]</label><label class="expand" for="c-37318039">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d assume people who do know about semiconductors are more used to NDAs and less apt to publicly pontificate.</div><br/></div></div></div></div></div></div><div id="37317051" class="c"><input type="checkbox" id="c-37317051" checked=""/><div class="controls bullet"><span class="by">shrubble</span><span>|</span><a href="#37316136">prev</a><span>|</span><a href="#37319050">next</a><span>|</span><label class="collapse" for="c-37317051">[-]</label><label class="expand" for="c-37317051">[2 more]</label></div><br/><div class="children"><div class="content">Sun did something similar many years ago, but they abandoned it in later UltraSPARC CPUs. Was it that the threads were starved? Did they find that less cores but faster was better? I can&#x27;t find out much detail about it.<p>Perhaps HN user bcantrill will give us the inside scoop :-)</div><br/><div id="37317153" class="c"><input type="checkbox" id="c-37317153" checked=""/><div class="controls bullet"><span class="by">tyingq</span><span>|</span><a href="#37317051">parent</a><span>|</span><a href="#37319050">next</a><span>|</span><label class="collapse" for="c-37317153">[-]</label><label class="expand" for="c-37317153">[1 more]</label></div><br/><div class="children"><div class="content">I used them in the heyday.  There were workloads where they were fantastic, but anything that needed good single-core performance suffered.  It also often required much more tuning of parameters to perform, or recompilation, etc.  For me, it also coincided with lots more need to use SSL, which had been optimized well for x86 but not Sparc. So now you were dealing with more complexity via SSL offload cards, or reverse proxies.  Basically, just too fussy to make them work well outside a few niche areas.<p>Maybe not a big factor, but it also was bothersome for sysadmins because much of the work we had to do was serial, single core, etc.  Meaning it showed it&#x27;s worst side to the group that usually signed the vendor checks.</div><br/></div></div></div></div><div id="37319050" class="c"><input type="checkbox" id="c-37319050" checked=""/><div class="controls bullet"><span class="by">lcnmrn</span><span>|</span><a href="#37317051">prev</a><span>|</span><a href="#37316101">next</a><span>|</span><label class="collapse" for="c-37319050">[-]</label><label class="expand" for="c-37319050">[1 more]</label></div><br/><div class="children"><div class="content">It will be great to have a setting in the OS to set number of threads per core.</div><br/></div></div><div id="37316101" class="c"><input type="checkbox" id="c-37316101" checked=""/><div class="controls bullet"><span class="by">matt3210</span><span>|</span><a href="#37319050">prev</a><span>|</span><a href="#37316790">next</a><span>|</span><label class="collapse" for="c-37316101">[-]</label><label class="expand" for="c-37316101">[16 more]</label></div><br/><div class="children"><div class="content">8 cores with 528 thread? What’s the math? I assumed 512 but had to reread it</div><br/><div id="37318692" class="c"><input type="checkbox" id="c-37318692" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#37316101">parent</a><span>|</span><a href="#37316111">next</a><span>|</span><label class="collapse" for="c-37318692">[-]</label><label class="expand" for="c-37318692">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s simple:  528 = 8 * (2 +64),<p>where 2 is number of slow threads, like current CPU,<p>and 64 are more like GPU threads.<p>This architecture could be next step in GPU integration. Hope they manage to write efficient implementation for standard math libs.  It could be faster than separate CPU+GPU in one package.</div><br/></div></div><div id="37316111" class="c"><input type="checkbox" id="c-37316111" checked=""/><div class="controls bullet"><span class="by">elromulous</span><span>|</span><a href="#37316101">parent</a><span>|</span><a href="#37318692">prev</a><span>|</span><a href="#37316115">next</a><span>|</span><label class="collapse" for="c-37316111">[-]</label><label class="expand" for="c-37316111">[4 more]</label></div><br/><div class="children"><div class="content">From the article:<p>Here is an interesting one. Intel has a 66-thread-per-core processor with 8 cores in a socket (528 threads?) The cache apparently is not well used due to the workload. This is a RISC ISA not x86.</div><br/><div id="37316143" class="c"><input type="checkbox" id="c-37316143" checked=""/><div class="controls bullet"><span class="by">bhouston</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316111">parent</a><span>|</span><a href="#37316115">next</a><span>|</span><label class="collapse" for="c-37316143">[-]</label><label class="expand" for="c-37316143">[3 more]</label></div><br/><div class="children"><div class="content">I guess it is like a GPU where you have so many threads that it hides pretty much all the memory latency?</div><br/><div id="37316252" class="c"><input type="checkbox" id="c-37316252" checked=""/><div class="controls bullet"><span class="by">dekhn</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316143">parent</a><span>|</span><a href="#37316115">next</a><span>|</span><label class="collapse" for="c-37316252">[-]</label><label class="expand" for="c-37316252">[2 more]</label></div><br/><div class="children"><div class="content">shades of <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cray_MTA" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cray_MTA</a></div><br/><div id="37316543" class="c"><input type="checkbox" id="c-37316543" checked=""/><div class="controls bullet"><span class="by">syspec</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316252">parent</a><span>|</span><a href="#37316115">next</a><span>|</span><label class="collapse" for="c-37316543">[-]</label><label class="expand" for="c-37316543">[1 more]</label></div><br/><div class="children"><div class="content">50 shades of Cray</div><br/></div></div></div></div></div></div></div></div><div id="37316115" class="c"><input type="checkbox" id="c-37316115" checked=""/><div class="controls bullet"><span class="by">wging</span><span>|</span><a href="#37316101">parent</a><span>|</span><a href="#37316111">prev</a><span>|</span><a href="#37316123">next</a><span>|</span><label class="collapse" for="c-37316115">[-]</label><label class="expand" for="c-37316115">[9 more]</label></div><br/><div class="children"><div class="content">&quot;8-core processor with 66 threads per core.&quot; 66*8 = 528. Why 66 is not explained.</div><br/><div id="37316741" class="c"><input type="checkbox" id="c-37316741" checked=""/><div class="controls bullet"><span class="by">adrianmonk</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316115">parent</a><span>|</span><a href="#37316498">next</a><span>|</span><label class="collapse" for="c-37316741">[-]</label><label class="expand" for="c-37316741">[2 more]</label></div><br/><div class="children"><div class="content">Look at slide 6, &quot;Die Architecture&quot; (<a href="https:&#x2F;&#x2F;www.servethehome.com&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;08&#x2F;Intel-Direct-Mesh-to-Mesh-Optical-Fabric_Page_06-scaled.jpg" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.servethehome.com&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;08&#x2F;Inte...</a>).<p>The diagram shows 8 gray boxes (in 2 columns of 4). Each gray box is a core.<p>Above that is a detailed view of what each core looks like. There&#x27;s a middle section labeled &quot;Crossbar&quot;, and above that are 3 boxes labeled STP, MTP, and MTP. Below that are another 3 identical boxes. So each core has 4x MTPs and 2x STP.<p>What are those? The text of the same slide says MTP is &quot;Multi-Threaded Pipelines&quot; with &quot;16 threads per pipeline&quot; and STP is &quot;Single-Threaded Pipelines&quot; with (self-evidently) 1 thread per pipeline.<p>And 4 * 16 + 2 * 1 = 66, so 66 threads per core.</div><br/><div id="37317360" class="c"><input type="checkbox" id="c-37317360" checked=""/><div class="controls bullet"><span class="by">Patrick-STH</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316741">parent</a><span>|</span><a href="#37316498">next</a><span>|</span><label class="collapse" for="c-37317360">[-]</label><label class="expand" for="c-37317360">[1 more]</label></div><br/><div class="children"><div class="content">Good one. These presentations are like 30 min each so it is hard to stay on top of all of them.</div><br/></div></div></div></div><div id="37316498" class="c"><input type="checkbox" id="c-37316498" checked=""/><div class="controls bullet"><span class="by">lambda</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316115">parent</a><span>|</span><a href="#37316741">prev</a><span>|</span><a href="#37316338">next</a><span>|</span><label class="collapse" for="c-37316498">[-]</label><label class="expand" for="c-37316498">[2 more]</label></div><br/><div class="children"><div class="content">Yes it is. They have four 16 thread pipelines, and two single thread pipelines per core. 4*16=64 and 64+2=66</div><br/><div id="37318797" class="c"><input type="checkbox" id="c-37318797" checked=""/><div class="controls bullet"><span class="by">mattashii</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316498">parent</a><span>|</span><a href="#37316338">next</a><span>|</span><label class="collapse" for="c-37318797">[-]</label><label class="expand" for="c-37318797">[1 more]</label></div><br/><div class="children"><div class="content">So, why do they consider that 1 core? Isn&#x27;t that more like a &quot;compute complex&quot; of multiple cores, as seen on zen 2, but with different core architectures attached instead of 4 cores of the same design?</div><br/></div></div></div></div><div id="37316338" class="c"><input type="checkbox" id="c-37316338" checked=""/><div class="controls bullet"><span class="by">loeg</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316115">parent</a><span>|</span><a href="#37316498">prev</a><span>|</span><a href="#37318695">next</a><span>|</span><label class="collapse" for="c-37316338">[-]</label><label class="expand" for="c-37316338">[2 more]</label></div><br/><div class="children"><div class="content">Maybe 2 higher-powered primary threads + 64 aux threads or something.  I don&#x27;t know how that makes sense as part of a single core but I don&#x27;t have a better guess.</div><br/><div id="37316468" class="c"><input type="checkbox" id="c-37316468" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316338">parent</a><span>|</span><a href="#37318695">next</a><span>|</span><label class="collapse" for="c-37316468">[-]</label><label class="expand" for="c-37316468">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s what it is, as shown on slide 6 (Die Architecture). Personally I would call this 16 big cores and 32 throughput cores but for some reason Intel is calling it 8 cores.</div><br/></div></div></div></div><div id="37318695" class="c"><input type="checkbox" id="c-37318695" checked=""/><div class="controls bullet"><span class="by">adrian_b</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316115">parent</a><span>|</span><a href="#37316338">prev</a><span>|</span><a href="#37316169">next</a><span>|</span><label class="collapse" for="c-37318695">[-]</label><label class="expand" for="c-37318695">[1 more]</label></div><br/><div class="children"><div class="content">66 = 64 slow GPU-like threads + 2 very fast CPU-like threads</div><br/></div></div><div id="37316169" class="c"><input type="checkbox" id="c-37316169" checked=""/><div class="controls bullet"><span class="by">teruakohatu</span><span>|</span><a href="#37316101">root</a><span>|</span><a href="#37316115">parent</a><span>|</span><a href="#37318695">prev</a><span>|</span><a href="#37316123">next</a><span>|</span><label class="collapse" for="c-37316169">[-]</label><label class="expand" for="c-37316169">[1 more]</label></div><br/><div class="children"><div class="content">Maybe they just couldn&#x27;t fit 67?</div><br/></div></div></div></div><div id="37316123" class="c"><input type="checkbox" id="c-37316123" checked=""/><div class="controls bullet"><span class="by">tgtweak</span><span>|</span><a href="#37316101">parent</a><span>|</span><a href="#37316115">prev</a><span>|</span><a href="#37316790">next</a><span>|</span><label class="collapse" for="c-37316123">[-]</label><label class="expand" for="c-37316123">[1 more]</label></div><br/><div class="children"><div class="content">66 per core does seem a bit odd! maybe 2 are for routing&#x2F;metadata or something.</div><br/></div></div></div></div><div id="37316790" class="c"><input type="checkbox" id="c-37316790" checked=""/><div class="controls bullet"><span class="by">shae</span><span>|</span><a href="#37316101">prev</a><span>|</span><a href="#37316214">next</a><span>|</span><label class="collapse" for="c-37316790">[-]</label><label class="expand" for="c-37316790">[1 more]</label></div><br/><div class="children"><div class="content">This would be perfect for graph reduction and dataflow programming. I could build some really col things with these if they ever go into production.</div><br/></div></div><div id="37316214" class="c"><input type="checkbox" id="c-37316214" checked=""/><div class="controls bullet"><span class="by">seeknotfind</span><span>|</span><a href="#37316790">prev</a><span>|</span><a href="#37316500">next</a><span>|</span><label class="collapse" for="c-37316214">[-]</label><label class="expand" for="c-37316214">[2 more]</label></div><br/><div class="children"><div class="content">Time to finish rewriting all code to be event driven, io_uring, etc.</div><br/><div id="37316595" class="c"><input type="checkbox" id="c-37316595" checked=""/><div class="controls bullet"><span class="by">convolvatron</span><span>|</span><a href="#37316214">parent</a><span>|</span><a href="#37316500">next</a><span>|</span><label class="collapse" for="c-37316595">[-]</label><label class="expand" for="c-37316595">[1 more]</label></div><br/><div class="children"><div class="content">in this kind of architecture, its generally more fruitful to leave the asynchrony to the hardware. the tera mta, which other people have mentioned has&#x2F;had hardware synchronization in the memory system to effect this.<p>there were no interrupts, just a thread waiting for someone to wake it up.</div><br/></div></div></div></div><div id="37316500" class="c"><input type="checkbox" id="c-37316500" checked=""/><div class="controls bullet"><span class="by">gautamcgoel</span><span>|</span><a href="#37316214">prev</a><span>|</span><a href="#37318063">next</a><span>|</span><label class="collapse" for="c-37316500">[-]</label><label class="expand" for="c-37316500">[5 more]</label></div><br/><div class="children"><div class="content">Did I read the article correctly? Is there 32GB of DRAM on-chip? Or was the DRAM just standard DIMMs?</div><br/><div id="37319065" class="c"><input type="checkbox" id="c-37319065" checked=""/><div class="controls bullet"><span class="by">yvdriess</span><span>|</span><a href="#37316500">parent</a><span>|</span><a href="#37316701">next</a><span>|</span><label class="collapse" for="c-37319065">[-]</label><label class="expand" for="c-37319065">[1 more]</label></div><br/><div class="children"><div class="content">Not on-chip no, it&#x27;s still LPDDR5 form factor DIMMs. What is cool about is that it is using custom DIMMs and memory controllers to do 8B-granularity accesses. Plus, each core has its own MC, as you can see on the die shot. If each MC manages 4GB of DRAM, that would explain the 32GB per chip.</div><br/></div></div><div id="37316701" class="c"><input type="checkbox" id="c-37316701" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#37316500">parent</a><span>|</span><a href="#37319065">prev</a><span>|</span><a href="#37317413">next</a><span>|</span><label class="collapse" for="c-37316701">[-]</label><label class="expand" for="c-37316701">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s regular DDR5.</div><br/></div></div><div id="37317413" class="c"><input type="checkbox" id="c-37317413" checked=""/><div class="controls bullet"><span class="by">geerlingguy</span><span>|</span><a href="#37316500">parent</a><span>|</span><a href="#37316701">prev</a><span>|</span><a href="#37318063">next</a><span>|</span><label class="collapse" for="c-37317413">[-]</label><label class="expand" for="c-37317413">[2 more]</label></div><br/><div class="children"><div class="content">[edit: I think I&#x27;m wrong!] I&#x27;m pretty sure this is HBM (High Bandwidth Memory) on the same substrate: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;High_Bandwidth_Memory" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;High_Bandwidth_Memory</a><p>There are some other explainers out there that go into more detail, but Nvidia is also doing this with Grace Hopper (I think?), and Apple with their M-series chips.<p>Update: It looks like it&#x27;s just DDR5 (&quot;custom DDR5-4400 DRAM&quot;) in this case.</div><br/><div id="37318798" class="c"><input type="checkbox" id="c-37318798" checked=""/><div class="controls bullet"><span class="by">felixg3</span><span>|</span><a href="#37316500">root</a><span>|</span><a href="#37317413">parent</a><span>|</span><a href="#37318063">next</a><span>|</span><label class="collapse" for="c-37318798">[-]</label><label class="expand" for="c-37318798">[1 more]</label></div><br/><div class="children"><div class="content">Apple is not using HBM on M-Series chips, although I bet the speed benefit would be massive.</div><br/></div></div></div></div></div></div><div id="37318063" class="c"><input type="checkbox" id="c-37318063" checked=""/><div class="controls bullet"><span class="by">tiffanyh</span><span>|</span><a href="#37316500">prev</a><span>|</span><a href="#37316107">next</a><span>|</span><label class="collapse" for="c-37318063">[-]</label><label class="expand" for="c-37318063">[3 more]</label></div><br/><div class="children"><div class="content">Use case?<p>What would be a good use case for a high-thread &#x2F; low-core chip?<p>Parallelism, like Erlang systems?</div><br/><div id="37319073" class="c"><input type="checkbox" id="c-37319073" checked=""/><div class="controls bullet"><span class="by">yvdriess</span><span>|</span><a href="#37318063">parent</a><span>|</span><a href="#37318079">next</a><span>|</span><label class="collapse" for="c-37319073">[-]</label><label class="expand" for="c-37319073">[1 more]</label></div><br/><div class="children"><div class="content">Graph workloads and other types of sparse compute.
<a href="https:&#x2F;&#x2F;www.darpa.mil&#x2F;program&#x2F;hierarchical-identify-verify-exploit" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.darpa.mil&#x2F;program&#x2F;hierarchical-identify-verify-e...</a></div><br/></div></div><div id="37318079" class="c"><input type="checkbox" id="c-37318079" checked=""/><div class="controls bullet"><span class="by">worthless-trash</span><span>|</span><a href="#37318063">parent</a><span>|</span><a href="#37319073">prev</a><span>|</span><a href="#37316107">next</a><span>|</span><label class="collapse" for="c-37318079">[-]</label><label class="expand" for="c-37318079">[1 more]</label></div><br/><div class="children"><div class="content">I benchmarked knights-phi at the time (the add on card) for erlang, it was very impressive.<p>Sadly it never took off.</div><br/></div></div></div></div><div id="37316107" class="c"><input type="checkbox" id="c-37316107" checked=""/><div class="controls bullet"><span class="by">tgtweak</span><span>|</span><a href="#37318063">prev</a><span>|</span><a href="#37317732">next</a><span>|</span><label class="collapse" for="c-37316107">[-]</label><label class="expand" for="c-37316107">[7 more]</label></div><br/><div class="children"><div class="content">Just a shout-out to the STH team (hey Patrick) who have been live blogging literally every presentation and announcement from hot chips.  I&#x27;ve been reading up on next gen xeons and google&#x27;s TPU datacenter architecture all day.</div><br/><div id="37317354" class="c"><input type="checkbox" id="c-37317354" checked=""/><div class="controls bullet"><span class="by">Patrick-STH</span><span>|</span><a href="#37316107">parent</a><span>|</span><a href="#37316236">next</a><span>|</span><label class="collapse" for="c-37317354">[-]</label><label class="expand" for="c-37317354">[2 more]</label></div><br/><div class="children"><div class="content">Thanks. We will have more in a bit, and may not get to all of them. I was talking to lots of folks that came to say hi today. Trying to get at least a good portion of these done this week.</div><br/><div id="37317425" class="c"><input type="checkbox" id="c-37317425" checked=""/><div class="controls bullet"><span class="by">geerlingguy</span><span>|</span><a href="#37316107">root</a><span>|</span><a href="#37317354">parent</a><span>|</span><a href="#37316236">next</a><span>|</span><label class="collapse" for="c-37317425">[-]</label><label class="expand" for="c-37317425">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for your service. Between your coverage and Dr. Ian Cutress&#x27;, we can pick up on announcements from events like Hot Chips with a lot more clarity than the PR speak the companies themselves put out.</div><br/></div></div></div></div><div id="37316236" class="c"><input type="checkbox" id="c-37316236" checked=""/><div class="controls bullet"><span class="by">daniel-s</span><span>|</span><a href="#37316107">parent</a><span>|</span><a href="#37317354">prev</a><span>|</span><a href="#37316177">next</a><span>|</span><label class="collapse" for="c-37316236">[-]</label><label class="expand" for="c-37316236">[2 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;youtube.com&#x2F;@ServeTheHomeVideo?feature=shared">https:&#x2F;&#x2F;youtube.com&#x2F;@ServeTheHomeVideo?feature=shared</a><p>The YouTube channel for those who like me are too impatient to ever read.</div><br/><div id="37316506" class="c"><input type="checkbox" id="c-37316506" checked=""/><div class="controls bullet"><span class="by">NikolaNovak</span><span>|</span><a href="#37316107">root</a><span>|</span><a href="#37316236">parent</a><span>|</span><a href="#37316177">next</a><span>|</span><label class="collapse" for="c-37316506">[-]</label><label class="expand" for="c-37316506">[1 more]</label></div><br/><div class="children"><div class="content">Lol, that&#x27;s the story of me and my best friend.<p>I&#x27;m <i>far</i> too impatient for YouTube videos. Gimme an article I can scan.<p>He&#x27;s <i>far</i> too impatient for articles. Give him a YouTube video he can listen to while doing something else.<p>20 years and we haven&#x27;t changed each others mind :-&gt;</div><br/></div></div></div></div><div id="37316177" class="c"><input type="checkbox" id="c-37316177" checked=""/><div class="controls bullet"><span class="by">zakki</span><span>|</span><a href="#37316107">parent</a><span>|</span><a href="#37316236">prev</a><span>|</span><a href="#37317732">next</a><span>|</span><label class="collapse" for="c-37316177">[-]</label><label class="expand" for="c-37316177">[2 more]</label></div><br/><div class="children"><div class="content">Mind to share the link?</div><br/><div id="37316223" class="c"><input type="checkbox" id="c-37316223" checked=""/><div class="controls bullet"><span class="by">tgtweak</span><span>|</span><a href="#37316107">root</a><span>|</span><a href="#37316177">parent</a><span>|</span><a href="#37317732">next</a><span>|</span><label class="collapse" for="c-37316223">[-]</label><label class="expand" for="c-37316223">[1 more]</label></div><br/><div class="children"><div class="content">[1] <a href="https:&#x2F;&#x2F;www.servethehome.com&#x2F;intel-granite-rapids-xeon-held-at-hot-chips-2023&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.servethehome.com&#x2F;intel-granite-rapids-xeon-held-...</a><p>[1b] <a href="https:&#x2F;&#x2F;www.servethehome.com&#x2F;intel-xeon-e-cores-for-next-gen-sierra-forest-and-more-at-hot-chips-2023&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.servethehome.com&#x2F;intel-xeon-e-cores-for-next-gen...</a><p>[2]<a href="https:&#x2F;&#x2F;www.servethehome.com&#x2F;google-details-tpuv4-and-its-crazy-optically-reconfigurable-ai-network&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.servethehome.com&#x2F;google-details-tpuv4-and-its-cr...</a><p>Very interesting to see the adoption of fiber optic in chips (PIC, photonics in chip&#x2F;photonic integrated circuit) from so many big players and newcomers.</div><br/></div></div></div></div></div></div><div id="37317732" class="c"><input type="checkbox" id="c-37317732" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#37316107">prev</a><span>|</span><a href="#37318058">next</a><span>|</span><label class="collapse" for="c-37317732">[-]</label><label class="expand" for="c-37317732">[5 more]</label></div><br/><div class="children"><div class="content">It really seems like Intel is designing this chip to support a very specific workload, when it would have been a better use of everyone&#x27;s time and money to just rewrite the workload to work well on normal chips...</div><br/><div id="37317892" class="c"><input type="checkbox" id="c-37317892" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#37317732">parent</a><span>|</span><a href="#37318058">next</a><span>|</span><label class="collapse" for="c-37317892">[-]</label><label class="expand" for="c-37317892">[4 more]</label></div><br/><div class="children"><div class="content">That graph workload fundamentally cannot work well on normal chips.</div><br/><div id="37318321" class="c"><input type="checkbox" id="c-37318321" checked=""/><div class="controls bullet"><span class="by">jandrewrogers</span><span>|</span><a href="#37317732">root</a><span>|</span><a href="#37317892">parent</a><span>|</span><a href="#37317979">next</a><span>|</span><label class="collapse" for="c-37318321">[-]</label><label class="expand" for="c-37318321">[1 more]</label></div><br/><div class="children"><div class="content">Graph workloads can work well on normal chips but you really have to know what you are doing. Clever algorithms that demonstrated graphs workloads could be efficiently run on CPUs was a major contributor to the demise of barrel processing research, since a lot of the interest in those architectures was for the purposes of efficient graph analysis. Given the option, economics heavily favors commodity silicon.</div><br/></div></div><div id="37317979" class="c"><input type="checkbox" id="c-37317979" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#37317732">root</a><span>|</span><a href="#37317892">parent</a><span>|</span><a href="#37318321">prev</a><span>|</span><a href="#37318058">next</a><span>|</span><label class="collapse" for="c-37317979">[-]</label><label class="expand" for="c-37317979">[2 more]</label></div><br/><div class="children"><div class="content">Citation needed.   Huge sparse graphs can be processed fairly efficiently on both CPU&#x27;s and GPU&#x27;s, but the code has to be written with the architecture in mind.</div><br/><div id="37319152" class="c"><input type="checkbox" id="c-37319152" checked=""/><div class="controls bullet"><span class="by">yvdriess</span><span>|</span><a href="#37317732">root</a><span>|</span><a href="#37317979">parent</a><span>|</span><a href="#37318058">next</a><span>|</span><label class="collapse" for="c-37319152">[-]</label><label class="expand" for="c-37319152">[1 more]</label></div><br/><div class="children"><div class="content">Their inefficiency at large-scale graph problems is the entire reason DARPA wrote out the program that funded this chip.</div><br/></div></div></div></div></div></div></div></div><div id="37318058" class="c"><input type="checkbox" id="c-37318058" checked=""/><div class="controls bullet"><span class="by">mrweasel</span><span>|</span><a href="#37317732">prev</a><span>|</span><a href="#37317168">next</a><span>|</span><label class="collapse" for="c-37318058">[-]</label><label class="expand" for="c-37318058">[10 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t help picturing the OpenBSD developers getting their hands on this and promptly disabling 65 threads per core due to security concerns.</div><br/><div id="37318610" class="c"><input type="checkbox" id="c-37318610" checked=""/><div class="controls bullet"><span class="by">belter</span><span>|</span><a href="#37318058">parent</a><span>|</span><a href="#37318758">next</a><span>|</span><label class="collapse" for="c-37318610">[-]</label><label class="expand" for="c-37318610">[2 more]</label></div><br/><div class="children"><div class="content">Those who sacrifice security to performance, deserve neither :-)</div><br/><div id="37318934" class="c"><input type="checkbox" id="c-37318934" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#37318058">root</a><span>|</span><a href="#37318610">parent</a><span>|</span><a href="#37318758">next</a><span>|</span><label class="collapse" for="c-37318934">[-]</label><label class="expand" for="c-37318934">[1 more]</label></div><br/><div class="children"><div class="content">Founding fathers aside, if you&#x27;re not connected to the internet or even wider LAN, but on some private lab running specific workloads, you don&#x27;t need security from malicious side-loaded apps.</div><br/></div></div></div></div><div id="37318758" class="c"><input type="checkbox" id="c-37318758" checked=""/><div class="controls bullet"><span class="by">kriro</span><span>|</span><a href="#37318058">parent</a><span>|</span><a href="#37318610">prev</a><span>|</span><a href="#37318890">next</a><span>|</span><label class="collapse" for="c-37318758">[-]</label><label class="expand" for="c-37318758">[1 more]</label></div><br/><div class="children"><div class="content">Pretty snarky comment in my opinion. From my understanding, OpenBSDs main reason for not supporting things (apart from the obvious lack of resources) is that they are not free (require blobs etc.).<p>Security concerns are typically solved in software by them as long as they can get access to the hardware in a free (as in freedom) way.<p>I actually applaud them for their hard stance and am happy that we have this end of the spectrum as well as the Linux end (pragmatic, just get devices to work somehow, willing to accept some non-freedom). It&#x27;s certainly not the easiest path to follow.</div><br/></div></div><div id="37318890" class="c"><input type="checkbox" id="c-37318890" checked=""/><div class="controls bullet"><span class="by">deaddodo</span><span>|</span><a href="#37318058">parent</a><span>|</span><a href="#37318758">prev</a><span>|</span><a href="#37318671">next</a><span>|</span><label class="collapse" for="c-37318890">[-]</label><label class="expand" for="c-37318890">[1 more]</label></div><br/><div class="children"><div class="content">I mean, considering Intel has had one of the least performant SMT designs in history, easily being trounced by both SPARC and POWER, you&#x27;d probably still get 70% of the chips&#x27; total performance with them disabled.<p>Now, when they disable Zen SMT, <i>then</i> there might be a decent talking point.</div><br/></div></div><div id="37318671" class="c"><input type="checkbox" id="c-37318671" checked=""/><div class="controls bullet"><span class="by">aitchnyu</span><span>|</span><a href="#37318058">parent</a><span>|</span><a href="#37318890">prev</a><span>|</span><a href="#37319012">next</a><span>|</span><label class="collapse" for="c-37318671">[-]</label><label class="expand" for="c-37318671">[4 more]</label></div><br/><div class="children"><div class="content">Can I have context on whether they are innovation killers or prophets vindicated after years of mockery or somewhere in between?</div><br/><div id="37318762" class="c"><input type="checkbox" id="c-37318762" checked=""/><div class="controls bullet"><span class="by">mrweasel</span><span>|</span><a href="#37318058">root</a><span>|</span><a href="#37318671">parent</a><span>|</span><a href="#37318737">next</a><span>|</span><label class="collapse" for="c-37318762">[-]</label><label class="expand" for="c-37318762">[1 more]</label></div><br/><div class="children"><div class="content">Interesting question. I don&#x27;t believe that neither Intel nor AMD have actually found a way to make SMT completely safe against Microarchitectural Data Sampling attacks, so maybe it&#x27;s not actually possible?<p>If you only care about security, then I think OpenBSDs approach is currently the best, but it also seems like they got lucky a few times, like with Zenbleed, where they for unknown reason never really adopted the AVX to the same extend as Linux or Windows.</div><br/></div></div><div id="37318737" class="c"><input type="checkbox" id="c-37318737" checked=""/><div class="controls bullet"><span class="by">boxed</span><span>|</span><a href="#37318058">root</a><span>|</span><a href="#37318671">parent</a><span>|</span><a href="#37318762">prev</a><span>|</span><a href="#37319012">next</a><span>|</span><label class="collapse" for="c-37318737">[-]</label><label class="expand" for="c-37318737">[2 more]</label></div><br/><div class="children"><div class="content">Imo prophets.</div><br/><div id="37319057" class="c"><input type="checkbox" id="c-37319057" checked=""/><div class="controls bullet"><span class="by">silon42</span><span>|</span><a href="#37318058">root</a><span>|</span><a href="#37318737">parent</a><span>|</span><a href="#37319012">next</a><span>|</span><label class="collapse" for="c-37319057">[-]</label><label class="expand" for="c-37319057">[1 more]</label></div><br/><div class="children"><div class="content">How about people disabling JS by default?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>