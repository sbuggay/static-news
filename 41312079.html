<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1724317256078" as="style"/><link rel="stylesheet" href="styles.css?v=1724317256078"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Launch HN: Outerport (YC S24) – Instant hot-swapping for AI model weights</a> </div><div class="subtext"><span>tovacinni</span> | <span>18 comments</span></div><br/><div><div id="41316764" class="c"><input type="checkbox" id="c-41316764" checked=""/><div class="controls bullet"><span class="by">volkopat</span><span>|</span><a href="#41314506">next</a><span>|</span><label class="collapse" for="c-41316764">[-]</label><label class="expand" for="c-41316764">[2 more]</label></div><br/><div class="children"><div class="content">This is really exciting! I was hoping for someone to tackle inference time and this product will definitely be a boost to some of our use cases in medical imaging.</div><br/><div id="41316941" class="c"><input type="checkbox" id="c-41316941" checked=""/><div class="controls bullet"><span class="by">tovacinni</span><span>|</span><a href="#41316764">parent</a><span>|</span><a href="#41314506">next</a><span>|</span><label class="collapse" for="c-41316941">[-]</label><label class="expand" for="c-41316941">[1 more]</label></div><br/><div class="children"><div class="content">Awesome to hear- that sounds like an application we&#x27;d love to help with!<p>(Please feel free to reach out to us too at towaki@outerport.com !)</div><br/></div></div></div></div><div id="41314506" class="c"><input type="checkbox" id="c-41314506" checked=""/><div class="controls bullet"><span class="by">harrisonjackson</span><span>|</span><a href="#41316764">prev</a><span>|</span><a href="#41317856">next</a><span>|</span><label class="collapse" for="c-41314506">[-]</label><label class="expand" for="c-41314506">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Outerport is a caching system for model weights, allowing read-only models to be cached in pinned RAM for fast loading into GPU. Outerport is also hierarchical, maintaining a cache across S3 to local SSD to RAM to GPU memory, optimizing for reduced data transfer costs and load balancing.<p>This is really cool. Are the costs to run this mainly storage or how much compute is actually tied up in it?<p>The time&#x2F;cost to download models on a gpu cloud instance really add up when you are paying per second.</div><br/><div id="41314781" class="c"><input type="checkbox" id="c-41314781" checked=""/><div class="controls bullet"><span class="by">tovacinni</span><span>|</span><a href="#41314506">parent</a><span>|</span><a href="#41317856">next</a><span>|</span><label class="collapse" for="c-41314781">[-]</label><label class="expand" for="c-41314781">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! If you mean the costs for users of Outerport, it&#x27;ll be a subscription model for our hosted registry (with a limit on storage &#x2F; S3 egress) and a license model for self-hosting the registry. So mainly storage, since the idea is to also minimize egress costs which are associated with the compute tied up in it!</div><br/></div></div></div></div><div id="41317856" class="c"><input type="checkbox" id="c-41317856" checked=""/><div class="controls bullet"><span class="by">raghavbali</span><span>|</span><a href="#41314506">prev</a><span>|</span><a href="#41312754">next</a><span>|</span><label class="collapse" for="c-41317856">[-]</label><label class="expand" for="c-41317856">[1 more]</label></div><br/><div class="children"><div class="content">Yet to go through in detail but this is really powerful. Initiatives such as these are what we need to further democratize DL. Kudos team</div><br/></div></div><div id="41312754" class="c"><input type="checkbox" id="c-41312754" checked=""/><div class="controls bullet"><span class="by">dbmikus</span><span>|</span><a href="#41317856">prev</a><span>|</span><a href="#41314748">next</a><span>|</span><label class="collapse" for="c-41312754">[-]</label><label class="expand" for="c-41312754">[4 more]</label></div><br/><div class="children"><div class="content">This is very cool! Most of the work I&#x27;ve seen on reducing inference costs has been via things like LoRAX that lets multiple fine-tunes share the same underlying base model.<p>Do you imagine Outerport being a better fit for OSS model hosts like Replicate, Anyscale, etc. or for companies that are trying to host multiple models themselves?<p>Your use case mentioned speaks more to the latter, but it seems like the value at scale is with model hosting as a service companies.</div><br/><div id="41312851" class="c"><input type="checkbox" id="c-41312851" checked=""/><div class="controls bullet"><span class="by">tovacinni</span><span>|</span><a href="#41312754">parent</a><span>|</span><a href="#41314748">next</a><span>|</span><label class="collapse" for="c-41312851">[-]</label><label class="expand" for="c-41312851">[3 more]</label></div><br/><div class="children"><div class="content">Thanks!<p>I think both are fits- we&#x27;ve gotten interest from both types of companies and our first customer is a &quot;OSS model host&quot;.<p>Our 40% savings result is also specifically for the 5 model services case, so there could be non-trivial cost reduction even with a reasonably small number of models.</div><br/><div id="41314793" class="c"><input type="checkbox" id="c-41314793" checked=""/><div class="controls bullet"><span class="by">samstave</span><span>|</span><a href="#41312754">root</a><span>|</span><a href="#41312851">parent</a><span>|</span><a href="#41314748">next</a><span>|</span><label class="collapse" for="c-41314793">[-]</label><label class="expand" for="c-41314793">[2 more]</label></div><br/><div class="children"><div class="content">Could you craft a model-weight as a preamble to a prompt? So you can submit prompts through a layer which will pre-warm the model weights for you based on the prompt - Taking the output into some next step in your workflow, apply a new weight preamble depending on what the next phase is?<p>Like, for a particular portion of the workflow - assume some crawler of weird Insurance Claims data of scale - and you want particular weights for the aspects of certain logic that youre running to search for fraud.</div><br/><div id="41314892" class="c"><input type="checkbox" id="c-41314892" checked=""/><div class="controls bullet"><span class="by">tovacinni</span><span>|</span><a href="#41312754">root</a><span>|</span><a href="#41314793">parent</a><span>|</span><a href="#41314748">next</a><span>|</span><label class="collapse" for="c-41314892">[-]</label><label class="expand" for="c-41314892">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a super neat idea- we should in fact be able to use this same system to support the orchestration of a &#x27;system prompt caching&#x27; sort of thing (across deployments). I&#x27;ll put this on my &#x27;things to hack on&#x27; list :)</div><br/></div></div></div></div></div></div></div></div><div id="41314748" class="c"><input type="checkbox" id="c-41314748" checked=""/><div class="controls bullet"><span class="by">bravura</span><span>|</span><a href="#41312754">prev</a><span>|</span><a href="#41315124">next</a><span>|</span><label class="collapse" for="c-41314748">[-]</label><label class="expand" for="c-41314748">[2 more]</label></div><br/><div class="children"><div class="content">Do all variations of the model need to have the same architecture?<p>Or can they be different types of models with different number of layers, etc?</div><br/><div id="41314794" class="c"><input type="checkbox" id="c-41314794" checked=""/><div class="controls bullet"><span class="by">tovacinni</span><span>|</span><a href="#41314748">parent</a><span>|</span><a href="#41315124">next</a><span>|</span><label class="collapse" for="c-41314794">[-]</label><label class="expand" for="c-41314794">[1 more]</label></div><br/><div class="children"><div class="content">Variants do not have to be the same architecture- the demo (<a href="https:&#x2F;&#x2F;hotswap.outerport.com&#x2F;">https:&#x2F;&#x2F;hotswap.outerport.com&#x2F;</a>) runs on a couple of different open source architectures.<p>That being said, there is some smart caching &#x2F; hashing on layers such that if you do have models that are similar (i.e. a fine-tuned model where only some layers are fine-tuned), it&#x27;ll minimize storage and transfer by reusing those weights.</div><br/></div></div></div></div><div id="41315124" class="c"><input type="checkbox" id="c-41315124" checked=""/><div class="controls bullet"><span class="by">CuriouslyC</span><span>|</span><a href="#41314748">prev</a><span>|</span><a href="#41315764">next</a><span>|</span><label class="collapse" for="c-41315124">[-]</label><label class="expand" for="c-41315124">[2 more]</label></div><br/><div class="children"><div class="content">This seems useful but honestly I think you guys are better off getting IP protection and licensing out the technology.  This is a classic &quot;feature not a product&quot; and I don&#x27;t see you competing against google&#x2F;microsoft&#x2F;huggingface in the model management space.</div><br/><div id="41315468" class="c"><input type="checkbox" id="c-41315468" checked=""/><div class="controls bullet"><span class="by">tovacinni</span><span>|</span><a href="#41315124">parent</a><span>|</span><a href="#41315764">next</a><span>|</span><label class="collapse" for="c-41315468">[-]</label><label class="expand" for="c-41315468">[1 more]</label></div><br/><div class="children"><div class="content">Maybe! Many people don&#x27;t want to be vendor locked-in though and there are new GPU cloud providers gaining traction. Some still prefer on-prem.<p>We hope to make it easier to bridge the multi-cloud landscape by being independent and &#x27;outer&#x27;.</div><br/></div></div></div></div><div id="41315764" class="c"><input type="checkbox" id="c-41315764" checked=""/><div class="controls bullet"><span class="by">parrot987</span><span>|</span><a href="#41315124">prev</a><span>|</span><a href="#41315932">next</a><span>|</span><label class="collapse" for="c-41315764">[-]</label><label class="expand" for="c-41315764">[2 more]</label></div><br/><div class="children"><div class="content">This looks awesome! will try it out</div><br/><div id="41316345" class="c"><input type="checkbox" id="c-41316345" checked=""/><div class="controls bullet"><span class="by">tovacinni</span><span>|</span><a href="#41315764">parent</a><span>|</span><a href="#41315932">next</a><span>|</span><label class="collapse" for="c-41316345">[-]</label><label class="expand" for="c-41316345">[1 more]</label></div><br/><div class="children"><div class="content">Thanks!!</div><br/></div></div></div></div><div id="41315932" class="c"><input type="checkbox" id="c-41315932" checked=""/><div class="controls bullet"><span class="by">astroalex</span><span>|</span><a href="#41315764">prev</a><span>|</span><label class="collapse" for="c-41315932">[-]</label><label class="expand" for="c-41315932">[2 more]</label></div><br/><div class="children"><div class="content">Cool! Will this work for multi-GPU inference?</div><br/><div id="41316353" class="c"><input type="checkbox" id="c-41316353" checked=""/><div class="controls bullet"><span class="by">tovacinni</span><span>|</span><a href="#41315932">parent</a><span>|</span><label class="collapse" for="c-41316353">[-]</label><label class="expand" for="c-41316353">[1 more]</label></div><br/><div class="children"><div class="content">Yep, it&#x27;ll work for multi-GPU as well!</div><br/></div></div></div></div></div></div></div></div></div></body></html>