<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1714208455418" as="style"/><link rel="stylesheet" href="styles.css?v=1714208455418"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.twingdata.com/p/building-an-open-data-pipeline-in">Building an open data pipeline in 2024</a> <span class="domain">(<a href="https://blog.twingdata.com">blog.twingdata.com</a>)</span></div><div class="subtext"><span>dangoldin</span> | <span>16 comments</span></div><br/><div><div id="40177937" class="c"><input type="checkbox" id="c-40177937" checked=""/><div class="controls bullet"><span class="by">amadio</span><span>|</span><a href="#40174941">next</a><span>|</span><label class="collapse" for="c-40177937">[-]</label><label class="expand" for="c-40177937">[2 more]</label></div><br/><div class="children"><div class="content">I take issue with this part of the article:<p>&gt; In general, managed tools will give you stronger governance and access controls compared to open source solutions. For businesses dealing with sensitive data that requires a robust security model, commercial solutions may be worth investing in, as they can provide an added layer of reassurance and a stronger audit trail.<p>There are definitely open source solutions capable of managing vast amounts of data securely. The storage group at CERN develops EOS (a distributed filesystem based on the XRootD framework), and CERNBox, which puts a nice web interface on top. See <a href="https:&#x2F;&#x2F;github.com&#x2F;xrootd&#x2F;xrootd">https:&#x2F;&#x2F;github.com&#x2F;xrootd&#x2F;xrootd</a> and <a href="https:&#x2F;&#x2F;github.com&#x2F;cern-eos&#x2F;eos">https:&#x2F;&#x2F;github.com&#x2F;cern-eos&#x2F;eos</a> for more information. See also <a href="https:&#x2F;&#x2F;techweekstorage.web.cern.ch" rel="nofollow">https:&#x2F;&#x2F;techweekstorage.web.cern.ch</a>, a recent event we had along with CS3 at CERN.</div><br/><div id="40178249" class="c"><input type="checkbox" id="c-40178249" checked=""/><div class="controls bullet"><span class="by">AnthonyMouse</span><span>|</span><a href="#40177937">parent</a><span>|</span><a href="#40174941">next</a><span>|</span><label class="collapse" for="c-40178249">[-]</label><label class="expand" for="c-40178249">[1 more]</label></div><br/><div class="children"><div class="content">Not only that, open source and proprietary software both generally handle the common case well, because otherwise nobody would use it.<p>It&#x27;s when you start doing something outside the norm that you notice a difference. Neither of them will be perfect when you&#x27;re the first person trying to do something with the software, but for proprietary software that&#x27;s game over, because you can&#x27;t fix it yourself.</div><br/></div></div></div></div><div id="40174941" class="c"><input type="checkbox" id="c-40174941" checked=""/><div class="controls bullet"><span class="by">RadiozRadioz</span><span>|</span><a href="#40177937">prev</a><span>|</span><label class="collapse" for="c-40174941">[-]</label><label class="expand" for="c-40174941">[13 more]</label></div><br/><div class="children"><div class="content">&gt; And if you’re dealing with truly massive datasets you can take advantage of GPUs for your data jobs.<p>I don&#x27;t think scale is the key deciding factor for whether GPUs are applicable for a given dataset.<p>I don&#x27;t think this is a particularly insightful article. Read the first paragraph of the &quot;Cost&quot; section.</div><br/><div id="40175702" class="c"><input type="checkbox" id="c-40175702" checked=""/><div class="controls bullet"><span class="by">bradford</span><span>|</span><a href="#40174941">parent</a><span>|</span><a href="#40175119">next</a><span>|</span><label class="collapse" for="c-40175702">[-]</label><label class="expand" for="c-40175702">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t think this is a particularly insightful article.<p>Data engineering can be lonely. I like seeing the approach that others are taking, and this article gives me a good idea of the implementation stack.</div><br/><div id="40176691" class="c"><input type="checkbox" id="c-40176691" checked=""/><div class="controls bullet"><span class="by">fredguth</span><span>|</span><a href="#40174941">root</a><span>|</span><a href="#40175702">parent</a><span>|</span><a href="#40175119">next</a><span>|</span><label class="collapse" for="c-40176691">[-]</label><label class="expand" for="c-40176691">[1 more]</label></div><br/><div class="children"><div class="content">Same here. I just wished OP pointed to an example repo with a minimum working example.</div><br/></div></div></div></div><div id="40175119" class="c"><input type="checkbox" id="c-40175119" checked=""/><div class="controls bullet"><span class="by">gchamonlive</span><span>|</span><a href="#40174941">parent</a><span>|</span><a href="#40175702">prev</a><span>|</span><a href="#40175404">next</a><span>|</span><label class="collapse" for="c-40175119">[-]</label><label class="expand" for="c-40175119">[4 more]</label></div><br/><div class="children"><div class="content">Yes I also believe both the dataset and the transformation algorithms have to lend themselves well to parallelization for GPUs to be useful. GPUs don&#x27;t do magic they are just really good at parallel computing.</div><br/><div id="40175481" class="c"><input type="checkbox" id="c-40175481" checked=""/><div class="controls bullet"><span class="by">winwang</span><span>|</span><a href="#40174941">root</a><span>|</span><a href="#40175119">parent</a><span>|</span><a href="#40175404">next</a><span>|</span><label class="collapse" for="c-40175481">[-]</label><label class="expand" for="c-40175481">[3 more]</label></div><br/><div class="children"><div class="content">That&#x27;s right, and that means most transforms in big data. The fact that the dataset can be distributed at all typically implies that the task is parallel.</div><br/><div id="40176581" class="c"><input type="checkbox" id="c-40176581" checked=""/><div class="controls bullet"><span class="by">nyokodo</span><span>|</span><a href="#40174941">root</a><span>|</span><a href="#40175481">parent</a><span>|</span><a href="#40175404">next</a><span>|</span><label class="collapse" for="c-40176581">[-]</label><label class="expand" for="c-40176581">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The fact that the dataset can be distributed at all typically implies that the task is parallel.<p>It depends, big data tasks aren’t necessarily CPU bound but IO bound so you won’t see any speed up throwing GPUs at the problem but you will see a speed up throwing more worker nodes that come with their own network bandwidth and memory. CPU bound problems aren’t all appropriate for GPUs either. I suspect the article author is thinking of ML pipelines where at large scales GPUs are definitely necessary but at lower scales you can get away with ordinary CPUs.</div><br/><div id="40176687" class="c"><input type="checkbox" id="c-40176687" checked=""/><div class="controls bullet"><span class="by">winwang</span><span>|</span><a href="#40174941">root</a><span>|</span><a href="#40176581">parent</a><span>|</span><a href="#40175404">next</a><span>|</span><label class="collapse" for="c-40176687">[-]</label><label class="expand" for="c-40176687">[1 more]</label></div><br/><div class="children"><div class="content">If they aren&#x27;t network&#x2F;disk bound, then GPUs have significantly higher memory bandwidth (per $). If you&#x27;re so network bound that your nodes must be &lt;8 cores, then sure. Otherwise, adding a cheap GPU to your nodes would likely be cheaper.</div><br/></div></div></div></div></div></div></div></div><div id="40175404" class="c"><input type="checkbox" id="c-40175404" checked=""/><div class="controls bullet"><span class="by">dangoldin</span><span>|</span><a href="#40174941">parent</a><span>|</span><a href="#40175119">prev</a><span>|</span><a href="#40175703">next</a><span>|</span><label class="collapse" for="c-40175404">[-]</label><label class="expand" for="c-40175404">[4 more]</label></div><br/><div class="children"><div class="content">Author here and there&#x27;s nuance here but as a rule of thumb data size is a decent enough proxy. Audience here isn&#x27;t everyone and the goal was to give less experienced data engineers and folk a sense of modern data tools and a possible approach.<p>But what did you mean by &quot;Read the first paragraph of the `Cost` section&quot;?</div><br/><div id="40176091" class="c"><input type="checkbox" id="c-40176091" checked=""/><div class="controls bullet"><span class="by">llm_trw</span><span>|</span><a href="#40174941">root</a><span>|</span><a href="#40175404">parent</a><span>|</span><a href="#40175703">next</a><span>|</span><label class="collapse" for="c-40176091">[-]</label><label class="expand" for="c-40176091">[3 more]</label></div><br/><div class="children"><div class="content">&gt;Author here and there&#x27;s nuance here but as a rule of thumb data size is a decent enough proxy.<p>It isn&#x27;t though.<p>What matters is the memory footprint of the algorithm during execution.<p>If you&#x27;re doing transformation that take constant time per item regardless of data size, sure, go for a GPU. If you&#x27;re doing linear work you can&#x27;t fit more than 24gb on a desktop card and prices go to the moon quickly after that.<p>Junior devs doing the equivalent of an outer product on data is the number one reason I&#x27;ve seen data pipelines explode in production.</div><br/><div id="40176571" class="c"><input type="checkbox" id="c-40176571" checked=""/><div class="controls bullet"><span class="by">dangoldin</span><span>|</span><a href="#40174941">root</a><span>|</span><a href="#40176091">parent</a><span>|</span><a href="#40175703">next</a><span>|</span><label class="collapse" for="c-40176571">[-]</label><label class="expand" for="c-40176571">[2 more]</label></div><br/><div class="children"><div class="content">Yes but most data-heavy tasks are parallelizable. SQL itself is naturally parallelizable. There&#x27;s a reason Apache RAPIDs, Voltron, Kinetica, Sqream, etc exist.<p>Full transparency I don&#x27;t have huge amount of experience at working on this massive scale and to your point you need to understand the problem and constraints before you propose a solution.</div><br/><div id="40178421" class="c"><input type="checkbox" id="c-40178421" checked=""/><div class="controls bullet"><span class="by">cgio</span><span>|</span><a href="#40174941">root</a><span>|</span><a href="#40176571">parent</a><span>|</span><a href="#40175703">next</a><span>|</span><label class="collapse" for="c-40178421">[-]</label><label class="expand" for="c-40178421">[1 more]</label></div><br/><div class="children"><div class="content">You have to revisit the assertion that SQL is naturally paralleliseable. As a guide have a look at the semantics around Spark shuffles.</div><br/></div></div></div></div></div></div></div></div><div id="40175703" class="c"><input type="checkbox" id="c-40175703" checked=""/><div class="controls bullet"><span class="by">zX41ZdbW</span><span>|</span><a href="#40174941">parent</a><span>|</span><a href="#40175404">prev</a><span>|</span><label class="collapse" for="c-40175703">[-]</label><label class="expand" for="c-40175703">[2 more]</label></div><br/><div class="children"><div class="content">In fact, the opposite is true. While small datasets can be handled on GPU (although there are no good GPU databases comparable in performance to ClickHouse), large datasets don&#x27;t fit, and unless there is a large amount of computation per byte of data, moving data around will eat the performance.</div><br/><div id="40177439" class="c"><input type="checkbox" id="c-40177439" checked=""/><div class="controls bullet"><span class="by">lmeyerov</span><span>|</span><a href="#40174941">root</a><span>|</span><a href="#40175703">parent</a><span>|</span><label class="collapse" for="c-40177439">[-]</label><label class="expand" for="c-40177439">[1 more]</label></div><br/><div class="children"><div class="content">Sort of<p>Databricks etc architectures are mostly slowly moving data from A to B and doing little work, and worse when that describes the distributed compute part too. I read a paper awhile back where that was often half the time.<p>GPU architectures end up being explicitly about scaling the bandwidth. One of my favorite projects to do with teams tackling something like using GPU RAPIDS to scale event&#x2F;log processing is to get GPU direct storage going. Imagine an SSD array reading back at 100GB&#x2F;s, which feeds 1-2 GPUs at the same (PCI cards), and then TB&#x2F;s for loaded data cross-GPU and mind-blowing many FLOPS. Modern GPUs get you 0.5TB+ per-node GPU RAM. So a single GPU node, when you do the IO bandwidth right for such fat streaming, is insane.<p>So yeah, taking a typical Spark cloud cluster and putting GPUs in vs the above is the difference between drinking from a childrens twirly straw vs a firehose.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>