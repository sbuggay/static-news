<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1712307649518" as="style"/><link rel="stylesheet" href="styles.css?v=1712307649518"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Show HN: Managed GitHub Actions Runners for AWS</a> </div><div class="subtext"><span>jacobwg</span> | <span>52 comments</span></div><br/><div><div id="39937804" class="c"><input type="checkbox" id="c-39937804" checked=""/><div class="controls bullet"><span class="by">jitl</span><span>|</span><a href="#39935283">next</a><span>|</span><label class="collapse" for="c-39937804">[-]</label><label class="expand" for="c-39937804">[3 more]</label></div><br/><div class="children"><div class="content">At Notion we run our GitHub Actions  jobs on ECS, and use auto-scaling to add and remove hosts from the ECS cluster as demand fluctuates throughout the day. We also age out and terminate hosts although they usually live for a few days to a week. I guess we had to pay some one time setup costs around configuring the ECS cluster and fiddling runner tags, but it seems to work pretty well. We have our own cache action although it’s not as fancy as depot’s, just a tarball in s3.<p>Overall it’s pretty simple terraform setup plus a couple dockerfiles. And we get to run in the same region as the rest of our infra that’s close to most of our devs (us-west-2).<p>ECS might sound more complicated than “just use ec2” but we don’t have to screw around with lambdas and the terraform is pretty simple, much simpler then the Philips-labs one. It’s about 1400 lines of Terraform across 2 files since ECS has so much stuff built in and integrates with auto scale groups well.</div><br/><div id="39939935" class="c"><input type="checkbox" id="c-39939935" checked=""/><div class="controls bullet"><span class="by">vicio</span><span>|</span><a href="#39937804">parent</a><span>|</span><a href="#39939147">next</a><span>|</span><label class="collapse" for="c-39939935">[-]</label><label class="expand" for="c-39939935">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for sharing - Do you have any blogpost or YouTube video where you go deep into the details of the implementation? that would be a good one</div><br/></div></div><div id="39939147" class="c"><input type="checkbox" id="c-39939147" checked=""/><div class="controls bullet"><span class="by">liamfd</span><span>|</span><a href="#39937804">parent</a><span>|</span><a href="#39939935">prev</a><span>|</span><a href="#39935283">next</a><span>|</span><label class="collapse" for="c-39939147">[-]</label><label class="expand" for="c-39939147">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like a good setup - if you don&#x27;t mind me asking, what do you use for your auto scaling metric?<p>Also curious how much y&#x27;all isolate it from your other infra. I&#x27;ve thought about this but I&#x27;ve been torn on whether I&#x27;d set up a separate vpc for it.</div><br/></div></div></div></div><div id="39935283" class="c"><input type="checkbox" id="c-39935283" checked=""/><div class="controls bullet"><span class="by">toomuchtodo</span><span>|</span><a href="#39937804">prev</a><span>|</span><a href="#39939180">next</a><span>|</span><label class="collapse" for="c-39935283">[-]</label><label class="expand" for="c-39935283">[8 more]</label></div><br/><div class="children"><div class="content">How will you compete if GitHub talks to the Azure folks (who have the benefit of Azure scale) and gets better compute and network treatment for runners? Or is the assumption GH running remains perpetually stunted as described (which is potentially a fair and legit assumption to make based on MS silos and enterprise inertia)?<p>To be clear, this is a genuine question, as compute (even when efficiently orchestrated and arbitraged) is a commodity. Your cache strategy is good (will be interested in testing to tease out where is S3 and where is Ceph), but not a moat and somewhat straightforward to replicate.<p>(again, questions from a place of curiosity, nothing more)</div><br/><div id="39935484" class="c"><input type="checkbox" id="c-39935484" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39935283">parent</a><span>|</span><a href="#39935680">next</a><span>|</span><label class="collapse" for="c-39935484">[-]</label><label class="expand" for="c-39935484">[4 more]</label></div><br/><div class="children"><div class="content">Yep, it&#x27;s a good question! At the moment, my thoughts are roughly:<p>GitHub&#x27;s incentives and design constraints are different than ours. GitHub needs to offer something that covers a very large user-base, to cover the widest possible number of workflows, and they&#x27;ve done this by offering basic ephemeral VMs on-demand. CI and builds are also not GitHub&#x27;s primary focus as an org.<p>We&#x27;re trying to be the absolute fastest place to build software, with a deep focus on achieving maximum performance and reducing build time as much as possible (even to 0 with caching). Software builds today are often wildly inefficient, and I personally believe there&#x27;s an opportunity to do for build compute what has been done for application compute over the last 10 years.<p>GitHub Actions workflows are more of an &quot;input&quot; for us then (similar to how container image builds have been), with the goal of adding more input types over time and applying the same core tech to all of them.</div><br/><div id="39935501" class="c"><input type="checkbox" id="c-39935501" checked=""/><div class="controls bullet"><span class="by">toomuchtodo</span><span>|</span><a href="#39935283">root</a><span>|</span><a href="#39935484">parent</a><span>|</span><a href="#39937382">next</a><span>|</span><label class="collapse" for="c-39935501">[-]</label><label class="expand" for="c-39935501">[2 more]</label></div><br/><div class="children"><div class="content">Good reply. It seems like you understand the market and where your product fits, which is half the battle.<p>Wishing you much success.</div><br/><div id="39935922" class="c"><input type="checkbox" id="c-39935922" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39935283">root</a><span>|</span><a href="#39935501">parent</a><span>|</span><a href="#39937382">next</a><span>|</span><label class="collapse" for="c-39935922">[-]</label><label class="expand" for="c-39935922">[1 more]</label></div><br/><div class="children"><div class="content">Thank you!</div><br/></div></div></div></div><div id="39937382" class="c"><input type="checkbox" id="c-39937382" checked=""/><div class="controls bullet"><span class="by">JohnMakin</span><span>|</span><a href="#39935283">root</a><span>|</span><a href="#39935484">parent</a><span>|</span><a href="#39935501">prev</a><span>|</span><a href="#39935680">next</a><span>|</span><label class="collapse" for="c-39937382">[-]</label><label class="expand" for="c-39937382">[1 more]</label></div><br/><div class="children"><div class="content">This is a really clever product and I&#x27;d love to learn more - good luck.</div><br/></div></div></div></div><div id="39935680" class="c"><input type="checkbox" id="c-39935680" checked=""/><div class="controls bullet"><span class="by">crohr</span><span>|</span><a href="#39935283">parent</a><span>|</span><a href="#39935484">prev</a><span>|</span><a href="#39938272">next</a><span>|</span><label class="collapse" for="c-39935680">[-]</label><label class="expand" for="c-39935680">[1 more]</label></div><br/><div class="children"><div class="content">I believe the solution is to decentralise, i.e. let the customer run the machines in their own AWS account (what I&#x27;m doing with RunsOn, link in bio if interested).<p>It is very hard for a single player to get favourable treatment from Azure &#x2F; AWS &#x2F; GCP to handle many thousands of jobs every day &#x2F; hour.<p>I wish Depot all the luck, I think they&#x27;ve done good work wrt caching.</div><br/></div></div><div id="39938272" class="c"><input type="checkbox" id="c-39938272" checked=""/><div class="controls bullet"><span class="by">coredog64</span><span>|</span><a href="#39935283">parent</a><span>|</span><a href="#39935680">prev</a><span>|</span><a href="#39935489">next</a><span>|</span><label class="collapse" for="c-39938272">[-]</label><label class="expand" for="c-39938272">[1 more]</label></div><br/><div class="children"><div class="content">Not mentioned down-thread, but GitHub’s incentive is to sell you CI minutes, and slow runners are shooting fish in a barrel.</div><br/></div></div><div id="39935489" class="c"><input type="checkbox" id="c-39935489" checked=""/><div class="controls bullet"><span class="by">playingalong</span><span>|</span><a href="#39935283">parent</a><span>|</span><a href="#39938272">prev</a><span>|</span><a href="#39939180">next</a><span>|</span><label class="collapse" for="c-39935489">[-]</label><label class="expand" for="c-39935489">[1 more]</label></div><br/><div class="children"><div class="content">Corporate inertia might not be the only reason for excessive pricing.<p>They might simply charge for everything working out of the box convenience. Or even for not being aware there are other options.</div><br/></div></div></div></div><div id="39939180" class="c"><input type="checkbox" id="c-39939180" checked=""/><div class="controls bullet"><span class="by">SOLAR_FIELDS</span><span>|</span><a href="#39935283">prev</a><span>|</span><a href="#39938906">next</a><span>|</span><label class="collapse" for="c-39939180">[-]</label><label class="expand" for="c-39939180">[8 more]</label></div><br/><div class="children"><div class="content">One of the most interesting value adds for me is not any of the things mentioned by OP. I would like to have a managed hosted runner solution where I can have a buildkit cache also in the same data center that I manage where I don’t have to pay ingress&#x2F;egress to that cache but also I don’t have to manage my own runner infra. I have done the whole self hosted Karpenter + Actions Runner Controller thing to achieve this and it is a lot of work to set up and tune to get right.<p>The problem is actually really that GitHub’s caching offering is very limited for anything except the most basic of use cases and also they don’t offer a way to colo your own cache with them so that you aren’t paying cloud fees back and forth. You have to use their machines, their storage and their protocol which is only really viable if your definition of caching is literally just “upload files here” and “check if the uploaded built file already exists”.<p>Yes, I’m aware that buildkit offers “experimental” GHA caching support. But given how fat image layers are it’s basically unusable for anything beyond a toy project that builds a couple layers on top of an alpine image (as of the time of writing this post GHA limits cache size to  10gb per repo. Fine if you’re building npm or pypi packages or whatever, but hilariously inadequate for buildkit layer caching)</div><br/><div id="39939552" class="c"><input type="checkbox" id="c-39939552" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39939180">parent</a><span>|</span><a href="#39939348">next</a><span>|</span><label class="collapse" for="c-39939552">[-]</label><label class="expand" for="c-39939552">[1 more]</label></div><br/><div class="children"><div class="content">Hey, yep we have this today! Depot&#x27;s original product is a fully-managed container build service (<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34898253">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34898253</a>) that caches all BuildKit layers to SSDs, so there&#x27;s no cache-to&#x2F;cache-from and cache doesn&#x27;t need to transfer over the network at all.<p>Our original version of that system used vanilla BuildKit + EBS volumes + orchestration, nowadays we&#x27;ve replaced EBS with a distributed ceph storage cluster for significantly faster IOPS and throughput and have modified BuildKit to be better suited for high-performance distributed builds.<p>Both the container build service and the Actions runners are in the same AWS VPC, so they get good network performance between the two and don&#x27;t need to egress over the internet.</div><br/></div></div><div id="39939348" class="c"><input type="checkbox" id="c-39939348" checked=""/><div class="controls bullet"><span class="by">crohr</span><span>|</span><a href="#39939180">parent</a><span>|</span><a href="#39939552">prev</a><span>|</span><a href="#39939483">next</a><span>|</span><label class="collapse" for="c-39939348">[-]</label><label class="expand" for="c-39939348">[3 more]</label></div><br/><div class="children"><div class="content">What you are looking for is a local S3 cache, which buildx supports as a backend. Just make sure you have an S3 gateway connected to your VPC (and that your S3 bucket is in the same region than your runners!) and enjoy free bandwidth, unlimited cache size, and crazy fast network throughput.<p><a href="https:&#x2F;&#x2F;runs-on.com&#x2F;reference&#x2F;caching&#x2F;" rel="nofollow">https:&#x2F;&#x2F;runs-on.com&#x2F;reference&#x2F;caching&#x2F;</a>
<a href="https:&#x2F;&#x2F;runs-on.com&#x2F;features&#x2F;s3-cache-for-github-actions&#x2F;" rel="nofollow">https:&#x2F;&#x2F;runs-on.com&#x2F;features&#x2F;s3-cache-for-github-actions&#x2F;</a></div><br/><div id="39939386" class="c"><input type="checkbox" id="c-39939386" checked=""/><div class="controls bullet"><span class="by">SOLAR_FIELDS</span><span>|</span><a href="#39939180">root</a><span>|</span><a href="#39939348">parent</a><span>|</span><a href="#39939483">next</a><span>|</span><label class="collapse" for="c-39939386">[-]</label><label class="expand" for="c-39939386">[2 more]</label></div><br/><div class="children"><div class="content">Looks neat but is there a way to guarantee that it’s colo’ed with GHA hosted runners and that I won’t pay ingress&#x2F;egress? If not then I don’t see how it’s much different than simply putting up my own bucket aside from saving me the logistics around permissions etc.<p>Edit: I see. This solution you linked doesn’t use GHA hosted runners at all - it’s intended to be a turnkey self hosted runner solution. In other words, a direct competitor to the service linked in OP. That wasn’t super clear from your comment but after reading your links it is more clear. I do really like the pricing here, if it actually works as advertised it’s a pretty great value prop for a lot of orgs.</div><br/><div id="39939452" class="c"><input type="checkbox" id="c-39939452" checked=""/><div class="controls bullet"><span class="by">crohr</span><span>|</span><a href="#39939180">root</a><span>|</span><a href="#39939386">parent</a><span>|</span><a href="#39939483">next</a><span>|</span><label class="collapse" for="c-39939452">[-]</label><label class="expand" for="c-39939452">[1 more]</label></div><br/><div class="children"><div class="content">Oh yes, it can&#x27;t work with GHA hosted runners otherwise you&#x27;ll pay egress fees. From your first post I was assuming you were starting from the point of view that you would be running your own runners already.<p>It does work as advertised, try it :) And yes RunsOn is a direct competitor to the 5 YCombinator-funded companies operating in this space (Ubicloud, Warpbuild, Buildjet, Blacksmith, Depot).</div><br/></div></div></div></div></div></div><div id="39939483" class="c"><input type="checkbox" id="c-39939483" checked=""/><div class="controls bullet"><span class="by">kylegalbraith</span><span>|</span><a href="#39939180">parent</a><span>|</span><a href="#39939348">prev</a><span>|</span><a href="#39939223">next</a><span>|</span><label class="collapse" for="c-39939483">[-]</label><label class="expand" for="c-39939483">[1 more]</label></div><br/><div class="children"><div class="content">Other Depot founder here. This is a really great point.<p>You&#x27;ve hit on all the main points regarding Docker image cache in GHA. Persisting the massive layer cache over networks is incredibly slow and has weird limits (like 10GB per repo). We persist the layer cache to ceph volumes and orchestrate your cache so it&#x27;s immediately available across builds with our first service, accelerated container image builds. Our GHA runners run right next to that same infra, so you don&#x27;t have ingress&#x2F;egress. All that can be hosted in your own AWS account (we&#x27;re also open to running that in any general compute environment for folks who need it).</div><br/></div></div><div id="39939223" class="c"><input type="checkbox" id="c-39939223" checked=""/><div class="controls bullet"><span class="by">boundlessdreamz</span><span>|</span><a href="#39939180">parent</a><span>|</span><a href="#39939483">prev</a><span>|</span><a href="#39938906">next</a><span>|</span><label class="collapse" for="c-39939223">[-]</label><label class="expand" for="c-39939223">[2 more]</label></div><br/><div class="children"><div class="content">The depot.dev service has excellent caching for docker. It&#x27;s almost like building locally.<p>Though the site (depot.dev) focuses on that aspect, this post doesn&#x27;t.<p>@jacobwg - Do the runners in AWS get the same docker caching performance as depot.dev hosted runners?</div><br/><div id="39939591" class="c"><input type="checkbox" id="c-39939591" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39939180">root</a><span>|</span><a href="#39939223">parent</a><span>|</span><a href="#39938906">next</a><span>|</span><label class="collapse" for="c-39939591">[-]</label><label class="expand" for="c-39939591">[1 more]</label></div><br/><div class="children"><div class="content">At the moment, I think you&#x27;d want to use both products together, i.e. using `depot build` in place of `docker build` to move the container build portion to a Depot container builder.<p>I&#x27;d like to have a more automatic integration at some point - the challenge is that a lot of BuildKit&#x27;s architecture performs best when many different build requests all arrive at a single build host, it is then able to efficiently deduplicate and cache work across all those build requests. So you really want the many different Actions jobs all communicating with the same BuildKit host.<p>We have some ideas for reducing the amount of change to Actions workflows to adopt ^ - longer term we&#x27;re also working on our own build engine, to free those workloads from being confined to single hosts (be that single CI runners or single container builders).</div><br/></div></div></div></div></div></div><div id="39938906" class="c"><input type="checkbox" id="c-39938906" checked=""/><div class="controls bullet"><span class="by">cocoflunchy</span><span>|</span><a href="#39939180">prev</a><span>|</span><a href="#39935449">next</a><span>|</span><label class="collapse" for="c-39938906">[-]</label><label class="expand" for="c-39938906">[2 more]</label></div><br/><div class="children"><div class="content">Half the price of github is not great right now, this space is heating up! Ubicloud is 10x cheaper and <a href="https:&#x2F;&#x2F;runs-on.com" rel="nofollow">https:&#x2F;&#x2F;runs-on.com</a> is in the same ballpark by using spot instances. (Currently switching to RunsOn)</div><br/><div id="39940040" class="c"><input type="checkbox" id="c-39940040" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39938906">parent</a><span>|</span><a href="#39935449">next</a><span>|</span><label class="collapse" for="c-39940040">[-]</label><label class="expand" for="c-39940040">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I think our goal is to be the fastest at building software, not necessarily the cheapest. Part of that involves AWS, to have access to more powerful and elastic infrastructure, but that comes at a premium.<p>But besides just compute, I think the bigger long-term unlock for build performance is a new distributed compute engine, to free build workloads from single machines. We&#x27;ve started building this for our container build product, and plan to integrate Actions jobs as an input as well, starting with the cache integration we have today.</div><br/></div></div></div></div><div id="39935449" class="c"><input type="checkbox" id="c-39935449" checked=""/><div class="controls bullet"><span class="by">werewrsdf</span><span>|</span><a href="#39938906">prev</a><span>|</span><a href="#39936182">next</a><span>|</span><label class="collapse" for="c-39935449">[-]</label><label class="expand" for="c-39935449">[4 more]</label></div><br/><div class="children"><div class="content">I recently set up AWS Github runners with this terraform. It works well and you don&#x27;t have to pay any extra in addition to AWS.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;philips-labs&#x2F;terraform-aws-github-runner">https:&#x2F;&#x2F;github.com&#x2F;philips-labs&#x2F;terraform-aws-github-runner</a></div><br/><div id="39936283" class="c"><input type="checkbox" id="c-39936283" checked=""/><div class="controls bullet"><span class="by">striking</span><span>|</span><a href="#39935449">parent</a><span>|</span><a href="#39935774">next</a><span>|</span><label class="collapse" for="c-39936283">[-]</label><label class="expand" for="c-39936283">[2 more]</label></div><br/><div class="children"><div class="content">I helped set this up at my workplace and can second that it works fairly well, but it definitely does have scale issues (we tend to exhaust our GH org&#x27;s API ratelimit and end up being unable to scale up sometimes, as well as seeing containers be prematurely terminated because the scale down lambda doesn&#x27;t seem to always see them in the GH API) and it&#x27;s definitely lacking a lot of tooling around building runner images and caching optimization that we ended up building in-house.<p>Definitely linking OP to my team now.</div><br/><div id="39939128" class="c"><input type="checkbox" id="c-39939128" checked=""/><div class="controls bullet"><span class="by">SOLAR_FIELDS</span><span>|</span><a href="#39935449">root</a><span>|</span><a href="#39936283">parent</a><span>|</span><a href="#39935774">next</a><span>|</span><label class="collapse" for="c-39939128">[-]</label><label class="expand" for="c-39939128">[1 more]</label></div><br/><div class="children"><div class="content">We looked at this Phillips solution originally in a previous org and eventually decided on Karpenter + Actions Runner Controller instead, configured with webhook aka push based triggers. It’s really the best solution for scale but it does take awhile to implement and tune to get right. If you have dedicated infra people I can recommend it. If you don’t, I would look to a more managed solution like OP’s offering</div><br/></div></div></div></div><div id="39935774" class="c"><input type="checkbox" id="c-39935774" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39935449">parent</a><span>|</span><a href="#39936283">prev</a><span>|</span><a href="#39936182">next</a><span>|</span><label class="collapse" for="c-39935774">[-]</label><label class="expand" for="c-39935774">[1 more]</label></div><br/><div class="children"><div class="content">Yeah this is a good option if you&#x27;d like something to deploy yourself! You can also build an AMI from GitHub&#x27;s upstream image definition (<a href="https:&#x2F;&#x2F;github.com&#x2F;actions&#x2F;runner-images&#x2F;tree&#x2F;main&#x2F;images&#x2F;ubuntu">https:&#x2F;&#x2F;github.com&#x2F;actions&#x2F;runner-images&#x2F;tree&#x2F;main&#x2F;images&#x2F;ub...</a>) if you&#x27;d like it to match what&#x27;s available in GitHub-hosted Actions.<p>With Depot, we&#x27;re moving towards deeper performance optimizations and observability than vanilla GitHub runners - we&#x27;ve integrated the runners with a cache storage cluster for instance, and we&#x27;re working on deeper integration with the compute platform that we built for distributed container image builds - as well as expanding the types of builds we can process beyond Actions and Docker, for instance.<p>But different options will be better for different folks, and the `philips-labs` project is good at what it does.</div><br/></div></div></div></div><div id="39936182" class="c"><input type="checkbox" id="c-39936182" checked=""/><div class="controls bullet"><span class="by">madisp</span><span>|</span><a href="#39935449">prev</a><span>|</span><a href="#39937483">next</a><span>|</span><label class="collapse" for="c-39936182">[-]</label><label class="expand" for="c-39936182">[4 more]</label></div><br/><div class="children"><div class="content">&gt; - Each instance has high-throughput networking of up to 12.5 Gbps, hosted in us-east-1, so interacting with artifacts, cache, container registries, or the internet at large is quick.<p>do you actually get the promised 12.5 Gbps? I&#x27;ve been doing some experiments and it&#x27;s really hard to get over 2.5Gbit&#x2F;s upstream from AWS EC2, even when using large 64 vCPU machines. Intra-AWS (e.g. VPC) traffic is another thing and that seems to be ok.</div><br/><div id="39936282" class="c"><input type="checkbox" id="c-39936282" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39936182">parent</a><span>|</span><a href="#39937992">next</a><span>|</span><label class="collapse" for="c-39936282">[-]</label><label class="expand" for="c-39936282">[2 more]</label></div><br/><div class="children"><div class="content">We do get the promised throughput, but it depends on the destination as you&#x27;ve discovered. AWS actually has some docs on this[0]:<p>- For instances with &gt;= 32 vCPUs, traffic to an internet gateway can use 50% of the throughput<p>- For instances with &lt; 32 vCPUs, traffic to an internet gateway can use 5 Gbps<p>- Traffic inside the VPC can use the full throughput<p>So for us, that means traffic outbound to the public internet can use up to 5 Gbps, but for things like our distributed cache or pulling Docker images from our container builders, we can get the full 12.5 Gbps.<p>[0] <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AWSEC2&#x2F;latest&#x2F;UserGuide&#x2F;ec2-instance-network-bandwidth.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AWSEC2&#x2F;latest&#x2F;UserGuide&#x2F;ec2-inst...</a></div><br/></div></div><div id="39937992" class="c"><input type="checkbox" id="c-39937992" checked=""/><div class="controls bullet"><span class="by">mdaniel</span><span>|</span><a href="#39936182">parent</a><span>|</span><a href="#39936282">prev</a><span>|</span><a href="#39937483">next</a><span>|</span><label class="collapse" for="c-39937992">[-]</label><label class="expand" for="c-39937992">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &gt; - Each instance has high-throughput networking of up to 12.5 Gbps, hosted in us-east-1<p>with that pull quote, I thought you were going to point out their use of us-fail-1. I struggle to think of a service that I care so little about its availability that I&#x27;d host it there, but CI&#x2F;CD for sure wouldn&#x27;t be one</div><br/></div></div></div></div><div id="39937483" class="c"><input type="checkbox" id="c-39937483" checked=""/><div class="controls bullet"><span class="by">bpsh</span><span>|</span><a href="#39936182">prev</a><span>|</span><a href="#39935371">next</a><span>|</span><label class="collapse" for="c-39937483">[-]</label><label class="expand" for="c-39937483">[1 more]</label></div><br/><div class="children"><div class="content">Interesting, makes a lot of sense to me as far as pricing too. However, I feel the video demonstration could greatly improve in terms of explaining and enthusiasm. It&#x27;s super cool though and presentations&#x2F;demos should showcase the full potential!</div><br/></div></div><div id="39935371" class="c"><input type="checkbox" id="c-39935371" checked=""/><div class="controls bullet"><span class="by">watermelon0</span><span>|</span><a href="#39937483">prev</a><span>|</span><a href="#39937464">next</a><span>|</span><label class="collapse" for="c-39935371">[-]</label><label class="expand" for="c-39935371">[4 more]</label></div><br/><div class="children"><div class="content">Hey, @jacobwg, this looks great.<p>I couldn&#x27;t find it anywhere on the page, but do you support Graviton3 (i.e. m7g instances) for GHA Runners? If the answer is no, are there any plans to support it in the future?<p>&gt; start them when an actual job request arrives, to keep job queue times around 5 seconds<p>Did you have to fine-tune Ubuntu kernel&#x2F;systemd boot to reach such fast startup times?</div><br/><div id="39935628" class="c"><input type="checkbox" id="c-39935628" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39935371">parent</a><span>|</span><a href="#39935513">next</a><span>|</span><label class="collapse" for="c-39935628">[-]</label><label class="expand" for="c-39935628">[1 more]</label></div><br/><div class="children"><div class="content">We do support Graviton! I actually _just_ enabled them today, which we&#x27;re calling &quot;beta&quot; for the moment: <a href="https:&#x2F;&#x2F;depot.dev&#x2F;docs&#x2F;github-actions&#x2F;overview#depot-supported-configurations">https:&#x2F;&#x2F;depot.dev&#x2F;docs&#x2F;github-actions&#x2F;overview#depot-support...</a>.<p>The challenge with Arm is actually just that GitHub doesn&#x27;t have a runner image defined for Arm. For the Intel runners, we build our image directly from GitHub&#x27;s source[0], and we&#x27;re doing the same for the Arm runners by patching those same Packer scripts for arm64. It also looks like some popular actions, like `actions&#x2F;setup-*`, don&#x27;t always have arm support either.<p>So the disclaimers for launching Depot `-arm` instances at the moment is basically just (1) we have no idea if our image is compatible with your workflows, and (2) those instances take a bit longer to start.<p>On achieving fast startup times, it&#x27;s a challenge. :) The main slowdown that prevents a &lt;5s kernel boot is actually EBS lazy-loading the AMI from S3 on launch.<p>To address that at the moment, we do keep a pool of instances that boot once, load their volume contents, then shutdown until they&#x27;re needed for a job. That works, at the cost of extra complexity and extra money - we&#x27;re experimenting some with more exotic solutions now though like netbooting the AMI. That&#x27;ll be a nice blog post someday I think.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;actions&#x2F;runner-images&#x2F;tree&#x2F;main&#x2F;images&#x2F;ubuntu">https:&#x2F;&#x2F;github.com&#x2F;actions&#x2F;runner-images&#x2F;tree&#x2F;main&#x2F;images&#x2F;ub...</a></div><br/></div></div><div id="39935513" class="c"><input type="checkbox" id="c-39935513" checked=""/><div class="controls bullet"><span class="by">playingalong</span><span>|</span><a href="#39935371">parent</a><span>|</span><a href="#39935628">prev</a><span>|</span><a href="#39937464">next</a><span>|</span><label class="collapse" for="c-39935513">[-]</label><label class="expand" for="c-39935513">[2 more]</label></div><br/><div class="children"><div class="content">Not affiliated, just guessing.<p>This 5 seconds might be the warm start, not cold. I.e. they likely have a pool of autoscaled, multi tenant workers</div><br/><div id="39935648" class="c"><input type="checkbox" id="c-39935648" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39935371">root</a><span>|</span><a href="#39935513">parent</a><span>|</span><a href="#39937464">next</a><span>|</span><label class="collapse" for="c-39935648">[-]</label><label class="expand" for="c-39935648">[1 more]</label></div><br/><div class="children"><div class="content">Yeah 5 seconds is from stopped to running, but to get that speed we need to pre-initialize the root EBS volumes so that they&#x27;re not streaming their contents from S3 during boot. The GitHub Actions runner image is 50GB in size _just_ from preinstalled software!</div><br/></div></div></div></div></div></div><div id="39937464" class="c"><input type="checkbox" id="c-39937464" checked=""/><div class="controls bullet"><span class="by">brycelarkin</span><span>|</span><a href="#39935371">prev</a><span>|</span><a href="#39936819">next</a><span>|</span><label class="collapse" for="c-39937464">[-]</label><label class="expand" for="c-39937464">[1 more]</label></div><br/><div class="children"><div class="content">For the AWS CDK folks, I’ve been very happy with this library. <a href="https:&#x2F;&#x2F;github.com&#x2F;CloudSnorkel&#x2F;cdk-github-runners">https:&#x2F;&#x2F;github.com&#x2F;CloudSnorkel&#x2F;cdk-github-runners</a>. Love that I can use spot pricing and the c7g instances for cicd.</div><br/></div></div><div id="39936819" class="c"><input type="checkbox" id="c-39936819" checked=""/><div class="controls bullet"><span class="by">LilBytes</span><span>|</span><a href="#39937464">prev</a><span>|</span><a href="#39937054">next</a><span>|</span><label class="collapse" for="c-39936819">[-]</label><label class="expand" for="c-39936819">[2 more]</label></div><br/><div class="children"><div class="content">Hey Jacob, awesome suggestion!<p>Are you building your base image from the GitHub runner-images repo?<p>Do you have any appetite for building self hosted EC2 agents for Azure DevOps and GitHub?<p>I&#x27;m happy to help if you are, I&#x27;m working on something similar myself for my employer.</div><br/><div id="39939611" class="c"><input type="checkbox" id="c-39939611" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39936819">parent</a><span>|</span><a href="#39937054">next</a><span>|</span><label class="collapse" for="c-39939611">[-]</label><label class="expand" for="c-39939611">[1 more]</label></div><br/><div class="children"><div class="content">Hey, we are building our base image from the runner-images repo! I&#x27;ll send you an email!</div><br/></div></div></div></div><div id="39937054" class="c"><input type="checkbox" id="c-39937054" checked=""/><div class="controls bullet"><span class="by">math0ne</span><span>|</span><a href="#39936819">prev</a><span>|</span><a href="#39935517">next</a><span>|</span><label class="collapse" for="c-39937054">[-]</label><label class="expand" for="c-39937054">[1 more]</label></div><br/><div class="children"><div class="content">I used this to setup my runners on a dedicated server: <a href="https:&#x2F;&#x2F;github.com&#x2F;vbem&#x2F;multi-runners">https:&#x2F;&#x2F;github.com&#x2F;vbem&#x2F;multi-runners</a></div><br/></div></div><div id="39935517" class="c"><input type="checkbox" id="c-39935517" checked=""/><div class="controls bullet"><span class="by">timvdalen</span><span>|</span><a href="#39937054">prev</a><span>|</span><a href="#39938568">next</a><span>|</span><label class="collapse" for="c-39935517">[-]</label><label class="expand" for="c-39935517">[2 more]</label></div><br/><div class="children"><div class="content">Congrats on shipping! We built something similar internally. Tweaking it for the right cost&#x2F;availability&#x2F;speed was interesting, but we now have it working to where workers are generally spun up from 0 faster than GitHub&#x27;s own are.</div><br/><div id="39935814" class="c"><input type="checkbox" id="c-39935814" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39935517">parent</a><span>|</span><a href="#39938568">next</a><span>|</span><label class="collapse" for="c-39935814">[-]</label><label class="expand" for="c-39935814">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, GitHub&#x27;s runners, especially the ones with &gt;2 CPUs, have surprisingly long start times!</div><br/></div></div></div></div><div id="39938568" class="c"><input type="checkbox" id="c-39938568" checked=""/><div class="controls bullet"><span class="by">YouWhy</span><span>|</span><a href="#39935517">prev</a><span>|</span><a href="#39935460">next</a><span>|</span><label class="collapse" for="c-39938568">[-]</label><label class="expand" for="c-39938568">[2 more]</label></div><br/><div class="children"><div class="content">TL;DR: managed runners by construction constitute a major ongoing infosec liability.<p>A managed runner means not only entrusting a third party with your code but also typically providing it with enough data&#x2F;network connectivity to make testing&#x2F;validation feasible as a part of the build process. While this is doable per se, it introduces multiple major failure modes outside of data owners&#x27; control.<p>Failure scenario (hypothetical): you hydrate your test DB using live data; you store it in a dedicated secure S3 bucket, which you make accessible for the build process. Now the managed runner organization  gets hacked because making resilient infra is hard, and the attackers intercept the S3 credentials used by your build process. Boom! Your live data is now at the mercy of the attackers.</div><br/><div id="39938806" class="c"><input type="checkbox" id="c-39938806" checked=""/><div class="controls bullet"><span class="by">benced</span><span>|</span><a href="#39938568">parent</a><span>|</span><a href="#39935460">next</a><span>|</span><label class="collapse" for="c-39938806">[-]</label><label class="expand" for="c-39938806">[1 more]</label></div><br/><div class="children"><div class="content">It’s not wisdom to point out that using 3P software constitutes a threat vector. Personally, except in rare cases of unusual competence or unusual sensitivity, I believe that in-house CI will be more vulnerable than managed.</div><br/></div></div></div></div><div id="39935460" class="c"><input type="checkbox" id="c-39935460" checked=""/><div class="controls bullet"><span class="by">alas44</span><span>|</span><a href="#39938568">prev</a><span>|</span><a href="#39935232">next</a><span>|</span><label class="collapse" for="c-39935460">[-]</label><label class="expand" for="c-39935460">[2 more]</label></div><br/><div class="children"><div class="content">How do you ensure privacy&#x2F;isolation between users if you have a pool of ready VMs that you re-use?</div><br/><div id="39935661" class="c"><input type="checkbox" id="c-39935661" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39935460">parent</a><span>|</span><a href="#39935232">next</a><span>|</span><label class="collapse" for="c-39935661">[-]</label><label class="expand" for="c-39935661">[1 more]</label></div><br/><div class="children"><div class="content">We don&#x27;t re-use the VMs - a VM&#x27;s lifecycle is basically:<p>1. Launch, prepare basic software, shut down<p>2. A GitHub job request arrives at Depot<p>3. The job is assigned to the stopped VM, which is then started<p>4. The job runs on the VM completes<p>5. The VM is terminated<p>So the pool exists to speed up the EC2 instance launch time, but the VMs themselves are both single-tenant and single-use.</div><br/></div></div></div></div><div id="39935232" class="c"><input type="checkbox" id="c-39935232" checked=""/><div class="controls bullet"><span class="by">playingalong</span><span>|</span><a href="#39935460">prev</a><span>|</span><a href="#39935332">next</a><span>|</span><label class="collapse" for="c-39935232">[-]</label><label class="expand" for="c-39935232">[2 more]</label></div><br/><div class="children"><div class="content">Can I use my own AWS account?</div><br/><div id="39935301" class="c"><input type="checkbox" id="c-39935301" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39935232">parent</a><span>|</span><a href="#39935332">next</a><span>|</span><label class="collapse" for="c-39935301">[-]</label><label class="expand" for="c-39935301">[1 more]</label></div><br/><div class="children"><div class="content">You can! The default is that we launch the runners on our AWS account, but we do also have a bring-your-own-cloud deployment option.<p>We have some docs on this for our container builder product - still need to write the docs for Actions runners too, though they use the same underlying system: <a href="https:&#x2F;&#x2F;depot.dev&#x2F;docs&#x2F;self-hosted&#x2F;overview">https:&#x2F;&#x2F;depot.dev&#x2F;docs&#x2F;self-hosted&#x2F;overview</a>.</div><br/></div></div></div></div><div id="39935332" class="c"><input type="checkbox" id="c-39935332" checked=""/><div class="controls bullet"><span class="by">pestkranker</span><span>|</span><a href="#39935232">prev</a><span>|</span><a href="#39938200">next</a><span>|</span><label class="collapse" for="c-39935332">[-]</label><label class="expand" for="c-39935332">[4 more]</label></div><br/><div class="children"><div class="content">How does it compare to BuildJet?</div><br/><div id="39935535" class="c"><input type="checkbox" id="c-39935535" checked=""/><div class="controls bullet"><span class="by">jacobwg</span><span>|</span><a href="#39935332">parent</a><span>|</span><a href="#39938200">next</a><span>|</span><label class="collapse" for="c-39935535">[-]</label><label class="expand" for="c-39935535">[3 more]</label></div><br/><div class="children"><div class="content">We&#x27;re both offering managed GitHub Actions runners - some of the differences include:<p>- Depot runners are hosted in AWS us-east-1, which has implications for network speed, cache speed, access to internet services, etc. (BuildJet is hosted in Europe - maybe Hetzner?)<p>- Also thanks to AWS: each runner has a dedicated public IP address, so you&#x27;re not sharing any third-party rate limits (e.g. Docker Hub) with other users<p>- We have an option to deploy the runners in your own AWS account or VPC-peer with your VPC<p>- We&#x27;re integrating Actions runners with the acceleration tech we&#x27;ve built for container builds, starting with distributed caching</div><br/><div id="39935634" class="c"><input type="checkbox" id="c-39935634" checked=""/><div class="controls bullet"><span class="by">crohr</span><span>|</span><a href="#39935332">root</a><span>|</span><a href="#39935535">parent</a><span>|</span><a href="#39936289">next</a><span>|</span><label class="collapse" for="c-39935634">[-]</label><label class="expand" for="c-39935634">[1 more]</label></div><br/><div class="children"><div class="content">Yes, BuildJet runs from Hetzner - <a href="https:&#x2F;&#x2F;runs-on.com&#x2F;reference&#x2F;benchmarks-gha-providers&#x2F;" rel="nofollow">https:&#x2F;&#x2F;runs-on.com&#x2F;reference&#x2F;benchmarks-gha-providers&#x2F;</a></div><br/></div></div><div id="39936289" class="c"><input type="checkbox" id="c-39936289" checked=""/><div class="controls bullet"><span class="by">everfrustrated</span><span>|</span><a href="#39935332">root</a><span>|</span><a href="#39935535">parent</a><span>|</span><a href="#39935634">prev</a><span>|</span><a href="#39938200">next</a><span>|</span><label class="collapse" for="c-39936289">[-]</label><label class="expand" for="c-39936289">[1 more]</label></div><br/><div class="children"><div class="content">GitHub has a colo presence in Frankfurt so pulling repos from Europe is quick.</div><br/></div></div></div></div></div></div><div id="39938200" class="c"><input type="checkbox" id="c-39938200" checked=""/><div class="controls bullet"><span class="by">nodesocket</span><span>|</span><a href="#39935332">prev</a><span>|</span><label class="collapse" for="c-39938200">[-]</label><label class="expand" for="c-39938200">[1 more]</label></div><br/><div class="children"><div class="content">A cool idea, but not sure the business case. I wrote a quick and dirty bash script which automates the process of adding 2x GitHub runners on instances (2 CPU cores and 4 GB memory each). Simply scale out horizontally. Since the instances are persistent you get docker image caching out of the box unlike hosted runners on GitHub. Also arm64 is fully supported.</div><br/></div></div></div></div></div></div></div></body></html>