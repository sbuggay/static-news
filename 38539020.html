<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701853256376" as="style"/><link rel="stylesheet" href="styles.css?v=1701853256376"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://ml-explore.github.io/mlx/build/html/index.html">MLX: NumPy like framework for Apple Silicon by Apple</a>Â <span class="domain">(<a href="https://ml-explore.github.io">ml-explore.github.io</a>)</span></div><div class="subtext"><span>dagmx</span> | <span>5 comments</span></div><br/><div><div id="38540858" class="c"><input type="checkbox" id="c-38540858" checked=""/><div class="controls bullet"><span class="by">runnerup</span><span>|</span><a href="#38541228">next</a><span>|</span><label class="collapse" for="c-38540858">[-]</label><label class="expand" for="c-38540858">[2 more]</label></div><br/><div class="children"><div class="content">&gt; The design of MLX is inspired by frameworks like PyTorch, Jax, and ArrayFire. A noteable difference from these frameworks and MLX is the unified memory model. Arrays in MLX live in shared memory. Operations on MLX arrays can be performed on any of the supported device types without performing data copies. Currently supported device types are the CPU and GPU.<p>Weird and unfortunate that a framework made by Apple for Apple Silicon doesn&#x27;t support targeting the Apple Neural Engine.</div><br/><div id="38541345" class="c"><input type="checkbox" id="c-38541345" checked=""/><div class="controls bullet"><span class="by">domschl</span><span>|</span><a href="#38540858">parent</a><span>|</span><a href="#38541228">next</a><span>|</span><label class="collapse" for="c-38541345">[-]</label><label class="expand" for="c-38541345">[1 more]</label></div><br/><div class="children"><div class="content">Neural engine is not helpful for training, its inference hardware, whereas this targets training and research. They use Accelerate and Metal (with seemingly similar&#x2F;identical performance shaders that their Pytorch adaption uses) which allows for high performance training.<p>This project additionally serves as documentation for other platforms to integrate Silicon, which is good.</div><br/></div></div></div></div><div id="38541228" class="c"><input type="checkbox" id="c-38541228" checked=""/><div class="controls bullet"><span class="by">skavi</span><span>|</span><a href="#38540858">prev</a><span>|</span><a href="#38540794">next</a><span>|</span><label class="collapse" for="c-38541228">[-]</label><label class="expand" for="c-38541228">[1 more]</label></div><br/><div class="children"><div class="content">dup: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38539153">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38539153</a></div><br/></div></div><div id="38540794" class="c"><input type="checkbox" id="c-38540794" checked=""/><div class="controls bullet"><span class="by">jerpint</span><span>|</span><a href="#38541228">prev</a><span>|</span><label class="collapse" for="c-38540794">[-]</label><label class="expand" for="c-38540794">[1 more]</label></div><br/><div class="children"><div class="content">The neural network module looks identical to PyTorch</div><br/></div></div></div></div></div></div></div></body></html>