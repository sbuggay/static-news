<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1692176461062" as="style"/><link rel="stylesheet" href="styles.css?v=1692176461062"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://nonint.com/2022/05/30/my-deep-learning-rig/">My deep learning rig (2022)</a> <span class="domain">(<a href="https://nonint.com">nonint.com</a>)</span></div><div class="subtext"><span>jacquesm</span> | <span>68 comments</span></div><br/><div><div id="37140609" class="c"><input type="checkbox" id="c-37140609" checked=""/><div class="controls bullet"><span class="by">knicholes</span><span>|</span><a href="#37141887">next</a><span>|</span><label class="collapse" for="c-37140609">[-]</label><label class="expand" for="c-37140609">[12 more]</label></div><br/><div class="children"><div class="content">I have pretty much the same setup but just 4 3080s in one machine. If you go to rent something from vast.ai, you can see the hardware specs of the most performant machines.  I just copied those and pieced together the rest.  Learning about PCIe versions and ports was very interesting, as I thought I could use another motherboard for a similar purpose, but just because there are four PCIe 3 slots, it doesn&#x27;t mean they&#x27;re all usable at 16x AT THE SAME TIME!<p>I bought 21 R12 Aurora Alienwares and turned a side-office in my garage into a hot-ass crypto farm with two swamp coolers, four 20A circuits, a 15A circuit, and a bunch of surge protectors.  I was always afraid to move something in fear that I&#x27;d overload a circuit due to the effort in calculating which power supply was powering which machine(s).<p>I gave away the 3080s to friends and family and kept the 6 3090s.</div><br/><div id="37142793" class="c"><input type="checkbox" id="c-37142793" checked=""/><div class="controls bullet"><span class="by">keyle</span><span>|</span><a href="#37140609">parent</a><span>|</span><a href="#37141013">next</a><span>|</span><label class="collapse" for="c-37142793">[-]</label><label class="expand" for="c-37142793">[5 more]</label></div><br/><div class="children"><div class="content">I have a dumb question - what do you do with it? And why is it better to have your own hardware for it?<p>Will you ever see positive return on investment from building this or is it feeding the nerd chute?</div><br/><div id="37142835" class="c"><input type="checkbox" id="c-37142835" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140609">root</a><span>|</span><a href="#37142793">parent</a><span>|</span><a href="#37141013">next</a><span>|</span><label class="collapse" for="c-37142835">[-]</label><label class="expand" for="c-37142835">[4 more]</label></div><br/><div class="children"><div class="content">&gt; what do you do with it?<p>&gt;&gt; crypto</div><br/><div id="37142947" class="c"><input type="checkbox" id="c-37142947" checked=""/><div class="controls bullet"><span class="by">trustingtrust</span><span>|</span><a href="#37140609">root</a><span>|</span><a href="#37142835">parent</a><span>|</span><a href="#37141013">next</a><span>|</span><label class="collapse" for="c-37142947">[-]</label><label class="expand" for="c-37142947">[3 more]</label></div><br/><div class="children"><div class="content">QuantFinance.<p>Money in the stock market (or crypto market but similar) is probably the only way to justify tens of thousands of dollars worth of GPUs that become obsolete quickly.<p>The other thing I can think of is Reseach scientists who use it for research. But funded research scientists that I know generally don&#x27;t get hardware to take home. They usually either get tons of cloud credits or time on a supercomputer to do their stuff.</div><br/><div id="37142959" class="c"><input type="checkbox" id="c-37142959" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140609">root</a><span>|</span><a href="#37142947">parent</a><span>|</span><a href="#37141013">next</a><span>|</span><label class="collapse" for="c-37142959">[-]</label><label class="expand" for="c-37142959">[2 more]</label></div><br/><div class="children"><div class="content">They wrote crypto in the original comment.</div><br/><div id="37143030" class="c"><input type="checkbox" id="c-37143030" checked=""/><div class="controls bullet"><span class="by">trustingtrust</span><span>|</span><a href="#37140609">root</a><span>|</span><a href="#37142959">parent</a><span>|</span><a href="#37141013">next</a><span>|</span><label class="collapse" for="c-37143030">[-]</label><label class="expand" for="c-37143030">[1 more]</label></div><br/><div class="children"><div class="content">Ah okay missed it. So not QF. I was hoping someone does QF at home :P</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37141013" class="c"><input type="checkbox" id="c-37141013" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#37140609">parent</a><span>|</span><a href="#37142793">prev</a><span>|</span><a href="#37140867">next</a><span>|</span><label class="collapse" for="c-37141013">[-]</label><label class="expand" for="c-37141013">[5 more]</label></div><br/><div class="children"><div class="content">Swamp coolers for electronics?</div><br/><div id="37141058" class="c"><input type="checkbox" id="c-37141058" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140609">root</a><span>|</span><a href="#37141013">parent</a><span>|</span><a href="#37141995">next</a><span>|</span><label class="collapse" for="c-37141058">[-]</label><label class="expand" for="c-37141058">[1 more]</label></div><br/><div class="children"><div class="content">Phase change based cooling, especially when combined with a natural source of low temp air (such as a large basement) can be remarkably effective. Your typical DC has much too high a power density to be able to utilize this but for a single large rig in a home it could work very well.</div><br/></div></div><div id="37141995" class="c"><input type="checkbox" id="c-37141995" checked=""/><div class="controls bullet"><span class="by">nomel</span><span>|</span><a href="#37140609">root</a><span>|</span><a href="#37141013">parent</a><span>|</span><a href="#37141058">prev</a><span>|</span><a href="#37141787">next</a><span>|</span><label class="collapse" for="c-37141995">[-]</label><label class="expand" for="c-37141995">[2 more]</label></div><br/><div class="children"><div class="content">Consumer electronics are designed for consumer living conditions. In many parts of the world, indoor humidity can sit over 60%, all year long. In a dry climate, you could get some significant cooling, and still be under what you&#x27;ll find in my house.</div><br/><div id="37143932" class="c"><input type="checkbox" id="c-37143932" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#37140609">root</a><span>|</span><a href="#37141995">parent</a><span>|</span><a href="#37141787">next</a><span>|</span><label class="collapse" for="c-37143932">[-]</label><label class="expand" for="c-37143932">[1 more]</label></div><br/><div class="children"><div class="content">Makes sense thanks</div><br/></div></div></div></div><div id="37141787" class="c"><input type="checkbox" id="c-37141787" checked=""/><div class="controls bullet"><span class="by">eep_social</span><span>|</span><a href="#37140609">root</a><span>|</span><a href="#37141013">parent</a><span>|</span><a href="#37141995">prev</a><span>|</span><a href="#37140867">next</a><span>|</span><label class="collapse" for="c-37141787">[-]</label><label class="expand" for="c-37141787">[1 more]</label></div><br/><div class="children"><div class="content">In a dry climate the increased humidity still barely moves the needle and they’re extremely cheap to build and operate.</div><br/></div></div></div></div></div></div><div id="37141887" class="c"><input type="checkbox" id="c-37141887" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#37140609">prev</a><span>|</span><a href="#37140011">next</a><span>|</span><label class="collapse" for="c-37141887">[-]</label><label class="expand" for="c-37141887">[5 more]</label></div><br/><div class="children"><div class="content">&gt; One of my EPYC’s is a retail model, the other is a QS model.<p>What&#x27;s a &quot;QS&quot; model?<p>Okay, I searched and it means &quot;Qualification Sample&quot;, i.e. a grey market, non-production grade CPU.<p>Never encountered this initialism before, despite being a CPU aficionado.  Hope this saves you some frustration!</div><br/><div id="37142806" class="c"><input type="checkbox" id="c-37142806" checked=""/><div class="controls bullet"><span class="by">wincy</span><span>|</span><a href="#37141887">parent</a><span>|</span><a href="#37142894">next</a><span>|</span><label class="collapse" for="c-37142806">[-]</label><label class="expand" for="c-37142806">[3 more]</label></div><br/><div class="children"><div class="content">Looks like I can get a $3000 MSRP EPYC 4th gen 9334 for $750. I can see why people buy them even if it’s not strictly legal.</div><br/><div id="37143157" class="c"><input type="checkbox" id="c-37143157" checked=""/><div class="controls bullet"><span class="by">kimixa</span><span>|</span><a href="#37141887">root</a><span>|</span><a href="#37142806">parent</a><span>|</span><a href="#37142894">next</a><span>|</span><label class="collapse" for="c-37143157">[-]</label><label class="expand" for="c-37143157">[2 more]</label></div><br/><div class="children"><div class="content">Also taking the risk on assuming it&#x27;ll get stuff like microcode updates, notable for the constant churn of new speculative execution attacks or other things that can cause those impossible-to-track-down occasional instability issues.</div><br/><div id="37143339" class="c"><input type="checkbox" id="c-37143339" checked=""/><div class="controls bullet"><span class="by">catchnear4321</span><span>|</span><a href="#37141887">root</a><span>|</span><a href="#37143157">parent</a><span>|</span><a href="#37142894">next</a><span>|</span><label class="collapse" for="c-37143339">[-]</label><label class="expand" for="c-37143339">[1 more]</label></div><br/><div class="children"><div class="content">but will it run crysis</div><br/></div></div></div></div></div></div><div id="37142894" class="c"><input type="checkbox" id="c-37142894" checked=""/><div class="controls bullet"><span class="by">seany</span><span>|</span><a href="#37141887">parent</a><span>|</span><a href="#37142806">prev</a><span>|</span><a href="#37140011">next</a><span>|</span><label class="collapse" for="c-37142894">[-]</label><label class="expand" for="c-37142894">[1 more]</label></div><br/><div class="children"><div class="content">ES = Engineering Sample.  Is also one that you come across from time to time.</div><br/></div></div></div></div><div id="37140011" class="c"><input type="checkbox" id="c-37140011" checked=""/><div class="controls bullet"><span class="by">throwing_away</span><span>|</span><a href="#37141887">prev</a><span>|</span><a href="#37140725">next</a><span>|</span><label class="collapse" for="c-37140011">[-]</label><label class="expand" for="c-37140011">[20 more]</label></div><br/><div class="children"><div class="content">&gt; This is because without dropping serious $$$ on mellanox high-speed NICs and switches, inter-server communication bandwidth quickly becomes the bottleneck when training large models. I can’t afford fancy enterprise grade hardware, so I get around it by keeping my compute all on the same machine. This goal drives many of the choices I made in building out my servers, as you will see.<p>10gbe is very cheap now, but I guess that&#x27;s not enough?</div><br/><div id="37140067" class="c"><input type="checkbox" id="c-37140067" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#37140011">parent</a><span>|</span><a href="#37140121">next</a><span>|</span><label class="collapse" for="c-37140067">[-]</label><label class="expand" for="c-37140067">[12 more]</label></div><br/><div class="children"><div class="content">Yeah, you need 100gbe minimal. 10gbe is too little (PCIe bandwidth can be a bottleneck, and that is already clocked around 100GbE (16GB)).<p>BTW: echo to the author, PSU and in the U.S. (120v) is a major issue why I am limiting to 4-GPUs. Also, it seems 3090 still have NVLink support, wondering why the author haven&#x27;t put that up. From what I experienced, NVLink does help if you run data parallel training.</div><br/><div id="37141822" class="c"><input type="checkbox" id="c-37141822" checked=""/><div class="controls bullet"><span class="by">nixgeek</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140067">parent</a><span>|</span><a href="#37141404">next</a><span>|</span><label class="collapse" for="c-37141822">[-]</label><label class="expand" for="c-37141822">[1 more]</label></div><br/><div class="children"><div class="content">You can do 100GbE for about $150 a port in switch cost (new); you sometimes see ConnectX-5 cards on eBay for about $100-150 a port (used). I’ve got a fairly good amount of 100GbE in my homelab. Pretty affordable in 2023.<p>200GbE and 400GbE is still totally unaffordable for anything remotely personal, IMO.</div><br/></div></div><div id="37141404" class="c"><input type="checkbox" id="c-37141404" checked=""/><div class="controls bullet"><span class="by">wredue</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140067">parent</a><span>|</span><a href="#37141822">prev</a><span>|</span><a href="#37140178">next</a><span>|</span><label class="collapse" for="c-37141404">[-]</label><label class="expand" for="c-37141404">[2 more]</label></div><br/><div class="children"><div class="content">I would be additionally skeptical that there’s any consumer, or even fire decal hardware (gamer brand stuff) that actually delivers consistently on 10gbe across several nodes.<p>Enthusiast &#x2F; small business &#x2F; entry level enterprise gear will get you there, but you’re looking at several hundred dollars per port.</div><br/><div id="37142377" class="c"><input type="checkbox" id="c-37142377" checked=""/><div class="controls bullet"><span class="by">magixx</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37141404">parent</a><span>|</span><a href="#37140178">next</a><span>|</span><label class="collapse" for="c-37142377">[-]</label><label class="expand" for="c-37142377">[1 more]</label></div><br/><div class="children"><div class="content">10Gbe can be pretty cheap ($30 for X540) PC side with used hardware (SFP mostly and not multigig however). Even generic PCIe cards can add a RJ45 10G multigig port for ~$50.
The switch&#x2F;router side is where I find it gets expensive.</div><br/></div></div></div></div><div id="37140178" class="c"><input type="checkbox" id="c-37140178" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140067">parent</a><span>|</span><a href="#37141404">prev</a><span>|</span><a href="#37140459">next</a><span>|</span><label class="collapse" for="c-37140178">[-]</label><label class="expand" for="c-37140178">[4 more]</label></div><br/><div class="children"><div class="content">Couldn&#x27;t you use a 240V dryer socket for that purpose? That should get you 7200 Watts on a 30A circuit.</div><br/><div id="37140591" class="c"><input type="checkbox" id="c-37140591" checked=""/><div class="controls bullet"><span class="by">supertrope</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140178">parent</a><span>|</span><a href="#37140459">next</a><span>|</span><label class="collapse" for="c-37140591">[-]</label><label class="expand" for="c-37140591">[3 more]</label></div><br/><div class="children"><div class="content">You might need a second 240V outlet for the air conditioner to evacuate that much heat.</div><br/><div id="37140615" class="c"><input type="checkbox" id="c-37140615" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140591">parent</a><span>|</span><a href="#37140459">next</a><span>|</span><label class="collapse" for="c-37140615">[-]</label><label class="expand" for="c-37140615">[2 more]</label></div><br/><div class="children"><div class="content">True, but when you operate 7 GPUs on one board I reckon keeping a good eye on your thermals is where it starts. Otherwise you can kiss your GPUs goodbye well before you reach the payback moment.<p>Edit: and you&#x27;d have to factor in that cooling power as well into the running costs.</div><br/></div></div></div></div></div></div><div id="37140459" class="c"><input type="checkbox" id="c-37140459" checked=""/><div class="controls bullet"><span class="by">buildbot</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140067">parent</a><span>|</span><a href="#37140178">prev</a><span>|</span><a href="#37140547">next</a><span>|</span><label class="collapse" for="c-37140459">[-]</label><label class="expand" for="c-37140459">[1 more]</label></div><br/><div class="children"><div class="content">They might not be using nvlink due to selling on vast, someone could rent a single GPU out of the four available. No idea if there is some cross user security implication with nvlink in that scenario.</div><br/></div></div><div id="37140547" class="c"><input type="checkbox" id="c-37140547" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140067">parent</a><span>|</span><a href="#37140459">prev</a><span>|</span><a href="#37140121">next</a><span>|</span><label class="collapse" for="c-37140547">[-]</label><label class="expand" for="c-37140547">[3 more]</label></div><br/><div class="children"><div class="content">Do you have any examples of nvlink improving performance for 3090 with vanilla pytorch DDP? Or are you talking some other training impl?</div><br/><div id="37142468" class="c"><input type="checkbox" id="c-37142468" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140547">parent</a><span>|</span><a href="#37140121">next</a><span>|</span><label class="collapse" for="c-37142468">[-]</label><label class="expand" for="c-37142468">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve literally not seen any real (more than buying another card) improvement with NVlink on anything i&#x27;ve seen online over the past ~year.<p>I&#x27;d honestly be a bit suspect.</div><br/><div id="37143009" class="c"><input type="checkbox" id="c-37143009" checked=""/><div class="controls bullet"><span class="by">choppaface</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37142468">parent</a><span>|</span><a href="#37140121">next</a><span>|</span><label class="collapse" for="c-37143009">[-]</label><label class="expand" for="c-37143009">[1 more]</label></div><br/><div class="children"><div class="content">I have seen some benefit on A100s only but am unfamiliar with how to get any nvlink gains on RTX cards. Monitoring vanilla pytorch DDP in nvtop on RTX, I haven’t seen PCIE bus transfer speeds approaching the theoretical max.  The OP uses bifurcators in his 8-gpu box so clearly OP does not seem to be bus-limited.</div><br/></div></div></div></div></div></div></div></div><div id="37140121" class="c"><input type="checkbox" id="c-37140121" checked=""/><div class="controls bullet"><span class="by">LTL_FTC</span><span>|</span><a href="#37140011">parent</a><span>|</span><a href="#37140067">prev</a><span>|</span><a href="#37140090">next</a><span>|</span><label class="collapse" for="c-37140121">[-]</label><label class="expand" for="c-37140121">[1 more]</label></div><br/><div class="children"><div class="content">If these server boards support thunderbolt AIC&#x27;s, and I believe they might as my Threadripper Pro board does, daisy chaining them together could get you 40Gbps somewhat easily, if that is sufficient.</div><br/></div></div><div id="37140090" class="c"><input type="checkbox" id="c-37140090" checked=""/><div class="controls bullet"><span class="by">bradfox2</span><span>|</span><a href="#37140011">parent</a><span>|</span><a href="#37140121">prev</a><span>|</span><a href="#37140725">next</a><span>|</span><label class="collapse" for="c-37140090">[-]</label><label class="expand" for="c-37140090">[6 more]</label></div><br/><div class="children"><div class="content">100gbe mellanox connect x cards are not actually that expensive though.</div><br/><div id="37140190" class="c"><input type="checkbox" id="c-37140190" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140090">parent</a><span>|</span><a href="#37140725">next</a><span>|</span><label class="collapse" for="c-37140190">[-]</label><label class="expand" for="c-37140190">[5 more]</label></div><br/><div class="children"><div class="content">You&#x27;d need a switch too, unless you&#x27;re going point-to-point but that will eat up PCI slots that you probably would like to use for GPUs.</div><br/><div id="37140509" class="c"><input type="checkbox" id="c-37140509" checked=""/><div class="controls bullet"><span class="by">tuetuopay</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140190">parent</a><span>|</span><a href="#37140675">next</a><span>|</span><label class="collapse" for="c-37140509">[-]</label><label class="expand" for="c-37140509">[2 more]</label></div><br/><div class="children"><div class="content">mikrotik makes some pretty nice hardware for rather cheap. they now offer a 4x100Gbps switch for $800, which is a darn good price.</div><br/><div id="37140538" class="c"><input type="checkbox" id="c-37140538" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140509">parent</a><span>|</span><a href="#37140675">next</a><span>|</span><label class="collapse" for="c-37140538">[-]</label><label class="expand" for="c-37140538">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, at $200 &#x2F; port that&#x27;s really neat if that&#x27;s all you need. Funny, I remember paying close to $1000 &#x2F; port for 100 mbps not all that long ago :)</div><br/></div></div></div></div><div id="37140675" class="c"><input type="checkbox" id="c-37140675" checked=""/><div class="controls bullet"><span class="by">bradfox2</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140190">parent</a><span>|</span><a href="#37140509">prev</a><span>|</span><a href="#37140725">next</a><span>|</span><label class="collapse" for="c-37140675">[-]</label><label class="expand" for="c-37140675">[2 more]</label></div><br/><div class="children"><div class="content">You really want gpu rdma though. It&#x27;s a bit of a pain to get setup but it&#x27;s worth it.</div><br/><div id="37140732" class="c"><input type="checkbox" id="c-37140732" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140011">root</a><span>|</span><a href="#37140675">parent</a><span>|</span><a href="#37140725">next</a><span>|</span><label class="collapse" for="c-37140732">[-]</label><label class="expand" for="c-37140732">[1 more]</label></div><br/><div class="children"><div class="content">Not on the 3090 though, isn&#x27;t it?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37140725" class="c"><input type="checkbox" id="c-37140725" checked=""/><div class="controls bullet"><span class="by">jpdus</span><span>|</span><a href="#37140011">prev</a><span>|</span><a href="#37143066">next</a><span>|</span><label class="collapse" for="c-37140725">[-]</label><label class="expand" for="c-37140725">[6 more]</label></div><br/><div class="children"><div class="content">What&#x27;s your opinion on the coming (or not) GPU crunch?<p>When looking at cloud GPU availability and current trends (no one except some enthusiasts and bigtech is finetuning and serving on a large scale yet and results keep getting better and better), I fear we will run into a situation where GPUs will be extremely expensive and hard to come by until supply catches up?<p>I ordered a high end PC with 4090 for the first time in years (normally would always prefer cloud even if more expensive) because I want to be on the safe side. What do you think, is this irrational and just a bubble thing?</div><br/><div id="37141255" class="c"><input type="checkbox" id="c-37141255" checked=""/><div class="controls bullet"><span class="by">panarky</span><span>|</span><a href="#37140725">parent</a><span>|</span><a href="#37143066">next</a><span>|</span><label class="collapse" for="c-37141255">[-]</label><label class="expand" for="c-37141255">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a temporary crunch while TSMC expands capacity. They were reluctant to invest in capacity during the crypto crunch because they (rightly) understood that to be a temporary spike in demand. This time, they (also rightly) recognize AI as a longer-term shift in demand, and they&#x27;re busy retooling to meet it.<p>The real question is whether NVIDIA will maintain its lock on the market, or if vendor-agnostic Torch will help commoditize the segment.</div><br/><div id="37143537" class="c"><input type="checkbox" id="c-37143537" checked=""/><div class="controls bullet"><span class="by">arvinsim</span><span>|</span><a href="#37140725">root</a><span>|</span><a href="#37141255">parent</a><span>|</span><a href="#37142521">next</a><span>|</span><label class="collapse" for="c-37143537">[-]</label><label class="expand" for="c-37143537">[1 more]</label></div><br/><div class="children"><div class="content">I am also thinking if I should build a rig to bet against expensive GPU prices.<p>My fear is that Nvidia trying to anchor GPU prices to crypto levels whether there is TSMC shortage is not.</div><br/></div></div><div id="37142521" class="c"><input type="checkbox" id="c-37142521" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#37140725">root</a><span>|</span><a href="#37141255">parent</a><span>|</span><a href="#37143537">prev</a><span>|</span><a href="#37142767">next</a><span>|</span><label class="collapse" for="c-37142521">[-]</label><label class="expand" for="c-37142521">[1 more]</label></div><br/><div class="children"><div class="content">&quot;thanks Facebook&quot; was not a term I have ever actually wanted to utter.</div><br/></div></div><div id="37142767" class="c"><input type="checkbox" id="c-37142767" checked=""/><div class="controls bullet"><span class="by">drBonkers</span><span>|</span><a href="#37140725">root</a><span>|</span><a href="#37141255">parent</a><span>|</span><a href="#37142521">prev</a><span>|</span><a href="#37143066">next</a><span>|</span><label class="collapse" for="c-37142767">[-]</label><label class="expand" for="c-37142767">[2 more]</label></div><br/><div class="children"><div class="content">&gt; vendor-agnostic Torch<p>Is this a competitor to CUDA?</div><br/><div id="37143335" class="c"><input type="checkbox" id="c-37143335" checked=""/><div class="controls bullet"><span class="by">Roark66</span><span>|</span><a href="#37140725">root</a><span>|</span><a href="#37142767">parent</a><span>|</span><a href="#37143066">next</a><span>|</span><label class="collapse" for="c-37143335">[-]</label><label class="expand" for="c-37143335">[1 more]</label></div><br/><div class="children"><div class="content">Cuda runs on a lower layer than torch. There is not much competition to cuda if one wants performance, but if one just wants to run it there is cpu (openblas etc and Intel&#x27;s MKL) and onnx.<p>It&#x27;s pretty astonishing to me AMD has neither a proper math library (like MKL) nor gpu compute library (like cuda).</div><br/></div></div></div></div></div></div></div></div><div id="37143066" class="c"><input type="checkbox" id="c-37143066" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#37140725">prev</a><span>|</span><a href="#37140184">next</a><span>|</span><label class="collapse" for="c-37143066">[-]</label><label class="expand" for="c-37143066">[3 more]</label></div><br/><div class="children"><div class="content">I am duper frustrated that AMD doesn&#x27;t make a &quot;ML Edition&quot; 48GB 7900. They dont have much to lose, so why not throw down the gauntlet.<p>Doubly so for Intel. They literally have no pro market to lose with a 32GB A770, and everything to gain from momentum for their stack.</div><br/><div id="37143154" class="c"><input type="checkbox" id="c-37143154" checked=""/><div class="controls bullet"><span class="by">slavik81</span><span>|</span><a href="#37143066">parent</a><span>|</span><a href="#37143274">next</a><span>|</span><label class="collapse" for="c-37143154">[-]</label><label class="expand" for="c-37143154">[1 more]</label></div><br/><div class="children"><div class="content">The Radeon Pro W7900 is 48 GB. <a href="https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;products&#x2F;professional-graphics&#x2F;amd-radeon-pro-w7900" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.amd.com&#x2F;en&#x2F;products&#x2F;professional-graphics&#x2F;amd-ra...</a><p>The W7900 is officially supported by ROCm on Windows. On Linux, the W7900 is enabled, though not officially supported.</div><br/></div></div><div id="37143274" class="c"><input type="checkbox" id="c-37143274" checked=""/><div class="controls bullet"><span class="by">kimixa</span><span>|</span><a href="#37143066">parent</a><span>|</span><a href="#37143154">prev</a><span>|</span><a href="#37140184">next</a><span>|</span><label class="collapse" for="c-37143274">[-]</label><label class="expand" for="c-37143274">[1 more]</label></div><br/><div class="children"><div class="content">Probably because they want people to buy the W&#x2F;MI series cards instead.<p>Though looking around you can get an MI60 on ebay for $500, seems really good for 32gb and still seems to be supported by rocm (as it&#x27;s just an MI50 with more hbm). Looks to be the cheapest way of getting a GPU with that region of memory support, though things like FP16 speed and BF support suffers compared to later generations. Though from what I&#x27;ve seen most &quot;home&quot; ML tasks are often memory limited pretty hard before ALU limitations kick in. And no idea if a home user would be able to use the IF links either for helping multi-gpu either.</div><br/></div></div></div></div><div id="37140184" class="c"><input type="checkbox" id="c-37140184" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#37143066">prev</a><span>|</span><a href="#37143505">next</a><span>|</span><label class="collapse" for="c-37140184">[-]</label><label class="expand" for="c-37140184">[10 more]</label></div><br/><div class="children"><div class="content">Without a fully connected NVLink network, the 3090s will be underutilized for models that distribute the layers across multiple GPUs.<p>If AMD were better supported, it would be most economical to use 4x MI60s for 128GB using an Infinity Fabric bridge. However, in order to get to the end of such a journey, you would have to know something.</div><br/><div id="37140469" class="c"><input type="checkbox" id="c-37140469" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#37140184">parent</a><span>|</span><a href="#37140195">next</a><span>|</span><label class="collapse" for="c-37140469">[-]</label><label class="expand" for="c-37140469">[8 more]</label></div><br/><div class="children"><div class="content">The bifurcated risers mean that some of the cards are only running at x8 pcie speed as well, and they mention they are only working with pcie-3 not 4.<p>This would severely limit training using model parallelism.<p>For data parallel where the full model fits on each card and the batch size is just increased it wouldn&#x27;t matter as much, and maybe that is the primary use for this.<p>I wonder how this is dealt with on vast.ai rentals.  Because there is a huge difference if I needed 7x 3090&#x27;s where I need all 168GB to load weights on a single giant LLM model vs. just wanting to run 4GB Stable Diffusion in parallel inference with a massive batch size....</div><br/><div id="37140552" class="c"><input type="checkbox" id="c-37140552" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140184">root</a><span>|</span><a href="#37140469">parent</a><span>|</span><a href="#37140195">next</a><span>|</span><label class="collapse" for="c-37140552">[-]</label><label class="expand" for="c-37140552">[7 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see much in terms of differentiation based on topology and interconnect, I also searched the FAQ. Maybe I&#x27;m missing something?</div><br/><div id="37140911" class="c"><input type="checkbox" id="c-37140911" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#37140184">root</a><span>|</span><a href="#37140552">parent</a><span>|</span><a href="#37140195">next</a><span>|</span><label class="collapse" for="c-37140911">[-]</label><label class="expand" for="c-37140911">[6 more]</label></div><br/><div class="children"><div class="content">It could completely depend on what size model your are training the topology, it may not make a difference for you, but for reference-<p>See here [0] about just the difference between having NV-link between cards or not, and the 23% increase in training speed, and the note that the peak bandwidth between 2x 3090s with the link is a peak of 112.5 GB&#x2F;sec.<p>[0]: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers&#x2F;v4.31.0&#x2F;en&#x2F;perf_hardware#nvlink" rel="nofollow noreferrer">https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers&#x2F;v4.31.0&#x2F;en&#x2F;perf_har...</a><p>Now look at PCIe 3.0 speeds, which would be what any two cards talking to each other would need to use thru your risers- only 15.754 GB&#x2F;s on x16 and only 7.877 GB&#x2F;s if you are on a x8 riser.<p>For some non-ML things that I use GPU&#x27;s for (CFD), the interconnect &#x2F; memory access bandwidth is the bottleneck, and the simulation time literally scales near linearly with the PCIe bandwidth I have between cpu lanes and the cards.</div><br/><div id="37141041" class="c"><input type="checkbox" id="c-37141041" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140184">root</a><span>|</span><a href="#37140911">parent</a><span>|</span><a href="#37140195">next</a><span>|</span><label class="collapse" for="c-37141041">[-]</label><label class="expand" for="c-37141041">[5 more]</label></div><br/><div class="children"><div class="content">Hm, that makes me wonder whether vast.ai does some kind of testing prior to dropping particular workloads on a machine so that this can be done without configuration. But there doesn&#x27;t seem to be a financial incentive to suppliers of GPU capacity to provide for good interconnects.</div><br/><div id="37141187" class="c"><input type="checkbox" id="c-37141187" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#37140184">root</a><span>|</span><a href="#37141041">parent</a><span>|</span><a href="#37140195">next</a><span>|</span><label class="collapse" for="c-37141187">[-]</label><label class="expand" for="c-37141187">[4 more]</label></div><br/><div class="children"><div class="content">vast.ai does denote GPU&#x27;s as either PCIe or SXM (SXM for the A100&#x27;s and now H100&#x27;s up there).  The SXM bandwidth between GPU&#x27;s is the full n-way NV-link, the best you can get;<p>They also have a little stat that lists &#x27;per-GPU&#x27; bandwidth in GB&#x2F;s and what PCIe version and speed  is being used.  So they must run some tests beforehand to gauge this.  When I look on there now it varys setup to setup.  I see people running quad 4090&#x27;s on PCIe4.0 x16 with 24GB&#x2F;s bandwidth between them, some people running x8, some on PCIe3.0 with 11 GB&#x2F;s, even someone with quad 3090&#x27;s but all on PCIe 2.0 x1 slots with the bandwidth reading 0.3GB&#x2F;s!!! (likely an old mining rig with those x1 slots)</div><br/><div id="37141245" class="c"><input type="checkbox" id="c-37141245" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140184">root</a><span>|</span><a href="#37141187">parent</a><span>|</span><a href="#37140195">next</a><span>|</span><label class="collapse" for="c-37141245">[-]</label><label class="expand" for="c-37141245">[3 more]</label></div><br/><div class="children"><div class="content">Do they get more money per instance or is that simply a matter of seeing more utilization?</div><br/><div id="37141325" class="c"><input type="checkbox" id="c-37141325" checked=""/><div class="controls bullet"><span class="by">mk_stjames</span><span>|</span><a href="#37140184">root</a><span>|</span><a href="#37141245">parent</a><span>|</span><a href="#37140195">next</a><span>|</span><label class="collapse" for="c-37141325">[-]</label><label class="expand" for="c-37141325">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never rented on there so I&#x27;m not sure. It seems like the prices are set by the sellers but with some guidance from their performance tool, likely?<p>The have a overall &quot;DLperf&quot; deep learning performance score which is an performance metric and it seems like if you want to get users you set your price per hour at something competitive in line with the market given that metric.<p>For instance, the guy with the quad 3090s on x1 slots actually has an hourly price set HIGHER than everyone else... even with horrible DLPerf score.  No one is using that, ever.</div><br/><div id="37141467" class="c"><input type="checkbox" id="c-37141467" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140184">root</a><span>|</span><a href="#37141325">parent</a><span>|</span><a href="#37140195">next</a><span>|</span><label class="collapse" for="c-37141467">[-]</label><label class="expand" for="c-37141467">[1 more]</label></div><br/><div class="children"><div class="content">Interesting... I should try some workloads to see what it can do in practice. Beats having a whole bunch of fans in my room and it seems to be cheaper than the other cloud GPU providers.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="37140195" class="c"><input type="checkbox" id="c-37140195" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140184">parent</a><span>|</span><a href="#37140469">prev</a><span>|</span><a href="#37143505">next</a><span>|</span><label class="collapse" for="c-37140195">[-]</label><label class="expand" for="c-37140195">[1 more]</label></div><br/><div class="children"><div class="content">What kind of factor would that be?</div><br/></div></div></div></div><div id="37143505" class="c"><input type="checkbox" id="c-37143505" checked=""/><div class="controls bullet"><span class="by">ragebol</span><span>|</span><a href="#37140184">prev</a><span>|</span><a href="#37140268">next</a><span>|</span><label class="collapse" for="c-37143505">[-]</label><label class="expand" for="c-37143505">[1 more]</label></div><br/><div class="children"><div class="content">&gt; PSUs: 3x EVGA 1600W G+<p>With the proper plumbing, you could hook up your water heater to it as well.</div><br/></div></div><div id="37140268" class="c"><input type="checkbox" id="c-37140268" checked=""/><div class="controls bullet"><span class="by">hooloovoo_zoo</span><span>|</span><a href="#37143505">prev</a><span>|</span><a href="#37142978">next</a><span>|</span><label class="collapse" for="c-37140268">[-]</label><label class="expand" for="c-37140268">[2 more]</label></div><br/><div class="children"><div class="content">Interesting, wonder what the actual income from vast.ai looked like.</div><br/><div id="37140380" class="c"><input type="checkbox" id="c-37140380" checked=""/><div class="controls bullet"><span class="by">jacquesm</span><span>|</span><a href="#37140268">parent</a><span>|</span><a href="#37142978">next</a><span>|</span><label class="collapse" for="c-37140380">[-]</label><label class="expand" for="c-37140380">[1 more]</label></div><br/><div class="children"><div class="content">Likewise, based on the costs listed on their page I&#x27;d say no more than $.8 &#x2F; hour or so assuming a 50% gross margin for vast.ai.<p>And that includes energy costs so I assume the OP has a cheap source of power. Here in NL I could not do this profitably, even off solar power it would be more efficient to sell that power to the grid than to use it to drive a GPU rig.</div><br/></div></div></div></div><div id="37141059" class="c"><input type="checkbox" id="c-37141059" checked=""/><div class="controls bullet"><span class="by">tamimio</span><span>|</span><a href="#37142978">prev</a><span>|</span><a href="#37139885">next</a><span>|</span><label class="collapse" for="c-37141059">[-]</label><label class="expand" for="c-37141059">[4 more]</label></div><br/><div class="children"><div class="content">We barely got done with mining craziness and now we have DL&#x2F;LLM craziness..</div><br/><div id="37142530" class="c"><input type="checkbox" id="c-37142530" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#37141059">parent</a><span>|</span><a href="#37143240">next</a><span>|</span><label class="collapse" for="c-37142530">[-]</label><label class="expand" for="c-37142530">[1 more]</label></div><br/><div class="children"><div class="content">There is an actual difference. You can make acutal, real-world, impacts with today&#x27;s LLMs in the existing business world. They can actually make a difference for customers.<p>That was never the case with a crypto currency.</div><br/></div></div><div id="37143240" class="c"><input type="checkbox" id="c-37143240" checked=""/><div class="controls bullet"><span class="by">slt2021</span><span>|</span><a href="#37141059">parent</a><span>|</span><a href="#37142530">prev</a><span>|</span><a href="#37139885">next</a><span>|</span><label class="collapse" for="c-37143240">[-]</label><label class="expand" for="c-37143240">[2 more]</label></div><br/><div class="children"><div class="content">Gamers though can breathe free, because LLM requires max GPU memory cards, while gamers are fine with smaller memory size cards</div><br/><div id="37143889" class="c"><input type="checkbox" id="c-37143889" checked=""/><div class="controls bullet"><span class="by">Havoc</span><span>|</span><a href="#37141059">root</a><span>|</span><a href="#37143240">parent</a><span>|</span><a href="#37139885">next</a><span>|</span><label class="collapse" for="c-37143889">[-]</label><label class="expand" for="c-37143889">[1 more]</label></div><br/><div class="children"><div class="content">To a point. All those gaming gpus with 8gb aber starting to reach their limits</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>