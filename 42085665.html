<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1731142866730" as="style"/><link rel="stylesheet" href="styles.css?v=1731142866730"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2410.21228">LoRA vs. Full Fine-Tuning: An Illusion of Equivalence</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>timbilt</span> | <span>55 comments</span></div><br/><div><div id="42086277" class="c"><input type="checkbox" id="c-42086277" checked=""/><div class="controls bullet"><span class="by">pwillia7</span><span>|</span><a href="#42087119">next</a><span>|</span><label class="collapse" for="c-42086277">[-]</label><label class="expand" for="c-42086277">[5 more]</label></div><br/><div class="children"><div class="content">This tracks with my feelings making and using Stable Diffusion Loras and fine tunes. Still, with the speed to train and use, Loras have worked for me in most use cases and it hasn&#x27;t been worth fine tuning the entire model.</div><br/><div id="42086413" class="c"><input type="checkbox" id="c-42086413" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#42086277">parent</a><span>|</span><a href="#42087119">next</a><span>|</span><label class="collapse" for="c-42086413">[-]</label><label class="expand" for="c-42086413">[4 more]</label></div><br/><div class="children"><div class="content">Yeah,it reflects the “feel” I get from lLoRa as well, especially if I overdo it. The new data becomes the preferred output even for unrelated  inputs.  I always felt like it was bludgeoning the model to some extent vs finetuning.<p>Also, LoRa tuning an extensively tuned model occasionally provokes full on  delusional “insanity” or gibberish seizures.<p>I have had really good luck though using a highly tuned model as the training basis for a LoRa and then applying that LoRa mask to the base version of that model. I’m not sure why that seems to work better than the same LoRa training directly on the base model.</div><br/><div id="42088411" class="c"><input type="checkbox" id="c-42088411" checked=""/><div class="controls bullet"><span class="by">cheald</span><span>|</span><a href="#42086277">root</a><span>|</span><a href="#42086413">parent</a><span>|</span><a href="#42087119">next</a><span>|</span><label class="collapse" for="c-42088411">[-]</label><label class="expand" for="c-42088411">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve done a lot of tinkering with the internals of LoRA training, specifically investigating why fine-tune and LoRA training result in such different results, and I&#x27;m no academic, but I have found that there are definitely some issues with the SOTA at least WRT Stable Diffusion.<p>I&#x27;ve had significant success with alternate init mechanisms (the standard technique of init&#x27;ing B to zeros really does hurt gradient flow), training alpha as a separate parameter (and <i>especially</i> if you bootstrap the process with alphas learned from a previous run), and altering the per-layer learning rates (because (lr * B) @ (lr @ A) produces an update of a fundamentally different magnitude than the fine-tune update of W * lr = lr * B @ A).<p>In the context of Stable Diffusion specifically, as well, there&#x27;s some really pathological stuff that happens when training text encoders alongside the unet; for SD-1.5, the norm of &quot;good&quot; embeddings settles right around 28.0, but the model learns that it can reduce loss by pushing the embeddings away from that value. However, this comes at the cost of de-generalizing your outputs! Adding a second loss term which penalizes the network for drifting away from the L1 norm of the untrained embeddings for a given text substantially reduces the &quot;insanity&quot; tendencies. There&#x27;s a more complete writeup at <a href="https:&#x2F;&#x2F;github.com&#x2F;kohya-ss&#x2F;sd-scripts&#x2F;discussions&#x2F;294#discussioncomment-9977651">https:&#x2F;&#x2F;github.com&#x2F;kohya-ss&#x2F;sd-scripts&#x2F;discussions&#x2F;294#discu...</a><p>You also have the fact that the current SOTA training tools just straight up don&#x27;t train some layers that fine-tunes do.<p>I do think there&#x27;s a huge amount of ground to be gained in diffusion LoRA training, but most of the existing techniques work well enough that people settle for &quot;good enough&quot;.</div><br/><div id="42088951" class="c"><input type="checkbox" id="c-42088951" checked=""/><div class="controls bullet"><span class="by">doctorpangloss</span><span>|</span><a href="#42086277">root</a><span>|</span><a href="#42088411">parent</a><span>|</span><a href="#42087119">next</a><span>|</span><label class="collapse" for="c-42088951">[-]</label><label class="expand" for="c-42088951">[2 more]</label></div><br/><div class="children"><div class="content">Most people are using LoRAs as a solution for IP transfer.<p>Thing is Ideogram v2 has already achieved IP transfer without fine tuning or adapters. So we know those aren&#x27;t needed.<p>Is Ideogram v2 an exotic architecture? No, I don&#x27;t think so.<p>Are there exotic architectures that will solve IP transfer and other tasks? The Chameleon and OmniGen architectures. Lots of expertise went into SD3 and Flux dataset prep, but: the multimodal architectures are so much more flexible and expressive.<p>Flow matching models are maybe the last we will see before multi-modal goes big.<p>What to make of things in the community? How is it possible that random hyperparameters and 30 minute long fine tunings produce good results?<p>(1) Dreambooth effect: if it&#x27;s like, a dog, you won&#x27;t notice the flaws.<p>(2) Filing drawer problem. Nobody publishes the 99 things that didn&#x27;t work.<p>(3) SD &lt;3 struggled with IP transfer on image content that could not have possibly been in its datasets. But laypeople are not doing that. They don&#x27;t have access to art content that Stability and BFL also don&#x27;t have access to.<p>(4) Faces: of course SD family saw celebrity images. Faces are over-represented in its datasets. So yeah, it&#x27;s going to be good at IP transfer of photographic faces. Most are in-sample.</div><br/><div id="42092945" class="c"><input type="checkbox" id="c-42092945" checked=""/><div class="controls bullet"><span class="by">jey</span><span>|</span><a href="#42086277">root</a><span>|</span><a href="#42088951">parent</a><span>|</span><a href="#42087119">next</a><span>|</span><label class="collapse" for="c-42092945">[-]</label><label class="expand" for="c-42092945">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s &quot;IP transfer&quot; in this context?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42087119" class="c"><input type="checkbox" id="c-42087119" checked=""/><div class="controls bullet"><span class="by">sorenjan</span><span>|</span><a href="#42086277">prev</a><span>|</span><a href="#42086056">next</a><span>|</span><label class="collapse" for="c-42087119">[-]</label><label class="expand" for="c-42087119">[2 more]</label></div><br/><div class="children"><div class="content">&gt; We randomly initialize A such that it has singular values of 1, freeze it, and only train B. When we do this, we see a sharp reduction in high ranking intruder dimensions in comparison to those in normal LoRA<p>This sounds interesting, but I can&#x27;t see that they do much with this result. Are they saving it for a follow up paper? I would think that if their whole paper is about a big problem with LoRAs and they then find what looks like an easy solution for that problem that would warrant more than a paragraph just before the conclusion.<p>It would also have been interesting if they included the DoRA method, they reference it briefly and that paper claims to resemble fine tuning learning behavior.<p>But perhaps this paper is focused on LoRA behavior, and a separate paper comparing various improvements is better.</div><br/><div id="42089032" class="c"><input type="checkbox" id="c-42089032" checked=""/><div class="controls bullet"><span class="by">liuliu</span><span>|</span><a href="#42087119">parent</a><span>|</span><a href="#42086056">next</a><span>|</span><label class="collapse" for="c-42089032">[-]</label><label class="expand" for="c-42089032">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, honestly not too surprising. Happy someone made the experiments though.<p><i>I think</i> we know that NN with limited data tends to over-fitting, so to train LoRA you need stronger regularization mechanism, that including:<p>* Fixing A as projection matrix so it doesn&#x27;t rotate to an &quot;easier&quot; orientation for B to learn.<p>* Periodically merging AB into W_tuned to simulate the full-model finetuning behavior.<p>I think fundamentally, LoRA is sound because gradient matrix is low-rank by its nature.</div><br/></div></div></div></div><div id="42086056" class="c"><input type="checkbox" id="c-42086056" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#42087119">prev</a><span>|</span><a href="#42088212">next</a><span>|</span><label class="collapse" for="c-42086056">[-]</label><label class="expand" for="c-42086056">[4 more]</label></div><br/><div class="children"><div class="content">So, in layman’s terms, LoRa appears to “traumatize “ the model to some degree, connecting the vector space with strong “jumpers” (intruder dimensions)  to change it’s behavior, instead of subtly conforming the entire model into a shape that accommodates the new data.<p>These jumpers or shortcuts do create connections between the relevant new concepts in the model, but by directly connecting them instead of associating them through the existing network of concepts, nuance is lost and the bypassed areas become deemphasized, leading to forgetting of previously held  associations.<p>Because of this, In general, fine tuning produces better results than LoRa in most cases, especially when forgetting of existing training is detrimental.<p>Or, to further oversimplify the issue in SE terms, LoRa == monkeypatching.  (Is this a kind of intruder dimension?)</div><br/><div id="42087315" class="c"><input type="checkbox" id="c-42087315" checked=""/><div class="controls bullet"><span class="by">six_four_eight</span><span>|</span><a href="#42086056">parent</a><span>|</span><a href="#42086865">next</a><span>|</span><label class="collapse" for="c-42087315">[-]</label><label class="expand" for="c-42087315">[1 more]</label></div><br/><div class="children"><div class="content">I wonder how this compares to &#x27;catastrophic forgetting&#x27; that can be a problem of full fine tuning. Or at least that&#x27;s what I&#x27;ve just been reading as a case _for_ using LoRa, as it&#x27;s not susceptible to that.  I guess this paper shows LoRa causes forgetting in a different way.<p>Are there good general principles yet for what fine tuning method to use in certain situations?  It still seems quite difficult to know ahead of time what&#x27;s going to happen.</div><br/></div></div><div id="42086865" class="c"><input type="checkbox" id="c-42086865" checked=""/><div class="controls bullet"><span class="by">ismailmaj</span><span>|</span><a href="#42086056">parent</a><span>|</span><a href="#42087315">prev</a><span>|</span><a href="#42086586">next</a><span>|</span><label class="collapse" for="c-42086865">[-]</label><label class="expand" for="c-42086865">[1 more]</label></div><br/><div class="children"><div class="content">How does it compare to partially fine-tuning the model by freezing most of the network beside the last few layers?</div><br/></div></div><div id="42086586" class="c"><input type="checkbox" id="c-42086586" checked=""/><div class="controls bullet"><span class="by">Mockapapella</span><span>|</span><a href="#42086056">parent</a><span>|</span><a href="#42086865">prev</a><span>|</span><a href="#42088212">next</a><span>|</span><label class="collapse" for="c-42086586">[-]</label><label class="expand" for="c-42086586">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for this layman explanation</div><br/></div></div></div></div><div id="42088212" class="c"><input type="checkbox" id="c-42088212" checked=""/><div class="controls bullet"><span class="by">viktour19</span><span>|</span><a href="#42086056">prev</a><span>|</span><a href="#42089989">next</a><span>|</span><label class="collapse" for="c-42088212">[-]</label><label class="expand" for="c-42088212">[5 more]</label></div><br/><div class="children"><div class="content">&gt; LoRA and full fine-tuning, with equal performance on the fine-tuning task, can have solutions with very different generalization behaviors outside the fine-tuning task distribution.<p>The ability for nnets to generalize is inherently tied to their trainable parameter count via mechanisms we don&#x27;t understand but we know parameter count is the key. When you finetune with lora, you&#x27;re updating maybe 5% of the parameters, I really don&#x27;t think there is an illusion of equivalence in the field.</div><br/><div id="42089755" class="c"><input type="checkbox" id="c-42089755" checked=""/><div class="controls bullet"><span class="by">kelseyfrog</span><span>|</span><a href="#42088212">parent</a><span>|</span><a href="#42088827">next</a><span>|</span><label class="collapse" for="c-42089755">[-]</label><label class="expand" for="c-42089755">[2 more]</label></div><br/><div class="children"><div class="content">&gt; When you finetune with lora, you&#x27;re updating maybe 5% of the parameters<p>I&#x27;m not sure I understand this comment. The LoRA paper[1] specifically says that all of the pretrained weights remain frozen.<p>&gt; keeping the pre-trained weights frozen<p>Specifically, the LoRA paper differentiates itself from updating some parameters by stating<p>&gt; Many sought to mitigate this by adapting only some parameters or
learning external modules for new tasks.<p>1. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2106.09685" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2106.09685</a></div><br/><div id="42090407" class="c"><input type="checkbox" id="c-42090407" checked=""/><div class="controls bullet"><span class="by">viktour19</span><span>|</span><a href="#42088212">root</a><span>|</span><a href="#42089755">parent</a><span>|</span><a href="#42088827">next</a><span>|</span><label class="collapse" for="c-42090407">[-]</label><label class="expand" for="c-42090407">[1 more]</label></div><br/><div class="children"><div class="content">The effective parameters of the model are the parameters of the original model + lora parameters i.e lora updates only lora parameters, and full finetuning updates only original model parameters.</div><br/></div></div></div></div><div id="42088827" class="c"><input type="checkbox" id="c-42088827" checked=""/><div class="controls bullet"><span class="by">abhgh</span><span>|</span><a href="#42088212">parent</a><span>|</span><a href="#42089755">prev</a><span>|</span><a href="#42088587">next</a><span>|</span><label class="collapse" for="c-42088827">[-]</label><label class="expand" for="c-42088827">[1 more]</label></div><br/><div class="children"><div class="content">More magnitude than count [1] I think, but I haven&#x27;t kept up in a while.<p>[1] <a href="https:&#x2F;&#x2F;proceedings.neurips.cc&#x2F;paper_files&#x2F;paper&#x2F;1996&#x2F;file&#x2F;fb2fcd534b0ff3bbed73cc51df620323-Paper.pdf" rel="nofollow">https:&#x2F;&#x2F;proceedings.neurips.cc&#x2F;paper_files&#x2F;paper&#x2F;1996&#x2F;file&#x2F;f...</a></div><br/></div></div><div id="42088587" class="c"><input type="checkbox" id="c-42088587" checked=""/><div class="controls bullet"><span class="by">wrs</span><span>|</span><a href="#42088212">parent</a><span>|</span><a href="#42088827">prev</a><span>|</span><a href="#42089989">next</a><span>|</span><label class="collapse" for="c-42088587">[-]</label><label class="expand" for="c-42088587">[1 more]</label></div><br/><div class="children"><div class="content">Well, I think it depends who you talk to. I suspect quite a few practitioners (as opposed to researchers) regard LoRA as a valid shortcut without full consideration of the difference.</div><br/></div></div></div></div><div id="42089989" class="c"><input type="checkbox" id="c-42089989" checked=""/><div class="controls bullet"><span class="by">deskr</span><span>|</span><a href="#42088212">prev</a><span>|</span><a href="#42088937">next</a><span>|</span><label class="collapse" for="c-42089989">[-]</label><label class="expand" for="c-42089989">[6 more]</label></div><br/><div class="children"><div class="content">What an unfortunate choice of name. LoRa is already a big project.</div><br/><div id="42090172" class="c"><input type="checkbox" id="c-42090172" checked=""/><div class="controls bullet"><span class="by">zwaps</span><span>|</span><a href="#42089989">parent</a><span>|</span><a href="#42090549">next</a><span>|</span><label class="collapse" for="c-42090172">[-]</label><label class="expand" for="c-42090172">[2 more]</label></div><br/><div class="children"><div class="content">Different field entirely</div><br/><div id="42090356" class="c"><input type="checkbox" id="c-42090356" checked=""/><div class="controls bullet"><span class="by">greenavocado</span><span>|</span><a href="#42089989">root</a><span>|</span><a href="#42090172">parent</a><span>|</span><a href="#42090549">next</a><span>|</span><label class="collapse" for="c-42090356">[-]</label><label class="expand" for="c-42090356">[1 more]</label></div><br/><div class="children"><div class="content">Just watch: Pretty soon there will be an LLM optimization called Windows</div><br/></div></div></div></div><div id="42090549" class="c"><input type="checkbox" id="c-42090549" checked=""/><div class="controls bullet"><span class="by">DidYaWipe</span><span>|</span><a href="#42089989">parent</a><span>|</span><a href="#42090172">prev</a><span>|</span><a href="#42090078">next</a><span>|</span><label class="collapse" for="c-42090549">[-]</label><label class="expand" for="c-42090549">[2 more]</label></div><br/><div class="children"><div class="content">Yep. People don&#x27;t bother to even check anymore.<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=YQ7aLHCTeeE" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=YQ7aLHCTeeE</a><p>And Amazon named its voice assistant after a well-known camera. And... and...</div><br/><div id="42093349" class="c"><input type="checkbox" id="c-42093349" checked=""/><div class="controls bullet"><span class="by">DidYaWipe</span><span>|</span><a href="#42089989">root</a><span>|</span><a href="#42090549">parent</a><span>|</span><a href="#42090078">next</a><span>|</span><label class="collapse" for="c-42093349">[-]</label><label class="expand" for="c-42093349">[1 more]</label></div><br/><div class="children"><div class="content">Gotta love how some incel downvoted this fact.</div><br/></div></div></div></div><div id="42090078" class="c"><input type="checkbox" id="c-42090078" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#42089989">parent</a><span>|</span><a href="#42090549">prev</a><span>|</span><a href="#42088937">next</a><span>|</span><label class="collapse" for="c-42090078">[-]</label><label class="expand" for="c-42090078">[1 more]</label></div><br/><div class="children"><div class="content">Welcome to ML&#x2F;AI project naming.</div><br/></div></div></div></div><div id="42088937" class="c"><input type="checkbox" id="c-42088937" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#42089989">prev</a><span>|</span><a href="#42087231">next</a><span>|</span><label class="collapse" for="c-42088937">[-]</label><label class="expand" for="c-42088937">[2 more]</label></div><br/><div class="children"><div class="content">This paper seems dubious, because it flies in the face of what the reft&#x2F;pyreft paper is showing (you can use 0.0001% of the parameters trained for 100 epochs to personalize on a small dataset):<p><a href="https:&#x2F;&#x2F;github.com&#x2F;stanfordnlp&#x2F;pyreft">https:&#x2F;&#x2F;github.com&#x2F;stanfordnlp&#x2F;pyreft</a><p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2404.03592" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2404.03592</a><p>Note that the OP paper is not peer reviewed yet, and while the one I linked isn&#x27;t either, it has Christopher Manning (yes, the one you know from youtube), the head of AI at Stanford, as a co-author.<p>In general, I think that Lora and especially reft should be more resistant to catastrophic forgetting due to them literally not impacting most of the model.<p>The Stable Diffusion community has literally tens of thousands of lora&#x27;s that don&#x27;t cripple a model at small rank.</div><br/><div id="42090886" class="c"><input type="checkbox" id="c-42090886" checked=""/><div class="controls bullet"><span class="by">chompychop</span><span>|</span><a href="#42088937">parent</a><span>|</span><a href="#42087231">next</a><span>|</span><label class="collapse" for="c-42090886">[-]</label><label class="expand" for="c-42090886">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t see how the authorship by Christopher Manning shifts favour towards the other paper; this paper has Antonio Torralba as a co-author, who&#x27;s also one of the big shots in AI.</div><br/></div></div></div></div><div id="42087231" class="c"><input type="checkbox" id="c-42087231" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#42088937">prev</a><span>|</span><a href="#42091375">next</a><span>|</span><label class="collapse" for="c-42087231">[-]</label><label class="expand" for="c-42087231">[1 more]</label></div><br/><div class="children"><div class="content">Is this just specifying what has been known, that LoRAs skew towards the new training heavily and are not &#x27;more intelligent&#x27; just &#x27;more targeted&#x27; and become less intelligent the more they are targeted? Or is this proposing something else? I am having a difficult time understanding exactly what &#x27;intruder dimensions&#x27; are.</div><br/></div></div><div id="42091375" class="c"><input type="checkbox" id="c-42091375" checked=""/><div class="controls bullet"><span class="by">blacklion</span><span>|</span><a href="#42087231">prev</a><span>|</span><a href="#42090644">next</a><span>|</span><label class="collapse" for="c-42091375">[-]</label><label class="expand" for="c-42091375">[1 more]</label></div><br/><div class="children"><div class="content">Each time I see &quot;LoRA&quot; in title I want to click it. Until I understand, that it is about DNN and not LoRa long distance radio modulation.</div><br/></div></div><div id="42090644" class="c"><input type="checkbox" id="c-42090644" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#42091375">prev</a><span>|</span><a href="#42090619">next</a><span>|</span><label class="collapse" for="c-42090644">[-]</label><label class="expand" for="c-42090644">[3 more]</label></div><br/><div class="children"><div class="content">TLDR:
1. Use alpha = 2*rank<p>2. Don&#x27;t use too small ranks (rank=1 to 8)<p>3. Sensational title. Better title &quot;LoRA works if done right&quot;<p>4. Didn&#x27;t test SVD init</div><br/><div id="42091725" class="c"><input type="checkbox" id="c-42091725" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#42090644">parent</a><span>|</span><a href="#42090619">next</a><span>|</span><label class="collapse" for="c-42091725">[-]</label><label class="expand" for="c-42091725">[2 more]</label></div><br/><div class="children"><div class="content">Thanks for the TLDR. Yeah, pretty much fits my experience, though I mainly cared about the specific task performance I was training rather than caring about regressing unrelated tasks.</div><br/><div id="42092051" class="c"><input type="checkbox" id="c-42092051" checked=""/><div class="controls bullet"><span class="by">danielhanchen</span><span>|</span><a href="#42090644">root</a><span>|</span><a href="#42091725">parent</a><span>|</span><a href="#42090619">next</a><span>|</span><label class="collapse" for="c-42092051">[-]</label><label class="expand" for="c-42092051">[1 more]</label></div><br/><div class="children"><div class="content">:) Oh ye from the paper it looks like if one uses alpha = 2*rank, sometimes LoRA does even better than full finetuning</div><br/></div></div></div></div></div></div><div id="42092157" class="c"><input type="checkbox" id="c-42092157" checked=""/><div class="controls bullet"><span class="by">idorosen</span><span>|</span><a href="#42086785">prev</a><span>|</span><label class="collapse" for="c-42092157">[-]</label><label class="expand" for="c-42092157">[1 more]</label></div><br/><div class="children"><div class="content">Jacob Andreas is one of the smartest people I’ve ever met.</div><br/></div></div></div></div></div></div></div></body></html>