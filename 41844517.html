<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1728982876463" as="style"/><link rel="stylesheet" href="styles.css?v=1728982876463"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/adaline/gateway">Local TypeScript Super SDK to Call 200 LLMs</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>ArshDilbagi</span> | <span>18 comments</span></div><br/><div><div id="41845795" class="c"><input type="checkbox" id="c-41845795" checked=""/><div class="controls bullet"><span class="by">Sn0wCoder</span><span>|</span><a href="#41845723">next</a><span>|</span><label class="collapse" for="c-41845795">[-]</label><label class="expand" for="c-41845795">[1 more]</label></div><br/><div class="children"><div class="content">Very neat, bookmarked.   Read through the readme.md and would be nice to show an example of using with Ollama or LM Studio running locally.  Would guess you just setup an OpenAI model, set the baseUrl to the local instance &#x2F; API and go from there?  For something that is Fully Local connecting to a provider with an API key is iffy at best, unless you are paying for enterprise keys.  I guess the first line says used by ‘Enterprises’ but to be fully local that would include running the LLM locally also?</div><br/></div></div><div id="41845723" class="c"><input type="checkbox" id="c-41845723" checked=""/><div class="controls bullet"><span class="by">nip</span><span>|</span><a href="#41845795">prev</a><span>|</span><a href="#41845406">next</a><span>|</span><label class="collapse" for="c-41845723">[-]</label><label class="expand" for="c-41845723">[1 more]</label></div><br/><div class="children"><div class="content">Incredible work!<p>I&#x27;ve been meaning to add &quot;intelligence&quot; to my Telegram monitoring bot: it couldn&#x27;t come at a better time!<p>Thank you for building it!</div><br/></div></div><div id="41845406" class="c"><input type="checkbox" id="c-41845406" checked=""/><div class="controls bullet"><span class="by">maeil</span><span>|</span><a href="#41845723">prev</a><span>|</span><a href="#41845424">next</a><span>|</span><label class="collapse" for="c-41845406">[-]</label><label class="expand" for="c-41845406">[1 more]</label></div><br/><div class="children"><div class="content">A more fleshed out competitor to llm-interface [1]? Looks great!<p>Does it run in FaaS&#x2F;serverless environments out of the box? Lambdas, Cloudflare Workers, Vercel functions and the likes? Deno? The README says &quot;Isomorphic - works everywhere&quot;, but might be nice to make this more explicit.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;samestrin&#x2F;llm-interface">https:&#x2F;&#x2F;github.com&#x2F;samestrin&#x2F;llm-interface</a></div><br/></div></div><div id="41845424" class="c"><input type="checkbox" id="c-41845424" checked=""/><div class="controls bullet"><span class="by">vbo</span><span>|</span><a href="#41845406">prev</a><span>|</span><a href="#41846000">next</a><span>|</span><label class="collapse" for="c-41845424">[-]</label><label class="expand" for="c-41845424">[1 more]</label></div><br/><div class="children"><div class="content">Looks good, might give it a try. I was looking for something similar to provide a unified interface for gpt and claude and eventually hacked something together myself, as none of the solutions I found could deal with structured output properly across both vendors.</div><br/></div></div><div id="41846000" class="c"><input type="checkbox" id="c-41846000" checked=""/><div class="controls bullet"><span class="by">hirako2000</span><span>|</span><a href="#41845424">prev</a><span>|</span><a href="#41845071">next</a><span>|</span><label class="collapse" for="c-41846000">[-]</label><label class="expand" for="c-41846000">[2 more]</label></div><br/><div class="children"><div class="content">What do you mean by &quot;no proxy&quot;?</div><br/><div id="41846519" class="c"><input type="checkbox" id="c-41846519" checked=""/><div class="controls bullet"><span class="by">madarco</span><span>|</span><a href="#41846000">parent</a><span>|</span><a href="#41845071">next</a><span>|</span><label class="collapse" for="c-41846519">[-]</label><label class="expand" for="c-41846519">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s because the library calls directly the LLM AND saves any debug&#x2F;trace info. While other tools let you use the standard (eg OpenAI) sdk and uses an https proxy to intercept the requests</div><br/></div></div></div></div><div id="41845071" class="c"><input type="checkbox" id="c-41845071" checked=""/><div class="controls bullet"><span class="by">kazcaptain</span><span>|</span><a href="#41846000">prev</a><span>|</span><a href="#41845336">next</a><span>|</span><label class="collapse" for="c-41845071">[-]</label><label class="expand" for="c-41845071">[2 more]</label></div><br/><div class="children"><div class="content">Great lib, will give it a go in my work</div><br/><div id="41845376" class="c"><input type="checkbox" id="c-41845376" checked=""/><div class="controls bullet"><span class="by">ArshDilbagi</span><span>|</span><a href="#41845071">parent</a><span>|</span><a href="#41845336">next</a><span>|</span><label class="collapse" for="c-41845376">[-]</label><label class="expand" for="c-41845376">[1 more]</label></div><br/><div class="children"><div class="content">thank you</div><br/></div></div></div></div><div id="41845336" class="c"><input type="checkbox" id="c-41845336" checked=""/><div class="controls bullet"><span class="by">alex_suzuki</span><span>|</span><a href="#41845071">prev</a><span>|</span><a href="#41845161">next</a><span>|</span><label class="collapse" for="c-41845336">[-]</label><label class="expand" for="c-41845336">[3 more]</label></div><br/><div class="children"><div class="content">what‘s a „Super SDK“? A meta sdk, i.e. an SDK wrapping other SDKs&#x2F;APIs?</div><br/><div id="41845375" class="c"><input type="checkbox" id="c-41845375" checked=""/><div class="controls bullet"><span class="by">ArshDilbagi</span><span>|</span><a href="#41845336">parent</a><span>|</span><a href="#41845161">next</a><span>|</span><label class="collapse" for="c-41845375">[-]</label><label class="expand" for="c-41845375">[2 more]</label></div><br/><div class="children"><div class="content">We have implemented “super-types” that are strongly typed in TypeScript and compatible with all providers (think a superset in mathematics). Hence the name, Super SDK. Gateway is super light weight. We don’t wrap around other SDKs. We describe the APIs in the provider packages (@adaline&#x2F;openai) that plugs into @adaline&#x2F;gateway that has all the features.</div><br/><div id="41845500" class="c"><input type="checkbox" id="c-41845500" checked=""/><div class="controls bullet"><span class="by">alex_suzuki</span><span>|</span><a href="#41845336">root</a><span>|</span><a href="#41845375">parent</a><span>|</span><a href="#41845161">next</a><span>|</span><label class="collapse" for="c-41845500">[-]</label><label class="expand" for="c-41845500">[1 more]</label></div><br/><div class="children"><div class="content">Got it, thanks!</div><br/></div></div></div></div></div></div><div id="41845161" class="c"><input type="checkbox" id="c-41845161" checked=""/><div class="controls bullet"><span class="by">npace12</span><span>|</span><a href="#41845336">prev</a><span>|</span><a href="#41845160">next</a><span>|</span><label class="collapse" for="c-41845161">[-]</label><label class="expand" for="c-41845161">[2 more]</label></div><br/><div class="children"><div class="content">that&#x27;s a lot of work and it looks nicely done, thanks!</div><br/><div id="41845377" class="c"><input type="checkbox" id="c-41845377" checked=""/><div class="controls bullet"><span class="by">ArshDilbagi</span><span>|</span><a href="#41845161">parent</a><span>|</span><a href="#41845160">next</a><span>|</span><label class="collapse" for="c-41845377">[-]</label><label class="expand" for="c-41845377">[1 more]</label></div><br/><div class="children"><div class="content">thank you</div><br/></div></div></div></div><div id="41845160" class="c"><input type="checkbox" id="c-41845160" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#41845161">prev</a><span>|</span><a href="#41844518">next</a><span>|</span><label class="collapse" for="c-41845160">[-]</label><label class="expand" for="c-41845160">[3 more]</label></div><br/><div class="children"><div class="content">Can tools return images to the LLM using this SDK? (where supported by the provider)</div><br/><div id="41845380" class="c"><input type="checkbox" id="c-41845380" checked=""/><div class="controls bullet"><span class="by">ArshDilbagi</span><span>|</span><a href="#41845160">parent</a><span>|</span><a href="#41844518">next</a><span>|</span><label class="collapse" for="c-41845380">[-]</label><label class="expand" for="c-41845380">[2 more]</label></div><br/><div class="children"><div class="content">Yes, we support images, tools, response format (for OpenAI) and everything else.</div><br/><div id="41845591" class="c"><input type="checkbox" id="c-41845591" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#41845160">root</a><span>|</span><a href="#41845380">parent</a><span>|</span><a href="#41844518">next</a><span>|</span><label class="collapse" for="c-41845591">[-]</label><label class="expand" for="c-41845591">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m asking specifically about images being returned by a tool call. I didn&#x27;t see any indication that it&#x27;s supported skimming through the Zod types</div><br/></div></div></div></div></div></div><div id="41844518" class="c"><input type="checkbox" id="c-41844518" checked=""/><div class="controls bullet"><span class="by">ArshDilbagi</span><span>|</span><a href="#41845160">prev</a><span>|</span><label class="collapse" for="c-41844518">[-]</label><label class="expand" for="c-41844518">[1 more]</label></div><br/><div class="children"><div class="content">The fully local production-grade Super SDK that provides a simple, unified, and powerful interface for calling more than 200+ LLMs.<p>- Production-ready and used by enterprises.
- Fully local and NOT a proxy. You can deploy it anywhere.
- Comes with batching, retries, caching, callbacks, and OpenTelemetry support.
- Supports custom plugins for caching, logging, HTTP client, and more. You can use it like LEGOs and make it work with your infrastructure.
- Supports plug-and-play providers. You can run fully custom providers and still leverage all the benefits of Adaline Gateway.<p>Features
 Strongly typed in TypeScript
 Isomorphic - works everywhere
 100% local and private and NOT a proxy
 Tool calling support across all compatible LLMs
 Batching for all requests with custom queue support
 Automatic retries with exponential backoff
 Caching with custom cache plug-in support
 Callbacks for full custom instrumentation and hooks
 OpenTelemetry to plug tracing into your existing infrastructure
 Plug-and-play custom providers for local and custom models</div><br/></div></div></div></div></div></div></div></body></html>