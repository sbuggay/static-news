<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1735808452641" as="style"/><link rel="stylesheet" href="styles.css?v=1735808452641"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://mathstodon.xyz/@tao/113721192051328193">One of my papers got declined today</a> <span class="domain">(<a href="https://mathstodon.xyz">mathstodon.xyz</a>)</span></div><div class="subtext"><span>GavCo</span> | <span>202 comments</span></div><br/><div><div id="42568746" class="c"><input type="checkbox" id="c-42568746" checked=""/><div class="controls bullet"><span class="by">dwaltrip</span><span>|</span><a href="#42569873">next</a><span>|</span><label class="collapse" for="c-42568746">[-]</label><label class="expand" for="c-42568746">[121 more]</label></div><br/><div class="children"><div class="content">Hilarious irony:<p>&gt; With hindsight, some of my past rejections have become amusing.  With a coauthor, I once almost solved a conjecture, establishing the result with an &quot;epsilon loss&quot; in a key parameter.  We submitted to a highly reputable journal, but it was rejected on the grounds that it did not resolve the full conjecture.  So we submitted elsewhere, and the paper was accepted.<p>&gt; The following year, we managed to finally prove the full conjecture without the epsilon loss, and decided to try submitting to the highly reputable journal again.  This time, the paper was rejected for only being an epsilon improvement over the previous literature!</div><br/><div id="42569608" class="c"><input type="checkbox" id="c-42569608" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568746">parent</a><span>|</span><a href="#42568835">next</a><span>|</span><label class="collapse" for="c-42569608">[-]</label><label class="expand" for="c-42569608">[64 more]</label></div><br/><div class="children"><div class="content">A lot of the replies make it seem like there is some great over-arching coordination and intent between subsequent submissions, but I’ll offer up an alternative explanation: sometimes the reviewer selection is an utter crap shoot. Just because the first set of reviewers may offer a justification for rejection, it may be completely unrelated to the rationale of a different set of reviewers. Reviewers are human and bring all kinds of biases and perspectives into the process.<p>It’s frustrating but the result of a somewhat haphazard process. It’s also not uncommon for conflicting comments within the same review cycle. Some of this may be attributed to a lack of clear communication by the author. But on occasion, it leads me to believe many journals don’t take a lot of time selecting appropriate reviewers and settle for the first few that agree to review.</div><br/><div id="42571379" class="c"><input type="checkbox" id="c-42571379" checked=""/><div class="controls bullet"><span class="by">keepamovin</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569608">parent</a><span>|</span><a href="#42571128">next</a><span>|</span><label class="collapse" for="c-42571379">[-]</label><label class="expand" for="c-42571379">[17 more]</label></div><br/><div class="children"><div class="content">And this is how we do science? How is that a good basis for  scientific reality? Seems there should at least be transparency and oversight, or maybe the whole system is broke: open reviews on web not limited to a small committee sounds better.<p>Science is about the unknown, building testable models and getting data.<p>Even an AI review system could help.</div><br/><div id="42571564" class="c"><input type="checkbox" id="c-42571564" checked=""/><div class="controls bullet"><span class="by">n144q</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571379">parent</a><span>|</span><a href="#42571128">next</a><span>|</span><label class="collapse" for="c-42571564">[-]</label><label class="expand" for="c-42571564">[16 more]</label></div><br/><div class="children"><div class="content">It is not a good way of doing science, but it is the best we have.<p>All the alternatives, including the ones you proposed, have their own serious downsides, which is why we kept the status quo for the past few decades.</div><br/><div id="42572081" class="c"><input type="checkbox" id="c-42572081" checked=""/><div class="controls bullet"><span class="by">eeeeeeehio</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571564">parent</a><span>|</span><a href="#42572032">next</a><span>|</span><label class="collapse" for="c-42572081">[-]</label><label class="expand" for="c-42572081">[7 more]</label></div><br/><div class="children"><div class="content">Peer review is not designed for science. Many papers are not rejected because of an issue with the <i>science</i> -- in fact, reviewers seldom have the time to actually check the science! As a CS-centric example: you&#x27;ll almost never find a reviewer who reads a single line of code (if code is submitted with the paper at all). There is artifact review, but this is never tied to the acceptance of the paper. Reviewers focus on ideas, presentation, and the <i>presented</i> results. (And the current system is a good filter for this! Most accepted papers are well-written and the results always look good on paper.) However, reviewers never take the time to actually verify that the experiment code matches the ideas described in the paper, and that the results reproduce. Ask any CS&#x2F;engineering PhD student how many papers (in top venues) they&#x27;ve seen with a critical implementation flaw that invalidates the results -- and you might begin to understand the problem.<p>At least in CS, the system <i>can</i> be fixed, but those in power are unable and unwilling to fix it. Authors don&#x27;t want to be held accountable (&quot;if we submit the code with the paper -- someone might find a critical bug and reject the paper!&quot;), and reviewers are both unqualified (i.e. haven&#x27;t written a line of code in 25 years) and unwilling to take on more responsibility (&quot;I don&#x27;t have the time to make sure their experiment code is fair!&quot;). So we are left with an obviously broken system where junior PhD students review artifacts for &quot;reproducibility&quot; and this evaluation has no bearing whatsoever on whether a paper gets accepted. It&#x27;s too easy to cook up positive results in almost any field (intentionally, or unintentionally), and we have a system with little accountability.<p>It&#x27;s not &quot;the best we have&quot;, it&#x27;s &quot;the best those in power will allow&quot;. Those in power do not want consequences for publishing bad research, and also don&#x27;t want the reviewing load required to keep bad research out.</div><br/><div id="42572648" class="c"><input type="checkbox" id="c-42572648" checked=""/><div class="controls bullet"><span class="by">Ar-Curunir</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42572081">parent</a><span>|</span><a href="#42572470">next</a><span>|</span><label class="collapse" for="c-42572648">[-]</label><label class="expand" for="c-42572648">[3 more]</label></div><br/><div class="children"><div class="content">This is much too negative. Peer review indeed misses issues with papers, but by-and-large catches the most glaring faults.<p>I don’t believe for one moment that the vast majority of papers in reputable conferences are wrong, if only for the simple reason that putting out incorrect research gives an easy layup for competing groups to write a follow-up paper that exposes the flaw.<p>It’s also a fallacy to state that papers aren’t reproducible without code. Yes code is important, but in most cases the core contribution of the research paper is not the code, but some set of ideas that together describe a novel way to approach the tackled problem.</div><br/><div id="42572826" class="c"><input type="checkbox" id="c-42572826" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42572648">parent</a><span>|</span><a href="#42572765">next</a><span>|</span><label class="collapse" for="c-42572826">[-]</label><label class="expand" for="c-42572826">[1 more]</label></div><br/><div class="children"><div class="content">They aren’t necessarily wrong but most are nearly completely useless due to some heavily downplayed or completely omitted flaw that surfaces when you try to implement the idea in actual systems.<p>There is technically academic novelty so it’s not “wrong”. It’s just not valuable for the field or science in general.</div><br/></div></div><div id="42572765" class="c"><input type="checkbox" id="c-42572765" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42572648">parent</a><span>|</span><a href="#42572826">prev</a><span>|</span><a href="#42572470">next</a><span>|</span><label class="collapse" for="c-42572765">[-]</label><label class="expand" for="c-42572765">[1 more]</label></div><br/><div class="children"><div class="content">I spent 3 months implementing a paper once. Finally, I got to the point where I understood the paper probably better than the author. It was an extremely complicated paper (homomorphic encryption). At this point, I realized that it doesn&#x27;t work. There was nothing about it that would ever work, and it wasn&#x27;t for lack of understanding. I emailed the author asking to clarify some specific things in the paper, they never responded.<p>In theory, the paper could work, but it would be incredibly weak (the key turned out to be either 1 or 0 -- a single bit).</div><br/></div></div></div></div><div id="42572470" class="c"><input type="checkbox" id="c-42572470" checked=""/><div class="controls bullet"><span class="by">DiogenesKynikos</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42572081">parent</a><span>|</span><a href="#42572648">prev</a><span>|</span><a href="#42572032">next</a><span>|</span><label class="collapse" for="c-42572470">[-]</label><label class="expand" for="c-42572470">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s not &quot;the best we have&quot;, it&#x27;s &quot;the best those in power will allow&quot;. Those in power do not want consequences for publishing bad research, and also don&#x27;t want the reviewing load required to keep bad research out.<p>This is a very conspiratorial view of things. The simple and true answer is your last suggestion: doing a more thorough review takes more time than anyone has available.<p>Reviewers work for free. Applying the level of scrutiny you&#x27;re requesting would require far more work than reviewers currently do, and maybe even something approaching the amount of work required to write the paper in the first place. The more work it takes to review an article, the less willing reviewers are to volunteer their time, and the harder it is for editors to find reviewers. The current level of scrutiny that papers get at the peer-review stage is a result of how much time reviewers can realistically volunteer.<p>Peer review is a very low standard. It&#x27;s only an initial filter to remove the garbage and to bring papers up to some basic quality standard. The real test of a paper is whether it is cited and built upon by other scientists after publication. Many papers are published and then forgotten, or found to be flawed and not used any more.</div><br/><div id="42572718" class="c"><input type="checkbox" id="c-42572718" checked=""/><div class="controls bullet"><span class="by">ksenzee</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42572470">parent</a><span>|</span><a href="#42572032">next</a><span>|</span><label class="collapse" for="c-42572718">[-]</label><label class="expand" for="c-42572718">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Reviewers work for free.<p>If journals were operating on a shoestring budget, I might be able to understand why academics are expected to do peer review for free. As it is, it makes no sense whatsoever. Elsevier pulls down huge amounts of money and still manages to command free labor.</div><br/><div id="42572784" class="c"><input type="checkbox" id="c-42572784" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42572718">parent</a><span>|</span><a href="#42572032">next</a><span>|</span><label class="collapse" for="c-42572784">[-]</label><label class="expand" for="c-42572784">[1 more]</label></div><br/><div class="children"><div class="content">I think it has to be this way, right? Otherwise a paid reviewer will have obvious biases from the company.</div><br/></div></div></div></div></div></div></div></div><div id="42572032" class="c"><input type="checkbox" id="c-42572032" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571564">parent</a><span>|</span><a href="#42572081">prev</a><span>|</span><a href="#42571740">next</a><span>|</span><label class="collapse" for="c-42572032">[-]</label><label class="expand" for="c-42572032">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It is not a good way of doing science, but it is the best we have.<p>What makes you think so?  We already have and had plenty of other ways.  Eg you can see how science is done in corporations or for the military or for fun (see those old gentlemen scientists, or amateurs these days), and you can also just publish things on your own these days.<p>The only real function of these old fashioned journals is as gatekeepers for funding and career decisions.</div><br/></div></div><div id="42571740" class="c"><input type="checkbox" id="c-42571740" checked=""/><div class="controls bullet"><span class="by">Panoramix</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571564">parent</a><span>|</span><a href="#42572032">prev</a><span>|</span><a href="#42571639">next</a><span>|</span><label class="collapse" for="c-42571740">[-]</label><label class="expand" for="c-42571740">[1 more]</label></div><br/><div class="children"><div class="content">We kept that mostly due to inertia and because it&#x27;s the most profitable for the journals (everybody does their work for free and they don&#x27;t have to invest in new systems), not because it&#x27;s the best for science and scientists.</div><br/></div></div><div id="42571639" class="c"><input type="checkbox" id="c-42571639" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571564">parent</a><span>|</span><a href="#42571740">prev</a><span>|</span><a href="#42571128">next</a><span>|</span><label class="collapse" for="c-42571639">[-]</label><label class="expand" for="c-42571639">[6 more]</label></div><br/><div class="children"><div class="content">What is the serious downside of open internet centric review?</div><br/><div id="42572685" class="c"><input type="checkbox" id="c-42572685" checked=""/><div class="controls bullet"><span class="by">daemontus</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571639">parent</a><span>|</span><a href="#42571660">next</a><span>|</span><label class="collapse" for="c-42572685">[-]</label><label class="expand" for="c-42572685">[1 more]</label></div><br/><div class="children"><div class="content">As others have mentioned, the main problem is that open systems are more vulnerable to low-cost, coordinated external attacks.<p>This is less of an issue with systems where there is little monetary value attached (I don&#x27;t know anyone whose mortgage is paid for by their Stack Overflow reputation). Now imagine that the future prospects of a national lab with multi-million yearly budget are tied to a system that can be (relatively easily) gamed with a Chinese or Russian bot farm for a few thousand dollars.<p>There are already players that are trying hard to game the current system, and it sometimes sort of works, but not quite, exactly because of how hard it is to get into the &quot;high reputation&quot; club (on the other hand, once you&#x27;re in, you can often publish a lot of lower quality stuff just because of your reputation, so I&#x27;m not saying this is a perfect system either).<p>In other words, I don&#x27;t think anyone reasonable is seriously against making peer review more transparent, but for better or worse, the current system (with all of its other downsides) is relatively robust to outside interference.<p>So, unless we (a) make &quot;being a scientist&quot; much more financially accessible, or (b), untangle funding from this new &quot;open&quot; measure of &quot;scientific achievement&quot;, the open system would probably not be very impactful. Of course, (a) is unlikely, at least in most high-impact fields; CS was an outlier for a long time, not so much today. And (b) would mean that funding agencies would still need something else to judge your research, which would most likely still be some closed, reputation-based system.<p>Edit TL;DR: Describe how the open science peer-review system should be used to distribute funding among researchers while begin reasonably robust to coordinated attacks. Then we can talk :)</div><br/></div></div><div id="42571660" class="c"><input type="checkbox" id="c-42571660" checked=""/><div class="controls bullet"><span class="by">reilly3000</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571639">parent</a><span>|</span><a href="#42572685">prev</a><span>|</span><a href="#42571128">next</a><span>|</span><label class="collapse" for="c-42571660">[-]</label><label class="expand" for="c-42571660">[4 more]</label></div><br/><div class="children"><div class="content">The open internet.<p>i.e. trolls, brigades, spammers, bots, and all manner of uninformed voices.</div><br/><div id="42571767" class="c"><input type="checkbox" id="c-42571767" checked=""/><div class="controls bullet"><span class="by">bruce511</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571660">parent</a><span>|</span><a href="#42571128">next</a><span>|</span><label class="collapse" for="c-42571767">[-]</label><label class="expand" for="c-42571767">[3 more]</label></div><br/><div class="children"><div class="content">To expand on this - because if the barrier to publishing is zero, then the &quot;reputation&quot; of the publisher is also zero.<p>(Actually, we already have the &quot;open publishing&quot; you are suggesting - it&#x27;s called Blogging or social media.)<p>In other words, if we have open publishing, then someone like me (with zero understanding of a topic) can publish a very authentic-looking pile of nonsense with exactly the same weight as someone who, you know, has actually done some science and knows what they&#x27;re talking about.<p>The common &quot;solution&quot; to this is voting - like with StackOverflow answers. But that is clearly trivial to game and would quickly become meaningless.<p>So human review it is - combined with the reputation that a journal brings. The author gains reputation because some reviewers (with reputation) reviewed the paper, and the journal (with reputation) accepted it.<p>Yes, this system is cumbersome, prone to failure, and subject to outside influences. It&#x27;s not perfect. Just the best we have right now.</div><br/><div id="42572042" class="c"><input type="checkbox" id="c-42572042" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571767">parent</a><span>|</span><a href="#42572598">next</a><span>|</span><label class="collapse" for="c-42572042">[-]</label><label class="expand" for="c-42572042">[1 more]</label></div><br/><div class="children"><div class="content">&gt; To expand on this - because if the barrier to publishing is zero, then the &quot;reputation&quot; of the publisher is also zero.<p>That&#x27;s fine.  I don&#x27;t read eg Astral Codex Ten because I think the reputation of Substack is great.  The blog can stand entirely on its own reputation (and the reputation of its author), no need for the publisher to rent out their reputation.<p>See also Gwern.net for a similar example.<p>No need for any voting.</div><br/></div></div><div id="42572598" class="c"><input type="checkbox" id="c-42572598" checked=""/><div class="controls bullet"><span class="by">ricksunny</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571767">parent</a><span>|</span><a href="#42572042">prev</a><span>|</span><a href="#42571128">next</a><span>|</span><label class="collapse" for="c-42572598">[-]</label><label class="expand" for="c-42572598">[1 more]</label></div><br/><div class="children"><div class="content">Reviewers could themselves have reputation levels that weight how visible their review is. This would make brigading more costly. There might still be a pseudoscientific brigade trying to take down (or boost) a particular paper, one that clusters so much that it builds its own competing reputatation, but that&#x27;s okay. The casual reader can decide which high-vote reviews to follow on their own merits.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42571128" class="c"><input type="checkbox" id="c-42571128" checked=""/><div class="controls bullet"><span class="by">dhosek</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569608">parent</a><span>|</span><a href="#42571379">prev</a><span>|</span><a href="#42569975">next</a><span>|</span><label class="collapse" for="c-42571128">[-]</label><label class="expand" for="c-42571128">[1 more]</label></div><br/><div class="children"><div class="content">Luck plays a lot of a role in many vaguely similar things. I regularly submit fiction and poetry for publication (with acceptance rates of 2% for fiction and 1.5% for poetry) and so much depends on things well out of my control (which is part of why I’m sanguine about those acceptance rates—given the venues I‘m submitting to, they’re not unreasonable numbers and more recent years’ stats are better than that).¹ In many cases the editors like what they read, but don’t have a place for it in the current issue or sometimes they’re just having a bad day.<p>⸻<p>1. For those who care about the full messy details I have charts and graphs at <a href="https:&#x2F;&#x2F;www.dahosek.com&#x2F;2024-in-reejctions-and-acceptances&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.dahosek.com&#x2F;2024-in-reejctions-and-acceptances&#x2F;</a></div><br/></div></div><div id="42569975" class="c"><input type="checkbox" id="c-42569975" checked=""/><div class="controls bullet"><span class="by">hanche</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569608">parent</a><span>|</span><a href="#42571128">prev</a><span>|</span><a href="#42571641">next</a><span>|</span><label class="collapse" for="c-42569975">[-]</label><label class="expand" for="c-42569975">[22 more]</label></div><br/><div class="children"><div class="content">&gt; sometimes the reviewer selection is an utter crap shoot<p>Indeed, but when someone of Tao&#x27;s caliber submits a paper, any editor would (should) make an extra effort to get the very best researchers to referee the paper.</div><br/><div id="42570156" class="c"><input type="checkbox" id="c-42570156" checked=""/><div class="controls bullet"><span class="by">crote</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569975">parent</a><span>|</span><a href="#42570056">next</a><span>|</span><label class="collapse" for="c-42570156">[-]</label><label class="expand" for="c-42570156">[18 more]</label></div><br/><div class="children"><div class="content">But isn&#x27;t that <i>exactly</i> why the submission should be anonymous to the reviewer? It&#x27;s science, the paper should speak for itself. You don&#x27;t want a reviewer to be biased by the previous accomplishments of the author. An absolute nobody can make groundbreaking and unexpected discoveries, and a Nobel prize winner can make stupid mistakes.</div><br/><div id="42570716" class="c"><input type="checkbox" id="c-42570716" checked=""/><div class="controls bullet"><span class="by">aj7</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570156">parent</a><span>|</span><a href="#42570168">next</a><span>|</span><label class="collapse" for="c-42570716">[-]</label><label class="expand" for="c-42570716">[3 more]</label></div><br/><div class="children"><div class="content">In subfields of physics, and I suspect math, the submitter is never anonymous. These people talk at conferences, have a list of previous works, etc., and fields are highly specialized. So the reviewer knows with 50-95% certainty who he is reviewing.</div><br/><div id="42570969" class="c"><input type="checkbox" id="c-42570969" checked=""/><div class="controls bullet"><span class="by">gus_massa</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570716">parent</a><span>|</span><a href="#42571530">next</a><span>|</span><label class="collapse" for="c-42570969">[-]</label><label class="expand" for="c-42570969">[1 more]</label></div><br/><div class="children"><div class="content">I agree, also many papers near the begining say<p>&gt; <i>We are exending our previous work in [7]</i><p>or cite a few relevant papers<p>&gt; <i>This topic has been studied in [3-8]</i><p>Where 3 was published by group X, 5 by group Y, 7 by group Z and 4, 6 and 8 by group W. Anyone can guess the author of the paper is in group W.<p>Just looking at the citations, it&#x27;s easy to guess the group of the author.</div><br/></div></div><div id="42571530" class="c"><input type="checkbox" id="c-42571530" checked=""/><div class="controls bullet"><span class="by">hexane360</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570716">parent</a><span>|</span><a href="#42570969">prev</a><span>|</span><a href="#42570168">next</a><span>|</span><label class="collapse" for="c-42571530">[-]</label><label class="expand" for="c-42571530">[1 more]</label></div><br/><div class="children"><div class="content">In many subfields, the submitter isn&#x27;t even attempted to be hidden from the reviewers. Usually, even the reviewers can be guessed with high accuracy by the submitters</div><br/></div></div></div></div><div id="42570168" class="c"><input type="checkbox" id="c-42570168" checked=""/><div class="controls bullet"><span class="by">hoten</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570156">parent</a><span>|</span><a href="#42570716">prev</a><span>|</span><a href="#42570307">next</a><span>|</span><label class="collapse" for="c-42570168">[-]</label><label class="expand" for="c-42570168">[8 more]</label></div><br/><div class="children"><div class="content">The reviewer wouldn&#x27;t need to know, just the one coordinating who should review what.</div><br/><div id="42570310" class="c"><input type="checkbox" id="c-42570310" checked=""/><div class="controls bullet"><span class="by">sokoloff</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570168">parent</a><span>|</span><a href="#42570658">next</a><span>|</span><label class="collapse" for="c-42570310">[-]</label><label class="expand" for="c-42570310">[4 more]</label></div><br/><div class="children"><div class="content">Inherent in the editor trying to &quot;get the very best researchers to [review] the paper&quot; is likely to be a leak of signal. (My spouse was a scientific journal editor for years; reviewers decline to review for any number of reasons, often just being too busy and the same reviewer is often asked multiple times per year. Taking the extra effort to say &quot;but <i>this specific paper</i> is from a really respected author&quot; would be bad, but so would &quot;but please make time to review <i>this specific paper</i> for reasons that I can&#x27;t tell you&quot;.)</div><br/><div id="42570576" class="c"><input type="checkbox" id="c-42570576" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570310">parent</a><span>|</span><a href="#42570658">next</a><span>|</span><label class="collapse" for="c-42570576">[-]</label><label class="expand" for="c-42570576">[3 more]</label></div><br/><div class="children"><div class="content">I didn’t read the comment to mean the editor would explicitly signal anything was noteworthy about the paper, but rather they would select referees from a specific pool of experts. From that standpoint, the referee would have no insight into whether it was anything special (and they couldn’t tell if the other referees were of distinction either).</div><br/><div id="42570787" class="c"><input type="checkbox" id="c-42570787" checked=""/><div class="controls bullet"><span class="by">sokoloff</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570576">parent</a><span>|</span><a href="#42570658">next</a><span>|</span><label class="collapse" for="c-42570787">[-]</label><label class="expand" for="c-42570787">[2 more]</label></div><br/><div class="children"><div class="content">The editor is <i>already</i> selecting the best matched reviewers though, for any paper they send out for review.<p>They have more flexibility on how hard they push the reviewer to accept doing the specific review, or for a specific timeline, but they still get declines from some reviewers on some papers.</div><br/><div id="42570803" class="c"><input type="checkbox" id="c-42570803" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570787">parent</a><span>|</span><a href="#42570658">next</a><span>|</span><label class="collapse" for="c-42570803">[-]</label><label class="expand" for="c-42570803">[1 more]</label></div><br/><div class="children"><div class="content">I know that’s the ideal but my original post ends with some skepticism at this claim. I’ve had more than a few come across my desk that are a poor fit. I try to be honest with the editors about why I reject the chance to review them. If I witness it more than a few times, they obviously aren’t being as judicial at their assignments as the ideal assumes.</div><br/></div></div></div></div></div></div></div></div><div id="42570658" class="c"><input type="checkbox" id="c-42570658" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570168">parent</a><span>|</span><a href="#42570310">prev</a><span>|</span><a href="#42570476">next</a><span>|</span><label class="collapse" for="c-42570658">[-]</label><label class="expand" for="c-42570658">[2 more]</label></div><br/><div class="children"><div class="content">Doesn’t that just move the source of bias from the reviewer to the coordinator? Some ‘nobody’ submitting a paper would get a crapshoot reviewer while a recognisable ‘somebody’ gets a well regarded fair reviewer.</div><br/></div></div><div id="42570476" class="c"><input type="checkbox" id="c-42570476" checked=""/><div class="controls bullet"><span class="by">wslh</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570168">parent</a><span>|</span><a href="#42570658">prev</a><span>|</span><a href="#42570307">next</a><span>|</span><label class="collapse" for="c-42570476">[-]</label><label class="expand" for="c-42570476">[1 more]</label></div><br/><div class="children"><div class="content">When submitting papers to high-profile journals, the expectations are very high for all authors. In most cases, the editorial team can determine from the abstract whether the paper is likely to meet their standards for acceptance.</div><br/></div></div></div></div><div id="42570307" class="c"><input type="checkbox" id="c-42570307" checked=""/><div class="controls bullet"><span class="by">derefr</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570156">parent</a><span>|</span><a href="#42570168">prev</a><span>|</span><a href="#42570173">next</a><span>|</span><label class="collapse" for="c-42570307">[-]</label><label class="expand" for="c-42570307">[5 more]</label></div><br/><div class="children"><div class="content">Full anonymity <i>may</i> be valuable, if the set of a paper&#x27;s reviewers has to stay fixed throughout the review process<p>If peer review worked more like other publication workflows (where documents are handed across multiple teams that review them for different reasons), I think partial anonymity (e.g. rounding authors down to a citation-count number) might actually be useful.<p>Basically: why can&#x27;t we treat peer review like the customer service gauntlet?<p>- Papers must pass all levels from the level they enter up to the final level, to be accepted for publication.<p>- Papers get triaged to the inbox of a given level based on the citation numbers of the submitter.<p>- Thus, papers from people with no known previous publications, go <i>first</i> to the level-1 reviewers, who exist purely to distinguish and filter off crankery&#x2F;quackery. They&#x27;re just there so that everyone else doesn&#x27;t have to waste time on this. (This level is what non-academic publishing houses call the &quot;slush pile.&quot;) <i>However</i>, they should be using criteria that give only false-positives [treating bad papers as good] but never false-negatives [treating good papers as bad.] The positives pass on to the level-2 (&quot;normal&quot;) stream.<p>- Likewise, papers from pre-eminent authors are assumed to not <i>often</i> contain stupid obvious mistakes, and therefore, to avoid wasting the submitter&#x27;s time <i>and</i> the time of reviewers in levels 1 through N-1, these papers get routed straight to final level-N reviewers. This group is mostly made up of pre-eminent authors themselves, who have the highest likelihood of catching the smallest, most esoteric fatal flaws. (However, they&#x27;re still also using criteria that requires them to be extremely critical of any <i>obvious</i> flaws as well. They just aren&#x27;t supposed to bother looking for them <i>first</i>, since the assumption is that they won&#x27;t be there.)<p>- Papers from people with an average number of citations end up landing on some middle level, getting reviewed for middling-picky stuff by middling-experienced people, and then either getting bounced back for iteration at that point, or getting repeatedly handed up the chain with those editing marks pre-picked so that the reviewers on higher levels don&#x27;t have to bother looking for those things and can focus on the more technically-difficult stuff. It&#x27;s up to the people on the earlier levels to make the call of whether to bounce the paper back to the author for revision.<p>(Note that, under this model, no paper is ever <i>rejected for publication</i>; papers just get trapped in an infinite revision loop, under the premise that in theory, even a paper fatally-flawed in its premise could be ship-of-Theseus-ed during revision into an entirely different, non-flawed paper.)<p>You could compare this to a software toolchain — first your code is &quot;reviewed&quot; by the lexer; then by the parser; then by the macro expansion; then by any static analysis passes; then by any semantic-model transformers run by the optimizer. Your submission can fail out as invalid at any step. More advanced &#x2F; low-level code (hand-written assembler) skips the earlier steps entirely, but that also means talking straight to something that expected pre-picked output and will give you very terse, annoyed-sounding, non-helpful errors if it <i>does</i> encounter a flaw that would have been caught earlier in the toolchain for HLL code.</div><br/><div id="42570589" class="c"><input type="checkbox" id="c-42570589" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570307">parent</a><span>|</span><a href="#42570585">next</a><span>|</span><label class="collapse" for="c-42570589">[-]</label><label class="expand" for="c-42570589">[1 more]</label></div><br/><div class="children"><div class="content">I agree with a lot of this premise but this gave me pause:<p>&gt;<i>under this model, no paper is ever rejected for publication; papers just get trapped in an infinite revision loop</i><p>This could mean a viable paper never gets published. Most journals require that you only submit to one journal at a time. So if it didn’t meet criteria for whatever reason (even a bad scope fit) it would never get a chance at a better fit somewhere else).</div><br/></div></div><div id="42570585" class="c"><input type="checkbox" id="c-42570585" checked=""/><div class="controls bullet"><span class="by">davrosthedalek</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570307">parent</a><span>|</span><a href="#42570589">prev</a><span>|</span><a href="#42570352">next</a><span>|</span><label class="collapse" for="c-42570585">[-]</label><label class="expand" for="c-42570585">[1 more]</label></div><br/><div class="children"><div class="content">Typically, papers are reviewed by 1 to 3 reviewers. I don&#x27;t think you realistically can have more than two levels -- the editor as the first line, and then one layer of reviewers.<p>You can&#x27;t really blind the author names. First, the reviewers must be able to recognize if there is a conflict of interest, and second, especially for papers on experiments, you know from the experiment name who the authors would be.</div><br/></div></div><div id="42570352" class="c"><input type="checkbox" id="c-42570352" checked=""/><div class="controls bullet"><span class="by">satellite2</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570307">parent</a><span>|</span><a href="#42570585">prev</a><span>|</span><a href="#42570993">next</a><span>|</span><label class="collapse" for="c-42570352">[-]</label><label class="expand" for="c-42570352">[1 more]</label></div><br/><div class="children"><div class="content">Assuming citations follow a zip distribution, almost all papers would have to go through all levels.</div><br/></div></div><div id="42570993" class="c"><input type="checkbox" id="c-42570993" checked=""/><div class="controls bullet"><span class="by">melagonster</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570307">parent</a><span>|</span><a href="#42570352">prev</a><span>|</span><a href="#42570173">next</a><span>|</span><label class="collapse" for="c-42570993">[-]</label><label class="expand" for="c-42570993">[1 more]</label></div><br/><div class="children"><div class="content">Unfortunately, reviewers do not get salary from this...</div><br/></div></div></div></div></div></div><div id="42570056" class="c"><input type="checkbox" id="c-42570056" checked=""/><div class="controls bullet"><span class="by">httpsterio</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569975">parent</a><span>|</span><a href="#42570156">prev</a><span>|</span><a href="#42570400">next</a><span>|</span><label class="collapse" for="c-42570056">[-]</label><label class="expand" for="c-42570056">[2 more]</label></div><br/><div class="children"><div class="content">depending on the publication the reviewers might not even know who the authors are.</div><br/><div id="42570104" class="c"><input type="checkbox" id="c-42570104" checked=""/><div class="controls bullet"><span class="by">sharth</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570056">parent</a><span>|</span><a href="#42570400">next</a><span>|</span><label class="collapse" for="c-42570104">[-]</label><label class="expand" for="c-42570104">[1 more]</label></div><br/><div class="children"><div class="content">But the journal editor should.</div><br/></div></div></div></div></div></div><div id="42571641" class="c"><input type="checkbox" id="c-42571641" checked=""/><div class="controls bullet"><span class="by">Salgat</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569608">parent</a><span>|</span><a href="#42569975">prev</a><span>|</span><a href="#42570595">next</a><span>|</span><label class="collapse" for="c-42571641">[-]</label><label class="expand" for="c-42571641">[4 more]</label></div><br/><div class="children"><div class="content">This is all due to the preverse incentives of modern academia prioritizing quantity over quantity, flooding journals with an unending churn of low effort garbage.</div><br/><div id="42571819" class="c"><input type="checkbox" id="c-42571819" checked=""/><div class="controls bullet"><span class="by">bruce511</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571641">parent</a><span>|</span><a href="#42570595">next</a><span>|</span><label class="collapse" for="c-42571819">[-]</label><label class="expand" for="c-42571819">[3 more]</label></div><br/><div class="children"><div class="content">There are easily tens of thousands of researchers globally. If every one did a single paper per year, that would still be way more than journals could realistically publish.<p>Since it is to some extent a numbers game, yes, academics (especially newer ones looking to build reputation) will submit quantity over quality. More tickets in the lottery means more chances to win.<p>I&#x27;m not sure though how you change this. With so many voices shouting for attention it&#x27;s hard to distinguish &quot;quality&quot; from the noise. And what does it even mean to prioritize &quot;quality&quot;? Is science limited to 10 advancements per year? 100? 1000? Should useful work in niche fields be ignored simply because the fields are niche?<p>Is it helpful to have academics on staff for multiple years (decades?) before they reach the standard of publishing quality?<p>I think perhaps the root of the problem you are describing is less one of &quot;quantity over quality&quot; and more one of an ever-growing &quot;industry&quot; where participants are competing against more and more people.</div><br/><div id="42572052" class="c"><input type="checkbox" id="c-42572052" checked=""/><div class="controls bullet"><span class="by">eru</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42571819">parent</a><span>|</span><a href="#42570595">next</a><span>|</span><label class="collapse" for="c-42572052">[-]</label><label class="expand" for="c-42572052">[2 more]</label></div><br/><div class="children"><div class="content">&gt; [...] way more than journals could realistically publish.<p>In what sense?  If you put it on a website, you can publish a lot more without breaking a sweat.<p>People who want a dead tree version can print it out on demand.</div><br/><div id="42572429" class="c"><input type="checkbox" id="c-42572429" checked=""/><div class="controls bullet"><span class="by">bruce511</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42572052">parent</a><span>|</span><a href="#42570595">next</a><span>|</span><label class="collapse" for="c-42572429">[-]</label><label class="expand" for="c-42572429">[1 more]</label></div><br/><div class="children"><div class="content">Publishing in the sense or reviewing, editing, etc. Distribution is the easy part.</div><br/></div></div></div></div></div></div></div></div><div id="42570595" class="c"><input type="checkbox" id="c-42570595" checked=""/><div class="controls bullet"><span class="by">foxglacier</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569608">parent</a><span>|</span><a href="#42571641">prev</a><span>|</span><a href="#42572025">next</a><span>|</span><label class="collapse" for="c-42570595">[-]</label><label class="expand" for="c-42570595">[3 more]</label></div><br/><div class="children"><div class="content">Or maybe it doesn&#x27;t matter. He got them published anyway and just lost some prestigious journal points on his career. Science&#x2F;math was the winner on the day and that&#x27;s the whole point of it. Maybe some of those lower ranked journals are run better and legitimately chipping away at the prestige of the top ones due to their carelessness.</div><br/><div id="42570791" class="c"><input type="checkbox" id="c-42570791" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570595">parent</a><span>|</span><a href="#42572025">next</a><span>|</span><label class="collapse" for="c-42570791">[-]</label><label class="expand" for="c-42570791">[2 more]</label></div><br/><div class="children"><div class="content">Research and publication incur opportunity costs. For every manuscript that has to be reworked and submitted elsewhere, you’re losing the ability to do new research. So a researcher is left trying to balance the cost&#x2F;benefit of additional time investment. Sometimes that results in a higher quality publication, sometimes it results in abandoning good (or bad) work, and sometimes it just wastes time.</div><br/><div id="42571009" class="c"><input type="checkbox" id="c-42571009" checked=""/><div class="controls bullet"><span class="by">melagonster</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570791">parent</a><span>|</span><a href="#42572025">next</a><span>|</span><label class="collapse" for="c-42571009">[-]</label><label class="expand" for="c-42571009">[1 more]</label></div><br/><div class="children"><div class="content">foxglacier offered a very good point! If some guy is so talented as Tao, perhaps this is the time to ameliorate  journal by his power (like what he did here).</div><br/></div></div></div></div></div></div><div id="42572025" class="c"><input type="checkbox" id="c-42572025" checked=""/><div class="controls bullet"><span class="by">nine_k</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569608">parent</a><span>|</span><a href="#42570595">prev</a><span>|</span><a href="#42569874">next</a><span>|</span><label class="collapse" for="c-42572025">[-]</label><label class="expand" for="c-42572025">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s as if big journals are after some drama. Or excitement at least. Not just an important result, but a groundbreaking result in its own right. If it&#x27;s a relatively small achievement that finishes a long chain of gradual progress, it better be some really famous problem, like Fermat&#x27;s last theorem, Poinrcaré&#x27;s conjecture, etc.<p>I wonder if it&#x27;s actually optimal from the journal&#x27;s selfish POV. I would expect it to want to publish articles that would be cited most widely. These should be results that are <i>important</i>, that is, are hubs for more potential related work, rather that impressive but self-contained results.</div><br/></div></div><div id="42569874" class="c"><input type="checkbox" id="c-42569874" checked=""/><div class="controls bullet"><span class="by">grepLeigh</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569608">parent</a><span>|</span><a href="#42572025">prev</a><span>|</span><a href="#42571101">next</a><span>|</span><label class="collapse" for="c-42569874">[-]</label><label class="expand" for="c-42569874">[14 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the compensation scheme for reviewers?<p>Are there any mechanisms to balance out the &quot;race to the bottom&quot; observed in other types of academic compensation? e.g. increase of adjunct&#x2F;gig work replacing full-time professorship.<p>Do universities require staff to perform a certain number of reviews in academic journals?</div><br/><div id="42570431" class="c"><input type="checkbox" id="c-42570431" checked=""/><div class="controls bullet"><span class="by">SJC_Hacker</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569874">parent</a><span>|</span><a href="#42569928">next</a><span>|</span><label class="collapse" for="c-42570431">[-]</label><label class="expand" for="c-42570431">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Do universities require staff to perform a certain number of reviews in academic journals?<p>No. Reviewers mostly do it because its expected of them, and they want to publish their own papers so they can get grants<p>In the end, the university only cares about the grant (money), because they get a cut - somewhere between 30-70% depending on the instituition&#x2F;field - for &quot;overhead&quot;<p>Its like the mafia - everyone has a boss they kick up to.<p>My old boss (PI on an RO1) explained it like this<p>Ideas -&gt; Grant -&gt; Money -&gt; Equipment&#x2F;Personnel -&gt; Experiments -&gt; Data -&gt; Paper -&gt; Submit&#x2F;Review&#x2F;Publish (hopefully) -&gt; Ideas -&gt; Grant<p>If you don&#x27;t review, go to conferences&#x2F;etc. its much less likely your own papers will get published, and you won&#x27;t get approved for grants.<p>Sadly there is still a bit of &quot;junior high popularity contest&quot; , scratch my back I&#x27;ll scratch yours that is still present in even &quot;highly respected&quot; science journals.<p>I hear this from basically every scientist I&#x27;ve known.  Even successful ones - not just the marginal ones.</div><br/><div id="42570573" class="c"><input type="checkbox" id="c-42570573" checked=""/><div class="controls bullet"><span class="by">davrosthedalek</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570431">parent</a><span>|</span><a href="#42569928">next</a><span>|</span><label class="collapse" for="c-42570573">[-]</label><label class="expand" for="c-42570573">[3 more]</label></div><br/><div class="children"><div class="content">While most of what you write is true to some extend, I do not see how reviewing will get your paper published, except maybe for the cases the authors can guess the reviewer. It&#x27;s anonymous normally.</div><br/><div id="42570655" class="c"><input type="checkbox" id="c-42570655" checked=""/><div class="controls bullet"><span class="by">SJC_Hacker</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570573">parent</a><span>|</span><a href="#42571157">next</a><span>|</span><label class="collapse" for="c-42570655">[-]</label><label class="expand" for="c-42570655">[1 more]</label></div><br/><div class="children"><div class="content">The editor does though, they all know each other.  They would know who&#x27;s not refereeing - and word gets around.</div><br/></div></div></div></div></div></div><div id="42569928" class="c"><input type="checkbox" id="c-42569928" checked=""/><div class="controls bullet"><span class="by">hanche</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569874">parent</a><span>|</span><a href="#42570431">prev</a><span>|</span><a href="#42569982">next</a><span>|</span><label class="collapse" for="c-42569928">[-]</label><label class="expand" for="c-42569928">[3 more]</label></div><br/><div class="children"><div class="content">Normally, referees are unpaid. You&#x27;re just supposed to do your share of referee work.
And then the publisher sells the fruits of all that work (research and refereeing) back to universities at a steep price. Academic publishing is one of the most profitable businesses on the planet! But univesities and academics are fighting back. Have been for a few years, but the fight is not yet over.</div><br/><div id="42570458" class="c"><input type="checkbox" id="c-42570458" checked=""/><div class="controls bullet"><span class="by">throwaway2037</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569928">parent</a><span>|</span><a href="#42569982">next</a><span>|</span><label class="collapse" for="c-42570458">[-]</label><label class="expand" for="c-42570458">[2 more]</label></div><br/><div class="children"><div class="content">If unis &quot;win&quot;, what is the likely outcome?</div><br/><div id="42570845" class="c"><input type="checkbox" id="c-42570845" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570458">parent</a><span>|</span><a href="#42569982">next</a><span>|</span><label class="collapse" for="c-42570845">[-]</label><label class="expand" for="c-42570845">[1 more]</label></div><br/><div class="children"><div class="content">More&#x2F;easier&#x2F;cheaper dissemination of research.</div><br/></div></div></div></div></div></div><div id="42569982" class="c"><input type="checkbox" id="c-42569982" checked=""/><div class="controls bullet"><span class="by">tokinonagare</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569874">parent</a><span>|</span><a href="#42569928">prev</a><span>|</span><a href="#42569972">next</a><span>|</span><label class="collapse" for="c-42569982">[-]</label><label class="expand" for="c-42569982">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t thing it&#x27;s a money problem. It&#x27;s more like a framing issue, with some reviewers being too narrow-minded, or lacking background knowledge on the topic of the paper. It&#x27;s not uncommon to have a full lab with people focussing on very different things, when you look in the details, the exact researchers interests don&#x27;t overlap too much.</div><br/></div></div><div id="42569972" class="c"><input type="checkbox" id="c-42569972" checked=""/><div class="controls bullet"><span class="by">davrosthedalek</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569874">parent</a><span>|</span><a href="#42569982">prev</a><span>|</span><a href="#42570583">next</a><span>|</span><label class="collapse" for="c-42569972">[-]</label><label class="expand" for="c-42569972">[1 more]</label></div><br/><div class="children"><div class="content">Typically, at least in physics (but as far as I know in all sciences), it&#x27;s not compensated, and the reviewers are anonymous. Some journals try to change this, with some &quot;reviewer coins&quot;, or Nature, which now publishes reviewer names if a paper is accepted and if the reviewer agrees. I think these are bad ideas.<p>Professors are expected to review by their employer, typically, and it&#x27;s a (very small) part of the tenure process.</div><br/></div></div><div id="42570583" class="c"><input type="checkbox" id="c-42570583" checked=""/><div class="controls bullet"><span class="by">jasonfarnon</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569874">parent</a><span>|</span><a href="#42569972">prev</a><span>|</span><a href="#42570407">next</a><span>|</span><label class="collapse" for="c-42570583">[-]</label><label class="expand" for="c-42570583">[1 more]</label></div><br/><div class="children"><div class="content">Do universities require staff to perform a certain number of reviews in academic journals?<p>Depends on what you mean by &quot;require&quot;. At most research universities it is a plus when reviewing tenureship files, bonuses, etc. It is a sign that someone cares about your work, and the quality of the journal seeking your review matters. If it were otherwise faculty wouldn&#x27;t list the journals they have reviewed for on their CVs. If no one would ever find out about a reviewers&#x27; efforts e.g. the process were double blind to everyone involved, the setup wouldnt work.</div><br/></div></div><div id="42570407" class="c"><input type="checkbox" id="c-42570407" checked=""/><div class="controls bullet"><span class="by">canjobear</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569874">parent</a><span>|</span><a href="#42570583">prev</a><span>|</span><a href="#42569887">next</a><span>|</span><label class="collapse" for="c-42570407">[-]</label><label class="expand" for="c-42570407">[1 more]</label></div><br/><div class="children"><div class="content">There is no compensation for reviewers, and usually no compensation for editors. It’s effectively volunteer work. I agree to review a paper if it seems interesting to me and I want to effectively force myself to read it a lot more carefully than normal. It’s hard work, especially if there is a problem with the paper, because you have to dig out the problem and explain it clearly. An academic could refuse to do any reviews with essentially no formal consequences, although they’d get a reputation as a “bad citizen” of some kind.</div><br/></div></div><div id="42569887" class="c"><input type="checkbox" id="c-42569887" checked=""/><div class="controls bullet"><span class="by">acomjean</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569874">parent</a><span>|</span><a href="#42570407">prev</a><span>|</span><a href="#42569941">next</a><span>|</span><label class="collapse" for="c-42569887">[-]</label><label class="expand" for="c-42569887">[1 more]</label></div><br/><div class="children"><div class="content">I know from some of my peers that reviewed biology (genetics) papers, they weren’t compensated.<p>I was approached to review something for no compensation as well, but I was a bad fit.</div><br/></div></div><div id="42569941" class="c"><input type="checkbox" id="c-42569941" checked=""/><div class="controls bullet"><span class="by">paulpauper</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569874">parent</a><span>|</span><a href="#42569887">prev</a><span>|</span><a href="#42571101">next</a><span>|</span><label class="collapse" for="c-42569941">[-]</label><label class="expand" for="c-42569941">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s implicitly understood that volunteer work makes the publishing process &#x27;work&#x27;. It&#x27;s supposed to be a level playing field where money does not matter.</div><br/></div></div></div></div><div id="42571101" class="c"><input type="checkbox" id="c-42571101" checked=""/><div class="controls bullet"><span class="by">wrsh07</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569608">parent</a><span>|</span><a href="#42569874">prev</a><span>|</span><a href="#42568835">next</a><span>|</span><label class="collapse" for="c-42571101">[-]</label><label class="expand" for="c-42571101">[1 more]</label></div><br/><div class="children"><div class="content">Right - it&#x27;s somewhat similar to code review<p>Sometimes one person is looking for an improvement in this area while someone else cares more about that other area<p>This is totally reasonable! (Ideally if they&#x27;re contradicting each other you can escalate to create a policy that prevents future contradictions of that sort)</div><br/></div></div></div></div><div id="42568835" class="c"><input type="checkbox" id="c-42568835" checked=""/><div class="controls bullet"><span class="by">bradleyjg</span><span>|</span><a href="#42568746">parent</a><span>|</span><a href="#42569608">prev</a><span>|</span><a href="#42568933">next</a><span>|</span><label class="collapse" for="c-42568835">[-]</label><label class="expand" for="c-42568835">[47 more]</label></div><br/><div class="children"><div class="content">This seems reasonable?<p>Suppose the full result is worth 7 impact points, which is broken up into 5 points for the partial result and 2 points for the fix. The journal has a threshold of 6 points for publication.<p>Had the authors held the paper until they had the full result, the journal would have published it, but neither part was significant enough.<p>Scholarship is better off for them not having done so, because someone else might have gotten the fix, but the journal seems to have acted reasonably.</div><br/><div id="42568946" class="c"><input type="checkbox" id="c-42568946" checked=""/><div class="controls bullet"><span class="by">tux3</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42569032">next</a><span>|</span><label class="collapse" for="c-42568946">[-]</label><label class="expand" for="c-42568946">[26 more]</label></div><br/><div class="children"><div class="content">If people thought this way - internalizing this publishing point idea - it would incentivize sitting on your incremental results, fiercely keeping them secret if and until you can prove the whole bigger result by yourself. However long that might take.<p>If a series of incremental results were as prestigious as holding off to bundle them people would have reason to collaborate and complete each other&#x27;s work more eagerly. Delaying an almost complete result for a year so that a journal will think it has enough impact point seems straightforwardly net bad, it slows down both progress &amp; collaboration.</div><br/><div id="42569196" class="c"><input type="checkbox" id="c-42569196" checked=""/><div class="controls bullet"><span class="by">gwerbret</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42569118">next</a><span>|</span><label class="collapse" for="c-42569196">[-]</label><label class="expand" for="c-42569196">[4 more]</label></div><br/><div class="children"><div class="content">&gt; If people thought this way - internalizing this publishing point idea - it would incentivize sitting on your incremental results, fiercely keeping them secret if and until you can prove the whole bigger result by yourself. However long that might take.<p>This is exactly what people think, and exactly what happens, especially in winner-takes-all situations. You end up with an interesting tension between how long you can wait to build your story, and how long until someone else publishes the same findings and takes all the credit.<p>A classic example in physics involves the discovery of the J&#x2F;ψ particle [0]. Samuel Ting&#x27;s group at MIT discovered it first (chronologically) but Ting decided he needed time to flesh out the findings, and so sat on the discovery and kept it quiet. Meanwhile, Burton Richter&#x27;s group at Stanford also happened upon the discovery, but they were less inclined to be quiet. Ting found out, and (in a spirit of collaboration) both groups submitted their papers for publication at the same time, and were published in the same issue of <i>Physical Review Letters</i>.<p>They both won the Nobel 2 years later.<p>0: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;J&#x2F;psi_meson" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;J&#x2F;psi_meson</a></div><br/><div id="42569872" class="c"><input type="checkbox" id="c-42569872" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569196">parent</a><span>|</span><a href="#42570732">next</a><span>|</span><label class="collapse" for="c-42569872">[-]</label><label class="expand" for="c-42569872">[2 more]</label></div><br/><div class="children"><div class="content">Wait, how did they both know that they both discovered it, but only after they had both discovered it?</div><br/><div id="42569978" class="c"><input type="checkbox" id="c-42569978" checked=""/><div class="controls bullet"><span class="by">davrosthedalek</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569872">parent</a><span>|</span><a href="#42570732">next</a><span>|</span><label class="collapse" for="c-42569978">[-]</label><label class="expand" for="c-42569978">[1 more]</label></div><br/><div class="children"><div class="content">People talk. The field isn&#x27;t that big.</div><br/></div></div></div></div><div id="42570732" class="c"><input type="checkbox" id="c-42570732" checked=""/><div class="controls bullet"><span class="by">ahartmetz</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569196">parent</a><span>|</span><a href="#42569872">prev</a><span>|</span><a href="#42569118">next</a><span>|</span><label class="collapse" for="c-42570732">[-]</label><label class="expand" for="c-42570732">[1 more]</label></div><br/><div class="children"><div class="content">They got an optimal result in that case, isn&#x27;t that nice.</div><br/></div></div></div></div><div id="42569118" class="c"><input type="checkbox" id="c-42569118" checked=""/><div class="controls bullet"><span class="by">chongli</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42569196">prev</a><span>|</span><a href="#42572643">next</a><span>|</span><label class="collapse" for="c-42569118">[-]</label><label class="expand" for="c-42569118">[1 more]</label></div><br/><div class="children"><div class="content">The reasonable thing to do here is to discourage all of your collaborators from ever submitting anything to that journal again. Work with your team, submit incremental results to journals who will accept them, and let the picky journal suffer a loss of reputation from not featuring some of the top researchers in the field.</div><br/></div></div><div id="42572643" class="c"><input type="checkbox" id="c-42572643" checked=""/><div class="controls bullet"><span class="by">Too</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42569118">prev</a><span>|</span><a href="#42569596">next</a><span>|</span><label class="collapse" for="c-42572643">[-]</label><label class="expand" for="c-42572643">[1 more]</label></div><br/><div class="children"><div class="content">Academic science discovers continuous integration.<p>In the software world, it&#x27;s often desired to have a steady stream of small, individually reviewable commits, that each deliver a incremental set of value.<p>Dropping a 20000 files changed bomb &quot;Complete rewrite of linux kernel audio subsystem&quot; is not seen as prestigious. Repeated, gradual contributions and involvement in the community is.</div><br/></div></div><div id="42569596" class="c"><input type="checkbox" id="c-42569596" checked=""/><div class="controls bullet"><span class="by">bennythomsson</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42572643">prev</a><span>|</span><a href="#42569296">next</a><span>|</span><label class="collapse" for="c-42569596">[-]</label><label class="expand" for="c-42569596">[3 more]</label></div><br/><div class="children"><div class="content">To supply a counter viewpoint here... The opposite is the &quot;least publishable unit&quot; which leads to loads and loads of almost-nothing results flooding the journals and other publication outlets. It would be hard to keep up with all that if there wasn&#x27;t a reasonable threshold. If anything then I find that threshold too low currently, rather than too high. The &quot;publish or perish&quot; principle also pushes people that way.</div><br/><div id="42570638" class="c"><input type="checkbox" id="c-42570638" checked=""/><div class="controls bullet"><span class="by">lupire</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569596">parent</a><span>|</span><a href="#42569296">next</a><span>|</span><label class="collapse" for="c-42570638">[-]</label><label class="expand" for="c-42570638">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s much less of a problem than the fact that papers are such poor media for sharing knowledge. They are published too slowly to be immediately useful versus just a quick chat, and simultaneously written in too rushed a way to comprehensively educate people on progress in the field.</div><br/><div id="42570778" class="c"><input type="checkbox" id="c-42570778" checked=""/><div class="controls bullet"><span class="by">ahartmetz</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42570638">parent</a><span>|</span><a href="#42569296">next</a><span>|</span><label class="collapse" for="c-42570778">[-]</label><label class="expand" for="c-42570778">[1 more]</label></div><br/><div class="children"><div class="content">The educational and editorial quality of papers from before 1980 or so beats just about anything published today. That is what publish or perish - impact factor - smallest publishable unit culture did.</div><br/></div></div></div></div></div></div><div id="42569296" class="c"><input type="checkbox" id="c-42569296" checked=""/><div class="controls bullet"><span class="by">slow_typist</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42569596">prev</a><span>|</span><a href="#42569312">next</a><span>|</span><label class="collapse" for="c-42569296">[-]</label><label class="expand" for="c-42569296">[4 more]</label></div><br/><div class="children"><div class="content">Don‘t know much about publishing in maths but in some disciplines it is clearly incentivised to create the biggest possible number of papers out of a single research project, leading automatically to incremental publishing of results. I call it atomic publishing (from Greek atomos - indivisible) since such a paper contains only one result that cannot be split up anymore.</div><br/><div id="42569954" class="c"><input type="checkbox" id="c-42569954" checked=""/><div class="controls bullet"><span class="by">hanche</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569296">parent</a><span>|</span><a href="#42572118">next</a><span>|</span><label class="collapse" for="c-42569954">[-]</label><label class="expand" for="c-42569954">[1 more]</label></div><br/><div class="children"><div class="content">Or cheese slicer publishing, as you are selling your cheese one slice at a time.
The practice is usually frowned upon.</div><br/></div></div><div id="42572118" class="c"><input type="checkbox" id="c-42572118" checked=""/><div class="controls bullet"><span class="by">dataflow</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569296">parent</a><span>|</span><a href="#42569954">prev</a><span>|</span><a href="#42570475">next</a><span>|</span><label class="collapse" for="c-42572118">[-]</label><label class="expand" for="c-42572118">[1 more]</label></div><br/><div class="children"><div class="content">I thought this was called salami slicing in publication.</div><br/></div></div><div id="42570475" class="c"><input type="checkbox" id="c-42570475" checked=""/><div class="controls bullet"><span class="by">lupire</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569296">parent</a><span>|</span><a href="#42572118">prev</a><span>|</span><a href="#42569312">next</a><span>|</span><label class="collapse" for="c-42570475">[-]</label><label class="expand" for="c-42570475">[1 more]</label></div><br/><div class="children"><div class="content">Andrew Wiles spent 6 years working on 1 paper, and then another year working on a minor follow-up.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Wiles%27s_proof_of_Fermat%27s_Last_Theorem" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Wiles%27s_proof_of_Fermat%27...</a></div><br/></div></div></div></div><div id="42569312" class="c"><input type="checkbox" id="c-42569312" checked=""/><div class="controls bullet"><span class="by">SoftTalker</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42569296">prev</a><span>|</span><a href="#42569635">next</a><span>|</span><label class="collapse" for="c-42569312">[-]</label><label class="expand" for="c-42569312">[1 more]</label></div><br/><div class="children"><div class="content">Science is almost all incremental results. There&#x27;s far more incentive to get published now than there is to &quot;sit on&quot; an incremental result hoping to add to it to make a bigger splash.</div><br/></div></div><div id="42568981" class="c"><input type="checkbox" id="c-42568981" checked=""/><div class="controls bullet"><span class="by">bradleyjg</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42569635">prev</a><span>|</span><a href="#42569595">next</a><span>|</span><label class="collapse" for="c-42568981">[-]</label><label class="expand" for="c-42568981">[4 more]</label></div><br/><div class="children"><div class="content">The big question here is if journal space is a limited resource. Obviously it was at one point.<p>Supposing it is, you have to trade off publishing these incremental results against publishing someone else’s complete result.<p>What if it had taken ten papers to get there instead of two? For a sufficiently important problem, sure, but the interesting question is at a problem that’s interesting enough to publish complete but barely.</div><br/><div id="42569253" class="c"><input type="checkbox" id="c-42569253" checked=""/><div class="controls bullet"><span class="by">parpfish</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568981">parent</a><span>|</span><a href="#42569269">next</a><span>|</span><label class="collapse" for="c-42569253">[-]</label><label class="expand" for="c-42569253">[1 more]</label></div><br/><div class="children"><div class="content">The limiting factor isn’t journal space, but attention among the audience. (In theory) the journals publishing restrictions help to filter and condense information so the audience is maximally informed given that they will only read a fixed amount</div><br/></div></div><div id="42569269" class="c"><input type="checkbox" id="c-42569269" checked=""/><div class="controls bullet"><span class="by">btilly</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568981">parent</a><span>|</span><a href="#42569253">prev</a><span>|</span><a href="#42570712">next</a><span>|</span><label class="collapse" for="c-42569269">[-]</label><label class="expand" for="c-42569269">[1 more]</label></div><br/><div class="children"><div class="content">Journal space is not a limited resource. Premium journal space is.<p>That&#x27;s because every researcher has a hierarchy of journals that they monitor. Prestigious journals are read by many researchers. So you&#x27;re essentially competing for access to the limited attention of many researchers.<p>Conversely, publishing in a premium journal has more value than a regular journal. And the big scientific publishers are therefore in competition to make sure that they own the premium journals. Which they have multiple tricks to ensure.<p>Interestingly, their tricks only really work in science. That&#x27;s because in the humanities, it is harder to establish objective opinions about quality. By contrast everyone can agree in science that <i>Nature</i> generally has the best papers. So attempting to raise the price on a prestigious science journal, works. Attempting to raise the price on a prestigious humanities journal, results in its circulation going down. Which makes it less prestigious.</div><br/></div></div><div id="42570712" class="c"><input type="checkbox" id="c-42570712" checked=""/><div class="controls bullet"><span class="by">waldrews</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568981">parent</a><span>|</span><a href="#42569269">prev</a><span>|</span><a href="#42569595">next</a><span>|</span><label class="collapse" for="c-42570712">[-]</label><label class="expand" for="c-42570712">[1 more]</label></div><br/><div class="children"><div class="content">Space isn&#x27;t a limited resource, but prestige points are deliberatly limited, as a proxy for the publications&#x27; competition for attention.  We can appreciate the irony, while considering the outcome reasonable - after all, the results weren&#x27;t kept out of the literature.  They just got published with a label that more or less  puts them lower in the search ranking for the next mathematician who looks up the topic.</div><br/></div></div></div></div><div id="42569595" class="c"><input type="checkbox" id="c-42569595" checked=""/><div class="controls bullet"><span class="by">jvanderbot</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42568981">prev</a><span>|</span><a href="#42569291">next</a><span>|</span><label class="collapse" for="c-42569595">[-]</label><label class="expand" for="c-42569595">[2 more]</label></div><br/><div class="children"><div class="content">Hyper focusing on a single journal publication is going to lead to absurdities like this. A researcher is judged by the total delta of his improvements, at least by his peers and future humanity. (the sum of all points, not the max).</div><br/></div></div><div id="42569291" class="c"><input type="checkbox" id="c-42569291" checked=""/><div class="controls bullet"><span class="by">JJMcJ</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42569595">prev</a><span>|</span><a href="#42570152">next</a><span>|</span><label class="collapse" for="c-42569291">[-]</label><label class="expand" for="c-42569291">[2 more]</label></div><br/><div class="children"><div class="content">Gauss did something along these lines and held back mathematical progress by decades.</div><br/><div id="42570627" class="c"><input type="checkbox" id="c-42570627" checked=""/><div class="controls bullet"><span class="by">lupire</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569291">parent</a><span>|</span><a href="#42570152">next</a><span>|</span><label class="collapse" for="c-42570627">[-]</label><label class="expand" for="c-42570627">[1 more]</label></div><br/><div class="children"><div class="content">Gauss had plenty of room for slack, giving people time to catch up on his work..<p>Every night Gauss went to sleep, mathematics was held back a week.</div><br/></div></div></div></div><div id="42570152" class="c"><input type="checkbox" id="c-42570152" checked=""/><div class="controls bullet"><span class="by">krick</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42569291">prev</a><span>|</span><a href="#42569030">next</a><span>|</span><label class="collapse" for="c-42570152">[-]</label><label class="expand" for="c-42570152">[1 more]</label></div><br/><div class="children"><div class="content">It is easy to defend any side of the argument by inflating the &quot;pitfalls of other approach&quot; ad absurdum. This is silly. Obviously, balance is the key, as always.<p>Instead, we should look at which side the, uh, <i>industry</i> currently tends to err. And this is definitely not the &quot;sitting on your incremental results&quot; side. The current motto of academia is to publish more. It doesn&#x27;t matter if your papers are crap, it doesn&#x27;t matter if you already have significant results and are working on something big, you have to publish to keep your position. How many crappy papers you release is a KPI of academia.<p>I mean, I can imagine a world were it would have been a good idea. I think it&#x27;s a better world, where science journals don&#x27;t exist. Instead, anybody can put any crap on ~arxiv.org~ Sci-Hub and anybody can leave comments, upvote&#x2F;downvote stuff, papers have actual links and all other modern social network mechanics up to the point you can have a feed of most interesting new papers tailored specially for you. This is open-source, non-profit, 1&#x2F;1000 of what universities used to pay for journal subscriptions is used to maintain the servers. Most importantly, because of some nice search screens or whatever the paper&#x27;s metadata becomes more important than the paper itself, and in the end we are able to assign 10-word simple summary on what the current community consensus on the paper is: if it proves anything, &quot;almost proves&quot; anything, has been 10 times disproved, 20 research teams failed to reproduce to results or 100 people (see names in the popup) tried to read and failed to understand this gibberish. Nothing gets retracted, ever.<p>Then it would be great. But as things are and all these &quot;highly reputable journals&quot; keep being a plague of society, it is actually kinda nice that somebody encourages you to finish your stuff before publishing.<p>Now, should have been this paper of Tao been rejected? I don&#x27;t know, I think not. Especially the second one. But it&#x27;s somewhat refreshing.</div><br/></div></div><div id="42569030" class="c"><input type="checkbox" id="c-42569030" checked=""/><div class="controls bullet"><span class="by">YetAnotherNick</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568946">parent</a><span>|</span><a href="#42570152">prev</a><span>|</span><a href="#42569032">next</a><span>|</span><label class="collapse" for="c-42569030">[-]</label><label class="expand" for="c-42569030">[1 more]</label></div><br/><div class="children"><div class="content">Two submission in medium reputation journal does not have significantly lower prestige than one in high reputation journal.</div><br/></div></div></div></div><div id="42569032" class="c"><input type="checkbox" id="c-42569032" checked=""/><div class="controls bullet"><span class="by">Arainach</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42568946">prev</a><span>|</span><a href="#42569000">next</a><span>|</span><label class="collapse" for="c-42569032">[-]</label><label class="expand" for="c-42569032">[2 more]</label></div><br/><div class="children"><div class="content">These patterns are ultimately detrimental to team&#x2F;community building, however.<p>You see it in software as well: As a manager in calibration meetings, I have repeatedly seen how it is harder to convince a committee to promote&#x2F;give a high rating to someone with a large pile of crucial but individually small projects delivered than someone with a single large project.<p>This is discouraging to people whose efforts seem to be unrewarded and creates bad incentives for people to hoard work and avoid sharing until one large impact, and it&#x27;s disastrous when (as in most software teams) those people don&#x27;t have significant autonomy over which projects they&#x27;re assigned.</div><br/><div id="42570193" class="c"><input type="checkbox" id="c-42570193" checked=""/><div class="controls bullet"><span class="by">mlepath</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569032">parent</a><span>|</span><a href="#42569000">next</a><span>|</span><label class="collapse" for="c-42570193">[-]</label><label class="expand" for="c-42570193">[1 more]</label></div><br/><div class="children"><div class="content">Hello, fellow Metamate ;)</div><br/></div></div></div></div><div id="42569000" class="c"><input type="checkbox" id="c-42569000" checked=""/><div class="controls bullet"><span class="by">cvoss</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42569032">prev</a><span>|</span><a href="#42568881">next</a><span>|</span><label class="collapse" for="c-42569000">[-]</label><label class="expand" for="c-42569000">[1 more]</label></div><br/><div class="children"><div class="content">The idea that a small number of reviewers can accurately quantify the importance of a paper as some number of &quot;impact points,&quot; and the idea that a journal should rely on this number and an arbitrary cut off point to decide publication, are both unreasonable ideas.<p>The journal may have acted <i>systematically</i>, but the system is arbitrary and capricious. Thus, the journal did not act reasonably.</div><br/></div></div><div id="42568881" class="c"><input type="checkbox" id="c-42568881" checked=""/><div class="controls bullet"><span class="by">remus</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42569000">prev</a><span>|</span><a href="#42568980">next</a><span>|</span><label class="collapse" for="c-42568881">[-]</label><label class="expand" for="c-42568881">[6 more]</label></div><br/><div class="children"><div class="content">&gt; This seems reasonable?<p>In some sense, but it does feel like the journal is missing the bigger picture somewhat. Say the two papers are A and B, and we have A + B = C. The journal is saying they&#x27;ll publish C, but not A and B!</div><br/><div id="42568967" class="c"><input type="checkbox" id="c-42568967" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568881">parent</a><span>|</span><a href="#42568930">next</a><span>|</span><label class="collapse" for="c-42568967">[-]</label><label class="expand" for="c-42568967">[3 more]</label></div><br/><div class="children"><div class="content">How many step papers before a keystone paper seems reasonable to you?<p>I suspect readers don’t find it as exciting to read partial result papers.  Unless there is an open invitation to compete on its completion, which would have a purpose and be fun. If papers are not page turners, then the journal is going to have a hard time keeping subscribers.<p>On the other hand, publishing a proof of a Millennium Problem as several installments, is probably a fantastic idea. Time to absorb each contributing result. And the suspense!<p>Then republish the collected papers as a signed special leather limited series edition. Easton, get on this!</div><br/><div id="42569343" class="c"><input type="checkbox" id="c-42569343" checked=""/><div class="controls bullet"><span class="by">slow_typist</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568967">parent</a><span>|</span><a href="#42568930">next</a><span>|</span><label class="collapse" for="c-42569343">[-]</label><label class="expand" for="c-42569343">[2 more]</label></div><br/><div class="children"><div class="content">Publishing partial results is always an invitation to compete in the completion, unless the completion is dependent on special lab capabilities which need time and money to acquire. There is no need to literally invite anyone.</div><br/><div id="42570269" class="c"><input type="checkbox" id="c-42570269" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569343">parent</a><span>|</span><a href="#42568930">next</a><span>|</span><label class="collapse" for="c-42570269">[-]</label><label class="expand" for="c-42570269">[1 more]</label></div><br/><div class="children"><div class="content">I meant if the editors found the paper’s problem and progress especially worthy of a competition.</div><br/></div></div></div></div></div></div><div id="42568925" class="c"><input type="checkbox" id="c-42568925" checked=""/><div class="controls bullet"><span class="by">cubefox</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568881">parent</a><span>|</span><a href="#42568930">prev</a><span>|</span><a href="#42568980">next</a><span>|</span><label class="collapse" for="c-42568925">[-]</label><label class="expand" for="c-42568925">[1 more]</label></div><br/><div class="children"><div class="content">... A and B separately.</div><br/></div></div></div></div><div id="42568980" class="c"><input type="checkbox" id="c-42568980" checked=""/><div class="controls bullet"><span class="by">pinkmuffinere</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42568881">prev</a><span>|</span><a href="#42569647">next</a><span>|</span><label class="collapse" for="c-42568980">[-]</label><label class="expand" for="c-42568980">[5 more]</label></div><br/><div class="children"><div class="content">I agree this is reasonable from the individual publisher standpoint. I once received feedback from a reviewer that I was &quot;searching for the minimum publishable unit&quot;, and in some sense the reviewer was right -- as soon as I thought the result could be published I started working towards the publication. A publisher can reasonably resist these kinds of papers, as you&#x27;re pointing out.<p>I think the impact to scholarship in general is less clear. Do you immediately publish once you get a &quot;big enough&quot; result, so that others can build off of it? Or does this needlessly clutter the field with publications? There&#x27;s probably some optimal balance, but I don&#x27;t think the right balance is immediately clear.</div><br/><div id="42569190" class="c"><input type="checkbox" id="c-42569190" checked=""/><div class="controls bullet"><span class="by">nextn</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568980">parent</a><span>|</span><a href="#42569568">next</a><span>|</span><label class="collapse" for="c-42569190">[-]</label><label class="expand" for="c-42569190">[2 more]</label></div><br/><div class="children"><div class="content">Why would publishing anything new needlessly clutter the field?<p>Discovering something is hard, proving it correct is hard, and writing a paper about is hard. Why delay all this?</div><br/><div id="42569697" class="c"><input type="checkbox" id="c-42569697" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569190">parent</a><span>|</span><a href="#42569568">next</a><span>|</span><label class="collapse" for="c-42569697">[-]</label><label class="expand" for="c-42569697">[1 more]</label></div><br/><div class="children"><div class="content">Playing devils advocate, there isn’t a consensus on what is incremental vs what is derivative. In theory, the latter may not warrant publication because anyone familiar with the state-of-the-art could connect the dots without reading about it in a publication.</div><br/></div></div></div></div><div id="42569568" class="c"><input type="checkbox" id="c-42569568" checked=""/><div class="controls bullet"><span class="by">SilasX</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568980">parent</a><span>|</span><a href="#42569190">prev</a><span>|</span><a href="#42569647">next</a><span>|</span><label class="collapse" for="c-42569568">[-]</label><label class="expand" for="c-42569568">[2 more]</label></div><br/><div class="children"><div class="content">Ouch. That would hurt to hear. It&#x27;s like they&#x27;re effectively saying, &quot;yeah, <i>obviously</i> you came up with something more significant than this, which you&#x27;re holding back. No one would be so incapable that <i>this</i> was as far as they could take the result!&quot;</div><br/><div id="42571758" class="c"><input type="checkbox" id="c-42571758" checked=""/><div class="controls bullet"><span class="by">pinkmuffinere</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569568">parent</a><span>|</span><a href="#42569647">next</a><span>|</span><label class="collapse" for="c-42571758">[-]</label><label class="expand" for="c-42571758">[1 more]</label></div><br/><div class="children"><div class="content">Thankfully the reviewer feedback was of such low quality in general that it had little impact on my feelings, haha. I think that’s unfortunately common. My advisor told me “leave some obvious but unimportant mistakes, so they have something to criticize, they can feel good, and move on”. I honestly think that was good advice.</div><br/></div></div></div></div></div></div><div id="42569647" class="c"><input type="checkbox" id="c-42569647" checked=""/><div class="controls bullet"><span class="by">omoikane</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42568980">prev</a><span>|</span><a href="#42569076">next</a><span>|</span><label class="collapse" for="c-42569647">[-]</label><label class="expand" for="c-42569647">[1 more]</label></div><br/><div class="children"><div class="content">But proportionally, wouldn&#x27;t a solution without an epsilon loss be much better than a solution with epsilon?<p>I am not sure what&#x27;s the exact conjecture that the author solved, but if the epsilon difference is between an approximate solution versus an exact solution, and the journal rejected the exact solution because it was &quot;only an epsilon improvement&quot;, I might question how reputable that journal really was.</div><br/></div></div><div id="42569076" class="c"><input type="checkbox" id="c-42569076" checked=""/><div class="controls bullet"><span class="by">saghm</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42569647">prev</a><span>|</span><a href="#42569369">next</a><span>|</span><label class="collapse" for="c-42569076">[-]</label><label class="expand" for="c-42569076">[1 more]</label></div><br/><div class="children"><div class="content">If this was actually how stuff was measured, it might be defensible. I&#x27;m having trouble believing that things are actually done this objectively rather than the rejections being somewhat arbitrary. Do you think that results can really be analyzed and compared in this way? How do you know that it&#x27;s 5 and 2 and not 6 and 1 or 4 and 3, and how do you determine how many points a full result is worth in total?</div><br/></div></div><div id="42569369" class="c"><input type="checkbox" id="c-42569369" checked=""/><div class="controls bullet"><span class="by">Brian_K_White</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42569076">prev</a><span>|</span><a href="#42569683">next</a><span>|</span><label class="collapse" for="c-42569369">[-]</label><label class="expand" for="c-42569369">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s demonstrably (there is one demonstration right there) self-defeating and counter-productive, and so by definition not reasonable.<p>Each individual step along the way merely has some rationale, but rationales come in the full spectrum of quality.</div><br/></div></div><div id="42569683" class="c"><input type="checkbox" id="c-42569683" checked=""/><div class="controls bullet"><span class="by">sunshowers</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42569369">prev</a><span>|</span><a href="#42568904">next</a><span>|</span><label class="collapse" for="c-42569683">[-]</label><label class="expand" for="c-42569683">[2 more]</label></div><br/><div class="children"><div class="content">Given the current incentive scheme in place it&#x27;s locally reasonable, but the current incentives suck. Is the goal to score the most impact points or to advance our understanding of the field?</div><br/><div id="42570080" class="c"><input type="checkbox" id="c-42570080" checked=""/><div class="controls bullet"><span class="by">mnky9800n</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569683">parent</a><span>|</span><a href="#42568904">next</a><span>|</span><label class="collapse" for="c-42570080">[-]</label><label class="expand" for="c-42570080">[1 more]</label></div><br/><div class="children"><div class="content">In my experience, it depends on the scientist. But it’s hard to know what an advance is. Like, people long searched for evidence of æther before giving up and accepting that light doesn’t need a medium to travel in. Perhaps 100 years from now people will laugh at the attention is all you need paper that led to the llm craze. Who knows. That’s why it’s important to give space to science. From my understanding Lorenz worked for 5 years without publishing as a research scientist before writing his atmospheric circulation paper. That paper essentially created the field of chaos. Would he be able to do the same today? Maybe? Or maybe counting papers or impact factors or all these other metrics turned science into a game instead of an intellectual pursuit. Shame we cannot ask Lorenz or Maxwell about their times as a scientist. They are dead.</div><br/></div></div></div></div><div id="42568904" class="c"><input type="checkbox" id="c-42568904" checked=""/><div class="controls bullet"><span class="by">Ar-Curunir</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568835">parent</a><span>|</span><a href="#42569683">prev</a><span>|</span><a href="#42568933">next</a><span>|</span><label class="collapse" for="c-42568904">[-]</label><label class="expand" for="c-42568904">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think that’s a useful way to think about this, especially when theres so little information provided about this. Reviewing is a capricious process.</div><br/></div></div></div></div><div id="42568933" class="c"><input type="checkbox" id="c-42568933" checked=""/><div class="controls bullet"><span class="by">stevage</span><span>|</span><a href="#42568746">parent</a><span>|</span><a href="#42568835">prev</a><span>|</span><a href="#42569289">next</a><span>|</span><label class="collapse" for="c-42568933">[-]</label><label class="expand" for="c-42568933">[4 more]</label></div><br/><div class="children"><div class="content">It actually seems reasonable for a journal that has limited space and too many submissions. What&#x27;s the alternative, to accept on or two of the half proofs, and bump one or two other papers in the process?</div><br/><div id="42568992" class="c"><input type="checkbox" id="c-42568992" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568933">parent</a><span>|</span><a href="#42569289">next</a><span>|</span><label class="collapse" for="c-42568992">[-]</label><label class="expand" for="c-42568992">[3 more]</label></div><br/><div class="children"><div class="content">Wow, it’s so sad that their budget doesn’t stretch to purchasing hard drives with capacities measured in gigabytes. It must be rough having to delete old files from the floppies they’re still forced to use in this day and age.</div><br/><div id="42569320" class="c"><input type="checkbox" id="c-42569320" checked=""/><div class="controls bullet"><span class="by">y1n0</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42568992">parent</a><span>|</span><a href="#42569289">next</a><span>|</span><label class="collapse" for="c-42569320">[-]</label><label class="expand" for="c-42569320">[2 more]</label></div><br/><div class="children"><div class="content">That logic is absurd. You might as well consider the whole internet a journal and everything is already published, so there is nothing to complain about.</div><br/><div id="42569460" class="c"><input type="checkbox" id="c-42569460" checked=""/><div class="controls bullet"><span class="by">jiggawatts</span><span>|</span><a href="#42568746">root</a><span>|</span><a href="#42569320">parent</a><span>|</span><a href="#42569289">next</a><span>|</span><label class="collapse" for="c-42569460">[-]</label><label class="expand" for="c-42569460">[1 more]</label></div><br/><div class="children"><div class="content">It pretty much <i>is</i> the logic — except replace digital media with paper.<p>It’s also “why” research papers can’t have color pictures or tables of raw data — because they’re expensive to print.<p>Scientists internalised their limitations and treat these as virtues now.<p>Limited space in printing means you have to “get in”, and that exclusivity has a cachet. They also now advise each other that photos are “not real science” (too much color!) and raw data shouldn’t be published at all.<p>I was making a joke to highlight how inane this is in an era where I can keep every paper ever published on one hard drive.<p>The same people that complain about negative results or reproductions not getting published will defend these limitations to the death.</div><br/></div></div></div></div></div></div></div></div><div id="42569289" class="c"><input type="checkbox" id="c-42569289" checked=""/><div class="controls bullet"><span class="by">JJMcJ</span><span>|</span><a href="#42568746">parent</a><span>|</span><a href="#42568933">prev</a><span>|</span><a href="#42570110">next</a><span>|</span><label class="collapse" for="c-42569289">[-]</label><label class="expand" for="c-42569289">[1 more]</label></div><br/><div class="children"><div class="content">Do Reddit mods also edit math journals?</div><br/></div></div><div id="42570110" class="c"><input type="checkbox" id="c-42570110" checked=""/><div class="controls bullet"><span class="by">dumbfounder</span><span>|</span><a href="#42568746">parent</a><span>|</span><a href="#42569289">prev</a><span>|</span><a href="#42571521">next</a><span>|</span><label class="collapse" for="c-42570110">[-]</label><label class="expand" for="c-42570110">[1 more]</label></div><br/><div class="children"><div class="content">Sort of. But it makes sense. They missed out the first time and don’t want to be an also-ran. If he had gone for the glory from the start it may have been different. The prestigious journals probably don’t want incremental papers.</div><br/></div></div><div id="42571521" class="c"><input type="checkbox" id="c-42571521" checked=""/><div class="controls bullet"><span class="by">pentae</span><span>|</span><a href="#42568746">parent</a><span>|</span><a href="#42570110">prev</a><span>|</span><a href="#42569929">next</a><span>|</span><label class="collapse" for="c-42571521">[-]</label><label class="expand" for="c-42571521">[1 more]</label></div><br/><div class="children"><div class="content">So it&#x27;s basically like submitting an iOS app to the app store.</div><br/></div></div><div id="42569929" class="c"><input type="checkbox" id="c-42569929" checked=""/><div class="controls bullet"><span class="by">paulpauper</span><span>|</span><a href="#42568746">parent</a><span>|</span><a href="#42571521">prev</a><span>|</span><a href="#42568836">next</a><span>|</span><label class="collapse" for="c-42569929">[-]</label><label class="expand" for="c-42569929">[1 more]</label></div><br/><div class="children"><div class="content">Don&#x27;t you hate it when you lose your epsilon, only to find it and it&#x27;s too late?<p>I wonder what the conjecture was?</div><br/></div></div><div id="42568836" class="c"><input type="checkbox" id="c-42568836" checked=""/><div class="controls bullet"><span class="by">gxs</span><span>|</span><a href="#42568746">parent</a><span>|</span><a href="#42569929">prev</a><span>|</span><a href="#42569873">next</a><span>|</span><label class="collapse" for="c-42568836">[-]</label><label class="expand" for="c-42568836">[1 more]</label></div><br/><div class="children"><div class="content">Are you sure this wasn’t an application to the DMV or an attempt to pull a building permit?</div><br/></div></div></div></div><div id="42569873" class="c"><input type="checkbox" id="c-42569873" checked=""/><div class="controls bullet"><span class="by">cperciva</span><span>|</span><a href="#42568746">prev</a><span>|</span><a href="#42568678">next</a><span>|</span><label class="collapse" for="c-42569873">[-]</label><label class="expand" for="c-42569873">[8 more]</label></div><br/><div class="children"><div class="content">In 2005, my paper on breaking RSA by observing a single private-key operation from a different hyperthread sharing the same L1 cache -- literally the first publication of a cryptographic attack exploiting shared caches -- was rejected from the cryptology preprint archive on the grounds that &quot;it was about CPU architecture, not cryptography&quot;.  Rejection from journals is like rejection from VCs -- it happens all the time and often not for any good reason.<p>(That paper has now been cited 971 times according to Google Scholar, despite never appearing in a journal.)</div><br/><div id="42569995" class="c"><input type="checkbox" id="c-42569995" checked=""/><div class="controls bullet"><span class="by">davrosthedalek</span><span>|</span><a href="#42569873">parent</a><span>|</span><a href="#42571565">next</a><span>|</span><label class="collapse" for="c-42569995">[-]</label><label class="expand" for="c-42569995">[6 more]</label></div><br/><div class="children"><div class="content">Is it on the arxiv? If not, please put it there.</div><br/><div id="42570237" class="c"><input type="checkbox" id="c-42570237" checked=""/><div class="controls bullet"><span class="by">ilya_m</span><span>|</span><a href="#42569873">root</a><span>|</span><a href="#42569995">parent</a><span>|</span><a href="#42571565">next</a><span>|</span><label class="collapse" for="c-42570237">[-]</label><label class="expand" for="c-42570237">[5 more]</label></div><br/><div class="children"><div class="content">The paper is here: <a href="http:&#x2F;&#x2F;www.daemonology.net&#x2F;hyperthreading-considered-harmful&#x2F;" rel="nofollow">http:&#x2F;&#x2F;www.daemonology.net&#x2F;hyperthreading-considered-harmful...</a><p>As its author noted, the paper has done fine ciation- and impact-wise.</div><br/><div id="42570276" class="c"><input type="checkbox" id="c-42570276" checked=""/><div class="controls bullet"><span class="by">cperciva</span><span>|</span><a href="#42569873">root</a><span>|</span><a href="#42570237">parent</a><span>|</span><a href="#42570563">next</a><span>|</span><label class="collapse" for="c-42570276">[-]</label><label class="expand" for="c-42570276">[1 more]</label></div><br/><div class="children"><div class="content">Paper is here: <a href="https:&#x2F;&#x2F;www.daemonology.net&#x2F;papers&#x2F;cachemissing.pdf" rel="nofollow">https:&#x2F;&#x2F;www.daemonology.net&#x2F;papers&#x2F;cachemissing.pdf</a><p>Your link is the website I put up for non-experts when I announced the issue.</div><br/></div></div><div id="42570563" class="c"><input type="checkbox" id="c-42570563" checked=""/><div class="controls bullet"><span class="by">davrosthedalek</span><span>|</span><a href="#42569873">root</a><span>|</span><a href="#42570237">parent</a><span>|</span><a href="#42570276">prev</a><span>|</span><a href="#42571565">next</a><span>|</span><label class="collapse" for="c-42570563">[-]</label><label class="expand" for="c-42570563">[3 more]</label></div><br/><div class="children"><div class="content">In this case, it&#x27;s less about discoverability, but more about long term archival. Will daemonology.net continue to exist forever? Arxiv.org might perish, but I am sure the community will make sure the data will be preserved.</div><br/><div id="42570781" class="c"><input type="checkbox" id="c-42570781" checked=""/><div class="controls bullet"><span class="by">cperciva</span><span>|</span><a href="#42569873">root</a><span>|</span><a href="#42570563">parent</a><span>|</span><a href="#42571565">next</a><span>|</span><label class="collapse" for="c-42570781">[-]</label><label class="expand" for="c-42570781">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not too worried about that -- this paper is &quot;mirrored&quot; on hundreds of university websites since it&#x27;s a common reference for graduate courses in computer security.</div><br/><div id="42571954" class="c"><input type="checkbox" id="c-42571954" checked=""/><div class="controls bullet"><span class="by">ht_th</span><span>|</span><a href="#42569873">root</a><span>|</span><a href="#42570781">parent</a><span>|</span><a href="#42571565">next</a><span>|</span><label class="collapse" for="c-42571954">[-]</label><label class="expand" for="c-42571954">[1 more]</label></div><br/><div class="children"><div class="content">In my experience, once teachers retire or move on, or a course gets mothballed, it&#x27;s only a matter of time for course websites disappear or become non-functional.<p>If the course website was even on the open web to begin with. If they&#x27;re in some university content management system (CMS), chances are that access is limited to students and teachers of that university and the CMS gets &quot;cleaned&quot; regularly by removing old and &quot;unused&quot; content. Let alone what will happen when the CMS is replaced by another after a couple of years.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42571565" class="c"><input type="checkbox" id="c-42571565" checked=""/><div class="controls bullet"><span class="by">fl4tul4</span><span>|</span><a href="#42569873">parent</a><span>|</span><a href="#42569995">prev</a><span>|</span><a href="#42568678">next</a><span>|</span><label class="collapse" for="c-42571565">[-]</label><label class="expand" for="c-42571565">[1 more]</label></div><br/><div class="children"><div class="content">The journal lost, as it would have increased their h-index and reputation significantly.</div><br/></div></div></div></div><div id="42568678" class="c"><input type="checkbox" id="c-42568678" checked=""/><div class="controls bullet"><span class="by">jraph</span><span>|</span><a href="#42569873">prev</a><span>|</span><a href="#42568971">next</a><span>|</span><label class="collapse" for="c-42568678">[-]</label><label class="expand" for="c-42568678">[15 more]</label></div><br/><div class="children"><div class="content">I was confused by the title because paper rejection is incredibly common in research, but that&#x27;s the point and one of the goals is to fight imposter syndrome.<p>It&#x27;s a good initiative. Next step: everybody realizes that researchers are just random people like everybody. Maybe that could kill any remaining imposter syndrome.<p>A rejection, although common, is quite tough during your PhD though, even ignoring the imposter syndrome, because in a short time, you are expected to have a bunch of accepted papers, in prestigious publications if possible. It feels like a rejection slows you down, and the clock is still ticking. If we could kill some of this nefarious system, that&#x27;d be good as well.</div><br/><div id="42569287" class="c"><input type="checkbox" id="c-42569287" checked=""/><div class="controls bullet"><span class="by">arrowsmith</span><span>|</span><a href="#42568678">parent</a><span>|</span><a href="#42568909">next</a><span>|</span><label class="collapse" for="c-42569287">[-]</label><label class="expand" for="c-42569287">[4 more]</label></div><br/><div class="children"><div class="content">It’s noteworthy because it’s from Terence Tao, regarded by many as the world’s greatest living mathematician.<p>If you read the full post he’s making the exact same point as you: it’s common and normal to get a paper rejected even if you’re Terence Tao, so don’t treat a rejection like the end of the world.</div><br/><div id="42570724" class="c"><input type="checkbox" id="c-42570724" checked=""/><div class="controls bullet"><span class="by">vitus</span><span>|</span><a href="#42568678">root</a><span>|</span><a href="#42569287">parent</a><span>|</span><a href="#42572087">next</a><span>|</span><label class="collapse" for="c-42570724">[-]</label><label class="expand" for="c-42570724">[2 more]</label></div><br/><div class="children"><div class="content">&gt; regarded by many as the world’s greatest living mathematician.<p>Oh?<p>Perelman comes to mind (as the only person who has been eligible to claim one of the Millennium prizes), although he is no longer actively practicing math AFAIK. Of Abel prize winners, Wiles proved Fermat&#x27;s last theorem, and Szemeredi has a number of number-theoretic and combinatorial contributions.<p>Recently deceased (past ~10 years) include figures such as John Nash, Grothendieck, and Conway.<p>Tao is definitely one of the most well-known mathematicians, and he&#x27;s still got several more decades of accomplishments ahead of him, but I don&#x27;t know that he rises to &quot;greatest living mathematician&quot; at this point.<p>That said, I do appreciate that he indicates that even his papers get rejected from time to time.</div><br/><div id="42570916" class="c"><input type="checkbox" id="c-42570916" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#42568678">root</a><span>|</span><a href="#42570724">parent</a><span>|</span><a href="#42572087">next</a><span>|</span><label class="collapse" for="c-42570916">[-]</label><label class="expand" for="c-42570916">[1 more]</label></div><br/><div class="children"><div class="content">Having been a child prodigy somehow gives one infamy (in the wider public consciousness) beyond anything one can achieve as an adult.</div><br/></div></div></div></div><div id="42572087" class="c"><input type="checkbox" id="c-42572087" checked=""/><div class="controls bullet"><span class="by">jraph</span><span>|</span><a href="#42568678">root</a><span>|</span><a href="#42569287">parent</a><span>|</span><a href="#42570724">prev</a><span>|</span><a href="#42568909">next</a><span>|</span><label class="collapse" for="c-42572087">[-]</label><label class="expand" for="c-42572087">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It’s noteworthy because it’s from Terence Tao, regarded by many as the world’s greatest living mathematician.<p>I didn&#x27;t know :-)<p>&gt; If you read the full post he’s making the exact same point as you<p>Oh yeah, that&#x27;s because I did read the full post and was summarizing. I should have made this clear.</div><br/></div></div></div></div><div id="42568909" class="c"><input type="checkbox" id="c-42568909" checked=""/><div class="controls bullet"><span class="by">bisby</span><span>|</span><a href="#42568678">parent</a><span>|</span><a href="#42569287">prev</a><span>|</span><a href="#42569769">next</a><span>|</span><label class="collapse" for="c-42568909">[-]</label><label class="expand" for="c-42568909">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s especially important coming from someone like Terence Tao. If one of the best and brightest mathematicians out there can get a paper declined, then it can happen to literally anyone.</div><br/></div></div><div id="42569769" class="c"><input type="checkbox" id="c-42569769" checked=""/><div class="controls bullet"><span class="by">jonathan_landy</span><span>|</span><a href="#42568678">parent</a><span>|</span><a href="#42568909">prev</a><span>|</span><a href="#42569292">next</a><span>|</span><label class="collapse" for="c-42569769">[-]</label><label class="expand" for="c-42569769">[1 more]</label></div><br/><div class="children"><div class="content">I guess it is nice to know that he is also not perfect.  But it’s still the case that his accomplishments outshine my own, so my imposter syndrome remains intact.</div><br/></div></div><div id="42571275" class="c"><input type="checkbox" id="c-42571275" checked=""/><div class="controls bullet"><span class="by">firesteelrain</span><span>|</span><a href="#42568678">parent</a><span>|</span><a href="#42569292">prev</a><span>|</span><a href="#42569845">next</a><span>|</span><label class="collapse" for="c-42571275">[-]</label><label class="expand" for="c-42571275">[2 more]</label></div><br/><div class="children"><div class="content">At my college, you only need one paper not many</div><br/><div id="42572191" class="c"><input type="checkbox" id="c-42572191" checked=""/><div class="controls bullet"><span class="by">jraph</span><span>|</span><a href="#42568678">root</a><span>|</span><a href="#42571275">parent</a><span>|</span><a href="#42569845">next</a><span>|</span><label class="collapse" for="c-42572191">[-]</label><label class="expand" for="c-42572191">[1 more]</label></div><br/><div class="children"><div class="content">In mine, I don&#x27;t think there was a hard requirement, but your PhD would be seen as weak with zero paper, and only one would be common enough I guess but still be seen a bit weak. It&#x27;s not very important to grade, but it&#x27;s important for what follows: your carrier, including getting a position.</div><br/></div></div></div></div><div id="42569845" class="c"><input type="checkbox" id="c-42569845" checked=""/><div class="controls bullet"><span class="by">2-3-7-43-1807</span><span>|</span><a href="#42568678">parent</a><span>|</span><a href="#42571275">prev</a><span>|</span><a href="#42568971">next</a><span>|</span><label class="collapse" for="c-42569845">[-]</label><label class="expand" for="c-42569845">[5 more]</label></div><br/><div class="children"><div class="content">terence tao is suffering from imposter syndrome? if anything, imposter syndrome is suffering from terence tao ... do you maybe not know who terence tao is?</div><br/><div id="42571593" class="c"><input type="checkbox" id="c-42571593" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#42568678">root</a><span>|</span><a href="#42569845">parent</a><span>|</span><a href="#42568971">next</a><span>|</span><label class="collapse" for="c-42571593">[-]</label><label class="expand" for="c-42571593">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;s terence tao trying to help others with imposter syndrome. It seems quite unlikely he himself would suffer from it...</div><br/><div id="42571655" class="c"><input type="checkbox" id="c-42571655" checked=""/><div class="controls bullet"><span class="by">NooneAtAll3</span><span>|</span><a href="#42568678">root</a><span>|</span><a href="#42571593">parent</a><span>|</span><a href="#42568971">next</a><span>|</span><label class="collapse" for="c-42571655">[-]</label><label class="expand" for="c-42571655">[3 more]</label></div><br/><div class="children"><div class="content">on the contrary, that&#x27;s exactly what he states in comment discussion below the thread<p>having higher reputation means higher responsibility not to crush someone with it in the sub-fields you aren&#x27;t as proficient as</div><br/><div id="42571917" class="c"><input type="checkbox" id="c-42571917" checked=""/><div class="controls bullet"><span class="by">danielmarkbruce</span><span>|</span><a href="#42568678">root</a><span>|</span><a href="#42571655">parent</a><span>|</span><a href="#42568971">next</a><span>|</span><label class="collapse" for="c-42571917">[-]</label><label class="expand" for="c-42571917">[2 more]</label></div><br/><div class="children"><div class="content">yeah... he&#x27;s telling a white lie of sorts...reread the comment. That doesn&#x27;t sound like someone lacking self confidence. &quot;the other members <i>collectively</i> ...&quot;. He&#x27;s basically saying &quot;get the world leading experts in some area of math that I&#x27;m sort of interested in in a room and between them they&#x27;ll know more than I do myself&quot;. Lol. And, that&#x27;s happened &quot;several times&quot;.<p>I&#x27;m sure he&#x27;s a genuinely nice, friendly person trying to do the right thing. But he is also likely confident as hell and never felt like an imposter anywhere.</div><br/><div id="42572163" class="c"><input type="checkbox" id="c-42572163" checked=""/><div class="controls bullet"><span class="by">jraph</span><span>|</span><a href="#42568678">root</a><span>|</span><a href="#42571917">parent</a><span>|</span><a href="#42568971">next</a><span>|</span><label class="collapse" for="c-42572163">[-]</label><label class="expand" for="c-42572163">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think it&#x27;s a white lie. Whether he has imposter syndrome is beside the point. It shows he has sympathy for his colleagues who might have it. Maybe he himself had it before which would let him understand even better what it is, and now he doesn&#x27;t anymore, this would motivate him to make this point.<p>The point he is making is all the motr convincing especially that he is seen as very good, whether he had imposter syndrome or not.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="42568971" class="c"><input type="checkbox" id="c-42568971" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568678">prev</a><span>|</span><a href="#42568592">next</a><span>|</span><label class="collapse" for="c-42568971">[-]</label><label class="expand" for="c-42568971">[8 more]</label></div><br/><div class="children"><div class="content">Adam Grant once related an amusing rejection from a double-blind review. One of the reviewers justified the rejection with something along the lines of “The author would do well to familiarize themselves with the work of Adam Grant”</div><br/><div id="42569117" class="c"><input type="checkbox" id="c-42569117" checked=""/><div class="controls bullet"><span class="by">orthoxerox</span><span>|</span><a href="#42568971">parent</a><span>|</span><a href="#42569093">next</a><span>|</span><label class="collapse" for="c-42569117">[-]</label><label class="expand" for="c-42569117">[1 more]</label></div><br/><div class="children"><div class="content">Life imitates art. In a 1986 comedy &quot;Back to School&quot; Rodney Dangerfield&#x27;s character delegates his college assignments to various subject matter experts. His English Lit teacher berates him for it, saying that not only did he obviously cheat, but he also copied his essay from someone who&#x27;s unfamiliar with the works of Kurt Vonnegut. Of course, the essay was written by Vonnegut himself, appearing in a cameo role.</div><br/></div></div><div id="42569093" class="c"><input type="checkbox" id="c-42569093" checked=""/><div class="controls bullet"><span class="by">Upvoter33</span><span>|</span><a href="#42568971">parent</a><span>|</span><a href="#42569117">prev</a><span>|</span><a href="#42570855">next</a><span>|</span><label class="collapse" for="c-42569093">[-]</label><label class="expand" for="c-42569093">[2 more]</label></div><br/><div class="children"><div class="content">This also happens pretty commonly. However, it&#x27;s not even unreasonable! Sometimes you write a paper and you don&#x27;t do a good enough of a job putting in the context of your own related work.</div><br/><div id="42569675" class="c"><input type="checkbox" id="c-42569675" checked=""/><div class="controls bullet"><span class="by">CrazyStat</span><span>|</span><a href="#42568971">root</a><span>|</span><a href="#42569093">parent</a><span>|</span><a href="#42570855">next</a><span>|</span><label class="collapse" for="c-42569675">[-]</label><label class="expand" for="c-42569675">[1 more]</label></div><br/><div class="children"><div class="content">And sometimes the reviewer didn&#x27;t read carefully and doesn&#x27;t understand what you&#x27;re doing.<p>I once wrote a paper along the lines of &quot;look we can do X blazingly fast, which (among other things) lets us put it inside a loop and do it millions of times to do Y.&quot; A reviewer responded with &quot;I don&#x27;t understand what the point of doing X fast is if you&#x27;re just going to put it in a loop and make it slow again.&quot; He also asked us to run simulations to compare our method to another paper which was doing an unrelated thing Z. The editor agreed that we could ignore his comments.</div><br/></div></div></div></div><div id="42570855" class="c"><input type="checkbox" id="c-42570855" checked=""/><div class="controls bullet"><span class="by">Metacelsus</span><span>|</span><a href="#42568971">parent</a><span>|</span><a href="#42569093">prev</a><span>|</span><a href="#42571155">next</a><span>|</span><label class="collapse" for="c-42570855">[-]</label><label class="expand" for="c-42570855">[1 more]</label></div><br/><div class="children"><div class="content">I, as a reviewer, made a similar mistake once! The author&#x27;s initial version seemed to contradict one of their earlier papers but I was missing some context.</div><br/></div></div><div id="42571155" class="c"><input type="checkbox" id="c-42571155" checked=""/><div class="controls bullet"><span class="by">Cheer2171</span><span>|</span><a href="#42568971">parent</a><span>|</span><a href="#42570855">prev</a><span>|</span><a href="#42569108">next</a><span>|</span><label class="collapse" for="c-42571155">[-]</label><label class="expand" for="c-42571155">[2 more]</label></div><br/><div class="children"><div class="content">Fair warning: I don&#x27;t know enough about mathematics to say if this is the case here.<p>I hear this all the time, but this is actually a real phenomenon that happens when well-known senior figures are rightfully cautious about over-citing their own work and&#x2F;or are just so familiar with their own work that they don&#x27;t include much of it in their literature review. For everybody else in the field, it&#x27;s obvious that the work of famous person X should make up a substantial chunk of the lit review and be explicit about how the new work builds on X&#x27;s prior literally paradigm shifting work. You can do a bad job at writing about your own past work for a given audience for so many different reasons, and many senior academics do all the time, making their work literally indistinguishable from that of graduate students --- hence the rejection.</div><br/><div id="42571168" class="c"><input type="checkbox" id="c-42571168" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568971">root</a><span>|</span><a href="#42571155">parent</a><span>|</span><a href="#42569108">next</a><span>|</span><label class="collapse" for="c-42571168">[-]</label><label class="expand" for="c-42571168">[1 more]</label></div><br/><div class="children"><div class="content">I totally understand the case when an author doesn&#x27;t sufficiently give context because they are so close to their previous work that they take it for granted that it&#x27;s obvious (or, like you said, they are wary of auto-citation).<p>I may be misremembering, but I believe the case with Grant was that the referee was using his own work to discredit his submission. Ie &quot;If the author was aware of the work of Adam Grant, they would understand why the submitted work is wrong.&quot;</div><br/></div></div></div></div><div id="42569108" class="c"><input type="checkbox" id="c-42569108" checked=""/><div class="controls bullet"><span class="by">Nevermark</span><span>|</span><a href="#42568971">parent</a><span>|</span><a href="#42571155">prev</a><span>|</span><a href="#42568592">next</a><span>|</span><label class="collapse" for="c-42569108">[-]</label><label class="expand" for="c-42569108">[1 more]</label></div><br/><div class="children"><div class="content">Yes, funny the first time.<p>Not so much the fifth!</div><br/></div></div></div></div><div id="42568592" class="c"><input type="checkbox" id="c-42568592" checked=""/><div class="controls bullet"><span class="by">remoquete</span><span>|</span><a href="#42568971">prev</a><span>|</span><a href="#42568776">next</a><span>|</span><label class="collapse" for="c-42568592">[-]</label><label class="expand" for="c-42568592">[3 more]</label></div><br/><div class="children"><div class="content">I find it refreshing when researchers disclose their own failures. Science is made of negative results, errors, and rejections, though it&#x27;s often characterized in a much different, unrealistic way.<p>By the way, even though some of you may know about it, here&#x27;s the link to the Journal of Negative Results: <a href="https:&#x2F;&#x2F;www.jnr-eeb.org&#x2F;index.php&#x2F;jnr" rel="nofollow">https:&#x2F;&#x2F;www.jnr-eeb.org&#x2F;index.php&#x2F;jnr</a></div><br/></div></div><div id="42568776" class="c"><input type="checkbox" id="c-42568776" checked=""/><div class="controls bullet"><span class="by">UniverseHacker</span><span>|</span><a href="#42568592">prev</a><span>|</span><a href="#42569115">next</a><span>|</span><label class="collapse" for="c-42568776">[-]</label><label class="expand" for="c-42568776">[7 more]</label></div><br/><div class="children"><div class="content">I am actually quite surprised Terence Tao still gets papers rejected from math journals... but appreciate him sharing this, as hearing this from him will help newer scientists not get discouraged by a rejection.<p>I had the lucky opportunity to do a postdoc with one of the most famous people in my field, and I was shocked how much difference the name did make- I never had a paper rejection from top tier journals submitting with him as the corresponding author. I am fairly certain the editors would have rejected my work for not being fundamentally on an interesting enough topic to them, if not for the name. The fact that a big name is interested in something, alone can make it a &quot;high impact subject.&quot;</div><br/><div id="42569026" class="c"><input type="checkbox" id="c-42569026" checked=""/><div class="controls bullet"><span class="by">vouaobrasil</span><span>|</span><a href="#42568776">parent</a><span>|</span><a href="#42569831">next</a><span>|</span><label class="collapse" for="c-42569026">[-]</label><label class="expand" for="c-42569026">[4 more]</label></div><br/><div class="children"><div class="content">&gt; I am actually quite surprised Terence Tao still gets papers rejected from math journals<p>At least it indicates that the system is working somewhat properly some of the time...</div><br/><div id="42570013" class="c"><input type="checkbox" id="c-42570013" checked=""/><div class="controls bullet"><span class="by">scubbo</span><span>|</span><a href="#42568776">root</a><span>|</span><a href="#42569026">parent</a><span>|</span><a href="#42569831">next</a><span>|</span><label class="collapse" for="c-42570013">[-]</label><label class="expand" for="c-42570013">[3 more]</label></div><br/><div class="children"><div class="content">Could you elaborate on this statement? It sounds like you&#x27;re implying something, but it&#x27;s not clear what.</div><br/><div id="42570082" class="c"><input type="checkbox" id="c-42570082" checked=""/><div class="controls bullet"><span class="by">monktastic1</span><span>|</span><a href="#42568776">root</a><span>|</span><a href="#42570013">parent</a><span>|</span><a href="#42570098">next</a><span>|</span><label class="collapse" for="c-42570082">[-]</label><label class="expand" for="c-42570082">[1 more]</label></div><br/><div class="children"><div class="content">I interpret it as saying that at least the system hasn&#x27;t just degraded into a rubber stamp (where someone like Tao can publish anything on name alone).</div><br/></div></div><div id="42570098" class="c"><input type="checkbox" id="c-42570098" checked=""/><div class="controls bullet"><span class="by">TN1ck</span><span>|</span><a href="#42568776">root</a><span>|</span><a href="#42570013">parent</a><span>|</span><a href="#42570082">prev</a><span>|</span><a href="#42569831">next</a><span>|</span><label class="collapse" for="c-42570098">[-]</label><label class="expand" for="c-42570098">[1 more]</label></div><br/><div class="children"><div class="content">I think it’s that a paper submitted by one of the most famous authors in the math field is not auto approved by the journals. That even he has to go through the normal process and gets rejected at times.</div><br/></div></div></div></div></div></div><div id="42569831" class="c"><input type="checkbox" id="c-42569831" checked=""/><div class="controls bullet"><span class="by">jcrites</span><span>|</span><a href="#42568776">parent</a><span>|</span><a href="#42569026">prev</a><span>|</span><a href="#42569115">next</a><span>|</span><label class="collapse" for="c-42569831">[-]</label><label class="expand" for="c-42569831">[2 more]</label></div><br/><div class="children"><div class="content">Could that also be because he reviewed the papers first and made sure they were in a suitable state to publish? Or you think it really was just the name alone, and if you had published without him they would not have been accepted?</div><br/><div id="42570196" class="c"><input type="checkbox" id="c-42570196" checked=""/><div class="controls bullet"><span class="by">UniverseHacker</span><span>|</span><a href="#42568776">root</a><span>|</span><a href="#42569831">parent</a><span>|</span><a href="#42569115">next</a><span>|</span><label class="collapse" for="c-42570196">[-]</label><label class="expand" for="c-42570196">[1 more]</label></div><br/><div class="children"><div class="content">He only skimmed them- scientists at his level are more like a CEO than the stereotype of a scientist- with multiple large labs, startups, and speaking engagements every few days. He trusted me to make sure the papers were good- and they were, but his name made the difference between getting into a good journal in the field, and a top “high impact” journal that usually does not consider the topic area popular enough to accept papers on, regardless of the quality or content of the paper. At some level, high impact journals are a popularity contest- to maintain the high citation rate, they only publish from people in large popular fields, as having more peers means more citations.</div><br/></div></div></div></div></div></div><div id="42569115" class="c"><input type="checkbox" id="c-42569115" checked=""/><div class="controls bullet"><span class="by">TZubiri</span><span>|</span><a href="#42568776">prev</a><span>|</span><a href="#42568732">next</a><span>|</span><label class="collapse" for="c-42569115">[-]</label><label class="expand" for="c-42569115">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Rejection is actually a relatively common occurrence for me, happening once or twice a year on average.&quot;<p>This feels like a superhuman trying to empathize with a regular person.</div><br/></div></div><div id="42568732" class="c"><input type="checkbox" id="c-42568732" checked=""/><div class="controls bullet"><span class="by">asah</span><span>|</span><a href="#42569115">prev</a><span>|</span><a href="#42569176">next</a><span>|</span><label class="collapse" for="c-42568732">[-]</label><label class="expand" for="c-42568732">[1 more]</label></div><br/><div class="children"><div class="content">Non-zero failure rate is indeed often optimal because it provides valuable feedback toward finding the optimal horizon for various metrics, e.g. speed, quality, LPU[1], etc.<p>That said, given the labor involved in academic publishing and review, the optimal rejection rate should be quite low, i.e. find a lower cost way to pre-filter papers. OTOH, the reviewers may get value from rejected papers...<p>[1] least publishable unit</div><br/></div></div><div id="42569176" class="c"><input type="checkbox" id="c-42569176" checked=""/><div class="controls bullet"><span class="by">ndesaulniers</span><span>|</span><a href="#42568732">prev</a><span>|</span><a href="#42572825">next</a><span>|</span><label class="collapse" for="c-42569176">[-]</label><label class="expand" for="c-42569176">[1 more]</label></div><br/><div class="children"><div class="content">The master has failed more than the beginner has tried.</div><br/></div></div><div id="42572825" class="c"><input type="checkbox" id="c-42572825" checked=""/><div class="controls bullet"><span class="by">SergeAx</span><span>|</span><a href="#42569176">prev</a><span>|</span><a href="#42572486">next</a><span>|</span><label class="collapse" for="c-42572825">[-]</label><label class="expand" for="c-42572825">[1 more]</label></div><br/><div class="children"><div class="content">We often talk about how important it is to be a platform for oneself, self-host blog under own domain etc. Why it is not the case for science papers, articles, issues? Like, isn&#x27;t the whole World Wide Web was invented specifically for that?</div><br/></div></div><div id="42572486" class="c"><input type="checkbox" id="c-42572486" checked=""/><div class="controls bullet"><span class="by">iamnotsure</span><span>|</span><a href="#42572825">prev</a><span>|</span><a href="#42572501">next</a><span>|</span><label class="collapse" for="c-42572486">[-]</label><label class="expand" for="c-42572486">[1 more]</label></div><br/><div class="children"><div class="content">Please note that despite much work being done in the equality department being famous is nowadays still a requirement for acquiring the status of impostor syndrome achiever. Persons who are not really famous do not have impostor syndrome but are just a simple copycats in this respect.</div><br/></div></div><div id="42572501" class="c"><input type="checkbox" id="c-42572501" checked=""/><div class="controls bullet"><span class="by">j7ake</span><span>|</span><a href="#42572486">prev</a><span>|</span><a href="#42570164">next</a><span>|</span><label class="collapse" for="c-42572501">[-]</label><label class="expand" for="c-42572501">[1 more]</label></div><br/><div class="children"><div class="content">We can laugh at academia but we know of these similar rejection stories nearly in all domains.<p>AirBnB being rejected for funding, musicians like Schubert struggling their entire life, writers like Rowling in poverty.<p>Rejection will always be the norm in competitive winner take all dynamics.</div><br/></div></div><div id="42570164" class="c"><input type="checkbox" id="c-42570164" checked=""/><div class="controls bullet"><span class="by">kittikitti</span><span>|</span><a href="#42572501">prev</a><span>|</span><a href="#42569344">next</a><span>|</span><label class="collapse" for="c-42570164">[-]</label><label class="expand" for="c-42570164">[2 more]</label></div><br/><div class="children"><div class="content">Academia is a paper tiger. The Internet means you don&#x27;t need a publisher for your work. Ironically, this self published blog might be one of his most read works yet.</div><br/><div id="42570717" class="c"><input type="checkbox" id="c-42570717" checked=""/><div class="controls bullet"><span class="by">snowwrestler</span><span>|</span><a href="#42570164">parent</a><span>|</span><a href="#42569344">next</a><span>|</span><label class="collapse" for="c-42570717">[-]</label><label class="expand" for="c-42570717">[1 more]</label></div><br/><div class="children"><div class="content">You never needed a publisher; before the Internet you could write up your findings and mail them to relevant people in your field. Quite a lot of scientists did this, actually.<p>What publication in a journal gives you is context, social proof, and structured placement in public archives like libraries. This remains true in the age of the Internet.</div><br/></div></div></div></div><div id="42569344" class="c"><input type="checkbox" id="c-42569344" checked=""/><div class="controls bullet"><span class="by">tetha</span><span>|</span><a href="#42570164">prev</a><span>|</span><a href="#42568647">next</a><span>|</span><label class="collapse" for="c-42569344">[-]</label><label class="expand" for="c-42569344">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Because of this, a perception can be created that all of one&#x27;s peers are achieving either success or controversy, with one&#x27;s own personal career ending up becoming the only known source of examples of &quot;mundane&quot; failure.<p>I&#x27;ve found similar insights when I joined a community of musicians and also discovered twitch &#x2F; youtube presences of musicians I listen to. Some of Dragonforces corona streams are absolutely worth a watch.<p>It&#x27;s easy to listen to mixed and finished albums and... despair to a degree. How could anyone learn to become that good? It must be impossible, giving up seems the only rational choice.<p>But in reality, people struggle and fumble along at their level. Sure enough, the level of someone playing guitar professionally for 20 years is a tad higher than mine, but that really, really perfect album take? That&#x27;s the one take out of a couple dozen.<p>This really helped me &quot;ground&quot; or &quot;calibrate&quot; my sense of how good or how bad I am and gave me a better appreciation of how much of a marathon an instrument can be.</div><br/></div></div><div id="42568647" class="c"><input type="checkbox" id="c-42568647" checked=""/><div class="controls bullet"><span class="by">amichail</span><span>|</span><a href="#42569344">prev</a><span>|</span><a href="#42568919">next</a><span>|</span><label class="collapse" for="c-42568647">[-]</label><label class="expand" for="c-42568647">[1 more]</label></div><br/><div class="children"><div class="content">Sure, even top mathematicians have paper rejections.<p>But I think the more important point is that very few people are capable of publishing papers in top math journals.</div><br/></div></div><div id="42568854" class="c"><input type="checkbox" id="c-42568854" checked=""/><div class="controls bullet"><span class="by">atrettel</span><span>|</span><a href="#42568919">prev</a><span>|</span><a href="#42569876">next</a><span>|</span><label class="collapse" for="c-42568854">[-]</label><label class="expand" for="c-42568854">[5 more]</label></div><br/><div class="children"><div class="content">I agree with the discussion that rejection is normal and researchers should discuss it more often.<p>That said, I do think that &quot;publish or perish&quot; plays an unspoken role here.  I see a lot of colleagues trying to push out &quot;least publishable units&quot; that might barely pass review (by definition).  If you need to juice your metrics, it&#x27;s a common strategy that people employ.  Still, I think a lot of papers would pass peer review more easily if researchers just combined multiple results into a single longer paper.  I find those papers to be easier to read since they require less boilerplate, and I imagine they would be easier to pass peer review by the virtue that they simply contain more significant results.</div><br/><div id="42569249" class="c"><input type="checkbox" id="c-42569249" checked=""/><div class="controls bullet"><span class="by">nextn</span><span>|</span><a href="#42568854">parent</a><span>|</span><a href="#42569980">next</a><span>|</span><label class="collapse" for="c-42569249">[-]</label><label class="expand" for="c-42569249">[3 more]</label></div><br/><div class="children"><div class="content">Longer papers with more claims have more to prove, not less. I imagine they would be harder to pass peer review.</div><br/><div id="42570441" class="c"><input type="checkbox" id="c-42570441" checked=""/><div class="controls bullet"><span class="by">atrettel</span><span>|</span><a href="#42568854">root</a><span>|</span><a href="#42569249">parent</a><span>|</span><a href="#42569548">next</a><span>|</span><label class="collapse" for="c-42570441">[-]</label><label class="expand" for="c-42570441">[1 more]</label></div><br/><div class="children"><div class="content">I agree with your first part but not your second.  Most authors do not make outrageous claims, and I surely would reject their manuscript if they did.  I&#x27;ve done it before and will do it again without any issue.<p>To me, the point of peer review is to both evaluate the science&#x2F;correctness of the work, but also to ensure that this is something novel that is worth telling others about.  Does the manuscript introduce something novel into the literature?  That is my standard (and the standard that I was taught).  I typically look for at least one of three things: new theory, new data&#x2F;experiments, or an extensive review and summation of existing work.  The more results the manuscript has, the more likely it is to meet this novelty requirement.</div><br/></div></div><div id="42569548" class="c"><input type="checkbox" id="c-42569548" checked=""/><div class="controls bullet"><span class="by">tredre3</span><span>|</span><a href="#42568854">root</a><span>|</span><a href="#42569249">parent</a><span>|</span><a href="#42570441">prev</a><span>|</span><a href="#42569980">next</a><span>|</span><label class="collapse" for="c-42569548">[-]</label><label class="expand" for="c-42569548">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Longer papers with more claims have more to prove, not less. I imagine they would be harder to pass peer review.<p>Yes, a longer paper puts more work on the peer reviewers (handful of people). But splitting one project in multiple papers puts more work on the reader (thousands of people). There is a balance to strike.</div><br/></div></div></div></div><div id="42569980" class="c"><input type="checkbox" id="c-42569980" checked=""/><div class="controls bullet"><span class="by">paulpauper</span><span>|</span><a href="#42568854">parent</a><span>|</span><a href="#42569249">prev</a><span>|</span><a href="#42569876">next</a><span>|</span><label class="collapse" for="c-42569980">[-]</label><label class="expand" for="c-42569980">[1 more]</label></div><br/><div class="children"><div class="content">Lots of co-authors. That is one surefire way to inflate it.</div><br/></div></div></div></div><div id="42569876" class="c"><input type="checkbox" id="c-42569876" checked=""/><div class="controls bullet"><span class="by">kzz102</span><span>|</span><a href="#42568854">prev</a><span>|</span><a href="#42568935">next</a><span>|</span><label class="collapse" for="c-42569876">[-]</label><label class="expand" for="c-42569876">[2 more]</label></div><br/><div class="children"><div class="content">In academic publishing, there is an implicit agreement between the authors and the journal to roughly match the importance of the paper to the prestige of the journal. Since there is no universal standard on either the prestige of the journal or the importance of the paper, mismatches happen regularly, and rejection is the natural result. In fact, the only way to avoid rejections is to submit a paper to a journal of lower prestige than your estimate, which is clearly not what authors want to do.</div><br/><div id="42572065" class="c"><input type="checkbox" id="c-42572065" checked=""/><div class="controls bullet"><span class="by">directevolve</span><span>|</span><a href="#42569876">parent</a><span>|</span><a href="#42568935">next</a><span>|</span><label class="collapse" for="c-42572065">[-]</label><label class="expand" for="c-42572065">[1 more]</label></div><br/><div class="children"><div class="content">It’s not an accident - if academics underestimated the quality of their own work or overestimated that of the journal, this would increase acceptance rates.<p>Authors start at an attainable stretch goal, hope for a quick rejection if that’s the outcome, and work their way down the list. That’s why rejection is inevitable.</div><br/></div></div></div></div><div id="42568935" class="c"><input type="checkbox" id="c-42568935" checked=""/><div class="controls bullet"><span class="by">ak_111</span><span>|</span><a href="#42569876">prev</a><span>|</span><a href="#42569132">next</a><span>|</span><label class="collapse" for="c-42568935">[-]</label><label class="expand" for="c-42568935">[1 more]</label></div><br/><div class="children"><div class="content">I always thought that part of the upside of being tenured and extremely recognised as a leader of your field is the freedom to submit to incredibly obscure (non-predatory) journals just for fun.</div><br/></div></div><div id="42569132" class="c"><input type="checkbox" id="c-42569132" checked=""/><div class="controls bullet"><span class="by">ziofill</span><span>|</span><a href="#42568935">prev</a><span>|</span><a href="#42568849">next</a><span>|</span><label class="collapse" for="c-42569132">[-]</label><label class="expand" for="c-42569132">[1 more]</label></div><br/><div class="children"><div class="content">This is his main point, and I wholeheartedly agree: <i>…a perception can be created that all of one&#x27;s peers are achieving either success or controversy, with one&#x27;s own personal career ending up becoming the only known source of examples of &quot;mundane&quot; failure.  I speculate that this may be a contributor to the &quot;impostor syndrome&quot;…</i></div><br/></div></div><div id="42568849" class="c"><input type="checkbox" id="c-42568849" checked=""/><div class="controls bullet"><span class="by">aborsy</span><span>|</span><a href="#42569132">prev</a><span>|</span><a href="#42569755">next</a><span>|</span><label class="collapse" for="c-42568849">[-]</label><label class="expand" for="c-42568849">[1 more]</label></div><br/><div class="children"><div class="content">Research is getting more and more specialized. Increasingly there may not be many potential journals for a paper, and, even if there are, the paper might be sent to the same reviewers (small sub communities).<p>You may have to leave a year of work on arxiv, with the expectation that the work will be rehashed and used in other published papers.</div><br/></div></div><div id="42569755" class="c"><input type="checkbox" id="c-42569755" checked=""/><div class="controls bullet"><span class="by">slackr</span><span>|</span><a href="#42568849">prev</a><span>|</span><a href="#42569654">next</a><span>|</span><label class="collapse" for="c-42569755">[-]</label><label class="expand" for="c-42569755">[4 more]</label></div><br/><div class="children"><div class="content">Reminds me—I wish someone would make an anti-LinkedIn, where the norm is to announce only setbacks and mistakes, disappointments etc.</div><br/><div id="42570003" class="c"><input type="checkbox" id="c-42570003" checked=""/><div class="controls bullet"><span class="by">omoikane</span><span>|</span><a href="#42569755">parent</a><span>|</span><a href="#42569810">next</a><span>|</span><label class="collapse" for="c-42570003">[-]</label><label class="expand" for="c-42570003">[1 more]</label></div><br/><div class="children"><div class="content">There was a site where people posted company failures:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fucked_Company" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fucked_Company</a></div><br/></div></div><div id="42569810" class="c"><input type="checkbox" id="c-42569810" checked=""/><div class="controls bullet"><span class="by">remoquete</span><span>|</span><a href="#42569755">parent</a><span>|</span><a href="#42570003">prev</a><span>|</span><a href="#42571089">next</a><span>|</span><label class="collapse" for="c-42569810">[-]</label><label class="expand" for="c-42569810">[1 more]</label></div><br/><div class="children"><div class="content">Folks already do. They often turn them into inspirational tales.</div><br/></div></div><div id="42571089" class="c"><input type="checkbox" id="c-42571089" checked=""/><div class="controls bullet"><span class="by">77pt77</span><span>|</span><a href="#42569755">parent</a><span>|</span><a href="#42569810">prev</a><span>|</span><a href="#42569654">next</a><span>|</span><label class="collapse" for="c-42571089">[-]</label><label class="expand" for="c-42571089">[1 more]</label></div><br/><div class="children"><div class="content">Just like in academia, no one cares about negative results in professional settings.</div><br/></div></div></div></div><div id="42569654" class="c"><input type="checkbox" id="c-42569654" checked=""/><div class="controls bullet"><span class="by">justinl33</span><span>|</span><a href="#42569755">prev</a><span>|</span><a href="#42568865">next</a><span>|</span><label class="collapse" for="c-42569654">[-]</label><label class="expand" for="c-42569654">[1 more]</label></div><br/><div class="children"><div class="content">It’s okay Terence, it happens to the best of us.</div><br/></div></div><div id="42568865" class="c"><input type="checkbox" id="c-42568865" checked=""/><div class="controls bullet"><span class="by">ak_111</span><span>|</span><a href="#42569654">prev</a><span>|</span><a href="#42568937">next</a><span>|</span><label class="collapse" for="c-42568865">[-]</label><label class="expand" for="c-42568865">[2 more]</label></div><br/><div class="children"><div class="content">- hey honey how was work today?<p>- it was fine, I desk rejected terence tao, his result was a bit meh and the write up wasn&#x27;t up to my standard. Then I had a bit of a quite office hour, anyway, ...</div><br/><div id="42569198" class="c"><input type="checkbox" id="c-42569198" checked=""/><div class="controls bullet"><span class="by">Der_Einzige</span><span>|</span><a href="#42568865">parent</a><span>|</span><a href="#42568937">next</a><span>|</span><label class="collapse" for="c-42569198">[-]</label><label class="expand" for="c-42569198">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve had the surreal moment of attending a workshop where the main presenter (famous) is talking about their soon to-be-published work where I realize that I&#x27;m one of their reviewers (months after I wrote the review, so no impact on my score). In this case, I loved their paper and gave it high marks, and so did the other reviewers. Not surprising when I found out who the author was!!!<p>I have to not say a word to them as I talk to them or else I could ruin the whole peer review thing!<p>&quot;Hey honey, I reviewed X work from Y famous person today&quot;</div><br/></div></div></div></div><div id="42568937" class="c"><input type="checkbox" id="c-42568937" checked=""/><div class="controls bullet"><span class="by">d0mine</span><span>|</span><a href="#42568865">prev</a><span>|</span><a href="#42568873">next</a><span>|</span><label class="collapse" for="c-42568937">[-]</label><label class="expand" for="c-42568937">[4 more]</label></div><br/><div class="children"><div class="content">Why journals exist at all? Could papers be published on something like arxiv.org (like software is on github.com)?<p>It could support links&#x2F;backref, citations(forks), questions(discussions), tags, followers, etc easily.</div><br/><div id="42569009" class="c"><input type="checkbox" id="c-42569009" checked=""/><div class="controls bullet"><span class="by">bumby</span><span>|</span><a href="#42568937">parent</a><span>|</span><a href="#42569742">next</a><span>|</span><label class="collapse" for="c-42569009">[-]</label><label class="expand" for="c-42569009">[2 more]</label></div><br/><div class="children"><div class="content">Part of the idea is that journals help curate better publications via the peer review process. Whether or not that occurs in practice is up for some debate.<p>Having a curated list can be important to separate the wheat from the chaff, especially in an era with ever increasing rates of research papers.</div><br/><div id="42572733" class="c"><input type="checkbox" id="c-42572733" checked=""/><div class="controls bullet"><span class="by">d0mine</span><span>|</span><a href="#42568937">root</a><span>|</span><a href="#42569009">parent</a><span>|</span><a href="#42569742">next</a><span>|</span><label class="collapse" for="c-42572733">[-]</label><label class="expand" for="c-42572733">[1 more]</label></div><br/><div class="children"><div class="content">Eliminating journals as a corporate monopoly  doesn&#x27;t eliminate peer review. For example, it should be easy to show the number of citations and even their specific context in other articles on the arxiv-like site. For example, if I like some app&#x2F;library implementation on github, I look at their dependencies (a citation in a sense) to discover things to try.<p>Curated lists can also exist on the site. Look at awesome* repos on github eg <a href="https:&#x2F;&#x2F;github.com&#x2F;vinta&#x2F;awesome-python">https:&#x2F;&#x2F;github.com&#x2F;vinta&#x2F;awesome-python</a><p>Obviously, some lists can be better than the others. Usual social mechanics is adequate here.</div><br/></div></div></div></div><div id="42569742" class="c"><input type="checkbox" id="c-42569742" checked=""/><div class="controls bullet"><span class="by">sunshowers</span><span>|</span><a href="#42568937">parent</a><span>|</span><a href="#42569009">prev</a><span>|</span><a href="#42568873">next</a><span>|</span><label class="collapse" for="c-42569742">[-]</label><label class="expand" for="c-42569742">[1 more]</label></div><br/><div class="children"><div class="content">I think in math, and in many other fields, it is pretty normal to post all papers on arXiv. But arXiv has a lot of incorrect papers on it (tons of P vs NP papers for example), so journals are supposed to act as a filtering mechanism. How well they succeed at it is debated.</div><br/></div></div></div></div><div id="42568873" class="c"><input type="checkbox" id="c-42568873" checked=""/><div class="controls bullet"><span class="by">haunter</span><span>|</span><a href="#42568937">prev</a><span>|</span><a href="#42568722">next</a><span>|</span><label class="collapse" for="c-42568873">[-]</label><label class="expand" for="c-42568873">[1 more]</label></div><br/><div class="children"><div class="content">fwiw, editorial review =&#x2F;= peer review</div><br/></div></div><div id="42568722" class="c"><input type="checkbox" id="c-42568722" checked=""/><div class="controls bullet"><span class="by">abetusk</span><span>|</span><a href="#42568873">prev</a><span>|</span><a href="#42569374">next</a><span>|</span><label class="collapse" for="c-42568722">[-]</label><label class="expand" for="c-42568722">[3 more]</label></div><br/><div class="children"><div class="content">The second post in that thread is gold:<p>&quot;&quot;&quot;<p>... I once almost solved a conjecture, establishing the result with an &quot;epsilon loss&quot; in a key parameter.  We submitted to a highly reputable journal, but it was rejected on the grounds that it did not resolve the full conjecture.  So we submitted elsewhere, and the paper was accepted.<p>The following year, we managed to finally prove the full conjecture without the epsilon loss, and decided to try submitting to the highly reputable journal again.  This time, the paper was rejected for only being an epsilon improvement over the previous literature!<p>...<p>&quot;&quot;&quot;</div><br/><div id="42568777" class="c"><input type="checkbox" id="c-42568777" checked=""/><div class="controls bullet"><span class="by">YouWhy</span><span>|</span><a href="#42568722">parent</a><span>|</span><a href="#42569374">next</a><span>|</span><label class="collapse" for="c-42568777">[-]</label><label class="expand" for="c-42568777">[2 more]</label></div><br/><div class="children"><div class="content">While I&#x27;m not a mathematician, I think such an attitude on behalf of the journal does not encourage healthy community dynamics.<p>Instead of allowing the community to join forces by breaking up a larger problem into pieces, it encourages siloing and camper mentality.</div><br/><div id="42568830" class="c"><input type="checkbox" id="c-42568830" checked=""/><div class="controls bullet"><span class="by">abetusk</span><span>|</span><a href="#42568722">root</a><span>|</span><a href="#42568777">parent</a><span>|</span><a href="#42569374">next</a><span>|</span><label class="collapse" for="c-42568830">[-]</label><label class="expand" for="c-42568830">[1 more]</label></div><br/><div class="children"><div class="content">I agree. This is also a lack of effort on the journal&#x27;s part to set expectations of what the reviewers should be looking for in an accepted paper.<p>In the journal&#x27;s defense though, what most likely happened is that the reviewers were different between submissions and they didn&#x27;t know about the context. Ultimately, I think, this type of rejection comes down to the mostly the reviewers discretion and it can lead to this type of situation.<p>I cut off the rest of the post but Tao finished it with this:<p>&quot;&quot;&quot;<p>... Being an editor myself, and having had to decline some decent submissions for a variety of reasons, I find it best not to take these sorts of rejections personally,<p>...<p>&quot;&quot;&quot;</div><br/></div></div></div></div></div></div><div id="42569374" class="c"><input type="checkbox" id="c-42569374" checked=""/><div class="controls bullet"><span class="by">cess11</span><span>|</span><a href="#42568722">prev</a><span>|</span><a href="#42570413">next</a><span>|</span><label class="collapse" for="c-42569374">[-]</label><label class="expand" for="c-42569374">[1 more]</label></div><br/><div class="children"><div class="content">Journals are typically for-profit, and science is not, so they don&#x27;t always align and we should not expect journals to serve science except incidentally.</div><br/></div></div><div id="42570413" class="c"><input type="checkbox" id="c-42570413" checked=""/><div class="controls bullet"><span class="by">kizer</span><span>|</span><a href="#42569374">prev</a><span>|</span><a href="#42570244">next</a><span>|</span><label class="collapse" for="c-42570413">[-]</label><label class="expand" for="c-42570413">[1 more]</label></div><br/><div class="children"><div class="content">Whether it’s a journal, a university, a tech company… never take it personally because there’s bureaucracy, policies, etc and information lost in the operation of the whole process. Cast a wide net and believe in the value you’ve created or bring.</div><br/></div></div><div id="42570244" class="c"><input type="checkbox" id="c-42570244" checked=""/><div class="controls bullet"><span class="by">lupire</span><span>|</span><a href="#42570413">prev</a><span>|</span><label class="collapse" for="c-42570244">[-]</label><label class="expand" for="c-42570244">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s important to remember there a journal&#x27;s reputation is built by the authors who publish there, and not vice versa.</div><br/></div></div></div></div></div></div></div></body></html>