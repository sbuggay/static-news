<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1737968469769" as="style"/><link rel="stylesheet" href="styles.css?v=1737968469769"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://youtubetranscriptoptimizer.com/blog/05_the_short_case_for_nvda">The impact of competition and DeepSeek on Nvidia</a> <span class="domain">(<a href="https://youtubetranscriptoptimizer.com">youtubetranscriptoptimizer.com</a>)</span></div><div class="subtext"><span>eigenvalue</span> | <span>102 comments</span></div><br/><div><div id="42835560" class="c"><input type="checkbox" id="c-42835560" checked=""/><div class="controls bullet"><span class="by">breadwinner</span><span>|</span><a href="#42836422">next</a><span>|</span><label class="collapse" for="c-42835560">[-]</label><label class="expand" for="c-42835560">[39 more]</label></div><br/><div class="children"><div class="content">Great article but it seems to have a fatal flaw.<p>As pointed out in the article, Nvidia has several advantages including:<p><pre><code>   - Better Linux drivers than AMD
   - CUDA
   - pytorch is optimized for Nvidia
   - High-speed interconnect
</code></pre>
Each of the advantages is under attack:<p><pre><code>   - George Hotz is making better drivers for AMD
   - MLX, Triton, JAX: Higher level abstractions that compile down to CUDA
   - Cerbras and Groq solve the interconnect problem
</code></pre>
The article concludes that NVIDIA faces an unprecedented convergence of competitive threats. The flaw in the analysis is that these threats are not unified. Any serious competitor must address ALL of Nvidia&#x27;s advantages. Instead Nvidia is being attacked by multiple disconnected competitors, and each of those competitors is only attacking one Nvidia advantage at a time. Even if each of those attacks are individually successful, Nvidia will remain the only company that has ALL of the advantages.</div><br/><div id="42838743" class="c"><input type="checkbox" id="c-42838743" checked=""/><div class="controls bullet"><span class="by">epolanski</span><span>|</span><a href="#42835560">parent</a><span>|</span><a href="#42835894">next</a><span>|</span><label class="collapse" for="c-42838743">[-]</label><label class="expand" for="c-42838743">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Any serious competitor must address ALL of Nvidia&#x27;s advantages.<p>Not really, his article focuses on Nvidia&#x27;s being valued so highly by stock markets, he&#x27;s not saying that Nvidia&#x27;s destined to lose its advantage in the space in the short term.<p>In any case, I also think that the likes of MSFT&#x2F;AMZN&#x2F;etc will be able to reduce their capex spending eventually by being able to work on a well integrated stack on their own.</div><br/></div></div><div id="42835894" class="c"><input type="checkbox" id="c-42835894" checked=""/><div class="controls bullet"><span class="by">Herring</span><span>|</span><a href="#42835560">parent</a><span>|</span><a href="#42838743">prev</a><span>|</span><a href="#42835819">next</a><span>|</span><label class="collapse" for="c-42835894">[-]</label><label class="expand" for="c-42835894">[18 more]</label></div><br/><div class="children"><div class="content">He&#x27;s setting up a case for shorting the stock, ie if the growth or margins drop a little from any of these (often well-funded) threats. The accuracy of the article is a function of the current valuation.</div><br/><div id="42835956" class="c"><input type="checkbox" id="c-42835956" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835894">parent</a><span>|</span><a href="#42835819">next</a><span>|</span><label class="collapse" for="c-42835956">[-]</label><label class="expand" for="c-42835956">[17 more]</label></div><br/><div class="children"><div class="content">Exactly. You just need to see a slight deceleration in projected revenue growth (which has been running 120%+ YoY recently) and some downward pressure on gross margins, and maybe even just some market share loss, and the stock could easily fall 25% from that.</div><br/><div id="42835970" class="c"><input type="checkbox" id="c-42835970" checked=""/><div class="controls bullet"><span class="by">breadwinner</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835956">parent</a><span>|</span><a href="#42837598">next</a><span>|</span><label class="collapse" for="c-42835970">[-]</label><label class="expand" for="c-42835970">[15 more]</label></div><br/><div class="children"><div class="content">AMD P&#x2F;E ratio is 109, NVDA is 56. Which stock is overvalued?</div><br/><div id="42836359" class="c"><input type="checkbox" id="c-42836359" checked=""/><div class="controls bullet"><span class="by">daveguy</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835970">parent</a><span>|</span><a href="#42836546">next</a><span>|</span><label class="collapse" for="c-42836359">[-]</label><label class="expand" for="c-42836359">[8 more]</label></div><br/><div class="children"><div class="content">That is extraordinarily simplistic. If NVDA is slowing and AMD has gains to realize compared to NVDA, then the 10x difference in market cap would imply that AMD is the better buy. Which is why I am long in AMD. You can&#x27;t just look at the current P&#x2F;E delta. You have to look at expectations of one vs the other. AMD gaining 2x over NVDA means they are approximately equivalently valued. If there are unrealized AI related gains all bets are off. AMD closing 50% of the gap in market cap value between NVDA and AMD means AMD is ~2.5x undervalued.<p>Disclaimer: long AMD, and not precise on percentages. Just illustrating a point.</div><br/><div id="42836506" class="c"><input type="checkbox" id="c-42836506" checked=""/><div class="controls bullet"><span class="by">flowerlad</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836359">parent</a><span>|</span><a href="#42836969">next</a><span>|</span><label class="collapse" for="c-42836506">[-]</label><label class="expand" for="c-42836506">[5 more]</label></div><br/><div class="children"><div class="content">The point is, it should not be taken for granted that NVDA is overvalued. Their P&#x2F;E is low enough that if you’re going to state that they are overvalued you have to make the case. The  article while well written, fails to make the case because it has a flaw: it assumes that addressing just one of Nvidia’s advantages is enough to make it crash and that’s just not true.</div><br/><div id="42836549" class="c"><input type="checkbox" id="c-42836549" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836506">parent</a><span>|</span><a href="#42836969">next</a><span>|</span><label class="collapse" for="c-42836549">[-]</label><label class="expand" for="c-42836549">[4 more]</label></div><br/><div class="children"><div class="content">If investing were as simple as looking at the P&#x2F;E, all P&#x2F;Es would already be at 15-20, wouldn&#x27;t they?</div><br/><div id="42836634" class="c"><input type="checkbox" id="c-42836634" checked=""/><div class="controls bullet"><span class="by">flowerlad</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836549">parent</a><span>|</span><a href="#42836969">next</a><span>|</span><label class="collapse" for="c-42836634">[-]</label><label class="expand" for="c-42836634">[3 more]</label></div><br/><div class="children"><div class="content">Not saying it is as simple as looking at P&#x2F;E</div><br/><div id="42836775" class="c"><input type="checkbox" id="c-42836775" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836634">parent</a><span>|</span><a href="#42836969">next</a><span>|</span><label class="collapse" for="c-42836775">[-]</label><label class="expand" for="c-42836775">[2 more]</label></div><br/><div class="children"><div class="content">My point is that you have to make the case for <i>anything</i> being over&#x2F;undervalued. The null hypothesis is that the market has correctly valued it, after all.</div><br/><div id="42837259" class="c"><input type="checkbox" id="c-42837259" checked=""/><div class="controls bullet"><span class="by">omgwtfbyobbq</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836775">parent</a><span>|</span><a href="#42836969">next</a><span>|</span><label class="collapse" for="c-42837259">[-]</label><label class="expand" for="c-42837259">[1 more]</label></div><br/><div class="children"><div class="content">In the long run, probably yes, but a particular stock is less likely to be accurately value in the short run.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42836969" class="c"><input type="checkbox" id="c-42836969" checked=""/><div class="controls bullet"><span class="by">bdangubic</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836359">parent</a><span>|</span><a href="#42836506">prev</a><span>|</span><a href="#42836546">next</a><span>|</span><label class="collapse" for="c-42836969">[-]</label><label class="expand" for="c-42836969">[2 more]</label></div><br/><div class="children"><div class="content">glad you are not my financial adviser :)</div><br/></div></div></div></div><div id="42836546" class="c"><input type="checkbox" id="c-42836546" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835970">parent</a><span>|</span><a href="#42836359">prev</a><span>|</span><a href="#42838047">next</a><span>|</span><label class="collapse" for="c-42836546">[-]</label><label class="expand" for="c-42836546">[1 more]</label></div><br/><div class="children"><div class="content">On the other hand, getting a bigger slice of the existing cake as a smaller challenger can be easier than baking a bigger cake as the incumbent.</div><br/></div></div><div id="42838047" class="c"><input type="checkbox" id="c-42838047" checked=""/><div class="controls bullet"><span class="by">baq</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835970">parent</a><span>|</span><a href="#42836546">prev</a><span>|</span><a href="#42838173">next</a><span>|</span><label class="collapse" for="c-42838047">[-]</label><label class="expand" for="c-42838047">[1 more]</label></div><br/><div class="children"><div class="content">Hey let’s buy intel</div><br/></div></div><div id="42838173" class="c"><input type="checkbox" id="c-42838173" checked=""/><div class="controls bullet"><span class="by">dismalaf</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835970">parent</a><span>|</span><a href="#42838047">prev</a><span>|</span><a href="#42836093">next</a><span>|</span><label class="collapse" for="c-42838173">[-]</label><label class="expand" for="c-42838173">[1 more]</label></div><br/><div class="children"><div class="content">NVDA is valued at $3.5 trillion, which means investors think it will grow to around $1 trillion in yearly revenue. Current revenue is around $35 billion per quarter, so call it $140 billion yearly.  Investors are betting on a 7x increase in revenue.  Not impossible, sounds plausible but you need to assume AMD, INTC, GOOG, AMZN, and all the others who make GPUs&#x2F;TPUs either won&#x27;t take market share or the market will be worth multiple trillions per year.</div><br/></div></div><div id="42836093" class="c"><input type="checkbox" id="c-42836093" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835970">parent</a><span>|</span><a href="#42838173">prev</a><span>|</span><a href="#42836576">next</a><span>|</span><label class="collapse" for="c-42836093">[-]</label><label class="expand" for="c-42836093">[2 more]</label></div><br/><div class="children"><div class="content">If it were all so simple, they wouldn’t pay hedge fund analysts so much money…</div><br/><div id="42838529" class="c"><input type="checkbox" id="c-42838529" checked=""/><div class="controls bullet"><span class="by">pineaux</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836093">parent</a><span>|</span><a href="#42836576">next</a><span>|</span><label class="collapse" for="c-42838529">[-]</label><label class="expand" for="c-42838529">[1 more]</label></div><br/><div class="children"><div class="content">No thats not true. Hedge funds get paid so well because getting a small percentage of a big bag of money is still a big bag of money. This statement is more true the closer the big bag of money is to infinity.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="42835819" class="c"><input type="checkbox" id="c-42835819" checked=""/><div class="controls bullet"><span class="by">toisanji</span><span>|</span><a href="#42835560">parent</a><span>|</span><a href="#42835894">prev</a><span>|</span><a href="#42838294">next</a><span>|</span><label class="collapse" for="c-42835819">[-]</label><label class="expand" for="c-42835819">[8 more]</label></div><br/><div class="children"><div class="content">I want the NVIDIA monopoly to end, but there is no real competition still.
* George Hotz has basically given up on AMD: 
<a href="https:&#x2F;&#x2F;x.com&#x2F;__tinygrad__&#x2F;status&#x2F;1770151484363354195" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;__tinygrad__&#x2F;status&#x2F;1770151484363354195</a><p>* Groq can&#x27;t produce more hardware past their &quot;demo&quot;. It seems like they haven&#x27;t grown capacity in the years since they announced, and they switched to a complete SaaS model and don&#x27;t even sell hardware anymore.<p>* I dont know enough about MLX, Triton, and JAX,</div><br/><div id="42838503" class="c"><input type="checkbox" id="c-42838503" checked=""/><div class="controls bullet"><span class="by">bfung</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835819">parent</a><span>|</span><a href="#42836291">next</a><span>|</span><label class="collapse" for="c-42838503">[-]</label><label class="expand" for="c-42838503">[2 more]</label></div><br/><div class="children"><div class="content">It looks like he’s close to having own AMD stack, tweet linked in the article, Jan 15,2025: <a href="https:&#x2F;&#x2F;x.com&#x2F;__tinygrad__&#x2F;status&#x2F;1879615316378198516" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;__tinygrad__&#x2F;status&#x2F;1879615316378198516</a></div><br/><div id="42838903" class="c"><input type="checkbox" id="c-42838903" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42838503">parent</a><span>|</span><a href="#42836291">next</a><span>|</span><label class="collapse" for="c-42838903">[-]</label><label class="expand" for="c-42838903">[1 more]</label></div><br/><div class="children"><div class="content">$1000 bounty? That&#x27;s like 2 hours of development time at market rate lol</div><br/></div></div></div></div><div id="42836291" class="c"><input type="checkbox" id="c-42836291" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835819">parent</a><span>|</span><a href="#42838503">prev</a><span>|</span><a href="#42838294">next</a><span>|</span><label class="collapse" for="c-42836291">[-]</label><label class="expand" for="c-42836291">[5 more]</label></div><br/><div class="children"><div class="content">That George Hotz tweet is from March last year. He&#x27;s gone back and forth on AMD a bunch more times since then.</div><br/><div id="42836975" class="c"><input type="checkbox" id="c-42836975" checked=""/><div class="controls bullet"><span class="by">bdangubic</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836291">parent</a><span>|</span><a href="#42838294">next</a><span>|</span><label class="collapse" for="c-42836975">[-]</label><label class="expand" for="c-42836975">[4 more]</label></div><br/><div class="children"><div class="content">is that good or bad?</div><br/><div id="42838149" class="c"><input type="checkbox" id="c-42838149" checked=""/><div class="controls bullet"><span class="by">solarkraft</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836975">parent</a><span>|</span><a href="#42837354">next</a><span>|</span><label class="collapse" for="c-42838149">[-]</label><label class="expand" for="c-42838149">[1 more]</label></div><br/><div class="children"><div class="content">I consider it a good sign that he hasn’t completely given up. But it sure all seems shaky.</div><br/></div></div><div id="42837354" class="c"><input type="checkbox" id="c-42837354" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42836975">parent</a><span>|</span><a href="#42838149">prev</a><span>|</span><a href="#42838294">next</a><span>|</span><label class="collapse" for="c-42837354">[-]</label><label class="expand" for="c-42837354">[2 more]</label></div><br/><div class="children"><div class="content">Honestly I tried searching his recent tweets for AMD and there was way too much noise in there to figure out his current position!</div><br/><div id="42838834" class="c"><input type="checkbox" id="c-42838834" checked=""/><div class="controls bullet"><span class="by">zby</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42837354">parent</a><span>|</span><a href="#42838294">next</a><span>|</span><label class="collapse" for="c-42838834">[-]</label><label class="expand" for="c-42838834">[1 more]</label></div><br/><div class="children"><div class="content">&quot; we are going to move it off AMD to our own or partner silicon. We have developed it to be very portable.&quot;<p><a href="https:&#x2F;&#x2F;x.com&#x2F;__tinygrad__&#x2F;status&#x2F;1879617702526087346" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;__tinygrad__&#x2F;status&#x2F;1879617702526087346</a></div><br/></div></div></div></div></div></div></div></div></div></div><div id="42838294" class="c"><input type="checkbox" id="c-42838294" checked=""/><div class="controls bullet"><span class="by">aorloff</span><span>|</span><a href="#42835560">parent</a><span>|</span><a href="#42835819">prev</a><span>|</span><a href="#42838417">next</a><span>|</span><label class="collapse" for="c-42838294">[-]</label><label class="expand" for="c-42838294">[1 more]</label></div><br/><div class="children"><div class="content">The unification of the flaws is the scarcity of H100s<p>He says this and talks about it in The Fallout section - even at BigCos with megabucks the teams are starved for time on the Nvidia chips and if these innovations work other teams will use them and then boom Nvidia&#x27;s moat is truncated somehow which doesn&#x27;t look good at such lofty multiples</div><br/></div></div><div id="42838417" class="c"><input type="checkbox" id="c-42838417" checked=""/><div class="controls bullet"><span class="by">isatty</span><span>|</span><a href="#42835560">parent</a><span>|</span><a href="#42838294">prev</a><span>|</span><a href="#42835938">next</a><span>|</span><label class="collapse" for="c-42838417">[-]</label><label class="expand" for="c-42838417">[4 more]</label></div><br/><div class="children"><div class="content">Sorry, I don’t know who George Hotz is, but why isn’t AMD making better drivers for AMD?</div><br/><div id="42838452" class="c"><input type="checkbox" id="c-42838452" checked=""/><div class="controls bullet"><span class="by">adastra22</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42838417">parent</a><span>|</span><a href="#42835938">next</a><span>|</span><label class="collapse" for="c-42838452">[-]</label><label class="expand" for="c-42838452">[3 more]</label></div><br/><div class="children"><div class="content">George Hotz is a hot Internet celebrity that has basically accomplished nothing of value but has a large cult following. You can safely ignore.<p>(Famous for hacking the PS3–except he just took credit for a separate group’s work. And for making a self-driving car in his garage—except oh wait that didn’t happen either.)</div><br/><div id="42838492" class="c"><input type="checkbox" id="c-42838492" checked=""/><div class="controls bullet"><span class="by">Den_VR</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42838452">parent</a><span>|</span><a href="#42838660">next</a><span>|</span><label class="collapse" for="c-42838492">[-]</label><label class="expand" for="c-42838492">[1 more]</label></div><br/><div class="children"><div class="content">You’re not wrong, but after all these years it’s fair to give benefit of the doubt - geohot may have grown as a person. The PS3 affair was incredibly disappointing.</div><br/></div></div><div id="42838660" class="c"><input type="checkbox" id="c-42838660" checked=""/><div class="controls bullet"><span class="by">xuki</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42838452">parent</a><span>|</span><a href="#42838492">prev</a><span>|</span><a href="#42835938">next</a><span>|</span><label class="collapse" for="c-42838660">[-]</label><label class="expand" for="c-42838660">[1 more]</label></div><br/><div class="children"><div class="content">He was famous before the PS3 hack, he was the first person to unlock the original iPhone.</div><br/></div></div></div></div></div></div><div id="42835938" class="c"><input type="checkbox" id="c-42835938" checked=""/><div class="controls bullet"><span class="by">dralley</span><span>|</span><a href="#42835560">parent</a><span>|</span><a href="#42838417">prev</a><span>|</span><a href="#42835983">next</a><span>|</span><label class="collapse" for="c-42835938">[-]</label><label class="expand" for="c-42835938">[2 more]</label></div><br/><div class="children"><div class="content">&gt;So how is this possible? Well, the main reasons have to do with software— better drivers that &quot;just work&quot; on Linux and which are highly battle-tested and reliable (unlike AMD, which is notorious for the low quality and instability of their Linux drivers)<p>This does not match my experience from the past ~6 years of using AMD graphics on Linux. Maybe things are different with AI&#x2F;Compute, I&#x27;ve never messed with that, but in terms of normal consumer stuff the experience of using AMD is vastly superior than trying to deal with Nvidia&#x27;s out-of-tree drivers.</div><br/><div id="42836103" class="c"><input type="checkbox" id="c-42836103" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835938">parent</a><span>|</span><a href="#42835983">next</a><span>|</span><label class="collapse" for="c-42836103">[-]</label><label class="expand" for="c-42836103">[1 more]</label></div><br/><div class="children"><div class="content">They are.</div><br/></div></div></div></div><div id="42835983" class="c"><input type="checkbox" id="c-42835983" checked=""/><div class="controls bullet"><span class="by">grajaganDev</span><span>|</span><a href="#42835560">parent</a><span>|</span><a href="#42835938">prev</a><span>|</span><a href="#42835975">next</a><span>|</span><label class="collapse" for="c-42835983">[-]</label><label class="expand" for="c-42835983">[2 more]</label></div><br/><div class="children"><div class="content">There is not enough water (to cool data centers) to justify NVDA&#x27;s current valuation.<p>The same is true of electricity - neither nuclear power nor fusion will not be online anytime soon.</div><br/><div id="42836718" class="c"><input type="checkbox" id="c-42836718" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835983">parent</a><span>|</span><a href="#42835975">next</a><span>|</span><label class="collapse" for="c-42836718">[-]</label><label class="expand" for="c-42836718">[1 more]</label></div><br/><div class="children"><div class="content">Those are definitely not the limiting factors here.<p>Not nearly all data centers are water cooled, and there is this amazing technology that can convert sunlight into electricity in a relatively straightforward way.<p>AI workloads (at least training) are just about as geographically distributeable as it gets due to not being very latency-sensitive, and even if you can&#x27;t obtain sufficient grid interconnection or buffer storage, you can always leave them idle at night.</div><br/></div></div></div></div><div id="42835975" class="c"><input type="checkbox" id="c-42835975" checked=""/><div class="controls bullet"><span class="by">thousand_nights</span><span>|</span><a href="#42835560">parent</a><span>|</span><a href="#42835983">prev</a><span>|</span><a href="#42836422">next</a><span>|</span><label class="collapse" for="c-42835975">[-]</label><label class="expand" for="c-42835975">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  George Hotz is making better drivers for AMD<p>lol</div><br/><div id="42836108" class="c"><input type="checkbox" id="c-42836108" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42835560">root</a><span>|</span><a href="#42835975">parent</a><span>|</span><a href="#42836422">next</a><span>|</span><label class="collapse" for="c-42836108">[-]</label><label class="expand" for="c-42836108">[1 more]</label></div><br/><div class="children"><div class="content">*George Hotz is making posts online talking about how AMD isn’t helping him</div><br/></div></div></div></div></div></div><div id="42836422" class="c"><input type="checkbox" id="c-42836422" checked=""/><div class="controls bullet"><span class="by">andrewgross</span><span>|</span><a href="#42835560">prev</a><span>|</span><a href="#42836326">next</a><span>|</span><label class="collapse" for="c-42836422">[-]</label><label class="expand" for="c-42836422">[5 more]</label></div><br/><div class="children"><div class="content">&gt; The beauty of the MOE model approach is that you can decompose the big model into a collection of smaller models that each know different, non-overlapping (at least fully) pieces of knowledge.<p>I was under the impression that this was not how MoE models work. They are not a collection of independent models, but instead a way of routing to a subset of active parameters at each layer.  There is no &quot;expert&quot; that is loaded or unloaded per question. All of the weights are loaded in VRAM, its just a matter of which are actually loaded to the registers for calculation.  As far as I could tell from the Deepseek v3&#x2F;v2 papers, their MoE approach follows this instead of being an explicit collection of experts. If thats the case, theres no VRAM saving to be had using an MOE nor an ability to extract the weights of the expert to run locally (aside from distillation or similar).<p>If there is someone more versed on the construction of MoE architectures I would love some help understanding what I missed here.</div><br/><div id="42836829" class="c"><input type="checkbox" id="c-42836829" checked=""/><div class="controls bullet"><span class="by">Kubuxu</span><span>|</span><a href="#42836422">parent</a><span>|</span><a href="#42836326">next</a><span>|</span><label class="collapse" for="c-42836829">[-]</label><label class="expand" for="c-42836829">[4 more]</label></div><br/><div class="children"><div class="content">Not sure about DeepSeek R1, but you are right in regards to previous MoE architectures.<p>It doesn’t reduce memory usage, as each subsequent token might require different expert buy it reduces per token compute&#x2F;bandwidth usage.
If you place experts in different GPUs, and run batched inference you would see these benefits.</div><br/><div id="42838184" class="c"><input type="checkbox" id="c-42838184" checked=""/><div class="controls bullet"><span class="by">rahimnathwani</span><span>|</span><a href="#42836422">root</a><span>|</span><a href="#42836829">parent</a><span>|</span><a href="#42837045">next</a><span>|</span><label class="collapse" for="c-42838184">[-]</label><label class="expand" for="c-42838184">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  If you place experts in different GPUs
</code></pre>
Right, this is described in the Deepseek V3 paper (section 3.4 on pages 18-20).</div><br/></div></div><div id="42837045" class="c"><input type="checkbox" id="c-42837045" checked=""/><div class="controls bullet"><span class="by">andrewgross</span><span>|</span><a href="#42836422">root</a><span>|</span><a href="#42836829">parent</a><span>|</span><a href="#42838184">prev</a><span>|</span><a href="#42836326">next</a><span>|</span><label class="collapse" for="c-42837045">[-]</label><label class="expand" for="c-42837045">[2 more]</label></div><br/><div class="children"><div class="content">Is there a concept of an expert that persists across layers? I thought each layer was essentially independent in terms of the &quot;experts&quot;. I suppose you could look at what part of each layer was most likely to trigger together and segregate those by GPU though.<p>I could be very wrong on how experts work across layers though, I have only done a naive reading on it so far.</div><br/><div id="42838220" class="c"><input type="checkbox" id="c-42838220" checked=""/><div class="controls bullet"><span class="by">rahimnathwani</span><span>|</span><a href="#42836422">root</a><span>|</span><a href="#42837045">parent</a><span>|</span><a href="#42836326">next</a><span>|</span><label class="collapse" for="c-42838220">[-]</label><label class="expand" for="c-42838220">[1 more]</label></div><br/><div class="children"><div class="content"><p><pre><code>  I suppose you could look at what part of each layer was most likely to trigger together and segregate those by GPU though
</code></pre>
Yes, I think that&#x27;s what they describe in section 3.4 of the V3 paper. Section 2.1.2 talks about &quot;token-to-expert affinity&quot;. I think there&#x27;s a layer which calculates these affinities (between a token and an expert) and then sends the computation to the GPUs with the right experts.<p>This doesn&#x27;t sound like it would work if you&#x27;re running just one chat, as you need all the experts loaded at once if you want to avoid spending lots of time loading and unloading models. But at scale with batches of requests it should work. There&#x27;s some discussion of this in 2.1.2 but it&#x27;s beyond my current ability to comprehend!</div><br/></div></div></div></div></div></div></div></div><div id="42836326" class="c"><input type="checkbox" id="c-42836326" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42836422">prev</a><span>|</span><a href="#42832052">next</a><span>|</span><label class="collapse" for="c-42836326">[-]</label><label class="expand" for="c-42836326">[2 more]</label></div><br/><div class="children"><div class="content">This is excellent writing.<p>Even if you have no interest at all in stock market shorting strategies there is <i>plenty</i> of meaty technical content in here, including some of the clearest summaries I&#x27;ve seen anywhere of the interesting ideas from the DeepSeek v3 and R1 papers.</div><br/><div id="42836800" class="c"><input type="checkbox" id="c-42836800" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#42836326">parent</a><span>|</span><a href="#42832052">next</a><span>|</span><label class="collapse" for="c-42836800">[-]</label><label class="expand" for="c-42836800">[1 more]</label></div><br/><div class="children"><div class="content">Thanks Simon! I’m a big fan of your writing (and tools) so it means a lot coming from you.</div><br/></div></div></div></div><div id="42832052" class="c"><input type="checkbox" id="c-42832052" checked=""/><div class="controls bullet"><span class="by">j7ake</span><span>|</span><a href="#42836326">prev</a><span>|</span><a href="#42838625">next</a><span>|</span><label class="collapse" for="c-42832052">[-]</label><label class="expand" for="c-42832052">[5 more]</label></div><br/><div class="children"><div class="content">This was an amazing summary of the landscape of ML currently.<p>I think the title does the article injustice, or maybe it’s too long for people to read to appreciate it (eg the deepseek stuff can be an article within itself).<p>Whatever the ones with longer attention span will benefit from this read.<p>Thanks for summarising this up!</div><br/><div id="42835346" class="c"><input type="checkbox" id="c-42835346" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#42832052">parent</a><span>|</span><a href="#42834190">next</a><span>|</span><label class="collapse" for="c-42835346">[-]</label><label class="expand" for="c-42835346">[1 more]</label></div><br/><div class="children"><div class="content">The site is currently offline, here&#x27;s a snapshot:<p><a href="https:&#x2F;&#x2F;archive.today&#x2F;y4utp" rel="nofollow">https:&#x2F;&#x2F;archive.today&#x2F;y4utp</a></div><br/></div></div><div id="42834190" class="c"><input type="checkbox" id="c-42834190" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#42832052">parent</a><span>|</span><a href="#42835346">prev</a><span>|</span><a href="#42832961">next</a><span>|</span><label class="collapse" for="c-42834190">[-]</label><label class="expand" for="c-42834190">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;ve changed the title to a different one suggested by the author.</div><br/></div></div><div id="42832961" class="c"><input type="checkbox" id="c-42832961" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#42832052">parent</a><span>|</span><a href="#42834190">prev</a><span>|</span><a href="#42838625">next</a><span>|</span><label class="collapse" for="c-42832961">[-]</label><label class="expand" for="c-42832961">[2 more]</label></div><br/><div class="children"><div class="content">Thanks! I was a bit disappointed that no one saw it on HN because I think they’d like it a lot.</div><br/><div id="42833692" class="c"><input type="checkbox" id="c-42833692" checked=""/><div class="controls bullet"><span class="by">j7ake</span><span>|</span><a href="#42832052">root</a><span>|</span><a href="#42832961">parent</a><span>|</span><a href="#42838625">next</a><span>|</span><label class="collapse" for="c-42833692">[-]</label><label class="expand" for="c-42833692">[1 more]</label></div><br/><div class="children"><div class="content">I think they would like it a lot, but I think the title doesn’t match the content, and it takes too much reading before one realises it goes beyond the title.<p>Keep it up!</div><br/></div></div></div></div></div></div><div id="42838625" class="c"><input type="checkbox" id="c-42838625" checked=""/><div class="controls bullet"><span class="by">suraci</span><span>|</span><a href="#42832052">prev</a><span>|</span><a href="#42834998">next</a><span>|</span><label class="collapse" for="c-42838625">[-]</label><label class="expand" for="c-42838625">[1 more]</label></div><br/><div class="children"><div class="content">DeepSeek is not the black swan<p>NVDA was overpriced a lot already even without r1, the market is full of air GPUs hiding in the capex of tech giants like MSFT.<p>If orders are canceled or delivery fails for any reason, NVDA’s EPS would be pulled back to its fundamentally justified level<p>or if all those air GPUs are produced and delivered in recent years, and the demand keeps rising? well, that will be a crazy world then<p>it&#x27;s a finance game, not related with the real world</div><br/></div></div><div id="42834998" class="c"><input type="checkbox" id="c-42834998" checked=""/><div class="controls bullet"><span class="by">snowmaker</span><span>|</span><a href="#42838625">prev</a><span>|</span><a href="#42838257">next</a><span>|</span><label class="collapse" for="c-42834998">[-]</label><label class="expand" for="c-42834998">[2 more]</label></div><br/><div class="children"><div class="content">This is an excellent article, basically a patio11 &#x2F; matt levine level breakdown of what&#x27;s happening with the GPU market.</div><br/><div id="42836596" class="c"><input type="checkbox" id="c-42836596" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42834998">parent</a><span>|</span><a href="#42838257">next</a><span>|</span><label class="collapse" for="c-42836596">[-]</label><label class="expand" for="c-42836596">[1 more]</label></div><br/><div class="children"><div class="content">Couldn&#x27;t agree more! If this is the byproduct, these must be some optimized Youtube transcripts :)</div><br/></div></div></div></div><div id="42838257" class="c"><input type="checkbox" id="c-42838257" checked=""/><div class="controls bullet"><span class="by">miraculixx</span><span>|</span><a href="#42834998">prev</a><span>|</span><a href="#42836861">next</a><span>|</span><label class="collapse" for="c-42838257">[-]</label><label class="expand" for="c-42838257">[1 more]</label></div><br/><div class="children"><div class="content">If we are to get to AGI why do we need to train on all data? That&#x27;s silly, and all we get is compression and probabliatic retrieval.<p>Intelligence by definition is not compression, but ability to think and act according to new data, based on experience.<p>Trully AGI models will work on   the this principle, not on best compression of as much data as possible.<p>We need a new approach.</div><br/></div></div><div id="42836861" class="c"><input type="checkbox" id="c-42836861" checked=""/><div class="controls bullet"><span class="by">breadwinner</span><span>|</span><a href="#42838257">prev</a><span>|</span><a href="#42838614">next</a><span>|</span><label class="collapse" for="c-42836861">[-]</label><label class="expand" for="c-42836861">[2 more]</label></div><br/><div class="children"><div class="content">Part of the reason Musk, Zuckerberg, Ellison, Nadella and other CEOs are bragging about the number of GPUs they have (or plan to have) is to attract talent.<p>Perplexity CEO says he tried to hire an AI researcher from Meta, and was told to ‘come back to me when you have 10,000 H100 GPUs’<p>See <a href="https:&#x2F;&#x2F;www.businessinsider.nl&#x2F;ceo-says-he-tried-to-hire-an-ai-researcher-from-meta-and-was-told-to-come-back-to-me-when-you-have-10000-h100-gpus&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.businessinsider.nl&#x2F;ceo-says-he-tried-to-hire-an-...</a></div><br/><div id="42837819" class="c"><input type="checkbox" id="c-42837819" checked=""/><div class="controls bullet"><span class="by">mrbungie</span><span>|</span><a href="#42836861">parent</a><span>|</span><a href="#42838614">next</a><span>|</span><label class="collapse" for="c-42837819">[-]</label><label class="expand" for="c-42837819">[1 more]</label></div><br/><div class="children"><div class="content">Maybe DeepSeek ain&#x27;t it, but I expect a big &quot;box of scraps&quot;[1] moment soon. Constraint is mother of invention, and they are evading constraints with a promise of never-ending scale.<p>[1] <a href="https:&#x2F;&#x2F;youtu.be&#x2F;9foB2z_OVHc?si=eZSTMMGYEB3Nb4zI" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;9foB2z_OVHc?si=eZSTMMGYEB3Nb4zI</a></div><br/></div></div></div></div><div id="42838614" class="c"><input type="checkbox" id="c-42838614" checked=""/><div class="controls bullet"><span class="by">jwan584</span><span>|</span><a href="#42836861">prev</a><span>|</span><a href="#42836786">next</a><span>|</span><label class="collapse" for="c-42838614">[-]</label><label class="expand" for="c-42838614">[1 more]</label></div><br/><div class="children"><div class="content">The point about using FP32 for training is wrong. Mixed precision (FP16 multiplies, FP32 accumulates) has been use for years – the original paper came out in 2017.</div><br/></div></div><div id="42836786" class="c"><input type="checkbox" id="c-42836786" checked=""/><div class="controls bullet"><span class="by">pavelstoev</span><span>|</span><a href="#42838614">prev</a><span>|</span><a href="#42838154">next</a><span>|</span><label class="collapse" for="c-42836786">[-]</label><label class="expand" for="c-42836786">[1 more]</label></div><br/><div class="children"><div class="content">English economist William Stanley Jevons vs the author of the article.<p>Will NVIDIA be in trouble because of DSR1 ? Interpreting Jevon’s effect, if LLMs are “steam engines” and DSR1 brings 90% efficiency improvement for the same performance, more of it will be deployed. This is not considering the increase due to &lt;think&gt; tokens.<p>More NVIDIA GPUs will be sold to support growing use cases of more efficient LLMs.</div><br/></div></div><div id="42838154" class="c"><input type="checkbox" id="c-42838154" checked=""/><div class="controls bullet"><span class="by">mgraczyk</span><span>|</span><a href="#42836786">prev</a><span>|</span><a href="#42836757">next</a><span>|</span><label class="collapse" for="c-42838154">[-]</label><label class="expand" for="c-42838154">[4 more]</label></div><br/><div class="children"><div class="content">The beginning of the article was good, but the analysis of DeepSeek and what it means for Nvidia is confused and clearly out of the loop.<p><pre><code>  * People have been training models at &lt;fp32 precision for many years, I did this in 2021 and it was already easy in all the major libraries.
  * GPU FLOPs are used for many things besides training the final released model.
  * Demand for AI is capacity limited, so it&#x27;s possible and likely that increasing AI&#x2F;FLOP would not substantially reduce the price of GPUs</code></pre></div><br/><div id="42838223" class="c"><input type="checkbox" id="c-42838223" checked=""/><div class="controls bullet"><span class="by">lysecret</span><span>|</span><a href="#42838154">parent</a><span>|</span><a href="#42838301">next</a><span>|</span><label class="collapse" for="c-42838223">[-]</label><label class="expand" for="c-42838223">[2 more]</label></div><br/><div class="children"><div class="content">Where do you have this &quot;capacity&quot; limit from? I can get as many H100s from GCP or wherever as I wish, the only thing that is capacity limited are 100k clusters ala ELON+X, but what DeepSeek (and the recent evidence of a limit in pure base-model scaling) shows is that this might actually not be profitable, and we end up with much smaller base models scaled at inference time. The moat for Nvidia in this inference time scaling is much smaller, also you don&#x27;t need the humongous clusters for that either you can just distribute the inference (and in the future run it locally too).</div><br/><div id="42838282" class="c"><input type="checkbox" id="c-42838282" checked=""/><div class="controls bullet"><span class="by">mgraczyk</span><span>|</span><a href="#42838154">root</a><span>|</span><a href="#42838223">parent</a><span>|</span><a href="#42838301">next</a><span>|</span><label class="collapse" for="c-42838282">[-]</label><label class="expand" for="c-42838282">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s your GPU quota in GCP? How did you get it increased that much?</div><br/></div></div></div></div><div id="42838301" class="c"><input type="checkbox" id="c-42838301" checked=""/><div class="controls bullet"><span class="by">aorloff</span><span>|</span><a href="#42838154">parent</a><span>|</span><a href="#42838223">prev</a><span>|</span><a href="#42836757">next</a><span>|</span><label class="collapse" for="c-42838301">[-]</label><label class="expand" for="c-42838301">[1 more]</label></div><br/><div class="children"><div class="content">His DeepSeek argument was essentially that experts who look at the economics of running these teams (eg. ha ha the engineers themselves might dabble) are looking over the hedge at DeepSeek&#x27;s claims and they are really awestruck</div><br/></div></div></div></div><div id="42836757" class="c"><input type="checkbox" id="c-42836757" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42838154">prev</a><span>|</span><a href="#42834291">next</a><span>|</span><label class="collapse" for="c-42836757">[-]</label><label class="expand" for="c-42836757">[2 more]</label></div><br/><div class="children"><div class="content">Man, do I love myself a deep, well-researched long-form contrarian analysis published as a tangent of an already niche blog on a Sunday evening! The old web isn&#x27;t dead yet :)</div><br/><div id="42836889" class="c"><input type="checkbox" id="c-42836889" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#42836757">parent</a><span>|</span><a href="#42834291">next</a><span>|</span><label class="collapse" for="c-42836889">[-]</label><label class="expand" for="c-42836889">[1 more]</label></div><br/><div class="children"><div class="content">Hah thanks, that’s my favorite piece of feedback yet on this.</div><br/></div></div></div></div><div id="42834291" class="c"><input type="checkbox" id="c-42834291" checked=""/><div class="controls bullet"><span class="by">arcanus</span><span>|</span><a href="#42836757">prev</a><span>|</span><a href="#42835391">next</a><span>|</span><label class="collapse" for="c-42834291">[-]</label><label class="expand" for="c-42834291">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Amazon gets a lot of flak for totally bungling their internal AI model development, squandering massive amounts of internal compute resources on models that ultimately are not competitive, but the custom silicon is another matter<p>Juicy. Anyone have a link or context to this? I&#x27;d not heard of this reception to NOVA and related.</div><br/><div id="42836304" class="c"><input type="checkbox" id="c-42836304" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42834291">parent</a><span>|</span><a href="#42835391">next</a><span>|</span><label class="collapse" for="c-42836304">[-]</label><label class="expand" for="c-42836304">[2 more]</label></div><br/><div class="children"><div class="content">I think Nova may have changed things here. Prior to Nova their LLMs were pretty rubbish - Nova only came out in December but seems a whole lot better, at least from initial impressions: <a href="https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Dec&#x2F;4&#x2F;amazon-nova&#x2F;" rel="nofollow">https:&#x2F;&#x2F;simonwillison.net&#x2F;2024&#x2F;Dec&#x2F;4&#x2F;amazon-nova&#x2F;</a></div><br/><div id="42836924" class="c"><input type="checkbox" id="c-42836924" checked=""/><div class="controls bullet"><span class="by">arcanus</span><span>|</span><a href="#42834291">root</a><span>|</span><a href="#42836304">parent</a><span>|</span><a href="#42835391">next</a><span>|</span><label class="collapse" for="c-42836924">[-]</label><label class="expand" for="c-42836924">[1 more]</label></div><br/><div class="children"><div class="content">Thanks! That&#x27;s consistent with my impression.</div><br/></div></div></div></div></div></div><div id="42835391" class="c"><input type="checkbox" id="c-42835391" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#42834291">prev</a><span>|</span><a href="#42835638">next</a><span>|</span><label class="collapse" for="c-42835391">[-]</label><label class="expand" for="c-42835391">[1 more]</label></div><br/><div class="children"><div class="content">Sorry, my blog crashed! Had a stupid bug where it was calling GitHub too frequently to pull in updated markdown for the posts and kept getting rate limits. Had to rewrite it but it should be much better now.</div><br/></div></div><div id="42835638" class="c"><input type="checkbox" id="c-42835638" checked=""/><div class="controls bullet"><span class="by">gnlrtntv</span><span>|</span><a href="#42835391">prev</a><span>|</span><a href="#42838178">next</a><span>|</span><label class="collapse" for="c-42835638">[-]</label><label class="expand" for="c-42835638">[3 more]</label></div><br/><div class="children"><div class="content">&gt; While Apple&#x27;s focus seems somewhat orthogonal to these other players in terms of its mobile-first, consumer oriented, &quot;edge compute&quot; focus, if it ends up spending enough money on its new contract with OpenAI to provide AI services to iPhone users, you have to imagine that they have teams looking into making their own custom silicon for inference&#x2F;training<p>This is already happening today. Most of the new LLM features announced this year are primarily on-device, using the Neural Engine, and the rest is in Private Cloud Compute, which is also using Apple-trained models, on Apple hardware.<p>The only features using OpenAI for inference are the ones that announce the content came from ChatGPT.</div><br/><div id="42835689" class="c"><input type="checkbox" id="c-42835689" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#42835638">parent</a><span>|</span><a href="#42838178">next</a><span>|</span><label class="collapse" for="c-42835689">[-]</label><label class="expand" for="c-42835689">[2 more]</label></div><br/><div class="children"><div class="content">&quot;if it ends up spending enough money on its new contract with OpenAI to provide AI services to iPhone users&quot;<p>John Gruber says neither Apple nor OpenAI are paying for that deal: <a href="https:&#x2F;&#x2F;daringfireball.net&#x2F;linked&#x2F;2024&#x2F;06&#x2F;13&#x2F;gurman-openai-apple" rel="nofollow">https:&#x2F;&#x2F;daringfireball.net&#x2F;linked&#x2F;2024&#x2F;06&#x2F;13&#x2F;gurman-openai-a...</a></div><br/><div id="42836725" class="c"><input type="checkbox" id="c-42836725" checked=""/><div class="controls bullet"><span class="by">lxgr</span><span>|</span><a href="#42835638">root</a><span>|</span><a href="#42835689">parent</a><span>|</span><a href="#42838178">next</a><span>|</span><label class="collapse" for="c-42836725">[-]</label><label class="expand" for="c-42836725">[1 more]</label></div><br/><div class="children"><div class="content">Mark Gurman (from Bloomberg) is saying that.</div><br/></div></div></div></div></div></div><div id="42838178" class="c"><input type="checkbox" id="c-42838178" checked=""/><div class="controls bullet"><span class="by">mkalygin</span><span>|</span><a href="#42835638">prev</a><span>|</span><a href="#42836616">next</a><span>|</span><label class="collapse" for="c-42838178">[-]</label><label class="expand" for="c-42838178">[1 more]</label></div><br/><div class="children"><div class="content">This is such a comprehensive analysis, thank you. For someone just starting to learn about the field, it’s a great way to understand what’s going on in the industry.</div><br/></div></div><div id="42836616" class="c"><input type="checkbox" id="c-42836616" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#42838178">prev</a><span>|</span><a href="#42836300">next</a><span>|</span><label class="collapse" for="c-42836616">[-]</label><label class="expand" for="c-42836616">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; Another very smart thing they did is to use what is known as a Mixture-of-Experts (MOE) Transformer architecture, but with key innovations around load balancing. As you might know, the size or capacity of an AI model is often measured in terms of the number of parameters the model contains. A parameter is just a number that stores some attribute of the model; either the &quot;weight&quot; or importance a particular artificial neuron has relative to another one, or the importance of a particular token depending on its context (in the &quot;attention mechanism&quot;).</i><p>Has a wide-scale model analysis been performed inspecting the parameters and their weights for all popular open &#x2F; available models yet?  The impact and effects of disclosed inbound data and tuning parameters on individual vector tokens will prove highly informative and clarifying.<p>Such analysis will undoubtedly  help semi-literate AI folks level up and bridge any gaps.</div><br/></div></div><div id="42836300" class="c"><input type="checkbox" id="c-42836300" checked=""/><div class="controls bullet"><span class="by">uncletaco</span><span>|</span><a href="#42836616">prev</a><span>|</span><a href="#42836624">next</a><span>|</span><label class="collapse" for="c-42836300">[-]</label><label class="expand" for="c-42836300">[1 more]</label></div><br/><div class="children"><div class="content">When he says better linux drivers than AMD he&#x27;s strictly talking about for AI, right? Because for video the opposite has been the case for as far back as I can remember.</div><br/></div></div><div id="42836624" class="c"><input type="checkbox" id="c-42836624" checked=""/><div class="controls bullet"><span class="by">naveen99</span><span>|</span><a href="#42836300">prev</a><span>|</span><a href="#42835295">next</a><span>|</span><label class="collapse" for="c-42836624">[-]</label><label class="expand" for="c-42836624">[3 more]</label></div><br/><div class="children"><div class="content">Deepseek iOS app makes TikTok ban pointless.</div><br/><div id="42836810" class="c"><input type="checkbox" id="c-42836810" checked=""/><div class="controls bullet"><span class="by">pavelstoev</span><span>|</span><a href="#42836624">parent</a><span>|</span><a href="#42835295">next</a><span>|</span><label class="collapse" for="c-42836810">[-]</label><label class="expand" for="c-42836810">[2 more]</label></div><br/><div class="children"><div class="content">Interesting take. They are now reading our minds vs looking at our kids and interiors.</div><br/><div id="42836858" class="c"><input type="checkbox" id="c-42836858" checked=""/><div class="controls bullet"><span class="by">naveen99</span><span>|</span><a href="#42836624">root</a><span>|</span><a href="#42836810">parent</a><span>|</span><a href="#42835295">next</a><span>|</span><label class="collapse" for="c-42836858">[-]</label><label class="expand" for="c-42836858">[1 more]</label></div><br/><div class="children"><div class="content">yeah, what’s stopping zoom from integrating Deepseek and doing an end run around Microsoft teams.</div><br/></div></div></div></div></div></div><div id="42835061" class="c"><input type="checkbox" id="c-42835061" checked=""/><div class="controls bullet"><span class="by">eprparadox</span><span>|</span><a href="#42835295">prev</a><span>|</span><a href="#42837652">next</a><span>|</span><label class="collapse" for="c-42835061">[-]</label><label class="expand" for="c-42835061">[2 more]</label></div><br/><div class="children"><div class="content">link seems to be dead... is this article still up somewhere?</div><br/><div id="42835150" class="c"><input type="checkbox" id="c-42835150" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#42835061">parent</a><span>|</span><a href="#42837652">next</a><span>|</span><label class="collapse" for="c-42835150">[-]</label><label class="expand" for="c-42835150">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s back up, but just in case:<p><a href="https:&#x2F;&#x2F;archive.is&#x2F;y4utp" rel="nofollow">https:&#x2F;&#x2F;archive.is&#x2F;y4utp</a></div><br/></div></div></div></div><div id="42837652" class="c"><input type="checkbox" id="c-42837652" checked=""/><div class="controls bullet"><span class="by">jms55</span><span>|</span><a href="#42835061">prev</a><span>|</span><a href="#42823015">next</a><span>|</span><label class="collapse" for="c-42837652">[-]</label><label class="expand" for="c-42837652">[1 more]</label></div><br/><div class="children"><div class="content">Great article, thanks for writing it! Really great summary of the current state of the AI industry for someone like me who&#x27;s outside of it (but tangential, given that I work with GPUs for graphics).<p>The one thing from the article that sticks out to me is that the author&#x2F;people are assuming that deepseek needing 1&#x2F;45th the amount of hardware means that the other 44&#x2F;45ths large tech companies have invested were wasteful.<p>Does software not scale to meet hardware? I don&#x27;t see this as 44&#x2F;45ths wasted hardware, but as a free increase in the amount of hardware people have. Software needing less hardware means you can run even _more_ software without spending more money, not that you need less hardware, right? (for the top-end, non-embedded use cases).<p>---<p>As an aside, the state of the &quot;AI&quot; industry really freaks me out sometimes. Ignoring any sort of short or long term effects on society, jobs, people, etc, just the sheer amount of money and time invested into this one thing is, insane?<p>Tons of custom processing chips, interconnects, compilers, algorithms, _press releases!_, etc all for one specific field. It&#x27;s like someone taking the last decade of advances in computers, software, etc, and shoving it in the space of a year. For comparison, Rust 1.0 is 10 years old - I vividly remember the release. And even then it took years to propagate out as a &quot;thing&quot; that people were interested in and invested significant time into. Meanwhile deepseek releases a new model (complete with a customer-facing product name and chat interface, instead of something boring and technical), and in 5 days it&#x27;s being replicated (to at least some degree) and copied by competitors. Google, Apple, Microsoft, etc are all making custom chips and investing insane amounts of money into different compilers, programming languages, hardware, and research.<p>It&#x27;s just, kind of disquieting? Like everyone involved in AI lives in another world operating at breakneck speed, with billions of dollars involved, and the rest of us are just watching from the sidelines. Most of it (LLMs specifically) is no longer exciting to me. It&#x27;s like, what&#x27;s the point of spending time on a non-AI related project? We can spend some time writing a nice API and working on a cool feature or making a UI prettier and that&#x27;s great, and maybe with a good amount of contributors and solid, sustained effort, we can make a cool project that&#x27;s useful and people enjoy, and earns money to support people if it&#x27;s commercial. But then for AI, github repos with shiny well-written readmes pop up overnight, tons of text is being written, thought, effort, and billions of dollars get burned or speculated on in an instant on new things, as soon as the next marketing release is posted.<p>How can the next advancement in graphics, databases, cryptography, etc compete with the sheer amount of societal attention AI receives?<p>Where does that leave writing software for the rest of us?</div><br/></div></div><div id="42823015" class="c"><input type="checkbox" id="c-42823015" checked=""/><div class="controls bullet"><span class="by">zippyman55</span><span>|</span><a href="#42837652">prev</a><span>|</span><a href="#42822163">next</a><span>|</span><label class="collapse" for="c-42823015">[-]</label><label class="expand" for="c-42823015">[1 more]</label></div><br/><div class="children"><div class="content">So at some point we will have too many cannon ball polishing factories and it will become apparent the cannon ball trajectory is not easily improved on.</div><br/></div></div><div id="42822163" class="c"><input type="checkbox" id="c-42822163" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#42823015">prev</a><span>|</span><a href="#42833220">next</a><span>|</span><label class="collapse" for="c-42822163">[-]</label><label class="expand" for="c-42822163">[3 more]</label></div><br/><div class="children"><div class="content">Yesterday I wrote up all my thoughts on whether NVDA stock is finally a decent short (or at least not a good thing to own at this point). I’m a huge bull when it comes to the power and potential of AI, but there are just too many forces arrayed against them to sustain supernormal profits.<p>Anyway, I hope people here find it interesting to read, and I welcome any debate or discussion about my arguments.</div><br/><div id="42835944" class="c"><input type="checkbox" id="c-42835944" checked=""/><div class="controls bullet"><span class="by">scsilver</span><span>|</span><a href="#42822163">parent</a><span>|</span><a href="#42835658">next</a><span>|</span><label class="collapse" for="c-42835944">[-]</label><label class="expand" for="c-42835944">[1 more]</label></div><br/><div class="children"><div class="content">Wanted to add a preface: Thank you for your time on this article, I appreciate your perspective and experience, hoping you can help refine and reign in my bull case.<p>Where do you expect NVDA&#x27;s forward and current eps to land? What revenue drop off are you expecting in late 2025&#x2F;2026. Part of my bull case for NVDA, continuing, is it&#x27;s very reasonable multiple on insane revenue. An leveling off can be expected, but I still feel bullish on it hitting $200+ (5 Trillion market cap? on ~195B revenue for Fiscal year 2026 (calendar 2025) at 33 EPS) based on this years revenue according to their guidance and the guidance of the hyperscalers spending. Finding a sell point is a whole different matter to being actively short. I can see the case to take some profits, hard for me to go short, especially in an inflationary environment (tariffs, electric energy, bullying for lower US interest rates).<p>The scale of production of Grace Hopper and Blackwell amaze me, 800k units of Blackwell coming out this quarter, is there even production room for AMD to get their chips made? (Looking at the new chip factories in Arizona)<p>R1 might be nice for reducing llm inferencing costs, unsure about the local llama one&#x27;s accuracy (couldnt get it to correctly spit out the NFL teams and their associated conferences, kept mixing NFL with Euro Football) but I still want to train YOLO vision models on faster chips like A100&#x27;s vs T4 (4-5x multiples in speed for me).<p>Lastly, if the Robot&#x2F;Autonomous vehicle ML wave hits within the next year, (First drones and cars -&gt; factories -&gt; humanoids) I think this compute demand can sustain NVDA compute demand.<p>The real mystery is how we power all this within 2 years...<p>* This is not financial advice and some of my numbers might be a little off, still refining my model and verifying sources and numbers</div><br/></div></div><div id="42835658" class="c"><input type="checkbox" id="c-42835658" checked=""/><div class="controls bullet"><span class="by">patrickhogan1</span><span>|</span><a href="#42822163">parent</a><span>|</span><a href="#42835944">prev</a><span>|</span><a href="#42833220">next</a><span>|</span><label class="collapse" for="c-42835658">[-]</label><label class="expand" for="c-42835658">[1 more]</label></div><br/><div class="children"><div class="content">Good article. Maybe I missed it, but I see lots of analysis without a clear concluding opinion.</div><br/></div></div></div></div><div id="42833220" class="c"><input type="checkbox" id="c-42833220" checked=""/><div class="controls bullet"><span class="by">diesel4</span><span>|</span><a href="#42822163">prev</a><span>|</span><a href="#42822194">next</a><span>|</span><label class="collapse" for="c-42833220">[-]</label><label class="expand" for="c-42833220">[3 more]</label></div><br/><div class="children"><div class="content">Link isn&#x27;t working.  Is there another or a cached version?</div><br/><div id="42833279" class="c"><input type="checkbox" id="c-42833279" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#42833220">parent</a><span>|</span><a href="#42822194">next</a><span>|</span><label class="collapse" for="c-42833279">[-]</label><label class="expand" for="c-42833279">[2 more]</label></div><br/><div class="children"><div class="content">Try again! Just rebooted the server since it’s going viral now.</div><br/></div></div></div></div><div id="42834055" class="c"><input type="checkbox" id="c-42834055" checked=""/><div class="controls bullet"><span class="by">OutOfHere</span><span>|</span><a href="#42822197">prev</a><span>|</span><label class="collapse" for="c-42834055">[-]</label><label class="expand" for="c-42834055">[10 more]</label></div><br/><div class="children"><div class="content">It seems like a pointless discussion since DeepSeek uses Nvidia GPUs after all.</div><br/><div id="42834093" class="c"><input type="checkbox" id="c-42834093" checked=""/><div class="controls bullet"><span class="by">jjeaff</span><span>|</span><a href="#42834055">parent</a><span>|</span><a href="#42835479">next</a><span>|</span><label class="collapse" for="c-42834093">[-]</label><label class="expand" for="c-42834093">[6 more]</label></div><br/><div class="children"><div class="content">it uses a fractional amount of GPUs though.</div><br/><div id="42834476" class="c"><input type="checkbox" id="c-42834476" checked=""/><div class="controls bullet"><span class="by">breadwinner</span><span>|</span><a href="#42834055">root</a><span>|</span><a href="#42834093">parent</a><span>|</span><a href="#42835792">next</a><span>|</span><label class="collapse" for="c-42834476">[-]</label><label class="expand" for="c-42834476">[1 more]</label></div><br/><div class="children"><div class="content">As it says in the article, you are talking about a mere constant of proportionality, a single multiple. When you&#x27;re dealing with an exponential growth curve, that stuff gets washed out so quickly that it doesn&#x27;t end up matter all that much.<p>Keep in mind that the goal everyone is driving towards is AGI, not simply an incremental improvement over the latest model from Open AI.</div><br/></div></div><div id="42835792" class="c"><input type="checkbox" id="c-42835792" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#42834055">root</a><span>|</span><a href="#42834093">parent</a><span>|</span><a href="#42834476">prev</a><span>|</span><a href="#42834635">next</a><span>|</span><label class="collapse" for="c-42835792">[-]</label><label class="expand" for="c-42835792">[1 more]</label></div><br/><div class="children"><div class="content">Jevons Paradox states that increasing efficiency can cause an even larger increase in demand.</div><br/></div></div><div id="42834635" class="c"><input type="checkbox" id="c-42834635" checked=""/><div class="controls bullet"><span class="by">ithkuil</span><span>|</span><a href="#42834055">root</a><span>|</span><a href="#42834093">parent</a><span>|</span><a href="#42835792">prev</a><span>|</span><a href="#42835841">next</a><span>|</span><label class="collapse" for="c-42834635">[-]</label><label class="expand" for="c-42834635">[1 more]</label></div><br/><div class="children"><div class="content">Which due to the Jevons Paradox may ultimately cause more shovels to be sold</div><br/></div></div><div id="42835841" class="c"><input type="checkbox" id="c-42835841" checked=""/><div class="controls bullet"><span class="by">dutchbookmaker</span><span>|</span><a href="#42834055">root</a><span>|</span><a href="#42834093">parent</a><span>|</span><a href="#42834635">prev</a><span>|</span><a href="#42834842">next</a><span>|</span><label class="collapse" for="c-42835841">[-]</label><label class="expand" for="c-42835841">[1 more]</label></div><br/><div class="children"><div class="content">&quot;wait&quot; I suspect we are all in a bit of denial.<p>When was the last time the US got their lunch ate in technology?<p>Sputnik might be a bit hyperbolic but after using the model all day and as someone who had been thinking of a pro subscription, it is hard to grasp the ramifications.<p>There is just no good reference point that I can think of.</div><br/></div></div><div id="42834842" class="c"><input type="checkbox" id="c-42834842" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#42834055">root</a><span>|</span><a href="#42834093">parent</a><span>|</span><a href="#42835841">prev</a><span>|</span><a href="#42835479">next</a><span>|</span><label class="collapse" for="c-42834842">[-]</label><label class="expand" for="c-42834842">[1 more]</label></div><br/><div class="children"><div class="content">Their loss curve with the RL didn&#x27;t level off much though, could be taken a lot further and scaled up to more parameters on the big nvidia mega clusters out there.  And the architecture is heavily tuned to nvidia optimizations.</div><br/></div></div></div></div><div id="42835479" class="c"><input type="checkbox" id="c-42835479" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#42834055">parent</a><span>|</span><a href="#42834093">prev</a><span>|</span><label class="collapse" for="c-42835479">[-]</label><label class="expand" for="c-42835479">[3 more]</label></div><br/><div class="children"><div class="content">Yep some CEO said they have 50K GPUs of the prior generation. They probably accumulated them through intermediaries that are basically helping nvidia sell to sanctioned parties by proxy</div><br/><div id="42835992" class="c"><input type="checkbox" id="c-42835992" checked=""/><div class="controls bullet"><span class="by">idonotknowwhy</span><span>|</span><a href="#42834055">root</a><span>|</span><a href="#42835479">parent</a><span>|</span><label class="collapse" for="c-42835992">[-]</label><label class="expand" for="c-42835992">[2 more]</label></div><br/><div class="children"><div class="content">Deepseek was there side project. They had a lot of GPUs from their crypto mining project.<p>Then Ethereum turned off PoW mining, so they looked into other things to do with their GPUs, and started DeepSeek.</div><br/><div id="42836117" class="c"><input type="checkbox" id="c-42836117" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#42834055">root</a><span>|</span><a href="#42835992">parent</a><span>|</span><label class="collapse" for="c-42836117">[-]</label><label class="expand" for="c-42836117">[1 more]</label></div><br/><div class="children"><div class="content">Mining crypto on H100s?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></body></html>