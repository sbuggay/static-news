<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1737536470554" as="style"/><link rel="stylesheet" href="styles.css?v=1737536470554"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a>Ask HN: Is anyone doing anything cool with tiny language models?</a> </div><div class="subtext"><span>prettyblocks</span> | <span>145 comments</span></div><br/><div><div id="42790190" class="c"><input type="checkbox" id="c-42790190" checked=""/><div class="controls bullet"><span class="by">kaspermarstal</span><span>|</span><a href="#42786869">next</a><span>|</span><label class="collapse" for="c-42790190">[-]</label><label class="expand" for="c-42790190">[4 more]</label></div><br/><div class="children"><div class="content">I built an Excel Add-In that allows my girlfriend to quickly filter 7000 paper titles and abstracts for a review paper that she is writing [1]. It uses Gemma 2 2b which is a wonderful little model that can run on her laptop CPU. It works surprisingly well for this kind of binary classification task.<p>The nice thing is that she can copy&#x2F;paste the titles and abstracts in to two columns and write e.g. &quot;=PROMPT(A1:B1, &quot;If the paper studies diabetic neuropathy and stroke, return &#x27;Include&#x27;, otherwise return &#x27;Exclude&#x27;&quot;)&quot; and then drag down the formula across 7000 rows to bulk process the data on her own because it&#x27;s just Excel. There is a gif on the readme on the Github repo that shows it.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;getcellm&#x2F;cellm">https:&#x2F;&#x2F;github.com&#x2F;getcellm&#x2F;cellm</a></div><br/><div id="42790494" class="c"><input type="checkbox" id="c-42790494" checked=""/><div class="controls bullet"><span class="by">afro88</span><span>|</span><a href="#42790190">parent</a><span>|</span><a href="#42790265">next</a><span>|</span><label class="collapse" for="c-42790494">[-]</label><label class="expand" for="c-42790494">[1 more]</label></div><br/><div class="children"><div class="content">How accurate are the classifications?</div><br/></div></div><div id="42790265" class="c"><input type="checkbox" id="c-42790265" checked=""/><div class="controls bullet"><span class="by">relistan</span><span>|</span><a href="#42790190">parent</a><span>|</span><a href="#42790494">prev</a><span>|</span><a href="#42790359">next</a><span>|</span><label class="collapse" for="c-42790265">[-]</label><label class="expand" for="c-42790265">[1 more]</label></div><br/><div class="children"><div class="content">Very cool idea. I’ve used gemma2 2b for a few small things. Very good model for being so small.</div><br/></div></div></div></div><div id="42786869" class="c"><input type="checkbox" id="c-42786869" checked=""/><div class="controls bullet"><span class="by">Evidlo</span><span>|</span><a href="#42790190">prev</a><span>|</span><a href="#42786841">next</a><span>|</span><label class="collapse" for="c-42786869">[-]</label><label class="expand" for="c-42786869">[20 more]</label></div><br/><div class="children"><div class="content">I have ollama responding to SMS spam texts.  I told it to feign interest in whatever the spammer is selling&#x2F;buying.  Each number gets its own persona, like a millennial gymbro or 19th century British gentleman.<p><a href="http:&#x2F;&#x2F;files.widloski.com&#x2F;image10%20(1).png" rel="nofollow">http:&#x2F;&#x2F;files.widloski.com&#x2F;image10%20(1).png</a><p><a href="http:&#x2F;&#x2F;files.widloski.com&#x2F;image11.png" rel="nofollow">http:&#x2F;&#x2F;files.widloski.com&#x2F;image11.png</a></div><br/><div id="42787151" class="c"><input type="checkbox" id="c-42787151" checked=""/><div class="controls bullet"><span class="by">celestialcheese</span><span>|</span><a href="#42786869">parent</a><span>|</span><a href="#42789860">next</a><span>|</span><label class="collapse" for="c-42787151">[-]</label><label class="expand" for="c-42787151">[4 more]</label></div><br/><div class="children"><div class="content">Given the source, I&#x27;m skeptical it&#x27;s not just a troll, but found this explanation [0] plausible as to why those vague spam text exists.  If true, this trolling helps the spammers warm those phone numbers up.<p>0 - <a href="https:&#x2F;&#x2F;x.com&#x2F;nikitabier&#x2F;status&#x2F;1867029883387580571" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;nikitabier&#x2F;status&#x2F;1867029883387580571</a></div><br/><div id="42787482" class="c"><input type="checkbox" id="c-42787482" checked=""/><div class="controls bullet"><span class="by">stogot</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42787151">parent</a><span>|</span><a href="#42789860">next</a><span>|</span><label class="collapse" for="c-42787482">[-]</label><label class="expand" for="c-42787482">[3 more]</label></div><br/><div class="children"><div class="content">Why does STOP work here?</div><br/><div id="42787551" class="c"><input type="checkbox" id="c-42787551" checked=""/><div class="controls bullet"><span class="by">inerte</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42787482">parent</a><span>|</span><a href="#42787538">next</a><span>|</span><label class="collapse" for="c-42787551">[-]</label><label class="expand" for="c-42787551">[1 more]</label></div><br/><div class="children"><div class="content">Carriers and SMS service providers (like Twillio) obey that, no matter what service is behind.<p>There are stories of people replying STOP to spam, then never getting a legit SMS because the number was re-used by another service. That&#x27;s because it&#x27;s being blocked between the spammer and the phone.</div><br/></div></div><div id="42787538" class="c"><input type="checkbox" id="c-42787538" checked=""/><div class="controls bullet"><span class="by">celestialcheese</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42787482">parent</a><span>|</span><a href="#42787551">prev</a><span>|</span><a href="#42789860">next</a><span>|</span><label class="collapse" for="c-42787538">[-]</label><label class="expand" for="c-42787538">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;x.com&#x2F;nikitabier&#x2F;status&#x2F;1867069169256308766" rel="nofollow">https:&#x2F;&#x2F;x.com&#x2F;nikitabier&#x2F;status&#x2F;1867069169256308766</a><p>Again, no clue if this is true, but it seems plausible.</div><br/></div></div></div></div></div></div><div id="42789860" class="c"><input type="checkbox" id="c-42789860" checked=""/><div class="controls bullet"><span class="by">merpkz</span><span>|</span><a href="#42786869">parent</a><span>|</span><a href="#42787151">prev</a><span>|</span><a href="#42786904">next</a><span>|</span><label class="collapse" for="c-42789860">[-]</label><label class="expand" for="c-42789860">[1 more]</label></div><br/><div class="children"><div class="content">Calling Jessica an old chap is quite a giveaway that it&#x27;s a bot xD
Nice idea indeed, but I have a feeling that it&#x27;s just two LLMs now conversing with each other.</div><br/></div></div><div id="42786904" class="c"><input type="checkbox" id="c-42786904" checked=""/><div class="controls bullet"><span class="by">RVuRnvbM2e</span><span>|</span><a href="#42786869">parent</a><span>|</span><a href="#42789860">prev</a><span>|</span><a href="#42786974">next</a><span>|</span><label class="collapse" for="c-42786904">[-]</label><label class="expand" for="c-42786904">[8 more]</label></div><br/><div class="children"><div class="content">This is fantastic. How have your hooked up a mobile number to the llm?</div><br/><div id="42786993" class="c"><input type="checkbox" id="c-42786993" checked=""/><div class="controls bullet"><span class="by">Evidlo</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42786904">parent</a><span>|</span><a href="#42786967">next</a><span>|</span><label class="collapse" for="c-42786993">[-]</label><label class="expand" for="c-42786993">[6 more]</label></div><br/><div class="children"><div class="content">Android app that forwards to a Python service on remote workstation over MQTT.  I can make a Show HN if people are interested.</div><br/><div id="42787356" class="c"><input type="checkbox" id="c-42787356" checked=""/><div class="controls bullet"><span class="by">dkga</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42786993">parent</a><span>|</span><a href="#42787153">next</a><span>|</span><label class="collapse" for="c-42787356">[-]</label><label class="expand" for="c-42787356">[1 more]</label></div><br/><div class="children"><div class="content">Yes, I&#x27;d be interested in that!</div><br/></div></div><div id="42787153" class="c"><input type="checkbox" id="c-42787153" checked=""/><div class="controls bullet"><span class="by">deadbabe</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42786993">parent</a><span>|</span><a href="#42787356">prev</a><span>|</span><a href="#42786967">next</a><span>|</span><label class="collapse" for="c-42787153">[-]</label><label class="expand" for="c-42787153">[4 more]</label></div><br/><div class="children"><div class="content">I’d love to see that. Could you simulate iMessage?</div><br/><div id="42787660" class="c"><input type="checkbox" id="c-42787660" checked=""/><div class="controls bullet"><span class="by">great_psy</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42787153">parent</a><span>|</span><a href="#42787315">next</a><span>|</span><label class="collapse" for="c-42787660">[-]</label><label class="expand" for="c-42787660">[1 more]</label></div><br/><div class="children"><div class="content">Yes it’s possible, but it’s not something you can easily scale.<p>I had a similar project a few years back that used OSX automations and Shortcuts and Python to send a message everyday to a friend. It required you to be signed in to iMessage on your MacBook.<p>Than was a send operation, the reading of replies is not something I implemented, but I know there is a file somewhere that holds a history of your recent iMessages. So you would have to parse it on file update and that should give you the read operation so you can have a conversation.<p>Very doable in a few hours unless something dramatic changed with how the messages apps works within the last few years.</div><br/></div></div><div id="42787315" class="c"><input type="checkbox" id="c-42787315" checked=""/><div class="controls bullet"><span class="by">Evidlo</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42787153">parent</a><span>|</span><a href="#42787660">prev</a><span>|</span><a href="#42786967">next</a><span>|</span><label class="collapse" for="c-42787315">[-]</label><label class="expand" for="c-42787315">[2 more]</label></div><br/><div class="children"><div class="content">If you mean hook this into iMessage, I don&#x27;t know.  I&#x27;m willing to bet it&#x27;s way harder though because Apple</div><br/><div id="42790394" class="c"><input type="checkbox" id="c-42790394" checked=""/><div class="controls bullet"><span class="by">dambi0</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42787315">parent</a><span>|</span><a href="#42786967">next</a><span>|</span><label class="collapse" for="c-42790394">[-]</label><label class="expand" for="c-42790394">[1 more]</label></div><br/><div class="children"><div class="content">If you are willing to use Apple Shortcuts on iOS it’s pretty easy to add something that will be trigged when a message is received and can call out to a service or even use SSH to do something with the contents, including  replying</div><br/></div></div></div></div></div></div></div></div><div id="42786967" class="c"><input type="checkbox" id="c-42786967" checked=""/><div class="controls bullet"><span class="by">spiritplumber</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42786904">parent</a><span>|</span><a href="#42786993">prev</a><span>|</span><a href="#42786974">next</a><span>|</span><label class="collapse" for="c-42786967">[-]</label><label class="expand" for="c-42786967">[1 more]</label></div><br/><div class="children"><div class="content">For something similar with FB chat, I use Selenium and run it on the same box that the llm is running on. Using multiple personalities is really cool though. I should update mine likewise!</div><br/></div></div></div></div><div id="42786974" class="c"><input type="checkbox" id="c-42786974" checked=""/><div class="controls bullet"><span class="by">zx8080</span><span>|</span><a href="#42786869">parent</a><span>|</span><a href="#42786904">prev</a><span>|</span><a href="#42787781">next</a><span>|</span><label class="collapse" for="c-42786974">[-]</label><label class="expand" for="c-42786974">[2 more]</label></div><br/><div class="children"><div class="content">Cool! Do you consider the risk of unintentional (and until some moment, an unknown) subscription to some paid SMS service and how do you mitigate it?</div><br/><div id="42787017" class="c"><input type="checkbox" id="c-42787017" checked=""/><div class="controls bullet"><span class="by">Evidlo</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42786974">parent</a><span>|</span><a href="#42787781">next</a><span>|</span><label class="collapse" for="c-42787017">[-]</label><label class="expand" for="c-42787017">[1 more]</label></div><br/><div class="children"><div class="content">I have to whitelist a conversation before the LLM can respond.</div><br/></div></div></div></div><div id="42787781" class="c"><input type="checkbox" id="c-42787781" checked=""/><div class="controls bullet"><span class="by">blackeyeblitzar</span><span>|</span><a href="#42786869">parent</a><span>|</span><a href="#42786974">prev</a><span>|</span><a href="#42789419">next</a><span>|</span><label class="collapse" for="c-42787781">[-]</label><label class="expand" for="c-42787781">[2 more]</label></div><br/><div class="children"><div class="content">You realize this is going to cause carriers to allow the number to send more spam, because it looks like engagement. The best thing to do is to report the offending message to 7726 (SPAM) so the carrier can take action. You can also file complaints at the FTC and FCC websites, but that takes a bit more effort.</div><br/><div id="42790409" class="c"><input type="checkbox" id="c-42790409" checked=""/><div class="controls bullet"><span class="by">thegabriele</span><span>|</span><a href="#42786869">root</a><span>|</span><a href="#42787781">parent</a><span>|</span><a href="#42789419">next</a><span>|</span><label class="collapse" for="c-42790409">[-]</label><label class="expand" for="c-42790409">[1 more]</label></div><br/><div class="children"><div class="content">Yes, the very last thing to do is respond to spam (calls, email, text...) and inform that you are eligible to more solicitation.</div><br/></div></div></div></div><div id="42789419" class="c"><input type="checkbox" id="c-42789419" checked=""/><div class="controls bullet"><span class="by">metadat</span><span>|</span><a href="#42786869">parent</a><span>|</span><a href="#42787781">prev</a><span>|</span><a href="#42787231">next</a><span>|</span><label class="collapse" for="c-42789419">[-]</label><label class="expand" for="c-42789419">[1 more]</label></div><br/><div class="children"><div class="content">I love this, more please!!!</div><br/></div></div><div id="42787231" class="c"><input type="checkbox" id="c-42787231" checked=""/><div class="controls bullet"><span class="by">thecosmicfrog</span><span>|</span><a href="#42786869">parent</a><span>|</span><a href="#42789419">prev</a><span>|</span><a href="#42786841">next</a><span>|</span><label class="collapse" for="c-42787231">[-]</label><label class="expand" for="c-42787231">[1 more]</label></div><br/><div class="children"><div class="content">Please tell me you have a blog&#x2F;archive of these somewhere. This was such a joy to read!</div><br/></div></div></div></div><div id="42786841" class="c"><input type="checkbox" id="c-42786841" checked=""/><div class="controls bullet"><span class="by">antonok</span><span>|</span><a href="#42786869">prev</a><span>|</span><a href="#42786586">next</a><span>|</span><label class="collapse" for="c-42786841">[-]</label><label class="expand" for="c-42786841">[12 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using Llama models to identify cookie notices on websites, for the purpose of adding filter rules to block them in EasyList Cookie. Otherwise, this is normally done by, essentially, manual volunteer reporting.<p>Most cookie notices turn out to be pretty similar, HTML&#x2F;CSS-wise, and then you can grab their `innerText` and filter out false positives with a small LLM. I&#x27;ve found the 3B models have decent performance on this task, given enough prompt engineering. They do fall apart slightly around edge cases like less common languages or combined cookie notice + age restriction banners. 7B has a negligible false-positive rate without much extra cost. Either way these things are really fast and it&#x27;s amazing to see reports streaming in during a crawl with no human effort required.<p>Code is at <a href="https:&#x2F;&#x2F;github.com&#x2F;brave&#x2F;cookiemonster">https:&#x2F;&#x2F;github.com&#x2F;brave&#x2F;cookiemonster</a>. You can see the prompt at <a href="https:&#x2F;&#x2F;github.com&#x2F;brave&#x2F;cookiemonster&#x2F;blob&#x2F;main&#x2F;src&#x2F;text-classification.mjs#L12">https:&#x2F;&#x2F;github.com&#x2F;brave&#x2F;cookiemonster&#x2F;blob&#x2F;main&#x2F;src&#x2F;text-cl...</a>.</div><br/><div id="42786896" class="c"><input type="checkbox" id="c-42786896" checked=""/><div class="controls bullet"><span class="by">bazmattaz</span><span>|</span><a href="#42786841">parent</a><span>|</span><a href="#42786891">next</a><span>|</span><label class="collapse" for="c-42786896">[-]</label><label class="expand" for="c-42786896">[4 more]</label></div><br/><div class="children"><div class="content">This is so cool thanks for sharing. I can imagine it’s not technically possible (yet?) but it would be cool if this could simply be run as a browser extension rather than running a docker container</div><br/><div id="42786919" class="c"><input type="checkbox" id="c-42786919" checked=""/><div class="controls bullet"><span class="by">antonok</span><span>|</span><a href="#42786841">root</a><span>|</span><a href="#42786896">parent</a><span>|</span><a href="#42789894">next</a><span>|</span><label class="collapse" for="c-42786919">[-]</label><label class="expand" for="c-42786919">[1 more]</label></div><br/><div class="children"><div class="content">I did actually make a rough proof-of-concept of this! One of my long-term visions is to have it running natively in-browser, and able to automatically fix site issues caused by adblocking whenever they happen.<p>The PoC is a bit outdated but it&#x27;s here: <a href="https:&#x2F;&#x2F;github.com&#x2F;brave&#x2F;cookiemonster&#x2F;tree&#x2F;webext">https:&#x2F;&#x2F;github.com&#x2F;brave&#x2F;cookiemonster&#x2F;tree&#x2F;webext</a></div><br/></div></div><div id="42789894" class="c"><input type="checkbox" id="c-42789894" checked=""/><div class="controls bullet"><span class="by">MarioMan</span><span>|</span><a href="#42786841">root</a><span>|</span><a href="#42786896">parent</a><span>|</span><a href="#42786919">prev</a><span>|</span><a href="#42788804">next</a><span>|</span><label class="collapse" for="c-42789894">[-]</label><label class="expand" for="c-42789894">[1 more]</label></div><br/><div class="children"><div class="content">There are a couple of WebGPU LLM platforms available that form the building blocks to accomplish this right from the browser, especially since the models are so small.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;mlc-ai&#x2F;web-llm">https:&#x2F;&#x2F;github.com&#x2F;mlc-ai&#x2F;web-llm</a><p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers.js&#x2F;en&#x2F;index" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers.js&#x2F;en&#x2F;index</a><p>You do have to worry about WebGPU compatibility in browsers though.<p><a href="https:&#x2F;&#x2F;caniuse.com&#x2F;webgpu" rel="nofollow">https:&#x2F;&#x2F;caniuse.com&#x2F;webgpu</a></div><br/></div></div><div id="42788804" class="c"><input type="checkbox" id="c-42788804" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#42786841">root</a><span>|</span><a href="#42786896">parent</a><span>|</span><a href="#42789894">prev</a><span>|</span><a href="#42786891">next</a><span>|</span><label class="collapse" for="c-42788804">[-]</label><label class="expand" for="c-42788804">[1 more]</label></div><br/><div class="children"><div class="content">It should be possible using native messaging [1] which can call out to an external binary. The 1password extensions use that to communicate with the password manager binary.<p>[1] <a href="https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Mozilla&#x2F;Add-ons&#x2F;WebExtensions&#x2F;Native_messaging" rel="nofollow">https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Mozilla&#x2F;Add-ons&#x2F;Web...</a></div><br/></div></div></div></div><div id="42786891" class="c"><input type="checkbox" id="c-42786891" checked=""/><div class="controls bullet"><span class="by">binarysneaker</span><span>|</span><a href="#42786841">parent</a><span>|</span><a href="#42786896">prev</a><span>|</span><a href="#42786586">next</a><span>|</span><label class="collapse" for="c-42786891">[-]</label><label class="expand" for="c-42786891">[7 more]</label></div><br/><div class="children"><div class="content">Maybe it could also send automated petitions to the EU to undo cookie consent legislation, and reverse some of the enshitification.</div><br/><div id="42786953" class="c"><input type="checkbox" id="c-42786953" checked=""/><div class="controls bullet"><span class="by">antonok</span><span>|</span><a href="#42786841">root</a><span>|</span><a href="#42786891">parent</a><span>|</span><a href="#42787244">next</a><span>|</span><label class="collapse" for="c-42786953">[-]</label><label class="expand" for="c-42786953">[1 more]</label></div><br/><div class="children"><div class="content">Ha, I&#x27;m not sure the EU is prepared to handle the deluge of petitions that would ensue.<p>On a more serious note, this must be the first time we can quantitatively measure the impact of cookie consent legislation across the web, so maybe there&#x27;s something to be explored there.</div><br/></div></div><div id="42787244" class="c"><input type="checkbox" id="c-42787244" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#42786841">root</a><span>|</span><a href="#42786891">parent</a><span>|</span><a href="#42786953">prev</a><span>|</span><a href="#42788894">next</a><span>|</span><label class="collapse" for="c-42787244">[-]</label><label class="expand" for="c-42787244">[3 more]</label></div><br/><div class="children"><div class="content">I think there is real potential here, for smart browsing. Have the llm get the page, replace all the ads with kittens, find non-paywall versions if possible and needed, spoof fingerprint data, detect and highlight AI generated drivel, etc. The site would have no way of knowing that it wasn’t touching eyeballs.  We might be able to rake back a bit of the web this way.</div><br/><div id="42787340" class="c"><input type="checkbox" id="c-42787340" checked=""/><div class="controls bullet"><span class="by">antonok</span><span>|</span><a href="#42786841">root</a><span>|</span><a href="#42787244">parent</a><span>|</span><a href="#42788894">next</a><span>|</span><label class="collapse" for="c-42787340">[-]</label><label class="expand" for="c-42787340">[2 more]</label></div><br/><div class="children"><div class="content">You probably wouldn&#x27;t want to run this in real-time on every site as it&#x27;ll significantly increase the load on your browser, but as long as it&#x27;s possible to generate adblock filter rules, the fixes can scale to a pretty large audience.</div><br/><div id="42788192" class="c"><input type="checkbox" id="c-42788192" checked=""/><div class="controls bullet"><span class="by">K0balt</span><span>|</span><a href="#42786841">root</a><span>|</span><a href="#42787340">parent</a><span>|</span><a href="#42788894">next</a><span>|</span><label class="collapse" for="c-42788192">[-]</label><label class="expand" for="c-42788192">[1 more]</label></div><br/><div class="children"><div class="content">I was thinking running it in my home lab server as a proxy, but yeah, scaling it to the browser would require some pretty strong hardware. Still, maybe in a couple of years it could be mainstream.</div><br/></div></div></div></div></div></div><div id="42788894" class="c"><input type="checkbox" id="c-42788894" checked=""/><div class="controls bullet"><span class="by">sebastiennight</span><span>|</span><a href="#42786841">root</a><span>|</span><a href="#42786891">parent</a><span>|</span><a href="#42787244">prev</a><span>|</span><a href="#42786586">next</a><span>|</span><label class="collapse" for="c-42788894">[-]</label><label class="expand" for="c-42788894">[2 more]</label></div><br/><div class="children"><div class="content">To me this take is like smokers complaining that the evil government is forcing the good tobacco companies to degrade the experience by adding pictures of cancer patients on cigarette packs.</div><br/><div id="42790227" class="c"><input type="checkbox" id="c-42790227" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#42786841">root</a><span>|</span><a href="#42788894">parent</a><span>|</span><a href="#42786586">next</a><span>|</span><label class="collapse" for="c-42790227">[-]</label><label class="expand" for="c-42790227">[1 more]</label></div><br/><div class="children"><div class="content">Those don’t really work: <a href="https:&#x2F;&#x2F;jamanetwork.com&#x2F;journals&#x2F;jamanetworkopen&#x2F;fullarticle&#x2F;2782665" rel="nofollow">https:&#x2F;&#x2F;jamanetwork.com&#x2F;journals&#x2F;jamanetworkopen&#x2F;fullarticle...</a></div><br/></div></div></div></div></div></div></div></div><div id="42786586" class="c"><input type="checkbox" id="c-42786586" checked=""/><div class="controls bullet"><span class="by">nozzlegear</span><span>|</span><a href="#42786841">prev</a><span>|</span><a href="#42785105">next</a><span>|</span><label class="collapse" for="c-42786586">[-]</label><label class="expand" for="c-42786586">[4 more]</label></div><br/><div class="children"><div class="content">I have a small fish script I use to prompt a model to generate three commit messages based off of my current git diff. I&#x27;m still playing around with which model comes up with the best messages, but usually I only use it to give me some ideas when my brain isn&#x27;t working. All the models accomplish that task pretty well.<p>Here&#x27;s the script: <a href="https:&#x2F;&#x2F;github.com&#x2F;nozzlegear&#x2F;dotfiles&#x2F;blob&#x2F;master&#x2F;fish-functions&#x2F;gen_commit_msg.fish">https:&#x2F;&#x2F;github.com&#x2F;nozzlegear&#x2F;dotfiles&#x2F;blob&#x2F;master&#x2F;fish-func...</a><p>And for this change [1] it generated these messages:<p><pre><code>    1. `fix: change from printf to echo for handling git diff input`
    
    2. `refactor: update codeblock syntax in commit message generator`
    
    3. `style: improve readability by adjusting prompt formatting`
</code></pre>
[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;nozzlegear&#x2F;dotfiles&#x2F;commit&#x2F;0db65054524d0d2e706cbcf57e8067b878b3358b">https:&#x2F;&#x2F;github.com&#x2F;nozzlegear&#x2F;dotfiles&#x2F;commit&#x2F;0db65054524d0d...</a></div><br/><div id="42790370" class="c"><input type="checkbox" id="c-42790370" checked=""/><div class="controls bullet"><span class="by">relistan</span><span>|</span><a href="#42786586">parent</a><span>|</span><a href="#42790595">next</a><span>|</span><label class="collapse" for="c-42790370">[-]</label><label class="expand" for="c-42790370">[1 more]</label></div><br/><div class="children"><div class="content">Interesting idea. But those say what’s in the commit. The commit diff already tells you that. The best commit messages IMO tell you why you did it and what value was delivered. I think it’s gonna be hard for an LLM to do that since that context lives outside the code. But maybe it would, if you hook it to e.g. a ticketing system and include relevant tickets so it can grab context.<p>For instance, in your first example, why was that change needed? It was a fix, but for what issue?<p>In the second message: why was that a desirable change?</div><br/></div></div><div id="42790595" class="c"><input type="checkbox" id="c-42790595" checked=""/><div class="controls bullet"><span class="by">lionkor</span><span>|</span><a href="#42786586">parent</a><span>|</span><a href="#42790370">prev</a><span>|</span><a href="#42788793">next</a><span>|</span><label class="collapse" for="c-42790595">[-]</label><label class="expand" for="c-42790595">[1 more]</label></div><br/><div class="children"><div class="content">Those commit messages are pretty terrible, please try to come up with actual messages ;)</div><br/></div></div><div id="42788793" class="c"><input type="checkbox" id="c-42788793" checked=""/><div class="controls bullet"><span class="by">mentos</span><span>|</span><a href="#42786586">parent</a><span>|</span><a href="#42790595">prev</a><span>|</span><a href="#42785105">next</a><span>|</span><label class="collapse" for="c-42788793">[-]</label><label class="expand" for="c-42788793">[1 more]</label></div><br/><div class="children"><div class="content">Awesome need to make one for naming variables too haha</div><br/></div></div></div></div><div id="42785105" class="c"><input type="checkbox" id="c-42785105" checked=""/><div class="controls bullet"><span class="by">behohippy</span><span>|</span><a href="#42786586">prev</a><span>|</span><a href="#42790521">next</a><span>|</span><label class="collapse" for="c-42785105">[-]</label><label class="expand" for="c-42785105">[13 more]</label></div><br/><div class="children"><div class="content">I have a mini PC with an n100 CPU connected to a small 7&quot; monitor sitting on my desk, under the regular PC.  I have llama 3b (q4) generating endless stories in different genres and styles.  It&#x27;s fun to glance over at it and read whatever it&#x27;s in the middle of making.  I gave llama.cpp one CPU core and it generates slow enough to just read at a normal pace, and the CPU fans don&#x27;t go nuts.  Totally not productive or really useful but I like it.</div><br/><div id="42786114" class="c"><input type="checkbox" id="c-42786114" checked=""/><div class="controls bullet"><span class="by">ipython</span><span>|</span><a href="#42785105">parent</a><span>|</span><a href="#42785325">next</a><span>|</span><label class="collapse" for="c-42786114">[-]</label><label class="expand" for="c-42786114">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s neat. I just tried something similar:<p><pre><code>    FORTUNE=$(fortune) &amp;&amp; echo $FORTUNE &amp;&amp; echo &quot;Convert the following output of the Unix `fortune` command into a small screenplay in the style of Shakespeare: \n\n $FORTUNE&quot; | ollama run phi4</code></pre></div><br/><div id="42790266" class="c"><input type="checkbox" id="c-42790266" checked=""/><div class="controls bullet"><span class="by">watermelon0</span><span>|</span><a href="#42785105">root</a><span>|</span><a href="#42786114">parent</a><span>|</span><a href="#42785325">next</a><span>|</span><label class="collapse" for="c-42790266">[-]</label><label class="expand" for="c-42790266">[1 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t `fortune` inside double quotes execute the command in bash? You should use single quotes instead of backticks.</div><br/></div></div></div></div><div id="42785325" class="c"><input type="checkbox" id="c-42785325" checked=""/><div class="controls bullet"><span class="by">Uehreka</span><span>|</span><a href="#42785105">parent</a><span>|</span><a href="#42786114">prev</a><span>|</span><a href="#42785192">next</a><span>|</span><label class="collapse" for="c-42785325">[-]</label><label class="expand" for="c-42785325">[6 more]</label></div><br/><div class="children"><div class="content">Do you find that it actually generates varied and diverse stories? Or does it just fall into the same 3 grooves?<p>Last week I tried to get an LLM (one of the recent Llama models running through Groq, it was 70B I believe) to produce randomly generated prompts in a variety of styles and it kept producing cyberpunk scifi stuff. When I told it to stop doing cyberpunk scifi stuff it went completely to wild west.</div><br/><div id="42785456" class="c"><input type="checkbox" id="c-42785456" checked=""/><div class="controls bullet"><span class="by">o11c</span><span>|</span><a href="#42785105">root</a><span>|</span><a href="#42785325">parent</a><span>|</span><a href="#42788219">next</a><span>|</span><label class="collapse" for="c-42785456">[-]</label><label class="expand" for="c-42785456">[2 more]</label></div><br/><div class="children"><div class="content">You should not ever expect an LLM to actually do what you want without handholding, and randomness in particular is one of the places it fails badly. This is probably fundamental.<p>That said, this is also not helped by the fact that all of the default interfaces lack many essential features, so you have to build the interface yourself. Neither &quot;clear the context on every attempt&quot; nor &quot;reuse the context repeatedly&quot; will give good results, but having one context producing just one-line summaries, then fresh contexts expanding each one will do slightly less badly.<p>(If you actually want the LLM to do something useful, there are many more things that need to be added beyond this)</div><br/><div id="42786158" class="c"><input type="checkbox" id="c-42786158" checked=""/><div class="controls bullet"><span class="by">dotancohen</span><span>|</span><a href="#42785105">root</a><span>|</span><a href="#42785456">parent</a><span>|</span><a href="#42788219">next</a><span>|</span><label class="collapse" for="c-42786158">[-]</label><label class="expand" for="c-42786158">[1 more]</label></div><br/><div class="children"><div class="content">Sounds to me like you might want to reduce the Top P - that will prevent the really unlikely next tokens from ever being selected, while still providing nice randomness in the remaining next tokens so you continue to get diverse stories.</div><br/></div></div></div></div><div id="42788219" class="c"><input type="checkbox" id="c-42788219" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#42785105">root</a><span>|</span><a href="#42785325">parent</a><span>|</span><a href="#42785456">prev</a><span>|</span><a href="#42786232">next</a><span>|</span><label class="collapse" for="c-42788219">[-]</label><label class="expand" for="c-42788219">[1 more]</label></div><br/><div class="children"><div class="content">Someone mentioned generating millions of (very short) stories with an LLM a few weeks ago: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42577644">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42577644</a><p>They linked to an interactive explorer that nicely shows the diversity of the dataset, and the HF repo links to the GitHub repo that has the code that generated the stories: <a href="https:&#x2F;&#x2F;github.com&#x2F;lennart-finke&#x2F;simple_stories_generate">https:&#x2F;&#x2F;github.com&#x2F;lennart-finke&#x2F;simple_stories_generate</a><p>So, it seems there are ways to get varied stories.</div><br/></div></div><div id="42786232" class="c"><input type="checkbox" id="c-42786232" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#42785105">root</a><span>|</span><a href="#42785325">parent</a><span>|</span><a href="#42788219">prev</a><span>|</span><a href="#42789260">next</a><span>|</span><label class="collapse" for="c-42786232">[-]</label><label class="expand" for="c-42786232">[1 more]</label></div><br/><div class="children"><div class="content">Generate a list of 5000 possible topics you’d like it to talk about. Randomly pick one and inject that into your prompt.</div><br/></div></div><div id="42789260" class="c"><input type="checkbox" id="c-42789260" checked=""/><div class="controls bullet"><span class="by">TMWNN</span><span>|</span><a href="#42785105">root</a><span>|</span><a href="#42785325">parent</a><span>|</span><a href="#42786232">prev</a><span>|</span><a href="#42785192">next</a><span>|</span><label class="collapse" for="c-42789260">[-]</label><label class="expand" for="c-42789260">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Do you find that it actually generates varied and diverse stories? Or does it just fall into the same 3 grooves?<p>&gt; Last week I tried to get an LLM (one of the recent Llama models running through Groq, it was 70B I believe) to produce randomly generated prompts in a variety of styles and it kept producing cyberpunk scifi stuff.<p>100% relevant: &quot;Someday&quot; &lt;<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Someday_(short_story)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Someday_(short_story)</a>&gt; by Isaac Asimov, 1956</div><br/></div></div></div></div><div id="42785192" class="c"><input type="checkbox" id="c-42785192" checked=""/><div class="controls bullet"><span class="by">Dansvidania</span><span>|</span><a href="#42785105">parent</a><span>|</span><a href="#42785325">prev</a><span>|</span><a href="#42786081">next</a><span>|</span><label class="collapse" for="c-42785192">[-]</label><label class="expand" for="c-42785192">[1 more]</label></div><br/><div class="children"><div class="content">this sounds pretty cool, do you have any video&#x2F;media of it?</div><br/></div></div><div id="42786081" class="c"><input type="checkbox" id="c-42786081" checked=""/><div class="controls bullet"><span class="by">keeganpoppen</span><span>|</span><a href="#42785105">parent</a><span>|</span><a href="#42785192">prev</a><span>|</span><a href="#42785253">next</a><span>|</span><label class="collapse" for="c-42786081">[-]</label><label class="expand" for="c-42786081">[1 more]</label></div><br/><div class="children"><div class="content">oh wow that is actually such a brilliant little use case-- really cuts to the core of the real &quot;magic&quot; of ai: that it can just keep running continuously. it never gets tired, and never gets tired of thinking.</div><br/></div></div><div id="42785253" class="c"><input type="checkbox" id="c-42785253" checked=""/><div class="controls bullet"><span class="by">bithavoc</span><span>|</span><a href="#42785105">parent</a><span>|</span><a href="#42786081">prev</a><span>|</span><a href="#42787856">next</a><span>|</span><label class="collapse" for="c-42785253">[-]</label><label class="expand" for="c-42785253">[1 more]</label></div><br/><div class="children"><div class="content">this is so cool, any chance you post a video?</div><br/></div></div><div id="42787856" class="c"><input type="checkbox" id="c-42787856" checked=""/><div class="controls bullet"><span class="by">droideqa</span><span>|</span><a href="#42785105">parent</a><span>|</span><a href="#42785253">prev</a><span>|</span><a href="#42790521">next</a><span>|</span><label class="collapse" for="c-42787856">[-]</label><label class="expand" for="c-42787856">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s awesome!</div><br/></div></div></div></div><div id="42790521" class="c"><input type="checkbox" id="c-42790521" checked=""/><div class="controls bullet"><span class="by">ceritium</span><span>|</span><a href="#42785105">prev</a><span>|</span><a href="#42788468">next</a><span>|</span><label class="collapse" for="c-42790521">[-]</label><label class="expand" for="c-42790521">[2 more]</label></div><br/><div class="children"><div class="content">I am doing nothing, but I was wondering if it would make sense to combine a small LLM and SQLITE to parse date time human expressions. For example, given a human input like &quot;last day of this month&quot;, the LLM will generate the following query `SELECT date(&#x27;now&#x27;,&#x27;start of month&#x27;,&#x27;+1 month&#x27;,&#x27;-1 day&#x27;);`<p>It is probably super overengineering, considering that pretty good libraries are already doing that on different languages, but it would be funny. I did some tests with chatGPT, and it worked sometimes. It would probably work with some fine-tuning, but I don&#x27;t have the experience or the time right now.</div><br/><div id="42790583" class="c"><input type="checkbox" id="c-42790583" checked=""/><div class="controls bullet"><span class="by">lionkor</span><span>|</span><a href="#42790521">parent</a><span>|</span><a href="#42788468">next</a><span>|</span><label class="collapse" for="c-42790583">[-]</label><label class="expand" for="c-42790583">[1 more]</label></div><br/><div class="children"><div class="content">LLMs tend to REALLY get this wrong. Ask it to generate a query to sum up likes on items uploaded in the last week, defined as the last monday-sunday week (not the last 7 days), and watch it get it subtly wrong almost every time.</div><br/></div></div></div></div><div id="42788468" class="c"><input type="checkbox" id="c-42788468" checked=""/><div class="controls bullet"><span class="by">sidravi1</span><span>|</span><a href="#42790521">prev</a><span>|</span><a href="#42785739">next</a><span>|</span><label class="collapse" for="c-42788468">[-]</label><label class="expand" for="c-42788468">[3 more]</label></div><br/><div class="children"><div class="content">We fine-tuned a Gemma 2B to identify urgent messages sent by new and expecting mothers on a government-run maternal health helpline.<p><a href="https:&#x2F;&#x2F;idinsight.github.io&#x2F;tech-blog&#x2F;blog&#x2F;enhancing_maternal_healthcare&#x2F;" rel="nofollow">https:&#x2F;&#x2F;idinsight.github.io&#x2F;tech-blog&#x2F;blog&#x2F;enhancing_materna...</a></div><br/><div id="42790308" class="c"><input type="checkbox" id="c-42790308" checked=""/><div class="controls bullet"><span class="by">Mashimo</span><span>|</span><a href="#42788468">parent</a><span>|</span><a href="#42788954">next</a><span>|</span><label class="collapse" for="c-42790308">[-]</label><label class="expand" for="c-42790308">[1 more]</label></div><br/><div class="children"><div class="content">Oh that is a nice writeup. We have something similar in mind at work. Will forward it.</div><br/></div></div><div id="42788954" class="c"><input type="checkbox" id="c-42788954" checked=""/><div class="controls bullet"><span class="by">proxygeek</span><span>|</span><a href="#42788468">parent</a><span>|</span><a href="#42790308">prev</a><span>|</span><a href="#42785739">next</a><span>|</span><label class="collapse" for="c-42788954">[-]</label><label class="expand" for="c-42788954">[1 more]</label></div><br/><div class="children"><div class="content">Such a fun thread but this is the kind of applications that perk up my attention!<p>Very cool!</div><br/></div></div></div></div><div id="42785739" class="c"><input type="checkbox" id="c-42785739" checked=""/><div class="controls bullet"><span class="by">flippyhead</span><span>|</span><a href="#42788468">prev</a><span>|</span><a href="#42790399">next</a><span>|</span><label class="collapse" for="c-42785739">[-]</label><label class="expand" for="c-42785739">[12 more]</label></div><br/><div class="children"><div class="content">I have a tiny device that listens to conversations between two people or more and constantly tries to declare a &quot;winner&quot;</div><br/><div id="42787108" class="c"><input type="checkbox" id="c-42787108" checked=""/><div class="controls bullet"><span class="by">mkaic</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42786672">next</a><span>|</span><label class="collapse" for="c-42787108">[-]</label><label class="expand" for="c-42787108">[1 more]</label></div><br/><div class="children"><div class="content">This reminds me of the antics of streamer DougDoug, who often uses LLM APIs to live-summarize, analyze, or interact with his (often multi-thousand-strong) Twitch chat. Most recently I saw him do a GeoGuessr stream where he had ChatGPT assume the role of a detective who must comb through the thousands of chat messages for clues about where the chat thinks the location is, then synthesizes the clamor into a final guess. Aside from constantly being trolled by people spamming nothing but &quot;Kyoto, Japan&quot; in chat, it occasionaly demonstrated a pretty effective incarnation of &quot;the wisdom of the crowd&quot; and was strikingly accurate at times.</div><br/></div></div><div id="42786672" class="c"><input type="checkbox" id="c-42786672" checked=""/><div class="controls bullet"><span class="by">eddd-ddde</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42787108">prev</a><span>|</span><a href="#42785791">next</a><span>|</span><label class="collapse" for="c-42786672">[-]</label><label class="expand" for="c-42786672">[1 more]</label></div><br/><div class="children"><div class="content">I love that there&#x27;s not even a vague idea of the winner &quot;metric&quot; in your explanation. Like it&#x27;s just, _the_ winner.</div><br/></div></div><div id="42785791" class="c"><input type="checkbox" id="c-42785791" checked=""/><div class="controls bullet"><span class="by">oa335</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42786672">prev</a><span>|</span><a href="#42785979">next</a><span>|</span><label class="collapse" for="c-42785791">[-]</label><label class="expand" for="c-42785791">[1 more]</label></div><br/><div class="children"><div class="content">This made me actually laugh out loud.  Can you share more details on hardware and models used?</div><br/></div></div><div id="42785979" class="c"><input type="checkbox" id="c-42785979" checked=""/><div class="controls bullet"><span class="by">jjcm</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42785791">prev</a><span>|</span><a href="#42785949">next</a><span>|</span><label class="collapse" for="c-42785979">[-]</label><label class="expand" for="c-42785979">[1 more]</label></div><br/><div class="children"><div class="content">Are you raising a funding round? I&#x27;m bought in. This is hilarious.</div><br/></div></div><div id="42785949" class="c"><input type="checkbox" id="c-42785949" checked=""/><div class="controls bullet"><span class="by">econ</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42785979">prev</a><span>|</span><a href="#42786455">next</a><span>|</span><label class="collapse" for="c-42785949">[-]</label><label class="expand" for="c-42785949">[1 more]</label></div><br/><div class="children"><div class="content">This is a product I want</div><br/></div></div><div id="42786455" class="c"><input type="checkbox" id="c-42786455" checked=""/><div class="controls bullet"><span class="by">hn8726</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42785949">prev</a><span>|</span><a href="#42785781">next</a><span>|</span><label class="collapse" for="c-42786455">[-]</label><label class="expand" for="c-42786455">[1 more]</label></div><br/><div class="children"><div class="content">What approach&#x2F;stack would you recommend for listening to an ongoing conversation, transcribing it and passing through llm? I had some use cases in mind but I&#x27;m not very familiar with AI frameworks and tools</div><br/></div></div><div id="42785781" class="c"><input type="checkbox" id="c-42785781" checked=""/><div class="controls bullet"><span class="by">pseudosavant</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42786455">prev</a><span>|</span><a href="#42789840">next</a><span>|</span><label class="collapse" for="c-42785781">[-]</label><label class="expand" for="c-42785781">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to hear more about the hardware behind this project. I&#x27;ve had concepts for tech requiring a mic on me at all times for various reasons. Always tricky to have enough power in a reasonable DIY form factor.</div><br/></div></div><div id="42789840" class="c"><input type="checkbox" id="c-42789840" checked=""/><div class="controls bullet"><span class="by">deivid</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42785781">prev</a><span>|</span><a href="#42788937">next</a><span>|</span><label class="collapse" for="c-42789840">[-]</label><label class="expand" for="c-42789840">[1 more]</label></div><br/><div class="children"><div class="content">what model do you use for speech to text?</div><br/></div></div><div id="42788937" class="c"><input type="checkbox" id="c-42788937" checked=""/><div class="controls bullet"><span class="by">prakashn27</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42789840">prev</a><span>|</span><a href="#42785970">next</a><span>|</span><label class="collapse" for="c-42788937">[-]</label><label class="expand" for="c-42788937">[1 more]</label></div><br/><div class="children"><div class="content">wifey always wins. ;)</div><br/></div></div><div id="42785970" class="c"><input type="checkbox" id="c-42785970" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42788937">prev</a><span>|</span><a href="#42788174">next</a><span>|</span><label class="collapse" for="c-42785970">[-]</label><label class="expand" for="c-42785970">[1 more]</label></div><br/><div class="children"><div class="content">You can use the model to generate winning speeches also.</div><br/></div></div><div id="42788174" class="c"><input type="checkbox" id="c-42788174" checked=""/><div class="controls bullet"><span class="by">nejsjsjsbsb</span><span>|</span><a href="#42785739">parent</a><span>|</span><a href="#42785970">prev</a><span>|</span><a href="#42790399">next</a><span>|</span><label class="collapse" for="c-42788174">[-]</label><label class="expand" for="c-42788174">[1 more]</label></div><br/><div class="children"><div class="content">All computation on device?</div><br/></div></div></div></div><div id="42790399" class="c"><input type="checkbox" id="c-42790399" checked=""/><div class="controls bullet"><span class="by">computers3333</span><span>|</span><a href="#42785739">prev</a><span>|</span><a href="#42785938">next</a><span>|</span><label class="collapse" for="c-42790399">[-]</label><label class="expand" for="c-42790399">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;gophersignal.com" rel="nofollow">https:&#x2F;&#x2F;gophersignal.com</a> – I built GopherSignal!<p>It&#x27;s a lightweight tool that summarizes Hacker News articles. I originally used LLaMA 3.2 for the backend, which performs much better, but recently started experimenting with the smaller LLaMA 3.2:1B model.<p>It’s been cool seeing other people’s ideas too. Curious—does anyone have suggestions for small models that are good for summaries?<p>Feel free to check it out or make changes: <a href="https:&#x2F;&#x2F;github.com&#x2F;k-zehnder&#x2F;gophersignal">https:&#x2F;&#x2F;github.com&#x2F;k-zehnder&#x2F;gophersignal</a></div><br/></div></div><div id="42785938" class="c"><input type="checkbox" id="c-42785938" checked=""/><div class="controls bullet"><span class="by">simonjgreen</span><span>|</span><a href="#42790399">prev</a><span>|</span><a href="#42790611">next</a><span>|</span><label class="collapse" for="c-42785938">[-]</label><label class="expand" for="c-42785938">[3 more]</label></div><br/><div class="children"><div class="content">Micro Wake Word is a library and set of on device models for ESPs to wake on a spoken wake word.
<a href="https:&#x2F;&#x2F;github.com&#x2F;kahrendt&#x2F;microWakeWord">https:&#x2F;&#x2F;github.com&#x2F;kahrendt&#x2F;microWakeWord</a><p>Recently deployed in Home Assistants fully local capable Alexa replacement. <a href="https:&#x2F;&#x2F;www.home-assistant.io&#x2F;voice_control&#x2F;about_wake_word&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.home-assistant.io&#x2F;voice_control&#x2F;about_wake_word&#x2F;</a></div><br/><div id="42789733" class="c"><input type="checkbox" id="c-42789733" checked=""/><div class="controls bullet"><span class="by">yzydserd</span><span>|</span><a href="#42785938">parent</a><span>|</span><a href="#42790611">next</a><span>|</span><label class="collapse" for="c-42789733">[-]</label><label class="expand" for="c-42789733">[2 more]</label></div><br/><div class="children"><div class="content">Nice idea.</div><br/><div id="42790246" class="c"><input type="checkbox" id="c-42790246" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#42785938">root</a><span>|</span><a href="#42789733">parent</a><span>|</span><a href="#42790611">next</a><span>|</span><label class="collapse" for="c-42790246">[-]</label><label class="expand" for="c-42790246">[1 more]</label></div><br/><div class="children"><div class="content">Make sure your meeting participants know you’re transcribing them. Has similar notification requirements as recording state to state.</div><br/></div></div></div></div></div></div><div id="42790611" class="c"><input type="checkbox" id="c-42790611" checked=""/><div class="controls bullet"><span class="by">numba888</span><span>|</span><a href="#42785938">prev</a><span>|</span><a href="#42784922">next</a><span>|</span><label class="collapse" for="c-42790611">[-]</label><label class="expand" for="c-42790611">[1 more]</label></div><br/><div class="children"><div class="content">Many interesting projects, cool. I&#x27;m waiting to LLMs in games. That would make them much more fun. Any time now...</div><br/></div></div><div id="42784922" class="c"><input type="checkbox" id="c-42784922" checked=""/><div class="controls bullet"><span class="by">RhysU</span><span>|</span><a href="#42790611">prev</a><span>|</span><a href="#42785041">next</a><span>|</span><label class="collapse" for="c-42784922">[-]</label><label class="expand" for="c-42784922">[2 more]</label></div><br/><div class="children"><div class="content">&quot;Comedy Writing With Small Generative Models&quot; by Jamie Brew (Strange Loop 2023)<p><a href="https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=M2o4f_2L0No" rel="nofollow">https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=M2o4f_2L0No</a><p>Spend the 45 minutes watching this talk. It is a delight. If you are unsure, wait until the speaker picks up the guitar.</div><br/><div id="42784951" class="c"><input type="checkbox" id="c-42784951" checked=""/><div class="controls bullet"><span class="by">100k</span><span>|</span><a href="#42784922">parent</a><span>|</span><a href="#42785041">next</a><span>|</span><label class="collapse" for="c-42784951">[-]</label><label class="expand" for="c-42784951">[1 more]</label></div><br/><div class="children"><div class="content">Seconded! This was my favorite talk at Strange Loop (including my own).</div><br/></div></div></div></div><div id="42785041" class="c"><input type="checkbox" id="c-42785041" checked=""/><div class="controls bullet"><span class="by">azhenley</span><span>|</span><a href="#42784922">prev</a><span>|</span><a href="#42785400">next</a><span>|</span><label class="collapse" for="c-42785041">[-]</label><label class="expand" for="c-42785041">[10 more]</label></div><br/><div class="children"><div class="content">Microsoft published a paper on their FLAME model (60M parameters) for Excel formula repair&#x2F;completion which outperformed much larger models (&gt;100B parameters).<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2301.13779" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2301.13779</a></div><br/><div id="42788633" class="c"><input type="checkbox" id="c-42788633" checked=""/><div class="controls bullet"><span class="by">coder543</span><span>|</span><a href="#42785041">parent</a><span>|</span><a href="#42785415">next</a><span>|</span><label class="collapse" for="c-42788633">[-]</label><label class="expand" for="c-42788633">[1 more]</label></div><br/><div class="children"><div class="content">That paper is from over a year ago, and it compared against codex-davinci... which was basically GPT-3, from what I understand. Saying &gt;100B makes it sound a lot more impressive than it is in today&#x27;s context... 100B models today are a <i>lot</i> more capable. The researchers also compared against a couple of other ancient(&#x2F;irrelevant today), small models that don&#x27;t give me much insight.<p>FLAME seems like a fun little model, and 60M is truly tiny compared to other LLMs, but I have no idea how good it is in today&#x27;s context, and it doesn&#x27;t seem like they ever released it.</div><br/></div></div><div id="42785415" class="c"><input type="checkbox" id="c-42785415" checked=""/><div class="controls bullet"><span class="by">andai</span><span>|</span><a href="#42785041">parent</a><span>|</span><a href="#42788633">prev</a><span>|</span><a href="#42785673">next</a><span>|</span><label class="collapse" for="c-42785415">[-]</label><label class="expand" for="c-42785415">[1 more]</label></div><br/><div class="children"><div class="content">This is wild. They claim it was trained exclusively on Excel formulas, but then they mention retrieval? Is it understanding the connection between English and formulas? Or am I misunderstanding retrieval in this context?<p>Edit: No, the retrieval is Formula-Formula, the model (nor I believe tokenizer) does not handle English.</div><br/></div></div><div id="42785673" class="c"><input type="checkbox" id="c-42785673" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#42785041">parent</a><span>|</span><a href="#42785415">prev</a><span>|</span><a href="#42785270">next</a><span>|</span><label class="collapse" for="c-42785673">[-]</label><label class="expand" for="c-42785673">[6 more]</label></div><br/><div class="children"><div class="content">But I feel we&#x27;re going back full circle. These small models are not generalist, thus not really LLMs at least in terms of objective. Recently there has been a rise of &quot;specialized&quot; models that provide lots of values, but that&#x27;s not why we were sold on LLMs.</div><br/><div id="42786287" class="c"><input type="checkbox" id="c-42786287" checked=""/><div class="controls bullet"><span class="by">Suppafly</span><span>|</span><a href="#42785041">root</a><span>|</span><a href="#42785673">parent</a><span>|</span><a href="#42785764">next</a><span>|</span><label class="collapse" for="c-42786287">[-]</label><label class="expand" for="c-42786287">[1 more]</label></div><br/><div class="children"><div class="content">Specialized models work much better still for most stuff. Really we need an LLM to understand the input and then hand it off to a specialized model that actually provides good results.</div><br/></div></div><div id="42785764" class="c"><input type="checkbox" id="c-42785764" checked=""/><div class="controls bullet"><span class="by">colechristensen</span><span>|</span><a href="#42785041">root</a><span>|</span><a href="#42785673">parent</a><span>|</span><a href="#42786287">prev</a><span>|</span><a href="#42786397">next</a><span>|</span><label class="collapse" for="c-42785764">[-]</label><label class="expand" for="c-42785764">[3 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s the thing, I don&#x27;t need my ML model to be able to write me a sonnet about the history of beets, especially if I want to run it at home for specific tasks like as a programming assistant.<p>I&#x27;m fine with and prefer specialist models in most cases.</div><br/><div id="42786703" class="c"><input type="checkbox" id="c-42786703" checked=""/><div class="controls bullet"><span class="by">zeroCalories</span><span>|</span><a href="#42785041">root</a><span>|</span><a href="#42785764">parent</a><span>|</span><a href="#42786397">next</a><span>|</span><label class="collapse" for="c-42786703">[-]</label><label class="expand" for="c-42786703">[2 more]</label></div><br/><div class="children"><div class="content">I would love a model that knows SQL really well so I don&#x27;t need to remember all the small details of the language. Beyond that, I don&#x27;t see why the transformer architecture can&#x27;t be applied to any problem that needs to predict sequences.</div><br/><div id="42787370" class="c"><input type="checkbox" id="c-42787370" checked=""/><div class="controls bullet"><span class="by">dr_kiszonka</span><span>|</span><a href="#42785041">root</a><span>|</span><a href="#42786703">parent</a><span>|</span><a href="#42786397">next</a><span>|</span><label class="collapse" for="c-42787370">[-]</label><label class="expand" for="c-42787370">[1 more]</label></div><br/><div class="children"><div class="content">The trick is to find such problems with enough training data and some market potential. I am terrible at it.</div><br/></div></div></div></div></div></div><div id="42786397" class="c"><input type="checkbox" id="c-42786397" checked=""/><div class="controls bullet"><span class="by">janalsncm</span><span>|</span><a href="#42785041">root</a><span>|</span><a href="#42785673">parent</a><span>|</span><a href="#42785764">prev</a><span>|</span><a href="#42785270">next</a><span>|</span><label class="collapse" for="c-42786397">[-]</label><label class="expand" for="c-42786397">[1 more]</label></div><br/><div class="children"><div class="content">I think playing word games about what really counts as an LLM is a losing battle. It has become a marketing term, mostly. It’s better to have a functionalist point of view of “what can this thing do”.</div><br/></div></div></div></div><div id="42785270" class="c"><input type="checkbox" id="c-42785270" checked=""/><div class="controls bullet"><span class="by">barrenko</span><span>|</span><a href="#42785041">parent</a><span>|</span><a href="#42785673">prev</a><span>|</span><a href="#42785400">next</a><span>|</span><label class="collapse" for="c-42785270">[-]</label><label class="expand" for="c-42785270">[1 more]</label></div><br/><div class="children"><div class="content">This is really cool. Is this already in Excel?</div><br/></div></div></div></div><div id="42785400" class="c"><input type="checkbox" id="c-42785400" checked=""/><div class="controls bullet"><span class="by">deet</span><span>|</span><a href="#42785041">prev</a><span>|</span><a href="#42784724">next</a><span>|</span><label class="collapse" for="c-42785400">[-]</label><label class="expand" for="c-42785400">[1 more]</label></div><br/><div class="children"><div class="content">We (avy.ai) are using models in that range to analyze computer activity on-device, in a privacy sensitive way, to help knowledge workers as they go about their day.<p>The local models do things ranging from cleaning up OCR, to summarizing meetings, to estimating the user&#x27;s current goals and activity, to predicting search terms, to predicting queries and actions that, if run, would help the user accomplish their current task.<p>The capabilities of these tiny models have really surged recently. Even small vision models are becoming useful, especially if fine tuned.</div><br/></div></div><div id="42784724" class="c"><input type="checkbox" id="c-42784724" checked=""/><div class="controls bullet"><span class="by">mettamage</span><span>|</span><a href="#42785400">prev</a><span>|</span><a href="#42787767">next</a><span>|</span><label class="collapse" for="c-42784724">[-]</label><label class="expand" for="c-42784724">[11 more]</label></div><br/><div class="children"><div class="content">I simply use it to de-anonymize code that I typed in via Claude<p>Maybe should write a plugin for it (open source):<p>1. Put in all your work related questions in the plugin, an LLM will make it as an abstract question for you to preview and send it<p>2. And then get the answer with all the data back<p>E.g. df[“cookie_company_name”] becomes df[“a”] and back</div><br/><div id="42785696" class="c"><input type="checkbox" id="c-42785696" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#42784724">parent</a><span>|</span><a href="#42784789">next</a><span>|</span><label class="collapse" for="c-42785696">[-]</label><label class="expand" for="c-42785696">[2 more]</label></div><br/><div class="children"><div class="content">So you are using a local small model to remove identifying information and make the question generic, which is then sent to a larger model? Is that understanding correct?<p>I think this would have some additional benefits of not confusing the larger model with facts it doesn&#x27;t need to know about. My erasing information, you can allow its attention heads to focus on the pieces that matter.<p>Requires further study.</div><br/><div id="42790194" class="c"><input type="checkbox" id="c-42790194" checked=""/><div class="controls bullet"><span class="by">mettamage</span><span>|</span><a href="#42784724">root</a><span>|</span><a href="#42785696">parent</a><span>|</span><a href="#42784789">next</a><span>|</span><label class="collapse" for="c-42790194">[-]</label><label class="expand" for="c-42790194">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So you are using a local small model to remove identifying information and make the question generic, which is then sent to a larger model? Is that understanding correct?<p>Yep that&#x27;s it</div><br/></div></div></div></div><div id="42784789" class="c"><input type="checkbox" id="c-42784789" checked=""/><div class="controls bullet"><span class="by">politelemon</span><span>|</span><a href="#42784724">parent</a><span>|</span><a href="#42785696">prev</a><span>|</span><a href="#42788777">next</a><span>|</span><label class="collapse" for="c-42784789">[-]</label><label class="expand" for="c-42784789">[5 more]</label></div><br/><div class="children"><div class="content">Could you recommend a tiny language model I could try out locally?</div><br/><div id="42784953" class="c"><input type="checkbox" id="c-42784953" checked=""/><div class="controls bullet"><span class="by">mettamage</span><span>|</span><a href="#42784724">root</a><span>|</span><a href="#42784789">parent</a><span>|</span><a href="#42788777">next</a><span>|</span><label class="collapse" for="c-42784953">[-]</label><label class="expand" for="c-42784953">[4 more]</label></div><br/><div class="children"><div class="content">Llama 3.2 has about 3.2b parameters. I have to admit, I use bigger ones like phi-4 (14.7b) and Llama 3.3 (70.6b) but I think Llama 3.2 could do de-anonimization and anonimization of code</div><br/><div id="42785057" class="c"><input type="checkbox" id="c-42785057" checked=""/><div class="controls bullet"><span class="by">OxfordOutlander</span><span>|</span><a href="#42784724">root</a><span>|</span><a href="#42784953">parent</a><span>|</span><a href="#42785333">next</a><span>|</span><label class="collapse" for="c-42785057">[-]</label><label class="expand" for="c-42785057">[1 more]</label></div><br/><div class="children"><div class="content">+1 this idea. I do the same. Just do it locally using ollama, also using 3.2 3b</div><br/></div></div><div id="42785333" class="c"><input type="checkbox" id="c-42785333" checked=""/><div class="controls bullet"><span class="by">RicoElectrico</span><span>|</span><a href="#42784724">root</a><span>|</span><a href="#42784953">parent</a><span>|</span><a href="#42785057">prev</a><span>|</span><a href="#42788777">next</a><span>|</span><label class="collapse" for="c-42785333">[-]</label><label class="expand" for="c-42785333">[2 more]</label></div><br/><div class="children"><div class="content">Llama 3.2 punches way above its weight. For general &quot;language manipulation&quot; tasks it&#x27;s good enough - and it can be used on a CPU with acceptable speed.</div><br/><div id="42785773" class="c"><input type="checkbox" id="c-42785773" checked=""/><div class="controls bullet"><span class="by">seunosewa</span><span>|</span><a href="#42784724">root</a><span>|</span><a href="#42785333">parent</a><span>|</span><a href="#42788777">next</a><span>|</span><label class="collapse" for="c-42785773">[-]</label><label class="expand" for="c-42785773">[1 more]</label></div><br/><div class="children"><div class="content">How many tokens&#x2F;s?</div><br/></div></div></div></div></div></div></div></div><div id="42788777" class="c"><input type="checkbox" id="c-42788777" checked=""/><div class="controls bullet"><span class="by">sundarurfriend</span><span>|</span><a href="#42784724">parent</a><span>|</span><a href="#42784789">prev</a><span>|</span><a href="#42785808">next</a><span>|</span><label class="collapse" for="c-42788777">[-]</label><label class="expand" for="c-42788777">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re using it to <i>anonymize</i> your code, not de-anonymize someone&#x27;s code. I was confused by your comment until I read the replies and realized that&#x27;s what you meant to say.</div><br/><div id="42790197" class="c"><input type="checkbox" id="c-42790197" checked=""/><div class="controls bullet"><span class="by">kreyenborgi</span><span>|</span><a href="#42784724">root</a><span>|</span><a href="#42788777">parent</a><span>|</span><a href="#42785808">next</a><span>|</span><label class="collapse" for="c-42790197">[-]</label><label class="expand" for="c-42790197">[1 more]</label></div><br/><div class="children"><div class="content">I read it the other way, their code contains eg fetch(url, pw:hunter123), and they&#x27;re asking Claude anonymized questions like 
&quot;implement handler for fetch(url, {pw:mycleartrxtpw})&quot;<p>And then claude replies<p>fetch(url, {pw:mycleartrxtpw}).then(writething)<p>And then the local llm converts the placeholder mycleartrxtpw into hunter123 using its access to the real code</div><br/></div></div></div></div><div id="42785808" class="c"><input type="checkbox" id="c-42785808" checked=""/><div class="controls bullet"><span class="by">sauwan</span><span>|</span><a href="#42784724">parent</a><span>|</span><a href="#42788777">prev</a><span>|</span><a href="#42787767">next</a><span>|</span><label class="collapse" for="c-42785808">[-]</label><label class="expand" for="c-42785808">[1 more]</label></div><br/><div class="children"><div class="content">Are you using the model to create a key-value pair to find&#x2F;replace and then reverse to reanonymize, or are you using its outputs directly? If the latter, is it fast enough and reliable enough?</div><br/></div></div></div></div><div id="42787767" class="c"><input type="checkbox" id="c-42787767" checked=""/><div class="controls bullet"><span class="by">jwitthuhn</span><span>|</span><a href="#42784724">prev</a><span>|</span><a href="#42786354">next</a><span>|</span><label class="collapse" for="c-42787767">[-]</label><label class="expand" for="c-42787767">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve made a tiny ~1m parameter model that can generate random Magic the Gathering cards that is largely based on Karpathy&#x27;s nanogpt with a few more features added on top.<p>I don&#x27;t have a pre-trained model to share but you can make one yourself from the git repo, assuming you have an apple silicon mac.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;jlwitthuhn&#x2F;TCGGPT">https:&#x2F;&#x2F;github.com&#x2F;jlwitthuhn&#x2F;TCGGPT</a></div><br/></div></div><div id="42786354" class="c"><input type="checkbox" id="c-42786354" checked=""/><div class="controls bullet"><span class="by">ata_aman</span><span>|</span><a href="#42787767">prev</a><span>|</span><a href="#42788651">next</a><span>|</span><label class="collapse" for="c-42786354">[-]</label><label class="expand" for="c-42786354">[3 more]</label></div><br/><div class="children"><div class="content">I have it running on a Raspberry Pi 5 for offline chat and RAG.
I wrote this open-source code for it: <a href="https:&#x2F;&#x2F;github.com&#x2F;persys-ai&#x2F;persys">https:&#x2F;&#x2F;github.com&#x2F;persys-ai&#x2F;persys</a><p>It also does RAG on apps there, like the music player, contacts app and to-do app. I can ask it to recommend similar artists to listen to based on my music library for example or ask it to quiz me on my PDF papers.</div><br/><div id="42788228" class="c"><input type="checkbox" id="c-42788228" checked=""/><div class="controls bullet"><span class="by">nejsjsjsbsb</span><span>|</span><a href="#42786354">parent</a><span>|</span><a href="#42788651">next</a><span>|</span><label class="collapse" for="c-42788228">[-]</label><label class="expand" for="c-42788228">[2 more]</label></div><br/><div class="children"><div class="content">Does <a href="https:&#x2F;&#x2F;github.com&#x2F;persys-ai&#x2F;persys-server">https:&#x2F;&#x2F;github.com&#x2F;persys-ai&#x2F;persys-server</a> run on the rpi?<p>Is that design 3d printable? Or is that for paid users only.</div><br/><div id="42788718" class="c"><input type="checkbox" id="c-42788718" checked=""/><div class="controls bullet"><span class="by">ata_aman</span><span>|</span><a href="#42786354">root</a><span>|</span><a href="#42788228">parent</a><span>|</span><a href="#42788651">next</a><span>|</span><label class="collapse" for="c-42788718">[-]</label><label class="expand" for="c-42788718">[1 more]</label></div><br/><div class="children"><div class="content">I can publish it no problem. I’ll create a new repo with instructions for the hardware with CAD files.<p>Designing a new one for the NVIDIA Orin Nano Super so it might take a few days.</div><br/></div></div></div></div></div></div><div id="42788651" class="c"><input type="checkbox" id="c-42788651" checked=""/><div class="controls bullet"><span class="by">gpm</span><span>|</span><a href="#42786354">prev</a><span>|</span><a href="#42784612">next</a><span>|</span><label class="collapse" for="c-42788651">[-]</label><label class="expand" for="c-42788651">[2 more]</label></div><br/><div class="children"><div class="content">I made a shell alias to translate things from French to English, does that count?<p><pre><code>    function trans
        llm &quot;Translate \&quot;$argv\&quot; from French to English please&quot;
    end
</code></pre>
Llama 3.2:3b is a fine French-English dictionary IMHO.</div><br/><div id="42790203" class="c"><input type="checkbox" id="c-42790203" checked=""/><div class="controls bullet"><span class="by">kreyenborgi</span><span>|</span><a href="#42788651">parent</a><span>|</span><a href="#42784612">next</a><span>|</span><label class="collapse" for="c-42790203">[-]</label><label class="expand" for="c-42790203">[1 more]</label></div><br/><div class="children"><div class="content">Is it better than translatelocally? <a href="https:&#x2F;&#x2F;translatelocally.com&#x2F;downloads&#x2F;" rel="nofollow">https:&#x2F;&#x2F;translatelocally.com&#x2F;downloads&#x2F;</a> (the same as used in firefox)</div><br/></div></div></div></div><div id="42784612" class="c"><input type="checkbox" id="c-42784612" checked=""/><div class="controls bullet"><span class="by">psyklic</span><span>|</span><a href="#42788651">prev</a><span>|</span><a href="#42787549">next</a><span>|</span><label class="collapse" for="c-42784612">[-]</label><label class="expand" for="c-42784612">[12 more]</label></div><br/><div class="children"><div class="content">JetBrains&#x27; local single-line autocomplete model is 0.1B (w&#x2F; 1536-token context, ~170 lines of code): <a href="https:&#x2F;&#x2F;blog.jetbrains.com&#x2F;blog&#x2F;2024&#x2F;04&#x2F;04&#x2F;full-line-code-completion-in-jetbrains-ides-all-you-need-to-know&#x2F;#under-the-hood" rel="nofollow">https:&#x2F;&#x2F;blog.jetbrains.com&#x2F;blog&#x2F;2024&#x2F;04&#x2F;04&#x2F;full-line-code-co...</a><p>For context, GPT-2-small is 0.124B params (w&#x2F; 1024-token context).</div><br/><div id="42785838" class="c"><input type="checkbox" id="c-42785838" checked=""/><div class="controls bullet"><span class="by">pseudosavant</span><span>|</span><a href="#42784612">parent</a><span>|</span><a href="#42785728">next</a><span>|</span><label class="collapse" for="c-42785838">[-]</label><label class="expand" for="c-42785838">[5 more]</label></div><br/><div class="children"><div class="content">I wonder how big that model is in RAM&#x2F;disk. I use LLMs for FFMPEG all the time, and I was thinking about training a model on just the FFMPEG CLI arguments. If it was small enough, it could be a package for FFMPEG. e.g. `ffmpeg llm &quot;Convert this MP4 into the latest royalty-free codecs in an MKV.&quot;`</div><br/><div id="42786381" class="c"><input type="checkbox" id="c-42786381" checked=""/><div class="controls bullet"><span class="by">h0l0cube</span><span>|</span><a href="#42784612">root</a><span>|</span><a href="#42785838">parent</a><span>|</span><a href="#42785929">next</a><span>|</span><label class="collapse" for="c-42786381">[-]</label><label class="expand" for="c-42786381">[1 more]</label></div><br/><div class="children"><div class="content">Please submit a blog post to HN when you&#x27;re done.  I&#x27;d be curious to know the most minimal LLM setup needed get consistently sane output for FFMPEG parameters.</div><br/></div></div><div id="42785929" class="c"><input type="checkbox" id="c-42785929" checked=""/><div class="controls bullet"><span class="by">jedbrooke</span><span>|</span><a href="#42784612">root</a><span>|</span><a href="#42785838">parent</a><span>|</span><a href="#42786381">prev</a><span>|</span><a href="#42787136">next</a><span>|</span><label class="collapse" for="c-42785929">[-]</label><label class="expand" for="c-42785929">[1 more]</label></div><br/><div class="children"><div class="content">the jetbrains models are about 70MB zipped on disk (one model per language)</div><br/></div></div><div id="42787136" class="c"><input type="checkbox" id="c-42787136" checked=""/><div class="controls bullet"><span class="by">binary132</span><span>|</span><a href="#42784612">root</a><span>|</span><a href="#42785838">parent</a><span>|</span><a href="#42785929">prev</a><span>|</span><a href="#42786629">next</a><span>|</span><label class="collapse" for="c-42787136">[-]</label><label class="expand" for="c-42787136">[1 more]</label></div><br/><div class="children"><div class="content">That’s a great idea, but I feel like it might be hard to get it to be correct enough</div><br/></div></div><div id="42786629" class="c"><input type="checkbox" id="c-42786629" checked=""/><div class="controls bullet"><span class="by">maujim</span><span>|</span><a href="#42784612">root</a><span>|</span><a href="#42785838">parent</a><span>|</span><a href="#42787136">prev</a><span>|</span><a href="#42785728">next</a><span>|</span><label class="collapse" for="c-42786629">[-]</label><label class="expand" for="c-42786629">[1 more]</label></div><br/><div class="children"><div class="content">from a few days ago: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42706637">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=42706637</a></div><br/></div></div></div></div><div id="42785728" class="c"><input type="checkbox" id="c-42785728" checked=""/><div class="controls bullet"><span class="by">smaddox</span><span>|</span><a href="#42784612">parent</a><span>|</span><a href="#42785838">prev</a><span>|</span><a href="#42785009">next</a><span>|</span><label class="collapse" for="c-42785728">[-]</label><label class="expand" for="c-42785728">[1 more]</label></div><br/><div class="children"><div class="content">You can train that size of a model on ~1 billion tokens in ~3 minutes on a rented 8xH100 80GB node (~$9&#x2F;hr on Lambda Labs, RunPod io, etc.) using the NanoGPT speed run repo: <a href="https:&#x2F;&#x2F;github.com&#x2F;KellerJordan&#x2F;modded-nanogpt">https:&#x2F;&#x2F;github.com&#x2F;KellerJordan&#x2F;modded-nanogpt</a><p>For that short of a run, you&#x27;ll spend more time waiting for the node to come up, downloading the dataset, and compiling the model, though.</div><br/></div></div><div id="42785009" class="c"><input type="checkbox" id="c-42785009" checked=""/><div class="controls bullet"><span class="by">WithinReason</span><span>|</span><a href="#42784612">parent</a><span>|</span><a href="#42785728">prev</a><span>|</span><a href="#42786326">next</a><span>|</span><label class="collapse" for="c-42785009">[-]</label><label class="expand" for="c-42785009">[4 more]</label></div><br/><div class="children"><div class="content">That size is on the edge of something you can train at home</div><br/><div id="42785431" class="c"><input type="checkbox" id="c-42785431" checked=""/><div class="controls bullet"><span class="by">vineyardmike</span><span>|</span><a href="#42784612">root</a><span>|</span><a href="#42785009">parent</a><span>|</span><a href="#42786773">next</a><span>|</span><label class="collapse" for="c-42785431">[-]</label><label class="expand" for="c-42785431">[2 more]</label></div><br/><div class="children"><div class="content">If you have modern hardware, you can absolutely train that at home. Or <i>very</i> affordable on a cloud service.<p>I’ve seen a number of “DIY GPT-2” tutorials that target this sweet spot. You won’t get amazing results unless you want to leave a personal computer running for a number of hours&#x2F;days and you have solid data to train on locally, but fine-tuning should be in the realm of normal hobbyists patience.</div><br/><div id="42785617" class="c"><input type="checkbox" id="c-42785617" checked=""/><div class="controls bullet"><span class="by">nottorp</span><span>|</span><a href="#42784612">root</a><span>|</span><a href="#42785431">parent</a><span>|</span><a href="#42786773">next</a><span>|</span><label class="collapse" for="c-42785617">[-]</label><label class="expand" for="c-42785617">[1 more]</label></div><br/><div class="children"><div class="content">Hmm is there anything reasonably ready made* for this spot? Training and querying a llm locally on an existing codebase?<p>* I don&#x27;t mind compiling it myself but i&#x27;d rather not write it.</div><br/></div></div></div></div><div id="42786773" class="c"><input type="checkbox" id="c-42786773" checked=""/><div class="controls bullet"><span class="by">Sohcahtoa82</span><span>|</span><a href="#42784612">root</a><span>|</span><a href="#42785009">parent</a><span>|</span><a href="#42785431">prev</a><span>|</span><a href="#42786326">next</a><span>|</span><label class="collapse" for="c-42786773">[-]</label><label class="expand" for="c-42786773">[1 more]</label></div><br/><div class="children"><div class="content">Not even on the edge.  That&#x27;s something you could train on a 2 GB GPU.<p>The general guidance I&#x27;ve used is that to train a model, you need an amount of RAM (or VRAM) equal to 8x the number of parameters, so a 0.125B model would need 1 GB of RAM to train.</div><br/></div></div></div></div><div id="42786326" class="c"><input type="checkbox" id="c-42786326" checked=""/><div class="controls bullet"><span class="by">staticautomatic</span><span>|</span><a href="#42784612">parent</a><span>|</span><a href="#42785009">prev</a><span>|</span><a href="#42787549">next</a><span>|</span><label class="collapse" for="c-42786326">[-]</label><label class="expand" for="c-42786326">[1 more]</label></div><br/><div class="children"><div class="content">Is that why their tab completion is so bad now?</div><br/></div></div></div></div><div id="42787549" class="c"><input type="checkbox" id="c-42787549" checked=""/><div class="controls bullet"><span class="by">JLCarveth</span><span>|</span><a href="#42784612">prev</a><span>|</span><a href="#42789518">next</a><span>|</span><label class="collapse" for="c-42787549">[-]</label><label class="expand" for="c-42787549">[3 more]</label></div><br/><div class="children"><div class="content">I used a small (3b, I think) model plus tesseract.js to perform OCR on an image of a nutritional facts table and output structured JSON.</div><br/><div id="42789249" class="c"><input type="checkbox" id="c-42789249" checked=""/><div class="controls bullet"><span class="by">deivid</span><span>|</span><a href="#42787549">parent</a><span>|</span><a href="#42789735">next</a><span>|</span><label class="collapse" for="c-42789249">[-]</label><label class="expand" for="c-42789249">[1 more]</label></div><br/><div class="children"><div class="content">What was the model? What kind of performance did you get out of it?<p>Could you share a link to your project, if it is public?</div><br/></div></div><div id="42789735" class="c"><input type="checkbox" id="c-42789735" checked=""/><div class="controls bullet"><span class="by">tigrank</span><span>|</span><a href="#42787549">parent</a><span>|</span><a href="#42789249">prev</a><span>|</span><a href="#42789518">next</a><span>|</span><label class="collapse" for="c-42789735">[-]</label><label class="expand" for="c-42789735">[1 more]</label></div><br/><div class="children"><div class="content">All that server side or client?</div><br/></div></div></div></div><div id="42789518" class="c"><input type="checkbox" id="c-42789518" checked=""/><div class="controls bullet"><span class="by">sauravpanda</span><span>|</span><a href="#42787549">prev</a><span>|</span><a href="#42786422">next</a><span>|</span><label class="collapse" for="c-42789518">[-]</label><label class="expand" for="c-42789518">[1 more]</label></div><br/><div class="children"><div class="content">We are building a framework to run this tiny language model in the web so anyone can access private LLMs in their browser: <a href="https:&#x2F;&#x2F;github.com&#x2F;sauravpanda&#x2F;BrowserAI">https:&#x2F;&#x2F;github.com&#x2F;sauravpanda&#x2F;BrowserAI</a>.<p>With just three lines of code, you can run Small LLM models inside the browser. We feel this unlocks a ton of potential for businesses so that they can introduce AI without fear of cost and can personalize the experience using AI.<p>Would love your thoughts and what we can do more or better!</div><br/></div></div><div id="42786422" class="c"><input type="checkbox" id="c-42786422" checked=""/><div class="controls bullet"><span class="by">deivid</span><span>|</span><a href="#42789518">prev</a><span>|</span><a href="#42790226">next</a><span>|</span><label class="collapse" for="c-42786422">[-]</label><label class="expand" for="c-42786422">[4 more]</label></div><br/><div class="children"><div class="content">Not sure it qualifies, but I&#x27;ve started building an Android app that wraps bergamot[0] (the firefox translation models) to have on-device translation without reliance on google.<p>Bergamot is already used inside firefox, but I wanted translation also outside the browser.<p>[0]: bergamot <a href="https:&#x2F;&#x2F;github.com&#x2F;browsermt&#x2F;bergamot-translator">https:&#x2F;&#x2F;github.com&#x2F;browsermt&#x2F;bergamot-translator</a></div><br/><div id="42789246" class="c"><input type="checkbox" id="c-42789246" checked=""/><div class="controls bullet"><span class="by">deivid</span><span>|</span><a href="#42786422">parent</a><span>|</span><a href="#42786996">next</a><span>|</span><label class="collapse" for="c-42789246">[-]</label><label class="expand" for="c-42789246">[2 more]</label></div><br/><div class="children"><div class="content">I would be very interested if someone is aware of any small&#x2F;tiny models to perform OCR, so the app can translate pictures as well</div><br/><div id="42789882" class="c"><input type="checkbox" id="c-42789882" checked=""/><div class="controls bullet"><span class="by">Eisenstein</span><span>|</span><a href="#42786422">root</a><span>|</span><a href="#42789246">parent</a><span>|</span><a href="#42786996">next</a><span>|</span><label class="collapse" for="c-42789882">[-]</label><label class="expand" for="c-42789882">[1 more]</label></div><br/><div class="children"><div class="content">MiniCPM-V 2.6 isn&#x27;t that small (8b) but it can do this.<p>Here is a demo.<p>* <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;pAuTeAf.jpeg" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;pAuTeAf.jpeg</a><p>Using this script:<p>* <a href="https:&#x2F;&#x2F;github.com&#x2F;jabberjabberjabber&#x2F;LLMOCR&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;jabberjabberjabber&#x2F;LLMOCR&#x2F;</a></div><br/></div></div></div></div></div></div><div id="42790226" class="c"><input type="checkbox" id="c-42790226" checked=""/><div class="controls bullet"><span class="by">evacchi</span><span>|</span><a href="#42786422">prev</a><span>|</span><a href="#42785183">next</a><span>|</span><label class="collapse" for="c-42790226">[-]</label><label class="expand" for="c-42790226">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m interested in finding tiny models to create workflows stringing together several function&#x2F;tools and running them on device using mcp.run servlets on Android (disclaimer: I work on that)</div><br/></div></div><div id="42785183" class="c"><input type="checkbox" id="c-42785183" checked=""/><div class="controls bullet"><span class="by">eb0la</span><span>|</span><a href="#42790226">prev</a><span>|</span><a href="#42785570">next</a><span>|</span><label class="collapse" for="c-42785183">[-]</label><label class="expand" for="c-42785183">[2 more]</label></div><br/><div class="children"><div class="content">We&#x27;re using small language models to detect prompt injection. Not too cool, but at least we can publish some AI-related stuff on the internet without a huge bill.</div><br/><div id="42785713" class="c"><input type="checkbox" id="c-42785713" checked=""/><div class="controls bullet"><span class="by">sitkack</span><span>|</span><a href="#42785183">parent</a><span>|</span><a href="#42785570">next</a><span>|</span><label class="collapse" for="c-42785713">[-]</label><label class="expand" for="c-42785713">[1 more]</label></div><br/><div class="children"><div class="content">What kind of prompt injection attacks do you filter out? Have you tested with a prompt tuning framework?</div><br/></div></div></div></div><div id="42785570" class="c"><input type="checkbox" id="c-42785570" checked=""/><div class="controls bullet"><span class="by">mritchie712</span><span>|</span><a href="#42785183">prev</a><span>|</span><a href="#42786641">next</a><span>|</span><label class="collapse" for="c-42785570">[-]</label><label class="expand" for="c-42785570">[3 more]</label></div><br/><div class="children"><div class="content">I used local LLMs via Ollama for generating H1&#x27;s &#x2F; marketing copy.<p>1. Create several different personas<p>2. Generate a ton of variation using a high temperature<p>3. Compare the variagtions head-to-head using the LLM to get a win &#x2F; loss ratio<p>The best ones can be quite good.<p>0 - <a href="https:&#x2F;&#x2F;www.definite.app&#x2F;blog&#x2F;overkillm" rel="nofollow">https:&#x2F;&#x2F;www.definite.app&#x2F;blog&#x2F;overkillm</a></div><br/><div id="42790343" class="c"><input type="checkbox" id="c-42790343" checked=""/><div class="controls bullet"><span class="by">Mashimo</span><span>|</span><a href="#42785570">parent</a><span>|</span><a href="#42788292">next</a><span>|</span><label class="collapse" for="c-42790343">[-]</label><label class="expand" for="c-42790343">[1 more]</label></div><br/><div class="children"><div class="content">What is an H1?</div><br/></div></div><div id="42788292" class="c"><input type="checkbox" id="c-42788292" checked=""/><div class="controls bullet"><span class="by">UltraSane</span><span>|</span><a href="#42785570">parent</a><span>|</span><a href="#42790343">prev</a><span>|</span><a href="#42786641">next</a><span>|</span><label class="collapse" for="c-42788292">[-]</label><label class="expand" for="c-42788292">[1 more]</label></div><br/><div class="children"><div class="content">clever name!</div><br/></div></div></div></div><div id="42786641" class="c"><input type="checkbox" id="c-42786641" checked=""/><div class="controls bullet"><span class="by">cwmoore</span><span>|</span><a href="#42785570">prev</a><span>|</span><a href="#42784970">next</a><span>|</span><label class="collapse" for="c-42786641">[-]</label><label class="expand" for="c-42786641">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m playing with the idea of identifying logical fallacies stated by live broadcasters.</div><br/><div id="42787653" class="c"><input type="checkbox" id="c-42787653" checked=""/><div class="controls bullet"><span class="by">genewitch</span><span>|</span><a href="#42786641">parent</a><span>|</span><a href="#42788889">next</a><span>|</span><label class="collapse" for="c-42787653">[-]</label><label class="expand" for="c-42787653">[1 more]</label></div><br/><div class="children"><div class="content">I have several rhetoric and logic books of the sort you might use for  training or whatever, and one of my best friends got a doctorate in a tangential field, and may have materials and insights.<p>We actually just threw a relationship curative app online in 17 hours around Thanksgiving., so they &quot;owe&quot; me, as it were.<p>I&#x27;m one of those people that can do  anything practical with tech and the like, but I have no imagination for it - so when someone mentions something that I think would be beneficial for my fellow humans I get this immense desire to at least cheer on if not ask to help.</div><br/></div></div><div id="42788889" class="c"><input type="checkbox" id="c-42788889" checked=""/><div class="controls bullet"><span class="by">JayStavis</span><span>|</span><a href="#42786641">parent</a><span>|</span><a href="#42787653">prev</a><span>|</span><a href="#42787010">next</a><span>|</span><label class="collapse" for="c-42788889">[-]</label><label class="expand" for="c-42788889">[1 more]</label></div><br/><div class="children"><div class="content">Automation to identify logical&#x2F;rhetorical fallacies is a long held dream of mine, would love to follow along with this project if it picks up somehow</div><br/></div></div><div id="42787010" class="c"><input type="checkbox" id="c-42787010" checked=""/><div class="controls bullet"><span class="by">spiritplumber</span><span>|</span><a href="#42786641">parent</a><span>|</span><a href="#42788889">prev</a><span>|</span><a href="#42788090">next</a><span>|</span><label class="collapse" for="c-42787010">[-]</label><label class="expand" for="c-42787010">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s fantastic and I&#x27;d love to help</div><br/><div id="42787121" class="c"><input type="checkbox" id="c-42787121" checked=""/><div class="controls bullet"><span class="by">cwmoore</span><span>|</span><a href="#42786641">root</a><span>|</span><a href="#42787010">parent</a><span>|</span><a href="#42788090">next</a><span>|</span><label class="collapse" for="c-42787121">[-]</label><label class="expand" for="c-42787121">[1 more]</label></div><br/><div class="children"><div class="content">So far not much beyond this list of targets to identify <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_fallacies" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_fallacies</a></div><br/></div></div></div></div><div id="42788090" class="c"><input type="checkbox" id="c-42788090" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#42786641">parent</a><span>|</span><a href="#42787010">prev</a><span>|</span><a href="#42784970">next</a><span>|</span><label class="collapse" for="c-42788090">[-]</label><label class="expand" for="c-42788090">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll be very positively impressed if you make this work; I spend all day every day for work trying to make more capable models perform basic reasoning, and often failing :-P</div><br/></div></div></div></div><div id="42784970" class="c"><input type="checkbox" id="c-42784970" checked=""/><div class="controls bullet"><span class="by">iamnotagenius</span><span>|</span><a href="#42786641">prev</a><span>|</span><a href="#42788414">next</a><span>|</span><label class="collapse" for="c-42784970">[-]</label><label class="expand" for="c-42784970">[4 more]</label></div><br/><div class="children"><div class="content">No, but I use llama 3.2 1b and qwen2.5 1.5 as bash oneliner generator, always runnimg in console.</div><br/><div id="42785424" class="c"><input type="checkbox" id="c-42785424" checked=""/><div class="controls bullet"><span class="by">andai</span><span>|</span><a href="#42784970">parent</a><span>|</span><a href="#42786003">next</a><span>|</span><label class="collapse" for="c-42785424">[-]</label><label class="expand" for="c-42785424">[2 more]</label></div><br/><div class="children"><div class="content">Could you elaborate?</div><br/><div id="42785998" class="c"><input type="checkbox" id="c-42785998" checked=""/><div class="controls bullet"><span class="by">XMasterrrr</span><span>|</span><a href="#42784970">root</a><span>|</span><a href="#42785424">parent</a><span>|</span><a href="#42786003">next</a><span>|</span><label class="collapse" for="c-42785998">[-]</label><label class="expand" for="c-42785998">[1 more]</label></div><br/><div class="children"><div class="content">I think I know what he means. I use AI Chat. I load Qwen2.5-1.5B-Instruct with llama.cpp server, fully offloaded to the CPU, and then I config AI Chat to connect to the llama.cpp endpoint.<p>Checkout the demo they have below<p><a href="https:&#x2F;&#x2F;github.com&#x2F;sigoden&#x2F;aichat#shell-assistant">https:&#x2F;&#x2F;github.com&#x2F;sigoden&#x2F;aichat#shell-assistant</a></div><br/></div></div></div></div><div id="42786003" class="c"><input type="checkbox" id="c-42786003" checked=""/><div class="controls bullet"><span class="by">XMasterrrr</span><span>|</span><a href="#42784970">parent</a><span>|</span><a href="#42785424">prev</a><span>|</span><a href="#42788414">next</a><span>|</span><label class="collapse" for="c-42786003">[-]</label><label class="expand" for="c-42786003">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s your workflow like? I use AI Chat. I load Qwen2.5-1.5B-Instruct with llama.cpp server, fully offloaded to the CPU, and then I config AI Chat to connect to the llama.cpp endpoint.</div><br/></div></div></div></div><div id="42788414" class="c"><input type="checkbox" id="c-42788414" checked=""/><div class="controls bullet"><span class="by">linsomniac</span><span>|</span><a href="#42784970">prev</a><span>|</span><a href="#42788807">next</a><span>|</span><label class="collapse" for="c-42788414">[-]</label><label class="expand" for="c-42788414">[1 more]</label></div><br/><div class="children"><div class="content">I have this idea that a tiny LM would be good at canonicalizing entered real estate addresses.  We currently buy a data set and software from Experian, but it feels like something an LM might be very good at.  There are lots of weirdnesses in address entry that regexes have a hard time with.  We know the bulk of addresses a user might be entering, unless it&#x27;s a totally new property, so we should be able to train it on that.</div><br/></div></div><div id="42788807" class="c"><input type="checkbox" id="c-42788807" checked=""/><div class="controls bullet"><span class="by">guywithahat</span><span>|</span><a href="#42788414">prev</a><span>|</span><a href="#42785022">next</a><span>|</span><label class="collapse" for="c-42788807">[-]</label><label class="expand" for="c-42788807">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been working on a self-hosted, low-latency service for small LLM&#x27;s. It&#x27;s basically exactly what I would have wanted when I started my previous startup. The goal is for real time applications, where even the network time to access a fast LLM like groq is an issue.<p>I haven&#x27;t benchmarked it yet but I&#x27;d be happy to hear opinions on it. It&#x27;s written in C++ (specifically not python), and is designed to be a self-contained microservice based around llama.cpp.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;thansen0&#x2F;fastllm.cpp">https:&#x2F;&#x2F;github.com&#x2F;thansen0&#x2F;fastllm.cpp</a></div><br/></div></div><div id="42785022" class="c"><input type="checkbox" id="c-42785022" checked=""/><div class="controls bullet"><span class="by">arionhardison</span><span>|</span><a href="#42788807">prev</a><span>|</span><label class="collapse" for="c-42785022">[-]</label><label class="expand" for="c-42785022">[1 more]</label></div><br/><div class="children"><div class="content">I am, in a way by using EHR&#x2F;EMR data for fine tuning so agents can query each other for medical records in a HIPPA compliant manner.</div><br/></div></div></div></div></div></div></div></body></html>