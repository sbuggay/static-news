<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1708160453223" as="style"/><link rel="stylesheet" href="styles.css?v=1708160453223"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2402.06664">LLM Agents Can Autonomously Hack Websites</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>pella</span> | <span>6 comments</span></div><br/><div><div id="39407696" class="c"><input type="checkbox" id="c-39407696" checked=""/><div class="controls bullet"><span class="by">ActorNightly</span><span>|</span><a href="#39407648">next</a><span>|</span><label class="collapse" for="c-39407696">[-]</label><label class="expand" for="c-39407696">[1 more]</label></div><br/><div class="children"><div class="content">Things to note:<p>1. Hacking a website is not an activity of taking a random website a finding THE vulnerability that lets you hack it. Most of the vulnerabilities listed in the paper are essentially mistakes, and quite easy to avoid with standard development practices like input indirection and sanitization.<p>2. The methodology used by LLMS already exists in a wide array of tool suites for security. The reason script kiddie terms exists is because pretty much most anyone can get Kali linux and follow youtube tutorials on how to do any of that.<p>3. Fundamentally, the uncertainty of the responses with LLMs means that they are unlikely going to be utilized for fear of leaking PII.<p>Most of the exploits these days target the human element because its ironically the easiest. LLMs can definitely make this easier, considering they probably are able to make ad hoc templates for websites faster than manual coding.</div><br/></div></div><div id="39407648" class="c"><input type="checkbox" id="c-39407648" checked=""/><div class="controls bullet"><span class="by">panqueca</span><span>|</span><a href="#39407696">prev</a><span>|</span><a href="#39407692">next</a><span>|</span><label class="collapse" for="c-39407648">[-]</label><label class="expand" for="c-39407648">[1 more]</label></div><br/><div class="children"><div class="content">Neither cybersecurity engineers  are safe from AI</div><br/></div></div><div id="39407692" class="c"><input type="checkbox" id="c-39407692" checked=""/><div class="controls bullet"><span class="by">bbor</span><span>|</span><a href="#39407648">prev</a><span>|</span><a href="#39407590">next</a><span>|</span><label class="collapse" for="c-39407692">[-]</label><label class="expand" for="c-39407692">[1 more]</label></div><br/><div class="children"><div class="content">Great science - always test the obvious. That said, this seems like a kiiiinda dangerous paper from the “publicizing vulnerabilities” perspective. That is, assuming their call to stop LLMs isn’t heeded, lol. For example:<p><pre><code>  …These capabilities are now widely available in standard APIs, such as in the newly released OpenAI Assistants API (OpenAI, 2023). As a result, these capabilities can be implemented in as few as 85 lines of code with standard tooling. We show a schematic of the agent in Figure 1.</code></pre></div><br/></div></div><div id="39407590" class="c"><input type="checkbox" id="c-39407590" checked=""/><div class="controls bullet"><span class="by">your_friend</span><span>|</span><a href="#39407692">prev</a><span>|</span><label class="collapse" for="c-39407590">[-]</label><label class="expand" for="c-39407590">[2 more]</label></div><br/><div class="children"><div class="content">Humans can also autonomously hack websites. Just saying.</div><br/><div id="39407689" class="c"><input type="checkbox" id="c-39407689" checked=""/><div class="controls bullet"><span class="by">_flux</span><span>|</span><a href="#39407590">parent</a><span>|</span><label class="collapse" for="c-39407689">[-]</label><label class="expand" for="c-39407689">[1 more]</label></div><br/><div class="children"><div class="content">Yes, but can you get more people from AWS with a (stolen) credit card, and are those people able to hack websites 24&#x2F;7?</div><br/></div></div></div></div></div></div></div></div></div></body></html>