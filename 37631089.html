<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1695632463156" as="style"/><link rel="stylesheet" href="styles.css?v=1695632463156"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.youtube.com/watch?v=jkrNMKz9pWU">A hacker&#x27;s guide to language models [video]</a>Â <span class="domain">(<a href="https://www.youtube.com">www.youtube.com</a>)</span></div><div class="subtext"><span>rrampage</span> | <span>25 comments</span></div><br/><div><div id="37631506" class="c"><input type="checkbox" id="c-37631506" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#37638465">next</a><span>|</span><label class="collapse" for="c-37631506">[-]</label><label class="expand" for="c-37631506">[1 more]</label></div><br/><div class="children"><div class="content">Oh wow I only just uploaded this and it&#x27;s on HN already!<p>I&#x27;m actually quite excited about this video because I tried my hardest to pack all the key info I could think of into a 90 minute talk -- the goal is to be the one place I point coders at when they ask &quot;hey tell me everything I need to know about LLMs&quot;.<p>Having said that, I&#x27;m sure I missed things or there are bits that are unclear -- this is my first attempt at doing this, and I plan to expand this out into a full course at some point. So please tell me any questions you still have after watching the video, or let me know of any concepts you think I should have covered but didn&#x27;t.<p>I&#x27;m actually heading to bed shortly (it&#x27;s getting late here in Australia!) so not sure I&#x27;ll be able to answer many questions until morning, sorry. But I&#x27;ll definitely take a look at this page when I get up. I&#x27;ll also add links to relevant papers and stuff in the YouTube description tomorrow.<p>(Oh I should mention -- I didn&#x27;t cover any ethical or policy issues; not because they&#x27;re not important, but because I decided to focus entirely on technical issues for this talk.)</div><br/></div></div><div id="37638465" class="c"><input type="checkbox" id="c-37638465" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37631506">prev</a><span>|</span><a href="#37636479">next</a><span>|</span><label class="collapse" for="c-37638465">[-]</label><label class="expand" for="c-37638465">[2 more]</label></div><br/><div class="children"><div class="content">This was excellent. Here&#x27;s the notebook that accompanies the video: <a href="https:&#x2F;&#x2F;github.com&#x2F;fastai&#x2F;lm-hackers&#x2F;blob&#x2F;main&#x2F;lm-hackers.ipynb">https:&#x2F;&#x2F;github.com&#x2F;fastai&#x2F;lm-hackers&#x2F;blob&#x2F;main&#x2F;lm-hackers.ip...</a><p>I thought the selection of projects was great - some OpenAI API hacking including a Code Interpreter imitation created using OpenAI functions, then some Hugging Face model local LLM execution, and then a fine-tuning example to build a text-to-SQL model somehow crammed into just 10 minutes at the end!</div><br/><div id="37638903" class="c"><input type="checkbox" id="c-37638903" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#37638465">parent</a><span>|</span><a href="#37636479">next</a><span>|</span><label class="collapse" for="c-37638903">[-]</label><label class="expand" for="c-37638903">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m glad you like it Simon! And thank you for all the marvellous learning material you&#x27;ve provided. :D</div><br/></div></div></div></div><div id="37636479" class="c"><input type="checkbox" id="c-37636479" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#37638465">prev</a><span>|</span><a href="#37631961">next</a><span>|</span><label class="collapse" for="c-37636479">[-]</label><label class="expand" for="c-37636479">[8 more]</label></div><br/><div class="children"><div class="content">Thanks a lot for this video, best LLM usage tutorial I&#x27;ve seen so far.<p>At <a href="https:&#x2F;&#x2F;youtu.be&#x2F;jkrNMKz9pWU?si=Dvz-Hs4InJXNozhi&amp;t=3278" rel="nofollow noreferrer">https:&#x2F;&#x2F;youtu.be&#x2F;jkrNMKz9pWU?si=Dvz-Hs4InJXNozhi&amp;t=3278</a> when talking about valid use cases for a local model vs GPT4 is: &quot;You might want to create your own model that&#x27;s particularly good at solving the kinds of problems that you need to solve using fine tuning, and these are all things that you absolutely can get better than GPT4 performance&quot;.<p>In regards to this, there&#x27;s an idea I&#x27;ve been thinking about for some time: Imagine a chatbot that is backed by multiple &quot;small&quot; models (such as 7B parameters), where each model is fine tuned for a specific task. Could such a system outperform GPT4?<p>Here&#x27;s a high level overview how I imagine this to work:<p>- Context&#x2F;prompt is sent to a &quot;router model&quot;, which is trained to determine what kind of expert model can best answer&#x2F;complete the prompt.<p>- The system then passes the context&#x2F;prompt to the expert model and returns that answer.<p>- If no expert model is found, just use a generic instruct tuned general purpose LLM to answer<p>If you can theoretically get better than GPT4 performance on a small models fine tuned for that task, maybe a cluster of such small models could collectively outperform GPT4.<p>Does that make sense?</div><br/><div id="37638630" class="c"><input type="checkbox" id="c-37638630" checked=""/><div class="controls bullet"><span class="by">germanjoey</span><span>|</span><a href="#37636479">parent</a><span>|</span><a href="#37637099">next</a><span>|</span><label class="collapse" for="c-37638630">[-]</label><label class="expand" for="c-37638630">[2 more]</label></div><br/><div class="children"><div class="content">Sambanova just launched something similar to what you&#x27;re describing. It&#x27;s a demo of their new chip running a 1T param MoE model 150 7B llama2s, each retrained  to be an expert in a different topic. So one of them is a &quot;law&quot; expert, another on &quot;physics&quot;, etc.<p>They&#x27;ve got a video here [1] (scroll down slightly) that compares it against a 180B Falcon model that&#x27;s running on GPUs on HuggingFace. The MoE results are not only just as good quality-wise, but also ridiculously fast. Like, nearly instant. A big benefit is that the experts can be swapped-out and retrained with new data, which is obviously not as easy with the more monolithic 180B model.<p>[1] <a href="https:&#x2F;&#x2F;sambanova.ai&#x2F;launch2023" rel="nofollow noreferrer">https:&#x2F;&#x2F;sambanova.ai&#x2F;launch2023</a></div><br/><div id="37638750" class="c"><input type="checkbox" id="c-37638750" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#37636479">root</a><span>|</span><a href="#37638630">parent</a><span>|</span><a href="#37637099">next</a><span>|</span><label class="collapse" for="c-37638750">[-]</label><label class="expand" for="c-37638750">[1 more]</label></div><br/><div class="children"><div class="content">Really impressive, thanks for sharing</div><br/></div></div></div></div><div id="37637099" class="c"><input type="checkbox" id="c-37637099" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#37636479">parent</a><span>|</span><a href="#37638630">prev</a><span>|</span><a href="#37636978">next</a><span>|</span><label class="collapse" for="c-37637099">[-]</label><label class="expand" for="c-37637099">[2 more]</label></div><br/><div class="children"><div class="content">It makes a lot of sense! In fact there&#x27;s a number of open source projects working on just such a model right now. Here&#x27;s a great example: <a href="https:&#x2F;&#x2F;github.com&#x2F;XueFuzhao&#x2F;OpenMoE&#x2F;">https:&#x2F;&#x2F;github.com&#x2F;XueFuzhao&#x2F;OpenMoE&#x2F;</a></div><br/><div id="37638758" class="c"><input type="checkbox" id="c-37638758" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#37636479">root</a><span>|</span><a href="#37637099">parent</a><span>|</span><a href="#37636978">next</a><span>|</span><label class="collapse" for="c-37638758">[-]</label><label class="expand" for="c-37638758">[1 more]</label></div><br/><div class="children"><div class="content">Awesome, thanks for sharing.</div><br/></div></div></div></div><div id="37636978" class="c"><input type="checkbox" id="c-37636978" checked=""/><div class="controls bullet"><span class="by">Guillaume86</span><span>|</span><a href="#37636479">parent</a><span>|</span><a href="#37637099">prev</a><span>|</span><a href="#37631961">next</a><span>|</span><label class="collapse" for="c-37636978">[-]</label><label class="expand" for="c-37636978">[3 more]</label></div><br/><div class="children"><div class="content">Search &quot;mixture of experts&quot; on Google, some unverified leaks say GPT4 is using it already.</div><br/><div id="37638763" class="c"><input type="checkbox" id="c-37638763" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#37636479">root</a><span>|</span><a href="#37636978">parent</a><span>|</span><a href="#37631961">next</a><span>|</span><label class="collapse" for="c-37638763">[-]</label><label class="expand" for="c-37638763">[2 more]</label></div><br/><div class="children"><div class="content">Can you share where you read about these leaks?</div><br/><div id="37639877" class="c"><input type="checkbox" id="c-37639877" checked=""/><div class="controls bullet"><span class="by">isaacfung</span><span>|</span><a href="#37636479">root</a><span>|</span><a href="#37638763">parent</a><span>|</span><a href="#37631961">next</a><span>|</span><label class="collapse" for="c-37639877">[-]</label><label class="expand" for="c-37639877">[1 more]</label></div><br/><div class="children"><div class="content">It was all over hackernews. Just google &quot;hacker news gpt4 mixture of experts&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="37631961" class="c"><input type="checkbox" id="c-37631961" checked=""/><div class="controls bullet"><span class="by">etewiah</span><span>|</span><a href="#37636479">prev</a><span>|</span><a href="#37639008">next</a><span>|</span><label class="collapse" for="c-37631961">[-]</label><label class="expand" for="c-37631961">[1 more]</label></div><br/><div class="children"><div class="content">Gems like this make all the time I spend on HN worthwhile.  Thank you so much Jeremy Howard, you are a legend!!</div><br/></div></div><div id="37639008" class="c"><input type="checkbox" id="c-37639008" checked=""/><div class="controls bullet"><span class="by">liamwire</span><span>|</span><a href="#37631961">prev</a><span>|</span><a href="#37638090">next</a><span>|</span><label class="collapse" for="c-37639008">[-]</label><label class="expand" for="c-37639008">[1 more]</label></div><br/><div class="children"><div class="content">Jeremy is an idol of mine, and as someone born and living in Queensland, a reminder that global talent really does exist all around us.<p>(Caveat, of course thereâs many such people in all domains, Jeremy is simply one of the people I both know of, and admire deeply.)</div><br/></div></div><div id="37638090" class="c"><input type="checkbox" id="c-37638090" checked=""/><div class="controls bullet"><span class="by">sabertoothed</span><span>|</span><a href="#37639008">prev</a><span>|</span><a href="#37636548">next</a><span>|</span><label class="collapse" for="c-37638090">[-]</label><label class="expand" for="c-37638090">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re a legend, thank you. You&#x27;re admired all around the world.</div><br/></div></div><div id="37636548" class="c"><input type="checkbox" id="c-37636548" checked=""/><div class="controls bullet"><span class="by">mraza007</span><span>|</span><a href="#37638090">prev</a><span>|</span><a href="#37638349">next</a><span>|</span><label class="collapse" for="c-37636548">[-]</label><label class="expand" for="c-37636548">[1 more]</label></div><br/><div class="children"><div class="content">This is amazing.<p>What an explanation. He clearly break downs concepts making it easier to understand<p>Thatâs why I love HN also discovering something new</div><br/></div></div><div id="37638349" class="c"><input type="checkbox" id="c-37638349" checked=""/><div class="controls bullet"><span class="by">RockRobotRock</span><span>|</span><a href="#37636548">prev</a><span>|</span><a href="#37635801">next</a><span>|</span><label class="collapse" for="c-37638349">[-]</label><label class="expand" for="c-37638349">[2 more]</label></div><br/><div class="children"><div class="content">The most exciting thing about LLMs is how they become easier for intermediate programmers every day. It really makes your imagination run wild when you can grasp the concepts.</div><br/><div id="37640087" class="c"><input type="checkbox" id="c-37640087" checked=""/><div class="controls bullet"><span class="by">jawerty</span><span>|</span><a href="#37638349">parent</a><span>|</span><a href="#37635801">next</a><span>|</span><label class="collapse" for="c-37640087">[-]</label><label class="expand" for="c-37640087">[1 more]</label></div><br/><div class="children"><div class="content">This is what excites me the most. Itâs such a simple interface (prompting) with unlimited capabilities once you look at it as a logic and pattern engine rather than magic</div><br/></div></div></div></div><div id="37635801" class="c"><input type="checkbox" id="c-37635801" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#37638349">prev</a><span>|</span><a href="#37638732">next</a><span>|</span><label class="collapse" for="c-37635801">[-]</label><label class="expand" for="c-37635801">[1 more]</label></div><br/><div class="children"><div class="content">This is by far the best LLM user tutorial I&#x27;ve seen.</div><br/></div></div><div id="37638732" class="c"><input type="checkbox" id="c-37638732" checked=""/><div class="controls bullet"><span class="by">nadavwiz</span><span>|</span><a href="#37635801">prev</a><span>|</span><a href="#37631451">next</a><span>|</span><label class="collapse" for="c-37638732">[-]</label><label class="expand" for="c-37638732">[1 more]</label></div><br/><div class="children"><div class="content">Pretty cool!</div><br/></div></div><div id="37631451" class="c"><input type="checkbox" id="c-37631451" checked=""/><div class="controls bullet"><span class="by">telegpt</span><span>|</span><a href="#37638732">prev</a><span>|</span><a href="#37631619">next</a><span>|</span><label class="collapse" for="c-37631451">[-]</label><label class="expand" for="c-37631451">[3 more]</label></div><br/><div class="children"><div class="content">For those who want to read more about this: <a href="https:&#x2F;&#x2F;blog.musemind.net&#x2F;unleashing-the-power-of-language-models-a-hackers-manifesto&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.musemind.net&#x2F;unleashing-the-power-of-language-m...</a></div><br/><div id="37638459" class="c"><input type="checkbox" id="c-37638459" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#37631451">parent</a><span>|</span><a href="#37631619">next</a><span>|</span><label class="collapse" for="c-37638459">[-]</label><label class="expand" for="c-37638459">[2 more]</label></div><br/><div class="children"><div class="content">Did an LLM write that? It has a writing style that feels very LLM.</div><br/><div id="37638907" class="c"><input type="checkbox" id="c-37638907" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#37631451">root</a><span>|</span><a href="#37638459">parent</a><span>|</span><a href="#37631619">next</a><span>|</span><label class="collapse" for="c-37638907">[-]</label><label class="expand" for="c-37638907">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I&#x27;m pretty sure it did - that website provides a service for just this kind of writing.</div><br/></div></div></div></div></div></div><div id="37631619" class="c"><input type="checkbox" id="c-37631619" checked=""/><div class="controls bullet"><span class="by">dvh</span><span>|</span><a href="#37631451">prev</a><span>|</span><label class="collapse" for="c-37631619">[-]</label><label class="expand" for="c-37631619">[2 more]</label></div><br/><div class="children"><div class="content">As the original author, can you rate this ai generated summary of your video:<p>Video tutorial on language models by Jeremy Howard from fast.ai. In the tutorial, Howard explains the basics of language models and how to use them in practice. He starts by defining a language model as something that can predict the next word of a sentence or fill in missing words. He demonstrates this using an open AI language model called text DaVinci 003.<p>Howard explains that language models work by predicting the probability of various possible next words based on the given context. He shows how to use language models for creative brainstorming and playing with different word predictions.<p>He then discusses language model training and fine-tuning processes, using the ULMfit approach as an example. He explains the three steps of language model training: pre-training, language model fine-tuning, and classifier fine-tuning. He mentions the importance of fine-tuning language models for specific tasks to make them more useful.<p>Howard also demonstrates how to use the open AI API to access language models programmatically. He shows examples of using the API to generate text, ask questions, perform code interpretation, and even extract text from images using OCR.<p>Additionally, he discusses the options for running language models on your own computer, such as using GPUs, renting GPU servers, or utilizing cloud platforms like Kaggle and Colab.<p>He mentions the Transformers library from Hugging Face, which provides pre-trained models and data sets for language processing tasks. He highlights the benefits of fine-tuning models and using retrieval augmented generation to combine document retrieval with language generation.<p>The tutorial concludes with a discussion on other options for running language models, including using private GPT models, Mac-based solutions like H2O GPT and lima.cpp, and the possibility of fine-tuning models with custom data sets.<p>Overall, the tutorial provides a comprehensive overview of language models, their applications, and different ways to use them, both with open AI models and on your own computer.</div><br/><div id="37631641" class="c"><input type="checkbox" id="c-37631641" checked=""/><div class="controls bullet"><span class="by">jph00</span><span>|</span><a href="#37631619">parent</a><span>|</span><label class="collapse" for="c-37631641">[-]</label><label class="expand" for="c-37631641">[1 more]</label></div><br/><div class="children"><div class="content">I think that summary is pretty good, although it doesn&#x27;t really highlight the most interesting bits, such as the fact that we implement a code interpreter from scratch, and that we cover fine-tuning to create a model that successfully converts prose questions into SQL queries.<p>I actually just created my own summary of the bits I&#x27;m most excited about, in case it&#x27;s helpful to folks: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;jeremyphoward&#x2F;status&#x2F;1705883362991472984" rel="nofollow noreferrer">https:&#x2F;&#x2F;twitter.com&#x2F;jeremyphoward&#x2F;status&#x2F;1705883362991472984</a></div><br/></div></div></div></div></div></div></div></div></div></body></html>